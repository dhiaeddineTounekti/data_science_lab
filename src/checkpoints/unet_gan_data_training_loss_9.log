Epoch: 1 | Iteration number: [10/565] 1% | Training loss: 0.764272254705429
Epoch: 1 | Iteration number: [20/565] 3% | Training loss: 0.7293372482061387
Epoch: 1 | Iteration number: [30/565] 5% | Training loss: 0.7175120949745178
Epoch: 1 | Iteration number: [40/565] 7% | Training loss: 0.7116725832223892
Epoch: 1 | Iteration number: [50/565] 8% | Training loss: 0.7081353664398193
Epoch: 1 | Iteration number: [60/565] 10% | Training loss: 0.7057453602552414
Epoch: 1 | Iteration number: [70/565] 12% | Training loss: 0.7040108748844691
Epoch: 1 | Iteration number: [80/565] 14% | Training loss: 0.7027539446949959
Epoch: 1 | Iteration number: [90/565] 15% | Training loss: 0.7017246027787526
Epoch: 1 | Iteration number: [100/565] 17% | Training loss: 0.7009183067083359
Epoch: 1 | Iteration number: [110/565] 19% | Training loss: 0.7002161058512602
Epoch: 1 | Iteration number: [120/565] 21% | Training loss: 0.6996229961514473
Epoch: 1 | Iteration number: [130/565] 23% | Training loss: 0.6991305502561422
Epoch: 1 | Iteration number: [140/565] 24% | Training loss: 0.6986964430127826
Epoch: 1 | Iteration number: [150/565] 26% | Training loss: 0.6983215177059173
Epoch: 1 | Iteration number: [160/565] 28% | Training loss: 0.6979883227497339
Epoch: 1 | Iteration number: [170/565] 30% | Training loss: 0.6976867759928984
Epoch: 1 | Iteration number: [180/565] 31% | Training loss: 0.6974242114358478
Epoch: 1 | Iteration number: [190/565] 33% | Training loss: 0.6971634466397135
Epoch: 1 | Iteration number: [200/565] 35% | Training loss: 0.696928798854351
Epoch: 1 | Iteration number: [210/565] 37% | Training loss: 0.6966989372457777
Epoch: 1 | Iteration number: [220/565] 38% | Training loss: 0.696496306495233
Epoch: 1 | Iteration number: [230/565] 40% | Training loss: 0.6963189456773841
Epoch: 1 | Iteration number: [240/565] 42% | Training loss: 0.6961408530672392
Epoch: 1 | Iteration number: [250/565] 44% | Training loss: 0.6959775834083557
Epoch: 1 | Iteration number: [260/565] 46% | Training loss: 0.6958308864098329
Epoch: 1 | Iteration number: [270/565] 47% | Training loss: 0.6956994791825613
Epoch: 1 | Iteration number: [280/565] 49% | Training loss: 0.695582632294723
Epoch: 1 | Iteration number: [290/565] 51% | Training loss: 0.6954552280491796
Epoch: 1 | Iteration number: [300/565] 53% | Training loss: 0.6953375075260798
Epoch: 1 | Iteration number: [310/565] 54% | Training loss: 0.695240710050829
Epoch: 1 | Iteration number: [320/565] 56% | Training loss: 0.6951284125447273
Epoch: 1 | Iteration number: [330/565] 58% | Training loss: 0.6950256793787986
Epoch: 1 | Iteration number: [340/565] 60% | Training loss: 0.694922244198182
Epoch: 1 | Iteration number: [350/565] 61% | Training loss: 0.6948328455856868
Epoch: 1 | Iteration number: [360/565] 63% | Training loss: 0.6947397786709998
Epoch: 1 | Iteration number: [370/565] 65% | Training loss: 0.6946552850104667
Epoch: 1 | Iteration number: [380/565] 67% | Training loss: 0.6945761992743141
Epoch: 1 | Iteration number: [390/565] 69% | Training loss: 0.6945002390788152
Epoch: 1 | Iteration number: [400/565] 70% | Training loss: 0.6944258113205433
Epoch: 1 | Iteration number: [410/565] 72% | Training loss: 0.694353753764455
Epoch: 1 | Iteration number: [420/565] 74% | Training loss: 0.6942920730227515
Epoch: 1 | Iteration number: [430/565] 76% | Training loss: 0.6942233247812404
Epoch: 1 | Iteration number: [440/565] 77% | Training loss: 0.6941585130312226
Epoch: 1 | Iteration number: [450/565] 79% | Training loss: 0.694100063641866
Epoch: 1 | Iteration number: [460/565] 81% | Training loss: 0.6940370611522508
Epoch: 1 | Iteration number: [470/565] 83% | Training loss: 0.6939767039836722
Epoch: 1 | Iteration number: [480/565] 84% | Training loss: 0.6939159305145343
Epoch: 1 | Iteration number: [490/565] 86% | Training loss: 0.693864764972609
Epoch: 1 | Iteration number: [500/565] 88% | Training loss: 0.6938023785352707
Epoch: 1 | Iteration number: [510/565] 90% | Training loss: 0.6937491814295451
Epoch: 1 | Iteration number: [520/565] 92% | Training loss: 0.6936939404560969
Epoch: 1 | Iteration number: [530/565] 93% | Training loss: 0.6936429043985762
Epoch: 1 | Iteration number: [540/565] 95% | Training loss: 0.6935921795942165
Epoch: 1 | Iteration number: [550/565] 97% | Training loss: 0.6935474066300825
Epoch: 1 | Iteration number: [560/565] 99% | Training loss: 0.6934972160628864

 End of epoch: 1 | Train Loss: 0.6922545636649681 | Training Time: 88 

 End of epoch: 1 | Eval Loss: 0.6932520270347595 | Evaluating Time: 6 
Epoch: 2 | Iteration number: [10/565] 1% | Training loss: 0.7595923542976379
Epoch: 2 | Iteration number: [20/565] 3% | Training loss: 0.7251771181821823
Epoch: 2 | Iteration number: [30/565] 5% | Training loss: 0.7138722240924835
Epoch: 2 | Iteration number: [40/565] 7% | Training loss: 0.7081354260444641
Epoch: 2 | Iteration number: [50/565] 8% | Training loss: 0.7046538674831391
Epoch: 2 | Iteration number: [60/565] 10% | Training loss: 0.7023199439048767
Epoch: 2 | Iteration number: [70/565] 12% | Training loss: 0.7006473975522177
Epoch: 2 | Iteration number: [80/565] 14% | Training loss: 0.6993426643311977
Epoch: 2 | Iteration number: [90/565] 15% | Training loss: 0.6983563085397084
Epoch: 2 | Iteration number: [100/565] 17% | Training loss: 0.6975810807943345
Epoch: 2 | Iteration number: [110/565] 19% | Training loss: 0.6969613617116754
Epoch: 2 | Iteration number: [120/565] 21% | Training loss: 0.6964417358239492
Epoch: 2 | Iteration number: [130/565] 23% | Training loss: 0.6959981702841245
Epoch: 2 | Iteration number: [140/565] 24% | Training loss: 0.6956163253102984
Epoch: 2 | Iteration number: [150/565] 26% | Training loss: 0.6952616067727407
Epoch: 2 | Iteration number: [160/565] 28% | Training loss: 0.6949753321707248
Epoch: 2 | Iteration number: [170/565] 30% | Training loss: 0.6947263486245099
Epoch: 2 | Iteration number: [180/565] 31% | Training loss: 0.6944798883464601
Epoch: 2 | Iteration number: [190/565] 33% | Training loss: 0.6942796202082383
Epoch: 2 | Iteration number: [200/565] 35% | Training loss: 0.6940784692764282
Epoch: 2 | Iteration number: [210/565] 37% | Training loss: 0.6938826302687328
Epoch: 2 | Iteration number: [220/565] 38% | Training loss: 0.6937197525392879
Epoch: 2 | Iteration number: [230/565] 40% | Training loss: 0.6935818120189335
Epoch: 2 | Iteration number: [240/565] 42% | Training loss: 0.6934577648838361
Epoch: 2 | Iteration number: [250/565] 44% | Training loss: 0.6933245680332184
Epoch: 2 | Iteration number: [260/565] 46% | Training loss: 0.6932093150340594
Epoch: 2 | Iteration number: [270/565] 47% | Training loss: 0.6930974560755271
Epoch: 2 | Iteration number: [280/565] 49% | Training loss: 0.6929914751223155
Epoch: 2 | Iteration number: [290/565] 51% | Training loss: 0.6928914731946485
Epoch: 2 | Iteration number: [300/565] 53% | Training loss: 0.6928076553344726
Epoch: 2 | Iteration number: [310/565] 54% | Training loss: 0.6927153819991696
Epoch: 2 | Iteration number: [320/565] 56% | Training loss: 0.6926340727135539
Epoch: 2 | Iteration number: [330/565] 58% | Training loss: 0.6925587023749497
Epoch: 2 | Iteration number: [340/565] 60% | Training loss: 0.6924863438395893
Epoch: 2 | Iteration number: [350/565] 61% | Training loss: 0.6924213579722813
Epoch: 2 | Iteration number: [360/565] 63% | Training loss: 0.6923618518643909
Epoch: 2 | Iteration number: [370/565] 65% | Training loss: 0.6923033483930536
Epoch: 2 | Iteration number: [380/565] 67% | Training loss: 0.6922483387746309
Epoch: 2 | Iteration number: [390/565] 69% | Training loss: 0.6921886346279047
Epoch: 2 | Iteration number: [400/565] 70% | Training loss: 0.6921331399679184
Epoch: 2 | Iteration number: [410/565] 72% | Training loss: 0.6920846892566216
Epoch: 2 | Iteration number: [420/565] 74% | Training loss: 0.6920306807472593
Epoch: 2 | Iteration number: [430/565] 76% | Training loss: 0.6919842774091765
Epoch: 2 | Iteration number: [440/565] 77% | Training loss: 0.6919337177818472
Epoch: 2 | Iteration number: [450/565] 79% | Training loss: 0.6918918274508582
Epoch: 2 | Iteration number: [460/565] 81% | Training loss: 0.6918433445951213
Epoch: 2 | Iteration number: [470/565] 83% | Training loss: 0.6917948845853197
Epoch: 2 | Iteration number: [480/565] 84% | Training loss: 0.6917659635345141
Epoch: 2 | Iteration number: [490/565] 86% | Training loss: 0.6917370027425338
Epoch: 2 | Iteration number: [500/565] 88% | Training loss: 0.6916971023082733
Epoch: 2 | Iteration number: [510/565] 90% | Training loss: 0.6916575061339958
Epoch: 2 | Iteration number: [520/565] 92% | Training loss: 0.6916205999942926
Epoch: 2 | Iteration number: [530/565] 93% | Training loss: 0.6915787446049024
Epoch: 2 | Iteration number: [540/565] 95% | Training loss: 0.6915441378399177
Epoch: 2 | Iteration number: [550/565] 97% | Training loss: 0.6915106119892814
Epoch: 2 | Iteration number: [560/565] 99% | Training loss: 0.6914810137024947

 End of epoch: 2 | Train Loss: 0.69024696656033 | Training Time: 89 

 End of epoch: 2 | Eval Loss: 0.6920813747814724 | Evaluating Time: 6 
Epoch: 3 | Iteration number: [10/565] 1% | Training loss: 0.7588028907775879
Epoch: 3 | Iteration number: [20/565] 3% | Training loss: 0.7241298615932464
Epoch: 3 | Iteration number: [30/565] 5% | Training loss: 0.7126444379488627
Epoch: 3 | Iteration number: [40/565] 7% | Training loss: 0.7068821042776108
Epoch: 3 | Iteration number: [50/565] 8% | Training loss: 0.703418869972229
Epoch: 3 | Iteration number: [60/565] 10% | Training loss: 0.7011639068524043
Epoch: 3 | Iteration number: [70/565] 12% | Training loss: 0.6994590171745845
Epoch: 3 | Iteration number: [80/565] 14% | Training loss: 0.6982028923928738
Epoch: 3 | Iteration number: [90/565] 15% | Training loss: 0.6973035805755191
Epoch: 3 | Iteration number: [100/565] 17% | Training loss: 0.6965580993890762
Epoch: 3 | Iteration number: [110/565] 19% | Training loss: 0.6959162446585568
Epoch: 3 | Iteration number: [120/565] 21% | Training loss: 0.6953804135322571
Epoch: 3 | Iteration number: [130/565] 23% | Training loss: 0.6949407875537872
Epoch: 3 | Iteration number: [140/565] 24% | Training loss: 0.6945705256291799
Epoch: 3 | Iteration number: [150/565] 26% | Training loss: 0.6942308974266053
Epoch: 3 | Iteration number: [160/565] 28% | Training loss: 0.6939564131200313
Epoch: 3 | Iteration number: [170/565] 30% | Training loss: 0.6937143430990331
Epoch: 3 | Iteration number: [180/565] 31% | Training loss: 0.6934808287355635
Epoch: 3 | Iteration number: [190/565] 33% | Training loss: 0.6932467529648229
Epoch: 3 | Iteration number: [200/565] 35% | Training loss: 0.6930692654848098
Epoch: 3 | Iteration number: [210/565] 37% | Training loss: 0.6929167943341391
Epoch: 3 | Iteration number: [220/565] 38% | Training loss: 0.6927600494839928
Epoch: 3 | Iteration number: [230/565] 40% | Training loss: 0.6926097657369531
Epoch: 3 | Iteration number: [240/565] 42% | Training loss: 0.6924672983586788
Epoch: 3 | Iteration number: [250/565] 44% | Training loss: 0.6923392057418823
Epoch: 3 | Iteration number: [260/565] 46% | Training loss: 0.6922369661239477
Epoch: 3 | Iteration number: [270/565] 47% | Training loss: 0.6921204525011557
Epoch: 3 | Iteration number: [280/565] 49% | Training loss: 0.6920292239103999
Epoch: 3 | Iteration number: [290/565] 51% | Training loss: 0.6919406179724068
Epoch: 3 | Iteration number: [300/565] 53% | Training loss: 0.691863451997439
Epoch: 3 | Iteration number: [310/565] 54% | Training loss: 0.6917748245500749
Epoch: 3 | Iteration number: [320/565] 56% | Training loss: 0.6916992526501418
Epoch: 3 | Iteration number: [330/565] 58% | Training loss: 0.6916194079500256
Epoch: 3 | Iteration number: [340/565] 60% | Training loss: 0.6915530709659352
Epoch: 3 | Iteration number: [350/565] 61% | Training loss: 0.6915057327066149
Epoch: 3 | Iteration number: [360/565] 63% | Training loss: 0.6914401297767957
Epoch: 3 | Iteration number: [370/565] 65% | Training loss: 0.691391021818728
Epoch: 3 | Iteration number: [380/565] 67% | Training loss: 0.6913433681977422
Epoch: 3 | Iteration number: [390/565] 69% | Training loss: 0.6912944115125216
Epoch: 3 | Iteration number: [400/565] 70% | Training loss: 0.6912333884835243
Epoch: 3 | Iteration number: [410/565] 72% | Training loss: 0.6911824746829708
Epoch: 3 | Iteration number: [420/565] 74% | Training loss: 0.6911355438686553
Epoch: 3 | Iteration number: [430/565] 76% | Training loss: 0.6910925673884015
Epoch: 3 | Iteration number: [440/565] 77% | Training loss: 0.6910583317279816
Epoch: 3 | Iteration number: [450/565] 79% | Training loss: 0.69101337618298
Epoch: 3 | Iteration number: [460/565] 81% | Training loss: 0.6909753914760507
Epoch: 3 | Iteration number: [470/565] 83% | Training loss: 0.6909351437649829
Epoch: 3 | Iteration number: [480/565] 84% | Training loss: 0.6908893536776304
Epoch: 3 | Iteration number: [490/565] 86% | Training loss: 0.6908537378116529
Epoch: 3 | Iteration number: [500/565] 88% | Training loss: 0.6908153837919235
Epoch: 3 | Iteration number: [510/565] 90% | Training loss: 0.690784895069459
Epoch: 3 | Iteration number: [520/565] 92% | Training loss: 0.6907594684224863
Epoch: 3 | Iteration number: [530/565] 93% | Training loss: 0.6907252346569637
Epoch: 3 | Iteration number: [540/565] 95% | Training loss: 0.6906920402138321
Epoch: 3 | Iteration number: [550/565] 97% | Training loss: 0.6906594114953821
Epoch: 3 | Iteration number: [560/565] 99% | Training loss: 0.6906338324504239

 End of epoch: 3 | Train Loss: 0.6894006500201942 | Training Time: 90 

 End of epoch: 3 | Eval Loss: 0.6916236196245465 | Evaluating Time: 6 
Epoch: 4 | Iteration number: [10/565] 1% | Training loss: 0.7580671668052673
Epoch: 4 | Iteration number: [20/565] 3% | Training loss: 0.7235903322696686
Epoch: 4 | Iteration number: [30/565] 5% | Training loss: 0.7120089789231618
Epoch: 4 | Iteration number: [40/565] 7% | Training loss: 0.7062631487846375
Epoch: 4 | Iteration number: [50/565] 8% | Training loss: 0.7028868746757507
Epoch: 4 | Iteration number: [60/565] 10% | Training loss: 0.7005752970774969
Epoch: 4 | Iteration number: [70/565] 12% | Training loss: 0.6988769769668579
Epoch: 4 | Iteration number: [80/565] 14% | Training loss: 0.6976516127586365
Epoch: 4 | Iteration number: [90/565] 15% | Training loss: 0.6966714176866743
Epoch: 4 | Iteration number: [100/565] 17% | Training loss: 0.6959070175886154
Epoch: 4 | Iteration number: [110/565] 19% | Training loss: 0.6953027345917442
Epoch: 4 | Iteration number: [120/565] 21% | Training loss: 0.6947948530316352
Epoch: 4 | Iteration number: [130/565] 23% | Training loss: 0.6943552163931039
Epoch: 4 | Iteration number: [140/565] 24% | Training loss: 0.6939890967948096
Epoch: 4 | Iteration number: [150/565] 26% | Training loss: 0.6936544799804687
Epoch: 4 | Iteration number: [160/565] 28% | Training loss: 0.6933668281883001
Epoch: 4 | Iteration number: [170/565] 30% | Training loss: 0.6931057453155518
Epoch: 4 | Iteration number: [180/565] 31% | Training loss: 0.6928836719857322
Epoch: 4 | Iteration number: [190/565] 33% | Training loss: 0.6926696827537135
Epoch: 4 | Iteration number: [200/565] 35% | Training loss: 0.6924805524945259
Epoch: 4 | Iteration number: [210/565] 37% | Training loss: 0.6922921351024083
Epoch: 4 | Iteration number: [220/565] 38% | Training loss: 0.692139473286542
Epoch: 4 | Iteration number: [230/565] 40% | Training loss: 0.6919962051122085
Epoch: 4 | Iteration number: [240/565] 42% | Training loss: 0.6918711711963018
Epoch: 4 | Iteration number: [250/565] 44% | Training loss: 0.6917470428943634
Epoch: 4 | Iteration number: [260/565] 46% | Training loss: 0.6916390531338178
Epoch: 4 | Iteration number: [270/565] 47% | Training loss: 0.6915370740272381
Epoch: 4 | Iteration number: [280/565] 49% | Training loss: 0.6914340368338994
Epoch: 4 | Iteration number: [290/565] 51% | Training loss: 0.6913359043927029
Epoch: 4 | Iteration number: [300/565] 53% | Training loss: 0.6912442344427109
Epoch: 4 | Iteration number: [310/565] 54% | Training loss: 0.6911633351156788
Epoch: 4 | Iteration number: [320/565] 56% | Training loss: 0.6910818591713905
Epoch: 4 | Iteration number: [330/565] 58% | Training loss: 0.6910064760482673
Epoch: 4 | Iteration number: [340/565] 60% | Training loss: 0.6909340791842516
Epoch: 4 | Iteration number: [350/565] 61% | Training loss: 0.6908779634748187
Epoch: 4 | Iteration number: [360/565] 63% | Training loss: 0.69081442637576
Epoch: 4 | Iteration number: [370/565] 65% | Training loss: 0.6907647803023055
Epoch: 4 | Iteration number: [380/565] 67% | Training loss: 0.6907184928655624
Epoch: 4 | Iteration number: [390/565] 69% | Training loss: 0.6906672607629727
Epoch: 4 | Iteration number: [400/565] 70% | Training loss: 0.6906189848482609
Epoch: 4 | Iteration number: [410/565] 72% | Training loss: 0.6905817184506393
Epoch: 4 | Iteration number: [420/565] 74% | Training loss: 0.6905351261297862
Epoch: 4 | Iteration number: [430/565] 76% | Training loss: 0.690494207587353
Epoch: 4 | Iteration number: [440/565] 77% | Training loss: 0.6904521421952681
Epoch: 4 | Iteration number: [450/565] 79% | Training loss: 0.6904084353976779
Epoch: 4 | Iteration number: [460/565] 81% | Training loss: 0.6903694855130237
Epoch: 4 | Iteration number: [470/565] 83% | Training loss: 0.6903326148682453
Epoch: 4 | Iteration number: [480/565] 84% | Training loss: 0.6902874739219745
Epoch: 4 | Iteration number: [490/565] 86% | Training loss: 0.6902469001254257
Epoch: 4 | Iteration number: [500/565] 88% | Training loss: 0.6902227095365524
Epoch: 4 | Iteration number: [510/565] 90% | Training loss: 0.6901896622835421
Epoch: 4 | Iteration number: [520/565] 92% | Training loss: 0.6901602737032451
Epoch: 4 | Iteration number: [530/565] 93% | Training loss: 0.6901269270564026
Epoch: 4 | Iteration number: [540/565] 95% | Training loss: 0.6900955884544938
Epoch: 4 | Iteration number: [550/565] 97% | Training loss: 0.6900672728365118
Epoch: 4 | Iteration number: [560/565] 99% | Training loss: 0.6900429769286087

 End of epoch: 4 | Train Loss: 0.6888085920198829 | Training Time: 88 

 End of epoch: 4 | Eval Loss: 0.6909773094313485 | Evaluating Time: 6 
Epoch: 5 | Iteration number: [10/565] 1% | Training loss: 0.7571031987667084
Epoch: 5 | Iteration number: [20/565] 3% | Training loss: 0.7228375166654587
Epoch: 5 | Iteration number: [30/565] 5% | Training loss: 0.7114257375399272
Epoch: 5 | Iteration number: [40/565] 7% | Training loss: 0.7057353124022484
Epoch: 5 | Iteration number: [50/565] 8% | Training loss: 0.7023501491546631
Epoch: 5 | Iteration number: [60/565] 10% | Training loss: 0.7000036925077439
Epoch: 5 | Iteration number: [70/565] 12% | Training loss: 0.698372448342187
Epoch: 5 | Iteration number: [80/565] 14% | Training loss: 0.697170726209879
Epoch: 5 | Iteration number: [90/565] 15% | Training loss: 0.6961520294348399
Epoch: 5 | Iteration number: [100/565] 17% | Training loss: 0.6954002273082733
Epoch: 5 | Iteration number: [110/565] 19% | Training loss: 0.6947676425630396
Epoch: 5 | Iteration number: [120/565] 21% | Training loss: 0.694265112777551
Epoch: 5 | Iteration number: [130/565] 23% | Training loss: 0.6938278775948744
Epoch: 5 | Iteration number: [140/565] 24% | Training loss: 0.6934526890516282
Epoch: 5 | Iteration number: [150/565] 26% | Training loss: 0.693149340947469
Epoch: 5 | Iteration number: [160/565] 28% | Training loss: 0.6928594954311847
Epoch: 5 | Iteration number: [170/565] 30% | Training loss: 0.6925660641754374
Epoch: 5 | Iteration number: [180/565] 31% | Training loss: 0.6923417356279161
Epoch: 5 | Iteration number: [190/565] 33% | Training loss: 0.6921368620897594
Epoch: 5 | Iteration number: [200/565] 35% | Training loss: 0.6919241240620613
Epoch: 5 | Iteration number: [210/565] 37% | Training loss: 0.6917738693101065
Epoch: 5 | Iteration number: [220/565] 38% | Training loss: 0.6916065180843527
Epoch: 5 | Iteration number: [230/565] 40% | Training loss: 0.6914662330046945
Epoch: 5 | Iteration number: [240/565] 42% | Training loss: 0.6913270046313603
Epoch: 5 | Iteration number: [250/565] 44% | Training loss: 0.6912126731872559
Epoch: 5 | Iteration number: [260/565] 46% | Training loss: 0.6910961848038893
Epoch: 5 | Iteration number: [270/565] 47% | Training loss: 0.691001174626527
Epoch: 5 | Iteration number: [280/565] 49% | Training loss: 0.6909029236861638
Epoch: 5 | Iteration number: [290/565] 51% | Training loss: 0.6908171429716308
Epoch: 5 | Iteration number: [300/565] 53% | Training loss: 0.690736153125763
Epoch: 5 | Iteration number: [310/565] 54% | Training loss: 0.6906670195441093
Epoch: 5 | Iteration number: [320/565] 56% | Training loss: 0.690601054392755
Epoch: 5 | Iteration number: [330/565] 58% | Training loss: 0.6905331152858156
Epoch: 5 | Iteration number: [340/565] 60% | Training loss: 0.6904678292134229
Epoch: 5 | Iteration number: [350/565] 61% | Training loss: 0.6903954936776843
Epoch: 5 | Iteration number: [360/565] 63% | Training loss: 0.6903312322166231
Epoch: 5 | Iteration number: [370/565] 65% | Training loss: 0.6902832377601315
Epoch: 5 | Iteration number: [380/565] 67% | Training loss: 0.6902287155389786
Epoch: 5 | Iteration number: [390/565] 69% | Training loss: 0.6901762355596591
Epoch: 5 | Iteration number: [400/565] 70% | Training loss: 0.690137834995985
Epoch: 5 | Iteration number: [410/565] 72% | Training loss: 0.6901013412126681
Epoch: 5 | Iteration number: [420/565] 74% | Training loss: 0.6900591088192803
Epoch: 5 | Iteration number: [430/565] 76% | Training loss: 0.6900140670842903
Epoch: 5 | Iteration number: [440/565] 77% | Training loss: 0.689964712749828
Epoch: 5 | Iteration number: [450/565] 79% | Training loss: 0.6899318993091583
Epoch: 5 | Iteration number: [460/565] 81% | Training loss: 0.6898957332839136
Epoch: 5 | Iteration number: [470/565] 83% | Training loss: 0.6898609973014669
Epoch: 5 | Iteration number: [480/565] 84% | Training loss: 0.689830785493056
Epoch: 5 | Iteration number: [490/565] 86% | Training loss: 0.6897943657271716
Epoch: 5 | Iteration number: [500/565] 88% | Training loss: 0.6897527750730514
Epoch: 5 | Iteration number: [510/565] 90% | Training loss: 0.6897193085913564
Epoch: 5 | Iteration number: [520/565] 92% | Training loss: 0.6896799251437187
Epoch: 5 | Iteration number: [530/565] 93% | Training loss: 0.6896540036741293
Epoch: 5 | Iteration number: [540/565] 95% | Training loss: 0.6896200619362018
Epoch: 5 | Iteration number: [550/565] 97% | Training loss: 0.6895984788374467
Epoch: 5 | Iteration number: [560/565] 99% | Training loss: 0.6895767145923206

 End of epoch: 5 | Train Loss: 0.6883492841129809 | Training Time: 88 

 End of epoch: 5 | Eval Loss: 0.6910172189985003 | Evaluating Time: 6 
Epoch: 6 | Iteration number: [10/565] 1% | Training loss: 0.7571990668773652
Epoch: 6 | Iteration number: [20/565] 3% | Training loss: 0.7228093177080155
Epoch: 6 | Iteration number: [30/565] 5% | Training loss: 0.7113278905550638
Epoch: 6 | Iteration number: [40/565] 7% | Training loss: 0.7054733157157898
Epoch: 6 | Iteration number: [50/565] 8% | Training loss: 0.7020218229293823
Epoch: 6 | Iteration number: [60/565] 10% | Training loss: 0.6996865501006444
Epoch: 6 | Iteration number: [70/565] 12% | Training loss: 0.6979889827115195
Epoch: 6 | Iteration number: [80/565] 14% | Training loss: 0.6967628911137581
Epoch: 6 | Iteration number: [90/565] 15% | Training loss: 0.6958267357614305
Epoch: 6 | Iteration number: [100/565] 17% | Training loss: 0.6950419348478317
Epoch: 6 | Iteration number: [110/565] 19% | Training loss: 0.6944240521300923
Epoch: 6 | Iteration number: [120/565] 21% | Training loss: 0.6939071481426556
Epoch: 6 | Iteration number: [130/565] 23% | Training loss: 0.6934980342021355
Epoch: 6 | Iteration number: [140/565] 24% | Training loss: 0.6931348289762225
Epoch: 6 | Iteration number: [150/565] 26% | Training loss: 0.6927870706717173
Epoch: 6 | Iteration number: [160/565] 28% | Training loss: 0.692478358745575
Epoch: 6 | Iteration number: [170/565] 30% | Training loss: 0.6922082508311552
Epoch: 6 | Iteration number: [180/565] 31% | Training loss: 0.6919676274061203
Epoch: 6 | Iteration number: [190/565] 33% | Training loss: 0.6917537676660638
Epoch: 6 | Iteration number: [200/565] 35% | Training loss: 0.6915603429079056
Epoch: 6 | Iteration number: [210/565] 37% | Training loss: 0.6913955188932873
Epoch: 6 | Iteration number: [220/565] 38% | Training loss: 0.6912397419864481
Epoch: 6 | Iteration number: [230/565] 40% | Training loss: 0.6910903567853182
Epoch: 6 | Iteration number: [240/565] 42% | Training loss: 0.6909538393219312
Epoch: 6 | Iteration number: [250/565] 44% | Training loss: 0.6908229103088379
Epoch: 6 | Iteration number: [260/565] 46% | Training loss: 0.6906901006515209
Epoch: 6 | Iteration number: [270/565] 47% | Training loss: 0.6905902421032941
Epoch: 6 | Iteration number: [280/565] 49% | Training loss: 0.690510074368545
Epoch: 6 | Iteration number: [290/565] 51% | Training loss: 0.6904244427023263
Epoch: 6 | Iteration number: [300/565] 53% | Training loss: 0.6903347001473109
Epoch: 6 | Iteration number: [310/565] 54% | Training loss: 0.6902543588992088
Epoch: 6 | Iteration number: [320/565] 56% | Training loss: 0.6901775160804391
Epoch: 6 | Iteration number: [330/565] 58% | Training loss: 0.690111966566606
Epoch: 6 | Iteration number: [340/565] 60% | Training loss: 0.6900443352320615
Epoch: 6 | Iteration number: [350/565] 61% | Training loss: 0.6899895141805922
Epoch: 6 | Iteration number: [360/565] 63% | Training loss: 0.6899322339230114
Epoch: 6 | Iteration number: [370/565] 65% | Training loss: 0.6898864941017048
Epoch: 6 | Iteration number: [380/565] 67% | Training loss: 0.6898381007345099
Epoch: 6 | Iteration number: [390/565] 69% | Training loss: 0.6897844071571644
Epoch: 6 | Iteration number: [400/565] 70% | Training loss: 0.689748036712408
Epoch: 6 | Iteration number: [410/565] 72% | Training loss: 0.6897104670361774
Epoch: 6 | Iteration number: [420/565] 74% | Training loss: 0.6896639064663932
Epoch: 6 | Iteration number: [430/565] 76% | Training loss: 0.6896206589632257
Epoch: 6 | Iteration number: [440/565] 77% | Training loss: 0.6895840402353893
Epoch: 6 | Iteration number: [450/565] 79% | Training loss: 0.6895472719934251
Epoch: 6 | Iteration number: [460/565] 81% | Training loss: 0.6895069464393284
Epoch: 6 | Iteration number: [470/565] 83% | Training loss: 0.6894873660929659
Epoch: 6 | Iteration number: [480/565] 84% | Training loss: 0.6894692822049061
Epoch: 6 | Iteration number: [490/565] 86% | Training loss: 0.6894350982442194
Epoch: 6 | Iteration number: [500/565] 88% | Training loss: 0.6894136171340942
Epoch: 6 | Iteration number: [510/565] 90% | Training loss: 0.6893877307573955
Epoch: 6 | Iteration number: [520/565] 92% | Training loss: 0.6893580628129152
Epoch: 6 | Iteration number: [530/565] 93% | Training loss: 0.6893256161572798
Epoch: 6 | Iteration number: [540/565] 95% | Training loss: 0.6893035859973342
Epoch: 6 | Iteration number: [550/565] 97% | Training loss: 0.6892834746837616
Epoch: 6 | Iteration number: [560/565] 99% | Training loss: 0.6892568791551249

 End of epoch: 6 | Train Loss: 0.6880264020599095 | Training Time: 89 

 End of epoch: 6 | Eval Loss: 0.6913950954164777 | Evaluating Time: 6 
Epoch: 7 | Iteration number: [10/565] 1% | Training loss: 0.7570053279399872
Epoch: 7 | Iteration number: [20/565] 3% | Training loss: 0.722555723786354
Epoch: 7 | Iteration number: [30/565] 5% | Training loss: 0.7111314177513123
Epoch: 7 | Iteration number: [40/565] 7% | Training loss: 0.7053824186325073
Epoch: 7 | Iteration number: [50/565] 8% | Training loss: 0.7019817864894867
Epoch: 7 | Iteration number: [60/565] 10% | Training loss: 0.6996034522851308
Epoch: 7 | Iteration number: [70/565] 12% | Training loss: 0.6979041150638036
Epoch: 7 | Iteration number: [80/565] 14% | Training loss: 0.6966512635350227
Epoch: 7 | Iteration number: [90/565] 15% | Training loss: 0.6957234316402011
Epoch: 7 | Iteration number: [100/565] 17% | Training loss: 0.6949159514904022
Epoch: 7 | Iteration number: [110/565] 19% | Training loss: 0.6942801719362085
Epoch: 7 | Iteration number: [120/565] 21% | Training loss: 0.6937401364247004
Epoch: 7 | Iteration number: [130/565] 23% | Training loss: 0.6932383349308601
Epoch: 7 | Iteration number: [140/565] 24% | Training loss: 0.6928455557141985
Epoch: 7 | Iteration number: [150/565] 26% | Training loss: 0.6924835928281148
Epoch: 7 | Iteration number: [160/565] 28% | Training loss: 0.6921949677169323
Epoch: 7 | Iteration number: [170/565] 30% | Training loss: 0.6919436177786659
Epoch: 7 | Iteration number: [180/565] 31% | Training loss: 0.6917269703414705
Epoch: 7 | Iteration number: [190/565] 33% | Training loss: 0.6914962696401696
Epoch: 7 | Iteration number: [200/565] 35% | Training loss: 0.6913004314899445
Epoch: 7 | Iteration number: [210/565] 37% | Training loss: 0.6911263150828225
Epoch: 7 | Iteration number: [220/565] 38% | Training loss: 0.6909848099405115
Epoch: 7 | Iteration number: [230/565] 40% | Training loss: 0.6908562921959421
Epoch: 7 | Iteration number: [240/565] 42% | Training loss: 0.6907217308878899
Epoch: 7 | Iteration number: [250/565] 44% | Training loss: 0.6905910663604736
Epoch: 7 | Iteration number: [260/565] 46% | Training loss: 0.6904834421781393
Epoch: 7 | Iteration number: [270/565] 47% | Training loss: 0.6903801617798981
Epoch: 7 | Iteration number: [280/565] 49% | Training loss: 0.690307489676135
Epoch: 7 | Iteration number: [290/565] 51% | Training loss: 0.6902258009746157
Epoch: 7 | Iteration number: [300/565] 53% | Training loss: 0.6901365631818771
Epoch: 7 | Iteration number: [310/565] 54% | Training loss: 0.6900745893678357
Epoch: 7 | Iteration number: [320/565] 56% | Training loss: 0.6900032538920641
Epoch: 7 | Iteration number: [330/565] 58% | Training loss: 0.6899419311321143
Epoch: 7 | Iteration number: [340/565] 60% | Training loss: 0.6898809925598257
Epoch: 7 | Iteration number: [350/565] 61% | Training loss: 0.6898201947552817
Epoch: 7 | Iteration number: [360/565] 63% | Training loss: 0.6897683567470975
Epoch: 7 | Iteration number: [370/565] 65% | Training loss: 0.689716544988993
Epoch: 7 | Iteration number: [380/565] 67% | Training loss: 0.6896778991347865
Epoch: 7 | Iteration number: [390/565] 69% | Training loss: 0.6896136097418957
Epoch: 7 | Iteration number: [400/565] 70% | Training loss: 0.6895645177364349
Epoch: 7 | Iteration number: [410/565] 72% | Training loss: 0.6895236849784852
Epoch: 7 | Iteration number: [420/565] 74% | Training loss: 0.6894723853894642
Epoch: 7 | Iteration number: [430/565] 76% | Training loss: 0.6894297432067782
Epoch: 7 | Iteration number: [440/565] 77% | Training loss: 0.6893869045105847
Epoch: 7 | Iteration number: [450/565] 79% | Training loss: 0.6893549908532036
Epoch: 7 | Iteration number: [460/565] 81% | Training loss: 0.6893187626548435
Epoch: 7 | Iteration number: [470/565] 83% | Training loss: 0.6892869069221171
Epoch: 7 | Iteration number: [480/565] 84% | Training loss: 0.6892593442151944
Epoch: 7 | Iteration number: [490/565] 86% | Training loss: 0.6892318695175405
Epoch: 7 | Iteration number: [500/565] 88% | Training loss: 0.6892027564048767
Epoch: 7 | Iteration number: [510/565] 90% | Training loss: 0.6891737330193614
Epoch: 7 | Iteration number: [520/565] 92% | Training loss: 0.6891441534344966
Epoch: 7 | Iteration number: [530/565] 93% | Training loss: 0.6891219074996012
Epoch: 7 | Iteration number: [540/565] 95% | Training loss: 0.6890977991951837
Epoch: 7 | Iteration number: [550/565] 97% | Training loss: 0.6890722308375619
Epoch: 7 | Iteration number: [560/565] 99% | Training loss: 0.6890521361359528

 End of epoch: 7 | Train Loss: 0.6878225452077072 | Training Time: 87 

 End of epoch: 7 | Eval Loss: 0.6908526931490216 | Evaluating Time: 6 
Epoch: 8 | Iteration number: [10/565] 1% | Training loss: 0.7567204833030701
Epoch: 8 | Iteration number: [20/565] 3% | Training loss: 0.7220910012722015
Epoch: 8 | Iteration number: [30/565] 5% | Training loss: 0.7106556117534637
Epoch: 8 | Iteration number: [40/565] 7% | Training loss: 0.7049347639083863
Epoch: 8 | Iteration number: [50/565] 8% | Training loss: 0.7015157866477967
Epoch: 8 | Iteration number: [60/565] 10% | Training loss: 0.6991950035095215
Epoch: 8 | Iteration number: [70/565] 12% | Training loss: 0.6974925884178707
Epoch: 8 | Iteration number: [80/565] 14% | Training loss: 0.6962022855877876
Epoch: 8 | Iteration number: [90/565] 15% | Training loss: 0.6952960544162327
Epoch: 8 | Iteration number: [100/565] 17% | Training loss: 0.6944943434000015
Epoch: 8 | Iteration number: [110/565] 19% | Training loss: 0.6938758785074407
Epoch: 8 | Iteration number: [120/565] 21% | Training loss: 0.6933127269148827
Epoch: 8 | Iteration number: [130/565] 23% | Training loss: 0.6928748350877029
Epoch: 8 | Iteration number: [140/565] 24% | Training loss: 0.6924917766026089
Epoch: 8 | Iteration number: [150/565] 26% | Training loss: 0.6921857889493307
Epoch: 8 | Iteration number: [160/565] 28% | Training loss: 0.691909684240818
Epoch: 8 | Iteration number: [170/565] 30% | Training loss: 0.6916381594012765
Epoch: 8 | Iteration number: [180/565] 31% | Training loss: 0.6914364470375909
Epoch: 8 | Iteration number: [190/565] 33% | Training loss: 0.691234751124131
Epoch: 8 | Iteration number: [200/565] 35% | Training loss: 0.6910464176535607
Epoch: 8 | Iteration number: [210/565] 37% | Training loss: 0.6908739271618071
Epoch: 8 | Iteration number: [220/565] 38% | Training loss: 0.6907512150027535
Epoch: 8 | Iteration number: [230/565] 40% | Training loss: 0.6906066472115724
Epoch: 8 | Iteration number: [240/565] 42% | Training loss: 0.6904765531420708
Epoch: 8 | Iteration number: [250/565] 44% | Training loss: 0.690357460975647
Epoch: 8 | Iteration number: [260/565] 46% | Training loss: 0.690256574520698
Epoch: 8 | Iteration number: [270/565] 47% | Training loss: 0.6901556065788975
Epoch: 8 | Iteration number: [280/565] 49% | Training loss: 0.6900627500244549
Epoch: 8 | Iteration number: [290/565] 51% | Training loss: 0.6899759440586485
Epoch: 8 | Iteration number: [300/565] 53% | Training loss: 0.6898856987555821
Epoch: 8 | Iteration number: [310/565] 54% | Training loss: 0.6898009015667823
Epoch: 8 | Iteration number: [320/565] 56% | Training loss: 0.6897332351654768
Epoch: 8 | Iteration number: [330/565] 58% | Training loss: 0.6896798825625218
Epoch: 8 | Iteration number: [340/565] 60% | Training loss: 0.6896286391160067
Epoch: 8 | Iteration number: [350/565] 61% | Training loss: 0.6895756137371063
Epoch: 8 | Iteration number: [360/565] 63% | Training loss: 0.689520138502121
Epoch: 8 | Iteration number: [370/565] 65% | Training loss: 0.6894617791111405
Epoch: 8 | Iteration number: [380/565] 67% | Training loss: 0.6894150539448387
Epoch: 8 | Iteration number: [390/565] 69% | Training loss: 0.6893772967350789
Epoch: 8 | Iteration number: [400/565] 70% | Training loss: 0.6893405713140964
Epoch: 8 | Iteration number: [410/565] 72% | Training loss: 0.6893000063372822
Epoch: 8 | Iteration number: [420/565] 74% | Training loss: 0.6892529232161385
Epoch: 8 | Iteration number: [430/565] 76% | Training loss: 0.6892116166824518
Epoch: 8 | Iteration number: [440/565] 77% | Training loss: 0.6891781573945825
Epoch: 8 | Iteration number: [450/565] 79% | Training loss: 0.6891520247194503
Epoch: 8 | Iteration number: [460/565] 81% | Training loss: 0.689120765613473
Epoch: 8 | Iteration number: [470/565] 83% | Training loss: 0.689086074397919
Epoch: 8 | Iteration number: [480/565] 84% | Training loss: 0.6890597297499578
Epoch: 8 | Iteration number: [490/565] 86% | Training loss: 0.6890296487175689
Epoch: 8 | Iteration number: [500/565] 88% | Training loss: 0.6889913109540939
Epoch: 8 | Iteration number: [510/565] 90% | Training loss: 0.6889627976744783
Epoch: 8 | Iteration number: [520/565] 92% | Training loss: 0.6889354568261367
Epoch: 8 | Iteration number: [530/565] 93% | Training loss: 0.6889065024987706
Epoch: 8 | Iteration number: [540/565] 95% | Training loss: 0.6888857371277279
Epoch: 8 | Iteration number: [550/565] 97% | Training loss: 0.688867230090228
Epoch: 8 | Iteration number: [560/565] 99% | Training loss: 0.6888529080365385

 End of epoch: 8 | Train Loss: 0.6876260673050332 | Training Time: 90 

 End of epoch: 8 | Eval Loss: 0.6905708568436759 | Evaluating Time: 6 
Epoch: 9 | Iteration number: [10/565] 1% | Training loss: 0.7559503793716431
Epoch: 9 | Iteration number: [20/565] 3% | Training loss: 0.7217670977115631
Epoch: 9 | Iteration number: [30/565] 5% | Training loss: 0.7102520724137624
Epoch: 9 | Iteration number: [40/565] 7% | Training loss: 0.7045419216156006
Epoch: 9 | Iteration number: [50/565] 8% | Training loss: 0.7011908090114594
Epoch: 9 | Iteration number: [60/565] 10% | Training loss: 0.6988744626442591
Epoch: 9 | Iteration number: [70/565] 12% | Training loss: 0.6973018169403076
Epoch: 9 | Iteration number: [80/565] 14% | Training loss: 0.6961337633430957
Epoch: 9 | Iteration number: [90/565] 15% | Training loss: 0.6952058414618174
Epoch: 9 | Iteration number: [100/565] 17% | Training loss: 0.6944398921728134
Epoch: 9 | Iteration number: [110/565] 19% | Training loss: 0.6938091218471527
Epoch: 9 | Iteration number: [120/565] 21% | Training loss: 0.6933259626229604
Epoch: 9 | Iteration number: [130/565] 23% | Training loss: 0.6928411217836233
Epoch: 9 | Iteration number: [140/565] 24% | Training loss: 0.6924734162432807
Epoch: 9 | Iteration number: [150/565] 26% | Training loss: 0.692129694223404
Epoch: 9 | Iteration number: [160/565] 28% | Training loss: 0.6918520409613848
Epoch: 9 | Iteration number: [170/565] 30% | Training loss: 0.6916030953912174
Epoch: 9 | Iteration number: [180/565] 31% | Training loss: 0.6913839141527812
Epoch: 9 | Iteration number: [190/565] 33% | Training loss: 0.6911951312893315
Epoch: 9 | Iteration number: [200/565] 35% | Training loss: 0.691000069975853
Epoch: 9 | Iteration number: [210/565] 37% | Training loss: 0.690845878635134
Epoch: 9 | Iteration number: [220/565] 38% | Training loss: 0.6907055524262515
Epoch: 9 | Iteration number: [230/565] 40% | Training loss: 0.6905449553676274
Epoch: 9 | Iteration number: [240/565] 42% | Training loss: 0.69042010953029
Epoch: 9 | Iteration number: [250/565] 44% | Training loss: 0.6903122239112854
Epoch: 9 | Iteration number: [260/565] 46% | Training loss: 0.690199562907219
Epoch: 9 | Iteration number: [270/565] 47% | Training loss: 0.6900981885415537
Epoch: 9 | Iteration number: [280/565] 49% | Training loss: 0.6900181929980006
Epoch: 9 | Iteration number: [290/565] 51% | Training loss: 0.6899201837079278
Epoch: 9 | Iteration number: [300/565] 53% | Training loss: 0.6898349626859029
Epoch: 9 | Iteration number: [310/565] 54% | Training loss: 0.6897528267675831
Epoch: 9 | Iteration number: [320/565] 56% | Training loss: 0.6896776676177978
Epoch: 9 | Iteration number: [330/565] 58% | Training loss: 0.6896071495431843
Epoch: 9 | Iteration number: [340/565] 60% | Training loss: 0.6895374035134035
Epoch: 9 | Iteration number: [350/565] 61% | Training loss: 0.6894849760191781
Epoch: 9 | Iteration number: [360/565] 63% | Training loss: 0.6894177916977141
Epoch: 9 | Iteration number: [370/565] 65% | Training loss: 0.6893722245822081
Epoch: 9 | Iteration number: [380/565] 67% | Training loss: 0.6893189157310285
Epoch: 9 | Iteration number: [390/565] 69% | Training loss: 0.6892666864089477
Epoch: 9 | Iteration number: [400/565] 70% | Training loss: 0.689222772270441
Epoch: 9 | Iteration number: [410/565] 72% | Training loss: 0.6891879139876947
Epoch: 9 | Iteration number: [420/565] 74% | Training loss: 0.6891514819292796
Epoch: 9 | Iteration number: [430/565] 76% | Training loss: 0.6891226456608883
Epoch: 9 | Iteration number: [440/565] 77% | Training loss: 0.6890935068780726
Epoch: 9 | Iteration number: [450/565] 79% | Training loss: 0.6890501119030846
Epoch: 9 | Iteration number: [460/565] 81% | Training loss: 0.6890090227127075
Epoch: 9 | Iteration number: [470/565] 83% | Training loss: 0.6889737948458245
Epoch: 9 | Iteration number: [480/565] 84% | Training loss: 0.688940113907059
Epoch: 9 | Iteration number: [490/565] 86% | Training loss: 0.6889089435947184
Epoch: 9 | Iteration number: [500/565] 88% | Training loss: 0.688880778670311
Epoch: 9 | Iteration number: [510/565] 90% | Training loss: 0.6888484106344335
Epoch: 9 | Iteration number: [520/565] 92% | Training loss: 0.6888159098533484
Epoch: 9 | Iteration number: [530/565] 93% | Training loss: 0.6887882772481666
Epoch: 9 | Iteration number: [540/565] 95% | Training loss: 0.6887646360529793
Epoch: 9 | Iteration number: [550/565] 97% | Training loss: 0.6887468750910325
Epoch: 9 | Iteration number: [560/565] 99% | Training loss: 0.6887226750808103

 End of epoch: 9 | Train Loss: 0.6874937167209861 | Training Time: 89 

 End of epoch: 9 | Eval Loss: 0.6905389939035688 | Evaluating Time: 6 
Epoch: 10 | Iteration number: [10/565] 1% | Training loss: 0.7561162829399108
Epoch: 10 | Iteration number: [20/565] 3% | Training loss: 0.7218587696552277
Epoch: 10 | Iteration number: [30/565] 5% | Training loss: 0.7103996117909749
Epoch: 10 | Iteration number: [40/565] 7% | Training loss: 0.704730960726738
Epoch: 10 | Iteration number: [50/565] 8% | Training loss: 0.7013543510437011
Epoch: 10 | Iteration number: [60/565] 10% | Training loss: 0.6990474760532379
Epoch: 10 | Iteration number: [70/565] 12% | Training loss: 0.6974437296390533
Epoch: 10 | Iteration number: [80/565] 14% | Training loss: 0.6961285620927811
Epoch: 10 | Iteration number: [90/565] 15% | Training loss: 0.6951933536264632
Epoch: 10 | Iteration number: [100/565] 17% | Training loss: 0.6944404566287994
Epoch: 10 | Iteration number: [110/565] 19% | Training loss: 0.6937719800255515
Epoch: 10 | Iteration number: [120/565] 21% | Training loss: 0.6932333593567213
Epoch: 10 | Iteration number: [130/565] 23% | Training loss: 0.6927730496113117
Epoch: 10 | Iteration number: [140/565] 24% | Training loss: 0.6924009442329406
Epoch: 10 | Iteration number: [150/565] 26% | Training loss: 0.6920625162124634
Epoch: 10 | Iteration number: [160/565] 28% | Training loss: 0.6917878601700067
Epoch: 10 | Iteration number: [170/565] 30% | Training loss: 0.6915230870246887
Epoch: 10 | Iteration number: [180/565] 31% | Training loss: 0.6912944217522939
Epoch: 10 | Iteration number: [190/565] 33% | Training loss: 0.6910925661262713
Epoch: 10 | Iteration number: [200/565] 35% | Training loss: 0.6909135407209397
Epoch: 10 | Iteration number: [210/565] 37% | Training loss: 0.6907405668780917
Epoch: 10 | Iteration number: [220/565] 38% | Training loss: 0.6906165632334622
Epoch: 10 | Iteration number: [230/565] 40% | Training loss: 0.6904798531013986
Epoch: 10 | Iteration number: [240/565] 42% | Training loss: 0.6903665103018284
Epoch: 10 | Iteration number: [250/565] 44% | Training loss: 0.6902615230083465
Epoch: 10 | Iteration number: [260/565] 46% | Training loss: 0.6901616928669122
Epoch: 10 | Iteration number: [270/565] 47% | Training loss: 0.6900625502621686
Epoch: 10 | Iteration number: [280/565] 49% | Training loss: 0.689961533674172
Epoch: 10 | Iteration number: [290/565] 51% | Training loss: 0.689870685338974
Epoch: 10 | Iteration number: [300/565] 53% | Training loss: 0.6897944370905559
Epoch: 10 | Iteration number: [310/565] 54% | Training loss: 0.6897064468552989
Epoch: 10 | Iteration number: [320/565] 56% | Training loss: 0.689610835723579
Epoch: 10 | Iteration number: [330/565] 58% | Training loss: 0.6895288350004138
Epoch: 10 | Iteration number: [340/565] 60% | Training loss: 0.6894515028771232
Epoch: 10 | Iteration number: [350/565] 61% | Training loss: 0.6893750795296261
Epoch: 10 | Iteration number: [360/565] 63% | Training loss: 0.6893189234866036
Epoch: 10 | Iteration number: [370/565] 65% | Training loss: 0.689267613275631
Epoch: 10 | Iteration number: [380/565] 67% | Training loss: 0.6892175410923205
Epoch: 10 | Iteration number: [390/565] 69% | Training loss: 0.6891621482677949
Epoch: 10 | Iteration number: [400/565] 70% | Training loss: 0.6891188052296638
Epoch: 10 | Iteration number: [410/565] 72% | Training loss: 0.6890660188546995
Epoch: 10 | Iteration number: [420/565] 74% | Training loss: 0.6890268605379831
Epoch: 10 | Iteration number: [430/565] 76% | Training loss: 0.6889964612417443
Epoch: 10 | Iteration number: [440/565] 77% | Training loss: 0.6889666895974766
Epoch: 10 | Iteration number: [450/565] 79% | Training loss: 0.6889305127991571
Epoch: 10 | Iteration number: [460/565] 81% | Training loss: 0.6888862660397654
Epoch: 10 | Iteration number: [470/565] 83% | Training loss: 0.6888612679978634
Epoch: 10 | Iteration number: [480/565] 84% | Training loss: 0.6888227925946315
Epoch: 10 | Iteration number: [490/565] 86% | Training loss: 0.6887767918255865
Epoch: 10 | Iteration number: [500/565] 88% | Training loss: 0.6887560487985611
Epoch: 10 | Iteration number: [510/565] 90% | Training loss: 0.6887185474236807
Epoch: 10 | Iteration number: [520/565] 92% | Training loss: 0.6886898386936922
Epoch: 10 | Iteration number: [530/565] 93% | Training loss: 0.6886544723555726
Epoch: 10 | Iteration number: [540/565] 95% | Training loss: 0.6886322225685473
Epoch: 10 | Iteration number: [550/565] 97% | Training loss: 0.688611718524586
Epoch: 10 | Iteration number: [560/565] 99% | Training loss: 0.688581013998815

 End of epoch: 10 | Train Loss: 0.6873539050068476 | Training Time: 89 

 End of epoch: 10 | Eval Loss: 0.690513551235199 | Evaluating Time: 6 
Epoch: 11 | Iteration number: [10/565] 1% | Training loss: 0.7560018062591553
Epoch: 11 | Iteration number: [20/565] 3% | Training loss: 0.7217556715011597
Epoch: 11 | Iteration number: [30/565] 5% | Training loss: 0.7102008918921153
Epoch: 11 | Iteration number: [40/565] 7% | Training loss: 0.7046249687671662
Epoch: 11 | Iteration number: [50/565] 8% | Training loss: 0.7011675953865051
Epoch: 11 | Iteration number: [60/565] 10% | Training loss: 0.698884230852127
Epoch: 11 | Iteration number: [70/565] 12% | Training loss: 0.6972754495484489
Epoch: 11 | Iteration number: [80/565] 14% | Training loss: 0.6960570514202118
Epoch: 11 | Iteration number: [90/565] 15% | Training loss: 0.6950781987773047
Epoch: 11 | Iteration number: [100/565] 17% | Training loss: 0.6943425291776657
Epoch: 11 | Iteration number: [110/565] 19% | Training loss: 0.69371187470176
Epoch: 11 | Iteration number: [120/565] 21% | Training loss: 0.6931935876607895
Epoch: 11 | Iteration number: [130/565] 23% | Training loss: 0.6927510940111601
Epoch: 11 | Iteration number: [140/565] 24% | Training loss: 0.6923809634787695
Epoch: 11 | Iteration number: [150/565] 26% | Training loss: 0.6920501935482025
Epoch: 11 | Iteration number: [160/565] 28% | Training loss: 0.6917739793658256
Epoch: 11 | Iteration number: [170/565] 30% | Training loss: 0.6915038915241466
Epoch: 11 | Iteration number: [180/565] 31% | Training loss: 0.6912778069575628
Epoch: 11 | Iteration number: [190/565] 33% | Training loss: 0.6910352622207843
Epoch: 11 | Iteration number: [200/565] 35% | Training loss: 0.6908726373314857
Epoch: 11 | Iteration number: [210/565] 37% | Training loss: 0.6907050870713733
Epoch: 11 | Iteration number: [220/565] 38% | Training loss: 0.690543869137764
Epoch: 11 | Iteration number: [230/565] 40% | Training loss: 0.6904014071692591
Epoch: 11 | Iteration number: [240/565] 42% | Training loss: 0.6902671121060848
Epoch: 11 | Iteration number: [250/565] 44% | Training loss: 0.6901417572498322
Epoch: 11 | Iteration number: [260/565] 46% | Training loss: 0.6900440371953525
Epoch: 11 | Iteration number: [270/565] 47% | Training loss: 0.689923549802215
Epoch: 11 | Iteration number: [280/565] 49% | Training loss: 0.6898206101996558
Epoch: 11 | Iteration number: [290/565] 51% | Training loss: 0.689727975376721
Epoch: 11 | Iteration number: [300/565] 53% | Training loss: 0.6896424162387848
Epoch: 11 | Iteration number: [310/565] 54% | Training loss: 0.6895509702544058
Epoch: 11 | Iteration number: [320/565] 56% | Training loss: 0.6894865363836289
Epoch: 11 | Iteration number: [330/565] 58% | Training loss: 0.6894087822148294
Epoch: 11 | Iteration number: [340/565] 60% | Training loss: 0.689358818005113
Epoch: 11 | Iteration number: [350/565] 61% | Training loss: 0.6892947282109941
Epoch: 11 | Iteration number: [360/565] 63% | Training loss: 0.6892397888832622
Epoch: 11 | Iteration number: [370/565] 65% | Training loss: 0.6891956835179716
Epoch: 11 | Iteration number: [380/565] 67% | Training loss: 0.6891461083763524
Epoch: 11 | Iteration number: [390/565] 69% | Training loss: 0.6891069418344742
Epoch: 11 | Iteration number: [400/565] 70% | Training loss: 0.6890571799874305
Epoch: 11 | Iteration number: [410/565] 72% | Training loss: 0.689013201579815
Epoch: 11 | Iteration number: [420/565] 74% | Training loss: 0.6889756421248118
Epoch: 11 | Iteration number: [430/565] 76% | Training loss: 0.6889408459497053
Epoch: 11 | Iteration number: [440/565] 77% | Training loss: 0.6889022221619433
Epoch: 11 | Iteration number: [450/565] 79% | Training loss: 0.6888685941696167
Epoch: 11 | Iteration number: [460/565] 81% | Training loss: 0.6888392642788265
Epoch: 11 | Iteration number: [470/565] 83% | Training loss: 0.6887982539674069
Epoch: 11 | Iteration number: [480/565] 84% | Training loss: 0.6887619679172834
Epoch: 11 | Iteration number: [490/565] 86% | Training loss: 0.6887172486100878
Epoch: 11 | Iteration number: [500/565] 88% | Training loss: 0.6886987180709839
Epoch: 11 | Iteration number: [510/565] 90% | Training loss: 0.6886810275853849
Epoch: 11 | Iteration number: [520/565] 92% | Training loss: 0.6886544856887598
Epoch: 11 | Iteration number: [530/565] 93% | Training loss: 0.6886176311744834
Epoch: 11 | Iteration number: [540/565] 95% | Training loss: 0.6885897058027762
Epoch: 11 | Iteration number: [550/565] 97% | Training loss: 0.6885632921348919
Epoch: 11 | Iteration number: [560/565] 99% | Training loss: 0.6885356322995254

 End of epoch: 11 | Train Loss: 0.6873033536218964 | Training Time: 89 

 End of epoch: 11 | Eval Loss: 0.6906284775052752 | Evaluating Time: 6 
Epoch: 12 | Iteration number: [10/565] 1% | Training loss: 0.7560535967350006
Epoch: 12 | Iteration number: [20/565] 3% | Training loss: 0.7214505523443222
Epoch: 12 | Iteration number: [30/565] 5% | Training loss: 0.7100898464520772
Epoch: 12 | Iteration number: [40/565] 7% | Training loss: 0.7044904336333275
Epoch: 12 | Iteration number: [50/565] 8% | Training loss: 0.7010748147964477
Epoch: 12 | Iteration number: [60/565] 10% | Training loss: 0.6988149295250575
Epoch: 12 | Iteration number: [70/565] 12% | Training loss: 0.6971787921019963
Epoch: 12 | Iteration number: [80/565] 14% | Training loss: 0.6959399983286858
Epoch: 12 | Iteration number: [90/565] 15% | Training loss: 0.6949292010731167
Epoch: 12 | Iteration number: [100/565] 17% | Training loss: 0.6941616863012314
Epoch: 12 | Iteration number: [110/565] 19% | Training loss: 0.6935269155285575
Epoch: 12 | Iteration number: [120/565] 21% | Training loss: 0.6929689481854439
Epoch: 12 | Iteration number: [130/565] 23% | Training loss: 0.692521661061507
Epoch: 12 | Iteration number: [140/565] 24% | Training loss: 0.6921338477305004
Epoch: 12 | Iteration number: [150/565] 26% | Training loss: 0.6918290114402771
Epoch: 12 | Iteration number: [160/565] 28% | Training loss: 0.6915177669376135
Epoch: 12 | Iteration number: [170/565] 30% | Training loss: 0.6912513438393088
Epoch: 12 | Iteration number: [180/565] 31% | Training loss: 0.6910193744632933
Epoch: 12 | Iteration number: [190/565] 33% | Training loss: 0.690822212319625
Epoch: 12 | Iteration number: [200/565] 35% | Training loss: 0.6906608188152313
Epoch: 12 | Iteration number: [210/565] 37% | Training loss: 0.6904859988462357
Epoch: 12 | Iteration number: [220/565] 38% | Training loss: 0.6903239247473804
Epoch: 12 | Iteration number: [230/565] 40% | Training loss: 0.6901959740597269
Epoch: 12 | Iteration number: [240/565] 42% | Training loss: 0.6900703291098277
Epoch: 12 | Iteration number: [250/565] 44% | Training loss: 0.6899437057971954
Epoch: 12 | Iteration number: [260/565] 46% | Training loss: 0.689842406144509
Epoch: 12 | Iteration number: [270/565] 47% | Training loss: 0.6897340383794572
Epoch: 12 | Iteration number: [280/565] 49% | Training loss: 0.6896387892110007
Epoch: 12 | Iteration number: [290/565] 51% | Training loss: 0.6895601482226931
Epoch: 12 | Iteration number: [300/565] 53% | Training loss: 0.6894939339160919
Epoch: 12 | Iteration number: [310/565] 54% | Training loss: 0.6894272073622673
Epoch: 12 | Iteration number: [320/565] 56% | Training loss: 0.6893459860235452
Epoch: 12 | Iteration number: [330/565] 58% | Training loss: 0.6892921509164752
Epoch: 12 | Iteration number: [340/565] 60% | Training loss: 0.6892261861001744
Epoch: 12 | Iteration number: [350/565] 61% | Training loss: 0.6891680891173226
Epoch: 12 | Iteration number: [360/565] 63% | Training loss: 0.6891172672311465
Epoch: 12 | Iteration number: [370/565] 65% | Training loss: 0.6890675216107756
Epoch: 12 | Iteration number: [380/565] 67% | Training loss: 0.6890148936133635
Epoch: 12 | Iteration number: [390/565] 69% | Training loss: 0.6889744527828999
Epoch: 12 | Iteration number: [400/565] 70% | Training loss: 0.6889409689605236
Epoch: 12 | Iteration number: [410/565] 72% | Training loss: 0.6888976792009865
Epoch: 12 | Iteration number: [420/565] 74% | Training loss: 0.688863842118354
Epoch: 12 | Iteration number: [430/565] 76% | Training loss: 0.6888203185658123
Epoch: 12 | Iteration number: [440/565] 77% | Training loss: 0.6887893980199641
Epoch: 12 | Iteration number: [450/565] 79% | Training loss: 0.6887540658315022
Epoch: 12 | Iteration number: [460/565] 81% | Training loss: 0.6887230275765709
Epoch: 12 | Iteration number: [470/565] 83% | Training loss: 0.6887063900206951
Epoch: 12 | Iteration number: [480/565] 84% | Training loss: 0.6886789572735628
Epoch: 12 | Iteration number: [490/565] 86% | Training loss: 0.6886403696877615
Epoch: 12 | Iteration number: [500/565] 88% | Training loss: 0.6886100882291794
Epoch: 12 | Iteration number: [510/565] 90% | Training loss: 0.688579705883475
Epoch: 12 | Iteration number: [520/565] 92% | Training loss: 0.6885530988757427
Epoch: 12 | Iteration number: [530/565] 93% | Training loss: 0.6885182675325645
Epoch: 12 | Iteration number: [540/565] 95% | Training loss: 0.688485582559197
Epoch: 12 | Iteration number: [550/565] 97% | Training loss: 0.6884656688300046
Epoch: 12 | Iteration number: [560/565] 99% | Training loss: 0.6884438810603959

 End of epoch: 12 | Train Loss: 0.687214562428736 | Training Time: 89 

 End of epoch: 12 | Eval Loss: 0.6901211397988456 | Evaluating Time: 6 
Epoch: 13 | Iteration number: [10/565] 1% | Training loss: 0.7558666348457337
Epoch: 13 | Iteration number: [20/565] 3% | Training loss: 0.7216268181800842
Epoch: 13 | Iteration number: [30/565] 5% | Training loss: 0.7103536864121754
Epoch: 13 | Iteration number: [40/565] 7% | Training loss: 0.7046078845858574
Epoch: 13 | Iteration number: [50/565] 8% | Training loss: 0.7011938059329986
Epoch: 13 | Iteration number: [60/565] 10% | Training loss: 0.6988221397002538
Epoch: 13 | Iteration number: [70/565] 12% | Training loss: 0.6971548897879464
Epoch: 13 | Iteration number: [80/565] 14% | Training loss: 0.6959000512957573
Epoch: 13 | Iteration number: [90/565] 15% | Training loss: 0.694885993666119
Epoch: 13 | Iteration number: [100/565] 17% | Training loss: 0.6941072767972947
Epoch: 13 | Iteration number: [110/565] 19% | Training loss: 0.6935152162205089
Epoch: 13 | Iteration number: [120/565] 21% | Training loss: 0.6929602319995563
Epoch: 13 | Iteration number: [130/565] 23% | Training loss: 0.6924905689863058
Epoch: 13 | Iteration number: [140/565] 24% | Training loss: 0.6920978380101067
Epoch: 13 | Iteration number: [150/565] 26% | Training loss: 0.6917678455511729
Epoch: 13 | Iteration number: [160/565] 28% | Training loss: 0.6914748173207045
Epoch: 13 | Iteration number: [170/565] 30% | Training loss: 0.6912152809255263
Epoch: 13 | Iteration number: [180/565] 31% | Training loss: 0.6909848190016217
Epoch: 13 | Iteration number: [190/565] 33% | Training loss: 0.6907876425667813
Epoch: 13 | Iteration number: [200/565] 35% | Training loss: 0.6906213411688804
Epoch: 13 | Iteration number: [210/565] 37% | Training loss: 0.6904583999088832
Epoch: 13 | Iteration number: [220/565] 38% | Training loss: 0.690311349792914
Epoch: 13 | Iteration number: [230/565] 40% | Training loss: 0.6901795636052671
Epoch: 13 | Iteration number: [240/565] 42% | Training loss: 0.6900417464474837
Epoch: 13 | Iteration number: [250/565] 44% | Training loss: 0.689924120426178
Epoch: 13 | Iteration number: [260/565] 46% | Training loss: 0.6898074558148017
Epoch: 13 | Iteration number: [270/565] 47% | Training loss: 0.6897239062521193
Epoch: 13 | Iteration number: [280/565] 49% | Training loss: 0.6896217614412308
Epoch: 13 | Iteration number: [290/565] 51% | Training loss: 0.6895375136671396
Epoch: 13 | Iteration number: [300/565] 53% | Training loss: 0.6894629253943761
Epoch: 13 | Iteration number: [310/565] 54% | Training loss: 0.6893570684617566
Epoch: 13 | Iteration number: [320/565] 56% | Training loss: 0.6892938170582056
Epoch: 13 | Iteration number: [330/565] 58% | Training loss: 0.6892296765789842
Epoch: 13 | Iteration number: [340/565] 60% | Training loss: 0.6891601054107441
Epoch: 13 | Iteration number: [350/565] 61% | Training loss: 0.6890986391476223
Epoch: 13 | Iteration number: [360/565] 63% | Training loss: 0.6890484987033738
Epoch: 13 | Iteration number: [370/565] 65% | Training loss: 0.6890050420889984
Epoch: 13 | Iteration number: [380/565] 67% | Training loss: 0.6889526856573005
Epoch: 13 | Iteration number: [390/565] 69% | Training loss: 0.6889106397445385
Epoch: 13 | Iteration number: [400/565] 70% | Training loss: 0.6888771030306816
Epoch: 13 | Iteration number: [410/565] 72% | Training loss: 0.6888348982101533
Epoch: 13 | Iteration number: [420/565] 74% | Training loss: 0.6888019889593124
Epoch: 13 | Iteration number: [430/565] 76% | Training loss: 0.6887653302314669
Epoch: 13 | Iteration number: [440/565] 77% | Training loss: 0.688731957023794
Epoch: 13 | Iteration number: [450/565] 79% | Training loss: 0.6886949551105499
Epoch: 13 | Iteration number: [460/565] 81% | Training loss: 0.6886583666438642
Epoch: 13 | Iteration number: [470/565] 83% | Training loss: 0.6886265447799196
Epoch: 13 | Iteration number: [480/565] 84% | Training loss: 0.6885906606912613
Epoch: 13 | Iteration number: [490/565] 86% | Training loss: 0.6885595061341111
Epoch: 13 | Iteration number: [500/565] 88% | Training loss: 0.6885286808013916
Epoch: 13 | Iteration number: [510/565] 90% | Training loss: 0.6884964449732911
Epoch: 13 | Iteration number: [520/565] 92% | Training loss: 0.6884649907167141
Epoch: 13 | Iteration number: [530/565] 93% | Training loss: 0.6884434733750685
Epoch: 13 | Iteration number: [540/565] 95% | Training loss: 0.6884203697796221
Epoch: 13 | Iteration number: [550/565] 97% | Training loss: 0.6883947409283031
Epoch: 13 | Iteration number: [560/565] 99% | Training loss: 0.6883696371955531

 End of epoch: 13 | Train Loss: 0.6871363432006499 | Training Time: 89 

 End of epoch: 13 | Eval Loss: 0.6903640713010516 | Evaluating Time: 6 
Epoch: 14 | Iteration number: [10/565] 1% | Training loss: 0.7557755649089813
Epoch: 14 | Iteration number: [20/565] 3% | Training loss: 0.7211229234933854
Epoch: 14 | Iteration number: [30/565] 5% | Training loss: 0.7097354670365651
Epoch: 14 | Iteration number: [40/565] 7% | Training loss: 0.7040512651205063
Epoch: 14 | Iteration number: [50/565] 8% | Training loss: 0.700691704750061
Epoch: 14 | Iteration number: [60/565] 10% | Training loss: 0.6984252780675888
Epoch: 14 | Iteration number: [70/565] 12% | Training loss: 0.696807530096599
Epoch: 14 | Iteration number: [80/565] 14% | Training loss: 0.6955908045172692
Epoch: 14 | Iteration number: [90/565] 15% | Training loss: 0.6946788595782386
Epoch: 14 | Iteration number: [100/565] 17% | Training loss: 0.6939215046167374
Epoch: 14 | Iteration number: [110/565] 19% | Training loss: 0.693332436951724
Epoch: 14 | Iteration number: [120/565] 21% | Training loss: 0.6928368647893269
Epoch: 14 | Iteration number: [130/565] 23% | Training loss: 0.6923993298640618
Epoch: 14 | Iteration number: [140/565] 24% | Training loss: 0.692027627996036
Epoch: 14 | Iteration number: [150/565] 26% | Training loss: 0.6916938241322835
Epoch: 14 | Iteration number: [160/565] 28% | Training loss: 0.6913863178342581
Epoch: 14 | Iteration number: [170/565] 30% | Training loss: 0.6911387373419369
Epoch: 14 | Iteration number: [180/565] 31% | Training loss: 0.6909573472208447
Epoch: 14 | Iteration number: [190/565] 33% | Training loss: 0.6907705021531958
Epoch: 14 | Iteration number: [200/565] 35% | Training loss: 0.6905735406279564
Epoch: 14 | Iteration number: [210/565] 37% | Training loss: 0.6904018626326607
Epoch: 14 | Iteration number: [220/565] 38% | Training loss: 0.6902608641169288
Epoch: 14 | Iteration number: [230/565] 40% | Training loss: 0.6901013845982759
Epoch: 14 | Iteration number: [240/565] 42% | Training loss: 0.689956055333217
Epoch: 14 | Iteration number: [250/565] 44% | Training loss: 0.6898385767936707
Epoch: 14 | Iteration number: [260/565] 46% | Training loss: 0.6897154803459461
Epoch: 14 | Iteration number: [270/565] 47% | Training loss: 0.6896204162527013
Epoch: 14 | Iteration number: [280/565] 49% | Training loss: 0.6895336815289088
Epoch: 14 | Iteration number: [290/565] 51% | Training loss: 0.6894483070949028
Epoch: 14 | Iteration number: [300/565] 53% | Training loss: 0.6893659907579422
Epoch: 14 | Iteration number: [310/565] 54% | Training loss: 0.6892953499670952
Epoch: 14 | Iteration number: [320/565] 56% | Training loss: 0.6892295585945248
Epoch: 14 | Iteration number: [330/565] 58% | Training loss: 0.6891805200865775
Epoch: 14 | Iteration number: [340/565] 60% | Training loss: 0.6891197421971489
Epoch: 14 | Iteration number: [350/565] 61% | Training loss: 0.6890771152291979
Epoch: 14 | Iteration number: [360/565] 63% | Training loss: 0.6890324162112342
Epoch: 14 | Iteration number: [370/565] 65% | Training loss: 0.6889777065934362
Epoch: 14 | Iteration number: [380/565] 67% | Training loss: 0.6889275307718076
Epoch: 14 | Iteration number: [390/565] 69% | Training loss: 0.6888810466497373
Epoch: 14 | Iteration number: [400/565] 70% | Training loss: 0.6888351035118103
Epoch: 14 | Iteration number: [410/565] 72% | Training loss: 0.6887911657007729
Epoch: 14 | Iteration number: [420/565] 74% | Training loss: 0.6887544894502277
Epoch: 14 | Iteration number: [430/565] 76% | Training loss: 0.6887250567591467
Epoch: 14 | Iteration number: [440/565] 77% | Training loss: 0.6886881352825598
Epoch: 14 | Iteration number: [450/565] 79% | Training loss: 0.6886499781078762
Epoch: 14 | Iteration number: [460/565] 81% | Training loss: 0.6886126375716666
Epoch: 14 | Iteration number: [470/565] 83% | Training loss: 0.6885698991887113
Epoch: 14 | Iteration number: [480/565] 84% | Training loss: 0.6885424956679345
Epoch: 14 | Iteration number: [490/565] 86% | Training loss: 0.6885142441915006
Epoch: 14 | Iteration number: [500/565] 88% | Training loss: 0.6884867315292358
Epoch: 14 | Iteration number: [510/565] 90% | Training loss: 0.68845421017385
Epoch: 14 | Iteration number: [520/565] 92% | Training loss: 0.6884321132531532
Epoch: 14 | Iteration number: [530/565] 93% | Training loss: 0.6884051081144584
Epoch: 14 | Iteration number: [540/565] 95% | Training loss: 0.6883725594591211
Epoch: 14 | Iteration number: [550/565] 97% | Training loss: 0.6883512324636633
Epoch: 14 | Iteration number: [560/565] 99% | Training loss: 0.6883276605180332

 End of epoch: 14 | Train Loss: 0.6871024897668214 | Training Time: 90 

 End of epoch: 14 | Eval Loss: 0.6901362112590245 | Evaluating Time: 6 
Epoch: 15 | Iteration number: [10/565] 1% | Training loss: 0.7557833075523377
Epoch: 15 | Iteration number: [20/565] 3% | Training loss: 0.7215068191289902
Epoch: 15 | Iteration number: [30/565] 5% | Training loss: 0.7100203931331635
Epoch: 15 | Iteration number: [40/565] 7% | Training loss: 0.7043108522891999
Epoch: 15 | Iteration number: [50/565] 8% | Training loss: 0.7007503652572632
Epoch: 15 | Iteration number: [60/565] 10% | Training loss: 0.6984574834505717
Epoch: 15 | Iteration number: [70/565] 12% | Training loss: 0.696763574225562
Epoch: 15 | Iteration number: [80/565] 14% | Training loss: 0.6955451808869839
Epoch: 15 | Iteration number: [90/565] 15% | Training loss: 0.6946060551537407
Epoch: 15 | Iteration number: [100/565] 17% | Training loss: 0.6938291573524475
Epoch: 15 | Iteration number: [110/565] 19% | Training loss: 0.6932364772666585
Epoch: 15 | Iteration number: [120/565] 21% | Training loss: 0.692748361825943
Epoch: 15 | Iteration number: [130/565] 23% | Training loss: 0.6923318211848919
Epoch: 15 | Iteration number: [140/565] 24% | Training loss: 0.6919520646333694
Epoch: 15 | Iteration number: [150/565] 26% | Training loss: 0.6916127479076386
Epoch: 15 | Iteration number: [160/565] 28% | Training loss: 0.6913286730647087
Epoch: 15 | Iteration number: [170/565] 30% | Training loss: 0.6910859167575836
Epoch: 15 | Iteration number: [180/565] 31% | Training loss: 0.6908602880107032
Epoch: 15 | Iteration number: [190/565] 33% | Training loss: 0.6906610548496246
Epoch: 15 | Iteration number: [200/565] 35% | Training loss: 0.6904855519533157
Epoch: 15 | Iteration number: [210/565] 37% | Training loss: 0.6903334901446387
Epoch: 15 | Iteration number: [220/565] 38% | Training loss: 0.6901884157549251
Epoch: 15 | Iteration number: [230/565] 40% | Training loss: 0.6900667955046115
Epoch: 15 | Iteration number: [240/565] 42% | Training loss: 0.6899569685260455
Epoch: 15 | Iteration number: [250/565] 44% | Training loss: 0.689840136051178
Epoch: 15 | Iteration number: [260/565] 46% | Training loss: 0.6897105434766182
Epoch: 15 | Iteration number: [270/565] 47% | Training loss: 0.6896159902766898
Epoch: 15 | Iteration number: [280/565] 49% | Training loss: 0.6895369223185948
Epoch: 15 | Iteration number: [290/565] 51% | Training loss: 0.6894405743171429
Epoch: 15 | Iteration number: [300/565] 53% | Training loss: 0.6893561611572901
Epoch: 15 | Iteration number: [310/565] 54% | Training loss: 0.6892876390487918
Epoch: 15 | Iteration number: [320/565] 56% | Training loss: 0.6892344204708933
Epoch: 15 | Iteration number: [330/565] 58% | Training loss: 0.6891580520254192
Epoch: 15 | Iteration number: [340/565] 60% | Training loss: 0.6890936520169763
Epoch: 15 | Iteration number: [350/565] 61% | Training loss: 0.6890446712289537
Epoch: 15 | Iteration number: [360/565] 63% | Training loss: 0.6889936281575098
Epoch: 15 | Iteration number: [370/565] 65% | Training loss: 0.6889499259961618
Epoch: 15 | Iteration number: [380/565] 67% | Training loss: 0.6888908971297113
Epoch: 15 | Iteration number: [390/565] 69% | Training loss: 0.688853181936802
Epoch: 15 | Iteration number: [400/565] 70% | Training loss: 0.6888025215268135
Epoch: 15 | Iteration number: [410/565] 72% | Training loss: 0.6887694411161469
Epoch: 15 | Iteration number: [420/565] 74% | Training loss: 0.6887252847353618
Epoch: 15 | Iteration number: [430/565] 76% | Training loss: 0.6886922563231268
Epoch: 15 | Iteration number: [440/565] 77% | Training loss: 0.6886615692214533
Epoch: 15 | Iteration number: [450/565] 79% | Training loss: 0.6886215153005388
Epoch: 15 | Iteration number: [460/565] 81% | Training loss: 0.68858459578908
Epoch: 15 | Iteration number: [470/565] 83% | Training loss: 0.688548113056954
Epoch: 15 | Iteration number: [480/565] 84% | Training loss: 0.688513966028889
Epoch: 15 | Iteration number: [490/565] 86% | Training loss: 0.6884827407038941
Epoch: 15 | Iteration number: [500/565] 88% | Training loss: 0.6884573138952256
Epoch: 15 | Iteration number: [510/565] 90% | Training loss: 0.6884346489812814
Epoch: 15 | Iteration number: [520/565] 92% | Training loss: 0.6884020210458682
Epoch: 15 | Iteration number: [530/565] 93% | Training loss: 0.6883796393871308
Epoch: 15 | Iteration number: [540/565] 95% | Training loss: 0.6883611708879471
Epoch: 15 | Iteration number: [550/565] 97% | Training loss: 0.6883348834514618
Epoch: 15 | Iteration number: [560/565] 99% | Training loss: 0.6883150792547634

 End of epoch: 15 | Train Loss: 0.6870825666241941 | Training Time: 89 

 End of epoch: 15 | Eval Loss: 0.6905664886747088 | Evaluating Time: 5 
Epoch: 16 | Iteration number: [10/565] 1% | Training loss: 0.7558993339538574
Epoch: 16 | Iteration number: [20/565] 3% | Training loss: 0.7216393947601318
Epoch: 16 | Iteration number: [30/565] 5% | Training loss: 0.710194609562556
Epoch: 16 | Iteration number: [40/565] 7% | Training loss: 0.7044026017189026
Epoch: 16 | Iteration number: [50/565] 8% | Training loss: 0.7009165418148041
Epoch: 16 | Iteration number: [60/565] 10% | Training loss: 0.6986921648184459
Epoch: 16 | Iteration number: [70/565] 12% | Training loss: 0.6969939070088523
Epoch: 16 | Iteration number: [80/565] 14% | Training loss: 0.6957389242947102
Epoch: 16 | Iteration number: [90/565] 15% | Training loss: 0.6948102023866441
Epoch: 16 | Iteration number: [100/565] 17% | Training loss: 0.6940538227558136
Epoch: 16 | Iteration number: [110/565] 19% | Training loss: 0.6934051058509133
Epoch: 16 | Iteration number: [120/565] 21% | Training loss: 0.6928866133093834
Epoch: 16 | Iteration number: [130/565] 23% | Training loss: 0.692464043543889
Epoch: 16 | Iteration number: [140/565] 24% | Training loss: 0.6920911086457117
Epoch: 16 | Iteration number: [150/565] 26% | Training loss: 0.6917865002155303
Epoch: 16 | Iteration number: [160/565] 28% | Training loss: 0.6914921183139086
Epoch: 16 | Iteration number: [170/565] 30% | Training loss: 0.6912514735670651
Epoch: 16 | Iteration number: [180/565] 31% | Training loss: 0.6909925950898065
Epoch: 16 | Iteration number: [190/565] 33% | Training loss: 0.6907989062761005
Epoch: 16 | Iteration number: [200/565] 35% | Training loss: 0.6905978041887283
Epoch: 16 | Iteration number: [210/565] 37% | Training loss: 0.6904225133714221
Epoch: 16 | Iteration number: [220/565] 38% | Training loss: 0.6902837300842458
Epoch: 16 | Iteration number: [230/565] 40% | Training loss: 0.690123204562975
Epoch: 16 | Iteration number: [240/565] 42% | Training loss: 0.6899786246319611
Epoch: 16 | Iteration number: [250/565] 44% | Training loss: 0.689871239900589
Epoch: 16 | Iteration number: [260/565] 46% | Training loss: 0.689762266094868
Epoch: 16 | Iteration number: [270/565] 47% | Training loss: 0.6896662882080784
Epoch: 16 | Iteration number: [280/565] 49% | Training loss: 0.6895936584898403
Epoch: 16 | Iteration number: [290/565] 51% | Training loss: 0.6895017305324818
Epoch: 16 | Iteration number: [300/565] 53% | Training loss: 0.6894293439388275
Epoch: 16 | Iteration number: [310/565] 54% | Training loss: 0.6893491773836075
Epoch: 16 | Iteration number: [320/565] 56% | Training loss: 0.6892760546877981
Epoch: 16 | Iteration number: [330/565] 58% | Training loss: 0.6891980913552371
Epoch: 16 | Iteration number: [340/565] 60% | Training loss: 0.6891250822473974
Epoch: 16 | Iteration number: [350/565] 61% | Training loss: 0.6890542794976916
Epoch: 16 | Iteration number: [360/565] 63% | Training loss: 0.6889938781658809
Epoch: 16 | Iteration number: [370/565] 65% | Training loss: 0.6889351520989392
Epoch: 16 | Iteration number: [380/565] 67% | Training loss: 0.6888832062482834
Epoch: 16 | Iteration number: [390/565] 69% | Training loss: 0.6888267061649225
Epoch: 16 | Iteration number: [400/565] 70% | Training loss: 0.6887900587916375
Epoch: 16 | Iteration number: [410/565] 72% | Training loss: 0.688752110266104
Epoch: 16 | Iteration number: [420/565] 74% | Training loss: 0.6887149265834264
Epoch: 16 | Iteration number: [430/565] 76% | Training loss: 0.6886687838753989
Epoch: 16 | Iteration number: [440/565] 77% | Training loss: 0.6886349535801194
Epoch: 16 | Iteration number: [450/565] 79% | Training loss: 0.6885999707380931
Epoch: 16 | Iteration number: [460/565] 81% | Training loss: 0.6885580100443052
Epoch: 16 | Iteration number: [470/565] 83% | Training loss: 0.688521407766545
Epoch: 16 | Iteration number: [480/565] 84% | Training loss: 0.688487293322881
Epoch: 16 | Iteration number: [490/565] 86% | Training loss: 0.6884533025780503
Epoch: 16 | Iteration number: [500/565] 88% | Training loss: 0.6884267610311509
Epoch: 16 | Iteration number: [510/565] 90% | Training loss: 0.6883938309024362
Epoch: 16 | Iteration number: [520/565] 92% | Training loss: 0.6883643579024535
Epoch: 16 | Iteration number: [530/565] 93% | Training loss: 0.6883390846117488
Epoch: 16 | Iteration number: [540/565] 95% | Training loss: 0.6883087498170358
Epoch: 16 | Iteration number: [550/565] 97% | Training loss: 0.6882830774784088
Epoch: 16 | Iteration number: [560/565] 99% | Training loss: 0.6882665136030742

 End of epoch: 16 | Train Loss: 0.6870413043857676 | Training Time: 90 

 End of epoch: 16 | Eval Loss: 0.6906148280416217 | Evaluating Time: 6 
Epoch: 17 | Iteration number: [10/565] 1% | Training loss: 0.7560657858848572
Epoch: 17 | Iteration number: [20/565] 3% | Training loss: 0.7213347762823105
Epoch: 17 | Iteration number: [30/565] 5% | Training loss: 0.7099537094434102
Epoch: 17 | Iteration number: [40/565] 7% | Training loss: 0.7040705680847168
Epoch: 17 | Iteration number: [50/565] 8% | Training loss: 0.7007163488864898
Epoch: 17 | Iteration number: [60/565] 10% | Training loss: 0.6984359333912532
Epoch: 17 | Iteration number: [70/565] 12% | Training loss: 0.6968334700380053
Epoch: 17 | Iteration number: [80/565] 14% | Training loss: 0.6955962635576725
Epoch: 17 | Iteration number: [90/565] 15% | Training loss: 0.6946469300323063
Epoch: 17 | Iteration number: [100/565] 17% | Training loss: 0.6938402259349823
Epoch: 17 | Iteration number: [110/565] 19% | Training loss: 0.6932533231648532
Epoch: 17 | Iteration number: [120/565] 21% | Training loss: 0.6927380884687105
Epoch: 17 | Iteration number: [130/565] 23% | Training loss: 0.6923176412398998
Epoch: 17 | Iteration number: [140/565] 24% | Training loss: 0.6919316296066557
Epoch: 17 | Iteration number: [150/565] 26% | Training loss: 0.6915756197770436
Epoch: 17 | Iteration number: [160/565] 28% | Training loss: 0.6912882409989833
Epoch: 17 | Iteration number: [170/565] 30% | Training loss: 0.6910483858164619
Epoch: 17 | Iteration number: [180/565] 31% | Training loss: 0.6908163411749734
Epoch: 17 | Iteration number: [190/565] 33% | Training loss: 0.6906158974296168
Epoch: 17 | Iteration number: [200/565] 35% | Training loss: 0.6904325839877129
Epoch: 17 | Iteration number: [210/565] 37% | Training loss: 0.6902964631716411
Epoch: 17 | Iteration number: [220/565] 38% | Training loss: 0.6901607421311465
Epoch: 17 | Iteration number: [230/565] 40% | Training loss: 0.6900333733662315
Epoch: 17 | Iteration number: [240/565] 42% | Training loss: 0.6899143263697625
Epoch: 17 | Iteration number: [250/565] 44% | Training loss: 0.6897678425312043
Epoch: 17 | Iteration number: [260/565] 46% | Training loss: 0.6896647042953051
Epoch: 17 | Iteration number: [270/565] 47% | Training loss: 0.6895809880009404
Epoch: 17 | Iteration number: [280/565] 49% | Training loss: 0.689495025575161
Epoch: 17 | Iteration number: [290/565] 51% | Training loss: 0.6894078086162435
Epoch: 17 | Iteration number: [300/565] 53% | Training loss: 0.6893077520529429
Epoch: 17 | Iteration number: [310/565] 54% | Training loss: 0.6892225130911797
Epoch: 17 | Iteration number: [320/565] 56% | Training loss: 0.6891538066789508
Epoch: 17 | Iteration number: [330/565] 58% | Training loss: 0.6890694063721281
Epoch: 17 | Iteration number: [340/565] 60% | Training loss: 0.6890201931490617
Epoch: 17 | Iteration number: [350/565] 61% | Training loss: 0.688966988665717
Epoch: 17 | Iteration number: [360/565] 63% | Training loss: 0.6889119702908728
Epoch: 17 | Iteration number: [370/565] 65% | Training loss: 0.6888486496500067
Epoch: 17 | Iteration number: [380/565] 67% | Training loss: 0.6888014529880725
Epoch: 17 | Iteration number: [390/565] 69% | Training loss: 0.6887577871481577
Epoch: 17 | Iteration number: [400/565] 70% | Training loss: 0.6887268607318401
Epoch: 17 | Iteration number: [410/565] 72% | Training loss: 0.6886790198523823
Epoch: 17 | Iteration number: [420/565] 74% | Training loss: 0.6886373140982219
Epoch: 17 | Iteration number: [430/565] 76% | Training loss: 0.6885945810828098
Epoch: 17 | Iteration number: [440/565] 77% | Training loss: 0.6885557846589522
Epoch: 17 | Iteration number: [450/565] 79% | Training loss: 0.6885313230090672
Epoch: 17 | Iteration number: [460/565] 81% | Training loss: 0.688487339667652
Epoch: 17 | Iteration number: [470/565] 83% | Training loss: 0.6884515828274665
Epoch: 17 | Iteration number: [480/565] 84% | Training loss: 0.6884182658046484
Epoch: 17 | Iteration number: [490/565] 86% | Training loss: 0.6883937581461304
Epoch: 17 | Iteration number: [500/565] 88% | Training loss: 0.6883705747127533
Epoch: 17 | Iteration number: [510/565] 90% | Training loss: 0.6883420099230374
Epoch: 17 | Iteration number: [520/565] 92% | Training loss: 0.6883141871828299
Epoch: 17 | Iteration number: [530/565] 93% | Training loss: 0.6883073458131754
Epoch: 17 | Iteration number: [540/565] 95% | Training loss: 0.6882807681957881
Epoch: 17 | Iteration number: [550/565] 97% | Training loss: 0.688258768861944
Epoch: 17 | Iteration number: [560/565] 99% | Training loss: 0.6882365079862731

 End of epoch: 17 | Train Loss: 0.6870142453539688 | Training Time: 89 

 End of epoch: 17 | Eval Loss: 0.6899446163858686 | Evaluating Time: 6 
Epoch: 18 | Iteration number: [10/565] 1% | Training loss: 0.755564147233963
Epoch: 18 | Iteration number: [20/565] 3% | Training loss: 0.7212977886199952
Epoch: 18 | Iteration number: [30/565] 5% | Training loss: 0.7098972638448079
Epoch: 18 | Iteration number: [40/565] 7% | Training loss: 0.7041438043117523
Epoch: 18 | Iteration number: [50/565] 8% | Training loss: 0.7006756424903869
Epoch: 18 | Iteration number: [60/565] 10% | Training loss: 0.6984422077735265
Epoch: 18 | Iteration number: [70/565] 12% | Training loss: 0.6967648778642926
Epoch: 18 | Iteration number: [80/565] 14% | Training loss: 0.6955638468265534
Epoch: 18 | Iteration number: [90/565] 15% | Training loss: 0.6945944090684255
Epoch: 18 | Iteration number: [100/565] 17% | Training loss: 0.6937805032730102
Epoch: 18 | Iteration number: [110/565] 19% | Training loss: 0.6931818084283309
Epoch: 18 | Iteration number: [120/565] 21% | Training loss: 0.6926940754055977
Epoch: 18 | Iteration number: [130/565] 23% | Training loss: 0.6922568843914912
Epoch: 18 | Iteration number: [140/565] 24% | Training loss: 0.6918726554938726
Epoch: 18 | Iteration number: [150/565] 26% | Training loss: 0.6915252582232158
Epoch: 18 | Iteration number: [160/565] 28% | Training loss: 0.6912943568080664
Epoch: 18 | Iteration number: [170/565] 30% | Training loss: 0.6910516493460711
Epoch: 18 | Iteration number: [180/565] 31% | Training loss: 0.6908239401049084
Epoch: 18 | Iteration number: [190/565] 33% | Training loss: 0.6906177517614867
Epoch: 18 | Iteration number: [200/565] 35% | Training loss: 0.6904458752274514
Epoch: 18 | Iteration number: [210/565] 37% | Training loss: 0.6902830087003253
Epoch: 18 | Iteration number: [220/565] 38% | Training loss: 0.6901483172720129
Epoch: 18 | Iteration number: [230/565] 40% | Training loss: 0.690019607025644
Epoch: 18 | Iteration number: [240/565] 42% | Training loss: 0.6898998496433099
Epoch: 18 | Iteration number: [250/565] 44% | Training loss: 0.6897808330059052
Epoch: 18 | Iteration number: [260/565] 46% | Training loss: 0.6896789440741906
Epoch: 18 | Iteration number: [270/565] 47% | Training loss: 0.6895862502080423
Epoch: 18 | Iteration number: [280/565] 49% | Training loss: 0.6895083791443279
Epoch: 18 | Iteration number: [290/565] 51% | Training loss: 0.689438788849732
Epoch: 18 | Iteration number: [300/565] 53% | Training loss: 0.6893662013610204
Epoch: 18 | Iteration number: [310/565] 54% | Training loss: 0.6892925370124079
Epoch: 18 | Iteration number: [320/565] 56% | Training loss: 0.6892189409583807
Epoch: 18 | Iteration number: [330/565] 58% | Training loss: 0.6891351022503592
Epoch: 18 | Iteration number: [340/565] 60% | Training loss: 0.6890755627085181
Epoch: 18 | Iteration number: [350/565] 61% | Training loss: 0.6889927572863442
Epoch: 18 | Iteration number: [360/565] 63% | Training loss: 0.6889409252338939
Epoch: 18 | Iteration number: [370/565] 65% | Training loss: 0.688872938381659
Epoch: 18 | Iteration number: [380/565] 67% | Training loss: 0.6888259644571103
Epoch: 18 | Iteration number: [390/565] 69% | Training loss: 0.6887824316819509
Epoch: 18 | Iteration number: [400/565] 70% | Training loss: 0.6887371124327183
Epoch: 18 | Iteration number: [410/565] 72% | Training loss: 0.6886972281990982
Epoch: 18 | Iteration number: [420/565] 74% | Training loss: 0.6886526404392151
Epoch: 18 | Iteration number: [430/565] 76% | Training loss: 0.6886213620041692
Epoch: 18 | Iteration number: [440/565] 77% | Training loss: 0.6885780165141279
Epoch: 18 | Iteration number: [450/565] 79% | Training loss: 0.6885469886991713
Epoch: 18 | Iteration number: [460/565] 81% | Training loss: 0.6885183533896571
Epoch: 18 | Iteration number: [470/565] 83% | Training loss: 0.6884887376998333
Epoch: 18 | Iteration number: [480/565] 84% | Training loss: 0.6884546052664519
Epoch: 18 | Iteration number: [490/565] 86% | Training loss: 0.6884222435707948
Epoch: 18 | Iteration number: [500/565] 88% | Training loss: 0.6883907494544983
Epoch: 18 | Iteration number: [510/565] 90% | Training loss: 0.6883658702467003
Epoch: 18 | Iteration number: [520/565] 92% | Training loss: 0.6883445356900876
Epoch: 18 | Iteration number: [530/565] 93% | Training loss: 0.6883158420616726
Epoch: 18 | Iteration number: [540/565] 95% | Training loss: 0.688286206126213
Epoch: 18 | Iteration number: [550/565] 97% | Training loss: 0.6882749838178808
Epoch: 18 | Iteration number: [560/565] 99% | Training loss: 0.6882461508469923

 End of epoch: 18 | Train Loss: 0.6870166218386288 | Training Time: 90 

 End of epoch: 18 | Eval Loss: 0.6903726032802037 | Evaluating Time: 6 
Epoch: 19 | Iteration number: [10/565] 1% | Training loss: 0.7555587768554688
Epoch: 19 | Iteration number: [20/565] 3% | Training loss: 0.7214348912239075
Epoch: 19 | Iteration number: [30/565] 5% | Training loss: 0.7099668125311533
Epoch: 19 | Iteration number: [40/565] 7% | Training loss: 0.7042235866189003
Epoch: 19 | Iteration number: [50/565] 8% | Training loss: 0.7006930410861969
Epoch: 19 | Iteration number: [60/565] 10% | Training loss: 0.6984272013107936
Epoch: 19 | Iteration number: [70/565] 12% | Training loss: 0.6968051280294146
Epoch: 19 | Iteration number: [80/565] 14% | Training loss: 0.6956193640828132
Epoch: 19 | Iteration number: [90/565] 15% | Training loss: 0.6946118652820588
Epoch: 19 | Iteration number: [100/565] 17% | Training loss: 0.6938282996416092
Epoch: 19 | Iteration number: [110/565] 19% | Training loss: 0.693225724588741
Epoch: 19 | Iteration number: [120/565] 21% | Training loss: 0.692757581671079
Epoch: 19 | Iteration number: [130/565] 23% | Training loss: 0.6923034443305089
Epoch: 19 | Iteration number: [140/565] 24% | Training loss: 0.6919242169175829
Epoch: 19 | Iteration number: [150/565] 26% | Training loss: 0.6916155576705932
Epoch: 19 | Iteration number: [160/565] 28% | Training loss: 0.6913588661700487
Epoch: 19 | Iteration number: [170/565] 30% | Training loss: 0.6910824347944821
Epoch: 19 | Iteration number: [180/565] 31% | Training loss: 0.6908469392193688
Epoch: 19 | Iteration number: [190/565] 33% | Training loss: 0.6906279535670029
Epoch: 19 | Iteration number: [200/565] 35% | Training loss: 0.6904575270414353
Epoch: 19 | Iteration number: [210/565] 37% | Training loss: 0.6903112896851131
Epoch: 19 | Iteration number: [220/565] 38% | Training loss: 0.6901618781414899
Epoch: 19 | Iteration number: [230/565] 40% | Training loss: 0.6900184703909833
Epoch: 19 | Iteration number: [240/565] 42% | Training loss: 0.6899039236207803
Epoch: 19 | Iteration number: [250/565] 44% | Training loss: 0.6898008966445923
Epoch: 19 | Iteration number: [260/565] 46% | Training loss: 0.6896976104149452
Epoch: 19 | Iteration number: [270/565] 47% | Training loss: 0.6895927614635892
Epoch: 19 | Iteration number: [280/565] 49% | Training loss: 0.6894973256758281
Epoch: 19 | Iteration number: [290/565] 51% | Training loss: 0.6894063513854455
Epoch: 19 | Iteration number: [300/565] 53% | Training loss: 0.6893044022719065
Epoch: 19 | Iteration number: [310/565] 54% | Training loss: 0.6892161153977917
Epoch: 19 | Iteration number: [320/565] 56% | Training loss: 0.6891418093815446
Epoch: 19 | Iteration number: [330/565] 58% | Training loss: 0.6890662621368061
Epoch: 19 | Iteration number: [340/565] 60% | Training loss: 0.6889981539810405
Epoch: 19 | Iteration number: [350/565] 61% | Training loss: 0.6889321179049356
Epoch: 19 | Iteration number: [360/565] 63% | Training loss: 0.6888702442248662
Epoch: 19 | Iteration number: [370/565] 65% | Training loss: 0.6888229689082583
Epoch: 19 | Iteration number: [380/565] 67% | Training loss: 0.6887798875570297
Epoch: 19 | Iteration number: [390/565] 69% | Training loss: 0.6887253260001158
Epoch: 19 | Iteration number: [400/565] 70% | Training loss: 0.6886822520196438
Epoch: 19 | Iteration number: [410/565] 72% | Training loss: 0.6886411099899106
Epoch: 19 | Iteration number: [420/565] 74% | Training loss: 0.6886074985776629
Epoch: 19 | Iteration number: [430/565] 76% | Training loss: 0.6885673151459805
Epoch: 19 | Iteration number: [440/565] 77% | Training loss: 0.6885311313650825
Epoch: 19 | Iteration number: [450/565] 79% | Training loss: 0.6884875814119975
Epoch: 19 | Iteration number: [460/565] 81% | Training loss: 0.6884484129107517
Epoch: 19 | Iteration number: [470/565] 83% | Training loss: 0.6884240723670797
Epoch: 19 | Iteration number: [480/565] 84% | Training loss: 0.6883911574880283
Epoch: 19 | Iteration number: [490/565] 86% | Training loss: 0.688359089408602
Epoch: 19 | Iteration number: [500/565] 88% | Training loss: 0.6883369343280792
Epoch: 19 | Iteration number: [510/565] 90% | Training loss: 0.6883165451825833
Epoch: 19 | Iteration number: [520/565] 92% | Training loss: 0.6882950802262012
Epoch: 19 | Iteration number: [530/565] 93% | Training loss: 0.6882735295115777
Epoch: 19 | Iteration number: [540/565] 95% | Training loss: 0.6882465422153473
Epoch: 19 | Iteration number: [550/565] 97% | Training loss: 0.6882297483357516
Epoch: 19 | Iteration number: [560/565] 99% | Training loss: 0.6882129793720586

 End of epoch: 19 | Train Loss: 0.6869885349695661 | Training Time: 87 

 End of epoch: 19 | Eval Loss: 0.6896881205695016 | Evaluating Time: 5 
Epoch: 20 | Iteration number: [10/565] 1% | Training loss: 0.7558703780174255
Epoch: 20 | Iteration number: [20/565] 3% | Training loss: 0.7214833527803421
Epoch: 20 | Iteration number: [30/565] 5% | Training loss: 0.7099722464879353
Epoch: 20 | Iteration number: [40/565] 7% | Training loss: 0.7040995314717293
Epoch: 20 | Iteration number: [50/565] 8% | Training loss: 0.7006404280662537
Epoch: 20 | Iteration number: [60/565] 10% | Training loss: 0.6983813931544621
Epoch: 20 | Iteration number: [70/565] 12% | Training loss: 0.6967232039996556
Epoch: 20 | Iteration number: [80/565] 14% | Training loss: 0.6954554617404938
Epoch: 20 | Iteration number: [90/565] 15% | Training loss: 0.6945544792546167
Epoch: 20 | Iteration number: [100/565] 17% | Training loss: 0.6938106322288513
Epoch: 20 | Iteration number: [110/565] 19% | Training loss: 0.6932235501029275
Epoch: 20 | Iteration number: [120/565] 21% | Training loss: 0.6927226354678472
Epoch: 20 | Iteration number: [130/565] 23% | Training loss: 0.6922894537448883
Epoch: 20 | Iteration number: [140/565] 24% | Training loss: 0.6919240495988301
Epoch: 20 | Iteration number: [150/565] 26% | Training loss: 0.691597089767456
Epoch: 20 | Iteration number: [160/565] 28% | Training loss: 0.6913034982979298
Epoch: 20 | Iteration number: [170/565] 30% | Training loss: 0.6910340431858512
Epoch: 20 | Iteration number: [180/565] 31% | Training loss: 0.6908367388778263
Epoch: 20 | Iteration number: [190/565] 33% | Training loss: 0.690631408754148
Epoch: 20 | Iteration number: [200/565] 35% | Training loss: 0.6904575628042221
Epoch: 20 | Iteration number: [210/565] 37% | Training loss: 0.6903057526974451
Epoch: 20 | Iteration number: [220/565] 38% | Training loss: 0.6901455042037097
Epoch: 20 | Iteration number: [230/565] 40% | Training loss: 0.6900015841359678
Epoch: 20 | Iteration number: [240/565] 42% | Training loss: 0.6898800996442636
Epoch: 20 | Iteration number: [250/565] 44% | Training loss: 0.6897750542163849
Epoch: 20 | Iteration number: [260/565] 46% | Training loss: 0.6896706812656843
Epoch: 20 | Iteration number: [270/565] 47% | Training loss: 0.6895518898963928
Epoch: 20 | Iteration number: [280/565] 49% | Training loss: 0.6894518745797021
Epoch: 20 | Iteration number: [290/565] 51% | Training loss: 0.6893649650031123
Epoch: 20 | Iteration number: [300/565] 53% | Training loss: 0.6892992140849431
Epoch: 20 | Iteration number: [310/565] 54% | Training loss: 0.6892262085791557
Epoch: 20 | Iteration number: [320/565] 56% | Training loss: 0.6891527203842998
Epoch: 20 | Iteration number: [330/565] 58% | Training loss: 0.6890925985394102
Epoch: 20 | Iteration number: [340/565] 60% | Training loss: 0.6890444550444098
Epoch: 20 | Iteration number: [350/565] 61% | Training loss: 0.6889670816489628
Epoch: 20 | Iteration number: [360/565] 63% | Training loss: 0.6889064772261514
Epoch: 20 | Iteration number: [370/565] 65% | Training loss: 0.6888557446969522
Epoch: 20 | Iteration number: [380/565] 67% | Training loss: 0.688799416862036
Epoch: 20 | Iteration number: [390/565] 69% | Training loss: 0.6887512668585166
Epoch: 20 | Iteration number: [400/565] 70% | Training loss: 0.6887100350856781
Epoch: 20 | Iteration number: [410/565] 72% | Training loss: 0.6886758067258975
Epoch: 20 | Iteration number: [420/565] 74% | Training loss: 0.6886261470261075
Epoch: 20 | Iteration number: [430/565] 76% | Training loss: 0.688584726771643
Epoch: 20 | Iteration number: [440/565] 77% | Training loss: 0.6885419989174063
Epoch: 20 | Iteration number: [450/565] 79% | Training loss: 0.688513038555781
Epoch: 20 | Iteration number: [460/565] 81% | Training loss: 0.6884727409352427
Epoch: 20 | Iteration number: [470/565] 83% | Training loss: 0.6884417226974
Epoch: 20 | Iteration number: [480/565] 84% | Training loss: 0.6884071533878644
Epoch: 20 | Iteration number: [490/565] 86% | Training loss: 0.6883789523523681
Epoch: 20 | Iteration number: [500/565] 88% | Training loss: 0.6883558099269866
Epoch: 20 | Iteration number: [510/565] 90% | Training loss: 0.6883260915092394
Epoch: 20 | Iteration number: [520/565] 92% | Training loss: 0.6882932630869059
Epoch: 20 | Iteration number: [530/565] 93% | Training loss: 0.6882649796189002
Epoch: 20 | Iteration number: [540/565] 95% | Training loss: 0.6882369853832103
Epoch: 20 | Iteration number: [550/565] 97% | Training loss: 0.6882174364003268
Epoch: 20 | Iteration number: [560/565] 99% | Training loss: 0.6882018031818526

 End of epoch: 20 | Train Loss: 0.6869699476039515 | Training Time: 89 

 End of epoch: 20 | Eval Loss: 0.6901345763887677 | Evaluating Time: 6 
Epoch: 21 | Iteration number: [10/565] 1% | Training loss: 0.7555976629257202
Epoch: 21 | Iteration number: [20/565] 3% | Training loss: 0.7212430864572525
Epoch: 21 | Iteration number: [30/565] 5% | Training loss: 0.7098911523818969
Epoch: 21 | Iteration number: [40/565] 7% | Training loss: 0.7041916668415069
Epoch: 21 | Iteration number: [50/565] 8% | Training loss: 0.7007250845432281
Epoch: 21 | Iteration number: [60/565] 10% | Training loss: 0.6984040846427282
Epoch: 21 | Iteration number: [70/565] 12% | Training loss: 0.6967503121920995
Epoch: 21 | Iteration number: [80/565] 14% | Training loss: 0.6955386266112328
Epoch: 21 | Iteration number: [90/565] 15% | Training loss: 0.6946109837955898
Epoch: 21 | Iteration number: [100/565] 17% | Training loss: 0.6938219583034515
Epoch: 21 | Iteration number: [110/565] 19% | Training loss: 0.6932100014253096
Epoch: 21 | Iteration number: [120/565] 21% | Training loss: 0.6927068049709002
Epoch: 21 | Iteration number: [130/565] 23% | Training loss: 0.6922688296208015
Epoch: 21 | Iteration number: [140/565] 24% | Training loss: 0.6918736704758235
Epoch: 21 | Iteration number: [150/565] 26% | Training loss: 0.6915474088986715
Epoch: 21 | Iteration number: [160/565] 28% | Training loss: 0.6912773117423058
Epoch: 21 | Iteration number: [170/565] 30% | Training loss: 0.6910331031855415
Epoch: 21 | Iteration number: [180/565] 31% | Training loss: 0.6907871017853419
Epoch: 21 | Iteration number: [190/565] 33% | Training loss: 0.6905684144873369
Epoch: 21 | Iteration number: [200/565] 35% | Training loss: 0.6903906732797622
Epoch: 21 | Iteration number: [210/565] 37% | Training loss: 0.6902045701231275
Epoch: 21 | Iteration number: [220/565] 38% | Training loss: 0.6900550435889851
Epoch: 21 | Iteration number: [230/565] 40% | Training loss: 0.6899312319962875
Epoch: 21 | Iteration number: [240/565] 42% | Training loss: 0.68981148848931
Epoch: 21 | Iteration number: [250/565] 44% | Training loss: 0.6896963994503021
Epoch: 21 | Iteration number: [260/565] 46% | Training loss: 0.6895831963190666
Epoch: 21 | Iteration number: [270/565] 47% | Training loss: 0.6894801400325916
Epoch: 21 | Iteration number: [280/565] 49% | Training loss: 0.6893788946526391
Epoch: 21 | Iteration number: [290/565] 51% | Training loss: 0.6893012437327155
Epoch: 21 | Iteration number: [300/565] 53% | Training loss: 0.6892255083719889
Epoch: 21 | Iteration number: [310/565] 54% | Training loss: 0.6891523053569178
Epoch: 21 | Iteration number: [320/565] 56% | Training loss: 0.6890893327072263
Epoch: 21 | Iteration number: [330/565] 58% | Training loss: 0.6890369050430529
Epoch: 21 | Iteration number: [340/565] 60% | Training loss: 0.6889753993819742
Epoch: 21 | Iteration number: [350/565] 61% | Training loss: 0.6889259794780186
Epoch: 21 | Iteration number: [360/565] 63% | Training loss: 0.6888771482639843
Epoch: 21 | Iteration number: [370/565] 65% | Training loss: 0.688821198489215
Epoch: 21 | Iteration number: [380/565] 67% | Training loss: 0.6887752100041038
Epoch: 21 | Iteration number: [390/565] 69% | Training loss: 0.6887178847422967
Epoch: 21 | Iteration number: [400/565] 70% | Training loss: 0.6886730162799358
Epoch: 21 | Iteration number: [410/565] 72% | Training loss: 0.688629328913805
Epoch: 21 | Iteration number: [420/565] 74% | Training loss: 0.6885835912965593
Epoch: 21 | Iteration number: [430/565] 76% | Training loss: 0.6885432290476422
Epoch: 21 | Iteration number: [440/565] 77% | Training loss: 0.6885158771818335
Epoch: 21 | Iteration number: [450/565] 79% | Training loss: 0.6884756995571985
Epoch: 21 | Iteration number: [460/565] 81% | Training loss: 0.6884460686341576
Epoch: 21 | Iteration number: [470/565] 83% | Training loss: 0.688411428319647
Epoch: 21 | Iteration number: [480/565] 84% | Training loss: 0.688376505797108
Epoch: 21 | Iteration number: [490/565] 86% | Training loss: 0.6883587579337918
Epoch: 21 | Iteration number: [500/565] 88% | Training loss: 0.6883286862373352
Epoch: 21 | Iteration number: [510/565] 90% | Training loss: 0.6883017328439974
Epoch: 21 | Iteration number: [520/565] 92% | Training loss: 0.6882832211943773
Epoch: 21 | Iteration number: [530/565] 93% | Training loss: 0.6882597409329324
Epoch: 21 | Iteration number: [540/565] 95% | Training loss: 0.6882414983378516
Epoch: 21 | Iteration number: [550/565] 97% | Training loss: 0.6882131044431167
Epoch: 21 | Iteration number: [560/565] 99% | Training loss: 0.6881862993751253

 End of epoch: 21 | Train Loss: 0.6869645962672951 | Training Time: 89 

 End of epoch: 21 | Eval Loss: 0.6902593459401812 | Evaluating Time: 6 
Epoch: 22 | Iteration number: [10/565] 1% | Training loss: 0.7558784246444702
Epoch: 22 | Iteration number: [20/565] 3% | Training loss: 0.7215196043252945
Epoch: 22 | Iteration number: [30/565] 5% | Training loss: 0.7101210057735443
Epoch: 22 | Iteration number: [40/565] 7% | Training loss: 0.7043341800570488
Epoch: 22 | Iteration number: [50/565] 8% | Training loss: 0.7008694696426392
Epoch: 22 | Iteration number: [60/565] 10% | Training loss: 0.6984986652930577
Epoch: 22 | Iteration number: [70/565] 12% | Training loss: 0.6969165580613272
Epoch: 22 | Iteration number: [80/565] 14% | Training loss: 0.6956476405262947
Epoch: 22 | Iteration number: [90/565] 15% | Training loss: 0.6947278519471486
Epoch: 22 | Iteration number: [100/565] 17% | Training loss: 0.6939537888765335
Epoch: 22 | Iteration number: [110/565] 19% | Training loss: 0.6933251808990132
Epoch: 22 | Iteration number: [120/565] 21% | Training loss: 0.6927814513444901
Epoch: 22 | Iteration number: [130/565] 23% | Training loss: 0.6923192239724673
Epoch: 22 | Iteration number: [140/565] 24% | Training loss: 0.6919312766620092
Epoch: 22 | Iteration number: [150/565] 26% | Training loss: 0.6916264684995016
Epoch: 22 | Iteration number: [160/565] 28% | Training loss: 0.6913616053760052
Epoch: 22 | Iteration number: [170/565] 30% | Training loss: 0.6911015675348394
Epoch: 22 | Iteration number: [180/565] 31% | Training loss: 0.6908572471804089
Epoch: 22 | Iteration number: [190/565] 33% | Training loss: 0.690640580026727
Epoch: 22 | Iteration number: [200/565] 35% | Training loss: 0.6904349502921104
Epoch: 22 | Iteration number: [210/565] 37% | Training loss: 0.6902710043248677
Epoch: 22 | Iteration number: [220/565] 38% | Training loss: 0.690118364312432
Epoch: 22 | Iteration number: [230/565] 40% | Training loss: 0.689989479728367
Epoch: 22 | Iteration number: [240/565] 42% | Training loss: 0.6898706269760927
Epoch: 22 | Iteration number: [250/565] 44% | Training loss: 0.6897507779598236
Epoch: 22 | Iteration number: [260/565] 46% | Training loss: 0.6896488661949451
Epoch: 22 | Iteration number: [270/565] 47% | Training loss: 0.6895412661411144
Epoch: 22 | Iteration number: [280/565] 49% | Training loss: 0.6894451132842473
Epoch: 22 | Iteration number: [290/565] 51% | Training loss: 0.6893533283266527
Epoch: 22 | Iteration number: [300/565] 53% | Training loss: 0.6892642364899317
Epoch: 22 | Iteration number: [310/565] 54% | Training loss: 0.6891988888863594
Epoch: 22 | Iteration number: [320/565] 56% | Training loss: 0.6891266535967588
Epoch: 22 | Iteration number: [330/565] 58% | Training loss: 0.6890642429843093
Epoch: 22 | Iteration number: [340/565] 60% | Training loss: 0.689003200916683
Epoch: 22 | Iteration number: [350/565] 61% | Training loss: 0.6889311230182648
Epoch: 22 | Iteration number: [360/565] 63% | Training loss: 0.688873717851109
Epoch: 22 | Iteration number: [370/565] 65% | Training loss: 0.688812904261254
Epoch: 22 | Iteration number: [380/565] 67% | Training loss: 0.6887692898511887
Epoch: 22 | Iteration number: [390/565] 69% | Training loss: 0.688732796907425
Epoch: 22 | Iteration number: [400/565] 70% | Training loss: 0.6886815539002419
Epoch: 22 | Iteration number: [410/565] 72% | Training loss: 0.68864765545217
Epoch: 22 | Iteration number: [420/565] 74% | Training loss: 0.688600965482848
Epoch: 22 | Iteration number: [430/565] 76% | Training loss: 0.6885676815066226
Epoch: 22 | Iteration number: [440/565] 77% | Training loss: 0.6885342434048652
Epoch: 22 | Iteration number: [450/565] 79% | Training loss: 0.6884963332282172
Epoch: 22 | Iteration number: [460/565] 81% | Training loss: 0.6884608381468317
Epoch: 22 | Iteration number: [470/565] 83% | Training loss: 0.6884252390962966
Epoch: 22 | Iteration number: [480/565] 84% | Training loss: 0.6883955297370752
Epoch: 22 | Iteration number: [490/565] 86% | Training loss: 0.6883628039943929
Epoch: 22 | Iteration number: [500/565] 88% | Training loss: 0.6883338297605515
Epoch: 22 | Iteration number: [510/565] 90% | Training loss: 0.6883032249469383
Epoch: 22 | Iteration number: [520/565] 92% | Training loss: 0.6882720557542947
Epoch: 22 | Iteration number: [530/565] 93% | Training loss: 0.6882498574706744
Epoch: 22 | Iteration number: [540/565] 95% | Training loss: 0.6882189218644743
Epoch: 22 | Iteration number: [550/565] 97% | Training loss: 0.6881952671571211
Epoch: 22 | Iteration number: [560/565] 99% | Training loss: 0.6881786591240338

 End of epoch: 22 | Train Loss: 0.686956682458388 | Training Time: 89 

 End of epoch: 22 | Eval Loss: 0.6903000388826642 | Evaluating Time: 6 
Epoch: 23 | Iteration number: [10/565] 1% | Training loss: 0.7558930218219757
Epoch: 23 | Iteration number: [20/565] 3% | Training loss: 0.7213965028524398
Epoch: 23 | Iteration number: [30/565] 5% | Training loss: 0.7098500192165375
Epoch: 23 | Iteration number: [40/565] 7% | Training loss: 0.7041275963187218
Epoch: 23 | Iteration number: [50/565] 8% | Training loss: 0.700684357881546
Epoch: 23 | Iteration number: [60/565] 10% | Training loss: 0.6984251658121745
Epoch: 23 | Iteration number: [70/565] 12% | Training loss: 0.696806527035577
Epoch: 23 | Iteration number: [80/565] 14% | Training loss: 0.6955912820994854
Epoch: 23 | Iteration number: [90/565] 15% | Training loss: 0.694659478796853
Epoch: 23 | Iteration number: [100/565] 17% | Training loss: 0.6938693356513977
Epoch: 23 | Iteration number: [110/565] 19% | Training loss: 0.6932704172351144
Epoch: 23 | Iteration number: [120/565] 21% | Training loss: 0.6927325909336408
Epoch: 23 | Iteration number: [130/565] 23% | Training loss: 0.69230581338589
Epoch: 23 | Iteration number: [140/565] 24% | Training loss: 0.6919148032154355
Epoch: 23 | Iteration number: [150/565] 26% | Training loss: 0.6916088529427846
Epoch: 23 | Iteration number: [160/565] 28% | Training loss: 0.6912905655801296
Epoch: 23 | Iteration number: [170/565] 30% | Training loss: 0.6910488577450022
Epoch: 23 | Iteration number: [180/565] 31% | Training loss: 0.6908268610636393
Epoch: 23 | Iteration number: [190/565] 33% | Training loss: 0.6906037600416887
Epoch: 23 | Iteration number: [200/565] 35% | Training loss: 0.6904074776172638
Epoch: 23 | Iteration number: [210/565] 37% | Training loss: 0.6902447314489455
Epoch: 23 | Iteration number: [220/565] 38% | Training loss: 0.6900856792926788
Epoch: 23 | Iteration number: [230/565] 40% | Training loss: 0.6899326218211133
Epoch: 23 | Iteration number: [240/565] 42% | Training loss: 0.6898125012715658
Epoch: 23 | Iteration number: [250/565] 44% | Training loss: 0.6896991336345673
Epoch: 23 | Iteration number: [260/565] 46% | Training loss: 0.689590011880948
Epoch: 23 | Iteration number: [270/565] 47% | Training loss: 0.6894805815484789
Epoch: 23 | Iteration number: [280/565] 49% | Training loss: 0.6893892805491175
Epoch: 23 | Iteration number: [290/565] 51% | Training loss: 0.6892964568631402
Epoch: 23 | Iteration number: [300/565] 53% | Training loss: 0.6892221194505691
Epoch: 23 | Iteration number: [310/565] 54% | Training loss: 0.6891496444902112
Epoch: 23 | Iteration number: [320/565] 56% | Training loss: 0.6890853855758905
Epoch: 23 | Iteration number: [330/565] 58% | Training loss: 0.68902429486766
Epoch: 23 | Iteration number: [340/565] 60% | Training loss: 0.6889647974687464
Epoch: 23 | Iteration number: [350/565] 61% | Training loss: 0.6888993334770203
Epoch: 23 | Iteration number: [360/565] 63% | Training loss: 0.6888453569677141
Epoch: 23 | Iteration number: [370/565] 65% | Training loss: 0.6887947111516386
Epoch: 23 | Iteration number: [380/565] 67% | Training loss: 0.6887452247895692
Epoch: 23 | Iteration number: [390/565] 69% | Training loss: 0.6886991753027989
Epoch: 23 | Iteration number: [400/565] 70% | Training loss: 0.688667941391468
Epoch: 23 | Iteration number: [410/565] 72% | Training loss: 0.6886311945391864
Epoch: 23 | Iteration number: [420/565] 74% | Training loss: 0.6885888677267801
Epoch: 23 | Iteration number: [430/565] 76% | Training loss: 0.6885432950285978
Epoch: 23 | Iteration number: [440/565] 77% | Training loss: 0.6885069053281437
Epoch: 23 | Iteration number: [450/565] 79% | Training loss: 0.6884712235132853
Epoch: 23 | Iteration number: [460/565] 81% | Training loss: 0.6884389914896177
Epoch: 23 | Iteration number: [470/565] 83% | Training loss: 0.6884014512630219
Epoch: 23 | Iteration number: [480/565] 84% | Training loss: 0.6883646813531716
Epoch: 23 | Iteration number: [490/565] 86% | Training loss: 0.6883315296805634
Epoch: 23 | Iteration number: [500/565] 88% | Training loss: 0.6883106346130371
Epoch: 23 | Iteration number: [510/565] 90% | Training loss: 0.6882843340144438
Epoch: 23 | Iteration number: [520/565] 92% | Training loss: 0.6882474811031268
Epoch: 23 | Iteration number: [530/565] 93% | Training loss: 0.6882297154867424
Epoch: 23 | Iteration number: [540/565] 95% | Training loss: 0.6881987849871317
Epoch: 23 | Iteration number: [550/565] 97% | Training loss: 0.6881804957173088
Epoch: 23 | Iteration number: [560/565] 99% | Training loss: 0.6881556718477181

 End of epoch: 23 | Train Loss: 0.6869285473781349 | Training Time: 88 

 End of epoch: 23 | Eval Loss: 0.6904676897185189 | Evaluating Time: 6 
Epoch: 24 | Iteration number: [10/565] 1% | Training loss: 0.7556706964969635
Epoch: 24 | Iteration number: [20/565] 3% | Training loss: 0.7213392615318298
Epoch: 24 | Iteration number: [30/565] 5% | Training loss: 0.7097790141900381
Epoch: 24 | Iteration number: [40/565] 7% | Training loss: 0.70404122620821
Epoch: 24 | Iteration number: [50/565] 8% | Training loss: 0.7005437612533569
Epoch: 24 | Iteration number: [60/565] 10% | Training loss: 0.6983076790968578
Epoch: 24 | Iteration number: [70/565] 12% | Training loss: 0.6966987780162266
Epoch: 24 | Iteration number: [80/565] 14% | Training loss: 0.6954901956021786
Epoch: 24 | Iteration number: [90/565] 15% | Training loss: 0.6945125096374087
Epoch: 24 | Iteration number: [100/565] 17% | Training loss: 0.6937709701061249
Epoch: 24 | Iteration number: [110/565] 19% | Training loss: 0.69316434209997
Epoch: 24 | Iteration number: [120/565] 21% | Training loss: 0.69262725263834
Epoch: 24 | Iteration number: [130/565] 23% | Training loss: 0.6921674045232626
Epoch: 24 | Iteration number: [140/565] 24% | Training loss: 0.6917807851518903
Epoch: 24 | Iteration number: [150/565] 26% | Training loss: 0.691434368689855
Epoch: 24 | Iteration number: [160/565] 28% | Training loss: 0.6911574728786946
Epoch: 24 | Iteration number: [170/565] 30% | Training loss: 0.6909139054663042
Epoch: 24 | Iteration number: [180/565] 31% | Training loss: 0.6906607677539189
Epoch: 24 | Iteration number: [190/565] 33% | Training loss: 0.6904919969408135
Epoch: 24 | Iteration number: [200/565] 35% | Training loss: 0.6903262552618981
Epoch: 24 | Iteration number: [210/565] 37% | Training loss: 0.6901721656322479
Epoch: 24 | Iteration number: [220/565] 38% | Training loss: 0.6899944297292016
Epoch: 24 | Iteration number: [230/565] 40% | Training loss: 0.6898550202017245
Epoch: 24 | Iteration number: [240/565] 42% | Training loss: 0.6897294153769811
Epoch: 24 | Iteration number: [250/565] 44% | Training loss: 0.6896315588951111
Epoch: 24 | Iteration number: [260/565] 46% | Training loss: 0.6895290803450804
Epoch: 24 | Iteration number: [270/565] 47% | Training loss: 0.6894327384454233
Epoch: 24 | Iteration number: [280/565] 49% | Training loss: 0.6893459637250219
Epoch: 24 | Iteration number: [290/565] 51% | Training loss: 0.6892512549614084
Epoch: 24 | Iteration number: [300/565] 53% | Training loss: 0.6891973199446996
Epoch: 24 | Iteration number: [310/565] 54% | Training loss: 0.6891178413744896
Epoch: 24 | Iteration number: [320/565] 56% | Training loss: 0.6890376828610897
Epoch: 24 | Iteration number: [330/565] 58% | Training loss: 0.6889790525942138
Epoch: 24 | Iteration number: [340/565] 60% | Training loss: 0.6889157824656542
Epoch: 24 | Iteration number: [350/565] 61% | Training loss: 0.6888526039464133
Epoch: 24 | Iteration number: [360/565] 63% | Training loss: 0.6887961433993446
Epoch: 24 | Iteration number: [370/565] 65% | Training loss: 0.6887435387920688
Epoch: 24 | Iteration number: [380/565] 67% | Training loss: 0.6886857120614303
Epoch: 24 | Iteration number: [390/565] 69% | Training loss: 0.688641672103833
Epoch: 24 | Iteration number: [400/565] 70% | Training loss: 0.688587492108345
Epoch: 24 | Iteration number: [410/565] 72% | Training loss: 0.6885539783210289
Epoch: 24 | Iteration number: [420/565] 74% | Training loss: 0.6885075447105226
Epoch: 24 | Iteration number: [430/565] 76% | Training loss: 0.6884669213793998
Epoch: 24 | Iteration number: [440/565] 77% | Training loss: 0.6884360058741136
Epoch: 24 | Iteration number: [450/565] 79% | Training loss: 0.688408930434121
Epoch: 24 | Iteration number: [460/565] 81% | Training loss: 0.6883794315483259
Epoch: 24 | Iteration number: [470/565] 83% | Training loss: 0.6883564760076238
Epoch: 24 | Iteration number: [480/565] 84% | Training loss: 0.6883247651159763
Epoch: 24 | Iteration number: [490/565] 86% | Training loss: 0.6882995112818114
Epoch: 24 | Iteration number: [500/565] 88% | Training loss: 0.6882724992036819
Epoch: 24 | Iteration number: [510/565] 90% | Training loss: 0.6882489643844903
Epoch: 24 | Iteration number: [520/565] 92% | Training loss: 0.6882279576017306
Epoch: 24 | Iteration number: [530/565] 93% | Training loss: 0.6881973876143401
Epoch: 24 | Iteration number: [540/565] 95% | Training loss: 0.6881869131768191
Epoch: 24 | Iteration number: [550/565] 97% | Training loss: 0.688165737065402
Epoch: 24 | Iteration number: [560/565] 99% | Training loss: 0.6881458676287107

 End of epoch: 24 | Train Loss: 0.6869249262640962 | Training Time: 90 

 End of epoch: 24 | Eval Loss: 0.689940163067409 | Evaluating Time: 5 
Epoch: 25 | Iteration number: [10/565] 1% | Training loss: 0.755679726600647
Epoch: 25 | Iteration number: [20/565] 3% | Training loss: 0.7216028809547425
Epoch: 25 | Iteration number: [30/565] 5% | Training loss: 0.7101133485635122
Epoch: 25 | Iteration number: [40/565] 7% | Training loss: 0.70424824655056
Epoch: 25 | Iteration number: [50/565] 8% | Training loss: 0.7008154952526092
Epoch: 25 | Iteration number: [60/565] 10% | Training loss: 0.6984599103530248
Epoch: 25 | Iteration number: [70/565] 12% | Training loss: 0.6968282188688005
Epoch: 25 | Iteration number: [80/565] 14% | Training loss: 0.6955742366611958
Epoch: 25 | Iteration number: [90/565] 15% | Training loss: 0.6945743752850426
Epoch: 25 | Iteration number: [100/565] 17% | Training loss: 0.69386012673378
Epoch: 25 | Iteration number: [110/565] 19% | Training loss: 0.6932792035016146
Epoch: 25 | Iteration number: [120/565] 21% | Training loss: 0.6927488575379054
Epoch: 25 | Iteration number: [130/565] 23% | Training loss: 0.6923412671455971
Epoch: 25 | Iteration number: [140/565] 24% | Training loss: 0.6919517351048333
Epoch: 25 | Iteration number: [150/565] 26% | Training loss: 0.6916544310251872
Epoch: 25 | Iteration number: [160/565] 28% | Training loss: 0.6913748681545258
Epoch: 25 | Iteration number: [170/565] 30% | Training loss: 0.6910988937405979
Epoch: 25 | Iteration number: [180/565] 31% | Training loss: 0.6908864200115203
Epoch: 25 | Iteration number: [190/565] 33% | Training loss: 0.6906683840249714
Epoch: 25 | Iteration number: [200/565] 35% | Training loss: 0.6905054980516434
Epoch: 25 | Iteration number: [210/565] 37% | Training loss: 0.6903160344986689
Epoch: 25 | Iteration number: [220/565] 38% | Training loss: 0.6901623663577167
Epoch: 25 | Iteration number: [230/565] 40% | Training loss: 0.6900146471417469
Epoch: 25 | Iteration number: [240/565] 42% | Training loss: 0.6898895464837551
Epoch: 25 | Iteration number: [250/565] 44% | Training loss: 0.6897659108638764
Epoch: 25 | Iteration number: [260/565] 46% | Training loss: 0.6896648555994034
Epoch: 25 | Iteration number: [270/565] 47% | Training loss: 0.6895722470901631
Epoch: 25 | Iteration number: [280/565] 49% | Training loss: 0.689471586900098
Epoch: 25 | Iteration number: [290/565] 51% | Training loss: 0.6893909069998511
Epoch: 25 | Iteration number: [300/565] 53% | Training loss: 0.6893260353803634
Epoch: 25 | Iteration number: [310/565] 54% | Training loss: 0.6892578021172554
Epoch: 25 | Iteration number: [320/565] 56% | Training loss: 0.6891845328733325
Epoch: 25 | Iteration number: [330/565] 58% | Training loss: 0.6891161206996802
Epoch: 25 | Iteration number: [340/565] 60% | Training loss: 0.6890397880007239
Epoch: 25 | Iteration number: [350/565] 61% | Training loss: 0.6889779829978943
Epoch: 25 | Iteration number: [360/565] 63% | Training loss: 0.6889210965898301
Epoch: 25 | Iteration number: [370/565] 65% | Training loss: 0.688873742399989
Epoch: 25 | Iteration number: [380/565] 67% | Training loss: 0.6888213948199623
Epoch: 25 | Iteration number: [390/565] 69% | Training loss: 0.6887755183073191
Epoch: 25 | Iteration number: [400/565] 70% | Training loss: 0.6887261301279068
Epoch: 25 | Iteration number: [410/565] 72% | Training loss: 0.6886762792017401
Epoch: 25 | Iteration number: [420/565] 74% | Training loss: 0.6886257817347844
Epoch: 25 | Iteration number: [430/565] 76% | Training loss: 0.688586838300838
Epoch: 25 | Iteration number: [440/565] 77% | Training loss: 0.6885431202975186
Epoch: 25 | Iteration number: [450/565] 79% | Training loss: 0.6885038652684954
Epoch: 25 | Iteration number: [460/565] 81% | Training loss: 0.6884702927392462
Epoch: 25 | Iteration number: [470/565] 83% | Training loss: 0.6884397190936068
Epoch: 25 | Iteration number: [480/565] 84% | Training loss: 0.6883970665434996
Epoch: 25 | Iteration number: [490/565] 86% | Training loss: 0.6883620669647139
Epoch: 25 | Iteration number: [500/565] 88% | Training loss: 0.6883296880722046
Epoch: 25 | Iteration number: [510/565] 90% | Training loss: 0.6883033658943924
Epoch: 25 | Iteration number: [520/565] 92% | Training loss: 0.6882769929674956
Epoch: 25 | Iteration number: [530/565] 93% | Training loss: 0.6882451219378777
Epoch: 25 | Iteration number: [540/565] 95% | Training loss: 0.6882190127063681
Epoch: 25 | Iteration number: [550/565] 97% | Training loss: 0.6881954743645408
Epoch: 25 | Iteration number: [560/565] 99% | Training loss: 0.6881729757147176

 End of epoch: 25 | Train Loss: 0.6869431702436599 | Training Time: 91 

 End of epoch: 25 | Eval Loss: 0.6903326341084072 | Evaluating Time: 5 
Epoch: 26 | Iteration number: [10/565] 1% | Training loss: 0.755651307106018
Epoch: 26 | Iteration number: [20/565] 3% | Training loss: 0.7209786593914032
Epoch: 26 | Iteration number: [30/565] 5% | Training loss: 0.7096628169218699
Epoch: 26 | Iteration number: [40/565] 7% | Training loss: 0.7039100453257561
Epoch: 26 | Iteration number: [50/565] 8% | Training loss: 0.7005033993721008
Epoch: 26 | Iteration number: [60/565] 10% | Training loss: 0.6982265849908192
Epoch: 26 | Iteration number: [70/565] 12% | Training loss: 0.6966290882655553
Epoch: 26 | Iteration number: [80/565] 14% | Training loss: 0.6954748123884201
Epoch: 26 | Iteration number: [90/565] 15% | Training loss: 0.6945442974567413
Epoch: 26 | Iteration number: [100/565] 17% | Training loss: 0.693823874592781
Epoch: 26 | Iteration number: [110/565] 19% | Training loss: 0.6932385704734109
Epoch: 26 | Iteration number: [120/565] 21% | Training loss: 0.6927374944090843
Epoch: 26 | Iteration number: [130/565] 23% | Training loss: 0.692305698303076
Epoch: 26 | Iteration number: [140/565] 24% | Training loss: 0.6919621808188302
Epoch: 26 | Iteration number: [150/565] 26% | Training loss: 0.6916335093975067
Epoch: 26 | Iteration number: [160/565] 28% | Training loss: 0.6913071691989898
Epoch: 26 | Iteration number: [170/565] 30% | Training loss: 0.6910377905649298
Epoch: 26 | Iteration number: [180/565] 31% | Training loss: 0.6907993975612853
Epoch: 26 | Iteration number: [190/565] 33% | Training loss: 0.6905863877974059
Epoch: 26 | Iteration number: [200/565] 35% | Training loss: 0.690409181714058
Epoch: 26 | Iteration number: [210/565] 37% | Training loss: 0.690227069457372
Epoch: 26 | Iteration number: [220/565] 38% | Training loss: 0.6900832802057266
Epoch: 26 | Iteration number: [230/565] 40% | Training loss: 0.689954997404762
Epoch: 26 | Iteration number: [240/565] 42% | Training loss: 0.6898211451868216
Epoch: 26 | Iteration number: [250/565] 44% | Training loss: 0.6897077348232269
Epoch: 26 | Iteration number: [260/565] 46% | Training loss: 0.6895909174130513
Epoch: 26 | Iteration number: [270/565] 47% | Training loss: 0.6894932934531459
Epoch: 26 | Iteration number: [280/565] 49% | Training loss: 0.6893861242703029
Epoch: 26 | Iteration number: [290/565] 51% | Training loss: 0.689323216676712
Epoch: 26 | Iteration number: [300/565] 53% | Training loss: 0.6892404178778331
Epoch: 26 | Iteration number: [310/565] 54% | Training loss: 0.6891579587613382
Epoch: 26 | Iteration number: [320/565] 56% | Training loss: 0.6890849361196161
Epoch: 26 | Iteration number: [330/565] 58% | Training loss: 0.6890375823685617
Epoch: 26 | Iteration number: [340/565] 60% | Training loss: 0.6889648293747621
Epoch: 26 | Iteration number: [350/565] 61% | Training loss: 0.6889006752627237
Epoch: 26 | Iteration number: [360/565] 63% | Training loss: 0.6888408064842224
Epoch: 26 | Iteration number: [370/565] 65% | Training loss: 0.6887895300581649
Epoch: 26 | Iteration number: [380/565] 67% | Training loss: 0.6887418575977025
Epoch: 26 | Iteration number: [390/565] 69% | Training loss: 0.6886719862620035
Epoch: 26 | Iteration number: [400/565] 70% | Training loss: 0.68863382011652
Epoch: 26 | Iteration number: [410/565] 72% | Training loss: 0.688593076932721
Epoch: 26 | Iteration number: [420/565] 74% | Training loss: 0.6885565573260898
Epoch: 26 | Iteration number: [430/565] 76% | Training loss: 0.6885253325451252
Epoch: 26 | Iteration number: [440/565] 77% | Training loss: 0.6884992813522165
Epoch: 26 | Iteration number: [450/565] 79% | Training loss: 0.6884728761514028
Epoch: 26 | Iteration number: [460/565] 81% | Training loss: 0.6884283188892447
Epoch: 26 | Iteration number: [470/565] 83% | Training loss: 0.6883956428537977
Epoch: 26 | Iteration number: [480/565] 84% | Training loss: 0.688362297291557
Epoch: 26 | Iteration number: [490/565] 86% | Training loss: 0.6883294281910877
Epoch: 26 | Iteration number: [500/565] 88% | Training loss: 0.6883105416297912
Epoch: 26 | Iteration number: [510/565] 90% | Training loss: 0.6882850193509868
Epoch: 26 | Iteration number: [520/565] 92% | Training loss: 0.6882626275603588
Epoch: 26 | Iteration number: [530/565] 93% | Training loss: 0.6882331310578113
Epoch: 26 | Iteration number: [540/565] 95% | Training loss: 0.688207592677187
Epoch: 26 | Iteration number: [550/565] 97% | Training loss: 0.688183282288638
Epoch: 26 | Iteration number: [560/565] 99% | Training loss: 0.6881530255079269

 End of epoch: 26 | Train Loss: 0.6869269495516752 | Training Time: 89 

 End of epoch: 26 | Eval Loss: 0.690255982535226 | Evaluating Time: 6 
Epoch: 27 | Iteration number: [10/565] 1% | Training loss: 0.7556706726551056
Epoch: 27 | Iteration number: [20/565] 3% | Training loss: 0.7212355136871338
Epoch: 27 | Iteration number: [30/565] 5% | Training loss: 0.7098425984382629
Epoch: 27 | Iteration number: [40/565] 7% | Training loss: 0.7041252195835114
Epoch: 27 | Iteration number: [50/565] 8% | Training loss: 0.7006672549247742
Epoch: 27 | Iteration number: [60/565] 10% | Training loss: 0.6983807931343714
Epoch: 27 | Iteration number: [70/565] 12% | Training loss: 0.6967290205614908
Epoch: 27 | Iteration number: [80/565] 14% | Training loss: 0.6955724030733108
Epoch: 27 | Iteration number: [90/565] 15% | Training loss: 0.6946052173773448
Epoch: 27 | Iteration number: [100/565] 17% | Training loss: 0.6938446074724197
Epoch: 27 | Iteration number: [110/565] 19% | Training loss: 0.693213397806341
Epoch: 27 | Iteration number: [120/565] 21% | Training loss: 0.6926981622974078
Epoch: 27 | Iteration number: [130/565] 23% | Training loss: 0.6922713064230406
Epoch: 27 | Iteration number: [140/565] 24% | Training loss: 0.6918880517993654
Epoch: 27 | Iteration number: [150/565] 26% | Training loss: 0.6915726216634115
Epoch: 27 | Iteration number: [160/565] 28% | Training loss: 0.6912933371961116
Epoch: 27 | Iteration number: [170/565] 30% | Training loss: 0.6910376348916222
Epoch: 27 | Iteration number: [180/565] 31% | Training loss: 0.6908076150549782
Epoch: 27 | Iteration number: [190/565] 33% | Training loss: 0.6906014843990929
Epoch: 27 | Iteration number: [200/565] 35% | Training loss: 0.6904060304164886
Epoch: 27 | Iteration number: [210/565] 37% | Training loss: 0.6902163008848826
Epoch: 27 | Iteration number: [220/565] 38% | Training loss: 0.6900502511046149
Epoch: 27 | Iteration number: [230/565] 40% | Training loss: 0.6899034373138262
Epoch: 27 | Iteration number: [240/565] 42% | Training loss: 0.6897940593461196
Epoch: 27 | Iteration number: [250/565] 44% | Training loss: 0.689676218032837
Epoch: 27 | Iteration number: [260/565] 46% | Training loss: 0.6895825230158292
Epoch: 27 | Iteration number: [270/565] 47% | Training loss: 0.6894734610010076
Epoch: 27 | Iteration number: [280/565] 49% | Training loss: 0.6893633165529796
Epoch: 27 | Iteration number: [290/565] 51% | Training loss: 0.68929379829045
Epoch: 27 | Iteration number: [300/565] 53% | Training loss: 0.689221541484197
Epoch: 27 | Iteration number: [310/565] 54% | Training loss: 0.6891488677070987
Epoch: 27 | Iteration number: [320/565] 56% | Training loss: 0.6890758782625198
Epoch: 27 | Iteration number: [330/565] 58% | Training loss: 0.6890174712195541
Epoch: 27 | Iteration number: [340/565] 60% | Training loss: 0.6889518210116554
Epoch: 27 | Iteration number: [350/565] 61% | Training loss: 0.6889063170978001
Epoch: 27 | Iteration number: [360/565] 63% | Training loss: 0.6888528087072903
Epoch: 27 | Iteration number: [370/565] 65% | Training loss: 0.6888046428963944
Epoch: 27 | Iteration number: [380/565] 67% | Training loss: 0.6887462979868839
Epoch: 27 | Iteration number: [390/565] 69% | Training loss: 0.6887003793166234
Epoch: 27 | Iteration number: [400/565] 70% | Training loss: 0.6886567206680775
Epoch: 27 | Iteration number: [410/565] 72% | Training loss: 0.6886149231980486
Epoch: 27 | Iteration number: [420/565] 74% | Training loss: 0.6885758925051916
Epoch: 27 | Iteration number: [430/565] 76% | Training loss: 0.6885366693485615
Epoch: 27 | Iteration number: [440/565] 77% | Training loss: 0.6885033454407345
Epoch: 27 | Iteration number: [450/565] 79% | Training loss: 0.6884634269608392
Epoch: 27 | Iteration number: [460/565] 81% | Training loss: 0.6884243271920992
Epoch: 27 | Iteration number: [470/565] 83% | Training loss: 0.6883926208983077
Epoch: 27 | Iteration number: [480/565] 84% | Training loss: 0.6883649341762066
Epoch: 27 | Iteration number: [490/565] 86% | Training loss: 0.688338179369362
Epoch: 27 | Iteration number: [500/565] 88% | Training loss: 0.6883113701343536
Epoch: 27 | Iteration number: [510/565] 90% | Training loss: 0.6882821572761909
Epoch: 27 | Iteration number: [520/565] 92% | Training loss: 0.688245745576345
Epoch: 27 | Iteration number: [530/565] 93% | Training loss: 0.6882117545829629
Epoch: 27 | Iteration number: [540/565] 95% | Training loss: 0.6881864334698077
Epoch: 27 | Iteration number: [550/565] 97% | Training loss: 0.6881685440106825
Epoch: 27 | Iteration number: [560/565] 99% | Training loss: 0.6881425684051854

 End of epoch: 27 | Train Loss: 0.686916724875965 | Training Time: 89 

 End of epoch: 27 | Eval Loss: 0.6898607526506696 | Evaluating Time: 6 
Epoch: 28 | Iteration number: [10/565] 1% | Training loss: 0.7555038452148437
Epoch: 28 | Iteration number: [20/565] 3% | Training loss: 0.7210268974304199
Epoch: 28 | Iteration number: [30/565] 5% | Training loss: 0.7097631653149923
Epoch: 28 | Iteration number: [40/565] 7% | Training loss: 0.7041768699884414
Epoch: 28 | Iteration number: [50/565] 8% | Training loss: 0.7007336902618408
Epoch: 28 | Iteration number: [60/565] 10% | Training loss: 0.6983890285094579
Epoch: 28 | Iteration number: [70/565] 12% | Training loss: 0.696834088223321
Epoch: 28 | Iteration number: [80/565] 14% | Training loss: 0.6955553218722343
Epoch: 28 | Iteration number: [90/565] 15% | Training loss: 0.6945761766698625
Epoch: 28 | Iteration number: [100/565] 17% | Training loss: 0.6938078582286835
Epoch: 28 | Iteration number: [110/565] 19% | Training loss: 0.6931863909417932
Epoch: 28 | Iteration number: [120/565] 21% | Training loss: 0.6926768253246943
Epoch: 28 | Iteration number: [130/565] 23% | Training loss: 0.6922599457777463
Epoch: 28 | Iteration number: [140/565] 24% | Training loss: 0.6918604493141174
Epoch: 28 | Iteration number: [150/565] 26% | Training loss: 0.6915437436103821
Epoch: 28 | Iteration number: [160/565] 28% | Training loss: 0.6912123043090105
Epoch: 28 | Iteration number: [170/565] 30% | Training loss: 0.6909616947174072
Epoch: 28 | Iteration number: [180/565] 31% | Training loss: 0.6907303111420737
Epoch: 28 | Iteration number: [190/565] 33% | Training loss: 0.6905256591345135
Epoch: 28 | Iteration number: [200/565] 35% | Training loss: 0.6903410857915878
Epoch: 28 | Iteration number: [210/565] 37% | Training loss: 0.6901878257592519
Epoch: 28 | Iteration number: [220/565] 38% | Training loss: 0.690052136236971
Epoch: 28 | Iteration number: [230/565] 40% | Training loss: 0.6899077739404595
Epoch: 28 | Iteration number: [240/565] 42% | Training loss: 0.6897827039162318
Epoch: 28 | Iteration number: [250/565] 44% | Training loss: 0.6896648895740509
Epoch: 28 | Iteration number: [260/565] 46% | Training loss: 0.689542865065428
Epoch: 28 | Iteration number: [270/565] 47% | Training loss: 0.6894526567724016
Epoch: 28 | Iteration number: [280/565] 49% | Training loss: 0.6893541908689907
Epoch: 28 | Iteration number: [290/565] 51% | Training loss: 0.6892763281690664
Epoch: 28 | Iteration number: [300/565] 53% | Training loss: 0.6891981238126754
Epoch: 28 | Iteration number: [310/565] 54% | Training loss: 0.6891148601808855
Epoch: 28 | Iteration number: [320/565] 56% | Training loss: 0.6890552263706923
Epoch: 28 | Iteration number: [330/565] 58% | Training loss: 0.6889876952677062
Epoch: 28 | Iteration number: [340/565] 60% | Training loss: 0.6889220384990468
Epoch: 28 | Iteration number: [350/565] 61% | Training loss: 0.6888637043748583
Epoch: 28 | Iteration number: [360/565] 63% | Training loss: 0.6888117902808719
Epoch: 28 | Iteration number: [370/565] 65% | Training loss: 0.6887609302997589
Epoch: 28 | Iteration number: [380/565] 67% | Training loss: 0.6887150366055338
Epoch: 28 | Iteration number: [390/565] 69% | Training loss: 0.6886768545859899
Epoch: 28 | Iteration number: [400/565] 70% | Training loss: 0.6886403955519199
Epoch: 28 | Iteration number: [410/565] 72% | Training loss: 0.6885974458078059
Epoch: 28 | Iteration number: [420/565] 74% | Training loss: 0.6885503774597531
Epoch: 28 | Iteration number: [430/565] 76% | Training loss: 0.6885078134924867
Epoch: 28 | Iteration number: [440/565] 77% | Training loss: 0.6884711043401198
Epoch: 28 | Iteration number: [450/565] 79% | Training loss: 0.6884362848599752
Epoch: 28 | Iteration number: [460/565] 81% | Training loss: 0.6883938184250956
Epoch: 28 | Iteration number: [470/565] 83% | Training loss: 0.6883551330008405
Epoch: 28 | Iteration number: [480/565] 84% | Training loss: 0.6883215062320233
Epoch: 28 | Iteration number: [490/565] 86% | Training loss: 0.6882940202343221
Epoch: 28 | Iteration number: [500/565] 88% | Training loss: 0.6882689471244812
Epoch: 28 | Iteration number: [510/565] 90% | Training loss: 0.6882474465697419
Epoch: 28 | Iteration number: [520/565] 92% | Training loss: 0.6882226384603061
Epoch: 28 | Iteration number: [530/565] 93% | Training loss: 0.6882042156075532
Epoch: 28 | Iteration number: [540/565] 95% | Training loss: 0.688175892829895
Epoch: 28 | Iteration number: [550/565] 97% | Training loss: 0.6881601655483246
Epoch: 28 | Iteration number: [560/565] 99% | Training loss: 0.6881458840199879

 End of epoch: 28 | Train Loss: 0.686918517340601 | Training Time: 89 

 End of epoch: 28 | Eval Loss: 0.69045490026474 | Evaluating Time: 6 
Epoch: 29 | Iteration number: [10/565] 1% | Training loss: 0.7550063252449035
Epoch: 29 | Iteration number: [20/565] 3% | Training loss: 0.7211412161588668
Epoch: 29 | Iteration number: [30/565] 5% | Training loss: 0.709750642379125
Epoch: 29 | Iteration number: [40/565] 7% | Training loss: 0.7040389865636826
Epoch: 29 | Iteration number: [50/565] 8% | Training loss: 0.7005972301959992
Epoch: 29 | Iteration number: [60/565] 10% | Training loss: 0.6982966353495915
Epoch: 29 | Iteration number: [70/565] 12% | Training loss: 0.6966815786702293
Epoch: 29 | Iteration number: [80/565] 14% | Training loss: 0.6954577803611756
Epoch: 29 | Iteration number: [90/565] 15% | Training loss: 0.6945551441775428
Epoch: 29 | Iteration number: [100/565] 17% | Training loss: 0.6937917506694794
Epoch: 29 | Iteration number: [110/565] 19% | Training loss: 0.6931817959655415
Epoch: 29 | Iteration number: [120/565] 21% | Training loss: 0.6926731218894323
Epoch: 29 | Iteration number: [130/565] 23% | Training loss: 0.6922345551160666
Epoch: 29 | Iteration number: [140/565] 24% | Training loss: 0.6918993583747319
Epoch: 29 | Iteration number: [150/565] 26% | Training loss: 0.6915548133850098
Epoch: 29 | Iteration number: [160/565] 28% | Training loss: 0.6912684008479119
Epoch: 29 | Iteration number: [170/565] 30% | Training loss: 0.6910200504695668
Epoch: 29 | Iteration number: [180/565] 31% | Training loss: 0.6907774219910304
Epoch: 29 | Iteration number: [190/565] 33% | Training loss: 0.6905798595202597
Epoch: 29 | Iteration number: [200/565] 35% | Training loss: 0.6903963202238083
Epoch: 29 | Iteration number: [210/565] 37% | Training loss: 0.6902225758348193
Epoch: 29 | Iteration number: [220/565] 38% | Training loss: 0.6900629729032517
Epoch: 29 | Iteration number: [230/565] 40% | Training loss: 0.6899486482143402
Epoch: 29 | Iteration number: [240/565] 42% | Training loss: 0.6898206862310569
Epoch: 29 | Iteration number: [250/565] 44% | Training loss: 0.6896975433826447
Epoch: 29 | Iteration number: [260/565] 46% | Training loss: 0.6895718957369145
Epoch: 29 | Iteration number: [270/565] 47% | Training loss: 0.6894748014432412
Epoch: 29 | Iteration number: [280/565] 49% | Training loss: 0.6893889765654292
Epoch: 29 | Iteration number: [290/565] 51% | Training loss: 0.6892990145190009
Epoch: 29 | Iteration number: [300/565] 53% | Training loss: 0.6892107711235682
Epoch: 29 | Iteration number: [310/565] 54% | Training loss: 0.6891372565300234
Epoch: 29 | Iteration number: [320/565] 56% | Training loss: 0.6890743970870972
Epoch: 29 | Iteration number: [330/565] 58% | Training loss: 0.6890057661316612
Epoch: 29 | Iteration number: [340/565] 60% | Training loss: 0.6889385484597262
Epoch: 29 | Iteration number: [350/565] 61% | Training loss: 0.6888761653218951
Epoch: 29 | Iteration number: [360/565] 63% | Training loss: 0.6888131674793031
Epoch: 29 | Iteration number: [370/565] 65% | Training loss: 0.6887669086456298
Epoch: 29 | Iteration number: [380/565] 67% | Training loss: 0.6887253441308674
Epoch: 29 | Iteration number: [390/565] 69% | Training loss: 0.6886653579198397
Epoch: 29 | Iteration number: [400/565] 70% | Training loss: 0.6886206802725792
Epoch: 29 | Iteration number: [410/565] 72% | Training loss: 0.6885787029091904
Epoch: 29 | Iteration number: [420/565] 74% | Training loss: 0.6885452694836117
Epoch: 29 | Iteration number: [430/565] 76% | Training loss: 0.6885191267312959
Epoch: 29 | Iteration number: [440/565] 77% | Training loss: 0.6884794274514372
Epoch: 29 | Iteration number: [450/565] 79% | Training loss: 0.6884400085608164
Epoch: 29 | Iteration number: [460/565] 81% | Training loss: 0.6884071335844372
Epoch: 29 | Iteration number: [470/565] 83% | Training loss: 0.6883766835040235
Epoch: 29 | Iteration number: [480/565] 84% | Training loss: 0.688343645259738
Epoch: 29 | Iteration number: [490/565] 86% | Training loss: 0.688308915070125
Epoch: 29 | Iteration number: [500/565] 88% | Training loss: 0.6882757269144059
Epoch: 29 | Iteration number: [510/565] 90% | Training loss: 0.6882450014937158
Epoch: 29 | Iteration number: [520/565] 92% | Training loss: 0.6882185402971047
Epoch: 29 | Iteration number: [530/565] 93% | Training loss: 0.6882039136481735
Epoch: 29 | Iteration number: [540/565] 95% | Training loss: 0.6881806222377
Epoch: 29 | Iteration number: [550/565] 97% | Training loss: 0.6881543579968539
Epoch: 29 | Iteration number: [560/565] 99% | Training loss: 0.6881321191787719

 End of epoch: 29 | Train Loss: 0.6869027515428257 | Training Time: 89 

 End of epoch: 29 | Eval Loss: 0.6897679652486529 | Evaluating Time: 6 
Epoch: 30 | Iteration number: [10/565] 1% | Training loss: 0.7551881968975067
Epoch: 30 | Iteration number: [20/565] 3% | Training loss: 0.7210344970226288
Epoch: 30 | Iteration number: [30/565] 5% | Training loss: 0.7096942325433095
Epoch: 30 | Iteration number: [40/565] 7% | Training loss: 0.7039535433053971
Epoch: 30 | Iteration number: [50/565] 8% | Training loss: 0.7004399144649506
Epoch: 30 | Iteration number: [60/565] 10% | Training loss: 0.6982571790615718
Epoch: 30 | Iteration number: [70/565] 12% | Training loss: 0.6966922802584512
Epoch: 30 | Iteration number: [80/565] 14% | Training loss: 0.6954632483422756
Epoch: 30 | Iteration number: [90/565] 15% | Training loss: 0.6945140249199337
Epoch: 30 | Iteration number: [100/565] 17% | Training loss: 0.6937808603048324
Epoch: 30 | Iteration number: [110/565] 19% | Training loss: 0.6931694773110476
Epoch: 30 | Iteration number: [120/565] 21% | Training loss: 0.6926362385352453
Epoch: 30 | Iteration number: [130/565] 23% | Training loss: 0.692189162511092
Epoch: 30 | Iteration number: [140/565] 24% | Training loss: 0.6917970427445003
Epoch: 30 | Iteration number: [150/565] 26% | Training loss: 0.6914565352598826
Epoch: 30 | Iteration number: [160/565] 28% | Training loss: 0.6911630388349295
Epoch: 30 | Iteration number: [170/565] 30% | Training loss: 0.6909133031087763
Epoch: 30 | Iteration number: [180/565] 31% | Training loss: 0.6907058818472757
Epoch: 30 | Iteration number: [190/565] 33% | Training loss: 0.6904995902588493
Epoch: 30 | Iteration number: [200/565] 35% | Training loss: 0.6903205293416977
Epoch: 30 | Iteration number: [210/565] 37% | Training loss: 0.6901446061474936
Epoch: 30 | Iteration number: [220/565] 38% | Training loss: 0.6899889815937389
Epoch: 30 | Iteration number: [230/565] 40% | Training loss: 0.6898685268733813
Epoch: 30 | Iteration number: [240/565] 42% | Training loss: 0.6897365413606167
Epoch: 30 | Iteration number: [250/565] 44% | Training loss: 0.6896126117706299
Epoch: 30 | Iteration number: [260/565] 46% | Training loss: 0.689503515454439
Epoch: 30 | Iteration number: [270/565] 47% | Training loss: 0.6894236447634521
Epoch: 30 | Iteration number: [280/565] 49% | Training loss: 0.6893234608428819
Epoch: 30 | Iteration number: [290/565] 51% | Training loss: 0.6892293260015291
Epoch: 30 | Iteration number: [300/565] 53% | Training loss: 0.6891604395707448
Epoch: 30 | Iteration number: [310/565] 54% | Training loss: 0.6890891396230266
Epoch: 30 | Iteration number: [320/565] 56% | Training loss: 0.6890143331140279
Epoch: 30 | Iteration number: [330/565] 58% | Training loss: 0.6889509374445135
Epoch: 30 | Iteration number: [340/565] 60% | Training loss: 0.6888924495262259
Epoch: 30 | Iteration number: [350/565] 61% | Training loss: 0.6888404985836574
Epoch: 30 | Iteration number: [360/565] 63% | Training loss: 0.6887980747554038
Epoch: 30 | Iteration number: [370/565] 65% | Training loss: 0.6887413342256804
Epoch: 30 | Iteration number: [380/565] 67% | Training loss: 0.6886890262365342
Epoch: 30 | Iteration number: [390/565] 69% | Training loss: 0.6886425236860911
Epoch: 30 | Iteration number: [400/565] 70% | Training loss: 0.6885945020616054
Epoch: 30 | Iteration number: [410/565] 72% | Training loss: 0.6885505796932593
Epoch: 30 | Iteration number: [420/565] 74% | Training loss: 0.6885186700593857
Epoch: 30 | Iteration number: [430/565] 76% | Training loss: 0.6884833492511927
Epoch: 30 | Iteration number: [440/565] 77% | Training loss: 0.688448370586742
Epoch: 30 | Iteration number: [450/565] 79% | Training loss: 0.6884169663323296
Epoch: 30 | Iteration number: [460/565] 81% | Training loss: 0.6883837493865387
Epoch: 30 | Iteration number: [470/565] 83% | Training loss: 0.68835049157447
Epoch: 30 | Iteration number: [480/565] 84% | Training loss: 0.688317600513498
Epoch: 30 | Iteration number: [490/565] 86% | Training loss: 0.6882947916887244
Epoch: 30 | Iteration number: [500/565] 88% | Training loss: 0.6882578945159912
Epoch: 30 | Iteration number: [510/565] 90% | Training loss: 0.6882230542454065
Epoch: 30 | Iteration number: [520/565] 92% | Training loss: 0.6882006381566708
Epoch: 30 | Iteration number: [530/565] 93% | Training loss: 0.6881746939893039
Epoch: 30 | Iteration number: [540/565] 95% | Training loss: 0.6881489217281341
Epoch: 30 | Iteration number: [550/565] 97% | Training loss: 0.68812894300981
Epoch: 30 | Iteration number: [560/565] 99% | Training loss: 0.6881101838179997

 End of epoch: 30 | Train Loss: 0.6868851789331014 | Training Time: 89 

 End of epoch: 30 | Eval Loss: 0.6897269657679966 | Evaluating Time: 5 
Epoch: 31 | Iteration number: [10/565] 1% | Training loss: 0.7557258903980255
Epoch: 31 | Iteration number: [20/565] 3% | Training loss: 0.7211914598941803
Epoch: 31 | Iteration number: [30/565] 5% | Training loss: 0.709608672062556
Epoch: 31 | Iteration number: [40/565] 7% | Training loss: 0.7039590284228325
Epoch: 31 | Iteration number: [50/565] 8% | Training loss: 0.7005700659751892
Epoch: 31 | Iteration number: [60/565] 10% | Training loss: 0.6983230441808701
Epoch: 31 | Iteration number: [70/565] 12% | Training loss: 0.6966195472649166
Epoch: 31 | Iteration number: [80/565] 14% | Training loss: 0.695465063303709
Epoch: 31 | Iteration number: [90/565] 15% | Training loss: 0.6944728169176314
Epoch: 31 | Iteration number: [100/565] 17% | Training loss: 0.6937110871076584
Epoch: 31 | Iteration number: [110/565] 19% | Training loss: 0.6930904886939309
Epoch: 31 | Iteration number: [120/565] 21% | Training loss: 0.692598461608092
Epoch: 31 | Iteration number: [130/565] 23% | Training loss: 0.6921470119402959
Epoch: 31 | Iteration number: [140/565] 24% | Training loss: 0.69176447561809
Epoch: 31 | Iteration number: [150/565] 26% | Training loss: 0.6914502123991648
Epoch: 31 | Iteration number: [160/565] 28% | Training loss: 0.6911472875624896
Epoch: 31 | Iteration number: [170/565] 30% | Training loss: 0.6909134184612947
Epoch: 31 | Iteration number: [180/565] 31% | Training loss: 0.6906613697608311
Epoch: 31 | Iteration number: [190/565] 33% | Training loss: 0.6904717718300066
Epoch: 31 | Iteration number: [200/565] 35% | Training loss: 0.6902863976359367
Epoch: 31 | Iteration number: [210/565] 37% | Training loss: 0.6901394455205827
Epoch: 31 | Iteration number: [220/565] 38% | Training loss: 0.68998150175268
Epoch: 31 | Iteration number: [230/565] 40% | Training loss: 0.6898161942544191
Epoch: 31 | Iteration number: [240/565] 42% | Training loss: 0.6896966067453225
Epoch: 31 | Iteration number: [250/565] 44% | Training loss: 0.6895964686870575
Epoch: 31 | Iteration number: [260/565] 46% | Training loss: 0.689507158444478
Epoch: 31 | Iteration number: [270/565] 47% | Training loss: 0.6894061256338049
Epoch: 31 | Iteration number: [280/565] 49% | Training loss: 0.6893209614924022
Epoch: 31 | Iteration number: [290/565] 51% | Training loss: 0.6892366051673889
Epoch: 31 | Iteration number: [300/565] 53% | Training loss: 0.6891595458984375
Epoch: 31 | Iteration number: [310/565] 54% | Training loss: 0.6890846892710655
Epoch: 31 | Iteration number: [320/565] 56% | Training loss: 0.6890327922999859
Epoch: 31 | Iteration number: [330/565] 58% | Training loss: 0.6889759851224495
Epoch: 31 | Iteration number: [340/565] 60% | Training loss: 0.6889095716616687
Epoch: 31 | Iteration number: [350/565] 61% | Training loss: 0.6888415447303227
Epoch: 31 | Iteration number: [360/565] 63% | Training loss: 0.6887957721948623
Epoch: 31 | Iteration number: [370/565] 65% | Training loss: 0.6887344821079358
Epoch: 31 | Iteration number: [380/565] 67% | Training loss: 0.6886788440378089
Epoch: 31 | Iteration number: [390/565] 69% | Training loss: 0.6886390601977324
Epoch: 31 | Iteration number: [400/565] 70% | Training loss: 0.6885894970595836
Epoch: 31 | Iteration number: [410/565] 72% | Training loss: 0.6885416129740273
Epoch: 31 | Iteration number: [420/565] 74% | Training loss: 0.6885036188931692
Epoch: 31 | Iteration number: [430/565] 76% | Training loss: 0.6884685768637546
Epoch: 31 | Iteration number: [440/565] 77% | Training loss: 0.6884356500072912
Epoch: 31 | Iteration number: [450/565] 79% | Training loss: 0.6884092383914524
Epoch: 31 | Iteration number: [460/565] 81% | Training loss: 0.6883761659912441
Epoch: 31 | Iteration number: [470/565] 83% | Training loss: 0.6883449971675872
Epoch: 31 | Iteration number: [480/565] 84% | Training loss: 0.6883166755239168
Epoch: 31 | Iteration number: [490/565] 86% | Training loss: 0.6882916877464372
Epoch: 31 | Iteration number: [500/565] 88% | Training loss: 0.6882671518325806
Epoch: 31 | Iteration number: [510/565] 90% | Training loss: 0.6882388117266637
Epoch: 31 | Iteration number: [520/565] 92% | Training loss: 0.6882157565309451
Epoch: 31 | Iteration number: [530/565] 93% | Training loss: 0.6881870410352383
Epoch: 31 | Iteration number: [540/565] 95% | Training loss: 0.6881573705761521
Epoch: 31 | Iteration number: [550/565] 97% | Training loss: 0.6881427315148441
Epoch: 31 | Iteration number: [560/565] 99% | Training loss: 0.6881199039518833

 End of epoch: 31 | Train Loss: 0.6868941596124024 | Training Time: 89 

 End of epoch: 31 | Eval Loss: 0.6902396508625576 | Evaluating Time: 6 
Epoch: 32 | Iteration number: [10/565] 1% | Training loss: 0.7551981389522553
Epoch: 32 | Iteration number: [20/565] 3% | Training loss: 0.7208443373441696
Epoch: 32 | Iteration number: [30/565] 5% | Training loss: 0.7093774060408274
Epoch: 32 | Iteration number: [40/565] 7% | Training loss: 0.7038147255778313
Epoch: 32 | Iteration number: [50/565] 8% | Training loss: 0.7003854620456695
Epoch: 32 | Iteration number: [60/565] 10% | Training loss: 0.6981360872586568
Epoch: 32 | Iteration number: [70/565] 12% | Training loss: 0.6965483248233795
Epoch: 32 | Iteration number: [80/565] 14% | Training loss: 0.6953154288232326
Epoch: 32 | Iteration number: [90/565] 15% | Training loss: 0.6943894690937467
Epoch: 32 | Iteration number: [100/565] 17% | Training loss: 0.6936645245552063
Epoch: 32 | Iteration number: [110/565] 19% | Training loss: 0.6930620458993044
Epoch: 32 | Iteration number: [120/565] 21% | Training loss: 0.6925945902864138
Epoch: 32 | Iteration number: [130/565] 23% | Training loss: 0.6922014396924239
Epoch: 32 | Iteration number: [140/565] 24% | Training loss: 0.6918189376592636
Epoch: 32 | Iteration number: [150/565] 26% | Training loss: 0.6914906505743662
Epoch: 32 | Iteration number: [160/565] 28% | Training loss: 0.6911881323903799
Epoch: 32 | Iteration number: [170/565] 30% | Training loss: 0.690956604831359
Epoch: 32 | Iteration number: [180/565] 31% | Training loss: 0.6907411714394888
Epoch: 32 | Iteration number: [190/565] 33% | Training loss: 0.6905361197496716
Epoch: 32 | Iteration number: [200/565] 35% | Training loss: 0.6903608864545823
Epoch: 32 | Iteration number: [210/565] 37% | Training loss: 0.6902026477314177
Epoch: 32 | Iteration number: [220/565] 38% | Training loss: 0.690050380338322
Epoch: 32 | Iteration number: [230/565] 40% | Training loss: 0.6899105647335881
Epoch: 32 | Iteration number: [240/565] 42% | Training loss: 0.6897717215120792
Epoch: 32 | Iteration number: [250/565] 44% | Training loss: 0.6896581060886383
Epoch: 32 | Iteration number: [260/565] 46% | Training loss: 0.6895627083686682
Epoch: 32 | Iteration number: [270/565] 47% | Training loss: 0.6894489641542788
Epoch: 32 | Iteration number: [280/565] 49% | Training loss: 0.6893607145973615
Epoch: 32 | Iteration number: [290/565] 51% | Training loss: 0.689269389777348
Epoch: 32 | Iteration number: [300/565] 53% | Training loss: 0.6891865748167038
Epoch: 32 | Iteration number: [310/565] 54% | Training loss: 0.6891288859228935
Epoch: 32 | Iteration number: [320/565] 56% | Training loss: 0.6890535952523351
Epoch: 32 | Iteration number: [330/565] 58% | Training loss: 0.6889898869124326
Epoch: 32 | Iteration number: [340/565] 60% | Training loss: 0.6889241676120197
Epoch: 32 | Iteration number: [350/565] 61% | Training loss: 0.6888684466906956
Epoch: 32 | Iteration number: [360/565] 63% | Training loss: 0.6888170209195879
Epoch: 32 | Iteration number: [370/565] 65% | Training loss: 0.6887743263631254
Epoch: 32 | Iteration number: [380/565] 67% | Training loss: 0.6887327779280512
Epoch: 32 | Iteration number: [390/565] 69% | Training loss: 0.6886889038941799
Epoch: 32 | Iteration number: [400/565] 70% | Training loss: 0.6886472530663014
Epoch: 32 | Iteration number: [410/565] 72% | Training loss: 0.6886013372642238
Epoch: 32 | Iteration number: [420/565] 74% | Training loss: 0.6885551123392014
Epoch: 32 | Iteration number: [430/565] 76% | Training loss: 0.6885239057762679
Epoch: 32 | Iteration number: [440/565] 77% | Training loss: 0.6884847101840106
Epoch: 32 | Iteration number: [450/565] 79% | Training loss: 0.688442806535297
Epoch: 32 | Iteration number: [460/565] 81% | Training loss: 0.6884078877127688
Epoch: 32 | Iteration number: [470/565] 83% | Training loss: 0.6883797058399688
Epoch: 32 | Iteration number: [480/565] 84% | Training loss: 0.6883370839059353
Epoch: 32 | Iteration number: [490/565] 86% | Training loss: 0.6883004344239527
Epoch: 32 | Iteration number: [500/565] 88% | Training loss: 0.6882782046794891
Epoch: 32 | Iteration number: [510/565] 90% | Training loss: 0.6882430431889552
Epoch: 32 | Iteration number: [520/565] 92% | Training loss: 0.6882095262408257
Epoch: 32 | Iteration number: [530/565] 93% | Training loss: 0.6881776199025927
Epoch: 32 | Iteration number: [540/565] 95% | Training loss: 0.6881624508787084
Epoch: 32 | Iteration number: [550/565] 97% | Training loss: 0.6881458883935755
Epoch: 32 | Iteration number: [560/565] 99% | Training loss: 0.6881324217787811

 End of epoch: 32 | Train Loss: 0.6869030699265741 | Training Time: 89 

 End of epoch: 32 | Eval Loss: 0.6905583824430194 | Evaluating Time: 6 
Epoch: 33 | Iteration number: [10/565] 1% | Training loss: 0.7557927191257476
Epoch: 33 | Iteration number: [20/565] 3% | Training loss: 0.7214644879102707
Epoch: 33 | Iteration number: [30/565] 5% | Training loss: 0.7097834487756093
Epoch: 33 | Iteration number: [40/565] 7% | Training loss: 0.7039636373519897
Epoch: 33 | Iteration number: [50/565] 8% | Training loss: 0.700553730726242
Epoch: 33 | Iteration number: [60/565] 10% | Training loss: 0.6982260396083196
Epoch: 33 | Iteration number: [70/565] 12% | Training loss: 0.6965736840452467
Epoch: 33 | Iteration number: [80/565] 14% | Training loss: 0.6953088916838169
Epoch: 33 | Iteration number: [90/565] 15% | Training loss: 0.6943668762842814
Epoch: 33 | Iteration number: [100/565] 17% | Training loss: 0.6936200881004333
Epoch: 33 | Iteration number: [110/565] 19% | Training loss: 0.693052383444526
Epoch: 33 | Iteration number: [120/565] 21% | Training loss: 0.6925593217213949
Epoch: 33 | Iteration number: [130/565] 23% | Training loss: 0.6920875141253838
Epoch: 33 | Iteration number: [140/565] 24% | Training loss: 0.691709537591253
Epoch: 33 | Iteration number: [150/565] 26% | Training loss: 0.6914085666338603
Epoch: 33 | Iteration number: [160/565] 28% | Training loss: 0.6911041628569364
Epoch: 33 | Iteration number: [170/565] 30% | Training loss: 0.6908629617270301
Epoch: 33 | Iteration number: [180/565] 31% | Training loss: 0.6906394418742922
Epoch: 33 | Iteration number: [190/565] 33% | Training loss: 0.6904368366065778
Epoch: 33 | Iteration number: [200/565] 35% | Training loss: 0.6902695164084435
Epoch: 33 | Iteration number: [210/565] 37% | Training loss: 0.690099885350182
Epoch: 33 | Iteration number: [220/565] 38% | Training loss: 0.689951521971009
Epoch: 33 | Iteration number: [230/565] 40% | Training loss: 0.6898211658000946
Epoch: 33 | Iteration number: [240/565] 42% | Training loss: 0.6896956463654836
Epoch: 33 | Iteration number: [250/565] 44% | Training loss: 0.6895794689655304
Epoch: 33 | Iteration number: [260/565] 46% | Training loss: 0.6894846696120042
Epoch: 33 | Iteration number: [270/565] 47% | Training loss: 0.6893714414702521
Epoch: 33 | Iteration number: [280/565] 49% | Training loss: 0.689309945489679
Epoch: 33 | Iteration number: [290/565] 51% | Training loss: 0.6892291459543952
Epoch: 33 | Iteration number: [300/565] 53% | Training loss: 0.6891480068365733
Epoch: 33 | Iteration number: [310/565] 54% | Training loss: 0.6890705983484945
Epoch: 33 | Iteration number: [320/565] 56% | Training loss: 0.6890147099271416
Epoch: 33 | Iteration number: [330/565] 58% | Training loss: 0.6889485017819839
Epoch: 33 | Iteration number: [340/565] 60% | Training loss: 0.6888806646361071
Epoch: 33 | Iteration number: [350/565] 61% | Training loss: 0.6888115278312138
Epoch: 33 | Iteration number: [360/565] 63% | Training loss: 0.6887481348382102
Epoch: 33 | Iteration number: [370/565] 65% | Training loss: 0.6886865747941507
Epoch: 33 | Iteration number: [380/565] 67% | Training loss: 0.6886470546847896
Epoch: 33 | Iteration number: [390/565] 69% | Training loss: 0.6885968237351149
Epoch: 33 | Iteration number: [400/565] 70% | Training loss: 0.6885674364864827
Epoch: 33 | Iteration number: [410/565] 72% | Training loss: 0.6885280046521164
Epoch: 33 | Iteration number: [420/565] 74% | Training loss: 0.6885012098721095
Epoch: 33 | Iteration number: [430/565] 76% | Training loss: 0.6884768937909326
Epoch: 33 | Iteration number: [440/565] 77% | Training loss: 0.6884545040401545
Epoch: 33 | Iteration number: [450/565] 79% | Training loss: 0.6884055867460039
Epoch: 33 | Iteration number: [460/565] 81% | Training loss: 0.6883754587691763
Epoch: 33 | Iteration number: [470/565] 83% | Training loss: 0.688348151901935
Epoch: 33 | Iteration number: [480/565] 84% | Training loss: 0.6883171898623307
Epoch: 33 | Iteration number: [490/565] 86% | Training loss: 0.6882975125799373
Epoch: 33 | Iteration number: [500/565] 88% | Training loss: 0.6882701516151428
Epoch: 33 | Iteration number: [510/565] 90% | Training loss: 0.6882452969457589
Epoch: 33 | Iteration number: [520/565] 92% | Training loss: 0.6882142635492178
Epoch: 33 | Iteration number: [530/565] 93% | Training loss: 0.6881868961847053
Epoch: 33 | Iteration number: [540/565] 95% | Training loss: 0.6881556770315876
Epoch: 33 | Iteration number: [550/565] 97% | Training loss: 0.6881317345662551
Epoch: 33 | Iteration number: [560/565] 99% | Training loss: 0.688110448207174

 End of epoch: 33 | Train Loss: 0.6868805794589288 | Training Time: 86 

 End of epoch: 33 | Eval Loss: 0.6903812714985439 | Evaluating Time: 6 
Epoch: 34 | Iteration number: [10/565] 1% | Training loss: 0.7555984497070313
Epoch: 34 | Iteration number: [20/565] 3% | Training loss: 0.7214842110872268
Epoch: 34 | Iteration number: [30/565] 5% | Training loss: 0.710039218266805
Epoch: 34 | Iteration number: [40/565] 7% | Training loss: 0.7042036354541779
Epoch: 34 | Iteration number: [50/565] 8% | Training loss: 0.7007244896888732
Epoch: 34 | Iteration number: [60/565] 10% | Training loss: 0.6984196821848552
Epoch: 34 | Iteration number: [70/565] 12% | Training loss: 0.6967828571796417
Epoch: 34 | Iteration number: [80/565] 14% | Training loss: 0.6955470211803914
Epoch: 34 | Iteration number: [90/565] 15% | Training loss: 0.6946559760305616
Epoch: 34 | Iteration number: [100/565] 17% | Training loss: 0.6938774251937866
Epoch: 34 | Iteration number: [110/565] 19% | Training loss: 0.6932138708504764
Epoch: 34 | Iteration number: [120/565] 21% | Training loss: 0.6926849519213041
Epoch: 34 | Iteration number: [130/565] 23% | Training loss: 0.6922312071690193
Epoch: 34 | Iteration number: [140/565] 24% | Training loss: 0.6918144634791783
Epoch: 34 | Iteration number: [150/565] 26% | Training loss: 0.6915022158622741
Epoch: 34 | Iteration number: [160/565] 28% | Training loss: 0.691226065158844
Epoch: 34 | Iteration number: [170/565] 30% | Training loss: 0.6909821128143984
Epoch: 34 | Iteration number: [180/565] 31% | Training loss: 0.690755479534467
Epoch: 34 | Iteration number: [190/565] 33% | Training loss: 0.690529183337563
Epoch: 34 | Iteration number: [200/565] 35% | Training loss: 0.6903467416763306
Epoch: 34 | Iteration number: [210/565] 37% | Training loss: 0.6901704402196975
Epoch: 34 | Iteration number: [220/565] 38% | Training loss: 0.6900252193212509
Epoch: 34 | Iteration number: [230/565] 40% | Training loss: 0.6898947661337645
Epoch: 34 | Iteration number: [240/565] 42% | Training loss: 0.6897728604574999
Epoch: 34 | Iteration number: [250/565] 44% | Training loss: 0.6896653726100922
Epoch: 34 | Iteration number: [260/565] 46% | Training loss: 0.6895348645173587
Epoch: 34 | Iteration number: [270/565] 47% | Training loss: 0.6894429469550097
Epoch: 34 | Iteration number: [280/565] 49% | Training loss: 0.6893510452338627
Epoch: 34 | Iteration number: [290/565] 51% | Training loss: 0.6892600462354462
Epoch: 34 | Iteration number: [300/565] 53% | Training loss: 0.6891518898804982
Epoch: 34 | Iteration number: [310/565] 54% | Training loss: 0.6890740123487288
Epoch: 34 | Iteration number: [320/565] 56% | Training loss: 0.6890106430277229
Epoch: 34 | Iteration number: [330/565] 58% | Training loss: 0.688953146609393
Epoch: 34 | Iteration number: [340/565] 60% | Training loss: 0.6888903084923239
Epoch: 34 | Iteration number: [350/565] 61% | Training loss: 0.6888319425923484
Epoch: 34 | Iteration number: [360/565] 63% | Training loss: 0.6887838764323129
Epoch: 34 | Iteration number: [370/565] 65% | Training loss: 0.6887309171058036
Epoch: 34 | Iteration number: [380/565] 67% | Training loss: 0.688684879321801
Epoch: 34 | Iteration number: [390/565] 69% | Training loss: 0.6886395972508651
Epoch: 34 | Iteration number: [400/565] 70% | Training loss: 0.6885794511437416
Epoch: 34 | Iteration number: [410/565] 72% | Training loss: 0.6885405915539439
Epoch: 34 | Iteration number: [420/565] 74% | Training loss: 0.6885076420647758
Epoch: 34 | Iteration number: [430/565] 76% | Training loss: 0.6884772059529327
Epoch: 34 | Iteration number: [440/565] 77% | Training loss: 0.6884371351112019
Epoch: 34 | Iteration number: [450/565] 79% | Training loss: 0.6884111819002363
Epoch: 34 | Iteration number: [460/565] 81% | Training loss: 0.688387069106102
Epoch: 34 | Iteration number: [470/565] 83% | Training loss: 0.6883496346625876
Epoch: 34 | Iteration number: [480/565] 84% | Training loss: 0.6883156020194292
Epoch: 34 | Iteration number: [490/565] 86% | Training loss: 0.6882855045552156
Epoch: 34 | Iteration number: [500/565] 88% | Training loss: 0.6882595386505127
Epoch: 34 | Iteration number: [510/565] 90% | Training loss: 0.6882164602186166
Epoch: 34 | Iteration number: [520/565] 92% | Training loss: 0.6881865018835435
Epoch: 34 | Iteration number: [530/565] 93% | Training loss: 0.6881708172132384
Epoch: 34 | Iteration number: [540/565] 95% | Training loss: 0.6881472211193156
Epoch: 34 | Iteration number: [550/565] 97% | Training loss: 0.6881226844137365
Epoch: 34 | Iteration number: [560/565] 99% | Training loss: 0.6880905969866684

 End of epoch: 34 | Train Loss: 0.6868626932127286 | Training Time: 90 

 End of epoch: 34 | Eval Loss: 0.6900055834225246 | Evaluating Time: 6 
Epoch: 35 | Iteration number: [10/565] 1% | Training loss: 0.7559776425361633
Epoch: 35 | Iteration number: [20/565] 3% | Training loss: 0.7214925318956376
Epoch: 35 | Iteration number: [30/565] 5% | Training loss: 0.7099536856015524
Epoch: 35 | Iteration number: [40/565] 7% | Training loss: 0.7042972326278687
Epoch: 35 | Iteration number: [50/565] 8% | Training loss: 0.7007619106769561
Epoch: 35 | Iteration number: [60/565] 10% | Training loss: 0.698430539170901
Epoch: 35 | Iteration number: [70/565] 12% | Training loss: 0.6967791378498077
Epoch: 35 | Iteration number: [80/565] 14% | Training loss: 0.6955690965056419
Epoch: 35 | Iteration number: [90/565] 15% | Training loss: 0.6945957243442535
Epoch: 35 | Iteration number: [100/565] 17% | Training loss: 0.693837684392929
Epoch: 35 | Iteration number: [110/565] 19% | Training loss: 0.6931922202760523
Epoch: 35 | Iteration number: [120/565] 21% | Training loss: 0.6926771273215612
Epoch: 35 | Iteration number: [130/565] 23% | Training loss: 0.6922324286057399
Epoch: 35 | Iteration number: [140/565] 24% | Training loss: 0.6918797748429435
Epoch: 35 | Iteration number: [150/565] 26% | Training loss: 0.6915351593494415
Epoch: 35 | Iteration number: [160/565] 28% | Training loss: 0.6912292439490557
Epoch: 35 | Iteration number: [170/565] 30% | Training loss: 0.690969059046577
Epoch: 35 | Iteration number: [180/565] 31% | Training loss: 0.6907312760750453
Epoch: 35 | Iteration number: [190/565] 33% | Training loss: 0.690536356913416
Epoch: 35 | Iteration number: [200/565] 35% | Training loss: 0.6903378841280937
Epoch: 35 | Iteration number: [210/565] 37% | Training loss: 0.6901831541742597
Epoch: 35 | Iteration number: [220/565] 38% | Training loss: 0.6900286761197176
Epoch: 35 | Iteration number: [230/565] 40% | Training loss: 0.6898722342822863
Epoch: 35 | Iteration number: [240/565] 42% | Training loss: 0.6897517196834088
Epoch: 35 | Iteration number: [250/565] 44% | Training loss: 0.689646903514862
Epoch: 35 | Iteration number: [260/565] 46% | Training loss: 0.6895291184003537
Epoch: 35 | Iteration number: [270/565] 47% | Training loss: 0.6894310114560304
Epoch: 35 | Iteration number: [280/565] 49% | Training loss: 0.6893537163734436
Epoch: 35 | Iteration number: [290/565] 51% | Training loss: 0.689280132589669
Epoch: 35 | Iteration number: [300/565] 53% | Training loss: 0.6892127156257629
Epoch: 35 | Iteration number: [310/565] 54% | Training loss: 0.6891298734372662
Epoch: 35 | Iteration number: [320/565] 56% | Training loss: 0.6890596965327859
Epoch: 35 | Iteration number: [330/565] 58% | Training loss: 0.6889994471362143
Epoch: 35 | Iteration number: [340/565] 60% | Training loss: 0.6889521723284441
Epoch: 35 | Iteration number: [350/565] 61% | Training loss: 0.6888844685895102
Epoch: 35 | Iteration number: [360/565] 63% | Training loss: 0.6888381638460689
Epoch: 35 | Iteration number: [370/565] 65% | Training loss: 0.6887817455304636
Epoch: 35 | Iteration number: [380/565] 67% | Training loss: 0.6887324607685993
Epoch: 35 | Iteration number: [390/565] 69% | Training loss: 0.6886814501041021
Epoch: 35 | Iteration number: [400/565] 70% | Training loss: 0.6886392097175121
Epoch: 35 | Iteration number: [410/565] 72% | Training loss: 0.6885849900361968
Epoch: 35 | Iteration number: [420/565] 74% | Training loss: 0.6885273421094531
Epoch: 35 | Iteration number: [430/565] 76% | Training loss: 0.6884934741397236
Epoch: 35 | Iteration number: [440/565] 77% | Training loss: 0.6884535006501458
Epoch: 35 | Iteration number: [450/565] 79% | Training loss: 0.6884125346607632
Epoch: 35 | Iteration number: [460/565] 81% | Training loss: 0.6883834932161415
Epoch: 35 | Iteration number: [470/565] 83% | Training loss: 0.6883418941751439
Epoch: 35 | Iteration number: [480/565] 84% | Training loss: 0.6883167566110691
Epoch: 35 | Iteration number: [490/565] 86% | Training loss: 0.6882884379552335
Epoch: 35 | Iteration number: [500/565] 88% | Training loss: 0.688260505437851
Epoch: 35 | Iteration number: [510/565] 90% | Training loss: 0.6882261223652784
Epoch: 35 | Iteration number: [520/565] 92% | Training loss: 0.6882059981043522
Epoch: 35 | Iteration number: [530/565] 93% | Training loss: 0.6881730814025088
Epoch: 35 | Iteration number: [540/565] 95% | Training loss: 0.6881474468443128
Epoch: 35 | Iteration number: [550/565] 97% | Training loss: 0.688122263063084
Epoch: 35 | Iteration number: [560/565] 99% | Training loss: 0.6880991740950516

 End of epoch: 35 | Train Loss: 0.6868775091340057 | Training Time: 90 

 End of epoch: 35 | Eval Loss: 0.6903203300067356 | Evaluating Time: 6 
Epoch: 36 | Iteration number: [10/565] 1% | Training loss: 0.7557952463626861
Epoch: 36 | Iteration number: [20/565] 3% | Training loss: 0.7216129064559936
Epoch: 36 | Iteration number: [30/565] 5% | Training loss: 0.7099562684694926
Epoch: 36 | Iteration number: [40/565] 7% | Training loss: 0.7042800828814506
Epoch: 36 | Iteration number: [50/565] 8% | Training loss: 0.7008258819580078
Epoch: 36 | Iteration number: [60/565] 10% | Training loss: 0.6985134641329448
Epoch: 36 | Iteration number: [70/565] 12% | Training loss: 0.6968682493482318
Epoch: 36 | Iteration number: [80/565] 14% | Training loss: 0.6956626005470753
Epoch: 36 | Iteration number: [90/565] 15% | Training loss: 0.6946777337127261
Epoch: 36 | Iteration number: [100/565] 17% | Training loss: 0.69390081346035
Epoch: 36 | Iteration number: [110/565] 19% | Training loss: 0.6932281060652299
Epoch: 36 | Iteration number: [120/565] 21% | Training loss: 0.6927144726117452
Epoch: 36 | Iteration number: [130/565] 23% | Training loss: 0.6923085308991945
Epoch: 36 | Iteration number: [140/565] 24% | Training loss: 0.6919305933373315
Epoch: 36 | Iteration number: [150/565] 26% | Training loss: 0.691602186759313
Epoch: 36 | Iteration number: [160/565] 28% | Training loss: 0.6912963222712278
Epoch: 36 | Iteration number: [170/565] 30% | Training loss: 0.6910476053462309
Epoch: 36 | Iteration number: [180/565] 31% | Training loss: 0.6908282167381711
Epoch: 36 | Iteration number: [190/565] 33% | Training loss: 0.6906153048339643
Epoch: 36 | Iteration number: [200/565] 35% | Training loss: 0.690430013537407
Epoch: 36 | Iteration number: [210/565] 37% | Training loss: 0.6902458000750769
Epoch: 36 | Iteration number: [220/565] 38% | Training loss: 0.6901078218763524
Epoch: 36 | Iteration number: [230/565] 40% | Training loss: 0.6899689480014469
Epoch: 36 | Iteration number: [240/565] 42% | Training loss: 0.6898378270367781
Epoch: 36 | Iteration number: [250/565] 44% | Training loss: 0.6897152793407441
Epoch: 36 | Iteration number: [260/565] 46% | Training loss: 0.6895922658535151
Epoch: 36 | Iteration number: [270/565] 47% | Training loss: 0.6894941488901775
Epoch: 36 | Iteration number: [280/565] 49% | Training loss: 0.6893974310585431
Epoch: 36 | Iteration number: [290/565] 51% | Training loss: 0.689314569481488
Epoch: 36 | Iteration number: [300/565] 53% | Training loss: 0.6892236385742824
Epoch: 36 | Iteration number: [310/565] 54% | Training loss: 0.6891712519430345
Epoch: 36 | Iteration number: [320/565] 56% | Training loss: 0.6890960251912475
Epoch: 36 | Iteration number: [330/565] 58% | Training loss: 0.6890205348982955
Epoch: 36 | Iteration number: [340/565] 60% | Training loss: 0.6889561612816418
Epoch: 36 | Iteration number: [350/565] 61% | Training loss: 0.688889570236206
Epoch: 36 | Iteration number: [360/565] 63% | Training loss: 0.6888258559836282
Epoch: 36 | Iteration number: [370/565] 65% | Training loss: 0.6887722972277048
Epoch: 36 | Iteration number: [380/565] 67% | Training loss: 0.6887161963864377
Epoch: 36 | Iteration number: [390/565] 69% | Training loss: 0.6886556435854007
Epoch: 36 | Iteration number: [400/565] 70% | Training loss: 0.6886033841967583
Epoch: 36 | Iteration number: [410/565] 72% | Training loss: 0.688552941345587
Epoch: 36 | Iteration number: [420/565] 74% | Training loss: 0.6885045932871955
Epoch: 36 | Iteration number: [430/565] 76% | Training loss: 0.6884746752506079
Epoch: 36 | Iteration number: [440/565] 77% | Training loss: 0.6884358071468093
Epoch: 36 | Iteration number: [450/565] 79% | Training loss: 0.6884090522925059
Epoch: 36 | Iteration number: [460/565] 81% | Training loss: 0.6883833443341048
Epoch: 36 | Iteration number: [470/565] 83% | Training loss: 0.6883467411741298
Epoch: 36 | Iteration number: [480/565] 84% | Training loss: 0.6883107632398605
Epoch: 36 | Iteration number: [490/565] 86% | Training loss: 0.6882815317231782
Epoch: 36 | Iteration number: [500/565] 88% | Training loss: 0.688264087319374
Epoch: 36 | Iteration number: [510/565] 90% | Training loss: 0.6882305895580965
Epoch: 36 | Iteration number: [520/565] 92% | Training loss: 0.6882019663086304
Epoch: 36 | Iteration number: [530/565] 93% | Training loss: 0.6881646329501889
Epoch: 36 | Iteration number: [540/565] 95% | Training loss: 0.6881371444022214
Epoch: 36 | Iteration number: [550/565] 97% | Training loss: 0.6881075213172219
Epoch: 36 | Iteration number: [560/565] 99% | Training loss: 0.6880805987332549

 End of epoch: 36 | Train Loss: 0.6868594277221545 | Training Time: 89 

 End of epoch: 36 | Eval Loss: 0.6899750999041966 | Evaluating Time: 5 
Epoch: 37 | Iteration number: [10/565] 1% | Training loss: 0.7549794375896454
Epoch: 37 | Iteration number: [20/565] 3% | Training loss: 0.7206280648708343
Epoch: 37 | Iteration number: [30/565] 5% | Training loss: 0.7094316363334656
Epoch: 37 | Iteration number: [40/565] 7% | Training loss: 0.7038019686937332
Epoch: 37 | Iteration number: [50/565] 8% | Training loss: 0.7004089772701263
Epoch: 37 | Iteration number: [60/565] 10% | Training loss: 0.6981144368648529
Epoch: 37 | Iteration number: [70/565] 12% | Training loss: 0.6964809094156538
Epoch: 37 | Iteration number: [80/565] 14% | Training loss: 0.695342379808426
Epoch: 37 | Iteration number: [90/565] 15% | Training loss: 0.694356558057997
Epoch: 37 | Iteration number: [100/565] 17% | Training loss: 0.6936452907323837
Epoch: 37 | Iteration number: [110/565] 19% | Training loss: 0.6930117737163197
Epoch: 37 | Iteration number: [120/565] 21% | Training loss: 0.692506360510985
Epoch: 37 | Iteration number: [130/565] 23% | Training loss: 0.6920742337520306
Epoch: 37 | Iteration number: [140/565] 24% | Training loss: 0.6916901937552861
Epoch: 37 | Iteration number: [150/565] 26% | Training loss: 0.6913625816504161
Epoch: 37 | Iteration number: [160/565] 28% | Training loss: 0.6910801347345114
Epoch: 37 | Iteration number: [170/565] 30% | Training loss: 0.6908491611480713
Epoch: 37 | Iteration number: [180/565] 31% | Training loss: 0.6906261122888989
Epoch: 37 | Iteration number: [190/565] 33% | Training loss: 0.6904192353549756
Epoch: 37 | Iteration number: [200/565] 35% | Training loss: 0.6902593499422074
Epoch: 37 | Iteration number: [210/565] 37% | Training loss: 0.6901025882789067
Epoch: 37 | Iteration number: [220/565] 38% | Training loss: 0.6899564390832728
Epoch: 37 | Iteration number: [230/565] 40% | Training loss: 0.6898335975149403
Epoch: 37 | Iteration number: [240/565] 42% | Training loss: 0.6897289137045542
Epoch: 37 | Iteration number: [250/565] 44% | Training loss: 0.689614218711853
Epoch: 37 | Iteration number: [260/565] 46% | Training loss: 0.6895183916275318
Epoch: 37 | Iteration number: [270/565] 47% | Training loss: 0.6894273270059514
Epoch: 37 | Iteration number: [280/565] 49% | Training loss: 0.6893304839730263
Epoch: 37 | Iteration number: [290/565] 51% | Training loss: 0.6892429477181928
Epoch: 37 | Iteration number: [300/565] 53% | Training loss: 0.6891445849339167
Epoch: 37 | Iteration number: [310/565] 54% | Training loss: 0.689059692428958
Epoch: 37 | Iteration number: [320/565] 56% | Training loss: 0.6889844147488475
Epoch: 37 | Iteration number: [330/565] 58% | Training loss: 0.6889140537290862
Epoch: 37 | Iteration number: [340/565] 60% | Training loss: 0.6888480517794104
Epoch: 37 | Iteration number: [350/565] 61% | Training loss: 0.6888052131448473
Epoch: 37 | Iteration number: [360/565] 63% | Training loss: 0.6887521785166528
Epoch: 37 | Iteration number: [370/565] 65% | Training loss: 0.6886951920148489
Epoch: 37 | Iteration number: [380/565] 67% | Training loss: 0.6886458556903036
Epoch: 37 | Iteration number: [390/565] 69% | Training loss: 0.688613861035078
Epoch: 37 | Iteration number: [400/565] 70% | Training loss: 0.6885762657225132
Epoch: 37 | Iteration number: [410/565] 72% | Training loss: 0.6885398113146061
Epoch: 37 | Iteration number: [420/565] 74% | Training loss: 0.6885013943626768
Epoch: 37 | Iteration number: [430/565] 76% | Training loss: 0.6884725536024847
Epoch: 37 | Iteration number: [440/565] 77% | Training loss: 0.6884280559691516
Epoch: 37 | Iteration number: [450/565] 79% | Training loss: 0.6883947939342923
Epoch: 37 | Iteration number: [460/565] 81% | Training loss: 0.6883593459492144
Epoch: 37 | Iteration number: [470/565] 83% | Training loss: 0.6883228485888623
Epoch: 37 | Iteration number: [480/565] 84% | Training loss: 0.6882931685696045
Epoch: 37 | Iteration number: [490/565] 86% | Training loss: 0.6882657806484067
Epoch: 37 | Iteration number: [500/565] 88% | Training loss: 0.688234945178032
Epoch: 37 | Iteration number: [510/565] 90% | Training loss: 0.6882029639739616
Epoch: 37 | Iteration number: [520/565] 92% | Training loss: 0.6881832872445767
Epoch: 37 | Iteration number: [530/565] 93% | Training loss: 0.6881586370603093
Epoch: 37 | Iteration number: [540/565] 95% | Training loss: 0.6881359211824558
Epoch: 37 | Iteration number: [550/565] 97% | Training loss: 0.6881143618713725
Epoch: 37 | Iteration number: [560/565] 99% | Training loss: 0.6880927736205714

 End of epoch: 37 | Train Loss: 0.6868622098348837 | Training Time: 89 

 End of epoch: 37 | Eval Loss: 0.6898658701351711 | Evaluating Time: 6 
Epoch: 38 | Iteration number: [10/565] 1% | Training loss: 0.7550997018814087
Epoch: 38 | Iteration number: [20/565] 3% | Training loss: 0.7209212243556976
Epoch: 38 | Iteration number: [30/565] 5% | Training loss: 0.7094997048377991
Epoch: 38 | Iteration number: [40/565] 7% | Training loss: 0.7039253026247024
Epoch: 38 | Iteration number: [50/565] 8% | Training loss: 0.7006259346008301
Epoch: 38 | Iteration number: [60/565] 10% | Training loss: 0.6983849813540777
Epoch: 38 | Iteration number: [70/565] 12% | Training loss: 0.6967328948634012
Epoch: 38 | Iteration number: [80/565] 14% | Training loss: 0.695542874187231
Epoch: 38 | Iteration number: [90/565] 15% | Training loss: 0.6945459749963548
Epoch: 38 | Iteration number: [100/565] 17% | Training loss: 0.6937325292825699
Epoch: 38 | Iteration number: [110/565] 19% | Training loss: 0.6931538267569108
Epoch: 38 | Iteration number: [120/565] 21% | Training loss: 0.6926012337207794
Epoch: 38 | Iteration number: [130/565] 23% | Training loss: 0.6921726180956914
Epoch: 38 | Iteration number: [140/565] 24% | Training loss: 0.6918084178652082
Epoch: 38 | Iteration number: [150/565] 26% | Training loss: 0.6914506165186564
Epoch: 38 | Iteration number: [160/565] 28% | Training loss: 0.6911496076732874
Epoch: 38 | Iteration number: [170/565] 30% | Training loss: 0.6908877944245058
Epoch: 38 | Iteration number: [180/565] 31% | Training loss: 0.6906754629479515
Epoch: 38 | Iteration number: [190/565] 33% | Training loss: 0.6904722935275027
Epoch: 38 | Iteration number: [200/565] 35% | Training loss: 0.6902670031785965
Epoch: 38 | Iteration number: [210/565] 37% | Training loss: 0.6900806270894551
Epoch: 38 | Iteration number: [220/565] 38% | Training loss: 0.6899343555623835
Epoch: 38 | Iteration number: [230/565] 40% | Training loss: 0.6898007462853971
Epoch: 38 | Iteration number: [240/565] 42% | Training loss: 0.6896750658750535
Epoch: 38 | Iteration number: [250/565] 44% | Training loss: 0.6895632843971252
Epoch: 38 | Iteration number: [260/565] 46% | Training loss: 0.6894643971553216
Epoch: 38 | Iteration number: [270/565] 47% | Training loss: 0.689347360752247
Epoch: 38 | Iteration number: [280/565] 49% | Training loss: 0.6892465204000473
Epoch: 38 | Iteration number: [290/565] 51% | Training loss: 0.6891783603306474
Epoch: 38 | Iteration number: [300/565] 53% | Training loss: 0.6890838046868643
Epoch: 38 | Iteration number: [310/565] 54% | Training loss: 0.6890084364721852
Epoch: 38 | Iteration number: [320/565] 56% | Training loss: 0.6889371568337083
Epoch: 38 | Iteration number: [330/565] 58% | Training loss: 0.6888846413655715
Epoch: 38 | Iteration number: [340/565] 60% | Training loss: 0.6888303826836979
Epoch: 38 | Iteration number: [350/565] 61% | Training loss: 0.6887743437290191
Epoch: 38 | Iteration number: [360/565] 63% | Training loss: 0.688724704252349
Epoch: 38 | Iteration number: [370/565] 65% | Training loss: 0.6886622804242212
Epoch: 38 | Iteration number: [380/565] 67% | Training loss: 0.6886304921225498
Epoch: 38 | Iteration number: [390/565] 69% | Training loss: 0.6885972275183752
Epoch: 38 | Iteration number: [400/565] 70% | Training loss: 0.688552673459053
Epoch: 38 | Iteration number: [410/565] 72% | Training loss: 0.6885111458417846
Epoch: 38 | Iteration number: [420/565] 74% | Training loss: 0.6884738077720006
Epoch: 38 | Iteration number: [430/565] 76% | Training loss: 0.6884404789569766
Epoch: 38 | Iteration number: [440/565] 77% | Training loss: 0.6883998322215947
Epoch: 38 | Iteration number: [450/565] 79% | Training loss: 0.6883642975489298
Epoch: 38 | Iteration number: [460/565] 81% | Training loss: 0.6883392411729564
Epoch: 38 | Iteration number: [470/565] 83% | Training loss: 0.6883077344995864
Epoch: 38 | Iteration number: [480/565] 84% | Training loss: 0.6882765055944522
Epoch: 38 | Iteration number: [490/565] 86% | Training loss: 0.6882397668702261
Epoch: 38 | Iteration number: [500/565] 88% | Training loss: 0.6882194530963898
Epoch: 38 | Iteration number: [510/565] 90% | Training loss: 0.6881930504359451
Epoch: 38 | Iteration number: [520/565] 92% | Training loss: 0.6881679447797628
Epoch: 38 | Iteration number: [530/565] 93% | Training loss: 0.6881402284469245
Epoch: 38 | Iteration number: [540/565] 95% | Training loss: 0.688123306521663
Epoch: 38 | Iteration number: [550/565] 97% | Training loss: 0.6881100651350889
Epoch: 38 | Iteration number: [560/565] 99% | Training loss: 0.6880855065371309

 End of epoch: 38 | Train Loss: 0.68686126048586 | Training Time: 88 

 End of epoch: 38 | Eval Loss: 0.6903705596923828 | Evaluating Time: 6 
Epoch: 39 | Iteration number: [10/565] 1% | Training loss: 0.7553857922554016
Epoch: 39 | Iteration number: [20/565] 3% | Training loss: 0.7209752112627029
Epoch: 39 | Iteration number: [30/565] 5% | Training loss: 0.7097245673338572
Epoch: 39 | Iteration number: [40/565] 7% | Training loss: 0.704116603732109
Epoch: 39 | Iteration number: [50/565] 8% | Training loss: 0.7006217277050019
Epoch: 39 | Iteration number: [60/565] 10% | Training loss: 0.6983004152774811
Epoch: 39 | Iteration number: [70/565] 12% | Training loss: 0.6965908706188202
Epoch: 39 | Iteration number: [80/565] 14% | Training loss: 0.695319727808237
Epoch: 39 | Iteration number: [90/565] 15% | Training loss: 0.6943396912680732
Epoch: 39 | Iteration number: [100/565] 17% | Training loss: 0.6935734874010087
Epoch: 39 | Iteration number: [110/565] 19% | Training loss: 0.6930139872160825
Epoch: 39 | Iteration number: [120/565] 21% | Training loss: 0.6924845958749454
Epoch: 39 | Iteration number: [130/565] 23% | Training loss: 0.6920648368505331
Epoch: 39 | Iteration number: [140/565] 24% | Training loss: 0.6916620237486703
Epoch: 39 | Iteration number: [150/565] 26% | Training loss: 0.6913370319207509
Epoch: 39 | Iteration number: [160/565] 28% | Training loss: 0.6910862375050784
Epoch: 39 | Iteration number: [170/565] 30% | Training loss: 0.6908744657740874
Epoch: 39 | Iteration number: [180/565] 31% | Training loss: 0.6906263185871973
Epoch: 39 | Iteration number: [190/565] 33% | Training loss: 0.6904332706802769
Epoch: 39 | Iteration number: [200/565] 35% | Training loss: 0.6902468699216843
Epoch: 39 | Iteration number: [210/565] 37% | Training loss: 0.6900677272251674
Epoch: 39 | Iteration number: [220/565] 38% | Training loss: 0.6899130032821135
Epoch: 39 | Iteration number: [230/565] 40% | Training loss: 0.68978096920511
Epoch: 39 | Iteration number: [240/565] 42% | Training loss: 0.6896680931250254
Epoch: 39 | Iteration number: [250/565] 44% | Training loss: 0.6895552558898925
Epoch: 39 | Iteration number: [260/565] 46% | Training loss: 0.6894326890890415
Epoch: 39 | Iteration number: [270/565] 47% | Training loss: 0.6893313856036575
Epoch: 39 | Iteration number: [280/565] 49% | Training loss: 0.6892558106354305
Epoch: 39 | Iteration number: [290/565] 51% | Training loss: 0.6891858252985724
Epoch: 39 | Iteration number: [300/565] 53% | Training loss: 0.6891068742672602
Epoch: 39 | Iteration number: [310/565] 54% | Training loss: 0.6890321058611716
Epoch: 39 | Iteration number: [320/565] 56% | Training loss: 0.6889621069654822
Epoch: 39 | Iteration number: [330/565] 58% | Training loss: 0.6888895312945048
Epoch: 39 | Iteration number: [340/565] 60% | Training loss: 0.6888201587340411
Epoch: 39 | Iteration number: [350/565] 61% | Training loss: 0.6887712735789163
Epoch: 39 | Iteration number: [360/565] 63% | Training loss: 0.6887140651543935
Epoch: 39 | Iteration number: [370/565] 65% | Training loss: 0.6886706621260257
Epoch: 39 | Iteration number: [380/565] 67% | Training loss: 0.6886081190485703
Epoch: 39 | Iteration number: [390/565] 69% | Training loss: 0.6885637828936944
Epoch: 39 | Iteration number: [400/565] 70% | Training loss: 0.688530969619751
Epoch: 39 | Iteration number: [410/565] 72% | Training loss: 0.6884882867336273
Epoch: 39 | Iteration number: [420/565] 74% | Training loss: 0.6884568519535519
Epoch: 39 | Iteration number: [430/565] 76% | Training loss: 0.6884174446726954
Epoch: 39 | Iteration number: [440/565] 77% | Training loss: 0.6883755072951316
Epoch: 39 | Iteration number: [450/565] 79% | Training loss: 0.6883479105101691
Epoch: 39 | Iteration number: [460/565] 81% | Training loss: 0.6883167945820352
Epoch: 39 | Iteration number: [470/565] 83% | Training loss: 0.6882947394188415
Epoch: 39 | Iteration number: [480/565] 84% | Training loss: 0.6882659607877334
Epoch: 39 | Iteration number: [490/565] 86% | Training loss: 0.6882383981529547
Epoch: 39 | Iteration number: [500/565] 88% | Training loss: 0.6882161452770234
Epoch: 39 | Iteration number: [510/565] 90% | Training loss: 0.6881838446738673
Epoch: 39 | Iteration number: [520/565] 92% | Training loss: 0.6881604865193367
Epoch: 39 | Iteration number: [530/565] 93% | Training loss: 0.6881419056991361
Epoch: 39 | Iteration number: [540/565] 95% | Training loss: 0.6881166689925724
Epoch: 39 | Iteration number: [550/565] 97% | Training loss: 0.6880953698808496
Epoch: 39 | Iteration number: [560/565] 99% | Training loss: 0.6880737715533801

 End of epoch: 39 | Train Loss: 0.6868513415345049 | Training Time: 88 

 End of epoch: 39 | Eval Loss: 0.6899417127881732 | Evaluating Time: 6 
Epoch: 40 | Iteration number: [10/565] 1% | Training loss: 0.7554974257946014
Epoch: 40 | Iteration number: [20/565] 3% | Training loss: 0.7209731847047806
Epoch: 40 | Iteration number: [30/565] 5% | Training loss: 0.7095726211865743
Epoch: 40 | Iteration number: [40/565] 7% | Training loss: 0.7039772629737854
Epoch: 40 | Iteration number: [50/565] 8% | Training loss: 0.7005369365215302
Epoch: 40 | Iteration number: [60/565] 10% | Training loss: 0.6982196946938832
Epoch: 40 | Iteration number: [70/565] 12% | Training loss: 0.6966354412691934
Epoch: 40 | Iteration number: [80/565] 14% | Training loss: 0.6954517506062985
Epoch: 40 | Iteration number: [90/565] 15% | Training loss: 0.6944599588712056
Epoch: 40 | Iteration number: [100/565] 17% | Training loss: 0.6937021481990814
Epoch: 40 | Iteration number: [110/565] 19% | Training loss: 0.6930688381195068
Epoch: 40 | Iteration number: [120/565] 21% | Training loss: 0.6925277640422185
Epoch: 40 | Iteration number: [130/565] 23% | Training loss: 0.6920651500041668
Epoch: 40 | Iteration number: [140/565] 24% | Training loss: 0.6917071572371891
Epoch: 40 | Iteration number: [150/565] 26% | Training loss: 0.6913851944605509
Epoch: 40 | Iteration number: [160/565] 28% | Training loss: 0.6910892874002457
Epoch: 40 | Iteration number: [170/565] 30% | Training loss: 0.6908600298797383
Epoch: 40 | Iteration number: [180/565] 31% | Training loss: 0.6906532903512319
Epoch: 40 | Iteration number: [190/565] 33% | Training loss: 0.6904693245887756
Epoch: 40 | Iteration number: [200/565] 35% | Training loss: 0.6902726569771767
Epoch: 40 | Iteration number: [210/565] 37% | Training loss: 0.6901149386451357
Epoch: 40 | Iteration number: [220/565] 38% | Training loss: 0.6899704957550222
Epoch: 40 | Iteration number: [230/565] 40% | Training loss: 0.6898585801539214
Epoch: 40 | Iteration number: [240/565] 42% | Training loss: 0.6897247066100438
Epoch: 40 | Iteration number: [250/565] 44% | Training loss: 0.6896279201507568
Epoch: 40 | Iteration number: [260/565] 46% | Training loss: 0.6895106558616345
Epoch: 40 | Iteration number: [270/565] 47% | Training loss: 0.6894266000500432
Epoch: 40 | Iteration number: [280/565] 49% | Training loss: 0.6893329222287451
Epoch: 40 | Iteration number: [290/565] 51% | Training loss: 0.6892405384573443
Epoch: 40 | Iteration number: [300/565] 53% | Training loss: 0.6891633448998133
Epoch: 40 | Iteration number: [310/565] 54% | Training loss: 0.68909338885738
Epoch: 40 | Iteration number: [320/565] 56% | Training loss: 0.6890328105539083
Epoch: 40 | Iteration number: [330/565] 58% | Training loss: 0.6889488953532594
Epoch: 40 | Iteration number: [340/565] 60% | Training loss: 0.6888968779760248
Epoch: 40 | Iteration number: [350/565] 61% | Training loss: 0.6888352525234223
Epoch: 40 | Iteration number: [360/565] 63% | Training loss: 0.6887637433078554
Epoch: 40 | Iteration number: [370/565] 65% | Training loss: 0.6887057740946074
Epoch: 40 | Iteration number: [380/565] 67% | Training loss: 0.6886619591399243
Epoch: 40 | Iteration number: [390/565] 69% | Training loss: 0.688615565880751
Epoch: 40 | Iteration number: [400/565] 70% | Training loss: 0.688567713946104
Epoch: 40 | Iteration number: [410/565] 72% | Training loss: 0.6885325511781181
Epoch: 40 | Iteration number: [420/565] 74% | Training loss: 0.6884926463876452
Epoch: 40 | Iteration number: [430/565] 76% | Training loss: 0.688453726851663
Epoch: 40 | Iteration number: [440/565] 77% | Training loss: 0.6884112593802538
Epoch: 40 | Iteration number: [450/565] 79% | Training loss: 0.6883678001827663
Epoch: 40 | Iteration number: [460/565] 81% | Training loss: 0.6883330846610276
Epoch: 40 | Iteration number: [470/565] 83% | Training loss: 0.6882962107658386
Epoch: 40 | Iteration number: [480/565] 84% | Training loss: 0.6882620143393675
Epoch: 40 | Iteration number: [490/565] 86% | Training loss: 0.6882424294948578
Epoch: 40 | Iteration number: [500/565] 88% | Training loss: 0.6882196021080017
Epoch: 40 | Iteration number: [510/565] 90% | Training loss: 0.6881950477759043
Epoch: 40 | Iteration number: [520/565] 92% | Training loss: 0.6881754090006534
Epoch: 40 | Iteration number: [530/565] 93% | Training loss: 0.6881515021594066
Epoch: 40 | Iteration number: [540/565] 95% | Training loss: 0.6881315065754785
Epoch: 40 | Iteration number: [550/565] 97% | Training loss: 0.6881110774387013
Epoch: 40 | Iteration number: [560/565] 99% | Training loss: 0.6880858798112188

 End of epoch: 40 | Train Loss: 0.6868591359231324 | Training Time: 88 

 End of epoch: 40 | Eval Loss: 0.6901902045522418 | Evaluating Time: 5 
Epoch: 41 | Iteration number: [10/565] 1% | Training loss: 0.756047922372818
Epoch: 41 | Iteration number: [20/565] 3% | Training loss: 0.7214294016361237
Epoch: 41 | Iteration number: [30/565] 5% | Training loss: 0.7098159333070119
Epoch: 41 | Iteration number: [40/565] 7% | Training loss: 0.7041683524847031
Epoch: 41 | Iteration number: [50/565] 8% | Training loss: 0.7006975722312927
Epoch: 41 | Iteration number: [60/565] 10% | Training loss: 0.6983350137869517
Epoch: 41 | Iteration number: [70/565] 12% | Training loss: 0.6967091952051435
Epoch: 41 | Iteration number: [80/565] 14% | Training loss: 0.6954759590327739
Epoch: 41 | Iteration number: [90/565] 15% | Training loss: 0.6945589363574982
Epoch: 41 | Iteration number: [100/565] 17% | Training loss: 0.6937987011671066
Epoch: 41 | Iteration number: [110/565] 19% | Training loss: 0.6931527961384166
Epoch: 41 | Iteration number: [120/565] 21% | Training loss: 0.6926707024375598
Epoch: 41 | Iteration number: [130/565] 23% | Training loss: 0.6922414270731119
Epoch: 41 | Iteration number: [140/565] 24% | Training loss: 0.6918497494288853
Epoch: 41 | Iteration number: [150/565] 26% | Training loss: 0.6915022420883179
Epoch: 41 | Iteration number: [160/565] 28% | Training loss: 0.6912074130028486
Epoch: 41 | Iteration number: [170/565] 30% | Training loss: 0.6909331556628732
Epoch: 41 | Iteration number: [180/565] 31% | Training loss: 0.6907145397530662
Epoch: 41 | Iteration number: [190/565] 33% | Training loss: 0.6905242079182675
Epoch: 41 | Iteration number: [200/565] 35% | Training loss: 0.6903330737352371
Epoch: 41 | Iteration number: [210/565] 37% | Training loss: 0.6901572627680642
Epoch: 41 | Iteration number: [220/565] 38% | Training loss: 0.690027988227931
Epoch: 41 | Iteration number: [230/565] 40% | Training loss: 0.6898906331995259
Epoch: 41 | Iteration number: [240/565] 42% | Training loss: 0.6897741099198659
Epoch: 41 | Iteration number: [250/565] 44% | Training loss: 0.6896839873790741
Epoch: 41 | Iteration number: [260/565] 46% | Training loss: 0.689576850946133
Epoch: 41 | Iteration number: [270/565] 47% | Training loss: 0.6894779750594386
Epoch: 41 | Iteration number: [280/565] 49% | Training loss: 0.6893839929785047
Epoch: 41 | Iteration number: [290/565] 51% | Training loss: 0.6892812200661363
Epoch: 41 | Iteration number: [300/565] 53% | Training loss: 0.6892010658979416
Epoch: 41 | Iteration number: [310/565] 54% | Training loss: 0.6891323683723327
Epoch: 41 | Iteration number: [320/565] 56% | Training loss: 0.6890624320134521
Epoch: 41 | Iteration number: [330/565] 58% | Training loss: 0.6889982321045616
Epoch: 41 | Iteration number: [340/565] 60% | Training loss: 0.6889344900846481
Epoch: 41 | Iteration number: [350/565] 61% | Training loss: 0.6888728419372013
Epoch: 41 | Iteration number: [360/565] 63% | Training loss: 0.6888174517287149
Epoch: 41 | Iteration number: [370/565] 65% | Training loss: 0.6887621378576433
Epoch: 41 | Iteration number: [380/565] 67% | Training loss: 0.6887054659818348
Epoch: 41 | Iteration number: [390/565] 69% | Training loss: 0.6886447891210898
Epoch: 41 | Iteration number: [400/565] 70% | Training loss: 0.6885933803021907
Epoch: 41 | Iteration number: [410/565] 72% | Training loss: 0.6885508780072375
Epoch: 41 | Iteration number: [420/565] 74% | Training loss: 0.6885035828465507
Epoch: 41 | Iteration number: [430/565] 76% | Training loss: 0.6884626173695853
Epoch: 41 | Iteration number: [440/565] 77% | Training loss: 0.6884356771003116
Epoch: 41 | Iteration number: [450/565] 79% | Training loss: 0.6884057989385393
Epoch: 41 | Iteration number: [460/565] 81% | Training loss: 0.688370253469633
Epoch: 41 | Iteration number: [470/565] 83% | Training loss: 0.6883372148300739
Epoch: 41 | Iteration number: [480/565] 84% | Training loss: 0.6882987048476934
Epoch: 41 | Iteration number: [490/565] 86% | Training loss: 0.6882699620967009
Epoch: 41 | Iteration number: [500/565] 88% | Training loss: 0.6882428578138351
Epoch: 41 | Iteration number: [510/565] 90% | Training loss: 0.6882133099378324
Epoch: 41 | Iteration number: [520/565] 92% | Training loss: 0.6881882218214181
Epoch: 41 | Iteration number: [530/565] 93% | Training loss: 0.6881541310616259
Epoch: 41 | Iteration number: [540/565] 95% | Training loss: 0.688127828306622
Epoch: 41 | Iteration number: [550/565] 97% | Training loss: 0.6881090414524078
Epoch: 41 | Iteration number: [560/565] 99% | Training loss: 0.6880929962864943

 End of epoch: 41 | Train Loss: 0.6868677136117378 | Training Time: 90 

 End of epoch: 41 | Eval Loss: 0.6903856311525617 | Evaluating Time: 6 
Epoch: 42 | Iteration number: [10/565] 1% | Training loss: 0.7554167568683624
Epoch: 42 | Iteration number: [20/565] 3% | Training loss: 0.7211436361074448
Epoch: 42 | Iteration number: [30/565] 5% | Training loss: 0.7097078005472819
Epoch: 42 | Iteration number: [40/565] 7% | Training loss: 0.7039951741695404
Epoch: 42 | Iteration number: [50/565] 8% | Training loss: 0.7005356848239899
Epoch: 42 | Iteration number: [60/565] 10% | Training loss: 0.6983285307884216
Epoch: 42 | Iteration number: [70/565] 12% | Training loss: 0.6967026940413884
Epoch: 42 | Iteration number: [80/565] 14% | Training loss: 0.6954779624938965
Epoch: 42 | Iteration number: [90/565] 15% | Training loss: 0.6945368634329901
Epoch: 42 | Iteration number: [100/565] 17% | Training loss: 0.6938051092624664
Epoch: 42 | Iteration number: [110/565] 19% | Training loss: 0.6931594409725883
Epoch: 42 | Iteration number: [120/565] 21% | Training loss: 0.6926269337534905
Epoch: 42 | Iteration number: [130/565] 23% | Training loss: 0.6922206218426045
Epoch: 42 | Iteration number: [140/565] 24% | Training loss: 0.691823463354792
Epoch: 42 | Iteration number: [150/565] 26% | Training loss: 0.6915023493766784
Epoch: 42 | Iteration number: [160/565] 28% | Training loss: 0.6912139691412449
Epoch: 42 | Iteration number: [170/565] 30% | Training loss: 0.6909615043331595
Epoch: 42 | Iteration number: [180/565] 31% | Training loss: 0.6907294521729151
Epoch: 42 | Iteration number: [190/565] 33% | Training loss: 0.6905177370498055
Epoch: 42 | Iteration number: [200/565] 35% | Training loss: 0.6903498581051827
Epoch: 42 | Iteration number: [210/565] 37% | Training loss: 0.6901968385492052
Epoch: 42 | Iteration number: [220/565] 38% | Training loss: 0.6900478354909203
Epoch: 42 | Iteration number: [230/565] 40% | Training loss: 0.6899141495642455
Epoch: 42 | Iteration number: [240/565] 42% | Training loss: 0.6897687827547391
Epoch: 42 | Iteration number: [250/565] 44% | Training loss: 0.689666356086731
Epoch: 42 | Iteration number: [260/565] 46% | Training loss: 0.6895392842017687
Epoch: 42 | Iteration number: [270/565] 47% | Training loss: 0.6894443061616685
Epoch: 42 | Iteration number: [280/565] 49% | Training loss: 0.6893478523407663
Epoch: 42 | Iteration number: [290/565] 51% | Training loss: 0.6892605097129427
Epoch: 42 | Iteration number: [300/565] 53% | Training loss: 0.6891751845677694
Epoch: 42 | Iteration number: [310/565] 54% | Training loss: 0.6891054330333587
Epoch: 42 | Iteration number: [320/565] 56% | Training loss: 0.6890421589836478
Epoch: 42 | Iteration number: [330/565] 58% | Training loss: 0.6889814606218627
Epoch: 42 | Iteration number: [340/565] 60% | Training loss: 0.6889212774879793
Epoch: 42 | Iteration number: [350/565] 61% | Training loss: 0.6888549440247672
Epoch: 42 | Iteration number: [360/565] 63% | Training loss: 0.6888061794969771
Epoch: 42 | Iteration number: [370/565] 65% | Training loss: 0.6887554033382519
Epoch: 42 | Iteration number: [380/565] 67% | Training loss: 0.688694314737069
Epoch: 42 | Iteration number: [390/565] 69% | Training loss: 0.6886434856133583
Epoch: 42 | Iteration number: [400/565] 70% | Training loss: 0.6885892952978611
Epoch: 42 | Iteration number: [410/565] 72% | Training loss: 0.6885406488325537
Epoch: 42 | Iteration number: [420/565] 74% | Training loss: 0.6884939054648082
Epoch: 42 | Iteration number: [430/565] 76% | Training loss: 0.6884554607923641
Epoch: 42 | Iteration number: [440/565] 77% | Training loss: 0.6884287216446616
Epoch: 42 | Iteration number: [450/565] 79% | Training loss: 0.6883978674146864
Epoch: 42 | Iteration number: [460/565] 81% | Training loss: 0.6883602655452231
Epoch: 42 | Iteration number: [470/565] 83% | Training loss: 0.6883212341907177
Epoch: 42 | Iteration number: [480/565] 84% | Training loss: 0.6882862262427807
Epoch: 42 | Iteration number: [490/565] 86% | Training loss: 0.6882565349948649
Epoch: 42 | Iteration number: [500/565] 88% | Training loss: 0.6882278906106949
Epoch: 42 | Iteration number: [510/565] 90% | Training loss: 0.6882094599452673
Epoch: 42 | Iteration number: [520/565] 92% | Training loss: 0.6881852782689608
Epoch: 42 | Iteration number: [530/565] 93% | Training loss: 0.6881479140722526
Epoch: 42 | Iteration number: [540/565] 95% | Training loss: 0.6881260019761545
Epoch: 42 | Iteration number: [550/565] 97% | Training loss: 0.6880918424779718
Epoch: 42 | Iteration number: [560/565] 99% | Training loss: 0.688066562797342

 End of epoch: 42 | Train Loss: 0.6868436377660363 | Training Time: 89 

 End of epoch: 42 | Eval Loss: 0.689922741481236 | Evaluating Time: 6 
Epoch: 43 | Iteration number: [10/565] 1% | Training loss: 0.7555841267108917
Epoch: 43 | Iteration number: [20/565] 3% | Training loss: 0.7211166232824325
Epoch: 43 | Iteration number: [30/565] 5% | Training loss: 0.7097220083077749
Epoch: 43 | Iteration number: [40/565] 7% | Training loss: 0.7037835851311683
Epoch: 43 | Iteration number: [50/565] 8% | Training loss: 0.7004761004447937
Epoch: 43 | Iteration number: [60/565] 10% | Training loss: 0.6982241233189901
Epoch: 43 | Iteration number: [70/565] 12% | Training loss: 0.696596337216241
Epoch: 43 | Iteration number: [80/565] 14% | Training loss: 0.6954095557332038
Epoch: 43 | Iteration number: [90/565] 15% | Training loss: 0.6944415642155541
Epoch: 43 | Iteration number: [100/565] 17% | Training loss: 0.6936494582891464
Epoch: 43 | Iteration number: [110/565] 19% | Training loss: 0.6930490428751165
Epoch: 43 | Iteration number: [120/565] 21% | Training loss: 0.692529001335303
Epoch: 43 | Iteration number: [130/565] 23% | Training loss: 0.6920960187911988
Epoch: 43 | Iteration number: [140/565] 24% | Training loss: 0.691700501527105
Epoch: 43 | Iteration number: [150/565] 26% | Training loss: 0.6914012050628662
Epoch: 43 | Iteration number: [160/565] 28% | Training loss: 0.6911257322877645
Epoch: 43 | Iteration number: [170/565] 30% | Training loss: 0.6908674348803128
Epoch: 43 | Iteration number: [180/565] 31% | Training loss: 0.6906502220365737
Epoch: 43 | Iteration number: [190/565] 33% | Training loss: 0.6904452327050661
Epoch: 43 | Iteration number: [200/565] 35% | Training loss: 0.690246756374836
Epoch: 43 | Iteration number: [210/565] 37% | Training loss: 0.6900806918030693
Epoch: 43 | Iteration number: [220/565] 38% | Training loss: 0.6899385062131015
Epoch: 43 | Iteration number: [230/565] 40% | Training loss: 0.6897789418697358
Epoch: 43 | Iteration number: [240/565] 42% | Training loss: 0.6896508604288101
Epoch: 43 | Iteration number: [250/565] 44% | Training loss: 0.6895350399017334
Epoch: 43 | Iteration number: [260/565] 46% | Training loss: 0.6894322963861319
Epoch: 43 | Iteration number: [270/565] 47% | Training loss: 0.6893571725598088
Epoch: 43 | Iteration number: [280/565] 49% | Training loss: 0.6892762820635523
Epoch: 43 | Iteration number: [290/565] 51% | Training loss: 0.6892064904344493
Epoch: 43 | Iteration number: [300/565] 53% | Training loss: 0.6891295892000199
Epoch: 43 | Iteration number: [310/565] 54% | Training loss: 0.6890566695121026
Epoch: 43 | Iteration number: [320/565] 56% | Training loss: 0.6889919638633728
Epoch: 43 | Iteration number: [330/565] 58% | Training loss: 0.6889243671388338
Epoch: 43 | Iteration number: [340/565] 60% | Training loss: 0.6888618632274516
Epoch: 43 | Iteration number: [350/565] 61% | Training loss: 0.6887978374958038
Epoch: 43 | Iteration number: [360/565] 63% | Training loss: 0.688755597670873
Epoch: 43 | Iteration number: [370/565] 65% | Training loss: 0.6887153938009932
Epoch: 43 | Iteration number: [380/565] 67% | Training loss: 0.6886509031057357
Epoch: 43 | Iteration number: [390/565] 69% | Training loss: 0.6885997753876906
Epoch: 43 | Iteration number: [400/565] 70% | Training loss: 0.6885557715594769
Epoch: 43 | Iteration number: [410/565] 72% | Training loss: 0.6885080299726347
Epoch: 43 | Iteration number: [420/565] 74% | Training loss: 0.6884693626846586
Epoch: 43 | Iteration number: [430/565] 76% | Training loss: 0.6884349660817967
Epoch: 43 | Iteration number: [440/565] 77% | Training loss: 0.6884047002954916
Epoch: 43 | Iteration number: [450/565] 79% | Training loss: 0.6883593251970079
Epoch: 43 | Iteration number: [460/565] 81% | Training loss: 0.6883169724889423
Epoch: 43 | Iteration number: [470/565] 83% | Training loss: 0.6882838863007565
Epoch: 43 | Iteration number: [480/565] 84% | Training loss: 0.6882528154800336
Epoch: 43 | Iteration number: [490/565] 86% | Training loss: 0.6882303392400547
Epoch: 43 | Iteration number: [500/565] 88% | Training loss: 0.6882017084360122
Epoch: 43 | Iteration number: [510/565] 90% | Training loss: 0.6881771757322199
Epoch: 43 | Iteration number: [520/565] 92% | Training loss: 0.6881500742756403
Epoch: 43 | Iteration number: [530/565] 93% | Training loss: 0.6881333699766196
Epoch: 43 | Iteration number: [540/565] 95% | Training loss: 0.688104486796591
Epoch: 43 | Iteration number: [550/565] 97% | Training loss: 0.6880738815394315
Epoch: 43 | Iteration number: [560/565] 99% | Training loss: 0.6880576295512063

 End of epoch: 43 | Train Loss: 0.6868300187904223 | Training Time: 89 

 End of epoch: 43 | Eval Loss: 0.6899993930544172 | Evaluating Time: 6 
Epoch: 44 | Iteration number: [10/565] 1% | Training loss: 0.7563236594200134
Epoch: 44 | Iteration number: [20/565] 3% | Training loss: 0.7216030418872833
Epoch: 44 | Iteration number: [30/565] 5% | Training loss: 0.7097105979919434
Epoch: 44 | Iteration number: [40/565] 7% | Training loss: 0.703957237303257
Epoch: 44 | Iteration number: [50/565] 8% | Training loss: 0.7005434155464172
Epoch: 44 | Iteration number: [60/565] 10% | Training loss: 0.6982808103164037
Epoch: 44 | Iteration number: [70/565] 12% | Training loss: 0.6966823271342686
Epoch: 44 | Iteration number: [80/565] 14% | Training loss: 0.6953619249165058
Epoch: 44 | Iteration number: [90/565] 15% | Training loss: 0.6944125321176317
Epoch: 44 | Iteration number: [100/565] 17% | Training loss: 0.693633189201355
Epoch: 44 | Iteration number: [110/565] 19% | Training loss: 0.6930279114029624
Epoch: 44 | Iteration number: [120/565] 21% | Training loss: 0.6925072247783343
Epoch: 44 | Iteration number: [130/565] 23% | Training loss: 0.6920607686042786
Epoch: 44 | Iteration number: [140/565] 24% | Training loss: 0.6917084868465151
Epoch: 44 | Iteration number: [150/565] 26% | Training loss: 0.6913633998235067
Epoch: 44 | Iteration number: [160/565] 28% | Training loss: 0.6910930395126342
Epoch: 44 | Iteration number: [170/565] 30% | Training loss: 0.6908494570676018
Epoch: 44 | Iteration number: [180/565] 31% | Training loss: 0.6906199819511838
Epoch: 44 | Iteration number: [190/565] 33% | Training loss: 0.6904104706488158
Epoch: 44 | Iteration number: [200/565] 35% | Training loss: 0.6902418306469917
Epoch: 44 | Iteration number: [210/565] 37% | Training loss: 0.6901004334290822
Epoch: 44 | Iteration number: [220/565] 38% | Training loss: 0.6899565908041867
Epoch: 44 | Iteration number: [230/565] 40% | Training loss: 0.6898219240748364
Epoch: 44 | Iteration number: [240/565] 42% | Training loss: 0.689700311422348
Epoch: 44 | Iteration number: [250/565] 44% | Training loss: 0.6895858614444733
Epoch: 44 | Iteration number: [260/565] 46% | Training loss: 0.6894699197549087
Epoch: 44 | Iteration number: [270/565] 47% | Training loss: 0.6893661699913166
Epoch: 44 | Iteration number: [280/565] 49% | Training loss: 0.6892808358584132
Epoch: 44 | Iteration number: [290/565] 51% | Training loss: 0.6892057040642048
Epoch: 44 | Iteration number: [300/565] 53% | Training loss: 0.6891248993078868
Epoch: 44 | Iteration number: [310/565] 54% | Training loss: 0.6890628807006344
Epoch: 44 | Iteration number: [320/565] 56% | Training loss: 0.6889973782002926
Epoch: 44 | Iteration number: [330/565] 58% | Training loss: 0.6889319454178665
Epoch: 44 | Iteration number: [340/565] 60% | Training loss: 0.6888645661227843
Epoch: 44 | Iteration number: [350/565] 61% | Training loss: 0.6888137119156974
Epoch: 44 | Iteration number: [360/565] 63% | Training loss: 0.6887590769264433
Epoch: 44 | Iteration number: [370/565] 65% | Training loss: 0.6887071098830249
Epoch: 44 | Iteration number: [380/565] 67% | Training loss: 0.6886526733636856
Epoch: 44 | Iteration number: [390/565] 69% | Training loss: 0.6886085383402996
Epoch: 44 | Iteration number: [400/565] 70% | Training loss: 0.6885583905875683
Epoch: 44 | Iteration number: [410/565] 72% | Training loss: 0.6885233489478507
Epoch: 44 | Iteration number: [420/565] 74% | Training loss: 0.6884825541859582
Epoch: 44 | Iteration number: [430/565] 76% | Training loss: 0.6884428582912268
Epoch: 44 | Iteration number: [440/565] 77% | Training loss: 0.6884054070169275
Epoch: 44 | Iteration number: [450/565] 79% | Training loss: 0.6883667323324415
Epoch: 44 | Iteration number: [460/565] 81% | Training loss: 0.6883254096559857
Epoch: 44 | Iteration number: [470/565] 83% | Training loss: 0.6883007341242852
Epoch: 44 | Iteration number: [480/565] 84% | Training loss: 0.688264928261439
Epoch: 44 | Iteration number: [490/565] 86% | Training loss: 0.6882386981224528
Epoch: 44 | Iteration number: [500/565] 88% | Training loss: 0.6882114530801773
Epoch: 44 | Iteration number: [510/565] 90% | Training loss: 0.6881716161381964
Epoch: 44 | Iteration number: [520/565] 92% | Training loss: 0.6881334814887781
Epoch: 44 | Iteration number: [530/565] 93% | Training loss: 0.6881100553386617
Epoch: 44 | Iteration number: [540/565] 95% | Training loss: 0.688093747584908
Epoch: 44 | Iteration number: [550/565] 97% | Training loss: 0.6880760452964089
Epoch: 44 | Iteration number: [560/565] 99% | Training loss: 0.6880521888179438

 End of epoch: 44 | Train Loss: 0.6868276852422056 | Training Time: 90 

 End of epoch: 44 | Eval Loss: 0.6905103836740766 | Evaluating Time: 6 
Epoch: 45 | Iteration number: [10/565] 1% | Training loss: 0.7552633225917816
Epoch: 45 | Iteration number: [20/565] 3% | Training loss: 0.7209646165370941
Epoch: 45 | Iteration number: [30/565] 5% | Training loss: 0.709678441286087
Epoch: 45 | Iteration number: [40/565] 7% | Training loss: 0.7039974272251129
Epoch: 45 | Iteration number: [50/565] 8% | Training loss: 0.7005579257011414
Epoch: 45 | Iteration number: [60/565] 10% | Training loss: 0.6983430514732997
Epoch: 45 | Iteration number: [70/565] 12% | Training loss: 0.6967008394854409
Epoch: 45 | Iteration number: [80/565] 14% | Training loss: 0.6954798541963101
Epoch: 45 | Iteration number: [90/565] 15% | Training loss: 0.6945004416836633
Epoch: 45 | Iteration number: [100/565] 17% | Training loss: 0.6936988240480423
Epoch: 45 | Iteration number: [110/565] 19% | Training loss: 0.6930425215851177
Epoch: 45 | Iteration number: [120/565] 21% | Training loss: 0.6924758061766625
Epoch: 45 | Iteration number: [130/565] 23% | Training loss: 0.6920669344755319
Epoch: 45 | Iteration number: [140/565] 24% | Training loss: 0.6916914982455117
Epoch: 45 | Iteration number: [150/565] 26% | Training loss: 0.6913226155440012
Epoch: 45 | Iteration number: [160/565] 28% | Training loss: 0.691031314432621
Epoch: 45 | Iteration number: [170/565] 30% | Training loss: 0.6907816574854009
Epoch: 45 | Iteration number: [180/565] 31% | Training loss: 0.6905811829699411
Epoch: 45 | Iteration number: [190/565] 33% | Training loss: 0.6904103768499275
Epoch: 45 | Iteration number: [200/565] 35% | Training loss: 0.6902396953105927
Epoch: 45 | Iteration number: [210/565] 37% | Training loss: 0.6900787239982968
Epoch: 45 | Iteration number: [220/565] 38% | Training loss: 0.689919914169745
Epoch: 45 | Iteration number: [230/565] 40% | Training loss: 0.6897878017114556
Epoch: 45 | Iteration number: [240/565] 42% | Training loss: 0.6896652815242609
Epoch: 45 | Iteration number: [250/565] 44% | Training loss: 0.6895582330226898
Epoch: 45 | Iteration number: [260/565] 46% | Training loss: 0.6894512032087032
Epoch: 45 | Iteration number: [270/565] 47% | Training loss: 0.6893567692350459
Epoch: 45 | Iteration number: [280/565] 49% | Training loss: 0.6892776218908173
Epoch: 45 | Iteration number: [290/565] 51% | Training loss: 0.6891919487509234
Epoch: 45 | Iteration number: [300/565] 53% | Training loss: 0.6891082672278086
Epoch: 45 | Iteration number: [310/565] 54% | Training loss: 0.6890331233701398
Epoch: 45 | Iteration number: [320/565] 56% | Training loss: 0.6889701465144753
Epoch: 45 | Iteration number: [330/565] 58% | Training loss: 0.6889142097848835
Epoch: 45 | Iteration number: [340/565] 60% | Training loss: 0.6888616554877337
Epoch: 45 | Iteration number: [350/565] 61% | Training loss: 0.6888034665584564
Epoch: 45 | Iteration number: [360/565] 63% | Training loss: 0.688754374285539
Epoch: 45 | Iteration number: [370/565] 65% | Training loss: 0.6886989562898069
Epoch: 45 | Iteration number: [380/565] 67% | Training loss: 0.6886452508600135
Epoch: 45 | Iteration number: [390/565] 69% | Training loss: 0.688603163529665
Epoch: 45 | Iteration number: [400/565] 70% | Training loss: 0.688558424860239
Epoch: 45 | Iteration number: [410/565] 72% | Training loss: 0.6885202192678684
Epoch: 45 | Iteration number: [420/565] 74% | Training loss: 0.6884818440391904
Epoch: 45 | Iteration number: [430/565] 76% | Training loss: 0.6884422324424566
Epoch: 45 | Iteration number: [440/565] 77% | Training loss: 0.688406668197025
Epoch: 45 | Iteration number: [450/565] 79% | Training loss: 0.6883637844191657
Epoch: 45 | Iteration number: [460/565] 81% | Training loss: 0.6883315252221149
Epoch: 45 | Iteration number: [470/565] 83% | Training loss: 0.6883111067274783
Epoch: 45 | Iteration number: [480/565] 84% | Training loss: 0.6882883299142122
Epoch: 45 | Iteration number: [490/565] 86% | Training loss: 0.6882592810659992
Epoch: 45 | Iteration number: [500/565] 88% | Training loss: 0.6882343631982804
Epoch: 45 | Iteration number: [510/565] 90% | Training loss: 0.6882077485907312
Epoch: 45 | Iteration number: [520/565] 92% | Training loss: 0.688175922861466
Epoch: 45 | Iteration number: [530/565] 93% | Training loss: 0.6881494043008336
Epoch: 45 | Iteration number: [540/565] 95% | Training loss: 0.6881184756755829
Epoch: 45 | Iteration number: [550/565] 97% | Training loss: 0.6880954251506112
Epoch: 45 | Iteration number: [560/565] 99% | Training loss: 0.6880753863070692

 End of epoch: 45 | Train Loss: 0.6868535216930693 | Training Time: 90 

 End of epoch: 45 | Eval Loss: 0.6899262326104301 | Evaluating Time: 6 
Epoch: 46 | Iteration number: [10/565] 1% | Training loss: 0.7557814359664917
Epoch: 46 | Iteration number: [20/565] 3% | Training loss: 0.721264100074768
Epoch: 46 | Iteration number: [30/565] 5% | Training loss: 0.7098594605922699
Epoch: 46 | Iteration number: [40/565] 7% | Training loss: 0.7040557086467742
Epoch: 46 | Iteration number: [50/565] 8% | Training loss: 0.70051025390625
Epoch: 46 | Iteration number: [60/565] 10% | Training loss: 0.6982014040152232
Epoch: 46 | Iteration number: [70/565] 12% | Training loss: 0.6965589668069567
Epoch: 46 | Iteration number: [80/565] 14% | Training loss: 0.6953337088227272
Epoch: 46 | Iteration number: [90/565] 15% | Training loss: 0.6943655636575486
Epoch: 46 | Iteration number: [100/565] 17% | Training loss: 0.6935994744300842
Epoch: 46 | Iteration number: [110/565] 19% | Training loss: 0.693003572659059
Epoch: 46 | Iteration number: [120/565] 21% | Training loss: 0.6925211017330487
Epoch: 46 | Iteration number: [130/565] 23% | Training loss: 0.6920842555853036
Epoch: 46 | Iteration number: [140/565] 24% | Training loss: 0.6917146112237658
Epoch: 46 | Iteration number: [150/565] 26% | Training loss: 0.6913811552524567
Epoch: 46 | Iteration number: [160/565] 28% | Training loss: 0.6911069002002478
Epoch: 46 | Iteration number: [170/565] 30% | Training loss: 0.6908666445928462
Epoch: 46 | Iteration number: [180/565] 31% | Training loss: 0.6906358304950926
Epoch: 46 | Iteration number: [190/565] 33% | Training loss: 0.69042830028032
Epoch: 46 | Iteration number: [200/565] 35% | Training loss: 0.6902429530024529
Epoch: 46 | Iteration number: [210/565] 37% | Training loss: 0.69009013459796
Epoch: 46 | Iteration number: [220/565] 38% | Training loss: 0.6899504190141504
Epoch: 46 | Iteration number: [230/565] 40% | Training loss: 0.6898007413615351
Epoch: 46 | Iteration number: [240/565] 42% | Training loss: 0.6896711523334186
Epoch: 46 | Iteration number: [250/565] 44% | Training loss: 0.6895579404830933
Epoch: 46 | Iteration number: [260/565] 46% | Training loss: 0.6894619584083557
Epoch: 46 | Iteration number: [270/565] 47% | Training loss: 0.6893719127884618
Epoch: 46 | Iteration number: [280/565] 49% | Training loss: 0.6892860665917396
Epoch: 46 | Iteration number: [290/565] 51% | Training loss: 0.6891902798208697
Epoch: 46 | Iteration number: [300/565] 53% | Training loss: 0.6891192058722179
Epoch: 46 | Iteration number: [310/565] 54% | Training loss: 0.6890393105245406
Epoch: 46 | Iteration number: [320/565] 56% | Training loss: 0.6889871524646878
Epoch: 46 | Iteration number: [330/565] 58% | Training loss: 0.6889332086750956
Epoch: 46 | Iteration number: [340/565] 60% | Training loss: 0.6888695916708778
Epoch: 46 | Iteration number: [350/565] 61% | Training loss: 0.6888002925259726
Epoch: 46 | Iteration number: [360/565] 63% | Training loss: 0.6887578166193432
Epoch: 46 | Iteration number: [370/565] 65% | Training loss: 0.6887105555147738
Epoch: 46 | Iteration number: [380/565] 67% | Training loss: 0.688662096073753
Epoch: 46 | Iteration number: [390/565] 69% | Training loss: 0.6886167355072804
Epoch: 46 | Iteration number: [400/565] 70% | Training loss: 0.6885773876309395
Epoch: 46 | Iteration number: [410/565] 72% | Training loss: 0.6885350074709915
Epoch: 46 | Iteration number: [420/565] 74% | Training loss: 0.6884879501093002
Epoch: 46 | Iteration number: [430/565] 76% | Training loss: 0.6884426444075828
Epoch: 46 | Iteration number: [440/565] 77% | Training loss: 0.6884032849561085
Epoch: 46 | Iteration number: [450/565] 79% | Training loss: 0.6883675722281138
Epoch: 46 | Iteration number: [460/565] 81% | Training loss: 0.6883357605208521
Epoch: 46 | Iteration number: [470/565] 83% | Training loss: 0.6882994082379849
Epoch: 46 | Iteration number: [480/565] 84% | Training loss: 0.6882676151891549
Epoch: 46 | Iteration number: [490/565] 86% | Training loss: 0.6882386016602419
Epoch: 46 | Iteration number: [500/565] 88% | Training loss: 0.6882135555744171
Epoch: 46 | Iteration number: [510/565] 90% | Training loss: 0.6881828602622537
Epoch: 46 | Iteration number: [520/565] 92% | Training loss: 0.6881533674322642
Epoch: 46 | Iteration number: [530/565] 93% | Training loss: 0.6881239780839884
Epoch: 46 | Iteration number: [540/565] 95% | Training loss: 0.6881056580278608
Epoch: 46 | Iteration number: [550/565] 97% | Training loss: 0.6880915474891662
Epoch: 46 | Iteration number: [560/565] 99% | Training loss: 0.6880678003387791

 End of epoch: 46 | Train Loss: 0.686839132287861 | Training Time: 88 

 End of epoch: 46 | Eval Loss: 0.6897914324487958 | Evaluating Time: 6 
Epoch: 47 | Iteration number: [10/565] 1% | Training loss: 0.7556665599346161
Epoch: 47 | Iteration number: [20/565] 3% | Training loss: 0.7212771296501159
Epoch: 47 | Iteration number: [30/565] 5% | Training loss: 0.7098176578680674
Epoch: 47 | Iteration number: [40/565] 7% | Training loss: 0.7041760757565498
Epoch: 47 | Iteration number: [50/565] 8% | Training loss: 0.7007107889652252
Epoch: 47 | Iteration number: [60/565] 10% | Training loss: 0.6983902315298717
Epoch: 47 | Iteration number: [70/565] 12% | Training loss: 0.69674905027662
Epoch: 47 | Iteration number: [80/565] 14% | Training loss: 0.6955275624990463
Epoch: 47 | Iteration number: [90/565] 15% | Training loss: 0.6945821695857578
Epoch: 47 | Iteration number: [100/565] 17% | Training loss: 0.6938271182775497
Epoch: 47 | Iteration number: [110/565] 19% | Training loss: 0.6931883448904211
Epoch: 47 | Iteration number: [120/565] 21% | Training loss: 0.6926187301675478
Epoch: 47 | Iteration number: [130/565] 23% | Training loss: 0.6921678423881531
Epoch: 47 | Iteration number: [140/565] 24% | Training loss: 0.6917751380375453
Epoch: 47 | Iteration number: [150/565] 26% | Training loss: 0.6914328821500142
Epoch: 47 | Iteration number: [160/565] 28% | Training loss: 0.6911298051476479
Epoch: 47 | Iteration number: [170/565] 30% | Training loss: 0.6908568497966318
Epoch: 47 | Iteration number: [180/565] 31% | Training loss: 0.6906332661708195
Epoch: 47 | Iteration number: [190/565] 33% | Training loss: 0.6904567294999173
Epoch: 47 | Iteration number: [200/565] 35% | Training loss: 0.6902727070450783
Epoch: 47 | Iteration number: [210/565] 37% | Training loss: 0.6900941448552268
Epoch: 47 | Iteration number: [220/565] 38% | Training loss: 0.6899544669823213
Epoch: 47 | Iteration number: [230/565] 40% | Training loss: 0.6898145522760308
Epoch: 47 | Iteration number: [240/565] 42% | Training loss: 0.6896994737287362
Epoch: 47 | Iteration number: [250/565] 44% | Training loss: 0.6895812306404113
Epoch: 47 | Iteration number: [260/565] 46% | Training loss: 0.6894723275533089
Epoch: 47 | Iteration number: [270/565] 47% | Training loss: 0.6893576697066978
Epoch: 47 | Iteration number: [280/565] 49% | Training loss: 0.6892643355897494
Epoch: 47 | Iteration number: [290/565] 51% | Training loss: 0.6891910951713036
Epoch: 47 | Iteration number: [300/565] 53% | Training loss: 0.6891002182165782
Epoch: 47 | Iteration number: [310/565] 54% | Training loss: 0.6890236589216416
Epoch: 47 | Iteration number: [320/565] 56% | Training loss: 0.6889463366940618
Epoch: 47 | Iteration number: [330/565] 58% | Training loss: 0.6888793835134217
Epoch: 47 | Iteration number: [340/565] 60% | Training loss: 0.6888151908622069
Epoch: 47 | Iteration number: [350/565] 61% | Training loss: 0.6887693136078971
Epoch: 47 | Iteration number: [360/565] 63% | Training loss: 0.6887164865930875
Epoch: 47 | Iteration number: [370/565] 65% | Training loss: 0.6886720127350575
Epoch: 47 | Iteration number: [380/565] 67% | Training loss: 0.6886147919454073
Epoch: 47 | Iteration number: [390/565] 69% | Training loss: 0.6885623204402435
Epoch: 47 | Iteration number: [400/565] 70% | Training loss: 0.6885175101459027
Epoch: 47 | Iteration number: [410/565] 72% | Training loss: 0.6884756819504063
Epoch: 47 | Iteration number: [420/565] 74% | Training loss: 0.68844445787725
Epoch: 47 | Iteration number: [430/565] 76% | Training loss: 0.6884133153183516
Epoch: 47 | Iteration number: [440/565] 77% | Training loss: 0.6883667643774639
Epoch: 47 | Iteration number: [450/565] 79% | Training loss: 0.688331368499332
Epoch: 47 | Iteration number: [460/565] 81% | Training loss: 0.6882963411186053
Epoch: 47 | Iteration number: [470/565] 83% | Training loss: 0.688261652373253
Epoch: 47 | Iteration number: [480/565] 84% | Training loss: 0.6882375956823429
Epoch: 47 | Iteration number: [490/565] 86% | Training loss: 0.6882097514308229
Epoch: 47 | Iteration number: [500/565] 88% | Training loss: 0.6881933376789093
Epoch: 47 | Iteration number: [510/565] 90% | Training loss: 0.6881630153048273
Epoch: 47 | Iteration number: [520/565] 92% | Training loss: 0.6881329787465242
Epoch: 47 | Iteration number: [530/565] 93% | Training loss: 0.6881147132729585
Epoch: 47 | Iteration number: [540/565] 95% | Training loss: 0.688102615321124
Epoch: 47 | Iteration number: [550/565] 97% | Training loss: 0.6880750581351194
Epoch: 47 | Iteration number: [560/565] 99% | Training loss: 0.688046803112541

 End of epoch: 47 | Train Loss: 0.6868181232857493 | Training Time: 89 

 End of epoch: 47 | Eval Loss: 0.6899447781699044 | Evaluating Time: 6 
Epoch: 48 | Iteration number: [10/565] 1% | Training loss: 0.7556032776832581
Epoch: 48 | Iteration number: [20/565] 3% | Training loss: 0.7212050437927247
Epoch: 48 | Iteration number: [30/565] 5% | Training loss: 0.7097953855991364
Epoch: 48 | Iteration number: [40/565] 7% | Training loss: 0.7040916219353676
Epoch: 48 | Iteration number: [50/565] 8% | Training loss: 0.7006330442428589
Epoch: 48 | Iteration number: [60/565] 10% | Training loss: 0.6983866731325785
Epoch: 48 | Iteration number: [70/565] 12% | Training loss: 0.696724327972957
Epoch: 48 | Iteration number: [80/565] 14% | Training loss: 0.6954288929700851
Epoch: 48 | Iteration number: [90/565] 15% | Training loss: 0.6944416542847951
Epoch: 48 | Iteration number: [100/565] 17% | Training loss: 0.6937314873933792
Epoch: 48 | Iteration number: [110/565] 19% | Training loss: 0.6931261376901107
Epoch: 48 | Iteration number: [120/565] 21% | Training loss: 0.6926134606202443
Epoch: 48 | Iteration number: [130/565] 23% | Training loss: 0.6921836522909312
Epoch: 48 | Iteration number: [140/565] 24% | Training loss: 0.6917937329837254
Epoch: 48 | Iteration number: [150/565] 26% | Training loss: 0.6914691666762034
Epoch: 48 | Iteration number: [160/565] 28% | Training loss: 0.6911785710602999
Epoch: 48 | Iteration number: [170/565] 30% | Training loss: 0.690932127307443
Epoch: 48 | Iteration number: [180/565] 31% | Training loss: 0.6906982034444809
Epoch: 48 | Iteration number: [190/565] 33% | Training loss: 0.6904996257079276
Epoch: 48 | Iteration number: [200/565] 35% | Training loss: 0.6903178974986076
Epoch: 48 | Iteration number: [210/565] 37% | Training loss: 0.6901591011456081
Epoch: 48 | Iteration number: [220/565] 38% | Training loss: 0.6900101805275137
Epoch: 48 | Iteration number: [230/565] 40% | Training loss: 0.6898634265298429
Epoch: 48 | Iteration number: [240/565] 42% | Training loss: 0.6897173836827278
Epoch: 48 | Iteration number: [250/565] 44% | Training loss: 0.6896135761737824
Epoch: 48 | Iteration number: [260/565] 46% | Training loss: 0.689519613981247
Epoch: 48 | Iteration number: [270/565] 47% | Training loss: 0.6894147471145348
Epoch: 48 | Iteration number: [280/565] 49% | Training loss: 0.6893329620361328
Epoch: 48 | Iteration number: [290/565] 51% | Training loss: 0.6892567704463827
Epoch: 48 | Iteration number: [300/565] 53% | Training loss: 0.6891870272159576
Epoch: 48 | Iteration number: [310/565] 54% | Training loss: 0.6891094228913707
Epoch: 48 | Iteration number: [320/565] 56% | Training loss: 0.6890381831675768
Epoch: 48 | Iteration number: [330/565] 58% | Training loss: 0.6889693200588226
Epoch: 48 | Iteration number: [340/565] 60% | Training loss: 0.6889129670227275
Epoch: 48 | Iteration number: [350/565] 61% | Training loss: 0.6888603355203357
Epoch: 48 | Iteration number: [360/565] 63% | Training loss: 0.688804511891471
Epoch: 48 | Iteration number: [370/565] 65% | Training loss: 0.688752665551933
Epoch: 48 | Iteration number: [380/565] 67% | Training loss: 0.6887057199289924
Epoch: 48 | Iteration number: [390/565] 69% | Training loss: 0.6886559495559106
Epoch: 48 | Iteration number: [400/565] 70% | Training loss: 0.6886047008633613
Epoch: 48 | Iteration number: [410/565] 72% | Training loss: 0.6885613355694747
Epoch: 48 | Iteration number: [420/565] 74% | Training loss: 0.6885084350903828
Epoch: 48 | Iteration number: [430/565] 76% | Training loss: 0.6884652317956437
Epoch: 48 | Iteration number: [440/565] 77% | Training loss: 0.688430427285758
Epoch: 48 | Iteration number: [450/565] 79% | Training loss: 0.6883923061688741
Epoch: 48 | Iteration number: [460/565] 81% | Training loss: 0.6883582594602005
Epoch: 48 | Iteration number: [470/565] 83% | Training loss: 0.6883311266594745
Epoch: 48 | Iteration number: [480/565] 84% | Training loss: 0.688294933612148
Epoch: 48 | Iteration number: [490/565] 86% | Training loss: 0.6882565328053065
Epoch: 48 | Iteration number: [500/565] 88% | Training loss: 0.6882270556688309
Epoch: 48 | Iteration number: [510/565] 90% | Training loss: 0.6881960293825935
Epoch: 48 | Iteration number: [520/565] 92% | Training loss: 0.6881697811759435
Epoch: 48 | Iteration number: [530/565] 93% | Training loss: 0.6881415405363407
Epoch: 48 | Iteration number: [540/565] 95% | Training loss: 0.6881181078928488
Epoch: 48 | Iteration number: [550/565] 97% | Training loss: 0.6880969575318423
Epoch: 48 | Iteration number: [560/565] 99% | Training loss: 0.6880753185067858

 End of epoch: 48 | Train Loss: 0.6868518767103685 | Training Time: 87 

 End of epoch: 48 | Eval Loss: 0.6907136269978115 | Evaluating Time: 6 
Epoch: 49 | Iteration number: [10/565] 1% | Training loss: 0.7555122137069702
Epoch: 49 | Iteration number: [20/565] 3% | Training loss: 0.7210566163063049
Epoch: 49 | Iteration number: [30/565] 5% | Training loss: 0.7096042195955913
Epoch: 49 | Iteration number: [40/565] 7% | Training loss: 0.7039272755384445
Epoch: 49 | Iteration number: [50/565] 8% | Training loss: 0.7005281221866607
Epoch: 49 | Iteration number: [60/565] 10% | Training loss: 0.6983068406581878
Epoch: 49 | Iteration number: [70/565] 12% | Training loss: 0.6966760064874377
Epoch: 49 | Iteration number: [80/565] 14% | Training loss: 0.6954535409808159
Epoch: 49 | Iteration number: [90/565] 15% | Training loss: 0.694464220603307
Epoch: 49 | Iteration number: [100/565] 17% | Training loss: 0.6936633950471878
Epoch: 49 | Iteration number: [110/565] 19% | Training loss: 0.6930812494321303
Epoch: 49 | Iteration number: [120/565] 21% | Training loss: 0.6925875882307688
Epoch: 49 | Iteration number: [130/565] 23% | Training loss: 0.6921568545011374
Epoch: 49 | Iteration number: [140/565] 24% | Training loss: 0.6917655915021896
Epoch: 49 | Iteration number: [150/565] 26% | Training loss: 0.6914172049363454
Epoch: 49 | Iteration number: [160/565] 28% | Training loss: 0.691135023906827
Epoch: 49 | Iteration number: [170/565] 30% | Training loss: 0.6908665288897121
Epoch: 49 | Iteration number: [180/565] 31% | Training loss: 0.6906383484601974
Epoch: 49 | Iteration number: [190/565] 33% | Training loss: 0.690431285845606
Epoch: 49 | Iteration number: [200/565] 35% | Training loss: 0.6902403581142426
Epoch: 49 | Iteration number: [210/565] 37% | Training loss: 0.6900859253747123
Epoch: 49 | Iteration number: [220/565] 38% | Training loss: 0.6899313032627106
Epoch: 49 | Iteration number: [230/565] 40% | Training loss: 0.6897905269394751
Epoch: 49 | Iteration number: [240/565] 42% | Training loss: 0.6896765907605489
Epoch: 49 | Iteration number: [250/565] 44% | Training loss: 0.6895501594543457
Epoch: 49 | Iteration number: [260/565] 46% | Training loss: 0.6894718594275988
Epoch: 49 | Iteration number: [270/565] 47% | Training loss: 0.689379632252234
Epoch: 49 | Iteration number: [280/565] 49% | Training loss: 0.6892903376902852
Epoch: 49 | Iteration number: [290/565] 51% | Training loss: 0.6892186596475799
Epoch: 49 | Iteration number: [300/565] 53% | Training loss: 0.6891304202874502
Epoch: 49 | Iteration number: [310/565] 54% | Training loss: 0.6890509836135372
Epoch: 49 | Iteration number: [320/565] 56% | Training loss: 0.6889725683256984
Epoch: 49 | Iteration number: [330/565] 58% | Training loss: 0.6889002361080864
Epoch: 49 | Iteration number: [340/565] 60% | Training loss: 0.6888455667916467
Epoch: 49 | Iteration number: [350/565] 61% | Training loss: 0.6887865739209311
Epoch: 49 | Iteration number: [360/565] 63% | Training loss: 0.6887443340486951
Epoch: 49 | Iteration number: [370/565] 65% | Training loss: 0.6886910182398719
Epoch: 49 | Iteration number: [380/565] 67% | Training loss: 0.6886383185261175
Epoch: 49 | Iteration number: [390/565] 69% | Training loss: 0.688591828254553
Epoch: 49 | Iteration number: [400/565] 70% | Training loss: 0.6885499568283557
Epoch: 49 | Iteration number: [410/565] 72% | Training loss: 0.6885166089709213
Epoch: 49 | Iteration number: [420/565] 74% | Training loss: 0.6884786953528722
Epoch: 49 | Iteration number: [430/565] 76% | Training loss: 0.6884343615798063
Epoch: 49 | Iteration number: [440/565] 77% | Training loss: 0.6884054835547101
Epoch: 49 | Iteration number: [450/565] 79% | Training loss: 0.6883700531058842
Epoch: 49 | Iteration number: [460/565] 81% | Training loss: 0.6883371162673702
Epoch: 49 | Iteration number: [470/565] 83% | Training loss: 0.6883031857774613
Epoch: 49 | Iteration number: [480/565] 84% | Training loss: 0.6882687408477068
Epoch: 49 | Iteration number: [490/565] 86% | Training loss: 0.6882339460509164
Epoch: 49 | Iteration number: [500/565] 88% | Training loss: 0.6882090430259704
Epoch: 49 | Iteration number: [510/565] 90% | Training loss: 0.6881883804704628
Epoch: 49 | Iteration number: [520/565] 92% | Training loss: 0.6881616329917541
Epoch: 49 | Iteration number: [530/565] 93% | Training loss: 0.6881373640501274
Epoch: 49 | Iteration number: [540/565] 95% | Training loss: 0.6881124409260573
Epoch: 49 | Iteration number: [550/565] 97% | Training loss: 0.6880854921991175
Epoch: 49 | Iteration number: [560/565] 99% | Training loss: 0.6880682107593332

 End of epoch: 49 | Train Loss: 0.6868425245833608 | Training Time: 89 

 End of epoch: 49 | Eval Loss: 0.689245206969125 | Evaluating Time: 6 
Epoch: 50 | Iteration number: [10/565] 1% | Training loss: 0.7557467937469482
Epoch: 50 | Iteration number: [20/565] 3% | Training loss: 0.7214227735996246
Epoch: 50 | Iteration number: [30/565] 5% | Training loss: 0.7097512443860372
Epoch: 50 | Iteration number: [40/565] 7% | Training loss: 0.7040730312466621
Epoch: 50 | Iteration number: [50/565] 8% | Training loss: 0.7005465626716614
Epoch: 50 | Iteration number: [60/565] 10% | Training loss: 0.698270030816396
Epoch: 50 | Iteration number: [70/565] 12% | Training loss: 0.696579236643655
Epoch: 50 | Iteration number: [80/565] 14% | Training loss: 0.695317554473877
Epoch: 50 | Iteration number: [90/565] 15% | Training loss: 0.6943601489067077
Epoch: 50 | Iteration number: [100/565] 17% | Training loss: 0.6936105144023895
Epoch: 50 | Iteration number: [110/565] 19% | Training loss: 0.6929826649752531
Epoch: 50 | Iteration number: [120/565] 21% | Training loss: 0.6924779618779818
Epoch: 50 | Iteration number: [130/565] 23% | Training loss: 0.6920599368902353
Epoch: 50 | Iteration number: [140/565] 24% | Training loss: 0.6916779173271996
Epoch: 50 | Iteration number: [150/565] 26% | Training loss: 0.6913688059647878
Epoch: 50 | Iteration number: [160/565] 28% | Training loss: 0.6911172449588776
Epoch: 50 | Iteration number: [170/565] 30% | Training loss: 0.6908639224136577
Epoch: 50 | Iteration number: [180/565] 31% | Training loss: 0.6906070874796973
Epoch: 50 | Iteration number: [190/565] 33% | Training loss: 0.6904042516884051
Epoch: 50 | Iteration number: [200/565] 35% | Training loss: 0.6902501168847084
Epoch: 50 | Iteration number: [210/565] 37% | Training loss: 0.690096024956022
Epoch: 50 | Iteration number: [220/565] 38% | Training loss: 0.6899415425278924
Epoch: 50 | Iteration number: [230/565] 40% | Training loss: 0.6898001748582591
Epoch: 50 | Iteration number: [240/565] 42% | Training loss: 0.6896843132873376
Epoch: 50 | Iteration number: [250/565] 44% | Training loss: 0.6895800383090973
Epoch: 50 | Iteration number: [260/565] 46% | Training loss: 0.6894779514807922
Epoch: 50 | Iteration number: [270/565] 47% | Training loss: 0.6893644328470583
Epoch: 50 | Iteration number: [280/565] 49% | Training loss: 0.6892656454018184
Epoch: 50 | Iteration number: [290/565] 51% | Training loss: 0.6891855652990012
Epoch: 50 | Iteration number: [300/565] 53% | Training loss: 0.6891130916277568
Epoch: 50 | Iteration number: [310/565] 54% | Training loss: 0.6890498824657932
Epoch: 50 | Iteration number: [320/565] 56% | Training loss: 0.6889793539419771
Epoch: 50 | Iteration number: [330/565] 58% | Training loss: 0.6889203279307394
Epoch: 50 | Iteration number: [340/565] 60% | Training loss: 0.6888674872763016
Epoch: 50 | Iteration number: [350/565] 61% | Training loss: 0.688812631538936
Epoch: 50 | Iteration number: [360/565] 63% | Training loss: 0.688747153017256
Epoch: 50 | Iteration number: [370/565] 65% | Training loss: 0.6886961550325961
Epoch: 50 | Iteration number: [380/565] 67% | Training loss: 0.6886542020659697
Epoch: 50 | Iteration number: [390/565] 69% | Training loss: 0.688594758663422
Epoch: 50 | Iteration number: [400/565] 70% | Training loss: 0.6885598926246166
Epoch: 50 | Iteration number: [410/565] 72% | Training loss: 0.6885127955820503
Epoch: 50 | Iteration number: [420/565] 74% | Training loss: 0.6884803271009808
Epoch: 50 | Iteration number: [430/565] 76% | Training loss: 0.6884402765784152
Epoch: 50 | Iteration number: [440/565] 77% | Training loss: 0.6883962964469736
Epoch: 50 | Iteration number: [450/565] 79% | Training loss: 0.6883601628409491
Epoch: 50 | Iteration number: [460/565] 81% | Training loss: 0.6883290704177774
Epoch: 50 | Iteration number: [470/565] 83% | Training loss: 0.6882982749888238
Epoch: 50 | Iteration number: [480/565] 84% | Training loss: 0.6882627669721841
Epoch: 50 | Iteration number: [490/565] 86% | Training loss: 0.6882304830210549
Epoch: 50 | Iteration number: [500/565] 88% | Training loss: 0.6882033700942993
Epoch: 50 | Iteration number: [510/565] 90% | Training loss: 0.6881700688717411
Epoch: 50 | Iteration number: [520/565] 92% | Training loss: 0.6881471338180395
Epoch: 50 | Iteration number: [530/565] 93% | Training loss: 0.6881214160964174
Epoch: 50 | Iteration number: [540/565] 95% | Training loss: 0.6880842551037117
Epoch: 50 | Iteration number: [550/565] 97% | Training loss: 0.6880542120066556
Epoch: 50 | Iteration number: [560/565] 99% | Training loss: 0.688037746399641

 End of epoch: 50 | Train Loss: 0.6868152968651425 | Training Time: 89 

 End of epoch: 50 | Eval Loss: 0.690163927418845 | Evaluating Time: 6 
Epoch: 51 | Iteration number: [10/565] 1% | Training loss: 0.7557601273059845
Epoch: 51 | Iteration number: [20/565] 3% | Training loss: 0.7212611258029937
Epoch: 51 | Iteration number: [30/565] 5% | Training loss: 0.7097229699293772
Epoch: 51 | Iteration number: [40/565] 7% | Training loss: 0.704070433974266
Epoch: 51 | Iteration number: [50/565] 8% | Training loss: 0.7004946792125701
Epoch: 51 | Iteration number: [60/565] 10% | Training loss: 0.6981990247964859
Epoch: 51 | Iteration number: [70/565] 12% | Training loss: 0.6965367249080113
Epoch: 51 | Iteration number: [80/565] 14% | Training loss: 0.6953424379229546
Epoch: 51 | Iteration number: [90/565] 15% | Training loss: 0.6943932937251197
Epoch: 51 | Iteration number: [100/565] 17% | Training loss: 0.6936027652025223
Epoch: 51 | Iteration number: [110/565] 19% | Training loss: 0.6929687321186065
Epoch: 51 | Iteration number: [120/565] 21% | Training loss: 0.6924493556221326
Epoch: 51 | Iteration number: [130/565] 23% | Training loss: 0.6920317044624915
Epoch: 51 | Iteration number: [140/565] 24% | Training loss: 0.6916206083127431
Epoch: 51 | Iteration number: [150/565] 26% | Training loss: 0.6912933735052744
Epoch: 51 | Iteration number: [160/565] 28% | Training loss: 0.6910096101462841
Epoch: 51 | Iteration number: [170/565] 30% | Training loss: 0.6907390471766977
Epoch: 51 | Iteration number: [180/565] 31% | Training loss: 0.6905247923400667
Epoch: 51 | Iteration number: [190/565] 33% | Training loss: 0.69033018162376
Epoch: 51 | Iteration number: [200/565] 35% | Training loss: 0.6901660656929016
Epoch: 51 | Iteration number: [210/565] 37% | Training loss: 0.6899939483120328
Epoch: 51 | Iteration number: [220/565] 38% | Training loss: 0.6898472458124161
Epoch: 51 | Iteration number: [230/565] 40% | Training loss: 0.6897227440191351
Epoch: 51 | Iteration number: [240/565] 42% | Training loss: 0.6896091284851233
Epoch: 51 | Iteration number: [250/565] 44% | Training loss: 0.6894972250461578
Epoch: 51 | Iteration number: [260/565] 46% | Training loss: 0.6894043612938661
Epoch: 51 | Iteration number: [270/565] 47% | Training loss: 0.6893010667076818
Epoch: 51 | Iteration number: [280/565] 49% | Training loss: 0.689224830695561
Epoch: 51 | Iteration number: [290/565] 51% | Training loss: 0.6891592033978167
Epoch: 51 | Iteration number: [300/565] 53% | Training loss: 0.6890979454914729
Epoch: 51 | Iteration number: [310/565] 54% | Training loss: 0.6890208655788053
Epoch: 51 | Iteration number: [320/565] 56% | Training loss: 0.6889458034187556
Epoch: 51 | Iteration number: [330/565] 58% | Training loss: 0.6888790392514431
Epoch: 51 | Iteration number: [340/565] 60% | Training loss: 0.6888316224603092
Epoch: 51 | Iteration number: [350/565] 61% | Training loss: 0.6887744944436209
Epoch: 51 | Iteration number: [360/565] 63% | Training loss: 0.6887182710899247
Epoch: 51 | Iteration number: [370/565] 65% | Training loss: 0.6886677990088592
Epoch: 51 | Iteration number: [380/565] 67% | Training loss: 0.6886104274737207
Epoch: 51 | Iteration number: [390/565] 69% | Training loss: 0.6885669372020624
Epoch: 51 | Iteration number: [400/565] 70% | Training loss: 0.6885157828032971
Epoch: 51 | Iteration number: [410/565] 72% | Training loss: 0.6884802694727735
Epoch: 51 | Iteration number: [420/565] 74% | Training loss: 0.6884393934692655
Epoch: 51 | Iteration number: [430/565] 76% | Training loss: 0.6884064720120541
Epoch: 51 | Iteration number: [440/565] 77% | Training loss: 0.6883680458773266
Epoch: 51 | Iteration number: [450/565] 79% | Training loss: 0.688333074649175
Epoch: 51 | Iteration number: [460/565] 81% | Training loss: 0.6883022023283917
Epoch: 51 | Iteration number: [470/565] 83% | Training loss: 0.6882630769242631
Epoch: 51 | Iteration number: [480/565] 84% | Training loss: 0.6882289758572976
Epoch: 51 | Iteration number: [490/565] 86% | Training loss: 0.688189508598678
Epoch: 51 | Iteration number: [500/565] 88% | Training loss: 0.6881654340028763
Epoch: 51 | Iteration number: [510/565] 90% | Training loss: 0.6881393867380479
Epoch: 51 | Iteration number: [520/565] 92% | Training loss: 0.6881181804033426
Epoch: 51 | Iteration number: [530/565] 93% | Training loss: 0.6880939325071731
Epoch: 51 | Iteration number: [540/565] 95% | Training loss: 0.688073887096511
Epoch: 51 | Iteration number: [550/565] 97% | Training loss: 0.6880483678254214
Epoch: 51 | Iteration number: [560/565] 99% | Training loss: 0.6880327734564032

 End of epoch: 51 | Train Loss: 0.6868107243976762 | Training Time: 89 

 End of epoch: 51 | Eval Loss: 0.6899313671248299 | Evaluating Time: 6 
Epoch: 52 | Iteration number: [10/565] 1% | Training loss: 0.7551693260669708
Epoch: 52 | Iteration number: [20/565] 3% | Training loss: 0.7210913211107254
Epoch: 52 | Iteration number: [30/565] 5% | Training loss: 0.7096954087416331
Epoch: 52 | Iteration number: [40/565] 7% | Training loss: 0.7039968967437744
Epoch: 52 | Iteration number: [50/565] 8% | Training loss: 0.7004699110984802
Epoch: 52 | Iteration number: [60/565] 10% | Training loss: 0.6982290277878443
Epoch: 52 | Iteration number: [70/565] 12% | Training loss: 0.6965300449303218
Epoch: 52 | Iteration number: [80/565] 14% | Training loss: 0.695310965925455
Epoch: 52 | Iteration number: [90/565] 15% | Training loss: 0.6943958706325954
Epoch: 52 | Iteration number: [100/565] 17% | Training loss: 0.6936425590515136
Epoch: 52 | Iteration number: [110/565] 19% | Training loss: 0.6930209002711556
Epoch: 52 | Iteration number: [120/565] 21% | Training loss: 0.6925106291969617
Epoch: 52 | Iteration number: [130/565] 23% | Training loss: 0.6920731576589437
Epoch: 52 | Iteration number: [140/565] 24% | Training loss: 0.6916519956929343
Epoch: 52 | Iteration number: [150/565] 26% | Training loss: 0.6913212974866231
Epoch: 52 | Iteration number: [160/565] 28% | Training loss: 0.6910569228231906
Epoch: 52 | Iteration number: [170/565] 30% | Training loss: 0.690798852373572
Epoch: 52 | Iteration number: [180/565] 31% | Training loss: 0.6905952490038342
Epoch: 52 | Iteration number: [190/565] 33% | Training loss: 0.6904110899097041
Epoch: 52 | Iteration number: [200/565] 35% | Training loss: 0.6902140673995018
Epoch: 52 | Iteration number: [210/565] 37% | Training loss: 0.6900538084052857
Epoch: 52 | Iteration number: [220/565] 38% | Training loss: 0.6899138540029526
Epoch: 52 | Iteration number: [230/565] 40% | Training loss: 0.6897998545480811
Epoch: 52 | Iteration number: [240/565] 42% | Training loss: 0.6896762716273467
Epoch: 52 | Iteration number: [250/565] 44% | Training loss: 0.6895677247047425
Epoch: 52 | Iteration number: [260/565] 46% | Training loss: 0.6894567553813641
Epoch: 52 | Iteration number: [270/565] 47% | Training loss: 0.6893456260363261
Epoch: 52 | Iteration number: [280/565] 49% | Training loss: 0.6892464158790452
Epoch: 52 | Iteration number: [290/565] 51% | Training loss: 0.6891561432131406
Epoch: 52 | Iteration number: [300/565] 53% | Training loss: 0.6890776411692301
Epoch: 52 | Iteration number: [310/565] 54% | Training loss: 0.6890147107262765
Epoch: 52 | Iteration number: [320/565] 56% | Training loss: 0.6889506986364722
Epoch: 52 | Iteration number: [330/565] 58% | Training loss: 0.6888853185104601
Epoch: 52 | Iteration number: [340/565] 60% | Training loss: 0.688830543440931
Epoch: 52 | Iteration number: [350/565] 61% | Training loss: 0.6887696043082646
Epoch: 52 | Iteration number: [360/565] 63% | Training loss: 0.688708094921377
Epoch: 52 | Iteration number: [370/565] 65% | Training loss: 0.6886636845163396
Epoch: 52 | Iteration number: [380/565] 67% | Training loss: 0.688623784874615
Epoch: 52 | Iteration number: [390/565] 69% | Training loss: 0.6885974208513895
Epoch: 52 | Iteration number: [400/565] 70% | Training loss: 0.6885544002056122
Epoch: 52 | Iteration number: [410/565] 72% | Training loss: 0.6885019548055602
Epoch: 52 | Iteration number: [420/565] 74% | Training loss: 0.6884529475654875
Epoch: 52 | Iteration number: [430/565] 76% | Training loss: 0.6884005801622257
Epoch: 52 | Iteration number: [440/565] 77% | Training loss: 0.6883746908469633
Epoch: 52 | Iteration number: [450/565] 79% | Training loss: 0.6883458624945746
Epoch: 52 | Iteration number: [460/565] 81% | Training loss: 0.688306330597919
Epoch: 52 | Iteration number: [470/565] 83% | Training loss: 0.6882700655054539
Epoch: 52 | Iteration number: [480/565] 84% | Training loss: 0.6882372215390206
Epoch: 52 | Iteration number: [490/565] 86% | Training loss: 0.6882085215072242
Epoch: 52 | Iteration number: [500/565] 88% | Training loss: 0.6881832876205445
Epoch: 52 | Iteration number: [510/565] 90% | Training loss: 0.6881688259395898
Epoch: 52 | Iteration number: [520/565] 92% | Training loss: 0.6881427736236498
Epoch: 52 | Iteration number: [530/565] 93% | Training loss: 0.6881166786517737
Epoch: 52 | Iteration number: [540/565] 95% | Training loss: 0.6880955378214518
Epoch: 52 | Iteration number: [550/565] 97% | Training loss: 0.6880653951384804
Epoch: 52 | Iteration number: [560/565] 99% | Training loss: 0.6880427059318338

 End of epoch: 52 | Train Loss: 0.6868193391150078 | Training Time: 90 

 End of epoch: 52 | Eval Loss: 0.689781095300402 | Evaluating Time: 6 
Epoch: 53 | Iteration number: [10/565] 1% | Training loss: 0.7555608630180359
Epoch: 53 | Iteration number: [20/565] 3% | Training loss: 0.7214241296052932
Epoch: 53 | Iteration number: [30/565] 5% | Training loss: 0.7099438190460206
Epoch: 53 | Iteration number: [40/565] 7% | Training loss: 0.7041872695088387
Epoch: 53 | Iteration number: [50/565] 8% | Training loss: 0.7008138155937195
Epoch: 53 | Iteration number: [60/565] 10% | Training loss: 0.6985320806503296
Epoch: 53 | Iteration number: [70/565] 12% | Training loss: 0.6968966160501753
Epoch: 53 | Iteration number: [80/565] 14% | Training loss: 0.6956196069717407
Epoch: 53 | Iteration number: [90/565] 15% | Training loss: 0.6945880492528279
Epoch: 53 | Iteration number: [100/565] 17% | Training loss: 0.69382120013237
Epoch: 53 | Iteration number: [110/565] 19% | Training loss: 0.6931814621795308
Epoch: 53 | Iteration number: [120/565] 21% | Training loss: 0.6926068748037021
Epoch: 53 | Iteration number: [130/565] 23% | Training loss: 0.6922061590047983
Epoch: 53 | Iteration number: [140/565] 24% | Training loss: 0.6918427207640239
Epoch: 53 | Iteration number: [150/565] 26% | Training loss: 0.6915078731377919
Epoch: 53 | Iteration number: [160/565] 28% | Training loss: 0.6912235200405121
Epoch: 53 | Iteration number: [170/565] 30% | Training loss: 0.6909566847717061
Epoch: 53 | Iteration number: [180/565] 31% | Training loss: 0.6907262957758373
Epoch: 53 | Iteration number: [190/565] 33% | Training loss: 0.690514210964504
Epoch: 53 | Iteration number: [200/565] 35% | Training loss: 0.6903412359952926
Epoch: 53 | Iteration number: [210/565] 37% | Training loss: 0.6901668225015912
Epoch: 53 | Iteration number: [220/565] 38% | Training loss: 0.6900154279036955
Epoch: 53 | Iteration number: [230/565] 40% | Training loss: 0.6898795425891876
Epoch: 53 | Iteration number: [240/565] 42% | Training loss: 0.6897559978067875
Epoch: 53 | Iteration number: [250/565] 44% | Training loss: 0.6896413843631745
Epoch: 53 | Iteration number: [260/565] 46% | Training loss: 0.6895201914585554
Epoch: 53 | Iteration number: [270/565] 47% | Training loss: 0.6894143557107008
Epoch: 53 | Iteration number: [280/565] 49% | Training loss: 0.6893243604472705
Epoch: 53 | Iteration number: [290/565] 51% | Training loss: 0.689238663377433
Epoch: 53 | Iteration number: [300/565] 53% | Training loss: 0.6891653474171956
Epoch: 53 | Iteration number: [310/565] 54% | Training loss: 0.689080511946832
Epoch: 53 | Iteration number: [320/565] 56% | Training loss: 0.6889951596036553
Epoch: 53 | Iteration number: [330/565] 58% | Training loss: 0.6889320360891746
Epoch: 53 | Iteration number: [340/565] 60% | Training loss: 0.6888774771900738
Epoch: 53 | Iteration number: [350/565] 61% | Training loss: 0.688822500024523
Epoch: 53 | Iteration number: [360/565] 63% | Training loss: 0.6887625134653516
Epoch: 53 | Iteration number: [370/565] 65% | Training loss: 0.6887177456069637
Epoch: 53 | Iteration number: [380/565] 67% | Training loss: 0.6886677842391165
Epoch: 53 | Iteration number: [390/565] 69% | Training loss: 0.688614707879531
Epoch: 53 | Iteration number: [400/565] 70% | Training loss: 0.6885690869390965
Epoch: 53 | Iteration number: [410/565] 72% | Training loss: 0.6885230381314348
Epoch: 53 | Iteration number: [420/565] 74% | Training loss: 0.6884917107366381
Epoch: 53 | Iteration number: [430/565] 76% | Training loss: 0.6884435540021852
Epoch: 53 | Iteration number: [440/565] 77% | Training loss: 0.6884060869162733
Epoch: 53 | Iteration number: [450/565] 79% | Training loss: 0.6883741311232249
Epoch: 53 | Iteration number: [460/565] 81% | Training loss: 0.6883419829866161
Epoch: 53 | Iteration number: [470/565] 83% | Training loss: 0.688303250835297
Epoch: 53 | Iteration number: [480/565] 84% | Training loss: 0.6882753590742747
Epoch: 53 | Iteration number: [490/565] 86% | Training loss: 0.6882332163197654
Epoch: 53 | Iteration number: [500/565] 88% | Training loss: 0.6881963769197464
Epoch: 53 | Iteration number: [510/565] 90% | Training loss: 0.6881742680774016
Epoch: 53 | Iteration number: [520/565] 92% | Training loss: 0.6881493654388647
Epoch: 53 | Iteration number: [530/565] 93% | Training loss: 0.6881248440382616
Epoch: 53 | Iteration number: [540/565] 95% | Training loss: 0.688102869855033
Epoch: 53 | Iteration number: [550/565] 97% | Training loss: 0.6880704053965482
Epoch: 53 | Iteration number: [560/565] 99% | Training loss: 0.688052672786372

 End of epoch: 53 | Train Loss: 0.6868207924133909 | Training Time: 89 

 End of epoch: 53 | Eval Loss: 0.6901618923459735 | Evaluating Time: 6 
Epoch: 54 | Iteration number: [10/565] 1% | Training loss: 0.7555426120758056
Epoch: 54 | Iteration number: [20/565] 3% | Training loss: 0.721001210808754
Epoch: 54 | Iteration number: [30/565] 5% | Training loss: 0.7095380246639251
Epoch: 54 | Iteration number: [40/565] 7% | Training loss: 0.7037912920117378
Epoch: 54 | Iteration number: [50/565] 8% | Training loss: 0.7003984749317169
Epoch: 54 | Iteration number: [60/565] 10% | Training loss: 0.698119534055392
Epoch: 54 | Iteration number: [70/565] 12% | Training loss: 0.6964366742542811
Epoch: 54 | Iteration number: [80/565] 14% | Training loss: 0.6952201180160046
Epoch: 54 | Iteration number: [90/565] 15% | Training loss: 0.6942371447881063
Epoch: 54 | Iteration number: [100/565] 17% | Training loss: 0.693491085767746
Epoch: 54 | Iteration number: [110/565] 19% | Training loss: 0.6928607236255299
Epoch: 54 | Iteration number: [120/565] 21% | Training loss: 0.6923536871870358
Epoch: 54 | Iteration number: [130/565] 23% | Training loss: 0.6919245027578794
Epoch: 54 | Iteration number: [140/565] 24% | Training loss: 0.6915437327963966
Epoch: 54 | Iteration number: [150/565] 26% | Training loss: 0.6912571529547373
Epoch: 54 | Iteration number: [160/565] 28% | Training loss: 0.6909910928457975
Epoch: 54 | Iteration number: [170/565] 30% | Training loss: 0.6907365108237548
Epoch: 54 | Iteration number: [180/565] 31% | Training loss: 0.6905238270759583
Epoch: 54 | Iteration number: [190/565] 33% | Training loss: 0.6903282275325373
Epoch: 54 | Iteration number: [200/565] 35% | Training loss: 0.690140428841114
Epoch: 54 | Iteration number: [210/565] 37% | Training loss: 0.6899759190423148
Epoch: 54 | Iteration number: [220/565] 38% | Training loss: 0.6898479001088575
Epoch: 54 | Iteration number: [230/565] 40% | Training loss: 0.689712718517884
Epoch: 54 | Iteration number: [240/565] 42% | Training loss: 0.6895916509131591
Epoch: 54 | Iteration number: [250/565] 44% | Training loss: 0.6894769020080567
Epoch: 54 | Iteration number: [260/565] 46% | Training loss: 0.6893780146653835
Epoch: 54 | Iteration number: [270/565] 47% | Training loss: 0.6892656074629889
Epoch: 54 | Iteration number: [280/565] 49% | Training loss: 0.6891689832721438
Epoch: 54 | Iteration number: [290/565] 51% | Training loss: 0.6890891839717996
Epoch: 54 | Iteration number: [300/565] 53% | Training loss: 0.6890287067492803
Epoch: 54 | Iteration number: [310/565] 54% | Training loss: 0.6889812990542381
Epoch: 54 | Iteration number: [320/565] 56% | Training loss: 0.6889098862186074
Epoch: 54 | Iteration number: [330/565] 58% | Training loss: 0.6888391585061044
Epoch: 54 | Iteration number: [340/565] 60% | Training loss: 0.688782309609301
Epoch: 54 | Iteration number: [350/565] 61% | Training loss: 0.6887255655016218
Epoch: 54 | Iteration number: [360/565] 63% | Training loss: 0.6886672768327925
Epoch: 54 | Iteration number: [370/565] 65% | Training loss: 0.6886305164646458
Epoch: 54 | Iteration number: [380/565] 67% | Training loss: 0.6885891072059932
Epoch: 54 | Iteration number: [390/565] 69% | Training loss: 0.6885440928813739
Epoch: 54 | Iteration number: [400/565] 70% | Training loss: 0.6885042575001716
Epoch: 54 | Iteration number: [410/565] 72% | Training loss: 0.6884672606863627
Epoch: 54 | Iteration number: [420/565] 74% | Training loss: 0.6884327256963366
Epoch: 54 | Iteration number: [430/565] 76% | Training loss: 0.6883951781794082
Epoch: 54 | Iteration number: [440/565] 77% | Training loss: 0.6883568851785227
Epoch: 54 | Iteration number: [450/565] 79% | Training loss: 0.6883315857251485
Epoch: 54 | Iteration number: [460/565] 81% | Training loss: 0.688294299400371
Epoch: 54 | Iteration number: [470/565] 83% | Training loss: 0.688257342069707
Epoch: 54 | Iteration number: [480/565] 84% | Training loss: 0.6882301915436984
Epoch: 54 | Iteration number: [490/565] 86% | Training loss: 0.6881928682327271
Epoch: 54 | Iteration number: [500/565] 88% | Training loss: 0.6881671860218048
Epoch: 54 | Iteration number: [510/565] 90% | Training loss: 0.6881386561720979
Epoch: 54 | Iteration number: [520/565] 92% | Training loss: 0.688124736570395
Epoch: 54 | Iteration number: [530/565] 93% | Training loss: 0.6880987722918672
Epoch: 54 | Iteration number: [540/565] 95% | Training loss: 0.6880834955860067
Epoch: 54 | Iteration number: [550/565] 97% | Training loss: 0.6880586349964142
Epoch: 54 | Iteration number: [560/565] 99% | Training loss: 0.6880393206008844

 End of epoch: 54 | Train Loss: 0.6868145649412037 | Training Time: 88 

 End of epoch: 54 | Eval Loss: 0.6901058980396816 | Evaluating Time: 6 
Epoch: 55 | Iteration number: [10/565] 1% | Training loss: 0.7553889036178589
Epoch: 55 | Iteration number: [20/565] 3% | Training loss: 0.7212061941623688
Epoch: 55 | Iteration number: [30/565] 5% | Training loss: 0.7097729126612345
Epoch: 55 | Iteration number: [40/565] 7% | Training loss: 0.704000499844551
Epoch: 55 | Iteration number: [50/565] 8% | Training loss: 0.700677078962326
Epoch: 55 | Iteration number: [60/565] 10% | Training loss: 0.6983371953169505
Epoch: 55 | Iteration number: [70/565] 12% | Training loss: 0.6967219037669046
Epoch: 55 | Iteration number: [80/565] 14% | Training loss: 0.6954408429563046
Epoch: 55 | Iteration number: [90/565] 15% | Training loss: 0.6944420728418562
Epoch: 55 | Iteration number: [100/565] 17% | Training loss: 0.6936666369438171
Epoch: 55 | Iteration number: [110/565] 19% | Training loss: 0.6930626863783056
Epoch: 55 | Iteration number: [120/565] 21% | Training loss: 0.6925339673956236
Epoch: 55 | Iteration number: [130/565] 23% | Training loss: 0.6920898304535792
Epoch: 55 | Iteration number: [140/565] 24% | Training loss: 0.6916922952447618
Epoch: 55 | Iteration number: [150/565] 26% | Training loss: 0.6913947137196859
Epoch: 55 | Iteration number: [160/565] 28% | Training loss: 0.691105242818594
Epoch: 55 | Iteration number: [170/565] 30% | Training loss: 0.6908467794165892
Epoch: 55 | Iteration number: [180/565] 31% | Training loss: 0.6906147546238369
Epoch: 55 | Iteration number: [190/565] 33% | Training loss: 0.6904386758804322
Epoch: 55 | Iteration number: [200/565] 35% | Training loss: 0.6902587518095971
Epoch: 55 | Iteration number: [210/565] 37% | Training loss: 0.6900911422002883
Epoch: 55 | Iteration number: [220/565] 38% | Training loss: 0.6899411399256099
Epoch: 55 | Iteration number: [230/565] 40% | Training loss: 0.6898008818211763
Epoch: 55 | Iteration number: [240/565] 42% | Training loss: 0.6896799609065056
Epoch: 55 | Iteration number: [250/565] 44% | Training loss: 0.6895680558681488
Epoch: 55 | Iteration number: [260/565] 46% | Training loss: 0.6894674619803062
Epoch: 55 | Iteration number: [270/565] 47% | Training loss: 0.689355092799222
Epoch: 55 | Iteration number: [280/565] 49% | Training loss: 0.6892594935638564
Epoch: 55 | Iteration number: [290/565] 51% | Training loss: 0.6891816642777673
Epoch: 55 | Iteration number: [300/565] 53% | Training loss: 0.689091587861379
Epoch: 55 | Iteration number: [310/565] 54% | Training loss: 0.6890097297007037
Epoch: 55 | Iteration number: [320/565] 56% | Training loss: 0.6889364229515195
Epoch: 55 | Iteration number: [330/565] 58% | Training loss: 0.6888513008753459
Epoch: 55 | Iteration number: [340/565] 60% | Training loss: 0.688787833031486
Epoch: 55 | Iteration number: [350/565] 61% | Training loss: 0.6887359671933311
Epoch: 55 | Iteration number: [360/565] 63% | Training loss: 0.6886823410789172
Epoch: 55 | Iteration number: [370/565] 65% | Training loss: 0.6886367641590737
Epoch: 55 | Iteration number: [380/565] 67% | Training loss: 0.6885807478114179
Epoch: 55 | Iteration number: [390/565] 69% | Training loss: 0.6885263277934148
Epoch: 55 | Iteration number: [400/565] 70% | Training loss: 0.6884901952743531
Epoch: 55 | Iteration number: [410/565] 72% | Training loss: 0.6884481507103618
Epoch: 55 | Iteration number: [420/565] 74% | Training loss: 0.6884131469896861
Epoch: 55 | Iteration number: [430/565] 76% | Training loss: 0.688380886787592
Epoch: 55 | Iteration number: [440/565] 77% | Training loss: 0.688335856930776
Epoch: 55 | Iteration number: [450/565] 79% | Training loss: 0.6883096200890011
Epoch: 55 | Iteration number: [460/565] 81% | Training loss: 0.6882754248121511
Epoch: 55 | Iteration number: [470/565] 83% | Training loss: 0.6882406177672934
Epoch: 55 | Iteration number: [480/565] 84% | Training loss: 0.6882153732081254
Epoch: 55 | Iteration number: [490/565] 86% | Training loss: 0.6881858780676005
Epoch: 55 | Iteration number: [500/565] 88% | Training loss: 0.6881631425619126
Epoch: 55 | Iteration number: [510/565] 90% | Training loss: 0.6881376299203611
Epoch: 55 | Iteration number: [520/565] 92% | Training loss: 0.6881103650881694
Epoch: 55 | Iteration number: [530/565] 93% | Training loss: 0.6880898604977805
Epoch: 55 | Iteration number: [540/565] 95% | Training loss: 0.6880700572773263
Epoch: 55 | Iteration number: [550/565] 97% | Training loss: 0.688053572177887
Epoch: 55 | Iteration number: [560/565] 99% | Training loss: 0.6880279597427164

 End of epoch: 55 | Train Loss: 0.6868005163901675 | Training Time: 89 

 End of epoch: 55 | Eval Loss: 0.6897777829851423 | Evaluating Time: 6 
Epoch: 56 | Iteration number: [10/565] 1% | Training loss: 0.7545891284942627
Epoch: 56 | Iteration number: [20/565] 3% | Training loss: 0.7207289457321167
Epoch: 56 | Iteration number: [30/565] 5% | Training loss: 0.7093592564264933
Epoch: 56 | Iteration number: [40/565] 7% | Training loss: 0.7038333043456078
Epoch: 56 | Iteration number: [50/565] 8% | Training loss: 0.7003575766086578
Epoch: 56 | Iteration number: [60/565] 10% | Training loss: 0.6981124589840572
Epoch: 56 | Iteration number: [70/565] 12% | Training loss: 0.6964552972997938
Epoch: 56 | Iteration number: [80/565] 14% | Training loss: 0.6952828571200371
Epoch: 56 | Iteration number: [90/565] 15% | Training loss: 0.6943393674161699
Epoch: 56 | Iteration number: [100/565] 17% | Training loss: 0.6935710555315018
Epoch: 56 | Iteration number: [110/565] 19% | Training loss: 0.6929465835744685
Epoch: 56 | Iteration number: [120/565] 21% | Training loss: 0.6924560258785883
Epoch: 56 | Iteration number: [130/565] 23% | Training loss: 0.6920280222709362
Epoch: 56 | Iteration number: [140/565] 24% | Training loss: 0.6916751457112176
Epoch: 56 | Iteration number: [150/565] 26% | Training loss: 0.6913425223032633
Epoch: 56 | Iteration number: [160/565] 28% | Training loss: 0.6910630200058222
Epoch: 56 | Iteration number: [170/565] 30% | Training loss: 0.6908168368479785
Epoch: 56 | Iteration number: [180/565] 31% | Training loss: 0.6905887660053042
Epoch: 56 | Iteration number: [190/565] 33% | Training loss: 0.6903780846219314
Epoch: 56 | Iteration number: [200/565] 35% | Training loss: 0.6901997795701027
Epoch: 56 | Iteration number: [210/565] 37% | Training loss: 0.6900207865805853
Epoch: 56 | Iteration number: [220/565] 38% | Training loss: 0.689875734665177
Epoch: 56 | Iteration number: [230/565] 40% | Training loss: 0.6897426307201385
Epoch: 56 | Iteration number: [240/565] 42% | Training loss: 0.6896148550013701
Epoch: 56 | Iteration number: [250/565] 44% | Training loss: 0.6895049567222595
Epoch: 56 | Iteration number: [260/565] 46% | Training loss: 0.6893903899651307
Epoch: 56 | Iteration number: [270/565] 47% | Training loss: 0.6892865790261162
Epoch: 56 | Iteration number: [280/565] 49% | Training loss: 0.6891915570412364
Epoch: 56 | Iteration number: [290/565] 51% | Training loss: 0.6891113248364679
Epoch: 56 | Iteration number: [300/565] 53% | Training loss: 0.6890300887823105
Epoch: 56 | Iteration number: [310/565] 54% | Training loss: 0.6889475180256751
Epoch: 56 | Iteration number: [320/565] 56% | Training loss: 0.6888913253322244
Epoch: 56 | Iteration number: [330/565] 58% | Training loss: 0.6888377359419158
Epoch: 56 | Iteration number: [340/565] 60% | Training loss: 0.68878194269012
Epoch: 56 | Iteration number: [350/565] 61% | Training loss: 0.6887231358460018
Epoch: 56 | Iteration number: [360/565] 63% | Training loss: 0.6886764913797379
Epoch: 56 | Iteration number: [370/565] 65% | Training loss: 0.6886155175196158
Epoch: 56 | Iteration number: [380/565] 67% | Training loss: 0.6885633986247214
Epoch: 56 | Iteration number: [390/565] 69% | Training loss: 0.6885203222433726
Epoch: 56 | Iteration number: [400/565] 70% | Training loss: 0.6884986706078052
Epoch: 56 | Iteration number: [410/565] 72% | Training loss: 0.688462423260619
Epoch: 56 | Iteration number: [420/565] 74% | Training loss: 0.6884195699578239
Epoch: 56 | Iteration number: [430/565] 76% | Training loss: 0.688385587237602
Epoch: 56 | Iteration number: [440/565] 77% | Training loss: 0.6883564580570568
Epoch: 56 | Iteration number: [450/565] 79% | Training loss: 0.6883221775955624
Epoch: 56 | Iteration number: [460/565] 81% | Training loss: 0.6882837364207144
Epoch: 56 | Iteration number: [470/565] 83% | Training loss: 0.6882512121758563
Epoch: 56 | Iteration number: [480/565] 84% | Training loss: 0.6882177859544754
Epoch: 56 | Iteration number: [490/565] 86% | Training loss: 0.6881925276347569
Epoch: 56 | Iteration number: [500/565] 88% | Training loss: 0.6881631770133972
Epoch: 56 | Iteration number: [510/565] 90% | Training loss: 0.6881428346914403
Epoch: 56 | Iteration number: [520/565] 92% | Training loss: 0.6881257124818289
Epoch: 56 | Iteration number: [530/565] 93% | Training loss: 0.6881045284136287
Epoch: 56 | Iteration number: [540/565] 95% | Training loss: 0.688074345169244
Epoch: 56 | Iteration number: [550/565] 97% | Training loss: 0.6880533553253521
Epoch: 56 | Iteration number: [560/565] 99% | Training loss: 0.6880273832806519

 End of epoch: 56 | Train Loss: 0.6868022555798556 | Training Time: 90 

 End of epoch: 56 | Eval Loss: 0.689727646963937 | Evaluating Time: 6 
Epoch: 57 | Iteration number: [10/565] 1% | Training loss: 0.7551985919475556
Epoch: 57 | Iteration number: [20/565] 3% | Training loss: 0.7208298146724701
Epoch: 57 | Iteration number: [30/565] 5% | Training loss: 0.7094936470190684
Epoch: 57 | Iteration number: [40/565] 7% | Training loss: 0.7038705453276635
Epoch: 57 | Iteration number: [50/565] 8% | Training loss: 0.7004762697219848
Epoch: 57 | Iteration number: [60/565] 10% | Training loss: 0.6981987873713176
Epoch: 57 | Iteration number: [70/565] 12% | Training loss: 0.6966100096702575
Epoch: 57 | Iteration number: [80/565] 14% | Training loss: 0.6953596018254757
Epoch: 57 | Iteration number: [90/565] 15% | Training loss: 0.6944451544019911
Epoch: 57 | Iteration number: [100/565] 17% | Training loss: 0.693663979768753
Epoch: 57 | Iteration number: [110/565] 19% | Training loss: 0.6931054310365157
Epoch: 57 | Iteration number: [120/565] 21% | Training loss: 0.6925395160913468
Epoch: 57 | Iteration number: [130/565] 23% | Training loss: 0.692131481720851
Epoch: 57 | Iteration number: [140/565] 24% | Training loss: 0.6917664851461138
Epoch: 57 | Iteration number: [150/565] 26% | Training loss: 0.6914470378557841
Epoch: 57 | Iteration number: [160/565] 28% | Training loss: 0.6911681406199932
Epoch: 57 | Iteration number: [170/565] 30% | Training loss: 0.690914216111688
Epoch: 57 | Iteration number: [180/565] 31% | Training loss: 0.6906781617138121
Epoch: 57 | Iteration number: [190/565] 33% | Training loss: 0.6904740691184997
Epoch: 57 | Iteration number: [200/565] 35% | Training loss: 0.6902978664636612
Epoch: 57 | Iteration number: [210/565] 37% | Training loss: 0.6901261559554509
Epoch: 57 | Iteration number: [220/565] 38% | Training loss: 0.6899644082242792
Epoch: 57 | Iteration number: [230/565] 40% | Training loss: 0.6898237723371257
Epoch: 57 | Iteration number: [240/565] 42% | Training loss: 0.6896872110664845
Epoch: 57 | Iteration number: [250/565] 44% | Training loss: 0.6895666694641114
Epoch: 57 | Iteration number: [260/565] 46% | Training loss: 0.6894633714969342
Epoch: 57 | Iteration number: [270/565] 47% | Training loss: 0.689343391082905
Epoch: 57 | Iteration number: [280/565] 49% | Training loss: 0.6892587829913411
Epoch: 57 | Iteration number: [290/565] 51% | Training loss: 0.6891858733933548
Epoch: 57 | Iteration number: [300/565] 53% | Training loss: 0.6891027708848317
Epoch: 57 | Iteration number: [310/565] 54% | Training loss: 0.6890386773693946
Epoch: 57 | Iteration number: [320/565] 56% | Training loss: 0.6889717377722263
Epoch: 57 | Iteration number: [330/565] 58% | Training loss: 0.6888986293113593
Epoch: 57 | Iteration number: [340/565] 60% | Training loss: 0.6888401068308774
Epoch: 57 | Iteration number: [350/565] 61% | Training loss: 0.6887795557294573
Epoch: 57 | Iteration number: [360/565] 63% | Training loss: 0.6887266443835365
Epoch: 57 | Iteration number: [370/565] 65% | Training loss: 0.6886766117972296
Epoch: 57 | Iteration number: [380/565] 67% | Training loss: 0.6886263359534113
Epoch: 57 | Iteration number: [390/565] 69% | Training loss: 0.6885792753635309
Epoch: 57 | Iteration number: [400/565] 70% | Training loss: 0.6885239806771278
Epoch: 57 | Iteration number: [410/565] 72% | Training loss: 0.688470623260591
Epoch: 57 | Iteration number: [420/565] 74% | Training loss: 0.6884287429707391
Epoch: 57 | Iteration number: [430/565] 76% | Training loss: 0.6883764187956966
Epoch: 57 | Iteration number: [440/565] 77% | Training loss: 0.6883389466188171
Epoch: 57 | Iteration number: [450/565] 79% | Training loss: 0.6883037734031677
Epoch: 57 | Iteration number: [460/565] 81% | Training loss: 0.6882802110651265
Epoch: 57 | Iteration number: [470/565] 83% | Training loss: 0.6882473691980889
Epoch: 57 | Iteration number: [480/565] 84% | Training loss: 0.6882227727522453
Epoch: 57 | Iteration number: [490/565] 86% | Training loss: 0.6881887501599837
Epoch: 57 | Iteration number: [500/565] 88% | Training loss: 0.6881652988195419
Epoch: 57 | Iteration number: [510/565] 90% | Training loss: 0.6881411565285103
Epoch: 57 | Iteration number: [520/565] 92% | Training loss: 0.6881239305321987
Epoch: 57 | Iteration number: [530/565] 93% | Training loss: 0.6880932302969807
Epoch: 57 | Iteration number: [540/565] 95% | Training loss: 0.6880707650272935
Epoch: 57 | Iteration number: [550/565] 97% | Training loss: 0.6880454523996873
Epoch: 57 | Iteration number: [560/565] 99% | Training loss: 0.688028302362987

 End of epoch: 57 | Train Loss: 0.6868016640696906 | Training Time: 90 

 End of epoch: 57 | Eval Loss: 0.6895970361573356 | Evaluating Time: 6 
Epoch: 58 | Iteration number: [10/565] 1% | Training loss: 0.7553120851516724
Epoch: 58 | Iteration number: [20/565] 3% | Training loss: 0.720879328250885
Epoch: 58 | Iteration number: [30/565] 5% | Training loss: 0.7093554814656575
Epoch: 58 | Iteration number: [40/565] 7% | Training loss: 0.703675451874733
Epoch: 58 | Iteration number: [50/565] 8% | Training loss: 0.7003948831558228
Epoch: 58 | Iteration number: [60/565] 10% | Training loss: 0.6980968832969665
Epoch: 58 | Iteration number: [70/565] 12% | Training loss: 0.6964457843984876
Epoch: 58 | Iteration number: [80/565] 14% | Training loss: 0.6952341213822365
Epoch: 58 | Iteration number: [90/565] 15% | Training loss: 0.6942922963036431
Epoch: 58 | Iteration number: [100/565] 17% | Training loss: 0.6934983956813813
Epoch: 58 | Iteration number: [110/565] 19% | Training loss: 0.6929086923599244
Epoch: 58 | Iteration number: [120/565] 21% | Training loss: 0.6924348672231039
Epoch: 58 | Iteration number: [130/565] 23% | Training loss: 0.6920242506724138
Epoch: 58 | Iteration number: [140/565] 24% | Training loss: 0.6916745075157711
Epoch: 58 | Iteration number: [150/565] 26% | Training loss: 0.6913752528031667
Epoch: 58 | Iteration number: [160/565] 28% | Training loss: 0.6910865999758243
Epoch: 58 | Iteration number: [170/565] 30% | Training loss: 0.6908336197628694
Epoch: 58 | Iteration number: [180/565] 31% | Training loss: 0.690599340862698
Epoch: 58 | Iteration number: [190/565] 33% | Training loss: 0.6904204735630437
Epoch: 58 | Iteration number: [200/565] 35% | Training loss: 0.6902395153045654
Epoch: 58 | Iteration number: [210/565] 37% | Training loss: 0.6900624121938433
Epoch: 58 | Iteration number: [220/565] 38% | Training loss: 0.6899267283352939
Epoch: 58 | Iteration number: [230/565] 40% | Training loss: 0.6898123272087263
Epoch: 58 | Iteration number: [240/565] 42% | Training loss: 0.6896727996567885
Epoch: 58 | Iteration number: [250/565] 44% | Training loss: 0.6895661201477051
Epoch: 58 | Iteration number: [260/565] 46% | Training loss: 0.6894540954094667
Epoch: 58 | Iteration number: [270/565] 47% | Training loss: 0.689363244065532
Epoch: 58 | Iteration number: [280/565] 49% | Training loss: 0.6892731779388019
Epoch: 58 | Iteration number: [290/565] 51% | Training loss: 0.6891885389541758
Epoch: 58 | Iteration number: [300/565] 53% | Training loss: 0.6891113607088725
Epoch: 58 | Iteration number: [310/565] 54% | Training loss: 0.6890467603360453
Epoch: 58 | Iteration number: [320/565] 56% | Training loss: 0.688964650966227
Epoch: 58 | Iteration number: [330/565] 58% | Training loss: 0.688902456110174
Epoch: 58 | Iteration number: [340/565] 60% | Training loss: 0.6888354015700957
Epoch: 58 | Iteration number: [350/565] 61% | Training loss: 0.6887696579524449
Epoch: 58 | Iteration number: [360/565] 63% | Training loss: 0.6887163249982728
Epoch: 58 | Iteration number: [370/565] 65% | Training loss: 0.6886749688032511
Epoch: 58 | Iteration number: [380/565] 67% | Training loss: 0.6886191935915696
Epoch: 58 | Iteration number: [390/565] 69% | Training loss: 0.6885660518438388
Epoch: 58 | Iteration number: [400/565] 70% | Training loss: 0.6885171070694923
Epoch: 58 | Iteration number: [410/565] 72% | Training loss: 0.6884827375411987
Epoch: 58 | Iteration number: [420/565] 74% | Training loss: 0.688440811350232
Epoch: 58 | Iteration number: [430/565] 76% | Training loss: 0.6883995336155558
Epoch: 58 | Iteration number: [440/565] 77% | Training loss: 0.6883607730269432
Epoch: 58 | Iteration number: [450/565] 79% | Training loss: 0.6883277373843723
Epoch: 58 | Iteration number: [460/565] 81% | Training loss: 0.6882925344550092
Epoch: 58 | Iteration number: [470/565] 83% | Training loss: 0.6882604772740222
Epoch: 58 | Iteration number: [480/565] 84% | Training loss: 0.6882242361704508
Epoch: 58 | Iteration number: [490/565] 86% | Training loss: 0.6881925384609067
Epoch: 58 | Iteration number: [500/565] 88% | Training loss: 0.6881653965711594
Epoch: 58 | Iteration number: [510/565] 90% | Training loss: 0.6881333320748573
Epoch: 58 | Iteration number: [520/565] 92% | Training loss: 0.6881079986691475
Epoch: 58 | Iteration number: [530/565] 93% | Training loss: 0.6880885912562317
Epoch: 58 | Iteration number: [540/565] 95% | Training loss: 0.6880688777676335
Epoch: 58 | Iteration number: [550/565] 97% | Training loss: 0.6880406377532265
Epoch: 58 | Iteration number: [560/565] 99% | Training loss: 0.6880203665367195

 End of epoch: 58 | Train Loss: 0.6867968693243719 | Training Time: 88 

 End of epoch: 58 | Eval Loss: 0.6895502550261361 | Evaluating Time: 6 
Epoch: 59 | Iteration number: [10/565] 1% | Training loss: 0.7552948296070099
Epoch: 59 | Iteration number: [20/565] 3% | Training loss: 0.7212154120206833
Epoch: 59 | Iteration number: [30/565] 5% | Training loss: 0.7098126073678335
Epoch: 59 | Iteration number: [40/565] 7% | Training loss: 0.7040757745504379
Epoch: 59 | Iteration number: [50/565] 8% | Training loss: 0.7005409944057465
Epoch: 59 | Iteration number: [60/565] 10% | Training loss: 0.6982220391432444
Epoch: 59 | Iteration number: [70/565] 12% | Training loss: 0.696647368158613
Epoch: 59 | Iteration number: [80/565] 14% | Training loss: 0.6954146318137646
Epoch: 59 | Iteration number: [90/565] 15% | Training loss: 0.6944488293594784
Epoch: 59 | Iteration number: [100/565] 17% | Training loss: 0.6936238926649093
Epoch: 59 | Iteration number: [110/565] 19% | Training loss: 0.6930179124528711
Epoch: 59 | Iteration number: [120/565] 21% | Training loss: 0.6924938842654228
Epoch: 59 | Iteration number: [130/565] 23% | Training loss: 0.6920669574003954
Epoch: 59 | Iteration number: [140/565] 24% | Training loss: 0.6917247887168612
Epoch: 59 | Iteration number: [150/565] 26% | Training loss: 0.6914194385210674
Epoch: 59 | Iteration number: [160/565] 28% | Training loss: 0.6911099217832088
Epoch: 59 | Iteration number: [170/565] 30% | Training loss: 0.6908327277968912
Epoch: 59 | Iteration number: [180/565] 31% | Training loss: 0.6905794150299496
Epoch: 59 | Iteration number: [190/565] 33% | Training loss: 0.6903902041284662
Epoch: 59 | Iteration number: [200/565] 35% | Training loss: 0.6902248659729957
Epoch: 59 | Iteration number: [210/565] 37% | Training loss: 0.6900698204835256
Epoch: 59 | Iteration number: [220/565] 38% | Training loss: 0.689919221943075
Epoch: 59 | Iteration number: [230/565] 40% | Training loss: 0.6897968419220136
Epoch: 59 | Iteration number: [240/565] 42% | Training loss: 0.6896712598701318
Epoch: 59 | Iteration number: [250/565] 44% | Training loss: 0.6895528683662414
Epoch: 59 | Iteration number: [260/565] 46% | Training loss: 0.6894667036258257
Epoch: 59 | Iteration number: [270/565] 47% | Training loss: 0.689366160719483
Epoch: 59 | Iteration number: [280/565] 49% | Training loss: 0.6892675380621638
Epoch: 59 | Iteration number: [290/565] 51% | Training loss: 0.689179793925121
Epoch: 59 | Iteration number: [300/565] 53% | Training loss: 0.6891146743297577
Epoch: 59 | Iteration number: [310/565] 54% | Training loss: 0.6890310933513026
Epoch: 59 | Iteration number: [320/565] 56% | Training loss: 0.6889580735936761
Epoch: 59 | Iteration number: [330/565] 58% | Training loss: 0.6888919870058695
Epoch: 59 | Iteration number: [340/565] 60% | Training loss: 0.6888229289475609
Epoch: 59 | Iteration number: [350/565] 61% | Training loss: 0.6887581336498261
Epoch: 59 | Iteration number: [360/565] 63% | Training loss: 0.6886982099877463
Epoch: 59 | Iteration number: [370/565] 65% | Training loss: 0.6886443036633569
Epoch: 59 | Iteration number: [380/565] 67% | Training loss: 0.6885975073826941
Epoch: 59 | Iteration number: [390/565] 69% | Training loss: 0.6885507884698037
Epoch: 59 | Iteration number: [400/565] 70% | Training loss: 0.6885010063648224
Epoch: 59 | Iteration number: [410/565] 72% | Training loss: 0.6884632632499788
Epoch: 59 | Iteration number: [420/565] 74% | Training loss: 0.688425306621052
Epoch: 59 | Iteration number: [430/565] 76% | Training loss: 0.6883916997632314
Epoch: 59 | Iteration number: [440/565] 77% | Training loss: 0.6883487438613718
Epoch: 59 | Iteration number: [450/565] 79% | Training loss: 0.6883240621619754
Epoch: 59 | Iteration number: [460/565] 81% | Training loss: 0.6882926372082337
Epoch: 59 | Iteration number: [470/565] 83% | Training loss: 0.6882619776624315
Epoch: 59 | Iteration number: [480/565] 84% | Training loss: 0.6882279086858034
Epoch: 59 | Iteration number: [490/565] 86% | Training loss: 0.6882048576462025
Epoch: 59 | Iteration number: [500/565] 88% | Training loss: 0.6881757072210312
Epoch: 59 | Iteration number: [510/565] 90% | Training loss: 0.688145060632743
Epoch: 59 | Iteration number: [520/565] 92% | Training loss: 0.6881234595408806
Epoch: 59 | Iteration number: [530/565] 93% | Training loss: 0.6881041958646954
Epoch: 59 | Iteration number: [540/565] 95% | Training loss: 0.6880756995192281
Epoch: 59 | Iteration number: [550/565] 97% | Training loss: 0.6880519257892261
Epoch: 59 | Iteration number: [560/565] 99% | Training loss: 0.6880322641560009

 End of epoch: 59 | Train Loss: 0.6868066808818716 | Training Time: 89 

 End of epoch: 59 | Eval Loss: 0.6902056847299848 | Evaluating Time: 6 
Epoch: 60 | Iteration number: [10/565] 1% | Training loss: 0.7554471373558045
Epoch: 60 | Iteration number: [20/565] 3% | Training loss: 0.7212820649147034
Epoch: 60 | Iteration number: [30/565] 5% | Training loss: 0.7097497920195261
Epoch: 60 | Iteration number: [40/565] 7% | Training loss: 0.7039308905601501
Epoch: 60 | Iteration number: [50/565] 8% | Training loss: 0.7005114090442658
Epoch: 60 | Iteration number: [60/565] 10% | Training loss: 0.6982368389765422
Epoch: 60 | Iteration number: [70/565] 12% | Training loss: 0.6965843141078949
Epoch: 60 | Iteration number: [80/565] 14% | Training loss: 0.6953537553548813
Epoch: 60 | Iteration number: [90/565] 15% | Training loss: 0.694415020942688
Epoch: 60 | Iteration number: [100/565] 17% | Training loss: 0.6936119413375854
Epoch: 60 | Iteration number: [110/565] 19% | Training loss: 0.6930407605387948
Epoch: 60 | Iteration number: [120/565] 21% | Training loss: 0.6925202051798502
Epoch: 60 | Iteration number: [130/565] 23% | Training loss: 0.6920811740251688
Epoch: 60 | Iteration number: [140/565] 24% | Training loss: 0.6917209305933544
Epoch: 60 | Iteration number: [150/565] 26% | Training loss: 0.6913919576009114
Epoch: 60 | Iteration number: [160/565] 28% | Training loss: 0.6911132737994194
Epoch: 60 | Iteration number: [170/565] 30% | Training loss: 0.6908513325102189
Epoch: 60 | Iteration number: [180/565] 31% | Training loss: 0.6906336747937732
Epoch: 60 | Iteration number: [190/565] 33% | Training loss: 0.6904291871346926
Epoch: 60 | Iteration number: [200/565] 35% | Training loss: 0.6902513489127159
Epoch: 60 | Iteration number: [210/565] 37% | Training loss: 0.6901001050358727
Epoch: 60 | Iteration number: [220/565] 38% | Training loss: 0.6899460556832226
Epoch: 60 | Iteration number: [230/565] 40% | Training loss: 0.6897905238296674
Epoch: 60 | Iteration number: [240/565] 42% | Training loss: 0.6896667085587979
Epoch: 60 | Iteration number: [250/565] 44% | Training loss: 0.689548172712326
Epoch: 60 | Iteration number: [260/565] 46% | Training loss: 0.6894441448725187
Epoch: 60 | Iteration number: [270/565] 47% | Training loss: 0.6893444761081978
Epoch: 60 | Iteration number: [280/565] 49% | Training loss: 0.6892655146973473
Epoch: 60 | Iteration number: [290/565] 51% | Training loss: 0.6891754520350489
Epoch: 60 | Iteration number: [300/565] 53% | Training loss: 0.6890891428788503
Epoch: 60 | Iteration number: [310/565] 54% | Training loss: 0.6890160948999466
Epoch: 60 | Iteration number: [320/565] 56% | Training loss: 0.6889506980776787
Epoch: 60 | Iteration number: [330/565] 58% | Training loss: 0.6888946572939555
Epoch: 60 | Iteration number: [340/565] 60% | Training loss: 0.6888301891439101
Epoch: 60 | Iteration number: [350/565] 61% | Training loss: 0.6887785748073033
Epoch: 60 | Iteration number: [360/565] 63% | Training loss: 0.6887118617693583
Epoch: 60 | Iteration number: [370/565] 65% | Training loss: 0.6886574582473651
Epoch: 60 | Iteration number: [380/565] 67% | Training loss: 0.688609024568608
Epoch: 60 | Iteration number: [390/565] 69% | Training loss: 0.6885543971489637
Epoch: 60 | Iteration number: [400/565] 70% | Training loss: 0.6885135892033577
Epoch: 60 | Iteration number: [410/565] 72% | Training loss: 0.6884764195942297
Epoch: 60 | Iteration number: [420/565] 74% | Training loss: 0.688434496380034
Epoch: 60 | Iteration number: [430/565] 76% | Training loss: 0.6884062036525371
Epoch: 60 | Iteration number: [440/565] 77% | Training loss: 0.6883716573769396
Epoch: 60 | Iteration number: [450/565] 79% | Training loss: 0.6883379961384667
Epoch: 60 | Iteration number: [460/565] 81% | Training loss: 0.6882964195116706
Epoch: 60 | Iteration number: [470/565] 83% | Training loss: 0.6882583402572794
Epoch: 60 | Iteration number: [480/565] 84% | Training loss: 0.6882300184418758
Epoch: 60 | Iteration number: [490/565] 86% | Training loss: 0.6881911615936124
Epoch: 60 | Iteration number: [500/565] 88% | Training loss: 0.6881631419658661
Epoch: 60 | Iteration number: [510/565] 90% | Training loss: 0.6881390411479801
Epoch: 60 | Iteration number: [520/565] 92% | Training loss: 0.6881194782944826
Epoch: 60 | Iteration number: [530/565] 93% | Training loss: 0.6880960407122126
Epoch: 60 | Iteration number: [540/565] 95% | Training loss: 0.6880711420818612
Epoch: 60 | Iteration number: [550/565] 97% | Training loss: 0.6880433085831729
Epoch: 60 | Iteration number: [560/565] 99% | Training loss: 0.6880261367985181

 End of epoch: 60 | Train Loss: 0.686798277048938 | Training Time: 89 

 End of epoch: 60 | Eval Loss: 0.6901312385286603 | Evaluating Time: 6 
Epoch: 61 | Iteration number: [10/565] 1% | Training loss: 0.7554159462451935
Epoch: 61 | Iteration number: [20/565] 3% | Training loss: 0.7211834549903869
Epoch: 61 | Iteration number: [30/565] 5% | Training loss: 0.7097584962844848
Epoch: 61 | Iteration number: [40/565] 7% | Training loss: 0.7039645805954933
Epoch: 61 | Iteration number: [50/565] 8% | Training loss: 0.7005759882926941
Epoch: 61 | Iteration number: [60/565] 10% | Training loss: 0.6981873373190562
Epoch: 61 | Iteration number: [70/565] 12% | Training loss: 0.6966044034276689
Epoch: 61 | Iteration number: [80/565] 14% | Training loss: 0.6954037092626095
Epoch: 61 | Iteration number: [90/565] 15% | Training loss: 0.6944427205456628
Epoch: 61 | Iteration number: [100/565] 17% | Training loss: 0.6936707955598831
Epoch: 61 | Iteration number: [110/565] 19% | Training loss: 0.693047139861367
Epoch: 61 | Iteration number: [120/565] 21% | Training loss: 0.6925335988402367
Epoch: 61 | Iteration number: [130/565] 23% | Training loss: 0.6920748550158281
Epoch: 61 | Iteration number: [140/565] 24% | Training loss: 0.6916953887258257
Epoch: 61 | Iteration number: [150/565] 26% | Training loss: 0.691342890659968
Epoch: 61 | Iteration number: [160/565] 28% | Training loss: 0.69104970023036
Epoch: 61 | Iteration number: [170/565] 30% | Training loss: 0.6907956982360167
Epoch: 61 | Iteration number: [180/565] 31% | Training loss: 0.6905897594160504
Epoch: 61 | Iteration number: [190/565] 33% | Training loss: 0.6903853410168698
Epoch: 61 | Iteration number: [200/565] 35% | Training loss: 0.690197186768055
Epoch: 61 | Iteration number: [210/565] 37% | Training loss: 0.690040295464652
Epoch: 61 | Iteration number: [220/565] 38% | Training loss: 0.6898884822021831
Epoch: 61 | Iteration number: [230/565] 40% | Training loss: 0.6897719862668411
Epoch: 61 | Iteration number: [240/565] 42% | Training loss: 0.6896416982014973
Epoch: 61 | Iteration number: [250/565] 44% | Training loss: 0.689526606798172
Epoch: 61 | Iteration number: [260/565] 46% | Training loss: 0.6894102504620185
Epoch: 61 | Iteration number: [270/565] 47% | Training loss: 0.6892941309346093
Epoch: 61 | Iteration number: [280/565] 49% | Training loss: 0.6891854352184704
Epoch: 61 | Iteration number: [290/565] 51% | Training loss: 0.6891083141853069
Epoch: 61 | Iteration number: [300/565] 53% | Training loss: 0.6890193003416062
Epoch: 61 | Iteration number: [310/565] 54% | Training loss: 0.6889623518913023
Epoch: 61 | Iteration number: [320/565] 56% | Training loss: 0.6889037685468793
Epoch: 61 | Iteration number: [330/565] 58% | Training loss: 0.6888510698621924
Epoch: 61 | Iteration number: [340/565] 60% | Training loss: 0.6887925065615598
Epoch: 61 | Iteration number: [350/565] 61% | Training loss: 0.6887408321244376
Epoch: 61 | Iteration number: [360/565] 63% | Training loss: 0.688686158756415
Epoch: 61 | Iteration number: [370/565] 65% | Training loss: 0.6886319363439405
Epoch: 61 | Iteration number: [380/565] 67% | Training loss: 0.6885792959677546
Epoch: 61 | Iteration number: [390/565] 69% | Training loss: 0.6885369808245928
Epoch: 61 | Iteration number: [400/565] 70% | Training loss: 0.6884963871538639
Epoch: 61 | Iteration number: [410/565] 72% | Training loss: 0.6884509955964437
Epoch: 61 | Iteration number: [420/565] 74% | Training loss: 0.6884097513698396
Epoch: 61 | Iteration number: [430/565] 76% | Training loss: 0.6883614922678748
Epoch: 61 | Iteration number: [440/565] 77% | Training loss: 0.6883318258957429
Epoch: 61 | Iteration number: [450/565] 79% | Training loss: 0.6883086245589786
Epoch: 61 | Iteration number: [460/565] 81% | Training loss: 0.6882846959259199
Epoch: 61 | Iteration number: [470/565] 83% | Training loss: 0.6882543709683926
Epoch: 61 | Iteration number: [480/565] 84% | Training loss: 0.688220472758015
Epoch: 61 | Iteration number: [490/565] 86% | Training loss: 0.688184288448217
Epoch: 61 | Iteration number: [500/565] 88% | Training loss: 0.6881637464761734
Epoch: 61 | Iteration number: [510/565] 90% | Training loss: 0.688142461052128
Epoch: 61 | Iteration number: [520/565] 92% | Training loss: 0.6881127052582228
Epoch: 61 | Iteration number: [530/565] 93% | Training loss: 0.6880932937253196
Epoch: 61 | Iteration number: [540/565] 95% | Training loss: 0.6880831742728198
Epoch: 61 | Iteration number: [550/565] 97% | Training loss: 0.6880619011142037
Epoch: 61 | Iteration number: [560/565] 99% | Training loss: 0.6880346624978951

 End of epoch: 61 | Train Loss: 0.6868050606904832 | Training Time: 89 

 End of epoch: 61 | Eval Loss: 0.6894346220152718 | Evaluating Time: 6 
Epoch: 62 | Iteration number: [10/565] 1% | Training loss: 0.7556316316127777
Epoch: 62 | Iteration number: [20/565] 3% | Training loss: 0.7212224811315536
Epoch: 62 | Iteration number: [30/565] 5% | Training loss: 0.7096533715724945
Epoch: 62 | Iteration number: [40/565] 7% | Training loss: 0.7040508896112442
Epoch: 62 | Iteration number: [50/565] 8% | Training loss: 0.7006275498867035
Epoch: 62 | Iteration number: [60/565] 10% | Training loss: 0.6982514023780823
Epoch: 62 | Iteration number: [70/565] 12% | Training loss: 0.6966844694955009
Epoch: 62 | Iteration number: [80/565] 14% | Training loss: 0.6954546853899956
Epoch: 62 | Iteration number: [90/565] 15% | Training loss: 0.6944894611835479
Epoch: 62 | Iteration number: [100/565] 17% | Training loss: 0.6937494260072709
Epoch: 62 | Iteration number: [110/565] 19% | Training loss: 0.6931381501934745
Epoch: 62 | Iteration number: [120/565] 21% | Training loss: 0.6925999214251836
Epoch: 62 | Iteration number: [130/565] 23% | Training loss: 0.6921610222412989
Epoch: 62 | Iteration number: [140/565] 24% | Training loss: 0.6917797441993441
Epoch: 62 | Iteration number: [150/565] 26% | Training loss: 0.6914474181334178
Epoch: 62 | Iteration number: [160/565] 28% | Training loss: 0.6911586113274097
Epoch: 62 | Iteration number: [170/565] 30% | Training loss: 0.690919356135761
Epoch: 62 | Iteration number: [180/565] 31% | Training loss: 0.690708808766471
Epoch: 62 | Iteration number: [190/565] 33% | Training loss: 0.6904840729738536
Epoch: 62 | Iteration number: [200/565] 35% | Training loss: 0.6903097799420357
Epoch: 62 | Iteration number: [210/565] 37% | Training loss: 0.6901474620614733
Epoch: 62 | Iteration number: [220/565] 38% | Training loss: 0.6899816876107996
Epoch: 62 | Iteration number: [230/565] 40% | Training loss: 0.6898410791936128
Epoch: 62 | Iteration number: [240/565] 42% | Training loss: 0.6897222655514876
Epoch: 62 | Iteration number: [250/565] 44% | Training loss: 0.6896188247203827
Epoch: 62 | Iteration number: [260/565] 46% | Training loss: 0.6895074186416773
Epoch: 62 | Iteration number: [270/565] 47% | Training loss: 0.6893842418988546
Epoch: 62 | Iteration number: [280/565] 49% | Training loss: 0.6892699827040945
Epoch: 62 | Iteration number: [290/565] 51% | Training loss: 0.6891715380652198
Epoch: 62 | Iteration number: [300/565] 53% | Training loss: 0.6890730053186417
Epoch: 62 | Iteration number: [310/565] 54% | Training loss: 0.6890052810792
Epoch: 62 | Iteration number: [320/565] 56% | Training loss: 0.688925719447434
Epoch: 62 | Iteration number: [330/565] 58% | Training loss: 0.6888622618082798
Epoch: 62 | Iteration number: [340/565] 60% | Training loss: 0.6888009756803513
Epoch: 62 | Iteration number: [350/565] 61% | Training loss: 0.688752749306815
Epoch: 62 | Iteration number: [360/565] 63% | Training loss: 0.6887118842866685
Epoch: 62 | Iteration number: [370/565] 65% | Training loss: 0.6886637860053294
Epoch: 62 | Iteration number: [380/565] 67% | Training loss: 0.6886270720707742
Epoch: 62 | Iteration number: [390/565] 69% | Training loss: 0.6885738470615484
Epoch: 62 | Iteration number: [400/565] 70% | Training loss: 0.6885225600004197
Epoch: 62 | Iteration number: [410/565] 72% | Training loss: 0.6884723994790054
Epoch: 62 | Iteration number: [420/565] 74% | Training loss: 0.6884282641467594
Epoch: 62 | Iteration number: [430/565] 76% | Training loss: 0.6884010930394018
Epoch: 62 | Iteration number: [440/565] 77% | Training loss: 0.6883724921128966
Epoch: 62 | Iteration number: [450/565] 79% | Training loss: 0.6883405233754052
Epoch: 62 | Iteration number: [460/565] 81% | Training loss: 0.6883002838362818
Epoch: 62 | Iteration number: [470/565] 83% | Training loss: 0.688270540059881
Epoch: 62 | Iteration number: [480/565] 84% | Training loss: 0.6882328666746617
Epoch: 62 | Iteration number: [490/565] 86% | Training loss: 0.6881970748609426
Epoch: 62 | Iteration number: [500/565] 88% | Training loss: 0.6881641113758087
Epoch: 62 | Iteration number: [510/565] 90% | Training loss: 0.6881439171585382
Epoch: 62 | Iteration number: [520/565] 92% | Training loss: 0.6881180671545175
Epoch: 62 | Iteration number: [530/565] 93% | Training loss: 0.6881038344131326
Epoch: 62 | Iteration number: [540/565] 95% | Training loss: 0.6880823377105925
Epoch: 62 | Iteration number: [550/565] 97% | Training loss: 0.6880545829642902
Epoch: 62 | Iteration number: [560/565] 99% | Training loss: 0.6880309549825532

 End of epoch: 62 | Train Loss: 0.6868016984610431 | Training Time: 88 

 End of epoch: 62 | Eval Loss: 0.6901163629123143 | Evaluating Time: 6 
Epoch: 63 | Iteration number: [10/565] 1% | Training loss: 0.7554837882518768
Epoch: 63 | Iteration number: [20/565] 3% | Training loss: 0.7211642503738404
Epoch: 63 | Iteration number: [30/565] 5% | Training loss: 0.7099343160788218
Epoch: 63 | Iteration number: [40/565] 7% | Training loss: 0.704176053404808
Epoch: 63 | Iteration number: [50/565] 8% | Training loss: 0.7006157052516937
Epoch: 63 | Iteration number: [60/565] 10% | Training loss: 0.6983734289805095
Epoch: 63 | Iteration number: [70/565] 12% | Training loss: 0.6966826413358961
Epoch: 63 | Iteration number: [80/565] 14% | Training loss: 0.695423249900341
Epoch: 63 | Iteration number: [90/565] 15% | Training loss: 0.6944506678316328
Epoch: 63 | Iteration number: [100/565] 17% | Training loss: 0.6937166953086853
Epoch: 63 | Iteration number: [110/565] 19% | Training loss: 0.6930668657476252
Epoch: 63 | Iteration number: [120/565] 21% | Training loss: 0.6925337865948678
Epoch: 63 | Iteration number: [130/565] 23% | Training loss: 0.6921008252180539
Epoch: 63 | Iteration number: [140/565] 24% | Training loss: 0.6917141224656786
Epoch: 63 | Iteration number: [150/565] 26% | Training loss: 0.691378519932429
Epoch: 63 | Iteration number: [160/565] 28% | Training loss: 0.6910735491663218
Epoch: 63 | Iteration number: [170/565] 30% | Training loss: 0.6908346877378576
Epoch: 63 | Iteration number: [180/565] 31% | Training loss: 0.6906123754050997
Epoch: 63 | Iteration number: [190/565] 33% | Training loss: 0.6903875382323014
Epoch: 63 | Iteration number: [200/565] 35% | Training loss: 0.6901892879605294
Epoch: 63 | Iteration number: [210/565] 37% | Training loss: 0.6900389773505075
Epoch: 63 | Iteration number: [220/565] 38% | Training loss: 0.6899044063958255
Epoch: 63 | Iteration number: [230/565] 40% | Training loss: 0.689754732536233
Epoch: 63 | Iteration number: [240/565] 42% | Training loss: 0.689665338397026
Epoch: 63 | Iteration number: [250/565] 44% | Training loss: 0.6895543975830078
Epoch: 63 | Iteration number: [260/565] 46% | Training loss: 0.6894655582996515
Epoch: 63 | Iteration number: [270/565] 47% | Training loss: 0.6893848255828575
Epoch: 63 | Iteration number: [280/565] 49% | Training loss: 0.6892852221216474
Epoch: 63 | Iteration number: [290/565] 51% | Training loss: 0.6891880298482961
Epoch: 63 | Iteration number: [300/565] 53% | Training loss: 0.6891062521934509
Epoch: 63 | Iteration number: [310/565] 54% | Training loss: 0.6890312731266022
Epoch: 63 | Iteration number: [320/565] 56% | Training loss: 0.6889606188982725
Epoch: 63 | Iteration number: [330/565] 58% | Training loss: 0.6888952484636596
Epoch: 63 | Iteration number: [340/565] 60% | Training loss: 0.6888326071641024
Epoch: 63 | Iteration number: [350/565] 61% | Training loss: 0.6887681513173239
Epoch: 63 | Iteration number: [360/565] 63% | Training loss: 0.688727286292447
Epoch: 63 | Iteration number: [370/565] 65% | Training loss: 0.6886747469773163
Epoch: 63 | Iteration number: [380/565] 67% | Training loss: 0.6886195462000998
Epoch: 63 | Iteration number: [390/565] 69% | Training loss: 0.6885680201726082
Epoch: 63 | Iteration number: [400/565] 70% | Training loss: 0.6885254347324371
Epoch: 63 | Iteration number: [410/565] 72% | Training loss: 0.6884738407483915
Epoch: 63 | Iteration number: [420/565] 74% | Training loss: 0.6884349746363504
Epoch: 63 | Iteration number: [430/565] 76% | Training loss: 0.6883935150712035
Epoch: 63 | Iteration number: [440/565] 77% | Training loss: 0.6883456723256545
Epoch: 63 | Iteration number: [450/565] 79% | Training loss: 0.688314152956009
Epoch: 63 | Iteration number: [460/565] 81% | Training loss: 0.6882874574350274
Epoch: 63 | Iteration number: [470/565] 83% | Training loss: 0.6882597235923118
Epoch: 63 | Iteration number: [480/565] 84% | Training loss: 0.688230567301313
Epoch: 63 | Iteration number: [490/565] 86% | Training loss: 0.6881980335225865
Epoch: 63 | Iteration number: [500/565] 88% | Training loss: 0.6881695582866668
Epoch: 63 | Iteration number: [510/565] 90% | Training loss: 0.6881427722818712
Epoch: 63 | Iteration number: [520/565] 92% | Training loss: 0.6881200798428976
Epoch: 63 | Iteration number: [530/565] 93% | Training loss: 0.6880870597542457
Epoch: 63 | Iteration number: [540/565] 95% | Training loss: 0.6880617555644777
Epoch: 63 | Iteration number: [550/565] 97% | Training loss: 0.6880431058190085
Epoch: 63 | Iteration number: [560/565] 99% | Training loss: 0.6880202192280974

 End of epoch: 63 | Train Loss: 0.6867908181342404 | Training Time: 89 

 End of epoch: 63 | Eval Loss: 0.6899253896304539 | Evaluating Time: 5 
Epoch: 64 | Iteration number: [10/565] 1% | Training loss: 0.7553921163082122
Epoch: 64 | Iteration number: [20/565] 3% | Training loss: 0.7213117271661759
Epoch: 64 | Iteration number: [30/565] 5% | Training loss: 0.7096991618474324
Epoch: 64 | Iteration number: [40/565] 7% | Training loss: 0.7040014326572418
Epoch: 64 | Iteration number: [50/565] 8% | Training loss: 0.7005744040012359
Epoch: 64 | Iteration number: [60/565] 10% | Training loss: 0.6982755651076634
Epoch: 64 | Iteration number: [70/565] 12% | Training loss: 0.6967062592506409
Epoch: 64 | Iteration number: [80/565] 14% | Training loss: 0.6954284839332103
Epoch: 64 | Iteration number: [90/565] 15% | Training loss: 0.6944411396980286
Epoch: 64 | Iteration number: [100/565] 17% | Training loss: 0.6936622583866119
Epoch: 64 | Iteration number: [110/565] 19% | Training loss: 0.6930141909555956
Epoch: 64 | Iteration number: [120/565] 21% | Training loss: 0.6925183261434237
Epoch: 64 | Iteration number: [130/565] 23% | Training loss: 0.6920711416464586
Epoch: 64 | Iteration number: [140/565] 24% | Training loss: 0.6917095933641706
Epoch: 64 | Iteration number: [150/565] 26% | Training loss: 0.69137881676356
Epoch: 64 | Iteration number: [160/565] 28% | Training loss: 0.6910732764750719
Epoch: 64 | Iteration number: [170/565] 30% | Training loss: 0.6908277641324436
Epoch: 64 | Iteration number: [180/565] 31% | Training loss: 0.690586456656456
Epoch: 64 | Iteration number: [190/565] 33% | Training loss: 0.6903652385661476
Epoch: 64 | Iteration number: [200/565] 35% | Training loss: 0.6901800191402435
Epoch: 64 | Iteration number: [210/565] 37% | Training loss: 0.6900296898115249
Epoch: 64 | Iteration number: [220/565] 38% | Training loss: 0.689883293075995
Epoch: 64 | Iteration number: [230/565] 40% | Training loss: 0.689759363817132
Epoch: 64 | Iteration number: [240/565] 42% | Training loss: 0.6896255381405354
Epoch: 64 | Iteration number: [250/565] 44% | Training loss: 0.6895267872810363
Epoch: 64 | Iteration number: [260/565] 46% | Training loss: 0.6894107924057887
Epoch: 64 | Iteration number: [270/565] 47% | Training loss: 0.6893150545932628
Epoch: 64 | Iteration number: [280/565] 49% | Training loss: 0.68922425785235
Epoch: 64 | Iteration number: [290/565] 51% | Training loss: 0.6891437396920961
Epoch: 64 | Iteration number: [300/565] 53% | Training loss: 0.6890694459279378
Epoch: 64 | Iteration number: [310/565] 54% | Training loss: 0.6890009316705888
Epoch: 64 | Iteration number: [320/565] 56% | Training loss: 0.6889472244307399
Epoch: 64 | Iteration number: [330/565] 58% | Training loss: 0.6888732940861673
Epoch: 64 | Iteration number: [340/565] 60% | Training loss: 0.6888047703925301
Epoch: 64 | Iteration number: [350/565] 61% | Training loss: 0.6887550868306841
Epoch: 64 | Iteration number: [360/565] 63% | Training loss: 0.6886967144078678
Epoch: 64 | Iteration number: [370/565] 65% | Training loss: 0.6886351369522713
Epoch: 64 | Iteration number: [380/565] 67% | Training loss: 0.6885911737617694
Epoch: 64 | Iteration number: [390/565] 69% | Training loss: 0.6885463917866731
Epoch: 64 | Iteration number: [400/565] 70% | Training loss: 0.6885146038234233
Epoch: 64 | Iteration number: [410/565] 72% | Training loss: 0.688475410676584
Epoch: 64 | Iteration number: [420/565] 74% | Training loss: 0.6884247347002938
Epoch: 64 | Iteration number: [430/565] 76% | Training loss: 0.6883721093798792
Epoch: 64 | Iteration number: [440/565] 77% | Training loss: 0.6883305884220383
Epoch: 64 | Iteration number: [450/565] 79% | Training loss: 0.68830127120018
Epoch: 64 | Iteration number: [460/565] 81% | Training loss: 0.688272580763568
Epoch: 64 | Iteration number: [470/565] 83% | Training loss: 0.6882318444708561
Epoch: 64 | Iteration number: [480/565] 84% | Training loss: 0.6882004705568154
Epoch: 64 | Iteration number: [490/565] 86% | Training loss: 0.6881764966614392
Epoch: 64 | Iteration number: [500/565] 88% | Training loss: 0.6881474548578262
Epoch: 64 | Iteration number: [510/565] 90% | Training loss: 0.6881278394484053
Epoch: 64 | Iteration number: [520/565] 92% | Training loss: 0.6881097398125209
Epoch: 64 | Iteration number: [530/565] 93% | Training loss: 0.6880837070492078
Epoch: 64 | Iteration number: [540/565] 95% | Training loss: 0.6880561881595187
Epoch: 64 | Iteration number: [550/565] 97% | Training loss: 0.6880333595926111
Epoch: 64 | Iteration number: [560/565] 99% | Training loss: 0.6880069825266089

 End of epoch: 64 | Train Loss: 0.6867857385525661 | Training Time: 89 

 End of epoch: 64 | Eval Loss: 0.6896441578865051 | Evaluating Time: 6 
Epoch: 65 | Iteration number: [10/565] 1% | Training loss: 0.7551954388618469
Epoch: 65 | Iteration number: [20/565] 3% | Training loss: 0.7212499678134918
Epoch: 65 | Iteration number: [30/565] 5% | Training loss: 0.7097363670667013
Epoch: 65 | Iteration number: [40/565] 7% | Training loss: 0.703935919702053
Epoch: 65 | Iteration number: [50/565] 8% | Training loss: 0.7004992890357972
Epoch: 65 | Iteration number: [60/565] 10% | Training loss: 0.6982030878464381
Epoch: 65 | Iteration number: [70/565] 12% | Training loss: 0.6966079609734671
Epoch: 65 | Iteration number: [80/565] 14% | Training loss: 0.6953538805246353
Epoch: 65 | Iteration number: [90/565] 15% | Training loss: 0.6944398436281416
Epoch: 65 | Iteration number: [100/565] 17% | Training loss: 0.6936371177434921
Epoch: 65 | Iteration number: [110/565] 19% | Training loss: 0.6930339450185949
Epoch: 65 | Iteration number: [120/565] 21% | Training loss: 0.6925292467077573
Epoch: 65 | Iteration number: [130/565] 23% | Training loss: 0.69210507778021
Epoch: 65 | Iteration number: [140/565] 24% | Training loss: 0.6917384492499488
Epoch: 65 | Iteration number: [150/565] 26% | Training loss: 0.6914140160878499
Epoch: 65 | Iteration number: [160/565] 28% | Training loss: 0.6911170035600662
Epoch: 65 | Iteration number: [170/565] 30% | Training loss: 0.6908476226470049
Epoch: 65 | Iteration number: [180/565] 31% | Training loss: 0.690636756685045
Epoch: 65 | Iteration number: [190/565] 33% | Training loss: 0.6904169534382067
Epoch: 65 | Iteration number: [200/565] 35% | Training loss: 0.690217810869217
Epoch: 65 | Iteration number: [210/565] 37% | Training loss: 0.6900738369850885
Epoch: 65 | Iteration number: [220/565] 38% | Training loss: 0.689929260448976
Epoch: 65 | Iteration number: [230/565] 40% | Training loss: 0.6897778938645902
Epoch: 65 | Iteration number: [240/565] 42% | Training loss: 0.6896544759472211
Epoch: 65 | Iteration number: [250/565] 44% | Training loss: 0.689547117471695
Epoch: 65 | Iteration number: [260/565] 46% | Training loss: 0.6894428597046779
Epoch: 65 | Iteration number: [270/565] 47% | Training loss: 0.6893714273417437
Epoch: 65 | Iteration number: [280/565] 49% | Training loss: 0.6892771854996681
Epoch: 65 | Iteration number: [290/565] 51% | Training loss: 0.6891779449479333
Epoch: 65 | Iteration number: [300/565] 53% | Training loss: 0.6890921650330225
Epoch: 65 | Iteration number: [310/565] 54% | Training loss: 0.6890205779383259
Epoch: 65 | Iteration number: [320/565] 56% | Training loss: 0.6889589842408895
Epoch: 65 | Iteration number: [330/565] 58% | Training loss: 0.6888829166238958
Epoch: 65 | Iteration number: [340/565] 60% | Training loss: 0.6888134023722481
Epoch: 65 | Iteration number: [350/565] 61% | Training loss: 0.6887603310176305
Epoch: 65 | Iteration number: [360/565] 63% | Training loss: 0.6887064865893788
Epoch: 65 | Iteration number: [370/565] 65% | Training loss: 0.6886560799302281
Epoch: 65 | Iteration number: [380/565] 67% | Training loss: 0.6886128827145225
Epoch: 65 | Iteration number: [390/565] 69% | Training loss: 0.6885554738533802
Epoch: 65 | Iteration number: [400/565] 70% | Training loss: 0.6885159161686897
Epoch: 65 | Iteration number: [410/565] 72% | Training loss: 0.6884649237481559
Epoch: 65 | Iteration number: [420/565] 74% | Training loss: 0.6884310904003325
Epoch: 65 | Iteration number: [430/565] 76% | Training loss: 0.688393930778947
Epoch: 65 | Iteration number: [440/565] 77% | Training loss: 0.6883485462177884
Epoch: 65 | Iteration number: [450/565] 79% | Training loss: 0.6883201645480261
Epoch: 65 | Iteration number: [460/565] 81% | Training loss: 0.6882845961529276
Epoch: 65 | Iteration number: [470/565] 83% | Training loss: 0.6882524410460857
Epoch: 65 | Iteration number: [480/565] 84% | Training loss: 0.6882324938972791
Epoch: 65 | Iteration number: [490/565] 86% | Training loss: 0.6882070247007877
Epoch: 65 | Iteration number: [500/565] 88% | Training loss: 0.6881769671440124
Epoch: 65 | Iteration number: [510/565] 90% | Training loss: 0.688152960468741
Epoch: 65 | Iteration number: [520/565] 92% | Training loss: 0.6881222942700753
Epoch: 65 | Iteration number: [530/565] 93% | Training loss: 0.688098191877581
Epoch: 65 | Iteration number: [540/565] 95% | Training loss: 0.688072685069508
Epoch: 65 | Iteration number: [550/565] 97% | Training loss: 0.6880445961518721
Epoch: 65 | Iteration number: [560/565] 99% | Training loss: 0.6880202292331628

 End of epoch: 65 | Train Loss: 0.6867888181610445 | Training Time: 89 

 End of epoch: 65 | Eval Loss: 0.6896741986274719 | Evaluating Time: 6 
Epoch: 66 | Iteration number: [10/565] 1% | Training loss: 0.7551085889339447
Epoch: 66 | Iteration number: [20/565] 3% | Training loss: 0.7209712654352188
Epoch: 66 | Iteration number: [30/565] 5% | Training loss: 0.70973695119222
Epoch: 66 | Iteration number: [40/565] 7% | Training loss: 0.7041223004460335
Epoch: 66 | Iteration number: [50/565] 8% | Training loss: 0.7006032907962799
Epoch: 66 | Iteration number: [60/565] 10% | Training loss: 0.6982235332330068
Epoch: 66 | Iteration number: [70/565] 12% | Training loss: 0.6965205584253583
Epoch: 66 | Iteration number: [80/565] 14% | Training loss: 0.6953033380210399
Epoch: 66 | Iteration number: [90/565] 15% | Training loss: 0.694324846400155
Epoch: 66 | Iteration number: [100/565] 17% | Training loss: 0.6935956537723541
Epoch: 66 | Iteration number: [110/565] 19% | Training loss: 0.6929848638447849
Epoch: 66 | Iteration number: [120/565] 21% | Training loss: 0.6924641336003939
Epoch: 66 | Iteration number: [130/565] 23% | Training loss: 0.6920106640228858
Epoch: 66 | Iteration number: [140/565] 24% | Training loss: 0.6916482384715762
Epoch: 66 | Iteration number: [150/565] 26% | Training loss: 0.691364045937856
Epoch: 66 | Iteration number: [160/565] 28% | Training loss: 0.6910757824778557
Epoch: 66 | Iteration number: [170/565] 30% | Training loss: 0.6908024847507477
Epoch: 66 | Iteration number: [180/565] 31% | Training loss: 0.690548930896653
Epoch: 66 | Iteration number: [190/565] 33% | Training loss: 0.6903528279379795
Epoch: 66 | Iteration number: [200/565] 35% | Training loss: 0.6901725187897683
Epoch: 66 | Iteration number: [210/565] 37% | Training loss: 0.6900134847277687
Epoch: 66 | Iteration number: [220/565] 38% | Training loss: 0.6898633423176679
Epoch: 66 | Iteration number: [230/565] 40% | Training loss: 0.6897372821102972
Epoch: 66 | Iteration number: [240/565] 42% | Training loss: 0.6896039808789889
Epoch: 66 | Iteration number: [250/565] 44% | Training loss: 0.6894872262477875
Epoch: 66 | Iteration number: [260/565] 46% | Training loss: 0.6893853925741635
Epoch: 66 | Iteration number: [270/565] 47% | Training loss: 0.6892862163208149
Epoch: 66 | Iteration number: [280/565] 49% | Training loss: 0.6891874898757253
Epoch: 66 | Iteration number: [290/565] 51% | Training loss: 0.6891141013852481
Epoch: 66 | Iteration number: [300/565] 53% | Training loss: 0.6890405456225077
Epoch: 66 | Iteration number: [310/565] 54% | Training loss: 0.688980721658276
Epoch: 66 | Iteration number: [320/565] 56% | Training loss: 0.6888999523594975
Epoch: 66 | Iteration number: [330/565] 58% | Training loss: 0.6888339696508465
Epoch: 66 | Iteration number: [340/565] 60% | Training loss: 0.6887813506757512
Epoch: 66 | Iteration number: [350/565] 61% | Training loss: 0.6887268577303205
Epoch: 66 | Iteration number: [360/565] 63% | Training loss: 0.6886776371134652
Epoch: 66 | Iteration number: [370/565] 65% | Training loss: 0.6886206573731191
Epoch: 66 | Iteration number: [380/565] 67% | Training loss: 0.6885727451035851
Epoch: 66 | Iteration number: [390/565] 69% | Training loss: 0.6885329654583564
Epoch: 66 | Iteration number: [400/565] 70% | Training loss: 0.6884927439689636
Epoch: 66 | Iteration number: [410/565] 72% | Training loss: 0.6884595759031249
Epoch: 66 | Iteration number: [420/565] 74% | Training loss: 0.6884223454055332
Epoch: 66 | Iteration number: [430/565] 76% | Training loss: 0.6883790214394414
Epoch: 66 | Iteration number: [440/565] 77% | Training loss: 0.6883443982763724
Epoch: 66 | Iteration number: [450/565] 79% | Training loss: 0.6883203698529138
Epoch: 66 | Iteration number: [460/565] 81% | Training loss: 0.6882828983275787
Epoch: 66 | Iteration number: [470/565] 83% | Training loss: 0.6882552491857651
Epoch: 66 | Iteration number: [480/565] 84% | Training loss: 0.6882231609274944
Epoch: 66 | Iteration number: [490/565] 86% | Training loss: 0.6881936473505837
Epoch: 66 | Iteration number: [500/565] 88% | Training loss: 0.6881661351919174
Epoch: 66 | Iteration number: [510/565] 90% | Training loss: 0.6881446850066092
Epoch: 66 | Iteration number: [520/565] 92% | Training loss: 0.6881148963020398
Epoch: 66 | Iteration number: [530/565] 93% | Training loss: 0.6880949483727509
Epoch: 66 | Iteration number: [540/565] 95% | Training loss: 0.6880776467146696
Epoch: 66 | Iteration number: [550/565] 97% | Training loss: 0.6880454604192213
Epoch: 66 | Iteration number: [560/565] 99% | Training loss: 0.6880229456084115

 End of epoch: 66 | Train Loss: 0.6867977084311764 | Training Time: 89 

 End of epoch: 66 | Eval Loss: 0.6898500578744071 | Evaluating Time: 6 
Epoch: 67 | Iteration number: [10/565] 1% | Training loss: 0.7555594921112061
Epoch: 67 | Iteration number: [20/565] 3% | Training loss: 0.7213662475347519
Epoch: 67 | Iteration number: [30/565] 5% | Training loss: 0.7100645045439402
Epoch: 67 | Iteration number: [40/565] 7% | Training loss: 0.7041783690452575
Epoch: 67 | Iteration number: [50/565] 8% | Training loss: 0.7007749140262604
Epoch: 67 | Iteration number: [60/565] 10% | Training loss: 0.698356048266093
Epoch: 67 | Iteration number: [70/565] 12% | Training loss: 0.6967060267925262
Epoch: 67 | Iteration number: [80/565] 14% | Training loss: 0.6954857937991619
Epoch: 67 | Iteration number: [90/565] 15% | Training loss: 0.6945215735170577
Epoch: 67 | Iteration number: [100/565] 17% | Training loss: 0.6938026911020279
Epoch: 67 | Iteration number: [110/565] 19% | Training loss: 0.6932033078237013
Epoch: 67 | Iteration number: [120/565] 21% | Training loss: 0.6926805421710014
Epoch: 67 | Iteration number: [130/565] 23% | Training loss: 0.6922059733134049
Epoch: 67 | Iteration number: [140/565] 24% | Training loss: 0.6917760482856206
Epoch: 67 | Iteration number: [150/565] 26% | Training loss: 0.6914185762405396
Epoch: 67 | Iteration number: [160/565] 28% | Training loss: 0.6911267939954996
Epoch: 67 | Iteration number: [170/565] 30% | Training loss: 0.69086973491837
Epoch: 67 | Iteration number: [180/565] 31% | Training loss: 0.6906494581037097
Epoch: 67 | Iteration number: [190/565] 33% | Training loss: 0.6904350425067701
Epoch: 67 | Iteration number: [200/565] 35% | Training loss: 0.6902491557598114
Epoch: 67 | Iteration number: [210/565] 37% | Training loss: 0.6901051027434213
Epoch: 67 | Iteration number: [220/565] 38% | Training loss: 0.6899533854289488
Epoch: 67 | Iteration number: [230/565] 40% | Training loss: 0.6898112229678942
Epoch: 67 | Iteration number: [240/565] 42% | Training loss: 0.6896970085799694
Epoch: 67 | Iteration number: [250/565] 44% | Training loss: 0.6895799717903137
Epoch: 67 | Iteration number: [260/565] 46% | Training loss: 0.6894723905966832
Epoch: 67 | Iteration number: [270/565] 47% | Training loss: 0.689366732261799
Epoch: 67 | Iteration number: [280/565] 49% | Training loss: 0.6892858907580376
Epoch: 67 | Iteration number: [290/565] 51% | Training loss: 0.6891900907302725
Epoch: 67 | Iteration number: [300/565] 53% | Training loss: 0.6891048187017441
Epoch: 67 | Iteration number: [310/565] 54% | Training loss: 0.6890260452224363
Epoch: 67 | Iteration number: [320/565] 56% | Training loss: 0.6889514572918415
Epoch: 67 | Iteration number: [330/565] 58% | Training loss: 0.6888795108506174
Epoch: 67 | Iteration number: [340/565] 60% | Training loss: 0.6888208068468992
Epoch: 67 | Iteration number: [350/565] 61% | Training loss: 0.6887632015773228
Epoch: 67 | Iteration number: [360/565] 63% | Training loss: 0.6887136878238784
Epoch: 67 | Iteration number: [370/565] 65% | Training loss: 0.6886558155755739
Epoch: 67 | Iteration number: [380/565] 67% | Training loss: 0.688610337282482
Epoch: 67 | Iteration number: [390/565] 69% | Training loss: 0.6885632443122375
Epoch: 67 | Iteration number: [400/565] 70% | Training loss: 0.688515262901783
Epoch: 67 | Iteration number: [410/565] 72% | Training loss: 0.6884797996137201
Epoch: 67 | Iteration number: [420/565] 74% | Training loss: 0.6884438757385526
Epoch: 67 | Iteration number: [430/565] 76% | Training loss: 0.688410907706549
Epoch: 67 | Iteration number: [440/565] 77% | Training loss: 0.6883666209199212
Epoch: 67 | Iteration number: [450/565] 79% | Training loss: 0.6883389506075117
Epoch: 67 | Iteration number: [460/565] 81% | Training loss: 0.6883118587991466
Epoch: 67 | Iteration number: [470/565] 83% | Training loss: 0.6882826190045539
Epoch: 67 | Iteration number: [480/565] 84% | Training loss: 0.6882472335050503
Epoch: 67 | Iteration number: [490/565] 86% | Training loss: 0.6882150933450583
Epoch: 67 | Iteration number: [500/565] 88% | Training loss: 0.6881935280561448
Epoch: 67 | Iteration number: [510/565] 90% | Training loss: 0.6881584911954169
Epoch: 67 | Iteration number: [520/565] 92% | Training loss: 0.6881294609262393
Epoch: 67 | Iteration number: [530/565] 93% | Training loss: 0.6880986026997836
Epoch: 67 | Iteration number: [540/565] 95% | Training loss: 0.6880681490456616
Epoch: 67 | Iteration number: [550/565] 97% | Training loss: 0.6880480026115071
Epoch: 67 | Iteration number: [560/565] 99% | Training loss: 0.6880237501646791

 End of epoch: 67 | Train Loss: 0.6867968662650185 | Training Time: 90 

 End of epoch: 67 | Eval Loss: 0.6900625654629299 | Evaluating Time: 6 
Epoch: 68 | Iteration number: [10/565] 1% | Training loss: 0.7557074069976807
Epoch: 68 | Iteration number: [20/565] 3% | Training loss: 0.7213438212871551
Epoch: 68 | Iteration number: [30/565] 5% | Training loss: 0.7097135702768962
Epoch: 68 | Iteration number: [40/565] 7% | Training loss: 0.7039129316806794
Epoch: 68 | Iteration number: [50/565] 8% | Training loss: 0.7004720628261566
Epoch: 68 | Iteration number: [60/565] 10% | Training loss: 0.6981915920972824
Epoch: 68 | Iteration number: [70/565] 12% | Training loss: 0.696547589131764
Epoch: 68 | Iteration number: [80/565] 14% | Training loss: 0.6953583210706711
Epoch: 68 | Iteration number: [90/565] 15% | Training loss: 0.6944351573785146
Epoch: 68 | Iteration number: [100/565] 17% | Training loss: 0.6936751687526703
Epoch: 68 | Iteration number: [110/565] 19% | Training loss: 0.6930423655293204
Epoch: 68 | Iteration number: [120/565] 21% | Training loss: 0.6925275971492132
Epoch: 68 | Iteration number: [130/565] 23% | Training loss: 0.6921085018378038
Epoch: 68 | Iteration number: [140/565] 24% | Training loss: 0.6917379375014986
Epoch: 68 | Iteration number: [150/565] 26% | Training loss: 0.691416099468867
Epoch: 68 | Iteration number: [160/565] 28% | Training loss: 0.6910979747772217
Epoch: 68 | Iteration number: [170/565] 30% | Training loss: 0.6908547317280489
Epoch: 68 | Iteration number: [180/565] 31% | Training loss: 0.6906266020403968
Epoch: 68 | Iteration number: [190/565] 33% | Training loss: 0.69040241492422
Epoch: 68 | Iteration number: [200/565] 35% | Training loss: 0.6902325829863548
Epoch: 68 | Iteration number: [210/565] 37% | Training loss: 0.6900535328047616
Epoch: 68 | Iteration number: [220/565] 38% | Training loss: 0.6899059983817014
Epoch: 68 | Iteration number: [230/565] 40% | Training loss: 0.6897943600364354
Epoch: 68 | Iteration number: [240/565] 42% | Training loss: 0.6896739132702351
Epoch: 68 | Iteration number: [250/565] 44% | Training loss: 0.689551459312439
Epoch: 68 | Iteration number: [260/565] 46% | Training loss: 0.6894386947154999
Epoch: 68 | Iteration number: [270/565] 47% | Training loss: 0.6893444131921839
Epoch: 68 | Iteration number: [280/565] 49% | Training loss: 0.6892584528241839
Epoch: 68 | Iteration number: [290/565] 51% | Training loss: 0.6891754392919869
Epoch: 68 | Iteration number: [300/565] 53% | Training loss: 0.6890941898028056
Epoch: 68 | Iteration number: [310/565] 54% | Training loss: 0.6890126076436812
Epoch: 68 | Iteration number: [320/565] 56% | Training loss: 0.6889431739225984
Epoch: 68 | Iteration number: [330/565] 58% | Training loss: 0.6888825291937047
Epoch: 68 | Iteration number: [340/565] 60% | Training loss: 0.688812247093986
Epoch: 68 | Iteration number: [350/565] 61% | Training loss: 0.6887474662917001
Epoch: 68 | Iteration number: [360/565] 63% | Training loss: 0.6886873111128807
Epoch: 68 | Iteration number: [370/565] 65% | Training loss: 0.6886424468981253
Epoch: 68 | Iteration number: [380/565] 67% | Training loss: 0.6885937020966881
Epoch: 68 | Iteration number: [390/565] 69% | Training loss: 0.6885428936053545
Epoch: 68 | Iteration number: [400/565] 70% | Training loss: 0.6884984242916107
Epoch: 68 | Iteration number: [410/565] 72% | Training loss: 0.6884608844431436
Epoch: 68 | Iteration number: [420/565] 74% | Training loss: 0.688411693204017
Epoch: 68 | Iteration number: [430/565] 76% | Training loss: 0.6883752868619076
Epoch: 68 | Iteration number: [440/565] 77% | Training loss: 0.6883416853167794
Epoch: 68 | Iteration number: [450/565] 79% | Training loss: 0.6883128174146016
Epoch: 68 | Iteration number: [460/565] 81% | Training loss: 0.6882802126200303
Epoch: 68 | Iteration number: [470/565] 83% | Training loss: 0.6882520950855093
Epoch: 68 | Iteration number: [480/565] 84% | Training loss: 0.688219969968001
Epoch: 68 | Iteration number: [490/565] 86% | Training loss: 0.688192339089452
Epoch: 68 | Iteration number: [500/565] 88% | Training loss: 0.6881594333648682
Epoch: 68 | Iteration number: [510/565] 90% | Training loss: 0.6881348142436906
Epoch: 68 | Iteration number: [520/565] 92% | Training loss: 0.6881027264090684
Epoch: 68 | Iteration number: [530/565] 93% | Training loss: 0.688080144153451
Epoch: 68 | Iteration number: [540/565] 95% | Training loss: 0.6880593784429408
Epoch: 68 | Iteration number: [550/565] 97% | Training loss: 0.6880336026711897
Epoch: 68 | Iteration number: [560/565] 99% | Training loss: 0.6880089816238198

 End of epoch: 68 | Train Loss: 0.6867828870241621 | Training Time: 90 

 End of epoch: 68 | Eval Loss: 0.6900963698114667 | Evaluating Time: 6 
Epoch: 69 | Iteration number: [10/565] 1% | Training loss: 0.7552655875682831
Epoch: 69 | Iteration number: [20/565] 3% | Training loss: 0.721084913611412
Epoch: 69 | Iteration number: [30/565] 5% | Training loss: 0.7095202465852102
Epoch: 69 | Iteration number: [40/565] 7% | Training loss: 0.7038656860589981
Epoch: 69 | Iteration number: [50/565] 8% | Training loss: 0.7004794883728027
Epoch: 69 | Iteration number: [60/565] 10% | Training loss: 0.6982236325740814
Epoch: 69 | Iteration number: [70/565] 12% | Training loss: 0.6965734822409494
Epoch: 69 | Iteration number: [80/565] 14% | Training loss: 0.6953657411038876
Epoch: 69 | Iteration number: [90/565] 15% | Training loss: 0.6944396058718364
Epoch: 69 | Iteration number: [100/565] 17% | Training loss: 0.6936948204040527
Epoch: 69 | Iteration number: [110/565] 19% | Training loss: 0.6930730304934761
Epoch: 69 | Iteration number: [120/565] 21% | Training loss: 0.6925649831692378
Epoch: 69 | Iteration number: [130/565] 23% | Training loss: 0.692117408147225
Epoch: 69 | Iteration number: [140/565] 24% | Training loss: 0.6917486288717815
Epoch: 69 | Iteration number: [150/565] 26% | Training loss: 0.6914136731624603
Epoch: 69 | Iteration number: [160/565] 28% | Training loss: 0.691098278388381
Epoch: 69 | Iteration number: [170/565] 30% | Training loss: 0.6908267946804271
Epoch: 69 | Iteration number: [180/565] 31% | Training loss: 0.6906048887305789
Epoch: 69 | Iteration number: [190/565] 33% | Training loss: 0.6903964619887503
Epoch: 69 | Iteration number: [200/565] 35% | Training loss: 0.6902322369813919
Epoch: 69 | Iteration number: [210/565] 37% | Training loss: 0.6900561281612941
Epoch: 69 | Iteration number: [220/565] 38% | Training loss: 0.6899152246388522
Epoch: 69 | Iteration number: [230/565] 40% | Training loss: 0.6897898795812026
Epoch: 69 | Iteration number: [240/565] 42% | Training loss: 0.6896642213066418
Epoch: 69 | Iteration number: [250/565] 44% | Training loss: 0.6895294125080109
Epoch: 69 | Iteration number: [260/565] 46% | Training loss: 0.6894355879380153
Epoch: 69 | Iteration number: [270/565] 47% | Training loss: 0.6893389801184336
Epoch: 69 | Iteration number: [280/565] 49% | Training loss: 0.6892498597502709
Epoch: 69 | Iteration number: [290/565] 51% | Training loss: 0.6891528518035495
Epoch: 69 | Iteration number: [300/565] 53% | Training loss: 0.6890777126948039
Epoch: 69 | Iteration number: [310/565] 54% | Training loss: 0.6889894047091084
Epoch: 69 | Iteration number: [320/565] 56% | Training loss: 0.6889209549874067
Epoch: 69 | Iteration number: [330/565] 58% | Training loss: 0.6888682486432971
Epoch: 69 | Iteration number: [340/565] 60% | Training loss: 0.6888074082486769
Epoch: 69 | Iteration number: [350/565] 61% | Training loss: 0.688734701020377
Epoch: 69 | Iteration number: [360/565] 63% | Training loss: 0.6886791999141375
Epoch: 69 | Iteration number: [370/565] 65% | Training loss: 0.6886315274882961
Epoch: 69 | Iteration number: [380/565] 67% | Training loss: 0.6885882669373562
Epoch: 69 | Iteration number: [390/565] 69% | Training loss: 0.6885391275087992
Epoch: 69 | Iteration number: [400/565] 70% | Training loss: 0.6885089759528636
Epoch: 69 | Iteration number: [410/565] 72% | Training loss: 0.688468792234979
Epoch: 69 | Iteration number: [420/565] 74% | Training loss: 0.688431356208665
Epoch: 69 | Iteration number: [430/565] 76% | Training loss: 0.6883920761041863
Epoch: 69 | Iteration number: [440/565] 77% | Training loss: 0.6883470310406251
Epoch: 69 | Iteration number: [450/565] 79% | Training loss: 0.6883121951421102
Epoch: 69 | Iteration number: [460/565] 81% | Training loss: 0.6882807100596635
Epoch: 69 | Iteration number: [470/565] 83% | Training loss: 0.6882486547561402
Epoch: 69 | Iteration number: [480/565] 84% | Training loss: 0.688218076651295
Epoch: 69 | Iteration number: [490/565] 86% | Training loss: 0.6881941037518637
Epoch: 69 | Iteration number: [500/565] 88% | Training loss: 0.6881670736074448
Epoch: 69 | Iteration number: [510/565] 90% | Training loss: 0.6881416440010071
Epoch: 69 | Iteration number: [520/565] 92% | Training loss: 0.6881104361552458
Epoch: 69 | Iteration number: [530/565] 93% | Training loss: 0.6880873589020855
Epoch: 69 | Iteration number: [540/565] 95% | Training loss: 0.6880599516409415
Epoch: 69 | Iteration number: [550/565] 97% | Training loss: 0.6880281161178242
Epoch: 69 | Iteration number: [560/565] 99% | Training loss: 0.688000953410353

 End of epoch: 69 | Train Loss: 0.6867753762059507 | Training Time: 90 

 End of epoch: 69 | Eval Loss: 0.6898244108472552 | Evaluating Time: 6 
Epoch: 70 | Iteration number: [10/565] 1% | Training loss: 0.7551677227020264
Epoch: 70 | Iteration number: [20/565] 3% | Training loss: 0.7211362540721893
Epoch: 70 | Iteration number: [30/565] 5% | Training loss: 0.7095331947008768
Epoch: 70 | Iteration number: [40/565] 7% | Training loss: 0.7038519591093063
Epoch: 70 | Iteration number: [50/565] 8% | Training loss: 0.7004335248470306
Epoch: 70 | Iteration number: [60/565] 10% | Training loss: 0.6980912427107493
Epoch: 70 | Iteration number: [70/565] 12% | Training loss: 0.6964761095387595
Epoch: 70 | Iteration number: [80/565] 14% | Training loss: 0.6952575333416462
Epoch: 70 | Iteration number: [90/565] 15% | Training loss: 0.6943158381515079
Epoch: 70 | Iteration number: [100/565] 17% | Training loss: 0.6935507816076278
Epoch: 70 | Iteration number: [110/565] 19% | Training loss: 0.6929282849485224
Epoch: 70 | Iteration number: [120/565] 21% | Training loss: 0.6924253354469935
Epoch: 70 | Iteration number: [130/565] 23% | Training loss: 0.6919921425672678
Epoch: 70 | Iteration number: [140/565] 24% | Training loss: 0.6916320536817823
Epoch: 70 | Iteration number: [150/565] 26% | Training loss: 0.6913333944479625
Epoch: 70 | Iteration number: [160/565] 28% | Training loss: 0.6910446587949991
Epoch: 70 | Iteration number: [170/565] 30% | Training loss: 0.6907734253827263
Epoch: 70 | Iteration number: [180/565] 31% | Training loss: 0.6905658735169304
Epoch: 70 | Iteration number: [190/565] 33% | Training loss: 0.6903558370314147
Epoch: 70 | Iteration number: [200/565] 35% | Training loss: 0.6901702585816384
Epoch: 70 | Iteration number: [210/565] 37% | Training loss: 0.6899951426755815
Epoch: 70 | Iteration number: [220/565] 38% | Training loss: 0.6898564105684107
Epoch: 70 | Iteration number: [230/565] 40% | Training loss: 0.6897464666677557
Epoch: 70 | Iteration number: [240/565] 42% | Training loss: 0.6896455988287926
Epoch: 70 | Iteration number: [250/565] 44% | Training loss: 0.6895348377227783
Epoch: 70 | Iteration number: [260/565] 46% | Training loss: 0.6894251364928026
Epoch: 70 | Iteration number: [270/565] 47% | Training loss: 0.6893289939120963
Epoch: 70 | Iteration number: [280/565] 49% | Training loss: 0.6892269283533097
Epoch: 70 | Iteration number: [290/565] 51% | Training loss: 0.6891346945844847
Epoch: 70 | Iteration number: [300/565] 53% | Training loss: 0.68905552983284
Epoch: 70 | Iteration number: [310/565] 54% | Training loss: 0.6889837586110638
Epoch: 70 | Iteration number: [320/565] 56% | Training loss: 0.6889101298525929
Epoch: 70 | Iteration number: [330/565] 58% | Training loss: 0.688854502547871
Epoch: 70 | Iteration number: [340/565] 60% | Training loss: 0.6887920225367826
Epoch: 70 | Iteration number: [350/565] 61% | Training loss: 0.6887303948402405
Epoch: 70 | Iteration number: [360/565] 63% | Training loss: 0.688681860268116
Epoch: 70 | Iteration number: [370/565] 65% | Training loss: 0.6886339740173236
Epoch: 70 | Iteration number: [380/565] 67% | Training loss: 0.6885801828221271
Epoch: 70 | Iteration number: [390/565] 69% | Training loss: 0.6885270066750355
Epoch: 70 | Iteration number: [400/565] 70% | Training loss: 0.6884936994314194
Epoch: 70 | Iteration number: [410/565] 72% | Training loss: 0.6884532948819603
Epoch: 70 | Iteration number: [420/565] 74% | Training loss: 0.688418337844667
Epoch: 70 | Iteration number: [430/565] 76% | Training loss: 0.6883834453516229
Epoch: 70 | Iteration number: [440/565] 77% | Training loss: 0.6883506016297773
Epoch: 70 | Iteration number: [450/565] 79% | Training loss: 0.6883199795087178
Epoch: 70 | Iteration number: [460/565] 81% | Training loss: 0.6882740824118905
Epoch: 70 | Iteration number: [470/565] 83% | Training loss: 0.6882524657756725
Epoch: 70 | Iteration number: [480/565] 84% | Training loss: 0.6882280070334673
Epoch: 70 | Iteration number: [490/565] 86% | Training loss: 0.6881908105344189
Epoch: 70 | Iteration number: [500/565] 88% | Training loss: 0.6881741758584976
Epoch: 70 | Iteration number: [510/565] 90% | Training loss: 0.6881444534834693
Epoch: 70 | Iteration number: [520/565] 92% | Training loss: 0.688121710717678
Epoch: 70 | Iteration number: [530/565] 93% | Training loss: 0.6880875780897321
Epoch: 70 | Iteration number: [540/565] 95% | Training loss: 0.6880681681412237
Epoch: 70 | Iteration number: [550/565] 97% | Training loss: 0.6880394317887046
Epoch: 70 | Iteration number: [560/565] 99% | Training loss: 0.6880163573793002

 End of epoch: 70 | Train Loss: 0.6867887735366821 | Training Time: 88 

 End of epoch: 70 | Eval Loss: 0.6887151854378837 | Evaluating Time: 6 
Epoch: 71 | Iteration number: [10/565] 1% | Training loss: 0.7554638862609864
Epoch: 71 | Iteration number: [20/565] 3% | Training loss: 0.7210751950740815
Epoch: 71 | Iteration number: [30/565] 5% | Training loss: 0.7095866084098816
Epoch: 71 | Iteration number: [40/565] 7% | Training loss: 0.7038883715867996
Epoch: 71 | Iteration number: [50/565] 8% | Training loss: 0.7004850697517395
Epoch: 71 | Iteration number: [60/565] 10% | Training loss: 0.6982289175192515
Epoch: 71 | Iteration number: [70/565] 12% | Training loss: 0.6965673497744969
Epoch: 71 | Iteration number: [80/565] 14% | Training loss: 0.6953383952379226
Epoch: 71 | Iteration number: [90/565] 15% | Training loss: 0.6944113519456652
Epoch: 71 | Iteration number: [100/565] 17% | Training loss: 0.6936278033256531
Epoch: 71 | Iteration number: [110/565] 19% | Training loss: 0.692954217303883
Epoch: 71 | Iteration number: [120/565] 21% | Training loss: 0.6924860124786695
Epoch: 71 | Iteration number: [130/565] 23% | Training loss: 0.6920271474581499
Epoch: 71 | Iteration number: [140/565] 24% | Training loss: 0.6917097636631557
Epoch: 71 | Iteration number: [150/565] 26% | Training loss: 0.6913811361789703
Epoch: 71 | Iteration number: [160/565] 28% | Training loss: 0.691085421666503
Epoch: 71 | Iteration number: [170/565] 30% | Training loss: 0.6908350064473994
Epoch: 71 | Iteration number: [180/565] 31% | Training loss: 0.6906191229820251
Epoch: 71 | Iteration number: [190/565] 33% | Training loss: 0.6904358292880811
Epoch: 71 | Iteration number: [200/565] 35% | Training loss: 0.690264381468296
Epoch: 71 | Iteration number: [210/565] 37% | Training loss: 0.6900947034358978
Epoch: 71 | Iteration number: [220/565] 38% | Training loss: 0.6899534268812699
Epoch: 71 | Iteration number: [230/565] 40% | Training loss: 0.6898242496925852
Epoch: 71 | Iteration number: [240/565] 42% | Training loss: 0.6897064208984375
Epoch: 71 | Iteration number: [250/565] 44% | Training loss: 0.6896156871318817
Epoch: 71 | Iteration number: [260/565] 46% | Training loss: 0.689503652545122
Epoch: 71 | Iteration number: [270/565] 47% | Training loss: 0.6893904524820822
Epoch: 71 | Iteration number: [280/565] 49% | Training loss: 0.6893120342067309
Epoch: 71 | Iteration number: [290/565] 51% | Training loss: 0.6892330424538974
Epoch: 71 | Iteration number: [300/565] 53% | Training loss: 0.6891490507125855
Epoch: 71 | Iteration number: [310/565] 54% | Training loss: 0.6890580123470675
Epoch: 71 | Iteration number: [320/565] 56% | Training loss: 0.6889897085726261
Epoch: 71 | Iteration number: [330/565] 58% | Training loss: 0.6889242155985399
Epoch: 71 | Iteration number: [340/565] 60% | Training loss: 0.6888740723623948
Epoch: 71 | Iteration number: [350/565] 61% | Training loss: 0.6888099430288588
Epoch: 71 | Iteration number: [360/565] 63% | Training loss: 0.6887383500734965
Epoch: 71 | Iteration number: [370/565] 65% | Training loss: 0.6886931280832033
Epoch: 71 | Iteration number: [380/565] 67% | Training loss: 0.6886286851606871
Epoch: 71 | Iteration number: [390/565] 69% | Training loss: 0.6885724513958662
Epoch: 71 | Iteration number: [400/565] 70% | Training loss: 0.6885243688523769
Epoch: 71 | Iteration number: [410/565] 72% | Training loss: 0.6884695849767546
Epoch: 71 | Iteration number: [420/565] 74% | Training loss: 0.6884227613608043
Epoch: 71 | Iteration number: [430/565] 76% | Training loss: 0.6883907032567401
Epoch: 71 | Iteration number: [440/565] 77% | Training loss: 0.6883423335172913
Epoch: 71 | Iteration number: [450/565] 79% | Training loss: 0.6883024824990167
Epoch: 71 | Iteration number: [460/565] 81% | Training loss: 0.6882654289836468
Epoch: 71 | Iteration number: [470/565] 83% | Training loss: 0.6882384520895938
Epoch: 71 | Iteration number: [480/565] 84% | Training loss: 0.6882061791916688
Epoch: 71 | Iteration number: [490/565] 86% | Training loss: 0.6881725061912926
Epoch: 71 | Iteration number: [500/565] 88% | Training loss: 0.6881461021900177
Epoch: 71 | Iteration number: [510/565] 90% | Training loss: 0.6881212184242174
Epoch: 71 | Iteration number: [520/565] 92% | Training loss: 0.6880981637881353
Epoch: 71 | Iteration number: [530/565] 93% | Training loss: 0.6880709932660157
Epoch: 71 | Iteration number: [540/565] 95% | Training loss: 0.6880451455160423
Epoch: 71 | Iteration number: [550/565] 97% | Training loss: 0.6880230142853477
Epoch: 71 | Iteration number: [560/565] 99% | Training loss: 0.6879969271165984

 End of epoch: 71 | Train Loss: 0.6867733502809981 | Training Time: 91 

 End of epoch: 71 | Eval Loss: 0.6900538631847927 | Evaluating Time: 5 
Epoch: 72 | Iteration number: [10/565] 1% | Training loss: 0.7553013741970063
Epoch: 72 | Iteration number: [20/565] 3% | Training loss: 0.7212347567081452
Epoch: 72 | Iteration number: [30/565] 5% | Training loss: 0.7097624063491821
Epoch: 72 | Iteration number: [40/565] 7% | Training loss: 0.7040526330471039
Epoch: 72 | Iteration number: [50/565] 8% | Training loss: 0.7004980266094207
Epoch: 72 | Iteration number: [60/565] 10% | Training loss: 0.6982013593117397
Epoch: 72 | Iteration number: [70/565] 12% | Training loss: 0.6964767788137708
Epoch: 72 | Iteration number: [80/565] 14% | Training loss: 0.695288484543562
Epoch: 72 | Iteration number: [90/565] 15% | Training loss: 0.6943796237309774
Epoch: 72 | Iteration number: [100/565] 17% | Training loss: 0.6936323893070221
Epoch: 72 | Iteration number: [110/565] 19% | Training loss: 0.6930501813238318
Epoch: 72 | Iteration number: [120/565] 21% | Training loss: 0.6925235738356909
Epoch: 72 | Iteration number: [130/565] 23% | Training loss: 0.6920742296255552
Epoch: 72 | Iteration number: [140/565] 24% | Training loss: 0.6916737011500768
Epoch: 72 | Iteration number: [150/565] 26% | Training loss: 0.6913512388865153
Epoch: 72 | Iteration number: [160/565] 28% | Training loss: 0.6910210154950619
Epoch: 72 | Iteration number: [170/565] 30% | Training loss: 0.6907606475493487
Epoch: 72 | Iteration number: [180/565] 31% | Training loss: 0.6905051559209824
Epoch: 72 | Iteration number: [190/565] 33% | Training loss: 0.6903202935269005
Epoch: 72 | Iteration number: [200/565] 35% | Training loss: 0.690146413743496
Epoch: 72 | Iteration number: [210/565] 37% | Training loss: 0.689980065254938
Epoch: 72 | Iteration number: [220/565] 38% | Training loss: 0.6898376055739143
Epoch: 72 | Iteration number: [230/565] 40% | Training loss: 0.6897346120813619
Epoch: 72 | Iteration number: [240/565] 42% | Training loss: 0.68959435770909
Epoch: 72 | Iteration number: [250/565] 44% | Training loss: 0.6894733755588531
Epoch: 72 | Iteration number: [260/565] 46% | Training loss: 0.689374289375085
Epoch: 72 | Iteration number: [270/565] 47% | Training loss: 0.6892782953050401
Epoch: 72 | Iteration number: [280/565] 49% | Training loss: 0.6891939816730362
Epoch: 72 | Iteration number: [290/565] 51% | Training loss: 0.6891184418365873
Epoch: 72 | Iteration number: [300/565] 53% | Training loss: 0.6890551014741262
Epoch: 72 | Iteration number: [310/565] 54% | Training loss: 0.688992703153241
Epoch: 72 | Iteration number: [320/565] 56% | Training loss: 0.6889281321316958
Epoch: 72 | Iteration number: [330/565] 58% | Training loss: 0.6888627753113256
Epoch: 72 | Iteration number: [340/565] 60% | Training loss: 0.6888065143543132
Epoch: 72 | Iteration number: [350/565] 61% | Training loss: 0.6887666910035269
Epoch: 72 | Iteration number: [360/565] 63% | Training loss: 0.6887018827928437
Epoch: 72 | Iteration number: [370/565] 65% | Training loss: 0.6886508139404091
Epoch: 72 | Iteration number: [380/565] 67% | Training loss: 0.6886048026775059
Epoch: 72 | Iteration number: [390/565] 69% | Training loss: 0.6885539536292736
Epoch: 72 | Iteration number: [400/565] 70% | Training loss: 0.6885088528692722
Epoch: 72 | Iteration number: [410/565] 72% | Training loss: 0.6884683603193702
Epoch: 72 | Iteration number: [420/565] 74% | Training loss: 0.6884334743022918
Epoch: 72 | Iteration number: [430/565] 76% | Training loss: 0.6883950782376667
Epoch: 72 | Iteration number: [440/565] 77% | Training loss: 0.6883641554550691
Epoch: 72 | Iteration number: [450/565] 79% | Training loss: 0.6883436869250403
Epoch: 72 | Iteration number: [460/565] 81% | Training loss: 0.6883091257966083
Epoch: 72 | Iteration number: [470/565] 83% | Training loss: 0.6882666740011661
Epoch: 72 | Iteration number: [480/565] 84% | Training loss: 0.688231301556031
Epoch: 72 | Iteration number: [490/565] 86% | Training loss: 0.688201291463813
Epoch: 72 | Iteration number: [500/565] 88% | Training loss: 0.6881774252653122
Epoch: 72 | Iteration number: [510/565] 90% | Training loss: 0.6881515062322804
Epoch: 72 | Iteration number: [520/565] 92% | Training loss: 0.6881199296850424
Epoch: 72 | Iteration number: [530/565] 93% | Training loss: 0.6880934660164815
Epoch: 72 | Iteration number: [540/565] 95% | Training loss: 0.6880638471356144
Epoch: 72 | Iteration number: [550/565] 97% | Training loss: 0.6880356824398041
Epoch: 72 | Iteration number: [560/565] 99% | Training loss: 0.6880066429930074

 End of epoch: 72 | Train Loss: 0.6867762588821681 | Training Time: 90 

 End of epoch: 72 | Eval Loss: 0.6900120377540588 | Evaluating Time: 5 
Epoch: 73 | Iteration number: [10/565] 1% | Training loss: 0.7559220910072326
Epoch: 73 | Iteration number: [20/565] 3% | Training loss: 0.721214485168457
Epoch: 73 | Iteration number: [30/565] 5% | Training loss: 0.7097052991390228
Epoch: 73 | Iteration number: [40/565] 7% | Training loss: 0.704029580950737
Epoch: 73 | Iteration number: [50/565] 8% | Training loss: 0.7006046199798583
Epoch: 73 | Iteration number: [60/565] 10% | Training loss: 0.6983078628778457
Epoch: 73 | Iteration number: [70/565] 12% | Training loss: 0.6967072784900665
Epoch: 73 | Iteration number: [80/565] 14% | Training loss: 0.6954723507165909
Epoch: 73 | Iteration number: [90/565] 15% | Training loss: 0.6944789939456516
Epoch: 73 | Iteration number: [100/565] 17% | Training loss: 0.6937203705310822
Epoch: 73 | Iteration number: [110/565] 19% | Training loss: 0.6931183885444294
Epoch: 73 | Iteration number: [120/565] 21% | Training loss: 0.6926216125488281
Epoch: 73 | Iteration number: [130/565] 23% | Training loss: 0.6922042897114387
Epoch: 73 | Iteration number: [140/565] 24% | Training loss: 0.6918198457786016
Epoch: 73 | Iteration number: [150/565] 26% | Training loss: 0.6914584910869599
Epoch: 73 | Iteration number: [160/565] 28% | Training loss: 0.6911900214850902
Epoch: 73 | Iteration number: [170/565] 30% | Training loss: 0.6909180890111363
Epoch: 73 | Iteration number: [180/565] 31% | Training loss: 0.6907007329993777
Epoch: 73 | Iteration number: [190/565] 33% | Training loss: 0.6904975699751
Epoch: 73 | Iteration number: [200/565] 35% | Training loss: 0.6902876380085945
Epoch: 73 | Iteration number: [210/565] 37% | Training loss: 0.6901239622206915
Epoch: 73 | Iteration number: [220/565] 38% | Training loss: 0.6899539253928445
Epoch: 73 | Iteration number: [230/565] 40% | Training loss: 0.6898033538590307
Epoch: 73 | Iteration number: [240/565] 42% | Training loss: 0.6896592622001966
Epoch: 73 | Iteration number: [250/565] 44% | Training loss: 0.689535032749176
Epoch: 73 | Iteration number: [260/565] 46% | Training loss: 0.6894279603774731
Epoch: 73 | Iteration number: [270/565] 47% | Training loss: 0.6893397258387671
Epoch: 73 | Iteration number: [280/565] 49% | Training loss: 0.6892554557749203
Epoch: 73 | Iteration number: [290/565] 51% | Training loss: 0.6891828156750778
Epoch: 73 | Iteration number: [300/565] 53% | Training loss: 0.6891081110636393
Epoch: 73 | Iteration number: [310/565] 54% | Training loss: 0.6890468799298809
Epoch: 73 | Iteration number: [320/565] 56% | Training loss: 0.6889774519950151
Epoch: 73 | Iteration number: [330/565] 58% | Training loss: 0.688908892508709
Epoch: 73 | Iteration number: [340/565] 60% | Training loss: 0.6888503409483854
Epoch: 73 | Iteration number: [350/565] 61% | Training loss: 0.6887942130225045
Epoch: 73 | Iteration number: [360/565] 63% | Training loss: 0.6887410897347662
Epoch: 73 | Iteration number: [370/565] 65% | Training loss: 0.688691964987162
Epoch: 73 | Iteration number: [380/565] 67% | Training loss: 0.6886341160849521
Epoch: 73 | Iteration number: [390/565] 69% | Training loss: 0.6885939793708997
Epoch: 73 | Iteration number: [400/565] 70% | Training loss: 0.6885553692281247
Epoch: 73 | Iteration number: [410/565] 72% | Training loss: 0.6885155482989985
Epoch: 73 | Iteration number: [420/565] 74% | Training loss: 0.6884700799272174
Epoch: 73 | Iteration number: [430/565] 76% | Training loss: 0.6884375964486322
Epoch: 73 | Iteration number: [440/565] 77% | Training loss: 0.688399300114675
Epoch: 73 | Iteration number: [450/565] 79% | Training loss: 0.6883598887920379
Epoch: 73 | Iteration number: [460/565] 81% | Training loss: 0.6883169253235278
Epoch: 73 | Iteration number: [470/565] 83% | Training loss: 0.6882838091951735
Epoch: 73 | Iteration number: [480/565] 84% | Training loss: 0.6882477879524231
Epoch: 73 | Iteration number: [490/565] 86% | Training loss: 0.6882169931518788
Epoch: 73 | Iteration number: [500/565] 88% | Training loss: 0.6881869621276856
Epoch: 73 | Iteration number: [510/565] 90% | Training loss: 0.6881636528407826
Epoch: 73 | Iteration number: [520/565] 92% | Training loss: 0.6881427871493193
Epoch: 73 | Iteration number: [530/565] 93% | Training loss: 0.6881096806166307
Epoch: 73 | Iteration number: [540/565] 95% | Training loss: 0.6880807778349629
Epoch: 73 | Iteration number: [550/565] 97% | Training loss: 0.6880542521043257
Epoch: 73 | Iteration number: [560/565] 99% | Training loss: 0.6880215046661241

 End of epoch: 73 | Train Loss: 0.6867951019675331 | Training Time: 89 

 End of epoch: 73 | Eval Loss: 0.6898633752550397 | Evaluating Time: 5 
Epoch: 74 | Iteration number: [10/565] 1% | Training loss: 0.7554245889186859
Epoch: 74 | Iteration number: [20/565] 3% | Training loss: 0.7214119911193848
Epoch: 74 | Iteration number: [30/565] 5% | Training loss: 0.7098600486914317
Epoch: 74 | Iteration number: [40/565] 7% | Training loss: 0.704218378663063
Epoch: 74 | Iteration number: [50/565] 8% | Training loss: 0.7007554829120636
Epoch: 74 | Iteration number: [60/565] 10% | Training loss: 0.6983716169993083
Epoch: 74 | Iteration number: [70/565] 12% | Training loss: 0.6966630620615822
Epoch: 74 | Iteration number: [80/565] 14% | Training loss: 0.6954396091401577
Epoch: 74 | Iteration number: [90/565] 15% | Training loss: 0.6944695399867163
Epoch: 74 | Iteration number: [100/565] 17% | Training loss: 0.6937548583745956
Epoch: 74 | Iteration number: [110/565] 19% | Training loss: 0.693134005503221
Epoch: 74 | Iteration number: [120/565] 21% | Training loss: 0.6926071877280872
Epoch: 74 | Iteration number: [130/565] 23% | Training loss: 0.6921763204611264
Epoch: 74 | Iteration number: [140/565] 24% | Training loss: 0.6917903763907296
Epoch: 74 | Iteration number: [150/565] 26% | Training loss: 0.6914591876665751
Epoch: 74 | Iteration number: [160/565] 28% | Training loss: 0.6911802586168051
Epoch: 74 | Iteration number: [170/565] 30% | Training loss: 0.690888207099017
Epoch: 74 | Iteration number: [180/565] 31% | Training loss: 0.6906552000178231
Epoch: 74 | Iteration number: [190/565] 33% | Training loss: 0.6904399184804214
Epoch: 74 | Iteration number: [200/565] 35% | Training loss: 0.6902519473433495
Epoch: 74 | Iteration number: [210/565] 37% | Training loss: 0.6900911390781402
Epoch: 74 | Iteration number: [220/565] 38% | Training loss: 0.6899552954868837
Epoch: 74 | Iteration number: [230/565] 40% | Training loss: 0.6898086648920309
Epoch: 74 | Iteration number: [240/565] 42% | Training loss: 0.6896771724025409
Epoch: 74 | Iteration number: [250/565] 44% | Training loss: 0.689561271905899
Epoch: 74 | Iteration number: [260/565] 46% | Training loss: 0.6894546790764882
Epoch: 74 | Iteration number: [270/565] 47% | Training loss: 0.6893372681405809
Epoch: 74 | Iteration number: [280/565] 49% | Training loss: 0.6892567151359149
Epoch: 74 | Iteration number: [290/565] 51% | Training loss: 0.6891678921107588
Epoch: 74 | Iteration number: [300/565] 53% | Training loss: 0.6890791028738021
Epoch: 74 | Iteration number: [310/565] 54% | Training loss: 0.6890013177548685
Epoch: 74 | Iteration number: [320/565] 56% | Training loss: 0.6889257160946727
Epoch: 74 | Iteration number: [330/565] 58% | Training loss: 0.6888677819208665
Epoch: 74 | Iteration number: [340/565] 60% | Training loss: 0.6888027050915886
Epoch: 74 | Iteration number: [350/565] 61% | Training loss: 0.6887388965061733
Epoch: 74 | Iteration number: [360/565] 63% | Training loss: 0.6886673899160491
Epoch: 74 | Iteration number: [370/565] 65% | Training loss: 0.6886090428442568
Epoch: 74 | Iteration number: [380/565] 67% | Training loss: 0.6885501812947424
Epoch: 74 | Iteration number: [390/565] 69% | Training loss: 0.6884935591465388
Epoch: 74 | Iteration number: [400/565] 70% | Training loss: 0.6884507596492767
Epoch: 74 | Iteration number: [410/565] 72% | Training loss: 0.6884146142296674
Epoch: 74 | Iteration number: [420/565] 74% | Training loss: 0.6883794824282329
Epoch: 74 | Iteration number: [430/565] 76% | Training loss: 0.6883529004662536
Epoch: 74 | Iteration number: [440/565] 77% | Training loss: 0.6883168808438561
Epoch: 74 | Iteration number: [450/565] 79% | Training loss: 0.6882941473854912
Epoch: 74 | Iteration number: [460/565] 81% | Training loss: 0.6882665535678034
Epoch: 74 | Iteration number: [470/565] 83% | Training loss: 0.6882339218829541
Epoch: 74 | Iteration number: [480/565] 84% | Training loss: 0.6882066664596399
Epoch: 74 | Iteration number: [490/565] 86% | Training loss: 0.6881791685308729
Epoch: 74 | Iteration number: [500/565] 88% | Training loss: 0.6881494827270508
Epoch: 74 | Iteration number: [510/565] 90% | Training loss: 0.6881278230863459
Epoch: 74 | Iteration number: [520/565] 92% | Training loss: 0.6880977400220357
Epoch: 74 | Iteration number: [530/565] 93% | Training loss: 0.688073087413356
Epoch: 74 | Iteration number: [540/565] 95% | Training loss: 0.6880478361138591
Epoch: 74 | Iteration number: [550/565] 97% | Training loss: 0.688028862693093
Epoch: 74 | Iteration number: [560/565] 99% | Training loss: 0.6879951019372259

 End of epoch: 74 | Train Loss: 0.6867729404331309 | Training Time: 90 

 End of epoch: 74 | Eval Loss: 0.6898065975734166 | Evaluating Time: 6 
Epoch: 75 | Iteration number: [10/565] 1% | Training loss: 0.7558547914028168
Epoch: 75 | Iteration number: [20/565] 3% | Training loss: 0.7213830977678299
Epoch: 75 | Iteration number: [30/565] 5% | Training loss: 0.7098547379175822
Epoch: 75 | Iteration number: [40/565] 7% | Training loss: 0.7039859831333161
Epoch: 75 | Iteration number: [50/565] 8% | Training loss: 0.7006736862659454
Epoch: 75 | Iteration number: [60/565] 10% | Training loss: 0.6983346462249755
Epoch: 75 | Iteration number: [70/565] 12% | Training loss: 0.6966399618557522
Epoch: 75 | Iteration number: [80/565] 14% | Training loss: 0.6953808419406414
Epoch: 75 | Iteration number: [90/565] 15% | Training loss: 0.6944872995217641
Epoch: 75 | Iteration number: [100/565] 17% | Training loss: 0.6936813127994538
Epoch: 75 | Iteration number: [110/565] 19% | Training loss: 0.6930363091555509
Epoch: 75 | Iteration number: [120/565] 21% | Training loss: 0.692506916821003
Epoch: 75 | Iteration number: [130/565] 23% | Training loss: 0.6920789915781754
Epoch: 75 | Iteration number: [140/565] 24% | Training loss: 0.6917044584240232
Epoch: 75 | Iteration number: [150/565] 26% | Training loss: 0.6913779457410176
Epoch: 75 | Iteration number: [160/565] 28% | Training loss: 0.6911034233868122
Epoch: 75 | Iteration number: [170/565] 30% | Training loss: 0.6908370719236486
Epoch: 75 | Iteration number: [180/565] 31% | Training loss: 0.6906033565600713
Epoch: 75 | Iteration number: [190/565] 33% | Training loss: 0.6904020933728469
Epoch: 75 | Iteration number: [200/565] 35% | Training loss: 0.6902233752608299
Epoch: 75 | Iteration number: [210/565] 37% | Training loss: 0.6900788403692699
Epoch: 75 | Iteration number: [220/565] 38% | Training loss: 0.6899208927696402
Epoch: 75 | Iteration number: [230/565] 40% | Training loss: 0.6897921432619509
Epoch: 75 | Iteration number: [240/565] 42% | Training loss: 0.689655867467324
Epoch: 75 | Iteration number: [250/565] 44% | Training loss: 0.6895473277568818
Epoch: 75 | Iteration number: [260/565] 46% | Training loss: 0.6894449912584745
Epoch: 75 | Iteration number: [270/565] 47% | Training loss: 0.6893587655491299
Epoch: 75 | Iteration number: [280/565] 49% | Training loss: 0.6892453176634652
Epoch: 75 | Iteration number: [290/565] 51% | Training loss: 0.6891580400795773
Epoch: 75 | Iteration number: [300/565] 53% | Training loss: 0.689070984919866
Epoch: 75 | Iteration number: [310/565] 54% | Training loss: 0.6889981160240789
Epoch: 75 | Iteration number: [320/565] 56% | Training loss: 0.6889185003936291
Epoch: 75 | Iteration number: [330/565] 58% | Training loss: 0.6888644335847912
Epoch: 75 | Iteration number: [340/565] 60% | Training loss: 0.6887975026579464
Epoch: 75 | Iteration number: [350/565] 61% | Training loss: 0.6887405894483839
Epoch: 75 | Iteration number: [360/565] 63% | Training loss: 0.6886956214904785
Epoch: 75 | Iteration number: [370/565] 65% | Training loss: 0.6886505141451552
Epoch: 75 | Iteration number: [380/565] 67% | Training loss: 0.688601038016771
Epoch: 75 | Iteration number: [390/565] 69% | Training loss: 0.6885487232452784
Epoch: 75 | Iteration number: [400/565] 70% | Training loss: 0.6885118301212788
Epoch: 75 | Iteration number: [410/565] 72% | Training loss: 0.6884700293948011
Epoch: 75 | Iteration number: [420/565] 74% | Training loss: 0.6884121224993751
Epoch: 75 | Iteration number: [430/565] 76% | Training loss: 0.6883658944174301
Epoch: 75 | Iteration number: [440/565] 77% | Training loss: 0.6883390461856669
Epoch: 75 | Iteration number: [450/565] 79% | Training loss: 0.6883165078692967
Epoch: 75 | Iteration number: [460/565] 81% | Training loss: 0.6882885040148444
Epoch: 75 | Iteration number: [470/565] 83% | Training loss: 0.6882515784273756
Epoch: 75 | Iteration number: [480/565] 84% | Training loss: 0.6882085314641396
Epoch: 75 | Iteration number: [490/565] 86% | Training loss: 0.6881681649052367
Epoch: 75 | Iteration number: [500/565] 88% | Training loss: 0.6881397459506988
Epoch: 75 | Iteration number: [510/565] 90% | Training loss: 0.6881196583018584
Epoch: 75 | Iteration number: [520/565] 92% | Training loss: 0.6880941944626662
Epoch: 75 | Iteration number: [530/565] 93% | Training loss: 0.688074684255528
Epoch: 75 | Iteration number: [540/565] 95% | Training loss: 0.6880488180451922
Epoch: 75 | Iteration number: [550/565] 97% | Training loss: 0.6880263717608018
Epoch: 75 | Iteration number: [560/565] 99% | Training loss: 0.688003524605717

 End of epoch: 75 | Train Loss: 0.686776980995077 | Training Time: 91 

 End of epoch: 75 | Eval Loss: 0.6897820489747184 | Evaluating Time: 6 
Epoch: 76 | Iteration number: [10/565] 1% | Training loss: 0.7553341865539551
Epoch: 76 | Iteration number: [20/565] 3% | Training loss: 0.7211356848478317
Epoch: 76 | Iteration number: [30/565] 5% | Training loss: 0.7097256243228912
Epoch: 76 | Iteration number: [40/565] 7% | Training loss: 0.7038968205451965
Epoch: 76 | Iteration number: [50/565] 8% | Training loss: 0.7005598878860474
Epoch: 76 | Iteration number: [60/565] 10% | Training loss: 0.6982559412717819
Epoch: 76 | Iteration number: [70/565] 12% | Training loss: 0.6966274159295218
Epoch: 76 | Iteration number: [80/565] 14% | Training loss: 0.695408022403717
Epoch: 76 | Iteration number: [90/565] 15% | Training loss: 0.6944204946358998
Epoch: 76 | Iteration number: [100/565] 17% | Training loss: 0.693707042336464
Epoch: 76 | Iteration number: [110/565] 19% | Training loss: 0.6930778216231953
Epoch: 76 | Iteration number: [120/565] 21% | Training loss: 0.6925450364748637
Epoch: 76 | Iteration number: [130/565] 23% | Training loss: 0.6921488381349123
Epoch: 76 | Iteration number: [140/565] 24% | Training loss: 0.6917869193213326
Epoch: 76 | Iteration number: [150/565] 26% | Training loss: 0.6914129495620728
Epoch: 76 | Iteration number: [160/565] 28% | Training loss: 0.6911144003272056
Epoch: 76 | Iteration number: [170/565] 30% | Training loss: 0.6908791598151712
Epoch: 76 | Iteration number: [180/565] 31% | Training loss: 0.6906381368637085
Epoch: 76 | Iteration number: [190/565] 33% | Training loss: 0.6904309646079415
Epoch: 76 | Iteration number: [200/565] 35% | Training loss: 0.6902337184548378
Epoch: 76 | Iteration number: [210/565] 37% | Training loss: 0.6900620906125932
Epoch: 76 | Iteration number: [220/565] 38% | Training loss: 0.689908505840735
Epoch: 76 | Iteration number: [230/565] 40% | Training loss: 0.6897699990998144
Epoch: 76 | Iteration number: [240/565] 42% | Training loss: 0.6896546863019466
Epoch: 76 | Iteration number: [250/565] 44% | Training loss: 0.6895578899383545
Epoch: 76 | Iteration number: [260/565] 46% | Training loss: 0.6894373141802275
Epoch: 76 | Iteration number: [270/565] 47% | Training loss: 0.6893382030504721
Epoch: 76 | Iteration number: [280/565] 49% | Training loss: 0.6892485009772437
Epoch: 76 | Iteration number: [290/565] 51% | Training loss: 0.6891748222811469
Epoch: 76 | Iteration number: [300/565] 53% | Training loss: 0.6890868588288626
Epoch: 76 | Iteration number: [310/565] 54% | Training loss: 0.688999205443167
Epoch: 76 | Iteration number: [320/565] 56% | Training loss: 0.6889238504692912
Epoch: 76 | Iteration number: [330/565] 58% | Training loss: 0.6888440663164312
Epoch: 76 | Iteration number: [340/565] 60% | Training loss: 0.6887759082457598
Epoch: 76 | Iteration number: [350/565] 61% | Training loss: 0.6887210662024362
Epoch: 76 | Iteration number: [360/565] 63% | Training loss: 0.6886531374520726
Epoch: 76 | Iteration number: [370/565] 65% | Training loss: 0.6885961112138387
Epoch: 76 | Iteration number: [380/565] 67% | Training loss: 0.6885381315883837
Epoch: 76 | Iteration number: [390/565] 69% | Training loss: 0.6884927919277778
Epoch: 76 | Iteration number: [400/565] 70% | Training loss: 0.6884518977999687
Epoch: 76 | Iteration number: [410/565] 72% | Training loss: 0.6884159791760328
Epoch: 76 | Iteration number: [420/565] 74% | Training loss: 0.6883864378645307
Epoch: 76 | Iteration number: [430/565] 76% | Training loss: 0.68835688067037
Epoch: 76 | Iteration number: [440/565] 77% | Training loss: 0.6883160409602251
Epoch: 76 | Iteration number: [450/565] 79% | Training loss: 0.6882857106791602
Epoch: 76 | Iteration number: [460/565] 81% | Training loss: 0.6882616227087768
Epoch: 76 | Iteration number: [470/565] 83% | Training loss: 0.6882334861349553
Epoch: 76 | Iteration number: [480/565] 84% | Training loss: 0.6882040063540141
Epoch: 76 | Iteration number: [490/565] 86% | Training loss: 0.6881840617072825
Epoch: 76 | Iteration number: [500/565] 88% | Training loss: 0.6881548087596894
Epoch: 76 | Iteration number: [510/565] 90% | Training loss: 0.6881328200592715
Epoch: 76 | Iteration number: [520/565] 92% | Training loss: 0.6881095430025688
Epoch: 76 | Iteration number: [530/565] 93% | Training loss: 0.6880873856679448
Epoch: 76 | Iteration number: [540/565] 95% | Training loss: 0.6880623409041652
Epoch: 76 | Iteration number: [550/565] 97% | Training loss: 0.688028026602485
Epoch: 76 | Iteration number: [560/565] 99% | Training loss: 0.6880071625113487

 End of epoch: 76 | Train Loss: 0.6867831612055281 | Training Time: 89 

 End of epoch: 76 | Eval Loss: 0.6898988911083767 | Evaluating Time: 6 
Epoch: 77 | Iteration number: [10/565] 1% | Training loss: 0.7555339395999908
Epoch: 77 | Iteration number: [20/565] 3% | Training loss: 0.7209837257862091
Epoch: 77 | Iteration number: [30/565] 5% | Training loss: 0.7095336834589641
Epoch: 77 | Iteration number: [40/565] 7% | Training loss: 0.7038025870919228
Epoch: 77 | Iteration number: [50/565] 8% | Training loss: 0.700371013879776
Epoch: 77 | Iteration number: [60/565] 10% | Training loss: 0.6980465739965439
Epoch: 77 | Iteration number: [70/565] 12% | Training loss: 0.696444627216884
Epoch: 77 | Iteration number: [80/565] 14% | Training loss: 0.695275791734457
Epoch: 77 | Iteration number: [90/565] 15% | Training loss: 0.6943310413095686
Epoch: 77 | Iteration number: [100/565] 17% | Training loss: 0.6935809087753296
Epoch: 77 | Iteration number: [110/565] 19% | Training loss: 0.692968654090708
Epoch: 77 | Iteration number: [120/565] 21% | Training loss: 0.6924697170654933
Epoch: 77 | Iteration number: [130/565] 23% | Training loss: 0.692034440774184
Epoch: 77 | Iteration number: [140/565] 24% | Training loss: 0.6916693657636642
Epoch: 77 | Iteration number: [150/565] 26% | Training loss: 0.691364008585612
Epoch: 77 | Iteration number: [160/565] 28% | Training loss: 0.6910806830972434
Epoch: 77 | Iteration number: [170/565] 30% | Training loss: 0.6908368569963118
Epoch: 77 | Iteration number: [180/565] 31% | Training loss: 0.6905855172210269
Epoch: 77 | Iteration number: [190/565] 33% | Training loss: 0.6903864000972949
Epoch: 77 | Iteration number: [200/565] 35% | Training loss: 0.6902060988545418
Epoch: 77 | Iteration number: [210/565] 37% | Training loss: 0.6900456204300836
Epoch: 77 | Iteration number: [220/565] 38% | Training loss: 0.6898958544839512
Epoch: 77 | Iteration number: [230/565] 40% | Training loss: 0.6897629652334296
Epoch: 77 | Iteration number: [240/565] 42% | Training loss: 0.6896417334675788
Epoch: 77 | Iteration number: [250/565] 44% | Training loss: 0.6895243897438049
Epoch: 77 | Iteration number: [260/565] 46% | Training loss: 0.6894122479053644
Epoch: 77 | Iteration number: [270/565] 47% | Training loss: 0.6893220338556502
Epoch: 77 | Iteration number: [280/565] 49% | Training loss: 0.6892284538064685
Epoch: 77 | Iteration number: [290/565] 51% | Training loss: 0.6891347622049266
Epoch: 77 | Iteration number: [300/565] 53% | Training loss: 0.6890637548764547
Epoch: 77 | Iteration number: [310/565] 54% | Training loss: 0.6889762003575602
Epoch: 77 | Iteration number: [320/565] 56% | Training loss: 0.6889017291367054
Epoch: 77 | Iteration number: [330/565] 58% | Training loss: 0.6888377007209894
Epoch: 77 | Iteration number: [340/565] 60% | Training loss: 0.6887894712826785
Epoch: 77 | Iteration number: [350/565] 61% | Training loss: 0.6887405221802848
Epoch: 77 | Iteration number: [360/565] 63% | Training loss: 0.6886950951483515
Epoch: 77 | Iteration number: [370/565] 65% | Training loss: 0.6886416655939979
Epoch: 77 | Iteration number: [380/565] 67% | Training loss: 0.6885909500874972
Epoch: 77 | Iteration number: [390/565] 69% | Training loss: 0.6885507537768437
Epoch: 77 | Iteration number: [400/565] 70% | Training loss: 0.6885052767395973
Epoch: 77 | Iteration number: [410/565] 72% | Training loss: 0.6884772027411112
Epoch: 77 | Iteration number: [420/565] 74% | Training loss: 0.6884406092621032
Epoch: 77 | Iteration number: [430/565] 76% | Training loss: 0.6884017868097438
Epoch: 77 | Iteration number: [440/565] 77% | Training loss: 0.6883709973909639
Epoch: 77 | Iteration number: [450/565] 79% | Training loss: 0.6883407023217943
Epoch: 77 | Iteration number: [460/565] 81% | Training loss: 0.6883114340512649
Epoch: 77 | Iteration number: [470/565] 83% | Training loss: 0.6882807417118803
Epoch: 77 | Iteration number: [480/565] 84% | Training loss: 0.6882405164341132
Epoch: 77 | Iteration number: [490/565] 86% | Training loss: 0.6882085269811202
Epoch: 77 | Iteration number: [500/565] 88% | Training loss: 0.6881770330667496
Epoch: 77 | Iteration number: [510/565] 90% | Training loss: 0.688142993403416
Epoch: 77 | Iteration number: [520/565] 92% | Training loss: 0.6881170033262326
Epoch: 77 | Iteration number: [530/565] 93% | Training loss: 0.6880912335413807
Epoch: 77 | Iteration number: [540/565] 95% | Training loss: 0.6880628441218977
Epoch: 77 | Iteration number: [550/565] 97% | Training loss: 0.6880374496633356
Epoch: 77 | Iteration number: [560/565] 99% | Training loss: 0.6880136018352849

 End of epoch: 77 | Train Loss: 0.6867814386840415 | Training Time: 91 

 End of epoch: 77 | Eval Loss: 0.6897855656487601 | Evaluating Time: 6 
Epoch: 78 | Iteration number: [10/565] 1% | Training loss: 0.7556719899177551
Epoch: 78 | Iteration number: [20/565] 3% | Training loss: 0.7212210774421692
Epoch: 78 | Iteration number: [30/565] 5% | Training loss: 0.7096969862778981
Epoch: 78 | Iteration number: [40/565] 7% | Training loss: 0.7040358945727349
Epoch: 78 | Iteration number: [50/565] 8% | Training loss: 0.7006640565395356
Epoch: 78 | Iteration number: [60/565] 10% | Training loss: 0.6983119189739228
Epoch: 78 | Iteration number: [70/565] 12% | Training loss: 0.6966508303369795
Epoch: 78 | Iteration number: [80/565] 14% | Training loss: 0.6953529648482799
Epoch: 78 | Iteration number: [90/565] 15% | Training loss: 0.6944210165076785
Epoch: 78 | Iteration number: [100/565] 17% | Training loss: 0.693682045340538
Epoch: 78 | Iteration number: [110/565] 19% | Training loss: 0.6930214681408622
Epoch: 78 | Iteration number: [120/565] 21% | Training loss: 0.6924798722068469
Epoch: 78 | Iteration number: [130/565] 23% | Training loss: 0.6920012501569894
Epoch: 78 | Iteration number: [140/565] 24% | Training loss: 0.6916351556777954
Epoch: 78 | Iteration number: [150/565] 26% | Training loss: 0.6913144036134085
Epoch: 78 | Iteration number: [160/565] 28% | Training loss: 0.6910547699779273
Epoch: 78 | Iteration number: [170/565] 30% | Training loss: 0.6907682478427887
Epoch: 78 | Iteration number: [180/565] 31% | Training loss: 0.6905515511830648
Epoch: 78 | Iteration number: [190/565] 33% | Training loss: 0.6903589700397692
Epoch: 78 | Iteration number: [200/565] 35% | Training loss: 0.6901714530587196
Epoch: 78 | Iteration number: [210/565] 37% | Training loss: 0.6900113264719645
Epoch: 78 | Iteration number: [220/565] 38% | Training loss: 0.6898812765424902
Epoch: 78 | Iteration number: [230/565] 40% | Training loss: 0.6897429888663085
Epoch: 78 | Iteration number: [240/565] 42% | Training loss: 0.68961911474665
Epoch: 78 | Iteration number: [250/565] 44% | Training loss: 0.6895132768154144
Epoch: 78 | Iteration number: [260/565] 46% | Training loss: 0.689413829950186
Epoch: 78 | Iteration number: [270/565] 47% | Training loss: 0.6893081956439548
Epoch: 78 | Iteration number: [280/565] 49% | Training loss: 0.689216285943985
Epoch: 78 | Iteration number: [290/565] 51% | Training loss: 0.6891253126078638
Epoch: 78 | Iteration number: [300/565] 53% | Training loss: 0.6890526368220647
Epoch: 78 | Iteration number: [310/565] 54% | Training loss: 0.6889696338484365
Epoch: 78 | Iteration number: [320/565] 56% | Training loss: 0.6889105513691902
Epoch: 78 | Iteration number: [330/565] 58% | Training loss: 0.6888441804683569
Epoch: 78 | Iteration number: [340/565] 60% | Training loss: 0.6887907464714611
Epoch: 78 | Iteration number: [350/565] 61% | Training loss: 0.6887334583486829
Epoch: 78 | Iteration number: [360/565] 63% | Training loss: 0.688680401775572
Epoch: 78 | Iteration number: [370/565] 65% | Training loss: 0.6886380203672358
Epoch: 78 | Iteration number: [380/565] 67% | Training loss: 0.6885855180652518
Epoch: 78 | Iteration number: [390/565] 69% | Training loss: 0.6885231968684075
Epoch: 78 | Iteration number: [400/565] 70% | Training loss: 0.6884808948636055
Epoch: 78 | Iteration number: [410/565] 72% | Training loss: 0.688434587164623
Epoch: 78 | Iteration number: [420/565] 74% | Training loss: 0.6884010306426457
Epoch: 78 | Iteration number: [430/565] 76% | Training loss: 0.6883736377538636
Epoch: 78 | Iteration number: [440/565] 77% | Training loss: 0.6883380448276346
Epoch: 78 | Iteration number: [450/565] 79% | Training loss: 0.6883050665590498
Epoch: 78 | Iteration number: [460/565] 81% | Training loss: 0.6882857204779335
Epoch: 78 | Iteration number: [470/565] 83% | Training loss: 0.68825491337066
Epoch: 78 | Iteration number: [480/565] 84% | Training loss: 0.6882222478588422
Epoch: 78 | Iteration number: [490/565] 86% | Training loss: 0.688189841776478
Epoch: 78 | Iteration number: [500/565] 88% | Training loss: 0.688162220954895
Epoch: 78 | Iteration number: [510/565] 90% | Training loss: 0.6881341345169965
Epoch: 78 | Iteration number: [520/565] 92% | Training loss: 0.6881015178102713
Epoch: 78 | Iteration number: [530/565] 93% | Training loss: 0.6880779543012943
Epoch: 78 | Iteration number: [540/565] 95% | Training loss: 0.6880450010299682
Epoch: 78 | Iteration number: [550/565] 97% | Training loss: 0.6880098822983829
Epoch: 78 | Iteration number: [560/565] 99% | Training loss: 0.6879952560578074

 End of epoch: 78 | Train Loss: 0.6867725235171023 | Training Time: 90 

 End of epoch: 78 | Eval Loss: 0.6894171748842511 | Evaluating Time: 6 
Epoch: 79 | Iteration number: [10/565] 1% | Training loss: 0.7557624578475952
Epoch: 79 | Iteration number: [20/565] 3% | Training loss: 0.7212758928537368
Epoch: 79 | Iteration number: [30/565] 5% | Training loss: 0.7098770598570506
Epoch: 79 | Iteration number: [40/565] 7% | Training loss: 0.7041104838252068
Epoch: 79 | Iteration number: [50/565] 8% | Training loss: 0.7007571578025817
Epoch: 79 | Iteration number: [60/565] 10% | Training loss: 0.6983976463476816
Epoch: 79 | Iteration number: [70/565] 12% | Training loss: 0.696766756262098
Epoch: 79 | Iteration number: [80/565] 14% | Training loss: 0.6955259762704372
Epoch: 79 | Iteration number: [90/565] 15% | Training loss: 0.694527765777376
Epoch: 79 | Iteration number: [100/565] 17% | Training loss: 0.6937190455198288
Epoch: 79 | Iteration number: [110/565] 19% | Training loss: 0.6930894970893859
Epoch: 79 | Iteration number: [120/565] 21% | Training loss: 0.6925558730959892
Epoch: 79 | Iteration number: [130/565] 23% | Training loss: 0.6921202219449557
Epoch: 79 | Iteration number: [140/565] 24% | Training loss: 0.6917331533772605
Epoch: 79 | Iteration number: [150/565] 26% | Training loss: 0.6914024460315704
Epoch: 79 | Iteration number: [160/565] 28% | Training loss: 0.6911035180091858
Epoch: 79 | Iteration number: [170/565] 30% | Training loss: 0.6908511813949136
Epoch: 79 | Iteration number: [180/565] 31% | Training loss: 0.6906214786900414
Epoch: 79 | Iteration number: [190/565] 33% | Training loss: 0.6904302396272358
Epoch: 79 | Iteration number: [200/565] 35% | Training loss: 0.6902664279937745
Epoch: 79 | Iteration number: [210/565] 37% | Training loss: 0.6900819826693761
Epoch: 79 | Iteration number: [220/565] 38% | Training loss: 0.689950707283887
Epoch: 79 | Iteration number: [230/565] 40% | Training loss: 0.6897991164870884
Epoch: 79 | Iteration number: [240/565] 42% | Training loss: 0.6896600045263768
Epoch: 79 | Iteration number: [250/565] 44% | Training loss: 0.6895574607849121
Epoch: 79 | Iteration number: [260/565] 46% | Training loss: 0.6894542866028273
Epoch: 79 | Iteration number: [270/565] 47% | Training loss: 0.6893403377797869
Epoch: 79 | Iteration number: [280/565] 49% | Training loss: 0.6892521777323314
Epoch: 79 | Iteration number: [290/565] 51% | Training loss: 0.6891765584205759
Epoch: 79 | Iteration number: [300/565] 53% | Training loss: 0.6891046382983526
Epoch: 79 | Iteration number: [310/565] 54% | Training loss: 0.6890260659879254
Epoch: 79 | Iteration number: [320/565] 56% | Training loss: 0.6889433667063714
Epoch: 79 | Iteration number: [330/565] 58% | Training loss: 0.6888855347127626
Epoch: 79 | Iteration number: [340/565] 60% | Training loss: 0.6888253078741186
Epoch: 79 | Iteration number: [350/565] 61% | Training loss: 0.6887694185120719
Epoch: 79 | Iteration number: [360/565] 63% | Training loss: 0.6887089331944783
Epoch: 79 | Iteration number: [370/565] 65% | Training loss: 0.6886682806788265
Epoch: 79 | Iteration number: [380/565] 67% | Training loss: 0.6886140111245607
Epoch: 79 | Iteration number: [390/565] 69% | Training loss: 0.6885638666458619
Epoch: 79 | Iteration number: [400/565] 70% | Training loss: 0.6885166189074516
Epoch: 79 | Iteration number: [410/565] 72% | Training loss: 0.6884749326764084
Epoch: 79 | Iteration number: [420/565] 74% | Training loss: 0.6884429988406954
Epoch: 79 | Iteration number: [430/565] 76% | Training loss: 0.6883982347887616
Epoch: 79 | Iteration number: [440/565] 77% | Training loss: 0.6883640145713633
Epoch: 79 | Iteration number: [450/565] 79% | Training loss: 0.6883272058433957
Epoch: 79 | Iteration number: [460/565] 81% | Training loss: 0.6883028787115346
Epoch: 79 | Iteration number: [470/565] 83% | Training loss: 0.6882722390458939
Epoch: 79 | Iteration number: [480/565] 84% | Training loss: 0.6882343977689743
Epoch: 79 | Iteration number: [490/565] 86% | Training loss: 0.6881937020895432
Epoch: 79 | Iteration number: [500/565] 88% | Training loss: 0.688153621673584
Epoch: 79 | Iteration number: [510/565] 90% | Training loss: 0.688118695862153
Epoch: 79 | Iteration number: [520/565] 92% | Training loss: 0.6880935694162662
Epoch: 79 | Iteration number: [530/565] 93% | Training loss: 0.688065487596224
Epoch: 79 | Iteration number: [540/565] 95% | Training loss: 0.688040867999748
Epoch: 79 | Iteration number: [550/565] 97% | Training loss: 0.6880145766518333
Epoch: 79 | Iteration number: [560/565] 99% | Training loss: 0.6879897580615112

 End of epoch: 79 | Train Loss: 0.6867646474753861 | Training Time: 89 

 End of epoch: 79 | Eval Loss: 0.6898005178996495 | Evaluating Time: 6 
Epoch: 80 | Iteration number: [10/565] 1% | Training loss: 0.7552826464176178
Epoch: 80 | Iteration number: [20/565] 3% | Training loss: 0.7210844933986664
Epoch: 80 | Iteration number: [30/565] 5% | Training loss: 0.7097858508427938
Epoch: 80 | Iteration number: [40/565] 7% | Training loss: 0.7041534751653671
Epoch: 80 | Iteration number: [50/565] 8% | Training loss: 0.7006189966201782
Epoch: 80 | Iteration number: [60/565] 10% | Training loss: 0.6982733309268951
Epoch: 80 | Iteration number: [70/565] 12% | Training loss: 0.6966619168009077
Epoch: 80 | Iteration number: [80/565] 14% | Training loss: 0.6953776940703392
Epoch: 80 | Iteration number: [90/565] 15% | Training loss: 0.69443754752477
Epoch: 80 | Iteration number: [100/565] 17% | Training loss: 0.6937136644124985
Epoch: 80 | Iteration number: [110/565] 19% | Training loss: 0.6930432883175937
Epoch: 80 | Iteration number: [120/565] 21% | Training loss: 0.692480331659317
Epoch: 80 | Iteration number: [130/565] 23% | Training loss: 0.6920481292101053
Epoch: 80 | Iteration number: [140/565] 24% | Training loss: 0.6916609559740339
Epoch: 80 | Iteration number: [150/565] 26% | Training loss: 0.6913363925615946
Epoch: 80 | Iteration number: [160/565] 28% | Training loss: 0.6910463742911815
Epoch: 80 | Iteration number: [170/565] 30% | Training loss: 0.6907894036349128
Epoch: 80 | Iteration number: [180/565] 31% | Training loss: 0.690594537390603
Epoch: 80 | Iteration number: [190/565] 33% | Training loss: 0.6903910671409808
Epoch: 80 | Iteration number: [200/565] 35% | Training loss: 0.690206680893898
Epoch: 80 | Iteration number: [210/565] 37% | Training loss: 0.6900758240904127
Epoch: 80 | Iteration number: [220/565] 38% | Training loss: 0.6899175849827853
Epoch: 80 | Iteration number: [230/565] 40% | Training loss: 0.6897708154242972
Epoch: 80 | Iteration number: [240/565] 42% | Training loss: 0.6896370480457942
Epoch: 80 | Iteration number: [250/565] 44% | Training loss: 0.6895148482322693
Epoch: 80 | Iteration number: [260/565] 46% | Training loss: 0.6894009840029937
Epoch: 80 | Iteration number: [270/565] 47% | Training loss: 0.6892920390323356
Epoch: 80 | Iteration number: [280/565] 49% | Training loss: 0.6892205796071461
Epoch: 80 | Iteration number: [290/565] 51% | Training loss: 0.6891397708448871
Epoch: 80 | Iteration number: [300/565] 53% | Training loss: 0.6890670798222224
Epoch: 80 | Iteration number: [310/565] 54% | Training loss: 0.6890038936368881
Epoch: 80 | Iteration number: [320/565] 56% | Training loss: 0.6889357000589371
Epoch: 80 | Iteration number: [330/565] 58% | Training loss: 0.6888725945443818
Epoch: 80 | Iteration number: [340/565] 60% | Training loss: 0.6888252105783014
Epoch: 80 | Iteration number: [350/565] 61% | Training loss: 0.6887637378488268
Epoch: 80 | Iteration number: [360/565] 63% | Training loss: 0.6887172175778283
Epoch: 80 | Iteration number: [370/565] 65% | Training loss: 0.6886573499924428
Epoch: 80 | Iteration number: [380/565] 67% | Training loss: 0.6886082023382187
Epoch: 80 | Iteration number: [390/565] 69% | Training loss: 0.6885649827810434
Epoch: 80 | Iteration number: [400/565] 70% | Training loss: 0.6885174585878849
Epoch: 80 | Iteration number: [410/565] 72% | Training loss: 0.6884744446452071
Epoch: 80 | Iteration number: [420/565] 74% | Training loss: 0.6884301143033164
Epoch: 80 | Iteration number: [430/565] 76% | Training loss: 0.6884020978628203
Epoch: 80 | Iteration number: [440/565] 77% | Training loss: 0.6883669626983729
Epoch: 80 | Iteration number: [450/565] 79% | Training loss: 0.6883314412169986
Epoch: 80 | Iteration number: [460/565] 81% | Training loss: 0.6882928979137669
Epoch: 80 | Iteration number: [470/565] 83% | Training loss: 0.6882516915493823
Epoch: 80 | Iteration number: [480/565] 84% | Training loss: 0.6882239075998465
Epoch: 80 | Iteration number: [490/565] 86% | Training loss: 0.6881896233072087
Epoch: 80 | Iteration number: [500/565] 88% | Training loss: 0.6881481931209564
Epoch: 80 | Iteration number: [510/565] 90% | Training loss: 0.6881109130148794
Epoch: 80 | Iteration number: [520/565] 92% | Training loss: 0.6880843772337987
Epoch: 80 | Iteration number: [530/565] 93% | Training loss: 0.6880598136838877
Epoch: 80 | Iteration number: [540/565] 95% | Training loss: 0.6880336395016423
Epoch: 80 | Iteration number: [550/565] 97% | Training loss: 0.6880020919713107
Epoch: 80 | Iteration number: [560/565] 99% | Training loss: 0.6879877548132624

 End of epoch: 80 | Train Loss: 0.6867666821564193 | Training Time: 89 

 End of epoch: 80 | Eval Loss: 0.6893813950674874 | Evaluating Time: 6 
Epoch: 81 | Iteration number: [10/565] 1% | Training loss: 0.7557543039321899
Epoch: 81 | Iteration number: [20/565] 3% | Training loss: 0.7213694423437118
Epoch: 81 | Iteration number: [30/565] 5% | Training loss: 0.7099893232186635
Epoch: 81 | Iteration number: [40/565] 7% | Training loss: 0.7042123436927795
Epoch: 81 | Iteration number: [50/565] 8% | Training loss: 0.7007087814807892
Epoch: 81 | Iteration number: [60/565] 10% | Training loss: 0.6983477224906286
Epoch: 81 | Iteration number: [70/565] 12% | Training loss: 0.696704294851848
Epoch: 81 | Iteration number: [80/565] 14% | Training loss: 0.695506875962019
Epoch: 81 | Iteration number: [90/565] 15% | Training loss: 0.6945555614100563
Epoch: 81 | Iteration number: [100/565] 17% | Training loss: 0.6937289357185363
Epoch: 81 | Iteration number: [110/565] 19% | Training loss: 0.6931426573883404
Epoch: 81 | Iteration number: [120/565] 21% | Training loss: 0.6926224107543627
Epoch: 81 | Iteration number: [130/565] 23% | Training loss: 0.69218909740448
Epoch: 81 | Iteration number: [140/565] 24% | Training loss: 0.6918006530829839
Epoch: 81 | Iteration number: [150/565] 26% | Training loss: 0.69145521124204
Epoch: 81 | Iteration number: [160/565] 28% | Training loss: 0.6911627490073442
Epoch: 81 | Iteration number: [170/565] 30% | Training loss: 0.6909078706713284
Epoch: 81 | Iteration number: [180/565] 31% | Training loss: 0.6907056424352858
Epoch: 81 | Iteration number: [190/565] 33% | Training loss: 0.6904952689221031
Epoch: 81 | Iteration number: [200/565] 35% | Training loss: 0.6903033900260925
Epoch: 81 | Iteration number: [210/565] 37% | Training loss: 0.6901470857007163
Epoch: 81 | Iteration number: [220/565] 38% | Training loss: 0.689988084543835
Epoch: 81 | Iteration number: [230/565] 40% | Training loss: 0.6898459263469862
Epoch: 81 | Iteration number: [240/565] 42% | Training loss: 0.6897085271775723
Epoch: 81 | Iteration number: [250/565] 44% | Training loss: 0.6895775027275085
Epoch: 81 | Iteration number: [260/565] 46% | Training loss: 0.6894641523177807
Epoch: 81 | Iteration number: [270/565] 47% | Training loss: 0.6893612852802983
Epoch: 81 | Iteration number: [280/565] 49% | Training loss: 0.6892748913594655
Epoch: 81 | Iteration number: [290/565] 51% | Training loss: 0.6891995941770488
Epoch: 81 | Iteration number: [300/565] 53% | Training loss: 0.689102622270584
Epoch: 81 | Iteration number: [310/565] 54% | Training loss: 0.6890125711118021
Epoch: 81 | Iteration number: [320/565] 56% | Training loss: 0.6889511823654175
Epoch: 81 | Iteration number: [330/565] 58% | Training loss: 0.6888742284341292
Epoch: 81 | Iteration number: [340/565] 60% | Training loss: 0.6888205437099233
Epoch: 81 | Iteration number: [350/565] 61% | Training loss: 0.6887623969146184
Epoch: 81 | Iteration number: [360/565] 63% | Training loss: 0.688700800968541
Epoch: 81 | Iteration number: [370/565] 65% | Training loss: 0.6886533561590555
Epoch: 81 | Iteration number: [380/565] 67% | Training loss: 0.6885924797309072
Epoch: 81 | Iteration number: [390/565] 69% | Training loss: 0.6885395679718409
Epoch: 81 | Iteration number: [400/565] 70% | Training loss: 0.6885004131495953
Epoch: 81 | Iteration number: [410/565] 72% | Training loss: 0.6884571921534655
Epoch: 81 | Iteration number: [420/565] 74% | Training loss: 0.6884040222281501
Epoch: 81 | Iteration number: [430/565] 76% | Training loss: 0.6883800970953564
Epoch: 81 | Iteration number: [440/565] 77% | Training loss: 0.6883430035276846
Epoch: 81 | Iteration number: [450/565] 79% | Training loss: 0.688311673535241
Epoch: 81 | Iteration number: [460/565] 81% | Training loss: 0.6882763274337934
Epoch: 81 | Iteration number: [470/565] 83% | Training loss: 0.68824061408956
Epoch: 81 | Iteration number: [480/565] 84% | Training loss: 0.6882079930355152
Epoch: 81 | Iteration number: [490/565] 86% | Training loss: 0.6881697486857978
Epoch: 81 | Iteration number: [500/565] 88% | Training loss: 0.6881546618938446
Epoch: 81 | Iteration number: [510/565] 90% | Training loss: 0.688124481603211
Epoch: 81 | Iteration number: [520/565] 92% | Training loss: 0.688098940711755
Epoch: 81 | Iteration number: [530/565] 93% | Training loss: 0.6880752389161092
Epoch: 81 | Iteration number: [540/565] 95% | Training loss: 0.6880478813692376
Epoch: 81 | Iteration number: [550/565] 97% | Training loss: 0.6880257659608667
Epoch: 81 | Iteration number: [560/565] 99% | Training loss: 0.6879981283630644

 End of epoch: 81 | Train Loss: 0.6867724220309638 | Training Time: 90 

 End of epoch: 81 | Eval Loss: 0.6893254603658404 | Evaluating Time: 6 
Epoch: 82 | Iteration number: [10/565] 1% | Training loss: 0.755310696363449
Epoch: 82 | Iteration number: [20/565] 3% | Training loss: 0.7210289895534515
Epoch: 82 | Iteration number: [30/565] 5% | Training loss: 0.7095925211906433
Epoch: 82 | Iteration number: [40/565] 7% | Training loss: 0.703919206559658
Epoch: 82 | Iteration number: [50/565] 8% | Training loss: 0.7004682040214538
Epoch: 82 | Iteration number: [60/565] 10% | Training loss: 0.6981548557678858
Epoch: 82 | Iteration number: [70/565] 12% | Training loss: 0.6965229170663017
Epoch: 82 | Iteration number: [80/565] 14% | Training loss: 0.6952841147780419
Epoch: 82 | Iteration number: [90/565] 15% | Training loss: 0.6943228006362915
Epoch: 82 | Iteration number: [100/565] 17% | Training loss: 0.6935329538583755
Epoch: 82 | Iteration number: [110/565] 19% | Training loss: 0.6928747312589125
Epoch: 82 | Iteration number: [120/565] 21% | Training loss: 0.6923720116416613
Epoch: 82 | Iteration number: [130/565] 23% | Training loss: 0.6919601348730234
Epoch: 82 | Iteration number: [140/565] 24% | Training loss: 0.6915836083037513
Epoch: 82 | Iteration number: [150/565] 26% | Training loss: 0.69128244916598
Epoch: 82 | Iteration number: [160/565] 28% | Training loss: 0.6910039789974689
Epoch: 82 | Iteration number: [170/565] 30% | Training loss: 0.6907571175519158
Epoch: 82 | Iteration number: [180/565] 31% | Training loss: 0.6905236717727449
Epoch: 82 | Iteration number: [190/565] 33% | Training loss: 0.6903070220821782
Epoch: 82 | Iteration number: [200/565] 35% | Training loss: 0.6901228818297386
Epoch: 82 | Iteration number: [210/565] 37% | Training loss: 0.689965340069362
Epoch: 82 | Iteration number: [220/565] 38% | Training loss: 0.6898355237462304
Epoch: 82 | Iteration number: [230/565] 40% | Training loss: 0.6897046332773955
Epoch: 82 | Iteration number: [240/565] 42% | Training loss: 0.6895739922920863
Epoch: 82 | Iteration number: [250/565] 44% | Training loss: 0.6894553766250611
Epoch: 82 | Iteration number: [260/565] 46% | Training loss: 0.6893648901811013
Epoch: 82 | Iteration number: [270/565] 47% | Training loss: 0.689279188712438
Epoch: 82 | Iteration number: [280/565] 49% | Training loss: 0.6891882253544671
Epoch: 82 | Iteration number: [290/565] 51% | Training loss: 0.689095256657436
Epoch: 82 | Iteration number: [300/565] 53% | Training loss: 0.6890093610684077
Epoch: 82 | Iteration number: [310/565] 54% | Training loss: 0.6889545855983611
Epoch: 82 | Iteration number: [320/565] 56% | Training loss: 0.688883645273745
Epoch: 82 | Iteration number: [330/565] 58% | Training loss: 0.6888311846689744
Epoch: 82 | Iteration number: [340/565] 60% | Training loss: 0.688776433467865
Epoch: 82 | Iteration number: [350/565] 61% | Training loss: 0.6886985564231872
Epoch: 82 | Iteration number: [360/565] 63% | Training loss: 0.6886475885907809
Epoch: 82 | Iteration number: [370/565] 65% | Training loss: 0.6886002635633623
Epoch: 82 | Iteration number: [380/565] 67% | Training loss: 0.6885531961917877
Epoch: 82 | Iteration number: [390/565] 69% | Training loss: 0.6885070819121141
Epoch: 82 | Iteration number: [400/565] 70% | Training loss: 0.6884812177717685
Epoch: 82 | Iteration number: [410/565] 72% | Training loss: 0.6884455728821638
Epoch: 82 | Iteration number: [420/565] 74% | Training loss: 0.6884068009399232
Epoch: 82 | Iteration number: [430/565] 76% | Training loss: 0.6883688813032106
Epoch: 82 | Iteration number: [440/565] 77% | Training loss: 0.6883321273055943
Epoch: 82 | Iteration number: [450/565] 79% | Training loss: 0.6882972988817427
Epoch: 82 | Iteration number: [460/565] 81% | Training loss: 0.6882677373678788
Epoch: 82 | Iteration number: [470/565] 83% | Training loss: 0.6882353356544008
Epoch: 82 | Iteration number: [480/565] 84% | Training loss: 0.6881959948688745
Epoch: 82 | Iteration number: [490/565] 86% | Training loss: 0.6881594822114828
Epoch: 82 | Iteration number: [500/565] 88% | Training loss: 0.6881406838893891
Epoch: 82 | Iteration number: [510/565] 90% | Training loss: 0.6881171249875835
Epoch: 82 | Iteration number: [520/565] 92% | Training loss: 0.6880850468690579
Epoch: 82 | Iteration number: [530/565] 93% | Training loss: 0.6880560692751183
Epoch: 82 | Iteration number: [540/565] 95% | Training loss: 0.6880370418230692
Epoch: 82 | Iteration number: [550/565] 97% | Training loss: 0.6880068814754486
Epoch: 82 | Iteration number: [560/565] 99% | Training loss: 0.6879904477724007

 End of epoch: 82 | Train Loss: 0.6867647449527167 | Training Time: 89 

 End of epoch: 82 | Eval Loss: 0.6895968573434013 | Evaluating Time: 5 
Epoch: 83 | Iteration number: [10/565] 1% | Training loss: 0.7553264617919921
Epoch: 83 | Iteration number: [20/565] 3% | Training loss: 0.721009424328804
Epoch: 83 | Iteration number: [30/565] 5% | Training loss: 0.7095134596029917
Epoch: 83 | Iteration number: [40/565] 7% | Training loss: 0.7037697121500969
Epoch: 83 | Iteration number: [50/565] 8% | Training loss: 0.7004308700561523
Epoch: 83 | Iteration number: [60/565] 10% | Training loss: 0.6980449686447779
Epoch: 83 | Iteration number: [70/565] 12% | Training loss: 0.696473136969975
Epoch: 83 | Iteration number: [80/565] 14% | Training loss: 0.6952159680426121
Epoch: 83 | Iteration number: [90/565] 15% | Training loss: 0.6943161480956608
Epoch: 83 | Iteration number: [100/565] 17% | Training loss: 0.6935395461320877
Epoch: 83 | Iteration number: [110/565] 19% | Training loss: 0.6929663175886328
Epoch: 83 | Iteration number: [120/565] 21% | Training loss: 0.6924317489067714
Epoch: 83 | Iteration number: [130/565] 23% | Training loss: 0.6920179082797124
Epoch: 83 | Iteration number: [140/565] 24% | Training loss: 0.6916374334267208
Epoch: 83 | Iteration number: [150/565] 26% | Training loss: 0.6912911319732666
Epoch: 83 | Iteration number: [160/565] 28% | Training loss: 0.6910038478672504
Epoch: 83 | Iteration number: [170/565] 30% | Training loss: 0.6907546867342557
Epoch: 83 | Iteration number: [180/565] 31% | Training loss: 0.6905210839377509
Epoch: 83 | Iteration number: [190/565] 33% | Training loss: 0.6903369153800764
Epoch: 83 | Iteration number: [200/565] 35% | Training loss: 0.6901695111393928
Epoch: 83 | Iteration number: [210/565] 37% | Training loss: 0.6900196716898963
Epoch: 83 | Iteration number: [220/565] 38% | Training loss: 0.6898751478303563
Epoch: 83 | Iteration number: [230/565] 40% | Training loss: 0.6897403947685076
Epoch: 83 | Iteration number: [240/565] 42% | Training loss: 0.6896364547312259
Epoch: 83 | Iteration number: [250/565] 44% | Training loss: 0.6895229692459106
Epoch: 83 | Iteration number: [260/565] 46% | Training loss: 0.6894267412332388
Epoch: 83 | Iteration number: [270/565] 47% | Training loss: 0.6893237116160216
Epoch: 83 | Iteration number: [280/565] 49% | Training loss: 0.6892407755766596
Epoch: 83 | Iteration number: [290/565] 51% | Training loss: 0.6891577971392664
Epoch: 83 | Iteration number: [300/565] 53% | Training loss: 0.6890843472878139
Epoch: 83 | Iteration number: [310/565] 54% | Training loss: 0.6890012842993583
Epoch: 83 | Iteration number: [320/565] 56% | Training loss: 0.688940055668354
Epoch: 83 | Iteration number: [330/565] 58% | Training loss: 0.6888816329565915
Epoch: 83 | Iteration number: [340/565] 60% | Training loss: 0.6888124360757716
Epoch: 83 | Iteration number: [350/565] 61% | Training loss: 0.6887611058780125
Epoch: 83 | Iteration number: [360/565] 63% | Training loss: 0.6887214102678829
Epoch: 83 | Iteration number: [370/565] 65% | Training loss: 0.6886581050383078
Epoch: 83 | Iteration number: [380/565] 67% | Training loss: 0.6886051703440516
Epoch: 83 | Iteration number: [390/565] 69% | Training loss: 0.6885546716359946
Epoch: 83 | Iteration number: [400/565] 70% | Training loss: 0.6885091304779053
Epoch: 83 | Iteration number: [410/565] 72% | Training loss: 0.6884728046452127
Epoch: 83 | Iteration number: [420/565] 74% | Training loss: 0.6884314735730489
Epoch: 83 | Iteration number: [430/565] 76% | Training loss: 0.6883845849092617
Epoch: 83 | Iteration number: [440/565] 77% | Training loss: 0.6883409321308136
Epoch: 83 | Iteration number: [450/565] 79% | Training loss: 0.6883104092544979
Epoch: 83 | Iteration number: [460/565] 81% | Training loss: 0.6882730931043625
Epoch: 83 | Iteration number: [470/565] 83% | Training loss: 0.6882444476827662
Epoch: 83 | Iteration number: [480/565] 84% | Training loss: 0.6882128186523915
Epoch: 83 | Iteration number: [490/565] 86% | Training loss: 0.6881823710032872
Epoch: 83 | Iteration number: [500/565] 88% | Training loss: 0.6881478953361512
Epoch: 83 | Iteration number: [510/565] 90% | Training loss: 0.6881255212952109
Epoch: 83 | Iteration number: [520/565] 92% | Training loss: 0.6880952106072352
Epoch: 83 | Iteration number: [530/565] 93% | Training loss: 0.6880789227080795
Epoch: 83 | Iteration number: [540/565] 95% | Training loss: 0.6880530649865115
Epoch: 83 | Iteration number: [550/565] 97% | Training loss: 0.6880339239944111
Epoch: 83 | Iteration number: [560/565] 99% | Training loss: 0.6880113340914249

 End of epoch: 83 | Train Loss: 0.6867875578129186 | Training Time: 90 

 End of epoch: 83 | Eval Loss: 0.6899837255477905 | Evaluating Time: 6 
Epoch: 84 | Iteration number: [10/565] 1% | Training loss: 0.7553291499614716
Epoch: 84 | Iteration number: [20/565] 3% | Training loss: 0.7210120886564255
Epoch: 84 | Iteration number: [30/565] 5% | Training loss: 0.7096385995546977
Epoch: 84 | Iteration number: [40/565] 7% | Training loss: 0.7038939625024796
Epoch: 84 | Iteration number: [50/565] 8% | Training loss: 0.7005300009250641
Epoch: 84 | Iteration number: [60/565] 10% | Training loss: 0.6982805083195368
Epoch: 84 | Iteration number: [70/565] 12% | Training loss: 0.6966209403106145
Epoch: 84 | Iteration number: [80/565] 14% | Training loss: 0.6953593954443932
Epoch: 84 | Iteration number: [90/565] 15% | Training loss: 0.6943516711393992
Epoch: 84 | Iteration number: [100/565] 17% | Training loss: 0.6935764884948731
Epoch: 84 | Iteration number: [110/565] 19% | Training loss: 0.6929675568233836
Epoch: 84 | Iteration number: [120/565] 21% | Training loss: 0.6924689715107282
Epoch: 84 | Iteration number: [130/565] 23% | Training loss: 0.6920130816789773
Epoch: 84 | Iteration number: [140/565] 24% | Training loss: 0.6916328268391746
Epoch: 84 | Iteration number: [150/565] 26% | Training loss: 0.6912891968091329
Epoch: 84 | Iteration number: [160/565] 28% | Training loss: 0.6909938097000122
Epoch: 84 | Iteration number: [170/565] 30% | Training loss: 0.6907348776564879
Epoch: 84 | Iteration number: [180/565] 31% | Training loss: 0.6905185878276825
Epoch: 84 | Iteration number: [190/565] 33% | Training loss: 0.6903184504885422
Epoch: 84 | Iteration number: [200/565] 35% | Training loss: 0.6901185736060143
Epoch: 84 | Iteration number: [210/565] 37% | Training loss: 0.689954731294087
Epoch: 84 | Iteration number: [220/565] 38% | Training loss: 0.6897957996888594
Epoch: 84 | Iteration number: [230/565] 40% | Training loss: 0.6896893713785255
Epoch: 84 | Iteration number: [240/565] 42% | Training loss: 0.6895657338201999
Epoch: 84 | Iteration number: [250/565] 44% | Training loss: 0.6894451065063476
Epoch: 84 | Iteration number: [260/565] 46% | Training loss: 0.6893508333426256
Epoch: 84 | Iteration number: [270/565] 47% | Training loss: 0.68925706854573
Epoch: 84 | Iteration number: [280/565] 49% | Training loss: 0.6891777502638953
Epoch: 84 | Iteration number: [290/565] 51% | Training loss: 0.6890949493852155
Epoch: 84 | Iteration number: [300/565] 53% | Training loss: 0.6890185938278834
Epoch: 84 | Iteration number: [310/565] 54% | Training loss: 0.6889570118919496
Epoch: 84 | Iteration number: [320/565] 56% | Training loss: 0.6888645393773913
Epoch: 84 | Iteration number: [330/565] 58% | Training loss: 0.6887999180591468
Epoch: 84 | Iteration number: [340/565] 60% | Training loss: 0.6887420770000009
Epoch: 84 | Iteration number: [350/565] 61% | Training loss: 0.6886877262592316
Epoch: 84 | Iteration number: [360/565] 63% | Training loss: 0.6886229642563396
Epoch: 84 | Iteration number: [370/565] 65% | Training loss: 0.6885707189907899
Epoch: 84 | Iteration number: [380/565] 67% | Training loss: 0.6885248703391929
Epoch: 84 | Iteration number: [390/565] 69% | Training loss: 0.6884871933704767
Epoch: 84 | Iteration number: [400/565] 70% | Training loss: 0.6884452447295188
Epoch: 84 | Iteration number: [410/565] 72% | Training loss: 0.6884018413904237
Epoch: 84 | Iteration number: [420/565] 74% | Training loss: 0.6883543074131012
Epoch: 84 | Iteration number: [430/565] 76% | Training loss: 0.688326659313468
Epoch: 84 | Iteration number: [440/565] 77% | Training loss: 0.6882954732938247
Epoch: 84 | Iteration number: [450/565] 79% | Training loss: 0.6882650860150655
Epoch: 84 | Iteration number: [460/565] 81% | Training loss: 0.6882402861895769
Epoch: 84 | Iteration number: [470/565] 83% | Training loss: 0.6882144931783067
Epoch: 84 | Iteration number: [480/565] 84% | Training loss: 0.6881953197220961
Epoch: 84 | Iteration number: [490/565] 86% | Training loss: 0.6881690920615683
Epoch: 84 | Iteration number: [500/565] 88% | Training loss: 0.6881398463249206
Epoch: 84 | Iteration number: [510/565] 90% | Training loss: 0.68811803576993
Epoch: 84 | Iteration number: [520/565] 92% | Training loss: 0.6880910455034329
Epoch: 84 | Iteration number: [530/565] 93% | Training loss: 0.6880717631780876
Epoch: 84 | Iteration number: [540/565] 95% | Training loss: 0.6880507183295709
Epoch: 84 | Iteration number: [550/565] 97% | Training loss: 0.6880176137794148
Epoch: 84 | Iteration number: [560/565] 99% | Training loss: 0.6879935459366866

 End of epoch: 84 | Train Loss: 0.6867707044677397 | Training Time: 89 

 End of epoch: 84 | Eval Loss: 0.6900148817471096 | Evaluating Time: 6 
Epoch: 85 | Iteration number: [10/565] 1% | Training loss: 0.7550562441349029
Epoch: 85 | Iteration number: [20/565] 3% | Training loss: 0.7210796236991882
Epoch: 85 | Iteration number: [30/565] 5% | Training loss: 0.7095785697301229
Epoch: 85 | Iteration number: [40/565] 7% | Training loss: 0.7039188891649246
Epoch: 85 | Iteration number: [50/565] 8% | Training loss: 0.700512547492981
Epoch: 85 | Iteration number: [60/565] 10% | Training loss: 0.6982286403576533
Epoch: 85 | Iteration number: [70/565] 12% | Training loss: 0.6966107036386218
Epoch: 85 | Iteration number: [80/565] 14% | Training loss: 0.6953792840242385
Epoch: 85 | Iteration number: [90/565] 15% | Training loss: 0.6944490982426538
Epoch: 85 | Iteration number: [100/565] 17% | Training loss: 0.6936594945192337
Epoch: 85 | Iteration number: [110/565] 19% | Training loss: 0.6930479775775563
Epoch: 85 | Iteration number: [120/565] 21% | Training loss: 0.6924892475207647
Epoch: 85 | Iteration number: [130/565] 23% | Training loss: 0.6920276371332316
Epoch: 85 | Iteration number: [140/565] 24% | Training loss: 0.6916524184601648
Epoch: 85 | Iteration number: [150/565] 26% | Training loss: 0.6913271578152974
Epoch: 85 | Iteration number: [160/565] 28% | Training loss: 0.6910260241478682
Epoch: 85 | Iteration number: [170/565] 30% | Training loss: 0.6907826644532821
Epoch: 85 | Iteration number: [180/565] 31% | Training loss: 0.6905478513903088
Epoch: 85 | Iteration number: [190/565] 33% | Training loss: 0.6903474327765013
Epoch: 85 | Iteration number: [200/565] 35% | Training loss: 0.6901567581295968
Epoch: 85 | Iteration number: [210/565] 37% | Training loss: 0.6900114868368421
Epoch: 85 | Iteration number: [220/565] 38% | Training loss: 0.6898594709959898
Epoch: 85 | Iteration number: [230/565] 40% | Training loss: 0.689738632025926
Epoch: 85 | Iteration number: [240/565] 42% | Training loss: 0.689623470356067
Epoch: 85 | Iteration number: [250/565] 44% | Training loss: 0.6895175461769104
Epoch: 85 | Iteration number: [260/565] 46% | Training loss: 0.6894169018818782
Epoch: 85 | Iteration number: [270/565] 47% | Training loss: 0.6893132141342869
Epoch: 85 | Iteration number: [280/565] 49% | Training loss: 0.6892240464687347
Epoch: 85 | Iteration number: [290/565] 51% | Training loss: 0.6891473398126405
Epoch: 85 | Iteration number: [300/565] 53% | Training loss: 0.6890604297320048
Epoch: 85 | Iteration number: [310/565] 54% | Training loss: 0.6889709664929298
Epoch: 85 | Iteration number: [320/565] 56% | Training loss: 0.6889069698750973
Epoch: 85 | Iteration number: [330/565] 58% | Training loss: 0.6888348333763353
Epoch: 85 | Iteration number: [340/565] 60% | Training loss: 0.6887630313634873
Epoch: 85 | Iteration number: [350/565] 61% | Training loss: 0.6887037186963217
Epoch: 85 | Iteration number: [360/565] 63% | Training loss: 0.6886524880925814
Epoch: 85 | Iteration number: [370/565] 65% | Training loss: 0.688619469468658
Epoch: 85 | Iteration number: [380/565] 67% | Training loss: 0.688563828876144
Epoch: 85 | Iteration number: [390/565] 69% | Training loss: 0.6885050738469148
Epoch: 85 | Iteration number: [400/565] 70% | Training loss: 0.6884691867232323
Epoch: 85 | Iteration number: [410/565] 72% | Training loss: 0.688431844333323
Epoch: 85 | Iteration number: [420/565] 74% | Training loss: 0.6883939992813837
Epoch: 85 | Iteration number: [430/565] 76% | Training loss: 0.6883453981820927
Epoch: 85 | Iteration number: [440/565] 77% | Training loss: 0.688304754956202
Epoch: 85 | Iteration number: [450/565] 79% | Training loss: 0.6882713764243655
Epoch: 85 | Iteration number: [460/565] 81% | Training loss: 0.6882416503584903
Epoch: 85 | Iteration number: [470/565] 83% | Training loss: 0.6882169791992675
Epoch: 85 | Iteration number: [480/565] 84% | Training loss: 0.6881870956470569
Epoch: 85 | Iteration number: [490/565] 86% | Training loss: 0.688175592738755
Epoch: 85 | Iteration number: [500/565] 88% | Training loss: 0.6881463143825531
Epoch: 85 | Iteration number: [510/565] 90% | Training loss: 0.6881275926150527
Epoch: 85 | Iteration number: [520/565] 92% | Training loss: 0.6881034820125653
Epoch: 85 | Iteration number: [530/565] 93% | Training loss: 0.6880767426400815
Epoch: 85 | Iteration number: [540/565] 95% | Training loss: 0.6880569970166242
Epoch: 85 | Iteration number: [550/565] 97% | Training loss: 0.68802896250378
Epoch: 85 | Iteration number: [560/565] 99% | Training loss: 0.6879959265036243

 End of epoch: 85 | Train Loss: 0.6867652446822783 | Training Time: 88 

 End of epoch: 85 | Eval Loss: 0.6896687575748989 | Evaluating Time: 6 
Epoch: 86 | Iteration number: [10/565] 1% | Training loss: 0.7557701528072357
Epoch: 86 | Iteration number: [20/565] 3% | Training loss: 0.721469396352768
Epoch: 86 | Iteration number: [30/565] 5% | Training loss: 0.7097529311974843
Epoch: 86 | Iteration number: [40/565] 7% | Training loss: 0.7039867401123047
Epoch: 86 | Iteration number: [50/565] 8% | Training loss: 0.7005316460132599
Epoch: 86 | Iteration number: [60/565] 10% | Training loss: 0.6982244928677876
Epoch: 86 | Iteration number: [70/565] 12% | Training loss: 0.696612742117473
Epoch: 86 | Iteration number: [80/565] 14% | Training loss: 0.6952586613595486
Epoch: 86 | Iteration number: [90/565] 15% | Training loss: 0.6943296273549397
Epoch: 86 | Iteration number: [100/565] 17% | Training loss: 0.6935567253828049
Epoch: 86 | Iteration number: [110/565] 19% | Training loss: 0.6929415908726779
Epoch: 86 | Iteration number: [120/565] 21% | Training loss: 0.6924318328499794
Epoch: 86 | Iteration number: [130/565] 23% | Training loss: 0.6920058603470142
Epoch: 86 | Iteration number: [140/565] 24% | Training loss: 0.6916483385222298
Epoch: 86 | Iteration number: [150/565] 26% | Training loss: 0.6913479808966319
Epoch: 86 | Iteration number: [160/565] 28% | Training loss: 0.6910748429596424
Epoch: 86 | Iteration number: [170/565] 30% | Training loss: 0.6908318323247573
Epoch: 86 | Iteration number: [180/565] 31% | Training loss: 0.6906239400307338
Epoch: 86 | Iteration number: [190/565] 33% | Training loss: 0.6904377833793037
Epoch: 86 | Iteration number: [200/565] 35% | Training loss: 0.69023845911026
Epoch: 86 | Iteration number: [210/565] 37% | Training loss: 0.690080988407135
Epoch: 86 | Iteration number: [220/565] 38% | Training loss: 0.6899338188496503
Epoch: 86 | Iteration number: [230/565] 40% | Training loss: 0.6898097854593526
Epoch: 86 | Iteration number: [240/565] 42% | Training loss: 0.6896832175552845
Epoch: 86 | Iteration number: [250/565] 44% | Training loss: 0.6895603287220001
Epoch: 86 | Iteration number: [260/565] 46% | Training loss: 0.6894361530358974
Epoch: 86 | Iteration number: [270/565] 47% | Training loss: 0.6893294745021397
Epoch: 86 | Iteration number: [280/565] 49% | Training loss: 0.6892267448561532
Epoch: 86 | Iteration number: [290/565] 51% | Training loss: 0.6891485810279846
Epoch: 86 | Iteration number: [300/565] 53% | Training loss: 0.6890861302614212
Epoch: 86 | Iteration number: [310/565] 54% | Training loss: 0.6890078869558149
Epoch: 86 | Iteration number: [320/565] 56% | Training loss: 0.6889451209455728
Epoch: 86 | Iteration number: [330/565] 58% | Training loss: 0.6888730365218538
Epoch: 86 | Iteration number: [340/565] 60% | Training loss: 0.6888126494253383
Epoch: 86 | Iteration number: [350/565] 61% | Training loss: 0.6887481818880353
Epoch: 86 | Iteration number: [360/565] 63% | Training loss: 0.6886880359715886
Epoch: 86 | Iteration number: [370/565] 65% | Training loss: 0.6886301585145899
Epoch: 86 | Iteration number: [380/565] 67% | Training loss: 0.6885744579528508
Epoch: 86 | Iteration number: [390/565] 69% | Training loss: 0.6885286509990692
Epoch: 86 | Iteration number: [400/565] 70% | Training loss: 0.6884782053530216
Epoch: 86 | Iteration number: [410/565] 72% | Training loss: 0.6884416873862104
Epoch: 86 | Iteration number: [420/565] 74% | Training loss: 0.6883983365127019
Epoch: 86 | Iteration number: [430/565] 76% | Training loss: 0.68834834736447
Epoch: 86 | Iteration number: [440/565] 77% | Training loss: 0.6883149913766168
Epoch: 86 | Iteration number: [450/565] 79% | Training loss: 0.6882752798663245
Epoch: 86 | Iteration number: [460/565] 81% | Training loss: 0.6882358289283255
Epoch: 86 | Iteration number: [470/565] 83% | Training loss: 0.6882039630666692
Epoch: 86 | Iteration number: [480/565] 84% | Training loss: 0.6881726785252492
Epoch: 86 | Iteration number: [490/565] 86% | Training loss: 0.6881520475660051
Epoch: 86 | Iteration number: [500/565] 88% | Training loss: 0.6881265611648559
Epoch: 86 | Iteration number: [510/565] 90% | Training loss: 0.6881002786112767
Epoch: 86 | Iteration number: [520/565] 92% | Training loss: 0.6880721935859093
Epoch: 86 | Iteration number: [530/565] 93% | Training loss: 0.6880413404050864
Epoch: 86 | Iteration number: [540/565] 95% | Training loss: 0.6880137154349575
Epoch: 86 | Iteration number: [550/565] 97% | Training loss: 0.6879988668181679
Epoch: 86 | Iteration number: [560/565] 99% | Training loss: 0.6879794402846269

 End of epoch: 86 | Train Loss: 0.686755988239187 | Training Time: 89 

 End of epoch: 86 | Eval Loss: 0.6900564687592643 | Evaluating Time: 6 
Epoch: 87 | Iteration number: [10/565] 1% | Training loss: 0.7554443776607513
Epoch: 87 | Iteration number: [20/565] 3% | Training loss: 0.7211597323417663
Epoch: 87 | Iteration number: [30/565] 5% | Training loss: 0.7096736351648967
Epoch: 87 | Iteration number: [40/565] 7% | Training loss: 0.7040008053183555
Epoch: 87 | Iteration number: [50/565] 8% | Training loss: 0.7005157339572906
Epoch: 87 | Iteration number: [60/565] 10% | Training loss: 0.698203765352567
Epoch: 87 | Iteration number: [70/565] 12% | Training loss: 0.6965495714119503
Epoch: 87 | Iteration number: [80/565] 14% | Training loss: 0.6953441485762596
Epoch: 87 | Iteration number: [90/565] 15% | Training loss: 0.6943856961197323
Epoch: 87 | Iteration number: [100/565] 17% | Training loss: 0.6936517989635468
Epoch: 87 | Iteration number: [110/565] 19% | Training loss: 0.6930108341303739
Epoch: 87 | Iteration number: [120/565] 21% | Training loss: 0.6924632216493288
Epoch: 87 | Iteration number: [130/565] 23% | Training loss: 0.6920239769495451
Epoch: 87 | Iteration number: [140/565] 24% | Training loss: 0.691638103553227
Epoch: 87 | Iteration number: [150/565] 26% | Training loss: 0.6912865535418192
Epoch: 87 | Iteration number: [160/565] 28% | Training loss: 0.691022564843297
Epoch: 87 | Iteration number: [170/565] 30% | Training loss: 0.6907832324504852
Epoch: 87 | Iteration number: [180/565] 31% | Training loss: 0.6905220945676168
Epoch: 87 | Iteration number: [190/565] 33% | Training loss: 0.690322692770707
Epoch: 87 | Iteration number: [200/565] 35% | Training loss: 0.6901277765631676
Epoch: 87 | Iteration number: [210/565] 37% | Training loss: 0.6899781139124007
Epoch: 87 | Iteration number: [220/565] 38% | Training loss: 0.6898269347169182
Epoch: 87 | Iteration number: [230/565] 40% | Training loss: 0.6896959421427353
Epoch: 87 | Iteration number: [240/565] 42% | Training loss: 0.6895755169292291
Epoch: 87 | Iteration number: [250/565] 44% | Training loss: 0.689464510679245
Epoch: 87 | Iteration number: [260/565] 46% | Training loss: 0.6893646171459785
Epoch: 87 | Iteration number: [270/565] 47% | Training loss: 0.689271726210912
Epoch: 87 | Iteration number: [280/565] 49% | Training loss: 0.6891855833785875
Epoch: 87 | Iteration number: [290/565] 51% | Training loss: 0.689109808823158
Epoch: 87 | Iteration number: [300/565] 53% | Training loss: 0.6890454761187236
Epoch: 87 | Iteration number: [310/565] 54% | Training loss: 0.6889711810696509
Epoch: 87 | Iteration number: [320/565] 56% | Training loss: 0.6888930452987552
Epoch: 87 | Iteration number: [330/565] 58% | Training loss: 0.6888214487018007
Epoch: 87 | Iteration number: [340/565] 60% | Training loss: 0.6887682914733887
Epoch: 87 | Iteration number: [350/565] 61% | Training loss: 0.6887052135808127
Epoch: 87 | Iteration number: [360/565] 63% | Training loss: 0.6886661054359542
Epoch: 87 | Iteration number: [370/565] 65% | Training loss: 0.6886112989606084
Epoch: 87 | Iteration number: [380/565] 67% | Training loss: 0.6885697670673069
Epoch: 87 | Iteration number: [390/565] 69% | Training loss: 0.6885250618824592
Epoch: 87 | Iteration number: [400/565] 70% | Training loss: 0.6884790250658989
Epoch: 87 | Iteration number: [410/565] 72% | Training loss: 0.6884289583054984
Epoch: 87 | Iteration number: [420/565] 74% | Training loss: 0.6883817144802639
Epoch: 87 | Iteration number: [430/565] 76% | Training loss: 0.6883407272571741
Epoch: 87 | Iteration number: [440/565] 77% | Training loss: 0.6883156418800354
Epoch: 87 | Iteration number: [450/565] 79% | Training loss: 0.6882743936114841
Epoch: 87 | Iteration number: [460/565] 81% | Training loss: 0.688245827348336
Epoch: 87 | Iteration number: [470/565] 83% | Training loss: 0.6882097916400179
Epoch: 87 | Iteration number: [480/565] 84% | Training loss: 0.6881791520863771
Epoch: 87 | Iteration number: [490/565] 86% | Training loss: 0.6881557268755777
Epoch: 87 | Iteration number: [500/565] 88% | Training loss: 0.6881299008131028
Epoch: 87 | Iteration number: [510/565] 90% | Training loss: 0.6881008462578643
Epoch: 87 | Iteration number: [520/565] 92% | Training loss: 0.6880685861294086
Epoch: 87 | Iteration number: [530/565] 93% | Training loss: 0.6880458972364102
Epoch: 87 | Iteration number: [540/565] 95% | Training loss: 0.6880197126556326
Epoch: 87 | Iteration number: [550/565] 97% | Training loss: 0.688004465861754
Epoch: 87 | Iteration number: [560/565] 99% | Training loss: 0.6879889045442854

 End of epoch: 87 | Train Loss: 0.6867636078226883 | Training Time: 89 

 End of epoch: 87 | Eval Loss: 0.6899329509053912 | Evaluating Time: 6 
Epoch: 88 | Iteration number: [10/565] 1% | Training loss: 0.7559069156646728
Epoch: 88 | Iteration number: [20/565] 3% | Training loss: 0.7209705203771591
Epoch: 88 | Iteration number: [30/565] 5% | Training loss: 0.7096006214618683
Epoch: 88 | Iteration number: [40/565] 7% | Training loss: 0.7039249330759049
Epoch: 88 | Iteration number: [50/565] 8% | Training loss: 0.7005046391487122
Epoch: 88 | Iteration number: [60/565] 10% | Training loss: 0.6982422600189845
Epoch: 88 | Iteration number: [70/565] 12% | Training loss: 0.6966351211071015
Epoch: 88 | Iteration number: [80/565] 14% | Training loss: 0.6954546861350537
Epoch: 88 | Iteration number: [90/565] 15% | Training loss: 0.6944923566447364
Epoch: 88 | Iteration number: [100/565] 17% | Training loss: 0.6937240952253342
Epoch: 88 | Iteration number: [110/565] 19% | Training loss: 0.6930826328017495
Epoch: 88 | Iteration number: [120/565] 21% | Training loss: 0.692568093041579
Epoch: 88 | Iteration number: [130/565] 23% | Training loss: 0.6921710147307469
Epoch: 88 | Iteration number: [140/565] 24% | Training loss: 0.6918031556265695
Epoch: 88 | Iteration number: [150/565] 26% | Training loss: 0.6914715071519216
Epoch: 88 | Iteration number: [160/565] 28% | Training loss: 0.6911929484456778
Epoch: 88 | Iteration number: [170/565] 30% | Training loss: 0.6909309769377989
Epoch: 88 | Iteration number: [180/565] 31% | Training loss: 0.6907048443953197
Epoch: 88 | Iteration number: [190/565] 33% | Training loss: 0.6904885957115575
Epoch: 88 | Iteration number: [200/565] 35% | Training loss: 0.6902872207760811
Epoch: 88 | Iteration number: [210/565] 37% | Training loss: 0.6901335679349445
Epoch: 88 | Iteration number: [220/565] 38% | Training loss: 0.6899744868278503
Epoch: 88 | Iteration number: [230/565] 40% | Training loss: 0.6898348932680877
Epoch: 88 | Iteration number: [240/565] 42% | Training loss: 0.6897026759882768
Epoch: 88 | Iteration number: [250/565] 44% | Training loss: 0.6895757534503937
Epoch: 88 | Iteration number: [260/565] 46% | Training loss: 0.6894589130695049
Epoch: 88 | Iteration number: [270/565] 47% | Training loss: 0.6893611570199331
Epoch: 88 | Iteration number: [280/565] 49% | Training loss: 0.6892782724329404
Epoch: 88 | Iteration number: [290/565] 51% | Training loss: 0.6891895273636127
Epoch: 88 | Iteration number: [300/565] 53% | Training loss: 0.6891230740149816
Epoch: 88 | Iteration number: [310/565] 54% | Training loss: 0.6890502823937323
Epoch: 88 | Iteration number: [320/565] 56% | Training loss: 0.6889754809439183
Epoch: 88 | Iteration number: [330/565] 58% | Training loss: 0.6889067122430512
Epoch: 88 | Iteration number: [340/565] 60% | Training loss: 0.6888387150624219
Epoch: 88 | Iteration number: [350/565] 61% | Training loss: 0.6887890660762787
Epoch: 88 | Iteration number: [360/565] 63% | Training loss: 0.6887254450056288
Epoch: 88 | Iteration number: [370/565] 65% | Training loss: 0.6886720813609458
Epoch: 88 | Iteration number: [380/565] 67% | Training loss: 0.6886195435335761
Epoch: 88 | Iteration number: [390/565] 69% | Training loss: 0.6885688963608864
Epoch: 88 | Iteration number: [400/565] 70% | Training loss: 0.6885165445506573
Epoch: 88 | Iteration number: [410/565] 72% | Training loss: 0.6884595468276884
Epoch: 88 | Iteration number: [420/565] 74% | Training loss: 0.6884145252761387
Epoch: 88 | Iteration number: [430/565] 76% | Training loss: 0.6883809563725494
Epoch: 88 | Iteration number: [440/565] 77% | Training loss: 0.6883470054377209
Epoch: 88 | Iteration number: [450/565] 79% | Training loss: 0.6883134689595964
Epoch: 88 | Iteration number: [460/565] 81% | Training loss: 0.6882821308529895
Epoch: 88 | Iteration number: [470/565] 83% | Training loss: 0.6882376724101128
Epoch: 88 | Iteration number: [480/565] 84% | Training loss: 0.6882116625706355
Epoch: 88 | Iteration number: [490/565] 86% | Training loss: 0.6881879852742565
Epoch: 88 | Iteration number: [500/565] 88% | Training loss: 0.6881636753082275
Epoch: 88 | Iteration number: [510/565] 90% | Training loss: 0.6881314135065266
Epoch: 88 | Iteration number: [520/565] 92% | Training loss: 0.6881028936459468
Epoch: 88 | Iteration number: [530/565] 93% | Training loss: 0.6880730442281039
Epoch: 88 | Iteration number: [540/565] 95% | Training loss: 0.6880414328089467
Epoch: 88 | Iteration number: [550/565] 97% | Training loss: 0.6880199096419595
Epoch: 88 | Iteration number: [560/565] 99% | Training loss: 0.687984329781362

 End of epoch: 88 | Train Loss: 0.6867575964041516 | Training Time: 89 

 End of epoch: 88 | Eval Loss: 0.6899071931838989 | Evaluating Time: 6 
Epoch: 89 | Iteration number: [10/565] 1% | Training loss: 0.7550841271877289
Epoch: 89 | Iteration number: [20/565] 3% | Training loss: 0.721117177605629
Epoch: 89 | Iteration number: [30/565] 5% | Training loss: 0.7097391704718272
Epoch: 89 | Iteration number: [40/565] 7% | Training loss: 0.7039605870842933
Epoch: 89 | Iteration number: [50/565] 8% | Training loss: 0.7005473268032074
Epoch: 89 | Iteration number: [60/565] 10% | Training loss: 0.6982605367898941
Epoch: 89 | Iteration number: [70/565] 12% | Training loss: 0.6966775834560395
Epoch: 89 | Iteration number: [80/565] 14% | Training loss: 0.6953830808401108
Epoch: 89 | Iteration number: [90/565] 15% | Training loss: 0.6944239344861772
Epoch: 89 | Iteration number: [100/565] 17% | Training loss: 0.6936763054132462
Epoch: 89 | Iteration number: [110/565] 19% | Training loss: 0.6930392362854697
Epoch: 89 | Iteration number: [120/565] 21% | Training loss: 0.6924968615174294
Epoch: 89 | Iteration number: [130/565] 23% | Training loss: 0.6920261002503909
Epoch: 89 | Iteration number: [140/565] 24% | Training loss: 0.6916433789900371
Epoch: 89 | Iteration number: [150/565] 26% | Training loss: 0.6913454035917918
Epoch: 89 | Iteration number: [160/565] 28% | Training loss: 0.691065925359726
Epoch: 89 | Iteration number: [170/565] 30% | Training loss: 0.6908118521465975
Epoch: 89 | Iteration number: [180/565] 31% | Training loss: 0.6905824498997795
Epoch: 89 | Iteration number: [190/565] 33% | Training loss: 0.6903608896230397
Epoch: 89 | Iteration number: [200/565] 35% | Training loss: 0.6901995071768761
Epoch: 89 | Iteration number: [210/565] 37% | Training loss: 0.6900394138835725
Epoch: 89 | Iteration number: [220/565] 38% | Training loss: 0.6898784965276719
Epoch: 89 | Iteration number: [230/565] 40% | Training loss: 0.6897710515105206
Epoch: 89 | Iteration number: [240/565] 42% | Training loss: 0.689658024162054
Epoch: 89 | Iteration number: [250/565] 44% | Training loss: 0.6895305786132813
Epoch: 89 | Iteration number: [260/565] 46% | Training loss: 0.6894318119837688
Epoch: 89 | Iteration number: [270/565] 47% | Training loss: 0.6893249260054695
Epoch: 89 | Iteration number: [280/565] 49% | Training loss: 0.6892407470515796
Epoch: 89 | Iteration number: [290/565] 51% | Training loss: 0.689152998965362
Epoch: 89 | Iteration number: [300/565] 53% | Training loss: 0.6890818401177724
Epoch: 89 | Iteration number: [310/565] 54% | Training loss: 0.6890194844815039
Epoch: 89 | Iteration number: [320/565] 56% | Training loss: 0.6889576528221368
Epoch: 89 | Iteration number: [330/565] 58% | Training loss: 0.6888879167311119
Epoch: 89 | Iteration number: [340/565] 60% | Training loss: 0.6888317905804691
Epoch: 89 | Iteration number: [350/565] 61% | Training loss: 0.6887738973753793
Epoch: 89 | Iteration number: [360/565] 63% | Training loss: 0.6887083037032021
Epoch: 89 | Iteration number: [370/565] 65% | Training loss: 0.688652750769177
Epoch: 89 | Iteration number: [380/565] 67% | Training loss: 0.6886031797057703
Epoch: 89 | Iteration number: [390/565] 69% | Training loss: 0.6885412830572862
Epoch: 89 | Iteration number: [400/565] 70% | Training loss: 0.6884936632215977
Epoch: 89 | Iteration number: [410/565] 72% | Training loss: 0.6884484727208208
Epoch: 89 | Iteration number: [420/565] 74% | Training loss: 0.6884052876915251
Epoch: 89 | Iteration number: [430/565] 76% | Training loss: 0.6883519388908563
Epoch: 89 | Iteration number: [440/565] 77% | Training loss: 0.6883244821971113
Epoch: 89 | Iteration number: [450/565] 79% | Training loss: 0.6882894827259911
Epoch: 89 | Iteration number: [460/565] 81% | Training loss: 0.6882643792940223
Epoch: 89 | Iteration number: [470/565] 83% | Training loss: 0.6882349303428162
Epoch: 89 | Iteration number: [480/565] 84% | Training loss: 0.6882048397014539
Epoch: 89 | Iteration number: [490/565] 86% | Training loss: 0.6881716116350525
Epoch: 89 | Iteration number: [500/565] 88% | Training loss: 0.6881377530097962
Epoch: 89 | Iteration number: [510/565] 90% | Training loss: 0.6881107887801002
Epoch: 89 | Iteration number: [520/565] 92% | Training loss: 0.68808818677297
Epoch: 89 | Iteration number: [530/565] 93% | Training loss: 0.6880570455542151
Epoch: 89 | Iteration number: [540/565] 95% | Training loss: 0.688037633895874
Epoch: 89 | Iteration number: [550/565] 97% | Training loss: 0.6880072516744787
Epoch: 89 | Iteration number: [560/565] 99% | Training loss: 0.6879812035177435

 End of epoch: 89 | Train Loss: 0.6867565321711312 | Training Time: 89 

 End of epoch: 89 | Eval Loss: 0.689499420779092 | Evaluating Time: 6 
Epoch: 90 | Iteration number: [10/565] 1% | Training loss: 0.7557874858379364
Epoch: 90 | Iteration number: [20/565] 3% | Training loss: 0.7212932288646698
Epoch: 90 | Iteration number: [30/565] 5% | Training loss: 0.7097639799118042
Epoch: 90 | Iteration number: [40/565] 7% | Training loss: 0.7038795471191406
Epoch: 90 | Iteration number: [50/565] 8% | Training loss: 0.7004347693920135
Epoch: 90 | Iteration number: [60/565] 10% | Training loss: 0.6981459716955821
Epoch: 90 | Iteration number: [70/565] 12% | Training loss: 0.6965160744530814
Epoch: 90 | Iteration number: [80/565] 14% | Training loss: 0.6953399375081062
Epoch: 90 | Iteration number: [90/565] 15% | Training loss: 0.6943935301568773
Epoch: 90 | Iteration number: [100/565] 17% | Training loss: 0.6936109006404877
Epoch: 90 | Iteration number: [110/565] 19% | Training loss: 0.6929960429668427
Epoch: 90 | Iteration number: [120/565] 21% | Training loss: 0.692480116089185
Epoch: 90 | Iteration number: [130/565] 23% | Training loss: 0.6920376520890456
Epoch: 90 | Iteration number: [140/565] 24% | Training loss: 0.6916565848248345
Epoch: 90 | Iteration number: [150/565] 26% | Training loss: 0.691337327559789
Epoch: 90 | Iteration number: [160/565] 28% | Training loss: 0.691060721129179
Epoch: 90 | Iteration number: [170/565] 30% | Training loss: 0.6907926015994128
Epoch: 90 | Iteration number: [180/565] 31% | Training loss: 0.6905809746848213
Epoch: 90 | Iteration number: [190/565] 33% | Training loss: 0.6903672895933453
Epoch: 90 | Iteration number: [200/565] 35% | Training loss: 0.6901808193325997
Epoch: 90 | Iteration number: [210/565] 37% | Training loss: 0.6899792285192581
Epoch: 90 | Iteration number: [220/565] 38% | Training loss: 0.6898247951811011
Epoch: 90 | Iteration number: [230/565] 40% | Training loss: 0.6896916944047679
Epoch: 90 | Iteration number: [240/565] 42% | Training loss: 0.6895803935825825
Epoch: 90 | Iteration number: [250/565] 44% | Training loss: 0.6894868116378784
Epoch: 90 | Iteration number: [260/565] 46% | Training loss: 0.68938515323859
Epoch: 90 | Iteration number: [270/565] 47% | Training loss: 0.6892971643695125
Epoch: 90 | Iteration number: [280/565] 49% | Training loss: 0.689207090650286
Epoch: 90 | Iteration number: [290/565] 51% | Training loss: 0.6891287187050129
Epoch: 90 | Iteration number: [300/565] 53% | Training loss: 0.6890492443243662
Epoch: 90 | Iteration number: [310/565] 54% | Training loss: 0.6889861485650463
Epoch: 90 | Iteration number: [320/565] 56% | Training loss: 0.6889296714216471
Epoch: 90 | Iteration number: [330/565] 58% | Training loss: 0.6888620428966753
Epoch: 90 | Iteration number: [340/565] 60% | Training loss: 0.6887907235061421
Epoch: 90 | Iteration number: [350/565] 61% | Training loss: 0.6887213666098458
Epoch: 90 | Iteration number: [360/565] 63% | Training loss: 0.6886659358938535
Epoch: 90 | Iteration number: [370/565] 65% | Training loss: 0.6886111795902252
Epoch: 90 | Iteration number: [380/565] 67% | Training loss: 0.6885606017551924
Epoch: 90 | Iteration number: [390/565] 69% | Training loss: 0.6885171034397223
Epoch: 90 | Iteration number: [400/565] 70% | Training loss: 0.6884770672023296
Epoch: 90 | Iteration number: [410/565] 72% | Training loss: 0.6884313090545375
Epoch: 90 | Iteration number: [420/565] 74% | Training loss: 0.6883954008420309
Epoch: 90 | Iteration number: [430/565] 76% | Training loss: 0.688358702077422
Epoch: 90 | Iteration number: [440/565] 77% | Training loss: 0.6883260388265956
Epoch: 90 | Iteration number: [450/565] 79% | Training loss: 0.6882894281546275
Epoch: 90 | Iteration number: [460/565] 81% | Training loss: 0.6882598639830299
Epoch: 90 | Iteration number: [470/565] 83% | Training loss: 0.6882272227013365
Epoch: 90 | Iteration number: [480/565] 84% | Training loss: 0.6882018512735765
Epoch: 90 | Iteration number: [490/565] 86% | Training loss: 0.6881710026945387
Epoch: 90 | Iteration number: [500/565] 88% | Training loss: 0.688144708275795
Epoch: 90 | Iteration number: [510/565] 90% | Training loss: 0.688112379990372
Epoch: 90 | Iteration number: [520/565] 92% | Training loss: 0.6880895764781878
Epoch: 90 | Iteration number: [530/565] 93% | Training loss: 0.6880680042617726
Epoch: 90 | Iteration number: [540/565] 95% | Training loss: 0.6880479634911926
Epoch: 90 | Iteration number: [550/565] 97% | Training loss: 0.6880141002481635
Epoch: 90 | Iteration number: [560/565] 99% | Training loss: 0.6879806082163539

 End of epoch: 90 | Train Loss: 0.686756084978053 | Training Time: 89 

 End of epoch: 90 | Eval Loss: 0.6898621661322457 | Evaluating Time: 6 
Epoch: 91 | Iteration number: [10/565] 1% | Training loss: 0.7550694704055786
Epoch: 91 | Iteration number: [20/565] 3% | Training loss: 0.7210426598787307
Epoch: 91 | Iteration number: [30/565] 5% | Training loss: 0.7096719443798065
Epoch: 91 | Iteration number: [40/565] 7% | Training loss: 0.7039537459611893
Epoch: 91 | Iteration number: [50/565] 8% | Training loss: 0.7005162680149079
Epoch: 91 | Iteration number: [60/565] 10% | Training loss: 0.6982568989197413
Epoch: 91 | Iteration number: [70/565] 12% | Training loss: 0.6965976510729108
Epoch: 91 | Iteration number: [80/565] 14% | Training loss: 0.6953764088451863
Epoch: 91 | Iteration number: [90/565] 15% | Training loss: 0.6944004019101461
Epoch: 91 | Iteration number: [100/565] 17% | Training loss: 0.6936626672744751
Epoch: 91 | Iteration number: [110/565] 19% | Training loss: 0.6929989798502488
Epoch: 91 | Iteration number: [120/565] 21% | Training loss: 0.6925064290563265
Epoch: 91 | Iteration number: [130/565] 23% | Training loss: 0.6920683746154491
Epoch: 91 | Iteration number: [140/565] 24% | Training loss: 0.691672025833811
Epoch: 91 | Iteration number: [150/565] 26% | Training loss: 0.6913828325271606
Epoch: 91 | Iteration number: [160/565] 28% | Training loss: 0.6910845059901476
Epoch: 91 | Iteration number: [170/565] 30% | Training loss: 0.6908390038153704
Epoch: 91 | Iteration number: [180/565] 31% | Training loss: 0.6906218989027871
Epoch: 91 | Iteration number: [190/565] 33% | Training loss: 0.6903920747731861
Epoch: 91 | Iteration number: [200/565] 35% | Training loss: 0.6902079963684082
Epoch: 91 | Iteration number: [210/565] 37% | Training loss: 0.6900578549930028
Epoch: 91 | Iteration number: [220/565] 38% | Training loss: 0.6899036380377683
Epoch: 91 | Iteration number: [230/565] 40% | Training loss: 0.6897628392862237
Epoch: 91 | Iteration number: [240/565] 42% | Training loss: 0.6896205380558967
Epoch: 91 | Iteration number: [250/565] 44% | Training loss: 0.689492014169693
Epoch: 91 | Iteration number: [260/565] 46% | Training loss: 0.6893936624893775
Epoch: 91 | Iteration number: [270/565] 47% | Training loss: 0.6892878673694752
Epoch: 91 | Iteration number: [280/565] 49% | Training loss: 0.689197928564889
Epoch: 91 | Iteration number: [290/565] 51% | Training loss: 0.6891129296401451
Epoch: 91 | Iteration number: [300/565] 53% | Training loss: 0.689032774567604
Epoch: 91 | Iteration number: [310/565] 54% | Training loss: 0.6889537432501392
Epoch: 91 | Iteration number: [320/565] 56% | Training loss: 0.68888770788908
Epoch: 91 | Iteration number: [330/565] 58% | Training loss: 0.6888263586795691
Epoch: 91 | Iteration number: [340/565] 60% | Training loss: 0.6887457979076049
Epoch: 91 | Iteration number: [350/565] 61% | Training loss: 0.6886963854517255
Epoch: 91 | Iteration number: [360/565] 63% | Training loss: 0.6886464046107398
Epoch: 91 | Iteration number: [370/565] 65% | Training loss: 0.6885995359034152
Epoch: 91 | Iteration number: [380/565] 67% | Training loss: 0.6885502012152421
Epoch: 91 | Iteration number: [390/565] 69% | Training loss: 0.6885016769934923
Epoch: 91 | Iteration number: [400/565] 70% | Training loss: 0.6884632571041585
Epoch: 91 | Iteration number: [410/565] 72% | Training loss: 0.6884272031667756
Epoch: 91 | Iteration number: [420/565] 74% | Training loss: 0.6883894444931121
Epoch: 91 | Iteration number: [430/565] 76% | Training loss: 0.6883511814960214
Epoch: 91 | Iteration number: [440/565] 77% | Training loss: 0.6883198755708608
Epoch: 91 | Iteration number: [450/565] 79% | Training loss: 0.6882866831620534
Epoch: 91 | Iteration number: [460/565] 81% | Training loss: 0.6882547144008719
Epoch: 91 | Iteration number: [470/565] 83% | Training loss: 0.688223983886394
Epoch: 91 | Iteration number: [480/565] 84% | Training loss: 0.6882000600298246
Epoch: 91 | Iteration number: [490/565] 86% | Training loss: 0.6881639653322648
Epoch: 91 | Iteration number: [500/565] 88% | Training loss: 0.6881453442573547
Epoch: 91 | Iteration number: [510/565] 90% | Training loss: 0.68811267953293
Epoch: 91 | Iteration number: [520/565] 92% | Training loss: 0.68808340968994
Epoch: 91 | Iteration number: [530/565] 93% | Training loss: 0.6880575211542957
Epoch: 91 | Iteration number: [540/565] 95% | Training loss: 0.688027533226543
Epoch: 91 | Iteration number: [550/565] 97% | Training loss: 0.6879960430752148
Epoch: 91 | Iteration number: [560/565] 99% | Training loss: 0.6879763413752829

 End of epoch: 91 | Train Loss: 0.6867495738299547 | Training Time: 89 

 End of epoch: 91 | Eval Loss: 0.6899399757385254 | Evaluating Time: 6 
Epoch: 92 | Iteration number: [10/565] 1% | Training loss: 0.7557774186134338
Epoch: 92 | Iteration number: [20/565] 3% | Training loss: 0.7211732685565948
Epoch: 92 | Iteration number: [30/565] 5% | Training loss: 0.7097109476725261
Epoch: 92 | Iteration number: [40/565] 7% | Training loss: 0.7040234908461571
Epoch: 92 | Iteration number: [50/565] 8% | Training loss: 0.7005837595462799
Epoch: 92 | Iteration number: [60/565] 10% | Training loss: 0.698237360517184
Epoch: 92 | Iteration number: [70/565] 12% | Training loss: 0.696550292628152
Epoch: 92 | Iteration number: [80/565] 14% | Training loss: 0.6953464232385158
Epoch: 92 | Iteration number: [90/565] 15% | Training loss: 0.6943829582797156
Epoch: 92 | Iteration number: [100/565] 17% | Training loss: 0.6936303943395614
Epoch: 92 | Iteration number: [110/565] 19% | Training loss: 0.6930383064530112
Epoch: 92 | Iteration number: [120/565] 21% | Training loss: 0.6925650070110957
Epoch: 92 | Iteration number: [130/565] 23% | Training loss: 0.6921280663747054
Epoch: 92 | Iteration number: [140/565] 24% | Training loss: 0.6917249786002295
Epoch: 92 | Iteration number: [150/565] 26% | Training loss: 0.6914114503065745
Epoch: 92 | Iteration number: [160/565] 28% | Training loss: 0.6911267925053834
Epoch: 92 | Iteration number: [170/565] 30% | Training loss: 0.6908717071308809
Epoch: 92 | Iteration number: [180/565] 31% | Training loss: 0.6906541731622484
Epoch: 92 | Iteration number: [190/565] 33% | Training loss: 0.6904320120811462
Epoch: 92 | Iteration number: [200/565] 35% | Training loss: 0.6902564051747322
Epoch: 92 | Iteration number: [210/565] 37% | Training loss: 0.6900855433373224
Epoch: 92 | Iteration number: [220/565] 38% | Training loss: 0.6899095191196962
Epoch: 92 | Iteration number: [230/565] 40% | Training loss: 0.6897800344487895
Epoch: 92 | Iteration number: [240/565] 42% | Training loss: 0.6896364942193032
Epoch: 92 | Iteration number: [250/565] 44% | Training loss: 0.6895324530601501
Epoch: 92 | Iteration number: [260/565] 46% | Training loss: 0.6894222848690473
Epoch: 92 | Iteration number: [270/565] 47% | Training loss: 0.689324395303373
Epoch: 92 | Iteration number: [280/565] 49% | Training loss: 0.6892208388873509
Epoch: 92 | Iteration number: [290/565] 51% | Training loss: 0.6891376731724574
Epoch: 92 | Iteration number: [300/565] 53% | Training loss: 0.6890395319461823
Epoch: 92 | Iteration number: [310/565] 54% | Training loss: 0.6889737154206922
Epoch: 92 | Iteration number: [320/565] 56% | Training loss: 0.6889046728610992
Epoch: 92 | Iteration number: [330/565] 58% | Training loss: 0.6888473783478593
Epoch: 92 | Iteration number: [340/565] 60% | Training loss: 0.6887932183111415
Epoch: 92 | Iteration number: [350/565] 61% | Training loss: 0.688739402294159
Epoch: 92 | Iteration number: [360/565] 63% | Training loss: 0.6886827713913388
Epoch: 92 | Iteration number: [370/565] 65% | Training loss: 0.6886251280436645
Epoch: 92 | Iteration number: [380/565] 67% | Training loss: 0.6885652455844378
Epoch: 92 | Iteration number: [390/565] 69% | Training loss: 0.688527967990973
Epoch: 92 | Iteration number: [400/565] 70% | Training loss: 0.6884866358339786
Epoch: 92 | Iteration number: [410/565] 72% | Training loss: 0.6884400399719797
Epoch: 92 | Iteration number: [420/565] 74% | Training loss: 0.688396160659336
Epoch: 92 | Iteration number: [430/565] 76% | Training loss: 0.6883539267750673
Epoch: 92 | Iteration number: [440/565] 77% | Training loss: 0.688318048146638
Epoch: 92 | Iteration number: [450/565] 79% | Training loss: 0.6882804012298585
Epoch: 92 | Iteration number: [460/565] 81% | Training loss: 0.688247226761735
Epoch: 92 | Iteration number: [470/565] 83% | Training loss: 0.6882159267334228
Epoch: 92 | Iteration number: [480/565] 84% | Training loss: 0.6881825496753057
Epoch: 92 | Iteration number: [490/565] 86% | Training loss: 0.688159942505311
Epoch: 92 | Iteration number: [500/565] 88% | Training loss: 0.6881328575611114
Epoch: 92 | Iteration number: [510/565] 90% | Training loss: 0.6881052371333627
Epoch: 92 | Iteration number: [520/565] 92% | Training loss: 0.6880723811112918
Epoch: 92 | Iteration number: [530/565] 93% | Training loss: 0.6880525478776895
Epoch: 92 | Iteration number: [540/565] 95% | Training loss: 0.6880252643867776
Epoch: 92 | Iteration number: [550/565] 97% | Training loss: 0.688002196225253
Epoch: 92 | Iteration number: [560/565] 99% | Training loss: 0.687979394942522

 End of epoch: 92 | Train Loss: 0.6867486371403246 | Training Time: 91 

 End of epoch: 92 | Eval Loss: 0.6901298761367798 | Evaluating Time: 5 
Epoch: 93 | Iteration number: [10/565] 1% | Training loss: 0.7554881632328033
Epoch: 93 | Iteration number: [20/565] 3% | Training loss: 0.7212606698274613
Epoch: 93 | Iteration number: [30/565] 5% | Training loss: 0.7096830447514851
Epoch: 93 | Iteration number: [40/565] 7% | Training loss: 0.7038995712995529
Epoch: 93 | Iteration number: [50/565] 8% | Training loss: 0.7004337048530579
Epoch: 93 | Iteration number: [60/565] 10% | Training loss: 0.6981751730044683
Epoch: 93 | Iteration number: [70/565] 12% | Training loss: 0.6965925259249551
Epoch: 93 | Iteration number: [80/565] 14% | Training loss: 0.6954078704118729
Epoch: 93 | Iteration number: [90/565] 15% | Training loss: 0.6944996072186365
Epoch: 93 | Iteration number: [100/565] 17% | Training loss: 0.6937180191278458
Epoch: 93 | Iteration number: [110/565] 19% | Training loss: 0.6930920340798118
Epoch: 93 | Iteration number: [120/565] 21% | Training loss: 0.6925483703613281
Epoch: 93 | Iteration number: [130/565] 23% | Training loss: 0.692141691996501
Epoch: 93 | Iteration number: [140/565] 24% | Training loss: 0.691765290072986
Epoch: 93 | Iteration number: [150/565] 26% | Training loss: 0.6914256795247395
Epoch: 93 | Iteration number: [160/565] 28% | Training loss: 0.6911577418446541
Epoch: 93 | Iteration number: [170/565] 30% | Training loss: 0.690914417365018
Epoch: 93 | Iteration number: [180/565] 31% | Training loss: 0.6906589524613487
Epoch: 93 | Iteration number: [190/565] 33% | Training loss: 0.6904623753146122
Epoch: 93 | Iteration number: [200/565] 35% | Training loss: 0.6902707520127297
Epoch: 93 | Iteration number: [210/565] 37% | Training loss: 0.6900795286610013
Epoch: 93 | Iteration number: [220/565] 38% | Training loss: 0.6899343287402934
Epoch: 93 | Iteration number: [230/565] 40% | Training loss: 0.6897966203482254
Epoch: 93 | Iteration number: [240/565] 42% | Training loss: 0.6896767735481262
Epoch: 93 | Iteration number: [250/565] 44% | Training loss: 0.6895552914142609
Epoch: 93 | Iteration number: [260/565] 46% | Training loss: 0.6894436611579015
Epoch: 93 | Iteration number: [270/565] 47% | Training loss: 0.6893406839282424
Epoch: 93 | Iteration number: [280/565] 49% | Training loss: 0.689227691079889
Epoch: 93 | Iteration number: [290/565] 51% | Training loss: 0.6891546286385635
Epoch: 93 | Iteration number: [300/565] 53% | Training loss: 0.689098673860232
Epoch: 93 | Iteration number: [310/565] 54% | Training loss: 0.6890353658506947
Epoch: 93 | Iteration number: [320/565] 56% | Training loss: 0.688961418159306
Epoch: 93 | Iteration number: [330/565] 58% | Training loss: 0.6888856024453134
Epoch: 93 | Iteration number: [340/565] 60% | Training loss: 0.6888217484249788
Epoch: 93 | Iteration number: [350/565] 61% | Training loss: 0.688771037374224
Epoch: 93 | Iteration number: [360/565] 63% | Training loss: 0.6887103171812163
Epoch: 93 | Iteration number: [370/565] 65% | Training loss: 0.688654591908326
Epoch: 93 | Iteration number: [380/565] 67% | Training loss: 0.6886041468695591
Epoch: 93 | Iteration number: [390/565] 69% | Training loss: 0.6885590519660558
Epoch: 93 | Iteration number: [400/565] 70% | Training loss: 0.6885244628787041
Epoch: 93 | Iteration number: [410/565] 72% | Training loss: 0.6884721542276987
Epoch: 93 | Iteration number: [420/565] 74% | Training loss: 0.6884301029500507
Epoch: 93 | Iteration number: [430/565] 76% | Training loss: 0.6883899864762328
Epoch: 93 | Iteration number: [440/565] 77% | Training loss: 0.6883510253646157
Epoch: 93 | Iteration number: [450/565] 79% | Training loss: 0.6883126828405592
Epoch: 93 | Iteration number: [460/565] 81% | Training loss: 0.6882860087830087
Epoch: 93 | Iteration number: [470/565] 83% | Training loss: 0.6882509929068545
Epoch: 93 | Iteration number: [480/565] 84% | Training loss: 0.6882262243578832
Epoch: 93 | Iteration number: [490/565] 86% | Training loss: 0.6882072541178489
Epoch: 93 | Iteration number: [500/565] 88% | Training loss: 0.6881784852743149
Epoch: 93 | Iteration number: [510/565] 90% | Training loss: 0.6881448520164863
Epoch: 93 | Iteration number: [520/565] 92% | Training loss: 0.6881216222277055
Epoch: 93 | Iteration number: [530/565] 93% | Training loss: 0.6880869471801901
Epoch: 93 | Iteration number: [540/565] 95% | Training loss: 0.6880605621470346
Epoch: 93 | Iteration number: [550/565] 97% | Training loss: 0.6880324381048029
Epoch: 93 | Iteration number: [560/565] 99% | Training loss: 0.6880152127572469

 End of epoch: 93 | Train Loss: 0.6867859680040748 | Training Time: 91 

 End of epoch: 93 | Eval Loss: 0.68943738085883 | Evaluating Time: 5 
Epoch: 94 | Iteration number: [10/565] 1% | Training loss: 0.7551574647426605
Epoch: 94 | Iteration number: [20/565] 3% | Training loss: 0.7209699004888535
Epoch: 94 | Iteration number: [30/565] 5% | Training loss: 0.709565524260203
Epoch: 94 | Iteration number: [40/565] 7% | Training loss: 0.7038551434874535
Epoch: 94 | Iteration number: [50/565] 8% | Training loss: 0.7003981721401215
Epoch: 94 | Iteration number: [60/565] 10% | Training loss: 0.6980683624744415
Epoch: 94 | Iteration number: [70/565] 12% | Training loss: 0.6963945976325444
Epoch: 94 | Iteration number: [80/565] 14% | Training loss: 0.6952515304088592
Epoch: 94 | Iteration number: [90/565] 15% | Training loss: 0.6942970726225112
Epoch: 94 | Iteration number: [100/565] 17% | Training loss: 0.6935688304901123
Epoch: 94 | Iteration number: [110/565] 19% | Training loss: 0.6929681013930927
Epoch: 94 | Iteration number: [120/565] 21% | Training loss: 0.6924339036146799
Epoch: 94 | Iteration number: [130/565] 23% | Training loss: 0.6920071299259479
Epoch: 94 | Iteration number: [140/565] 24% | Training loss: 0.691625714302063
Epoch: 94 | Iteration number: [150/565] 26% | Training loss: 0.6913068437576294
Epoch: 94 | Iteration number: [160/565] 28% | Training loss: 0.6910407189279795
Epoch: 94 | Iteration number: [170/565] 30% | Training loss: 0.6907929897308349
Epoch: 94 | Iteration number: [180/565] 31% | Training loss: 0.6905754784742991
Epoch: 94 | Iteration number: [190/565] 33% | Training loss: 0.6903641957985728
Epoch: 94 | Iteration number: [200/565] 35% | Training loss: 0.6901664698123932
Epoch: 94 | Iteration number: [210/565] 37% | Training loss: 0.6900057239191872
Epoch: 94 | Iteration number: [220/565] 38% | Training loss: 0.689891871268099
Epoch: 94 | Iteration number: [230/565] 40% | Training loss: 0.6897442955037821
Epoch: 94 | Iteration number: [240/565] 42% | Training loss: 0.6896402771274249
Epoch: 94 | Iteration number: [250/565] 44% | Training loss: 0.6895432534217835
Epoch: 94 | Iteration number: [260/565] 46% | Training loss: 0.6894418207498697
Epoch: 94 | Iteration number: [270/565] 47% | Training loss: 0.689341808910723
Epoch: 94 | Iteration number: [280/565] 49% | Training loss: 0.6892493401254927
Epoch: 94 | Iteration number: [290/565] 51% | Training loss: 0.6891471192754548
Epoch: 94 | Iteration number: [300/565] 53% | Training loss: 0.6890811681747436
Epoch: 94 | Iteration number: [310/565] 54% | Training loss: 0.6889929479168307
Epoch: 94 | Iteration number: [320/565] 56% | Training loss: 0.6889199621975421
Epoch: 94 | Iteration number: [330/565] 58% | Training loss: 0.6888713719266834
Epoch: 94 | Iteration number: [340/565] 60% | Training loss: 0.688805932858411
Epoch: 94 | Iteration number: [350/565] 61% | Training loss: 0.6887446088450295
Epoch: 94 | Iteration number: [360/565] 63% | Training loss: 0.6886945808927218
Epoch: 94 | Iteration number: [370/565] 65% | Training loss: 0.6886378773160883
Epoch: 94 | Iteration number: [380/565] 67% | Training loss: 0.6885838508605957
Epoch: 94 | Iteration number: [390/565] 69% | Training loss: 0.6885252715685428
Epoch: 94 | Iteration number: [400/565] 70% | Training loss: 0.6884740942716598
Epoch: 94 | Iteration number: [410/565] 72% | Training loss: 0.6884371136746755
Epoch: 94 | Iteration number: [420/565] 74% | Training loss: 0.6883932925405957
Epoch: 94 | Iteration number: [430/565] 76% | Training loss: 0.6883513349433278
Epoch: 94 | Iteration number: [440/565] 77% | Training loss: 0.6883205207911405
Epoch: 94 | Iteration number: [450/565] 79% | Training loss: 0.6882822473843893
Epoch: 94 | Iteration number: [460/565] 81% | Training loss: 0.6882509213426838
Epoch: 94 | Iteration number: [470/565] 83% | Training loss: 0.6882261441109029
Epoch: 94 | Iteration number: [480/565] 84% | Training loss: 0.688201088582476
Epoch: 94 | Iteration number: [490/565] 86% | Training loss: 0.6881718310774589
Epoch: 94 | Iteration number: [500/565] 88% | Training loss: 0.6881323076486587
Epoch: 94 | Iteration number: [510/565] 90% | Training loss: 0.6881047570237926
Epoch: 94 | Iteration number: [520/565] 92% | Training loss: 0.6880650787399365
Epoch: 94 | Iteration number: [530/565] 93% | Training loss: 0.6880418842693545
Epoch: 94 | Iteration number: [540/565] 95% | Training loss: 0.6880243636943676
Epoch: 94 | Iteration number: [550/565] 97% | Training loss: 0.6880072851614518
Epoch: 94 | Iteration number: [560/565] 99% | Training loss: 0.6879812431122575

 End of epoch: 94 | Train Loss: 0.686751750401691 | Training Time: 91 

 End of epoch: 94 | Eval Loss: 0.6895836591720581 | Evaluating Time: 5 
Epoch: 95 | Iteration number: [10/565] 1% | Training loss: 0.7553819239139556
Epoch: 95 | Iteration number: [20/565] 3% | Training loss: 0.7212455064058304
Epoch: 95 | Iteration number: [30/565] 5% | Training loss: 0.7097108165423075
Epoch: 95 | Iteration number: [40/565] 7% | Training loss: 0.7038551598787308
Epoch: 95 | Iteration number: [50/565] 8% | Training loss: 0.7004341387748718
Epoch: 95 | Iteration number: [60/565] 10% | Training loss: 0.6981782664855322
Epoch: 95 | Iteration number: [70/565] 12% | Training loss: 0.6965363000120436
Epoch: 95 | Iteration number: [80/565] 14% | Training loss: 0.6953189335763454
Epoch: 95 | Iteration number: [90/565] 15% | Training loss: 0.6943645801809099
Epoch: 95 | Iteration number: [100/565] 17% | Training loss: 0.6935839259624481
Epoch: 95 | Iteration number: [110/565] 19% | Training loss: 0.6929701122370633
Epoch: 95 | Iteration number: [120/565] 21% | Training loss: 0.6924702073136966
Epoch: 95 | Iteration number: [130/565] 23% | Training loss: 0.6920199380471156
Epoch: 95 | Iteration number: [140/565] 24% | Training loss: 0.6916902146169117
Epoch: 95 | Iteration number: [150/565] 26% | Training loss: 0.6913878293832143
Epoch: 95 | Iteration number: [160/565] 28% | Training loss: 0.6910782411694527
Epoch: 95 | Iteration number: [170/565] 30% | Training loss: 0.6908152706482831
Epoch: 95 | Iteration number: [180/565] 31% | Training loss: 0.6905960076385074
Epoch: 95 | Iteration number: [190/565] 33% | Training loss: 0.6903955726247085
Epoch: 95 | Iteration number: [200/565] 35% | Training loss: 0.6901876372098923
Epoch: 95 | Iteration number: [210/565] 37% | Training loss: 0.6900105428128015
Epoch: 95 | Iteration number: [220/565] 38% | Training loss: 0.6898609510876915
Epoch: 95 | Iteration number: [230/565] 40% | Training loss: 0.6897216022014618
Epoch: 95 | Iteration number: [240/565] 42% | Training loss: 0.6896243671576182
Epoch: 95 | Iteration number: [250/565] 44% | Training loss: 0.6895115616321563
Epoch: 95 | Iteration number: [260/565] 46% | Training loss: 0.6893888833431098
Epoch: 95 | Iteration number: [270/565] 47% | Training loss: 0.68928870956103
Epoch: 95 | Iteration number: [280/565] 49% | Training loss: 0.6891993814281054
Epoch: 95 | Iteration number: [290/565] 51% | Training loss: 0.689118892776555
Epoch: 95 | Iteration number: [300/565] 53% | Training loss: 0.6890521669387817
Epoch: 95 | Iteration number: [310/565] 54% | Training loss: 0.6889801719496327
Epoch: 95 | Iteration number: [320/565] 56% | Training loss: 0.6888986548408866
Epoch: 95 | Iteration number: [330/565] 58% | Training loss: 0.6888270450360847
Epoch: 95 | Iteration number: [340/565] 60% | Training loss: 0.688763140930849
Epoch: 95 | Iteration number: [350/565] 61% | Training loss: 0.6887023915563311
Epoch: 95 | Iteration number: [360/565] 63% | Training loss: 0.6886508807539939
Epoch: 95 | Iteration number: [370/565] 65% | Training loss: 0.6886094644262984
Epoch: 95 | Iteration number: [380/565] 67% | Training loss: 0.6885672462613959
Epoch: 95 | Iteration number: [390/565] 69% | Training loss: 0.6885072541542542
Epoch: 95 | Iteration number: [400/565] 70% | Training loss: 0.6884627072513103
Epoch: 95 | Iteration number: [410/565] 72% | Training loss: 0.6884153242518262
Epoch: 95 | Iteration number: [420/565] 74% | Training loss: 0.6883794987485522
Epoch: 95 | Iteration number: [430/565] 76% | Training loss: 0.6883398961189181
Epoch: 95 | Iteration number: [440/565] 77% | Training loss: 0.68830814673142
Epoch: 95 | Iteration number: [450/565] 79% | Training loss: 0.6882580151822832
Epoch: 95 | Iteration number: [460/565] 81% | Training loss: 0.6882305815168049
Epoch: 95 | Iteration number: [470/565] 83% | Training loss: 0.6881967147614093
Epoch: 95 | Iteration number: [480/565] 84% | Training loss: 0.6881663704911868
Epoch: 95 | Iteration number: [490/565] 86% | Training loss: 0.6881388570581164
Epoch: 95 | Iteration number: [500/565] 88% | Training loss: 0.6881118646860123
Epoch: 95 | Iteration number: [510/565] 90% | Training loss: 0.6880837120261847
Epoch: 95 | Iteration number: [520/565] 92% | Training loss: 0.688055350803412
Epoch: 95 | Iteration number: [530/565] 93% | Training loss: 0.6880366648143192
Epoch: 95 | Iteration number: [540/565] 95% | Training loss: 0.688011015786065
Epoch: 95 | Iteration number: [550/565] 97% | Training loss: 0.6879922259937633
Epoch: 95 | Iteration number: [560/565] 99% | Training loss: 0.6879752007978303

 End of epoch: 95 | Train Loss: 0.6867471020833581 | Training Time: 92 

 End of epoch: 95 | Eval Loss: 0.6889448165893555 | Evaluating Time: 5 
Epoch: 96 | Iteration number: [10/565] 1% | Training loss: 0.7554157257080079
Epoch: 96 | Iteration number: [20/565] 3% | Training loss: 0.7210388481616974
Epoch: 96 | Iteration number: [30/565] 5% | Training loss: 0.7096486926078797
Epoch: 96 | Iteration number: [40/565] 7% | Training loss: 0.7039419308304786
Epoch: 96 | Iteration number: [50/565] 8% | Training loss: 0.700483570098877
Epoch: 96 | Iteration number: [60/565] 10% | Training loss: 0.6981925398111344
Epoch: 96 | Iteration number: [70/565] 12% | Training loss: 0.6966035970619746
Epoch: 96 | Iteration number: [80/565] 14% | Training loss: 0.6953742943704129
Epoch: 96 | Iteration number: [90/565] 15% | Training loss: 0.6944164574146271
Epoch: 96 | Iteration number: [100/565] 17% | Training loss: 0.6936447024345398
Epoch: 96 | Iteration number: [110/565] 19% | Training loss: 0.6929878397421403
Epoch: 96 | Iteration number: [120/565] 21% | Training loss: 0.6924455528457959
Epoch: 96 | Iteration number: [130/565] 23% | Training loss: 0.6919739030874692
Epoch: 96 | Iteration number: [140/565] 24% | Training loss: 0.6916183229003634
Epoch: 96 | Iteration number: [150/565] 26% | Training loss: 0.6912611122926077
Epoch: 96 | Iteration number: [160/565] 28% | Training loss: 0.6909670859575272
Epoch: 96 | Iteration number: [170/565] 30% | Training loss: 0.6907284319400787
Epoch: 96 | Iteration number: [180/565] 31% | Training loss: 0.6904909580945968
Epoch: 96 | Iteration number: [190/565] 33% | Training loss: 0.6902761732277117
Epoch: 96 | Iteration number: [200/565] 35% | Training loss: 0.6901190653443336
Epoch: 96 | Iteration number: [210/565] 37% | Training loss: 0.6899771210693177
Epoch: 96 | Iteration number: [220/565] 38% | Training loss: 0.6898058243773201
Epoch: 96 | Iteration number: [230/565] 40% | Training loss: 0.6896677141604216
Epoch: 96 | Iteration number: [240/565] 42% | Training loss: 0.6895504564046859
Epoch: 96 | Iteration number: [250/565] 44% | Training loss: 0.6894272401332855
Epoch: 96 | Iteration number: [260/565] 46% | Training loss: 0.6893239170312881
Epoch: 96 | Iteration number: [270/565] 47% | Training loss: 0.689241616372709
Epoch: 96 | Iteration number: [280/565] 49% | Training loss: 0.6891555607318878
Epoch: 96 | Iteration number: [290/565] 51% | Training loss: 0.6890772620151783
Epoch: 96 | Iteration number: [300/565] 53% | Training loss: 0.6890099271138509
Epoch: 96 | Iteration number: [310/565] 54% | Training loss: 0.6889307589300218
Epoch: 96 | Iteration number: [320/565] 56% | Training loss: 0.6888705033808946
Epoch: 96 | Iteration number: [330/565] 58% | Training loss: 0.6888097483100313
Epoch: 96 | Iteration number: [340/565] 60% | Training loss: 0.688738612742985
Epoch: 96 | Iteration number: [350/565] 61% | Training loss: 0.6886842349597386
Epoch: 96 | Iteration number: [360/565] 63% | Training loss: 0.6886239833301968
Epoch: 96 | Iteration number: [370/565] 65% | Training loss: 0.6885798341519124
Epoch: 96 | Iteration number: [380/565] 67% | Training loss: 0.6885321099507181
Epoch: 96 | Iteration number: [390/565] 69% | Training loss: 0.6884800423414279
Epoch: 96 | Iteration number: [400/565] 70% | Training loss: 0.6884312024712562
Epoch: 96 | Iteration number: [410/565] 72% | Training loss: 0.6883869098453987
Epoch: 96 | Iteration number: [420/565] 74% | Training loss: 0.688340173590751
Epoch: 96 | Iteration number: [430/565] 76% | Training loss: 0.6883139987324559
Epoch: 96 | Iteration number: [440/565] 77% | Training loss: 0.6882844681089575
Epoch: 96 | Iteration number: [450/565] 79% | Training loss: 0.6882470671335856
Epoch: 96 | Iteration number: [460/565] 81% | Training loss: 0.6882256319989328
Epoch: 96 | Iteration number: [470/565] 83% | Training loss: 0.6881910116114515
Epoch: 96 | Iteration number: [480/565] 84% | Training loss: 0.6881573079774778
Epoch: 96 | Iteration number: [490/565] 86% | Training loss: 0.688139840413113
Epoch: 96 | Iteration number: [500/565] 88% | Training loss: 0.6881173181533814
Epoch: 96 | Iteration number: [510/565] 90% | Training loss: 0.6880885213029151
Epoch: 96 | Iteration number: [520/565] 92% | Training loss: 0.688054988361322
Epoch: 96 | Iteration number: [530/565] 93% | Training loss: 0.6880436694846963
Epoch: 96 | Iteration number: [540/565] 95% | Training loss: 0.688020642819228
Epoch: 96 | Iteration number: [550/565] 97% | Training loss: 0.6880042430487546
Epoch: 96 | Iteration number: [560/565] 99% | Training loss: 0.6879801172230925

 End of epoch: 96 | Train Loss: 0.6867511080429617 | Training Time: 91 

 End of epoch: 96 | Eval Loss: 0.689729630947113 | Evaluating Time: 5 
Epoch: 97 | Iteration number: [10/565] 1% | Training loss: 0.7553485274314881
Epoch: 97 | Iteration number: [20/565] 3% | Training loss: 0.7210403352975845
Epoch: 97 | Iteration number: [30/565] 5% | Training loss: 0.7096156537532806
Epoch: 97 | Iteration number: [40/565] 7% | Training loss: 0.7039866462349892
Epoch: 97 | Iteration number: [50/565] 8% | Training loss: 0.7005614817142487
Epoch: 97 | Iteration number: [60/565] 10% | Training loss: 0.6982512831687927
Epoch: 97 | Iteration number: [70/565] 12% | Training loss: 0.6966062537261418
Epoch: 97 | Iteration number: [80/565] 14% | Training loss: 0.6954263806343078
Epoch: 97 | Iteration number: [90/565] 15% | Training loss: 0.694490596320894
Epoch: 97 | Iteration number: [100/565] 17% | Training loss: 0.6936779206991196
Epoch: 97 | Iteration number: [110/565] 19% | Training loss: 0.6930566121231426
Epoch: 97 | Iteration number: [120/565] 21% | Training loss: 0.6925246223807335
Epoch: 97 | Iteration number: [130/565] 23% | Training loss: 0.6921099259303166
Epoch: 97 | Iteration number: [140/565] 24% | Training loss: 0.6917360246181488
Epoch: 97 | Iteration number: [150/565] 26% | Training loss: 0.6914101048310598
Epoch: 97 | Iteration number: [160/565] 28% | Training loss: 0.6911324877291918
Epoch: 97 | Iteration number: [170/565] 30% | Training loss: 0.6908700350452872
Epoch: 97 | Iteration number: [180/565] 31% | Training loss: 0.6906420512331857
Epoch: 97 | Iteration number: [190/565] 33% | Training loss: 0.69044529952501
Epoch: 97 | Iteration number: [200/565] 35% | Training loss: 0.6902466285228729
Epoch: 97 | Iteration number: [210/565] 37% | Training loss: 0.690096352213905
Epoch: 97 | Iteration number: [220/565] 38% | Training loss: 0.6899246622215618
Epoch: 97 | Iteration number: [230/565] 40% | Training loss: 0.6897962093353271
Epoch: 97 | Iteration number: [240/565] 42% | Training loss: 0.6896670853098233
Epoch: 97 | Iteration number: [250/565] 44% | Training loss: 0.689549706697464
Epoch: 97 | Iteration number: [260/565] 46% | Training loss: 0.6894520500531564
Epoch: 97 | Iteration number: [270/565] 47% | Training loss: 0.6893440542397675
Epoch: 97 | Iteration number: [280/565] 49% | Training loss: 0.6892476820519993
Epoch: 97 | Iteration number: [290/565] 51% | Training loss: 0.6891489146084621
Epoch: 97 | Iteration number: [300/565] 53% | Training loss: 0.6890732522805532
Epoch: 97 | Iteration number: [310/565] 54% | Training loss: 0.6889971519670178
Epoch: 97 | Iteration number: [320/565] 56% | Training loss: 0.6889381490647792
Epoch: 97 | Iteration number: [330/565] 58% | Training loss: 0.6888788911429319
Epoch: 97 | Iteration number: [340/565] 60% | Training loss: 0.6888152418767705
Epoch: 97 | Iteration number: [350/565] 61% | Training loss: 0.6887540827478681
Epoch: 97 | Iteration number: [360/565] 63% | Training loss: 0.6887047242787149
Epoch: 97 | Iteration number: [370/565] 65% | Training loss: 0.6886488595524349
Epoch: 97 | Iteration number: [380/565] 67% | Training loss: 0.6886013239622116
Epoch: 97 | Iteration number: [390/565] 69% | Training loss: 0.6885455594613001
Epoch: 97 | Iteration number: [400/565] 70% | Training loss: 0.6884939244389534
Epoch: 97 | Iteration number: [410/565] 72% | Training loss: 0.6884566192219898
Epoch: 97 | Iteration number: [420/565] 74% | Training loss: 0.6884060377166384
Epoch: 97 | Iteration number: [430/565] 76% | Training loss: 0.6883604818998381
Epoch: 97 | Iteration number: [440/565] 77% | Training loss: 0.6883367850021882
Epoch: 97 | Iteration number: [450/565] 79% | Training loss: 0.6882945741547478
Epoch: 97 | Iteration number: [460/565] 81% | Training loss: 0.6882573849481085
Epoch: 97 | Iteration number: [470/565] 83% | Training loss: 0.6882322584060913
Epoch: 97 | Iteration number: [480/565] 84% | Training loss: 0.6882099064687888
Epoch: 97 | Iteration number: [490/565] 86% | Training loss: 0.6881739322020083
Epoch: 97 | Iteration number: [500/565] 88% | Training loss: 0.6881355154514313
Epoch: 97 | Iteration number: [510/565] 90% | Training loss: 0.6881073432810166
Epoch: 97 | Iteration number: [520/565] 92% | Training loss: 0.6880739962825408
Epoch: 97 | Iteration number: [530/565] 93% | Training loss: 0.6880478050348894
Epoch: 97 | Iteration number: [540/565] 95% | Training loss: 0.6880231331895899
Epoch: 97 | Iteration number: [550/565] 97% | Training loss: 0.6879968281225725
Epoch: 97 | Iteration number: [560/565] 99% | Training loss: 0.687973695567676

 End of epoch: 97 | Train Loss: 0.6867443641730114 | Training Time: 91 

 End of epoch: 97 | Eval Loss: 0.6897801586559841 | Evaluating Time: 5 
Epoch: 98 | Iteration number: [10/565] 1% | Training loss: 0.7553144991397858
Epoch: 98 | Iteration number: [20/565] 3% | Training loss: 0.7212994217872619
Epoch: 98 | Iteration number: [30/565] 5% | Training loss: 0.7098243335882822
Epoch: 98 | Iteration number: [40/565] 7% | Training loss: 0.7041073009371758
Epoch: 98 | Iteration number: [50/565] 8% | Training loss: 0.700631753206253
Epoch: 98 | Iteration number: [60/565] 10% | Training loss: 0.6983064015706381
Epoch: 98 | Iteration number: [70/565] 12% | Training loss: 0.6966003962925502
Epoch: 98 | Iteration number: [80/565] 14% | Training loss: 0.6953869171440601
Epoch: 98 | Iteration number: [90/565] 15% | Training loss: 0.6943771514627669
Epoch: 98 | Iteration number: [100/565] 17% | Training loss: 0.6936408299207687
Epoch: 98 | Iteration number: [110/565] 19% | Training loss: 0.6929934805089777
Epoch: 98 | Iteration number: [120/565] 21% | Training loss: 0.6924727444847425
Epoch: 98 | Iteration number: [130/565] 23% | Training loss: 0.6920095883882963
Epoch: 98 | Iteration number: [140/565] 24% | Training loss: 0.6916428493601935
Epoch: 98 | Iteration number: [150/565] 26% | Training loss: 0.6913187750180563
Epoch: 98 | Iteration number: [160/565] 28% | Training loss: 0.6910496976226568
Epoch: 98 | Iteration number: [170/565] 30% | Training loss: 0.6907884468050564
Epoch: 98 | Iteration number: [180/565] 31% | Training loss: 0.6905723922782474
Epoch: 98 | Iteration number: [190/565] 33% | Training loss: 0.6903700803455554
Epoch: 98 | Iteration number: [200/565] 35% | Training loss: 0.6901693391799927
Epoch: 98 | Iteration number: [210/565] 37% | Training loss: 0.6899903618154072
Epoch: 98 | Iteration number: [220/565] 38% | Training loss: 0.6898205697536468
Epoch: 98 | Iteration number: [230/565] 40% | Training loss: 0.6896765841090161
Epoch: 98 | Iteration number: [240/565] 42% | Training loss: 0.6895652274290721
Epoch: 98 | Iteration number: [250/565] 44% | Training loss: 0.6894511475563049
Epoch: 98 | Iteration number: [260/565] 46% | Training loss: 0.6893455143158252
Epoch: 98 | Iteration number: [270/565] 47% | Training loss: 0.689266907065003
Epoch: 98 | Iteration number: [280/565] 49% | Training loss: 0.6891796482460839
Epoch: 98 | Iteration number: [290/565] 51% | Training loss: 0.6890932884709589
Epoch: 98 | Iteration number: [300/565] 53% | Training loss: 0.6890086034933726
Epoch: 98 | Iteration number: [310/565] 54% | Training loss: 0.68893044148722
Epoch: 98 | Iteration number: [320/565] 56% | Training loss: 0.6888633811846375
Epoch: 98 | Iteration number: [330/565] 58% | Training loss: 0.6887934802156506
Epoch: 98 | Iteration number: [340/565] 60% | Training loss: 0.6887248091837939
Epoch: 98 | Iteration number: [350/565] 61% | Training loss: 0.6886740272385733
Epoch: 98 | Iteration number: [360/565] 63% | Training loss: 0.6886219857467546
Epoch: 98 | Iteration number: [370/565] 65% | Training loss: 0.6885721171224439
Epoch: 98 | Iteration number: [380/565] 67% | Training loss: 0.6885313793232567
Epoch: 98 | Iteration number: [390/565] 69% | Training loss: 0.6884858088615613
Epoch: 98 | Iteration number: [400/565] 70% | Training loss: 0.6884446308016777
Epoch: 98 | Iteration number: [410/565] 72% | Training loss: 0.6884006026314526
Epoch: 98 | Iteration number: [420/565] 74% | Training loss: 0.6883666423105058
Epoch: 98 | Iteration number: [430/565] 76% | Training loss: 0.688322188687879
Epoch: 98 | Iteration number: [440/565] 77% | Training loss: 0.6882900546897541
Epoch: 98 | Iteration number: [450/565] 79% | Training loss: 0.6882548220952351
Epoch: 98 | Iteration number: [460/565] 81% | Training loss: 0.6882152694722881
Epoch: 98 | Iteration number: [470/565] 83% | Training loss: 0.6881766319274902
Epoch: 98 | Iteration number: [480/565] 84% | Training loss: 0.6881585401793321
Epoch: 98 | Iteration number: [490/565] 86% | Training loss: 0.6881391515537184
Epoch: 98 | Iteration number: [500/565] 88% | Training loss: 0.6881199094057083
Epoch: 98 | Iteration number: [510/565] 90% | Training loss: 0.6880897274204328
Epoch: 98 | Iteration number: [520/565] 92% | Training loss: 0.6880708363193732
Epoch: 98 | Iteration number: [530/565] 93% | Training loss: 0.6880430611799349
Epoch: 98 | Iteration number: [540/565] 95% | Training loss: 0.6880072717313414
Epoch: 98 | Iteration number: [550/565] 97% | Training loss: 0.687981283231215
Epoch: 98 | Iteration number: [560/565] 99% | Training loss: 0.6879652651292937

 End of epoch: 98 | Train Loss: 0.6867419485497264 | Training Time: 91 

 End of epoch: 98 | Eval Loss: 0.6897368090493339 | Evaluating Time: 5 
Epoch: 99 | Iteration number: [10/565] 1% | Training loss: 0.7549041986465455
Epoch: 99 | Iteration number: [20/565] 3% | Training loss: 0.7209105581045151
Epoch: 99 | Iteration number: [30/565] 5% | Training loss: 0.709620718161265
Epoch: 99 | Iteration number: [40/565] 7% | Training loss: 0.7039807885885239
Epoch: 99 | Iteration number: [50/565] 8% | Training loss: 0.7006173837184906
Epoch: 99 | Iteration number: [60/565] 10% | Training loss: 0.698281662662824
Epoch: 99 | Iteration number: [70/565] 12% | Training loss: 0.6966233389718192
Epoch: 99 | Iteration number: [80/565] 14% | Training loss: 0.6953153058886528
Epoch: 99 | Iteration number: [90/565] 15% | Training loss: 0.6943743533558315
Epoch: 99 | Iteration number: [100/565] 17% | Training loss: 0.693563928604126
Epoch: 99 | Iteration number: [110/565] 19% | Training loss: 0.6929050012068315
Epoch: 99 | Iteration number: [120/565] 21% | Training loss: 0.692381002008915
Epoch: 99 | Iteration number: [130/565] 23% | Training loss: 0.6919556686511407
Epoch: 99 | Iteration number: [140/565] 24% | Training loss: 0.6915478127343314
Epoch: 99 | Iteration number: [150/565] 26% | Training loss: 0.6912343577543895
Epoch: 99 | Iteration number: [160/565] 28% | Training loss: 0.6909507498145103
Epoch: 99 | Iteration number: [170/565] 30% | Training loss: 0.6907009769888485
Epoch: 99 | Iteration number: [180/565] 31% | Training loss: 0.690493509835667
Epoch: 99 | Iteration number: [190/565] 33% | Training loss: 0.6903079387388731
Epoch: 99 | Iteration number: [200/565] 35% | Training loss: 0.6901473841071128
Epoch: 99 | Iteration number: [210/565] 37% | Training loss: 0.6899984791165307
Epoch: 99 | Iteration number: [220/565] 38% | Training loss: 0.6898691090670499
Epoch: 99 | Iteration number: [230/565] 40% | Training loss: 0.6897145162458005
Epoch: 99 | Iteration number: [240/565] 42% | Training loss: 0.689572292069594
Epoch: 99 | Iteration number: [250/565] 44% | Training loss: 0.6894649968147278
Epoch: 99 | Iteration number: [260/565] 46% | Training loss: 0.6893567245740156
Epoch: 99 | Iteration number: [270/565] 47% | Training loss: 0.6892703038674813
Epoch: 99 | Iteration number: [280/565] 49% | Training loss: 0.6891868831855911
Epoch: 99 | Iteration number: [290/565] 51% | Training loss: 0.6891255853504971
Epoch: 99 | Iteration number: [300/565] 53% | Training loss: 0.6890678469340007
Epoch: 99 | Iteration number: [310/565] 54% | Training loss: 0.688988430653849
Epoch: 99 | Iteration number: [320/565] 56% | Training loss: 0.6889142714440822
Epoch: 99 | Iteration number: [330/565] 58% | Training loss: 0.6888490794282971
Epoch: 99 | Iteration number: [340/565] 60% | Training loss: 0.6887862759477952
Epoch: 99 | Iteration number: [350/565] 61% | Training loss: 0.6887282296589443
Epoch: 99 | Iteration number: [360/565] 63% | Training loss: 0.6886764705181122
Epoch: 99 | Iteration number: [370/565] 65% | Training loss: 0.6886148383488526
Epoch: 99 | Iteration number: [380/565] 67% | Training loss: 0.6885724724907624
Epoch: 99 | Iteration number: [390/565] 69% | Training loss: 0.6885138386335128
Epoch: 99 | Iteration number: [400/565] 70% | Training loss: 0.6884746651351452
Epoch: 99 | Iteration number: [410/565] 72% | Training loss: 0.6884202326216349
Epoch: 99 | Iteration number: [420/565] 74% | Training loss: 0.6883812972477504
Epoch: 99 | Iteration number: [430/565] 76% | Training loss: 0.6883381289105083
Epoch: 99 | Iteration number: [440/565] 77% | Training loss: 0.6883093835277991
Epoch: 99 | Iteration number: [450/565] 79% | Training loss: 0.6882748235596551
Epoch: 99 | Iteration number: [460/565] 81% | Training loss: 0.688240851526675
Epoch: 99 | Iteration number: [470/565] 83% | Training loss: 0.6882164009073948
Epoch: 99 | Iteration number: [480/565] 84% | Training loss: 0.6881886377930642
Epoch: 99 | Iteration number: [490/565] 86% | Training loss: 0.6881665220065992
Epoch: 99 | Iteration number: [500/565] 88% | Training loss: 0.6881434378623963
Epoch: 99 | Iteration number: [510/565] 90% | Training loss: 0.6881096832892474
Epoch: 99 | Iteration number: [520/565] 92% | Training loss: 0.6880786259586994
Epoch: 99 | Iteration number: [530/565] 93% | Training loss: 0.6880494848737176
Epoch: 99 | Iteration number: [540/565] 95% | Training loss: 0.6880201403741484
Epoch: 99 | Iteration number: [550/565] 97% | Training loss: 0.6880016446113586
Epoch: 99 | Iteration number: [560/565] 99% | Training loss: 0.687971110961267

 End of epoch: 99 | Train Loss: 0.6867436978669293 | Training Time: 91 

 End of epoch: 99 | Eval Loss: 0.6901318175452096 | Evaluating Time: 5 
Epoch: 100 | Iteration number: [10/565] 1% | Training loss: 0.7557666897773743
Epoch: 100 | Iteration number: [20/565] 3% | Training loss: 0.7212593048810959
Epoch: 100 | Iteration number: [30/565] 5% | Training loss: 0.7096931715806325
Epoch: 100 | Iteration number: [40/565] 7% | Training loss: 0.7041252419352532
Epoch: 100 | Iteration number: [50/565] 8% | Training loss: 0.700623426437378
Epoch: 100 | Iteration number: [60/565] 10% | Training loss: 0.698323917388916
Epoch: 100 | Iteration number: [70/565] 12% | Training loss: 0.6966759937150138
Epoch: 100 | Iteration number: [80/565] 14% | Training loss: 0.6954304829239846
Epoch: 100 | Iteration number: [90/565] 15% | Training loss: 0.6944474233521356
Epoch: 100 | Iteration number: [100/565] 17% | Training loss: 0.693707504272461
Epoch: 100 | Iteration number: [110/565] 19% | Training loss: 0.6930803526531566
Epoch: 100 | Iteration number: [120/565] 21% | Training loss: 0.6925504018863042
Epoch: 100 | Iteration number: [130/565] 23% | Training loss: 0.692083745277845
Epoch: 100 | Iteration number: [140/565] 24% | Training loss: 0.6917039241109576
Epoch: 100 | Iteration number: [150/565] 26% | Training loss: 0.6913685325781505
Epoch: 100 | Iteration number: [160/565] 28% | Training loss: 0.6910546384751797
Epoch: 100 | Iteration number: [170/565] 30% | Training loss: 0.6907765767153572
Epoch: 100 | Iteration number: [180/565] 31% | Training loss: 0.6905628628200955
Epoch: 100 | Iteration number: [190/565] 33% | Training loss: 0.6903694328508879
Epoch: 100 | Iteration number: [200/565] 35% | Training loss: 0.6901941084861756
Epoch: 100 | Iteration number: [210/565] 37% | Training loss: 0.6900588728132702
Epoch: 100 | Iteration number: [220/565] 38% | Training loss: 0.6899084102023731
Epoch: 100 | Iteration number: [230/565] 40% | Training loss: 0.6897581312967384
Epoch: 100 | Iteration number: [240/565] 42% | Training loss: 0.6896391498545805
Epoch: 100 | Iteration number: [250/565] 44% | Training loss: 0.6895176570415497
Epoch: 100 | Iteration number: [260/565] 46% | Training loss: 0.6894072777949847
Epoch: 100 | Iteration number: [270/565] 47% | Training loss: 0.6893231707590598
Epoch: 100 | Iteration number: [280/565] 49% | Training loss: 0.6892237186431884
Epoch: 100 | Iteration number: [290/565] 51% | Training loss: 0.6891370754817436
Epoch: 100 | Iteration number: [300/565] 53% | Training loss: 0.6890498809019725
Epoch: 100 | Iteration number: [310/565] 54% | Training loss: 0.6889889544056308
Epoch: 100 | Iteration number: [320/565] 56% | Training loss: 0.6889292947947979
Epoch: 100 | Iteration number: [330/565] 58% | Training loss: 0.6888713829445117
Epoch: 100 | Iteration number: [340/565] 60% | Training loss: 0.6888081559363534
Epoch: 100 | Iteration number: [350/565] 61% | Training loss: 0.6887558027676174
Epoch: 100 | Iteration number: [360/565] 63% | Training loss: 0.6886968084507519
Epoch: 100 | Iteration number: [370/565] 65% | Training loss: 0.6886510678239771
Epoch: 100 | Iteration number: [380/565] 67% | Training loss: 0.6885994385731847
Epoch: 100 | Iteration number: [390/565] 69% | Training loss: 0.6885548648161766
Epoch: 100 | Iteration number: [400/565] 70% | Training loss: 0.6885084843635559
Epoch: 100 | Iteration number: [410/565] 72% | Training loss: 0.6884599015480135
Epoch: 100 | Iteration number: [420/565] 74% | Training loss: 0.6884088648217065
Epoch: 100 | Iteration number: [430/565] 76% | Training loss: 0.6883701518524524
Epoch: 100 | Iteration number: [440/565] 77% | Training loss: 0.688329158181494
Epoch: 100 | Iteration number: [450/565] 79% | Training loss: 0.6882994581593408
Epoch: 100 | Iteration number: [460/565] 81% | Training loss: 0.6882585148448529
Epoch: 100 | Iteration number: [470/565] 83% | Training loss: 0.6882200050861278
Epoch: 100 | Iteration number: [480/565] 84% | Training loss: 0.6881786275655031
Epoch: 100 | Iteration number: [490/565] 86% | Training loss: 0.6881485583830853
Epoch: 100 | Iteration number: [500/565] 88% | Training loss: 0.6881126147508622
Epoch: 100 | Iteration number: [510/565] 90% | Training loss: 0.6880895075844783
Epoch: 100 | Iteration number: [520/565] 92% | Training loss: 0.6880633413791657
Epoch: 100 | Iteration number: [530/565] 93% | Training loss: 0.6880329464966396
Epoch: 100 | Iteration number: [540/565] 95% | Training loss: 0.6880058661655143
Epoch: 100 | Iteration number: [550/565] 97% | Training loss: 0.6879815858060664
Epoch: 100 | Iteration number: [560/565] 99% | Training loss: 0.6879639570202146

 End of epoch: 100 | Train Loss: 0.6867427482014209 | Training Time: 91 

 End of epoch: 100 | Eval Loss: 0.6900320138250079 | Evaluating Time: 6 

 End of Test | Dice Loss: 0.9599689585821969 | Binary Cross Entropy With Logits Loss: 0.6899734565189907 
