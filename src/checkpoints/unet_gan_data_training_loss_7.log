Epoch: 1 | Iteration number: [10/565] 1% | Training loss: 0.7631660640239716
Epoch: 1 | Iteration number: [20/565] 3% | Training loss: 0.7283654868602752
Epoch: 1 | Iteration number: [30/565] 5% | Training loss: 0.7166253904501597
Epoch: 1 | Iteration number: [40/565] 7% | Training loss: 0.7107528880238533
Epoch: 1 | Iteration number: [50/565] 8% | Training loss: 0.7071762251853942
Epoch: 1 | Iteration number: [60/565] 10% | Training loss: 0.7047803193330765
Epoch: 1 | Iteration number: [70/565] 12% | Training loss: 0.7030832350254059
Epoch: 1 | Iteration number: [80/565] 14% | Training loss: 0.7017886765301228
Epoch: 1 | Iteration number: [90/565] 15% | Training loss: 0.7007695482836829
Epoch: 1 | Iteration number: [100/565] 17% | Training loss: 0.6999466985464096
Epoch: 1 | Iteration number: [110/565] 19% | Training loss: 0.6992763210426677
Epoch: 1 | Iteration number: [120/565] 21% | Training loss: 0.698696956038475
Epoch: 1 | Iteration number: [130/565] 23% | Training loss: 0.6981735036923336
Epoch: 1 | Iteration number: [140/565] 24% | Training loss: 0.6977161403213229
Epoch: 1 | Iteration number: [150/565] 26% | Training loss: 0.6973115821679433
Epoch: 1 | Iteration number: [160/565] 28% | Training loss: 0.6969855915755033
Epoch: 1 | Iteration number: [170/565] 30% | Training loss: 0.6966674120987163
Epoch: 1 | Iteration number: [180/565] 31% | Training loss: 0.6963889731301202
Epoch: 1 | Iteration number: [190/565] 33% | Training loss: 0.696138247376994
Epoch: 1 | Iteration number: [200/565] 35% | Training loss: 0.6959071749448776
Epoch: 1 | Iteration number: [210/565] 37% | Training loss: 0.6956919159208025
Epoch: 1 | Iteration number: [220/565] 38% | Training loss: 0.6955067436803472
Epoch: 1 | Iteration number: [230/565] 40% | Training loss: 0.6953113750271175
Epoch: 1 | Iteration number: [240/565] 42% | Training loss: 0.6951353885233402
Epoch: 1 | Iteration number: [250/565] 44% | Training loss: 0.6949824783802032
Epoch: 1 | Iteration number: [260/565] 46% | Training loss: 0.6948259775455181
Epoch: 1 | Iteration number: [270/565] 47% | Training loss: 0.694696146691287
Epoch: 1 | Iteration number: [280/565] 49% | Training loss: 0.6945706742150443
Epoch: 1 | Iteration number: [290/565] 51% | Training loss: 0.694450581073761
Epoch: 1 | Iteration number: [300/565] 53% | Training loss: 0.6943466305732727
Epoch: 1 | Iteration number: [310/565] 54% | Training loss: 0.694236506377497
Epoch: 1 | Iteration number: [320/565] 56% | Training loss: 0.6941337244585156
Epoch: 1 | Iteration number: [330/565] 58% | Training loss: 0.6940295994281769
Epoch: 1 | Iteration number: [340/565] 60% | Training loss: 0.6939308006973828
Epoch: 1 | Iteration number: [350/565] 61% | Training loss: 0.6938349453040532
Epoch: 1 | Iteration number: [360/565] 63% | Training loss: 0.6937295307715734
Epoch: 1 | Iteration number: [370/565] 65% | Training loss: 0.6936478837116344
Epoch: 1 | Iteration number: [380/565] 67% | Training loss: 0.6935576862410495
Epoch: 1 | Iteration number: [390/565] 69% | Training loss: 0.6934796185065538
Epoch: 1 | Iteration number: [400/565] 70% | Training loss: 0.6934094811975956
Epoch: 1 | Iteration number: [410/565] 72% | Training loss: 0.6933318847563209
Epoch: 1 | Iteration number: [420/565] 74% | Training loss: 0.6932664571773438
Epoch: 1 | Iteration number: [430/565] 76% | Training loss: 0.6931936459485875
Epoch: 1 | Iteration number: [440/565] 77% | Training loss: 0.693127790228887
Epoch: 1 | Iteration number: [450/565] 79% | Training loss: 0.6930716768900553
Epoch: 1 | Iteration number: [460/565] 81% | Training loss: 0.6930137699065001
Epoch: 1 | Iteration number: [470/565] 83% | Training loss: 0.6929611356968576
Epoch: 1 | Iteration number: [480/565] 84% | Training loss: 0.6929128638158242
Epoch: 1 | Iteration number: [490/565] 86% | Training loss: 0.6928578337844538
Epoch: 1 | Iteration number: [500/565] 88% | Training loss: 0.6928067240715027
Epoch: 1 | Iteration number: [510/565] 90% | Training loss: 0.69275242896641
Epoch: 1 | Iteration number: [520/565] 92% | Training loss: 0.6926976895103087
Epoch: 1 | Iteration number: [530/565] 93% | Training loss: 0.692642284339329
Epoch: 1 | Iteration number: [540/565] 95% | Training loss: 0.6925948602181894
Epoch: 1 | Iteration number: [550/565] 97% | Training loss: 0.6925449831919237
Epoch: 1 | Iteration number: [560/565] 99% | Training loss: 0.692495743823903

 End of epoch: 1 | Train Loss: 0.6912544200905656 | Training Time: 88 

 End of epoch: 1 | Eval Loss: 0.6919081466538566 | Evaluating Time: 5 
Epoch: 2 | Iteration number: [10/565] 1% | Training loss: 0.7591026246547699
Epoch: 2 | Iteration number: [20/565] 3% | Training loss: 0.7246443957090378
Epoch: 2 | Iteration number: [30/565] 5% | Training loss: 0.7130774835745494
Epoch: 2 | Iteration number: [40/565] 7% | Training loss: 0.7072472319006919
Epoch: 2 | Iteration number: [50/565] 8% | Training loss: 0.7037371802330017
Epoch: 2 | Iteration number: [60/565] 10% | Training loss: 0.7014209369818369
Epoch: 2 | Iteration number: [70/565] 12% | Training loss: 0.6998095818928309
Epoch: 2 | Iteration number: [80/565] 14% | Training loss: 0.698521013557911
Epoch: 2 | Iteration number: [90/565] 15% | Training loss: 0.6975659522745344
Epoch: 2 | Iteration number: [100/565] 17% | Training loss: 0.696816371679306
Epoch: 2 | Iteration number: [110/565] 19% | Training loss: 0.6961806400255723
Epoch: 2 | Iteration number: [120/565] 21% | Training loss: 0.6956575373808543
Epoch: 2 | Iteration number: [130/565] 23% | Training loss: 0.6951818897173955
Epoch: 2 | Iteration number: [140/565] 24% | Training loss: 0.6947988275970731
Epoch: 2 | Iteration number: [150/565] 26% | Training loss: 0.6944490253925324
Epoch: 2 | Iteration number: [160/565] 28% | Training loss: 0.6941509161144495
Epoch: 2 | Iteration number: [170/565] 30% | Training loss: 0.6938913622323204
Epoch: 2 | Iteration number: [180/565] 31% | Training loss: 0.693635669681761
Epoch: 2 | Iteration number: [190/565] 33% | Training loss: 0.6934255449395431
Epoch: 2 | Iteration number: [200/565] 35% | Training loss: 0.693246488571167
Epoch: 2 | Iteration number: [210/565] 37% | Training loss: 0.693066654318855
Epoch: 2 | Iteration number: [220/565] 38% | Training loss: 0.6929021808234128
Epoch: 2 | Iteration number: [230/565] 40% | Training loss: 0.6927784085273743
Epoch: 2 | Iteration number: [240/565] 42% | Training loss: 0.6926535218954086
Epoch: 2 | Iteration number: [250/565] 44% | Training loss: 0.6925238196849823
Epoch: 2 | Iteration number: [260/565] 46% | Training loss: 0.6924056587310937
Epoch: 2 | Iteration number: [270/565] 47% | Training loss: 0.6922893345355987
Epoch: 2 | Iteration number: [280/565] 49% | Training loss: 0.6922000073960849
Epoch: 2 | Iteration number: [290/565] 51% | Training loss: 0.6921063254619467
Epoch: 2 | Iteration number: [300/565] 53% | Training loss: 0.6920252801974615
Epoch: 2 | Iteration number: [310/565] 54% | Training loss: 0.6919307018479993
Epoch: 2 | Iteration number: [320/565] 56% | Training loss: 0.6918477579951287
Epoch: 2 | Iteration number: [330/565] 58% | Training loss: 0.6917769255060138
Epoch: 2 | Iteration number: [340/565] 60% | Training loss: 0.6917333036661149
Epoch: 2 | Iteration number: [350/565] 61% | Training loss: 0.6916753506660461
Epoch: 2 | Iteration number: [360/565] 63% | Training loss: 0.6916101790136762
Epoch: 2 | Iteration number: [370/565] 65% | Training loss: 0.6915507550175125
Epoch: 2 | Iteration number: [380/565] 67% | Training loss: 0.6914971180652317
Epoch: 2 | Iteration number: [390/565] 69% | Training loss: 0.6914392384198996
Epoch: 2 | Iteration number: [400/565] 70% | Training loss: 0.6913929022848606
Epoch: 2 | Iteration number: [410/565] 72% | Training loss: 0.6913482011818304
Epoch: 2 | Iteration number: [420/565] 74% | Training loss: 0.6913083611499695
Epoch: 2 | Iteration number: [430/565] 76% | Training loss: 0.6912645120953405
Epoch: 2 | Iteration number: [440/565] 77% | Training loss: 0.6912136507305232
Epoch: 2 | Iteration number: [450/565] 79% | Training loss: 0.6911663773324754
Epoch: 2 | Iteration number: [460/565] 81% | Training loss: 0.6911241609117259
Epoch: 2 | Iteration number: [470/565] 83% | Training loss: 0.6910826726162688
Epoch: 2 | Iteration number: [480/565] 84% | Training loss: 0.691041931261619
Epoch: 2 | Iteration number: [490/565] 86% | Training loss: 0.6910001279140006
Epoch: 2 | Iteration number: [500/565] 88% | Training loss: 0.6909658117294312
Epoch: 2 | Iteration number: [510/565] 90% | Training loss: 0.6909333839136012
Epoch: 2 | Iteration number: [520/565] 92% | Training loss: 0.6909064918756485
Epoch: 2 | Iteration number: [530/565] 93% | Training loss: 0.690873555079946
Epoch: 2 | Iteration number: [540/565] 95% | Training loss: 0.6908389163238031
Epoch: 2 | Iteration number: [550/565] 97% | Training loss: 0.6908015075596896
Epoch: 2 | Iteration number: [560/565] 99% | Training loss: 0.6907685246850763

 End of epoch: 2 | Train Loss: 0.6895372860199582 | Training Time: 90 

 End of epoch: 2 | Eval Loss: 0.6913058246885028 | Evaluating Time: 5 
Epoch: 3 | Iteration number: [10/565] 1% | Training loss: 0.758472990989685
Epoch: 3 | Iteration number: [20/565] 3% | Training loss: 0.7236994862556457
Epoch: 3 | Iteration number: [30/565] 5% | Training loss: 0.7122716903686523
Epoch: 3 | Iteration number: [40/565] 7% | Training loss: 0.7064392790198326
Epoch: 3 | Iteration number: [50/565] 8% | Training loss: 0.7028755927085877
Epoch: 3 | Iteration number: [60/565] 10% | Training loss: 0.7005729337533315
Epoch: 3 | Iteration number: [70/565] 12% | Training loss: 0.6989034201417651
Epoch: 3 | Iteration number: [80/565] 14% | Training loss: 0.6976315297186375
Epoch: 3 | Iteration number: [90/565] 15% | Training loss: 0.6966893633206686
Epoch: 3 | Iteration number: [100/565] 17% | Training loss: 0.6959061563014984
Epoch: 3 | Iteration number: [110/565] 19% | Training loss: 0.6952462445605885
Epoch: 3 | Iteration number: [120/565] 21% | Training loss: 0.6947398766875267
Epoch: 3 | Iteration number: [130/565] 23% | Training loss: 0.6943212889708006
Epoch: 3 | Iteration number: [140/565] 24% | Training loss: 0.6939733854361942
Epoch: 3 | Iteration number: [150/565] 26% | Training loss: 0.6936335368951162
Epoch: 3 | Iteration number: [160/565] 28% | Training loss: 0.6933346223086119
Epoch: 3 | Iteration number: [170/565] 30% | Training loss: 0.6930928759715136
Epoch: 3 | Iteration number: [180/565] 31% | Training loss: 0.6928671283854378
Epoch: 3 | Iteration number: [190/565] 33% | Training loss: 0.6926272596183576
Epoch: 3 | Iteration number: [200/565] 35% | Training loss: 0.6924364811182022
Epoch: 3 | Iteration number: [210/565] 37% | Training loss: 0.6922687326158796
Epoch: 3 | Iteration number: [220/565] 38% | Training loss: 0.6921127281405709
Epoch: 3 | Iteration number: [230/565] 40% | Training loss: 0.6919670320075492
Epoch: 3 | Iteration number: [240/565] 42% | Training loss: 0.6918389735122522
Epoch: 3 | Iteration number: [250/565] 44% | Training loss: 0.691733323097229
Epoch: 3 | Iteration number: [260/565] 46% | Training loss: 0.6916159804050739
Epoch: 3 | Iteration number: [270/565] 47% | Training loss: 0.6915192025679129
Epoch: 3 | Iteration number: [280/565] 49% | Training loss: 0.691435589322022
Epoch: 3 | Iteration number: [290/565] 51% | Training loss: 0.6913397885602096
Epoch: 3 | Iteration number: [300/565] 53% | Training loss: 0.691254230539004
Epoch: 3 | Iteration number: [310/565] 54% | Training loss: 0.6911735275099354
Epoch: 3 | Iteration number: [320/565] 56% | Training loss: 0.6911050051450729
Epoch: 3 | Iteration number: [330/565] 58% | Training loss: 0.69104235533512
Epoch: 3 | Iteration number: [340/565] 60% | Training loss: 0.6909705158542184
Epoch: 3 | Iteration number: [350/565] 61% | Training loss: 0.6909153778212411
Epoch: 3 | Iteration number: [360/565] 63% | Training loss: 0.690855686697695
Epoch: 3 | Iteration number: [370/565] 65% | Training loss: 0.6907942367566599
Epoch: 3 | Iteration number: [380/565] 67% | Training loss: 0.6907347741879915
Epoch: 3 | Iteration number: [390/565] 69% | Training loss: 0.6906915206175585
Epoch: 3 | Iteration number: [400/565] 70% | Training loss: 0.6906416301429271
Epoch: 3 | Iteration number: [410/565] 72% | Training loss: 0.6905933506605102
Epoch: 3 | Iteration number: [420/565] 74% | Training loss: 0.6905585386923381
Epoch: 3 | Iteration number: [430/565] 76% | Training loss: 0.6905119435731755
Epoch: 3 | Iteration number: [440/565] 77% | Training loss: 0.6904657267711379
Epoch: 3 | Iteration number: [450/565] 79% | Training loss: 0.6904277030626933
Epoch: 3 | Iteration number: [460/565] 81% | Training loss: 0.6903835433980693
Epoch: 3 | Iteration number: [470/565] 83% | Training loss: 0.690339088313123
Epoch: 3 | Iteration number: [480/565] 84% | Training loss: 0.6903059360881646
Epoch: 3 | Iteration number: [490/565] 86% | Training loss: 0.6902757057121822
Epoch: 3 | Iteration number: [500/565] 88% | Training loss: 0.6902415931224823
Epoch: 3 | Iteration number: [510/565] 90% | Training loss: 0.690208634558846
Epoch: 3 | Iteration number: [520/565] 92% | Training loss: 0.690175287425518
Epoch: 3 | Iteration number: [530/565] 93% | Training loss: 0.6901424553034441
Epoch: 3 | Iteration number: [540/565] 95% | Training loss: 0.6901128459859778
Epoch: 3 | Iteration number: [550/565] 97% | Training loss: 0.6900809958848086
Epoch: 3 | Iteration number: [560/565] 99% | Training loss: 0.6900485599679607

 End of epoch: 3 | Train Loss: 0.6888176721809185 | Training Time: 91 

 End of epoch: 3 | Eval Loss: 0.6911927121026176 | Evaluating Time: 5 
Epoch: 4 | Iteration number: [10/565] 1% | Training loss: 0.7579138040542602
Epoch: 4 | Iteration number: [20/565] 3% | Training loss: 0.72348812520504
Epoch: 4 | Iteration number: [30/565] 5% | Training loss: 0.7119273563226064
Epoch: 4 | Iteration number: [40/565] 7% | Training loss: 0.7061084672808647
Epoch: 4 | Iteration number: [50/565] 8% | Training loss: 0.7025949692726136
Epoch: 4 | Iteration number: [60/565] 10% | Training loss: 0.7002313196659088
Epoch: 4 | Iteration number: [70/565] 12% | Training loss: 0.6985215382916586
Epoch: 4 | Iteration number: [80/565] 14% | Training loss: 0.6972380720078946
Epoch: 4 | Iteration number: [90/565] 15% | Training loss: 0.6962676564852397
Epoch: 4 | Iteration number: [100/565] 17% | Training loss: 0.6954800194501877
Epoch: 4 | Iteration number: [110/565] 19% | Training loss: 0.694834796407006
Epoch: 4 | Iteration number: [120/565] 21% | Training loss: 0.6942690402269364
Epoch: 4 | Iteration number: [130/565] 23% | Training loss: 0.6938125293988447
Epoch: 4 | Iteration number: [140/565] 24% | Training loss: 0.693403006025723
Epoch: 4 | Iteration number: [150/565] 26% | Training loss: 0.6930604402224223
Epoch: 4 | Iteration number: [160/565] 28% | Training loss: 0.6927865650504827
Epoch: 4 | Iteration number: [170/565] 30% | Training loss: 0.6925443102331722
Epoch: 4 | Iteration number: [180/565] 31% | Training loss: 0.6923265791601605
Epoch: 4 | Iteration number: [190/565] 33% | Training loss: 0.6921178265621788
Epoch: 4 | Iteration number: [200/565] 35% | Training loss: 0.6919355818629265
Epoch: 4 | Iteration number: [210/565] 37% | Training loss: 0.6917655249436696
Epoch: 4 | Iteration number: [220/565] 38% | Training loss: 0.6916343344883485
Epoch: 4 | Iteration number: [230/565] 40% | Training loss: 0.6914914543214051
Epoch: 4 | Iteration number: [240/565] 42% | Training loss: 0.691347264746825
Epoch: 4 | Iteration number: [250/565] 44% | Training loss: 0.6912283296585083
Epoch: 4 | Iteration number: [260/565] 46% | Training loss: 0.6910999933114419
Epoch: 4 | Iteration number: [270/565] 47% | Training loss: 0.6910163353990626
Epoch: 4 | Iteration number: [280/565] 49% | Training loss: 0.6909342612539019
Epoch: 4 | Iteration number: [290/565] 51% | Training loss: 0.6908356123957141
Epoch: 4 | Iteration number: [300/565] 53% | Training loss: 0.6907460796833038
Epoch: 4 | Iteration number: [310/565] 54% | Training loss: 0.6906700057368125
Epoch: 4 | Iteration number: [320/565] 56% | Training loss: 0.6905993023887277
Epoch: 4 | Iteration number: [330/565] 58% | Training loss: 0.6905415404926647
Epoch: 4 | Iteration number: [340/565] 60% | Training loss: 0.690484260986833
Epoch: 4 | Iteration number: [350/565] 61% | Training loss: 0.6904301190376282
Epoch: 4 | Iteration number: [360/565] 63% | Training loss: 0.6903728430469831
Epoch: 4 | Iteration number: [370/565] 65% | Training loss: 0.6903154426329845
Epoch: 4 | Iteration number: [380/565] 67% | Training loss: 0.6902628153562546
Epoch: 4 | Iteration number: [390/565] 69% | Training loss: 0.6902034203211467
Epoch: 4 | Iteration number: [400/565] 70% | Training loss: 0.6901482866704464
Epoch: 4 | Iteration number: [410/565] 72% | Training loss: 0.6901027728871602
Epoch: 4 | Iteration number: [420/565] 74% | Training loss: 0.6900651291722343
Epoch: 4 | Iteration number: [430/565] 76% | Training loss: 0.6900140081727227
Epoch: 4 | Iteration number: [440/565] 77% | Training loss: 0.6899744529615749
Epoch: 4 | Iteration number: [450/565] 79% | Training loss: 0.6899306686719259
Epoch: 4 | Iteration number: [460/565] 81% | Training loss: 0.6899041620285614
Epoch: 4 | Iteration number: [470/565] 83% | Training loss: 0.6898786940473192
Epoch: 4 | Iteration number: [480/565] 84% | Training loss: 0.6898453123867512
Epoch: 4 | Iteration number: [490/565] 86% | Training loss: 0.6898034298906521
Epoch: 4 | Iteration number: [500/565] 88% | Training loss: 0.6897646706104279
Epoch: 4 | Iteration number: [510/565] 90% | Training loss: 0.6897294656903136
Epoch: 4 | Iteration number: [520/565] 92% | Training loss: 0.6896884177739804
Epoch: 4 | Iteration number: [530/565] 93% | Training loss: 0.6896670473071764
Epoch: 4 | Iteration number: [540/565] 95% | Training loss: 0.6896338514707706
Epoch: 4 | Iteration number: [550/565] 97% | Training loss: 0.6896099430864507
Epoch: 4 | Iteration number: [560/565] 99% | Training loss: 0.6895901665091515

 End of epoch: 4 | Train Loss: 0.6883565137871599 | Training Time: 90 

 End of epoch: 4 | Eval Loss: 0.6912052290780204 | Evaluating Time: 5 
Epoch: 5 | Iteration number: [10/565] 1% | Training loss: 0.756725686788559
Epoch: 5 | Iteration number: [20/565] 3% | Training loss: 0.7222107023000717
Epoch: 5 | Iteration number: [30/565] 5% | Training loss: 0.71075040102005
Epoch: 5 | Iteration number: [40/565] 7% | Training loss: 0.7050586476922035
Epoch: 5 | Iteration number: [50/565] 8% | Training loss: 0.7017290925979615
Epoch: 5 | Iteration number: [60/565] 10% | Training loss: 0.6995138059059779
Epoch: 5 | Iteration number: [70/565] 12% | Training loss: 0.6978691118104118
Epoch: 5 | Iteration number: [80/565] 14% | Training loss: 0.6966598525643348
Epoch: 5 | Iteration number: [90/565] 15% | Training loss: 0.69569068286154
Epoch: 5 | Iteration number: [100/565] 17% | Training loss: 0.6949273455142975
Epoch: 5 | Iteration number: [110/565] 19% | Training loss: 0.6943236876617779
Epoch: 5 | Iteration number: [120/565] 21% | Training loss: 0.6937751531600952
Epoch: 5 | Iteration number: [130/565] 23% | Training loss: 0.6933136105537414
Epoch: 5 | Iteration number: [140/565] 24% | Training loss: 0.6929477993931089
Epoch: 5 | Iteration number: [150/565] 26% | Training loss: 0.6926506626605987
Epoch: 5 | Iteration number: [160/565] 28% | Training loss: 0.6923905313014984
Epoch: 5 | Iteration number: [170/565] 30% | Training loss: 0.6921257404720083
Epoch: 5 | Iteration number: [180/565] 31% | Training loss: 0.6919135679801305
Epoch: 5 | Iteration number: [190/565] 33% | Training loss: 0.6917056569927618
Epoch: 5 | Iteration number: [200/565] 35% | Training loss: 0.6915353590250015
Epoch: 5 | Iteration number: [210/565] 37% | Training loss: 0.6913776834805806
Epoch: 5 | Iteration number: [220/565] 38% | Training loss: 0.6912072875282981
Epoch: 5 | Iteration number: [230/565] 40% | Training loss: 0.6910638962102973
Epoch: 5 | Iteration number: [240/565] 42% | Training loss: 0.6909600652754306
Epoch: 5 | Iteration number: [250/565] 44% | Training loss: 0.6908404879570007
Epoch: 5 | Iteration number: [260/565] 46% | Training loss: 0.6907360792160034
Epoch: 5 | Iteration number: [270/565] 47% | Training loss: 0.6906417491259398
Epoch: 5 | Iteration number: [280/565] 49% | Training loss: 0.690565088391304
Epoch: 5 | Iteration number: [290/565] 51% | Training loss: 0.6904552963273278
Epoch: 5 | Iteration number: [300/565] 53% | Training loss: 0.6903753077983856
Epoch: 5 | Iteration number: [310/565] 54% | Training loss: 0.6902951773135892
Epoch: 5 | Iteration number: [320/565] 56% | Training loss: 0.6902315437793731
Epoch: 5 | Iteration number: [330/565] 58% | Training loss: 0.6901660890290231
Epoch: 5 | Iteration number: [340/565] 60% | Training loss: 0.6901040692539776
Epoch: 5 | Iteration number: [350/565] 61% | Training loss: 0.6900522904736656
Epoch: 5 | Iteration number: [360/565] 63% | Training loss: 0.6899943090147442
Epoch: 5 | Iteration number: [370/565] 65% | Training loss: 0.6899405996541719
Epoch: 5 | Iteration number: [380/565] 67% | Training loss: 0.6898887777014783
Epoch: 5 | Iteration number: [390/565] 69% | Training loss: 0.6898412510370597
Epoch: 5 | Iteration number: [400/565] 70% | Training loss: 0.6898136447370052
Epoch: 5 | Iteration number: [410/565] 72% | Training loss: 0.6897668403823202
Epoch: 5 | Iteration number: [420/565] 74% | Training loss: 0.6897290752047585
Epoch: 5 | Iteration number: [430/565] 76% | Training loss: 0.6896900350271269
Epoch: 5 | Iteration number: [440/565] 77% | Training loss: 0.6896419454704631
Epoch: 5 | Iteration number: [450/565] 79% | Training loss: 0.6896020294560327
Epoch: 5 | Iteration number: [460/565] 81% | Training loss: 0.6895730872517046
Epoch: 5 | Iteration number: [470/565] 83% | Training loss: 0.6895390534654576
Epoch: 5 | Iteration number: [480/565] 84% | Training loss: 0.6895079776644707
Epoch: 5 | Iteration number: [490/565] 86% | Training loss: 0.6894760383635151
Epoch: 5 | Iteration number: [500/565] 88% | Training loss: 0.6894425880908966
Epoch: 5 | Iteration number: [510/565] 90% | Training loss: 0.6894115331126195
Epoch: 5 | Iteration number: [520/565] 92% | Training loss: 0.689382813183161
Epoch: 5 | Iteration number: [530/565] 93% | Training loss: 0.6893600318791732
Epoch: 5 | Iteration number: [540/565] 95% | Training loss: 0.6893328380805475
Epoch: 5 | Iteration number: [550/565] 97% | Training loss: 0.6893079355630007
Epoch: 5 | Iteration number: [560/565] 99% | Training loss: 0.68928438020604

 End of epoch: 5 | Train Loss: 0.6880563759170802 | Training Time: 90 

 End of epoch: 5 | Eval Loss: 0.6902775594166347 | Evaluating Time: 5 
Epoch: 6 | Iteration number: [10/565] 1% | Training loss: 0.7568810224533081
Epoch: 6 | Iteration number: [20/565] 3% | Training loss: 0.7220597684383392
Epoch: 6 | Iteration number: [30/565] 5% | Training loss: 0.7107252995173137
Epoch: 6 | Iteration number: [40/565] 7% | Training loss: 0.7050921127200127
Epoch: 6 | Iteration number: [50/565] 8% | Training loss: 0.7016000032424927
Epoch: 6 | Iteration number: [60/565] 10% | Training loss: 0.6992717583974203
Epoch: 6 | Iteration number: [70/565] 12% | Training loss: 0.6976176134177616
Epoch: 6 | Iteration number: [80/565] 14% | Training loss: 0.6964047364890575
Epoch: 6 | Iteration number: [90/565] 15% | Training loss: 0.6954514198833042
Epoch: 6 | Iteration number: [100/565] 17% | Training loss: 0.6946752482652664
Epoch: 6 | Iteration number: [110/565] 19% | Training loss: 0.6940663819963282
Epoch: 6 | Iteration number: [120/565] 21% | Training loss: 0.6935634449124336
Epoch: 6 | Iteration number: [130/565] 23% | Training loss: 0.6931615939507118
Epoch: 6 | Iteration number: [140/565] 24% | Training loss: 0.6927928784063884
Epoch: 6 | Iteration number: [150/565] 26% | Training loss: 0.6924771829446157
Epoch: 6 | Iteration number: [160/565] 28% | Training loss: 0.6921643581241369
Epoch: 6 | Iteration number: [170/565] 30% | Training loss: 0.6919276076204637
Epoch: 6 | Iteration number: [180/565] 31% | Training loss: 0.6917082293166055
Epoch: 6 | Iteration number: [190/565] 33% | Training loss: 0.691515039456518
Epoch: 6 | Iteration number: [200/565] 35% | Training loss: 0.6913171190023423
Epoch: 6 | Iteration number: [210/565] 37% | Training loss: 0.6911473433176677
Epoch: 6 | Iteration number: [220/565] 38% | Training loss: 0.6909849936311895
Epoch: 6 | Iteration number: [230/565] 40% | Training loss: 0.69085776935453
Epoch: 6 | Iteration number: [240/565] 42% | Training loss: 0.6907307180265586
Epoch: 6 | Iteration number: [250/565] 44% | Training loss: 0.6906022055149078
Epoch: 6 | Iteration number: [260/565] 46% | Training loss: 0.6905101950352008
Epoch: 6 | Iteration number: [270/565] 47% | Training loss: 0.6903989582150071
Epoch: 6 | Iteration number: [280/565] 49% | Training loss: 0.6903173267841339
Epoch: 6 | Iteration number: [290/565] 51% | Training loss: 0.6902356127212788
Epoch: 6 | Iteration number: [300/565] 53% | Training loss: 0.690163825750351
Epoch: 6 | Iteration number: [310/565] 54% | Training loss: 0.6900884864791748
Epoch: 6 | Iteration number: [320/565] 56% | Training loss: 0.6900238586589694
Epoch: 6 | Iteration number: [330/565] 58% | Training loss: 0.6899508963931691
Epoch: 6 | Iteration number: [340/565] 60% | Training loss: 0.6899044284049203
Epoch: 6 | Iteration number: [350/565] 61% | Training loss: 0.6898407460962023
Epoch: 6 | Iteration number: [360/565] 63% | Training loss: 0.689775137272146
Epoch: 6 | Iteration number: [370/565] 65% | Training loss: 0.6897197510745074
Epoch: 6 | Iteration number: [380/565] 67% | Training loss: 0.6896652954189401
Epoch: 6 | Iteration number: [390/565] 69% | Training loss: 0.6896072363242125
Epoch: 6 | Iteration number: [400/565] 70% | Training loss: 0.6895620335638523
Epoch: 6 | Iteration number: [410/565] 72% | Training loss: 0.6895136272034994
Epoch: 6 | Iteration number: [420/565] 74% | Training loss: 0.6894753359612964
Epoch: 6 | Iteration number: [430/565] 76% | Training loss: 0.6894297594247862
Epoch: 6 | Iteration number: [440/565] 77% | Training loss: 0.689396100694483
Epoch: 6 | Iteration number: [450/565] 79% | Training loss: 0.6893707505861918
Epoch: 6 | Iteration number: [460/565] 81% | Training loss: 0.6893257769553558
Epoch: 6 | Iteration number: [470/565] 83% | Training loss: 0.6892987654564229
Epoch: 6 | Iteration number: [480/565] 84% | Training loss: 0.6892675033460061
Epoch: 6 | Iteration number: [490/565] 86% | Training loss: 0.6892443276181512
Epoch: 6 | Iteration number: [500/565] 88% | Training loss: 0.6892196731567383
Epoch: 6 | Iteration number: [510/565] 90% | Training loss: 0.6891847823180405
Epoch: 6 | Iteration number: [520/565] 92% | Training loss: 0.6891657744462674
Epoch: 6 | Iteration number: [530/565] 93% | Training loss: 0.6891445255504465
Epoch: 6 | Iteration number: [540/565] 95% | Training loss: 0.6891199491642139
Epoch: 6 | Iteration number: [550/565] 97% | Training loss: 0.689088482206518
Epoch: 6 | Iteration number: [560/565] 99% | Training loss: 0.6890690843973841

 End of epoch: 6 | Train Loss: 0.6878374755910013 | Training Time: 91 

 End of epoch: 6 | Eval Loss: 0.6904950397355216 | Evaluating Time: 5 
Epoch: 7 | Iteration number: [10/565] 1% | Training loss: 0.7564065217971802
Epoch: 7 | Iteration number: [20/565] 3% | Training loss: 0.7220266789197922
Epoch: 7 | Iteration number: [30/565] 5% | Training loss: 0.7105755885442098
Epoch: 7 | Iteration number: [40/565] 7% | Training loss: 0.7048352941870689
Epoch: 7 | Iteration number: [50/565] 8% | Training loss: 0.7013619792461395
Epoch: 7 | Iteration number: [60/565] 10% | Training loss: 0.6991265912850698
Epoch: 7 | Iteration number: [70/565] 12% | Training loss: 0.6974928915500641
Epoch: 7 | Iteration number: [80/565] 14% | Training loss: 0.6963010482490063
Epoch: 7 | Iteration number: [90/565] 15% | Training loss: 0.6953468998273213
Epoch: 7 | Iteration number: [100/565] 17% | Training loss: 0.6945521795749664
Epoch: 7 | Iteration number: [110/565] 19% | Training loss: 0.6939015128395775
Epoch: 7 | Iteration number: [120/565] 21% | Training loss: 0.6933814446131389
Epoch: 7 | Iteration number: [130/565] 23% | Training loss: 0.6929556149702806
Epoch: 7 | Iteration number: [140/565] 24% | Training loss: 0.692599727852004
Epoch: 7 | Iteration number: [150/565] 26% | Training loss: 0.6922901380062103
Epoch: 7 | Iteration number: [160/565] 28% | Training loss: 0.6919966880232096
Epoch: 7 | Iteration number: [170/565] 30% | Training loss: 0.691745687232298
Epoch: 7 | Iteration number: [180/565] 31% | Training loss: 0.6915429774257872
Epoch: 7 | Iteration number: [190/565] 33% | Training loss: 0.6913465753981941
Epoch: 7 | Iteration number: [200/565] 35% | Training loss: 0.6911550712585449
Epoch: 7 | Iteration number: [210/565] 37% | Training loss: 0.6909812101296016
Epoch: 7 | Iteration number: [220/565] 38% | Training loss: 0.6908121499148282
Epoch: 7 | Iteration number: [230/565] 40% | Training loss: 0.690689575412999
Epoch: 7 | Iteration number: [240/565] 42% | Training loss: 0.6905709053079288
Epoch: 7 | Iteration number: [250/565] 44% | Training loss: 0.6904594926834107
Epoch: 7 | Iteration number: [260/565] 46% | Training loss: 0.6903649513538067
Epoch: 7 | Iteration number: [270/565] 47% | Training loss: 0.6902669063320866
Epoch: 7 | Iteration number: [280/565] 49% | Training loss: 0.6901680912290301
Epoch: 7 | Iteration number: [290/565] 51% | Training loss: 0.6900797081404719
Epoch: 7 | Iteration number: [300/565] 53% | Training loss: 0.6899954179922739
Epoch: 7 | Iteration number: [310/565] 54% | Training loss: 0.689923829609348
Epoch: 7 | Iteration number: [320/565] 56% | Training loss: 0.6898566240444779
Epoch: 7 | Iteration number: [330/565] 58% | Training loss: 0.6897958825935017
Epoch: 7 | Iteration number: [340/565] 60% | Training loss: 0.6897411646211848
Epoch: 7 | Iteration number: [350/565] 61% | Training loss: 0.6896881006445204
Epoch: 7 | Iteration number: [360/565] 63% | Training loss: 0.6896264859371715
Epoch: 7 | Iteration number: [370/565] 65% | Training loss: 0.6895805115635331
Epoch: 7 | Iteration number: [380/565] 67% | Training loss: 0.6895195636310075
Epoch: 7 | Iteration number: [390/565] 69% | Training loss: 0.6894675392370958
Epoch: 7 | Iteration number: [400/565] 70% | Training loss: 0.6894166956841946
Epoch: 7 | Iteration number: [410/565] 72% | Training loss: 0.6893781590752486
Epoch: 7 | Iteration number: [420/565] 74% | Training loss: 0.6893249938885371
Epoch: 7 | Iteration number: [430/565] 76% | Training loss: 0.6892815247524616
Epoch: 7 | Iteration number: [440/565] 77% | Training loss: 0.6892402352257209
Epoch: 7 | Iteration number: [450/565] 79% | Training loss: 0.6892055608166588
Epoch: 7 | Iteration number: [460/565] 81% | Training loss: 0.6891751777866613
Epoch: 7 | Iteration number: [470/565] 83% | Training loss: 0.6891486957986304
Epoch: 7 | Iteration number: [480/565] 84% | Training loss: 0.689114614451925
Epoch: 7 | Iteration number: [490/565] 86% | Training loss: 0.6890825709518121
Epoch: 7 | Iteration number: [500/565] 88% | Training loss: 0.6890526201725006
Epoch: 7 | Iteration number: [510/565] 90% | Training loss: 0.6890187437627829
Epoch: 7 | Iteration number: [520/565] 92% | Training loss: 0.6889902090797058
Epoch: 7 | Iteration number: [530/565] 93% | Training loss: 0.68896095606516
Epoch: 7 | Iteration number: [540/565] 95% | Training loss: 0.6889356236766886
Epoch: 7 | Iteration number: [550/565] 97% | Training loss: 0.6889139772545207
Epoch: 7 | Iteration number: [560/565] 99% | Training loss: 0.6888921741928373

 End of epoch: 7 | Train Loss: 0.6876640977057735 | Training Time: 90 

 End of epoch: 7 | Eval Loss: 0.6903699891907829 | Evaluating Time: 5 
Epoch: 8 | Iteration number: [10/565] 1% | Training loss: 0.756419575214386
Epoch: 8 | Iteration number: [20/565] 3% | Training loss: 0.722033366560936
Epoch: 8 | Iteration number: [30/565] 5% | Training loss: 0.710414832830429
Epoch: 8 | Iteration number: [40/565] 7% | Training loss: 0.7046637862920762
Epoch: 8 | Iteration number: [50/565] 8% | Training loss: 0.7011335945129394
Epoch: 8 | Iteration number: [60/565] 10% | Training loss: 0.6988932450612386
Epoch: 8 | Iteration number: [70/565] 12% | Training loss: 0.6972456182752337
Epoch: 8 | Iteration number: [80/565] 14% | Training loss: 0.6960440449416637
Epoch: 8 | Iteration number: [90/565] 15% | Training loss: 0.6950981809033288
Epoch: 8 | Iteration number: [100/565] 17% | Training loss: 0.6943709242343903
Epoch: 8 | Iteration number: [110/565] 19% | Training loss: 0.6937434689565138
Epoch: 8 | Iteration number: [120/565] 21% | Training loss: 0.6932192424933116
Epoch: 8 | Iteration number: [130/565] 23% | Training loss: 0.692790234547395
Epoch: 8 | Iteration number: [140/565] 24% | Training loss: 0.6924240678548813
Epoch: 8 | Iteration number: [150/565] 26% | Training loss: 0.6920678933461507
Epoch: 8 | Iteration number: [160/565] 28% | Training loss: 0.691781722381711
Epoch: 8 | Iteration number: [170/565] 30% | Training loss: 0.6915456151261049
Epoch: 8 | Iteration number: [180/565] 31% | Training loss: 0.6913173655668895
Epoch: 8 | Iteration number: [190/565] 33% | Training loss: 0.6911300411349849
Epoch: 8 | Iteration number: [200/565] 35% | Training loss: 0.6909446921944619
Epoch: 8 | Iteration number: [210/565] 37% | Training loss: 0.6907652874787649
Epoch: 8 | Iteration number: [220/565] 38% | Training loss: 0.6906224437735298
Epoch: 8 | Iteration number: [230/565] 40% | Training loss: 0.6904844260734061
Epoch: 8 | Iteration number: [240/565] 42% | Training loss: 0.690349330753088
Epoch: 8 | Iteration number: [250/565] 44% | Training loss: 0.6902414078712463
Epoch: 8 | Iteration number: [260/565] 46% | Training loss: 0.6901387865726765
Epoch: 8 | Iteration number: [270/565] 47% | Training loss: 0.6900577686451099
Epoch: 8 | Iteration number: [280/565] 49% | Training loss: 0.6899799289447921
Epoch: 8 | Iteration number: [290/565] 51% | Training loss: 0.6898905028556955
Epoch: 8 | Iteration number: [300/565] 53% | Training loss: 0.6897984812657039
Epoch: 8 | Iteration number: [310/565] 54% | Training loss: 0.6897289897164991
Epoch: 8 | Iteration number: [320/565] 56% | Training loss: 0.6896677715703845
Epoch: 8 | Iteration number: [330/565] 58% | Training loss: 0.6896009183291233
Epoch: 8 | Iteration number: [340/565] 60% | Training loss: 0.6895445452016943
Epoch: 8 | Iteration number: [350/565] 61% | Training loss: 0.6894833947931017
Epoch: 8 | Iteration number: [360/565] 63% | Training loss: 0.6894265936480628
Epoch: 8 | Iteration number: [370/565] 65% | Training loss: 0.6893718319970208
Epoch: 8 | Iteration number: [380/565] 67% | Training loss: 0.689320360516247
Epoch: 8 | Iteration number: [390/565] 69% | Training loss: 0.6892755415195074
Epoch: 8 | Iteration number: [400/565] 70% | Training loss: 0.6892272640764713
Epoch: 8 | Iteration number: [410/565] 72% | Training loss: 0.6891855920233377
Epoch: 8 | Iteration number: [420/565] 74% | Training loss: 0.6891430035943077
Epoch: 8 | Iteration number: [430/565] 76% | Training loss: 0.6891011616518331
Epoch: 8 | Iteration number: [440/565] 77% | Training loss: 0.6890562589872967
Epoch: 8 | Iteration number: [450/565] 79% | Training loss: 0.6890298630131616
Epoch: 8 | Iteration number: [460/565] 81% | Training loss: 0.6889895770860754
Epoch: 8 | Iteration number: [470/565] 83% | Training loss: 0.6889614791312116
Epoch: 8 | Iteration number: [480/565] 84% | Training loss: 0.6889282874763012
Epoch: 8 | Iteration number: [490/565] 86% | Training loss: 0.6888984641250299
Epoch: 8 | Iteration number: [500/565] 88% | Training loss: 0.6888649621009827
Epoch: 8 | Iteration number: [510/565] 90% | Training loss: 0.6888484750308242
Epoch: 8 | Iteration number: [520/565] 92% | Training loss: 0.6888167442037509
Epoch: 8 | Iteration number: [530/565] 93% | Training loss: 0.6887923137196955
Epoch: 8 | Iteration number: [540/565] 95% | Training loss: 0.6887678290958757
Epoch: 8 | Iteration number: [550/565] 97% | Training loss: 0.6887452339042317
Epoch: 8 | Iteration number: [560/565] 99% | Training loss: 0.6887225608740534

 End of epoch: 8 | Train Loss: 0.687494805745319 | Training Time: 90 

 End of epoch: 8 | Eval Loss: 0.6903942567961556 | Evaluating Time: 5 
Epoch: 9 | Iteration number: [10/565] 1% | Training loss: 0.7560956537723541
Epoch: 9 | Iteration number: [20/565] 3% | Training loss: 0.7217494815587997
Epoch: 9 | Iteration number: [30/565] 5% | Training loss: 0.710271680355072
Epoch: 9 | Iteration number: [40/565] 7% | Training loss: 0.7046474829316139
Epoch: 9 | Iteration number: [50/565] 8% | Training loss: 0.7012374758720398
Epoch: 9 | Iteration number: [60/565] 10% | Training loss: 0.6989379743734996
Epoch: 9 | Iteration number: [70/565] 12% | Training loss: 0.6972909484590802
Epoch: 9 | Iteration number: [80/565] 14% | Training loss: 0.6960721738636494
Epoch: 9 | Iteration number: [90/565] 15% | Training loss: 0.6951023240884145
Epoch: 9 | Iteration number: [100/565] 17% | Training loss: 0.6942809814214707
Epoch: 9 | Iteration number: [110/565] 19% | Training loss: 0.6936565404588526
Epoch: 9 | Iteration number: [120/565] 21% | Training loss: 0.6931302741169929
Epoch: 9 | Iteration number: [130/565] 23% | Training loss: 0.6927480830596043
Epoch: 9 | Iteration number: [140/565] 24% | Training loss: 0.6923708481448038
Epoch: 9 | Iteration number: [150/565] 26% | Training loss: 0.6920208855470021
Epoch: 9 | Iteration number: [160/565] 28% | Training loss: 0.6917212020605803
Epoch: 9 | Iteration number: [170/565] 30% | Training loss: 0.6914612710475921
Epoch: 9 | Iteration number: [180/565] 31% | Training loss: 0.6912192066510519
Epoch: 9 | Iteration number: [190/565] 33% | Training loss: 0.6910148102986186
Epoch: 9 | Iteration number: [200/565] 35% | Training loss: 0.6908260026574135
Epoch: 9 | Iteration number: [210/565] 37% | Training loss: 0.6906534183593024
Epoch: 9 | Iteration number: [220/565] 38% | Training loss: 0.6905195940624583
Epoch: 9 | Iteration number: [230/565] 40% | Training loss: 0.6903712397036346
Epoch: 9 | Iteration number: [240/565] 42% | Training loss: 0.6902347845335801
Epoch: 9 | Iteration number: [250/565] 44% | Training loss: 0.6901284694671631
Epoch: 9 | Iteration number: [260/565] 46% | Training loss: 0.6900253451787508
Epoch: 9 | Iteration number: [270/565] 47% | Training loss: 0.6899433564256738
Epoch: 9 | Iteration number: [280/565] 49% | Training loss: 0.6898454942873546
Epoch: 9 | Iteration number: [290/565] 51% | Training loss: 0.6897710101357821
Epoch: 9 | Iteration number: [300/565] 53% | Training loss: 0.6896957780917485
Epoch: 9 | Iteration number: [310/565] 54% | Training loss: 0.689624987686834
Epoch: 9 | Iteration number: [320/565] 56% | Training loss: 0.6895625304430724
Epoch: 9 | Iteration number: [330/565] 58% | Training loss: 0.6894901517665748
Epoch: 9 | Iteration number: [340/565] 60% | Training loss: 0.6894488075200249
Epoch: 9 | Iteration number: [350/565] 61% | Training loss: 0.6893887484073639
Epoch: 9 | Iteration number: [360/565] 63% | Training loss: 0.689341353211138
Epoch: 9 | Iteration number: [370/565] 65% | Training loss: 0.6892923994644268
Epoch: 9 | Iteration number: [380/565] 67% | Training loss: 0.6892484387284831
Epoch: 9 | Iteration number: [390/565] 69% | Training loss: 0.6891912202040354
Epoch: 9 | Iteration number: [400/565] 70% | Training loss: 0.6891420491039753
Epoch: 9 | Iteration number: [410/565] 72% | Training loss: 0.6891028929047468
Epoch: 9 | Iteration number: [420/565] 74% | Training loss: 0.6890621376889092
Epoch: 9 | Iteration number: [430/565] 76% | Training loss: 0.6890266096869181
Epoch: 9 | Iteration number: [440/565] 77% | Training loss: 0.6889970710331743
Epoch: 9 | Iteration number: [450/565] 79% | Training loss: 0.6889586067199707
Epoch: 9 | Iteration number: [460/565] 81% | Training loss: 0.6889270157917686
Epoch: 9 | Iteration number: [470/565] 83% | Training loss: 0.6888945010114224
Epoch: 9 | Iteration number: [480/565] 84% | Training loss: 0.6888558036337297
Epoch: 9 | Iteration number: [490/565] 86% | Training loss: 0.6888207964751185
Epoch: 9 | Iteration number: [500/565] 88% | Training loss: 0.6887969306707382
Epoch: 9 | Iteration number: [510/565] 90% | Training loss: 0.6887701489177405
Epoch: 9 | Iteration number: [520/565] 92% | Training loss: 0.6887389547549762
Epoch: 9 | Iteration number: [530/565] 93% | Training loss: 0.6887115208607799
Epoch: 9 | Iteration number: [540/565] 95% | Training loss: 0.688684074304722
Epoch: 9 | Iteration number: [550/565] 97% | Training loss: 0.6886592306874015
Epoch: 9 | Iteration number: [560/565] 99% | Training loss: 0.68862722579922

 End of epoch: 9 | Train Loss: 0.6873999424740277 | Training Time: 91 

 End of epoch: 9 | Eval Loss: 0.6904276098523822 | Evaluating Time: 5 
Epoch: 10 | Iteration number: [10/565] 1% | Training loss: 0.7562972366809845
Epoch: 10 | Iteration number: [20/565] 3% | Training loss: 0.7219105750322342
Epoch: 10 | Iteration number: [30/565] 5% | Training loss: 0.7104422092437744
Epoch: 10 | Iteration number: [40/565] 7% | Training loss: 0.7047059237957001
Epoch: 10 | Iteration number: [50/565] 8% | Training loss: 0.7011277067661286
Epoch: 10 | Iteration number: [60/565] 10% | Training loss: 0.6987794756889343
Epoch: 10 | Iteration number: [70/565] 12% | Training loss: 0.697136709519795
Epoch: 10 | Iteration number: [80/565] 14% | Training loss: 0.6958658300340176
Epoch: 10 | Iteration number: [90/565] 15% | Training loss: 0.6949178013536665
Epoch: 10 | Iteration number: [100/565] 17% | Training loss: 0.6941284912824631
Epoch: 10 | Iteration number: [110/565] 19% | Training loss: 0.6934848969632929
Epoch: 10 | Iteration number: [120/565] 21% | Training loss: 0.6929678405324619
Epoch: 10 | Iteration number: [130/565] 23% | Training loss: 0.6925111908179064
Epoch: 10 | Iteration number: [140/565] 24% | Training loss: 0.692114121573312
Epoch: 10 | Iteration number: [150/565] 26% | Training loss: 0.6917879350980123
Epoch: 10 | Iteration number: [160/565] 28% | Training loss: 0.6914756968617439
Epoch: 10 | Iteration number: [170/565] 30% | Training loss: 0.6912458707304562
Epoch: 10 | Iteration number: [180/565] 31% | Training loss: 0.6910178913010492
Epoch: 10 | Iteration number: [190/565] 33% | Training loss: 0.6908321757065622
Epoch: 10 | Iteration number: [200/565] 35% | Training loss: 0.6906659039855003
Epoch: 10 | Iteration number: [210/565] 37% | Training loss: 0.6905016967228481
Epoch: 10 | Iteration number: [220/565] 38% | Training loss: 0.6903633827512915
Epoch: 10 | Iteration number: [230/565] 40% | Training loss: 0.6902269492978635
Epoch: 10 | Iteration number: [240/565] 42% | Training loss: 0.6901044641931852
Epoch: 10 | Iteration number: [250/565] 44% | Training loss: 0.6899911873340606
Epoch: 10 | Iteration number: [260/565] 46% | Training loss: 0.689896689928495
Epoch: 10 | Iteration number: [270/565] 47% | Training loss: 0.6898012342276396
Epoch: 10 | Iteration number: [280/565] 49% | Training loss: 0.689713622203895
Epoch: 10 | Iteration number: [290/565] 51% | Training loss: 0.6896208456878005
Epoch: 10 | Iteration number: [300/565] 53% | Training loss: 0.6895302486419678
Epoch: 10 | Iteration number: [310/565] 54% | Training loss: 0.6894629659191255
Epoch: 10 | Iteration number: [320/565] 56% | Training loss: 0.6894113885238766
Epoch: 10 | Iteration number: [330/565] 58% | Training loss: 0.6893453392115506
Epoch: 10 | Iteration number: [340/565] 60% | Training loss: 0.6892892851549036
Epoch: 10 | Iteration number: [350/565] 61% | Training loss: 0.6892301028115408
Epoch: 10 | Iteration number: [360/565] 63% | Training loss: 0.6891747539242109
Epoch: 10 | Iteration number: [370/565] 65% | Training loss: 0.689117939891042
Epoch: 10 | Iteration number: [380/565] 67% | Training loss: 0.6890698399982954
Epoch: 10 | Iteration number: [390/565] 69% | Training loss: 0.6890219133633834
Epoch: 10 | Iteration number: [400/565] 70% | Training loss: 0.6889791363477706
Epoch: 10 | Iteration number: [410/565] 72% | Training loss: 0.6889391766815651
Epoch: 10 | Iteration number: [420/565] 74% | Training loss: 0.6889023946864264
Epoch: 10 | Iteration number: [430/565] 76% | Training loss: 0.6888637447079947
Epoch: 10 | Iteration number: [440/565] 77% | Training loss: 0.6888280915943059
Epoch: 10 | Iteration number: [450/565] 79% | Training loss: 0.6887958200772604
Epoch: 10 | Iteration number: [460/565] 81% | Training loss: 0.6887684376343437
Epoch: 10 | Iteration number: [470/565] 83% | Training loss: 0.6887343900000795
Epoch: 10 | Iteration number: [480/565] 84% | Training loss: 0.6887062116215626
Epoch: 10 | Iteration number: [490/565] 86% | Training loss: 0.6886785734672936
Epoch: 10 | Iteration number: [500/565] 88% | Training loss: 0.6886636363267898
Epoch: 10 | Iteration number: [510/565] 90% | Training loss: 0.6886363380095538
Epoch: 10 | Iteration number: [520/565] 92% | Training loss: 0.6886095869999665
Epoch: 10 | Iteration number: [530/565] 93% | Training loss: 0.6885795046698372
Epoch: 10 | Iteration number: [540/565] 95% | Training loss: 0.6885532852676179
Epoch: 10 | Iteration number: [550/565] 97% | Training loss: 0.6885322189331055
Epoch: 10 | Iteration number: [560/565] 99% | Training loss: 0.6885007693299225

 End of epoch: 10 | Train Loss: 0.6872741597943601 | Training Time: 91 

 End of epoch: 10 | Eval Loss: 0.6906229513032096 | Evaluating Time: 6 
Epoch: 11 | Iteration number: [10/565] 1% | Training loss: 0.7564928293228149
Epoch: 11 | Iteration number: [20/565] 3% | Training loss: 0.7217900037765503
Epoch: 11 | Iteration number: [30/565] 5% | Training loss: 0.7103460411230723
Epoch: 11 | Iteration number: [40/565] 7% | Training loss: 0.7046245008707046
Epoch: 11 | Iteration number: [50/565] 8% | Training loss: 0.7009942293167114
Epoch: 11 | Iteration number: [60/565] 10% | Training loss: 0.6987230161825816
Epoch: 11 | Iteration number: [70/565] 12% | Training loss: 0.6971068808010646
Epoch: 11 | Iteration number: [80/565] 14% | Training loss: 0.6958829745650291
Epoch: 11 | Iteration number: [90/565] 15% | Training loss: 0.6949638260735406
Epoch: 11 | Iteration number: [100/565] 17% | Training loss: 0.694208055138588
Epoch: 11 | Iteration number: [110/565] 19% | Training loss: 0.6935369914228265
Epoch: 11 | Iteration number: [120/565] 21% | Training loss: 0.6929673130313555
Epoch: 11 | Iteration number: [130/565] 23% | Training loss: 0.692508720434629
Epoch: 11 | Iteration number: [140/565] 24% | Training loss: 0.6921183122055871
Epoch: 11 | Iteration number: [150/565] 26% | Training loss: 0.6917923669020335
Epoch: 11 | Iteration number: [160/565] 28% | Training loss: 0.6915197394788265
Epoch: 11 | Iteration number: [170/565] 30% | Training loss: 0.6912340350010816
Epoch: 11 | Iteration number: [180/565] 31% | Training loss: 0.6910099695126216
Epoch: 11 | Iteration number: [190/565] 33% | Training loss: 0.6907995362030832
Epoch: 11 | Iteration number: [200/565] 35% | Training loss: 0.6906336361169815
Epoch: 11 | Iteration number: [210/565] 37% | Training loss: 0.6904795447985331
Epoch: 11 | Iteration number: [220/565] 38% | Training loss: 0.6903549644080076
Epoch: 11 | Iteration number: [230/565] 40% | Training loss: 0.6902005317418471
Epoch: 11 | Iteration number: [240/565] 42% | Training loss: 0.6900680683553219
Epoch: 11 | Iteration number: [250/565] 44% | Training loss: 0.6899337685108184
Epoch: 11 | Iteration number: [260/565] 46% | Training loss: 0.6898328375357848
Epoch: 11 | Iteration number: [270/565] 47% | Training loss: 0.6897298285254726
Epoch: 11 | Iteration number: [280/565] 49% | Training loss: 0.6896442211100033
Epoch: 11 | Iteration number: [290/565] 51% | Training loss: 0.6895558155816177
Epoch: 11 | Iteration number: [300/565] 53% | Training loss: 0.6894817012548446
Epoch: 11 | Iteration number: [310/565] 54% | Training loss: 0.6894140660762786
Epoch: 11 | Iteration number: [320/565] 56% | Training loss: 0.6893362034112215
Epoch: 11 | Iteration number: [330/565] 58% | Training loss: 0.6892799673658428
Epoch: 11 | Iteration number: [340/565] 60% | Training loss: 0.6892268810202093
Epoch: 11 | Iteration number: [350/565] 61% | Training loss: 0.689163464988981
Epoch: 11 | Iteration number: [360/565] 63% | Training loss: 0.6891093166338073
Epoch: 11 | Iteration number: [370/565] 65% | Training loss: 0.6890580244966455
Epoch: 11 | Iteration number: [380/565] 67% | Training loss: 0.6890087700203845
Epoch: 11 | Iteration number: [390/565] 69% | Training loss: 0.6889732611485017
Epoch: 11 | Iteration number: [400/565] 70% | Training loss: 0.6889277072250843
Epoch: 11 | Iteration number: [410/565] 72% | Training loss: 0.6888988445444805
Epoch: 11 | Iteration number: [420/565] 74% | Training loss: 0.6888517138503847
Epoch: 11 | Iteration number: [430/565] 76% | Training loss: 0.6888169940127883
Epoch: 11 | Iteration number: [440/565] 77% | Training loss: 0.6887822572480549
Epoch: 11 | Iteration number: [450/565] 79% | Training loss: 0.6887430503633287
Epoch: 11 | Iteration number: [460/565] 81% | Training loss: 0.6887161669523819
Epoch: 11 | Iteration number: [470/565] 83% | Training loss: 0.6886841579954674
Epoch: 11 | Iteration number: [480/565] 84% | Training loss: 0.6886516540000837
Epoch: 11 | Iteration number: [490/565] 86% | Training loss: 0.6886227715988549
Epoch: 11 | Iteration number: [500/565] 88% | Training loss: 0.6885838377475738
Epoch: 11 | Iteration number: [510/565] 90% | Training loss: 0.6885500793363534
Epoch: 11 | Iteration number: [520/565] 92% | Training loss: 0.6885135278105736
Epoch: 11 | Iteration number: [530/565] 93% | Training loss: 0.6884835170125062
Epoch: 11 | Iteration number: [540/565] 95% | Training loss: 0.6884525209665299
Epoch: 11 | Iteration number: [550/565] 97% | Training loss: 0.6884280847419392
Epoch: 11 | Iteration number: [560/565] 99% | Training loss: 0.6884059538798672

 End of epoch: 11 | Train Loss: 0.6871749372608894 | Training Time: 90 

 End of epoch: 11 | Eval Loss: 0.6904561604772296 | Evaluating Time: 5 
Epoch: 12 | Iteration number: [10/565] 1% | Training loss: 0.7560178637504578
Epoch: 12 | Iteration number: [20/565] 3% | Training loss: 0.7214859902858735
Epoch: 12 | Iteration number: [30/565] 5% | Training loss: 0.7102209230264028
Epoch: 12 | Iteration number: [40/565] 7% | Training loss: 0.7045205414295197
Epoch: 12 | Iteration number: [50/565] 8% | Training loss: 0.7010042333602905
Epoch: 12 | Iteration number: [60/565] 10% | Training loss: 0.6986927062273025
Epoch: 12 | Iteration number: [70/565] 12% | Training loss: 0.6970096622194563
Epoch: 12 | Iteration number: [80/565] 14% | Training loss: 0.6958253033459186
Epoch: 12 | Iteration number: [90/565] 15% | Training loss: 0.6948436889383528
Epoch: 12 | Iteration number: [100/565] 17% | Training loss: 0.6940755474567414
Epoch: 12 | Iteration number: [110/565] 19% | Training loss: 0.6934404318982904
Epoch: 12 | Iteration number: [120/565] 21% | Training loss: 0.692901765803496
Epoch: 12 | Iteration number: [130/565] 23% | Training loss: 0.6924247040198399
Epoch: 12 | Iteration number: [140/565] 24% | Training loss: 0.6920121610164642
Epoch: 12 | Iteration number: [150/565] 26% | Training loss: 0.6916953043142955
Epoch: 12 | Iteration number: [160/565] 28% | Training loss: 0.6914047665894032
Epoch: 12 | Iteration number: [170/565] 30% | Training loss: 0.6911695718765258
Epoch: 12 | Iteration number: [180/565] 31% | Training loss: 0.6909308936860826
Epoch: 12 | Iteration number: [190/565] 33% | Training loss: 0.6907274854810614
Epoch: 12 | Iteration number: [200/565] 35% | Training loss: 0.6905554208159447
Epoch: 12 | Iteration number: [210/565] 37% | Training loss: 0.690387688648133
Epoch: 12 | Iteration number: [220/565] 38% | Training loss: 0.6902474040334875
Epoch: 12 | Iteration number: [230/565] 40% | Training loss: 0.6901223047919895
Epoch: 12 | Iteration number: [240/565] 42% | Training loss: 0.6899914768834908
Epoch: 12 | Iteration number: [250/565] 44% | Training loss: 0.6898912169933319
Epoch: 12 | Iteration number: [260/565] 46% | Training loss: 0.6897856884277784
Epoch: 12 | Iteration number: [270/565] 47% | Training loss: 0.6896884112446396
Epoch: 12 | Iteration number: [280/565] 49% | Training loss: 0.6895931773952075
Epoch: 12 | Iteration number: [290/565] 51% | Training loss: 0.6895144257052191
Epoch: 12 | Iteration number: [300/565] 53% | Training loss: 0.6894374809662501
Epoch: 12 | Iteration number: [310/565] 54% | Training loss: 0.6893603805572756
Epoch: 12 | Iteration number: [320/565] 56% | Training loss: 0.6892910933122038
Epoch: 12 | Iteration number: [330/565] 58% | Training loss: 0.6892330995111754
Epoch: 12 | Iteration number: [340/565] 60% | Training loss: 0.6891719094094109
Epoch: 12 | Iteration number: [350/565] 61% | Training loss: 0.6891080476556506
Epoch: 12 | Iteration number: [360/565] 63% | Training loss: 0.6890427955322795
Epoch: 12 | Iteration number: [370/565] 65% | Training loss: 0.6889913990690901
Epoch: 12 | Iteration number: [380/565] 67% | Training loss: 0.6889351546764374
Epoch: 12 | Iteration number: [390/565] 69% | Training loss: 0.6888948451250028
Epoch: 12 | Iteration number: [400/565] 70% | Training loss: 0.6888546606898308
Epoch: 12 | Iteration number: [410/565] 72% | Training loss: 0.6888233634029947
Epoch: 12 | Iteration number: [420/565] 74% | Training loss: 0.6887789575826554
Epoch: 12 | Iteration number: [430/565] 76% | Training loss: 0.6887350028337434
Epoch: 12 | Iteration number: [440/565] 77% | Training loss: 0.6886977450414138
Epoch: 12 | Iteration number: [450/565] 79% | Training loss: 0.6886717853281233
Epoch: 12 | Iteration number: [460/565] 81% | Training loss: 0.688634009724078
Epoch: 12 | Iteration number: [470/565] 83% | Training loss: 0.6885912701170496
Epoch: 12 | Iteration number: [480/565] 84% | Training loss: 0.688556574533383
Epoch: 12 | Iteration number: [490/565] 86% | Training loss: 0.6885338600800962
Epoch: 12 | Iteration number: [500/565] 88% | Training loss: 0.6885111464262008
Epoch: 12 | Iteration number: [510/565] 90% | Training loss: 0.6884895788688286
Epoch: 12 | Iteration number: [520/565] 92% | Training loss: 0.688466760286918
Epoch: 12 | Iteration number: [530/565] 93% | Training loss: 0.6884460410981809
Epoch: 12 | Iteration number: [540/565] 95% | Training loss: 0.6884196236177728
Epoch: 12 | Iteration number: [550/565] 97% | Training loss: 0.6883973855322058
Epoch: 12 | Iteration number: [560/565] 99% | Training loss: 0.6883724856589521

 End of epoch: 12 | Train Loss: 0.6871453331635061 | Training Time: 91 

 End of epoch: 12 | Eval Loss: 0.6901017001696995 | Evaluating Time: 5 
Epoch: 13 | Iteration number: [10/565] 1% | Training loss: 0.7556247353553772
Epoch: 13 | Iteration number: [20/565] 3% | Training loss: 0.721332636475563
Epoch: 13 | Iteration number: [30/565] 5% | Training loss: 0.7099868913491567
Epoch: 13 | Iteration number: [40/565] 7% | Training loss: 0.7042717635631561
Epoch: 13 | Iteration number: [50/565] 8% | Training loss: 0.7009204757213593
Epoch: 13 | Iteration number: [60/565] 10% | Training loss: 0.6987035016218821
Epoch: 13 | Iteration number: [70/565] 12% | Training loss: 0.697020435333252
Epoch: 13 | Iteration number: [80/565] 14% | Training loss: 0.6958048455417156
Epoch: 13 | Iteration number: [90/565] 15% | Training loss: 0.6948610047499338
Epoch: 13 | Iteration number: [100/565] 17% | Training loss: 0.6940954107046128
Epoch: 13 | Iteration number: [110/565] 19% | Training loss: 0.6934516868808053
Epoch: 13 | Iteration number: [120/565] 21% | Training loss: 0.6929580464959144
Epoch: 13 | Iteration number: [130/565] 23% | Training loss: 0.6925289873893444
Epoch: 13 | Iteration number: [140/565] 24% | Training loss: 0.6921203000204904
Epoch: 13 | Iteration number: [150/565] 26% | Training loss: 0.6917668414115906
Epoch: 13 | Iteration number: [160/565] 28% | Training loss: 0.6914906200021506
Epoch: 13 | Iteration number: [170/565] 30% | Training loss: 0.6912339007153231
Epoch: 13 | Iteration number: [180/565] 31% | Training loss: 0.6909930715958278
Epoch: 13 | Iteration number: [190/565] 33% | Training loss: 0.6907661685818121
Epoch: 13 | Iteration number: [200/565] 35% | Training loss: 0.6905676817893982
Epoch: 13 | Iteration number: [210/565] 37% | Training loss: 0.6904106279214223
Epoch: 13 | Iteration number: [220/565] 38% | Training loss: 0.690260291912339
Epoch: 13 | Iteration number: [230/565] 40% | Training loss: 0.6901207369306813
Epoch: 13 | Iteration number: [240/565] 42% | Training loss: 0.6899781689047814
Epoch: 13 | Iteration number: [250/565] 44% | Training loss: 0.689862982749939
Epoch: 13 | Iteration number: [260/565] 46% | Training loss: 0.6897516021361718
Epoch: 13 | Iteration number: [270/565] 47% | Training loss: 0.6896391870798888
Epoch: 13 | Iteration number: [280/565] 49% | Training loss: 0.6895393109747342
Epoch: 13 | Iteration number: [290/565] 51% | Training loss: 0.6894670883129383
Epoch: 13 | Iteration number: [300/565] 53% | Training loss: 0.6893935420115789
Epoch: 13 | Iteration number: [310/565] 54% | Training loss: 0.6893130079392464
Epoch: 13 | Iteration number: [320/565] 56% | Training loss: 0.6892444550991058
Epoch: 13 | Iteration number: [330/565] 58% | Training loss: 0.689172315416914
Epoch: 13 | Iteration number: [340/565] 60% | Training loss: 0.6891146665110307
Epoch: 13 | Iteration number: [350/565] 61% | Training loss: 0.6890599857057844
Epoch: 13 | Iteration number: [360/565] 63% | Training loss: 0.6890015545818541
Epoch: 13 | Iteration number: [370/565] 65% | Training loss: 0.6889500039654809
Epoch: 13 | Iteration number: [380/565] 67% | Training loss: 0.6889062230524264
Epoch: 13 | Iteration number: [390/565] 69% | Training loss: 0.6888646993881616
Epoch: 13 | Iteration number: [400/565] 70% | Training loss: 0.6888210615515709
Epoch: 13 | Iteration number: [410/565] 72% | Training loss: 0.6887796817756281
Epoch: 13 | Iteration number: [420/565] 74% | Training loss: 0.6887405694950195
Epoch: 13 | Iteration number: [430/565] 76% | Training loss: 0.6886971012104389
Epoch: 13 | Iteration number: [440/565] 77% | Training loss: 0.6886594483798201
Epoch: 13 | Iteration number: [450/565] 79% | Training loss: 0.6886327052116394
Epoch: 13 | Iteration number: [460/565] 81% | Training loss: 0.6886047897131546
Epoch: 13 | Iteration number: [470/565] 83% | Training loss: 0.6885692152571171
Epoch: 13 | Iteration number: [480/565] 84% | Training loss: 0.6885327144215504
Epoch: 13 | Iteration number: [490/565] 86% | Training loss: 0.6885083942997212
Epoch: 13 | Iteration number: [500/565] 88% | Training loss: 0.6884778649806976
Epoch: 13 | Iteration number: [510/565] 90% | Training loss: 0.6884509164913027
Epoch: 13 | Iteration number: [520/565] 92% | Training loss: 0.6884281203150749
Epoch: 13 | Iteration number: [530/565] 93% | Training loss: 0.6884038278516733
Epoch: 13 | Iteration number: [540/565] 95% | Training loss: 0.6883894135554631
Epoch: 13 | Iteration number: [550/565] 97% | Training loss: 0.6883683462576433
Epoch: 13 | Iteration number: [560/565] 99% | Training loss: 0.6883544956999166

 End of epoch: 13 | Train Loss: 0.6871256520262862 | Training Time: 89 

 End of epoch: 13 | Eval Loss: 0.6899569375174386 | Evaluating Time: 5 
Epoch: 14 | Iteration number: [10/565] 1% | Training loss: 0.7552635848522187
Epoch: 14 | Iteration number: [20/565] 3% | Training loss: 0.7212370812892914
Epoch: 14 | Iteration number: [30/565] 5% | Training loss: 0.7100200474262237
Epoch: 14 | Iteration number: [40/565] 7% | Training loss: 0.7042804539203644
Epoch: 14 | Iteration number: [50/565] 8% | Training loss: 0.7007998597621917
Epoch: 14 | Iteration number: [60/565] 10% | Training loss: 0.6985408882300059
Epoch: 14 | Iteration number: [70/565] 12% | Training loss: 0.6968945086002349
Epoch: 14 | Iteration number: [80/565] 14% | Training loss: 0.6956376150250435
Epoch: 14 | Iteration number: [90/565] 15% | Training loss: 0.6947221484449174
Epoch: 14 | Iteration number: [100/565] 17% | Training loss: 0.6939993464946747
Epoch: 14 | Iteration number: [110/565] 19% | Training loss: 0.6933779434724288
Epoch: 14 | Iteration number: [120/565] 21% | Training loss: 0.6928652668992679
Epoch: 14 | Iteration number: [130/565] 23% | Training loss: 0.6924244651427636
Epoch: 14 | Iteration number: [140/565] 24% | Training loss: 0.6920614063739776
Epoch: 14 | Iteration number: [150/565] 26% | Training loss: 0.691725035905838
Epoch: 14 | Iteration number: [160/565] 28% | Training loss: 0.6914504040032625
Epoch: 14 | Iteration number: [170/565] 30% | Training loss: 0.6911734086625716
Epoch: 14 | Iteration number: [180/565] 31% | Training loss: 0.690962451034122
Epoch: 14 | Iteration number: [190/565] 33% | Training loss: 0.6907770592915384
Epoch: 14 | Iteration number: [200/565] 35% | Training loss: 0.690600978732109
Epoch: 14 | Iteration number: [210/565] 37% | Training loss: 0.6904364111877623
Epoch: 14 | Iteration number: [220/565] 38% | Training loss: 0.6902743082154881
Epoch: 14 | Iteration number: [230/565] 40% | Training loss: 0.6901187484679014
Epoch: 14 | Iteration number: [240/565] 42% | Training loss: 0.6899878852069378
Epoch: 14 | Iteration number: [250/565] 44% | Training loss: 0.6898783683776856
Epoch: 14 | Iteration number: [260/565] 46% | Training loss: 0.6897729330337965
Epoch: 14 | Iteration number: [270/565] 47% | Training loss: 0.6896765744244611
Epoch: 14 | Iteration number: [280/565] 49% | Training loss: 0.6895833558269909
Epoch: 14 | Iteration number: [290/565] 51% | Training loss: 0.6895054233485255
Epoch: 14 | Iteration number: [300/565] 53% | Training loss: 0.6894285273551941
Epoch: 14 | Iteration number: [310/565] 54% | Training loss: 0.6893371272471643
Epoch: 14 | Iteration number: [320/565] 56% | Training loss: 0.6892763456329704
Epoch: 14 | Iteration number: [330/565] 58% | Training loss: 0.6892109757119959
Epoch: 14 | Iteration number: [340/565] 60% | Training loss: 0.6891399695592768
Epoch: 14 | Iteration number: [350/565] 61% | Training loss: 0.6890707191399166
Epoch: 14 | Iteration number: [360/565] 63% | Training loss: 0.6890220294396082
Epoch: 14 | Iteration number: [370/565] 65% | Training loss: 0.6889592761928971
Epoch: 14 | Iteration number: [380/565] 67% | Training loss: 0.6889100876293685
Epoch: 14 | Iteration number: [390/565] 69% | Training loss: 0.6888715855586223
Epoch: 14 | Iteration number: [400/565] 70% | Training loss: 0.6888219082355499
Epoch: 14 | Iteration number: [410/565] 72% | Training loss: 0.6887781285658116
Epoch: 14 | Iteration number: [420/565] 74% | Training loss: 0.6887279355809802
Epoch: 14 | Iteration number: [430/565] 76% | Training loss: 0.6886912038159925
Epoch: 14 | Iteration number: [440/565] 77% | Training loss: 0.6886530273339965
Epoch: 14 | Iteration number: [450/565] 79% | Training loss: 0.6886141726705763
Epoch: 14 | Iteration number: [460/565] 81% | Training loss: 0.6885777279086734
Epoch: 14 | Iteration number: [470/565] 83% | Training loss: 0.688547136935782
Epoch: 14 | Iteration number: [480/565] 84% | Training loss: 0.6885177823404471
Epoch: 14 | Iteration number: [490/565] 86% | Training loss: 0.6884836185951622
Epoch: 14 | Iteration number: [500/565] 88% | Training loss: 0.6884455671310424
Epoch: 14 | Iteration number: [510/565] 90% | Training loss: 0.6884182423937555
Epoch: 14 | Iteration number: [520/565] 92% | Training loss: 0.6883945281688983
Epoch: 14 | Iteration number: [530/565] 93% | Training loss: 0.6883676351241346
Epoch: 14 | Iteration number: [540/565] 95% | Training loss: 0.6883392763358576
Epoch: 14 | Iteration number: [550/565] 97% | Training loss: 0.6883184129541571
Epoch: 14 | Iteration number: [560/565] 99% | Training loss: 0.6883019602724484

 End of epoch: 14 | Train Loss: 0.6870738455679565 | Training Time: 91 

 End of epoch: 14 | Eval Loss: 0.6903306330953326 | Evaluating Time: 5 
Epoch: 15 | Iteration number: [10/565] 1% | Training loss: 0.7557292819023133
Epoch: 15 | Iteration number: [20/565] 3% | Training loss: 0.7214573740959167
Epoch: 15 | Iteration number: [30/565] 5% | Training loss: 0.7099540452162425
Epoch: 15 | Iteration number: [40/565] 7% | Training loss: 0.7043250516057015
Epoch: 15 | Iteration number: [50/565] 8% | Training loss: 0.7008333647251129
Epoch: 15 | Iteration number: [60/565] 10% | Training loss: 0.6985536148150762
Epoch: 15 | Iteration number: [70/565] 12% | Training loss: 0.6968854938234602
Epoch: 15 | Iteration number: [80/565] 14% | Training loss: 0.6956582292914391
Epoch: 15 | Iteration number: [90/565] 15% | Training loss: 0.6947108785311381
Epoch: 15 | Iteration number: [100/565] 17% | Training loss: 0.6939209258556366
Epoch: 15 | Iteration number: [110/565] 19% | Training loss: 0.6932984964414076
Epoch: 15 | Iteration number: [120/565] 21% | Training loss: 0.692791415254275
Epoch: 15 | Iteration number: [130/565] 23% | Training loss: 0.6923319248052744
Epoch: 15 | Iteration number: [140/565] 24% | Training loss: 0.6919669713292803
Epoch: 15 | Iteration number: [150/565] 26% | Training loss: 0.6916254210472107
Epoch: 15 | Iteration number: [160/565] 28% | Training loss: 0.691350293904543
Epoch: 15 | Iteration number: [170/565] 30% | Training loss: 0.6911218958742479
Epoch: 15 | Iteration number: [180/565] 31% | Training loss: 0.690905189845297
Epoch: 15 | Iteration number: [190/565] 33% | Training loss: 0.6907010232147418
Epoch: 15 | Iteration number: [200/565] 35% | Training loss: 0.6904890501499176
Epoch: 15 | Iteration number: [210/565] 37% | Training loss: 0.6903414204007103
Epoch: 15 | Iteration number: [220/565] 38% | Training loss: 0.6902013556523756
Epoch: 15 | Iteration number: [230/565] 40% | Training loss: 0.6900611569052157
Epoch: 15 | Iteration number: [240/565] 42% | Training loss: 0.6899407962958019
Epoch: 15 | Iteration number: [250/565] 44% | Training loss: 0.6898103713989258
Epoch: 15 | Iteration number: [260/565] 46% | Training loss: 0.689695961200274
Epoch: 15 | Iteration number: [270/565] 47% | Training loss: 0.6895961693039647
Epoch: 15 | Iteration number: [280/565] 49% | Training loss: 0.6894927184496608
Epoch: 15 | Iteration number: [290/565] 51% | Training loss: 0.6894127333986348
Epoch: 15 | Iteration number: [300/565] 53% | Training loss: 0.689328886270523
Epoch: 15 | Iteration number: [310/565] 54% | Training loss: 0.6892544923290129
Epoch: 15 | Iteration number: [320/565] 56% | Training loss: 0.6891801627352834
Epoch: 15 | Iteration number: [330/565] 58% | Training loss: 0.6891143340052981
Epoch: 15 | Iteration number: [340/565] 60% | Training loss: 0.6890427145887824
Epoch: 15 | Iteration number: [350/565] 61% | Training loss: 0.6889811049188886
Epoch: 15 | Iteration number: [360/565] 63% | Training loss: 0.6889416169789102
Epoch: 15 | Iteration number: [370/565] 65% | Training loss: 0.6888900060911436
Epoch: 15 | Iteration number: [380/565] 67% | Training loss: 0.688843904670916
Epoch: 15 | Iteration number: [390/565] 69% | Training loss: 0.688793490636043
Epoch: 15 | Iteration number: [400/565] 70% | Training loss: 0.6887593130767345
Epoch: 15 | Iteration number: [410/565] 72% | Training loss: 0.6887152860804302
Epoch: 15 | Iteration number: [420/565] 74% | Training loss: 0.688664331748372
Epoch: 15 | Iteration number: [430/565] 76% | Training loss: 0.6886337601861289
Epoch: 15 | Iteration number: [440/565] 77% | Training loss: 0.6886089379137212
Epoch: 15 | Iteration number: [450/565] 79% | Training loss: 0.6885691740777757
Epoch: 15 | Iteration number: [460/565] 81% | Training loss: 0.6885370159926621
Epoch: 15 | Iteration number: [470/565] 83% | Training loss: 0.6884959805519023
Epoch: 15 | Iteration number: [480/565] 84% | Training loss: 0.6884743195027113
Epoch: 15 | Iteration number: [490/565] 86% | Training loss: 0.6884459394581464
Epoch: 15 | Iteration number: [500/565] 88% | Training loss: 0.6884115340709687
Epoch: 15 | Iteration number: [510/565] 90% | Training loss: 0.6883936375963922
Epoch: 15 | Iteration number: [520/565] 92% | Training loss: 0.6883592691559058
Epoch: 15 | Iteration number: [530/565] 93% | Training loss: 0.688327122072004
Epoch: 15 | Iteration number: [540/565] 95% | Training loss: 0.6883004993200302
Epoch: 15 | Iteration number: [550/565] 97% | Training loss: 0.6882800878177989
Epoch: 15 | Iteration number: [560/565] 99% | Training loss: 0.688255640225751

 End of epoch: 15 | Train Loss: 0.6870268133889257 | Training Time: 89 

 End of epoch: 15 | Eval Loss: 0.6903709684099469 | Evaluating Time: 5 
Epoch: 16 | Iteration number: [10/565] 1% | Training loss: 0.755749499797821
Epoch: 16 | Iteration number: [20/565] 3% | Training loss: 0.7213894814252854
Epoch: 16 | Iteration number: [30/565] 5% | Training loss: 0.7100108842055003
Epoch: 16 | Iteration number: [40/565] 7% | Training loss: 0.7042797654867172
Epoch: 16 | Iteration number: [50/565] 8% | Training loss: 0.700788836479187
Epoch: 16 | Iteration number: [60/565] 10% | Training loss: 0.6985157648722331
Epoch: 16 | Iteration number: [70/565] 12% | Training loss: 0.6968372634478978
Epoch: 16 | Iteration number: [80/565] 14% | Training loss: 0.6956962391734123
Epoch: 16 | Iteration number: [90/565] 15% | Training loss: 0.6947346097893186
Epoch: 16 | Iteration number: [100/565] 17% | Training loss: 0.6939672619104386
Epoch: 16 | Iteration number: [110/565] 19% | Training loss: 0.6933414708484303
Epoch: 16 | Iteration number: [120/565] 21% | Training loss: 0.6928085560599963
Epoch: 16 | Iteration number: [130/565] 23% | Training loss: 0.6923603282524989
Epoch: 16 | Iteration number: [140/565] 24% | Training loss: 0.6919677202190672
Epoch: 16 | Iteration number: [150/565] 26% | Training loss: 0.6916808140277863
Epoch: 16 | Iteration number: [160/565] 28% | Training loss: 0.691370640695095
Epoch: 16 | Iteration number: [170/565] 30% | Training loss: 0.6911153895013472
Epoch: 16 | Iteration number: [180/565] 31% | Training loss: 0.6908999605311288
Epoch: 16 | Iteration number: [190/565] 33% | Training loss: 0.6907023975723668
Epoch: 16 | Iteration number: [200/565] 35% | Training loss: 0.6905222114920616
Epoch: 16 | Iteration number: [210/565] 37% | Training loss: 0.6903563116277968
Epoch: 16 | Iteration number: [220/565] 38% | Training loss: 0.6902091695503755
Epoch: 16 | Iteration number: [230/565] 40% | Training loss: 0.6900521467561307
Epoch: 16 | Iteration number: [240/565] 42% | Training loss: 0.6899458736181259
Epoch: 16 | Iteration number: [250/565] 44% | Training loss: 0.6898378655910492
Epoch: 16 | Iteration number: [260/565] 46% | Training loss: 0.6897207445823229
Epoch: 16 | Iteration number: [270/565] 47% | Training loss: 0.6896229984583678
Epoch: 16 | Iteration number: [280/565] 49% | Training loss: 0.6895258356417928
Epoch: 16 | Iteration number: [290/565] 51% | Training loss: 0.6894236416652285
Epoch: 16 | Iteration number: [300/565] 53% | Training loss: 0.6893266020218531
Epoch: 16 | Iteration number: [310/565] 54% | Training loss: 0.6892367401430683
Epoch: 16 | Iteration number: [320/565] 56% | Training loss: 0.6891658484935761
Epoch: 16 | Iteration number: [330/565] 58% | Training loss: 0.6890989746108199
Epoch: 16 | Iteration number: [340/565] 60% | Training loss: 0.6890355667647193
Epoch: 16 | Iteration number: [350/565] 61% | Training loss: 0.6889871541091374
Epoch: 16 | Iteration number: [360/565] 63% | Training loss: 0.6889310345053673
Epoch: 16 | Iteration number: [370/565] 65% | Training loss: 0.6888761633151287
Epoch: 16 | Iteration number: [380/565] 67% | Training loss: 0.6888255784386083
Epoch: 16 | Iteration number: [390/565] 69% | Training loss: 0.6887680234053196
Epoch: 16 | Iteration number: [400/565] 70% | Training loss: 0.6887312859296799
Epoch: 16 | Iteration number: [410/565] 72% | Training loss: 0.6886835322147462
Epoch: 16 | Iteration number: [420/565] 74% | Training loss: 0.6886387667485646
Epoch: 16 | Iteration number: [430/565] 76% | Training loss: 0.688610321144725
Epoch: 16 | Iteration number: [440/565] 77% | Training loss: 0.6885849402709441
Epoch: 16 | Iteration number: [450/565] 79% | Training loss: 0.6885458890597026
Epoch: 16 | Iteration number: [460/565] 81% | Training loss: 0.6885205789752629
Epoch: 16 | Iteration number: [470/565] 83% | Training loss: 0.688484853759725
Epoch: 16 | Iteration number: [480/565] 84% | Training loss: 0.6884551667918761
Epoch: 16 | Iteration number: [490/565] 86% | Training loss: 0.6884253986027776
Epoch: 16 | Iteration number: [500/565] 88% | Training loss: 0.6884025491476059
Epoch: 16 | Iteration number: [510/565] 90% | Training loss: 0.6883705709494796
Epoch: 16 | Iteration number: [520/565] 92% | Training loss: 0.688343426814446
Epoch: 16 | Iteration number: [530/565] 93% | Training loss: 0.6883232807213405
Epoch: 16 | Iteration number: [540/565] 95% | Training loss: 0.6882974588208728
Epoch: 16 | Iteration number: [550/565] 97% | Training loss: 0.6882793231443926
Epoch: 16 | Iteration number: [560/565] 99% | Training loss: 0.6882563767688615

 End of epoch: 16 | Train Loss: 0.6870292590782706 | Training Time: 91 

 End of epoch: 16 | Eval Loss: 0.6900310346058437 | Evaluating Time: 5 
Epoch: 17 | Iteration number: [10/565] 1% | Training loss: 0.7556901216506958
Epoch: 17 | Iteration number: [20/565] 3% | Training loss: 0.7212626039981842
Epoch: 17 | Iteration number: [30/565] 5% | Training loss: 0.7098419527212779
Epoch: 17 | Iteration number: [40/565] 7% | Training loss: 0.7040949761867523
Epoch: 17 | Iteration number: [50/565] 8% | Training loss: 0.7006839168071747
Epoch: 17 | Iteration number: [60/565] 10% | Training loss: 0.6983914782603582
Epoch: 17 | Iteration number: [70/565] 12% | Training loss: 0.6967962452343532
Epoch: 17 | Iteration number: [80/565] 14% | Training loss: 0.6956167928874493
Epoch: 17 | Iteration number: [90/565] 15% | Training loss: 0.6946474664741092
Epoch: 17 | Iteration number: [100/565] 17% | Training loss: 0.6939122062921524
Epoch: 17 | Iteration number: [110/565] 19% | Training loss: 0.6932913801886819
Epoch: 17 | Iteration number: [120/565] 21% | Training loss: 0.6927559276421865
Epoch: 17 | Iteration number: [130/565] 23% | Training loss: 0.6923057528642508
Epoch: 17 | Iteration number: [140/565] 24% | Training loss: 0.6919316100222724
Epoch: 17 | Iteration number: [150/565] 26% | Training loss: 0.6916118597984314
Epoch: 17 | Iteration number: [160/565] 28% | Training loss: 0.691315657645464
Epoch: 17 | Iteration number: [170/565] 30% | Training loss: 0.6910556705559001
Epoch: 17 | Iteration number: [180/565] 31% | Training loss: 0.690826251771715
Epoch: 17 | Iteration number: [190/565] 33% | Training loss: 0.690640831307361
Epoch: 17 | Iteration number: [200/565] 35% | Training loss: 0.6904328262805939
Epoch: 17 | Iteration number: [210/565] 37% | Training loss: 0.6902883705638704
Epoch: 17 | Iteration number: [220/565] 38% | Training loss: 0.6901533015749671
Epoch: 17 | Iteration number: [230/565] 40% | Training loss: 0.6899937743725983
Epoch: 17 | Iteration number: [240/565] 42% | Training loss: 0.6898599964876969
Epoch: 17 | Iteration number: [250/565] 44% | Training loss: 0.6897476937770843
Epoch: 17 | Iteration number: [260/565] 46% | Training loss: 0.6896342465510735
Epoch: 17 | Iteration number: [270/565] 47% | Training loss: 0.6895253759843332
Epoch: 17 | Iteration number: [280/565] 49% | Training loss: 0.6894312024116516
Epoch: 17 | Iteration number: [290/565] 51% | Training loss: 0.6893515644402339
Epoch: 17 | Iteration number: [300/565] 53% | Training loss: 0.689274325966835
Epoch: 17 | Iteration number: [310/565] 54% | Training loss: 0.6891990144406596
Epoch: 17 | Iteration number: [320/565] 56% | Training loss: 0.6891316877678036
Epoch: 17 | Iteration number: [330/565] 58% | Training loss: 0.6890751800753854
Epoch: 17 | Iteration number: [340/565] 60% | Training loss: 0.6890262284699609
Epoch: 17 | Iteration number: [350/565] 61% | Training loss: 0.6889640016215188
Epoch: 17 | Iteration number: [360/565] 63% | Training loss: 0.6889181502991253
Epoch: 17 | Iteration number: [370/565] 65% | Training loss: 0.6888848892740301
Epoch: 17 | Iteration number: [380/565] 67% | Training loss: 0.6888261627209814
Epoch: 17 | Iteration number: [390/565] 69% | Training loss: 0.6887724090845156
Epoch: 17 | Iteration number: [400/565] 70% | Training loss: 0.6887274610996247
Epoch: 17 | Iteration number: [410/565] 72% | Training loss: 0.6886811220064396
Epoch: 17 | Iteration number: [420/565] 74% | Training loss: 0.6886419790131705
Epoch: 17 | Iteration number: [430/565] 76% | Training loss: 0.6886036603949791
Epoch: 17 | Iteration number: [440/565] 77% | Training loss: 0.6885650424794717
Epoch: 17 | Iteration number: [450/565] 79% | Training loss: 0.6885354664590624
Epoch: 17 | Iteration number: [460/565] 81% | Training loss: 0.6885000638339831
Epoch: 17 | Iteration number: [470/565] 83% | Training loss: 0.6884667326795294
Epoch: 17 | Iteration number: [480/565] 84% | Training loss: 0.6884306562443574
Epoch: 17 | Iteration number: [490/565] 86% | Training loss: 0.6883936997579069
Epoch: 17 | Iteration number: [500/565] 88% | Training loss: 0.6883703309297562
Epoch: 17 | Iteration number: [510/565] 90% | Training loss: 0.6883287866910298
Epoch: 17 | Iteration number: [520/565] 92% | Training loss: 0.6883017782981579
Epoch: 17 | Iteration number: [530/565] 93% | Training loss: 0.6882772880905079
Epoch: 17 | Iteration number: [540/565] 95% | Training loss: 0.688260249959098
Epoch: 17 | Iteration number: [550/565] 97% | Training loss: 0.6882362992113287
Epoch: 17 | Iteration number: [560/565] 99% | Training loss: 0.6882186707641397

 End of epoch: 17 | Train Loss: 0.6869923621152354 | Training Time: 90 

 End of epoch: 17 | Eval Loss: 0.6904473049300057 | Evaluating Time: 6 
Epoch: 18 | Iteration number: [10/565] 1% | Training loss: 0.7557740807533264
Epoch: 18 | Iteration number: [20/565] 3% | Training loss: 0.7212408185005188
Epoch: 18 | Iteration number: [30/565] 5% | Training loss: 0.7097166379292806
Epoch: 18 | Iteration number: [40/565] 7% | Training loss: 0.7040888085961342
Epoch: 18 | Iteration number: [50/565] 8% | Training loss: 0.7006933069229127
Epoch: 18 | Iteration number: [60/565] 10% | Training loss: 0.6983806222677231
Epoch: 18 | Iteration number: [70/565] 12% | Training loss: 0.696771536554609
Epoch: 18 | Iteration number: [80/565] 14% | Training loss: 0.6955193616449833
Epoch: 18 | Iteration number: [90/565] 15% | Training loss: 0.6945585303836399
Epoch: 18 | Iteration number: [100/565] 17% | Training loss: 0.693792895078659
Epoch: 18 | Iteration number: [110/565] 19% | Training loss: 0.6932002994147214
Epoch: 18 | Iteration number: [120/565] 21% | Training loss: 0.6926617314418156
Epoch: 18 | Iteration number: [130/565] 23% | Training loss: 0.6922375082969665
Epoch: 18 | Iteration number: [140/565] 24% | Training loss: 0.6918679262910571
Epoch: 18 | Iteration number: [150/565] 26% | Training loss: 0.6915533006191253
Epoch: 18 | Iteration number: [160/565] 28% | Training loss: 0.6912593822926283
Epoch: 18 | Iteration number: [170/565] 30% | Training loss: 0.6909893674008987
Epoch: 18 | Iteration number: [180/565] 31% | Training loss: 0.6907674640417099
Epoch: 18 | Iteration number: [190/565] 33% | Training loss: 0.6905721416598872
Epoch: 18 | Iteration number: [200/565] 35% | Training loss: 0.6904087996482849
Epoch: 18 | Iteration number: [210/565] 37% | Training loss: 0.6902572390579041
Epoch: 18 | Iteration number: [220/565] 38% | Training loss: 0.6901219679550691
Epoch: 18 | Iteration number: [230/565] 40% | Training loss: 0.6899871027987936
Epoch: 18 | Iteration number: [240/565] 42% | Training loss: 0.6898686304688454
Epoch: 18 | Iteration number: [250/565] 44% | Training loss: 0.6897513942718506
Epoch: 18 | Iteration number: [260/565] 46% | Training loss: 0.6896538936174833
Epoch: 18 | Iteration number: [270/565] 47% | Training loss: 0.6895556606628277
Epoch: 18 | Iteration number: [280/565] 49% | Training loss: 0.6894698685833386
Epoch: 18 | Iteration number: [290/565] 51% | Training loss: 0.6893950809692514
Epoch: 18 | Iteration number: [300/565] 53% | Training loss: 0.6893093872070313
Epoch: 18 | Iteration number: [310/565] 54% | Training loss: 0.689245415695252
Epoch: 18 | Iteration number: [320/565] 56% | Training loss: 0.6891629954800009
Epoch: 18 | Iteration number: [330/565] 58% | Training loss: 0.6890951830329317
Epoch: 18 | Iteration number: [340/565] 60% | Training loss: 0.6890352378873265
Epoch: 18 | Iteration number: [350/565] 61% | Training loss: 0.6889649430343083
Epoch: 18 | Iteration number: [360/565] 63% | Training loss: 0.6889074464639028
Epoch: 18 | Iteration number: [370/565] 65% | Training loss: 0.688856798249322
Epoch: 18 | Iteration number: [380/565] 67% | Training loss: 0.6888129927610096
Epoch: 18 | Iteration number: [390/565] 69% | Training loss: 0.6887803945785914
Epoch: 18 | Iteration number: [400/565] 70% | Training loss: 0.6887340526282787
Epoch: 18 | Iteration number: [410/565] 72% | Training loss: 0.6886855390013717
Epoch: 18 | Iteration number: [420/565] 74% | Training loss: 0.6886454810698827
Epoch: 18 | Iteration number: [430/565] 76% | Training loss: 0.6886162609555001
Epoch: 18 | Iteration number: [440/565] 77% | Training loss: 0.6885737085884268
Epoch: 18 | Iteration number: [450/565] 79% | Training loss: 0.6885311280356513
Epoch: 18 | Iteration number: [460/565] 81% | Training loss: 0.6884959705497907
Epoch: 18 | Iteration number: [470/565] 83% | Training loss: 0.6884606107752373
Epoch: 18 | Iteration number: [480/565] 84% | Training loss: 0.6884311163177093
Epoch: 18 | Iteration number: [490/565] 86% | Training loss: 0.6883972571820629
Epoch: 18 | Iteration number: [500/565] 88% | Training loss: 0.6883701548576355
Epoch: 18 | Iteration number: [510/565] 90% | Training loss: 0.6883406487165713
Epoch: 18 | Iteration number: [520/565] 92% | Training loss: 0.6883097366644786
Epoch: 18 | Iteration number: [530/565] 93% | Training loss: 0.6882905022153315
Epoch: 18 | Iteration number: [540/565] 95% | Training loss: 0.6882728451931918
Epoch: 18 | Iteration number: [550/565] 97% | Training loss: 0.688254007101059
Epoch: 18 | Iteration number: [560/565] 99% | Training loss: 0.6882343024015427

 End of epoch: 18 | Train Loss: 0.6870102649241422 | Training Time: 90 

 End of epoch: 18 | Eval Loss: 0.6901865260941642 | Evaluating Time: 6 
Epoch: 19 | Iteration number: [10/565] 1% | Training loss: 0.755575692653656
Epoch: 19 | Iteration number: [20/565] 3% | Training loss: 0.7213721066713333
Epoch: 19 | Iteration number: [30/565] 5% | Training loss: 0.7099573095639546
Epoch: 19 | Iteration number: [40/565] 7% | Training loss: 0.7041280210018158
Epoch: 19 | Iteration number: [50/565] 8% | Training loss: 0.7007809150218963
Epoch: 19 | Iteration number: [60/565] 10% | Training loss: 0.6984756877024968
Epoch: 19 | Iteration number: [70/565] 12% | Training loss: 0.6967683460031237
Epoch: 19 | Iteration number: [80/565] 14% | Training loss: 0.6955614760518074
Epoch: 19 | Iteration number: [90/565] 15% | Training loss: 0.6946043570836385
Epoch: 19 | Iteration number: [100/565] 17% | Training loss: 0.6938194888830185
Epoch: 19 | Iteration number: [110/565] 19% | Training loss: 0.6931711489504034
Epoch: 19 | Iteration number: [120/565] 21% | Training loss: 0.6926504025856653
Epoch: 19 | Iteration number: [130/565] 23% | Training loss: 0.6922084730405074
Epoch: 19 | Iteration number: [140/565] 24% | Training loss: 0.6918442755937576
Epoch: 19 | Iteration number: [150/565] 26% | Training loss: 0.6915360049406687
Epoch: 19 | Iteration number: [160/565] 28% | Training loss: 0.6912752240896225
Epoch: 19 | Iteration number: [170/565] 30% | Training loss: 0.6910175863434287
Epoch: 19 | Iteration number: [180/565] 31% | Training loss: 0.6907771246300803
Epoch: 19 | Iteration number: [190/565] 33% | Training loss: 0.6905771804483314
Epoch: 19 | Iteration number: [200/565] 35% | Training loss: 0.6903833624720573
Epoch: 19 | Iteration number: [210/565] 37% | Training loss: 0.6902236024538676
Epoch: 19 | Iteration number: [220/565] 38% | Training loss: 0.6900639951229095
Epoch: 19 | Iteration number: [230/565] 40% | Training loss: 0.6899316912112029
Epoch: 19 | Iteration number: [240/565] 42% | Training loss: 0.6897828817367554
Epoch: 19 | Iteration number: [250/565] 44% | Training loss: 0.6896800456047059
Epoch: 19 | Iteration number: [260/565] 46% | Training loss: 0.6895805828846417
Epoch: 19 | Iteration number: [270/565] 47% | Training loss: 0.6894904240413948
Epoch: 19 | Iteration number: [280/565] 49% | Training loss: 0.6893962419458798
Epoch: 19 | Iteration number: [290/565] 51% | Training loss: 0.6893069248774956
Epoch: 19 | Iteration number: [300/565] 53% | Training loss: 0.6892319738864898
Epoch: 19 | Iteration number: [310/565] 54% | Training loss: 0.6891594875243402
Epoch: 19 | Iteration number: [320/565] 56% | Training loss: 0.689099770411849
Epoch: 19 | Iteration number: [330/565] 58% | Training loss: 0.6890519859212818
Epoch: 19 | Iteration number: [340/565] 60% | Training loss: 0.6889863249133615
Epoch: 19 | Iteration number: [350/565] 61% | Training loss: 0.6889294738428934
Epoch: 19 | Iteration number: [360/565] 63% | Training loss: 0.6888687617248959
Epoch: 19 | Iteration number: [370/565] 65% | Training loss: 0.6888224822443885
Epoch: 19 | Iteration number: [380/565] 67% | Training loss: 0.6887764588782662
Epoch: 19 | Iteration number: [390/565] 69% | Training loss: 0.6887333909670512
Epoch: 19 | Iteration number: [400/565] 70% | Training loss: 0.6886887438595295
Epoch: 19 | Iteration number: [410/565] 72% | Training loss: 0.688653499905656
Epoch: 19 | Iteration number: [420/565] 74% | Training loss: 0.6886229292267845
Epoch: 19 | Iteration number: [430/565] 76% | Training loss: 0.6885860440342926
Epoch: 19 | Iteration number: [440/565] 77% | Training loss: 0.6885533607818863
Epoch: 19 | Iteration number: [450/565] 79% | Training loss: 0.6885168148411644
Epoch: 19 | Iteration number: [460/565] 81% | Training loss: 0.6884821788124417
Epoch: 19 | Iteration number: [470/565] 83% | Training loss: 0.6884492450572075
Epoch: 19 | Iteration number: [480/565] 84% | Training loss: 0.6884128741919995
Epoch: 19 | Iteration number: [490/565] 86% | Training loss: 0.6883839042819276
Epoch: 19 | Iteration number: [500/565] 88% | Training loss: 0.688353578209877
Epoch: 19 | Iteration number: [510/565] 90% | Training loss: 0.6883271009314293
Epoch: 19 | Iteration number: [520/565] 92% | Training loss: 0.688294185583408
Epoch: 19 | Iteration number: [530/565] 93% | Training loss: 0.6882676346122094
Epoch: 19 | Iteration number: [540/565] 95% | Training loss: 0.688246782179232
Epoch: 19 | Iteration number: [550/565] 97% | Training loss: 0.6882326031814922
Epoch: 19 | Iteration number: [560/565] 99% | Training loss: 0.6882064417004585

 End of epoch: 19 | Train Loss: 0.6869789117205459 | Training Time: 91 

 End of epoch: 19 | Eval Loss: 0.6906419140951974 | Evaluating Time: 6 
Epoch: 20 | Iteration number: [10/565] 1% | Training loss: 0.7555334806442261
Epoch: 20 | Iteration number: [20/565] 3% | Training loss: 0.7213250368833541
Epoch: 20 | Iteration number: [30/565] 5% | Training loss: 0.7097841262817383
Epoch: 20 | Iteration number: [40/565] 7% | Training loss: 0.704028294980526
Epoch: 20 | Iteration number: [50/565] 8% | Training loss: 0.7006270885467529
Epoch: 20 | Iteration number: [60/565] 10% | Training loss: 0.6983900338411331
Epoch: 20 | Iteration number: [70/565] 12% | Training loss: 0.6967408418655395
Epoch: 20 | Iteration number: [80/565] 14% | Training loss: 0.6955448113381862
Epoch: 20 | Iteration number: [90/565] 15% | Training loss: 0.6945973919497596
Epoch: 20 | Iteration number: [100/565] 17% | Training loss: 0.6938053178787231
Epoch: 20 | Iteration number: [110/565] 19% | Training loss: 0.6932439256798137
Epoch: 20 | Iteration number: [120/565] 21% | Training loss: 0.6927535519003868
Epoch: 20 | Iteration number: [130/565] 23% | Training loss: 0.6923177595321949
Epoch: 20 | Iteration number: [140/565] 24% | Training loss: 0.6919158488512039
Epoch: 20 | Iteration number: [150/565] 26% | Training loss: 0.6916035954157511
Epoch: 20 | Iteration number: [160/565] 28% | Training loss: 0.6913284480571746
Epoch: 20 | Iteration number: [170/565] 30% | Training loss: 0.6910538662882412
Epoch: 20 | Iteration number: [180/565] 31% | Training loss: 0.6908261093828413
Epoch: 20 | Iteration number: [190/565] 33% | Training loss: 0.6906213716456765
Epoch: 20 | Iteration number: [200/565] 35% | Training loss: 0.6904653996229172
Epoch: 20 | Iteration number: [210/565] 37% | Training loss: 0.6902986424309867
Epoch: 20 | Iteration number: [220/565] 38% | Training loss: 0.6901341619816693
Epoch: 20 | Iteration number: [230/565] 40% | Training loss: 0.6900104859600896
Epoch: 20 | Iteration number: [240/565] 42% | Training loss: 0.6898835157354672
Epoch: 20 | Iteration number: [250/565] 44% | Training loss: 0.6897605829238892
Epoch: 20 | Iteration number: [260/565] 46% | Training loss: 0.6896391430726418
Epoch: 20 | Iteration number: [270/565] 47% | Training loss: 0.6895360098944769
Epoch: 20 | Iteration number: [280/565] 49% | Training loss: 0.6894654559237616
Epoch: 20 | Iteration number: [290/565] 51% | Training loss: 0.6893862208415722
Epoch: 20 | Iteration number: [300/565] 53% | Training loss: 0.6892965805530548
Epoch: 20 | Iteration number: [310/565] 54% | Training loss: 0.6892314464815201
Epoch: 20 | Iteration number: [320/565] 56% | Training loss: 0.6891661604866386
Epoch: 20 | Iteration number: [330/565] 58% | Training loss: 0.6890896332986427
Epoch: 20 | Iteration number: [340/565] 60% | Training loss: 0.6890426721642999
Epoch: 20 | Iteration number: [350/565] 61% | Training loss: 0.6889810989584242
Epoch: 20 | Iteration number: [360/565] 63% | Training loss: 0.6889277579055892
Epoch: 20 | Iteration number: [370/565] 65% | Training loss: 0.6888701762702014
Epoch: 20 | Iteration number: [380/565] 67% | Training loss: 0.6888201644546107
Epoch: 20 | Iteration number: [390/565] 69% | Training loss: 0.6887705399439885
Epoch: 20 | Iteration number: [400/565] 70% | Training loss: 0.6887246809899807
Epoch: 20 | Iteration number: [410/565] 72% | Training loss: 0.6886819915073674
Epoch: 20 | Iteration number: [420/565] 74% | Training loss: 0.688646042630786
Epoch: 20 | Iteration number: [430/565] 76% | Training loss: 0.6886091018832007
Epoch: 20 | Iteration number: [440/565] 77% | Training loss: 0.6885673621838743
Epoch: 20 | Iteration number: [450/565] 79% | Training loss: 0.6885379931661818
Epoch: 20 | Iteration number: [460/565] 81% | Training loss: 0.6885008372690367
Epoch: 20 | Iteration number: [470/565] 83% | Training loss: 0.6884657187664762
Epoch: 20 | Iteration number: [480/565] 84% | Training loss: 0.6884321593989928
Epoch: 20 | Iteration number: [490/565] 86% | Training loss: 0.688406566697724
Epoch: 20 | Iteration number: [500/565] 88% | Training loss: 0.6883731588125229
Epoch: 20 | Iteration number: [510/565] 90% | Training loss: 0.6883330055311614
Epoch: 20 | Iteration number: [520/565] 92% | Training loss: 0.6883010408053032
Epoch: 20 | Iteration number: [530/565] 93% | Training loss: 0.6882781020875247
Epoch: 20 | Iteration number: [540/565] 95% | Training loss: 0.6882612453566657
Epoch: 20 | Iteration number: [550/565] 97% | Training loss: 0.6882407013936477
Epoch: 20 | Iteration number: [560/565] 99% | Training loss: 0.6882252852831569

 End of epoch: 20 | Train Loss: 0.6869948552773062 | Training Time: 90 

 End of epoch: 20 | Eval Loss: 0.6899156825883048 | Evaluating Time: 6 
Epoch: 21 | Iteration number: [10/565] 1% | Training loss: 0.7556657135486603
Epoch: 21 | Iteration number: [20/565] 3% | Training loss: 0.7215214669704437
Epoch: 21 | Iteration number: [30/565] 5% | Training loss: 0.7099895815054575
Epoch: 21 | Iteration number: [40/565] 7% | Training loss: 0.7042332336306572
Epoch: 21 | Iteration number: [50/565] 8% | Training loss: 0.70074298620224
Epoch: 21 | Iteration number: [60/565] 10% | Training loss: 0.6984486639499664
Epoch: 21 | Iteration number: [70/565] 12% | Training loss: 0.6968053357941764
Epoch: 21 | Iteration number: [80/565] 14% | Training loss: 0.69560701623559
Epoch: 21 | Iteration number: [90/565] 15% | Training loss: 0.6946629736158583
Epoch: 21 | Iteration number: [100/565] 17% | Training loss: 0.6938938295841217
Epoch: 21 | Iteration number: [110/565] 19% | Training loss: 0.6932603028687564
Epoch: 21 | Iteration number: [120/565] 21% | Training loss: 0.6926991139849027
Epoch: 21 | Iteration number: [130/565] 23% | Training loss: 0.6922341021207663
Epoch: 21 | Iteration number: [140/565] 24% | Training loss: 0.691862707904407
Epoch: 21 | Iteration number: [150/565] 26% | Training loss: 0.6915126613775889
Epoch: 21 | Iteration number: [160/565] 28% | Training loss: 0.6912283409386873
Epoch: 21 | Iteration number: [170/565] 30% | Training loss: 0.690937074843575
Epoch: 21 | Iteration number: [180/565] 31% | Training loss: 0.6907282842530145
Epoch: 21 | Iteration number: [190/565] 33% | Training loss: 0.6905520385817477
Epoch: 21 | Iteration number: [200/565] 35% | Training loss: 0.6903697615861892
Epoch: 21 | Iteration number: [210/565] 37% | Training loss: 0.6902147826694307
Epoch: 21 | Iteration number: [220/565] 38% | Training loss: 0.6900892157446255
Epoch: 21 | Iteration number: [230/565] 40% | Training loss: 0.6899542492368947
Epoch: 21 | Iteration number: [240/565] 42% | Training loss: 0.6898330554366112
Epoch: 21 | Iteration number: [250/565] 44% | Training loss: 0.6897048466205596
Epoch: 21 | Iteration number: [260/565] 46% | Training loss: 0.6895923144542254
Epoch: 21 | Iteration number: [270/565] 47% | Training loss: 0.6894874771436056
Epoch: 21 | Iteration number: [280/565] 49% | Training loss: 0.6893889708178383
Epoch: 21 | Iteration number: [290/565] 51% | Training loss: 0.6893023176439877
Epoch: 21 | Iteration number: [300/565] 53% | Training loss: 0.6892220781246821
Epoch: 21 | Iteration number: [310/565] 54% | Training loss: 0.6891577462996206
Epoch: 21 | Iteration number: [320/565] 56% | Training loss: 0.6890914477407932
Epoch: 21 | Iteration number: [330/565] 58% | Training loss: 0.6890215729222153
Epoch: 21 | Iteration number: [340/565] 60% | Training loss: 0.6889493209474227
Epoch: 21 | Iteration number: [350/565] 61% | Training loss: 0.6888920783996582
Epoch: 21 | Iteration number: [360/565] 63% | Training loss: 0.6888332252701124
Epoch: 21 | Iteration number: [370/565] 65% | Training loss: 0.6887897188599045
Epoch: 21 | Iteration number: [380/565] 67% | Training loss: 0.6887621037269893
Epoch: 21 | Iteration number: [390/565] 69% | Training loss: 0.688700890693909
Epoch: 21 | Iteration number: [400/565] 70% | Training loss: 0.6886538523435592
Epoch: 21 | Iteration number: [410/565] 72% | Training loss: 0.6886122203454739
Epoch: 21 | Iteration number: [420/565] 74% | Training loss: 0.6885753048317773
Epoch: 21 | Iteration number: [430/565] 76% | Training loss: 0.6885293009669282
Epoch: 21 | Iteration number: [440/565] 77% | Training loss: 0.6885034971616485
Epoch: 21 | Iteration number: [450/565] 79% | Training loss: 0.6884672163592445
Epoch: 21 | Iteration number: [460/565] 81% | Training loss: 0.6884319931268692
Epoch: 21 | Iteration number: [470/565] 83% | Training loss: 0.6883902137583875
Epoch: 21 | Iteration number: [480/565] 84% | Training loss: 0.6883578069508076
Epoch: 21 | Iteration number: [490/565] 86% | Training loss: 0.6883282588452709
Epoch: 21 | Iteration number: [500/565] 88% | Training loss: 0.6883017932176589
Epoch: 21 | Iteration number: [510/565] 90% | Training loss: 0.6882735710518033
Epoch: 21 | Iteration number: [520/565] 92% | Training loss: 0.6882544498030956
Epoch: 21 | Iteration number: [530/565] 93% | Training loss: 0.6882372312950638
Epoch: 21 | Iteration number: [540/565] 95% | Training loss: 0.6882098883390426
Epoch: 21 | Iteration number: [550/565] 97% | Training loss: 0.6881913055073131
Epoch: 21 | Iteration number: [560/565] 99% | Training loss: 0.6881700323096344

 End of epoch: 21 | Train Loss: 0.6869488215024493 | Training Time: 90 

 End of epoch: 21 | Eval Loss: 0.6902762821742466 | Evaluating Time: 6 
Epoch: 22 | Iteration number: [10/565] 1% | Training loss: 0.7554707229137421
Epoch: 22 | Iteration number: [20/565] 3% | Training loss: 0.7211378335952758
Epoch: 22 | Iteration number: [30/565] 5% | Training loss: 0.7097438434759776
Epoch: 22 | Iteration number: [40/565] 7% | Training loss: 0.7039877116680145
Epoch: 22 | Iteration number: [50/565] 8% | Training loss: 0.7006492793560029
Epoch: 22 | Iteration number: [60/565] 10% | Training loss: 0.6982959429423015
Epoch: 22 | Iteration number: [70/565] 12% | Training loss: 0.6966428296906607
Epoch: 22 | Iteration number: [80/565] 14% | Training loss: 0.6954125359654426
Epoch: 22 | Iteration number: [90/565] 15% | Training loss: 0.6944337328275044
Epoch: 22 | Iteration number: [100/565] 17% | Training loss: 0.6936688667535782
Epoch: 22 | Iteration number: [110/565] 19% | Training loss: 0.6931014494462446
Epoch: 22 | Iteration number: [120/565] 21% | Training loss: 0.6925508012374242
Epoch: 22 | Iteration number: [130/565] 23% | Training loss: 0.6920539521254025
Epoch: 22 | Iteration number: [140/565] 24% | Training loss: 0.691680200610842
Epoch: 22 | Iteration number: [150/565] 26% | Training loss: 0.6913334143161773
Epoch: 22 | Iteration number: [160/565] 28% | Training loss: 0.6910836193710566
Epoch: 22 | Iteration number: [170/565] 30% | Training loss: 0.6908482719870175
Epoch: 22 | Iteration number: [180/565] 31% | Training loss: 0.690644998020596
Epoch: 22 | Iteration number: [190/565] 33% | Training loss: 0.6904540796028941
Epoch: 22 | Iteration number: [200/565] 35% | Training loss: 0.6902559226751328
Epoch: 22 | Iteration number: [210/565] 37% | Training loss: 0.6900786615553356
Epoch: 22 | Iteration number: [220/565] 38% | Training loss: 0.689913706887852
Epoch: 22 | Iteration number: [230/565] 40% | Training loss: 0.6897809331831725
Epoch: 22 | Iteration number: [240/565] 42% | Training loss: 0.6896652554472288
Epoch: 22 | Iteration number: [250/565] 44% | Training loss: 0.6895826947689057
Epoch: 22 | Iteration number: [260/565] 46% | Training loss: 0.6894902974367142
Epoch: 22 | Iteration number: [270/565] 47% | Training loss: 0.6893872945396988
Epoch: 22 | Iteration number: [280/565] 49% | Training loss: 0.6893089656318937
Epoch: 22 | Iteration number: [290/565] 51% | Training loss: 0.6892368333093051
Epoch: 22 | Iteration number: [300/565] 53% | Training loss: 0.6891720845301946
Epoch: 22 | Iteration number: [310/565] 54% | Training loss: 0.68910049642286
Epoch: 22 | Iteration number: [320/565] 56% | Training loss: 0.6890362618491054
Epoch: 22 | Iteration number: [330/565] 58% | Training loss: 0.6889862176143762
Epoch: 22 | Iteration number: [340/565] 60% | Training loss: 0.6889323483495151
Epoch: 22 | Iteration number: [350/565] 61% | Training loss: 0.6888813429219383
Epoch: 22 | Iteration number: [360/565] 63% | Training loss: 0.688826269739204
Epoch: 22 | Iteration number: [370/565] 65% | Training loss: 0.6887941697159329
Epoch: 22 | Iteration number: [380/565] 67% | Training loss: 0.6887321349821592
Epoch: 22 | Iteration number: [390/565] 69% | Training loss: 0.6886786827674278
Epoch: 22 | Iteration number: [400/565] 70% | Training loss: 0.6886393961310386
Epoch: 22 | Iteration number: [410/565] 72% | Training loss: 0.6885892295255893
Epoch: 22 | Iteration number: [420/565] 74% | Training loss: 0.6885520194258009
Epoch: 22 | Iteration number: [430/565] 76% | Training loss: 0.6885167695755182
Epoch: 22 | Iteration number: [440/565] 77% | Training loss: 0.6884751215577125
Epoch: 22 | Iteration number: [450/565] 79% | Training loss: 0.6884416160318586
Epoch: 22 | Iteration number: [460/565] 81% | Training loss: 0.6884041324905728
Epoch: 22 | Iteration number: [470/565] 83% | Training loss: 0.6883806028264634
Epoch: 22 | Iteration number: [480/565] 84% | Training loss: 0.6883509129285812
Epoch: 22 | Iteration number: [490/565] 86% | Training loss: 0.6883240609752889
Epoch: 22 | Iteration number: [500/565] 88% | Training loss: 0.6883037313222885
Epoch: 22 | Iteration number: [510/565] 90% | Training loss: 0.6882839084840289
Epoch: 22 | Iteration number: [520/565] 92% | Training loss: 0.6882515371992037
Epoch: 22 | Iteration number: [530/565] 93% | Training loss: 0.6882254816451163
Epoch: 22 | Iteration number: [540/565] 95% | Training loss: 0.6882032965068464
Epoch: 22 | Iteration number: [550/565] 97% | Training loss: 0.6881777492436496
Epoch: 22 | Iteration number: [560/565] 99% | Training loss: 0.6881525208907467

 End of epoch: 22 | Train Loss: 0.6869244072289593 | Training Time: 90 

 End of epoch: 22 | Eval Loss: 0.6900940196854728 | Evaluating Time: 6 
Epoch: 23 | Iteration number: [10/565] 1% | Training loss: 0.7558883249759674
Epoch: 23 | Iteration number: [20/565] 3% | Training loss: 0.7214062631130218
Epoch: 23 | Iteration number: [30/565] 5% | Training loss: 0.7098308642705281
Epoch: 23 | Iteration number: [40/565] 7% | Training loss: 0.7041160956025123
Epoch: 23 | Iteration number: [50/565] 8% | Training loss: 0.7005854392051697
Epoch: 23 | Iteration number: [60/565] 10% | Training loss: 0.6982789327700932
Epoch: 23 | Iteration number: [70/565] 12% | Training loss: 0.6967104443481991
Epoch: 23 | Iteration number: [80/565] 14% | Training loss: 0.6955246232450009
Epoch: 23 | Iteration number: [90/565] 15% | Training loss: 0.6945475512080722
Epoch: 23 | Iteration number: [100/565] 17% | Training loss: 0.6937994188070298
Epoch: 23 | Iteration number: [110/565] 19% | Training loss: 0.6931681107391011
Epoch: 23 | Iteration number: [120/565] 21% | Training loss: 0.6926153004169464
Epoch: 23 | Iteration number: [130/565] 23% | Training loss: 0.692203885775346
Epoch: 23 | Iteration number: [140/565] 24% | Training loss: 0.6918304924454007
Epoch: 23 | Iteration number: [150/565] 26% | Training loss: 0.6915437547365825
Epoch: 23 | Iteration number: [160/565] 28% | Training loss: 0.6912532284855842
Epoch: 23 | Iteration number: [170/565] 30% | Training loss: 0.6910039372303907
Epoch: 23 | Iteration number: [180/565] 31% | Training loss: 0.6907583855920367
Epoch: 23 | Iteration number: [190/565] 33% | Training loss: 0.6905661714704413
Epoch: 23 | Iteration number: [200/565] 35% | Training loss: 0.6903835359215736
Epoch: 23 | Iteration number: [210/565] 37% | Training loss: 0.6902134336176373
Epoch: 23 | Iteration number: [220/565] 38% | Training loss: 0.6900512110103261
Epoch: 23 | Iteration number: [230/565] 40% | Training loss: 0.6899245067783024
Epoch: 23 | Iteration number: [240/565] 42% | Training loss: 0.6898007363080978
Epoch: 23 | Iteration number: [250/565] 44% | Training loss: 0.6896924364566803
Epoch: 23 | Iteration number: [260/565] 46% | Training loss: 0.6895927195365612
Epoch: 23 | Iteration number: [270/565] 47% | Training loss: 0.6895120669294287
Epoch: 23 | Iteration number: [280/565] 49% | Training loss: 0.6894069922821863
Epoch: 23 | Iteration number: [290/565] 51% | Training loss: 0.6893156896377431
Epoch: 23 | Iteration number: [300/565] 53% | Training loss: 0.6892457308371862
Epoch: 23 | Iteration number: [310/565] 54% | Training loss: 0.6891622810594498
Epoch: 23 | Iteration number: [320/565] 56% | Training loss: 0.6890743272379041
Epoch: 23 | Iteration number: [330/565] 58% | Training loss: 0.6890049638170185
Epoch: 23 | Iteration number: [340/565] 60% | Training loss: 0.6889451002373415
Epoch: 23 | Iteration number: [350/565] 61% | Training loss: 0.6888807843412672
Epoch: 23 | Iteration number: [360/565] 63% | Training loss: 0.6888214760356479
Epoch: 23 | Iteration number: [370/565] 65% | Training loss: 0.6887763727355648
Epoch: 23 | Iteration number: [380/565] 67% | Training loss: 0.6887212530562752
Epoch: 23 | Iteration number: [390/565] 69% | Training loss: 0.6886788091598413
Epoch: 23 | Iteration number: [400/565] 70% | Training loss: 0.6886416691541671
Epoch: 23 | Iteration number: [410/565] 72% | Training loss: 0.6885988226751002
Epoch: 23 | Iteration number: [420/565] 74% | Training loss: 0.6885528257914952
Epoch: 23 | Iteration number: [430/565] 76% | Training loss: 0.6885169415972954
Epoch: 23 | Iteration number: [440/565] 77% | Training loss: 0.6884911655025049
Epoch: 23 | Iteration number: [450/565] 79% | Training loss: 0.6884596264362335
Epoch: 23 | Iteration number: [460/565] 81% | Training loss: 0.6884345513323079
Epoch: 23 | Iteration number: [470/565] 83% | Training loss: 0.6884159748858594
Epoch: 23 | Iteration number: [480/565] 84% | Training loss: 0.6883857619017363
Epoch: 23 | Iteration number: [490/565] 86% | Training loss: 0.6883433012329803
Epoch: 23 | Iteration number: [500/565] 88% | Training loss: 0.688319078207016
Epoch: 23 | Iteration number: [510/565] 90% | Training loss: 0.688297653315114
Epoch: 23 | Iteration number: [520/565] 92% | Training loss: 0.6882740606482213
Epoch: 23 | Iteration number: [530/565] 93% | Training loss: 0.6882439305197517
Epoch: 23 | Iteration number: [540/565] 95% | Training loss: 0.6882128769600833
Epoch: 23 | Iteration number: [550/565] 97% | Training loss: 0.6881850538470529
Epoch: 23 | Iteration number: [560/565] 99% | Training loss: 0.6881580287856716

 End of epoch: 23 | Train Loss: 0.6869279745405754 | Training Time: 90 

 End of epoch: 23 | Eval Loss: 0.6901553528649467 | Evaluating Time: 6 
Epoch: 24 | Iteration number: [10/565] 1% | Training loss: 0.7556420087814331
Epoch: 24 | Iteration number: [20/565] 3% | Training loss: 0.7212167888879776
Epoch: 24 | Iteration number: [30/565] 5% | Training loss: 0.709590204556783
Epoch: 24 | Iteration number: [40/565] 7% | Training loss: 0.7039435833692551
Epoch: 24 | Iteration number: [50/565] 8% | Training loss: 0.7005673730373383
Epoch: 24 | Iteration number: [60/565] 10% | Training loss: 0.6983041077852249
Epoch: 24 | Iteration number: [70/565] 12% | Training loss: 0.696687240259988
Epoch: 24 | Iteration number: [80/565] 14% | Training loss: 0.6954760402441025
Epoch: 24 | Iteration number: [90/565] 15% | Training loss: 0.6945218662420909
Epoch: 24 | Iteration number: [100/565] 17% | Training loss: 0.6937980580329896
Epoch: 24 | Iteration number: [110/565] 19% | Training loss: 0.6931453022089872
Epoch: 24 | Iteration number: [120/565] 21% | Training loss: 0.692633077998956
Epoch: 24 | Iteration number: [130/565] 23% | Training loss: 0.6922169708288632
Epoch: 24 | Iteration number: [140/565] 24% | Training loss: 0.6918283803122384
Epoch: 24 | Iteration number: [150/565] 26% | Training loss: 0.6914905174573263
Epoch: 24 | Iteration number: [160/565] 28% | Training loss: 0.6912404619157314
Epoch: 24 | Iteration number: [170/565] 30% | Training loss: 0.6909829679657431
Epoch: 24 | Iteration number: [180/565] 31% | Training loss: 0.6907769726382361
Epoch: 24 | Iteration number: [190/565] 33% | Training loss: 0.6905724732499373
Epoch: 24 | Iteration number: [200/565] 35% | Training loss: 0.6903989589214325
Epoch: 24 | Iteration number: [210/565] 37% | Training loss: 0.6902160925524575
Epoch: 24 | Iteration number: [220/565] 38% | Training loss: 0.6900537875565615
Epoch: 24 | Iteration number: [230/565] 40% | Training loss: 0.689934968430063
Epoch: 24 | Iteration number: [240/565] 42% | Training loss: 0.6898060602446398
Epoch: 24 | Iteration number: [250/565] 44% | Training loss: 0.6896977727413177
Epoch: 24 | Iteration number: [260/565] 46% | Training loss: 0.6895910950807425
Epoch: 24 | Iteration number: [270/565] 47% | Training loss: 0.6895071239383133
Epoch: 24 | Iteration number: [280/565] 49% | Training loss: 0.6894164206726211
Epoch: 24 | Iteration number: [290/565] 51% | Training loss: 0.6893210460399759
Epoch: 24 | Iteration number: [300/565] 53% | Training loss: 0.6892514133453369
Epoch: 24 | Iteration number: [310/565] 54% | Training loss: 0.6891785802379731
Epoch: 24 | Iteration number: [320/565] 56% | Training loss: 0.6890886083245278
Epoch: 24 | Iteration number: [330/565] 58% | Training loss: 0.689011520689184
Epoch: 24 | Iteration number: [340/565] 60% | Training loss: 0.6889500158674576
Epoch: 24 | Iteration number: [350/565] 61% | Training loss: 0.6888875789301736
Epoch: 24 | Iteration number: [360/565] 63% | Training loss: 0.6888428428106838
Epoch: 24 | Iteration number: [370/565] 65% | Training loss: 0.6887945851764163
Epoch: 24 | Iteration number: [380/565] 67% | Training loss: 0.6887441042222475
Epoch: 24 | Iteration number: [390/565] 69% | Training loss: 0.6886882951626411
Epoch: 24 | Iteration number: [400/565] 70% | Training loss: 0.688653150498867
Epoch: 24 | Iteration number: [410/565] 72% | Training loss: 0.6886145588828296
Epoch: 24 | Iteration number: [420/565] 74% | Training loss: 0.6885790502741224
Epoch: 24 | Iteration number: [430/565] 76% | Training loss: 0.6885311690873878
Epoch: 24 | Iteration number: [440/565] 77% | Training loss: 0.6885033320296895
Epoch: 24 | Iteration number: [450/565] 79% | Training loss: 0.6884651949670579
Epoch: 24 | Iteration number: [460/565] 81% | Training loss: 0.6884405768435934
Epoch: 24 | Iteration number: [470/565] 83% | Training loss: 0.6884049259601756
Epoch: 24 | Iteration number: [480/565] 84% | Training loss: 0.6883675538003444
Epoch: 24 | Iteration number: [490/565] 86% | Training loss: 0.6883312738671594
Epoch: 24 | Iteration number: [500/565] 88% | Training loss: 0.6883016330003738
Epoch: 24 | Iteration number: [510/565] 90% | Training loss: 0.6882737037013559
Epoch: 24 | Iteration number: [520/565] 92% | Training loss: 0.6882516213334524
Epoch: 24 | Iteration number: [530/565] 93% | Training loss: 0.6882215655074929
Epoch: 24 | Iteration number: [540/565] 95% | Training loss: 0.6881988135752855
Epoch: 24 | Iteration number: [550/565] 97% | Training loss: 0.6881818547032096
Epoch: 24 | Iteration number: [560/565] 99% | Training loss: 0.6881567807069846

 End of epoch: 24 | Train Loss: 0.6869280506024319 | Training Time: 89 

 End of epoch: 24 | Eval Loss: 0.6903838089534214 | Evaluating Time: 6 
Epoch: 25 | Iteration number: [10/565] 1% | Training loss: 0.7556039690971375
Epoch: 25 | Iteration number: [20/565] 3% | Training loss: 0.7214636415243149
Epoch: 25 | Iteration number: [30/565] 5% | Training loss: 0.7100915511449178
Epoch: 25 | Iteration number: [40/565] 7% | Training loss: 0.7044112384319305
Epoch: 25 | Iteration number: [50/565] 8% | Training loss: 0.7010158550739288
Epoch: 25 | Iteration number: [60/565] 10% | Training loss: 0.6986305862665176
Epoch: 25 | Iteration number: [70/565] 12% | Training loss: 0.6969745763710566
Epoch: 25 | Iteration number: [80/565] 14% | Training loss: 0.6957489594817161
Epoch: 25 | Iteration number: [90/565] 15% | Training loss: 0.694724307457606
Epoch: 25 | Iteration number: [100/565] 17% | Training loss: 0.6939212173223496
Epoch: 25 | Iteration number: [110/565] 19% | Training loss: 0.6932501668279821
Epoch: 25 | Iteration number: [120/565] 21% | Training loss: 0.6926931415994962
Epoch: 25 | Iteration number: [130/565] 23% | Training loss: 0.6922439153377826
Epoch: 25 | Iteration number: [140/565] 24% | Training loss: 0.6918513140508107
Epoch: 25 | Iteration number: [150/565] 26% | Training loss: 0.6915247845649719
Epoch: 25 | Iteration number: [160/565] 28% | Training loss: 0.6912534605711699
Epoch: 25 | Iteration number: [170/565] 30% | Training loss: 0.6910023447345285
Epoch: 25 | Iteration number: [180/565] 31% | Training loss: 0.6907752109898462
Epoch: 25 | Iteration number: [190/565] 33% | Training loss: 0.6905750403278752
Epoch: 25 | Iteration number: [200/565] 35% | Training loss: 0.6903858569264412
Epoch: 25 | Iteration number: [210/565] 37% | Training loss: 0.6902223865191142
Epoch: 25 | Iteration number: [220/565] 38% | Training loss: 0.6900744635950435
Epoch: 25 | Iteration number: [230/565] 40% | Training loss: 0.6899428631948388
Epoch: 25 | Iteration number: [240/565] 42% | Training loss: 0.6898043682177861
Epoch: 25 | Iteration number: [250/565] 44% | Training loss: 0.6897039368152619
Epoch: 25 | Iteration number: [260/565] 46% | Training loss: 0.6895881375441184
Epoch: 25 | Iteration number: [270/565] 47% | Training loss: 0.6895077268282572
Epoch: 25 | Iteration number: [280/565] 49% | Training loss: 0.6894107522709029
Epoch: 25 | Iteration number: [290/565] 51% | Training loss: 0.6893323844876783
Epoch: 25 | Iteration number: [300/565] 53% | Training loss: 0.6892456010977427
Epoch: 25 | Iteration number: [310/565] 54% | Training loss: 0.6891805487294351
Epoch: 25 | Iteration number: [320/565] 56% | Training loss: 0.6890978949144483
Epoch: 25 | Iteration number: [330/565] 58% | Training loss: 0.689032733259779
Epoch: 25 | Iteration number: [340/565] 60% | Training loss: 0.6889667684541029
Epoch: 25 | Iteration number: [350/565] 61% | Training loss: 0.6888974734715053
Epoch: 25 | Iteration number: [360/565] 63% | Training loss: 0.6888462973965539
Epoch: 25 | Iteration number: [370/565] 65% | Training loss: 0.68878931886441
Epoch: 25 | Iteration number: [380/565] 67% | Training loss: 0.6887354869591562
Epoch: 25 | Iteration number: [390/565] 69% | Training loss: 0.6886886113729233
Epoch: 25 | Iteration number: [400/565] 70% | Training loss: 0.6886425396800041
Epoch: 25 | Iteration number: [410/565] 72% | Training loss: 0.6885955762572404
Epoch: 25 | Iteration number: [420/565] 74% | Training loss: 0.688549924322537
Epoch: 25 | Iteration number: [430/565] 76% | Training loss: 0.6885177172893702
Epoch: 25 | Iteration number: [440/565] 77% | Training loss: 0.6884756477041678
Epoch: 25 | Iteration number: [450/565] 79% | Training loss: 0.6884429850843218
Epoch: 25 | Iteration number: [460/565] 81% | Training loss: 0.6884103293004243
Epoch: 25 | Iteration number: [470/565] 83% | Training loss: 0.6883912266568935
Epoch: 25 | Iteration number: [480/565] 84% | Training loss: 0.6883742937197288
Epoch: 25 | Iteration number: [490/565] 86% | Training loss: 0.6883448880545947
Epoch: 25 | Iteration number: [500/565] 88% | Training loss: 0.6883208280801774
Epoch: 25 | Iteration number: [510/565] 90% | Training loss: 0.688298345079609
Epoch: 25 | Iteration number: [520/565] 92% | Training loss: 0.6882761887632883
Epoch: 25 | Iteration number: [530/565] 93% | Training loss: 0.6882498046137252
Epoch: 25 | Iteration number: [540/565] 95% | Training loss: 0.6882244790041888
Epoch: 25 | Iteration number: [550/565] 97% | Training loss: 0.6881914551691576
Epoch: 25 | Iteration number: [560/565] 99% | Training loss: 0.6881649260010038

 End of epoch: 25 | Train Loss: 0.6869422644640493 | Training Time: 88 

 End of epoch: 25 | Eval Loss: 0.6905110733849662 | Evaluating Time: 6 
Epoch: 26 | Iteration number: [10/565] 1% | Training loss: 0.7553178906440735
Epoch: 26 | Iteration number: [20/565] 3% | Training loss: 0.7210937708616256
Epoch: 26 | Iteration number: [30/565] 5% | Training loss: 0.7095820705095927
Epoch: 26 | Iteration number: [40/565] 7% | Training loss: 0.7039532914757729
Epoch: 26 | Iteration number: [50/565] 8% | Training loss: 0.700594310760498
Epoch: 26 | Iteration number: [60/565] 10% | Training loss: 0.6982777605454127
Epoch: 26 | Iteration number: [70/565] 12% | Training loss: 0.6966373460633414
Epoch: 26 | Iteration number: [80/565] 14% | Training loss: 0.6954259142279625
Epoch: 26 | Iteration number: [90/565] 15% | Training loss: 0.6945117625925276
Epoch: 26 | Iteration number: [100/565] 17% | Training loss: 0.69367835521698
Epoch: 26 | Iteration number: [110/565] 19% | Training loss: 0.6931175665421919
Epoch: 26 | Iteration number: [120/565] 21% | Training loss: 0.6925973395506541
Epoch: 26 | Iteration number: [130/565] 23% | Training loss: 0.6921675856296833
Epoch: 26 | Iteration number: [140/565] 24% | Training loss: 0.6918039241007397
Epoch: 26 | Iteration number: [150/565] 26% | Training loss: 0.6914878173669179
Epoch: 26 | Iteration number: [160/565] 28% | Training loss: 0.6912043452262878
Epoch: 26 | Iteration number: [170/565] 30% | Training loss: 0.6909489842022166
Epoch: 26 | Iteration number: [180/565] 31% | Training loss: 0.6907307383086946
Epoch: 26 | Iteration number: [190/565] 33% | Training loss: 0.6905279328948573
Epoch: 26 | Iteration number: [200/565] 35% | Training loss: 0.690362648665905
Epoch: 26 | Iteration number: [210/565] 37% | Training loss: 0.6902048292614165
Epoch: 26 | Iteration number: [220/565] 38% | Training loss: 0.6900546133518219
Epoch: 26 | Iteration number: [230/565] 40% | Training loss: 0.6899153162603793
Epoch: 26 | Iteration number: [240/565] 42% | Training loss: 0.6897757786015669
Epoch: 26 | Iteration number: [250/565] 44% | Training loss: 0.6896589016914367
Epoch: 26 | Iteration number: [260/565] 46% | Training loss: 0.6895516141102864
Epoch: 26 | Iteration number: [270/565] 47% | Training loss: 0.6894350654549068
Epoch: 26 | Iteration number: [280/565] 49% | Training loss: 0.6893330203635352
Epoch: 26 | Iteration number: [290/565] 51% | Training loss: 0.6892507902507125
Epoch: 26 | Iteration number: [300/565] 53% | Training loss: 0.6891889103253682
Epoch: 26 | Iteration number: [310/565] 54% | Training loss: 0.6891208781350043
Epoch: 26 | Iteration number: [320/565] 56% | Training loss: 0.6890503196045756
Epoch: 26 | Iteration number: [330/565] 58% | Training loss: 0.688990387952689
Epoch: 26 | Iteration number: [340/565] 60% | Training loss: 0.6889390682472902
Epoch: 26 | Iteration number: [350/565] 61% | Training loss: 0.6888774219581059
Epoch: 26 | Iteration number: [360/565] 63% | Training loss: 0.688839872346984
Epoch: 26 | Iteration number: [370/565] 65% | Training loss: 0.6887857477407198
Epoch: 26 | Iteration number: [380/565] 67% | Training loss: 0.6887368059472034
Epoch: 26 | Iteration number: [390/565] 69% | Training loss: 0.6886836745800116
Epoch: 26 | Iteration number: [400/565] 70% | Training loss: 0.6886480115354061
Epoch: 26 | Iteration number: [410/565] 72% | Training loss: 0.6886029483341589
Epoch: 26 | Iteration number: [420/565] 74% | Training loss: 0.6885606826770874
Epoch: 26 | Iteration number: [430/565] 76% | Training loss: 0.6885241666505503
Epoch: 26 | Iteration number: [440/565] 77% | Training loss: 0.6884921999140219
Epoch: 26 | Iteration number: [450/565] 79% | Training loss: 0.6884618849224514
Epoch: 26 | Iteration number: [460/565] 81% | Training loss: 0.6884295385816823
Epoch: 26 | Iteration number: [470/565] 83% | Training loss: 0.6883999562009852
Epoch: 26 | Iteration number: [480/565] 84% | Training loss: 0.6883581868062417
Epoch: 26 | Iteration number: [490/565] 86% | Training loss: 0.6883172808861245
Epoch: 26 | Iteration number: [500/565] 88% | Training loss: 0.6882912132740021
Epoch: 26 | Iteration number: [510/565] 90% | Training loss: 0.68827478593471
Epoch: 26 | Iteration number: [520/565] 92% | Training loss: 0.688248975116473
Epoch: 26 | Iteration number: [530/565] 93% | Training loss: 0.6882196977453412
Epoch: 26 | Iteration number: [540/565] 95% | Training loss: 0.6881955969112891
Epoch: 26 | Iteration number: [550/565] 97% | Training loss: 0.6881691828641024
Epoch: 26 | Iteration number: [560/565] 99% | Training loss: 0.6881442519170897

 End of epoch: 26 | Train Loss: 0.6869196858026285 | Training Time: 87 

 End of epoch: 26 | Eval Loss: 0.6902779425893512 | Evaluating Time: 5 
Epoch: 27 | Iteration number: [10/565] 1% | Training loss: 0.7557694673538208
Epoch: 27 | Iteration number: [20/565] 3% | Training loss: 0.7215376138687134
Epoch: 27 | Iteration number: [30/565] 5% | Training loss: 0.7101320147514343
Epoch: 27 | Iteration number: [40/565] 7% | Training loss: 0.7043404042720794
Epoch: 27 | Iteration number: [50/565] 8% | Training loss: 0.700779185295105
Epoch: 27 | Iteration number: [60/565] 10% | Training loss: 0.698442804813385
Epoch: 27 | Iteration number: [70/565] 12% | Training loss: 0.6968067969594683
Epoch: 27 | Iteration number: [80/565] 14% | Training loss: 0.6955177634954453
Epoch: 27 | Iteration number: [90/565] 15% | Training loss: 0.6945664803187053
Epoch: 27 | Iteration number: [100/565] 17% | Training loss: 0.6937819695472718
Epoch: 27 | Iteration number: [110/565] 19% | Training loss: 0.6931432420557195
Epoch: 27 | Iteration number: [120/565] 21% | Training loss: 0.692607565720876
Epoch: 27 | Iteration number: [130/565] 23% | Training loss: 0.6921687557147099
Epoch: 27 | Iteration number: [140/565] 24% | Training loss: 0.6918061367103032
Epoch: 27 | Iteration number: [150/565] 26% | Training loss: 0.6915187327067057
Epoch: 27 | Iteration number: [160/565] 28% | Training loss: 0.6912121221423149
Epoch: 27 | Iteration number: [170/565] 30% | Training loss: 0.6909587186925551
Epoch: 27 | Iteration number: [180/565] 31% | Training loss: 0.6907378259632323
Epoch: 27 | Iteration number: [190/565] 33% | Training loss: 0.6905476212501526
Epoch: 27 | Iteration number: [200/565] 35% | Training loss: 0.6903607061505318
Epoch: 27 | Iteration number: [210/565] 37% | Training loss: 0.6902229456674485
Epoch: 27 | Iteration number: [220/565] 38% | Training loss: 0.6900661387226799
Epoch: 27 | Iteration number: [230/565] 40% | Training loss: 0.6899238042209459
Epoch: 27 | Iteration number: [240/565] 42% | Training loss: 0.6897846991817157
Epoch: 27 | Iteration number: [250/565] 44% | Training loss: 0.6896861817836761
Epoch: 27 | Iteration number: [260/565] 46% | Training loss: 0.6895735999712578
Epoch: 27 | Iteration number: [270/565] 47% | Training loss: 0.6894866389256936
Epoch: 27 | Iteration number: [280/565] 49% | Training loss: 0.6893916977303368
Epoch: 27 | Iteration number: [290/565] 51% | Training loss: 0.689313528455537
Epoch: 27 | Iteration number: [300/565] 53% | Training loss: 0.6892361297210058
Epoch: 27 | Iteration number: [310/565] 54% | Training loss: 0.6891671321084423
Epoch: 27 | Iteration number: [320/565] 56% | Training loss: 0.6890999039635062
Epoch: 27 | Iteration number: [330/565] 58% | Training loss: 0.6890320230614055
Epoch: 27 | Iteration number: [340/565] 60% | Training loss: 0.6889724000411875
Epoch: 27 | Iteration number: [350/565] 61% | Training loss: 0.6889161586761474
Epoch: 27 | Iteration number: [360/565] 63% | Training loss: 0.688857991165585
Epoch: 27 | Iteration number: [370/565] 65% | Training loss: 0.6888045185321087
Epoch: 27 | Iteration number: [380/565] 67% | Training loss: 0.6887385860869759
Epoch: 27 | Iteration number: [390/565] 69% | Training loss: 0.6886931494260445
Epoch: 27 | Iteration number: [400/565] 70% | Training loss: 0.6886400112509727
Epoch: 27 | Iteration number: [410/565] 72% | Training loss: 0.6886013602338186
Epoch: 27 | Iteration number: [420/565] 74% | Training loss: 0.6885733341886884
Epoch: 27 | Iteration number: [430/565] 76% | Training loss: 0.688539423360381
Epoch: 27 | Iteration number: [440/565] 77% | Training loss: 0.6884849858554927
Epoch: 27 | Iteration number: [450/565] 79% | Training loss: 0.6884386902385288
Epoch: 27 | Iteration number: [460/565] 81% | Training loss: 0.6884066566177036
Epoch: 27 | Iteration number: [470/565] 83% | Training loss: 0.6883766968199547
Epoch: 27 | Iteration number: [480/565] 84% | Training loss: 0.6883542026082675
Epoch: 27 | Iteration number: [490/565] 86% | Training loss: 0.6883205804289604
Epoch: 27 | Iteration number: [500/565] 88% | Training loss: 0.6882947078943252
Epoch: 27 | Iteration number: [510/565] 90% | Training loss: 0.6882664597501942
Epoch: 27 | Iteration number: [520/565] 92% | Training loss: 0.6882390138048392
Epoch: 27 | Iteration number: [530/565] 93% | Training loss: 0.6882083229298862
Epoch: 27 | Iteration number: [540/565] 95% | Training loss: 0.6881804790761735
Epoch: 27 | Iteration number: [550/565] 97% | Training loss: 0.6881574061783877
Epoch: 27 | Iteration number: [560/565] 99% | Training loss: 0.6881348970745291

 End of epoch: 27 | Train Loss: 0.6869039646292154 | Training Time: 91 

 End of epoch: 27 | Eval Loss: 0.6898233039038522 | Evaluating Time: 6 
Epoch: 28 | Iteration number: [10/565] 1% | Training loss: 0.7552888691425323
Epoch: 28 | Iteration number: [20/565] 3% | Training loss: 0.7210934937000275
Epoch: 28 | Iteration number: [30/565] 5% | Training loss: 0.709734853108724
Epoch: 28 | Iteration number: [40/565] 7% | Training loss: 0.7040566489100456
Epoch: 28 | Iteration number: [50/565] 8% | Training loss: 0.7005892682075501
Epoch: 28 | Iteration number: [60/565] 10% | Training loss: 0.6982465595006943
Epoch: 28 | Iteration number: [70/565] 12% | Training loss: 0.6966056116989681
Epoch: 28 | Iteration number: [80/565] 14% | Training loss: 0.6953610941767693
Epoch: 28 | Iteration number: [90/565] 15% | Training loss: 0.6944268345832825
Epoch: 28 | Iteration number: [100/565] 17% | Training loss: 0.6936552947759629
Epoch: 28 | Iteration number: [110/565] 19% | Training loss: 0.6930612667040391
Epoch: 28 | Iteration number: [120/565] 21% | Training loss: 0.6925600901246071
Epoch: 28 | Iteration number: [130/565] 23% | Training loss: 0.6920885374912848
Epoch: 28 | Iteration number: [140/565] 24% | Training loss: 0.6917431311947959
Epoch: 28 | Iteration number: [150/565] 26% | Training loss: 0.6914068067073822
Epoch: 28 | Iteration number: [160/565] 28% | Training loss: 0.6911038149148225
Epoch: 28 | Iteration number: [170/565] 30% | Training loss: 0.690834748394349
Epoch: 28 | Iteration number: [180/565] 31% | Training loss: 0.6906279371844397
Epoch: 28 | Iteration number: [190/565] 33% | Training loss: 0.6904404367271223
Epoch: 28 | Iteration number: [200/565] 35% | Training loss: 0.6902416738867759
Epoch: 28 | Iteration number: [210/565] 37% | Training loss: 0.6900847991307576
Epoch: 28 | Iteration number: [220/565] 38% | Training loss: 0.6899497655304996
Epoch: 28 | Iteration number: [230/565] 40% | Training loss: 0.6898167317328245
Epoch: 28 | Iteration number: [240/565] 42% | Training loss: 0.6897019858161608
Epoch: 28 | Iteration number: [250/565] 44% | Training loss: 0.6895861811637879
Epoch: 28 | Iteration number: [260/565] 46% | Training loss: 0.6894893859441463
Epoch: 28 | Iteration number: [270/565] 47% | Training loss: 0.6894052704175313
Epoch: 28 | Iteration number: [280/565] 49% | Training loss: 0.6893271942223821
Epoch: 28 | Iteration number: [290/565] 51% | Training loss: 0.6892425300746129
Epoch: 28 | Iteration number: [300/565] 53% | Training loss: 0.689172310034434
Epoch: 28 | Iteration number: [310/565] 54% | Training loss: 0.6890766284158153
Epoch: 28 | Iteration number: [320/565] 56% | Training loss: 0.6890046522021294
Epoch: 28 | Iteration number: [330/565] 58% | Training loss: 0.6889403354037892
Epoch: 28 | Iteration number: [340/565] 60% | Training loss: 0.6888865355183097
Epoch: 28 | Iteration number: [350/565] 61% | Training loss: 0.6888343604973385
Epoch: 28 | Iteration number: [360/565] 63% | Training loss: 0.6887749413649241
Epoch: 28 | Iteration number: [370/565] 65% | Training loss: 0.6887352241052164
Epoch: 28 | Iteration number: [380/565] 67% | Training loss: 0.6887004558977328
Epoch: 28 | Iteration number: [390/565] 69% | Training loss: 0.6886544068654378
Epoch: 28 | Iteration number: [400/565] 70% | Training loss: 0.6886069040000439
Epoch: 28 | Iteration number: [410/565] 72% | Training loss: 0.6885684481481227
Epoch: 28 | Iteration number: [420/565] 74% | Training loss: 0.6885265876849492
Epoch: 28 | Iteration number: [430/565] 76% | Training loss: 0.6884880702162898
Epoch: 28 | Iteration number: [440/565] 77% | Training loss: 0.6884485829960216
Epoch: 28 | Iteration number: [450/565] 79% | Training loss: 0.6884177888764276
Epoch: 28 | Iteration number: [460/565] 81% | Training loss: 0.6883875616218733
Epoch: 28 | Iteration number: [470/565] 83% | Training loss: 0.6883540416017492
Epoch: 28 | Iteration number: [480/565] 84% | Training loss: 0.6883313135554393
Epoch: 28 | Iteration number: [490/565] 86% | Training loss: 0.6883072196220865
Epoch: 28 | Iteration number: [500/565] 88% | Training loss: 0.6882805041074753
Epoch: 28 | Iteration number: [510/565] 90% | Training loss: 0.6882443390640558
Epoch: 28 | Iteration number: [520/565] 92% | Training loss: 0.6882194813627464
Epoch: 28 | Iteration number: [530/565] 93% | Training loss: 0.6881999087783526
Epoch: 28 | Iteration number: [540/565] 95% | Training loss: 0.6881714307599598
Epoch: 28 | Iteration number: [550/565] 97% | Training loss: 0.6881602536548268
Epoch: 28 | Iteration number: [560/565] 99% | Training loss: 0.6881303897925786

 End of epoch: 28 | Train Loss: 0.6869050518601342 | Training Time: 88 

 End of epoch: 28 | Eval Loss: 0.6904608522142682 | Evaluating Time: 6 
Epoch: 29 | Iteration number: [10/565] 1% | Training loss: 0.7554449439048767
Epoch: 29 | Iteration number: [20/565] 3% | Training loss: 0.7211685061454773
Epoch: 29 | Iteration number: [30/565] 5% | Training loss: 0.7095977008342743
Epoch: 29 | Iteration number: [40/565] 7% | Training loss: 0.7039650782942772
Epoch: 29 | Iteration number: [50/565] 8% | Training loss: 0.7006026375293731
Epoch: 29 | Iteration number: [60/565] 10% | Training loss: 0.6983013570308685
Epoch: 29 | Iteration number: [70/565] 12% | Training loss: 0.6965747083936419
Epoch: 29 | Iteration number: [80/565] 14% | Training loss: 0.6953438371419907
Epoch: 29 | Iteration number: [90/565] 15% | Training loss: 0.6944820000065698
Epoch: 29 | Iteration number: [100/565] 17% | Training loss: 0.6937404799461365
Epoch: 29 | Iteration number: [110/565] 19% | Training loss: 0.6931416181000796
Epoch: 29 | Iteration number: [120/565] 21% | Training loss: 0.6926085943977038
Epoch: 29 | Iteration number: [130/565] 23% | Training loss: 0.6921685700233166
Epoch: 29 | Iteration number: [140/565] 24% | Training loss: 0.6918026153530393
Epoch: 29 | Iteration number: [150/565] 26% | Training loss: 0.6914997760454814
Epoch: 29 | Iteration number: [160/565] 28% | Training loss: 0.6911984935402871
Epoch: 29 | Iteration number: [170/565] 30% | Training loss: 0.6909486973986906
Epoch: 29 | Iteration number: [180/565] 31% | Training loss: 0.6907380008035235
Epoch: 29 | Iteration number: [190/565] 33% | Training loss: 0.6905334701663569
Epoch: 29 | Iteration number: [200/565] 35% | Training loss: 0.690357216000557
Epoch: 29 | Iteration number: [210/565] 37% | Training loss: 0.6902187327543895
Epoch: 29 | Iteration number: [220/565] 38% | Training loss: 0.6900711717930708
Epoch: 29 | Iteration number: [230/565] 40% | Training loss: 0.6899536122446475
Epoch: 29 | Iteration number: [240/565] 42% | Training loss: 0.6898510478436947
Epoch: 29 | Iteration number: [250/565] 44% | Training loss: 0.6897195460796356
Epoch: 29 | Iteration number: [260/565] 46% | Training loss: 0.689617706491397
Epoch: 29 | Iteration number: [270/565] 47% | Training loss: 0.6895153672606856
Epoch: 29 | Iteration number: [280/565] 49% | Training loss: 0.6894237722669329
Epoch: 29 | Iteration number: [290/565] 51% | Training loss: 0.6893320221325446
Epoch: 29 | Iteration number: [300/565] 53% | Training loss: 0.6892518703142801
Epoch: 29 | Iteration number: [310/565] 54% | Training loss: 0.6891872709797274
Epoch: 29 | Iteration number: [320/565] 56% | Training loss: 0.6890977390110493
Epoch: 29 | Iteration number: [330/565] 58% | Training loss: 0.689036677642302
Epoch: 29 | Iteration number: [340/565] 60% | Training loss: 0.6889812653555589
Epoch: 29 | Iteration number: [350/565] 61% | Training loss: 0.6889251102719988
Epoch: 29 | Iteration number: [360/565] 63% | Training loss: 0.6888591277930471
Epoch: 29 | Iteration number: [370/565] 65% | Training loss: 0.6887989108626907
Epoch: 29 | Iteration number: [380/565] 67% | Training loss: 0.6887507642570295
Epoch: 29 | Iteration number: [390/565] 69% | Training loss: 0.6887012662031712
Epoch: 29 | Iteration number: [400/565] 70% | Training loss: 0.688664685189724
Epoch: 29 | Iteration number: [410/565] 72% | Training loss: 0.6886160276285032
Epoch: 29 | Iteration number: [420/565] 74% | Training loss: 0.6885808026506788
Epoch: 29 | Iteration number: [430/565] 76% | Training loss: 0.6885341875774916
Epoch: 29 | Iteration number: [440/565] 77% | Training loss: 0.6884881350127133
Epoch: 29 | Iteration number: [450/565] 79% | Training loss: 0.6884542324807909
Epoch: 29 | Iteration number: [460/565] 81% | Training loss: 0.6884106958689897
Epoch: 29 | Iteration number: [470/565] 83% | Training loss: 0.6883838042299798
Epoch: 29 | Iteration number: [480/565] 84% | Training loss: 0.6883442837744951
Epoch: 29 | Iteration number: [490/565] 86% | Training loss: 0.6883163015453183
Epoch: 29 | Iteration number: [500/565] 88% | Training loss: 0.6882887703180313
Epoch: 29 | Iteration number: [510/565] 90% | Training loss: 0.6882686438513738
Epoch: 29 | Iteration number: [520/565] 92% | Training loss: 0.6882418896143253
Epoch: 29 | Iteration number: [530/565] 93% | Training loss: 0.6882078410319562
Epoch: 29 | Iteration number: [540/565] 95% | Training loss: 0.6881923287003129
Epoch: 29 | Iteration number: [550/565] 97% | Training loss: 0.6881664239276539
Epoch: 29 | Iteration number: [560/565] 99% | Training loss: 0.6881430614207472

 End of epoch: 29 | Train Loss: 0.6869164697891843 | Training Time: 89 

 End of epoch: 29 | Eval Loss: 0.6901158009256635 | Evaluating Time: 6 
Epoch: 30 | Iteration number: [10/565] 1% | Training loss: 0.7555911004543304
Epoch: 30 | Iteration number: [20/565] 3% | Training loss: 0.7210725963115692
Epoch: 30 | Iteration number: [30/565] 5% | Training loss: 0.7095579624176025
Epoch: 30 | Iteration number: [40/565] 7% | Training loss: 0.7038742765784264
Epoch: 30 | Iteration number: [50/565] 8% | Training loss: 0.7004336297512055
Epoch: 30 | Iteration number: [60/565] 10% | Training loss: 0.698193817337354
Epoch: 30 | Iteration number: [70/565] 12% | Training loss: 0.6965899756976537
Epoch: 30 | Iteration number: [80/565] 14% | Training loss: 0.6953922808170319
Epoch: 30 | Iteration number: [90/565] 15% | Training loss: 0.6944282637702094
Epoch: 30 | Iteration number: [100/565] 17% | Training loss: 0.6936466568708419
Epoch: 30 | Iteration number: [110/565] 19% | Training loss: 0.6930082467469302
Epoch: 30 | Iteration number: [120/565] 21% | Training loss: 0.6924750020106634
Epoch: 30 | Iteration number: [130/565] 23% | Training loss: 0.6920493057140937
Epoch: 30 | Iteration number: [140/565] 24% | Training loss: 0.6916933221476419
Epoch: 30 | Iteration number: [150/565] 26% | Training loss: 0.691368289788564
Epoch: 30 | Iteration number: [160/565] 28% | Training loss: 0.6911147329956293
Epoch: 30 | Iteration number: [170/565] 30% | Training loss: 0.6908683187821332
Epoch: 30 | Iteration number: [180/565] 31% | Training loss: 0.6906181808975008
Epoch: 30 | Iteration number: [190/565] 33% | Training loss: 0.6904101735667179
Epoch: 30 | Iteration number: [200/565] 35% | Training loss: 0.6902094641327858
Epoch: 30 | Iteration number: [210/565] 37% | Training loss: 0.6900651511691865
Epoch: 30 | Iteration number: [220/565] 38% | Training loss: 0.6899424119429155
Epoch: 30 | Iteration number: [230/565] 40% | Training loss: 0.689811412666155
Epoch: 30 | Iteration number: [240/565] 42% | Training loss: 0.6896818034350872
Epoch: 30 | Iteration number: [250/565] 44% | Training loss: 0.6895673508644105
Epoch: 30 | Iteration number: [260/565] 46% | Training loss: 0.6894588394806935
Epoch: 30 | Iteration number: [270/565] 47% | Training loss: 0.6893714622214988
Epoch: 30 | Iteration number: [280/565] 49% | Training loss: 0.6892957519207682
Epoch: 30 | Iteration number: [290/565] 51% | Training loss: 0.6892116943310047
Epoch: 30 | Iteration number: [300/565] 53% | Training loss: 0.6891295705238978
Epoch: 30 | Iteration number: [310/565] 54% | Training loss: 0.6890559390667946
Epoch: 30 | Iteration number: [320/565] 56% | Training loss: 0.68899641726166
Epoch: 30 | Iteration number: [330/565] 58% | Training loss: 0.6889247941248344
Epoch: 30 | Iteration number: [340/565] 60% | Training loss: 0.6888612354502959
Epoch: 30 | Iteration number: [350/565] 61% | Training loss: 0.6887965995924813
Epoch: 30 | Iteration number: [360/565] 63% | Training loss: 0.6887434817022747
Epoch: 30 | Iteration number: [370/565] 65% | Training loss: 0.6886945914577793
Epoch: 30 | Iteration number: [380/565] 67% | Training loss: 0.6886508427168193
Epoch: 30 | Iteration number: [390/565] 69% | Training loss: 0.6886177570391924
Epoch: 30 | Iteration number: [400/565] 70% | Training loss: 0.6885804823040962
Epoch: 30 | Iteration number: [410/565] 72% | Training loss: 0.6885478179629256
Epoch: 30 | Iteration number: [420/565] 74% | Training loss: 0.6885090876193274
Epoch: 30 | Iteration number: [430/565] 76% | Training loss: 0.6884574908156728
Epoch: 30 | Iteration number: [440/565] 77% | Training loss: 0.6884154250675981
Epoch: 30 | Iteration number: [450/565] 79% | Training loss: 0.6883820651637184
Epoch: 30 | Iteration number: [460/565] 81% | Training loss: 0.6883487478546474
Epoch: 30 | Iteration number: [470/565] 83% | Training loss: 0.6883277527829434
Epoch: 30 | Iteration number: [480/565] 84% | Training loss: 0.6883032025148471
Epoch: 30 | Iteration number: [490/565] 86% | Training loss: 0.6882827430355306
Epoch: 30 | Iteration number: [500/565] 88% | Training loss: 0.6882676199674607
Epoch: 30 | Iteration number: [510/565] 90% | Training loss: 0.6882294173334159
Epoch: 30 | Iteration number: [520/565] 92% | Training loss: 0.6881966539300405
Epoch: 30 | Iteration number: [530/565] 93% | Training loss: 0.6881774573955896
Epoch: 30 | Iteration number: [540/565] 95% | Training loss: 0.6881568713320626
Epoch: 30 | Iteration number: [550/565] 97% | Training loss: 0.6881339759176428
Epoch: 30 | Iteration number: [560/565] 99% | Training loss: 0.6881158352962562

 End of epoch: 30 | Train Loss: 0.6868865513168605 | Training Time: 89 

 End of epoch: 30 | Eval Loss: 0.6899370721408299 | Evaluating Time: 5 
Epoch: 31 | Iteration number: [10/565] 1% | Training loss: 0.7558853209018708
Epoch: 31 | Iteration number: [20/565] 3% | Training loss: 0.7213178664445877
Epoch: 31 | Iteration number: [30/565] 5% | Training loss: 0.7097222824891408
Epoch: 31 | Iteration number: [40/565] 7% | Training loss: 0.7040326625108719
Epoch: 31 | Iteration number: [50/565] 8% | Training loss: 0.7006172835826874
Epoch: 31 | Iteration number: [60/565] 10% | Training loss: 0.6983751078446706
Epoch: 31 | Iteration number: [70/565] 12% | Training loss: 0.696736330645425
Epoch: 31 | Iteration number: [80/565] 14% | Training loss: 0.6955010384321213
Epoch: 31 | Iteration number: [90/565] 15% | Training loss: 0.6945484320322672
Epoch: 31 | Iteration number: [100/565] 17% | Training loss: 0.6938175541162491
Epoch: 31 | Iteration number: [110/565] 19% | Training loss: 0.6932038962841034
Epoch: 31 | Iteration number: [120/565] 21% | Training loss: 0.6926766216754914
Epoch: 31 | Iteration number: [130/565] 23% | Training loss: 0.6922212504423582
Epoch: 31 | Iteration number: [140/565] 24% | Training loss: 0.6918416044541768
Epoch: 31 | Iteration number: [150/565] 26% | Training loss: 0.6915329877535502
Epoch: 31 | Iteration number: [160/565] 28% | Training loss: 0.6912646915763616
Epoch: 31 | Iteration number: [170/565] 30% | Training loss: 0.6910435276872972
Epoch: 31 | Iteration number: [180/565] 31% | Training loss: 0.6908176316155328
Epoch: 31 | Iteration number: [190/565] 33% | Training loss: 0.6906181843657243
Epoch: 31 | Iteration number: [200/565] 35% | Training loss: 0.6904174962639809
Epoch: 31 | Iteration number: [210/565] 37% | Training loss: 0.6902618762992677
Epoch: 31 | Iteration number: [220/565] 38% | Training loss: 0.6901090770959855
Epoch: 31 | Iteration number: [230/565] 40% | Training loss: 0.6899438427842182
Epoch: 31 | Iteration number: [240/565] 42% | Training loss: 0.6898188166320324
Epoch: 31 | Iteration number: [250/565] 44% | Training loss: 0.689706377029419
Epoch: 31 | Iteration number: [260/565] 46% | Training loss: 0.6896058437915948
Epoch: 31 | Iteration number: [270/565] 47% | Training loss: 0.6895075614805575
Epoch: 31 | Iteration number: [280/565] 49% | Training loss: 0.6894130255494799
Epoch: 31 | Iteration number: [290/565] 51% | Training loss: 0.6893281167951123
Epoch: 31 | Iteration number: [300/565] 53% | Training loss: 0.6892551215489705
Epoch: 31 | Iteration number: [310/565] 54% | Training loss: 0.6891666558481032
Epoch: 31 | Iteration number: [320/565] 56% | Training loss: 0.6890968697145581
Epoch: 31 | Iteration number: [330/565] 58% | Training loss: 0.6890352082974983
Epoch: 31 | Iteration number: [340/565] 60% | Training loss: 0.6889648044810576
Epoch: 31 | Iteration number: [350/565] 61% | Training loss: 0.688892628124782
Epoch: 31 | Iteration number: [360/565] 63% | Training loss: 0.6888416750563515
Epoch: 31 | Iteration number: [370/565] 65% | Training loss: 0.6887923079567987
Epoch: 31 | Iteration number: [380/565] 67% | Training loss: 0.688738267515835
Epoch: 31 | Iteration number: [390/565] 69% | Training loss: 0.6886833132841648
Epoch: 31 | Iteration number: [400/565] 70% | Training loss: 0.6886331468820572
Epoch: 31 | Iteration number: [410/565] 72% | Training loss: 0.6886005725802444
Epoch: 31 | Iteration number: [420/565] 74% | Training loss: 0.6885585885672342
Epoch: 31 | Iteration number: [430/565] 76% | Training loss: 0.6885228061398795
Epoch: 31 | Iteration number: [440/565] 77% | Training loss: 0.6884855277158998
Epoch: 31 | Iteration number: [450/565] 79% | Training loss: 0.6884425301022
Epoch: 31 | Iteration number: [460/565] 81% | Training loss: 0.6884030343397803
Epoch: 31 | Iteration number: [470/565] 83% | Training loss: 0.6883769669431321
Epoch: 31 | Iteration number: [480/565] 84% | Training loss: 0.6883527850111325
Epoch: 31 | Iteration number: [490/565] 86% | Training loss: 0.6883218260443941
Epoch: 31 | Iteration number: [500/565] 88% | Training loss: 0.6882878606319427
Epoch: 31 | Iteration number: [510/565] 90% | Training loss: 0.688262998005923
Epoch: 31 | Iteration number: [520/565] 92% | Training loss: 0.6882454222211472
Epoch: 31 | Iteration number: [530/565] 93% | Training loss: 0.6882210753998667
Epoch: 31 | Iteration number: [540/565] 95% | Training loss: 0.688195291603053
Epoch: 31 | Iteration number: [550/565] 97% | Training loss: 0.6881682037223469
Epoch: 31 | Iteration number: [560/565] 99% | Training loss: 0.6881499699183873

 End of epoch: 31 | Train Loss: 0.6869247202324656 | Training Time: 89 

 End of epoch: 31 | Eval Loss: 0.6901183043207441 | Evaluating Time: 6 
Epoch: 32 | Iteration number: [10/565] 1% | Training loss: 0.7560898005962372
Epoch: 32 | Iteration number: [20/565] 3% | Training loss: 0.7215522676706314
Epoch: 32 | Iteration number: [30/565] 5% | Training loss: 0.7099755446116129
Epoch: 32 | Iteration number: [40/565] 7% | Training loss: 0.7042342722415924
Epoch: 32 | Iteration number: [50/565] 8% | Training loss: 0.7006883239746093
Epoch: 32 | Iteration number: [60/565] 10% | Training loss: 0.6983979195356369
Epoch: 32 | Iteration number: [70/565] 12% | Training loss: 0.696769449540547
Epoch: 32 | Iteration number: [80/565] 14% | Training loss: 0.6955082103610039
Epoch: 32 | Iteration number: [90/565] 15% | Training loss: 0.6945262008243137
Epoch: 32 | Iteration number: [100/565] 17% | Training loss: 0.6937438917160034
Epoch: 32 | Iteration number: [110/565] 19% | Training loss: 0.6931344904682853
Epoch: 32 | Iteration number: [120/565] 21% | Training loss: 0.6926192939281464
Epoch: 32 | Iteration number: [130/565] 23% | Training loss: 0.6921589264502892
Epoch: 32 | Iteration number: [140/565] 24% | Training loss: 0.6917733767202923
Epoch: 32 | Iteration number: [150/565] 26% | Training loss: 0.6914474244912465
Epoch: 32 | Iteration number: [160/565] 28% | Training loss: 0.6911415342241526
Epoch: 32 | Iteration number: [170/565] 30% | Training loss: 0.6909022990395041
Epoch: 32 | Iteration number: [180/565] 31% | Training loss: 0.6906820178031922
Epoch: 32 | Iteration number: [190/565] 33% | Training loss: 0.6904671242362574
Epoch: 32 | Iteration number: [200/565] 35% | Training loss: 0.6902982038259506
Epoch: 32 | Iteration number: [210/565] 37% | Training loss: 0.6901161588373639
Epoch: 32 | Iteration number: [220/565] 38% | Training loss: 0.6899757033044641
Epoch: 32 | Iteration number: [230/565] 40% | Training loss: 0.6898490509261256
Epoch: 32 | Iteration number: [240/565] 42% | Training loss: 0.6897574650744597
Epoch: 32 | Iteration number: [250/565] 44% | Training loss: 0.6896572604179382
Epoch: 32 | Iteration number: [260/565] 46% | Training loss: 0.6895536585496023
Epoch: 32 | Iteration number: [270/565] 47% | Training loss: 0.6894760621918572
Epoch: 32 | Iteration number: [280/565] 49% | Training loss: 0.6893966962184225
Epoch: 32 | Iteration number: [290/565] 51% | Training loss: 0.689295172485812
Epoch: 32 | Iteration number: [300/565] 53% | Training loss: 0.689214643239975
Epoch: 32 | Iteration number: [310/565] 54% | Training loss: 0.6891244486454995
Epoch: 32 | Iteration number: [320/565] 56% | Training loss: 0.6890561811625957
Epoch: 32 | Iteration number: [330/565] 58% | Training loss: 0.6889853443160202
Epoch: 32 | Iteration number: [340/565] 60% | Training loss: 0.6889249330057817
Epoch: 32 | Iteration number: [350/565] 61% | Training loss: 0.6888781729766301
Epoch: 32 | Iteration number: [360/565] 63% | Training loss: 0.6888333241144816
Epoch: 32 | Iteration number: [370/565] 65% | Training loss: 0.6887828509549837
Epoch: 32 | Iteration number: [380/565] 67% | Training loss: 0.6887294606158608
Epoch: 32 | Iteration number: [390/565] 69% | Training loss: 0.6886910134401076
Epoch: 32 | Iteration number: [400/565] 70% | Training loss: 0.6886257821321488
Epoch: 32 | Iteration number: [410/565] 72% | Training loss: 0.6885780684831666
Epoch: 32 | Iteration number: [420/565] 74% | Training loss: 0.6885455474967048
Epoch: 32 | Iteration number: [430/565] 76% | Training loss: 0.6884940322055373
Epoch: 32 | Iteration number: [440/565] 77% | Training loss: 0.6884569565003569
Epoch: 32 | Iteration number: [450/565] 79% | Training loss: 0.6884383928775787
Epoch: 32 | Iteration number: [460/565] 81% | Training loss: 0.6883931573318398
Epoch: 32 | Iteration number: [470/565] 83% | Training loss: 0.6883579984624335
Epoch: 32 | Iteration number: [480/565] 84% | Training loss: 0.6883225514243047
Epoch: 32 | Iteration number: [490/565] 86% | Training loss: 0.688296097030445
Epoch: 32 | Iteration number: [500/565] 88% | Training loss: 0.6882631554603577
Epoch: 32 | Iteration number: [510/565] 90% | Training loss: 0.6882404783192803
Epoch: 32 | Iteration number: [520/565] 92% | Training loss: 0.6882175113146122
Epoch: 32 | Iteration number: [530/565] 93% | Training loss: 0.6881883960849834
Epoch: 32 | Iteration number: [540/565] 95% | Training loss: 0.6881586526279097
Epoch: 32 | Iteration number: [550/565] 97% | Training loss: 0.688135953057896
Epoch: 32 | Iteration number: [560/565] 99% | Training loss: 0.688116590572255

 End of epoch: 32 | Train Loss: 0.6868858455556683 | Training Time: 89 

 End of epoch: 32 | Eval Loss: 0.6897861531802586 | Evaluating Time: 6 
Epoch: 33 | Iteration number: [10/565] 1% | Training loss: 0.755722850561142
Epoch: 33 | Iteration number: [20/565] 3% | Training loss: 0.7212513208389282
Epoch: 33 | Iteration number: [30/565] 5% | Training loss: 0.7099266628424327
Epoch: 33 | Iteration number: [40/565] 7% | Training loss: 0.7042783573269844
Epoch: 33 | Iteration number: [50/565] 8% | Training loss: 0.7007925808429718
Epoch: 33 | Iteration number: [60/565] 10% | Training loss: 0.698417192697525
Epoch: 33 | Iteration number: [70/565] 12% | Training loss: 0.6966967795576368
Epoch: 33 | Iteration number: [80/565] 14% | Training loss: 0.6954558759927749
Epoch: 33 | Iteration number: [90/565] 15% | Training loss: 0.6945117943816714
Epoch: 33 | Iteration number: [100/565] 17% | Training loss: 0.6937466377019882
Epoch: 33 | Iteration number: [110/565] 19% | Training loss: 0.6931142595681277
Epoch: 33 | Iteration number: [120/565] 21% | Training loss: 0.692602488398552
Epoch: 33 | Iteration number: [130/565] 23% | Training loss: 0.6921308242357694
Epoch: 33 | Iteration number: [140/565] 24% | Training loss: 0.6917453169822693
Epoch: 33 | Iteration number: [150/565] 26% | Training loss: 0.6913865824540456
Epoch: 33 | Iteration number: [160/565] 28% | Training loss: 0.6911311477422715
Epoch: 33 | Iteration number: [170/565] 30% | Training loss: 0.6908909068388097
Epoch: 33 | Iteration number: [180/565] 31% | Training loss: 0.6906568653053707
Epoch: 33 | Iteration number: [190/565] 33% | Training loss: 0.6904502874926517
Epoch: 33 | Iteration number: [200/565] 35% | Training loss: 0.6902608647942543
Epoch: 33 | Iteration number: [210/565] 37% | Training loss: 0.6900942845003946
Epoch: 33 | Iteration number: [220/565] 38% | Training loss: 0.6899375184015795
Epoch: 33 | Iteration number: [230/565] 40% | Training loss: 0.6898127485876498
Epoch: 33 | Iteration number: [240/565] 42% | Training loss: 0.6896863289177417
Epoch: 33 | Iteration number: [250/565] 44% | Training loss: 0.6895947859287263
Epoch: 33 | Iteration number: [260/565] 46% | Training loss: 0.689492922104322
Epoch: 33 | Iteration number: [270/565] 47% | Training loss: 0.6893905915595867
Epoch: 33 | Iteration number: [280/565] 49% | Training loss: 0.6893007261412484
Epoch: 33 | Iteration number: [290/565] 51% | Training loss: 0.6892229287788786
Epoch: 33 | Iteration number: [300/565] 53% | Training loss: 0.6891432629028956
Epoch: 33 | Iteration number: [310/565] 54% | Training loss: 0.6890708750294101
Epoch: 33 | Iteration number: [320/565] 56% | Training loss: 0.689004385843873
Epoch: 33 | Iteration number: [330/565] 58% | Training loss: 0.6889446280219338
Epoch: 33 | Iteration number: [340/565] 60% | Training loss: 0.688878429461928
Epoch: 33 | Iteration number: [350/565] 61% | Training loss: 0.6888278429848808
Epoch: 33 | Iteration number: [360/565] 63% | Training loss: 0.688768527077304
Epoch: 33 | Iteration number: [370/565] 65% | Training loss: 0.6887183584071495
Epoch: 33 | Iteration number: [380/565] 67% | Training loss: 0.6886778542869969
Epoch: 33 | Iteration number: [390/565] 69% | Training loss: 0.6886255539380587
Epoch: 33 | Iteration number: [400/565] 70% | Training loss: 0.6885807679593563
Epoch: 33 | Iteration number: [410/565] 72% | Training loss: 0.6885369037709586
Epoch: 33 | Iteration number: [420/565] 74% | Training loss: 0.6884967108567556
Epoch: 33 | Iteration number: [430/565] 76% | Training loss: 0.6884555296842442
Epoch: 33 | Iteration number: [440/565] 77% | Training loss: 0.6884253818880428
Epoch: 33 | Iteration number: [450/565] 79% | Training loss: 0.6883886427349515
Epoch: 33 | Iteration number: [460/565] 81% | Training loss: 0.6883562085421189
Epoch: 33 | Iteration number: [470/565] 83% | Training loss: 0.6883300409672108
Epoch: 33 | Iteration number: [480/565] 84% | Training loss: 0.6883008980502685
Epoch: 33 | Iteration number: [490/565] 86% | Training loss: 0.6882763489168517
Epoch: 33 | Iteration number: [500/565] 88% | Training loss: 0.6882375559806824
Epoch: 33 | Iteration number: [510/565] 90% | Training loss: 0.6882175027155408
Epoch: 33 | Iteration number: [520/565] 92% | Training loss: 0.6881721377372741
Epoch: 33 | Iteration number: [530/565] 93% | Training loss: 0.6881493860820554
Epoch: 33 | Iteration number: [540/565] 95% | Training loss: 0.6881298726355588
Epoch: 33 | Iteration number: [550/565] 97% | Training loss: 0.6881162257628007
Epoch: 33 | Iteration number: [560/565] 99% | Training loss: 0.6880971782973835

 End of epoch: 33 | Train Loss: 0.6868694430958908 | Training Time: 88 

 End of epoch: 33 | Eval Loss: 0.690189676625388 | Evaluating Time: 5 
Epoch: 34 | Iteration number: [10/565] 1% | Training loss: 0.7556637942790985
Epoch: 34 | Iteration number: [20/565] 3% | Training loss: 0.7211536794900895
Epoch: 34 | Iteration number: [30/565] 5% | Training loss: 0.709628677368164
Epoch: 34 | Iteration number: [40/565] 7% | Training loss: 0.7039516434073448
Epoch: 34 | Iteration number: [50/565] 8% | Training loss: 0.7005046355724335
Epoch: 34 | Iteration number: [60/565] 10% | Training loss: 0.6982251167297363
Epoch: 34 | Iteration number: [70/565] 12% | Training loss: 0.6966361667428698
Epoch: 34 | Iteration number: [80/565] 14% | Training loss: 0.6954288683831692
Epoch: 34 | Iteration number: [90/565] 15% | Training loss: 0.6944763978322347
Epoch: 34 | Iteration number: [100/565] 17% | Training loss: 0.6937641716003418
Epoch: 34 | Iteration number: [110/565] 19% | Training loss: 0.6931241398507898
Epoch: 34 | Iteration number: [120/565] 21% | Training loss: 0.6926399365067482
Epoch: 34 | Iteration number: [130/565] 23% | Training loss: 0.6921618869671455
Epoch: 34 | Iteration number: [140/565] 24% | Training loss: 0.6917549593108041
Epoch: 34 | Iteration number: [150/565] 26% | Training loss: 0.6914218250910441
Epoch: 34 | Iteration number: [160/565] 28% | Training loss: 0.6911304984241724
Epoch: 34 | Iteration number: [170/565] 30% | Training loss: 0.6908738528980928
Epoch: 34 | Iteration number: [180/565] 31% | Training loss: 0.6906263288524416
Epoch: 34 | Iteration number: [190/565] 33% | Training loss: 0.6904182518783368
Epoch: 34 | Iteration number: [200/565] 35% | Training loss: 0.6902163395285607
Epoch: 34 | Iteration number: [210/565] 37% | Training loss: 0.6900583755402337
Epoch: 34 | Iteration number: [220/565] 38% | Training loss: 0.6899126784367995
Epoch: 34 | Iteration number: [230/565] 40% | Training loss: 0.689776833679365
Epoch: 34 | Iteration number: [240/565] 42% | Training loss: 0.689656547208627
Epoch: 34 | Iteration number: [250/565] 44% | Training loss: 0.6895398921966552
Epoch: 34 | Iteration number: [260/565] 46% | Training loss: 0.6894454717636108
Epoch: 34 | Iteration number: [270/565] 47% | Training loss: 0.689371708366606
Epoch: 34 | Iteration number: [280/565] 49% | Training loss: 0.6892916504825864
Epoch: 34 | Iteration number: [290/565] 51% | Training loss: 0.6892129708980692
Epoch: 34 | Iteration number: [300/565] 53% | Training loss: 0.6891143494844436
Epoch: 34 | Iteration number: [310/565] 54% | Training loss: 0.689032716712644
Epoch: 34 | Iteration number: [320/565] 56% | Training loss: 0.6889566063880921
Epoch: 34 | Iteration number: [330/565] 58% | Training loss: 0.6888832265680487
Epoch: 34 | Iteration number: [340/565] 60% | Training loss: 0.6888231819166857
Epoch: 34 | Iteration number: [350/565] 61% | Training loss: 0.688769587618964
Epoch: 34 | Iteration number: [360/565] 63% | Training loss: 0.6887154849039183
Epoch: 34 | Iteration number: [370/565] 65% | Training loss: 0.6886736003128258
Epoch: 34 | Iteration number: [380/565] 67% | Training loss: 0.6886282509879063
Epoch: 34 | Iteration number: [390/565] 69% | Training loss: 0.688586004727926
Epoch: 34 | Iteration number: [400/565] 70% | Training loss: 0.6885427813231945
Epoch: 34 | Iteration number: [410/565] 72% | Training loss: 0.6885029515115226
Epoch: 34 | Iteration number: [420/565] 74% | Training loss: 0.6884624790577661
Epoch: 34 | Iteration number: [430/565] 76% | Training loss: 0.6884295937626861
Epoch: 34 | Iteration number: [440/565] 77% | Training loss: 0.6883934316310015
Epoch: 34 | Iteration number: [450/565] 79% | Training loss: 0.6883624250359005
Epoch: 34 | Iteration number: [460/565] 81% | Training loss: 0.6883342678132265
Epoch: 34 | Iteration number: [470/565] 83% | Training loss: 0.6883074833991679
Epoch: 34 | Iteration number: [480/565] 84% | Training loss: 0.6882792579631011
Epoch: 34 | Iteration number: [490/565] 86% | Training loss: 0.6882505077488569
Epoch: 34 | Iteration number: [500/565] 88% | Training loss: 0.6882275433540345
Epoch: 34 | Iteration number: [510/565] 90% | Training loss: 0.6882083458058974
Epoch: 34 | Iteration number: [520/565] 92% | Training loss: 0.6881853606838446
Epoch: 34 | Iteration number: [530/565] 93% | Training loss: 0.6881563070810066
Epoch: 34 | Iteration number: [540/565] 95% | Training loss: 0.6881360993341163
Epoch: 34 | Iteration number: [550/565] 97% | Training loss: 0.6881144661253149
Epoch: 34 | Iteration number: [560/565] 99% | Training loss: 0.6880879380873272

 End of epoch: 34 | Train Loss: 0.6868640079962469 | Training Time: 89 

 End of epoch: 34 | Eval Loss: 0.688734803880964 | Evaluating Time: 6 
Epoch: 35 | Iteration number: [10/565] 1% | Training loss: 0.7555712223052978
Epoch: 35 | Iteration number: [20/565] 3% | Training loss: 0.721095758676529
Epoch: 35 | Iteration number: [30/565] 5% | Training loss: 0.7096826016902924
Epoch: 35 | Iteration number: [40/565] 7% | Training loss: 0.703842306137085
Epoch: 35 | Iteration number: [50/565] 8% | Training loss: 0.7004541409015655
Epoch: 35 | Iteration number: [60/565] 10% | Training loss: 0.6982325385014216
Epoch: 35 | Iteration number: [70/565] 12% | Training loss: 0.6966091317789895
Epoch: 35 | Iteration number: [80/565] 14% | Training loss: 0.6953972905874253
Epoch: 35 | Iteration number: [90/565] 15% | Training loss: 0.694430289665858
Epoch: 35 | Iteration number: [100/565] 17% | Training loss: 0.6936994135379791
Epoch: 35 | Iteration number: [110/565] 19% | Training loss: 0.6930887005545876
Epoch: 35 | Iteration number: [120/565] 21% | Training loss: 0.6925921191771826
Epoch: 35 | Iteration number: [130/565] 23% | Training loss: 0.6922082094045786
Epoch: 35 | Iteration number: [140/565] 24% | Training loss: 0.6918211285557065
Epoch: 35 | Iteration number: [150/565] 26% | Training loss: 0.6914811940987905
Epoch: 35 | Iteration number: [160/565] 28% | Training loss: 0.6912235047668218
Epoch: 35 | Iteration number: [170/565] 30% | Training loss: 0.6909570290761835
Epoch: 35 | Iteration number: [180/565] 31% | Training loss: 0.69072884619236
Epoch: 35 | Iteration number: [190/565] 33% | Training loss: 0.6905302493195785
Epoch: 35 | Iteration number: [200/565] 35% | Training loss: 0.6903375726938248
Epoch: 35 | Iteration number: [210/565] 37% | Training loss: 0.6901569247245789
Epoch: 35 | Iteration number: [220/565] 38% | Training loss: 0.6899970081719485
Epoch: 35 | Iteration number: [230/565] 40% | Training loss: 0.689844397617423
Epoch: 35 | Iteration number: [240/565] 42% | Training loss: 0.689706210543712
Epoch: 35 | Iteration number: [250/565] 44% | Training loss: 0.6895891795158386
Epoch: 35 | Iteration number: [260/565] 46% | Training loss: 0.6894994403307254
Epoch: 35 | Iteration number: [270/565] 47% | Training loss: 0.6893962339118674
Epoch: 35 | Iteration number: [280/565] 49% | Training loss: 0.6893037521413394
Epoch: 35 | Iteration number: [290/565] 51% | Training loss: 0.6892303931302037
Epoch: 35 | Iteration number: [300/565] 53% | Training loss: 0.6891528513034185
Epoch: 35 | Iteration number: [310/565] 54% | Training loss: 0.6890834719904008
Epoch: 35 | Iteration number: [320/565] 56% | Training loss: 0.6890030935406685
Epoch: 35 | Iteration number: [330/565] 58% | Training loss: 0.6889365268476082
Epoch: 35 | Iteration number: [340/565] 60% | Training loss: 0.6888762640602448
Epoch: 35 | Iteration number: [350/565] 61% | Training loss: 0.6888149971621377
Epoch: 35 | Iteration number: [360/565] 63% | Training loss: 0.6887418892648485
Epoch: 35 | Iteration number: [370/565] 65% | Training loss: 0.6887095121113029
Epoch: 35 | Iteration number: [380/565] 67% | Training loss: 0.6886664269786132
Epoch: 35 | Iteration number: [390/565] 69% | Training loss: 0.6886322524303045
Epoch: 35 | Iteration number: [400/565] 70% | Training loss: 0.6885918490588665
Epoch: 35 | Iteration number: [410/565] 72% | Training loss: 0.6885445549720671
Epoch: 35 | Iteration number: [420/565] 74% | Training loss: 0.6885088936204002
Epoch: 35 | Iteration number: [430/565] 76% | Training loss: 0.6884778026924577
Epoch: 35 | Iteration number: [440/565] 77% | Training loss: 0.6884274922988631
Epoch: 35 | Iteration number: [450/565] 79% | Training loss: 0.6883886286947463
Epoch: 35 | Iteration number: [460/565] 81% | Training loss: 0.6883615123189014
Epoch: 35 | Iteration number: [470/565] 83% | Training loss: 0.6883374127935856
Epoch: 35 | Iteration number: [480/565] 84% | Training loss: 0.6883047226816416
Epoch: 35 | Iteration number: [490/565] 86% | Training loss: 0.6882767953434769
Epoch: 35 | Iteration number: [500/565] 88% | Training loss: 0.6882557345628738
Epoch: 35 | Iteration number: [510/565] 90% | Training loss: 0.6882310301649804
Epoch: 35 | Iteration number: [520/565] 92% | Training loss: 0.6881997342293079
Epoch: 35 | Iteration number: [530/565] 93% | Training loss: 0.688166918282239
Epoch: 35 | Iteration number: [540/565] 95% | Training loss: 0.6881412745625884
Epoch: 35 | Iteration number: [550/565] 97% | Training loss: 0.6881160096688704
Epoch: 35 | Iteration number: [560/565] 99% | Training loss: 0.6880943868841444

 End of epoch: 35 | Train Loss: 0.6868701178415687 | Training Time: 88 

 End of epoch: 35 | Eval Loss: 0.6907034260886056 | Evaluating Time: 6 
Epoch: 36 | Iteration number: [10/565] 1% | Training loss: 0.7554892539978028
Epoch: 36 | Iteration number: [20/565] 3% | Training loss: 0.7213775157928467
Epoch: 36 | Iteration number: [30/565] 5% | Training loss: 0.7098970691363017
Epoch: 36 | Iteration number: [40/565] 7% | Training loss: 0.7042663484811783
Epoch: 36 | Iteration number: [50/565] 8% | Training loss: 0.7008845686912537
Epoch: 36 | Iteration number: [60/565] 10% | Training loss: 0.698547484477361
Epoch: 36 | Iteration number: [70/565] 12% | Training loss: 0.6969476197447095
Epoch: 36 | Iteration number: [80/565] 14% | Training loss: 0.6957104682922364
Epoch: 36 | Iteration number: [90/565] 15% | Training loss: 0.694727071126302
Epoch: 36 | Iteration number: [100/565] 17% | Training loss: 0.69391166806221
Epoch: 36 | Iteration number: [110/565] 19% | Training loss: 0.6932950003580614
Epoch: 36 | Iteration number: [120/565] 21% | Training loss: 0.6927873432636261
Epoch: 36 | Iteration number: [130/565] 23% | Training loss: 0.6923769845412328
Epoch: 36 | Iteration number: [140/565] 24% | Training loss: 0.6919729207243238
Epoch: 36 | Iteration number: [150/565] 26% | Training loss: 0.6916619193553925
Epoch: 36 | Iteration number: [160/565] 28% | Training loss: 0.6913858346641064
Epoch: 36 | Iteration number: [170/565] 30% | Training loss: 0.6911092695067911
Epoch: 36 | Iteration number: [180/565] 31% | Training loss: 0.6908501356840133
Epoch: 36 | Iteration number: [190/565] 33% | Training loss: 0.690621005547674
Epoch: 36 | Iteration number: [200/565] 35% | Training loss: 0.6904267352819443
Epoch: 36 | Iteration number: [210/565] 37% | Training loss: 0.6902569765136355
Epoch: 36 | Iteration number: [220/565] 38% | Training loss: 0.690101632475853
Epoch: 36 | Iteration number: [230/565] 40% | Training loss: 0.6899690775767616
Epoch: 36 | Iteration number: [240/565] 42% | Training loss: 0.6898462382455667
Epoch: 36 | Iteration number: [250/565] 44% | Training loss: 0.6897027056217193
Epoch: 36 | Iteration number: [260/565] 46% | Training loss: 0.6895919251900453
Epoch: 36 | Iteration number: [270/565] 47% | Training loss: 0.6894838432470958
Epoch: 36 | Iteration number: [280/565] 49% | Training loss: 0.6893747619220189
Epoch: 36 | Iteration number: [290/565] 51% | Training loss: 0.689298768290158
Epoch: 36 | Iteration number: [300/565] 53% | Training loss: 0.6892259869972864
Epoch: 36 | Iteration number: [310/565] 54% | Training loss: 0.6891412698453473
Epoch: 36 | Iteration number: [320/565] 56% | Training loss: 0.6890667008236051
Epoch: 36 | Iteration number: [330/565] 58% | Training loss: 0.6890039566791419
Epoch: 36 | Iteration number: [340/565] 60% | Training loss: 0.6889343664926642
Epoch: 36 | Iteration number: [350/565] 61% | Training loss: 0.6888784267221179
Epoch: 36 | Iteration number: [360/565] 63% | Training loss: 0.6888256778319677
Epoch: 36 | Iteration number: [370/565] 65% | Training loss: 0.688770990275048
Epoch: 36 | Iteration number: [380/565] 67% | Training loss: 0.6887197260793887
Epoch: 36 | Iteration number: [390/565] 69% | Training loss: 0.6886835257212321
Epoch: 36 | Iteration number: [400/565] 70% | Training loss: 0.6886443509161473
Epoch: 36 | Iteration number: [410/565] 72% | Training loss: 0.6886013622690992
Epoch: 36 | Iteration number: [420/565] 74% | Training loss: 0.6885550320148468
Epoch: 36 | Iteration number: [430/565] 76% | Training loss: 0.6885229931321255
Epoch: 36 | Iteration number: [440/565] 77% | Training loss: 0.6884873676029118
Epoch: 36 | Iteration number: [450/565] 79% | Training loss: 0.6884504911634657
Epoch: 36 | Iteration number: [460/565] 81% | Training loss: 0.6884045634580696
Epoch: 36 | Iteration number: [470/565] 83% | Training loss: 0.6883776102928405
Epoch: 36 | Iteration number: [480/565] 84% | Training loss: 0.6883382854362329
Epoch: 36 | Iteration number: [490/565] 86% | Training loss: 0.688305565654015
Epoch: 36 | Iteration number: [500/565] 88% | Training loss: 0.6882820200920104
Epoch: 36 | Iteration number: [510/565] 90% | Training loss: 0.688253858276442
Epoch: 36 | Iteration number: [520/565] 92% | Training loss: 0.6882294976940522
Epoch: 36 | Iteration number: [530/565] 93% | Training loss: 0.6882040532130116
Epoch: 36 | Iteration number: [540/565] 95% | Training loss: 0.6881720626795733
Epoch: 36 | Iteration number: [550/565] 97% | Training loss: 0.688141424222426
Epoch: 36 | Iteration number: [560/565] 99% | Training loss: 0.6881172462233476

 End of epoch: 36 | Train Loss: 0.6868889537532773 | Training Time: 89 

 End of epoch: 36 | Eval Loss: 0.6903369086129325 | Evaluating Time: 5 
Epoch: 37 | Iteration number: [10/565] 1% | Training loss: 0.755289363861084
Epoch: 37 | Iteration number: [20/565] 3% | Training loss: 0.7210615664720536
Epoch: 37 | Iteration number: [30/565] 5% | Training loss: 0.7097086230913798
Epoch: 37 | Iteration number: [40/565] 7% | Training loss: 0.7040353521704674
Epoch: 37 | Iteration number: [50/565] 8% | Training loss: 0.7006059694290161
Epoch: 37 | Iteration number: [60/565] 10% | Training loss: 0.6983181178569794
Epoch: 37 | Iteration number: [70/565] 12% | Training loss: 0.6966701873711177
Epoch: 37 | Iteration number: [80/565] 14% | Training loss: 0.695410429686308
Epoch: 37 | Iteration number: [90/565] 15% | Training loss: 0.6944915718502469
Epoch: 37 | Iteration number: [100/565] 17% | Training loss: 0.6937323874235153
Epoch: 37 | Iteration number: [110/565] 19% | Training loss: 0.6930827915668487
Epoch: 37 | Iteration number: [120/565] 21% | Training loss: 0.6925608684619268
Epoch: 37 | Iteration number: [130/565] 23% | Training loss: 0.6921061433278597
Epoch: 37 | Iteration number: [140/565] 24% | Training loss: 0.6917264150721686
Epoch: 37 | Iteration number: [150/565] 26% | Training loss: 0.6914185929298401
Epoch: 37 | Iteration number: [160/565] 28% | Training loss: 0.691118586063385
Epoch: 37 | Iteration number: [170/565] 30% | Training loss: 0.6908403301940245
Epoch: 37 | Iteration number: [180/565] 31% | Training loss: 0.6906176037258572
Epoch: 37 | Iteration number: [190/565] 33% | Training loss: 0.6904358060736405
Epoch: 37 | Iteration number: [200/565] 35% | Training loss: 0.6902478763461113
Epoch: 37 | Iteration number: [210/565] 37% | Training loss: 0.69006952387946
Epoch: 37 | Iteration number: [220/565] 38% | Training loss: 0.6899343360554088
Epoch: 37 | Iteration number: [230/565] 40% | Training loss: 0.6898224726967189
Epoch: 37 | Iteration number: [240/565] 42% | Training loss: 0.6897009717921416
Epoch: 37 | Iteration number: [250/565] 44% | Training loss: 0.68958163022995
Epoch: 37 | Iteration number: [260/565] 46% | Training loss: 0.6894731475756719
Epoch: 37 | Iteration number: [270/565] 47% | Training loss: 0.6893825323493392
Epoch: 37 | Iteration number: [280/565] 49% | Training loss: 0.6892915346792766
Epoch: 37 | Iteration number: [290/565] 51% | Training loss: 0.6891987950637423
Epoch: 37 | Iteration number: [300/565] 53% | Training loss: 0.6891273816426595
Epoch: 37 | Iteration number: [310/565] 54% | Training loss: 0.6890462879211672
Epoch: 37 | Iteration number: [320/565] 56% | Training loss: 0.6889712551608682
Epoch: 37 | Iteration number: [330/565] 58% | Training loss: 0.6889066255453861
Epoch: 37 | Iteration number: [340/565] 60% | Training loss: 0.6888450655867072
Epoch: 37 | Iteration number: [350/565] 61% | Training loss: 0.6887746940340315
Epoch: 37 | Iteration number: [360/565] 63% | Training loss: 0.688728791806433
Epoch: 37 | Iteration number: [370/565] 65% | Training loss: 0.6886785054529035
Epoch: 37 | Iteration number: [380/565] 67% | Training loss: 0.688625294911234
Epoch: 37 | Iteration number: [390/565] 69% | Training loss: 0.6885840562673715
Epoch: 37 | Iteration number: [400/565] 70% | Training loss: 0.6885390715301036
Epoch: 37 | Iteration number: [410/565] 72% | Training loss: 0.6885050077263902
Epoch: 37 | Iteration number: [420/565] 74% | Training loss: 0.6884741693735122
Epoch: 37 | Iteration number: [430/565] 76% | Training loss: 0.6884338507818621
Epoch: 37 | Iteration number: [440/565] 77% | Training loss: 0.688410930741917
Epoch: 37 | Iteration number: [450/565] 79% | Training loss: 0.6883797115749783
Epoch: 37 | Iteration number: [460/565] 81% | Training loss: 0.6883536119823871
Epoch: 37 | Iteration number: [470/565] 83% | Training loss: 0.6883217670816056
Epoch: 37 | Iteration number: [480/565] 84% | Training loss: 0.6882894931981961
Epoch: 37 | Iteration number: [490/565] 86% | Training loss: 0.6882609616736977
Epoch: 37 | Iteration number: [500/565] 88% | Training loss: 0.6882362148761749
Epoch: 37 | Iteration number: [510/565] 90% | Training loss: 0.6882147639405494
Epoch: 37 | Iteration number: [520/565] 92% | Training loss: 0.6881837976666597
Epoch: 37 | Iteration number: [530/565] 93% | Training loss: 0.6881590043598751
Epoch: 37 | Iteration number: [540/565] 95% | Training loss: 0.6881246469638965
Epoch: 37 | Iteration number: [550/565] 97% | Training loss: 0.6881066870689392
Epoch: 37 | Iteration number: [560/565] 99% | Training loss: 0.6880795971623489

 End of epoch: 37 | Train Loss: 0.6868565429628423 | Training Time: 89 

 End of epoch: 37 | Eval Loss: 0.6901599849973407 | Evaluating Time: 5 
Epoch: 38 | Iteration number: [10/565] 1% | Training loss: 0.7552430748939514
Epoch: 38 | Iteration number: [20/565] 3% | Training loss: 0.7208899974822998
Epoch: 38 | Iteration number: [30/565] 5% | Training loss: 0.709434159596761
Epoch: 38 | Iteration number: [40/565] 7% | Training loss: 0.7037632524967193
Epoch: 38 | Iteration number: [50/565] 8% | Training loss: 0.7004238379001617
Epoch: 38 | Iteration number: [60/565] 10% | Training loss: 0.698131741086642
Epoch: 38 | Iteration number: [70/565] 12% | Training loss: 0.6964888623782567
Epoch: 38 | Iteration number: [80/565] 14% | Training loss: 0.6952571965754032
Epoch: 38 | Iteration number: [90/565] 15% | Training loss: 0.6943495141135322
Epoch: 38 | Iteration number: [100/565] 17% | Training loss: 0.6935989689826966
Epoch: 38 | Iteration number: [110/565] 19% | Training loss: 0.6930330628698522
Epoch: 38 | Iteration number: [120/565] 21% | Training loss: 0.6925323083996773
Epoch: 38 | Iteration number: [130/565] 23% | Training loss: 0.6920931357603807
Epoch: 38 | Iteration number: [140/565] 24% | Training loss: 0.6917049505880901
Epoch: 38 | Iteration number: [150/565] 26% | Training loss: 0.6913923339049022
Epoch: 38 | Iteration number: [160/565] 28% | Training loss: 0.691082613542676
Epoch: 38 | Iteration number: [170/565] 30% | Training loss: 0.6908125032396878
Epoch: 38 | Iteration number: [180/565] 31% | Training loss: 0.6905609538157781
Epoch: 38 | Iteration number: [190/565] 33% | Training loss: 0.6903432033563915
Epoch: 38 | Iteration number: [200/565] 35% | Training loss: 0.6901722285151481
Epoch: 38 | Iteration number: [210/565] 37% | Training loss: 0.6900026338441031
Epoch: 38 | Iteration number: [220/565] 38% | Training loss: 0.6898625988851894
Epoch: 38 | Iteration number: [230/565] 40% | Training loss: 0.6897118371465932
Epoch: 38 | Iteration number: [240/565] 42% | Training loss: 0.6895954864720504
Epoch: 38 | Iteration number: [250/565] 44% | Training loss: 0.689479850769043
Epoch: 38 | Iteration number: [260/565] 46% | Training loss: 0.6893904199967018
Epoch: 38 | Iteration number: [270/565] 47% | Training loss: 0.6893043787391098
Epoch: 38 | Iteration number: [280/565] 49% | Training loss: 0.6892176019293922
Epoch: 38 | Iteration number: [290/565] 51% | Training loss: 0.6891297552092323
Epoch: 38 | Iteration number: [300/565] 53% | Training loss: 0.6890545040369034
Epoch: 38 | Iteration number: [310/565] 54% | Training loss: 0.6889814309535488
Epoch: 38 | Iteration number: [320/565] 56% | Training loss: 0.6889165660366416
Epoch: 38 | Iteration number: [330/565] 58% | Training loss: 0.6888570698824796
Epoch: 38 | Iteration number: [340/565] 60% | Training loss: 0.6888053387403488
Epoch: 38 | Iteration number: [350/565] 61% | Training loss: 0.6887603306770325
Epoch: 38 | Iteration number: [360/565] 63% | Training loss: 0.6887178051802847
Epoch: 38 | Iteration number: [370/565] 65% | Training loss: 0.6886661900056376
Epoch: 38 | Iteration number: [380/565] 67% | Training loss: 0.6886099435781178
Epoch: 38 | Iteration number: [390/565] 69% | Training loss: 0.6885587881772947
Epoch: 38 | Iteration number: [400/565] 70% | Training loss: 0.6885101641714573
Epoch: 38 | Iteration number: [410/565] 72% | Training loss: 0.6884661800977661
Epoch: 38 | Iteration number: [420/565] 74% | Training loss: 0.6884289808216549
Epoch: 38 | Iteration number: [430/565] 76% | Training loss: 0.6883975121864053
Epoch: 38 | Iteration number: [440/565] 77% | Training loss: 0.6883625508709388
Epoch: 38 | Iteration number: [450/565] 79% | Training loss: 0.6883314288987054
Epoch: 38 | Iteration number: [460/565] 81% | Training loss: 0.6883031359185343
Epoch: 38 | Iteration number: [470/565] 83% | Training loss: 0.6882774619345969
Epoch: 38 | Iteration number: [480/565] 84% | Training loss: 0.6882487175365289
Epoch: 38 | Iteration number: [490/565] 86% | Training loss: 0.6882195269574924
Epoch: 38 | Iteration number: [500/565] 88% | Training loss: 0.6881908349990845
Epoch: 38 | Iteration number: [510/565] 90% | Training loss: 0.688170355909011
Epoch: 38 | Iteration number: [520/565] 92% | Training loss: 0.6881425984776937
Epoch: 38 | Iteration number: [530/565] 93% | Training loss: 0.6881181539229627
Epoch: 38 | Iteration number: [540/565] 95% | Training loss: 0.6880906452735265
Epoch: 38 | Iteration number: [550/565] 97% | Training loss: 0.688082461682233
Epoch: 38 | Iteration number: [560/565] 99% | Training loss: 0.6880704673273222

 End of epoch: 38 | Train Loss: 0.686852033370364 | Training Time: 89 

 End of epoch: 38 | Eval Loss: 0.6901107515607562 | Evaluating Time: 6 
Epoch: 39 | Iteration number: [10/565] 1% | Training loss: 0.7553748965263367
Epoch: 39 | Iteration number: [20/565] 3% | Training loss: 0.7212846457958222
Epoch: 39 | Iteration number: [30/565] 5% | Training loss: 0.7099089801311493
Epoch: 39 | Iteration number: [40/565] 7% | Training loss: 0.704256683588028
Epoch: 39 | Iteration number: [50/565] 8% | Training loss: 0.7007615756988526
Epoch: 39 | Iteration number: [60/565] 10% | Training loss: 0.6983995258808136
Epoch: 39 | Iteration number: [70/565] 12% | Training loss: 0.6967151556696211
Epoch: 39 | Iteration number: [80/565] 14% | Training loss: 0.695469468086958
Epoch: 39 | Iteration number: [90/565] 15% | Training loss: 0.6944920917352041
Epoch: 39 | Iteration number: [100/565] 17% | Training loss: 0.6936904036998749
Epoch: 39 | Iteration number: [110/565] 19% | Training loss: 0.6930183042179454
Epoch: 39 | Iteration number: [120/565] 21% | Training loss: 0.6924885114034017
Epoch: 39 | Iteration number: [130/565] 23% | Training loss: 0.6920715520015129
Epoch: 39 | Iteration number: [140/565] 24% | Training loss: 0.6917070056710924
Epoch: 39 | Iteration number: [150/565] 26% | Training loss: 0.6913804535071055
Epoch: 39 | Iteration number: [160/565] 28% | Training loss: 0.6910964403301477
Epoch: 39 | Iteration number: [170/565] 30% | Training loss: 0.6908389193170211
Epoch: 39 | Iteration number: [180/565] 31% | Training loss: 0.6906072977516386
Epoch: 39 | Iteration number: [190/565] 33% | Training loss: 0.6904341848273027
Epoch: 39 | Iteration number: [200/565] 35% | Training loss: 0.6902631092071533
Epoch: 39 | Iteration number: [210/565] 37% | Training loss: 0.6900888553687504
Epoch: 39 | Iteration number: [220/565] 38% | Training loss: 0.6899449435147372
Epoch: 39 | Iteration number: [230/565] 40% | Training loss: 0.6898231397504392
Epoch: 39 | Iteration number: [240/565] 42% | Training loss: 0.6897123587628206
Epoch: 39 | Iteration number: [250/565] 44% | Training loss: 0.6895981752872467
Epoch: 39 | Iteration number: [260/565] 46% | Training loss: 0.6894945013981599
Epoch: 39 | Iteration number: [270/565] 47% | Training loss: 0.6893998227737568
Epoch: 39 | Iteration number: [280/565] 49% | Training loss: 0.6893073580094746
Epoch: 39 | Iteration number: [290/565] 51% | Training loss: 0.6892131145658165
Epoch: 39 | Iteration number: [300/565] 53% | Training loss: 0.6891503016153971
Epoch: 39 | Iteration number: [310/565] 54% | Training loss: 0.6890856148735169
Epoch: 39 | Iteration number: [320/565] 56% | Training loss: 0.6890271345153451
Epoch: 39 | Iteration number: [330/565] 58% | Training loss: 0.6889599200451013
Epoch: 39 | Iteration number: [340/565] 60% | Training loss: 0.6888921465943841
Epoch: 39 | Iteration number: [350/565] 61% | Training loss: 0.6888479689189366
Epoch: 39 | Iteration number: [360/565] 63% | Training loss: 0.6887937631871965
Epoch: 39 | Iteration number: [370/565] 65% | Training loss: 0.6887383770298313
Epoch: 39 | Iteration number: [380/565] 67% | Training loss: 0.6886838920806584
Epoch: 39 | Iteration number: [390/565] 69% | Training loss: 0.6886391039078053
Epoch: 39 | Iteration number: [400/565] 70% | Training loss: 0.6885933877527713
Epoch: 39 | Iteration number: [410/565] 72% | Training loss: 0.6885577762999185
Epoch: 39 | Iteration number: [420/565] 74% | Training loss: 0.6885223242498579
Epoch: 39 | Iteration number: [430/565] 76% | Training loss: 0.6884787506835405
Epoch: 39 | Iteration number: [440/565] 77% | Training loss: 0.6884473846717314
Epoch: 39 | Iteration number: [450/565] 79% | Training loss: 0.6884092193179661
Epoch: 39 | Iteration number: [460/565] 81% | Training loss: 0.6883665198865144
Epoch: 39 | Iteration number: [470/565] 83% | Training loss: 0.6883327875999694
Epoch: 39 | Iteration number: [480/565] 84% | Training loss: 0.6883085492998362
Epoch: 39 | Iteration number: [490/565] 86% | Training loss: 0.6882828983725334
Epoch: 39 | Iteration number: [500/565] 88% | Training loss: 0.6882505369186401
Epoch: 39 | Iteration number: [510/565] 90% | Training loss: 0.688223055414125
Epoch: 39 | Iteration number: [520/565] 92% | Training loss: 0.6882059529423714
Epoch: 39 | Iteration number: [530/565] 93% | Training loss: 0.6881690104052706
Epoch: 39 | Iteration number: [540/565] 95% | Training loss: 0.6881484321973942
Epoch: 39 | Iteration number: [550/565] 97% | Training loss: 0.6881202710758556
Epoch: 39 | Iteration number: [560/565] 99% | Training loss: 0.6880911791963237

 End of epoch: 39 | Train Loss: 0.6868686123231871 | Training Time: 89 

 End of epoch: 39 | Eval Loss: 0.6900096535682678 | Evaluating Time: 6 
Epoch: 40 | Iteration number: [10/565] 1% | Training loss: 0.7556621193885803
Epoch: 40 | Iteration number: [20/565] 3% | Training loss: 0.7212142467498779
Epoch: 40 | Iteration number: [30/565] 5% | Training loss: 0.7097445468107859
Epoch: 40 | Iteration number: [40/565] 7% | Training loss: 0.7040728062391282
Epoch: 40 | Iteration number: [50/565] 8% | Training loss: 0.7006242644786834
Epoch: 40 | Iteration number: [60/565] 10% | Training loss: 0.6983096301555634
Epoch: 40 | Iteration number: [70/565] 12% | Training loss: 0.6966832075800214
Epoch: 40 | Iteration number: [80/565] 14% | Training loss: 0.6954469576478004
Epoch: 40 | Iteration number: [90/565] 15% | Training loss: 0.6944659398661719
Epoch: 40 | Iteration number: [100/565] 17% | Training loss: 0.6937178695201873
Epoch: 40 | Iteration number: [110/565] 19% | Training loss: 0.6930753155188127
Epoch: 40 | Iteration number: [120/565] 21% | Training loss: 0.6925386811296145
Epoch: 40 | Iteration number: [130/565] 23% | Training loss: 0.6920913742138789
Epoch: 40 | Iteration number: [140/565] 24% | Training loss: 0.6916888956512723
Epoch: 40 | Iteration number: [150/565] 26% | Training loss: 0.6913638961315155
Epoch: 40 | Iteration number: [160/565] 28% | Training loss: 0.6910832483321429
Epoch: 40 | Iteration number: [170/565] 30% | Training loss: 0.6908311640515047
Epoch: 40 | Iteration number: [180/565] 31% | Training loss: 0.6906306746933195
Epoch: 40 | Iteration number: [190/565] 33% | Training loss: 0.6904431644238924
Epoch: 40 | Iteration number: [200/565] 35% | Training loss: 0.6902739095687866
Epoch: 40 | Iteration number: [210/565] 37% | Training loss: 0.6901179339204516
Epoch: 40 | Iteration number: [220/565] 38% | Training loss: 0.6899655686183409
Epoch: 40 | Iteration number: [230/565] 40% | Training loss: 0.6898483877596648
Epoch: 40 | Iteration number: [240/565] 42% | Training loss: 0.6897228141625722
Epoch: 40 | Iteration number: [250/565] 44% | Training loss: 0.6896048169136048
Epoch: 40 | Iteration number: [260/565] 46% | Training loss: 0.6894909264949652
Epoch: 40 | Iteration number: [270/565] 47% | Training loss: 0.6893858523280533
Epoch: 40 | Iteration number: [280/565] 49% | Training loss: 0.6893100251044546
Epoch: 40 | Iteration number: [290/565] 51% | Training loss: 0.6892328585016316
Epoch: 40 | Iteration number: [300/565] 53% | Training loss: 0.6891456977526347
Epoch: 40 | Iteration number: [310/565] 54% | Training loss: 0.689078866281817
Epoch: 40 | Iteration number: [320/565] 56% | Training loss: 0.6890139462426305
Epoch: 40 | Iteration number: [330/565] 58% | Training loss: 0.6889471969821236
Epoch: 40 | Iteration number: [340/565] 60% | Training loss: 0.6888902413494447
Epoch: 40 | Iteration number: [350/565] 61% | Training loss: 0.6888415445600237
Epoch: 40 | Iteration number: [360/565] 63% | Training loss: 0.6887844095627467
Epoch: 40 | Iteration number: [370/565] 65% | Training loss: 0.6887200584282747
Epoch: 40 | Iteration number: [380/565] 67% | Training loss: 0.6886819999468954
Epoch: 40 | Iteration number: [390/565] 69% | Training loss: 0.688636547479874
Epoch: 40 | Iteration number: [400/565] 70% | Training loss: 0.6885959967970848
Epoch: 40 | Iteration number: [410/565] 72% | Training loss: 0.6885547393705787
Epoch: 40 | Iteration number: [420/565] 74% | Training loss: 0.688517838716507
Epoch: 40 | Iteration number: [430/565] 76% | Training loss: 0.6884838441083597
Epoch: 40 | Iteration number: [440/565] 77% | Training loss: 0.6884424532001668
Epoch: 40 | Iteration number: [450/565] 79% | Training loss: 0.6884032695823246
Epoch: 40 | Iteration number: [460/565] 81% | Training loss: 0.6883770068054614
Epoch: 40 | Iteration number: [470/565] 83% | Training loss: 0.6883458819795162
Epoch: 40 | Iteration number: [480/565] 84% | Training loss: 0.6883161975691716
Epoch: 40 | Iteration number: [490/565] 86% | Training loss: 0.6882899398706397
Epoch: 40 | Iteration number: [500/565] 88% | Training loss: 0.6882667611837388
Epoch: 40 | Iteration number: [510/565] 90% | Training loss: 0.6882389539597081
Epoch: 40 | Iteration number: [520/565] 92% | Training loss: 0.6882044835732534
Epoch: 40 | Iteration number: [530/565] 93% | Training loss: 0.6881804266065922
Epoch: 40 | Iteration number: [540/565] 95% | Training loss: 0.6881491226178629
Epoch: 40 | Iteration number: [550/565] 97% | Training loss: 0.6881235034899278
Epoch: 40 | Iteration number: [560/565] 99% | Training loss: 0.6881002557064806

 End of epoch: 40 | Train Loss: 0.686876106473197 | Training Time: 89 

 End of epoch: 40 | Eval Loss: 0.6900102410997663 | Evaluating Time: 5 
Epoch: 41 | Iteration number: [10/565] 1% | Training loss: 0.7556296825408936
Epoch: 41 | Iteration number: [20/565] 3% | Training loss: 0.7214366853237152
Epoch: 41 | Iteration number: [30/565] 5% | Training loss: 0.7100483516852061
Epoch: 41 | Iteration number: [40/565] 7% | Training loss: 0.704321613907814
Epoch: 41 | Iteration number: [50/565] 8% | Training loss: 0.7008157324790955
Epoch: 41 | Iteration number: [60/565] 10% | Training loss: 0.6985085984071095
Epoch: 41 | Iteration number: [70/565] 12% | Training loss: 0.6968669789178031
Epoch: 41 | Iteration number: [80/565] 14% | Training loss: 0.6955868549644947
Epoch: 41 | Iteration number: [90/565] 15% | Training loss: 0.6946003648969862
Epoch: 41 | Iteration number: [100/565] 17% | Training loss: 0.6937926304340363
Epoch: 41 | Iteration number: [110/565] 19% | Training loss: 0.6931893646717071
Epoch: 41 | Iteration number: [120/565] 21% | Training loss: 0.6926350742578506
Epoch: 41 | Iteration number: [130/565] 23% | Training loss: 0.6921786056115077
Epoch: 41 | Iteration number: [140/565] 24% | Training loss: 0.6918036026614053
Epoch: 41 | Iteration number: [150/565] 26% | Training loss: 0.6914804375171661
Epoch: 41 | Iteration number: [160/565] 28% | Training loss: 0.6911884926259517
Epoch: 41 | Iteration number: [170/565] 30% | Training loss: 0.6909542683292837
Epoch: 41 | Iteration number: [180/565] 31% | Training loss: 0.6906929251220492
Epoch: 41 | Iteration number: [190/565] 33% | Training loss: 0.6905008212516183
Epoch: 41 | Iteration number: [200/565] 35% | Training loss: 0.6902934962511063
Epoch: 41 | Iteration number: [210/565] 37% | Training loss: 0.6901254398482186
Epoch: 41 | Iteration number: [220/565] 38% | Training loss: 0.6899648820812052
Epoch: 41 | Iteration number: [230/565] 40% | Training loss: 0.6898126900196075
Epoch: 41 | Iteration number: [240/565] 42% | Training loss: 0.6896985612809658
Epoch: 41 | Iteration number: [250/565] 44% | Training loss: 0.6895875868797302
Epoch: 41 | Iteration number: [260/565] 46% | Training loss: 0.6894999488041951
Epoch: 41 | Iteration number: [270/565] 47% | Training loss: 0.6894128839174907
Epoch: 41 | Iteration number: [280/565] 49% | Training loss: 0.689323952794075
Epoch: 41 | Iteration number: [290/565] 51% | Training loss: 0.6892467095934112
Epoch: 41 | Iteration number: [300/565] 53% | Training loss: 0.6891804687182108
Epoch: 41 | Iteration number: [310/565] 54% | Training loss: 0.689097217013759
Epoch: 41 | Iteration number: [320/565] 56% | Training loss: 0.6890297936275601
Epoch: 41 | Iteration number: [330/565] 58% | Training loss: 0.6889635167338631
Epoch: 41 | Iteration number: [340/565] 60% | Training loss: 0.6889076932388194
Epoch: 41 | Iteration number: [350/565] 61% | Training loss: 0.6888334584236145
Epoch: 41 | Iteration number: [360/565] 63% | Training loss: 0.6887765799959501
Epoch: 41 | Iteration number: [370/565] 65% | Training loss: 0.68872468777605
Epoch: 41 | Iteration number: [380/565] 67% | Training loss: 0.6886722658809863
Epoch: 41 | Iteration number: [390/565] 69% | Training loss: 0.6886243763642433
Epoch: 41 | Iteration number: [400/565] 70% | Training loss: 0.6885752400755882
Epoch: 41 | Iteration number: [410/565] 72% | Training loss: 0.688533290857222
Epoch: 41 | Iteration number: [420/565] 74% | Training loss: 0.6885048633530026
Epoch: 41 | Iteration number: [430/565] 76% | Training loss: 0.6884659958440204
Epoch: 41 | Iteration number: [440/565] 77% | Training loss: 0.6884274065494538
Epoch: 41 | Iteration number: [450/565] 79% | Training loss: 0.6883932411670685
Epoch: 41 | Iteration number: [460/565] 81% | Training loss: 0.688361494048782
Epoch: 41 | Iteration number: [470/565] 83% | Training loss: 0.6883266630324911
Epoch: 41 | Iteration number: [480/565] 84% | Training loss: 0.6882957136879365
Epoch: 41 | Iteration number: [490/565] 86% | Training loss: 0.6882631338372522
Epoch: 41 | Iteration number: [500/565] 88% | Training loss: 0.6882423603534699
Epoch: 41 | Iteration number: [510/565] 90% | Training loss: 0.6882270637680502
Epoch: 41 | Iteration number: [520/565] 92% | Training loss: 0.6881981651370342
Epoch: 41 | Iteration number: [530/565] 93% | Training loss: 0.6881775547873299
Epoch: 41 | Iteration number: [540/565] 95% | Training loss: 0.6881418090175699
Epoch: 41 | Iteration number: [550/565] 97% | Training loss: 0.6881161556460641
Epoch: 41 | Iteration number: [560/565] 99% | Training loss: 0.6880778724593776

 End of epoch: 41 | Train Loss: 0.6868490719162257 | Training Time: 90 

 End of epoch: 41 | Eval Loss: 0.6900764874049595 | Evaluating Time: 5 
Epoch: 42 | Iteration number: [10/565] 1% | Training loss: 0.7557999610900878
Epoch: 42 | Iteration number: [20/565] 3% | Training loss: 0.7212324470281601
Epoch: 42 | Iteration number: [30/565] 5% | Training loss: 0.7099031885464986
Epoch: 42 | Iteration number: [40/565] 7% | Training loss: 0.7040942385792732
Epoch: 42 | Iteration number: [50/565] 8% | Training loss: 0.7007544362545013
Epoch: 42 | Iteration number: [60/565] 10% | Training loss: 0.6984687725702922
Epoch: 42 | Iteration number: [70/565] 12% | Training loss: 0.696782090834209
Epoch: 42 | Iteration number: [80/565] 14% | Training loss: 0.6955658800899982
Epoch: 42 | Iteration number: [90/565] 15% | Training loss: 0.6945872028668721
Epoch: 42 | Iteration number: [100/565] 17% | Training loss: 0.6938335567712783
Epoch: 42 | Iteration number: [110/565] 19% | Training loss: 0.6931969756429845
Epoch: 42 | Iteration number: [120/565] 21% | Training loss: 0.6926903977990151
Epoch: 42 | Iteration number: [130/565] 23% | Training loss: 0.6922610759735107
Epoch: 42 | Iteration number: [140/565] 24% | Training loss: 0.6919028839894703
Epoch: 42 | Iteration number: [150/565] 26% | Training loss: 0.6915639305114746
Epoch: 42 | Iteration number: [160/565] 28% | Training loss: 0.691312238574028
Epoch: 42 | Iteration number: [170/565] 30% | Training loss: 0.6910619293942171
Epoch: 42 | Iteration number: [180/565] 31% | Training loss: 0.6908215006192525
Epoch: 42 | Iteration number: [190/565] 33% | Training loss: 0.6906052608239023
Epoch: 42 | Iteration number: [200/565] 35% | Training loss: 0.6904087522625924
Epoch: 42 | Iteration number: [210/565] 37% | Training loss: 0.6902462388787951
Epoch: 42 | Iteration number: [220/565] 38% | Training loss: 0.6900975793600083
Epoch: 42 | Iteration number: [230/565] 40% | Training loss: 0.6899405728215756
Epoch: 42 | Iteration number: [240/565] 42% | Training loss: 0.6898043669760228
Epoch: 42 | Iteration number: [250/565] 44% | Training loss: 0.689661679983139
Epoch: 42 | Iteration number: [260/565] 46% | Training loss: 0.6895460651471065
Epoch: 42 | Iteration number: [270/565] 47% | Training loss: 0.6894406217115897
Epoch: 42 | Iteration number: [280/565] 49% | Training loss: 0.6893307089805603
Epoch: 42 | Iteration number: [290/565] 51% | Training loss: 0.6892396645299319
Epoch: 42 | Iteration number: [300/565] 53% | Training loss: 0.6891752173503239
Epoch: 42 | Iteration number: [310/565] 54% | Training loss: 0.6890889177399296
Epoch: 42 | Iteration number: [320/565] 56% | Training loss: 0.6890200452879072
Epoch: 42 | Iteration number: [330/565] 58% | Training loss: 0.6889597403280663
Epoch: 42 | Iteration number: [340/565] 60% | Training loss: 0.6889033370158252
Epoch: 42 | Iteration number: [350/565] 61% | Training loss: 0.6888449249948774
Epoch: 42 | Iteration number: [360/565] 63% | Training loss: 0.6887858867645263
Epoch: 42 | Iteration number: [370/565] 65% | Training loss: 0.688733481394278
Epoch: 42 | Iteration number: [380/565] 67% | Training loss: 0.6886861201963926
Epoch: 42 | Iteration number: [390/565] 69% | Training loss: 0.6886387997712844
Epoch: 42 | Iteration number: [400/565] 70% | Training loss: 0.6885868874192238
Epoch: 42 | Iteration number: [410/565] 72% | Training loss: 0.6885393165960545
Epoch: 42 | Iteration number: [420/565] 74% | Training loss: 0.6884948977402279
Epoch: 42 | Iteration number: [430/565] 76% | Training loss: 0.6884618391824323
Epoch: 42 | Iteration number: [440/565] 77% | Training loss: 0.6884224092418497
Epoch: 42 | Iteration number: [450/565] 79% | Training loss: 0.6883829832077026
Epoch: 42 | Iteration number: [460/565] 81% | Training loss: 0.6883491126091584
Epoch: 42 | Iteration number: [470/565] 83% | Training loss: 0.6883166675871991
Epoch: 42 | Iteration number: [480/565] 84% | Training loss: 0.6882849375406901
Epoch: 42 | Iteration number: [490/565] 86% | Training loss: 0.6882442226215285
Epoch: 42 | Iteration number: [500/565] 88% | Training loss: 0.6882128640413284
Epoch: 42 | Iteration number: [510/565] 90% | Training loss: 0.6881911601506028
Epoch: 42 | Iteration number: [520/565] 92% | Training loss: 0.6881559492303775
Epoch: 42 | Iteration number: [530/565] 93% | Training loss: 0.6881298386825705
Epoch: 42 | Iteration number: [540/565] 95% | Training loss: 0.6881046521442907
Epoch: 42 | Iteration number: [550/565] 97% | Training loss: 0.6880929662964561
Epoch: 42 | Iteration number: [560/565] 99% | Training loss: 0.6880662781851632

 End of epoch: 42 | Train Loss: 0.6868395964656256 | Training Time: 89 

 End of epoch: 42 | Eval Loss: 0.6894839491162982 | Evaluating Time: 6 
Epoch: 43 | Iteration number: [10/565] 1% | Training loss: 0.75505730509758
Epoch: 43 | Iteration number: [20/565] 3% | Training loss: 0.7210542619228363
Epoch: 43 | Iteration number: [30/565] 5% | Training loss: 0.7095531602700551
Epoch: 43 | Iteration number: [40/565] 7% | Training loss: 0.7038002669811249
Epoch: 43 | Iteration number: [50/565] 8% | Training loss: 0.7003688204288483
Epoch: 43 | Iteration number: [60/565] 10% | Training loss: 0.6981421788533528
Epoch: 43 | Iteration number: [70/565] 12% | Training loss: 0.6965431494372232
Epoch: 43 | Iteration number: [80/565] 14% | Training loss: 0.6953627146780491
Epoch: 43 | Iteration number: [90/565] 15% | Training loss: 0.6943617138597701
Epoch: 43 | Iteration number: [100/565] 17% | Training loss: 0.6936510330438614
Epoch: 43 | Iteration number: [110/565] 19% | Training loss: 0.6930250996893103
Epoch: 43 | Iteration number: [120/565] 21% | Training loss: 0.6925110662976901
Epoch: 43 | Iteration number: [130/565] 23% | Training loss: 0.692081820506316
Epoch: 43 | Iteration number: [140/565] 24% | Training loss: 0.6916944993393762
Epoch: 43 | Iteration number: [150/565] 26% | Training loss: 0.6913814425468445
Epoch: 43 | Iteration number: [160/565] 28% | Training loss: 0.6911022543907166
Epoch: 43 | Iteration number: [170/565] 30% | Training loss: 0.6908623449942645
Epoch: 43 | Iteration number: [180/565] 31% | Training loss: 0.6906503452195062
Epoch: 43 | Iteration number: [190/565] 33% | Training loss: 0.6904504258381693
Epoch: 43 | Iteration number: [200/565] 35% | Training loss: 0.6902264758944512
Epoch: 43 | Iteration number: [210/565] 37% | Training loss: 0.6900446082864489
Epoch: 43 | Iteration number: [220/565] 38% | Training loss: 0.6898870779709383
Epoch: 43 | Iteration number: [230/565] 40% | Training loss: 0.6897340409133745
Epoch: 43 | Iteration number: [240/565] 42% | Training loss: 0.6895917984346549
Epoch: 43 | Iteration number: [250/565] 44% | Training loss: 0.6894865057468414
Epoch: 43 | Iteration number: [260/565] 46% | Training loss: 0.6893672665724387
Epoch: 43 | Iteration number: [270/565] 47% | Training loss: 0.6892689788783039
Epoch: 43 | Iteration number: [280/565] 49% | Training loss: 0.6891899449484689
Epoch: 43 | Iteration number: [290/565] 51% | Training loss: 0.689094568737622
Epoch: 43 | Iteration number: [300/565] 53% | Training loss: 0.689025165438652
Epoch: 43 | Iteration number: [310/565] 54% | Training loss: 0.6889711916446686
Epoch: 43 | Iteration number: [320/565] 56% | Training loss: 0.6889029283076524
Epoch: 43 | Iteration number: [330/565] 58% | Training loss: 0.6888474899711031
Epoch: 43 | Iteration number: [340/565] 60% | Training loss: 0.6887731641530991
Epoch: 43 | Iteration number: [350/565] 61% | Training loss: 0.6887296564238412
Epoch: 43 | Iteration number: [360/565] 63% | Training loss: 0.6886786298619376
Epoch: 43 | Iteration number: [370/565] 65% | Training loss: 0.6886249437525466
Epoch: 43 | Iteration number: [380/565] 67% | Training loss: 0.6885854015224858
Epoch: 43 | Iteration number: [390/565] 69% | Training loss: 0.6885406258778695
Epoch: 43 | Iteration number: [400/565] 70% | Training loss: 0.6885036373138428
Epoch: 43 | Iteration number: [410/565] 72% | Training loss: 0.688469995085786
Epoch: 43 | Iteration number: [420/565] 74% | Training loss: 0.6884232380560467
Epoch: 43 | Iteration number: [430/565] 76% | Training loss: 0.6883950922378274
Epoch: 43 | Iteration number: [440/565] 77% | Training loss: 0.6883603962984952
Epoch: 43 | Iteration number: [450/565] 79% | Training loss: 0.6883325160874261
Epoch: 43 | Iteration number: [460/565] 81% | Training loss: 0.6883033166760983
Epoch: 43 | Iteration number: [470/565] 83% | Training loss: 0.6882714308322744
Epoch: 43 | Iteration number: [480/565] 84% | Training loss: 0.6882466421773036
Epoch: 43 | Iteration number: [490/565] 86% | Training loss: 0.6882305369085195
Epoch: 43 | Iteration number: [500/565] 88% | Training loss: 0.6882046414613724
Epoch: 43 | Iteration number: [510/565] 90% | Training loss: 0.6881812253419091
Epoch: 43 | Iteration number: [520/565] 92% | Training loss: 0.6881572576669547
Epoch: 43 | Iteration number: [530/565] 93% | Training loss: 0.6881284083960191
Epoch: 43 | Iteration number: [540/565] 95% | Training loss: 0.6881117233523616
Epoch: 43 | Iteration number: [550/565] 97% | Training loss: 0.688092650716955
Epoch: 43 | Iteration number: [560/565] 99% | Training loss: 0.6880817660263606

 End of epoch: 43 | Train Loss: 0.6868575664748133 | Training Time: 91 

 End of epoch: 43 | Eval Loss: 0.6897791113172259 | Evaluating Time: 6 
Epoch: 44 | Iteration number: [10/565] 1% | Training loss: 0.7559625923633575
Epoch: 44 | Iteration number: [20/565] 3% | Training loss: 0.7214099824428558
Epoch: 44 | Iteration number: [30/565] 5% | Training loss: 0.709928552309672
Epoch: 44 | Iteration number: [40/565] 7% | Training loss: 0.7040287554264069
Epoch: 44 | Iteration number: [50/565] 8% | Training loss: 0.7006208348274231
Epoch: 44 | Iteration number: [60/565] 10% | Training loss: 0.6983844767014186
Epoch: 44 | Iteration number: [70/565] 12% | Training loss: 0.6966980636119843
Epoch: 44 | Iteration number: [80/565] 14% | Training loss: 0.6954570524394512
Epoch: 44 | Iteration number: [90/565] 15% | Training loss: 0.6944905678431194
Epoch: 44 | Iteration number: [100/565] 17% | Training loss: 0.6936855757236481
Epoch: 44 | Iteration number: [110/565] 19% | Training loss: 0.6931013578718359
Epoch: 44 | Iteration number: [120/565] 21% | Training loss: 0.6925657153129577
Epoch: 44 | Iteration number: [130/565] 23% | Training loss: 0.6921029288035173
Epoch: 44 | Iteration number: [140/565] 24% | Training loss: 0.6917210962091174
Epoch: 44 | Iteration number: [150/565] 26% | Training loss: 0.6913691679636638
Epoch: 44 | Iteration number: [160/565] 28% | Training loss: 0.6910917226225137
Epoch: 44 | Iteration number: [170/565] 30% | Training loss: 0.6908377373919767
Epoch: 44 | Iteration number: [180/565] 31% | Training loss: 0.6905985944800906
Epoch: 44 | Iteration number: [190/565] 33% | Training loss: 0.6903972189677389
Epoch: 44 | Iteration number: [200/565] 35% | Training loss: 0.6902241817116738
Epoch: 44 | Iteration number: [210/565] 37% | Training loss: 0.6900659396534874
Epoch: 44 | Iteration number: [220/565] 38% | Training loss: 0.6899247619238766
Epoch: 44 | Iteration number: [230/565] 40% | Training loss: 0.6897753614446391
Epoch: 44 | Iteration number: [240/565] 42% | Training loss: 0.6896316048999628
Epoch: 44 | Iteration number: [250/565] 44% | Training loss: 0.6895346982479096
Epoch: 44 | Iteration number: [260/565] 46% | Training loss: 0.6894253373146058
Epoch: 44 | Iteration number: [270/565] 47% | Training loss: 0.6893310637385757
Epoch: 44 | Iteration number: [280/565] 49% | Training loss: 0.6892387654100146
Epoch: 44 | Iteration number: [290/565] 51% | Training loss: 0.6891454495232681
Epoch: 44 | Iteration number: [300/565] 53% | Training loss: 0.6890742049614589
Epoch: 44 | Iteration number: [310/565] 54% | Training loss: 0.6890069971161504
Epoch: 44 | Iteration number: [320/565] 56% | Training loss: 0.6889304457232356
Epoch: 44 | Iteration number: [330/565] 58% | Training loss: 0.6888766453121647
Epoch: 44 | Iteration number: [340/565] 60% | Training loss: 0.6888226559933495
Epoch: 44 | Iteration number: [350/565] 61% | Training loss: 0.6887807466302599
Epoch: 44 | Iteration number: [360/565] 63% | Training loss: 0.6887340644995371
Epoch: 44 | Iteration number: [370/565] 65% | Training loss: 0.6886863594119613
Epoch: 44 | Iteration number: [380/565] 67% | Training loss: 0.6886398155438272
Epoch: 44 | Iteration number: [390/565] 69% | Training loss: 0.688591075860537
Epoch: 44 | Iteration number: [400/565] 70% | Training loss: 0.6885582728683949
Epoch: 44 | Iteration number: [410/565] 72% | Training loss: 0.6885127660704822
Epoch: 44 | Iteration number: [420/565] 74% | Training loss: 0.6884774629558835
Epoch: 44 | Iteration number: [430/565] 76% | Training loss: 0.6884319915327914
Epoch: 44 | Iteration number: [440/565] 77% | Training loss: 0.6883977059613574
Epoch: 44 | Iteration number: [450/565] 79% | Training loss: 0.6883691704273224
Epoch: 44 | Iteration number: [460/565] 81% | Training loss: 0.6883342507092849
Epoch: 44 | Iteration number: [470/565] 83% | Training loss: 0.6882975215607501
Epoch: 44 | Iteration number: [480/565] 84% | Training loss: 0.6882687824467818
Epoch: 44 | Iteration number: [490/565] 86% | Training loss: 0.688225382566452
Epoch: 44 | Iteration number: [500/565] 88% | Training loss: 0.688206657409668
Epoch: 44 | Iteration number: [510/565] 90% | Training loss: 0.6881820926479265
Epoch: 44 | Iteration number: [520/565] 92% | Training loss: 0.688157596725684
Epoch: 44 | Iteration number: [530/565] 93% | Training loss: 0.688128525018692
Epoch: 44 | Iteration number: [540/565] 95% | Training loss: 0.6881087870509536
Epoch: 44 | Iteration number: [550/565] 97% | Training loss: 0.6880942367423665
Epoch: 44 | Iteration number: [560/565] 99% | Training loss: 0.6880697833640235

 End of epoch: 44 | Train Loss: 0.686844539431344 | Training Time: 90 

 End of epoch: 44 | Eval Loss: 0.6899741802896772 | Evaluating Time: 5 
Epoch: 45 | Iteration number: [10/565] 1% | Training loss: 0.7549229502677918
Epoch: 45 | Iteration number: [20/565] 3% | Training loss: 0.7211035788059235
Epoch: 45 | Iteration number: [30/565] 5% | Training loss: 0.7096141934394836
Epoch: 45 | Iteration number: [40/565] 7% | Training loss: 0.7038050293922424
Epoch: 45 | Iteration number: [50/565] 8% | Training loss: 0.7003609251976013
Epoch: 45 | Iteration number: [60/565] 10% | Training loss: 0.698129325111707
Epoch: 45 | Iteration number: [70/565] 12% | Training loss: 0.6965355481420245
Epoch: 45 | Iteration number: [80/565] 14% | Training loss: 0.6953231893479824
Epoch: 45 | Iteration number: [90/565] 15% | Training loss: 0.6943710724512736
Epoch: 45 | Iteration number: [100/565] 17% | Training loss: 0.6935811412334442
Epoch: 45 | Iteration number: [110/565] 19% | Training loss: 0.6929673753001473
Epoch: 45 | Iteration number: [120/565] 21% | Training loss: 0.6924633041024209
Epoch: 45 | Iteration number: [130/565] 23% | Training loss: 0.69201971750993
Epoch: 45 | Iteration number: [140/565] 24% | Training loss: 0.6916371434926987
Epoch: 45 | Iteration number: [150/565] 26% | Training loss: 0.6913060339291891
Epoch: 45 | Iteration number: [160/565] 28% | Training loss: 0.6910450100898743
Epoch: 45 | Iteration number: [170/565] 30% | Training loss: 0.6907958672327154
Epoch: 45 | Iteration number: [180/565] 31% | Training loss: 0.690562657515208
Epoch: 45 | Iteration number: [190/565] 33% | Training loss: 0.6903691627477345
Epoch: 45 | Iteration number: [200/565] 35% | Training loss: 0.6902000391483307
Epoch: 45 | Iteration number: [210/565] 37% | Training loss: 0.6900625325384594
Epoch: 45 | Iteration number: [220/565] 38% | Training loss: 0.6899154709144072
Epoch: 45 | Iteration number: [230/565] 40% | Training loss: 0.6897781644178473
Epoch: 45 | Iteration number: [240/565] 42% | Training loss: 0.6896551807721456
Epoch: 45 | Iteration number: [250/565] 44% | Training loss: 0.6895375459194183
Epoch: 45 | Iteration number: [260/565] 46% | Training loss: 0.6894428065189948
Epoch: 45 | Iteration number: [270/565] 47% | Training loss: 0.6893163261590181
Epoch: 45 | Iteration number: [280/565] 49% | Training loss: 0.6892392441630364
Epoch: 45 | Iteration number: [290/565] 51% | Training loss: 0.6891618087373931
Epoch: 45 | Iteration number: [300/565] 53% | Training loss: 0.6890735026200613
Epoch: 45 | Iteration number: [310/565] 54% | Training loss: 0.6890021293394027
Epoch: 45 | Iteration number: [320/565] 56% | Training loss: 0.6889410626143218
Epoch: 45 | Iteration number: [330/565] 58% | Training loss: 0.6888824737433231
Epoch: 45 | Iteration number: [340/565] 60% | Training loss: 0.6888299479204065
Epoch: 45 | Iteration number: [350/565] 61% | Training loss: 0.6887766810825893
Epoch: 45 | Iteration number: [360/565] 63% | Training loss: 0.6887177008721563
Epoch: 45 | Iteration number: [370/565] 65% | Training loss: 0.6886776651885058
Epoch: 45 | Iteration number: [380/565] 67% | Training loss: 0.6886310509945217
Epoch: 45 | Iteration number: [390/565] 69% | Training loss: 0.688585132207626
Epoch: 45 | Iteration number: [400/565] 70% | Training loss: 0.688550131469965
Epoch: 45 | Iteration number: [410/565] 72% | Training loss: 0.6885157413598968
Epoch: 45 | Iteration number: [420/565] 74% | Training loss: 0.6884802978663217
Epoch: 45 | Iteration number: [430/565] 76% | Training loss: 0.6884496766467427
Epoch: 45 | Iteration number: [440/565] 77% | Training loss: 0.6884056320244616
Epoch: 45 | Iteration number: [450/565] 79% | Training loss: 0.6883660519123077
Epoch: 45 | Iteration number: [460/565] 81% | Training loss: 0.6883277487495671
Epoch: 45 | Iteration number: [470/565] 83% | Training loss: 0.6882940573895231
Epoch: 45 | Iteration number: [480/565] 84% | Training loss: 0.6882686184098323
Epoch: 45 | Iteration number: [490/565] 86% | Training loss: 0.6882419882988443
Epoch: 45 | Iteration number: [500/565] 88% | Training loss: 0.6882091926336289
Epoch: 45 | Iteration number: [510/565] 90% | Training loss: 0.6881817496290394
Epoch: 45 | Iteration number: [520/565] 92% | Training loss: 0.6881522672680708
Epoch: 45 | Iteration number: [530/565] 93% | Training loss: 0.6881308638824607
Epoch: 45 | Iteration number: [540/565] 95% | Training loss: 0.6881070873251668
Epoch: 45 | Iteration number: [550/565] 97% | Training loss: 0.688087236772884
Epoch: 45 | Iteration number: [560/565] 99% | Training loss: 0.6880634348307337

 End of epoch: 45 | Train Loss: 0.6868348490875379 | Training Time: 87 

 End of epoch: 45 | Eval Loss: 0.6897543498447963 | Evaluating Time: 6 
Epoch: 46 | Iteration number: [10/565] 1% | Training loss: 0.7555930018424988
Epoch: 46 | Iteration number: [20/565] 3% | Training loss: 0.7212604939937591
Epoch: 46 | Iteration number: [30/565] 5% | Training loss: 0.7098180691401164
Epoch: 46 | Iteration number: [40/565] 7% | Training loss: 0.7040475755929947
Epoch: 46 | Iteration number: [50/565] 8% | Training loss: 0.7006649684906006
Epoch: 46 | Iteration number: [60/565] 10% | Training loss: 0.6983118971188863
Epoch: 46 | Iteration number: [70/565] 12% | Training loss: 0.6967181750706264
Epoch: 46 | Iteration number: [80/565] 14% | Training loss: 0.6954842992126942
Epoch: 46 | Iteration number: [90/565] 15% | Training loss: 0.6945671955744426
Epoch: 46 | Iteration number: [100/565] 17% | Training loss: 0.6937515366077424
Epoch: 46 | Iteration number: [110/565] 19% | Training loss: 0.6931108713150025
Epoch: 46 | Iteration number: [120/565] 21% | Training loss: 0.6925784056385358
Epoch: 46 | Iteration number: [130/565] 23% | Training loss: 0.6921564565255092
Epoch: 46 | Iteration number: [140/565] 24% | Training loss: 0.6917736802782332
Epoch: 46 | Iteration number: [150/565] 26% | Training loss: 0.6914722732702892
Epoch: 46 | Iteration number: [160/565] 28% | Training loss: 0.6911946956068278
Epoch: 46 | Iteration number: [170/565] 30% | Training loss: 0.6909347898819868
Epoch: 46 | Iteration number: [180/565] 31% | Training loss: 0.6906966553794013
Epoch: 46 | Iteration number: [190/565] 33% | Training loss: 0.6904601031228116
Epoch: 46 | Iteration number: [200/565] 35% | Training loss: 0.6902930712699891
Epoch: 46 | Iteration number: [210/565] 37% | Training loss: 0.6901438517229898
Epoch: 46 | Iteration number: [220/565] 38% | Training loss: 0.6899920569224791
Epoch: 46 | Iteration number: [230/565] 40% | Training loss: 0.6898420971372853
Epoch: 46 | Iteration number: [240/565] 42% | Training loss: 0.6897163455684979
Epoch: 46 | Iteration number: [250/565] 44% | Training loss: 0.6896035044193268
Epoch: 46 | Iteration number: [260/565] 46% | Training loss: 0.689480735705449
Epoch: 46 | Iteration number: [270/565] 47% | Training loss: 0.6893978816491586
Epoch: 46 | Iteration number: [280/565] 49% | Training loss: 0.6892945938876697
Epoch: 46 | Iteration number: [290/565] 51% | Training loss: 0.6891989066683013
Epoch: 46 | Iteration number: [300/565] 53% | Training loss: 0.6891282792886099
Epoch: 46 | Iteration number: [310/565] 54% | Training loss: 0.689046569793455
Epoch: 46 | Iteration number: [320/565] 56% | Training loss: 0.6889839934185147
Epoch: 46 | Iteration number: [330/565] 58% | Training loss: 0.6889215861306046
Epoch: 46 | Iteration number: [340/565] 60% | Training loss: 0.6888584585750804
Epoch: 46 | Iteration number: [350/565] 61% | Training loss: 0.6888062570776258
Epoch: 46 | Iteration number: [360/565] 63% | Training loss: 0.6887565909160508
Epoch: 46 | Iteration number: [370/565] 65% | Training loss: 0.6886948356757293
Epoch: 46 | Iteration number: [380/565] 67% | Training loss: 0.6886524005940086
Epoch: 46 | Iteration number: [390/565] 69% | Training loss: 0.6886035419427432
Epoch: 46 | Iteration number: [400/565] 70% | Training loss: 0.6885552203655243
Epoch: 46 | Iteration number: [410/565] 72% | Training loss: 0.6884965914051707
Epoch: 46 | Iteration number: [420/565] 74% | Training loss: 0.6884475516421454
Epoch: 46 | Iteration number: [430/565] 76% | Training loss: 0.68842254890952
Epoch: 46 | Iteration number: [440/565] 77% | Training loss: 0.6883948886936361
Epoch: 46 | Iteration number: [450/565] 79% | Training loss: 0.6883592735396491
Epoch: 46 | Iteration number: [460/565] 81% | Training loss: 0.6883202481528987
Epoch: 46 | Iteration number: [470/565] 83% | Training loss: 0.6882894691000594
Epoch: 46 | Iteration number: [480/565] 84% | Training loss: 0.6882618197550376
Epoch: 46 | Iteration number: [490/565] 86% | Training loss: 0.6882315799898031
Epoch: 46 | Iteration number: [500/565] 88% | Training loss: 0.6882012739181519
Epoch: 46 | Iteration number: [510/565] 90% | Training loss: 0.6881688715196124
Epoch: 46 | Iteration number: [520/565] 92% | Training loss: 0.6881368208390016
Epoch: 46 | Iteration number: [530/565] 93% | Training loss: 0.688117779425855
Epoch: 46 | Iteration number: [540/565] 95% | Training loss: 0.6880978055574276
Epoch: 46 | Iteration number: [550/565] 97% | Training loss: 0.6880674651536075
Epoch: 46 | Iteration number: [560/565] 99% | Training loss: 0.6880559284772192

 End of epoch: 46 | Train Loss: 0.6868330682273459 | Training Time: 88 

 End of epoch: 46 | Eval Loss: 0.6897452133042472 | Evaluating Time: 6 
Epoch: 47 | Iteration number: [10/565] 1% | Training loss: 0.7551611483097076
Epoch: 47 | Iteration number: [20/565] 3% | Training loss: 0.7211399435997009
Epoch: 47 | Iteration number: [30/565] 5% | Training loss: 0.7095771431922913
Epoch: 47 | Iteration number: [40/565] 7% | Training loss: 0.7037707313895225
Epoch: 47 | Iteration number: [50/565] 8% | Training loss: 0.7004205501079559
Epoch: 47 | Iteration number: [60/565] 10% | Training loss: 0.6981376886367798
Epoch: 47 | Iteration number: [70/565] 12% | Training loss: 0.6965877005032131
Epoch: 47 | Iteration number: [80/565] 14% | Training loss: 0.6953351251780987
Epoch: 47 | Iteration number: [90/565] 15% | Training loss: 0.6943546533584595
Epoch: 47 | Iteration number: [100/565] 17% | Training loss: 0.6935950148105622
Epoch: 47 | Iteration number: [110/565] 19% | Training loss: 0.6929899844256314
Epoch: 47 | Iteration number: [120/565] 21% | Training loss: 0.6924994687239329
Epoch: 47 | Iteration number: [130/565] 23% | Training loss: 0.6920658776393304
Epoch: 47 | Iteration number: [140/565] 24% | Training loss: 0.691680891598974
Epoch: 47 | Iteration number: [150/565] 26% | Training loss: 0.6913375063737234
Epoch: 47 | Iteration number: [160/565] 28% | Training loss: 0.6910620406270027
Epoch: 47 | Iteration number: [170/565] 30% | Training loss: 0.6908293268259834
Epoch: 47 | Iteration number: [180/565] 31% | Training loss: 0.690616305006875
Epoch: 47 | Iteration number: [190/565] 33% | Training loss: 0.6904394912092309
Epoch: 47 | Iteration number: [200/565] 35% | Training loss: 0.6902243542671204
Epoch: 47 | Iteration number: [210/565] 37% | Training loss: 0.6900672540778205
Epoch: 47 | Iteration number: [220/565] 38% | Training loss: 0.6899443003264341
Epoch: 47 | Iteration number: [230/565] 40% | Training loss: 0.6898017670797265
Epoch: 47 | Iteration number: [240/565] 42% | Training loss: 0.6896927898128827
Epoch: 47 | Iteration number: [250/565] 44% | Training loss: 0.6895574836730957
Epoch: 47 | Iteration number: [260/565] 46% | Training loss: 0.6894518517530881
Epoch: 47 | Iteration number: [270/565] 47% | Training loss: 0.6893594423929851
Epoch: 47 | Iteration number: [280/565] 49% | Training loss: 0.6892651351434844
Epoch: 47 | Iteration number: [290/565] 51% | Training loss: 0.6891632653515914
Epoch: 47 | Iteration number: [300/565] 53% | Training loss: 0.6890841968854269
Epoch: 47 | Iteration number: [310/565] 54% | Training loss: 0.6890208482742309
Epoch: 47 | Iteration number: [320/565] 56% | Training loss: 0.688953617028892
Epoch: 47 | Iteration number: [330/565] 58% | Training loss: 0.6888774212562676
Epoch: 47 | Iteration number: [340/565] 60% | Training loss: 0.6888246488921782
Epoch: 47 | Iteration number: [350/565] 61% | Training loss: 0.6887809216976166
Epoch: 47 | Iteration number: [360/565] 63% | Training loss: 0.6887231805258327
Epoch: 47 | Iteration number: [370/565] 65% | Training loss: 0.6886785425044395
Epoch: 47 | Iteration number: [380/565] 67% | Training loss: 0.688623959767191
Epoch: 47 | Iteration number: [390/565] 69% | Training loss: 0.6885714209996737
Epoch: 47 | Iteration number: [400/565] 70% | Training loss: 0.6885404758155346
Epoch: 47 | Iteration number: [410/565] 72% | Training loss: 0.6885001406437014
Epoch: 47 | Iteration number: [420/565] 74% | Training loss: 0.6884551059632075
Epoch: 47 | Iteration number: [430/565] 76% | Training loss: 0.6884268127208533
Epoch: 47 | Iteration number: [440/565] 77% | Training loss: 0.6883887349204584
Epoch: 47 | Iteration number: [450/565] 79% | Training loss: 0.6883545467588637
Epoch: 47 | Iteration number: [460/565] 81% | Training loss: 0.6883200768543326
Epoch: 47 | Iteration number: [470/565] 83% | Training loss: 0.6882907163589559
Epoch: 47 | Iteration number: [480/565] 84% | Training loss: 0.6882692161947489
Epoch: 47 | Iteration number: [490/565] 86% | Training loss: 0.6882263310101567
Epoch: 47 | Iteration number: [500/565] 88% | Training loss: 0.6881945507526398
Epoch: 47 | Iteration number: [510/565] 90% | Training loss: 0.6881673297461341
Epoch: 47 | Iteration number: [520/565] 92% | Training loss: 0.6881503688601347
Epoch: 47 | Iteration number: [530/565] 93% | Training loss: 0.6881230034918155
Epoch: 47 | Iteration number: [540/565] 95% | Training loss: 0.6881032071731709
Epoch: 47 | Iteration number: [550/565] 97% | Training loss: 0.6880825032971122
Epoch: 47 | Iteration number: [560/565] 99% | Training loss: 0.6880665949412754

 End of epoch: 47 | Train Loss: 0.6868439232353616 | Training Time: 88 

 End of epoch: 47 | Eval Loss: 0.689527554171426 | Evaluating Time: 6 
Epoch: 48 | Iteration number: [10/565] 1% | Training loss: 0.7543690145015717
Epoch: 48 | Iteration number: [20/565] 3% | Training loss: 0.7205048412084579
Epoch: 48 | Iteration number: [30/565] 5% | Training loss: 0.7093563516934712
Epoch: 48 | Iteration number: [40/565] 7% | Training loss: 0.703804112970829
Epoch: 48 | Iteration number: [50/565] 8% | Training loss: 0.7003827142715454
Epoch: 48 | Iteration number: [60/565] 10% | Training loss: 0.6981544494628906
Epoch: 48 | Iteration number: [70/565] 12% | Training loss: 0.6965487011841365
Epoch: 48 | Iteration number: [80/565] 14% | Training loss: 0.6953287065029145
Epoch: 48 | Iteration number: [90/565] 15% | Training loss: 0.6943887697325812
Epoch: 48 | Iteration number: [100/565] 17% | Training loss: 0.6936336094141007
Epoch: 48 | Iteration number: [110/565] 19% | Training loss: 0.6930138327858665
Epoch: 48 | Iteration number: [120/565] 21% | Training loss: 0.6925078173478444
Epoch: 48 | Iteration number: [130/565] 23% | Training loss: 0.6920946607222924
Epoch: 48 | Iteration number: [140/565] 24% | Training loss: 0.6917171772037234
Epoch: 48 | Iteration number: [150/565] 26% | Training loss: 0.6914198744297028
Epoch: 48 | Iteration number: [160/565] 28% | Training loss: 0.6911326684057713
Epoch: 48 | Iteration number: [170/565] 30% | Training loss: 0.6908796962569742
Epoch: 48 | Iteration number: [180/565] 31% | Training loss: 0.6906690484947628
Epoch: 48 | Iteration number: [190/565] 33% | Training loss: 0.6904811237987719
Epoch: 48 | Iteration number: [200/565] 35% | Training loss: 0.6902914851903915
Epoch: 48 | Iteration number: [210/565] 37% | Training loss: 0.6901101350784302
Epoch: 48 | Iteration number: [220/565] 38% | Training loss: 0.6899654686450958
Epoch: 48 | Iteration number: [230/565] 40% | Training loss: 0.6898281413575877
Epoch: 48 | Iteration number: [240/565] 42% | Training loss: 0.689703747878472
Epoch: 48 | Iteration number: [250/565] 44% | Training loss: 0.6895987689495087
Epoch: 48 | Iteration number: [260/565] 46% | Training loss: 0.6894916144701151
Epoch: 48 | Iteration number: [270/565] 47% | Training loss: 0.6894142305409466
Epoch: 48 | Iteration number: [280/565] 49% | Training loss: 0.6893206032259124
Epoch: 48 | Iteration number: [290/565] 51% | Training loss: 0.6892312874054086
Epoch: 48 | Iteration number: [300/565] 53% | Training loss: 0.6891534604628881
Epoch: 48 | Iteration number: [310/565] 54% | Training loss: 0.689085086314909
Epoch: 48 | Iteration number: [320/565] 56% | Training loss: 0.6890153391286731
Epoch: 48 | Iteration number: [330/565] 58% | Training loss: 0.6889465257976994
Epoch: 48 | Iteration number: [340/565] 60% | Training loss: 0.688888707055765
Epoch: 48 | Iteration number: [350/565] 61% | Training loss: 0.6888250635351454
Epoch: 48 | Iteration number: [360/565] 63% | Training loss: 0.6887737340397305
Epoch: 48 | Iteration number: [370/565] 65% | Training loss: 0.6887094690993025
Epoch: 48 | Iteration number: [380/565] 67% | Training loss: 0.6886586702183674
Epoch: 48 | Iteration number: [390/565] 69% | Training loss: 0.6886025555622883
Epoch: 48 | Iteration number: [400/565] 70% | Training loss: 0.6885617733001709
Epoch: 48 | Iteration number: [410/565] 72% | Training loss: 0.6885117352008819
Epoch: 48 | Iteration number: [420/565] 74% | Training loss: 0.6884674011241823
Epoch: 48 | Iteration number: [430/565] 76% | Training loss: 0.6884203716766003
Epoch: 48 | Iteration number: [440/565] 77% | Training loss: 0.6883782995018092
Epoch: 48 | Iteration number: [450/565] 79% | Training loss: 0.6883560823069679
Epoch: 48 | Iteration number: [460/565] 81% | Training loss: 0.6883227203203284
Epoch: 48 | Iteration number: [470/565] 83% | Training loss: 0.688298806357891
Epoch: 48 | Iteration number: [480/565] 84% | Training loss: 0.6882695522159338
Epoch: 48 | Iteration number: [490/565] 86% | Training loss: 0.6882453954949671
Epoch: 48 | Iteration number: [500/565] 88% | Training loss: 0.6882105857133866
Epoch: 48 | Iteration number: [510/565] 90% | Training loss: 0.6881782743276335
Epoch: 48 | Iteration number: [520/565] 92% | Training loss: 0.6881509859974567
Epoch: 48 | Iteration number: [530/565] 93% | Training loss: 0.6881251408244079
Epoch: 48 | Iteration number: [540/565] 95% | Training loss: 0.6881028452405223
Epoch: 48 | Iteration number: [550/565] 97% | Training loss: 0.6880829257314856
Epoch: 48 | Iteration number: [560/565] 99% | Training loss: 0.6880675684128489

 End of epoch: 48 | Train Loss: 0.6868350446751688 | Training Time: 90 

 End of epoch: 48 | Eval Loss: 0.6901036075183323 | Evaluating Time: 6 
Epoch: 49 | Iteration number: [10/565] 1% | Training loss: 0.7554222941398621
Epoch: 49 | Iteration number: [20/565] 3% | Training loss: 0.7212000042200089
Epoch: 49 | Iteration number: [30/565] 5% | Training loss: 0.7097166697184245
Epoch: 49 | Iteration number: [40/565] 7% | Training loss: 0.7039417639374733
Epoch: 49 | Iteration number: [50/565] 8% | Training loss: 0.7005433869361878
Epoch: 49 | Iteration number: [60/565] 10% | Training loss: 0.6982506742080052
Epoch: 49 | Iteration number: [70/565] 12% | Training loss: 0.6966308210577283
Epoch: 49 | Iteration number: [80/565] 14% | Training loss: 0.695431524515152
Epoch: 49 | Iteration number: [90/565] 15% | Training loss: 0.6945246186521318
Epoch: 49 | Iteration number: [100/565] 17% | Training loss: 0.6937051939964295
Epoch: 49 | Iteration number: [110/565] 19% | Training loss: 0.6930775994604285
Epoch: 49 | Iteration number: [120/565] 21% | Training loss: 0.6926070431868235
Epoch: 49 | Iteration number: [130/565] 23% | Training loss: 0.6922005910139818
Epoch: 49 | Iteration number: [140/565] 24% | Training loss: 0.6918220290115902
Epoch: 49 | Iteration number: [150/565] 26% | Training loss: 0.6914978774388632
Epoch: 49 | Iteration number: [160/565] 28% | Training loss: 0.6912203419953584
Epoch: 49 | Iteration number: [170/565] 30% | Training loss: 0.6909762992578394
Epoch: 49 | Iteration number: [180/565] 31% | Training loss: 0.6907707035541535
Epoch: 49 | Iteration number: [190/565] 33% | Training loss: 0.6905552613107782
Epoch: 49 | Iteration number: [200/565] 35% | Training loss: 0.6903586921095848
Epoch: 49 | Iteration number: [210/565] 37% | Training loss: 0.6901849051316579
Epoch: 49 | Iteration number: [220/565] 38% | Training loss: 0.6900327067483555
Epoch: 49 | Iteration number: [230/565] 40% | Training loss: 0.6898788120435632
Epoch: 49 | Iteration number: [240/565] 42% | Training loss: 0.6897327229380608
Epoch: 49 | Iteration number: [250/565] 44% | Training loss: 0.6896204504966735
Epoch: 49 | Iteration number: [260/565] 46% | Training loss: 0.6895117752827131
Epoch: 49 | Iteration number: [270/565] 47% | Training loss: 0.6894014786790919
Epoch: 49 | Iteration number: [280/565] 49% | Training loss: 0.689305020230157
Epoch: 49 | Iteration number: [290/565] 51% | Training loss: 0.6891997399001286
Epoch: 49 | Iteration number: [300/565] 53% | Training loss: 0.6891200623909632
Epoch: 49 | Iteration number: [310/565] 54% | Training loss: 0.6890403626426573
Epoch: 49 | Iteration number: [320/565] 56% | Training loss: 0.6889692900702358
Epoch: 49 | Iteration number: [330/565] 58% | Training loss: 0.6889005489421614
Epoch: 49 | Iteration number: [340/565] 60% | Training loss: 0.6888408799381817
Epoch: 49 | Iteration number: [350/565] 61% | Training loss: 0.6887737504073552
Epoch: 49 | Iteration number: [360/565] 63% | Training loss: 0.688721472521623
Epoch: 49 | Iteration number: [370/565] 65% | Training loss: 0.6886578575984852
Epoch: 49 | Iteration number: [380/565] 67% | Training loss: 0.6886119481764341
Epoch: 49 | Iteration number: [390/565] 69% | Training loss: 0.6885723636700557
Epoch: 49 | Iteration number: [400/565] 70% | Training loss: 0.688536554723978
Epoch: 49 | Iteration number: [410/565] 72% | Training loss: 0.6885042472583491
Epoch: 49 | Iteration number: [420/565] 74% | Training loss: 0.6884551650001889
Epoch: 49 | Iteration number: [430/565] 76% | Training loss: 0.6884241435416909
Epoch: 49 | Iteration number: [440/565] 77% | Training loss: 0.6883826093240217
Epoch: 49 | Iteration number: [450/565] 79% | Training loss: 0.6883509785599179
Epoch: 49 | Iteration number: [460/565] 81% | Training loss: 0.6883112229730772
Epoch: 49 | Iteration number: [470/565] 83% | Training loss: 0.6882781756685136
Epoch: 49 | Iteration number: [480/565] 84% | Training loss: 0.688245864212513
Epoch: 49 | Iteration number: [490/565] 86% | Training loss: 0.688210471187319
Epoch: 49 | Iteration number: [500/565] 88% | Training loss: 0.6881898765563965
Epoch: 49 | Iteration number: [510/565] 90% | Training loss: 0.6881708427971485
Epoch: 49 | Iteration number: [520/565] 92% | Training loss: 0.6881424028139848
Epoch: 49 | Iteration number: [530/565] 93% | Training loss: 0.6881150414358895
Epoch: 49 | Iteration number: [540/565] 95% | Training loss: 0.6880900971315526
Epoch: 49 | Iteration number: [550/565] 97% | Training loss: 0.6880651649561795
Epoch: 49 | Iteration number: [560/565] 99% | Training loss: 0.6880494160311562

 End of epoch: 49 | Train Loss: 0.6868240356445312 | Training Time: 88 

 End of epoch: 49 | Eval Loss: 0.6902550629207066 | Evaluating Time: 6 
Epoch: 50 | Iteration number: [10/565] 1% | Training loss: 0.7556996643543243
Epoch: 50 | Iteration number: [20/565] 3% | Training loss: 0.7214729070663453
Epoch: 50 | Iteration number: [30/565] 5% | Training loss: 0.7099423905213674
Epoch: 50 | Iteration number: [40/565] 7% | Training loss: 0.7041676834225654
Epoch: 50 | Iteration number: [50/565] 8% | Training loss: 0.7006777536869049
Epoch: 50 | Iteration number: [60/565] 10% | Training loss: 0.6983524590730668
Epoch: 50 | Iteration number: [70/565] 12% | Training loss: 0.6966945716312953
Epoch: 50 | Iteration number: [80/565] 14% | Training loss: 0.6955362163484097
Epoch: 50 | Iteration number: [90/565] 15% | Training loss: 0.6946086366971334
Epoch: 50 | Iteration number: [100/565] 17% | Training loss: 0.69378084897995
Epoch: 50 | Iteration number: [110/565] 19% | Training loss: 0.6931455736810511
Epoch: 50 | Iteration number: [120/565] 21% | Training loss: 0.6926198328534762
Epoch: 50 | Iteration number: [130/565] 23% | Training loss: 0.6921696442824143
Epoch: 50 | Iteration number: [140/565] 24% | Training loss: 0.6917592240231377
Epoch: 50 | Iteration number: [150/565] 26% | Training loss: 0.6914582975705464
Epoch: 50 | Iteration number: [160/565] 28% | Training loss: 0.6911611251533032
Epoch: 50 | Iteration number: [170/565] 30% | Training loss: 0.6909114679869484
Epoch: 50 | Iteration number: [180/565] 31% | Training loss: 0.6907025810745028
Epoch: 50 | Iteration number: [190/565] 33% | Training loss: 0.6904783926512066
Epoch: 50 | Iteration number: [200/565] 35% | Training loss: 0.6902986299991608
Epoch: 50 | Iteration number: [210/565] 37% | Training loss: 0.690143799214136
Epoch: 50 | Iteration number: [220/565] 38% | Training loss: 0.6899757685986432
Epoch: 50 | Iteration number: [230/565] 40% | Training loss: 0.6898465161738189
Epoch: 50 | Iteration number: [240/565] 42% | Training loss: 0.6897373313705126
Epoch: 50 | Iteration number: [250/565] 44% | Training loss: 0.6896152517795563
Epoch: 50 | Iteration number: [260/565] 46% | Training loss: 0.6894941969559742
Epoch: 50 | Iteration number: [270/565] 47% | Training loss: 0.6893952623561577
Epoch: 50 | Iteration number: [280/565] 49% | Training loss: 0.6893176227807999
Epoch: 50 | Iteration number: [290/565] 51% | Training loss: 0.6892263169946342
Epoch: 50 | Iteration number: [300/565] 53% | Training loss: 0.689130224386851
Epoch: 50 | Iteration number: [310/565] 54% | Training loss: 0.6890614282700324
Epoch: 50 | Iteration number: [320/565] 56% | Training loss: 0.6890017623081803
Epoch: 50 | Iteration number: [330/565] 58% | Training loss: 0.6889449258645376
Epoch: 50 | Iteration number: [340/565] 60% | Training loss: 0.6888814708765816
Epoch: 50 | Iteration number: [350/565] 61% | Training loss: 0.6888335611139025
Epoch: 50 | Iteration number: [360/565] 63% | Training loss: 0.6887714972098669
Epoch: 50 | Iteration number: [370/565] 65% | Training loss: 0.6887187999648017
Epoch: 50 | Iteration number: [380/565] 67% | Training loss: 0.6886604334178724
Epoch: 50 | Iteration number: [390/565] 69% | Training loss: 0.6886004894207686
Epoch: 50 | Iteration number: [400/565] 70% | Training loss: 0.6885623376071454
Epoch: 50 | Iteration number: [410/565] 72% | Training loss: 0.6885201682404773
Epoch: 50 | Iteration number: [420/565] 74% | Training loss: 0.6884714831908544
Epoch: 50 | Iteration number: [430/565] 76% | Training loss: 0.688435143370961
Epoch: 50 | Iteration number: [440/565] 77% | Training loss: 0.6884000835093584
Epoch: 50 | Iteration number: [450/565] 79% | Training loss: 0.6883603309260474
Epoch: 50 | Iteration number: [460/565] 81% | Training loss: 0.6883299497158631
Epoch: 50 | Iteration number: [470/565] 83% | Training loss: 0.6882975574503554
Epoch: 50 | Iteration number: [480/565] 84% | Training loss: 0.6882641188800335
Epoch: 50 | Iteration number: [490/565] 86% | Training loss: 0.6882292372839791
Epoch: 50 | Iteration number: [500/565] 88% | Training loss: 0.6881971535682678
Epoch: 50 | Iteration number: [510/565] 90% | Training loss: 0.6881728126722224
Epoch: 50 | Iteration number: [520/565] 92% | Training loss: 0.6881439345387312
Epoch: 50 | Iteration number: [530/565] 93% | Training loss: 0.6881146177930652
Epoch: 50 | Iteration number: [540/565] 95% | Training loss: 0.6880901880838253
Epoch: 50 | Iteration number: [550/565] 97% | Training loss: 0.6880612353845076
Epoch: 50 | Iteration number: [560/565] 99% | Training loss: 0.6880476581198829

 End of epoch: 50 | Train Loss: 0.6868220760759 | Training Time: 90 

 End of epoch: 50 | Eval Loss: 0.6899520243917193 | Evaluating Time: 5 
Epoch: 51 | Iteration number: [10/565] 1% | Training loss: 0.7549387156963349
Epoch: 51 | Iteration number: [20/565] 3% | Training loss: 0.7208920001983643
Epoch: 51 | Iteration number: [30/565] 5% | Training loss: 0.7096465349197387
Epoch: 51 | Iteration number: [40/565] 7% | Training loss: 0.7039741173386573
Epoch: 51 | Iteration number: [50/565] 8% | Training loss: 0.7005875396728516
Epoch: 51 | Iteration number: [60/565] 10% | Training loss: 0.6983140935500463
Epoch: 51 | Iteration number: [70/565] 12% | Training loss: 0.6967059620789119
Epoch: 51 | Iteration number: [80/565] 14% | Training loss: 0.695457911491394
Epoch: 51 | Iteration number: [90/565] 15% | Training loss: 0.6945129328303867
Epoch: 51 | Iteration number: [100/565] 17% | Training loss: 0.6937016087770462
Epoch: 51 | Iteration number: [110/565] 19% | Training loss: 0.6930573723532937
Epoch: 51 | Iteration number: [120/565] 21% | Training loss: 0.6925419554114342
Epoch: 51 | Iteration number: [130/565] 23% | Training loss: 0.6921371835928697
Epoch: 51 | Iteration number: [140/565] 24% | Training loss: 0.6917523843901497
Epoch: 51 | Iteration number: [150/565] 26% | Training loss: 0.6913916230201721
Epoch: 51 | Iteration number: [160/565] 28% | Training loss: 0.6910986609756946
Epoch: 51 | Iteration number: [170/565] 30% | Training loss: 0.6908286143751705
Epoch: 51 | Iteration number: [180/565] 31% | Training loss: 0.6906028452846739
Epoch: 51 | Iteration number: [190/565] 33% | Training loss: 0.69038226761316
Epoch: 51 | Iteration number: [200/565] 35% | Training loss: 0.6902017450332641
Epoch: 51 | Iteration number: [210/565] 37% | Training loss: 0.6900343815485637
Epoch: 51 | Iteration number: [220/565] 38% | Training loss: 0.6899005795067007
Epoch: 51 | Iteration number: [230/565] 40% | Training loss: 0.6897674977779389
Epoch: 51 | Iteration number: [240/565] 42% | Training loss: 0.6896473504602909
Epoch: 51 | Iteration number: [250/565] 44% | Training loss: 0.6895343718528748
Epoch: 51 | Iteration number: [260/565] 46% | Training loss: 0.6894144014670298
Epoch: 51 | Iteration number: [270/565] 47% | Training loss: 0.6893172087492766
Epoch: 51 | Iteration number: [280/565] 49% | Training loss: 0.6892220235296658
Epoch: 51 | Iteration number: [290/565] 51% | Training loss: 0.6891293328383873
Epoch: 51 | Iteration number: [300/565] 53% | Training loss: 0.6890695959329605
Epoch: 51 | Iteration number: [310/565] 54% | Training loss: 0.6890047344469254
Epoch: 51 | Iteration number: [320/565] 56% | Training loss: 0.688951407559216
Epoch: 51 | Iteration number: [330/565] 58% | Training loss: 0.6888875309265021
Epoch: 51 | Iteration number: [340/565] 60% | Training loss: 0.688829421471147
Epoch: 51 | Iteration number: [350/565] 61% | Training loss: 0.6887693660599845
Epoch: 51 | Iteration number: [360/565] 63% | Training loss: 0.688708112637202
Epoch: 51 | Iteration number: [370/565] 65% | Training loss: 0.6886535887782638
Epoch: 51 | Iteration number: [380/565] 67% | Training loss: 0.6886101600370909
Epoch: 51 | Iteration number: [390/565] 69% | Training loss: 0.6885655991542033
Epoch: 51 | Iteration number: [400/565] 70% | Training loss: 0.6885213589668274
Epoch: 51 | Iteration number: [410/565] 72% | Training loss: 0.6884792871591522
Epoch: 51 | Iteration number: [420/565] 74% | Training loss: 0.6884331092948005
Epoch: 51 | Iteration number: [430/565] 76% | Training loss: 0.6883930615214414
Epoch: 51 | Iteration number: [440/565] 77% | Training loss: 0.6883660599589347
Epoch: 51 | Iteration number: [450/565] 79% | Training loss: 0.688333305782742
Epoch: 51 | Iteration number: [460/565] 81% | Training loss: 0.688296923170919
Epoch: 51 | Iteration number: [470/565] 83% | Training loss: 0.6882746989422656
Epoch: 51 | Iteration number: [480/565] 84% | Training loss: 0.6882480622579654
Epoch: 51 | Iteration number: [490/565] 86% | Training loss: 0.6882208650209466
Epoch: 51 | Iteration number: [500/565] 88% | Training loss: 0.6881928064823151
Epoch: 51 | Iteration number: [510/565] 90% | Training loss: 0.6881697636024625
Epoch: 51 | Iteration number: [520/565] 92% | Training loss: 0.6881473739559834
Epoch: 51 | Iteration number: [530/565] 93% | Training loss: 0.6881219709819217
Epoch: 51 | Iteration number: [540/565] 95% | Training loss: 0.6881075015774479
Epoch: 51 | Iteration number: [550/565] 97% | Training loss: 0.688073110038584
Epoch: 51 | Iteration number: [560/565] 99% | Training loss: 0.6880468506898199

 End of epoch: 51 | Train Loss: 0.6868216189662967 | Training Time: 89 

 End of epoch: 51 | Eval Loss: 0.6900145752089364 | Evaluating Time: 6 
Epoch: 52 | Iteration number: [10/565] 1% | Training loss: 0.755396431684494
Epoch: 52 | Iteration number: [20/565] 3% | Training loss: 0.721116641163826
Epoch: 52 | Iteration number: [30/565] 5% | Training loss: 0.7097890118757884
Epoch: 52 | Iteration number: [40/565] 7% | Training loss: 0.7040808379650116
Epoch: 52 | Iteration number: [50/565] 8% | Training loss: 0.7006573712825775
Epoch: 52 | Iteration number: [60/565] 10% | Training loss: 0.6983011941115062
Epoch: 52 | Iteration number: [70/565] 12% | Training loss: 0.6966564255101341
Epoch: 52 | Iteration number: [80/565] 14% | Training loss: 0.6954735293984413
Epoch: 52 | Iteration number: [90/565] 15% | Training loss: 0.6944779958989885
Epoch: 52 | Iteration number: [100/565] 17% | Training loss: 0.6936820226907731
Epoch: 52 | Iteration number: [110/565] 19% | Training loss: 0.6930655576966026
Epoch: 52 | Iteration number: [120/565] 21% | Training loss: 0.6925471996267637
Epoch: 52 | Iteration number: [130/565] 23% | Training loss: 0.6921162907893841
Epoch: 52 | Iteration number: [140/565] 24% | Training loss: 0.6917240713323866
Epoch: 52 | Iteration number: [150/565] 26% | Training loss: 0.6913891490300497
Epoch: 52 | Iteration number: [160/565] 28% | Training loss: 0.6910869598388671
Epoch: 52 | Iteration number: [170/565] 30% | Training loss: 0.6908633964903215
Epoch: 52 | Iteration number: [180/565] 31% | Training loss: 0.6906608624590768
Epoch: 52 | Iteration number: [190/565] 33% | Training loss: 0.6904618238147936
Epoch: 52 | Iteration number: [200/565] 35% | Training loss: 0.6902820098400116
Epoch: 52 | Iteration number: [210/565] 37% | Training loss: 0.6901169615132469
Epoch: 52 | Iteration number: [220/565] 38% | Training loss: 0.6899844007058578
Epoch: 52 | Iteration number: [230/565] 40% | Training loss: 0.6898225400758826
Epoch: 52 | Iteration number: [240/565] 42% | Training loss: 0.6896967120468617
Epoch: 52 | Iteration number: [250/565] 44% | Training loss: 0.6895944492816926
Epoch: 52 | Iteration number: [260/565] 46% | Training loss: 0.6894820600748062
Epoch: 52 | Iteration number: [270/565] 47% | Training loss: 0.6893727059717532
Epoch: 52 | Iteration number: [280/565] 49% | Training loss: 0.6892905467322894
Epoch: 52 | Iteration number: [290/565] 51% | Training loss: 0.6892144838283802
Epoch: 52 | Iteration number: [300/565] 53% | Training loss: 0.6891357145706812
Epoch: 52 | Iteration number: [310/565] 54% | Training loss: 0.6890506527116221
Epoch: 52 | Iteration number: [320/565] 56% | Training loss: 0.688997563533485
Epoch: 52 | Iteration number: [330/565] 58% | Training loss: 0.688931422883814
Epoch: 52 | Iteration number: [340/565] 60% | Training loss: 0.6888680894585216
Epoch: 52 | Iteration number: [350/565] 61% | Training loss: 0.6888050212178911
Epoch: 52 | Iteration number: [360/565] 63% | Training loss: 0.6887435914741622
Epoch: 52 | Iteration number: [370/565] 65% | Training loss: 0.6886810289846884
Epoch: 52 | Iteration number: [380/565] 67% | Training loss: 0.6886342920755085
Epoch: 52 | Iteration number: [390/565] 69% | Training loss: 0.6885875868491638
Epoch: 52 | Iteration number: [400/565] 70% | Training loss: 0.6885407282412053
Epoch: 52 | Iteration number: [410/565] 72% | Training loss: 0.6885003092812328
Epoch: 52 | Iteration number: [420/565] 74% | Training loss: 0.688451604899906
Epoch: 52 | Iteration number: [430/565] 76% | Training loss: 0.6884211207545081
Epoch: 52 | Iteration number: [440/565] 77% | Training loss: 0.6883840210058473
Epoch: 52 | Iteration number: [450/565] 79% | Training loss: 0.6883467842472925
Epoch: 52 | Iteration number: [460/565] 81% | Training loss: 0.6883141947829206
Epoch: 52 | Iteration number: [470/565] 83% | Training loss: 0.688283697721806
Epoch: 52 | Iteration number: [480/565] 84% | Training loss: 0.688263809060057
Epoch: 52 | Iteration number: [490/565] 86% | Training loss: 0.6882363139366617
Epoch: 52 | Iteration number: [500/565] 88% | Training loss: 0.6882004605531693
Epoch: 52 | Iteration number: [510/565] 90% | Training loss: 0.6881731258887871
Epoch: 52 | Iteration number: [520/565] 92% | Training loss: 0.6881380249674504
Epoch: 52 | Iteration number: [530/565] 93% | Training loss: 0.6881111019062546
Epoch: 52 | Iteration number: [540/565] 95% | Training loss: 0.6880890953320044
Epoch: 52 | Iteration number: [550/565] 97% | Training loss: 0.6880730967088179
Epoch: 52 | Iteration number: [560/565] 99% | Training loss: 0.6880458859460694

 End of epoch: 52 | Train Loss: 0.6868157107218177 | Training Time: 89 

 End of epoch: 52 | Eval Loss: 0.6897485937391009 | Evaluating Time: 6 
Epoch: 53 | Iteration number: [10/565] 1% | Training loss: 0.7558863937854767
Epoch: 53 | Iteration number: [20/565] 3% | Training loss: 0.7214346319437027
Epoch: 53 | Iteration number: [30/565] 5% | Training loss: 0.7098657250404358
Epoch: 53 | Iteration number: [40/565] 7% | Training loss: 0.704141865670681
Epoch: 53 | Iteration number: [50/565] 8% | Training loss: 0.7006488716602326
Epoch: 53 | Iteration number: [60/565] 10% | Training loss: 0.6983606765667597
Epoch: 53 | Iteration number: [70/565] 12% | Training loss: 0.69669217978205
Epoch: 53 | Iteration number: [80/565] 14% | Training loss: 0.695469581335783
Epoch: 53 | Iteration number: [90/565] 15% | Training loss: 0.6945177919334835
Epoch: 53 | Iteration number: [100/565] 17% | Training loss: 0.6937597435712815
Epoch: 53 | Iteration number: [110/565] 19% | Training loss: 0.6931218152696436
Epoch: 53 | Iteration number: [120/565] 21% | Training loss: 0.6926213562488556
Epoch: 53 | Iteration number: [130/565] 23% | Training loss: 0.6921739757061005
Epoch: 53 | Iteration number: [140/565] 24% | Training loss: 0.6917807485376085
Epoch: 53 | Iteration number: [150/565] 26% | Training loss: 0.6914379795392355
Epoch: 53 | Iteration number: [160/565] 28% | Training loss: 0.6911528542637825
Epoch: 53 | Iteration number: [170/565] 30% | Training loss: 0.6908965899663813
Epoch: 53 | Iteration number: [180/565] 31% | Training loss: 0.690652138988177
Epoch: 53 | Iteration number: [190/565] 33% | Training loss: 0.6904447132035305
Epoch: 53 | Iteration number: [200/565] 35% | Training loss: 0.6902584171295166
Epoch: 53 | Iteration number: [210/565] 37% | Training loss: 0.6900960087776185
Epoch: 53 | Iteration number: [220/565] 38% | Training loss: 0.6899308055639267
Epoch: 53 | Iteration number: [230/565] 40% | Training loss: 0.6898100285426431
Epoch: 53 | Iteration number: [240/565] 42% | Training loss: 0.6896726369857789
Epoch: 53 | Iteration number: [250/565] 44% | Training loss: 0.689563087940216
Epoch: 53 | Iteration number: [260/565] 46% | Training loss: 0.689454761147499
Epoch: 53 | Iteration number: [270/565] 47% | Training loss: 0.6893247383612173
Epoch: 53 | Iteration number: [280/565] 49% | Training loss: 0.6892350956797599
Epoch: 53 | Iteration number: [290/565] 51% | Training loss: 0.6891571828003588
Epoch: 53 | Iteration number: [300/565] 53% | Training loss: 0.6890896801153819
Epoch: 53 | Iteration number: [310/565] 54% | Training loss: 0.6890064799016522
Epoch: 53 | Iteration number: [320/565] 56% | Training loss: 0.6889237882569432
Epoch: 53 | Iteration number: [330/565] 58% | Training loss: 0.6888636845530886
Epoch: 53 | Iteration number: [340/565] 60% | Training loss: 0.6887980580329895
Epoch: 53 | Iteration number: [350/565] 61% | Training loss: 0.6887427413463593
Epoch: 53 | Iteration number: [360/565] 63% | Training loss: 0.6886827886104584
Epoch: 53 | Iteration number: [370/565] 65% | Training loss: 0.6886222974674122
Epoch: 53 | Iteration number: [380/565] 67% | Training loss: 0.6885794303919139
Epoch: 53 | Iteration number: [390/565] 69% | Training loss: 0.6885263111346808
Epoch: 53 | Iteration number: [400/565] 70% | Training loss: 0.6884848654270173
Epoch: 53 | Iteration number: [410/565] 72% | Training loss: 0.6884489417076111
Epoch: 53 | Iteration number: [420/565] 74% | Training loss: 0.6884124659356616
Epoch: 53 | Iteration number: [430/565] 76% | Training loss: 0.6883746027946472
Epoch: 53 | Iteration number: [440/565] 77% | Training loss: 0.6883540032939477
Epoch: 53 | Iteration number: [450/565] 79% | Training loss: 0.6883175167772505
Epoch: 53 | Iteration number: [460/565] 81% | Training loss: 0.6882900635833326
Epoch: 53 | Iteration number: [470/565] 83% | Training loss: 0.6882658860784896
Epoch: 53 | Iteration number: [480/565] 84% | Training loss: 0.6882290804137786
Epoch: 53 | Iteration number: [490/565] 86% | Training loss: 0.6882045123041892
Epoch: 53 | Iteration number: [500/565] 88% | Training loss: 0.6881759077310562
Epoch: 53 | Iteration number: [510/565] 90% | Training loss: 0.6881615230850145
Epoch: 53 | Iteration number: [520/565] 92% | Training loss: 0.6881252060715969
Epoch: 53 | Iteration number: [530/565] 93% | Training loss: 0.6881044039186441
Epoch: 53 | Iteration number: [540/565] 95% | Training loss: 0.6880734996663199
Epoch: 53 | Iteration number: [550/565] 97% | Training loss: 0.6880594476786527
Epoch: 53 | Iteration number: [560/565] 99% | Training loss: 0.6880394144781998

 End of epoch: 53 | Train Loss: 0.6868123857320937 | Training Time: 89 

 End of epoch: 53 | Eval Loss: 0.6894502214023045 | Evaluating Time: 6 
Epoch: 54 | Iteration number: [10/565] 1% | Training loss: 0.7556791961193084
Epoch: 54 | Iteration number: [20/565] 3% | Training loss: 0.7210552215576171
Epoch: 54 | Iteration number: [30/565] 5% | Training loss: 0.7096970419088999
Epoch: 54 | Iteration number: [40/565] 7% | Training loss: 0.704127499461174
Epoch: 54 | Iteration number: [50/565] 8% | Training loss: 0.700691533088684
Epoch: 54 | Iteration number: [60/565] 10% | Training loss: 0.6984194080034892
Epoch: 54 | Iteration number: [70/565] 12% | Training loss: 0.6967749229499272
Epoch: 54 | Iteration number: [80/565] 14% | Training loss: 0.6955265633761882
Epoch: 54 | Iteration number: [90/565] 15% | Training loss: 0.6945589707957374
Epoch: 54 | Iteration number: [100/565] 17% | Training loss: 0.6938183981180192
Epoch: 54 | Iteration number: [110/565] 19% | Training loss: 0.6931565051729028
Epoch: 54 | Iteration number: [120/565] 21% | Training loss: 0.6926421905557315
Epoch: 54 | Iteration number: [130/565] 23% | Training loss: 0.6921797642341027
Epoch: 54 | Iteration number: [140/565] 24% | Training loss: 0.6917626534189497
Epoch: 54 | Iteration number: [150/565] 26% | Training loss: 0.6914025072256724
Epoch: 54 | Iteration number: [160/565] 28% | Training loss: 0.6911524940282107
Epoch: 54 | Iteration number: [170/565] 30% | Training loss: 0.6908989127944497
Epoch: 54 | Iteration number: [180/565] 31% | Training loss: 0.6906866464349959
Epoch: 54 | Iteration number: [190/565] 33% | Training loss: 0.6904750093033439
Epoch: 54 | Iteration number: [200/565] 35% | Training loss: 0.6902952465415001
Epoch: 54 | Iteration number: [210/565] 37% | Training loss: 0.6901398698488871
Epoch: 54 | Iteration number: [220/565] 38% | Training loss: 0.6899832148443569
Epoch: 54 | Iteration number: [230/565] 40% | Training loss: 0.6898653206617936
Epoch: 54 | Iteration number: [240/565] 42% | Training loss: 0.6897445470094681
Epoch: 54 | Iteration number: [250/565] 44% | Training loss: 0.6896162638664246
Epoch: 54 | Iteration number: [260/565] 46% | Training loss: 0.6894974548083085
Epoch: 54 | Iteration number: [270/565] 47% | Training loss: 0.689386248588562
Epoch: 54 | Iteration number: [280/565] 49% | Training loss: 0.6892924474818366
Epoch: 54 | Iteration number: [290/565] 51% | Training loss: 0.6892056783725475
Epoch: 54 | Iteration number: [300/565] 53% | Training loss: 0.6891297439734141
Epoch: 54 | Iteration number: [310/565] 54% | Training loss: 0.6890594393976273
Epoch: 54 | Iteration number: [320/565] 56% | Training loss: 0.6889851497486233
Epoch: 54 | Iteration number: [330/565] 58% | Training loss: 0.6889181151534571
Epoch: 54 | Iteration number: [340/565] 60% | Training loss: 0.6888549364664975
Epoch: 54 | Iteration number: [350/565] 61% | Training loss: 0.6887977387223925
Epoch: 54 | Iteration number: [360/565] 63% | Training loss: 0.6887402986486753
Epoch: 54 | Iteration number: [370/565] 65% | Training loss: 0.688692454711811
Epoch: 54 | Iteration number: [380/565] 67% | Training loss: 0.6886523502437691
Epoch: 54 | Iteration number: [390/565] 69% | Training loss: 0.6886034218164591
Epoch: 54 | Iteration number: [400/565] 70% | Training loss: 0.6885535331070423
Epoch: 54 | Iteration number: [410/565] 72% | Training loss: 0.6884936514424115
Epoch: 54 | Iteration number: [420/565] 74% | Training loss: 0.6884590449787321
Epoch: 54 | Iteration number: [430/565] 76% | Training loss: 0.688421476303145
Epoch: 54 | Iteration number: [440/565] 77% | Training loss: 0.688404672796076
Epoch: 54 | Iteration number: [450/565] 79% | Training loss: 0.6883745132552253
Epoch: 54 | Iteration number: [460/565] 81% | Training loss: 0.6883398627457411
Epoch: 54 | Iteration number: [470/565] 83% | Training loss: 0.6882971572115066
Epoch: 54 | Iteration number: [480/565] 84% | Training loss: 0.6882655642926693
Epoch: 54 | Iteration number: [490/565] 86% | Training loss: 0.6882367918685991
Epoch: 54 | Iteration number: [500/565] 88% | Training loss: 0.6882113896608353
Epoch: 54 | Iteration number: [510/565] 90% | Training loss: 0.6881876409053802
Epoch: 54 | Iteration number: [520/565] 92% | Training loss: 0.6881613538815425
Epoch: 54 | Iteration number: [530/565] 93% | Training loss: 0.6881371669049533
Epoch: 54 | Iteration number: [540/565] 95% | Training loss: 0.6881170748560517
Epoch: 54 | Iteration number: [550/565] 97% | Training loss: 0.6880887006629597
Epoch: 54 | Iteration number: [560/565] 99% | Training loss: 0.6880634825144495

 End of epoch: 54 | Train Loss: 0.6868316236850435 | Training Time: 89 

 End of epoch: 54 | Eval Loss: 0.6899345857756478 | Evaluating Time: 6 
Epoch: 55 | Iteration number: [10/565] 1% | Training loss: 0.7555544018745423
Epoch: 55 | Iteration number: [20/565] 3% | Training loss: 0.7213194012641907
Epoch: 55 | Iteration number: [30/565] 5% | Training loss: 0.70981059273084
Epoch: 55 | Iteration number: [40/565] 7% | Training loss: 0.703988766670227
Epoch: 55 | Iteration number: [50/565] 8% | Training loss: 0.7005807113647461
Epoch: 55 | Iteration number: [60/565] 10% | Training loss: 0.6982673078775405
Epoch: 55 | Iteration number: [70/565] 12% | Training loss: 0.6966157274586814
Epoch: 55 | Iteration number: [80/565] 14% | Training loss: 0.6953744329512119
Epoch: 55 | Iteration number: [90/565] 15% | Training loss: 0.6944049636522929
Epoch: 55 | Iteration number: [100/565] 17% | Training loss: 0.6936396712064743
Epoch: 55 | Iteration number: [110/565] 19% | Training loss: 0.6930438366803255
Epoch: 55 | Iteration number: [120/565] 21% | Training loss: 0.6925039266546568
Epoch: 55 | Iteration number: [130/565] 23% | Training loss: 0.6920707111175244
Epoch: 55 | Iteration number: [140/565] 24% | Training loss: 0.6917080811091831
Epoch: 55 | Iteration number: [150/565] 26% | Training loss: 0.6913709465662639
Epoch: 55 | Iteration number: [160/565] 28% | Training loss: 0.691085484623909
Epoch: 55 | Iteration number: [170/565] 30% | Training loss: 0.6908388923196231
Epoch: 55 | Iteration number: [180/565] 31% | Training loss: 0.6905928164720535
Epoch: 55 | Iteration number: [190/565] 33% | Training loss: 0.690389610277979
Epoch: 55 | Iteration number: [200/565] 35% | Training loss: 0.6902051848173142
Epoch: 55 | Iteration number: [210/565] 37% | Training loss: 0.6900198439757029
Epoch: 55 | Iteration number: [220/565] 38% | Training loss: 0.6898581304333427
Epoch: 55 | Iteration number: [230/565] 40% | Training loss: 0.6897125259689663
Epoch: 55 | Iteration number: [240/565] 42% | Training loss: 0.6896151162683963
Epoch: 55 | Iteration number: [250/565] 44% | Training loss: 0.6895067393779755
Epoch: 55 | Iteration number: [260/565] 46% | Training loss: 0.6894086720851752
Epoch: 55 | Iteration number: [270/565] 47% | Training loss: 0.6893093532986111
Epoch: 55 | Iteration number: [280/565] 49% | Training loss: 0.6892196806413787
Epoch: 55 | Iteration number: [290/565] 51% | Training loss: 0.6891459810322729
Epoch: 55 | Iteration number: [300/565] 53% | Training loss: 0.6890674948692321
Epoch: 55 | Iteration number: [310/565] 54% | Training loss: 0.6889982192747055
Epoch: 55 | Iteration number: [320/565] 56% | Training loss: 0.6889395952224732
Epoch: 55 | Iteration number: [330/565] 58% | Training loss: 0.6888820010604281
Epoch: 55 | Iteration number: [340/565] 60% | Training loss: 0.6888256665538339
Epoch: 55 | Iteration number: [350/565] 61% | Training loss: 0.6887651036466871
Epoch: 55 | Iteration number: [360/565] 63% | Training loss: 0.6886967895759477
Epoch: 55 | Iteration number: [370/565] 65% | Training loss: 0.6886420767049531
Epoch: 55 | Iteration number: [380/565] 67% | Training loss: 0.6885857955405587
Epoch: 55 | Iteration number: [390/565] 69% | Training loss: 0.6885294850055989
Epoch: 55 | Iteration number: [400/565] 70% | Training loss: 0.6884896855056286
Epoch: 55 | Iteration number: [410/565] 72% | Training loss: 0.6884575410587032
Epoch: 55 | Iteration number: [420/565] 74% | Training loss: 0.6884081125259399
Epoch: 55 | Iteration number: [430/565] 76% | Training loss: 0.6883836886217428
Epoch: 55 | Iteration number: [440/565] 77% | Training loss: 0.6883421079678969
Epoch: 55 | Iteration number: [450/565] 79% | Training loss: 0.6883026013109419
Epoch: 55 | Iteration number: [460/565] 81% | Training loss: 0.6882738556550897
Epoch: 55 | Iteration number: [470/565] 83% | Training loss: 0.6882413459585068
Epoch: 55 | Iteration number: [480/565] 84% | Training loss: 0.6882120077808698
Epoch: 55 | Iteration number: [490/565] 86% | Training loss: 0.6881859757462326
Epoch: 55 | Iteration number: [500/565] 88% | Training loss: 0.6881565492153168
Epoch: 55 | Iteration number: [510/565] 90% | Training loss: 0.6881339509113162
Epoch: 55 | Iteration number: [520/565] 92% | Training loss: 0.6881210055488807
Epoch: 55 | Iteration number: [530/565] 93% | Training loss: 0.6881080308050479
Epoch: 55 | Iteration number: [540/565] 95% | Training loss: 0.6880836480193668
Epoch: 55 | Iteration number: [550/565] 97% | Training loss: 0.6880601776729931
Epoch: 55 | Iteration number: [560/565] 99% | Training loss: 0.6880405107779163

 End of epoch: 55 | Train Loss: 0.6868193783591279 | Training Time: 88 

 End of epoch: 55 | Eval Loss: 0.6897644996643066 | Evaluating Time: 6 
Epoch: 56 | Iteration number: [10/565] 1% | Training loss: 0.7555644512176514
Epoch: 56 | Iteration number: [20/565] 3% | Training loss: 0.7213808059692383
Epoch: 56 | Iteration number: [30/565] 5% | Training loss: 0.7099792381127675
Epoch: 56 | Iteration number: [40/565] 7% | Training loss: 0.7042387202382088
Epoch: 56 | Iteration number: [50/565] 8% | Training loss: 0.7007980823516846
Epoch: 56 | Iteration number: [60/565] 10% | Training loss: 0.6984198878208796
Epoch: 56 | Iteration number: [70/565] 12% | Training loss: 0.6968071120125907
Epoch: 56 | Iteration number: [80/565] 14% | Training loss: 0.695491011440754
Epoch: 56 | Iteration number: [90/565] 15% | Training loss: 0.6944708029429117
Epoch: 56 | Iteration number: [100/565] 17% | Training loss: 0.6936883276700974
Epoch: 56 | Iteration number: [110/565] 19% | Training loss: 0.6930445205081593
Epoch: 56 | Iteration number: [120/565] 21% | Training loss: 0.6925383195281029
Epoch: 56 | Iteration number: [130/565] 23% | Training loss: 0.692079083277629
Epoch: 56 | Iteration number: [140/565] 24% | Training loss: 0.6917022871119636
Epoch: 56 | Iteration number: [150/565] 26% | Training loss: 0.6913833061854044
Epoch: 56 | Iteration number: [160/565] 28% | Training loss: 0.6910725265741349
Epoch: 56 | Iteration number: [170/565] 30% | Training loss: 0.690795782734366
Epoch: 56 | Iteration number: [180/565] 31% | Training loss: 0.6905742744604747
Epoch: 56 | Iteration number: [190/565] 33% | Training loss: 0.6903811323015313
Epoch: 56 | Iteration number: [200/565] 35% | Training loss: 0.6902002146840096
Epoch: 56 | Iteration number: [210/565] 37% | Training loss: 0.6900369607266925
Epoch: 56 | Iteration number: [220/565] 38% | Training loss: 0.6898696289821105
Epoch: 56 | Iteration number: [230/565] 40% | Training loss: 0.6897604657256085
Epoch: 56 | Iteration number: [240/565] 42% | Training loss: 0.6896388289829095
Epoch: 56 | Iteration number: [250/565] 44% | Training loss: 0.6895303902626038
Epoch: 56 | Iteration number: [260/565] 46% | Training loss: 0.6894419385836674
Epoch: 56 | Iteration number: [270/565] 47% | Training loss: 0.6893586244848039
Epoch: 56 | Iteration number: [280/565] 49% | Training loss: 0.689273361648832
Epoch: 56 | Iteration number: [290/565] 51% | Training loss: 0.6891882658004761
Epoch: 56 | Iteration number: [300/565] 53% | Training loss: 0.6891196306546529
Epoch: 56 | Iteration number: [310/565] 54% | Training loss: 0.6890554981846964
Epoch: 56 | Iteration number: [320/565] 56% | Training loss: 0.6889911219477654
Epoch: 56 | Iteration number: [330/565] 58% | Training loss: 0.6889247845519673
Epoch: 56 | Iteration number: [340/565] 60% | Training loss: 0.688861839911517
Epoch: 56 | Iteration number: [350/565] 61% | Training loss: 0.6887894221714564
Epoch: 56 | Iteration number: [360/565] 63% | Training loss: 0.6887442610330052
Epoch: 56 | Iteration number: [370/565] 65% | Training loss: 0.6886994508472649
Epoch: 56 | Iteration number: [380/565] 67% | Training loss: 0.688655991146439
Epoch: 56 | Iteration number: [390/565] 69% | Training loss: 0.6886108578779758
Epoch: 56 | Iteration number: [400/565] 70% | Training loss: 0.6885531418025493
Epoch: 56 | Iteration number: [410/565] 72% | Training loss: 0.6885004958001578
Epoch: 56 | Iteration number: [420/565] 74% | Training loss: 0.6884544362624486
Epoch: 56 | Iteration number: [430/565] 76% | Training loss: 0.6884044850981512
Epoch: 56 | Iteration number: [440/565] 77% | Training loss: 0.688366423547268
Epoch: 56 | Iteration number: [450/565] 79% | Training loss: 0.688329002459844
Epoch: 56 | Iteration number: [460/565] 81% | Training loss: 0.6883021911849146
Epoch: 56 | Iteration number: [470/565] 83% | Training loss: 0.6882665419832189
Epoch: 56 | Iteration number: [480/565] 84% | Training loss: 0.6882387225826582
Epoch: 56 | Iteration number: [490/565] 86% | Training loss: 0.6882131794277503
Epoch: 56 | Iteration number: [500/565] 88% | Training loss: 0.688194733262062
Epoch: 56 | Iteration number: [510/565] 90% | Training loss: 0.6881703397806953
Epoch: 56 | Iteration number: [520/565] 92% | Training loss: 0.6881420361307952
Epoch: 56 | Iteration number: [530/565] 93% | Training loss: 0.6881228165806464
Epoch: 56 | Iteration number: [540/565] 95% | Training loss: 0.6880967173311445
Epoch: 56 | Iteration number: [550/565] 97% | Training loss: 0.688072970346971
Epoch: 56 | Iteration number: [560/565] 99% | Training loss: 0.6880556281123843

 End of epoch: 56 | Train Loss: 0.6868313197541026 | Training Time: 89 

 End of epoch: 56 | Eval Loss: 0.6899569034576416 | Evaluating Time: 6 
Epoch: 57 | Iteration number: [10/565] 1% | Training loss: 0.7553402543067932
Epoch: 57 | Iteration number: [20/565] 3% | Training loss: 0.7211721688508987
Epoch: 57 | Iteration number: [30/565] 5% | Training loss: 0.709914364417394
Epoch: 57 | Iteration number: [40/565] 7% | Training loss: 0.7040176272392273
Epoch: 57 | Iteration number: [50/565] 8% | Training loss: 0.700538901090622
Epoch: 57 | Iteration number: [60/565] 10% | Training loss: 0.6982258280118306
Epoch: 57 | Iteration number: [70/565] 12% | Training loss: 0.6966646722384862
Epoch: 57 | Iteration number: [80/565] 14% | Training loss: 0.6954557597637177
Epoch: 57 | Iteration number: [90/565] 15% | Training loss: 0.6944639735751682
Epoch: 57 | Iteration number: [100/565] 17% | Training loss: 0.6936902302503586
Epoch: 57 | Iteration number: [110/565] 19% | Training loss: 0.6930809503251856
Epoch: 57 | Iteration number: [120/565] 21% | Training loss: 0.6925466656684875
Epoch: 57 | Iteration number: [130/565] 23% | Training loss: 0.6920688514526073
Epoch: 57 | Iteration number: [140/565] 24% | Training loss: 0.6916996483291898
Epoch: 57 | Iteration number: [150/565] 26% | Training loss: 0.6913500134150187
Epoch: 57 | Iteration number: [160/565] 28% | Training loss: 0.6910414043813944
Epoch: 57 | Iteration number: [170/565] 30% | Training loss: 0.6908126708339243
Epoch: 57 | Iteration number: [180/565] 31% | Training loss: 0.6906093100706736
Epoch: 57 | Iteration number: [190/565] 33% | Training loss: 0.6903876019151587
Epoch: 57 | Iteration number: [200/565] 35% | Training loss: 0.6902176809310913
Epoch: 57 | Iteration number: [210/565] 37% | Training loss: 0.6900586500054314
Epoch: 57 | Iteration number: [220/565] 38% | Training loss: 0.6899038902737877
Epoch: 57 | Iteration number: [230/565] 40% | Training loss: 0.6897494945837104
Epoch: 57 | Iteration number: [240/565] 42% | Training loss: 0.6896333798766137
Epoch: 57 | Iteration number: [250/565] 44% | Training loss: 0.689531683921814
Epoch: 57 | Iteration number: [260/565] 46% | Training loss: 0.6894185345906477
Epoch: 57 | Iteration number: [270/565] 47% | Training loss: 0.6893094559510549
Epoch: 57 | Iteration number: [280/565] 49% | Training loss: 0.6892234563827515
Epoch: 57 | Iteration number: [290/565] 51% | Training loss: 0.689153876592373
Epoch: 57 | Iteration number: [300/565] 53% | Training loss: 0.6890802562236786
Epoch: 57 | Iteration number: [310/565] 54% | Training loss: 0.6890136065021638
Epoch: 57 | Iteration number: [320/565] 56% | Training loss: 0.6889465594664216
Epoch: 57 | Iteration number: [330/565] 58% | Training loss: 0.6888792854366881
Epoch: 57 | Iteration number: [340/565] 60% | Training loss: 0.688828665544005
Epoch: 57 | Iteration number: [350/565] 61% | Training loss: 0.6887811192444393
Epoch: 57 | Iteration number: [360/565] 63% | Training loss: 0.6887218851182196
Epoch: 57 | Iteration number: [370/565] 65% | Training loss: 0.6886647205095033
Epoch: 57 | Iteration number: [380/565] 67% | Training loss: 0.6886083000584653
Epoch: 57 | Iteration number: [390/565] 69% | Training loss: 0.6885725391216767
Epoch: 57 | Iteration number: [400/565] 70% | Training loss: 0.688523196130991
Epoch: 57 | Iteration number: [410/565] 72% | Training loss: 0.6884785814983089
Epoch: 57 | Iteration number: [420/565] 74% | Training loss: 0.6884394854307174
Epoch: 57 | Iteration number: [430/565] 76% | Training loss: 0.6883929607480072
Epoch: 57 | Iteration number: [440/565] 77% | Training loss: 0.688359321653843
Epoch: 57 | Iteration number: [450/565] 79% | Training loss: 0.6883277931478289
Epoch: 57 | Iteration number: [460/565] 81% | Training loss: 0.6882899649765181
Epoch: 57 | Iteration number: [470/565] 83% | Training loss: 0.6882501600904668
Epoch: 57 | Iteration number: [480/565] 84% | Training loss: 0.6882273346185684
Epoch: 57 | Iteration number: [490/565] 86% | Training loss: 0.6882025526494396
Epoch: 57 | Iteration number: [500/565] 88% | Training loss: 0.6881728110313415
Epoch: 57 | Iteration number: [510/565] 90% | Training loss: 0.688146134334452
Epoch: 57 | Iteration number: [520/565] 92% | Training loss: 0.6881182806996199
Epoch: 57 | Iteration number: [530/565] 93% | Training loss: 0.6880883879256698
Epoch: 57 | Iteration number: [540/565] 95% | Training loss: 0.688069290805746
Epoch: 57 | Iteration number: [550/565] 97% | Training loss: 0.6880464338172566
Epoch: 57 | Iteration number: [560/565] 99% | Training loss: 0.6880308053323201

 End of epoch: 57 | Train Loss: 0.6868017085885579 | Training Time: 87 

 End of epoch: 57 | Eval Loss: 0.6892823321478707 | Evaluating Time: 6 
Epoch: 58 | Iteration number: [10/565] 1% | Training loss: 0.7552770376205444
Epoch: 58 | Iteration number: [20/565] 3% | Training loss: 0.7211373180150986
Epoch: 58 | Iteration number: [30/565] 5% | Training loss: 0.7096173365910848
Epoch: 58 | Iteration number: [40/565] 7% | Training loss: 0.7038801476359368
Epoch: 58 | Iteration number: [50/565] 8% | Training loss: 0.7005103600025177
Epoch: 58 | Iteration number: [60/565] 10% | Training loss: 0.6981991082429886
Epoch: 58 | Iteration number: [70/565] 12% | Training loss: 0.6966454650674547
Epoch: 58 | Iteration number: [80/565] 14% | Training loss: 0.695397237688303
Epoch: 58 | Iteration number: [90/565] 15% | Training loss: 0.6944366441832648
Epoch: 58 | Iteration number: [100/565] 17% | Training loss: 0.693656525015831
Epoch: 58 | Iteration number: [110/565] 19% | Training loss: 0.6930396356365898
Epoch: 58 | Iteration number: [120/565] 21% | Training loss: 0.6924852435787519
Epoch: 58 | Iteration number: [130/565] 23% | Training loss: 0.6920619345628298
Epoch: 58 | Iteration number: [140/565] 24% | Training loss: 0.6916591248341969
Epoch: 58 | Iteration number: [150/565] 26% | Training loss: 0.691325059334437
Epoch: 58 | Iteration number: [160/565] 28% | Training loss: 0.6910450991243124
Epoch: 58 | Iteration number: [170/565] 30% | Training loss: 0.690800513940699
Epoch: 58 | Iteration number: [180/565] 31% | Training loss: 0.6905718816651238
Epoch: 58 | Iteration number: [190/565] 33% | Training loss: 0.6903770151891206
Epoch: 58 | Iteration number: [200/565] 35% | Training loss: 0.6901942232251167
Epoch: 58 | Iteration number: [210/565] 37% | Training loss: 0.6900442668369838
Epoch: 58 | Iteration number: [220/565] 38% | Training loss: 0.6898965578187596
Epoch: 58 | Iteration number: [230/565] 40% | Training loss: 0.6897656697293987
Epoch: 58 | Iteration number: [240/565] 42% | Training loss: 0.6896467586358388
Epoch: 58 | Iteration number: [250/565] 44% | Training loss: 0.6895354199409485
Epoch: 58 | Iteration number: [260/565] 46% | Training loss: 0.6894318988690009
Epoch: 58 | Iteration number: [270/565] 47% | Training loss: 0.6893446981906891
Epoch: 58 | Iteration number: [280/565] 49% | Training loss: 0.6892558762005397
Epoch: 58 | Iteration number: [290/565] 51% | Training loss: 0.6891819951863124
Epoch: 58 | Iteration number: [300/565] 53% | Training loss: 0.6890954790512721
Epoch: 58 | Iteration number: [310/565] 54% | Training loss: 0.6890040818722017
Epoch: 58 | Iteration number: [320/565] 56% | Training loss: 0.6889335505664349
Epoch: 58 | Iteration number: [330/565] 58% | Training loss: 0.6888747630697308
Epoch: 58 | Iteration number: [340/565] 60% | Training loss: 0.688826126035522
Epoch: 58 | Iteration number: [350/565] 61% | Training loss: 0.6887704477991377
Epoch: 58 | Iteration number: [360/565] 63% | Training loss: 0.6887248628669315
Epoch: 58 | Iteration number: [370/565] 65% | Training loss: 0.6886703214129886
Epoch: 58 | Iteration number: [380/565] 67% | Training loss: 0.6886209164795123
Epoch: 58 | Iteration number: [390/565] 69% | Training loss: 0.6885701906986725
Epoch: 58 | Iteration number: [400/565] 70% | Training loss: 0.6885249914228916
Epoch: 58 | Iteration number: [410/565] 72% | Training loss: 0.6884915207944265
Epoch: 58 | Iteration number: [420/565] 74% | Training loss: 0.688448891043663
Epoch: 58 | Iteration number: [430/565] 76% | Training loss: 0.6884031355381012
Epoch: 58 | Iteration number: [440/565] 77% | Training loss: 0.6883542916991494
Epoch: 58 | Iteration number: [450/565] 79% | Training loss: 0.6883274070421854
Epoch: 58 | Iteration number: [460/565] 81% | Training loss: 0.6882929363976354
Epoch: 58 | Iteration number: [470/565] 83% | Training loss: 0.6882652076000862
Epoch: 58 | Iteration number: [480/565] 84% | Training loss: 0.6882358316332102
Epoch: 58 | Iteration number: [490/565] 86% | Training loss: 0.6882033841950553
Epoch: 58 | Iteration number: [500/565] 88% | Training loss: 0.6881818376779556
Epoch: 58 | Iteration number: [510/565] 90% | Training loss: 0.6881649946465211
Epoch: 58 | Iteration number: [520/565] 92% | Training loss: 0.688132880628109
Epoch: 58 | Iteration number: [530/565] 93% | Training loss: 0.6881049167435124
Epoch: 58 | Iteration number: [540/565] 95% | Training loss: 0.6880818832803656
Epoch: 58 | Iteration number: [550/565] 97% | Training loss: 0.6880629352006046
Epoch: 58 | Iteration number: [560/565] 99% | Training loss: 0.688031150081328

 End of epoch: 58 | Train Loss: 0.6868032442784943 | Training Time: 89 

 End of epoch: 58 | Eval Loss: 0.689344048500061 | Evaluating Time: 6 
Epoch: 59 | Iteration number: [10/565] 1% | Training loss: 0.7554728865623475
Epoch: 59 | Iteration number: [20/565] 3% | Training loss: 0.7208730161190033
Epoch: 59 | Iteration number: [30/565] 5% | Training loss: 0.7094055891036988
Epoch: 59 | Iteration number: [40/565] 7% | Training loss: 0.7037836328148842
Epoch: 59 | Iteration number: [50/565] 8% | Training loss: 0.7004163539409638
Epoch: 59 | Iteration number: [60/565] 10% | Training loss: 0.6980681926012039
Epoch: 59 | Iteration number: [70/565] 12% | Training loss: 0.6964314043521881
Epoch: 59 | Iteration number: [80/565] 14% | Training loss: 0.6952707178890705
Epoch: 59 | Iteration number: [90/565] 15% | Training loss: 0.6943354070186615
Epoch: 59 | Iteration number: [100/565] 17% | Training loss: 0.6935490429401397
Epoch: 59 | Iteration number: [110/565] 19% | Training loss: 0.6929713541811163
Epoch: 59 | Iteration number: [120/565] 21% | Training loss: 0.6924630353848139
Epoch: 59 | Iteration number: [130/565] 23% | Training loss: 0.6920364485337184
Epoch: 59 | Iteration number: [140/565] 24% | Training loss: 0.6916227847337723
Epoch: 59 | Iteration number: [150/565] 26% | Training loss: 0.6913104085127513
Epoch: 59 | Iteration number: [160/565] 28% | Training loss: 0.691009996458888
Epoch: 59 | Iteration number: [170/565] 30% | Training loss: 0.6907491322825937
Epoch: 59 | Iteration number: [180/565] 31% | Training loss: 0.6905249188343684
Epoch: 59 | Iteration number: [190/565] 33% | Training loss: 0.6903357747354005
Epoch: 59 | Iteration number: [200/565] 35% | Training loss: 0.6901630383729934
Epoch: 59 | Iteration number: [210/565] 37% | Training loss: 0.690003921588262
Epoch: 59 | Iteration number: [220/565] 38% | Training loss: 0.6898588649251244
Epoch: 59 | Iteration number: [230/565] 40% | Training loss: 0.6897314862064693
Epoch: 59 | Iteration number: [240/565] 42% | Training loss: 0.6896292544901371
Epoch: 59 | Iteration number: [250/565] 44% | Training loss: 0.689499805688858
Epoch: 59 | Iteration number: [260/565] 46% | Training loss: 0.6893948529775326
Epoch: 59 | Iteration number: [270/565] 47% | Training loss: 0.6893048036981512
Epoch: 59 | Iteration number: [280/565] 49% | Training loss: 0.6892047688364983
Epoch: 59 | Iteration number: [290/565] 51% | Training loss: 0.6891170581866954
Epoch: 59 | Iteration number: [300/565] 53% | Training loss: 0.6890466022491455
Epoch: 59 | Iteration number: [310/565] 54% | Training loss: 0.6889704396647792
Epoch: 59 | Iteration number: [320/565] 56% | Training loss: 0.6889065889641642
Epoch: 59 | Iteration number: [330/565] 58% | Training loss: 0.688845220117858
Epoch: 59 | Iteration number: [340/565] 60% | Training loss: 0.6887764559072607
Epoch: 59 | Iteration number: [350/565] 61% | Training loss: 0.6887181203705924
Epoch: 59 | Iteration number: [360/565] 63% | Training loss: 0.6886675167414877
Epoch: 59 | Iteration number: [370/565] 65% | Training loss: 0.6886219807573267
Epoch: 59 | Iteration number: [380/565] 67% | Training loss: 0.6885676292996658
Epoch: 59 | Iteration number: [390/565] 69% | Training loss: 0.6885288006220108
Epoch: 59 | Iteration number: [400/565] 70% | Training loss: 0.6884839208424092
Epoch: 59 | Iteration number: [410/565] 72% | Training loss: 0.688452444134689
Epoch: 59 | Iteration number: [420/565] 74% | Training loss: 0.688414056812014
Epoch: 59 | Iteration number: [430/565] 76% | Training loss: 0.6883774617383647
Epoch: 59 | Iteration number: [440/565] 77% | Training loss: 0.6883474921638315
Epoch: 59 | Iteration number: [450/565] 79% | Training loss: 0.6883155261145698
Epoch: 59 | Iteration number: [460/565] 81% | Training loss: 0.6883015418830125
Epoch: 59 | Iteration number: [470/565] 83% | Training loss: 0.6882717270800408
Epoch: 59 | Iteration number: [480/565] 84% | Training loss: 0.6882428134481112
Epoch: 59 | Iteration number: [490/565] 86% | Training loss: 0.6882044874891943
Epoch: 59 | Iteration number: [500/565] 88% | Training loss: 0.6881767435073852
Epoch: 59 | Iteration number: [510/565] 90% | Training loss: 0.6881484916397169
Epoch: 59 | Iteration number: [520/565] 92% | Training loss: 0.6881287479629883
Epoch: 59 | Iteration number: [530/565] 93% | Training loss: 0.6880998207713073
Epoch: 59 | Iteration number: [540/565] 95% | Training loss: 0.688083161799996
Epoch: 59 | Iteration number: [550/565] 97% | Training loss: 0.6880610325119713
Epoch: 59 | Iteration number: [560/565] 99% | Training loss: 0.6880407364240715

 End of epoch: 59 | Train Loss: 0.686810119173168 | Training Time: 88 

 End of epoch: 59 | Eval Loss: 0.6890893578529358 | Evaluating Time: 6 
Epoch: 60 | Iteration number: [10/565] 1% | Training loss: 0.7557832181453705
Epoch: 60 | Iteration number: [20/565] 3% | Training loss: 0.72144815325737
Epoch: 60 | Iteration number: [30/565] 5% | Training loss: 0.70979745388031
Epoch: 60 | Iteration number: [40/565] 7% | Training loss: 0.7040544793009758
Epoch: 60 | Iteration number: [50/565] 8% | Training loss: 0.7006930017471313
Epoch: 60 | Iteration number: [60/565] 10% | Training loss: 0.6984737396240235
Epoch: 60 | Iteration number: [70/565] 12% | Training loss: 0.6967263562338692
Epoch: 60 | Iteration number: [80/565] 14% | Training loss: 0.6954796507954597
Epoch: 60 | Iteration number: [90/565] 15% | Training loss: 0.6945413761668735
Epoch: 60 | Iteration number: [100/565] 17% | Training loss: 0.6937671810388565
Epoch: 60 | Iteration number: [110/565] 19% | Training loss: 0.6931483106179671
Epoch: 60 | Iteration number: [120/565] 21% | Training loss: 0.6925624430179596
Epoch: 60 | Iteration number: [130/565] 23% | Training loss: 0.6921227340514843
Epoch: 60 | Iteration number: [140/565] 24% | Training loss: 0.6917528416429247
Epoch: 60 | Iteration number: [150/565] 26% | Training loss: 0.6914332950115204
Epoch: 60 | Iteration number: [160/565] 28% | Training loss: 0.6911725230515003
Epoch: 60 | Iteration number: [170/565] 30% | Training loss: 0.6909182082204258
Epoch: 60 | Iteration number: [180/565] 31% | Training loss: 0.6906866394811206
Epoch: 60 | Iteration number: [190/565] 33% | Training loss: 0.6904623028479124
Epoch: 60 | Iteration number: [200/565] 35% | Training loss: 0.6902942770719528
Epoch: 60 | Iteration number: [210/565] 37% | Training loss: 0.6901434009983426
Epoch: 60 | Iteration number: [220/565] 38% | Training loss: 0.6899820121851834
Epoch: 60 | Iteration number: [230/565] 40% | Training loss: 0.6898486733436584
Epoch: 60 | Iteration number: [240/565] 42% | Training loss: 0.6897272263964017
Epoch: 60 | Iteration number: [250/565] 44% | Training loss: 0.6896110937595368
Epoch: 60 | Iteration number: [260/565] 46% | Training loss: 0.689491570683626
Epoch: 60 | Iteration number: [270/565] 47% | Training loss: 0.6893737007070471
Epoch: 60 | Iteration number: [280/565] 49% | Training loss: 0.6892577850392887
Epoch: 60 | Iteration number: [290/565] 51% | Training loss: 0.6891802978926691
Epoch: 60 | Iteration number: [300/565] 53% | Training loss: 0.6890931940078735
Epoch: 60 | Iteration number: [310/565] 54% | Training loss: 0.6890281590723222
Epoch: 60 | Iteration number: [320/565] 56% | Training loss: 0.6889585584402085
Epoch: 60 | Iteration number: [330/565] 58% | Training loss: 0.6888995280771545
Epoch: 60 | Iteration number: [340/565] 60% | Training loss: 0.688837401305928
Epoch: 60 | Iteration number: [350/565] 61% | Training loss: 0.6887768709659576
Epoch: 60 | Iteration number: [360/565] 63% | Training loss: 0.6887312670548756
Epoch: 60 | Iteration number: [370/565] 65% | Training loss: 0.6886787111694749
Epoch: 60 | Iteration number: [380/565] 67% | Training loss: 0.6886324978188465
Epoch: 60 | Iteration number: [390/565] 69% | Training loss: 0.6885834467716706
Epoch: 60 | Iteration number: [400/565] 70% | Training loss: 0.6885278885066509
Epoch: 60 | Iteration number: [410/565] 72% | Training loss: 0.6884969653152838
Epoch: 60 | Iteration number: [420/565] 74% | Training loss: 0.6884568327949161
Epoch: 60 | Iteration number: [430/565] 76% | Training loss: 0.6884206870267557
Epoch: 60 | Iteration number: [440/565] 77% | Training loss: 0.6883851624347946
Epoch: 60 | Iteration number: [450/565] 79% | Training loss: 0.6883369594150119
Epoch: 60 | Iteration number: [460/565] 81% | Training loss: 0.6882978971885598
Epoch: 60 | Iteration number: [470/565] 83% | Training loss: 0.688271684215424
Epoch: 60 | Iteration number: [480/565] 84% | Training loss: 0.6882412782559792
Epoch: 60 | Iteration number: [490/565] 86% | Training loss: 0.6882096497380004
Epoch: 60 | Iteration number: [500/565] 88% | Training loss: 0.6881849398612976
Epoch: 60 | Iteration number: [510/565] 90% | Training loss: 0.6881539047933092
Epoch: 60 | Iteration number: [520/565] 92% | Training loss: 0.6881334545520635
Epoch: 60 | Iteration number: [530/565] 93% | Training loss: 0.6881213885433269
Epoch: 60 | Iteration number: [540/565] 95% | Training loss: 0.6880870427246447
Epoch: 60 | Iteration number: [550/565] 97% | Training loss: 0.6880594936284152
Epoch: 60 | Iteration number: [560/565] 99% | Training loss: 0.6880356340536049

 End of epoch: 60 | Train Loss: 0.6868064362390907 | Training Time: 90 

 End of epoch: 60 | Eval Loss: 0.6897108129092625 | Evaluating Time: 6 
Epoch: 61 | Iteration number: [10/565] 1% | Training loss: 0.7560174226760864
Epoch: 61 | Iteration number: [20/565] 3% | Training loss: 0.721296763420105
Epoch: 61 | Iteration number: [30/565] 5% | Training loss: 0.7098221759001414
Epoch: 61 | Iteration number: [40/565] 7% | Training loss: 0.7041654333472251
Epoch: 61 | Iteration number: [50/565] 8% | Training loss: 0.7006861400604248
Epoch: 61 | Iteration number: [60/565] 10% | Training loss: 0.6984182854493459
Epoch: 61 | Iteration number: [70/565] 12% | Training loss: 0.6967985221317836
Epoch: 61 | Iteration number: [80/565] 14% | Training loss: 0.6955201737582684
Epoch: 61 | Iteration number: [90/565] 15% | Training loss: 0.6945640908347236
Epoch: 61 | Iteration number: [100/565] 17% | Training loss: 0.6937665343284607
Epoch: 61 | Iteration number: [110/565] 19% | Training loss: 0.6931407516652888
Epoch: 61 | Iteration number: [120/565] 21% | Training loss: 0.6926286752025287
Epoch: 61 | Iteration number: [130/565] 23% | Training loss: 0.6921818967048938
Epoch: 61 | Iteration number: [140/565] 24% | Training loss: 0.6917788109609059
Epoch: 61 | Iteration number: [150/565] 26% | Training loss: 0.6914341207345327
Epoch: 61 | Iteration number: [160/565] 28% | Training loss: 0.6911352939903737
Epoch: 61 | Iteration number: [170/565] 30% | Training loss: 0.6909058928489685
Epoch: 61 | Iteration number: [180/565] 31% | Training loss: 0.6906733009550307
Epoch: 61 | Iteration number: [190/565] 33% | Training loss: 0.6904476727309979
Epoch: 61 | Iteration number: [200/565] 35% | Training loss: 0.6902484983205796
Epoch: 61 | Iteration number: [210/565] 37% | Training loss: 0.6900688009602683
Epoch: 61 | Iteration number: [220/565] 38% | Training loss: 0.6899171346967871
Epoch: 61 | Iteration number: [230/565] 40% | Training loss: 0.6897919051025225
Epoch: 61 | Iteration number: [240/565] 42% | Training loss: 0.6896664177378019
Epoch: 61 | Iteration number: [250/565] 44% | Training loss: 0.6895447092056275
Epoch: 61 | Iteration number: [260/565] 46% | Training loss: 0.6894236974991285
Epoch: 61 | Iteration number: [270/565] 47% | Training loss: 0.6893306462853043
Epoch: 61 | Iteration number: [280/565] 49% | Training loss: 0.689251999769892
Epoch: 61 | Iteration number: [290/565] 51% | Training loss: 0.6891548584247458
Epoch: 61 | Iteration number: [300/565] 53% | Training loss: 0.6890718744198481
Epoch: 61 | Iteration number: [310/565] 54% | Training loss: 0.6889998822442946
Epoch: 61 | Iteration number: [320/565] 56% | Training loss: 0.6889224505051971
Epoch: 61 | Iteration number: [330/565] 58% | Training loss: 0.6888614524494517
Epoch: 61 | Iteration number: [340/565] 60% | Training loss: 0.6888011473066666
Epoch: 61 | Iteration number: [350/565] 61% | Training loss: 0.6887474272932325
Epoch: 61 | Iteration number: [360/565] 63% | Training loss: 0.688691185745928
Epoch: 61 | Iteration number: [370/565] 65% | Training loss: 0.6886482116338369
Epoch: 61 | Iteration number: [380/565] 67% | Training loss: 0.6885981732293179
Epoch: 61 | Iteration number: [390/565] 69% | Training loss: 0.6885548854485536
Epoch: 61 | Iteration number: [400/565] 70% | Training loss: 0.6885092693567276
Epoch: 61 | Iteration number: [410/565] 72% | Training loss: 0.6884774338908312
Epoch: 61 | Iteration number: [420/565] 74% | Training loss: 0.6884372740983963
Epoch: 61 | Iteration number: [430/565] 76% | Training loss: 0.6884033509465151
Epoch: 61 | Iteration number: [440/565] 77% | Training loss: 0.688360900635069
Epoch: 61 | Iteration number: [450/565] 79% | Training loss: 0.6883359820312924
Epoch: 61 | Iteration number: [460/565] 81% | Training loss: 0.6882985830307007
Epoch: 61 | Iteration number: [470/565] 83% | Training loss: 0.6882567755719449
Epoch: 61 | Iteration number: [480/565] 84% | Training loss: 0.6882199304799239
Epoch: 61 | Iteration number: [490/565] 86% | Training loss: 0.6881878693493045
Epoch: 61 | Iteration number: [500/565] 88% | Training loss: 0.6881578059196473
Epoch: 61 | Iteration number: [510/565] 90% | Training loss: 0.6881284268463359
Epoch: 61 | Iteration number: [520/565] 92% | Training loss: 0.6880985960364342
Epoch: 61 | Iteration number: [530/565] 93% | Training loss: 0.6880761350100895
Epoch: 61 | Iteration number: [540/565] 95% | Training loss: 0.6880513782854434
Epoch: 61 | Iteration number: [550/565] 97% | Training loss: 0.6880362506346269
Epoch: 61 | Iteration number: [560/565] 99% | Training loss: 0.6880201895322119

 End of epoch: 61 | Train Loss: 0.6867948565862875 | Training Time: 90 

 End of epoch: 61 | Eval Loss: 0.6901585374559674 | Evaluating Time: 6 
Epoch: 62 | Iteration number: [10/565] 1% | Training loss: 0.7547269642353058
Epoch: 62 | Iteration number: [20/565] 3% | Training loss: 0.7207897067070007
Epoch: 62 | Iteration number: [30/565] 5% | Training loss: 0.7094024002552033
Epoch: 62 | Iteration number: [40/565] 7% | Training loss: 0.7038415625691414
Epoch: 62 | Iteration number: [50/565] 8% | Training loss: 0.7004249727725983
Epoch: 62 | Iteration number: [60/565] 10% | Training loss: 0.6981907377640406
Epoch: 62 | Iteration number: [70/565] 12% | Training loss: 0.6965715501989637
Epoch: 62 | Iteration number: [80/565] 14% | Training loss: 0.6953384570777417
Epoch: 62 | Iteration number: [90/565] 15% | Training loss: 0.6944060815705193
Epoch: 62 | Iteration number: [100/565] 17% | Training loss: 0.693643804192543
Epoch: 62 | Iteration number: [110/565] 19% | Training loss: 0.6930395738645033
Epoch: 62 | Iteration number: [120/565] 21% | Training loss: 0.6925408745805423
Epoch: 62 | Iteration number: [130/565] 23% | Training loss: 0.6921297311782837
Epoch: 62 | Iteration number: [140/565] 24% | Training loss: 0.691760743515832
Epoch: 62 | Iteration number: [150/565] 26% | Training loss: 0.6914186135927836
Epoch: 62 | Iteration number: [160/565] 28% | Training loss: 0.691112433001399
Epoch: 62 | Iteration number: [170/565] 30% | Training loss: 0.6908514387467328
Epoch: 62 | Iteration number: [180/565] 31% | Training loss: 0.6906295067734188
Epoch: 62 | Iteration number: [190/565] 33% | Training loss: 0.6904096920239298
Epoch: 62 | Iteration number: [200/565] 35% | Training loss: 0.690206937789917
Epoch: 62 | Iteration number: [210/565] 37% | Training loss: 0.6900478539012728
Epoch: 62 | Iteration number: [220/565] 38% | Training loss: 0.6899012427438389
Epoch: 62 | Iteration number: [230/565] 40% | Training loss: 0.6897817764593207
Epoch: 62 | Iteration number: [240/565] 42% | Training loss: 0.6896800719201565
Epoch: 62 | Iteration number: [250/565] 44% | Training loss: 0.6895825538635254
Epoch: 62 | Iteration number: [260/565] 46% | Training loss: 0.6894622676647626
Epoch: 62 | Iteration number: [270/565] 47% | Training loss: 0.6893580255685029
Epoch: 62 | Iteration number: [280/565] 49% | Training loss: 0.6892656541296414
Epoch: 62 | Iteration number: [290/565] 51% | Training loss: 0.6891721604199245
Epoch: 62 | Iteration number: [300/565] 53% | Training loss: 0.6890834871927897
Epoch: 62 | Iteration number: [310/565] 54% | Training loss: 0.6890068184944891
Epoch: 62 | Iteration number: [320/565] 56% | Training loss: 0.6889409646391869
Epoch: 62 | Iteration number: [330/565] 58% | Training loss: 0.6888815341573773
Epoch: 62 | Iteration number: [340/565] 60% | Training loss: 0.6888240926405963
Epoch: 62 | Iteration number: [350/565] 61% | Training loss: 0.6887664430482047
Epoch: 62 | Iteration number: [360/565] 63% | Training loss: 0.6887078747153282
Epoch: 62 | Iteration number: [370/565] 65% | Training loss: 0.6886691847363033
Epoch: 62 | Iteration number: [380/565] 67% | Training loss: 0.688607949332187
Epoch: 62 | Iteration number: [390/565] 69% | Training loss: 0.6885574317895449
Epoch: 62 | Iteration number: [400/565] 70% | Training loss: 0.6885118246078491
Epoch: 62 | Iteration number: [410/565] 72% | Training loss: 0.688471447403838
Epoch: 62 | Iteration number: [420/565] 74% | Training loss: 0.6884308955499104
Epoch: 62 | Iteration number: [430/565] 76% | Training loss: 0.6883848101593727
Epoch: 62 | Iteration number: [440/565] 77% | Training loss: 0.688338496603749
Epoch: 62 | Iteration number: [450/565] 79% | Training loss: 0.6883010972870721
Epoch: 62 | Iteration number: [460/565] 81% | Training loss: 0.6882685858270396
Epoch: 62 | Iteration number: [470/565] 83% | Training loss: 0.6882440178952318
Epoch: 62 | Iteration number: [480/565] 84% | Training loss: 0.6882133141160012
Epoch: 62 | Iteration number: [490/565] 86% | Training loss: 0.6881838998016045
Epoch: 62 | Iteration number: [500/565] 88% | Training loss: 0.6881583551168442
Epoch: 62 | Iteration number: [510/565] 90% | Training loss: 0.6881194782023337
Epoch: 62 | Iteration number: [520/565] 92% | Training loss: 0.6880951201686493
Epoch: 62 | Iteration number: [530/565] 93% | Training loss: 0.6880697417933986
Epoch: 62 | Iteration number: [540/565] 95% | Training loss: 0.6880498494263049
Epoch: 62 | Iteration number: [550/565] 97% | Training loss: 0.6880307788198644
Epoch: 62 | Iteration number: [560/565] 99% | Training loss: 0.6880202811743532

 End of epoch: 62 | Train Loss: 0.6867949146085081 | Training Time: 88 

 End of epoch: 62 | Eval Loss: 0.6902110150882176 | Evaluating Time: 6 
Epoch: 63 | Iteration number: [10/565] 1% | Training loss: 0.7557115018367767
Epoch: 63 | Iteration number: [20/565] 3% | Training loss: 0.7211919873952866
Epoch: 63 | Iteration number: [30/565] 5% | Training loss: 0.7098562995592753
Epoch: 63 | Iteration number: [40/565] 7% | Training loss: 0.7040006071329117
Epoch: 63 | Iteration number: [50/565] 8% | Training loss: 0.7005383431911468
Epoch: 63 | Iteration number: [60/565] 10% | Training loss: 0.6981772055228551
Epoch: 63 | Iteration number: [70/565] 12% | Training loss: 0.696552916935512
Epoch: 63 | Iteration number: [80/565] 14% | Training loss: 0.6953218825161457
Epoch: 63 | Iteration number: [90/565] 15% | Training loss: 0.6943723360697428
Epoch: 63 | Iteration number: [100/565] 17% | Training loss: 0.6936383855342865
Epoch: 63 | Iteration number: [110/565] 19% | Training loss: 0.6929784590547735
Epoch: 63 | Iteration number: [120/565] 21% | Training loss: 0.6924627393484115
Epoch: 63 | Iteration number: [130/565] 23% | Training loss: 0.6920169711112976
Epoch: 63 | Iteration number: [140/565] 24% | Training loss: 0.6916387204613005
Epoch: 63 | Iteration number: [150/565] 26% | Training loss: 0.6913237639268239
Epoch: 63 | Iteration number: [160/565] 28% | Training loss: 0.6910296734422445
Epoch: 63 | Iteration number: [170/565] 30% | Training loss: 0.6907861281843747
Epoch: 63 | Iteration number: [180/565] 31% | Training loss: 0.6905808081229527
Epoch: 63 | Iteration number: [190/565] 33% | Training loss: 0.6903886641326703
Epoch: 63 | Iteration number: [200/565] 35% | Training loss: 0.6902198192477226
Epoch: 63 | Iteration number: [210/565] 37% | Training loss: 0.69004090712184
Epoch: 63 | Iteration number: [220/565] 38% | Training loss: 0.6898956496607174
Epoch: 63 | Iteration number: [230/565] 40% | Training loss: 0.6897553925928862
Epoch: 63 | Iteration number: [240/565] 42% | Training loss: 0.6896087321142356
Epoch: 63 | Iteration number: [250/565] 44% | Training loss: 0.6895042691230774
Epoch: 63 | Iteration number: [260/565] 46% | Training loss: 0.6893964327298678
Epoch: 63 | Iteration number: [270/565] 47% | Training loss: 0.6893004070829463
Epoch: 63 | Iteration number: [280/565] 49% | Training loss: 0.6892214019383703
Epoch: 63 | Iteration number: [290/565] 51% | Training loss: 0.6891436733048538
Epoch: 63 | Iteration number: [300/565] 53% | Training loss: 0.689062725106875
Epoch: 63 | Iteration number: [310/565] 54% | Training loss: 0.6889927666033467
Epoch: 63 | Iteration number: [320/565] 56% | Training loss: 0.6889187686145306
Epoch: 63 | Iteration number: [330/565] 58% | Training loss: 0.6888768138307514
Epoch: 63 | Iteration number: [340/565] 60% | Training loss: 0.6888110841021818
Epoch: 63 | Iteration number: [350/565] 61% | Training loss: 0.6887623841421945
Epoch: 63 | Iteration number: [360/565] 63% | Training loss: 0.688704040646553
Epoch: 63 | Iteration number: [370/565] 65% | Training loss: 0.6886478130881851
Epoch: 63 | Iteration number: [380/565] 67% | Training loss: 0.6885954012996272
Epoch: 63 | Iteration number: [390/565] 69% | Training loss: 0.6885540655026069
Epoch: 63 | Iteration number: [400/565] 70% | Training loss: 0.6885068774223327
Epoch: 63 | Iteration number: [410/565] 72% | Training loss: 0.6884738605196883
Epoch: 63 | Iteration number: [420/565] 74% | Training loss: 0.6884407141378948
Epoch: 63 | Iteration number: [430/565] 76% | Training loss: 0.688408476114273
Epoch: 63 | Iteration number: [440/565] 77% | Training loss: 0.6883678574453701
Epoch: 63 | Iteration number: [450/565] 79% | Training loss: 0.6883355830775367
Epoch: 63 | Iteration number: [460/565] 81% | Training loss: 0.6882982334365015
Epoch: 63 | Iteration number: [470/565] 83% | Training loss: 0.6882677798575544
Epoch: 63 | Iteration number: [480/565] 84% | Training loss: 0.6882352288812399
Epoch: 63 | Iteration number: [490/565] 86% | Training loss: 0.6881920816947003
Epoch: 63 | Iteration number: [500/565] 88% | Training loss: 0.6881669172048569
Epoch: 63 | Iteration number: [510/565] 90% | Training loss: 0.6881315912686142
Epoch: 63 | Iteration number: [520/565] 92% | Training loss: 0.6881092680188325
Epoch: 63 | Iteration number: [530/565] 93% | Training loss: 0.6880882159718927
Epoch: 63 | Iteration number: [540/565] 95% | Training loss: 0.6880724041550248
Epoch: 63 | Iteration number: [550/565] 97% | Training loss: 0.6880406454476443
Epoch: 63 | Iteration number: [560/565] 99% | Training loss: 0.6880246362515858

 End of epoch: 63 | Train Loss: 0.6867966646641757 | Training Time: 90 

 End of epoch: 63 | Eval Loss: 0.6901540756225586 | Evaluating Time: 6 
Epoch: 64 | Iteration number: [10/565] 1% | Training loss: 0.7554359197616577
Epoch: 64 | Iteration number: [20/565] 3% | Training loss: 0.7211326450109482
Epoch: 64 | Iteration number: [30/565] 5% | Training loss: 0.709562478462855
Epoch: 64 | Iteration number: [40/565] 7% | Training loss: 0.7037905707955361
Epoch: 64 | Iteration number: [50/565] 8% | Training loss: 0.7003569221496582
Epoch: 64 | Iteration number: [60/565] 10% | Training loss: 0.6980955809354782
Epoch: 64 | Iteration number: [70/565] 12% | Training loss: 0.696426226411547
Epoch: 64 | Iteration number: [80/565] 14% | Training loss: 0.6951930455863475
Epoch: 64 | Iteration number: [90/565] 15% | Training loss: 0.6942358116308848
Epoch: 64 | Iteration number: [100/565] 17% | Training loss: 0.6934459984302521
Epoch: 64 | Iteration number: [110/565] 19% | Training loss: 0.6928358148444783
Epoch: 64 | Iteration number: [120/565] 21% | Training loss: 0.6923159395654996
Epoch: 64 | Iteration number: [130/565] 23% | Training loss: 0.6919096479049096
Epoch: 64 | Iteration number: [140/565] 24% | Training loss: 0.6915375854287829
Epoch: 64 | Iteration number: [150/565] 26% | Training loss: 0.6912297864754995
Epoch: 64 | Iteration number: [160/565] 28% | Training loss: 0.6909693337976932
Epoch: 64 | Iteration number: [170/565] 30% | Training loss: 0.6907569962389329
Epoch: 64 | Iteration number: [180/565] 31% | Training loss: 0.6905397497945361
Epoch: 64 | Iteration number: [190/565] 33% | Training loss: 0.6903313210136012
Epoch: 64 | Iteration number: [200/565] 35% | Training loss: 0.6901400688290596
Epoch: 64 | Iteration number: [210/565] 37% | Training loss: 0.689999525603794
Epoch: 64 | Iteration number: [220/565] 38% | Training loss: 0.6898632902990688
Epoch: 64 | Iteration number: [230/565] 40% | Training loss: 0.6897396204264268
Epoch: 64 | Iteration number: [240/565] 42% | Training loss: 0.6896069154143334
Epoch: 64 | Iteration number: [250/565] 44% | Training loss: 0.6894739031791687
Epoch: 64 | Iteration number: [260/565] 46% | Training loss: 0.6893633853930693
Epoch: 64 | Iteration number: [270/565] 47% | Training loss: 0.6892724589065269
Epoch: 64 | Iteration number: [280/565] 49% | Training loss: 0.6891822757465499
Epoch: 64 | Iteration number: [290/565] 51% | Training loss: 0.6891131119481448
Epoch: 64 | Iteration number: [300/565] 53% | Training loss: 0.6890333954493205
Epoch: 64 | Iteration number: [310/565] 54% | Training loss: 0.6889739480710799
Epoch: 64 | Iteration number: [320/565] 56% | Training loss: 0.6889078602194786
Epoch: 64 | Iteration number: [330/565] 58% | Training loss: 0.6888506432374318
Epoch: 64 | Iteration number: [340/565] 60% | Training loss: 0.6887962951379664
Epoch: 64 | Iteration number: [350/565] 61% | Training loss: 0.688740462064743
Epoch: 64 | Iteration number: [360/565] 63% | Training loss: 0.6886883124709129
Epoch: 64 | Iteration number: [370/565] 65% | Training loss: 0.6886464905094456
Epoch: 64 | Iteration number: [380/565] 67% | Training loss: 0.6885963902661675
Epoch: 64 | Iteration number: [390/565] 69% | Training loss: 0.6885443737873664
Epoch: 64 | Iteration number: [400/565] 70% | Training loss: 0.6884982572495937
Epoch: 64 | Iteration number: [410/565] 72% | Training loss: 0.6884594437552661
Epoch: 64 | Iteration number: [420/565] 74% | Training loss: 0.6884324340593247
Epoch: 64 | Iteration number: [430/565] 76% | Training loss: 0.6883981080942376
Epoch: 64 | Iteration number: [440/565] 77% | Training loss: 0.6883483094247904
Epoch: 64 | Iteration number: [450/565] 79% | Training loss: 0.688308064672682
Epoch: 64 | Iteration number: [460/565] 81% | Training loss: 0.6882749150628629
Epoch: 64 | Iteration number: [470/565] 83% | Training loss: 0.6882470759939641
Epoch: 64 | Iteration number: [480/565] 84% | Training loss: 0.6882171913981437
Epoch: 64 | Iteration number: [490/565] 86% | Training loss: 0.688194919240718
Epoch: 64 | Iteration number: [500/565] 88% | Training loss: 0.6881643207073211
Epoch: 64 | Iteration number: [510/565] 90% | Training loss: 0.6881560086035261
Epoch: 64 | Iteration number: [520/565] 92% | Training loss: 0.6881324189213606
Epoch: 64 | Iteration number: [530/565] 93% | Training loss: 0.6881132899590259
Epoch: 64 | Iteration number: [540/565] 95% | Training loss: 0.6880918712527664
Epoch: 64 | Iteration number: [550/565] 97% | Training loss: 0.6880694416436282
Epoch: 64 | Iteration number: [560/565] 99% | Training loss: 0.688050743405308

 End of epoch: 64 | Train Loss: 0.686830646379859 | Training Time: 90 

 End of epoch: 64 | Eval Loss: 0.6894970791680473 | Evaluating Time: 6 
Epoch: 65 | Iteration number: [10/565] 1% | Training loss: 0.7558519840240479
Epoch: 65 | Iteration number: [20/565] 3% | Training loss: 0.7212080031633377
Epoch: 65 | Iteration number: [30/565] 5% | Training loss: 0.7097227394580841
Epoch: 65 | Iteration number: [40/565] 7% | Training loss: 0.7039881467819213
Epoch: 65 | Iteration number: [50/565] 8% | Training loss: 0.7004660260677338
Epoch: 65 | Iteration number: [60/565] 10% | Training loss: 0.6981801360845565
Epoch: 65 | Iteration number: [70/565] 12% | Training loss: 0.6964979461261205
Epoch: 65 | Iteration number: [80/565] 14% | Training loss: 0.6952972494065761
Epoch: 65 | Iteration number: [90/565] 15% | Training loss: 0.6943544626235962
Epoch: 65 | Iteration number: [100/565] 17% | Training loss: 0.6936053878068924
Epoch: 65 | Iteration number: [110/565] 19% | Training loss: 0.6930148097601804
Epoch: 65 | Iteration number: [120/565] 21% | Training loss: 0.6924910406271617
Epoch: 65 | Iteration number: [130/565] 23% | Training loss: 0.6920888974116399
Epoch: 65 | Iteration number: [140/565] 24% | Training loss: 0.6917088883263725
Epoch: 65 | Iteration number: [150/565] 26% | Training loss: 0.6913864584763845
Epoch: 65 | Iteration number: [160/565] 28% | Training loss: 0.6911032728850841
Epoch: 65 | Iteration number: [170/565] 30% | Training loss: 0.6908613222486832
Epoch: 65 | Iteration number: [180/565] 31% | Training loss: 0.6906496600972282
Epoch: 65 | Iteration number: [190/565] 33% | Training loss: 0.6904468690094195
Epoch: 65 | Iteration number: [200/565] 35% | Training loss: 0.6902318355441094
Epoch: 65 | Iteration number: [210/565] 37% | Training loss: 0.6900733953430539
Epoch: 65 | Iteration number: [220/565] 38% | Training loss: 0.6899432759393346
Epoch: 65 | Iteration number: [230/565] 40% | Training loss: 0.6897910159567128
Epoch: 65 | Iteration number: [240/565] 42% | Training loss: 0.6896621103088061
Epoch: 65 | Iteration number: [250/565] 44% | Training loss: 0.6895481355190277
Epoch: 65 | Iteration number: [260/565] 46% | Training loss: 0.6894505014786354
Epoch: 65 | Iteration number: [270/565] 47% | Training loss: 0.6893449465433756
Epoch: 65 | Iteration number: [280/565] 49% | Training loss: 0.689274899661541
Epoch: 65 | Iteration number: [290/565] 51% | Training loss: 0.6891774964743647
Epoch: 65 | Iteration number: [300/565] 53% | Training loss: 0.6890995130936305
Epoch: 65 | Iteration number: [310/565] 54% | Training loss: 0.6890089598394209
Epoch: 65 | Iteration number: [320/565] 56% | Training loss: 0.6889356452971697
Epoch: 65 | Iteration number: [330/565] 58% | Training loss: 0.6888812789411256
Epoch: 65 | Iteration number: [340/565] 60% | Training loss: 0.6888113454860799
Epoch: 65 | Iteration number: [350/565] 61% | Training loss: 0.6887549235139574
Epoch: 65 | Iteration number: [360/565] 63% | Training loss: 0.6887117313014136
Epoch: 65 | Iteration number: [370/565] 65% | Training loss: 0.6886582514724215
Epoch: 65 | Iteration number: [380/565] 67% | Training loss: 0.6886052859456916
Epoch: 65 | Iteration number: [390/565] 69% | Training loss: 0.6885648064124279
Epoch: 65 | Iteration number: [400/565] 70% | Training loss: 0.688523414582014
Epoch: 65 | Iteration number: [410/565] 72% | Training loss: 0.6884887238828147
Epoch: 65 | Iteration number: [420/565] 74% | Training loss: 0.6884454877603622
Epoch: 65 | Iteration number: [430/565] 76% | Training loss: 0.6884000718593597
Epoch: 65 | Iteration number: [440/565] 77% | Training loss: 0.6883601638403806
Epoch: 65 | Iteration number: [450/565] 79% | Training loss: 0.688322143819597
Epoch: 65 | Iteration number: [460/565] 81% | Training loss: 0.688284609499185
Epoch: 65 | Iteration number: [470/565] 83% | Training loss: 0.6882521401060389
Epoch: 65 | Iteration number: [480/565] 84% | Training loss: 0.6882269304245711
Epoch: 65 | Iteration number: [490/565] 86% | Training loss: 0.6882004597965552
Epoch: 65 | Iteration number: [500/565] 88% | Training loss: 0.6881775424480439
Epoch: 65 | Iteration number: [510/565] 90% | Training loss: 0.688156600559459
Epoch: 65 | Iteration number: [520/565] 92% | Training loss: 0.688125537106624
Epoch: 65 | Iteration number: [530/565] 93% | Training loss: 0.6881113423491424
Epoch: 65 | Iteration number: [540/565] 95% | Training loss: 0.6880811367873793
Epoch: 65 | Iteration number: [550/565] 97% | Training loss: 0.6880549305135554
Epoch: 65 | Iteration number: [560/565] 99% | Training loss: 0.6880253272397178

 End of epoch: 65 | Train Loss: 0.6868004288293619 | Training Time: 89 

 End of epoch: 65 | Eval Loss: 0.6900601642472404 | Evaluating Time: 6 
Epoch: 66 | Iteration number: [10/565] 1% | Training loss: 0.7561557590961456
Epoch: 66 | Iteration number: [20/565] 3% | Training loss: 0.7213464856147767
Epoch: 66 | Iteration number: [30/565] 5% | Training loss: 0.7097958584626516
Epoch: 66 | Iteration number: [40/565] 7% | Training loss: 0.7039252862334251
Epoch: 66 | Iteration number: [50/565] 8% | Training loss: 0.7004842150211334
Epoch: 66 | Iteration number: [60/565] 10% | Training loss: 0.6981512427330017
Epoch: 66 | Iteration number: [70/565] 12% | Training loss: 0.6965398677757808
Epoch: 66 | Iteration number: [80/565] 14% | Training loss: 0.6952426746487618
Epoch: 66 | Iteration number: [90/565] 15% | Training loss: 0.6942991349432204
Epoch: 66 | Iteration number: [100/565] 17% | Training loss: 0.6935219317674637
Epoch: 66 | Iteration number: [110/565] 19% | Training loss: 0.6929163477637551
Epoch: 66 | Iteration number: [120/565] 21% | Training loss: 0.6924080888430277
Epoch: 66 | Iteration number: [130/565] 23% | Training loss: 0.6920101229961102
Epoch: 66 | Iteration number: [140/565] 24% | Training loss: 0.6916056032691683
Epoch: 66 | Iteration number: [150/565] 26% | Training loss: 0.6912994770208994
Epoch: 66 | Iteration number: [160/565] 28% | Training loss: 0.6910177279263735
Epoch: 66 | Iteration number: [170/565] 30% | Training loss: 0.6907550254288841
Epoch: 66 | Iteration number: [180/565] 31% | Training loss: 0.6905272238784366
Epoch: 66 | Iteration number: [190/565] 33% | Training loss: 0.6903180668228551
Epoch: 66 | Iteration number: [200/565] 35% | Training loss: 0.6901401683688164
Epoch: 66 | Iteration number: [210/565] 37% | Training loss: 0.6899641144843328
Epoch: 66 | Iteration number: [220/565] 38% | Training loss: 0.6898134524172003
Epoch: 66 | Iteration number: [230/565] 40% | Training loss: 0.6896915184414905
Epoch: 66 | Iteration number: [240/565] 42% | Training loss: 0.6895684314270815
Epoch: 66 | Iteration number: [250/565] 44% | Training loss: 0.6894397139549255
Epoch: 66 | Iteration number: [260/565] 46% | Training loss: 0.6893296383894407
Epoch: 66 | Iteration number: [270/565] 47% | Training loss: 0.6892323308520847
Epoch: 66 | Iteration number: [280/565] 49% | Training loss: 0.6891283750534057
Epoch: 66 | Iteration number: [290/565] 51% | Training loss: 0.6890532481259313
Epoch: 66 | Iteration number: [300/565] 53% | Training loss: 0.6889783545335134
Epoch: 66 | Iteration number: [310/565] 54% | Training loss: 0.6888968067784463
Epoch: 66 | Iteration number: [320/565] 56% | Training loss: 0.6888311240822077
Epoch: 66 | Iteration number: [330/565] 58% | Training loss: 0.6887628967111761
Epoch: 66 | Iteration number: [340/565] 60% | Training loss: 0.6887167308260412
Epoch: 66 | Iteration number: [350/565] 61% | Training loss: 0.6886591569014958
Epoch: 66 | Iteration number: [360/565] 63% | Training loss: 0.6886173110869196
Epoch: 66 | Iteration number: [370/565] 65% | Training loss: 0.6885743516522485
Epoch: 66 | Iteration number: [380/565] 67% | Training loss: 0.6885353831868423
Epoch: 66 | Iteration number: [390/565] 69% | Training loss: 0.6884919515022865
Epoch: 66 | Iteration number: [400/565] 70% | Training loss: 0.6884515908360481
Epoch: 66 | Iteration number: [410/565] 72% | Training loss: 0.6884155593267302
Epoch: 66 | Iteration number: [420/565] 74% | Training loss: 0.6883808970451355
Epoch: 66 | Iteration number: [430/565] 76% | Training loss: 0.6883395892243053
Epoch: 66 | Iteration number: [440/565] 77% | Training loss: 0.6883000526915897
Epoch: 66 | Iteration number: [450/565] 79% | Training loss: 0.6882661436663734
Epoch: 66 | Iteration number: [460/565] 81% | Training loss: 0.6882200121879578
Epoch: 66 | Iteration number: [470/565] 83% | Training loss: 0.6882040600827399
Epoch: 66 | Iteration number: [480/565] 84% | Training loss: 0.6881699431687593
Epoch: 66 | Iteration number: [490/565] 86% | Training loss: 0.688137308067205
Epoch: 66 | Iteration number: [500/565] 88% | Training loss: 0.688118952870369
Epoch: 66 | Iteration number: [510/565] 90% | Training loss: 0.6881024043934018
Epoch: 66 | Iteration number: [520/565] 92% | Training loss: 0.6880781498092872
Epoch: 66 | Iteration number: [530/565] 93% | Training loss: 0.6880594702261799
Epoch: 66 | Iteration number: [540/565] 95% | Training loss: 0.6880481395456526
Epoch: 66 | Iteration number: [550/565] 97% | Training loss: 0.6880318702350964
Epoch: 66 | Iteration number: [560/565] 99% | Training loss: 0.6880132426108633

 End of epoch: 66 | Train Loss: 0.6867881799166181 | Training Time: 90 

 End of epoch: 66 | Eval Loss: 0.6896429061889648 | Evaluating Time: 6 
Epoch: 67 | Iteration number: [10/565] 1% | Training loss: 0.755575430393219
Epoch: 67 | Iteration number: [20/565] 3% | Training loss: 0.7212556421756744
Epoch: 67 | Iteration number: [30/565] 5% | Training loss: 0.7097343524297078
Epoch: 67 | Iteration number: [40/565] 7% | Training loss: 0.7039157822728157
Epoch: 67 | Iteration number: [50/565] 8% | Training loss: 0.7004893195629119
Epoch: 67 | Iteration number: [60/565] 10% | Training loss: 0.698225004474322
Epoch: 67 | Iteration number: [70/565] 12% | Training loss: 0.6966329148837498
Epoch: 67 | Iteration number: [80/565] 14% | Training loss: 0.6953932210803032
Epoch: 67 | Iteration number: [90/565] 15% | Training loss: 0.6944407939910888
Epoch: 67 | Iteration number: [100/565] 17% | Training loss: 0.6936649602651596
Epoch: 67 | Iteration number: [110/565] 19% | Training loss: 0.6930716314099051
Epoch: 67 | Iteration number: [120/565] 21% | Training loss: 0.6925714795788129
Epoch: 67 | Iteration number: [130/565] 23% | Training loss: 0.6920922095959003
Epoch: 67 | Iteration number: [140/565] 24% | Training loss: 0.6916957897799355
Epoch: 67 | Iteration number: [150/565] 26% | Training loss: 0.6913664948940277
Epoch: 67 | Iteration number: [160/565] 28% | Training loss: 0.6910970896482468
Epoch: 67 | Iteration number: [170/565] 30% | Training loss: 0.6908374232404372
Epoch: 67 | Iteration number: [180/565] 31% | Training loss: 0.6906047105789185
Epoch: 67 | Iteration number: [190/565] 33% | Training loss: 0.6904024161790546
Epoch: 67 | Iteration number: [200/565] 35% | Training loss: 0.6902266535162925
Epoch: 67 | Iteration number: [210/565] 37% | Training loss: 0.6900523131801969
Epoch: 67 | Iteration number: [220/565] 38% | Training loss: 0.6899162452329289
Epoch: 67 | Iteration number: [230/565] 40% | Training loss: 0.6897852547790693
Epoch: 67 | Iteration number: [240/565] 42% | Training loss: 0.6896605265637239
Epoch: 67 | Iteration number: [250/565] 44% | Training loss: 0.6895500581264495
Epoch: 67 | Iteration number: [260/565] 46% | Training loss: 0.6894455150916026
Epoch: 67 | Iteration number: [270/565] 47% | Training loss: 0.6893553153232291
Epoch: 67 | Iteration number: [280/565] 49% | Training loss: 0.6892642881189074
Epoch: 67 | Iteration number: [290/565] 51% | Training loss: 0.6891881967413014
Epoch: 67 | Iteration number: [300/565] 53% | Training loss: 0.6890992746750514
Epoch: 67 | Iteration number: [310/565] 54% | Training loss: 0.6890413070878675
Epoch: 67 | Iteration number: [320/565] 56% | Training loss: 0.6889772538095713
Epoch: 67 | Iteration number: [330/565] 58% | Training loss: 0.6889167774807323
Epoch: 67 | Iteration number: [340/565] 60% | Training loss: 0.6888373746591456
Epoch: 67 | Iteration number: [350/565] 61% | Training loss: 0.6887741890975407
Epoch: 67 | Iteration number: [360/565] 63% | Training loss: 0.688722611301475
Epoch: 67 | Iteration number: [370/565] 65% | Training loss: 0.6886814112598831
Epoch: 67 | Iteration number: [380/565] 67% | Training loss: 0.6886256377947958
Epoch: 67 | Iteration number: [390/565] 69% | Training loss: 0.6885752554123218
Epoch: 67 | Iteration number: [400/565] 70% | Training loss: 0.6885333316028118
Epoch: 67 | Iteration number: [410/565] 72% | Training loss: 0.6884928102900342
Epoch: 67 | Iteration number: [420/565] 74% | Training loss: 0.688459997517722
Epoch: 67 | Iteration number: [430/565] 76% | Training loss: 0.6884312079396359
Epoch: 67 | Iteration number: [440/565] 77% | Training loss: 0.6883929920467463
Epoch: 67 | Iteration number: [450/565] 79% | Training loss: 0.6883546917968326
Epoch: 67 | Iteration number: [460/565] 81% | Training loss: 0.6883199966472128
Epoch: 67 | Iteration number: [470/565] 83% | Training loss: 0.6882846546934006
Epoch: 67 | Iteration number: [480/565] 84% | Training loss: 0.6882463067770004
Epoch: 67 | Iteration number: [490/565] 86% | Training loss: 0.6882066854408809
Epoch: 67 | Iteration number: [500/565] 88% | Training loss: 0.6881690866947174
Epoch: 67 | Iteration number: [510/565] 90% | Training loss: 0.6881432914266399
Epoch: 67 | Iteration number: [520/565] 92% | Training loss: 0.6881235606395282
Epoch: 67 | Iteration number: [530/565] 93% | Training loss: 0.6881007093303608
Epoch: 67 | Iteration number: [540/565] 95% | Training loss: 0.6880699755968871
Epoch: 67 | Iteration number: [550/565] 97% | Training loss: 0.6880440847440199
Epoch: 67 | Iteration number: [560/565] 99% | Training loss: 0.6880169341606753

 End of epoch: 67 | Train Loss: 0.686789923642589 | Training Time: 89 

 End of epoch: 67 | Eval Loss: 0.6891923717090062 | Evaluating Time: 6 
Epoch: 68 | Iteration number: [10/565] 1% | Training loss: 0.7547673046588897
Epoch: 68 | Iteration number: [20/565] 3% | Training loss: 0.7206000238656998
Epoch: 68 | Iteration number: [30/565] 5% | Training loss: 0.7092837651570638
Epoch: 68 | Iteration number: [40/565] 7% | Training loss: 0.7035763055086136
Epoch: 68 | Iteration number: [50/565] 8% | Training loss: 0.7002131307125091
Epoch: 68 | Iteration number: [60/565] 10% | Training loss: 0.697976240515709
Epoch: 68 | Iteration number: [70/565] 12% | Training loss: 0.6963549469198499
Epoch: 68 | Iteration number: [80/565] 14% | Training loss: 0.695165964961052
Epoch: 68 | Iteration number: [90/565] 15% | Training loss: 0.6942107836405437
Epoch: 68 | Iteration number: [100/565] 17% | Training loss: 0.6934798043966294
Epoch: 68 | Iteration number: [110/565] 19% | Training loss: 0.6928714362057773
Epoch: 68 | Iteration number: [120/565] 21% | Training loss: 0.6923742741346359
Epoch: 68 | Iteration number: [130/565] 23% | Training loss: 0.6919642361310813
Epoch: 68 | Iteration number: [140/565] 24% | Training loss: 0.6916048433099474
Epoch: 68 | Iteration number: [150/565] 26% | Training loss: 0.6912953265508016
Epoch: 68 | Iteration number: [160/565] 28% | Training loss: 0.6909871496260166
Epoch: 68 | Iteration number: [170/565] 30% | Training loss: 0.6907708921853234
Epoch: 68 | Iteration number: [180/565] 31% | Training loss: 0.6905563291576173
Epoch: 68 | Iteration number: [190/565] 33% | Training loss: 0.6903723243035769
Epoch: 68 | Iteration number: [200/565] 35% | Training loss: 0.6902061456441879
Epoch: 68 | Iteration number: [210/565] 37% | Training loss: 0.690013993921734
Epoch: 68 | Iteration number: [220/565] 38% | Training loss: 0.6898893559520894
Epoch: 68 | Iteration number: [230/565] 40% | Training loss: 0.6897526743619339
Epoch: 68 | Iteration number: [240/565] 42% | Training loss: 0.689645012219747
Epoch: 68 | Iteration number: [250/565] 44% | Training loss: 0.6895083310604095
Epoch: 68 | Iteration number: [260/565] 46% | Training loss: 0.6894142203606092
Epoch: 68 | Iteration number: [270/565] 47% | Training loss: 0.6893009938575604
Epoch: 68 | Iteration number: [280/565] 49% | Training loss: 0.6892217327441488
Epoch: 68 | Iteration number: [290/565] 51% | Training loss: 0.6891429650372473
Epoch: 68 | Iteration number: [300/565] 53% | Training loss: 0.6890728821357092
Epoch: 68 | Iteration number: [310/565] 54% | Training loss: 0.6889947422089115
Epoch: 68 | Iteration number: [320/565] 56% | Training loss: 0.6889359697699546
Epoch: 68 | Iteration number: [330/565] 58% | Training loss: 0.6888812988093405
Epoch: 68 | Iteration number: [340/565] 60% | Training loss: 0.6888140778331195
Epoch: 68 | Iteration number: [350/565] 61% | Training loss: 0.6887639617919922
Epoch: 68 | Iteration number: [360/565] 63% | Training loss: 0.6887123475472132
Epoch: 68 | Iteration number: [370/565] 65% | Training loss: 0.6886607010622282
Epoch: 68 | Iteration number: [380/565] 67% | Training loss: 0.6886202970617696
Epoch: 68 | Iteration number: [390/565] 69% | Training loss: 0.6885581568265573
Epoch: 68 | Iteration number: [400/565] 70% | Training loss: 0.6885122770071029
Epoch: 68 | Iteration number: [410/565] 72% | Training loss: 0.6884744987255189
Epoch: 68 | Iteration number: [420/565] 74% | Training loss: 0.6884291531074614
Epoch: 68 | Iteration number: [430/565] 76% | Training loss: 0.6884024503619172
Epoch: 68 | Iteration number: [440/565] 77% | Training loss: 0.6883655965328217
Epoch: 68 | Iteration number: [450/565] 79% | Training loss: 0.6883273666434818
Epoch: 68 | Iteration number: [460/565] 81% | Training loss: 0.6882810146912285
Epoch: 68 | Iteration number: [470/565] 83% | Training loss: 0.688239577349196
Epoch: 68 | Iteration number: [480/565] 84% | Training loss: 0.6882098303486903
Epoch: 68 | Iteration number: [490/565] 86% | Training loss: 0.6881821723616853
Epoch: 68 | Iteration number: [500/565] 88% | Training loss: 0.6881626598834991
Epoch: 68 | Iteration number: [510/565] 90% | Training loss: 0.6881317447213565
Epoch: 68 | Iteration number: [520/565] 92% | Training loss: 0.6881116199951905
Epoch: 68 | Iteration number: [530/565] 93% | Training loss: 0.6880837628301585
Epoch: 68 | Iteration number: [540/565] 95% | Training loss: 0.6880590485201942
Epoch: 68 | Iteration number: [550/565] 97% | Training loss: 0.6880394773049788
Epoch: 68 | Iteration number: [560/565] 99% | Training loss: 0.6880153318600996

 End of epoch: 68 | Train Loss: 0.6867869984787123 | Training Time: 90 

 End of epoch: 68 | Eval Loss: 0.6894581743649074 | Evaluating Time: 6 
Epoch: 69 | Iteration number: [10/565] 1% | Training loss: 0.7554220020771026
Epoch: 69 | Iteration number: [20/565] 3% | Training loss: 0.7209560483694076
Epoch: 69 | Iteration number: [30/565] 5% | Training loss: 0.7093891342480977
Epoch: 69 | Iteration number: [40/565] 7% | Training loss: 0.7037333354353905
Epoch: 69 | Iteration number: [50/565] 8% | Training loss: 0.7002973437309266
Epoch: 69 | Iteration number: [60/565] 10% | Training loss: 0.6979998211065929
Epoch: 69 | Iteration number: [70/565] 12% | Training loss: 0.6964513369968959
Epoch: 69 | Iteration number: [80/565] 14% | Training loss: 0.6952321656048298
Epoch: 69 | Iteration number: [90/565] 15% | Training loss: 0.6942463795344035
Epoch: 69 | Iteration number: [100/565] 17% | Training loss: 0.6935743242502213
Epoch: 69 | Iteration number: [110/565] 19% | Training loss: 0.6929419284517114
Epoch: 69 | Iteration number: [120/565] 21% | Training loss: 0.6924484113852183
Epoch: 69 | Iteration number: [130/565] 23% | Training loss: 0.6919758035586431
Epoch: 69 | Iteration number: [140/565] 24% | Training loss: 0.6916121989488602
Epoch: 69 | Iteration number: [150/565] 26% | Training loss: 0.6912929753462473
Epoch: 69 | Iteration number: [160/565] 28% | Training loss: 0.6910055164247751
Epoch: 69 | Iteration number: [170/565] 30% | Training loss: 0.6907686692826888
Epoch: 69 | Iteration number: [180/565] 31% | Training loss: 0.6905395083957249
Epoch: 69 | Iteration number: [190/565] 33% | Training loss: 0.6903240219542854
Epoch: 69 | Iteration number: [200/565] 35% | Training loss: 0.6901452377438545
Epoch: 69 | Iteration number: [210/565] 37% | Training loss: 0.6899909501984006
Epoch: 69 | Iteration number: [220/565] 38% | Training loss: 0.6898651532151482
Epoch: 69 | Iteration number: [230/565] 40% | Training loss: 0.6897152198397595
Epoch: 69 | Iteration number: [240/565] 42% | Training loss: 0.6895875602960586
Epoch: 69 | Iteration number: [250/565] 44% | Training loss: 0.6894991669654846
Epoch: 69 | Iteration number: [260/565] 46% | Training loss: 0.6894071661509
Epoch: 69 | Iteration number: [270/565] 47% | Training loss: 0.6893194600387856
Epoch: 69 | Iteration number: [280/565] 49% | Training loss: 0.6892322674393654
Epoch: 69 | Iteration number: [290/565] 51% | Training loss: 0.6891474762867237
Epoch: 69 | Iteration number: [300/565] 53% | Training loss: 0.6890772672494253
Epoch: 69 | Iteration number: [310/565] 54% | Training loss: 0.6890074751069469
Epoch: 69 | Iteration number: [320/565] 56% | Training loss: 0.6889320688322187
Epoch: 69 | Iteration number: [330/565] 58% | Training loss: 0.6888674649325284
Epoch: 69 | Iteration number: [340/565] 60% | Training loss: 0.6887956056524726
Epoch: 69 | Iteration number: [350/565] 61% | Training loss: 0.6887283745833805
Epoch: 69 | Iteration number: [360/565] 63% | Training loss: 0.6886906125479274
Epoch: 69 | Iteration number: [370/565] 65% | Training loss: 0.6886314881814493
Epoch: 69 | Iteration number: [380/565] 67% | Training loss: 0.6885952036631735
Epoch: 69 | Iteration number: [390/565] 69% | Training loss: 0.6885435692774944
Epoch: 69 | Iteration number: [400/565] 70% | Training loss: 0.6884955593943596
Epoch: 69 | Iteration number: [410/565] 72% | Training loss: 0.6884560987716768
Epoch: 69 | Iteration number: [420/565] 74% | Training loss: 0.6884232389075415
Epoch: 69 | Iteration number: [430/565] 76% | Training loss: 0.6883782126182734
Epoch: 69 | Iteration number: [440/565] 77% | Training loss: 0.6883480978283015
Epoch: 69 | Iteration number: [450/565] 79% | Training loss: 0.6883207099967533
Epoch: 69 | Iteration number: [460/565] 81% | Training loss: 0.6882900319669558
Epoch: 69 | Iteration number: [470/565] 83% | Training loss: 0.6882573286269573
Epoch: 69 | Iteration number: [480/565] 84% | Training loss: 0.6882238099972408
Epoch: 69 | Iteration number: [490/565] 86% | Training loss: 0.6881910673209599
Epoch: 69 | Iteration number: [500/565] 88% | Training loss: 0.6881664193868637
Epoch: 69 | Iteration number: [510/565] 90% | Training loss: 0.6881366707530676
Epoch: 69 | Iteration number: [520/565] 92% | Training loss: 0.6881032550564179
Epoch: 69 | Iteration number: [530/565] 93% | Training loss: 0.6880851271017543
Epoch: 69 | Iteration number: [540/565] 95% | Training loss: 0.6880576736397214
Epoch: 69 | Iteration number: [550/565] 97% | Training loss: 0.6880372602289373
Epoch: 69 | Iteration number: [560/565] 99% | Training loss: 0.6880119945321764

 End of epoch: 69 | Train Loss: 0.6867822183971911 | Training Time: 89 

 End of epoch: 69 | Eval Loss: 0.6891012191772461 | Evaluating Time: 6 
Epoch: 70 | Iteration number: [10/565] 1% | Training loss: 0.7553127884864808
Epoch: 70 | Iteration number: [20/565] 3% | Training loss: 0.721162211894989
Epoch: 70 | Iteration number: [30/565] 5% | Training loss: 0.7097935398419698
Epoch: 70 | Iteration number: [40/565] 7% | Training loss: 0.7040449365973472
Epoch: 70 | Iteration number: [50/565] 8% | Training loss: 0.7004818475246429
Epoch: 70 | Iteration number: [60/565] 10% | Training loss: 0.6982268879810969
Epoch: 70 | Iteration number: [70/565] 12% | Training loss: 0.6965631289141518
Epoch: 70 | Iteration number: [80/565] 14% | Training loss: 0.6953480936586857
Epoch: 70 | Iteration number: [90/565] 15% | Training loss: 0.6944285935825771
Epoch: 70 | Iteration number: [100/565] 17% | Training loss: 0.6937011134624481
Epoch: 70 | Iteration number: [110/565] 19% | Training loss: 0.6930974781513214
Epoch: 70 | Iteration number: [120/565] 21% | Training loss: 0.6925967027743657
Epoch: 70 | Iteration number: [130/565] 23% | Training loss: 0.6921827889405764
Epoch: 70 | Iteration number: [140/565] 24% | Training loss: 0.6917700209787914
Epoch: 70 | Iteration number: [150/565] 26% | Training loss: 0.6914367846647899
Epoch: 70 | Iteration number: [160/565] 28% | Training loss: 0.6911515548825264
Epoch: 70 | Iteration number: [170/565] 30% | Training loss: 0.6909102359238792
Epoch: 70 | Iteration number: [180/565] 31% | Training loss: 0.6906998124387529
Epoch: 70 | Iteration number: [190/565] 33% | Training loss: 0.6904794150277188
Epoch: 70 | Iteration number: [200/565] 35% | Training loss: 0.6902971491217613
Epoch: 70 | Iteration number: [210/565] 37% | Training loss: 0.6901417908214388
Epoch: 70 | Iteration number: [220/565] 38% | Training loss: 0.6899974237788807
Epoch: 70 | Iteration number: [230/565] 40% | Training loss: 0.6898337527461674
Epoch: 70 | Iteration number: [240/565] 42% | Training loss: 0.689697478711605
Epoch: 70 | Iteration number: [250/565] 44% | Training loss: 0.6895942840576171
Epoch: 70 | Iteration number: [260/565] 46% | Training loss: 0.6894742181667914
Epoch: 70 | Iteration number: [270/565] 47% | Training loss: 0.6893747219332942
Epoch: 70 | Iteration number: [280/565] 49% | Training loss: 0.6892812339322908
Epoch: 70 | Iteration number: [290/565] 51% | Training loss: 0.6891941393243856
Epoch: 70 | Iteration number: [300/565] 53% | Training loss: 0.6891175814469656
Epoch: 70 | Iteration number: [310/565] 54% | Training loss: 0.6890279383428635
Epoch: 70 | Iteration number: [320/565] 56% | Training loss: 0.6889676695689559
Epoch: 70 | Iteration number: [330/565] 58% | Training loss: 0.6888888557751973
Epoch: 70 | Iteration number: [340/565] 60% | Training loss: 0.6888339927967857
Epoch: 70 | Iteration number: [350/565] 61% | Training loss: 0.688771676336016
Epoch: 70 | Iteration number: [360/565] 63% | Training loss: 0.688723118768798
Epoch: 70 | Iteration number: [370/565] 65% | Training loss: 0.6886776197601009
Epoch: 70 | Iteration number: [380/565] 67% | Training loss: 0.6886279084180531
Epoch: 70 | Iteration number: [390/565] 69% | Training loss: 0.6885896091277782
Epoch: 70 | Iteration number: [400/565] 70% | Training loss: 0.6885351349413394
Epoch: 70 | Iteration number: [410/565] 72% | Training loss: 0.6884965043242385
Epoch: 70 | Iteration number: [420/565] 74% | Training loss: 0.6884425143400829
Epoch: 70 | Iteration number: [430/565] 76% | Training loss: 0.688391052983528
Epoch: 70 | Iteration number: [440/565] 77% | Training loss: 0.6883574702522971
Epoch: 70 | Iteration number: [450/565] 79% | Training loss: 0.6883385413222842
Epoch: 70 | Iteration number: [460/565] 81% | Training loss: 0.6882982137410537
Epoch: 70 | Iteration number: [470/565] 83% | Training loss: 0.688268177813672
Epoch: 70 | Iteration number: [480/565] 84% | Training loss: 0.6882358034451802
Epoch: 70 | Iteration number: [490/565] 86% | Training loss: 0.6882175064816767
Epoch: 70 | Iteration number: [500/565] 88% | Training loss: 0.6881902807950974
Epoch: 70 | Iteration number: [510/565] 90% | Training loss: 0.6881698262457754
Epoch: 70 | Iteration number: [520/565] 92% | Training loss: 0.6881403885208643
Epoch: 70 | Iteration number: [530/565] 93% | Training loss: 0.6881185208851437
Epoch: 70 | Iteration number: [540/565] 95% | Training loss: 0.6880906729786485
Epoch: 70 | Iteration number: [550/565] 97% | Training loss: 0.6880614454096013
Epoch: 70 | Iteration number: [560/565] 99% | Training loss: 0.6880355263394969

 End of epoch: 70 | Train Loss: 0.6868097002527355 | Training Time: 89 

 End of epoch: 70 | Eval Loss: 0.6899589470454625 | Evaluating Time: 6 
Epoch: 71 | Iteration number: [10/565] 1% | Training loss: 0.7555647611618042
Epoch: 71 | Iteration number: [20/565] 3% | Training loss: 0.7211614102125168
Epoch: 71 | Iteration number: [30/565] 5% | Training loss: 0.7097678164641062
Epoch: 71 | Iteration number: [40/565] 7% | Training loss: 0.704004117846489
Epoch: 71 | Iteration number: [50/565] 8% | Training loss: 0.7005528533458709
Epoch: 71 | Iteration number: [60/565] 10% | Training loss: 0.6981859107812246
Epoch: 71 | Iteration number: [70/565] 12% | Training loss: 0.6966083543641227
Epoch: 71 | Iteration number: [80/565] 14% | Training loss: 0.6953786216676235
Epoch: 71 | Iteration number: [90/565] 15% | Training loss: 0.6944015973144108
Epoch: 71 | Iteration number: [100/565] 17% | Training loss: 0.6936828607320785
Epoch: 71 | Iteration number: [110/565] 19% | Training loss: 0.6930688180706718
Epoch: 71 | Iteration number: [120/565] 21% | Training loss: 0.6925668636957805
Epoch: 71 | Iteration number: [130/565] 23% | Training loss: 0.6921266257762909
Epoch: 71 | Iteration number: [140/565] 24% | Training loss: 0.6917447618075779
Epoch: 71 | Iteration number: [150/565] 26% | Training loss: 0.6914222586154938
Epoch: 71 | Iteration number: [160/565] 28% | Training loss: 0.691137682273984
Epoch: 71 | Iteration number: [170/565] 30% | Training loss: 0.6908744300113004
Epoch: 71 | Iteration number: [180/565] 31% | Training loss: 0.6906663629743788
Epoch: 71 | Iteration number: [190/565] 33% | Training loss: 0.6904314612087451
Epoch: 71 | Iteration number: [200/565] 35% | Training loss: 0.6902312695980072
Epoch: 71 | Iteration number: [210/565] 37% | Training loss: 0.6900470191524142
Epoch: 71 | Iteration number: [220/565] 38% | Training loss: 0.689910091324286
Epoch: 71 | Iteration number: [230/565] 40% | Training loss: 0.6897705277670985
Epoch: 71 | Iteration number: [240/565] 42% | Training loss: 0.6896466853717963
Epoch: 71 | Iteration number: [250/565] 44% | Training loss: 0.6895291407108307
Epoch: 71 | Iteration number: [260/565] 46% | Training loss: 0.6894321198646839
Epoch: 71 | Iteration number: [270/565] 47% | Training loss: 0.6893463183332372
Epoch: 71 | Iteration number: [280/565] 49% | Training loss: 0.6892559347408158
Epoch: 71 | Iteration number: [290/565] 51% | Training loss: 0.6891681899284494
Epoch: 71 | Iteration number: [300/565] 53% | Training loss: 0.6890748278299967
Epoch: 71 | Iteration number: [310/565] 54% | Training loss: 0.6890081594067236
Epoch: 71 | Iteration number: [320/565] 56% | Training loss: 0.6889306962490082
Epoch: 71 | Iteration number: [330/565] 58% | Training loss: 0.688864467902617
Epoch: 71 | Iteration number: [340/565] 60% | Training loss: 0.6888060685466317
Epoch: 71 | Iteration number: [350/565] 61% | Training loss: 0.6887435647419521
Epoch: 71 | Iteration number: [360/565] 63% | Training loss: 0.6886842217710283
Epoch: 71 | Iteration number: [370/565] 65% | Training loss: 0.6886398703665346
Epoch: 71 | Iteration number: [380/565] 67% | Training loss: 0.6885936268066105
Epoch: 71 | Iteration number: [390/565] 69% | Training loss: 0.688547539863831
Epoch: 71 | Iteration number: [400/565] 70% | Training loss: 0.6885070717334747
Epoch: 71 | Iteration number: [410/565] 72% | Training loss: 0.6884726934316682
Epoch: 71 | Iteration number: [420/565] 74% | Training loss: 0.6884305238723755
Epoch: 71 | Iteration number: [430/565] 76% | Training loss: 0.6883916032868762
Epoch: 71 | Iteration number: [440/565] 77% | Training loss: 0.6883522453633222
Epoch: 71 | Iteration number: [450/565] 79% | Training loss: 0.6883158156606886
Epoch: 71 | Iteration number: [460/565] 81% | Training loss: 0.688267483011536
Epoch: 71 | Iteration number: [470/565] 83% | Training loss: 0.6882405013480085
Epoch: 71 | Iteration number: [480/565] 84% | Training loss: 0.6882043528060119
Epoch: 71 | Iteration number: [490/565] 86% | Training loss: 0.6881822488745865
Epoch: 71 | Iteration number: [500/565] 88% | Training loss: 0.6881483827829361
Epoch: 71 | Iteration number: [510/565] 90% | Training loss: 0.6881175800865772
Epoch: 71 | Iteration number: [520/565] 92% | Training loss: 0.6880912416256391
Epoch: 71 | Iteration number: [530/565] 93% | Training loss: 0.6880621328668775
Epoch: 71 | Iteration number: [540/565] 95% | Training loss: 0.6880392669527619
Epoch: 71 | Iteration number: [550/565] 97% | Training loss: 0.6880256610566919
Epoch: 71 | Iteration number: [560/565] 99% | Training loss: 0.6879993973033769

 End of epoch: 71 | Train Loss: 0.6867805393396226 | Training Time: 90 

 End of epoch: 71 | Eval Loss: 0.6897580283028739 | Evaluating Time: 6 
Epoch: 72 | Iteration number: [10/565] 1% | Training loss: 0.7553301632404328
Epoch: 72 | Iteration number: [20/565] 3% | Training loss: 0.7210231572389603
Epoch: 72 | Iteration number: [30/565] 5% | Training loss: 0.7096378763516744
Epoch: 72 | Iteration number: [40/565] 7% | Training loss: 0.7039479359984397
Epoch: 72 | Iteration number: [50/565] 8% | Training loss: 0.7004449129104614
Epoch: 72 | Iteration number: [60/565] 10% | Training loss: 0.6981626282135646
Epoch: 72 | Iteration number: [70/565] 12% | Training loss: 0.6965531366212028
Epoch: 72 | Iteration number: [80/565] 14% | Training loss: 0.695367407798767
Epoch: 72 | Iteration number: [90/565] 15% | Training loss: 0.6944556812445323
Epoch: 72 | Iteration number: [100/565] 17% | Training loss: 0.6937051153182984
Epoch: 72 | Iteration number: [110/565] 19% | Training loss: 0.6930298122492704
Epoch: 72 | Iteration number: [120/565] 21% | Training loss: 0.6925298059980075
Epoch: 72 | Iteration number: [130/565] 23% | Training loss: 0.6921034143521235
Epoch: 72 | Iteration number: [140/565] 24% | Training loss: 0.6917157147611891
Epoch: 72 | Iteration number: [150/565] 26% | Training loss: 0.6913855302333832
Epoch: 72 | Iteration number: [160/565] 28% | Training loss: 0.6910830717533827
Epoch: 72 | Iteration number: [170/565] 30% | Training loss: 0.6908453306731056
Epoch: 72 | Iteration number: [180/565] 31% | Training loss: 0.6906213710705439
Epoch: 72 | Iteration number: [190/565] 33% | Training loss: 0.6904113985990223
Epoch: 72 | Iteration number: [200/565] 35% | Training loss: 0.6902472048997879
Epoch: 72 | Iteration number: [210/565] 37% | Training loss: 0.6900882701079051
Epoch: 72 | Iteration number: [220/565] 38% | Training loss: 0.6899215064265511
Epoch: 72 | Iteration number: [230/565] 40% | Training loss: 0.689794413421465
Epoch: 72 | Iteration number: [240/565] 42% | Training loss: 0.6896646238863469
Epoch: 72 | Iteration number: [250/565] 44% | Training loss: 0.6895407679080963
Epoch: 72 | Iteration number: [260/565] 46% | Training loss: 0.6894502222537995
Epoch: 72 | Iteration number: [270/565] 47% | Training loss: 0.6893478649633902
Epoch: 72 | Iteration number: [280/565] 49% | Training loss: 0.6892650889498847
Epoch: 72 | Iteration number: [290/565] 51% | Training loss: 0.6891726148539576
Epoch: 72 | Iteration number: [300/565] 53% | Training loss: 0.689096408089002
Epoch: 72 | Iteration number: [310/565] 54% | Training loss: 0.6890328316919265
Epoch: 72 | Iteration number: [320/565] 56% | Training loss: 0.6889530017971992
Epoch: 72 | Iteration number: [330/565] 58% | Training loss: 0.6888928256251595
Epoch: 72 | Iteration number: [340/565] 60% | Training loss: 0.688829262992915
Epoch: 72 | Iteration number: [350/565] 61% | Training loss: 0.688775987625122
Epoch: 72 | Iteration number: [360/565] 63% | Training loss: 0.6887261572811338
Epoch: 72 | Iteration number: [370/565] 65% | Training loss: 0.6886707964781168
Epoch: 72 | Iteration number: [380/565] 67% | Training loss: 0.6886145464683834
Epoch: 72 | Iteration number: [390/565] 69% | Training loss: 0.68857145798512
Epoch: 72 | Iteration number: [400/565] 70% | Training loss: 0.6885206663608551
Epoch: 72 | Iteration number: [410/565] 72% | Training loss: 0.6884834862336879
Epoch: 72 | Iteration number: [420/565] 74% | Training loss: 0.6884448133763813
Epoch: 72 | Iteration number: [430/565] 76% | Training loss: 0.6883968037228252
Epoch: 72 | Iteration number: [440/565] 77% | Training loss: 0.688366085561839
Epoch: 72 | Iteration number: [450/565] 79% | Training loss: 0.6883247097333273
Epoch: 72 | Iteration number: [460/565] 81% | Training loss: 0.6882894217967988
Epoch: 72 | Iteration number: [470/565] 83% | Training loss: 0.6882584488138239
Epoch: 72 | Iteration number: [480/565] 84% | Training loss: 0.6882291546712319
Epoch: 72 | Iteration number: [490/565] 86% | Training loss: 0.6882053203728734
Epoch: 72 | Iteration number: [500/565] 88% | Training loss: 0.6881802808046341
Epoch: 72 | Iteration number: [510/565] 90% | Training loss: 0.6881532767239739
Epoch: 72 | Iteration number: [520/565] 92% | Training loss: 0.6881208918415583
Epoch: 72 | Iteration number: [530/565] 93% | Training loss: 0.6880875988951269
Epoch: 72 | Iteration number: [540/565] 95% | Training loss: 0.6880605224106047
Epoch: 72 | Iteration number: [550/565] 97% | Training loss: 0.6880371710387143
Epoch: 72 | Iteration number: [560/565] 99% | Training loss: 0.6880133352109364

 End of epoch: 72 | Train Loss: 0.6867846531150615 | Training Time: 90 

 End of epoch: 72 | Eval Loss: 0.6896114008767265 | Evaluating Time: 6 
Epoch: 73 | Iteration number: [10/565] 1% | Training loss: 0.755147385597229
Epoch: 73 | Iteration number: [20/565] 3% | Training loss: 0.7210785120725631
Epoch: 73 | Iteration number: [30/565] 5% | Training loss: 0.709618620077769
Epoch: 73 | Iteration number: [40/565] 7% | Training loss: 0.7039775639772415
Epoch: 73 | Iteration number: [50/565] 8% | Training loss: 0.7006042206287384
Epoch: 73 | Iteration number: [60/565] 10% | Training loss: 0.6982892443736394
Epoch: 73 | Iteration number: [70/565] 12% | Training loss: 0.6966459674494607
Epoch: 73 | Iteration number: [80/565] 14% | Training loss: 0.6954152539372445
Epoch: 73 | Iteration number: [90/565] 15% | Training loss: 0.6944874505201976
Epoch: 73 | Iteration number: [100/565] 17% | Training loss: 0.6937326574325562
Epoch: 73 | Iteration number: [110/565] 19% | Training loss: 0.693094953623685
Epoch: 73 | Iteration number: [120/565] 21% | Training loss: 0.6925261278947195
Epoch: 73 | Iteration number: [130/565] 23% | Training loss: 0.6920698693165412
Epoch: 73 | Iteration number: [140/565] 24% | Training loss: 0.6916976315634591
Epoch: 73 | Iteration number: [150/565] 26% | Training loss: 0.6913718831539154
Epoch: 73 | Iteration number: [160/565] 28% | Training loss: 0.6911117423325777
Epoch: 73 | Iteration number: [170/565] 30% | Training loss: 0.690856796503067
Epoch: 73 | Iteration number: [180/565] 31% | Training loss: 0.6905983868572447
Epoch: 73 | Iteration number: [190/565] 33% | Training loss: 0.6904055551478737
Epoch: 73 | Iteration number: [200/565] 35% | Training loss: 0.6902135360240936
Epoch: 73 | Iteration number: [210/565] 37% | Training loss: 0.6900322803429195
Epoch: 73 | Iteration number: [220/565] 38% | Training loss: 0.6898839124224403
Epoch: 73 | Iteration number: [230/565] 40% | Training loss: 0.689745701395947
Epoch: 73 | Iteration number: [240/565] 42% | Training loss: 0.6896334663033485
Epoch: 73 | Iteration number: [250/565] 44% | Training loss: 0.6895193960666657
Epoch: 73 | Iteration number: [260/565] 46% | Training loss: 0.6894131367023174
Epoch: 73 | Iteration number: [270/565] 47% | Training loss: 0.6893141662632978
Epoch: 73 | Iteration number: [280/565] 49% | Training loss: 0.6892269507050515
Epoch: 73 | Iteration number: [290/565] 51% | Training loss: 0.6891340864115748
Epoch: 73 | Iteration number: [300/565] 53% | Training loss: 0.6890615214904149
Epoch: 73 | Iteration number: [310/565] 54% | Training loss: 0.6889999860717404
Epoch: 73 | Iteration number: [320/565] 56% | Training loss: 0.6889233974739909
Epoch: 73 | Iteration number: [330/565] 58% | Training loss: 0.688868960647872
Epoch: 73 | Iteration number: [340/565] 60% | Training loss: 0.688809600647758
Epoch: 73 | Iteration number: [350/565] 61% | Training loss: 0.6887496318135943
Epoch: 73 | Iteration number: [360/565] 63% | Training loss: 0.6887049083908399
Epoch: 73 | Iteration number: [370/565] 65% | Training loss: 0.6886550073688095
Epoch: 73 | Iteration number: [380/565] 67% | Training loss: 0.6886077913798784
Epoch: 73 | Iteration number: [390/565] 69% | Training loss: 0.6885681078984187
Epoch: 73 | Iteration number: [400/565] 70% | Training loss: 0.6885251931846141
Epoch: 73 | Iteration number: [410/565] 72% | Training loss: 0.6884863132383765
Epoch: 73 | Iteration number: [420/565] 74% | Training loss: 0.6884471596706481
Epoch: 73 | Iteration number: [430/565] 76% | Training loss: 0.6883995354175567
Epoch: 73 | Iteration number: [440/565] 77% | Training loss: 0.6883606375618414
Epoch: 73 | Iteration number: [450/565] 79% | Training loss: 0.688322096798155
Epoch: 73 | Iteration number: [460/565] 81% | Training loss: 0.688290998339653
Epoch: 73 | Iteration number: [470/565] 83% | Training loss: 0.6882600737378952
Epoch: 73 | Iteration number: [480/565] 84% | Training loss: 0.6882301066070795
Epoch: 73 | Iteration number: [490/565] 86% | Training loss: 0.6882026352444474
Epoch: 73 | Iteration number: [500/565] 88% | Training loss: 0.688180191040039
Epoch: 73 | Iteration number: [510/565] 90% | Training loss: 0.6881418250355066
Epoch: 73 | Iteration number: [520/565] 92% | Training loss: 0.6881189842636769
Epoch: 73 | Iteration number: [530/565] 93% | Training loss: 0.6880904277540603
Epoch: 73 | Iteration number: [540/565] 95% | Training loss: 0.6880635418273785
Epoch: 73 | Iteration number: [550/565] 97% | Training loss: 0.6880431699752808
Epoch: 73 | Iteration number: [560/565] 99% | Training loss: 0.688020458072424

 End of epoch: 73 | Train Loss: 0.6867943345972922 | Training Time: 89 

 End of epoch: 73 | Eval Loss: 0.690168593611036 | Evaluating Time: 6 
Epoch: 74 | Iteration number: [10/565] 1% | Training loss: 0.7555394768714905
Epoch: 74 | Iteration number: [20/565] 3% | Training loss: 0.7212610363960266
Epoch: 74 | Iteration number: [30/565] 5% | Training loss: 0.7097413996855418
Epoch: 74 | Iteration number: [40/565] 7% | Training loss: 0.7040185898542404
Epoch: 74 | Iteration number: [50/565] 8% | Training loss: 0.70053053855896
Epoch: 74 | Iteration number: [60/565] 10% | Training loss: 0.6982081701358159
Epoch: 74 | Iteration number: [70/565] 12% | Training loss: 0.6965651290757315
Epoch: 74 | Iteration number: [80/565] 14% | Training loss: 0.6953055657446384
Epoch: 74 | Iteration number: [90/565] 15% | Training loss: 0.6943307830227746
Epoch: 74 | Iteration number: [100/565] 17% | Training loss: 0.6935618662834168
Epoch: 74 | Iteration number: [110/565] 19% | Training loss: 0.6929192402146079
Epoch: 74 | Iteration number: [120/565] 21% | Training loss: 0.692397765815258
Epoch: 74 | Iteration number: [130/565] 23% | Training loss: 0.6919413140186896
Epoch: 74 | Iteration number: [140/565] 24% | Training loss: 0.6915655038186482
Epoch: 74 | Iteration number: [150/565] 26% | Training loss: 0.6912615990638733
Epoch: 74 | Iteration number: [160/565] 28% | Training loss: 0.6909930229187011
Epoch: 74 | Iteration number: [170/565] 30% | Training loss: 0.6907515788779539
Epoch: 74 | Iteration number: [180/565] 31% | Training loss: 0.6905342396762636
Epoch: 74 | Iteration number: [190/565] 33% | Training loss: 0.6903292546146794
Epoch: 74 | Iteration number: [200/565] 35% | Training loss: 0.6901338678598404
Epoch: 74 | Iteration number: [210/565] 37% | Training loss: 0.6899911301476614
Epoch: 74 | Iteration number: [220/565] 38% | Training loss: 0.6898543631488626
Epoch: 74 | Iteration number: [230/565] 40% | Training loss: 0.6897070423416469
Epoch: 74 | Iteration number: [240/565] 42% | Training loss: 0.6895957571764787
Epoch: 74 | Iteration number: [250/565] 44% | Training loss: 0.6894713554382325
Epoch: 74 | Iteration number: [260/565] 46% | Training loss: 0.6893771792833622
Epoch: 74 | Iteration number: [270/565] 47% | Training loss: 0.6892872642587733
Epoch: 74 | Iteration number: [280/565] 49% | Training loss: 0.6891885727643967
Epoch: 74 | Iteration number: [290/565] 51% | Training loss: 0.6891170121472457
Epoch: 74 | Iteration number: [300/565] 53% | Training loss: 0.689051931699117
Epoch: 74 | Iteration number: [310/565] 54% | Training loss: 0.68897041889929
Epoch: 74 | Iteration number: [320/565] 56% | Training loss: 0.6889034176245332
Epoch: 74 | Iteration number: [330/565] 58% | Training loss: 0.6888470628044822
Epoch: 74 | Iteration number: [340/565] 60% | Training loss: 0.6887914150953293
Epoch: 74 | Iteration number: [350/565] 61% | Training loss: 0.688725140094757
Epoch: 74 | Iteration number: [360/565] 63% | Training loss: 0.6886728179123667
Epoch: 74 | Iteration number: [370/565] 65% | Training loss: 0.6886241439226511
Epoch: 74 | Iteration number: [380/565] 67% | Training loss: 0.6885722866183833
Epoch: 74 | Iteration number: [390/565] 69% | Training loss: 0.6885189516422076
Epoch: 74 | Iteration number: [400/565] 70% | Training loss: 0.6884795935451984
Epoch: 74 | Iteration number: [410/565] 72% | Training loss: 0.6884555668365665
Epoch: 74 | Iteration number: [420/565] 74% | Training loss: 0.688416220602535
Epoch: 74 | Iteration number: [430/565] 76% | Training loss: 0.6883827809677567
Epoch: 74 | Iteration number: [440/565] 77% | Training loss: 0.6883455756035718
Epoch: 74 | Iteration number: [450/565] 79% | Training loss: 0.6883152062363095
Epoch: 74 | Iteration number: [460/565] 81% | Training loss: 0.6882831734159719
Epoch: 74 | Iteration number: [470/565] 83% | Training loss: 0.6882598955580529
Epoch: 74 | Iteration number: [480/565] 84% | Training loss: 0.6882279444485903
Epoch: 74 | Iteration number: [490/565] 86% | Training loss: 0.6881923251006068
Epoch: 74 | Iteration number: [500/565] 88% | Training loss: 0.6881553041934967
Epoch: 74 | Iteration number: [510/565] 90% | Training loss: 0.6881262484718772
Epoch: 74 | Iteration number: [520/565] 92% | Training loss: 0.6881028324365616
Epoch: 74 | Iteration number: [530/565] 93% | Training loss: 0.6880763301309549
Epoch: 74 | Iteration number: [540/565] 95% | Training loss: 0.6880462892629482
Epoch: 74 | Iteration number: [550/565] 97% | Training loss: 0.6880315619165247
Epoch: 74 | Iteration number: [560/565] 99% | Training loss: 0.6880069250507014

 End of epoch: 74 | Train Loss: 0.6867803843675462 | Training Time: 90 

 End of epoch: 74 | Eval Loss: 0.6898395248821804 | Evaluating Time: 6 
Epoch: 75 | Iteration number: [10/565] 1% | Training loss: 0.7559011995792388
Epoch: 75 | Iteration number: [20/565] 3% | Training loss: 0.7214597731828689
Epoch: 75 | Iteration number: [30/565] 5% | Training loss: 0.7098753273487091
Epoch: 75 | Iteration number: [40/565] 7% | Training loss: 0.7039238452911377
Epoch: 75 | Iteration number: [50/565] 8% | Training loss: 0.7004975211620331
Epoch: 75 | Iteration number: [60/565] 10% | Training loss: 0.6982856382926305
Epoch: 75 | Iteration number: [70/565] 12% | Training loss: 0.6966507843562535
Epoch: 75 | Iteration number: [80/565] 14% | Training loss: 0.6953777618706226
Epoch: 75 | Iteration number: [90/565] 15% | Training loss: 0.6944475491841634
Epoch: 75 | Iteration number: [100/565] 17% | Training loss: 0.6936838817596436
Epoch: 75 | Iteration number: [110/565] 19% | Training loss: 0.6930972283536737
Epoch: 75 | Iteration number: [120/565] 21% | Training loss: 0.6925947412848472
Epoch: 75 | Iteration number: [130/565] 23% | Training loss: 0.6921505409937638
Epoch: 75 | Iteration number: [140/565] 24% | Training loss: 0.6917985371180944
Epoch: 75 | Iteration number: [150/565] 26% | Training loss: 0.6914667026201884
Epoch: 75 | Iteration number: [160/565] 28% | Training loss: 0.6911493014544249
Epoch: 75 | Iteration number: [170/565] 30% | Training loss: 0.6908808308489183
Epoch: 75 | Iteration number: [180/565] 31% | Training loss: 0.6906567570235994
Epoch: 75 | Iteration number: [190/565] 33% | Training loss: 0.6904559088380713
Epoch: 75 | Iteration number: [200/565] 35% | Training loss: 0.6902752801775932
Epoch: 75 | Iteration number: [210/565] 37% | Training loss: 0.690106445267087
Epoch: 75 | Iteration number: [220/565] 38% | Training loss: 0.6899488977410576
Epoch: 75 | Iteration number: [230/565] 40% | Training loss: 0.6898032229879628
Epoch: 75 | Iteration number: [240/565] 42% | Training loss: 0.6896562370161216
Epoch: 75 | Iteration number: [250/565] 44% | Training loss: 0.6895496697425842
Epoch: 75 | Iteration number: [260/565] 46% | Training loss: 0.6894599135105427
Epoch: 75 | Iteration number: [270/565] 47% | Training loss: 0.6893808411227332
Epoch: 75 | Iteration number: [280/565] 49% | Training loss: 0.6892831830041749
Epoch: 75 | Iteration number: [290/565] 51% | Training loss: 0.6892193208480704
Epoch: 75 | Iteration number: [300/565] 53% | Training loss: 0.6891169406970342
Epoch: 75 | Iteration number: [310/565] 54% | Training loss: 0.689044367113421
Epoch: 75 | Iteration number: [320/565] 56% | Training loss: 0.6889735022559762
Epoch: 75 | Iteration number: [330/565] 58% | Training loss: 0.6889030927961522
Epoch: 75 | Iteration number: [340/565] 60% | Training loss: 0.6888413764098111
Epoch: 75 | Iteration number: [350/565] 61% | Training loss: 0.688768926007407
Epoch: 75 | Iteration number: [360/565] 63% | Training loss: 0.6887051850557327
Epoch: 75 | Iteration number: [370/565] 65% | Training loss: 0.6886412037385476
Epoch: 75 | Iteration number: [380/565] 67% | Training loss: 0.6885935328508678
Epoch: 75 | Iteration number: [390/565] 69% | Training loss: 0.6885390827288994
Epoch: 75 | Iteration number: [400/565] 70% | Training loss: 0.6884938627481461
Epoch: 75 | Iteration number: [410/565] 72% | Training loss: 0.688461464352724
Epoch: 75 | Iteration number: [420/565] 74% | Training loss: 0.6884240820294335
Epoch: 75 | Iteration number: [430/565] 76% | Training loss: 0.6883833271126415
Epoch: 75 | Iteration number: [440/565] 77% | Training loss: 0.688350806182081
Epoch: 75 | Iteration number: [450/565] 79% | Training loss: 0.6883164287938012
Epoch: 75 | Iteration number: [460/565] 81% | Training loss: 0.6882823621449263
Epoch: 75 | Iteration number: [470/565] 83% | Training loss: 0.6882435577981015
Epoch: 75 | Iteration number: [480/565] 84% | Training loss: 0.6882109413544337
Epoch: 75 | Iteration number: [490/565] 86% | Training loss: 0.6881821442623528
Epoch: 75 | Iteration number: [500/565] 88% | Training loss: 0.6881534737348557
Epoch: 75 | Iteration number: [510/565] 90% | Training loss: 0.6881299994739831
Epoch: 75 | Iteration number: [520/565] 92% | Training loss: 0.6881018188137275
Epoch: 75 | Iteration number: [530/565] 93% | Training loss: 0.6880735774085207
Epoch: 75 | Iteration number: [540/565] 95% | Training loss: 0.6880463422448547
Epoch: 75 | Iteration number: [550/565] 97% | Training loss: 0.688027427629991
Epoch: 75 | Iteration number: [560/565] 99% | Training loss: 0.6880049044532436

 End of epoch: 75 | Train Loss: 0.6867755318109968 | Training Time: 90 

 End of epoch: 75 | Eval Loss: 0.6897446683474949 | Evaluating Time: 6 
Epoch: 76 | Iteration number: [10/565] 1% | Training loss: 0.7558090925216675
Epoch: 76 | Iteration number: [20/565] 3% | Training loss: 0.7212495893239975
Epoch: 76 | Iteration number: [30/565] 5% | Training loss: 0.7096971531709035
Epoch: 76 | Iteration number: [40/565] 7% | Training loss: 0.7038764119148254
Epoch: 76 | Iteration number: [50/565] 8% | Training loss: 0.7003427600860596
Epoch: 76 | Iteration number: [60/565] 10% | Training loss: 0.6981348713239034
Epoch: 76 | Iteration number: [70/565] 12% | Training loss: 0.6965420705931528
Epoch: 76 | Iteration number: [80/565] 14% | Training loss: 0.6953600011765957
Epoch: 76 | Iteration number: [90/565] 15% | Training loss: 0.694428003496594
Epoch: 76 | Iteration number: [100/565] 17% | Training loss: 0.6936198848485947
Epoch: 76 | Iteration number: [110/565] 19% | Training loss: 0.6930200739340349
Epoch: 76 | Iteration number: [120/565] 21% | Training loss: 0.6924883499741554
Epoch: 76 | Iteration number: [130/565] 23% | Training loss: 0.6920319887307974
Epoch: 76 | Iteration number: [140/565] 24% | Training loss: 0.6916759929486683
Epoch: 76 | Iteration number: [150/565] 26% | Training loss: 0.6913672045866648
Epoch: 76 | Iteration number: [160/565] 28% | Training loss: 0.6910898480564356
Epoch: 76 | Iteration number: [170/565] 30% | Training loss: 0.6908741214696099
Epoch: 76 | Iteration number: [180/565] 31% | Training loss: 0.690645459956593
Epoch: 76 | Iteration number: [190/565] 33% | Training loss: 0.6904234886169434
Epoch: 76 | Iteration number: [200/565] 35% | Training loss: 0.6902374240756035
Epoch: 76 | Iteration number: [210/565] 37% | Training loss: 0.6900773065430778
Epoch: 76 | Iteration number: [220/565] 38% | Training loss: 0.6899288602850654
Epoch: 76 | Iteration number: [230/565] 40% | Training loss: 0.6898043583268705
Epoch: 76 | Iteration number: [240/565] 42% | Training loss: 0.6896767877042294
Epoch: 76 | Iteration number: [250/565] 44% | Training loss: 0.6895569298267364
Epoch: 76 | Iteration number: [260/565] 46% | Training loss: 0.6894425793335988
Epoch: 76 | Iteration number: [270/565] 47% | Training loss: 0.6893370261898747
Epoch: 76 | Iteration number: [280/565] 49% | Training loss: 0.6892284538064685
Epoch: 76 | Iteration number: [290/565] 51% | Training loss: 0.6891416153003429
Epoch: 76 | Iteration number: [300/565] 53% | Training loss: 0.6890642424424489
Epoch: 76 | Iteration number: [310/565] 54% | Training loss: 0.68899429228998
Epoch: 76 | Iteration number: [320/565] 56% | Training loss: 0.688928735256195
Epoch: 76 | Iteration number: [330/565] 58% | Training loss: 0.6888645408731519
Epoch: 76 | Iteration number: [340/565] 60% | Training loss: 0.6888030060950447
Epoch: 76 | Iteration number: [350/565] 61% | Training loss: 0.6887458498137338
Epoch: 76 | Iteration number: [360/565] 63% | Training loss: 0.6886914903918903
Epoch: 76 | Iteration number: [370/565] 65% | Training loss: 0.6886484930644164
Epoch: 76 | Iteration number: [380/565] 67% | Training loss: 0.6886110145794718
Epoch: 76 | Iteration number: [390/565] 69% | Training loss: 0.688560942808787
Epoch: 76 | Iteration number: [400/565] 70% | Training loss: 0.6885298904776573
Epoch: 76 | Iteration number: [410/565] 72% | Training loss: 0.6884905620319087
Epoch: 76 | Iteration number: [420/565] 74% | Training loss: 0.6884583772647949
Epoch: 76 | Iteration number: [430/565] 76% | Training loss: 0.6884156557016594
Epoch: 76 | Iteration number: [440/565] 77% | Training loss: 0.6883676398884166
Epoch: 76 | Iteration number: [450/565] 79% | Training loss: 0.6883273567093743
Epoch: 76 | Iteration number: [460/565] 81% | Training loss: 0.6882944377868072
Epoch: 76 | Iteration number: [470/565] 83% | Training loss: 0.6882703256099783
Epoch: 76 | Iteration number: [480/565] 84% | Training loss: 0.6882335552324851
Epoch: 76 | Iteration number: [490/565] 86% | Training loss: 0.6882138878715282
Epoch: 76 | Iteration number: [500/565] 88% | Training loss: 0.688186849117279
Epoch: 76 | Iteration number: [510/565] 90% | Training loss: 0.6881602371440214
Epoch: 76 | Iteration number: [520/565] 92% | Training loss: 0.6881217025793516
Epoch: 76 | Iteration number: [530/565] 93% | Training loss: 0.688094324660751
Epoch: 76 | Iteration number: [540/565] 95% | Training loss: 0.6880657959867407
Epoch: 76 | Iteration number: [550/565] 97% | Training loss: 0.6880357201532884
Epoch: 76 | Iteration number: [560/565] 99% | Training loss: 0.6880117462149689

 End of epoch: 76 | Train Loss: 0.6867877370488327 | Training Time: 88 

 End of epoch: 76 | Eval Loss: 0.6900665249143328 | Evaluating Time: 6 
Epoch: 77 | Iteration number: [10/565] 1% | Training loss: 0.7551481306552887
Epoch: 77 | Iteration number: [20/565] 3% | Training loss: 0.7207791179418563
Epoch: 77 | Iteration number: [30/565] 5% | Training loss: 0.7093418935934702
Epoch: 77 | Iteration number: [40/565] 7% | Training loss: 0.7037574931979179
Epoch: 77 | Iteration number: [50/565] 8% | Training loss: 0.7003709781169891
Epoch: 77 | Iteration number: [60/565] 10% | Training loss: 0.6981852680444718
Epoch: 77 | Iteration number: [70/565] 12% | Training loss: 0.6964828278337206
Epoch: 77 | Iteration number: [80/565] 14% | Training loss: 0.6952939495444298
Epoch: 77 | Iteration number: [90/565] 15% | Training loss: 0.6943552454312643
Epoch: 77 | Iteration number: [100/565] 17% | Training loss: 0.6936000782251358
Epoch: 77 | Iteration number: [110/565] 19% | Training loss: 0.6930080256678841
Epoch: 77 | Iteration number: [120/565] 21% | Training loss: 0.6924672414859135
Epoch: 77 | Iteration number: [130/565] 23% | Training loss: 0.6920286485782037
Epoch: 77 | Iteration number: [140/565] 24% | Training loss: 0.6916013270616531
Epoch: 77 | Iteration number: [150/565] 26% | Training loss: 0.6912853248914083
Epoch: 77 | Iteration number: [160/565] 28% | Training loss: 0.690998500213027
Epoch: 77 | Iteration number: [170/565] 30% | Training loss: 0.6907519564909094
Epoch: 77 | Iteration number: [180/565] 31% | Training loss: 0.6905593550867505
Epoch: 77 | Iteration number: [190/565] 33% | Training loss: 0.6903398749075438
Epoch: 77 | Iteration number: [200/565] 35% | Training loss: 0.6901765763759613
Epoch: 77 | Iteration number: [210/565] 37% | Training loss: 0.690016390028454
Epoch: 77 | Iteration number: [220/565] 38% | Training loss: 0.68986174762249
Epoch: 77 | Iteration number: [230/565] 40% | Training loss: 0.6897274890671605
Epoch: 77 | Iteration number: [240/565] 42% | Training loss: 0.6896388781567414
Epoch: 77 | Iteration number: [250/565] 44% | Training loss: 0.6895590538978577
Epoch: 77 | Iteration number: [260/565] 46% | Training loss: 0.6894637919389285
Epoch: 77 | Iteration number: [270/565] 47% | Training loss: 0.6893748934622164
Epoch: 77 | Iteration number: [280/565] 49% | Training loss: 0.6892686390451023
Epoch: 77 | Iteration number: [290/565] 51% | Training loss: 0.689181748546403
Epoch: 77 | Iteration number: [300/565] 53% | Training loss: 0.6891045794884364
Epoch: 77 | Iteration number: [310/565] 54% | Training loss: 0.689040990414158
Epoch: 77 | Iteration number: [320/565] 56% | Training loss: 0.6889623243361711
Epoch: 77 | Iteration number: [330/565] 58% | Training loss: 0.6888879338900248
Epoch: 77 | Iteration number: [340/565] 60% | Training loss: 0.68883156793959
Epoch: 77 | Iteration number: [350/565] 61% | Training loss: 0.6887816701616559
Epoch: 77 | Iteration number: [360/565] 63% | Training loss: 0.6887306181920899
Epoch: 77 | Iteration number: [370/565] 65% | Training loss: 0.6886778886253769
Epoch: 77 | Iteration number: [380/565] 67% | Training loss: 0.6886107821213572
Epoch: 77 | Iteration number: [390/565] 69% | Training loss: 0.6885633948521737
Epoch: 77 | Iteration number: [400/565] 70% | Training loss: 0.6885267363488674
Epoch: 77 | Iteration number: [410/565] 72% | Training loss: 0.6884821782751781
Epoch: 77 | Iteration number: [420/565] 74% | Training loss: 0.6884413768847784
Epoch: 77 | Iteration number: [430/565] 76% | Training loss: 0.6883965191453002
Epoch: 77 | Iteration number: [440/565] 77% | Training loss: 0.6883585064248605
Epoch: 77 | Iteration number: [450/565] 79% | Training loss: 0.6883279203044044
Epoch: 77 | Iteration number: [460/565] 81% | Training loss: 0.6882811385652293
Epoch: 77 | Iteration number: [470/565] 83% | Training loss: 0.6882384278672806
Epoch: 77 | Iteration number: [480/565] 84% | Training loss: 0.6882106918841601
Epoch: 77 | Iteration number: [490/565] 86% | Training loss: 0.6881836741554493
Epoch: 77 | Iteration number: [500/565] 88% | Training loss: 0.6881453114748001
Epoch: 77 | Iteration number: [510/565] 90% | Training loss: 0.6881180608973784
Epoch: 77 | Iteration number: [520/565] 92% | Training loss: 0.6880935814518195
Epoch: 77 | Iteration number: [530/565] 93% | Training loss: 0.6880671067057915
Epoch: 77 | Iteration number: [540/565] 95% | Training loss: 0.6880390882492066
Epoch: 77 | Iteration number: [550/565] 97% | Training loss: 0.6880182023481889
Epoch: 77 | Iteration number: [560/565] 99% | Training loss: 0.6879992608513151

 End of epoch: 77 | Train Loss: 0.68677636363865 | Training Time: 91 

 End of epoch: 77 | Eval Loss: 0.6896521704537528 | Evaluating Time: 6 
Epoch: 78 | Iteration number: [10/565] 1% | Training loss: 0.7553924083709717
Epoch: 78 | Iteration number: [20/565] 3% | Training loss: 0.7210521429777146
Epoch: 78 | Iteration number: [30/565] 5% | Training loss: 0.709590901931127
Epoch: 78 | Iteration number: [40/565] 7% | Training loss: 0.7038685038685799
Epoch: 78 | Iteration number: [50/565] 8% | Training loss: 0.7004175555706024
Epoch: 78 | Iteration number: [60/565] 10% | Training loss: 0.6981067766745885
Epoch: 78 | Iteration number: [70/565] 12% | Training loss: 0.6964331167084831
Epoch: 78 | Iteration number: [80/565] 14% | Training loss: 0.6952671565115451
Epoch: 78 | Iteration number: [90/565] 15% | Training loss: 0.6943426430225372
Epoch: 78 | Iteration number: [100/565] 17% | Training loss: 0.6935728371143342
Epoch: 78 | Iteration number: [110/565] 19% | Training loss: 0.6929547342387112
Epoch: 78 | Iteration number: [120/565] 21% | Training loss: 0.6924592634042104
Epoch: 78 | Iteration number: [130/565] 23% | Training loss: 0.6920519627057589
Epoch: 78 | Iteration number: [140/565] 24% | Training loss: 0.6916766656296593
Epoch: 78 | Iteration number: [150/565] 26% | Training loss: 0.6913509674866994
Epoch: 78 | Iteration number: [160/565] 28% | Training loss: 0.691077959164977
Epoch: 78 | Iteration number: [170/565] 30% | Training loss: 0.6908004729186787
Epoch: 78 | Iteration number: [180/565] 31% | Training loss: 0.6905814068184959
Epoch: 78 | Iteration number: [190/565] 33% | Training loss: 0.690378193792544
Epoch: 78 | Iteration number: [200/565] 35% | Training loss: 0.690197534263134
Epoch: 78 | Iteration number: [210/565] 37% | Training loss: 0.6900258172126044
Epoch: 78 | Iteration number: [220/565] 38% | Training loss: 0.6898883074522019
Epoch: 78 | Iteration number: [230/565] 40% | Training loss: 0.6897505661715632
Epoch: 78 | Iteration number: [240/565] 42% | Training loss: 0.6896085234979789
Epoch: 78 | Iteration number: [250/565] 44% | Training loss: 0.6894882438182831
Epoch: 78 | Iteration number: [260/565] 46% | Training loss: 0.6894032537937165
Epoch: 78 | Iteration number: [270/565] 47% | Training loss: 0.6893098162280189
Epoch: 78 | Iteration number: [280/565] 49% | Training loss: 0.6892118492296764
Epoch: 78 | Iteration number: [290/565] 51% | Training loss: 0.6891422725957016
Epoch: 78 | Iteration number: [300/565] 53% | Training loss: 0.6890582730372746
Epoch: 78 | Iteration number: [310/565] 54% | Training loss: 0.6889880161131582
Epoch: 78 | Iteration number: [320/565] 56% | Training loss: 0.6889135383069516
Epoch: 78 | Iteration number: [330/565] 58% | Training loss: 0.6888564059228608
Epoch: 78 | Iteration number: [340/565] 60% | Training loss: 0.6887780280674205
Epoch: 78 | Iteration number: [350/565] 61% | Training loss: 0.6887141985552652
Epoch: 78 | Iteration number: [360/565] 63% | Training loss: 0.6886665382319026
Epoch: 78 | Iteration number: [370/565] 65% | Training loss: 0.6886131114250905
Epoch: 78 | Iteration number: [380/565] 67% | Training loss: 0.6885582909772271
Epoch: 78 | Iteration number: [390/565] 69% | Training loss: 0.688515605376317
Epoch: 78 | Iteration number: [400/565] 70% | Training loss: 0.6884816955029964
Epoch: 78 | Iteration number: [410/565] 72% | Training loss: 0.6884485960006714
Epoch: 78 | Iteration number: [420/565] 74% | Training loss: 0.6884063310566403
Epoch: 78 | Iteration number: [430/565] 76% | Training loss: 0.6883662708970003
Epoch: 78 | Iteration number: [440/565] 77% | Training loss: 0.688336527618495
Epoch: 78 | Iteration number: [450/565] 79% | Training loss: 0.6882916349834866
Epoch: 78 | Iteration number: [460/565] 81% | Training loss: 0.6882514432720516
Epoch: 78 | Iteration number: [470/565] 83% | Training loss: 0.6882289315791841
Epoch: 78 | Iteration number: [480/565] 84% | Training loss: 0.6881994061172009
Epoch: 78 | Iteration number: [490/565] 86% | Training loss: 0.6881719474889794
Epoch: 78 | Iteration number: [500/565] 88% | Training loss: 0.6881434986591339
Epoch: 78 | Iteration number: [510/565] 90% | Training loss: 0.6881182476585986
Epoch: 78 | Iteration number: [520/565] 92% | Training loss: 0.6880997524811672
Epoch: 78 | Iteration number: [530/565] 93% | Training loss: 0.6880785330286566
Epoch: 78 | Iteration number: [540/565] 95% | Training loss: 0.6880465581461236
Epoch: 78 | Iteration number: [550/565] 97% | Training loss: 0.6880199648033489
Epoch: 78 | Iteration number: [560/565] 99% | Training loss: 0.6879969305225782

 End of epoch: 78 | Train Loss: 0.6867712109489779 | Training Time: 90 

 End of epoch: 78 | Eval Loss: 0.6897241473197937 | Evaluating Time: 6 
Epoch: 79 | Iteration number: [10/565] 1% | Training loss: 0.7552841126918792
Epoch: 79 | Iteration number: [20/565] 3% | Training loss: 0.7212452352046966
Epoch: 79 | Iteration number: [30/565] 5% | Training loss: 0.709850694735845
Epoch: 79 | Iteration number: [40/565] 7% | Training loss: 0.7040671616792679
Epoch: 79 | Iteration number: [50/565] 8% | Training loss: 0.7006292641162872
Epoch: 79 | Iteration number: [60/565] 10% | Training loss: 0.6982642561197281
Epoch: 79 | Iteration number: [70/565] 12% | Training loss: 0.6966209266866956
Epoch: 79 | Iteration number: [80/565] 14% | Training loss: 0.6953491285443306
Epoch: 79 | Iteration number: [90/565] 15% | Training loss: 0.6944349454508887
Epoch: 79 | Iteration number: [100/565] 17% | Training loss: 0.6936618196964264
Epoch: 79 | Iteration number: [110/565] 19% | Training loss: 0.6930266271937977
Epoch: 79 | Iteration number: [120/565] 21% | Training loss: 0.6924790372451146
Epoch: 79 | Iteration number: [130/565] 23% | Training loss: 0.6920283459700071
Epoch: 79 | Iteration number: [140/565] 24% | Training loss: 0.6916055777243205
Epoch: 79 | Iteration number: [150/565] 26% | Training loss: 0.6912929379940033
Epoch: 79 | Iteration number: [160/565] 28% | Training loss: 0.6910093195736409
Epoch: 79 | Iteration number: [170/565] 30% | Training loss: 0.6907846170313218
Epoch: 79 | Iteration number: [180/565] 31% | Training loss: 0.6905463652478324
Epoch: 79 | Iteration number: [190/565] 33% | Training loss: 0.6903510956387771
Epoch: 79 | Iteration number: [200/565] 35% | Training loss: 0.6901428207755089
Epoch: 79 | Iteration number: [210/565] 37% | Training loss: 0.6899942565531958
Epoch: 79 | Iteration number: [220/565] 38% | Training loss: 0.6898409881375053
Epoch: 79 | Iteration number: [230/565] 40% | Training loss: 0.6897200136081032
Epoch: 79 | Iteration number: [240/565] 42% | Training loss: 0.6896003099779288
Epoch: 79 | Iteration number: [250/565] 44% | Training loss: 0.6894907932281494
Epoch: 79 | Iteration number: [260/565] 46% | Training loss: 0.6893899793808277
Epoch: 79 | Iteration number: [270/565] 47% | Training loss: 0.6893024508599882
Epoch: 79 | Iteration number: [280/565] 49% | Training loss: 0.6892111269491059
Epoch: 79 | Iteration number: [290/565] 51% | Training loss: 0.6891348448292962
Epoch: 79 | Iteration number: [300/565] 53% | Training loss: 0.6890669033924739
Epoch: 79 | Iteration number: [310/565] 54% | Training loss: 0.6889938621751723
Epoch: 79 | Iteration number: [320/565] 56% | Training loss: 0.688907990604639
Epoch: 79 | Iteration number: [330/565] 58% | Training loss: 0.6888464860843889
Epoch: 79 | Iteration number: [340/565] 60% | Training loss: 0.6887837681700202
Epoch: 79 | Iteration number: [350/565] 61% | Training loss: 0.688724091053009
Epoch: 79 | Iteration number: [360/565] 63% | Training loss: 0.6886666764815649
Epoch: 79 | Iteration number: [370/565] 65% | Training loss: 0.6886093987000955
Epoch: 79 | Iteration number: [380/565] 67% | Training loss: 0.6885633114137147
Epoch: 79 | Iteration number: [390/565] 69% | Training loss: 0.6885118181888874
Epoch: 79 | Iteration number: [400/565] 70% | Training loss: 0.6884750238060952
Epoch: 79 | Iteration number: [410/565] 72% | Training loss: 0.6884358949777557
Epoch: 79 | Iteration number: [420/565] 74% | Training loss: 0.6883999391680672
Epoch: 79 | Iteration number: [430/565] 76% | Training loss: 0.6883652398752612
Epoch: 79 | Iteration number: [440/565] 77% | Training loss: 0.6883355876261538
Epoch: 79 | Iteration number: [450/565] 79% | Training loss: 0.6882972458998362
Epoch: 79 | Iteration number: [460/565] 81% | Training loss: 0.6882637621267982
Epoch: 79 | Iteration number: [470/565] 83% | Training loss: 0.6882266603885813
Epoch: 79 | Iteration number: [480/565] 84% | Training loss: 0.6881962496787309
Epoch: 79 | Iteration number: [490/565] 86% | Training loss: 0.6881722181427236
Epoch: 79 | Iteration number: [500/565] 88% | Training loss: 0.6881552155017853
Epoch: 79 | Iteration number: [510/565] 90% | Training loss: 0.688128238215166
Epoch: 79 | Iteration number: [520/565] 92% | Training loss: 0.6881090440429174
Epoch: 79 | Iteration number: [530/565] 93% | Training loss: 0.688083153400781
Epoch: 79 | Iteration number: [540/565] 95% | Training loss: 0.6880516034585459
Epoch: 79 | Iteration number: [550/565] 97% | Training loss: 0.6880303727496754
Epoch: 79 | Iteration number: [560/565] 99% | Training loss: 0.6880019175154822

 End of epoch: 79 | Train Loss: 0.6867755594506728 | Training Time: 89 

 End of epoch: 79 | Eval Loss: 0.6900754826409476 | Evaluating Time: 5 
Epoch: 80 | Iteration number: [10/565] 1% | Training loss: 0.7556742250919342
Epoch: 80 | Iteration number: [20/565] 3% | Training loss: 0.7214378923177719
Epoch: 80 | Iteration number: [30/565] 5% | Training loss: 0.7099515855312347
Epoch: 80 | Iteration number: [40/565] 7% | Training loss: 0.7042136535048484
Epoch: 80 | Iteration number: [50/565] 8% | Training loss: 0.7007106673717499
Epoch: 80 | Iteration number: [60/565] 10% | Training loss: 0.6983282993237178
Epoch: 80 | Iteration number: [70/565] 12% | Training loss: 0.6966881045273372
Epoch: 80 | Iteration number: [80/565] 14% | Training loss: 0.6954337678849697
Epoch: 80 | Iteration number: [90/565] 15% | Training loss: 0.6945456849204169
Epoch: 80 | Iteration number: [100/565] 17% | Training loss: 0.6937877058982849
Epoch: 80 | Iteration number: [110/565] 19% | Training loss: 0.6931511375037107
Epoch: 80 | Iteration number: [120/565] 21% | Training loss: 0.6926179334521294
Epoch: 80 | Iteration number: [130/565] 23% | Training loss: 0.692161795267692
Epoch: 80 | Iteration number: [140/565] 24% | Training loss: 0.6917661641325269
Epoch: 80 | Iteration number: [150/565] 26% | Training loss: 0.691413878997167
Epoch: 80 | Iteration number: [160/565] 28% | Training loss: 0.6911241713911295
Epoch: 80 | Iteration number: [170/565] 30% | Training loss: 0.690874717165442
Epoch: 80 | Iteration number: [180/565] 31% | Training loss: 0.6906313598155975
Epoch: 80 | Iteration number: [190/565] 33% | Training loss: 0.6904350180374949
Epoch: 80 | Iteration number: [200/565] 35% | Training loss: 0.6902543258666992
Epoch: 80 | Iteration number: [210/565] 37% | Training loss: 0.6900804088229224
Epoch: 80 | Iteration number: [220/565] 38% | Training loss: 0.6899294831536033
Epoch: 80 | Iteration number: [230/565] 40% | Training loss: 0.6897714283155358
Epoch: 80 | Iteration number: [240/565] 42% | Training loss: 0.6896390611926715
Epoch: 80 | Iteration number: [250/565] 44% | Training loss: 0.6895212182998657
Epoch: 80 | Iteration number: [260/565] 46% | Training loss: 0.6894215003802227
Epoch: 80 | Iteration number: [270/565] 47% | Training loss: 0.6893220676316155
Epoch: 80 | Iteration number: [280/565] 49% | Training loss: 0.689227443081992
Epoch: 80 | Iteration number: [290/565] 51% | Training loss: 0.6891450331128877
Epoch: 80 | Iteration number: [300/565] 53% | Training loss: 0.689061110218366
Epoch: 80 | Iteration number: [310/565] 54% | Training loss: 0.6889790083131483
Epoch: 80 | Iteration number: [320/565] 56% | Training loss: 0.6889057226479054
Epoch: 80 | Iteration number: [330/565] 58% | Training loss: 0.6888364929141421
Epoch: 80 | Iteration number: [340/565] 60% | Training loss: 0.6887718086733537
Epoch: 80 | Iteration number: [350/565] 61% | Training loss: 0.6887132016250065
Epoch: 80 | Iteration number: [360/565] 63% | Training loss: 0.688661686413818
Epoch: 80 | Iteration number: [370/565] 65% | Training loss: 0.6885954235051129
Epoch: 80 | Iteration number: [380/565] 67% | Training loss: 0.6885576290519614
Epoch: 80 | Iteration number: [390/565] 69% | Training loss: 0.6885060330231985
Epoch: 80 | Iteration number: [400/565] 70% | Training loss: 0.6884548205137253
Epoch: 80 | Iteration number: [410/565] 72% | Training loss: 0.6884240995093089
Epoch: 80 | Iteration number: [420/565] 74% | Training loss: 0.6883818256003517
Epoch: 80 | Iteration number: [430/565] 76% | Training loss: 0.6883486952892569
Epoch: 80 | Iteration number: [440/565] 77% | Training loss: 0.6883095191283659
Epoch: 80 | Iteration number: [450/565] 79% | Training loss: 0.6882800549930996
Epoch: 80 | Iteration number: [460/565] 81% | Training loss: 0.6882479312627212
Epoch: 80 | Iteration number: [470/565] 83% | Training loss: 0.6882225594622023
Epoch: 80 | Iteration number: [480/565] 84% | Training loss: 0.6881991325567166
Epoch: 80 | Iteration number: [490/565] 86% | Training loss: 0.6881701863541895
Epoch: 80 | Iteration number: [500/565] 88% | Training loss: 0.6881401602029801
Epoch: 80 | Iteration number: [510/565] 90% | Training loss: 0.6881135876272239
Epoch: 80 | Iteration number: [520/565] 92% | Training loss: 0.6880908600412883
Epoch: 80 | Iteration number: [530/565] 93% | Training loss: 0.6880617356525277
Epoch: 80 | Iteration number: [540/565] 95% | Training loss: 0.6880356157267535
Epoch: 80 | Iteration number: [550/565] 97% | Training loss: 0.688019709370353
Epoch: 80 | Iteration number: [560/565] 99% | Training loss: 0.6879932811217648

 End of epoch: 80 | Train Loss: 0.6867717296676298 | Training Time: 91 

 End of epoch: 80 | Eval Loss: 0.6893049819128854 | Evaluating Time: 6 
Epoch: 81 | Iteration number: [10/565] 1% | Training loss: 0.7551342248916626
Epoch: 81 | Iteration number: [20/565] 3% | Training loss: 0.7205189943313599
Epoch: 81 | Iteration number: [30/565] 5% | Training loss: 0.7092067042986552
Epoch: 81 | Iteration number: [40/565] 7% | Training loss: 0.7035513266921043
Epoch: 81 | Iteration number: [50/565] 8% | Training loss: 0.7001859903335571
Epoch: 81 | Iteration number: [60/565] 10% | Training loss: 0.6979663699865342
Epoch: 81 | Iteration number: [70/565] 12% | Training loss: 0.6963214422975268
Epoch: 81 | Iteration number: [80/565] 14% | Training loss: 0.6951454304158687
Epoch: 81 | Iteration number: [90/565] 15% | Training loss: 0.6941912492116292
Epoch: 81 | Iteration number: [100/565] 17% | Training loss: 0.6934449845552444
Epoch: 81 | Iteration number: [110/565] 19% | Training loss: 0.6928386503999884
Epoch: 81 | Iteration number: [120/565] 21% | Training loss: 0.6923507904012998
Epoch: 81 | Iteration number: [130/565] 23% | Training loss: 0.6919330220956069
Epoch: 81 | Iteration number: [140/565] 24% | Training loss: 0.6916057539837701
Epoch: 81 | Iteration number: [150/565] 26% | Training loss: 0.6913050778706868
Epoch: 81 | Iteration number: [160/565] 28% | Training loss: 0.6909988209605217
Epoch: 81 | Iteration number: [170/565] 30% | Training loss: 0.6907483553185182
Epoch: 81 | Iteration number: [180/565] 31% | Training loss: 0.6905142188072204
Epoch: 81 | Iteration number: [190/565] 33% | Training loss: 0.6903079484638415
Epoch: 81 | Iteration number: [200/565] 35% | Training loss: 0.6901483857631683
Epoch: 81 | Iteration number: [210/565] 37% | Training loss: 0.6899834610167004
Epoch: 81 | Iteration number: [220/565] 38% | Training loss: 0.6898327683860606
Epoch: 81 | Iteration number: [230/565] 40% | Training loss: 0.6897111778673919
Epoch: 81 | Iteration number: [240/565] 42% | Training loss: 0.6895959568520387
Epoch: 81 | Iteration number: [250/565] 44% | Training loss: 0.6894802610874176
Epoch: 81 | Iteration number: [260/565] 46% | Training loss: 0.6893823839150942
Epoch: 81 | Iteration number: [270/565] 47% | Training loss: 0.6892876620645876
Epoch: 81 | Iteration number: [280/565] 49% | Training loss: 0.689197206071445
Epoch: 81 | Iteration number: [290/565] 51% | Training loss: 0.6891092355909019
Epoch: 81 | Iteration number: [300/565] 53% | Training loss: 0.6890340568621953
Epoch: 81 | Iteration number: [310/565] 54% | Training loss: 0.6889616208691751
Epoch: 81 | Iteration number: [320/565] 56% | Training loss: 0.688874039426446
Epoch: 81 | Iteration number: [330/565] 58% | Training loss: 0.6888197869965524
Epoch: 81 | Iteration number: [340/565] 60% | Training loss: 0.68875991842326
Epoch: 81 | Iteration number: [350/565] 61% | Training loss: 0.6886937202726091
Epoch: 81 | Iteration number: [360/565] 63% | Training loss: 0.6886490091681481
Epoch: 81 | Iteration number: [370/565] 65% | Training loss: 0.6885980636686893
Epoch: 81 | Iteration number: [380/565] 67% | Training loss: 0.6885372034813229
Epoch: 81 | Iteration number: [390/565] 69% | Training loss: 0.68848828627513
Epoch: 81 | Iteration number: [400/565] 70% | Training loss: 0.6884485039114953
Epoch: 81 | Iteration number: [410/565] 72% | Training loss: 0.6884120071806559
Epoch: 81 | Iteration number: [420/565] 74% | Training loss: 0.6883699722233273
Epoch: 81 | Iteration number: [430/565] 76% | Training loss: 0.6883346583954123
Epoch: 81 | Iteration number: [440/565] 77% | Training loss: 0.6883121505379677
Epoch: 81 | Iteration number: [450/565] 79% | Training loss: 0.6882738710774315
Epoch: 81 | Iteration number: [460/565] 81% | Training loss: 0.6882378477117289
Epoch: 81 | Iteration number: [470/565] 83% | Training loss: 0.688216474208426
Epoch: 81 | Iteration number: [480/565] 84% | Training loss: 0.6881894333908956
Epoch: 81 | Iteration number: [490/565] 86% | Training loss: 0.6881576654862385
Epoch: 81 | Iteration number: [500/565] 88% | Training loss: 0.6881285684108734
Epoch: 81 | Iteration number: [510/565] 90% | Training loss: 0.6880981919812221
Epoch: 81 | Iteration number: [520/565] 92% | Training loss: 0.6880705849482462
Epoch: 81 | Iteration number: [530/565] 93% | Training loss: 0.6880467018991147
Epoch: 81 | Iteration number: [540/565] 95% | Training loss: 0.6880192146257118
Epoch: 81 | Iteration number: [550/565] 97% | Training loss: 0.6880075931549072
Epoch: 81 | Iteration number: [560/565] 99% | Training loss: 0.6879959332091468

 End of epoch: 81 | Train Loss: 0.6867669631949568 | Training Time: 91 

 End of epoch: 81 | Eval Loss: 0.6898343733378819 | Evaluating Time: 6 
Epoch: 82 | Iteration number: [10/565] 1% | Training loss: 0.7556078553199768
Epoch: 82 | Iteration number: [20/565] 3% | Training loss: 0.7212908059358597
Epoch: 82 | Iteration number: [30/565] 5% | Training loss: 0.7099996387958527
Epoch: 82 | Iteration number: [40/565] 7% | Training loss: 0.7041525959968566
Epoch: 82 | Iteration number: [50/565] 8% | Training loss: 0.7007091903686523
Epoch: 82 | Iteration number: [60/565] 10% | Training loss: 0.6983986079692841
Epoch: 82 | Iteration number: [70/565] 12% | Training loss: 0.6967283061572483
Epoch: 82 | Iteration number: [80/565] 14% | Training loss: 0.6954441525042057
Epoch: 82 | Iteration number: [90/565] 15% | Training loss: 0.6944813423686558
Epoch: 82 | Iteration number: [100/565] 17% | Training loss: 0.6937400567531585
Epoch: 82 | Iteration number: [110/565] 19% | Training loss: 0.6930986967953768
Epoch: 82 | Iteration number: [120/565] 21% | Training loss: 0.6925529683629672
Epoch: 82 | Iteration number: [130/565] 23% | Training loss: 0.6921263493024385
Epoch: 82 | Iteration number: [140/565] 24% | Training loss: 0.6917840987443924
Epoch: 82 | Iteration number: [150/565] 26% | Training loss: 0.6914419265588124
Epoch: 82 | Iteration number: [160/565] 28% | Training loss: 0.6911367375403643
Epoch: 82 | Iteration number: [170/565] 30% | Training loss: 0.6908787850071402
Epoch: 82 | Iteration number: [180/565] 31% | Training loss: 0.6906591604153315
Epoch: 82 | Iteration number: [190/565] 33% | Training loss: 0.690476089402249
Epoch: 82 | Iteration number: [200/565] 35% | Training loss: 0.6903090673685074
Epoch: 82 | Iteration number: [210/565] 37% | Training loss: 0.6901349570069994
Epoch: 82 | Iteration number: [220/565] 38% | Training loss: 0.6899901195005937
Epoch: 82 | Iteration number: [230/565] 40% | Training loss: 0.6898621914179429
Epoch: 82 | Iteration number: [240/565] 42% | Training loss: 0.6897409901022911
Epoch: 82 | Iteration number: [250/565] 44% | Training loss: 0.6896231925487518
Epoch: 82 | Iteration number: [260/565] 46% | Training loss: 0.6895046717845477
Epoch: 82 | Iteration number: [270/565] 47% | Training loss: 0.6894110792213016
Epoch: 82 | Iteration number: [280/565] 49% | Training loss: 0.6893076890281269
Epoch: 82 | Iteration number: [290/565] 51% | Training loss: 0.6892175801869096
Epoch: 82 | Iteration number: [300/565] 53% | Training loss: 0.6891416903336843
Epoch: 82 | Iteration number: [310/565] 54% | Training loss: 0.6890665856099898
Epoch: 82 | Iteration number: [320/565] 56% | Training loss: 0.68899916857481
Epoch: 82 | Iteration number: [330/565] 58% | Training loss: 0.6889326796387181
Epoch: 82 | Iteration number: [340/565] 60% | Training loss: 0.6888783803757499
Epoch: 82 | Iteration number: [350/565] 61% | Training loss: 0.688817549433027
Epoch: 82 | Iteration number: [360/565] 63% | Training loss: 0.6887694731354713
Epoch: 82 | Iteration number: [370/565] 65% | Training loss: 0.6887214013048121
Epoch: 82 | Iteration number: [380/565] 67% | Training loss: 0.6886681421806938
Epoch: 82 | Iteration number: [390/565] 69% | Training loss: 0.6886284716618367
Epoch: 82 | Iteration number: [400/565] 70% | Training loss: 0.6885737778246402
Epoch: 82 | Iteration number: [410/565] 72% | Training loss: 0.6885264908395162
Epoch: 82 | Iteration number: [420/565] 74% | Training loss: 0.6884701152642568
Epoch: 82 | Iteration number: [430/565] 76% | Training loss: 0.688420845325603
Epoch: 82 | Iteration number: [440/565] 77% | Training loss: 0.6883907438679175
Epoch: 82 | Iteration number: [450/565] 79% | Training loss: 0.6883566866980658
Epoch: 82 | Iteration number: [460/565] 81% | Training loss: 0.6883187909489092
Epoch: 82 | Iteration number: [470/565] 83% | Training loss: 0.6882888448999284
Epoch: 82 | Iteration number: [480/565] 84% | Training loss: 0.6882631643364827
Epoch: 82 | Iteration number: [490/565] 86% | Training loss: 0.6882369278645029
Epoch: 82 | Iteration number: [500/565] 88% | Training loss: 0.6882041714191437
Epoch: 82 | Iteration number: [510/565] 90% | Training loss: 0.6881677507185469
Epoch: 82 | Iteration number: [520/565] 92% | Training loss: 0.6881382469947521
Epoch: 82 | Iteration number: [530/565] 93% | Training loss: 0.6881179738719508
Epoch: 82 | Iteration number: [540/565] 95% | Training loss: 0.6880929353060545
Epoch: 82 | Iteration number: [550/565] 97% | Training loss: 0.6880627443573691
Epoch: 82 | Iteration number: [560/565] 99% | Training loss: 0.6880461207457951

 End of epoch: 82 | Train Loss: 0.6868171121166871 | Training Time: 89 

 End of epoch: 82 | Eval Loss: 0.6899695311273847 | Evaluating Time: 6 
Epoch: 83 | Iteration number: [10/565] 1% | Training loss: 0.7552706956863403
Epoch: 83 | Iteration number: [20/565] 3% | Training loss: 0.7208534777164459
Epoch: 83 | Iteration number: [30/565] 5% | Training loss: 0.7096349755922954
Epoch: 83 | Iteration number: [40/565] 7% | Training loss: 0.7038267508149147
Epoch: 83 | Iteration number: [50/565] 8% | Training loss: 0.7005143439769745
Epoch: 83 | Iteration number: [60/565] 10% | Training loss: 0.6982805083195368
Epoch: 83 | Iteration number: [70/565] 12% | Training loss: 0.696612069436482
Epoch: 83 | Iteration number: [80/565] 14% | Training loss: 0.6953871726989747
Epoch: 83 | Iteration number: [90/565] 15% | Training loss: 0.6944481194019317
Epoch: 83 | Iteration number: [100/565] 17% | Training loss: 0.6936808979511261
Epoch: 83 | Iteration number: [110/565] 19% | Training loss: 0.693038368766958
Epoch: 83 | Iteration number: [120/565] 21% | Training loss: 0.6925430928667387
Epoch: 83 | Iteration number: [130/565] 23% | Training loss: 0.6921513717908125
Epoch: 83 | Iteration number: [140/565] 24% | Training loss: 0.691771125793457
Epoch: 83 | Iteration number: [150/565] 26% | Training loss: 0.691417908668518
Epoch: 83 | Iteration number: [160/565] 28% | Training loss: 0.6911076571792364
Epoch: 83 | Iteration number: [170/565] 30% | Training loss: 0.6908406450467951
Epoch: 83 | Iteration number: [180/565] 31% | Training loss: 0.690642124414444
Epoch: 83 | Iteration number: [190/565] 33% | Training loss: 0.6904410807709945
Epoch: 83 | Iteration number: [200/565] 35% | Training loss: 0.6902521619200707
Epoch: 83 | Iteration number: [210/565] 37% | Training loss: 0.6900784376121702
Epoch: 83 | Iteration number: [220/565] 38% | Training loss: 0.6899282693862915
Epoch: 83 | Iteration number: [230/565] 40% | Training loss: 0.6898051476996878
Epoch: 83 | Iteration number: [240/565] 42% | Training loss: 0.6896747623880705
Epoch: 83 | Iteration number: [250/565] 44% | Training loss: 0.6895713739395142
Epoch: 83 | Iteration number: [260/565] 46% | Training loss: 0.6894543826580047
Epoch: 83 | Iteration number: [270/565] 47% | Training loss: 0.6893580324119992
Epoch: 83 | Iteration number: [280/565] 49% | Training loss: 0.6892504936882428
Epoch: 83 | Iteration number: [290/565] 51% | Training loss: 0.689154884938536
Epoch: 83 | Iteration number: [300/565] 53% | Training loss: 0.6890723540385564
Epoch: 83 | Iteration number: [310/565] 54% | Training loss: 0.6890006451837478
Epoch: 83 | Iteration number: [320/565] 56% | Training loss: 0.6889251239597798
Epoch: 83 | Iteration number: [330/565] 58% | Training loss: 0.6888635994810046
Epoch: 83 | Iteration number: [340/565] 60% | Training loss: 0.6888050862971474
Epoch: 83 | Iteration number: [350/565] 61% | Training loss: 0.6887524104118348
Epoch: 83 | Iteration number: [360/565] 63% | Training loss: 0.6886982508831554
Epoch: 83 | Iteration number: [370/565] 65% | Training loss: 0.6886563792422011
Epoch: 83 | Iteration number: [380/565] 67% | Training loss: 0.6886086253743423
Epoch: 83 | Iteration number: [390/565] 69% | Training loss: 0.6885528209881905
Epoch: 83 | Iteration number: [400/565] 70% | Training loss: 0.6885056057572365
Epoch: 83 | Iteration number: [410/565] 72% | Training loss: 0.6884681240814489
Epoch: 83 | Iteration number: [420/565] 74% | Training loss: 0.6884137349469321
Epoch: 83 | Iteration number: [430/565] 76% | Training loss: 0.6883672231851622
Epoch: 83 | Iteration number: [440/565] 77% | Training loss: 0.6883360945365645
Epoch: 83 | Iteration number: [450/565] 79% | Training loss: 0.6883017855220371
Epoch: 83 | Iteration number: [460/565] 81% | Training loss: 0.6882669337417768
Epoch: 83 | Iteration number: [470/565] 83% | Training loss: 0.688239393462526
Epoch: 83 | Iteration number: [480/565] 84% | Training loss: 0.6882132835686207
Epoch: 83 | Iteration number: [490/565] 86% | Training loss: 0.6881772958502478
Epoch: 83 | Iteration number: [500/565] 88% | Training loss: 0.6881491354703904
Epoch: 83 | Iteration number: [510/565] 90% | Training loss: 0.6881237188975017
Epoch: 83 | Iteration number: [520/565] 92% | Training loss: 0.6880944333397425
Epoch: 83 | Iteration number: [530/565] 93% | Training loss: 0.688073478442318
Epoch: 83 | Iteration number: [540/565] 95% | Training loss: 0.6880515885573847
Epoch: 83 | Iteration number: [550/565] 97% | Training loss: 0.6880273724686016
Epoch: 83 | Iteration number: [560/565] 99% | Training loss: 0.6880018159747123

 End of epoch: 83 | Train Loss: 0.6867815574713513 | Training Time: 89 

 End of epoch: 83 | Eval Loss: 0.6894065652574811 | Evaluating Time: 6 
Epoch: 84 | Iteration number: [10/565] 1% | Training loss: 0.755276882648468
Epoch: 84 | Iteration number: [20/565] 3% | Training loss: 0.7209310472011566
Epoch: 84 | Iteration number: [30/565] 5% | Training loss: 0.7093502779801687
Epoch: 84 | Iteration number: [40/565] 7% | Training loss: 0.7037176564335823
Epoch: 84 | Iteration number: [50/565] 8% | Training loss: 0.7003990185260772
Epoch: 84 | Iteration number: [60/565] 10% | Training loss: 0.6981023500363032
Epoch: 84 | Iteration number: [70/565] 12% | Training loss: 0.696480655670166
Epoch: 84 | Iteration number: [80/565] 14% | Training loss: 0.6952403455972671
Epoch: 84 | Iteration number: [90/565] 15% | Training loss: 0.6942890756660037
Epoch: 84 | Iteration number: [100/565] 17% | Training loss: 0.6935426527261734
Epoch: 84 | Iteration number: [110/565] 19% | Training loss: 0.6929364415732298
Epoch: 84 | Iteration number: [120/565] 21% | Training loss: 0.6924471159776052
Epoch: 84 | Iteration number: [130/565] 23% | Training loss: 0.6920342234464792
Epoch: 84 | Iteration number: [140/565] 24% | Training loss: 0.6916474802153451
Epoch: 84 | Iteration number: [150/565] 26% | Training loss: 0.6913478477795919
Epoch: 84 | Iteration number: [160/565] 28% | Training loss: 0.6910785112529994
Epoch: 84 | Iteration number: [170/565] 30% | Training loss: 0.690845808912726
Epoch: 84 | Iteration number: [180/565] 31% | Training loss: 0.6906059543291728
Epoch: 84 | Iteration number: [190/565] 33% | Training loss: 0.6903690253433429
Epoch: 84 | Iteration number: [200/565] 35% | Training loss: 0.6901897823810578
Epoch: 84 | Iteration number: [210/565] 37% | Training loss: 0.6900422348862603
Epoch: 84 | Iteration number: [220/565] 38% | Training loss: 0.6899022262204777
Epoch: 84 | Iteration number: [230/565] 40% | Training loss: 0.6897670414136804
Epoch: 84 | Iteration number: [240/565] 42% | Training loss: 0.6896530422071616
Epoch: 84 | Iteration number: [250/565] 44% | Training loss: 0.6895279657840728
Epoch: 84 | Iteration number: [260/565] 46% | Training loss: 0.6894164979457855
Epoch: 84 | Iteration number: [270/565] 47% | Training loss: 0.6893090780134554
Epoch: 84 | Iteration number: [280/565] 49% | Training loss: 0.6892257794737816
Epoch: 84 | Iteration number: [290/565] 51% | Training loss: 0.6891508303839585
Epoch: 84 | Iteration number: [300/565] 53% | Training loss: 0.6890672926108042
Epoch: 84 | Iteration number: [310/565] 54% | Training loss: 0.6889962682800909
Epoch: 84 | Iteration number: [320/565] 56% | Training loss: 0.6889270400628448
Epoch: 84 | Iteration number: [330/565] 58% | Training loss: 0.6888607760270437
Epoch: 84 | Iteration number: [340/565] 60% | Training loss: 0.688801028973916
Epoch: 84 | Iteration number: [350/565] 61% | Training loss: 0.6887495989458902
Epoch: 84 | Iteration number: [360/565] 63% | Training loss: 0.6886830909384621
Epoch: 84 | Iteration number: [370/565] 65% | Training loss: 0.68863229799915
Epoch: 84 | Iteration number: [380/565] 67% | Training loss: 0.688574448541591
Epoch: 84 | Iteration number: [390/565] 69% | Training loss: 0.688526316330983
Epoch: 84 | Iteration number: [400/565] 70% | Training loss: 0.6884865665435791
Epoch: 84 | Iteration number: [410/565] 72% | Training loss: 0.688434498775296
Epoch: 84 | Iteration number: [420/565] 74% | Training loss: 0.6883883405299414
Epoch: 84 | Iteration number: [430/565] 76% | Training loss: 0.6883487260618876
Epoch: 84 | Iteration number: [440/565] 77% | Training loss: 0.6883211474527012
Epoch: 84 | Iteration number: [450/565] 79% | Training loss: 0.6882899799611834
Epoch: 84 | Iteration number: [460/565] 81% | Training loss: 0.6882676009250723
Epoch: 84 | Iteration number: [470/565] 83% | Training loss: 0.6882312419566702
Epoch: 84 | Iteration number: [480/565] 84% | Training loss: 0.6881979212164879
Epoch: 84 | Iteration number: [490/565] 86% | Training loss: 0.6881722487965408
Epoch: 84 | Iteration number: [500/565] 88% | Training loss: 0.6881452637910843
Epoch: 84 | Iteration number: [510/565] 90% | Training loss: 0.688121481853373
Epoch: 84 | Iteration number: [520/565] 92% | Training loss: 0.6880991184940705
Epoch: 84 | Iteration number: [530/565] 93% | Training loss: 0.6880798614250039
Epoch: 84 | Iteration number: [540/565] 95% | Training loss: 0.6880563246983069
Epoch: 84 | Iteration number: [550/565] 97% | Training loss: 0.688030055327849
Epoch: 84 | Iteration number: [560/565] 99% | Training loss: 0.6880016984684126

 End of epoch: 84 | Train Loss: 0.6867703912532435 | Training Time: 89 

 End of epoch: 84 | Eval Loss: 0.6895407438278198 | Evaluating Time: 6 
Epoch: 85 | Iteration number: [10/565] 1% | Training loss: 0.7558014154434204
Epoch: 85 | Iteration number: [20/565] 3% | Training loss: 0.7212048918008804
Epoch: 85 | Iteration number: [30/565] 5% | Training loss: 0.7096527576446533
Epoch: 85 | Iteration number: [40/565] 7% | Training loss: 0.7039147436618804
Epoch: 85 | Iteration number: [50/565] 8% | Training loss: 0.7004669010639191
Epoch: 85 | Iteration number: [60/565] 10% | Training loss: 0.698204826315244
Epoch: 85 | Iteration number: [70/565] 12% | Training loss: 0.6965959140232632
Epoch: 85 | Iteration number: [80/565] 14% | Training loss: 0.6953349336981773
Epoch: 85 | Iteration number: [90/565] 15% | Training loss: 0.6944012761116027
Epoch: 85 | Iteration number: [100/565] 17% | Training loss: 0.6936425441503524
Epoch: 85 | Iteration number: [110/565] 19% | Training loss: 0.6930106997489929
Epoch: 85 | Iteration number: [120/565] 21% | Training loss: 0.6925192435582479
Epoch: 85 | Iteration number: [130/565] 23% | Training loss: 0.6920685722277715
Epoch: 85 | Iteration number: [140/565] 24% | Training loss: 0.6916877282517296
Epoch: 85 | Iteration number: [150/565] 26% | Training loss: 0.6913512639204661
Epoch: 85 | Iteration number: [160/565] 28% | Training loss: 0.691072478890419
Epoch: 85 | Iteration number: [170/565] 30% | Training loss: 0.6908401983625748
Epoch: 85 | Iteration number: [180/565] 31% | Training loss: 0.690624021159278
Epoch: 85 | Iteration number: [190/565] 33% | Training loss: 0.6904295617028287
Epoch: 85 | Iteration number: [200/565] 35% | Training loss: 0.6902415519952774
Epoch: 85 | Iteration number: [210/565] 37% | Training loss: 0.6901044258049556
Epoch: 85 | Iteration number: [220/565] 38% | Training loss: 0.6899477308446711
Epoch: 85 | Iteration number: [230/565] 40% | Training loss: 0.6898045381774073
Epoch: 85 | Iteration number: [240/565] 42% | Training loss: 0.6896682468553385
Epoch: 85 | Iteration number: [250/565] 44% | Training loss: 0.6895523271560668
Epoch: 85 | Iteration number: [260/565] 46% | Training loss: 0.6894476583370795
Epoch: 85 | Iteration number: [270/565] 47% | Training loss: 0.6893474726765244
Epoch: 85 | Iteration number: [280/565] 49% | Training loss: 0.6892528829830034
Epoch: 85 | Iteration number: [290/565] 51% | Training loss: 0.6891696666849071
Epoch: 85 | Iteration number: [300/565] 53% | Training loss: 0.689095875620842
Epoch: 85 | Iteration number: [310/565] 54% | Training loss: 0.6890100123420838
Epoch: 85 | Iteration number: [320/565] 56% | Training loss: 0.6889399539679288
Epoch: 85 | Iteration number: [330/565] 58% | Training loss: 0.6888669953201756
Epoch: 85 | Iteration number: [340/565] 60% | Training loss: 0.6888005661613801
Epoch: 85 | Iteration number: [350/565] 61% | Training loss: 0.6887325201715742
Epoch: 85 | Iteration number: [360/565] 63% | Training loss: 0.6886898365285662
Epoch: 85 | Iteration number: [370/565] 65% | Training loss: 0.6886455569718335
Epoch: 85 | Iteration number: [380/565] 67% | Training loss: 0.688600806813491
Epoch: 85 | Iteration number: [390/565] 69% | Training loss: 0.6885544676047105
Epoch: 85 | Iteration number: [400/565] 70% | Training loss: 0.6885183729231358
Epoch: 85 | Iteration number: [410/565] 72% | Training loss: 0.6884711149262219
Epoch: 85 | Iteration number: [420/565] 74% | Training loss: 0.6884282430013021
Epoch: 85 | Iteration number: [430/565] 76% | Training loss: 0.6883888092151907
Epoch: 85 | Iteration number: [440/565] 77% | Training loss: 0.6883405312895775
Epoch: 85 | Iteration number: [450/565] 79% | Training loss: 0.6883127906587388
Epoch: 85 | Iteration number: [460/565] 81% | Training loss: 0.6882809466641883
Epoch: 85 | Iteration number: [470/565] 83% | Training loss: 0.6882441646241128
Epoch: 85 | Iteration number: [480/565] 84% | Training loss: 0.688207334280014
Epoch: 85 | Iteration number: [490/565] 86% | Training loss: 0.6881834623764972
Epoch: 85 | Iteration number: [500/565] 88% | Training loss: 0.6881610504388809
Epoch: 85 | Iteration number: [510/565] 90% | Training loss: 0.6881277110062394
Epoch: 85 | Iteration number: [520/565] 92% | Training loss: 0.6880980340334085
Epoch: 85 | Iteration number: [530/565] 93% | Training loss: 0.6880760043297174
Epoch: 85 | Iteration number: [540/565] 95% | Training loss: 0.688047320092166
Epoch: 85 | Iteration number: [550/565] 97% | Training loss: 0.6880152146382765
Epoch: 85 | Iteration number: [560/565] 99% | Training loss: 0.6879930232252394

 End of epoch: 85 | Train Loss: 0.6867618484834654 | Training Time: 88 

 End of epoch: 85 | Eval Loss: 0.6899809837341309 | Evaluating Time: 6 
Epoch: 86 | Iteration number: [10/565] 1% | Training loss: 0.7556873619556427
Epoch: 86 | Iteration number: [20/565] 3% | Training loss: 0.7208905100822449
Epoch: 86 | Iteration number: [30/565] 5% | Training loss: 0.7094681620597839
Epoch: 86 | Iteration number: [40/565] 7% | Training loss: 0.7038667306303978
Epoch: 86 | Iteration number: [50/565] 8% | Training loss: 0.7004471039772033
Epoch: 86 | Iteration number: [60/565] 10% | Training loss: 0.6982312669356664
Epoch: 86 | Iteration number: [70/565] 12% | Training loss: 0.6966281039374215
Epoch: 86 | Iteration number: [80/565] 14% | Training loss: 0.6953655809164048
Epoch: 86 | Iteration number: [90/565] 15% | Training loss: 0.6944422112570868
Epoch: 86 | Iteration number: [100/565] 17% | Training loss: 0.693702712059021
Epoch: 86 | Iteration number: [110/565] 19% | Training loss: 0.6930871865966103
Epoch: 86 | Iteration number: [120/565] 21% | Training loss: 0.6926053697864215
Epoch: 86 | Iteration number: [130/565] 23% | Training loss: 0.6921848095380343
Epoch: 86 | Iteration number: [140/565] 24% | Training loss: 0.6918444603681564
Epoch: 86 | Iteration number: [150/565] 26% | Training loss: 0.6914844111601511
Epoch: 86 | Iteration number: [160/565] 28% | Training loss: 0.6911776795983314
Epoch: 86 | Iteration number: [170/565] 30% | Training loss: 0.6909440492882448
Epoch: 86 | Iteration number: [180/565] 31% | Training loss: 0.6907135417064031
Epoch: 86 | Iteration number: [190/565] 33% | Training loss: 0.6905069915871871
Epoch: 86 | Iteration number: [200/565] 35% | Training loss: 0.6903039848804474
Epoch: 86 | Iteration number: [210/565] 37% | Training loss: 0.6901533030328296
Epoch: 86 | Iteration number: [220/565] 38% | Training loss: 0.6899927315386859
Epoch: 86 | Iteration number: [230/565] 40% | Training loss: 0.6898605388143788
Epoch: 86 | Iteration number: [240/565] 42% | Training loss: 0.6897234626114368
Epoch: 86 | Iteration number: [250/565] 44% | Training loss: 0.6896108124256134
Epoch: 86 | Iteration number: [260/565] 46% | Training loss: 0.6894900727730531
Epoch: 86 | Iteration number: [270/565] 47% | Training loss: 0.6893980293362229
Epoch: 86 | Iteration number: [280/565] 49% | Training loss: 0.6893167078495026
Epoch: 86 | Iteration number: [290/565] 51% | Training loss: 0.6892236871966
Epoch: 86 | Iteration number: [300/565] 53% | Training loss: 0.6891485190391541
Epoch: 86 | Iteration number: [310/565] 54% | Training loss: 0.6890865179800219
Epoch: 86 | Iteration number: [320/565] 56% | Training loss: 0.6890024168416857
Epoch: 86 | Iteration number: [330/565] 58% | Training loss: 0.6889390136256363
Epoch: 86 | Iteration number: [340/565] 60% | Training loss: 0.6888668596744537
Epoch: 86 | Iteration number: [350/565] 61% | Training loss: 0.6888057890960149
Epoch: 86 | Iteration number: [360/565] 63% | Training loss: 0.6887476017077764
Epoch: 86 | Iteration number: [370/565] 65% | Training loss: 0.6886806207734185
Epoch: 86 | Iteration number: [380/565] 67% | Training loss: 0.6886227214022687
Epoch: 86 | Iteration number: [390/565] 69% | Training loss: 0.6885728868154379
Epoch: 86 | Iteration number: [400/565] 70% | Training loss: 0.6885237547755242
Epoch: 86 | Iteration number: [410/565] 72% | Training loss: 0.6884776366920006
Epoch: 86 | Iteration number: [420/565] 74% | Training loss: 0.6884372373421986
Epoch: 86 | Iteration number: [430/565] 76% | Training loss: 0.6884002440197523
Epoch: 86 | Iteration number: [440/565] 77% | Training loss: 0.6883612662553787
Epoch: 86 | Iteration number: [450/565] 79% | Training loss: 0.6883240534199608
Epoch: 86 | Iteration number: [460/565] 81% | Training loss: 0.6882810163757075
Epoch: 86 | Iteration number: [470/565] 83% | Training loss: 0.6882499666924172
Epoch: 86 | Iteration number: [480/565] 84% | Training loss: 0.6882065506031115
Epoch: 86 | Iteration number: [490/565] 86% | Training loss: 0.6881763950902589
Epoch: 86 | Iteration number: [500/565] 88% | Training loss: 0.6881464968919754
Epoch: 86 | Iteration number: [510/565] 90% | Training loss: 0.688115149268917
Epoch: 86 | Iteration number: [520/565] 92% | Training loss: 0.6880780686552708
Epoch: 86 | Iteration number: [530/565] 93% | Training loss: 0.6880554174477199
Epoch: 86 | Iteration number: [540/565] 95% | Training loss: 0.6880347648152598
Epoch: 86 | Iteration number: [550/565] 97% | Training loss: 0.6880125122720545
Epoch: 86 | Iteration number: [560/565] 99% | Training loss: 0.6879891929881913

 End of epoch: 86 | Train Loss: 0.6867629177802432 | Training Time: 88 

 End of epoch: 86 | Eval Loss: 0.6901163969721112 | Evaluating Time: 6 
Epoch: 87 | Iteration number: [10/565] 1% | Training loss: 0.7558428883552551
Epoch: 87 | Iteration number: [20/565] 3% | Training loss: 0.7211963355541229
Epoch: 87 | Iteration number: [30/565] 5% | Training loss: 0.7099073628584543
Epoch: 87 | Iteration number: [40/565] 7% | Training loss: 0.7041581809520722
Epoch: 87 | Iteration number: [50/565] 8% | Training loss: 0.7006503868103028
Epoch: 87 | Iteration number: [60/565] 10% | Training loss: 0.6984175115823745
Epoch: 87 | Iteration number: [70/565] 12% | Training loss: 0.6967888866152082
Epoch: 87 | Iteration number: [80/565] 14% | Training loss: 0.6955603301525116
Epoch: 87 | Iteration number: [90/565] 15% | Training loss: 0.6945506890614828
Epoch: 87 | Iteration number: [100/565] 17% | Training loss: 0.6937317961454391
Epoch: 87 | Iteration number: [110/565] 19% | Training loss: 0.6930784518068487
Epoch: 87 | Iteration number: [120/565] 21% | Training loss: 0.6925208911299705
Epoch: 87 | Iteration number: [130/565] 23% | Training loss: 0.6920913732968844
Epoch: 87 | Iteration number: [140/565] 24% | Training loss: 0.6917130070073264
Epoch: 87 | Iteration number: [150/565] 26% | Training loss: 0.6913814028104146
Epoch: 87 | Iteration number: [160/565] 28% | Training loss: 0.691099014133215
Epoch: 87 | Iteration number: [170/565] 30% | Training loss: 0.6907959867926204
Epoch: 87 | Iteration number: [180/565] 31% | Training loss: 0.690568537844552
Epoch: 87 | Iteration number: [190/565] 33% | Training loss: 0.6903715572859112
Epoch: 87 | Iteration number: [200/565] 35% | Training loss: 0.6902197906374932
Epoch: 87 | Iteration number: [210/565] 37% | Training loss: 0.6900561925910768
Epoch: 87 | Iteration number: [220/565] 38% | Training loss: 0.6899245446378535
Epoch: 87 | Iteration number: [230/565] 40% | Training loss: 0.6897967053496319
Epoch: 87 | Iteration number: [240/565] 42% | Training loss: 0.6896890724698702
Epoch: 87 | Iteration number: [250/565] 44% | Training loss: 0.689571786403656
Epoch: 87 | Iteration number: [260/565] 46% | Training loss: 0.6894710905276812
Epoch: 87 | Iteration number: [270/565] 47% | Training loss: 0.6893518379441014
Epoch: 87 | Iteration number: [280/565] 49% | Training loss: 0.6892666339874267
Epoch: 87 | Iteration number: [290/565] 51% | Training loss: 0.6891869581978897
Epoch: 87 | Iteration number: [300/565] 53% | Training loss: 0.6891040235757828
Epoch: 87 | Iteration number: [310/565] 54% | Training loss: 0.6890200730293028
Epoch: 87 | Iteration number: [320/565] 56% | Training loss: 0.6889591382816433
Epoch: 87 | Iteration number: [330/565] 58% | Training loss: 0.6888964221333013
Epoch: 87 | Iteration number: [340/565] 60% | Training loss: 0.688830209128997
Epoch: 87 | Iteration number: [350/565] 61% | Training loss: 0.688775155033384
Epoch: 87 | Iteration number: [360/565] 63% | Training loss: 0.6886975809931755
Epoch: 87 | Iteration number: [370/565] 65% | Training loss: 0.6886395518844192
Epoch: 87 | Iteration number: [380/565] 67% | Training loss: 0.6885791598181975
Epoch: 87 | Iteration number: [390/565] 69% | Training loss: 0.6885347213500586
Epoch: 87 | Iteration number: [400/565] 70% | Training loss: 0.6884847585856915
Epoch: 87 | Iteration number: [410/565] 72% | Training loss: 0.6884619116783142
Epoch: 87 | Iteration number: [420/565] 74% | Training loss: 0.6884265419982728
Epoch: 87 | Iteration number: [430/565] 76% | Training loss: 0.6883788523285888
Epoch: 87 | Iteration number: [440/565] 77% | Training loss: 0.6883295098488981
Epoch: 87 | Iteration number: [450/565] 79% | Training loss: 0.6882890933089786
Epoch: 87 | Iteration number: [460/565] 81% | Training loss: 0.6882573412812274
Epoch: 87 | Iteration number: [470/565] 83% | Training loss: 0.688222398402843
Epoch: 87 | Iteration number: [480/565] 84% | Training loss: 0.6881923604756593
Epoch: 87 | Iteration number: [490/565] 86% | Training loss: 0.6881626025754578
Epoch: 87 | Iteration number: [500/565] 88% | Training loss: 0.6881397414207459
Epoch: 87 | Iteration number: [510/565] 90% | Training loss: 0.6881101626975864
Epoch: 87 | Iteration number: [520/565] 92% | Training loss: 0.6880871863319323
Epoch: 87 | Iteration number: [530/565] 93% | Training loss: 0.688065679793088
Epoch: 87 | Iteration number: [540/565] 95% | Training loss: 0.6880500020804229
Epoch: 87 | Iteration number: [550/565] 97% | Training loss: 0.6880288904363459
Epoch: 87 | Iteration number: [560/565] 99% | Training loss: 0.6880047089287213

 End of epoch: 87 | Train Loss: 0.6867747536802714 | Training Time: 86 

 End of epoch: 87 | Eval Loss: 0.6898325000490461 | Evaluating Time: 6 
Epoch: 88 | Iteration number: [10/565] 1% | Training loss: 0.7553858995437622
Epoch: 88 | Iteration number: [20/565] 3% | Training loss: 0.7211461514234543
Epoch: 88 | Iteration number: [30/565] 5% | Training loss: 0.709523735443751
Epoch: 88 | Iteration number: [40/565] 7% | Training loss: 0.7037573963403702
Epoch: 88 | Iteration number: [50/565] 8% | Training loss: 0.7003845012187958
Epoch: 88 | Iteration number: [60/565] 10% | Training loss: 0.6981941938400269
Epoch: 88 | Iteration number: [70/565] 12% | Training loss: 0.6965599792344229
Epoch: 88 | Iteration number: [80/565] 14% | Training loss: 0.6953656196594238
Epoch: 88 | Iteration number: [90/565] 15% | Training loss: 0.6943646636274126
Epoch: 88 | Iteration number: [100/565] 17% | Training loss: 0.6935630011558532
Epoch: 88 | Iteration number: [110/565] 19% | Training loss: 0.6929675476117567
Epoch: 88 | Iteration number: [120/565] 21% | Training loss: 0.6924283916751544
Epoch: 88 | Iteration number: [130/565] 23% | Training loss: 0.6920189472345205
Epoch: 88 | Iteration number: [140/565] 24% | Training loss: 0.6916168630123138
Epoch: 88 | Iteration number: [150/565] 26% | Training loss: 0.6912839754422506
Epoch: 88 | Iteration number: [160/565] 28% | Training loss: 0.6910073556005955
Epoch: 88 | Iteration number: [170/565] 30% | Training loss: 0.6907384493771721
Epoch: 88 | Iteration number: [180/565] 31% | Training loss: 0.6905068510108524
Epoch: 88 | Iteration number: [190/565] 33% | Training loss: 0.6903125809995752
Epoch: 88 | Iteration number: [200/565] 35% | Training loss: 0.6901611691713333
Epoch: 88 | Iteration number: [210/565] 37% | Training loss: 0.6899871337981451
Epoch: 88 | Iteration number: [220/565] 38% | Training loss: 0.6898291671817953
Epoch: 88 | Iteration number: [230/565] 40% | Training loss: 0.6897020606890969
Epoch: 88 | Iteration number: [240/565] 42% | Training loss: 0.6895918610195318
Epoch: 88 | Iteration number: [250/565] 44% | Training loss: 0.6894872233867645
Epoch: 88 | Iteration number: [260/565] 46% | Training loss: 0.6893791425686616
Epoch: 88 | Iteration number: [270/565] 47% | Training loss: 0.6892785209196585
Epoch: 88 | Iteration number: [280/565] 49% | Training loss: 0.6891888122473444
Epoch: 88 | Iteration number: [290/565] 51% | Training loss: 0.6891293550359792
Epoch: 88 | Iteration number: [300/565] 53% | Training loss: 0.689049085577329
Epoch: 88 | Iteration number: [310/565] 54% | Training loss: 0.6889776929732292
Epoch: 88 | Iteration number: [320/565] 56% | Training loss: 0.6889115238562227
Epoch: 88 | Iteration number: [330/565] 58% | Training loss: 0.6888315641518795
Epoch: 88 | Iteration number: [340/565] 60% | Training loss: 0.688763206671266
Epoch: 88 | Iteration number: [350/565] 61% | Training loss: 0.6886976722308568
Epoch: 88 | Iteration number: [360/565] 63% | Training loss: 0.688652650018533
Epoch: 88 | Iteration number: [370/565] 65% | Training loss: 0.6886091884729024
Epoch: 88 | Iteration number: [380/565] 67% | Training loss: 0.6885702423359218
Epoch: 88 | Iteration number: [390/565] 69% | Training loss: 0.6885191070727813
Epoch: 88 | Iteration number: [400/565] 70% | Training loss: 0.688479360640049
Epoch: 88 | Iteration number: [410/565] 72% | Training loss: 0.6884363223866719
Epoch: 88 | Iteration number: [420/565] 74% | Training loss: 0.6883906791607539
Epoch: 88 | Iteration number: [430/565] 76% | Training loss: 0.6883474108784697
Epoch: 88 | Iteration number: [440/565] 77% | Training loss: 0.6883182260123166
Epoch: 88 | Iteration number: [450/565] 79% | Training loss: 0.6882832021183438
Epoch: 88 | Iteration number: [460/565] 81% | Training loss: 0.6882403639347657
Epoch: 88 | Iteration number: [470/565] 83% | Training loss: 0.6882139306119148
Epoch: 88 | Iteration number: [480/565] 84% | Training loss: 0.6881835016111533
Epoch: 88 | Iteration number: [490/565] 86% | Training loss: 0.68815538299327
Epoch: 88 | Iteration number: [500/565] 88% | Training loss: 0.6881305795907974
Epoch: 88 | Iteration number: [510/565] 90% | Training loss: 0.6881057677315731
Epoch: 88 | Iteration number: [520/565] 92% | Training loss: 0.6880823725691209
Epoch: 88 | Iteration number: [530/565] 93% | Training loss: 0.6880587905083062
Epoch: 88 | Iteration number: [540/565] 95% | Training loss: 0.688038600815667
Epoch: 88 | Iteration number: [550/565] 97% | Training loss: 0.68800842480226
Epoch: 88 | Iteration number: [560/565] 99% | Training loss: 0.6879893613713128

 End of epoch: 88 | Train Loss: 0.6867616232517546 | Training Time: 88 

 End of epoch: 88 | Eval Loss: 0.6898787191935948 | Evaluating Time: 6 
Epoch: 89 | Iteration number: [10/565] 1% | Training loss: 0.7560029327869415
Epoch: 89 | Iteration number: [20/565] 3% | Training loss: 0.721329852938652
Epoch: 89 | Iteration number: [30/565] 5% | Training loss: 0.7097611705462138
Epoch: 89 | Iteration number: [40/565] 7% | Training loss: 0.7039454787969589
Epoch: 89 | Iteration number: [50/565] 8% | Training loss: 0.7005330908298493
Epoch: 89 | Iteration number: [60/565] 10% | Training loss: 0.6982718576987584
Epoch: 89 | Iteration number: [70/565] 12% | Training loss: 0.6966412024838584
Epoch: 89 | Iteration number: [80/565] 14% | Training loss: 0.6954006798565388
Epoch: 89 | Iteration number: [90/565] 15% | Training loss: 0.6944701698091295
Epoch: 89 | Iteration number: [100/565] 17% | Training loss: 0.6937212651968002
Epoch: 89 | Iteration number: [110/565] 19% | Training loss: 0.6930774136023088
Epoch: 89 | Iteration number: [120/565] 21% | Training loss: 0.6925268958012263
Epoch: 89 | Iteration number: [130/565] 23% | Training loss: 0.6920795468183664
Epoch: 89 | Iteration number: [140/565] 24% | Training loss: 0.6917137009756905
Epoch: 89 | Iteration number: [150/565] 26% | Training loss: 0.691394084294637
Epoch: 89 | Iteration number: [160/565] 28% | Training loss: 0.6911039106547833
Epoch: 89 | Iteration number: [170/565] 30% | Training loss: 0.6908428469124962
Epoch: 89 | Iteration number: [180/565] 31% | Training loss: 0.6906268510553571
Epoch: 89 | Iteration number: [190/565] 33% | Training loss: 0.6904312698464644
Epoch: 89 | Iteration number: [200/565] 35% | Training loss: 0.6902631944417954
Epoch: 89 | Iteration number: [210/565] 37% | Training loss: 0.6900933191889809
Epoch: 89 | Iteration number: [220/565] 38% | Training loss: 0.6899449521845037
Epoch: 89 | Iteration number: [230/565] 40% | Training loss: 0.689797803370849
Epoch: 89 | Iteration number: [240/565] 42% | Training loss: 0.6896691523492336
Epoch: 89 | Iteration number: [250/565] 44% | Training loss: 0.6895405218601227
Epoch: 89 | Iteration number: [260/565] 46% | Training loss: 0.6894450249580236
Epoch: 89 | Iteration number: [270/565] 47% | Training loss: 0.6893583887153202
Epoch: 89 | Iteration number: [280/565] 49% | Training loss: 0.6892564207315445
Epoch: 89 | Iteration number: [290/565] 51% | Training loss: 0.6891584657389542
Epoch: 89 | Iteration number: [300/565] 53% | Training loss: 0.6890820990006129
Epoch: 89 | Iteration number: [310/565] 54% | Training loss: 0.6890183241136613
Epoch: 89 | Iteration number: [320/565] 56% | Training loss: 0.6889479579403996
Epoch: 89 | Iteration number: [330/565] 58% | Training loss: 0.6888734611597929
Epoch: 89 | Iteration number: [340/565] 60% | Training loss: 0.6888209940756068
Epoch: 89 | Iteration number: [350/565] 61% | Training loss: 0.6887640724863325
Epoch: 89 | Iteration number: [360/565] 63% | Training loss: 0.6886953860521317
Epoch: 89 | Iteration number: [370/565] 65% | Training loss: 0.688643417165086
Epoch: 89 | Iteration number: [380/565] 67% | Training loss: 0.6885953849867771
Epoch: 89 | Iteration number: [390/565] 69% | Training loss: 0.6885447503664555
Epoch: 89 | Iteration number: [400/565] 70% | Training loss: 0.688504493534565
Epoch: 89 | Iteration number: [410/565] 72% | Training loss: 0.6884517540292042
Epoch: 89 | Iteration number: [420/565] 74% | Training loss: 0.6884027049655006
Epoch: 89 | Iteration number: [430/565] 76% | Training loss: 0.6883587207905082
Epoch: 89 | Iteration number: [440/565] 77% | Training loss: 0.688314342092384
Epoch: 89 | Iteration number: [450/565] 79% | Training loss: 0.6882813372876909
Epoch: 89 | Iteration number: [460/565] 81% | Training loss: 0.6882397225369578
Epoch: 89 | Iteration number: [470/565] 83% | Training loss: 0.6882155447564227
Epoch: 89 | Iteration number: [480/565] 84% | Training loss: 0.6881749905645848
Epoch: 89 | Iteration number: [490/565] 86% | Training loss: 0.6881522823353203
Epoch: 89 | Iteration number: [500/565] 88% | Training loss: 0.6881288759708405
Epoch: 89 | Iteration number: [510/565] 90% | Training loss: 0.6881068119815752
Epoch: 89 | Iteration number: [520/565] 92% | Training loss: 0.6880860711519535
Epoch: 89 | Iteration number: [530/565] 93% | Training loss: 0.6880543932599842
Epoch: 89 | Iteration number: [540/565] 95% | Training loss: 0.6880296930118843
Epoch: 89 | Iteration number: [550/565] 97% | Training loss: 0.6880077105218714
Epoch: 89 | Iteration number: [560/565] 99% | Training loss: 0.6879848975156034

 End of epoch: 89 | Train Loss: 0.6867593964644237 | Training Time: 89 

 End of epoch: 89 | Eval Loss: 0.6897783279418945 | Evaluating Time: 6 
Epoch: 90 | Iteration number: [10/565] 1% | Training loss: 0.7552355885505676
Epoch: 90 | Iteration number: [20/565] 3% | Training loss: 0.7211383581161499
Epoch: 90 | Iteration number: [30/565] 5% | Training loss: 0.7097606400648753
Epoch: 90 | Iteration number: [40/565] 7% | Training loss: 0.7039578318595886
Epoch: 90 | Iteration number: [50/565] 8% | Training loss: 0.7005266642570496
Epoch: 90 | Iteration number: [60/565] 10% | Training loss: 0.6982470661401748
Epoch: 90 | Iteration number: [70/565] 12% | Training loss: 0.6965526401996612
Epoch: 90 | Iteration number: [80/565] 14% | Training loss: 0.6953120313584804
Epoch: 90 | Iteration number: [90/565] 15% | Training loss: 0.6943290187252893
Epoch: 90 | Iteration number: [100/565] 17% | Training loss: 0.6935879564285279
Epoch: 90 | Iteration number: [110/565] 19% | Training loss: 0.6929222789677707
Epoch: 90 | Iteration number: [120/565] 21% | Training loss: 0.6923782487710317
Epoch: 90 | Iteration number: [130/565] 23% | Training loss: 0.6919353654751411
Epoch: 90 | Iteration number: [140/565] 24% | Training loss: 0.6915884256362915
Epoch: 90 | Iteration number: [150/565] 26% | Training loss: 0.691289303302765
Epoch: 90 | Iteration number: [160/565] 28% | Training loss: 0.6910313133150339
Epoch: 90 | Iteration number: [170/565] 30% | Training loss: 0.690785669929841
Epoch: 90 | Iteration number: [180/565] 31% | Training loss: 0.6905989978048537
Epoch: 90 | Iteration number: [190/565] 33% | Training loss: 0.6903916713438536
Epoch: 90 | Iteration number: [200/565] 35% | Training loss: 0.6902109387516976
Epoch: 90 | Iteration number: [210/565] 37% | Training loss: 0.6900395836148944
Epoch: 90 | Iteration number: [220/565] 38% | Training loss: 0.689903250336647
Epoch: 90 | Iteration number: [230/565] 40% | Training loss: 0.6897710564343825
Epoch: 90 | Iteration number: [240/565] 42% | Training loss: 0.6896222857137521
Epoch: 90 | Iteration number: [250/565] 44% | Training loss: 0.6895140340328216
Epoch: 90 | Iteration number: [260/565] 46% | Training loss: 0.689415108699065
Epoch: 90 | Iteration number: [270/565] 47% | Training loss: 0.6893138203356001
Epoch: 90 | Iteration number: [280/565] 49% | Training loss: 0.6892168922083718
Epoch: 90 | Iteration number: [290/565] 51% | Training loss: 0.6891364913562249
Epoch: 90 | Iteration number: [300/565] 53% | Training loss: 0.6890466890732447
Epoch: 90 | Iteration number: [310/565] 54% | Training loss: 0.6889810219887764
Epoch: 90 | Iteration number: [320/565] 56% | Training loss: 0.6889231698587537
Epoch: 90 | Iteration number: [330/565] 58% | Training loss: 0.6888562159104781
Epoch: 90 | Iteration number: [340/565] 60% | Training loss: 0.6888009719988879
Epoch: 90 | Iteration number: [350/565] 61% | Training loss: 0.6887197530269623
Epoch: 90 | Iteration number: [360/565] 63% | Training loss: 0.6886635409461127
Epoch: 90 | Iteration number: [370/565] 65% | Training loss: 0.688607260665378
Epoch: 90 | Iteration number: [380/565] 67% | Training loss: 0.6885638822066157
Epoch: 90 | Iteration number: [390/565] 69% | Training loss: 0.6885232726732889
Epoch: 90 | Iteration number: [400/565] 70% | Training loss: 0.6884785796701908
Epoch: 90 | Iteration number: [410/565] 72% | Training loss: 0.688436713887424
Epoch: 90 | Iteration number: [420/565] 74% | Training loss: 0.6883933237620763
Epoch: 90 | Iteration number: [430/565] 76% | Training loss: 0.6883509896522344
Epoch: 90 | Iteration number: [440/565] 77% | Training loss: 0.6883209220387719
Epoch: 90 | Iteration number: [450/565] 79% | Training loss: 0.688284000688129
Epoch: 90 | Iteration number: [460/565] 81% | Training loss: 0.6882470138694929
Epoch: 90 | Iteration number: [470/565] 83% | Training loss: 0.6882192984540412
Epoch: 90 | Iteration number: [480/565] 84% | Training loss: 0.6881824405242999
Epoch: 90 | Iteration number: [490/565] 86% | Training loss: 0.6881561179550326
Epoch: 90 | Iteration number: [500/565] 88% | Training loss: 0.6881275804042816
Epoch: 90 | Iteration number: [510/565] 90% | Training loss: 0.6880964155290641
Epoch: 90 | Iteration number: [520/565] 92% | Training loss: 0.6880736987178142
Epoch: 90 | Iteration number: [530/565] 93% | Training loss: 0.6880496435570267
Epoch: 90 | Iteration number: [540/565] 95% | Training loss: 0.6880223033604799
Epoch: 90 | Iteration number: [550/565] 97% | Training loss: 0.6880069616707889
Epoch: 90 | Iteration number: [560/565] 99% | Training loss: 0.6879824362695217

 End of epoch: 90 | Train Loss: 0.6867582329606587 | Training Time: 90 

 End of epoch: 90 | Eval Loss: 0.6899256706237793 | Evaluating Time: 5 
Epoch: 91 | Iteration number: [10/565] 1% | Training loss: 0.7554329752922058
Epoch: 91 | Iteration number: [20/565] 3% | Training loss: 0.721153923869133
Epoch: 91 | Iteration number: [30/565] 5% | Training loss: 0.7099030296007792
Epoch: 91 | Iteration number: [40/565] 7% | Training loss: 0.7042642787098885
Epoch: 91 | Iteration number: [50/565] 8% | Training loss: 0.7007671463489532
Epoch: 91 | Iteration number: [60/565] 10% | Training loss: 0.6983638922373454
Epoch: 91 | Iteration number: [70/565] 12% | Training loss: 0.6967570713588169
Epoch: 91 | Iteration number: [80/565] 14% | Training loss: 0.6954919397830963
Epoch: 91 | Iteration number: [90/565] 15% | Training loss: 0.69448431664043
Epoch: 91 | Iteration number: [100/565] 17% | Training loss: 0.6937426042556762
Epoch: 91 | Iteration number: [110/565] 19% | Training loss: 0.693111366033554
Epoch: 91 | Iteration number: [120/565] 21% | Training loss: 0.6926142747203509
Epoch: 91 | Iteration number: [130/565] 23% | Training loss: 0.692159294623595
Epoch: 91 | Iteration number: [140/565] 24% | Training loss: 0.691732593519347
Epoch: 91 | Iteration number: [150/565] 26% | Training loss: 0.6913738969961802
Epoch: 91 | Iteration number: [160/565] 28% | Training loss: 0.6910721328109503
Epoch: 91 | Iteration number: [170/565] 30% | Training loss: 0.6908233516356524
Epoch: 91 | Iteration number: [180/565] 31% | Training loss: 0.6905832780732049
Epoch: 91 | Iteration number: [190/565] 33% | Training loss: 0.6903917971410249
Epoch: 91 | Iteration number: [200/565] 35% | Training loss: 0.6902238294482231
Epoch: 91 | Iteration number: [210/565] 37% | Training loss: 0.6900699172701155
Epoch: 91 | Iteration number: [220/565] 38% | Training loss: 0.6899052966724742
Epoch: 91 | Iteration number: [230/565] 40% | Training loss: 0.6897626539935237
Epoch: 91 | Iteration number: [240/565] 42% | Training loss: 0.6896381037930648
Epoch: 91 | Iteration number: [250/565] 44% | Training loss: 0.6895224106311798
Epoch: 91 | Iteration number: [260/565] 46% | Training loss: 0.689399321950399
Epoch: 91 | Iteration number: [270/565] 47% | Training loss: 0.6893125333167889
Epoch: 91 | Iteration number: [280/565] 49% | Training loss: 0.6892253041267395
Epoch: 91 | Iteration number: [290/565] 51% | Training loss: 0.6891365610319993
Epoch: 91 | Iteration number: [300/565] 53% | Training loss: 0.6890688439210256
Epoch: 91 | Iteration number: [310/565] 54% | Training loss: 0.6889951446364003
Epoch: 91 | Iteration number: [320/565] 56% | Training loss: 0.6889282055199146
Epoch: 91 | Iteration number: [330/565] 58% | Training loss: 0.6888541976610819
Epoch: 91 | Iteration number: [340/565] 60% | Training loss: 0.6887981055413975
Epoch: 91 | Iteration number: [350/565] 61% | Training loss: 0.6887320753506252
Epoch: 91 | Iteration number: [360/565] 63% | Training loss: 0.6886712652113702
Epoch: 91 | Iteration number: [370/565] 65% | Training loss: 0.68863333737528
Epoch: 91 | Iteration number: [380/565] 67% | Training loss: 0.688586690865065
Epoch: 91 | Iteration number: [390/565] 69% | Training loss: 0.6885348896185557
Epoch: 91 | Iteration number: [400/565] 70% | Training loss: 0.688488087952137
Epoch: 91 | Iteration number: [410/565] 72% | Training loss: 0.6884476263348649
Epoch: 91 | Iteration number: [420/565] 74% | Training loss: 0.6884170491070974
Epoch: 91 | Iteration number: [430/565] 76% | Training loss: 0.688383386024209
Epoch: 91 | Iteration number: [440/565] 77% | Training loss: 0.6883445923978632
Epoch: 91 | Iteration number: [450/565] 79% | Training loss: 0.6883073625299666
Epoch: 91 | Iteration number: [460/565] 81% | Training loss: 0.6882740627164426
Epoch: 91 | Iteration number: [470/565] 83% | Training loss: 0.6882428657501302
Epoch: 91 | Iteration number: [480/565] 84% | Training loss: 0.6882146264115969
Epoch: 91 | Iteration number: [490/565] 86% | Training loss: 0.6881787738021539
Epoch: 91 | Iteration number: [500/565] 88% | Training loss: 0.6881449793577195
Epoch: 91 | Iteration number: [510/565] 90% | Training loss: 0.6881076692366133
Epoch: 91 | Iteration number: [520/565] 92% | Training loss: 0.6880992997151155
Epoch: 91 | Iteration number: [530/565] 93% | Training loss: 0.6880665558689045
Epoch: 91 | Iteration number: [540/565] 95% | Training loss: 0.6880436134559137
Epoch: 91 | Iteration number: [550/565] 97% | Training loss: 0.6880208515037189
Epoch: 91 | Iteration number: [560/565] 99% | Training loss: 0.6879903404840402

 End of epoch: 91 | Train Loss: 0.6867607953274144 | Training Time: 88 

 End of epoch: 91 | Eval Loss: 0.6897837434496198 | Evaluating Time: 6 
Epoch: 92 | Iteration number: [10/565] 1% | Training loss: 0.7557214319705963
Epoch: 92 | Iteration number: [20/565] 3% | Training loss: 0.7211667001247406
Epoch: 92 | Iteration number: [30/565] 5% | Training loss: 0.7096168498198191
Epoch: 92 | Iteration number: [40/565] 7% | Training loss: 0.7039117887616158
Epoch: 92 | Iteration number: [50/565] 8% | Training loss: 0.7004659008979798
Epoch: 92 | Iteration number: [60/565] 10% | Training loss: 0.69819708665212
Epoch: 92 | Iteration number: [70/565] 12% | Training loss: 0.6966141547475543
Epoch: 92 | Iteration number: [80/565] 14% | Training loss: 0.6953504368662834
Epoch: 92 | Iteration number: [90/565] 15% | Training loss: 0.6943873915407393
Epoch: 92 | Iteration number: [100/565] 17% | Training loss: 0.693635283112526
Epoch: 92 | Iteration number: [110/565] 19% | Training loss: 0.6930571789091283
Epoch: 92 | Iteration number: [120/565] 21% | Training loss: 0.6925562476118405
Epoch: 92 | Iteration number: [130/565] 23% | Training loss: 0.6921227505573859
Epoch: 92 | Iteration number: [140/565] 24% | Training loss: 0.6917460816247123
Epoch: 92 | Iteration number: [150/565] 26% | Training loss: 0.6914239414532979
Epoch: 92 | Iteration number: [160/565] 28% | Training loss: 0.6911346033215523
Epoch: 92 | Iteration number: [170/565] 30% | Training loss: 0.6908618274857016
Epoch: 92 | Iteration number: [180/565] 31% | Training loss: 0.6906586584117678
Epoch: 92 | Iteration number: [190/565] 33% | Training loss: 0.690432315751126
Epoch: 92 | Iteration number: [200/565] 35% | Training loss: 0.6902788782119751
Epoch: 92 | Iteration number: [210/565] 37% | Training loss: 0.6901108605521066
Epoch: 92 | Iteration number: [220/565] 38% | Training loss: 0.6899469549005682
Epoch: 92 | Iteration number: [230/565] 40% | Training loss: 0.6898247928723045
Epoch: 92 | Iteration number: [240/565] 42% | Training loss: 0.6896996051073074
Epoch: 92 | Iteration number: [250/565] 44% | Training loss: 0.6895837233066558
Epoch: 92 | Iteration number: [260/565] 46% | Training loss: 0.6894640317329994
Epoch: 92 | Iteration number: [270/565] 47% | Training loss: 0.6893688215149774
Epoch: 92 | Iteration number: [280/565] 49% | Training loss: 0.6892707439405578
Epoch: 92 | Iteration number: [290/565] 51% | Training loss: 0.6891878278091036
Epoch: 92 | Iteration number: [300/565] 53% | Training loss: 0.6891184550523758
Epoch: 92 | Iteration number: [310/565] 54% | Training loss: 0.6890481779652257
Epoch: 92 | Iteration number: [320/565] 56% | Training loss: 0.6889741292223335
Epoch: 92 | Iteration number: [330/565] 58% | Training loss: 0.6889130373795828
Epoch: 92 | Iteration number: [340/565] 60% | Training loss: 0.6888507974498412
Epoch: 92 | Iteration number: [350/565] 61% | Training loss: 0.6888057017326354
Epoch: 92 | Iteration number: [360/565] 63% | Training loss: 0.6887562581234508
Epoch: 92 | Iteration number: [370/565] 65% | Training loss: 0.6887134481120754
Epoch: 92 | Iteration number: [380/565] 67% | Training loss: 0.6886727293855266
Epoch: 92 | Iteration number: [390/565] 69% | Training loss: 0.6886222616220132
Epoch: 92 | Iteration number: [400/565] 70% | Training loss: 0.6885749262571335
Epoch: 92 | Iteration number: [410/565] 72% | Training loss: 0.6885312487439411
Epoch: 92 | Iteration number: [420/565] 74% | Training loss: 0.6884797744807742
Epoch: 92 | Iteration number: [430/565] 76% | Training loss: 0.6884341982908027
Epoch: 92 | Iteration number: [440/565] 77% | Training loss: 0.6883893451907418
Epoch: 92 | Iteration number: [450/565] 79% | Training loss: 0.688345343404346
Epoch: 92 | Iteration number: [460/565] 81% | Training loss: 0.6883148495269859
Epoch: 92 | Iteration number: [470/565] 83% | Training loss: 0.6882818376764338
Epoch: 92 | Iteration number: [480/565] 84% | Training loss: 0.688243089367946
Epoch: 92 | Iteration number: [490/565] 86% | Training loss: 0.6882119570459638
Epoch: 92 | Iteration number: [500/565] 88% | Training loss: 0.6881855142116546
Epoch: 92 | Iteration number: [510/565] 90% | Training loss: 0.6881546018170376
Epoch: 92 | Iteration number: [520/565] 92% | Training loss: 0.688123281300068
Epoch: 92 | Iteration number: [530/565] 93% | Training loss: 0.6880928382558643
Epoch: 92 | Iteration number: [540/565] 95% | Training loss: 0.6880709086303358
Epoch: 92 | Iteration number: [550/565] 97% | Training loss: 0.6880407709425146
Epoch: 92 | Iteration number: [560/565] 99% | Training loss: 0.6880240887403488

 End of epoch: 92 | Train Loss: 0.6867940494444518 | Training Time: 88 

 End of epoch: 92 | Eval Loss: 0.6899207830429077 | Evaluating Time: 6 
Epoch: 93 | Iteration number: [10/565] 1% | Training loss: 0.754961359500885
Epoch: 93 | Iteration number: [20/565] 3% | Training loss: 0.7210503995418549
Epoch: 93 | Iteration number: [30/565] 5% | Training loss: 0.7094077487786611
Epoch: 93 | Iteration number: [40/565] 7% | Training loss: 0.7037420943379402
Epoch: 93 | Iteration number: [50/565] 8% | Training loss: 0.7003329312801361
Epoch: 93 | Iteration number: [60/565] 10% | Training loss: 0.6981065859397252
Epoch: 93 | Iteration number: [70/565] 12% | Training loss: 0.6964567133358547
Epoch: 93 | Iteration number: [80/565] 14% | Training loss: 0.6952188447117805
Epoch: 93 | Iteration number: [90/565] 15% | Training loss: 0.6942906048562791
Epoch: 93 | Iteration number: [100/565] 17% | Training loss: 0.6935379499197006
Epoch: 93 | Iteration number: [110/565] 19% | Training loss: 0.6929038286209106
Epoch: 93 | Iteration number: [120/565] 21% | Training loss: 0.692409976820151
Epoch: 93 | Iteration number: [130/565] 23% | Training loss: 0.6919187958423908
Epoch: 93 | Iteration number: [140/565] 24% | Training loss: 0.6915259514536176
Epoch: 93 | Iteration number: [150/565] 26% | Training loss: 0.6912185200055441
Epoch: 93 | Iteration number: [160/565] 28% | Training loss: 0.6909278072416782
Epoch: 93 | Iteration number: [170/565] 30% | Training loss: 0.6906748617396635
Epoch: 93 | Iteration number: [180/565] 31% | Training loss: 0.6904504928323958
Epoch: 93 | Iteration number: [190/565] 33% | Training loss: 0.6902401575916692
Epoch: 93 | Iteration number: [200/565] 35% | Training loss: 0.6900874605774879
Epoch: 93 | Iteration number: [210/565] 37% | Training loss: 0.6899368680658795
Epoch: 93 | Iteration number: [220/565] 38% | Training loss: 0.6897721534425562
Epoch: 93 | Iteration number: [230/565] 40% | Training loss: 0.6896524092425471
Epoch: 93 | Iteration number: [240/565] 42% | Training loss: 0.6895175913969676
Epoch: 93 | Iteration number: [250/565] 44% | Training loss: 0.6894153201580048
Epoch: 93 | Iteration number: [260/565] 46% | Training loss: 0.68931640959703
Epoch: 93 | Iteration number: [270/565] 47% | Training loss: 0.6892308751742046
Epoch: 93 | Iteration number: [280/565] 49% | Training loss: 0.6891549206205777
Epoch: 93 | Iteration number: [290/565] 51% | Training loss: 0.6890443551129308
Epoch: 93 | Iteration number: [300/565] 53% | Training loss: 0.6889594054222107
Epoch: 93 | Iteration number: [310/565] 54% | Training loss: 0.6889091741654181
Epoch: 93 | Iteration number: [320/565] 56% | Training loss: 0.6888503300026059
Epoch: 93 | Iteration number: [330/565] 58% | Training loss: 0.6887773167003285
Epoch: 93 | Iteration number: [340/565] 60% | Training loss: 0.688719323628089
Epoch: 93 | Iteration number: [350/565] 61% | Training loss: 0.688667186328343
Epoch: 93 | Iteration number: [360/565] 63% | Training loss: 0.6886211786005232
Epoch: 93 | Iteration number: [370/565] 65% | Training loss: 0.6885812106970194
Epoch: 93 | Iteration number: [380/565] 67% | Training loss: 0.6885295493038077
Epoch: 93 | Iteration number: [390/565] 69% | Training loss: 0.6884876604263599
Epoch: 93 | Iteration number: [400/565] 70% | Training loss: 0.6884542380273342
Epoch: 93 | Iteration number: [410/565] 72% | Training loss: 0.6884066644238263
Epoch: 93 | Iteration number: [420/565] 74% | Training loss: 0.6883704033635911
Epoch: 93 | Iteration number: [430/565] 76% | Training loss: 0.6883325375789819
Epoch: 93 | Iteration number: [440/565] 77% | Training loss: 0.6883062675595284
Epoch: 93 | Iteration number: [450/565] 79% | Training loss: 0.6882852288087209
Epoch: 93 | Iteration number: [460/565] 81% | Training loss: 0.6882548317961071
Epoch: 93 | Iteration number: [470/565] 83% | Training loss: 0.688223290316602
Epoch: 93 | Iteration number: [480/565] 84% | Training loss: 0.6881884100536505
Epoch: 93 | Iteration number: [490/565] 86% | Training loss: 0.6881552792325312
Epoch: 93 | Iteration number: [500/565] 88% | Training loss: 0.6881237789392471
Epoch: 93 | Iteration number: [510/565] 90% | Training loss: 0.6881045783267302
Epoch: 93 | Iteration number: [520/565] 92% | Training loss: 0.6880794119376402
Epoch: 93 | Iteration number: [530/565] 93% | Training loss: 0.6880520566454473
Epoch: 93 | Iteration number: [540/565] 95% | Training loss: 0.688031088091709
Epoch: 93 | Iteration number: [550/565] 97% | Training loss: 0.6880058878118341
Epoch: 93 | Iteration number: [560/565] 99% | Training loss: 0.6879885139209884

 End of epoch: 93 | Train Loss: 0.6867589068623771 | Training Time: 89 

 End of epoch: 93 | Eval Loss: 0.68963508946555 | Evaluating Time: 6 
Epoch: 94 | Iteration number: [10/565] 1% | Training loss: 0.7555189430713654
Epoch: 94 | Iteration number: [20/565] 3% | Training loss: 0.7210882723331451
Epoch: 94 | Iteration number: [30/565] 5% | Training loss: 0.709731908639272
Epoch: 94 | Iteration number: [40/565] 7% | Training loss: 0.7040167227387428
Epoch: 94 | Iteration number: [50/565] 8% | Training loss: 0.7005424284934998
Epoch: 94 | Iteration number: [60/565] 10% | Training loss: 0.6982750584681828
Epoch: 94 | Iteration number: [70/565] 12% | Training loss: 0.6966047508375985
Epoch: 94 | Iteration number: [80/565] 14% | Training loss: 0.6954047098755837
Epoch: 94 | Iteration number: [90/565] 15% | Training loss: 0.694431416855918
Epoch: 94 | Iteration number: [100/565] 17% | Training loss: 0.6936621683835983
Epoch: 94 | Iteration number: [110/565] 19% | Training loss: 0.693050707470287
Epoch: 94 | Iteration number: [120/565] 21% | Training loss: 0.6925187826156616
Epoch: 94 | Iteration number: [130/565] 23% | Training loss: 0.6920841331665333
Epoch: 94 | Iteration number: [140/565] 24% | Training loss: 0.6917108339922768
Epoch: 94 | Iteration number: [150/565] 26% | Training loss: 0.6913843087355296
Epoch: 94 | Iteration number: [160/565] 28% | Training loss: 0.6911037497222423
Epoch: 94 | Iteration number: [170/565] 30% | Training loss: 0.6908194082624772
Epoch: 94 | Iteration number: [180/565] 31% | Training loss: 0.6905498183435864
Epoch: 94 | Iteration number: [190/565] 33% | Training loss: 0.690355446464137
Epoch: 94 | Iteration number: [200/565] 35% | Training loss: 0.6901737844944
Epoch: 94 | Iteration number: [210/565] 37% | Training loss: 0.6900244590781984
Epoch: 94 | Iteration number: [220/565] 38% | Training loss: 0.6898632168769836
Epoch: 94 | Iteration number: [230/565] 40% | Training loss: 0.6897074777147044
Epoch: 94 | Iteration number: [240/565] 42% | Training loss: 0.6895947533349196
Epoch: 94 | Iteration number: [250/565] 44% | Training loss: 0.6894871802330017
Epoch: 94 | Iteration number: [260/565] 46% | Training loss: 0.6893944245118361
Epoch: 94 | Iteration number: [270/565] 47% | Training loss: 0.6892728832032945
Epoch: 94 | Iteration number: [280/565] 49% | Training loss: 0.6891803771257401
Epoch: 94 | Iteration number: [290/565] 51% | Training loss: 0.6891008120158623
Epoch: 94 | Iteration number: [300/565] 53% | Training loss: 0.6890186723073324
Epoch: 94 | Iteration number: [310/565] 54% | Training loss: 0.6889426310216227
Epoch: 94 | Iteration number: [320/565] 56% | Training loss: 0.6888841480016709
Epoch: 94 | Iteration number: [330/565] 58% | Training loss: 0.6888187822067376
Epoch: 94 | Iteration number: [340/565] 60% | Training loss: 0.6887554464971318
Epoch: 94 | Iteration number: [350/565] 61% | Training loss: 0.688707001209259
Epoch: 94 | Iteration number: [360/565] 63% | Training loss: 0.6886490343345536
Epoch: 94 | Iteration number: [370/565] 65% | Training loss: 0.6885980825166444
Epoch: 94 | Iteration number: [380/565] 67% | Training loss: 0.688549838097472
Epoch: 94 | Iteration number: [390/565] 69% | Training loss: 0.688503315509894
Epoch: 94 | Iteration number: [400/565] 70% | Training loss: 0.6884691759943962
Epoch: 94 | Iteration number: [410/565] 72% | Training loss: 0.6884351877177634
Epoch: 94 | Iteration number: [420/565] 74% | Training loss: 0.6883891581069855
Epoch: 94 | Iteration number: [430/565] 76% | Training loss: 0.6883498940356942
Epoch: 94 | Iteration number: [440/565] 77% | Training loss: 0.688318241184408
Epoch: 94 | Iteration number: [450/565] 79% | Training loss: 0.688284418185552
Epoch: 94 | Iteration number: [460/565] 81% | Training loss: 0.6882513602142749
Epoch: 94 | Iteration number: [470/565] 83% | Training loss: 0.6882146992581956
Epoch: 94 | Iteration number: [480/565] 84% | Training loss: 0.6881745668749014
Epoch: 94 | Iteration number: [490/565] 86% | Training loss: 0.6881428606656133
Epoch: 94 | Iteration number: [500/565] 88% | Training loss: 0.6881226420402526
Epoch: 94 | Iteration number: [510/565] 90% | Training loss: 0.6881013887770036
Epoch: 94 | Iteration number: [520/565] 92% | Training loss: 0.6880845460754175
Epoch: 94 | Iteration number: [530/565] 93% | Training loss: 0.6880661845207214
Epoch: 94 | Iteration number: [540/565] 95% | Training loss: 0.6880280957177833
Epoch: 94 | Iteration number: [550/565] 97% | Training loss: 0.6880092458291487
Epoch: 94 | Iteration number: [560/565] 99% | Training loss: 0.6879821291991642

 End of epoch: 94 | Train Loss: 0.6867544509668266 | Training Time: 88 

 End of epoch: 94 | Eval Loss: 0.6895574331283569 | Evaluating Time: 5 
Epoch: 95 | Iteration number: [10/565] 1% | Training loss: 0.7553774774074554
Epoch: 95 | Iteration number: [20/565] 3% | Training loss: 0.7209962189197541
Epoch: 95 | Iteration number: [30/565] 5% | Training loss: 0.7095183948675792
Epoch: 95 | Iteration number: [40/565] 7% | Training loss: 0.7037735417485237
Epoch: 95 | Iteration number: [50/565] 8% | Training loss: 0.7003671848773956
Epoch: 95 | Iteration number: [60/565] 10% | Training loss: 0.6981353749831517
Epoch: 95 | Iteration number: [70/565] 12% | Training loss: 0.6964606131826129
Epoch: 95 | Iteration number: [80/565] 14% | Training loss: 0.695135859400034
Epoch: 95 | Iteration number: [90/565] 15% | Training loss: 0.6942173971070184
Epoch: 95 | Iteration number: [100/565] 17% | Training loss: 0.6934698259830475
Epoch: 95 | Iteration number: [110/565] 19% | Training loss: 0.6928791799328544
Epoch: 95 | Iteration number: [120/565] 21% | Training loss: 0.6923569187521934
Epoch: 95 | Iteration number: [130/565] 23% | Training loss: 0.6919422099223503
Epoch: 95 | Iteration number: [140/565] 24% | Training loss: 0.6916068515607289
Epoch: 95 | Iteration number: [150/565] 26% | Training loss: 0.6913349906603495
Epoch: 95 | Iteration number: [160/565] 28% | Training loss: 0.6910670135170222
Epoch: 95 | Iteration number: [170/565] 30% | Training loss: 0.6908012323519763
Epoch: 95 | Iteration number: [180/565] 31% | Training loss: 0.6905843175119823
Epoch: 95 | Iteration number: [190/565] 33% | Training loss: 0.6903861416013617
Epoch: 95 | Iteration number: [200/565] 35% | Training loss: 0.6902098196744919
Epoch: 95 | Iteration number: [210/565] 37% | Training loss: 0.6900618201210386
Epoch: 95 | Iteration number: [220/565] 38% | Training loss: 0.689891808683222
Epoch: 95 | Iteration number: [230/565] 40% | Training loss: 0.6897678142008574
Epoch: 95 | Iteration number: [240/565] 42% | Training loss: 0.6896371108790239
Epoch: 95 | Iteration number: [250/565] 44% | Training loss: 0.6895009100437164
Epoch: 95 | Iteration number: [260/565] 46% | Training loss: 0.6893993393732951
Epoch: 95 | Iteration number: [270/565] 47% | Training loss: 0.6892909672525194
Epoch: 95 | Iteration number: [280/565] 49% | Training loss: 0.6891956827470235
Epoch: 95 | Iteration number: [290/565] 51% | Training loss: 0.6891179732207594
Epoch: 95 | Iteration number: [300/565] 53% | Training loss: 0.6890329504013062
Epoch: 95 | Iteration number: [310/565] 54% | Training loss: 0.6889589730770357
Epoch: 95 | Iteration number: [320/565] 56% | Training loss: 0.6888828346505761
Epoch: 95 | Iteration number: [330/565] 58% | Training loss: 0.6888166133201483
Epoch: 95 | Iteration number: [340/565] 60% | Training loss: 0.6887548229273628
Epoch: 95 | Iteration number: [350/565] 61% | Training loss: 0.688696951184954
Epoch: 95 | Iteration number: [360/565] 63% | Training loss: 0.6886537298560143
Epoch: 95 | Iteration number: [370/565] 65% | Training loss: 0.6885963994103509
Epoch: 95 | Iteration number: [380/565] 67% | Training loss: 0.6885450454134691
Epoch: 95 | Iteration number: [390/565] 69% | Training loss: 0.6885109556026948
Epoch: 95 | Iteration number: [400/565] 70% | Training loss: 0.6884622474014759
Epoch: 95 | Iteration number: [410/565] 72% | Training loss: 0.6884206693346907
Epoch: 95 | Iteration number: [420/565] 74% | Training loss: 0.6883815735578537
Epoch: 95 | Iteration number: [430/565] 76% | Training loss: 0.6883476197719574
Epoch: 95 | Iteration number: [440/565] 77% | Training loss: 0.6883072331547737
Epoch: 95 | Iteration number: [450/565] 79% | Training loss: 0.6882787358760833
Epoch: 95 | Iteration number: [460/565] 81% | Training loss: 0.6882565973893456
Epoch: 95 | Iteration number: [470/565] 83% | Training loss: 0.6882256274527692
Epoch: 95 | Iteration number: [480/565] 84% | Training loss: 0.6881963847825925
Epoch: 95 | Iteration number: [490/565] 86% | Training loss: 0.6881613775175445
Epoch: 95 | Iteration number: [500/565] 88% | Training loss: 0.6881317015886307
Epoch: 95 | Iteration number: [510/565] 90% | Training loss: 0.6881073629154878
Epoch: 95 | Iteration number: [520/565] 92% | Training loss: 0.6880780310584949
Epoch: 95 | Iteration number: [530/565] 93% | Training loss: 0.6880537899035328
Epoch: 95 | Iteration number: [540/565] 95% | Training loss: 0.688035171561771
Epoch: 95 | Iteration number: [550/565] 97% | Training loss: 0.6880089038068598
Epoch: 95 | Iteration number: [560/565] 99% | Training loss: 0.6879764804882663

 End of epoch: 95 | Train Loss: 0.6867536853899998 | Training Time: 91 

 End of epoch: 95 | Eval Loss: 0.6899295023509434 | Evaluating Time: 6 
Epoch: 96 | Iteration number: [10/565] 1% | Training loss: 0.7551233470439911
Epoch: 96 | Iteration number: [20/565] 3% | Training loss: 0.7208817273378372
Epoch: 96 | Iteration number: [30/565] 5% | Training loss: 0.7095353881518046
Epoch: 96 | Iteration number: [40/565] 7% | Training loss: 0.7037377968430519
Epoch: 96 | Iteration number: [50/565] 8% | Training loss: 0.7003421366214753
Epoch: 96 | Iteration number: [60/565] 10% | Training loss: 0.698093643784523
Epoch: 96 | Iteration number: [70/565] 12% | Training loss: 0.6964710439954486
Epoch: 96 | Iteration number: [80/565] 14% | Training loss: 0.6952012255787849
Epoch: 96 | Iteration number: [90/565] 15% | Training loss: 0.6942492412196265
Epoch: 96 | Iteration number: [100/565] 17% | Training loss: 0.6934862607717514
Epoch: 96 | Iteration number: [110/565] 19% | Training loss: 0.6928320900960402
Epoch: 96 | Iteration number: [120/565] 21% | Training loss: 0.692342417438825
Epoch: 96 | Iteration number: [130/565] 23% | Training loss: 0.691887359894239
Epoch: 96 | Iteration number: [140/565] 24% | Training loss: 0.6915237954684667
Epoch: 96 | Iteration number: [150/565] 26% | Training loss: 0.6912383004029592
Epoch: 96 | Iteration number: [160/565] 28% | Training loss: 0.6909377425909042
Epoch: 96 | Iteration number: [170/565] 30% | Training loss: 0.6906732201576233
Epoch: 96 | Iteration number: [180/565] 31% | Training loss: 0.690459097094006
Epoch: 96 | Iteration number: [190/565] 33% | Training loss: 0.6902844592144615
Epoch: 96 | Iteration number: [200/565] 35% | Training loss: 0.6900909733772278
Epoch: 96 | Iteration number: [210/565] 37% | Training loss: 0.6899343277726855
Epoch: 96 | Iteration number: [220/565] 38% | Training loss: 0.6897931123321707
Epoch: 96 | Iteration number: [230/565] 40% | Training loss: 0.6896552402040232
Epoch: 96 | Iteration number: [240/565] 42% | Training loss: 0.6895177987714608
Epoch: 96 | Iteration number: [250/565] 44% | Training loss: 0.6893864142894744
Epoch: 96 | Iteration number: [260/565] 46% | Training loss: 0.689294944359706
Epoch: 96 | Iteration number: [270/565] 47% | Training loss: 0.6892002767986721
Epoch: 96 | Iteration number: [280/565] 49% | Training loss: 0.6891156477587563
Epoch: 96 | Iteration number: [290/565] 51% | Training loss: 0.6890355387638355
Epoch: 96 | Iteration number: [300/565] 53% | Training loss: 0.6889596869548161
Epoch: 96 | Iteration number: [310/565] 54% | Training loss: 0.6888762458678215
Epoch: 96 | Iteration number: [320/565] 56% | Training loss: 0.688811712525785
Epoch: 96 | Iteration number: [330/565] 58% | Training loss: 0.6887541588508721
Epoch: 96 | Iteration number: [340/565] 60% | Training loss: 0.6887029512840159
Epoch: 96 | Iteration number: [350/565] 61% | Training loss: 0.6886481423037393
Epoch: 96 | Iteration number: [360/565] 63% | Training loss: 0.6886036296685537
Epoch: 96 | Iteration number: [370/565] 65% | Training loss: 0.6885554577853229
Epoch: 96 | Iteration number: [380/565] 67% | Training loss: 0.6885144613291088
Epoch: 96 | Iteration number: [390/565] 69% | Training loss: 0.688474120085056
Epoch: 96 | Iteration number: [400/565] 70% | Training loss: 0.6884248243272304
Epoch: 96 | Iteration number: [410/565] 72% | Training loss: 0.6883836718594155
Epoch: 96 | Iteration number: [420/565] 74% | Training loss: 0.6883433970667067
Epoch: 96 | Iteration number: [430/565] 76% | Training loss: 0.6883073935675067
Epoch: 96 | Iteration number: [440/565] 77% | Training loss: 0.6882743739268996
Epoch: 96 | Iteration number: [450/565] 79% | Training loss: 0.6882381722662184
Epoch: 96 | Iteration number: [460/565] 81% | Training loss: 0.688215553501378
Epoch: 96 | Iteration number: [470/565] 83% | Training loss: 0.688188631483849
Epoch: 96 | Iteration number: [480/565] 84% | Training loss: 0.6881625857204199
Epoch: 96 | Iteration number: [490/565] 86% | Training loss: 0.688132934424342
Epoch: 96 | Iteration number: [500/565] 88% | Training loss: 0.6881105109453202
Epoch: 96 | Iteration number: [510/565] 90% | Training loss: 0.6880677551615472
Epoch: 96 | Iteration number: [520/565] 92% | Training loss: 0.6880418130984673
Epoch: 96 | Iteration number: [530/565] 93% | Training loss: 0.6880174239851394
Epoch: 96 | Iteration number: [540/565] 95% | Training loss: 0.6880040948037748
Epoch: 96 | Iteration number: [550/565] 97% | Training loss: 0.687983221357519
Epoch: 96 | Iteration number: [560/565] 99% | Training loss: 0.6879738298910004

 End of epoch: 96 | Train Loss: 0.6867546924447592 | Training Time: 92 

 End of epoch: 96 | Eval Loss: 0.6894945246832711 | Evaluating Time: 5 
Epoch: 97 | Iteration number: [10/565] 1% | Training loss: 0.7554074287414551
Epoch: 97 | Iteration number: [20/565] 3% | Training loss: 0.7210209488868713
Epoch: 97 | Iteration number: [30/565] 5% | Training loss: 0.7095307211081187
Epoch: 97 | Iteration number: [40/565] 7% | Training loss: 0.7039100304245949
Epoch: 97 | Iteration number: [50/565] 8% | Training loss: 0.7004177582263946
Epoch: 97 | Iteration number: [60/565] 10% | Training loss: 0.6980991015831629
Epoch: 97 | Iteration number: [70/565] 12% | Training loss: 0.696522958789553
Epoch: 97 | Iteration number: [80/565] 14% | Training loss: 0.695239144563675
Epoch: 97 | Iteration number: [90/565] 15% | Training loss: 0.6942635377248129
Epoch: 97 | Iteration number: [100/565] 17% | Training loss: 0.6934917843341828
Epoch: 97 | Iteration number: [110/565] 19% | Training loss: 0.6928957473148
Epoch: 97 | Iteration number: [120/565] 21% | Training loss: 0.6924091880520185
Epoch: 97 | Iteration number: [130/565] 23% | Training loss: 0.6919932287472945
Epoch: 97 | Iteration number: [140/565] 24% | Training loss: 0.6916295451777322
Epoch: 97 | Iteration number: [150/565] 26% | Training loss: 0.6913028538227082
Epoch: 97 | Iteration number: [160/565] 28% | Training loss: 0.6910082101821899
Epoch: 97 | Iteration number: [170/565] 30% | Training loss: 0.690748021883123
Epoch: 97 | Iteration number: [180/565] 31% | Training loss: 0.6905349294344584
Epoch: 97 | Iteration number: [190/565] 33% | Training loss: 0.6902991470537687
Epoch: 97 | Iteration number: [200/565] 35% | Training loss: 0.6900941523909568
Epoch: 97 | Iteration number: [210/565] 37% | Training loss: 0.6899367312590281
Epoch: 97 | Iteration number: [220/565] 38% | Training loss: 0.6897860944271088
Epoch: 97 | Iteration number: [230/565] 40% | Training loss: 0.6896392679732779
Epoch: 97 | Iteration number: [240/565] 42% | Training loss: 0.6895306492845218
Epoch: 97 | Iteration number: [250/565] 44% | Training loss: 0.6894322566986084
Epoch: 97 | Iteration number: [260/565] 46% | Training loss: 0.6893165581501447
Epoch: 97 | Iteration number: [270/565] 47% | Training loss: 0.6892369433685586
Epoch: 97 | Iteration number: [280/565] 49% | Training loss: 0.6891465244548661
Epoch: 97 | Iteration number: [290/565] 51% | Training loss: 0.689064403443501
Epoch: 97 | Iteration number: [300/565] 53% | Training loss: 0.6889983876546224
Epoch: 97 | Iteration number: [310/565] 54% | Training loss: 0.6889238382539441
Epoch: 97 | Iteration number: [320/565] 56% | Training loss: 0.6888631697744131
Epoch: 97 | Iteration number: [330/565] 58% | Training loss: 0.6888088556853208
Epoch: 97 | Iteration number: [340/565] 60% | Training loss: 0.6887499921462115
Epoch: 97 | Iteration number: [350/565] 61% | Training loss: 0.6886914890153067
Epoch: 97 | Iteration number: [360/565] 63% | Training loss: 0.6886335361335013
Epoch: 97 | Iteration number: [370/565] 65% | Training loss: 0.6885790407657624
Epoch: 97 | Iteration number: [380/565] 67% | Training loss: 0.688524015326249
Epoch: 97 | Iteration number: [390/565] 69% | Training loss: 0.688479487101237
Epoch: 97 | Iteration number: [400/565] 70% | Training loss: 0.6884375953674317
Epoch: 97 | Iteration number: [410/565] 72% | Training loss: 0.6884017992310407
Epoch: 97 | Iteration number: [420/565] 74% | Training loss: 0.6883684139876138
Epoch: 97 | Iteration number: [430/565] 76% | Training loss: 0.6883350093697392
Epoch: 97 | Iteration number: [440/565] 77% | Training loss: 0.6883054645224052
Epoch: 97 | Iteration number: [450/565] 79% | Training loss: 0.6882726628250546
Epoch: 97 | Iteration number: [460/565] 81% | Training loss: 0.6882368229005648
Epoch: 97 | Iteration number: [470/565] 83% | Training loss: 0.6881994024236151
Epoch: 97 | Iteration number: [480/565] 84% | Training loss: 0.6881706579277913
Epoch: 97 | Iteration number: [490/565] 86% | Training loss: 0.6881407656231705
Epoch: 97 | Iteration number: [500/565] 88% | Training loss: 0.6881192243099212
Epoch: 97 | Iteration number: [510/565] 90% | Training loss: 0.688095853842941
Epoch: 97 | Iteration number: [520/565] 92% | Training loss: 0.6880746310720077
Epoch: 97 | Iteration number: [530/565] 93% | Training loss: 0.688045231801159
Epoch: 97 | Iteration number: [540/565] 95% | Training loss: 0.6880222372434758
Epoch: 97 | Iteration number: [550/565] 97% | Training loss: 0.6879962771589105
Epoch: 97 | Iteration number: [560/565] 99% | Training loss: 0.6879730193742684

 End of epoch: 97 | Train Loss: 0.6867505820451585 | Training Time: 90 

 End of epoch: 97 | Eval Loss: 0.6900754826409476 | Evaluating Time: 5 
Epoch: 98 | Iteration number: [10/565] 1% | Training loss: 0.7549954235553742
Epoch: 98 | Iteration number: [20/565] 3% | Training loss: 0.7208394050598145
Epoch: 98 | Iteration number: [30/565] 5% | Training loss: 0.7095621148745219
Epoch: 98 | Iteration number: [40/565] 7% | Training loss: 0.7038347899913788
Epoch: 98 | Iteration number: [50/565] 8% | Training loss: 0.70041898727417
Epoch: 98 | Iteration number: [60/565] 10% | Training loss: 0.6982061952352524
Epoch: 98 | Iteration number: [70/565] 12% | Training loss: 0.6965735503605434
Epoch: 98 | Iteration number: [80/565] 14% | Training loss: 0.6953505329787731
Epoch: 98 | Iteration number: [90/565] 15% | Training loss: 0.6943740162584516
Epoch: 98 | Iteration number: [100/565] 17% | Training loss: 0.6936313837766648
Epoch: 98 | Iteration number: [110/565] 19% | Training loss: 0.6930309398607775
Epoch: 98 | Iteration number: [120/565] 21% | Training loss: 0.6925221587220828
Epoch: 98 | Iteration number: [130/565] 23% | Training loss: 0.6920867108381712
Epoch: 98 | Iteration number: [140/565] 24% | Training loss: 0.6916732421943119
Epoch: 98 | Iteration number: [150/565] 26% | Training loss: 0.6913632281621297
Epoch: 98 | Iteration number: [160/565] 28% | Training loss: 0.6910789765417575
Epoch: 98 | Iteration number: [170/565] 30% | Training loss: 0.690830705796971
Epoch: 98 | Iteration number: [180/565] 31% | Training loss: 0.6906210833125644
Epoch: 98 | Iteration number: [190/565] 33% | Training loss: 0.6904115557670594
Epoch: 98 | Iteration number: [200/565] 35% | Training loss: 0.6902248346805573
Epoch: 98 | Iteration number: [210/565] 37% | Training loss: 0.6900651664960952
Epoch: 98 | Iteration number: [220/565] 38% | Training loss: 0.6899328321218491
Epoch: 98 | Iteration number: [230/565] 40% | Training loss: 0.6898014781267746
Epoch: 98 | Iteration number: [240/565] 42% | Training loss: 0.6896864170829455
Epoch: 98 | Iteration number: [250/565] 44% | Training loss: 0.6895589127540588
Epoch: 98 | Iteration number: [260/565] 46% | Training loss: 0.689451627777173
Epoch: 98 | Iteration number: [270/565] 47% | Training loss: 0.6893438805032659
Epoch: 98 | Iteration number: [280/565] 49% | Training loss: 0.6892465144395828
Epoch: 98 | Iteration number: [290/565] 51% | Training loss: 0.6891701523599953
Epoch: 98 | Iteration number: [300/565] 53% | Training loss: 0.6890874391794205
Epoch: 98 | Iteration number: [310/565] 54% | Training loss: 0.6890135815066676
Epoch: 98 | Iteration number: [320/565] 56% | Training loss: 0.6889226676896214
Epoch: 98 | Iteration number: [330/565] 58% | Training loss: 0.6888483108896197
Epoch: 98 | Iteration number: [340/565] 60% | Training loss: 0.6887743157498977
Epoch: 98 | Iteration number: [350/565] 61% | Training loss: 0.6887235375813076
Epoch: 98 | Iteration number: [360/565] 63% | Training loss: 0.6886586066749361
Epoch: 98 | Iteration number: [370/565] 65% | Training loss: 0.6886069668305886
Epoch: 98 | Iteration number: [380/565] 67% | Training loss: 0.6885558181687406
Epoch: 98 | Iteration number: [390/565] 69% | Training loss: 0.6885128010541964
Epoch: 98 | Iteration number: [400/565] 70% | Training loss: 0.6884672057628631
Epoch: 98 | Iteration number: [410/565] 72% | Training loss: 0.6884260176158533
Epoch: 98 | Iteration number: [420/565] 74% | Training loss: 0.688392869205702
Epoch: 98 | Iteration number: [430/565] 76% | Training loss: 0.6883475282857584
Epoch: 98 | Iteration number: [440/565] 77% | Training loss: 0.68830634965138
Epoch: 98 | Iteration number: [450/565] 79% | Training loss: 0.6882685429520077
Epoch: 98 | Iteration number: [460/565] 81% | Training loss: 0.6882426854061043
Epoch: 98 | Iteration number: [470/565] 83% | Training loss: 0.6882123836811552
Epoch: 98 | Iteration number: [480/565] 84% | Training loss: 0.6881822180002928
Epoch: 98 | Iteration number: [490/565] 86% | Training loss: 0.6881656916774049
Epoch: 98 | Iteration number: [500/565] 88% | Training loss: 0.6881367036104202
Epoch: 98 | Iteration number: [510/565] 90% | Training loss: 0.6881126907526278
Epoch: 98 | Iteration number: [520/565] 92% | Training loss: 0.6880801265056317
Epoch: 98 | Iteration number: [530/565] 93% | Training loss: 0.6880609919440072
Epoch: 98 | Iteration number: [540/565] 95% | Training loss: 0.6880372624706339
Epoch: 98 | Iteration number: [550/565] 97% | Training loss: 0.6880099134011702
Epoch: 98 | Iteration number: [560/565] 99% | Training loss: 0.6879796216530459

 End of epoch: 98 | Train Loss: 0.6867518361690825 | Training Time: 89 

 End of epoch: 98 | Eval Loss: 0.6892683165413993 | Evaluating Time: 5 
Epoch: 99 | Iteration number: [10/565] 1% | Training loss: 0.7549852311611176
Epoch: 99 | Iteration number: [20/565] 3% | Training loss: 0.7208114266395569
Epoch: 99 | Iteration number: [30/565] 5% | Training loss: 0.7095563729604085
Epoch: 99 | Iteration number: [40/565] 7% | Training loss: 0.7039162218570709
Epoch: 99 | Iteration number: [50/565] 8% | Training loss: 0.7004002034664154
Epoch: 99 | Iteration number: [60/565] 10% | Training loss: 0.6981062551339468
Epoch: 99 | Iteration number: [70/565] 12% | Training loss: 0.6965699263981411
Epoch: 99 | Iteration number: [80/565] 14% | Training loss: 0.69537358507514
Epoch: 99 | Iteration number: [90/565] 15% | Training loss: 0.6944685068395403
Epoch: 99 | Iteration number: [100/565] 17% | Training loss: 0.6937038326263427
Epoch: 99 | Iteration number: [110/565] 19% | Training loss: 0.6930747005072507
Epoch: 99 | Iteration number: [120/565] 21% | Training loss: 0.6925506393114725
Epoch: 99 | Iteration number: [130/565] 23% | Training loss: 0.6921165489233457
Epoch: 99 | Iteration number: [140/565] 24% | Training loss: 0.6917140228407723
Epoch: 99 | Iteration number: [150/565] 26% | Training loss: 0.6913848094145457
Epoch: 99 | Iteration number: [160/565] 28% | Training loss: 0.6911197394132614
Epoch: 99 | Iteration number: [170/565] 30% | Training loss: 0.6908272809842053
Epoch: 99 | Iteration number: [180/565] 31% | Training loss: 0.690574554933442
Epoch: 99 | Iteration number: [190/565] 33% | Training loss: 0.6903689459750527
Epoch: 99 | Iteration number: [200/565] 35% | Training loss: 0.6901848196983338
Epoch: 99 | Iteration number: [210/565] 37% | Training loss: 0.690028372832707
Epoch: 99 | Iteration number: [220/565] 38% | Training loss: 0.6898721621795134
Epoch: 99 | Iteration number: [230/565] 40% | Training loss: 0.6897350365700929
Epoch: 99 | Iteration number: [240/565] 42% | Training loss: 0.689604073514541
Epoch: 99 | Iteration number: [250/565] 44% | Training loss: 0.6895007057189941
Epoch: 99 | Iteration number: [260/565] 46% | Training loss: 0.689391913322302
Epoch: 99 | Iteration number: [270/565] 47% | Training loss: 0.689310015351684
Epoch: 99 | Iteration number: [280/565] 49% | Training loss: 0.6892168764557157
Epoch: 99 | Iteration number: [290/565] 51% | Training loss: 0.6891443904103904
Epoch: 99 | Iteration number: [300/565] 53% | Training loss: 0.6890598036845526
Epoch: 99 | Iteration number: [310/565] 54% | Training loss: 0.68899405444822
Epoch: 99 | Iteration number: [320/565] 56% | Training loss: 0.6889186397194862
Epoch: 99 | Iteration number: [330/565] 58% | Training loss: 0.688840166908322
Epoch: 99 | Iteration number: [340/565] 60% | Training loss: 0.6887887058889165
Epoch: 99 | Iteration number: [350/565] 61% | Training loss: 0.6887399915286473
Epoch: 99 | Iteration number: [360/565] 63% | Training loss: 0.6886944035689037
Epoch: 99 | Iteration number: [370/565] 65% | Training loss: 0.6886467990037557
Epoch: 99 | Iteration number: [380/565] 67% | Training loss: 0.6886055640484158
Epoch: 99 | Iteration number: [390/565] 69% | Training loss: 0.6885624352173928
Epoch: 99 | Iteration number: [400/565] 70% | Training loss: 0.6885110776126385
Epoch: 99 | Iteration number: [410/565] 72% | Training loss: 0.688465218718459
Epoch: 99 | Iteration number: [420/565] 74% | Training loss: 0.6884308741206214
Epoch: 99 | Iteration number: [430/565] 76% | Training loss: 0.6883841647658238
Epoch: 99 | Iteration number: [440/565] 77% | Training loss: 0.6883430699055845
Epoch: 99 | Iteration number: [450/565] 79% | Training loss: 0.6883048257562849
Epoch: 99 | Iteration number: [460/565] 81% | Training loss: 0.6882643905670747
Epoch: 99 | Iteration number: [470/565] 83% | Training loss: 0.6882227624984498
Epoch: 99 | Iteration number: [480/565] 84% | Training loss: 0.6882007186611493
Epoch: 99 | Iteration number: [490/565] 86% | Training loss: 0.6881742023691839
Epoch: 99 | Iteration number: [500/565] 88% | Training loss: 0.6881379501819611
Epoch: 99 | Iteration number: [510/565] 90% | Training loss: 0.688122313747219
Epoch: 99 | Iteration number: [520/565] 92% | Training loss: 0.6880990920158533
Epoch: 99 | Iteration number: [530/565] 93% | Training loss: 0.6880684412875265
Epoch: 99 | Iteration number: [540/565] 95% | Training loss: 0.68804040186935
Epoch: 99 | Iteration number: [550/565] 97% | Training loss: 0.6880125148729844
Epoch: 99 | Iteration number: [560/565] 99% | Training loss: 0.6879983831729207

 End of epoch: 99 | Train Loss: 0.6867732957401107 | Training Time: 89 

 End of epoch: 99 | Eval Loss: 0.6899125150271824 | Evaluating Time: 6 
Epoch: 100 | Iteration number: [10/565] 1% | Training loss: 0.7552725076675415
Epoch: 100 | Iteration number: [20/565] 3% | Training loss: 0.7210509777069092
Epoch: 100 | Iteration number: [30/565] 5% | Training loss: 0.7095683077971141
Epoch: 100 | Iteration number: [40/565] 7% | Training loss: 0.7038406327366828
Epoch: 100 | Iteration number: [50/565] 8% | Training loss: 0.7004156386852265
Epoch: 100 | Iteration number: [60/565] 10% | Training loss: 0.6981337517499924
Epoch: 100 | Iteration number: [70/565] 12% | Training loss: 0.696546242918287
Epoch: 100 | Iteration number: [80/565] 14% | Training loss: 0.6953119218349457
Epoch: 100 | Iteration number: [90/565] 15% | Training loss: 0.6943231191900041
Epoch: 100 | Iteration number: [100/565] 17% | Training loss: 0.6935716509819031
Epoch: 100 | Iteration number: [110/565] 19% | Training loss: 0.6929850128563968
Epoch: 100 | Iteration number: [120/565] 21% | Training loss: 0.6924520989259084
Epoch: 100 | Iteration number: [130/565] 23% | Training loss: 0.6920142792738401
Epoch: 100 | Iteration number: [140/565] 24% | Training loss: 0.6916572860309056
Epoch: 100 | Iteration number: [150/565] 26% | Training loss: 0.6913343743483226
Epoch: 100 | Iteration number: [160/565] 28% | Training loss: 0.6910506702959538
Epoch: 100 | Iteration number: [170/565] 30% | Training loss: 0.6907881964655483
Epoch: 100 | Iteration number: [180/565] 31% | Training loss: 0.6905770619710286
Epoch: 100 | Iteration number: [190/565] 33% | Training loss: 0.6903681340970491
Epoch: 100 | Iteration number: [200/565] 35% | Training loss: 0.6901841214299202
Epoch: 100 | Iteration number: [210/565] 37% | Training loss: 0.6900375141983941
Epoch: 100 | Iteration number: [220/565] 38% | Training loss: 0.6898765775290403
Epoch: 100 | Iteration number: [230/565] 40% | Training loss: 0.6897440811862117
Epoch: 100 | Iteration number: [240/565] 42% | Training loss: 0.6896417200565338
Epoch: 100 | Iteration number: [250/565] 44% | Training loss: 0.6895403254032135
Epoch: 100 | Iteration number: [260/565] 46% | Training loss: 0.6894291857114205
Epoch: 100 | Iteration number: [270/565] 47% | Training loss: 0.6893297915105466
Epoch: 100 | Iteration number: [280/565] 49% | Training loss: 0.6892408886126109
Epoch: 100 | Iteration number: [290/565] 51% | Training loss: 0.6891474479231341
Epoch: 100 | Iteration number: [300/565] 53% | Training loss: 0.6890572692950566
Epoch: 100 | Iteration number: [310/565] 54% | Training loss: 0.6889740611276319
Epoch: 100 | Iteration number: [320/565] 56% | Training loss: 0.688903559744358
Epoch: 100 | Iteration number: [330/565] 58% | Training loss: 0.6888363444443905
Epoch: 100 | Iteration number: [340/565] 60% | Training loss: 0.6887797289034899
Epoch: 100 | Iteration number: [350/565] 61% | Training loss: 0.6887082414967673
Epoch: 100 | Iteration number: [360/565] 63% | Training loss: 0.6886530329783758
Epoch: 100 | Iteration number: [370/565] 65% | Training loss: 0.6886063983311524
Epoch: 100 | Iteration number: [380/565] 67% | Training loss: 0.6885626642327559
Epoch: 100 | Iteration number: [390/565] 69% | Training loss: 0.6885159151676373
Epoch: 100 | Iteration number: [400/565] 70% | Training loss: 0.6884773732721805
Epoch: 100 | Iteration number: [410/565] 72% | Training loss: 0.6884418179349201
Epoch: 100 | Iteration number: [420/565] 74% | Training loss: 0.6883875834090369
Epoch: 100 | Iteration number: [430/565] 76% | Training loss: 0.6883547354576199
Epoch: 100 | Iteration number: [440/565] 77% | Training loss: 0.6883290159431371
Epoch: 100 | Iteration number: [450/565] 79% | Training loss: 0.6882902320226033
Epoch: 100 | Iteration number: [460/565] 81% | Training loss: 0.6882663354925488
Epoch: 100 | Iteration number: [470/565] 83% | Training loss: 0.6882376142004702
Epoch: 100 | Iteration number: [480/565] 84% | Training loss: 0.6882111956675847
Epoch: 100 | Iteration number: [490/565] 86% | Training loss: 0.6881678840335534
Epoch: 100 | Iteration number: [500/565] 88% | Training loss: 0.6881400007009506
Epoch: 100 | Iteration number: [510/565] 90% | Training loss: 0.6881162714724447
Epoch: 100 | Iteration number: [520/565] 92% | Training loss: 0.688090935578713
Epoch: 100 | Iteration number: [530/565] 93% | Training loss: 0.6880598665408368
Epoch: 100 | Iteration number: [540/565] 95% | Training loss: 0.6880396325279166
Epoch: 100 | Iteration number: [550/565] 97% | Training loss: 0.6880127038738945
Epoch: 100 | Iteration number: [560/565] 99% | Training loss: 0.6879860897149358

 End of epoch: 100 | Train Loss: 0.6867542353351559 | Training Time: 89 

 End of epoch: 100 | Eval Loss: 0.6888982227870396 | Evaluating Time: 6 

 End of Test | Dice Loss: 0.9590188946042743 | Binary Cross Entropy With Logits Loss: 0.6878335390772138 
