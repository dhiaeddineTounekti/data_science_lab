Epoch: 1 | Iteration number: [10/565] 1% | Training loss: 0.7693326234817505
Epoch: 1 | Iteration number: [20/565] 3% | Training loss: 0.733909648656845
Epoch: 1 | Iteration number: [30/565] 5% | Training loss: 0.7221069931983948
Epoch: 1 | Iteration number: [40/565] 7% | Training loss: 0.7161739245057106
Epoch: 1 | Iteration number: [50/565] 8% | Training loss: 0.7125869047641754
Epoch: 1 | Iteration number: [60/565] 10% | Training loss: 0.7101775209108988
Epoch: 1 | Iteration number: [70/565] 12% | Training loss: 0.7084541848727635
Epoch: 1 | Iteration number: [80/565] 14% | Training loss: 0.7071135349571704
Epoch: 1 | Iteration number: [90/565] 15% | Training loss: 0.7060720456971062
Epoch: 1 | Iteration number: [100/565] 17% | Training loss: 0.7052470237016678
Epoch: 1 | Iteration number: [110/565] 19% | Training loss: 0.7045637547969819
Epoch: 1 | Iteration number: [120/565] 21% | Training loss: 0.7039715766906738
Epoch: 1 | Iteration number: [130/565] 23% | Training loss: 0.7034766664871803
Epoch: 1 | Iteration number: [140/565] 24% | Training loss: 0.7030586340597698
Epoch: 1 | Iteration number: [150/565] 26% | Training loss: 0.7026663088798523
Epoch: 1 | Iteration number: [160/565] 28% | Training loss: 0.7023183513432741
Epoch: 1 | Iteration number: [170/565] 30% | Training loss: 0.701992844132816
Epoch: 1 | Iteration number: [180/565] 31% | Training loss: 0.7017295377122031
Epoch: 1 | Iteration number: [190/565] 33% | Training loss: 0.7014633975530925
Epoch: 1 | Iteration number: [200/565] 35% | Training loss: 0.7012261241674423
Epoch: 1 | Iteration number: [210/565] 37% | Training loss: 0.7009930849075318
Epoch: 1 | Iteration number: [220/565] 38% | Training loss: 0.700799560546875
Epoch: 1 | Iteration number: [230/565] 40% | Training loss: 0.7006084522475367
Epoch: 1 | Iteration number: [240/565] 42% | Training loss: 0.7004289728899796
Epoch: 1 | Iteration number: [250/565] 44% | Training loss: 0.7002579946517944
Epoch: 1 | Iteration number: [260/565] 46% | Training loss: 0.7001009429876621
Epoch: 1 | Iteration number: [270/565] 47% | Training loss: 0.6999573402934605
Epoch: 1 | Iteration number: [280/565] 49% | Training loss: 0.6998236066528729
Epoch: 1 | Iteration number: [290/565] 51% | Training loss: 0.6996876560408494
Epoch: 1 | Iteration number: [300/565] 53% | Training loss: 0.699561820824941
Epoch: 1 | Iteration number: [310/565] 54% | Training loss: 0.699431203449926
Epoch: 1 | Iteration number: [320/565] 56% | Training loss: 0.6993049167096614
Epoch: 1 | Iteration number: [330/565] 58% | Training loss: 0.6991923928260804
Epoch: 1 | Iteration number: [340/565] 60% | Training loss: 0.6990835652631872
Epoch: 1 | Iteration number: [350/565] 61% | Training loss: 0.6989740691866193
Epoch: 1 | Iteration number: [360/565] 63% | Training loss: 0.6988813843992021
Epoch: 1 | Iteration number: [370/565] 65% | Training loss: 0.6988007511641529
Epoch: 1 | Iteration number: [380/565] 67% | Training loss: 0.6987062468340522
Epoch: 1 | Iteration number: [390/565] 69% | Training loss: 0.6986228987192497
Epoch: 1 | Iteration number: [400/565] 70% | Training loss: 0.6985378888249397
Epoch: 1 | Iteration number: [410/565] 72% | Training loss: 0.6984619589840494
Epoch: 1 | Iteration number: [420/565] 74% | Training loss: 0.6983863552411397
Epoch: 1 | Iteration number: [430/565] 76% | Training loss: 0.6983016831930293
Epoch: 1 | Iteration number: [440/565] 77% | Training loss: 0.6982234407554974
Epoch: 1 | Iteration number: [450/565] 79% | Training loss: 0.6981397726800707
Epoch: 1 | Iteration number: [460/565] 81% | Training loss: 0.6980662396420603
Epoch: 1 | Iteration number: [470/565] 83% | Training loss: 0.697998695551081
Epoch: 1 | Iteration number: [480/565] 84% | Training loss: 0.6979225371032953
Epoch: 1 | Iteration number: [490/565] 86% | Training loss: 0.6978591303436124
Epoch: 1 | Iteration number: [500/565] 88% | Training loss: 0.6977968425750732
Epoch: 1 | Iteration number: [510/565] 90% | Training loss: 0.6977395790464738
Epoch: 1 | Iteration number: [520/565] 92% | Training loss: 0.6976755880392514
Epoch: 1 | Iteration number: [530/565] 93% | Training loss: 0.6976191103458405
Epoch: 1 | Iteration number: [540/565] 95% | Training loss: 0.6975571832171192
Epoch: 1 | Iteration number: [550/565] 97% | Training loss: 0.6974994826316834
Epoch: 1 | Iteration number: [560/565] 99% | Training loss: 0.6974321150353977

 End of epoch: 1 | Train Loss: 0.6961746089226377 | Training Time: 89 

 End of epoch: 1 | Eval Loss: 0.6955353447369167 | Evaluating Time: 6 
Epoch: 2 | Iteration number: [10/565] 1% | Training loss: 0.7634072184562684
Epoch: 2 | Iteration number: [20/565] 3% | Training loss: 0.7289857238531112
Epoch: 2 | Iteration number: [30/565] 5% | Training loss: 0.7173701922098795
Epoch: 2 | Iteration number: [40/565] 7% | Training loss: 0.7115779787302017
Epoch: 2 | Iteration number: [50/565] 8% | Training loss: 0.7081021177768707
Epoch: 2 | Iteration number: [60/565] 10% | Training loss: 0.7057255119085312
Epoch: 2 | Iteration number: [70/565] 12% | Training loss: 0.704027590581349
Epoch: 2 | Iteration number: [80/565] 14% | Training loss: 0.702753521502018
Epoch: 2 | Iteration number: [90/565] 15% | Training loss: 0.7016968627770742
Epoch: 2 | Iteration number: [100/565] 17% | Training loss: 0.7009004992246628
Epoch: 2 | Iteration number: [110/565] 19% | Training loss: 0.7002539304169741
Epoch: 2 | Iteration number: [120/565] 21% | Training loss: 0.6996719881892204
Epoch: 2 | Iteration number: [130/565] 23% | Training loss: 0.699183656160648
Epoch: 2 | Iteration number: [140/565] 24% | Training loss: 0.6987927828516279
Epoch: 2 | Iteration number: [150/565] 26% | Training loss: 0.6984218808015188
Epoch: 2 | Iteration number: [160/565] 28% | Training loss: 0.6981279727071523
Epoch: 2 | Iteration number: [170/565] 30% | Training loss: 0.6978504878633163
Epoch: 2 | Iteration number: [180/565] 31% | Training loss: 0.6975986467467414
Epoch: 2 | Iteration number: [190/565] 33% | Training loss: 0.697388093722494
Epoch: 2 | Iteration number: [200/565] 35% | Training loss: 0.6971803653240204
Epoch: 2 | Iteration number: [210/565] 37% | Training loss: 0.6969972908496856
Epoch: 2 | Iteration number: [220/565] 38% | Training loss: 0.6968249917030335
Epoch: 2 | Iteration number: [230/565] 40% | Training loss: 0.6966860937035602
Epoch: 2 | Iteration number: [240/565] 42% | Training loss: 0.696561428407828
Epoch: 2 | Iteration number: [250/565] 44% | Training loss: 0.6964196302890777
Epoch: 2 | Iteration number: [260/565] 46% | Training loss: 0.6962913611760506
Epoch: 2 | Iteration number: [270/565] 47% | Training loss: 0.6961805330382453
Epoch: 2 | Iteration number: [280/565] 49% | Training loss: 0.6960600299494607
Epoch: 2 | Iteration number: [290/565] 51% | Training loss: 0.6959569986524253
Epoch: 2 | Iteration number: [300/565] 53% | Training loss: 0.6958554623524348
Epoch: 2 | Iteration number: [310/565] 54% | Training loss: 0.6957485512379677
Epoch: 2 | Iteration number: [320/565] 56% | Training loss: 0.6956513622775674
Epoch: 2 | Iteration number: [330/565] 58% | Training loss: 0.6955687362136262
Epoch: 2 | Iteration number: [340/565] 60% | Training loss: 0.6954914457657758
Epoch: 2 | Iteration number: [350/565] 61% | Training loss: 0.6954275219781059
Epoch: 2 | Iteration number: [360/565] 63% | Training loss: 0.6953493919637468
Epoch: 2 | Iteration number: [370/565] 65% | Training loss: 0.6952806224694124
Epoch: 2 | Iteration number: [380/565] 67% | Training loss: 0.6952229757057993
Epoch: 2 | Iteration number: [390/565] 69% | Training loss: 0.6951644736986894
Epoch: 2 | Iteration number: [400/565] 70% | Training loss: 0.6951090840995312
Epoch: 2 | Iteration number: [410/565] 72% | Training loss: 0.6950428036654868
Epoch: 2 | Iteration number: [420/565] 74% | Training loss: 0.6949885899112338
Epoch: 2 | Iteration number: [430/565] 76% | Training loss: 0.694928397134293
Epoch: 2 | Iteration number: [440/565] 77% | Training loss: 0.6948760318485173
Epoch: 2 | Iteration number: [450/565] 79% | Training loss: 0.6948206392923991
Epoch: 2 | Iteration number: [460/565] 81% | Training loss: 0.694766754300698
Epoch: 2 | Iteration number: [470/565] 83% | Training loss: 0.6947131773258778
Epoch: 2 | Iteration number: [480/565] 84% | Training loss: 0.6946671304603418
Epoch: 2 | Iteration number: [490/565] 86% | Training loss: 0.6946147533095612
Epoch: 2 | Iteration number: [500/565] 88% | Training loss: 0.6945669213533402
Epoch: 2 | Iteration number: [510/565] 90% | Training loss: 0.6945173822197259
Epoch: 2 | Iteration number: [520/565] 92% | Training loss: 0.6944734974549367
Epoch: 2 | Iteration number: [530/565] 93% | Training loss: 0.694429553454777
Epoch: 2 | Iteration number: [540/565] 95% | Training loss: 0.6943824430306752
Epoch: 2 | Iteration number: [550/565] 97% | Training loss: 0.6943458440087058
Epoch: 2 | Iteration number: [560/565] 99% | Training loss: 0.6942960964781898

 End of epoch: 2 | Train Loss: 0.6930514320863032 | Training Time: 88 

 End of epoch: 2 | Eval Loss: 0.6943148970603943 | Evaluating Time: 6 
Epoch: 3 | Iteration number: [10/565] 1% | Training loss: 0.7615559756755829
Epoch: 3 | Iteration number: [20/565] 3% | Training loss: 0.7266817927360535
Epoch: 3 | Iteration number: [30/565] 5% | Training loss: 0.7151820739110311
Epoch: 3 | Iteration number: [40/565] 7% | Training loss: 0.7092843532562256
Epoch: 3 | Iteration number: [50/565] 8% | Training loss: 0.7058579182624817
Epoch: 3 | Iteration number: [60/565] 10% | Training loss: 0.7036049485206604
Epoch: 3 | Iteration number: [70/565] 12% | Training loss: 0.7019688997949872
Epoch: 3 | Iteration number: [80/565] 14% | Training loss: 0.7007261335849762
Epoch: 3 | Iteration number: [90/565] 15% | Training loss: 0.6997550540500217
Epoch: 3 | Iteration number: [100/565] 17% | Training loss: 0.6989721995592117
Epoch: 3 | Iteration number: [110/565] 19% | Training loss: 0.6983360713178461
Epoch: 3 | Iteration number: [120/565] 21% | Training loss: 0.697787988682588
Epoch: 3 | Iteration number: [130/565] 23% | Training loss: 0.697319221496582
Epoch: 3 | Iteration number: [140/565] 24% | Training loss: 0.6969296659742082
Epoch: 3 | Iteration number: [150/565] 26% | Training loss: 0.6965677245457967
Epoch: 3 | Iteration number: [160/565] 28% | Training loss: 0.6962720528244972
Epoch: 3 | Iteration number: [170/565] 30% | Training loss: 0.6960026712978588
Epoch: 3 | Iteration number: [180/565] 31% | Training loss: 0.6957476745049159
Epoch: 3 | Iteration number: [190/565] 33% | Training loss: 0.6955330058148033
Epoch: 3 | Iteration number: [200/565] 35% | Training loss: 0.6953380817174911
Epoch: 3 | Iteration number: [210/565] 37% | Training loss: 0.6951462081500462
Epoch: 3 | Iteration number: [220/565] 38% | Training loss: 0.6949763918464834
Epoch: 3 | Iteration number: [230/565] 40% | Training loss: 0.6948170319847439
Epoch: 3 | Iteration number: [240/565] 42% | Training loss: 0.6946874293188254
Epoch: 3 | Iteration number: [250/565] 44% | Training loss: 0.6945582704544068
Epoch: 3 | Iteration number: [260/565] 46% | Training loss: 0.6944355049958596
Epoch: 3 | Iteration number: [270/565] 47% | Training loss: 0.6943334237292961
Epoch: 3 | Iteration number: [280/565] 49% | Training loss: 0.694239370737757
Epoch: 3 | Iteration number: [290/565] 51% | Training loss: 0.6941216386597732
Epoch: 3 | Iteration number: [300/565] 53% | Training loss: 0.694023810227712
Epoch: 3 | Iteration number: [310/565] 54% | Training loss: 0.6939289737132288
Epoch: 3 | Iteration number: [320/565] 56% | Training loss: 0.6938529863953591
Epoch: 3 | Iteration number: [330/565] 58% | Training loss: 0.6937502266782702
Epoch: 3 | Iteration number: [340/565] 60% | Training loss: 0.6936784595251083
Epoch: 3 | Iteration number: [350/565] 61% | Training loss: 0.6936189830303192
Epoch: 3 | Iteration number: [360/565] 63% | Training loss: 0.69355618291431
Epoch: 3 | Iteration number: [370/565] 65% | Training loss: 0.6934906814549421
Epoch: 3 | Iteration number: [380/565] 67% | Training loss: 0.6934329065837358
Epoch: 3 | Iteration number: [390/565] 69% | Training loss: 0.6933765776646443
Epoch: 3 | Iteration number: [400/565] 70% | Training loss: 0.6933245608210563
Epoch: 3 | Iteration number: [410/565] 72% | Training loss: 0.6932727857333858
Epoch: 3 | Iteration number: [420/565] 74% | Training loss: 0.6932207418339593
Epoch: 3 | Iteration number: [430/565] 76% | Training loss: 0.6931712595529335
Epoch: 3 | Iteration number: [440/565] 77% | Training loss: 0.693126445602287
Epoch: 3 | Iteration number: [450/565] 79% | Training loss: 0.6930876843134562
Epoch: 3 | Iteration number: [460/565] 81% | Training loss: 0.6930343226246212
Epoch: 3 | Iteration number: [470/565] 83% | Training loss: 0.6929953518066
Epoch: 3 | Iteration number: [480/565] 84% | Training loss: 0.6929551718135675
Epoch: 3 | Iteration number: [490/565] 86% | Training loss: 0.6929132279084653
Epoch: 3 | Iteration number: [500/565] 88% | Training loss: 0.6928659464120865
Epoch: 3 | Iteration number: [510/565] 90% | Training loss: 0.6928270254649368
Epoch: 3 | Iteration number: [520/565] 92% | Training loss: 0.6927829440969687
Epoch: 3 | Iteration number: [530/565] 93% | Training loss: 0.6927519569981773
Epoch: 3 | Iteration number: [540/565] 95% | Training loss: 0.6927141535061377
Epoch: 3 | Iteration number: [550/565] 97% | Training loss: 0.6926733469963073
Epoch: 3 | Iteration number: [560/565] 99% | Training loss: 0.6926365197769233

 End of epoch: 3 | Train Loss: 0.691396977310687 | Training Time: 90 

 End of epoch: 3 | Eval Loss: 0.6932859931673322 | Evaluating Time: 6 
Epoch: 4 | Iteration number: [10/565] 1% | Training loss: 0.7596627950668335
Epoch: 4 | Iteration number: [20/565] 3% | Training loss: 0.7250684082508088
Epoch: 4 | Iteration number: [30/565] 5% | Training loss: 0.7135124623775482
Epoch: 4 | Iteration number: [40/565] 7% | Training loss: 0.7078430935740471
Epoch: 4 | Iteration number: [50/565] 8% | Training loss: 0.7044403243064881
Epoch: 4 | Iteration number: [60/565] 10% | Training loss: 0.7020829409360886
Epoch: 4 | Iteration number: [70/565] 12% | Training loss: 0.7004428122724805
Epoch: 4 | Iteration number: [80/565] 14% | Training loss: 0.6991183690726757
Epoch: 4 | Iteration number: [90/565] 15% | Training loss: 0.6981943004661136
Epoch: 4 | Iteration number: [100/565] 17% | Training loss: 0.6974375694990158
Epoch: 4 | Iteration number: [110/565] 19% | Training loss: 0.6968065955422141
Epoch: 4 | Iteration number: [120/565] 21% | Training loss: 0.6962974439064662
Epoch: 4 | Iteration number: [130/565] 23% | Training loss: 0.6958715869830205
Epoch: 4 | Iteration number: [140/565] 24% | Training loss: 0.6955032101699284
Epoch: 4 | Iteration number: [150/565] 26% | Training loss: 0.6951478846867879
Epoch: 4 | Iteration number: [160/565] 28% | Training loss: 0.6948411479592324
Epoch: 4 | Iteration number: [170/565] 30% | Training loss: 0.6945792671512155
Epoch: 4 | Iteration number: [180/565] 31% | Training loss: 0.694353355301751
Epoch: 4 | Iteration number: [190/565] 33% | Training loss: 0.6941486173554471
Epoch: 4 | Iteration number: [200/565] 35% | Training loss: 0.6939559903740883
Epoch: 4 | Iteration number: [210/565] 37% | Training loss: 0.6937909361862001
Epoch: 4 | Iteration number: [220/565] 38% | Training loss: 0.6936249434947968
Epoch: 4 | Iteration number: [230/565] 40% | Training loss: 0.6934689112331556
Epoch: 4 | Iteration number: [240/565] 42% | Training loss: 0.6933244576056798
Epoch: 4 | Iteration number: [250/565] 44% | Training loss: 0.6932044398784637
Epoch: 4 | Iteration number: [260/565] 46% | Training loss: 0.6931160039626635
Epoch: 4 | Iteration number: [270/565] 47% | Training loss: 0.6930280753859768
Epoch: 4 | Iteration number: [280/565] 49% | Training loss: 0.6929343061787742
Epoch: 4 | Iteration number: [290/565] 51% | Training loss: 0.6928406770887046
Epoch: 4 | Iteration number: [300/565] 53% | Training loss: 0.6927594296137491
Epoch: 4 | Iteration number: [310/565] 54% | Training loss: 0.6926856385123346
Epoch: 4 | Iteration number: [320/565] 56% | Training loss: 0.6926075149327516
Epoch: 4 | Iteration number: [330/565] 58% | Training loss: 0.6925358790339846
Epoch: 4 | Iteration number: [340/565] 60% | Training loss: 0.6924827838645262
Epoch: 4 | Iteration number: [350/565] 61% | Training loss: 0.6924121572290148
Epoch: 4 | Iteration number: [360/565] 63% | Training loss: 0.6923422768712044
Epoch: 4 | Iteration number: [370/565] 65% | Training loss: 0.6922826617150694
Epoch: 4 | Iteration number: [380/565] 67% | Training loss: 0.6922195707496844
Epoch: 4 | Iteration number: [390/565] 69% | Training loss: 0.6921509003027891
Epoch: 4 | Iteration number: [400/565] 70% | Training loss: 0.6920980602502823
Epoch: 4 | Iteration number: [410/565] 72% | Training loss: 0.6920548460832456
Epoch: 4 | Iteration number: [420/565] 74% | Training loss: 0.6920102305355527
Epoch: 4 | Iteration number: [430/565] 76% | Training loss: 0.6919644088246102
Epoch: 4 | Iteration number: [440/565] 77% | Training loss: 0.6919156418605285
Epoch: 4 | Iteration number: [450/565] 79% | Training loss: 0.6918660583761004
Epoch: 4 | Iteration number: [460/565] 81% | Training loss: 0.6918301571970401
Epoch: 4 | Iteration number: [470/565] 83% | Training loss: 0.6917952214149719
Epoch: 4 | Iteration number: [480/565] 84% | Training loss: 0.691761656353871
Epoch: 4 | Iteration number: [490/565] 86% | Training loss: 0.6917243750727906
Epoch: 4 | Iteration number: [500/565] 88% | Training loss: 0.6916955544948578
Epoch: 4 | Iteration number: [510/565] 90% | Training loss: 0.6916586252988554
Epoch: 4 | Iteration number: [520/565] 92% | Training loss: 0.6916321338369296
Epoch: 4 | Iteration number: [530/565] 93% | Training loss: 0.6916062764401706
Epoch: 4 | Iteration number: [540/565] 95% | Training loss: 0.6915728835044084
Epoch: 4 | Iteration number: [550/565] 97% | Training loss: 0.6915440894256939
Epoch: 4 | Iteration number: [560/565] 99% | Training loss: 0.6915146015584469

 End of epoch: 4 | Train Loss: 0.6902825454695035 | Training Time: 89 

 End of epoch: 4 | Eval Loss: 0.6917750324521746 | Evaluating Time: 6 
Epoch: 5 | Iteration number: [10/565] 1% | Training loss: 0.7584280014038086
Epoch: 5 | Iteration number: [20/565] 3% | Training loss: 0.7241806805133819
Epoch: 5 | Iteration number: [30/565] 5% | Training loss: 0.7127426524957021
Epoch: 5 | Iteration number: [40/565] 7% | Training loss: 0.7069974288344383
Epoch: 5 | Iteration number: [50/565] 8% | Training loss: 0.7035664427280426
Epoch: 5 | Iteration number: [60/565] 10% | Training loss: 0.70121990442276
Epoch: 5 | Iteration number: [70/565] 12% | Training loss: 0.69960549558912
Epoch: 5 | Iteration number: [80/565] 14% | Training loss: 0.6983605615794659
Epoch: 5 | Iteration number: [90/565] 15% | Training loss: 0.6973981387085385
Epoch: 5 | Iteration number: [100/565] 17% | Training loss: 0.6966223436594009
Epoch: 5 | Iteration number: [110/565] 19% | Training loss: 0.6959531318057667
Epoch: 5 | Iteration number: [120/565] 21% | Training loss: 0.6954564919074376
Epoch: 5 | Iteration number: [130/565] 23% | Training loss: 0.6950163162671603
Epoch: 5 | Iteration number: [140/565] 24% | Training loss: 0.69463609457016
Epoch: 5 | Iteration number: [150/565] 26% | Training loss: 0.6943040704727172
Epoch: 5 | Iteration number: [160/565] 28% | Training loss: 0.6939899180084467
Epoch: 5 | Iteration number: [170/565] 30% | Training loss: 0.6937219956341911
Epoch: 5 | Iteration number: [180/565] 31% | Training loss: 0.6934959686464733
Epoch: 5 | Iteration number: [190/565] 33% | Training loss: 0.6932979702949524
Epoch: 5 | Iteration number: [200/565] 35% | Training loss: 0.6931136459112167
Epoch: 5 | Iteration number: [210/565] 37% | Training loss: 0.6929425855477651
Epoch: 5 | Iteration number: [220/565] 38% | Training loss: 0.6927967483347113
Epoch: 5 | Iteration number: [230/565] 40% | Training loss: 0.6926725794439731
Epoch: 5 | Iteration number: [240/565] 42% | Training loss: 0.6925373524427414
Epoch: 5 | Iteration number: [250/565] 44% | Training loss: 0.6924084813594819
Epoch: 5 | Iteration number: [260/565] 46% | Training loss: 0.6922800914599345
Epoch: 5 | Iteration number: [270/565] 47% | Training loss: 0.6921686885533509
Epoch: 5 | Iteration number: [280/565] 49% | Training loss: 0.6920551412871906
Epoch: 5 | Iteration number: [290/565] 51% | Training loss: 0.6919580005366227
Epoch: 5 | Iteration number: [300/565] 53% | Training loss: 0.6918678967158
Epoch: 5 | Iteration number: [310/565] 54% | Training loss: 0.6918058983741268
Epoch: 5 | Iteration number: [320/565] 56% | Training loss: 0.6917301751673222
Epoch: 5 | Iteration number: [330/565] 58% | Training loss: 0.6916646856250185
Epoch: 5 | Iteration number: [340/565] 60% | Training loss: 0.691608078865444
Epoch: 5 | Iteration number: [350/565] 61% | Training loss: 0.6915430891513824
Epoch: 5 | Iteration number: [360/565] 63% | Training loss: 0.6914885401725769
Epoch: 5 | Iteration number: [370/565] 65% | Training loss: 0.6914333486879194
Epoch: 5 | Iteration number: [380/565] 67% | Training loss: 0.691376224473903
Epoch: 5 | Iteration number: [390/565] 69% | Training loss: 0.6913237104049096
Epoch: 5 | Iteration number: [400/565] 70% | Training loss: 0.6912750713527203
Epoch: 5 | Iteration number: [410/565] 72% | Training loss: 0.6912156469938232
Epoch: 5 | Iteration number: [420/565] 74% | Training loss: 0.6911753802072435
Epoch: 5 | Iteration number: [430/565] 76% | Training loss: 0.6911409857661225
Epoch: 5 | Iteration number: [440/565] 77% | Training loss: 0.6910911713134159
Epoch: 5 | Iteration number: [450/565] 79% | Training loss: 0.6910504058996836
Epoch: 5 | Iteration number: [460/565] 81% | Training loss: 0.6910129081943761
Epoch: 5 | Iteration number: [470/565] 83% | Training loss: 0.6909817653767606
Epoch: 5 | Iteration number: [480/565] 84% | Training loss: 0.6909498270601034
Epoch: 5 | Iteration number: [490/565] 86% | Training loss: 0.6909142134140949
Epoch: 5 | Iteration number: [500/565] 88% | Training loss: 0.690879760146141
Epoch: 5 | Iteration number: [510/565] 90% | Training loss: 0.6908481920466704
Epoch: 5 | Iteration number: [520/565] 92% | Training loss: 0.6908164455340459
Epoch: 5 | Iteration number: [530/565] 93% | Training loss: 0.6907792595197569
Epoch: 5 | Iteration number: [540/565] 95% | Training loss: 0.6907466332117717
Epoch: 5 | Iteration number: [550/565] 97% | Training loss: 0.6907278354601426
Epoch: 5 | Iteration number: [560/565] 99% | Training loss: 0.6906955118690218

 End of epoch: 5 | Train Loss: 0.6894615752507101 | Training Time: 90 

 End of epoch: 5 | Eval Loss: 0.6917142357145037 | Evaluating Time: 6 
Epoch: 6 | Iteration number: [10/565] 1% | Training loss: 0.7584805130958557
Epoch: 6 | Iteration number: [20/565] 3% | Training loss: 0.7237342298030853
Epoch: 6 | Iteration number: [30/565] 5% | Training loss: 0.7121479868888855
Epoch: 6 | Iteration number: [40/565] 7% | Training loss: 0.7064061403274536
Epoch: 6 | Iteration number: [50/565] 8% | Training loss: 0.7029400408267975
Epoch: 6 | Iteration number: [60/565] 10% | Training loss: 0.7005564481019974
Epoch: 6 | Iteration number: [70/565] 12% | Training loss: 0.6988787617002215
Epoch: 6 | Iteration number: [80/565] 14% | Training loss: 0.6976806774735451
Epoch: 6 | Iteration number: [90/565] 15% | Training loss: 0.6967570622762044
Epoch: 6 | Iteration number: [100/565] 17% | Training loss: 0.6960460245609283
Epoch: 6 | Iteration number: [110/565] 19% | Training loss: 0.69539979967204
Epoch: 6 | Iteration number: [120/565] 21% | Training loss: 0.6948975205421448
Epoch: 6 | Iteration number: [130/565] 23% | Training loss: 0.6944728484520546
Epoch: 6 | Iteration number: [140/565] 24% | Training loss: 0.6940708658524922
Epoch: 6 | Iteration number: [150/565] 26% | Training loss: 0.6937195146083832
Epoch: 6 | Iteration number: [160/565] 28% | Training loss: 0.6934642214328051
Epoch: 6 | Iteration number: [170/565] 30% | Training loss: 0.6932085443945492
Epoch: 6 | Iteration number: [180/565] 31% | Training loss: 0.6929652008745405
Epoch: 6 | Iteration number: [190/565] 33% | Training loss: 0.6927507441294821
Epoch: 6 | Iteration number: [200/565] 35% | Training loss: 0.6925542873144149
Epoch: 6 | Iteration number: [210/565] 37% | Training loss: 0.6923977372192202
Epoch: 6 | Iteration number: [220/565] 38% | Training loss: 0.6922332273288206
Epoch: 6 | Iteration number: [230/565] 40% | Training loss: 0.6920849447665007
Epoch: 6 | Iteration number: [240/565] 42% | Training loss: 0.6919412096341451
Epoch: 6 | Iteration number: [250/565] 44% | Training loss: 0.6918072969913482
Epoch: 6 | Iteration number: [260/565] 46% | Training loss: 0.6916843870511422
Epoch: 6 | Iteration number: [270/565] 47% | Training loss: 0.6915822488290292
Epoch: 6 | Iteration number: [280/565] 49% | Training loss: 0.6915040284395217
Epoch: 6 | Iteration number: [290/565] 51% | Training loss: 0.6914184886833717
Epoch: 6 | Iteration number: [300/565] 53% | Training loss: 0.6913242216904958
Epoch: 6 | Iteration number: [310/565] 54% | Training loss: 0.6912449692526171
Epoch: 6 | Iteration number: [320/565] 56% | Training loss: 0.6911590285599232
Epoch: 6 | Iteration number: [330/565] 58% | Training loss: 0.6911049562873263
Epoch: 6 | Iteration number: [340/565] 60% | Training loss: 0.6910500764846802
Epoch: 6 | Iteration number: [350/565] 61% | Training loss: 0.6909981441497802
Epoch: 6 | Iteration number: [360/565] 63% | Training loss: 0.6909330873025789
Epoch: 6 | Iteration number: [370/565] 65% | Training loss: 0.6908782633575233
Epoch: 6 | Iteration number: [380/565] 67% | Training loss: 0.6908122484621249
Epoch: 6 | Iteration number: [390/565] 69% | Training loss: 0.6907639809143848
Epoch: 6 | Iteration number: [400/565] 70% | Training loss: 0.6906998111307621
Epoch: 6 | Iteration number: [410/565] 72% | Training loss: 0.690654659852749
Epoch: 6 | Iteration number: [420/565] 74% | Training loss: 0.6906223275831768
Epoch: 6 | Iteration number: [430/565] 76% | Training loss: 0.690587986901749
Epoch: 6 | Iteration number: [440/565] 77% | Training loss: 0.6905305140397765
Epoch: 6 | Iteration number: [450/565] 79% | Training loss: 0.6904987802770403
Epoch: 6 | Iteration number: [460/565] 81% | Training loss: 0.6904559680949087
Epoch: 6 | Iteration number: [470/565] 83% | Training loss: 0.6904068306405493
Epoch: 6 | Iteration number: [480/565] 84% | Training loss: 0.6903840848555167
Epoch: 6 | Iteration number: [490/565] 86% | Training loss: 0.6903438102225868
Epoch: 6 | Iteration number: [500/565] 88% | Training loss: 0.6903049218654632
Epoch: 6 | Iteration number: [510/565] 90% | Training loss: 0.6902758743248734
Epoch: 6 | Iteration number: [520/565] 92% | Training loss: 0.6902436023721328
Epoch: 6 | Iteration number: [530/565] 93% | Training loss: 0.6902084483290618
Epoch: 6 | Iteration number: [540/565] 95% | Training loss: 0.6901751385794745
Epoch: 6 | Iteration number: [550/565] 97% | Training loss: 0.6901518788120964
Epoch: 6 | Iteration number: [560/565] 99% | Training loss: 0.690130484529904

 End of epoch: 6 | Train Loss: 0.6888936745381988 | Training Time: 88 

 End of epoch: 6 | Eval Loss: 0.6910419634410313 | Evaluating Time: 6 
Epoch: 7 | Iteration number: [10/565] 1% | Training loss: 0.757778424024582
Epoch: 7 | Iteration number: [20/565] 3% | Training loss: 0.7232165694236755
Epoch: 7 | Iteration number: [30/565] 5% | Training loss: 0.711682140827179
Epoch: 7 | Iteration number: [40/565] 7% | Training loss: 0.7058981999754905
Epoch: 7 | Iteration number: [50/565] 8% | Training loss: 0.7024018704891205
Epoch: 7 | Iteration number: [60/565] 10% | Training loss: 0.7000619461139043
Epoch: 7 | Iteration number: [70/565] 12% | Training loss: 0.698401790857315
Epoch: 7 | Iteration number: [80/565] 14% | Training loss: 0.697123008966446
Epoch: 7 | Iteration number: [90/565] 15% | Training loss: 0.6961775951915317
Epoch: 7 | Iteration number: [100/565] 17% | Training loss: 0.6953927737474441
Epoch: 7 | Iteration number: [110/565] 19% | Training loss: 0.6947682911699469
Epoch: 7 | Iteration number: [120/565] 21% | Training loss: 0.6942332689960797
Epoch: 7 | Iteration number: [130/565] 23% | Training loss: 0.6938031467107626
Epoch: 7 | Iteration number: [140/565] 24% | Training loss: 0.6934442737272808
Epoch: 7 | Iteration number: [150/565] 26% | Training loss: 0.6931440552075704
Epoch: 7 | Iteration number: [160/565] 28% | Training loss: 0.6928617928177119
Epoch: 7 | Iteration number: [170/565] 30% | Training loss: 0.6926221966743469
Epoch: 7 | Iteration number: [180/565] 31% | Training loss: 0.6923996465073692
Epoch: 7 | Iteration number: [190/565] 33% | Training loss: 0.6922093909037741
Epoch: 7 | Iteration number: [200/565] 35% | Training loss: 0.6920304450392724
Epoch: 7 | Iteration number: [210/565] 37% | Training loss: 0.6918555974960328
Epoch: 7 | Iteration number: [220/565] 38% | Training loss: 0.6917160421609878
Epoch: 7 | Iteration number: [230/565] 40% | Training loss: 0.6915704939676368
Epoch: 7 | Iteration number: [240/565] 42% | Training loss: 0.6914456357558568
Epoch: 7 | Iteration number: [250/565] 44% | Training loss: 0.6913378286361694
Epoch: 7 | Iteration number: [260/565] 46% | Training loss: 0.6912190173680965
Epoch: 7 | Iteration number: [270/565] 47% | Training loss: 0.6911208859196416
Epoch: 7 | Iteration number: [280/565] 49% | Training loss: 0.6910167804786137
Epoch: 7 | Iteration number: [290/565] 51% | Training loss: 0.6909323690266445
Epoch: 7 | Iteration number: [300/565] 53% | Training loss: 0.6908551698923111
Epoch: 7 | Iteration number: [310/565] 54% | Training loss: 0.6907774650281475
Epoch: 7 | Iteration number: [320/565] 56% | Training loss: 0.6907011656090617
Epoch: 7 | Iteration number: [330/565] 58% | Training loss: 0.6906373083591462
Epoch: 7 | Iteration number: [340/565] 60% | Training loss: 0.6905778898912318
Epoch: 7 | Iteration number: [350/565] 61% | Training loss: 0.690522038766316
Epoch: 7 | Iteration number: [360/565] 63% | Training loss: 0.6904688401354684
Epoch: 7 | Iteration number: [370/565] 65% | Training loss: 0.6904063548590685
Epoch: 7 | Iteration number: [380/565] 67% | Training loss: 0.6903483869213807
Epoch: 7 | Iteration number: [390/565] 69% | Training loss: 0.6903048036954342
Epoch: 7 | Iteration number: [400/565] 70% | Training loss: 0.6902586260437965
Epoch: 7 | Iteration number: [410/565] 72% | Training loss: 0.6902186947624858
Epoch: 7 | Iteration number: [420/565] 74% | Training loss: 0.6901644728013447
Epoch: 7 | Iteration number: [430/565] 76% | Training loss: 0.6901255972163621
Epoch: 7 | Iteration number: [440/565] 77% | Training loss: 0.6900751348246228
Epoch: 7 | Iteration number: [450/565] 79% | Training loss: 0.6900331862767537
Epoch: 7 | Iteration number: [460/565] 81% | Training loss: 0.6899852790262389
Epoch: 7 | Iteration number: [470/565] 83% | Training loss: 0.6899482191877162
Epoch: 7 | Iteration number: [480/565] 84% | Training loss: 0.6899178826560577
Epoch: 7 | Iteration number: [490/565] 86% | Training loss: 0.6898930120224855
Epoch: 7 | Iteration number: [500/565] 88% | Training loss: 0.689856565952301
Epoch: 7 | Iteration number: [510/565] 90% | Training loss: 0.6898298487943761
Epoch: 7 | Iteration number: [520/565] 92% | Training loss: 0.6898005795020323
Epoch: 7 | Iteration number: [530/565] 93% | Training loss: 0.6897742099357101
Epoch: 7 | Iteration number: [540/565] 95% | Training loss: 0.6897462796281886
Epoch: 7 | Iteration number: [550/565] 97% | Training loss: 0.6897171019424092
Epoch: 7 | Iteration number: [560/565] 99% | Training loss: 0.6896893691803728

 End of epoch: 7 | Train Loss: 0.6884613890563492 | Training Time: 89 

 End of epoch: 7 | Eval Loss: 0.6910760998725891 | Evaluating Time: 5 
Epoch: 8 | Iteration number: [10/565] 1% | Training loss: 0.7567664623260498
Epoch: 8 | Iteration number: [20/565] 3% | Training loss: 0.7225030362606049
Epoch: 8 | Iteration number: [30/565] 5% | Training loss: 0.7110982278982798
Epoch: 8 | Iteration number: [40/565] 7% | Training loss: 0.7054286912083626
Epoch: 8 | Iteration number: [50/565] 8% | Training loss: 0.7019482588768006
Epoch: 8 | Iteration number: [60/565] 10% | Training loss: 0.699664514263471
Epoch: 8 | Iteration number: [70/565] 12% | Training loss: 0.6980387491839273
Epoch: 8 | Iteration number: [80/565] 14% | Training loss: 0.6968484297394753
Epoch: 8 | Iteration number: [90/565] 15% | Training loss: 0.6958859450287289
Epoch: 8 | Iteration number: [100/565] 17% | Training loss: 0.6951230931282043
Epoch: 8 | Iteration number: [110/565] 19% | Training loss: 0.6944686542857778
Epoch: 8 | Iteration number: [120/565] 21% | Training loss: 0.6939103792111079
Epoch: 8 | Iteration number: [130/565] 23% | Training loss: 0.6934370320576888
Epoch: 8 | Iteration number: [140/565] 24% | Training loss: 0.6930722781590053
Epoch: 8 | Iteration number: [150/565] 26% | Training loss: 0.6927464020252228
Epoch: 8 | Iteration number: [160/565] 28% | Training loss: 0.6924744963645935
Epoch: 8 | Iteration number: [170/565] 30% | Training loss: 0.6922293838332682
Epoch: 8 | Iteration number: [180/565] 31% | Training loss: 0.6919962730672624
Epoch: 8 | Iteration number: [190/565] 33% | Training loss: 0.6918016872907939
Epoch: 8 | Iteration number: [200/565] 35% | Training loss: 0.6916266924142838
Epoch: 8 | Iteration number: [210/565] 37% | Training loss: 0.691465509505499
Epoch: 8 | Iteration number: [220/565] 38% | Training loss: 0.6913118254054677
Epoch: 8 | Iteration number: [230/565] 40% | Training loss: 0.6911528338556704
Epoch: 8 | Iteration number: [240/565] 42% | Training loss: 0.6910278551280499
Epoch: 8 | Iteration number: [250/565] 44% | Training loss: 0.6908982043266296
Epoch: 8 | Iteration number: [260/565] 46% | Training loss: 0.6908038494678644
Epoch: 8 | Iteration number: [270/565] 47% | Training loss: 0.6907054320529655
Epoch: 8 | Iteration number: [280/565] 49% | Training loss: 0.6906216421297618
Epoch: 8 | Iteration number: [290/565] 51% | Training loss: 0.690535149081
Epoch: 8 | Iteration number: [300/565] 53% | Training loss: 0.6904552348454793
Epoch: 8 | Iteration number: [310/565] 54% | Training loss: 0.6903864191424463
Epoch: 8 | Iteration number: [320/565] 56% | Training loss: 0.6903100112453103
Epoch: 8 | Iteration number: [330/565] 58% | Training loss: 0.690235442645622
Epoch: 8 | Iteration number: [340/565] 60% | Training loss: 0.6901555447017446
Epoch: 8 | Iteration number: [350/565] 61% | Training loss: 0.6900986361503602
Epoch: 8 | Iteration number: [360/565] 63% | Training loss: 0.6900450252824359
Epoch: 8 | Iteration number: [370/565] 65% | Training loss: 0.6900012425474218
Epoch: 8 | Iteration number: [380/565] 67% | Training loss: 0.6899434174361981
Epoch: 8 | Iteration number: [390/565] 69% | Training loss: 0.6898980695467729
Epoch: 8 | Iteration number: [400/565] 70% | Training loss: 0.6898536571860313
Epoch: 8 | Iteration number: [410/565] 72% | Training loss: 0.6898146328402729
Epoch: 8 | Iteration number: [420/565] 74% | Training loss: 0.6897695253292719
Epoch: 8 | Iteration number: [430/565] 76% | Training loss: 0.6897249938443649
Epoch: 8 | Iteration number: [440/565] 77% | Training loss: 0.6896900191903115
Epoch: 8 | Iteration number: [450/565] 79% | Training loss: 0.6896463794178432
Epoch: 8 | Iteration number: [460/565] 81% | Training loss: 0.6896114230155945
Epoch: 8 | Iteration number: [470/565] 83% | Training loss: 0.6895736450844623
Epoch: 8 | Iteration number: [480/565] 84% | Training loss: 0.6895502905050913
Epoch: 8 | Iteration number: [490/565] 86% | Training loss: 0.6895253801832394
Epoch: 8 | Iteration number: [500/565] 88% | Training loss: 0.6894986869096756
Epoch: 8 | Iteration number: [510/565] 90% | Training loss: 0.6894683642714632
Epoch: 8 | Iteration number: [520/565] 92% | Training loss: 0.6894381551788403
Epoch: 8 | Iteration number: [530/565] 93% | Training loss: 0.6894112771412112
Epoch: 8 | Iteration number: [540/565] 95% | Training loss: 0.6893829332457648
Epoch: 8 | Iteration number: [550/565] 97% | Training loss: 0.6893626050515609
Epoch: 8 | Iteration number: [560/565] 99% | Training loss: 0.6893380552530288

 End of epoch: 8 | Train Loss: 0.688105139479173 | Training Time: 89 

 End of epoch: 8 | Eval Loss: 0.6899648989949908 | Evaluating Time: 6 
Epoch: 9 | Iteration number: [10/565] 1% | Training loss: 0.7564484000205993
Epoch: 9 | Iteration number: [20/565] 3% | Training loss: 0.7220542371273041
Epoch: 9 | Iteration number: [30/565] 5% | Training loss: 0.7107505619525909
Epoch: 9 | Iteration number: [40/565] 7% | Training loss: 0.7049754723906517
Epoch: 9 | Iteration number: [50/565] 8% | Training loss: 0.7015845751762391
Epoch: 9 | Iteration number: [60/565] 10% | Training loss: 0.6992587606112163
Epoch: 9 | Iteration number: [70/565] 12% | Training loss: 0.6976546074662889
Epoch: 9 | Iteration number: [80/565] 14% | Training loss: 0.6964856773614884
Epoch: 9 | Iteration number: [90/565] 15% | Training loss: 0.6955140352249145
Epoch: 9 | Iteration number: [100/565] 17% | Training loss: 0.6947736942768097
Epoch: 9 | Iteration number: [110/565] 19% | Training loss: 0.6941212735392831
Epoch: 9 | Iteration number: [120/565] 21% | Training loss: 0.6936116243402163
Epoch: 9 | Iteration number: [130/565] 23% | Training loss: 0.6931675828420198
Epoch: 9 | Iteration number: [140/565] 24% | Training loss: 0.6927748262882233
Epoch: 9 | Iteration number: [150/565] 26% | Training loss: 0.6924546333154042
Epoch: 9 | Iteration number: [160/565] 28% | Training loss: 0.6921636275947094
Epoch: 9 | Iteration number: [170/565] 30% | Training loss: 0.6919284087770126
Epoch: 9 | Iteration number: [180/565] 31% | Training loss: 0.6917183329661687
Epoch: 9 | Iteration number: [190/565] 33% | Training loss: 0.6915328192083459
Epoch: 9 | Iteration number: [200/565] 35% | Training loss: 0.6913311964273453
Epoch: 9 | Iteration number: [210/565] 37% | Training loss: 0.6911789317925771
Epoch: 9 | Iteration number: [220/565] 38% | Training loss: 0.6910517993298444
Epoch: 9 | Iteration number: [230/565] 40% | Training loss: 0.6909334423749344
Epoch: 9 | Iteration number: [240/565] 42% | Training loss: 0.6908099077641964
Epoch: 9 | Iteration number: [250/565] 44% | Training loss: 0.690689614534378
Epoch: 9 | Iteration number: [260/565] 46% | Training loss: 0.6905749541062575
Epoch: 9 | Iteration number: [270/565] 47% | Training loss: 0.6904977041262167
Epoch: 9 | Iteration number: [280/565] 49% | Training loss: 0.6904098868370057
Epoch: 9 | Iteration number: [290/565] 51% | Training loss: 0.6903213624296517
Epoch: 9 | Iteration number: [300/565] 53% | Training loss: 0.6902494907379151
Epoch: 9 | Iteration number: [310/565] 54% | Training loss: 0.6901853701760692
Epoch: 9 | Iteration number: [320/565] 56% | Training loss: 0.6901079323142767
Epoch: 9 | Iteration number: [330/565] 58% | Training loss: 0.6900406458161094
Epoch: 9 | Iteration number: [340/565] 60% | Training loss: 0.6899737607030307
Epoch: 9 | Iteration number: [350/565] 61% | Training loss: 0.6899097640173776
Epoch: 9 | Iteration number: [360/565] 63% | Training loss: 0.6898551649517484
Epoch: 9 | Iteration number: [370/565] 65% | Training loss: 0.6897976422632063
Epoch: 9 | Iteration number: [380/565] 67% | Training loss: 0.6897415703848788
Epoch: 9 | Iteration number: [390/565] 69% | Training loss: 0.6896848620512547
Epoch: 9 | Iteration number: [400/565] 70% | Training loss: 0.6896410851180553
Epoch: 9 | Iteration number: [410/565] 72% | Training loss: 0.6896002205406747
Epoch: 9 | Iteration number: [420/565] 74% | Training loss: 0.6895616693156106
Epoch: 9 | Iteration number: [430/565] 76% | Training loss: 0.6895213437634845
Epoch: 9 | Iteration number: [440/565] 77% | Training loss: 0.689487268843434
Epoch: 9 | Iteration number: [450/565] 79% | Training loss: 0.6894536125659942
Epoch: 9 | Iteration number: [460/565] 81% | Training loss: 0.6894130936135416
Epoch: 9 | Iteration number: [470/565] 83% | Training loss: 0.6893829557489841
Epoch: 9 | Iteration number: [480/565] 84% | Training loss: 0.6893568487217029
Epoch: 9 | Iteration number: [490/565] 86% | Training loss: 0.6893311914132566
Epoch: 9 | Iteration number: [500/565] 88% | Training loss: 0.689292433977127
Epoch: 9 | Iteration number: [510/565] 90% | Training loss: 0.6892597956984651
Epoch: 9 | Iteration number: [520/565] 92% | Training loss: 0.6892377021221014
Epoch: 9 | Iteration number: [530/565] 93% | Training loss: 0.689214509613109
Epoch: 9 | Iteration number: [540/565] 95% | Training loss: 0.6891825976195158
Epoch: 9 | Iteration number: [550/565] 97% | Training loss: 0.6891487115079706
Epoch: 9 | Iteration number: [560/565] 99% | Training loss: 0.6891183406114578

 End of epoch: 9 | Train Loss: 0.6878893931355097 | Training Time: 87 

 End of epoch: 9 | Eval Loss: 0.6908273611749921 | Evaluating Time: 6 
Epoch: 10 | Iteration number: [10/565] 1% | Training loss: 0.7567037165164947
Epoch: 10 | Iteration number: [20/565] 3% | Training loss: 0.722328832745552
Epoch: 10 | Iteration number: [30/565] 5% | Training loss: 0.7108126640319824
Epoch: 10 | Iteration number: [40/565] 7% | Training loss: 0.7051258817315101
Epoch: 10 | Iteration number: [50/565] 8% | Training loss: 0.701747282743454
Epoch: 10 | Iteration number: [60/565] 10% | Training loss: 0.6994358013073604
Epoch: 10 | Iteration number: [70/565] 12% | Training loss: 0.697818591764995
Epoch: 10 | Iteration number: [80/565] 14% | Training loss: 0.696564570069313
Epoch: 10 | Iteration number: [90/565] 15% | Training loss: 0.6956118782361348
Epoch: 10 | Iteration number: [100/565] 17% | Training loss: 0.6947940051555633
Epoch: 10 | Iteration number: [110/565] 19% | Training loss: 0.6941706912084059
Epoch: 10 | Iteration number: [120/565] 21% | Training loss: 0.6936321973800659
Epoch: 10 | Iteration number: [130/565] 23% | Training loss: 0.6931486689127409
Epoch: 10 | Iteration number: [140/565] 24% | Training loss: 0.6927798058305468
Epoch: 10 | Iteration number: [150/565] 26% | Training loss: 0.6924677038192749
Epoch: 10 | Iteration number: [160/565] 28% | Training loss: 0.6922114230692387
Epoch: 10 | Iteration number: [170/565] 30% | Training loss: 0.6919368515996372
Epoch: 10 | Iteration number: [180/565] 31% | Training loss: 0.6917024085919062
Epoch: 10 | Iteration number: [190/565] 33% | Training loss: 0.6914980148014269
Epoch: 10 | Iteration number: [200/565] 35% | Training loss: 0.6912898486852646
Epoch: 10 | Iteration number: [210/565] 37% | Training loss: 0.6911291758219401
Epoch: 10 | Iteration number: [220/565] 38% | Training loss: 0.6909677635539662
Epoch: 10 | Iteration number: [230/565] 40% | Training loss: 0.6908188952052075
Epoch: 10 | Iteration number: [240/565] 42% | Training loss: 0.6906835898756981
Epoch: 10 | Iteration number: [250/565] 44% | Training loss: 0.6905644929409027
Epoch: 10 | Iteration number: [260/565] 46% | Training loss: 0.6904576854063914
Epoch: 10 | Iteration number: [270/565] 47% | Training loss: 0.6903352759502552
Epoch: 10 | Iteration number: [280/565] 49% | Training loss: 0.6902404218912125
Epoch: 10 | Iteration number: [290/565] 51% | Training loss: 0.6901386939246079
Epoch: 10 | Iteration number: [300/565] 53% | Training loss: 0.6900678763786952
Epoch: 10 | Iteration number: [310/565] 54% | Training loss: 0.6899783955466363
Epoch: 10 | Iteration number: [320/565] 56% | Training loss: 0.6899166824296117
Epoch: 10 | Iteration number: [330/565] 58% | Training loss: 0.6898472981019453
Epoch: 10 | Iteration number: [340/565] 60% | Training loss: 0.6897944816771675
Epoch: 10 | Iteration number: [350/565] 61% | Training loss: 0.6897346367154803
Epoch: 10 | Iteration number: [360/565] 63% | Training loss: 0.6896661561396387
Epoch: 10 | Iteration number: [370/565] 65% | Training loss: 0.6896059136132936
Epoch: 10 | Iteration number: [380/565] 67% | Training loss: 0.6895647911649001
Epoch: 10 | Iteration number: [390/565] 69% | Training loss: 0.6895178970618125
Epoch: 10 | Iteration number: [400/565] 70% | Training loss: 0.6894644337892533
Epoch: 10 | Iteration number: [410/565] 72% | Training loss: 0.6894174703737584
Epoch: 10 | Iteration number: [420/565] 74% | Training loss: 0.6893685983760016
Epoch: 10 | Iteration number: [430/565] 76% | Training loss: 0.6893235246802485
Epoch: 10 | Iteration number: [440/565] 77% | Training loss: 0.6892748739231717
Epoch: 10 | Iteration number: [450/565] 79% | Training loss: 0.6892428357071346
Epoch: 10 | Iteration number: [460/565] 81% | Training loss: 0.6892063757647638
Epoch: 10 | Iteration number: [470/565] 83% | Training loss: 0.6891763664306478
Epoch: 10 | Iteration number: [480/565] 84% | Training loss: 0.689133433252573
Epoch: 10 | Iteration number: [490/565] 86% | Training loss: 0.6891004521019605
Epoch: 10 | Iteration number: [500/565] 88% | Training loss: 0.6890665582418442
Epoch: 10 | Iteration number: [510/565] 90% | Training loss: 0.6890425808289472
Epoch: 10 | Iteration number: [520/565] 92% | Training loss: 0.6890155214529771
Epoch: 10 | Iteration number: [530/565] 93% | Training loss: 0.6889902388149838
Epoch: 10 | Iteration number: [540/565] 95% | Training loss: 0.6889664949090393
Epoch: 10 | Iteration number: [550/565] 97% | Training loss: 0.6889481410113248
Epoch: 10 | Iteration number: [560/565] 99% | Training loss: 0.6889204073165144

 End of epoch: 10 | Train Loss: 0.6876900459812806 | Training Time: 89 

 End of epoch: 10 | Eval Loss: 0.6905241778918675 | Evaluating Time: 5 
Epoch: 11 | Iteration number: [10/565] 1% | Training loss: 0.7561868667602539
Epoch: 11 | Iteration number: [20/565] 3% | Training loss: 0.7218468427658081
Epoch: 11 | Iteration number: [30/565] 5% | Training loss: 0.71045294602712
Epoch: 11 | Iteration number: [40/565] 7% | Training loss: 0.7047955766320229
Epoch: 11 | Iteration number: [50/565] 8% | Training loss: 0.7014041137695313
Epoch: 11 | Iteration number: [60/565] 10% | Training loss: 0.6990883608659109
Epoch: 11 | Iteration number: [70/565] 12% | Training loss: 0.6974112110478538
Epoch: 11 | Iteration number: [80/565] 14% | Training loss: 0.6962247222661972
Epoch: 11 | Iteration number: [90/565] 15% | Training loss: 0.6952396379576788
Epoch: 11 | Iteration number: [100/565] 17% | Training loss: 0.6944952666759491
Epoch: 11 | Iteration number: [110/565] 19% | Training loss: 0.693921793049032
Epoch: 11 | Iteration number: [120/565] 21% | Training loss: 0.6934300606449445
Epoch: 11 | Iteration number: [130/565] 23% | Training loss: 0.6929595479598412
Epoch: 11 | Iteration number: [140/565] 24% | Training loss: 0.6925849386623928
Epoch: 11 | Iteration number: [150/565] 26% | Training loss: 0.6922407833735148
Epoch: 11 | Iteration number: [160/565] 28% | Training loss: 0.6919731374830007
Epoch: 11 | Iteration number: [170/565] 30% | Training loss: 0.691716855764389
Epoch: 11 | Iteration number: [180/565] 31% | Training loss: 0.6914894670248032
Epoch: 11 | Iteration number: [190/565] 33% | Training loss: 0.6912893577625877
Epoch: 11 | Iteration number: [200/565] 35% | Training loss: 0.6911071443557739
Epoch: 11 | Iteration number: [210/565] 37% | Training loss: 0.6909378054596129
Epoch: 11 | Iteration number: [220/565] 38% | Training loss: 0.6907783012498508
Epoch: 11 | Iteration number: [230/565] 40% | Training loss: 0.6906157630941142
Epoch: 11 | Iteration number: [240/565] 42% | Training loss: 0.6904806300997735
Epoch: 11 | Iteration number: [250/565] 44% | Training loss: 0.690365745306015
Epoch: 11 | Iteration number: [260/565] 46% | Training loss: 0.6902546859704531
Epoch: 11 | Iteration number: [270/565] 47% | Training loss: 0.6901366571585338
Epoch: 11 | Iteration number: [280/565] 49% | Training loss: 0.6900389375431197
Epoch: 11 | Iteration number: [290/565] 51% | Training loss: 0.6899555670803991
Epoch: 11 | Iteration number: [300/565] 53% | Training loss: 0.6898759657144546
Epoch: 11 | Iteration number: [310/565] 54% | Training loss: 0.6898163635884562
Epoch: 11 | Iteration number: [320/565] 56% | Training loss: 0.6897375971078873
Epoch: 11 | Iteration number: [330/565] 58% | Training loss: 0.6896596791166247
Epoch: 11 | Iteration number: [340/565] 60% | Training loss: 0.6895912480704924
Epoch: 11 | Iteration number: [350/565] 61% | Training loss: 0.689525329044887
Epoch: 11 | Iteration number: [360/565] 63% | Training loss: 0.6894679220186339
Epoch: 11 | Iteration number: [370/565] 65% | Training loss: 0.6894163542502635
Epoch: 11 | Iteration number: [380/565] 67% | Training loss: 0.6893640637397767
Epoch: 11 | Iteration number: [390/565] 69% | Training loss: 0.68931315327302
Epoch: 11 | Iteration number: [400/565] 70% | Training loss: 0.6892695517838001
Epoch: 11 | Iteration number: [410/565] 72% | Training loss: 0.6892315253978822
Epoch: 11 | Iteration number: [420/565] 74% | Training loss: 0.6891849787462325
Epoch: 11 | Iteration number: [430/565] 76% | Training loss: 0.6891541530919629
Epoch: 11 | Iteration number: [440/565] 77% | Training loss: 0.6891233819452199
Epoch: 11 | Iteration number: [450/565] 79% | Training loss: 0.6890817840894063
Epoch: 11 | Iteration number: [460/565] 81% | Training loss: 0.6890441411215326
Epoch: 11 | Iteration number: [470/565] 83% | Training loss: 0.6890162457811072
Epoch: 11 | Iteration number: [480/565] 84% | Training loss: 0.6889722410589456
Epoch: 11 | Iteration number: [490/565] 86% | Training loss: 0.6889454272328591
Epoch: 11 | Iteration number: [500/565] 88% | Training loss: 0.6889203954935074
Epoch: 11 | Iteration number: [510/565] 90% | Training loss: 0.6888976105287963
Epoch: 11 | Iteration number: [520/565] 92% | Training loss: 0.6888676694952525
Epoch: 11 | Iteration number: [530/565] 93% | Training loss: 0.6888378946286328
Epoch: 11 | Iteration number: [540/565] 95% | Training loss: 0.6888185564014647
Epoch: 11 | Iteration number: [550/565] 97% | Training loss: 0.6887949119914661
Epoch: 11 | Iteration number: [560/565] 99% | Training loss: 0.6887641191482544

 End of epoch: 11 | Train Loss: 0.6875288524458893 | Training Time: 87 

 End of epoch: 11 | Eval Loss: 0.6906894445419312 | Evaluating Time: 6 
Epoch: 12 | Iteration number: [10/565] 1% | Training loss: 0.7556520164012909
Epoch: 12 | Iteration number: [20/565] 3% | Training loss: 0.7214920908212662
Epoch: 12 | Iteration number: [30/565] 5% | Training loss: 0.7101863920688629
Epoch: 12 | Iteration number: [40/565] 7% | Training loss: 0.7045170068740845
Epoch: 12 | Iteration number: [50/565] 8% | Training loss: 0.7011259615421295
Epoch: 12 | Iteration number: [60/565] 10% | Training loss: 0.6988343358039856
Epoch: 12 | Iteration number: [70/565] 12% | Training loss: 0.6971815773418971
Epoch: 12 | Iteration number: [80/565] 14% | Training loss: 0.6959662318229676
Epoch: 12 | Iteration number: [90/565] 15% | Training loss: 0.6950086924764846
Epoch: 12 | Iteration number: [100/565] 17% | Training loss: 0.6942666953802109
Epoch: 12 | Iteration number: [110/565] 19% | Training loss: 0.6936294387687336
Epoch: 12 | Iteration number: [120/565] 21% | Training loss: 0.6931429535150528
Epoch: 12 | Iteration number: [130/565] 23% | Training loss: 0.6927152170584752
Epoch: 12 | Iteration number: [140/565] 24% | Training loss: 0.6923422919852393
Epoch: 12 | Iteration number: [150/565] 26% | Training loss: 0.6920080041885376
Epoch: 12 | Iteration number: [160/565] 28% | Training loss: 0.6917493369430303
Epoch: 12 | Iteration number: [170/565] 30% | Training loss: 0.6914894612396465
Epoch: 12 | Iteration number: [180/565] 31% | Training loss: 0.6912466863791148
Epoch: 12 | Iteration number: [190/565] 33% | Training loss: 0.69103196796618
Epoch: 12 | Iteration number: [200/565] 35% | Training loss: 0.690874052643776
Epoch: 12 | Iteration number: [210/565] 37% | Training loss: 0.6906942452703203
Epoch: 12 | Iteration number: [220/565] 38% | Training loss: 0.6905465359037573
Epoch: 12 | Iteration number: [230/565] 40% | Training loss: 0.6903976259024247
Epoch: 12 | Iteration number: [240/565] 42% | Training loss: 0.6902849403520425
Epoch: 12 | Iteration number: [250/565] 44% | Training loss: 0.6901600797176362
Epoch: 12 | Iteration number: [260/565] 46% | Training loss: 0.6900621609045909
Epoch: 12 | Iteration number: [270/565] 47% | Training loss: 0.6899476298579463
Epoch: 12 | Iteration number: [280/565] 49% | Training loss: 0.6898612543940544
Epoch: 12 | Iteration number: [290/565] 51% | Training loss: 0.6897792010471738
Epoch: 12 | Iteration number: [300/565] 53% | Training loss: 0.6896898541847865
Epoch: 12 | Iteration number: [310/565] 54% | Training loss: 0.689629389009168
Epoch: 12 | Iteration number: [320/565] 56% | Training loss: 0.6895452609285713
Epoch: 12 | Iteration number: [330/565] 58% | Training loss: 0.6894916341160283
Epoch: 12 | Iteration number: [340/565] 60% | Training loss: 0.6894290976664599
Epoch: 12 | Iteration number: [350/565] 61% | Training loss: 0.6893810546398162
Epoch: 12 | Iteration number: [360/565] 63% | Training loss: 0.6893278302417861
Epoch: 12 | Iteration number: [370/565] 65% | Training loss: 0.6892587502260465
Epoch: 12 | Iteration number: [380/565] 67% | Training loss: 0.68919969891247
Epoch: 12 | Iteration number: [390/565] 69% | Training loss: 0.6891592537745451
Epoch: 12 | Iteration number: [400/565] 70% | Training loss: 0.6891120134294033
Epoch: 12 | Iteration number: [410/565] 72% | Training loss: 0.6890639161191335
Epoch: 12 | Iteration number: [420/565] 74% | Training loss: 0.6890162812811987
Epoch: 12 | Iteration number: [430/565] 76% | Training loss: 0.6889846832253212
Epoch: 12 | Iteration number: [440/565] 77% | Training loss: 0.6889448966492306
Epoch: 12 | Iteration number: [450/565] 79% | Training loss: 0.6889006347126431
Epoch: 12 | Iteration number: [460/565] 81% | Training loss: 0.6888708967229594
Epoch: 12 | Iteration number: [470/565] 83% | Training loss: 0.688840818278333
Epoch: 12 | Iteration number: [480/565] 84% | Training loss: 0.6888156097382307
Epoch: 12 | Iteration number: [490/565] 86% | Training loss: 0.6887817647992348
Epoch: 12 | Iteration number: [500/565] 88% | Training loss: 0.6887574146986007
Epoch: 12 | Iteration number: [510/565] 90% | Training loss: 0.6887318424150055
Epoch: 12 | Iteration number: [520/565] 92% | Training loss: 0.6887059334378977
Epoch: 12 | Iteration number: [530/565] 93% | Training loss: 0.688687235566805
Epoch: 12 | Iteration number: [540/565] 95% | Training loss: 0.6886637494519905
Epoch: 12 | Iteration number: [550/565] 97% | Training loss: 0.6886396744034508
Epoch: 12 | Iteration number: [560/565] 99% | Training loss: 0.688616078879152

 End of epoch: 12 | Train Loss: 0.6873818904952665 | Training Time: 89 

 End of epoch: 12 | Eval Loss: 0.6896740879331317 | Evaluating Time: 6 
Epoch: 13 | Iteration number: [10/565] 1% | Training loss: 0.755790650844574
Epoch: 13 | Iteration number: [20/565] 3% | Training loss: 0.7215213179588318
Epoch: 13 | Iteration number: [30/565] 5% | Training loss: 0.7100492636362712
Epoch: 13 | Iteration number: [40/565] 7% | Training loss: 0.7043769031763076
Epoch: 13 | Iteration number: [50/565] 8% | Training loss: 0.7009638822078705
Epoch: 13 | Iteration number: [60/565] 10% | Training loss: 0.6986823072036107
Epoch: 13 | Iteration number: [70/565] 12% | Training loss: 0.6971097469329834
Epoch: 13 | Iteration number: [80/565] 14% | Training loss: 0.6958827540278435
Epoch: 13 | Iteration number: [90/565] 15% | Training loss: 0.6949599259429508
Epoch: 13 | Iteration number: [100/565] 17% | Training loss: 0.6942036014795303
Epoch: 13 | Iteration number: [110/565] 19% | Training loss: 0.6935404528271069
Epoch: 13 | Iteration number: [120/565] 21% | Training loss: 0.6930388634403547
Epoch: 13 | Iteration number: [130/565] 23% | Training loss: 0.6926089126330156
Epoch: 13 | Iteration number: [140/565] 24% | Training loss: 0.6922037273645401
Epoch: 13 | Iteration number: [150/565] 26% | Training loss: 0.6918495059013366
Epoch: 13 | Iteration number: [160/565] 28% | Training loss: 0.6916105721145869
Epoch: 13 | Iteration number: [170/565] 30% | Training loss: 0.6913591149975272
Epoch: 13 | Iteration number: [180/565] 31% | Training loss: 0.6911372035741806
Epoch: 13 | Iteration number: [190/565] 33% | Training loss: 0.6909187501982639
Epoch: 13 | Iteration number: [200/565] 35% | Training loss: 0.6907634177803993
Epoch: 13 | Iteration number: [210/565] 37% | Training loss: 0.69062463868232
Epoch: 13 | Iteration number: [220/565] 38% | Training loss: 0.6904798423702067
Epoch: 13 | Iteration number: [230/565] 40% | Training loss: 0.6903489517128986
Epoch: 13 | Iteration number: [240/565] 42% | Training loss: 0.6902189369002978
Epoch: 13 | Iteration number: [250/565] 44% | Training loss: 0.6901187317371369
Epoch: 13 | Iteration number: [260/565] 46% | Training loss: 0.6900157644198491
Epoch: 13 | Iteration number: [270/565] 47% | Training loss: 0.6899199304757295
Epoch: 13 | Iteration number: [280/565] 49% | Training loss: 0.6898190342954227
Epoch: 13 | Iteration number: [290/565] 51% | Training loss: 0.6897371789504742
Epoch: 13 | Iteration number: [300/565] 53% | Training loss: 0.6896584928035736
Epoch: 13 | Iteration number: [310/565] 54% | Training loss: 0.6895698268567362
Epoch: 13 | Iteration number: [320/565] 56% | Training loss: 0.6894997447729111
Epoch: 13 | Iteration number: [330/565] 58% | Training loss: 0.6894271861423146
Epoch: 13 | Iteration number: [340/565] 60% | Training loss: 0.6893526966080946
Epoch: 13 | Iteration number: [350/565] 61% | Training loss: 0.6892862830843244
Epoch: 13 | Iteration number: [360/565] 63% | Training loss: 0.6892194391952621
Epoch: 13 | Iteration number: [370/565] 65% | Training loss: 0.6891642282138
Epoch: 13 | Iteration number: [380/565] 67% | Training loss: 0.6891116459118692
Epoch: 13 | Iteration number: [390/565] 69% | Training loss: 0.6890776022886619
Epoch: 13 | Iteration number: [400/565] 70% | Training loss: 0.6890412424504757
Epoch: 13 | Iteration number: [410/565] 72% | Training loss: 0.6890001999168861
Epoch: 13 | Iteration number: [420/565] 74% | Training loss: 0.6889730955873217
Epoch: 13 | Iteration number: [430/565] 76% | Training loss: 0.6889305784258731
Epoch: 13 | Iteration number: [440/565] 77% | Training loss: 0.6888905541463332
Epoch: 13 | Iteration number: [450/565] 79% | Training loss: 0.6888537649313609
Epoch: 13 | Iteration number: [460/565] 81% | Training loss: 0.6888251215219497
Epoch: 13 | Iteration number: [470/565] 83% | Training loss: 0.6888009299623206
Epoch: 13 | Iteration number: [480/565] 84% | Training loss: 0.6887626457959414
Epoch: 13 | Iteration number: [490/565] 86% | Training loss: 0.6887245903209764
Epoch: 13 | Iteration number: [500/565] 88% | Training loss: 0.6887001024484635
Epoch: 13 | Iteration number: [510/565] 90% | Training loss: 0.6886750169828826
Epoch: 13 | Iteration number: [520/565] 92% | Training loss: 0.6886475048386134
Epoch: 13 | Iteration number: [530/565] 93% | Training loss: 0.6886166566947721
Epoch: 13 | Iteration number: [540/565] 95% | Training loss: 0.6885912240655334
Epoch: 13 | Iteration number: [550/565] 97% | Training loss: 0.6885749538378282
Epoch: 13 | Iteration number: [560/565] 99% | Training loss: 0.6885549155729157

 End of epoch: 13 | Train Loss: 0.6873220804518303 | Training Time: 89 

 End of epoch: 13 | Eval Loss: 0.6897622517177037 | Evaluating Time: 5 
Epoch: 14 | Iteration number: [10/565] 1% | Training loss: 0.7562123000621795
Epoch: 14 | Iteration number: [20/565] 3% | Training loss: 0.7217137217521667
Epoch: 14 | Iteration number: [30/565] 5% | Training loss: 0.7102582653363546
Epoch: 14 | Iteration number: [40/565] 7% | Training loss: 0.7047358363866806
Epoch: 14 | Iteration number: [50/565] 8% | Training loss: 0.7012503004074097
Epoch: 14 | Iteration number: [60/565] 10% | Training loss: 0.6988186965386073
Epoch: 14 | Iteration number: [70/565] 12% | Training loss: 0.6971101718289512
Epoch: 14 | Iteration number: [80/565] 14% | Training loss: 0.6958757735788822
Epoch: 14 | Iteration number: [90/565] 15% | Training loss: 0.6949408968289693
Epoch: 14 | Iteration number: [100/565] 17% | Training loss: 0.6941992592811584
Epoch: 14 | Iteration number: [110/565] 19% | Training loss: 0.6935489827936346
Epoch: 14 | Iteration number: [120/565] 21% | Training loss: 0.6930424188574155
Epoch: 14 | Iteration number: [130/565] 23% | Training loss: 0.6925888171562782
Epoch: 14 | Iteration number: [140/565] 24% | Training loss: 0.6921967766114644
Epoch: 14 | Iteration number: [150/565] 26% | Training loss: 0.6918418864409129
Epoch: 14 | Iteration number: [160/565] 28% | Training loss: 0.6915670398622751
Epoch: 14 | Iteration number: [170/565] 30% | Training loss: 0.6913134098052979
Epoch: 14 | Iteration number: [180/565] 31% | Training loss: 0.6910593615637886
Epoch: 14 | Iteration number: [190/565] 33% | Training loss: 0.6908313572406769
Epoch: 14 | Iteration number: [200/565] 35% | Training loss: 0.690659042596817
Epoch: 14 | Iteration number: [210/565] 37% | Training loss: 0.690499384630294
Epoch: 14 | Iteration number: [220/565] 38% | Training loss: 0.6903216137127443
Epoch: 14 | Iteration number: [230/565] 40% | Training loss: 0.6902081715024035
Epoch: 14 | Iteration number: [240/565] 42% | Training loss: 0.6900942129393418
Epoch: 14 | Iteration number: [250/565] 44% | Training loss: 0.6899833714962006
Epoch: 14 | Iteration number: [260/565] 46% | Training loss: 0.6898855108481187
Epoch: 14 | Iteration number: [270/565] 47% | Training loss: 0.6897896459809056
Epoch: 14 | Iteration number: [280/565] 49% | Training loss: 0.689704073539802
Epoch: 14 | Iteration number: [290/565] 51% | Training loss: 0.689623204798534
Epoch: 14 | Iteration number: [300/565] 53% | Training loss: 0.6895356901486714
Epoch: 14 | Iteration number: [310/565] 54% | Training loss: 0.6894662807064672
Epoch: 14 | Iteration number: [320/565] 56% | Training loss: 0.6893871806561946
Epoch: 14 | Iteration number: [330/565] 58% | Training loss: 0.6893115953965621
Epoch: 14 | Iteration number: [340/565] 60% | Training loss: 0.6892508192973978
Epoch: 14 | Iteration number: [350/565] 61% | Training loss: 0.6891942882537841
Epoch: 14 | Iteration number: [360/565] 63% | Training loss: 0.6891216695308685
Epoch: 14 | Iteration number: [370/565] 65% | Training loss: 0.6890618370996939
Epoch: 14 | Iteration number: [380/565] 67% | Training loss: 0.6890261025805222
Epoch: 14 | Iteration number: [390/565] 69% | Training loss: 0.6889912527341109
Epoch: 14 | Iteration number: [400/565] 70% | Training loss: 0.6889550071954728
Epoch: 14 | Iteration number: [410/565] 72% | Training loss: 0.6889255301254552
Epoch: 14 | Iteration number: [420/565] 74% | Training loss: 0.6888784276587623
Epoch: 14 | Iteration number: [430/565] 76% | Training loss: 0.6888438779254292
Epoch: 14 | Iteration number: [440/565] 77% | Training loss: 0.6887969740412452
Epoch: 14 | Iteration number: [450/565] 79% | Training loss: 0.6887675121095446
Epoch: 14 | Iteration number: [460/565] 81% | Training loss: 0.6887365982584331
Epoch: 14 | Iteration number: [470/565] 83% | Training loss: 0.6887082065673584
Epoch: 14 | Iteration number: [480/565] 84% | Training loss: 0.6886840422948202
Epoch: 14 | Iteration number: [490/565] 86% | Training loss: 0.6886502900902106
Epoch: 14 | Iteration number: [500/565] 88% | Training loss: 0.688620827794075
Epoch: 14 | Iteration number: [510/565] 90% | Training loss: 0.6885940473453671
Epoch: 14 | Iteration number: [520/565] 92% | Training loss: 0.6885561600327492
Epoch: 14 | Iteration number: [530/565] 93% | Training loss: 0.688532101208309
Epoch: 14 | Iteration number: [540/565] 95% | Training loss: 0.6885110686222712
Epoch: 14 | Iteration number: [550/565] 97% | Training loss: 0.6884962971643968
Epoch: 14 | Iteration number: [560/565] 99% | Training loss: 0.6884754823786872

 End of epoch: 14 | Train Loss: 0.6872445895608548 | Training Time: 89 

 End of epoch: 14 | Eval Loss: 0.6904636791774205 | Evaluating Time: 6 
Epoch: 15 | Iteration number: [10/565] 1% | Training loss: 0.755832839012146
Epoch: 15 | Iteration number: [20/565] 3% | Training loss: 0.7214450716972352
Epoch: 15 | Iteration number: [30/565] 5% | Training loss: 0.7098774353663126
Epoch: 15 | Iteration number: [40/565] 7% | Training loss: 0.7042191505432129
Epoch: 15 | Iteration number: [50/565] 8% | Training loss: 0.7008643162250519
Epoch: 15 | Iteration number: [60/565] 10% | Training loss: 0.6986501683791478
Epoch: 15 | Iteration number: [70/565] 12% | Training loss: 0.6970150658062526
Epoch: 15 | Iteration number: [80/565] 14% | Training loss: 0.6957796514034271
Epoch: 15 | Iteration number: [90/565] 15% | Training loss: 0.6948161582152049
Epoch: 15 | Iteration number: [100/565] 17% | Training loss: 0.6940993392467498
Epoch: 15 | Iteration number: [110/565] 19% | Training loss: 0.6934913467277181
Epoch: 15 | Iteration number: [120/565] 21% | Training loss: 0.6929827799399694
Epoch: 15 | Iteration number: [130/565] 23% | Training loss: 0.6925045481094947
Epoch: 15 | Iteration number: [140/565] 24% | Training loss: 0.692116916179657
Epoch: 15 | Iteration number: [150/565] 26% | Training loss: 0.6917771565914154
Epoch: 15 | Iteration number: [160/565] 28% | Training loss: 0.6915166921913624
Epoch: 15 | Iteration number: [170/565] 30% | Training loss: 0.6912711697466233
Epoch: 15 | Iteration number: [180/565] 31% | Training loss: 0.6910258866018719
Epoch: 15 | Iteration number: [190/565] 33% | Training loss: 0.690840566785712
Epoch: 15 | Iteration number: [200/565] 35% | Training loss: 0.6906661778688431
Epoch: 15 | Iteration number: [210/565] 37% | Training loss: 0.6904907342933473
Epoch: 15 | Iteration number: [220/565] 38% | Training loss: 0.6903023237531836
Epoch: 15 | Iteration number: [230/565] 40% | Training loss: 0.6901755294074183
Epoch: 15 | Iteration number: [240/565] 42% | Training loss: 0.6900465880831083
Epoch: 15 | Iteration number: [250/565] 44% | Training loss: 0.689936552286148
Epoch: 15 | Iteration number: [260/565] 46% | Training loss: 0.6898326516151428
Epoch: 15 | Iteration number: [270/565] 47% | Training loss: 0.6897454107249225
Epoch: 15 | Iteration number: [280/565] 49% | Training loss: 0.6896712094545364
Epoch: 15 | Iteration number: [290/565] 51% | Training loss: 0.6895964466292283
Epoch: 15 | Iteration number: [300/565] 53% | Training loss: 0.6895201849937439
Epoch: 15 | Iteration number: [310/565] 54% | Training loss: 0.6894229731252116
Epoch: 15 | Iteration number: [320/565] 56% | Training loss: 0.6893574662506581
Epoch: 15 | Iteration number: [330/565] 58% | Training loss: 0.6892936758922809
Epoch: 15 | Iteration number: [340/565] 60% | Training loss: 0.6892055416808409
Epoch: 15 | Iteration number: [350/565] 61% | Training loss: 0.689165804386139
Epoch: 15 | Iteration number: [360/565] 63% | Training loss: 0.689115558233526
Epoch: 15 | Iteration number: [370/565] 65% | Training loss: 0.6890723824501037
Epoch: 15 | Iteration number: [380/565] 67% | Training loss: 0.6890306022606398
Epoch: 15 | Iteration number: [390/565] 69% | Training loss: 0.688982894940254
Epoch: 15 | Iteration number: [400/565] 70% | Training loss: 0.6889339280128479
Epoch: 15 | Iteration number: [410/565] 72% | Training loss: 0.6889065528788217
Epoch: 15 | Iteration number: [420/565] 74% | Training loss: 0.6888662119706471
Epoch: 15 | Iteration number: [430/565] 76% | Training loss: 0.6888309925101525
Epoch: 15 | Iteration number: [440/565] 77% | Training loss: 0.6887899027629332
Epoch: 15 | Iteration number: [450/565] 79% | Training loss: 0.6887470565901862
Epoch: 15 | Iteration number: [460/565] 81% | Training loss: 0.6887175865795301
Epoch: 15 | Iteration number: [470/565] 83% | Training loss: 0.6886866498500743
Epoch: 15 | Iteration number: [480/565] 84% | Training loss: 0.6886543616652488
Epoch: 15 | Iteration number: [490/565] 86% | Training loss: 0.6886222345488412
Epoch: 15 | Iteration number: [500/565] 88% | Training loss: 0.6885935868024826
Epoch: 15 | Iteration number: [510/565] 90% | Training loss: 0.6885717373268277
Epoch: 15 | Iteration number: [520/565] 92% | Training loss: 0.6885457910024203
Epoch: 15 | Iteration number: [530/565] 93% | Training loss: 0.6885097442932848
Epoch: 15 | Iteration number: [540/565] 95% | Training loss: 0.6884882156495695
Epoch: 15 | Iteration number: [550/565] 97% | Training loss: 0.6884653382951563
Epoch: 15 | Iteration number: [560/565] 99% | Training loss: 0.6884355022438935

 End of epoch: 15 | Train Loss: 0.6872055058985684 | Training Time: 88 

 End of epoch: 15 | Eval Loss: 0.6901830179350716 | Evaluating Time: 6 
Epoch: 16 | Iteration number: [10/565] 1% | Training loss: 0.7556585013866425
Epoch: 16 | Iteration number: [20/565] 3% | Training loss: 0.7213380306959152
Epoch: 16 | Iteration number: [30/565] 5% | Training loss: 0.7098988751570384
Epoch: 16 | Iteration number: [40/565] 7% | Training loss: 0.70437091588974
Epoch: 16 | Iteration number: [50/565] 8% | Training loss: 0.7009307539463043
Epoch: 16 | Iteration number: [60/565] 10% | Training loss: 0.6986792226632436
Epoch: 16 | Iteration number: [70/565] 12% | Training loss: 0.6969621232577733
Epoch: 16 | Iteration number: [80/565] 14% | Training loss: 0.6957188539206982
Epoch: 16 | Iteration number: [90/565] 15% | Training loss: 0.6947763131724464
Epoch: 16 | Iteration number: [100/565] 17% | Training loss: 0.69405588388443
Epoch: 16 | Iteration number: [110/565] 19% | Training loss: 0.6933817738836462
Epoch: 16 | Iteration number: [120/565] 21% | Training loss: 0.6928866470853488
Epoch: 16 | Iteration number: [130/565] 23% | Training loss: 0.6924405611478366
Epoch: 16 | Iteration number: [140/565] 24% | Training loss: 0.692071892108236
Epoch: 16 | Iteration number: [150/565] 26% | Training loss: 0.6917626210053762
Epoch: 16 | Iteration number: [160/565] 28% | Training loss: 0.6914834894239903
Epoch: 16 | Iteration number: [170/565] 30% | Training loss: 0.6912450513418983
Epoch: 16 | Iteration number: [180/565] 31% | Training loss: 0.6910182148218155
Epoch: 16 | Iteration number: [190/565] 33% | Training loss: 0.6907952638048874
Epoch: 16 | Iteration number: [200/565] 35% | Training loss: 0.6906213647127152
Epoch: 16 | Iteration number: [210/565] 37% | Training loss: 0.6904619920821417
Epoch: 16 | Iteration number: [220/565] 38% | Training loss: 0.6903120785951614
Epoch: 16 | Iteration number: [230/565] 40% | Training loss: 0.6901622951030731
Epoch: 16 | Iteration number: [240/565] 42% | Training loss: 0.6900279988845189
Epoch: 16 | Iteration number: [250/565] 44% | Training loss: 0.6899098711013794
Epoch: 16 | Iteration number: [260/565] 46% | Training loss: 0.6898057098572071
Epoch: 16 | Iteration number: [270/565] 47% | Training loss: 0.6897096625080815
Epoch: 16 | Iteration number: [280/565] 49% | Training loss: 0.6896229333111218
Epoch: 16 | Iteration number: [290/565] 51% | Training loss: 0.6895109382169
Epoch: 16 | Iteration number: [300/565] 53% | Training loss: 0.6894278438886007
Epoch: 16 | Iteration number: [310/565] 54% | Training loss: 0.6893486172922196
Epoch: 16 | Iteration number: [320/565] 56% | Training loss: 0.6892756378278136
Epoch: 16 | Iteration number: [330/565] 58% | Training loss: 0.6892121463110953
Epoch: 16 | Iteration number: [340/565] 60% | Training loss: 0.6891602905357586
Epoch: 16 | Iteration number: [350/565] 61% | Training loss: 0.68908367395401
Epoch: 16 | Iteration number: [360/565] 63% | Training loss: 0.689018252491951
Epoch: 16 | Iteration number: [370/565] 65% | Training loss: 0.6889648690417006
Epoch: 16 | Iteration number: [380/565] 67% | Training loss: 0.6889224803761432
Epoch: 16 | Iteration number: [390/565] 69% | Training loss: 0.6888703249968016
Epoch: 16 | Iteration number: [400/565] 70% | Training loss: 0.6888267968595028
Epoch: 16 | Iteration number: [410/565] 72% | Training loss: 0.6887866204831659
Epoch: 16 | Iteration number: [420/565] 74% | Training loss: 0.6887370380617324
Epoch: 16 | Iteration number: [430/565] 76% | Training loss: 0.6887055904366249
Epoch: 16 | Iteration number: [440/565] 77% | Training loss: 0.688663981042125
Epoch: 16 | Iteration number: [450/565] 79% | Training loss: 0.6886409008502961
Epoch: 16 | Iteration number: [460/565] 81% | Training loss: 0.6886103648206462
Epoch: 16 | Iteration number: [470/565] 83% | Training loss: 0.6885912269987958
Epoch: 16 | Iteration number: [480/565] 84% | Training loss: 0.6885529772688945
Epoch: 16 | Iteration number: [490/565] 86% | Training loss: 0.6885216899064123
Epoch: 16 | Iteration number: [500/565] 88% | Training loss: 0.6884958686828613
Epoch: 16 | Iteration number: [510/565] 90% | Training loss: 0.6884549860860787
Epoch: 16 | Iteration number: [520/565] 92% | Training loss: 0.6884277410232104
Epoch: 16 | Iteration number: [530/565] 93% | Training loss: 0.688410793835262
Epoch: 16 | Iteration number: [540/565] 95% | Training loss: 0.6883855023869762
Epoch: 16 | Iteration number: [550/565] 97% | Training loss: 0.6883628172224219
Epoch: 16 | Iteration number: [560/565] 99% | Training loss: 0.6883298498179231

 End of epoch: 16 | Train Loss: 0.6871051038261008 | Training Time: 88 

 End of epoch: 16 | Eval Loss: 0.6899127193859645 | Evaluating Time: 5 
Epoch: 17 | Iteration number: [10/565] 1% | Training loss: 0.7561497330665589
Epoch: 17 | Iteration number: [20/565] 3% | Training loss: 0.7216901004314422
Epoch: 17 | Iteration number: [30/565] 5% | Training loss: 0.7100621779759725
Epoch: 17 | Iteration number: [40/565] 7% | Training loss: 0.704409335553646
Epoch: 17 | Iteration number: [50/565] 8% | Training loss: 0.7009388875961303
Epoch: 17 | Iteration number: [60/565] 10% | Training loss: 0.698587766289711
Epoch: 17 | Iteration number: [70/565] 12% | Training loss: 0.6969806807381767
Epoch: 17 | Iteration number: [80/565] 14% | Training loss: 0.6957246564328671
Epoch: 17 | Iteration number: [90/565] 15% | Training loss: 0.6947644862863752
Epoch: 17 | Iteration number: [100/565] 17% | Training loss: 0.6939899730682373
Epoch: 17 | Iteration number: [110/565] 19% | Training loss: 0.6933575408025221
Epoch: 17 | Iteration number: [120/565] 21% | Training loss: 0.6928528189659119
Epoch: 17 | Iteration number: [130/565] 23% | Training loss: 0.6924134506629064
Epoch: 17 | Iteration number: [140/565] 24% | Training loss: 0.6920152434280941
Epoch: 17 | Iteration number: [150/565] 26% | Training loss: 0.6916702540715536
Epoch: 17 | Iteration number: [160/565] 28% | Training loss: 0.6914086982607841
Epoch: 17 | Iteration number: [170/565] 30% | Training loss: 0.691144146638758
Epoch: 17 | Iteration number: [180/565] 31% | Training loss: 0.6909259577592214
Epoch: 17 | Iteration number: [190/565] 33% | Training loss: 0.690737185352727
Epoch: 17 | Iteration number: [200/565] 35% | Training loss: 0.6905579781532287
Epoch: 17 | Iteration number: [210/565] 37% | Training loss: 0.6904001054309663
Epoch: 17 | Iteration number: [220/565] 38% | Training loss: 0.6902450965209441
Epoch: 17 | Iteration number: [230/565] 40% | Training loss: 0.6901098380918088
Epoch: 17 | Iteration number: [240/565] 42% | Training loss: 0.6899865381419659
Epoch: 17 | Iteration number: [250/565] 44% | Training loss: 0.6898927059173584
Epoch: 17 | Iteration number: [260/565] 46% | Training loss: 0.6897743170077985
Epoch: 17 | Iteration number: [270/565] 47% | Training loss: 0.6896871732340919
Epoch: 17 | Iteration number: [280/565] 49% | Training loss: 0.6895874359777996
Epoch: 17 | Iteration number: [290/565] 51% | Training loss: 0.6894895668687492
Epoch: 17 | Iteration number: [300/565] 53% | Training loss: 0.689416675567627
Epoch: 17 | Iteration number: [310/565] 54% | Training loss: 0.6893246716068637
Epoch: 17 | Iteration number: [320/565] 56% | Training loss: 0.6892248161137104
Epoch: 17 | Iteration number: [330/565] 58% | Training loss: 0.689154385436665
Epoch: 17 | Iteration number: [340/565] 60% | Training loss: 0.689104442561374
Epoch: 17 | Iteration number: [350/565] 61% | Training loss: 0.6890500491006034
Epoch: 17 | Iteration number: [360/565] 63% | Training loss: 0.6889968201518059
Epoch: 17 | Iteration number: [370/565] 65% | Training loss: 0.6889449797772073
Epoch: 17 | Iteration number: [380/565] 67% | Training loss: 0.6888882707608374
Epoch: 17 | Iteration number: [390/565] 69% | Training loss: 0.688840966194104
Epoch: 17 | Iteration number: [400/565] 70% | Training loss: 0.6887916369736194
Epoch: 17 | Iteration number: [410/565] 72% | Training loss: 0.6887590169906617
Epoch: 17 | Iteration number: [420/565] 74% | Training loss: 0.6887215925114495
Epoch: 17 | Iteration number: [430/565] 76% | Training loss: 0.6886906881665075
Epoch: 17 | Iteration number: [440/565] 77% | Training loss: 0.6886595342646945
Epoch: 17 | Iteration number: [450/565] 79% | Training loss: 0.6886163930098216
Epoch: 17 | Iteration number: [460/565] 81% | Training loss: 0.6886017869348111
Epoch: 17 | Iteration number: [470/565] 83% | Training loss: 0.688569373272835
Epoch: 17 | Iteration number: [480/565] 84% | Training loss: 0.6885412479440371
Epoch: 17 | Iteration number: [490/565] 86% | Training loss: 0.6885076840313114
Epoch: 17 | Iteration number: [500/565] 88% | Training loss: 0.6884833028316498
Epoch: 17 | Iteration number: [510/565] 90% | Training loss: 0.6884444139751733
Epoch: 17 | Iteration number: [520/565] 92% | Training loss: 0.6884180628336393
Epoch: 17 | Iteration number: [530/565] 93% | Training loss: 0.6883931152100833
Epoch: 17 | Iteration number: [540/565] 95% | Training loss: 0.6883721354934904
Epoch: 17 | Iteration number: [550/565] 97% | Training loss: 0.6883408610387282
Epoch: 17 | Iteration number: [560/565] 99% | Training loss: 0.6883119296814714

 End of epoch: 17 | Train Loss: 0.6870867440130858 | Training Time: 88 

 End of epoch: 17 | Eval Loss: 0.6900702629770551 | Evaluating Time: 6 
Epoch: 18 | Iteration number: [10/565] 1% | Training loss: 0.755517965555191
Epoch: 18 | Iteration number: [20/565] 3% | Training loss: 0.7212885737419128
Epoch: 18 | Iteration number: [30/565] 5% | Training loss: 0.7098360558350881
Epoch: 18 | Iteration number: [40/565] 7% | Training loss: 0.7042127311229706
Epoch: 18 | Iteration number: [50/565] 8% | Training loss: 0.7008033418655395
Epoch: 18 | Iteration number: [60/565] 10% | Training loss: 0.6985333174467087
Epoch: 18 | Iteration number: [70/565] 12% | Training loss: 0.6968851821763175
Epoch: 18 | Iteration number: [80/565] 14% | Training loss: 0.6956504084169864
Epoch: 18 | Iteration number: [90/565] 15% | Training loss: 0.6947000881036123
Epoch: 18 | Iteration number: [100/565] 17% | Training loss: 0.6939213591814041
Epoch: 18 | Iteration number: [110/565] 19% | Training loss: 0.6932868020101027
Epoch: 18 | Iteration number: [120/565] 21% | Training loss: 0.6927777041991552
Epoch: 18 | Iteration number: [130/565] 23% | Training loss: 0.6923813205498915
Epoch: 18 | Iteration number: [140/565] 24% | Training loss: 0.6920159054653985
Epoch: 18 | Iteration number: [150/565] 26% | Training loss: 0.6916878875096639
Epoch: 18 | Iteration number: [160/565] 28% | Training loss: 0.691383358463645
Epoch: 18 | Iteration number: [170/565] 30% | Training loss: 0.6911509489311891
Epoch: 18 | Iteration number: [180/565] 31% | Training loss: 0.6909283849928114
Epoch: 18 | Iteration number: [190/565] 33% | Training loss: 0.6907293031090185
Epoch: 18 | Iteration number: [200/565] 35% | Training loss: 0.6905574497580528
Epoch: 18 | Iteration number: [210/565] 37% | Training loss: 0.6903926940191359
Epoch: 18 | Iteration number: [220/565] 38% | Training loss: 0.6902281089262529
Epoch: 18 | Iteration number: [230/565] 40% | Training loss: 0.6901034054548844
Epoch: 18 | Iteration number: [240/565] 42% | Training loss: 0.6899690560996532
Epoch: 18 | Iteration number: [250/565] 44% | Training loss: 0.6898502941131592
Epoch: 18 | Iteration number: [260/565] 46% | Training loss: 0.6897294402122498
Epoch: 18 | Iteration number: [270/565] 47% | Training loss: 0.6896230278191743
Epoch: 18 | Iteration number: [280/565] 49% | Training loss: 0.6895294453416552
Epoch: 18 | Iteration number: [290/565] 51% | Training loss: 0.6894443964136058
Epoch: 18 | Iteration number: [300/565] 53% | Training loss: 0.6893708115816116
Epoch: 18 | Iteration number: [310/565] 54% | Training loss: 0.6892824126828101
Epoch: 18 | Iteration number: [320/565] 56% | Training loss: 0.6892294332385063
Epoch: 18 | Iteration number: [330/565] 58% | Training loss: 0.6891687019304795
Epoch: 18 | Iteration number: [340/565] 60% | Training loss: 0.6891024729784797
Epoch: 18 | Iteration number: [350/565] 61% | Training loss: 0.6890480429785593
Epoch: 18 | Iteration number: [360/565] 63% | Training loss: 0.6889905931221114
Epoch: 18 | Iteration number: [370/565] 65% | Training loss: 0.6889448977805472
Epoch: 18 | Iteration number: [380/565] 67% | Training loss: 0.6888915763089531
Epoch: 18 | Iteration number: [390/565] 69% | Training loss: 0.6888316356218778
Epoch: 18 | Iteration number: [400/565] 70% | Training loss: 0.6887903800606727
Epoch: 18 | Iteration number: [410/565] 72% | Training loss: 0.6887573531488093
Epoch: 18 | Iteration number: [420/565] 74% | Training loss: 0.6887192659434818
Epoch: 18 | Iteration number: [430/565] 76% | Training loss: 0.688677664551624
Epoch: 18 | Iteration number: [440/565] 77% | Training loss: 0.6886424300345507
Epoch: 18 | Iteration number: [450/565] 79% | Training loss: 0.6886040663719177
Epoch: 18 | Iteration number: [460/565] 81% | Training loss: 0.6885748670152996
Epoch: 18 | Iteration number: [470/565] 83% | Training loss: 0.6885378103306953
Epoch: 18 | Iteration number: [480/565] 84% | Training loss: 0.6885102080802122
Epoch: 18 | Iteration number: [490/565] 86% | Training loss: 0.6884827713577115
Epoch: 18 | Iteration number: [500/565] 88% | Training loss: 0.6884436137676239
Epoch: 18 | Iteration number: [510/565] 90% | Training loss: 0.6884195555658902
Epoch: 18 | Iteration number: [520/565] 92% | Training loss: 0.6883854346779676
Epoch: 18 | Iteration number: [530/565] 93% | Training loss: 0.688359649113889
Epoch: 18 | Iteration number: [540/565] 95% | Training loss: 0.688334314469938
Epoch: 18 | Iteration number: [550/565] 97% | Training loss: 0.6883057530359789
Epoch: 18 | Iteration number: [560/565] 99% | Training loss: 0.6882830742214407

 End of epoch: 18 | Train Loss: 0.6870590982183946 | Training Time: 89 

 End of epoch: 18 | Eval Loss: 0.6897393890789577 | Evaluating Time: 6 
Epoch: 19 | Iteration number: [10/565] 1% | Training loss: 0.7555784344673157
Epoch: 19 | Iteration number: [20/565] 3% | Training loss: 0.7213627219200134
Epoch: 19 | Iteration number: [30/565] 5% | Training loss: 0.7099933743476867
Epoch: 19 | Iteration number: [40/565] 7% | Training loss: 0.7042332008481026
Epoch: 19 | Iteration number: [50/565] 8% | Training loss: 0.700787808895111
Epoch: 19 | Iteration number: [60/565] 10% | Training loss: 0.6985658933718999
Epoch: 19 | Iteration number: [70/565] 12% | Training loss: 0.6969573846885136
Epoch: 19 | Iteration number: [80/565] 14% | Training loss: 0.6956836938858032
Epoch: 19 | Iteration number: [90/565] 15% | Training loss: 0.6947569966316223
Epoch: 19 | Iteration number: [100/565] 17% | Training loss: 0.6939903271198272
Epoch: 19 | Iteration number: [110/565] 19% | Training loss: 0.6933508125218478
Epoch: 19 | Iteration number: [120/565] 21% | Training loss: 0.692810074488322
Epoch: 19 | Iteration number: [130/565] 23% | Training loss: 0.6923933464747208
Epoch: 19 | Iteration number: [140/565] 24% | Training loss: 0.6919869623013906
Epoch: 19 | Iteration number: [150/565] 26% | Training loss: 0.6916620755195617
Epoch: 19 | Iteration number: [160/565] 28% | Training loss: 0.6913508422672748
Epoch: 19 | Iteration number: [170/565] 30% | Training loss: 0.6910888563184178
Epoch: 19 | Iteration number: [180/565] 31% | Training loss: 0.6908817579348882
Epoch: 19 | Iteration number: [190/565] 33% | Training loss: 0.6906850510521939
Epoch: 19 | Iteration number: [200/565] 35% | Training loss: 0.6905178612470627
Epoch: 19 | Iteration number: [210/565] 37% | Training loss: 0.6903381364686149
Epoch: 19 | Iteration number: [220/565] 38% | Training loss: 0.69017413854599
Epoch: 19 | Iteration number: [230/565] 40% | Training loss: 0.6900429007799729
Epoch: 19 | Iteration number: [240/565] 42% | Training loss: 0.6899151752392451
Epoch: 19 | Iteration number: [250/565] 44% | Training loss: 0.6897917945384979
Epoch: 19 | Iteration number: [260/565] 46% | Training loss: 0.6896935160343464
Epoch: 19 | Iteration number: [270/565] 47% | Training loss: 0.6895931789168606
Epoch: 19 | Iteration number: [280/565] 49% | Training loss: 0.6894875632865088
Epoch: 19 | Iteration number: [290/565] 51% | Training loss: 0.6894051309289604
Epoch: 19 | Iteration number: [300/565] 53% | Training loss: 0.689323381781578
Epoch: 19 | Iteration number: [310/565] 54% | Training loss: 0.6892538072601442
Epoch: 19 | Iteration number: [320/565] 56% | Training loss: 0.6891845239326357
Epoch: 19 | Iteration number: [330/565] 58% | Training loss: 0.6891229678284038
Epoch: 19 | Iteration number: [340/565] 60% | Training loss: 0.6890594520989586
Epoch: 19 | Iteration number: [350/565] 61% | Training loss: 0.6890100637504033
Epoch: 19 | Iteration number: [360/565] 63% | Training loss: 0.6889498208959898
Epoch: 19 | Iteration number: [370/565] 65% | Training loss: 0.6889006339214944
Epoch: 19 | Iteration number: [380/565] 67% | Training loss: 0.68886181727836
Epoch: 19 | Iteration number: [390/565] 69% | Training loss: 0.6888264258702596
Epoch: 19 | Iteration number: [400/565] 70% | Training loss: 0.6887789329886437
Epoch: 19 | Iteration number: [410/565] 72% | Training loss: 0.6887420462398994
Epoch: 19 | Iteration number: [420/565] 74% | Training loss: 0.6887001764206659
Epoch: 19 | Iteration number: [430/565] 76% | Training loss: 0.6886561937110368
Epoch: 19 | Iteration number: [440/565] 77% | Training loss: 0.6886233388022943
Epoch: 19 | Iteration number: [450/565] 79% | Training loss: 0.6885901551776462
Epoch: 19 | Iteration number: [460/565] 81% | Training loss: 0.6885520107072333
Epoch: 19 | Iteration number: [470/565] 83% | Training loss: 0.6885136931500536
Epoch: 19 | Iteration number: [480/565] 84% | Training loss: 0.6884759878118832
Epoch: 19 | Iteration number: [490/565] 86% | Training loss: 0.6884503401055628
Epoch: 19 | Iteration number: [500/565] 88% | Training loss: 0.6884296383857728
Epoch: 19 | Iteration number: [510/565] 90% | Training loss: 0.6883951569304747
Epoch: 19 | Iteration number: [520/565] 92% | Training loss: 0.6883775942600691
Epoch: 19 | Iteration number: [530/565] 93% | Training loss: 0.6883460397990244
Epoch: 19 | Iteration number: [540/565] 95% | Training loss: 0.6883271825534326
Epoch: 19 | Iteration number: [550/565] 97% | Training loss: 0.6882992670752786
Epoch: 19 | Iteration number: [560/565] 99% | Training loss: 0.688278815895319

 End of epoch: 19 | Train Loss: 0.687047290802002 | Training Time: 88 

 End of epoch: 19 | Eval Loss: 0.6904159188270569 | Evaluating Time: 6 
Epoch: 20 | Iteration number: [10/565] 1% | Training loss: 0.7561851799488067
Epoch: 20 | Iteration number: [20/565] 3% | Training loss: 0.7213061451911926
Epoch: 20 | Iteration number: [30/565] 5% | Training loss: 0.7099767486254375
Epoch: 20 | Iteration number: [40/565] 7% | Training loss: 0.7042017325758934
Epoch: 20 | Iteration number: [50/565] 8% | Training loss: 0.700753720998764
Epoch: 20 | Iteration number: [60/565] 10% | Training loss: 0.6984204520781835
Epoch: 20 | Iteration number: [70/565] 12% | Training loss: 0.6968848126275199
Epoch: 20 | Iteration number: [80/565] 14% | Training loss: 0.6956077858805656
Epoch: 20 | Iteration number: [90/565] 15% | Training loss: 0.6946486923429701
Epoch: 20 | Iteration number: [100/565] 17% | Training loss: 0.693859971165657
Epoch: 20 | Iteration number: [110/565] 19% | Training loss: 0.6932315696369518
Epoch: 20 | Iteration number: [120/565] 21% | Training loss: 0.6926668787995974
Epoch: 20 | Iteration number: [130/565] 23% | Training loss: 0.6922472591583545
Epoch: 20 | Iteration number: [140/565] 24% | Training loss: 0.691897411431585
Epoch: 20 | Iteration number: [150/565] 26% | Training loss: 0.6916118295987447
Epoch: 20 | Iteration number: [160/565] 28% | Training loss: 0.6913195502012968
Epoch: 20 | Iteration number: [170/565] 30% | Training loss: 0.691043398660772
Epoch: 20 | Iteration number: [180/565] 31% | Training loss: 0.6908232818047205
Epoch: 20 | Iteration number: [190/565] 33% | Training loss: 0.6906118154525757
Epoch: 20 | Iteration number: [200/565] 35% | Training loss: 0.690406986773014
Epoch: 20 | Iteration number: [210/565] 37% | Training loss: 0.6902652490706671
Epoch: 20 | Iteration number: [220/565] 38% | Training loss: 0.6901118663224307
Epoch: 20 | Iteration number: [230/565] 40% | Training loss: 0.6899955467037533
Epoch: 20 | Iteration number: [240/565] 42% | Training loss: 0.689864112685124
Epoch: 20 | Iteration number: [250/565] 44% | Training loss: 0.6897612171173095
Epoch: 20 | Iteration number: [260/565] 46% | Training loss: 0.6896456617575425
Epoch: 20 | Iteration number: [270/565] 47% | Training loss: 0.6895432832064452
Epoch: 20 | Iteration number: [280/565] 49% | Training loss: 0.68944693676063
Epoch: 20 | Iteration number: [290/565] 51% | Training loss: 0.6893665977593126
Epoch: 20 | Iteration number: [300/565] 53% | Training loss: 0.689288271466891
Epoch: 20 | Iteration number: [310/565] 54% | Training loss: 0.6892090332123542
Epoch: 20 | Iteration number: [320/565] 56% | Training loss: 0.6891542365774512
Epoch: 20 | Iteration number: [330/565] 58% | Training loss: 0.6891032917933031
Epoch: 20 | Iteration number: [340/565] 60% | Training loss: 0.6890296851887422
Epoch: 20 | Iteration number: [350/565] 61% | Training loss: 0.6889788213797978
Epoch: 20 | Iteration number: [360/565] 63% | Training loss: 0.6889136476649178
Epoch: 20 | Iteration number: [370/565] 65% | Training loss: 0.6888507717364544
Epoch: 20 | Iteration number: [380/565] 67% | Training loss: 0.6888076565767589
Epoch: 20 | Iteration number: [390/565] 69% | Training loss: 0.6887715409963558
Epoch: 20 | Iteration number: [400/565] 70% | Training loss: 0.6887228392064572
Epoch: 20 | Iteration number: [410/565] 72% | Training loss: 0.6886760009498131
Epoch: 20 | Iteration number: [420/565] 74% | Training loss: 0.6886291999192465
Epoch: 20 | Iteration number: [430/565] 76% | Training loss: 0.6885845892651137
Epoch: 20 | Iteration number: [440/565] 77% | Training loss: 0.6885507250374013
Epoch: 20 | Iteration number: [450/565] 79% | Training loss: 0.6885205113887787
Epoch: 20 | Iteration number: [460/565] 81% | Training loss: 0.6884865512018619
Epoch: 20 | Iteration number: [470/565] 83% | Training loss: 0.6884633123874664
Epoch: 20 | Iteration number: [480/565] 84% | Training loss: 0.6884309779852629
Epoch: 20 | Iteration number: [490/565] 86% | Training loss: 0.688403844833374
Epoch: 20 | Iteration number: [500/565] 88% | Training loss: 0.6883781712055206
Epoch: 20 | Iteration number: [510/565] 90% | Training loss: 0.6883541703224182
Epoch: 20 | Iteration number: [520/565] 92% | Training loss: 0.6883239113367521
Epoch: 20 | Iteration number: [530/565] 93% | Training loss: 0.688297666806095
Epoch: 20 | Iteration number: [540/565] 95% | Training loss: 0.6882710141164285
Epoch: 20 | Iteration number: [550/565] 97% | Training loss: 0.6882528826323423
Epoch: 20 | Iteration number: [560/565] 99% | Training loss: 0.6882339932024479

 End of epoch: 20 | Train Loss: 0.6870080001586306 | Training Time: 88 

 End of epoch: 20 | Eval Loss: 0.6901518276759556 | Evaluating Time: 6 
Epoch: 21 | Iteration number: [10/565] 1% | Training loss: 0.755611103773117
Epoch: 21 | Iteration number: [20/565] 3% | Training loss: 0.7211984425783158
Epoch: 21 | Iteration number: [30/565] 5% | Training loss: 0.7096414665381113
Epoch: 21 | Iteration number: [40/565] 7% | Training loss: 0.7038422510027885
Epoch: 21 | Iteration number: [50/565] 8% | Training loss: 0.7004577839374542
Epoch: 21 | Iteration number: [60/565] 10% | Training loss: 0.6982749303181967
Epoch: 21 | Iteration number: [70/565] 12% | Training loss: 0.6966655688626425
Epoch: 21 | Iteration number: [80/565] 14% | Training loss: 0.6954714946448803
Epoch: 21 | Iteration number: [90/565] 15% | Training loss: 0.6945100704828898
Epoch: 21 | Iteration number: [100/565] 17% | Training loss: 0.6937449461221695
Epoch: 21 | Iteration number: [110/565] 19% | Training loss: 0.6931057870388031
Epoch: 21 | Iteration number: [120/565] 21% | Training loss: 0.6925758888324102
Epoch: 21 | Iteration number: [130/565] 23% | Training loss: 0.6921152197397672
Epoch: 21 | Iteration number: [140/565] 24% | Training loss: 0.6917731962033681
Epoch: 21 | Iteration number: [150/565] 26% | Training loss: 0.6914470799763998
Epoch: 21 | Iteration number: [160/565] 28% | Training loss: 0.691175190731883
Epoch: 21 | Iteration number: [170/565] 30% | Training loss: 0.6909460646264693
Epoch: 21 | Iteration number: [180/565] 31% | Training loss: 0.690714622868432
Epoch: 21 | Iteration number: [190/565] 33% | Training loss: 0.6905291921214054
Epoch: 21 | Iteration number: [200/565] 35% | Training loss: 0.6903663772344589
Epoch: 21 | Iteration number: [210/565] 37% | Training loss: 0.6901939287072136
Epoch: 21 | Iteration number: [220/565] 38% | Training loss: 0.6900493914430792
Epoch: 21 | Iteration number: [230/565] 40% | Training loss: 0.689938339461451
Epoch: 21 | Iteration number: [240/565] 42% | Training loss: 0.689818877230088
Epoch: 21 | Iteration number: [250/565] 44% | Training loss: 0.6896921510696411
Epoch: 21 | Iteration number: [260/565] 46% | Training loss: 0.6895966059886492
Epoch: 21 | Iteration number: [270/565] 47% | Training loss: 0.6895038035180834
Epoch: 21 | Iteration number: [280/565] 49% | Training loss: 0.6894183118428503
Epoch: 21 | Iteration number: [290/565] 51% | Training loss: 0.689343000280446
Epoch: 21 | Iteration number: [300/565] 53% | Training loss: 0.6892831095059713
Epoch: 21 | Iteration number: [310/565] 54% | Training loss: 0.6891980486531412
Epoch: 21 | Iteration number: [320/565] 56% | Training loss: 0.6891385303810239
Epoch: 21 | Iteration number: [330/565] 58% | Training loss: 0.6890832516280088
Epoch: 21 | Iteration number: [340/565] 60% | Training loss: 0.6890205665546305
Epoch: 21 | Iteration number: [350/565] 61% | Training loss: 0.6889519711903164
Epoch: 21 | Iteration number: [360/565] 63% | Training loss: 0.6888922495974434
Epoch: 21 | Iteration number: [370/565] 65% | Training loss: 0.6888479340720821
Epoch: 21 | Iteration number: [380/565] 67% | Training loss: 0.68878885884034
Epoch: 21 | Iteration number: [390/565] 69% | Training loss: 0.6887411122138684
Epoch: 21 | Iteration number: [400/565] 70% | Training loss: 0.6886901706457138
Epoch: 21 | Iteration number: [410/565] 72% | Training loss: 0.6886454929665822
Epoch: 21 | Iteration number: [420/565] 74% | Training loss: 0.6886104385058085
Epoch: 21 | Iteration number: [430/565] 76% | Training loss: 0.6885736756546553
Epoch: 21 | Iteration number: [440/565] 77% | Training loss: 0.6885453711856495
Epoch: 21 | Iteration number: [450/565] 79% | Training loss: 0.6885124700599247
Epoch: 21 | Iteration number: [460/565] 81% | Training loss: 0.688485291859378
Epoch: 21 | Iteration number: [470/565] 83% | Training loss: 0.6884533216344549
Epoch: 21 | Iteration number: [480/565] 84% | Training loss: 0.688430292531848
Epoch: 21 | Iteration number: [490/565] 86% | Training loss: 0.6883987143331645
Epoch: 21 | Iteration number: [500/565] 88% | Training loss: 0.6883716776371002
Epoch: 21 | Iteration number: [510/565] 90% | Training loss: 0.6883484438353894
Epoch: 21 | Iteration number: [520/565] 92% | Training loss: 0.6883252247021748
Epoch: 21 | Iteration number: [530/565] 93% | Training loss: 0.6883059456663312
Epoch: 21 | Iteration number: [540/565] 95% | Training loss: 0.6882768934523618
Epoch: 21 | Iteration number: [550/565] 97% | Training loss: 0.6882546576586637
Epoch: 21 | Iteration number: [560/565] 99% | Training loss: 0.688234714950834

 End of epoch: 21 | Train Loss: 0.6870027354333254 | Training Time: 87 

 End of epoch: 21 | Eval Loss: 0.6910685982022967 | Evaluating Time: 6 
Epoch: 22 | Iteration number: [10/565] 1% | Training loss: 0.7552637219429016
Epoch: 22 | Iteration number: [20/565] 3% | Training loss: 0.7211637198925018
Epoch: 22 | Iteration number: [30/565] 5% | Training loss: 0.7098144272963206
Epoch: 22 | Iteration number: [40/565] 7% | Training loss: 0.7041269898414612
Epoch: 22 | Iteration number: [50/565] 8% | Training loss: 0.7006742930412293
Epoch: 22 | Iteration number: [60/565] 10% | Training loss: 0.6983189761638642
Epoch: 22 | Iteration number: [70/565] 12% | Training loss: 0.6966255111353737
Epoch: 22 | Iteration number: [80/565] 14% | Training loss: 0.6954518921673298
Epoch: 22 | Iteration number: [90/565] 15% | Training loss: 0.6944664663738674
Epoch: 22 | Iteration number: [100/565] 17% | Training loss: 0.6937189888954163
Epoch: 22 | Iteration number: [110/565] 19% | Training loss: 0.6930890614336187
Epoch: 22 | Iteration number: [120/565] 21% | Training loss: 0.6926065986355145
Epoch: 22 | Iteration number: [130/565] 23% | Training loss: 0.6921908465715555
Epoch: 22 | Iteration number: [140/565] 24% | Training loss: 0.6918538455452238
Epoch: 22 | Iteration number: [150/565] 26% | Training loss: 0.6915370420614878
Epoch: 22 | Iteration number: [160/565] 28% | Training loss: 0.6912361744791269
Epoch: 22 | Iteration number: [170/565] 30% | Training loss: 0.6909800087704377
Epoch: 22 | Iteration number: [180/565] 31% | Training loss: 0.6907885041501787
Epoch: 22 | Iteration number: [190/565] 33% | Training loss: 0.6905806873974047
Epoch: 22 | Iteration number: [200/565] 35% | Training loss: 0.6903935226798058
Epoch: 22 | Iteration number: [210/565] 37% | Training loss: 0.6902104167711167
Epoch: 22 | Iteration number: [220/565] 38% | Training loss: 0.690063014626503
Epoch: 22 | Iteration number: [230/565] 40% | Training loss: 0.6899389184039572
Epoch: 22 | Iteration number: [240/565] 42% | Training loss: 0.6898098749419054
Epoch: 22 | Iteration number: [250/565] 44% | Training loss: 0.6896958913803101
Epoch: 22 | Iteration number: [260/565] 46% | Training loss: 0.6895913121791987
Epoch: 22 | Iteration number: [270/565] 47% | Training loss: 0.6895070645544265
Epoch: 22 | Iteration number: [280/565] 49% | Training loss: 0.6894152294312205
Epoch: 22 | Iteration number: [290/565] 51% | Training loss: 0.6893309490434054
Epoch: 22 | Iteration number: [300/565] 53% | Training loss: 0.6892376683155695
Epoch: 22 | Iteration number: [310/565] 54% | Training loss: 0.6891679475384374
Epoch: 22 | Iteration number: [320/565] 56% | Training loss: 0.6891110833734274
Epoch: 22 | Iteration number: [330/565] 58% | Training loss: 0.6890387966777339
Epoch: 22 | Iteration number: [340/565] 60% | Training loss: 0.6889733523130417
Epoch: 22 | Iteration number: [350/565] 61% | Training loss: 0.6889363382543836
Epoch: 22 | Iteration number: [360/565] 63% | Training loss: 0.6888767179515627
Epoch: 22 | Iteration number: [370/565] 65% | Training loss: 0.6888137375986254
Epoch: 22 | Iteration number: [380/565] 67% | Training loss: 0.6887751911815844
Epoch: 22 | Iteration number: [390/565] 69% | Training loss: 0.6887205715362842
Epoch: 22 | Iteration number: [400/565] 70% | Training loss: 0.6886699336767197
Epoch: 22 | Iteration number: [410/565] 72% | Training loss: 0.6886327055896201
Epoch: 22 | Iteration number: [420/565] 74% | Training loss: 0.6885939368179866
Epoch: 22 | Iteration number: [430/565] 76% | Training loss: 0.688562288672425
Epoch: 22 | Iteration number: [440/565] 77% | Training loss: 0.6885330068794164
Epoch: 22 | Iteration number: [450/565] 79% | Training loss: 0.6884981316990323
Epoch: 22 | Iteration number: [460/565] 81% | Training loss: 0.688467644608539
Epoch: 22 | Iteration number: [470/565] 83% | Training loss: 0.6884385049343109
Epoch: 22 | Iteration number: [480/565] 84% | Training loss: 0.6884085773179929
Epoch: 22 | Iteration number: [490/565] 86% | Training loss: 0.6883800212217837
Epoch: 22 | Iteration number: [500/565] 88% | Training loss: 0.6883440102338791
Epoch: 22 | Iteration number: [510/565] 90% | Training loss: 0.6883257363356796
Epoch: 22 | Iteration number: [520/565] 92% | Training loss: 0.6883035513070913
Epoch: 22 | Iteration number: [530/565] 93% | Training loss: 0.688270415787427
Epoch: 22 | Iteration number: [540/565] 95% | Training loss: 0.6882530034692199
Epoch: 22 | Iteration number: [550/565] 97% | Training loss: 0.6882310750267723
Epoch: 22 | Iteration number: [560/565] 99% | Training loss: 0.6882059763584818

 End of epoch: 22 | Train Loss: 0.6869767881072728 | Training Time: 89 

 End of epoch: 22 | Eval Loss: 0.6903041090284076 | Evaluating Time: 6 
Epoch: 23 | Iteration number: [10/565] 1% | Training loss: 0.755613511800766
Epoch: 23 | Iteration number: [20/565] 3% | Training loss: 0.7212849855422974
Epoch: 23 | Iteration number: [30/565] 5% | Training loss: 0.7097458998362224
Epoch: 23 | Iteration number: [40/565] 7% | Training loss: 0.7039594322443008
Epoch: 23 | Iteration number: [50/565] 8% | Training loss: 0.7006406629085541
Epoch: 23 | Iteration number: [60/565] 10% | Training loss: 0.6984280268351237
Epoch: 23 | Iteration number: [70/565] 12% | Training loss: 0.6968062332698277
Epoch: 23 | Iteration number: [80/565] 14% | Training loss: 0.6956140927970409
Epoch: 23 | Iteration number: [90/565] 15% | Training loss: 0.6946704963843028
Epoch: 23 | Iteration number: [100/565] 17% | Training loss: 0.6939146482944488
Epoch: 23 | Iteration number: [110/565] 19% | Training loss: 0.6933041209524328
Epoch: 23 | Iteration number: [120/565] 21% | Training loss: 0.6928001170357069
Epoch: 23 | Iteration number: [130/565] 23% | Training loss: 0.6923214389727665
Epoch: 23 | Iteration number: [140/565] 24% | Training loss: 0.6919387991939272
Epoch: 23 | Iteration number: [150/565] 26% | Training loss: 0.6916477465629578
Epoch: 23 | Iteration number: [160/565] 28% | Training loss: 0.6913754157721996
Epoch: 23 | Iteration number: [170/565] 30% | Training loss: 0.6911168003783507
Epoch: 23 | Iteration number: [180/565] 31% | Training loss: 0.6908904092179404
Epoch: 23 | Iteration number: [190/565] 33% | Training loss: 0.6906708594999815
Epoch: 23 | Iteration number: [200/565] 35% | Training loss: 0.6904906305670738
Epoch: 23 | Iteration number: [210/565] 37% | Training loss: 0.6903396918660119
Epoch: 23 | Iteration number: [220/565] 38% | Training loss: 0.6901792187582363
Epoch: 23 | Iteration number: [230/565] 40% | Training loss: 0.6900454715542171
Epoch: 23 | Iteration number: [240/565] 42% | Training loss: 0.6899106132487456
Epoch: 23 | Iteration number: [250/565] 44% | Training loss: 0.689791661977768
Epoch: 23 | Iteration number: [260/565] 46% | Training loss: 0.6896749473535098
Epoch: 23 | Iteration number: [270/565] 47% | Training loss: 0.6895722541544173
Epoch: 23 | Iteration number: [280/565] 49% | Training loss: 0.6894770053880556
Epoch: 23 | Iteration number: [290/565] 51% | Training loss: 0.6893965445715805
Epoch: 23 | Iteration number: [300/565] 53% | Training loss: 0.6893144502242406
Epoch: 23 | Iteration number: [310/565] 54% | Training loss: 0.6892217218875885
Epoch: 23 | Iteration number: [320/565] 56% | Training loss: 0.6891462739557028
Epoch: 23 | Iteration number: [330/565] 58% | Training loss: 0.6890683688900687
Epoch: 23 | Iteration number: [340/565] 60% | Training loss: 0.6889951225589304
Epoch: 23 | Iteration number: [350/565] 61% | Training loss: 0.6889415572370802
Epoch: 23 | Iteration number: [360/565] 63% | Training loss: 0.6888780446516143
Epoch: 23 | Iteration number: [370/565] 65% | Training loss: 0.6888242133565852
Epoch: 23 | Iteration number: [380/565] 67% | Training loss: 0.6887725122665104
Epoch: 23 | Iteration number: [390/565] 69% | Training loss: 0.6887217651575039
Epoch: 23 | Iteration number: [400/565] 70% | Training loss: 0.6886765395104885
Epoch: 23 | Iteration number: [410/565] 72% | Training loss: 0.6886318922042847
Epoch: 23 | Iteration number: [420/565] 74% | Training loss: 0.688588428071567
Epoch: 23 | Iteration number: [430/565] 76% | Training loss: 0.6885510246421016
Epoch: 23 | Iteration number: [440/565] 77% | Training loss: 0.6885173064741221
Epoch: 23 | Iteration number: [450/565] 79% | Training loss: 0.6884812927246093
Epoch: 23 | Iteration number: [460/565] 81% | Training loss: 0.6884425314872161
Epoch: 23 | Iteration number: [470/565] 83% | Training loss: 0.6884192986691252
Epoch: 23 | Iteration number: [480/565] 84% | Training loss: 0.6883977081626653
Epoch: 23 | Iteration number: [490/565] 86% | Training loss: 0.6883681776572247
Epoch: 23 | Iteration number: [500/565] 88% | Training loss: 0.688344429731369
Epoch: 23 | Iteration number: [510/565] 90% | Training loss: 0.6883215878524033
Epoch: 23 | Iteration number: [520/565] 92% | Training loss: 0.6882986233784603
Epoch: 23 | Iteration number: [530/565] 93% | Training loss: 0.688267833556769
Epoch: 23 | Iteration number: [540/565] 95% | Training loss: 0.6882389812557785
Epoch: 23 | Iteration number: [550/565] 97% | Training loss: 0.6882126407189803
Epoch: 23 | Iteration number: [560/565] 99% | Training loss: 0.6881977457020964

 End of epoch: 23 | Train Loss: 0.6869663738571437 | Training Time: 88 

 End of epoch: 23 | Eval Loss: 0.6897166882242475 | Evaluating Time: 6 
Epoch: 24 | Iteration number: [10/565] 1% | Training loss: 0.7562235295772552
Epoch: 24 | Iteration number: [20/565] 3% | Training loss: 0.721503621339798
Epoch: 24 | Iteration number: [30/565] 5% | Training loss: 0.7099895616372426
Epoch: 24 | Iteration number: [40/565] 7% | Training loss: 0.7042231500148773
Epoch: 24 | Iteration number: [50/565] 8% | Training loss: 0.7007747960090637
Epoch: 24 | Iteration number: [60/565] 10% | Training loss: 0.69851855635643
Epoch: 24 | Iteration number: [70/565] 12% | Training loss: 0.6968771381037576
Epoch: 24 | Iteration number: [80/565] 14% | Training loss: 0.6955452203750611
Epoch: 24 | Iteration number: [90/565] 15% | Training loss: 0.6946173283788893
Epoch: 24 | Iteration number: [100/565] 17% | Training loss: 0.6938222539424896
Epoch: 24 | Iteration number: [110/565] 19% | Training loss: 0.6931959683244878
Epoch: 24 | Iteration number: [120/565] 21% | Training loss: 0.6926520263155301
Epoch: 24 | Iteration number: [130/565] 23% | Training loss: 0.6922140451577994
Epoch: 24 | Iteration number: [140/565] 24% | Training loss: 0.6918036435331617
Epoch: 24 | Iteration number: [150/565] 26% | Training loss: 0.6915093978246053
Epoch: 24 | Iteration number: [160/565] 28% | Training loss: 0.691229735314846
Epoch: 24 | Iteration number: [170/565] 30% | Training loss: 0.6910088952849893
Epoch: 24 | Iteration number: [180/565] 31% | Training loss: 0.6907831801308526
Epoch: 24 | Iteration number: [190/565] 33% | Training loss: 0.6905700413804305
Epoch: 24 | Iteration number: [200/565] 35% | Training loss: 0.69039754986763
Epoch: 24 | Iteration number: [210/565] 37% | Training loss: 0.6902438456103915
Epoch: 24 | Iteration number: [220/565] 38% | Training loss: 0.6901004910469055
Epoch: 24 | Iteration number: [230/565] 40% | Training loss: 0.6899670733057934
Epoch: 24 | Iteration number: [240/565] 42% | Training loss: 0.689846736441056
Epoch: 24 | Iteration number: [250/565] 44% | Training loss: 0.6897264018058776
Epoch: 24 | Iteration number: [260/565] 46% | Training loss: 0.6896172042076404
Epoch: 24 | Iteration number: [270/565] 47% | Training loss: 0.6895146502388848
Epoch: 24 | Iteration number: [280/565] 49% | Training loss: 0.6894272010241236
Epoch: 24 | Iteration number: [290/565] 51% | Training loss: 0.689351317389258
Epoch: 24 | Iteration number: [300/565] 53% | Training loss: 0.6892809665203095
Epoch: 24 | Iteration number: [310/565] 54% | Training loss: 0.6892178654670715
Epoch: 24 | Iteration number: [320/565] 56% | Training loss: 0.6891546189785004
Epoch: 24 | Iteration number: [330/565] 58% | Training loss: 0.6890807063290567
Epoch: 24 | Iteration number: [340/565] 60% | Training loss: 0.6889925031101003
Epoch: 24 | Iteration number: [350/565] 61% | Training loss: 0.6889423971516745
Epoch: 24 | Iteration number: [360/565] 63% | Training loss: 0.6889020699593756
Epoch: 24 | Iteration number: [370/565] 65% | Training loss: 0.6888454830324328
Epoch: 24 | Iteration number: [380/565] 67% | Training loss: 0.6888027796619817
Epoch: 24 | Iteration number: [390/565] 69% | Training loss: 0.6887533352925227
Epoch: 24 | Iteration number: [400/565] 70% | Training loss: 0.6887107978761197
Epoch: 24 | Iteration number: [410/565] 72% | Training loss: 0.6886834132962111
Epoch: 24 | Iteration number: [420/565] 74% | Training loss: 0.6886395589226768
Epoch: 24 | Iteration number: [430/565] 76% | Training loss: 0.6885884498440942
Epoch: 24 | Iteration number: [440/565] 77% | Training loss: 0.6885449733246457
Epoch: 24 | Iteration number: [450/565] 79% | Training loss: 0.6885078843434652
Epoch: 24 | Iteration number: [460/565] 81% | Training loss: 0.6884691182685935
Epoch: 24 | Iteration number: [470/565] 83% | Training loss: 0.6884282761431755
Epoch: 24 | Iteration number: [480/565] 84% | Training loss: 0.6884027982751528
Epoch: 24 | Iteration number: [490/565] 86% | Training loss: 0.6883743904074844
Epoch: 24 | Iteration number: [500/565] 88% | Training loss: 0.6883446892499924
Epoch: 24 | Iteration number: [510/565] 90% | Training loss: 0.6883155177621281
Epoch: 24 | Iteration number: [520/565] 92% | Training loss: 0.688293789097896
Epoch: 24 | Iteration number: [530/565] 93% | Training loss: 0.6882795090945262
Epoch: 24 | Iteration number: [540/565] 95% | Training loss: 0.6882508154268618
Epoch: 24 | Iteration number: [550/565] 97% | Training loss: 0.6882339891520414
Epoch: 24 | Iteration number: [560/565] 99% | Training loss: 0.6882097731743541

 End of epoch: 24 | Train Loss: 0.6869852256985892 | Training Time: 89 

 End of epoch: 24 | Eval Loss: 0.6903385945728847 | Evaluating Time: 6 
Epoch: 25 | Iteration number: [10/565] 1% | Training loss: 0.7559394419193268
Epoch: 25 | Iteration number: [20/565] 3% | Training loss: 0.7215224415063858
Epoch: 25 | Iteration number: [30/565] 5% | Training loss: 0.7099629660447438
Epoch: 25 | Iteration number: [40/565] 7% | Training loss: 0.7042672067880631
Epoch: 25 | Iteration number: [50/565] 8% | Training loss: 0.700823746919632
Epoch: 25 | Iteration number: [60/565] 10% | Training loss: 0.6985521078109741
Epoch: 25 | Iteration number: [70/565] 12% | Training loss: 0.696883089201791
Epoch: 25 | Iteration number: [80/565] 14% | Training loss: 0.6956656672060489
Epoch: 25 | Iteration number: [90/565] 15% | Training loss: 0.6946956806712681
Epoch: 25 | Iteration number: [100/565] 17% | Training loss: 0.6938975912332535
Epoch: 25 | Iteration number: [110/565] 19% | Training loss: 0.6932622448964553
Epoch: 25 | Iteration number: [120/565] 21% | Training loss: 0.6927425081531207
Epoch: 25 | Iteration number: [130/565] 23% | Training loss: 0.6922995388507843
Epoch: 25 | Iteration number: [140/565] 24% | Training loss: 0.6918640221868243
Epoch: 25 | Iteration number: [150/565] 26% | Training loss: 0.6915425761540731
Epoch: 25 | Iteration number: [160/565] 28% | Training loss: 0.691247908771038
Epoch: 25 | Iteration number: [170/565] 30% | Training loss: 0.6910050276447744
Epoch: 25 | Iteration number: [180/565] 31% | Training loss: 0.6907635695404477
Epoch: 25 | Iteration number: [190/565] 33% | Training loss: 0.6905324462213014
Epoch: 25 | Iteration number: [200/565] 35% | Training loss: 0.6903706139326096
Epoch: 25 | Iteration number: [210/565] 37% | Training loss: 0.6902044142995561
Epoch: 25 | Iteration number: [220/565] 38% | Training loss: 0.6900393973697315
Epoch: 25 | Iteration number: [230/565] 40% | Training loss: 0.6899228248907172
Epoch: 25 | Iteration number: [240/565] 42% | Training loss: 0.6897946534057459
Epoch: 25 | Iteration number: [250/565] 44% | Training loss: 0.6896709926128387
Epoch: 25 | Iteration number: [260/565] 46% | Training loss: 0.6895658110196774
Epoch: 25 | Iteration number: [270/565] 47% | Training loss: 0.6894842490001961
Epoch: 25 | Iteration number: [280/565] 49% | Training loss: 0.6893828696438244
Epoch: 25 | Iteration number: [290/565] 51% | Training loss: 0.6892979482124592
Epoch: 25 | Iteration number: [300/565] 53% | Training loss: 0.6892143746217092
Epoch: 25 | Iteration number: [310/565] 54% | Training loss: 0.689138799905777
Epoch: 25 | Iteration number: [320/565] 56% | Training loss: 0.6890743911266327
Epoch: 25 | Iteration number: [330/565] 58% | Training loss: 0.6889985989440571
Epoch: 25 | Iteration number: [340/565] 60% | Training loss: 0.6889393136781805
Epoch: 25 | Iteration number: [350/565] 61% | Training loss: 0.6888833974088941
Epoch: 25 | Iteration number: [360/565] 63% | Training loss: 0.6888231303956773
Epoch: 25 | Iteration number: [370/565] 65% | Training loss: 0.6887790388352162
Epoch: 25 | Iteration number: [380/565] 67% | Training loss: 0.6887302817482698
Epoch: 25 | Iteration number: [390/565] 69% | Training loss: 0.6886769013527112
Epoch: 25 | Iteration number: [400/565] 70% | Training loss: 0.6886338239908218
Epoch: 25 | Iteration number: [410/565] 72% | Training loss: 0.6885942147999276
Epoch: 25 | Iteration number: [420/565] 74% | Training loss: 0.6885561633677709
Epoch: 25 | Iteration number: [430/565] 76% | Training loss: 0.6885134138340174
Epoch: 25 | Iteration number: [440/565] 77% | Training loss: 0.6884743889624422
Epoch: 25 | Iteration number: [450/565] 79% | Training loss: 0.6884458026621076
Epoch: 25 | Iteration number: [460/565] 81% | Training loss: 0.6884242324725441
Epoch: 25 | Iteration number: [470/565] 83% | Training loss: 0.6883896289987766
Epoch: 25 | Iteration number: [480/565] 84% | Training loss: 0.6883591650674741
Epoch: 25 | Iteration number: [490/565] 86% | Training loss: 0.6883298721848702
Epoch: 25 | Iteration number: [500/565] 88% | Training loss: 0.6882977324724198
Epoch: 25 | Iteration number: [510/565] 90% | Training loss: 0.6882752961972181
Epoch: 25 | Iteration number: [520/565] 92% | Training loss: 0.6882535794606576
Epoch: 25 | Iteration number: [530/565] 93% | Training loss: 0.6882313221130731
Epoch: 25 | Iteration number: [540/565] 95% | Training loss: 0.6882068156092255
Epoch: 25 | Iteration number: [550/565] 97% | Training loss: 0.6881840665773912
Epoch: 25 | Iteration number: [560/565] 99% | Training loss: 0.6881626929555621

 End of epoch: 25 | Train Loss: 0.6869342021182575 | Training Time: 89 

 End of epoch: 25 | Eval Loss: 0.6896204778126308 | Evaluating Time: 5 
Epoch: 26 | Iteration number: [10/565] 1% | Training loss: 0.7553909122943878
Epoch: 26 | Iteration number: [20/565] 3% | Training loss: 0.7211579471826554
Epoch: 26 | Iteration number: [30/565] 5% | Training loss: 0.7097687800725301
Epoch: 26 | Iteration number: [40/565] 7% | Training loss: 0.7039298877120018
Epoch: 26 | Iteration number: [50/565] 8% | Training loss: 0.7004251539707184
Epoch: 26 | Iteration number: [60/565] 10% | Training loss: 0.6981563011805216
Epoch: 26 | Iteration number: [70/565] 12% | Training loss: 0.6965241730213165
Epoch: 26 | Iteration number: [80/565] 14% | Training loss: 0.6953891552984715
Epoch: 26 | Iteration number: [90/565] 15% | Training loss: 0.6944613145457373
Epoch: 26 | Iteration number: [100/565] 17% | Training loss: 0.6936930179595947
Epoch: 26 | Iteration number: [110/565] 19% | Training loss: 0.6930904307148673
Epoch: 26 | Iteration number: [120/565] 21% | Training loss: 0.6925642763574918
Epoch: 26 | Iteration number: [130/565] 23% | Training loss: 0.692097208591608
Epoch: 26 | Iteration number: [140/565] 24% | Training loss: 0.6917311540671758
Epoch: 26 | Iteration number: [150/565] 26% | Training loss: 0.6913951726754507
Epoch: 26 | Iteration number: [160/565] 28% | Training loss: 0.6911123890429736
Epoch: 26 | Iteration number: [170/565] 30% | Training loss: 0.6908709746949813
Epoch: 26 | Iteration number: [180/565] 31% | Training loss: 0.6906871176428265
Epoch: 26 | Iteration number: [190/565] 33% | Training loss: 0.690477592694132
Epoch: 26 | Iteration number: [200/565] 35% | Training loss: 0.6903155359625817
Epoch: 26 | Iteration number: [210/565] 37% | Training loss: 0.6901566633156367
Epoch: 26 | Iteration number: [220/565] 38% | Training loss: 0.6900068776174025
Epoch: 26 | Iteration number: [230/565] 40% | Training loss: 0.6898633109486622
Epoch: 26 | Iteration number: [240/565] 42% | Training loss: 0.6897465415298939
Epoch: 26 | Iteration number: [250/565] 44% | Training loss: 0.6896409077644348
Epoch: 26 | Iteration number: [260/565] 46% | Training loss: 0.6895465289170926
Epoch: 26 | Iteration number: [270/565] 47% | Training loss: 0.689458410165928
Epoch: 26 | Iteration number: [280/565] 49% | Training loss: 0.6893677145242691
Epoch: 26 | Iteration number: [290/565] 51% | Training loss: 0.6892681298584774
Epoch: 26 | Iteration number: [300/565] 53% | Training loss: 0.689186737537384
Epoch: 26 | Iteration number: [310/565] 54% | Training loss: 0.6891188752266668
Epoch: 26 | Iteration number: [320/565] 56% | Training loss: 0.6890635065734386
Epoch: 26 | Iteration number: [330/565] 58% | Training loss: 0.6889816547885086
Epoch: 26 | Iteration number: [340/565] 60% | Training loss: 0.6889296671923469
Epoch: 26 | Iteration number: [350/565] 61% | Training loss: 0.6888821475846427
Epoch: 26 | Iteration number: [360/565] 63% | Training loss: 0.688839599986871
Epoch: 26 | Iteration number: [370/565] 65% | Training loss: 0.6887890052151036
Epoch: 26 | Iteration number: [380/565] 67% | Training loss: 0.6887346615916804
Epoch: 26 | Iteration number: [390/565] 69% | Training loss: 0.6886831943805402
Epoch: 26 | Iteration number: [400/565] 70% | Training loss: 0.6886380204558372
Epoch: 26 | Iteration number: [410/565] 72% | Training loss: 0.6885965364735301
Epoch: 26 | Iteration number: [420/565] 74% | Training loss: 0.6885590790283113
Epoch: 26 | Iteration number: [430/565] 76% | Training loss: 0.68853000998497
Epoch: 26 | Iteration number: [440/565] 77% | Training loss: 0.6884992332621054
Epoch: 26 | Iteration number: [450/565] 79% | Training loss: 0.6884585267967648
Epoch: 26 | Iteration number: [460/565] 81% | Training loss: 0.6884327681168266
Epoch: 26 | Iteration number: [470/565] 83% | Training loss: 0.6883944412495228
Epoch: 26 | Iteration number: [480/565] 84% | Training loss: 0.6883635155856609
Epoch: 26 | Iteration number: [490/565] 86% | Training loss: 0.6883461037460639
Epoch: 26 | Iteration number: [500/565] 88% | Training loss: 0.6883191382884979
Epoch: 26 | Iteration number: [510/565] 90% | Training loss: 0.6882935189733318
Epoch: 26 | Iteration number: [520/565] 92% | Training loss: 0.6882714730042677
Epoch: 26 | Iteration number: [530/565] 93% | Training loss: 0.6882356744892192
Epoch: 26 | Iteration number: [540/565] 95% | Training loss: 0.688220508451815
Epoch: 26 | Iteration number: [550/565] 97% | Training loss: 0.6882001162659038
Epoch: 26 | Iteration number: [560/565] 99% | Training loss: 0.6881794943341187

 End of epoch: 26 | Train Loss: 0.6869491160443398 | Training Time: 89 

 End of epoch: 26 | Eval Loss: 0.6897248455456325 | Evaluating Time: 6 
Epoch: 27 | Iteration number: [10/565] 1% | Training loss: 0.7560584902763366
Epoch: 27 | Iteration number: [20/565] 3% | Training loss: 0.721297749876976
Epoch: 27 | Iteration number: [30/565] 5% | Training loss: 0.7099136610825857
Epoch: 27 | Iteration number: [40/565] 7% | Training loss: 0.7041903883218765
Epoch: 27 | Iteration number: [50/565] 8% | Training loss: 0.7005906105041504
Epoch: 27 | Iteration number: [60/565] 10% | Training loss: 0.6983333418766657
Epoch: 27 | Iteration number: [70/565] 12% | Training loss: 0.6967274640287672
Epoch: 27 | Iteration number: [80/565] 14% | Training loss: 0.6955177709460258
Epoch: 27 | Iteration number: [90/565] 15% | Training loss: 0.6945857485135396
Epoch: 27 | Iteration number: [100/565] 17% | Training loss: 0.6937973994016647
Epoch: 27 | Iteration number: [110/565] 19% | Training loss: 0.6931491700085727
Epoch: 27 | Iteration number: [120/565] 21% | Training loss: 0.6926210602124532
Epoch: 27 | Iteration number: [130/565] 23% | Training loss: 0.6921710532445174
Epoch: 27 | Iteration number: [140/565] 24% | Training loss: 0.6917954853602818
Epoch: 27 | Iteration number: [150/565] 26% | Training loss: 0.6914679916699727
Epoch: 27 | Iteration number: [160/565] 28% | Training loss: 0.6911688938736915
Epoch: 27 | Iteration number: [170/565] 30% | Training loss: 0.6909253755036522
Epoch: 27 | Iteration number: [180/565] 31% | Training loss: 0.690715456671185
Epoch: 27 | Iteration number: [190/565] 33% | Training loss: 0.690520776886689
Epoch: 27 | Iteration number: [200/565] 35% | Training loss: 0.6903452095389366
Epoch: 27 | Iteration number: [210/565] 37% | Training loss: 0.6901802179359254
Epoch: 27 | Iteration number: [220/565] 38% | Training loss: 0.6900231085040353
Epoch: 27 | Iteration number: [230/565] 40% | Training loss: 0.689883992464646
Epoch: 27 | Iteration number: [240/565] 42% | Training loss: 0.6897688416143258
Epoch: 27 | Iteration number: [250/565] 44% | Training loss: 0.6896692974567413
Epoch: 27 | Iteration number: [260/565] 46% | Training loss: 0.6895672197525318
Epoch: 27 | Iteration number: [270/565] 47% | Training loss: 0.6894639180766211
Epoch: 27 | Iteration number: [280/565] 49% | Training loss: 0.6893672049045563
Epoch: 27 | Iteration number: [290/565] 51% | Training loss: 0.6892848175147485
Epoch: 27 | Iteration number: [300/565] 53% | Training loss: 0.6892052568991979
Epoch: 27 | Iteration number: [310/565] 54% | Training loss: 0.6891277843906033
Epoch: 27 | Iteration number: [320/565] 56% | Training loss: 0.6890525141730904
Epoch: 27 | Iteration number: [330/565] 58% | Training loss: 0.6889942170995654
Epoch: 27 | Iteration number: [340/565] 60% | Training loss: 0.6889375641065485
Epoch: 27 | Iteration number: [350/565] 61% | Training loss: 0.6888843699863979
Epoch: 27 | Iteration number: [360/565] 63% | Training loss: 0.6888253152370453
Epoch: 27 | Iteration number: [370/565] 65% | Training loss: 0.688769554608577
Epoch: 27 | Iteration number: [380/565] 67% | Training loss: 0.6887210921237343
Epoch: 27 | Iteration number: [390/565] 69% | Training loss: 0.6886622497668633
Epoch: 27 | Iteration number: [400/565] 70% | Training loss: 0.6886167120933533
Epoch: 27 | Iteration number: [410/565] 72% | Training loss: 0.6885824569841711
Epoch: 27 | Iteration number: [420/565] 74% | Training loss: 0.6885431994994481
Epoch: 27 | Iteration number: [430/565] 76% | Training loss: 0.6885131375734196
Epoch: 27 | Iteration number: [440/565] 77% | Training loss: 0.6884777319702235
Epoch: 27 | Iteration number: [450/565] 79% | Training loss: 0.6884401779704624
Epoch: 27 | Iteration number: [460/565] 81% | Training loss: 0.6883992827456931
Epoch: 27 | Iteration number: [470/565] 83% | Training loss: 0.688364429549968
Epoch: 27 | Iteration number: [480/565] 84% | Training loss: 0.6883252184838057
Epoch: 27 | Iteration number: [490/565] 86% | Training loss: 0.6882984242877181
Epoch: 27 | Iteration number: [500/565] 88% | Training loss: 0.688271124958992
Epoch: 27 | Iteration number: [510/565] 90% | Training loss: 0.6882532629312254
Epoch: 27 | Iteration number: [520/565] 92% | Training loss: 0.6882382246164175
Epoch: 27 | Iteration number: [530/565] 93% | Training loss: 0.6882092793032808
Epoch: 27 | Iteration number: [540/565] 95% | Training loss: 0.6881805474007571
Epoch: 27 | Iteration number: [550/565] 97% | Training loss: 0.6881671605326912
Epoch: 27 | Iteration number: [560/565] 99% | Training loss: 0.6881490445562771

 End of epoch: 27 | Train Loss: 0.6869256575550653 | Training Time: 89 

 End of epoch: 27 | Eval Loss: 0.6895722491400582 | Evaluating Time: 6 
Epoch: 28 | Iteration number: [10/565] 1% | Training loss: 0.7559017956256866
Epoch: 28 | Iteration number: [20/565] 3% | Training loss: 0.7213719010353088
Epoch: 28 | Iteration number: [30/565] 5% | Training loss: 0.7099665621916453
Epoch: 28 | Iteration number: [40/565] 7% | Training loss: 0.7041529610753059
Epoch: 28 | Iteration number: [50/565] 8% | Training loss: 0.700760326385498
Epoch: 28 | Iteration number: [60/565] 10% | Training loss: 0.6984742313623429
Epoch: 28 | Iteration number: [70/565] 12% | Training loss: 0.6968229438577379
Epoch: 28 | Iteration number: [80/565] 14% | Training loss: 0.6955461919307708
Epoch: 28 | Iteration number: [90/565] 15% | Training loss: 0.6945411125818889
Epoch: 28 | Iteration number: [100/565] 17% | Training loss: 0.6937578320503235
Epoch: 28 | Iteration number: [110/565] 19% | Training loss: 0.6931206697767431
Epoch: 28 | Iteration number: [120/565] 21% | Training loss: 0.6926182319720586
Epoch: 28 | Iteration number: [130/565] 23% | Training loss: 0.6921755043359903
Epoch: 28 | Iteration number: [140/565] 24% | Training loss: 0.6917797459023339
Epoch: 28 | Iteration number: [150/565] 26% | Training loss: 0.6914790904521942
Epoch: 28 | Iteration number: [160/565] 28% | Training loss: 0.6912066105753183
Epoch: 28 | Iteration number: [170/565] 30% | Training loss: 0.6909614152768079
Epoch: 28 | Iteration number: [180/565] 31% | Training loss: 0.6907411161396239
Epoch: 28 | Iteration number: [190/565] 33% | Training loss: 0.6905305388726686
Epoch: 28 | Iteration number: [200/565] 35% | Training loss: 0.6903348004817963
Epoch: 28 | Iteration number: [210/565] 37% | Training loss: 0.6901639995120821
Epoch: 28 | Iteration number: [220/565] 38% | Training loss: 0.6900111160495065
Epoch: 28 | Iteration number: [230/565] 40% | Training loss: 0.6898813011853592
Epoch: 28 | Iteration number: [240/565] 42% | Training loss: 0.6897486063341299
Epoch: 28 | Iteration number: [250/565] 44% | Training loss: 0.6896237807273865
Epoch: 28 | Iteration number: [260/565] 46% | Training loss: 0.6895238699821326
Epoch: 28 | Iteration number: [270/565] 47% | Training loss: 0.6894295548951185
Epoch: 28 | Iteration number: [280/565] 49% | Training loss: 0.6893553699765886
Epoch: 28 | Iteration number: [290/565] 51% | Training loss: 0.6892860630462909
Epoch: 28 | Iteration number: [300/565] 53% | Training loss: 0.6892186123132705
Epoch: 28 | Iteration number: [310/565] 54% | Training loss: 0.6891347537117619
Epoch: 28 | Iteration number: [320/565] 56% | Training loss: 0.6890608703717589
Epoch: 28 | Iteration number: [330/565] 58% | Training loss: 0.6889903689875747
Epoch: 28 | Iteration number: [340/565] 60% | Training loss: 0.6889231532812119
Epoch: 28 | Iteration number: [350/565] 61% | Training loss: 0.6888768182482038
Epoch: 28 | Iteration number: [360/565] 63% | Training loss: 0.6888254617651304
Epoch: 28 | Iteration number: [370/565] 65% | Training loss: 0.6887829120094712
Epoch: 28 | Iteration number: [380/565] 67% | Training loss: 0.688728697833262
Epoch: 28 | Iteration number: [390/565] 69% | Training loss: 0.6886845862254118
Epoch: 28 | Iteration number: [400/565] 70% | Training loss: 0.688635800331831
Epoch: 28 | Iteration number: [410/565] 72% | Training loss: 0.6885774805778411
Epoch: 28 | Iteration number: [420/565] 74% | Training loss: 0.6885427507616225
Epoch: 28 | Iteration number: [430/565] 76% | Training loss: 0.6884975447211155
Epoch: 28 | Iteration number: [440/565] 77% | Training loss: 0.6884680073369633
Epoch: 28 | Iteration number: [450/565] 79% | Training loss: 0.6884331157472399
Epoch: 28 | Iteration number: [460/565] 81% | Training loss: 0.6883979026390159
Epoch: 28 | Iteration number: [470/565] 83% | Training loss: 0.6883684745494355
Epoch: 28 | Iteration number: [480/565] 84% | Training loss: 0.6883409230659405
Epoch: 28 | Iteration number: [490/565] 86% | Training loss: 0.6883113807561446
Epoch: 28 | Iteration number: [500/565] 88% | Training loss: 0.6882889846563339
Epoch: 28 | Iteration number: [510/565] 90% | Training loss: 0.6882663983924716
Epoch: 28 | Iteration number: [520/565] 92% | Training loss: 0.6882327759495148
Epoch: 28 | Iteration number: [530/565] 93% | Training loss: 0.6882100747441345
Epoch: 28 | Iteration number: [540/565] 95% | Training loss: 0.6881894340117772
Epoch: 28 | Iteration number: [550/565] 97% | Training loss: 0.6881705835732547
Epoch: 28 | Iteration number: [560/565] 99% | Training loss: 0.6881531201303005

 End of epoch: 28 | Train Loss: 0.6869308056029598 | Training Time: 90 

 End of epoch: 28 | Eval Loss: 0.6903343030384609 | Evaluating Time: 5 
Epoch: 29 | Iteration number: [10/565] 1% | Training loss: 0.7551368057727814
Epoch: 29 | Iteration number: [20/565] 3% | Training loss: 0.7212657570838928
Epoch: 29 | Iteration number: [30/565] 5% | Training loss: 0.7099866688251495
Epoch: 29 | Iteration number: [40/565] 7% | Training loss: 0.7042987987399101
Epoch: 29 | Iteration number: [50/565] 8% | Training loss: 0.7007997238636017
Epoch: 29 | Iteration number: [60/565] 10% | Training loss: 0.6985214600960413
Epoch: 29 | Iteration number: [70/565] 12% | Training loss: 0.6968043787138802
Epoch: 29 | Iteration number: [80/565] 14% | Training loss: 0.6956155695021152
Epoch: 29 | Iteration number: [90/565] 15% | Training loss: 0.6946580251057942
Epoch: 29 | Iteration number: [100/565] 17% | Training loss: 0.6938680559396744
Epoch: 29 | Iteration number: [110/565] 19% | Training loss: 0.693220836466009
Epoch: 29 | Iteration number: [120/565] 21% | Training loss: 0.6926730901002884
Epoch: 29 | Iteration number: [130/565] 23% | Training loss: 0.6921746955468104
Epoch: 29 | Iteration number: [140/565] 24% | Training loss: 0.6918064526149205
Epoch: 29 | Iteration number: [150/565] 26% | Training loss: 0.691476061741511
Epoch: 29 | Iteration number: [160/565] 28% | Training loss: 0.6911887042224407
Epoch: 29 | Iteration number: [170/565] 30% | Training loss: 0.6909565792364233
Epoch: 29 | Iteration number: [180/565] 31% | Training loss: 0.6907251967324151
Epoch: 29 | Iteration number: [190/565] 33% | Training loss: 0.6905223027655952
Epoch: 29 | Iteration number: [200/565] 35% | Training loss: 0.6903284052014351
Epoch: 29 | Iteration number: [210/565] 37% | Training loss: 0.6901470922288441
Epoch: 29 | Iteration number: [220/565] 38% | Training loss: 0.6899814069271087
Epoch: 29 | Iteration number: [230/565] 40% | Training loss: 0.6898726313010506
Epoch: 29 | Iteration number: [240/565] 42% | Training loss: 0.6897520571947098
Epoch: 29 | Iteration number: [250/565] 44% | Training loss: 0.6896368961334228
Epoch: 29 | Iteration number: [260/565] 46% | Training loss: 0.689529526921419
Epoch: 29 | Iteration number: [270/565] 47% | Training loss: 0.6894392322610926
Epoch: 29 | Iteration number: [280/565] 49% | Training loss: 0.6893352150917054
Epoch: 29 | Iteration number: [290/565] 51% | Training loss: 0.6892566744623513
Epoch: 29 | Iteration number: [300/565] 53% | Training loss: 0.6891900306940079
Epoch: 29 | Iteration number: [310/565] 54% | Training loss: 0.6891189111817267
Epoch: 29 | Iteration number: [320/565] 56% | Training loss: 0.6890624912455678
Epoch: 29 | Iteration number: [330/565] 58% | Training loss: 0.6889774589827566
Epoch: 29 | Iteration number: [340/565] 60% | Training loss: 0.6889088409788469
Epoch: 29 | Iteration number: [350/565] 61% | Training loss: 0.6888475162642342
Epoch: 29 | Iteration number: [360/565] 63% | Training loss: 0.6887988953126801
Epoch: 29 | Iteration number: [370/565] 65% | Training loss: 0.6887499464524759
Epoch: 29 | Iteration number: [380/565] 67% | Training loss: 0.6887019762867376
Epoch: 29 | Iteration number: [390/565] 69% | Training loss: 0.6886681929612771
Epoch: 29 | Iteration number: [400/565] 70% | Training loss: 0.6886289547383785
Epoch: 29 | Iteration number: [410/565] 72% | Training loss: 0.6885848673378548
Epoch: 29 | Iteration number: [420/565] 74% | Training loss: 0.6885424592665264
Epoch: 29 | Iteration number: [430/565] 76% | Training loss: 0.6885091082994328
Epoch: 29 | Iteration number: [440/565] 77% | Training loss: 0.6884749846024947
Epoch: 29 | Iteration number: [450/565] 79% | Training loss: 0.6884414972199334
Epoch: 29 | Iteration number: [460/565] 81% | Training loss: 0.6884022768424904
Epoch: 29 | Iteration number: [470/565] 83% | Training loss: 0.6883755350366552
Epoch: 29 | Iteration number: [480/565] 84% | Training loss: 0.6883542622129123
Epoch: 29 | Iteration number: [490/565] 86% | Training loss: 0.6883177230552752
Epoch: 29 | Iteration number: [500/565] 88% | Training loss: 0.6882834457159043
Epoch: 29 | Iteration number: [510/565] 90% | Training loss: 0.6882603084339814
Epoch: 29 | Iteration number: [520/565] 92% | Training loss: 0.6882377399848058
Epoch: 29 | Iteration number: [530/565] 93% | Training loss: 0.6882158737137632
Epoch: 29 | Iteration number: [540/565] 95% | Training loss: 0.6881909802004144
Epoch: 29 | Iteration number: [550/565] 97% | Training loss: 0.6881615683165464
Epoch: 29 | Iteration number: [560/565] 99% | Training loss: 0.6881335842822279

 End of epoch: 29 | Train Loss: 0.6869129145039922 | Training Time: 88 

 End of epoch: 29 | Eval Loss: 0.6901696750095913 | Evaluating Time: 5 
Epoch: 30 | Iteration number: [10/565] 1% | Training loss: 0.7553353667259216
Epoch: 30 | Iteration number: [20/565] 3% | Training loss: 0.7209935873746872
Epoch: 30 | Iteration number: [30/565] 5% | Training loss: 0.709650707244873
Epoch: 30 | Iteration number: [40/565] 7% | Training loss: 0.7039626523852348
Epoch: 30 | Iteration number: [50/565] 8% | Training loss: 0.700491179227829
Epoch: 30 | Iteration number: [60/565] 10% | Training loss: 0.6981683353583018
Epoch: 30 | Iteration number: [70/565] 12% | Training loss: 0.6965158155986241
Epoch: 30 | Iteration number: [80/565] 14% | Training loss: 0.6953122667968273
Epoch: 30 | Iteration number: [90/565] 15% | Training loss: 0.6943474782837762
Epoch: 30 | Iteration number: [100/565] 17% | Training loss: 0.6935686790943145
Epoch: 30 | Iteration number: [110/565] 19% | Training loss: 0.6929723018949682
Epoch: 30 | Iteration number: [120/565] 21% | Training loss: 0.692449475824833
Epoch: 30 | Iteration number: [130/565] 23% | Training loss: 0.6920142590999603
Epoch: 30 | Iteration number: [140/565] 24% | Training loss: 0.6916378344808306
Epoch: 30 | Iteration number: [150/565] 26% | Training loss: 0.6913548620541891
Epoch: 30 | Iteration number: [160/565] 28% | Training loss: 0.6910772543400526
Epoch: 30 | Iteration number: [170/565] 30% | Training loss: 0.6908220206989961
Epoch: 30 | Iteration number: [180/565] 31% | Training loss: 0.6906115472316742
Epoch: 30 | Iteration number: [190/565] 33% | Training loss: 0.6904245235418018
Epoch: 30 | Iteration number: [200/565] 35% | Training loss: 0.6902624976634979
Epoch: 30 | Iteration number: [210/565] 37% | Training loss: 0.6901054808071682
Epoch: 30 | Iteration number: [220/565] 38% | Training loss: 0.689971649646759
Epoch: 30 | Iteration number: [230/565] 40% | Training loss: 0.6898559274880782
Epoch: 30 | Iteration number: [240/565] 42% | Training loss: 0.6897255132595698
Epoch: 30 | Iteration number: [250/565] 44% | Training loss: 0.6896350114345551
Epoch: 30 | Iteration number: [260/565] 46% | Training loss: 0.6895496572439487
Epoch: 30 | Iteration number: [270/565] 47% | Training loss: 0.6894411952407272
Epoch: 30 | Iteration number: [280/565] 49% | Training loss: 0.6893473156860896
Epoch: 30 | Iteration number: [290/565] 51% | Training loss: 0.6892692181570776
Epoch: 30 | Iteration number: [300/565] 53% | Training loss: 0.6891920588413875
Epoch: 30 | Iteration number: [310/565] 54% | Training loss: 0.6891119651256069
Epoch: 30 | Iteration number: [320/565] 56% | Training loss: 0.6890492852777242
Epoch: 30 | Iteration number: [330/565] 58% | Training loss: 0.6889724081212824
Epoch: 30 | Iteration number: [340/565] 60% | Training loss: 0.6889021354563096
Epoch: 30 | Iteration number: [350/565] 61% | Training loss: 0.6888496341024126
Epoch: 30 | Iteration number: [360/565] 63% | Training loss: 0.6887870550155639
Epoch: 30 | Iteration number: [370/565] 65% | Training loss: 0.6887328123724138
Epoch: 30 | Iteration number: [380/565] 67% | Training loss: 0.6886799589583749
Epoch: 30 | Iteration number: [390/565] 69% | Training loss: 0.6886381441201919
Epoch: 30 | Iteration number: [400/565] 70% | Training loss: 0.6885877826809883
Epoch: 30 | Iteration number: [410/565] 72% | Training loss: 0.6885558632815757
Epoch: 30 | Iteration number: [420/565] 74% | Training loss: 0.6885275476035617
Epoch: 30 | Iteration number: [430/565] 76% | Training loss: 0.6884987326555474
Epoch: 30 | Iteration number: [440/565] 77% | Training loss: 0.6884639754891395
Epoch: 30 | Iteration number: [450/565] 79% | Training loss: 0.6884277935822805
Epoch: 30 | Iteration number: [460/565] 81% | Training loss: 0.6884016345376553
Epoch: 30 | Iteration number: [470/565] 83% | Training loss: 0.688376373052597
Epoch: 30 | Iteration number: [480/565] 84% | Training loss: 0.6883429492513339
Epoch: 30 | Iteration number: [490/565] 86% | Training loss: 0.6883211263588497
Epoch: 30 | Iteration number: [500/565] 88% | Training loss: 0.6882909154891967
Epoch: 30 | Iteration number: [510/565] 90% | Training loss: 0.6882644779541913
Epoch: 30 | Iteration number: [520/565] 92% | Training loss: 0.6882347016380383
Epoch: 30 | Iteration number: [530/565] 93% | Training loss: 0.6882226960838965
Epoch: 30 | Iteration number: [540/565] 95% | Training loss: 0.6881940903487029
Epoch: 30 | Iteration number: [550/565] 97% | Training loss: 0.6881666885722767
Epoch: 30 | Iteration number: [560/565] 99% | Training loss: 0.6881464034318924

 End of epoch: 30 | Train Loss: 0.6869147334478598 | Training Time: 88 

 End of epoch: 30 | Eval Loss: 0.6901180233274188 | Evaluating Time: 6 
Epoch: 31 | Iteration number: [10/565] 1% | Training loss: 0.7559770047664642
Epoch: 31 | Iteration number: [20/565] 3% | Training loss: 0.7212644100189209
Epoch: 31 | Iteration number: [30/565] 5% | Training loss: 0.709642376502355
Epoch: 31 | Iteration number: [40/565] 7% | Training loss: 0.7039886593818665
Epoch: 31 | Iteration number: [50/565] 8% | Training loss: 0.7005484306812286
Epoch: 31 | Iteration number: [60/565] 10% | Training loss: 0.698265383640925
Epoch: 31 | Iteration number: [70/565] 12% | Training loss: 0.6966778218746186
Epoch: 31 | Iteration number: [80/565] 14% | Training loss: 0.6954612269997597
Epoch: 31 | Iteration number: [90/565] 15% | Training loss: 0.694524124595854
Epoch: 31 | Iteration number: [100/565] 17% | Training loss: 0.6937821215391159
Epoch: 31 | Iteration number: [110/565] 19% | Training loss: 0.6931386254050514
Epoch: 31 | Iteration number: [120/565] 21% | Training loss: 0.69260044246912
Epoch: 31 | Iteration number: [130/565] 23% | Training loss: 0.6921392330756554
Epoch: 31 | Iteration number: [140/565] 24% | Training loss: 0.6917417334658759
Epoch: 31 | Iteration number: [150/565] 26% | Training loss: 0.6914251764615377
Epoch: 31 | Iteration number: [160/565] 28% | Training loss: 0.6911417350172997
Epoch: 31 | Iteration number: [170/565] 30% | Training loss: 0.690902377577389
Epoch: 31 | Iteration number: [180/565] 31% | Training loss: 0.69067658815119
Epoch: 31 | Iteration number: [190/565] 33% | Training loss: 0.6904651563418539
Epoch: 31 | Iteration number: [200/565] 35% | Training loss: 0.6902962121367454
Epoch: 31 | Iteration number: [210/565] 37% | Training loss: 0.6901163461662474
Epoch: 31 | Iteration number: [220/565] 38% | Training loss: 0.689982733130455
Epoch: 31 | Iteration number: [230/565] 40% | Training loss: 0.6898408091586569
Epoch: 31 | Iteration number: [240/565] 42% | Training loss: 0.6897046181062857
Epoch: 31 | Iteration number: [250/565] 44% | Training loss: 0.6895964283943177
Epoch: 31 | Iteration number: [260/565] 46% | Training loss: 0.6895113777655821
Epoch: 31 | Iteration number: [270/565] 47% | Training loss: 0.6894290173495258
Epoch: 31 | Iteration number: [280/565] 49% | Training loss: 0.689328542990344
Epoch: 31 | Iteration number: [290/565] 51% | Training loss: 0.6892492226485548
Epoch: 31 | Iteration number: [300/565] 53% | Training loss: 0.6891601765155793
Epoch: 31 | Iteration number: [310/565] 54% | Training loss: 0.689083005343714
Epoch: 31 | Iteration number: [320/565] 56% | Training loss: 0.6890107005834579
Epoch: 31 | Iteration number: [330/565] 58% | Training loss: 0.6889660354816552
Epoch: 31 | Iteration number: [340/565] 60% | Training loss: 0.6889090247013989
Epoch: 31 | Iteration number: [350/565] 61% | Training loss: 0.6888430557932173
Epoch: 31 | Iteration number: [360/565] 63% | Training loss: 0.6887963124447398
Epoch: 31 | Iteration number: [370/565] 65% | Training loss: 0.6887471429399542
Epoch: 31 | Iteration number: [380/565] 67% | Training loss: 0.6887014069055256
Epoch: 31 | Iteration number: [390/565] 69% | Training loss: 0.6886519574202024
Epoch: 31 | Iteration number: [400/565] 70% | Training loss: 0.688608701378107
Epoch: 31 | Iteration number: [410/565] 72% | Training loss: 0.6885635714705397
Epoch: 31 | Iteration number: [420/565] 74% | Training loss: 0.6885377930743354
Epoch: 31 | Iteration number: [430/565] 76% | Training loss: 0.6884958547215129
Epoch: 31 | Iteration number: [440/565] 77% | Training loss: 0.6884538222442974
Epoch: 31 | Iteration number: [450/565] 79% | Training loss: 0.688416468832228
Epoch: 31 | Iteration number: [460/565] 81% | Training loss: 0.6883779562037924
Epoch: 31 | Iteration number: [470/565] 83% | Training loss: 0.6883531999080739
Epoch: 31 | Iteration number: [480/565] 84% | Training loss: 0.6883252369860808
Epoch: 31 | Iteration number: [490/565] 86% | Training loss: 0.6882971302587159
Epoch: 31 | Iteration number: [500/565] 88% | Training loss: 0.6882695986032485
Epoch: 31 | Iteration number: [510/565] 90% | Training loss: 0.688237929577921
Epoch: 31 | Iteration number: [520/565] 92% | Training loss: 0.688219904097227
Epoch: 31 | Iteration number: [530/565] 93% | Training loss: 0.6881856111985333
Epoch: 31 | Iteration number: [540/565] 95% | Training loss: 0.688168798883756
Epoch: 31 | Iteration number: [550/565] 97% | Training loss: 0.6881507806344466
Epoch: 31 | Iteration number: [560/565] 99% | Training loss: 0.6881264372595719

 End of epoch: 31 | Train Loss: 0.6868975923124668 | Training Time: 89 

 End of epoch: 31 | Eval Loss: 0.68979469367436 | Evaluating Time: 6 
Epoch: 32 | Iteration number: [10/565] 1% | Training loss: 0.755881804227829
Epoch: 32 | Iteration number: [20/565] 3% | Training loss: 0.7215701013803482
Epoch: 32 | Iteration number: [30/565] 5% | Training loss: 0.7100324908892314
Epoch: 32 | Iteration number: [40/565] 7% | Training loss: 0.7043067798018455
Epoch: 32 | Iteration number: [50/565] 8% | Training loss: 0.7008021926879883
Epoch: 32 | Iteration number: [60/565] 10% | Training loss: 0.6984784533580144
Epoch: 32 | Iteration number: [70/565] 12% | Training loss: 0.6967738040855953
Epoch: 32 | Iteration number: [80/565] 14% | Training loss: 0.6955372951924801
Epoch: 32 | Iteration number: [90/565] 15% | Training loss: 0.6945659663942125
Epoch: 32 | Iteration number: [100/565] 17% | Training loss: 0.6937345564365387
Epoch: 32 | Iteration number: [110/565] 19% | Training loss: 0.6931622299281034
Epoch: 32 | Iteration number: [120/565] 21% | Training loss: 0.6926705007751782
Epoch: 32 | Iteration number: [130/565] 23% | Training loss: 0.6922213944105001
Epoch: 32 | Iteration number: [140/565] 24% | Training loss: 0.6918219379016332
Epoch: 32 | Iteration number: [150/565] 26% | Training loss: 0.6914831598599752
Epoch: 32 | Iteration number: [160/565] 28% | Training loss: 0.6911598805338144
Epoch: 32 | Iteration number: [170/565] 30% | Training loss: 0.690904088230694
Epoch: 32 | Iteration number: [180/565] 31% | Training loss: 0.6907005439201991
Epoch: 32 | Iteration number: [190/565] 33% | Training loss: 0.6905002305382176
Epoch: 32 | Iteration number: [200/565] 35% | Training loss: 0.6903311601281166
Epoch: 32 | Iteration number: [210/565] 37% | Training loss: 0.6901729961236318
Epoch: 32 | Iteration number: [220/565] 38% | Training loss: 0.6900058155710047
Epoch: 32 | Iteration number: [230/565] 40% | Training loss: 0.6898686911748804
Epoch: 32 | Iteration number: [240/565] 42% | Training loss: 0.6897547483444214
Epoch: 32 | Iteration number: [250/565] 44% | Training loss: 0.6896371121406555
Epoch: 32 | Iteration number: [260/565] 46% | Training loss: 0.6895306713305986
Epoch: 32 | Iteration number: [270/565] 47% | Training loss: 0.6894396706863686
Epoch: 32 | Iteration number: [280/565] 49% | Training loss: 0.6893463890467372
Epoch: 32 | Iteration number: [290/565] 51% | Training loss: 0.689263253581935
Epoch: 32 | Iteration number: [300/565] 53% | Training loss: 0.6891797250509262
Epoch: 32 | Iteration number: [310/565] 54% | Training loss: 0.6891050211844906
Epoch: 32 | Iteration number: [320/565] 56% | Training loss: 0.6890334486961365
Epoch: 32 | Iteration number: [330/565] 58% | Training loss: 0.6889717409105012
Epoch: 32 | Iteration number: [340/565] 60% | Training loss: 0.6889015125877717
Epoch: 32 | Iteration number: [350/565] 61% | Training loss: 0.6888491387026651
Epoch: 32 | Iteration number: [360/565] 63% | Training loss: 0.6887922485669454
Epoch: 32 | Iteration number: [370/565] 65% | Training loss: 0.6887441931544124
Epoch: 32 | Iteration number: [380/565] 67% | Training loss: 0.688691026286075
Epoch: 32 | Iteration number: [390/565] 69% | Training loss: 0.6886555453141531
Epoch: 32 | Iteration number: [400/565] 70% | Training loss: 0.6886171807348728
Epoch: 32 | Iteration number: [410/565] 72% | Training loss: 0.6885778305007191
Epoch: 32 | Iteration number: [420/565] 74% | Training loss: 0.6885413351513091
Epoch: 32 | Iteration number: [430/565] 76% | Training loss: 0.6885125649529834
Epoch: 32 | Iteration number: [440/565] 77% | Training loss: 0.6884866837750782
Epoch: 32 | Iteration number: [450/565] 79% | Training loss: 0.6884389927652147
Epoch: 32 | Iteration number: [460/565] 81% | Training loss: 0.6884051883998125
Epoch: 32 | Iteration number: [470/565] 83% | Training loss: 0.6883707641287052
Epoch: 32 | Iteration number: [480/565] 84% | Training loss: 0.6883410786588987
Epoch: 32 | Iteration number: [490/565] 86% | Training loss: 0.6883043582342109
Epoch: 32 | Iteration number: [500/565] 88% | Training loss: 0.6882801017761231
Epoch: 32 | Iteration number: [510/565] 90% | Training loss: 0.6882484984164144
Epoch: 32 | Iteration number: [520/565] 92% | Training loss: 0.6882287151538409
Epoch: 32 | Iteration number: [530/565] 93% | Training loss: 0.6882000337231834
Epoch: 32 | Iteration number: [540/565] 95% | Training loss: 0.6881794957099138
Epoch: 32 | Iteration number: [550/565] 97% | Training loss: 0.688152280070565
Epoch: 32 | Iteration number: [560/565] 99% | Training loss: 0.6881246888211795

 End of epoch: 32 | Train Loss: 0.6868974882944495 | Training Time: 88 

 End of epoch: 32 | Eval Loss: 0.6900235159056527 | Evaluating Time: 6 
Epoch: 33 | Iteration number: [10/565] 1% | Training loss: 0.7553403973579407
Epoch: 33 | Iteration number: [20/565] 3% | Training loss: 0.7211266249418259
Epoch: 33 | Iteration number: [30/565] 5% | Training loss: 0.7098076581954956
Epoch: 33 | Iteration number: [40/565] 7% | Training loss: 0.704176840186119
Epoch: 33 | Iteration number: [50/565] 8% | Training loss: 0.700703284740448
Epoch: 33 | Iteration number: [60/565] 10% | Training loss: 0.698395703236262
Epoch: 33 | Iteration number: [70/565] 12% | Training loss: 0.6968799565519606
Epoch: 33 | Iteration number: [80/565] 14% | Training loss: 0.6956530563533306
Epoch: 33 | Iteration number: [90/565] 15% | Training loss: 0.6946721480952369
Epoch: 33 | Iteration number: [100/565] 17% | Training loss: 0.6939088356494904
Epoch: 33 | Iteration number: [110/565] 19% | Training loss: 0.6932892951098355
Epoch: 33 | Iteration number: [120/565] 21% | Training loss: 0.6927549948294958
Epoch: 33 | Iteration number: [130/565] 23% | Training loss: 0.692314847616049
Epoch: 33 | Iteration number: [140/565] 24% | Training loss: 0.6919397264719009
Epoch: 33 | Iteration number: [150/565] 26% | Training loss: 0.6916117084026336
Epoch: 33 | Iteration number: [160/565] 28% | Training loss: 0.6913301017135381
Epoch: 33 | Iteration number: [170/565] 30% | Training loss: 0.6910537088618559
Epoch: 33 | Iteration number: [180/565] 31% | Training loss: 0.6908233046531678
Epoch: 33 | Iteration number: [190/565] 33% | Training loss: 0.6906103510605661
Epoch: 33 | Iteration number: [200/565] 35% | Training loss: 0.6904275330901146
Epoch: 33 | Iteration number: [210/565] 37% | Training loss: 0.690252472389312
Epoch: 33 | Iteration number: [220/565] 38% | Training loss: 0.6901056877591393
Epoch: 33 | Iteration number: [230/565] 40% | Training loss: 0.6899562260378962
Epoch: 33 | Iteration number: [240/565] 42% | Training loss: 0.6898338181277116
Epoch: 33 | Iteration number: [250/565] 44% | Training loss: 0.6897082755565643
Epoch: 33 | Iteration number: [260/565] 46% | Training loss: 0.6895992217155603
Epoch: 33 | Iteration number: [270/565] 47% | Training loss: 0.6894787260779628
Epoch: 33 | Iteration number: [280/565] 49% | Training loss: 0.6893753420029368
Epoch: 33 | Iteration number: [290/565] 51% | Training loss: 0.689294844865799
Epoch: 33 | Iteration number: [300/565] 53% | Training loss: 0.689230790734291
Epoch: 33 | Iteration number: [310/565] 54% | Training loss: 0.6891476288918525
Epoch: 33 | Iteration number: [320/565] 56% | Training loss: 0.6890777084976435
Epoch: 33 | Iteration number: [330/565] 58% | Training loss: 0.6890174490032774
Epoch: 33 | Iteration number: [340/565] 60% | Training loss: 0.6889488739125869
Epoch: 33 | Iteration number: [350/565] 61% | Training loss: 0.6889004710742406
Epoch: 33 | Iteration number: [360/565] 63% | Training loss: 0.6888357349567943
Epoch: 33 | Iteration number: [370/565] 65% | Training loss: 0.6887860646118988
Epoch: 33 | Iteration number: [380/565] 67% | Training loss: 0.6887380308226535
Epoch: 33 | Iteration number: [390/565] 69% | Training loss: 0.6887008546254574
Epoch: 33 | Iteration number: [400/565] 70% | Training loss: 0.6886530248820781
Epoch: 33 | Iteration number: [410/565] 72% | Training loss: 0.6886135464761315
Epoch: 33 | Iteration number: [420/565] 74% | Training loss: 0.688576351035209
Epoch: 33 | Iteration number: [430/565] 76% | Training loss: 0.6885364194248997
Epoch: 33 | Iteration number: [440/565] 77% | Training loss: 0.6885003084486181
Epoch: 33 | Iteration number: [450/565] 79% | Training loss: 0.6884737401538426
Epoch: 33 | Iteration number: [460/565] 81% | Training loss: 0.6884233152088912
Epoch: 33 | Iteration number: [470/565] 83% | Training loss: 0.6883894667980519
Epoch: 33 | Iteration number: [480/565] 84% | Training loss: 0.6883598394691944
Epoch: 33 | Iteration number: [490/565] 86% | Training loss: 0.6883345801003126
Epoch: 33 | Iteration number: [500/565] 88% | Training loss: 0.6883131265640259
Epoch: 33 | Iteration number: [510/565] 90% | Training loss: 0.688285754591811
Epoch: 33 | Iteration number: [520/565] 92% | Training loss: 0.6882528772720924
Epoch: 33 | Iteration number: [530/565] 93% | Training loss: 0.6882207617444812
Epoch: 33 | Iteration number: [540/565] 95% | Training loss: 0.6882000137258459
Epoch: 33 | Iteration number: [550/565] 97% | Training loss: 0.6881787626309829
Epoch: 33 | Iteration number: [560/565] 99% | Training loss: 0.6881564463887896

 End of epoch: 33 | Train Loss: 0.6869224356339041 | Training Time: 88 

 End of epoch: 33 | Eval Loss: 0.6900448288236346 | Evaluating Time: 6 
Epoch: 34 | Iteration number: [10/565] 1% | Training loss: 0.7559549808502197
Epoch: 34 | Iteration number: [20/565] 3% | Training loss: 0.7214763283729553
Epoch: 34 | Iteration number: [30/565] 5% | Training loss: 0.7097927848498027
Epoch: 34 | Iteration number: [40/565] 7% | Training loss: 0.7040788695216179
Epoch: 34 | Iteration number: [50/565] 8% | Training loss: 0.7006299483776093
Epoch: 34 | Iteration number: [60/565] 10% | Training loss: 0.6983348766962687
Epoch: 34 | Iteration number: [70/565] 12% | Training loss: 0.6967289115701403
Epoch: 34 | Iteration number: [80/565] 14% | Training loss: 0.6954629026353359
Epoch: 34 | Iteration number: [90/565] 15% | Training loss: 0.6945305003060235
Epoch: 34 | Iteration number: [100/565] 17% | Training loss: 0.6937872707843781
Epoch: 34 | Iteration number: [110/565] 19% | Training loss: 0.693154263496399
Epoch: 34 | Iteration number: [120/565] 21% | Training loss: 0.6926123137275378
Epoch: 34 | Iteration number: [130/565] 23% | Training loss: 0.6921516785254845
Epoch: 34 | Iteration number: [140/565] 24% | Training loss: 0.6917794810874122
Epoch: 34 | Iteration number: [150/565] 26% | Training loss: 0.6914436622460683
Epoch: 34 | Iteration number: [160/565] 28% | Training loss: 0.6911727152764797
Epoch: 34 | Iteration number: [170/565] 30% | Training loss: 0.6909283041954041
Epoch: 34 | Iteration number: [180/565] 31% | Training loss: 0.6906907257106569
Epoch: 34 | Iteration number: [190/565] 33% | Training loss: 0.6904687853235948
Epoch: 34 | Iteration number: [200/565] 35% | Training loss: 0.6902992516756058
Epoch: 34 | Iteration number: [210/565] 37% | Training loss: 0.6901490370432536
Epoch: 34 | Iteration number: [220/565] 38% | Training loss: 0.6899959640069442
Epoch: 34 | Iteration number: [230/565] 40% | Training loss: 0.6898457625637884
Epoch: 34 | Iteration number: [240/565] 42% | Training loss: 0.6897258522609869
Epoch: 34 | Iteration number: [250/565] 44% | Training loss: 0.689607962846756
Epoch: 34 | Iteration number: [260/565] 46% | Training loss: 0.689497242982571
Epoch: 34 | Iteration number: [270/565] 47% | Training loss: 0.689396811414648
Epoch: 34 | Iteration number: [280/565] 49% | Training loss: 0.6893050911171096
Epoch: 34 | Iteration number: [290/565] 51% | Training loss: 0.6892209482604059
Epoch: 34 | Iteration number: [300/565] 53% | Training loss: 0.6891330190499624
Epoch: 34 | Iteration number: [310/565] 54% | Training loss: 0.6890710405765041
Epoch: 34 | Iteration number: [320/565] 56% | Training loss: 0.6890056917443872
Epoch: 34 | Iteration number: [330/565] 58% | Training loss: 0.688946667765126
Epoch: 34 | Iteration number: [340/565] 60% | Training loss: 0.6888849112917396
Epoch: 34 | Iteration number: [350/565] 61% | Training loss: 0.6888325847898211
Epoch: 34 | Iteration number: [360/565] 63% | Training loss: 0.6887855355938276
Epoch: 34 | Iteration number: [370/565] 65% | Training loss: 0.6887394874482542
Epoch: 34 | Iteration number: [380/565] 67% | Training loss: 0.6886997066046062
Epoch: 34 | Iteration number: [390/565] 69% | Training loss: 0.6886532106460669
Epoch: 34 | Iteration number: [400/565] 70% | Training loss: 0.6886043485999107
Epoch: 34 | Iteration number: [410/565] 72% | Training loss: 0.688558591284403
Epoch: 34 | Iteration number: [420/565] 74% | Training loss: 0.688515377612341
Epoch: 34 | Iteration number: [430/565] 76% | Training loss: 0.6884774891443031
Epoch: 34 | Iteration number: [440/565] 77% | Training loss: 0.6884495263749902
Epoch: 34 | Iteration number: [450/565] 79% | Training loss: 0.6884155344963073
Epoch: 34 | Iteration number: [460/565] 81% | Training loss: 0.6883891915497573
Epoch: 34 | Iteration number: [470/565] 83% | Training loss: 0.688357970562387
Epoch: 34 | Iteration number: [480/565] 84% | Training loss: 0.6883252999434869
Epoch: 34 | Iteration number: [490/565] 86% | Training loss: 0.6882970226054289
Epoch: 34 | Iteration number: [500/565] 88% | Training loss: 0.6882638684511184
Epoch: 34 | Iteration number: [510/565] 90% | Training loss: 0.6882336073061999
Epoch: 34 | Iteration number: [520/565] 92% | Training loss: 0.6882053095560807
Epoch: 34 | Iteration number: [530/565] 93% | Training loss: 0.6881801009178161
Epoch: 34 | Iteration number: [540/565] 95% | Training loss: 0.6881523349770793
Epoch: 34 | Iteration number: [550/565] 97% | Training loss: 0.6881228941137141
Epoch: 34 | Iteration number: [560/565] 99% | Training loss: 0.6880978111709867

 End of epoch: 34 | Train Loss: 0.6868750015191273 | Training Time: 90 

 End of epoch: 34 | Eval Loss: 0.6897318874086652 | Evaluating Time: 5 
Epoch: 35 | Iteration number: [10/565] 1% | Training loss: 0.7555772662162781
Epoch: 35 | Iteration number: [20/565] 3% | Training loss: 0.7212286472320557
Epoch: 35 | Iteration number: [30/565] 5% | Training loss: 0.7098066707452139
Epoch: 35 | Iteration number: [40/565] 7% | Training loss: 0.7041245266795159
Epoch: 35 | Iteration number: [50/565] 8% | Training loss: 0.7006926608085632
Epoch: 35 | Iteration number: [60/565] 10% | Training loss: 0.6983679691950481
Epoch: 35 | Iteration number: [70/565] 12% | Training loss: 0.6967322434697832
Epoch: 35 | Iteration number: [80/565] 14% | Training loss: 0.6954401560127735
Epoch: 35 | Iteration number: [90/565] 15% | Training loss: 0.6944608006212446
Epoch: 35 | Iteration number: [100/565] 17% | Training loss: 0.6937691098451615
Epoch: 35 | Iteration number: [110/565] 19% | Training loss: 0.6931144600564784
Epoch: 35 | Iteration number: [120/565] 21% | Training loss: 0.6926169489820798
Epoch: 35 | Iteration number: [130/565] 23% | Training loss: 0.6921485515741201
Epoch: 35 | Iteration number: [140/565] 24% | Training loss: 0.6917631506919861
Epoch: 35 | Iteration number: [150/565] 26% | Training loss: 0.6914487107594808
Epoch: 35 | Iteration number: [160/565] 28% | Training loss: 0.6912127461284399
Epoch: 35 | Iteration number: [170/565] 30% | Training loss: 0.6909443539731642
Epoch: 35 | Iteration number: [180/565] 31% | Training loss: 0.6907330006361008
Epoch: 35 | Iteration number: [190/565] 33% | Training loss: 0.690502582412017
Epoch: 35 | Iteration number: [200/565] 35% | Training loss: 0.6902982032299042
Epoch: 35 | Iteration number: [210/565] 37% | Training loss: 0.6901338892323631
Epoch: 35 | Iteration number: [220/565] 38% | Training loss: 0.6899769867008383
Epoch: 35 | Iteration number: [230/565] 40% | Training loss: 0.6898321009200552
Epoch: 35 | Iteration number: [240/565] 42% | Training loss: 0.689737873027722
Epoch: 35 | Iteration number: [250/565] 44% | Training loss: 0.6896129143238068
Epoch: 35 | Iteration number: [260/565] 46% | Training loss: 0.6895000299582115
Epoch: 35 | Iteration number: [270/565] 47% | Training loss: 0.689399293396208
Epoch: 35 | Iteration number: [280/565] 49% | Training loss: 0.6893018956695284
Epoch: 35 | Iteration number: [290/565] 51% | Training loss: 0.6892311272950008
Epoch: 35 | Iteration number: [300/565] 53% | Training loss: 0.6891411389907202
Epoch: 35 | Iteration number: [310/565] 54% | Training loss: 0.6890757068510979
Epoch: 35 | Iteration number: [320/565] 56% | Training loss: 0.6890191396698355
Epoch: 35 | Iteration number: [330/565] 58% | Training loss: 0.6889544761542118
Epoch: 35 | Iteration number: [340/565] 60% | Training loss: 0.6888980586739147
Epoch: 35 | Iteration number: [350/565] 61% | Training loss: 0.6888425171375274
Epoch: 35 | Iteration number: [360/565] 63% | Training loss: 0.6887985931502448
Epoch: 35 | Iteration number: [370/565] 65% | Training loss: 0.6887449269359176
Epoch: 35 | Iteration number: [380/565] 67% | Training loss: 0.6886908582950894
Epoch: 35 | Iteration number: [390/565] 69% | Training loss: 0.6886475599729098
Epoch: 35 | Iteration number: [400/565] 70% | Training loss: 0.6886034390330315
Epoch: 35 | Iteration number: [410/565] 72% | Training loss: 0.688557426667795
Epoch: 35 | Iteration number: [420/565] 74% | Training loss: 0.6885197840985797
Epoch: 35 | Iteration number: [430/565] 76% | Training loss: 0.6884807321914407
Epoch: 35 | Iteration number: [440/565] 77% | Training loss: 0.6884428371082653
Epoch: 35 | Iteration number: [450/565] 79% | Training loss: 0.6884189882543352
Epoch: 35 | Iteration number: [460/565] 81% | Training loss: 0.6883873830670896
Epoch: 35 | Iteration number: [470/565] 83% | Training loss: 0.6883500096645762
Epoch: 35 | Iteration number: [480/565] 84% | Training loss: 0.6883295113841693
Epoch: 35 | Iteration number: [490/565] 86% | Training loss: 0.6883018972922345
Epoch: 35 | Iteration number: [500/565] 88% | Training loss: 0.6882734872102737
Epoch: 35 | Iteration number: [510/565] 90% | Training loss: 0.6882468605742735
Epoch: 35 | Iteration number: [520/565] 92% | Training loss: 0.6882297398952337
Epoch: 35 | Iteration number: [530/565] 93% | Training loss: 0.6881988347701307
Epoch: 35 | Iteration number: [540/565] 95% | Training loss: 0.688171328107516
Epoch: 35 | Iteration number: [550/565] 97% | Training loss: 0.6881491153890437
Epoch: 35 | Iteration number: [560/565] 99% | Training loss: 0.6881287544965744

 End of epoch: 35 | Train Loss: 0.6869041013506662 | Training Time: 89 

 End of epoch: 35 | Eval Loss: 0.6898166622434344 | Evaluating Time: 5 
Epoch: 36 | Iteration number: [10/565] 1% | Training loss: 0.7554023027420044
Epoch: 36 | Iteration number: [20/565] 3% | Training loss: 0.7213029325008392
Epoch: 36 | Iteration number: [30/565] 5% | Training loss: 0.709783281882604
Epoch: 36 | Iteration number: [40/565] 7% | Training loss: 0.7040563434362411
Epoch: 36 | Iteration number: [50/565] 8% | Training loss: 0.7007150542736054
Epoch: 36 | Iteration number: [60/565] 10% | Training loss: 0.6983822464942933
Epoch: 36 | Iteration number: [70/565] 12% | Training loss: 0.6967156844479697
Epoch: 36 | Iteration number: [80/565] 14% | Training loss: 0.6954867318272591
Epoch: 36 | Iteration number: [90/565] 15% | Training loss: 0.6945295419957903
Epoch: 36 | Iteration number: [100/565] 17% | Training loss: 0.6936935293674469
Epoch: 36 | Iteration number: [110/565] 19% | Training loss: 0.6930486608635296
Epoch: 36 | Iteration number: [120/565] 21% | Training loss: 0.6925351291894912
Epoch: 36 | Iteration number: [130/565] 23% | Training loss: 0.6921274240200336
Epoch: 36 | Iteration number: [140/565] 24% | Training loss: 0.6917303093842098
Epoch: 36 | Iteration number: [150/565] 26% | Training loss: 0.69139892578125
Epoch: 36 | Iteration number: [160/565] 28% | Training loss: 0.6911262951791286
Epoch: 36 | Iteration number: [170/565] 30% | Training loss: 0.690861665501314
Epoch: 36 | Iteration number: [180/565] 31% | Training loss: 0.6906189795997407
Epoch: 36 | Iteration number: [190/565] 33% | Training loss: 0.6904223416980945
Epoch: 36 | Iteration number: [200/565] 35% | Training loss: 0.6902451971173287
Epoch: 36 | Iteration number: [210/565] 37% | Training loss: 0.6900954578604017
Epoch: 36 | Iteration number: [220/565] 38% | Training loss: 0.6899575290354816
Epoch: 36 | Iteration number: [230/565] 40% | Training loss: 0.6898212140021117
Epoch: 36 | Iteration number: [240/565] 42% | Training loss: 0.6897019204994043
Epoch: 36 | Iteration number: [250/565] 44% | Training loss: 0.6895991470813752
Epoch: 36 | Iteration number: [260/565] 46% | Training loss: 0.6894883524913055
Epoch: 36 | Iteration number: [270/565] 47% | Training loss: 0.6893828756279415
Epoch: 36 | Iteration number: [280/565] 49% | Training loss: 0.6893078953027725
Epoch: 36 | Iteration number: [290/565] 51% | Training loss: 0.6892244256775955
Epoch: 36 | Iteration number: [300/565] 53% | Training loss: 0.6891504404942195
Epoch: 36 | Iteration number: [310/565] 54% | Training loss: 0.6890718963838393
Epoch: 36 | Iteration number: [320/565] 56% | Training loss: 0.6890132250264287
Epoch: 36 | Iteration number: [330/565] 58% | Training loss: 0.6889558181618199
Epoch: 36 | Iteration number: [340/565] 60% | Training loss: 0.6889046504217036
Epoch: 36 | Iteration number: [350/565] 61% | Training loss: 0.6888530652863639
Epoch: 36 | Iteration number: [360/565] 63% | Training loss: 0.6887866525186432
Epoch: 36 | Iteration number: [370/565] 65% | Training loss: 0.6887394072236241
Epoch: 36 | Iteration number: [380/565] 67% | Training loss: 0.6886888642060129
Epoch: 36 | Iteration number: [390/565] 69% | Training loss: 0.6886405295286423
Epoch: 36 | Iteration number: [400/565] 70% | Training loss: 0.6885966138541698
Epoch: 36 | Iteration number: [410/565] 72% | Training loss: 0.6885649026893987
Epoch: 36 | Iteration number: [420/565] 74% | Training loss: 0.6885283898739588
Epoch: 36 | Iteration number: [430/565] 76% | Training loss: 0.6884879346503768
Epoch: 36 | Iteration number: [440/565] 77% | Training loss: 0.6884475875984538
Epoch: 36 | Iteration number: [450/565] 79% | Training loss: 0.6884090129534404
Epoch: 36 | Iteration number: [460/565] 81% | Training loss: 0.6883777689674626
Epoch: 36 | Iteration number: [470/565] 83% | Training loss: 0.6883551030716998
Epoch: 36 | Iteration number: [480/565] 84% | Training loss: 0.6883232751240332
Epoch: 36 | Iteration number: [490/565] 86% | Training loss: 0.6882947770916685
Epoch: 36 | Iteration number: [500/565] 88% | Training loss: 0.6882708079814911
Epoch: 36 | Iteration number: [510/565] 90% | Training loss: 0.6882322618774339
Epoch: 36 | Iteration number: [520/565] 92% | Training loss: 0.688199174633393
Epoch: 36 | Iteration number: [530/565] 93% | Training loss: 0.6881829385487539
Epoch: 36 | Iteration number: [540/565] 95% | Training loss: 0.6881593188753834
Epoch: 36 | Iteration number: [550/565] 97% | Training loss: 0.6881351113319397
Epoch: 36 | Iteration number: [560/565] 99% | Training loss: 0.6881108907716614

 End of epoch: 36 | Train Loss: 0.686886812627843 | Training Time: 88 

 End of epoch: 36 | Eval Loss: 0.690171480178833 | Evaluating Time: 6 
Epoch: 37 | Iteration number: [10/565] 1% | Training loss: 0.755027848482132
Epoch: 37 | Iteration number: [20/565] 3% | Training loss: 0.7207622468471527
Epoch: 37 | Iteration number: [30/565] 5% | Training loss: 0.7093864579995474
Epoch: 37 | Iteration number: [40/565] 7% | Training loss: 0.7037366956472397
Epoch: 37 | Iteration number: [50/565] 8% | Training loss: 0.7003850030899048
Epoch: 37 | Iteration number: [60/565] 10% | Training loss: 0.6981415947278341
Epoch: 37 | Iteration number: [70/565] 12% | Training loss: 0.6964803065572466
Epoch: 37 | Iteration number: [80/565] 14% | Training loss: 0.6952587738633156
Epoch: 37 | Iteration number: [90/565] 15% | Training loss: 0.694335185819202
Epoch: 37 | Iteration number: [100/565] 17% | Training loss: 0.6936333179473877
Epoch: 37 | Iteration number: [110/565] 19% | Training loss: 0.6930046585473147
Epoch: 37 | Iteration number: [120/565] 21% | Training loss: 0.6924950917561848
Epoch: 37 | Iteration number: [130/565] 23% | Training loss: 0.6920331129660973
Epoch: 37 | Iteration number: [140/565] 24% | Training loss: 0.6916709555046899
Epoch: 37 | Iteration number: [150/565] 26% | Training loss: 0.6913559607664744
Epoch: 37 | Iteration number: [160/565] 28% | Training loss: 0.6910553853958845
Epoch: 37 | Iteration number: [170/565] 30% | Training loss: 0.6908102747272042
Epoch: 37 | Iteration number: [180/565] 31% | Training loss: 0.6906075457731883
Epoch: 37 | Iteration number: [190/565] 33% | Training loss: 0.6904119475891716
Epoch: 37 | Iteration number: [200/565] 35% | Training loss: 0.690234237909317
Epoch: 37 | Iteration number: [210/565] 37% | Training loss: 0.6900851715178716
Epoch: 37 | Iteration number: [220/565] 38% | Training loss: 0.6899308117953213
Epoch: 37 | Iteration number: [230/565] 40% | Training loss: 0.6897958957630655
Epoch: 37 | Iteration number: [240/565] 42% | Training loss: 0.689675883948803
Epoch: 37 | Iteration number: [250/565] 44% | Training loss: 0.6895507185459137
Epoch: 37 | Iteration number: [260/565] 46% | Training loss: 0.6894622871508965
Epoch: 37 | Iteration number: [270/565] 47% | Training loss: 0.6893540978431701
Epoch: 37 | Iteration number: [280/565] 49% | Training loss: 0.6892546496220997
Epoch: 37 | Iteration number: [290/565] 51% | Training loss: 0.6891832768917083
Epoch: 37 | Iteration number: [300/565] 53% | Training loss: 0.6891187157233556
Epoch: 37 | Iteration number: [310/565] 54% | Training loss: 0.6890402811188852
Epoch: 37 | Iteration number: [320/565] 56% | Training loss: 0.6889823049306869
Epoch: 37 | Iteration number: [330/565] 58% | Training loss: 0.6889105144775275
Epoch: 37 | Iteration number: [340/565] 60% | Training loss: 0.6888363606789533
Epoch: 37 | Iteration number: [350/565] 61% | Training loss: 0.6887808058943067
Epoch: 37 | Iteration number: [360/565] 63% | Training loss: 0.6887392164932357
Epoch: 37 | Iteration number: [370/565] 65% | Training loss: 0.688699941377382
Epoch: 37 | Iteration number: [380/565] 67% | Training loss: 0.6886499037868098
Epoch: 37 | Iteration number: [390/565] 69% | Training loss: 0.6886030258276523
Epoch: 37 | Iteration number: [400/565] 70% | Training loss: 0.688554178327322
Epoch: 37 | Iteration number: [410/565] 72% | Training loss: 0.6885129140644539
Epoch: 37 | Iteration number: [420/565] 74% | Training loss: 0.6884774953126908
Epoch: 37 | Iteration number: [430/565] 76% | Training loss: 0.6884399037028468
Epoch: 37 | Iteration number: [440/565] 77% | Training loss: 0.6884120666167953
Epoch: 37 | Iteration number: [450/565] 79% | Training loss: 0.6883754007021586
Epoch: 37 | Iteration number: [460/565] 81% | Training loss: 0.6883546586917795
Epoch: 37 | Iteration number: [470/565] 83% | Training loss: 0.6883183029103787
Epoch: 37 | Iteration number: [480/565] 84% | Training loss: 0.6882920221736034
Epoch: 37 | Iteration number: [490/565] 86% | Training loss: 0.6882636699141288
Epoch: 37 | Iteration number: [500/565] 88% | Training loss: 0.6882299458980561
Epoch: 37 | Iteration number: [510/565] 90% | Training loss: 0.6881960187472549
Epoch: 37 | Iteration number: [520/565] 92% | Training loss: 0.6881795421242713
Epoch: 37 | Iteration number: [530/565] 93% | Training loss: 0.6881591658547239
Epoch: 37 | Iteration number: [540/565] 95% | Training loss: 0.6881373969493089
Epoch: 37 | Iteration number: [550/565] 97% | Training loss: 0.6881189259615812
Epoch: 37 | Iteration number: [560/565] 99% | Training loss: 0.6881012213017259

 End of epoch: 37 | Train Loss: 0.6868722350196501 | Training Time: 88 

 End of epoch: 37 | Eval Loss: 0.6902337074279785 | Evaluating Time: 6 
Epoch: 38 | Iteration number: [10/565] 1% | Training loss: 0.756309860944748
Epoch: 38 | Iteration number: [20/565] 3% | Training loss: 0.7216476768255233
Epoch: 38 | Iteration number: [30/565] 5% | Training loss: 0.7100381592909495
Epoch: 38 | Iteration number: [40/565] 7% | Training loss: 0.7042579248547554
Epoch: 38 | Iteration number: [50/565] 8% | Training loss: 0.7007684314250946
Epoch: 38 | Iteration number: [60/565] 10% | Training loss: 0.6982851624488831
Epoch: 38 | Iteration number: [70/565] 12% | Training loss: 0.6966737125601087
Epoch: 38 | Iteration number: [80/565] 14% | Training loss: 0.6954284057021141
Epoch: 38 | Iteration number: [90/565] 15% | Training loss: 0.6944279564751519
Epoch: 38 | Iteration number: [100/565] 17% | Training loss: 0.6936962354183197
Epoch: 38 | Iteration number: [110/565] 19% | Training loss: 0.693064179203727
Epoch: 38 | Iteration number: [120/565] 21% | Training loss: 0.6925525133808453
Epoch: 38 | Iteration number: [130/565] 23% | Training loss: 0.692140642954753
Epoch: 38 | Iteration number: [140/565] 24% | Training loss: 0.6917548196656363
Epoch: 38 | Iteration number: [150/565] 26% | Training loss: 0.6914640816052755
Epoch: 38 | Iteration number: [160/565] 28% | Training loss: 0.6911786813288927
Epoch: 38 | Iteration number: [170/565] 30% | Training loss: 0.6909532936180339
Epoch: 38 | Iteration number: [180/565] 31% | Training loss: 0.6907391253444883
Epoch: 38 | Iteration number: [190/565] 33% | Training loss: 0.690536840338456
Epoch: 38 | Iteration number: [200/565] 35% | Training loss: 0.6903444167971611
Epoch: 38 | Iteration number: [210/565] 37% | Training loss: 0.6901932472274417
Epoch: 38 | Iteration number: [220/565] 38% | Training loss: 0.6900450161912225
Epoch: 38 | Iteration number: [230/565] 40% | Training loss: 0.6898873139982639
Epoch: 38 | Iteration number: [240/565] 42% | Training loss: 0.689766992131869
Epoch: 38 | Iteration number: [250/565] 44% | Training loss: 0.6896513359546661
Epoch: 38 | Iteration number: [260/565] 46% | Training loss: 0.6895438689451951
Epoch: 38 | Iteration number: [270/565] 47% | Training loss: 0.6894536969838319
Epoch: 38 | Iteration number: [280/565] 49% | Training loss: 0.6893484417881285
Epoch: 38 | Iteration number: [290/565] 51% | Training loss: 0.689263071068402
Epoch: 38 | Iteration number: [300/565] 53% | Training loss: 0.6891772943735123
Epoch: 38 | Iteration number: [310/565] 54% | Training loss: 0.6891010019087023
Epoch: 38 | Iteration number: [320/565] 56% | Training loss: 0.6890280013903975
Epoch: 38 | Iteration number: [330/565] 58% | Training loss: 0.688975164565173
Epoch: 38 | Iteration number: [340/565] 60% | Training loss: 0.6889040794442681
Epoch: 38 | Iteration number: [350/565] 61% | Training loss: 0.6888323099272592
Epoch: 38 | Iteration number: [360/565] 63% | Training loss: 0.6887865056594212
Epoch: 38 | Iteration number: [370/565] 65% | Training loss: 0.6887318351784268
Epoch: 38 | Iteration number: [380/565] 67% | Training loss: 0.6886831920397909
Epoch: 38 | Iteration number: [390/565] 69% | Training loss: 0.6886556315116393
Epoch: 38 | Iteration number: [400/565] 70% | Training loss: 0.6885954466462135
Epoch: 38 | Iteration number: [410/565] 72% | Training loss: 0.6885503677333273
Epoch: 38 | Iteration number: [420/565] 74% | Training loss: 0.688509298648153
Epoch: 38 | Iteration number: [430/565] 76% | Training loss: 0.6884837734144788
Epoch: 38 | Iteration number: [440/565] 77% | Training loss: 0.6884608352726156
Epoch: 38 | Iteration number: [450/565] 79% | Training loss: 0.6884217989444733
Epoch: 38 | Iteration number: [460/565] 81% | Training loss: 0.6883855441342229
Epoch: 38 | Iteration number: [470/565] 83% | Training loss: 0.6883512588257485
Epoch: 38 | Iteration number: [480/565] 84% | Training loss: 0.6883159153163433
Epoch: 38 | Iteration number: [490/565] 86% | Training loss: 0.6882755335496397
Epoch: 38 | Iteration number: [500/565] 88% | Training loss: 0.6882481783628464
Epoch: 38 | Iteration number: [510/565] 90% | Training loss: 0.6882323133010491
Epoch: 38 | Iteration number: [520/565] 92% | Training loss: 0.6882033973932267
Epoch: 38 | Iteration number: [530/565] 93% | Training loss: 0.6881825520182555
Epoch: 38 | Iteration number: [540/565] 95% | Training loss: 0.6881585142126789
Epoch: 38 | Iteration number: [550/565] 97% | Training loss: 0.6881332634795796
Epoch: 38 | Iteration number: [560/565] 99% | Training loss: 0.688113935398204

 End of epoch: 38 | Train Loss: 0.6868920850542795 | Training Time: 89 

 End of epoch: 38 | Eval Loss: 0.689419184412275 | Evaluating Time: 6 
Epoch: 39 | Iteration number: [10/565] 1% | Training loss: 0.7554887652397155
Epoch: 39 | Iteration number: [20/565] 3% | Training loss: 0.7212475746870041
Epoch: 39 | Iteration number: [30/565] 5% | Training loss: 0.7096780677636464
Epoch: 39 | Iteration number: [40/565] 7% | Training loss: 0.7039371028542518
Epoch: 39 | Iteration number: [50/565] 8% | Training loss: 0.7005131804943084
Epoch: 39 | Iteration number: [60/565] 10% | Training loss: 0.6982445776462555
Epoch: 39 | Iteration number: [70/565] 12% | Training loss: 0.696618207863399
Epoch: 39 | Iteration number: [80/565] 14% | Training loss: 0.6953813657164574
Epoch: 39 | Iteration number: [90/565] 15% | Training loss: 0.6944822245173984
Epoch: 39 | Iteration number: [100/565] 17% | Training loss: 0.6937336766719818
Epoch: 39 | Iteration number: [110/565] 19% | Training loss: 0.6930823022669012
Epoch: 39 | Iteration number: [120/565] 21% | Training loss: 0.6925530672073364
Epoch: 39 | Iteration number: [130/565] 23% | Training loss: 0.6921133509049049
Epoch: 39 | Iteration number: [140/565] 24% | Training loss: 0.6917678449835096
Epoch: 39 | Iteration number: [150/565] 26% | Training loss: 0.6914976835250854
Epoch: 39 | Iteration number: [160/565] 28% | Training loss: 0.6912215404212475
Epoch: 39 | Iteration number: [170/565] 30% | Training loss: 0.6909500974066117
Epoch: 39 | Iteration number: [180/565] 31% | Training loss: 0.6907062219248877
Epoch: 39 | Iteration number: [190/565] 33% | Training loss: 0.6904849632790214
Epoch: 39 | Iteration number: [200/565] 35% | Training loss: 0.6903167134523391
Epoch: 39 | Iteration number: [210/565] 37% | Training loss: 0.6901494176614852
Epoch: 39 | Iteration number: [220/565] 38% | Training loss: 0.6900008285587484
Epoch: 39 | Iteration number: [230/565] 40% | Training loss: 0.6898639984752821
Epoch: 39 | Iteration number: [240/565] 42% | Training loss: 0.6897249639034271
Epoch: 39 | Iteration number: [250/565] 44% | Training loss: 0.6895975363254547
Epoch: 39 | Iteration number: [260/565] 46% | Training loss: 0.6894906188432987
Epoch: 39 | Iteration number: [270/565] 47% | Training loss: 0.6893855902883742
Epoch: 39 | Iteration number: [280/565] 49% | Training loss: 0.6893084681459836
Epoch: 39 | Iteration number: [290/565] 51% | Training loss: 0.6892241810930186
Epoch: 39 | Iteration number: [300/565] 53% | Training loss: 0.6891479402780533
Epoch: 39 | Iteration number: [310/565] 54% | Training loss: 0.6890731300077131
Epoch: 39 | Iteration number: [320/565] 56% | Training loss: 0.6890083411708474
Epoch: 39 | Iteration number: [330/565] 58% | Training loss: 0.6889329211278395
Epoch: 39 | Iteration number: [340/565] 60% | Training loss: 0.6888931344537174
Epoch: 39 | Iteration number: [350/565] 61% | Training loss: 0.6888284066745213
Epoch: 39 | Iteration number: [360/565] 63% | Training loss: 0.6887811071342892
Epoch: 39 | Iteration number: [370/565] 65% | Training loss: 0.6887228455092456
Epoch: 39 | Iteration number: [380/565] 67% | Training loss: 0.6886817980753748
Epoch: 39 | Iteration number: [390/565] 69% | Training loss: 0.6886472647006695
Epoch: 39 | Iteration number: [400/565] 70% | Training loss: 0.6886050087213517
Epoch: 39 | Iteration number: [410/565] 72% | Training loss: 0.6885550823153519
Epoch: 39 | Iteration number: [420/565] 74% | Training loss: 0.6885135769844055
Epoch: 39 | Iteration number: [430/565] 76% | Training loss: 0.6884713506975839
Epoch: 39 | Iteration number: [440/565] 77% | Training loss: 0.6884256514635954
Epoch: 39 | Iteration number: [450/565] 79% | Training loss: 0.6883982703420851
Epoch: 39 | Iteration number: [460/565] 81% | Training loss: 0.6883731725423232
Epoch: 39 | Iteration number: [470/565] 83% | Training loss: 0.6883397962184663
Epoch: 39 | Iteration number: [480/565] 84% | Training loss: 0.6883088160306216
Epoch: 39 | Iteration number: [490/565] 86% | Training loss: 0.688274370772498
Epoch: 39 | Iteration number: [500/565] 88% | Training loss: 0.6882440437078476
Epoch: 39 | Iteration number: [510/565] 90% | Training loss: 0.6882133723474017
Epoch: 39 | Iteration number: [520/565] 92% | Training loss: 0.6881823484714215
Epoch: 39 | Iteration number: [530/565] 93% | Training loss: 0.6881619245376227
Epoch: 39 | Iteration number: [540/565] 95% | Training loss: 0.6881461405091815
Epoch: 39 | Iteration number: [550/565] 97% | Training loss: 0.6881185918504542
Epoch: 39 | Iteration number: [560/565] 99% | Training loss: 0.688093563914299

 End of epoch: 39 | Train Loss: 0.6868631770125533 | Training Time: 88 

 End of epoch: 39 | Eval Loss: 0.690064115183694 | Evaluating Time: 6 
Epoch: 40 | Iteration number: [10/565] 1% | Training loss: 0.7554818332195282
Epoch: 40 | Iteration number: [20/565] 3% | Training loss: 0.7212225884199143
Epoch: 40 | Iteration number: [30/565] 5% | Training loss: 0.7097844441731771
Epoch: 40 | Iteration number: [40/565] 7% | Training loss: 0.7040894433856011
Epoch: 40 | Iteration number: [50/565] 8% | Training loss: 0.700591322183609
Epoch: 40 | Iteration number: [60/565] 10% | Training loss: 0.6983179658651352
Epoch: 40 | Iteration number: [70/565] 12% | Training loss: 0.6966574949877603
Epoch: 40 | Iteration number: [80/565] 14% | Training loss: 0.6954140715301037
Epoch: 40 | Iteration number: [90/565] 15% | Training loss: 0.6944501254293654
Epoch: 40 | Iteration number: [100/565] 17% | Training loss: 0.6937349998950958
Epoch: 40 | Iteration number: [110/565] 19% | Training loss: 0.6931195470419798
Epoch: 40 | Iteration number: [120/565] 21% | Training loss: 0.6926176513234774
Epoch: 40 | Iteration number: [130/565] 23% | Training loss: 0.6921193879384261
Epoch: 40 | Iteration number: [140/565] 24% | Training loss: 0.6917667738028935
Epoch: 40 | Iteration number: [150/565] 26% | Training loss: 0.6914339872201284
Epoch: 40 | Iteration number: [160/565] 28% | Training loss: 0.6911455687135458
Epoch: 40 | Iteration number: [170/565] 30% | Training loss: 0.6909104497993693
Epoch: 40 | Iteration number: [180/565] 31% | Training loss: 0.6906725810633765
Epoch: 40 | Iteration number: [190/565] 33% | Training loss: 0.6904727766388341
Epoch: 40 | Iteration number: [200/565] 35% | Training loss: 0.6903170105814934
Epoch: 40 | Iteration number: [210/565] 37% | Training loss: 0.6901458064715068
Epoch: 40 | Iteration number: [220/565] 38% | Training loss: 0.6899942796338688
Epoch: 40 | Iteration number: [230/565] 40% | Training loss: 0.6898525079955226
Epoch: 40 | Iteration number: [240/565] 42% | Training loss: 0.6897260054945946
Epoch: 40 | Iteration number: [250/565] 44% | Training loss: 0.6895974686145783
Epoch: 40 | Iteration number: [260/565] 46% | Training loss: 0.689497820689128
Epoch: 40 | Iteration number: [270/565] 47% | Training loss: 0.6893981330924563
Epoch: 40 | Iteration number: [280/565] 49% | Training loss: 0.6893152407237462
Epoch: 40 | Iteration number: [290/565] 51% | Training loss: 0.6892473354421813
Epoch: 40 | Iteration number: [300/565] 53% | Training loss: 0.6891775844494502
Epoch: 40 | Iteration number: [310/565] 54% | Training loss: 0.689095353118835
Epoch: 40 | Iteration number: [320/565] 56% | Training loss: 0.689021953009069
Epoch: 40 | Iteration number: [330/565] 58% | Training loss: 0.6889688748301882
Epoch: 40 | Iteration number: [340/565] 60% | Training loss: 0.6889121017035316
Epoch: 40 | Iteration number: [350/565] 61% | Training loss: 0.6888460847309658
Epoch: 40 | Iteration number: [360/565] 63% | Training loss: 0.6887986201379034
Epoch: 40 | Iteration number: [370/565] 65% | Training loss: 0.688757842134785
Epoch: 40 | Iteration number: [380/565] 67% | Training loss: 0.6887107118179924
Epoch: 40 | Iteration number: [390/565] 69% | Training loss: 0.6886467394156334
Epoch: 40 | Iteration number: [400/565] 70% | Training loss: 0.6885986563563347
Epoch: 40 | Iteration number: [410/565] 72% | Training loss: 0.6885595237336508
Epoch: 40 | Iteration number: [420/565] 74% | Training loss: 0.6885273936248961
Epoch: 40 | Iteration number: [430/565] 76% | Training loss: 0.6884744949119036
Epoch: 40 | Iteration number: [440/565] 77% | Training loss: 0.6884430377320809
Epoch: 40 | Iteration number: [450/565] 79% | Training loss: 0.6883976769447326
Epoch: 40 | Iteration number: [460/565] 81% | Training loss: 0.6883533376714458
Epoch: 40 | Iteration number: [470/565] 83% | Training loss: 0.6883215830681172
Epoch: 40 | Iteration number: [480/565] 84% | Training loss: 0.688295395175616
Epoch: 40 | Iteration number: [490/565] 86% | Training loss: 0.6882637290322051
Epoch: 40 | Iteration number: [500/565] 88% | Training loss: 0.6882311736345291
Epoch: 40 | Iteration number: [510/565] 90% | Training loss: 0.6882069093339583
Epoch: 40 | Iteration number: [520/565] 92% | Training loss: 0.6881808992761832
Epoch: 40 | Iteration number: [530/565] 93% | Training loss: 0.6881625760276363
Epoch: 40 | Iteration number: [540/565] 95% | Training loss: 0.688140920246089
Epoch: 40 | Iteration number: [550/565] 97% | Training loss: 0.6881132025068456
Epoch: 40 | Iteration number: [560/565] 99% | Training loss: 0.6880892747214862

 End of epoch: 40 | Train Loss: 0.6868604565088727 | Training Time: 88 

 End of epoch: 40 | Eval Loss: 0.6892846141542707 | Evaluating Time: 6 
Epoch: 41 | Iteration number: [10/565] 1% | Training loss: 0.7557425916194915
Epoch: 41 | Iteration number: [20/565] 3% | Training loss: 0.7213573634624482
Epoch: 41 | Iteration number: [30/565] 5% | Training loss: 0.7099877238273621
Epoch: 41 | Iteration number: [40/565] 7% | Training loss: 0.704135137796402
Epoch: 41 | Iteration number: [50/565] 8% | Training loss: 0.700620414018631
Epoch: 41 | Iteration number: [60/565] 10% | Training loss: 0.698267882068952
Epoch: 41 | Iteration number: [70/565] 12% | Training loss: 0.6966008024556296
Epoch: 41 | Iteration number: [80/565] 14% | Training loss: 0.6954470865428448
Epoch: 41 | Iteration number: [90/565] 15% | Training loss: 0.6944928599728478
Epoch: 41 | Iteration number: [100/565] 17% | Training loss: 0.6937373673915863
Epoch: 41 | Iteration number: [110/565] 19% | Training loss: 0.6931043581529097
Epoch: 41 | Iteration number: [120/565] 21% | Training loss: 0.6926006431380908
Epoch: 41 | Iteration number: [130/565] 23% | Training loss: 0.6921370056959298
Epoch: 41 | Iteration number: [140/565] 24% | Training loss: 0.6917641771691186
Epoch: 41 | Iteration number: [150/565] 26% | Training loss: 0.6914138742287954
Epoch: 41 | Iteration number: [160/565] 28% | Training loss: 0.691132377833128
Epoch: 41 | Iteration number: [170/565] 30% | Training loss: 0.6908869431299322
Epoch: 41 | Iteration number: [180/565] 31% | Training loss: 0.690664255950186
Epoch: 41 | Iteration number: [190/565] 33% | Training loss: 0.6904582710642564
Epoch: 41 | Iteration number: [200/565] 35% | Training loss: 0.6902916994690895
Epoch: 41 | Iteration number: [210/565] 37% | Training loss: 0.690132882197698
Epoch: 41 | Iteration number: [220/565] 38% | Training loss: 0.689972657236186
Epoch: 41 | Iteration number: [230/565] 40% | Training loss: 0.6898253707782082
Epoch: 41 | Iteration number: [240/565] 42% | Training loss: 0.6897047897179921
Epoch: 41 | Iteration number: [250/565] 44% | Training loss: 0.6895758233070374
Epoch: 41 | Iteration number: [260/565] 46% | Training loss: 0.689470430291616
Epoch: 41 | Iteration number: [270/565] 47% | Training loss: 0.6893585377269321
Epoch: 41 | Iteration number: [280/565] 49% | Training loss: 0.689253860286304
Epoch: 41 | Iteration number: [290/565] 51% | Training loss: 0.6891673556689558
Epoch: 41 | Iteration number: [300/565] 53% | Training loss: 0.6890977400541306
Epoch: 41 | Iteration number: [310/565] 54% | Training loss: 0.689037444514613
Epoch: 41 | Iteration number: [320/565] 56% | Training loss: 0.6889685789123178
Epoch: 41 | Iteration number: [330/565] 58% | Training loss: 0.6889182708480142
Epoch: 41 | Iteration number: [340/565] 60% | Training loss: 0.6888516745146583
Epoch: 41 | Iteration number: [350/565] 61% | Training loss: 0.6888145877633776
Epoch: 41 | Iteration number: [360/565] 63% | Training loss: 0.6887636981076665
Epoch: 41 | Iteration number: [370/565] 65% | Training loss: 0.688704208586667
Epoch: 41 | Iteration number: [380/565] 67% | Training loss: 0.6886600579086103
Epoch: 41 | Iteration number: [390/565] 69% | Training loss: 0.688606793146867
Epoch: 41 | Iteration number: [400/565] 70% | Training loss: 0.6885669520497322
Epoch: 41 | Iteration number: [410/565] 72% | Training loss: 0.6885357552912177
Epoch: 41 | Iteration number: [420/565] 74% | Training loss: 0.688500802289872
Epoch: 41 | Iteration number: [430/565] 76% | Training loss: 0.6884655772253524
Epoch: 41 | Iteration number: [440/565] 77% | Training loss: 0.6884323672814803
Epoch: 41 | Iteration number: [450/565] 79% | Training loss: 0.6883997277418772
Epoch: 41 | Iteration number: [460/565] 81% | Training loss: 0.6883644720782405
Epoch: 41 | Iteration number: [470/565] 83% | Training loss: 0.6883320103300379
Epoch: 41 | Iteration number: [480/565] 84% | Training loss: 0.6882956040402254
Epoch: 41 | Iteration number: [490/565] 86% | Training loss: 0.6882620636297732
Epoch: 41 | Iteration number: [500/565] 88% | Training loss: 0.6882326227426528
Epoch: 41 | Iteration number: [510/565] 90% | Training loss: 0.6881982506490221
Epoch: 41 | Iteration number: [520/565] 92% | Training loss: 0.6881709066721109
Epoch: 41 | Iteration number: [530/565] 93% | Training loss: 0.6881395973124594
Epoch: 41 | Iteration number: [540/565] 95% | Training loss: 0.6881140738725662
Epoch: 41 | Iteration number: [550/565] 97% | Training loss: 0.6880928700620478
Epoch: 41 | Iteration number: [560/565] 99% | Training loss: 0.6880737206765584

 End of epoch: 41 | Train Loss: 0.6868571182267855 | Training Time: 89 

 End of epoch: 41 | Eval Loss: 0.6893158299582345 | Evaluating Time: 6 
Epoch: 42 | Iteration number: [10/565] 1% | Training loss: 0.7555435299873352
Epoch: 42 | Iteration number: [20/565] 3% | Training loss: 0.7212396472692489
Epoch: 42 | Iteration number: [30/565] 5% | Training loss: 0.7097956518332164
Epoch: 42 | Iteration number: [40/565] 7% | Training loss: 0.7040381446480751
Epoch: 42 | Iteration number: [50/565] 8% | Training loss: 0.7005570363998413
Epoch: 42 | Iteration number: [60/565] 10% | Training loss: 0.6982019533713658
Epoch: 42 | Iteration number: [70/565] 12% | Training loss: 0.6966012741838182
Epoch: 42 | Iteration number: [80/565] 14% | Training loss: 0.6954460725188255
Epoch: 42 | Iteration number: [90/565] 15% | Training loss: 0.6944845113489363
Epoch: 42 | Iteration number: [100/565] 17% | Training loss: 0.6937578761577606
Epoch: 42 | Iteration number: [110/565] 19% | Training loss: 0.6931599281050942
Epoch: 42 | Iteration number: [120/565] 21% | Training loss: 0.6926243126392364
Epoch: 42 | Iteration number: [130/565] 23% | Training loss: 0.6921501017533815
Epoch: 42 | Iteration number: [140/565] 24% | Training loss: 0.6918028878314154
Epoch: 42 | Iteration number: [150/565] 26% | Training loss: 0.6914381702740987
Epoch: 42 | Iteration number: [160/565] 28% | Training loss: 0.6911283425986767
Epoch: 42 | Iteration number: [170/565] 30% | Training loss: 0.6909075670382556
Epoch: 42 | Iteration number: [180/565] 31% | Training loss: 0.6906695250007842
Epoch: 42 | Iteration number: [190/565] 33% | Training loss: 0.6904604714167746
Epoch: 42 | Iteration number: [200/565] 35% | Training loss: 0.6902577087283135
Epoch: 42 | Iteration number: [210/565] 37% | Training loss: 0.6901190720853352
Epoch: 42 | Iteration number: [220/565] 38% | Training loss: 0.6899782644076781
Epoch: 42 | Iteration number: [230/565] 40% | Training loss: 0.6898739760336668
Epoch: 42 | Iteration number: [240/565] 42% | Training loss: 0.6897426654895147
Epoch: 42 | Iteration number: [250/565] 44% | Training loss: 0.6896294679641723
Epoch: 42 | Iteration number: [260/565] 46% | Training loss: 0.6895084076202833
Epoch: 42 | Iteration number: [270/565] 47% | Training loss: 0.689411609923398
Epoch: 42 | Iteration number: [280/565] 49% | Training loss: 0.6893298830304827
Epoch: 42 | Iteration number: [290/565] 51% | Training loss: 0.6892404007500615
Epoch: 42 | Iteration number: [300/565] 53% | Training loss: 0.6891580849885941
Epoch: 42 | Iteration number: [310/565] 54% | Training loss: 0.6890653143005986
Epoch: 42 | Iteration number: [320/565] 56% | Training loss: 0.6890106787905097
Epoch: 42 | Iteration number: [330/565] 58% | Training loss: 0.6889533073613138
Epoch: 42 | Iteration number: [340/565] 60% | Training loss: 0.68889921763364
Epoch: 42 | Iteration number: [350/565] 61% | Training loss: 0.6888215475422995
Epoch: 42 | Iteration number: [360/565] 63% | Training loss: 0.6887731482585271
Epoch: 42 | Iteration number: [370/565] 65% | Training loss: 0.6887255952164933
Epoch: 42 | Iteration number: [380/565] 67% | Training loss: 0.6886707337279069
Epoch: 42 | Iteration number: [390/565] 69% | Training loss: 0.6886299759913713
Epoch: 42 | Iteration number: [400/565] 70% | Training loss: 0.6885804954171181
Epoch: 42 | Iteration number: [410/565] 72% | Training loss: 0.6885356520734183
Epoch: 42 | Iteration number: [420/565] 74% | Training loss: 0.6885105802899315
Epoch: 42 | Iteration number: [430/565] 76% | Training loss: 0.6884775533232578
Epoch: 42 | Iteration number: [440/565] 77% | Training loss: 0.6884309683333744
Epoch: 42 | Iteration number: [450/565] 79% | Training loss: 0.6883932014306386
Epoch: 42 | Iteration number: [460/565] 81% | Training loss: 0.6883585748465165
Epoch: 42 | Iteration number: [470/565] 83% | Training loss: 0.688329062309671
Epoch: 42 | Iteration number: [480/565] 84% | Training loss: 0.6882901839911938
Epoch: 42 | Iteration number: [490/565] 86% | Training loss: 0.6882601674722165
Epoch: 42 | Iteration number: [500/565] 88% | Training loss: 0.6882256090641021
Epoch: 42 | Iteration number: [510/565] 90% | Training loss: 0.6881932839459064
Epoch: 42 | Iteration number: [520/565] 92% | Training loss: 0.6881729324276631
Epoch: 42 | Iteration number: [530/565] 93% | Training loss: 0.6881502559724844
Epoch: 42 | Iteration number: [540/565] 95% | Training loss: 0.6881302842387447
Epoch: 42 | Iteration number: [550/565] 97% | Training loss: 0.6881081941994753
Epoch: 42 | Iteration number: [560/565] 99% | Training loss: 0.6880921745938914

 End of epoch: 42 | Train Loss: 0.686863353083619 | Training Time: 89 

 End of epoch: 42 | Eval Loss: 0.6897717203412738 | Evaluating Time: 6 
Epoch: 43 | Iteration number: [10/565] 1% | Training loss: 0.7553732693195343
Epoch: 43 | Iteration number: [20/565] 3% | Training loss: 0.7211470812559128
Epoch: 43 | Iteration number: [30/565] 5% | Training loss: 0.7095922629038492
Epoch: 43 | Iteration number: [40/565] 7% | Training loss: 0.7039384037256241
Epoch: 43 | Iteration number: [50/565] 8% | Training loss: 0.7005654799938202
Epoch: 43 | Iteration number: [60/565] 10% | Training loss: 0.6982487191756567
Epoch: 43 | Iteration number: [70/565] 12% | Training loss: 0.6966315933636257
Epoch: 43 | Iteration number: [80/565] 14% | Training loss: 0.6953858293592929
Epoch: 43 | Iteration number: [90/565] 15% | Training loss: 0.6944545004102919
Epoch: 43 | Iteration number: [100/565] 17% | Training loss: 0.6936913400888443
Epoch: 43 | Iteration number: [110/565] 19% | Training loss: 0.6930437142198737
Epoch: 43 | Iteration number: [120/565] 21% | Training loss: 0.6925156608223915
Epoch: 43 | Iteration number: [130/565] 23% | Training loss: 0.6920766967993516
Epoch: 43 | Iteration number: [140/565] 24% | Training loss: 0.6916960388422012
Epoch: 43 | Iteration number: [150/565] 26% | Training loss: 0.6913632806142171
Epoch: 43 | Iteration number: [160/565] 28% | Training loss: 0.6910988569259644
Epoch: 43 | Iteration number: [170/565] 30% | Training loss: 0.6908671575434068
Epoch: 43 | Iteration number: [180/565] 31% | Training loss: 0.6906602478689617
Epoch: 43 | Iteration number: [190/565] 33% | Training loss: 0.690479073085283
Epoch: 43 | Iteration number: [200/565] 35% | Training loss: 0.6902978822588921
Epoch: 43 | Iteration number: [210/565] 37% | Training loss: 0.690130698397046
Epoch: 43 | Iteration number: [220/565] 38% | Training loss: 0.68998886319724
Epoch: 43 | Iteration number: [230/565] 40% | Training loss: 0.6898534145044244
Epoch: 43 | Iteration number: [240/565] 42% | Training loss: 0.6897405157486598
Epoch: 43 | Iteration number: [250/565] 44% | Training loss: 0.6896296536922455
Epoch: 43 | Iteration number: [260/565] 46% | Training loss: 0.6895206641692382
Epoch: 43 | Iteration number: [270/565] 47% | Training loss: 0.6894127399833114
Epoch: 43 | Iteration number: [280/565] 49% | Training loss: 0.6893326142004558
Epoch: 43 | Iteration number: [290/565] 51% | Training loss: 0.6892323713878106
Epoch: 43 | Iteration number: [300/565] 53% | Training loss: 0.689146157503128
Epoch: 43 | Iteration number: [310/565] 54% | Training loss: 0.6890842208939214
Epoch: 43 | Iteration number: [320/565] 56% | Training loss: 0.6890146836638451
Epoch: 43 | Iteration number: [330/565] 58% | Training loss: 0.6889424219275966
Epoch: 43 | Iteration number: [340/565] 60% | Training loss: 0.6888784932739594
Epoch: 43 | Iteration number: [350/565] 61% | Training loss: 0.6888285994529724
Epoch: 43 | Iteration number: [360/565] 63% | Training loss: 0.6887782322035896
Epoch: 43 | Iteration number: [370/565] 65% | Training loss: 0.6887253592143188
Epoch: 43 | Iteration number: [380/565] 67% | Training loss: 0.6886825412511826
Epoch: 43 | Iteration number: [390/565] 69% | Training loss: 0.688633683247444
Epoch: 43 | Iteration number: [400/565] 70% | Training loss: 0.688594733029604
Epoch: 43 | Iteration number: [410/565] 72% | Training loss: 0.6885650037265405
Epoch: 43 | Iteration number: [420/565] 74% | Training loss: 0.6885261873404185
Epoch: 43 | Iteration number: [430/565] 76% | Training loss: 0.68848262013391
Epoch: 43 | Iteration number: [440/565] 77% | Training loss: 0.6884493838657032
Epoch: 43 | Iteration number: [450/565] 79% | Training loss: 0.6884051291147868
Epoch: 43 | Iteration number: [460/565] 81% | Training loss: 0.6883728076582369
Epoch: 43 | Iteration number: [470/565] 83% | Training loss: 0.6883432659697025
Epoch: 43 | Iteration number: [480/565] 84% | Training loss: 0.6883116104950507
Epoch: 43 | Iteration number: [490/565] 86% | Training loss: 0.6882782543192104
Epoch: 43 | Iteration number: [500/565] 88% | Training loss: 0.6882466413974762
Epoch: 43 | Iteration number: [510/565] 90% | Training loss: 0.6882219754013361
Epoch: 43 | Iteration number: [520/565] 92% | Training loss: 0.6882009855829753
Epoch: 43 | Iteration number: [530/565] 93% | Training loss: 0.6881758044350822
Epoch: 43 | Iteration number: [540/565] 95% | Training loss: 0.688151690143126
Epoch: 43 | Iteration number: [550/565] 97% | Training loss: 0.6881264816630971
Epoch: 43 | Iteration number: [560/565] 99% | Training loss: 0.6881021754017898

 End of epoch: 43 | Train Loss: 0.6868800590523576 | Training Time: 88 

 End of epoch: 43 | Eval Loss: 0.6898805924824306 | Evaluating Time: 6 
Epoch: 44 | Iteration number: [10/565] 1% | Training loss: 0.7551696062088012
Epoch: 44 | Iteration number: [20/565] 3% | Training loss: 0.7209885358810425
Epoch: 44 | Iteration number: [30/565] 5% | Training loss: 0.709522541364034
Epoch: 44 | Iteration number: [40/565] 7% | Training loss: 0.7037905842065811
Epoch: 44 | Iteration number: [50/565] 8% | Training loss: 0.7003992211818695
Epoch: 44 | Iteration number: [60/565] 10% | Training loss: 0.6981380015611649
Epoch: 44 | Iteration number: [70/565] 12% | Training loss: 0.6964956496443068
Epoch: 44 | Iteration number: [80/565] 14% | Training loss: 0.6952666409313679
Epoch: 44 | Iteration number: [90/565] 15% | Training loss: 0.6943428913752238
Epoch: 44 | Iteration number: [100/565] 17% | Training loss: 0.693565936088562
Epoch: 44 | Iteration number: [110/565] 19% | Training loss: 0.6929307287389582
Epoch: 44 | Iteration number: [120/565] 21% | Training loss: 0.692428708076477
Epoch: 44 | Iteration number: [130/565] 23% | Training loss: 0.6919999085939847
Epoch: 44 | Iteration number: [140/565] 24% | Training loss: 0.691655820608139
Epoch: 44 | Iteration number: [150/565] 26% | Training loss: 0.6913452668984731
Epoch: 44 | Iteration number: [160/565] 28% | Training loss: 0.6910669710487127
Epoch: 44 | Iteration number: [170/565] 30% | Training loss: 0.6907967823393205
Epoch: 44 | Iteration number: [180/565] 31% | Training loss: 0.6905686702993181
Epoch: 44 | Iteration number: [190/565] 33% | Training loss: 0.6903785831049869
Epoch: 44 | Iteration number: [200/565] 35% | Training loss: 0.690205205976963
Epoch: 44 | Iteration number: [210/565] 37% | Training loss: 0.6900385254905337
Epoch: 44 | Iteration number: [220/565] 38% | Training loss: 0.6898994648998434
Epoch: 44 | Iteration number: [230/565] 40% | Training loss: 0.6897633575874826
Epoch: 44 | Iteration number: [240/565] 42% | Training loss: 0.6896413226922353
Epoch: 44 | Iteration number: [250/565] 44% | Training loss: 0.6895342156887054
Epoch: 44 | Iteration number: [260/565] 46% | Training loss: 0.6894291079961337
Epoch: 44 | Iteration number: [270/565] 47% | Training loss: 0.6893162173253519
Epoch: 44 | Iteration number: [280/565] 49% | Training loss: 0.6892296035374914
Epoch: 44 | Iteration number: [290/565] 51% | Training loss: 0.6891477062784392
Epoch: 44 | Iteration number: [300/565] 53% | Training loss: 0.6890699877341588
Epoch: 44 | Iteration number: [310/565] 54% | Training loss: 0.688988592355482
Epoch: 44 | Iteration number: [320/565] 56% | Training loss: 0.6889224871993065
Epoch: 44 | Iteration number: [330/565] 58% | Training loss: 0.6888650393847263
Epoch: 44 | Iteration number: [340/565] 60% | Training loss: 0.6888114957248463
Epoch: 44 | Iteration number: [350/565] 61% | Training loss: 0.688762743302754
Epoch: 44 | Iteration number: [360/565] 63% | Training loss: 0.6887107852432462
Epoch: 44 | Iteration number: [370/565] 65% | Training loss: 0.6886655838102907
Epoch: 44 | Iteration number: [380/565] 67% | Training loss: 0.6886307942239862
Epoch: 44 | Iteration number: [390/565] 69% | Training loss: 0.6885865006691371
Epoch: 44 | Iteration number: [400/565] 70% | Training loss: 0.6885517261922359
Epoch: 44 | Iteration number: [410/565] 72% | Training loss: 0.6885139529297991
Epoch: 44 | Iteration number: [420/565] 74% | Training loss: 0.688482117652893
Epoch: 44 | Iteration number: [430/565] 76% | Training loss: 0.6884536066720652
Epoch: 44 | Iteration number: [440/565] 77% | Training loss: 0.6884182094172998
Epoch: 44 | Iteration number: [450/565] 79% | Training loss: 0.6883893797132704
Epoch: 44 | Iteration number: [460/565] 81% | Training loss: 0.6883541572353115
Epoch: 44 | Iteration number: [470/565] 83% | Training loss: 0.6883190784048527
Epoch: 44 | Iteration number: [480/565] 84% | Training loss: 0.6882825737198194
Epoch: 44 | Iteration number: [490/565] 86% | Training loss: 0.6882499045255233
Epoch: 44 | Iteration number: [500/565] 88% | Training loss: 0.6882279064655304
Epoch: 44 | Iteration number: [510/565] 90% | Training loss: 0.6882056127576267
Epoch: 44 | Iteration number: [520/565] 92% | Training loss: 0.6881828846839758
Epoch: 44 | Iteration number: [530/565] 93% | Training loss: 0.688151841568497
Epoch: 44 | Iteration number: [540/565] 95% | Training loss: 0.6881230102645026
Epoch: 44 | Iteration number: [550/565] 97% | Training loss: 0.68809997623617
Epoch: 44 | Iteration number: [560/565] 99% | Training loss: 0.6880855093044894

 End of epoch: 44 | Train Loss: 0.6868549919761388 | Training Time: 88 

 End of epoch: 44 | Eval Loss: 0.6899897626468113 | Evaluating Time: 6 
Epoch: 45 | Iteration number: [10/565] 1% | Training loss: 0.7549996554851532
Epoch: 45 | Iteration number: [20/565] 3% | Training loss: 0.7209508061408997
Epoch: 45 | Iteration number: [30/565] 5% | Training loss: 0.7096569418907166
Epoch: 45 | Iteration number: [40/565] 7% | Training loss: 0.7039210125803947
Epoch: 45 | Iteration number: [50/565] 8% | Training loss: 0.7005169355869293
Epoch: 45 | Iteration number: [60/565] 10% | Training loss: 0.6982503910859426
Epoch: 45 | Iteration number: [70/565] 12% | Training loss: 0.6966754249164037
Epoch: 45 | Iteration number: [80/565] 14% | Training loss: 0.6954243130981922
Epoch: 45 | Iteration number: [90/565] 15% | Training loss: 0.694460615184572
Epoch: 45 | Iteration number: [100/565] 17% | Training loss: 0.6936933350563049
Epoch: 45 | Iteration number: [110/565] 19% | Training loss: 0.69307307546789
Epoch: 45 | Iteration number: [120/565] 21% | Training loss: 0.6925783226887385
Epoch: 45 | Iteration number: [130/565] 23% | Training loss: 0.6921255978254172
Epoch: 45 | Iteration number: [140/565] 24% | Training loss: 0.6918151472296034
Epoch: 45 | Iteration number: [150/565] 26% | Training loss: 0.6914892041683197
Epoch: 45 | Iteration number: [160/565] 28% | Training loss: 0.6912279795855284
Epoch: 45 | Iteration number: [170/565] 30% | Training loss: 0.6909732699394227
Epoch: 45 | Iteration number: [180/565] 31% | Training loss: 0.6907363060447905
Epoch: 45 | Iteration number: [190/565] 33% | Training loss: 0.6905600284275256
Epoch: 45 | Iteration number: [200/565] 35% | Training loss: 0.6903922602534294
Epoch: 45 | Iteration number: [210/565] 37% | Training loss: 0.6901997336319514
Epoch: 45 | Iteration number: [220/565] 38% | Training loss: 0.6900589460676366
Epoch: 45 | Iteration number: [230/565] 40% | Training loss: 0.6899258320746214
Epoch: 45 | Iteration number: [240/565] 42% | Training loss: 0.6897879424194495
Epoch: 45 | Iteration number: [250/565] 44% | Training loss: 0.6896489565372467
Epoch: 45 | Iteration number: [260/565] 46% | Training loss: 0.6895576763611574
Epoch: 45 | Iteration number: [270/565] 47% | Training loss: 0.6894560109685969
Epoch: 45 | Iteration number: [280/565] 49% | Training loss: 0.6893446526357105
Epoch: 45 | Iteration number: [290/565] 51% | Training loss: 0.6892556792703168
Epoch: 45 | Iteration number: [300/565] 53% | Training loss: 0.6891809753576914
Epoch: 45 | Iteration number: [310/565] 54% | Training loss: 0.6891101510294022
Epoch: 45 | Iteration number: [320/565] 56% | Training loss: 0.6890385206788778
Epoch: 45 | Iteration number: [330/565] 58% | Training loss: 0.6889526535164227
Epoch: 45 | Iteration number: [340/565] 60% | Training loss: 0.6888862196136923
Epoch: 45 | Iteration number: [350/565] 61% | Training loss: 0.6888360445840018
Epoch: 45 | Iteration number: [360/565] 63% | Training loss: 0.6887764487001631
Epoch: 45 | Iteration number: [370/565] 65% | Training loss: 0.6887293321055334
Epoch: 45 | Iteration number: [380/565] 67% | Training loss: 0.6886733616653241
Epoch: 45 | Iteration number: [390/565] 69% | Training loss: 0.688624845406948
Epoch: 45 | Iteration number: [400/565] 70% | Training loss: 0.688584611415863
Epoch: 45 | Iteration number: [410/565] 72% | Training loss: 0.6885405459055086
Epoch: 45 | Iteration number: [420/565] 74% | Training loss: 0.6884982053722654
Epoch: 45 | Iteration number: [430/565] 76% | Training loss: 0.6884542790956275
Epoch: 45 | Iteration number: [440/565] 77% | Training loss: 0.6884207311001691
Epoch: 45 | Iteration number: [450/565] 79% | Training loss: 0.6883822378847334
Epoch: 45 | Iteration number: [460/565] 81% | Training loss: 0.6883469739685888
Epoch: 45 | Iteration number: [470/565] 83% | Training loss: 0.6883124758588507
Epoch: 45 | Iteration number: [480/565] 84% | Training loss: 0.688282041127483
Epoch: 45 | Iteration number: [490/565] 86% | Training loss: 0.6882575292976535
Epoch: 45 | Iteration number: [500/565] 88% | Training loss: 0.6882250030040741
Epoch: 45 | Iteration number: [510/565] 90% | Training loss: 0.6881975309521544
Epoch: 45 | Iteration number: [520/565] 92% | Training loss: 0.6881829585020359
Epoch: 45 | Iteration number: [530/565] 93% | Training loss: 0.6881495908746179
Epoch: 45 | Iteration number: [540/565] 95% | Training loss: 0.6881181747825057
Epoch: 45 | Iteration number: [550/565] 97% | Training loss: 0.6880975754694505
Epoch: 45 | Iteration number: [560/565] 99% | Training loss: 0.6880718919847693

 End of epoch: 45 | Train Loss: 0.6868469441886497 | Training Time: 89 

 End of epoch: 45 | Eval Loss: 0.6895032610212054 | Evaluating Time: 5 
Epoch: 46 | Iteration number: [10/565] 1% | Training loss: 0.7557808220386505
Epoch: 46 | Iteration number: [20/565] 3% | Training loss: 0.7213021039962768
Epoch: 46 | Iteration number: [30/565] 5% | Training loss: 0.7099262773990631
Epoch: 46 | Iteration number: [40/565] 7% | Training loss: 0.704140704870224
Epoch: 46 | Iteration number: [50/565] 8% | Training loss: 0.7007129037380219
Epoch: 46 | Iteration number: [60/565] 10% | Training loss: 0.6983544747034709
Epoch: 46 | Iteration number: [70/565] 12% | Training loss: 0.6966966211795806
Epoch: 46 | Iteration number: [80/565] 14% | Training loss: 0.6954351216554642
Epoch: 46 | Iteration number: [90/565] 15% | Training loss: 0.6944089028570387
Epoch: 46 | Iteration number: [100/565] 17% | Training loss: 0.6936037385463715
Epoch: 46 | Iteration number: [110/565] 19% | Training loss: 0.6929769792340018
Epoch: 46 | Iteration number: [120/565] 21% | Training loss: 0.6924514104922612
Epoch: 46 | Iteration number: [130/565] 23% | Training loss: 0.6920587104100447
Epoch: 46 | Iteration number: [140/565] 24% | Training loss: 0.6916872990982873
Epoch: 46 | Iteration number: [150/565] 26% | Training loss: 0.6913670365015666
Epoch: 46 | Iteration number: [160/565] 28% | Training loss: 0.6910671781748533
Epoch: 46 | Iteration number: [170/565] 30% | Training loss: 0.6908138913266799
Epoch: 46 | Iteration number: [180/565] 31% | Training loss: 0.6906153798103333
Epoch: 46 | Iteration number: [190/565] 33% | Training loss: 0.6904322122272692
Epoch: 46 | Iteration number: [200/565] 35% | Training loss: 0.6902729913592338
Epoch: 46 | Iteration number: [210/565] 37% | Training loss: 0.6901179160390581
Epoch: 46 | Iteration number: [220/565] 38% | Training loss: 0.689968957955187
Epoch: 46 | Iteration number: [230/565] 40% | Training loss: 0.6898126721382141
Epoch: 46 | Iteration number: [240/565] 42% | Training loss: 0.6896832798918088
Epoch: 46 | Iteration number: [250/565] 44% | Training loss: 0.6895965962409973
Epoch: 46 | Iteration number: [260/565] 46% | Training loss: 0.6894934862852097
Epoch: 46 | Iteration number: [270/565] 47% | Training loss: 0.6893987938209817
Epoch: 46 | Iteration number: [280/565] 49% | Training loss: 0.6893095814755985
Epoch: 46 | Iteration number: [290/565] 51% | Training loss: 0.689222324100034
Epoch: 46 | Iteration number: [300/565] 53% | Training loss: 0.6891541415452958
Epoch: 46 | Iteration number: [310/565] 54% | Training loss: 0.6890821230026983
Epoch: 46 | Iteration number: [320/565] 56% | Training loss: 0.6890099795535207
Epoch: 46 | Iteration number: [330/565] 58% | Training loss: 0.6889465368155278
Epoch: 46 | Iteration number: [340/565] 60% | Training loss: 0.6888878289391013
Epoch: 46 | Iteration number: [350/565] 61% | Training loss: 0.6888251943247659
Epoch: 46 | Iteration number: [360/565] 63% | Training loss: 0.6887762213746706
Epoch: 46 | Iteration number: [370/565] 65% | Training loss: 0.6887195899679854
Epoch: 46 | Iteration number: [380/565] 67% | Training loss: 0.6886647574211422
Epoch: 46 | Iteration number: [390/565] 69% | Training loss: 0.6886308604326004
Epoch: 46 | Iteration number: [400/565] 70% | Training loss: 0.6885688434541225
Epoch: 46 | Iteration number: [410/565] 72% | Training loss: 0.6885245568868591
Epoch: 46 | Iteration number: [420/565] 74% | Training loss: 0.6884765449024383
Epoch: 46 | Iteration number: [430/565] 76% | Training loss: 0.6884289705476095
Epoch: 46 | Iteration number: [440/565] 77% | Training loss: 0.688394077799537
Epoch: 46 | Iteration number: [450/565] 79% | Training loss: 0.6883589522043864
Epoch: 46 | Iteration number: [460/565] 81% | Training loss: 0.6883222944062689
Epoch: 46 | Iteration number: [470/565] 83% | Training loss: 0.6882987971001483
Epoch: 46 | Iteration number: [480/565] 84% | Training loss: 0.6882691857715447
Epoch: 46 | Iteration number: [490/565] 86% | Training loss: 0.6882406024300323
Epoch: 46 | Iteration number: [500/565] 88% | Training loss: 0.6882128423452377
Epoch: 46 | Iteration number: [510/565] 90% | Training loss: 0.6881833630449632
Epoch: 46 | Iteration number: [520/565] 92% | Training loss: 0.6881593908254917
Epoch: 46 | Iteration number: [530/565] 93% | Training loss: 0.6881358883290921
Epoch: 46 | Iteration number: [540/565] 95% | Training loss: 0.6881122563724165
Epoch: 46 | Iteration number: [550/565] 97% | Training loss: 0.6880852588740262
Epoch: 46 | Iteration number: [560/565] 99% | Training loss: 0.6880614760730948

 End of epoch: 46 | Train Loss: 0.6868372612294897 | Training Time: 89 

 End of epoch: 46 | Eval Loss: 0.6898277146475655 | Evaluating Time: 6 
Epoch: 47 | Iteration number: [10/565] 1% | Training loss: 0.7557699859142304
Epoch: 47 | Iteration number: [20/565] 3% | Training loss: 0.7213980197906494
Epoch: 47 | Iteration number: [30/565] 5% | Training loss: 0.7099480191866557
Epoch: 47 | Iteration number: [40/565] 7% | Training loss: 0.7042337790131569
Epoch: 47 | Iteration number: [50/565] 8% | Training loss: 0.7006831932067871
Epoch: 47 | Iteration number: [60/565] 10% | Training loss: 0.6983623166879018
Epoch: 47 | Iteration number: [70/565] 12% | Training loss: 0.6967795712607248
Epoch: 47 | Iteration number: [80/565] 14% | Training loss: 0.6955568999052048
Epoch: 47 | Iteration number: [90/565] 15% | Training loss: 0.6945709738466475
Epoch: 47 | Iteration number: [100/565] 17% | Training loss: 0.6938062739372254
Epoch: 47 | Iteration number: [110/565] 19% | Training loss: 0.6931413655931299
Epoch: 47 | Iteration number: [120/565] 21% | Training loss: 0.6926216507951418
Epoch: 47 | Iteration number: [130/565] 23% | Training loss: 0.6921484094399672
Epoch: 47 | Iteration number: [140/565] 24% | Training loss: 0.6917758460555757
Epoch: 47 | Iteration number: [150/565] 26% | Training loss: 0.6914570081233978
Epoch: 47 | Iteration number: [160/565] 28% | Training loss: 0.6911559127271175
Epoch: 47 | Iteration number: [170/565] 30% | Training loss: 0.6909017608446233
Epoch: 47 | Iteration number: [180/565] 31% | Training loss: 0.6906776862012015
Epoch: 47 | Iteration number: [190/565] 33% | Training loss: 0.6904722470986215
Epoch: 47 | Iteration number: [200/565] 35% | Training loss: 0.6902909010648728
Epoch: 47 | Iteration number: [210/565] 37% | Training loss: 0.690134710924966
Epoch: 47 | Iteration number: [220/565] 38% | Training loss: 0.68998041017489
Epoch: 47 | Iteration number: [230/565] 40% | Training loss: 0.6898382028807765
Epoch: 47 | Iteration number: [240/565] 42% | Training loss: 0.6897174835205078
Epoch: 47 | Iteration number: [250/565] 44% | Training loss: 0.6896206405162811
Epoch: 47 | Iteration number: [260/565] 46% | Training loss: 0.6895043517534549
Epoch: 47 | Iteration number: [270/565] 47% | Training loss: 0.689420802725686
Epoch: 47 | Iteration number: [280/565] 49% | Training loss: 0.689321591598647
Epoch: 47 | Iteration number: [290/565] 51% | Training loss: 0.689229825036279
Epoch: 47 | Iteration number: [300/565] 53% | Training loss: 0.6891490745544434
Epoch: 47 | Iteration number: [310/565] 54% | Training loss: 0.689075029665424
Epoch: 47 | Iteration number: [320/565] 56% | Training loss: 0.6889955118298531
Epoch: 47 | Iteration number: [330/565] 58% | Training loss: 0.6889243891744903
Epoch: 47 | Iteration number: [340/565] 60% | Training loss: 0.6888594758861205
Epoch: 47 | Iteration number: [350/565] 61% | Training loss: 0.6887982829979488
Epoch: 47 | Iteration number: [360/565] 63% | Training loss: 0.6887495345539517
Epoch: 47 | Iteration number: [370/565] 65% | Training loss: 0.688706539933746
Epoch: 47 | Iteration number: [380/565] 67% | Training loss: 0.6886445506622917
Epoch: 47 | Iteration number: [390/565] 69% | Training loss: 0.688591223802322
Epoch: 47 | Iteration number: [400/565] 70% | Training loss: 0.6885412952303887
Epoch: 47 | Iteration number: [410/565] 72% | Training loss: 0.688495308306159
Epoch: 47 | Iteration number: [420/565] 74% | Training loss: 0.6884709309963953
Epoch: 47 | Iteration number: [430/565] 76% | Training loss: 0.6884358349234558
Epoch: 47 | Iteration number: [440/565] 77% | Training loss: 0.6883918210864067
Epoch: 47 | Iteration number: [450/565] 79% | Training loss: 0.6883542528417376
Epoch: 47 | Iteration number: [460/565] 81% | Training loss: 0.6883236150378766
Epoch: 47 | Iteration number: [470/565] 83% | Training loss: 0.6882911964933923
Epoch: 47 | Iteration number: [480/565] 84% | Training loss: 0.6882674564917882
Epoch: 47 | Iteration number: [490/565] 86% | Training loss: 0.688237711969687
Epoch: 47 | Iteration number: [500/565] 88% | Training loss: 0.688210874915123
Epoch: 47 | Iteration number: [510/565] 90% | Training loss: 0.68819139529677
Epoch: 47 | Iteration number: [520/565] 92% | Training loss: 0.6881715184220901
Epoch: 47 | Iteration number: [530/565] 93% | Training loss: 0.688148732905118
Epoch: 47 | Iteration number: [540/565] 95% | Training loss: 0.6881363900723281
Epoch: 47 | Iteration number: [550/565] 97% | Training loss: 0.6881136168133128
Epoch: 47 | Iteration number: [560/565] 99% | Training loss: 0.6880851809467589

 End of epoch: 47 | Train Loss: 0.6868613274751512 | Training Time: 88 

 End of epoch: 47 | Eval Loss: 0.6900510702814374 | Evaluating Time: 6 
Epoch: 48 | Iteration number: [10/565] 1% | Training loss: 0.7548363983631134
Epoch: 48 | Iteration number: [20/565] 3% | Training loss: 0.7208015203475953
Epoch: 48 | Iteration number: [30/565] 5% | Training loss: 0.7095422367254893
Epoch: 48 | Iteration number: [40/565] 7% | Training loss: 0.7038881421089173
Epoch: 48 | Iteration number: [50/565] 8% | Training loss: 0.7004251182079315
Epoch: 48 | Iteration number: [60/565] 10% | Training loss: 0.6981774459282557
Epoch: 48 | Iteration number: [70/565] 12% | Training loss: 0.6965268978050777
Epoch: 48 | Iteration number: [80/565] 14% | Training loss: 0.6952874563634396
Epoch: 48 | Iteration number: [90/565] 15% | Training loss: 0.6943543321556516
Epoch: 48 | Iteration number: [100/565] 17% | Training loss: 0.6935609924793243
Epoch: 48 | Iteration number: [110/565] 19% | Training loss: 0.6929618895053864
Epoch: 48 | Iteration number: [120/565] 21% | Training loss: 0.6924803818265597
Epoch: 48 | Iteration number: [130/565] 23% | Training loss: 0.6920441453273479
Epoch: 48 | Iteration number: [140/565] 24% | Training loss: 0.6916581941502434
Epoch: 48 | Iteration number: [150/565] 26% | Training loss: 0.6913287862141927
Epoch: 48 | Iteration number: [160/565] 28% | Training loss: 0.6910595547407865
Epoch: 48 | Iteration number: [170/565] 30% | Training loss: 0.6908072745098787
Epoch: 48 | Iteration number: [180/565] 31% | Training loss: 0.690565953983201
Epoch: 48 | Iteration number: [190/565] 33% | Training loss: 0.6903833339088842
Epoch: 48 | Iteration number: [200/565] 35% | Training loss: 0.6902255949378013
Epoch: 48 | Iteration number: [210/565] 37% | Training loss: 0.6900547450497037
Epoch: 48 | Iteration number: [220/565] 38% | Training loss: 0.6899065294049003
Epoch: 48 | Iteration number: [230/565] 40% | Training loss: 0.6897810899693033
Epoch: 48 | Iteration number: [240/565] 42% | Training loss: 0.6896526530385018
Epoch: 48 | Iteration number: [250/565] 44% | Training loss: 0.6895434329509735
Epoch: 48 | Iteration number: [260/565] 46% | Training loss: 0.6894384152614154
Epoch: 48 | Iteration number: [270/565] 47% | Training loss: 0.6893358078267839
Epoch: 48 | Iteration number: [280/565] 49% | Training loss: 0.6892363343920026
Epoch: 48 | Iteration number: [290/565] 51% | Training loss: 0.6891738293499782
Epoch: 48 | Iteration number: [300/565] 53% | Training loss: 0.6890895825624466
Epoch: 48 | Iteration number: [310/565] 54% | Training loss: 0.6890218940473372
Epoch: 48 | Iteration number: [320/565] 56% | Training loss: 0.6889466987922788
Epoch: 48 | Iteration number: [330/565] 58% | Training loss: 0.6888979879292575
Epoch: 48 | Iteration number: [340/565] 60% | Training loss: 0.6888363734764211
Epoch: 48 | Iteration number: [350/565] 61% | Training loss: 0.6887809414522988
Epoch: 48 | Iteration number: [360/565] 63% | Training loss: 0.6887416041559643
Epoch: 48 | Iteration number: [370/565] 65% | Training loss: 0.6886911620964875
Epoch: 48 | Iteration number: [380/565] 67% | Training loss: 0.6886411968030428
Epoch: 48 | Iteration number: [390/565] 69% | Training loss: 0.6885970114133297
Epoch: 48 | Iteration number: [400/565] 70% | Training loss: 0.688551409393549
Epoch: 48 | Iteration number: [410/565] 72% | Training loss: 0.6884875581031893
Epoch: 48 | Iteration number: [420/565] 74% | Training loss: 0.6884406883092153
Epoch: 48 | Iteration number: [430/565] 76% | Training loss: 0.6883995053380034
Epoch: 48 | Iteration number: [440/565] 77% | Training loss: 0.6883698322556235
Epoch: 48 | Iteration number: [450/565] 79% | Training loss: 0.6883267483446334
Epoch: 48 | Iteration number: [460/565] 81% | Training loss: 0.688297514811806
Epoch: 48 | Iteration number: [470/565] 83% | Training loss: 0.688271405214959
Epoch: 48 | Iteration number: [480/565] 84% | Training loss: 0.6882411283751328
Epoch: 48 | Iteration number: [490/565] 86% | Training loss: 0.6882144052155164
Epoch: 48 | Iteration number: [500/565] 88% | Training loss: 0.6881897611618042
Epoch: 48 | Iteration number: [510/565] 90% | Training loss: 0.6881736321776522
Epoch: 48 | Iteration number: [520/565] 92% | Training loss: 0.6881471199484972
Epoch: 48 | Iteration number: [530/565] 93% | Training loss: 0.6881242735205956
Epoch: 48 | Iteration number: [540/565] 95% | Training loss: 0.6881013746614809
Epoch: 48 | Iteration number: [550/565] 97% | Training loss: 0.6880808808586815
Epoch: 48 | Iteration number: [560/565] 99% | Training loss: 0.6880621080952031

 End of epoch: 48 | Train Loss: 0.686836685016092 | Training Time: 88 

 End of epoch: 48 | Eval Loss: 0.6895991478647504 | Evaluating Time: 6 
Epoch: 49 | Iteration number: [10/565] 1% | Training loss: 0.7555626094341278
Epoch: 49 | Iteration number: [20/565] 3% | Training loss: 0.7209746390581131
Epoch: 49 | Iteration number: [30/565] 5% | Training loss: 0.7096181750297547
Epoch: 49 | Iteration number: [40/565] 7% | Training loss: 0.7039274200797081
Epoch: 49 | Iteration number: [50/565] 8% | Training loss: 0.7004971992969513
Epoch: 49 | Iteration number: [60/565] 10% | Training loss: 0.6981677651405335
Epoch: 49 | Iteration number: [70/565] 12% | Training loss: 0.6965583401066916
Epoch: 49 | Iteration number: [80/565] 14% | Training loss: 0.6953584544360638
Epoch: 49 | Iteration number: [90/565] 15% | Training loss: 0.6944352640046014
Epoch: 49 | Iteration number: [100/565] 17% | Training loss: 0.6936793184280395
Epoch: 49 | Iteration number: [110/565] 19% | Training loss: 0.6930507724935359
Epoch: 49 | Iteration number: [120/565] 21% | Training loss: 0.6925414234399796
Epoch: 49 | Iteration number: [130/565] 23% | Training loss: 0.6921028421475337
Epoch: 49 | Iteration number: [140/565] 24% | Training loss: 0.6917570114135743
Epoch: 49 | Iteration number: [150/565] 26% | Training loss: 0.6914109516143799
Epoch: 49 | Iteration number: [160/565] 28% | Training loss: 0.691118436306715
Epoch: 49 | Iteration number: [170/565] 30% | Training loss: 0.690835269759683
Epoch: 49 | Iteration number: [180/565] 31% | Training loss: 0.6906051639053556
Epoch: 49 | Iteration number: [190/565] 33% | Training loss: 0.6903799386400925
Epoch: 49 | Iteration number: [200/565] 35% | Training loss: 0.6902029272913933
Epoch: 49 | Iteration number: [210/565] 37% | Training loss: 0.690066096896217
Epoch: 49 | Iteration number: [220/565] 38% | Training loss: 0.6899035922505639
Epoch: 49 | Iteration number: [230/565] 40% | Training loss: 0.6897719248481419
Epoch: 49 | Iteration number: [240/565] 42% | Training loss: 0.6896627329289913
Epoch: 49 | Iteration number: [250/565] 44% | Training loss: 0.6895701112747192
Epoch: 49 | Iteration number: [260/565] 46% | Training loss: 0.6894863846210333
Epoch: 49 | Iteration number: [270/565] 47% | Training loss: 0.6893949389457703
Epoch: 49 | Iteration number: [280/565] 49% | Training loss: 0.6893082527177674
Epoch: 49 | Iteration number: [290/565] 51% | Training loss: 0.6892271202186059
Epoch: 49 | Iteration number: [300/565] 53% | Training loss: 0.6891615557670593
Epoch: 49 | Iteration number: [310/565] 54% | Training loss: 0.6890788564758916
Epoch: 49 | Iteration number: [320/565] 56% | Training loss: 0.6890119533985853
Epoch: 49 | Iteration number: [330/565] 58% | Training loss: 0.6889363783778566
Epoch: 49 | Iteration number: [340/565] 60% | Training loss: 0.6888839467483409
Epoch: 49 | Iteration number: [350/565] 61% | Training loss: 0.6888343448298319
Epoch: 49 | Iteration number: [360/565] 63% | Training loss: 0.6887694191601541
Epoch: 49 | Iteration number: [370/565] 65% | Training loss: 0.6887103320779027
Epoch: 49 | Iteration number: [380/565] 67% | Training loss: 0.6886698241296567
Epoch: 49 | Iteration number: [390/565] 69% | Training loss: 0.6886227661218398
Epoch: 49 | Iteration number: [400/565] 70% | Training loss: 0.6885874935984612
Epoch: 49 | Iteration number: [410/565] 72% | Training loss: 0.6885280010176869
Epoch: 49 | Iteration number: [420/565] 74% | Training loss: 0.6884876197292691
Epoch: 49 | Iteration number: [430/565] 76% | Training loss: 0.6884628133718358
Epoch: 49 | Iteration number: [440/565] 77% | Training loss: 0.6884256093339487
Epoch: 49 | Iteration number: [450/565] 79% | Training loss: 0.6883887296252781
Epoch: 49 | Iteration number: [460/565] 81% | Training loss: 0.6883562926364981
Epoch: 49 | Iteration number: [470/565] 83% | Training loss: 0.688317368512458
Epoch: 49 | Iteration number: [480/565] 84% | Training loss: 0.6882846107085546
Epoch: 49 | Iteration number: [490/565] 86% | Training loss: 0.6882524733640709
Epoch: 49 | Iteration number: [500/565] 88% | Training loss: 0.6882226362228393
Epoch: 49 | Iteration number: [510/565] 90% | Training loss: 0.6881955573371813
Epoch: 49 | Iteration number: [520/565] 92% | Training loss: 0.6881670828048999
Epoch: 49 | Iteration number: [530/565] 93% | Training loss: 0.6881446838378906
Epoch: 49 | Iteration number: [540/565] 95% | Training loss: 0.6881213179341069
Epoch: 49 | Iteration number: [550/565] 97% | Training loss: 0.688092493577437
Epoch: 49 | Iteration number: [560/565] 99% | Training loss: 0.6880681837243693

 End of epoch: 49 | Train Loss: 0.6868436241571882 | Training Time: 89 

 End of epoch: 49 | Eval Loss: 0.6899816053254264 | Evaluating Time: 6 
Epoch: 50 | Iteration number: [10/565] 1% | Training loss: 0.7558952808380127
Epoch: 50 | Iteration number: [20/565] 3% | Training loss: 0.721370741724968
Epoch: 50 | Iteration number: [30/565] 5% | Training loss: 0.7098285257816315
Epoch: 50 | Iteration number: [40/565] 7% | Training loss: 0.7040216192603111
Epoch: 50 | Iteration number: [50/565] 8% | Training loss: 0.7006367099285126
Epoch: 50 | Iteration number: [60/565] 10% | Training loss: 0.698306064804395
Epoch: 50 | Iteration number: [70/565] 12% | Training loss: 0.6967232925551278
Epoch: 50 | Iteration number: [80/565] 14% | Training loss: 0.6954247049987317
Epoch: 50 | Iteration number: [90/565] 15% | Training loss: 0.6944775210486518
Epoch: 50 | Iteration number: [100/565] 17% | Training loss: 0.6936901277303695
Epoch: 50 | Iteration number: [110/565] 19% | Training loss: 0.6930912597612902
Epoch: 50 | Iteration number: [120/565] 21% | Training loss: 0.6925467282533646
Epoch: 50 | Iteration number: [130/565] 23% | Training loss: 0.6921067467102637
Epoch: 50 | Iteration number: [140/565] 24% | Training loss: 0.6917382717132569
Epoch: 50 | Iteration number: [150/565] 26% | Training loss: 0.6914345169067383
Epoch: 50 | Iteration number: [160/565] 28% | Training loss: 0.6911566611379385
Epoch: 50 | Iteration number: [170/565] 30% | Training loss: 0.6908953396713032
Epoch: 50 | Iteration number: [180/565] 31% | Training loss: 0.690679269697931
Epoch: 50 | Iteration number: [190/565] 33% | Training loss: 0.6904886079461952
Epoch: 50 | Iteration number: [200/565] 35% | Training loss: 0.6902775105834007
Epoch: 50 | Iteration number: [210/565] 37% | Training loss: 0.6901046801181067
Epoch: 50 | Iteration number: [220/565] 38% | Training loss: 0.6899397898804057
Epoch: 50 | Iteration number: [230/565] 40% | Training loss: 0.6898063703723576
Epoch: 50 | Iteration number: [240/565] 42% | Training loss: 0.689692285656929
Epoch: 50 | Iteration number: [250/565] 44% | Training loss: 0.6895846712589264
Epoch: 50 | Iteration number: [260/565] 46% | Training loss: 0.6894830843577018
Epoch: 50 | Iteration number: [270/565] 47% | Training loss: 0.689373043510649
Epoch: 50 | Iteration number: [280/565] 49% | Training loss: 0.6892639328326498
Epoch: 50 | Iteration number: [290/565] 51% | Training loss: 0.6891813450846179
Epoch: 50 | Iteration number: [300/565] 53% | Training loss: 0.6891029479106268
Epoch: 50 | Iteration number: [310/565] 54% | Training loss: 0.6890402626606726
Epoch: 50 | Iteration number: [320/565] 56% | Training loss: 0.6889644984155894
Epoch: 50 | Iteration number: [330/565] 58% | Training loss: 0.6888975296959733
Epoch: 50 | Iteration number: [340/565] 60% | Training loss: 0.688821299812373
Epoch: 50 | Iteration number: [350/565] 61% | Training loss: 0.6887760596615927
Epoch: 50 | Iteration number: [360/565] 63% | Training loss: 0.6887145323885812
Epoch: 50 | Iteration number: [370/565] 65% | Training loss: 0.6886749209584416
Epoch: 50 | Iteration number: [380/565] 67% | Training loss: 0.688637397320647
Epoch: 50 | Iteration number: [390/565] 69% | Training loss: 0.6885923769229497
Epoch: 50 | Iteration number: [400/565] 70% | Training loss: 0.6885485388338566
Epoch: 50 | Iteration number: [410/565] 72% | Training loss: 0.688508557982561
Epoch: 50 | Iteration number: [420/565] 74% | Training loss: 0.6884684030498777
Epoch: 50 | Iteration number: [430/565] 76% | Training loss: 0.688433932426364
Epoch: 50 | Iteration number: [440/565] 77% | Training loss: 0.6883914435451681
Epoch: 50 | Iteration number: [450/565] 79% | Training loss: 0.688365595208274
Epoch: 50 | Iteration number: [460/565] 81% | Training loss: 0.6883266193711239
Epoch: 50 | Iteration number: [470/565] 83% | Training loss: 0.6882923722267151
Epoch: 50 | Iteration number: [480/565] 84% | Training loss: 0.6882571686059237
Epoch: 50 | Iteration number: [490/565] 86% | Training loss: 0.6882305864168673
Epoch: 50 | Iteration number: [500/565] 88% | Training loss: 0.6882013427019119
Epoch: 50 | Iteration number: [510/565] 90% | Training loss: 0.6881814207516465
Epoch: 50 | Iteration number: [520/565] 92% | Training loss: 0.6881562801507803
Epoch: 50 | Iteration number: [530/565] 93% | Training loss: 0.6881245759298217
Epoch: 50 | Iteration number: [540/565] 95% | Training loss: 0.6881079313931642
Epoch: 50 | Iteration number: [550/565] 97% | Training loss: 0.6880846176364205
Epoch: 50 | Iteration number: [560/565] 99% | Training loss: 0.6880665591784886

 End of epoch: 50 | Train Loss: 0.6868335146819595 | Training Time: 89 

 End of epoch: 50 | Eval Loss: 0.689551762172154 | Evaluating Time: 6 
Epoch: 51 | Iteration number: [10/565] 1% | Training loss: 0.7553870677947998
Epoch: 51 | Iteration number: [20/565] 3% | Training loss: 0.72115298807621
Epoch: 51 | Iteration number: [30/565] 5% | Training loss: 0.7097061455249787
Epoch: 51 | Iteration number: [40/565] 7% | Training loss: 0.7040229365229607
Epoch: 51 | Iteration number: [50/565] 8% | Training loss: 0.7005847406387329
Epoch: 51 | Iteration number: [60/565] 10% | Training loss: 0.6982414285341899
Epoch: 51 | Iteration number: [70/565] 12% | Training loss: 0.6966382588659014
Epoch: 51 | Iteration number: [80/565] 14% | Training loss: 0.6953853592276573
Epoch: 51 | Iteration number: [90/565] 15% | Training loss: 0.694407061735789
Epoch: 51 | Iteration number: [100/565] 17% | Training loss: 0.6936492735147476
Epoch: 51 | Iteration number: [110/565] 19% | Training loss: 0.6930039828473872
Epoch: 51 | Iteration number: [120/565] 21% | Training loss: 0.6924789701898892
Epoch: 51 | Iteration number: [130/565] 23% | Training loss: 0.69205768933663
Epoch: 51 | Iteration number: [140/565] 24% | Training loss: 0.6917162495000022
Epoch: 51 | Iteration number: [150/565] 26% | Training loss: 0.6914287066459656
Epoch: 51 | Iteration number: [160/565] 28% | Training loss: 0.6911401305347681
Epoch: 51 | Iteration number: [170/565] 30% | Training loss: 0.6908904524410472
Epoch: 51 | Iteration number: [180/565] 31% | Training loss: 0.690662181046274
Epoch: 51 | Iteration number: [190/565] 33% | Training loss: 0.6904775697934
Epoch: 51 | Iteration number: [200/565] 35% | Training loss: 0.6903059235215188
Epoch: 51 | Iteration number: [210/565] 37% | Training loss: 0.6901376729919797
Epoch: 51 | Iteration number: [220/565] 38% | Training loss: 0.6899653106927872
Epoch: 51 | Iteration number: [230/565] 40% | Training loss: 0.6898253826991372
Epoch: 51 | Iteration number: [240/565] 42% | Training loss: 0.6897258765995502
Epoch: 51 | Iteration number: [250/565] 44% | Training loss: 0.6896159782409668
Epoch: 51 | Iteration number: [260/565] 46% | Training loss: 0.6895264373375819
Epoch: 51 | Iteration number: [270/565] 47% | Training loss: 0.6894238765592928
Epoch: 51 | Iteration number: [280/565] 49% | Training loss: 0.6893399445073946
Epoch: 51 | Iteration number: [290/565] 51% | Training loss: 0.6892472772762693
Epoch: 51 | Iteration number: [300/565] 53% | Training loss: 0.6891756445169449
Epoch: 51 | Iteration number: [310/565] 54% | Training loss: 0.6890955380855068
Epoch: 51 | Iteration number: [320/565] 56% | Training loss: 0.6890329010784626
Epoch: 51 | Iteration number: [330/565] 58% | Training loss: 0.6889534276543241
Epoch: 51 | Iteration number: [340/565] 60% | Training loss: 0.6888839618248098
Epoch: 51 | Iteration number: [350/565] 61% | Training loss: 0.688818679537092
Epoch: 51 | Iteration number: [360/565] 63% | Training loss: 0.6887529532114665
Epoch: 51 | Iteration number: [370/565] 65% | Training loss: 0.688704188288869
Epoch: 51 | Iteration number: [380/565] 67% | Training loss: 0.6886597366709458
Epoch: 51 | Iteration number: [390/565] 69% | Training loss: 0.6886145075162252
Epoch: 51 | Iteration number: [400/565] 70% | Training loss: 0.6885687631368637
Epoch: 51 | Iteration number: [410/565] 72% | Training loss: 0.688531567410725
Epoch: 51 | Iteration number: [420/565] 74% | Training loss: 0.6885001325891131
Epoch: 51 | Iteration number: [430/565] 76% | Training loss: 0.6884676150111265
Epoch: 51 | Iteration number: [440/565] 77% | Training loss: 0.6884192963892763
Epoch: 51 | Iteration number: [450/565] 79% | Training loss: 0.6883809105555216
Epoch: 51 | Iteration number: [460/565] 81% | Training loss: 0.6883365544288055
Epoch: 51 | Iteration number: [470/565] 83% | Training loss: 0.6883000780927374
Epoch: 51 | Iteration number: [480/565] 84% | Training loss: 0.6882690917700529
Epoch: 51 | Iteration number: [490/565] 86% | Training loss: 0.6882392721516746
Epoch: 51 | Iteration number: [500/565] 88% | Training loss: 0.6882095602750778
Epoch: 51 | Iteration number: [510/565] 90% | Training loss: 0.6881849880312003
Epoch: 51 | Iteration number: [520/565] 92% | Training loss: 0.688158606336667
Epoch: 51 | Iteration number: [530/565] 93% | Training loss: 0.6881389271538213
Epoch: 51 | Iteration number: [540/565] 95% | Training loss: 0.6881190057154055
Epoch: 51 | Iteration number: [550/565] 97% | Training loss: 0.6880781815268776
Epoch: 51 | Iteration number: [560/565] 99% | Training loss: 0.688051939117057

 End of epoch: 51 | Train Loss: 0.686827063349496 | Training Time: 90 

 End of epoch: 51 | Eval Loss: 0.6900539823940822 | Evaluating Time: 6 
Epoch: 52 | Iteration number: [10/565] 1% | Training loss: 0.7553113043308258
Epoch: 52 | Iteration number: [20/565] 3% | Training loss: 0.7211941450834274
Epoch: 52 | Iteration number: [30/565] 5% | Training loss: 0.7097438673178355
Epoch: 52 | Iteration number: [40/565] 7% | Training loss: 0.704142838716507
Epoch: 52 | Iteration number: [50/565] 8% | Training loss: 0.7007193517684936
Epoch: 52 | Iteration number: [60/565] 10% | Training loss: 0.6984495411316554
Epoch: 52 | Iteration number: [70/565] 12% | Training loss: 0.696743152822767
Epoch: 52 | Iteration number: [80/565] 14% | Training loss: 0.6955110915005207
Epoch: 52 | Iteration number: [90/565] 15% | Training loss: 0.6945545030964746
Epoch: 52 | Iteration number: [100/565] 17% | Training loss: 0.6937914836406708
Epoch: 52 | Iteration number: [110/565] 19% | Training loss: 0.6931620982560245
Epoch: 52 | Iteration number: [120/565] 21% | Training loss: 0.6926849161585172
Epoch: 52 | Iteration number: [130/565] 23% | Training loss: 0.6922139342014606
Epoch: 52 | Iteration number: [140/565] 24% | Training loss: 0.691801820056779
Epoch: 52 | Iteration number: [150/565] 26% | Training loss: 0.6914964671929678
Epoch: 52 | Iteration number: [160/565] 28% | Training loss: 0.6911868639290333
Epoch: 52 | Iteration number: [170/565] 30% | Training loss: 0.6909395347623264
Epoch: 52 | Iteration number: [180/565] 31% | Training loss: 0.6907217429743873
Epoch: 52 | Iteration number: [190/565] 33% | Training loss: 0.6905072535339155
Epoch: 52 | Iteration number: [200/565] 35% | Training loss: 0.6903098526597023
Epoch: 52 | Iteration number: [210/565] 37% | Training loss: 0.6901313812959762
Epoch: 52 | Iteration number: [220/565] 38% | Training loss: 0.6899700576608832
Epoch: 52 | Iteration number: [230/565] 40% | Training loss: 0.689828989557598
Epoch: 52 | Iteration number: [240/565] 42% | Training loss: 0.6896967582404614
Epoch: 52 | Iteration number: [250/565] 44% | Training loss: 0.689570654630661
Epoch: 52 | Iteration number: [260/565] 46% | Training loss: 0.6894791857554362
Epoch: 52 | Iteration number: [270/565] 47% | Training loss: 0.6893779271178775
Epoch: 52 | Iteration number: [280/565] 49% | Training loss: 0.6892768342580115
Epoch: 52 | Iteration number: [290/565] 51% | Training loss: 0.6891945914975528
Epoch: 52 | Iteration number: [300/565] 53% | Training loss: 0.689112113515536
Epoch: 52 | Iteration number: [310/565] 54% | Training loss: 0.6890455763186177
Epoch: 52 | Iteration number: [320/565] 56% | Training loss: 0.6889730900526047
Epoch: 52 | Iteration number: [330/565] 58% | Training loss: 0.6889161924521129
Epoch: 52 | Iteration number: [340/565] 60% | Training loss: 0.6888549036839429
Epoch: 52 | Iteration number: [350/565] 61% | Training loss: 0.688795519556318
Epoch: 52 | Iteration number: [360/565] 63% | Training loss: 0.6887351277801725
Epoch: 52 | Iteration number: [370/565] 65% | Training loss: 0.6886843265713872
Epoch: 52 | Iteration number: [380/565] 67% | Training loss: 0.6886380136013031
Epoch: 52 | Iteration number: [390/565] 69% | Training loss: 0.6885906823170491
Epoch: 52 | Iteration number: [400/565] 70% | Training loss: 0.6885499289631843
Epoch: 52 | Iteration number: [410/565] 72% | Training loss: 0.6885115635104295
Epoch: 52 | Iteration number: [420/565] 74% | Training loss: 0.6884813415152686
Epoch: 52 | Iteration number: [430/565] 76% | Training loss: 0.6884427171806956
Epoch: 52 | Iteration number: [440/565] 77% | Training loss: 0.688402111557397
Epoch: 52 | Iteration number: [450/565] 79% | Training loss: 0.6883575605021582
Epoch: 52 | Iteration number: [460/565] 81% | Training loss: 0.6883231681326162
Epoch: 52 | Iteration number: [470/565] 83% | Training loss: 0.6882876028405859
Epoch: 52 | Iteration number: [480/565] 84% | Training loss: 0.6882578262438377
Epoch: 52 | Iteration number: [490/565] 86% | Training loss: 0.6882212412600615
Epoch: 52 | Iteration number: [500/565] 88% | Training loss: 0.688194177865982
Epoch: 52 | Iteration number: [510/565] 90% | Training loss: 0.6881675324019264
Epoch: 52 | Iteration number: [520/565] 92% | Training loss: 0.6881416389575371
Epoch: 52 | Iteration number: [530/565] 93% | Training loss: 0.6881176773107277
Epoch: 52 | Iteration number: [540/565] 95% | Training loss: 0.688094703135667
Epoch: 52 | Iteration number: [550/565] 97% | Training loss: 0.6880728096311742
Epoch: 52 | Iteration number: [560/565] 99% | Training loss: 0.6880502186715602

 End of epoch: 52 | Train Loss: 0.6868276116067329 | Training Time: 89 

 End of epoch: 52 | Eval Loss: 0.6899439096450806 | Evaluating Time: 6 
Epoch: 53 | Iteration number: [10/565] 1% | Training loss: 0.7555633783340454
Epoch: 53 | Iteration number: [20/565] 3% | Training loss: 0.7211643606424332
Epoch: 53 | Iteration number: [30/565] 5% | Training loss: 0.7096967736879984
Epoch: 53 | Iteration number: [40/565] 7% | Training loss: 0.7040476039052009
Epoch: 53 | Iteration number: [50/565] 8% | Training loss: 0.7005701792240143
Epoch: 53 | Iteration number: [60/565] 10% | Training loss: 0.6981841266155243
Epoch: 53 | Iteration number: [70/565] 12% | Training loss: 0.6965294012001583
Epoch: 53 | Iteration number: [80/565] 14% | Training loss: 0.6953210324048996
Epoch: 53 | Iteration number: [90/565] 15% | Training loss: 0.6944173137346904
Epoch: 53 | Iteration number: [100/565] 17% | Training loss: 0.6936841911077499
Epoch: 53 | Iteration number: [110/565] 19% | Training loss: 0.6930448282848705
Epoch: 53 | Iteration number: [120/565] 21% | Training loss: 0.6925179461638132
Epoch: 53 | Iteration number: [130/565] 23% | Training loss: 0.6920831171365884
Epoch: 53 | Iteration number: [140/565] 24% | Training loss: 0.6917329443352563
Epoch: 53 | Iteration number: [150/565] 26% | Training loss: 0.6914069394270579
Epoch: 53 | Iteration number: [160/565] 28% | Training loss: 0.6911314632743597
Epoch: 53 | Iteration number: [170/565] 30% | Training loss: 0.6908925957539502
Epoch: 53 | Iteration number: [180/565] 31% | Training loss: 0.6906721108489566
Epoch: 53 | Iteration number: [190/565] 33% | Training loss: 0.6904847364676626
Epoch: 53 | Iteration number: [200/565] 35% | Training loss: 0.6902884450554848
Epoch: 53 | Iteration number: [210/565] 37% | Training loss: 0.6901016624200912
Epoch: 53 | Iteration number: [220/565] 38% | Training loss: 0.6899576878005808
Epoch: 53 | Iteration number: [230/565] 40% | Training loss: 0.6898292896540269
Epoch: 53 | Iteration number: [240/565] 42% | Training loss: 0.6897165022790432
Epoch: 53 | Iteration number: [250/565] 44% | Training loss: 0.6896031351089478
Epoch: 53 | Iteration number: [260/565] 46% | Training loss: 0.6894790367438243
Epoch: 53 | Iteration number: [270/565] 47% | Training loss: 0.6893820402798829
Epoch: 53 | Iteration number: [280/565] 49% | Training loss: 0.6892901822924614
Epoch: 53 | Iteration number: [290/565] 51% | Training loss: 0.6891936474832995
Epoch: 53 | Iteration number: [300/565] 53% | Training loss: 0.6891291830937067
Epoch: 53 | Iteration number: [310/565] 54% | Training loss: 0.68905404863819
Epoch: 53 | Iteration number: [320/565] 56% | Training loss: 0.6889882139861584
Epoch: 53 | Iteration number: [330/565] 58% | Training loss: 0.6889251398317742
Epoch: 53 | Iteration number: [340/565] 60% | Training loss: 0.6888525449177798
Epoch: 53 | Iteration number: [350/565] 61% | Training loss: 0.6887959037508283
Epoch: 53 | Iteration number: [360/565] 63% | Training loss: 0.6887366599506802
Epoch: 53 | Iteration number: [370/565] 65% | Training loss: 0.6886916187969414
Epoch: 53 | Iteration number: [380/565] 67% | Training loss: 0.6886373286184512
Epoch: 53 | Iteration number: [390/565] 69% | Training loss: 0.6885798500134395
Epoch: 53 | Iteration number: [400/565] 70% | Training loss: 0.6885395249724389
Epoch: 53 | Iteration number: [410/565] 72% | Training loss: 0.6884950466272307
Epoch: 53 | Iteration number: [420/565] 74% | Training loss: 0.6884559483755203
Epoch: 53 | Iteration number: [430/565] 76% | Training loss: 0.6884314391502114
Epoch: 53 | Iteration number: [440/565] 77% | Training loss: 0.6883904645388776
Epoch: 53 | Iteration number: [450/565] 79% | Training loss: 0.6883559552828471
Epoch: 53 | Iteration number: [460/565] 81% | Training loss: 0.6883232287738634
Epoch: 53 | Iteration number: [470/565] 83% | Training loss: 0.6882978958018282
Epoch: 53 | Iteration number: [480/565] 84% | Training loss: 0.6882666292289893
Epoch: 53 | Iteration number: [490/565] 86% | Training loss: 0.6882299757733636
Epoch: 53 | Iteration number: [500/565] 88% | Training loss: 0.6881992673873901
Epoch: 53 | Iteration number: [510/565] 90% | Training loss: 0.6881715444957509
Epoch: 53 | Iteration number: [520/565] 92% | Training loss: 0.6881452380464628
Epoch: 53 | Iteration number: [530/565] 93% | Training loss: 0.6881274735027889
Epoch: 53 | Iteration number: [540/565] 95% | Training loss: 0.6881012757619221
Epoch: 53 | Iteration number: [550/565] 97% | Training loss: 0.688074285658923
Epoch: 53 | Iteration number: [560/565] 99% | Training loss: 0.6880557854260717

 End of epoch: 53 | Train Loss: 0.68682900762136 | Training Time: 89 

 End of epoch: 53 | Eval Loss: 0.6894385644367763 | Evaluating Time: 6 
Epoch: 54 | Iteration number: [10/565] 1% | Training loss: 0.755646699666977
Epoch: 54 | Iteration number: [20/565] 3% | Training loss: 0.721415251493454
Epoch: 54 | Iteration number: [30/565] 5% | Training loss: 0.7098390161991119
Epoch: 54 | Iteration number: [40/565] 7% | Training loss: 0.7039127007126809
Epoch: 54 | Iteration number: [50/565] 8% | Training loss: 0.7005205142498017
Epoch: 54 | Iteration number: [60/565] 10% | Training loss: 0.6981912056605021
Epoch: 54 | Iteration number: [70/565] 12% | Training loss: 0.6965918685708727
Epoch: 54 | Iteration number: [80/565] 14% | Training loss: 0.6953418776392937
Epoch: 54 | Iteration number: [90/565] 15% | Training loss: 0.694341508547465
Epoch: 54 | Iteration number: [100/565] 17% | Training loss: 0.6936070322990417
Epoch: 54 | Iteration number: [110/565] 19% | Training loss: 0.6929973878643729
Epoch: 54 | Iteration number: [120/565] 21% | Training loss: 0.6924852559963862
Epoch: 54 | Iteration number: [130/565] 23% | Training loss: 0.6920587218724764
Epoch: 54 | Iteration number: [140/565] 24% | Training loss: 0.6916711602892195
Epoch: 54 | Iteration number: [150/565] 26% | Training loss: 0.6913655944665273
Epoch: 54 | Iteration number: [160/565] 28% | Training loss: 0.6911100599914789
Epoch: 54 | Iteration number: [170/565] 30% | Training loss: 0.6908170016372905
Epoch: 54 | Iteration number: [180/565] 31% | Training loss: 0.6905858046478696
Epoch: 54 | Iteration number: [190/565] 33% | Training loss: 0.6903945511893222
Epoch: 54 | Iteration number: [200/565] 35% | Training loss: 0.6902174890041352
Epoch: 54 | Iteration number: [210/565] 37% | Training loss: 0.6900532041277204
Epoch: 54 | Iteration number: [220/565] 38% | Training loss: 0.6899209721521897
Epoch: 54 | Iteration number: [230/565] 40% | Training loss: 0.6897649593975232
Epoch: 54 | Iteration number: [240/565] 42% | Training loss: 0.689650468279918
Epoch: 54 | Iteration number: [250/565] 44% | Training loss: 0.6895245687961579
Epoch: 54 | Iteration number: [260/565] 46% | Training loss: 0.6894345228488629
Epoch: 54 | Iteration number: [270/565] 47% | Training loss: 0.6893216250119386
Epoch: 54 | Iteration number: [280/565] 49% | Training loss: 0.6892459860869816
Epoch: 54 | Iteration number: [290/565] 51% | Training loss: 0.6891643581719235
Epoch: 54 | Iteration number: [300/565] 53% | Training loss: 0.6890847963094712
Epoch: 54 | Iteration number: [310/565] 54% | Training loss: 0.6890143140669792
Epoch: 54 | Iteration number: [320/565] 56% | Training loss: 0.6889384498819708
Epoch: 54 | Iteration number: [330/565] 58% | Training loss: 0.6888805089574872
Epoch: 54 | Iteration number: [340/565] 60% | Training loss: 0.6888396513812682
Epoch: 54 | Iteration number: [350/565] 61% | Training loss: 0.6887837472983769
Epoch: 54 | Iteration number: [360/565] 63% | Training loss: 0.6887291765875286
Epoch: 54 | Iteration number: [370/565] 65% | Training loss: 0.6886696844487576
Epoch: 54 | Iteration number: [380/565] 67% | Training loss: 0.6886249030891217
Epoch: 54 | Iteration number: [390/565] 69% | Training loss: 0.6885887835270319
Epoch: 54 | Iteration number: [400/565] 70% | Training loss: 0.6885510464012623
Epoch: 54 | Iteration number: [410/565] 72% | Training loss: 0.6885121797643057
Epoch: 54 | Iteration number: [420/565] 74% | Training loss: 0.6884686340888341
Epoch: 54 | Iteration number: [430/565] 76% | Training loss: 0.68844145467115
Epoch: 54 | Iteration number: [440/565] 77% | Training loss: 0.6883893145756288
Epoch: 54 | Iteration number: [450/565] 79% | Training loss: 0.68835058649381
Epoch: 54 | Iteration number: [460/565] 81% | Training loss: 0.6883224102466002
Epoch: 54 | Iteration number: [470/565] 83% | Training loss: 0.688281163890311
Epoch: 54 | Iteration number: [480/565] 84% | Training loss: 0.6882525888582071
Epoch: 54 | Iteration number: [490/565] 86% | Training loss: 0.6882328352149651
Epoch: 54 | Iteration number: [500/565] 88% | Training loss: 0.6881968970298767
Epoch: 54 | Iteration number: [510/565] 90% | Training loss: 0.6881751676400503
Epoch: 54 | Iteration number: [520/565] 92% | Training loss: 0.6881468140161955
Epoch: 54 | Iteration number: [530/565] 93% | Training loss: 0.6881263281939165
Epoch: 54 | Iteration number: [540/565] 95% | Training loss: 0.6881001897432186
Epoch: 54 | Iteration number: [550/565] 97% | Training loss: 0.6880767727981915
Epoch: 54 | Iteration number: [560/565] 99% | Training loss: 0.6880587607622146

 End of epoch: 54 | Train Loss: 0.6868281634507981 | Training Time: 87 

 End of epoch: 54 | Eval Loss: 0.6901313236781529 | Evaluating Time: 5 
Epoch: 55 | Iteration number: [10/565] 1% | Training loss: 0.7560309290885925
Epoch: 55 | Iteration number: [20/565] 3% | Training loss: 0.7212686091661453
Epoch: 55 | Iteration number: [30/565] 5% | Training loss: 0.7098992188771566
Epoch: 55 | Iteration number: [40/565] 7% | Training loss: 0.7042005598545075
Epoch: 55 | Iteration number: [50/565] 8% | Training loss: 0.7007099294662475
Epoch: 55 | Iteration number: [60/565] 10% | Training loss: 0.698380787173907
Epoch: 55 | Iteration number: [70/565] 12% | Training loss: 0.6967446139880589
Epoch: 55 | Iteration number: [80/565] 14% | Training loss: 0.6954759731888771
Epoch: 55 | Iteration number: [90/565] 15% | Training loss: 0.6945808370908101
Epoch: 55 | Iteration number: [100/565] 17% | Training loss: 0.6938628715276718
Epoch: 55 | Iteration number: [110/565] 19% | Training loss: 0.6932020691308108
Epoch: 55 | Iteration number: [120/565] 21% | Training loss: 0.692676505446434
Epoch: 55 | Iteration number: [130/565] 23% | Training loss: 0.6922411418878115
Epoch: 55 | Iteration number: [140/565] 24% | Training loss: 0.6918543666601181
Epoch: 55 | Iteration number: [150/565] 26% | Training loss: 0.6915224317709605
Epoch: 55 | Iteration number: [160/565] 28% | Training loss: 0.6912351369857788
Epoch: 55 | Iteration number: [170/565] 30% | Training loss: 0.6909530015552745
Epoch: 55 | Iteration number: [180/565] 31% | Training loss: 0.6907227360539966
Epoch: 55 | Iteration number: [190/565] 33% | Training loss: 0.690542964872561
Epoch: 55 | Iteration number: [200/565] 35% | Training loss: 0.690355339050293
Epoch: 55 | Iteration number: [210/565] 37% | Training loss: 0.6901909862245832
Epoch: 55 | Iteration number: [220/565] 38% | Training loss: 0.6900567870248447
Epoch: 55 | Iteration number: [230/565] 40% | Training loss: 0.6899301114289657
Epoch: 55 | Iteration number: [240/565] 42% | Training loss: 0.6897963737448056
Epoch: 55 | Iteration number: [250/565] 44% | Training loss: 0.6896896765232087
Epoch: 55 | Iteration number: [260/565] 46% | Training loss: 0.6895622228200619
Epoch: 55 | Iteration number: [270/565] 47% | Training loss: 0.6894617588431747
Epoch: 55 | Iteration number: [280/565] 49% | Training loss: 0.6893558442592621
Epoch: 55 | Iteration number: [290/565] 51% | Training loss: 0.6892655208193023
Epoch: 55 | Iteration number: [300/565] 53% | Training loss: 0.6891640383005142
Epoch: 55 | Iteration number: [310/565] 54% | Training loss: 0.6890889629240959
Epoch: 55 | Iteration number: [320/565] 56% | Training loss: 0.6890179321169854
Epoch: 55 | Iteration number: [330/565] 58% | Training loss: 0.6889580881956852
Epoch: 55 | Iteration number: [340/565] 60% | Training loss: 0.6888908673735226
Epoch: 55 | Iteration number: [350/565] 61% | Training loss: 0.6888209099428995
Epoch: 55 | Iteration number: [360/565] 63% | Training loss: 0.6887599484788047
Epoch: 55 | Iteration number: [370/565] 65% | Training loss: 0.6886955652688
Epoch: 55 | Iteration number: [380/565] 67% | Training loss: 0.6886636552057768
Epoch: 55 | Iteration number: [390/565] 69% | Training loss: 0.6886059056489896
Epoch: 55 | Iteration number: [400/565] 70% | Training loss: 0.6885523851215839
Epoch: 55 | Iteration number: [410/565] 72% | Training loss: 0.6885151133304689
Epoch: 55 | Iteration number: [420/565] 74% | Training loss: 0.6884697132167362
Epoch: 55 | Iteration number: [430/565] 76% | Training loss: 0.688435603297034
Epoch: 55 | Iteration number: [440/565] 77% | Training loss: 0.6884042913263494
Epoch: 55 | Iteration number: [450/565] 79% | Training loss: 0.6883693669901954
Epoch: 55 | Iteration number: [460/565] 81% | Training loss: 0.6883348002381947
Epoch: 55 | Iteration number: [470/565] 83% | Training loss: 0.6883073383189262
Epoch: 55 | Iteration number: [480/565] 84% | Training loss: 0.6882710942377647
Epoch: 55 | Iteration number: [490/565] 86% | Training loss: 0.688247777734484
Epoch: 55 | Iteration number: [500/565] 88% | Training loss: 0.6882226524353028
Epoch: 55 | Iteration number: [510/565] 90% | Training loss: 0.688188222693462
Epoch: 55 | Iteration number: [520/565] 92% | Training loss: 0.6881522046831938
Epoch: 55 | Iteration number: [530/565] 93% | Training loss: 0.6881254590907186
Epoch: 55 | Iteration number: [540/565] 95% | Training loss: 0.6881033890777164
Epoch: 55 | Iteration number: [550/565] 97% | Training loss: 0.6880875767361034
Epoch: 55 | Iteration number: [560/565] 99% | Training loss: 0.6880612804421357

 End of epoch: 55 | Train Loss: 0.6868389226694023 | Training Time: 88 

 End of epoch: 55 | Eval Loss: 0.6898851139204842 | Evaluating Time: 6 
Epoch: 56 | Iteration number: [10/565] 1% | Training loss: 0.7553779482841492
Epoch: 56 | Iteration number: [20/565] 3% | Training loss: 0.7211331039667129
Epoch: 56 | Iteration number: [30/565] 5% | Training loss: 0.7096036752065022
Epoch: 56 | Iteration number: [40/565] 7% | Training loss: 0.7038683384656906
Epoch: 56 | Iteration number: [50/565] 8% | Training loss: 0.7004639625549316
Epoch: 56 | Iteration number: [60/565] 10% | Training loss: 0.698156201839447
Epoch: 56 | Iteration number: [70/565] 12% | Training loss: 0.6965952396392823
Epoch: 56 | Iteration number: [80/565] 14% | Training loss: 0.6953955866396427
Epoch: 56 | Iteration number: [90/565] 15% | Training loss: 0.6944029596116807
Epoch: 56 | Iteration number: [100/565] 17% | Training loss: 0.6936423230171204
Epoch: 56 | Iteration number: [110/565] 19% | Training loss: 0.6930295635353435
Epoch: 56 | Iteration number: [120/565] 21% | Training loss: 0.6924933314323425
Epoch: 56 | Iteration number: [130/565] 23% | Training loss: 0.6920488132880285
Epoch: 56 | Iteration number: [140/565] 24% | Training loss: 0.6916773119143077
Epoch: 56 | Iteration number: [150/565] 26% | Training loss: 0.69135684410731
Epoch: 56 | Iteration number: [160/565] 28% | Training loss: 0.6910560160875321
Epoch: 56 | Iteration number: [170/565] 30% | Training loss: 0.690811276435852
Epoch: 56 | Iteration number: [180/565] 31% | Training loss: 0.6905997345844904
Epoch: 56 | Iteration number: [190/565] 33% | Training loss: 0.6904275332626544
Epoch: 56 | Iteration number: [200/565] 35% | Training loss: 0.6902583086490631
Epoch: 56 | Iteration number: [210/565] 37% | Training loss: 0.6900735752923148
Epoch: 56 | Iteration number: [220/565] 38% | Training loss: 0.6899075348268856
Epoch: 56 | Iteration number: [230/565] 40% | Training loss: 0.6897793007933575
Epoch: 56 | Iteration number: [240/565] 42% | Training loss: 0.6896624145408471
Epoch: 56 | Iteration number: [250/565] 44% | Training loss: 0.6895474693775177
Epoch: 56 | Iteration number: [260/565] 46% | Training loss: 0.68944164285293
Epoch: 56 | Iteration number: [270/565] 47% | Training loss: 0.689322883994491
Epoch: 56 | Iteration number: [280/565] 49% | Training loss: 0.6892389342188835
Epoch: 56 | Iteration number: [290/565] 51% | Training loss: 0.6891770802695175
Epoch: 56 | Iteration number: [300/565] 53% | Training loss: 0.6891037346919378
Epoch: 56 | Iteration number: [310/565] 54% | Training loss: 0.6890277181902239
Epoch: 56 | Iteration number: [320/565] 56% | Training loss: 0.6889549301937222
Epoch: 56 | Iteration number: [330/565] 58% | Training loss: 0.68889679330768
Epoch: 56 | Iteration number: [340/565] 60% | Training loss: 0.6888450449003892
Epoch: 56 | Iteration number: [350/565] 61% | Training loss: 0.6887964863436563
Epoch: 56 | Iteration number: [360/565] 63% | Training loss: 0.6887337918082873
Epoch: 56 | Iteration number: [370/565] 65% | Training loss: 0.6886849733623298
Epoch: 56 | Iteration number: [380/565] 67% | Training loss: 0.688633822296795
Epoch: 56 | Iteration number: [390/565] 69% | Training loss: 0.6885859955579806
Epoch: 56 | Iteration number: [400/565] 70% | Training loss: 0.6885452504456043
Epoch: 56 | Iteration number: [410/565] 72% | Training loss: 0.6885060537152174
Epoch: 56 | Iteration number: [420/565] 74% | Training loss: 0.6884623431024097
Epoch: 56 | Iteration number: [430/565] 76% | Training loss: 0.6884359137956486
Epoch: 56 | Iteration number: [440/565] 77% | Training loss: 0.6884087907997045
Epoch: 56 | Iteration number: [450/565] 79% | Training loss: 0.6883710698286692
Epoch: 56 | Iteration number: [460/565] 81% | Training loss: 0.6883314163788505
Epoch: 56 | Iteration number: [470/565] 83% | Training loss: 0.6882960020227635
Epoch: 56 | Iteration number: [480/565] 84% | Training loss: 0.6882653063784043
Epoch: 56 | Iteration number: [490/565] 86% | Training loss: 0.6882355338456679
Epoch: 56 | Iteration number: [500/565] 88% | Training loss: 0.6881921994686127
Epoch: 56 | Iteration number: [510/565] 90% | Training loss: 0.6881697179055681
Epoch: 56 | Iteration number: [520/565] 92% | Training loss: 0.6881525900501472
Epoch: 56 | Iteration number: [530/565] 93% | Training loss: 0.6881267700555189
Epoch: 56 | Iteration number: [540/565] 95% | Training loss: 0.6881093164285024
Epoch: 56 | Iteration number: [550/565] 97% | Training loss: 0.6880791903625835
Epoch: 56 | Iteration number: [560/565] 99% | Training loss: 0.6880592823028564

 End of epoch: 56 | Train Loss: 0.6868288368250417 | Training Time: 88 

 End of epoch: 56 | Eval Loss: 0.6896578924996513 | Evaluating Time: 5 
Epoch: 57 | Iteration number: [10/565] 1% | Training loss: 0.7555452406406402
Epoch: 57 | Iteration number: [20/565] 3% | Training loss: 0.7209610939025879
Epoch: 57 | Iteration number: [30/565] 5% | Training loss: 0.7097537000974019
Epoch: 57 | Iteration number: [40/565] 7% | Training loss: 0.7041117683053016
Epoch: 57 | Iteration number: [50/565] 8% | Training loss: 0.7006309008598328
Epoch: 57 | Iteration number: [60/565] 10% | Training loss: 0.6983425249656041
Epoch: 57 | Iteration number: [70/565] 12% | Training loss: 0.6967322843415397
Epoch: 57 | Iteration number: [80/565] 14% | Training loss: 0.6954805977642536
Epoch: 57 | Iteration number: [90/565] 15% | Training loss: 0.6944611661963993
Epoch: 57 | Iteration number: [100/565] 17% | Training loss: 0.6936735689640046
Epoch: 57 | Iteration number: [110/565] 19% | Training loss: 0.6930768717419017
Epoch: 57 | Iteration number: [120/565] 21% | Training loss: 0.6925251101454099
Epoch: 57 | Iteration number: [130/565] 23% | Training loss: 0.6921273731268369
Epoch: 57 | Iteration number: [140/565] 24% | Training loss: 0.6917349696159363
Epoch: 57 | Iteration number: [150/565] 26% | Training loss: 0.6913968722025553
Epoch: 57 | Iteration number: [160/565] 28% | Training loss: 0.6911021012812852
Epoch: 57 | Iteration number: [170/565] 30% | Training loss: 0.6908455505090602
Epoch: 57 | Iteration number: [180/565] 31% | Training loss: 0.6906181938118405
Epoch: 57 | Iteration number: [190/565] 33% | Training loss: 0.6904187243235739
Epoch: 57 | Iteration number: [200/565] 35% | Training loss: 0.6902456417679786
Epoch: 57 | Iteration number: [210/565] 37% | Training loss: 0.6900735568432581
Epoch: 57 | Iteration number: [220/565] 38% | Training loss: 0.6899187088012695
Epoch: 57 | Iteration number: [230/565] 40% | Training loss: 0.6897850684497667
Epoch: 57 | Iteration number: [240/565] 42% | Training loss: 0.6896652427812417
Epoch: 57 | Iteration number: [250/565] 44% | Training loss: 0.689548722743988
Epoch: 57 | Iteration number: [260/565] 46% | Training loss: 0.6894225397935281
Epoch: 57 | Iteration number: [270/565] 47% | Training loss: 0.6893231798101355
Epoch: 57 | Iteration number: [280/565] 49% | Training loss: 0.6892477612410273
Epoch: 57 | Iteration number: [290/565] 51% | Training loss: 0.689162217543043
Epoch: 57 | Iteration number: [300/565] 53% | Training loss: 0.689092811147372
Epoch: 57 | Iteration number: [310/565] 54% | Training loss: 0.6890237846682149
Epoch: 57 | Iteration number: [320/565] 56% | Training loss: 0.6889528768137098
Epoch: 57 | Iteration number: [330/565] 58% | Training loss: 0.6888891301371834
Epoch: 57 | Iteration number: [340/565] 60% | Training loss: 0.688829926182242
Epoch: 57 | Iteration number: [350/565] 61% | Training loss: 0.6887749077592578
Epoch: 57 | Iteration number: [360/565] 63% | Training loss: 0.688730899658468
Epoch: 57 | Iteration number: [370/565] 65% | Training loss: 0.6886858661432524
Epoch: 57 | Iteration number: [380/565] 67% | Training loss: 0.6886408962701497
Epoch: 57 | Iteration number: [390/565] 69% | Training loss: 0.6885809860168359
Epoch: 57 | Iteration number: [400/565] 70% | Training loss: 0.6885228286683559
Epoch: 57 | Iteration number: [410/565] 72% | Training loss: 0.6884811439165255
Epoch: 57 | Iteration number: [420/565] 74% | Training loss: 0.6884371492124739
Epoch: 57 | Iteration number: [430/565] 76% | Training loss: 0.6884011494558911
Epoch: 57 | Iteration number: [440/565] 77% | Training loss: 0.6883733414790847
Epoch: 57 | Iteration number: [450/565] 79% | Training loss: 0.6883329982227749
Epoch: 57 | Iteration number: [460/565] 81% | Training loss: 0.6883014513098675
Epoch: 57 | Iteration number: [470/565] 83% | Training loss: 0.6882711131521996
Epoch: 57 | Iteration number: [480/565] 84% | Training loss: 0.6882403802126646
Epoch: 57 | Iteration number: [490/565] 86% | Training loss: 0.6882214621621735
Epoch: 57 | Iteration number: [500/565] 88% | Training loss: 0.6881900655031205
Epoch: 57 | Iteration number: [510/565] 90% | Training loss: 0.6881582563998653
Epoch: 57 | Iteration number: [520/565] 92% | Training loss: 0.6881318431634169
Epoch: 57 | Iteration number: [530/565] 93% | Training loss: 0.6881083658281363
Epoch: 57 | Iteration number: [540/565] 95% | Training loss: 0.6880929231643677
Epoch: 57 | Iteration number: [550/565] 97% | Training loss: 0.6880628272620114
Epoch: 57 | Iteration number: [560/565] 99% | Training loss: 0.688042311902557

 End of epoch: 57 | Train Loss: 0.6868183903989539 | Training Time: 89 

 End of epoch: 57 | Eval Loss: 0.6896072030067444 | Evaluating Time: 6 
Epoch: 58 | Iteration number: [10/565] 1% | Training loss: 0.7554376184940338
Epoch: 58 | Iteration number: [20/565] 3% | Training loss: 0.72129827439785
Epoch: 58 | Iteration number: [30/565] 5% | Training loss: 0.7097689072291057
Epoch: 58 | Iteration number: [40/565] 7% | Training loss: 0.7039023101329803
Epoch: 58 | Iteration number: [50/565] 8% | Training loss: 0.7004826641082764
Epoch: 58 | Iteration number: [60/565] 10% | Training loss: 0.6982255836327871
Epoch: 58 | Iteration number: [70/565] 12% | Training loss: 0.6966436181749617
Epoch: 58 | Iteration number: [80/565] 14% | Training loss: 0.695415661484003
Epoch: 58 | Iteration number: [90/565] 15% | Training loss: 0.6944608098930782
Epoch: 58 | Iteration number: [100/565] 17% | Training loss: 0.6937361758947372
Epoch: 58 | Iteration number: [110/565] 19% | Training loss: 0.6931153004819697
Epoch: 58 | Iteration number: [120/565] 21% | Training loss: 0.6925715819001198
Epoch: 58 | Iteration number: [130/565] 23% | Training loss: 0.6921064037543077
Epoch: 58 | Iteration number: [140/565] 24% | Training loss: 0.6917095988988876
Epoch: 58 | Iteration number: [150/565] 26% | Training loss: 0.6913759056727091
Epoch: 58 | Iteration number: [160/565] 28% | Training loss: 0.6910968996584416
Epoch: 58 | Iteration number: [170/565] 30% | Training loss: 0.6908288026557249
Epoch: 58 | Iteration number: [180/565] 31% | Training loss: 0.6906061718861262
Epoch: 58 | Iteration number: [190/565] 33% | Training loss: 0.6904014945030212
Epoch: 58 | Iteration number: [200/565] 35% | Training loss: 0.6902459359169006
Epoch: 58 | Iteration number: [210/565] 37% | Training loss: 0.6900750668275923
Epoch: 58 | Iteration number: [220/565] 38% | Training loss: 0.6899453810670159
Epoch: 58 | Iteration number: [230/565] 40% | Training loss: 0.6898141179395758
Epoch: 58 | Iteration number: [240/565] 42% | Training loss: 0.6897063121199608
Epoch: 58 | Iteration number: [250/565] 44% | Training loss: 0.6895966265201569
Epoch: 58 | Iteration number: [260/565] 46% | Training loss: 0.6894924888244042
Epoch: 58 | Iteration number: [270/565] 47% | Training loss: 0.6894021857667852
Epoch: 58 | Iteration number: [280/565] 49% | Training loss: 0.6892917103001049
Epoch: 58 | Iteration number: [290/565] 51% | Training loss: 0.6892159198892528
Epoch: 58 | Iteration number: [300/565] 53% | Training loss: 0.6891425478458405
Epoch: 58 | Iteration number: [310/565] 54% | Training loss: 0.6890591911731228
Epoch: 58 | Iteration number: [320/565] 56% | Training loss: 0.6889888931065797
Epoch: 58 | Iteration number: [330/565] 58% | Training loss: 0.6889252256263386
Epoch: 58 | Iteration number: [340/565] 60% | Training loss: 0.6888621637049843
Epoch: 58 | Iteration number: [350/565] 61% | Training loss: 0.6887915684495654
Epoch: 58 | Iteration number: [360/565] 63% | Training loss: 0.6887347433302138
Epoch: 58 | Iteration number: [370/565] 65% | Training loss: 0.6886868298053741
Epoch: 58 | Iteration number: [380/565] 67% | Training loss: 0.6886407494544983
Epoch: 58 | Iteration number: [390/565] 69% | Training loss: 0.6885915030271579
Epoch: 58 | Iteration number: [400/565] 70% | Training loss: 0.6885449402034283
Epoch: 58 | Iteration number: [410/565] 72% | Training loss: 0.6884875424024536
Epoch: 58 | Iteration number: [420/565] 74% | Training loss: 0.6884441954748971
Epoch: 58 | Iteration number: [430/565] 76% | Training loss: 0.6884091482606045
Epoch: 58 | Iteration number: [440/565] 77% | Training loss: 0.6883748325434598
Epoch: 58 | Iteration number: [450/565] 79% | Training loss: 0.6883362013763852
Epoch: 58 | Iteration number: [460/565] 81% | Training loss: 0.6883022712624591
Epoch: 58 | Iteration number: [470/565] 83% | Training loss: 0.6882674742252268
Epoch: 58 | Iteration number: [480/565] 84% | Training loss: 0.6882459898789723
Epoch: 58 | Iteration number: [490/565] 86% | Training loss: 0.6882188329891282
Epoch: 58 | Iteration number: [500/565] 88% | Training loss: 0.6881847709417344
Epoch: 58 | Iteration number: [510/565] 90% | Training loss: 0.6881461697466233
Epoch: 58 | Iteration number: [520/565] 92% | Training loss: 0.6881177000128306
Epoch: 58 | Iteration number: [530/565] 93% | Training loss: 0.688089791446362
Epoch: 58 | Iteration number: [540/565] 95% | Training loss: 0.6880651649501589
Epoch: 58 | Iteration number: [550/565] 97% | Training loss: 0.6880492737076499
Epoch: 58 | Iteration number: [560/565] 99% | Training loss: 0.6880346699484757

 End of epoch: 58 | Train Loss: 0.6868077167367513 | Training Time: 88 

 End of epoch: 58 | Eval Loss: 0.6892496943473816 | Evaluating Time: 6 
Epoch: 59 | Iteration number: [10/565] 1% | Training loss: 0.7558080375194549
Epoch: 59 | Iteration number: [20/565] 3% | Training loss: 0.7214610785245895
Epoch: 59 | Iteration number: [30/565] 5% | Training loss: 0.7099108477433522
Epoch: 59 | Iteration number: [40/565] 7% | Training loss: 0.7040888428688049
Epoch: 59 | Iteration number: [50/565] 8% | Training loss: 0.7006191635131835
Epoch: 59 | Iteration number: [60/565] 10% | Training loss: 0.6982953310012817
Epoch: 59 | Iteration number: [70/565] 12% | Training loss: 0.69674095085689
Epoch: 59 | Iteration number: [80/565] 14% | Training loss: 0.6954906262457371
Epoch: 59 | Iteration number: [90/565] 15% | Training loss: 0.6945670949088203
Epoch: 59 | Iteration number: [100/565] 17% | Training loss: 0.6937740421295167
Epoch: 59 | Iteration number: [110/565] 19% | Training loss: 0.6931062313643369
Epoch: 59 | Iteration number: [120/565] 21% | Training loss: 0.6925662000974019
Epoch: 59 | Iteration number: [130/565] 23% | Training loss: 0.6921276729840499
Epoch: 59 | Iteration number: [140/565] 24% | Training loss: 0.6917797314269202
Epoch: 59 | Iteration number: [150/565] 26% | Training loss: 0.6914461477597554
Epoch: 59 | Iteration number: [160/565] 28% | Training loss: 0.6911420006304979
Epoch: 59 | Iteration number: [170/565] 30% | Training loss: 0.690885326090981
Epoch: 59 | Iteration number: [180/565] 31% | Training loss: 0.6906471106741163
Epoch: 59 | Iteration number: [190/565] 33% | Training loss: 0.6904499954298923
Epoch: 59 | Iteration number: [200/565] 35% | Training loss: 0.6902632004022599
Epoch: 59 | Iteration number: [210/565] 37% | Training loss: 0.690100318761099
Epoch: 59 | Iteration number: [220/565] 38% | Training loss: 0.6899403433908116
Epoch: 59 | Iteration number: [230/565] 40% | Training loss: 0.6897950208705405
Epoch: 59 | Iteration number: [240/565] 42% | Training loss: 0.6896580286324024
Epoch: 59 | Iteration number: [250/565] 44% | Training loss: 0.6895445065498352
Epoch: 59 | Iteration number: [260/565] 46% | Training loss: 0.6894408750992554
Epoch: 59 | Iteration number: [270/565] 47% | Training loss: 0.6893458233939277
Epoch: 59 | Iteration number: [280/565] 49% | Training loss: 0.6892702641231673
Epoch: 59 | Iteration number: [290/565] 51% | Training loss: 0.6891896085492496
Epoch: 59 | Iteration number: [300/565] 53% | Training loss: 0.689116593003273
Epoch: 59 | Iteration number: [310/565] 54% | Training loss: 0.6890461046849528
Epoch: 59 | Iteration number: [320/565] 56% | Training loss: 0.6889838201925158
Epoch: 59 | Iteration number: [330/565] 58% | Training loss: 0.6889291674801797
Epoch: 59 | Iteration number: [340/565] 60% | Training loss: 0.6888628800125683
Epoch: 59 | Iteration number: [350/565] 61% | Training loss: 0.6887925919464656
Epoch: 59 | Iteration number: [360/565] 63% | Training loss: 0.6887357463439305
Epoch: 59 | Iteration number: [370/565] 65% | Training loss: 0.6886607801592027
Epoch: 59 | Iteration number: [380/565] 67% | Training loss: 0.6886082964508157
Epoch: 59 | Iteration number: [390/565] 69% | Training loss: 0.6885554619324513
Epoch: 59 | Iteration number: [400/565] 70% | Training loss: 0.6885170391201973
Epoch: 59 | Iteration number: [410/565] 72% | Training loss: 0.6884747306021248
Epoch: 59 | Iteration number: [420/565] 74% | Training loss: 0.688438993692398
Epoch: 59 | Iteration number: [430/565] 76% | Training loss: 0.6884153962135315
Epoch: 59 | Iteration number: [440/565] 77% | Training loss: 0.6883872259746898
Epoch: 59 | Iteration number: [450/565] 79% | Training loss: 0.6883512239985996
Epoch: 59 | Iteration number: [460/565] 81% | Training loss: 0.6883171098387759
Epoch: 59 | Iteration number: [470/565] 83% | Training loss: 0.6882788243445944
Epoch: 59 | Iteration number: [480/565] 84% | Training loss: 0.6882451004038255
Epoch: 59 | Iteration number: [490/565] 86% | Training loss: 0.6882268350951526
Epoch: 59 | Iteration number: [500/565] 88% | Training loss: 0.6882032164335251
Epoch: 59 | Iteration number: [510/565] 90% | Training loss: 0.6881812192645728
Epoch: 59 | Iteration number: [520/565] 92% | Training loss: 0.6881518015494713
Epoch: 59 | Iteration number: [530/565] 93% | Training loss: 0.6881341059252901
Epoch: 59 | Iteration number: [540/565] 95% | Training loss: 0.6881117234627406
Epoch: 59 | Iteration number: [550/565] 97% | Training loss: 0.6880867317589846
Epoch: 59 | Iteration number: [560/565] 99% | Training loss: 0.688069680013827

 End of epoch: 59 | Train Loss: 0.6868457731947435 | Training Time: 89 

 End of epoch: 59 | Eval Loss: 0.689027454171862 | Evaluating Time: 6 
Epoch: 60 | Iteration number: [10/565] 1% | Training loss: 0.7551363706588745
Epoch: 60 | Iteration number: [20/565] 3% | Training loss: 0.721103897690773
Epoch: 60 | Iteration number: [30/565] 5% | Training loss: 0.7096940179665884
Epoch: 60 | Iteration number: [40/565] 7% | Training loss: 0.7039707735180855
Epoch: 60 | Iteration number: [50/565] 8% | Training loss: 0.7005359268188477
Epoch: 60 | Iteration number: [60/565] 10% | Training loss: 0.6982066124677658
Epoch: 60 | Iteration number: [70/565] 12% | Training loss: 0.6966317806925092
Epoch: 60 | Iteration number: [80/565] 14% | Training loss: 0.6954772636294365
Epoch: 60 | Iteration number: [90/565] 15% | Training loss: 0.694551420211792
Epoch: 60 | Iteration number: [100/565] 17% | Training loss: 0.6937724381685257
Epoch: 60 | Iteration number: [110/565] 19% | Training loss: 0.6931659893556075
Epoch: 60 | Iteration number: [120/565] 21% | Training loss: 0.6926510721445084
Epoch: 60 | Iteration number: [130/565] 23% | Training loss: 0.6921594844414638
Epoch: 60 | Iteration number: [140/565] 24% | Training loss: 0.6917586330856595
Epoch: 60 | Iteration number: [150/565] 26% | Training loss: 0.6914157748222352
Epoch: 60 | Iteration number: [160/565] 28% | Training loss: 0.6911318000406027
Epoch: 60 | Iteration number: [170/565] 30% | Training loss: 0.6908837644492879
Epoch: 60 | Iteration number: [180/565] 31% | Training loss: 0.6906622979376051
Epoch: 60 | Iteration number: [190/565] 33% | Training loss: 0.6904638808024557
Epoch: 60 | Iteration number: [200/565] 35% | Training loss: 0.6902903428673745
Epoch: 60 | Iteration number: [210/565] 37% | Training loss: 0.6901395715418316
Epoch: 60 | Iteration number: [220/565] 38% | Training loss: 0.6899751351638274
Epoch: 60 | Iteration number: [230/565] 40% | Training loss: 0.6898202929807746
Epoch: 60 | Iteration number: [240/565] 42% | Training loss: 0.6896890603005886
Epoch: 60 | Iteration number: [250/565] 44% | Training loss: 0.6895715618133544
Epoch: 60 | Iteration number: [260/565] 46% | Training loss: 0.6894609728684792
Epoch: 60 | Iteration number: [270/565] 47% | Training loss: 0.6893592375296134
Epoch: 60 | Iteration number: [280/565] 49% | Training loss: 0.6892459658639771
Epoch: 60 | Iteration number: [290/565] 51% | Training loss: 0.6891749445734353
Epoch: 60 | Iteration number: [300/565] 53% | Training loss: 0.6890995613733928
Epoch: 60 | Iteration number: [310/565] 54% | Training loss: 0.6890383735779793
Epoch: 60 | Iteration number: [320/565] 56% | Training loss: 0.6889726592227816
Epoch: 60 | Iteration number: [330/565] 58% | Training loss: 0.688903623638731
Epoch: 60 | Iteration number: [340/565] 60% | Training loss: 0.688843134746832
Epoch: 60 | Iteration number: [350/565] 61% | Training loss: 0.6887797732012613
Epoch: 60 | Iteration number: [360/565] 63% | Training loss: 0.688721722861131
Epoch: 60 | Iteration number: [370/565] 65% | Training loss: 0.6886669471457197
Epoch: 60 | Iteration number: [380/565] 67% | Training loss: 0.6886207844081678
Epoch: 60 | Iteration number: [390/565] 69% | Training loss: 0.6885723902628972
Epoch: 60 | Iteration number: [400/565] 70% | Training loss: 0.6885259202122689
Epoch: 60 | Iteration number: [410/565] 72% | Training loss: 0.6884874089462001
Epoch: 60 | Iteration number: [420/565] 74% | Training loss: 0.6884352012759163
Epoch: 60 | Iteration number: [430/565] 76% | Training loss: 0.6883912433025449
Epoch: 60 | Iteration number: [440/565] 77% | Training loss: 0.6883560872890733
Epoch: 60 | Iteration number: [450/565] 79% | Training loss: 0.688326311773724
Epoch: 60 | Iteration number: [460/565] 81% | Training loss: 0.6882884076108103
Epoch: 60 | Iteration number: [470/565] 83% | Training loss: 0.6882615892176932
Epoch: 60 | Iteration number: [480/565] 84% | Training loss: 0.6882283752163251
Epoch: 60 | Iteration number: [490/565] 86% | Training loss: 0.688205863748278
Epoch: 60 | Iteration number: [500/565] 88% | Training loss: 0.6881856863498688
Epoch: 60 | Iteration number: [510/565] 90% | Training loss: 0.6881604479808433
Epoch: 60 | Iteration number: [520/565] 92% | Training loss: 0.6881293270450372
Epoch: 60 | Iteration number: [530/565] 93% | Training loss: 0.6881100833415985
Epoch: 60 | Iteration number: [540/565] 95% | Training loss: 0.6880832211838828
Epoch: 60 | Iteration number: [550/565] 97% | Training loss: 0.6880616260658611
Epoch: 60 | Iteration number: [560/565] 99% | Training loss: 0.6880398682185582

 End of epoch: 60 | Train Loss: 0.6868148653908114 | Training Time: 90 

 End of epoch: 60 | Eval Loss: 0.6892851420811245 | Evaluating Time: 6 
Epoch: 61 | Iteration number: [10/565] 1% | Training loss: 0.7558027803897858
Epoch: 61 | Iteration number: [20/565] 3% | Training loss: 0.7214236497879029
Epoch: 61 | Iteration number: [30/565] 5% | Training loss: 0.7098791897296906
Epoch: 61 | Iteration number: [40/565] 7% | Training loss: 0.7041173219680786
Epoch: 61 | Iteration number: [50/565] 8% | Training loss: 0.7007053124904633
Epoch: 61 | Iteration number: [60/565] 10% | Training loss: 0.6982899715503057
Epoch: 61 | Iteration number: [70/565] 12% | Training loss: 0.6966633038861411
Epoch: 61 | Iteration number: [80/565] 14% | Training loss: 0.6953852623701096
Epoch: 61 | Iteration number: [90/565] 15% | Training loss: 0.6944468034638299
Epoch: 61 | Iteration number: [100/565] 17% | Training loss: 0.6937015235424042
Epoch: 61 | Iteration number: [110/565] 19% | Training loss: 0.6930892337452281
Epoch: 61 | Iteration number: [120/565] 21% | Training loss: 0.6925973440210025
Epoch: 61 | Iteration number: [130/565] 23% | Training loss: 0.6921555853807009
Epoch: 61 | Iteration number: [140/565] 24% | Training loss: 0.6917650537831442
Epoch: 61 | Iteration number: [150/565] 26% | Training loss: 0.6914584426085154
Epoch: 61 | Iteration number: [160/565] 28% | Training loss: 0.6911712802946568
Epoch: 61 | Iteration number: [170/565] 30% | Training loss: 0.690914444362416
Epoch: 61 | Iteration number: [180/565] 31% | Training loss: 0.690674278471205
Epoch: 61 | Iteration number: [190/565] 33% | Training loss: 0.6904595823664414
Epoch: 61 | Iteration number: [200/565] 35% | Training loss: 0.6902993184328079
Epoch: 61 | Iteration number: [210/565] 37% | Training loss: 0.6901281609421684
Epoch: 61 | Iteration number: [220/565] 38% | Training loss: 0.689981716058471
Epoch: 61 | Iteration number: [230/565] 40% | Training loss: 0.6898436696633049
Epoch: 61 | Iteration number: [240/565] 42% | Training loss: 0.6897383987903595
Epoch: 61 | Iteration number: [250/565] 44% | Training loss: 0.6896238369941712
Epoch: 61 | Iteration number: [260/565] 46% | Training loss: 0.6895248784468724
Epoch: 61 | Iteration number: [270/565] 47% | Training loss: 0.6894338144196405
Epoch: 61 | Iteration number: [280/565] 49% | Training loss: 0.6893326784883227
Epoch: 61 | Iteration number: [290/565] 51% | Training loss: 0.6892492789646675
Epoch: 61 | Iteration number: [300/565] 53% | Training loss: 0.689172646800677
Epoch: 61 | Iteration number: [310/565] 54% | Training loss: 0.6890838069300498
Epoch: 61 | Iteration number: [320/565] 56% | Training loss: 0.6889999421313405
Epoch: 61 | Iteration number: [330/565] 58% | Training loss: 0.6889276598439072
Epoch: 61 | Iteration number: [340/565] 60% | Training loss: 0.6888668817632339
Epoch: 61 | Iteration number: [350/565] 61% | Training loss: 0.6888152209350041
Epoch: 61 | Iteration number: [360/565] 63% | Training loss: 0.6887550572554271
Epoch: 61 | Iteration number: [370/565] 65% | Training loss: 0.6887035999749158
Epoch: 61 | Iteration number: [380/565] 67% | Training loss: 0.6886465061652033
Epoch: 61 | Iteration number: [390/565] 69% | Training loss: 0.6886005971676264
Epoch: 61 | Iteration number: [400/565] 70% | Training loss: 0.6885558167099952
Epoch: 61 | Iteration number: [410/565] 72% | Training loss: 0.6885107851609951
Epoch: 61 | Iteration number: [420/565] 74% | Training loss: 0.6884689329635529
Epoch: 61 | Iteration number: [430/565] 76% | Training loss: 0.688426800106847
Epoch: 61 | Iteration number: [440/565] 77% | Training loss: 0.6883879549124025
Epoch: 61 | Iteration number: [450/565] 79% | Training loss: 0.688349849515491
Epoch: 61 | Iteration number: [460/565] 81% | Training loss: 0.6883234293564506
Epoch: 61 | Iteration number: [470/565] 83% | Training loss: 0.6882950149952097
Epoch: 61 | Iteration number: [480/565] 84% | Training loss: 0.6882649468878905
Epoch: 61 | Iteration number: [490/565] 86% | Training loss: 0.6882290228289001
Epoch: 61 | Iteration number: [500/565] 88% | Training loss: 0.6881950083971023
Epoch: 61 | Iteration number: [510/565] 90% | Training loss: 0.6881643019470514
Epoch: 61 | Iteration number: [520/565] 92% | Training loss: 0.6881308846748793
Epoch: 61 | Iteration number: [530/565] 93% | Training loss: 0.6881127305750577
Epoch: 61 | Iteration number: [540/565] 95% | Training loss: 0.6880870725269671
Epoch: 61 | Iteration number: [550/565] 97% | Training loss: 0.6880675208568573
Epoch: 61 | Iteration number: [560/565] 99% | Training loss: 0.6880470874054091

 End of epoch: 61 | Train Loss: 0.6868191972243047 | Training Time: 88 

 End of epoch: 61 | Eval Loss: 0.6894361547061375 | Evaluating Time: 6 
Epoch: 62 | Iteration number: [10/565] 1% | Training loss: 0.7558132410049438
Epoch: 62 | Iteration number: [20/565] 3% | Training loss: 0.721471318602562
Epoch: 62 | Iteration number: [30/565] 5% | Training loss: 0.7098476668198903
Epoch: 62 | Iteration number: [40/565] 7% | Training loss: 0.7040310099720954
Epoch: 62 | Iteration number: [50/565] 8% | Training loss: 0.7006621944904328
Epoch: 62 | Iteration number: [60/565] 10% | Training loss: 0.6983098636070887
Epoch: 62 | Iteration number: [70/565] 12% | Training loss: 0.6966363097940172
Epoch: 62 | Iteration number: [80/565] 14% | Training loss: 0.6953738272190094
Epoch: 62 | Iteration number: [90/565] 15% | Training loss: 0.6944030655754937
Epoch: 62 | Iteration number: [100/565] 17% | Training loss: 0.6936724972724915
Epoch: 62 | Iteration number: [110/565] 19% | Training loss: 0.6930310579863461
Epoch: 62 | Iteration number: [120/565] 21% | Training loss: 0.6925052349766095
Epoch: 62 | Iteration number: [130/565] 23% | Training loss: 0.6920493249709789
Epoch: 62 | Iteration number: [140/565] 24% | Training loss: 0.6916613004037312
Epoch: 62 | Iteration number: [150/565] 26% | Training loss: 0.6913426681359609
Epoch: 62 | Iteration number: [160/565] 28% | Training loss: 0.6910807058215142
Epoch: 62 | Iteration number: [170/565] 30% | Training loss: 0.6908383856801426
Epoch: 62 | Iteration number: [180/565] 31% | Training loss: 0.69063195321295
Epoch: 62 | Iteration number: [190/565] 33% | Training loss: 0.6904249668121338
Epoch: 62 | Iteration number: [200/565] 35% | Training loss: 0.6902390146255493
Epoch: 62 | Iteration number: [210/565] 37% | Training loss: 0.6900758672328222
Epoch: 62 | Iteration number: [220/565] 38% | Training loss: 0.6899330867962403
Epoch: 62 | Iteration number: [230/565] 40% | Training loss: 0.6898085138072139
Epoch: 62 | Iteration number: [240/565] 42% | Training loss: 0.6896888710558414
Epoch: 62 | Iteration number: [250/565] 44% | Training loss: 0.6895724151134491
Epoch: 62 | Iteration number: [260/565] 46% | Training loss: 0.6894583362799425
Epoch: 62 | Iteration number: [270/565] 47% | Training loss: 0.6893569533471708
Epoch: 62 | Iteration number: [280/565] 49% | Training loss: 0.6892716135297503
Epoch: 62 | Iteration number: [290/565] 51% | Training loss: 0.6891895877903905
Epoch: 62 | Iteration number: [300/565] 53% | Training loss: 0.6890955185890197
Epoch: 62 | Iteration number: [310/565] 54% | Training loss: 0.6890004688693631
Epoch: 62 | Iteration number: [320/565] 56% | Training loss: 0.6889485547319054
Epoch: 62 | Iteration number: [330/565] 58% | Training loss: 0.6888898549657879
Epoch: 62 | Iteration number: [340/565] 60% | Training loss: 0.6888279518660377
Epoch: 62 | Iteration number: [350/565] 61% | Training loss: 0.6887710748400007
Epoch: 62 | Iteration number: [360/565] 63% | Training loss: 0.6887081088291274
Epoch: 62 | Iteration number: [370/565] 65% | Training loss: 0.6886529872546325
Epoch: 62 | Iteration number: [380/565] 67% | Training loss: 0.6885997256166057
Epoch: 62 | Iteration number: [390/565] 69% | Training loss: 0.6885501450453049
Epoch: 62 | Iteration number: [400/565] 70% | Training loss: 0.6885011284053326
Epoch: 62 | Iteration number: [410/565] 72% | Training loss: 0.688467558273455
Epoch: 62 | Iteration number: [420/565] 74% | Training loss: 0.6884343517678124
Epoch: 62 | Iteration number: [430/565] 76% | Training loss: 0.6884028878322868
Epoch: 62 | Iteration number: [440/565] 77% | Training loss: 0.6883586204864762
Epoch: 62 | Iteration number: [450/565] 79% | Training loss: 0.6883233875698513
Epoch: 62 | Iteration number: [460/565] 81% | Training loss: 0.6882975696221642
Epoch: 62 | Iteration number: [470/565] 83% | Training loss: 0.68825699141685
Epoch: 62 | Iteration number: [480/565] 84% | Training loss: 0.6882352406779925
Epoch: 62 | Iteration number: [490/565] 86% | Training loss: 0.6882081393076449
Epoch: 62 | Iteration number: [500/565] 88% | Training loss: 0.6881816853284836
Epoch: 62 | Iteration number: [510/565] 90% | Training loss: 0.6881623001659618
Epoch: 62 | Iteration number: [520/565] 92% | Training loss: 0.6881389161715141
Epoch: 62 | Iteration number: [530/565] 93% | Training loss: 0.6881105171059663
Epoch: 62 | Iteration number: [540/565] 95% | Training loss: 0.6880885098819379
Epoch: 62 | Iteration number: [550/565] 97% | Training loss: 0.6880633266405626
Epoch: 62 | Iteration number: [560/565] 99% | Training loss: 0.6880330489150115

 End of epoch: 62 | Train Loss: 0.6868086319054123 | Training Time: 89 

 End of epoch: 62 | Eval Loss: 0.689387994153159 | Evaluating Time: 6 
Epoch: 63 | Iteration number: [10/565] 1% | Training loss: 0.7551178336143494
Epoch: 63 | Iteration number: [20/565] 3% | Training loss: 0.7208711534738541
Epoch: 63 | Iteration number: [30/565] 5% | Training loss: 0.7094632307688395
Epoch: 63 | Iteration number: [40/565] 7% | Training loss: 0.7037160053849221
Epoch: 63 | Iteration number: [50/565] 8% | Training loss: 0.7004383528232574
Epoch: 63 | Iteration number: [60/565] 10% | Training loss: 0.6981628388166428
Epoch: 63 | Iteration number: [70/565] 12% | Training loss: 0.6964995494910649
Epoch: 63 | Iteration number: [80/565] 14% | Training loss: 0.6952352792024612
Epoch: 63 | Iteration number: [90/565] 15% | Training loss: 0.6943273266156514
Epoch: 63 | Iteration number: [100/565] 17% | Training loss: 0.6936091566085816
Epoch: 63 | Iteration number: [110/565] 19% | Training loss: 0.6929553400386463
Epoch: 63 | Iteration number: [120/565] 21% | Training loss: 0.6924329896767935
Epoch: 63 | Iteration number: [130/565] 23% | Training loss: 0.6920248283789708
Epoch: 63 | Iteration number: [140/565] 24% | Training loss: 0.6916576266288758
Epoch: 63 | Iteration number: [150/565] 26% | Training loss: 0.69135768532753
Epoch: 63 | Iteration number: [160/565] 28% | Training loss: 0.6911064270883799
Epoch: 63 | Iteration number: [170/565] 30% | Training loss: 0.6908491713159225
Epoch: 63 | Iteration number: [180/565] 31% | Training loss: 0.6906295398871104
Epoch: 63 | Iteration number: [190/565] 33% | Training loss: 0.6904288712300752
Epoch: 63 | Iteration number: [200/565] 35% | Training loss: 0.6902423247694969
Epoch: 63 | Iteration number: [210/565] 37% | Training loss: 0.6900968432426453
Epoch: 63 | Iteration number: [220/565] 38% | Training loss: 0.6899457955902273
Epoch: 63 | Iteration number: [230/565] 40% | Training loss: 0.689799839258194
Epoch: 63 | Iteration number: [240/565] 42% | Training loss: 0.6896725594997406
Epoch: 63 | Iteration number: [250/565] 44% | Training loss: 0.6895244798660278
Epoch: 63 | Iteration number: [260/565] 46% | Training loss: 0.689426853106572
Epoch: 63 | Iteration number: [270/565] 47% | Training loss: 0.689319564015777
Epoch: 63 | Iteration number: [280/565] 49% | Training loss: 0.6892219473208699
Epoch: 63 | Iteration number: [290/565] 51% | Training loss: 0.6891513388732384
Epoch: 63 | Iteration number: [300/565] 53% | Training loss: 0.6890820801258087
Epoch: 63 | Iteration number: [310/565] 54% | Training loss: 0.689013639573128
Epoch: 63 | Iteration number: [320/565] 56% | Training loss: 0.6889467999339104
Epoch: 63 | Iteration number: [330/565] 58% | Training loss: 0.6888721944707813
Epoch: 63 | Iteration number: [340/565] 60% | Training loss: 0.6887964490581961
Epoch: 63 | Iteration number: [350/565] 61% | Training loss: 0.6887442248208182
Epoch: 63 | Iteration number: [360/565] 63% | Training loss: 0.688685665362411
Epoch: 63 | Iteration number: [370/565] 65% | Training loss: 0.6886133606369431
Epoch: 63 | Iteration number: [380/565] 67% | Training loss: 0.6885700299551613
Epoch: 63 | Iteration number: [390/565] 69% | Training loss: 0.6885224469197102
Epoch: 63 | Iteration number: [400/565] 70% | Training loss: 0.6884857384860515
Epoch: 63 | Iteration number: [410/565] 72% | Training loss: 0.6884490947897841
Epoch: 63 | Iteration number: [420/565] 74% | Training loss: 0.6884114123526074
Epoch: 63 | Iteration number: [430/565] 76% | Training loss: 0.6883632851201434
Epoch: 63 | Iteration number: [440/565] 77% | Training loss: 0.6883332374421033
Epoch: 63 | Iteration number: [450/565] 79% | Training loss: 0.6882870217164357
Epoch: 63 | Iteration number: [460/565] 81% | Training loss: 0.6882613699073377
Epoch: 63 | Iteration number: [470/565] 83% | Training loss: 0.6882250381276963
Epoch: 63 | Iteration number: [480/565] 84% | Training loss: 0.6882059754182895
Epoch: 63 | Iteration number: [490/565] 86% | Training loss: 0.6881867166684599
Epoch: 63 | Iteration number: [500/565] 88% | Training loss: 0.6881629388332366
Epoch: 63 | Iteration number: [510/565] 90% | Training loss: 0.6881343583265941
Epoch: 63 | Iteration number: [520/565] 92% | Training loss: 0.6881130826014739
Epoch: 63 | Iteration number: [530/565] 93% | Training loss: 0.6880988665346829
Epoch: 63 | Iteration number: [540/565] 95% | Training loss: 0.6880783428748448
Epoch: 63 | Iteration number: [550/565] 97% | Training loss: 0.6880628059127114
Epoch: 63 | Iteration number: [560/565] 99% | Training loss: 0.6880364266889436

 End of epoch: 63 | Train Loss: 0.6868088865702131 | Training Time: 88 

 End of epoch: 63 | Eval Loss: 0.6897262845720563 | Evaluating Time: 5 
Epoch: 64 | Iteration number: [10/565] 1% | Training loss: 0.754972517490387
Epoch: 64 | Iteration number: [20/565] 3% | Training loss: 0.7211186945438385
Epoch: 64 | Iteration number: [30/565] 5% | Training loss: 0.709782071908315
Epoch: 64 | Iteration number: [40/565] 7% | Training loss: 0.7040880560874939
Epoch: 64 | Iteration number: [50/565] 8% | Training loss: 0.7006205821037292
Epoch: 64 | Iteration number: [60/565] 10% | Training loss: 0.6982962777217229
Epoch: 64 | Iteration number: [70/565] 12% | Training loss: 0.6966529139450618
Epoch: 64 | Iteration number: [80/565] 14% | Training loss: 0.6954661466181278
Epoch: 64 | Iteration number: [90/565] 15% | Training loss: 0.694502368900511
Epoch: 64 | Iteration number: [100/565] 17% | Training loss: 0.6937855869531632
Epoch: 64 | Iteration number: [110/565] 19% | Training loss: 0.6931745919314298
Epoch: 64 | Iteration number: [120/565] 21% | Training loss: 0.6926096906264623
Epoch: 64 | Iteration number: [130/565] 23% | Training loss: 0.6921525758046371
Epoch: 64 | Iteration number: [140/565] 24% | Training loss: 0.6917761415243149
Epoch: 64 | Iteration number: [150/565] 26% | Training loss: 0.6914659591515859
Epoch: 64 | Iteration number: [160/565] 28% | Training loss: 0.691177175194025
Epoch: 64 | Iteration number: [170/565] 30% | Training loss: 0.6909253926838146
Epoch: 64 | Iteration number: [180/565] 31% | Training loss: 0.6906964206033283
Epoch: 64 | Iteration number: [190/565] 33% | Training loss: 0.6904930644913724
Epoch: 64 | Iteration number: [200/565] 35% | Training loss: 0.6903033259510994
Epoch: 64 | Iteration number: [210/565] 37% | Training loss: 0.6901382267475128
Epoch: 64 | Iteration number: [220/565] 38% | Training loss: 0.6899789918552746
Epoch: 64 | Iteration number: [230/565] 40% | Training loss: 0.6898380551649177
Epoch: 64 | Iteration number: [240/565] 42% | Training loss: 0.6896997841695944
Epoch: 64 | Iteration number: [250/565] 44% | Training loss: 0.6895703566074372
Epoch: 64 | Iteration number: [260/565] 46% | Training loss: 0.6894509249008619
Epoch: 64 | Iteration number: [270/565] 47% | Training loss: 0.6893567586386645
Epoch: 64 | Iteration number: [280/565] 49% | Training loss: 0.6892706673060145
Epoch: 64 | Iteration number: [290/565] 51% | Training loss: 0.6891814402465163
Epoch: 64 | Iteration number: [300/565] 53% | Training loss: 0.6890990676482519
Epoch: 64 | Iteration number: [310/565] 54% | Training loss: 0.6890284659401062
Epoch: 64 | Iteration number: [320/565] 56% | Training loss: 0.6889634100720287
Epoch: 64 | Iteration number: [330/565] 58% | Training loss: 0.6888971724293449
Epoch: 64 | Iteration number: [340/565] 60% | Training loss: 0.6888224312487771
Epoch: 64 | Iteration number: [350/565] 61% | Training loss: 0.6887652238777705
Epoch: 64 | Iteration number: [360/565] 63% | Training loss: 0.6887140449550416
Epoch: 64 | Iteration number: [370/565] 65% | Training loss: 0.6886530143183631
Epoch: 64 | Iteration number: [380/565] 67% | Training loss: 0.688598389688291
Epoch: 64 | Iteration number: [390/565] 69% | Training loss: 0.6885573778396997
Epoch: 64 | Iteration number: [400/565] 70% | Training loss: 0.6885217320919037
Epoch: 64 | Iteration number: [410/565] 72% | Training loss: 0.6884844926799216
Epoch: 64 | Iteration number: [420/565] 74% | Training loss: 0.688439595983142
Epoch: 64 | Iteration number: [430/565] 76% | Training loss: 0.6883991502052129
Epoch: 64 | Iteration number: [440/565] 77% | Training loss: 0.6883578999475999
Epoch: 64 | Iteration number: [450/565] 79% | Training loss: 0.6883299769295587
Epoch: 64 | Iteration number: [460/565] 81% | Training loss: 0.6883060408675152
Epoch: 64 | Iteration number: [470/565] 83% | Training loss: 0.6882674767615947
Epoch: 64 | Iteration number: [480/565] 84% | Training loss: 0.6882341880351305
Epoch: 64 | Iteration number: [490/565] 86% | Training loss: 0.6882103557489356
Epoch: 64 | Iteration number: [500/565] 88% | Training loss: 0.688183574795723
Epoch: 64 | Iteration number: [510/565] 90% | Training loss: 0.6881612949511584
Epoch: 64 | Iteration number: [520/565] 92% | Training loss: 0.6881350259368236
Epoch: 64 | Iteration number: [530/565] 93% | Training loss: 0.6881096333827612
Epoch: 64 | Iteration number: [540/565] 95% | Training loss: 0.6880834541938923
Epoch: 64 | Iteration number: [550/565] 97% | Training loss: 0.6880560139092532
Epoch: 64 | Iteration number: [560/565] 99% | Training loss: 0.6880305309380804

 End of epoch: 64 | Train Loss: 0.686807739207175 | Training Time: 88 

 End of epoch: 64 | Eval Loss: 0.6894491570336478 | Evaluating Time: 6 
Epoch: 65 | Iteration number: [10/565] 1% | Training loss: 0.7551845848560333
Epoch: 65 | Iteration number: [20/565] 3% | Training loss: 0.7209821552038193
Epoch: 65 | Iteration number: [30/565] 5% | Training loss: 0.7095847368240357
Epoch: 65 | Iteration number: [40/565] 7% | Training loss: 0.7039512917399406
Epoch: 65 | Iteration number: [50/565] 8% | Training loss: 0.7005332827568054
Epoch: 65 | Iteration number: [60/565] 10% | Training loss: 0.6982688228289287
Epoch: 65 | Iteration number: [70/565] 12% | Training loss: 0.6966759153774806
Epoch: 65 | Iteration number: [80/565] 14% | Training loss: 0.695422713458538
Epoch: 65 | Iteration number: [90/565] 15% | Training loss: 0.6944914533032311
Epoch: 65 | Iteration number: [100/565] 17% | Training loss: 0.6936732476949692
Epoch: 65 | Iteration number: [110/565] 19% | Training loss: 0.6930095569653945
Epoch: 65 | Iteration number: [120/565] 21% | Training loss: 0.6924927607178688
Epoch: 65 | Iteration number: [130/565] 23% | Training loss: 0.6920595911832956
Epoch: 65 | Iteration number: [140/565] 24% | Training loss: 0.6916704254490988
Epoch: 65 | Iteration number: [150/565] 26% | Training loss: 0.6913434422016144
Epoch: 65 | Iteration number: [160/565] 28% | Training loss: 0.691040463373065
Epoch: 65 | Iteration number: [170/565] 30% | Training loss: 0.6907990774687599
Epoch: 65 | Iteration number: [180/565] 31% | Training loss: 0.6905797964996762
Epoch: 65 | Iteration number: [190/565] 33% | Training loss: 0.6903875526628996
Epoch: 65 | Iteration number: [200/565] 35% | Training loss: 0.6901954945921898
Epoch: 65 | Iteration number: [210/565] 37% | Training loss: 0.6900164110319955
Epoch: 65 | Iteration number: [220/565] 38% | Training loss: 0.6898712588982149
Epoch: 65 | Iteration number: [230/565] 40% | Training loss: 0.6897185154583143
Epoch: 65 | Iteration number: [240/565] 42% | Training loss: 0.6896086886525155
Epoch: 65 | Iteration number: [250/565] 44% | Training loss: 0.6895012910366058
Epoch: 65 | Iteration number: [260/565] 46% | Training loss: 0.6893865101612531
Epoch: 65 | Iteration number: [270/565] 47% | Training loss: 0.6892997878569144
Epoch: 65 | Iteration number: [280/565] 49% | Training loss: 0.6892206130283219
Epoch: 65 | Iteration number: [290/565] 51% | Training loss: 0.6891406838236184
Epoch: 65 | Iteration number: [300/565] 53% | Training loss: 0.6890688443183899
Epoch: 65 | Iteration number: [310/565] 54% | Training loss: 0.6890017826710978
Epoch: 65 | Iteration number: [320/565] 56% | Training loss: 0.6889555308967829
Epoch: 65 | Iteration number: [330/565] 58% | Training loss: 0.6888845458175197
Epoch: 65 | Iteration number: [340/565] 60% | Training loss: 0.6888073111281675
Epoch: 65 | Iteration number: [350/565] 61% | Training loss: 0.6887595765931266
Epoch: 65 | Iteration number: [360/565] 63% | Training loss: 0.688688690132565
Epoch: 65 | Iteration number: [370/565] 65% | Training loss: 0.6886416309588664
Epoch: 65 | Iteration number: [380/565] 67% | Training loss: 0.6885763549490979
Epoch: 65 | Iteration number: [390/565] 69% | Training loss: 0.6885302551281758
Epoch: 65 | Iteration number: [400/565] 70% | Training loss: 0.6884924007952213
Epoch: 65 | Iteration number: [410/565] 72% | Training loss: 0.6884598609877796
Epoch: 65 | Iteration number: [420/565] 74% | Training loss: 0.6884246892872311
Epoch: 65 | Iteration number: [430/565] 76% | Training loss: 0.6883855643660524
Epoch: 65 | Iteration number: [440/565] 77% | Training loss: 0.6883524805307388
Epoch: 65 | Iteration number: [450/565] 79% | Training loss: 0.6883211052417755
Epoch: 65 | Iteration number: [460/565] 81% | Training loss: 0.6882963763630908
Epoch: 65 | Iteration number: [470/565] 83% | Training loss: 0.68826727588126
Epoch: 65 | Iteration number: [480/565] 84% | Training loss: 0.6882334896673759
Epoch: 65 | Iteration number: [490/565] 86% | Training loss: 0.6882127104973307
Epoch: 65 | Iteration number: [500/565] 88% | Training loss: 0.6881776707172393
Epoch: 65 | Iteration number: [510/565] 90% | Training loss: 0.6881511265156316
Epoch: 65 | Iteration number: [520/565] 92% | Training loss: 0.688129641688787
Epoch: 65 | Iteration number: [530/565] 93% | Training loss: 0.6881004217660652
Epoch: 65 | Iteration number: [540/565] 95% | Training loss: 0.6880767818954255
Epoch: 65 | Iteration number: [550/565] 97% | Training loss: 0.6880534361709248
Epoch: 65 | Iteration number: [560/565] 99% | Training loss: 0.6880254666720118

 End of epoch: 65 | Train Loss: 0.6868009841547603 | Training Time: 89 

 End of epoch: 65 | Eval Loss: 0.6895285248756409 | Evaluating Time: 6 
Epoch: 66 | Iteration number: [10/565] 1% | Training loss: 0.7555400550365448
Epoch: 66 | Iteration number: [20/565] 3% | Training loss: 0.7209825247526169
Epoch: 66 | Iteration number: [30/565] 5% | Training loss: 0.7097169061501821
Epoch: 66 | Iteration number: [40/565] 7% | Training loss: 0.7041129022836685
Epoch: 66 | Iteration number: [50/565] 8% | Training loss: 0.7006807219982147
Epoch: 66 | Iteration number: [60/565] 10% | Training loss: 0.6983505407969157
Epoch: 66 | Iteration number: [70/565] 12% | Training loss: 0.6967500124658857
Epoch: 66 | Iteration number: [80/565] 14% | Training loss: 0.6954526074230671
Epoch: 66 | Iteration number: [90/565] 15% | Training loss: 0.6944990648163689
Epoch: 66 | Iteration number: [100/565] 17% | Training loss: 0.693735978603363
Epoch: 66 | Iteration number: [110/565] 19% | Training loss: 0.6931047694249587
Epoch: 66 | Iteration number: [120/565] 21% | Training loss: 0.6925991222262382
Epoch: 66 | Iteration number: [130/565] 23% | Training loss: 0.6921641560701224
Epoch: 66 | Iteration number: [140/565] 24% | Training loss: 0.691791387115206
Epoch: 66 | Iteration number: [150/565] 26% | Training loss: 0.6914543644587199
Epoch: 66 | Iteration number: [160/565] 28% | Training loss: 0.6911636956036091
Epoch: 66 | Iteration number: [170/565] 30% | Training loss: 0.6909363897407756
Epoch: 66 | Iteration number: [180/565] 31% | Training loss: 0.6907087057828903
Epoch: 66 | Iteration number: [190/565] 33% | Training loss: 0.6905316744980059
Epoch: 66 | Iteration number: [200/565] 35% | Training loss: 0.6903487482666969
Epoch: 66 | Iteration number: [210/565] 37% | Training loss: 0.6901598234971364
Epoch: 66 | Iteration number: [220/565] 38% | Training loss: 0.6900080846114592
Epoch: 66 | Iteration number: [230/565] 40% | Training loss: 0.6898715874423151
Epoch: 66 | Iteration number: [240/565] 42% | Training loss: 0.6897437458237012
Epoch: 66 | Iteration number: [250/565] 44% | Training loss: 0.6896198832988739
Epoch: 66 | Iteration number: [260/565] 46% | Training loss: 0.6895081799763899
Epoch: 66 | Iteration number: [270/565] 47% | Training loss: 0.6894116706318325
Epoch: 66 | Iteration number: [280/565] 49% | Training loss: 0.689306378364563
Epoch: 66 | Iteration number: [290/565] 51% | Training loss: 0.6892046597497217
Epoch: 66 | Iteration number: [300/565] 53% | Training loss: 0.6890964398781458
Epoch: 66 | Iteration number: [310/565] 54% | Training loss: 0.68902390233932
Epoch: 66 | Iteration number: [320/565] 56% | Training loss: 0.688942164555192
Epoch: 66 | Iteration number: [330/565] 58% | Training loss: 0.6888853546344873
Epoch: 66 | Iteration number: [340/565] 60% | Training loss: 0.6888060725787106
Epoch: 66 | Iteration number: [350/565] 61% | Training loss: 0.6887521306106023
Epoch: 66 | Iteration number: [360/565] 63% | Training loss: 0.6887011708484756
Epoch: 66 | Iteration number: [370/565] 65% | Training loss: 0.6886481889196344
Epoch: 66 | Iteration number: [380/565] 67% | Training loss: 0.6886037440676438
Epoch: 66 | Iteration number: [390/565] 69% | Training loss: 0.688546651448959
Epoch: 66 | Iteration number: [400/565] 70% | Training loss: 0.6885068856179715
Epoch: 66 | Iteration number: [410/565] 72% | Training loss: 0.6884734770146812
Epoch: 66 | Iteration number: [420/565] 74% | Training loss: 0.6884305533908662
Epoch: 66 | Iteration number: [430/565] 76% | Training loss: 0.6883946895599365
Epoch: 66 | Iteration number: [440/565] 77% | Training loss: 0.6883594828573141
Epoch: 66 | Iteration number: [450/565] 79% | Training loss: 0.6883227614561717
Epoch: 66 | Iteration number: [460/565] 81% | Training loss: 0.688280193961185
Epoch: 66 | Iteration number: [470/565] 83% | Training loss: 0.6882500366961702
Epoch: 66 | Iteration number: [480/565] 84% | Training loss: 0.6882228686163823
Epoch: 66 | Iteration number: [490/565] 86% | Training loss: 0.6881861439773015
Epoch: 66 | Iteration number: [500/565] 88% | Training loss: 0.6881631281375885
Epoch: 66 | Iteration number: [510/565] 90% | Training loss: 0.6881415836951312
Epoch: 66 | Iteration number: [520/565] 92% | Training loss: 0.6881134546720065
Epoch: 66 | Iteration number: [530/565] 93% | Training loss: 0.6880863836351431
Epoch: 66 | Iteration number: [540/565] 95% | Training loss: 0.6880688853837825
Epoch: 66 | Iteration number: [550/565] 97% | Training loss: 0.6880505093661221
Epoch: 66 | Iteration number: [560/565] 99% | Training loss: 0.6880242885223457

 End of epoch: 66 | Train Loss: 0.686796658228984 | Training Time: 89 

 End of epoch: 66 | Eval Loss: 0.6898785744394574 | Evaluating Time: 6 
Epoch: 67 | Iteration number: [10/565] 1% | Training loss: 0.7554646015167237
Epoch: 67 | Iteration number: [20/565] 3% | Training loss: 0.7208563387393951
Epoch: 67 | Iteration number: [30/565] 5% | Training loss: 0.709297118584315
Epoch: 67 | Iteration number: [40/565] 7% | Training loss: 0.7036412507295609
Epoch: 67 | Iteration number: [50/565] 8% | Training loss: 0.7002698361873627
Epoch: 67 | Iteration number: [60/565] 10% | Training loss: 0.6980266163746516
Epoch: 67 | Iteration number: [70/565] 12% | Training loss: 0.6964504037584577
Epoch: 67 | Iteration number: [80/565] 14% | Training loss: 0.6952723056077957
Epoch: 67 | Iteration number: [90/565] 15% | Training loss: 0.6943284445338779
Epoch: 67 | Iteration number: [100/565] 17% | Training loss: 0.6935668021440506
Epoch: 67 | Iteration number: [110/565] 19% | Training loss: 0.6929844038052992
Epoch: 67 | Iteration number: [120/565] 21% | Training loss: 0.6924553632736206
Epoch: 67 | Iteration number: [130/565] 23% | Training loss: 0.6919899940490722
Epoch: 67 | Iteration number: [140/565] 24% | Training loss: 0.6915957323142461
Epoch: 67 | Iteration number: [150/565] 26% | Training loss: 0.6912490038077036
Epoch: 67 | Iteration number: [160/565] 28% | Training loss: 0.6909888442605734
Epoch: 67 | Iteration number: [170/565] 30% | Training loss: 0.6907267128720003
Epoch: 67 | Iteration number: [180/565] 31% | Training loss: 0.6905153569247987
Epoch: 67 | Iteration number: [190/565] 33% | Training loss: 0.6903063429029365
Epoch: 67 | Iteration number: [200/565] 35% | Training loss: 0.6901181420683861
Epoch: 67 | Iteration number: [210/565] 37% | Training loss: 0.6899376693226043
Epoch: 67 | Iteration number: [220/565] 38% | Training loss: 0.6897816576740958
Epoch: 67 | Iteration number: [230/565] 40% | Training loss: 0.6896705347558726
Epoch: 67 | Iteration number: [240/565] 42% | Training loss: 0.6895598103602727
Epoch: 67 | Iteration number: [250/565] 44% | Training loss: 0.6894519834518432
Epoch: 67 | Iteration number: [260/565] 46% | Training loss: 0.6893449936921779
Epoch: 67 | Iteration number: [270/565] 47% | Training loss: 0.6892402439205735
Epoch: 67 | Iteration number: [280/565] 49% | Training loss: 0.6891476492796625
Epoch: 67 | Iteration number: [290/565] 51% | Training loss: 0.6890770423001257
Epoch: 67 | Iteration number: [300/565] 53% | Training loss: 0.6889998747905095
Epoch: 67 | Iteration number: [310/565] 54% | Training loss: 0.6889298508244176
Epoch: 67 | Iteration number: [320/565] 56% | Training loss: 0.6888660812750459
Epoch: 67 | Iteration number: [330/565] 58% | Training loss: 0.6887987913507404
Epoch: 67 | Iteration number: [340/565] 60% | Training loss: 0.6887450472396963
Epoch: 67 | Iteration number: [350/565] 61% | Training loss: 0.6886883842945098
Epoch: 67 | Iteration number: [360/565] 63% | Training loss: 0.6886405997806125
Epoch: 67 | Iteration number: [370/565] 65% | Training loss: 0.6886013029394923
Epoch: 67 | Iteration number: [380/565] 67% | Training loss: 0.6885707510145087
Epoch: 67 | Iteration number: [390/565] 69% | Training loss: 0.6885291894276937
Epoch: 67 | Iteration number: [400/565] 70% | Training loss: 0.6884909495711327
Epoch: 67 | Iteration number: [410/565] 72% | Training loss: 0.6884379229894498
Epoch: 67 | Iteration number: [420/565] 74% | Training loss: 0.6883972292854672
Epoch: 67 | Iteration number: [430/565] 76% | Training loss: 0.6883577822252761
Epoch: 67 | Iteration number: [440/565] 77% | Training loss: 0.688334026390856
Epoch: 67 | Iteration number: [450/565] 79% | Training loss: 0.6882986201180352
Epoch: 67 | Iteration number: [460/565] 81% | Training loss: 0.6882625324570615
Epoch: 67 | Iteration number: [470/565] 83% | Training loss: 0.6882332259036125
Epoch: 67 | Iteration number: [480/565] 84% | Training loss: 0.6882073435932398
Epoch: 67 | Iteration number: [490/565] 86% | Training loss: 0.6881758784761234
Epoch: 67 | Iteration number: [500/565] 88% | Training loss: 0.6881457341909408
Epoch: 67 | Iteration number: [510/565] 90% | Training loss: 0.6881243723280289
Epoch: 67 | Iteration number: [520/565] 92% | Training loss: 0.6881010252695817
Epoch: 67 | Iteration number: [530/565] 93% | Training loss: 0.6880786928365815
Epoch: 67 | Iteration number: [540/565] 95% | Training loss: 0.6880610602873343
Epoch: 67 | Iteration number: [550/565] 97% | Training loss: 0.6880388889529488
Epoch: 67 | Iteration number: [560/565] 99% | Training loss: 0.6880153208971024

 End of epoch: 67 | Train Loss: 0.6867973631462164 | Training Time: 88 

 End of epoch: 67 | Eval Loss: 0.6896946089608329 | Evaluating Time: 6 
Epoch: 68 | Iteration number: [10/565] 1% | Training loss: 0.7556234419345855
Epoch: 68 | Iteration number: [20/565] 3% | Training loss: 0.7213045328855514
Epoch: 68 | Iteration number: [30/565] 5% | Training loss: 0.7098894814650217
Epoch: 68 | Iteration number: [40/565] 7% | Training loss: 0.7041469216346741
Epoch: 68 | Iteration number: [50/565] 8% | Training loss: 0.7006437802314758
Epoch: 68 | Iteration number: [60/565] 10% | Training loss: 0.6983844021956126
Epoch: 68 | Iteration number: [70/565] 12% | Training loss: 0.6967594734260014
Epoch: 68 | Iteration number: [80/565] 14% | Training loss: 0.6954557850956917
Epoch: 68 | Iteration number: [90/565] 15% | Training loss: 0.6945047630204095
Epoch: 68 | Iteration number: [100/565] 17% | Training loss: 0.6937601906061173
Epoch: 68 | Iteration number: [110/565] 19% | Training loss: 0.693119338425723
Epoch: 68 | Iteration number: [120/565] 21% | Training loss: 0.6925976996620496
Epoch: 68 | Iteration number: [130/565] 23% | Training loss: 0.692155037017969
Epoch: 68 | Iteration number: [140/565] 24% | Training loss: 0.6917776358979089
Epoch: 68 | Iteration number: [150/565] 26% | Training loss: 0.6914692922433218
Epoch: 68 | Iteration number: [160/565] 28% | Training loss: 0.6911712814122438
Epoch: 68 | Iteration number: [170/565] 30% | Training loss: 0.6908850792576285
Epoch: 68 | Iteration number: [180/565] 31% | Training loss: 0.6906733867194917
Epoch: 68 | Iteration number: [190/565] 33% | Training loss: 0.690464405009621
Epoch: 68 | Iteration number: [200/565] 35% | Training loss: 0.6902861788868904
Epoch: 68 | Iteration number: [210/565] 37% | Training loss: 0.6901118400551024
Epoch: 68 | Iteration number: [220/565] 38% | Training loss: 0.6899462832645936
Epoch: 68 | Iteration number: [230/565] 40% | Training loss: 0.6898378753143808
Epoch: 68 | Iteration number: [240/565] 42% | Training loss: 0.6897297859191894
Epoch: 68 | Iteration number: [250/565] 44% | Training loss: 0.6896068551540375
Epoch: 68 | Iteration number: [260/565] 46% | Training loss: 0.6894947719115477
Epoch: 68 | Iteration number: [270/565] 47% | Training loss: 0.6893940854955602
Epoch: 68 | Iteration number: [280/565] 49% | Training loss: 0.689312435899462
Epoch: 68 | Iteration number: [290/565] 51% | Training loss: 0.6892142669907931
Epoch: 68 | Iteration number: [300/565] 53% | Training loss: 0.689128010670344
Epoch: 68 | Iteration number: [310/565] 54% | Training loss: 0.6890563753343397
Epoch: 68 | Iteration number: [320/565] 56% | Training loss: 0.6889895910397172
Epoch: 68 | Iteration number: [330/565] 58% | Training loss: 0.6889267567432288
Epoch: 68 | Iteration number: [340/565] 60% | Training loss: 0.6888546177569558
Epoch: 68 | Iteration number: [350/565] 61% | Training loss: 0.6887991612298148
Epoch: 68 | Iteration number: [360/565] 63% | Training loss: 0.6887390092015266
Epoch: 68 | Iteration number: [370/565] 65% | Training loss: 0.6886842437692591
Epoch: 68 | Iteration number: [380/565] 67% | Training loss: 0.6886383389171801
Epoch: 68 | Iteration number: [390/565] 69% | Training loss: 0.6885927169750898
Epoch: 68 | Iteration number: [400/565] 70% | Training loss: 0.6885549932718277
Epoch: 68 | Iteration number: [410/565] 72% | Training loss: 0.6885057341761706
Epoch: 68 | Iteration number: [420/565] 74% | Training loss: 0.6884674966335297
Epoch: 68 | Iteration number: [430/565] 76% | Training loss: 0.6884261530499126
Epoch: 68 | Iteration number: [440/565] 77% | Training loss: 0.6883905998685144
Epoch: 68 | Iteration number: [450/565] 79% | Training loss: 0.6883572347958883
Epoch: 68 | Iteration number: [460/565] 81% | Training loss: 0.6883216502873793
Epoch: 68 | Iteration number: [470/565] 83% | Training loss: 0.6882777460077976
Epoch: 68 | Iteration number: [480/565] 84% | Training loss: 0.6882418842365344
Epoch: 68 | Iteration number: [490/565] 86% | Training loss: 0.6882093377259313
Epoch: 68 | Iteration number: [500/565] 88% | Training loss: 0.6881846539974212
Epoch: 68 | Iteration number: [510/565] 90% | Training loss: 0.6881616011554119
Epoch: 68 | Iteration number: [520/565] 92% | Training loss: 0.6881361403144323
Epoch: 68 | Iteration number: [530/565] 93% | Training loss: 0.6881050437126519
Epoch: 68 | Iteration number: [540/565] 95% | Training loss: 0.688076662906894
Epoch: 68 | Iteration number: [550/565] 97% | Training loss: 0.6880609050664035
Epoch: 68 | Iteration number: [560/565] 99% | Training loss: 0.688030583517892

 End of epoch: 68 | Train Loss: 0.6868029441453715 | Training Time: 89 

 End of epoch: 68 | Eval Loss: 0.6893138374601092 | Evaluating Time: 6 
Epoch: 69 | Iteration number: [10/565] 1% | Training loss: 0.7552260458469391
Epoch: 69 | Iteration number: [20/565] 3% | Training loss: 0.7210846692323685
Epoch: 69 | Iteration number: [30/565] 5% | Training loss: 0.7096628487110138
Epoch: 69 | Iteration number: [40/565] 7% | Training loss: 0.7040725871920586
Epoch: 69 | Iteration number: [50/565] 8% | Training loss: 0.7006641948223113
Epoch: 69 | Iteration number: [60/565] 10% | Training loss: 0.6983312825361888
Epoch: 69 | Iteration number: [70/565] 12% | Training loss: 0.6966824701854161
Epoch: 69 | Iteration number: [80/565] 14% | Training loss: 0.6954536512494087
Epoch: 69 | Iteration number: [90/565] 15% | Training loss: 0.6945709864298503
Epoch: 69 | Iteration number: [100/565] 17% | Training loss: 0.6937881171703338
Epoch: 69 | Iteration number: [110/565] 19% | Training loss: 0.6931758869778026
Epoch: 69 | Iteration number: [120/565] 21% | Training loss: 0.6926559249560038
Epoch: 69 | Iteration number: [130/565] 23% | Training loss: 0.692225116949815
Epoch: 69 | Iteration number: [140/565] 24% | Training loss: 0.6918398529291153
Epoch: 69 | Iteration number: [150/565] 26% | Training loss: 0.6915062395731608
Epoch: 69 | Iteration number: [160/565] 28% | Training loss: 0.6912134531885386
Epoch: 69 | Iteration number: [170/565] 30% | Training loss: 0.6909441127496607
Epoch: 69 | Iteration number: [180/565] 31% | Training loss: 0.6907320572270288
Epoch: 69 | Iteration number: [190/565] 33% | Training loss: 0.6905093845568205
Epoch: 69 | Iteration number: [200/565] 35% | Training loss: 0.6903186550736428
Epoch: 69 | Iteration number: [210/565] 37% | Training loss: 0.6901672417209261
Epoch: 69 | Iteration number: [220/565] 38% | Training loss: 0.6900138418782841
Epoch: 69 | Iteration number: [230/565] 40% | Training loss: 0.6898767725281093
Epoch: 69 | Iteration number: [240/565] 42% | Training loss: 0.6897353182236353
Epoch: 69 | Iteration number: [250/565] 44% | Training loss: 0.6895942566394806
Epoch: 69 | Iteration number: [260/565] 46% | Training loss: 0.689495831498733
Epoch: 69 | Iteration number: [270/565] 47% | Training loss: 0.6893789035302621
Epoch: 69 | Iteration number: [280/565] 49% | Training loss: 0.689284871518612
Epoch: 69 | Iteration number: [290/565] 51% | Training loss: 0.6891941294587892
Epoch: 69 | Iteration number: [300/565] 53% | Training loss: 0.6891082638502121
Epoch: 69 | Iteration number: [310/565] 54% | Training loss: 0.6890291125543656
Epoch: 69 | Iteration number: [320/565] 56% | Training loss: 0.6889508493244648
Epoch: 69 | Iteration number: [330/565] 58% | Training loss: 0.6888871033986409
Epoch: 69 | Iteration number: [340/565] 60% | Training loss: 0.6888236384181415
Epoch: 69 | Iteration number: [350/565] 61% | Training loss: 0.6887685285295759
Epoch: 69 | Iteration number: [360/565] 63% | Training loss: 0.6887139707803727
Epoch: 69 | Iteration number: [370/565] 65% | Training loss: 0.6886656189287031
Epoch: 69 | Iteration number: [380/565] 67% | Training loss: 0.688620914910969
Epoch: 69 | Iteration number: [390/565] 69% | Training loss: 0.6885721605557662
Epoch: 69 | Iteration number: [400/565] 70% | Training loss: 0.688533893674612
Epoch: 69 | Iteration number: [410/565] 72% | Training loss: 0.6884799085012296
Epoch: 69 | Iteration number: [420/565] 74% | Training loss: 0.688437813946179
Epoch: 69 | Iteration number: [430/565] 76% | Training loss: 0.6883911698363548
Epoch: 69 | Iteration number: [440/565] 77% | Training loss: 0.6883499466560103
Epoch: 69 | Iteration number: [450/565] 79% | Training loss: 0.6883120874563853
Epoch: 69 | Iteration number: [460/565] 81% | Training loss: 0.6882774499447449
Epoch: 69 | Iteration number: [470/565] 83% | Training loss: 0.6882495919440655
Epoch: 69 | Iteration number: [480/565] 84% | Training loss: 0.6882195285211007
Epoch: 69 | Iteration number: [490/565] 86% | Training loss: 0.6881930809848162
Epoch: 69 | Iteration number: [500/565] 88% | Training loss: 0.6881576464176178
Epoch: 69 | Iteration number: [510/565] 90% | Training loss: 0.6881357880199657
Epoch: 69 | Iteration number: [520/565] 92% | Training loss: 0.6881099760532379
Epoch: 69 | Iteration number: [530/565] 93% | Training loss: 0.6880855337628778
Epoch: 69 | Iteration number: [540/565] 95% | Training loss: 0.6880643313681638
Epoch: 69 | Iteration number: [550/565] 97% | Training loss: 0.6880470811236988
Epoch: 69 | Iteration number: [560/565] 99% | Training loss: 0.688024346956185

 End of epoch: 69 | Train Loss: 0.6867929345738572 | Training Time: 89 

 End of epoch: 69 | Eval Loss: 0.6894632237298148 | Evaluating Time: 5 
Epoch: 70 | Iteration number: [10/565] 1% | Training loss: 0.7558026015758514
Epoch: 70 | Iteration number: [20/565] 3% | Training loss: 0.7214551657438278
Epoch: 70 | Iteration number: [30/565] 5% | Training loss: 0.7100520511468251
Epoch: 70 | Iteration number: [40/565] 7% | Training loss: 0.7042416125535965
Epoch: 70 | Iteration number: [50/565] 8% | Training loss: 0.7007251155376434
Epoch: 70 | Iteration number: [60/565] 10% | Training loss: 0.6983726700146993
Epoch: 70 | Iteration number: [70/565] 12% | Training loss: 0.6967163894857679
Epoch: 70 | Iteration number: [80/565] 14% | Training loss: 0.6955342166125774
Epoch: 70 | Iteration number: [90/565] 15% | Training loss: 0.6945888837178548
Epoch: 70 | Iteration number: [100/565] 17% | Training loss: 0.6938073003292083
Epoch: 70 | Iteration number: [110/565] 19% | Training loss: 0.6931731413711201
Epoch: 70 | Iteration number: [120/565] 21% | Training loss: 0.6926606699824334
Epoch: 70 | Iteration number: [130/565] 23% | Training loss: 0.6922047642561105
Epoch: 70 | Iteration number: [140/565] 24% | Training loss: 0.6918328723737172
Epoch: 70 | Iteration number: [150/565] 26% | Training loss: 0.6914902651309967
Epoch: 70 | Iteration number: [160/565] 28% | Training loss: 0.691201527416706
Epoch: 70 | Iteration number: [170/565] 30% | Training loss: 0.6909231157863841
Epoch: 70 | Iteration number: [180/565] 31% | Training loss: 0.69070532851749
Epoch: 70 | Iteration number: [190/565] 33% | Training loss: 0.6905042861637316
Epoch: 70 | Iteration number: [200/565] 35% | Training loss: 0.690343764424324
Epoch: 70 | Iteration number: [210/565] 37% | Training loss: 0.6901716428143637
Epoch: 70 | Iteration number: [220/565] 38% | Training loss: 0.69001685814424
Epoch: 70 | Iteration number: [230/565] 40% | Training loss: 0.6898426698601764
Epoch: 70 | Iteration number: [240/565] 42% | Training loss: 0.6897231864432494
Epoch: 70 | Iteration number: [250/565] 44% | Training loss: 0.6895934522151947
Epoch: 70 | Iteration number: [260/565] 46% | Training loss: 0.6894912343758803
Epoch: 70 | Iteration number: [270/565] 47% | Training loss: 0.6893966718956276
Epoch: 70 | Iteration number: [280/565] 49% | Training loss: 0.6893129542469978
Epoch: 70 | Iteration number: [290/565] 51% | Training loss: 0.6892241558124279
Epoch: 70 | Iteration number: [300/565] 53% | Training loss: 0.6891527154048284
Epoch: 70 | Iteration number: [310/565] 54% | Training loss: 0.689072783147135
Epoch: 70 | Iteration number: [320/565] 56% | Training loss: 0.6890038372948766
Epoch: 70 | Iteration number: [330/565] 58% | Training loss: 0.6889272178664352
Epoch: 70 | Iteration number: [340/565] 60% | Training loss: 0.6888553035609862
Epoch: 70 | Iteration number: [350/565] 61% | Training loss: 0.688799056155341
Epoch: 70 | Iteration number: [360/565] 63% | Training loss: 0.6887526020407677
Epoch: 70 | Iteration number: [370/565] 65% | Training loss: 0.6887031732378779
Epoch: 70 | Iteration number: [380/565] 67% | Training loss: 0.6886487772590235
Epoch: 70 | Iteration number: [390/565] 69% | Training loss: 0.6885878457472875
Epoch: 70 | Iteration number: [400/565] 70% | Training loss: 0.6885238809883595
Epoch: 70 | Iteration number: [410/565] 72% | Training loss: 0.6884888327703244
Epoch: 70 | Iteration number: [420/565] 74% | Training loss: 0.6884580766870863
Epoch: 70 | Iteration number: [430/565] 76% | Training loss: 0.6884222065293512
Epoch: 70 | Iteration number: [440/565] 77% | Training loss: 0.6883883096955039
Epoch: 70 | Iteration number: [450/565] 79% | Training loss: 0.68835185541047
Epoch: 70 | Iteration number: [460/565] 81% | Training loss: 0.6883136604143225
Epoch: 70 | Iteration number: [470/565] 83% | Training loss: 0.6882768268280841
Epoch: 70 | Iteration number: [480/565] 84% | Training loss: 0.6882376316934824
Epoch: 70 | Iteration number: [490/565] 86% | Training loss: 0.6882087037271383
Epoch: 70 | Iteration number: [500/565] 88% | Training loss: 0.6881880083084106
Epoch: 70 | Iteration number: [510/565] 90% | Training loss: 0.6881546658628127
Epoch: 70 | Iteration number: [520/565] 92% | Training loss: 0.6881224751472473
Epoch: 70 | Iteration number: [530/565] 93% | Training loss: 0.6880983452751951
Epoch: 70 | Iteration number: [540/565] 95% | Training loss: 0.6880758133199479
Epoch: 70 | Iteration number: [550/565] 97% | Training loss: 0.6880470592325384
Epoch: 70 | Iteration number: [560/565] 99% | Training loss: 0.6880207329988479

 End of epoch: 70 | Train Loss: 0.6867970463448921 | Training Time: 89 

 End of epoch: 70 | Eval Loss: 0.6896800313677106 | Evaluating Time: 6 
Epoch: 71 | Iteration number: [10/565] 1% | Training loss: 0.7554226160049439
Epoch: 71 | Iteration number: [20/565] 3% | Training loss: 0.7212634891271591
Epoch: 71 | Iteration number: [30/565] 5% | Training loss: 0.709689215819041
Epoch: 71 | Iteration number: [40/565] 7% | Training loss: 0.7038818657398224
Epoch: 71 | Iteration number: [50/565] 8% | Training loss: 0.7005004644393921
Epoch: 71 | Iteration number: [60/565] 10% | Training loss: 0.6982326289017995
Epoch: 71 | Iteration number: [70/565] 12% | Training loss: 0.6966073138373239
Epoch: 71 | Iteration number: [80/565] 14% | Training loss: 0.6953539572656154
Epoch: 71 | Iteration number: [90/565] 15% | Training loss: 0.6944148361682891
Epoch: 71 | Iteration number: [100/565] 17% | Training loss: 0.6936858719587327
Epoch: 71 | Iteration number: [110/565] 19% | Training loss: 0.6930622805248607
Epoch: 71 | Iteration number: [120/565] 21% | Training loss: 0.6925609424710274
Epoch: 71 | Iteration number: [130/565] 23% | Training loss: 0.6921490352887374
Epoch: 71 | Iteration number: [140/565] 24% | Training loss: 0.6917626061609813
Epoch: 71 | Iteration number: [150/565] 26% | Training loss: 0.6914601997534434
Epoch: 71 | Iteration number: [160/565] 28% | Training loss: 0.6911702182143926
Epoch: 71 | Iteration number: [170/565] 30% | Training loss: 0.6909227630671333
Epoch: 71 | Iteration number: [180/565] 31% | Training loss: 0.6906838635603587
Epoch: 71 | Iteration number: [190/565] 33% | Training loss: 0.6904500694651353
Epoch: 71 | Iteration number: [200/565] 35% | Training loss: 0.6902667620778083
Epoch: 71 | Iteration number: [210/565] 37% | Training loss: 0.6900947760967981
Epoch: 71 | Iteration number: [220/565] 38% | Training loss: 0.6899547750299627
Epoch: 71 | Iteration number: [230/565] 40% | Training loss: 0.6897979972155198
Epoch: 71 | Iteration number: [240/565] 42% | Training loss: 0.6896699418624243
Epoch: 71 | Iteration number: [250/565] 44% | Training loss: 0.6895588128566742
Epoch: 71 | Iteration number: [260/565] 46% | Training loss: 0.6894390172683276
Epoch: 71 | Iteration number: [270/565] 47% | Training loss: 0.6893386410342323
Epoch: 71 | Iteration number: [280/565] 49% | Training loss: 0.6892626713429179
Epoch: 71 | Iteration number: [290/565] 51% | Training loss: 0.6891901743823085
Epoch: 71 | Iteration number: [300/565] 53% | Training loss: 0.6891250000397364
Epoch: 71 | Iteration number: [310/565] 54% | Training loss: 0.6890464240504849
Epoch: 71 | Iteration number: [320/565] 56% | Training loss: 0.6889815881848336
Epoch: 71 | Iteration number: [330/565] 58% | Training loss: 0.6889065518523707
Epoch: 71 | Iteration number: [340/565] 60% | Training loss: 0.6888451038038029
Epoch: 71 | Iteration number: [350/565] 61% | Training loss: 0.6888017736162458
Epoch: 71 | Iteration number: [360/565] 63% | Training loss: 0.68875675847133
Epoch: 71 | Iteration number: [370/565] 65% | Training loss: 0.6887025225806881
Epoch: 71 | Iteration number: [380/565] 67% | Training loss: 0.6886420464829395
Epoch: 71 | Iteration number: [390/565] 69% | Training loss: 0.6885930632933592
Epoch: 71 | Iteration number: [400/565] 70% | Training loss: 0.6885440595448017
Epoch: 71 | Iteration number: [410/565] 72% | Training loss: 0.6885065706764779
Epoch: 71 | Iteration number: [420/565] 74% | Training loss: 0.6884541813816343
Epoch: 71 | Iteration number: [430/565] 76% | Training loss: 0.6884148046027783
Epoch: 71 | Iteration number: [440/565] 77% | Training loss: 0.6883856888521801
Epoch: 71 | Iteration number: [450/565] 79% | Training loss: 0.6883479356765747
Epoch: 71 | Iteration number: [460/565] 81% | Training loss: 0.6883058620535809
Epoch: 71 | Iteration number: [470/565] 83% | Training loss: 0.6882780028150437
Epoch: 71 | Iteration number: [480/565] 84% | Training loss: 0.6882378841439883
Epoch: 71 | Iteration number: [490/565] 86% | Training loss: 0.688207151086963
Epoch: 71 | Iteration number: [500/565] 88% | Training loss: 0.6881807135343552
Epoch: 71 | Iteration number: [510/565] 90% | Training loss: 0.6881659213234397
Epoch: 71 | Iteration number: [520/565] 92% | Training loss: 0.6881359870617206
Epoch: 71 | Iteration number: [530/565] 93% | Training loss: 0.6881031320904786
Epoch: 71 | Iteration number: [540/565] 95% | Training loss: 0.6880766496614173
Epoch: 71 | Iteration number: [550/565] 97% | Training loss: 0.6880505310405385
Epoch: 71 | Iteration number: [560/565] 99% | Training loss: 0.6880288423172065

 End of epoch: 71 | Train Loss: 0.6868035460995362 | Training Time: 89 

 End of epoch: 71 | Eval Loss: 0.6899956124169486 | Evaluating Time: 5 
Epoch: 72 | Iteration number: [10/565] 1% | Training loss: 0.7552630543708801
Epoch: 72 | Iteration number: [20/565] 3% | Training loss: 0.7211146950721741
Epoch: 72 | Iteration number: [30/565] 5% | Training loss: 0.7098646958669027
Epoch: 72 | Iteration number: [40/565] 7% | Training loss: 0.7041065558791161
Epoch: 72 | Iteration number: [50/565] 8% | Training loss: 0.7006325650215149
Epoch: 72 | Iteration number: [60/565] 10% | Training loss: 0.698357030749321
Epoch: 72 | Iteration number: [70/565] 12% | Training loss: 0.6967792774949755
Epoch: 72 | Iteration number: [80/565] 14% | Training loss: 0.6955570362508297
Epoch: 72 | Iteration number: [90/565] 15% | Training loss: 0.6946011854542626
Epoch: 72 | Iteration number: [100/565] 17% | Training loss: 0.6937719190120697
Epoch: 72 | Iteration number: [110/565] 19% | Training loss: 0.6931177691979842
Epoch: 72 | Iteration number: [120/565] 21% | Training loss: 0.6926058083772659
Epoch: 72 | Iteration number: [130/565] 23% | Training loss: 0.6921224227318397
Epoch: 72 | Iteration number: [140/565] 24% | Training loss: 0.6917295868907656
Epoch: 72 | Iteration number: [150/565] 26% | Training loss: 0.6914261349042257
Epoch: 72 | Iteration number: [160/565] 28% | Training loss: 0.6911174423992634
Epoch: 72 | Iteration number: [170/565] 30% | Training loss: 0.6908608173622804
Epoch: 72 | Iteration number: [180/565] 31% | Training loss: 0.690621546904246
Epoch: 72 | Iteration number: [190/565] 33% | Training loss: 0.6904165114227094
Epoch: 72 | Iteration number: [200/565] 35% | Training loss: 0.6902245950698852
Epoch: 72 | Iteration number: [210/565] 37% | Training loss: 0.6900697779087793
Epoch: 72 | Iteration number: [220/565] 38% | Training loss: 0.6899281897328117
Epoch: 72 | Iteration number: [230/565] 40% | Training loss: 0.6897841795631077
Epoch: 72 | Iteration number: [240/565] 42% | Training loss: 0.6896499653657278
Epoch: 72 | Iteration number: [250/565] 44% | Training loss: 0.6895434749126435
Epoch: 72 | Iteration number: [260/565] 46% | Training loss: 0.6894582065252157
Epoch: 72 | Iteration number: [270/565] 47% | Training loss: 0.6893510551364334
Epoch: 72 | Iteration number: [280/565] 49% | Training loss: 0.6892543458512851
Epoch: 72 | Iteration number: [290/565] 51% | Training loss: 0.689157680396376
Epoch: 72 | Iteration number: [300/565] 53% | Training loss: 0.6890681177377701
Epoch: 72 | Iteration number: [310/565] 54% | Training loss: 0.6889910330695491
Epoch: 72 | Iteration number: [320/565] 56% | Training loss: 0.6889283964410424
Epoch: 72 | Iteration number: [330/565] 58% | Training loss: 0.688865844228051
Epoch: 72 | Iteration number: [340/565] 60% | Training loss: 0.6888092994689942
Epoch: 72 | Iteration number: [350/565] 61% | Training loss: 0.6887453120095389
Epoch: 72 | Iteration number: [360/565] 63% | Training loss: 0.6886856998006503
Epoch: 72 | Iteration number: [370/565] 65% | Training loss: 0.6886403985925623
Epoch: 72 | Iteration number: [380/565] 67% | Training loss: 0.688596931727309
Epoch: 72 | Iteration number: [390/565] 69% | Training loss: 0.6885446357421386
Epoch: 72 | Iteration number: [400/565] 70% | Training loss: 0.688503809273243
Epoch: 72 | Iteration number: [410/565] 72% | Training loss: 0.6884667701837494
Epoch: 72 | Iteration number: [420/565] 74% | Training loss: 0.6884226215737207
Epoch: 72 | Iteration number: [430/565] 76% | Training loss: 0.6883835256099701
Epoch: 72 | Iteration number: [440/565] 77% | Training loss: 0.6883479390632022
Epoch: 72 | Iteration number: [450/565] 79% | Training loss: 0.6883135108153026
Epoch: 72 | Iteration number: [460/565] 81% | Training loss: 0.6882885895345522
Epoch: 72 | Iteration number: [470/565] 83% | Training loss: 0.6882492301311899
Epoch: 72 | Iteration number: [480/565] 84% | Training loss: 0.6882263861596585
Epoch: 72 | Iteration number: [490/565] 86% | Training loss: 0.6882040591872468
Epoch: 72 | Iteration number: [500/565] 88% | Training loss: 0.6881743957996368
Epoch: 72 | Iteration number: [510/565] 90% | Training loss: 0.6881555536214043
Epoch: 72 | Iteration number: [520/565] 92% | Training loss: 0.6881277728539247
Epoch: 72 | Iteration number: [530/565] 93% | Training loss: 0.6880886414141025
Epoch: 72 | Iteration number: [540/565] 95% | Training loss: 0.6880725382654755
Epoch: 72 | Iteration number: [550/565] 97% | Training loss: 0.6880380600148981
Epoch: 72 | Iteration number: [560/565] 99% | Training loss: 0.6880082134689604

 End of epoch: 72 | Train Loss: 0.686789375279857 | Training Time: 88 

 End of epoch: 72 | Eval Loss: 0.6895354049546378 | Evaluating Time: 6 
Epoch: 73 | Iteration number: [10/565] 1% | Training loss: 0.7550467014312744
Epoch: 73 | Iteration number: [20/565] 3% | Training loss: 0.7208138525485992
Epoch: 73 | Iteration number: [30/565] 5% | Training loss: 0.7095025579134623
Epoch: 73 | Iteration number: [40/565] 7% | Training loss: 0.7038963660597801
Epoch: 73 | Iteration number: [50/565] 8% | Training loss: 0.7004616332054138
Epoch: 73 | Iteration number: [60/565] 10% | Training loss: 0.6981271495421727
Epoch: 73 | Iteration number: [70/565] 12% | Training loss: 0.6965010847364154
Epoch: 73 | Iteration number: [80/565] 14% | Training loss: 0.6952381484210491
Epoch: 73 | Iteration number: [90/565] 15% | Training loss: 0.6943181951840719
Epoch: 73 | Iteration number: [100/565] 17% | Training loss: 0.693528009057045
Epoch: 73 | Iteration number: [110/565] 19% | Training loss: 0.6929323505271565
Epoch: 73 | Iteration number: [120/565] 21% | Training loss: 0.6923873782157898
Epoch: 73 | Iteration number: [130/565] 23% | Training loss: 0.6919570858661945
Epoch: 73 | Iteration number: [140/565] 24% | Training loss: 0.6915719185556685
Epoch: 73 | Iteration number: [150/565] 26% | Training loss: 0.6912484514713287
Epoch: 73 | Iteration number: [160/565] 28% | Training loss: 0.6909429106861353
Epoch: 73 | Iteration number: [170/565] 30% | Training loss: 0.6907225591294905
Epoch: 73 | Iteration number: [180/565] 31% | Training loss: 0.6905104402038786
Epoch: 73 | Iteration number: [190/565] 33% | Training loss: 0.6903204908496455
Epoch: 73 | Iteration number: [200/565] 35% | Training loss: 0.6901487055420875
Epoch: 73 | Iteration number: [210/565] 37% | Training loss: 0.6899854617459433
Epoch: 73 | Iteration number: [220/565] 38% | Training loss: 0.6898411907932975
Epoch: 73 | Iteration number: [230/565] 40% | Training loss: 0.6897086664386417
Epoch: 73 | Iteration number: [240/565] 42% | Training loss: 0.6895616290469965
Epoch: 73 | Iteration number: [250/565] 44% | Training loss: 0.6894460570812225
Epoch: 73 | Iteration number: [260/565] 46% | Training loss: 0.6893459535562075
Epoch: 73 | Iteration number: [270/565] 47% | Training loss: 0.6892782780859206
Epoch: 73 | Iteration number: [280/565] 49% | Training loss: 0.689157007421766
Epoch: 73 | Iteration number: [290/565] 51% | Training loss: 0.6890678596907649
Epoch: 73 | Iteration number: [300/565] 53% | Training loss: 0.6889869014422099
Epoch: 73 | Iteration number: [310/565] 54% | Training loss: 0.6889291299927619
Epoch: 73 | Iteration number: [320/565] 56% | Training loss: 0.6888649765402078
Epoch: 73 | Iteration number: [330/565] 58% | Training loss: 0.6887959904742963
Epoch: 73 | Iteration number: [340/565] 60% | Training loss: 0.688746041059494
Epoch: 73 | Iteration number: [350/565] 61% | Training loss: 0.68869032229696
Epoch: 73 | Iteration number: [360/565] 63% | Training loss: 0.6886361961563429
Epoch: 73 | Iteration number: [370/565] 65% | Training loss: 0.6885813560034778
Epoch: 73 | Iteration number: [380/565] 67% | Training loss: 0.6885450466683036
Epoch: 73 | Iteration number: [390/565] 69% | Training loss: 0.6884937258867118
Epoch: 73 | Iteration number: [400/565] 70% | Training loss: 0.6884587341547013
Epoch: 73 | Iteration number: [410/565] 72% | Training loss: 0.6884110603390671
Epoch: 73 | Iteration number: [420/565] 74% | Training loss: 0.6883771882170723
Epoch: 73 | Iteration number: [430/565] 76% | Training loss: 0.6883523195288902
Epoch: 73 | Iteration number: [440/565] 77% | Training loss: 0.6883221768520095
Epoch: 73 | Iteration number: [450/565] 79% | Training loss: 0.6882794853051504
Epoch: 73 | Iteration number: [460/565] 81% | Training loss: 0.688244492204293
Epoch: 73 | Iteration number: [470/565] 83% | Training loss: 0.6882109250159973
Epoch: 73 | Iteration number: [480/565] 84% | Training loss: 0.6881936258325975
Epoch: 73 | Iteration number: [490/565] 86% | Training loss: 0.6881722031807412
Epoch: 73 | Iteration number: [500/565] 88% | Training loss: 0.688149400472641
Epoch: 73 | Iteration number: [510/565] 90% | Training loss: 0.6881201328015795
Epoch: 73 | Iteration number: [520/565] 92% | Training loss: 0.6880949809001042
Epoch: 73 | Iteration number: [530/565] 93% | Training loss: 0.6880723001821986
Epoch: 73 | Iteration number: [540/565] 95% | Training loss: 0.6880519136234566
Epoch: 73 | Iteration number: [550/565] 97% | Training loss: 0.6880249712683938
Epoch: 73 | Iteration number: [560/565] 99% | Training loss: 0.6880066189382757

 End of epoch: 73 | Train Loss: 0.686787115472608 | Training Time: 88 

 End of epoch: 73 | Eval Loss: 0.6896668246814183 | Evaluating Time: 6 
Epoch: 74 | Iteration number: [10/565] 1% | Training loss: 0.755460786819458
Epoch: 74 | Iteration number: [20/565] 3% | Training loss: 0.7208543002605439
Epoch: 74 | Iteration number: [30/565] 5% | Training loss: 0.7093641459941864
Epoch: 74 | Iteration number: [40/565] 7% | Training loss: 0.7036806598305703
Epoch: 74 | Iteration number: [50/565] 8% | Training loss: 0.7003596639633178
Epoch: 74 | Iteration number: [60/565] 10% | Training loss: 0.698080986738205
Epoch: 74 | Iteration number: [70/565] 12% | Training loss: 0.6965083701269967
Epoch: 74 | Iteration number: [80/565] 14% | Training loss: 0.6952863395214081
Epoch: 74 | Iteration number: [90/565] 15% | Training loss: 0.694314859310786
Epoch: 74 | Iteration number: [100/565] 17% | Training loss: 0.6935727542638779
Epoch: 74 | Iteration number: [110/565] 19% | Training loss: 0.6929181109775197
Epoch: 74 | Iteration number: [120/565] 21% | Training loss: 0.6924049620827039
Epoch: 74 | Iteration number: [130/565] 23% | Training loss: 0.6919778700058277
Epoch: 74 | Iteration number: [140/565] 24% | Training loss: 0.6916489575590407
Epoch: 74 | Iteration number: [150/565] 26% | Training loss: 0.691355729897817
Epoch: 74 | Iteration number: [160/565] 28% | Training loss: 0.6910609517246484
Epoch: 74 | Iteration number: [170/565] 30% | Training loss: 0.690811761337168
Epoch: 74 | Iteration number: [180/565] 31% | Training loss: 0.6905940055847168
Epoch: 74 | Iteration number: [190/565] 33% | Training loss: 0.6903662524725261
Epoch: 74 | Iteration number: [200/565] 35% | Training loss: 0.6901843577623368
Epoch: 74 | Iteration number: [210/565] 37% | Training loss: 0.6900233790988014
Epoch: 74 | Iteration number: [220/565] 38% | Training loss: 0.6898820416493849
Epoch: 74 | Iteration number: [230/565] 40% | Training loss: 0.6897672132305477
Epoch: 74 | Iteration number: [240/565] 42% | Training loss: 0.6896454838414987
Epoch: 74 | Iteration number: [250/565] 44% | Training loss: 0.6895242202281952
Epoch: 74 | Iteration number: [260/565] 46% | Training loss: 0.6894481649765601
Epoch: 74 | Iteration number: [270/565] 47% | Training loss: 0.689354850186242
Epoch: 74 | Iteration number: [280/565] 49% | Training loss: 0.689256620832852
Epoch: 74 | Iteration number: [290/565] 51% | Training loss: 0.689157096887457
Epoch: 74 | Iteration number: [300/565] 53% | Training loss: 0.6890830981731415
Epoch: 74 | Iteration number: [310/565] 54% | Training loss: 0.6890070021152497
Epoch: 74 | Iteration number: [320/565] 56% | Training loss: 0.6889381289482117
Epoch: 74 | Iteration number: [330/565] 58% | Training loss: 0.6888597240953734
Epoch: 74 | Iteration number: [340/565] 60% | Training loss: 0.6887985786970924
Epoch: 74 | Iteration number: [350/565] 61% | Training loss: 0.6887367522716522
Epoch: 74 | Iteration number: [360/565] 63% | Training loss: 0.6886748474505212
Epoch: 74 | Iteration number: [370/565] 65% | Training loss: 0.6886306701479732
Epoch: 74 | Iteration number: [380/565] 67% | Training loss: 0.6885686168545171
Epoch: 74 | Iteration number: [390/565] 69% | Training loss: 0.6885224930751018
Epoch: 74 | Iteration number: [400/565] 70% | Training loss: 0.6884704406559468
Epoch: 74 | Iteration number: [410/565] 72% | Training loss: 0.6884282872444246
Epoch: 74 | Iteration number: [420/565] 74% | Training loss: 0.6883894840876261
Epoch: 74 | Iteration number: [430/565] 76% | Training loss: 0.688352078615233
Epoch: 74 | Iteration number: [440/565] 77% | Training loss: 0.6883128961378878
Epoch: 74 | Iteration number: [450/565] 79% | Training loss: 0.6882749108473459
Epoch: 74 | Iteration number: [460/565] 81% | Training loss: 0.6882440679747125
Epoch: 74 | Iteration number: [470/565] 83% | Training loss: 0.6882156691652663
Epoch: 74 | Iteration number: [480/565] 84% | Training loss: 0.6881868754824002
Epoch: 74 | Iteration number: [490/565] 86% | Training loss: 0.6881718043161899
Epoch: 74 | Iteration number: [500/565] 88% | Training loss: 0.6881470243930816
Epoch: 74 | Iteration number: [510/565] 90% | Training loss: 0.6881218283784156
Epoch: 74 | Iteration number: [520/565] 92% | Training loss: 0.6881060661031649
Epoch: 74 | Iteration number: [530/565] 93% | Training loss: 0.6880726410532897
Epoch: 74 | Iteration number: [540/565] 95% | Training loss: 0.6880515841422258
Epoch: 74 | Iteration number: [550/565] 97% | Training loss: 0.6880324159968983
Epoch: 74 | Iteration number: [560/565] 99% | Training loss: 0.6880195377128465

 End of epoch: 74 | Train Loss: 0.6867912695471164 | Training Time: 89 

 End of epoch: 74 | Eval Loss: 0.6897561975887844 | Evaluating Time: 6 
Epoch: 75 | Iteration number: [10/565] 1% | Training loss: 0.7550694167613983
Epoch: 75 | Iteration number: [20/565] 3% | Training loss: 0.7209441483020782
Epoch: 75 | Iteration number: [30/565] 5% | Training loss: 0.7094712913036346
Epoch: 75 | Iteration number: [40/565] 7% | Training loss: 0.7038881242275238
Epoch: 75 | Iteration number: [50/565] 8% | Training loss: 0.7005267798900604
Epoch: 75 | Iteration number: [60/565] 10% | Training loss: 0.698246102531751
Epoch: 75 | Iteration number: [70/565] 12% | Training loss: 0.6965739028794425
Epoch: 75 | Iteration number: [80/565] 14% | Training loss: 0.6953392580151558
Epoch: 75 | Iteration number: [90/565] 15% | Training loss: 0.6943460663159688
Epoch: 75 | Iteration number: [100/565] 17% | Training loss: 0.6936322987079621
Epoch: 75 | Iteration number: [110/565] 19% | Training loss: 0.693032693862915
Epoch: 75 | Iteration number: [120/565] 21% | Training loss: 0.692536981900533
Epoch: 75 | Iteration number: [130/565] 23% | Training loss: 0.692119862483098
Epoch: 75 | Iteration number: [140/565] 24% | Training loss: 0.6917480979646955
Epoch: 75 | Iteration number: [150/565] 26% | Training loss: 0.6914071146647135
Epoch: 75 | Iteration number: [160/565] 28% | Training loss: 0.6911244776099921
Epoch: 75 | Iteration number: [170/565] 30% | Training loss: 0.6908486944787643
Epoch: 75 | Iteration number: [180/565] 31% | Training loss: 0.6906219022141562
Epoch: 75 | Iteration number: [190/565] 33% | Training loss: 0.6904098112332193
Epoch: 75 | Iteration number: [200/565] 35% | Training loss: 0.6902192282676697
Epoch: 75 | Iteration number: [210/565] 37% | Training loss: 0.6900394595804669
Epoch: 75 | Iteration number: [220/565] 38% | Training loss: 0.6898903247984973
Epoch: 75 | Iteration number: [230/565] 40% | Training loss: 0.6897669735162154
Epoch: 75 | Iteration number: [240/565] 42% | Training loss: 0.6896477736532688
Epoch: 75 | Iteration number: [250/565] 44% | Training loss: 0.6895402612686157
Epoch: 75 | Iteration number: [260/565] 46% | Training loss: 0.6894472016738011
Epoch: 75 | Iteration number: [270/565] 47% | Training loss: 0.6893553126741339
Epoch: 75 | Iteration number: [280/565] 49% | Training loss: 0.6892711013555527
Epoch: 75 | Iteration number: [290/565] 51% | Training loss: 0.6891829496827618
Epoch: 75 | Iteration number: [300/565] 53% | Training loss: 0.6891109206279119
Epoch: 75 | Iteration number: [310/565] 54% | Training loss: 0.6890362603049125
Epoch: 75 | Iteration number: [320/565] 56% | Training loss: 0.6889640485867858
Epoch: 75 | Iteration number: [330/565] 58% | Training loss: 0.6888880812760555
Epoch: 75 | Iteration number: [340/565] 60% | Training loss: 0.6888034897692064
Epoch: 75 | Iteration number: [350/565] 61% | Training loss: 0.6887532813208443
Epoch: 75 | Iteration number: [360/565] 63% | Training loss: 0.688710980117321
Epoch: 75 | Iteration number: [370/565] 65% | Training loss: 0.6886542408852964
Epoch: 75 | Iteration number: [380/565] 67% | Training loss: 0.6885974592284152
Epoch: 75 | Iteration number: [390/565] 69% | Training loss: 0.6885594951800811
Epoch: 75 | Iteration number: [400/565] 70% | Training loss: 0.6885195679962635
Epoch: 75 | Iteration number: [410/565] 72% | Training loss: 0.6884847521781922
Epoch: 75 | Iteration number: [420/565] 74% | Training loss: 0.6884481488239198
Epoch: 75 | Iteration number: [430/565] 76% | Training loss: 0.6884082708247873
Epoch: 75 | Iteration number: [440/565] 77% | Training loss: 0.6883738433772867
Epoch: 75 | Iteration number: [450/565] 79% | Training loss: 0.6883490418063269
Epoch: 75 | Iteration number: [460/565] 81% | Training loss: 0.6883033317068349
Epoch: 75 | Iteration number: [470/565] 83% | Training loss: 0.6882585223684919
Epoch: 75 | Iteration number: [480/565] 84% | Training loss: 0.6882324680685997
Epoch: 75 | Iteration number: [490/565] 86% | Training loss: 0.6881945315672426
Epoch: 75 | Iteration number: [500/565] 88% | Training loss: 0.6881678799390792
Epoch: 75 | Iteration number: [510/565] 90% | Training loss: 0.6881412216261321
Epoch: 75 | Iteration number: [520/565] 92% | Training loss: 0.6881217478559567
Epoch: 75 | Iteration number: [530/565] 93% | Training loss: 0.6880899806067629
Epoch: 75 | Iteration number: [540/565] 95% | Training loss: 0.6880571909524776
Epoch: 75 | Iteration number: [550/565] 97% | Training loss: 0.6880307842384685
Epoch: 75 | Iteration number: [560/565] 99% | Training loss: 0.6880111436758722

 End of epoch: 75 | Train Loss: 0.6867831845199113 | Training Time: 90 

 End of epoch: 75 | Eval Loss: 0.6899448292596 | Evaluating Time: 6 
Epoch: 76 | Iteration number: [10/565] 1% | Training loss: 0.7552736222743988
Epoch: 76 | Iteration number: [20/565] 3% | Training loss: 0.7211828023195267
Epoch: 76 | Iteration number: [30/565] 5% | Training loss: 0.7097856819629669
Epoch: 76 | Iteration number: [40/565] 7% | Training loss: 0.7039776608347893
Epoch: 76 | Iteration number: [50/565] 8% | Training loss: 0.7005159866809845
Epoch: 76 | Iteration number: [60/565] 10% | Training loss: 0.698260701696078
Epoch: 76 | Iteration number: [70/565] 12% | Training loss: 0.6966846806662423
Epoch: 76 | Iteration number: [80/565] 14% | Training loss: 0.6954808190464974
Epoch: 76 | Iteration number: [90/565] 15% | Training loss: 0.6945358839299943
Epoch: 76 | Iteration number: [100/565] 17% | Training loss: 0.6937217134237289
Epoch: 76 | Iteration number: [110/565] 19% | Training loss: 0.693122757023031
Epoch: 76 | Iteration number: [120/565] 21% | Training loss: 0.6925923675298691
Epoch: 76 | Iteration number: [130/565] 23% | Training loss: 0.6921014033831083
Epoch: 76 | Iteration number: [140/565] 24% | Training loss: 0.6917133803878511
Epoch: 76 | Iteration number: [150/565] 26% | Training loss: 0.6913878508408864
Epoch: 76 | Iteration number: [160/565] 28% | Training loss: 0.6910830087959766
Epoch: 76 | Iteration number: [170/565] 30% | Training loss: 0.6908061963670394
Epoch: 76 | Iteration number: [180/565] 31% | Training loss: 0.6905776626533933
Epoch: 76 | Iteration number: [190/565] 33% | Training loss: 0.6903908211933939
Epoch: 76 | Iteration number: [200/565] 35% | Training loss: 0.6902158981561661
Epoch: 76 | Iteration number: [210/565] 37% | Training loss: 0.6900663341794695
Epoch: 76 | Iteration number: [220/565] 38% | Training loss: 0.68993069014766
Epoch: 76 | Iteration number: [230/565] 40% | Training loss: 0.6897812578989112
Epoch: 76 | Iteration number: [240/565] 42% | Training loss: 0.6896459676325322
Epoch: 76 | Iteration number: [250/565] 44% | Training loss: 0.6895307800769805
Epoch: 76 | Iteration number: [260/565] 46% | Training loss: 0.6894388366204042
Epoch: 76 | Iteration number: [270/565] 47% | Training loss: 0.6893398419574455
Epoch: 76 | Iteration number: [280/565] 49% | Training loss: 0.6892652824521065
Epoch: 76 | Iteration number: [290/565] 51% | Training loss: 0.6891777747663959
Epoch: 76 | Iteration number: [300/565] 53% | Training loss: 0.6890951263904571
Epoch: 76 | Iteration number: [310/565] 54% | Training loss: 0.6890145936319905
Epoch: 76 | Iteration number: [320/565] 56% | Training loss: 0.6889487592503428
Epoch: 76 | Iteration number: [330/565] 58% | Training loss: 0.6888971440719835
Epoch: 76 | Iteration number: [340/565] 60% | Training loss: 0.6888337752398322
Epoch: 76 | Iteration number: [350/565] 61% | Training loss: 0.6887770647662027
Epoch: 76 | Iteration number: [360/565] 63% | Training loss: 0.6887151733040809
Epoch: 76 | Iteration number: [370/565] 65% | Training loss: 0.6886670893913991
Epoch: 76 | Iteration number: [380/565] 67% | Training loss: 0.6886176148527547
Epoch: 76 | Iteration number: [390/565] 69% | Training loss: 0.688557631847186
Epoch: 76 | Iteration number: [400/565] 70% | Training loss: 0.6885182262957096
Epoch: 76 | Iteration number: [410/565] 72% | Training loss: 0.6884767375341276
Epoch: 76 | Iteration number: [420/565] 74% | Training loss: 0.6884405786082858
Epoch: 76 | Iteration number: [430/565] 76% | Training loss: 0.6884071272473002
Epoch: 76 | Iteration number: [440/565] 77% | Training loss: 0.6883659965612672
Epoch: 76 | Iteration number: [450/565] 79% | Training loss: 0.688333699438307
Epoch: 76 | Iteration number: [460/565] 81% | Training loss: 0.6883063097362933
Epoch: 76 | Iteration number: [470/565] 83% | Training loss: 0.68827572617125
Epoch: 76 | Iteration number: [480/565] 84% | Training loss: 0.6882428345580895
Epoch: 76 | Iteration number: [490/565] 86% | Training loss: 0.6882143723721407
Epoch: 76 | Iteration number: [500/565] 88% | Training loss: 0.6881860190629959
Epoch: 76 | Iteration number: [510/565] 90% | Training loss: 0.6881606149907206
Epoch: 76 | Iteration number: [520/565] 92% | Training loss: 0.6881329882603425
Epoch: 76 | Iteration number: [530/565] 93% | Training loss: 0.6881063331972878
Epoch: 76 | Iteration number: [540/565] 95% | Training loss: 0.6880834504410073
Epoch: 76 | Iteration number: [550/565] 97% | Training loss: 0.6880581499229778
Epoch: 76 | Iteration number: [560/565] 99% | Training loss: 0.6880287767520973

 End of epoch: 76 | Train Loss: 0.68680015644141 | Training Time: 90 

 End of epoch: 76 | Eval Loss: 0.6896106089864459 | Evaluating Time: 6 
Epoch: 77 | Iteration number: [10/565] 1% | Training loss: 0.7558329463005066
Epoch: 77 | Iteration number: [20/565] 3% | Training loss: 0.7212353497743607
Epoch: 77 | Iteration number: [30/565] 5% | Training loss: 0.7098434925079345
Epoch: 77 | Iteration number: [40/565] 7% | Training loss: 0.7041614845395088
Epoch: 77 | Iteration number: [50/565] 8% | Training loss: 0.700728794336319
Epoch: 77 | Iteration number: [60/565] 10% | Training loss: 0.698399489124616
Epoch: 77 | Iteration number: [70/565] 12% | Training loss: 0.6968137068407876
Epoch: 77 | Iteration number: [80/565] 14% | Training loss: 0.6956011630594731
Epoch: 77 | Iteration number: [90/565] 15% | Training loss: 0.6946272763941023
Epoch: 77 | Iteration number: [100/565] 17% | Training loss: 0.6937996220588684
Epoch: 77 | Iteration number: [110/565] 19% | Training loss: 0.6931951273571361
Epoch: 77 | Iteration number: [120/565] 21% | Training loss: 0.6926103373368581
Epoch: 77 | Iteration number: [130/565] 23% | Training loss: 0.6921676356058855
Epoch: 77 | Iteration number: [140/565] 24% | Training loss: 0.691770567212786
Epoch: 77 | Iteration number: [150/565] 26% | Training loss: 0.6914617077509562
Epoch: 77 | Iteration number: [160/565] 28% | Training loss: 0.6911903910338879
Epoch: 77 | Iteration number: [170/565] 30% | Training loss: 0.6909415325697731
Epoch: 77 | Iteration number: [180/565] 31% | Training loss: 0.690706283516354
Epoch: 77 | Iteration number: [190/565] 33% | Training loss: 0.6904913610533664
Epoch: 77 | Iteration number: [200/565] 35% | Training loss: 0.6902672943472862
Epoch: 77 | Iteration number: [210/565] 37% | Training loss: 0.6900826527958824
Epoch: 77 | Iteration number: [220/565] 38% | Training loss: 0.6899454084309664
Epoch: 77 | Iteration number: [230/565] 40% | Training loss: 0.6898143335528996
Epoch: 77 | Iteration number: [240/565] 42% | Training loss: 0.6897007152438164
Epoch: 77 | Iteration number: [250/565] 44% | Training loss: 0.6895958876609802
Epoch: 77 | Iteration number: [260/565] 46% | Training loss: 0.68947602051955
Epoch: 77 | Iteration number: [270/565] 47% | Training loss: 0.6893848293357425
Epoch: 77 | Iteration number: [280/565] 49% | Training loss: 0.6893004242862973
Epoch: 77 | Iteration number: [290/565] 51% | Training loss: 0.6892076724562152
Epoch: 77 | Iteration number: [300/565] 53% | Training loss: 0.68913116812706
Epoch: 77 | Iteration number: [310/565] 54% | Training loss: 0.6890383445447491
Epoch: 77 | Iteration number: [320/565] 56% | Training loss: 0.6889712803065777
Epoch: 77 | Iteration number: [330/565] 58% | Training loss: 0.6889135380585988
Epoch: 77 | Iteration number: [340/565] 60% | Training loss: 0.6888447744004866
Epoch: 77 | Iteration number: [350/565] 61% | Training loss: 0.6887756386825017
Epoch: 77 | Iteration number: [360/565] 63% | Training loss: 0.6887023670805825
Epoch: 77 | Iteration number: [370/565] 65% | Training loss: 0.6886644083100396
Epoch: 77 | Iteration number: [380/565] 67% | Training loss: 0.6886008017941525
Epoch: 77 | Iteration number: [390/565] 69% | Training loss: 0.6885561160552196
Epoch: 77 | Iteration number: [400/565] 70% | Training loss: 0.6885051438212395
Epoch: 77 | Iteration number: [410/565] 72% | Training loss: 0.6884642073294012
Epoch: 77 | Iteration number: [420/565] 74% | Training loss: 0.6884285124994459
Epoch: 77 | Iteration number: [430/565] 76% | Training loss: 0.6883976164252259
Epoch: 77 | Iteration number: [440/565] 77% | Training loss: 0.6883634805679322
Epoch: 77 | Iteration number: [450/565] 79% | Training loss: 0.688327816857232
Epoch: 77 | Iteration number: [460/565] 81% | Training loss: 0.6882951089869375
Epoch: 77 | Iteration number: [470/565] 83% | Training loss: 0.6882677063028864
Epoch: 77 | Iteration number: [480/565] 84% | Training loss: 0.6882497522979975
Epoch: 77 | Iteration number: [490/565] 86% | Training loss: 0.6882208365566876
Epoch: 77 | Iteration number: [500/565] 88% | Training loss: 0.6881901232004166
Epoch: 77 | Iteration number: [510/565] 90% | Training loss: 0.6881529098632289
Epoch: 77 | Iteration number: [520/565] 92% | Training loss: 0.688125857940087
Epoch: 77 | Iteration number: [530/565] 93% | Training loss: 0.6881081916251273
Epoch: 77 | Iteration number: [540/565] 95% | Training loss: 0.6880819776543865
Epoch: 77 | Iteration number: [550/565] 97% | Training loss: 0.6880534193732522
Epoch: 77 | Iteration number: [560/565] 99% | Training loss: 0.6880286234830107

 End of epoch: 77 | Train Loss: 0.6868060427429402 | Training Time: 89 

 End of epoch: 77 | Eval Loss: 0.6891687767846244 | Evaluating Time: 6 
Epoch: 78 | Iteration number: [10/565] 1% | Training loss: 0.755433189868927
Epoch: 78 | Iteration number: [20/565] 3% | Training loss: 0.7212364643812179
Epoch: 78 | Iteration number: [30/565] 5% | Training loss: 0.709797606865565
Epoch: 78 | Iteration number: [40/565] 7% | Training loss: 0.7040669307112694
Epoch: 78 | Iteration number: [50/565] 8% | Training loss: 0.7006607472896575
Epoch: 78 | Iteration number: [60/565] 10% | Training loss: 0.6983572940031687
Epoch: 78 | Iteration number: [70/565] 12% | Training loss: 0.6967147537640163
Epoch: 78 | Iteration number: [80/565] 14% | Training loss: 0.6954679995775223
Epoch: 78 | Iteration number: [90/565] 15% | Training loss: 0.6945238027307722
Epoch: 78 | Iteration number: [100/565] 17% | Training loss: 0.6937926137447357
Epoch: 78 | Iteration number: [110/565] 19% | Training loss: 0.6931972043080763
Epoch: 78 | Iteration number: [120/565] 21% | Training loss: 0.6926724473635356
Epoch: 78 | Iteration number: [130/565] 23% | Training loss: 0.6922174187806936
Epoch: 78 | Iteration number: [140/565] 24% | Training loss: 0.6918407010180609
Epoch: 78 | Iteration number: [150/565] 26% | Training loss: 0.691504211028417
Epoch: 78 | Iteration number: [160/565] 28% | Training loss: 0.6911887474358082
Epoch: 78 | Iteration number: [170/565] 30% | Training loss: 0.6909312300822315
Epoch: 78 | Iteration number: [180/565] 31% | Training loss: 0.6906912962595622
Epoch: 78 | Iteration number: [190/565] 33% | Training loss: 0.6904818051739743
Epoch: 78 | Iteration number: [200/565] 35% | Training loss: 0.6902893874049186
Epoch: 78 | Iteration number: [210/565] 37% | Training loss: 0.6901407363868896
Epoch: 78 | Iteration number: [220/565] 38% | Training loss: 0.6899916562167081
Epoch: 78 | Iteration number: [230/565] 40% | Training loss: 0.6898518323898315
Epoch: 78 | Iteration number: [240/565] 42% | Training loss: 0.6897249765694141
Epoch: 78 | Iteration number: [250/565] 44% | Training loss: 0.6896258413791656
Epoch: 78 | Iteration number: [260/565] 46% | Training loss: 0.6895241322425696
Epoch: 78 | Iteration number: [270/565] 47% | Training loss: 0.6894008040428161
Epoch: 78 | Iteration number: [280/565] 49% | Training loss: 0.6893193442906652
Epoch: 78 | Iteration number: [290/565] 51% | Training loss: 0.6892221541240298
Epoch: 78 | Iteration number: [300/565] 53% | Training loss: 0.6891467452049256
Epoch: 78 | Iteration number: [310/565] 54% | Training loss: 0.6890669863070211
Epoch: 78 | Iteration number: [320/565] 56% | Training loss: 0.6889978680759669
Epoch: 78 | Iteration number: [330/565] 58% | Training loss: 0.6889229743769675
Epoch: 78 | Iteration number: [340/565] 60% | Training loss: 0.6888682712526882
Epoch: 78 | Iteration number: [350/565] 61% | Training loss: 0.6888048056193761
Epoch: 78 | Iteration number: [360/565] 63% | Training loss: 0.6887446456485324
Epoch: 78 | Iteration number: [370/565] 65% | Training loss: 0.6886808686965221
Epoch: 78 | Iteration number: [380/565] 67% | Training loss: 0.6886344768499073
Epoch: 78 | Iteration number: [390/565] 69% | Training loss: 0.6885836090797033
Epoch: 78 | Iteration number: [400/565] 70% | Training loss: 0.6885389399528503
Epoch: 78 | Iteration number: [410/565] 72% | Training loss: 0.688499395876396
Epoch: 78 | Iteration number: [420/565] 74% | Training loss: 0.6884533518836612
Epoch: 78 | Iteration number: [430/565] 76% | Training loss: 0.6884129391160122
Epoch: 78 | Iteration number: [440/565] 77% | Training loss: 0.6883783872831951
Epoch: 78 | Iteration number: [450/565] 79% | Training loss: 0.6883323809835646
Epoch: 78 | Iteration number: [460/565] 81% | Training loss: 0.6882845387510631
Epoch: 78 | Iteration number: [470/565] 83% | Training loss: 0.6882556200027465
Epoch: 78 | Iteration number: [480/565] 84% | Training loss: 0.6882320409019788
Epoch: 78 | Iteration number: [490/565] 86% | Training loss: 0.6882039362070512
Epoch: 78 | Iteration number: [500/565] 88% | Training loss: 0.6881782358884811
Epoch: 78 | Iteration number: [510/565] 90% | Training loss: 0.6881592584591286
Epoch: 78 | Iteration number: [520/565] 92% | Training loss: 0.6881183913120856
Epoch: 78 | Iteration number: [530/565] 93% | Training loss: 0.6880891267983419
Epoch: 78 | Iteration number: [540/565] 95% | Training loss: 0.6880619129648915
Epoch: 78 | Iteration number: [550/565] 97% | Training loss: 0.6880390901999041
Epoch: 78 | Iteration number: [560/565] 99% | Training loss: 0.6880103778626238

 End of epoch: 78 | Train Loss: 0.6867837321441785 | Training Time: 89 

 End of epoch: 78 | Eval Loss: 0.6894939201218742 | Evaluating Time: 6 
Epoch: 79 | Iteration number: [10/565] 1% | Training loss: 0.7552090644836426
Epoch: 79 | Iteration number: [20/565] 3% | Training loss: 0.7209261417388916
Epoch: 79 | Iteration number: [30/565] 5% | Training loss: 0.709582922856013
Epoch: 79 | Iteration number: [40/565] 7% | Training loss: 0.7038946017622948
Epoch: 79 | Iteration number: [50/565] 8% | Training loss: 0.7004977560043335
Epoch: 79 | Iteration number: [60/565] 10% | Training loss: 0.6983077585697174
Epoch: 79 | Iteration number: [70/565] 12% | Training loss: 0.6965903409889767
Epoch: 79 | Iteration number: [80/565] 14% | Training loss: 0.695314708352089
Epoch: 79 | Iteration number: [90/565] 15% | Training loss: 0.6943958302338918
Epoch: 79 | Iteration number: [100/565] 17% | Training loss: 0.6936223763227463
Epoch: 79 | Iteration number: [110/565] 19% | Training loss: 0.6930065556005998
Epoch: 79 | Iteration number: [120/565] 21% | Training loss: 0.6924819986025492
Epoch: 79 | Iteration number: [130/565] 23% | Training loss: 0.6920354325037736
Epoch: 79 | Iteration number: [140/565] 24% | Training loss: 0.6916829832962581
Epoch: 79 | Iteration number: [150/565] 26% | Training loss: 0.6913595469792684
Epoch: 79 | Iteration number: [160/565] 28% | Training loss: 0.6910946272313595
Epoch: 79 | Iteration number: [170/565] 30% | Training loss: 0.6908396727898541
Epoch: 79 | Iteration number: [180/565] 31% | Training loss: 0.6906241953372956
Epoch: 79 | Iteration number: [190/565] 33% | Training loss: 0.69040376010694
Epoch: 79 | Iteration number: [200/565] 35% | Training loss: 0.6902349171042442
Epoch: 79 | Iteration number: [210/565] 37% | Training loss: 0.6901118139425914
Epoch: 79 | Iteration number: [220/565] 38% | Training loss: 0.6899636084383184
Epoch: 79 | Iteration number: [230/565] 40% | Training loss: 0.6898226289645485
Epoch: 79 | Iteration number: [240/565] 42% | Training loss: 0.6896939468880494
Epoch: 79 | Iteration number: [250/565] 44% | Training loss: 0.6895819060802459
Epoch: 79 | Iteration number: [260/565] 46% | Training loss: 0.6894642527286823
Epoch: 79 | Iteration number: [270/565] 47% | Training loss: 0.6893734176953633
Epoch: 79 | Iteration number: [280/565] 49% | Training loss: 0.6892833796995027
Epoch: 79 | Iteration number: [290/565] 51% | Training loss: 0.6891854125877906
Epoch: 79 | Iteration number: [300/565] 53% | Training loss: 0.6890962612628937
Epoch: 79 | Iteration number: [310/565] 54% | Training loss: 0.6890226235312801
Epoch: 79 | Iteration number: [320/565] 56% | Training loss: 0.6889470349997282
Epoch: 79 | Iteration number: [330/565] 58% | Training loss: 0.6888914393656181
Epoch: 79 | Iteration number: [340/565] 60% | Training loss: 0.6888157827012679
Epoch: 79 | Iteration number: [350/565] 61% | Training loss: 0.6887507632800511
Epoch: 79 | Iteration number: [360/565] 63% | Training loss: 0.6887013294630581
Epoch: 79 | Iteration number: [370/565] 65% | Training loss: 0.6886389258745554
Epoch: 79 | Iteration number: [380/565] 67% | Training loss: 0.6885793502393521
Epoch: 79 | Iteration number: [390/565] 69% | Training loss: 0.6885263413955004
Epoch: 79 | Iteration number: [400/565] 70% | Training loss: 0.6884866473078728
Epoch: 79 | Iteration number: [410/565] 72% | Training loss: 0.6884458086839537
Epoch: 79 | Iteration number: [420/565] 74% | Training loss: 0.688414278626442
Epoch: 79 | Iteration number: [430/565] 76% | Training loss: 0.6883836366409479
Epoch: 79 | Iteration number: [440/565] 77% | Training loss: 0.6883463953029025
Epoch: 79 | Iteration number: [450/565] 79% | Training loss: 0.6883107844988505
Epoch: 79 | Iteration number: [460/565] 81% | Training loss: 0.6882746227409529
Epoch: 79 | Iteration number: [470/565] 83% | Training loss: 0.688242288599623
Epoch: 79 | Iteration number: [480/565] 84% | Training loss: 0.6882168428351482
Epoch: 79 | Iteration number: [490/565] 86% | Training loss: 0.6881821829445508
Epoch: 79 | Iteration number: [500/565] 88% | Training loss: 0.6881532850265503
Epoch: 79 | Iteration number: [510/565] 90% | Training loss: 0.6881189064652312
Epoch: 79 | Iteration number: [520/565] 92% | Training loss: 0.6880961124713604
Epoch: 79 | Iteration number: [530/565] 93% | Training loss: 0.68807225159879
Epoch: 79 | Iteration number: [540/565] 95% | Training loss: 0.6880532751480738
Epoch: 79 | Iteration number: [550/565] 97% | Training loss: 0.6880312376672572
Epoch: 79 | Iteration number: [560/565] 99% | Training loss: 0.6880115122667381

 End of epoch: 79 | Train Loss: 0.6867872364753116 | Training Time: 89 

 End of epoch: 79 | Eval Loss: 0.6899983031409127 | Evaluating Time: 6 
Epoch: 80 | Iteration number: [10/565] 1% | Training loss: 0.7555656254291534
Epoch: 80 | Iteration number: [20/565] 3% | Training loss: 0.7211774975061417
Epoch: 80 | Iteration number: [30/565] 5% | Training loss: 0.7099101126194001
Epoch: 80 | Iteration number: [40/565] 7% | Training loss: 0.7042241528630256
Epoch: 80 | Iteration number: [50/565] 8% | Training loss: 0.7007343566417694
Epoch: 80 | Iteration number: [60/565] 10% | Training loss: 0.6983440895875295
Epoch: 80 | Iteration number: [70/565] 12% | Training loss: 0.6967522748879024
Epoch: 80 | Iteration number: [80/565] 14% | Training loss: 0.6954836249351501
Epoch: 80 | Iteration number: [90/565] 15% | Training loss: 0.6946159773402744
Epoch: 80 | Iteration number: [100/565] 17% | Training loss: 0.6938261765241623
Epoch: 80 | Iteration number: [110/565] 19% | Training loss: 0.693214875459671
Epoch: 80 | Iteration number: [120/565] 21% | Training loss: 0.6927120238542557
Epoch: 80 | Iteration number: [130/565] 23% | Training loss: 0.6923041490408091
Epoch: 80 | Iteration number: [140/565] 24% | Training loss: 0.6919370480946132
Epoch: 80 | Iteration number: [150/565] 26% | Training loss: 0.6916004788875579
Epoch: 80 | Iteration number: [160/565] 28% | Training loss: 0.6913018062710762
Epoch: 80 | Iteration number: [170/565] 30% | Training loss: 0.6910298515768613
Epoch: 80 | Iteration number: [180/565] 31% | Training loss: 0.6907830867502425
Epoch: 80 | Iteration number: [190/565] 33% | Training loss: 0.690581728910145
Epoch: 80 | Iteration number: [200/565] 35% | Training loss: 0.6903852847218513
Epoch: 80 | Iteration number: [210/565] 37% | Training loss: 0.6902352702049982
Epoch: 80 | Iteration number: [220/565] 38% | Training loss: 0.6900859407403253
Epoch: 80 | Iteration number: [230/565] 40% | Training loss: 0.6899344923703566
Epoch: 80 | Iteration number: [240/565] 42% | Training loss: 0.6898074527581533
Epoch: 80 | Iteration number: [250/565] 44% | Training loss: 0.6896661982536316
Epoch: 80 | Iteration number: [260/565] 46% | Training loss: 0.6895284783381682
Epoch: 80 | Iteration number: [270/565] 47% | Training loss: 0.6894369652977697
Epoch: 80 | Iteration number: [280/565] 49% | Training loss: 0.689344075535025
Epoch: 80 | Iteration number: [290/565] 51% | Training loss: 0.6892451146553302
Epoch: 80 | Iteration number: [300/565] 53% | Training loss: 0.68915354291598
Epoch: 80 | Iteration number: [310/565] 54% | Training loss: 0.689070079980358
Epoch: 80 | Iteration number: [320/565] 56% | Training loss: 0.6889794867485761
Epoch: 80 | Iteration number: [330/565] 58% | Training loss: 0.6889075877088489
Epoch: 80 | Iteration number: [340/565] 60% | Training loss: 0.6888546196853413
Epoch: 80 | Iteration number: [350/565] 61% | Training loss: 0.6888100562776838
Epoch: 80 | Iteration number: [360/565] 63% | Training loss: 0.6887386752499475
Epoch: 80 | Iteration number: [370/565] 65% | Training loss: 0.6886906019739203
Epoch: 80 | Iteration number: [380/565] 67% | Training loss: 0.6886269784287402
Epoch: 80 | Iteration number: [390/565] 69% | Training loss: 0.6885811727780562
Epoch: 80 | Iteration number: [400/565] 70% | Training loss: 0.688531840890646
Epoch: 80 | Iteration number: [410/565] 72% | Training loss: 0.6884925634395785
Epoch: 80 | Iteration number: [420/565] 74% | Training loss: 0.6884465629146213
Epoch: 80 | Iteration number: [430/565] 76% | Training loss: 0.6884070548900338
Epoch: 80 | Iteration number: [440/565] 77% | Training loss: 0.6883684902028604
Epoch: 80 | Iteration number: [450/565] 79% | Training loss: 0.6883334851264954
Epoch: 80 | Iteration number: [460/565] 81% | Training loss: 0.6883014322622962
Epoch: 80 | Iteration number: [470/565] 83% | Training loss: 0.6882784019125269
Epoch: 80 | Iteration number: [480/565] 84% | Training loss: 0.6882343653589487
Epoch: 80 | Iteration number: [490/565] 86% | Training loss: 0.6882082390541933
Epoch: 80 | Iteration number: [500/565] 88% | Training loss: 0.6881703280210495
Epoch: 80 | Iteration number: [510/565] 90% | Training loss: 0.6881310503856809
Epoch: 80 | Iteration number: [520/565] 92% | Training loss: 0.688098184305888
Epoch: 80 | Iteration number: [530/565] 93% | Training loss: 0.6880755935075148
Epoch: 80 | Iteration number: [540/565] 95% | Training loss: 0.6880507896343867
Epoch: 80 | Iteration number: [550/565] 97% | Training loss: 0.6880242862484672
Epoch: 80 | Iteration number: [560/565] 99% | Training loss: 0.6879991551595075

 End of epoch: 80 | Train Loss: 0.6867776756792997 | Training Time: 88 

 End of epoch: 80 | Eval Loss: 0.6897108043943133 | Evaluating Time: 5 
Epoch: 81 | Iteration number: [10/565] 1% | Training loss: 0.7556443572044372
Epoch: 81 | Iteration number: [20/565] 3% | Training loss: 0.7212404757738113
Epoch: 81 | Iteration number: [30/565] 5% | Training loss: 0.709730855623881
Epoch: 81 | Iteration number: [40/565] 7% | Training loss: 0.7038963004946709
Epoch: 81 | Iteration number: [50/565] 8% | Training loss: 0.7005288577079773
Epoch: 81 | Iteration number: [60/565] 10% | Training loss: 0.6982701470454534
Epoch: 81 | Iteration number: [70/565] 12% | Training loss: 0.6965842195919582
Epoch: 81 | Iteration number: [80/565] 14% | Training loss: 0.6952913075685501
Epoch: 81 | Iteration number: [90/565] 15% | Training loss: 0.694313457277086
Epoch: 81 | Iteration number: [100/565] 17% | Training loss: 0.6935476577281952
Epoch: 81 | Iteration number: [110/565] 19% | Training loss: 0.692942723902789
Epoch: 81 | Iteration number: [120/565] 21% | Training loss: 0.692436657845974
Epoch: 81 | Iteration number: [130/565] 23% | Training loss: 0.6919599743989798
Epoch: 81 | Iteration number: [140/565] 24% | Training loss: 0.6915866728339877
Epoch: 81 | Iteration number: [150/565] 26% | Training loss: 0.6912428987026215
Epoch: 81 | Iteration number: [160/565] 28% | Training loss: 0.6909598685801029
Epoch: 81 | Iteration number: [170/565] 30% | Training loss: 0.6907140900106991
Epoch: 81 | Iteration number: [180/565] 31% | Training loss: 0.6905146711402469
Epoch: 81 | Iteration number: [190/565] 33% | Training loss: 0.6903151515283082
Epoch: 81 | Iteration number: [200/565] 35% | Training loss: 0.6901336014270782
Epoch: 81 | Iteration number: [210/565] 37% | Training loss: 0.6899879503817785
Epoch: 81 | Iteration number: [220/565] 38% | Training loss: 0.6898285621946508
Epoch: 81 | Iteration number: [230/565] 40% | Training loss: 0.6896925508975983
Epoch: 81 | Iteration number: [240/565] 42% | Training loss: 0.6895937065283457
Epoch: 81 | Iteration number: [250/565] 44% | Training loss: 0.6894630541801453
Epoch: 81 | Iteration number: [260/565] 46% | Training loss: 0.6893545455657519
Epoch: 81 | Iteration number: [270/565] 47% | Training loss: 0.6892637444867028
Epoch: 81 | Iteration number: [280/565] 49% | Training loss: 0.6891850888729095
Epoch: 81 | Iteration number: [290/565] 51% | Training loss: 0.6890905248707738
Epoch: 81 | Iteration number: [300/565] 53% | Training loss: 0.689033653140068
Epoch: 81 | Iteration number: [310/565] 54% | Training loss: 0.6889578838502207
Epoch: 81 | Iteration number: [320/565] 56% | Training loss: 0.6888851715251804
Epoch: 81 | Iteration number: [330/565] 58% | Training loss: 0.688809451009288
Epoch: 81 | Iteration number: [340/565] 60% | Training loss: 0.6887447325622335
Epoch: 81 | Iteration number: [350/565] 61% | Training loss: 0.6886850431987217
Epoch: 81 | Iteration number: [360/565] 63% | Training loss: 0.6886290786994829
Epoch: 81 | Iteration number: [370/565] 65% | Training loss: 0.6885801160657729
Epoch: 81 | Iteration number: [380/565] 67% | Training loss: 0.6885214477777482
Epoch: 81 | Iteration number: [390/565] 69% | Training loss: 0.6884843402948135
Epoch: 81 | Iteration number: [400/565] 70% | Training loss: 0.6884480810165405
Epoch: 81 | Iteration number: [410/565] 72% | Training loss: 0.688406440252211
Epoch: 81 | Iteration number: [420/565] 74% | Training loss: 0.6883721761760258
Epoch: 81 | Iteration number: [430/565] 76% | Training loss: 0.6883339427238286
Epoch: 81 | Iteration number: [440/565] 77% | Training loss: 0.6882890182462605
Epoch: 81 | Iteration number: [450/565] 79% | Training loss: 0.6882608208391402
Epoch: 81 | Iteration number: [460/565] 81% | Training loss: 0.688237923902014
Epoch: 81 | Iteration number: [470/565] 83% | Training loss: 0.6882121967508438
Epoch: 81 | Iteration number: [480/565] 84% | Training loss: 0.6881806783378124
Epoch: 81 | Iteration number: [490/565] 86% | Training loss: 0.6881465256214142
Epoch: 81 | Iteration number: [500/565] 88% | Training loss: 0.6881275471448899
Epoch: 81 | Iteration number: [510/565] 90% | Training loss: 0.6881052787397423
Epoch: 81 | Iteration number: [520/565] 92% | Training loss: 0.6880784157377023
Epoch: 81 | Iteration number: [530/565] 93% | Training loss: 0.6880611487154691
Epoch: 81 | Iteration number: [540/565] 95% | Training loss: 0.6880377811414224
Epoch: 81 | Iteration number: [550/565] 97% | Training loss: 0.6880148936401714
Epoch: 81 | Iteration number: [560/565] 99% | Training loss: 0.6879981266600745

 End of epoch: 81 | Train Loss: 0.6867771936728891 | Training Time: 90 

 End of epoch: 81 | Eval Loss: 0.6895798870495388 | Evaluating Time: 6 
Epoch: 82 | Iteration number: [10/565] 1% | Training loss: 0.75539271235466
Epoch: 82 | Iteration number: [20/565] 3% | Training loss: 0.7209818214178085
Epoch: 82 | Iteration number: [30/565] 5% | Training loss: 0.7095905204614004
Epoch: 82 | Iteration number: [40/565] 7% | Training loss: 0.7040046200156211
Epoch: 82 | Iteration number: [50/565] 8% | Training loss: 0.700603905916214
Epoch: 82 | Iteration number: [60/565] 10% | Training loss: 0.6983057240645091
Epoch: 82 | Iteration number: [70/565] 12% | Training loss: 0.6966114742415291
Epoch: 82 | Iteration number: [80/565] 14% | Training loss: 0.695439750701189
Epoch: 82 | Iteration number: [90/565] 15% | Training loss: 0.6944597913159265
Epoch: 82 | Iteration number: [100/565] 17% | Training loss: 0.6937091594934464
Epoch: 82 | Iteration number: [110/565] 19% | Training loss: 0.6930433956059543
Epoch: 82 | Iteration number: [120/565] 21% | Training loss: 0.6925179362297058
Epoch: 82 | Iteration number: [130/565] 23% | Training loss: 0.6921027229382442
Epoch: 82 | Iteration number: [140/565] 24% | Training loss: 0.6916846198695047
Epoch: 82 | Iteration number: [150/565] 26% | Training loss: 0.6913739510377248
Epoch: 82 | Iteration number: [160/565] 28% | Training loss: 0.691067648679018
Epoch: 82 | Iteration number: [170/565] 30% | Training loss: 0.6908397302908056
Epoch: 82 | Iteration number: [180/565] 31% | Training loss: 0.6906131724516551
Epoch: 82 | Iteration number: [190/565] 33% | Training loss: 0.6904184322608145
Epoch: 82 | Iteration number: [200/565] 35% | Training loss: 0.6902209377288818
Epoch: 82 | Iteration number: [210/565] 37% | Training loss: 0.6900488379455748
Epoch: 82 | Iteration number: [220/565] 38% | Training loss: 0.6899171769618988
Epoch: 82 | Iteration number: [230/565] 40% | Training loss: 0.6897815338943316
Epoch: 82 | Iteration number: [240/565] 42% | Training loss: 0.6896631551285585
Epoch: 82 | Iteration number: [250/565] 44% | Training loss: 0.689528785943985
Epoch: 82 | Iteration number: [260/565] 46% | Training loss: 0.689437047793315
Epoch: 82 | Iteration number: [270/565] 47% | Training loss: 0.6893480625417497
Epoch: 82 | Iteration number: [280/565] 49% | Training loss: 0.6892604736345155
Epoch: 82 | Iteration number: [290/565] 51% | Training loss: 0.6891698602972359
Epoch: 82 | Iteration number: [300/565] 53% | Training loss: 0.6890826511383057
Epoch: 82 | Iteration number: [310/565] 54% | Training loss: 0.6890103470894599
Epoch: 82 | Iteration number: [320/565] 56% | Training loss: 0.6889335796236992
Epoch: 82 | Iteration number: [330/565] 58% | Training loss: 0.6888715220220161
Epoch: 82 | Iteration number: [340/565] 60% | Training loss: 0.6888094730236951
Epoch: 82 | Iteration number: [350/565] 61% | Training loss: 0.68875660606793
Epoch: 82 | Iteration number: [360/565] 63% | Training loss: 0.6887020212080743
Epoch: 82 | Iteration number: [370/565] 65% | Training loss: 0.6886506644455163
Epoch: 82 | Iteration number: [380/565] 67% | Training loss: 0.6886059252839339
Epoch: 82 | Iteration number: [390/565] 69% | Training loss: 0.6885623493255713
Epoch: 82 | Iteration number: [400/565] 70% | Training loss: 0.6885103173553944
Epoch: 82 | Iteration number: [410/565] 72% | Training loss: 0.6884673897813006
Epoch: 82 | Iteration number: [420/565] 74% | Training loss: 0.6884276602949415
Epoch: 82 | Iteration number: [430/565] 76% | Training loss: 0.6883701447830644
Epoch: 82 | Iteration number: [440/565] 77% | Training loss: 0.6883376927538352
Epoch: 82 | Iteration number: [450/565] 79% | Training loss: 0.6882997869120704
Epoch: 82 | Iteration number: [460/565] 81% | Training loss: 0.6882636877505676
Epoch: 82 | Iteration number: [470/565] 83% | Training loss: 0.6882396517915929
Epoch: 82 | Iteration number: [480/565] 84% | Training loss: 0.6882073659449816
Epoch: 82 | Iteration number: [490/565] 86% | Training loss: 0.6881738554458229
Epoch: 82 | Iteration number: [500/565] 88% | Training loss: 0.6881506711244583
Epoch: 82 | Iteration number: [510/565] 90% | Training loss: 0.6881212281245811
Epoch: 82 | Iteration number: [520/565] 92% | Training loss: 0.6880940957711293
Epoch: 82 | Iteration number: [530/565] 93% | Training loss: 0.6880717661020891
Epoch: 82 | Iteration number: [540/565] 95% | Training loss: 0.6880483088669953
Epoch: 82 | Iteration number: [550/565] 97% | Training loss: 0.6880285295573147
Epoch: 82 | Iteration number: [560/565] 99% | Training loss: 0.6879986043487276

 End of epoch: 82 | Train Loss: 0.6867709208378749 | Training Time: 89 

 End of epoch: 82 | Eval Loss: 0.6897514888218471 | Evaluating Time: 6 
Epoch: 83 | Iteration number: [10/565] 1% | Training loss: 0.7556671082973481
Epoch: 83 | Iteration number: [20/565] 3% | Training loss: 0.7214728176593781
Epoch: 83 | Iteration number: [30/565] 5% | Training loss: 0.7096963485081991
Epoch: 83 | Iteration number: [40/565] 7% | Training loss: 0.7039301633834839
Epoch: 83 | Iteration number: [50/565] 8% | Training loss: 0.7005158913135529
Epoch: 83 | Iteration number: [60/565] 10% | Training loss: 0.698231186469396
Epoch: 83 | Iteration number: [70/565] 12% | Training loss: 0.6965460734707969
Epoch: 83 | Iteration number: [80/565] 14% | Training loss: 0.6953763924539089
Epoch: 83 | Iteration number: [90/565] 15% | Training loss: 0.6943624185191261
Epoch: 83 | Iteration number: [100/565] 17% | Training loss: 0.6935890513658524
Epoch: 83 | Iteration number: [110/565] 19% | Training loss: 0.6929863713004373
Epoch: 83 | Iteration number: [120/565] 21% | Training loss: 0.6924727022647857
Epoch: 83 | Iteration number: [130/565] 23% | Training loss: 0.6920707289989178
Epoch: 83 | Iteration number: [140/565] 24% | Training loss: 0.6916989479746137
Epoch: 83 | Iteration number: [150/565] 26% | Training loss: 0.6913552622000376
Epoch: 83 | Iteration number: [160/565] 28% | Training loss: 0.6910830549895763
Epoch: 83 | Iteration number: [170/565] 30% | Training loss: 0.690851460835513
Epoch: 83 | Iteration number: [180/565] 31% | Training loss: 0.6906124350097445
Epoch: 83 | Iteration number: [190/565] 33% | Training loss: 0.6904221955098604
Epoch: 83 | Iteration number: [200/565] 35% | Training loss: 0.6902481257915497
Epoch: 83 | Iteration number: [210/565] 37% | Training loss: 0.6900986427352542
Epoch: 83 | Iteration number: [220/565] 38% | Training loss: 0.6899523469534787
Epoch: 83 | Iteration number: [230/565] 40% | Training loss: 0.6898058544034543
Epoch: 83 | Iteration number: [240/565] 42% | Training loss: 0.6896804300447305
Epoch: 83 | Iteration number: [250/565] 44% | Training loss: 0.689560485124588
Epoch: 83 | Iteration number: [260/565] 46% | Training loss: 0.6894389333633276
Epoch: 83 | Iteration number: [270/565] 47% | Training loss: 0.6893500398706507
Epoch: 83 | Iteration number: [280/565] 49% | Training loss: 0.6892598411866597
Epoch: 83 | Iteration number: [290/565] 51% | Training loss: 0.6891813950291995
Epoch: 83 | Iteration number: [300/565] 53% | Training loss: 0.6890911269187927
Epoch: 83 | Iteration number: [310/565] 54% | Training loss: 0.6890235039495652
Epoch: 83 | Iteration number: [320/565] 56% | Training loss: 0.6889503689482808
Epoch: 83 | Iteration number: [330/565] 58% | Training loss: 0.6888801905241879
Epoch: 83 | Iteration number: [340/565] 60% | Training loss: 0.6888087514568778
Epoch: 83 | Iteration number: [350/565] 61% | Training loss: 0.6887523206642696
Epoch: 83 | Iteration number: [360/565] 63% | Training loss: 0.6886988252401351
Epoch: 83 | Iteration number: [370/565] 65% | Training loss: 0.6886509875993471
Epoch: 83 | Iteration number: [380/565] 67% | Training loss: 0.6886067351228312
Epoch: 83 | Iteration number: [390/565] 69% | Training loss: 0.6885481577653151
Epoch: 83 | Iteration number: [400/565] 70% | Training loss: 0.6885070697963238
Epoch: 83 | Iteration number: [410/565] 72% | Training loss: 0.688467300083579
Epoch: 83 | Iteration number: [420/565] 74% | Training loss: 0.688427076737086
Epoch: 83 | Iteration number: [430/565] 76% | Training loss: 0.6883877590645191
Epoch: 83 | Iteration number: [440/565] 77% | Training loss: 0.6883591956712983
Epoch: 83 | Iteration number: [450/565] 79% | Training loss: 0.6883181844817268
Epoch: 83 | Iteration number: [460/565] 81% | Training loss: 0.6882874823134878
Epoch: 83 | Iteration number: [470/565] 83% | Training loss: 0.688259740459158
Epoch: 83 | Iteration number: [480/565] 84% | Training loss: 0.688221650570631
Epoch: 83 | Iteration number: [490/565] 86% | Training loss: 0.6881956139389349
Epoch: 83 | Iteration number: [500/565] 88% | Training loss: 0.6881586625576019
Epoch: 83 | Iteration number: [510/565] 90% | Training loss: 0.6881370952316359
Epoch: 83 | Iteration number: [520/565] 92% | Training loss: 0.688116383094054
Epoch: 83 | Iteration number: [530/565] 93% | Training loss: 0.688093116935694
Epoch: 83 | Iteration number: [540/565] 95% | Training loss: 0.6880562646521462
Epoch: 83 | Iteration number: [550/565] 97% | Training loss: 0.6880392743240703
Epoch: 83 | Iteration number: [560/565] 99% | Training loss: 0.688014881419284

 End of epoch: 83 | Train Loss: 0.6867915888803195 | Training Time: 88 

 End of epoch: 83 | Eval Loss: 0.689799930368151 | Evaluating Time: 6 
Epoch: 84 | Iteration number: [10/565] 1% | Training loss: 0.7557556390762329
Epoch: 84 | Iteration number: [20/565] 3% | Training loss: 0.7212939530611038
Epoch: 84 | Iteration number: [30/565] 5% | Training loss: 0.7096984446048736
Epoch: 84 | Iteration number: [40/565] 7% | Training loss: 0.7038632497191429
Epoch: 84 | Iteration number: [50/565] 8% | Training loss: 0.7004799950122833
Epoch: 84 | Iteration number: [60/565] 10% | Training loss: 0.6982288390398026
Epoch: 84 | Iteration number: [70/565] 12% | Training loss: 0.6966091232640402
Epoch: 84 | Iteration number: [80/565] 14% | Training loss: 0.6954399175941944
Epoch: 84 | Iteration number: [90/565] 15% | Training loss: 0.6944670908980899
Epoch: 84 | Iteration number: [100/565] 17% | Training loss: 0.6937205117940902
Epoch: 84 | Iteration number: [110/565] 19% | Training loss: 0.693079394643957
Epoch: 84 | Iteration number: [120/565] 21% | Training loss: 0.6925382107496262
Epoch: 84 | Iteration number: [130/565] 23% | Training loss: 0.6920635975324191
Epoch: 84 | Iteration number: [140/565] 24% | Training loss: 0.6917202630213328
Epoch: 84 | Iteration number: [150/565] 26% | Training loss: 0.6914041924476624
Epoch: 84 | Iteration number: [160/565] 28% | Training loss: 0.6911120235919952
Epoch: 84 | Iteration number: [170/565] 30% | Training loss: 0.6908694502185373
Epoch: 84 | Iteration number: [180/565] 31% | Training loss: 0.6906521111726761
Epoch: 84 | Iteration number: [190/565] 33% | Training loss: 0.6904770374298096
Epoch: 84 | Iteration number: [200/565] 35% | Training loss: 0.6903218626976013
Epoch: 84 | Iteration number: [210/565] 37% | Training loss: 0.6901393742788405
Epoch: 84 | Iteration number: [220/565] 38% | Training loss: 0.6899924299933694
Epoch: 84 | Iteration number: [230/565] 40% | Training loss: 0.6898647186548813
Epoch: 84 | Iteration number: [240/565] 42% | Training loss: 0.689718084037304
Epoch: 84 | Iteration number: [250/565] 44% | Training loss: 0.6896066601276398
Epoch: 84 | Iteration number: [260/565] 46% | Training loss: 0.6894969277656995
Epoch: 84 | Iteration number: [270/565] 47% | Training loss: 0.6894037469669625
Epoch: 84 | Iteration number: [280/565] 49% | Training loss: 0.6893126787883895
Epoch: 84 | Iteration number: [290/565] 51% | Training loss: 0.6892245080964319
Epoch: 84 | Iteration number: [300/565] 53% | Training loss: 0.6891440369685491
Epoch: 84 | Iteration number: [310/565] 54% | Training loss: 0.6890751607956425
Epoch: 84 | Iteration number: [320/565] 56% | Training loss: 0.6889865232631565
Epoch: 84 | Iteration number: [330/565] 58% | Training loss: 0.6889245576930768
Epoch: 84 | Iteration number: [340/565] 60% | Training loss: 0.6888626167002846
Epoch: 84 | Iteration number: [350/565] 61% | Training loss: 0.6888040142399924
Epoch: 84 | Iteration number: [360/565] 63% | Training loss: 0.6887517399258084
Epoch: 84 | Iteration number: [370/565] 65% | Training loss: 0.68868830558416
Epoch: 84 | Iteration number: [380/565] 67% | Training loss: 0.6886366778298428
Epoch: 84 | Iteration number: [390/565] 69% | Training loss: 0.6885873725781074
Epoch: 84 | Iteration number: [400/565] 70% | Training loss: 0.68853952601552
Epoch: 84 | Iteration number: [410/565] 72% | Training loss: 0.688491094693905
Epoch: 84 | Iteration number: [420/565] 74% | Training loss: 0.6884426833618255
Epoch: 84 | Iteration number: [430/565] 76% | Training loss: 0.6884034088877744
Epoch: 84 | Iteration number: [440/565] 77% | Training loss: 0.6883619435808875
Epoch: 84 | Iteration number: [450/565] 79% | Training loss: 0.6883227778805627
Epoch: 84 | Iteration number: [460/565] 81% | Training loss: 0.6882824453322783
Epoch: 84 | Iteration number: [470/565] 83% | Training loss: 0.6882475776875273
Epoch: 84 | Iteration number: [480/565] 84% | Training loss: 0.6882102390130361
Epoch: 84 | Iteration number: [490/565] 86% | Training loss: 0.688181712067857
Epoch: 84 | Iteration number: [500/565] 88% | Training loss: 0.6881485186815262
Epoch: 84 | Iteration number: [510/565] 90% | Training loss: 0.6881251097894182
Epoch: 84 | Iteration number: [520/565] 92% | Training loss: 0.6880917322177154
Epoch: 84 | Iteration number: [530/565] 93% | Training loss: 0.6880733449504061
Epoch: 84 | Iteration number: [540/565] 95% | Training loss: 0.6880506516606719
Epoch: 84 | Iteration number: [550/565] 97% | Training loss: 0.688029822436246
Epoch: 84 | Iteration number: [560/565] 99% | Training loss: 0.6880063607224396

 End of epoch: 84 | Train Loss: 0.6867778114512958 | Training Time: 89 

 End of epoch: 84 | Eval Loss: 0.6885413016591754 | Evaluating Time: 6 
Epoch: 85 | Iteration number: [10/565] 1% | Training loss: 0.7551356971263885
Epoch: 85 | Iteration number: [20/565] 3% | Training loss: 0.7211288213729858
Epoch: 85 | Iteration number: [30/565] 5% | Training loss: 0.7095113277435303
Epoch: 85 | Iteration number: [40/565] 7% | Training loss: 0.7038725897669792
Epoch: 85 | Iteration number: [50/565] 8% | Training loss: 0.700463707447052
Epoch: 85 | Iteration number: [60/565] 10% | Training loss: 0.6982013573249181
Epoch: 85 | Iteration number: [70/565] 12% | Training loss: 0.6965861346040453
Epoch: 85 | Iteration number: [80/565] 14% | Training loss: 0.6953797295689583
Epoch: 85 | Iteration number: [90/565] 15% | Training loss: 0.6943924804528554
Epoch: 85 | Iteration number: [100/565] 17% | Training loss: 0.6936202377080918
Epoch: 85 | Iteration number: [110/565] 19% | Training loss: 0.6930081307888031
Epoch: 85 | Iteration number: [120/565] 21% | Training loss: 0.6924817418058713
Epoch: 85 | Iteration number: [130/565] 23% | Training loss: 0.6920426923495072
Epoch: 85 | Iteration number: [140/565] 24% | Training loss: 0.6916628066982542
Epoch: 85 | Iteration number: [150/565] 26% | Training loss: 0.6913622283935547
Epoch: 85 | Iteration number: [160/565] 28% | Training loss: 0.6910647127777338
Epoch: 85 | Iteration number: [170/565] 30% | Training loss: 0.6907836353077608
Epoch: 85 | Iteration number: [180/565] 31% | Training loss: 0.6905617339743508
Epoch: 85 | Iteration number: [190/565] 33% | Training loss: 0.6903787487431576
Epoch: 85 | Iteration number: [200/565] 35% | Training loss: 0.6901629886031151
Epoch: 85 | Iteration number: [210/565] 37% | Training loss: 0.6900077337310427
Epoch: 85 | Iteration number: [220/565] 38% | Training loss: 0.6898536012931303
Epoch: 85 | Iteration number: [230/565] 40% | Training loss: 0.6897163085315539
Epoch: 85 | Iteration number: [240/565] 42% | Training loss: 0.6896177560091019
Epoch: 85 | Iteration number: [250/565] 44% | Training loss: 0.6894841015338897
Epoch: 85 | Iteration number: [260/565] 46% | Training loss: 0.6893792223471862
Epoch: 85 | Iteration number: [270/565] 47% | Training loss: 0.6892895049519009
Epoch: 85 | Iteration number: [280/565] 49% | Training loss: 0.68920117020607
Epoch: 85 | Iteration number: [290/565] 51% | Training loss: 0.6891226404699786
Epoch: 85 | Iteration number: [300/565] 53% | Training loss: 0.6890615540742874
Epoch: 85 | Iteration number: [310/565] 54% | Training loss: 0.6889881372451783
Epoch: 85 | Iteration number: [320/565] 56% | Training loss: 0.6889247180894017
Epoch: 85 | Iteration number: [330/565] 58% | Training loss: 0.6888620018959045
Epoch: 85 | Iteration number: [340/565] 60% | Training loss: 0.6887864239075605
Epoch: 85 | Iteration number: [350/565] 61% | Training loss: 0.688726554598127
Epoch: 85 | Iteration number: [360/565] 63% | Training loss: 0.6886501954661475
Epoch: 85 | Iteration number: [370/565] 65% | Training loss: 0.6886068358614638
Epoch: 85 | Iteration number: [380/565] 67% | Training loss: 0.6885525668922223
Epoch: 85 | Iteration number: [390/565] 69% | Training loss: 0.6885110254471118
Epoch: 85 | Iteration number: [400/565] 70% | Training loss: 0.6884566070139408
Epoch: 85 | Iteration number: [410/565] 72% | Training loss: 0.6884175022927727
Epoch: 85 | Iteration number: [420/565] 74% | Training loss: 0.6883816335882459
Epoch: 85 | Iteration number: [430/565] 76% | Training loss: 0.6883442723473837
Epoch: 85 | Iteration number: [440/565] 77% | Training loss: 0.6883051059462807
Epoch: 85 | Iteration number: [450/565] 79% | Training loss: 0.688276861111323
Epoch: 85 | Iteration number: [460/565] 81% | Training loss: 0.6882584897072419
Epoch: 85 | Iteration number: [470/565] 83% | Training loss: 0.6882182882187214
Epoch: 85 | Iteration number: [480/565] 84% | Training loss: 0.688188760727644
Epoch: 85 | Iteration number: [490/565] 86% | Training loss: 0.6881510828222547
Epoch: 85 | Iteration number: [500/565] 88% | Training loss: 0.6881237149238586
Epoch: 85 | Iteration number: [510/565] 90% | Training loss: 0.6880987591603223
Epoch: 85 | Iteration number: [520/565] 92% | Training loss: 0.6880708309320304
Epoch: 85 | Iteration number: [530/565] 93% | Training loss: 0.6880490075867131
Epoch: 85 | Iteration number: [540/565] 95% | Training loss: 0.6880235818801103
Epoch: 85 | Iteration number: [550/565] 97% | Training loss: 0.6880125322125175
Epoch: 85 | Iteration number: [560/565] 99% | Training loss: 0.6880003240491662

 End of epoch: 85 | Train Loss: 0.6867757844713936 | Training Time: 89 

 End of epoch: 85 | Eval Loss: 0.6898826445852008 | Evaluating Time: 5 
Epoch: 86 | Iteration number: [10/565] 1% | Training loss: 0.7557932436466217
Epoch: 86 | Iteration number: [20/565] 3% | Training loss: 0.7213372856378555
Epoch: 86 | Iteration number: [30/565] 5% | Training loss: 0.7099741995334625
Epoch: 86 | Iteration number: [40/565] 7% | Training loss: 0.7041297271847725
Epoch: 86 | Iteration number: [50/565] 8% | Training loss: 0.700616728067398
Epoch: 86 | Iteration number: [60/565] 10% | Training loss: 0.6982985317707062
Epoch: 86 | Iteration number: [70/565] 12% | Training loss: 0.696632673910686
Epoch: 86 | Iteration number: [80/565] 14% | Training loss: 0.6954401969909668
Epoch: 86 | Iteration number: [90/565] 15% | Training loss: 0.6945029510392083
Epoch: 86 | Iteration number: [100/565] 17% | Training loss: 0.693698143362999
Epoch: 86 | Iteration number: [110/565] 19% | Training loss: 0.6930494503541427
Epoch: 86 | Iteration number: [120/565] 21% | Training loss: 0.6925183529655139
Epoch: 86 | Iteration number: [130/565] 23% | Training loss: 0.6920722713837257
Epoch: 86 | Iteration number: [140/565] 24% | Training loss: 0.6916949459484645
Epoch: 86 | Iteration number: [150/565] 26% | Training loss: 0.691345409154892
Epoch: 86 | Iteration number: [160/565] 28% | Training loss: 0.6910484340041876
Epoch: 86 | Iteration number: [170/565] 30% | Training loss: 0.6907812027370228
Epoch: 86 | Iteration number: [180/565] 31% | Training loss: 0.6905577278799481
Epoch: 86 | Iteration number: [190/565] 33% | Training loss: 0.6903635517547005
Epoch: 86 | Iteration number: [200/565] 35% | Training loss: 0.6901684516668319
Epoch: 86 | Iteration number: [210/565] 37% | Training loss: 0.6900079304263705
Epoch: 86 | Iteration number: [220/565] 38% | Training loss: 0.6898412466049194
Epoch: 86 | Iteration number: [230/565] 40% | Training loss: 0.689731567579767
Epoch: 86 | Iteration number: [240/565] 42% | Training loss: 0.6896158417065938
Epoch: 86 | Iteration number: [250/565] 44% | Training loss: 0.6894950876235962
Epoch: 86 | Iteration number: [260/565] 46% | Training loss: 0.6894080079518832
Epoch: 86 | Iteration number: [270/565] 47% | Training loss: 0.6893000624797962
Epoch: 86 | Iteration number: [280/565] 49% | Training loss: 0.6892206675239971
Epoch: 86 | Iteration number: [290/565] 51% | Training loss: 0.6891366294745741
Epoch: 86 | Iteration number: [300/565] 53% | Training loss: 0.6890536403656006
Epoch: 86 | Iteration number: [310/565] 54% | Training loss: 0.6889810458306344
Epoch: 86 | Iteration number: [320/565] 56% | Training loss: 0.6889031348749995
Epoch: 86 | Iteration number: [330/565] 58% | Training loss: 0.6888328026641499
Epoch: 86 | Iteration number: [340/565] 60% | Training loss: 0.6887871274176766
Epoch: 86 | Iteration number: [350/565] 61% | Training loss: 0.6887355865750994
Epoch: 86 | Iteration number: [360/565] 63% | Training loss: 0.6886924314830039
Epoch: 86 | Iteration number: [370/565] 65% | Training loss: 0.6886420915255675
Epoch: 86 | Iteration number: [380/565] 67% | Training loss: 0.6885905474424362
Epoch: 86 | Iteration number: [390/565] 69% | Training loss: 0.6885443034844521
Epoch: 86 | Iteration number: [400/565] 70% | Training loss: 0.6884985291957855
Epoch: 86 | Iteration number: [410/565] 72% | Training loss: 0.6884581916215943
Epoch: 86 | Iteration number: [420/565] 74% | Training loss: 0.6884187753711428
Epoch: 86 | Iteration number: [430/565] 76% | Training loss: 0.6883899927139282
Epoch: 86 | Iteration number: [440/565] 77% | Training loss: 0.6883475928144022
Epoch: 86 | Iteration number: [450/565] 79% | Training loss: 0.6883162208398184
Epoch: 86 | Iteration number: [460/565] 81% | Training loss: 0.6882741968268934
Epoch: 86 | Iteration number: [470/565] 83% | Training loss: 0.6882429844521462
Epoch: 86 | Iteration number: [480/565] 84% | Training loss: 0.6882147488494714
Epoch: 86 | Iteration number: [490/565] 86% | Training loss: 0.6881780885920232
Epoch: 86 | Iteration number: [500/565] 88% | Training loss: 0.6881511261463166
Epoch: 86 | Iteration number: [510/565] 90% | Training loss: 0.688125419850443
Epoch: 86 | Iteration number: [520/565] 92% | Training loss: 0.6880929820812666
Epoch: 86 | Iteration number: [530/565] 93% | Training loss: 0.6880618058285624
Epoch: 86 | Iteration number: [540/565] 95% | Training loss: 0.6880341123651575
Epoch: 86 | Iteration number: [550/565] 97% | Training loss: 0.6880144826932387
Epoch: 86 | Iteration number: [560/565] 99% | Training loss: 0.6879959153277534

 End of epoch: 86 | Train Loss: 0.6867746252929214 | Training Time: 89 

 End of epoch: 86 | Eval Loss: 0.6895911523274013 | Evaluating Time: 6 
Epoch: 87 | Iteration number: [10/565] 1% | Training loss: 0.7552270114421844
Epoch: 87 | Iteration number: [20/565] 3% | Training loss: 0.7209501326084137
Epoch: 87 | Iteration number: [30/565] 5% | Training loss: 0.7094135999679565
Epoch: 87 | Iteration number: [40/565] 7% | Training loss: 0.7036913186311722
Epoch: 87 | Iteration number: [50/565] 8% | Training loss: 0.7003385531902313
Epoch: 87 | Iteration number: [60/565] 10% | Training loss: 0.6980242937803268
Epoch: 87 | Iteration number: [70/565] 12% | Training loss: 0.6964018940925598
Epoch: 87 | Iteration number: [80/565] 14% | Training loss: 0.6951596803963185
Epoch: 87 | Iteration number: [90/565] 15% | Training loss: 0.694212344619963
Epoch: 87 | Iteration number: [100/565] 17% | Training loss: 0.693441361784935
Epoch: 87 | Iteration number: [110/565] 19% | Training loss: 0.6928384255279194
Epoch: 87 | Iteration number: [120/565] 21% | Training loss: 0.6923258418838183
Epoch: 87 | Iteration number: [130/565] 23% | Training loss: 0.6918888073701125
Epoch: 87 | Iteration number: [140/565] 24% | Training loss: 0.6915551888091224
Epoch: 87 | Iteration number: [150/565] 26% | Training loss: 0.6912414566675822
Epoch: 87 | Iteration number: [160/565] 28% | Training loss: 0.6909839190542698
Epoch: 87 | Iteration number: [170/565] 30% | Training loss: 0.6907363649676828
Epoch: 87 | Iteration number: [180/565] 31% | Training loss: 0.6905084878206253
Epoch: 87 | Iteration number: [190/565] 33% | Training loss: 0.6903477822479449
Epoch: 87 | Iteration number: [200/565] 35% | Training loss: 0.6901712575554848
Epoch: 87 | Iteration number: [210/565] 37% | Training loss: 0.6900143995171502
Epoch: 87 | Iteration number: [220/565] 38% | Training loss: 0.6898647936907681
Epoch: 87 | Iteration number: [230/565] 40% | Training loss: 0.6897287747134333
Epoch: 87 | Iteration number: [240/565] 42% | Training loss: 0.6896095591286818
Epoch: 87 | Iteration number: [250/565] 44% | Training loss: 0.6894959647655488
Epoch: 87 | Iteration number: [260/565] 46% | Training loss: 0.689397058578638
Epoch: 87 | Iteration number: [270/565] 47% | Training loss: 0.6893006329183226
Epoch: 87 | Iteration number: [280/565] 49% | Training loss: 0.689220811000892
Epoch: 87 | Iteration number: [290/565] 51% | Training loss: 0.6891472658206677
Epoch: 87 | Iteration number: [300/565] 53% | Training loss: 0.6890708227952321
Epoch: 87 | Iteration number: [310/565] 54% | Training loss: 0.6889987959015754
Epoch: 87 | Iteration number: [320/565] 56% | Training loss: 0.6889317007735372
Epoch: 87 | Iteration number: [330/565] 58% | Training loss: 0.688861012097561
Epoch: 87 | Iteration number: [340/565] 60% | Training loss: 0.6888045673861223
Epoch: 87 | Iteration number: [350/565] 61% | Training loss: 0.6887474484103067
Epoch: 87 | Iteration number: [360/565] 63% | Training loss: 0.6886990538901753
Epoch: 87 | Iteration number: [370/565] 65% | Training loss: 0.6886339569413984
Epoch: 87 | Iteration number: [380/565] 67% | Training loss: 0.6885769994635331
Epoch: 87 | Iteration number: [390/565] 69% | Training loss: 0.6885235651945456
Epoch: 87 | Iteration number: [400/565] 70% | Training loss: 0.6884783643484116
Epoch: 87 | Iteration number: [410/565] 72% | Training loss: 0.6884385635213154
Epoch: 87 | Iteration number: [420/565] 74% | Training loss: 0.6883881551878793
Epoch: 87 | Iteration number: [430/565] 76% | Training loss: 0.6883552452852559
Epoch: 87 | Iteration number: [440/565] 77% | Training loss: 0.6883224365386096
Epoch: 87 | Iteration number: [450/565] 79% | Training loss: 0.6882960957951015
Epoch: 87 | Iteration number: [460/565] 81% | Training loss: 0.6882617254620013
Epoch: 87 | Iteration number: [470/565] 83% | Training loss: 0.6882237477505461
Epoch: 87 | Iteration number: [480/565] 84% | Training loss: 0.6881896773974101
Epoch: 87 | Iteration number: [490/565] 86% | Training loss: 0.6881568779750746
Epoch: 87 | Iteration number: [500/565] 88% | Training loss: 0.6881273493766785
Epoch: 87 | Iteration number: [510/565] 90% | Training loss: 0.6880999113999161
Epoch: 87 | Iteration number: [520/565] 92% | Training loss: 0.6880760266230657
Epoch: 87 | Iteration number: [530/565] 93% | Training loss: 0.6880517789777719
Epoch: 87 | Iteration number: [540/565] 95% | Training loss: 0.6880276345544392
Epoch: 87 | Iteration number: [550/565] 97% | Training loss: 0.6880118348381736
Epoch: 87 | Iteration number: [560/565] 99% | Training loss: 0.6879919450197901

 End of epoch: 87 | Train Loss: 0.68676359442483 | Training Time: 88 

 End of epoch: 87 | Eval Loss: 0.689456215926579 | Evaluating Time: 6 
Epoch: 88 | Iteration number: [10/565] 1% | Training loss: 0.7555894494056702
Epoch: 88 | Iteration number: [20/565] 3% | Training loss: 0.7211220979690551
Epoch: 88 | Iteration number: [30/565] 5% | Training loss: 0.7095783889293671
Epoch: 88 | Iteration number: [40/565] 7% | Training loss: 0.7038792207837105
Epoch: 88 | Iteration number: [50/565] 8% | Training loss: 0.7003989219665527
Epoch: 88 | Iteration number: [60/565] 10% | Training loss: 0.6982053567965826
Epoch: 88 | Iteration number: [70/565] 12% | Training loss: 0.696612389598574
Epoch: 88 | Iteration number: [80/565] 14% | Training loss: 0.6953608192503452
Epoch: 88 | Iteration number: [90/565] 15% | Training loss: 0.6943625940216912
Epoch: 88 | Iteration number: [100/565] 17% | Training loss: 0.6936402803659439
Epoch: 88 | Iteration number: [110/565] 19% | Training loss: 0.6930342435836792
Epoch: 88 | Iteration number: [120/565] 21% | Training loss: 0.6924678097168605
Epoch: 88 | Iteration number: [130/565] 23% | Training loss: 0.6920483813836025
Epoch: 88 | Iteration number: [140/565] 24% | Training loss: 0.691676180277552
Epoch: 88 | Iteration number: [150/565] 26% | Training loss: 0.6913384850819906
Epoch: 88 | Iteration number: [160/565] 28% | Training loss: 0.6910442668944597
Epoch: 88 | Iteration number: [170/565] 30% | Training loss: 0.6907929557211259
Epoch: 88 | Iteration number: [180/565] 31% | Training loss: 0.6905777431196637
Epoch: 88 | Iteration number: [190/565] 33% | Training loss: 0.690368600268113
Epoch: 88 | Iteration number: [200/565] 35% | Training loss: 0.6901961177587509
Epoch: 88 | Iteration number: [210/565] 37% | Training loss: 0.690044953709557
Epoch: 88 | Iteration number: [220/565] 38% | Training loss: 0.6899042980237441
Epoch: 88 | Iteration number: [230/565] 40% | Training loss: 0.6897692776244619
Epoch: 88 | Iteration number: [240/565] 42% | Training loss: 0.689640632023414
Epoch: 88 | Iteration number: [250/565] 44% | Training loss: 0.6895288689136505
Epoch: 88 | Iteration number: [260/565] 46% | Training loss: 0.689422305730673
Epoch: 88 | Iteration number: [270/565] 47% | Training loss: 0.6893177065584395
Epoch: 88 | Iteration number: [280/565] 49% | Training loss: 0.6892269837004797
Epoch: 88 | Iteration number: [290/565] 51% | Training loss: 0.6891465968099134
Epoch: 88 | Iteration number: [300/565] 53% | Training loss: 0.6890679989258448
Epoch: 88 | Iteration number: [310/565] 54% | Training loss: 0.6889807966447645
Epoch: 88 | Iteration number: [320/565] 56% | Training loss: 0.6888967886567116
Epoch: 88 | Iteration number: [330/565] 58% | Training loss: 0.6888327051292766
Epoch: 88 | Iteration number: [340/565] 60% | Training loss: 0.6887681077508365
Epoch: 88 | Iteration number: [350/565] 61% | Training loss: 0.6887068586690085
Epoch: 88 | Iteration number: [360/565] 63% | Training loss: 0.6886500174800555
Epoch: 88 | Iteration number: [370/565] 65% | Training loss: 0.6886024384885221
Epoch: 88 | Iteration number: [380/565] 67% | Training loss: 0.6885728155311786
Epoch: 88 | Iteration number: [390/565] 69% | Training loss: 0.6885222360109672
Epoch: 88 | Iteration number: [400/565] 70% | Training loss: 0.6884880545735359
Epoch: 88 | Iteration number: [410/565] 72% | Training loss: 0.6884551542561229
Epoch: 88 | Iteration number: [420/565] 74% | Training loss: 0.6884220148835863
Epoch: 88 | Iteration number: [430/565] 76% | Training loss: 0.6883831011694531
Epoch: 88 | Iteration number: [440/565] 77% | Training loss: 0.6883468562906438
Epoch: 88 | Iteration number: [450/565] 79% | Training loss: 0.6883068896664514
Epoch: 88 | Iteration number: [460/565] 81% | Training loss: 0.688278296460276
Epoch: 88 | Iteration number: [470/565] 83% | Training loss: 0.6882398762601487
Epoch: 88 | Iteration number: [480/565] 84% | Training loss: 0.6882141673316559
Epoch: 88 | Iteration number: [490/565] 86% | Training loss: 0.6881707965111246
Epoch: 88 | Iteration number: [500/565] 88% | Training loss: 0.6881377675533294
Epoch: 88 | Iteration number: [510/565] 90% | Training loss: 0.6881127803933387
Epoch: 88 | Iteration number: [520/565] 92% | Training loss: 0.6880826935172081
Epoch: 88 | Iteration number: [530/565] 93% | Training loss: 0.6880517464763714
Epoch: 88 | Iteration number: [540/565] 95% | Training loss: 0.688031887014707
Epoch: 88 | Iteration number: [550/565] 97% | Training loss: 0.6880066788196564
Epoch: 88 | Iteration number: [560/565] 99% | Training loss: 0.6879883851323809

 End of epoch: 88 | Train Loss: 0.6867648359948555 | Training Time: 89 

 End of epoch: 88 | Eval Loss: 0.6897118857928685 | Evaluating Time: 6 
Epoch: 89 | Iteration number: [10/565] 1% | Training loss: 0.7553648948669434
Epoch: 89 | Iteration number: [20/565] 3% | Training loss: 0.721002733707428
Epoch: 89 | Iteration number: [30/565] 5% | Training loss: 0.7097891648610433
Epoch: 89 | Iteration number: [40/565] 7% | Training loss: 0.703996330499649
Epoch: 89 | Iteration number: [50/565] 8% | Training loss: 0.7005141532421112
Epoch: 89 | Iteration number: [60/565] 10% | Training loss: 0.6981921980778376
Epoch: 89 | Iteration number: [70/565] 12% | Training loss: 0.6965587096554893
Epoch: 89 | Iteration number: [80/565] 14% | Training loss: 0.6953361734747887
Epoch: 89 | Iteration number: [90/565] 15% | Training loss: 0.6944398807154761
Epoch: 89 | Iteration number: [100/565] 17% | Training loss: 0.6937163478136062
Epoch: 89 | Iteration number: [110/565] 19% | Training loss: 0.6930437754500997
Epoch: 89 | Iteration number: [120/565] 21% | Training loss: 0.6924659391244252
Epoch: 89 | Iteration number: [130/565] 23% | Training loss: 0.69205473615573
Epoch: 89 | Iteration number: [140/565] 24% | Training loss: 0.6916871807404927
Epoch: 89 | Iteration number: [150/565] 26% | Training loss: 0.6913570813337961
Epoch: 89 | Iteration number: [160/565] 28% | Training loss: 0.6910705894231797
Epoch: 89 | Iteration number: [170/565] 30% | Training loss: 0.6908142061794506
Epoch: 89 | Iteration number: [180/565] 31% | Training loss: 0.6905853394005034
Epoch: 89 | Iteration number: [190/565] 33% | Training loss: 0.6903694287726754
Epoch: 89 | Iteration number: [200/565] 35% | Training loss: 0.6901758220791817
Epoch: 89 | Iteration number: [210/565] 37% | Training loss: 0.6900292972723643
Epoch: 89 | Iteration number: [220/565] 38% | Training loss: 0.6898896442218261
Epoch: 89 | Iteration number: [230/565] 40% | Training loss: 0.6897353063458982
Epoch: 89 | Iteration number: [240/565] 42% | Training loss: 0.6896125172575315
Epoch: 89 | Iteration number: [250/565] 44% | Training loss: 0.689502949476242
Epoch: 89 | Iteration number: [260/565] 46% | Training loss: 0.689394309429022
Epoch: 89 | Iteration number: [270/565] 47% | Training loss: 0.6892951870406115
Epoch: 89 | Iteration number: [280/565] 49% | Training loss: 0.6892197106565748
Epoch: 89 | Iteration number: [290/565] 51% | Training loss: 0.6891365112929508
Epoch: 89 | Iteration number: [300/565] 53% | Training loss: 0.6890558300415675
Epoch: 89 | Iteration number: [310/565] 54% | Training loss: 0.6889854469606953
Epoch: 89 | Iteration number: [320/565] 56% | Training loss: 0.6889093177393079
Epoch: 89 | Iteration number: [330/565] 58% | Training loss: 0.6888496879375342
Epoch: 89 | Iteration number: [340/565] 60% | Training loss: 0.6887843417770723
Epoch: 89 | Iteration number: [350/565] 61% | Training loss: 0.6887197613716125
Epoch: 89 | Iteration number: [360/565] 63% | Training loss: 0.68866785251432
Epoch: 89 | Iteration number: [370/565] 65% | Training loss: 0.6886128572193352
Epoch: 89 | Iteration number: [380/565] 67% | Training loss: 0.6885673579416777
Epoch: 89 | Iteration number: [390/565] 69% | Training loss: 0.6885263690581689
Epoch: 89 | Iteration number: [400/565] 70% | Training loss: 0.6884766402840614
Epoch: 89 | Iteration number: [410/565] 72% | Training loss: 0.6884333164226718
Epoch: 89 | Iteration number: [420/565] 74% | Training loss: 0.6883953901983443
Epoch: 89 | Iteration number: [430/565] 76% | Training loss: 0.6883645090945931
Epoch: 89 | Iteration number: [440/565] 77% | Training loss: 0.6883223338560625
Epoch: 89 | Iteration number: [450/565] 79% | Training loss: 0.6882902379830679
Epoch: 89 | Iteration number: [460/565] 81% | Training loss: 0.6882609005855478
Epoch: 89 | Iteration number: [470/565] 83% | Training loss: 0.6882376942228764
Epoch: 89 | Iteration number: [480/565] 84% | Training loss: 0.6882091375688711
Epoch: 89 | Iteration number: [490/565] 86% | Training loss: 0.6881764857136473
Epoch: 89 | Iteration number: [500/565] 88% | Training loss: 0.6881358143091202
Epoch: 89 | Iteration number: [510/565] 90% | Training loss: 0.6881068180589115
Epoch: 89 | Iteration number: [520/565] 92% | Training loss: 0.6880796855458846
Epoch: 89 | Iteration number: [530/565] 93% | Training loss: 0.688063698557188
Epoch: 89 | Iteration number: [540/565] 95% | Training loss: 0.6880409624841478
Epoch: 89 | Iteration number: [550/565] 97% | Training loss: 0.6880145787109028
Epoch: 89 | Iteration number: [560/565] 99% | Training loss: 0.6879926728350776

 End of epoch: 89 | Train Loss: 0.6867698645169756 | Training Time: 89 

 End of epoch: 89 | Eval Loss: 0.6897202048982892 | Evaluating Time: 5 
Epoch: 90 | Iteration number: [10/565] 1% | Training loss: 0.7553032755851745
Epoch: 90 | Iteration number: [20/565] 3% | Training loss: 0.7210754424333572
Epoch: 90 | Iteration number: [30/565] 5% | Training loss: 0.7097190479437511
Epoch: 90 | Iteration number: [40/565] 7% | Training loss: 0.7039487853646278
Epoch: 90 | Iteration number: [50/565] 8% | Training loss: 0.7005056941509247
Epoch: 90 | Iteration number: [60/565] 10% | Training loss: 0.698257694641749
Epoch: 90 | Iteration number: [70/565] 12% | Training loss: 0.6965122044086456
Epoch: 90 | Iteration number: [80/565] 14% | Training loss: 0.6952369704842567
Epoch: 90 | Iteration number: [90/565] 15% | Training loss: 0.6942959328492483
Epoch: 90 | Iteration number: [100/565] 17% | Training loss: 0.6935415023565292
Epoch: 90 | Iteration number: [110/565] 19% | Training loss: 0.6929000339724801
Epoch: 90 | Iteration number: [120/565] 21% | Training loss: 0.6923871879776319
Epoch: 90 | Iteration number: [130/565] 23% | Training loss: 0.6919584388916309
Epoch: 90 | Iteration number: [140/565] 24% | Training loss: 0.6916142983095986
Epoch: 90 | Iteration number: [150/565] 26% | Training loss: 0.6912741514046987
Epoch: 90 | Iteration number: [160/565] 28% | Training loss: 0.6909995391964913
Epoch: 90 | Iteration number: [170/565] 30% | Training loss: 0.6907558612963732
Epoch: 90 | Iteration number: [180/565] 31% | Training loss: 0.6905346360471514
Epoch: 90 | Iteration number: [190/565] 33% | Training loss: 0.6903347134590149
Epoch: 90 | Iteration number: [200/565] 35% | Training loss: 0.6901453605294228
Epoch: 90 | Iteration number: [210/565] 37% | Training loss: 0.6899910325095767
Epoch: 90 | Iteration number: [220/565] 38% | Training loss: 0.6898547267371958
Epoch: 90 | Iteration number: [230/565] 40% | Training loss: 0.6896915140359298
Epoch: 90 | Iteration number: [240/565] 42% | Training loss: 0.6895776882767677
Epoch: 90 | Iteration number: [250/565] 44% | Training loss: 0.6894756579399108
Epoch: 90 | Iteration number: [260/565] 46% | Training loss: 0.6893781691789627
Epoch: 90 | Iteration number: [270/565] 47% | Training loss: 0.6892872225355219
Epoch: 90 | Iteration number: [280/565] 49% | Training loss: 0.6892191754920142
Epoch: 90 | Iteration number: [290/565] 51% | Training loss: 0.6891438463638568
Epoch: 90 | Iteration number: [300/565] 53% | Training loss: 0.6890706185499827
Epoch: 90 | Iteration number: [310/565] 54% | Training loss: 0.6890073137898599
Epoch: 90 | Iteration number: [320/565] 56% | Training loss: 0.6889384601265192
Epoch: 90 | Iteration number: [330/565] 58% | Training loss: 0.6888663515900121
Epoch: 90 | Iteration number: [340/565] 60% | Training loss: 0.6887925002504798
Epoch: 90 | Iteration number: [350/565] 61% | Training loss: 0.6887350232260567
Epoch: 90 | Iteration number: [360/565] 63% | Training loss: 0.6886930369668537
Epoch: 90 | Iteration number: [370/565] 65% | Training loss: 0.6886396016623523
Epoch: 90 | Iteration number: [380/565] 67% | Training loss: 0.688570898771286
Epoch: 90 | Iteration number: [390/565] 69% | Training loss: 0.6885308988583394
Epoch: 90 | Iteration number: [400/565] 70% | Training loss: 0.6884714995324611
Epoch: 90 | Iteration number: [410/565] 72% | Training loss: 0.688438005999821
Epoch: 90 | Iteration number: [420/565] 74% | Training loss: 0.6883929706755139
Epoch: 90 | Iteration number: [430/565] 76% | Training loss: 0.6883629947207694
Epoch: 90 | Iteration number: [440/565] 77% | Training loss: 0.6883232669396834
Epoch: 90 | Iteration number: [450/565] 79% | Training loss: 0.6882963053385417
Epoch: 90 | Iteration number: [460/565] 81% | Training loss: 0.6882619012957034
Epoch: 90 | Iteration number: [470/565] 83% | Training loss: 0.6882291743095885
Epoch: 90 | Iteration number: [480/565] 84% | Training loss: 0.6882006343454122
Epoch: 90 | Iteration number: [490/565] 86% | Training loss: 0.6881753926374474
Epoch: 90 | Iteration number: [500/565] 88% | Training loss: 0.6881442056894302
Epoch: 90 | Iteration number: [510/565] 90% | Training loss: 0.6881215723121867
Epoch: 90 | Iteration number: [520/565] 92% | Training loss: 0.6880901258725386
Epoch: 90 | Iteration number: [530/565] 93% | Training loss: 0.6880566711695689
Epoch: 90 | Iteration number: [540/565] 95% | Training loss: 0.6880450661535616
Epoch: 90 | Iteration number: [550/565] 97% | Training loss: 0.6880245734344829
Epoch: 90 | Iteration number: [560/565] 99% | Training loss: 0.6879948148769992

 End of epoch: 90 | Train Loss: 0.6867673416053299 | Training Time: 89 

 End of epoch: 90 | Eval Loss: 0.6896785497665405 | Evaluating Time: 6 
Epoch: 91 | Iteration number: [10/565] 1% | Training loss: 0.755393773317337
Epoch: 91 | Iteration number: [20/565] 3% | Training loss: 0.720983624458313
Epoch: 91 | Iteration number: [30/565] 5% | Training loss: 0.7096601307392121
Epoch: 91 | Iteration number: [40/565] 7% | Training loss: 0.7038428813219071
Epoch: 91 | Iteration number: [50/565] 8% | Training loss: 0.7003063666820526
Epoch: 91 | Iteration number: [60/565] 10% | Training loss: 0.6980296969413757
Epoch: 91 | Iteration number: [70/565] 12% | Training loss: 0.6964889713696071
Epoch: 91 | Iteration number: [80/565] 14% | Training loss: 0.6952494271099567
Epoch: 91 | Iteration number: [90/565] 15% | Training loss: 0.6943771998087566
Epoch: 91 | Iteration number: [100/565] 17% | Training loss: 0.6935961025953293
Epoch: 91 | Iteration number: [110/565] 19% | Training loss: 0.6929548501968383
Epoch: 91 | Iteration number: [120/565] 21% | Training loss: 0.6924540494879087
Epoch: 91 | Iteration number: [130/565] 23% | Training loss: 0.6920191173370068
Epoch: 91 | Iteration number: [140/565] 24% | Training loss: 0.6916389043842043
Epoch: 91 | Iteration number: [150/565] 26% | Training loss: 0.6912917613983154
Epoch: 91 | Iteration number: [160/565] 28% | Training loss: 0.6910184603184462
Epoch: 91 | Iteration number: [170/565] 30% | Training loss: 0.6907721358187059
Epoch: 91 | Iteration number: [180/565] 31% | Training loss: 0.6905338943004609
Epoch: 91 | Iteration number: [190/565] 33% | Training loss: 0.6903290369008717
Epoch: 91 | Iteration number: [200/565] 35% | Training loss: 0.6901415780186653
Epoch: 91 | Iteration number: [210/565] 37% | Training loss: 0.6899599404562087
Epoch: 91 | Iteration number: [220/565] 38% | Training loss: 0.6898203627629713
Epoch: 91 | Iteration number: [230/565] 40% | Training loss: 0.6897055174993432
Epoch: 91 | Iteration number: [240/565] 42% | Training loss: 0.6895789958536624
Epoch: 91 | Iteration number: [250/565] 44% | Training loss: 0.6894455082416534
Epoch: 91 | Iteration number: [260/565] 46% | Training loss: 0.6893493826572712
Epoch: 91 | Iteration number: [270/565] 47% | Training loss: 0.6892519425462793
Epoch: 91 | Iteration number: [280/565] 49% | Training loss: 0.6891691910369055
Epoch: 91 | Iteration number: [290/565] 51% | Training loss: 0.6890728697694581
Epoch: 91 | Iteration number: [300/565] 53% | Training loss: 0.6890014525254567
Epoch: 91 | Iteration number: [310/565] 54% | Training loss: 0.6889206624800159
Epoch: 91 | Iteration number: [320/565] 56% | Training loss: 0.6888637563213706
Epoch: 91 | Iteration number: [330/565] 58% | Training loss: 0.688809935613112
Epoch: 91 | Iteration number: [340/565] 60% | Training loss: 0.6887534713043886
Epoch: 91 | Iteration number: [350/565] 61% | Training loss: 0.6887044824872698
Epoch: 91 | Iteration number: [360/565] 63% | Training loss: 0.6886494893166754
Epoch: 91 | Iteration number: [370/565] 65% | Training loss: 0.6886013957294258
Epoch: 91 | Iteration number: [380/565] 67% | Training loss: 0.6885639501245399
Epoch: 91 | Iteration number: [390/565] 69% | Training loss: 0.68851151237121
Epoch: 91 | Iteration number: [400/565] 70% | Training loss: 0.688467857837677
Epoch: 91 | Iteration number: [410/565] 72% | Training loss: 0.6884388723024508
Epoch: 91 | Iteration number: [420/565] 74% | Training loss: 0.6883913010358811
Epoch: 91 | Iteration number: [430/565] 76% | Training loss: 0.68834444104239
Epoch: 91 | Iteration number: [440/565] 77% | Training loss: 0.6883069046519019
Epoch: 91 | Iteration number: [450/565] 79% | Training loss: 0.6882775282859802
Epoch: 91 | Iteration number: [460/565] 81% | Training loss: 0.6882418492565985
Epoch: 91 | Iteration number: [470/565] 83% | Training loss: 0.6882160417577053
Epoch: 91 | Iteration number: [480/565] 84% | Training loss: 0.6881856088836987
Epoch: 91 | Iteration number: [490/565] 86% | Training loss: 0.6881545497446644
Epoch: 91 | Iteration number: [500/565] 88% | Training loss: 0.6881280827522278
Epoch: 91 | Iteration number: [510/565] 90% | Training loss: 0.688107876216664
Epoch: 91 | Iteration number: [520/565] 92% | Training loss: 0.6880823785295853
Epoch: 91 | Iteration number: [530/565] 93% | Training loss: 0.6880604274992673
Epoch: 91 | Iteration number: [540/565] 95% | Training loss: 0.6880358889147088
Epoch: 91 | Iteration number: [550/565] 97% | Training loss: 0.6880139447342266
Epoch: 91 | Iteration number: [560/565] 99% | Training loss: 0.6879898421466351

 End of epoch: 91 | Train Loss: 0.6867640295914844 | Training Time: 89 

 End of epoch: 91 | Eval Loss: 0.6888368810926165 | Evaluating Time: 6 
Epoch: 92 | Iteration number: [10/565] 1% | Training loss: 0.7553177237510681
Epoch: 92 | Iteration number: [20/565] 3% | Training loss: 0.7209238886833191
Epoch: 92 | Iteration number: [30/565] 5% | Training loss: 0.7096386869748433
Epoch: 92 | Iteration number: [40/565] 7% | Training loss: 0.7039455562829972
Epoch: 92 | Iteration number: [50/565] 8% | Training loss: 0.7005167901515961
Epoch: 92 | Iteration number: [60/565] 10% | Training loss: 0.6982141395409902
Epoch: 92 | Iteration number: [70/565] 12% | Training loss: 0.6965140087263925
Epoch: 92 | Iteration number: [80/565] 14% | Training loss: 0.6952231265604496
Epoch: 92 | Iteration number: [90/565] 15% | Training loss: 0.6942567368348439
Epoch: 92 | Iteration number: [100/565] 17% | Training loss: 0.6935241335630417
Epoch: 92 | Iteration number: [110/565] 19% | Training loss: 0.6929820510474118
Epoch: 92 | Iteration number: [120/565] 21% | Training loss: 0.6924425542354584
Epoch: 92 | Iteration number: [130/565] 23% | Training loss: 0.6920349538326264
Epoch: 92 | Iteration number: [140/565] 24% | Training loss: 0.6916676057236535
Epoch: 92 | Iteration number: [150/565] 26% | Training loss: 0.6913705269495646
Epoch: 92 | Iteration number: [160/565] 28% | Training loss: 0.6910890623927116
Epoch: 92 | Iteration number: [170/565] 30% | Training loss: 0.6908328196581672
Epoch: 92 | Iteration number: [180/565] 31% | Training loss: 0.6906297935379876
Epoch: 92 | Iteration number: [190/565] 33% | Training loss: 0.6904124200344086
Epoch: 92 | Iteration number: [200/565] 35% | Training loss: 0.6902088835835457
Epoch: 92 | Iteration number: [210/565] 37% | Training loss: 0.6900477520057133
Epoch: 92 | Iteration number: [220/565] 38% | Training loss: 0.6898834613236514
Epoch: 92 | Iteration number: [230/565] 40% | Training loss: 0.6897527342257292
Epoch: 92 | Iteration number: [240/565] 42% | Training loss: 0.6896269999444484
Epoch: 92 | Iteration number: [250/565] 44% | Training loss: 0.6894975914955139
Epoch: 92 | Iteration number: [260/565] 46% | Training loss: 0.6893695230667408
Epoch: 92 | Iteration number: [270/565] 47% | Training loss: 0.6892823342923765
Epoch: 92 | Iteration number: [280/565] 49% | Training loss: 0.6891861096024513
Epoch: 92 | Iteration number: [290/565] 51% | Training loss: 0.6890985018220441
Epoch: 92 | Iteration number: [300/565] 53% | Training loss: 0.6890332835912705
Epoch: 92 | Iteration number: [310/565] 54% | Training loss: 0.6889686669072798
Epoch: 92 | Iteration number: [320/565] 56% | Training loss: 0.6889147756621241
Epoch: 92 | Iteration number: [330/565] 58% | Training loss: 0.6888509587808089
Epoch: 92 | Iteration number: [340/565] 60% | Training loss: 0.688793782100958
Epoch: 92 | Iteration number: [350/565] 61% | Training loss: 0.6887353798321315
Epoch: 92 | Iteration number: [360/565] 63% | Training loss: 0.68867110957702
Epoch: 92 | Iteration number: [370/565] 65% | Training loss: 0.688615369313472
Epoch: 92 | Iteration number: [380/565] 67% | Training loss: 0.6885575554872814
Epoch: 92 | Iteration number: [390/565] 69% | Training loss: 0.6885100713142982
Epoch: 92 | Iteration number: [400/565] 70% | Training loss: 0.6884647937119007
Epoch: 92 | Iteration number: [410/565] 72% | Training loss: 0.688423638809018
Epoch: 92 | Iteration number: [420/565] 74% | Training loss: 0.688380657349314
Epoch: 92 | Iteration number: [430/565] 76% | Training loss: 0.688355075758557
Epoch: 92 | Iteration number: [440/565] 77% | Training loss: 0.6883133099837737
Epoch: 92 | Iteration number: [450/565] 79% | Training loss: 0.6882719851864709
Epoch: 92 | Iteration number: [460/565] 81% | Training loss: 0.688243361270946
Epoch: 92 | Iteration number: [470/565] 83% | Training loss: 0.6882081725495927
Epoch: 92 | Iteration number: [480/565] 84% | Training loss: 0.6881815992295742
Epoch: 92 | Iteration number: [490/565] 86% | Training loss: 0.6881594717502594
Epoch: 92 | Iteration number: [500/565] 88% | Training loss: 0.6881304582357407
Epoch: 92 | Iteration number: [510/565] 90% | Training loss: 0.6881046458786609
Epoch: 92 | Iteration number: [520/565] 92% | Training loss: 0.6880807301172843
Epoch: 92 | Iteration number: [530/565] 93% | Training loss: 0.688063948334388
Epoch: 92 | Iteration number: [540/565] 95% | Training loss: 0.6880500243769752
Epoch: 92 | Iteration number: [550/565] 97% | Training loss: 0.6880166079781272
Epoch: 92 | Iteration number: [560/565] 99% | Training loss: 0.6879917400223868

 End of epoch: 92 | Train Loss: 0.686764523307834 | Training Time: 88 

 End of epoch: 92 | Eval Loss: 0.689329172883715 | Evaluating Time: 6 
Epoch: 93 | Iteration number: [10/565] 1% | Training loss: 0.7556586861610413
Epoch: 93 | Iteration number: [20/565] 3% | Training loss: 0.7212809950113297
Epoch: 93 | Iteration number: [30/565] 5% | Training loss: 0.7099263230959575
Epoch: 93 | Iteration number: [40/565] 7% | Training loss: 0.7040629804134368
Epoch: 93 | Iteration number: [50/565] 8% | Training loss: 0.7005950462818146
Epoch: 93 | Iteration number: [60/565] 10% | Training loss: 0.698288643360138
Epoch: 93 | Iteration number: [70/565] 12% | Training loss: 0.6966106261525835
Epoch: 93 | Iteration number: [80/565] 14% | Training loss: 0.6953554473817348
Epoch: 93 | Iteration number: [90/565] 15% | Training loss: 0.6943766176700592
Epoch: 93 | Iteration number: [100/565] 17% | Training loss: 0.6936076718568802
Epoch: 93 | Iteration number: [110/565] 19% | Training loss: 0.6930200858549638
Epoch: 93 | Iteration number: [120/565] 21% | Training loss: 0.692502316335837
Epoch: 93 | Iteration number: [130/565] 23% | Training loss: 0.6920406960524046
Epoch: 93 | Iteration number: [140/565] 24% | Training loss: 0.6916526594332286
Epoch: 93 | Iteration number: [150/565] 26% | Training loss: 0.6913283312320709
Epoch: 93 | Iteration number: [160/565] 28% | Training loss: 0.691036107391119
Epoch: 93 | Iteration number: [170/565] 30% | Training loss: 0.6907810624907998
Epoch: 93 | Iteration number: [180/565] 31% | Training loss: 0.6905665321482553
Epoch: 93 | Iteration number: [190/565] 33% | Training loss: 0.6903654198897512
Epoch: 93 | Iteration number: [200/565] 35% | Training loss: 0.690193342268467
Epoch: 93 | Iteration number: [210/565] 37% | Training loss: 0.6900508585430327
Epoch: 93 | Iteration number: [220/565] 38% | Training loss: 0.6898957393386147
Epoch: 93 | Iteration number: [230/565] 40% | Training loss: 0.6897580618443696
Epoch: 93 | Iteration number: [240/565] 42% | Training loss: 0.6896448378761609
Epoch: 93 | Iteration number: [250/565] 44% | Training loss: 0.6895307061672211
Epoch: 93 | Iteration number: [260/565] 46% | Training loss: 0.6894144716171118
Epoch: 93 | Iteration number: [270/565] 47% | Training loss: 0.6893059165389449
Epoch: 93 | Iteration number: [280/565] 49% | Training loss: 0.6892011061310768
Epoch: 93 | Iteration number: [290/565] 51% | Training loss: 0.6891135275363922
Epoch: 93 | Iteration number: [300/565] 53% | Training loss: 0.689046685496966
Epoch: 93 | Iteration number: [310/565] 54% | Training loss: 0.6889806501327023
Epoch: 93 | Iteration number: [320/565] 56% | Training loss: 0.6889040160924196
Epoch: 93 | Iteration number: [330/565] 58% | Training loss: 0.6888462467627092
Epoch: 93 | Iteration number: [340/565] 60% | Training loss: 0.6887742068837671
Epoch: 93 | Iteration number: [350/565] 61% | Training loss: 0.6887287986278534
Epoch: 93 | Iteration number: [360/565] 63% | Training loss: 0.6886656670106782
Epoch: 93 | Iteration number: [370/565] 65% | Training loss: 0.6886167974085421
Epoch: 93 | Iteration number: [380/565] 67% | Training loss: 0.6885627771678724
Epoch: 93 | Iteration number: [390/565] 69% | Training loss: 0.6885171836767441
Epoch: 93 | Iteration number: [400/565] 70% | Training loss: 0.6884711064398289
Epoch: 93 | Iteration number: [410/565] 72% | Training loss: 0.6884345916713156
Epoch: 93 | Iteration number: [420/565] 74% | Training loss: 0.688396482240586
Epoch: 93 | Iteration number: [430/565] 76% | Training loss: 0.6883554351884266
Epoch: 93 | Iteration number: [440/565] 77% | Training loss: 0.6883106592026624
Epoch: 93 | Iteration number: [450/565] 79% | Training loss: 0.6882833312617408
Epoch: 93 | Iteration number: [460/565] 81% | Training loss: 0.6882563835900762
Epoch: 93 | Iteration number: [470/565] 83% | Training loss: 0.6882134804066191
Epoch: 93 | Iteration number: [480/565] 84% | Training loss: 0.688183423380057
Epoch: 93 | Iteration number: [490/565] 86% | Training loss: 0.6881531210578218
Epoch: 93 | Iteration number: [500/565] 88% | Training loss: 0.6881286450624466
Epoch: 93 | Iteration number: [510/565] 90% | Training loss: 0.6881108593706992
Epoch: 93 | Iteration number: [520/565] 92% | Training loss: 0.688079276910195
Epoch: 93 | Iteration number: [530/565] 93% | Training loss: 0.6880585167767866
Epoch: 93 | Iteration number: [540/565] 95% | Training loss: 0.6880354653905939
Epoch: 93 | Iteration number: [550/565] 97% | Training loss: 0.6880139800635251
Epoch: 93 | Iteration number: [560/565] 99% | Training loss: 0.6879918734942164

 End of epoch: 93 | Train Loss: 0.6867608157934341 | Training Time: 88 

 End of epoch: 93 | Eval Loss: 0.6897030217306954 | Evaluating Time: 6 
Epoch: 94 | Iteration number: [10/565] 1% | Training loss: 0.7549722731113434
Epoch: 94 | Iteration number: [20/565] 3% | Training loss: 0.7212243467569351
Epoch: 94 | Iteration number: [30/565] 5% | Training loss: 0.7098776598771414
Epoch: 94 | Iteration number: [40/565] 7% | Training loss: 0.7040541395545006
Epoch: 94 | Iteration number: [50/565] 8% | Training loss: 0.70064936876297
Epoch: 94 | Iteration number: [60/565] 10% | Training loss: 0.6983339279890061
Epoch: 94 | Iteration number: [70/565] 12% | Training loss: 0.6967116151537214
Epoch: 94 | Iteration number: [80/565] 14% | Training loss: 0.6954587638378144
Epoch: 94 | Iteration number: [90/565] 15% | Training loss: 0.6944813019699521
Epoch: 94 | Iteration number: [100/565] 17% | Training loss: 0.6937395882606506
Epoch: 94 | Iteration number: [110/565] 19% | Training loss: 0.6930744496258823
Epoch: 94 | Iteration number: [120/565] 21% | Training loss: 0.6925818954904874
Epoch: 94 | Iteration number: [130/565] 23% | Training loss: 0.6920973768601051
Epoch: 94 | Iteration number: [140/565] 24% | Training loss: 0.6917237418038504
Epoch: 94 | Iteration number: [150/565] 26% | Training loss: 0.691376756032308
Epoch: 94 | Iteration number: [160/565] 28% | Training loss: 0.6910722315311432
Epoch: 94 | Iteration number: [170/565] 30% | Training loss: 0.6908043658032137
Epoch: 94 | Iteration number: [180/565] 31% | Training loss: 0.6905809005101522
Epoch: 94 | Iteration number: [190/565] 33% | Training loss: 0.6903897796806536
Epoch: 94 | Iteration number: [200/565] 35% | Training loss: 0.690194842517376
Epoch: 94 | Iteration number: [210/565] 37% | Training loss: 0.6900353213151296
Epoch: 94 | Iteration number: [220/565] 38% | Training loss: 0.6898766975511205
Epoch: 94 | Iteration number: [230/565] 40% | Training loss: 0.6897352594396342
Epoch: 94 | Iteration number: [240/565] 42% | Training loss: 0.6895902924239635
Epoch: 94 | Iteration number: [250/565] 44% | Training loss: 0.689475819826126
Epoch: 94 | Iteration number: [260/565] 46% | Training loss: 0.6893862501933025
Epoch: 94 | Iteration number: [270/565] 47% | Training loss: 0.6893085506227281
Epoch: 94 | Iteration number: [280/565] 49% | Training loss: 0.689210191156183
Epoch: 94 | Iteration number: [290/565] 51% | Training loss: 0.6891281306743622
Epoch: 94 | Iteration number: [300/565] 53% | Training loss: 0.6890462019046147
Epoch: 94 | Iteration number: [310/565] 54% | Training loss: 0.68897189959403
Epoch: 94 | Iteration number: [320/565] 56% | Training loss: 0.6889057785272599
Epoch: 94 | Iteration number: [330/565] 58% | Training loss: 0.6888407049757062
Epoch: 94 | Iteration number: [340/565] 60% | Training loss: 0.6887814397321028
Epoch: 94 | Iteration number: [350/565] 61% | Training loss: 0.6887209830965315
Epoch: 94 | Iteration number: [360/565] 63% | Training loss: 0.6886603535877334
Epoch: 94 | Iteration number: [370/565] 65% | Training loss: 0.6886178538605974
Epoch: 94 | Iteration number: [380/565] 67% | Training loss: 0.6885726555397637
Epoch: 94 | Iteration number: [390/565] 69% | Training loss: 0.6885328982120905
Epoch: 94 | Iteration number: [400/565] 70% | Training loss: 0.6884907096624374
Epoch: 94 | Iteration number: [410/565] 72% | Training loss: 0.6884502218990791
Epoch: 94 | Iteration number: [420/565] 74% | Training loss: 0.6884027806066332
Epoch: 94 | Iteration number: [430/565] 76% | Training loss: 0.6883608529734057
Epoch: 94 | Iteration number: [440/565] 77% | Training loss: 0.6883241761814464
Epoch: 94 | Iteration number: [450/565] 79% | Training loss: 0.6882866774664985
Epoch: 94 | Iteration number: [460/565] 81% | Training loss: 0.6882482133481813
Epoch: 94 | Iteration number: [470/565] 83% | Training loss: 0.688214835207513
Epoch: 94 | Iteration number: [480/565] 84% | Training loss: 0.6881940136353175
Epoch: 94 | Iteration number: [490/565] 86% | Training loss: 0.6881591476956193
Epoch: 94 | Iteration number: [500/565] 88% | Training loss: 0.6881407737731934
Epoch: 94 | Iteration number: [510/565] 90% | Training loss: 0.6881058053643095
Epoch: 94 | Iteration number: [520/565] 92% | Training loss: 0.6880815855585611
Epoch: 94 | Iteration number: [530/565] 93% | Training loss: 0.6880533764947135
Epoch: 94 | Iteration number: [540/565] 95% | Training loss: 0.688027733012482
Epoch: 94 | Iteration number: [550/565] 97% | Training loss: 0.6880021769350225
Epoch: 94 | Iteration number: [560/565] 99% | Training loss: 0.6879863218537399

 End of epoch: 94 | Train Loss: 0.686758928699831 | Training Time: 90 

 End of epoch: 94 | Eval Loss: 0.6898173349244254 | Evaluating Time: 5 
Epoch: 95 | Iteration number: [10/565] 1% | Training loss: 0.7549659669399261
Epoch: 95 | Iteration number: [20/565] 3% | Training loss: 0.7206444352865219
Epoch: 95 | Iteration number: [30/565] 5% | Training loss: 0.7093922396500906
Epoch: 95 | Iteration number: [40/565] 7% | Training loss: 0.7037306264042854
Epoch: 95 | Iteration number: [50/565] 8% | Training loss: 0.7003275978565217
Epoch: 95 | Iteration number: [60/565] 10% | Training loss: 0.6980099846919378
Epoch: 95 | Iteration number: [70/565] 12% | Training loss: 0.6964514204433986
Epoch: 95 | Iteration number: [80/565] 14% | Training loss: 0.6952354297041893
Epoch: 95 | Iteration number: [90/565] 15% | Training loss: 0.6943169593811035
Epoch: 95 | Iteration number: [100/565] 17% | Training loss: 0.6935623151063919
Epoch: 95 | Iteration number: [110/565] 19% | Training loss: 0.6929745652458884
Epoch: 95 | Iteration number: [120/565] 21% | Training loss: 0.6924232626954715
Epoch: 95 | Iteration number: [130/565] 23% | Training loss: 0.6919892810858213
Epoch: 95 | Iteration number: [140/565] 24% | Training loss: 0.6916437740836825
Epoch: 95 | Iteration number: [150/565] 26% | Training loss: 0.6913085520267487
Epoch: 95 | Iteration number: [160/565] 28% | Training loss: 0.69102155379951
Epoch: 95 | Iteration number: [170/565] 30% | Training loss: 0.6907654471257154
Epoch: 95 | Iteration number: [180/565] 31% | Training loss: 0.6905544059144126
Epoch: 95 | Iteration number: [190/565] 33% | Training loss: 0.690380114630649
Epoch: 95 | Iteration number: [200/565] 35% | Training loss: 0.6902135166525841
Epoch: 95 | Iteration number: [210/565] 37% | Training loss: 0.690048040662493
Epoch: 95 | Iteration number: [220/565] 38% | Training loss: 0.6898874654011293
Epoch: 95 | Iteration number: [230/565] 40% | Training loss: 0.6897740993810737
Epoch: 95 | Iteration number: [240/565] 42% | Training loss: 0.6896463843683401
Epoch: 95 | Iteration number: [250/565] 44% | Training loss: 0.689526435136795
Epoch: 95 | Iteration number: [260/565] 46% | Training loss: 0.6894147022412374
Epoch: 95 | Iteration number: [270/565] 47% | Training loss: 0.6893153738092493
Epoch: 95 | Iteration number: [280/565] 49% | Training loss: 0.6892312590565001
Epoch: 95 | Iteration number: [290/565] 51% | Training loss: 0.6891430918512673
Epoch: 95 | Iteration number: [300/565] 53% | Training loss: 0.6890688202778499
Epoch: 95 | Iteration number: [310/565] 54% | Training loss: 0.6890014675355727
Epoch: 95 | Iteration number: [320/565] 56% | Training loss: 0.6889442808926105
Epoch: 95 | Iteration number: [330/565] 58% | Training loss: 0.6888850464965358
Epoch: 95 | Iteration number: [340/565] 60% | Training loss: 0.6888217082794975
Epoch: 95 | Iteration number: [350/565] 61% | Training loss: 0.6887496057578496
Epoch: 95 | Iteration number: [360/565] 63% | Training loss: 0.6886870379249255
Epoch: 95 | Iteration number: [370/565] 65% | Training loss: 0.6886431412116901
Epoch: 95 | Iteration number: [380/565] 67% | Training loss: 0.6885930541314577
Epoch: 95 | Iteration number: [390/565] 69% | Training loss: 0.6885431448618571
Epoch: 95 | Iteration number: [400/565] 70% | Training loss: 0.688504124879837
Epoch: 95 | Iteration number: [410/565] 72% | Training loss: 0.688468299551708
Epoch: 95 | Iteration number: [420/565] 74% | Training loss: 0.6884191828114646
Epoch: 95 | Iteration number: [430/565] 76% | Training loss: 0.6883825130240862
Epoch: 95 | Iteration number: [440/565] 77% | Training loss: 0.6883417827161875
Epoch: 95 | Iteration number: [450/565] 79% | Training loss: 0.6883161720964643
Epoch: 95 | Iteration number: [460/565] 81% | Training loss: 0.6882901827926221
Epoch: 95 | Iteration number: [470/565] 83% | Training loss: 0.6882493336149986
Epoch: 95 | Iteration number: [480/565] 84% | Training loss: 0.6882194717725117
Epoch: 95 | Iteration number: [490/565] 86% | Training loss: 0.6881830917329205
Epoch: 95 | Iteration number: [500/565] 88% | Training loss: 0.6881513271331787
Epoch: 95 | Iteration number: [510/565] 90% | Training loss: 0.6881102809719011
Epoch: 95 | Iteration number: [520/565] 92% | Training loss: 0.6880824306836495
Epoch: 95 | Iteration number: [530/565] 93% | Training loss: 0.6880594025243003
Epoch: 95 | Iteration number: [540/565] 95% | Training loss: 0.6880239002130649
Epoch: 95 | Iteration number: [550/565] 97% | Training loss: 0.6880034034902399
Epoch: 95 | Iteration number: [560/565] 99% | Training loss: 0.6879842528275081

 End of epoch: 95 | Train Loss: 0.6867592156460854 | Training Time: 88 

 End of epoch: 95 | Eval Loss: 0.689409213406699 | Evaluating Time: 6 
Epoch: 96 | Iteration number: [10/565] 1% | Training loss: 0.7552928149700164
Epoch: 96 | Iteration number: [20/565] 3% | Training loss: 0.7209971696138382
Epoch: 96 | Iteration number: [30/565] 5% | Training loss: 0.7096737742424011
Epoch: 96 | Iteration number: [40/565] 7% | Training loss: 0.7038129597902298
Epoch: 96 | Iteration number: [50/565] 8% | Training loss: 0.7004672491550445
Epoch: 96 | Iteration number: [60/565] 10% | Training loss: 0.6981659710407258
Epoch: 96 | Iteration number: [70/565] 12% | Training loss: 0.696526118687221
Epoch: 96 | Iteration number: [80/565] 14% | Training loss: 0.695275642722845
Epoch: 96 | Iteration number: [90/565] 15% | Training loss: 0.6943828953637017
Epoch: 96 | Iteration number: [100/565] 17% | Training loss: 0.6935943400859833
Epoch: 96 | Iteration number: [110/565] 19% | Training loss: 0.6929581365802071
Epoch: 96 | Iteration number: [120/565] 21% | Training loss: 0.6924530069033304
Epoch: 96 | Iteration number: [130/565] 23% | Training loss: 0.6919780621161827
Epoch: 96 | Iteration number: [140/565] 24% | Training loss: 0.691628485918045
Epoch: 96 | Iteration number: [150/565] 26% | Training loss: 0.6913076444466909
Epoch: 96 | Iteration number: [160/565] 28% | Training loss: 0.6910056129097939
Epoch: 96 | Iteration number: [170/565] 30% | Training loss: 0.6907526770058801
Epoch: 96 | Iteration number: [180/565] 31% | Training loss: 0.6905017657412423
Epoch: 96 | Iteration number: [190/565] 33% | Training loss: 0.6902883093608053
Epoch: 96 | Iteration number: [200/565] 35% | Training loss: 0.6901379811763764
Epoch: 96 | Iteration number: [210/565] 37% | Training loss: 0.6899736906800952
Epoch: 96 | Iteration number: [220/565] 38% | Training loss: 0.6898342763835733
Epoch: 96 | Iteration number: [230/565] 40% | Training loss: 0.6896781439366548
Epoch: 96 | Iteration number: [240/565] 42% | Training loss: 0.689567078401645
Epoch: 96 | Iteration number: [250/565] 44% | Training loss: 0.6894467697143555
Epoch: 96 | Iteration number: [260/565] 46% | Training loss: 0.6893474299174088
Epoch: 96 | Iteration number: [270/565] 47% | Training loss: 0.6892673834606453
Epoch: 96 | Iteration number: [280/565] 49% | Training loss: 0.6891864176307406
Epoch: 96 | Iteration number: [290/565] 51% | Training loss: 0.6890858639930857
Epoch: 96 | Iteration number: [300/565] 53% | Training loss: 0.6890067013104757
Epoch: 96 | Iteration number: [310/565] 54% | Training loss: 0.6889419571045906
Epoch: 96 | Iteration number: [320/565] 56% | Training loss: 0.6888839771971107
Epoch: 96 | Iteration number: [330/565] 58% | Training loss: 0.6888192724097859
Epoch: 96 | Iteration number: [340/565] 60% | Training loss: 0.6887663064634099
Epoch: 96 | Iteration number: [350/565] 61% | Training loss: 0.6887127109936305
Epoch: 96 | Iteration number: [360/565] 63% | Training loss: 0.6886574831273821
Epoch: 96 | Iteration number: [370/565] 65% | Training loss: 0.6886051084544208
Epoch: 96 | Iteration number: [380/565] 67% | Training loss: 0.6885574317292164
Epoch: 96 | Iteration number: [390/565] 69% | Training loss: 0.6885062041955117
Epoch: 96 | Iteration number: [400/565] 70% | Training loss: 0.6884513619542122
Epoch: 96 | Iteration number: [410/565] 72% | Training loss: 0.6884115028672102
Epoch: 96 | Iteration number: [420/565] 74% | Training loss: 0.6883724292119344
Epoch: 96 | Iteration number: [430/565] 76% | Training loss: 0.6883305376352266
Epoch: 96 | Iteration number: [440/565] 77% | Training loss: 0.688297243009914
Epoch: 96 | Iteration number: [450/565] 79% | Training loss: 0.6882742639382681
Epoch: 96 | Iteration number: [460/565] 81% | Training loss: 0.6882416537274485
Epoch: 96 | Iteration number: [470/565] 83% | Training loss: 0.6882082533329091
Epoch: 96 | Iteration number: [480/565] 84% | Training loss: 0.6881842320164044
Epoch: 96 | Iteration number: [490/565] 86% | Training loss: 0.68815649832998
Epoch: 96 | Iteration number: [500/565] 88% | Training loss: 0.6881359224319458
Epoch: 96 | Iteration number: [510/565] 90% | Training loss: 0.6881071490399978
Epoch: 96 | Iteration number: [520/565] 92% | Training loss: 0.6880785458363019
Epoch: 96 | Iteration number: [530/565] 93% | Training loss: 0.6880526475186618
Epoch: 96 | Iteration number: [540/565] 95% | Training loss: 0.6880268556100351
Epoch: 96 | Iteration number: [550/565] 97% | Training loss: 0.6880017704313451
Epoch: 96 | Iteration number: [560/565] 99% | Training loss: 0.6879832083625453

 End of epoch: 96 | Train Loss: 0.6867609236092694 | Training Time: 89 

 End of epoch: 96 | Eval Loss: 0.689908104283469 | Evaluating Time: 5 
Epoch: 97 | Iteration number: [10/565] 1% | Training loss: 0.7554431736469269
Epoch: 97 | Iteration number: [20/565] 3% | Training loss: 0.7210775882005691
Epoch: 97 | Iteration number: [30/565] 5% | Training loss: 0.7096541007359822
Epoch: 97 | Iteration number: [40/565] 7% | Training loss: 0.7039516746997834
Epoch: 97 | Iteration number: [50/565] 8% | Training loss: 0.7005643320083618
Epoch: 97 | Iteration number: [60/565] 10% | Training loss: 0.6982694715261459
Epoch: 97 | Iteration number: [70/565] 12% | Training loss: 0.6965827703475952
Epoch: 97 | Iteration number: [80/565] 14% | Training loss: 0.6952831663191319
Epoch: 97 | Iteration number: [90/565] 15% | Training loss: 0.6942998707294464
Epoch: 97 | Iteration number: [100/565] 17% | Training loss: 0.6935473763942719
Epoch: 97 | Iteration number: [110/565] 19% | Training loss: 0.6929439355026592
Epoch: 97 | Iteration number: [120/565] 21% | Training loss: 0.6924543266495069
Epoch: 97 | Iteration number: [130/565] 23% | Training loss: 0.6920116543769836
Epoch: 97 | Iteration number: [140/565] 24% | Training loss: 0.6916329937321799
Epoch: 97 | Iteration number: [150/565] 26% | Training loss: 0.6912946693102519
Epoch: 97 | Iteration number: [160/565] 28% | Training loss: 0.6910441819578409
Epoch: 97 | Iteration number: [170/565] 30% | Training loss: 0.6907819484963137
Epoch: 97 | Iteration number: [180/565] 31% | Training loss: 0.6905965391132567
Epoch: 97 | Iteration number: [190/565] 33% | Training loss: 0.690398485409586
Epoch: 97 | Iteration number: [200/565] 35% | Training loss: 0.6902138203382492
Epoch: 97 | Iteration number: [210/565] 37% | Training loss: 0.6900432788190387
Epoch: 97 | Iteration number: [220/565] 38% | Training loss: 0.6899073053490031
Epoch: 97 | Iteration number: [230/565] 40% | Training loss: 0.6897762150868125
Epoch: 97 | Iteration number: [240/565] 42% | Training loss: 0.6896598962446053
Epoch: 97 | Iteration number: [250/565] 44% | Training loss: 0.6895441174507141
Epoch: 97 | Iteration number: [260/565] 46% | Training loss: 0.689436425612523
Epoch: 97 | Iteration number: [270/565] 47% | Training loss: 0.6893219309824484
Epoch: 97 | Iteration number: [280/565] 49% | Training loss: 0.6892259091138839
Epoch: 97 | Iteration number: [290/565] 51% | Training loss: 0.6891446822676165
Epoch: 97 | Iteration number: [300/565] 53% | Training loss: 0.6890761053562164
Epoch: 97 | Iteration number: [310/565] 54% | Training loss: 0.6889998845515712
Epoch: 97 | Iteration number: [320/565] 56% | Training loss: 0.6889296671375632
Epoch: 97 | Iteration number: [330/565] 58% | Training loss: 0.6888694819175836
Epoch: 97 | Iteration number: [340/565] 60% | Training loss: 0.6888033207725076
Epoch: 97 | Iteration number: [350/565] 61% | Training loss: 0.6887429516656058
Epoch: 97 | Iteration number: [360/565] 63% | Training loss: 0.6886827622850736
Epoch: 97 | Iteration number: [370/565] 65% | Training loss: 0.6886149720565693
Epoch: 97 | Iteration number: [380/565] 67% | Training loss: 0.6885661035776138
Epoch: 97 | Iteration number: [390/565] 69% | Training loss: 0.6885198937012599
Epoch: 97 | Iteration number: [400/565] 70% | Training loss: 0.6884851589798927
Epoch: 97 | Iteration number: [410/565] 72% | Training loss: 0.6884426665015337
Epoch: 97 | Iteration number: [420/565] 74% | Training loss: 0.6884080397231238
Epoch: 97 | Iteration number: [430/565] 76% | Training loss: 0.6883656123349833
Epoch: 97 | Iteration number: [440/565] 77% | Training loss: 0.6883277359333906
Epoch: 97 | Iteration number: [450/565] 79% | Training loss: 0.6882898101541731
Epoch: 97 | Iteration number: [460/565] 81% | Training loss: 0.6882661073104195
Epoch: 97 | Iteration number: [470/565] 83% | Training loss: 0.6882354426891246
Epoch: 97 | Iteration number: [480/565] 84% | Training loss: 0.6882003658761581
Epoch: 97 | Iteration number: [490/565] 86% | Training loss: 0.6881751193075764
Epoch: 97 | Iteration number: [500/565] 88% | Training loss: 0.6881476159095764
Epoch: 97 | Iteration number: [510/565] 90% | Training loss: 0.6881154928721633
Epoch: 97 | Iteration number: [520/565] 92% | Training loss: 0.6880893209805855
Epoch: 97 | Iteration number: [530/565] 93% | Training loss: 0.688061101369138
Epoch: 97 | Iteration number: [540/565] 95% | Training loss: 0.6880389034748078
Epoch: 97 | Iteration number: [550/565] 97% | Training loss: 0.6880221927165985
Epoch: 97 | Iteration number: [560/565] 99% | Training loss: 0.6879991193967206

 End of epoch: 97 | Train Loss: 0.6867708238880191 | Training Time: 88 

 End of epoch: 97 | Eval Loss: 0.6895052024296352 | Evaluating Time: 6 
Epoch: 98 | Iteration number: [10/565] 1% | Training loss: 0.7555741906166077
Epoch: 98 | Iteration number: [20/565] 3% | Training loss: 0.7212607860565186
Epoch: 98 | Iteration number: [30/565] 5% | Training loss: 0.7096538603305816
Epoch: 98 | Iteration number: [40/565] 7% | Training loss: 0.7038432821631432
Epoch: 98 | Iteration number: [50/565] 8% | Training loss: 0.7004302954673767
Epoch: 98 | Iteration number: [60/565] 10% | Training loss: 0.6981506377458573
Epoch: 98 | Iteration number: [70/565] 12% | Training loss: 0.6965383657387325
Epoch: 98 | Iteration number: [80/565] 14% | Training loss: 0.6952230058610439
Epoch: 98 | Iteration number: [90/565] 15% | Training loss: 0.6942078338729011
Epoch: 98 | Iteration number: [100/565] 17% | Training loss: 0.6934357261657715
Epoch: 98 | Iteration number: [110/565] 19% | Training loss: 0.6928395433859391
Epoch: 98 | Iteration number: [120/565] 21% | Training loss: 0.6923668523629506
Epoch: 98 | Iteration number: [130/565] 23% | Training loss: 0.6919192204108605
Epoch: 98 | Iteration number: [140/565] 24% | Training loss: 0.6915588932377952
Epoch: 98 | Iteration number: [150/565] 26% | Training loss: 0.6912222603956858
Epoch: 98 | Iteration number: [160/565] 28% | Training loss: 0.6909326765686273
Epoch: 98 | Iteration number: [170/565] 30% | Training loss: 0.6907027682837318
Epoch: 98 | Iteration number: [180/565] 31% | Training loss: 0.6904859781265259
Epoch: 98 | Iteration number: [190/565] 33% | Training loss: 0.6902912224593916
Epoch: 98 | Iteration number: [200/565] 35% | Training loss: 0.6901032358407975
Epoch: 98 | Iteration number: [210/565] 37% | Training loss: 0.6899502813816071
Epoch: 98 | Iteration number: [220/565] 38% | Training loss: 0.6898123971440575
Epoch: 98 | Iteration number: [230/565] 40% | Training loss: 0.6896874883900518
Epoch: 98 | Iteration number: [240/565] 42% | Training loss: 0.6895850573976835
Epoch: 98 | Iteration number: [250/565] 44% | Training loss: 0.6894851450920105
Epoch: 98 | Iteration number: [260/565] 46% | Training loss: 0.6893891673821669
Epoch: 98 | Iteration number: [270/565] 47% | Training loss: 0.6892790324158139
Epoch: 98 | Iteration number: [280/565] 49% | Training loss: 0.6891963403139796
Epoch: 98 | Iteration number: [290/565] 51% | Training loss: 0.6890999662465063
Epoch: 98 | Iteration number: [300/565] 53% | Training loss: 0.6890235869089762
Epoch: 98 | Iteration number: [310/565] 54% | Training loss: 0.6889375390545014
Epoch: 98 | Iteration number: [320/565] 56% | Training loss: 0.688860590569675
Epoch: 98 | Iteration number: [330/565] 58% | Training loss: 0.6887869383349563
Epoch: 98 | Iteration number: [340/565] 60% | Training loss: 0.6887274146080017
Epoch: 98 | Iteration number: [350/565] 61% | Training loss: 0.688673392704555
Epoch: 98 | Iteration number: [360/565] 63% | Training loss: 0.6886303992735014
Epoch: 98 | Iteration number: [370/565] 65% | Training loss: 0.6885883893515613
Epoch: 98 | Iteration number: [380/565] 67% | Training loss: 0.6885374117838708
Epoch: 98 | Iteration number: [390/565] 69% | Training loss: 0.6884967071887774
Epoch: 98 | Iteration number: [400/565] 70% | Training loss: 0.6884522631764411
Epoch: 98 | Iteration number: [410/565] 72% | Training loss: 0.6884091464484611
Epoch: 98 | Iteration number: [420/565] 74% | Training loss: 0.6883726111480168
Epoch: 98 | Iteration number: [430/565] 76% | Training loss: 0.6883302924244903
Epoch: 98 | Iteration number: [440/565] 77% | Training loss: 0.6883002483031967
Epoch: 98 | Iteration number: [450/565] 79% | Training loss: 0.6882710003852844
Epoch: 98 | Iteration number: [460/565] 81% | Training loss: 0.6882359416588493
Epoch: 98 | Iteration number: [470/565] 83% | Training loss: 0.6882051016422028
Epoch: 98 | Iteration number: [480/565] 84% | Training loss: 0.6881742575516303
Epoch: 98 | Iteration number: [490/565] 86% | Training loss: 0.6881571088518416
Epoch: 98 | Iteration number: [500/565] 88% | Training loss: 0.68812999355793
Epoch: 98 | Iteration number: [510/565] 90% | Training loss: 0.6881191045630212
Epoch: 98 | Iteration number: [520/565] 92% | Training loss: 0.6880933371874002
Epoch: 98 | Iteration number: [530/565] 93% | Training loss: 0.6880642066586692
Epoch: 98 | Iteration number: [540/565] 95% | Training loss: 0.6880380493623239
Epoch: 98 | Iteration number: [550/565] 97% | Training loss: 0.6880199949307875
Epoch: 98 | Iteration number: [560/565] 99% | Training loss: 0.6879991983728749

 End of epoch: 98 | Train Loss: 0.6867736387041817 | Training Time: 90 

 End of epoch: 98 | Eval Loss: 0.6893889222826276 | Evaluating Time: 5 
Epoch: 99 | Iteration number: [10/565] 1% | Training loss: 0.7557792842388154
Epoch: 99 | Iteration number: [20/565] 3% | Training loss: 0.7213963598012925
Epoch: 99 | Iteration number: [30/565] 5% | Training loss: 0.7098054071267446
Epoch: 99 | Iteration number: [40/565] 7% | Training loss: 0.7039720341563225
Epoch: 99 | Iteration number: [50/565] 8% | Training loss: 0.7005851233005523
Epoch: 99 | Iteration number: [60/565] 10% | Training loss: 0.6982326060533524
Epoch: 99 | Iteration number: [70/565] 12% | Training loss: 0.6966254029955182
Epoch: 99 | Iteration number: [80/565] 14% | Training loss: 0.695313361287117
Epoch: 99 | Iteration number: [90/565] 15% | Training loss: 0.6943308571974437
Epoch: 99 | Iteration number: [100/565] 17% | Training loss: 0.6935095727443695
Epoch: 99 | Iteration number: [110/565] 19% | Training loss: 0.6928668135946447
Epoch: 99 | Iteration number: [120/565] 21% | Training loss: 0.692360678811868
Epoch: 99 | Iteration number: [130/565] 23% | Training loss: 0.6919541519421798
Epoch: 99 | Iteration number: [140/565] 24% | Training loss: 0.691573019538607
Epoch: 99 | Iteration number: [150/565] 26% | Training loss: 0.6912466148535411
Epoch: 99 | Iteration number: [160/565] 28% | Training loss: 0.6910005778074264
Epoch: 99 | Iteration number: [170/565] 30% | Training loss: 0.6907679606886471
Epoch: 99 | Iteration number: [180/565] 31% | Training loss: 0.6905736393398709
Epoch: 99 | Iteration number: [190/565] 33% | Training loss: 0.6903445971639532
Epoch: 99 | Iteration number: [200/565] 35% | Training loss: 0.6901628291606903
Epoch: 99 | Iteration number: [210/565] 37% | Training loss: 0.689991956949234
Epoch: 99 | Iteration number: [220/565] 38% | Training loss: 0.6898399339480834
Epoch: 99 | Iteration number: [230/565] 40% | Training loss: 0.6897123712560405
Epoch: 99 | Iteration number: [240/565] 42% | Training loss: 0.6895776788393656
Epoch: 99 | Iteration number: [250/565] 44% | Training loss: 0.6894496319293976
Epoch: 99 | Iteration number: [260/565] 46% | Training loss: 0.6893338208015148
Epoch: 99 | Iteration number: [270/565] 47% | Training loss: 0.6892322094352157
Epoch: 99 | Iteration number: [280/565] 49% | Training loss: 0.6891215650098664
Epoch: 99 | Iteration number: [290/565] 51% | Training loss: 0.6890433745137576
Epoch: 99 | Iteration number: [300/565] 53% | Training loss: 0.6889579210678737
Epoch: 99 | Iteration number: [310/565] 54% | Training loss: 0.6889022825225707
Epoch: 99 | Iteration number: [320/565] 56% | Training loss: 0.6888496370986104
Epoch: 99 | Iteration number: [330/565] 58% | Training loss: 0.6887894523866249
Epoch: 99 | Iteration number: [340/565] 60% | Training loss: 0.6887241510783925
Epoch: 99 | Iteration number: [350/565] 61% | Training loss: 0.6886667207309178
Epoch: 99 | Iteration number: [360/565] 63% | Training loss: 0.6886270450221168
Epoch: 99 | Iteration number: [370/565] 65% | Training loss: 0.6885795765631908
Epoch: 99 | Iteration number: [380/565] 67% | Training loss: 0.6885278974708758
Epoch: 99 | Iteration number: [390/565] 69% | Training loss: 0.6884831764759162
Epoch: 99 | Iteration number: [400/565] 70% | Training loss: 0.6884487549960613
Epoch: 99 | Iteration number: [410/565] 72% | Training loss: 0.688417106430705
Epoch: 99 | Iteration number: [420/565] 74% | Training loss: 0.6883858352899551
Epoch: 99 | Iteration number: [430/565] 76% | Training loss: 0.6883448123931885
Epoch: 99 | Iteration number: [440/565] 77% | Training loss: 0.688309580494057
Epoch: 99 | Iteration number: [450/565] 79% | Training loss: 0.6882695236470964
Epoch: 99 | Iteration number: [460/565] 81% | Training loss: 0.6882387513699739
Epoch: 99 | Iteration number: [470/565] 83% | Training loss: 0.6882080045152218
Epoch: 99 | Iteration number: [480/565] 84% | Training loss: 0.6881712138652801
Epoch: 99 | Iteration number: [490/565] 86% | Training loss: 0.6881470846886537
Epoch: 99 | Iteration number: [500/565] 88% | Training loss: 0.688126294851303
Epoch: 99 | Iteration number: [510/565] 90% | Training loss: 0.6881036124977411
Epoch: 99 | Iteration number: [520/565] 92% | Training loss: 0.6880818880521334
Epoch: 99 | Iteration number: [530/565] 93% | Training loss: 0.6880519159559934
Epoch: 99 | Iteration number: [540/565] 95% | Training loss: 0.6880298688455865
Epoch: 99 | Iteration number: [550/565] 97% | Training loss: 0.688005609403957
Epoch: 99 | Iteration number: [560/565] 99% | Training loss: 0.6879896501345294

 End of epoch: 99 | Train Loss: 0.6867623894615511 | Training Time: 89 

 End of epoch: 99 | Eval Loss: 0.689337398324694 | Evaluating Time: 6 
Epoch: 100 | Iteration number: [10/565] 1% | Training loss: 0.7558251798152924
Epoch: 100 | Iteration number: [20/565] 3% | Training loss: 0.7212317168712616
Epoch: 100 | Iteration number: [30/565] 5% | Training loss: 0.7097255229949951
Epoch: 100 | Iteration number: [40/565] 7% | Training loss: 0.7040011122822761
Epoch: 100 | Iteration number: [50/565] 8% | Training loss: 0.7004993402957916
Epoch: 100 | Iteration number: [60/565] 10% | Training loss: 0.6982229928175608
Epoch: 100 | Iteration number: [70/565] 12% | Training loss: 0.6965646641595024
Epoch: 100 | Iteration number: [80/565] 14% | Training loss: 0.6953257903456688
Epoch: 100 | Iteration number: [90/565] 15% | Training loss: 0.6943728493319618
Epoch: 100 | Iteration number: [100/565] 17% | Training loss: 0.6936442285776139
Epoch: 100 | Iteration number: [110/565] 19% | Training loss: 0.6930502869866111
Epoch: 100 | Iteration number: [120/565] 21% | Training loss: 0.6925737475355466
Epoch: 100 | Iteration number: [130/565] 23% | Training loss: 0.6921105815814091
Epoch: 100 | Iteration number: [140/565] 24% | Training loss: 0.6917448014020919
Epoch: 100 | Iteration number: [150/565] 26% | Training loss: 0.6914088833332062
Epoch: 100 | Iteration number: [160/565] 28% | Training loss: 0.6911127422004938
Epoch: 100 | Iteration number: [170/565] 30% | Training loss: 0.690852763372309
Epoch: 100 | Iteration number: [180/565] 31% | Training loss: 0.6906103061305152
Epoch: 100 | Iteration number: [190/565] 33% | Training loss: 0.6904099219723752
Epoch: 100 | Iteration number: [200/565] 35% | Training loss: 0.6902376422286034
Epoch: 100 | Iteration number: [210/565] 37% | Training loss: 0.6900700137728737
Epoch: 100 | Iteration number: [220/565] 38% | Training loss: 0.6899322989312086
Epoch: 100 | Iteration number: [230/565] 40% | Training loss: 0.6897892044938129
Epoch: 100 | Iteration number: [240/565] 42% | Training loss: 0.6896388751765092
Epoch: 100 | Iteration number: [250/565] 44% | Training loss: 0.6895417370796204
Epoch: 100 | Iteration number: [260/565] 46% | Training loss: 0.6894314431227171
Epoch: 100 | Iteration number: [270/565] 47% | Training loss: 0.6893236087428198
Epoch: 100 | Iteration number: [280/565] 49% | Training loss: 0.6892405086330005
Epoch: 100 | Iteration number: [290/565] 51% | Training loss: 0.6891390537393505
Epoch: 100 | Iteration number: [300/565] 53% | Training loss: 0.6890696032842001
Epoch: 100 | Iteration number: [310/565] 54% | Training loss: 0.6889810585206555
Epoch: 100 | Iteration number: [320/565] 56% | Training loss: 0.6889177007600665
Epoch: 100 | Iteration number: [330/565] 58% | Training loss: 0.6888648154157581
Epoch: 100 | Iteration number: [340/565] 60% | Training loss: 0.6888051478301778
Epoch: 100 | Iteration number: [350/565] 61% | Training loss: 0.6887608945369721
Epoch: 100 | Iteration number: [360/565] 63% | Training loss: 0.6887118442191018
Epoch: 100 | Iteration number: [370/565] 65% | Training loss: 0.6886504708109675
Epoch: 100 | Iteration number: [380/565] 67% | Training loss: 0.6885979828081633
Epoch: 100 | Iteration number: [390/565] 69% | Training loss: 0.6885529444767878
Epoch: 100 | Iteration number: [400/565] 70% | Training loss: 0.6885090325772762
Epoch: 100 | Iteration number: [410/565] 72% | Training loss: 0.6884701692476505
Epoch: 100 | Iteration number: [420/565] 74% | Training loss: 0.6884302373443331
Epoch: 100 | Iteration number: [430/565] 76% | Training loss: 0.6883817976297334
Epoch: 100 | Iteration number: [440/565] 77% | Training loss: 0.6883355291052298
Epoch: 100 | Iteration number: [450/565] 79% | Training loss: 0.6883018669817182
Epoch: 100 | Iteration number: [460/565] 81% | Training loss: 0.6882763607346494
Epoch: 100 | Iteration number: [470/565] 83% | Training loss: 0.6882465428494392
Epoch: 100 | Iteration number: [480/565] 84% | Training loss: 0.6882191594690085
Epoch: 100 | Iteration number: [490/565] 86% | Training loss: 0.6881908157650305
Epoch: 100 | Iteration number: [500/565] 88% | Training loss: 0.6881601675748825
Epoch: 100 | Iteration number: [510/565] 90% | Training loss: 0.688134479639577
Epoch: 100 | Iteration number: [520/565] 92% | Training loss: 0.6881010214869793
Epoch: 100 | Iteration number: [530/565] 93% | Training loss: 0.6880684721020033
Epoch: 100 | Iteration number: [540/565] 95% | Training loss: 0.6880382843591549
Epoch: 100 | Iteration number: [550/565] 97% | Training loss: 0.6880129970203747
Epoch: 100 | Iteration number: [560/565] 99% | Training loss: 0.6879800583635057

 End of epoch: 100 | Train Loss: 0.6867589427306589 | Training Time: 90 

 End of epoch: 100 | Eval Loss: 0.6891009892736163 | Evaluating Time: 5 

 End of Test | Dice Loss: 0.9571520345551627 | Binary Cross Entropy With Logits Loss: 0.6897766590118408 
