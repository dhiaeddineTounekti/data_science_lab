Epoch: 1 | Iteration number: [10/565] 1% | Training loss: 0.7636866092681884
Epoch: 1 | Iteration number: [20/565] 3% | Training loss: 0.7286130100488662
Epoch: 1 | Iteration number: [30/565] 5% | Training loss: 0.7170071105162302
Epoch: 1 | Iteration number: [40/565] 7% | Training loss: 0.7111326411366463
Epoch: 1 | Iteration number: [50/565] 8% | Training loss: 0.7075387346744537
Epoch: 1 | Iteration number: [60/565] 10% | Training loss: 0.7051495750745137
Epoch: 1 | Iteration number: [70/565] 12% | Training loss: 0.7033965621675764
Epoch: 1 | Iteration number: [80/565] 14% | Training loss: 0.7021032676100731
Epoch: 1 | Iteration number: [90/565] 15% | Training loss: 0.7010816633701324
Epoch: 1 | Iteration number: [100/565] 17% | Training loss: 0.700236394405365
Epoch: 1 | Iteration number: [110/565] 19% | Training loss: 0.6995398700237274
Epoch: 1 | Iteration number: [120/565] 21% | Training loss: 0.6989361008008321
Epoch: 1 | Iteration number: [130/565] 23% | Training loss: 0.6984374303084153
Epoch: 1 | Iteration number: [140/565] 24% | Training loss: 0.6980202879224505
Epoch: 1 | Iteration number: [150/565] 26% | Training loss: 0.6976410881678263
Epoch: 1 | Iteration number: [160/565] 28% | Training loss: 0.6972924530506134
Epoch: 1 | Iteration number: [170/565] 30% | Training loss: 0.6969828293604009
Epoch: 1 | Iteration number: [180/565] 31% | Training loss: 0.6966764539480209
Epoch: 1 | Iteration number: [190/565] 33% | Training loss: 0.696427310454218
Epoch: 1 | Iteration number: [200/565] 35% | Training loss: 0.6961935609579086
Epoch: 1 | Iteration number: [210/565] 37% | Training loss: 0.6959810759340014
Epoch: 1 | Iteration number: [220/565] 38% | Training loss: 0.6958052163774316
Epoch: 1 | Iteration number: [230/565] 40% | Training loss: 0.695625970415447
Epoch: 1 | Iteration number: [240/565] 42% | Training loss: 0.6954651479919751
Epoch: 1 | Iteration number: [250/565] 44% | Training loss: 0.6953097937107087
Epoch: 1 | Iteration number: [260/565] 46% | Training loss: 0.6951594600310692
Epoch: 1 | Iteration number: [270/565] 47% | Training loss: 0.6950241499476962
Epoch: 1 | Iteration number: [280/565] 49% | Training loss: 0.6948905768139022
Epoch: 1 | Iteration number: [290/565] 51% | Training loss: 0.6947731774428795
Epoch: 1 | Iteration number: [300/565] 53% | Training loss: 0.6946826400359472
Epoch: 1 | Iteration number: [310/565] 54% | Training loss: 0.6945806151436221
Epoch: 1 | Iteration number: [320/565] 56% | Training loss: 0.6944903030991554
Epoch: 1 | Iteration number: [330/565] 58% | Training loss: 0.694394874572754
Epoch: 1 | Iteration number: [340/565] 60% | Training loss: 0.6943114817142486
Epoch: 1 | Iteration number: [350/565] 61% | Training loss: 0.6942385252884457
Epoch: 1 | Iteration number: [360/565] 63% | Training loss: 0.6941540403498544
Epoch: 1 | Iteration number: [370/565] 65% | Training loss: 0.6940735518932343
Epoch: 1 | Iteration number: [380/565] 67% | Training loss: 0.6939936523374758
Epoch: 1 | Iteration number: [390/565] 69% | Training loss: 0.6939193141766083
Epoch: 1 | Iteration number: [400/565] 70% | Training loss: 0.693842021226883
Epoch: 1 | Iteration number: [410/565] 72% | Training loss: 0.6937684258309806
Epoch: 1 | Iteration number: [420/565] 74% | Training loss: 0.6937065520456859
Epoch: 1 | Iteration number: [430/565] 76% | Training loss: 0.6936404766038406
Epoch: 1 | Iteration number: [440/565] 77% | Training loss: 0.693569407815283
Epoch: 1 | Iteration number: [450/565] 79% | Training loss: 0.693505245314704
Epoch: 1 | Iteration number: [460/565] 81% | Training loss: 0.6934364092090856
Epoch: 1 | Iteration number: [470/565] 83% | Training loss: 0.6933860248707711
Epoch: 1 | Iteration number: [480/565] 84% | Training loss: 0.693329993262887
Epoch: 1 | Iteration number: [490/565] 86% | Training loss: 0.6932774839352588
Epoch: 1 | Iteration number: [500/565] 88% | Training loss: 0.6932248500585556
Epoch: 1 | Iteration number: [510/565] 90% | Training loss: 0.6931656007673226
Epoch: 1 | Iteration number: [520/565] 92% | Training loss: 0.6931160166859627
Epoch: 1 | Iteration number: [530/565] 93% | Training loss: 0.6930665442403757
Epoch: 1 | Iteration number: [540/565] 95% | Training loss: 0.6930186021107214
Epoch: 1 | Iteration number: [550/565] 97% | Training loss: 0.6929702273282138
Epoch: 1 | Iteration number: [560/565] 99% | Training loss: 0.6929272542042392

 End of epoch: 1 | Train Loss: 0.6916797983962878 | Training Time: 87 

 End of epoch: 1 | Eval Loss: 0.6923869848251343 | Evaluating Time: 6 
Epoch: 2 | Iteration number: [10/565] 1% | Training loss: 0.7591257214546203
Epoch: 2 | Iteration number: [20/565] 3% | Training loss: 0.7247999966144562
Epoch: 2 | Iteration number: [30/565] 5% | Training loss: 0.7133050421873729
Epoch: 2 | Iteration number: [40/565] 7% | Training loss: 0.7075536951422692
Epoch: 2 | Iteration number: [50/565] 8% | Training loss: 0.7040482175350189
Epoch: 2 | Iteration number: [60/565] 10% | Training loss: 0.7017245848973592
Epoch: 2 | Iteration number: [70/565] 12% | Training loss: 0.7000408853803363
Epoch: 2 | Iteration number: [80/565] 14% | Training loss: 0.6987739339470863
Epoch: 2 | Iteration number: [90/565] 15% | Training loss: 0.6978367553816901
Epoch: 2 | Iteration number: [100/565] 17% | Training loss: 0.6970559650659561
Epoch: 2 | Iteration number: [110/565] 19% | Training loss: 0.696391166340221
Epoch: 2 | Iteration number: [120/565] 21% | Training loss: 0.6958546996116638
Epoch: 2 | Iteration number: [130/565] 23% | Training loss: 0.6953765736176417
Epoch: 2 | Iteration number: [140/565] 24% | Training loss: 0.6949895522424153
Epoch: 2 | Iteration number: [150/565] 26% | Training loss: 0.6946573781967164
Epoch: 2 | Iteration number: [160/565] 28% | Training loss: 0.6943648185580968
Epoch: 2 | Iteration number: [170/565] 30% | Training loss: 0.6941312274512123
Epoch: 2 | Iteration number: [180/565] 31% | Training loss: 0.6939055383205414
Epoch: 2 | Iteration number: [190/565] 33% | Training loss: 0.6936896038682837
Epoch: 2 | Iteration number: [200/565] 35% | Training loss: 0.6934904593229294
Epoch: 2 | Iteration number: [210/565] 37% | Training loss: 0.6933084363029116
Epoch: 2 | Iteration number: [220/565] 38% | Training loss: 0.6931502418084579
Epoch: 2 | Iteration number: [230/565] 40% | Training loss: 0.6930062325104424
Epoch: 2 | Iteration number: [240/565] 42% | Training loss: 0.6929000216225784
Epoch: 2 | Iteration number: [250/565] 44% | Training loss: 0.6927850110530853
Epoch: 2 | Iteration number: [260/565] 46% | Training loss: 0.69267737361101
Epoch: 2 | Iteration number: [270/565] 47% | Training loss: 0.6925732133565126
Epoch: 2 | Iteration number: [280/565] 49% | Training loss: 0.6924675147448267
Epoch: 2 | Iteration number: [290/565] 51% | Training loss: 0.6923845461730299
Epoch: 2 | Iteration number: [300/565] 53% | Training loss: 0.6923146718740463
Epoch: 2 | Iteration number: [310/565] 54% | Training loss: 0.6922321209984441
Epoch: 2 | Iteration number: [320/565] 56% | Training loss: 0.692148718982935
Epoch: 2 | Iteration number: [330/565] 58% | Training loss: 0.6920766920754404
Epoch: 2 | Iteration number: [340/565] 60% | Training loss: 0.6920092612504959
Epoch: 2 | Iteration number: [350/565] 61% | Training loss: 0.6919545922960554
Epoch: 2 | Iteration number: [360/565] 63% | Training loss: 0.6918972576657931
Epoch: 2 | Iteration number: [370/565] 65% | Training loss: 0.6918356998546703
Epoch: 2 | Iteration number: [380/565] 67% | Training loss: 0.6917761517198462
Epoch: 2 | Iteration number: [390/565] 69% | Training loss: 0.6917138924965491
Epoch: 2 | Iteration number: [400/565] 70% | Training loss: 0.6916613437235355
Epoch: 2 | Iteration number: [410/565] 72% | Training loss: 0.6916217417251773
Epoch: 2 | Iteration number: [420/565] 74% | Training loss: 0.6915695800667717
Epoch: 2 | Iteration number: [430/565] 76% | Training loss: 0.6915267457795697
Epoch: 2 | Iteration number: [440/565] 77% | Training loss: 0.6914860230955211
Epoch: 2 | Iteration number: [450/565] 79% | Training loss: 0.6914459658993615
Epoch: 2 | Iteration number: [460/565] 81% | Training loss: 0.6914023833430332
Epoch: 2 | Iteration number: [470/565] 83% | Training loss: 0.6913686441614273
Epoch: 2 | Iteration number: [480/565] 84% | Training loss: 0.6913338585446278
Epoch: 2 | Iteration number: [490/565] 86% | Training loss: 0.6913072260058656
Epoch: 2 | Iteration number: [500/565] 88% | Training loss: 0.6912760473489762
Epoch: 2 | Iteration number: [510/565] 90% | Training loss: 0.6912360887901455
Epoch: 2 | Iteration number: [520/565] 92% | Training loss: 0.6912054859674894
Epoch: 2 | Iteration number: [530/565] 93% | Training loss: 0.691171984852485
Epoch: 2 | Iteration number: [540/565] 95% | Training loss: 0.6911324261515229
Epoch: 2 | Iteration number: [550/565] 97% | Training loss: 0.691101755879142
Epoch: 2 | Iteration number: [560/565] 99% | Training loss: 0.6910752029291221

 End of epoch: 2 | Train Loss: 0.6898434990275223 | Training Time: 87 

 End of epoch: 2 | Eval Loss: 0.6914863160678318 | Evaluating Time: 5 
Epoch: 3 | Iteration number: [10/565] 1% | Training loss: 0.7583317339420319
Epoch: 3 | Iteration number: [20/565] 3% | Training loss: 0.723799678683281
Epoch: 3 | Iteration number: [30/565] 5% | Training loss: 0.7123591105143229
Epoch: 3 | Iteration number: [40/565] 7% | Training loss: 0.7066321164369583
Epoch: 3 | Iteration number: [50/565] 8% | Training loss: 0.7031787729263306
Epoch: 3 | Iteration number: [60/565] 10% | Training loss: 0.7009771714607874
Epoch: 3 | Iteration number: [70/565] 12% | Training loss: 0.699245855637959
Epoch: 3 | Iteration number: [80/565] 14% | Training loss: 0.6980293780565262
Epoch: 3 | Iteration number: [90/565] 15% | Training loss: 0.6970494634575314
Epoch: 3 | Iteration number: [100/565] 17% | Training loss: 0.6962590694427491
Epoch: 3 | Iteration number: [110/565] 19% | Training loss: 0.695606118440628
Epoch: 3 | Iteration number: [120/565] 21% | Training loss: 0.6950964401165645
Epoch: 3 | Iteration number: [130/565] 23% | Training loss: 0.6946069987920614
Epoch: 3 | Iteration number: [140/565] 24% | Training loss: 0.6942282153027398
Epoch: 3 | Iteration number: [150/565] 26% | Training loss: 0.6938821053504944
Epoch: 3 | Iteration number: [160/565] 28% | Training loss: 0.6935738045722246
Epoch: 3 | Iteration number: [170/565] 30% | Training loss: 0.6932921833851758
Epoch: 3 | Iteration number: [180/565] 31% | Training loss: 0.6930490112966962
Epoch: 3 | Iteration number: [190/565] 33% | Training loss: 0.6928477858242236
Epoch: 3 | Iteration number: [200/565] 35% | Training loss: 0.6926571655273438
Epoch: 3 | Iteration number: [210/565] 37% | Training loss: 0.6925171432040986
Epoch: 3 | Iteration number: [220/565] 38% | Training loss: 0.6923634008927779
Epoch: 3 | Iteration number: [230/565] 40% | Training loss: 0.692221860004508
Epoch: 3 | Iteration number: [240/565] 42% | Training loss: 0.6921042027572791
Epoch: 3 | Iteration number: [250/565] 44% | Training loss: 0.6919653460979461
Epoch: 3 | Iteration number: [260/565] 46% | Training loss: 0.6918611732813028
Epoch: 3 | Iteration number: [270/565] 47% | Training loss: 0.6917522576120164
Epoch: 3 | Iteration number: [280/565] 49% | Training loss: 0.6916437962225506
Epoch: 3 | Iteration number: [290/565] 51% | Training loss: 0.6915611373967138
Epoch: 3 | Iteration number: [300/565] 53% | Training loss: 0.6914759025971094
Epoch: 3 | Iteration number: [310/565] 54% | Training loss: 0.6913978670873949
Epoch: 3 | Iteration number: [320/565] 56% | Training loss: 0.6913181034848094
Epoch: 3 | Iteration number: [330/565] 58% | Training loss: 0.6912606728799415
Epoch: 3 | Iteration number: [340/565] 60% | Training loss: 0.6911875332103056
Epoch: 3 | Iteration number: [350/565] 61% | Training loss: 0.6911320500714438
Epoch: 3 | Iteration number: [360/565] 63% | Training loss: 0.6910752519965172
Epoch: 3 | Iteration number: [370/565] 65% | Training loss: 0.6910094009863363
Epoch: 3 | Iteration number: [380/565] 67% | Training loss: 0.6909545815304706
Epoch: 3 | Iteration number: [390/565] 69% | Training loss: 0.6909062564373016
Epoch: 3 | Iteration number: [400/565] 70% | Training loss: 0.6908540071547031
Epoch: 3 | Iteration number: [410/565] 72% | Training loss: 0.6908068148101248
Epoch: 3 | Iteration number: [420/565] 74% | Training loss: 0.6907604000398091
Epoch: 3 | Iteration number: [430/565] 76% | Training loss: 0.6907190041486607
Epoch: 3 | Iteration number: [440/565] 77% | Training loss: 0.6906785753640261
Epoch: 3 | Iteration number: [450/565] 79% | Training loss: 0.6906420297092861
Epoch: 3 | Iteration number: [460/565] 81% | Training loss: 0.6905924791875093
Epoch: 3 | Iteration number: [470/565] 83% | Training loss: 0.6905623214041933
Epoch: 3 | Iteration number: [480/565] 84% | Training loss: 0.6905252188444138
Epoch: 3 | Iteration number: [490/565] 86% | Training loss: 0.6904791559491839
Epoch: 3 | Iteration number: [500/565] 88% | Training loss: 0.6904546000957489
Epoch: 3 | Iteration number: [510/565] 90% | Training loss: 0.6904234574121587
Epoch: 3 | Iteration number: [520/565] 92% | Training loss: 0.6903895522539433
Epoch: 3 | Iteration number: [530/565] 93% | Training loss: 0.6903519656298296
Epoch: 3 | Iteration number: [540/565] 95% | Training loss: 0.6903280297915141
Epoch: 3 | Iteration number: [550/565] 97% | Training loss: 0.6903030849586833
Epoch: 3 | Iteration number: [560/565] 99% | Training loss: 0.6902729102543422

 End of epoch: 3 | Train Loss: 0.6890418510521408 | Training Time: 88 

 End of epoch: 3 | Eval Loss: 0.6912203005381993 | Evaluating Time: 5 
Epoch: 4 | Iteration number: [10/565] 1% | Training loss: 0.7575809776782989
Epoch: 4 | Iteration number: [20/565] 3% | Training loss: 0.7230398565530777
Epoch: 4 | Iteration number: [30/565] 5% | Training loss: 0.7115269124507904
Epoch: 4 | Iteration number: [40/565] 7% | Training loss: 0.7058157876133919
Epoch: 4 | Iteration number: [50/565] 8% | Training loss: 0.7023932206630706
Epoch: 4 | Iteration number: [60/565] 10% | Training loss: 0.7000970592101415
Epoch: 4 | Iteration number: [70/565] 12% | Training loss: 0.6984710233552115
Epoch: 4 | Iteration number: [80/565] 14% | Training loss: 0.697247214615345
Epoch: 4 | Iteration number: [90/565] 15% | Training loss: 0.6963158713446723
Epoch: 4 | Iteration number: [100/565] 17% | Training loss: 0.6955286586284637
Epoch: 4 | Iteration number: [110/565] 19% | Training loss: 0.6949478219855916
Epoch: 4 | Iteration number: [120/565] 21% | Training loss: 0.6944475829601288
Epoch: 4 | Iteration number: [130/565] 23% | Training loss: 0.6939822320754712
Epoch: 4 | Iteration number: [140/565] 24% | Training loss: 0.6935949236154556
Epoch: 4 | Iteration number: [150/565] 26% | Training loss: 0.693293819030126
Epoch: 4 | Iteration number: [160/565] 28% | Training loss: 0.6930020097643137
Epoch: 4 | Iteration number: [170/565] 30% | Training loss: 0.6927274318302379
Epoch: 4 | Iteration number: [180/565] 31% | Training loss: 0.6925022211339739
Epoch: 4 | Iteration number: [190/565] 33% | Training loss: 0.6922712818572395
Epoch: 4 | Iteration number: [200/565] 35% | Training loss: 0.6920662513375282
Epoch: 4 | Iteration number: [210/565] 37% | Training loss: 0.6918916520618257
Epoch: 4 | Iteration number: [220/565] 38% | Training loss: 0.6917432877150449
Epoch: 4 | Iteration number: [230/565] 40% | Training loss: 0.6916107664937559
Epoch: 4 | Iteration number: [240/565] 42% | Training loss: 0.691492089132468
Epoch: 4 | Iteration number: [250/565] 44% | Training loss: 0.6913662576675415
Epoch: 4 | Iteration number: [260/565] 46% | Training loss: 0.6912524823959058
Epoch: 4 | Iteration number: [270/565] 47% | Training loss: 0.691144546976796
Epoch: 4 | Iteration number: [280/565] 49% | Training loss: 0.6910572782158851
Epoch: 4 | Iteration number: [290/565] 51% | Training loss: 0.6909559543790489
Epoch: 4 | Iteration number: [300/565] 53% | Training loss: 0.690875572959582
Epoch: 4 | Iteration number: [310/565] 54% | Training loss: 0.6908044663167769
Epoch: 4 | Iteration number: [320/565] 56% | Training loss: 0.6907339775934815
Epoch: 4 | Iteration number: [330/565] 58% | Training loss: 0.6906587768684734
Epoch: 4 | Iteration number: [340/565] 60% | Training loss: 0.6906071233398774
Epoch: 4 | Iteration number: [350/565] 61% | Training loss: 0.6905542572907039
Epoch: 4 | Iteration number: [360/565] 63% | Training loss: 0.6904942754242155
Epoch: 4 | Iteration number: [370/565] 65% | Training loss: 0.690436211953292
Epoch: 4 | Iteration number: [380/565] 67% | Training loss: 0.6903882512920781
Epoch: 4 | Iteration number: [390/565] 69% | Training loss: 0.6903320778638888
Epoch: 4 | Iteration number: [400/565] 70% | Training loss: 0.6902773590385913
Epoch: 4 | Iteration number: [410/565] 72% | Training loss: 0.6902303207211378
Epoch: 4 | Iteration number: [420/565] 74% | Training loss: 0.6902070248410815
Epoch: 4 | Iteration number: [430/565] 76% | Training loss: 0.6901771115702252
Epoch: 4 | Iteration number: [440/565] 77% | Training loss: 0.6901301761919801
Epoch: 4 | Iteration number: [450/565] 79% | Training loss: 0.6901013384924994
Epoch: 4 | Iteration number: [460/565] 81% | Training loss: 0.6900747328996658
Epoch: 4 | Iteration number: [470/565] 83% | Training loss: 0.6900368606790583
Epoch: 4 | Iteration number: [480/565] 84% | Training loss: 0.6900036637981732
Epoch: 4 | Iteration number: [490/565] 86% | Training loss: 0.689965025259524
Epoch: 4 | Iteration number: [500/565] 88% | Training loss: 0.6899377634525299
Epoch: 4 | Iteration number: [510/565] 90% | Training loss: 0.6899032425646688
Epoch: 4 | Iteration number: [520/565] 92% | Training loss: 0.6898745471468338
Epoch: 4 | Iteration number: [530/565] 93% | Training loss: 0.6898494893649839
Epoch: 4 | Iteration number: [540/565] 95% | Training loss: 0.6898211855579306
Epoch: 4 | Iteration number: [550/565] 97% | Training loss: 0.6897917607697573
Epoch: 4 | Iteration number: [560/565] 99% | Training loss: 0.6897687053041799

 End of epoch: 4 | Train Loss: 0.6885390751129759 | Training Time: 90 

 End of epoch: 4 | Eval Loss: 0.69110221522195 | Evaluating Time: 6 
Epoch: 5 | Iteration number: [10/565] 1% | Training loss: 0.7568691372871399
Epoch: 5 | Iteration number: [20/565] 3% | Training loss: 0.7227869838476181
Epoch: 5 | Iteration number: [30/565] 5% | Training loss: 0.7113341947396596
Epoch: 5 | Iteration number: [40/565] 7% | Training loss: 0.7056209906935692
Epoch: 5 | Iteration number: [50/565] 8% | Training loss: 0.7021691465377807
Epoch: 5 | Iteration number: [60/565] 10% | Training loss: 0.6998344053824742
Epoch: 5 | Iteration number: [70/565] 12% | Training loss: 0.6981515569346292
Epoch: 5 | Iteration number: [80/565] 14% | Training loss: 0.6969082839787006
Epoch: 5 | Iteration number: [90/565] 15% | Training loss: 0.6958944671683841
Epoch: 5 | Iteration number: [100/565] 17% | Training loss: 0.6951225131750107
Epoch: 5 | Iteration number: [110/565] 19% | Training loss: 0.694459669156508
Epoch: 5 | Iteration number: [120/565] 21% | Training loss: 0.6939844757318496
Epoch: 5 | Iteration number: [130/565] 23% | Training loss: 0.6935337479297932
Epoch: 5 | Iteration number: [140/565] 24% | Training loss: 0.6931837282010487
Epoch: 5 | Iteration number: [150/565] 26% | Training loss: 0.6928377517064412
Epoch: 5 | Iteration number: [160/565] 28% | Training loss: 0.6925482962280511
Epoch: 5 | Iteration number: [170/565] 30% | Training loss: 0.6922906854573418
Epoch: 5 | Iteration number: [180/565] 31% | Training loss: 0.692055606842041
Epoch: 5 | Iteration number: [190/565] 33% | Training loss: 0.6918610591637461
Epoch: 5 | Iteration number: [200/565] 35% | Training loss: 0.6916450217366219
Epoch: 5 | Iteration number: [210/565] 37% | Training loss: 0.691503457796006
Epoch: 5 | Iteration number: [220/565] 38% | Training loss: 0.6913608694618398
Epoch: 5 | Iteration number: [230/565] 40% | Training loss: 0.6912160818991454
Epoch: 5 | Iteration number: [240/565] 42% | Training loss: 0.6911003313958645
Epoch: 5 | Iteration number: [250/565] 44% | Training loss: 0.6909799847602844
Epoch: 5 | Iteration number: [260/565] 46% | Training loss: 0.6908798976586416
Epoch: 5 | Iteration number: [270/565] 47% | Training loss: 0.6907701673331084
Epoch: 5 | Iteration number: [280/565] 49% | Training loss: 0.6906913220882416
Epoch: 5 | Iteration number: [290/565] 51% | Training loss: 0.6906180414660223
Epoch: 5 | Iteration number: [300/565] 53% | Training loss: 0.6905372178554535
Epoch: 5 | Iteration number: [310/565] 54% | Training loss: 0.6904507938892611
Epoch: 5 | Iteration number: [320/565] 56% | Training loss: 0.6903751267120242
Epoch: 5 | Iteration number: [330/565] 58% | Training loss: 0.6902952273686727
Epoch: 5 | Iteration number: [340/565] 60% | Training loss: 0.6902366085964091
Epoch: 5 | Iteration number: [350/565] 61% | Training loss: 0.6901762933390481
Epoch: 5 | Iteration number: [360/565] 63% | Training loss: 0.6901073091559939
Epoch: 5 | Iteration number: [370/565] 65% | Training loss: 0.6900492805081445
Epoch: 5 | Iteration number: [380/565] 67% | Training loss: 0.6900075019974458
Epoch: 5 | Iteration number: [390/565] 69% | Training loss: 0.6899710624645918
Epoch: 5 | Iteration number: [400/565] 70% | Training loss: 0.689923038482666
Epoch: 5 | Iteration number: [410/565] 72% | Training loss: 0.6898651376003172
Epoch: 5 | Iteration number: [420/565] 74% | Training loss: 0.6898266877446856
Epoch: 5 | Iteration number: [430/565] 76% | Training loss: 0.6897908202437467
Epoch: 5 | Iteration number: [440/565] 77% | Training loss: 0.6897521938789974
Epoch: 5 | Iteration number: [450/565] 79% | Training loss: 0.6897244687875111
Epoch: 5 | Iteration number: [460/565] 81% | Training loss: 0.6896865927654764
Epoch: 5 | Iteration number: [470/565] 83% | Training loss: 0.6896509356955265
Epoch: 5 | Iteration number: [480/565] 84% | Training loss: 0.6896262504160404
Epoch: 5 | Iteration number: [490/565] 86% | Training loss: 0.689600759623002
Epoch: 5 | Iteration number: [500/565] 88% | Training loss: 0.6895675048828125
Epoch: 5 | Iteration number: [510/565] 90% | Training loss: 0.6895314664232964
Epoch: 5 | Iteration number: [520/565] 92% | Training loss: 0.6895036227427996
Epoch: 5 | Iteration number: [530/565] 93% | Training loss: 0.6894813687171576
Epoch: 5 | Iteration number: [540/565] 95% | Training loss: 0.6894548656763854
Epoch: 5 | Iteration number: [550/565] 97% | Training loss: 0.6894352026419206
Epoch: 5 | Iteration number: [560/565] 99% | Training loss: 0.6894098309533937

 End of epoch: 5 | Train Loss: 0.6881794477986023 | Training Time: 90 

 End of epoch: 5 | Eval Loss: 0.6902123859950474 | Evaluating Time: 6 
Epoch: 6 | Iteration number: [10/565] 1% | Training loss: 0.7565373122692108
Epoch: 6 | Iteration number: [20/565] 3% | Training loss: 0.7223603934049606
Epoch: 6 | Iteration number: [30/565] 5% | Training loss: 0.7108874917030334
Epoch: 6 | Iteration number: [40/565] 7% | Training loss: 0.7051384776830674
Epoch: 6 | Iteration number: [50/565] 8% | Training loss: 0.7017028415203095
Epoch: 6 | Iteration number: [60/565] 10% | Training loss: 0.6993847548961639
Epoch: 6 | Iteration number: [70/565] 12% | Training loss: 0.697747358254024
Epoch: 6 | Iteration number: [80/565] 14% | Training loss: 0.6965541303157806
Epoch: 6 | Iteration number: [90/565] 15% | Training loss: 0.6956707312001122
Epoch: 6 | Iteration number: [100/565] 17% | Training loss: 0.6948901867866516
Epoch: 6 | Iteration number: [110/565] 19% | Training loss: 0.6942793526432731
Epoch: 6 | Iteration number: [120/565] 21% | Training loss: 0.6937262922525406
Epoch: 6 | Iteration number: [130/565] 23% | Training loss: 0.6932868645741389
Epoch: 6 | Iteration number: [140/565] 24% | Training loss: 0.6928711329187666
Epoch: 6 | Iteration number: [150/565] 26% | Training loss: 0.69253622174263
Epoch: 6 | Iteration number: [160/565] 28% | Training loss: 0.6922730181366206
Epoch: 6 | Iteration number: [170/565] 30% | Training loss: 0.6920145231134751
Epoch: 6 | Iteration number: [180/565] 31% | Training loss: 0.6918115360869301
Epoch: 6 | Iteration number: [190/565] 33% | Training loss: 0.6916129833773563
Epoch: 6 | Iteration number: [200/565] 35% | Training loss: 0.6914387202262878
Epoch: 6 | Iteration number: [210/565] 37% | Training loss: 0.6912950873374939
Epoch: 6 | Iteration number: [220/565] 38% | Training loss: 0.6911493537100879
Epoch: 6 | Iteration number: [230/565] 40% | Training loss: 0.6910139990889508
Epoch: 6 | Iteration number: [240/565] 42% | Training loss: 0.6908909618854523
Epoch: 6 | Iteration number: [250/565] 44% | Training loss: 0.6907702004909515
Epoch: 6 | Iteration number: [260/565] 46% | Training loss: 0.6906675893526811
Epoch: 6 | Iteration number: [270/565] 47% | Training loss: 0.6905598591875147
Epoch: 6 | Iteration number: [280/565] 49% | Training loss: 0.6904634435261999
Epoch: 6 | Iteration number: [290/565] 51% | Training loss: 0.6903698873930963
Epoch: 6 | Iteration number: [300/565] 53% | Training loss: 0.6903000915050507
Epoch: 6 | Iteration number: [310/565] 54% | Training loss: 0.6902230801120881
Epoch: 6 | Iteration number: [320/565] 56% | Training loss: 0.6901482237502933
Epoch: 6 | Iteration number: [330/565] 58% | Training loss: 0.6900809878652746
Epoch: 6 | Iteration number: [340/565] 60% | Training loss: 0.6900052884045769
Epoch: 6 | Iteration number: [350/565] 61% | Training loss: 0.6899475242410388
Epoch: 6 | Iteration number: [360/565] 63% | Training loss: 0.6898952503999074
Epoch: 6 | Iteration number: [370/565] 65% | Training loss: 0.6898320502526051
Epoch: 6 | Iteration number: [380/565] 67% | Training loss: 0.6897890095648013
Epoch: 6 | Iteration number: [390/565] 69% | Training loss: 0.6897311057799902
Epoch: 6 | Iteration number: [400/565] 70% | Training loss: 0.6896860951185226
Epoch: 6 | Iteration number: [410/565] 72% | Training loss: 0.6896491530464917
Epoch: 6 | Iteration number: [420/565] 74% | Training loss: 0.6896010576259523
Epoch: 6 | Iteration number: [430/565] 76% | Training loss: 0.6895625939202863
Epoch: 6 | Iteration number: [440/565] 77% | Training loss: 0.6895177590576085
Epoch: 6 | Iteration number: [450/565] 79% | Training loss: 0.6894771598445044
Epoch: 6 | Iteration number: [460/565] 81% | Training loss: 0.6894439587126607
Epoch: 6 | Iteration number: [470/565] 83% | Training loss: 0.6894028486089504
Epoch: 6 | Iteration number: [480/565] 84% | Training loss: 0.6893713364998499
Epoch: 6 | Iteration number: [490/565] 86% | Training loss: 0.6893349122027962
Epoch: 6 | Iteration number: [500/565] 88% | Training loss: 0.6892940014600754
Epoch: 6 | Iteration number: [510/565] 90% | Training loss: 0.6892698359255697
Epoch: 6 | Iteration number: [520/565] 92% | Training loss: 0.6892359318641516
Epoch: 6 | Iteration number: [530/565] 93% | Training loss: 0.6892032716634139
Epoch: 6 | Iteration number: [540/565] 95% | Training loss: 0.6891812537555342
Epoch: 6 | Iteration number: [550/565] 97% | Training loss: 0.6891491769660603
Epoch: 6 | Iteration number: [560/565] 99% | Training loss: 0.6891288683882781

 End of epoch: 6 | Train Loss: 0.6879023328291631 | Training Time: 89 

 End of epoch: 6 | Eval Loss: 0.6905266216823033 | Evaluating Time: 6 
Epoch: 7 | Iteration number: [10/565] 1% | Training loss: 0.7564613223075867
Epoch: 7 | Iteration number: [20/565] 3% | Training loss: 0.7221211791038513
Epoch: 7 | Iteration number: [30/565] 5% | Training loss: 0.7106836040814718
Epoch: 7 | Iteration number: [40/565] 7% | Training loss: 0.7049547657370567
Epoch: 7 | Iteration number: [50/565] 8% | Training loss: 0.7014931845664978
Epoch: 7 | Iteration number: [60/565] 10% | Training loss: 0.6991462558507919
Epoch: 7 | Iteration number: [70/565] 12% | Training loss: 0.697551292181015
Epoch: 7 | Iteration number: [80/565] 14% | Training loss: 0.6963119804859161
Epoch: 7 | Iteration number: [90/565] 15% | Training loss: 0.6953729053338369
Epoch: 7 | Iteration number: [100/565] 17% | Training loss: 0.6946092689037323
Epoch: 7 | Iteration number: [110/565] 19% | Training loss: 0.6939979043873874
Epoch: 7 | Iteration number: [120/565] 21% | Training loss: 0.6934482182065645
Epoch: 7 | Iteration number: [130/565] 23% | Training loss: 0.6930107465157143
Epoch: 7 | Iteration number: [140/565] 24% | Training loss: 0.6926788457802364
Epoch: 7 | Iteration number: [150/565] 26% | Training loss: 0.6923903683821361
Epoch: 7 | Iteration number: [160/565] 28% | Training loss: 0.6920867070555687
Epoch: 7 | Iteration number: [170/565] 30% | Training loss: 0.6918310274096097
Epoch: 7 | Iteration number: [180/565] 31% | Training loss: 0.6916078050931295
Epoch: 7 | Iteration number: [190/565] 33% | Training loss: 0.6913993283321983
Epoch: 7 | Iteration number: [200/565] 35% | Training loss: 0.6912230810523033
Epoch: 7 | Iteration number: [210/565] 37% | Training loss: 0.6910580283119565
Epoch: 7 | Iteration number: [220/565] 38% | Training loss: 0.6908984249288386
Epoch: 7 | Iteration number: [230/565] 40% | Training loss: 0.690754592936972
Epoch: 7 | Iteration number: [240/565] 42% | Training loss: 0.6906330399215221
Epoch: 7 | Iteration number: [250/565] 44% | Training loss: 0.6905113160610199
Epoch: 7 | Iteration number: [260/565] 46% | Training loss: 0.6904027095207801
Epoch: 7 | Iteration number: [270/565] 47% | Training loss: 0.6902925074100494
Epoch: 7 | Iteration number: [280/565] 49% | Training loss: 0.690180121575083
Epoch: 7 | Iteration number: [290/565] 51% | Training loss: 0.6900781674631711
Epoch: 7 | Iteration number: [300/565] 53% | Training loss: 0.689997349580129
Epoch: 7 | Iteration number: [310/565] 54% | Training loss: 0.6899288235172149
Epoch: 7 | Iteration number: [320/565] 56% | Training loss: 0.6898631909862161
Epoch: 7 | Iteration number: [330/565] 58% | Training loss: 0.6897940789208268
Epoch: 7 | Iteration number: [340/565] 60% | Training loss: 0.6897317812723271
Epoch: 7 | Iteration number: [350/565] 61% | Training loss: 0.6896803774152483
Epoch: 7 | Iteration number: [360/565] 63% | Training loss: 0.6896264006694158
Epoch: 7 | Iteration number: [370/565] 65% | Training loss: 0.6895835509171357
Epoch: 7 | Iteration number: [380/565] 67% | Training loss: 0.6895428248141942
Epoch: 7 | Iteration number: [390/565] 69% | Training loss: 0.6894922961027194
Epoch: 7 | Iteration number: [400/565] 70% | Training loss: 0.6894543884694576
Epoch: 7 | Iteration number: [410/565] 72% | Training loss: 0.6894121981248623
Epoch: 7 | Iteration number: [420/565] 74% | Training loss: 0.6893765638271968
Epoch: 7 | Iteration number: [430/565] 76% | Training loss: 0.6893420535464619
Epoch: 7 | Iteration number: [440/565] 77% | Training loss: 0.6893053612925789
Epoch: 7 | Iteration number: [450/565] 79% | Training loss: 0.6892561075422499
Epoch: 7 | Iteration number: [460/565] 81% | Training loss: 0.6892186573018199
Epoch: 7 | Iteration number: [470/565] 83% | Training loss: 0.6891829989057906
Epoch: 7 | Iteration number: [480/565] 84% | Training loss: 0.6891485188156367
Epoch: 7 | Iteration number: [490/565] 86% | Training loss: 0.6891200312546322
Epoch: 7 | Iteration number: [500/565] 88% | Training loss: 0.6890982825756073
Epoch: 7 | Iteration number: [510/565] 90% | Training loss: 0.6890749760702545
Epoch: 7 | Iteration number: [520/565] 92% | Training loss: 0.6890606324260051
Epoch: 7 | Iteration number: [530/565] 93% | Training loss: 0.6890315563048957
Epoch: 7 | Iteration number: [540/565] 95% | Training loss: 0.6890093695234369
Epoch: 7 | Iteration number: [550/565] 97% | Training loss: 0.6889947814291174
Epoch: 7 | Iteration number: [560/565] 99% | Training loss: 0.6889748200774193

 End of epoch: 7 | Train Loss: 0.687748248387227 | Training Time: 90 

 End of epoch: 7 | Eval Loss: 0.6907137887818473 | Evaluating Time: 6 
Epoch: 8 | Iteration number: [10/565] 1% | Training loss: 0.7565986692905426
Epoch: 8 | Iteration number: [20/565] 3% | Training loss: 0.7220745652914047
Epoch: 8 | Iteration number: [30/565] 5% | Training loss: 0.7104530513286591
Epoch: 8 | Iteration number: [40/565] 7% | Training loss: 0.7047568589448929
Epoch: 8 | Iteration number: [50/565] 8% | Training loss: 0.7012601864337921
Epoch: 8 | Iteration number: [60/565] 10% | Training loss: 0.6990244766076406
Epoch: 8 | Iteration number: [70/565] 12% | Training loss: 0.6974408481802259
Epoch: 8 | Iteration number: [80/565] 14% | Training loss: 0.6961769126355648
Epoch: 8 | Iteration number: [90/565] 15% | Training loss: 0.6951346099376678
Epoch: 8 | Iteration number: [100/565] 17% | Training loss: 0.6944222313165664
Epoch: 8 | Iteration number: [110/565] 19% | Training loss: 0.6938128964467483
Epoch: 8 | Iteration number: [120/565] 21% | Training loss: 0.6933143650492032
Epoch: 8 | Iteration number: [130/565] 23% | Training loss: 0.6928894620675307
Epoch: 8 | Iteration number: [140/565] 24% | Training loss: 0.6925080401556832
Epoch: 8 | Iteration number: [150/565] 26% | Training loss: 0.6921573527654012
Epoch: 8 | Iteration number: [160/565] 28% | Training loss: 0.6918708000332117
Epoch: 8 | Iteration number: [170/565] 30% | Training loss: 0.6916300408980426
Epoch: 8 | Iteration number: [180/565] 31% | Training loss: 0.6914315942260955
Epoch: 8 | Iteration number: [190/565] 33% | Training loss: 0.6912364708749872
Epoch: 8 | Iteration number: [200/565] 35% | Training loss: 0.6910436755418777
Epoch: 8 | Iteration number: [210/565] 37% | Training loss: 0.6908752634411767
Epoch: 8 | Iteration number: [220/565] 38% | Training loss: 0.6907216714187102
Epoch: 8 | Iteration number: [230/565] 40% | Training loss: 0.6906020275924517
Epoch: 8 | Iteration number: [240/565] 42% | Training loss: 0.6904863168795904
Epoch: 8 | Iteration number: [250/565] 44% | Training loss: 0.6903877248764038
Epoch: 8 | Iteration number: [260/565] 46% | Training loss: 0.6902692223970707
Epoch: 8 | Iteration number: [270/565] 47% | Training loss: 0.6901539533226578
Epoch: 8 | Iteration number: [280/565] 49% | Training loss: 0.6900657655937331
Epoch: 8 | Iteration number: [290/565] 51% | Training loss: 0.6899902896634463
Epoch: 8 | Iteration number: [300/565] 53% | Training loss: 0.6899084156751633
Epoch: 8 | Iteration number: [310/565] 54% | Training loss: 0.6898420097366456
Epoch: 8 | Iteration number: [320/565] 56% | Training loss: 0.689776442758739
Epoch: 8 | Iteration number: [330/565] 58% | Training loss: 0.6897153319734516
Epoch: 8 | Iteration number: [340/565] 60% | Training loss: 0.689643974163953
Epoch: 8 | Iteration number: [350/565] 61% | Training loss: 0.689578241620745
Epoch: 8 | Iteration number: [360/565] 63% | Training loss: 0.6895186957385805
Epoch: 8 | Iteration number: [370/565] 65% | Training loss: 0.6894649971175838
Epoch: 8 | Iteration number: [380/565] 67% | Training loss: 0.6894224858597705
Epoch: 8 | Iteration number: [390/565] 69% | Training loss: 0.6893797574899135
Epoch: 8 | Iteration number: [400/565] 70% | Training loss: 0.6893384486436844
Epoch: 8 | Iteration number: [410/565] 72% | Training loss: 0.6893024869081451
Epoch: 8 | Iteration number: [420/565] 74% | Training loss: 0.6892637278352465
Epoch: 8 | Iteration number: [430/565] 76% | Training loss: 0.6892339882462524
Epoch: 8 | Iteration number: [440/565] 77% | Training loss: 0.6891940080306747
Epoch: 8 | Iteration number: [450/565] 79% | Training loss: 0.6891651690006256
Epoch: 8 | Iteration number: [460/565] 81% | Training loss: 0.6891294755365538
Epoch: 8 | Iteration number: [470/565] 83% | Training loss: 0.6890995300830679
Epoch: 8 | Iteration number: [480/565] 84% | Training loss: 0.6890575841069222
Epoch: 8 | Iteration number: [490/565] 86% | Training loss: 0.689031405473242
Epoch: 8 | Iteration number: [500/565] 88% | Training loss: 0.6889997968673706
Epoch: 8 | Iteration number: [510/565] 90% | Training loss: 0.6889714045851838
Epoch: 8 | Iteration number: [520/565] 92% | Training loss: 0.6889405757188797
Epoch: 8 | Iteration number: [530/565] 93% | Training loss: 0.688919901397993
Epoch: 8 | Iteration number: [540/565] 95% | Training loss: 0.6888955997096168
Epoch: 8 | Iteration number: [550/565] 97% | Training loss: 0.6888672758232464
Epoch: 8 | Iteration number: [560/565] 99% | Training loss: 0.6888456213687147

 End of epoch: 8 | Train Loss: 0.6876167237231162 | Training Time: 88 

 End of epoch: 8 | Eval Loss: 0.6901198540415082 | Evaluating Time: 6 
Epoch: 9 | Iteration number: [10/565] 1% | Training loss: 0.756536340713501
Epoch: 9 | Iteration number: [20/565] 3% | Training loss: 0.7222195565700531
Epoch: 9 | Iteration number: [30/565] 5% | Training loss: 0.7106281121571859
Epoch: 9 | Iteration number: [40/565] 7% | Training loss: 0.7047749862074852
Epoch: 9 | Iteration number: [50/565] 8% | Training loss: 0.7013617932796479
Epoch: 9 | Iteration number: [60/565] 10% | Training loss: 0.6990989913543065
Epoch: 9 | Iteration number: [70/565] 12% | Training loss: 0.6973804439817156
Epoch: 9 | Iteration number: [80/565] 14% | Training loss: 0.6961501359939575
Epoch: 9 | Iteration number: [90/565] 15% | Training loss: 0.6951548529995812
Epoch: 9 | Iteration number: [100/565] 17% | Training loss: 0.6944348150491715
Epoch: 9 | Iteration number: [110/565] 19% | Training loss: 0.6937697107141668
Epoch: 9 | Iteration number: [120/565] 21% | Training loss: 0.6932635436455409
Epoch: 9 | Iteration number: [130/565] 23% | Training loss: 0.6927951432191408
Epoch: 9 | Iteration number: [140/565] 24% | Training loss: 0.6924132202352796
Epoch: 9 | Iteration number: [150/565] 26% | Training loss: 0.6920716063181559
Epoch: 9 | Iteration number: [160/565] 28% | Training loss: 0.6918079692870378
Epoch: 9 | Iteration number: [170/565] 30% | Training loss: 0.6915627342813155
Epoch: 9 | Iteration number: [180/565] 31% | Training loss: 0.6913229905896716
Epoch: 9 | Iteration number: [190/565] 33% | Training loss: 0.691101765005212
Epoch: 9 | Iteration number: [200/565] 35% | Training loss: 0.6909443357586861
Epoch: 9 | Iteration number: [210/565] 37% | Training loss: 0.6907926170598893
Epoch: 9 | Iteration number: [220/565] 38% | Training loss: 0.6906257930127058
Epoch: 9 | Iteration number: [230/565] 40% | Training loss: 0.6904927002347034
Epoch: 9 | Iteration number: [240/565] 42% | Training loss: 0.6903523596624533
Epoch: 9 | Iteration number: [250/565] 44% | Training loss: 0.6902699458599091
Epoch: 9 | Iteration number: [260/565] 46% | Training loss: 0.6901644025857632
Epoch: 9 | Iteration number: [270/565] 47% | Training loss: 0.6900508262492993
Epoch: 9 | Iteration number: [280/565] 49% | Training loss: 0.689958898297378
Epoch: 9 | Iteration number: [290/565] 51% | Training loss: 0.6898795380674559
Epoch: 9 | Iteration number: [300/565] 53% | Training loss: 0.6898055380582809
Epoch: 9 | Iteration number: [310/565] 54% | Training loss: 0.6897214595348604
Epoch: 9 | Iteration number: [320/565] 56% | Training loss: 0.6896513206884265
Epoch: 9 | Iteration number: [330/565] 58% | Training loss: 0.6895920386820128
Epoch: 9 | Iteration number: [340/565] 60% | Training loss: 0.6895318601061317
Epoch: 9 | Iteration number: [350/565] 61% | Training loss: 0.689478212424687
Epoch: 9 | Iteration number: [360/565] 63% | Training loss: 0.689420689145724
Epoch: 9 | Iteration number: [370/565] 65% | Training loss: 0.6893702144558366
Epoch: 9 | Iteration number: [380/565] 67% | Training loss: 0.6893240845517108
Epoch: 9 | Iteration number: [390/565] 69% | Training loss: 0.6892706403365502
Epoch: 9 | Iteration number: [400/565] 70% | Training loss: 0.6892311660945416
Epoch: 9 | Iteration number: [410/565] 72% | Training loss: 0.6891831424178146
Epoch: 9 | Iteration number: [420/565] 74% | Training loss: 0.6891305316062201
Epoch: 9 | Iteration number: [430/565] 76% | Training loss: 0.689080592366152
Epoch: 9 | Iteration number: [440/565] 77% | Training loss: 0.6890328389677134
Epoch: 9 | Iteration number: [450/565] 79% | Training loss: 0.6889997050497267
Epoch: 9 | Iteration number: [460/565] 81% | Training loss: 0.688963821919068
Epoch: 9 | Iteration number: [470/565] 83% | Training loss: 0.6889388702017196
Epoch: 9 | Iteration number: [480/565] 84% | Training loss: 0.688903450469176
Epoch: 9 | Iteration number: [490/565] 86% | Training loss: 0.6888754781411619
Epoch: 9 | Iteration number: [500/565] 88% | Training loss: 0.688848100066185
Epoch: 9 | Iteration number: [510/565] 90% | Training loss: 0.6888151687734267
Epoch: 9 | Iteration number: [520/565] 92% | Training loss: 0.6887937577871176
Epoch: 9 | Iteration number: [530/565] 93% | Training loss: 0.6887591986161358
Epoch: 9 | Iteration number: [540/565] 95% | Training loss: 0.6887391123506758
Epoch: 9 | Iteration number: [550/565] 97% | Training loss: 0.6887216273221103
Epoch: 9 | Iteration number: [560/565] 99% | Training loss: 0.6886978101517472

 End of epoch: 9 | Train Loss: 0.6874707803262019 | Training Time: 89 

 End of epoch: 9 | Eval Loss: 0.6901718207768032 | Evaluating Time: 6 
Epoch: 10 | Iteration number: [10/565] 1% | Training loss: 0.7562344491481781
Epoch: 10 | Iteration number: [20/565] 3% | Training loss: 0.7221394121646881
Epoch: 10 | Iteration number: [30/565] 5% | Training loss: 0.7106360852718353
Epoch: 10 | Iteration number: [40/565] 7% | Training loss: 0.7048928797245025
Epoch: 10 | Iteration number: [50/565] 8% | Training loss: 0.7013792181015015
Epoch: 10 | Iteration number: [60/565] 10% | Training loss: 0.698937115073204
Epoch: 10 | Iteration number: [70/565] 12% | Training loss: 0.6972563198634556
Epoch: 10 | Iteration number: [80/565] 14% | Training loss: 0.6961092434823513
Epoch: 10 | Iteration number: [90/565] 15% | Training loss: 0.6951402412520514
Epoch: 10 | Iteration number: [100/565] 17% | Training loss: 0.6944014793634414
Epoch: 10 | Iteration number: [110/565] 19% | Training loss: 0.693748985637318
Epoch: 10 | Iteration number: [120/565] 21% | Training loss: 0.6931940635045369
Epoch: 10 | Iteration number: [130/565] 23% | Training loss: 0.692741255576794
Epoch: 10 | Iteration number: [140/565] 24% | Training loss: 0.6923418249402727
Epoch: 10 | Iteration number: [150/565] 26% | Training loss: 0.6919923023382822
Epoch: 10 | Iteration number: [160/565] 28% | Training loss: 0.691699779778719
Epoch: 10 | Iteration number: [170/565] 30% | Training loss: 0.6914357627139373
Epoch: 10 | Iteration number: [180/565] 31% | Training loss: 0.6911923107173708
Epoch: 10 | Iteration number: [190/565] 33% | Training loss: 0.6909995678224061
Epoch: 10 | Iteration number: [200/565] 35% | Training loss: 0.6908128380775451
Epoch: 10 | Iteration number: [210/565] 37% | Training loss: 0.6906540569804963
Epoch: 10 | Iteration number: [220/565] 38% | Training loss: 0.6905085688287561
Epoch: 10 | Iteration number: [230/565] 40% | Training loss: 0.6903819190419238
Epoch: 10 | Iteration number: [240/565] 42% | Training loss: 0.6902506584922473
Epoch: 10 | Iteration number: [250/565] 44% | Training loss: 0.6901281604766846
Epoch: 10 | Iteration number: [260/565] 46% | Training loss: 0.6900225735627687
Epoch: 10 | Iteration number: [270/565] 47% | Training loss: 0.6899338998176433
Epoch: 10 | Iteration number: [280/565] 49% | Training loss: 0.6898472040891648
Epoch: 10 | Iteration number: [290/565] 51% | Training loss: 0.6897597393085216
Epoch: 10 | Iteration number: [300/565] 53% | Training loss: 0.6896787772576014
Epoch: 10 | Iteration number: [310/565] 54% | Training loss: 0.6895980446569381
Epoch: 10 | Iteration number: [320/565] 56% | Training loss: 0.6895284669473767
Epoch: 10 | Iteration number: [330/565] 58% | Training loss: 0.6894616668874567
Epoch: 10 | Iteration number: [340/565] 60% | Training loss: 0.6894164334325229
Epoch: 10 | Iteration number: [350/565] 61% | Training loss: 0.6893530748571668
Epoch: 10 | Iteration number: [360/565] 63% | Training loss: 0.6893004069725672
Epoch: 10 | Iteration number: [370/565] 65% | Training loss: 0.689244575758238
Epoch: 10 | Iteration number: [380/565] 67% | Training loss: 0.6891953258137954
Epoch: 10 | Iteration number: [390/565] 69% | Training loss: 0.6891489719733214
Epoch: 10 | Iteration number: [400/565] 70% | Training loss: 0.6891047336161137
Epoch: 10 | Iteration number: [410/565] 72% | Training loss: 0.6890552591986773
Epoch: 10 | Iteration number: [420/565] 74% | Training loss: 0.6890138623260317
Epoch: 10 | Iteration number: [430/565] 76% | Training loss: 0.6889637698960859
Epoch: 10 | Iteration number: [440/565] 77% | Training loss: 0.6889261320233345
Epoch: 10 | Iteration number: [450/565] 79% | Training loss: 0.6889038186603123
Epoch: 10 | Iteration number: [460/565] 81% | Training loss: 0.6888657646334689
Epoch: 10 | Iteration number: [470/565] 83% | Training loss: 0.6888382195158208
Epoch: 10 | Iteration number: [480/565] 84% | Training loss: 0.6888202330718438
Epoch: 10 | Iteration number: [490/565] 86% | Training loss: 0.6887929534425541
Epoch: 10 | Iteration number: [500/565] 88% | Training loss: 0.6887619495391846
Epoch: 10 | Iteration number: [510/565] 90% | Training loss: 0.6887236742412343
Epoch: 10 | Iteration number: [520/565] 92% | Training loss: 0.6886988710898619
Epoch: 10 | Iteration number: [530/565] 93% | Training loss: 0.6886748653537822
Epoch: 10 | Iteration number: [540/565] 95% | Training loss: 0.688649336165852
Epoch: 10 | Iteration number: [550/565] 97% | Training loss: 0.688627872358669
Epoch: 10 | Iteration number: [560/565] 99% | Training loss: 0.6886175688888345

 End of epoch: 10 | Train Loss: 0.687389038305367 | Training Time: 89 

 End of epoch: 10 | Eval Loss: 0.6903513669967651 | Evaluating Time: 6 
Epoch: 11 | Iteration number: [10/565] 1% | Training loss: 0.756400752067566
Epoch: 11 | Iteration number: [20/565] 3% | Training loss: 0.7218930780887604
Epoch: 11 | Iteration number: [30/565] 5% | Training loss: 0.7103514989217122
Epoch: 11 | Iteration number: [40/565] 7% | Training loss: 0.7046109974384308
Epoch: 11 | Iteration number: [50/565] 8% | Training loss: 0.7011423802375794
Epoch: 11 | Iteration number: [60/565] 10% | Training loss: 0.6988574206829071
Epoch: 11 | Iteration number: [70/565] 12% | Training loss: 0.6972380484853472
Epoch: 11 | Iteration number: [80/565] 14% | Training loss: 0.6959459014236927
Epoch: 11 | Iteration number: [90/565] 15% | Training loss: 0.6949840837054783
Epoch: 11 | Iteration number: [100/565] 17% | Training loss: 0.6942547643184662
Epoch: 11 | Iteration number: [110/565] 19% | Training loss: 0.6936601064421913
Epoch: 11 | Iteration number: [120/565] 21% | Training loss: 0.6931601946552595
Epoch: 11 | Iteration number: [130/565] 23% | Training loss: 0.6927174297662881
Epoch: 11 | Iteration number: [140/565] 24% | Training loss: 0.6923173883131573
Epoch: 11 | Iteration number: [150/565] 26% | Training loss: 0.6919795068105062
Epoch: 11 | Iteration number: [160/565] 28% | Training loss: 0.6916719052940608
Epoch: 11 | Iteration number: [170/565] 30% | Training loss: 0.6913926243782044
Epoch: 11 | Iteration number: [180/565] 31% | Training loss: 0.6911422722869449
Epoch: 11 | Iteration number: [190/565] 33% | Training loss: 0.6909527565303601
Epoch: 11 | Iteration number: [200/565] 35% | Training loss: 0.6907767829298973
Epoch: 11 | Iteration number: [210/565] 37% | Training loss: 0.6906111538410187
Epoch: 11 | Iteration number: [220/565] 38% | Training loss: 0.6904524957591837
Epoch: 11 | Iteration number: [230/565] 40% | Training loss: 0.6902924408083376
Epoch: 11 | Iteration number: [240/565] 42% | Training loss: 0.6901726417243481
Epoch: 11 | Iteration number: [250/565] 44% | Training loss: 0.6900636947154999
Epoch: 11 | Iteration number: [260/565] 46% | Training loss: 0.6899488290915122
Epoch: 11 | Iteration number: [270/565] 47% | Training loss: 0.689852355144642
Epoch: 11 | Iteration number: [280/565] 49% | Training loss: 0.6897629022598266
Epoch: 11 | Iteration number: [290/565] 51% | Training loss: 0.6896851023723339
Epoch: 11 | Iteration number: [300/565] 53% | Training loss: 0.6896008016665777
Epoch: 11 | Iteration number: [310/565] 54% | Training loss: 0.6895163597599152
Epoch: 11 | Iteration number: [320/565] 56% | Training loss: 0.6894529482349754
Epoch: 11 | Iteration number: [330/565] 58% | Training loss: 0.6893811921278635
Epoch: 11 | Iteration number: [340/565] 60% | Training loss: 0.6893073895398308
Epoch: 11 | Iteration number: [350/565] 61% | Training loss: 0.6892525812557765
Epoch: 11 | Iteration number: [360/565] 63% | Training loss: 0.6891988981101248
Epoch: 11 | Iteration number: [370/565] 65% | Training loss: 0.6891476083446193
Epoch: 11 | Iteration number: [380/565] 67% | Training loss: 0.6890985383799202
Epoch: 11 | Iteration number: [390/565] 69% | Training loss: 0.6890571459745749
Epoch: 11 | Iteration number: [400/565] 70% | Training loss: 0.6890174080431462
Epoch: 11 | Iteration number: [410/565] 72% | Training loss: 0.6889786746443771
Epoch: 11 | Iteration number: [420/565] 74% | Training loss: 0.6889346562680744
Epoch: 11 | Iteration number: [430/565] 76% | Training loss: 0.6888998789842739
Epoch: 11 | Iteration number: [440/565] 77% | Training loss: 0.6888649245554751
Epoch: 11 | Iteration number: [450/565] 79% | Training loss: 0.6888245024946
Epoch: 11 | Iteration number: [460/565] 81% | Training loss: 0.6887877354155416
Epoch: 11 | Iteration number: [470/565] 83% | Training loss: 0.6887467025442326
Epoch: 11 | Iteration number: [480/565] 84% | Training loss: 0.6887216980258624
Epoch: 11 | Iteration number: [490/565] 86% | Training loss: 0.6886859249095527
Epoch: 11 | Iteration number: [500/565] 88% | Training loss: 0.6886559145450593
Epoch: 11 | Iteration number: [510/565] 90% | Training loss: 0.6886313120524089
Epoch: 11 | Iteration number: [520/565] 92% | Training loss: 0.6886097191618039
Epoch: 11 | Iteration number: [530/565] 93% | Training loss: 0.6885818096826661
Epoch: 11 | Iteration number: [540/565] 95% | Training loss: 0.688554467536785
Epoch: 11 | Iteration number: [550/565] 97% | Training loss: 0.6885234653949738
Epoch: 11 | Iteration number: [560/565] 99% | Training loss: 0.6885024231459413

 End of epoch: 11 | Train Loss: 0.6872795272717434 | Training Time: 88 

 End of epoch: 11 | Eval Loss: 0.6899506194250924 | Evaluating Time: 6 
Epoch: 12 | Iteration number: [10/565] 1% | Training loss: 0.7555233299732208
Epoch: 12 | Iteration number: [20/565] 3% | Training loss: 0.7212478756904602
Epoch: 12 | Iteration number: [30/565] 5% | Training loss: 0.7098668833573659
Epoch: 12 | Iteration number: [40/565] 7% | Training loss: 0.7041464254260064
Epoch: 12 | Iteration number: [50/565] 8% | Training loss: 0.7007105433940888
Epoch: 12 | Iteration number: [60/565] 10% | Training loss: 0.6984510173400243
Epoch: 12 | Iteration number: [70/565] 12% | Training loss: 0.6968183091708592
Epoch: 12 | Iteration number: [80/565] 14% | Training loss: 0.6956159383058548
Epoch: 12 | Iteration number: [90/565] 15% | Training loss: 0.6946859372986688
Epoch: 12 | Iteration number: [100/565] 17% | Training loss: 0.693941251039505
Epoch: 12 | Iteration number: [110/565] 19% | Training loss: 0.6933446721597152
Epoch: 12 | Iteration number: [120/565] 21% | Training loss: 0.6928421705961227
Epoch: 12 | Iteration number: [130/565] 23% | Training loss: 0.6924023059698251
Epoch: 12 | Iteration number: [140/565] 24% | Training loss: 0.6920264886958258
Epoch: 12 | Iteration number: [150/565] 26% | Training loss: 0.6917053580284118
Epoch: 12 | Iteration number: [160/565] 28% | Training loss: 0.6914325635880232
Epoch: 12 | Iteration number: [170/565] 30% | Training loss: 0.691187859282774
Epoch: 12 | Iteration number: [180/565] 31% | Training loss: 0.6909615543153551
Epoch: 12 | Iteration number: [190/565] 33% | Training loss: 0.6907788769194955
Epoch: 12 | Iteration number: [200/565] 35% | Training loss: 0.6905972537398338
Epoch: 12 | Iteration number: [210/565] 37% | Training loss: 0.690448146206992
Epoch: 12 | Iteration number: [220/565] 38% | Training loss: 0.690304652669213
Epoch: 12 | Iteration number: [230/565] 40% | Training loss: 0.6901722731797592
Epoch: 12 | Iteration number: [240/565] 42% | Training loss: 0.6900399431586266
Epoch: 12 | Iteration number: [250/565] 44% | Training loss: 0.6899451868534088
Epoch: 12 | Iteration number: [260/565] 46% | Training loss: 0.6898416104225013
Epoch: 12 | Iteration number: [270/565] 47% | Training loss: 0.6897336129788999
Epoch: 12 | Iteration number: [280/565] 49% | Training loss: 0.6896521781172071
Epoch: 12 | Iteration number: [290/565] 51% | Training loss: 0.6895745700803296
Epoch: 12 | Iteration number: [300/565] 53% | Training loss: 0.6894908108313879
Epoch: 12 | Iteration number: [310/565] 54% | Training loss: 0.6894195581636121
Epoch: 12 | Iteration number: [320/565] 56% | Training loss: 0.6893527414649725
Epoch: 12 | Iteration number: [330/565] 58% | Training loss: 0.6892935313961722
Epoch: 12 | Iteration number: [340/565] 60% | Training loss: 0.6892244880690294
Epoch: 12 | Iteration number: [350/565] 61% | Training loss: 0.689163430418287
Epoch: 12 | Iteration number: [360/565] 63% | Training loss: 0.6891226410865784
Epoch: 12 | Iteration number: [370/565] 65% | Training loss: 0.6890690560276443
Epoch: 12 | Iteration number: [380/565] 67% | Training loss: 0.6890128499583195
Epoch: 12 | Iteration number: [390/565] 69% | Training loss: 0.6889670298649715
Epoch: 12 | Iteration number: [400/565] 70% | Training loss: 0.6889124411344528
Epoch: 12 | Iteration number: [410/565] 72% | Training loss: 0.6888643021990614
Epoch: 12 | Iteration number: [420/565] 74% | Training loss: 0.6888263060933068
Epoch: 12 | Iteration number: [430/565] 76% | Training loss: 0.6888056877047517
Epoch: 12 | Iteration number: [440/565] 77% | Training loss: 0.6887662655927919
Epoch: 12 | Iteration number: [450/565] 79% | Training loss: 0.6887248734633128
Epoch: 12 | Iteration number: [460/565] 81% | Training loss: 0.688690366304439
Epoch: 12 | Iteration number: [470/565] 83% | Training loss: 0.6886680206085773
Epoch: 12 | Iteration number: [480/565] 84% | Training loss: 0.688636040315032
Epoch: 12 | Iteration number: [490/565] 86% | Training loss: 0.688619639557235
Epoch: 12 | Iteration number: [500/565] 88% | Training loss: 0.688600495815277
Epoch: 12 | Iteration number: [510/565] 90% | Training loss: 0.6885674318846534
Epoch: 12 | Iteration number: [520/565] 92% | Training loss: 0.6885367882939485
Epoch: 12 | Iteration number: [530/565] 93% | Training loss: 0.6885158250916679
Epoch: 12 | Iteration number: [540/565] 95% | Training loss: 0.6884961498004419
Epoch: 12 | Iteration number: [550/565] 97% | Training loss: 0.6884697208621285
Epoch: 12 | Iteration number: [560/565] 99% | Training loss: 0.6884489036032132

 End of epoch: 12 | Train Loss: 0.6872216410341516 | Training Time: 89 

 End of epoch: 12 | Eval Loss: 0.6894251533917019 | Evaluating Time: 6 
Epoch: 13 | Iteration number: [10/565] 1% | Training loss: 0.7561968982219696
Epoch: 13 | Iteration number: [20/565] 3% | Training loss: 0.7216014742851258
Epoch: 13 | Iteration number: [30/565] 5% | Training loss: 0.710165947675705
Epoch: 13 | Iteration number: [40/565] 7% | Training loss: 0.7044234678149224
Epoch: 13 | Iteration number: [50/565] 8% | Training loss: 0.7010271072387695
Epoch: 13 | Iteration number: [60/565] 10% | Training loss: 0.6987390100955964
Epoch: 13 | Iteration number: [70/565] 12% | Training loss: 0.6970374805586679
Epoch: 13 | Iteration number: [80/565] 14% | Training loss: 0.6958226822316647
Epoch: 13 | Iteration number: [90/565] 15% | Training loss: 0.694912980000178
Epoch: 13 | Iteration number: [100/565] 17% | Training loss: 0.6941089928150177
Epoch: 13 | Iteration number: [110/565] 19% | Training loss: 0.693459130417217
Epoch: 13 | Iteration number: [120/565] 21% | Training loss: 0.6929060866435369
Epoch: 13 | Iteration number: [130/565] 23% | Training loss: 0.6924767242028163
Epoch: 13 | Iteration number: [140/565] 24% | Training loss: 0.6921027524130685
Epoch: 13 | Iteration number: [150/565] 26% | Training loss: 0.6917785608768463
Epoch: 13 | Iteration number: [160/565] 28% | Training loss: 0.6914543952792883
Epoch: 13 | Iteration number: [170/565] 30% | Training loss: 0.6911848892183865
Epoch: 13 | Iteration number: [180/565] 31% | Training loss: 0.6909604016277525
Epoch: 13 | Iteration number: [190/565] 33% | Training loss: 0.6907589570472115
Epoch: 13 | Iteration number: [200/565] 35% | Training loss: 0.6905786043405533
Epoch: 13 | Iteration number: [210/565] 37% | Training loss: 0.6904002609707061
Epoch: 13 | Iteration number: [220/565] 38% | Training loss: 0.6902501612901688
Epoch: 13 | Iteration number: [230/565] 40% | Training loss: 0.6901098860346753
Epoch: 13 | Iteration number: [240/565] 42% | Training loss: 0.689985683063666
Epoch: 13 | Iteration number: [250/565] 44% | Training loss: 0.6898750946521759
Epoch: 13 | Iteration number: [260/565] 46% | Training loss: 0.6897768712960757
Epoch: 13 | Iteration number: [270/565] 47% | Training loss: 0.6896885538542712
Epoch: 13 | Iteration number: [280/565] 49% | Training loss: 0.6895895696112088
Epoch: 13 | Iteration number: [290/565] 51% | Training loss: 0.6895121979302373
Epoch: 13 | Iteration number: [300/565] 53% | Training loss: 0.6894536658128103
Epoch: 13 | Iteration number: [310/565] 54% | Training loss: 0.6893768839297756
Epoch: 13 | Iteration number: [320/565] 56% | Training loss: 0.6892987916246056
Epoch: 13 | Iteration number: [330/565] 58% | Training loss: 0.6892328428499627
Epoch: 13 | Iteration number: [340/565] 60% | Training loss: 0.689168319106102
Epoch: 13 | Iteration number: [350/565] 61% | Training loss: 0.6891100777898516
Epoch: 13 | Iteration number: [360/565] 63% | Training loss: 0.6890473948584662
Epoch: 13 | Iteration number: [370/565] 65% | Training loss: 0.6889980454702636
Epoch: 13 | Iteration number: [380/565] 67% | Training loss: 0.68894501171614
Epoch: 13 | Iteration number: [390/565] 69% | Training loss: 0.6889080764391483
Epoch: 13 | Iteration number: [400/565] 70% | Training loss: 0.68885522544384
Epoch: 13 | Iteration number: [410/565] 72% | Training loss: 0.6888204051227105
Epoch: 13 | Iteration number: [420/565] 74% | Training loss: 0.6887727839606149
Epoch: 13 | Iteration number: [430/565] 76% | Training loss: 0.6887343439944955
Epoch: 13 | Iteration number: [440/565] 77% | Training loss: 0.6887015573003076
Epoch: 13 | Iteration number: [450/565] 79% | Training loss: 0.6886663386556837
Epoch: 13 | Iteration number: [460/565] 81% | Training loss: 0.6886469847482184
Epoch: 13 | Iteration number: [470/565] 83% | Training loss: 0.6886228721192542
Epoch: 13 | Iteration number: [480/565] 84% | Training loss: 0.6885959333429734
Epoch: 13 | Iteration number: [490/565] 86% | Training loss: 0.6885786491997388
Epoch: 13 | Iteration number: [500/565] 88% | Training loss: 0.68854794049263
Epoch: 13 | Iteration number: [510/565] 90% | Training loss: 0.6885084230525821
Epoch: 13 | Iteration number: [520/565] 92% | Training loss: 0.6884809623544033
Epoch: 13 | Iteration number: [530/565] 93% | Training loss: 0.6884588298932561
Epoch: 13 | Iteration number: [540/565] 95% | Training loss: 0.6884294990036223
Epoch: 13 | Iteration number: [550/565] 97% | Training loss: 0.6884004468267614
Epoch: 13 | Iteration number: [560/565] 99% | Training loss: 0.6883839412459305

 End of epoch: 13 | Train Loss: 0.6871490398339466 | Training Time: 89 

 End of epoch: 13 | Eval Loss: 0.6899453827313015 | Evaluating Time: 6 
Epoch: 14 | Iteration number: [10/565] 1% | Training loss: 0.7556099534034729
Epoch: 14 | Iteration number: [20/565] 3% | Training loss: 0.7215470194816589
Epoch: 14 | Iteration number: [30/565] 5% | Training loss: 0.709977775812149
Epoch: 14 | Iteration number: [40/565] 7% | Training loss: 0.7041752874851227
Epoch: 14 | Iteration number: [50/565] 8% | Training loss: 0.7008210444450378
Epoch: 14 | Iteration number: [60/565] 10% | Training loss: 0.698536001642545
Epoch: 14 | Iteration number: [70/565] 12% | Training loss: 0.6968887669699533
Epoch: 14 | Iteration number: [80/565] 14% | Training loss: 0.6957146465778351
Epoch: 14 | Iteration number: [90/565] 15% | Training loss: 0.6947426749600305
Epoch: 14 | Iteration number: [100/565] 17% | Training loss: 0.6939472740888596
Epoch: 14 | Iteration number: [110/565] 19% | Training loss: 0.6932971016927199
Epoch: 14 | Iteration number: [120/565] 21% | Training loss: 0.6928092554211617
Epoch: 14 | Iteration number: [130/565] 23% | Training loss: 0.6923696307035593
Epoch: 14 | Iteration number: [140/565] 24% | Training loss: 0.6919969499111176
Epoch: 14 | Iteration number: [150/565] 26% | Training loss: 0.6916925942897797
Epoch: 14 | Iteration number: [160/565] 28% | Training loss: 0.6914226293563843
Epoch: 14 | Iteration number: [170/565] 30% | Training loss: 0.6911246327792897
Epoch: 14 | Iteration number: [180/565] 31% | Training loss: 0.6909149338801702
Epoch: 14 | Iteration number: [190/565] 33% | Training loss: 0.6907309403544978
Epoch: 14 | Iteration number: [200/565] 35% | Training loss: 0.6905513924360275
Epoch: 14 | Iteration number: [210/565] 37% | Training loss: 0.6903613802932558
Epoch: 14 | Iteration number: [220/565] 38% | Training loss: 0.6902064995332198
Epoch: 14 | Iteration number: [230/565] 40% | Training loss: 0.6900633990764617
Epoch: 14 | Iteration number: [240/565] 42% | Training loss: 0.6899251408874989
Epoch: 14 | Iteration number: [250/565] 44% | Training loss: 0.6898289647102356
Epoch: 14 | Iteration number: [260/565] 46% | Training loss: 0.6897296790893261
Epoch: 14 | Iteration number: [270/565] 47% | Training loss: 0.6896299664621
Epoch: 14 | Iteration number: [280/565] 49% | Training loss: 0.689543850507055
Epoch: 14 | Iteration number: [290/565] 51% | Training loss: 0.6894712920846611
Epoch: 14 | Iteration number: [300/565] 53% | Training loss: 0.6893943228324254
Epoch: 14 | Iteration number: [310/565] 54% | Training loss: 0.6893245177884255
Epoch: 14 | Iteration number: [320/565] 56% | Training loss: 0.6892457950860262
Epoch: 14 | Iteration number: [330/565] 58% | Training loss: 0.6891776482264201
Epoch: 14 | Iteration number: [340/565] 60% | Training loss: 0.6891158719273175
Epoch: 14 | Iteration number: [350/565] 61% | Training loss: 0.6890685089996883
Epoch: 14 | Iteration number: [360/565] 63% | Training loss: 0.6890123239821858
Epoch: 14 | Iteration number: [370/565] 65% | Training loss: 0.6889592457462002
Epoch: 14 | Iteration number: [380/565] 67% | Training loss: 0.6889052618491022
Epoch: 14 | Iteration number: [390/565] 69% | Training loss: 0.6888545071467375
Epoch: 14 | Iteration number: [400/565] 70% | Training loss: 0.6887998212873936
Epoch: 14 | Iteration number: [410/565] 72% | Training loss: 0.6887708732267706
Epoch: 14 | Iteration number: [420/565] 74% | Training loss: 0.6887366778793789
Epoch: 14 | Iteration number: [430/565] 76% | Training loss: 0.6886854356111483
Epoch: 14 | Iteration number: [440/565] 77% | Training loss: 0.6886534846641801
Epoch: 14 | Iteration number: [450/565] 79% | Training loss: 0.6886203436056773
Epoch: 14 | Iteration number: [460/565] 81% | Training loss: 0.6885865300893783
Epoch: 14 | Iteration number: [470/565] 83% | Training loss: 0.6885580461075965
Epoch: 14 | Iteration number: [480/565] 84% | Training loss: 0.6885105720410745
Epoch: 14 | Iteration number: [490/565] 86% | Training loss: 0.6884812559400286
Epoch: 14 | Iteration number: [500/565] 88% | Training loss: 0.6884567648172378
Epoch: 14 | Iteration number: [510/565] 90% | Training loss: 0.6884295828202192
Epoch: 14 | Iteration number: [520/565] 92% | Training loss: 0.6884094548913149
Epoch: 14 | Iteration number: [530/565] 93% | Training loss: 0.6883878058982346
Epoch: 14 | Iteration number: [540/565] 95% | Training loss: 0.6883636129123193
Epoch: 14 | Iteration number: [550/565] 97% | Training loss: 0.6883488028699701
Epoch: 14 | Iteration number: [560/565] 99% | Training loss: 0.6883274921349116

 End of epoch: 14 | Train Loss: 0.6870995888667824 | Training Time: 88 

 End of epoch: 14 | Eval Loss: 0.6899053369249616 | Evaluating Time: 6 
Epoch: 15 | Iteration number: [10/565] 1% | Training loss: 0.7557851433753967
Epoch: 15 | Iteration number: [20/565] 3% | Training loss: 0.7213632315397263
Epoch: 15 | Iteration number: [30/565] 5% | Training loss: 0.7099726021289825
Epoch: 15 | Iteration number: [40/565] 7% | Training loss: 0.7044187694787979
Epoch: 15 | Iteration number: [50/565] 8% | Training loss: 0.7009581851959229
Epoch: 15 | Iteration number: [60/565] 10% | Training loss: 0.6986062993605932
Epoch: 15 | Iteration number: [70/565] 12% | Training loss: 0.6969618720667703
Epoch: 15 | Iteration number: [80/565] 14% | Training loss: 0.6957469612360001
Epoch: 15 | Iteration number: [90/565] 15% | Training loss: 0.6948408941427867
Epoch: 15 | Iteration number: [100/565] 17% | Training loss: 0.6940384149551392
Epoch: 15 | Iteration number: [110/565] 19% | Training loss: 0.6934014450420033
Epoch: 15 | Iteration number: [120/565] 21% | Training loss: 0.692852217455705
Epoch: 15 | Iteration number: [130/565] 23% | Training loss: 0.6924214161359347
Epoch: 15 | Iteration number: [140/565] 24% | Training loss: 0.6920094460248947
Epoch: 15 | Iteration number: [150/565] 26% | Training loss: 0.6916833770275116
Epoch: 15 | Iteration number: [160/565] 28% | Training loss: 0.6914154045283795
Epoch: 15 | Iteration number: [170/565] 30% | Training loss: 0.691156756176668
Epoch: 15 | Iteration number: [180/565] 31% | Training loss: 0.6909210814370049
Epoch: 15 | Iteration number: [190/565] 33% | Training loss: 0.6907034124198713
Epoch: 15 | Iteration number: [200/565] 35% | Training loss: 0.6905123800039291
Epoch: 15 | Iteration number: [210/565] 37% | Training loss: 0.690371307588759
Epoch: 15 | Iteration number: [220/565] 38% | Training loss: 0.6902134453708475
Epoch: 15 | Iteration number: [230/565] 40% | Training loss: 0.6900864888792453
Epoch: 15 | Iteration number: [240/565] 42% | Training loss: 0.689969694862763
Epoch: 15 | Iteration number: [250/565] 44% | Training loss: 0.6898611073493958
Epoch: 15 | Iteration number: [260/565] 46% | Training loss: 0.6897426009178161
Epoch: 15 | Iteration number: [270/565] 47% | Training loss: 0.6896780137662535
Epoch: 15 | Iteration number: [280/565] 49% | Training loss: 0.689572931613241
Epoch: 15 | Iteration number: [290/565] 51% | Training loss: 0.6894790626805404
Epoch: 15 | Iteration number: [300/565] 53% | Training loss: 0.689401022195816
Epoch: 15 | Iteration number: [310/565] 54% | Training loss: 0.6893364152600688
Epoch: 15 | Iteration number: [320/565] 56% | Training loss: 0.689252358302474
Epoch: 15 | Iteration number: [330/565] 58% | Training loss: 0.6891962889469031
Epoch: 15 | Iteration number: [340/565] 60% | Training loss: 0.6891367680886212
Epoch: 15 | Iteration number: [350/565] 61% | Training loss: 0.6890693553856441
Epoch: 15 | Iteration number: [360/565] 63% | Training loss: 0.6890229655636682
Epoch: 15 | Iteration number: [370/565] 65% | Training loss: 0.6889835541312759
Epoch: 15 | Iteration number: [380/565] 67% | Training loss: 0.6889346049020165
Epoch: 15 | Iteration number: [390/565] 69% | Training loss: 0.6888814087097461
Epoch: 15 | Iteration number: [400/565] 70% | Training loss: 0.6888389518857002
Epoch: 15 | Iteration number: [410/565] 72% | Training loss: 0.6887857582510971
Epoch: 15 | Iteration number: [420/565] 74% | Training loss: 0.6887514410983948
Epoch: 15 | Iteration number: [430/565] 76% | Training loss: 0.6887042959069096
Epoch: 15 | Iteration number: [440/565] 77% | Training loss: 0.6886689253828743
Epoch: 15 | Iteration number: [450/565] 79% | Training loss: 0.6886320063802931
Epoch: 15 | Iteration number: [460/565] 81% | Training loss: 0.6885987989280535
Epoch: 15 | Iteration number: [470/565] 83% | Training loss: 0.6885582738734306
Epoch: 15 | Iteration number: [480/565] 84% | Training loss: 0.6885234388212363
Epoch: 15 | Iteration number: [490/565] 86% | Training loss: 0.6884860297855065
Epoch: 15 | Iteration number: [500/565] 88% | Training loss: 0.6884598038196563
Epoch: 15 | Iteration number: [510/565] 90% | Training loss: 0.6884428071040734
Epoch: 15 | Iteration number: [520/565] 92% | Training loss: 0.6884154858497473
Epoch: 15 | Iteration number: [530/565] 93% | Training loss: 0.6883859867194914
Epoch: 15 | Iteration number: [540/565] 95% | Training loss: 0.6883551962949611
Epoch: 15 | Iteration number: [550/565] 97% | Training loss: 0.688339497717944
Epoch: 15 | Iteration number: [560/565] 99% | Training loss: 0.6883204371801445

 End of epoch: 15 | Train Loss: 0.6870985023743283 | Training Time: 90 

 End of epoch: 15 | Eval Loss: 0.690107422215598 | Evaluating Time: 6 
Epoch: 16 | Iteration number: [10/565] 1% | Training loss: 0.7554988026618957
Epoch: 16 | Iteration number: [20/565] 3% | Training loss: 0.7212863981723785
Epoch: 16 | Iteration number: [30/565] 5% | Training loss: 0.7099060118198395
Epoch: 16 | Iteration number: [40/565] 7% | Training loss: 0.7041846439242363
Epoch: 16 | Iteration number: [50/565] 8% | Training loss: 0.700689971446991
Epoch: 16 | Iteration number: [60/565] 10% | Training loss: 0.6984124183654785
Epoch: 16 | Iteration number: [70/565] 12% | Training loss: 0.69682537317276
Epoch: 16 | Iteration number: [80/565] 14% | Training loss: 0.6956309601664543
Epoch: 16 | Iteration number: [90/565] 15% | Training loss: 0.6946736964914534
Epoch: 16 | Iteration number: [100/565] 17% | Training loss: 0.6938764351606369
Epoch: 16 | Iteration number: [110/565] 19% | Training loss: 0.6932497929443012
Epoch: 16 | Iteration number: [120/565] 21% | Training loss: 0.6927348817388217
Epoch: 16 | Iteration number: [130/565] 23% | Training loss: 0.6922847834917215
Epoch: 16 | Iteration number: [140/565] 24% | Training loss: 0.691869568824768
Epoch: 16 | Iteration number: [150/565] 26% | Training loss: 0.6915181867281596
Epoch: 16 | Iteration number: [160/565] 28% | Training loss: 0.6912240300327539
Epoch: 16 | Iteration number: [170/565] 30% | Training loss: 0.6909761842559365
Epoch: 16 | Iteration number: [180/565] 31% | Training loss: 0.6907740344603857
Epoch: 16 | Iteration number: [190/565] 33% | Training loss: 0.6905589875422026
Epoch: 16 | Iteration number: [200/565] 35% | Training loss: 0.6903820720314979
Epoch: 16 | Iteration number: [210/565] 37% | Training loss: 0.690247395776567
Epoch: 16 | Iteration number: [220/565] 38% | Training loss: 0.690097210353071
Epoch: 16 | Iteration number: [230/565] 40% | Training loss: 0.6899674633274908
Epoch: 16 | Iteration number: [240/565] 42% | Training loss: 0.6898556798696518
Epoch: 16 | Iteration number: [250/565] 44% | Training loss: 0.689734676361084
Epoch: 16 | Iteration number: [260/565] 46% | Training loss: 0.6896104422899393
Epoch: 16 | Iteration number: [270/565] 47% | Training loss: 0.6895252298425745
Epoch: 16 | Iteration number: [280/565] 49% | Training loss: 0.6894367003015109
Epoch: 16 | Iteration number: [290/565] 51% | Training loss: 0.6893511137057995
Epoch: 16 | Iteration number: [300/565] 53% | Training loss: 0.6892767030000687
Epoch: 16 | Iteration number: [310/565] 54% | Training loss: 0.6891974608744345
Epoch: 16 | Iteration number: [320/565] 56% | Training loss: 0.6891348855569959
Epoch: 16 | Iteration number: [330/565] 58% | Training loss: 0.6890635410944621
Epoch: 16 | Iteration number: [340/565] 60% | Training loss: 0.6890075995641596
Epoch: 16 | Iteration number: [350/565] 61% | Training loss: 0.6889551823479788
Epoch: 16 | Iteration number: [360/565] 63% | Training loss: 0.6889008187585407
Epoch: 16 | Iteration number: [370/565] 65% | Training loss: 0.688857673632132
Epoch: 16 | Iteration number: [380/565] 67% | Training loss: 0.6888080786717565
Epoch: 16 | Iteration number: [390/565] 69% | Training loss: 0.6887767058152419
Epoch: 16 | Iteration number: [400/565] 70% | Training loss: 0.6887361837923527
Epoch: 16 | Iteration number: [410/565] 72% | Training loss: 0.6886909031286472
Epoch: 16 | Iteration number: [420/565] 74% | Training loss: 0.6886460940043132
Epoch: 16 | Iteration number: [430/565] 76% | Training loss: 0.6886119530644528
Epoch: 16 | Iteration number: [440/565] 77% | Training loss: 0.6885874878276478
Epoch: 16 | Iteration number: [450/565] 79% | Training loss: 0.688548571533627
Epoch: 16 | Iteration number: [460/565] 81% | Training loss: 0.6885084251994672
Epoch: 16 | Iteration number: [470/565] 83% | Training loss: 0.6884667886064407
Epoch: 16 | Iteration number: [480/565] 84% | Training loss: 0.6884399111072222
Epoch: 16 | Iteration number: [490/565] 86% | Training loss: 0.6884104808982537
Epoch: 16 | Iteration number: [500/565] 88% | Training loss: 0.68838017141819
Epoch: 16 | Iteration number: [510/565] 90% | Training loss: 0.6883608351735507
Epoch: 16 | Iteration number: [520/565] 92% | Training loss: 0.6883347807022241
Epoch: 16 | Iteration number: [530/565] 93% | Training loss: 0.6883183113808902
Epoch: 16 | Iteration number: [540/565] 95% | Training loss: 0.6882993128564623
Epoch: 16 | Iteration number: [550/565] 97% | Training loss: 0.6882734814557162
Epoch: 16 | Iteration number: [560/565] 99% | Training loss: 0.6882552820656981

 End of epoch: 16 | Train Loss: 0.6870334415309197 | Training Time: 89 

 End of epoch: 16 | Eval Loss: 0.6898680329322815 | Evaluating Time: 6 
Epoch: 17 | Iteration number: [10/565] 1% | Training loss: 0.7553585827350616
Epoch: 17 | Iteration number: [20/565] 3% | Training loss: 0.7209443151950836
Epoch: 17 | Iteration number: [30/565] 5% | Training loss: 0.7098510146141053
Epoch: 17 | Iteration number: [40/565] 7% | Training loss: 0.704234765470028
Epoch: 17 | Iteration number: [50/565] 8% | Training loss: 0.7007532572746277
Epoch: 17 | Iteration number: [60/565] 10% | Training loss: 0.6984433968861897
Epoch: 17 | Iteration number: [70/565] 12% | Training loss: 0.6967892859663282
Epoch: 17 | Iteration number: [80/565] 14% | Training loss: 0.6955728121101856
Epoch: 17 | Iteration number: [90/565] 15% | Training loss: 0.6946843047936757
Epoch: 17 | Iteration number: [100/565] 17% | Training loss: 0.6939368134737015
Epoch: 17 | Iteration number: [110/565] 19% | Training loss: 0.6932939285581762
Epoch: 17 | Iteration number: [120/565] 21% | Training loss: 0.6927693073948225
Epoch: 17 | Iteration number: [130/565] 23% | Training loss: 0.6923327922821045
Epoch: 17 | Iteration number: [140/565] 24% | Training loss: 0.6919313413756234
Epoch: 17 | Iteration number: [150/565] 26% | Training loss: 0.6915942354996999
Epoch: 17 | Iteration number: [160/565] 28% | Training loss: 0.6913186341524125
Epoch: 17 | Iteration number: [170/565] 30% | Training loss: 0.6910891827415018
Epoch: 17 | Iteration number: [180/565] 31% | Training loss: 0.6908636318312751
Epoch: 17 | Iteration number: [190/565] 33% | Training loss: 0.6906209707260131
Epoch: 17 | Iteration number: [200/565] 35% | Training loss: 0.6904437491297721
Epoch: 17 | Iteration number: [210/565] 37% | Training loss: 0.6902524255570911
Epoch: 17 | Iteration number: [220/565] 38% | Training loss: 0.6901190381158482
Epoch: 17 | Iteration number: [230/565] 40% | Training loss: 0.6899696528911591
Epoch: 17 | Iteration number: [240/565] 42% | Training loss: 0.6898513952891032
Epoch: 17 | Iteration number: [250/565] 44% | Training loss: 0.6897381930351257
Epoch: 17 | Iteration number: [260/565] 46% | Training loss: 0.6896147042512893
Epoch: 17 | Iteration number: [270/565] 47% | Training loss: 0.6895023714613031
Epoch: 17 | Iteration number: [280/565] 49% | Training loss: 0.68942227853196
Epoch: 17 | Iteration number: [290/565] 51% | Training loss: 0.6893337040111936
Epoch: 17 | Iteration number: [300/565] 53% | Training loss: 0.6892645106712977
Epoch: 17 | Iteration number: [310/565] 54% | Training loss: 0.6891963481903076
Epoch: 17 | Iteration number: [320/565] 56% | Training loss: 0.6891317442059517
Epoch: 17 | Iteration number: [330/565] 58% | Training loss: 0.6890836022116921
Epoch: 17 | Iteration number: [340/565] 60% | Training loss: 0.6890163789777195
Epoch: 17 | Iteration number: [350/565] 61% | Training loss: 0.6889750446592059
Epoch: 17 | Iteration number: [360/565] 63% | Training loss: 0.688928073644638
Epoch: 17 | Iteration number: [370/565] 65% | Training loss: 0.6888724148273468
Epoch: 17 | Iteration number: [380/565] 67% | Training loss: 0.6888131439685822
Epoch: 17 | Iteration number: [390/565] 69% | Training loss: 0.6887674405024602
Epoch: 17 | Iteration number: [400/565] 70% | Training loss: 0.6887214604020119
Epoch: 17 | Iteration number: [410/565] 72% | Training loss: 0.6886934613309256
Epoch: 17 | Iteration number: [420/565] 74% | Training loss: 0.6886596578927268
Epoch: 17 | Iteration number: [430/565] 76% | Training loss: 0.6886099625465482
Epoch: 17 | Iteration number: [440/565] 77% | Training loss: 0.6885803406888789
Epoch: 17 | Iteration number: [450/565] 79% | Training loss: 0.6885523992114597
Epoch: 17 | Iteration number: [460/565] 81% | Training loss: 0.6885213686072308
Epoch: 17 | Iteration number: [470/565] 83% | Training loss: 0.6885006312360155
Epoch: 17 | Iteration number: [480/565] 84% | Training loss: 0.6884628454844157
Epoch: 17 | Iteration number: [490/565] 86% | Training loss: 0.6884260193425782
Epoch: 17 | Iteration number: [500/565] 88% | Training loss: 0.688394839644432
Epoch: 17 | Iteration number: [510/565] 90% | Training loss: 0.6883679637721941
Epoch: 17 | Iteration number: [520/565] 92% | Training loss: 0.6883455603168561
Epoch: 17 | Iteration number: [530/565] 93% | Training loss: 0.6883157021594497
Epoch: 17 | Iteration number: [540/565] 95% | Training loss: 0.6882955369022158
Epoch: 17 | Iteration number: [550/565] 97% | Training loss: 0.6882668115875937
Epoch: 17 | Iteration number: [560/565] 99% | Training loss: 0.6882485995335238

 End of epoch: 17 | Train Loss: 0.6870200236286738 | Training Time: 90 

 End of epoch: 17 | Eval Loss: 0.6900320989745004 | Evaluating Time: 6 
Epoch: 18 | Iteration number: [10/565] 1% | Training loss: 0.7556375682353973
Epoch: 18 | Iteration number: [20/565] 3% | Training loss: 0.7213230222463608
Epoch: 18 | Iteration number: [30/565] 5% | Training loss: 0.7099291304747264
Epoch: 18 | Iteration number: [40/565] 7% | Training loss: 0.7042978033423424
Epoch: 18 | Iteration number: [50/565] 8% | Training loss: 0.700830008983612
Epoch: 18 | Iteration number: [60/565] 10% | Training loss: 0.6985706706841787
Epoch: 18 | Iteration number: [70/565] 12% | Training loss: 0.6968976880822862
Epoch: 18 | Iteration number: [80/565] 14% | Training loss: 0.6956268385052681
Epoch: 18 | Iteration number: [90/565] 15% | Training loss: 0.6946414861414167
Epoch: 18 | Iteration number: [100/565] 17% | Training loss: 0.6938677608966828
Epoch: 18 | Iteration number: [110/565] 19% | Training loss: 0.693211410262368
Epoch: 18 | Iteration number: [120/565] 21% | Training loss: 0.6926779955625534
Epoch: 18 | Iteration number: [130/565] 23% | Training loss: 0.6922205970837519
Epoch: 18 | Iteration number: [140/565] 24% | Training loss: 0.6918624988624028
Epoch: 18 | Iteration number: [150/565] 26% | Training loss: 0.6915260795752207
Epoch: 18 | Iteration number: [160/565] 28% | Training loss: 0.6912230931222438
Epoch: 18 | Iteration number: [170/565] 30% | Training loss: 0.6909741931101855
Epoch: 18 | Iteration number: [180/565] 31% | Training loss: 0.6907423572407828
Epoch: 18 | Iteration number: [190/565] 33% | Training loss: 0.6905545266051042
Epoch: 18 | Iteration number: [200/565] 35% | Training loss: 0.6903880518674851
Epoch: 18 | Iteration number: [210/565] 37% | Training loss: 0.6902317049957457
Epoch: 18 | Iteration number: [220/565] 38% | Training loss: 0.6900952458381653
Epoch: 18 | Iteration number: [230/565] 40% | Training loss: 0.6899705189725627
Epoch: 18 | Iteration number: [240/565] 42% | Training loss: 0.6898462260762851
Epoch: 18 | Iteration number: [250/565] 44% | Training loss: 0.6897398197650909
Epoch: 18 | Iteration number: [260/565] 46% | Training loss: 0.6896392989617127
Epoch: 18 | Iteration number: [270/565] 47% | Training loss: 0.6895440256154096
Epoch: 18 | Iteration number: [280/565] 49% | Training loss: 0.6894483442817415
Epoch: 18 | Iteration number: [290/565] 51% | Training loss: 0.6893628956942722
Epoch: 18 | Iteration number: [300/565] 53% | Training loss: 0.6892840286095937
Epoch: 18 | Iteration number: [310/565] 54% | Training loss: 0.6892212808132172
Epoch: 18 | Iteration number: [320/565] 56% | Training loss: 0.6891531286761164
Epoch: 18 | Iteration number: [330/565] 58% | Training loss: 0.6890937754602143
Epoch: 18 | Iteration number: [340/565] 60% | Training loss: 0.6890295873670017
Epoch: 18 | Iteration number: [350/565] 61% | Training loss: 0.6889629949842181
Epoch: 18 | Iteration number: [360/565] 63% | Training loss: 0.6889109803570641
Epoch: 18 | Iteration number: [370/565] 65% | Training loss: 0.6888531634936461
Epoch: 18 | Iteration number: [380/565] 67% | Training loss: 0.6888052228250001
Epoch: 18 | Iteration number: [390/565] 69% | Training loss: 0.6887545940203544
Epoch: 18 | Iteration number: [400/565] 70% | Training loss: 0.6887125305831432
Epoch: 18 | Iteration number: [410/565] 72% | Training loss: 0.6886776104205992
Epoch: 18 | Iteration number: [420/565] 74% | Training loss: 0.688652923419362
Epoch: 18 | Iteration number: [430/565] 76% | Training loss: 0.6886222351429074
Epoch: 18 | Iteration number: [440/565] 77% | Training loss: 0.6885890234600414
Epoch: 18 | Iteration number: [450/565] 79% | Training loss: 0.6885591469870673
Epoch: 18 | Iteration number: [460/565] 81% | Training loss: 0.688519949109658
Epoch: 18 | Iteration number: [470/565] 83% | Training loss: 0.6884854210183976
Epoch: 18 | Iteration number: [480/565] 84% | Training loss: 0.6884543345620234
Epoch: 18 | Iteration number: [490/565] 86% | Training loss: 0.6884259624140603
Epoch: 18 | Iteration number: [500/565] 88% | Training loss: 0.6883994914293289
Epoch: 18 | Iteration number: [510/565] 90% | Training loss: 0.6883721860016093
Epoch: 18 | Iteration number: [520/565] 92% | Training loss: 0.6883500252778714
Epoch: 18 | Iteration number: [530/565] 93% | Training loss: 0.6883386057502818
Epoch: 18 | Iteration number: [540/565] 95% | Training loss: 0.6883124515966133
Epoch: 18 | Iteration number: [550/565] 97% | Training loss: 0.6882921304486015
Epoch: 18 | Iteration number: [560/565] 99% | Training loss: 0.6882717616856098

 End of epoch: 18 | Train Loss: 0.6870408747048504 | Training Time: 87 

 End of epoch: 18 | Eval Loss: 0.6900497845241002 | Evaluating Time: 6 
Epoch: 19 | Iteration number: [10/565] 1% | Training loss: 0.7554275989532471
Epoch: 19 | Iteration number: [20/565] 3% | Training loss: 0.7210993677377701
Epoch: 19 | Iteration number: [30/565] 5% | Training loss: 0.7094825426737468
Epoch: 19 | Iteration number: [40/565] 7% | Training loss: 0.703777651488781
Epoch: 19 | Iteration number: [50/565] 8% | Training loss: 0.7003863155841827
Epoch: 19 | Iteration number: [60/565] 10% | Training loss: 0.6981727391481399
Epoch: 19 | Iteration number: [70/565] 12% | Training loss: 0.6965782838208335
Epoch: 19 | Iteration number: [80/565] 14% | Training loss: 0.695367344468832
Epoch: 19 | Iteration number: [90/565] 15% | Training loss: 0.694448686308331
Epoch: 19 | Iteration number: [100/565] 17% | Training loss: 0.693732470870018
Epoch: 19 | Iteration number: [110/565] 19% | Training loss: 0.6931083711710844
Epoch: 19 | Iteration number: [120/565] 21% | Training loss: 0.6926270936926205
Epoch: 19 | Iteration number: [130/565] 23% | Training loss: 0.6922072286789234
Epoch: 19 | Iteration number: [140/565] 24% | Training loss: 0.6918270600693567
Epoch: 19 | Iteration number: [150/565] 26% | Training loss: 0.6914959832032521
Epoch: 19 | Iteration number: [160/565] 28% | Training loss: 0.6912048228085041
Epoch: 19 | Iteration number: [170/565] 30% | Training loss: 0.6909632030655356
Epoch: 19 | Iteration number: [180/565] 31% | Training loss: 0.6907381428612603
Epoch: 19 | Iteration number: [190/565] 33% | Training loss: 0.6905252073940478
Epoch: 19 | Iteration number: [200/565] 35% | Training loss: 0.6903509363532067
Epoch: 19 | Iteration number: [210/565] 37% | Training loss: 0.6902020272754488
Epoch: 19 | Iteration number: [220/565] 38% | Training loss: 0.6900645543228496
Epoch: 19 | Iteration number: [230/565] 40% | Training loss: 0.6899380194104237
Epoch: 19 | Iteration number: [240/565] 42% | Training loss: 0.6898139471809069
Epoch: 19 | Iteration number: [250/565] 44% | Training loss: 0.6897089991569519
Epoch: 19 | Iteration number: [260/565] 46% | Training loss: 0.6895887831082711
Epoch: 19 | Iteration number: [270/565] 47% | Training loss: 0.6894858119664369
Epoch: 19 | Iteration number: [280/565] 49% | Training loss: 0.6893936665994781
Epoch: 19 | Iteration number: [290/565] 51% | Training loss: 0.6893179922268309
Epoch: 19 | Iteration number: [300/565] 53% | Training loss: 0.6892405225833257
Epoch: 19 | Iteration number: [310/565] 54% | Training loss: 0.6891733629088248
Epoch: 19 | Iteration number: [320/565] 56% | Training loss: 0.6891038885340095
Epoch: 19 | Iteration number: [330/565] 58% | Training loss: 0.689039773832668
Epoch: 19 | Iteration number: [340/565] 60% | Training loss: 0.6889834444312488
Epoch: 19 | Iteration number: [350/565] 61% | Training loss: 0.688919506072998
Epoch: 19 | Iteration number: [360/565] 63% | Training loss: 0.6888600713676877
Epoch: 19 | Iteration number: [370/565] 65% | Training loss: 0.6888146020270682
Epoch: 19 | Iteration number: [380/565] 67% | Training loss: 0.6887631990407642
Epoch: 19 | Iteration number: [390/565] 69% | Training loss: 0.68871128650812
Epoch: 19 | Iteration number: [400/565] 70% | Training loss: 0.6886700470745564
Epoch: 19 | Iteration number: [410/565] 72% | Training loss: 0.688642785898069
Epoch: 19 | Iteration number: [420/565] 74% | Training loss: 0.6886152693203518
Epoch: 19 | Iteration number: [430/565] 76% | Training loss: 0.6885873978914216
Epoch: 19 | Iteration number: [440/565] 77% | Training loss: 0.6885535734620961
Epoch: 19 | Iteration number: [450/565] 79% | Training loss: 0.6885160288545821
Epoch: 19 | Iteration number: [460/565] 81% | Training loss: 0.6884881543076556
Epoch: 19 | Iteration number: [470/565] 83% | Training loss: 0.6884603940426035
Epoch: 19 | Iteration number: [480/565] 84% | Training loss: 0.6884274410704772
Epoch: 19 | Iteration number: [490/565] 86% | Training loss: 0.6884007442970665
Epoch: 19 | Iteration number: [500/565] 88% | Training loss: 0.6883661233186722
Epoch: 19 | Iteration number: [510/565] 90% | Training loss: 0.6883385231681899
Epoch: 19 | Iteration number: [520/565] 92% | Training loss: 0.6883164045902399
Epoch: 19 | Iteration number: [530/565] 93% | Training loss: 0.6882842499130177
Epoch: 19 | Iteration number: [540/565] 95% | Training loss: 0.6882546882938456
Epoch: 19 | Iteration number: [550/565] 97% | Training loss: 0.6882346552068537
Epoch: 19 | Iteration number: [560/565] 99% | Training loss: 0.688217743486166

 End of epoch: 19 | Train Loss: 0.6869916953871735 | Training Time: 87 

 End of epoch: 19 | Eval Loss: 0.6902789899281093 | Evaluating Time: 6 
Epoch: 20 | Iteration number: [10/565] 1% | Training loss: 0.7560468316078186
Epoch: 20 | Iteration number: [20/565] 3% | Training loss: 0.7214226067066193
Epoch: 20 | Iteration number: [30/565] 5% | Training loss: 0.7098640064398448
Epoch: 20 | Iteration number: [40/565] 7% | Training loss: 0.7040863618254661
Epoch: 20 | Iteration number: [50/565] 8% | Training loss: 0.7005954921245575
Epoch: 20 | Iteration number: [60/565] 10% | Training loss: 0.6983117083708446
Epoch: 20 | Iteration number: [70/565] 12% | Training loss: 0.6967229391847338
Epoch: 20 | Iteration number: [80/565] 14% | Training loss: 0.6954954206943512
Epoch: 20 | Iteration number: [90/565] 15% | Training loss: 0.6945572919315762
Epoch: 20 | Iteration number: [100/565] 17% | Training loss: 0.6937481081485748
Epoch: 20 | Iteration number: [110/565] 19% | Training loss: 0.6931337985125455
Epoch: 20 | Iteration number: [120/565] 21% | Training loss: 0.6926271632313729
Epoch: 20 | Iteration number: [130/565] 23% | Training loss: 0.6921788770418901
Epoch: 20 | Iteration number: [140/565] 24% | Training loss: 0.6917959643261773
Epoch: 20 | Iteration number: [150/565] 26% | Training loss: 0.6915016643206279
Epoch: 20 | Iteration number: [160/565] 28% | Training loss: 0.6911843288689852
Epoch: 20 | Iteration number: [170/565] 30% | Training loss: 0.690938422609778
Epoch: 20 | Iteration number: [180/565] 31% | Training loss: 0.6907208717531628
Epoch: 20 | Iteration number: [190/565] 33% | Training loss: 0.6905305887523451
Epoch: 20 | Iteration number: [200/565] 35% | Training loss: 0.6903428199887276
Epoch: 20 | Iteration number: [210/565] 37% | Training loss: 0.6901814460754394
Epoch: 20 | Iteration number: [220/565] 38% | Training loss: 0.6900396639650518
Epoch: 20 | Iteration number: [230/565] 40% | Training loss: 0.6898948780868365
Epoch: 20 | Iteration number: [240/565] 42% | Training loss: 0.6897908948361874
Epoch: 20 | Iteration number: [250/565] 44% | Training loss: 0.6896729106903077
Epoch: 20 | Iteration number: [260/565] 46% | Training loss: 0.6895842891473036
Epoch: 20 | Iteration number: [270/565] 47% | Training loss: 0.6894864603325173
Epoch: 20 | Iteration number: [280/565] 49% | Training loss: 0.6893963551947049
Epoch: 20 | Iteration number: [290/565] 51% | Training loss: 0.6893185046212427
Epoch: 20 | Iteration number: [300/565] 53% | Training loss: 0.6892574352025985
Epoch: 20 | Iteration number: [310/565] 54% | Training loss: 0.6891723423234878
Epoch: 20 | Iteration number: [320/565] 56% | Training loss: 0.6890966141596436
Epoch: 20 | Iteration number: [330/565] 58% | Training loss: 0.689025097362923
Epoch: 20 | Iteration number: [340/565] 60% | Training loss: 0.6889779197819093
Epoch: 20 | Iteration number: [350/565] 61% | Training loss: 0.6889286174092975
Epoch: 20 | Iteration number: [360/565] 63% | Training loss: 0.6888760873013072
Epoch: 20 | Iteration number: [370/565] 65% | Training loss: 0.6888279926132511
Epoch: 20 | Iteration number: [380/565] 67% | Training loss: 0.6887813127354572
Epoch: 20 | Iteration number: [390/565] 69% | Training loss: 0.6887311093318157
Epoch: 20 | Iteration number: [400/565] 70% | Training loss: 0.6886819863319397
Epoch: 20 | Iteration number: [410/565] 72% | Training loss: 0.6886476189624973
Epoch: 20 | Iteration number: [420/565] 74% | Training loss: 0.6886066534689494
Epoch: 20 | Iteration number: [430/565] 76% | Training loss: 0.6885673395423002
Epoch: 20 | Iteration number: [440/565] 77% | Training loss: 0.6885360612110658
Epoch: 20 | Iteration number: [450/565] 79% | Training loss: 0.6885067204634349
Epoch: 20 | Iteration number: [460/565] 81% | Training loss: 0.6884824470333432
Epoch: 20 | Iteration number: [470/565] 83% | Training loss: 0.6884670849810255
Epoch: 20 | Iteration number: [480/565] 84% | Training loss: 0.6884443619598944
Epoch: 20 | Iteration number: [490/565] 86% | Training loss: 0.6884051524862951
Epoch: 20 | Iteration number: [500/565] 88% | Training loss: 0.6883732963800431
Epoch: 20 | Iteration number: [510/565] 90% | Training loss: 0.6883432045871136
Epoch: 20 | Iteration number: [520/565] 92% | Training loss: 0.6883091481832357
Epoch: 20 | Iteration number: [530/565] 93% | Training loss: 0.6882877975139978
Epoch: 20 | Iteration number: [540/565] 95% | Training loss: 0.6882644892842681
Epoch: 20 | Iteration number: [550/565] 97% | Training loss: 0.6882415796409954
Epoch: 20 | Iteration number: [560/565] 99% | Training loss: 0.688214109731572

 End of epoch: 20 | Train Loss: 0.6869896814886448 | Training Time: 89 

 End of epoch: 20 | Eval Loss: 0.6892885821206229 | Evaluating Time: 6 
Epoch: 21 | Iteration number: [10/565] 1% | Training loss: 0.7556058168411255
Epoch: 21 | Iteration number: [20/565] 3% | Training loss: 0.7213270157575608
Epoch: 21 | Iteration number: [30/565] 5% | Training loss: 0.7098167975743611
Epoch: 21 | Iteration number: [40/565] 7% | Training loss: 0.7040326774120331
Epoch: 21 | Iteration number: [50/565] 8% | Training loss: 0.7006151354312897
Epoch: 21 | Iteration number: [60/565] 10% | Training loss: 0.6984184682369232
Epoch: 21 | Iteration number: [70/565] 12% | Training loss: 0.6967735520430973
Epoch: 21 | Iteration number: [80/565] 14% | Training loss: 0.695475859194994
Epoch: 21 | Iteration number: [90/565] 15% | Training loss: 0.6945358647240533
Epoch: 21 | Iteration number: [100/565] 17% | Training loss: 0.6937703090906143
Epoch: 21 | Iteration number: [110/565] 19% | Training loss: 0.6931405246257782
Epoch: 21 | Iteration number: [120/565] 21% | Training loss: 0.6926444302002589
Epoch: 21 | Iteration number: [130/565] 23% | Training loss: 0.6922012952657847
Epoch: 21 | Iteration number: [140/565] 24% | Training loss: 0.6918273159435817
Epoch: 21 | Iteration number: [150/565] 26% | Training loss: 0.6915158208211263
Epoch: 21 | Iteration number: [160/565] 28% | Training loss: 0.6912374116480351
Epoch: 21 | Iteration number: [170/565] 30% | Training loss: 0.6909801809226765
Epoch: 21 | Iteration number: [180/565] 31% | Training loss: 0.6907594737079409
Epoch: 21 | Iteration number: [190/565] 33% | Training loss: 0.6905322893669731
Epoch: 21 | Iteration number: [200/565] 35% | Training loss: 0.6903661048412323
Epoch: 21 | Iteration number: [210/565] 37% | Training loss: 0.69020771696454
Epoch: 21 | Iteration number: [220/565] 38% | Training loss: 0.6900759301402352
Epoch: 21 | Iteration number: [230/565] 40% | Training loss: 0.6899350661298503
Epoch: 21 | Iteration number: [240/565] 42% | Training loss: 0.6898127382000288
Epoch: 21 | Iteration number: [250/565] 44% | Training loss: 0.6896908361911773
Epoch: 21 | Iteration number: [260/565] 46% | Training loss: 0.6895892801193091
Epoch: 21 | Iteration number: [270/565] 47% | Training loss: 0.6895103461212582
Epoch: 21 | Iteration number: [280/565] 49% | Training loss: 0.6894181002463613
Epoch: 21 | Iteration number: [290/565] 51% | Training loss: 0.6893221121409844
Epoch: 21 | Iteration number: [300/565] 53% | Training loss: 0.6892537577946981
Epoch: 21 | Iteration number: [310/565] 54% | Training loss: 0.6891801751429035
Epoch: 21 | Iteration number: [320/565] 56% | Training loss: 0.6891059475019574
Epoch: 21 | Iteration number: [330/565] 58% | Training loss: 0.689039690024925
Epoch: 21 | Iteration number: [340/565] 60% | Training loss: 0.6889777748023762
Epoch: 21 | Iteration number: [350/565] 61% | Training loss: 0.6889208938394275
Epoch: 21 | Iteration number: [360/565] 63% | Training loss: 0.6888776467906104
Epoch: 21 | Iteration number: [370/565] 65% | Training loss: 0.6888227902554177
Epoch: 21 | Iteration number: [380/565] 67% | Training loss: 0.6887609168102867
Epoch: 21 | Iteration number: [390/565] 69% | Training loss: 0.688716337008354
Epoch: 21 | Iteration number: [400/565] 70% | Training loss: 0.6886669878661632
Epoch: 21 | Iteration number: [410/565] 72% | Training loss: 0.6886201832352615
Epoch: 21 | Iteration number: [420/565] 74% | Training loss: 0.6885743412233535
Epoch: 21 | Iteration number: [430/565] 76% | Training loss: 0.688539049098658
Epoch: 21 | Iteration number: [440/565] 77% | Training loss: 0.688494922356172
Epoch: 21 | Iteration number: [450/565] 79% | Training loss: 0.6884579091601901
Epoch: 21 | Iteration number: [460/565] 81% | Training loss: 0.6884213634159254
Epoch: 21 | Iteration number: [470/565] 83% | Training loss: 0.6883880870139345
Epoch: 21 | Iteration number: [480/565] 84% | Training loss: 0.6883644182235003
Epoch: 21 | Iteration number: [490/565] 86% | Training loss: 0.6883442687744997
Epoch: 21 | Iteration number: [500/565] 88% | Training loss: 0.6883169926404953
Epoch: 21 | Iteration number: [510/565] 90% | Training loss: 0.6882994698543174
Epoch: 21 | Iteration number: [520/565] 92% | Training loss: 0.6882770547500023
Epoch: 21 | Iteration number: [530/565] 93% | Training loss: 0.6882460334390964
Epoch: 21 | Iteration number: [540/565] 95% | Training loss: 0.6882221854395336
Epoch: 21 | Iteration number: [550/565] 97% | Training loss: 0.6882002622430975
Epoch: 21 | Iteration number: [560/565] 99% | Training loss: 0.6881838030048779

 End of epoch: 21 | Train Loss: 0.6869563252524992 | Training Time: 90 

 End of epoch: 21 | Eval Loss: 0.6899366804531643 | Evaluating Time: 6 
Epoch: 22 | Iteration number: [10/565] 1% | Training loss: 0.7554947733879089
Epoch: 22 | Iteration number: [20/565] 3% | Training loss: 0.7209830403327941
Epoch: 22 | Iteration number: [30/565] 5% | Training loss: 0.7096126139163971
Epoch: 22 | Iteration number: [40/565] 7% | Training loss: 0.7039996892213821
Epoch: 22 | Iteration number: [50/565] 8% | Training loss: 0.700471134185791
Epoch: 22 | Iteration number: [60/565] 10% | Training loss: 0.6981857707103093
Epoch: 22 | Iteration number: [70/565] 12% | Training loss: 0.6966023666518075
Epoch: 22 | Iteration number: [80/565] 14% | Training loss: 0.6954039074480534
Epoch: 22 | Iteration number: [90/565] 15% | Training loss: 0.6944522069560157
Epoch: 22 | Iteration number: [100/565] 17% | Training loss: 0.6937043732404709
Epoch: 22 | Iteration number: [110/565] 19% | Training loss: 0.6930909644473683
Epoch: 22 | Iteration number: [120/565] 21% | Training loss: 0.6925704265634219
Epoch: 22 | Iteration number: [130/565] 23% | Training loss: 0.6921808710465065
Epoch: 22 | Iteration number: [140/565] 24% | Training loss: 0.6918220034667424
Epoch: 22 | Iteration number: [150/565] 26% | Training loss: 0.6914965709050497
Epoch: 22 | Iteration number: [160/565] 28% | Training loss: 0.6912013210356236
Epoch: 22 | Iteration number: [170/565] 30% | Training loss: 0.6909584792221294
Epoch: 22 | Iteration number: [180/565] 31% | Training loss: 0.6907254768742456
Epoch: 22 | Iteration number: [190/565] 33% | Training loss: 0.6905339341414602
Epoch: 22 | Iteration number: [200/565] 35% | Training loss: 0.6903446239233016
Epoch: 22 | Iteration number: [210/565] 37% | Training loss: 0.6901763004916055
Epoch: 22 | Iteration number: [220/565] 38% | Training loss: 0.6899947041814978
Epoch: 22 | Iteration number: [230/565] 40% | Training loss: 0.6898727111194445
Epoch: 22 | Iteration number: [240/565] 42% | Training loss: 0.6897422653933366
Epoch: 22 | Iteration number: [250/565] 44% | Training loss: 0.6896256887912751
Epoch: 22 | Iteration number: [260/565] 46% | Training loss: 0.689528900384903
Epoch: 22 | Iteration number: [270/565] 47% | Training loss: 0.6894268117569111
Epoch: 22 | Iteration number: [280/565] 49% | Training loss: 0.6893507278391293
Epoch: 22 | Iteration number: [290/565] 51% | Training loss: 0.6892846239024195
Epoch: 22 | Iteration number: [300/565] 53% | Training loss: 0.6892069228490194
Epoch: 22 | Iteration number: [310/565] 54% | Training loss: 0.6891335946898307
Epoch: 22 | Iteration number: [320/565] 56% | Training loss: 0.68905293866992
Epoch: 22 | Iteration number: [330/565] 58% | Training loss: 0.689001218658505
Epoch: 22 | Iteration number: [340/565] 60% | Training loss: 0.6889416812097325
Epoch: 22 | Iteration number: [350/565] 61% | Training loss: 0.6888826767035893
Epoch: 22 | Iteration number: [360/565] 63% | Training loss: 0.6888332840469148
Epoch: 22 | Iteration number: [370/565] 65% | Training loss: 0.6887880152947193
Epoch: 22 | Iteration number: [380/565] 67% | Training loss: 0.688754740827962
Epoch: 22 | Iteration number: [390/565] 69% | Training loss: 0.6887073278427124
Epoch: 22 | Iteration number: [400/565] 70% | Training loss: 0.6886620581150055
Epoch: 22 | Iteration number: [410/565] 72% | Training loss: 0.688620132644002
Epoch: 22 | Iteration number: [420/565] 74% | Training loss: 0.6885709420556114
Epoch: 22 | Iteration number: [430/565] 76% | Training loss: 0.6885257291239362
Epoch: 22 | Iteration number: [440/565] 77% | Training loss: 0.6884805908257311
Epoch: 22 | Iteration number: [450/565] 79% | Training loss: 0.6884482842021519
Epoch: 22 | Iteration number: [460/565] 81% | Training loss: 0.688421461634014
Epoch: 22 | Iteration number: [470/565] 83% | Training loss: 0.6884004381108791
Epoch: 22 | Iteration number: [480/565] 84% | Training loss: 0.6883706887563069
Epoch: 22 | Iteration number: [490/565] 86% | Training loss: 0.6883381436065752
Epoch: 22 | Iteration number: [500/565] 88% | Training loss: 0.6883105909824372
Epoch: 22 | Iteration number: [510/565] 90% | Training loss: 0.6882778431854996
Epoch: 22 | Iteration number: [520/565] 92% | Training loss: 0.6882474067119452
Epoch: 22 | Iteration number: [530/565] 93% | Training loss: 0.6882192117987939
Epoch: 22 | Iteration number: [540/565] 95% | Training loss: 0.6881995074175022
Epoch: 22 | Iteration number: [550/565] 97% | Training loss: 0.6881796065243808
Epoch: 22 | Iteration number: [560/565] 99% | Training loss: 0.6881618975528649

 End of epoch: 22 | Train Loss: 0.6869350554668798 | Training Time: 89 

 End of epoch: 22 | Eval Loss: 0.6895755018506732 | Evaluating Time: 5 
Epoch: 23 | Iteration number: [10/565] 1% | Training loss: 0.7554708600044251
Epoch: 23 | Iteration number: [20/565] 3% | Training loss: 0.7213187247514725
Epoch: 23 | Iteration number: [30/565] 5% | Training loss: 0.7098719537258148
Epoch: 23 | Iteration number: [40/565] 7% | Training loss: 0.7041288912296295
Epoch: 23 | Iteration number: [50/565] 8% | Training loss: 0.7006396102905273
Epoch: 23 | Iteration number: [60/565] 10% | Training loss: 0.6983183979988098
Epoch: 23 | Iteration number: [70/565] 12% | Training loss: 0.6966227037566048
Epoch: 23 | Iteration number: [80/565] 14% | Training loss: 0.6954159222543239
Epoch: 23 | Iteration number: [90/565] 15% | Training loss: 0.6944648265838623
Epoch: 23 | Iteration number: [100/565] 17% | Training loss: 0.6936992436647416
Epoch: 23 | Iteration number: [110/565] 19% | Training loss: 0.693068432266062
Epoch: 23 | Iteration number: [120/565] 21% | Training loss: 0.6926026071111361
Epoch: 23 | Iteration number: [130/565] 23% | Training loss: 0.6921515671106485
Epoch: 23 | Iteration number: [140/565] 24% | Training loss: 0.6917854747601918
Epoch: 23 | Iteration number: [150/565] 26% | Training loss: 0.6914680083592732
Epoch: 23 | Iteration number: [160/565] 28% | Training loss: 0.691201027855277
Epoch: 23 | Iteration number: [170/565] 30% | Training loss: 0.6909381947096657
Epoch: 23 | Iteration number: [180/565] 31% | Training loss: 0.6907165629996194
Epoch: 23 | Iteration number: [190/565] 33% | Training loss: 0.690519885954104
Epoch: 23 | Iteration number: [200/565] 35% | Training loss: 0.6903603684902191
Epoch: 23 | Iteration number: [210/565] 37% | Training loss: 0.6902034697078523
Epoch: 23 | Iteration number: [220/565] 38% | Training loss: 0.6900590124455366
Epoch: 23 | Iteration number: [230/565] 40% | Training loss: 0.6899216356484786
Epoch: 23 | Iteration number: [240/565] 42% | Training loss: 0.6897980327407519
Epoch: 23 | Iteration number: [250/565] 44% | Training loss: 0.6896895246505738
Epoch: 23 | Iteration number: [260/565] 46% | Training loss: 0.6895872306365233
Epoch: 23 | Iteration number: [270/565] 47% | Training loss: 0.6895011460339582
Epoch: 23 | Iteration number: [280/565] 49% | Training loss: 0.689423603458064
Epoch: 23 | Iteration number: [290/565] 51% | Training loss: 0.6893360343472711
Epoch: 23 | Iteration number: [300/565] 53% | Training loss: 0.6892421356836955
Epoch: 23 | Iteration number: [310/565] 54% | Training loss: 0.689155981233043
Epoch: 23 | Iteration number: [320/565] 56% | Training loss: 0.6890814520418644
Epoch: 23 | Iteration number: [330/565] 58% | Training loss: 0.6890104774272803
Epoch: 23 | Iteration number: [340/565] 60% | Training loss: 0.6889514891540303
Epoch: 23 | Iteration number: [350/565] 61% | Training loss: 0.6888854241371155
Epoch: 23 | Iteration number: [360/565] 63% | Training loss: 0.6888436686661509
Epoch: 23 | Iteration number: [370/565] 65% | Training loss: 0.688789136345322
Epoch: 23 | Iteration number: [380/565] 67% | Training loss: 0.6887423029071407
Epoch: 23 | Iteration number: [390/565] 69% | Training loss: 0.6886890290639339
Epoch: 23 | Iteration number: [400/565] 70% | Training loss: 0.6886429436504841
Epoch: 23 | Iteration number: [410/565] 72% | Training loss: 0.6886047257155907
Epoch: 23 | Iteration number: [420/565] 74% | Training loss: 0.6885679477737063
Epoch: 23 | Iteration number: [430/565] 76% | Training loss: 0.6885266746199408
Epoch: 23 | Iteration number: [440/565] 77% | Training loss: 0.6885023175315423
Epoch: 23 | Iteration number: [450/565] 79% | Training loss: 0.688463253710005
Epoch: 23 | Iteration number: [460/565] 81% | Training loss: 0.6884357523659002
Epoch: 23 | Iteration number: [470/565] 83% | Training loss: 0.6884036026102431
Epoch: 23 | Iteration number: [480/565] 84% | Training loss: 0.6883652421335379
Epoch: 23 | Iteration number: [490/565] 86% | Training loss: 0.6883331813374344
Epoch: 23 | Iteration number: [500/565] 88% | Training loss: 0.6882999762296677
Epoch: 23 | Iteration number: [510/565] 90% | Training loss: 0.6882784566458534
Epoch: 23 | Iteration number: [520/565] 92% | Training loss: 0.6882534992236358
Epoch: 23 | Iteration number: [530/565] 93% | Training loss: 0.6882274015894476
Epoch: 23 | Iteration number: [540/565] 95% | Training loss: 0.6882082748192327
Epoch: 23 | Iteration number: [550/565] 97% | Training loss: 0.6881818720427426
Epoch: 23 | Iteration number: [560/565] 99% | Training loss: 0.6881590867681163

 End of epoch: 23 | Train Loss: 0.6869292386865193 | Training Time: 88 

 End of epoch: 23 | Eval Loss: 0.6898120471409389 | Evaluating Time: 6 
Epoch: 24 | Iteration number: [10/565] 1% | Training loss: 0.7552846133708954
Epoch: 24 | Iteration number: [20/565] 3% | Training loss: 0.7211152613162994
Epoch: 24 | Iteration number: [30/565] 5% | Training loss: 0.7097490708033244
Epoch: 24 | Iteration number: [40/565] 7% | Training loss: 0.7039336159825325
Epoch: 24 | Iteration number: [50/565] 8% | Training loss: 0.700540406703949
Epoch: 24 | Iteration number: [60/565] 10% | Training loss: 0.6981855452060699
Epoch: 24 | Iteration number: [70/565] 12% | Training loss: 0.6965676537581853
Epoch: 24 | Iteration number: [80/565] 14% | Training loss: 0.6953675009310245
Epoch: 24 | Iteration number: [90/565] 15% | Training loss: 0.6944335414303674
Epoch: 24 | Iteration number: [100/565] 17% | Training loss: 0.6936911022663117
Epoch: 24 | Iteration number: [110/565] 19% | Training loss: 0.6931080969897183
Epoch: 24 | Iteration number: [120/565] 21% | Training loss: 0.6926314691702525
Epoch: 24 | Iteration number: [130/565] 23% | Training loss: 0.6922102520099053
Epoch: 24 | Iteration number: [140/565] 24% | Training loss: 0.691861896429743
Epoch: 24 | Iteration number: [150/565] 26% | Training loss: 0.6915092269579569
Epoch: 24 | Iteration number: [160/565] 28% | Training loss: 0.6912088304758072
Epoch: 24 | Iteration number: [170/565] 30% | Training loss: 0.6909579638172598
Epoch: 24 | Iteration number: [180/565] 31% | Training loss: 0.6907681465148926
Epoch: 24 | Iteration number: [190/565] 33% | Training loss: 0.6905665560772545
Epoch: 24 | Iteration number: [200/565] 35% | Training loss: 0.6903960195183754
Epoch: 24 | Iteration number: [210/565] 37% | Training loss: 0.6902481783004034
Epoch: 24 | Iteration number: [220/565] 38% | Training loss: 0.6900707569989291
Epoch: 24 | Iteration number: [230/565] 40% | Training loss: 0.6899273683195529
Epoch: 24 | Iteration number: [240/565] 42% | Training loss: 0.6897931059201559
Epoch: 24 | Iteration number: [250/565] 44% | Training loss: 0.6896788597106933
Epoch: 24 | Iteration number: [260/565] 46% | Training loss: 0.6895880034336677
Epoch: 24 | Iteration number: [270/565] 47% | Training loss: 0.6894862442104904
Epoch: 24 | Iteration number: [280/565] 49% | Training loss: 0.6893798955849239
Epoch: 24 | Iteration number: [290/565] 51% | Training loss: 0.6892976701259613
Epoch: 24 | Iteration number: [300/565] 53% | Training loss: 0.6892054857810338
Epoch: 24 | Iteration number: [310/565] 54% | Training loss: 0.6891299038164077
Epoch: 24 | Iteration number: [320/565] 56% | Training loss: 0.6890794217586518
Epoch: 24 | Iteration number: [330/565] 58% | Training loss: 0.6890169541041057
Epoch: 24 | Iteration number: [340/565] 60% | Training loss: 0.6889607050839592
Epoch: 24 | Iteration number: [350/565] 61% | Training loss: 0.6888883406775338
Epoch: 24 | Iteration number: [360/565] 63% | Training loss: 0.6888541065984302
Epoch: 24 | Iteration number: [370/565] 65% | Training loss: 0.6888128955621977
Epoch: 24 | Iteration number: [380/565] 67% | Training loss: 0.6887678892988908
Epoch: 24 | Iteration number: [390/565] 69% | Training loss: 0.6887223529510009
Epoch: 24 | Iteration number: [400/565] 70% | Training loss: 0.6886767852306366
Epoch: 24 | Iteration number: [410/565] 72% | Training loss: 0.6886330854601976
Epoch: 24 | Iteration number: [420/565] 74% | Training loss: 0.6886005828777949
Epoch: 24 | Iteration number: [430/565] 76% | Training loss: 0.6885625234870023
Epoch: 24 | Iteration number: [440/565] 77% | Training loss: 0.688531317223202
Epoch: 24 | Iteration number: [450/565] 79% | Training loss: 0.6884996831417084
Epoch: 24 | Iteration number: [460/565] 81% | Training loss: 0.6884633008552634
Epoch: 24 | Iteration number: [470/565] 83% | Training loss: 0.6884320232462375
Epoch: 24 | Iteration number: [480/565] 84% | Training loss: 0.6883930580069622
Epoch: 24 | Iteration number: [490/565] 86% | Training loss: 0.6883581537373212
Epoch: 24 | Iteration number: [500/565] 88% | Training loss: 0.6883258602619171
Epoch: 24 | Iteration number: [510/565] 90% | Training loss: 0.6882949619900947
Epoch: 24 | Iteration number: [520/565] 92% | Training loss: 0.6882690387276503
Epoch: 24 | Iteration number: [530/565] 93% | Training loss: 0.6882391275099988
Epoch: 24 | Iteration number: [540/565] 95% | Training loss: 0.6882148972264043
Epoch: 24 | Iteration number: [550/565] 97% | Training loss: 0.6881910024989735
Epoch: 24 | Iteration number: [560/565] 99% | Training loss: 0.6881735249289445

 End of epoch: 24 | Train Loss: 0.6869406050285407 | Training Time: 90 

 End of epoch: 24 | Eval Loss: 0.6894820332527161 | Evaluating Time: 5 
Epoch: 25 | Iteration number: [10/565] 1% | Training loss: 0.7556824505329132
Epoch: 25 | Iteration number: [20/565] 3% | Training loss: 0.7213686048984528
Epoch: 25 | Iteration number: [30/565] 5% | Training loss: 0.7098801016807557
Epoch: 25 | Iteration number: [40/565] 7% | Training loss: 0.7041329890489578
Epoch: 25 | Iteration number: [50/565] 8% | Training loss: 0.7007489228248596
Epoch: 25 | Iteration number: [60/565] 10% | Training loss: 0.6983778655529023
Epoch: 25 | Iteration number: [70/565] 12% | Training loss: 0.6967272656304496
Epoch: 25 | Iteration number: [80/565] 14% | Training loss: 0.6955837540328502
Epoch: 25 | Iteration number: [90/565] 15% | Training loss: 0.6946340693367852
Epoch: 25 | Iteration number: [100/565] 17% | Training loss: 0.6938819587230682
Epoch: 25 | Iteration number: [110/565] 19% | Training loss: 0.6932547899809751
Epoch: 25 | Iteration number: [120/565] 21% | Training loss: 0.6927334566911062
Epoch: 25 | Iteration number: [130/565] 23% | Training loss: 0.6922730656770559
Epoch: 25 | Iteration number: [140/565] 24% | Training loss: 0.6918621425117765
Epoch: 25 | Iteration number: [150/565] 26% | Training loss: 0.6915388313929239
Epoch: 25 | Iteration number: [160/565] 28% | Training loss: 0.691255447268486
Epoch: 25 | Iteration number: [170/565] 30% | Training loss: 0.6910070878617903
Epoch: 25 | Iteration number: [180/565] 31% | Training loss: 0.6907920734749899
Epoch: 25 | Iteration number: [190/565] 33% | Training loss: 0.6905988461092899
Epoch: 25 | Iteration number: [200/565] 35% | Training loss: 0.690421661734581
Epoch: 25 | Iteration number: [210/565] 37% | Training loss: 0.6902407157988776
Epoch: 25 | Iteration number: [220/565] 38% | Training loss: 0.6901021331548691
Epoch: 25 | Iteration number: [230/565] 40% | Training loss: 0.6899646632049394
Epoch: 25 | Iteration number: [240/565] 42% | Training loss: 0.6898293331265449
Epoch: 25 | Iteration number: [250/565] 44% | Training loss: 0.6897173311710357
Epoch: 25 | Iteration number: [260/565] 46% | Training loss: 0.689621365070343
Epoch: 25 | Iteration number: [270/565] 47% | Training loss: 0.6895211029935766
Epoch: 25 | Iteration number: [280/565] 49% | Training loss: 0.6894395498292787
Epoch: 25 | Iteration number: [290/565] 51% | Training loss: 0.689342738020009
Epoch: 25 | Iteration number: [300/565] 53% | Training loss: 0.6892553981145223
Epoch: 25 | Iteration number: [310/565] 54% | Training loss: 0.689175158931363
Epoch: 25 | Iteration number: [320/565] 56% | Training loss: 0.6891063949093222
Epoch: 25 | Iteration number: [330/565] 58% | Training loss: 0.6890422165393829
Epoch: 25 | Iteration number: [340/565] 60% | Training loss: 0.6889662115012898
Epoch: 25 | Iteration number: [350/565] 61% | Training loss: 0.6888977079732077
Epoch: 25 | Iteration number: [360/565] 63% | Training loss: 0.6888421222567558
Epoch: 25 | Iteration number: [370/565] 65% | Training loss: 0.6887917589496921
Epoch: 25 | Iteration number: [380/565] 67% | Training loss: 0.68875664111815
Epoch: 25 | Iteration number: [390/565] 69% | Training loss: 0.6887082223708813
Epoch: 25 | Iteration number: [400/565] 70% | Training loss: 0.6886554922163487
Epoch: 25 | Iteration number: [410/565] 72% | Training loss: 0.6886237490467909
Epoch: 25 | Iteration number: [420/565] 74% | Training loss: 0.6885740019026256
Epoch: 25 | Iteration number: [430/565] 76% | Training loss: 0.6885391501493232
Epoch: 25 | Iteration number: [440/565] 77% | Training loss: 0.688503616235473
Epoch: 25 | Iteration number: [450/565] 79% | Training loss: 0.6884644907050662
Epoch: 25 | Iteration number: [460/565] 81% | Training loss: 0.6884329122045766
Epoch: 25 | Iteration number: [470/565] 83% | Training loss: 0.6884020975295534
Epoch: 25 | Iteration number: [480/565] 84% | Training loss: 0.6883611885209878
Epoch: 25 | Iteration number: [490/565] 86% | Training loss: 0.6883192047780874
Epoch: 25 | Iteration number: [500/565] 88% | Training loss: 0.6882976185083389
Epoch: 25 | Iteration number: [510/565] 90% | Training loss: 0.6882775195673401
Epoch: 25 | Iteration number: [520/565] 92% | Training loss: 0.6882473945617675
Epoch: 25 | Iteration number: [530/565] 93% | Training loss: 0.6882183196409694
Epoch: 25 | Iteration number: [540/565] 95% | Training loss: 0.6881953019786764
Epoch: 25 | Iteration number: [550/565] 97% | Training loss: 0.688171268159693
Epoch: 25 | Iteration number: [560/565] 99% | Training loss: 0.6881504825183323

 End of epoch: 25 | Train Loss: 0.6869217774509329 | Training Time: 89 

 End of epoch: 25 | Eval Loss: 0.6898901377405439 | Evaluating Time: 6 
Epoch: 26 | Iteration number: [10/565] 1% | Training loss: 0.755482816696167
Epoch: 26 | Iteration number: [20/565] 3% | Training loss: 0.7211200326681138
Epoch: 26 | Iteration number: [30/565] 5% | Training loss: 0.7097386598587037
Epoch: 26 | Iteration number: [40/565] 7% | Training loss: 0.7039760649204254
Epoch: 26 | Iteration number: [50/565] 8% | Training loss: 0.7006148934364319
Epoch: 26 | Iteration number: [60/565] 10% | Training loss: 0.6982984811067581
Epoch: 26 | Iteration number: [70/565] 12% | Training loss: 0.6966416375977652
Epoch: 26 | Iteration number: [80/565] 14% | Training loss: 0.6953772827982903
Epoch: 26 | Iteration number: [90/565] 15% | Training loss: 0.6944847093688117
Epoch: 26 | Iteration number: [100/565] 17% | Training loss: 0.6937683421373367
Epoch: 26 | Iteration number: [110/565] 19% | Training loss: 0.6931368350982666
Epoch: 26 | Iteration number: [120/565] 21% | Training loss: 0.692608331143856
Epoch: 26 | Iteration number: [130/565] 23% | Training loss: 0.6921756308812361
Epoch: 26 | Iteration number: [140/565] 24% | Training loss: 0.6917925000190734
Epoch: 26 | Iteration number: [150/565] 26% | Training loss: 0.6914615404605865
Epoch: 26 | Iteration number: [160/565] 28% | Training loss: 0.6911754105240107
Epoch: 26 | Iteration number: [170/565] 30% | Training loss: 0.6909496174139135
Epoch: 26 | Iteration number: [180/565] 31% | Training loss: 0.6907133877277374
Epoch: 26 | Iteration number: [190/565] 33% | Training loss: 0.6905025579427418
Epoch: 26 | Iteration number: [200/565] 35% | Training loss: 0.6903258806467056
Epoch: 26 | Iteration number: [210/565] 37% | Training loss: 0.690148016952333
Epoch: 26 | Iteration number: [220/565] 38% | Training loss: 0.6900086134672165
Epoch: 26 | Iteration number: [230/565] 40% | Training loss: 0.6898717095022616
Epoch: 26 | Iteration number: [240/565] 42% | Training loss: 0.6897707877059778
Epoch: 26 | Iteration number: [250/565] 44% | Training loss: 0.6896602101325989
Epoch: 26 | Iteration number: [260/565] 46% | Training loss: 0.689564583163995
Epoch: 26 | Iteration number: [270/565] 47% | Training loss: 0.6894700701589938
Epoch: 26 | Iteration number: [280/565] 49% | Training loss: 0.6893752070409911
Epoch: 26 | Iteration number: [290/565] 51% | Training loss: 0.6892779510596703
Epoch: 26 | Iteration number: [300/565] 53% | Training loss: 0.6892145850261052
Epoch: 26 | Iteration number: [310/565] 54% | Training loss: 0.689138122335557
Epoch: 26 | Iteration number: [320/565] 56% | Training loss: 0.689072817005217
Epoch: 26 | Iteration number: [330/565] 58% | Training loss: 0.6890116133473136
Epoch: 26 | Iteration number: [340/565] 60% | Training loss: 0.6889374871464337
Epoch: 26 | Iteration number: [350/565] 61% | Training loss: 0.6888833059583391
Epoch: 26 | Iteration number: [360/565] 63% | Training loss: 0.6888215512037277
Epoch: 26 | Iteration number: [370/565] 65% | Training loss: 0.6887737912100714
Epoch: 26 | Iteration number: [380/565] 67% | Training loss: 0.6887306864324368
Epoch: 26 | Iteration number: [390/565] 69% | Training loss: 0.6886879098721039
Epoch: 26 | Iteration number: [400/565] 70% | Training loss: 0.6886415040493011
Epoch: 26 | Iteration number: [410/565] 72% | Training loss: 0.6885815120324856
Epoch: 26 | Iteration number: [420/565] 74% | Training loss: 0.6885394148883366
Epoch: 26 | Iteration number: [430/565] 76% | Training loss: 0.6884989153507144
Epoch: 26 | Iteration number: [440/565] 77% | Training loss: 0.6884566156701608
Epoch: 26 | Iteration number: [450/565] 79% | Training loss: 0.6884171687232123
Epoch: 26 | Iteration number: [460/565] 81% | Training loss: 0.688391071298848
Epoch: 26 | Iteration number: [470/565] 83% | Training loss: 0.6883536458015442
Epoch: 26 | Iteration number: [480/565] 84% | Training loss: 0.6883280454824369
Epoch: 26 | Iteration number: [490/565] 86% | Training loss: 0.6883001443074674
Epoch: 26 | Iteration number: [500/565] 88% | Training loss: 0.6882741078138351
Epoch: 26 | Iteration number: [510/565] 90% | Training loss: 0.6882416078857347
Epoch: 26 | Iteration number: [520/565] 92% | Training loss: 0.6882162247712795
Epoch: 26 | Iteration number: [530/565] 93% | Training loss: 0.6881956796601133
Epoch: 26 | Iteration number: [540/565] 95% | Training loss: 0.6881765560971366
Epoch: 26 | Iteration number: [550/565] 97% | Training loss: 0.6881567123803225
Epoch: 26 | Iteration number: [560/565] 99% | Training loss: 0.6881343784076827

 End of epoch: 26 | Train Loss: 0.6869077887155314 | Training Time: 88 

 End of epoch: 26 | Eval Loss: 0.6900485072817121 | Evaluating Time: 6 
Epoch: 27 | Iteration number: [10/565] 1% | Training loss: 0.755398017168045
Epoch: 27 | Iteration number: [20/565] 3% | Training loss: 0.7211155295372009
Epoch: 27 | Iteration number: [30/565] 5% | Training loss: 0.7096323013305664
Epoch: 27 | Iteration number: [40/565] 7% | Training loss: 0.7039648666977882
Epoch: 27 | Iteration number: [50/565] 8% | Training loss: 0.7005488061904908
Epoch: 27 | Iteration number: [60/565] 10% | Training loss: 0.6983163406451544
Epoch: 27 | Iteration number: [70/565] 12% | Training loss: 0.6967814036778042
Epoch: 27 | Iteration number: [80/565] 14% | Training loss: 0.6955746322870254
Epoch: 27 | Iteration number: [90/565] 15% | Training loss: 0.6946305116017659
Epoch: 27 | Iteration number: [100/565] 17% | Training loss: 0.6938705641031265
Epoch: 27 | Iteration number: [110/565] 19% | Training loss: 0.693204606663097
Epoch: 27 | Iteration number: [120/565] 21% | Training loss: 0.6926686118046442
Epoch: 27 | Iteration number: [130/565] 23% | Training loss: 0.6922248244285584
Epoch: 27 | Iteration number: [140/565] 24% | Training loss: 0.6918374563966478
Epoch: 27 | Iteration number: [150/565] 26% | Training loss: 0.691514253616333
Epoch: 27 | Iteration number: [160/565] 28% | Training loss: 0.6912021592259407
Epoch: 27 | Iteration number: [170/565] 30% | Training loss: 0.6909715989056755
Epoch: 27 | Iteration number: [180/565] 31% | Training loss: 0.6907541318072213
Epoch: 27 | Iteration number: [190/565] 33% | Training loss: 0.6905526016887865
Epoch: 27 | Iteration number: [200/565] 35% | Training loss: 0.6904027768969536
Epoch: 27 | Iteration number: [210/565] 37% | Training loss: 0.6902377821150281
Epoch: 27 | Iteration number: [220/565] 38% | Training loss: 0.6900721723383123
Epoch: 27 | Iteration number: [230/565] 40% | Training loss: 0.6899261466834856
Epoch: 27 | Iteration number: [240/565] 42% | Training loss: 0.6898020061353842
Epoch: 27 | Iteration number: [250/565] 44% | Training loss: 0.6896758317947388
Epoch: 27 | Iteration number: [260/565] 46% | Training loss: 0.6895597721521671
Epoch: 27 | Iteration number: [270/565] 47% | Training loss: 0.6894552425101951
Epoch: 27 | Iteration number: [280/565] 49% | Training loss: 0.6893712420548711
Epoch: 27 | Iteration number: [290/565] 51% | Training loss: 0.6892881613353203
Epoch: 27 | Iteration number: [300/565] 53% | Training loss: 0.6892121301094691
Epoch: 27 | Iteration number: [310/565] 54% | Training loss: 0.6891363851485713
Epoch: 27 | Iteration number: [320/565] 56% | Training loss: 0.6890722131356597
Epoch: 27 | Iteration number: [330/565] 58% | Training loss: 0.6890080437515721
Epoch: 27 | Iteration number: [340/565] 60% | Training loss: 0.688931265298058
Epoch: 27 | Iteration number: [350/565] 61% | Training loss: 0.6888816092695509
Epoch: 27 | Iteration number: [360/565] 63% | Training loss: 0.6888212944070499
Epoch: 27 | Iteration number: [370/565] 65% | Training loss: 0.6887667691385424
Epoch: 27 | Iteration number: [380/565] 67% | Training loss: 0.6887220621109009
Epoch: 27 | Iteration number: [390/565] 69% | Training loss: 0.6886704243146456
Epoch: 27 | Iteration number: [400/565] 70% | Training loss: 0.6886286692321301
Epoch: 27 | Iteration number: [410/565] 72% | Training loss: 0.6885973603260226
Epoch: 27 | Iteration number: [420/565] 74% | Training loss: 0.688549063886915
Epoch: 27 | Iteration number: [430/565] 76% | Training loss: 0.6885125523389772
Epoch: 27 | Iteration number: [440/565] 77% | Training loss: 0.6884700471704657
Epoch: 27 | Iteration number: [450/565] 79% | Training loss: 0.6884348703755273
Epoch: 27 | Iteration number: [460/565] 81% | Training loss: 0.6884101726438688
Epoch: 27 | Iteration number: [470/565] 83% | Training loss: 0.6883769462717341
Epoch: 27 | Iteration number: [480/565] 84% | Training loss: 0.6883470450838407
Epoch: 27 | Iteration number: [490/565] 86% | Training loss: 0.6883213135660912
Epoch: 27 | Iteration number: [500/565] 88% | Training loss: 0.6882979379892349
Epoch: 27 | Iteration number: [510/565] 90% | Training loss: 0.6882620736664417
Epoch: 27 | Iteration number: [520/565] 92% | Training loss: 0.688229733820145
Epoch: 27 | Iteration number: [530/565] 93% | Training loss: 0.6882107431033873
Epoch: 27 | Iteration number: [540/565] 95% | Training loss: 0.6881783913683008
Epoch: 27 | Iteration number: [550/565] 97% | Training loss: 0.6881519511612979
Epoch: 27 | Iteration number: [560/565] 99% | Training loss: 0.688124912657908

 End of epoch: 27 | Train Loss: 0.6868990440284256 | Training Time: 91 

 End of epoch: 27 | Eval Loss: 0.6897730997630528 | Evaluating Time: 6 
Epoch: 28 | Iteration number: [10/565] 1% | Training loss: 0.7554599285125733
Epoch: 28 | Iteration number: [20/565] 3% | Training loss: 0.7213345319032669
Epoch: 28 | Iteration number: [30/565] 5% | Training loss: 0.7097695350646973
Epoch: 28 | Iteration number: [40/565] 7% | Training loss: 0.7041156247258187
Epoch: 28 | Iteration number: [50/565] 8% | Training loss: 0.7007236909866333
Epoch: 28 | Iteration number: [60/565] 10% | Training loss: 0.6984527200460434
Epoch: 28 | Iteration number: [70/565] 12% | Training loss: 0.6967687887804849
Epoch: 28 | Iteration number: [80/565] 14% | Training loss: 0.6955194987356663
Epoch: 28 | Iteration number: [90/565] 15% | Training loss: 0.694569773806466
Epoch: 28 | Iteration number: [100/565] 17% | Training loss: 0.6937622094154358
Epoch: 28 | Iteration number: [110/565] 19% | Training loss: 0.6931017192927273
Epoch: 28 | Iteration number: [120/565] 21% | Training loss: 0.6925542722145717
Epoch: 28 | Iteration number: [130/565] 23% | Training loss: 0.6921120611520913
Epoch: 28 | Iteration number: [140/565] 24% | Training loss: 0.6917512727635248
Epoch: 28 | Iteration number: [150/565] 26% | Training loss: 0.6914159456888834
Epoch: 28 | Iteration number: [160/565] 28% | Training loss: 0.6911326333880424
Epoch: 28 | Iteration number: [170/565] 30% | Training loss: 0.690919130339342
Epoch: 28 | Iteration number: [180/565] 31% | Training loss: 0.6907047278351254
Epoch: 28 | Iteration number: [190/565] 33% | Training loss: 0.6904946261330654
Epoch: 28 | Iteration number: [200/565] 35% | Training loss: 0.6903230887651444
Epoch: 28 | Iteration number: [210/565] 37% | Training loss: 0.6901601499035245
Epoch: 28 | Iteration number: [220/565] 38% | Training loss: 0.690005446022207
Epoch: 28 | Iteration number: [230/565] 40% | Training loss: 0.6898844210997872
Epoch: 28 | Iteration number: [240/565] 42% | Training loss: 0.6897678606212139
Epoch: 28 | Iteration number: [250/565] 44% | Training loss: 0.6896638059616089
Epoch: 28 | Iteration number: [260/565] 46% | Training loss: 0.6895493078690309
Epoch: 28 | Iteration number: [270/565] 47% | Training loss: 0.689454107814365
Epoch: 28 | Iteration number: [280/565] 49% | Training loss: 0.6893513969012669
Epoch: 28 | Iteration number: [290/565] 51% | Training loss: 0.689288263896416
Epoch: 28 | Iteration number: [300/565] 53% | Training loss: 0.6892166256904602
Epoch: 28 | Iteration number: [310/565] 54% | Training loss: 0.6891467461662908
Epoch: 28 | Iteration number: [320/565] 56% | Training loss: 0.6890868512913585
Epoch: 28 | Iteration number: [330/565] 58% | Training loss: 0.689003990093867
Epoch: 28 | Iteration number: [340/565] 60% | Training loss: 0.6889346839750514
Epoch: 28 | Iteration number: [350/565] 61% | Training loss: 0.6888647137369428
Epoch: 28 | Iteration number: [360/565] 63% | Training loss: 0.6887966713971562
Epoch: 28 | Iteration number: [370/565] 65% | Training loss: 0.6887320632870133
Epoch: 28 | Iteration number: [380/565] 67% | Training loss: 0.688684577377219
Epoch: 28 | Iteration number: [390/565] 69% | Training loss: 0.6886312475571266
Epoch: 28 | Iteration number: [400/565] 70% | Training loss: 0.6885936607420444
Epoch: 28 | Iteration number: [410/565] 72% | Training loss: 0.6885629430049803
Epoch: 28 | Iteration number: [420/565] 74% | Training loss: 0.6885179833287285
Epoch: 28 | Iteration number: [430/565] 76% | Training loss: 0.6884834681832513
Epoch: 28 | Iteration number: [440/565] 77% | Training loss: 0.6884382422674786
Epoch: 28 | Iteration number: [450/565] 79% | Training loss: 0.6884138558970557
Epoch: 28 | Iteration number: [460/565] 81% | Training loss: 0.6883897636247718
Epoch: 28 | Iteration number: [470/565] 83% | Training loss: 0.6883569955825806
Epoch: 28 | Iteration number: [480/565] 84% | Training loss: 0.6883256964385509
Epoch: 28 | Iteration number: [490/565] 86% | Training loss: 0.6882963512625013
Epoch: 28 | Iteration number: [500/565] 88% | Training loss: 0.688270852804184
Epoch: 28 | Iteration number: [510/565] 90% | Training loss: 0.6882425864537557
Epoch: 28 | Iteration number: [520/565] 92% | Training loss: 0.6882117588932698
Epoch: 28 | Iteration number: [530/565] 93% | Training loss: 0.688196937093195
Epoch: 28 | Iteration number: [540/565] 95% | Training loss: 0.688176965603122
Epoch: 28 | Iteration number: [550/565] 97% | Training loss: 0.6881532803448763
Epoch: 28 | Iteration number: [560/565] 99% | Training loss: 0.6881324779774461

 End of epoch: 28 | Train Loss: 0.6869086802533243 | Training Time: 91 

 End of epoch: 28 | Eval Loss: 0.6902069364275251 | Evaluating Time: 5 
Epoch: 29 | Iteration number: [10/565] 1% | Training loss: 0.755654901266098
Epoch: 29 | Iteration number: [20/565] 3% | Training loss: 0.7210791230201721
Epoch: 29 | Iteration number: [30/565] 5% | Training loss: 0.7096549451351166
Epoch: 29 | Iteration number: [40/565] 7% | Training loss: 0.7040892601013183
Epoch: 29 | Iteration number: [50/565] 8% | Training loss: 0.700701425075531
Epoch: 29 | Iteration number: [60/565] 10% | Training loss: 0.6985056469837825
Epoch: 29 | Iteration number: [70/565] 12% | Training loss: 0.6969094182763781
Epoch: 29 | Iteration number: [80/565] 14% | Training loss: 0.6956535205245018
Epoch: 29 | Iteration number: [90/565] 15% | Training loss: 0.6947115812036726
Epoch: 29 | Iteration number: [100/565] 17% | Training loss: 0.6939211493730545
Epoch: 29 | Iteration number: [110/565] 19% | Training loss: 0.6932425114241514
Epoch: 29 | Iteration number: [120/565] 21% | Training loss: 0.692685234049956
Epoch: 29 | Iteration number: [130/565] 23% | Training loss: 0.6922251903093778
Epoch: 29 | Iteration number: [140/565] 24% | Training loss: 0.6918254962989262
Epoch: 29 | Iteration number: [150/565] 26% | Training loss: 0.6914716422557831
Epoch: 29 | Iteration number: [160/565] 28% | Training loss: 0.6912035092711448
Epoch: 29 | Iteration number: [170/565] 30% | Training loss: 0.6909522726255305
Epoch: 29 | Iteration number: [180/565] 31% | Training loss: 0.6907213764058219
Epoch: 29 | Iteration number: [190/565] 33% | Training loss: 0.6905428986800345
Epoch: 29 | Iteration number: [200/565] 35% | Training loss: 0.690383886396885
Epoch: 29 | Iteration number: [210/565] 37% | Training loss: 0.6902073706899371
Epoch: 29 | Iteration number: [220/565] 38% | Training loss: 0.6900473754514348
Epoch: 29 | Iteration number: [230/565] 40% | Training loss: 0.6898905331673829
Epoch: 29 | Iteration number: [240/565] 42% | Training loss: 0.689765936632951
Epoch: 29 | Iteration number: [250/565] 44% | Training loss: 0.6896588957309723
Epoch: 29 | Iteration number: [260/565] 46% | Training loss: 0.6895380730812366
Epoch: 29 | Iteration number: [270/565] 47% | Training loss: 0.6894504456608384
Epoch: 29 | Iteration number: [280/565] 49% | Training loss: 0.6893569016030856
Epoch: 29 | Iteration number: [290/565] 51% | Training loss: 0.6892572074100889
Epoch: 29 | Iteration number: [300/565] 53% | Training loss: 0.6891838524738948
Epoch: 29 | Iteration number: [310/565] 54% | Training loss: 0.6891121197131372
Epoch: 29 | Iteration number: [320/565] 56% | Training loss: 0.6890491845086217
Epoch: 29 | Iteration number: [330/565] 58% | Training loss: 0.6889872876080599
Epoch: 29 | Iteration number: [340/565] 60% | Training loss: 0.6889228391296723
Epoch: 29 | Iteration number: [350/565] 61% | Training loss: 0.6888645826067243
Epoch: 29 | Iteration number: [360/565] 63% | Training loss: 0.6888162263565594
Epoch: 29 | Iteration number: [370/565] 65% | Training loss: 0.688761513458716
Epoch: 29 | Iteration number: [380/565] 67% | Training loss: 0.6887063343273966
Epoch: 29 | Iteration number: [390/565] 69% | Training loss: 0.6886519314386905
Epoch: 29 | Iteration number: [400/565] 70% | Training loss: 0.6886068207025527
Epoch: 29 | Iteration number: [410/565] 72% | Training loss: 0.6885593252937968
Epoch: 29 | Iteration number: [420/565] 74% | Training loss: 0.6885135395186288
Epoch: 29 | Iteration number: [430/565] 76% | Training loss: 0.6884746831516887
Epoch: 29 | Iteration number: [440/565] 77% | Training loss: 0.6884457421573725
Epoch: 29 | Iteration number: [450/565] 79% | Training loss: 0.6884119915962219
Epoch: 29 | Iteration number: [460/565] 81% | Training loss: 0.6883821206248325
Epoch: 29 | Iteration number: [470/565] 83% | Training loss: 0.6883470786378739
Epoch: 29 | Iteration number: [480/565] 84% | Training loss: 0.6883136335760355
Epoch: 29 | Iteration number: [490/565] 86% | Training loss: 0.6882759592971023
Epoch: 29 | Iteration number: [500/565] 88% | Training loss: 0.688254139304161
Epoch: 29 | Iteration number: [510/565] 90% | Training loss: 0.6882253964742024
Epoch: 29 | Iteration number: [520/565] 92% | Training loss: 0.6881968851272876
Epoch: 29 | Iteration number: [530/565] 93% | Training loss: 0.6881714862472607
Epoch: 29 | Iteration number: [540/565] 95% | Training loss: 0.6881536190156583
Epoch: 29 | Iteration number: [550/565] 97% | Training loss: 0.6881349727240476
Epoch: 29 | Iteration number: [560/565] 99% | Training loss: 0.688118851184845

 End of epoch: 29 | Train Loss: 0.6868890244348914 | Training Time: 91 

 End of epoch: 29 | Eval Loss: 0.6896860003471375 | Evaluating Time: 5 
Epoch: 30 | Iteration number: [10/565] 1% | Training loss: 0.7555620729923248
Epoch: 30 | Iteration number: [20/565] 3% | Training loss: 0.721272087097168
Epoch: 30 | Iteration number: [30/565] 5% | Training loss: 0.7097647150357564
Epoch: 30 | Iteration number: [40/565] 7% | Training loss: 0.7039210945367813
Epoch: 30 | Iteration number: [50/565] 8% | Training loss: 0.7005724585056305
Epoch: 30 | Iteration number: [60/565] 10% | Training loss: 0.6982096542914709
Epoch: 30 | Iteration number: [70/565] 12% | Training loss: 0.6965914121695927
Epoch: 30 | Iteration number: [80/565] 14% | Training loss: 0.6953905843198299
Epoch: 30 | Iteration number: [90/565] 15% | Training loss: 0.6944399078687032
Epoch: 30 | Iteration number: [100/565] 17% | Training loss: 0.6937399613857269
Epoch: 30 | Iteration number: [110/565] 19% | Training loss: 0.6931686303832314
Epoch: 30 | Iteration number: [120/565] 21% | Training loss: 0.6926167358954748
Epoch: 30 | Iteration number: [130/565] 23% | Training loss: 0.6921640721651224
Epoch: 30 | Iteration number: [140/565] 24% | Training loss: 0.691793413247381
Epoch: 30 | Iteration number: [150/565] 26% | Training loss: 0.6914604457219442
Epoch: 30 | Iteration number: [160/565] 28% | Training loss: 0.6911372080445289
Epoch: 30 | Iteration number: [170/565] 30% | Training loss: 0.69086774131831
Epoch: 30 | Iteration number: [180/565] 31% | Training loss: 0.6906575305594338
Epoch: 30 | Iteration number: [190/565] 33% | Training loss: 0.6904593696719722
Epoch: 30 | Iteration number: [200/565] 35% | Training loss: 0.6902830129861832
Epoch: 30 | Iteration number: [210/565] 37% | Training loss: 0.6901129160608565
Epoch: 30 | Iteration number: [220/565] 38% | Training loss: 0.6899553074078126
Epoch: 30 | Iteration number: [230/565] 40% | Training loss: 0.6898118604784427
Epoch: 30 | Iteration number: [240/565] 42% | Training loss: 0.6896945538620154
Epoch: 30 | Iteration number: [250/565] 44% | Training loss: 0.6895804731845856
Epoch: 30 | Iteration number: [260/565] 46% | Training loss: 0.6894890549091193
Epoch: 30 | Iteration number: [270/565] 47% | Training loss: 0.6893874870406257
Epoch: 30 | Iteration number: [280/565] 49% | Training loss: 0.6893026428563255
Epoch: 30 | Iteration number: [290/565] 51% | Training loss: 0.6892198692108022
Epoch: 30 | Iteration number: [300/565] 53% | Training loss: 0.6891507196426392
Epoch: 30 | Iteration number: [310/565] 54% | Training loss: 0.6890685883260542
Epoch: 30 | Iteration number: [320/565] 56% | Training loss: 0.6890091517940163
Epoch: 30 | Iteration number: [330/565] 58% | Training loss: 0.6889488173253608
Epoch: 30 | Iteration number: [340/565] 60% | Training loss: 0.6889032246435389
Epoch: 30 | Iteration number: [350/565] 61% | Training loss: 0.6888514145783016
Epoch: 30 | Iteration number: [360/565] 63% | Training loss: 0.688800340394179
Epoch: 30 | Iteration number: [370/565] 65% | Training loss: 0.6887570445602005
Epoch: 30 | Iteration number: [380/565] 67% | Training loss: 0.6887066475654903
Epoch: 30 | Iteration number: [390/565] 69% | Training loss: 0.6886620342731475
Epoch: 30 | Iteration number: [400/565] 70% | Training loss: 0.6886144202947616
Epoch: 30 | Iteration number: [410/565] 72% | Training loss: 0.6885767451146754
Epoch: 30 | Iteration number: [420/565] 74% | Training loss: 0.6885371443771181
Epoch: 30 | Iteration number: [430/565] 76% | Training loss: 0.6884948812251868
Epoch: 30 | Iteration number: [440/565] 77% | Training loss: 0.6884512700817802
Epoch: 30 | Iteration number: [450/565] 79% | Training loss: 0.6884052312374115
Epoch: 30 | Iteration number: [460/565] 81% | Training loss: 0.6883822687294172
Epoch: 30 | Iteration number: [470/565] 83% | Training loss: 0.6883531263534058
Epoch: 30 | Iteration number: [480/565] 84% | Training loss: 0.6883105772236983
Epoch: 30 | Iteration number: [490/565] 86% | Training loss: 0.6882867376415097
Epoch: 30 | Iteration number: [500/565] 88% | Training loss: 0.6882610535621643
Epoch: 30 | Iteration number: [510/565] 90% | Training loss: 0.6882330555541842
Epoch: 30 | Iteration number: [520/565] 92% | Training loss: 0.6882117099486864
Epoch: 30 | Iteration number: [530/565] 93% | Training loss: 0.6881800851731931
Epoch: 30 | Iteration number: [540/565] 95% | Training loss: 0.6881517542733087
Epoch: 30 | Iteration number: [550/565] 97% | Training loss: 0.6881282758712769
Epoch: 30 | Iteration number: [560/565] 99% | Training loss: 0.6881026614989553

 End of epoch: 30 | Train Loss: 0.6868805933842617 | Training Time: 90 

 End of epoch: 30 | Eval Loss: 0.6899200763021197 | Evaluating Time: 5 
Epoch: 31 | Iteration number: [10/565] 1% | Training loss: 0.7556564033031463
Epoch: 31 | Iteration number: [20/565] 3% | Training loss: 0.7213463366031647
Epoch: 31 | Iteration number: [30/565] 5% | Training loss: 0.7099822064240774
Epoch: 31 | Iteration number: [40/565] 7% | Training loss: 0.7041912913322449
Epoch: 31 | Iteration number: [50/565] 8% | Training loss: 0.7007224774360656
Epoch: 31 | Iteration number: [60/565] 10% | Training loss: 0.6985002766052882
Epoch: 31 | Iteration number: [70/565] 12% | Training loss: 0.6967430199895587
Epoch: 31 | Iteration number: [80/565] 14% | Training loss: 0.6954813823103905
Epoch: 31 | Iteration number: [90/565] 15% | Training loss: 0.6945292956299252
Epoch: 31 | Iteration number: [100/565] 17% | Training loss: 0.6937618529796601
Epoch: 31 | Iteration number: [110/565] 19% | Training loss: 0.6931354647332971
Epoch: 31 | Iteration number: [120/565] 21% | Training loss: 0.6926234051585197
Epoch: 31 | Iteration number: [130/565] 23% | Training loss: 0.6921876632250272
Epoch: 31 | Iteration number: [140/565] 24% | Training loss: 0.69177579837186
Epoch: 31 | Iteration number: [150/565] 26% | Training loss: 0.6914244747161865
Epoch: 31 | Iteration number: [160/565] 28% | Training loss: 0.6911437556147575
Epoch: 31 | Iteration number: [170/565] 30% | Training loss: 0.6908794010386747
Epoch: 31 | Iteration number: [180/565] 31% | Training loss: 0.6906709250476625
Epoch: 31 | Iteration number: [190/565] 33% | Training loss: 0.690466078331596
Epoch: 31 | Iteration number: [200/565] 35% | Training loss: 0.6902974408864975
Epoch: 31 | Iteration number: [210/565] 37% | Training loss: 0.6901253649166652
Epoch: 31 | Iteration number: [220/565] 38% | Training loss: 0.6899729647419669
Epoch: 31 | Iteration number: [230/565] 40% | Training loss: 0.6898385441821554
Epoch: 31 | Iteration number: [240/565] 42% | Training loss: 0.6897196792066097
Epoch: 31 | Iteration number: [250/565] 44% | Training loss: 0.6896053235530853
Epoch: 31 | Iteration number: [260/565] 46% | Training loss: 0.6894929704757837
Epoch: 31 | Iteration number: [270/565] 47% | Training loss: 0.689386863620193
Epoch: 31 | Iteration number: [280/565] 49% | Training loss: 0.6892985573836735
Epoch: 31 | Iteration number: [290/565] 51% | Training loss: 0.6892290777173535
Epoch: 31 | Iteration number: [300/565] 53% | Training loss: 0.6891453025738398
Epoch: 31 | Iteration number: [310/565] 54% | Training loss: 0.6890669651569858
Epoch: 31 | Iteration number: [320/565] 56% | Training loss: 0.6889986917376518
Epoch: 31 | Iteration number: [330/565] 58% | Training loss: 0.688931075370673
Epoch: 31 | Iteration number: [340/565] 60% | Training loss: 0.6888554672984516
Epoch: 31 | Iteration number: [350/565] 61% | Training loss: 0.6888112618241992
Epoch: 31 | Iteration number: [360/565] 63% | Training loss: 0.6887572207384639
Epoch: 31 | Iteration number: [370/565] 65% | Training loss: 0.6887126265345394
Epoch: 31 | Iteration number: [380/565] 67% | Training loss: 0.6886548846960068
Epoch: 31 | Iteration number: [390/565] 69% | Training loss: 0.6886190894322518
Epoch: 31 | Iteration number: [400/565] 70% | Training loss: 0.688571996986866
Epoch: 31 | Iteration number: [410/565] 72% | Training loss: 0.6885376989841461
Epoch: 31 | Iteration number: [420/565] 74% | Training loss: 0.6884964984087717
Epoch: 31 | Iteration number: [430/565] 76% | Training loss: 0.6884534704130749
Epoch: 31 | Iteration number: [440/565] 77% | Training loss: 0.6884205250577493
Epoch: 31 | Iteration number: [450/565] 79% | Training loss: 0.688382847044203
Epoch: 31 | Iteration number: [460/565] 81% | Training loss: 0.6883552424285723
Epoch: 31 | Iteration number: [470/565] 83% | Training loss: 0.688318530422576
Epoch: 31 | Iteration number: [480/565] 84% | Training loss: 0.6882881966729959
Epoch: 31 | Iteration number: [490/565] 86% | Training loss: 0.6882659324577877
Epoch: 31 | Iteration number: [500/565] 88% | Training loss: 0.6882321580648422
Epoch: 31 | Iteration number: [510/565] 90% | Training loss: 0.688208114750245
Epoch: 31 | Iteration number: [520/565] 92% | Training loss: 0.6881825155936755
Epoch: 31 | Iteration number: [530/565] 93% | Training loss: 0.6881604438682772
Epoch: 31 | Iteration number: [540/565] 95% | Training loss: 0.6881347516068705
Epoch: 31 | Iteration number: [550/565] 97% | Training loss: 0.6881161694093184
Epoch: 31 | Iteration number: [560/565] 99% | Training loss: 0.6880947606904166

 End of epoch: 31 | Train Loss: 0.6868713507610085 | Training Time: 91 

 End of epoch: 31 | Eval Loss: 0.689405586038317 | Evaluating Time: 5 
Epoch: 32 | Iteration number: [10/565] 1% | Training loss: 0.7558799922466278
Epoch: 32 | Iteration number: [20/565] 3% | Training loss: 0.7212696522474289
Epoch: 32 | Iteration number: [30/565] 5% | Training loss: 0.7099769751230876
Epoch: 32 | Iteration number: [40/565] 7% | Training loss: 0.7041474372148514
Epoch: 32 | Iteration number: [50/565] 8% | Training loss: 0.7007220947742462
Epoch: 32 | Iteration number: [60/565] 10% | Training loss: 0.6984144707520803
Epoch: 32 | Iteration number: [70/565] 12% | Training loss: 0.6968035084860665
Epoch: 32 | Iteration number: [80/565] 14% | Training loss: 0.6955645367503166
Epoch: 32 | Iteration number: [90/565] 15% | Training loss: 0.6945836398336622
Epoch: 32 | Iteration number: [100/565] 17% | Training loss: 0.6938481324911118
Epoch: 32 | Iteration number: [110/565] 19% | Training loss: 0.6932124782692303
Epoch: 32 | Iteration number: [120/565] 21% | Training loss: 0.6926911359031995
Epoch: 32 | Iteration number: [130/565] 23% | Training loss: 0.6922611149457785
Epoch: 32 | Iteration number: [140/565] 24% | Training loss: 0.6918430145297731
Epoch: 32 | Iteration number: [150/565] 26% | Training loss: 0.6915188185373942
Epoch: 32 | Iteration number: [160/565] 28% | Training loss: 0.6912106763571501
Epoch: 32 | Iteration number: [170/565] 30% | Training loss: 0.690934696968864
Epoch: 32 | Iteration number: [180/565] 31% | Training loss: 0.6906862792041567
Epoch: 32 | Iteration number: [190/565] 33% | Training loss: 0.6905113803712946
Epoch: 32 | Iteration number: [200/565] 35% | Training loss: 0.6903442671895027
Epoch: 32 | Iteration number: [210/565] 37% | Training loss: 0.6901941952251253
Epoch: 32 | Iteration number: [220/565] 38% | Training loss: 0.6900509059429168
Epoch: 32 | Iteration number: [230/565] 40% | Training loss: 0.6898985033449919
Epoch: 32 | Iteration number: [240/565] 42% | Training loss: 0.6897679040829341
Epoch: 32 | Iteration number: [250/565] 44% | Training loss: 0.6896342566013336
Epoch: 32 | Iteration number: [260/565] 46% | Training loss: 0.6895244133013946
Epoch: 32 | Iteration number: [270/565] 47% | Training loss: 0.6894391048837591
Epoch: 32 | Iteration number: [280/565] 49% | Training loss: 0.6893513230340821
Epoch: 32 | Iteration number: [290/565] 51% | Training loss: 0.6892605504085277
Epoch: 32 | Iteration number: [300/565] 53% | Training loss: 0.6891970366239548
Epoch: 32 | Iteration number: [310/565] 54% | Training loss: 0.6891265942204383
Epoch: 32 | Iteration number: [320/565] 56% | Training loss: 0.6890558931976557
Epoch: 32 | Iteration number: [330/565] 58% | Training loss: 0.6890009504376036
Epoch: 32 | Iteration number: [340/565] 60% | Training loss: 0.688943947764004
Epoch: 32 | Iteration number: [350/565] 61% | Training loss: 0.6888858151435852
Epoch: 32 | Iteration number: [360/565] 63% | Training loss: 0.6888452660706308
Epoch: 32 | Iteration number: [370/565] 65% | Training loss: 0.688785067925582
Epoch: 32 | Iteration number: [380/565] 67% | Training loss: 0.6887427722152911
Epoch: 32 | Iteration number: [390/565] 69% | Training loss: 0.6886857812221233
Epoch: 32 | Iteration number: [400/565] 70% | Training loss: 0.688631540685892
Epoch: 32 | Iteration number: [410/565] 72% | Training loss: 0.6885787412887666
Epoch: 32 | Iteration number: [420/565] 74% | Training loss: 0.688545457805906
Epoch: 32 | Iteration number: [430/565] 76% | Training loss: 0.6885099409624588
Epoch: 32 | Iteration number: [440/565] 77% | Training loss: 0.6884748588908802
Epoch: 32 | Iteration number: [450/565] 79% | Training loss: 0.6884348539511362
Epoch: 32 | Iteration number: [460/565] 81% | Training loss: 0.6884067154448965
Epoch: 32 | Iteration number: [470/565] 83% | Training loss: 0.688377962721155
Epoch: 32 | Iteration number: [480/565] 84% | Training loss: 0.6883381906896829
Epoch: 32 | Iteration number: [490/565] 86% | Training loss: 0.6883042994810611
Epoch: 32 | Iteration number: [500/565] 88% | Training loss: 0.6882703025341034
Epoch: 32 | Iteration number: [510/565] 90% | Training loss: 0.6882425869212431
Epoch: 32 | Iteration number: [520/565] 92% | Training loss: 0.6882079346821859
Epoch: 32 | Iteration number: [530/565] 93% | Training loss: 0.6881816826901346
Epoch: 32 | Iteration number: [540/565] 95% | Training loss: 0.6881550005188695
Epoch: 32 | Iteration number: [550/565] 97% | Training loss: 0.6881331609595905
Epoch: 32 | Iteration number: [560/565] 99% | Training loss: 0.6881085175488676

 End of epoch: 32 | Train Loss: 0.6868813734138961 | Training Time: 90 

 End of epoch: 32 | Eval Loss: 0.6897610340799604 | Evaluating Time: 5 
Epoch: 33 | Iteration number: [10/565] 1% | Training loss: 0.7554225325584412
Epoch: 33 | Iteration number: [20/565] 3% | Training loss: 0.721035224199295
Epoch: 33 | Iteration number: [30/565] 5% | Training loss: 0.7095832486947378
Epoch: 33 | Iteration number: [40/565] 7% | Training loss: 0.7038899600505829
Epoch: 33 | Iteration number: [50/565] 8% | Training loss: 0.700434514284134
Epoch: 33 | Iteration number: [60/565] 10% | Training loss: 0.698214007417361
Epoch: 33 | Iteration number: [70/565] 12% | Training loss: 0.6966110272066933
Epoch: 33 | Iteration number: [80/565] 14% | Training loss: 0.6953889206051826
Epoch: 33 | Iteration number: [90/565] 15% | Training loss: 0.694446074962616
Epoch: 33 | Iteration number: [100/565] 17% | Training loss: 0.6937257069349289
Epoch: 33 | Iteration number: [110/565] 19% | Training loss: 0.6931419735605067
Epoch: 33 | Iteration number: [120/565] 21% | Training loss: 0.6925709759195645
Epoch: 33 | Iteration number: [130/565] 23% | Training loss: 0.6921374128415034
Epoch: 33 | Iteration number: [140/565] 24% | Training loss: 0.6917689327682768
Epoch: 33 | Iteration number: [150/565] 26% | Training loss: 0.6914671266078949
Epoch: 33 | Iteration number: [160/565] 28% | Training loss: 0.6911718040704727
Epoch: 33 | Iteration number: [170/565] 30% | Training loss: 0.6909050398013171
Epoch: 33 | Iteration number: [180/565] 31% | Training loss: 0.6906766295433044
Epoch: 33 | Iteration number: [190/565] 33% | Training loss: 0.6904795646667481
Epoch: 33 | Iteration number: [200/565] 35% | Training loss: 0.6903163340687751
Epoch: 33 | Iteration number: [210/565] 37% | Training loss: 0.6901468708401635
Epoch: 33 | Iteration number: [220/565] 38% | Training loss: 0.6900111916390332
Epoch: 33 | Iteration number: [230/565] 40% | Training loss: 0.6898788159308227
Epoch: 33 | Iteration number: [240/565] 42% | Training loss: 0.6897383677462737
Epoch: 33 | Iteration number: [250/565] 44% | Training loss: 0.6896042370796204
Epoch: 33 | Iteration number: [260/565] 46% | Training loss: 0.6895142598794057
Epoch: 33 | Iteration number: [270/565] 47% | Training loss: 0.6894217453621052
Epoch: 33 | Iteration number: [280/565] 49% | Training loss: 0.6893386291606086
Epoch: 33 | Iteration number: [290/565] 51% | Training loss: 0.6892625773775166
Epoch: 33 | Iteration number: [300/565] 53% | Training loss: 0.6891821891069412
Epoch: 33 | Iteration number: [310/565] 54% | Training loss: 0.6891074601681002
Epoch: 33 | Iteration number: [320/565] 56% | Training loss: 0.6890428241342306
Epoch: 33 | Iteration number: [330/565] 58% | Training loss: 0.6889772102688299
Epoch: 33 | Iteration number: [340/565] 60% | Training loss: 0.6889168530702591
Epoch: 33 | Iteration number: [350/565] 61% | Training loss: 0.6888684269360134
Epoch: 33 | Iteration number: [360/565] 63% | Training loss: 0.6888090310825242
Epoch: 33 | Iteration number: [370/565] 65% | Training loss: 0.6887571135082761
Epoch: 33 | Iteration number: [380/565] 67% | Training loss: 0.6887131113755075
Epoch: 33 | Iteration number: [390/565] 69% | Training loss: 0.6886586334460821
Epoch: 33 | Iteration number: [400/565] 70% | Training loss: 0.6886206336319447
Epoch: 33 | Iteration number: [410/565] 72% | Training loss: 0.6885701573476559
Epoch: 33 | Iteration number: [420/565] 74% | Training loss: 0.6885321394318626
Epoch: 33 | Iteration number: [430/565] 76% | Training loss: 0.6884928255580193
Epoch: 33 | Iteration number: [440/565] 77% | Training loss: 0.6884513594887474
Epoch: 33 | Iteration number: [450/565] 79% | Training loss: 0.688418614466985
Epoch: 33 | Iteration number: [460/565] 81% | Training loss: 0.6883858281633128
Epoch: 33 | Iteration number: [470/565] 83% | Training loss: 0.6883522363419229
Epoch: 33 | Iteration number: [480/565] 84% | Training loss: 0.6883173788587252
Epoch: 33 | Iteration number: [490/565] 86% | Training loss: 0.6882882710622281
Epoch: 33 | Iteration number: [500/565] 88% | Training loss: 0.6882578576803208
Epoch: 33 | Iteration number: [510/565] 90% | Training loss: 0.6882364135162503
Epoch: 33 | Iteration number: [520/565] 92% | Training loss: 0.6882165661224953
Epoch: 33 | Iteration number: [530/565] 93% | Training loss: 0.6881965571979307
Epoch: 33 | Iteration number: [540/565] 95% | Training loss: 0.6881602732119737
Epoch: 33 | Iteration number: [550/565] 97% | Training loss: 0.6881333630735224
Epoch: 33 | Iteration number: [560/565] 99% | Training loss: 0.688106052258185

 End of epoch: 33 | Train Loss: 0.6868822726528202 | Training Time: 90 

 End of epoch: 33 | Eval Loss: 0.6898235763822284 | Evaluating Time: 5 
Epoch: 34 | Iteration number: [10/565] 1% | Training loss: 0.7555668473243713
Epoch: 34 | Iteration number: [20/565] 3% | Training loss: 0.7208694368600845
Epoch: 34 | Iteration number: [30/565] 5% | Training loss: 0.709553700685501
Epoch: 34 | Iteration number: [40/565] 7% | Training loss: 0.7039300724864006
Epoch: 34 | Iteration number: [50/565] 8% | Training loss: 0.7005449938774109
Epoch: 34 | Iteration number: [60/565] 10% | Training loss: 0.6982596019903818
Epoch: 34 | Iteration number: [70/565] 12% | Training loss: 0.6965940041201455
Epoch: 34 | Iteration number: [80/565] 14% | Training loss: 0.6953701458871364
Epoch: 34 | Iteration number: [90/565] 15% | Training loss: 0.6944414615631104
Epoch: 34 | Iteration number: [100/565] 17% | Training loss: 0.6937109327316284
Epoch: 34 | Iteration number: [110/565] 19% | Training loss: 0.6930578621951017
Epoch: 34 | Iteration number: [120/565] 21% | Training loss: 0.6925292780001958
Epoch: 34 | Iteration number: [130/565] 23% | Training loss: 0.692100335084475
Epoch: 34 | Iteration number: [140/565] 24% | Training loss: 0.6916852870157787
Epoch: 34 | Iteration number: [150/565] 26% | Training loss: 0.6913806247711182
Epoch: 34 | Iteration number: [160/565] 28% | Training loss: 0.6911150798201561
Epoch: 34 | Iteration number: [170/565] 30% | Training loss: 0.6908552842981676
Epoch: 34 | Iteration number: [180/565] 31% | Training loss: 0.6906180418199963
Epoch: 34 | Iteration number: [190/565] 33% | Training loss: 0.6904177499444861
Epoch: 34 | Iteration number: [200/565] 35% | Training loss: 0.6902356725931168
Epoch: 34 | Iteration number: [210/565] 37% | Training loss: 0.6900718013445536
Epoch: 34 | Iteration number: [220/565] 38% | Training loss: 0.6899162758480418
Epoch: 34 | Iteration number: [230/565] 40% | Training loss: 0.6897811690102453
Epoch: 34 | Iteration number: [240/565] 42% | Training loss: 0.6896698425213496
Epoch: 34 | Iteration number: [250/565] 44% | Training loss: 0.6895703291893005
Epoch: 34 | Iteration number: [260/565] 46% | Training loss: 0.6895017435917488
Epoch: 34 | Iteration number: [270/565] 47% | Training loss: 0.6894056887538345
Epoch: 34 | Iteration number: [280/565] 49% | Training loss: 0.6893041238188744
Epoch: 34 | Iteration number: [290/565] 51% | Training loss: 0.6892228062810569
Epoch: 34 | Iteration number: [300/565] 53% | Training loss: 0.6891390695174535
Epoch: 34 | Iteration number: [310/565] 54% | Training loss: 0.6890601123532941
Epoch: 34 | Iteration number: [320/565] 56% | Training loss: 0.6890058059245348
Epoch: 34 | Iteration number: [330/565] 58% | Training loss: 0.6889471781976295
Epoch: 34 | Iteration number: [340/565] 60% | Training loss: 0.6888790889697917
Epoch: 34 | Iteration number: [350/565] 61% | Training loss: 0.6888297986984253
Epoch: 34 | Iteration number: [360/565] 63% | Training loss: 0.6887657129102283
Epoch: 34 | Iteration number: [370/565] 65% | Training loss: 0.6887219672267502
Epoch: 34 | Iteration number: [380/565] 67% | Training loss: 0.6886810196073432
Epoch: 34 | Iteration number: [390/565] 69% | Training loss: 0.688644899160434
Epoch: 34 | Iteration number: [400/565] 70% | Training loss: 0.6885959459841251
Epoch: 34 | Iteration number: [410/565] 72% | Training loss: 0.6885582167927812
Epoch: 34 | Iteration number: [420/565] 74% | Training loss: 0.6885236880608967
Epoch: 34 | Iteration number: [430/565] 76% | Training loss: 0.6884885076866594
Epoch: 34 | Iteration number: [440/565] 77% | Training loss: 0.6884497459639203
Epoch: 34 | Iteration number: [450/565] 79% | Training loss: 0.6884127391709222
Epoch: 34 | Iteration number: [460/565] 81% | Training loss: 0.6883910600257956
Epoch: 34 | Iteration number: [470/565] 83% | Training loss: 0.6883564516584924
Epoch: 34 | Iteration number: [480/565] 84% | Training loss: 0.6883262868970632
Epoch: 34 | Iteration number: [490/565] 86% | Training loss: 0.688293324562968
Epoch: 34 | Iteration number: [500/565] 88% | Training loss: 0.6882738435268402
Epoch: 34 | Iteration number: [510/565] 90% | Training loss: 0.6882453217225917
Epoch: 34 | Iteration number: [520/565] 92% | Training loss: 0.6882155319819083
Epoch: 34 | Iteration number: [530/565] 93% | Training loss: 0.6881906903014993
Epoch: 34 | Iteration number: [540/565] 95% | Training loss: 0.688161567957313
Epoch: 34 | Iteration number: [550/565] 97% | Training loss: 0.6881361704522914
Epoch: 34 | Iteration number: [560/565] 99% | Training loss: 0.6881132849625179

 End of epoch: 34 | Train Loss: 0.6868875861167908 | Training Time: 93 

 End of epoch: 34 | Eval Loss: 0.6895164932523455 | Evaluating Time: 6 
Epoch: 35 | Iteration number: [10/565] 1% | Training loss: 0.7556275188922882
Epoch: 35 | Iteration number: [20/565] 3% | Training loss: 0.7213575214147567
Epoch: 35 | Iteration number: [30/565] 5% | Training loss: 0.7096766650676727
Epoch: 35 | Iteration number: [40/565] 7% | Training loss: 0.7040204510092736
Epoch: 35 | Iteration number: [50/565] 8% | Training loss: 0.7007069396972656
Epoch: 35 | Iteration number: [60/565] 10% | Training loss: 0.698282653093338
Epoch: 35 | Iteration number: [70/565] 12% | Training loss: 0.6966719423021589
Epoch: 35 | Iteration number: [80/565] 14% | Training loss: 0.6954610839486122
Epoch: 35 | Iteration number: [90/565] 15% | Training loss: 0.694540305270089
Epoch: 35 | Iteration number: [100/565] 17% | Training loss: 0.6937905490398407
Epoch: 35 | Iteration number: [110/565] 19% | Training loss: 0.6931605366143313
Epoch: 35 | Iteration number: [120/565] 21% | Training loss: 0.6926482165853183
Epoch: 35 | Iteration number: [130/565] 23% | Training loss: 0.6922389768637144
Epoch: 35 | Iteration number: [140/565] 24% | Training loss: 0.6918491921254567
Epoch: 35 | Iteration number: [150/565] 26% | Training loss: 0.6915365691979726
Epoch: 35 | Iteration number: [160/565] 28% | Training loss: 0.6912714123725892
Epoch: 35 | Iteration number: [170/565] 30% | Training loss: 0.6909940635456758
Epoch: 35 | Iteration number: [180/565] 31% | Training loss: 0.6907546401023865
Epoch: 35 | Iteration number: [190/565] 33% | Training loss: 0.6905305589500227
Epoch: 35 | Iteration number: [200/565] 35% | Training loss: 0.690363812148571
Epoch: 35 | Iteration number: [210/565] 37% | Training loss: 0.6902038611116863
Epoch: 35 | Iteration number: [220/565] 38% | Training loss: 0.6900366216897964
Epoch: 35 | Iteration number: [230/565] 40% | Training loss: 0.6898972560530123
Epoch: 35 | Iteration number: [240/565] 42% | Training loss: 0.6897738645474116
Epoch: 35 | Iteration number: [250/565] 44% | Training loss: 0.6896303796768188
Epoch: 35 | Iteration number: [260/565] 46% | Training loss: 0.6895255483113802
Epoch: 35 | Iteration number: [270/565] 47% | Training loss: 0.6894336859385173
Epoch: 35 | Iteration number: [280/565] 49% | Training loss: 0.6893470153212548
Epoch: 35 | Iteration number: [290/565] 51% | Training loss: 0.6892544808058904
Epoch: 35 | Iteration number: [300/565] 53% | Training loss: 0.6891650074720382
Epoch: 35 | Iteration number: [310/565] 54% | Training loss: 0.689099479875257
Epoch: 35 | Iteration number: [320/565] 56% | Training loss: 0.6890257351100445
Epoch: 35 | Iteration number: [330/565] 58% | Training loss: 0.6889504727089044
Epoch: 35 | Iteration number: [340/565] 60% | Training loss: 0.6888769116471796
Epoch: 35 | Iteration number: [350/565] 61% | Training loss: 0.6888155262810843
Epoch: 35 | Iteration number: [360/565] 63% | Training loss: 0.6887530422872967
Epoch: 35 | Iteration number: [370/565] 65% | Training loss: 0.6887120214668481
Epoch: 35 | Iteration number: [380/565] 67% | Training loss: 0.6886699499268281
Epoch: 35 | Iteration number: [390/565] 69% | Training loss: 0.6886294415363898
Epoch: 35 | Iteration number: [400/565] 70% | Training loss: 0.6885862328112126
Epoch: 35 | Iteration number: [410/565] 72% | Training loss: 0.688543714691953
Epoch: 35 | Iteration number: [420/565] 74% | Training loss: 0.6885052224000295
Epoch: 35 | Iteration number: [430/565] 76% | Training loss: 0.6884556153485941
Epoch: 35 | Iteration number: [440/565] 77% | Training loss: 0.6884275486523455
Epoch: 35 | Iteration number: [450/565] 79% | Training loss: 0.6883968088361953
Epoch: 35 | Iteration number: [460/565] 81% | Training loss: 0.6883643130893292
Epoch: 35 | Iteration number: [470/565] 83% | Training loss: 0.6883309496209976
Epoch: 35 | Iteration number: [480/565] 84% | Training loss: 0.6883051266272863
Epoch: 35 | Iteration number: [490/565] 86% | Training loss: 0.6882727860187997
Epoch: 35 | Iteration number: [500/565] 88% | Training loss: 0.6882427666187286
Epoch: 35 | Iteration number: [510/565] 90% | Training loss: 0.688216589829501
Epoch: 35 | Iteration number: [520/565] 92% | Training loss: 0.6881976591852995
Epoch: 35 | Iteration number: [530/565] 93% | Training loss: 0.6881650580550139
Epoch: 35 | Iteration number: [540/565] 95% | Training loss: 0.688141683516679
Epoch: 35 | Iteration number: [550/565] 97% | Training loss: 0.6881166859106584
Epoch: 35 | Iteration number: [560/565] 99% | Training loss: 0.6880863504750389

 End of epoch: 35 | Train Loss: 0.6868604135724296 | Training Time: 90 

 End of epoch: 35 | Eval Loss: 0.6901629992893764 | Evaluating Time: 5 
Epoch: 36 | Iteration number: [10/565] 1% | Training loss: 0.7556197106838226
Epoch: 36 | Iteration number: [20/565] 3% | Training loss: 0.7214885145425797
Epoch: 36 | Iteration number: [30/565] 5% | Training loss: 0.7098821083704631
Epoch: 36 | Iteration number: [40/565] 7% | Training loss: 0.7041615024209023
Epoch: 36 | Iteration number: [50/565] 8% | Training loss: 0.7006992423534393
Epoch: 36 | Iteration number: [60/565] 10% | Training loss: 0.6984096974134445
Epoch: 36 | Iteration number: [70/565] 12% | Training loss: 0.6967824297291892
Epoch: 36 | Iteration number: [80/565] 14% | Training loss: 0.6955345563590527
Epoch: 36 | Iteration number: [90/565] 15% | Training loss: 0.6945227139525944
Epoch: 36 | Iteration number: [100/565] 17% | Training loss: 0.6937762278318406
Epoch: 36 | Iteration number: [110/565] 19% | Training loss: 0.6931211390278557
Epoch: 36 | Iteration number: [120/565] 21% | Training loss: 0.6925754323601723
Epoch: 36 | Iteration number: [130/565] 23% | Training loss: 0.6921122399660257
Epoch: 36 | Iteration number: [140/565] 24% | Training loss: 0.691741310272898
Epoch: 36 | Iteration number: [150/565] 26% | Training loss: 0.6914058156808217
Epoch: 36 | Iteration number: [160/565] 28% | Training loss: 0.6911187965422869
Epoch: 36 | Iteration number: [170/565] 30% | Training loss: 0.6908631766543669
Epoch: 36 | Iteration number: [180/565] 31% | Training loss: 0.6906264579958385
Epoch: 36 | Iteration number: [190/565] 33% | Training loss: 0.6904540573295794
Epoch: 36 | Iteration number: [200/565] 35% | Training loss: 0.6902706933021545
Epoch: 36 | Iteration number: [210/565] 37% | Training loss: 0.6900992861815861
Epoch: 36 | Iteration number: [220/565] 38% | Training loss: 0.6899604865095832
Epoch: 36 | Iteration number: [230/565] 40% | Training loss: 0.6898299730342368
Epoch: 36 | Iteration number: [240/565] 42% | Training loss: 0.6897236198186875
Epoch: 36 | Iteration number: [250/565] 44% | Training loss: 0.6896100747585296
Epoch: 36 | Iteration number: [260/565] 46% | Training loss: 0.6894894923155125
Epoch: 36 | Iteration number: [270/565] 47% | Training loss: 0.6893818855285645
Epoch: 36 | Iteration number: [280/565] 49% | Training loss: 0.6892739070313317
Epoch: 36 | Iteration number: [290/565] 51% | Training loss: 0.6891859617726556
Epoch: 36 | Iteration number: [300/565] 53% | Training loss: 0.6891122295459111
Epoch: 36 | Iteration number: [310/565] 54% | Training loss: 0.6890387006344334
Epoch: 36 | Iteration number: [320/565] 56% | Training loss: 0.6889553157612681
Epoch: 36 | Iteration number: [330/565] 58% | Training loss: 0.6889017014792471
Epoch: 36 | Iteration number: [340/565] 60% | Training loss: 0.6888420131276636
Epoch: 36 | Iteration number: [350/565] 61% | Training loss: 0.6887851098605565
Epoch: 36 | Iteration number: [360/565] 63% | Training loss: 0.6887238792247242
Epoch: 36 | Iteration number: [370/565] 65% | Training loss: 0.6886792559881468
Epoch: 36 | Iteration number: [380/565] 67% | Training loss: 0.6886330416328028
Epoch: 36 | Iteration number: [390/565] 69% | Training loss: 0.688587169158153
Epoch: 36 | Iteration number: [400/565] 70% | Training loss: 0.688548880815506
Epoch: 36 | Iteration number: [410/565] 72% | Training loss: 0.6885126660509807
Epoch: 36 | Iteration number: [420/565] 74% | Training loss: 0.6884527778341657
Epoch: 36 | Iteration number: [430/565] 76% | Training loss: 0.6884172129076581
Epoch: 36 | Iteration number: [440/565] 77% | Training loss: 0.6883841492912987
Epoch: 36 | Iteration number: [450/565] 79% | Training loss: 0.6883439766036139
Epoch: 36 | Iteration number: [460/565] 81% | Training loss: 0.6883172100004943
Epoch: 36 | Iteration number: [470/565] 83% | Training loss: 0.6882809207794515
Epoch: 36 | Iteration number: [480/565] 84% | Training loss: 0.6882563502838214
Epoch: 36 | Iteration number: [490/565] 86% | Training loss: 0.6882241621309397
Epoch: 36 | Iteration number: [500/565] 88% | Training loss: 0.6881985473632812
Epoch: 36 | Iteration number: [510/565] 90% | Training loss: 0.6881714728533053
Epoch: 36 | Iteration number: [520/565] 92% | Training loss: 0.6881540212493676
Epoch: 36 | Iteration number: [530/565] 93% | Training loss: 0.6881402868144917
Epoch: 36 | Iteration number: [540/565] 95% | Training loss: 0.6881081849336624
Epoch: 36 | Iteration number: [550/565] 97% | Training loss: 0.6880905539339239
Epoch: 36 | Iteration number: [560/565] 99% | Training loss: 0.6880719074181147

 End of epoch: 36 | Train Loss: 0.6868442411971303 | Training Time: 90 

 End of epoch: 36 | Eval Loss: 0.6894610864775521 | Evaluating Time: 5 
Epoch: 37 | Iteration number: [10/565] 1% | Training loss: 0.755607146024704
Epoch: 37 | Iteration number: [20/565] 3% | Training loss: 0.7212853223085404
Epoch: 37 | Iteration number: [30/565] 5% | Training loss: 0.7097213447093964
Epoch: 37 | Iteration number: [40/565] 7% | Training loss: 0.7039273396134377
Epoch: 37 | Iteration number: [50/565] 8% | Training loss: 0.7005379486083985
Epoch: 37 | Iteration number: [60/565] 10% | Training loss: 0.6982690691947937
Epoch: 37 | Iteration number: [70/565] 12% | Training loss: 0.6966707561697278
Epoch: 37 | Iteration number: [80/565] 14% | Training loss: 0.6954363614320755
Epoch: 37 | Iteration number: [90/565] 15% | Training loss: 0.6944854451550377
Epoch: 37 | Iteration number: [100/565] 17% | Training loss: 0.6937007474899292
Epoch: 37 | Iteration number: [110/565] 19% | Training loss: 0.6930837251923301
Epoch: 37 | Iteration number: [120/565] 21% | Training loss: 0.692588447034359
Epoch: 37 | Iteration number: [130/565] 23% | Training loss: 0.6921624114880195
Epoch: 37 | Iteration number: [140/565] 24% | Training loss: 0.6917807493891035
Epoch: 37 | Iteration number: [150/565] 26% | Training loss: 0.6914612384637197
Epoch: 37 | Iteration number: [160/565] 28% | Training loss: 0.6911613259464502
Epoch: 37 | Iteration number: [170/565] 30% | Training loss: 0.6909274283577415
Epoch: 37 | Iteration number: [180/565] 31% | Training loss: 0.6906973587142097
Epoch: 37 | Iteration number: [190/565] 33% | Training loss: 0.6904879648434489
Epoch: 37 | Iteration number: [200/565] 35% | Training loss: 0.6903161236643791
Epoch: 37 | Iteration number: [210/565] 37% | Training loss: 0.6901230431738354
Epoch: 37 | Iteration number: [220/565] 38% | Training loss: 0.690010696107691
Epoch: 37 | Iteration number: [230/565] 40% | Training loss: 0.6898888901523922
Epoch: 37 | Iteration number: [240/565] 42% | Training loss: 0.6897753042479357
Epoch: 37 | Iteration number: [250/565] 44% | Training loss: 0.6896678531169891
Epoch: 37 | Iteration number: [260/565] 46% | Training loss: 0.6895591479081374
Epoch: 37 | Iteration number: [270/565] 47% | Training loss: 0.6894490292778721
Epoch: 37 | Iteration number: [280/565] 49% | Training loss: 0.689361932022231
Epoch: 37 | Iteration number: [290/565] 51% | Training loss: 0.689274117453345
Epoch: 37 | Iteration number: [300/565] 53% | Training loss: 0.6891903360684712
Epoch: 37 | Iteration number: [310/565] 54% | Training loss: 0.6891200405936088
Epoch: 37 | Iteration number: [320/565] 56% | Training loss: 0.6890451155602932
Epoch: 37 | Iteration number: [330/565] 58% | Training loss: 0.6889835933844248
Epoch: 37 | Iteration number: [340/565] 60% | Training loss: 0.6889139494475196
Epoch: 37 | Iteration number: [350/565] 61% | Training loss: 0.6888554397651128
Epoch: 37 | Iteration number: [360/565] 63% | Training loss: 0.6888014627827539
Epoch: 37 | Iteration number: [370/565] 65% | Training loss: 0.6887454100557275
Epoch: 37 | Iteration number: [380/565] 67% | Training loss: 0.6886926246316809
Epoch: 37 | Iteration number: [390/565] 69% | Training loss: 0.6886436254550249
Epoch: 37 | Iteration number: [400/565] 70% | Training loss: 0.6885988569259643
Epoch: 37 | Iteration number: [410/565] 72% | Training loss: 0.6885603456962399
Epoch: 37 | Iteration number: [420/565] 74% | Training loss: 0.6885184876975559
Epoch: 37 | Iteration number: [430/565] 76% | Training loss: 0.6884729883005453
Epoch: 37 | Iteration number: [440/565] 77% | Training loss: 0.6884354883974249
Epoch: 37 | Iteration number: [450/565] 79% | Training loss: 0.6883942508697509
Epoch: 37 | Iteration number: [460/565] 81% | Training loss: 0.6883615881204606
Epoch: 37 | Iteration number: [470/565] 83% | Training loss: 0.6883266159828673
Epoch: 37 | Iteration number: [480/565] 84% | Training loss: 0.688295788069566
Epoch: 37 | Iteration number: [490/565] 86% | Training loss: 0.6882638843692079
Epoch: 37 | Iteration number: [500/565] 88% | Training loss: 0.6882341738939285
Epoch: 37 | Iteration number: [510/565] 90% | Training loss: 0.6882065947149314
Epoch: 37 | Iteration number: [520/565] 92% | Training loss: 0.6881832754382721
Epoch: 37 | Iteration number: [530/565] 93% | Training loss: 0.6881530247769265
Epoch: 37 | Iteration number: [540/565] 95% | Training loss: 0.6881321863995657
Epoch: 37 | Iteration number: [550/565] 97% | Training loss: 0.6881084304506129
Epoch: 37 | Iteration number: [560/565] 99% | Training loss: 0.6880773304828576

 End of epoch: 37 | Train Loss: 0.6868519969746075 | Training Time: 90 

 End of epoch: 37 | Eval Loss: 0.6900304130145481 | Evaluating Time: 5 
Epoch: 38 | Iteration number: [10/565] 1% | Training loss: 0.7556095659732819
Epoch: 38 | Iteration number: [20/565] 3% | Training loss: 0.7210999161005021
Epoch: 38 | Iteration number: [30/565] 5% | Training loss: 0.709563014904658
Epoch: 38 | Iteration number: [40/565] 7% | Training loss: 0.7039609625935555
Epoch: 38 | Iteration number: [50/565] 8% | Training loss: 0.7005358326435089
Epoch: 38 | Iteration number: [60/565] 10% | Training loss: 0.6982376048962275
Epoch: 38 | Iteration number: [70/565] 12% | Training loss: 0.6966279251234871
Epoch: 38 | Iteration number: [80/565] 14% | Training loss: 0.6954275302588939
Epoch: 38 | Iteration number: [90/565] 15% | Training loss: 0.6944458338949415
Epoch: 38 | Iteration number: [100/565] 17% | Training loss: 0.6937145233154297
Epoch: 38 | Iteration number: [110/565] 19% | Training loss: 0.6930996157906272
Epoch: 38 | Iteration number: [120/565] 21% | Training loss: 0.6925557548801105
Epoch: 38 | Iteration number: [130/565] 23% | Training loss: 0.6920947822240683
Epoch: 38 | Iteration number: [140/565] 24% | Training loss: 0.6917252676827567
Epoch: 38 | Iteration number: [150/565] 26% | Training loss: 0.6914181792736054
Epoch: 38 | Iteration number: [160/565] 28% | Training loss: 0.6911202479153872
Epoch: 38 | Iteration number: [170/565] 30% | Training loss: 0.6908703470931333
Epoch: 38 | Iteration number: [180/565] 31% | Training loss: 0.690652064482371
Epoch: 38 | Iteration number: [190/565] 33% | Training loss: 0.6904443264007568
Epoch: 38 | Iteration number: [200/565] 35% | Training loss: 0.690274116396904
Epoch: 38 | Iteration number: [210/565] 37% | Training loss: 0.6901257060822986
Epoch: 38 | Iteration number: [220/565] 38% | Training loss: 0.6899847919290716
Epoch: 38 | Iteration number: [230/565] 40% | Training loss: 0.6898580058761264
Epoch: 38 | Iteration number: [240/565] 42% | Training loss: 0.6897414537767569
Epoch: 38 | Iteration number: [250/565] 44% | Training loss: 0.6896316900253295
Epoch: 38 | Iteration number: [260/565] 46% | Training loss: 0.6895149992062495
Epoch: 38 | Iteration number: [270/565] 47% | Training loss: 0.6894203799742239
Epoch: 38 | Iteration number: [280/565] 49% | Training loss: 0.6893202417663166
Epoch: 38 | Iteration number: [290/565] 51% | Training loss: 0.6892323179491635
Epoch: 38 | Iteration number: [300/565] 53% | Training loss: 0.6891495154301326
Epoch: 38 | Iteration number: [310/565] 54% | Training loss: 0.6890711061416134
Epoch: 38 | Iteration number: [320/565] 56% | Training loss: 0.689004378579557
Epoch: 38 | Iteration number: [330/565] 58% | Training loss: 0.6889382595365697
Epoch: 38 | Iteration number: [340/565] 60% | Training loss: 0.6888820281800102
Epoch: 38 | Iteration number: [350/565] 61% | Training loss: 0.6888211665834699
Epoch: 38 | Iteration number: [360/565] 63% | Training loss: 0.6887742522690031
Epoch: 38 | Iteration number: [370/565] 65% | Training loss: 0.6887158978629757
Epoch: 38 | Iteration number: [380/565] 67% | Training loss: 0.688669164557206
Epoch: 38 | Iteration number: [390/565] 69% | Training loss: 0.6886132480242313
Epoch: 38 | Iteration number: [400/565] 70% | Training loss: 0.6885682827234268
Epoch: 38 | Iteration number: [410/565] 72% | Training loss: 0.6885211281660126
Epoch: 38 | Iteration number: [420/565] 74% | Training loss: 0.6884776226111821
Epoch: 38 | Iteration number: [430/565] 76% | Training loss: 0.688448451424754
Epoch: 38 | Iteration number: [440/565] 77% | Training loss: 0.6884038883176717
Epoch: 38 | Iteration number: [450/565] 79% | Training loss: 0.6883794562021891
Epoch: 38 | Iteration number: [460/565] 81% | Training loss: 0.6883582522039828
Epoch: 38 | Iteration number: [470/565] 83% | Training loss: 0.6883332398343593
Epoch: 38 | Iteration number: [480/565] 84% | Training loss: 0.688318136955301
Epoch: 38 | Iteration number: [490/565] 86% | Training loss: 0.6882851086100753
Epoch: 38 | Iteration number: [500/565] 88% | Training loss: 0.6882588508129119
Epoch: 38 | Iteration number: [510/565] 90% | Training loss: 0.6882305444455614
Epoch: 38 | Iteration number: [520/565] 92% | Training loss: 0.6882096546200606
Epoch: 38 | Iteration number: [530/565] 93% | Training loss: 0.6881799748483693
Epoch: 38 | Iteration number: [540/565] 95% | Training loss: 0.6881554568255389
Epoch: 38 | Iteration number: [550/565] 97% | Training loss: 0.6881268855658444
Epoch: 38 | Iteration number: [560/565] 99% | Training loss: 0.6880996146372387

 End of epoch: 38 | Train Loss: 0.686874623319744 | Training Time: 90 

 End of epoch: 38 | Eval Loss: 0.6899892858096531 | Evaluating Time: 5 
Epoch: 39 | Iteration number: [10/565] 1% | Training loss: 0.75603746175766
Epoch: 39 | Iteration number: [20/565] 3% | Training loss: 0.7215499013662339
Epoch: 39 | Iteration number: [30/565] 5% | Training loss: 0.7101094047228496
Epoch: 39 | Iteration number: [40/565] 7% | Training loss: 0.7042568430304528
Epoch: 39 | Iteration number: [50/565] 8% | Training loss: 0.7007703471183777
Epoch: 39 | Iteration number: [60/565] 10% | Training loss: 0.6984503159920374
Epoch: 39 | Iteration number: [70/565] 12% | Training loss: 0.6967873769147056
Epoch: 39 | Iteration number: [80/565] 14% | Training loss: 0.6955483019351959
Epoch: 39 | Iteration number: [90/565] 15% | Training loss: 0.6946437332365248
Epoch: 39 | Iteration number: [100/565] 17% | Training loss: 0.6938639533519745
Epoch: 39 | Iteration number: [110/565] 19% | Training loss: 0.6932367254387248
Epoch: 39 | Iteration number: [120/565] 21% | Training loss: 0.6927136947711309
Epoch: 39 | Iteration number: [130/565] 23% | Training loss: 0.6922745081094596
Epoch: 39 | Iteration number: [140/565] 24% | Training loss: 0.6918800737176622
Epoch: 39 | Iteration number: [150/565] 26% | Training loss: 0.6915304966767629
Epoch: 39 | Iteration number: [160/565] 28% | Training loss: 0.6912162888795137
Epoch: 39 | Iteration number: [170/565] 30% | Training loss: 0.690944870780496
Epoch: 39 | Iteration number: [180/565] 31% | Training loss: 0.6907113982571496
Epoch: 39 | Iteration number: [190/565] 33% | Training loss: 0.6904952042981198
Epoch: 39 | Iteration number: [200/565] 35% | Training loss: 0.6903245970606804
Epoch: 39 | Iteration number: [210/565] 37% | Training loss: 0.6901614458788009
Epoch: 39 | Iteration number: [220/565] 38% | Training loss: 0.6900102840228515
Epoch: 39 | Iteration number: [230/565] 40% | Training loss: 0.689876494459484
Epoch: 39 | Iteration number: [240/565] 42% | Training loss: 0.6897611235578854
Epoch: 39 | Iteration number: [250/565] 44% | Training loss: 0.6896431577205658
Epoch: 39 | Iteration number: [260/565] 46% | Training loss: 0.6895333090653786
Epoch: 39 | Iteration number: [270/565] 47% | Training loss: 0.6894381169919614
Epoch: 39 | Iteration number: [280/565] 49% | Training loss: 0.6893531024456024
Epoch: 39 | Iteration number: [290/565] 51% | Training loss: 0.6892592119759526
Epoch: 39 | Iteration number: [300/565] 53% | Training loss: 0.6891822083791097
Epoch: 39 | Iteration number: [310/565] 54% | Training loss: 0.6890973489130697
Epoch: 39 | Iteration number: [320/565] 56% | Training loss: 0.6890417886897922
Epoch: 39 | Iteration number: [330/565] 58% | Training loss: 0.6889750722682837
Epoch: 39 | Iteration number: [340/565] 60% | Training loss: 0.6889145570642808
Epoch: 39 | Iteration number: [350/565] 61% | Training loss: 0.6888521661077227
Epoch: 39 | Iteration number: [360/565] 63% | Training loss: 0.6887846685118145
Epoch: 39 | Iteration number: [370/565] 65% | Training loss: 0.6887422321615992
Epoch: 39 | Iteration number: [380/565] 67% | Training loss: 0.6886943730868791
Epoch: 39 | Iteration number: [390/565] 69% | Training loss: 0.688642493272439
Epoch: 39 | Iteration number: [400/565] 70% | Training loss: 0.6885860607028007
Epoch: 39 | Iteration number: [410/565] 72% | Training loss: 0.6885475261909205
Epoch: 39 | Iteration number: [420/565] 74% | Training loss: 0.6885099138532366
Epoch: 39 | Iteration number: [430/565] 76% | Training loss: 0.6884683665841125
Epoch: 39 | Iteration number: [440/565] 77% | Training loss: 0.6884369002147155
Epoch: 39 | Iteration number: [450/565] 79% | Training loss: 0.6884070066610972
Epoch: 39 | Iteration number: [460/565] 81% | Training loss: 0.6883692077968432
Epoch: 39 | Iteration number: [470/565] 83% | Training loss: 0.6883296479570105
Epoch: 39 | Iteration number: [480/565] 84% | Training loss: 0.6882997451970975
Epoch: 39 | Iteration number: [490/565] 86% | Training loss: 0.6882764354044077
Epoch: 39 | Iteration number: [500/565] 88% | Training loss: 0.6882413163185119
Epoch: 39 | Iteration number: [510/565] 90% | Training loss: 0.6882003518880583
Epoch: 39 | Iteration number: [520/565] 92% | Training loss: 0.6881744592235639
Epoch: 39 | Iteration number: [530/565] 93% | Training loss: 0.6881472827128644
Epoch: 39 | Iteration number: [540/565] 95% | Training loss: 0.6881217507300553
Epoch: 39 | Iteration number: [550/565] 97% | Training loss: 0.6880956336584958
Epoch: 39 | Iteration number: [560/565] 99% | Training loss: 0.6880780277507645

 End of epoch: 39 | Train Loss: 0.6868454543890151 | Training Time: 90 

 End of epoch: 39 | Eval Loss: 0.6901047825813293 | Evaluating Time: 6 
Epoch: 40 | Iteration number: [10/565] 1% | Training loss: 0.7557624518871308
Epoch: 40 | Iteration number: [20/565] 3% | Training loss: 0.721360656619072
Epoch: 40 | Iteration number: [30/565] 5% | Training loss: 0.7098437964916229
Epoch: 40 | Iteration number: [40/565] 7% | Training loss: 0.7040737330913543
Epoch: 40 | Iteration number: [50/565] 8% | Training loss: 0.7006081438064575
Epoch: 40 | Iteration number: [60/565] 10% | Training loss: 0.6983238995075226
Epoch: 40 | Iteration number: [70/565] 12% | Training loss: 0.6966835950102125
Epoch: 40 | Iteration number: [80/565] 14% | Training loss: 0.6955605901777744
Epoch: 40 | Iteration number: [90/565] 15% | Training loss: 0.694522785478168
Epoch: 40 | Iteration number: [100/565] 17% | Training loss: 0.6937557166814804
Epoch: 40 | Iteration number: [110/565] 19% | Training loss: 0.6930978845466267
Epoch: 40 | Iteration number: [120/565] 21% | Training loss: 0.6925698553522428
Epoch: 40 | Iteration number: [130/565] 23% | Training loss: 0.6921286491247324
Epoch: 40 | Iteration number: [140/565] 24% | Training loss: 0.6917278813464302
Epoch: 40 | Iteration number: [150/565] 26% | Training loss: 0.6914103205998738
Epoch: 40 | Iteration number: [160/565] 28% | Training loss: 0.6911063753068447
Epoch: 40 | Iteration number: [170/565] 30% | Training loss: 0.6908298969268799
Epoch: 40 | Iteration number: [180/565] 31% | Training loss: 0.6906213584873412
Epoch: 40 | Iteration number: [190/565] 33% | Training loss: 0.6904381177927318
Epoch: 40 | Iteration number: [200/565] 35% | Training loss: 0.6902552029490471
Epoch: 40 | Iteration number: [210/565] 37% | Training loss: 0.6900830717313857
Epoch: 40 | Iteration number: [220/565] 38% | Training loss: 0.6899604865095832
Epoch: 40 | Iteration number: [230/565] 40% | Training loss: 0.6898477308128191
Epoch: 40 | Iteration number: [240/565] 42% | Training loss: 0.6897253421445687
Epoch: 40 | Iteration number: [250/565] 44% | Training loss: 0.6896194970607757
Epoch: 40 | Iteration number: [260/565] 46% | Training loss: 0.6895082047352424
Epoch: 40 | Iteration number: [270/565] 47% | Training loss: 0.6894134565635964
Epoch: 40 | Iteration number: [280/565] 49% | Training loss: 0.6893158412405422
Epoch: 40 | Iteration number: [290/565] 51% | Training loss: 0.6892220501242012
Epoch: 40 | Iteration number: [300/565] 53% | Training loss: 0.6891315857569377
Epoch: 40 | Iteration number: [310/565] 54% | Training loss: 0.6890599137352359
Epoch: 40 | Iteration number: [320/565] 56% | Training loss: 0.6889839913696051
Epoch: 40 | Iteration number: [330/565] 58% | Training loss: 0.68891479083986
Epoch: 40 | Iteration number: [340/565] 60% | Training loss: 0.6888587388922186
Epoch: 40 | Iteration number: [350/565] 61% | Training loss: 0.6888068911007472
Epoch: 40 | Iteration number: [360/565] 63% | Training loss: 0.6887566975421375
Epoch: 40 | Iteration number: [370/565] 65% | Training loss: 0.6886927934917244
Epoch: 40 | Iteration number: [380/565] 67% | Training loss: 0.6886493093089053
Epoch: 40 | Iteration number: [390/565] 69% | Training loss: 0.6885906636714936
Epoch: 40 | Iteration number: [400/565] 70% | Training loss: 0.6885478518903255
Epoch: 40 | Iteration number: [410/565] 72% | Training loss: 0.6885128640547031
Epoch: 40 | Iteration number: [420/565] 74% | Training loss: 0.6884686289798646
Epoch: 40 | Iteration number: [430/565] 76% | Training loss: 0.6884290955787481
Epoch: 40 | Iteration number: [440/565] 77% | Training loss: 0.6883960837667639
Epoch: 40 | Iteration number: [450/565] 79% | Training loss: 0.6883611098925273
Epoch: 40 | Iteration number: [460/565] 81% | Training loss: 0.6883240225522415
Epoch: 40 | Iteration number: [470/565] 83% | Training loss: 0.6883016976904361
Epoch: 40 | Iteration number: [480/565] 84% | Training loss: 0.6882761865854263
Epoch: 40 | Iteration number: [490/565] 86% | Training loss: 0.6882486014950032
Epoch: 40 | Iteration number: [500/565] 88% | Training loss: 0.6882171362638474
Epoch: 40 | Iteration number: [510/565] 90% | Training loss: 0.6881801122543858
Epoch: 40 | Iteration number: [520/565] 92% | Training loss: 0.688158406317234
Epoch: 40 | Iteration number: [530/565] 93% | Training loss: 0.6881359603045122
Epoch: 40 | Iteration number: [540/565] 95% | Training loss: 0.6881098766017844
Epoch: 40 | Iteration number: [550/565] 97% | Training loss: 0.6880959756807847
Epoch: 40 | Iteration number: [560/565] 99% | Training loss: 0.6880686874900546

 End of epoch: 40 | Train Loss: 0.6868363733840199 | Training Time: 89 

 End of epoch: 40 | Eval Loss: 0.6893080472946167 | Evaluating Time: 6 
Epoch: 41 | Iteration number: [10/565] 1% | Training loss: 0.7553440809249878
Epoch: 41 | Iteration number: [20/565] 3% | Training loss: 0.721240320801735
Epoch: 41 | Iteration number: [30/565] 5% | Training loss: 0.7097726186116536
Epoch: 41 | Iteration number: [40/565] 7% | Training loss: 0.7041178435087204
Epoch: 41 | Iteration number: [50/565] 8% | Training loss: 0.7007514202594757
Epoch: 41 | Iteration number: [60/565] 10% | Training loss: 0.69848126967748
Epoch: 41 | Iteration number: [70/565] 12% | Training loss: 0.6967530974320003
Epoch: 41 | Iteration number: [80/565] 14% | Training loss: 0.695571719110012
Epoch: 41 | Iteration number: [90/565] 15% | Training loss: 0.6946232577164968
Epoch: 41 | Iteration number: [100/565] 17% | Training loss: 0.693841844201088
Epoch: 41 | Iteration number: [110/565] 19% | Training loss: 0.6931934145363894
Epoch: 41 | Iteration number: [120/565] 21% | Training loss: 0.6926697919766108
Epoch: 41 | Iteration number: [130/565] 23% | Training loss: 0.6922379209445073
Epoch: 41 | Iteration number: [140/565] 24% | Training loss: 0.691841276202883
Epoch: 41 | Iteration number: [150/565] 26% | Training loss: 0.6915172096093496
Epoch: 41 | Iteration number: [160/565] 28% | Training loss: 0.6912494763731957
Epoch: 41 | Iteration number: [170/565] 30% | Training loss: 0.6910181101630716
Epoch: 41 | Iteration number: [180/565] 31% | Training loss: 0.6907790217134687
Epoch: 41 | Iteration number: [190/565] 33% | Training loss: 0.6905777554762991
Epoch: 41 | Iteration number: [200/565] 35% | Training loss: 0.6903761804103852
Epoch: 41 | Iteration number: [210/565] 37% | Training loss: 0.6901833732922872
Epoch: 41 | Iteration number: [220/565] 38% | Training loss: 0.6900465556166389
Epoch: 41 | Iteration number: [230/565] 40% | Training loss: 0.6899327560611394
Epoch: 41 | Iteration number: [240/565] 42% | Training loss: 0.689809154222409
Epoch: 41 | Iteration number: [250/565] 44% | Training loss: 0.6897030835151672
Epoch: 41 | Iteration number: [260/565] 46% | Training loss: 0.6895948792879398
Epoch: 41 | Iteration number: [270/565] 47% | Training loss: 0.6894939930350692
Epoch: 41 | Iteration number: [280/565] 49% | Training loss: 0.6893972567149571
Epoch: 41 | Iteration number: [290/565] 51% | Training loss: 0.6893173121172806
Epoch: 41 | Iteration number: [300/565] 53% | Training loss: 0.6892416693766912
Epoch: 41 | Iteration number: [310/565] 54% | Training loss: 0.6891542700029188
Epoch: 41 | Iteration number: [320/565] 56% | Training loss: 0.6890713537111879
Epoch: 41 | Iteration number: [330/565] 58% | Training loss: 0.6890043760790969
Epoch: 41 | Iteration number: [340/565] 60% | Training loss: 0.6889341619084863
Epoch: 41 | Iteration number: [350/565] 61% | Training loss: 0.6888657292297908
Epoch: 41 | Iteration number: [360/565] 63% | Training loss: 0.688805432120959
Epoch: 41 | Iteration number: [370/565] 65% | Training loss: 0.6887572887781505
Epoch: 41 | Iteration number: [380/565] 67% | Training loss: 0.6887134417107231
Epoch: 41 | Iteration number: [390/565] 69% | Training loss: 0.6886609390760079
Epoch: 41 | Iteration number: [400/565] 70% | Training loss: 0.6886263880133628
Epoch: 41 | Iteration number: [410/565] 72% | Training loss: 0.6885774820316128
Epoch: 41 | Iteration number: [420/565] 74% | Training loss: 0.688532174768902
Epoch: 41 | Iteration number: [430/565] 76% | Training loss: 0.6884871900081635
Epoch: 41 | Iteration number: [440/565] 77% | Training loss: 0.6884535487402569
Epoch: 41 | Iteration number: [450/565] 79% | Training loss: 0.6884140316645304
Epoch: 41 | Iteration number: [460/565] 81% | Training loss: 0.6883783015220062
Epoch: 41 | Iteration number: [470/565] 83% | Training loss: 0.6883454127514615
Epoch: 41 | Iteration number: [480/565] 84% | Training loss: 0.688309070840478
Epoch: 41 | Iteration number: [490/565] 86% | Training loss: 0.688277758870806
Epoch: 41 | Iteration number: [500/565] 88% | Training loss: 0.6882420440912247
Epoch: 41 | Iteration number: [510/565] 90% | Training loss: 0.6882127406550389
Epoch: 41 | Iteration number: [520/565] 92% | Training loss: 0.6881832658098295
Epoch: 41 | Iteration number: [530/565] 93% | Training loss: 0.6881614306063022
Epoch: 41 | Iteration number: [540/565] 95% | Training loss: 0.6881415802019614
Epoch: 41 | Iteration number: [550/565] 97% | Training loss: 0.6881142576174303
Epoch: 41 | Iteration number: [560/565] 99% | Training loss: 0.6880896458668369

 End of epoch: 41 | Train Loss: 0.6868618249893188 | Training Time: 88 

 End of epoch: 41 | Eval Loss: 0.6899312904902867 | Evaluating Time: 6 
Epoch: 42 | Iteration number: [10/565] 1% | Training loss: 0.7555454730987549
Epoch: 42 | Iteration number: [20/565] 3% | Training loss: 0.7214843273162842
Epoch: 42 | Iteration number: [30/565] 5% | Training loss: 0.7098940531412761
Epoch: 42 | Iteration number: [40/565] 7% | Training loss: 0.7039929702877998
Epoch: 42 | Iteration number: [50/565] 8% | Training loss: 0.700529146194458
Epoch: 42 | Iteration number: [60/565] 10% | Training loss: 0.6982505758603413
Epoch: 42 | Iteration number: [70/565] 12% | Training loss: 0.6966216589723314
Epoch: 42 | Iteration number: [80/565] 14% | Training loss: 0.6953903034329414
Epoch: 42 | Iteration number: [90/565] 15% | Training loss: 0.6944731619622972
Epoch: 42 | Iteration number: [100/565] 17% | Training loss: 0.6936806780099869
Epoch: 42 | Iteration number: [110/565] 19% | Training loss: 0.6931004085324027
Epoch: 42 | Iteration number: [120/565] 21% | Training loss: 0.6926204452912013
Epoch: 42 | Iteration number: [130/565] 23% | Training loss: 0.6921988918231083
Epoch: 42 | Iteration number: [140/565] 24% | Training loss: 0.6918061890772411
Epoch: 42 | Iteration number: [150/565] 26% | Training loss: 0.6914894541104635
Epoch: 42 | Iteration number: [160/565] 28% | Training loss: 0.6911995284259319
Epoch: 42 | Iteration number: [170/565] 30% | Training loss: 0.6909406363964081
Epoch: 42 | Iteration number: [180/565] 31% | Training loss: 0.6907142453723484
Epoch: 42 | Iteration number: [190/565] 33% | Training loss: 0.6905116018496061
Epoch: 42 | Iteration number: [200/565] 35% | Training loss: 0.6903461587429046
Epoch: 42 | Iteration number: [210/565] 37% | Training loss: 0.6901581602437156
Epoch: 42 | Iteration number: [220/565] 38% | Training loss: 0.6900339771400799
Epoch: 42 | Iteration number: [230/565] 40% | Training loss: 0.6898897051811218
Epoch: 42 | Iteration number: [240/565] 42% | Training loss: 0.6897588888804118
Epoch: 42 | Iteration number: [250/565] 44% | Training loss: 0.6896461758613587
Epoch: 42 | Iteration number: [260/565] 46% | Training loss: 0.689550232887268
Epoch: 42 | Iteration number: [270/565] 47% | Training loss: 0.6894628818388339
Epoch: 42 | Iteration number: [280/565] 49% | Training loss: 0.6893693306616374
Epoch: 42 | Iteration number: [290/565] 51% | Training loss: 0.6892851354746983
Epoch: 42 | Iteration number: [300/565] 53% | Training loss: 0.6891810315847396
Epoch: 42 | Iteration number: [310/565] 54% | Training loss: 0.6890995314044337
Epoch: 42 | Iteration number: [320/565] 56% | Training loss: 0.6890408046543598
Epoch: 42 | Iteration number: [330/565] 58% | Training loss: 0.6889641257849607
Epoch: 42 | Iteration number: [340/565] 60% | Training loss: 0.6888997251496596
Epoch: 42 | Iteration number: [350/565] 61% | Training loss: 0.6888325083255767
Epoch: 42 | Iteration number: [360/565] 63% | Training loss: 0.6887655647264587
Epoch: 42 | Iteration number: [370/565] 65% | Training loss: 0.6887213141531557
Epoch: 42 | Iteration number: [380/565] 67% | Training loss: 0.6886765547488866
Epoch: 42 | Iteration number: [390/565] 69% | Training loss: 0.6886299917331109
Epoch: 42 | Iteration number: [400/565] 70% | Training loss: 0.6885778653621674
Epoch: 42 | Iteration number: [410/565] 72% | Training loss: 0.6885240828118673
Epoch: 42 | Iteration number: [420/565] 74% | Training loss: 0.6884816775719325
Epoch: 42 | Iteration number: [430/565] 76% | Training loss: 0.6884570916031683
Epoch: 42 | Iteration number: [440/565] 77% | Training loss: 0.6884272622791203
Epoch: 42 | Iteration number: [450/565] 79% | Training loss: 0.688387684557173
Epoch: 42 | Iteration number: [460/565] 81% | Training loss: 0.6883579519779786
Epoch: 42 | Iteration number: [470/565] 83% | Training loss: 0.6883200924447243
Epoch: 42 | Iteration number: [480/565] 84% | Training loss: 0.6882848632832368
Epoch: 42 | Iteration number: [490/565] 86% | Training loss: 0.6882515459644551
Epoch: 42 | Iteration number: [500/565] 88% | Training loss: 0.688219030380249
Epoch: 42 | Iteration number: [510/565] 90% | Training loss: 0.6881916109253379
Epoch: 42 | Iteration number: [520/565] 92% | Training loss: 0.6881739563666858
Epoch: 42 | Iteration number: [530/565] 93% | Training loss: 0.6881439631839968
Epoch: 42 | Iteration number: [540/565] 95% | Training loss: 0.6881194310055838
Epoch: 42 | Iteration number: [550/565] 97% | Training loss: 0.6880861481753262
Epoch: 42 | Iteration number: [560/565] 99% | Training loss: 0.6880695374948638

 End of epoch: 42 | Train Loss: 0.6868437331334679 | Training Time: 86 

 End of epoch: 42 | Eval Loss: 0.689843910081046 | Evaluating Time: 6 
Epoch: 43 | Iteration number: [10/565] 1% | Training loss: 0.7552945673465729
Epoch: 43 | Iteration number: [20/565] 3% | Training loss: 0.7209991723299026
Epoch: 43 | Iteration number: [30/565] 5% | Training loss: 0.7096466422080994
Epoch: 43 | Iteration number: [40/565] 7% | Training loss: 0.7039509937167168
Epoch: 43 | Iteration number: [50/565] 8% | Training loss: 0.7004891204833984
Epoch: 43 | Iteration number: [60/565] 10% | Training loss: 0.6982707897822062
Epoch: 43 | Iteration number: [70/565] 12% | Training loss: 0.6966718086174556
Epoch: 43 | Iteration number: [80/565] 14% | Training loss: 0.6954591386020184
Epoch: 43 | Iteration number: [90/565] 15% | Training loss: 0.6944784376356337
Epoch: 43 | Iteration number: [100/565] 17% | Training loss: 0.6937155914306641
Epoch: 43 | Iteration number: [110/565] 19% | Training loss: 0.6931196949698708
Epoch: 43 | Iteration number: [120/565] 21% | Training loss: 0.6925608898202579
Epoch: 43 | Iteration number: [130/565] 23% | Training loss: 0.692125830742029
Epoch: 43 | Iteration number: [140/565] 24% | Training loss: 0.6917655506304332
Epoch: 43 | Iteration number: [150/565] 26% | Training loss: 0.6914078299204508
Epoch: 43 | Iteration number: [160/565] 28% | Training loss: 0.691085684299469
Epoch: 43 | Iteration number: [170/565] 30% | Training loss: 0.6908434117541594
Epoch: 43 | Iteration number: [180/565] 31% | Training loss: 0.6906017538574006
Epoch: 43 | Iteration number: [190/565] 33% | Training loss: 0.6904279997474269
Epoch: 43 | Iteration number: [200/565] 35% | Training loss: 0.6902339798212052
Epoch: 43 | Iteration number: [210/565] 37% | Training loss: 0.6900684629167829
Epoch: 43 | Iteration number: [220/565] 38% | Training loss: 0.6899177513339303
Epoch: 43 | Iteration number: [230/565] 40% | Training loss: 0.6897830810235894
Epoch: 43 | Iteration number: [240/565] 42% | Training loss: 0.6896438087026279
Epoch: 43 | Iteration number: [250/565] 44% | Training loss: 0.6895356585979462
Epoch: 43 | Iteration number: [260/565] 46% | Training loss: 0.6894279716106562
Epoch: 43 | Iteration number: [270/565] 47% | Training loss: 0.6893359261530417
Epoch: 43 | Iteration number: [280/565] 49% | Training loss: 0.6892367307628904
Epoch: 43 | Iteration number: [290/565] 51% | Training loss: 0.6891623077721432
Epoch: 43 | Iteration number: [300/565] 53% | Training loss: 0.6890865516662598
Epoch: 43 | Iteration number: [310/565] 54% | Training loss: 0.6890131892696504
Epoch: 43 | Iteration number: [320/565] 56% | Training loss: 0.6889591336250305
Epoch: 43 | Iteration number: [330/565] 58% | Training loss: 0.6888918482896054
Epoch: 43 | Iteration number: [340/565] 60% | Training loss: 0.6888375517200022
Epoch: 43 | Iteration number: [350/565] 61% | Training loss: 0.6887826527867998
Epoch: 43 | Iteration number: [360/565] 63% | Training loss: 0.68872486088011
Epoch: 43 | Iteration number: [370/565] 65% | Training loss: 0.6886653592457642
Epoch: 43 | Iteration number: [380/565] 67% | Training loss: 0.688629467079514
Epoch: 43 | Iteration number: [390/565] 69% | Training loss: 0.6885752685559101
Epoch: 43 | Iteration number: [400/565] 70% | Training loss: 0.6885317063331604
Epoch: 43 | Iteration number: [410/565] 72% | Training loss: 0.6884946671927847
Epoch: 43 | Iteration number: [420/565] 74% | Training loss: 0.6884656522955214
Epoch: 43 | Iteration number: [430/565] 76% | Training loss: 0.6884251149587853
Epoch: 43 | Iteration number: [440/565] 77% | Training loss: 0.6883898821744052
Epoch: 43 | Iteration number: [450/565] 79% | Training loss: 0.6883563368850284
Epoch: 43 | Iteration number: [460/565] 81% | Training loss: 0.6883207909438921
Epoch: 43 | Iteration number: [470/565] 83% | Training loss: 0.6882799114318604
Epoch: 43 | Iteration number: [480/565] 84% | Training loss: 0.6882537747422854
Epoch: 43 | Iteration number: [490/565] 86% | Training loss: 0.6882328466493256
Epoch: 43 | Iteration number: [500/565] 88% | Training loss: 0.6882021859884262
Epoch: 43 | Iteration number: [510/565] 90% | Training loss: 0.6881859800394844
Epoch: 43 | Iteration number: [520/565] 92% | Training loss: 0.6881594665921651
Epoch: 43 | Iteration number: [530/565] 93% | Training loss: 0.6881284186300242
Epoch: 43 | Iteration number: [540/565] 95% | Training loss: 0.6881067857698158
Epoch: 43 | Iteration number: [550/565] 97% | Training loss: 0.6880850465731188
Epoch: 43 | Iteration number: [560/565] 99% | Training loss: 0.688068052487714

 End of epoch: 43 | Train Loss: 0.6868360801080687 | Training Time: 89 

 End of epoch: 43 | Eval Loss: 0.6894579189164298 | Evaluating Time: 6 
Epoch: 44 | Iteration number: [10/565] 1% | Training loss: 0.7552678644657135
Epoch: 44 | Iteration number: [20/565] 3% | Training loss: 0.7212205350399017
Epoch: 44 | Iteration number: [30/565] 5% | Training loss: 0.7098412891228993
Epoch: 44 | Iteration number: [40/565] 7% | Training loss: 0.7041606485843659
Epoch: 44 | Iteration number: [50/565] 8% | Training loss: 0.7006956326961518
Epoch: 44 | Iteration number: [60/565] 10% | Training loss: 0.6983934263388316
Epoch: 44 | Iteration number: [70/565] 12% | Training loss: 0.696678284236363
Epoch: 44 | Iteration number: [80/565] 14% | Training loss: 0.6955106593668461
Epoch: 44 | Iteration number: [90/565] 15% | Training loss: 0.6945254617267185
Epoch: 44 | Iteration number: [100/565] 17% | Training loss: 0.6937897253036499
Epoch: 44 | Iteration number: [110/565] 19% | Training loss: 0.6931610335003245
Epoch: 44 | Iteration number: [120/565] 21% | Training loss: 0.6926341702540716
Epoch: 44 | Iteration number: [130/565] 23% | Training loss: 0.6921678176293007
Epoch: 44 | Iteration number: [140/565] 24% | Training loss: 0.6917851916381291
Epoch: 44 | Iteration number: [150/565] 26% | Training loss: 0.6914711236953736
Epoch: 44 | Iteration number: [160/565] 28% | Training loss: 0.6911745000630617
Epoch: 44 | Iteration number: [170/565] 30% | Training loss: 0.6909136800205007
Epoch: 44 | Iteration number: [180/565] 31% | Training loss: 0.6906681583987342
Epoch: 44 | Iteration number: [190/565] 33% | Training loss: 0.6904563059932307
Epoch: 44 | Iteration number: [200/565] 35% | Training loss: 0.6902612102031708
Epoch: 44 | Iteration number: [210/565] 37% | Training loss: 0.6901005035354978
Epoch: 44 | Iteration number: [220/565] 38% | Training loss: 0.6899402122605931
Epoch: 44 | Iteration number: [230/565] 40% | Training loss: 0.6897987028826837
Epoch: 44 | Iteration number: [240/565] 42% | Training loss: 0.689673813432455
Epoch: 44 | Iteration number: [250/565] 44% | Training loss: 0.6895647912025452
Epoch: 44 | Iteration number: [260/565] 46% | Training loss: 0.6894695673997585
Epoch: 44 | Iteration number: [270/565] 47% | Training loss: 0.6893705970711178
Epoch: 44 | Iteration number: [280/565] 49% | Training loss: 0.6892858786242348
Epoch: 44 | Iteration number: [290/565] 51% | Training loss: 0.6891973571530704
Epoch: 44 | Iteration number: [300/565] 53% | Training loss: 0.6891165651877721
Epoch: 44 | Iteration number: [310/565] 54% | Training loss: 0.6890566199056564
Epoch: 44 | Iteration number: [320/565] 56% | Training loss: 0.6889850609004498
Epoch: 44 | Iteration number: [330/565] 58% | Training loss: 0.6889194289843241
Epoch: 44 | Iteration number: [340/565] 60% | Training loss: 0.6888542894054862
Epoch: 44 | Iteration number: [350/565] 61% | Training loss: 0.6887816863400595
Epoch: 44 | Iteration number: [360/565] 63% | Training loss: 0.6887369336353408
Epoch: 44 | Iteration number: [370/565] 65% | Training loss: 0.6886852025985718
Epoch: 44 | Iteration number: [380/565] 67% | Training loss: 0.6886443326347753
Epoch: 44 | Iteration number: [390/565] 69% | Training loss: 0.6886018022512779
Epoch: 44 | Iteration number: [400/565] 70% | Training loss: 0.6885552442073822
Epoch: 44 | Iteration number: [410/565] 72% | Training loss: 0.6885045465899677
Epoch: 44 | Iteration number: [420/565] 74% | Training loss: 0.6884729158310663
Epoch: 44 | Iteration number: [430/565] 76% | Training loss: 0.6884285815926485
Epoch: 44 | Iteration number: [440/565] 77% | Training loss: 0.6883921147747474
Epoch: 44 | Iteration number: [450/565] 79% | Training loss: 0.6883556883864933
Epoch: 44 | Iteration number: [460/565] 81% | Training loss: 0.6883270390655684
Epoch: 44 | Iteration number: [470/565] 83% | Training loss: 0.6882863184239002
Epoch: 44 | Iteration number: [480/565] 84% | Training loss: 0.6882531763364871
Epoch: 44 | Iteration number: [490/565] 86% | Training loss: 0.6882225828511375
Epoch: 44 | Iteration number: [500/565] 88% | Training loss: 0.6881937016248703
Epoch: 44 | Iteration number: [510/565] 90% | Training loss: 0.6881737693852069
Epoch: 44 | Iteration number: [520/565] 92% | Training loss: 0.6881401711931595
Epoch: 44 | Iteration number: [530/565] 93% | Training loss: 0.6881228128694138
Epoch: 44 | Iteration number: [540/565] 95% | Training loss: 0.6881021047080005
Epoch: 44 | Iteration number: [550/565] 97% | Training loss: 0.6880802965164184
Epoch: 44 | Iteration number: [560/565] 99% | Training loss: 0.6880541578999587

 End of epoch: 44 | Train Loss: 0.6868307118922208 | Training Time: 90 

 End of epoch: 44 | Eval Loss: 0.6893325277737209 | Evaluating Time: 6 
Epoch: 45 | Iteration number: [10/565] 1% | Training loss: 0.7552998185157775
Epoch: 45 | Iteration number: [20/565] 3% | Training loss: 0.7209241449832916
Epoch: 45 | Iteration number: [30/565] 5% | Training loss: 0.7095417439937591
Epoch: 45 | Iteration number: [40/565] 7% | Training loss: 0.7038036406040191
Epoch: 45 | Iteration number: [50/565] 8% | Training loss: 0.7004335856437683
Epoch: 45 | Iteration number: [60/565] 10% | Training loss: 0.6981963266928991
Epoch: 45 | Iteration number: [70/565] 12% | Training loss: 0.6965681084564754
Epoch: 45 | Iteration number: [80/565] 14% | Training loss: 0.6953315056860447
Epoch: 45 | Iteration number: [90/565] 15% | Training loss: 0.694454507695304
Epoch: 45 | Iteration number: [100/565] 17% | Training loss: 0.6937093007564544
Epoch: 45 | Iteration number: [110/565] 19% | Training loss: 0.693130572275682
Epoch: 45 | Iteration number: [120/565] 21% | Training loss: 0.6926164776086807
Epoch: 45 | Iteration number: [130/565] 23% | Training loss: 0.6921777450121366
Epoch: 45 | Iteration number: [140/565] 24% | Training loss: 0.6917539805173873
Epoch: 45 | Iteration number: [150/565] 26% | Training loss: 0.6914208098252614
Epoch: 45 | Iteration number: [160/565] 28% | Training loss: 0.6911168582737446
Epoch: 45 | Iteration number: [170/565] 30% | Training loss: 0.6908482348217684
Epoch: 45 | Iteration number: [180/565] 31% | Training loss: 0.6906111809942458
Epoch: 45 | Iteration number: [190/565] 33% | Training loss: 0.6904135575419978
Epoch: 45 | Iteration number: [200/565] 35% | Training loss: 0.6902454888820648
Epoch: 45 | Iteration number: [210/565] 37% | Training loss: 0.6900954757417951
Epoch: 45 | Iteration number: [220/565] 38% | Training loss: 0.6899127412926067
Epoch: 45 | Iteration number: [230/565] 40% | Training loss: 0.6897951947606128
Epoch: 45 | Iteration number: [240/565] 42% | Training loss: 0.6896745068331559
Epoch: 45 | Iteration number: [250/565] 44% | Training loss: 0.6895565459728241
Epoch: 45 | Iteration number: [260/565] 46% | Training loss: 0.6894601957156108
Epoch: 45 | Iteration number: [270/565] 47% | Training loss: 0.6893740219098551
Epoch: 45 | Iteration number: [280/565] 49% | Training loss: 0.6892853360090937
Epoch: 45 | Iteration number: [290/565] 51% | Training loss: 0.689194713584308
Epoch: 45 | Iteration number: [300/565] 53% | Training loss: 0.6891129046678544
Epoch: 45 | Iteration number: [310/565] 54% | Training loss: 0.6890404209013908
Epoch: 45 | Iteration number: [320/565] 56% | Training loss: 0.6889688847586513
Epoch: 45 | Iteration number: [330/565] 58% | Training loss: 0.6889077775406115
Epoch: 45 | Iteration number: [340/565] 60% | Training loss: 0.6888540459029815
Epoch: 45 | Iteration number: [350/565] 61% | Training loss: 0.6887999640192304
Epoch: 45 | Iteration number: [360/565] 63% | Training loss: 0.6887532482544582
Epoch: 45 | Iteration number: [370/565] 65% | Training loss: 0.6887115594503042
Epoch: 45 | Iteration number: [380/565] 67% | Training loss: 0.6886641292195571
Epoch: 45 | Iteration number: [390/565] 69% | Training loss: 0.6886195607674428
Epoch: 45 | Iteration number: [400/565] 70% | Training loss: 0.688570464849472
Epoch: 45 | Iteration number: [410/565] 72% | Training loss: 0.6885260903253788
Epoch: 45 | Iteration number: [420/565] 74% | Training loss: 0.68849345544974
Epoch: 45 | Iteration number: [430/565] 76% | Training loss: 0.6884639288103858
Epoch: 45 | Iteration number: [440/565] 77% | Training loss: 0.688434580645778
Epoch: 45 | Iteration number: [450/565] 79% | Training loss: 0.6884068648020426
Epoch: 45 | Iteration number: [460/565] 81% | Training loss: 0.6883610722811325
Epoch: 45 | Iteration number: [470/565] 83% | Training loss: 0.6883175920932851
Epoch: 45 | Iteration number: [480/565] 84% | Training loss: 0.6882770252724488
Epoch: 45 | Iteration number: [490/565] 86% | Training loss: 0.6882444701632675
Epoch: 45 | Iteration number: [500/565] 88% | Training loss: 0.688211011171341
Epoch: 45 | Iteration number: [510/565] 90% | Training loss: 0.6881815990980934
Epoch: 45 | Iteration number: [520/565] 92% | Training loss: 0.6881592674897268
Epoch: 45 | Iteration number: [530/565] 93% | Training loss: 0.6881361495773747
Epoch: 45 | Iteration number: [540/565] 95% | Training loss: 0.6881121346244106
Epoch: 45 | Iteration number: [550/565] 97% | Training loss: 0.6880915849859064
Epoch: 45 | Iteration number: [560/565] 99% | Training loss: 0.6880632822002684

 End of epoch: 45 | Train Loss: 0.6868342506147064 | Training Time: 88 

 End of epoch: 45 | Eval Loss: 0.6899878212383815 | Evaluating Time: 6 
Epoch: 46 | Iteration number: [10/565] 1% | Training loss: 0.7562877595424652
Epoch: 46 | Iteration number: [20/565] 3% | Training loss: 0.7215274155139924
Epoch: 46 | Iteration number: [30/565] 5% | Training loss: 0.7099365095297495
Epoch: 46 | Iteration number: [40/565] 7% | Training loss: 0.7041709214448929
Epoch: 46 | Iteration number: [50/565] 8% | Training loss: 0.7006361091136932
Epoch: 46 | Iteration number: [60/565] 10% | Training loss: 0.6983285874128342
Epoch: 46 | Iteration number: [70/565] 12% | Training loss: 0.6967028779642922
Epoch: 46 | Iteration number: [80/565] 14% | Training loss: 0.6954835288226604
Epoch: 46 | Iteration number: [90/565] 15% | Training loss: 0.6945450822512309
Epoch: 46 | Iteration number: [100/565] 17% | Training loss: 0.6937543201446533
Epoch: 46 | Iteration number: [110/565] 19% | Training loss: 0.6931350290775299
Epoch: 46 | Iteration number: [120/565] 21% | Training loss: 0.6926271225015322
Epoch: 46 | Iteration number: [130/565] 23% | Training loss: 0.6921606192222008
Epoch: 46 | Iteration number: [140/565] 24% | Training loss: 0.6917841898543494
Epoch: 46 | Iteration number: [150/565] 26% | Training loss: 0.6914491049448649
Epoch: 46 | Iteration number: [160/565] 28% | Training loss: 0.6911514572799206
Epoch: 46 | Iteration number: [170/565] 30% | Training loss: 0.69088814924745
Epoch: 46 | Iteration number: [180/565] 31% | Training loss: 0.6906684405273862
Epoch: 46 | Iteration number: [190/565] 33% | Training loss: 0.6904617438190862
Epoch: 46 | Iteration number: [200/565] 35% | Training loss: 0.690292032957077
Epoch: 46 | Iteration number: [210/565] 37% | Training loss: 0.690133550053551
Epoch: 46 | Iteration number: [220/565] 38% | Training loss: 0.6899899144064296
Epoch: 46 | Iteration number: [230/565] 40% | Training loss: 0.6898594770742499
Epoch: 46 | Iteration number: [240/565] 42% | Training loss: 0.68971620524923
Epoch: 46 | Iteration number: [250/565] 44% | Training loss: 0.6895941255092621
Epoch: 46 | Iteration number: [260/565] 46% | Training loss: 0.6894900606228755
Epoch: 46 | Iteration number: [270/565] 47% | Training loss: 0.6893983191914028
Epoch: 46 | Iteration number: [280/565] 49% | Training loss: 0.6893020444682666
Epoch: 46 | Iteration number: [290/565] 51% | Training loss: 0.6892089773868693
Epoch: 46 | Iteration number: [300/565] 53% | Training loss: 0.6891288858652115
Epoch: 46 | Iteration number: [310/565] 54% | Training loss: 0.6890466791968192
Epoch: 46 | Iteration number: [320/565] 56% | Training loss: 0.6889775143936276
Epoch: 46 | Iteration number: [330/565] 58% | Training loss: 0.6889109801162373
Epoch: 46 | Iteration number: [340/565] 60% | Training loss: 0.6888395195498186
Epoch: 46 | Iteration number: [350/565] 61% | Training loss: 0.6887819233962468
Epoch: 46 | Iteration number: [360/565] 63% | Training loss: 0.6887462986840143
Epoch: 46 | Iteration number: [370/565] 65% | Training loss: 0.6886921997005875
Epoch: 46 | Iteration number: [380/565] 67% | Training loss: 0.6886248566602405
Epoch: 46 | Iteration number: [390/565] 69% | Training loss: 0.6885783304006625
Epoch: 46 | Iteration number: [400/565] 70% | Training loss: 0.6885250289738178
Epoch: 46 | Iteration number: [410/565] 72% | Training loss: 0.6884740338092897
Epoch: 46 | Iteration number: [420/565] 74% | Training loss: 0.6884395612137658
Epoch: 46 | Iteration number: [430/565] 76% | Training loss: 0.6884063540503036
Epoch: 46 | Iteration number: [440/565] 77% | Training loss: 0.6883731350302696
Epoch: 46 | Iteration number: [450/565] 79% | Training loss: 0.6883323899904887
Epoch: 46 | Iteration number: [460/565] 81% | Training loss: 0.6882990892814553
Epoch: 46 | Iteration number: [470/565] 83% | Training loss: 0.6882805490747411
Epoch: 46 | Iteration number: [480/565] 84% | Training loss: 0.6882490242520968
Epoch: 46 | Iteration number: [490/565] 86% | Training loss: 0.6882186872618539
Epoch: 46 | Iteration number: [500/565] 88% | Training loss: 0.6881912257671357
Epoch: 46 | Iteration number: [510/565] 90% | Training loss: 0.6881742385088229
Epoch: 46 | Iteration number: [520/565] 92% | Training loss: 0.6881418573168608
Epoch: 46 | Iteration number: [530/565] 93% | Training loss: 0.6881144709182235
Epoch: 46 | Iteration number: [540/565] 95% | Training loss: 0.6880865710752981
Epoch: 46 | Iteration number: [550/565] 97% | Training loss: 0.688060738065026
Epoch: 46 | Iteration number: [560/565] 99% | Training loss: 0.6880437898848738

 End of epoch: 46 | Train Loss: 0.6868186013888469 | Training Time: 89 

 End of epoch: 46 | Eval Loss: 0.6900163122585842 | Evaluating Time: 6 
Epoch: 47 | Iteration number: [10/565] 1% | Training loss: 0.755557382106781
Epoch: 47 | Iteration number: [20/565] 3% | Training loss: 0.7211547046899796
Epoch: 47 | Iteration number: [30/565] 5% | Training loss: 0.7097958624362946
Epoch: 47 | Iteration number: [40/565] 7% | Training loss: 0.7041023656725883
Epoch: 47 | Iteration number: [50/565] 8% | Training loss: 0.7007982957363129
Epoch: 47 | Iteration number: [60/565] 10% | Training loss: 0.6984710117181142
Epoch: 47 | Iteration number: [70/565] 12% | Training loss: 0.696739854982921
Epoch: 47 | Iteration number: [80/565] 14% | Training loss: 0.6954785741865634
Epoch: 47 | Iteration number: [90/565] 15% | Training loss: 0.6945140388276841
Epoch: 47 | Iteration number: [100/565] 17% | Training loss: 0.6937610089778901
Epoch: 47 | Iteration number: [110/565] 19% | Training loss: 0.6931061988527124
Epoch: 47 | Iteration number: [120/565] 21% | Training loss: 0.6925855934619903
Epoch: 47 | Iteration number: [130/565] 23% | Training loss: 0.6921280329044048
Epoch: 47 | Iteration number: [140/565] 24% | Training loss: 0.6917602321931294
Epoch: 47 | Iteration number: [150/565] 26% | Training loss: 0.691422791481018
Epoch: 47 | Iteration number: [160/565] 28% | Training loss: 0.6910914469510316
Epoch: 47 | Iteration number: [170/565] 30% | Training loss: 0.6908492421402651
Epoch: 47 | Iteration number: [180/565] 31% | Training loss: 0.6906379759311676
Epoch: 47 | Iteration number: [190/565] 33% | Training loss: 0.6904289474612788
Epoch: 47 | Iteration number: [200/565] 35% | Training loss: 0.690249265730381
Epoch: 47 | Iteration number: [210/565] 37% | Training loss: 0.6900727774415697
Epoch: 47 | Iteration number: [220/565] 38% | Training loss: 0.689936930753968
Epoch: 47 | Iteration number: [230/565] 40% | Training loss: 0.6897965273131494
Epoch: 47 | Iteration number: [240/565] 42% | Training loss: 0.6896821434299151
Epoch: 47 | Iteration number: [250/565] 44% | Training loss: 0.6895735819339752
Epoch: 47 | Iteration number: [260/565] 46% | Training loss: 0.6894735932350159
Epoch: 47 | Iteration number: [270/565] 47% | Training loss: 0.6893882585896386
Epoch: 47 | Iteration number: [280/565] 49% | Training loss: 0.6892957717180253
Epoch: 47 | Iteration number: [290/565] 51% | Training loss: 0.689206431240871
Epoch: 47 | Iteration number: [300/565] 53% | Training loss: 0.6891299984852473
Epoch: 47 | Iteration number: [310/565] 54% | Training loss: 0.6890559559868228
Epoch: 47 | Iteration number: [320/565] 56% | Training loss: 0.6889795087277889
Epoch: 47 | Iteration number: [330/565] 58% | Training loss: 0.6889131322051539
Epoch: 47 | Iteration number: [340/565] 60% | Training loss: 0.6888615355772131
Epoch: 47 | Iteration number: [350/565] 61% | Training loss: 0.6888119845730918
Epoch: 47 | Iteration number: [360/565] 63% | Training loss: 0.688764290842745
Epoch: 47 | Iteration number: [370/565] 65% | Training loss: 0.6887123396267762
Epoch: 47 | Iteration number: [380/565] 67% | Training loss: 0.688658479483504
Epoch: 47 | Iteration number: [390/565] 69% | Training loss: 0.6886127795928564
Epoch: 47 | Iteration number: [400/565] 70% | Training loss: 0.6885731096565724
Epoch: 47 | Iteration number: [410/565] 72% | Training loss: 0.6885384920166759
Epoch: 47 | Iteration number: [420/565] 74% | Training loss: 0.6884857122387205
Epoch: 47 | Iteration number: [430/565] 76% | Training loss: 0.6884381872276927
Epoch: 47 | Iteration number: [440/565] 77% | Training loss: 0.6883929793130268
Epoch: 47 | Iteration number: [450/565] 79% | Training loss: 0.6883523786067962
Epoch: 47 | Iteration number: [460/565] 81% | Training loss: 0.688314836828605
Epoch: 47 | Iteration number: [470/565] 83% | Training loss: 0.6882798357212797
Epoch: 47 | Iteration number: [480/565] 84% | Training loss: 0.6882494304329156
Epoch: 47 | Iteration number: [490/565] 86% | Training loss: 0.6882183602878026
Epoch: 47 | Iteration number: [500/565] 88% | Training loss: 0.6881884589195252
Epoch: 47 | Iteration number: [510/565] 90% | Training loss: 0.6881661914142908
Epoch: 47 | Iteration number: [520/565] 92% | Training loss: 0.6881409706977698
Epoch: 47 | Iteration number: [530/565] 93% | Training loss: 0.6881247894943885
Epoch: 47 | Iteration number: [540/565] 95% | Training loss: 0.6880994359652202
Epoch: 47 | Iteration number: [550/565] 97% | Training loss: 0.6880819720571691
Epoch: 47 | Iteration number: [560/565] 99% | Training loss: 0.6880591147712298

 End of epoch: 47 | Train Loss: 0.6868289570892807 | Training Time: 88 

 End of epoch: 47 | Eval Loss: 0.6898622172219413 | Evaluating Time: 6 
Epoch: 48 | Iteration number: [10/565] 1% | Training loss: 0.7559821963310241
Epoch: 48 | Iteration number: [20/565] 3% | Training loss: 0.7213551878929139
Epoch: 48 | Iteration number: [30/565] 5% | Training loss: 0.7098360240459443
Epoch: 48 | Iteration number: [40/565] 7% | Training loss: 0.7040498077869415
Epoch: 48 | Iteration number: [50/565] 8% | Training loss: 0.7005773961544037
Epoch: 48 | Iteration number: [60/565] 10% | Training loss: 0.6983131438493728
Epoch: 48 | Iteration number: [70/565] 12% | Training loss: 0.6966285858835493
Epoch: 48 | Iteration number: [80/565] 14% | Training loss: 0.6955008961260318
Epoch: 48 | Iteration number: [90/565] 15% | Training loss: 0.6945496771070693
Epoch: 48 | Iteration number: [100/565] 17% | Training loss: 0.6937630957365036
Epoch: 48 | Iteration number: [110/565] 19% | Training loss: 0.6931451271880756
Epoch: 48 | Iteration number: [120/565] 21% | Training loss: 0.69259941081206
Epoch: 48 | Iteration number: [130/565] 23% | Training loss: 0.6921488830676445
Epoch: 48 | Iteration number: [140/565] 24% | Training loss: 0.691760379927499
Epoch: 48 | Iteration number: [150/565] 26% | Training loss: 0.6914336256186168
Epoch: 48 | Iteration number: [160/565] 28% | Training loss: 0.6911460209637881
Epoch: 48 | Iteration number: [170/565] 30% | Training loss: 0.6908724129199981
Epoch: 48 | Iteration number: [180/565] 31% | Training loss: 0.6906302895810869
Epoch: 48 | Iteration number: [190/565] 33% | Training loss: 0.690448029104032
Epoch: 48 | Iteration number: [200/565] 35% | Training loss: 0.6902693060040473
Epoch: 48 | Iteration number: [210/565] 37% | Training loss: 0.6900666327703566
Epoch: 48 | Iteration number: [220/565] 38% | Training loss: 0.689925662224943
Epoch: 48 | Iteration number: [230/565] 40% | Training loss: 0.68978765529135
Epoch: 48 | Iteration number: [240/565] 42% | Training loss: 0.6896646896998088
Epoch: 48 | Iteration number: [250/565] 44% | Training loss: 0.6895472319126129
Epoch: 48 | Iteration number: [260/565] 46% | Training loss: 0.6894429899179019
Epoch: 48 | Iteration number: [270/565] 47% | Training loss: 0.6893592618129871
Epoch: 48 | Iteration number: [280/565] 49% | Training loss: 0.6892533406615258
Epoch: 48 | Iteration number: [290/565] 51% | Training loss: 0.6891830456667933
Epoch: 48 | Iteration number: [300/565] 53% | Training loss: 0.6890955058733622
Epoch: 48 | Iteration number: [310/565] 54% | Training loss: 0.6890232755291846
Epoch: 48 | Iteration number: [320/565] 56% | Training loss: 0.6889622289687395
Epoch: 48 | Iteration number: [330/565] 58% | Training loss: 0.688904817718448
Epoch: 48 | Iteration number: [340/565] 60% | Training loss: 0.6888291476403966
Epoch: 48 | Iteration number: [350/565] 61% | Training loss: 0.688781247649874
Epoch: 48 | Iteration number: [360/565] 63% | Training loss: 0.6887327548530366
Epoch: 48 | Iteration number: [370/565] 65% | Training loss: 0.6886884423526558
Epoch: 48 | Iteration number: [380/565] 67% | Training loss: 0.6886374039085288
Epoch: 48 | Iteration number: [390/565] 69% | Training loss: 0.6886049261459938
Epoch: 48 | Iteration number: [400/565] 70% | Training loss: 0.6885610084235668
Epoch: 48 | Iteration number: [410/565] 72% | Training loss: 0.6885176647000196
Epoch: 48 | Iteration number: [420/565] 74% | Training loss: 0.6884811245259784
Epoch: 48 | Iteration number: [430/565] 76% | Training loss: 0.6884468190891798
Epoch: 48 | Iteration number: [440/565] 77% | Training loss: 0.6884038140827959
Epoch: 48 | Iteration number: [450/565] 79% | Training loss: 0.6883706580268012
Epoch: 48 | Iteration number: [460/565] 81% | Training loss: 0.6883354869873627
Epoch: 48 | Iteration number: [470/565] 83% | Training loss: 0.6883005352730447
Epoch: 48 | Iteration number: [480/565] 84% | Training loss: 0.6882609205941359
Epoch: 48 | Iteration number: [490/565] 86% | Training loss: 0.6882308664370557
Epoch: 48 | Iteration number: [500/565] 88% | Training loss: 0.6881986488103866
Epoch: 48 | Iteration number: [510/565] 90% | Training loss: 0.6881660405327292
Epoch: 48 | Iteration number: [520/565] 92% | Training loss: 0.6881379564221088
Epoch: 48 | Iteration number: [530/565] 93% | Training loss: 0.6881149028832058
Epoch: 48 | Iteration number: [540/565] 95% | Training loss: 0.6880921916829215
Epoch: 48 | Iteration number: [550/565] 97% | Training loss: 0.6880643062158064
Epoch: 48 | Iteration number: [560/565] 99% | Training loss: 0.6880406507423946

 End of epoch: 48 | Train Loss: 0.6868195433532243 | Training Time: 89 

 End of epoch: 48 | Eval Loss: 0.6898101568222046 | Evaluating Time: 6 
Epoch: 49 | Iteration number: [10/565] 1% | Training loss: 0.7555972874164582
Epoch: 49 | Iteration number: [20/565] 3% | Training loss: 0.7211148411035537
Epoch: 49 | Iteration number: [30/565] 5% | Training loss: 0.7096423884232839
Epoch: 49 | Iteration number: [40/565] 7% | Training loss: 0.7038586512207985
Epoch: 49 | Iteration number: [50/565] 8% | Training loss: 0.7005204403400421
Epoch: 49 | Iteration number: [60/565] 10% | Training loss: 0.6981680105129878
Epoch: 49 | Iteration number: [70/565] 12% | Training loss: 0.6965389822210585
Epoch: 49 | Iteration number: [80/565] 14% | Training loss: 0.6953445814549923
Epoch: 49 | Iteration number: [90/565] 15% | Training loss: 0.6943775753180186
Epoch: 49 | Iteration number: [100/565] 17% | Training loss: 0.6936498343944549
Epoch: 49 | Iteration number: [110/565] 19% | Training loss: 0.693043449791995
Epoch: 49 | Iteration number: [120/565] 21% | Training loss: 0.6925321529308955
Epoch: 49 | Iteration number: [130/565] 23% | Training loss: 0.6920956891316634
Epoch: 49 | Iteration number: [140/565] 24% | Training loss: 0.6917329609394074
Epoch: 49 | Iteration number: [150/565] 26% | Training loss: 0.691398161649704
Epoch: 49 | Iteration number: [160/565] 28% | Training loss: 0.6910959672182798
Epoch: 49 | Iteration number: [170/565] 30% | Training loss: 0.6908573006882387
Epoch: 49 | Iteration number: [180/565] 31% | Training loss: 0.6906302193800609
Epoch: 49 | Iteration number: [190/565] 33% | Training loss: 0.6904300184626329
Epoch: 49 | Iteration number: [200/565] 35% | Training loss: 0.6902266415953636
Epoch: 49 | Iteration number: [210/565] 37% | Training loss: 0.6900440423261551
Epoch: 49 | Iteration number: [220/565] 38% | Training loss: 0.6899148447947069
Epoch: 49 | Iteration number: [230/565] 40% | Training loss: 0.6897733377373737
Epoch: 49 | Iteration number: [240/565] 42% | Training loss: 0.6896459743380546
Epoch: 49 | Iteration number: [250/565] 44% | Training loss: 0.6895187265872955
Epoch: 49 | Iteration number: [260/565] 46% | Training loss: 0.6894101489048737
Epoch: 49 | Iteration number: [270/565] 47% | Training loss: 0.6893118034910273
Epoch: 49 | Iteration number: [280/565] 49% | Training loss: 0.6892320305109024
Epoch: 49 | Iteration number: [290/565] 51% | Training loss: 0.6891521122948877
Epoch: 49 | Iteration number: [300/565] 53% | Training loss: 0.6890707604090373
Epoch: 49 | Iteration number: [310/565] 54% | Training loss: 0.6889951254090955
Epoch: 49 | Iteration number: [320/565] 56% | Training loss: 0.6889283485710621
Epoch: 49 | Iteration number: [330/565] 58% | Training loss: 0.6888744440945712
Epoch: 49 | Iteration number: [340/565] 60% | Training loss: 0.6888087558395722
Epoch: 49 | Iteration number: [350/565] 61% | Training loss: 0.6887453428336552
Epoch: 49 | Iteration number: [360/565] 63% | Training loss: 0.6887024889389673
Epoch: 49 | Iteration number: [370/565] 65% | Training loss: 0.6886576924775097
Epoch: 49 | Iteration number: [380/565] 67% | Training loss: 0.6886167101169888
Epoch: 49 | Iteration number: [390/565] 69% | Training loss: 0.6885687256470705
Epoch: 49 | Iteration number: [400/565] 70% | Training loss: 0.688515310883522
Epoch: 49 | Iteration number: [410/565] 72% | Training loss: 0.6884853022854502
Epoch: 49 | Iteration number: [420/565] 74% | Training loss: 0.6884433825810751
Epoch: 49 | Iteration number: [430/565] 76% | Training loss: 0.6884189066498778
Epoch: 49 | Iteration number: [440/565] 77% | Training loss: 0.6883840720761906
Epoch: 49 | Iteration number: [450/565] 79% | Training loss: 0.688349501159456
Epoch: 49 | Iteration number: [460/565] 81% | Training loss: 0.6883196015720782
Epoch: 49 | Iteration number: [470/565] 83% | Training loss: 0.6882990019118532
Epoch: 49 | Iteration number: [480/565] 84% | Training loss: 0.688272030154864
Epoch: 49 | Iteration number: [490/565] 86% | Training loss: 0.6882417880758948
Epoch: 49 | Iteration number: [500/565] 88% | Training loss: 0.6882058162689209
Epoch: 49 | Iteration number: [510/565] 90% | Training loss: 0.6881778126838161
Epoch: 49 | Iteration number: [520/565] 92% | Training loss: 0.6881525704493889
Epoch: 49 | Iteration number: [530/565] 93% | Training loss: 0.6881265201658573
Epoch: 49 | Iteration number: [540/565] 95% | Training loss: 0.6881044611886695
Epoch: 49 | Iteration number: [550/565] 97% | Training loss: 0.6880698223547502
Epoch: 49 | Iteration number: [560/565] 99% | Training loss: 0.6880412705242633

 End of epoch: 49 | Train Loss: 0.6868199478208491 | Training Time: 88 

 End of epoch: 49 | Eval Loss: 0.689527588231223 | Evaluating Time: 5 
Epoch: 50 | Iteration number: [10/565] 1% | Training loss: 0.7557919144630432
Epoch: 50 | Iteration number: [20/565] 3% | Training loss: 0.7212722659111023
Epoch: 50 | Iteration number: [30/565] 5% | Training loss: 0.7101014415423076
Epoch: 50 | Iteration number: [40/565] 7% | Training loss: 0.7042215943336487
Epoch: 50 | Iteration number: [50/565] 8% | Training loss: 0.7007298398017884
Epoch: 50 | Iteration number: [60/565] 10% | Training loss: 0.6983729571104049
Epoch: 50 | Iteration number: [70/565] 12% | Training loss: 0.6967313528060913
Epoch: 50 | Iteration number: [80/565] 14% | Training loss: 0.6955301135778427
Epoch: 50 | Iteration number: [90/565] 15% | Training loss: 0.6945447146892547
Epoch: 50 | Iteration number: [100/565] 17% | Training loss: 0.6937759888172149
Epoch: 50 | Iteration number: [110/565] 19% | Training loss: 0.6931567652658983
Epoch: 50 | Iteration number: [120/565] 21% | Training loss: 0.6926301643252373
Epoch: 50 | Iteration number: [130/565] 23% | Training loss: 0.6921642275956961
Epoch: 50 | Iteration number: [140/565] 24% | Training loss: 0.6917576836688178
Epoch: 50 | Iteration number: [150/565] 26% | Training loss: 0.6914447422822316
Epoch: 50 | Iteration number: [160/565] 28% | Training loss: 0.6911498151719571
Epoch: 50 | Iteration number: [170/565] 30% | Training loss: 0.6909009495202233
Epoch: 50 | Iteration number: [180/565] 31% | Training loss: 0.6906649761729771
Epoch: 50 | Iteration number: [190/565] 33% | Training loss: 0.690480092011
Epoch: 50 | Iteration number: [200/565] 35% | Training loss: 0.6903042590618134
Epoch: 50 | Iteration number: [210/565] 37% | Training loss: 0.6901367999258495
Epoch: 50 | Iteration number: [220/565] 38% | Training loss: 0.6899844061244618
Epoch: 50 | Iteration number: [230/565] 40% | Training loss: 0.6898416537305583
Epoch: 50 | Iteration number: [240/565] 42% | Training loss: 0.6897053574522336
Epoch: 50 | Iteration number: [250/565] 44% | Training loss: 0.6895874831676483
Epoch: 50 | Iteration number: [260/565] 46% | Training loss: 0.6894924078996365
Epoch: 50 | Iteration number: [270/565] 47% | Training loss: 0.6893988172213237
Epoch: 50 | Iteration number: [280/565] 49% | Training loss: 0.6892976286155837
Epoch: 50 | Iteration number: [290/565] 51% | Training loss: 0.6892155221823988
Epoch: 50 | Iteration number: [300/565] 53% | Training loss: 0.6891302647193273
Epoch: 50 | Iteration number: [310/565] 54% | Training loss: 0.6890595605296473
Epoch: 50 | Iteration number: [320/565] 56% | Training loss: 0.6889626838266849
Epoch: 50 | Iteration number: [330/565] 58% | Training loss: 0.6889021114869551
Epoch: 50 | Iteration number: [340/565] 60% | Training loss: 0.6888482512796626
Epoch: 50 | Iteration number: [350/565] 61% | Training loss: 0.6887942292009082
Epoch: 50 | Iteration number: [360/565] 63% | Training loss: 0.688759723967976
Epoch: 50 | Iteration number: [370/565] 65% | Training loss: 0.6887118964581876
Epoch: 50 | Iteration number: [380/565] 67% | Training loss: 0.6886516647903542
Epoch: 50 | Iteration number: [390/565] 69% | Training loss: 0.688610104414133
Epoch: 50 | Iteration number: [400/565] 70% | Training loss: 0.6885707387328148
Epoch: 50 | Iteration number: [410/565] 72% | Training loss: 0.688539293917214
Epoch: 50 | Iteration number: [420/565] 74% | Training loss: 0.6885014949809938
Epoch: 50 | Iteration number: [430/565] 76% | Training loss: 0.6884579524051312
Epoch: 50 | Iteration number: [440/565] 77% | Training loss: 0.6884282618761063
Epoch: 50 | Iteration number: [450/565] 79% | Training loss: 0.6883962934547
Epoch: 50 | Iteration number: [460/565] 81% | Training loss: 0.688358589877253
Epoch: 50 | Iteration number: [470/565] 83% | Training loss: 0.6883300191544471
Epoch: 50 | Iteration number: [480/565] 84% | Training loss: 0.68829233708481
Epoch: 50 | Iteration number: [490/565] 86% | Training loss: 0.6882578634485906
Epoch: 50 | Iteration number: [500/565] 88% | Training loss: 0.688220314502716
Epoch: 50 | Iteration number: [510/565] 90% | Training loss: 0.688190572051441
Epoch: 50 | Iteration number: [520/565] 92% | Training loss: 0.6881656407163693
Epoch: 50 | Iteration number: [530/565] 93% | Training loss: 0.6881456006248042
Epoch: 50 | Iteration number: [540/565] 95% | Training loss: 0.6881147155055294
Epoch: 50 | Iteration number: [550/565] 97% | Training loss: 0.6880868899822236
Epoch: 50 | Iteration number: [560/565] 99% | Training loss: 0.6880528061517648

 End of epoch: 50 | Train Loss: 0.6868244218615304 | Training Time: 89 

 End of epoch: 50 | Eval Loss: 0.689964268888746 | Evaluating Time: 6 
Epoch: 51 | Iteration number: [10/565] 1% | Training loss: 0.7554690837860107
Epoch: 51 | Iteration number: [20/565] 3% | Training loss: 0.7210372984409332
Epoch: 51 | Iteration number: [30/565] 5% | Training loss: 0.709560493628184
Epoch: 51 | Iteration number: [40/565] 7% | Training loss: 0.7038116097450257
Epoch: 51 | Iteration number: [50/565] 8% | Training loss: 0.7004331183433533
Epoch: 51 | Iteration number: [60/565] 10% | Training loss: 0.6980855117241541
Epoch: 51 | Iteration number: [70/565] 12% | Training loss: 0.6965039270264762
Epoch: 51 | Iteration number: [80/565] 14% | Training loss: 0.6952807731926441
Epoch: 51 | Iteration number: [90/565] 15% | Training loss: 0.6943614668316311
Epoch: 51 | Iteration number: [100/565] 17% | Training loss: 0.6935895156860351
Epoch: 51 | Iteration number: [110/565] 19% | Training loss: 0.6930053049867804
Epoch: 51 | Iteration number: [120/565] 21% | Training loss: 0.6924758543570836
Epoch: 51 | Iteration number: [130/565] 23% | Training loss: 0.6920273734973027
Epoch: 51 | Iteration number: [140/565] 24% | Training loss: 0.6916418143681118
Epoch: 51 | Iteration number: [150/565] 26% | Training loss: 0.6913329041004181
Epoch: 51 | Iteration number: [160/565] 28% | Training loss: 0.69103131480515
Epoch: 51 | Iteration number: [170/565] 30% | Training loss: 0.6907541530973771
Epoch: 51 | Iteration number: [180/565] 31% | Training loss: 0.6905379282103644
Epoch: 51 | Iteration number: [190/565] 33% | Training loss: 0.6903383913793062
Epoch: 51 | Iteration number: [200/565] 35% | Training loss: 0.6901792448759079
Epoch: 51 | Iteration number: [210/565] 37% | Training loss: 0.6900396988505408
Epoch: 51 | Iteration number: [220/565] 38% | Training loss: 0.6898909270763397
Epoch: 51 | Iteration number: [230/565] 40% | Training loss: 0.689762602681699
Epoch: 51 | Iteration number: [240/565] 42% | Training loss: 0.6896586549778779
Epoch: 51 | Iteration number: [250/565] 44% | Training loss: 0.6895522811412811
Epoch: 51 | Iteration number: [260/565] 46% | Training loss: 0.6894374597531099
Epoch: 51 | Iteration number: [270/565] 47% | Training loss: 0.689327746629715
Epoch: 51 | Iteration number: [280/565] 49% | Training loss: 0.6892373940774372
Epoch: 51 | Iteration number: [290/565] 51% | Training loss: 0.6891430264916913
Epoch: 51 | Iteration number: [300/565] 53% | Training loss: 0.6890634387731552
Epoch: 51 | Iteration number: [310/565] 54% | Training loss: 0.6890019759055107
Epoch: 51 | Iteration number: [320/565] 56% | Training loss: 0.6889383420348167
Epoch: 51 | Iteration number: [330/565] 58% | Training loss: 0.6888658659024672
Epoch: 51 | Iteration number: [340/565] 60% | Training loss: 0.6888139751027612
Epoch: 51 | Iteration number: [350/565] 61% | Training loss: 0.6887443910326276
Epoch: 51 | Iteration number: [360/565] 63% | Training loss: 0.688691684934828
Epoch: 51 | Iteration number: [370/565] 65% | Training loss: 0.6886401150677656
Epoch: 51 | Iteration number: [380/565] 67% | Training loss: 0.6885960313834643
Epoch: 51 | Iteration number: [390/565] 69% | Training loss: 0.6885453438147521
Epoch: 51 | Iteration number: [400/565] 70% | Training loss: 0.6885070574283599
Epoch: 51 | Iteration number: [410/565] 72% | Training loss: 0.6884612878648246
Epoch: 51 | Iteration number: [420/565] 74% | Training loss: 0.6884232701290222
Epoch: 51 | Iteration number: [430/565] 76% | Training loss: 0.6883897526319637
Epoch: 51 | Iteration number: [440/565] 77% | Training loss: 0.6883570053360679
Epoch: 51 | Iteration number: [450/565] 79% | Training loss: 0.6883274300893147
Epoch: 51 | Iteration number: [460/565] 81% | Training loss: 0.6882984544919885
Epoch: 51 | Iteration number: [470/565] 83% | Training loss: 0.6882618171103457
Epoch: 51 | Iteration number: [480/565] 84% | Training loss: 0.6882399109502634
Epoch: 51 | Iteration number: [490/565] 86% | Training loss: 0.6882118588807632
Epoch: 51 | Iteration number: [500/565] 88% | Training loss: 0.6881749594211578
Epoch: 51 | Iteration number: [510/565] 90% | Training loss: 0.6881517219777201
Epoch: 51 | Iteration number: [520/565] 92% | Training loss: 0.6881231314860857
Epoch: 51 | Iteration number: [530/565] 93% | Training loss: 0.6880970154168471
Epoch: 51 | Iteration number: [540/565] 95% | Training loss: 0.6880811152634797
Epoch: 51 | Iteration number: [550/565] 97% | Training loss: 0.688061908158389
Epoch: 51 | Iteration number: [560/565] 99% | Training loss: 0.6880405007728508

 End of epoch: 51 | Train Loss: 0.686816982146913 | Training Time: 89 

 End of epoch: 51 | Eval Loss: 0.689478201525552 | Evaluating Time: 6 
Epoch: 52 | Iteration number: [10/565] 1% | Training loss: 0.7553984940052032
Epoch: 52 | Iteration number: [20/565] 3% | Training loss: 0.7209553420543671
Epoch: 52 | Iteration number: [30/565] 5% | Training loss: 0.7095822592576345
Epoch: 52 | Iteration number: [40/565] 7% | Training loss: 0.7037872388958931
Epoch: 52 | Iteration number: [50/565] 8% | Training loss: 0.7005049026012421
Epoch: 52 | Iteration number: [60/565] 10% | Training loss: 0.6983176728089651
Epoch: 52 | Iteration number: [70/565] 12% | Training loss: 0.696661662203925
Epoch: 52 | Iteration number: [80/565] 14% | Training loss: 0.695434769243002
Epoch: 52 | Iteration number: [90/565] 15% | Training loss: 0.6944605615403917
Epoch: 52 | Iteration number: [100/565] 17% | Training loss: 0.6937550520896911
Epoch: 52 | Iteration number: [110/565] 19% | Training loss: 0.6931343831799247
Epoch: 52 | Iteration number: [120/565] 21% | Training loss: 0.6926295141379039
Epoch: 52 | Iteration number: [130/565] 23% | Training loss: 0.692190317924206
Epoch: 52 | Iteration number: [140/565] 24% | Training loss: 0.6917351841926574
Epoch: 52 | Iteration number: [150/565] 26% | Training loss: 0.6914102474848429
Epoch: 52 | Iteration number: [160/565] 28% | Training loss: 0.6911525227129459
Epoch: 52 | Iteration number: [170/565] 30% | Training loss: 0.690918242931366
Epoch: 52 | Iteration number: [180/565] 31% | Training loss: 0.6906913333468967
Epoch: 52 | Iteration number: [190/565] 33% | Training loss: 0.6904737513316305
Epoch: 52 | Iteration number: [200/565] 35% | Training loss: 0.6902815240621567
Epoch: 52 | Iteration number: [210/565] 37% | Training loss: 0.6901319109258197
Epoch: 52 | Iteration number: [220/565] 38% | Training loss: 0.6899738818407058
Epoch: 52 | Iteration number: [230/565] 40% | Training loss: 0.6898383454136227
Epoch: 52 | Iteration number: [240/565] 42% | Training loss: 0.6896985625227292
Epoch: 52 | Iteration number: [250/565] 44% | Training loss: 0.6895969352722168
Epoch: 52 | Iteration number: [260/565] 46% | Training loss: 0.6894839947040264
Epoch: 52 | Iteration number: [270/565] 47% | Training loss: 0.6893896100697694
Epoch: 52 | Iteration number: [280/565] 49% | Training loss: 0.6893054625817707
Epoch: 52 | Iteration number: [290/565] 51% | Training loss: 0.6892063521105668
Epoch: 52 | Iteration number: [300/565] 53% | Training loss: 0.6891235860188802
Epoch: 52 | Iteration number: [310/565] 54% | Training loss: 0.6890587029918548
Epoch: 52 | Iteration number: [320/565] 56% | Training loss: 0.6889809478074312
Epoch: 52 | Iteration number: [330/565] 58% | Training loss: 0.6889055277362014
Epoch: 52 | Iteration number: [340/565] 60% | Training loss: 0.6888353121631285
Epoch: 52 | Iteration number: [350/565] 61% | Training loss: 0.6887752839497158
Epoch: 52 | Iteration number: [360/565] 63% | Training loss: 0.6887066453695297
Epoch: 52 | Iteration number: [370/565] 65% | Training loss: 0.6886498352965793
Epoch: 52 | Iteration number: [380/565] 67% | Training loss: 0.6885955652124003
Epoch: 52 | Iteration number: [390/565] 69% | Training loss: 0.6885525341217335
Epoch: 52 | Iteration number: [400/565] 70% | Training loss: 0.6885080796480179
Epoch: 52 | Iteration number: [410/565] 72% | Training loss: 0.6884668796527676
Epoch: 52 | Iteration number: [420/565] 74% | Training loss: 0.68843278161117
Epoch: 52 | Iteration number: [430/565] 76% | Training loss: 0.6883960133375123
Epoch: 52 | Iteration number: [440/565] 77% | Training loss: 0.6883556359193542
Epoch: 52 | Iteration number: [450/565] 79% | Training loss: 0.688332308265898
Epoch: 52 | Iteration number: [460/565] 81% | Training loss: 0.6883036766363226
Epoch: 52 | Iteration number: [470/565] 83% | Training loss: 0.688268684579971
Epoch: 52 | Iteration number: [480/565] 84% | Training loss: 0.6882361183563869
Epoch: 52 | Iteration number: [490/565] 86% | Training loss: 0.6882065882488173
Epoch: 52 | Iteration number: [500/565] 88% | Training loss: 0.6881842386722564
Epoch: 52 | Iteration number: [510/565] 90% | Training loss: 0.688162421245201
Epoch: 52 | Iteration number: [520/565] 92% | Training loss: 0.6881356843388997
Epoch: 52 | Iteration number: [530/565] 93% | Training loss: 0.6881096596987742
Epoch: 52 | Iteration number: [540/565] 95% | Training loss: 0.6880813957364471
Epoch: 52 | Iteration number: [550/565] 97% | Training loss: 0.6880517438325015
Epoch: 52 | Iteration number: [560/565] 99% | Training loss: 0.6880301773548126

 End of epoch: 52 | Train Loss: 0.6868062653372773 | Training Time: 91 

 End of epoch: 52 | Eval Loss: 0.6897715500422886 | Evaluating Time: 6 
Epoch: 53 | Iteration number: [10/565] 1% | Training loss: 0.7554460883140564
Epoch: 53 | Iteration number: [20/565] 3% | Training loss: 0.7210285991430283
Epoch: 53 | Iteration number: [30/565] 5% | Training loss: 0.7097016751766205
Epoch: 53 | Iteration number: [40/565] 7% | Training loss: 0.7039456620812417
Epoch: 53 | Iteration number: [50/565] 8% | Training loss: 0.70059255361557
Epoch: 53 | Iteration number: [60/565] 10% | Training loss: 0.6982825696468353
Epoch: 53 | Iteration number: [70/565] 12% | Training loss: 0.6966115304401943
Epoch: 53 | Iteration number: [80/565] 14% | Training loss: 0.6953961171209813
Epoch: 53 | Iteration number: [90/565] 15% | Training loss: 0.6944001754124959
Epoch: 53 | Iteration number: [100/565] 17% | Training loss: 0.6936436522006989
Epoch: 53 | Iteration number: [110/565] 19% | Training loss: 0.6930197802456942
Epoch: 53 | Iteration number: [120/565] 21% | Training loss: 0.6925103068351746
Epoch: 53 | Iteration number: [130/565] 23% | Training loss: 0.6920740012939159
Epoch: 53 | Iteration number: [140/565] 24% | Training loss: 0.6916518867015838
Epoch: 53 | Iteration number: [150/565] 26% | Training loss: 0.6913255635897319
Epoch: 53 | Iteration number: [160/565] 28% | Training loss: 0.6910680398344994
Epoch: 53 | Iteration number: [170/565] 30% | Training loss: 0.6908126294612884
Epoch: 53 | Iteration number: [180/565] 31% | Training loss: 0.6906280520889494
Epoch: 53 | Iteration number: [190/565] 33% | Training loss: 0.6904309018662101
Epoch: 53 | Iteration number: [200/565] 35% | Training loss: 0.6902704071998597
Epoch: 53 | Iteration number: [210/565] 37% | Training loss: 0.6901137723809196
Epoch: 53 | Iteration number: [220/565] 38% | Training loss: 0.6899846342476932
Epoch: 53 | Iteration number: [230/565] 40% | Training loss: 0.6898400394812875
Epoch: 53 | Iteration number: [240/565] 42% | Training loss: 0.6897220447659492
Epoch: 53 | Iteration number: [250/565] 44% | Training loss: 0.689596440076828
Epoch: 53 | Iteration number: [260/565] 46% | Training loss: 0.6894995542672965
Epoch: 53 | Iteration number: [270/565] 47% | Training loss: 0.6894162228813878
Epoch: 53 | Iteration number: [280/565] 49% | Training loss: 0.6893325812050275
Epoch: 53 | Iteration number: [290/565] 51% | Training loss: 0.6892403113430944
Epoch: 53 | Iteration number: [300/565] 53% | Training loss: 0.6891759087642034
Epoch: 53 | Iteration number: [310/565] 54% | Training loss: 0.6890969766724494
Epoch: 53 | Iteration number: [320/565] 56% | Training loss: 0.6890339367091656
Epoch: 53 | Iteration number: [330/565] 58% | Training loss: 0.6889629683711312
Epoch: 53 | Iteration number: [340/565] 60% | Training loss: 0.6888979590990965
Epoch: 53 | Iteration number: [350/565] 61% | Training loss: 0.688826002563749
Epoch: 53 | Iteration number: [360/565] 63% | Training loss: 0.6887578470839395
Epoch: 53 | Iteration number: [370/565] 65% | Training loss: 0.6887112822081591
Epoch: 53 | Iteration number: [380/565] 67% | Training loss: 0.6886604704354938
Epoch: 53 | Iteration number: [390/565] 69% | Training loss: 0.6886201157019689
Epoch: 53 | Iteration number: [400/565] 70% | Training loss: 0.688579843044281
Epoch: 53 | Iteration number: [410/565] 72% | Training loss: 0.6885476057122394
Epoch: 53 | Iteration number: [420/565] 74% | Training loss: 0.6885067938339142
Epoch: 53 | Iteration number: [430/565] 76% | Training loss: 0.6884704962719318
Epoch: 53 | Iteration number: [440/565] 77% | Training loss: 0.6884340245615352
Epoch: 53 | Iteration number: [450/565] 79% | Training loss: 0.6884049733479818
Epoch: 53 | Iteration number: [460/565] 81% | Training loss: 0.6883678188790445
Epoch: 53 | Iteration number: [470/565] 83% | Training loss: 0.6883276259645502
Epoch: 53 | Iteration number: [480/565] 84% | Training loss: 0.6883035304645697
Epoch: 53 | Iteration number: [490/565] 86% | Training loss: 0.6882682417120253
Epoch: 53 | Iteration number: [500/565] 88% | Training loss: 0.6882393764257431
Epoch: 53 | Iteration number: [510/565] 90% | Training loss: 0.6882076429385765
Epoch: 53 | Iteration number: [520/565] 92% | Training loss: 0.6881781810751328
Epoch: 53 | Iteration number: [530/565] 93% | Training loss: 0.6881433454324615
Epoch: 53 | Iteration number: [540/565] 95% | Training loss: 0.6881189350728636
Epoch: 53 | Iteration number: [550/565] 97% | Training loss: 0.6880922307751396
Epoch: 53 | Iteration number: [560/565] 99% | Training loss: 0.6880688818437712

 End of epoch: 53 | Train Loss: 0.6868393059325429 | Training Time: 91 

 End of epoch: 53 | Eval Loss: 0.6898459451539176 | Evaluating Time: 6 
Epoch: 54 | Iteration number: [10/565] 1% | Training loss: 0.755378258228302
Epoch: 54 | Iteration number: [20/565] 3% | Training loss: 0.7209559679031372
Epoch: 54 | Iteration number: [30/565] 5% | Training loss: 0.7095493197441101
Epoch: 54 | Iteration number: [40/565] 7% | Training loss: 0.7039239838719368
Epoch: 54 | Iteration number: [50/565] 8% | Training loss: 0.7005148041248321
Epoch: 54 | Iteration number: [60/565] 10% | Training loss: 0.6982754021883011
Epoch: 54 | Iteration number: [70/565] 12% | Training loss: 0.6965995413916451
Epoch: 54 | Iteration number: [80/565] 14% | Training loss: 0.6953418985009193
Epoch: 54 | Iteration number: [90/565] 15% | Training loss: 0.6943786362806956
Epoch: 54 | Iteration number: [100/565] 17% | Training loss: 0.6936490201950073
Epoch: 54 | Iteration number: [110/565] 19% | Training loss: 0.6930446814407002
Epoch: 54 | Iteration number: [120/565] 21% | Training loss: 0.6924981107314427
Epoch: 54 | Iteration number: [130/565] 23% | Training loss: 0.6920456033486586
Epoch: 54 | Iteration number: [140/565] 24% | Training loss: 0.6916344629866736
Epoch: 54 | Iteration number: [150/565] 26% | Training loss: 0.6912915778160095
Epoch: 54 | Iteration number: [160/565] 28% | Training loss: 0.6910048883408308
Epoch: 54 | Iteration number: [170/565] 30% | Training loss: 0.6907725449870614
Epoch: 54 | Iteration number: [180/565] 31% | Training loss: 0.6905474593242009
Epoch: 54 | Iteration number: [190/565] 33% | Training loss: 0.6903553357249812
Epoch: 54 | Iteration number: [200/565] 35% | Training loss: 0.6901906087994576
Epoch: 54 | Iteration number: [210/565] 37% | Training loss: 0.690044675554548
Epoch: 54 | Iteration number: [220/565] 38% | Training loss: 0.689886164394292
Epoch: 54 | Iteration number: [230/565] 40% | Training loss: 0.6897454059642294
Epoch: 54 | Iteration number: [240/565] 42% | Training loss: 0.6896215215325355
Epoch: 54 | Iteration number: [250/565] 44% | Training loss: 0.6895047595500946
Epoch: 54 | Iteration number: [260/565] 46% | Training loss: 0.6894063642391792
Epoch: 54 | Iteration number: [270/565] 47% | Training loss: 0.6893004494684714
Epoch: 54 | Iteration number: [280/565] 49% | Training loss: 0.6892167972666877
Epoch: 54 | Iteration number: [290/565] 51% | Training loss: 0.6891268257437081
Epoch: 54 | Iteration number: [300/565] 53% | Training loss: 0.6890237164497376
Epoch: 54 | Iteration number: [310/565] 54% | Training loss: 0.688956021493481
Epoch: 54 | Iteration number: [320/565] 56% | Training loss: 0.6888824148103595
Epoch: 54 | Iteration number: [330/565] 58% | Training loss: 0.6888201728011623
Epoch: 54 | Iteration number: [340/565] 60% | Training loss: 0.6887607534142102
Epoch: 54 | Iteration number: [350/565] 61% | Training loss: 0.6887076028755733
Epoch: 54 | Iteration number: [360/565] 63% | Training loss: 0.6886512764626079
Epoch: 54 | Iteration number: [370/565] 65% | Training loss: 0.6886050432114987
Epoch: 54 | Iteration number: [380/565] 67% | Training loss: 0.6885672097143374
Epoch: 54 | Iteration number: [390/565] 69% | Training loss: 0.6885277609030406
Epoch: 54 | Iteration number: [400/565] 70% | Training loss: 0.6884940919280053
Epoch: 54 | Iteration number: [410/565] 72% | Training loss: 0.6884372276503865
Epoch: 54 | Iteration number: [420/565] 74% | Training loss: 0.6884006118490582
Epoch: 54 | Iteration number: [430/565] 76% | Training loss: 0.6883708083352377
Epoch: 54 | Iteration number: [440/565] 77% | Training loss: 0.6883294841105287
Epoch: 54 | Iteration number: [450/565] 79% | Training loss: 0.6883003334204356
Epoch: 54 | Iteration number: [460/565] 81% | Training loss: 0.6882707699485447
Epoch: 54 | Iteration number: [470/565] 83% | Training loss: 0.6882466483623424
Epoch: 54 | Iteration number: [480/565] 84% | Training loss: 0.6882208939641714
Epoch: 54 | Iteration number: [490/565] 86% | Training loss: 0.6881952609334673
Epoch: 54 | Iteration number: [500/565] 88% | Training loss: 0.6881783260107041
Epoch: 54 | Iteration number: [510/565] 90% | Training loss: 0.6881474085882598
Epoch: 54 | Iteration number: [520/565] 92% | Training loss: 0.6881291700097231
Epoch: 54 | Iteration number: [530/565] 93% | Training loss: 0.6881031143215467
Epoch: 54 | Iteration number: [540/565] 95% | Training loss: 0.688085463974211
Epoch: 54 | Iteration number: [550/565] 97% | Training loss: 0.688057334206321
Epoch: 54 | Iteration number: [560/565] 99% | Training loss: 0.6880315102636814

 End of epoch: 54 | Train Loss: 0.6868032100981316 | Training Time: 89 

 End of epoch: 54 | Eval Loss: 0.6895183409963336 | Evaluating Time: 6 
Epoch: 55 | Iteration number: [10/565] 1% | Training loss: 0.7553526759147644
Epoch: 55 | Iteration number: [20/565] 3% | Training loss: 0.7207705497741699
Epoch: 55 | Iteration number: [30/565] 5% | Training loss: 0.709269650777181
Epoch: 55 | Iteration number: [40/565] 7% | Training loss: 0.7036935091018677
Epoch: 55 | Iteration number: [50/565] 8% | Training loss: 0.7003321075439453
Epoch: 55 | Iteration number: [60/565] 10% | Training loss: 0.6981058140595754
Epoch: 55 | Iteration number: [70/565] 12% | Training loss: 0.6965025169508797
Epoch: 55 | Iteration number: [80/565] 14% | Training loss: 0.6953203544020653
Epoch: 55 | Iteration number: [90/565] 15% | Training loss: 0.6943236748377483
Epoch: 55 | Iteration number: [100/565] 17% | Training loss: 0.6935819101333618
Epoch: 55 | Iteration number: [110/565] 19% | Training loss: 0.6929632734168659
Epoch: 55 | Iteration number: [120/565] 21% | Training loss: 0.6924343089262645
Epoch: 55 | Iteration number: [130/565] 23% | Training loss: 0.692019568498318
Epoch: 55 | Iteration number: [140/565] 24% | Training loss: 0.691648627604757
Epoch: 55 | Iteration number: [150/565] 26% | Training loss: 0.6913317414124807
Epoch: 55 | Iteration number: [160/565] 28% | Training loss: 0.6910557851195336
Epoch: 55 | Iteration number: [170/565] 30% | Training loss: 0.6908318530110752
Epoch: 55 | Iteration number: [180/565] 31% | Training loss: 0.6906153109338549
Epoch: 55 | Iteration number: [190/565] 33% | Training loss: 0.690437295248634
Epoch: 55 | Iteration number: [200/565] 35% | Training loss: 0.6902649942040443
Epoch: 55 | Iteration number: [210/565] 37% | Training loss: 0.6901004714625222
Epoch: 55 | Iteration number: [220/565] 38% | Training loss: 0.6899421895092184
Epoch: 55 | Iteration number: [230/565] 40% | Training loss: 0.6898033313129259
Epoch: 55 | Iteration number: [240/565] 42% | Training loss: 0.6896701643864314
Epoch: 55 | Iteration number: [250/565] 44% | Training loss: 0.6895486788749695
Epoch: 55 | Iteration number: [260/565] 46% | Training loss: 0.6894564552949025
Epoch: 55 | Iteration number: [270/565] 47% | Training loss: 0.6893752764772486
Epoch: 55 | Iteration number: [280/565] 49% | Training loss: 0.689292447907584
Epoch: 55 | Iteration number: [290/565] 51% | Training loss: 0.6891947538688266
Epoch: 55 | Iteration number: [300/565] 53% | Training loss: 0.6891014814376831
Epoch: 55 | Iteration number: [310/565] 54% | Training loss: 0.6890210030540344
Epoch: 55 | Iteration number: [320/565] 56% | Training loss: 0.6889500115066767
Epoch: 55 | Iteration number: [330/565] 58% | Training loss: 0.688898201602878
Epoch: 55 | Iteration number: [340/565] 60% | Training loss: 0.6888436496257782
Epoch: 55 | Iteration number: [350/565] 61% | Training loss: 0.6887789000783647
Epoch: 55 | Iteration number: [360/565] 63% | Training loss: 0.6887337712777986
Epoch: 55 | Iteration number: [370/565] 65% | Training loss: 0.6886754640050836
Epoch: 55 | Iteration number: [380/565] 67% | Training loss: 0.6886192566470096
Epoch: 55 | Iteration number: [390/565] 69% | Training loss: 0.6885630832268641
Epoch: 55 | Iteration number: [400/565] 70% | Training loss: 0.6885351011157036
Epoch: 55 | Iteration number: [410/565] 72% | Training loss: 0.6884809556530743
Epoch: 55 | Iteration number: [420/565] 74% | Training loss: 0.6884450229860487
Epoch: 55 | Iteration number: [430/565] 76% | Training loss: 0.688400196474652
Epoch: 55 | Iteration number: [440/565] 77% | Training loss: 0.6883637861772017
Epoch: 55 | Iteration number: [450/565] 79% | Training loss: 0.688317883544498
Epoch: 55 | Iteration number: [460/565] 81% | Training loss: 0.6882790942554888
Epoch: 55 | Iteration number: [470/565] 83% | Training loss: 0.6882505310342667
Epoch: 55 | Iteration number: [480/565] 84% | Training loss: 0.6882256307949622
Epoch: 55 | Iteration number: [490/565] 86% | Training loss: 0.6881973233758186
Epoch: 55 | Iteration number: [500/565] 88% | Training loss: 0.6881776381731033
Epoch: 55 | Iteration number: [510/565] 90% | Training loss: 0.6881468882747724
Epoch: 55 | Iteration number: [520/565] 92% | Training loss: 0.6881138926515212
Epoch: 55 | Iteration number: [530/565] 93% | Training loss: 0.6880952397607407
Epoch: 55 | Iteration number: [540/565] 95% | Training loss: 0.6880757226988121
Epoch: 55 | Iteration number: [550/565] 97% | Training loss: 0.6880486908825961
Epoch: 55 | Iteration number: [560/565] 99% | Training loss: 0.688028440198728

 End of epoch: 55 | Train Loss: 0.6867985654721218 | Training Time: 90 

 End of epoch: 55 | Eval Loss: 0.6889422365597316 | Evaluating Time: 6 
Epoch: 56 | Iteration number: [10/565] 1% | Training loss: 0.7552628934383392
Epoch: 56 | Iteration number: [20/565] 3% | Training loss: 0.7209374070167541
Epoch: 56 | Iteration number: [30/565] 5% | Training loss: 0.7094580829143524
Epoch: 56 | Iteration number: [40/565] 7% | Training loss: 0.7037895932793617
Epoch: 56 | Iteration number: [50/565] 8% | Training loss: 0.7003486394882202
Epoch: 56 | Iteration number: [60/565] 10% | Training loss: 0.6981314341227214
Epoch: 56 | Iteration number: [70/565] 12% | Training loss: 0.696486017533711
Epoch: 56 | Iteration number: [80/565] 14% | Training loss: 0.6952299252152443
Epoch: 56 | Iteration number: [90/565] 15% | Training loss: 0.6942887862523397
Epoch: 56 | Iteration number: [100/565] 17% | Training loss: 0.6935546392202377
Epoch: 56 | Iteration number: [110/565] 19% | Training loss: 0.6928969106890939
Epoch: 56 | Iteration number: [120/565] 21% | Training loss: 0.6923753043015798
Epoch: 56 | Iteration number: [130/565] 23% | Training loss: 0.6919656914014083
Epoch: 56 | Iteration number: [140/565] 24% | Training loss: 0.6915957242250442
Epoch: 56 | Iteration number: [150/565] 26% | Training loss: 0.6912691672643025
Epoch: 56 | Iteration number: [160/565] 28% | Training loss: 0.6910065028816461
Epoch: 56 | Iteration number: [170/565] 30% | Training loss: 0.6907382372547598
Epoch: 56 | Iteration number: [180/565] 31% | Training loss: 0.6905273904403051
Epoch: 56 | Iteration number: [190/565] 33% | Training loss: 0.6903297101196489
Epoch: 56 | Iteration number: [200/565] 35% | Training loss: 0.6901780766248703
Epoch: 56 | Iteration number: [210/565] 37% | Training loss: 0.6900120746521723
Epoch: 56 | Iteration number: [220/565] 38% | Training loss: 0.6898544801907106
Epoch: 56 | Iteration number: [230/565] 40% | Training loss: 0.6897149358106696
Epoch: 56 | Iteration number: [240/565] 42% | Training loss: 0.6895897301534811
Epoch: 56 | Iteration number: [250/565] 44% | Training loss: 0.6894790787696838
Epoch: 56 | Iteration number: [260/565] 46% | Training loss: 0.6893593476368831
Epoch: 56 | Iteration number: [270/565] 47% | Training loss: 0.6892661542804153
Epoch: 56 | Iteration number: [280/565] 49% | Training loss: 0.689174280847822
Epoch: 56 | Iteration number: [290/565] 51% | Training loss: 0.6890922042830238
Epoch: 56 | Iteration number: [300/565] 53% | Training loss: 0.6890348690748215
Epoch: 56 | Iteration number: [310/565] 54% | Training loss: 0.688958445672066
Epoch: 56 | Iteration number: [320/565] 56% | Training loss: 0.6888791143894195
Epoch: 56 | Iteration number: [330/565] 58% | Training loss: 0.6888157819256638
Epoch: 56 | Iteration number: [340/565] 60% | Training loss: 0.6887437901076149
Epoch: 56 | Iteration number: [350/565] 61% | Training loss: 0.6886895961420877
Epoch: 56 | Iteration number: [360/565] 63% | Training loss: 0.6886425781581137
Epoch: 56 | Iteration number: [370/565] 65% | Training loss: 0.6885937497422502
Epoch: 56 | Iteration number: [380/565] 67% | Training loss: 0.6885383502433174
Epoch: 56 | Iteration number: [390/565] 69% | Training loss: 0.6884938394412016
Epoch: 56 | Iteration number: [400/565] 70% | Training loss: 0.688451930731535
Epoch: 56 | Iteration number: [410/565] 72% | Training loss: 0.6884189583906313
Epoch: 56 | Iteration number: [420/565] 74% | Training loss: 0.6883847364357539
Epoch: 56 | Iteration number: [430/565] 76% | Training loss: 0.6883545196333597
Epoch: 56 | Iteration number: [440/565] 77% | Training loss: 0.688314528492364
Epoch: 56 | Iteration number: [450/565] 79% | Training loss: 0.6882862949371338
Epoch: 56 | Iteration number: [460/565] 81% | Training loss: 0.6882506597301234
Epoch: 56 | Iteration number: [470/565] 83% | Training loss: 0.688228011892197
Epoch: 56 | Iteration number: [480/565] 84% | Training loss: 0.688209155574441
Epoch: 56 | Iteration number: [490/565] 86% | Training loss: 0.6881922300981016
Epoch: 56 | Iteration number: [500/565] 88% | Training loss: 0.6881625298261642
Epoch: 56 | Iteration number: [510/565] 90% | Training loss: 0.6881320710275688
Epoch: 56 | Iteration number: [520/565] 92% | Training loss: 0.6881123488912215
Epoch: 56 | Iteration number: [530/565] 93% | Training loss: 0.6880896368116702
Epoch: 56 | Iteration number: [540/565] 95% | Training loss: 0.6880695012984452
Epoch: 56 | Iteration number: [550/565] 97% | Training loss: 0.6880505441535603
Epoch: 56 | Iteration number: [560/565] 99% | Training loss: 0.6880276735339846

 End of epoch: 56 | Train Loss: 0.6868052578605381 | Training Time: 88 

 End of epoch: 56 | Eval Loss: 0.6893958364214215 | Evaluating Time: 6 
Epoch: 57 | Iteration number: [10/565] 1% | Training loss: 0.7555404841899872
Epoch: 57 | Iteration number: [20/565] 3% | Training loss: 0.7211522877216339
Epoch: 57 | Iteration number: [30/565] 5% | Training loss: 0.7099232614040375
Epoch: 57 | Iteration number: [40/565] 7% | Training loss: 0.7041944622993469
Epoch: 57 | Iteration number: [50/565] 8% | Training loss: 0.7007443630695342
Epoch: 57 | Iteration number: [60/565] 10% | Training loss: 0.6984325597683588
Epoch: 57 | Iteration number: [70/565] 12% | Training loss: 0.6967577057225364
Epoch: 57 | Iteration number: [80/565] 14% | Training loss: 0.6954945050179958
Epoch: 57 | Iteration number: [90/565] 15% | Training loss: 0.6945102903578017
Epoch: 57 | Iteration number: [100/565] 17% | Training loss: 0.6936873179674149
Epoch: 57 | Iteration number: [110/565] 19% | Training loss: 0.6930355570533059
Epoch: 57 | Iteration number: [120/565] 21% | Training loss: 0.6925507461031278
Epoch: 57 | Iteration number: [130/565] 23% | Training loss: 0.6921195144836719
Epoch: 57 | Iteration number: [140/565] 24% | Training loss: 0.6917578130960464
Epoch: 57 | Iteration number: [150/565] 26% | Training loss: 0.6914572974046072
Epoch: 57 | Iteration number: [160/565] 28% | Training loss: 0.6911712873727083
Epoch: 57 | Iteration number: [170/565] 30% | Training loss: 0.6909213402692009
Epoch: 57 | Iteration number: [180/565] 31% | Training loss: 0.6907066577010684
Epoch: 57 | Iteration number: [190/565] 33% | Training loss: 0.6904773279240257
Epoch: 57 | Iteration number: [200/565] 35% | Training loss: 0.6903043988347054
Epoch: 57 | Iteration number: [210/565] 37% | Training loss: 0.6901240916479201
Epoch: 57 | Iteration number: [220/565] 38% | Training loss: 0.6899748967452483
Epoch: 57 | Iteration number: [230/565] 40% | Training loss: 0.689843374490738
Epoch: 57 | Iteration number: [240/565] 42% | Training loss: 0.6897044616440932
Epoch: 57 | Iteration number: [250/565] 44% | Training loss: 0.6895805490016937
Epoch: 57 | Iteration number: [260/565] 46% | Training loss: 0.6894903146303617
Epoch: 57 | Iteration number: [270/565] 47% | Training loss: 0.6893962407553638
Epoch: 57 | Iteration number: [280/565] 49% | Training loss: 0.6892987868615559
Epoch: 57 | Iteration number: [290/565] 51% | Training loss: 0.6892111367192761
Epoch: 57 | Iteration number: [300/565] 53% | Training loss: 0.6891341427961986
Epoch: 57 | Iteration number: [310/565] 54% | Training loss: 0.6890631625729222
Epoch: 57 | Iteration number: [320/565] 56% | Training loss: 0.6889857161790133
Epoch: 57 | Iteration number: [330/565] 58% | Training loss: 0.6889228777451949
Epoch: 57 | Iteration number: [340/565] 60% | Training loss: 0.6888579098617329
Epoch: 57 | Iteration number: [350/565] 61% | Training loss: 0.6887977514948164
Epoch: 57 | Iteration number: [360/565] 63% | Training loss: 0.688755687740114
Epoch: 57 | Iteration number: [370/565] 65% | Training loss: 0.6886996675182033
Epoch: 57 | Iteration number: [380/565] 67% | Training loss: 0.6886436743171591
Epoch: 57 | Iteration number: [390/565] 69% | Training loss: 0.6885886644705748
Epoch: 57 | Iteration number: [400/565] 70% | Training loss: 0.6885360069572926
Epoch: 57 | Iteration number: [410/565] 72% | Training loss: 0.688489330687174
Epoch: 57 | Iteration number: [420/565] 74% | Training loss: 0.6884472625596183
Epoch: 57 | Iteration number: [430/565] 76% | Training loss: 0.688407335863557
Epoch: 57 | Iteration number: [440/565] 77% | Training loss: 0.6883681451732462
Epoch: 57 | Iteration number: [450/565] 79% | Training loss: 0.6883323582013449
Epoch: 57 | Iteration number: [460/565] 81% | Training loss: 0.688302924969922
Epoch: 57 | Iteration number: [470/565] 83% | Training loss: 0.6882666364629217
Epoch: 57 | Iteration number: [480/565] 84% | Training loss: 0.6882357624669869
Epoch: 57 | Iteration number: [490/565] 86% | Training loss: 0.6882094210507919
Epoch: 57 | Iteration number: [500/565] 88% | Training loss: 0.688184796333313
Epoch: 57 | Iteration number: [510/565] 90% | Training loss: 0.6881694119350583
Epoch: 57 | Iteration number: [520/565] 92% | Training loss: 0.6881443013365452
Epoch: 57 | Iteration number: [530/565] 93% | Training loss: 0.6881171013949052
Epoch: 57 | Iteration number: [540/565] 95% | Training loss: 0.6880875551038318
Epoch: 57 | Iteration number: [550/565] 97% | Training loss: 0.6880634417317131
Epoch: 57 | Iteration number: [560/565] 99% | Training loss: 0.6880448837365423

 End of epoch: 57 | Train Loss: 0.6868141551988315 | Training Time: 90 

 End of epoch: 57 | Eval Loss: 0.6899611864771161 | Evaluating Time: 6 
Epoch: 58 | Iteration number: [10/565] 1% | Training loss: 0.7557027280330658
Epoch: 58 | Iteration number: [20/565] 3% | Training loss: 0.721285393834114
Epoch: 58 | Iteration number: [30/565] 5% | Training loss: 0.7098037441571553
Epoch: 58 | Iteration number: [40/565] 7% | Training loss: 0.7041714668273926
Epoch: 58 | Iteration number: [50/565] 8% | Training loss: 0.7007123219966889
Epoch: 58 | Iteration number: [60/565] 10% | Training loss: 0.6984070738156637
Epoch: 58 | Iteration number: [70/565] 12% | Training loss: 0.6967510265963418
Epoch: 58 | Iteration number: [80/565] 14% | Training loss: 0.6955269478261471
Epoch: 58 | Iteration number: [90/565] 15% | Training loss: 0.694564155737559
Epoch: 58 | Iteration number: [100/565] 17% | Training loss: 0.6938175076246261
Epoch: 58 | Iteration number: [110/565] 19% | Training loss: 0.6931290236386386
Epoch: 58 | Iteration number: [120/565] 21% | Training loss: 0.692621619005998
Epoch: 58 | Iteration number: [130/565] 23% | Training loss: 0.6921798696884742
Epoch: 58 | Iteration number: [140/565] 24% | Training loss: 0.6917881625039237
Epoch: 58 | Iteration number: [150/565] 26% | Training loss: 0.691429961125056
Epoch: 58 | Iteration number: [160/565] 28% | Training loss: 0.6911253124475479
Epoch: 58 | Iteration number: [170/565] 30% | Training loss: 0.6908525288105011
Epoch: 58 | Iteration number: [180/565] 31% | Training loss: 0.6906076557106442
Epoch: 58 | Iteration number: [190/565] 33% | Training loss: 0.6904147163817757
Epoch: 58 | Iteration number: [200/565] 35% | Training loss: 0.6902380365133286
Epoch: 58 | Iteration number: [210/565] 37% | Training loss: 0.6900833833785284
Epoch: 58 | Iteration number: [220/565] 38% | Training loss: 0.6899395154281096
Epoch: 58 | Iteration number: [230/565] 40% | Training loss: 0.6897917345814083
Epoch: 58 | Iteration number: [240/565] 42% | Training loss: 0.6896833879252274
Epoch: 58 | Iteration number: [250/565] 44% | Training loss: 0.6895578784942626
Epoch: 58 | Iteration number: [260/565] 46% | Training loss: 0.6894454142222037
Epoch: 58 | Iteration number: [270/565] 47% | Training loss: 0.6893251299858093
Epoch: 58 | Iteration number: [280/565] 49% | Training loss: 0.6892263325197356
Epoch: 58 | Iteration number: [290/565] 51% | Training loss: 0.6891336660960625
Epoch: 58 | Iteration number: [300/565] 53% | Training loss: 0.689039490421613
Epoch: 58 | Iteration number: [310/565] 54% | Training loss: 0.6889816786012342
Epoch: 58 | Iteration number: [320/565] 56% | Training loss: 0.6889264089986682
Epoch: 58 | Iteration number: [330/565] 58% | Training loss: 0.6888601093581228
Epoch: 58 | Iteration number: [340/565] 60% | Training loss: 0.6887864750974318
Epoch: 58 | Iteration number: [350/565] 61% | Training loss: 0.6887355249268668
Epoch: 58 | Iteration number: [360/565] 63% | Training loss: 0.6886828151014116
Epoch: 58 | Iteration number: [370/565] 65% | Training loss: 0.6886217199467324
Epoch: 58 | Iteration number: [380/565] 67% | Training loss: 0.6885633404317655
Epoch: 58 | Iteration number: [390/565] 69% | Training loss: 0.6885155179561713
Epoch: 58 | Iteration number: [400/565] 70% | Training loss: 0.6884795472025871
Epoch: 58 | Iteration number: [410/565] 72% | Training loss: 0.6884398852906576
Epoch: 58 | Iteration number: [420/565] 74% | Training loss: 0.6884025846208844
Epoch: 58 | Iteration number: [430/565] 76% | Training loss: 0.6883771901906923
Epoch: 58 | Iteration number: [440/565] 77% | Training loss: 0.688341986997561
Epoch: 58 | Iteration number: [450/565] 79% | Training loss: 0.6883136399586995
Epoch: 58 | Iteration number: [460/565] 81% | Training loss: 0.6882747480402822
Epoch: 58 | Iteration number: [470/565] 83% | Training loss: 0.6882356336776246
Epoch: 58 | Iteration number: [480/565] 84% | Training loss: 0.6882161835829417
Epoch: 58 | Iteration number: [490/565] 86% | Training loss: 0.6881923608633936
Epoch: 58 | Iteration number: [500/565] 88% | Training loss: 0.6881690217256546
Epoch: 58 | Iteration number: [510/565] 90% | Training loss: 0.6881432451453864
Epoch: 58 | Iteration number: [520/565] 92% | Training loss: 0.6881193001682941
Epoch: 58 | Iteration number: [530/565] 93% | Training loss: 0.6880919818608267
Epoch: 58 | Iteration number: [540/565] 95% | Training loss: 0.6880708547653975
Epoch: 58 | Iteration number: [550/565] 97% | Training loss: 0.6880570820244876
Epoch: 58 | Iteration number: [560/565] 99% | Training loss: 0.6880271079284804

 End of epoch: 58 | Train Loss: 0.6868063301111744 | Training Time: 90 

 End of epoch: 58 | Eval Loss: 0.6898203832762582 | Evaluating Time: 5 
Epoch: 59 | Iteration number: [10/565] 1% | Training loss: 0.7552478969097137
Epoch: 59 | Iteration number: [20/565] 3% | Training loss: 0.7210517913103104
Epoch: 59 | Iteration number: [30/565] 5% | Training loss: 0.709577473004659
Epoch: 59 | Iteration number: [40/565] 7% | Training loss: 0.7039567038416863
Epoch: 59 | Iteration number: [50/565] 8% | Training loss: 0.7005416917800903
Epoch: 59 | Iteration number: [60/565] 10% | Training loss: 0.6982810566822688
Epoch: 59 | Iteration number: [70/565] 12% | Training loss: 0.6966681752886091
Epoch: 59 | Iteration number: [80/565] 14% | Training loss: 0.6954566322267055
Epoch: 59 | Iteration number: [90/565] 15% | Training loss: 0.6944977707333035
Epoch: 59 | Iteration number: [100/565] 17% | Training loss: 0.6937034839391708
Epoch: 59 | Iteration number: [110/565] 19% | Training loss: 0.6930578882044012
Epoch: 59 | Iteration number: [120/565] 21% | Training loss: 0.692510220905145
Epoch: 59 | Iteration number: [130/565] 23% | Training loss: 0.6920744176094349
Epoch: 59 | Iteration number: [140/565] 24% | Training loss: 0.691666750397001
Epoch: 59 | Iteration number: [150/565] 26% | Training loss: 0.6913539715607961
Epoch: 59 | Iteration number: [160/565] 28% | Training loss: 0.6910545695573092
Epoch: 59 | Iteration number: [170/565] 30% | Training loss: 0.6907985210418701
Epoch: 59 | Iteration number: [180/565] 31% | Training loss: 0.6906035582224528
Epoch: 59 | Iteration number: [190/565] 33% | Training loss: 0.6903942550483503
Epoch: 59 | Iteration number: [200/565] 35% | Training loss: 0.6902210095524788
Epoch: 59 | Iteration number: [210/565] 37% | Training loss: 0.6900717247100103
Epoch: 59 | Iteration number: [220/565] 38% | Training loss: 0.6899054521864111
Epoch: 59 | Iteration number: [230/565] 40% | Training loss: 0.6897638885871223
Epoch: 59 | Iteration number: [240/565] 42% | Training loss: 0.6896465664108594
Epoch: 59 | Iteration number: [250/565] 44% | Training loss: 0.689534108877182
Epoch: 59 | Iteration number: [260/565] 46% | Training loss: 0.6894353816142449
Epoch: 59 | Iteration number: [270/565] 47% | Training loss: 0.6893337307152925
Epoch: 59 | Iteration number: [280/565] 49% | Training loss: 0.6892457725746292
Epoch: 59 | Iteration number: [290/565] 51% | Training loss: 0.6891606795376745
Epoch: 59 | Iteration number: [300/565] 53% | Training loss: 0.6890887186924617
Epoch: 59 | Iteration number: [310/565] 54% | Training loss: 0.6890120702405129
Epoch: 59 | Iteration number: [320/565] 56% | Training loss: 0.688942439854145
Epoch: 59 | Iteration number: [330/565] 58% | Training loss: 0.6888753141417648
Epoch: 59 | Iteration number: [340/565] 60% | Training loss: 0.6888115893392002
Epoch: 59 | Iteration number: [350/565] 61% | Training loss: 0.6887565420355115
Epoch: 59 | Iteration number: [360/565] 63% | Training loss: 0.6887071965469255
Epoch: 59 | Iteration number: [370/565] 65% | Training loss: 0.6886473821627127
Epoch: 59 | Iteration number: [380/565] 67% | Training loss: 0.6885890805407574
Epoch: 59 | Iteration number: [390/565] 69% | Training loss: 0.688545285891264
Epoch: 59 | Iteration number: [400/565] 70% | Training loss: 0.6885047593712806
Epoch: 59 | Iteration number: [410/565] 72% | Training loss: 0.6884607778816688
Epoch: 59 | Iteration number: [420/565] 74% | Training loss: 0.6884115335487184
Epoch: 59 | Iteration number: [430/565] 76% | Training loss: 0.6883694262005562
Epoch: 59 | Iteration number: [440/565] 77% | Training loss: 0.6883316867730834
Epoch: 59 | Iteration number: [450/565] 79% | Training loss: 0.6883013698789808
Epoch: 59 | Iteration number: [460/565] 81% | Training loss: 0.6882718275422636
Epoch: 59 | Iteration number: [470/565] 83% | Training loss: 0.6882452897568967
Epoch: 59 | Iteration number: [480/565] 84% | Training loss: 0.6882100775837898
Epoch: 59 | Iteration number: [490/565] 86% | Training loss: 0.6881892484061573
Epoch: 59 | Iteration number: [500/565] 88% | Training loss: 0.6881617062091827
Epoch: 59 | Iteration number: [510/565] 90% | Training loss: 0.6881457552021625
Epoch: 59 | Iteration number: [520/565] 92% | Training loss: 0.6881155631863154
Epoch: 59 | Iteration number: [530/565] 93% | Training loss: 0.6880904761125457
Epoch: 59 | Iteration number: [540/565] 95% | Training loss: 0.6880685999437615
Epoch: 59 | Iteration number: [550/565] 97% | Training loss: 0.6880552690679377
Epoch: 59 | Iteration number: [560/565] 99% | Training loss: 0.688018300384283

 End of epoch: 59 | Train Loss: 0.6867923327251874 | Training Time: 89 

 End of epoch: 59 | Eval Loss: 0.6895766513688224 | Evaluating Time: 6 
Epoch: 60 | Iteration number: [10/565] 1% | Training loss: 0.7557912111282349
Epoch: 60 | Iteration number: [20/565] 3% | Training loss: 0.7212650001049041
Epoch: 60 | Iteration number: [30/565] 5% | Training loss: 0.709749948978424
Epoch: 60 | Iteration number: [40/565] 7% | Training loss: 0.7040513888001442
Epoch: 60 | Iteration number: [50/565] 8% | Training loss: 0.7004885184764862
Epoch: 60 | Iteration number: [60/565] 10% | Training loss: 0.6982597539822261
Epoch: 60 | Iteration number: [70/565] 12% | Training loss: 0.6965914666652679
Epoch: 60 | Iteration number: [80/565] 14% | Training loss: 0.6953688010573387
Epoch: 60 | Iteration number: [90/565] 15% | Training loss: 0.6944168455070919
Epoch: 60 | Iteration number: [100/565] 17% | Training loss: 0.6936046653985977
Epoch: 60 | Iteration number: [110/565] 19% | Training loss: 0.6930148260159926
Epoch: 60 | Iteration number: [120/565] 21% | Training loss: 0.6924812371532122
Epoch: 60 | Iteration number: [130/565] 23% | Training loss: 0.6920787375706893
Epoch: 60 | Iteration number: [140/565] 24% | Training loss: 0.6916715345212392
Epoch: 60 | Iteration number: [150/565] 26% | Training loss: 0.6913316345214844
Epoch: 60 | Iteration number: [160/565] 28% | Training loss: 0.6910684622824192
Epoch: 60 | Iteration number: [170/565] 30% | Training loss: 0.6908257947248571
Epoch: 60 | Iteration number: [180/565] 31% | Training loss: 0.6905992892053392
Epoch: 60 | Iteration number: [190/565] 33% | Training loss: 0.6904096412031274
Epoch: 60 | Iteration number: [200/565] 35% | Training loss: 0.6902188718318939
Epoch: 60 | Iteration number: [210/565] 37% | Training loss: 0.6900599871362959
Epoch: 60 | Iteration number: [220/565] 38% | Training loss: 0.689913242242553
Epoch: 60 | Iteration number: [230/565] 40% | Training loss: 0.6897692955058554
Epoch: 60 | Iteration number: [240/565] 42% | Training loss: 0.6896427904566129
Epoch: 60 | Iteration number: [250/565] 44% | Training loss: 0.6895438027381897
Epoch: 60 | Iteration number: [260/565] 46% | Training loss: 0.6894281758711889
Epoch: 60 | Iteration number: [270/565] 47% | Training loss: 0.6893179348221532
Epoch: 60 | Iteration number: [280/565] 49% | Training loss: 0.6892328856246812
Epoch: 60 | Iteration number: [290/565] 51% | Training loss: 0.6891535189645044
Epoch: 60 | Iteration number: [300/565] 53% | Training loss: 0.6890763666232427
Epoch: 60 | Iteration number: [310/565] 54% | Training loss: 0.6889829108791966
Epoch: 60 | Iteration number: [320/565] 56% | Training loss: 0.6889122137799859
Epoch: 60 | Iteration number: [330/565] 58% | Training loss: 0.688845958854213
Epoch: 60 | Iteration number: [340/565] 60% | Training loss: 0.6887924215372871
Epoch: 60 | Iteration number: [350/565] 61% | Training loss: 0.6887253318514143
Epoch: 60 | Iteration number: [360/565] 63% | Training loss: 0.6886799054013358
Epoch: 60 | Iteration number: [370/565] 65% | Training loss: 0.6886405973821073
Epoch: 60 | Iteration number: [380/565] 67% | Training loss: 0.6885958809601633
Epoch: 60 | Iteration number: [390/565] 69% | Training loss: 0.6885472216667273
Epoch: 60 | Iteration number: [400/565] 70% | Training loss: 0.6884996709227562
Epoch: 60 | Iteration number: [410/565] 72% | Training loss: 0.6884630714974752
Epoch: 60 | Iteration number: [420/565] 74% | Training loss: 0.6884235941228413
Epoch: 60 | Iteration number: [430/565] 76% | Training loss: 0.6883898102959921
Epoch: 60 | Iteration number: [440/565] 77% | Training loss: 0.6883500385013493
Epoch: 60 | Iteration number: [450/565] 79% | Training loss: 0.6883160660001967
Epoch: 60 | Iteration number: [460/565] 81% | Training loss: 0.6882934523665387
Epoch: 60 | Iteration number: [470/565] 83% | Training loss: 0.6882665738146356
Epoch: 60 | Iteration number: [480/565] 84% | Training loss: 0.6882463751981656
Epoch: 60 | Iteration number: [490/565] 86% | Training loss: 0.6882175607340676
Epoch: 60 | Iteration number: [500/565] 88% | Training loss: 0.6881855101585388
Epoch: 60 | Iteration number: [510/565] 90% | Training loss: 0.6881531199988197
Epoch: 60 | Iteration number: [520/565] 92% | Training loss: 0.6881244505827243
Epoch: 60 | Iteration number: [530/565] 93% | Training loss: 0.68809769367272
Epoch: 60 | Iteration number: [540/565] 95% | Training loss: 0.688082570610223
Epoch: 60 | Iteration number: [550/565] 97% | Training loss: 0.6880538681420413
Epoch: 60 | Iteration number: [560/565] 99% | Training loss: 0.6880319663456508

 End of epoch: 60 | Train Loss: 0.68680665440264 | Training Time: 88 

 End of epoch: 60 | Eval Loss: 0.6900724002293178 | Evaluating Time: 6 
Epoch: 61 | Iteration number: [10/565] 1% | Training loss: 0.7556297183036804
Epoch: 61 | Iteration number: [20/565] 3% | Training loss: 0.7211894243955612
Epoch: 61 | Iteration number: [30/565] 5% | Training loss: 0.7097054600715638
Epoch: 61 | Iteration number: [40/565] 7% | Training loss: 0.7040823444724083
Epoch: 61 | Iteration number: [50/565] 8% | Training loss: 0.7005972719192505
Epoch: 61 | Iteration number: [60/565] 10% | Training loss: 0.6982942601044972
Epoch: 61 | Iteration number: [70/565] 12% | Training loss: 0.696681272983551
Epoch: 61 | Iteration number: [80/565] 14% | Training loss: 0.6954870514571667
Epoch: 61 | Iteration number: [90/565] 15% | Training loss: 0.6944649822182125
Epoch: 61 | Iteration number: [100/565] 17% | Training loss: 0.6936454963684082
Epoch: 61 | Iteration number: [110/565] 19% | Training loss: 0.69302793470296
Epoch: 61 | Iteration number: [120/565] 21% | Training loss: 0.6924779643615087
Epoch: 61 | Iteration number: [130/565] 23% | Training loss: 0.692075967330199
Epoch: 61 | Iteration number: [140/565] 24% | Training loss: 0.691668963432312
Epoch: 61 | Iteration number: [150/565] 26% | Training loss: 0.6913610378901164
Epoch: 61 | Iteration number: [160/565] 28% | Training loss: 0.6910639595240354
Epoch: 61 | Iteration number: [170/565] 30% | Training loss: 0.6908430597361397
Epoch: 61 | Iteration number: [180/565] 31% | Training loss: 0.6906207803222868
Epoch: 61 | Iteration number: [190/565] 33% | Training loss: 0.6904502401226446
Epoch: 61 | Iteration number: [200/565] 35% | Training loss: 0.6902457877993584
Epoch: 61 | Iteration number: [210/565] 37% | Training loss: 0.6900973558425904
Epoch: 61 | Iteration number: [220/565] 38% | Training loss: 0.689946836233139
Epoch: 61 | Iteration number: [230/565] 40% | Training loss: 0.6898201981316442
Epoch: 61 | Iteration number: [240/565] 42% | Training loss: 0.6896978760759036
Epoch: 61 | Iteration number: [250/565] 44% | Training loss: 0.6895706593990326
Epoch: 61 | Iteration number: [260/565] 46% | Training loss: 0.689476229594304
Epoch: 61 | Iteration number: [270/565] 47% | Training loss: 0.6893805437617831
Epoch: 61 | Iteration number: [280/565] 49% | Training loss: 0.6892871371337346
Epoch: 61 | Iteration number: [290/565] 51% | Training loss: 0.6891993382881427
Epoch: 61 | Iteration number: [300/565] 53% | Training loss: 0.6891202145814895
Epoch: 61 | Iteration number: [310/565] 54% | Training loss: 0.6890336167427802
Epoch: 61 | Iteration number: [320/565] 56% | Training loss: 0.6889609098434448
Epoch: 61 | Iteration number: [330/565] 58% | Training loss: 0.6889058002919862
Epoch: 61 | Iteration number: [340/565] 60% | Training loss: 0.6888462171835058
Epoch: 61 | Iteration number: [350/565] 61% | Training loss: 0.6887860936777932
Epoch: 61 | Iteration number: [360/565] 63% | Training loss: 0.6887350055906508
Epoch: 61 | Iteration number: [370/565] 65% | Training loss: 0.6886673938583683
Epoch: 61 | Iteration number: [380/565] 67% | Training loss: 0.6886127111158873
Epoch: 61 | Iteration number: [390/565] 69% | Training loss: 0.6885580156093989
Epoch: 61 | Iteration number: [400/565] 70% | Training loss: 0.6885117182135582
Epoch: 61 | Iteration number: [410/565] 72% | Training loss: 0.6884741383354839
Epoch: 61 | Iteration number: [420/565] 74% | Training loss: 0.6884341977891468
Epoch: 61 | Iteration number: [430/565] 76% | Training loss: 0.6883947185305662
Epoch: 61 | Iteration number: [440/565] 77% | Training loss: 0.6883515722372315
Epoch: 61 | Iteration number: [450/565] 79% | Training loss: 0.6883080179161496
Epoch: 61 | Iteration number: [460/565] 81% | Training loss: 0.6882749690957691
Epoch: 61 | Iteration number: [470/565] 83% | Training loss: 0.6882432169102608
Epoch: 61 | Iteration number: [480/565] 84% | Training loss: 0.6882128780086835
Epoch: 61 | Iteration number: [490/565] 86% | Training loss: 0.6881896240370614
Epoch: 61 | Iteration number: [500/565] 88% | Training loss: 0.6881664420366287
Epoch: 61 | Iteration number: [510/565] 90% | Training loss: 0.688138888279597
Epoch: 61 | Iteration number: [520/565] 92% | Training loss: 0.6881076073417297
Epoch: 61 | Iteration number: [530/565] 93% | Training loss: 0.6880817800197961
Epoch: 61 | Iteration number: [540/565] 95% | Training loss: 0.6880575884271551
Epoch: 61 | Iteration number: [550/565] 97% | Training loss: 0.6880342561548406
Epoch: 61 | Iteration number: [560/565] 99% | Training loss: 0.6880198904446193

 End of epoch: 61 | Train Loss: 0.6867906368939223 | Training Time: 88 

 End of epoch: 61 | Eval Loss: 0.6892144339425224 | Evaluating Time: 5 
Epoch: 62 | Iteration number: [10/565] 1% | Training loss: 0.7551520884037017
Epoch: 62 | Iteration number: [20/565] 3% | Training loss: 0.7210378795862198
Epoch: 62 | Iteration number: [30/565] 5% | Training loss: 0.7096361815929413
Epoch: 62 | Iteration number: [40/565] 7% | Training loss: 0.7039667889475822
Epoch: 62 | Iteration number: [50/565] 8% | Training loss: 0.7004458796977997
Epoch: 62 | Iteration number: [60/565] 10% | Training loss: 0.6982176770766576
Epoch: 62 | Iteration number: [70/565] 12% | Training loss: 0.696621013539178
Epoch: 62 | Iteration number: [80/565] 14% | Training loss: 0.6953965879976749
Epoch: 62 | Iteration number: [90/565] 15% | Training loss: 0.6944637245602078
Epoch: 62 | Iteration number: [100/565] 17% | Training loss: 0.6936862027645111
Epoch: 62 | Iteration number: [110/565] 19% | Training loss: 0.6930463037707589
Epoch: 62 | Iteration number: [120/565] 21% | Training loss: 0.6925247296690941
Epoch: 62 | Iteration number: [130/565] 23% | Training loss: 0.6920638547493861
Epoch: 62 | Iteration number: [140/565] 24% | Training loss: 0.6916731727974755
Epoch: 62 | Iteration number: [150/565] 26% | Training loss: 0.6913243214289347
Epoch: 62 | Iteration number: [160/565] 28% | Training loss: 0.691026371344924
Epoch: 62 | Iteration number: [170/565] 30% | Training loss: 0.6907778424375197
Epoch: 62 | Iteration number: [180/565] 31% | Training loss: 0.690559948152966
Epoch: 62 | Iteration number: [190/565] 33% | Training loss: 0.6903607337098373
Epoch: 62 | Iteration number: [200/565] 35% | Training loss: 0.6902025532722473
Epoch: 62 | Iteration number: [210/565] 37% | Training loss: 0.6900413933254423
Epoch: 62 | Iteration number: [220/565] 38% | Training loss: 0.6898948146538301
Epoch: 62 | Iteration number: [230/565] 40% | Training loss: 0.6897716706213743
Epoch: 62 | Iteration number: [240/565] 42% | Training loss: 0.689641993244489
Epoch: 62 | Iteration number: [250/565] 44% | Training loss: 0.6895386271476746
Epoch: 62 | Iteration number: [260/565] 46% | Training loss: 0.6894511014223099
Epoch: 62 | Iteration number: [270/565] 47% | Training loss: 0.6893276740003516
Epoch: 62 | Iteration number: [280/565] 49% | Training loss: 0.6892501579863685
Epoch: 62 | Iteration number: [290/565] 51% | Training loss: 0.6891487549091208
Epoch: 62 | Iteration number: [300/565] 53% | Training loss: 0.6890802959601084
Epoch: 62 | Iteration number: [310/565] 54% | Training loss: 0.689012344614152
Epoch: 62 | Iteration number: [320/565] 56% | Training loss: 0.688944892771542
Epoch: 62 | Iteration number: [330/565] 58% | Training loss: 0.6888755108370925
Epoch: 62 | Iteration number: [340/565] 60% | Training loss: 0.6888047640814501
Epoch: 62 | Iteration number: [350/565] 61% | Training loss: 0.6887478249413627
Epoch: 62 | Iteration number: [360/565] 63% | Training loss: 0.6886852772699462
Epoch: 62 | Iteration number: [370/565] 65% | Training loss: 0.6886331798257055
Epoch: 62 | Iteration number: [380/565] 67% | Training loss: 0.6885937508783843
Epoch: 62 | Iteration number: [390/565] 69% | Training loss: 0.6885598185734871
Epoch: 62 | Iteration number: [400/565] 70% | Training loss: 0.6885125188529492
Epoch: 62 | Iteration number: [410/565] 72% | Training loss: 0.6884756144953937
Epoch: 62 | Iteration number: [420/565] 74% | Training loss: 0.6884348955892381
Epoch: 62 | Iteration number: [430/565] 76% | Training loss: 0.6883947676004365
Epoch: 62 | Iteration number: [440/565] 77% | Training loss: 0.6883437672799284
Epoch: 62 | Iteration number: [450/565] 79% | Training loss: 0.6883091006014083
Epoch: 62 | Iteration number: [460/565] 81% | Training loss: 0.6882903562939685
Epoch: 62 | Iteration number: [470/565] 83% | Training loss: 0.6882619157750556
Epoch: 62 | Iteration number: [480/565] 84% | Training loss: 0.6882310866067807
Epoch: 62 | Iteration number: [490/565] 86% | Training loss: 0.6881959025957146
Epoch: 62 | Iteration number: [500/565] 88% | Training loss: 0.6881557421684266
Epoch: 62 | Iteration number: [510/565] 90% | Training loss: 0.6881253761403701
Epoch: 62 | Iteration number: [520/565] 92% | Training loss: 0.6881012033957702
Epoch: 62 | Iteration number: [530/565] 93% | Training loss: 0.6880716458806452
Epoch: 62 | Iteration number: [540/565] 95% | Training loss: 0.6880576796001858
Epoch: 62 | Iteration number: [550/565] 97% | Training loss: 0.6880344715985385
Epoch: 62 | Iteration number: [560/565] 99% | Training loss: 0.6880124899957861

 End of epoch: 62 | Train Loss: 0.686788647681211 | Training Time: 88 

 End of epoch: 62 | Eval Loss: 0.6897545116288322 | Evaluating Time: 6 
Epoch: 63 | Iteration number: [10/565] 1% | Training loss: 0.7553667247295379
Epoch: 63 | Iteration number: [20/565] 3% | Training loss: 0.7209617763757705
Epoch: 63 | Iteration number: [30/565] 5% | Training loss: 0.709498929977417
Epoch: 63 | Iteration number: [40/565] 7% | Training loss: 0.7038677513599396
Epoch: 63 | Iteration number: [50/565] 8% | Training loss: 0.7005378532409668
Epoch: 63 | Iteration number: [60/565] 10% | Training loss: 0.6982159276803335
Epoch: 63 | Iteration number: [70/565] 12% | Training loss: 0.6966029925005777
Epoch: 63 | Iteration number: [80/565] 14% | Training loss: 0.6953335888683796
Epoch: 63 | Iteration number: [90/565] 15% | Training loss: 0.694393781820933
Epoch: 63 | Iteration number: [100/565] 17% | Training loss: 0.6937160754203796
Epoch: 63 | Iteration number: [110/565] 19% | Training loss: 0.6930637045340104
Epoch: 63 | Iteration number: [120/565] 21% | Training loss: 0.6925399750471115
Epoch: 63 | Iteration number: [130/565] 23% | Training loss: 0.6920909968706278
Epoch: 63 | Iteration number: [140/565] 24% | Training loss: 0.6917084004197802
Epoch: 63 | Iteration number: [150/565] 26% | Training loss: 0.6913713284333547
Epoch: 63 | Iteration number: [160/565] 28% | Training loss: 0.6910581722855568
Epoch: 63 | Iteration number: [170/565] 30% | Training loss: 0.6907960334244896
Epoch: 63 | Iteration number: [180/565] 31% | Training loss: 0.6905987319019106
Epoch: 63 | Iteration number: [190/565] 33% | Training loss: 0.6903851788294942
Epoch: 63 | Iteration number: [200/565] 35% | Training loss: 0.6902161040902137
Epoch: 63 | Iteration number: [210/565] 37% | Training loss: 0.6900504994960058
Epoch: 63 | Iteration number: [220/565] 38% | Training loss: 0.6898708665912802
Epoch: 63 | Iteration number: [230/565] 40% | Training loss: 0.689727193635443
Epoch: 63 | Iteration number: [240/565] 42% | Training loss: 0.6896138722697894
Epoch: 63 | Iteration number: [250/565] 44% | Training loss: 0.6894920737743377
Epoch: 63 | Iteration number: [260/565] 46% | Training loss: 0.6893837960866781
Epoch: 63 | Iteration number: [270/565] 47% | Training loss: 0.6892877159295259
Epoch: 63 | Iteration number: [280/565] 49% | Training loss: 0.6891977608203887
Epoch: 63 | Iteration number: [290/565] 51% | Training loss: 0.6891115457847201
Epoch: 63 | Iteration number: [300/565] 53% | Training loss: 0.6890261413653692
Epoch: 63 | Iteration number: [310/565] 54% | Training loss: 0.688953104903621
Epoch: 63 | Iteration number: [320/565] 56% | Training loss: 0.6888911416754127
Epoch: 63 | Iteration number: [330/565] 58% | Training loss: 0.6888243761929599
Epoch: 63 | Iteration number: [340/565] 60% | Training loss: 0.6887557227821911
Epoch: 63 | Iteration number: [350/565] 61% | Training loss: 0.6887093268121992
Epoch: 63 | Iteration number: [360/565] 63% | Training loss: 0.6886629207266701
Epoch: 63 | Iteration number: [370/565] 65% | Training loss: 0.6886136303076873
Epoch: 63 | Iteration number: [380/565] 67% | Training loss: 0.6885611498042157
Epoch: 63 | Iteration number: [390/565] 69% | Training loss: 0.6885191318316337
Epoch: 63 | Iteration number: [400/565] 70% | Training loss: 0.6884695281088352
Epoch: 63 | Iteration number: [410/565] 72% | Training loss: 0.6884251796617741
Epoch: 63 | Iteration number: [420/565] 74% | Training loss: 0.688381852990105
Epoch: 63 | Iteration number: [430/565] 76% | Training loss: 0.6883600987667261
Epoch: 63 | Iteration number: [440/565] 77% | Training loss: 0.6883398352698846
Epoch: 63 | Iteration number: [450/565] 79% | Training loss: 0.6883035038577185
Epoch: 63 | Iteration number: [460/565] 81% | Training loss: 0.688263712629028
Epoch: 63 | Iteration number: [470/565] 83% | Training loss: 0.6882322138928353
Epoch: 63 | Iteration number: [480/565] 84% | Training loss: 0.6882075057675441
Epoch: 63 | Iteration number: [490/565] 86% | Training loss: 0.6881821993662387
Epoch: 63 | Iteration number: [500/565] 88% | Training loss: 0.6881590237617493
Epoch: 63 | Iteration number: [510/565] 90% | Training loss: 0.6881378107211169
Epoch: 63 | Iteration number: [520/565] 92% | Training loss: 0.6881208057586964
Epoch: 63 | Iteration number: [530/565] 93% | Training loss: 0.6880880681973583
Epoch: 63 | Iteration number: [540/565] 95% | Training loss: 0.688069909479883
Epoch: 63 | Iteration number: [550/565] 97% | Training loss: 0.6880493100122972
Epoch: 63 | Iteration number: [560/565] 99% | Training loss: 0.6880206777581147

 End of epoch: 63 | Train Loss: 0.6868019985941659 | Training Time: 88 

 End of epoch: 63 | Eval Loss: 0.689700790813991 | Evaluating Time: 6 
Epoch: 64 | Iteration number: [10/565] 1% | Training loss: 0.7556608259677887
Epoch: 64 | Iteration number: [20/565] 3% | Training loss: 0.7212995827198029
Epoch: 64 | Iteration number: [30/565] 5% | Training loss: 0.709572829802831
Epoch: 64 | Iteration number: [40/565] 7% | Training loss: 0.7037804201245308
Epoch: 64 | Iteration number: [50/565] 8% | Training loss: 0.7004356491565704
Epoch: 64 | Iteration number: [60/565] 10% | Training loss: 0.6981467097997666
Epoch: 64 | Iteration number: [70/565] 12% | Training loss: 0.6964146656649454
Epoch: 64 | Iteration number: [80/565] 14% | Training loss: 0.6952080085873604
Epoch: 64 | Iteration number: [90/565] 15% | Training loss: 0.6942559440930685
Epoch: 64 | Iteration number: [100/565] 17% | Training loss: 0.6935126411914826
Epoch: 64 | Iteration number: [110/565] 19% | Training loss: 0.6929100264202465
Epoch: 64 | Iteration number: [120/565] 21% | Training loss: 0.6923738802472751
Epoch: 64 | Iteration number: [130/565] 23% | Training loss: 0.6919425336214212
Epoch: 64 | Iteration number: [140/565] 24% | Training loss: 0.6915563400302615
Epoch: 64 | Iteration number: [150/565] 26% | Training loss: 0.6912120020389557
Epoch: 64 | Iteration number: [160/565] 28% | Training loss: 0.6909537073224783
Epoch: 64 | Iteration number: [170/565] 30% | Training loss: 0.690720428088132
Epoch: 64 | Iteration number: [180/565] 31% | Training loss: 0.6905036416318682
Epoch: 64 | Iteration number: [190/565] 33% | Training loss: 0.6903032033067
Epoch: 64 | Iteration number: [200/565] 35% | Training loss: 0.6901359680294991
Epoch: 64 | Iteration number: [210/565] 37% | Training loss: 0.6899832342352186
Epoch: 64 | Iteration number: [220/565] 38% | Training loss: 0.6898554701696743
Epoch: 64 | Iteration number: [230/565] 40% | Training loss: 0.6897167153980421
Epoch: 64 | Iteration number: [240/565] 42% | Training loss: 0.6895941600203515
Epoch: 64 | Iteration number: [250/565] 44% | Training loss: 0.6894625761508941
Epoch: 64 | Iteration number: [260/565] 46% | Training loss: 0.689371752509704
Epoch: 64 | Iteration number: [270/565] 47% | Training loss: 0.6892916465247119
Epoch: 64 | Iteration number: [280/565] 49% | Training loss: 0.6891996613570622
Epoch: 64 | Iteration number: [290/565] 51% | Training loss: 0.6891152457944278
Epoch: 64 | Iteration number: [300/565] 53% | Training loss: 0.6890327952305476
Epoch: 64 | Iteration number: [310/565] 54% | Training loss: 0.6889692310364016
Epoch: 64 | Iteration number: [320/565] 56% | Training loss: 0.688894216902554
Epoch: 64 | Iteration number: [330/565] 58% | Training loss: 0.6888282588033965
Epoch: 64 | Iteration number: [340/565] 60% | Training loss: 0.6887656792121775
Epoch: 64 | Iteration number: [350/565] 61% | Training loss: 0.6887077495029994
Epoch: 64 | Iteration number: [360/565] 63% | Training loss: 0.6886461979813046
Epoch: 64 | Iteration number: [370/565] 65% | Training loss: 0.6886041365765236
Epoch: 64 | Iteration number: [380/565] 67% | Training loss: 0.6885542711145
Epoch: 64 | Iteration number: [390/565] 69% | Training loss: 0.6885170453634017
Epoch: 64 | Iteration number: [400/565] 70% | Training loss: 0.6884757572412491
Epoch: 64 | Iteration number: [410/565] 72% | Training loss: 0.6884405775768001
Epoch: 64 | Iteration number: [420/565] 74% | Training loss: 0.6883930514256159
Epoch: 64 | Iteration number: [430/565] 76% | Training loss: 0.6883537022180335
Epoch: 64 | Iteration number: [440/565] 77% | Training loss: 0.6883207728916948
Epoch: 64 | Iteration number: [450/565] 79% | Training loss: 0.6882881393697526
Epoch: 64 | Iteration number: [460/565] 81% | Training loss: 0.6882492145766382
Epoch: 64 | Iteration number: [470/565] 83% | Training loss: 0.6882231180972241
Epoch: 64 | Iteration number: [480/565] 84% | Training loss: 0.6881931470086177
Epoch: 64 | Iteration number: [490/565] 86% | Training loss: 0.6881650728838784
Epoch: 64 | Iteration number: [500/565] 88% | Training loss: 0.6881368403434753
Epoch: 64 | Iteration number: [510/565] 90% | Training loss: 0.6881091112015294
Epoch: 64 | Iteration number: [520/565] 92% | Training loss: 0.6880964594391676
Epoch: 64 | Iteration number: [530/565] 93% | Training loss: 0.6880772781821917
Epoch: 64 | Iteration number: [540/565] 95% | Training loss: 0.6880534185303582
Epoch: 64 | Iteration number: [550/565] 97% | Training loss: 0.688026828549125
Epoch: 64 | Iteration number: [560/565] 99% | Training loss: 0.68801060585039

 End of epoch: 64 | Train Loss: 0.6867819549763097 | Training Time: 91 

 End of epoch: 64 | Eval Loss: 0.68972476039614 | Evaluating Time: 5 
Epoch: 65 | Iteration number: [10/565] 1% | Training loss: 0.7549959719181061
Epoch: 65 | Iteration number: [20/565] 3% | Training loss: 0.7209901750087738
Epoch: 65 | Iteration number: [30/565] 5% | Training loss: 0.709655370314916
Epoch: 65 | Iteration number: [40/565] 7% | Training loss: 0.7039615586400032
Epoch: 65 | Iteration number: [50/565] 8% | Training loss: 0.7004335916042328
Epoch: 65 | Iteration number: [60/565] 10% | Training loss: 0.6981456965208054
Epoch: 65 | Iteration number: [70/565] 12% | Training loss: 0.6964995282036918
Epoch: 65 | Iteration number: [80/565] 14% | Training loss: 0.6953844375908375
Epoch: 65 | Iteration number: [90/565] 15% | Training loss: 0.694420584042867
Epoch: 65 | Iteration number: [100/565] 17% | Training loss: 0.6936856025457382
Epoch: 65 | Iteration number: [110/565] 19% | Training loss: 0.6930152096531608
Epoch: 65 | Iteration number: [120/565] 21% | Training loss: 0.6925153419375419
Epoch: 65 | Iteration number: [130/565] 23% | Training loss: 0.692086424277379
Epoch: 65 | Iteration number: [140/565] 24% | Training loss: 0.6916955117668424
Epoch: 65 | Iteration number: [150/565] 26% | Training loss: 0.691370689868927
Epoch: 65 | Iteration number: [160/565] 28% | Training loss: 0.691079780831933
Epoch: 65 | Iteration number: [170/565] 30% | Training loss: 0.6908303569344914
Epoch: 65 | Iteration number: [180/565] 31% | Training loss: 0.6905823750628366
Epoch: 65 | Iteration number: [190/565] 33% | Training loss: 0.6903869813994358
Epoch: 65 | Iteration number: [200/565] 35% | Training loss: 0.6901967242360115
Epoch: 65 | Iteration number: [210/565] 37% | Training loss: 0.6900070303962345
Epoch: 65 | Iteration number: [220/565] 38% | Training loss: 0.6898446484045548
Epoch: 65 | Iteration number: [230/565] 40% | Training loss: 0.6896927310072858
Epoch: 65 | Iteration number: [240/565] 42% | Training loss: 0.6895866028964519
Epoch: 65 | Iteration number: [250/565] 44% | Training loss: 0.689458164691925
Epoch: 65 | Iteration number: [260/565] 46% | Training loss: 0.6893586651637004
Epoch: 65 | Iteration number: [270/565] 47% | Training loss: 0.6892664492130279
Epoch: 65 | Iteration number: [280/565] 49% | Training loss: 0.6891770333051681
Epoch: 65 | Iteration number: [290/565] 51% | Training loss: 0.6890900190534263
Epoch: 65 | Iteration number: [300/565] 53% | Training loss: 0.6889976867039999
Epoch: 65 | Iteration number: [310/565] 54% | Training loss: 0.6889321755978369
Epoch: 65 | Iteration number: [320/565] 56% | Training loss: 0.6888664435595274
Epoch: 65 | Iteration number: [330/565] 58% | Training loss: 0.6888102302045533
Epoch: 65 | Iteration number: [340/565] 60% | Training loss: 0.6887427301967846
Epoch: 65 | Iteration number: [350/565] 61% | Training loss: 0.6886751823765891
Epoch: 65 | Iteration number: [360/565] 63% | Training loss: 0.688634110821618
Epoch: 65 | Iteration number: [370/565] 65% | Training loss: 0.6885807614068727
Epoch: 65 | Iteration number: [380/565] 67% | Training loss: 0.6885380410834363
Epoch: 65 | Iteration number: [390/565] 69% | Training loss: 0.6884982321506892
Epoch: 65 | Iteration number: [400/565] 70% | Training loss: 0.6884509985148907
Epoch: 65 | Iteration number: [410/565] 72% | Training loss: 0.6884213760131743
Epoch: 65 | Iteration number: [420/565] 74% | Training loss: 0.6883931729055587
Epoch: 65 | Iteration number: [430/565] 76% | Training loss: 0.6883544356323952
Epoch: 65 | Iteration number: [440/565] 77% | Training loss: 0.6883247910575433
Epoch: 65 | Iteration number: [450/565] 79% | Training loss: 0.6882979516188303
Epoch: 65 | Iteration number: [460/565] 81% | Training loss: 0.6882688636365144
Epoch: 65 | Iteration number: [470/565] 83% | Training loss: 0.6882398497551045
Epoch: 65 | Iteration number: [480/565] 84% | Training loss: 0.6882134313384692
Epoch: 65 | Iteration number: [490/565] 86% | Training loss: 0.6881856149556685
Epoch: 65 | Iteration number: [500/565] 88% | Training loss: 0.6881563180685043
Epoch: 65 | Iteration number: [510/565] 90% | Training loss: 0.6881353832927405
Epoch: 65 | Iteration number: [520/565] 92% | Training loss: 0.6881108684035447
Epoch: 65 | Iteration number: [530/565] 93% | Training loss: 0.688077646718835
Epoch: 65 | Iteration number: [540/565] 95% | Training loss: 0.6880554606517156
Epoch: 65 | Iteration number: [550/565] 97% | Training loss: 0.6880335749279369
Epoch: 65 | Iteration number: [560/565] 99% | Training loss: 0.6880088459168162

 End of epoch: 65 | Train Loss: 0.6867818732177262 | Training Time: 91 

 End of epoch: 65 | Eval Loss: 0.6899788890566144 | Evaluating Time: 5 
Epoch: 66 | Iteration number: [10/565] 1% | Training loss: 0.755424189567566
Epoch: 66 | Iteration number: [20/565] 3% | Training loss: 0.7210842818021774
Epoch: 66 | Iteration number: [30/565] 5% | Training loss: 0.7095598677794138
Epoch: 66 | Iteration number: [40/565] 7% | Training loss: 0.7037992030382156
Epoch: 66 | Iteration number: [50/565] 8% | Training loss: 0.7003012073040008
Epoch: 66 | Iteration number: [60/565] 10% | Training loss: 0.6980769375960032
Epoch: 66 | Iteration number: [70/565] 12% | Training loss: 0.6964496348585402
Epoch: 66 | Iteration number: [80/565] 14% | Training loss: 0.6952101707458496
Epoch: 66 | Iteration number: [90/565] 15% | Training loss: 0.6942768646611108
Epoch: 66 | Iteration number: [100/565] 17% | Training loss: 0.6935250592231751
Epoch: 66 | Iteration number: [110/565] 19% | Training loss: 0.69288370013237
Epoch: 66 | Iteration number: [120/565] 21% | Training loss: 0.6923940713206927
Epoch: 66 | Iteration number: [130/565] 23% | Training loss: 0.6919726115006667
Epoch: 66 | Iteration number: [140/565] 24% | Training loss: 0.6916080849511282
Epoch: 66 | Iteration number: [150/565] 26% | Training loss: 0.6912820780277252
Epoch: 66 | Iteration number: [160/565] 28% | Training loss: 0.6910192765295505
Epoch: 66 | Iteration number: [170/565] 30% | Training loss: 0.6907432135413675
Epoch: 66 | Iteration number: [180/565] 31% | Training loss: 0.6905335313744015
Epoch: 66 | Iteration number: [190/565] 33% | Training loss: 0.6903570112429167
Epoch: 66 | Iteration number: [200/565] 35% | Training loss: 0.6901860302686691
Epoch: 66 | Iteration number: [210/565] 37% | Training loss: 0.6900287457874843
Epoch: 66 | Iteration number: [220/565] 38% | Training loss: 0.6899028312076222
Epoch: 66 | Iteration number: [230/565] 40% | Training loss: 0.689764242068581
Epoch: 66 | Iteration number: [240/565] 42% | Training loss: 0.6896511346101761
Epoch: 66 | Iteration number: [250/565] 44% | Training loss: 0.6895411992073059
Epoch: 66 | Iteration number: [260/565] 46% | Training loss: 0.6894528531111204
Epoch: 66 | Iteration number: [270/565] 47% | Training loss: 0.6893339819378324
Epoch: 66 | Iteration number: [280/565] 49% | Training loss: 0.6892412592257772
Epoch: 66 | Iteration number: [290/565] 51% | Training loss: 0.6891513616874301
Epoch: 66 | Iteration number: [300/565] 53% | Training loss: 0.6890664633115132
Epoch: 66 | Iteration number: [310/565] 54% | Training loss: 0.6889883552828143
Epoch: 66 | Iteration number: [320/565] 56% | Training loss: 0.6889293232932687
Epoch: 66 | Iteration number: [330/565] 58% | Training loss: 0.6888648919986956
Epoch: 66 | Iteration number: [340/565] 60% | Training loss: 0.6887900375268039
Epoch: 66 | Iteration number: [350/565] 61% | Training loss: 0.6887139683110374
Epoch: 66 | Iteration number: [360/565] 63% | Training loss: 0.6886626564794116
Epoch: 66 | Iteration number: [370/565] 65% | Training loss: 0.6886262658480051
Epoch: 66 | Iteration number: [380/565] 67% | Training loss: 0.6885827698205647
Epoch: 66 | Iteration number: [390/565] 69% | Training loss: 0.6885262937117845
Epoch: 66 | Iteration number: [400/565] 70% | Training loss: 0.688489224910736
Epoch: 66 | Iteration number: [410/565] 72% | Training loss: 0.6884501266770247
Epoch: 66 | Iteration number: [420/565] 74% | Training loss: 0.6884152937503089
Epoch: 66 | Iteration number: [430/565] 76% | Training loss: 0.688381334792736
Epoch: 66 | Iteration number: [440/565] 77% | Training loss: 0.6883506486361677
Epoch: 66 | Iteration number: [450/565] 79% | Training loss: 0.6883169117238787
Epoch: 66 | Iteration number: [460/565] 81% | Training loss: 0.6882732681606127
Epoch: 66 | Iteration number: [470/565] 83% | Training loss: 0.6882383858903925
Epoch: 66 | Iteration number: [480/565] 84% | Training loss: 0.6882089996089538
Epoch: 66 | Iteration number: [490/565] 86% | Training loss: 0.6881790139237228
Epoch: 66 | Iteration number: [500/565] 88% | Training loss: 0.6881643457412719
Epoch: 66 | Iteration number: [510/565] 90% | Training loss: 0.6881460742623198
Epoch: 66 | Iteration number: [520/565] 92% | Training loss: 0.6881206706166267
Epoch: 66 | Iteration number: [530/565] 93% | Training loss: 0.6880994092743352
Epoch: 66 | Iteration number: [540/565] 95% | Training loss: 0.6880658876012873
Epoch: 66 | Iteration number: [550/565] 97% | Training loss: 0.6880415876345201
Epoch: 66 | Iteration number: [560/565] 99% | Training loss: 0.6880233317613602

 End of epoch: 66 | Train Loss: 0.6867913795783457 | Training Time: 90 

 End of epoch: 66 | Eval Loss: 0.6894288999693734 | Evaluating Time: 5 
Epoch: 67 | Iteration number: [10/565] 1% | Training loss: 0.7551026344299316
Epoch: 67 | Iteration number: [20/565] 3% | Training loss: 0.7208390712738038
Epoch: 67 | Iteration number: [30/565] 5% | Training loss: 0.7095058401425679
Epoch: 67 | Iteration number: [40/565] 7% | Training loss: 0.7038669019937516
Epoch: 67 | Iteration number: [50/565] 8% | Training loss: 0.7004203879833222
Epoch: 67 | Iteration number: [60/565] 10% | Training loss: 0.6981870571772257
Epoch: 67 | Iteration number: [70/565] 12% | Training loss: 0.6965753214699881
Epoch: 67 | Iteration number: [80/565] 14% | Training loss: 0.695322210341692
Epoch: 67 | Iteration number: [90/565] 15% | Training loss: 0.6943919314278497
Epoch: 67 | Iteration number: [100/565] 17% | Training loss: 0.693662914633751
Epoch: 67 | Iteration number: [110/565] 19% | Training loss: 0.693072337995876
Epoch: 67 | Iteration number: [120/565] 21% | Training loss: 0.6925750603278478
Epoch: 67 | Iteration number: [130/565] 23% | Training loss: 0.6921147387761336
Epoch: 67 | Iteration number: [140/565] 24% | Training loss: 0.6917064832789558
Epoch: 67 | Iteration number: [150/565] 26% | Training loss: 0.6913975711663564
Epoch: 67 | Iteration number: [160/565] 28% | Training loss: 0.6911359287798404
Epoch: 67 | Iteration number: [170/565] 30% | Training loss: 0.690872653091655
Epoch: 67 | Iteration number: [180/565] 31% | Training loss: 0.690671209163136
Epoch: 67 | Iteration number: [190/565] 33% | Training loss: 0.6904472398130517
Epoch: 67 | Iteration number: [200/565] 35% | Training loss: 0.6902660846710205
Epoch: 67 | Iteration number: [210/565] 37% | Training loss: 0.6900975136529832
Epoch: 67 | Iteration number: [220/565] 38% | Training loss: 0.6899214015765623
Epoch: 67 | Iteration number: [230/565] 40% | Training loss: 0.689777866653774
Epoch: 67 | Iteration number: [240/565] 42% | Training loss: 0.6896594494581223
Epoch: 67 | Iteration number: [250/565] 44% | Training loss: 0.6895409774780273
Epoch: 67 | Iteration number: [260/565] 46% | Training loss: 0.6894474923610687
Epoch: 67 | Iteration number: [270/565] 47% | Training loss: 0.6893575136308316
Epoch: 67 | Iteration number: [280/565] 49% | Training loss: 0.689261725119182
Epoch: 67 | Iteration number: [290/565] 51% | Training loss: 0.6891753133000998
Epoch: 67 | Iteration number: [300/565] 53% | Training loss: 0.689085051814715
Epoch: 67 | Iteration number: [310/565] 54% | Training loss: 0.6890107168305305
Epoch: 67 | Iteration number: [320/565] 56% | Training loss: 0.6889399409294128
Epoch: 67 | Iteration number: [330/565] 58% | Training loss: 0.6888789863297433
Epoch: 67 | Iteration number: [340/565] 60% | Training loss: 0.6888167174423442
Epoch: 67 | Iteration number: [350/565] 61% | Training loss: 0.6887425398826599
Epoch: 67 | Iteration number: [360/565] 63% | Training loss: 0.6886989777286847
Epoch: 67 | Iteration number: [370/565] 65% | Training loss: 0.6886273227833413
Epoch: 67 | Iteration number: [380/565] 67% | Training loss: 0.6885863308843814
Epoch: 67 | Iteration number: [390/565] 69% | Training loss: 0.6885374105893649
Epoch: 67 | Iteration number: [400/565] 70% | Training loss: 0.6884968900680541
Epoch: 67 | Iteration number: [410/565] 72% | Training loss: 0.688442021899107
Epoch: 67 | Iteration number: [420/565] 74% | Training loss: 0.688402092172986
Epoch: 67 | Iteration number: [430/565] 76% | Training loss: 0.6883688348670338
Epoch: 67 | Iteration number: [440/565] 77% | Training loss: 0.6883379982276396
Epoch: 67 | Iteration number: [450/565] 79% | Training loss: 0.6883113508754306
Epoch: 67 | Iteration number: [460/565] 81% | Training loss: 0.6882724371941193
Epoch: 67 | Iteration number: [470/565] 83% | Training loss: 0.6882395286509331
Epoch: 67 | Iteration number: [480/565] 84% | Training loss: 0.6882100269198418
Epoch: 67 | Iteration number: [490/565] 86% | Training loss: 0.6881775567726213
Epoch: 67 | Iteration number: [500/565] 88% | Training loss: 0.6881441415548325
Epoch: 67 | Iteration number: [510/565] 90% | Training loss: 0.688115924947402
Epoch: 67 | Iteration number: [520/565] 92% | Training loss: 0.6880936526335203
Epoch: 67 | Iteration number: [530/565] 93% | Training loss: 0.6880700796280267
Epoch: 67 | Iteration number: [540/565] 95% | Training loss: 0.6880421551289382
Epoch: 67 | Iteration number: [550/565] 97% | Training loss: 0.6880280499024825
Epoch: 67 | Iteration number: [560/565] 99% | Training loss: 0.6880112276545592

 End of epoch: 67 | Train Loss: 0.6867796258588807 | Training Time: 91 

 End of epoch: 67 | Eval Loss: 0.6899489760398865 | Evaluating Time: 5 
Epoch: 68 | Iteration number: [10/565] 1% | Training loss: 0.7554211914539337
Epoch: 68 | Iteration number: [20/565] 3% | Training loss: 0.7210522383451462
Epoch: 68 | Iteration number: [30/565] 5% | Training loss: 0.7096939504146575
Epoch: 68 | Iteration number: [40/565] 7% | Training loss: 0.7039540320634842
Epoch: 68 | Iteration number: [50/565] 8% | Training loss: 0.7005054116249084
Epoch: 68 | Iteration number: [60/565] 10% | Training loss: 0.6982697854439418
Epoch: 68 | Iteration number: [70/565] 12% | Training loss: 0.6966657025473458
Epoch: 68 | Iteration number: [80/565] 14% | Training loss: 0.6953732818365097
Epoch: 68 | Iteration number: [90/565] 15% | Training loss: 0.694476322333018
Epoch: 68 | Iteration number: [100/565] 17% | Training loss: 0.6937151259183884
Epoch: 68 | Iteration number: [110/565] 19% | Training loss: 0.6930425351316278
Epoch: 68 | Iteration number: [120/565] 21% | Training loss: 0.6925239781538646
Epoch: 68 | Iteration number: [130/565] 23% | Training loss: 0.6920777650979849
Epoch: 68 | Iteration number: [140/565] 24% | Training loss: 0.6917224211352212
Epoch: 68 | Iteration number: [150/565] 26% | Training loss: 0.6913635126749674
Epoch: 68 | Iteration number: [160/565] 28% | Training loss: 0.6910557892173529
Epoch: 68 | Iteration number: [170/565] 30% | Training loss: 0.6908124811509077
Epoch: 68 | Iteration number: [180/565] 31% | Training loss: 0.6905972507264879
Epoch: 68 | Iteration number: [190/565] 33% | Training loss: 0.6904125279501865
Epoch: 68 | Iteration number: [200/565] 35% | Training loss: 0.6902275088429451
Epoch: 68 | Iteration number: [210/565] 37% | Training loss: 0.6900403156166985
Epoch: 68 | Iteration number: [220/565] 38% | Training loss: 0.6898873583836989
Epoch: 68 | Iteration number: [230/565] 40% | Training loss: 0.6897543679112973
Epoch: 68 | Iteration number: [240/565] 42% | Training loss: 0.6896292567253113
Epoch: 68 | Iteration number: [250/565] 44% | Training loss: 0.6895324440002442
Epoch: 68 | Iteration number: [260/565] 46% | Training loss: 0.6894082035009678
Epoch: 68 | Iteration number: [270/565] 47% | Training loss: 0.689319818549686
Epoch: 68 | Iteration number: [280/565] 49% | Training loss: 0.6892345058066505
Epoch: 68 | Iteration number: [290/565] 51% | Training loss: 0.689157733835023
Epoch: 68 | Iteration number: [300/565] 53% | Training loss: 0.6890753277142843
Epoch: 68 | Iteration number: [310/565] 54% | Training loss: 0.6890182558567294
Epoch: 68 | Iteration number: [320/565] 56% | Training loss: 0.6889575999230146
Epoch: 68 | Iteration number: [330/565] 58% | Training loss: 0.688865130778515
Epoch: 68 | Iteration number: [340/565] 60% | Training loss: 0.6888135305222343
Epoch: 68 | Iteration number: [350/565] 61% | Training loss: 0.6887536495072502
Epoch: 68 | Iteration number: [360/565] 63% | Training loss: 0.6886999264359475
Epoch: 68 | Iteration number: [370/565] 65% | Training loss: 0.688649509726344
Epoch: 68 | Iteration number: [380/565] 67% | Training loss: 0.6886005434550737
Epoch: 68 | Iteration number: [390/565] 69% | Training loss: 0.688545903792748
Epoch: 68 | Iteration number: [400/565] 70% | Training loss: 0.6885108649730682
Epoch: 68 | Iteration number: [410/565] 72% | Training loss: 0.6884662687778473
Epoch: 68 | Iteration number: [420/565] 74% | Training loss: 0.6884190881536121
Epoch: 68 | Iteration number: [430/565] 76% | Training loss: 0.6883838819902997
Epoch: 68 | Iteration number: [440/565] 77% | Training loss: 0.6883482277393341
Epoch: 68 | Iteration number: [450/565] 79% | Training loss: 0.688312193022834
Epoch: 68 | Iteration number: [460/565] 81% | Training loss: 0.6882735923580502
Epoch: 68 | Iteration number: [470/565] 83% | Training loss: 0.6882425710241845
Epoch: 68 | Iteration number: [480/565] 84% | Training loss: 0.6882182690004508
Epoch: 68 | Iteration number: [490/565] 86% | Training loss: 0.6881949494079668
Epoch: 68 | Iteration number: [500/565] 88% | Training loss: 0.688161528468132
Epoch: 68 | Iteration number: [510/565] 90% | Training loss: 0.6881337404251099
Epoch: 68 | Iteration number: [520/565] 92% | Training loss: 0.688107568369462
Epoch: 68 | Iteration number: [530/565] 93% | Training loss: 0.6880795756600938
Epoch: 68 | Iteration number: [540/565] 95% | Training loss: 0.6880611514603651
Epoch: 68 | Iteration number: [550/565] 97% | Training loss: 0.688038963729685
Epoch: 68 | Iteration number: [560/565] 99% | Training loss: 0.6880154444703034

 End of epoch: 68 | Train Loss: 0.686785967582095 | Training Time: 92 

 End of epoch: 68 | Eval Loss: 0.6895052875791278 | Evaluating Time: 5 
Epoch: 69 | Iteration number: [10/565] 1% | Training loss: 0.7554420053958892
Epoch: 69 | Iteration number: [20/565] 3% | Training loss: 0.7210866451263428
Epoch: 69 | Iteration number: [30/565] 5% | Training loss: 0.7096617579460144
Epoch: 69 | Iteration number: [40/565] 7% | Training loss: 0.7039047434926033
Epoch: 69 | Iteration number: [50/565] 8% | Training loss: 0.7003911972045899
Epoch: 69 | Iteration number: [60/565] 10% | Training loss: 0.6981414089600245
Epoch: 69 | Iteration number: [70/565] 12% | Training loss: 0.696494369847434
Epoch: 69 | Iteration number: [80/565] 14% | Training loss: 0.6952620536088944
Epoch: 69 | Iteration number: [90/565] 15% | Training loss: 0.6943162964449988
Epoch: 69 | Iteration number: [100/565] 17% | Training loss: 0.693589961528778
Epoch: 69 | Iteration number: [110/565] 19% | Training loss: 0.6929686795581471
Epoch: 69 | Iteration number: [120/565] 21% | Training loss: 0.6924342647194862
Epoch: 69 | Iteration number: [130/565] 23% | Training loss: 0.6919860766484187
Epoch: 69 | Iteration number: [140/565] 24% | Training loss: 0.6916007620947702
Epoch: 69 | Iteration number: [150/565] 26% | Training loss: 0.6912990188598633
Epoch: 69 | Iteration number: [160/565] 28% | Training loss: 0.6910322140902281
Epoch: 69 | Iteration number: [170/565] 30% | Training loss: 0.6908055656096515
Epoch: 69 | Iteration number: [180/565] 31% | Training loss: 0.6905780951182048
Epoch: 69 | Iteration number: [190/565] 33% | Training loss: 0.6903733821291672
Epoch: 69 | Iteration number: [200/565] 35% | Training loss: 0.6902019912004471
Epoch: 69 | Iteration number: [210/565] 37% | Training loss: 0.690041861079988
Epoch: 69 | Iteration number: [220/565] 38% | Training loss: 0.6898966775699096
Epoch: 69 | Iteration number: [230/565] 40% | Training loss: 0.6897667993669925
Epoch: 69 | Iteration number: [240/565] 42% | Training loss: 0.6896294732888539
Epoch: 69 | Iteration number: [250/565] 44% | Training loss: 0.6895171282291412
Epoch: 69 | Iteration number: [260/565] 46% | Training loss: 0.6894057150070484
Epoch: 69 | Iteration number: [270/565] 47% | Training loss: 0.6893079338250336
Epoch: 69 | Iteration number: [280/565] 49% | Training loss: 0.6892133006027766
Epoch: 69 | Iteration number: [290/565] 51% | Training loss: 0.6891244105223951
Epoch: 69 | Iteration number: [300/565] 53% | Training loss: 0.689056345820427
Epoch: 69 | Iteration number: [310/565] 54% | Training loss: 0.6889847265135858
Epoch: 69 | Iteration number: [320/565] 56% | Training loss: 0.688919304125011
Epoch: 69 | Iteration number: [330/565] 58% | Training loss: 0.6888546865997892
Epoch: 69 | Iteration number: [340/565] 60% | Training loss: 0.6887918787844041
Epoch: 69 | Iteration number: [350/565] 61% | Training loss: 0.6887348878383637
Epoch: 69 | Iteration number: [360/565] 63% | Training loss: 0.6886751789185735
Epoch: 69 | Iteration number: [370/565] 65% | Training loss: 0.6886324294515558
Epoch: 69 | Iteration number: [380/565] 67% | Training loss: 0.6885792730670226
Epoch: 69 | Iteration number: [390/565] 69% | Training loss: 0.6885332044882652
Epoch: 69 | Iteration number: [400/565] 70% | Training loss: 0.6884993170201779
Epoch: 69 | Iteration number: [410/565] 72% | Training loss: 0.6884556825568037
Epoch: 69 | Iteration number: [420/565] 74% | Training loss: 0.6884169249307541
Epoch: 69 | Iteration number: [430/565] 76% | Training loss: 0.6883839367434036
Epoch: 69 | Iteration number: [440/565] 77% | Training loss: 0.6883444366129962
Epoch: 69 | Iteration number: [450/565] 79% | Training loss: 0.688296301762263
Epoch: 69 | Iteration number: [460/565] 81% | Training loss: 0.6882651755343313
Epoch: 69 | Iteration number: [470/565] 83% | Training loss: 0.6882435397898897
Epoch: 69 | Iteration number: [480/565] 84% | Training loss: 0.6882166488717
Epoch: 69 | Iteration number: [490/565] 86% | Training loss: 0.6881868606927444
Epoch: 69 | Iteration number: [500/565] 88% | Training loss: 0.6881680309772491
Epoch: 69 | Iteration number: [510/565] 90% | Training loss: 0.688135027885437
Epoch: 69 | Iteration number: [520/565] 92% | Training loss: 0.6881097430220017
Epoch: 69 | Iteration number: [530/565] 93% | Training loss: 0.6880812048912048
Epoch: 69 | Iteration number: [540/565] 95% | Training loss: 0.6880583546779774
Epoch: 69 | Iteration number: [550/565] 97% | Training loss: 0.6880288876186718
Epoch: 69 | Iteration number: [560/565] 99% | Training loss: 0.6880017686103072

 End of epoch: 69 | Train Loss: 0.6867770989384271 | Training Time: 90 

 End of epoch: 69 | Eval Loss: 0.6898154786654881 | Evaluating Time: 5 
Epoch: 70 | Iteration number: [10/565] 1% | Training loss: 0.7555853188037872
Epoch: 70 | Iteration number: [20/565] 3% | Training loss: 0.721240970492363
Epoch: 70 | Iteration number: [30/565] 5% | Training loss: 0.709498240550359
Epoch: 70 | Iteration number: [40/565] 7% | Training loss: 0.7039042204618454
Epoch: 70 | Iteration number: [50/565] 8% | Training loss: 0.700450131893158
Epoch: 70 | Iteration number: [60/565] 10% | Training loss: 0.6981844037771225
Epoch: 70 | Iteration number: [70/565] 12% | Training loss: 0.6965329893997737
Epoch: 70 | Iteration number: [80/565] 14% | Training loss: 0.6953510366380214
Epoch: 70 | Iteration number: [90/565] 15% | Training loss: 0.6944147282176547
Epoch: 70 | Iteration number: [100/565] 17% | Training loss: 0.6936660200357437
Epoch: 70 | Iteration number: [110/565] 19% | Training loss: 0.6931067239154469
Epoch: 70 | Iteration number: [120/565] 21% | Training loss: 0.692596057554086
Epoch: 70 | Iteration number: [130/565] 23% | Training loss: 0.6921539357075325
Epoch: 70 | Iteration number: [140/565] 24% | Training loss: 0.6917691043445042
Epoch: 70 | Iteration number: [150/565] 26% | Training loss: 0.69138853987058
Epoch: 70 | Iteration number: [160/565] 28% | Training loss: 0.6911001611500979
Epoch: 70 | Iteration number: [170/565] 30% | Training loss: 0.6908458257422728
Epoch: 70 | Iteration number: [180/565] 31% | Training loss: 0.69059410293897
Epoch: 70 | Iteration number: [190/565] 33% | Training loss: 0.6903756398903697
Epoch: 70 | Iteration number: [200/565] 35% | Training loss: 0.6901980593800545
Epoch: 70 | Iteration number: [210/565] 37% | Training loss: 0.6900419130211785
Epoch: 70 | Iteration number: [220/565] 38% | Training loss: 0.689885260571133
Epoch: 70 | Iteration number: [230/565] 40% | Training loss: 0.6897660110307776
Epoch: 70 | Iteration number: [240/565] 42% | Training loss: 0.6896460838615894
Epoch: 70 | Iteration number: [250/565] 44% | Training loss: 0.6895247836112977
Epoch: 70 | Iteration number: [260/565] 46% | Training loss: 0.6894078252407221
Epoch: 70 | Iteration number: [270/565] 47% | Training loss: 0.6892948684868989
Epoch: 70 | Iteration number: [280/565] 49% | Training loss: 0.6892096953732627
Epoch: 70 | Iteration number: [290/565] 51% | Training loss: 0.6891278007934833
Epoch: 70 | Iteration number: [300/565] 53% | Training loss: 0.6890650566418965
Epoch: 70 | Iteration number: [310/565] 54% | Training loss: 0.6889926839259363
Epoch: 70 | Iteration number: [320/565] 56% | Training loss: 0.6889444269239903
Epoch: 70 | Iteration number: [330/565] 58% | Training loss: 0.6888770553198728
Epoch: 70 | Iteration number: [340/565] 60% | Training loss: 0.6888287777409834
Epoch: 70 | Iteration number: [350/565] 61% | Training loss: 0.6887634992599487
Epoch: 70 | Iteration number: [360/565] 63% | Training loss: 0.6887123997012774
Epoch: 70 | Iteration number: [370/565] 65% | Training loss: 0.6886567811708193
Epoch: 70 | Iteration number: [380/565] 67% | Training loss: 0.6886078207116378
Epoch: 70 | Iteration number: [390/565] 69% | Training loss: 0.6885544177813407
Epoch: 70 | Iteration number: [400/565] 70% | Training loss: 0.6885065133869648
Epoch: 70 | Iteration number: [410/565] 72% | Training loss: 0.688458734169239
Epoch: 70 | Iteration number: [420/565] 74% | Training loss: 0.6884195170232228
Epoch: 70 | Iteration number: [430/565] 76% | Training loss: 0.6883738616178202
Epoch: 70 | Iteration number: [440/565] 77% | Training loss: 0.6883472453464161
Epoch: 70 | Iteration number: [450/565] 79% | Training loss: 0.6883158844047123
Epoch: 70 | Iteration number: [460/565] 81% | Training loss: 0.6882897721684498
Epoch: 70 | Iteration number: [470/565] 83% | Training loss: 0.6882661412370966
Epoch: 70 | Iteration number: [480/565] 84% | Training loss: 0.688247588276863
Epoch: 70 | Iteration number: [490/565] 86% | Training loss: 0.6882203475553162
Epoch: 70 | Iteration number: [500/565] 88% | Training loss: 0.6881967324018479
Epoch: 70 | Iteration number: [510/565] 90% | Training loss: 0.6881731274081212
Epoch: 70 | Iteration number: [520/565] 92% | Training loss: 0.6881388614957149
Epoch: 70 | Iteration number: [530/565] 93% | Training loss: 0.6881112367477057
Epoch: 70 | Iteration number: [540/565] 95% | Training loss: 0.6880790117714141
Epoch: 70 | Iteration number: [550/565] 97% | Training loss: 0.6880501299554651
Epoch: 70 | Iteration number: [560/565] 99% | Training loss: 0.6880226441792079

 End of epoch: 70 | Train Loss: 0.6867974145222554 | Training Time: 90 

 End of epoch: 70 | Eval Loss: 0.6892680951527187 | Evaluating Time: 5 
Epoch: 71 | Iteration number: [10/565] 1% | Training loss: 0.7552805721759797
Epoch: 71 | Iteration number: [20/565] 3% | Training loss: 0.7210103183984756
Epoch: 71 | Iteration number: [30/565] 5% | Training loss: 0.7095740775267283
Epoch: 71 | Iteration number: [40/565] 7% | Training loss: 0.7039421409368515
Epoch: 71 | Iteration number: [50/565] 8% | Training loss: 0.7005111157894135
Epoch: 71 | Iteration number: [60/565] 10% | Training loss: 0.6982746144135793
Epoch: 71 | Iteration number: [70/565] 12% | Training loss: 0.6965793234961374
Epoch: 71 | Iteration number: [80/565] 14% | Training loss: 0.6953256167471409
Epoch: 71 | Iteration number: [90/565] 15% | Training loss: 0.6943652987480163
Epoch: 71 | Iteration number: [100/565] 17% | Training loss: 0.6935823500156403
Epoch: 71 | Iteration number: [110/565] 19% | Training loss: 0.6930116664279591
Epoch: 71 | Iteration number: [120/565] 21% | Training loss: 0.692459161579609
Epoch: 71 | Iteration number: [130/565] 23% | Training loss: 0.6920269333399259
Epoch: 71 | Iteration number: [140/565] 24% | Training loss: 0.6916239244597299
Epoch: 71 | Iteration number: [150/565] 26% | Training loss: 0.691310613155365
Epoch: 71 | Iteration number: [160/565] 28% | Training loss: 0.6910197708755732
Epoch: 71 | Iteration number: [170/565] 30% | Training loss: 0.6907455686260672
Epoch: 71 | Iteration number: [180/565] 31% | Training loss: 0.6905160377422969
Epoch: 71 | Iteration number: [190/565] 33% | Training loss: 0.6903035643853639
Epoch: 71 | Iteration number: [200/565] 35% | Training loss: 0.6901201900839805
Epoch: 71 | Iteration number: [210/565] 37% | Training loss: 0.6899509597392309
Epoch: 71 | Iteration number: [220/565] 38% | Training loss: 0.6898045472123406
Epoch: 71 | Iteration number: [230/565] 40% | Training loss: 0.6896653444870658
Epoch: 71 | Iteration number: [240/565] 42% | Training loss: 0.6895560609797636
Epoch: 71 | Iteration number: [250/565] 44% | Training loss: 0.6894582397937775
Epoch: 71 | Iteration number: [260/565] 46% | Training loss: 0.6893582827769793
Epoch: 71 | Iteration number: [270/565] 47% | Training loss: 0.6892642078576264
Epoch: 71 | Iteration number: [280/565] 49% | Training loss: 0.6891902653234345
Epoch: 71 | Iteration number: [290/565] 51% | Training loss: 0.6891063838169492
Epoch: 71 | Iteration number: [300/565] 53% | Training loss: 0.689029638171196
Epoch: 71 | Iteration number: [310/565] 54% | Training loss: 0.688971737700124
Epoch: 71 | Iteration number: [320/565] 56% | Training loss: 0.6889013346284628
Epoch: 71 | Iteration number: [330/565] 58% | Training loss: 0.6888377236597466
Epoch: 71 | Iteration number: [340/565] 60% | Training loss: 0.6887656757060219
Epoch: 71 | Iteration number: [350/565] 61% | Training loss: 0.6887208354473114
Epoch: 71 | Iteration number: [360/565] 63% | Training loss: 0.6886521852678723
Epoch: 71 | Iteration number: [370/565] 65% | Training loss: 0.6886037617116361
Epoch: 71 | Iteration number: [380/565] 67% | Training loss: 0.6885641245465529
Epoch: 71 | Iteration number: [390/565] 69% | Training loss: 0.688527630842649
Epoch: 71 | Iteration number: [400/565] 70% | Training loss: 0.6884911772608757
Epoch: 71 | Iteration number: [410/565] 72% | Training loss: 0.6884454058437812
Epoch: 71 | Iteration number: [420/565] 74% | Training loss: 0.6884065855117071
Epoch: 71 | Iteration number: [430/565] 76% | Training loss: 0.6883574057457059
Epoch: 71 | Iteration number: [440/565] 77% | Training loss: 0.6883233318274672
Epoch: 71 | Iteration number: [450/565] 79% | Training loss: 0.6882956308788724
Epoch: 71 | Iteration number: [460/565] 81% | Training loss: 0.6882618911888289
Epoch: 71 | Iteration number: [470/565] 83% | Training loss: 0.6882324761532722
Epoch: 71 | Iteration number: [480/565] 84% | Training loss: 0.6882010351866483
Epoch: 71 | Iteration number: [490/565] 86% | Training loss: 0.6881832959700603
Epoch: 71 | Iteration number: [500/565] 88% | Training loss: 0.6881576640605926
Epoch: 71 | Iteration number: [510/565] 90% | Training loss: 0.6881277820643257
Epoch: 71 | Iteration number: [520/565] 92% | Training loss: 0.6881022836153324
Epoch: 71 | Iteration number: [530/565] 93% | Training loss: 0.6880837448363034
Epoch: 71 | Iteration number: [540/565] 95% | Training loss: 0.6880567460148422
Epoch: 71 | Iteration number: [550/565] 97% | Training loss: 0.6880294262279164
Epoch: 71 | Iteration number: [560/565] 99% | Training loss: 0.6880061969161033

 End of epoch: 71 | Train Loss: 0.686779155984389 | Training Time: 91 

 End of epoch: 71 | Eval Loss: 0.6898253389767238 | Evaluating Time: 5 
Epoch: 72 | Iteration number: [10/565] 1% | Training loss: 0.7555911123752594
Epoch: 72 | Iteration number: [20/565] 3% | Training loss: 0.7210370868444442
Epoch: 72 | Iteration number: [30/565] 5% | Training loss: 0.7095617969830831
Epoch: 72 | Iteration number: [40/565] 7% | Training loss: 0.7037802621722221
Epoch: 72 | Iteration number: [50/565] 8% | Training loss: 0.7004528570175171
Epoch: 72 | Iteration number: [60/565] 10% | Training loss: 0.6981086800495784
Epoch: 72 | Iteration number: [70/565] 12% | Training loss: 0.6964257538318634
Epoch: 72 | Iteration number: [80/565] 14% | Training loss: 0.6952309101819992
Epoch: 72 | Iteration number: [90/565] 15% | Training loss: 0.6942708379692502
Epoch: 72 | Iteration number: [100/565] 17% | Training loss: 0.693470389842987
Epoch: 72 | Iteration number: [110/565] 19% | Training loss: 0.6928768017075279
Epoch: 72 | Iteration number: [120/565] 21% | Training loss: 0.6923751955231031
Epoch: 72 | Iteration number: [130/565] 23% | Training loss: 0.6919603650386517
Epoch: 72 | Iteration number: [140/565] 24% | Training loss: 0.6915727130004338
Epoch: 72 | Iteration number: [150/565] 26% | Training loss: 0.6912470265229543
Epoch: 72 | Iteration number: [160/565] 28% | Training loss: 0.6909366317093373
Epoch: 72 | Iteration number: [170/565] 30% | Training loss: 0.6907125052283792
Epoch: 72 | Iteration number: [180/565] 31% | Training loss: 0.6905052645338906
Epoch: 72 | Iteration number: [190/565] 33% | Training loss: 0.6902909244361677
Epoch: 72 | Iteration number: [200/565] 35% | Training loss: 0.6901312699913978
Epoch: 72 | Iteration number: [210/565] 37% | Training loss: 0.6899762812114897
Epoch: 72 | Iteration number: [220/565] 38% | Training loss: 0.6898403010585091
Epoch: 72 | Iteration number: [230/565] 40% | Training loss: 0.6897247107132621
Epoch: 72 | Iteration number: [240/565] 42% | Training loss: 0.6896031334996223
Epoch: 72 | Iteration number: [250/565] 44% | Training loss: 0.6895191893577576
Epoch: 72 | Iteration number: [260/565] 46% | Training loss: 0.6894090638710902
Epoch: 72 | Iteration number: [270/565] 47% | Training loss: 0.6893086186161748
Epoch: 72 | Iteration number: [280/565] 49% | Training loss: 0.6892308750322886
Epoch: 72 | Iteration number: [290/565] 51% | Training loss: 0.6891413959963568
Epoch: 72 | Iteration number: [300/565] 53% | Training loss: 0.6890595078468322
Epoch: 72 | Iteration number: [310/565] 54% | Training loss: 0.6889810719797688
Epoch: 72 | Iteration number: [320/565] 56% | Training loss: 0.6889007775112986
Epoch: 72 | Iteration number: [330/565] 58% | Training loss: 0.6888428684436914
Epoch: 72 | Iteration number: [340/565] 60% | Training loss: 0.6887763608904446
Epoch: 72 | Iteration number: [350/565] 61% | Training loss: 0.6887139637129648
Epoch: 72 | Iteration number: [360/565] 63% | Training loss: 0.6886637618144353
Epoch: 72 | Iteration number: [370/565] 65% | Training loss: 0.6886045169185948
Epoch: 72 | Iteration number: [380/565] 67% | Training loss: 0.6885736413692173
Epoch: 72 | Iteration number: [390/565] 69% | Training loss: 0.6885402060472048
Epoch: 72 | Iteration number: [400/565] 70% | Training loss: 0.6884952865540981
Epoch: 72 | Iteration number: [410/565] 72% | Training loss: 0.6884548912688
Epoch: 72 | Iteration number: [420/565] 74% | Training loss: 0.6884006304400307
Epoch: 72 | Iteration number: [430/565] 76% | Training loss: 0.6883677775083586
Epoch: 72 | Iteration number: [440/565] 77% | Training loss: 0.6883296546610919
Epoch: 72 | Iteration number: [450/565] 79% | Training loss: 0.6883011302683089
Epoch: 72 | Iteration number: [460/565] 81% | Training loss: 0.688265827557315
Epoch: 72 | Iteration number: [470/565] 83% | Training loss: 0.688229405119064
Epoch: 72 | Iteration number: [480/565] 84% | Training loss: 0.6881865940988063
Epoch: 72 | Iteration number: [490/565] 86% | Training loss: 0.6881615000111716
Epoch: 72 | Iteration number: [500/565] 88% | Training loss: 0.6881302083730698
Epoch: 72 | Iteration number: [510/565] 90% | Training loss: 0.6881025161228927
Epoch: 72 | Iteration number: [520/565] 92% | Training loss: 0.6880809611999071
Epoch: 72 | Iteration number: [530/565] 93% | Training loss: 0.6880527688647217
Epoch: 72 | Iteration number: [540/565] 95% | Training loss: 0.68802797584622
Epoch: 72 | Iteration number: [550/565] 97% | Training loss: 0.6880137289654125
Epoch: 72 | Iteration number: [560/565] 99% | Training loss: 0.6880006695432322

 End of epoch: 72 | Train Loss: 0.6867725681414646 | Training Time: 92 

 End of epoch: 72 | Eval Loss: 0.6892139315605164 | Evaluating Time: 5 
Epoch: 73 | Iteration number: [10/565] 1% | Training loss: 0.7552377641201019
Epoch: 73 | Iteration number: [20/565] 3% | Training loss: 0.7208883464336395
Epoch: 73 | Iteration number: [30/565] 5% | Training loss: 0.7095395723978678
Epoch: 73 | Iteration number: [40/565] 7% | Training loss: 0.703843954205513
Epoch: 73 | Iteration number: [50/565] 8% | Training loss: 0.7004488134384155
Epoch: 73 | Iteration number: [60/565] 10% | Training loss: 0.6982719788948695
Epoch: 73 | Iteration number: [70/565] 12% | Training loss: 0.6966335500989641
Epoch: 73 | Iteration number: [80/565] 14% | Training loss: 0.6953712336719036
Epoch: 73 | Iteration number: [90/565] 15% | Training loss: 0.6944114089012146
Epoch: 73 | Iteration number: [100/565] 17% | Training loss: 0.6936345320940017
Epoch: 73 | Iteration number: [110/565] 19% | Training loss: 0.6930168178948489
Epoch: 73 | Iteration number: [120/565] 21% | Training loss: 0.6924900377790133
Epoch: 73 | Iteration number: [130/565] 23% | Training loss: 0.6920690820767329
Epoch: 73 | Iteration number: [140/565] 24% | Training loss: 0.6916735419205257
Epoch: 73 | Iteration number: [150/565] 26% | Training loss: 0.6913434704144795
Epoch: 73 | Iteration number: [160/565] 28% | Training loss: 0.6910754192620516
Epoch: 73 | Iteration number: [170/565] 30% | Training loss: 0.6908481317407945
Epoch: 73 | Iteration number: [180/565] 31% | Training loss: 0.6906342582570182
Epoch: 73 | Iteration number: [190/565] 33% | Training loss: 0.6904187694976204
Epoch: 73 | Iteration number: [200/565] 35% | Training loss: 0.6902545300126076
Epoch: 73 | Iteration number: [210/565] 37% | Training loss: 0.6900945484638215
Epoch: 73 | Iteration number: [220/565] 38% | Training loss: 0.6899401540105993
Epoch: 73 | Iteration number: [230/565] 40% | Training loss: 0.689810082445974
Epoch: 73 | Iteration number: [240/565] 42% | Training loss: 0.6896873454252879
Epoch: 73 | Iteration number: [250/565] 44% | Training loss: 0.6895452375411988
Epoch: 73 | Iteration number: [260/565] 46% | Training loss: 0.6894537095840161
Epoch: 73 | Iteration number: [270/565] 47% | Training loss: 0.6893601872302868
Epoch: 73 | Iteration number: [280/565] 49% | Training loss: 0.6892612142222269
Epoch: 73 | Iteration number: [290/565] 51% | Training loss: 0.6891689793816929
Epoch: 73 | Iteration number: [300/565] 53% | Training loss: 0.6890814745426178
Epoch: 73 | Iteration number: [310/565] 54% | Training loss: 0.6890128750954905
Epoch: 73 | Iteration number: [320/565] 56% | Training loss: 0.6889490112662315
Epoch: 73 | Iteration number: [330/565] 58% | Training loss: 0.6888646866336013
Epoch: 73 | Iteration number: [340/565] 60% | Training loss: 0.6887932521455428
Epoch: 73 | Iteration number: [350/565] 61% | Training loss: 0.6887349990436009
Epoch: 73 | Iteration number: [360/565] 63% | Training loss: 0.6886734830008613
Epoch: 73 | Iteration number: [370/565] 65% | Training loss: 0.6886069644141841
Epoch: 73 | Iteration number: [380/565] 67% | Training loss: 0.6885666139815984
Epoch: 73 | Iteration number: [390/565] 69% | Training loss: 0.6885294497013092
Epoch: 73 | Iteration number: [400/565] 70% | Training loss: 0.6884958721697331
Epoch: 73 | Iteration number: [410/565] 72% | Training loss: 0.6884490785075397
Epoch: 73 | Iteration number: [420/565] 74% | Training loss: 0.68840933910438
Epoch: 73 | Iteration number: [430/565] 76% | Training loss: 0.6883614050787549
Epoch: 73 | Iteration number: [440/565] 77% | Training loss: 0.6883169942281463
Epoch: 73 | Iteration number: [450/565] 79% | Training loss: 0.6882845401763916
Epoch: 73 | Iteration number: [460/565] 81% | Training loss: 0.68826233835324
Epoch: 73 | Iteration number: [470/565] 83% | Training loss: 0.6882259259832666
Epoch: 73 | Iteration number: [480/565] 84% | Training loss: 0.688193712507685
Epoch: 73 | Iteration number: [490/565] 86% | Training loss: 0.688161405616877
Epoch: 73 | Iteration number: [500/565] 88% | Training loss: 0.6881385610103607
Epoch: 73 | Iteration number: [510/565] 90% | Training loss: 0.6881119739775564
Epoch: 73 | Iteration number: [520/565] 92% | Training loss: 0.6880964608146594
Epoch: 73 | Iteration number: [530/565] 93% | Training loss: 0.6880663655838877
Epoch: 73 | Iteration number: [540/565] 95% | Training loss: 0.6880405888513282
Epoch: 73 | Iteration number: [550/565] 97% | Training loss: 0.6880232734029943
Epoch: 73 | Iteration number: [560/565] 99% | Training loss: 0.688003396987915

 End of epoch: 73 | Train Loss: 0.686769469227411 | Training Time: 90 

 End of epoch: 73 | Eval Loss: 0.6897119283676147 | Evaluating Time: 5 
Epoch: 74 | Iteration number: [10/565] 1% | Training loss: 0.7556251883506775
Epoch: 74 | Iteration number: [20/565] 3% | Training loss: 0.7213274657726287
Epoch: 74 | Iteration number: [30/565] 5% | Training loss: 0.7099189301331837
Epoch: 74 | Iteration number: [40/565] 7% | Training loss: 0.7040670424699783
Epoch: 74 | Iteration number: [50/565] 8% | Training loss: 0.7007036674022674
Epoch: 74 | Iteration number: [60/565] 10% | Training loss: 0.6985083868106207
Epoch: 74 | Iteration number: [70/565] 12% | Training loss: 0.696812002147947
Epoch: 74 | Iteration number: [80/565] 14% | Training loss: 0.6956200733780861
Epoch: 74 | Iteration number: [90/565] 15% | Training loss: 0.6946370442708333
Epoch: 74 | Iteration number: [100/565] 17% | Training loss: 0.6938749819993972
Epoch: 74 | Iteration number: [110/565] 19% | Training loss: 0.6932148218154908
Epoch: 74 | Iteration number: [120/565] 21% | Training loss: 0.6926788831750552
Epoch: 74 | Iteration number: [130/565] 23% | Training loss: 0.6921981242986825
Epoch: 74 | Iteration number: [140/565] 24% | Training loss: 0.6918090522289276
Epoch: 74 | Iteration number: [150/565] 26% | Training loss: 0.6914667995770772
Epoch: 74 | Iteration number: [160/565] 28% | Training loss: 0.6911848653107882
Epoch: 74 | Iteration number: [170/565] 30% | Training loss: 0.6909297319019542
Epoch: 74 | Iteration number: [180/565] 31% | Training loss: 0.69069770971934
Epoch: 74 | Iteration number: [190/565] 33% | Training loss: 0.6904897495319969
Epoch: 74 | Iteration number: [200/565] 35% | Training loss: 0.6902868729829789
Epoch: 74 | Iteration number: [210/565] 37% | Training loss: 0.690102671157746
Epoch: 74 | Iteration number: [220/565] 38% | Training loss: 0.6899594472213225
Epoch: 74 | Iteration number: [230/565] 40% | Training loss: 0.6898305359094039
Epoch: 74 | Iteration number: [240/565] 42% | Training loss: 0.6896874676148097
Epoch: 74 | Iteration number: [250/565] 44% | Training loss: 0.6895841236114502
Epoch: 74 | Iteration number: [260/565] 46% | Training loss: 0.6894710664565746
Epoch: 74 | Iteration number: [270/565] 47% | Training loss: 0.6893699272915169
Epoch: 74 | Iteration number: [280/565] 49% | Training loss: 0.6892751944916589
Epoch: 74 | Iteration number: [290/565] 51% | Training loss: 0.6892073281880082
Epoch: 74 | Iteration number: [300/565] 53% | Training loss: 0.6891152304410935
Epoch: 74 | Iteration number: [310/565] 54% | Training loss: 0.6890239625207839
Epoch: 74 | Iteration number: [320/565] 56% | Training loss: 0.6889447422698141
Epoch: 74 | Iteration number: [330/565] 58% | Training loss: 0.6888830309564417
Epoch: 74 | Iteration number: [340/565] 60% | Training loss: 0.688821665153784
Epoch: 74 | Iteration number: [350/565] 61% | Training loss: 0.6887663379737309
Epoch: 74 | Iteration number: [360/565] 63% | Training loss: 0.6887157219979498
Epoch: 74 | Iteration number: [370/565] 65% | Training loss: 0.6886709955898491
Epoch: 74 | Iteration number: [380/565] 67% | Training loss: 0.6886184538665571
Epoch: 74 | Iteration number: [390/565] 69% | Training loss: 0.6885631926548786
Epoch: 74 | Iteration number: [400/565] 70% | Training loss: 0.6885030329227447
Epoch: 74 | Iteration number: [410/565] 72% | Training loss: 0.6884579655600758
Epoch: 74 | Iteration number: [420/565] 74% | Training loss: 0.6884248306353887
Epoch: 74 | Iteration number: [430/565] 76% | Training loss: 0.6883882051290467
Epoch: 74 | Iteration number: [440/565] 77% | Training loss: 0.6883449547670104
Epoch: 74 | Iteration number: [450/565] 79% | Training loss: 0.6883077736695608
Epoch: 74 | Iteration number: [460/565] 81% | Training loss: 0.6882822657408921
Epoch: 74 | Iteration number: [470/565] 83% | Training loss: 0.6882541766826142
Epoch: 74 | Iteration number: [480/565] 84% | Training loss: 0.6882210684319338
Epoch: 74 | Iteration number: [490/565] 86% | Training loss: 0.6881925596266377
Epoch: 74 | Iteration number: [500/565] 88% | Training loss: 0.6881762796640396
Epoch: 74 | Iteration number: [510/565] 90% | Training loss: 0.688142881673925
Epoch: 74 | Iteration number: [520/565] 92% | Training loss: 0.6881136763554353
Epoch: 74 | Iteration number: [530/565] 93% | Training loss: 0.6880974372602858
Epoch: 74 | Iteration number: [540/565] 95% | Training loss: 0.6880642280534461
Epoch: 74 | Iteration number: [550/565] 97% | Training loss: 0.6880279609290036
Epoch: 74 | Iteration number: [560/565] 99% | Training loss: 0.6880008577236107

 End of epoch: 74 | Train Loss: 0.6867726779617039 | Training Time: 91 

 End of epoch: 74 | Eval Loss: 0.6892783982413155 | Evaluating Time: 6 
Epoch: 75 | Iteration number: [10/565] 1% | Training loss: 0.7552062034606933
Epoch: 75 | Iteration number: [20/565] 3% | Training loss: 0.7208688944578171
Epoch: 75 | Iteration number: [30/565] 5% | Training loss: 0.7094537516434988
Epoch: 75 | Iteration number: [40/565] 7% | Training loss: 0.7037575826048851
Epoch: 75 | Iteration number: [50/565] 8% | Training loss: 0.7004049694538117
Epoch: 75 | Iteration number: [60/565] 10% | Training loss: 0.6981538861989975
Epoch: 75 | Iteration number: [70/565] 12% | Training loss: 0.696489862033299
Epoch: 75 | Iteration number: [80/565] 14% | Training loss: 0.695292429625988
Epoch: 75 | Iteration number: [90/565] 15% | Training loss: 0.69432300262981
Epoch: 75 | Iteration number: [100/565] 17% | Training loss: 0.6935855597257614
Epoch: 75 | Iteration number: [110/565] 19% | Training loss: 0.6929699838161468
Epoch: 75 | Iteration number: [120/565] 21% | Training loss: 0.6924759020407995
Epoch: 75 | Iteration number: [130/565] 23% | Training loss: 0.6919940091096438
Epoch: 75 | Iteration number: [140/565] 24% | Training loss: 0.6916160987956184
Epoch: 75 | Iteration number: [150/565] 26% | Training loss: 0.69126025557518
Epoch: 75 | Iteration number: [160/565] 28% | Training loss: 0.6909922540187836
Epoch: 75 | Iteration number: [170/565] 30% | Training loss: 0.6907598334200242
Epoch: 75 | Iteration number: [180/565] 31% | Training loss: 0.6905638923247656
Epoch: 75 | Iteration number: [190/565] 33% | Training loss: 0.690378223908575
Epoch: 75 | Iteration number: [200/565] 35% | Training loss: 0.690201570391655
Epoch: 75 | Iteration number: [210/565] 37% | Training loss: 0.6900260522252037
Epoch: 75 | Iteration number: [220/565] 38% | Training loss: 0.6898799134926362
Epoch: 75 | Iteration number: [230/565] 40% | Training loss: 0.6897533878036167
Epoch: 75 | Iteration number: [240/565] 42% | Training loss: 0.6896309743324915
Epoch: 75 | Iteration number: [250/565] 44% | Training loss: 0.6895018134117127
Epoch: 75 | Iteration number: [260/565] 46% | Training loss: 0.6894032047345088
Epoch: 75 | Iteration number: [270/565] 47% | Training loss: 0.6893196494491012
Epoch: 75 | Iteration number: [280/565] 49% | Training loss: 0.6892190369112151
Epoch: 75 | Iteration number: [290/565] 51% | Training loss: 0.6891275239401851
Epoch: 75 | Iteration number: [300/565] 53% | Training loss: 0.6890481865406036
Epoch: 75 | Iteration number: [310/565] 54% | Training loss: 0.6889809081631322
Epoch: 75 | Iteration number: [320/565] 56% | Training loss: 0.6889149377122521
Epoch: 75 | Iteration number: [330/565] 58% | Training loss: 0.6888603506666241
Epoch: 75 | Iteration number: [340/565] 60% | Training loss: 0.6888031198697931
Epoch: 75 | Iteration number: [350/565] 61% | Training loss: 0.688734313590186
Epoch: 75 | Iteration number: [360/565] 63% | Training loss: 0.6886948098738989
Epoch: 75 | Iteration number: [370/565] 65% | Training loss: 0.6886378127175409
Epoch: 75 | Iteration number: [380/565] 67% | Training loss: 0.6886054959736372
Epoch: 75 | Iteration number: [390/565] 69% | Training loss: 0.6885608289486322
Epoch: 75 | Iteration number: [400/565] 70% | Training loss: 0.6885226683318615
Epoch: 75 | Iteration number: [410/565] 72% | Training loss: 0.6884808413866089
Epoch: 75 | Iteration number: [420/565] 74% | Training loss: 0.6884420082682655
Epoch: 75 | Iteration number: [430/565] 76% | Training loss: 0.6884008424226628
Epoch: 75 | Iteration number: [440/565] 77% | Training loss: 0.6883692509748719
Epoch: 75 | Iteration number: [450/565] 79% | Training loss: 0.6883367391427359
Epoch: 75 | Iteration number: [460/565] 81% | Training loss: 0.6883040954237399
Epoch: 75 | Iteration number: [470/565] 83% | Training loss: 0.6882668654969398
Epoch: 75 | Iteration number: [480/565] 84% | Training loss: 0.6882355770717065
Epoch: 75 | Iteration number: [490/565] 86% | Training loss: 0.6881979373036599
Epoch: 75 | Iteration number: [500/565] 88% | Training loss: 0.6881654512882233
Epoch: 75 | Iteration number: [510/565] 90% | Training loss: 0.6881360181406433
Epoch: 75 | Iteration number: [520/565] 92% | Training loss: 0.6881050412471478
Epoch: 75 | Iteration number: [530/565] 93% | Training loss: 0.6880805024560892
Epoch: 75 | Iteration number: [540/565] 95% | Training loss: 0.6880528022845586
Epoch: 75 | Iteration number: [550/565] 97% | Training loss: 0.6880390110882846
Epoch: 75 | Iteration number: [560/565] 99% | Training loss: 0.6880141246531691

 End of epoch: 75 | Train Loss: 0.686785841304644 | Training Time: 90 

 End of epoch: 75 | Eval Loss: 0.6894520180565971 | Evaluating Time: 5 
Epoch: 76 | Iteration number: [10/565] 1% | Training loss: 0.7551070034503937
Epoch: 76 | Iteration number: [20/565] 3% | Training loss: 0.7211097061634064
Epoch: 76 | Iteration number: [30/565] 5% | Training loss: 0.7096295297145844
Epoch: 76 | Iteration number: [40/565] 7% | Training loss: 0.7037628203630447
Epoch: 76 | Iteration number: [50/565] 8% | Training loss: 0.7004348504543304
Epoch: 76 | Iteration number: [60/565] 10% | Training loss: 0.6981559405724208
Epoch: 76 | Iteration number: [70/565] 12% | Training loss: 0.6965340886797223
Epoch: 76 | Iteration number: [80/565] 14% | Training loss: 0.6953977689146995
Epoch: 76 | Iteration number: [90/565] 15% | Training loss: 0.6944741626580556
Epoch: 76 | Iteration number: [100/565] 17% | Training loss: 0.6936630886793137
Epoch: 76 | Iteration number: [110/565] 19% | Training loss: 0.6930099741979079
Epoch: 76 | Iteration number: [120/565] 21% | Training loss: 0.6924802511930466
Epoch: 76 | Iteration number: [130/565] 23% | Training loss: 0.6920696790401752
Epoch: 76 | Iteration number: [140/565] 24% | Training loss: 0.6916649733270918
Epoch: 76 | Iteration number: [150/565] 26% | Training loss: 0.6913532141844432
Epoch: 76 | Iteration number: [160/565] 28% | Training loss: 0.691093523055315
Epoch: 76 | Iteration number: [170/565] 30% | Training loss: 0.6908305154127233
Epoch: 76 | Iteration number: [180/565] 31% | Training loss: 0.6905983087089327
Epoch: 76 | Iteration number: [190/565] 33% | Training loss: 0.6904017661747179
Epoch: 76 | Iteration number: [200/565] 35% | Training loss: 0.69021607786417
Epoch: 76 | Iteration number: [210/565] 37% | Training loss: 0.6900566563719794
Epoch: 76 | Iteration number: [220/565] 38% | Training loss: 0.689911656759002
Epoch: 76 | Iteration number: [230/565] 40% | Training loss: 0.6897678349329077
Epoch: 76 | Iteration number: [240/565] 42% | Training loss: 0.6896618197361628
Epoch: 76 | Iteration number: [250/565] 44% | Training loss: 0.6895559427738189
Epoch: 76 | Iteration number: [260/565] 46% | Training loss: 0.6894580740195054
Epoch: 76 | Iteration number: [270/565] 47% | Training loss: 0.6893680053728598
Epoch: 76 | Iteration number: [280/565] 49% | Training loss: 0.6892540269664356
Epoch: 76 | Iteration number: [290/565] 51% | Training loss: 0.689168341817527
Epoch: 76 | Iteration number: [300/565] 53% | Training loss: 0.6890643598635992
Epoch: 76 | Iteration number: [310/565] 54% | Training loss: 0.6889763684042038
Epoch: 76 | Iteration number: [320/565] 56% | Training loss: 0.6889111189171672
Epoch: 76 | Iteration number: [330/565] 58% | Training loss: 0.6888572264801373
Epoch: 76 | Iteration number: [340/565] 60% | Training loss: 0.6887961366597344
Epoch: 76 | Iteration number: [350/565] 61% | Training loss: 0.6887357676029205
Epoch: 76 | Iteration number: [360/565] 63% | Training loss: 0.6886779826548365
Epoch: 76 | Iteration number: [370/565] 65% | Training loss: 0.6886365898557611
Epoch: 76 | Iteration number: [380/565] 67% | Training loss: 0.6885711116226096
Epoch: 76 | Iteration number: [390/565] 69% | Training loss: 0.6885139815318279
Epoch: 76 | Iteration number: [400/565] 70% | Training loss: 0.6884691616892815
Epoch: 76 | Iteration number: [410/565] 72% | Training loss: 0.6884336878613728
Epoch: 76 | Iteration number: [420/565] 74% | Training loss: 0.6883957762093771
Epoch: 76 | Iteration number: [430/565] 76% | Training loss: 0.6883452200612357
Epoch: 76 | Iteration number: [440/565] 77% | Training loss: 0.6883105664090676
Epoch: 76 | Iteration number: [450/565] 79% | Training loss: 0.688271922270457
Epoch: 76 | Iteration number: [460/565] 81% | Training loss: 0.6882432467263678
Epoch: 76 | Iteration number: [470/565] 83% | Training loss: 0.6882197726280131
Epoch: 76 | Iteration number: [480/565] 84% | Training loss: 0.6881981315712135
Epoch: 76 | Iteration number: [490/565] 86% | Training loss: 0.6881619246638551
Epoch: 76 | Iteration number: [500/565] 88% | Training loss: 0.6881390110254287
Epoch: 76 | Iteration number: [510/565] 90% | Training loss: 0.6881126209801318
Epoch: 76 | Iteration number: [520/565] 92% | Training loss: 0.6880897525411386
Epoch: 76 | Iteration number: [530/565] 93% | Training loss: 0.688069956032735
Epoch: 76 | Iteration number: [540/565] 95% | Training loss: 0.6880487557914522
Epoch: 76 | Iteration number: [550/565] 97% | Training loss: 0.6880272695151243
Epoch: 76 | Iteration number: [560/565] 99% | Training loss: 0.6880068054156644

 End of epoch: 76 | Train Loss: 0.6867789792803537 | Training Time: 91 

 End of epoch: 76 | Eval Loss: 0.6897451962743487 | Evaluating Time: 5 
Epoch: 77 | Iteration number: [10/565] 1% | Training loss: 0.7557378351688385
Epoch: 77 | Iteration number: [20/565] 3% | Training loss: 0.7212102919816971
Epoch: 77 | Iteration number: [30/565] 5% | Training loss: 0.709763503074646
Epoch: 77 | Iteration number: [40/565] 7% | Training loss: 0.7040637090802193
Epoch: 77 | Iteration number: [50/565] 8% | Training loss: 0.7006081438064575
Epoch: 77 | Iteration number: [60/565] 10% | Training loss: 0.6982682456572851
Epoch: 77 | Iteration number: [70/565] 12% | Training loss: 0.6966001229626791
Epoch: 77 | Iteration number: [80/565] 14% | Training loss: 0.695369054377079
Epoch: 77 | Iteration number: [90/565] 15% | Training loss: 0.6943679074446361
Epoch: 77 | Iteration number: [100/565] 17% | Training loss: 0.6935760778188705
Epoch: 77 | Iteration number: [110/565] 19% | Training loss: 0.6929237799210982
Epoch: 77 | Iteration number: [120/565] 21% | Training loss: 0.6924241642157237
Epoch: 77 | Iteration number: [130/565] 23% | Training loss: 0.6919993020020998
Epoch: 77 | Iteration number: [140/565] 24% | Training loss: 0.6916196129151753
Epoch: 77 | Iteration number: [150/565] 26% | Training loss: 0.6913166499137878
Epoch: 77 | Iteration number: [160/565] 28% | Training loss: 0.6910603526979685
Epoch: 77 | Iteration number: [170/565] 30% | Training loss: 0.6907847558750826
Epoch: 77 | Iteration number: [180/565] 31% | Training loss: 0.6905637992752923
Epoch: 77 | Iteration number: [190/565] 33% | Training loss: 0.6903790602558537
Epoch: 77 | Iteration number: [200/565] 35% | Training loss: 0.690196690261364
Epoch: 77 | Iteration number: [210/565] 37% | Training loss: 0.6900462255591437
Epoch: 77 | Iteration number: [220/565] 38% | Training loss: 0.6898711190982298
Epoch: 77 | Iteration number: [230/565] 40% | Training loss: 0.6897013511346735
Epoch: 77 | Iteration number: [240/565] 42% | Training loss: 0.6895682747165363
Epoch: 77 | Iteration number: [250/565] 44% | Training loss: 0.6894861938953399
Epoch: 77 | Iteration number: [260/565] 46% | Training loss: 0.6894032166554378
Epoch: 77 | Iteration number: [270/565] 47% | Training loss: 0.6892944241011584
Epoch: 77 | Iteration number: [280/565] 49% | Training loss: 0.6891987102372306
Epoch: 77 | Iteration number: [290/565] 51% | Training loss: 0.6891237883732236
Epoch: 77 | Iteration number: [300/565] 53% | Training loss: 0.6890426276127497
Epoch: 77 | Iteration number: [310/565] 54% | Training loss: 0.6889887223320622
Epoch: 77 | Iteration number: [320/565] 56% | Training loss: 0.6889108128845691
Epoch: 77 | Iteration number: [330/565] 58% | Training loss: 0.6888523101806641
Epoch: 77 | Iteration number: [340/565] 60% | Training loss: 0.6888029324657777
Epoch: 77 | Iteration number: [350/565] 61% | Training loss: 0.6887462193625314
Epoch: 77 | Iteration number: [360/565] 63% | Training loss: 0.6886859484844737
Epoch: 77 | Iteration number: [370/565] 65% | Training loss: 0.6886368381010519
Epoch: 77 | Iteration number: [380/565] 67% | Training loss: 0.68858453411805
Epoch: 77 | Iteration number: [390/565] 69% | Training loss: 0.6885176305587475
Epoch: 77 | Iteration number: [400/565] 70% | Training loss: 0.6884763684868812
Epoch: 77 | Iteration number: [410/565] 72% | Training loss: 0.6884367857037521
Epoch: 77 | Iteration number: [420/565] 74% | Training loss: 0.688400656410626
Epoch: 77 | Iteration number: [430/565] 76% | Training loss: 0.6883693531502125
Epoch: 77 | Iteration number: [440/565] 77% | Training loss: 0.6883358970284462
Epoch: 77 | Iteration number: [450/565] 79% | Training loss: 0.6882997804217869
Epoch: 77 | Iteration number: [460/565] 81% | Training loss: 0.6882743418216706
Epoch: 77 | Iteration number: [470/565] 83% | Training loss: 0.6882334591226374
Epoch: 77 | Iteration number: [480/565] 84% | Training loss: 0.6882066796223323
Epoch: 77 | Iteration number: [490/565] 86% | Training loss: 0.6881801394783721
Epoch: 77 | Iteration number: [500/565] 88% | Training loss: 0.6881450279951096
Epoch: 77 | Iteration number: [510/565] 90% | Training loss: 0.6881109819692723
Epoch: 77 | Iteration number: [520/565] 92% | Training loss: 0.68808140789087
Epoch: 77 | Iteration number: [530/565] 93% | Training loss: 0.688060244524254
Epoch: 77 | Iteration number: [540/565] 95% | Training loss: 0.6880325727992588
Epoch: 77 | Iteration number: [550/565] 97% | Training loss: 0.6880003572594036
Epoch: 77 | Iteration number: [560/565] 99% | Training loss: 0.6879867808095046

 End of epoch: 77 | Train Loss: 0.6867679767904028 | Training Time: 90 

 End of epoch: 77 | Eval Loss: 0.6897509949547904 | Evaluating Time: 5 
Epoch: 78 | Iteration number: [10/565] 1% | Training loss: 0.7556639194488526
Epoch: 78 | Iteration number: [20/565] 3% | Training loss: 0.7214490294456481
Epoch: 78 | Iteration number: [30/565] 5% | Training loss: 0.7098077277342478
Epoch: 78 | Iteration number: [40/565] 7% | Training loss: 0.7040646478533745
Epoch: 78 | Iteration number: [50/565] 8% | Training loss: 0.7007035303115845
Epoch: 78 | Iteration number: [60/565] 10% | Training loss: 0.6983449955781301
Epoch: 78 | Iteration number: [70/565] 12% | Training loss: 0.6967673948832921
Epoch: 78 | Iteration number: [80/565] 14% | Training loss: 0.6954530790448189
Epoch: 78 | Iteration number: [90/565] 15% | Training loss: 0.6944684127966563
Epoch: 78 | Iteration number: [100/565] 17% | Training loss: 0.693647552728653
Epoch: 78 | Iteration number: [110/565] 19% | Training loss: 0.6930657413872805
Epoch: 78 | Iteration number: [120/565] 21% | Training loss: 0.6925143669048945
Epoch: 78 | Iteration number: [130/565] 23% | Training loss: 0.6920999728716337
Epoch: 78 | Iteration number: [140/565] 24% | Training loss: 0.6916951158217022
Epoch: 78 | Iteration number: [150/565] 26% | Training loss: 0.6913722105820974
Epoch: 78 | Iteration number: [160/565] 28% | Training loss: 0.6910768177360296
Epoch: 78 | Iteration number: [170/565] 30% | Training loss: 0.6908008284428541
Epoch: 78 | Iteration number: [180/565] 31% | Training loss: 0.6905886163314183
Epoch: 78 | Iteration number: [190/565] 33% | Training loss: 0.6904228285739297
Epoch: 78 | Iteration number: [200/565] 35% | Training loss: 0.6902444359660148
Epoch: 78 | Iteration number: [210/565] 37% | Training loss: 0.6900671581427257
Epoch: 78 | Iteration number: [220/565] 38% | Training loss: 0.6899274801666087
Epoch: 78 | Iteration number: [230/565] 40% | Training loss: 0.6898010681504788
Epoch: 78 | Iteration number: [240/565] 42% | Training loss: 0.6896740563213826
Epoch: 78 | Iteration number: [250/565] 44% | Training loss: 0.6895579643249512
Epoch: 78 | Iteration number: [260/565] 46% | Training loss: 0.689475477200288
Epoch: 78 | Iteration number: [270/565] 47% | Training loss: 0.6893834537929959
Epoch: 78 | Iteration number: [280/565] 49% | Training loss: 0.6892780320984977
Epoch: 78 | Iteration number: [290/565] 51% | Training loss: 0.689206803461601
Epoch: 78 | Iteration number: [300/565] 53% | Training loss: 0.6891134476661682
Epoch: 78 | Iteration number: [310/565] 54% | Training loss: 0.6890358717210832
Epoch: 78 | Iteration number: [320/565] 56% | Training loss: 0.6889591759070754
Epoch: 78 | Iteration number: [330/565] 58% | Training loss: 0.6888774790547111
Epoch: 78 | Iteration number: [340/565] 60% | Training loss: 0.6888143125702353
Epoch: 78 | Iteration number: [350/565] 61% | Training loss: 0.6887525544847761
Epoch: 78 | Iteration number: [360/565] 63% | Training loss: 0.6886857625510957
Epoch: 78 | Iteration number: [370/565] 65% | Training loss: 0.6886281825400687
Epoch: 78 | Iteration number: [380/565] 67% | Training loss: 0.6885777418550693
Epoch: 78 | Iteration number: [390/565] 69% | Training loss: 0.6885282521064465
Epoch: 78 | Iteration number: [400/565] 70% | Training loss: 0.6884871001541615
Epoch: 78 | Iteration number: [410/565] 72% | Training loss: 0.6884525656700134
Epoch: 78 | Iteration number: [420/565] 74% | Training loss: 0.6884149960109166
Epoch: 78 | Iteration number: [430/565] 76% | Training loss: 0.6883778210296188
Epoch: 78 | Iteration number: [440/565] 77% | Training loss: 0.6883437606421384
Epoch: 78 | Iteration number: [450/565] 79% | Training loss: 0.6882995303471883
Epoch: 78 | Iteration number: [460/565] 81% | Training loss: 0.6882698753605718
Epoch: 78 | Iteration number: [470/565] 83% | Training loss: 0.6882299946977737
Epoch: 78 | Iteration number: [480/565] 84% | Training loss: 0.6881982572376728
Epoch: 78 | Iteration number: [490/565] 86% | Training loss: 0.68816855817425
Epoch: 78 | Iteration number: [500/565] 88% | Training loss: 0.6881403130292892
Epoch: 78 | Iteration number: [510/565] 90% | Training loss: 0.6881088941704994
Epoch: 78 | Iteration number: [520/565] 92% | Training loss: 0.6880848725254719
Epoch: 78 | Iteration number: [530/565] 93% | Training loss: 0.6880600713333993
Epoch: 78 | Iteration number: [540/565] 95% | Training loss: 0.6880492569119842
Epoch: 78 | Iteration number: [550/565] 97% | Training loss: 0.6880329662019556
Epoch: 78 | Iteration number: [560/565] 99% | Training loss: 0.6880053357354232

 End of epoch: 78 | Train Loss: 0.6867815825791486 | Training Time: 91 

 End of epoch: 78 | Eval Loss: 0.6899172152791705 | Evaluating Time: 5 
Epoch: 79 | Iteration number: [10/565] 1% | Training loss: 0.7551368594169616
Epoch: 79 | Iteration number: [20/565] 3% | Training loss: 0.7208716690540313
Epoch: 79 | Iteration number: [30/565] 5% | Training loss: 0.7094671090443929
Epoch: 79 | Iteration number: [40/565] 7% | Training loss: 0.7037868708372116
Epoch: 79 | Iteration number: [50/565] 8% | Training loss: 0.7003806817531586
Epoch: 79 | Iteration number: [60/565] 10% | Training loss: 0.6980606148640315
Epoch: 79 | Iteration number: [70/565] 12% | Training loss: 0.6965136570589883
Epoch: 79 | Iteration number: [80/565] 14% | Training loss: 0.6952984079718589
Epoch: 79 | Iteration number: [90/565] 15% | Training loss: 0.6943611873520745
Epoch: 79 | Iteration number: [100/565] 17% | Training loss: 0.6936115962266922
Epoch: 79 | Iteration number: [110/565] 19% | Training loss: 0.6929957454854792
Epoch: 79 | Iteration number: [120/565] 21% | Training loss: 0.6925030698378881
Epoch: 79 | Iteration number: [130/565] 23% | Training loss: 0.6920629547192501
Epoch: 79 | Iteration number: [140/565] 24% | Training loss: 0.6916632890701294
Epoch: 79 | Iteration number: [150/565] 26% | Training loss: 0.6913187793890635
Epoch: 79 | Iteration number: [160/565] 28% | Training loss: 0.6910346485674381
Epoch: 79 | Iteration number: [170/565] 30% | Training loss: 0.6907843929879806
Epoch: 79 | Iteration number: [180/565] 31% | Training loss: 0.690573842657937
Epoch: 79 | Iteration number: [190/565] 33% | Training loss: 0.690392415774496
Epoch: 79 | Iteration number: [200/565] 35% | Training loss: 0.6902048575878144
Epoch: 79 | Iteration number: [210/565] 37% | Training loss: 0.6900476058324178
Epoch: 79 | Iteration number: [220/565] 38% | Training loss: 0.6898944041945717
Epoch: 79 | Iteration number: [230/565] 40% | Training loss: 0.6897711048955503
Epoch: 79 | Iteration number: [240/565] 42% | Training loss: 0.6896332604189713
Epoch: 79 | Iteration number: [250/565] 44% | Training loss: 0.6895240149497985
Epoch: 79 | Iteration number: [260/565] 46% | Training loss: 0.689408429998618
Epoch: 79 | Iteration number: [270/565] 47% | Training loss: 0.6893135854491481
Epoch: 79 | Iteration number: [280/565] 49% | Training loss: 0.6892181441187859
Epoch: 79 | Iteration number: [290/565] 51% | Training loss: 0.689125053635959
Epoch: 79 | Iteration number: [300/565] 53% | Training loss: 0.6890435653924942
Epoch: 79 | Iteration number: [310/565] 54% | Training loss: 0.6889651235072843
Epoch: 79 | Iteration number: [320/565] 56% | Training loss: 0.6888894291594625
Epoch: 79 | Iteration number: [330/565] 58% | Training loss: 0.6888233737512068
Epoch: 79 | Iteration number: [340/565] 60% | Training loss: 0.6887754058136659
Epoch: 79 | Iteration number: [350/565] 61% | Training loss: 0.6887148305347988
Epoch: 79 | Iteration number: [360/565] 63% | Training loss: 0.6886602587170071
Epoch: 79 | Iteration number: [370/565] 65% | Training loss: 0.6886105311883463
Epoch: 79 | Iteration number: [380/565] 67% | Training loss: 0.6885626487041775
Epoch: 79 | Iteration number: [390/565] 69% | Training loss: 0.6885114619365105
Epoch: 79 | Iteration number: [400/565] 70% | Training loss: 0.6884722489118577
Epoch: 79 | Iteration number: [410/565] 72% | Training loss: 0.688432738693749
Epoch: 79 | Iteration number: [420/565] 74% | Training loss: 0.6883916061548959
Epoch: 79 | Iteration number: [430/565] 76% | Training loss: 0.6883599339529526
Epoch: 79 | Iteration number: [440/565] 77% | Training loss: 0.6883306787772612
Epoch: 79 | Iteration number: [450/565] 79% | Training loss: 0.6882966371377309
Epoch: 79 | Iteration number: [460/565] 81% | Training loss: 0.6882624421430671
Epoch: 79 | Iteration number: [470/565] 83% | Training loss: 0.6882238163592967
Epoch: 79 | Iteration number: [480/565] 84% | Training loss: 0.6881841254731019
Epoch: 79 | Iteration number: [490/565] 86% | Training loss: 0.6881558892678241
Epoch: 79 | Iteration number: [500/565] 88% | Training loss: 0.6881313602924347
Epoch: 79 | Iteration number: [510/565] 90% | Training loss: 0.6881066296614853
Epoch: 79 | Iteration number: [520/565] 92% | Training loss: 0.6880808292673184
Epoch: 79 | Iteration number: [530/565] 93% | Training loss: 0.6880662232075098
Epoch: 79 | Iteration number: [540/565] 95% | Training loss: 0.6880455044684587
Epoch: 79 | Iteration number: [550/565] 97% | Training loss: 0.68801415161653
Epoch: 79 | Iteration number: [560/565] 99% | Training loss: 0.6879898361861706

 End of epoch: 79 | Train Loss: 0.6867611212013042 | Training Time: 91 

 End of epoch: 79 | Eval Loss: 0.6897546819278172 | Evaluating Time: 5 
Epoch: 80 | Iteration number: [10/565] 1% | Training loss: 0.7556005775928497
Epoch: 80 | Iteration number: [20/565] 3% | Training loss: 0.7210959285497666
Epoch: 80 | Iteration number: [30/565] 5% | Training loss: 0.7096426308155059
Epoch: 80 | Iteration number: [40/565] 7% | Training loss: 0.7038592085242271
Epoch: 80 | Iteration number: [50/565] 8% | Training loss: 0.7004442358016968
Epoch: 80 | Iteration number: [60/565] 10% | Training loss: 0.6980651994546254
Epoch: 80 | Iteration number: [70/565] 12% | Training loss: 0.696456606047494
Epoch: 80 | Iteration number: [80/565] 14% | Training loss: 0.6952281802892685
Epoch: 80 | Iteration number: [90/565] 15% | Training loss: 0.6942998210589091
Epoch: 80 | Iteration number: [100/565] 17% | Training loss: 0.6935335779190064
Epoch: 80 | Iteration number: [110/565] 19% | Training loss: 0.6929105877876282
Epoch: 80 | Iteration number: [120/565] 21% | Training loss: 0.6924022977550824
Epoch: 80 | Iteration number: [130/565] 23% | Training loss: 0.691981728718831
Epoch: 80 | Iteration number: [140/565] 24% | Training loss: 0.6915927210024425
Epoch: 80 | Iteration number: [150/565] 26% | Training loss: 0.6912732402483622
Epoch: 80 | Iteration number: [160/565] 28% | Training loss: 0.6909859191626311
Epoch: 80 | Iteration number: [170/565] 30% | Training loss: 0.6907513916492463
Epoch: 80 | Iteration number: [180/565] 31% | Training loss: 0.6905332336823146
Epoch: 80 | Iteration number: [190/565] 33% | Training loss: 0.6903535115091424
Epoch: 80 | Iteration number: [200/565] 35% | Training loss: 0.6901711827516556
Epoch: 80 | Iteration number: [210/565] 37% | Training loss: 0.6899857617559887
Epoch: 80 | Iteration number: [220/565] 38% | Training loss: 0.6898472566496242
Epoch: 80 | Iteration number: [230/565] 40% | Training loss: 0.689712890593902
Epoch: 80 | Iteration number: [240/565] 42% | Training loss: 0.6895820592840513
Epoch: 80 | Iteration number: [250/565] 44% | Training loss: 0.6894640109539032
Epoch: 80 | Iteration number: [260/565] 46% | Training loss: 0.689367861701892
Epoch: 80 | Iteration number: [270/565] 47% | Training loss: 0.6892645990407026
Epoch: 80 | Iteration number: [280/565] 49% | Training loss: 0.6891757036958422
Epoch: 80 | Iteration number: [290/565] 51% | Training loss: 0.6891030774034302
Epoch: 80 | Iteration number: [300/565] 53% | Training loss: 0.6890058163801829
Epoch: 80 | Iteration number: [310/565] 54% | Training loss: 0.6889341600479618
Epoch: 80 | Iteration number: [320/565] 56% | Training loss: 0.6888709999620914
Epoch: 80 | Iteration number: [330/565] 58% | Training loss: 0.688810629013813
Epoch: 80 | Iteration number: [340/565] 60% | Training loss: 0.6887645405881545
Epoch: 80 | Iteration number: [350/565] 61% | Training loss: 0.6886864725181034
Epoch: 80 | Iteration number: [360/565] 63% | Training loss: 0.688625284201569
Epoch: 80 | Iteration number: [370/565] 65% | Training loss: 0.6885701361540202
Epoch: 80 | Iteration number: [380/565] 67% | Training loss: 0.688525452739314
Epoch: 80 | Iteration number: [390/565] 69% | Training loss: 0.688490344163699
Epoch: 80 | Iteration number: [400/565] 70% | Training loss: 0.6884498672187328
Epoch: 80 | Iteration number: [410/565] 72% | Training loss: 0.68841353058815
Epoch: 80 | Iteration number: [420/565] 74% | Training loss: 0.6883713364601135
Epoch: 80 | Iteration number: [430/565] 76% | Training loss: 0.6883396083532378
Epoch: 80 | Iteration number: [440/565] 77% | Training loss: 0.6882952197031541
Epoch: 80 | Iteration number: [450/565] 79% | Training loss: 0.6882678181595272
Epoch: 80 | Iteration number: [460/565] 81% | Training loss: 0.6882421025763388
Epoch: 80 | Iteration number: [470/565] 83% | Training loss: 0.688215619072001
Epoch: 80 | Iteration number: [480/565] 84% | Training loss: 0.6881882297496001
Epoch: 80 | Iteration number: [490/565] 86% | Training loss: 0.6881615955002454
Epoch: 80 | Iteration number: [500/565] 88% | Training loss: 0.6881282416582107
Epoch: 80 | Iteration number: [510/565] 90% | Training loss: 0.6880997469612197
Epoch: 80 | Iteration number: [520/565] 92% | Training loss: 0.6880843982100486
Epoch: 80 | Iteration number: [530/565] 93% | Training loss: 0.6880629039035653
Epoch: 80 | Iteration number: [540/565] 95% | Training loss: 0.6880301227172215
Epoch: 80 | Iteration number: [550/565] 97% | Training loss: 0.6880080039934678
Epoch: 80 | Iteration number: [560/565] 99% | Training loss: 0.6879909528153283

 End of epoch: 80 | Train Loss: 0.6867613600418631 | Training Time: 90 

 End of epoch: 80 | Eval Loss: 0.6898898908070156 | Evaluating Time: 5 
Epoch: 81 | Iteration number: [10/565] 1% | Training loss: 0.7555557906627655
Epoch: 81 | Iteration number: [20/565] 3% | Training loss: 0.7210631191730499
Epoch: 81 | Iteration number: [30/565] 5% | Training loss: 0.7095812817414602
Epoch: 81 | Iteration number: [40/565] 7% | Training loss: 0.7040018171072007
Epoch: 81 | Iteration number: [50/565] 8% | Training loss: 0.7005645322799683
Epoch: 81 | Iteration number: [60/565] 10% | Training loss: 0.6982943346103032
Epoch: 81 | Iteration number: [70/565] 12% | Training loss: 0.6966649736676898
Epoch: 81 | Iteration number: [80/565] 14% | Training loss: 0.6954073056578636
Epoch: 81 | Iteration number: [90/565] 15% | Training loss: 0.6944609966542986
Epoch: 81 | Iteration number: [100/565] 17% | Training loss: 0.693642765879631
Epoch: 81 | Iteration number: [110/565] 19% | Training loss: 0.6930377039042386
Epoch: 81 | Iteration number: [120/565] 21% | Training loss: 0.6925443217158318
Epoch: 81 | Iteration number: [130/565] 23% | Training loss: 0.6920675777471983
Epoch: 81 | Iteration number: [140/565] 24% | Training loss: 0.691689834850175
Epoch: 81 | Iteration number: [150/565] 26% | Training loss: 0.6913859689235687
Epoch: 81 | Iteration number: [160/565] 28% | Training loss: 0.6910452079027891
Epoch: 81 | Iteration number: [170/565] 30% | Training loss: 0.6908015026765711
Epoch: 81 | Iteration number: [180/565] 31% | Training loss: 0.6905700544516246
Epoch: 81 | Iteration number: [190/565] 33% | Training loss: 0.6903703507624175
Epoch: 81 | Iteration number: [200/565] 35% | Training loss: 0.6901869577169418
Epoch: 81 | Iteration number: [210/565] 37% | Training loss: 0.6900170950662522
Epoch: 81 | Iteration number: [220/565] 38% | Training loss: 0.689861569350416
Epoch: 81 | Iteration number: [230/565] 40% | Training loss: 0.6897574904172317
Epoch: 81 | Iteration number: [240/565] 42% | Training loss: 0.6896370882789294
Epoch: 81 | Iteration number: [250/565] 44% | Training loss: 0.6895306639671326
Epoch: 81 | Iteration number: [260/565] 46% | Training loss: 0.6894328000453802
Epoch: 81 | Iteration number: [270/565] 47% | Training loss: 0.689336218878075
Epoch: 81 | Iteration number: [280/565] 49% | Training loss: 0.6892401567527227
Epoch: 81 | Iteration number: [290/565] 51% | Training loss: 0.6891456347087334
Epoch: 81 | Iteration number: [300/565] 53% | Training loss: 0.6890709004799525
Epoch: 81 | Iteration number: [310/565] 54% | Training loss: 0.6889920403880457
Epoch: 81 | Iteration number: [320/565] 56% | Training loss: 0.6889216100797058
Epoch: 81 | Iteration number: [330/565] 58% | Training loss: 0.6888452692465349
Epoch: 81 | Iteration number: [340/565] 60% | Training loss: 0.6887754689244663
Epoch: 81 | Iteration number: [350/565] 61% | Training loss: 0.6887108434949603
Epoch: 81 | Iteration number: [360/565] 63% | Training loss: 0.6886530208918783
Epoch: 81 | Iteration number: [370/565] 65% | Training loss: 0.6885966793910877
Epoch: 81 | Iteration number: [380/565] 67% | Training loss: 0.6885380572394321
Epoch: 81 | Iteration number: [390/565] 69% | Training loss: 0.6884926705788343
Epoch: 81 | Iteration number: [400/565] 70% | Training loss: 0.6884444935619831
Epoch: 81 | Iteration number: [410/565] 72% | Training loss: 0.6883980982187318
Epoch: 81 | Iteration number: [420/565] 74% | Training loss: 0.6883583576906295
Epoch: 81 | Iteration number: [430/565] 76% | Training loss: 0.6883136481739754
Epoch: 81 | Iteration number: [440/565] 77% | Training loss: 0.6882765392010862
Epoch: 81 | Iteration number: [450/565] 79% | Training loss: 0.6882387553320991
Epoch: 81 | Iteration number: [460/565] 81% | Training loss: 0.6882153104180875
Epoch: 81 | Iteration number: [470/565] 83% | Training loss: 0.6881865606663075
Epoch: 81 | Iteration number: [480/565] 84% | Training loss: 0.6881610193600257
Epoch: 81 | Iteration number: [490/565] 86% | Training loss: 0.6881374682698931
Epoch: 81 | Iteration number: [500/565] 88% | Training loss: 0.6881129403114319
Epoch: 81 | Iteration number: [510/565] 90% | Training loss: 0.6880913413038441
Epoch: 81 | Iteration number: [520/565] 92% | Training loss: 0.6880737815911954
Epoch: 81 | Iteration number: [530/565] 93% | Training loss: 0.688043056681471
Epoch: 81 | Iteration number: [540/565] 95% | Training loss: 0.6880282278414126
Epoch: 81 | Iteration number: [550/565] 97% | Training loss: 0.6880070331963626
Epoch: 81 | Iteration number: [560/565] 99% | Training loss: 0.6879901097289154

 End of epoch: 81 | Train Loss: 0.6867603256639127 | Training Time: 91 

 End of epoch: 81 | Eval Loss: 0.6896013362067086 | Evaluating Time: 5 
Epoch: 82 | Iteration number: [10/565] 1% | Training loss: 0.7562484920024872
Epoch: 82 | Iteration number: [20/565] 3% | Training loss: 0.7215803325176239
Epoch: 82 | Iteration number: [30/565] 5% | Training loss: 0.7099977314472199
Epoch: 82 | Iteration number: [40/565] 7% | Training loss: 0.7041370168328285
Epoch: 82 | Iteration number: [50/565] 8% | Training loss: 0.7006557202339172
Epoch: 82 | Iteration number: [60/565] 10% | Training loss: 0.6984026253223419
Epoch: 82 | Iteration number: [70/565] 12% | Training loss: 0.6967127118791853
Epoch: 82 | Iteration number: [80/565] 14% | Training loss: 0.6954901725053787
Epoch: 82 | Iteration number: [90/565] 15% | Training loss: 0.694513816303677
Epoch: 82 | Iteration number: [100/565] 17% | Training loss: 0.6936754894256592
Epoch: 82 | Iteration number: [110/565] 19% | Training loss: 0.6929834430867975
Epoch: 82 | Iteration number: [120/565] 21% | Training loss: 0.692500568429629
Epoch: 82 | Iteration number: [130/565] 23% | Training loss: 0.6920677753595206
Epoch: 82 | Iteration number: [140/565] 24% | Training loss: 0.691709976536887
Epoch: 82 | Iteration number: [150/565] 26% | Training loss: 0.6913730728626252
Epoch: 82 | Iteration number: [160/565] 28% | Training loss: 0.6910680692642928
Epoch: 82 | Iteration number: [170/565] 30% | Training loss: 0.6908008060034584
Epoch: 82 | Iteration number: [180/565] 31% | Training loss: 0.6905930078691906
Epoch: 82 | Iteration number: [190/565] 33% | Training loss: 0.6904048813016791
Epoch: 82 | Iteration number: [200/565] 35% | Training loss: 0.6902566742897034
Epoch: 82 | Iteration number: [210/565] 37% | Training loss: 0.6901114194166093
Epoch: 82 | Iteration number: [220/565] 38% | Training loss: 0.6899664003740658
Epoch: 82 | Iteration number: [230/565] 40% | Training loss: 0.6898130507572837
Epoch: 82 | Iteration number: [240/565] 42% | Training loss: 0.6896912487844626
Epoch: 82 | Iteration number: [250/565] 44% | Training loss: 0.6895711781978607
Epoch: 82 | Iteration number: [260/565] 46% | Training loss: 0.68944913653227
Epoch: 82 | Iteration number: [270/565] 47% | Training loss: 0.6893648196149755
Epoch: 82 | Iteration number: [280/565] 49% | Training loss: 0.6892744234630039
Epoch: 82 | Iteration number: [290/565] 51% | Training loss: 0.6891791723925492
Epoch: 82 | Iteration number: [300/565] 53% | Training loss: 0.6890967820088069
Epoch: 82 | Iteration number: [310/565] 54% | Training loss: 0.6890095191617166
Epoch: 82 | Iteration number: [320/565] 56% | Training loss: 0.6889419877901674
Epoch: 82 | Iteration number: [330/565] 58% | Training loss: 0.6888697532090273
Epoch: 82 | Iteration number: [340/565] 60% | Training loss: 0.6888000221813426
Epoch: 82 | Iteration number: [350/565] 61% | Training loss: 0.6887455592836652
Epoch: 82 | Iteration number: [360/565] 63% | Training loss: 0.6886936907966932
Epoch: 82 | Iteration number: [370/565] 65% | Training loss: 0.6886275747337857
Epoch: 82 | Iteration number: [380/565] 67% | Training loss: 0.6885854824593193
Epoch: 82 | Iteration number: [390/565] 69% | Training loss: 0.6885516481521802
Epoch: 82 | Iteration number: [400/565] 70% | Training loss: 0.6885053692758083
Epoch: 82 | Iteration number: [410/565] 72% | Training loss: 0.6884628413653955
Epoch: 82 | Iteration number: [420/565] 74% | Training loss: 0.6884273327532269
Epoch: 82 | Iteration number: [430/565] 76% | Training loss: 0.6883788053379503
Epoch: 82 | Iteration number: [440/565] 77% | Training loss: 0.6883521726185625
Epoch: 82 | Iteration number: [450/565] 79% | Training loss: 0.6883145795928107
Epoch: 82 | Iteration number: [460/565] 81% | Training loss: 0.6882781658483588
Epoch: 82 | Iteration number: [470/565] 83% | Training loss: 0.6882536771449637
Epoch: 82 | Iteration number: [480/565] 84% | Training loss: 0.6882257502526045
Epoch: 82 | Iteration number: [490/565] 86% | Training loss: 0.6882001851286207
Epoch: 82 | Iteration number: [500/565] 88% | Training loss: 0.688172870516777
Epoch: 82 | Iteration number: [510/565] 90% | Training loss: 0.6881387627592274
Epoch: 82 | Iteration number: [520/565] 92% | Training loss: 0.6881040243002084
Epoch: 82 | Iteration number: [530/565] 93% | Training loss: 0.6880832751966872
Epoch: 82 | Iteration number: [540/565] 95% | Training loss: 0.6880568601466991
Epoch: 82 | Iteration number: [550/565] 97% | Training loss: 0.6880258668552746
Epoch: 82 | Iteration number: [560/565] 99% | Training loss: 0.6879970528185367

 End of epoch: 82 | Train Loss: 0.6867682933807373 | Training Time: 92 

 End of epoch: 82 | Eval Loss: 0.6894169194357735 | Evaluating Time: 5 
Epoch: 83 | Iteration number: [10/565] 1% | Training loss: 0.754957115650177
Epoch: 83 | Iteration number: [20/565] 3% | Training loss: 0.720920392870903
Epoch: 83 | Iteration number: [30/565] 5% | Training loss: 0.7093175192674
Epoch: 83 | Iteration number: [40/565] 7% | Training loss: 0.7036003097891808
Epoch: 83 | Iteration number: [50/565] 8% | Training loss: 0.7001243829727173
Epoch: 83 | Iteration number: [60/565] 10% | Training loss: 0.6979458411534627
Epoch: 83 | Iteration number: [70/565] 12% | Training loss: 0.696374442747661
Epoch: 83 | Iteration number: [80/565] 14% | Training loss: 0.6951426893472672
Epoch: 83 | Iteration number: [90/565] 15% | Training loss: 0.6942260894510481
Epoch: 83 | Iteration number: [100/565] 17% | Training loss: 0.6934987837076187
Epoch: 83 | Iteration number: [110/565] 19% | Training loss: 0.6928948380730369
Epoch: 83 | Iteration number: [120/565] 21% | Training loss: 0.6923660849531491
Epoch: 83 | Iteration number: [130/565] 23% | Training loss: 0.691962958757694
Epoch: 83 | Iteration number: [140/565] 24% | Training loss: 0.6915709729705538
Epoch: 83 | Iteration number: [150/565] 26% | Training loss: 0.6912430047988891
Epoch: 83 | Iteration number: [160/565] 28% | Training loss: 0.6909576952457428
Epoch: 83 | Iteration number: [170/565] 30% | Training loss: 0.6907216724227456
Epoch: 83 | Iteration number: [180/565] 31% | Training loss: 0.6905030737320582
Epoch: 83 | Iteration number: [190/565] 33% | Training loss: 0.6902950726057354
Epoch: 83 | Iteration number: [200/565] 35% | Training loss: 0.6901267364621162
Epoch: 83 | Iteration number: [210/565] 37% | Training loss: 0.6899497182596297
Epoch: 83 | Iteration number: [220/565] 38% | Training loss: 0.6898209642280232
Epoch: 83 | Iteration number: [230/565] 40% | Training loss: 0.6896992846675541
Epoch: 83 | Iteration number: [240/565] 42% | Training loss: 0.6895685123900572
Epoch: 83 | Iteration number: [250/565] 44% | Training loss: 0.6894646422863007
Epoch: 83 | Iteration number: [260/565] 46% | Training loss: 0.6893588233452577
Epoch: 83 | Iteration number: [270/565] 47% | Training loss: 0.6892629305521647
Epoch: 83 | Iteration number: [280/565] 49% | Training loss: 0.6891672064151083
Epoch: 83 | Iteration number: [290/565] 51% | Training loss: 0.689091099747296
Epoch: 83 | Iteration number: [300/565] 53% | Training loss: 0.6890126589934031
Epoch: 83 | Iteration number: [310/565] 54% | Training loss: 0.6889443678240622
Epoch: 83 | Iteration number: [320/565] 56% | Training loss: 0.6888750011101366
Epoch: 83 | Iteration number: [330/565] 58% | Training loss: 0.6888151340412371
Epoch: 83 | Iteration number: [340/565] 60% | Training loss: 0.6887500634964775
Epoch: 83 | Iteration number: [350/565] 61% | Training loss: 0.688691440139498
Epoch: 83 | Iteration number: [360/565] 63% | Training loss: 0.6886419148908721
Epoch: 83 | Iteration number: [370/565] 65% | Training loss: 0.6885907675768878
Epoch: 83 | Iteration number: [380/565] 67% | Training loss: 0.6885515343201788
Epoch: 83 | Iteration number: [390/565] 69% | Training loss: 0.6885128906139961
Epoch: 83 | Iteration number: [400/565] 70% | Training loss: 0.6884589467942714
Epoch: 83 | Iteration number: [410/565] 72% | Training loss: 0.6884240403407957
Epoch: 83 | Iteration number: [420/565] 74% | Training loss: 0.6883913883141108
Epoch: 83 | Iteration number: [430/565] 76% | Training loss: 0.6883491499479427
Epoch: 83 | Iteration number: [440/565] 77% | Training loss: 0.6883120103315874
Epoch: 83 | Iteration number: [450/565] 79% | Training loss: 0.688281057940589
Epoch: 83 | Iteration number: [460/565] 81% | Training loss: 0.6882381962693256
Epoch: 83 | Iteration number: [470/565] 83% | Training loss: 0.6882167601839025
Epoch: 83 | Iteration number: [480/565] 84% | Training loss: 0.6881801954160134
Epoch: 83 | Iteration number: [490/565] 86% | Training loss: 0.6881538038351098
Epoch: 83 | Iteration number: [500/565] 88% | Training loss: 0.6881304209232331
Epoch: 83 | Iteration number: [510/565] 90% | Training loss: 0.6880996378029094
Epoch: 83 | Iteration number: [520/565] 92% | Training loss: 0.6880725662295635
Epoch: 83 | Iteration number: [530/565] 93% | Training loss: 0.6880509740901444
Epoch: 83 | Iteration number: [540/565] 95% | Training loss: 0.688027940304191
Epoch: 83 | Iteration number: [550/565] 97% | Training loss: 0.6880076881972226
Epoch: 83 | Iteration number: [560/565] 99% | Training loss: 0.6879831852657454

 End of epoch: 83 | Train Loss: 0.6867591932811569 | Training Time: 90 

 End of epoch: 83 | Eval Loss: 0.6894594260624477 | Evaluating Time: 6 
Epoch: 84 | Iteration number: [10/565] 1% | Training loss: 0.7552622437477112
Epoch: 84 | Iteration number: [20/565] 3% | Training loss: 0.7210319906473159
Epoch: 84 | Iteration number: [30/565] 5% | Training loss: 0.7094522436459859
Epoch: 84 | Iteration number: [40/565] 7% | Training loss: 0.7037799090147019
Epoch: 84 | Iteration number: [50/565] 8% | Training loss: 0.7003404343128204
Epoch: 84 | Iteration number: [60/565] 10% | Training loss: 0.6980589310328166
Epoch: 84 | Iteration number: [70/565] 12% | Training loss: 0.6964321025780269
Epoch: 84 | Iteration number: [80/565] 14% | Training loss: 0.6952104449272156
Epoch: 84 | Iteration number: [90/565] 15% | Training loss: 0.6943027476469675
Epoch: 84 | Iteration number: [100/565] 17% | Training loss: 0.6935585772991181
Epoch: 84 | Iteration number: [110/565] 19% | Training loss: 0.6929461257024245
Epoch: 84 | Iteration number: [120/565] 21% | Training loss: 0.6924168646335602
Epoch: 84 | Iteration number: [130/565] 23% | Training loss: 0.6919825696028196
Epoch: 84 | Iteration number: [140/565] 24% | Training loss: 0.691603130527905
Epoch: 84 | Iteration number: [150/565] 26% | Training loss: 0.6913191719849905
Epoch: 84 | Iteration number: [160/565] 28% | Training loss: 0.6910205125808716
Epoch: 84 | Iteration number: [170/565] 30% | Training loss: 0.6907590136808508
Epoch: 84 | Iteration number: [180/565] 31% | Training loss: 0.6905285335249371
Epoch: 84 | Iteration number: [190/565] 33% | Training loss: 0.6903156791862689
Epoch: 84 | Iteration number: [200/565] 35% | Training loss: 0.6901472279429436
Epoch: 84 | Iteration number: [210/565] 37% | Training loss: 0.6899773725441524
Epoch: 84 | Iteration number: [220/565] 38% | Training loss: 0.6898338854312897
Epoch: 84 | Iteration number: [230/565] 40% | Training loss: 0.6897074945594953
Epoch: 84 | Iteration number: [240/565] 42% | Training loss: 0.6895930496354897
Epoch: 84 | Iteration number: [250/565] 44% | Training loss: 0.689469375371933
Epoch: 84 | Iteration number: [260/565] 46% | Training loss: 0.6893625743114031
Epoch: 84 | Iteration number: [270/565] 47% | Training loss: 0.6892696607995916
Epoch: 84 | Iteration number: [280/565] 49% | Training loss: 0.6891781768628529
Epoch: 84 | Iteration number: [290/565] 51% | Training loss: 0.6890870620464457
Epoch: 84 | Iteration number: [300/565] 53% | Training loss: 0.689017609556516
Epoch: 84 | Iteration number: [310/565] 54% | Training loss: 0.6889321065718128
Epoch: 84 | Iteration number: [320/565] 56% | Training loss: 0.6888669770210981
Epoch: 84 | Iteration number: [330/565] 58% | Training loss: 0.6887947111418753
Epoch: 84 | Iteration number: [340/565] 60% | Training loss: 0.6887443647665136
Epoch: 84 | Iteration number: [350/565] 61% | Training loss: 0.6886699308667864
Epoch: 84 | Iteration number: [360/565] 63% | Training loss: 0.6886220597558551
Epoch: 84 | Iteration number: [370/565] 65% | Training loss: 0.6885792323060937
Epoch: 84 | Iteration number: [380/565] 67% | Training loss: 0.6885297224709862
Epoch: 84 | Iteration number: [390/565] 69% | Training loss: 0.6884884744118421
Epoch: 84 | Iteration number: [400/565] 70% | Training loss: 0.6884422545135022
Epoch: 84 | Iteration number: [410/565] 72% | Training loss: 0.6884109633724864
Epoch: 84 | Iteration number: [420/565] 74% | Training loss: 0.6883908229214805
Epoch: 84 | Iteration number: [430/565] 76% | Training loss: 0.6883542595907699
Epoch: 84 | Iteration number: [440/565] 77% | Training loss: 0.6883195618336851
Epoch: 84 | Iteration number: [450/565] 79% | Training loss: 0.6882776990201738
Epoch: 84 | Iteration number: [460/565] 81% | Training loss: 0.6882398490024649
Epoch: 84 | Iteration number: [470/565] 83% | Training loss: 0.6882131937970506
Epoch: 84 | Iteration number: [480/565] 84% | Training loss: 0.6881744767228762
Epoch: 84 | Iteration number: [490/565] 86% | Training loss: 0.6881508454984548
Epoch: 84 | Iteration number: [500/565] 88% | Training loss: 0.6881284729242325
Epoch: 84 | Iteration number: [510/565] 90% | Training loss: 0.688094171589496
Epoch: 84 | Iteration number: [520/565] 92% | Training loss: 0.6880789112586242
Epoch: 84 | Iteration number: [530/565] 93% | Training loss: 0.6880507286989463
Epoch: 84 | Iteration number: [540/565] 95% | Training loss: 0.6880319989389844
Epoch: 84 | Iteration number: [550/565] 97% | Training loss: 0.6880093172463504
Epoch: 84 | Iteration number: [560/565] 99% | Training loss: 0.6879865003483636

 End of epoch: 84 | Train Loss: 0.686763066211633 | Training Time: 90 

 End of epoch: 84 | Eval Loss: 0.6893725395202637 | Evaluating Time: 6 
Epoch: 85 | Iteration number: [10/565] 1% | Training loss: 0.7556243777275086
Epoch: 85 | Iteration number: [20/565] 3% | Training loss: 0.7213104218244553
Epoch: 85 | Iteration number: [30/565] 5% | Training loss: 0.7098327120145161
Epoch: 85 | Iteration number: [40/565] 7% | Training loss: 0.704038842022419
Epoch: 85 | Iteration number: [50/565] 8% | Training loss: 0.7006186878681183
Epoch: 85 | Iteration number: [60/565] 10% | Training loss: 0.6983243236939113
Epoch: 85 | Iteration number: [70/565] 12% | Training loss: 0.6966716178825924
Epoch: 85 | Iteration number: [80/565] 14% | Training loss: 0.6953429244458675
Epoch: 85 | Iteration number: [90/565] 15% | Training loss: 0.694412687751982
Epoch: 85 | Iteration number: [100/565] 17% | Training loss: 0.693642019033432
Epoch: 85 | Iteration number: [110/565] 19% | Training loss: 0.693028103763407
Epoch: 85 | Iteration number: [120/565] 21% | Training loss: 0.6924990306297938
Epoch: 85 | Iteration number: [130/565] 23% | Training loss: 0.6920430907836327
Epoch: 85 | Iteration number: [140/565] 24% | Training loss: 0.6916701304061073
Epoch: 85 | Iteration number: [150/565] 26% | Training loss: 0.6913148891925812
Epoch: 85 | Iteration number: [160/565] 28% | Training loss: 0.6910221390426159
Epoch: 85 | Iteration number: [170/565] 30% | Training loss: 0.6908038865117466
Epoch: 85 | Iteration number: [180/565] 31% | Training loss: 0.6905808432234658
Epoch: 85 | Iteration number: [190/565] 33% | Training loss: 0.6903869685373808
Epoch: 85 | Iteration number: [200/565] 35% | Training loss: 0.6902039724588395
Epoch: 85 | Iteration number: [210/565] 37% | Training loss: 0.6900433957576751
Epoch: 85 | Iteration number: [220/565] 38% | Training loss: 0.6898817639459264
Epoch: 85 | Iteration number: [230/565] 40% | Training loss: 0.689761731935584
Epoch: 85 | Iteration number: [240/565] 42% | Training loss: 0.6896329507231712
Epoch: 85 | Iteration number: [250/565] 44% | Training loss: 0.6895041916370391
Epoch: 85 | Iteration number: [260/565] 46% | Training loss: 0.689409766288904
Epoch: 85 | Iteration number: [270/565] 47% | Training loss: 0.689332718760879
Epoch: 85 | Iteration number: [280/565] 49% | Training loss: 0.6892362715942519
Epoch: 85 | Iteration number: [290/565] 51% | Training loss: 0.6891597310016895
Epoch: 85 | Iteration number: [300/565] 53% | Training loss: 0.6890715579191844
Epoch: 85 | Iteration number: [310/565] 54% | Training loss: 0.6890112771141914
Epoch: 85 | Iteration number: [320/565] 56% | Training loss: 0.6889303997159004
Epoch: 85 | Iteration number: [330/565] 58% | Training loss: 0.6888760687726917
Epoch: 85 | Iteration number: [340/565] 60% | Training loss: 0.6888117465902778
Epoch: 85 | Iteration number: [350/565] 61% | Training loss: 0.6887594044208527
Epoch: 85 | Iteration number: [360/565] 63% | Training loss: 0.6887081149551604
Epoch: 85 | Iteration number: [370/565] 65% | Training loss: 0.6886399842597343
Epoch: 85 | Iteration number: [380/565] 67% | Training loss: 0.6885895067139676
Epoch: 85 | Iteration number: [390/565] 69% | Training loss: 0.6885533286974981
Epoch: 85 | Iteration number: [400/565] 70% | Training loss: 0.6885002802312374
Epoch: 85 | Iteration number: [410/565] 72% | Training loss: 0.6884405085226385
Epoch: 85 | Iteration number: [420/565] 74% | Training loss: 0.6884010262432553
Epoch: 85 | Iteration number: [430/565] 76% | Training loss: 0.6883557671724364
Epoch: 85 | Iteration number: [440/565] 77% | Training loss: 0.6883123339577155
Epoch: 85 | Iteration number: [450/565] 79% | Training loss: 0.6882775543795692
Epoch: 85 | Iteration number: [460/565] 81% | Training loss: 0.6882401945798293
Epoch: 85 | Iteration number: [470/565] 83% | Training loss: 0.688204553659926
Epoch: 85 | Iteration number: [480/565] 84% | Training loss: 0.6881722173343102
Epoch: 85 | Iteration number: [490/565] 86% | Training loss: 0.6881503207342965
Epoch: 85 | Iteration number: [500/565] 88% | Training loss: 0.6881207710504532
Epoch: 85 | Iteration number: [510/565] 90% | Training loss: 0.6880987893132603
Epoch: 85 | Iteration number: [520/565] 92% | Training loss: 0.6880798964546277
Epoch: 85 | Iteration number: [530/565] 93% | Training loss: 0.6880562750798351
Epoch: 85 | Iteration number: [540/565] 95% | Training loss: 0.6880436462384684
Epoch: 85 | Iteration number: [550/565] 97% | Training loss: 0.6880231662230059
Epoch: 85 | Iteration number: [560/565] 99% | Training loss: 0.6879996027265276

 End of epoch: 85 | Train Loss: 0.6867685899270319 | Training Time: 90 

 End of epoch: 85 | Eval Loss: 0.6894373978887286 | Evaluating Time: 5 
Epoch: 86 | Iteration number: [10/565] 1% | Training loss: 0.7548526167869568
Epoch: 86 | Iteration number: [20/565] 3% | Training loss: 0.7209098160266876
Epoch: 86 | Iteration number: [30/565] 5% | Training loss: 0.7092742502689362
Epoch: 86 | Iteration number: [40/565] 7% | Training loss: 0.7036177009344101
Epoch: 86 | Iteration number: [50/565] 8% | Training loss: 0.7002793204784393
Epoch: 86 | Iteration number: [60/565] 10% | Training loss: 0.6979705721139908
Epoch: 86 | Iteration number: [70/565] 12% | Training loss: 0.6964238549981798
Epoch: 86 | Iteration number: [80/565] 14% | Training loss: 0.6952482149004936
Epoch: 86 | Iteration number: [90/565] 15% | Training loss: 0.6943071610397763
Epoch: 86 | Iteration number: [100/565] 17% | Training loss: 0.6935949611663819
Epoch: 86 | Iteration number: [110/565] 19% | Training loss: 0.6929520612413232
Epoch: 86 | Iteration number: [120/565] 21% | Training loss: 0.6924443711837133
Epoch: 86 | Iteration number: [130/565] 23% | Training loss: 0.6919988751411438
Epoch: 86 | Iteration number: [140/565] 24% | Training loss: 0.6916298231908253
Epoch: 86 | Iteration number: [150/565] 26% | Training loss: 0.6912994937101999
Epoch: 86 | Iteration number: [160/565] 28% | Training loss: 0.6909981001168489
Epoch: 86 | Iteration number: [170/565] 30% | Training loss: 0.6907459069700802
Epoch: 86 | Iteration number: [180/565] 31% | Training loss: 0.6905101084046894
Epoch: 86 | Iteration number: [190/565] 33% | Training loss: 0.6903525540703221
Epoch: 86 | Iteration number: [200/565] 35% | Training loss: 0.6901684871315956
Epoch: 86 | Iteration number: [210/565] 37% | Training loss: 0.6899890388761248
Epoch: 86 | Iteration number: [220/565] 38% | Training loss: 0.689857414635745
Epoch: 86 | Iteration number: [230/565] 40% | Training loss: 0.6897351389345916
Epoch: 86 | Iteration number: [240/565] 42% | Training loss: 0.6896095645924409
Epoch: 86 | Iteration number: [250/565] 44% | Training loss: 0.6895038383007049
Epoch: 86 | Iteration number: [260/565] 46% | Training loss: 0.6893830077006267
Epoch: 86 | Iteration number: [270/565] 47% | Training loss: 0.6892830789089203
Epoch: 86 | Iteration number: [280/565] 49% | Training loss: 0.6891974819558008
Epoch: 86 | Iteration number: [290/565] 51% | Training loss: 0.6890956091469732
Epoch: 86 | Iteration number: [300/565] 53% | Training loss: 0.6890160346031189
Epoch: 86 | Iteration number: [310/565] 54% | Training loss: 0.6889472557652381
Epoch: 86 | Iteration number: [320/565] 56% | Training loss: 0.6888838954269886
Epoch: 86 | Iteration number: [330/565] 58% | Training loss: 0.6888051428578117
Epoch: 86 | Iteration number: [340/565] 60% | Training loss: 0.6887504186700372
Epoch: 86 | Iteration number: [350/565] 61% | Training loss: 0.688703087908881
Epoch: 86 | Iteration number: [360/565] 63% | Training loss: 0.6886541823546092
Epoch: 86 | Iteration number: [370/565] 65% | Training loss: 0.688591577233495
Epoch: 86 | Iteration number: [380/565] 67% | Training loss: 0.6885517016837471
Epoch: 86 | Iteration number: [390/565] 69% | Training loss: 0.6885018023160788
Epoch: 86 | Iteration number: [400/565] 70% | Training loss: 0.6884562601149082
Epoch: 86 | Iteration number: [410/565] 72% | Training loss: 0.6884079450514259
Epoch: 86 | Iteration number: [420/565] 74% | Training loss: 0.6883721029474622
Epoch: 86 | Iteration number: [430/565] 76% | Training loss: 0.6883201435554859
Epoch: 86 | Iteration number: [440/565] 77% | Training loss: 0.6882952573624525
Epoch: 86 | Iteration number: [450/565] 79% | Training loss: 0.688265135023329
Epoch: 86 | Iteration number: [460/565] 81% | Training loss: 0.6882447295862696
Epoch: 86 | Iteration number: [470/565] 83% | Training loss: 0.6882117941024456
Epoch: 86 | Iteration number: [480/565] 84% | Training loss: 0.6881805690626304
Epoch: 86 | Iteration number: [490/565] 86% | Training loss: 0.6881505308102588
Epoch: 86 | Iteration number: [500/565] 88% | Training loss: 0.6881338974237442
Epoch: 86 | Iteration number: [510/565] 90% | Training loss: 0.6881079427167481
Epoch: 86 | Iteration number: [520/565] 92% | Training loss: 0.6880802984421069
Epoch: 86 | Iteration number: [530/565] 93% | Training loss: 0.6880624360633346
Epoch: 86 | Iteration number: [540/565] 95% | Training loss: 0.6880374955910223
Epoch: 86 | Iteration number: [550/565] 97% | Training loss: 0.6880083338780837
Epoch: 86 | Iteration number: [560/565] 99% | Training loss: 0.6879887197698865

 End of epoch: 86 | Train Loss: 0.6867651805413508 | Training Time: 89 

 End of epoch: 86 | Eval Loss: 0.6895326035363334 | Evaluating Time: 6 
Epoch: 87 | Iteration number: [10/565] 1% | Training loss: 0.7557387411594391
Epoch: 87 | Iteration number: [20/565] 3% | Training loss: 0.7211853742599488
Epoch: 87 | Iteration number: [30/565] 5% | Training loss: 0.7097499748071034
Epoch: 87 | Iteration number: [40/565] 7% | Training loss: 0.7040190607309341
Epoch: 87 | Iteration number: [50/565] 8% | Training loss: 0.7006105697154998
Epoch: 87 | Iteration number: [60/565] 10% | Training loss: 0.6982733905315399
Epoch: 87 | Iteration number: [70/565] 12% | Training loss: 0.6966982253960201
Epoch: 87 | Iteration number: [80/565] 14% | Training loss: 0.695448063313961
Epoch: 87 | Iteration number: [90/565] 15% | Training loss: 0.6944887585110134
Epoch: 87 | Iteration number: [100/565] 17% | Training loss: 0.6937481606006622
Epoch: 87 | Iteration number: [110/565] 19% | Training loss: 0.6931269629435106
Epoch: 87 | Iteration number: [120/565] 21% | Training loss: 0.6925655260682106
Epoch: 87 | Iteration number: [130/565] 23% | Training loss: 0.6921564336006458
Epoch: 87 | Iteration number: [140/565] 24% | Training loss: 0.6917723391737257
Epoch: 87 | Iteration number: [150/565] 26% | Training loss: 0.6913953856627146
Epoch: 87 | Iteration number: [160/565] 28% | Training loss: 0.6911087863147258
Epoch: 87 | Iteration number: [170/565] 30% | Training loss: 0.6908473835271948
Epoch: 87 | Iteration number: [180/565] 31% | Training loss: 0.6906155857774946
Epoch: 87 | Iteration number: [190/565] 33% | Training loss: 0.6904386407450626
Epoch: 87 | Iteration number: [200/565] 35% | Training loss: 0.690283223092556
Epoch: 87 | Iteration number: [210/565] 37% | Training loss: 0.6901102625188373
Epoch: 87 | Iteration number: [220/565] 38% | Training loss: 0.6899538034742528
Epoch: 87 | Iteration number: [230/565] 40% | Training loss: 0.6898233022378839
Epoch: 87 | Iteration number: [240/565] 42% | Training loss: 0.6896943636238575
Epoch: 87 | Iteration number: [250/565] 44% | Training loss: 0.6895752487182617
Epoch: 87 | Iteration number: [260/565] 46% | Training loss: 0.6894703064973537
Epoch: 87 | Iteration number: [270/565] 47% | Training loss: 0.6893598748577966
Epoch: 87 | Iteration number: [280/565] 49% | Training loss: 0.6892760862197195
Epoch: 87 | Iteration number: [290/565] 51% | Training loss: 0.6892002983339902
Epoch: 87 | Iteration number: [300/565] 53% | Training loss: 0.689117948015531
Epoch: 87 | Iteration number: [310/565] 54% | Training loss: 0.6890478999383988
Epoch: 87 | Iteration number: [320/565] 56% | Training loss: 0.6889771128073334
Epoch: 87 | Iteration number: [330/565] 58% | Training loss: 0.6889147664561416
Epoch: 87 | Iteration number: [340/565] 60% | Training loss: 0.6888382953755996
Epoch: 87 | Iteration number: [350/565] 61% | Training loss: 0.6887762682778494
Epoch: 87 | Iteration number: [360/565] 63% | Training loss: 0.6887203257944848
Epoch: 87 | Iteration number: [370/565] 65% | Training loss: 0.6886640123418859
Epoch: 87 | Iteration number: [380/565] 67% | Training loss: 0.6886100370632975
Epoch: 87 | Iteration number: [390/565] 69% | Training loss: 0.6885549789819962
Epoch: 87 | Iteration number: [400/565] 70% | Training loss: 0.6885090377926827
Epoch: 87 | Iteration number: [410/565] 72% | Training loss: 0.6884692917509777
Epoch: 87 | Iteration number: [420/565] 74% | Training loss: 0.6884245805797122
Epoch: 87 | Iteration number: [430/565] 76% | Training loss: 0.6883787785851678
Epoch: 87 | Iteration number: [440/565] 77% | Training loss: 0.6883494024926966
Epoch: 87 | Iteration number: [450/565] 79% | Training loss: 0.6883121339480082
Epoch: 87 | Iteration number: [460/565] 81% | Training loss: 0.6882878101390341
Epoch: 87 | Iteration number: [470/565] 83% | Training loss: 0.6882467797461976
Epoch: 87 | Iteration number: [480/565] 84% | Training loss: 0.6882073577493429
Epoch: 87 | Iteration number: [490/565] 86% | Training loss: 0.688168054819107
Epoch: 87 | Iteration number: [500/565] 88% | Training loss: 0.6881434601545334
Epoch: 87 | Iteration number: [510/565] 90% | Training loss: 0.6881130497829587
Epoch: 87 | Iteration number: [520/565] 92% | Training loss: 0.6880831128129592
Epoch: 87 | Iteration number: [530/565] 93% | Training loss: 0.6880651333422031
Epoch: 87 | Iteration number: [540/565] 95% | Training loss: 0.6880423856002313
Epoch: 87 | Iteration number: [550/565] 97% | Training loss: 0.6880140500718896
Epoch: 87 | Iteration number: [560/565] 99% | Training loss: 0.6879890366324357

 End of epoch: 87 | Train Loss: 0.686758039271937 | Training Time: 90 

 End of epoch: 87 | Eval Loss: 0.689258371080671 | Evaluating Time: 6 
Epoch: 88 | Iteration number: [10/565] 1% | Training loss: 0.7559617817401886
Epoch: 88 | Iteration number: [20/565] 3% | Training loss: 0.7214046001434327
Epoch: 88 | Iteration number: [30/565] 5% | Training loss: 0.709909059604009
Epoch: 88 | Iteration number: [40/565] 7% | Training loss: 0.7041384503245354
Epoch: 88 | Iteration number: [50/565] 8% | Training loss: 0.7005628967285156
Epoch: 88 | Iteration number: [60/565] 10% | Training loss: 0.6982206205526987
Epoch: 88 | Iteration number: [70/565] 12% | Training loss: 0.696565877539771
Epoch: 88 | Iteration number: [80/565] 14% | Training loss: 0.6954096399247647
Epoch: 88 | Iteration number: [90/565] 15% | Training loss: 0.694495474629932
Epoch: 88 | Iteration number: [100/565] 17% | Training loss: 0.6936969131231308
Epoch: 88 | Iteration number: [110/565] 19% | Training loss: 0.6930766707116908
Epoch: 88 | Iteration number: [120/565] 21% | Training loss: 0.6925725966691971
Epoch: 88 | Iteration number: [130/565] 23% | Training loss: 0.6921094215833223
Epoch: 88 | Iteration number: [140/565] 24% | Training loss: 0.6916982063225338
Epoch: 88 | Iteration number: [150/565] 26% | Training loss: 0.691377408504486
Epoch: 88 | Iteration number: [160/565] 28% | Training loss: 0.6910818163305521
Epoch: 88 | Iteration number: [170/565] 30% | Training loss: 0.690835604948156
Epoch: 88 | Iteration number: [180/565] 31% | Training loss: 0.6906116118033727
Epoch: 88 | Iteration number: [190/565] 33% | Training loss: 0.6904029977949042
Epoch: 88 | Iteration number: [200/565] 35% | Training loss: 0.6902204608917236
Epoch: 88 | Iteration number: [210/565] 37% | Training loss: 0.6900478192738124
Epoch: 88 | Iteration number: [220/565] 38% | Training loss: 0.689886794036085
Epoch: 88 | Iteration number: [230/565] 40% | Training loss: 0.6897490205972091
Epoch: 88 | Iteration number: [240/565] 42% | Training loss: 0.6896424675981204
Epoch: 88 | Iteration number: [250/565] 44% | Training loss: 0.6895313944816589
Epoch: 88 | Iteration number: [260/565] 46% | Training loss: 0.6894359976053238
Epoch: 88 | Iteration number: [270/565] 47% | Training loss: 0.6893400549888611
Epoch: 88 | Iteration number: [280/565] 49% | Training loss: 0.6892311036586761
Epoch: 88 | Iteration number: [290/565] 51% | Training loss: 0.6891408404399608
Epoch: 88 | Iteration number: [300/565] 53% | Training loss: 0.6890618981917699
Epoch: 88 | Iteration number: [310/565] 54% | Training loss: 0.6889808172179807
Epoch: 88 | Iteration number: [320/565] 56% | Training loss: 0.688910998031497
Epoch: 88 | Iteration number: [330/565] 58% | Training loss: 0.6888543414347099
Epoch: 88 | Iteration number: [340/565] 60% | Training loss: 0.6887983511475956
Epoch: 88 | Iteration number: [350/565] 61% | Training loss: 0.6887471635001047
Epoch: 88 | Iteration number: [360/565] 63% | Training loss: 0.6886958753069242
Epoch: 88 | Iteration number: [370/565] 65% | Training loss: 0.6886538096376368
Epoch: 88 | Iteration number: [380/565] 67% | Training loss: 0.6886019463601866
Epoch: 88 | Iteration number: [390/565] 69% | Training loss: 0.688552938363491
Epoch: 88 | Iteration number: [400/565] 70% | Training loss: 0.6885066260397434
Epoch: 88 | Iteration number: [410/565] 72% | Training loss: 0.68846244797474
Epoch: 88 | Iteration number: [420/565] 74% | Training loss: 0.6884193969624383
Epoch: 88 | Iteration number: [430/565] 76% | Training loss: 0.6883802631566691
Epoch: 88 | Iteration number: [440/565] 77% | Training loss: 0.688346592811021
Epoch: 88 | Iteration number: [450/565] 79% | Training loss: 0.6883069672849443
Epoch: 88 | Iteration number: [460/565] 81% | Training loss: 0.6882791748513346
Epoch: 88 | Iteration number: [470/565] 83% | Training loss: 0.6882311369510408
Epoch: 88 | Iteration number: [480/565] 84% | Training loss: 0.6881996236741543
Epoch: 88 | Iteration number: [490/565] 86% | Training loss: 0.6881533147120963
Epoch: 88 | Iteration number: [500/565] 88% | Training loss: 0.6881246740818023
Epoch: 88 | Iteration number: [510/565] 90% | Training loss: 0.6880899311280718
Epoch: 88 | Iteration number: [520/565] 92% | Training loss: 0.6880682892524279
Epoch: 88 | Iteration number: [530/565] 93% | Training loss: 0.6880574741453495
Epoch: 88 | Iteration number: [540/565] 95% | Training loss: 0.6880400213930342
Epoch: 88 | Iteration number: [550/565] 97% | Training loss: 0.6880157498879866
Epoch: 88 | Iteration number: [560/565] 99% | Training loss: 0.6879959125603948

 End of epoch: 88 | Train Loss: 0.6867661962466958 | Training Time: 89 

 End of epoch: 88 | Eval Loss: 0.6889687435967582 | Evaluating Time: 6 
Epoch: 89 | Iteration number: [10/565] 1% | Training loss: 0.7552606046199799
Epoch: 89 | Iteration number: [20/565] 3% | Training loss: 0.7212140411138535
Epoch: 89 | Iteration number: [30/565] 5% | Training loss: 0.7097952485084533
Epoch: 89 | Iteration number: [40/565] 7% | Training loss: 0.704057589173317
Epoch: 89 | Iteration number: [50/565] 8% | Training loss: 0.700558043718338
Epoch: 89 | Iteration number: [60/565] 10% | Training loss: 0.6982485791047414
Epoch: 89 | Iteration number: [70/565] 12% | Training loss: 0.6966065330164773
Epoch: 89 | Iteration number: [80/565] 14% | Training loss: 0.6953729391098022
Epoch: 89 | Iteration number: [90/565] 15% | Training loss: 0.6944364223215315
Epoch: 89 | Iteration number: [100/565] 17% | Training loss: 0.6936532306671143
Epoch: 89 | Iteration number: [110/565] 19% | Training loss: 0.6930391653017565
Epoch: 89 | Iteration number: [120/565] 21% | Training loss: 0.6925085534652075
Epoch: 89 | Iteration number: [130/565] 23% | Training loss: 0.6920790154200334
Epoch: 89 | Iteration number: [140/565] 24% | Training loss: 0.6916785533939089
Epoch: 89 | Iteration number: [150/565] 26% | Training loss: 0.6913600965340932
Epoch: 89 | Iteration number: [160/565] 28% | Training loss: 0.6910569652915001
Epoch: 89 | Iteration number: [170/565] 30% | Training loss: 0.6908110348617329
Epoch: 89 | Iteration number: [180/565] 31% | Training loss: 0.6906169884734683
Epoch: 89 | Iteration number: [190/565] 33% | Training loss: 0.6903976591009843
Epoch: 89 | Iteration number: [200/565] 35% | Training loss: 0.6901984196901322
Epoch: 89 | Iteration number: [210/565] 37% | Training loss: 0.6900215989067441
Epoch: 89 | Iteration number: [220/565] 38% | Training loss: 0.6898874851790342
Epoch: 89 | Iteration number: [230/565] 40% | Training loss: 0.6897341202134671
Epoch: 89 | Iteration number: [240/565] 42% | Training loss: 0.6896162857611974
Epoch: 89 | Iteration number: [250/565] 44% | Training loss: 0.6895047225952149
Epoch: 89 | Iteration number: [260/565] 46% | Training loss: 0.6894057464141112
Epoch: 89 | Iteration number: [270/565] 47% | Training loss: 0.6893029005439193
Epoch: 89 | Iteration number: [280/565] 49% | Training loss: 0.6892256472791944
Epoch: 89 | Iteration number: [290/565] 51% | Training loss: 0.6891458114673351
Epoch: 89 | Iteration number: [300/565] 53% | Training loss: 0.6890405376752218
Epoch: 89 | Iteration number: [310/565] 54% | Training loss: 0.6889673179195773
Epoch: 89 | Iteration number: [320/565] 56% | Training loss: 0.6888890514150262
Epoch: 89 | Iteration number: [330/565] 58% | Training loss: 0.6888254736409043
Epoch: 89 | Iteration number: [340/565] 60% | Training loss: 0.6887610547682819
Epoch: 89 | Iteration number: [350/565] 61% | Training loss: 0.6887153244018555
Epoch: 89 | Iteration number: [360/565] 63% | Training loss: 0.6886631336477068
Epoch: 89 | Iteration number: [370/565] 65% | Training loss: 0.6886194155022904
Epoch: 89 | Iteration number: [380/565] 67% | Training loss: 0.6885677643512425
Epoch: 89 | Iteration number: [390/565] 69% | Training loss: 0.6885163670931107
Epoch: 89 | Iteration number: [400/565] 70% | Training loss: 0.6884595257043838
Epoch: 89 | Iteration number: [410/565] 72% | Training loss: 0.6884224775360852
Epoch: 89 | Iteration number: [420/565] 74% | Training loss: 0.6883829368012292
Epoch: 89 | Iteration number: [430/565] 76% | Training loss: 0.6883469741011775
Epoch: 89 | Iteration number: [440/565] 77% | Training loss: 0.6883071255954829
Epoch: 89 | Iteration number: [450/565] 79% | Training loss: 0.6882745928234524
Epoch: 89 | Iteration number: [460/565] 81% | Training loss: 0.6882447102795477
Epoch: 89 | Iteration number: [470/565] 83% | Training loss: 0.6882117776160545
Epoch: 89 | Iteration number: [480/565] 84% | Training loss: 0.6881741162389516
Epoch: 89 | Iteration number: [490/565] 86% | Training loss: 0.6881358454422075
Epoch: 89 | Iteration number: [500/565] 88% | Training loss: 0.6881105120182037
Epoch: 89 | Iteration number: [510/565] 90% | Training loss: 0.6880879507345312
Epoch: 89 | Iteration number: [520/565] 92% | Training loss: 0.6880713275991953
Epoch: 89 | Iteration number: [530/565] 93% | Training loss: 0.6880550907467896
Epoch: 89 | Iteration number: [540/565] 95% | Training loss: 0.6880321184794108
Epoch: 89 | Iteration number: [550/565] 97% | Training loss: 0.6880073378302834
Epoch: 89 | Iteration number: [560/565] 99% | Training loss: 0.6879818981247289

 End of epoch: 89 | Train Loss: 0.6867511019242548 | Training Time: 89 

 End of epoch: 89 | Eval Loss: 0.6895187241690499 | Evaluating Time: 6 
Epoch: 90 | Iteration number: [10/565] 1% | Training loss: 0.7551841378211975
Epoch: 90 | Iteration number: [20/565] 3% | Training loss: 0.7212011337280273
Epoch: 90 | Iteration number: [30/565] 5% | Training loss: 0.7095471938451131
Epoch: 90 | Iteration number: [40/565] 7% | Training loss: 0.7038753539323807
Epoch: 90 | Iteration number: [50/565] 8% | Training loss: 0.7005392456054688
Epoch: 90 | Iteration number: [60/565] 10% | Training loss: 0.6982743561267852
Epoch: 90 | Iteration number: [70/565] 12% | Training loss: 0.6966788223811559
Epoch: 90 | Iteration number: [80/565] 14% | Training loss: 0.6954271696507931
Epoch: 90 | Iteration number: [90/565] 15% | Training loss: 0.6945058577590518
Epoch: 90 | Iteration number: [100/565] 17% | Training loss: 0.6937294155359268
Epoch: 90 | Iteration number: [110/565] 19% | Training loss: 0.6931205104697834
Epoch: 90 | Iteration number: [120/565] 21% | Training loss: 0.6925368666648865
Epoch: 90 | Iteration number: [130/565] 23% | Training loss: 0.692116458599384
Epoch: 90 | Iteration number: [140/565] 24% | Training loss: 0.6917157573359353
Epoch: 90 | Iteration number: [150/565] 26% | Training loss: 0.6913701717058818
Epoch: 90 | Iteration number: [160/565] 28% | Training loss: 0.6910733859986067
Epoch: 90 | Iteration number: [170/565] 30% | Training loss: 0.6908351775477914
Epoch: 90 | Iteration number: [180/565] 31% | Training loss: 0.6906355814801322
Epoch: 90 | Iteration number: [190/565] 33% | Training loss: 0.6904323355147713
Epoch: 90 | Iteration number: [200/565] 35% | Training loss: 0.6902535435557365
Epoch: 90 | Iteration number: [210/565] 37% | Training loss: 0.6900868966465905
Epoch: 90 | Iteration number: [220/565] 38% | Training loss: 0.6899495338851755
Epoch: 90 | Iteration number: [230/565] 40% | Training loss: 0.6897899213044539
Epoch: 90 | Iteration number: [240/565] 42% | Training loss: 0.6896560075382392
Epoch: 90 | Iteration number: [250/565] 44% | Training loss: 0.6895424659252167
Epoch: 90 | Iteration number: [260/565] 46% | Training loss: 0.6894444034649776
Epoch: 90 | Iteration number: [270/565] 47% | Training loss: 0.6893574805171402
Epoch: 90 | Iteration number: [280/565] 49% | Training loss: 0.6892509707382747
Epoch: 90 | Iteration number: [290/565] 51% | Training loss: 0.6891660363509737
Epoch: 90 | Iteration number: [300/565] 53% | Training loss: 0.6890805631875991
Epoch: 90 | Iteration number: [310/565] 54% | Training loss: 0.68901245363297
Epoch: 90 | Iteration number: [320/565] 56% | Training loss: 0.6889329485595226
Epoch: 90 | Iteration number: [330/565] 58% | Training loss: 0.688875343763467
Epoch: 90 | Iteration number: [340/565] 60% | Training loss: 0.6888158377479104
Epoch: 90 | Iteration number: [350/565] 61% | Training loss: 0.6887625476292202
Epoch: 90 | Iteration number: [360/565] 63% | Training loss: 0.688702251513799
Epoch: 90 | Iteration number: [370/565] 65% | Training loss: 0.6886460104504147
Epoch: 90 | Iteration number: [380/565] 67% | Training loss: 0.6885983431025555
Epoch: 90 | Iteration number: [390/565] 69% | Training loss: 0.6885520140329997
Epoch: 90 | Iteration number: [400/565] 70% | Training loss: 0.6885138176381588
Epoch: 90 | Iteration number: [410/565] 72% | Training loss: 0.6884726418227685
Epoch: 90 | Iteration number: [420/565] 74% | Training loss: 0.688441473813284
Epoch: 90 | Iteration number: [430/565] 76% | Training loss: 0.6883970533692559
Epoch: 90 | Iteration number: [440/565] 77% | Training loss: 0.6883676385337656
Epoch: 90 | Iteration number: [450/565] 79% | Training loss: 0.6883445745044284
Epoch: 90 | Iteration number: [460/565] 81% | Training loss: 0.6883011836072673
Epoch: 90 | Iteration number: [470/565] 83% | Training loss: 0.6882599493290515
Epoch: 90 | Iteration number: [480/565] 84% | Training loss: 0.6882345036913952
Epoch: 90 | Iteration number: [490/565] 86% | Training loss: 0.6882019406678725
Epoch: 90 | Iteration number: [500/565] 88% | Training loss: 0.6881666653156281
Epoch: 90 | Iteration number: [510/565] 90% | Training loss: 0.6881329236077327
Epoch: 90 | Iteration number: [520/565] 92% | Training loss: 0.6881077654086627
Epoch: 90 | Iteration number: [530/565] 93% | Training loss: 0.6880884513540088
Epoch: 90 | Iteration number: [540/565] 95% | Training loss: 0.6880573787071087
Epoch: 90 | Iteration number: [550/565] 97% | Training loss: 0.6880389107357372
Epoch: 90 | Iteration number: [560/565] 99% | Training loss: 0.6880146195845944

 End of epoch: 90 | Train Loss: 0.6867874553773256 | Training Time: 89 

 End of epoch: 90 | Eval Loss: 0.6894295981952122 | Evaluating Time: 6 
Epoch: 91 | Iteration number: [10/565] 1% | Training loss: 0.7560660302639007
Epoch: 91 | Iteration number: [20/565] 3% | Training loss: 0.7214144974946975
Epoch: 91 | Iteration number: [30/565] 5% | Training loss: 0.7097885767618816
Epoch: 91 | Iteration number: [40/565] 7% | Training loss: 0.70400922447443
Epoch: 91 | Iteration number: [50/565] 8% | Training loss: 0.7004821586608887
Epoch: 91 | Iteration number: [60/565] 10% | Training loss: 0.6981539358695348
Epoch: 91 | Iteration number: [70/565] 12% | Training loss: 0.6965588390827179
Epoch: 91 | Iteration number: [80/565] 14% | Training loss: 0.695365709066391
Epoch: 91 | Iteration number: [90/565] 15% | Training loss: 0.6944060001108382
Epoch: 91 | Iteration number: [100/565] 17% | Training loss: 0.6936591470241547
Epoch: 91 | Iteration number: [110/565] 19% | Training loss: 0.6930188038132408
Epoch: 91 | Iteration number: [120/565] 21% | Training loss: 0.6924935321013133
Epoch: 91 | Iteration number: [130/565] 23% | Training loss: 0.6920427812979771
Epoch: 91 | Iteration number: [140/565] 24% | Training loss: 0.6916522064379284
Epoch: 91 | Iteration number: [150/565] 26% | Training loss: 0.6913213654359182
Epoch: 91 | Iteration number: [160/565] 28% | Training loss: 0.6910542819648982
Epoch: 91 | Iteration number: [170/565] 30% | Training loss: 0.69080391385976
Epoch: 91 | Iteration number: [180/565] 31% | Training loss: 0.6905829976002376
Epoch: 91 | Iteration number: [190/565] 33% | Training loss: 0.6903976032608434
Epoch: 91 | Iteration number: [200/565] 35% | Training loss: 0.6902148577570916
Epoch: 91 | Iteration number: [210/565] 37% | Training loss: 0.6900782437551589
Epoch: 91 | Iteration number: [220/565] 38% | Training loss: 0.6899335741996765
Epoch: 91 | Iteration number: [230/565] 40% | Training loss: 0.6897844034692515
Epoch: 91 | Iteration number: [240/565] 42% | Training loss: 0.6896323648591837
Epoch: 91 | Iteration number: [250/565] 44% | Training loss: 0.6895207901000977
Epoch: 91 | Iteration number: [260/565] 46% | Training loss: 0.6894190050088442
Epoch: 91 | Iteration number: [270/565] 47% | Training loss: 0.6893097879710021
Epoch: 91 | Iteration number: [280/565] 49% | Training loss: 0.6892125685300146
Epoch: 91 | Iteration number: [290/565] 51% | Training loss: 0.6891347494618646
Epoch: 91 | Iteration number: [300/565] 53% | Training loss: 0.6890578546126683
Epoch: 91 | Iteration number: [310/565] 54% | Training loss: 0.6890052441627749
Epoch: 91 | Iteration number: [320/565] 56% | Training loss: 0.6889335725456476
Epoch: 91 | Iteration number: [330/565] 58% | Training loss: 0.688862618894288
Epoch: 91 | Iteration number: [340/565] 60% | Training loss: 0.6888062652419595
Epoch: 91 | Iteration number: [350/565] 61% | Training loss: 0.688747193472726
Epoch: 91 | Iteration number: [360/565] 63% | Training loss: 0.6886938103371196
Epoch: 91 | Iteration number: [370/565] 65% | Training loss: 0.6886529060634407
Epoch: 91 | Iteration number: [380/565] 67% | Training loss: 0.6886070334597638
Epoch: 91 | Iteration number: [390/565] 69% | Training loss: 0.6885572635210477
Epoch: 91 | Iteration number: [400/565] 70% | Training loss: 0.6885012722015381
Epoch: 91 | Iteration number: [410/565] 72% | Training loss: 0.6884493794383072
Epoch: 91 | Iteration number: [420/565] 74% | Training loss: 0.6884204285485404
Epoch: 91 | Iteration number: [430/565] 76% | Training loss: 0.6883759750876316
Epoch: 91 | Iteration number: [440/565] 77% | Training loss: 0.6883471810004927
Epoch: 91 | Iteration number: [450/565] 79% | Training loss: 0.6883070850372315
Epoch: 91 | Iteration number: [460/565] 81% | Training loss: 0.6882767460916354
Epoch: 91 | Iteration number: [470/565] 83% | Training loss: 0.6882499841933555
Epoch: 91 | Iteration number: [480/565] 84% | Training loss: 0.6882086640844742
Epoch: 91 | Iteration number: [490/565] 86% | Training loss: 0.6881738864645666
Epoch: 91 | Iteration number: [500/565] 88% | Training loss: 0.6881468468904495
Epoch: 91 | Iteration number: [510/565] 90% | Training loss: 0.6881114903618307
Epoch: 91 | Iteration number: [520/565] 92% | Training loss: 0.6880890487478329
Epoch: 91 | Iteration number: [530/565] 93% | Training loss: 0.6880612973896962
Epoch: 91 | Iteration number: [540/565] 95% | Training loss: 0.688034278706268
Epoch: 91 | Iteration number: [550/565] 97% | Training loss: 0.6880079171874306
Epoch: 91 | Iteration number: [560/565] 99% | Training loss: 0.6879896664193699

 End of epoch: 91 | Train Loss: 0.6867621148582054 | Training Time: 88 

 End of epoch: 91 | Eval Loss: 0.6894312756402152 | Evaluating Time: 6 
Epoch: 92 | Iteration number: [10/565] 1% | Training loss: 0.755637526512146
Epoch: 92 | Iteration number: [20/565] 3% | Training loss: 0.7210255950689316
Epoch: 92 | Iteration number: [30/565] 5% | Training loss: 0.7096936027208964
Epoch: 92 | Iteration number: [40/565] 7% | Training loss: 0.7040552794933319
Epoch: 92 | Iteration number: [50/565] 8% | Training loss: 0.7005455517768859
Epoch: 92 | Iteration number: [60/565] 10% | Training loss: 0.6982355733712514
Epoch: 92 | Iteration number: [70/565] 12% | Training loss: 0.6965474801404136
Epoch: 92 | Iteration number: [80/565] 14% | Training loss: 0.6952694915235043
Epoch: 92 | Iteration number: [90/565] 15% | Training loss: 0.6943241821395026
Epoch: 92 | Iteration number: [100/565] 17% | Training loss: 0.6935373651981354
Epoch: 92 | Iteration number: [110/565] 19% | Training loss: 0.692929482460022
Epoch: 92 | Iteration number: [120/565] 21% | Training loss: 0.6924180333813031
Epoch: 92 | Iteration number: [130/565] 23% | Training loss: 0.6919849363657145
Epoch: 92 | Iteration number: [140/565] 24% | Training loss: 0.6916170669453484
Epoch: 92 | Iteration number: [150/565] 26% | Training loss: 0.6912808803717295
Epoch: 92 | Iteration number: [160/565] 28% | Training loss: 0.6909974724054336
Epoch: 92 | Iteration number: [170/565] 30% | Training loss: 0.6907871432164137
Epoch: 92 | Iteration number: [180/565] 31% | Training loss: 0.6905873672829734
Epoch: 92 | Iteration number: [190/565] 33% | Training loss: 0.6903832030923743
Epoch: 92 | Iteration number: [200/565] 35% | Training loss: 0.690220562517643
Epoch: 92 | Iteration number: [210/565] 37% | Training loss: 0.6900434224378496
Epoch: 92 | Iteration number: [220/565] 38% | Training loss: 0.6898855065757578
Epoch: 92 | Iteration number: [230/565] 40% | Training loss: 0.6897632795831431
Epoch: 92 | Iteration number: [240/565] 42% | Training loss: 0.6896404144664605
Epoch: 92 | Iteration number: [250/565] 44% | Training loss: 0.68952384018898
Epoch: 92 | Iteration number: [260/565] 46% | Training loss: 0.6894205226347997
Epoch: 92 | Iteration number: [270/565] 47% | Training loss: 0.6892980030289403
Epoch: 92 | Iteration number: [280/565] 49% | Training loss: 0.6891994084630694
Epoch: 92 | Iteration number: [290/565] 51% | Training loss: 0.6891156868687991
Epoch: 92 | Iteration number: [300/565] 53% | Training loss: 0.6890316379070281
Epoch: 92 | Iteration number: [310/565] 54% | Training loss: 0.6889545106118725
Epoch: 92 | Iteration number: [320/565] 56% | Training loss: 0.6888968421146273
Epoch: 92 | Iteration number: [330/565] 58% | Training loss: 0.6888446296706344
Epoch: 92 | Iteration number: [340/565] 60% | Training loss: 0.6887830713215997
Epoch: 92 | Iteration number: [350/565] 61% | Training loss: 0.6887232983112335
Epoch: 92 | Iteration number: [360/565] 63% | Training loss: 0.6886682738860448
Epoch: 92 | Iteration number: [370/565] 65% | Training loss: 0.6886116593270688
Epoch: 92 | Iteration number: [380/565] 67% | Training loss: 0.6885656802277816
Epoch: 92 | Iteration number: [390/565] 69% | Training loss: 0.6885263096063565
Epoch: 92 | Iteration number: [400/565] 70% | Training loss: 0.6884736934304237
Epoch: 92 | Iteration number: [410/565] 72% | Training loss: 0.6884349471185266
Epoch: 92 | Iteration number: [420/565] 74% | Training loss: 0.6884003317072278
Epoch: 92 | Iteration number: [430/565] 76% | Training loss: 0.6883608259433924
Epoch: 92 | Iteration number: [440/565] 77% | Training loss: 0.6883331908421083
Epoch: 92 | Iteration number: [450/565] 79% | Training loss: 0.6882997839980656
Epoch: 92 | Iteration number: [460/565] 81% | Training loss: 0.688263485353926
Epoch: 92 | Iteration number: [470/565] 83% | Training loss: 0.6882308754515141
Epoch: 92 | Iteration number: [480/565] 84% | Training loss: 0.6881882973015309
Epoch: 92 | Iteration number: [490/565] 86% | Training loss: 0.6881598044414909
Epoch: 92 | Iteration number: [500/565] 88% | Training loss: 0.6881287393569946
Epoch: 92 | Iteration number: [510/565] 90% | Training loss: 0.6881075883612914
Epoch: 92 | Iteration number: [520/565] 92% | Training loss: 0.6880768638390761
Epoch: 92 | Iteration number: [530/565] 93% | Training loss: 0.6880459827072215
Epoch: 92 | Iteration number: [540/565] 95% | Training loss: 0.6880206855358901
Epoch: 92 | Iteration number: [550/565] 97% | Training loss: 0.6879987070777199
Epoch: 92 | Iteration number: [560/565] 99% | Training loss: 0.6879764534533024

 End of epoch: 92 | Train Loss: 0.6867529622221415 | Training Time: 90 

 End of epoch: 92 | Eval Loss: 0.689508318901062 | Evaluating Time: 5 
Epoch: 93 | Iteration number: [10/565] 1% | Training loss: 0.7557700037956238
Epoch: 93 | Iteration number: [20/565] 3% | Training loss: 0.7214147627353669
Epoch: 93 | Iteration number: [30/565] 5% | Training loss: 0.7099557240804036
Epoch: 93 | Iteration number: [40/565] 7% | Training loss: 0.7041898921132088
Epoch: 93 | Iteration number: [50/565] 8% | Training loss: 0.7006337022781373
Epoch: 93 | Iteration number: [60/565] 10% | Training loss: 0.6983321378628413
Epoch: 93 | Iteration number: [70/565] 12% | Training loss: 0.696692897592272
Epoch: 93 | Iteration number: [80/565] 14% | Training loss: 0.6953922845423222
Epoch: 93 | Iteration number: [90/565] 15% | Training loss: 0.6944390171104007
Epoch: 93 | Iteration number: [100/565] 17% | Training loss: 0.6936202049255371
Epoch: 93 | Iteration number: [110/565] 19% | Training loss: 0.6930225648663261
Epoch: 93 | Iteration number: [120/565] 21% | Training loss: 0.6925036037961642
Epoch: 93 | Iteration number: [130/565] 23% | Training loss: 0.6920509618062239
Epoch: 93 | Iteration number: [140/565] 24% | Training loss: 0.6916868371622903
Epoch: 93 | Iteration number: [150/565] 26% | Training loss: 0.6913456046581268
Epoch: 93 | Iteration number: [160/565] 28% | Training loss: 0.6910590954124928
Epoch: 93 | Iteration number: [170/565] 30% | Training loss: 0.6908227710162892
Epoch: 93 | Iteration number: [180/565] 31% | Training loss: 0.6905977010726929
Epoch: 93 | Iteration number: [190/565] 33% | Training loss: 0.6903967775796589
Epoch: 93 | Iteration number: [200/565] 35% | Training loss: 0.690218368768692
Epoch: 93 | Iteration number: [210/565] 37% | Training loss: 0.6900435058843521
Epoch: 93 | Iteration number: [220/565] 38% | Training loss: 0.6898815474726937
Epoch: 93 | Iteration number: [230/565] 40% | Training loss: 0.6897327962129013
Epoch: 93 | Iteration number: [240/565] 42% | Training loss: 0.6896098233759403
Epoch: 93 | Iteration number: [250/565] 44% | Training loss: 0.6895009319782257
Epoch: 93 | Iteration number: [260/565] 46% | Training loss: 0.6893933099049788
Epoch: 93 | Iteration number: [270/565] 47% | Training loss: 0.6892885590041126
Epoch: 93 | Iteration number: [280/565] 49% | Training loss: 0.6891924006598337
Epoch: 93 | Iteration number: [290/565] 51% | Training loss: 0.6891240703648535
Epoch: 93 | Iteration number: [300/565] 53% | Training loss: 0.6890540792544683
Epoch: 93 | Iteration number: [310/565] 54% | Training loss: 0.6889813678879891
Epoch: 93 | Iteration number: [320/565] 56% | Training loss: 0.6889106461778283
Epoch: 93 | Iteration number: [330/565] 58% | Training loss: 0.6888512602358153
Epoch: 93 | Iteration number: [340/565] 60% | Training loss: 0.6887887167579988
Epoch: 93 | Iteration number: [350/565] 61% | Training loss: 0.6887214241709028
Epoch: 93 | Iteration number: [360/565] 63% | Training loss: 0.688670256237189
Epoch: 93 | Iteration number: [370/565] 65% | Training loss: 0.6886111222408914
Epoch: 93 | Iteration number: [380/565] 67% | Training loss: 0.6885706605095613
Epoch: 93 | Iteration number: [390/565] 69% | Training loss: 0.6885278545893155
Epoch: 93 | Iteration number: [400/565] 70% | Training loss: 0.6884822826087474
Epoch: 93 | Iteration number: [410/565] 72% | Training loss: 0.6884166905065862
Epoch: 93 | Iteration number: [420/565] 74% | Training loss: 0.6883851743879772
Epoch: 93 | Iteration number: [430/565] 76% | Training loss: 0.6883457382057988
Epoch: 93 | Iteration number: [440/565] 77% | Training loss: 0.688312994891947
Epoch: 93 | Iteration number: [450/565] 79% | Training loss: 0.6882808926370408
Epoch: 93 | Iteration number: [460/565] 81% | Training loss: 0.6882525512705678
Epoch: 93 | Iteration number: [470/565] 83% | Training loss: 0.6882165793408739
Epoch: 93 | Iteration number: [480/565] 84% | Training loss: 0.6881928037852049
Epoch: 93 | Iteration number: [490/565] 86% | Training loss: 0.6881603755513016
Epoch: 93 | Iteration number: [500/565] 88% | Training loss: 0.6881348975896835
Epoch: 93 | Iteration number: [510/565] 90% | Training loss: 0.6881076623411739
Epoch: 93 | Iteration number: [520/565] 92% | Training loss: 0.6880785326545055
Epoch: 93 | Iteration number: [530/565] 93% | Training loss: 0.6880538071101566
Epoch: 93 | Iteration number: [540/565] 95% | Training loss: 0.688035563075984
Epoch: 93 | Iteration number: [550/565] 97% | Training loss: 0.6880145311355591
Epoch: 93 | Iteration number: [560/565] 99% | Training loss: 0.6879792750946113

 End of epoch: 93 | Train Loss: 0.6867525630292639 | Training Time: 89 

 End of epoch: 93 | Eval Loss: 0.6897320832524981 | Evaluating Time: 6 
Epoch: 94 | Iteration number: [10/565] 1% | Training loss: 0.7550242185592652
Epoch: 94 | Iteration number: [20/565] 3% | Training loss: 0.7210199326276779
Epoch: 94 | Iteration number: [30/565] 5% | Training loss: 0.709572046995163
Epoch: 94 | Iteration number: [40/565] 7% | Training loss: 0.7038900554180145
Epoch: 94 | Iteration number: [50/565] 8% | Training loss: 0.7005636477470398
Epoch: 94 | Iteration number: [60/565] 10% | Training loss: 0.6982650230328242
Epoch: 94 | Iteration number: [70/565] 12% | Training loss: 0.6966538940157209
Epoch: 94 | Iteration number: [80/565] 14% | Training loss: 0.6954654812812805
Epoch: 94 | Iteration number: [90/565] 15% | Training loss: 0.6944893181324006
Epoch: 94 | Iteration number: [100/565] 17% | Training loss: 0.6937357753515243
Epoch: 94 | Iteration number: [110/565] 19% | Training loss: 0.6930955030701377
Epoch: 94 | Iteration number: [120/565] 21% | Training loss: 0.6925706878304482
Epoch: 94 | Iteration number: [130/565] 23% | Training loss: 0.6921332501448118
Epoch: 94 | Iteration number: [140/565] 24% | Training loss: 0.6917596463646207
Epoch: 94 | Iteration number: [150/565] 26% | Training loss: 0.6914158447583516
Epoch: 94 | Iteration number: [160/565] 28% | Training loss: 0.6911207977682352
Epoch: 94 | Iteration number: [170/565] 30% | Training loss: 0.6908555479610667
Epoch: 94 | Iteration number: [180/565] 31% | Training loss: 0.6906131360265944
Epoch: 94 | Iteration number: [190/565] 33% | Training loss: 0.690420462269532
Epoch: 94 | Iteration number: [200/565] 35% | Training loss: 0.6902623856067658
Epoch: 94 | Iteration number: [210/565] 37% | Training loss: 0.6901031005950201
Epoch: 94 | Iteration number: [220/565] 38% | Training loss: 0.6899548861113461
Epoch: 94 | Iteration number: [230/565] 40% | Training loss: 0.6898028718388599
Epoch: 94 | Iteration number: [240/565] 42% | Training loss: 0.689674421151479
Epoch: 94 | Iteration number: [250/565] 44% | Training loss: 0.6895591418743133
Epoch: 94 | Iteration number: [260/565] 46% | Training loss: 0.6894511869320503
Epoch: 94 | Iteration number: [270/565] 47% | Training loss: 0.689355546898312
Epoch: 94 | Iteration number: [280/565] 49% | Training loss: 0.6892792665532657
Epoch: 94 | Iteration number: [290/565] 51% | Training loss: 0.689207221105181
Epoch: 94 | Iteration number: [300/565] 53% | Training loss: 0.6891261231899262
Epoch: 94 | Iteration number: [310/565] 54% | Training loss: 0.6890365962059267
Epoch: 94 | Iteration number: [320/565] 56% | Training loss: 0.6889606412500143
Epoch: 94 | Iteration number: [330/565] 58% | Training loss: 0.6888945055730415
Epoch: 94 | Iteration number: [340/565] 60% | Training loss: 0.6888330974999596
Epoch: 94 | Iteration number: [350/565] 61% | Training loss: 0.6887784273283822
Epoch: 94 | Iteration number: [360/565] 63% | Training loss: 0.688725949327151
Epoch: 94 | Iteration number: [370/565] 65% | Training loss: 0.6886723573143417
Epoch: 94 | Iteration number: [380/565] 67% | Training loss: 0.6886213152032149
Epoch: 94 | Iteration number: [390/565] 69% | Training loss: 0.6885686232493474
Epoch: 94 | Iteration number: [400/565] 70% | Training loss: 0.688519572019577
Epoch: 94 | Iteration number: [410/565] 72% | Training loss: 0.6884623040513295
Epoch: 94 | Iteration number: [420/565] 74% | Training loss: 0.6884238636209852
Epoch: 94 | Iteration number: [430/565] 76% | Training loss: 0.6883902461029763
Epoch: 94 | Iteration number: [440/565] 77% | Training loss: 0.688346654041247
Epoch: 94 | Iteration number: [450/565] 79% | Training loss: 0.6883167619175381
Epoch: 94 | Iteration number: [460/565] 81% | Training loss: 0.68828264772892
Epoch: 94 | Iteration number: [470/565] 83% | Training loss: 0.6882469618574102
Epoch: 94 | Iteration number: [480/565] 84% | Training loss: 0.6882109665622314
Epoch: 94 | Iteration number: [490/565] 86% | Training loss: 0.68818120506345
Epoch: 94 | Iteration number: [500/565] 88% | Training loss: 0.6881517204046249
Epoch: 94 | Iteration number: [510/565] 90% | Training loss: 0.688116989883722
Epoch: 94 | Iteration number: [520/565] 92% | Training loss: 0.6880873728256959
Epoch: 94 | Iteration number: [530/565] 93% | Training loss: 0.6880605453590177
Epoch: 94 | Iteration number: [540/565] 95% | Training loss: 0.6880296510678751
Epoch: 94 | Iteration number: [550/565] 97% | Training loss: 0.6880056340044195
Epoch: 94 | Iteration number: [560/565] 99% | Training loss: 0.6879802153578827

 End of epoch: 94 | Train Loss: 0.6867512306280895 | Training Time: 91 

 End of epoch: 94 | Eval Loss: 0.688998145716531 | Evaluating Time: 6 
Epoch: 95 | Iteration number: [10/565] 1% | Training loss: 0.755716735124588
Epoch: 95 | Iteration number: [20/565] 3% | Training loss: 0.7212244868278503
Epoch: 95 | Iteration number: [30/565] 5% | Training loss: 0.7097265144189199
Epoch: 95 | Iteration number: [40/565] 7% | Training loss: 0.7038630828261375
Epoch: 95 | Iteration number: [50/565] 8% | Training loss: 0.7004110991954804
Epoch: 95 | Iteration number: [60/565] 10% | Training loss: 0.6981015314658483
Epoch: 95 | Iteration number: [70/565] 12% | Training loss: 0.6965130831514086
Epoch: 95 | Iteration number: [80/565] 14% | Training loss: 0.6952682934701443
Epoch: 95 | Iteration number: [90/565] 15% | Training loss: 0.6942725817362467
Epoch: 95 | Iteration number: [100/565] 17% | Training loss: 0.6935528492927552
Epoch: 95 | Iteration number: [110/565] 19% | Training loss: 0.6929461961442774
Epoch: 95 | Iteration number: [120/565] 21% | Training loss: 0.6924218147993088
Epoch: 95 | Iteration number: [130/565] 23% | Training loss: 0.6919652700424195
Epoch: 95 | Iteration number: [140/565] 24% | Training loss: 0.691599994472095
Epoch: 95 | Iteration number: [150/565] 26% | Training loss: 0.6912621096769969
Epoch: 95 | Iteration number: [160/565] 28% | Training loss: 0.6909715503454208
Epoch: 95 | Iteration number: [170/565] 30% | Training loss: 0.6907246424871333
Epoch: 95 | Iteration number: [180/565] 31% | Training loss: 0.6905050939983792
Epoch: 95 | Iteration number: [190/565] 33% | Training loss: 0.6902996458505329
Epoch: 95 | Iteration number: [200/565] 35% | Training loss: 0.6901561531424523
Epoch: 95 | Iteration number: [210/565] 37% | Training loss: 0.6900143248694284
Epoch: 95 | Iteration number: [220/565] 38% | Training loss: 0.6898573918776079
Epoch: 95 | Iteration number: [230/565] 40% | Training loss: 0.6897239021632983
Epoch: 95 | Iteration number: [240/565] 42% | Training loss: 0.6895721189677715
Epoch: 95 | Iteration number: [250/565] 44% | Training loss: 0.6894475440979004
Epoch: 95 | Iteration number: [260/565] 46% | Training loss: 0.6893341197417333
Epoch: 95 | Iteration number: [270/565] 47% | Training loss: 0.6892519233403382
Epoch: 95 | Iteration number: [280/565] 49% | Training loss: 0.6891493416258268
Epoch: 95 | Iteration number: [290/565] 51% | Training loss: 0.6890806148792136
Epoch: 95 | Iteration number: [300/565] 53% | Training loss: 0.6890101492404938
Epoch: 95 | Iteration number: [310/565] 54% | Training loss: 0.6889452286304966
Epoch: 95 | Iteration number: [320/565] 56% | Training loss: 0.6888837384060025
Epoch: 95 | Iteration number: [330/565] 58% | Training loss: 0.6888193495345838
Epoch: 95 | Iteration number: [340/565] 60% | Training loss: 0.6887727458687389
Epoch: 95 | Iteration number: [350/565] 61% | Training loss: 0.6887258567128862
Epoch: 95 | Iteration number: [360/565] 63% | Training loss: 0.6886718392372131
Epoch: 95 | Iteration number: [370/565] 65% | Training loss: 0.6886130247567152
Epoch: 95 | Iteration number: [380/565] 67% | Training loss: 0.6885669033778341
Epoch: 95 | Iteration number: [390/565] 69% | Training loss: 0.6885276337464651
Epoch: 95 | Iteration number: [400/565] 70% | Training loss: 0.6884765985608101
Epoch: 95 | Iteration number: [410/565] 72% | Training loss: 0.6884392204808025
Epoch: 95 | Iteration number: [420/565] 74% | Training loss: 0.6883949532395317
Epoch: 95 | Iteration number: [430/565] 76% | Training loss: 0.6883518123349478
Epoch: 95 | Iteration number: [440/565] 77% | Training loss: 0.6883209233934229
Epoch: 95 | Iteration number: [450/565] 79% | Training loss: 0.6882866581281026
Epoch: 95 | Iteration number: [460/565] 81% | Training loss: 0.688259825758312
Epoch: 95 | Iteration number: [470/565] 83% | Training loss: 0.6882291886400669
Epoch: 95 | Iteration number: [480/565] 84% | Training loss: 0.6881969557454188
Epoch: 95 | Iteration number: [490/565] 86% | Training loss: 0.6881698174136025
Epoch: 95 | Iteration number: [500/565] 88% | Training loss: 0.6881441224813462
Epoch: 95 | Iteration number: [510/565] 90% | Training loss: 0.6881158301643296
Epoch: 95 | Iteration number: [520/565] 92% | Training loss: 0.6880856739786955
Epoch: 95 | Iteration number: [530/565] 93% | Training loss: 0.6880581616230731
Epoch: 95 | Iteration number: [540/565] 95% | Training loss: 0.6880264583561155
Epoch: 95 | Iteration number: [550/565] 97% | Training loss: 0.6880012647672133
Epoch: 95 | Iteration number: [560/565] 99% | Training loss: 0.6879756941327027

 End of epoch: 95 | Train Loss: 0.6867496232015897 | Training Time: 90 

 End of epoch: 95 | Eval Loss: 0.6897163816860744 | Evaluating Time: 6 
Epoch: 96 | Iteration number: [10/565] 1% | Training loss: 0.7554634928703308
Epoch: 96 | Iteration number: [20/565] 3% | Training loss: 0.7211498051881791
Epoch: 96 | Iteration number: [30/565] 5% | Training loss: 0.7098225514094035
Epoch: 96 | Iteration number: [40/565] 7% | Training loss: 0.7040758788585663
Epoch: 96 | Iteration number: [50/565] 8% | Training loss: 0.7005485105514526
Epoch: 96 | Iteration number: [60/565] 10% | Training loss: 0.6982743481794993
Epoch: 96 | Iteration number: [70/565] 12% | Training loss: 0.6965960834707533
Epoch: 96 | Iteration number: [80/565] 14% | Training loss: 0.695395003259182
Epoch: 96 | Iteration number: [90/565] 15% | Training loss: 0.6944524261686537
Epoch: 96 | Iteration number: [100/565] 17% | Training loss: 0.6936401212215424
Epoch: 96 | Iteration number: [110/565] 19% | Training loss: 0.6930038056590341
Epoch: 96 | Iteration number: [120/565] 21% | Training loss: 0.6924741248289744
Epoch: 96 | Iteration number: [130/565] 23% | Training loss: 0.6919967582592598
Epoch: 96 | Iteration number: [140/565] 24% | Training loss: 0.691614373241152
Epoch: 96 | Iteration number: [150/565] 26% | Training loss: 0.6912805076440175
Epoch: 96 | Iteration number: [160/565] 28% | Training loss: 0.690974409878254
Epoch: 96 | Iteration number: [170/565] 30% | Training loss: 0.6907091550967273
Epoch: 96 | Iteration number: [180/565] 31% | Training loss: 0.6904985182815128
Epoch: 96 | Iteration number: [190/565] 33% | Training loss: 0.6903006265037939
Epoch: 96 | Iteration number: [200/565] 35% | Training loss: 0.6901517555117607
Epoch: 96 | Iteration number: [210/565] 37% | Training loss: 0.6899916348003206
Epoch: 96 | Iteration number: [220/565] 38% | Training loss: 0.6898330127651041
Epoch: 96 | Iteration number: [230/565] 40% | Training loss: 0.6896998664607172
Epoch: 96 | Iteration number: [240/565] 42% | Training loss: 0.6895981937646866
Epoch: 96 | Iteration number: [250/565] 44% | Training loss: 0.6894754915237427
Epoch: 96 | Iteration number: [260/565] 46% | Training loss: 0.6893716014348543
Epoch: 96 | Iteration number: [270/565] 47% | Training loss: 0.6892716370247028
Epoch: 96 | Iteration number: [280/565] 49% | Training loss: 0.6891636991075107
Epoch: 96 | Iteration number: [290/565] 51% | Training loss: 0.6890822120781602
Epoch: 96 | Iteration number: [300/565] 53% | Training loss: 0.6890205858151118
Epoch: 96 | Iteration number: [310/565] 54% | Training loss: 0.6889417606015359
Epoch: 96 | Iteration number: [320/565] 56% | Training loss: 0.6888776188716292
Epoch: 96 | Iteration number: [330/565] 58% | Training loss: 0.6888124350345496
Epoch: 96 | Iteration number: [340/565] 60% | Training loss: 0.6887569189071655
Epoch: 96 | Iteration number: [350/565] 61% | Training loss: 0.6887048184871674
Epoch: 96 | Iteration number: [360/565] 63% | Training loss: 0.6886551522546345
Epoch: 96 | Iteration number: [370/565] 65% | Training loss: 0.6886033507617744
Epoch: 96 | Iteration number: [380/565] 67% | Training loss: 0.6885452541865801
Epoch: 96 | Iteration number: [390/565] 69% | Training loss: 0.6884966028042329
Epoch: 96 | Iteration number: [400/565] 70% | Training loss: 0.688452582359314
Epoch: 96 | Iteration number: [410/565] 72% | Training loss: 0.6884137076575582
Epoch: 96 | Iteration number: [420/565] 74% | Training loss: 0.6883798102537791
Epoch: 96 | Iteration number: [430/565] 76% | Training loss: 0.6883394908073337
Epoch: 96 | Iteration number: [440/565] 77% | Training loss: 0.6883093802766367
Epoch: 96 | Iteration number: [450/565] 79% | Training loss: 0.6882882322205438
Epoch: 96 | Iteration number: [460/565] 81% | Training loss: 0.688262233397235
Epoch: 96 | Iteration number: [470/565] 83% | Training loss: 0.6882259574342281
Epoch: 96 | Iteration number: [480/565] 84% | Training loss: 0.6881902125974496
Epoch: 96 | Iteration number: [490/565] 86% | Training loss: 0.6881629622712427
Epoch: 96 | Iteration number: [500/565] 88% | Training loss: 0.6881363781690597
Epoch: 96 | Iteration number: [510/565] 90% | Training loss: 0.688107587776932
Epoch: 96 | Iteration number: [520/565] 92% | Training loss: 0.6880772250202986
Epoch: 96 | Iteration number: [530/565] 93% | Training loss: 0.688048676387319
Epoch: 96 | Iteration number: [540/565] 95% | Training loss: 0.6880253780771185
Epoch: 96 | Iteration number: [550/565] 97% | Training loss: 0.6879911642724817
Epoch: 96 | Iteration number: [560/565] 99% | Training loss: 0.6879662035831383

 End of epoch: 96 | Train Loss: 0.6867456939368122 | Training Time: 90 

 End of epoch: 96 | Eval Loss: 0.6898422922406878 | Evaluating Time: 6 
Epoch: 97 | Iteration number: [10/565] 1% | Training loss: 0.7550998389720917
Epoch: 97 | Iteration number: [20/565] 3% | Training loss: 0.721024465560913
Epoch: 97 | Iteration number: [30/565] 5% | Training loss: 0.7095518231391906
Epoch: 97 | Iteration number: [40/565] 7% | Training loss: 0.7037997081875801
Epoch: 97 | Iteration number: [50/565] 8% | Training loss: 0.7004311347007751
Epoch: 97 | Iteration number: [60/565] 10% | Training loss: 0.6981384247541428
Epoch: 97 | Iteration number: [70/565] 12% | Training loss: 0.6965007134846278
Epoch: 97 | Iteration number: [80/565] 14% | Training loss: 0.6952719606459141
Epoch: 97 | Iteration number: [90/565] 15% | Training loss: 0.69432719151179
Epoch: 97 | Iteration number: [100/565] 17% | Training loss: 0.6935311889648438
Epoch: 97 | Iteration number: [110/565] 19% | Training loss: 0.6929172694683075
Epoch: 97 | Iteration number: [120/565] 21% | Training loss: 0.6923595448335012
Epoch: 97 | Iteration number: [130/565] 23% | Training loss: 0.6919249552946825
Epoch: 97 | Iteration number: [140/565] 24% | Training loss: 0.6915361936603274
Epoch: 97 | Iteration number: [150/565] 26% | Training loss: 0.6912368945280711
Epoch: 97 | Iteration number: [160/565] 28% | Training loss: 0.6909552767872811
Epoch: 97 | Iteration number: [170/565] 30% | Training loss: 0.6907161491758683
Epoch: 97 | Iteration number: [180/565] 31% | Training loss: 0.6904940899875429
Epoch: 97 | Iteration number: [190/565] 33% | Training loss: 0.6903329827283559
Epoch: 97 | Iteration number: [200/565] 35% | Training loss: 0.6901467296481133
Epoch: 97 | Iteration number: [210/565] 37% | Training loss: 0.6899988072259086
Epoch: 97 | Iteration number: [220/565] 38% | Training loss: 0.6898525007746437
Epoch: 97 | Iteration number: [230/565] 40% | Training loss: 0.6897129403508228
Epoch: 97 | Iteration number: [240/565] 42% | Training loss: 0.689590980609258
Epoch: 97 | Iteration number: [250/565] 44% | Training loss: 0.6894688746929168
Epoch: 97 | Iteration number: [260/565] 46% | Training loss: 0.6893864475763761
Epoch: 97 | Iteration number: [270/565] 47% | Training loss: 0.6893128346513819
Epoch: 97 | Iteration number: [280/565] 49% | Training loss: 0.6892211424452918
Epoch: 97 | Iteration number: [290/565] 51% | Training loss: 0.6891181181217062
Epoch: 97 | Iteration number: [300/565] 53% | Training loss: 0.6890423387289047
Epoch: 97 | Iteration number: [310/565] 54% | Training loss: 0.6889584270215804
Epoch: 97 | Iteration number: [320/565] 56% | Training loss: 0.6888906337320805
Epoch: 97 | Iteration number: [330/565] 58% | Training loss: 0.6888093502232523
Epoch: 97 | Iteration number: [340/565] 60% | Training loss: 0.6887622580808752
Epoch: 97 | Iteration number: [350/565] 61% | Training loss: 0.6887062861238207
Epoch: 97 | Iteration number: [360/565] 63% | Training loss: 0.68867147349649
Epoch: 97 | Iteration number: [370/565] 65% | Training loss: 0.688611276246406
Epoch: 97 | Iteration number: [380/565] 67% | Training loss: 0.688571467681935
Epoch: 97 | Iteration number: [390/565] 69% | Training loss: 0.6885245780150095
Epoch: 97 | Iteration number: [400/565] 70% | Training loss: 0.6884736032783985
Epoch: 97 | Iteration number: [410/565] 72% | Training loss: 0.6884386910171043
Epoch: 97 | Iteration number: [420/565] 74% | Training loss: 0.688398774606841
Epoch: 97 | Iteration number: [430/565] 76% | Training loss: 0.6883679352527441
Epoch: 97 | Iteration number: [440/565] 77% | Training loss: 0.68833071697842
Epoch: 97 | Iteration number: [450/565] 79% | Training loss: 0.6882991259627872
Epoch: 97 | Iteration number: [460/565] 81% | Training loss: 0.6882551695989526
Epoch: 97 | Iteration number: [470/565] 83% | Training loss: 0.6882277510267623
Epoch: 97 | Iteration number: [480/565] 84% | Training loss: 0.6881916577617327
Epoch: 97 | Iteration number: [490/565] 86% | Training loss: 0.6881614815215675
Epoch: 97 | Iteration number: [500/565] 88% | Training loss: 0.6881243313550949
Epoch: 97 | Iteration number: [510/565] 90% | Training loss: 0.6880995672123105
Epoch: 97 | Iteration number: [520/565] 92% | Training loss: 0.6880698379415732
Epoch: 97 | Iteration number: [530/565] 93% | Training loss: 0.6880482453220296
Epoch: 97 | Iteration number: [540/565] 95% | Training loss: 0.6880232265702
Epoch: 97 | Iteration number: [550/565] 97% | Training loss: 0.6880027410117062
Epoch: 97 | Iteration number: [560/565] 99% | Training loss: 0.6879727741437299

 End of epoch: 97 | Train Loss: 0.6867511899070402 | Training Time: 91 

 End of epoch: 97 | Eval Loss: 0.6891369308744159 | Evaluating Time: 5 
Epoch: 98 | Iteration number: [10/565] 1% | Training loss: 0.7552623212337494
Epoch: 98 | Iteration number: [20/565] 3% | Training loss: 0.7211450338363647
Epoch: 98 | Iteration number: [30/565] 5% | Training loss: 0.7096926450729371
Epoch: 98 | Iteration number: [40/565] 7% | Training loss: 0.7040046423673629
Epoch: 98 | Iteration number: [50/565] 8% | Training loss: 0.700540292263031
Epoch: 98 | Iteration number: [60/565] 10% | Training loss: 0.6982627292474111
Epoch: 98 | Iteration number: [70/565] 12% | Training loss: 0.6965942578656333
Epoch: 98 | Iteration number: [80/565] 14% | Training loss: 0.6954122059047222
Epoch: 98 | Iteration number: [90/565] 15% | Training loss: 0.6944701141781278
Epoch: 98 | Iteration number: [100/565] 17% | Training loss: 0.6937054085731507
Epoch: 98 | Iteration number: [110/565] 19% | Training loss: 0.6930749237537384
Epoch: 98 | Iteration number: [120/565] 21% | Training loss: 0.6925909851988157
Epoch: 98 | Iteration number: [130/565] 23% | Training loss: 0.6921373784542084
Epoch: 98 | Iteration number: [140/565] 24% | Training loss: 0.6917563787528447
Epoch: 98 | Iteration number: [150/565] 26% | Training loss: 0.691429850657781
Epoch: 98 | Iteration number: [160/565] 28% | Training loss: 0.6911390140652657
Epoch: 98 | Iteration number: [170/565] 30% | Training loss: 0.6908787190914154
Epoch: 98 | Iteration number: [180/565] 31% | Training loss: 0.690657608376609
Epoch: 98 | Iteration number: [190/565] 33% | Training loss: 0.6904669099732449
Epoch: 98 | Iteration number: [200/565] 35% | Training loss: 0.6902778059244156
Epoch: 98 | Iteration number: [210/565] 37% | Training loss: 0.6900913383279528
Epoch: 98 | Iteration number: [220/565] 38% | Training loss: 0.6899508869106119
Epoch: 98 | Iteration number: [230/565] 40% | Training loss: 0.6898250437301138
Epoch: 98 | Iteration number: [240/565] 42% | Training loss: 0.6896968851486842
Epoch: 98 | Iteration number: [250/565] 44% | Training loss: 0.6895815854072571
Epoch: 98 | Iteration number: [260/565] 46% | Training loss: 0.6894735897962864
Epoch: 98 | Iteration number: [270/565] 47% | Training loss: 0.6893581045998467
Epoch: 98 | Iteration number: [280/565] 49% | Training loss: 0.6892478706581252
Epoch: 98 | Iteration number: [290/565] 51% | Training loss: 0.6891560083833234
Epoch: 98 | Iteration number: [300/565] 53% | Training loss: 0.6890781756242116
Epoch: 98 | Iteration number: [310/565] 54% | Training loss: 0.6890001481579197
Epoch: 98 | Iteration number: [320/565] 56% | Training loss: 0.6889304189011455
Epoch: 98 | Iteration number: [330/565] 58% | Training loss: 0.6888695422447089
Epoch: 98 | Iteration number: [340/565] 60% | Training loss: 0.6888061246451209
Epoch: 98 | Iteration number: [350/565] 61% | Training loss: 0.6887418038504465
Epoch: 98 | Iteration number: [360/565] 63% | Training loss: 0.6886769693758753
Epoch: 98 | Iteration number: [370/565] 65% | Training loss: 0.6886158923845034
Epoch: 98 | Iteration number: [380/565] 67% | Training loss: 0.6885648957992855
Epoch: 98 | Iteration number: [390/565] 69% | Training loss: 0.6885156782773825
Epoch: 98 | Iteration number: [400/565] 70% | Training loss: 0.688469202965498
Epoch: 98 | Iteration number: [410/565] 72% | Training loss: 0.6884182669767519
Epoch: 98 | Iteration number: [420/565] 74% | Training loss: 0.688387213292576
Epoch: 98 | Iteration number: [430/565] 76% | Training loss: 0.6883503309516019
Epoch: 98 | Iteration number: [440/565] 77% | Training loss: 0.6883147425272248
Epoch: 98 | Iteration number: [450/565] 79% | Training loss: 0.688279650343789
Epoch: 98 | Iteration number: [460/565] 81% | Training loss: 0.688251464004102
Epoch: 98 | Iteration number: [470/565] 83% | Training loss: 0.6882182949400962
Epoch: 98 | Iteration number: [480/565] 84% | Training loss: 0.6881861307968696
Epoch: 98 | Iteration number: [490/565] 86% | Training loss: 0.6881493435830486
Epoch: 98 | Iteration number: [500/565] 88% | Training loss: 0.6881202484369278
Epoch: 98 | Iteration number: [510/565] 90% | Training loss: 0.6880982674804388
Epoch: 98 | Iteration number: [520/565] 92% | Training loss: 0.6880721322618998
Epoch: 98 | Iteration number: [530/565] 93% | Training loss: 0.6880451485795794
Epoch: 98 | Iteration number: [540/565] 95% | Training loss: 0.6880242823450654
Epoch: 98 | Iteration number: [550/565] 97% | Training loss: 0.6880019103397023
Epoch: 98 | Iteration number: [560/565] 99% | Training loss: 0.6879873168255601

 End of epoch: 98 | Train Loss: 0.6867618443691625 | Training Time: 88 

 End of epoch: 98 | Eval Loss: 0.6895767876080104 | Evaluating Time: 5 
Epoch: 99 | Iteration number: [10/565] 1% | Training loss: 0.7552292943000793
Epoch: 99 | Iteration number: [20/565] 3% | Training loss: 0.7209291338920594
Epoch: 99 | Iteration number: [30/565] 5% | Training loss: 0.7094501694043477
Epoch: 99 | Iteration number: [40/565] 7% | Training loss: 0.7037872955203056
Epoch: 99 | Iteration number: [50/565] 8% | Training loss: 0.7004284524917602
Epoch: 99 | Iteration number: [60/565] 10% | Training loss: 0.6982399314641953
Epoch: 99 | Iteration number: [70/565] 12% | Training loss: 0.6965672995362963
Epoch: 99 | Iteration number: [80/565] 14% | Training loss: 0.695319177210331
Epoch: 99 | Iteration number: [90/565] 15% | Training loss: 0.6944081359439426
Epoch: 99 | Iteration number: [100/565] 17% | Training loss: 0.6936467516422272
Epoch: 99 | Iteration number: [110/565] 19% | Training loss: 0.6930728630586104
Epoch: 99 | Iteration number: [120/565] 21% | Training loss: 0.6925442675749461
Epoch: 99 | Iteration number: [130/565] 23% | Training loss: 0.6920774890826299
Epoch: 99 | Iteration number: [140/565] 24% | Training loss: 0.691671930040632
Epoch: 99 | Iteration number: [150/565] 26% | Training loss: 0.6913427027066549
Epoch: 99 | Iteration number: [160/565] 28% | Training loss: 0.6910630125552416
Epoch: 99 | Iteration number: [170/565] 30% | Training loss: 0.6908167467397802
Epoch: 99 | Iteration number: [180/565] 31% | Training loss: 0.6906169219149484
Epoch: 99 | Iteration number: [190/565] 33% | Training loss: 0.6904096339878283
Epoch: 99 | Iteration number: [200/565] 35% | Training loss: 0.6902287510037423
Epoch: 99 | Iteration number: [210/565] 37% | Training loss: 0.6900635063648224
Epoch: 99 | Iteration number: [220/565] 38% | Training loss: 0.6899075383489782
Epoch: 99 | Iteration number: [230/565] 40% | Training loss: 0.6897698604542276
Epoch: 99 | Iteration number: [240/565] 42% | Training loss: 0.6896295306583246
Epoch: 99 | Iteration number: [250/565] 44% | Training loss: 0.6895045890808106
Epoch: 99 | Iteration number: [260/565] 46% | Training loss: 0.6894164656217282
Epoch: 99 | Iteration number: [270/565] 47% | Training loss: 0.6893174840344323
Epoch: 99 | Iteration number: [280/565] 49% | Training loss: 0.6892191761306354
Epoch: 99 | Iteration number: [290/565] 51% | Training loss: 0.6891282032276022
Epoch: 99 | Iteration number: [300/565] 53% | Training loss: 0.6890325651566187
Epoch: 99 | Iteration number: [310/565] 54% | Training loss: 0.6889697413290701
Epoch: 99 | Iteration number: [320/565] 56% | Training loss: 0.6888977827504277
Epoch: 99 | Iteration number: [330/565] 58% | Training loss: 0.6888510527032794
Epoch: 99 | Iteration number: [340/565] 60% | Training loss: 0.6887893275302999
Epoch: 99 | Iteration number: [350/565] 61% | Training loss: 0.688731233051845
Epoch: 99 | Iteration number: [360/565] 63% | Training loss: 0.688678810497125
Epoch: 99 | Iteration number: [370/565] 65% | Training loss: 0.6886094289856988
Epoch: 99 | Iteration number: [380/565] 67% | Training loss: 0.6885468045347616
Epoch: 99 | Iteration number: [390/565] 69% | Training loss: 0.6884971403158628
Epoch: 99 | Iteration number: [400/565] 70% | Training loss: 0.6884542299807072
Epoch: 99 | Iteration number: [410/565] 72% | Training loss: 0.6884075647447168
Epoch: 99 | Iteration number: [420/565] 74% | Training loss: 0.688372203707695
Epoch: 99 | Iteration number: [430/565] 76% | Training loss: 0.6883381811685341
Epoch: 99 | Iteration number: [440/565] 77% | Training loss: 0.6883039810440758
Epoch: 99 | Iteration number: [450/565] 79% | Training loss: 0.6882660867108239
Epoch: 99 | Iteration number: [460/565] 81% | Training loss: 0.6882335377776104
Epoch: 99 | Iteration number: [470/565] 83% | Training loss: 0.6881975735755677
Epoch: 99 | Iteration number: [480/565] 84% | Training loss: 0.6881574533879757
Epoch: 99 | Iteration number: [490/565] 86% | Training loss: 0.6881288285158118
Epoch: 99 | Iteration number: [500/565] 88% | Training loss: 0.6881066275835037
Epoch: 99 | Iteration number: [510/565] 90% | Training loss: 0.6880837583074383
Epoch: 99 | Iteration number: [520/565] 92% | Training loss: 0.6880606007117491
Epoch: 99 | Iteration number: [530/565] 93% | Training loss: 0.6880396948670441
Epoch: 99 | Iteration number: [540/565] 95% | Training loss: 0.6880214000189746
Epoch: 99 | Iteration number: [550/565] 97% | Training loss: 0.6879981487447565
Epoch: 99 | Iteration number: [560/565] 99% | Training loss: 0.6879777168588979

 End of epoch: 99 | Train Loss: 0.6867510706977507 | Training Time: 90 

 End of epoch: 99 | Eval Loss: 0.6896617668015617 | Evaluating Time: 6 
Epoch: 100 | Iteration number: [10/565] 1% | Training loss: 0.7557583928108216
Epoch: 100 | Iteration number: [20/565] 3% | Training loss: 0.7213357299566269
Epoch: 100 | Iteration number: [30/565] 5% | Training loss: 0.7099587380886078
Epoch: 100 | Iteration number: [40/565] 7% | Training loss: 0.7041002243757248
Epoch: 100 | Iteration number: [50/565] 8% | Training loss: 0.7006839919090271
Epoch: 100 | Iteration number: [60/565] 10% | Training loss: 0.6983513712882996
Epoch: 100 | Iteration number: [70/565] 12% | Training loss: 0.6967167854309082
Epoch: 100 | Iteration number: [80/565] 14% | Training loss: 0.6954681098461151
Epoch: 100 | Iteration number: [90/565] 15% | Training loss: 0.6945046411620246
Epoch: 100 | Iteration number: [100/565] 17% | Training loss: 0.6937235403060913
Epoch: 100 | Iteration number: [110/565] 19% | Training loss: 0.6930839668620716
Epoch: 100 | Iteration number: [120/565] 21% | Training loss: 0.6925329958399137
Epoch: 100 | Iteration number: [130/565] 23% | Training loss: 0.692118011529629
Epoch: 100 | Iteration number: [140/565] 24% | Training loss: 0.6917240538767406
Epoch: 100 | Iteration number: [150/565] 26% | Training loss: 0.6914074023564657
Epoch: 100 | Iteration number: [160/565] 28% | Training loss: 0.6911057386547327
Epoch: 100 | Iteration number: [170/565] 30% | Training loss: 0.6908581540865056
Epoch: 100 | Iteration number: [180/565] 31% | Training loss: 0.6906237724754546
Epoch: 100 | Iteration number: [190/565] 33% | Training loss: 0.6904030222641794
Epoch: 100 | Iteration number: [200/565] 35% | Training loss: 0.6902216070890427
Epoch: 100 | Iteration number: [210/565] 37% | Training loss: 0.690049766358875
Epoch: 100 | Iteration number: [220/565] 38% | Training loss: 0.6898945924910632
Epoch: 100 | Iteration number: [230/565] 40% | Training loss: 0.689770394563675
Epoch: 100 | Iteration number: [240/565] 42% | Training loss: 0.6896414009233316
Epoch: 100 | Iteration number: [250/565] 44% | Training loss: 0.6895308253765107
Epoch: 100 | Iteration number: [260/565] 46% | Training loss: 0.6894218561741022
Epoch: 100 | Iteration number: [270/565] 47% | Training loss: 0.6893116661795864
Epoch: 100 | Iteration number: [280/565] 49% | Training loss: 0.6892243046845709
Epoch: 100 | Iteration number: [290/565] 51% | Training loss: 0.6891141145393767
Epoch: 100 | Iteration number: [300/565] 53% | Training loss: 0.689029771288236
Epoch: 100 | Iteration number: [310/565] 54% | Training loss: 0.6889566294608578
Epoch: 100 | Iteration number: [320/565] 56% | Training loss: 0.6888716837391258
Epoch: 100 | Iteration number: [330/565] 58% | Training loss: 0.6888090776674676
Epoch: 100 | Iteration number: [340/565] 60% | Training loss: 0.6887470729210797
Epoch: 100 | Iteration number: [350/565] 61% | Training loss: 0.6887008050509862
Epoch: 100 | Iteration number: [360/565] 63% | Training loss: 0.6886578993664847
Epoch: 100 | Iteration number: [370/565] 65% | Training loss: 0.6886081492578661
Epoch: 100 | Iteration number: [380/565] 67% | Training loss: 0.6885645642092354
Epoch: 100 | Iteration number: [390/565] 69% | Training loss: 0.6885146457415361
Epoch: 100 | Iteration number: [400/565] 70% | Training loss: 0.6884709930419922
Epoch: 100 | Iteration number: [410/565] 72% | Training loss: 0.6884321805907458
Epoch: 100 | Iteration number: [420/565] 74% | Training loss: 0.6883928198189962
Epoch: 100 | Iteration number: [430/565] 76% | Training loss: 0.6883495147838149
Epoch: 100 | Iteration number: [440/565] 77% | Training loss: 0.6883139344778928
Epoch: 100 | Iteration number: [450/565] 79% | Training loss: 0.6882829927073585
Epoch: 100 | Iteration number: [460/565] 81% | Training loss: 0.6882423334795496
Epoch: 100 | Iteration number: [470/565] 83% | Training loss: 0.6882100115431116
Epoch: 100 | Iteration number: [480/565] 84% | Training loss: 0.6881855964660645
Epoch: 100 | Iteration number: [490/565] 86% | Training loss: 0.6881618677353373
Epoch: 100 | Iteration number: [500/565] 88% | Training loss: 0.6881351450681686
Epoch: 100 | Iteration number: [510/565] 90% | Training loss: 0.6881110920625575
Epoch: 100 | Iteration number: [520/565] 92% | Training loss: 0.6880813769423044
Epoch: 100 | Iteration number: [530/565] 93% | Training loss: 0.6880592105523595
Epoch: 100 | Iteration number: [540/565] 95% | Training loss: 0.6880359827368348
Epoch: 100 | Iteration number: [550/565] 97% | Training loss: 0.688018981218338
Epoch: 100 | Iteration number: [560/565] 99% | Training loss: 0.6879925414919853

 End of epoch: 100 | Train Loss: 0.6867649549931552 | Training Time: 89 

 End of epoch: 100 | Eval Loss: 0.6898020165307182 | Evaluating Time: 5 

 End of Test | Dice Loss: 0.9418026975222996 | Binary Cross Entropy With Logits Loss: 0.6901072008269173 
