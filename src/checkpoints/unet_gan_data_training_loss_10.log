Epoch: 1 | Iteration number: [10/565] 1% | Training loss: 0.7648009479045867
Epoch: 1 | Iteration number: [20/565] 3% | Training loss: 0.7299960196018219
Epoch: 1 | Iteration number: [30/565] 5% | Training loss: 0.7182776550451915
Epoch: 1 | Iteration number: [40/565] 7% | Training loss: 0.712351743876934
Epoch: 1 | Iteration number: [50/565] 8% | Training loss: 0.7087733674049378
Epoch: 1 | Iteration number: [60/565] 10% | Training loss: 0.7064154158035915
Epoch: 1 | Iteration number: [70/565] 12% | Training loss: 0.7046887627669743
Epoch: 1 | Iteration number: [80/565] 14% | Training loss: 0.7034036636352539
Epoch: 1 | Iteration number: [90/565] 15% | Training loss: 0.7023557285467784
Epoch: 1 | Iteration number: [100/565] 17% | Training loss: 0.7015537106990815
Epoch: 1 | Iteration number: [110/565] 19% | Training loss: 0.7008898274465041
Epoch: 1 | Iteration number: [120/565] 21% | Training loss: 0.7002807959914208
Epoch: 1 | Iteration number: [130/565] 23% | Training loss: 0.6998035706006563
Epoch: 1 | Iteration number: [140/565] 24% | Training loss: 0.6993851006031037
Epoch: 1 | Iteration number: [150/565] 26% | Training loss: 0.6990267483393351
Epoch: 1 | Iteration number: [160/565] 28% | Training loss: 0.6987004771828651
Epoch: 1 | Iteration number: [170/565] 30% | Training loss: 0.6984290000270394
Epoch: 1 | Iteration number: [180/565] 31% | Training loss: 0.6981559369299147
Epoch: 1 | Iteration number: [190/565] 33% | Training loss: 0.697908408704557
Epoch: 1 | Iteration number: [200/565] 35% | Training loss: 0.6976937448978424
Epoch: 1 | Iteration number: [210/565] 37% | Training loss: 0.6974922952197847
Epoch: 1 | Iteration number: [220/565] 38% | Training loss: 0.697290648655458
Epoch: 1 | Iteration number: [230/565] 40% | Training loss: 0.6971201437970866
Epoch: 1 | Iteration number: [240/565] 42% | Training loss: 0.6969552708168825
Epoch: 1 | Iteration number: [250/565] 44% | Training loss: 0.6968070025444031
Epoch: 1 | Iteration number: [260/565] 46% | Training loss: 0.6966548121892489
Epoch: 1 | Iteration number: [270/565] 47% | Training loss: 0.6965196536646949
Epoch: 1 | Iteration number: [280/565] 49% | Training loss: 0.6964025348424911
Epoch: 1 | Iteration number: [290/565] 51% | Training loss: 0.6962920100524508
Epoch: 1 | Iteration number: [300/565] 53% | Training loss: 0.6961831720670064
Epoch: 1 | Iteration number: [310/565] 54% | Training loss: 0.6960734546184539
Epoch: 1 | Iteration number: [320/565] 56% | Training loss: 0.6959608741104603
Epoch: 1 | Iteration number: [330/565] 58% | Training loss: 0.6958566587982755
Epoch: 1 | Iteration number: [340/565] 60% | Training loss: 0.6957672480274649
Epoch: 1 | Iteration number: [350/565] 61% | Training loss: 0.6956663256032126
Epoch: 1 | Iteration number: [360/565] 63% | Training loss: 0.6955726764268345
Epoch: 1 | Iteration number: [370/565] 65% | Training loss: 0.69548826555948
Epoch: 1 | Iteration number: [380/565] 67% | Training loss: 0.6953977741693196
Epoch: 1 | Iteration number: [390/565] 69% | Training loss: 0.6953203633809701
Epoch: 1 | Iteration number: [400/565] 70% | Training loss: 0.6952184602618218
Epoch: 1 | Iteration number: [410/565] 72% | Training loss: 0.6951466368465888
Epoch: 1 | Iteration number: [420/565] 74% | Training loss: 0.6950709344375701
Epoch: 1 | Iteration number: [430/565] 76% | Training loss: 0.6950003303760706
Epoch: 1 | Iteration number: [440/565] 77% | Training loss: 0.6949244030497291
Epoch: 1 | Iteration number: [450/565] 79% | Training loss: 0.6948562313450707
Epoch: 1 | Iteration number: [460/565] 81% | Training loss: 0.6947906120963718
Epoch: 1 | Iteration number: [470/565] 83% | Training loss: 0.6947223929648704
Epoch: 1 | Iteration number: [480/565] 84% | Training loss: 0.6946560284743707
Epoch: 1 | Iteration number: [490/565] 86% | Training loss: 0.694590254340853
Epoch: 1 | Iteration number: [500/565] 88% | Training loss: 0.694530700802803
Epoch: 1 | Iteration number: [510/565] 90% | Training loss: 0.6944646428613102
Epoch: 1 | Iteration number: [520/565] 92% | Training loss: 0.6944062255896055
Epoch: 1 | Iteration number: [530/565] 93% | Training loss: 0.6943551589857857
Epoch: 1 | Iteration number: [540/565] 95% | Training loss: 0.694299974044164
Epoch: 1 | Iteration number: [550/565] 97% | Training loss: 0.6942542107538744
Epoch: 1 | Iteration number: [560/565] 99% | Training loss: 0.6941970001373973

 End of epoch: 1 | Train Loss: 0.6929467933367839 | Training Time: 89 

 End of epoch: 1 | Eval Loss: 0.6930895277432033 | Evaluating Time: 5 
Epoch: 2 | Iteration number: [10/565] 1% | Training loss: 0.7601784646511078
Epoch: 2 | Iteration number: [20/565] 3% | Training loss: 0.7255648851394654
Epoch: 2 | Iteration number: [30/565] 5% | Training loss: 0.7141536831855774
Epoch: 2 | Iteration number: [40/565] 7% | Training loss: 0.708345040678978
Epoch: 2 | Iteration number: [50/565] 8% | Training loss: 0.7049219846725464
Epoch: 2 | Iteration number: [60/565] 10% | Training loss: 0.7025677522023519
Epoch: 2 | Iteration number: [70/565] 12% | Training loss: 0.7008837861674172
Epoch: 2 | Iteration number: [80/565] 14% | Training loss: 0.6995839133858681
Epoch: 2 | Iteration number: [90/565] 15% | Training loss: 0.698600486252043
Epoch: 2 | Iteration number: [100/565] 17% | Training loss: 0.6978085589408874
Epoch: 2 | Iteration number: [110/565] 19% | Training loss: 0.6971574219790372
Epoch: 2 | Iteration number: [120/565] 21% | Training loss: 0.6966098363200823
Epoch: 2 | Iteration number: [130/565] 23% | Training loss: 0.6961427353895627
Epoch: 2 | Iteration number: [140/565] 24% | Training loss: 0.6957225429160254
Epoch: 2 | Iteration number: [150/565] 26% | Training loss: 0.6953655930360159
Epoch: 2 | Iteration number: [160/565] 28% | Training loss: 0.695054580271244
Epoch: 2 | Iteration number: [170/565] 30% | Training loss: 0.6947800625773037
Epoch: 2 | Iteration number: [180/565] 31% | Training loss: 0.6945181565152274
Epoch: 2 | Iteration number: [190/565] 33% | Training loss: 0.6943100373995932
Epoch: 2 | Iteration number: [200/565] 35% | Training loss: 0.6941121527552605
Epoch: 2 | Iteration number: [210/565] 37% | Training loss: 0.6939318310646784
Epoch: 2 | Iteration number: [220/565] 38% | Training loss: 0.6937540130181746
Epoch: 2 | Iteration number: [230/565] 40% | Training loss: 0.6936026943766552
Epoch: 2 | Iteration number: [240/565] 42% | Training loss: 0.6934769409398238
Epoch: 2 | Iteration number: [250/565] 44% | Training loss: 0.6933518061637879
Epoch: 2 | Iteration number: [260/565] 46% | Training loss: 0.6932382835791662
Epoch: 2 | Iteration number: [270/565] 47% | Training loss: 0.6931372830161342
Epoch: 2 | Iteration number: [280/565] 49% | Training loss: 0.6930310945425715
Epoch: 2 | Iteration number: [290/565] 51% | Training loss: 0.6929363421325025
Epoch: 2 | Iteration number: [300/565] 53% | Training loss: 0.6928356891870499
Epoch: 2 | Iteration number: [310/565] 54% | Training loss: 0.692748095335499
Epoch: 2 | Iteration number: [320/565] 56% | Training loss: 0.6926566537469625
Epoch: 2 | Iteration number: [330/565] 58% | Training loss: 0.6925829979506406
Epoch: 2 | Iteration number: [340/565] 60% | Training loss: 0.6925042836105122
Epoch: 2 | Iteration number: [350/565] 61% | Training loss: 0.6924459752014706
Epoch: 2 | Iteration number: [360/565] 63% | Training loss: 0.6923824840121799
Epoch: 2 | Iteration number: [370/565] 65% | Training loss: 0.6923065541563808
Epoch: 2 | Iteration number: [380/565] 67% | Training loss: 0.6922345078305194
Epoch: 2 | Iteration number: [390/565] 69% | Training loss: 0.6921805707307962
Epoch: 2 | Iteration number: [400/565] 70% | Training loss: 0.6921178013086319
Epoch: 2 | Iteration number: [410/565] 72% | Training loss: 0.6920644376336075
Epoch: 2 | Iteration number: [420/565] 74% | Training loss: 0.6920127090953645
Epoch: 2 | Iteration number: [430/565] 76% | Training loss: 0.6919608660908633
Epoch: 2 | Iteration number: [440/565] 77% | Training loss: 0.6919016236608678
Epoch: 2 | Iteration number: [450/565] 79% | Training loss: 0.6918637571069929
Epoch: 2 | Iteration number: [460/565] 81% | Training loss: 0.6918191872213197
Epoch: 2 | Iteration number: [470/565] 83% | Training loss: 0.6917690797055022
Epoch: 2 | Iteration number: [480/565] 84% | Training loss: 0.6917245117326577
Epoch: 2 | Iteration number: [490/565] 86% | Training loss: 0.6916738015048358
Epoch: 2 | Iteration number: [500/565] 88% | Training loss: 0.6916375572681427
Epoch: 2 | Iteration number: [510/565] 90% | Training loss: 0.6916085632408366
Epoch: 2 | Iteration number: [520/565] 92% | Training loss: 0.6915712856329405
Epoch: 2 | Iteration number: [530/565] 93% | Training loss: 0.6915286383538876
Epoch: 2 | Iteration number: [540/565] 95% | Training loss: 0.6914946102433734
Epoch: 2 | Iteration number: [550/565] 97% | Training loss: 0.6914603531360626
Epoch: 2 | Iteration number: [560/565] 99% | Training loss: 0.6914324525211538

 End of epoch: 2 | Train Loss: 0.6901983603966975 | Training Time: 91 

 End of epoch: 2 | Eval Loss: 0.6919016412326268 | Evaluating Time: 5 
Epoch: 3 | Iteration number: [10/565] 1% | Training loss: 0.7587636947631836
Epoch: 3 | Iteration number: [20/565] 3% | Training loss: 0.72408527135849
Epoch: 3 | Iteration number: [30/565] 5% | Training loss: 0.7125359276930491
Epoch: 3 | Iteration number: [40/565] 7% | Training loss: 0.706740990281105
Epoch: 3 | Iteration number: [50/565] 8% | Training loss: 0.7032913446426392
Epoch: 3 | Iteration number: [60/565] 10% | Training loss: 0.7009875655174256
Epoch: 3 | Iteration number: [70/565] 12% | Training loss: 0.6993868521281651
Epoch: 3 | Iteration number: [80/565] 14% | Training loss: 0.698127306252718
Epoch: 3 | Iteration number: [90/565] 15% | Training loss: 0.6971741020679474
Epoch: 3 | Iteration number: [100/565] 17% | Training loss: 0.6964293533563614
Epoch: 3 | Iteration number: [110/565] 19% | Training loss: 0.6957945644855499
Epoch: 3 | Iteration number: [120/565] 21% | Training loss: 0.695289287964503
Epoch: 3 | Iteration number: [130/565] 23% | Training loss: 0.6948429841261644
Epoch: 3 | Iteration number: [140/565] 24% | Training loss: 0.6944586200373514
Epoch: 3 | Iteration number: [150/565] 26% | Training loss: 0.6941266620159149
Epoch: 3 | Iteration number: [160/565] 28% | Training loss: 0.6938301298767329
Epoch: 3 | Iteration number: [170/565] 30% | Training loss: 0.6935909698991215
Epoch: 3 | Iteration number: [180/565] 31% | Training loss: 0.6933499544858932
Epoch: 3 | Iteration number: [190/565] 33% | Training loss: 0.6931462485539286
Epoch: 3 | Iteration number: [200/565] 35% | Training loss: 0.6929551231861114
Epoch: 3 | Iteration number: [210/565] 37% | Training loss: 0.6927697281042735
Epoch: 3 | Iteration number: [220/565] 38% | Training loss: 0.6926184488968415
Epoch: 3 | Iteration number: [230/565] 40% | Training loss: 0.6924802373284878
Epoch: 3 | Iteration number: [240/565] 42% | Training loss: 0.6923337367673715
Epoch: 3 | Iteration number: [250/565] 44% | Training loss: 0.6922207396030426
Epoch: 3 | Iteration number: [260/565] 46% | Training loss: 0.6920933232857631
Epoch: 3 | Iteration number: [270/565] 47% | Training loss: 0.6919764247205522
Epoch: 3 | Iteration number: [280/565] 49% | Training loss: 0.6918785927551133
Epoch: 3 | Iteration number: [290/565] 51% | Training loss: 0.6918039276682098
Epoch: 3 | Iteration number: [300/565] 53% | Training loss: 0.6917027135690054
Epoch: 3 | Iteration number: [310/565] 54% | Training loss: 0.6916302819405833
Epoch: 3 | Iteration number: [320/565] 56% | Training loss: 0.6915650025010109
Epoch: 3 | Iteration number: [330/565] 58% | Training loss: 0.691504388144522
Epoch: 3 | Iteration number: [340/565] 60% | Training loss: 0.6914375242064981
Epoch: 3 | Iteration number: [350/565] 61% | Training loss: 0.6913795270238604
Epoch: 3 | Iteration number: [360/565] 63% | Training loss: 0.6913203304012616
Epoch: 3 | Iteration number: [370/565] 65% | Training loss: 0.691264744223775
Epoch: 3 | Iteration number: [380/565] 67% | Training loss: 0.6912133913291129
Epoch: 3 | Iteration number: [390/565] 69% | Training loss: 0.6911568473546933
Epoch: 3 | Iteration number: [400/565] 70% | Training loss: 0.691107801347971
Epoch: 3 | Iteration number: [410/565] 72% | Training loss: 0.6910627039467416
Epoch: 3 | Iteration number: [420/565] 74% | Training loss: 0.6910057963359924
Epoch: 3 | Iteration number: [430/565] 76% | Training loss: 0.6909686267375946
Epoch: 3 | Iteration number: [440/565] 77% | Training loss: 0.6909380148757588
Epoch: 3 | Iteration number: [450/565] 79% | Training loss: 0.6909032962057325
Epoch: 3 | Iteration number: [460/565] 81% | Training loss: 0.6908670411161755
Epoch: 3 | Iteration number: [470/565] 83% | Training loss: 0.690830674069993
Epoch: 3 | Iteration number: [480/565] 84% | Training loss: 0.6907944701611995
Epoch: 3 | Iteration number: [490/565] 86% | Training loss: 0.690751167827723
Epoch: 3 | Iteration number: [500/565] 88% | Training loss: 0.6907103550434113
Epoch: 3 | Iteration number: [510/565] 90% | Training loss: 0.6906781862763798
Epoch: 3 | Iteration number: [520/565] 92% | Training loss: 0.6906472026155546
Epoch: 3 | Iteration number: [530/565] 93% | Training loss: 0.6906198361009922
Epoch: 3 | Iteration number: [540/565] 95% | Training loss: 0.6905945047184273
Epoch: 3 | Iteration number: [550/565] 97% | Training loss: 0.6905691849101674
Epoch: 3 | Iteration number: [560/565] 99% | Training loss: 0.6905422672629357

 End of epoch: 3 | Train Loss: 0.6893088005285347 | Training Time: 90 

 End of epoch: 3 | Eval Loss: 0.6919403416769845 | Evaluating Time: 5 
Epoch: 4 | Iteration number: [10/565] 1% | Training loss: 0.7579608082771301
Epoch: 4 | Iteration number: [20/565] 3% | Training loss: 0.7234018206596374
Epoch: 4 | Iteration number: [30/565] 5% | Training loss: 0.7118061105410258
Epoch: 4 | Iteration number: [40/565] 7% | Training loss: 0.7060924902558326
Epoch: 4 | Iteration number: [50/565] 8% | Training loss: 0.7026902592182159
Epoch: 4 | Iteration number: [60/565] 10% | Training loss: 0.700369706749916
Epoch: 4 | Iteration number: [70/565] 12% | Training loss: 0.6986856639385224
Epoch: 4 | Iteration number: [80/565] 14% | Training loss: 0.6974684864282608
Epoch: 4 | Iteration number: [90/565] 15% | Training loss: 0.6965356700950198
Epoch: 4 | Iteration number: [100/565] 17% | Training loss: 0.6957865816354751
Epoch: 4 | Iteration number: [110/565] 19% | Training loss: 0.6951577381654219
Epoch: 4 | Iteration number: [120/565] 21% | Training loss: 0.6946058849493663
Epoch: 4 | Iteration number: [130/565] 23% | Training loss: 0.6941603944851802
Epoch: 4 | Iteration number: [140/565] 24% | Training loss: 0.6938010024172919
Epoch: 4 | Iteration number: [150/565] 26% | Training loss: 0.6934763967990876
Epoch: 4 | Iteration number: [160/565] 28% | Training loss: 0.693220791593194
Epoch: 4 | Iteration number: [170/565] 30% | Training loss: 0.6929757013040431
Epoch: 4 | Iteration number: [180/565] 31% | Training loss: 0.6927450683381823
Epoch: 4 | Iteration number: [190/565] 33% | Training loss: 0.6925367706700375
Epoch: 4 | Iteration number: [200/565] 35% | Training loss: 0.6923646873235703
Epoch: 4 | Iteration number: [210/565] 37% | Training loss: 0.6922114786647615
Epoch: 4 | Iteration number: [220/565] 38% | Training loss: 0.6920508390123193
Epoch: 4 | Iteration number: [230/565] 40% | Training loss: 0.6919252639231475
Epoch: 4 | Iteration number: [240/565] 42% | Training loss: 0.6917948896686236
Epoch: 4 | Iteration number: [250/565] 44% | Training loss: 0.6916811439990997
Epoch: 4 | Iteration number: [260/565] 46% | Training loss: 0.6915692982765345
Epoch: 4 | Iteration number: [270/565] 47% | Training loss: 0.6914654299064918
Epoch: 4 | Iteration number: [280/565] 49% | Training loss: 0.6913740694522857
Epoch: 4 | Iteration number: [290/565] 51% | Training loss: 0.6912774864969582
Epoch: 4 | Iteration number: [300/565] 53% | Training loss: 0.6911955122152964
Epoch: 4 | Iteration number: [310/565] 54% | Training loss: 0.6911113835150196
Epoch: 4 | Iteration number: [320/565] 56% | Training loss: 0.6910340955480934
Epoch: 4 | Iteration number: [330/565] 58% | Training loss: 0.6909548264561277
Epoch: 4 | Iteration number: [340/565] 60% | Training loss: 0.6908905669170268
Epoch: 4 | Iteration number: [350/565] 61% | Training loss: 0.6908183913571494
Epoch: 4 | Iteration number: [360/565] 63% | Training loss: 0.6907336380746629
Epoch: 4 | Iteration number: [370/565] 65% | Training loss: 0.6906739629603721
Epoch: 4 | Iteration number: [380/565] 67% | Training loss: 0.6906109165204198
Epoch: 4 | Iteration number: [390/565] 69% | Training loss: 0.6905633773559179
Epoch: 4 | Iteration number: [400/565] 70% | Training loss: 0.690521649569273
Epoch: 4 | Iteration number: [410/565] 72% | Training loss: 0.6904670998817537
Epoch: 4 | Iteration number: [420/565] 74% | Training loss: 0.6904331403119224
Epoch: 4 | Iteration number: [430/565] 76% | Training loss: 0.6903985641723456
Epoch: 4 | Iteration number: [440/565] 77% | Training loss: 0.6903635092756965
Epoch: 4 | Iteration number: [450/565] 79% | Training loss: 0.6903221849600474
Epoch: 4 | Iteration number: [460/565] 81% | Training loss: 0.690288779269094
Epoch: 4 | Iteration number: [470/565] 83% | Training loss: 0.6902509951845128
Epoch: 4 | Iteration number: [480/565] 84% | Training loss: 0.6902105233321587
Epoch: 4 | Iteration number: [490/565] 86% | Training loss: 0.6901801841599601
Epoch: 4 | Iteration number: [500/565] 88% | Training loss: 0.6901451326608657
Epoch: 4 | Iteration number: [510/565] 90% | Training loss: 0.6901061402816399
Epoch: 4 | Iteration number: [520/565] 92% | Training loss: 0.6900749508004922
Epoch: 4 | Iteration number: [530/565] 93% | Training loss: 0.6900416429312723
Epoch: 4 | Iteration number: [540/565] 95% | Training loss: 0.6900174631012811
Epoch: 4 | Iteration number: [550/565] 97% | Training loss: 0.6900014313784513
Epoch: 4 | Iteration number: [560/565] 99% | Training loss: 0.6899705705898148

 End of epoch: 4 | Train Loss: 0.6887364373797864 | Training Time: 91 

 End of epoch: 4 | Eval Loss: 0.6915910158838544 | Evaluating Time: 5 
Epoch: 5 | Iteration number: [10/565] 1% | Training loss: 0.7578844666481018
Epoch: 5 | Iteration number: [20/565] 3% | Training loss: 0.7232596755027771
Epoch: 5 | Iteration number: [30/565] 5% | Training loss: 0.7116617580254873
Epoch: 5 | Iteration number: [40/565] 7% | Training loss: 0.7059264361858368
Epoch: 5 | Iteration number: [50/565] 8% | Training loss: 0.7024197351932525
Epoch: 5 | Iteration number: [60/565] 10% | Training loss: 0.7001396556695302
Epoch: 5 | Iteration number: [70/565] 12% | Training loss: 0.698512978213174
Epoch: 5 | Iteration number: [80/565] 14% | Training loss: 0.697295355796814
Epoch: 5 | Iteration number: [90/565] 15% | Training loss: 0.6962871849536896
Epoch: 5 | Iteration number: [100/565] 17% | Training loss: 0.6954970288276673
Epoch: 5 | Iteration number: [110/565] 19% | Training loss: 0.6948496043682099
Epoch: 5 | Iteration number: [120/565] 21% | Training loss: 0.6943014358480771
Epoch: 5 | Iteration number: [130/565] 23% | Training loss: 0.6938213926095229
Epoch: 5 | Iteration number: [140/565] 24% | Training loss: 0.6934576247419629
Epoch: 5 | Iteration number: [150/565] 26% | Training loss: 0.6931267710526784
Epoch: 5 | Iteration number: [160/565] 28% | Training loss: 0.6928383830934763
Epoch: 5 | Iteration number: [170/565] 30% | Training loss: 0.6926048990558176
Epoch: 5 | Iteration number: [180/565] 31% | Training loss: 0.6924092504713271
Epoch: 5 | Iteration number: [190/565] 33% | Training loss: 0.6921989396998757
Epoch: 5 | Iteration number: [200/565] 35% | Training loss: 0.6920221707224846
Epoch: 5 | Iteration number: [210/565] 37% | Training loss: 0.6918624398254213
Epoch: 5 | Iteration number: [220/565] 38% | Training loss: 0.6917130109938708
Epoch: 5 | Iteration number: [230/565] 40% | Training loss: 0.6915774202865103
Epoch: 5 | Iteration number: [240/565] 42% | Training loss: 0.6914399437606334
Epoch: 5 | Iteration number: [250/565] 44% | Training loss: 0.6913177270889282
Epoch: 5 | Iteration number: [260/565] 46% | Training loss: 0.6911773314842811
Epoch: 5 | Iteration number: [270/565] 47% | Training loss: 0.6910674443951359
Epoch: 5 | Iteration number: [280/565] 49% | Training loss: 0.6909749903849193
Epoch: 5 | Iteration number: [290/565] 51% | Training loss: 0.6908725952279979
Epoch: 5 | Iteration number: [300/565] 53% | Training loss: 0.6907964440186819
Epoch: 5 | Iteration number: [310/565] 54% | Training loss: 0.6907096978156797
Epoch: 5 | Iteration number: [320/565] 56% | Training loss: 0.6906399145722389
Epoch: 5 | Iteration number: [330/565] 58% | Training loss: 0.6905587376970234
Epoch: 5 | Iteration number: [340/565] 60% | Training loss: 0.6904914319515228
Epoch: 5 | Iteration number: [350/565] 61% | Training loss: 0.6904360548087529
Epoch: 5 | Iteration number: [360/565] 63% | Training loss: 0.6903828114271164
Epoch: 5 | Iteration number: [370/565] 65% | Training loss: 0.6903221703864433
Epoch: 5 | Iteration number: [380/565] 67% | Training loss: 0.690261728355759
Epoch: 5 | Iteration number: [390/565] 69% | Training loss: 0.6902075726252336
Epoch: 5 | Iteration number: [400/565] 70% | Training loss: 0.6901642614603043
Epoch: 5 | Iteration number: [410/565] 72% | Training loss: 0.6901131548532625
Epoch: 5 | Iteration number: [420/565] 74% | Training loss: 0.6900703773612068
Epoch: 5 | Iteration number: [430/565] 76% | Training loss: 0.6900319361409476
Epoch: 5 | Iteration number: [440/565] 77% | Training loss: 0.6899874757636677
Epoch: 5 | Iteration number: [450/565] 79% | Training loss: 0.6899572004212273
Epoch: 5 | Iteration number: [460/565] 81% | Training loss: 0.6899242043495178
Epoch: 5 | Iteration number: [470/565] 83% | Training loss: 0.6898923101577353
Epoch: 5 | Iteration number: [480/565] 84% | Training loss: 0.6898527622222901
Epoch: 5 | Iteration number: [490/565] 86% | Training loss: 0.6898139523000133
Epoch: 5 | Iteration number: [500/565] 88% | Training loss: 0.689781297326088
Epoch: 5 | Iteration number: [510/565] 90% | Training loss: 0.6897472042663425
Epoch: 5 | Iteration number: [520/565] 92% | Training loss: 0.6897145327467185
Epoch: 5 | Iteration number: [530/565] 93% | Training loss: 0.6896881583726631
Epoch: 5 | Iteration number: [540/565] 95% | Training loss: 0.6896516091293758
Epoch: 5 | Iteration number: [550/565] 97% | Training loss: 0.6896296195550399
Epoch: 5 | Iteration number: [560/565] 99% | Training loss: 0.6896084822714329

 End of epoch: 5 | Train Loss: 0.6883810989624631 | Training Time: 90 

 End of epoch: 5 | Eval Loss: 0.6915374483380999 | Evaluating Time: 5 
Epoch: 6 | Iteration number: [10/565] 1% | Training loss: 0.757238358259201
Epoch: 6 | Iteration number: [20/565] 3% | Training loss: 0.7228406637907028
Epoch: 6 | Iteration number: [30/565] 5% | Training loss: 0.7115108470122019
Epoch: 6 | Iteration number: [40/565] 7% | Training loss: 0.7056809455156327
Epoch: 6 | Iteration number: [50/565] 8% | Training loss: 0.702216980457306
Epoch: 6 | Iteration number: [60/565] 10% | Training loss: 0.6999157398939133
Epoch: 6 | Iteration number: [70/565] 12% | Training loss: 0.6982786774635314
Epoch: 6 | Iteration number: [80/565] 14% | Training loss: 0.6969995871186256
Epoch: 6 | Iteration number: [90/565] 15% | Training loss: 0.696023342344496
Epoch: 6 | Iteration number: [100/565] 17% | Training loss: 0.695221735239029
Epoch: 6 | Iteration number: [110/565] 19% | Training loss: 0.6945643685080788
Epoch: 6 | Iteration number: [120/565] 21% | Training loss: 0.6940119296312333
Epoch: 6 | Iteration number: [130/565] 23% | Training loss: 0.6935306361088386
Epoch: 6 | Iteration number: [140/565] 24% | Training loss: 0.69317373079913
Epoch: 6 | Iteration number: [150/565] 26% | Training loss: 0.6928108982245127
Epoch: 6 | Iteration number: [160/565] 28% | Training loss: 0.6925268419086933
Epoch: 6 | Iteration number: [170/565] 30% | Training loss: 0.692277202536078
Epoch: 6 | Iteration number: [180/565] 31% | Training loss: 0.6920331680112415
Epoch: 6 | Iteration number: [190/565] 33% | Training loss: 0.6918289661407471
Epoch: 6 | Iteration number: [200/565] 35% | Training loss: 0.6916320151090622
Epoch: 6 | Iteration number: [210/565] 37% | Training loss: 0.6914610465367635
Epoch: 6 | Iteration number: [220/565] 38% | Training loss: 0.6913151104341854
Epoch: 6 | Iteration number: [230/565] 40% | Training loss: 0.6911835548670395
Epoch: 6 | Iteration number: [240/565] 42% | Training loss: 0.6910404250025749
Epoch: 6 | Iteration number: [250/565] 44% | Training loss: 0.6909182953834534
Epoch: 6 | Iteration number: [260/565] 46% | Training loss: 0.6907974117077313
Epoch: 6 | Iteration number: [270/565] 47% | Training loss: 0.6907020668188731
Epoch: 6 | Iteration number: [280/565] 49% | Training loss: 0.6906107755643981
Epoch: 6 | Iteration number: [290/565] 51% | Training loss: 0.6905068403687971
Epoch: 6 | Iteration number: [300/565] 53% | Training loss: 0.6904211769501368
Epoch: 6 | Iteration number: [310/565] 54% | Training loss: 0.6903420932831302
Epoch: 6 | Iteration number: [320/565] 56% | Training loss: 0.6902636276558042
Epoch: 6 | Iteration number: [330/565] 58% | Training loss: 0.6901933124571136
Epoch: 6 | Iteration number: [340/565] 60% | Training loss: 0.690115992286626
Epoch: 6 | Iteration number: [350/565] 61% | Training loss: 0.6900544590609414
Epoch: 6 | Iteration number: [360/565] 63% | Training loss: 0.6900042020612293
Epoch: 6 | Iteration number: [370/565] 65% | Training loss: 0.6899397257212047
Epoch: 6 | Iteration number: [380/565] 67% | Training loss: 0.6898857529226102
Epoch: 6 | Iteration number: [390/565] 69% | Training loss: 0.6898324596576202
Epoch: 6 | Iteration number: [400/565] 70% | Training loss: 0.6897850055992604
Epoch: 6 | Iteration number: [410/565] 72% | Training loss: 0.6897438726774077
Epoch: 6 | Iteration number: [420/565] 74% | Training loss: 0.6897104335682732
Epoch: 6 | Iteration number: [430/565] 76% | Training loss: 0.6896750351717306
Epoch: 6 | Iteration number: [440/565] 77% | Training loss: 0.6896412100304257
Epoch: 6 | Iteration number: [450/565] 79% | Training loss: 0.6896037211683061
Epoch: 6 | Iteration number: [460/565] 81% | Training loss: 0.6895748769459518
Epoch: 6 | Iteration number: [470/565] 83% | Training loss: 0.689538567751012
Epoch: 6 | Iteration number: [480/565] 84% | Training loss: 0.6895072715977828
Epoch: 6 | Iteration number: [490/565] 86% | Training loss: 0.6894744169955351
Epoch: 6 | Iteration number: [500/565] 88% | Training loss: 0.6894472239017486
Epoch: 6 | Iteration number: [510/565] 90% | Training loss: 0.6894220044799879
Epoch: 6 | Iteration number: [520/565] 92% | Training loss: 0.6894030396754925
Epoch: 6 | Iteration number: [530/565] 93% | Training loss: 0.6893801574437124
Epoch: 6 | Iteration number: [540/565] 95% | Training loss: 0.6893541855944527
Epoch: 6 | Iteration number: [550/565] 97% | Training loss: 0.6893266334316948
Epoch: 6 | Iteration number: [560/565] 99% | Training loss: 0.6893014198967389

 End of epoch: 6 | Train Loss: 0.6880730103602452 | Training Time: 91 

 End of epoch: 6 | Eval Loss: 0.691348501614162 | Evaluating Time: 5 
Epoch: 7 | Iteration number: [10/565] 1% | Training loss: 0.7567275166511536
Epoch: 7 | Iteration number: [20/565] 3% | Training loss: 0.7222973048686981
Epoch: 7 | Iteration number: [30/565] 5% | Training loss: 0.7107599079608917
Epoch: 7 | Iteration number: [40/565] 7% | Training loss: 0.7049945712089538
Epoch: 7 | Iteration number: [50/565] 8% | Training loss: 0.7015842914581298
Epoch: 7 | Iteration number: [60/565] 10% | Training loss: 0.6992401252190272
Epoch: 7 | Iteration number: [70/565] 12% | Training loss: 0.6976236283779145
Epoch: 7 | Iteration number: [80/565] 14% | Training loss: 0.6964236773550511
Epoch: 7 | Iteration number: [90/565] 15% | Training loss: 0.6955340729819404
Epoch: 7 | Iteration number: [100/565] 17% | Training loss: 0.6947601103782653
Epoch: 7 | Iteration number: [110/565] 19% | Training loss: 0.6941023924133994
Epoch: 7 | Iteration number: [120/565] 21% | Training loss: 0.6935808380444844
Epoch: 7 | Iteration number: [130/565] 23% | Training loss: 0.6931301928483523
Epoch: 7 | Iteration number: [140/565] 24% | Training loss: 0.6927389340741293
Epoch: 7 | Iteration number: [150/565] 26% | Training loss: 0.6924360207716624
Epoch: 7 | Iteration number: [160/565] 28% | Training loss: 0.6921414487063885
Epoch: 7 | Iteration number: [170/565] 30% | Training loss: 0.691875379225787
Epoch: 7 | Iteration number: [180/565] 31% | Training loss: 0.6916616804069943
Epoch: 7 | Iteration number: [190/565] 33% | Training loss: 0.6914575736773642
Epoch: 7 | Iteration number: [200/565] 35% | Training loss: 0.6912722936272622
Epoch: 7 | Iteration number: [210/565] 37% | Training loss: 0.6911142624559856
Epoch: 7 | Iteration number: [220/565] 38% | Training loss: 0.6909775907343084
Epoch: 7 | Iteration number: [230/565] 40% | Training loss: 0.6908500575500985
Epoch: 7 | Iteration number: [240/565] 42% | Training loss: 0.6907334129015604
Epoch: 7 | Iteration number: [250/565] 44% | Training loss: 0.6906207020282745
Epoch: 7 | Iteration number: [260/565] 46% | Training loss: 0.6905415385961533
Epoch: 7 | Iteration number: [270/565] 47% | Training loss: 0.6904348962836795
Epoch: 7 | Iteration number: [280/565] 49% | Training loss: 0.6903438544699124
Epoch: 7 | Iteration number: [290/565] 51% | Training loss: 0.6902659603233995
Epoch: 7 | Iteration number: [300/565] 53% | Training loss: 0.6901935885349909
Epoch: 7 | Iteration number: [310/565] 54% | Training loss: 0.6901265890367569
Epoch: 7 | Iteration number: [320/565] 56% | Training loss: 0.6900602724403143
Epoch: 7 | Iteration number: [330/565] 58% | Training loss: 0.6899967793262366
Epoch: 7 | Iteration number: [340/565] 60% | Training loss: 0.6899509203784606
Epoch: 7 | Iteration number: [350/565] 61% | Training loss: 0.6898656947272165
Epoch: 7 | Iteration number: [360/565] 63% | Training loss: 0.6898154341512256
Epoch: 7 | Iteration number: [370/565] 65% | Training loss: 0.689749026298523
Epoch: 7 | Iteration number: [380/565] 67% | Training loss: 0.6897032813022012
Epoch: 7 | Iteration number: [390/565] 69% | Training loss: 0.6896427668057955
Epoch: 7 | Iteration number: [400/565] 70% | Training loss: 0.689598526507616
Epoch: 7 | Iteration number: [410/565] 72% | Training loss: 0.6895475641983312
Epoch: 7 | Iteration number: [420/565] 74% | Training loss: 0.6895011426437468
Epoch: 7 | Iteration number: [430/565] 76% | Training loss: 0.6894582135732784
Epoch: 7 | Iteration number: [440/565] 77% | Training loss: 0.6894232109189034
Epoch: 7 | Iteration number: [450/565] 79% | Training loss: 0.6893970154391394
Epoch: 7 | Iteration number: [460/565] 81% | Training loss: 0.6893678095029748
Epoch: 7 | Iteration number: [470/565] 83% | Training loss: 0.6893374126008216
Epoch: 7 | Iteration number: [480/565] 84% | Training loss: 0.6893111533174913
Epoch: 7 | Iteration number: [490/565] 86% | Training loss: 0.6892849535358195
Epoch: 7 | Iteration number: [500/565] 88% | Training loss: 0.6892609680891038
Epoch: 7 | Iteration number: [510/565] 90% | Training loss: 0.6892240620126912
Epoch: 7 | Iteration number: [520/565] 92% | Training loss: 0.6891890112024087
Epoch: 7 | Iteration number: [530/565] 93% | Training loss: 0.689163239721982
Epoch: 7 | Iteration number: [540/565] 95% | Training loss: 0.6891356884329407
Epoch: 7 | Iteration number: [550/565] 97% | Training loss: 0.6891137476400896
Epoch: 7 | Iteration number: [560/565] 99% | Training loss: 0.6890975560460771

 End of epoch: 7 | Train Loss: 0.6878692172269906 | Training Time: 91 

 End of epoch: 7 | Eval Loss: 0.6912211605480739 | Evaluating Time: 5 
Epoch: 8 | Iteration number: [10/565] 1% | Training loss: 0.7566202044486999
Epoch: 8 | Iteration number: [20/565] 3% | Training loss: 0.7222264617681503
Epoch: 8 | Iteration number: [30/565] 5% | Training loss: 0.7107756674289704
Epoch: 8 | Iteration number: [40/565] 7% | Training loss: 0.7050644621253014
Epoch: 8 | Iteration number: [50/565] 8% | Training loss: 0.7016027176380157
Epoch: 8 | Iteration number: [60/565] 10% | Training loss: 0.6992930471897125
Epoch: 8 | Iteration number: [70/565] 12% | Training loss: 0.6976497241428921
Epoch: 8 | Iteration number: [80/565] 14% | Training loss: 0.6963863305747509
Epoch: 8 | Iteration number: [90/565] 15% | Training loss: 0.6953686621454027
Epoch: 8 | Iteration number: [100/565] 17% | Training loss: 0.6946145826578141
Epoch: 8 | Iteration number: [110/565] 19% | Training loss: 0.6940080447630449
Epoch: 8 | Iteration number: [120/565] 21% | Training loss: 0.6934951186180115
Epoch: 8 | Iteration number: [130/565] 23% | Training loss: 0.6930475757672236
Epoch: 8 | Iteration number: [140/565] 24% | Training loss: 0.6926632191453661
Epoch: 8 | Iteration number: [150/565] 26% | Training loss: 0.6923435095945994
Epoch: 8 | Iteration number: [160/565] 28% | Training loss: 0.6920677620917559
Epoch: 8 | Iteration number: [170/565] 30% | Training loss: 0.6918337450307959
Epoch: 8 | Iteration number: [180/565] 31% | Training loss: 0.6915964235862097
Epoch: 8 | Iteration number: [190/565] 33% | Training loss: 0.6913996903519881
Epoch: 8 | Iteration number: [200/565] 35% | Training loss: 0.6912036862969398
Epoch: 8 | Iteration number: [210/565] 37% | Training loss: 0.6910363242739723
Epoch: 8 | Iteration number: [220/565] 38% | Training loss: 0.690875715288249
Epoch: 8 | Iteration number: [230/565] 40% | Training loss: 0.6907225183818652
Epoch: 8 | Iteration number: [240/565] 42% | Training loss: 0.6906040621300539
Epoch: 8 | Iteration number: [250/565] 44% | Training loss: 0.6904878280162812
Epoch: 8 | Iteration number: [260/565] 46% | Training loss: 0.6903945177793502
Epoch: 8 | Iteration number: [270/565] 47% | Training loss: 0.6903068286401254
Epoch: 8 | Iteration number: [280/565] 49% | Training loss: 0.6902172571846417
Epoch: 8 | Iteration number: [290/565] 51% | Training loss: 0.6901247088251443
Epoch: 8 | Iteration number: [300/565] 53% | Training loss: 0.6900502189000448
Epoch: 8 | Iteration number: [310/565] 54% | Training loss: 0.6899677451579801
Epoch: 8 | Iteration number: [320/565] 56% | Training loss: 0.6898981675505638
Epoch: 8 | Iteration number: [330/565] 58% | Training loss: 0.6898199364994512
Epoch: 8 | Iteration number: [340/565] 60% | Training loss: 0.6897493998793994
Epoch: 8 | Iteration number: [350/565] 61% | Training loss: 0.6896947540555681
Epoch: 8 | Iteration number: [360/565] 63% | Training loss: 0.6896338878406418
Epoch: 8 | Iteration number: [370/565] 65% | Training loss: 0.6895817714768487
Epoch: 8 | Iteration number: [380/565] 67% | Training loss: 0.6895258577246415
Epoch: 8 | Iteration number: [390/565] 69% | Training loss: 0.6894767823891762
Epoch: 8 | Iteration number: [400/565] 70% | Training loss: 0.6894314751029015
Epoch: 8 | Iteration number: [410/565] 72% | Training loss: 0.6893874645233155
Epoch: 8 | Iteration number: [420/565] 74% | Training loss: 0.6893458965278807
Epoch: 8 | Iteration number: [430/565] 76% | Training loss: 0.6893049349618513
Epoch: 8 | Iteration number: [440/565] 77% | Training loss: 0.6892609019171108
Epoch: 8 | Iteration number: [450/565] 79% | Training loss: 0.6892189066939883
Epoch: 8 | Iteration number: [460/565] 81% | Training loss: 0.689181738184846
Epoch: 8 | Iteration number: [470/565] 83% | Training loss: 0.689146622444721
Epoch: 8 | Iteration number: [480/565] 84% | Training loss: 0.689114560559392
Epoch: 8 | Iteration number: [490/565] 86% | Training loss: 0.6890747015573541
Epoch: 8 | Iteration number: [500/565] 88% | Training loss: 0.6890421392917633
Epoch: 8 | Iteration number: [510/565] 90% | Training loss: 0.6890185246280596
Epoch: 8 | Iteration number: [520/565] 92% | Training loss: 0.6889933492128666
Epoch: 8 | Iteration number: [530/565] 93% | Training loss: 0.688961335735501
Epoch: 8 | Iteration number: [540/565] 95% | Training loss: 0.6889399954566249
Epoch: 8 | Iteration number: [550/565] 97% | Training loss: 0.6889219429276207
Epoch: 8 | Iteration number: [560/565] 99% | Training loss: 0.6888962361429419

 End of epoch: 8 | Train Loss: 0.687666615237177 | Training Time: 91 

 End of epoch: 8 | Eval Loss: 0.6903049605233329 | Evaluating Time: 5 
Epoch: 9 | Iteration number: [10/565] 1% | Training loss: 0.7562126398086548
Epoch: 9 | Iteration number: [20/565] 3% | Training loss: 0.7218721151351929
Epoch: 9 | Iteration number: [30/565] 5% | Training loss: 0.7104363858699798
Epoch: 9 | Iteration number: [40/565] 7% | Training loss: 0.7047307685017585
Epoch: 9 | Iteration number: [50/565] 8% | Training loss: 0.7012468039989471
Epoch: 9 | Iteration number: [60/565] 10% | Training loss: 0.6989754021167756
Epoch: 9 | Iteration number: [70/565] 12% | Training loss: 0.6973474715437208
Epoch: 9 | Iteration number: [80/565] 14% | Training loss: 0.6961721457540989
Epoch: 9 | Iteration number: [90/565] 15% | Training loss: 0.6952033208476173
Epoch: 9 | Iteration number: [100/565] 17% | Training loss: 0.6944676196575165
Epoch: 9 | Iteration number: [110/565] 19% | Training loss: 0.6938520778309215
Epoch: 9 | Iteration number: [120/565] 21% | Training loss: 0.6933012023568154
Epoch: 9 | Iteration number: [130/565] 23% | Training loss: 0.6928686265762035
Epoch: 9 | Iteration number: [140/565] 24% | Training loss: 0.6925398647785187
Epoch: 9 | Iteration number: [150/565] 26% | Training loss: 0.6921880539258322
Epoch: 9 | Iteration number: [160/565] 28% | Training loss: 0.6918909199535846
Epoch: 9 | Iteration number: [170/565] 30% | Training loss: 0.6916387831463533
Epoch: 9 | Iteration number: [180/565] 31% | Training loss: 0.6914021465513441
Epoch: 9 | Iteration number: [190/565] 33% | Training loss: 0.6911948865965793
Epoch: 9 | Iteration number: [200/565] 35% | Training loss: 0.6910154563188553
Epoch: 9 | Iteration number: [210/565] 37% | Training loss: 0.6908520755313692
Epoch: 9 | Iteration number: [220/565] 38% | Training loss: 0.6907153609124097
Epoch: 9 | Iteration number: [230/565] 40% | Training loss: 0.6905852014603822
Epoch: 9 | Iteration number: [240/565] 42% | Training loss: 0.6904478703935941
Epoch: 9 | Iteration number: [250/565] 44% | Training loss: 0.6903503389358521
Epoch: 9 | Iteration number: [260/565] 46% | Training loss: 0.6902441620826721
Epoch: 9 | Iteration number: [270/565] 47% | Training loss: 0.6901386868070674
Epoch: 9 | Iteration number: [280/565] 49% | Training loss: 0.690047812461853
Epoch: 9 | Iteration number: [290/565] 51% | Training loss: 0.6899601617763782
Epoch: 9 | Iteration number: [300/565] 53% | Training loss: 0.6898895929257075
Epoch: 9 | Iteration number: [310/565] 54% | Training loss: 0.6898245017374716
Epoch: 9 | Iteration number: [320/565] 56% | Training loss: 0.689751541800797
Epoch: 9 | Iteration number: [330/565] 58% | Training loss: 0.6896727312694896
Epoch: 9 | Iteration number: [340/565] 60% | Training loss: 0.689594455852228
Epoch: 9 | Iteration number: [350/565] 61% | Training loss: 0.6895249354839325
Epoch: 9 | Iteration number: [360/565] 63% | Training loss: 0.6894757671488656
Epoch: 9 | Iteration number: [370/565] 65% | Training loss: 0.6894266249360265
Epoch: 9 | Iteration number: [380/565] 67% | Training loss: 0.6893839288699
Epoch: 9 | Iteration number: [390/565] 69% | Training loss: 0.6893435227565277
Epoch: 9 | Iteration number: [400/565] 70% | Training loss: 0.6892913725972175
Epoch: 9 | Iteration number: [410/565] 72% | Training loss: 0.6892542821605031
Epoch: 9 | Iteration number: [420/565] 74% | Training loss: 0.6892136106888453
Epoch: 9 | Iteration number: [430/565] 76% | Training loss: 0.6891692703546479
Epoch: 9 | Iteration number: [440/565] 77% | Training loss: 0.6891167483546518
Epoch: 9 | Iteration number: [450/565] 79% | Training loss: 0.6890852302975125
Epoch: 9 | Iteration number: [460/565] 81% | Training loss: 0.6890551883241405
Epoch: 9 | Iteration number: [470/565] 83% | Training loss: 0.6890283697463097
Epoch: 9 | Iteration number: [480/565] 84% | Training loss: 0.6890043708185355
Epoch: 9 | Iteration number: [490/565] 86% | Training loss: 0.6889703901446596
Epoch: 9 | Iteration number: [500/565] 88% | Training loss: 0.6889308696985245
Epoch: 9 | Iteration number: [510/565] 90% | Training loss: 0.6888912357536017
Epoch: 9 | Iteration number: [520/565] 92% | Training loss: 0.688860838000591
Epoch: 9 | Iteration number: [530/565] 93% | Training loss: 0.6888369807657205
Epoch: 9 | Iteration number: [540/565] 95% | Training loss: 0.6888177727107648
Epoch: 9 | Iteration number: [550/565] 97% | Training loss: 0.6887916312434457
Epoch: 9 | Iteration number: [560/565] 99% | Training loss: 0.6887706126485552

 End of epoch: 9 | Train Loss: 0.6875514131731691 | Training Time: 91 

 End of epoch: 9 | Eval Loss: 0.691545137337276 | Evaluating Time: 6 
Epoch: 10 | Iteration number: [10/565] 1% | Training loss: 0.7563002526760101
Epoch: 10 | Iteration number: [20/565] 3% | Training loss: 0.7219920665025711
Epoch: 10 | Iteration number: [30/565] 5% | Training loss: 0.7105118076006571
Epoch: 10 | Iteration number: [40/565] 7% | Training loss: 0.7047643646597862
Epoch: 10 | Iteration number: [50/565] 8% | Training loss: 0.7012708568572998
Epoch: 10 | Iteration number: [60/565] 10% | Training loss: 0.699058543642362
Epoch: 10 | Iteration number: [70/565] 12% | Training loss: 0.6974140950611659
Epoch: 10 | Iteration number: [80/565] 14% | Training loss: 0.6961140401661396
Epoch: 10 | Iteration number: [90/565] 15% | Training loss: 0.6951558596558041
Epoch: 10 | Iteration number: [100/565] 17% | Training loss: 0.6943619138002396
Epoch: 10 | Iteration number: [110/565] 19% | Training loss: 0.693751533464952
Epoch: 10 | Iteration number: [120/565] 21% | Training loss: 0.6932259514927864
Epoch: 10 | Iteration number: [130/565] 23% | Training loss: 0.6927652175609882
Epoch: 10 | Iteration number: [140/565] 24% | Training loss: 0.6923838632447379
Epoch: 10 | Iteration number: [150/565] 26% | Training loss: 0.6920427584648132
Epoch: 10 | Iteration number: [160/565] 28% | Training loss: 0.6917727004736662
Epoch: 10 | Iteration number: [170/565] 30% | Training loss: 0.691517055385253
Epoch: 10 | Iteration number: [180/565] 31% | Training loss: 0.6912867108980815
Epoch: 10 | Iteration number: [190/565] 33% | Training loss: 0.6910993638791536
Epoch: 10 | Iteration number: [200/565] 35% | Training loss: 0.69088946133852
Epoch: 10 | Iteration number: [210/565] 37% | Training loss: 0.6907264527820406
Epoch: 10 | Iteration number: [220/565] 38% | Training loss: 0.6905608645894311
Epoch: 10 | Iteration number: [230/565] 40% | Training loss: 0.6904168442539547
Epoch: 10 | Iteration number: [240/565] 42% | Training loss: 0.690302129338185
Epoch: 10 | Iteration number: [250/565] 44% | Training loss: 0.6902035126686096
Epoch: 10 | Iteration number: [260/565] 46% | Training loss: 0.690103858938584
Epoch: 10 | Iteration number: [270/565] 47% | Training loss: 0.6900102003856942
Epoch: 10 | Iteration number: [280/565] 49% | Training loss: 0.6899105376430921
Epoch: 10 | Iteration number: [290/565] 51% | Training loss: 0.6898299102125497
Epoch: 10 | Iteration number: [300/565] 53% | Training loss: 0.6897433280944825
Epoch: 10 | Iteration number: [310/565] 54% | Training loss: 0.68967618769215
Epoch: 10 | Iteration number: [320/565] 56% | Training loss: 0.6896061824634672
Epoch: 10 | Iteration number: [330/565] 58% | Training loss: 0.6895476951743618
Epoch: 10 | Iteration number: [340/565] 60% | Training loss: 0.6894808534313651
Epoch: 10 | Iteration number: [350/565] 61% | Training loss: 0.6894163341181618
Epoch: 10 | Iteration number: [360/565] 63% | Training loss: 0.689369061589241
Epoch: 10 | Iteration number: [370/565] 65% | Training loss: 0.689315369000306
Epoch: 10 | Iteration number: [380/565] 67% | Training loss: 0.6892756002513986
Epoch: 10 | Iteration number: [390/565] 69% | Training loss: 0.689218684954521
Epoch: 10 | Iteration number: [400/565] 70% | Training loss: 0.6891660940647125
Epoch: 10 | Iteration number: [410/565] 72% | Training loss: 0.6891258501425022
Epoch: 10 | Iteration number: [420/565] 74% | Training loss: 0.6890826435316176
Epoch: 10 | Iteration number: [430/565] 76% | Training loss: 0.6890471644179765
Epoch: 10 | Iteration number: [440/565] 77% | Training loss: 0.6890055027875033
Epoch: 10 | Iteration number: [450/565] 79% | Training loss: 0.6889676586786906
Epoch: 10 | Iteration number: [460/565] 81% | Training loss: 0.6889316557542138
Epoch: 10 | Iteration number: [470/565] 83% | Training loss: 0.6889056070053831
Epoch: 10 | Iteration number: [480/565] 84% | Training loss: 0.6888739606986444
Epoch: 10 | Iteration number: [490/565] 86% | Training loss: 0.6888495406325983
Epoch: 10 | Iteration number: [500/565] 88% | Training loss: 0.6888281493186951
Epoch: 10 | Iteration number: [510/565] 90% | Training loss: 0.6888027749809564
Epoch: 10 | Iteration number: [520/565] 92% | Training loss: 0.6887777369755965
Epoch: 10 | Iteration number: [530/565] 93% | Training loss: 0.6887503199982193
Epoch: 10 | Iteration number: [540/565] 95% | Training loss: 0.6887191809989788
Epoch: 10 | Iteration number: [550/565] 97% | Training loss: 0.6886940755627372
Epoch: 10 | Iteration number: [560/565] 99% | Training loss: 0.6886720194348267

 End of epoch: 10 | Train Loss: 0.6874454656533435 | Training Time: 91 

 End of epoch: 10 | Eval Loss: 0.6904268690517971 | Evaluating Time: 5 
Epoch: 11 | Iteration number: [10/565] 1% | Training loss: 0.7561019062995911
Epoch: 11 | Iteration number: [20/565] 3% | Training loss: 0.7217382431030274
Epoch: 11 | Iteration number: [30/565] 5% | Training loss: 0.7102510849634807
Epoch: 11 | Iteration number: [40/565] 7% | Training loss: 0.7044961541891098
Epoch: 11 | Iteration number: [50/565] 8% | Training loss: 0.7010931897163392
Epoch: 11 | Iteration number: [60/565] 10% | Training loss: 0.6987850318352381
Epoch: 11 | Iteration number: [70/565] 12% | Training loss: 0.6972214707306453
Epoch: 11 | Iteration number: [80/565] 14% | Training loss: 0.6960320234298706
Epoch: 11 | Iteration number: [90/565] 15% | Training loss: 0.6950529601838854
Epoch: 11 | Iteration number: [100/565] 17% | Training loss: 0.694338030219078
Epoch: 11 | Iteration number: [110/565] 19% | Training loss: 0.6936481020667337
Epoch: 11 | Iteration number: [120/565] 21% | Training loss: 0.6931223263343175
Epoch: 11 | Iteration number: [130/565] 23% | Training loss: 0.6926903046094455
Epoch: 11 | Iteration number: [140/565] 24% | Training loss: 0.6922917170183999
Epoch: 11 | Iteration number: [150/565] 26% | Training loss: 0.6919640513261159
Epoch: 11 | Iteration number: [160/565] 28% | Training loss: 0.6916603695601224
Epoch: 11 | Iteration number: [170/565] 30% | Training loss: 0.6914120011469898
Epoch: 11 | Iteration number: [180/565] 31% | Training loss: 0.6911852171023687
Epoch: 11 | Iteration number: [190/565] 33% | Training loss: 0.6909923161330976
Epoch: 11 | Iteration number: [200/565] 35% | Training loss: 0.6908226776123046
Epoch: 11 | Iteration number: [210/565] 37% | Training loss: 0.6906627467700414
Epoch: 11 | Iteration number: [220/565] 38% | Training loss: 0.6905377336523749
Epoch: 11 | Iteration number: [230/565] 40% | Training loss: 0.6904043345347695
Epoch: 11 | Iteration number: [240/565] 42% | Training loss: 0.6902833186089993
Epoch: 11 | Iteration number: [250/565] 44% | Training loss: 0.6901474413871765
Epoch: 11 | Iteration number: [260/565] 46% | Training loss: 0.6900440805233442
Epoch: 11 | Iteration number: [270/565] 47% | Training loss: 0.689941406470758
Epoch: 11 | Iteration number: [280/565] 49% | Training loss: 0.6898279460413116
Epoch: 11 | Iteration number: [290/565] 51% | Training loss: 0.6897459519320521
Epoch: 11 | Iteration number: [300/565] 53% | Training loss: 0.6896718525886536
Epoch: 11 | Iteration number: [310/565] 54% | Training loss: 0.6896042131608532
Epoch: 11 | Iteration number: [320/565] 56% | Training loss: 0.6895300507545471
Epoch: 11 | Iteration number: [330/565] 58% | Training loss: 0.6894634745337747
Epoch: 11 | Iteration number: [340/565] 60% | Training loss: 0.6894077287000768
Epoch: 11 | Iteration number: [350/565] 61% | Training loss: 0.6893450180121831
Epoch: 11 | Iteration number: [360/565] 63% | Training loss: 0.6892803109354443
Epoch: 11 | Iteration number: [370/565] 65% | Training loss: 0.6892247229009061
Epoch: 11 | Iteration number: [380/565] 67% | Training loss: 0.6891800033418756
Epoch: 11 | Iteration number: [390/565] 69% | Training loss: 0.6891400873661041
Epoch: 11 | Iteration number: [400/565] 70% | Training loss: 0.6890992529690265
Epoch: 11 | Iteration number: [410/565] 72% | Training loss: 0.689048265974696
Epoch: 11 | Iteration number: [420/565] 74% | Training loss: 0.689001533814839
Epoch: 11 | Iteration number: [430/565] 76% | Training loss: 0.6889655041140179
Epoch: 11 | Iteration number: [440/565] 77% | Training loss: 0.6889271168546243
Epoch: 11 | Iteration number: [450/565] 79% | Training loss: 0.6888799697822995
Epoch: 11 | Iteration number: [460/565] 81% | Training loss: 0.6888443648815155
Epoch: 11 | Iteration number: [470/565] 83% | Training loss: 0.6888175406354539
Epoch: 11 | Iteration number: [480/565] 84% | Training loss: 0.6887789821873108
Epoch: 11 | Iteration number: [490/565] 86% | Training loss: 0.6887483192949879
Epoch: 11 | Iteration number: [500/565] 88% | Training loss: 0.6887216867208481
Epoch: 11 | Iteration number: [510/565] 90% | Training loss: 0.6886929201144798
Epoch: 11 | Iteration number: [520/565] 92% | Training loss: 0.6886587012272615
Epoch: 11 | Iteration number: [530/565] 93% | Training loss: 0.6886447426283134
Epoch: 11 | Iteration number: [540/565] 95% | Training loss: 0.6886212981409496
Epoch: 11 | Iteration number: [550/565] 97% | Training loss: 0.6885959134318612
Epoch: 11 | Iteration number: [560/565] 99% | Training loss: 0.6885742149182729

 End of epoch: 11 | Train Loss: 0.6873461844646825 | Training Time: 91 

 End of epoch: 11 | Eval Loss: 0.6908706171172005 | Evaluating Time: 6 
Epoch: 12 | Iteration number: [10/565] 1% | Training loss: 0.756338918209076
Epoch: 12 | Iteration number: [20/565] 3% | Training loss: 0.7219059139490127
Epoch: 12 | Iteration number: [30/565] 5% | Training loss: 0.7103032092253367
Epoch: 12 | Iteration number: [40/565] 7% | Training loss: 0.704445418715477
Epoch: 12 | Iteration number: [50/565] 8% | Training loss: 0.7010492444038391
Epoch: 12 | Iteration number: [60/565] 10% | Training loss: 0.6987568944692611
Epoch: 12 | Iteration number: [70/565] 12% | Training loss: 0.6971511372498104
Epoch: 12 | Iteration number: [80/565] 14% | Training loss: 0.695917359739542
Epoch: 12 | Iteration number: [90/565] 15% | Training loss: 0.6948936978975931
Epoch: 12 | Iteration number: [100/565] 17% | Training loss: 0.6941587769985199
Epoch: 12 | Iteration number: [110/565] 19% | Training loss: 0.6935265985402194
Epoch: 12 | Iteration number: [120/565] 21% | Training loss: 0.6929733653863271
Epoch: 12 | Iteration number: [130/565] 23% | Training loss: 0.6925325233202714
Epoch: 12 | Iteration number: [140/565] 24% | Training loss: 0.6921590949807849
Epoch: 12 | Iteration number: [150/565] 26% | Training loss: 0.6918270842234293
Epoch: 12 | Iteration number: [160/565] 28% | Training loss: 0.6915424834936857
Epoch: 12 | Iteration number: [170/565] 30% | Training loss: 0.691281451547847
Epoch: 12 | Iteration number: [180/565] 31% | Training loss: 0.6910633706384235
Epoch: 12 | Iteration number: [190/565] 33% | Training loss: 0.6908762781243575
Epoch: 12 | Iteration number: [200/565] 35% | Training loss: 0.6906954407691955
Epoch: 12 | Iteration number: [210/565] 37% | Training loss: 0.6905408757073539
Epoch: 12 | Iteration number: [220/565] 38% | Training loss: 0.6903951915827664
Epoch: 12 | Iteration number: [230/565] 40% | Training loss: 0.6902468336665112
Epoch: 12 | Iteration number: [240/565] 42% | Training loss: 0.6901179937024912
Epoch: 12 | Iteration number: [250/565] 44% | Training loss: 0.6900193824768066
Epoch: 12 | Iteration number: [260/565] 46% | Training loss: 0.6899206755252985
Epoch: 12 | Iteration number: [270/565] 47% | Training loss: 0.6898460840737378
Epoch: 12 | Iteration number: [280/565] 49% | Training loss: 0.6897363965000425
Epoch: 12 | Iteration number: [290/565] 51% | Training loss: 0.6896486991438372
Epoch: 12 | Iteration number: [300/565] 53% | Training loss: 0.6895613078276316
Epoch: 12 | Iteration number: [310/565] 54% | Training loss: 0.6894853424641394
Epoch: 12 | Iteration number: [320/565] 56% | Training loss: 0.689413097500801
Epoch: 12 | Iteration number: [330/565] 58% | Training loss: 0.6893403347694512
Epoch: 12 | Iteration number: [340/565] 60% | Training loss: 0.6892761304098017
Epoch: 12 | Iteration number: [350/565] 61% | Training loss: 0.6892093014717102
Epoch: 12 | Iteration number: [360/565] 63% | Training loss: 0.689158224562804
Epoch: 12 | Iteration number: [370/565] 65% | Training loss: 0.689112586588473
Epoch: 12 | Iteration number: [380/565] 67% | Training loss: 0.6890559161964216
Epoch: 12 | Iteration number: [390/565] 69% | Training loss: 0.6890193390540588
Epoch: 12 | Iteration number: [400/565] 70% | Training loss: 0.6889800290763378
Epoch: 12 | Iteration number: [410/565] 72% | Training loss: 0.6889491950593344
Epoch: 12 | Iteration number: [420/565] 74% | Training loss: 0.6889260187035515
Epoch: 12 | Iteration number: [430/565] 76% | Training loss: 0.6888884163180063
Epoch: 12 | Iteration number: [440/565] 77% | Training loss: 0.6888527704910798
Epoch: 12 | Iteration number: [450/565] 79% | Training loss: 0.6888270350297292
Epoch: 12 | Iteration number: [460/565] 81% | Training loss: 0.6888059281784555
Epoch: 12 | Iteration number: [470/565] 83% | Training loss: 0.6887713940853768
Epoch: 12 | Iteration number: [480/565] 84% | Training loss: 0.6887409829845031
Epoch: 12 | Iteration number: [490/565] 86% | Training loss: 0.6887122965588861
Epoch: 12 | Iteration number: [500/565] 88% | Training loss: 0.6886760894060134
Epoch: 12 | Iteration number: [510/565] 90% | Training loss: 0.6886483575783524
Epoch: 12 | Iteration number: [520/565] 92% | Training loss: 0.6886196705011222
Epoch: 12 | Iteration number: [530/565] 93% | Training loss: 0.6885913367541331
Epoch: 12 | Iteration number: [540/565] 95% | Training loss: 0.6885654385443087
Epoch: 12 | Iteration number: [550/565] 97% | Training loss: 0.6885471422022039
Epoch: 12 | Iteration number: [560/565] 99% | Training loss: 0.6885335905211313

 End of epoch: 12 | Train Loss: 0.6873032364170109 | Training Time: 89 

 End of epoch: 12 | Eval Loss: 0.6901243329048157 | Evaluating Time: 6 
Epoch: 13 | Iteration number: [10/565] 1% | Training loss: 0.7564280867576599
Epoch: 13 | Iteration number: [20/565] 3% | Training loss: 0.7217488050460815
Epoch: 13 | Iteration number: [30/565] 5% | Training loss: 0.7102291226387024
Epoch: 13 | Iteration number: [40/565] 7% | Training loss: 0.7045014783740043
Epoch: 13 | Iteration number: [50/565] 8% | Training loss: 0.7010868990421295
Epoch: 13 | Iteration number: [60/565] 10% | Training loss: 0.6987790505091349
Epoch: 13 | Iteration number: [70/565] 12% | Training loss: 0.6970906794071198
Epoch: 13 | Iteration number: [80/565] 14% | Training loss: 0.6958549283444881
Epoch: 13 | Iteration number: [90/565] 15% | Training loss: 0.6948824505011241
Epoch: 13 | Iteration number: [100/565] 17% | Training loss: 0.6941083019971848
Epoch: 13 | Iteration number: [110/565] 19% | Training loss: 0.6934741946783933
Epoch: 13 | Iteration number: [120/565] 21% | Training loss: 0.6929998671015104
Epoch: 13 | Iteration number: [130/565] 23% | Training loss: 0.6925772483532245
Epoch: 13 | Iteration number: [140/565] 24% | Training loss: 0.6921935072966985
Epoch: 13 | Iteration number: [150/565] 26% | Training loss: 0.6918386006355286
Epoch: 13 | Iteration number: [160/565] 28% | Training loss: 0.6915005944669247
Epoch: 13 | Iteration number: [170/565] 30% | Training loss: 0.6912453718045178
Epoch: 13 | Iteration number: [180/565] 31% | Training loss: 0.6910249524646335
Epoch: 13 | Iteration number: [190/565] 33% | Training loss: 0.6908470323211269
Epoch: 13 | Iteration number: [200/565] 35% | Training loss: 0.6906716260313988
Epoch: 13 | Iteration number: [210/565] 37% | Training loss: 0.6904907232239132
Epoch: 13 | Iteration number: [220/565] 38% | Training loss: 0.690336133946072
Epoch: 13 | Iteration number: [230/565] 40% | Training loss: 0.6901848743791166
Epoch: 13 | Iteration number: [240/565] 42% | Training loss: 0.6900541784862677
Epoch: 13 | Iteration number: [250/565] 44% | Training loss: 0.6899126584529877
Epoch: 13 | Iteration number: [260/565] 46% | Training loss: 0.6898191392421722
Epoch: 13 | Iteration number: [270/565] 47% | Training loss: 0.6897280209594303
Epoch: 13 | Iteration number: [280/565] 49% | Training loss: 0.6896402629358428
Epoch: 13 | Iteration number: [290/565] 51% | Training loss: 0.6895593154019323
Epoch: 13 | Iteration number: [300/565] 53% | Training loss: 0.689484369357427
Epoch: 13 | Iteration number: [310/565] 54% | Training loss: 0.6894190994001204
Epoch: 13 | Iteration number: [320/565] 56% | Training loss: 0.6893501209095121
Epoch: 13 | Iteration number: [330/565] 58% | Training loss: 0.6892808397610982
Epoch: 13 | Iteration number: [340/565] 60% | Training loss: 0.6892251419670442
Epoch: 13 | Iteration number: [350/565] 61% | Training loss: 0.6891765642166138
Epoch: 13 | Iteration number: [360/565] 63% | Training loss: 0.6891188351644411
Epoch: 13 | Iteration number: [370/565] 65% | Training loss: 0.6890742082853575
Epoch: 13 | Iteration number: [380/565] 67% | Training loss: 0.6890272724001031
Epoch: 13 | Iteration number: [390/565] 69% | Training loss: 0.68898024559021
Epoch: 13 | Iteration number: [400/565] 70% | Training loss: 0.6889253835380077
Epoch: 13 | Iteration number: [410/565] 72% | Training loss: 0.6888898372650146
Epoch: 13 | Iteration number: [420/565] 74% | Training loss: 0.6888433615366618
Epoch: 13 | Iteration number: [430/565] 76% | Training loss: 0.6888068043908407
Epoch: 13 | Iteration number: [440/565] 77% | Training loss: 0.6887757574970071
Epoch: 13 | Iteration number: [450/565] 79% | Training loss: 0.6887320415178935
Epoch: 13 | Iteration number: [460/565] 81% | Training loss: 0.6886986083310583
Epoch: 13 | Iteration number: [470/565] 83% | Training loss: 0.6886610814865599
Epoch: 13 | Iteration number: [480/565] 84% | Training loss: 0.6886259986708562
Epoch: 13 | Iteration number: [490/565] 86% | Training loss: 0.68860778309861
Epoch: 13 | Iteration number: [500/565] 88% | Training loss: 0.6885878145694733
Epoch: 13 | Iteration number: [510/565] 90% | Training loss: 0.6885565499464671
Epoch: 13 | Iteration number: [520/565] 92% | Training loss: 0.6885264128446579
Epoch: 13 | Iteration number: [530/565] 93% | Training loss: 0.6884874096456564
Epoch: 13 | Iteration number: [540/565] 95% | Training loss: 0.6884610180501585
Epoch: 13 | Iteration number: [550/565] 97% | Training loss: 0.6884420239925384
Epoch: 13 | Iteration number: [560/565] 99% | Training loss: 0.6884162276983261

 End of epoch: 13 | Train Loss: 0.6871848792101429 | Training Time: 88 

 End of epoch: 13 | Eval Loss: 0.6903787170137677 | Evaluating Time: 6 
Epoch: 14 | Iteration number: [10/565] 1% | Training loss: 0.7552867829799652
Epoch: 14 | Iteration number: [20/565] 3% | Training loss: 0.7211565941572189
Epoch: 14 | Iteration number: [30/565] 5% | Training loss: 0.7098071297009786
Epoch: 14 | Iteration number: [40/565] 7% | Training loss: 0.7041276514530181
Epoch: 14 | Iteration number: [50/565] 8% | Training loss: 0.7007558715343475
Epoch: 14 | Iteration number: [60/565] 10% | Training loss: 0.698430581887563
Epoch: 14 | Iteration number: [70/565] 12% | Training loss: 0.6968535201890128
Epoch: 14 | Iteration number: [80/565] 14% | Training loss: 0.6956682458519936
Epoch: 14 | Iteration number: [90/565] 15% | Training loss: 0.6947183827559154
Epoch: 14 | Iteration number: [100/565] 17% | Training loss: 0.6939591163396835
Epoch: 14 | Iteration number: [110/565] 19% | Training loss: 0.6933492730964314
Epoch: 14 | Iteration number: [120/565] 21% | Training loss: 0.6928317914406459
Epoch: 14 | Iteration number: [130/565] 23% | Training loss: 0.6923851118637965
Epoch: 14 | Iteration number: [140/565] 24% | Training loss: 0.691997400351933
Epoch: 14 | Iteration number: [150/565] 26% | Training loss: 0.6916909805933634
Epoch: 14 | Iteration number: [160/565] 28% | Training loss: 0.6913947597146034
Epoch: 14 | Iteration number: [170/565] 30% | Training loss: 0.691113637826022
Epoch: 14 | Iteration number: [180/565] 31% | Training loss: 0.6909038331773546
Epoch: 14 | Iteration number: [190/565] 33% | Training loss: 0.6907063192442844
Epoch: 14 | Iteration number: [200/565] 35% | Training loss: 0.6905295556783676
Epoch: 14 | Iteration number: [210/565] 37% | Training loss: 0.6903756201267243
Epoch: 14 | Iteration number: [220/565] 38% | Training loss: 0.6902289542284878
Epoch: 14 | Iteration number: [230/565] 40% | Training loss: 0.6900949327842049
Epoch: 14 | Iteration number: [240/565] 42% | Training loss: 0.6899679496884346
Epoch: 14 | Iteration number: [250/565] 44% | Training loss: 0.6898434238433838
Epoch: 14 | Iteration number: [260/565] 46% | Training loss: 0.6897368266032292
Epoch: 14 | Iteration number: [270/565] 47% | Training loss: 0.689631747757947
Epoch: 14 | Iteration number: [280/565] 49% | Training loss: 0.6895442668880735
Epoch: 14 | Iteration number: [290/565] 51% | Training loss: 0.6894670948900026
Epoch: 14 | Iteration number: [300/565] 53% | Training loss: 0.6893933548529942
Epoch: 14 | Iteration number: [310/565] 54% | Training loss: 0.6893123138335443
Epoch: 14 | Iteration number: [320/565] 56% | Training loss: 0.6892380548641086
Epoch: 14 | Iteration number: [330/565] 58% | Training loss: 0.68918504949772
Epoch: 14 | Iteration number: [340/565] 60% | Training loss: 0.6891338153797038
Epoch: 14 | Iteration number: [350/565] 61% | Training loss: 0.6890631081376757
Epoch: 14 | Iteration number: [360/565] 63% | Training loss: 0.6890134347809685
Epoch: 14 | Iteration number: [370/565] 65% | Training loss: 0.68895965395747
Epoch: 14 | Iteration number: [380/565] 67% | Training loss: 0.6889048126183058
Epoch: 14 | Iteration number: [390/565] 69% | Training loss: 0.6888542578770565
Epoch: 14 | Iteration number: [400/565] 70% | Training loss: 0.6888098202645778
Epoch: 14 | Iteration number: [410/565] 72% | Training loss: 0.6887790242346322
Epoch: 14 | Iteration number: [420/565] 74% | Training loss: 0.688739512789817
Epoch: 14 | Iteration number: [430/565] 76% | Training loss: 0.6886988693891569
Epoch: 14 | Iteration number: [440/565] 77% | Training loss: 0.6886536396362565
Epoch: 14 | Iteration number: [450/565] 79% | Training loss: 0.6886248103777568
Epoch: 14 | Iteration number: [460/565] 81% | Training loss: 0.6885962687108828
Epoch: 14 | Iteration number: [470/565] 83% | Training loss: 0.6885784620934344
Epoch: 14 | Iteration number: [480/565] 84% | Training loss: 0.6885537245621284
Epoch: 14 | Iteration number: [490/565] 86% | Training loss: 0.6885178145097226
Epoch: 14 | Iteration number: [500/565] 88% | Training loss: 0.6884945521354675
Epoch: 14 | Iteration number: [510/565] 90% | Training loss: 0.6884687861975501
Epoch: 14 | Iteration number: [520/565] 92% | Training loss: 0.6884455395432619
Epoch: 14 | Iteration number: [530/565] 93% | Training loss: 0.6884273090452518
Epoch: 14 | Iteration number: [540/565] 95% | Training loss: 0.6883994381736827
Epoch: 14 | Iteration number: [550/565] 97% | Training loss: 0.6883797487345609
Epoch: 14 | Iteration number: [560/565] 99% | Training loss: 0.6883562450962407

 End of epoch: 14 | Train Loss: 0.6871248061678051 | Training Time: 89 

 End of epoch: 14 | Eval Loss: 0.6908221415110997 | Evaluating Time: 6 
Epoch: 15 | Iteration number: [10/565] 1% | Training loss: 0.7559389114379883
Epoch: 15 | Iteration number: [20/565] 3% | Training loss: 0.7217274278402328
Epoch: 15 | Iteration number: [30/565] 5% | Training loss: 0.7102414389451345
Epoch: 15 | Iteration number: [40/565] 7% | Training loss: 0.7045054286718369
Epoch: 15 | Iteration number: [50/565] 8% | Training loss: 0.700975912809372
Epoch: 15 | Iteration number: [60/565] 10% | Training loss: 0.6985922008752823
Epoch: 15 | Iteration number: [70/565] 12% | Training loss: 0.6969744690826961
Epoch: 15 | Iteration number: [80/565] 14% | Training loss: 0.6957283169031143
Epoch: 15 | Iteration number: [90/565] 15% | Training loss: 0.6947542435593075
Epoch: 15 | Iteration number: [100/565] 17% | Training loss: 0.6939547216892242
Epoch: 15 | Iteration number: [110/565] 19% | Training loss: 0.693310576135462
Epoch: 15 | Iteration number: [120/565] 21% | Training loss: 0.6928036605318387
Epoch: 15 | Iteration number: [130/565] 23% | Training loss: 0.6923577551658336
Epoch: 15 | Iteration number: [140/565] 24% | Training loss: 0.6919407780681338
Epoch: 15 | Iteration number: [150/565] 26% | Training loss: 0.6916307469209035
Epoch: 15 | Iteration number: [160/565] 28% | Training loss: 0.691354063525796
Epoch: 15 | Iteration number: [170/565] 30% | Training loss: 0.6910830620457145
Epoch: 15 | Iteration number: [180/565] 31% | Training loss: 0.6908595105012257
Epoch: 15 | Iteration number: [190/565] 33% | Training loss: 0.6906857063895777
Epoch: 15 | Iteration number: [200/565] 35% | Training loss: 0.6905170553922653
Epoch: 15 | Iteration number: [210/565] 37% | Training loss: 0.6903618608202253
Epoch: 15 | Iteration number: [220/565] 38% | Training loss: 0.6902312357317317
Epoch: 15 | Iteration number: [230/565] 40% | Training loss: 0.6901019282962965
Epoch: 15 | Iteration number: [240/565] 42% | Training loss: 0.689987125992775
Epoch: 15 | Iteration number: [250/565] 44% | Training loss: 0.689866777420044
Epoch: 15 | Iteration number: [260/565] 46% | Training loss: 0.6897734600764055
Epoch: 15 | Iteration number: [270/565] 47% | Training loss: 0.6896733387752816
Epoch: 15 | Iteration number: [280/565] 49% | Training loss: 0.6895724869200162
Epoch: 15 | Iteration number: [290/565] 51% | Training loss: 0.6894898381726495
Epoch: 15 | Iteration number: [300/565] 53% | Training loss: 0.689414487083753
Epoch: 15 | Iteration number: [310/565] 54% | Training loss: 0.6893419632988591
Epoch: 15 | Iteration number: [320/565] 56% | Training loss: 0.6892849650233984
Epoch: 15 | Iteration number: [330/565] 58% | Training loss: 0.6892213976744449
Epoch: 15 | Iteration number: [340/565] 60% | Training loss: 0.6891661405563354
Epoch: 15 | Iteration number: [350/565] 61% | Training loss: 0.6891109338828496
Epoch: 15 | Iteration number: [360/565] 63% | Training loss: 0.689062489900324
Epoch: 15 | Iteration number: [370/565] 65% | Training loss: 0.6890017101893554
Epoch: 15 | Iteration number: [380/565] 67% | Training loss: 0.6889375487440511
Epoch: 15 | Iteration number: [390/565] 69% | Training loss: 0.6888893180932754
Epoch: 15 | Iteration number: [400/565] 70% | Training loss: 0.688843903541565
Epoch: 15 | Iteration number: [410/565] 72% | Training loss: 0.6888065027027596
Epoch: 15 | Iteration number: [420/565] 74% | Training loss: 0.6887752303055354
Epoch: 15 | Iteration number: [430/565] 76% | Training loss: 0.688730997262999
Epoch: 15 | Iteration number: [440/565] 77% | Training loss: 0.688679028776559
Epoch: 15 | Iteration number: [450/565] 79% | Training loss: 0.6886390659544203
Epoch: 15 | Iteration number: [460/565] 81% | Training loss: 0.688604481064755
Epoch: 15 | Iteration number: [470/565] 83% | Training loss: 0.6885679904450761
Epoch: 15 | Iteration number: [480/565] 84% | Training loss: 0.6885380703955889
Epoch: 15 | Iteration number: [490/565] 86% | Training loss: 0.688503196896339
Epoch: 15 | Iteration number: [500/565] 88% | Training loss: 0.6884691190719604
Epoch: 15 | Iteration number: [510/565] 90% | Training loss: 0.6884453207838769
Epoch: 15 | Iteration number: [520/565] 92% | Training loss: 0.688421742618084
Epoch: 15 | Iteration number: [530/565] 93% | Training loss: 0.6883953674784247
Epoch: 15 | Iteration number: [540/565] 95% | Training loss: 0.6883644290544368
Epoch: 15 | Iteration number: [550/565] 97% | Training loss: 0.6883353586630387
Epoch: 15 | Iteration number: [560/565] 99% | Training loss: 0.6883162373942988

 End of epoch: 15 | Train Loss: 0.687090782570628 | Training Time: 90 

 End of epoch: 15 | Eval Loss: 0.6906065600258964 | Evaluating Time: 6 
Epoch: 16 | Iteration number: [10/565] 1% | Training loss: 0.7564317524433136
Epoch: 16 | Iteration number: [20/565] 3% | Training loss: 0.721951374411583
Epoch: 16 | Iteration number: [30/565] 5% | Training loss: 0.7102601706981659
Epoch: 16 | Iteration number: [40/565] 7% | Training loss: 0.7044287741184234
Epoch: 16 | Iteration number: [50/565] 8% | Training loss: 0.7009809613227844
Epoch: 16 | Iteration number: [60/565] 10% | Training loss: 0.6986440976460775
Epoch: 16 | Iteration number: [70/565] 12% | Training loss: 0.6970275342464447
Epoch: 16 | Iteration number: [80/565] 14% | Training loss: 0.69583051353693
Epoch: 16 | Iteration number: [90/565] 15% | Training loss: 0.6948927177323235
Epoch: 16 | Iteration number: [100/565] 17% | Training loss: 0.6941001510620117
Epoch: 16 | Iteration number: [110/565] 19% | Training loss: 0.693444868109443
Epoch: 16 | Iteration number: [120/565] 21% | Training loss: 0.6929057662685713
Epoch: 16 | Iteration number: [130/565] 23% | Training loss: 0.6924804178568033
Epoch: 16 | Iteration number: [140/565] 24% | Training loss: 0.6921159467526845
Epoch: 16 | Iteration number: [150/565] 26% | Training loss: 0.6917767584323883
Epoch: 16 | Iteration number: [160/565] 28% | Training loss: 0.6915085919201374
Epoch: 16 | Iteration number: [170/565] 30% | Training loss: 0.6912448802415062
Epoch: 16 | Iteration number: [180/565] 31% | Training loss: 0.6910312672456106
Epoch: 16 | Iteration number: [190/565] 33% | Training loss: 0.6908285253926327
Epoch: 16 | Iteration number: [200/565] 35% | Training loss: 0.6906479999423027
Epoch: 16 | Iteration number: [210/565] 37% | Training loss: 0.690478918949763
Epoch: 16 | Iteration number: [220/565] 38% | Training loss: 0.6903267150575464
Epoch: 16 | Iteration number: [230/565] 40% | Training loss: 0.6901900905629863
Epoch: 16 | Iteration number: [240/565] 42% | Training loss: 0.6900394044816494
Epoch: 16 | Iteration number: [250/565] 44% | Training loss: 0.6899165065288544
Epoch: 16 | Iteration number: [260/565] 46% | Training loss: 0.6898064221327121
Epoch: 16 | Iteration number: [270/565] 47% | Training loss: 0.6897156894207
Epoch: 16 | Iteration number: [280/565] 49% | Training loss: 0.6896091416478157
Epoch: 16 | Iteration number: [290/565] 51% | Training loss: 0.6895220452341541
Epoch: 16 | Iteration number: [300/565] 53% | Training loss: 0.6894316434860229
Epoch: 16 | Iteration number: [310/565] 54% | Training loss: 0.6893492714051277
Epoch: 16 | Iteration number: [320/565] 56% | Training loss: 0.6892767503857613
Epoch: 16 | Iteration number: [330/565] 58% | Training loss: 0.6892029260144089
Epoch: 16 | Iteration number: [340/565] 60% | Training loss: 0.6891269296407699
Epoch: 16 | Iteration number: [350/565] 61% | Training loss: 0.6890547723429543
Epoch: 16 | Iteration number: [360/565] 63% | Training loss: 0.6889961552288797
Epoch: 16 | Iteration number: [370/565] 65% | Training loss: 0.688940516516969
Epoch: 16 | Iteration number: [380/565] 67% | Training loss: 0.6888888188098606
Epoch: 16 | Iteration number: [390/565] 69% | Training loss: 0.6888494794185345
Epoch: 16 | Iteration number: [400/565] 70% | Training loss: 0.6888172869384289
Epoch: 16 | Iteration number: [410/565] 72% | Training loss: 0.6887800827258971
Epoch: 16 | Iteration number: [420/565] 74% | Training loss: 0.6887428175835383
Epoch: 16 | Iteration number: [430/565] 76% | Training loss: 0.6887000057586404
Epoch: 16 | Iteration number: [440/565] 77% | Training loss: 0.6886573125015606
Epoch: 16 | Iteration number: [450/565] 79% | Training loss: 0.6886181427372826
Epoch: 16 | Iteration number: [460/565] 81% | Training loss: 0.6885879008666329
Epoch: 16 | Iteration number: [470/565] 83% | Training loss: 0.6885485365035686
Epoch: 16 | Iteration number: [480/565] 84% | Training loss: 0.6885135656843583
Epoch: 16 | Iteration number: [490/565] 86% | Training loss: 0.6884780912983174
Epoch: 16 | Iteration number: [500/565] 88% | Training loss: 0.6884501403570176
Epoch: 16 | Iteration number: [510/565] 90% | Training loss: 0.6884260136707157
Epoch: 16 | Iteration number: [520/565] 92% | Training loss: 0.6883900069273435
Epoch: 16 | Iteration number: [530/565] 93% | Training loss: 0.6883647771376484
Epoch: 16 | Iteration number: [540/565] 95% | Training loss: 0.6883394523903176
Epoch: 16 | Iteration number: [550/565] 97% | Training loss: 0.6883117932623083
Epoch: 16 | Iteration number: [560/565] 99% | Training loss: 0.6882909639605455

 End of epoch: 16 | Train Loss: 0.6870640074257303 | Training Time: 89 

 End of epoch: 16 | Eval Loss: 0.6905556235994611 | Evaluating Time: 6 
Epoch: 17 | Iteration number: [10/565] 1% | Training loss: 0.7559444427490234
Epoch: 17 | Iteration number: [20/565] 3% | Training loss: 0.7213244557380676
Epoch: 17 | Iteration number: [30/565] 5% | Training loss: 0.7099445780118306
Epoch: 17 | Iteration number: [40/565] 7% | Training loss: 0.7041972756385804
Epoch: 17 | Iteration number: [50/565] 8% | Training loss: 0.7007594513893127
Epoch: 17 | Iteration number: [60/565] 10% | Training loss: 0.6984540353218714
Epoch: 17 | Iteration number: [70/565] 12% | Training loss: 0.6967553002493722
Epoch: 17 | Iteration number: [80/565] 14% | Training loss: 0.6955416299402714
Epoch: 17 | Iteration number: [90/565] 15% | Training loss: 0.6945621656046973
Epoch: 17 | Iteration number: [100/565] 17% | Training loss: 0.6938590216636658
Epoch: 17 | Iteration number: [110/565] 19% | Training loss: 0.6932601489804008
Epoch: 17 | Iteration number: [120/565] 21% | Training loss: 0.6927781785527866
Epoch: 17 | Iteration number: [130/565] 23% | Training loss: 0.6923627871733445
Epoch: 17 | Iteration number: [140/565] 24% | Training loss: 0.6919637824807848
Epoch: 17 | Iteration number: [150/565] 26% | Training loss: 0.691667720079422
Epoch: 17 | Iteration number: [160/565] 28% | Training loss: 0.6913926046341657
Epoch: 17 | Iteration number: [170/565] 30% | Training loss: 0.6911141451667336
Epoch: 17 | Iteration number: [180/565] 31% | Training loss: 0.690895105070538
Epoch: 17 | Iteration number: [190/565] 33% | Training loss: 0.6906698650435398
Epoch: 17 | Iteration number: [200/565] 35% | Training loss: 0.6904711452126503
Epoch: 17 | Iteration number: [210/565] 37% | Training loss: 0.6903175825164432
Epoch: 17 | Iteration number: [220/565] 38% | Training loss: 0.6901658087968826
Epoch: 17 | Iteration number: [230/565] 40% | Training loss: 0.690028125565985
Epoch: 17 | Iteration number: [240/565] 42% | Training loss: 0.6898943275213242
Epoch: 17 | Iteration number: [250/565] 44% | Training loss: 0.6897949421405792
Epoch: 17 | Iteration number: [260/565] 46% | Training loss: 0.6896985131960649
Epoch: 17 | Iteration number: [270/565] 47% | Training loss: 0.6896112437601443
Epoch: 17 | Iteration number: [280/565] 49% | Training loss: 0.6895201876759529
Epoch: 17 | Iteration number: [290/565] 51% | Training loss: 0.6894398586503391
Epoch: 17 | Iteration number: [300/565] 53% | Training loss: 0.6893345048030217
Epoch: 17 | Iteration number: [310/565] 54% | Training loss: 0.6892529022309088
Epoch: 17 | Iteration number: [320/565] 56% | Training loss: 0.6891744391992688
Epoch: 17 | Iteration number: [330/565] 58% | Training loss: 0.6891210315805493
Epoch: 17 | Iteration number: [340/565] 60% | Training loss: 0.6890701227328356
Epoch: 17 | Iteration number: [350/565] 61% | Training loss: 0.6890186217853002
Epoch: 17 | Iteration number: [360/565] 63% | Training loss: 0.6889643596278296
Epoch: 17 | Iteration number: [370/565] 65% | Training loss: 0.6889147687602688
Epoch: 17 | Iteration number: [380/565] 67% | Training loss: 0.6888566882986772
Epoch: 17 | Iteration number: [390/565] 69% | Training loss: 0.6888128156845387
Epoch: 17 | Iteration number: [400/565] 70% | Training loss: 0.688774354159832
Epoch: 17 | Iteration number: [410/565] 72% | Training loss: 0.6887266212847175
Epoch: 17 | Iteration number: [420/565] 74% | Training loss: 0.6886882384618124
Epoch: 17 | Iteration number: [430/565] 76% | Training loss: 0.6886481976786325
Epoch: 17 | Iteration number: [440/565] 77% | Training loss: 0.6886176042936065
Epoch: 17 | Iteration number: [450/565] 79% | Training loss: 0.6885876499281989
Epoch: 17 | Iteration number: [460/565] 81% | Training loss: 0.688558973307195
Epoch: 17 | Iteration number: [470/565] 83% | Training loss: 0.6885347734106347
Epoch: 17 | Iteration number: [480/565] 84% | Training loss: 0.6885018368562063
Epoch: 17 | Iteration number: [490/565] 86% | Training loss: 0.688470424924578
Epoch: 17 | Iteration number: [500/565] 88% | Training loss: 0.6884381310939789
Epoch: 17 | Iteration number: [510/565] 90% | Training loss: 0.6884078912875231
Epoch: 17 | Iteration number: [520/565] 92% | Training loss: 0.688381678209855
Epoch: 17 | Iteration number: [530/565] 93% | Training loss: 0.6883620607403089
Epoch: 17 | Iteration number: [540/565] 95% | Training loss: 0.688334098899806
Epoch: 17 | Iteration number: [550/565] 97% | Training loss: 0.6883190995996649
Epoch: 17 | Iteration number: [560/565] 99% | Training loss: 0.688295950634139

 End of epoch: 17 | Train Loss: 0.687069661743873 | Training Time: 89 

 End of epoch: 17 | Eval Loss: 0.6906136018889291 | Evaluating Time: 5 
Epoch: 18 | Iteration number: [10/565] 1% | Training loss: 0.7552520513534546
Epoch: 18 | Iteration number: [20/565] 3% | Training loss: 0.7212858974933625
Epoch: 18 | Iteration number: [30/565] 5% | Training loss: 0.7097340484460195
Epoch: 18 | Iteration number: [40/565] 7% | Training loss: 0.704062107205391
Epoch: 18 | Iteration number: [50/565] 8% | Training loss: 0.7006706488132477
Epoch: 18 | Iteration number: [60/565] 10% | Training loss: 0.698415333032608
Epoch: 18 | Iteration number: [70/565] 12% | Training loss: 0.6967989538397108
Epoch: 18 | Iteration number: [80/565] 14% | Training loss: 0.6956146225333214
Epoch: 18 | Iteration number: [90/565] 15% | Training loss: 0.6946505314773983
Epoch: 18 | Iteration number: [100/565] 17% | Training loss: 0.6938650590181351
Epoch: 18 | Iteration number: [110/565] 19% | Training loss: 0.6932490267536857
Epoch: 18 | Iteration number: [120/565] 21% | Training loss: 0.6927305216590564
Epoch: 18 | Iteration number: [130/565] 23% | Training loss: 0.6922846165987161
Epoch: 18 | Iteration number: [140/565] 24% | Training loss: 0.6919072125639234
Epoch: 18 | Iteration number: [150/565] 26% | Training loss: 0.6915980005264282
Epoch: 18 | Iteration number: [160/565] 28% | Training loss: 0.6913182817399501
Epoch: 18 | Iteration number: [170/565] 30% | Training loss: 0.6910979597007527
Epoch: 18 | Iteration number: [180/565] 31% | Training loss: 0.6908826212088267
Epoch: 18 | Iteration number: [190/565] 33% | Training loss: 0.6906810242878764
Epoch: 18 | Iteration number: [200/565] 35% | Training loss: 0.690530561208725
Epoch: 18 | Iteration number: [210/565] 37% | Training loss: 0.6903438553923652
Epoch: 18 | Iteration number: [220/565] 38% | Training loss: 0.6901876132596623
Epoch: 18 | Iteration number: [230/565] 40% | Training loss: 0.6900451395822608
Epoch: 18 | Iteration number: [240/565] 42% | Training loss: 0.6899324248234431
Epoch: 18 | Iteration number: [250/565] 44% | Training loss: 0.6898138251304626
Epoch: 18 | Iteration number: [260/565] 46% | Training loss: 0.6897131355909201
Epoch: 18 | Iteration number: [270/565] 47% | Training loss: 0.6895808034472996
Epoch: 18 | Iteration number: [280/565] 49% | Training loss: 0.6894948216421264
Epoch: 18 | Iteration number: [290/565] 51% | Training loss: 0.6894121396130529
Epoch: 18 | Iteration number: [300/565] 53% | Training loss: 0.6893412737051646
Epoch: 18 | Iteration number: [310/565] 54% | Training loss: 0.6892630380968894
Epoch: 18 | Iteration number: [320/565] 56% | Training loss: 0.6891886917874217
Epoch: 18 | Iteration number: [330/565] 58% | Training loss: 0.6891195940248894
Epoch: 18 | Iteration number: [340/565] 60% | Training loss: 0.6890532972181544
Epoch: 18 | Iteration number: [350/565] 61% | Training loss: 0.6889935493469238
Epoch: 18 | Iteration number: [360/565] 63% | Training loss: 0.688936150736279
Epoch: 18 | Iteration number: [370/565] 65% | Training loss: 0.6888859312276583
Epoch: 18 | Iteration number: [380/565] 67% | Training loss: 0.6888287299557736
Epoch: 18 | Iteration number: [390/565] 69% | Training loss: 0.6887677585467314
Epoch: 18 | Iteration number: [400/565] 70% | Training loss: 0.688737595230341
Epoch: 18 | Iteration number: [410/565] 72% | Training loss: 0.6886976547357513
Epoch: 18 | Iteration number: [420/565] 74% | Training loss: 0.6886632635479881
Epoch: 18 | Iteration number: [430/565] 76% | Training loss: 0.6886204221913981
Epoch: 18 | Iteration number: [440/565] 77% | Training loss: 0.688577625290914
Epoch: 18 | Iteration number: [450/565] 79% | Training loss: 0.6885385102695889
Epoch: 18 | Iteration number: [460/565] 81% | Training loss: 0.6885024306566819
Epoch: 18 | Iteration number: [470/565] 83% | Training loss: 0.6884658296057519
Epoch: 18 | Iteration number: [480/565] 84% | Training loss: 0.6884280155102412
Epoch: 18 | Iteration number: [490/565] 86% | Training loss: 0.6884071687046363
Epoch: 18 | Iteration number: [500/565] 88% | Training loss: 0.6883758273124695
Epoch: 18 | Iteration number: [510/565] 90% | Training loss: 0.6883470633450677
Epoch: 18 | Iteration number: [520/565] 92% | Training loss: 0.6883277237415314
Epoch: 18 | Iteration number: [530/565] 93% | Training loss: 0.688302165719698
Epoch: 18 | Iteration number: [540/565] 95% | Training loss: 0.6882796006070243
Epoch: 18 | Iteration number: [550/565] 97% | Training loss: 0.6882595509832555
Epoch: 18 | Iteration number: [560/565] 99% | Training loss: 0.6882364150668894

 End of epoch: 18 | Train Loss: 0.6870121609848158 | Training Time: 89 

 End of epoch: 18 | Eval Loss: 0.6902290667806353 | Evaluating Time: 6 
Epoch: 19 | Iteration number: [10/565] 1% | Training loss: 0.755332088470459
Epoch: 19 | Iteration number: [20/565] 3% | Training loss: 0.7210082799196244
Epoch: 19 | Iteration number: [30/565] 5% | Training loss: 0.7095724284648895
Epoch: 19 | Iteration number: [40/565] 7% | Training loss: 0.7038859769701957
Epoch: 19 | Iteration number: [50/565] 8% | Training loss: 0.7004765820503235
Epoch: 19 | Iteration number: [60/565] 10% | Training loss: 0.6981387923161189
Epoch: 19 | Iteration number: [70/565] 12% | Training loss: 0.6965517691203527
Epoch: 19 | Iteration number: [80/565] 14% | Training loss: 0.6953563570976258
Epoch: 19 | Iteration number: [90/565] 15% | Training loss: 0.6944085001945496
Epoch: 19 | Iteration number: [100/565] 17% | Training loss: 0.6937039971351624
Epoch: 19 | Iteration number: [110/565] 19% | Training loss: 0.6931107320568778
Epoch: 19 | Iteration number: [120/565] 21% | Training loss: 0.6926214878757795
Epoch: 19 | Iteration number: [130/565] 23% | Training loss: 0.6921792782269991
Epoch: 19 | Iteration number: [140/565] 24% | Training loss: 0.6918408215045929
Epoch: 19 | Iteration number: [150/565] 26% | Training loss: 0.6915297849973043
Epoch: 19 | Iteration number: [160/565] 28% | Training loss: 0.6912354830652475
Epoch: 19 | Iteration number: [170/565] 30% | Training loss: 0.6909994837115793
Epoch: 19 | Iteration number: [180/565] 31% | Training loss: 0.6907902836799622
Epoch: 19 | Iteration number: [190/565] 33% | Training loss: 0.6906044065952301
Epoch: 19 | Iteration number: [200/565] 35% | Training loss: 0.6904141697287559
Epoch: 19 | Iteration number: [210/565] 37% | Training loss: 0.6902375527790614
Epoch: 19 | Iteration number: [220/565] 38% | Training loss: 0.6901037170128389
Epoch: 19 | Iteration number: [230/565] 40% | Training loss: 0.6899832971718001
Epoch: 19 | Iteration number: [240/565] 42% | Training loss: 0.6898661740124226
Epoch: 19 | Iteration number: [250/565] 44% | Training loss: 0.6897219693660737
Epoch: 19 | Iteration number: [260/565] 46% | Training loss: 0.6896098943857046
Epoch: 19 | Iteration number: [270/565] 47% | Training loss: 0.6895180366657399
Epoch: 19 | Iteration number: [280/565] 49% | Training loss: 0.6894329505307334
Epoch: 19 | Iteration number: [290/565] 51% | Training loss: 0.6893404011068673
Epoch: 19 | Iteration number: [300/565] 53% | Training loss: 0.6892626738548279
Epoch: 19 | Iteration number: [310/565] 54% | Training loss: 0.6891794825753857
Epoch: 19 | Iteration number: [320/565] 56% | Training loss: 0.689106565900147
Epoch: 19 | Iteration number: [330/565] 58% | Training loss: 0.6890242397785187
Epoch: 19 | Iteration number: [340/565] 60% | Training loss: 0.6889757265062894
Epoch: 19 | Iteration number: [350/565] 61% | Training loss: 0.6889168523039136
Epoch: 19 | Iteration number: [360/565] 63% | Training loss: 0.6888565353221363
Epoch: 19 | Iteration number: [370/565] 65% | Training loss: 0.6888092765936981
Epoch: 19 | Iteration number: [380/565] 67% | Training loss: 0.6887607759550998
Epoch: 19 | Iteration number: [390/565] 69% | Training loss: 0.6887174702607668
Epoch: 19 | Iteration number: [400/565] 70% | Training loss: 0.6886718387901783
Epoch: 19 | Iteration number: [410/565] 72% | Training loss: 0.6886276480628223
Epoch: 19 | Iteration number: [420/565] 74% | Training loss: 0.6885937624034427
Epoch: 19 | Iteration number: [430/565] 76% | Training loss: 0.6885538968929025
Epoch: 19 | Iteration number: [440/565] 77% | Training loss: 0.6885173719037663
Epoch: 19 | Iteration number: [450/565] 79% | Training loss: 0.6884925525718265
Epoch: 19 | Iteration number: [460/565] 81% | Training loss: 0.6884457212427388
Epoch: 19 | Iteration number: [470/565] 83% | Training loss: 0.6884176785641528
Epoch: 19 | Iteration number: [480/565] 84% | Training loss: 0.6883876410623392
Epoch: 19 | Iteration number: [490/565] 86% | Training loss: 0.6883520567903714
Epoch: 19 | Iteration number: [500/565] 88% | Training loss: 0.6883223716020584
Epoch: 19 | Iteration number: [510/565] 90% | Training loss: 0.6882971666607203
Epoch: 19 | Iteration number: [520/565] 92% | Training loss: 0.6882777198002888
Epoch: 19 | Iteration number: [530/565] 93% | Training loss: 0.6882631881057092
Epoch: 19 | Iteration number: [540/565] 95% | Training loss: 0.6882416794697443
Epoch: 19 | Iteration number: [550/565] 97% | Training loss: 0.6882248461246491
Epoch: 19 | Iteration number: [560/565] 99% | Training loss: 0.6882008344999382

 End of epoch: 19 | Train Loss: 0.6869789713251907 | Training Time: 91 

 End of epoch: 19 | Eval Loss: 0.6905918291636876 | Evaluating Time: 6 
Epoch: 20 | Iteration number: [10/565] 1% | Training loss: 0.7558580815792084
Epoch: 20 | Iteration number: [20/565] 3% | Training loss: 0.7213952004909515
Epoch: 20 | Iteration number: [30/565] 5% | Training loss: 0.7099298675855
Epoch: 20 | Iteration number: [40/565] 7% | Training loss: 0.7041620939970017
Epoch: 20 | Iteration number: [50/565] 8% | Training loss: 0.7007401025295258
Epoch: 20 | Iteration number: [60/565] 10% | Training loss: 0.6984701136747996
Epoch: 20 | Iteration number: [70/565] 12% | Training loss: 0.6968512398856027
Epoch: 20 | Iteration number: [80/565] 14% | Training loss: 0.6956151984632015
Epoch: 20 | Iteration number: [90/565] 15% | Training loss: 0.6946917937861549
Epoch: 20 | Iteration number: [100/565] 17% | Training loss: 0.6939309471845627
Epoch: 20 | Iteration number: [110/565] 19% | Training loss: 0.6933203355832533
Epoch: 20 | Iteration number: [120/565] 21% | Training loss: 0.6927917003631592
Epoch: 20 | Iteration number: [130/565] 23% | Training loss: 0.6923321132476513
Epoch: 20 | Iteration number: [140/565] 24% | Training loss: 0.6919564975159509
Epoch: 20 | Iteration number: [150/565] 26% | Training loss: 0.6916364010175069
Epoch: 20 | Iteration number: [160/565] 28% | Training loss: 0.6913331016898155
Epoch: 20 | Iteration number: [170/565] 30% | Training loss: 0.6910695675541373
Epoch: 20 | Iteration number: [180/565] 31% | Training loss: 0.6908170286152098
Epoch: 20 | Iteration number: [190/565] 33% | Training loss: 0.6906147774897123
Epoch: 20 | Iteration number: [200/565] 35% | Training loss: 0.690463664829731
Epoch: 20 | Iteration number: [210/565] 37% | Training loss: 0.6902762214342754
Epoch: 20 | Iteration number: [220/565] 38% | Training loss: 0.6901240934025158
Epoch: 20 | Iteration number: [230/565] 40% | Training loss: 0.6899724527545598
Epoch: 20 | Iteration number: [240/565] 42% | Training loss: 0.6898350891967614
Epoch: 20 | Iteration number: [250/565] 44% | Training loss: 0.6897187151908875
Epoch: 20 | Iteration number: [260/565] 46% | Training loss: 0.6896319061517715
Epoch: 20 | Iteration number: [270/565] 47% | Training loss: 0.689534623976107
Epoch: 20 | Iteration number: [280/565] 49% | Training loss: 0.68945045790502
Epoch: 20 | Iteration number: [290/565] 51% | Training loss: 0.689355218410492
Epoch: 20 | Iteration number: [300/565] 53% | Training loss: 0.6892991415659586
Epoch: 20 | Iteration number: [310/565] 54% | Training loss: 0.6892282593634821
Epoch: 20 | Iteration number: [320/565] 56% | Training loss: 0.6891605885699391
Epoch: 20 | Iteration number: [330/565] 58% | Training loss: 0.6891024520902923
Epoch: 20 | Iteration number: [340/565] 60% | Training loss: 0.6890404389185064
Epoch: 20 | Iteration number: [350/565] 61% | Training loss: 0.6889871643270765
Epoch: 20 | Iteration number: [360/565] 63% | Training loss: 0.688932319647736
Epoch: 20 | Iteration number: [370/565] 65% | Training loss: 0.6888672079588916
Epoch: 20 | Iteration number: [380/565] 67% | Training loss: 0.6888162380770633
Epoch: 20 | Iteration number: [390/565] 69% | Training loss: 0.6887851265760568
Epoch: 20 | Iteration number: [400/565] 70% | Training loss: 0.6887306478619576
Epoch: 20 | Iteration number: [410/565] 72% | Training loss: 0.6886925505428779
Epoch: 20 | Iteration number: [420/565] 74% | Training loss: 0.6886563024350575
Epoch: 20 | Iteration number: [430/565] 76% | Training loss: 0.688613539518312
Epoch: 20 | Iteration number: [440/565] 77% | Training loss: 0.6885730267925696
Epoch: 20 | Iteration number: [450/565] 79% | Training loss: 0.6885265970230102
Epoch: 20 | Iteration number: [460/565] 81% | Training loss: 0.6884914440953214
Epoch: 20 | Iteration number: [470/565] 83% | Training loss: 0.6884613323718943
Epoch: 20 | Iteration number: [480/565] 84% | Training loss: 0.6884303238242865
Epoch: 20 | Iteration number: [490/565] 86% | Training loss: 0.6883996273790087
Epoch: 20 | Iteration number: [500/565] 88% | Training loss: 0.6883767895698547
Epoch: 20 | Iteration number: [510/565] 90% | Training loss: 0.6883525743204004
Epoch: 20 | Iteration number: [520/565] 92% | Training loss: 0.6883168120796864
Epoch: 20 | Iteration number: [530/565] 93% | Training loss: 0.6883003594740382
Epoch: 20 | Iteration number: [540/565] 95% | Training loss: 0.6882769000751001
Epoch: 20 | Iteration number: [550/565] 97% | Training loss: 0.6882559363408522
Epoch: 20 | Iteration number: [560/565] 99% | Training loss: 0.6882309971111161

 End of epoch: 20 | Train Loss: 0.6870093961732577 | Training Time: 90 

 End of epoch: 20 | Eval Loss: 0.6902938655444554 | Evaluating Time: 6 
Epoch: 21 | Iteration number: [10/565] 1% | Training loss: 0.7556340992450714
Epoch: 21 | Iteration number: [20/565] 3% | Training loss: 0.721396479010582
Epoch: 21 | Iteration number: [30/565] 5% | Training loss: 0.7099526564280192
Epoch: 21 | Iteration number: [40/565] 7% | Training loss: 0.7041408300399781
Epoch: 21 | Iteration number: [50/565] 8% | Training loss: 0.7007134652137756
Epoch: 21 | Iteration number: [60/565] 10% | Training loss: 0.6983467757701873
Epoch: 21 | Iteration number: [70/565] 12% | Training loss: 0.6967060812882014
Epoch: 21 | Iteration number: [80/565] 14% | Training loss: 0.6954990424215793
Epoch: 21 | Iteration number: [90/565] 15% | Training loss: 0.6945936878522238
Epoch: 21 | Iteration number: [100/565] 17% | Training loss: 0.6938250005245209
Epoch: 21 | Iteration number: [110/565] 19% | Training loss: 0.6932055614211342
Epoch: 21 | Iteration number: [120/565] 21% | Training loss: 0.692681344350179
Epoch: 21 | Iteration number: [130/565] 23% | Training loss: 0.6922384051176218
Epoch: 21 | Iteration number: [140/565] 24% | Training loss: 0.691869187780789
Epoch: 21 | Iteration number: [150/565] 26% | Training loss: 0.6915453922748566
Epoch: 21 | Iteration number: [160/565] 28% | Training loss: 0.6912462238222361
Epoch: 21 | Iteration number: [170/565] 30% | Training loss: 0.6910128425149357
Epoch: 21 | Iteration number: [180/565] 31% | Training loss: 0.6907695889472961
Epoch: 21 | Iteration number: [190/565] 33% | Training loss: 0.6905708952953941
Epoch: 21 | Iteration number: [200/565] 35% | Training loss: 0.6903809359669686
Epoch: 21 | Iteration number: [210/565] 37% | Training loss: 0.690205420766558
Epoch: 21 | Iteration number: [220/565] 38% | Training loss: 0.6900367842479186
Epoch: 21 | Iteration number: [230/565] 40% | Training loss: 0.6899200685646223
Epoch: 21 | Iteration number: [240/565] 42% | Training loss: 0.6898135013878346
Epoch: 21 | Iteration number: [250/565] 44% | Training loss: 0.6897078504562378
Epoch: 21 | Iteration number: [260/565] 46% | Training loss: 0.6895983074720089
Epoch: 21 | Iteration number: [270/565] 47% | Training loss: 0.6894959535863664
Epoch: 21 | Iteration number: [280/565] 49% | Training loss: 0.6893907402242933
Epoch: 21 | Iteration number: [290/565] 51% | Training loss: 0.6893154057963141
Epoch: 21 | Iteration number: [300/565] 53% | Training loss: 0.6892257694403331
Epoch: 21 | Iteration number: [310/565] 54% | Training loss: 0.689145125496772
Epoch: 21 | Iteration number: [320/565] 56% | Training loss: 0.6890970489010215
Epoch: 21 | Iteration number: [330/565] 58% | Training loss: 0.6890275884758342
Epoch: 21 | Iteration number: [340/565] 60% | Training loss: 0.6889748724067912
Epoch: 21 | Iteration number: [350/565] 61% | Training loss: 0.6889233934879303
Epoch: 21 | Iteration number: [360/565] 63% | Training loss: 0.6888737887144089
Epoch: 21 | Iteration number: [370/565] 65% | Training loss: 0.6888226356055286
Epoch: 21 | Iteration number: [380/565] 67% | Training loss: 0.688770284621339
Epoch: 21 | Iteration number: [390/565] 69% | Training loss: 0.6887191968086438
Epoch: 21 | Iteration number: [400/565] 70% | Training loss: 0.6886770424246788
Epoch: 21 | Iteration number: [410/565] 72% | Training loss: 0.6886364795812746
Epoch: 21 | Iteration number: [420/565] 74% | Training loss: 0.6885861860854285
Epoch: 21 | Iteration number: [430/565] 76% | Training loss: 0.6885496745275896
Epoch: 21 | Iteration number: [440/565] 77% | Training loss: 0.6885094764557752
Epoch: 21 | Iteration number: [450/565] 79% | Training loss: 0.6884763526916504
Epoch: 21 | Iteration number: [460/565] 81% | Training loss: 0.6884488287179367
Epoch: 21 | Iteration number: [470/565] 83% | Training loss: 0.6884255120094787
Epoch: 21 | Iteration number: [480/565] 84% | Training loss: 0.6883989069610834
Epoch: 21 | Iteration number: [490/565] 86% | Training loss: 0.6883760199254872
Epoch: 21 | Iteration number: [500/565] 88% | Training loss: 0.6883350728750229
Epoch: 21 | Iteration number: [510/565] 90% | Training loss: 0.6882958717205945
Epoch: 21 | Iteration number: [520/565] 92% | Training loss: 0.6882751863736373
Epoch: 21 | Iteration number: [530/565] 93% | Training loss: 0.6882521510124207
Epoch: 21 | Iteration number: [540/565] 95% | Training loss: 0.6882328313809855
Epoch: 21 | Iteration number: [550/565] 97% | Training loss: 0.6882100531187925
Epoch: 21 | Iteration number: [560/565] 99% | Training loss: 0.688182900420257

 End of epoch: 21 | Train Loss: 0.6869614907070599 | Training Time: 91 

 End of epoch: 21 | Eval Loss: 0.6901666522026062 | Evaluating Time: 6 
Epoch: 22 | Iteration number: [10/565] 1% | Training loss: 0.7557453513145447
Epoch: 22 | Iteration number: [20/565] 3% | Training loss: 0.7212263613939285
Epoch: 22 | Iteration number: [30/565] 5% | Training loss: 0.7099398016929627
Epoch: 22 | Iteration number: [40/565] 7% | Training loss: 0.704290883243084
Epoch: 22 | Iteration number: [50/565] 8% | Training loss: 0.700829085111618
Epoch: 22 | Iteration number: [60/565] 10% | Training loss: 0.6984722842772801
Epoch: 22 | Iteration number: [70/565] 12% | Training loss: 0.696830278635025
Epoch: 22 | Iteration number: [80/565] 14% | Training loss: 0.695554929971695
Epoch: 22 | Iteration number: [90/565] 15% | Training loss: 0.6945518745316399
Epoch: 22 | Iteration number: [100/565] 17% | Training loss: 0.6937949365377426
Epoch: 22 | Iteration number: [110/565] 19% | Training loss: 0.6932216460054571
Epoch: 22 | Iteration number: [120/565] 21% | Training loss: 0.6926610440015792
Epoch: 22 | Iteration number: [130/565] 23% | Training loss: 0.6922405252089867
Epoch: 22 | Iteration number: [140/565] 24% | Training loss: 0.6918602956192834
Epoch: 22 | Iteration number: [150/565] 26% | Training loss: 0.6915250730514526
Epoch: 22 | Iteration number: [160/565] 28% | Training loss: 0.6912423864006996
Epoch: 22 | Iteration number: [170/565] 30% | Training loss: 0.6909992863150204
Epoch: 22 | Iteration number: [180/565] 31% | Training loss: 0.6907719400193956
Epoch: 22 | Iteration number: [190/565] 33% | Training loss: 0.6905618880924426
Epoch: 22 | Iteration number: [200/565] 35% | Training loss: 0.6903665381669998
Epoch: 22 | Iteration number: [210/565] 37% | Training loss: 0.6901964772315252
Epoch: 22 | Iteration number: [220/565] 38% | Training loss: 0.6900609799406745
Epoch: 22 | Iteration number: [230/565] 40% | Training loss: 0.6899403875288757
Epoch: 22 | Iteration number: [240/565] 42% | Training loss: 0.6897951357066632
Epoch: 22 | Iteration number: [250/565] 44% | Training loss: 0.6896865193843842
Epoch: 22 | Iteration number: [260/565] 46% | Training loss: 0.6896140724420547
Epoch: 22 | Iteration number: [270/565] 47% | Training loss: 0.6895116711104358
Epoch: 22 | Iteration number: [280/565] 49% | Training loss: 0.6894045991556985
Epoch: 22 | Iteration number: [290/565] 51% | Training loss: 0.6893106466737287
Epoch: 22 | Iteration number: [300/565] 53% | Training loss: 0.6892225529750188
Epoch: 22 | Iteration number: [310/565] 54% | Training loss: 0.6891454767796301
Epoch: 22 | Iteration number: [320/565] 56% | Training loss: 0.6890706529840827
Epoch: 22 | Iteration number: [330/565] 58% | Training loss: 0.6890019458351713
Epoch: 22 | Iteration number: [340/565] 60% | Training loss: 0.6889464076827554
Epoch: 22 | Iteration number: [350/565] 61% | Training loss: 0.6888982481615884
Epoch: 22 | Iteration number: [360/565] 63% | Training loss: 0.6888392746448517
Epoch: 22 | Iteration number: [370/565] 65% | Training loss: 0.6887911740187053
Epoch: 22 | Iteration number: [380/565] 67% | Training loss: 0.6887473636551907
Epoch: 22 | Iteration number: [390/565] 69% | Training loss: 0.6887157061161139
Epoch: 22 | Iteration number: [400/565] 70% | Training loss: 0.6886723136901856
Epoch: 22 | Iteration number: [410/565] 72% | Training loss: 0.6886344649442813
Epoch: 22 | Iteration number: [420/565] 74% | Training loss: 0.6885920084658124
Epoch: 22 | Iteration number: [430/565] 76% | Training loss: 0.6885476774947588
Epoch: 22 | Iteration number: [440/565] 77% | Training loss: 0.6885162853381851
Epoch: 22 | Iteration number: [450/565] 79% | Training loss: 0.6884872641828325
Epoch: 22 | Iteration number: [460/565] 81% | Training loss: 0.6884513135837472
Epoch: 22 | Iteration number: [470/565] 83% | Training loss: 0.6884239315986633
Epoch: 22 | Iteration number: [480/565] 84% | Training loss: 0.6884054404993852
Epoch: 22 | Iteration number: [490/565] 86% | Training loss: 0.6883785605430603
Epoch: 22 | Iteration number: [500/565] 88% | Training loss: 0.6883492867946625
Epoch: 22 | Iteration number: [510/565] 90% | Training loss: 0.6883277575174968
Epoch: 22 | Iteration number: [520/565] 92% | Training loss: 0.6882961933429425
Epoch: 22 | Iteration number: [530/565] 93% | Training loss: 0.6882658469227125
Epoch: 22 | Iteration number: [540/565] 95% | Training loss: 0.6882517704257258
Epoch: 22 | Iteration number: [550/565] 97% | Training loss: 0.6882281951470809
Epoch: 22 | Iteration number: [560/565] 99% | Training loss: 0.6882065773010254

 End of epoch: 22 | Train Loss: 0.686980516826157 | Training Time: 90 

 End of epoch: 22 | Eval Loss: 0.6905216234070914 | Evaluating Time: 6 
Epoch: 23 | Iteration number: [10/565] 1% | Training loss: 0.7559568583965302
Epoch: 23 | Iteration number: [20/565] 3% | Training loss: 0.7216311693191528
Epoch: 23 | Iteration number: [30/565] 5% | Training loss: 0.7098957240581513
Epoch: 23 | Iteration number: [40/565] 7% | Training loss: 0.704187873005867
Epoch: 23 | Iteration number: [50/565] 8% | Training loss: 0.7007400500774383
Epoch: 23 | Iteration number: [60/565] 10% | Training loss: 0.6983955025672912
Epoch: 23 | Iteration number: [70/565] 12% | Training loss: 0.6968103195939745
Epoch: 23 | Iteration number: [80/565] 14% | Training loss: 0.6955642536282539
Epoch: 23 | Iteration number: [90/565] 15% | Training loss: 0.6946234616968366
Epoch: 23 | Iteration number: [100/565] 17% | Training loss: 0.6938889729976654
Epoch: 23 | Iteration number: [110/565] 19% | Training loss: 0.693282148512927
Epoch: 23 | Iteration number: [120/565] 21% | Training loss: 0.6927905167142551
Epoch: 23 | Iteration number: [130/565] 23% | Training loss: 0.6923510147975042
Epoch: 23 | Iteration number: [140/565] 24% | Training loss: 0.6920113687004362
Epoch: 23 | Iteration number: [150/565] 26% | Training loss: 0.6916856741905213
Epoch: 23 | Iteration number: [160/565] 28% | Training loss: 0.6913805402815342
Epoch: 23 | Iteration number: [170/565] 30% | Training loss: 0.691132674147101
Epoch: 23 | Iteration number: [180/565] 31% | Training loss: 0.690897704826461
Epoch: 23 | Iteration number: [190/565] 33% | Training loss: 0.6906793327707993
Epoch: 23 | Iteration number: [200/565] 35% | Training loss: 0.690520060658455
Epoch: 23 | Iteration number: [210/565] 37% | Training loss: 0.6903411672228859
Epoch: 23 | Iteration number: [220/565] 38% | Training loss: 0.6901836606589231
Epoch: 23 | Iteration number: [230/565] 40% | Training loss: 0.6900372093138487
Epoch: 23 | Iteration number: [240/565] 42% | Training loss: 0.6899043711523215
Epoch: 23 | Iteration number: [250/565] 44% | Training loss: 0.6898138525485993
Epoch: 23 | Iteration number: [260/565] 46% | Training loss: 0.689714921437777
Epoch: 23 | Iteration number: [270/565] 47% | Training loss: 0.689632899010623
Epoch: 23 | Iteration number: [280/565] 49% | Training loss: 0.6895167278391975
Epoch: 23 | Iteration number: [290/565] 51% | Training loss: 0.689421861336149
Epoch: 23 | Iteration number: [300/565] 53% | Training loss: 0.6893323036034902
Epoch: 23 | Iteration number: [310/565] 54% | Training loss: 0.6892597279241008
Epoch: 23 | Iteration number: [320/565] 56% | Training loss: 0.6891814954578876
Epoch: 23 | Iteration number: [330/565] 58% | Training loss: 0.6891151588974577
Epoch: 23 | Iteration number: [340/565] 60% | Training loss: 0.6890625178813934
Epoch: 23 | Iteration number: [350/565] 61% | Training loss: 0.689020529304232
Epoch: 23 | Iteration number: [360/565] 63% | Training loss: 0.6889681067731646
Epoch: 23 | Iteration number: [370/565] 65% | Training loss: 0.688914782775415
Epoch: 23 | Iteration number: [380/565] 67% | Training loss: 0.6888618237093875
Epoch: 23 | Iteration number: [390/565] 69% | Training loss: 0.6888207105489877
Epoch: 23 | Iteration number: [400/565] 70% | Training loss: 0.6887717461585998
Epoch: 23 | Iteration number: [410/565] 72% | Training loss: 0.6887271351930572
Epoch: 23 | Iteration number: [420/565] 74% | Training loss: 0.6886831706478482
Epoch: 23 | Iteration number: [430/565] 76% | Training loss: 0.6886476143848065
Epoch: 23 | Iteration number: [440/565] 77% | Training loss: 0.6886043633926998
Epoch: 23 | Iteration number: [450/565] 79% | Training loss: 0.6885669061872695
Epoch: 23 | Iteration number: [460/565] 81% | Training loss: 0.688521102329959
Epoch: 23 | Iteration number: [470/565] 83% | Training loss: 0.6884938913456937
Epoch: 23 | Iteration number: [480/565] 84% | Training loss: 0.6884538256873687
Epoch: 23 | Iteration number: [490/565] 86% | Training loss: 0.6884183071097549
Epoch: 23 | Iteration number: [500/565] 88% | Training loss: 0.6883952728509903
Epoch: 23 | Iteration number: [510/565] 90% | Training loss: 0.6883719536603666
Epoch: 23 | Iteration number: [520/565] 92% | Training loss: 0.6883399243538196
Epoch: 23 | Iteration number: [530/565] 93% | Training loss: 0.6883109617908046
Epoch: 23 | Iteration number: [540/565] 95% | Training loss: 0.6882787591881222
Epoch: 23 | Iteration number: [550/565] 97% | Training loss: 0.688251404653896
Epoch: 23 | Iteration number: [560/565] 99% | Training loss: 0.6882193418485778

 End of epoch: 23 | Train Loss: 0.6869941746239113 | Training Time: 89 

 End of epoch: 23 | Eval Loss: 0.6904445971761431 | Evaluating Time: 6 
Epoch: 24 | Iteration number: [10/565] 1% | Training loss: 0.756095153093338
Epoch: 24 | Iteration number: [20/565] 3% | Training loss: 0.721523305773735
Epoch: 24 | Iteration number: [30/565] 5% | Training loss: 0.709986811876297
Epoch: 24 | Iteration number: [40/565] 7% | Training loss: 0.7041710078716278
Epoch: 24 | Iteration number: [50/565] 8% | Training loss: 0.7007061970233918
Epoch: 24 | Iteration number: [60/565] 10% | Training loss: 0.6983598589897155
Epoch: 24 | Iteration number: [70/565] 12% | Training loss: 0.6967740067413875
Epoch: 24 | Iteration number: [80/565] 14% | Training loss: 0.6955187357962132
Epoch: 24 | Iteration number: [90/565] 15% | Training loss: 0.6946158958805932
Epoch: 24 | Iteration number: [100/565] 17% | Training loss: 0.6938832771778106
Epoch: 24 | Iteration number: [110/565] 19% | Training loss: 0.6932583781805906
Epoch: 24 | Iteration number: [120/565] 21% | Training loss: 0.6927352175116539
Epoch: 24 | Iteration number: [130/565] 23% | Training loss: 0.6922849641396449
Epoch: 24 | Iteration number: [140/565] 24% | Training loss: 0.6919083612305778
Epoch: 24 | Iteration number: [150/565] 26% | Training loss: 0.6915643326441447
Epoch: 24 | Iteration number: [160/565] 28% | Training loss: 0.6912816684693098
Epoch: 24 | Iteration number: [170/565] 30% | Training loss: 0.6910401607260984
Epoch: 24 | Iteration number: [180/565] 31% | Training loss: 0.6908359057373471
Epoch: 24 | Iteration number: [190/565] 33% | Training loss: 0.6906273876365863
Epoch: 24 | Iteration number: [200/565] 35% | Training loss: 0.6904387655854225
Epoch: 24 | Iteration number: [210/565] 37% | Training loss: 0.690274232058298
Epoch: 24 | Iteration number: [220/565] 38% | Training loss: 0.6901488718661395
Epoch: 24 | Iteration number: [230/565] 40% | Training loss: 0.6900053037249524
Epoch: 24 | Iteration number: [240/565] 42% | Training loss: 0.6898692627747853
Epoch: 24 | Iteration number: [250/565] 44% | Training loss: 0.6897319731712341
Epoch: 24 | Iteration number: [260/565] 46% | Training loss: 0.6896281425769513
Epoch: 24 | Iteration number: [270/565] 47% | Training loss: 0.6895283261934916
Epoch: 24 | Iteration number: [280/565] 49% | Training loss: 0.6894296905824117
Epoch: 24 | Iteration number: [290/565] 51% | Training loss: 0.6893403830199406
Epoch: 24 | Iteration number: [300/565] 53% | Training loss: 0.6892627008756002
Epoch: 24 | Iteration number: [310/565] 54% | Training loss: 0.6891822334258787
Epoch: 24 | Iteration number: [320/565] 56% | Training loss: 0.6891132742166519
Epoch: 24 | Iteration number: [330/565] 58% | Training loss: 0.6890391237807997
Epoch: 24 | Iteration number: [340/565] 60% | Training loss: 0.6889815358554616
Epoch: 24 | Iteration number: [350/565] 61% | Training loss: 0.6889072026525225
Epoch: 24 | Iteration number: [360/565] 63% | Training loss: 0.6888614520430565
Epoch: 24 | Iteration number: [370/565] 65% | Training loss: 0.6888030682061169
Epoch: 24 | Iteration number: [380/565] 67% | Training loss: 0.688761030686529
Epoch: 24 | Iteration number: [390/565] 69% | Training loss: 0.6887167099194649
Epoch: 24 | Iteration number: [400/565] 70% | Training loss: 0.6886765120923519
Epoch: 24 | Iteration number: [410/565] 72% | Training loss: 0.6886175478376994
Epoch: 24 | Iteration number: [420/565] 74% | Training loss: 0.6885777672131856
Epoch: 24 | Iteration number: [430/565] 76% | Training loss: 0.6885318456694137
Epoch: 24 | Iteration number: [440/565] 77% | Training loss: 0.6884911198507656
Epoch: 24 | Iteration number: [450/565] 79% | Training loss: 0.688455042441686
Epoch: 24 | Iteration number: [460/565] 81% | Training loss: 0.6884236629890359
Epoch: 24 | Iteration number: [470/565] 83% | Training loss: 0.6883930884777232
Epoch: 24 | Iteration number: [480/565] 84% | Training loss: 0.6883615732192994
Epoch: 24 | Iteration number: [490/565] 86% | Training loss: 0.6883410223892756
Epoch: 24 | Iteration number: [500/565] 88% | Training loss: 0.6883202897310257
Epoch: 24 | Iteration number: [510/565] 90% | Training loss: 0.6882964962837743
Epoch: 24 | Iteration number: [520/565] 92% | Training loss: 0.6882627137578451
Epoch: 24 | Iteration number: [530/565] 93% | Training loss: 0.688237919447557
Epoch: 24 | Iteration number: [540/565] 95% | Training loss: 0.6882073588945248
Epoch: 24 | Iteration number: [550/565] 97% | Training loss: 0.688185895356265
Epoch: 24 | Iteration number: [560/565] 99% | Training loss: 0.688162669220141

 End of epoch: 24 | Train Loss: 0.6869408074733431 | Training Time: 88 

 End of epoch: 24 | Eval Loss: 0.6902382799557277 | Evaluating Time: 6 
Epoch: 25 | Iteration number: [10/565] 1% | Training loss: 0.7559749066829682
Epoch: 25 | Iteration number: [20/565] 3% | Training loss: 0.7214943051338196
Epoch: 25 | Iteration number: [30/565] 5% | Training loss: 0.7099830170472463
Epoch: 25 | Iteration number: [40/565] 7% | Training loss: 0.7042802602052689
Epoch: 25 | Iteration number: [50/565] 8% | Training loss: 0.7008491742610932
Epoch: 25 | Iteration number: [60/565] 10% | Training loss: 0.698554790019989
Epoch: 25 | Iteration number: [70/565] 12% | Training loss: 0.6969074121543339
Epoch: 25 | Iteration number: [80/565] 14% | Training loss: 0.6956470236182213
Epoch: 25 | Iteration number: [90/565] 15% | Training loss: 0.6946671320332422
Epoch: 25 | Iteration number: [100/565] 17% | Training loss: 0.6938672155141831
Epoch: 25 | Iteration number: [110/565] 19% | Training loss: 0.6931908092715523
Epoch: 25 | Iteration number: [120/565] 21% | Training loss: 0.6926710660258929
Epoch: 25 | Iteration number: [130/565] 23% | Training loss: 0.6922356142447545
Epoch: 25 | Iteration number: [140/565] 24% | Training loss: 0.6918819401945386
Epoch: 25 | Iteration number: [150/565] 26% | Training loss: 0.6915415648619334
Epoch: 25 | Iteration number: [160/565] 28% | Training loss: 0.6912334099411964
Epoch: 25 | Iteration number: [170/565] 30% | Training loss: 0.6909879782620598
Epoch: 25 | Iteration number: [180/565] 31% | Training loss: 0.6907760524087482
Epoch: 25 | Iteration number: [190/565] 33% | Training loss: 0.6905759588668221
Epoch: 25 | Iteration number: [200/565] 35% | Training loss: 0.690419242978096
Epoch: 25 | Iteration number: [210/565] 37% | Training loss: 0.6902563041164762
Epoch: 25 | Iteration number: [220/565] 38% | Training loss: 0.6900924912907861
Epoch: 25 | Iteration number: [230/565] 40% | Training loss: 0.6899692377318507
Epoch: 25 | Iteration number: [240/565] 42% | Training loss: 0.6898316266636054
Epoch: 25 | Iteration number: [250/565] 44% | Training loss: 0.6896990270614624
Epoch: 25 | Iteration number: [260/565] 46% | Training loss: 0.6896005261402863
Epoch: 25 | Iteration number: [270/565] 47% | Training loss: 0.689496115843455
Epoch: 25 | Iteration number: [280/565] 49% | Training loss: 0.6893968316061156
Epoch: 25 | Iteration number: [290/565] 51% | Training loss: 0.6893119466715846
Epoch: 25 | Iteration number: [300/565] 53% | Training loss: 0.689229245185852
Epoch: 25 | Iteration number: [310/565] 54% | Training loss: 0.689179999789884
Epoch: 25 | Iteration number: [320/565] 56% | Training loss: 0.68911247048527
Epoch: 25 | Iteration number: [330/565] 58% | Training loss: 0.6890522575739658
Epoch: 25 | Iteration number: [340/565] 60% | Training loss: 0.6889862092102275
Epoch: 25 | Iteration number: [350/565] 61% | Training loss: 0.6889305646078927
Epoch: 25 | Iteration number: [360/565] 63% | Training loss: 0.6888728068934546
Epoch: 25 | Iteration number: [370/565] 65% | Training loss: 0.6888159067244143
Epoch: 25 | Iteration number: [380/565] 67% | Training loss: 0.6887562171409004
Epoch: 25 | Iteration number: [390/565] 69% | Training loss: 0.6887043344668853
Epoch: 25 | Iteration number: [400/565] 70% | Training loss: 0.688656861782074
Epoch: 25 | Iteration number: [410/565] 72% | Training loss: 0.6886104729117417
Epoch: 25 | Iteration number: [420/565] 74% | Training loss: 0.68856435077531
Epoch: 25 | Iteration number: [430/565] 76% | Training loss: 0.6885217911975329
Epoch: 25 | Iteration number: [440/565] 77% | Training loss: 0.6884857939048247
Epoch: 25 | Iteration number: [450/565] 79% | Training loss: 0.6884476024574704
Epoch: 25 | Iteration number: [460/565] 81% | Training loss: 0.6884161294802376
Epoch: 25 | Iteration number: [470/565] 83% | Training loss: 0.6883824887427877
Epoch: 25 | Iteration number: [480/565] 84% | Training loss: 0.688350955521067
Epoch: 25 | Iteration number: [490/565] 86% | Training loss: 0.688327893553948
Epoch: 25 | Iteration number: [500/565] 88% | Training loss: 0.6882928352355957
Epoch: 25 | Iteration number: [510/565] 90% | Training loss: 0.688264771302541
Epoch: 25 | Iteration number: [520/565] 92% | Training loss: 0.6882421187483347
Epoch: 25 | Iteration number: [530/565] 93% | Training loss: 0.6882137009557688
Epoch: 25 | Iteration number: [540/565] 95% | Training loss: 0.6881889915024793
Epoch: 25 | Iteration number: [550/565] 97% | Training loss: 0.6881679857860912
Epoch: 25 | Iteration number: [560/565] 99% | Training loss: 0.6881414358104978

 End of epoch: 25 | Train Loss: 0.6869192231017931 | Training Time: 90 

 End of epoch: 25 | Eval Loss: 0.6905283076422555 | Evaluating Time: 6 
Epoch: 26 | Iteration number: [10/565] 1% | Training loss: 0.7561509311199188
Epoch: 26 | Iteration number: [20/565] 3% | Training loss: 0.72161765396595
Epoch: 26 | Iteration number: [30/565] 5% | Training loss: 0.7099355737368266
Epoch: 26 | Iteration number: [40/565] 7% | Training loss: 0.7040346339344978
Epoch: 26 | Iteration number: [50/565] 8% | Training loss: 0.7005811262130738
Epoch: 26 | Iteration number: [60/565] 10% | Training loss: 0.6983208934466044
Epoch: 26 | Iteration number: [70/565] 12% | Training loss: 0.6966445369379861
Epoch: 26 | Iteration number: [80/565] 14% | Training loss: 0.6954477481544018
Epoch: 26 | Iteration number: [90/565] 15% | Training loss: 0.6945321434073978
Epoch: 26 | Iteration number: [100/565] 17% | Training loss: 0.6937909954786301
Epoch: 26 | Iteration number: [110/565] 19% | Training loss: 0.6931644185022874
Epoch: 26 | Iteration number: [120/565] 21% | Training loss: 0.6926446477572124
Epoch: 26 | Iteration number: [130/565] 23% | Training loss: 0.692200665290539
Epoch: 26 | Iteration number: [140/565] 24% | Training loss: 0.6918354349476951
Epoch: 26 | Iteration number: [150/565] 26% | Training loss: 0.6914756298065186
Epoch: 26 | Iteration number: [160/565] 28% | Training loss: 0.6911730889230967
Epoch: 26 | Iteration number: [170/565] 30% | Training loss: 0.6909114679869484
Epoch: 26 | Iteration number: [180/565] 31% | Training loss: 0.6907007601526048
Epoch: 26 | Iteration number: [190/565] 33% | Training loss: 0.6904922601423765
Epoch: 26 | Iteration number: [200/565] 35% | Training loss: 0.6903392016887665
Epoch: 26 | Iteration number: [210/565] 37% | Training loss: 0.6901557419981276
Epoch: 26 | Iteration number: [220/565] 38% | Training loss: 0.6900118239901283
Epoch: 26 | Iteration number: [230/565] 40% | Training loss: 0.6898895429528278
Epoch: 26 | Iteration number: [240/565] 42% | Training loss: 0.6897682674229145
Epoch: 26 | Iteration number: [250/565] 44% | Training loss: 0.6896689295768738
Epoch: 26 | Iteration number: [260/565] 46% | Training loss: 0.6895684297268208
Epoch: 26 | Iteration number: [270/565] 47% | Training loss: 0.6894844695373817
Epoch: 26 | Iteration number: [280/565] 49% | Training loss: 0.689394944693361
Epoch: 26 | Iteration number: [290/565] 51% | Training loss: 0.6893092402096452
Epoch: 26 | Iteration number: [300/565] 53% | Training loss: 0.6892312463124594
Epoch: 26 | Iteration number: [310/565] 54% | Training loss: 0.6891449299550826
Epoch: 26 | Iteration number: [320/565] 56% | Training loss: 0.6890639444813133
Epoch: 26 | Iteration number: [330/565] 58% | Training loss: 0.6889994763966762
Epoch: 26 | Iteration number: [340/565] 60% | Training loss: 0.6889433711767197
Epoch: 26 | Iteration number: [350/565] 61% | Training loss: 0.6888841644355229
Epoch: 26 | Iteration number: [360/565] 63% | Training loss: 0.6888241204950545
Epoch: 26 | Iteration number: [370/565] 65% | Training loss: 0.6887681990056425
Epoch: 26 | Iteration number: [380/565] 67% | Training loss: 0.6887095001183058
Epoch: 26 | Iteration number: [390/565] 69% | Training loss: 0.688659538825353
Epoch: 26 | Iteration number: [400/565] 70% | Training loss: 0.6886309979856015
Epoch: 26 | Iteration number: [410/565] 72% | Training loss: 0.6885932128603865
Epoch: 26 | Iteration number: [420/565] 74% | Training loss: 0.6885519564151764
Epoch: 26 | Iteration number: [430/565] 76% | Training loss: 0.6885141598623853
Epoch: 26 | Iteration number: [440/565] 77% | Training loss: 0.6884813780134375
Epoch: 26 | Iteration number: [450/565] 79% | Training loss: 0.6884433159563277
Epoch: 26 | Iteration number: [460/565] 81% | Training loss: 0.6884038114029428
Epoch: 26 | Iteration number: [470/565] 83% | Training loss: 0.6883731928277523
Epoch: 26 | Iteration number: [480/565] 84% | Training loss: 0.6883426225433747
Epoch: 26 | Iteration number: [490/565] 86% | Training loss: 0.6883175162636503
Epoch: 26 | Iteration number: [500/565] 88% | Training loss: 0.6882850643396378
Epoch: 26 | Iteration number: [510/565] 90% | Training loss: 0.6882600427842608
Epoch: 26 | Iteration number: [520/565] 92% | Training loss: 0.6882354038266035
Epoch: 26 | Iteration number: [530/565] 93% | Training loss: 0.6882196446634689
Epoch: 26 | Iteration number: [540/565] 95% | Training loss: 0.6881993567502057
Epoch: 26 | Iteration number: [550/565] 97% | Training loss: 0.6881718541275371
Epoch: 26 | Iteration number: [560/565] 99% | Training loss: 0.6881490361477648

 End of epoch: 26 | Train Loss: 0.6869196542596395 | Training Time: 87 

 End of epoch: 26 | Eval Loss: 0.6903418557984489 | Evaluating Time: 6 
Epoch: 27 | Iteration number: [10/565] 1% | Training loss: 0.7561205208301545
Epoch: 27 | Iteration number: [20/565] 3% | Training loss: 0.7215373903512955
Epoch: 27 | Iteration number: [30/565] 5% | Training loss: 0.7098446190357208
Epoch: 27 | Iteration number: [40/565] 7% | Training loss: 0.7040912926197052
Epoch: 27 | Iteration number: [50/565] 8% | Training loss: 0.7006604981422424
Epoch: 27 | Iteration number: [60/565] 10% | Training loss: 0.6983032345771789
Epoch: 27 | Iteration number: [70/565] 12% | Training loss: 0.696753808430263
Epoch: 27 | Iteration number: [80/565] 14% | Training loss: 0.6955263234674931
Epoch: 27 | Iteration number: [90/565] 15% | Training loss: 0.694566117392646
Epoch: 27 | Iteration number: [100/565] 17% | Training loss: 0.6937705802917481
Epoch: 27 | Iteration number: [110/565] 19% | Training loss: 0.6931581838564439
Epoch: 27 | Iteration number: [120/565] 21% | Training loss: 0.6926560272773107
Epoch: 27 | Iteration number: [130/565] 23% | Training loss: 0.6922365949704097
Epoch: 27 | Iteration number: [140/565] 24% | Training loss: 0.6918645582028797
Epoch: 27 | Iteration number: [150/565] 26% | Training loss: 0.6915323177973429
Epoch: 27 | Iteration number: [160/565] 28% | Training loss: 0.6912208165973425
Epoch: 27 | Iteration number: [170/565] 30% | Training loss: 0.6909314821748173
Epoch: 27 | Iteration number: [180/565] 31% | Training loss: 0.6907260729206933
Epoch: 27 | Iteration number: [190/565] 33% | Training loss: 0.6905127776296516
Epoch: 27 | Iteration number: [200/565] 35% | Training loss: 0.6903346320986747
Epoch: 27 | Iteration number: [210/565] 37% | Training loss: 0.6901749877702622
Epoch: 27 | Iteration number: [220/565] 38% | Training loss: 0.6900216154076836
Epoch: 27 | Iteration number: [230/565] 40% | Training loss: 0.6898869522239851
Epoch: 27 | Iteration number: [240/565] 42% | Training loss: 0.6897470268110434
Epoch: 27 | Iteration number: [250/565] 44% | Training loss: 0.6896273951530456
Epoch: 27 | Iteration number: [260/565] 46% | Training loss: 0.6895072322625381
Epoch: 27 | Iteration number: [270/565] 47% | Training loss: 0.6894101054580123
Epoch: 27 | Iteration number: [280/565] 49% | Training loss: 0.6893230627690042
Epoch: 27 | Iteration number: [290/565] 51% | Training loss: 0.6892557579895545
Epoch: 27 | Iteration number: [300/565] 53% | Training loss: 0.6891843771934509
Epoch: 27 | Iteration number: [310/565] 54% | Training loss: 0.6891011347693782
Epoch: 27 | Iteration number: [320/565] 56% | Training loss: 0.689032163284719
Epoch: 27 | Iteration number: [330/565] 58% | Training loss: 0.6889689689332789
Epoch: 27 | Iteration number: [340/565] 60% | Training loss: 0.6889195010942571
Epoch: 27 | Iteration number: [350/565] 61% | Training loss: 0.6888663801125118
Epoch: 27 | Iteration number: [360/565] 63% | Training loss: 0.6888138319055239
Epoch: 27 | Iteration number: [370/565] 65% | Training loss: 0.6887673042915963
Epoch: 27 | Iteration number: [380/565] 67% | Training loss: 0.6887276167932309
Epoch: 27 | Iteration number: [390/565] 69% | Training loss: 0.6886963773996402
Epoch: 27 | Iteration number: [400/565] 70% | Training loss: 0.6886415995657444
Epoch: 27 | Iteration number: [410/565] 72% | Training loss: 0.6885868656926039
Epoch: 27 | Iteration number: [420/565] 74% | Training loss: 0.6885452198130744
Epoch: 27 | Iteration number: [430/565] 76% | Training loss: 0.6885119978771653
Epoch: 27 | Iteration number: [440/565] 77% | Training loss: 0.6884642560373653
Epoch: 27 | Iteration number: [450/565] 79% | Training loss: 0.6884246426158481
Epoch: 27 | Iteration number: [460/565] 81% | Training loss: 0.6883931189775467
Epoch: 27 | Iteration number: [470/565] 83% | Training loss: 0.6883705929238746
Epoch: 27 | Iteration number: [480/565] 84% | Training loss: 0.6883422450472911
Epoch: 27 | Iteration number: [490/565] 86% | Training loss: 0.6883169751994463
Epoch: 27 | Iteration number: [500/565] 88% | Training loss: 0.688278506398201
Epoch: 27 | Iteration number: [510/565] 90% | Training loss: 0.6882528278173184
Epoch: 27 | Iteration number: [520/565] 92% | Training loss: 0.6882270658245453
Epoch: 27 | Iteration number: [530/565] 93% | Training loss: 0.688202616291226
Epoch: 27 | Iteration number: [540/565] 95% | Training loss: 0.688180723675975
Epoch: 27 | Iteration number: [550/565] 97% | Training loss: 0.6881575480374423
Epoch: 27 | Iteration number: [560/565] 99% | Training loss: 0.6881398595869541

 End of epoch: 27 | Train Loss: 0.6869102762863699 | Training Time: 89 

 End of epoch: 27 | Eval Loss: 0.6904201422418866 | Evaluating Time: 6 
Epoch: 28 | Iteration number: [10/565] 1% | Training loss: 0.7552156507968902
Epoch: 28 | Iteration number: [20/565] 3% | Training loss: 0.7209921777248383
Epoch: 28 | Iteration number: [30/565] 5% | Training loss: 0.7096514026323955
Epoch: 28 | Iteration number: [40/565] 7% | Training loss: 0.7038774847984314
Epoch: 28 | Iteration number: [50/565] 8% | Training loss: 0.7005029213428497
Epoch: 28 | Iteration number: [60/565] 10% | Training loss: 0.6982441544532776
Epoch: 28 | Iteration number: [70/565] 12% | Training loss: 0.6966421689305987
Epoch: 28 | Iteration number: [80/565] 14% | Training loss: 0.6954895034432411
Epoch: 28 | Iteration number: [90/565] 15% | Training loss: 0.6945548428429498
Epoch: 28 | Iteration number: [100/565] 17% | Training loss: 0.6937645208835602
Epoch: 28 | Iteration number: [110/565] 19% | Training loss: 0.693178680268201
Epoch: 28 | Iteration number: [120/565] 21% | Training loss: 0.6927079727252324
Epoch: 28 | Iteration number: [130/565] 23% | Training loss: 0.6922793842278994
Epoch: 28 | Iteration number: [140/565] 24% | Training loss: 0.6918864488601685
Epoch: 28 | Iteration number: [150/565] 26% | Training loss: 0.6915844821929932
Epoch: 28 | Iteration number: [160/565] 28% | Training loss: 0.6912749510258436
Epoch: 28 | Iteration number: [170/565] 30% | Training loss: 0.6910405348328983
Epoch: 28 | Iteration number: [180/565] 31% | Training loss: 0.690829391611947
Epoch: 28 | Iteration number: [190/565] 33% | Training loss: 0.6906147718429565
Epoch: 28 | Iteration number: [200/565] 35% | Training loss: 0.6904109182953835
Epoch: 28 | Iteration number: [210/565] 37% | Training loss: 0.6902501489434923
Epoch: 28 | Iteration number: [220/565] 38% | Training loss: 0.6900772864168341
Epoch: 28 | Iteration number: [230/565] 40% | Training loss: 0.6899480161459549
Epoch: 28 | Iteration number: [240/565] 42% | Training loss: 0.6898123048245907
Epoch: 28 | Iteration number: [250/565] 44% | Training loss: 0.6897109730243682
Epoch: 28 | Iteration number: [260/565] 46% | Training loss: 0.6896171248876132
Epoch: 28 | Iteration number: [270/565] 47% | Training loss: 0.6895144742948037
Epoch: 28 | Iteration number: [280/565] 49% | Training loss: 0.6894085660576821
Epoch: 28 | Iteration number: [290/565] 51% | Training loss: 0.6893237751105736
Epoch: 28 | Iteration number: [300/565] 53% | Training loss: 0.6892385663588841
Epoch: 28 | Iteration number: [310/565] 54% | Training loss: 0.6891595082898294
Epoch: 28 | Iteration number: [320/565] 56% | Training loss: 0.6890915894880891
Epoch: 28 | Iteration number: [330/565] 58% | Training loss: 0.6890294028050972
Epoch: 28 | Iteration number: [340/565] 60% | Training loss: 0.6889498668558457
Epoch: 28 | Iteration number: [350/565] 61% | Training loss: 0.6888872647285461
Epoch: 28 | Iteration number: [360/565] 63% | Training loss: 0.6888348655568228
Epoch: 28 | Iteration number: [370/565] 65% | Training loss: 0.688783691380475
Epoch: 28 | Iteration number: [380/565] 67% | Training loss: 0.6887334318537461
Epoch: 28 | Iteration number: [390/565] 69% | Training loss: 0.68869208357273
Epoch: 28 | Iteration number: [400/565] 70% | Training loss: 0.6886605919897556
Epoch: 28 | Iteration number: [410/565] 72% | Training loss: 0.6886130036377325
Epoch: 28 | Iteration number: [420/565] 74% | Training loss: 0.688584421929859
Epoch: 28 | Iteration number: [430/565] 76% | Training loss: 0.6885408730007881
Epoch: 28 | Iteration number: [440/565] 77% | Training loss: 0.6885041339830918
Epoch: 28 | Iteration number: [450/565] 79% | Training loss: 0.6884748147593605
Epoch: 28 | Iteration number: [460/565] 81% | Training loss: 0.6884413680304652
Epoch: 28 | Iteration number: [470/565] 83% | Training loss: 0.6884039795145075
Epoch: 28 | Iteration number: [480/565] 84% | Training loss: 0.688365462422371
Epoch: 28 | Iteration number: [490/565] 86% | Training loss: 0.6883286373955863
Epoch: 28 | Iteration number: [500/565] 88% | Training loss: 0.6882966150045395
Epoch: 28 | Iteration number: [510/565] 90% | Training loss: 0.6882730699052998
Epoch: 28 | Iteration number: [520/565] 92% | Training loss: 0.6882610117013638
Epoch: 28 | Iteration number: [530/565] 93% | Training loss: 0.6882328870161525
Epoch: 28 | Iteration number: [540/565] 95% | Training loss: 0.6882060177900173
Epoch: 28 | Iteration number: [550/565] 97% | Training loss: 0.6881745777346872
Epoch: 28 | Iteration number: [560/565] 99% | Training loss: 0.6881517425179482

 End of epoch: 28 | Train Loss: 0.6869265328466365 | Training Time: 89 

 End of epoch: 28 | Eval Loss: 0.6900610412870135 | Evaluating Time: 6 
Epoch: 29 | Iteration number: [10/565] 1% | Training loss: 0.7559120059013367
Epoch: 29 | Iteration number: [20/565] 3% | Training loss: 0.7212006539106369
Epoch: 29 | Iteration number: [30/565] 5% | Training loss: 0.7099127372105917
Epoch: 29 | Iteration number: [40/565] 7% | Training loss: 0.7041035830974579
Epoch: 29 | Iteration number: [50/565] 8% | Training loss: 0.7005510973930359
Epoch: 29 | Iteration number: [60/565] 10% | Training loss: 0.6983368118604024
Epoch: 29 | Iteration number: [70/565] 12% | Training loss: 0.6966934016772679
Epoch: 29 | Iteration number: [80/565] 14% | Training loss: 0.6954768046736717
Epoch: 29 | Iteration number: [90/565] 15% | Training loss: 0.6945399264494578
Epoch: 29 | Iteration number: [100/565] 17% | Training loss: 0.6937943351268768
Epoch: 29 | Iteration number: [110/565] 19% | Training loss: 0.6931946646083486
Epoch: 29 | Iteration number: [120/565] 21% | Training loss: 0.6926765874028206
Epoch: 29 | Iteration number: [130/565] 23% | Training loss: 0.6922145105325259
Epoch: 29 | Iteration number: [140/565] 24% | Training loss: 0.6918271456445967
Epoch: 29 | Iteration number: [150/565] 26% | Training loss: 0.6914814436435699
Epoch: 29 | Iteration number: [160/565] 28% | Training loss: 0.6911850418895483
Epoch: 29 | Iteration number: [170/565] 30% | Training loss: 0.6909277537289787
Epoch: 29 | Iteration number: [180/565] 31% | Training loss: 0.6906990968518787
Epoch: 29 | Iteration number: [190/565] 33% | Training loss: 0.6904738752465499
Epoch: 29 | Iteration number: [200/565] 35% | Training loss: 0.6903074344992638
Epoch: 29 | Iteration number: [210/565] 37% | Training loss: 0.690148320368358
Epoch: 29 | Iteration number: [220/565] 38% | Training loss: 0.6899733188477429
Epoch: 29 | Iteration number: [230/565] 40% | Training loss: 0.6898656725883484
Epoch: 29 | Iteration number: [240/565] 42% | Training loss: 0.6897505524257819
Epoch: 29 | Iteration number: [250/565] 44% | Training loss: 0.6896270024776459
Epoch: 29 | Iteration number: [260/565] 46% | Training loss: 0.689533663713015
Epoch: 29 | Iteration number: [270/565] 47% | Training loss: 0.6894584039847056
Epoch: 29 | Iteration number: [280/565] 49% | Training loss: 0.6893717035651207
Epoch: 29 | Iteration number: [290/565] 51% | Training loss: 0.6892849768030233
Epoch: 29 | Iteration number: [300/565] 53% | Training loss: 0.6891931384801865
Epoch: 29 | Iteration number: [310/565] 54% | Training loss: 0.6891043538047421
Epoch: 29 | Iteration number: [320/565] 56% | Training loss: 0.6890454899519682
Epoch: 29 | Iteration number: [330/565] 58% | Training loss: 0.6889838760549372
Epoch: 29 | Iteration number: [340/565] 60% | Training loss: 0.6889189502772163
Epoch: 29 | Iteration number: [350/565] 61% | Training loss: 0.6888600483962468
Epoch: 29 | Iteration number: [360/565] 63% | Training loss: 0.6888042350610097
Epoch: 29 | Iteration number: [370/565] 65% | Training loss: 0.6887521142895158
Epoch: 29 | Iteration number: [380/565] 67% | Training loss: 0.6887008144667274
Epoch: 29 | Iteration number: [390/565] 69% | Training loss: 0.6886534998050102
Epoch: 29 | Iteration number: [400/565] 70% | Training loss: 0.6886125227808952
Epoch: 29 | Iteration number: [410/565] 72% | Training loss: 0.6885720798155156
Epoch: 29 | Iteration number: [420/565] 74% | Training loss: 0.6885268598794937
Epoch: 29 | Iteration number: [430/565] 76% | Training loss: 0.6884867268939351
Epoch: 29 | Iteration number: [440/565] 77% | Training loss: 0.6884475565769456
Epoch: 29 | Iteration number: [450/565] 79% | Training loss: 0.6884237594074674
Epoch: 29 | Iteration number: [460/565] 81% | Training loss: 0.6883967078250387
Epoch: 29 | Iteration number: [470/565] 83% | Training loss: 0.6883700481120576
Epoch: 29 | Iteration number: [480/565] 84% | Training loss: 0.688336014499267
Epoch: 29 | Iteration number: [490/565] 86% | Training loss: 0.6883042453503122
Epoch: 29 | Iteration number: [500/565] 88% | Training loss: 0.688286389708519
Epoch: 29 | Iteration number: [510/565] 90% | Training loss: 0.6882624017257316
Epoch: 29 | Iteration number: [520/565] 92% | Training loss: 0.6882364965402163
Epoch: 29 | Iteration number: [530/565] 93% | Training loss: 0.6882110483241531
Epoch: 29 | Iteration number: [540/565] 95% | Training loss: 0.6881827943854861
Epoch: 29 | Iteration number: [550/565] 97% | Training loss: 0.6881567534533414
Epoch: 29 | Iteration number: [560/565] 99% | Training loss: 0.688135987413781

 End of epoch: 29 | Train Loss: 0.6869055930492097 | Training Time: 89 

 End of epoch: 29 | Eval Loss: 0.690270117350987 | Evaluating Time: 6 
Epoch: 30 | Iteration number: [10/565] 1% | Training loss: 0.7558073043823242
Epoch: 30 | Iteration number: [20/565] 3% | Training loss: 0.7212610125541687
Epoch: 30 | Iteration number: [30/565] 5% | Training loss: 0.7098119656244913
Epoch: 30 | Iteration number: [40/565] 7% | Training loss: 0.7041368901729583
Epoch: 30 | Iteration number: [50/565] 8% | Training loss: 0.7007161593437194
Epoch: 30 | Iteration number: [60/565] 10% | Training loss: 0.6984236150979996
Epoch: 30 | Iteration number: [70/565] 12% | Training loss: 0.6967446046216147
Epoch: 30 | Iteration number: [80/565] 14% | Training loss: 0.6954844743013382
Epoch: 30 | Iteration number: [90/565] 15% | Training loss: 0.6945264690452152
Epoch: 30 | Iteration number: [100/565] 17% | Training loss: 0.6937674802541732
Epoch: 30 | Iteration number: [110/565] 19% | Training loss: 0.693153056231412
Epoch: 30 | Iteration number: [120/565] 21% | Training loss: 0.692643266916275
Epoch: 30 | Iteration number: [130/565] 23% | Training loss: 0.6921991114432995
Epoch: 30 | Iteration number: [140/565] 24% | Training loss: 0.6918176340205329
Epoch: 30 | Iteration number: [150/565] 26% | Training loss: 0.6914791528383891
Epoch: 30 | Iteration number: [160/565] 28% | Training loss: 0.691218138858676
Epoch: 30 | Iteration number: [170/565] 30% | Training loss: 0.6909665339133318
Epoch: 30 | Iteration number: [180/565] 31% | Training loss: 0.6907572570774291
Epoch: 30 | Iteration number: [190/565] 33% | Training loss: 0.69056152670007
Epoch: 30 | Iteration number: [200/565] 35% | Training loss: 0.6903781312704086
Epoch: 30 | Iteration number: [210/565] 37% | Training loss: 0.6902024521714165
Epoch: 30 | Iteration number: [220/565] 38% | Training loss: 0.6900492456826297
Epoch: 30 | Iteration number: [230/565] 40% | Training loss: 0.6899306079615717
Epoch: 30 | Iteration number: [240/565] 42% | Training loss: 0.6898076278467973
Epoch: 30 | Iteration number: [250/565] 44% | Training loss: 0.6896919939517975
Epoch: 30 | Iteration number: [260/565] 46% | Training loss: 0.6895869569136546
Epoch: 30 | Iteration number: [270/565] 47% | Training loss: 0.6894855075412326
Epoch: 30 | Iteration number: [280/565] 49% | Training loss: 0.6893784599644798
Epoch: 30 | Iteration number: [290/565] 51% | Training loss: 0.6892897190718815
Epoch: 30 | Iteration number: [300/565] 53% | Training loss: 0.6892004185914993
Epoch: 30 | Iteration number: [310/565] 54% | Training loss: 0.6891085007498341
Epoch: 30 | Iteration number: [320/565] 56% | Training loss: 0.6890322130173445
Epoch: 30 | Iteration number: [330/565] 58% | Training loss: 0.6889623206673247
Epoch: 30 | Iteration number: [340/565] 60% | Training loss: 0.688903075631927
Epoch: 30 | Iteration number: [350/565] 61% | Training loss: 0.6888437187671661
Epoch: 30 | Iteration number: [360/565] 63% | Training loss: 0.6887731701135635
Epoch: 30 | Iteration number: [370/565] 65% | Training loss: 0.6887316647413615
Epoch: 30 | Iteration number: [380/565] 67% | Training loss: 0.6886814228798214
Epoch: 30 | Iteration number: [390/565] 69% | Training loss: 0.6886256619905814
Epoch: 30 | Iteration number: [400/565] 70% | Training loss: 0.6885855004191399
Epoch: 30 | Iteration number: [410/565] 72% | Training loss: 0.6885442461909317
Epoch: 30 | Iteration number: [420/565] 74% | Training loss: 0.6885038262321835
Epoch: 30 | Iteration number: [430/565] 76% | Training loss: 0.6884745924971825
Epoch: 30 | Iteration number: [440/565] 77% | Training loss: 0.6884353406049989
Epoch: 30 | Iteration number: [450/565] 79% | Training loss: 0.6883963000774384
Epoch: 30 | Iteration number: [460/565] 81% | Training loss: 0.688358545821646
Epoch: 30 | Iteration number: [470/565] 83% | Training loss: 0.6883339361941561
Epoch: 30 | Iteration number: [480/565] 84% | Training loss: 0.6883150156587362
Epoch: 30 | Iteration number: [490/565] 86% | Training loss: 0.6882862192027422
Epoch: 30 | Iteration number: [500/565] 88% | Training loss: 0.6882560707330704
Epoch: 30 | Iteration number: [510/565] 90% | Training loss: 0.6882348327075734
Epoch: 30 | Iteration number: [520/565] 92% | Training loss: 0.6882106413061803
Epoch: 30 | Iteration number: [530/565] 93% | Training loss: 0.6881918220025188
Epoch: 30 | Iteration number: [540/565] 95% | Training loss: 0.6881712385901698
Epoch: 30 | Iteration number: [550/565] 97% | Training loss: 0.6881518786603754
Epoch: 30 | Iteration number: [560/565] 99% | Training loss: 0.688134733906814

 End of epoch: 30 | Train Loss: 0.686909508916129 | Training Time: 90 

 End of epoch: 30 | Eval Loss: 0.6908362082072667 | Evaluating Time: 6 
Epoch: 31 | Iteration number: [10/565] 1% | Training loss: 0.755439281463623
Epoch: 31 | Iteration number: [20/565] 3% | Training loss: 0.721484848856926
Epoch: 31 | Iteration number: [30/565] 5% | Training loss: 0.7100387891133626
Epoch: 31 | Iteration number: [40/565] 7% | Training loss: 0.7041328728199006
Epoch: 31 | Iteration number: [50/565] 8% | Training loss: 0.7006162118911743
Epoch: 31 | Iteration number: [60/565] 10% | Training loss: 0.6983118206262589
Epoch: 31 | Iteration number: [70/565] 12% | Training loss: 0.6967224981103625
Epoch: 31 | Iteration number: [80/565] 14% | Training loss: 0.6955349810421467
Epoch: 31 | Iteration number: [90/565] 15% | Training loss: 0.6945795072449579
Epoch: 31 | Iteration number: [100/565] 17% | Training loss: 0.6938101637363434
Epoch: 31 | Iteration number: [110/565] 19% | Training loss: 0.693133579600941
Epoch: 31 | Iteration number: [120/565] 21% | Training loss: 0.6926386495431264
Epoch: 31 | Iteration number: [130/565] 23% | Training loss: 0.6922138952291929
Epoch: 31 | Iteration number: [140/565] 24% | Training loss: 0.6918264248541424
Epoch: 31 | Iteration number: [150/565] 26% | Training loss: 0.6914922157923381
Epoch: 31 | Iteration number: [160/565] 28% | Training loss: 0.6912152148783207
Epoch: 31 | Iteration number: [170/565] 30% | Training loss: 0.6909681642756743
Epoch: 31 | Iteration number: [180/565] 31% | Training loss: 0.6907625380489562
Epoch: 31 | Iteration number: [190/565] 33% | Training loss: 0.6905680336450276
Epoch: 31 | Iteration number: [200/565] 35% | Training loss: 0.6903800609707832
Epoch: 31 | Iteration number: [210/565] 37% | Training loss: 0.6902237826869602
Epoch: 31 | Iteration number: [220/565] 38% | Training loss: 0.6900835004719821
Epoch: 31 | Iteration number: [230/565] 40% | Training loss: 0.6899563268474911
Epoch: 31 | Iteration number: [240/565] 42% | Training loss: 0.6898070439696312
Epoch: 31 | Iteration number: [250/565] 44% | Training loss: 0.6896844971179962
Epoch: 31 | Iteration number: [260/565] 46% | Training loss: 0.6895896634230247
Epoch: 31 | Iteration number: [270/565] 47% | Training loss: 0.6894874605867598
Epoch: 31 | Iteration number: [280/565] 49% | Training loss: 0.6894208886793681
Epoch: 31 | Iteration number: [290/565] 51% | Training loss: 0.6893408119678497
Epoch: 31 | Iteration number: [300/565] 53% | Training loss: 0.6892522644996643
Epoch: 31 | Iteration number: [310/565] 54% | Training loss: 0.6891642441672664
Epoch: 31 | Iteration number: [320/565] 56% | Training loss: 0.6890936946496368
Epoch: 31 | Iteration number: [330/565] 58% | Training loss: 0.6890111175450412
Epoch: 31 | Iteration number: [340/565] 60% | Training loss: 0.6889448448139078
Epoch: 31 | Iteration number: [350/565] 61% | Training loss: 0.6888884149278913
Epoch: 31 | Iteration number: [360/565] 63% | Training loss: 0.6888408331407441
Epoch: 31 | Iteration number: [370/565] 65% | Training loss: 0.6887832820415497
Epoch: 31 | Iteration number: [380/565] 67% | Training loss: 0.6887235462665557
Epoch: 31 | Iteration number: [390/565] 69% | Training loss: 0.688674971079215
Epoch: 31 | Iteration number: [400/565] 70% | Training loss: 0.688628621250391
Epoch: 31 | Iteration number: [410/565] 72% | Training loss: 0.6885831736936802
Epoch: 31 | Iteration number: [420/565] 74% | Training loss: 0.6885465094021388
Epoch: 31 | Iteration number: [430/565] 76% | Training loss: 0.6885073840618133
Epoch: 31 | Iteration number: [440/565] 77% | Training loss: 0.6884728653864427
Epoch: 31 | Iteration number: [450/565] 79% | Training loss: 0.6884355562263065
Epoch: 31 | Iteration number: [460/565] 81% | Training loss: 0.6883950049462526
Epoch: 31 | Iteration number: [470/565] 83% | Training loss: 0.6883711280974936
Epoch: 31 | Iteration number: [480/565] 84% | Training loss: 0.6883438126494487
Epoch: 31 | Iteration number: [490/565] 86% | Training loss: 0.6883140607756011
Epoch: 31 | Iteration number: [500/565] 88% | Training loss: 0.6882816463708877
Epoch: 31 | Iteration number: [510/565] 90% | Training loss: 0.6882569162284626
Epoch: 31 | Iteration number: [520/565] 92% | Training loss: 0.6882315848882382
Epoch: 31 | Iteration number: [530/565] 93% | Training loss: 0.6882100853155244
Epoch: 31 | Iteration number: [540/565] 95% | Training loss: 0.688192359827183
Epoch: 31 | Iteration number: [550/565] 97% | Training loss: 0.688164629611102
Epoch: 31 | Iteration number: [560/565] 99% | Training loss: 0.6881471008062363

 End of epoch: 31 | Train Loss: 0.6869199057595919 | Training Time: 90 

 End of epoch: 31 | Eval Loss: 0.6897141592843192 | Evaluating Time: 6 
Epoch: 32 | Iteration number: [10/565] 1% | Training loss: 0.7553101539611816
Epoch: 32 | Iteration number: [20/565] 3% | Training loss: 0.7210542440414429
Epoch: 32 | Iteration number: [30/565] 5% | Training loss: 0.7095215857028961
Epoch: 32 | Iteration number: [40/565] 7% | Training loss: 0.703979741036892
Epoch: 32 | Iteration number: [50/565] 8% | Training loss: 0.7006213068962097
Epoch: 32 | Iteration number: [60/565] 10% | Training loss: 0.6983571549256643
Epoch: 32 | Iteration number: [70/565] 12% | Training loss: 0.6967101906027112
Epoch: 32 | Iteration number: [80/565] 14% | Training loss: 0.6954354159533978
Epoch: 32 | Iteration number: [90/565] 15% | Training loss: 0.6944775025049845
Epoch: 32 | Iteration number: [100/565] 17% | Training loss: 0.6937408328056336
Epoch: 32 | Iteration number: [110/565] 19% | Training loss: 0.6931366178122433
Epoch: 32 | Iteration number: [120/565] 21% | Training loss: 0.6926132957140605
Epoch: 32 | Iteration number: [130/565] 23% | Training loss: 0.6921921913440411
Epoch: 32 | Iteration number: [140/565] 24% | Training loss: 0.691815931882177
Epoch: 32 | Iteration number: [150/565] 26% | Training loss: 0.6914780636628469
Epoch: 32 | Iteration number: [160/565] 28% | Training loss: 0.6911940723657608
Epoch: 32 | Iteration number: [170/565] 30% | Training loss: 0.6909418379559237
Epoch: 32 | Iteration number: [180/565] 31% | Training loss: 0.6907060924503539
Epoch: 32 | Iteration number: [190/565] 33% | Training loss: 0.690511262103131
Epoch: 32 | Iteration number: [200/565] 35% | Training loss: 0.690318640768528
Epoch: 32 | Iteration number: [210/565] 37% | Training loss: 0.6901498822938829
Epoch: 32 | Iteration number: [220/565] 38% | Training loss: 0.6899974332614378
Epoch: 32 | Iteration number: [230/565] 40% | Training loss: 0.6898605447748433
Epoch: 32 | Iteration number: [240/565] 42% | Training loss: 0.6897472898165385
Epoch: 32 | Iteration number: [250/565] 44% | Training loss: 0.6896367146968841
Epoch: 32 | Iteration number: [260/565] 46% | Training loss: 0.6895154285889405
Epoch: 32 | Iteration number: [270/565] 47% | Training loss: 0.6894032306141323
Epoch: 32 | Iteration number: [280/565] 49% | Training loss: 0.689305644588811
Epoch: 32 | Iteration number: [290/565] 51% | Training loss: 0.6892119709787697
Epoch: 32 | Iteration number: [300/565] 53% | Training loss: 0.6891527791817983
Epoch: 32 | Iteration number: [310/565] 54% | Training loss: 0.6890816990406282
Epoch: 32 | Iteration number: [320/565] 56% | Training loss: 0.6890110705047846
Epoch: 32 | Iteration number: [330/565] 58% | Training loss: 0.6889495165059061
Epoch: 32 | Iteration number: [340/565] 60% | Training loss: 0.6888917789739721
Epoch: 32 | Iteration number: [350/565] 61% | Training loss: 0.6888381269999913
Epoch: 32 | Iteration number: [360/565] 63% | Training loss: 0.688773914012644
Epoch: 32 | Iteration number: [370/565] 65% | Training loss: 0.6887294622691902
Epoch: 32 | Iteration number: [380/565] 67% | Training loss: 0.6886813969988572
Epoch: 32 | Iteration number: [390/565] 69% | Training loss: 0.6886320745333647
Epoch: 32 | Iteration number: [400/565] 70% | Training loss: 0.6885806487500667
Epoch: 32 | Iteration number: [410/565] 72% | Training loss: 0.6885367139083584
Epoch: 32 | Iteration number: [420/565] 74% | Training loss: 0.6884980164823078
Epoch: 32 | Iteration number: [430/565] 76% | Training loss: 0.688462323227594
Epoch: 32 | Iteration number: [440/565] 77% | Training loss: 0.6884232120080428
Epoch: 32 | Iteration number: [450/565] 79% | Training loss: 0.6883907730049558
Epoch: 32 | Iteration number: [460/565] 81% | Training loss: 0.6883503286734871
Epoch: 32 | Iteration number: [470/565] 83% | Training loss: 0.6883237321326073
Epoch: 32 | Iteration number: [480/565] 84% | Training loss: 0.6882903721183539
Epoch: 32 | Iteration number: [490/565] 86% | Training loss: 0.6882624723473374
Epoch: 32 | Iteration number: [500/565] 88% | Training loss: 0.6882372446060181
Epoch: 32 | Iteration number: [510/565] 90% | Training loss: 0.6882078577490414
Epoch: 32 | Iteration number: [520/565] 92% | Training loss: 0.6881974128576426
Epoch: 32 | Iteration number: [530/565] 93% | Training loss: 0.6881702667137362
Epoch: 32 | Iteration number: [540/565] 95% | Training loss: 0.6881514644181287
Epoch: 32 | Iteration number: [550/565] 97% | Training loss: 0.6881299152157524
Epoch: 32 | Iteration number: [560/565] 99% | Training loss: 0.6881123020180634

 End of epoch: 32 | Train Loss: 0.6868869756175353 | Training Time: 87 

 End of epoch: 32 | Eval Loss: 0.6904993908745902 | Evaluating Time: 6 
Epoch: 33 | Iteration number: [10/565] 1% | Training loss: 0.7557962536811829
Epoch: 33 | Iteration number: [20/565] 3% | Training loss: 0.7214278191328048
Epoch: 33 | Iteration number: [30/565] 5% | Training loss: 0.7100446244080861
Epoch: 33 | Iteration number: [40/565] 7% | Training loss: 0.7042425945401192
Epoch: 33 | Iteration number: [50/565] 8% | Training loss: 0.7007003974914551
Epoch: 33 | Iteration number: [60/565] 10% | Training loss: 0.6984414925177892
Epoch: 33 | Iteration number: [70/565] 12% | Training loss: 0.6967474699020386
Epoch: 33 | Iteration number: [80/565] 14% | Training loss: 0.6954696409404277
Epoch: 33 | Iteration number: [90/565] 15% | Training loss: 0.6944509817494287
Epoch: 33 | Iteration number: [100/565] 17% | Training loss: 0.6937137603759765
Epoch: 33 | Iteration number: [110/565] 19% | Training loss: 0.693061311678453
Epoch: 33 | Iteration number: [120/565] 21% | Training loss: 0.6925271396835645
Epoch: 33 | Iteration number: [130/565] 23% | Training loss: 0.6920965268061712
Epoch: 33 | Iteration number: [140/565] 24% | Training loss: 0.6917239878858839
Epoch: 33 | Iteration number: [150/565] 26% | Training loss: 0.6913735524813334
Epoch: 33 | Iteration number: [160/565] 28% | Training loss: 0.691071817651391
Epoch: 33 | Iteration number: [170/565] 30% | Training loss: 0.6907893145785612
Epoch: 33 | Iteration number: [180/565] 31% | Training loss: 0.6905708826250501
Epoch: 33 | Iteration number: [190/565] 33% | Training loss: 0.6903878397063206
Epoch: 33 | Iteration number: [200/565] 35% | Training loss: 0.6902107557654381
Epoch: 33 | Iteration number: [210/565] 37% | Training loss: 0.6900445066747212
Epoch: 33 | Iteration number: [220/565] 38% | Training loss: 0.6899095836010847
Epoch: 33 | Iteration number: [230/565] 40% | Training loss: 0.6897719186285268
Epoch: 33 | Iteration number: [240/565] 42% | Training loss: 0.689645783106486
Epoch: 33 | Iteration number: [250/565] 44% | Training loss: 0.6895318772792817
Epoch: 33 | Iteration number: [260/565] 46% | Training loss: 0.6894477514120249
Epoch: 33 | Iteration number: [270/565] 47% | Training loss: 0.6893474333816104
Epoch: 33 | Iteration number: [280/565] 49% | Training loss: 0.6892619473593575
Epoch: 33 | Iteration number: [290/565] 51% | Training loss: 0.6891842757833415
Epoch: 33 | Iteration number: [300/565] 53% | Training loss: 0.6891104890902837
Epoch: 33 | Iteration number: [310/565] 54% | Training loss: 0.6890429579442547
Epoch: 33 | Iteration number: [320/565] 56% | Training loss: 0.6889662681147456
Epoch: 33 | Iteration number: [330/565] 58% | Training loss: 0.6889035963650906
Epoch: 33 | Iteration number: [340/565] 60% | Training loss: 0.6888457321068819
Epoch: 33 | Iteration number: [350/565] 61% | Training loss: 0.688795131444931
Epoch: 33 | Iteration number: [360/565] 63% | Training loss: 0.6887525255481403
Epoch: 33 | Iteration number: [370/565] 65% | Training loss: 0.688703834849435
Epoch: 33 | Iteration number: [380/565] 67% | Training loss: 0.688668618547289
Epoch: 33 | Iteration number: [390/565] 69% | Training loss: 0.6886186338388003
Epoch: 33 | Iteration number: [400/565] 70% | Training loss: 0.6885716766119003
Epoch: 33 | Iteration number: [410/565] 72% | Training loss: 0.6885339156883519
Epoch: 33 | Iteration number: [420/565] 74% | Training loss: 0.6885026934601012
Epoch: 33 | Iteration number: [430/565] 76% | Training loss: 0.6884611418080885
Epoch: 33 | Iteration number: [440/565] 77% | Training loss: 0.688424186814915
Epoch: 33 | Iteration number: [450/565] 79% | Training loss: 0.6883953526284959
Epoch: 33 | Iteration number: [460/565] 81% | Training loss: 0.6883644768725271
Epoch: 33 | Iteration number: [470/565] 83% | Training loss: 0.688335702901191
Epoch: 33 | Iteration number: [480/565] 84% | Training loss: 0.6883180055767297
Epoch: 33 | Iteration number: [490/565] 86% | Training loss: 0.6882788109536073
Epoch: 33 | Iteration number: [500/565] 88% | Training loss: 0.6882576767206192
Epoch: 33 | Iteration number: [510/565] 90% | Training loss: 0.6882217054273568
Epoch: 33 | Iteration number: [520/565] 92% | Training loss: 0.6881969489730322
Epoch: 33 | Iteration number: [530/565] 93% | Training loss: 0.6881752807014393
Epoch: 33 | Iteration number: [540/565] 95% | Training loss: 0.6881541032482077
Epoch: 33 | Iteration number: [550/565] 97% | Training loss: 0.6881304298747669
Epoch: 33 | Iteration number: [560/565] 99% | Training loss: 0.6881124292101178

 End of epoch: 33 | Train Loss: 0.686880809543407 | Training Time: 90 

 End of epoch: 33 | Eval Loss: 0.6902293222291129 | Evaluating Time: 6 
Epoch: 34 | Iteration number: [10/565] 1% | Training loss: 0.7554226398468018
Epoch: 34 | Iteration number: [20/565] 3% | Training loss: 0.7212297707796097
Epoch: 34 | Iteration number: [30/565] 5% | Training loss: 0.709817506869634
Epoch: 34 | Iteration number: [40/565] 7% | Training loss: 0.7041310295462608
Epoch: 34 | Iteration number: [50/565] 8% | Training loss: 0.700497852563858
Epoch: 34 | Iteration number: [60/565] 10% | Training loss: 0.6983269800742468
Epoch: 34 | Iteration number: [70/565] 12% | Training loss: 0.6966791008199964
Epoch: 34 | Iteration number: [80/565] 14% | Training loss: 0.6954898238182068
Epoch: 34 | Iteration number: [90/565] 15% | Training loss: 0.6945057948430379
Epoch: 34 | Iteration number: [100/565] 17% | Training loss: 0.6937234336137772
Epoch: 34 | Iteration number: [110/565] 19% | Training loss: 0.6931228572672063
Epoch: 34 | Iteration number: [120/565] 21% | Training loss: 0.6926198994119962
Epoch: 34 | Iteration number: [130/565] 23% | Training loss: 0.6921526023974786
Epoch: 34 | Iteration number: [140/565] 24% | Training loss: 0.6917744879211698
Epoch: 34 | Iteration number: [150/565] 26% | Training loss: 0.6914347489674886
Epoch: 34 | Iteration number: [160/565] 28% | Training loss: 0.6911817468702793
Epoch: 34 | Iteration number: [170/565] 30% | Training loss: 0.6909407363218419
Epoch: 34 | Iteration number: [180/565] 31% | Training loss: 0.6906956765386794
Epoch: 34 | Iteration number: [190/565] 33% | Training loss: 0.6905156646904193
Epoch: 34 | Iteration number: [200/565] 35% | Training loss: 0.690342313349247
Epoch: 34 | Iteration number: [210/565] 37% | Training loss: 0.6901994356087275
Epoch: 34 | Iteration number: [220/565] 38% | Training loss: 0.6900626662102612
Epoch: 34 | Iteration number: [230/565] 40% | Training loss: 0.6899155564930128
Epoch: 34 | Iteration number: [240/565] 42% | Training loss: 0.6897908588250478
Epoch: 34 | Iteration number: [250/565] 44% | Training loss: 0.6896862637996674
Epoch: 34 | Iteration number: [260/565] 46% | Training loss: 0.6895754114939616
Epoch: 34 | Iteration number: [270/565] 47% | Training loss: 0.6894571485342803
Epoch: 34 | Iteration number: [280/565] 49% | Training loss: 0.6893651732376643
Epoch: 34 | Iteration number: [290/565] 51% | Training loss: 0.6892962585235464
Epoch: 34 | Iteration number: [300/565] 53% | Training loss: 0.6892158035437266
Epoch: 34 | Iteration number: [310/565] 54% | Training loss: 0.689131494491331
Epoch: 34 | Iteration number: [320/565] 56% | Training loss: 0.689060395769775
Epoch: 34 | Iteration number: [330/565] 58% | Training loss: 0.6889914171262221
Epoch: 34 | Iteration number: [340/565] 60% | Training loss: 0.6889269225737628
Epoch: 34 | Iteration number: [350/565] 61% | Training loss: 0.6888668409415654
Epoch: 34 | Iteration number: [360/565] 63% | Training loss: 0.6888052039676242
Epoch: 34 | Iteration number: [370/565] 65% | Training loss: 0.6887529392500181
Epoch: 34 | Iteration number: [380/565] 67% | Training loss: 0.6886968512284128
Epoch: 34 | Iteration number: [390/565] 69% | Training loss: 0.6886551453517034
Epoch: 34 | Iteration number: [400/565] 70% | Training loss: 0.6886026658117771
Epoch: 34 | Iteration number: [410/565] 72% | Training loss: 0.6885659100078955
Epoch: 34 | Iteration number: [420/565] 74% | Training loss: 0.688521734731538
Epoch: 34 | Iteration number: [430/565] 76% | Training loss: 0.6884781472904737
Epoch: 34 | Iteration number: [440/565] 77% | Training loss: 0.6884392363103953
Epoch: 34 | Iteration number: [450/565] 79% | Training loss: 0.6884050341447194
Epoch: 34 | Iteration number: [460/565] 81% | Training loss: 0.6883737461722416
Epoch: 34 | Iteration number: [470/565] 83% | Training loss: 0.6883409930036423
Epoch: 34 | Iteration number: [480/565] 84% | Training loss: 0.6883078552782536
Epoch: 34 | Iteration number: [490/565] 86% | Training loss: 0.6882859022033457
Epoch: 34 | Iteration number: [500/565] 88% | Training loss: 0.6882623429298401
Epoch: 34 | Iteration number: [510/565] 90% | Training loss: 0.6882385922413247
Epoch: 34 | Iteration number: [520/565] 92% | Training loss: 0.6882026286079334
Epoch: 34 | Iteration number: [530/565] 93% | Training loss: 0.6881732684261394
Epoch: 34 | Iteration number: [540/565] 95% | Training loss: 0.6881467621635508
Epoch: 34 | Iteration number: [550/565] 97% | Training loss: 0.688117173910141
Epoch: 34 | Iteration number: [560/565] 99% | Training loss: 0.6880952556218419

 End of epoch: 34 | Train Loss: 0.6868669988834752 | Training Time: 89 

 End of epoch: 34 | Eval Loss: 0.6903407147952488 | Evaluating Time: 6 
Epoch: 35 | Iteration number: [10/565] 1% | Training loss: 0.7555359721183776
Epoch: 35 | Iteration number: [20/565] 3% | Training loss: 0.7211774945259094
Epoch: 35 | Iteration number: [30/565] 5% | Training loss: 0.7097506582736969
Epoch: 35 | Iteration number: [40/565] 7% | Training loss: 0.7039856225252151
Epoch: 35 | Iteration number: [50/565] 8% | Training loss: 0.7005497097969056
Epoch: 35 | Iteration number: [60/565] 10% | Training loss: 0.698252339164416
Epoch: 35 | Iteration number: [70/565] 12% | Training loss: 0.6966365482125964
Epoch: 35 | Iteration number: [80/565] 14% | Training loss: 0.6953926369547844
Epoch: 35 | Iteration number: [90/565] 15% | Training loss: 0.6944576813115014
Epoch: 35 | Iteration number: [100/565] 17% | Training loss: 0.6937124598026275
Epoch: 35 | Iteration number: [110/565] 19% | Training loss: 0.6931137057867918
Epoch: 35 | Iteration number: [120/565] 21% | Training loss: 0.6925677294532459
Epoch: 35 | Iteration number: [130/565] 23% | Training loss: 0.6921124384953425
Epoch: 35 | Iteration number: [140/565] 24% | Training loss: 0.6917155964033944
Epoch: 35 | Iteration number: [150/565] 26% | Training loss: 0.6914010834693909
Epoch: 35 | Iteration number: [160/565] 28% | Training loss: 0.6911353174597025
Epoch: 35 | Iteration number: [170/565] 30% | Training loss: 0.6909006472896128
Epoch: 35 | Iteration number: [180/565] 31% | Training loss: 0.6907031248013179
Epoch: 35 | Iteration number: [190/565] 33% | Training loss: 0.6904918786726499
Epoch: 35 | Iteration number: [200/565] 35% | Training loss: 0.6903182417154312
Epoch: 35 | Iteration number: [210/565] 37% | Training loss: 0.6901478633994148
Epoch: 35 | Iteration number: [220/565] 38% | Training loss: 0.6900034259666096
Epoch: 35 | Iteration number: [230/565] 40% | Training loss: 0.6898797960385032
Epoch: 35 | Iteration number: [240/565] 42% | Training loss: 0.6897553185621897
Epoch: 35 | Iteration number: [250/565] 44% | Training loss: 0.6896340777873993
Epoch: 35 | Iteration number: [260/565] 46% | Training loss: 0.6895293334355721
Epoch: 35 | Iteration number: [270/565] 47% | Training loss: 0.6894290018964697
Epoch: 35 | Iteration number: [280/565] 49% | Training loss: 0.689319043287209
Epoch: 35 | Iteration number: [290/565] 51% | Training loss: 0.6892296745859343
Epoch: 35 | Iteration number: [300/565] 53% | Training loss: 0.6891434619824092
Epoch: 35 | Iteration number: [310/565] 54% | Training loss: 0.6890629849126262
Epoch: 35 | Iteration number: [320/565] 56% | Training loss: 0.6889833927154541
Epoch: 35 | Iteration number: [330/565] 58% | Training loss: 0.688921265891104
Epoch: 35 | Iteration number: [340/565] 60% | Training loss: 0.688848750205601
Epoch: 35 | Iteration number: [350/565] 61% | Training loss: 0.6887928121430533
Epoch: 35 | Iteration number: [360/565] 63% | Training loss: 0.6887431951032744
Epoch: 35 | Iteration number: [370/565] 65% | Training loss: 0.6886997085970801
Epoch: 35 | Iteration number: [380/565] 67% | Training loss: 0.6886584663077404
Epoch: 35 | Iteration number: [390/565] 69% | Training loss: 0.6886197441663497
Epoch: 35 | Iteration number: [400/565] 70% | Training loss: 0.6885760647058486
Epoch: 35 | Iteration number: [410/565] 72% | Training loss: 0.6885452498749989
Epoch: 35 | Iteration number: [420/565] 74% | Training loss: 0.6884961464575359
Epoch: 35 | Iteration number: [430/565] 76% | Training loss: 0.6884579794351444
Epoch: 35 | Iteration number: [440/565] 77% | Training loss: 0.6884283802726052
Epoch: 35 | Iteration number: [450/565] 79% | Training loss: 0.6883883072270287
Epoch: 35 | Iteration number: [460/565] 81% | Training loss: 0.6883541804292928
Epoch: 35 | Iteration number: [470/565] 83% | Training loss: 0.6883180012094213
Epoch: 35 | Iteration number: [480/565] 84% | Training loss: 0.6882893727471431
Epoch: 35 | Iteration number: [490/565] 86% | Training loss: 0.68826470715659
Epoch: 35 | Iteration number: [500/565] 88% | Training loss: 0.6882379969358444
Epoch: 35 | Iteration number: [510/565] 90% | Training loss: 0.688215909985935
Epoch: 35 | Iteration number: [520/565] 92% | Training loss: 0.6881995445260635
Epoch: 35 | Iteration number: [530/565] 93% | Training loss: 0.6881778295310038
Epoch: 35 | Iteration number: [540/565] 95% | Training loss: 0.6881605103060051
Epoch: 35 | Iteration number: [550/565] 97% | Training loss: 0.6881374605135484
Epoch: 35 | Iteration number: [560/565] 99% | Training loss: 0.6881134923015322

 End of epoch: 35 | Train Loss: 0.6868851929639292 | Training Time: 90 

 End of epoch: 35 | Eval Loss: 0.6903727735791888 | Evaluating Time: 6 
Epoch: 36 | Iteration number: [10/565] 1% | Training loss: 0.7560942888259887
Epoch: 36 | Iteration number: [20/565] 3% | Training loss: 0.7212048590183258
Epoch: 36 | Iteration number: [30/565] 5% | Training loss: 0.7099576195081075
Epoch: 36 | Iteration number: [40/565] 7% | Training loss: 0.7042936727404594
Epoch: 36 | Iteration number: [50/565] 8% | Training loss: 0.7007716619968414
Epoch: 36 | Iteration number: [60/565] 10% | Training loss: 0.6984621316194535
Epoch: 36 | Iteration number: [70/565] 12% | Training loss: 0.6968034982681275
Epoch: 36 | Iteration number: [80/565] 14% | Training loss: 0.6955738045275212
Epoch: 36 | Iteration number: [90/565] 15% | Training loss: 0.6946115473906199
Epoch: 36 | Iteration number: [100/565] 17% | Training loss: 0.6938388794660568
Epoch: 36 | Iteration number: [110/565] 19% | Training loss: 0.6932699100537734
Epoch: 36 | Iteration number: [120/565] 21% | Training loss: 0.6927153507868449
Epoch: 36 | Iteration number: [130/565] 23% | Training loss: 0.6922682945544903
Epoch: 36 | Iteration number: [140/565] 24% | Training loss: 0.6918832067932401
Epoch: 36 | Iteration number: [150/565] 26% | Training loss: 0.6915508202711741
Epoch: 36 | Iteration number: [160/565] 28% | Training loss: 0.691262849420309
Epoch: 36 | Iteration number: [170/565] 30% | Training loss: 0.6909805865848766
Epoch: 36 | Iteration number: [180/565] 31% | Training loss: 0.6907609810431798
Epoch: 36 | Iteration number: [190/565] 33% | Training loss: 0.6905736888709821
Epoch: 36 | Iteration number: [200/565] 35% | Training loss: 0.6903913843631745
Epoch: 36 | Iteration number: [210/565] 37% | Training loss: 0.6902404058547247
Epoch: 36 | Iteration number: [220/565] 38% | Training loss: 0.6900745294310829
Epoch: 36 | Iteration number: [230/565] 40% | Training loss: 0.6899382145508476
Epoch: 36 | Iteration number: [240/565] 42% | Training loss: 0.6898231729865074
Epoch: 36 | Iteration number: [250/565] 44% | Training loss: 0.689712890625
Epoch: 36 | Iteration number: [260/565] 46% | Training loss: 0.6895927172440749
Epoch: 36 | Iteration number: [270/565] 47% | Training loss: 0.6894857475051174
Epoch: 36 | Iteration number: [280/565] 49% | Training loss: 0.6893960799489702
Epoch: 36 | Iteration number: [290/565] 51% | Training loss: 0.6892981995796336
Epoch: 36 | Iteration number: [300/565] 53% | Training loss: 0.6892096894979477
Epoch: 36 | Iteration number: [310/565] 54% | Training loss: 0.6891404759499334
Epoch: 36 | Iteration number: [320/565] 56% | Training loss: 0.6890745863318444
Epoch: 36 | Iteration number: [330/565] 58% | Training loss: 0.689000833756996
Epoch: 36 | Iteration number: [340/565] 60% | Training loss: 0.6889405504745596
Epoch: 36 | Iteration number: [350/565] 61% | Training loss: 0.6888810266767229
Epoch: 36 | Iteration number: [360/565] 63% | Training loss: 0.6888251864247852
Epoch: 36 | Iteration number: [370/565] 65% | Training loss: 0.6887584977858775
Epoch: 36 | Iteration number: [380/565] 67% | Training loss: 0.6886989519784324
Epoch: 36 | Iteration number: [390/565] 69% | Training loss: 0.6886441501287314
Epoch: 36 | Iteration number: [400/565] 70% | Training loss: 0.6885974961519241
Epoch: 36 | Iteration number: [410/565] 72% | Training loss: 0.6885422318446927
Epoch: 36 | Iteration number: [420/565] 74% | Training loss: 0.6885140566598802
Epoch: 36 | Iteration number: [430/565] 76% | Training loss: 0.6884665095528891
Epoch: 36 | Iteration number: [440/565] 77% | Training loss: 0.6884467864578421
Epoch: 36 | Iteration number: [450/565] 79% | Training loss: 0.6884095436996884
Epoch: 36 | Iteration number: [460/565] 81% | Training loss: 0.6883696591076643
Epoch: 36 | Iteration number: [470/565] 83% | Training loss: 0.6883395144279967
Epoch: 36 | Iteration number: [480/565] 84% | Training loss: 0.6882970663408439
Epoch: 36 | Iteration number: [490/565] 86% | Training loss: 0.6882627084547159
Epoch: 36 | Iteration number: [500/565] 88% | Training loss: 0.6882373608350754
Epoch: 36 | Iteration number: [510/565] 90% | Training loss: 0.688215845005185
Epoch: 36 | Iteration number: [520/565] 92% | Training loss: 0.6881921125146059
Epoch: 36 | Iteration number: [530/565] 93% | Training loss: 0.6881669104099274
Epoch: 36 | Iteration number: [540/565] 95% | Training loss: 0.6881355537308587
Epoch: 36 | Iteration number: [550/565] 97% | Training loss: 0.6881054955179041
Epoch: 36 | Iteration number: [560/565] 99% | Training loss: 0.6880853541195393

 End of epoch: 36 | Train Loss: 0.6868653394479667 | Training Time: 90 

 End of epoch: 36 | Eval Loss: 0.6905808023044041 | Evaluating Time: 6 
Epoch: 37 | Iteration number: [10/565] 1% | Training loss: 0.7559144377708436
Epoch: 37 | Iteration number: [20/565] 3% | Training loss: 0.7213856875896454
Epoch: 37 | Iteration number: [30/565] 5% | Training loss: 0.709896469116211
Epoch: 37 | Iteration number: [40/565] 7% | Training loss: 0.7043025255203247
Epoch: 37 | Iteration number: [50/565] 8% | Training loss: 0.7008113813400269
Epoch: 37 | Iteration number: [60/565] 10% | Training loss: 0.6984449903170268
Epoch: 37 | Iteration number: [70/565] 12% | Training loss: 0.6967610733849662
Epoch: 37 | Iteration number: [80/565] 14% | Training loss: 0.6955037273466587
Epoch: 37 | Iteration number: [90/565] 15% | Training loss: 0.6945517049895392
Epoch: 37 | Iteration number: [100/565] 17% | Training loss: 0.6938167035579681
Epoch: 37 | Iteration number: [110/565] 19% | Training loss: 0.6932160756804726
Epoch: 37 | Iteration number: [120/565] 21% | Training loss: 0.6927355602383614
Epoch: 37 | Iteration number: [130/565] 23% | Training loss: 0.692324180327929
Epoch: 37 | Iteration number: [140/565] 24% | Training loss: 0.6919357636145183
Epoch: 37 | Iteration number: [150/565] 26% | Training loss: 0.6916179617245992
Epoch: 37 | Iteration number: [160/565] 28% | Training loss: 0.691327341645956
Epoch: 37 | Iteration number: [170/565] 30% | Training loss: 0.6910590305047877
Epoch: 37 | Iteration number: [180/565] 31% | Training loss: 0.6908129039737914
Epoch: 37 | Iteration number: [190/565] 33% | Training loss: 0.6906027373514677
Epoch: 37 | Iteration number: [200/565] 35% | Training loss: 0.6904233545064926
Epoch: 37 | Iteration number: [210/565] 37% | Training loss: 0.6902402750083378
Epoch: 37 | Iteration number: [220/565] 38% | Training loss: 0.6900908816944469
Epoch: 37 | Iteration number: [230/565] 40% | Training loss: 0.6899654264035432
Epoch: 37 | Iteration number: [240/565] 42% | Training loss: 0.6898301477233569
Epoch: 37 | Iteration number: [250/565] 44% | Training loss: 0.6896934475898743
Epoch: 37 | Iteration number: [260/565] 46% | Training loss: 0.6895982900491128
Epoch: 37 | Iteration number: [270/565] 47% | Training loss: 0.6894857101970249
Epoch: 37 | Iteration number: [280/565] 49% | Training loss: 0.6894010699221066
Epoch: 37 | Iteration number: [290/565] 51% | Training loss: 0.6893083155155182
Epoch: 37 | Iteration number: [300/565] 53% | Training loss: 0.6892263434330622
Epoch: 37 | Iteration number: [310/565] 54% | Training loss: 0.6891453810276523
Epoch: 37 | Iteration number: [320/565] 56% | Training loss: 0.6890652507543564
Epoch: 37 | Iteration number: [330/565] 58% | Training loss: 0.688996508807847
Epoch: 37 | Iteration number: [340/565] 60% | Training loss: 0.6889121150269227
Epoch: 37 | Iteration number: [350/565] 61% | Training loss: 0.6888598639624459
Epoch: 37 | Iteration number: [360/565] 63% | Training loss: 0.6888100910517905
Epoch: 37 | Iteration number: [370/565] 65% | Training loss: 0.6887656374557598
Epoch: 37 | Iteration number: [380/565] 67% | Training loss: 0.6887175705872084
Epoch: 37 | Iteration number: [390/565] 69% | Training loss: 0.6886586852562733
Epoch: 37 | Iteration number: [400/565] 70% | Training loss: 0.6886162593960762
Epoch: 37 | Iteration number: [410/565] 72% | Training loss: 0.6885806301744973
Epoch: 37 | Iteration number: [420/565] 74% | Training loss: 0.6885380280869348
Epoch: 37 | Iteration number: [430/565] 76% | Training loss: 0.6885050941345303
Epoch: 37 | Iteration number: [440/565] 77% | Training loss: 0.6884623370387337
Epoch: 37 | Iteration number: [450/565] 79% | Training loss: 0.6884167081779904
Epoch: 37 | Iteration number: [460/565] 81% | Training loss: 0.688382251366325
Epoch: 37 | Iteration number: [470/565] 83% | Training loss: 0.6883462171605292
Epoch: 37 | Iteration number: [480/565] 84% | Training loss: 0.6883139796555042
Epoch: 37 | Iteration number: [490/565] 86% | Training loss: 0.6882728700735131
Epoch: 37 | Iteration number: [500/565] 88% | Training loss: 0.688248522400856
Epoch: 37 | Iteration number: [510/565] 90% | Training loss: 0.6882211837114073
Epoch: 37 | Iteration number: [520/565] 92% | Training loss: 0.6881915893692236
Epoch: 37 | Iteration number: [530/565] 93% | Training loss: 0.6881684449483764
Epoch: 37 | Iteration number: [540/565] 95% | Training loss: 0.688144690019113
Epoch: 37 | Iteration number: [550/565] 97% | Training loss: 0.6881201202219183
Epoch: 37 | Iteration number: [560/565] 99% | Training loss: 0.688091049769095

 End of epoch: 37 | Train Loss: 0.686867815730846 | Training Time: 90 

 End of epoch: 37 | Eval Loss: 0.6903084346226284 | Evaluating Time: 6 
Epoch: 38 | Iteration number: [10/565] 1% | Training loss: 0.7561861217021942
Epoch: 38 | Iteration number: [20/565] 3% | Training loss: 0.7213272899389267
Epoch: 38 | Iteration number: [30/565] 5% | Training loss: 0.7097984214623769
Epoch: 38 | Iteration number: [40/565] 7% | Training loss: 0.7040529698133469
Epoch: 38 | Iteration number: [50/565] 8% | Training loss: 0.7005496728420257
Epoch: 38 | Iteration number: [60/565] 10% | Training loss: 0.6982136160135269
Epoch: 38 | Iteration number: [70/565] 12% | Training loss: 0.6965728640556336
Epoch: 38 | Iteration number: [80/565] 14% | Training loss: 0.6954158514738082
Epoch: 38 | Iteration number: [90/565] 15% | Training loss: 0.6945267200469971
Epoch: 38 | Iteration number: [100/565] 17% | Training loss: 0.6937771451473236
Epoch: 38 | Iteration number: [110/565] 19% | Training loss: 0.693133841861378
Epoch: 38 | Iteration number: [120/565] 21% | Training loss: 0.6926091094811757
Epoch: 38 | Iteration number: [130/565] 23% | Training loss: 0.6921314775943757
Epoch: 38 | Iteration number: [140/565] 24% | Training loss: 0.6917666448014123
Epoch: 38 | Iteration number: [150/565] 26% | Training loss: 0.691425306002299
Epoch: 38 | Iteration number: [160/565] 28% | Training loss: 0.6911047749221325
Epoch: 38 | Iteration number: [170/565] 30% | Training loss: 0.6908400689854342
Epoch: 38 | Iteration number: [180/565] 31% | Training loss: 0.690655924545394
Epoch: 38 | Iteration number: [190/565] 33% | Training loss: 0.6904491619059914
Epoch: 38 | Iteration number: [200/565] 35% | Training loss: 0.6902905789017677
Epoch: 38 | Iteration number: [210/565] 37% | Training loss: 0.6901170846961794
Epoch: 38 | Iteration number: [220/565] 38% | Training loss: 0.6899617812850258
Epoch: 38 | Iteration number: [230/565] 40% | Training loss: 0.68981493892877
Epoch: 38 | Iteration number: [240/565] 42% | Training loss: 0.6896633992592494
Epoch: 38 | Iteration number: [250/565] 44% | Training loss: 0.6895581378936767
Epoch: 38 | Iteration number: [260/565] 46% | Training loss: 0.6894580366519781
Epoch: 38 | Iteration number: [270/565] 47% | Training loss: 0.6893631193372939
Epoch: 38 | Iteration number: [280/565] 49% | Training loss: 0.6892912202647754
Epoch: 38 | Iteration number: [290/565] 51% | Training loss: 0.6892065315411009
Epoch: 38 | Iteration number: [300/565] 53% | Training loss: 0.6891311897834143
Epoch: 38 | Iteration number: [310/565] 54% | Training loss: 0.6890667298147756
Epoch: 38 | Iteration number: [320/565] 56% | Training loss: 0.6889911767095327
Epoch: 38 | Iteration number: [330/565] 58% | Training loss: 0.6889259690588171
Epoch: 38 | Iteration number: [340/565] 60% | Training loss: 0.6888669706442777
Epoch: 38 | Iteration number: [350/565] 61% | Training loss: 0.6888014529432569
Epoch: 38 | Iteration number: [360/565] 63% | Training loss: 0.6887553418676059
Epoch: 38 | Iteration number: [370/565] 65% | Training loss: 0.6887090278638376
Epoch: 38 | Iteration number: [380/565] 67% | Training loss: 0.6886549816319817
Epoch: 38 | Iteration number: [390/565] 69% | Training loss: 0.6886059062603193
Epoch: 38 | Iteration number: [400/565] 70% | Training loss: 0.6885559684038163
Epoch: 38 | Iteration number: [410/565] 72% | Training loss: 0.6885153184576732
Epoch: 38 | Iteration number: [420/565] 74% | Training loss: 0.6884783347447713
Epoch: 38 | Iteration number: [430/565] 76% | Training loss: 0.6884633818338084
Epoch: 38 | Iteration number: [440/565] 77% | Training loss: 0.6884201733903451
Epoch: 38 | Iteration number: [450/565] 79% | Training loss: 0.6883807588948144
Epoch: 38 | Iteration number: [460/565] 81% | Training loss: 0.6883521466151528
Epoch: 38 | Iteration number: [470/565] 83% | Training loss: 0.6883161904964041
Epoch: 38 | Iteration number: [480/565] 84% | Training loss: 0.6882939449201028
Epoch: 38 | Iteration number: [490/565] 86% | Training loss: 0.6882673506834069
Epoch: 38 | Iteration number: [500/565] 88% | Training loss: 0.6882374356985093
Epoch: 38 | Iteration number: [510/565] 90% | Training loss: 0.6882101759022358
Epoch: 38 | Iteration number: [520/565] 92% | Training loss: 0.6881873577833175
Epoch: 38 | Iteration number: [530/565] 93% | Training loss: 0.6881640324052775
Epoch: 38 | Iteration number: [540/565] 95% | Training loss: 0.6881357778001714
Epoch: 38 | Iteration number: [550/565] 97% | Training loss: 0.688109542131424
Epoch: 38 | Iteration number: [560/565] 99% | Training loss: 0.6880873287362712

 End of epoch: 38 | Train Loss: 0.6868640329985491 | Training Time: 91 

 End of epoch: 38 | Eval Loss: 0.6902605380330767 | Evaluating Time: 6 
Epoch: 39 | Iteration number: [10/565] 1% | Training loss: 0.7551200747489929
Epoch: 39 | Iteration number: [20/565] 3% | Training loss: 0.7210368424654007
Epoch: 39 | Iteration number: [30/565] 5% | Training loss: 0.7097030540307363
Epoch: 39 | Iteration number: [40/565] 7% | Training loss: 0.7040480449795723
Epoch: 39 | Iteration number: [50/565] 8% | Training loss: 0.7006539452075958
Epoch: 39 | Iteration number: [60/565] 10% | Training loss: 0.6983173658450444
Epoch: 39 | Iteration number: [70/565] 12% | Training loss: 0.6966325283050537
Epoch: 39 | Iteration number: [80/565] 14% | Training loss: 0.6954057395458222
Epoch: 39 | Iteration number: [90/565] 15% | Training loss: 0.694452844063441
Epoch: 39 | Iteration number: [100/565] 17% | Training loss: 0.6936501389741898
Epoch: 39 | Iteration number: [110/565] 19% | Training loss: 0.6930367756973613
Epoch: 39 | Iteration number: [120/565] 21% | Training loss: 0.692546941836675
Epoch: 39 | Iteration number: [130/565] 23% | Training loss: 0.6921409946221572
Epoch: 39 | Iteration number: [140/565] 24% | Training loss: 0.6917559598173414
Epoch: 39 | Iteration number: [150/565] 26% | Training loss: 0.6914327649275461
Epoch: 39 | Iteration number: [160/565] 28% | Training loss: 0.6911724720150232
Epoch: 39 | Iteration number: [170/565] 30% | Training loss: 0.6909345595275654
Epoch: 39 | Iteration number: [180/565] 31% | Training loss: 0.6907087918784883
Epoch: 39 | Iteration number: [190/565] 33% | Training loss: 0.6905052564646068
Epoch: 39 | Iteration number: [200/565] 35% | Training loss: 0.6903210183978081
Epoch: 39 | Iteration number: [210/565] 37% | Training loss: 0.6901570127123878
Epoch: 39 | Iteration number: [220/565] 38% | Training loss: 0.6899928174235604
Epoch: 39 | Iteration number: [230/565] 40% | Training loss: 0.689840276863264
Epoch: 39 | Iteration number: [240/565] 42% | Training loss: 0.6897092973192532
Epoch: 39 | Iteration number: [250/565] 44% | Training loss: 0.6896067521572113
Epoch: 39 | Iteration number: [260/565] 46% | Training loss: 0.6894934869729555
Epoch: 39 | Iteration number: [270/565] 47% | Training loss: 0.6893853154447344
Epoch: 39 | Iteration number: [280/565] 49% | Training loss: 0.6892837626593453
Epoch: 39 | Iteration number: [290/565] 51% | Training loss: 0.689190561401433
Epoch: 39 | Iteration number: [300/565] 53% | Training loss: 0.6891071224212646
Epoch: 39 | Iteration number: [310/565] 54% | Training loss: 0.6890336569278471
Epoch: 39 | Iteration number: [320/565] 56% | Training loss: 0.6889603789895773
Epoch: 39 | Iteration number: [330/565] 58% | Training loss: 0.6888972833301081
Epoch: 39 | Iteration number: [340/565] 60% | Training loss: 0.6888472976053462
Epoch: 39 | Iteration number: [350/565] 61% | Training loss: 0.6887867530754634
Epoch: 39 | Iteration number: [360/565] 63% | Training loss: 0.6887325725621647
Epoch: 39 | Iteration number: [370/565] 65% | Training loss: 0.6886824604627249
Epoch: 39 | Iteration number: [380/565] 67% | Training loss: 0.6886397124905336
Epoch: 39 | Iteration number: [390/565] 69% | Training loss: 0.6886015054507133
Epoch: 39 | Iteration number: [400/565] 70% | Training loss: 0.6885608291625976
Epoch: 39 | Iteration number: [410/565] 72% | Training loss: 0.6884997213759073
Epoch: 39 | Iteration number: [420/565] 74% | Training loss: 0.6884690341495332
Epoch: 39 | Iteration number: [430/565] 76% | Training loss: 0.6884361896404
Epoch: 39 | Iteration number: [440/565] 77% | Training loss: 0.6884050111879002
Epoch: 39 | Iteration number: [450/565] 79% | Training loss: 0.6883704859680599
Epoch: 39 | Iteration number: [460/565] 81% | Training loss: 0.6883409805919813
Epoch: 39 | Iteration number: [470/565] 83% | Training loss: 0.6883071380726835
Epoch: 39 | Iteration number: [480/565] 84% | Training loss: 0.6882715577880542
Epoch: 39 | Iteration number: [490/565] 86% | Training loss: 0.688246617390185
Epoch: 39 | Iteration number: [500/565] 88% | Training loss: 0.6882206529378891
Epoch: 39 | Iteration number: [510/565] 90% | Training loss: 0.6881951911776674
Epoch: 39 | Iteration number: [520/565] 92% | Training loss: 0.6881710147628417
Epoch: 39 | Iteration number: [530/565] 93% | Training loss: 0.6881477212006191
Epoch: 39 | Iteration number: [540/565] 95% | Training loss: 0.6881267893093603
Epoch: 39 | Iteration number: [550/565] 97% | Training loss: 0.6881084389036352
Epoch: 39 | Iteration number: [560/565] 99% | Training loss: 0.688091788228069

 End of epoch: 39 | Train Loss: 0.6868593443811467 | Training Time: 89 

 End of epoch: 39 | Eval Loss: 0.6901089293616158 | Evaluating Time: 6 
Epoch: 40 | Iteration number: [10/565] 1% | Training loss: 0.755245053768158
Epoch: 40 | Iteration number: [20/565] 3% | Training loss: 0.7212778687477112
Epoch: 40 | Iteration number: [30/565] 5% | Training loss: 0.7097761174043019
Epoch: 40 | Iteration number: [40/565] 7% | Training loss: 0.7040737301111222
Epoch: 40 | Iteration number: [50/565] 8% | Training loss: 0.7006052911281586
Epoch: 40 | Iteration number: [60/565] 10% | Training loss: 0.6983291347821553
Epoch: 40 | Iteration number: [70/565] 12% | Training loss: 0.696738771029881
Epoch: 40 | Iteration number: [80/565] 14% | Training loss: 0.6954946018755436
Epoch: 40 | Iteration number: [90/565] 15% | Training loss: 0.6945771164364285
Epoch: 40 | Iteration number: [100/565] 17% | Training loss: 0.6937838298082352
Epoch: 40 | Iteration number: [110/565] 19% | Training loss: 0.6931416414000772
Epoch: 40 | Iteration number: [120/565] 21% | Training loss: 0.6926539480686188
Epoch: 40 | Iteration number: [130/565] 23% | Training loss: 0.6922096247856434
Epoch: 40 | Iteration number: [140/565] 24% | Training loss: 0.6918266045195716
Epoch: 40 | Iteration number: [150/565] 26% | Training loss: 0.6914900008837382
Epoch: 40 | Iteration number: [160/565] 28% | Training loss: 0.691198217868805
Epoch: 40 | Iteration number: [170/565] 30% | Training loss: 0.6909393780371722
Epoch: 40 | Iteration number: [180/565] 31% | Training loss: 0.6907258258925544
Epoch: 40 | Iteration number: [190/565] 33% | Training loss: 0.6905248720394938
Epoch: 40 | Iteration number: [200/565] 35% | Training loss: 0.6903421953320503
Epoch: 40 | Iteration number: [210/565] 37% | Training loss: 0.6901984702973138
Epoch: 40 | Iteration number: [220/565] 38% | Training loss: 0.6900494128465653
Epoch: 40 | Iteration number: [230/565] 40% | Training loss: 0.6899017111114834
Epoch: 40 | Iteration number: [240/565] 42% | Training loss: 0.6897841682036717
Epoch: 40 | Iteration number: [250/565] 44% | Training loss: 0.6896662044525147
Epoch: 40 | Iteration number: [260/565] 46% | Training loss: 0.6895594058128504
Epoch: 40 | Iteration number: [270/565] 47% | Training loss: 0.6894429120752547
Epoch: 40 | Iteration number: [280/565] 49% | Training loss: 0.6893387189933232
Epoch: 40 | Iteration number: [290/565] 51% | Training loss: 0.6892544433988373
Epoch: 40 | Iteration number: [300/565] 53% | Training loss: 0.689179343978564
Epoch: 40 | Iteration number: [310/565] 54% | Training loss: 0.6890950716310932
Epoch: 40 | Iteration number: [320/565] 56% | Training loss: 0.6890182800590992
Epoch: 40 | Iteration number: [330/565] 58% | Training loss: 0.6889579010732246
Epoch: 40 | Iteration number: [340/565] 60% | Training loss: 0.6889013376306085
Epoch: 40 | Iteration number: [350/565] 61% | Training loss: 0.6888482672827584
Epoch: 40 | Iteration number: [360/565] 63% | Training loss: 0.6887919634580613
Epoch: 40 | Iteration number: [370/565] 65% | Training loss: 0.6887423795622748
Epoch: 40 | Iteration number: [380/565] 67% | Training loss: 0.6886913498765543
Epoch: 40 | Iteration number: [390/565] 69% | Training loss: 0.688644056289624
Epoch: 40 | Iteration number: [400/565] 70% | Training loss: 0.6885962022840977
Epoch: 40 | Iteration number: [410/565] 72% | Training loss: 0.6885653873769249
Epoch: 40 | Iteration number: [420/565] 74% | Training loss: 0.6885226407221385
Epoch: 40 | Iteration number: [430/565] 76% | Training loss: 0.6884837189386057
Epoch: 40 | Iteration number: [440/565] 77% | Training loss: 0.6884371204809709
Epoch: 40 | Iteration number: [450/565] 79% | Training loss: 0.6884022547139061
Epoch: 40 | Iteration number: [460/565] 81% | Training loss: 0.6883584693722103
Epoch: 40 | Iteration number: [470/565] 83% | Training loss: 0.6883212050224873
Epoch: 40 | Iteration number: [480/565] 84% | Training loss: 0.6882999069988728
Epoch: 40 | Iteration number: [490/565] 86% | Training loss: 0.6882696761160481
Epoch: 40 | Iteration number: [500/565] 88% | Training loss: 0.6882380284070969
Epoch: 40 | Iteration number: [510/565] 90% | Training loss: 0.688207824791179
Epoch: 40 | Iteration number: [520/565] 92% | Training loss: 0.6881760162802842
Epoch: 40 | Iteration number: [530/565] 93% | Training loss: 0.6881464102358188
Epoch: 40 | Iteration number: [540/565] 95% | Training loss: 0.6881191386116876
Epoch: 40 | Iteration number: [550/565] 97% | Training loss: 0.6881007986718958
Epoch: 40 | Iteration number: [560/565] 99% | Training loss: 0.6880715065768787

 End of epoch: 40 | Train Loss: 0.6868463871753321 | Training Time: 90 

 End of epoch: 40 | Eval Loss: 0.6901412265641349 | Evaluating Time: 6 
Epoch: 41 | Iteration number: [10/565] 1% | Training loss: 0.7552840232849121
Epoch: 41 | Iteration number: [20/565] 3% | Training loss: 0.7210993558168411
Epoch: 41 | Iteration number: [30/565] 5% | Training loss: 0.70966717004776
Epoch: 41 | Iteration number: [40/565] 7% | Training loss: 0.7040076911449432
Epoch: 41 | Iteration number: [50/565] 8% | Training loss: 0.700584864616394
Epoch: 41 | Iteration number: [60/565] 10% | Training loss: 0.6983267068862915
Epoch: 41 | Iteration number: [70/565] 12% | Training loss: 0.6967172614165715
Epoch: 41 | Iteration number: [80/565] 14% | Training loss: 0.6955034203827382
Epoch: 41 | Iteration number: [90/565] 15% | Training loss: 0.6945525546868642
Epoch: 41 | Iteration number: [100/565] 17% | Training loss: 0.6937794816493988
Epoch: 41 | Iteration number: [110/565] 19% | Training loss: 0.6931510361758145
Epoch: 41 | Iteration number: [120/565] 21% | Training loss: 0.6926261231303215
Epoch: 41 | Iteration number: [130/565] 23% | Training loss: 0.6921962215350225
Epoch: 41 | Iteration number: [140/565] 24% | Training loss: 0.6917905930961882
Epoch: 41 | Iteration number: [150/565] 26% | Training loss: 0.6914543720086416
Epoch: 41 | Iteration number: [160/565] 28% | Training loss: 0.6911757294088602
Epoch: 41 | Iteration number: [170/565] 30% | Training loss: 0.6909320645472583
Epoch: 41 | Iteration number: [180/565] 31% | Training loss: 0.6906904992130067
Epoch: 41 | Iteration number: [190/565] 33% | Training loss: 0.6904875137304005
Epoch: 41 | Iteration number: [200/565] 35% | Training loss: 0.6902768832445144
Epoch: 41 | Iteration number: [210/565] 37% | Training loss: 0.6901199647358486
Epoch: 41 | Iteration number: [220/565] 38% | Training loss: 0.6899547517299652
Epoch: 41 | Iteration number: [230/565] 40% | Training loss: 0.6898242543572964
Epoch: 41 | Iteration number: [240/565] 42% | Training loss: 0.689701704432567
Epoch: 41 | Iteration number: [250/565] 44% | Training loss: 0.6895878119468689
Epoch: 41 | Iteration number: [260/565] 46% | Training loss: 0.6894806589071567
Epoch: 41 | Iteration number: [270/565] 47% | Training loss: 0.6893803735574087
Epoch: 41 | Iteration number: [280/565] 49% | Training loss: 0.6893086699502808
Epoch: 41 | Iteration number: [290/565] 51% | Training loss: 0.6892321983288074
Epoch: 41 | Iteration number: [300/565] 53% | Training loss: 0.6891532494624456
Epoch: 41 | Iteration number: [310/565] 54% | Training loss: 0.6890811806724918
Epoch: 41 | Iteration number: [320/565] 56% | Training loss: 0.689018639177084
Epoch: 41 | Iteration number: [330/565] 58% | Training loss: 0.6889446639653408
Epoch: 41 | Iteration number: [340/565] 60% | Training loss: 0.6888881068019306
Epoch: 41 | Iteration number: [350/565] 61% | Training loss: 0.6888356852531433
Epoch: 41 | Iteration number: [360/565] 63% | Training loss: 0.6887765682405895
Epoch: 41 | Iteration number: [370/565] 65% | Training loss: 0.6887270017250164
Epoch: 41 | Iteration number: [380/565] 67% | Training loss: 0.6886893862172176
Epoch: 41 | Iteration number: [390/565] 69% | Training loss: 0.6886547242983794
Epoch: 41 | Iteration number: [400/565] 70% | Training loss: 0.688609544634819
Epoch: 41 | Iteration number: [410/565] 72% | Training loss: 0.6885783196949378
Epoch: 41 | Iteration number: [420/565] 74% | Training loss: 0.6885363161563873
Epoch: 41 | Iteration number: [430/565] 76% | Training loss: 0.688490580264912
Epoch: 41 | Iteration number: [440/565] 77% | Training loss: 0.6884489647366784
Epoch: 41 | Iteration number: [450/565] 79% | Training loss: 0.6884157688087887
Epoch: 41 | Iteration number: [460/565] 81% | Training loss: 0.6883824496165566
Epoch: 41 | Iteration number: [470/565] 83% | Training loss: 0.6883453049558275
Epoch: 41 | Iteration number: [480/565] 84% | Training loss: 0.6883096281439066
Epoch: 41 | Iteration number: [490/565] 86% | Training loss: 0.6882699212249445
Epoch: 41 | Iteration number: [500/565] 88% | Training loss: 0.6882469557523727
Epoch: 41 | Iteration number: [510/565] 90% | Training loss: 0.6882202405555575
Epoch: 41 | Iteration number: [520/565] 92% | Training loss: 0.6881987693218085
Epoch: 41 | Iteration number: [530/565] 93% | Training loss: 0.688163191192555
Epoch: 41 | Iteration number: [540/565] 95% | Training loss: 0.6881315169511018
Epoch: 41 | Iteration number: [550/565] 97% | Training loss: 0.6881041653589769
Epoch: 41 | Iteration number: [560/565] 99% | Training loss: 0.688080780846732

 End of epoch: 41 | Train Loss: 0.6868529137256926 | Training Time: 89 

 End of epoch: 41 | Eval Loss: 0.6901511464800153 | Evaluating Time: 6 
Epoch: 42 | Iteration number: [10/565] 1% | Training loss: 0.7557684123516083
Epoch: 42 | Iteration number: [20/565] 3% | Training loss: 0.721323961019516
Epoch: 42 | Iteration number: [30/565] 5% | Training loss: 0.7096741199493408
Epoch: 42 | Iteration number: [40/565] 7% | Training loss: 0.7040019616484642
Epoch: 42 | Iteration number: [50/565] 8% | Training loss: 0.7005644500255584
Epoch: 42 | Iteration number: [60/565] 10% | Training loss: 0.6983239938815434
Epoch: 42 | Iteration number: [70/565] 12% | Training loss: 0.6966579496860504
Epoch: 42 | Iteration number: [80/565] 14% | Training loss: 0.6955079436302185
Epoch: 42 | Iteration number: [90/565] 15% | Training loss: 0.694586400853263
Epoch: 42 | Iteration number: [100/565] 17% | Training loss: 0.6938431984186173
Epoch: 42 | Iteration number: [110/565] 19% | Training loss: 0.6932012379169464
Epoch: 42 | Iteration number: [120/565] 21% | Training loss: 0.6926612943410874
Epoch: 42 | Iteration number: [130/565] 23% | Training loss: 0.6922130139974447
Epoch: 42 | Iteration number: [140/565] 24% | Training loss: 0.6918136507272721
Epoch: 42 | Iteration number: [150/565] 26% | Training loss: 0.6914524467786153
Epoch: 42 | Iteration number: [160/565] 28% | Training loss: 0.6911171894520521
Epoch: 42 | Iteration number: [170/565] 30% | Training loss: 0.6908592371379628
Epoch: 42 | Iteration number: [180/565] 31% | Training loss: 0.6906266119745043
Epoch: 42 | Iteration number: [190/565] 33% | Training loss: 0.6904273249601063
Epoch: 42 | Iteration number: [200/565] 35% | Training loss: 0.6902492633461952
Epoch: 42 | Iteration number: [210/565] 37% | Training loss: 0.6900918319111778
Epoch: 42 | Iteration number: [220/565] 38% | Training loss: 0.6899449074810201
Epoch: 42 | Iteration number: [230/565] 40% | Training loss: 0.6898312439089236
Epoch: 42 | Iteration number: [240/565] 42% | Training loss: 0.6897074868281682
Epoch: 42 | Iteration number: [250/565] 44% | Training loss: 0.6895868728160858
Epoch: 42 | Iteration number: [260/565] 46% | Training loss: 0.6894852890418126
Epoch: 42 | Iteration number: [270/565] 47% | Training loss: 0.6893919812308418
Epoch: 42 | Iteration number: [280/565] 49% | Training loss: 0.689313072179045
Epoch: 42 | Iteration number: [290/565] 51% | Training loss: 0.6892275600597776
Epoch: 42 | Iteration number: [300/565] 53% | Training loss: 0.6891541747252147
Epoch: 42 | Iteration number: [310/565] 54% | Training loss: 0.6890708769521405
Epoch: 42 | Iteration number: [320/565] 56% | Training loss: 0.6889909215271472
Epoch: 42 | Iteration number: [330/565] 58% | Training loss: 0.6889309250947201
Epoch: 42 | Iteration number: [340/565] 60% | Training loss: 0.6888632607810637
Epoch: 42 | Iteration number: [350/565] 61% | Training loss: 0.6887930342129298
Epoch: 42 | Iteration number: [360/565] 63% | Training loss: 0.6887416980332799
Epoch: 42 | Iteration number: [370/565] 65% | Training loss: 0.6887019138078432
Epoch: 42 | Iteration number: [380/565] 67% | Training loss: 0.6886554484304629
Epoch: 42 | Iteration number: [390/565] 69% | Training loss: 0.6886090882313557
Epoch: 42 | Iteration number: [400/565] 70% | Training loss: 0.6885589754581452
Epoch: 42 | Iteration number: [410/565] 72% | Training loss: 0.6885250710859532
Epoch: 42 | Iteration number: [420/565] 74% | Training loss: 0.6884908488818577
Epoch: 42 | Iteration number: [430/565] 76% | Training loss: 0.6884649879710619
Epoch: 42 | Iteration number: [440/565] 77% | Training loss: 0.6884342092004689
Epoch: 42 | Iteration number: [450/565] 79% | Training loss: 0.6883983182907104
Epoch: 42 | Iteration number: [460/565] 81% | Training loss: 0.6883547522451566
Epoch: 42 | Iteration number: [470/565] 83% | Training loss: 0.6883157060501424
Epoch: 42 | Iteration number: [480/565] 84% | Training loss: 0.6882752316693465
Epoch: 42 | Iteration number: [490/565] 86% | Training loss: 0.6882490592343466
Epoch: 42 | Iteration number: [500/565] 88% | Training loss: 0.6882229760885239
Epoch: 42 | Iteration number: [510/565] 90% | Training loss: 0.6881936158619675
Epoch: 42 | Iteration number: [520/565] 92% | Training loss: 0.6881649946937194
Epoch: 42 | Iteration number: [530/565] 93% | Training loss: 0.6881471448349503
Epoch: 42 | Iteration number: [540/565] 95% | Training loss: 0.6881208389997482
Epoch: 42 | Iteration number: [550/565] 97% | Training loss: 0.6880977096340873
Epoch: 42 | Iteration number: [560/565] 99% | Training loss: 0.6880789947296891

 End of epoch: 42 | Train Loss: 0.6868535038644233 | Training Time: 88 

 End of epoch: 42 | Eval Loss: 0.6901602574757167 | Evaluating Time: 6 
Epoch: 43 | Iteration number: [10/565] 1% | Training loss: 0.755228191614151
Epoch: 43 | Iteration number: [20/565] 3% | Training loss: 0.7209948301315308
Epoch: 43 | Iteration number: [30/565] 5% | Training loss: 0.7096583286921183
Epoch: 43 | Iteration number: [40/565] 7% | Training loss: 0.7039186924695968
Epoch: 43 | Iteration number: [50/565] 8% | Training loss: 0.7005002498626709
Epoch: 43 | Iteration number: [60/565] 10% | Training loss: 0.6982627173264822
Epoch: 43 | Iteration number: [70/565] 12% | Training loss: 0.6966462211949485
Epoch: 43 | Iteration number: [80/565] 14% | Training loss: 0.6954001806676388
Epoch: 43 | Iteration number: [90/565] 15% | Training loss: 0.6945028172598945
Epoch: 43 | Iteration number: [100/565] 17% | Training loss: 0.6937622964382172
Epoch: 43 | Iteration number: [110/565] 19% | Training loss: 0.6931498971852389
Epoch: 43 | Iteration number: [120/565] 21% | Training loss: 0.6926211287577947
Epoch: 43 | Iteration number: [130/565] 23% | Training loss: 0.6921759174420283
Epoch: 43 | Iteration number: [140/565] 24% | Training loss: 0.691788113968713
Epoch: 43 | Iteration number: [150/565] 26% | Training loss: 0.6914553304513296
Epoch: 43 | Iteration number: [160/565] 28% | Training loss: 0.6911755423992872
Epoch: 43 | Iteration number: [170/565] 30% | Training loss: 0.6909162433708416
Epoch: 43 | Iteration number: [180/565] 31% | Training loss: 0.6906982594066196
Epoch: 43 | Iteration number: [190/565] 33% | Training loss: 0.6905198705823798
Epoch: 43 | Iteration number: [200/565] 35% | Training loss: 0.6903456410765648
Epoch: 43 | Iteration number: [210/565] 37% | Training loss: 0.6901958905515216
Epoch: 43 | Iteration number: [220/565] 38% | Training loss: 0.6900443781505932
Epoch: 43 | Iteration number: [230/565] 40% | Training loss: 0.689924198648204
Epoch: 43 | Iteration number: [240/565] 42% | Training loss: 0.6897961296141147
Epoch: 43 | Iteration number: [250/565] 44% | Training loss: 0.6896707017421723
Epoch: 43 | Iteration number: [260/565] 46% | Training loss: 0.6895471497223927
Epoch: 43 | Iteration number: [270/565] 47% | Training loss: 0.6894269762215791
Epoch: 43 | Iteration number: [280/565] 49% | Training loss: 0.6893427440098354
Epoch: 43 | Iteration number: [290/565] 51% | Training loss: 0.6892479265558309
Epoch: 43 | Iteration number: [300/565] 53% | Training loss: 0.6891830883423488
Epoch: 43 | Iteration number: [310/565] 54% | Training loss: 0.6890959491652827
Epoch: 43 | Iteration number: [320/565] 56% | Training loss: 0.6890231860801578
Epoch: 43 | Iteration number: [330/565] 58% | Training loss: 0.6889345486958821
Epoch: 43 | Iteration number: [340/565] 60% | Training loss: 0.6888687544009264
Epoch: 43 | Iteration number: [350/565] 61% | Training loss: 0.6888125789165497
Epoch: 43 | Iteration number: [360/565] 63% | Training loss: 0.6887489037381278
Epoch: 43 | Iteration number: [370/565] 65% | Training loss: 0.6886964458066064
Epoch: 43 | Iteration number: [380/565] 67% | Training loss: 0.6886384013452028
Epoch: 43 | Iteration number: [390/565] 69% | Training loss: 0.6885993473040752
Epoch: 43 | Iteration number: [400/565] 70% | Training loss: 0.6885493776202202
Epoch: 43 | Iteration number: [410/565] 72% | Training loss: 0.68850761332163
Epoch: 43 | Iteration number: [420/565] 74% | Training loss: 0.6884748667478562
Epoch: 43 | Iteration number: [430/565] 76% | Training loss: 0.6884412055791811
Epoch: 43 | Iteration number: [440/565] 77% | Training loss: 0.6883942723274231
Epoch: 43 | Iteration number: [450/565] 79% | Training loss: 0.6883604827192095
Epoch: 43 | Iteration number: [460/565] 81% | Training loss: 0.6883279254902964
Epoch: 43 | Iteration number: [470/565] 83% | Training loss: 0.6882911236996346
Epoch: 43 | Iteration number: [480/565] 84% | Training loss: 0.6882630527019501
Epoch: 43 | Iteration number: [490/565] 86% | Training loss: 0.6882338534812538
Epoch: 43 | Iteration number: [500/565] 88% | Training loss: 0.6882068042755127
Epoch: 43 | Iteration number: [510/565] 90% | Training loss: 0.6881897204062518
Epoch: 43 | Iteration number: [520/565] 92% | Training loss: 0.6881692133270777
Epoch: 43 | Iteration number: [530/565] 93% | Training loss: 0.6881511510543104
Epoch: 43 | Iteration number: [540/565] 95% | Training loss: 0.6881251952162495
Epoch: 43 | Iteration number: [550/565] 97% | Training loss: 0.6881034033948725
Epoch: 43 | Iteration number: [560/565] 99% | Training loss: 0.6880782471171447

 End of epoch: 43 | Train Loss: 0.6868585526415733 | Training Time: 89 

 End of epoch: 43 | Eval Loss: 0.6901680741991315 | Evaluating Time: 6 
Epoch: 44 | Iteration number: [10/565] 1% | Training loss: 0.7555918514728546
Epoch: 44 | Iteration number: [20/565] 3% | Training loss: 0.7210843503475189
Epoch: 44 | Iteration number: [30/565] 5% | Training loss: 0.7097310364246369
Epoch: 44 | Iteration number: [40/565] 7% | Training loss: 0.7040000170469284
Epoch: 44 | Iteration number: [50/565] 8% | Training loss: 0.7005291819572449
Epoch: 44 | Iteration number: [60/565] 10% | Training loss: 0.6982049902280172
Epoch: 44 | Iteration number: [70/565] 12% | Training loss: 0.6966171605246407
Epoch: 44 | Iteration number: [80/565] 14% | Training loss: 0.6953847080469131
Epoch: 44 | Iteration number: [90/565] 15% | Training loss: 0.6944514115651449
Epoch: 44 | Iteration number: [100/565] 17% | Training loss: 0.6937333852052688
Epoch: 44 | Iteration number: [110/565] 19% | Training loss: 0.6930839002132416
Epoch: 44 | Iteration number: [120/565] 21% | Training loss: 0.6925355523824692
Epoch: 44 | Iteration number: [130/565] 23% | Training loss: 0.6920998389904316
Epoch: 44 | Iteration number: [140/565] 24% | Training loss: 0.6917355171271733
Epoch: 44 | Iteration number: [150/565] 26% | Training loss: 0.6914240749677022
Epoch: 44 | Iteration number: [160/565] 28% | Training loss: 0.6911057770252228
Epoch: 44 | Iteration number: [170/565] 30% | Training loss: 0.6908554750330308
Epoch: 44 | Iteration number: [180/565] 31% | Training loss: 0.6906271722581652
Epoch: 44 | Iteration number: [190/565] 33% | Training loss: 0.6904551982879639
Epoch: 44 | Iteration number: [200/565] 35% | Training loss: 0.6903075462579727
Epoch: 44 | Iteration number: [210/565] 37% | Training loss: 0.6901156232470558
Epoch: 44 | Iteration number: [220/565] 38% | Training loss: 0.6899491865526546
Epoch: 44 | Iteration number: [230/565] 40% | Training loss: 0.6898148321587106
Epoch: 44 | Iteration number: [240/565] 42% | Training loss: 0.6896908797323704
Epoch: 44 | Iteration number: [250/565] 44% | Training loss: 0.6895715780258179
Epoch: 44 | Iteration number: [260/565] 46% | Training loss: 0.689472617323582
Epoch: 44 | Iteration number: [270/565] 47% | Training loss: 0.6893780275627419
Epoch: 44 | Iteration number: [280/565] 49% | Training loss: 0.6892912485769817
Epoch: 44 | Iteration number: [290/565] 51% | Training loss: 0.6892070517457765
Epoch: 44 | Iteration number: [300/565] 53% | Training loss: 0.689119343161583
Epoch: 44 | Iteration number: [310/565] 54% | Training loss: 0.6890432178974152
Epoch: 44 | Iteration number: [320/565] 56% | Training loss: 0.6889613447710872
Epoch: 44 | Iteration number: [330/565] 58% | Training loss: 0.6889023526148362
Epoch: 44 | Iteration number: [340/565] 60% | Training loss: 0.6888413934146657
Epoch: 44 | Iteration number: [350/565] 61% | Training loss: 0.6887835735934121
Epoch: 44 | Iteration number: [360/565] 63% | Training loss: 0.6887347878681289
Epoch: 44 | Iteration number: [370/565] 65% | Training loss: 0.688684330598728
Epoch: 44 | Iteration number: [380/565] 67% | Training loss: 0.6886281957751826
Epoch: 44 | Iteration number: [390/565] 69% | Training loss: 0.6885870658434354
Epoch: 44 | Iteration number: [400/565] 70% | Training loss: 0.6885478971898555
Epoch: 44 | Iteration number: [410/565] 72% | Training loss: 0.6885156105204326
Epoch: 44 | Iteration number: [420/565] 74% | Training loss: 0.6884774323020663
Epoch: 44 | Iteration number: [430/565] 76% | Training loss: 0.6884416541387869
Epoch: 44 | Iteration number: [440/565] 77% | Training loss: 0.6884018834341656
Epoch: 44 | Iteration number: [450/565] 79% | Training loss: 0.688364239136378
Epoch: 44 | Iteration number: [460/565] 81% | Training loss: 0.6883420657852422
Epoch: 44 | Iteration number: [470/565] 83% | Training loss: 0.6883104547541192
Epoch: 44 | Iteration number: [480/565] 84% | Training loss: 0.6882804971188307
Epoch: 44 | Iteration number: [490/565] 86% | Training loss: 0.6882475298278186
Epoch: 44 | Iteration number: [500/565] 88% | Training loss: 0.688215388417244
Epoch: 44 | Iteration number: [510/565] 90% | Training loss: 0.6881889995406656
Epoch: 44 | Iteration number: [520/565] 92% | Training loss: 0.6881696853500147
Epoch: 44 | Iteration number: [530/565] 93% | Training loss: 0.6881417571373706
Epoch: 44 | Iteration number: [540/565] 95% | Training loss: 0.6881129443645477
Epoch: 44 | Iteration number: [550/565] 97% | Training loss: 0.6880930023843592
Epoch: 44 | Iteration number: [560/565] 99% | Training loss: 0.6880759264741625

 End of epoch: 44 | Train Loss: 0.6868495680589591 | Training Time: 88 

 End of epoch: 44 | Eval Loss: 0.6905343873160226 | Evaluating Time: 6 
Epoch: 45 | Iteration number: [10/565] 1% | Training loss: 0.7558391630649567
Epoch: 45 | Iteration number: [20/565] 3% | Training loss: 0.7211004734039307
Epoch: 45 | Iteration number: [30/565] 5% | Training loss: 0.7095549066861471
Epoch: 45 | Iteration number: [40/565] 7% | Training loss: 0.7038823738694191
Epoch: 45 | Iteration number: [50/565] 8% | Training loss: 0.700555124282837
Epoch: 45 | Iteration number: [60/565] 10% | Training loss: 0.6982538878917695
Epoch: 45 | Iteration number: [70/565] 12% | Training loss: 0.6966134292738778
Epoch: 45 | Iteration number: [80/565] 14% | Training loss: 0.6953901648521423
Epoch: 45 | Iteration number: [90/565] 15% | Training loss: 0.6944637331697676
Epoch: 45 | Iteration number: [100/565] 17% | Training loss: 0.6936564028263092
Epoch: 45 | Iteration number: [110/565] 19% | Training loss: 0.693008257042278
Epoch: 45 | Iteration number: [120/565] 21% | Training loss: 0.6925006940960884
Epoch: 45 | Iteration number: [130/565] 23% | Training loss: 0.6920637529629927
Epoch: 45 | Iteration number: [140/565] 24% | Training loss: 0.6917096576520375
Epoch: 45 | Iteration number: [150/565] 26% | Training loss: 0.6913991530736288
Epoch: 45 | Iteration number: [160/565] 28% | Training loss: 0.6910993341356516
Epoch: 45 | Iteration number: [170/565] 30% | Training loss: 0.6908497971646926
Epoch: 45 | Iteration number: [180/565] 31% | Training loss: 0.6906402319669723
Epoch: 45 | Iteration number: [190/565] 33% | Training loss: 0.6904248319174114
Epoch: 45 | Iteration number: [200/565] 35% | Training loss: 0.6902591621875763
Epoch: 45 | Iteration number: [210/565] 37% | Training loss: 0.6901016476608458
Epoch: 45 | Iteration number: [220/565] 38% | Training loss: 0.6899642662568526
Epoch: 45 | Iteration number: [230/565] 40% | Training loss: 0.6898195336694303
Epoch: 45 | Iteration number: [240/565] 42% | Training loss: 0.6897066541016101
Epoch: 45 | Iteration number: [250/565] 44% | Training loss: 0.6895783340930939
Epoch: 45 | Iteration number: [260/565] 46% | Training loss: 0.6894774560744946
Epoch: 45 | Iteration number: [270/565] 47% | Training loss: 0.6893857538700103
Epoch: 45 | Iteration number: [280/565] 49% | Training loss: 0.6892934252108847
Epoch: 45 | Iteration number: [290/565] 51% | Training loss: 0.6892081437439754
Epoch: 45 | Iteration number: [300/565] 53% | Training loss: 0.6891203979651134
Epoch: 45 | Iteration number: [310/565] 54% | Training loss: 0.6890464651969171
Epoch: 45 | Iteration number: [320/565] 56% | Training loss: 0.6889587631449103
Epoch: 45 | Iteration number: [330/565] 58% | Training loss: 0.6888994814771594
Epoch: 45 | Iteration number: [340/565] 60% | Training loss: 0.6888424300095615
Epoch: 45 | Iteration number: [350/565] 61% | Training loss: 0.6887976452282497
Epoch: 45 | Iteration number: [360/565] 63% | Training loss: 0.6887472207347552
Epoch: 45 | Iteration number: [370/565] 65% | Training loss: 0.6886983592767973
Epoch: 45 | Iteration number: [380/565] 67% | Training loss: 0.6886593407706211
Epoch: 45 | Iteration number: [390/565] 69% | Training loss: 0.6886141534035023
Epoch: 45 | Iteration number: [400/565] 70% | Training loss: 0.6885677634179592
Epoch: 45 | Iteration number: [410/565] 72% | Training loss: 0.6885206889815447
Epoch: 45 | Iteration number: [420/565] 74% | Training loss: 0.6884738262210574
Epoch: 45 | Iteration number: [430/565] 76% | Training loss: 0.688419116652289
Epoch: 45 | Iteration number: [440/565] 77% | Training loss: 0.6883847279982134
Epoch: 45 | Iteration number: [450/565] 79% | Training loss: 0.6883470417393578
Epoch: 45 | Iteration number: [460/565] 81% | Training loss: 0.6883201518784399
Epoch: 45 | Iteration number: [470/565] 83% | Training loss: 0.6882898924198556
Epoch: 45 | Iteration number: [480/565] 84% | Training loss: 0.6882672037929296
Epoch: 45 | Iteration number: [490/565] 86% | Training loss: 0.6882360539874252
Epoch: 45 | Iteration number: [500/565] 88% | Training loss: 0.6882010456323624
Epoch: 45 | Iteration number: [510/565] 90% | Training loss: 0.6881769177960414
Epoch: 45 | Iteration number: [520/565] 92% | Training loss: 0.6881588029173704
Epoch: 45 | Iteration number: [530/565] 93% | Training loss: 0.6881295783339806
Epoch: 45 | Iteration number: [540/565] 95% | Training loss: 0.6881037614963673
Epoch: 45 | Iteration number: [550/565] 97% | Training loss: 0.6880744851719249
Epoch: 45 | Iteration number: [560/565] 99% | Training loss: 0.6880592106708459

 End of epoch: 45 | Train Loss: 0.6868311354544311 | Training Time: 89 

 End of epoch: 45 | Eval Loss: 0.6897673947470528 | Evaluating Time: 6 
Epoch: 46 | Iteration number: [10/565] 1% | Training loss: 0.7552010416984558
Epoch: 46 | Iteration number: [20/565] 3% | Training loss: 0.7211520791053772
Epoch: 46 | Iteration number: [30/565] 5% | Training loss: 0.7097296198209126
Epoch: 46 | Iteration number: [40/565] 7% | Training loss: 0.7038808718323708
Epoch: 46 | Iteration number: [50/565] 8% | Training loss: 0.7005010282993317
Epoch: 46 | Iteration number: [60/565] 10% | Training loss: 0.6982043494780859
Epoch: 46 | Iteration number: [70/565] 12% | Training loss: 0.6965540749686104
Epoch: 46 | Iteration number: [80/565] 14% | Training loss: 0.6953161552548408
Epoch: 46 | Iteration number: [90/565] 15% | Training loss: 0.6944031371010675
Epoch: 46 | Iteration number: [100/565] 17% | Training loss: 0.6936892235279083
Epoch: 46 | Iteration number: [110/565] 19% | Training loss: 0.6931004134091464
Epoch: 46 | Iteration number: [120/565] 21% | Training loss: 0.6925714527567227
Epoch: 46 | Iteration number: [130/565] 23% | Training loss: 0.6921173861393561
Epoch: 46 | Iteration number: [140/565] 24% | Training loss: 0.6917476394346782
Epoch: 46 | Iteration number: [150/565] 26% | Training loss: 0.6914567220211029
Epoch: 46 | Iteration number: [160/565] 28% | Training loss: 0.6911549296230077
Epoch: 46 | Iteration number: [170/565] 30% | Training loss: 0.690905874967575
Epoch: 46 | Iteration number: [180/565] 31% | Training loss: 0.6907068828741709
Epoch: 46 | Iteration number: [190/565] 33% | Training loss: 0.690508330495734
Epoch: 46 | Iteration number: [200/565] 35% | Training loss: 0.6903152471780777
Epoch: 46 | Iteration number: [210/565] 37% | Training loss: 0.6901546265397753
Epoch: 46 | Iteration number: [220/565] 38% | Training loss: 0.6899910244074735
Epoch: 46 | Iteration number: [230/565] 40% | Training loss: 0.6898506527361663
Epoch: 46 | Iteration number: [240/565] 42% | Training loss: 0.6897201935450236
Epoch: 46 | Iteration number: [250/565] 44% | Training loss: 0.6895833742618561
Epoch: 46 | Iteration number: [260/565] 46% | Training loss: 0.6894728937974343
Epoch: 46 | Iteration number: [270/565] 47% | Training loss: 0.6893572860293918
Epoch: 46 | Iteration number: [280/565] 49% | Training loss: 0.6892638185194561
Epoch: 46 | Iteration number: [290/565] 51% | Training loss: 0.6891630692728634
Epoch: 46 | Iteration number: [300/565] 53% | Training loss: 0.6890753257274628
Epoch: 46 | Iteration number: [310/565] 54% | Training loss: 0.6889964957391063
Epoch: 46 | Iteration number: [320/565] 56% | Training loss: 0.6889464866369963
Epoch: 46 | Iteration number: [330/565] 58% | Training loss: 0.6888917140888445
Epoch: 46 | Iteration number: [340/565] 60% | Training loss: 0.6888451558702132
Epoch: 46 | Iteration number: [350/565] 61% | Training loss: 0.6887843343189785
Epoch: 46 | Iteration number: [360/565] 63% | Training loss: 0.6887326412730747
Epoch: 46 | Iteration number: [370/565] 65% | Training loss: 0.6886783930095466
Epoch: 46 | Iteration number: [380/565] 67% | Training loss: 0.6886279390046471
Epoch: 46 | Iteration number: [390/565] 69% | Training loss: 0.6885797820030115
Epoch: 46 | Iteration number: [400/565] 70% | Training loss: 0.6885293108224869
Epoch: 46 | Iteration number: [410/565] 72% | Training loss: 0.6884945536532053
Epoch: 46 | Iteration number: [420/565] 74% | Training loss: 0.6884632114853177
Epoch: 46 | Iteration number: [430/565] 76% | Training loss: 0.6884326024110927
Epoch: 46 | Iteration number: [440/565] 77% | Training loss: 0.6883964285254478
Epoch: 46 | Iteration number: [450/565] 79% | Training loss: 0.6883676460054186
Epoch: 46 | Iteration number: [460/565] 81% | Training loss: 0.6883330705373184
Epoch: 46 | Iteration number: [470/565] 83% | Training loss: 0.688297020247642
Epoch: 46 | Iteration number: [480/565] 84% | Training loss: 0.6882554768274228
Epoch: 46 | Iteration number: [490/565] 86% | Training loss: 0.688227549621037
Epoch: 46 | Iteration number: [500/565] 88% | Training loss: 0.6882062528133392
Epoch: 46 | Iteration number: [510/565] 90% | Training loss: 0.6881798797962713
Epoch: 46 | Iteration number: [520/565] 92% | Training loss: 0.6881537712537326
Epoch: 46 | Iteration number: [530/565] 93% | Training loss: 0.6881322187072826
Epoch: 46 | Iteration number: [540/565] 95% | Training loss: 0.688099357927287
Epoch: 46 | Iteration number: [550/565] 97% | Training loss: 0.6880830056017095
Epoch: 46 | Iteration number: [560/565] 99% | Training loss: 0.6880660305065768

 End of epoch: 46 | Train Loss: 0.6868361614446724 | Training Time: 90 

 End of epoch: 46 | Eval Loss: 0.6901529346193586 | Evaluating Time: 6 
Epoch: 47 | Iteration number: [10/565] 1% | Training loss: 0.7558234393596649
Epoch: 47 | Iteration number: [20/565] 3% | Training loss: 0.7214950054883957
Epoch: 47 | Iteration number: [30/565] 5% | Training loss: 0.709980821609497
Epoch: 47 | Iteration number: [40/565] 7% | Training loss: 0.7041634157299995
Epoch: 47 | Iteration number: [50/565] 8% | Training loss: 0.7006563401222229
Epoch: 47 | Iteration number: [60/565] 10% | Training loss: 0.6983667413393656
Epoch: 47 | Iteration number: [70/565] 12% | Training loss: 0.6967496769768852
Epoch: 47 | Iteration number: [80/565] 14% | Training loss: 0.6954963751137256
Epoch: 47 | Iteration number: [90/565] 15% | Training loss: 0.6945015728473664
Epoch: 47 | Iteration number: [100/565] 17% | Training loss: 0.6937541288137435
Epoch: 47 | Iteration number: [110/565] 19% | Training loss: 0.6931123500520533
Epoch: 47 | Iteration number: [120/565] 21% | Training loss: 0.6925801177819569
Epoch: 47 | Iteration number: [130/565] 23% | Training loss: 0.6921465227237115
Epoch: 47 | Iteration number: [140/565] 24% | Training loss: 0.6917933246919087
Epoch: 47 | Iteration number: [150/565] 26% | Training loss: 0.6914336609840394
Epoch: 47 | Iteration number: [160/565] 28% | Training loss: 0.6911358568817377
Epoch: 47 | Iteration number: [170/565] 30% | Training loss: 0.6908799637766445
Epoch: 47 | Iteration number: [180/565] 31% | Training loss: 0.6906499981880188
Epoch: 47 | Iteration number: [190/565] 33% | Training loss: 0.6904483861044833
Epoch: 47 | Iteration number: [200/565] 35% | Training loss: 0.6902676182985306
Epoch: 47 | Iteration number: [210/565] 37% | Training loss: 0.6901220733211154
Epoch: 47 | Iteration number: [220/565] 38% | Training loss: 0.6899647089568052
Epoch: 47 | Iteration number: [230/565] 40% | Training loss: 0.6898176048112952
Epoch: 47 | Iteration number: [240/565] 42% | Training loss: 0.689707791308562
Epoch: 47 | Iteration number: [250/565] 44% | Training loss: 0.6895826680660248
Epoch: 47 | Iteration number: [260/565] 46% | Training loss: 0.6894748774858621
Epoch: 47 | Iteration number: [270/565] 47% | Training loss: 0.6893783368446209
Epoch: 47 | Iteration number: [280/565] 49% | Training loss: 0.6892842207636152
Epoch: 47 | Iteration number: [290/565] 51% | Training loss: 0.6891870081424714
Epoch: 47 | Iteration number: [300/565] 53% | Training loss: 0.6891237531105677
Epoch: 47 | Iteration number: [310/565] 54% | Training loss: 0.6890512101111873
Epoch: 47 | Iteration number: [320/565] 56% | Training loss: 0.6889779621735215
Epoch: 47 | Iteration number: [330/565] 58% | Training loss: 0.6889077833204559
Epoch: 47 | Iteration number: [340/565] 60% | Training loss: 0.6888553331880009
Epoch: 47 | Iteration number: [350/565] 61% | Training loss: 0.688797379902431
Epoch: 47 | Iteration number: [360/565] 63% | Training loss: 0.6887276141179932
Epoch: 47 | Iteration number: [370/565] 65% | Training loss: 0.6887010245709806
Epoch: 47 | Iteration number: [380/565] 67% | Training loss: 0.6886516265178981
Epoch: 47 | Iteration number: [390/565] 69% | Training loss: 0.6886083268202268
Epoch: 47 | Iteration number: [400/565] 70% | Training loss: 0.688564413189888
Epoch: 47 | Iteration number: [410/565] 72% | Training loss: 0.6885192796951387
Epoch: 47 | Iteration number: [420/565] 74% | Training loss: 0.688480903846877
Epoch: 47 | Iteration number: [430/565] 76% | Training loss: 0.6884331825167633
Epoch: 47 | Iteration number: [440/565] 77% | Training loss: 0.6884088925339958
Epoch: 47 | Iteration number: [450/565] 79% | Training loss: 0.6883782504664527
Epoch: 47 | Iteration number: [460/565] 81% | Training loss: 0.6883455483809762
Epoch: 47 | Iteration number: [470/565] 83% | Training loss: 0.6883191452381459
Epoch: 47 | Iteration number: [480/565] 84% | Training loss: 0.6882810146858295
Epoch: 47 | Iteration number: [490/565] 86% | Training loss: 0.6882589343859224
Epoch: 47 | Iteration number: [500/565] 88% | Training loss: 0.6882308132648468
Epoch: 47 | Iteration number: [510/565] 90% | Training loss: 0.6881980935732523
Epoch: 47 | Iteration number: [520/565] 92% | Training loss: 0.6881756781385495
Epoch: 47 | Iteration number: [530/565] 93% | Training loss: 0.6881496396829497
Epoch: 47 | Iteration number: [540/565] 95% | Training loss: 0.6881274287347441
Epoch: 47 | Iteration number: [550/565] 97% | Training loss: 0.6881053181128068
Epoch: 47 | Iteration number: [560/565] 99% | Training loss: 0.6880791681153434

 End of epoch: 47 | Train Loss: 0.6868520963508471 | Training Time: 87 

 End of epoch: 47 | Eval Loss: 0.6899534293583461 | Evaluating Time: 5 
Epoch: 48 | Iteration number: [10/565] 1% | Training loss: 0.7559376776218414
Epoch: 48 | Iteration number: [20/565] 3% | Training loss: 0.7215388596057892
Epoch: 48 | Iteration number: [30/565] 5% | Training loss: 0.7100773175557454
Epoch: 48 | Iteration number: [40/565] 7% | Training loss: 0.7042258843779564
Epoch: 48 | Iteration number: [50/565] 8% | Training loss: 0.7007953715324402
Epoch: 48 | Iteration number: [60/565] 10% | Training loss: 0.6985073914130528
Epoch: 48 | Iteration number: [70/565] 12% | Training loss: 0.6968476695673806
Epoch: 48 | Iteration number: [80/565] 14% | Training loss: 0.6955584399402142
Epoch: 48 | Iteration number: [90/565] 15% | Training loss: 0.6945775694317288
Epoch: 48 | Iteration number: [100/565] 17% | Training loss: 0.6938277268409729
Epoch: 48 | Iteration number: [110/565] 19% | Training loss: 0.6931816290725361
Epoch: 48 | Iteration number: [120/565] 21% | Training loss: 0.6926832462350527
Epoch: 48 | Iteration number: [130/565] 23% | Training loss: 0.6922053781839518
Epoch: 48 | Iteration number: [140/565] 24% | Training loss: 0.6918057088341032
Epoch: 48 | Iteration number: [150/565] 26% | Training loss: 0.6914495368798573
Epoch: 48 | Iteration number: [160/565] 28% | Training loss: 0.6911616101861
Epoch: 48 | Iteration number: [170/565] 30% | Training loss: 0.6908910467344171
Epoch: 48 | Iteration number: [180/565] 31% | Training loss: 0.690672140651279
Epoch: 48 | Iteration number: [190/565] 33% | Training loss: 0.6904737836436221
Epoch: 48 | Iteration number: [200/565] 35% | Training loss: 0.6902897024154663
Epoch: 48 | Iteration number: [210/565] 37% | Training loss: 0.6901347668397995
Epoch: 48 | Iteration number: [220/565] 38% | Training loss: 0.689995553818616
Epoch: 48 | Iteration number: [230/565] 40% | Training loss: 0.6898415928301604
Epoch: 48 | Iteration number: [240/565] 42% | Training loss: 0.689733200520277
Epoch: 48 | Iteration number: [250/565] 44% | Training loss: 0.6896137278079987
Epoch: 48 | Iteration number: [260/565] 46% | Training loss: 0.6894983190756577
Epoch: 48 | Iteration number: [270/565] 47% | Training loss: 0.6894064057756353
Epoch: 48 | Iteration number: [280/565] 49% | Training loss: 0.6893116767917361
Epoch: 48 | Iteration number: [290/565] 51% | Training loss: 0.6892229939329213
Epoch: 48 | Iteration number: [300/565] 53% | Training loss: 0.6891251891851425
Epoch: 48 | Iteration number: [310/565] 54% | Training loss: 0.6890535841065069
Epoch: 48 | Iteration number: [320/565] 56% | Training loss: 0.6889658935368062
Epoch: 48 | Iteration number: [330/565] 58% | Training loss: 0.6889088421156913
Epoch: 48 | Iteration number: [340/565] 60% | Training loss: 0.6888419773648767
Epoch: 48 | Iteration number: [350/565] 61% | Training loss: 0.6887743181841715
Epoch: 48 | Iteration number: [360/565] 63% | Training loss: 0.6887246617012553
Epoch: 48 | Iteration number: [370/565] 65% | Training loss: 0.6886701500093615
Epoch: 48 | Iteration number: [380/565] 67% | Training loss: 0.6886258620964854
Epoch: 48 | Iteration number: [390/565] 69% | Training loss: 0.6885886050187624
Epoch: 48 | Iteration number: [400/565] 70% | Training loss: 0.6885420410335064
Epoch: 48 | Iteration number: [410/565] 72% | Training loss: 0.6885082968851415
Epoch: 48 | Iteration number: [420/565] 74% | Training loss: 0.6884683777888616
Epoch: 48 | Iteration number: [430/565] 76% | Training loss: 0.6884448525517486
Epoch: 48 | Iteration number: [440/565] 77% | Training loss: 0.6884055350314487
Epoch: 48 | Iteration number: [450/565] 79% | Training loss: 0.6883686504099105
Epoch: 48 | Iteration number: [460/565] 81% | Training loss: 0.6883429888797843
Epoch: 48 | Iteration number: [470/565] 83% | Training loss: 0.6883147346212509
Epoch: 48 | Iteration number: [480/565] 84% | Training loss: 0.6882861394435167
Epoch: 48 | Iteration number: [490/565] 86% | Training loss: 0.6882492586058013
Epoch: 48 | Iteration number: [500/565] 88% | Training loss: 0.6882127432823181
Epoch: 48 | Iteration number: [510/565] 90% | Training loss: 0.6881822963555654
Epoch: 48 | Iteration number: [520/565] 92% | Training loss: 0.688155971123622
Epoch: 48 | Iteration number: [530/565] 93% | Training loss: 0.6881244648177669
Epoch: 48 | Iteration number: [540/565] 95% | Training loss: 0.6881068536528835
Epoch: 48 | Iteration number: [550/565] 97% | Training loss: 0.6880795081095262
Epoch: 48 | Iteration number: [560/565] 99% | Training loss: 0.6880532669169562

 End of epoch: 48 | Train Loss: 0.6868249271823241 | Training Time: 88 

 End of epoch: 48 | Eval Loss: 0.6900680831500462 | Evaluating Time: 6 
Epoch: 49 | Iteration number: [10/565] 1% | Training loss: 0.7557361960411072
Epoch: 49 | Iteration number: [20/565] 3% | Training loss: 0.7211449950933456
Epoch: 49 | Iteration number: [30/565] 5% | Training loss: 0.7097422540187835
Epoch: 49 | Iteration number: [40/565] 7% | Training loss: 0.703962329030037
Epoch: 49 | Iteration number: [50/565] 8% | Training loss: 0.7006547844409943
Epoch: 49 | Iteration number: [60/565] 10% | Training loss: 0.6983278582493464
Epoch: 49 | Iteration number: [70/565] 12% | Training loss: 0.6966349797589438
Epoch: 49 | Iteration number: [80/565] 14% | Training loss: 0.6954411007463932
Epoch: 49 | Iteration number: [90/565] 15% | Training loss: 0.694453567928738
Epoch: 49 | Iteration number: [100/565] 17% | Training loss: 0.6936987882852554
Epoch: 49 | Iteration number: [110/565] 19% | Training loss: 0.6930608500133861
Epoch: 49 | Iteration number: [120/565] 21% | Training loss: 0.6925683066248893
Epoch: 49 | Iteration number: [130/565] 23% | Training loss: 0.6921468913555145
Epoch: 49 | Iteration number: [140/565] 24% | Training loss: 0.6917469135352543
Epoch: 49 | Iteration number: [150/565] 26% | Training loss: 0.6914511922995249
Epoch: 49 | Iteration number: [160/565] 28% | Training loss: 0.6911624871194363
Epoch: 49 | Iteration number: [170/565] 30% | Training loss: 0.690921660381205
Epoch: 49 | Iteration number: [180/565] 31% | Training loss: 0.6907021784120135
Epoch: 49 | Iteration number: [190/565] 33% | Training loss: 0.690527765060726
Epoch: 49 | Iteration number: [200/565] 35% | Training loss: 0.6903435871005058
Epoch: 49 | Iteration number: [210/565] 37% | Training loss: 0.6901764810085297
Epoch: 49 | Iteration number: [220/565] 38% | Training loss: 0.6900175072930076
Epoch: 49 | Iteration number: [230/565] 40% | Training loss: 0.6898791862570721
Epoch: 49 | Iteration number: [240/565] 42% | Training loss: 0.6897383742034435
Epoch: 49 | Iteration number: [250/565] 44% | Training loss: 0.6896127543449402
Epoch: 49 | Iteration number: [260/565] 46% | Training loss: 0.6895001863057797
Epoch: 49 | Iteration number: [270/565] 47% | Training loss: 0.6893942051463657
Epoch: 49 | Iteration number: [280/565] 49% | Training loss: 0.6893043724553926
Epoch: 49 | Iteration number: [290/565] 51% | Training loss: 0.6892097818440405
Epoch: 49 | Iteration number: [300/565] 53% | Training loss: 0.689141140182813
Epoch: 49 | Iteration number: [310/565] 54% | Training loss: 0.6890596772393872
Epoch: 49 | Iteration number: [320/565] 56% | Training loss: 0.6889970170333981
Epoch: 49 | Iteration number: [330/565] 58% | Training loss: 0.688935438972531
Epoch: 49 | Iteration number: [340/565] 60% | Training loss: 0.6888758040526334
Epoch: 49 | Iteration number: [350/565] 61% | Training loss: 0.6888108827386583
Epoch: 49 | Iteration number: [360/565] 63% | Training loss: 0.6887510529822773
Epoch: 49 | Iteration number: [370/565] 65% | Training loss: 0.6887031377972783
Epoch: 49 | Iteration number: [380/565] 67% | Training loss: 0.688665342017224
Epoch: 49 | Iteration number: [390/565] 69% | Training loss: 0.6886134818578378
Epoch: 49 | Iteration number: [400/565] 70% | Training loss: 0.6885605558753014
Epoch: 49 | Iteration number: [410/565] 72% | Training loss: 0.6885197233862993
Epoch: 49 | Iteration number: [420/565] 74% | Training loss: 0.6884736264035816
Epoch: 49 | Iteration number: [430/565] 76% | Training loss: 0.688433410400568
Epoch: 49 | Iteration number: [440/565] 77% | Training loss: 0.6883934327147224
Epoch: 49 | Iteration number: [450/565] 79% | Training loss: 0.6883522260189057
Epoch: 49 | Iteration number: [460/565] 81% | Training loss: 0.6883183411929918
Epoch: 49 | Iteration number: [470/565] 83% | Training loss: 0.6882860463984469
Epoch: 49 | Iteration number: [480/565] 84% | Training loss: 0.6882602997124195
Epoch: 49 | Iteration number: [490/565] 86% | Training loss: 0.6882231034794632
Epoch: 49 | Iteration number: [500/565] 88% | Training loss: 0.688193708062172
Epoch: 49 | Iteration number: [510/565] 90% | Training loss: 0.6881675853448755
Epoch: 49 | Iteration number: [520/565] 92% | Training loss: 0.688147397683217
Epoch: 49 | Iteration number: [530/565] 93% | Training loss: 0.688119279888441
Epoch: 49 | Iteration number: [540/565] 95% | Training loss: 0.6881022151973513
Epoch: 49 | Iteration number: [550/565] 97% | Training loss: 0.6880710443583402
Epoch: 49 | Iteration number: [560/565] 99% | Training loss: 0.6880518173532827

 End of epoch: 49 | Train Loss: 0.6868261958645508 | Training Time: 89 

 End of epoch: 49 | Eval Loss: 0.6899412104061672 | Evaluating Time: 6 
Epoch: 50 | Iteration number: [10/565] 1% | Training loss: 0.7552452564239502
Epoch: 50 | Iteration number: [20/565] 3% | Training loss: 0.7210676848888398
Epoch: 50 | Iteration number: [30/565] 5% | Training loss: 0.7097707450389862
Epoch: 50 | Iteration number: [40/565] 7% | Training loss: 0.7040064573287964
Epoch: 50 | Iteration number: [50/565] 8% | Training loss: 0.7005340504646301
Epoch: 50 | Iteration number: [60/565] 10% | Training loss: 0.6983043084541957
Epoch: 50 | Iteration number: [70/565] 12% | Training loss: 0.6967154281479971
Epoch: 50 | Iteration number: [80/565] 14% | Training loss: 0.6954975374042988
Epoch: 50 | Iteration number: [90/565] 15% | Training loss: 0.6944485432571835
Epoch: 50 | Iteration number: [100/565] 17% | Training loss: 0.6936753302812576
Epoch: 50 | Iteration number: [110/565] 19% | Training loss: 0.6930352140556683
Epoch: 50 | Iteration number: [120/565] 21% | Training loss: 0.6925244614481926
Epoch: 50 | Iteration number: [130/565] 23% | Training loss: 0.6920847599322979
Epoch: 50 | Iteration number: [140/565] 24% | Training loss: 0.6917157658508846
Epoch: 50 | Iteration number: [150/565] 26% | Training loss: 0.6913923788070678
Epoch: 50 | Iteration number: [160/565] 28% | Training loss: 0.691109600290656
Epoch: 50 | Iteration number: [170/565] 30% | Training loss: 0.6908620627487407
Epoch: 50 | Iteration number: [180/565] 31% | Training loss: 0.6906493392255572
Epoch: 50 | Iteration number: [190/565] 33% | Training loss: 0.6904491073206851
Epoch: 50 | Iteration number: [200/565] 35% | Training loss: 0.6902744483947754
Epoch: 50 | Iteration number: [210/565] 37% | Training loss: 0.6901200930277507
Epoch: 50 | Iteration number: [220/565] 38% | Training loss: 0.6899814332073385
Epoch: 50 | Iteration number: [230/565] 40% | Training loss: 0.6898288908212081
Epoch: 50 | Iteration number: [240/565] 42% | Training loss: 0.6897022744019826
Epoch: 50 | Iteration number: [250/565] 44% | Training loss: 0.6895815885066986
Epoch: 50 | Iteration number: [260/565] 46% | Training loss: 0.689487784413191
Epoch: 50 | Iteration number: [270/565] 47% | Training loss: 0.6894010961055755
Epoch: 50 | Iteration number: [280/565] 49% | Training loss: 0.6893105440906115
Epoch: 50 | Iteration number: [290/565] 51% | Training loss: 0.6892325999407932
Epoch: 50 | Iteration number: [300/565] 53% | Training loss: 0.6891684923569361
Epoch: 50 | Iteration number: [310/565] 54% | Training loss: 0.6890854268304764
Epoch: 50 | Iteration number: [320/565] 56% | Training loss: 0.6890261713415384
Epoch: 50 | Iteration number: [330/565] 58% | Training loss: 0.6889682444659146
Epoch: 50 | Iteration number: [340/565] 60% | Training loss: 0.68890502558035
Epoch: 50 | Iteration number: [350/565] 61% | Training loss: 0.6888519103186471
Epoch: 50 | Iteration number: [360/565] 63% | Training loss: 0.6887805879116058
Epoch: 50 | Iteration number: [370/565] 65% | Training loss: 0.6887276539931426
Epoch: 50 | Iteration number: [380/565] 67% | Training loss: 0.6886733011195534
Epoch: 50 | Iteration number: [390/565] 69% | Training loss: 0.688623799269016
Epoch: 50 | Iteration number: [400/565] 70% | Training loss: 0.6885633824765682
Epoch: 50 | Iteration number: [410/565] 72% | Training loss: 0.6885192051166441
Epoch: 50 | Iteration number: [420/565] 74% | Training loss: 0.6884730339050293
Epoch: 50 | Iteration number: [430/565] 76% | Training loss: 0.6884413830069609
Epoch: 50 | Iteration number: [440/565] 77% | Training loss: 0.6883936650373719
Epoch: 50 | Iteration number: [450/565] 79% | Training loss: 0.6883575868606567
Epoch: 50 | Iteration number: [460/565] 81% | Training loss: 0.6883244000051333
Epoch: 50 | Iteration number: [470/565] 83% | Training loss: 0.6882957009558982
Epoch: 50 | Iteration number: [480/565] 84% | Training loss: 0.6882662158459425
Epoch: 50 | Iteration number: [490/565] 86% | Training loss: 0.6882309116879288
Epoch: 50 | Iteration number: [500/565] 88% | Training loss: 0.6881996752023697
Epoch: 50 | Iteration number: [510/565] 90% | Training loss: 0.6881747825472962
Epoch: 50 | Iteration number: [520/565] 92% | Training loss: 0.6881435610927068
Epoch: 50 | Iteration number: [530/565] 93% | Training loss: 0.6881125312931132
Epoch: 50 | Iteration number: [540/565] 95% | Training loss: 0.6880907589638675
Epoch: 50 | Iteration number: [550/565] 97% | Training loss: 0.6880661909146742
Epoch: 50 | Iteration number: [560/565] 99% | Training loss: 0.6880492045411042

 End of epoch: 50 | Train Loss: 0.6868245434972037 | Training Time: 91 

 End of epoch: 50 | Eval Loss: 0.6901056936808995 | Evaluating Time: 6 
Epoch: 51 | Iteration number: [10/565] 1% | Training loss: 0.7552639007568359
Epoch: 51 | Iteration number: [20/565] 3% | Training loss: 0.7208065688610077
Epoch: 51 | Iteration number: [30/565] 5% | Training loss: 0.709380970398585
Epoch: 51 | Iteration number: [40/565] 7% | Training loss: 0.7037441924214363
Epoch: 51 | Iteration number: [50/565] 8% | Training loss: 0.700436202287674
Epoch: 51 | Iteration number: [60/565] 10% | Training loss: 0.6982008188962936
Epoch: 51 | Iteration number: [70/565] 12% | Training loss: 0.6965234867164067
Epoch: 51 | Iteration number: [80/565] 14% | Training loss: 0.6953158624470234
Epoch: 51 | Iteration number: [90/565] 15% | Training loss: 0.6943849080138736
Epoch: 51 | Iteration number: [100/565] 17% | Training loss: 0.6936523461341858
Epoch: 51 | Iteration number: [110/565] 19% | Training loss: 0.6930040251124989
Epoch: 51 | Iteration number: [120/565] 21% | Training loss: 0.6924871077140172
Epoch: 51 | Iteration number: [130/565] 23% | Training loss: 0.6920371183982262
Epoch: 51 | Iteration number: [140/565] 24% | Training loss: 0.691650921532086
Epoch: 51 | Iteration number: [150/565] 26% | Training loss: 0.6913193468252817
Epoch: 51 | Iteration number: [160/565] 28% | Training loss: 0.6910270266234875
Epoch: 51 | Iteration number: [170/565] 30% | Training loss: 0.6907678207930397
Epoch: 51 | Iteration number: [180/565] 31% | Training loss: 0.6905354834265179
Epoch: 51 | Iteration number: [190/565] 33% | Training loss: 0.690330719006689
Epoch: 51 | Iteration number: [200/565] 35% | Training loss: 0.6901650673151016
Epoch: 51 | Iteration number: [210/565] 37% | Training loss: 0.689997950338182
Epoch: 51 | Iteration number: [220/565] 38% | Training loss: 0.6898616303097118
Epoch: 51 | Iteration number: [230/565] 40% | Training loss: 0.6897461054117783
Epoch: 51 | Iteration number: [240/565] 42% | Training loss: 0.6896276168525219
Epoch: 51 | Iteration number: [250/565] 44% | Training loss: 0.6895121273994446
Epoch: 51 | Iteration number: [260/565] 46% | Training loss: 0.689394429555306
Epoch: 51 | Iteration number: [270/565] 47% | Training loss: 0.6893073872283653
Epoch: 51 | Iteration number: [280/565] 49% | Training loss: 0.6892188527754375
Epoch: 51 | Iteration number: [290/565] 51% | Training loss: 0.6891289776769177
Epoch: 51 | Iteration number: [300/565] 53% | Training loss: 0.6890582523743312
Epoch: 51 | Iteration number: [310/565] 54% | Training loss: 0.6889998376369476
Epoch: 51 | Iteration number: [320/565] 56% | Training loss: 0.688936223462224
Epoch: 51 | Iteration number: [330/565] 58% | Training loss: 0.688878125855417
Epoch: 51 | Iteration number: [340/565] 60% | Training loss: 0.6888187324299532
Epoch: 51 | Iteration number: [350/565] 61% | Training loss: 0.6887831158297403
Epoch: 51 | Iteration number: [360/565] 63% | Training loss: 0.6887216960390409
Epoch: 51 | Iteration number: [370/565] 65% | Training loss: 0.6886803427258054
Epoch: 51 | Iteration number: [380/565] 67% | Training loss: 0.6886280130398901
Epoch: 51 | Iteration number: [390/565] 69% | Training loss: 0.6885914684870305
Epoch: 51 | Iteration number: [400/565] 70% | Training loss: 0.688553749024868
Epoch: 51 | Iteration number: [410/565] 72% | Training loss: 0.6885106166688407
Epoch: 51 | Iteration number: [420/565] 74% | Training loss: 0.6884663889805476
Epoch: 51 | Iteration number: [430/565] 76% | Training loss: 0.688425865838694
Epoch: 51 | Iteration number: [440/565] 77% | Training loss: 0.6883937998251481
Epoch: 51 | Iteration number: [450/565] 79% | Training loss: 0.6883445074823168
Epoch: 51 | Iteration number: [460/565] 81% | Training loss: 0.6883143007755279
Epoch: 51 | Iteration number: [470/565] 83% | Training loss: 0.6882778475893304
Epoch: 51 | Iteration number: [480/565] 84% | Training loss: 0.6882421183089416
Epoch: 51 | Iteration number: [490/565] 86% | Training loss: 0.688217177318067
Epoch: 51 | Iteration number: [500/565] 88% | Training loss: 0.6881843895912171
Epoch: 51 | Iteration number: [510/565] 90% | Training loss: 0.6881554518260208
Epoch: 51 | Iteration number: [520/565] 92% | Training loss: 0.688132794545247
Epoch: 51 | Iteration number: [530/565] 93% | Training loss: 0.6881187753857306
Epoch: 51 | Iteration number: [540/565] 95% | Training loss: 0.6880960727179491
Epoch: 51 | Iteration number: [550/565] 97% | Training loss: 0.6880800433592363
Epoch: 51 | Iteration number: [560/565] 99% | Training loss: 0.6880550165261541

 End of epoch: 51 | Train Loss: 0.6868317286525153 | Training Time: 90 

 End of epoch: 51 | Eval Loss: 0.6903480291366577 | Evaluating Time: 6 
Epoch: 52 | Iteration number: [10/565] 1% | Training loss: 0.7552326321601868
Epoch: 52 | Iteration number: [20/565] 3% | Training loss: 0.7212062031030655
Epoch: 52 | Iteration number: [30/565] 5% | Training loss: 0.7098871211210886
Epoch: 52 | Iteration number: [40/565] 7% | Training loss: 0.7041912168264389
Epoch: 52 | Iteration number: [50/565] 8% | Training loss: 0.70063401222229
Epoch: 52 | Iteration number: [60/565] 10% | Training loss: 0.6983369052410126
Epoch: 52 | Iteration number: [70/565] 12% | Training loss: 0.6967122367450169
Epoch: 52 | Iteration number: [80/565] 14% | Training loss: 0.6954976446926594
Epoch: 52 | Iteration number: [90/565] 15% | Training loss: 0.6944886671172248
Epoch: 52 | Iteration number: [100/565] 17% | Training loss: 0.6937480258941651
Epoch: 52 | Iteration number: [110/565] 19% | Training loss: 0.6930844198573719
Epoch: 52 | Iteration number: [120/565] 21% | Training loss: 0.6925922403732936
Epoch: 52 | Iteration number: [130/565] 23% | Training loss: 0.6921496730584364
Epoch: 52 | Iteration number: [140/565] 24% | Training loss: 0.6917610815593175
Epoch: 52 | Iteration number: [150/565] 26% | Training loss: 0.691413228114446
Epoch: 52 | Iteration number: [160/565] 28% | Training loss: 0.6911155439913272
Epoch: 52 | Iteration number: [170/565] 30% | Training loss: 0.6908600537215962
Epoch: 52 | Iteration number: [180/565] 31% | Training loss: 0.690638980931706
Epoch: 52 | Iteration number: [190/565] 33% | Training loss: 0.6904431242691843
Epoch: 52 | Iteration number: [200/565] 35% | Training loss: 0.6902606844902038
Epoch: 52 | Iteration number: [210/565] 37% | Training loss: 0.6901072309130714
Epoch: 52 | Iteration number: [220/565] 38% | Training loss: 0.6899716661735015
Epoch: 52 | Iteration number: [230/565] 40% | Training loss: 0.6898160115532254
Epoch: 52 | Iteration number: [240/565] 42% | Training loss: 0.6896855456133684
Epoch: 52 | Iteration number: [250/565] 44% | Training loss: 0.6895694196224212
Epoch: 52 | Iteration number: [260/565] 46% | Training loss: 0.6894574325818282
Epoch: 52 | Iteration number: [270/565] 47% | Training loss: 0.6893652377305207
Epoch: 52 | Iteration number: [280/565] 49% | Training loss: 0.6892734672342028
Epoch: 52 | Iteration number: [290/565] 51% | Training loss: 0.6891959095823353
Epoch: 52 | Iteration number: [300/565] 53% | Training loss: 0.6891302551825841
Epoch: 52 | Iteration number: [310/565] 54% | Training loss: 0.6890428352740503
Epoch: 52 | Iteration number: [320/565] 56% | Training loss: 0.6889725362882018
Epoch: 52 | Iteration number: [330/565] 58% | Training loss: 0.6888999062957186
Epoch: 52 | Iteration number: [340/565] 60% | Training loss: 0.6888313305728576
Epoch: 52 | Iteration number: [350/565] 61% | Training loss: 0.688775840997696
Epoch: 52 | Iteration number: [360/565] 63% | Training loss: 0.6887217261725002
Epoch: 52 | Iteration number: [370/565] 65% | Training loss: 0.6886633325267483
Epoch: 52 | Iteration number: [380/565] 67% | Training loss: 0.6886194208734914
Epoch: 52 | Iteration number: [390/565] 69% | Training loss: 0.6885772940440056
Epoch: 52 | Iteration number: [400/565] 70% | Training loss: 0.6885399308800697
Epoch: 52 | Iteration number: [410/565] 72% | Training loss: 0.6884891347187322
Epoch: 52 | Iteration number: [420/565] 74% | Training loss: 0.6884479748351233
Epoch: 52 | Iteration number: [430/565] 76% | Training loss: 0.6884137337984041
Epoch: 52 | Iteration number: [440/565] 77% | Training loss: 0.6883769235827706
Epoch: 52 | Iteration number: [450/565] 79% | Training loss: 0.688339847723643
Epoch: 52 | Iteration number: [460/565] 81% | Training loss: 0.6883113219686177
Epoch: 52 | Iteration number: [470/565] 83% | Training loss: 0.6882799452923714
Epoch: 52 | Iteration number: [480/565] 84% | Training loss: 0.6882408856103818
Epoch: 52 | Iteration number: [490/565] 86% | Training loss: 0.6882153219106246
Epoch: 52 | Iteration number: [500/565] 88% | Training loss: 0.6881893299818039
Epoch: 52 | Iteration number: [510/565] 90% | Training loss: 0.6881704402904885
Epoch: 52 | Iteration number: [520/565] 92% | Training loss: 0.6881377299244588
Epoch: 52 | Iteration number: [530/565] 93% | Training loss: 0.6881176341254757
Epoch: 52 | Iteration number: [540/565] 95% | Training loss: 0.6880956048214877
Epoch: 52 | Iteration number: [550/565] 97% | Training loss: 0.6880673836578023
Epoch: 52 | Iteration number: [560/565] 99% | Training loss: 0.6880556945289884

 End of epoch: 52 | Train Loss: 0.6868322166721378 | Training Time: 88 

 End of epoch: 52 | Eval Loss: 0.6903152465820312 | Evaluating Time: 6 
Epoch: 53 | Iteration number: [10/565] 1% | Training loss: 0.7552470624446869
Epoch: 53 | Iteration number: [20/565] 3% | Training loss: 0.7210082978010177
Epoch: 53 | Iteration number: [30/565] 5% | Training loss: 0.7097734431425731
Epoch: 53 | Iteration number: [40/565] 7% | Training loss: 0.7041271507740021
Epoch: 53 | Iteration number: [50/565] 8% | Training loss: 0.7006406164169312
Epoch: 53 | Iteration number: [60/565] 10% | Training loss: 0.6983068426450093
Epoch: 53 | Iteration number: [70/565] 12% | Training loss: 0.6966614399637495
Epoch: 53 | Iteration number: [80/565] 14% | Training loss: 0.6954067654907703
Epoch: 53 | Iteration number: [90/565] 15% | Training loss: 0.694482296705246
Epoch: 53 | Iteration number: [100/565] 17% | Training loss: 0.6936946129798889
Epoch: 53 | Iteration number: [110/565] 19% | Training loss: 0.6930173397064209
Epoch: 53 | Iteration number: [120/565] 21% | Training loss: 0.6924701338013013
Epoch: 53 | Iteration number: [130/565] 23% | Training loss: 0.6920128932366004
Epoch: 53 | Iteration number: [140/565] 24% | Training loss: 0.6916661185877664
Epoch: 53 | Iteration number: [150/565] 26% | Training loss: 0.6913510191440583
Epoch: 53 | Iteration number: [160/565] 28% | Training loss: 0.691064590960741
Epoch: 53 | Iteration number: [170/565] 30% | Training loss: 0.6908267119351555
Epoch: 53 | Iteration number: [180/565] 31% | Training loss: 0.6906085544162326
Epoch: 53 | Iteration number: [190/565] 33% | Training loss: 0.6904308968468716
Epoch: 53 | Iteration number: [200/565] 35% | Training loss: 0.6902600383758545
Epoch: 53 | Iteration number: [210/565] 37% | Training loss: 0.690114229349863
Epoch: 53 | Iteration number: [220/565] 38% | Training loss: 0.6899584035981785
Epoch: 53 | Iteration number: [230/565] 40% | Training loss: 0.6898222068081732
Epoch: 53 | Iteration number: [240/565] 42% | Training loss: 0.6897052717705567
Epoch: 53 | Iteration number: [250/565] 44% | Training loss: 0.689590292930603
Epoch: 53 | Iteration number: [260/565] 46% | Training loss: 0.6894706251529547
Epoch: 53 | Iteration number: [270/565] 47% | Training loss: 0.6893841611014472
Epoch: 53 | Iteration number: [280/565] 49% | Training loss: 0.6892928627984864
Epoch: 53 | Iteration number: [290/565] 51% | Training loss: 0.6892089299086867
Epoch: 53 | Iteration number: [300/565] 53% | Training loss: 0.6891138152281443
Epoch: 53 | Iteration number: [310/565] 54% | Training loss: 0.6890344489005304
Epoch: 53 | Iteration number: [320/565] 56% | Training loss: 0.6889497192576528
Epoch: 53 | Iteration number: [330/565] 58% | Training loss: 0.6888977764230786
Epoch: 53 | Iteration number: [340/565] 60% | Training loss: 0.6888331637663
Epoch: 53 | Iteration number: [350/565] 61% | Training loss: 0.6887682155200413
Epoch: 53 | Iteration number: [360/565] 63% | Training loss: 0.6887217859427134
Epoch: 53 | Iteration number: [370/565] 65% | Training loss: 0.688676404953003
Epoch: 53 | Iteration number: [380/565] 67% | Training loss: 0.6886137032195141
Epoch: 53 | Iteration number: [390/565] 69% | Training loss: 0.6885616866441874
Epoch: 53 | Iteration number: [400/565] 70% | Training loss: 0.6885175931453705
Epoch: 53 | Iteration number: [410/565] 72% | Training loss: 0.6884753621206051
Epoch: 53 | Iteration number: [420/565] 74% | Training loss: 0.688439184711093
Epoch: 53 | Iteration number: [430/565] 76% | Training loss: 0.6884157920992652
Epoch: 53 | Iteration number: [440/565] 77% | Training loss: 0.6883832355791872
Epoch: 53 | Iteration number: [450/565] 79% | Training loss: 0.6883417465951708
Epoch: 53 | Iteration number: [460/565] 81% | Training loss: 0.6883046300514885
Epoch: 53 | Iteration number: [470/565] 83% | Training loss: 0.6882813647706458
Epoch: 53 | Iteration number: [480/565] 84% | Training loss: 0.6882536701858044
Epoch: 53 | Iteration number: [490/565] 86% | Training loss: 0.6882202918432196
Epoch: 53 | Iteration number: [500/565] 88% | Training loss: 0.6881942018270493
Epoch: 53 | Iteration number: [510/565] 90% | Training loss: 0.6881739760146421
Epoch: 53 | Iteration number: [520/565] 92% | Training loss: 0.6881480275438382
Epoch: 53 | Iteration number: [530/565] 93% | Training loss: 0.688118642343665
Epoch: 53 | Iteration number: [540/565] 95% | Training loss: 0.6880955773371237
Epoch: 53 | Iteration number: [550/565] 97% | Training loss: 0.688065845749595
Epoch: 53 | Iteration number: [560/565] 99% | Training loss: 0.6880494968167373

 End of epoch: 53 | Train Loss: 0.6868247492123494 | Training Time: 88 

 End of epoch: 53 | Eval Loss: 0.6904765793255397 | Evaluating Time: 6 
Epoch: 54 | Iteration number: [10/565] 1% | Training loss: 0.7553775906562805
Epoch: 54 | Iteration number: [20/565] 3% | Training loss: 0.7209790885448456
Epoch: 54 | Iteration number: [30/565] 5% | Training loss: 0.7094820618629456
Epoch: 54 | Iteration number: [40/565] 7% | Training loss: 0.7037998333573341
Epoch: 54 | Iteration number: [50/565] 8% | Training loss: 0.700369029045105
Epoch: 54 | Iteration number: [60/565] 10% | Training loss: 0.6981288293997446
Epoch: 54 | Iteration number: [70/565] 12% | Training loss: 0.6964764731270926
Epoch: 54 | Iteration number: [80/565] 14% | Training loss: 0.6952904894948005
Epoch: 54 | Iteration number: [90/565] 15% | Training loss: 0.6943352593315972
Epoch: 54 | Iteration number: [100/565] 17% | Training loss: 0.6936058497428894
Epoch: 54 | Iteration number: [110/565] 19% | Training loss: 0.6929121120409532
Epoch: 54 | Iteration number: [120/565] 21% | Training loss: 0.6923727189501127
Epoch: 54 | Iteration number: [130/565] 23% | Training loss: 0.6919245990423056
Epoch: 54 | Iteration number: [140/565] 24% | Training loss: 0.6915834618466241
Epoch: 54 | Iteration number: [150/565] 26% | Training loss: 0.6912951191266378
Epoch: 54 | Iteration number: [160/565] 28% | Training loss: 0.6909871075302363
Epoch: 54 | Iteration number: [170/565] 30% | Training loss: 0.6907598646248088
Epoch: 54 | Iteration number: [180/565] 31% | Training loss: 0.6905491365326776
Epoch: 54 | Iteration number: [190/565] 33% | Training loss: 0.6903480805848774
Epoch: 54 | Iteration number: [200/565] 35% | Training loss: 0.6901853930950165
Epoch: 54 | Iteration number: [210/565] 37% | Training loss: 0.6900132216158368
Epoch: 54 | Iteration number: [220/565] 38% | Training loss: 0.689892643419179
Epoch: 54 | Iteration number: [230/565] 40% | Training loss: 0.6897648285264554
Epoch: 54 | Iteration number: [240/565] 42% | Training loss: 0.6896333212653796
Epoch: 54 | Iteration number: [250/565] 44% | Training loss: 0.6895200464725494
Epoch: 54 | Iteration number: [260/565] 46% | Training loss: 0.6894303026107641
Epoch: 54 | Iteration number: [270/565] 47% | Training loss: 0.6893414559187713
Epoch: 54 | Iteration number: [280/565] 49% | Training loss: 0.689257743528911
Epoch: 54 | Iteration number: [290/565] 51% | Training loss: 0.6891797499410037
Epoch: 54 | Iteration number: [300/565] 53% | Training loss: 0.6890977547566096
Epoch: 54 | Iteration number: [310/565] 54% | Training loss: 0.6890325944269857
Epoch: 54 | Iteration number: [320/565] 56% | Training loss: 0.6889708055183291
Epoch: 54 | Iteration number: [330/565] 58% | Training loss: 0.6888948624784296
Epoch: 54 | Iteration number: [340/565] 60% | Training loss: 0.6888450399917715
Epoch: 54 | Iteration number: [350/565] 61% | Training loss: 0.6887687264169966
Epoch: 54 | Iteration number: [360/565] 63% | Training loss: 0.6887172253595458
Epoch: 54 | Iteration number: [370/565] 65% | Training loss: 0.6886767991491266
Epoch: 54 | Iteration number: [380/565] 67% | Training loss: 0.6886086388638145
Epoch: 54 | Iteration number: [390/565] 69% | Training loss: 0.688568817346524
Epoch: 54 | Iteration number: [400/565] 70% | Training loss: 0.6885364803671837
Epoch: 54 | Iteration number: [410/565] 72% | Training loss: 0.6884940103786747
Epoch: 54 | Iteration number: [420/565] 74% | Training loss: 0.6884538673219227
Epoch: 54 | Iteration number: [430/565] 76% | Training loss: 0.688406877739485
Epoch: 54 | Iteration number: [440/565] 77% | Training loss: 0.6883751671422612
Epoch: 54 | Iteration number: [450/565] 79% | Training loss: 0.6883461210462782
Epoch: 54 | Iteration number: [460/565] 81% | Training loss: 0.6883120194725368
Epoch: 54 | Iteration number: [470/565] 83% | Training loss: 0.6882878826019612
Epoch: 54 | Iteration number: [480/565] 84% | Training loss: 0.6882522307336331
Epoch: 54 | Iteration number: [490/565] 86% | Training loss: 0.6882252954706853
Epoch: 54 | Iteration number: [500/565] 88% | Training loss: 0.6881904901266098
Epoch: 54 | Iteration number: [510/565] 90% | Training loss: 0.6881637586098092
Epoch: 54 | Iteration number: [520/565] 92% | Training loss: 0.6881406309512945
Epoch: 54 | Iteration number: [530/565] 93% | Training loss: 0.6881131632148095
Epoch: 54 | Iteration number: [540/565] 95% | Training loss: 0.688094601587013
Epoch: 54 | Iteration number: [550/565] 97% | Training loss: 0.6880641839720986
Epoch: 54 | Iteration number: [560/565] 99% | Training loss: 0.6880421046699796

 End of epoch: 54 | Train Loss: 0.6868145095563568 | Training Time: 89 

 End of epoch: 54 | Eval Loss: 0.6898718731743949 | Evaluating Time: 6 
Epoch: 55 | Iteration number: [10/565] 1% | Training loss: 0.7553409695625305
Epoch: 55 | Iteration number: [20/565] 3% | Training loss: 0.7210907250642776
Epoch: 55 | Iteration number: [30/565] 5% | Training loss: 0.7097732881704967
Epoch: 55 | Iteration number: [40/565] 7% | Training loss: 0.7040077477693558
Epoch: 55 | Iteration number: [50/565] 8% | Training loss: 0.700599205493927
Epoch: 55 | Iteration number: [60/565] 10% | Training loss: 0.6983157753944397
Epoch: 55 | Iteration number: [70/565] 12% | Training loss: 0.696636278288705
Epoch: 55 | Iteration number: [80/565] 14% | Training loss: 0.6953885182738304
Epoch: 55 | Iteration number: [90/565] 15% | Training loss: 0.6944068478213417
Epoch: 55 | Iteration number: [100/565] 17% | Training loss: 0.6936091297864914
Epoch: 55 | Iteration number: [110/565] 19% | Training loss: 0.6929633899168535
Epoch: 55 | Iteration number: [120/565] 21% | Training loss: 0.692441588640213
Epoch: 55 | Iteration number: [130/565] 23% | Training loss: 0.6920178184142479
Epoch: 55 | Iteration number: [140/565] 24% | Training loss: 0.6916452842099327
Epoch: 55 | Iteration number: [150/565] 26% | Training loss: 0.6913480130831401
Epoch: 55 | Iteration number: [160/565] 28% | Training loss: 0.6910685081034899
Epoch: 55 | Iteration number: [170/565] 30% | Training loss: 0.6908233162234811
Epoch: 55 | Iteration number: [180/565] 31% | Training loss: 0.6906125379933251
Epoch: 55 | Iteration number: [190/565] 33% | Training loss: 0.6904244062147642
Epoch: 55 | Iteration number: [200/565] 35% | Training loss: 0.690229124724865
Epoch: 55 | Iteration number: [210/565] 37% | Training loss: 0.6900702235244569
Epoch: 55 | Iteration number: [220/565] 38% | Training loss: 0.6899201496080919
Epoch: 55 | Iteration number: [230/565] 40% | Training loss: 0.6897661698901135
Epoch: 55 | Iteration number: [240/565] 42% | Training loss: 0.6896565961341063
Epoch: 55 | Iteration number: [250/565] 44% | Training loss: 0.689533910036087
Epoch: 55 | Iteration number: [260/565] 46% | Training loss: 0.689421383692668
Epoch: 55 | Iteration number: [270/565] 47% | Training loss: 0.6893284429002691
Epoch: 55 | Iteration number: [280/565] 49% | Training loss: 0.6892398393579892
Epoch: 55 | Iteration number: [290/565] 51% | Training loss: 0.6891439246720281
Epoch: 55 | Iteration number: [300/565] 53% | Training loss: 0.6890791489680608
Epoch: 55 | Iteration number: [310/565] 54% | Training loss: 0.6890110037019176
Epoch: 55 | Iteration number: [320/565] 56% | Training loss: 0.6889459839090705
Epoch: 55 | Iteration number: [330/565] 58% | Training loss: 0.6888743835868257
Epoch: 55 | Iteration number: [340/565] 60% | Training loss: 0.6888210705097983
Epoch: 55 | Iteration number: [350/565] 61% | Training loss: 0.6887653582436698
Epoch: 55 | Iteration number: [360/565] 63% | Training loss: 0.6887006991439395
Epoch: 55 | Iteration number: [370/565] 65% | Training loss: 0.6886433284024934
Epoch: 55 | Iteration number: [380/565] 67% | Training loss: 0.6885973172752481
Epoch: 55 | Iteration number: [390/565] 69% | Training loss: 0.6885546101973608
Epoch: 55 | Iteration number: [400/565] 70% | Training loss: 0.6885062266886234
Epoch: 55 | Iteration number: [410/565] 72% | Training loss: 0.6884597416331129
Epoch: 55 | Iteration number: [420/565] 74% | Training loss: 0.6884212346304031
Epoch: 55 | Iteration number: [430/565] 76% | Training loss: 0.6883807207262793
Epoch: 55 | Iteration number: [440/565] 77% | Training loss: 0.6883509786291556
Epoch: 55 | Iteration number: [450/565] 79% | Training loss: 0.6883073408073849
Epoch: 55 | Iteration number: [460/565] 81% | Training loss: 0.6882739125386529
Epoch: 55 | Iteration number: [470/565] 83% | Training loss: 0.6882474781350887
Epoch: 55 | Iteration number: [480/565] 84% | Training loss: 0.6882226025064786
Epoch: 55 | Iteration number: [490/565] 86% | Training loss: 0.6881920990895252
Epoch: 55 | Iteration number: [500/565] 88% | Training loss: 0.6881699080467224
Epoch: 55 | Iteration number: [510/565] 90% | Training loss: 0.6881421435113046
Epoch: 55 | Iteration number: [520/565] 92% | Training loss: 0.6881205555338126
Epoch: 55 | Iteration number: [530/565] 93% | Training loss: 0.6880952241285792
Epoch: 55 | Iteration number: [540/565] 95% | Training loss: 0.6880728899328797
Epoch: 55 | Iteration number: [550/565] 97% | Training loss: 0.6880534822290594
Epoch: 55 | Iteration number: [560/565] 99% | Training loss: 0.6880283239696707

 End of epoch: 55 | Train Loss: 0.6868046536909795 | Training Time: 90 

 End of epoch: 55 | Eval Loss: 0.6900170615741185 | Evaluating Time: 5 
Epoch: 56 | Iteration number: [10/565] 1% | Training loss: 0.7550794899463653
Epoch: 56 | Iteration number: [20/565] 3% | Training loss: 0.7209274649620057
Epoch: 56 | Iteration number: [30/565] 5% | Training loss: 0.7095348576704661
Epoch: 56 | Iteration number: [40/565] 7% | Training loss: 0.7037729650735856
Epoch: 56 | Iteration number: [50/565] 8% | Training loss: 0.7003470373153686
Epoch: 56 | Iteration number: [60/565] 10% | Training loss: 0.6981004764636357
Epoch: 56 | Iteration number: [70/565] 12% | Training loss: 0.6964359734739576
Epoch: 56 | Iteration number: [80/565] 14% | Training loss: 0.6953101217746734
Epoch: 56 | Iteration number: [90/565] 15% | Training loss: 0.69433550702201
Epoch: 56 | Iteration number: [100/565] 17% | Training loss: 0.6935986524820328
Epoch: 56 | Iteration number: [110/565] 19% | Training loss: 0.6930108205838637
Epoch: 56 | Iteration number: [120/565] 21% | Training loss: 0.6925301288565
Epoch: 56 | Iteration number: [130/565] 23% | Training loss: 0.6921308292792394
Epoch: 56 | Iteration number: [140/565] 24% | Training loss: 0.6917722178356988
Epoch: 56 | Iteration number: [150/565] 26% | Training loss: 0.6914477415879567
Epoch: 56 | Iteration number: [160/565] 28% | Training loss: 0.6911596015095711
Epoch: 56 | Iteration number: [170/565] 30% | Training loss: 0.6908873558044434
Epoch: 56 | Iteration number: [180/565] 31% | Training loss: 0.6906504743629032
Epoch: 56 | Iteration number: [190/565] 33% | Training loss: 0.6904608202608008
Epoch: 56 | Iteration number: [200/565] 35% | Training loss: 0.6902484783530235
Epoch: 56 | Iteration number: [210/565] 37% | Training loss: 0.6900916389056615
Epoch: 56 | Iteration number: [220/565] 38% | Training loss: 0.6899304024197839
Epoch: 56 | Iteration number: [230/565] 40% | Training loss: 0.6897891420385112
Epoch: 56 | Iteration number: [240/565] 42% | Training loss: 0.6896706221004327
Epoch: 56 | Iteration number: [250/565] 44% | Training loss: 0.6895492615699768
Epoch: 56 | Iteration number: [260/565] 46% | Training loss: 0.6894428713963582
Epoch: 56 | Iteration number: [270/565] 47% | Training loss: 0.689338876803716
Epoch: 56 | Iteration number: [280/565] 49% | Training loss: 0.6892402014562062
Epoch: 56 | Iteration number: [290/565] 51% | Training loss: 0.6891522832985582
Epoch: 56 | Iteration number: [300/565] 53% | Training loss: 0.6890688461065292
Epoch: 56 | Iteration number: [310/565] 54% | Training loss: 0.6889941030933011
Epoch: 56 | Iteration number: [320/565] 56% | Training loss: 0.6889190005138517
Epoch: 56 | Iteration number: [330/565] 58% | Training loss: 0.6888491547468937
Epoch: 56 | Iteration number: [340/565] 60% | Training loss: 0.6887885155046687
Epoch: 56 | Iteration number: [350/565] 61% | Training loss: 0.6887391883986337
Epoch: 56 | Iteration number: [360/565] 63% | Training loss: 0.6886867918901973
Epoch: 56 | Iteration number: [370/565] 65% | Training loss: 0.6886483248826619
Epoch: 56 | Iteration number: [380/565] 67% | Training loss: 0.688597423308774
Epoch: 56 | Iteration number: [390/565] 69% | Training loss: 0.6885473089340406
Epoch: 56 | Iteration number: [400/565] 70% | Training loss: 0.6885098189115524
Epoch: 56 | Iteration number: [410/565] 72% | Training loss: 0.6884665067602949
Epoch: 56 | Iteration number: [420/565] 74% | Training loss: 0.6884276419878006
Epoch: 56 | Iteration number: [430/565] 76% | Training loss: 0.6884015587873237
Epoch: 56 | Iteration number: [440/565] 77% | Training loss: 0.6883572661063888
Epoch: 56 | Iteration number: [450/565] 79% | Training loss: 0.6883156228065491
Epoch: 56 | Iteration number: [460/565] 81% | Training loss: 0.6882915676935859
Epoch: 56 | Iteration number: [470/565] 83% | Training loss: 0.6882624189904396
Epoch: 56 | Iteration number: [480/565] 84% | Training loss: 0.6882356869677703
Epoch: 56 | Iteration number: [490/565] 86% | Training loss: 0.6882071059577319
Epoch: 56 | Iteration number: [500/565] 88% | Training loss: 0.6881848407983779
Epoch: 56 | Iteration number: [510/565] 90% | Training loss: 0.6881598047181672
Epoch: 56 | Iteration number: [520/565] 92% | Training loss: 0.6881366040844183
Epoch: 56 | Iteration number: [530/565] 93% | Training loss: 0.6881061090613311
Epoch: 56 | Iteration number: [540/565] 95% | Training loss: 0.6880886007238317
Epoch: 56 | Iteration number: [550/565] 97% | Training loss: 0.6880746830593456
Epoch: 56 | Iteration number: [560/565] 99% | Training loss: 0.6880511729844979

 End of epoch: 56 | Train Loss: 0.6868260428968784 | Training Time: 89 

 End of epoch: 56 | Eval Loss: 0.6899421981402806 | Evaluating Time: 6 
Epoch: 57 | Iteration number: [10/565] 1% | Training loss: 0.7552438020706177
Epoch: 57 | Iteration number: [20/565] 3% | Training loss: 0.7212366819381714
Epoch: 57 | Iteration number: [30/565] 5% | Training loss: 0.709807817141215
Epoch: 57 | Iteration number: [40/565] 7% | Training loss: 0.7041146859526635
Epoch: 57 | Iteration number: [50/565] 8% | Training loss: 0.7006580996513366
Epoch: 57 | Iteration number: [60/565] 10% | Training loss: 0.6983586420615514
Epoch: 57 | Iteration number: [70/565] 12% | Training loss: 0.696656618799482
Epoch: 57 | Iteration number: [80/565] 14% | Training loss: 0.6954678297042847
Epoch: 57 | Iteration number: [90/565] 15% | Training loss: 0.6944825490315755
Epoch: 57 | Iteration number: [100/565] 17% | Training loss: 0.6937105339765549
Epoch: 57 | Iteration number: [110/565] 19% | Training loss: 0.6930995556441221
Epoch: 57 | Iteration number: [120/565] 21% | Training loss: 0.6925658226013184
Epoch: 57 | Iteration number: [130/565] 23% | Training loss: 0.6921592235565186
Epoch: 57 | Iteration number: [140/565] 24% | Training loss: 0.6918149948120117
Epoch: 57 | Iteration number: [150/565] 26% | Training loss: 0.6914984285831451
Epoch: 57 | Iteration number: [160/565] 28% | Training loss: 0.6911677241325378
Epoch: 57 | Iteration number: [170/565] 30% | Training loss: 0.6909219405230353
Epoch: 57 | Iteration number: [180/565] 31% | Training loss: 0.6907059527105756
Epoch: 57 | Iteration number: [190/565] 33% | Training loss: 0.6905052523863943
Epoch: 57 | Iteration number: [200/565] 35% | Training loss: 0.6902825319766999
Epoch: 57 | Iteration number: [210/565] 37% | Training loss: 0.6901151171752384
Epoch: 57 | Iteration number: [220/565] 38% | Training loss: 0.6899657932194796
Epoch: 57 | Iteration number: [230/565] 40% | Training loss: 0.6898347509943921
Epoch: 57 | Iteration number: [240/565] 42% | Training loss: 0.6896963648498058
Epoch: 57 | Iteration number: [250/565] 44% | Training loss: 0.6895558338165283
Epoch: 57 | Iteration number: [260/565] 46% | Training loss: 0.6894446712273817
Epoch: 57 | Iteration number: [270/565] 47% | Training loss: 0.6893383149747495
Epoch: 57 | Iteration number: [280/565] 49% | Training loss: 0.6892328140991074
Epoch: 57 | Iteration number: [290/565] 51% | Training loss: 0.6891460365262525
Epoch: 57 | Iteration number: [300/565] 53% | Training loss: 0.6890670323371887
Epoch: 57 | Iteration number: [310/565] 54% | Training loss: 0.6890101842341885
Epoch: 57 | Iteration number: [320/565] 56% | Training loss: 0.6889468066394329
Epoch: 57 | Iteration number: [330/565] 58% | Training loss: 0.6888704630461606
Epoch: 57 | Iteration number: [340/565] 60% | Training loss: 0.6887957860441769
Epoch: 57 | Iteration number: [350/565] 61% | Training loss: 0.6887385826451438
Epoch: 57 | Iteration number: [360/565] 63% | Training loss: 0.6886968069606357
Epoch: 57 | Iteration number: [370/565] 65% | Training loss: 0.6886449187188535
Epoch: 57 | Iteration number: [380/565] 67% | Training loss: 0.6885977770152845
Epoch: 57 | Iteration number: [390/565] 69% | Training loss: 0.6885579003737523
Epoch: 57 | Iteration number: [400/565] 70% | Training loss: 0.6885150654613972
Epoch: 57 | Iteration number: [410/565] 72% | Training loss: 0.6884775597874712
Epoch: 57 | Iteration number: [420/565] 74% | Training loss: 0.688445765205792
Epoch: 57 | Iteration number: [430/565] 76% | Training loss: 0.6884064670218978
Epoch: 57 | Iteration number: [440/565] 77% | Training loss: 0.6883735639127818
Epoch: 57 | Iteration number: [450/565] 79% | Training loss: 0.6883445799350738
Epoch: 57 | Iteration number: [460/565] 81% | Training loss: 0.6883113774268523
Epoch: 57 | Iteration number: [470/565] 83% | Training loss: 0.6882731042009719
Epoch: 57 | Iteration number: [480/565] 84% | Training loss: 0.6882500026375056
Epoch: 57 | Iteration number: [490/565] 86% | Training loss: 0.6882160404506995
Epoch: 57 | Iteration number: [500/565] 88% | Training loss: 0.6881833441257477
Epoch: 57 | Iteration number: [510/565] 90% | Training loss: 0.6881651344252567
Epoch: 57 | Iteration number: [520/565] 92% | Training loss: 0.6881348385260655
Epoch: 57 | Iteration number: [530/565] 93% | Training loss: 0.6881090773726409
Epoch: 57 | Iteration number: [540/565] 95% | Training loss: 0.688088838700895
Epoch: 57 | Iteration number: [550/565] 97% | Training loss: 0.6880646657943725
Epoch: 57 | Iteration number: [560/565] 99% | Training loss: 0.688032539827483

 End of epoch: 57 | Train Loss: 0.6868057858627454 | Training Time: 89 

 End of epoch: 57 | Eval Loss: 0.6900202546800885 | Evaluating Time: 6 
Epoch: 58 | Iteration number: [10/565] 1% | Training loss: 0.7552592337131501
Epoch: 58 | Iteration number: [20/565] 3% | Training loss: 0.7209630638360978
Epoch: 58 | Iteration number: [30/565] 5% | Training loss: 0.7094676434993744
Epoch: 58 | Iteration number: [40/565] 7% | Training loss: 0.7038278818130493
Epoch: 58 | Iteration number: [50/565] 8% | Training loss: 0.7004435729980468
Epoch: 58 | Iteration number: [60/565] 10% | Training loss: 0.6981841464837392
Epoch: 58 | Iteration number: [70/565] 12% | Training loss: 0.6964647097246988
Epoch: 58 | Iteration number: [80/565] 14% | Training loss: 0.695325730741024
Epoch: 58 | Iteration number: [90/565] 15% | Training loss: 0.6943980243470934
Epoch: 58 | Iteration number: [100/565] 17% | Training loss: 0.6936121433973312
Epoch: 58 | Iteration number: [110/565] 19% | Training loss: 0.692995455048301
Epoch: 58 | Iteration number: [120/565] 21% | Training loss: 0.6924661527077357
Epoch: 58 | Iteration number: [130/565] 23% | Training loss: 0.6920256963142982
Epoch: 58 | Iteration number: [140/565] 24% | Training loss: 0.6916673277105604
Epoch: 58 | Iteration number: [150/565] 26% | Training loss: 0.6913351150353749
Epoch: 58 | Iteration number: [160/565] 28% | Training loss: 0.6910524878650903
Epoch: 58 | Iteration number: [170/565] 30% | Training loss: 0.6907952168408562
Epoch: 58 | Iteration number: [180/565] 31% | Training loss: 0.690603909889857
Epoch: 58 | Iteration number: [190/565] 33% | Training loss: 0.6904116759174749
Epoch: 58 | Iteration number: [200/565] 35% | Training loss: 0.6902229362726211
Epoch: 58 | Iteration number: [210/565] 37% | Training loss: 0.6900521190393538
Epoch: 58 | Iteration number: [220/565] 38% | Training loss: 0.6898843201723965
Epoch: 58 | Iteration number: [230/565] 40% | Training loss: 0.6897446072619894
Epoch: 58 | Iteration number: [240/565] 42% | Training loss: 0.6896143317222595
Epoch: 58 | Iteration number: [250/565] 44% | Training loss: 0.6895096983909607
Epoch: 58 | Iteration number: [260/565] 46% | Training loss: 0.6894119306252553
Epoch: 58 | Iteration number: [270/565] 47% | Training loss: 0.6893128377419931
Epoch: 58 | Iteration number: [280/565] 49% | Training loss: 0.6892236175281661
Epoch: 58 | Iteration number: [290/565] 51% | Training loss: 0.6891497359193605
Epoch: 58 | Iteration number: [300/565] 53% | Training loss: 0.6890643084049225
Epoch: 58 | Iteration number: [310/565] 54% | Training loss: 0.6889935107000412
Epoch: 58 | Iteration number: [320/565] 56% | Training loss: 0.6889198806136847
Epoch: 58 | Iteration number: [330/565] 58% | Training loss: 0.6888579975474964
Epoch: 58 | Iteration number: [340/565] 60% | Training loss: 0.6888027445358389
Epoch: 58 | Iteration number: [350/565] 61% | Training loss: 0.6887508879389082
Epoch: 58 | Iteration number: [360/565] 63% | Training loss: 0.6886889432867368
Epoch: 58 | Iteration number: [370/565] 65% | Training loss: 0.6886346448112178
Epoch: 58 | Iteration number: [380/565] 67% | Training loss: 0.6885839186216656
Epoch: 58 | Iteration number: [390/565] 69% | Training loss: 0.6885314180300786
Epoch: 58 | Iteration number: [400/565] 70% | Training loss: 0.6884906686842441
Epoch: 58 | Iteration number: [410/565] 72% | Training loss: 0.6884566802804063
Epoch: 58 | Iteration number: [420/565] 74% | Training loss: 0.6884056270122528
Epoch: 58 | Iteration number: [430/565] 76% | Training loss: 0.6883618311826573
Epoch: 58 | Iteration number: [440/565] 77% | Training loss: 0.6883252103220333
Epoch: 58 | Iteration number: [450/565] 79% | Training loss: 0.6882975590229035
Epoch: 58 | Iteration number: [460/565] 81% | Training loss: 0.6882656921511111
Epoch: 58 | Iteration number: [470/565] 83% | Training loss: 0.6882353422489572
Epoch: 58 | Iteration number: [480/565] 84% | Training loss: 0.6882070321589708
Epoch: 58 | Iteration number: [490/565] 86% | Training loss: 0.6881772875785828
Epoch: 58 | Iteration number: [500/565] 88% | Training loss: 0.6881534185409546
Epoch: 58 | Iteration number: [510/565] 90% | Training loss: 0.6881273318739498
Epoch: 58 | Iteration number: [520/565] 92% | Training loss: 0.6881082554276173
Epoch: 58 | Iteration number: [530/565] 93% | Training loss: 0.6880851690499288
Epoch: 58 | Iteration number: [540/565] 95% | Training loss: 0.6880667472327197
Epoch: 58 | Iteration number: [550/565] 97% | Training loss: 0.688043713461269
Epoch: 58 | Iteration number: [560/565] 99% | Training loss: 0.6880301191338472

 End of epoch: 58 | Train Loss: 0.6867988354336899 | Training Time: 89 

 End of epoch: 58 | Eval Loss: 0.6903524483953204 | Evaluating Time: 6 
Epoch: 59 | Iteration number: [10/565] 1% | Training loss: 0.7557039439678193
Epoch: 59 | Iteration number: [20/565] 3% | Training loss: 0.7210763216018676
Epoch: 59 | Iteration number: [30/565] 5% | Training loss: 0.7095688064893086
Epoch: 59 | Iteration number: [40/565] 7% | Training loss: 0.7038648262619972
Epoch: 59 | Iteration number: [50/565] 8% | Training loss: 0.7004419994354248
Epoch: 59 | Iteration number: [60/565] 10% | Training loss: 0.6981870333353678
Epoch: 59 | Iteration number: [70/565] 12% | Training loss: 0.6965388587542942
Epoch: 59 | Iteration number: [80/565] 14% | Training loss: 0.6954066805541516
Epoch: 59 | Iteration number: [90/565] 15% | Training loss: 0.6944931950834062
Epoch: 59 | Iteration number: [100/565] 17% | Training loss: 0.6937277108430863
Epoch: 59 | Iteration number: [110/565] 19% | Training loss: 0.6931374132633209
Epoch: 59 | Iteration number: [120/565] 21% | Training loss: 0.6925937081376712
Epoch: 59 | Iteration number: [130/565] 23% | Training loss: 0.692137499497487
Epoch: 59 | Iteration number: [140/565] 24% | Training loss: 0.69179120021207
Epoch: 59 | Iteration number: [150/565] 26% | Training loss: 0.6914702820777893
Epoch: 59 | Iteration number: [160/565] 28% | Training loss: 0.6911776434630156
Epoch: 59 | Iteration number: [170/565] 30% | Training loss: 0.6909433491089765
Epoch: 59 | Iteration number: [180/565] 31% | Training loss: 0.6907223794195387
Epoch: 59 | Iteration number: [190/565] 33% | Training loss: 0.6905114333880575
Epoch: 59 | Iteration number: [200/565] 35% | Training loss: 0.690325520336628
Epoch: 59 | Iteration number: [210/565] 37% | Training loss: 0.6901224119322641
Epoch: 59 | Iteration number: [220/565] 38% | Training loss: 0.6899830297990279
Epoch: 59 | Iteration number: [230/565] 40% | Training loss: 0.689842482753422
Epoch: 59 | Iteration number: [240/565] 42% | Training loss: 0.6897092036902904
Epoch: 59 | Iteration number: [250/565] 44% | Training loss: 0.6895910477638245
Epoch: 59 | Iteration number: [260/565] 46% | Training loss: 0.689471277136069
Epoch: 59 | Iteration number: [270/565] 47% | Training loss: 0.6893662441659857
Epoch: 59 | Iteration number: [280/565] 49% | Training loss: 0.6892715381724493
Epoch: 59 | Iteration number: [290/565] 51% | Training loss: 0.6891824942210625
Epoch: 59 | Iteration number: [300/565] 53% | Training loss: 0.6890957168738048
Epoch: 59 | Iteration number: [310/565] 54% | Training loss: 0.6890277049233836
Epoch: 59 | Iteration number: [320/565] 56% | Training loss: 0.6889543682336807
Epoch: 59 | Iteration number: [330/565] 58% | Training loss: 0.688900287584825
Epoch: 59 | Iteration number: [340/565] 60% | Training loss: 0.6888428668765461
Epoch: 59 | Iteration number: [350/565] 61% | Training loss: 0.6887801258904593
Epoch: 59 | Iteration number: [360/565] 63% | Training loss: 0.6887129697534773
Epoch: 59 | Iteration number: [370/565] 65% | Training loss: 0.688661773140366
Epoch: 59 | Iteration number: [380/565] 67% | Training loss: 0.6886127871902366
Epoch: 59 | Iteration number: [390/565] 69% | Training loss: 0.6885583276932056
Epoch: 59 | Iteration number: [400/565] 70% | Training loss: 0.6885107071697711
Epoch: 59 | Iteration number: [410/565] 72% | Training loss: 0.6884728113325631
Epoch: 59 | Iteration number: [420/565] 74% | Training loss: 0.6884321381648382
Epoch: 59 | Iteration number: [430/565] 76% | Training loss: 0.6884002688319184
Epoch: 59 | Iteration number: [440/565] 77% | Training loss: 0.6883720847693356
Epoch: 59 | Iteration number: [450/565] 79% | Training loss: 0.6883452614148458
Epoch: 59 | Iteration number: [460/565] 81% | Training loss: 0.6883194643518199
Epoch: 59 | Iteration number: [470/565] 83% | Training loss: 0.6882887636093383
Epoch: 59 | Iteration number: [480/565] 84% | Training loss: 0.6882628378768761
Epoch: 59 | Iteration number: [490/565] 86% | Training loss: 0.6882325770903607
Epoch: 59 | Iteration number: [500/565] 88% | Training loss: 0.6882068674564361
Epoch: 59 | Iteration number: [510/565] 90% | Training loss: 0.6881722442075318
Epoch: 59 | Iteration number: [520/565] 92% | Training loss: 0.6881401521655229
Epoch: 59 | Iteration number: [530/565] 93% | Training loss: 0.6881223490778006
Epoch: 59 | Iteration number: [540/565] 95% | Training loss: 0.6880973108388759
Epoch: 59 | Iteration number: [550/565] 97% | Training loss: 0.688074818090959
Epoch: 59 | Iteration number: [560/565] 99% | Training loss: 0.6880538610475404

 End of epoch: 59 | Train Loss: 0.6868294472188021 | Training Time: 90 

 End of epoch: 59 | Eval Loss: 0.6902631180627006 | Evaluating Time: 6 
Epoch: 60 | Iteration number: [10/565] 1% | Training loss: 0.7551192581653595
Epoch: 60 | Iteration number: [20/565] 3% | Training loss: 0.7210472315549851
Epoch: 60 | Iteration number: [30/565] 5% | Training loss: 0.7094925165176391
Epoch: 60 | Iteration number: [40/565] 7% | Training loss: 0.7038792699575425
Epoch: 60 | Iteration number: [50/565] 8% | Training loss: 0.7004640698432922
Epoch: 60 | Iteration number: [60/565] 10% | Training loss: 0.6980963458617528
Epoch: 60 | Iteration number: [70/565] 12% | Training loss: 0.6964875297886984
Epoch: 60 | Iteration number: [80/565] 14% | Training loss: 0.6952798344194889
Epoch: 60 | Iteration number: [90/565] 15% | Training loss: 0.6943182130654653
Epoch: 60 | Iteration number: [100/565] 17% | Training loss: 0.6935913008451462
Epoch: 60 | Iteration number: [110/565] 19% | Training loss: 0.692986710505052
Epoch: 60 | Iteration number: [120/565] 21% | Training loss: 0.692485865453879
Epoch: 60 | Iteration number: [130/565] 23% | Training loss: 0.6920710861682892
Epoch: 60 | Iteration number: [140/565] 24% | Training loss: 0.6916876801422664
Epoch: 60 | Iteration number: [150/565] 26% | Training loss: 0.6913877948125203
Epoch: 60 | Iteration number: [160/565] 28% | Training loss: 0.691123741492629
Epoch: 60 | Iteration number: [170/565] 30% | Training loss: 0.6908620595932007
Epoch: 60 | Iteration number: [180/565] 31% | Training loss: 0.6906302710374196
Epoch: 60 | Iteration number: [190/565] 33% | Training loss: 0.6904327154159546
Epoch: 60 | Iteration number: [200/565] 35% | Training loss: 0.6902355498075485
Epoch: 60 | Iteration number: [210/565] 37% | Training loss: 0.6900828557355063
Epoch: 60 | Iteration number: [220/565] 38% | Training loss: 0.6899439418857748
Epoch: 60 | Iteration number: [230/565] 40% | Training loss: 0.68981548651405
Epoch: 60 | Iteration number: [240/565] 42% | Training loss: 0.689685033261776
Epoch: 60 | Iteration number: [250/565] 44% | Training loss: 0.6895611207485199
Epoch: 60 | Iteration number: [260/565] 46% | Training loss: 0.6894559387977307
Epoch: 60 | Iteration number: [270/565] 47% | Training loss: 0.6893670236622845
Epoch: 60 | Iteration number: [280/565] 49% | Training loss: 0.6892853998712131
Epoch: 60 | Iteration number: [290/565] 51% | Training loss: 0.6892076025749075
Epoch: 60 | Iteration number: [300/565] 53% | Training loss: 0.6891270045439403
Epoch: 60 | Iteration number: [310/565] 54% | Training loss: 0.6890482852535863
Epoch: 60 | Iteration number: [320/565] 56% | Training loss: 0.6889791836962104
Epoch: 60 | Iteration number: [330/565] 58% | Training loss: 0.6889066569732897
Epoch: 60 | Iteration number: [340/565] 60% | Training loss: 0.6888524593675838
Epoch: 60 | Iteration number: [350/565] 61% | Training loss: 0.6887857799870627
Epoch: 60 | Iteration number: [360/565] 63% | Training loss: 0.6887363026539485
Epoch: 60 | Iteration number: [370/565] 65% | Training loss: 0.6886723081807833
Epoch: 60 | Iteration number: [380/565] 67% | Training loss: 0.6886260344793922
Epoch: 60 | Iteration number: [390/565] 69% | Training loss: 0.688580194192055
Epoch: 60 | Iteration number: [400/565] 70% | Training loss: 0.6885205216705799
Epoch: 60 | Iteration number: [410/565] 72% | Training loss: 0.6884878971227786
Epoch: 60 | Iteration number: [420/565] 74% | Training loss: 0.6884436373199735
Epoch: 60 | Iteration number: [430/565] 76% | Training loss: 0.6884024915307068
Epoch: 60 | Iteration number: [440/565] 77% | Training loss: 0.6883682683110237
Epoch: 60 | Iteration number: [450/565] 79% | Training loss: 0.6883281143506368
Epoch: 60 | Iteration number: [460/565] 81% | Training loss: 0.6883007414962934
Epoch: 60 | Iteration number: [470/565] 83% | Training loss: 0.6882619821010751
Epoch: 60 | Iteration number: [480/565] 84% | Training loss: 0.6882348372290532
Epoch: 60 | Iteration number: [490/565] 86% | Training loss: 0.6882011250573762
Epoch: 60 | Iteration number: [500/565] 88% | Training loss: 0.6881775594949723
Epoch: 60 | Iteration number: [510/565] 90% | Training loss: 0.6881570959792418
Epoch: 60 | Iteration number: [520/565] 92% | Training loss: 0.6881311183938613
Epoch: 60 | Iteration number: [530/565] 93% | Training loss: 0.6881040005189067
Epoch: 60 | Iteration number: [540/565] 95% | Training loss: 0.6880815433131324
Epoch: 60 | Iteration number: [550/565] 97% | Training loss: 0.6880606730417772
Epoch: 60 | Iteration number: [560/565] 99% | Training loss: 0.6880382444177355

 End of epoch: 60 | Train Loss: 0.6868079648608655 | Training Time: 89 

 End of epoch: 60 | Eval Loss: 0.6902776615960258 | Evaluating Time: 6 
Epoch: 61 | Iteration number: [10/565] 1% | Training loss: 0.755860161781311
Epoch: 61 | Iteration number: [20/565] 3% | Training loss: 0.7212070941925048
Epoch: 61 | Iteration number: [30/565] 5% | Training loss: 0.7096632639567058
Epoch: 61 | Iteration number: [40/565] 7% | Training loss: 0.7038965910673142
Epoch: 61 | Iteration number: [50/565] 8% | Training loss: 0.7004165208339691
Epoch: 61 | Iteration number: [60/565] 10% | Training loss: 0.6981192588806152
Epoch: 61 | Iteration number: [70/565] 12% | Training loss: 0.6964990215642112
Epoch: 61 | Iteration number: [80/565] 14% | Training loss: 0.6953059330582618
Epoch: 61 | Iteration number: [90/565] 15% | Training loss: 0.6943733142481909
Epoch: 61 | Iteration number: [100/565] 17% | Training loss: 0.6936181634664536
Epoch: 61 | Iteration number: [110/565] 19% | Training loss: 0.6929753802039407
Epoch: 61 | Iteration number: [120/565] 21% | Training loss: 0.6924944058060646
Epoch: 61 | Iteration number: [130/565] 23% | Training loss: 0.6920230113542997
Epoch: 61 | Iteration number: [140/565] 24% | Training loss: 0.6916375700916563
Epoch: 61 | Iteration number: [150/565] 26% | Training loss: 0.6913125145435334
Epoch: 61 | Iteration number: [160/565] 28% | Training loss: 0.6910318456590175
Epoch: 61 | Iteration number: [170/565] 30% | Training loss: 0.6907815330168781
Epoch: 61 | Iteration number: [180/565] 31% | Training loss: 0.6905652771393458
Epoch: 61 | Iteration number: [190/565] 33% | Training loss: 0.6903633020426098
Epoch: 61 | Iteration number: [200/565] 35% | Training loss: 0.6901884660124779
Epoch: 61 | Iteration number: [210/565] 37% | Training loss: 0.69000865987369
Epoch: 61 | Iteration number: [220/565] 38% | Training loss: 0.6898320170966061
Epoch: 61 | Iteration number: [230/565] 40% | Training loss: 0.6896958558455758
Epoch: 61 | Iteration number: [240/565] 42% | Training loss: 0.6895788888136546
Epoch: 61 | Iteration number: [250/565] 44% | Training loss: 0.6894721570014953
Epoch: 61 | Iteration number: [260/565] 46% | Training loss: 0.6893827211398345
Epoch: 61 | Iteration number: [270/565] 47% | Training loss: 0.6892782429854075
Epoch: 61 | Iteration number: [280/565] 49% | Training loss: 0.6892000079154968
Epoch: 61 | Iteration number: [290/565] 51% | Training loss: 0.6891140876145199
Epoch: 61 | Iteration number: [300/565] 53% | Training loss: 0.6890315463145574
Epoch: 61 | Iteration number: [310/565] 54% | Training loss: 0.6889562451070355
Epoch: 61 | Iteration number: [320/565] 56% | Training loss: 0.6889036901295185
Epoch: 61 | Iteration number: [330/565] 58% | Training loss: 0.6888372049187169
Epoch: 61 | Iteration number: [340/565] 60% | Training loss: 0.6887865010429831
Epoch: 61 | Iteration number: [350/565] 61% | Training loss: 0.6887467331545694
Epoch: 61 | Iteration number: [360/565] 63% | Training loss: 0.6886933176053895
Epoch: 61 | Iteration number: [370/565] 65% | Training loss: 0.6886439455522073
Epoch: 61 | Iteration number: [380/565] 67% | Training loss: 0.6886020687065626
Epoch: 61 | Iteration number: [390/565] 69% | Training loss: 0.6885492434868445
Epoch: 61 | Iteration number: [400/565] 70% | Training loss: 0.6885152588784694
Epoch: 61 | Iteration number: [410/565] 72% | Training loss: 0.6884757896748984
Epoch: 61 | Iteration number: [420/565] 74% | Training loss: 0.6884468758390063
Epoch: 61 | Iteration number: [430/565] 76% | Training loss: 0.6884040998858075
Epoch: 61 | Iteration number: [440/565] 77% | Training loss: 0.688367501984943
Epoch: 61 | Iteration number: [450/565] 79% | Training loss: 0.6883386667569479
Epoch: 61 | Iteration number: [460/565] 81% | Training loss: 0.6882924354594687
Epoch: 61 | Iteration number: [470/565] 83% | Training loss: 0.6882572408686293
Epoch: 61 | Iteration number: [480/565] 84% | Training loss: 0.6882188177357117
Epoch: 61 | Iteration number: [490/565] 86% | Training loss: 0.6881923774067237
Epoch: 61 | Iteration number: [500/565] 88% | Training loss: 0.6881702563762665
Epoch: 61 | Iteration number: [510/565] 90% | Training loss: 0.6881498266668881
Epoch: 61 | Iteration number: [520/565] 92% | Training loss: 0.6881221901911956
Epoch: 61 | Iteration number: [530/565] 93% | Training loss: 0.6880981170906211
Epoch: 61 | Iteration number: [540/565] 95% | Training loss: 0.6880723188320795
Epoch: 61 | Iteration number: [550/565] 97% | Training loss: 0.6880496056513353
Epoch: 61 | Iteration number: [560/565] 99% | Training loss: 0.6880353056958743

 End of epoch: 61 | Train Loss: 0.6868069965227516 | Training Time: 90 

 End of epoch: 61 | Eval Loss: 0.689677357673645 | Evaluating Time: 6 
Epoch: 62 | Iteration number: [10/565] 1% | Training loss: 0.7550817430019379
Epoch: 62 | Iteration number: [20/565] 3% | Training loss: 0.7209822744131088
Epoch: 62 | Iteration number: [30/565] 5% | Training loss: 0.7096476356188456
Epoch: 62 | Iteration number: [40/565] 7% | Training loss: 0.7039889633655548
Epoch: 62 | Iteration number: [50/565] 8% | Training loss: 0.7005341303348541
Epoch: 62 | Iteration number: [60/565] 10% | Training loss: 0.6982450316349665
Epoch: 62 | Iteration number: [70/565] 12% | Training loss: 0.6966004601546696
Epoch: 62 | Iteration number: [80/565] 14% | Training loss: 0.6953802675008773
Epoch: 62 | Iteration number: [90/565] 15% | Training loss: 0.694378423028522
Epoch: 62 | Iteration number: [100/565] 17% | Training loss: 0.6936095350980759
Epoch: 62 | Iteration number: [110/565] 19% | Training loss: 0.6929975937713276
Epoch: 62 | Iteration number: [120/565] 21% | Training loss: 0.692465693751971
Epoch: 62 | Iteration number: [130/565] 23% | Training loss: 0.6920360702734727
Epoch: 62 | Iteration number: [140/565] 24% | Training loss: 0.6916744870798929
Epoch: 62 | Iteration number: [150/565] 26% | Training loss: 0.6913611328601837
Epoch: 62 | Iteration number: [160/565] 28% | Training loss: 0.6910649836063385
Epoch: 62 | Iteration number: [170/565] 30% | Training loss: 0.6908196056590361
Epoch: 62 | Iteration number: [180/565] 31% | Training loss: 0.6905808988544676
Epoch: 62 | Iteration number: [190/565] 33% | Training loss: 0.6903517788962314
Epoch: 62 | Iteration number: [200/565] 35% | Training loss: 0.6901589530706406
Epoch: 62 | Iteration number: [210/565] 37% | Training loss: 0.6899874227387565
Epoch: 62 | Iteration number: [220/565] 38% | Training loss: 0.6898329574953426
Epoch: 62 | Iteration number: [230/565] 40% | Training loss: 0.689711302259694
Epoch: 62 | Iteration number: [240/565] 42% | Training loss: 0.6896124541759491
Epoch: 62 | Iteration number: [250/565] 44% | Training loss: 0.6895113863945007
Epoch: 62 | Iteration number: [260/565] 46% | Training loss: 0.6894035467734704
Epoch: 62 | Iteration number: [270/565] 47% | Training loss: 0.6893188207237809
Epoch: 62 | Iteration number: [280/565] 49% | Training loss: 0.6892181813716889
Epoch: 62 | Iteration number: [290/565] 51% | Training loss: 0.6891480141672595
Epoch: 62 | Iteration number: [300/565] 53% | Training loss: 0.6890852707624435
Epoch: 62 | Iteration number: [310/565] 54% | Training loss: 0.6890123784542084
Epoch: 62 | Iteration number: [320/565] 56% | Training loss: 0.6889426939189434
Epoch: 62 | Iteration number: [330/565] 58% | Training loss: 0.6888732352040031
Epoch: 62 | Iteration number: [340/565] 60% | Training loss: 0.6888094321769827
Epoch: 62 | Iteration number: [350/565] 61% | Training loss: 0.6887402921063559
Epoch: 62 | Iteration number: [360/565] 63% | Training loss: 0.6886944482723872
Epoch: 62 | Iteration number: [370/565] 65% | Training loss: 0.6886394598999539
Epoch: 62 | Iteration number: [380/565] 67% | Training loss: 0.688602102743952
Epoch: 62 | Iteration number: [390/565] 69% | Training loss: 0.688544863768113
Epoch: 62 | Iteration number: [400/565] 70% | Training loss: 0.6885079614818096
Epoch: 62 | Iteration number: [410/565] 72% | Training loss: 0.6884575018068639
Epoch: 62 | Iteration number: [420/565] 74% | Training loss: 0.688431169305529
Epoch: 62 | Iteration number: [430/565] 76% | Training loss: 0.6883934923382693
Epoch: 62 | Iteration number: [440/565] 77% | Training loss: 0.688345203074542
Epoch: 62 | Iteration number: [450/565] 79% | Training loss: 0.6883134622044034
Epoch: 62 | Iteration number: [460/565] 81% | Training loss: 0.68828756964725
Epoch: 62 | Iteration number: [470/565] 83% | Training loss: 0.6882604155134647
Epoch: 62 | Iteration number: [480/565] 84% | Training loss: 0.6882377207279206
Epoch: 62 | Iteration number: [490/565] 86% | Training loss: 0.6882043479656687
Epoch: 62 | Iteration number: [500/565] 88% | Training loss: 0.6881799782514573
Epoch: 62 | Iteration number: [510/565] 90% | Training loss: 0.6881555627374089
Epoch: 62 | Iteration number: [520/565] 92% | Training loss: 0.6881240669351357
Epoch: 62 | Iteration number: [530/565] 93% | Training loss: 0.688092440929053
Epoch: 62 | Iteration number: [540/565] 95% | Training loss: 0.688069220383962
Epoch: 62 | Iteration number: [550/565] 97% | Training loss: 0.688046478358182
Epoch: 62 | Iteration number: [560/565] 99% | Training loss: 0.6880236136061805

 End of epoch: 62 | Train Loss: 0.6867942470364866 | Training Time: 90 

 End of epoch: 62 | Eval Loss: 0.690005464213235 | Evaluating Time: 6 
Epoch: 63 | Iteration number: [10/565] 1% | Training loss: 0.7555141985416413
Epoch: 63 | Iteration number: [20/565] 3% | Training loss: 0.7211080312728881
Epoch: 63 | Iteration number: [30/565] 5% | Training loss: 0.7097889264424642
Epoch: 63 | Iteration number: [40/565] 7% | Training loss: 0.7040673047304153
Epoch: 63 | Iteration number: [50/565] 8% | Training loss: 0.7005283927917481
Epoch: 63 | Iteration number: [60/565] 10% | Training loss: 0.6982578545808792
Epoch: 63 | Iteration number: [70/565] 12% | Training loss: 0.6966206329209464
Epoch: 63 | Iteration number: [80/565] 14% | Training loss: 0.6954601891338825
Epoch: 63 | Iteration number: [90/565] 15% | Training loss: 0.694520565536287
Epoch: 63 | Iteration number: [100/565] 17% | Training loss: 0.693688714504242
Epoch: 63 | Iteration number: [110/565] 19% | Training loss: 0.693025967207822
Epoch: 63 | Iteration number: [120/565] 21% | Training loss: 0.6924664710958799
Epoch: 63 | Iteration number: [130/565] 23% | Training loss: 0.6920213832305028
Epoch: 63 | Iteration number: [140/565] 24% | Training loss: 0.6916444642203194
Epoch: 63 | Iteration number: [150/565] 26% | Training loss: 0.6913253466288248
Epoch: 63 | Iteration number: [160/565] 28% | Training loss: 0.6910424306988716
Epoch: 63 | Iteration number: [170/565] 30% | Training loss: 0.6907827836625716
Epoch: 63 | Iteration number: [180/565] 31% | Training loss: 0.6905599951744079
Epoch: 63 | Iteration number: [190/565] 33% | Training loss: 0.6903447489989432
Epoch: 63 | Iteration number: [200/565] 35% | Training loss: 0.6901836678385734
Epoch: 63 | Iteration number: [210/565] 37% | Training loss: 0.6900391692206973
Epoch: 63 | Iteration number: [220/565] 38% | Training loss: 0.6898921337994662
Epoch: 63 | Iteration number: [230/565] 40% | Training loss: 0.6897775294988052
Epoch: 63 | Iteration number: [240/565] 42% | Training loss: 0.68964357872804
Epoch: 63 | Iteration number: [250/565] 44% | Training loss: 0.6895433378219604
Epoch: 63 | Iteration number: [260/565] 46% | Training loss: 0.6894338098856119
Epoch: 63 | Iteration number: [270/565] 47% | Training loss: 0.6893334600660536
Epoch: 63 | Iteration number: [280/565] 49% | Training loss: 0.6892374304788453
Epoch: 63 | Iteration number: [290/565] 51% | Training loss: 0.6891701414667327
Epoch: 63 | Iteration number: [300/565] 53% | Training loss: 0.6890851392348607
Epoch: 63 | Iteration number: [310/565] 54% | Training loss: 0.6890008722582172
Epoch: 63 | Iteration number: [320/565] 56% | Training loss: 0.6889364842325449
Epoch: 63 | Iteration number: [330/565] 58% | Training loss: 0.6888701659260374
Epoch: 63 | Iteration number: [340/565] 60% | Training loss: 0.6887991926249336
Epoch: 63 | Iteration number: [350/565] 61% | Training loss: 0.6887445170538766
Epoch: 63 | Iteration number: [360/565] 63% | Training loss: 0.6886850463019477
Epoch: 63 | Iteration number: [370/565] 65% | Training loss: 0.6886367308126914
Epoch: 63 | Iteration number: [380/565] 67% | Training loss: 0.6885873127924769
Epoch: 63 | Iteration number: [390/565] 69% | Training loss: 0.6885530062210865
Epoch: 63 | Iteration number: [400/565] 70% | Training loss: 0.6885081307590007
Epoch: 63 | Iteration number: [410/565] 72% | Training loss: 0.6884664518077199
Epoch: 63 | Iteration number: [420/565] 74% | Training loss: 0.6884363831508727
Epoch: 63 | Iteration number: [430/565] 76% | Training loss: 0.6884134759736615
Epoch: 63 | Iteration number: [440/565] 77% | Training loss: 0.6883805092085492
Epoch: 63 | Iteration number: [450/565] 79% | Training loss: 0.6883353397581312
Epoch: 63 | Iteration number: [460/565] 81% | Training loss: 0.688308464055476
Epoch: 63 | Iteration number: [470/565] 83% | Training loss: 0.6882781002115697
Epoch: 63 | Iteration number: [480/565] 84% | Training loss: 0.6882479254156351
Epoch: 63 | Iteration number: [490/565] 86% | Training loss: 0.6882196989594673
Epoch: 63 | Iteration number: [500/565] 88% | Training loss: 0.6881893029212952
Epoch: 63 | Iteration number: [510/565] 90% | Training loss: 0.6881611769105874
Epoch: 63 | Iteration number: [520/565] 92% | Training loss: 0.6881295925149551
Epoch: 63 | Iteration number: [530/565] 93% | Training loss: 0.6881080411515146
Epoch: 63 | Iteration number: [540/565] 95% | Training loss: 0.6880926745909232
Epoch: 63 | Iteration number: [550/565] 97% | Training loss: 0.6880690612576225
Epoch: 63 | Iteration number: [560/565] 99% | Training loss: 0.6880391677575451

 End of epoch: 63 | Train Loss: 0.6868062951923471 | Training Time: 90 

 End of epoch: 63 | Eval Loss: 0.6900807704244342 | Evaluating Time: 6 
Epoch: 64 | Iteration number: [10/565] 1% | Training loss: 0.7552172124385834
Epoch: 64 | Iteration number: [20/565] 3% | Training loss: 0.720862278342247
Epoch: 64 | Iteration number: [30/565] 5% | Training loss: 0.7095226526260376
Epoch: 64 | Iteration number: [40/565] 7% | Training loss: 0.7037556931376457
Epoch: 64 | Iteration number: [50/565] 8% | Training loss: 0.7003705275058746
Epoch: 64 | Iteration number: [60/565] 10% | Training loss: 0.6980747063954671
Epoch: 64 | Iteration number: [70/565] 12% | Training loss: 0.6964814169066292
Epoch: 64 | Iteration number: [80/565] 14% | Training loss: 0.6952648937702179
Epoch: 64 | Iteration number: [90/565] 15% | Training loss: 0.6943668312496609
Epoch: 64 | Iteration number: [100/565] 17% | Training loss: 0.6936164677143097
Epoch: 64 | Iteration number: [110/565] 19% | Training loss: 0.6930150980299169
Epoch: 64 | Iteration number: [120/565] 21% | Training loss: 0.692514938612779
Epoch: 64 | Iteration number: [130/565] 23% | Training loss: 0.6920661105559422
Epoch: 64 | Iteration number: [140/565] 24% | Training loss: 0.6917332934481757
Epoch: 64 | Iteration number: [150/565] 26% | Training loss: 0.6914183954397838
Epoch: 64 | Iteration number: [160/565] 28% | Training loss: 0.6911249130964279
Epoch: 64 | Iteration number: [170/565] 30% | Training loss: 0.6908910512924195
Epoch: 64 | Iteration number: [180/565] 31% | Training loss: 0.6906747877597809
Epoch: 64 | Iteration number: [190/565] 33% | Training loss: 0.6904543396673705
Epoch: 64 | Iteration number: [200/565] 35% | Training loss: 0.6902730992436409
Epoch: 64 | Iteration number: [210/565] 37% | Training loss: 0.6901027642545245
Epoch: 64 | Iteration number: [220/565] 38% | Training loss: 0.6899451014670459
Epoch: 64 | Iteration number: [230/565] 40% | Training loss: 0.6898062915905662
Epoch: 64 | Iteration number: [240/565] 42% | Training loss: 0.6896692919234435
Epoch: 64 | Iteration number: [250/565] 44% | Training loss: 0.689565813779831
Epoch: 64 | Iteration number: [260/565] 46% | Training loss: 0.6894590196701197
Epoch: 64 | Iteration number: [270/565] 47% | Training loss: 0.689363302345629
Epoch: 64 | Iteration number: [280/565] 49% | Training loss: 0.6892869406512805
Epoch: 64 | Iteration number: [290/565] 51% | Training loss: 0.6892093232993421
Epoch: 64 | Iteration number: [300/565] 53% | Training loss: 0.6891233259439469
Epoch: 64 | Iteration number: [310/565] 54% | Training loss: 0.6890396702674128
Epoch: 64 | Iteration number: [320/565] 56% | Training loss: 0.6889575811102986
Epoch: 64 | Iteration number: [330/565] 58% | Training loss: 0.688898104429245
Epoch: 64 | Iteration number: [340/565] 60% | Training loss: 0.688845957903301
Epoch: 64 | Iteration number: [350/565] 61% | Training loss: 0.688790409224374
Epoch: 64 | Iteration number: [360/565] 63% | Training loss: 0.68874182469315
Epoch: 64 | Iteration number: [370/565] 65% | Training loss: 0.6886857272805395
Epoch: 64 | Iteration number: [380/565] 67% | Training loss: 0.6886522998935298
Epoch: 64 | Iteration number: [390/565] 69% | Training loss: 0.6886067046568944
Epoch: 64 | Iteration number: [400/565] 70% | Training loss: 0.688549627661705
Epoch: 64 | Iteration number: [410/565] 72% | Training loss: 0.6884918875810576
Epoch: 64 | Iteration number: [420/565] 74% | Training loss: 0.688434474950745
Epoch: 64 | Iteration number: [430/565] 76% | Training loss: 0.6883990434713142
Epoch: 64 | Iteration number: [440/565] 77% | Training loss: 0.6883662926879797
Epoch: 64 | Iteration number: [450/565] 79% | Training loss: 0.6883306662241618
Epoch: 64 | Iteration number: [460/565] 81% | Training loss: 0.6882974607788999
Epoch: 64 | Iteration number: [470/565] 83% | Training loss: 0.6882699135770189
Epoch: 64 | Iteration number: [480/565] 84% | Training loss: 0.6882372566809257
Epoch: 64 | Iteration number: [490/565] 86% | Training loss: 0.6882076650249714
Epoch: 64 | Iteration number: [500/565] 88% | Training loss: 0.6881700012683868
Epoch: 64 | Iteration number: [510/565] 90% | Training loss: 0.6881385555454329
Epoch: 64 | Iteration number: [520/565] 92% | Training loss: 0.6881181292808973
Epoch: 64 | Iteration number: [530/565] 93% | Training loss: 0.6880923075496026
Epoch: 64 | Iteration number: [540/565] 95% | Training loss: 0.6880734358672742
Epoch: 64 | Iteration number: [550/565] 97% | Training loss: 0.6880539157173851
Epoch: 64 | Iteration number: [560/565] 99% | Training loss: 0.6880287942077432

 End of epoch: 64 | Train Loss: 0.6867948412895203 | Training Time: 88 

 End of epoch: 64 | Eval Loss: 0.6903050541877747 | Evaluating Time: 6 
Epoch: 65 | Iteration number: [10/565] 1% | Training loss: 0.7551247119903565
Epoch: 65 | Iteration number: [20/565] 3% | Training loss: 0.7210557639598847
Epoch: 65 | Iteration number: [30/565] 5% | Training loss: 0.709633606672287
Epoch: 65 | Iteration number: [40/565] 7% | Training loss: 0.7038751438260078
Epoch: 65 | Iteration number: [50/565] 8% | Training loss: 0.7004979681968689
Epoch: 65 | Iteration number: [60/565] 10% | Training loss: 0.698286019762357
Epoch: 65 | Iteration number: [70/565] 12% | Training loss: 0.6966813828263964
Epoch: 65 | Iteration number: [80/565] 14% | Training loss: 0.6954769112169743
Epoch: 65 | Iteration number: [90/565] 15% | Training loss: 0.694484900103675
Epoch: 65 | Iteration number: [100/565] 17% | Training loss: 0.6937138426303864
Epoch: 65 | Iteration number: [110/565] 19% | Training loss: 0.6930639830502596
Epoch: 65 | Iteration number: [120/565] 21% | Training loss: 0.6925546278556188
Epoch: 65 | Iteration number: [130/565] 23% | Training loss: 0.6920771530041328
Epoch: 65 | Iteration number: [140/565] 24% | Training loss: 0.6916982591152191
Epoch: 65 | Iteration number: [150/565] 26% | Training loss: 0.6913586735725403
Epoch: 65 | Iteration number: [160/565] 28% | Training loss: 0.6910616904497147
Epoch: 65 | Iteration number: [170/565] 30% | Training loss: 0.6908289232674767
Epoch: 65 | Iteration number: [180/565] 31% | Training loss: 0.6906022446023093
Epoch: 65 | Iteration number: [190/565] 33% | Training loss: 0.690372843177695
Epoch: 65 | Iteration number: [200/565] 35% | Training loss: 0.6902068462967873
Epoch: 65 | Iteration number: [210/565] 37% | Training loss: 0.6900681478636606
Epoch: 65 | Iteration number: [220/565] 38% | Training loss: 0.6899224855683067
Epoch: 65 | Iteration number: [230/565] 40% | Training loss: 0.6897989358590997
Epoch: 65 | Iteration number: [240/565] 42% | Training loss: 0.6896939526001612
Epoch: 65 | Iteration number: [250/565] 44% | Training loss: 0.6895833389759064
Epoch: 65 | Iteration number: [260/565] 46% | Training loss: 0.6894567434604352
Epoch: 65 | Iteration number: [270/565] 47% | Training loss: 0.6893569986025493
Epoch: 65 | Iteration number: [280/565] 49% | Training loss: 0.6892576858401298
Epoch: 65 | Iteration number: [290/565] 51% | Training loss: 0.6891734717221095
Epoch: 65 | Iteration number: [300/565] 53% | Training loss: 0.6890885875622431
Epoch: 65 | Iteration number: [310/565] 54% | Training loss: 0.6889983709781401
Epoch: 65 | Iteration number: [320/565] 56% | Training loss: 0.6889084283262491
Epoch: 65 | Iteration number: [330/565] 58% | Training loss: 0.6888471363168774
Epoch: 65 | Iteration number: [340/565] 60% | Training loss: 0.6887858075254104
Epoch: 65 | Iteration number: [350/565] 61% | Training loss: 0.6887303297860282
Epoch: 65 | Iteration number: [360/565] 63% | Training loss: 0.6886742146478759
Epoch: 65 | Iteration number: [370/565] 65% | Training loss: 0.6886276678459065
Epoch: 65 | Iteration number: [380/565] 67% | Training loss: 0.6885813777384006
Epoch: 65 | Iteration number: [390/565] 69% | Training loss: 0.688531956458703
Epoch: 65 | Iteration number: [400/565] 70% | Training loss: 0.6884903585910798
Epoch: 65 | Iteration number: [410/565] 72% | Training loss: 0.6884458543323889
Epoch: 65 | Iteration number: [420/565] 74% | Training loss: 0.6884054078942253
Epoch: 65 | Iteration number: [430/565] 76% | Training loss: 0.6883752590002016
Epoch: 65 | Iteration number: [440/565] 77% | Training loss: 0.6883356095715003
Epoch: 65 | Iteration number: [450/565] 79% | Training loss: 0.6882915478282504
Epoch: 65 | Iteration number: [460/565] 81% | Training loss: 0.6882574001084203
Epoch: 65 | Iteration number: [470/565] 83% | Training loss: 0.6882337694472455
Epoch: 65 | Iteration number: [480/565] 84% | Training loss: 0.6882070531447728
Epoch: 65 | Iteration number: [490/565] 86% | Training loss: 0.6881860863189309
Epoch: 65 | Iteration number: [500/565] 88% | Training loss: 0.6881709080934525
Epoch: 65 | Iteration number: [510/565] 90% | Training loss: 0.688142135330275
Epoch: 65 | Iteration number: [520/565] 92% | Training loss: 0.6881141396669241
Epoch: 65 | Iteration number: [530/565] 93% | Training loss: 0.6880934881714155
Epoch: 65 | Iteration number: [540/565] 95% | Training loss: 0.6880746413160254
Epoch: 65 | Iteration number: [550/565] 97% | Training loss: 0.6880457305908203
Epoch: 65 | Iteration number: [560/565] 99% | Training loss: 0.6880230269261769

 End of epoch: 65 | Train Loss: 0.6867920201436608 | Training Time: 90 

 End of epoch: 65 | Eval Loss: 0.6897722142083305 | Evaluating Time: 5 
Epoch: 66 | Iteration number: [10/565] 1% | Training loss: 0.7557362794876099
Epoch: 66 | Iteration number: [20/565] 3% | Training loss: 0.7213176995515823
Epoch: 66 | Iteration number: [30/565] 5% | Training loss: 0.7097062607606252
Epoch: 66 | Iteration number: [40/565] 7% | Training loss: 0.7038802295923233
Epoch: 66 | Iteration number: [50/565] 8% | Training loss: 0.7005291414260865
Epoch: 66 | Iteration number: [60/565] 10% | Training loss: 0.6982639183600744
Epoch: 66 | Iteration number: [70/565] 12% | Training loss: 0.6965948794569288
Epoch: 66 | Iteration number: [80/565] 14% | Training loss: 0.6953707449138165
Epoch: 66 | Iteration number: [90/565] 15% | Training loss: 0.6944008323881361
Epoch: 66 | Iteration number: [100/565] 17% | Training loss: 0.693627217411995
Epoch: 66 | Iteration number: [110/565] 19% | Training loss: 0.6929831363938072
Epoch: 66 | Iteration number: [120/565] 21% | Training loss: 0.6924711460868518
Epoch: 66 | Iteration number: [130/565] 23% | Training loss: 0.6920442572006813
Epoch: 66 | Iteration number: [140/565] 24% | Training loss: 0.6916285323245185
Epoch: 66 | Iteration number: [150/565] 26% | Training loss: 0.6913144997755687
Epoch: 66 | Iteration number: [160/565] 28% | Training loss: 0.6910447426140308
Epoch: 66 | Iteration number: [170/565] 30% | Training loss: 0.6908150855232688
Epoch: 66 | Iteration number: [180/565] 31% | Training loss: 0.6906037555800544
Epoch: 66 | Iteration number: [190/565] 33% | Training loss: 0.690374617827566
Epoch: 66 | Iteration number: [200/565] 35% | Training loss: 0.6902022537589073
Epoch: 66 | Iteration number: [210/565] 37% | Training loss: 0.6900300179209028
Epoch: 66 | Iteration number: [220/565] 38% | Training loss: 0.6898701933297244
Epoch: 66 | Iteration number: [230/565] 40% | Training loss: 0.6897575401741526
Epoch: 66 | Iteration number: [240/565] 42% | Training loss: 0.6896353853245576
Epoch: 66 | Iteration number: [250/565] 44% | Training loss: 0.6895217306613922
Epoch: 66 | Iteration number: [260/565] 46% | Training loss: 0.6894006486122425
Epoch: 66 | Iteration number: [270/565] 47% | Training loss: 0.6892901674464896
Epoch: 66 | Iteration number: [280/565] 49% | Training loss: 0.6891982246722493
Epoch: 66 | Iteration number: [290/565] 51% | Training loss: 0.6891352735716721
Epoch: 66 | Iteration number: [300/565] 53% | Training loss: 0.6890603890021642
Epoch: 66 | Iteration number: [310/565] 54% | Training loss: 0.6890042224237996
Epoch: 66 | Iteration number: [320/565] 56% | Training loss: 0.6889390856027603
Epoch: 66 | Iteration number: [330/565] 58% | Training loss: 0.688869817871036
Epoch: 66 | Iteration number: [340/565] 60% | Training loss: 0.6888063613106222
Epoch: 66 | Iteration number: [350/565] 61% | Training loss: 0.6887497411455427
Epoch: 66 | Iteration number: [360/565] 63% | Training loss: 0.6886963792973094
Epoch: 66 | Iteration number: [370/565] 65% | Training loss: 0.6886590783660477
Epoch: 66 | Iteration number: [380/565] 67% | Training loss: 0.6886002763321525
Epoch: 66 | Iteration number: [390/565] 69% | Training loss: 0.688547724332565
Epoch: 66 | Iteration number: [400/565] 70% | Training loss: 0.6885087394714355
Epoch: 66 | Iteration number: [410/565] 72% | Training loss: 0.6884680425248495
Epoch: 66 | Iteration number: [420/565] 74% | Training loss: 0.688427580680166
Epoch: 66 | Iteration number: [430/565] 76% | Training loss: 0.6883942465449489
Epoch: 66 | Iteration number: [440/565] 77% | Training loss: 0.6883535424416716
Epoch: 66 | Iteration number: [450/565] 79% | Training loss: 0.6883225084675683
Epoch: 66 | Iteration number: [460/565] 81% | Training loss: 0.6882745144159897
Epoch: 66 | Iteration number: [470/565] 83% | Training loss: 0.688244640193087
Epoch: 66 | Iteration number: [480/565] 84% | Training loss: 0.6882091692338387
Epoch: 66 | Iteration number: [490/565] 86% | Training loss: 0.688184031783318
Epoch: 66 | Iteration number: [500/565] 88% | Training loss: 0.6881616253852845
Epoch: 66 | Iteration number: [510/565] 90% | Training loss: 0.6881368139210869
Epoch: 66 | Iteration number: [520/565] 92% | Training loss: 0.6881108741347607
Epoch: 66 | Iteration number: [530/565] 93% | Training loss: 0.6880839387200913
Epoch: 66 | Iteration number: [540/565] 95% | Training loss: 0.6880546023448308
Epoch: 66 | Iteration number: [550/565] 97% | Training loss: 0.6880422977967696
Epoch: 66 | Iteration number: [560/565] 99% | Training loss: 0.6880256673055035

 End of epoch: 66 | Train Loss: 0.6868005621749743 | Training Time: 88 

 End of epoch: 66 | Eval Loss: 0.689958495753152 | Evaluating Time: 6 
Epoch: 67 | Iteration number: [10/565] 1% | Training loss: 0.7549945831298828
Epoch: 67 | Iteration number: [20/565] 3% | Training loss: 0.7209319353103638
Epoch: 67 | Iteration number: [30/565] 5% | Training loss: 0.7095734059810639
Epoch: 67 | Iteration number: [40/565] 7% | Training loss: 0.703837601840496
Epoch: 67 | Iteration number: [50/565] 8% | Training loss: 0.7004652523994446
Epoch: 67 | Iteration number: [60/565] 10% | Training loss: 0.6981011897325515
Epoch: 67 | Iteration number: [70/565] 12% | Training loss: 0.6964759588241577
Epoch: 67 | Iteration number: [80/565] 14% | Training loss: 0.6952680304646492
Epoch: 67 | Iteration number: [90/565] 15% | Training loss: 0.6944074392318725
Epoch: 67 | Iteration number: [100/565] 17% | Training loss: 0.6936002808809281
Epoch: 67 | Iteration number: [110/565] 19% | Training loss: 0.692971472306685
Epoch: 67 | Iteration number: [120/565] 21% | Training loss: 0.6924752692381541
Epoch: 67 | Iteration number: [130/565] 23% | Training loss: 0.6920620409341959
Epoch: 67 | Iteration number: [140/565] 24% | Training loss: 0.6916639736720493
Epoch: 67 | Iteration number: [150/565] 26% | Training loss: 0.6913402795791626
Epoch: 67 | Iteration number: [160/565] 28% | Training loss: 0.6910468805581331
Epoch: 67 | Iteration number: [170/565] 30% | Training loss: 0.6908150069853839
Epoch: 67 | Iteration number: [180/565] 31% | Training loss: 0.6905759390857484
Epoch: 67 | Iteration number: [190/565] 33% | Training loss: 0.6903818117944818
Epoch: 67 | Iteration number: [200/565] 35% | Training loss: 0.690194445848465
Epoch: 67 | Iteration number: [210/565] 37% | Training loss: 0.6900241599196479
Epoch: 67 | Iteration number: [220/565] 38% | Training loss: 0.6898683504624801
Epoch: 67 | Iteration number: [230/565] 40% | Training loss: 0.6897456666697627
Epoch: 67 | Iteration number: [240/565] 42% | Training loss: 0.689638452976942
Epoch: 67 | Iteration number: [250/565] 44% | Training loss: 0.6895217654705048
Epoch: 67 | Iteration number: [260/565] 46% | Training loss: 0.6894045994831965
Epoch: 67 | Iteration number: [270/565] 47% | Training loss: 0.6893193004307924
Epoch: 67 | Iteration number: [280/565] 49% | Training loss: 0.6892502816660063
Epoch: 67 | Iteration number: [290/565] 51% | Training loss: 0.6891730657939253
Epoch: 67 | Iteration number: [300/565] 53% | Training loss: 0.6891106690963109
Epoch: 67 | Iteration number: [310/565] 54% | Training loss: 0.6890331001051011
Epoch: 67 | Iteration number: [320/565] 56% | Training loss: 0.6889607774093747
Epoch: 67 | Iteration number: [330/565] 58% | Training loss: 0.6888779510151256
Epoch: 67 | Iteration number: [340/565] 60% | Training loss: 0.688811507821083
Epoch: 67 | Iteration number: [350/565] 61% | Training loss: 0.6887529594557625
Epoch: 67 | Iteration number: [360/565] 63% | Training loss: 0.688703081674046
Epoch: 67 | Iteration number: [370/565] 65% | Training loss: 0.6886616764841853
Epoch: 67 | Iteration number: [380/565] 67% | Training loss: 0.6886221714709935
Epoch: 67 | Iteration number: [390/565] 69% | Training loss: 0.6885719930514311
Epoch: 67 | Iteration number: [400/565] 70% | Training loss: 0.6885290366411209
Epoch: 67 | Iteration number: [410/565] 72% | Training loss: 0.6884749935894477
Epoch: 67 | Iteration number: [420/565] 74% | Training loss: 0.6884428386177336
Epoch: 67 | Iteration number: [430/565] 76% | Training loss: 0.6883955861246863
Epoch: 67 | Iteration number: [440/565] 77% | Training loss: 0.6883625007488511
Epoch: 67 | Iteration number: [450/565] 79% | Training loss: 0.6883248946401808
Epoch: 67 | Iteration number: [460/565] 81% | Training loss: 0.6882890024910803
Epoch: 67 | Iteration number: [470/565] 83% | Training loss: 0.6882584786161463
Epoch: 67 | Iteration number: [480/565] 84% | Training loss: 0.6882245422651371
Epoch: 67 | Iteration number: [490/565] 86% | Training loss: 0.6881939784604676
Epoch: 67 | Iteration number: [500/565] 88% | Training loss: 0.6881608171463013
Epoch: 67 | Iteration number: [510/565] 90% | Training loss: 0.6881364193617129
Epoch: 67 | Iteration number: [520/565] 92% | Training loss: 0.6881123945116997
Epoch: 67 | Iteration number: [530/565] 93% | Training loss: 0.6880841378895741
Epoch: 67 | Iteration number: [540/565] 95% | Training loss: 0.6880616229993326
Epoch: 67 | Iteration number: [550/565] 97% | Training loss: 0.6880397825891321
Epoch: 67 | Iteration number: [560/565] 99% | Training loss: 0.688020467545305

 End of epoch: 67 | Train Loss: 0.6867990637247541 | Training Time: 90 

 End of epoch: 67 | Eval Loss: 0.6894155485289437 | Evaluating Time: 6 
Epoch: 68 | Iteration number: [10/565] 1% | Training loss: 0.7550539493560791
Epoch: 68 | Iteration number: [20/565] 3% | Training loss: 0.7209347605705261
Epoch: 68 | Iteration number: [30/565] 5% | Training loss: 0.7097487111886343
Epoch: 68 | Iteration number: [40/565] 7% | Training loss: 0.7039099663496018
Epoch: 68 | Iteration number: [50/565] 8% | Training loss: 0.7005266606807709
Epoch: 68 | Iteration number: [60/565] 10% | Training loss: 0.6981973459323247
Epoch: 68 | Iteration number: [70/565] 12% | Training loss: 0.6966241811003003
Epoch: 68 | Iteration number: [80/565] 14% | Training loss: 0.6953688949346543
Epoch: 68 | Iteration number: [90/565] 15% | Training loss: 0.6944481492042541
Epoch: 68 | Iteration number: [100/565] 17% | Training loss: 0.6936770516633988
Epoch: 68 | Iteration number: [110/565] 19% | Training loss: 0.6930097542025826
Epoch: 68 | Iteration number: [120/565] 21% | Training loss: 0.6924978777766228
Epoch: 68 | Iteration number: [130/565] 23% | Training loss: 0.6920614132514367
Epoch: 68 | Iteration number: [140/565] 24% | Training loss: 0.6916970508439201
Epoch: 68 | Iteration number: [150/565] 26% | Training loss: 0.6913549057642618
Epoch: 68 | Iteration number: [160/565] 28% | Training loss: 0.6910755135118961
Epoch: 68 | Iteration number: [170/565] 30% | Training loss: 0.6908358412630418
Epoch: 68 | Iteration number: [180/565] 31% | Training loss: 0.6906235800849067
Epoch: 68 | Iteration number: [190/565] 33% | Training loss: 0.6904330507705086
Epoch: 68 | Iteration number: [200/565] 35% | Training loss: 0.6902690932154656
Epoch: 68 | Iteration number: [210/565] 37% | Training loss: 0.6900990190960112
Epoch: 68 | Iteration number: [220/565] 38% | Training loss: 0.6899381480433724
Epoch: 68 | Iteration number: [230/565] 40% | Training loss: 0.6897808994935907
Epoch: 68 | Iteration number: [240/565] 42% | Training loss: 0.6896614022552967
Epoch: 68 | Iteration number: [250/565] 44% | Training loss: 0.6895342972278595
Epoch: 68 | Iteration number: [260/565] 46% | Training loss: 0.6894218956048672
Epoch: 68 | Iteration number: [270/565] 47% | Training loss: 0.6893184558109001
Epoch: 68 | Iteration number: [280/565] 49% | Training loss: 0.6892375269106457
Epoch: 68 | Iteration number: [290/565] 51% | Training loss: 0.6891404343062434
Epoch: 68 | Iteration number: [300/565] 53% | Training loss: 0.6890742232402166
Epoch: 68 | Iteration number: [310/565] 54% | Training loss: 0.6890025632996712
Epoch: 68 | Iteration number: [320/565] 56% | Training loss: 0.6889250438660384
Epoch: 68 | Iteration number: [330/565] 58% | Training loss: 0.6888675866704999
Epoch: 68 | Iteration number: [340/565] 60% | Training loss: 0.6888125928009258
Epoch: 68 | Iteration number: [350/565] 61% | Training loss: 0.6887592230524335
Epoch: 68 | Iteration number: [360/565] 63% | Training loss: 0.688702958325545
Epoch: 68 | Iteration number: [370/565] 65% | Training loss: 0.6886643095596416
Epoch: 68 | Iteration number: [380/565] 67% | Training loss: 0.688607879532011
Epoch: 68 | Iteration number: [390/565] 69% | Training loss: 0.6885571007545178
Epoch: 68 | Iteration number: [400/565] 70% | Training loss: 0.6885136944055558
Epoch: 68 | Iteration number: [410/565] 72% | Training loss: 0.688467945703646
Epoch: 68 | Iteration number: [420/565] 74% | Training loss: 0.6884291414703642
Epoch: 68 | Iteration number: [430/565] 76% | Training loss: 0.6883899665156076
Epoch: 68 | Iteration number: [440/565] 77% | Training loss: 0.6883531418713656
Epoch: 68 | Iteration number: [450/565] 79% | Training loss: 0.6883134798208872
Epoch: 68 | Iteration number: [460/565] 81% | Training loss: 0.6882708291644636
Epoch: 68 | Iteration number: [470/565] 83% | Training loss: 0.6882428629601255
Epoch: 68 | Iteration number: [480/565] 84% | Training loss: 0.6882108074923357
Epoch: 68 | Iteration number: [490/565] 86% | Training loss: 0.6881838987068254
Epoch: 68 | Iteration number: [500/565] 88% | Training loss: 0.6881611334085465
Epoch: 68 | Iteration number: [510/565] 90% | Training loss: 0.6881309607449699
Epoch: 68 | Iteration number: [520/565] 92% | Training loss: 0.6881115274933668
Epoch: 68 | Iteration number: [530/565] 93% | Training loss: 0.6880995489516348
Epoch: 68 | Iteration number: [540/565] 95% | Training loss: 0.6880656254512293
Epoch: 68 | Iteration number: [550/565] 97% | Training loss: 0.6880439471114765
Epoch: 68 | Iteration number: [560/565] 99% | Training loss: 0.6880157733602184

 End of epoch: 68 | Train Loss: 0.6867908007275741 | Training Time: 90 

 End of epoch: 68 | Eval Loss: 0.6903296964509147 | Evaluating Time: 6 
Epoch: 69 | Iteration number: [10/565] 1% | Training loss: 0.7555055558681488
Epoch: 69 | Iteration number: [20/565] 3% | Training loss: 0.7211217045783996
Epoch: 69 | Iteration number: [30/565] 5% | Training loss: 0.7095690071582794
Epoch: 69 | Iteration number: [40/565] 7% | Training loss: 0.7039548084139824
Epoch: 69 | Iteration number: [50/565] 8% | Training loss: 0.7005679059028626
Epoch: 69 | Iteration number: [60/565] 10% | Training loss: 0.6983094255129496
Epoch: 69 | Iteration number: [70/565] 12% | Training loss: 0.6967001404081072
Epoch: 69 | Iteration number: [80/565] 14% | Training loss: 0.6954170115292072
Epoch: 69 | Iteration number: [90/565] 15% | Training loss: 0.6944035172462464
Epoch: 69 | Iteration number: [100/565] 17% | Training loss: 0.693648327589035
Epoch: 69 | Iteration number: [110/565] 19% | Training loss: 0.6930457055568695
Epoch: 69 | Iteration number: [120/565] 21% | Training loss: 0.6925238564610481
Epoch: 69 | Iteration number: [130/565] 23% | Training loss: 0.6921210366946
Epoch: 69 | Iteration number: [140/565] 24% | Training loss: 0.6917792750256402
Epoch: 69 | Iteration number: [150/565] 26% | Training loss: 0.6914119533697765
Epoch: 69 | Iteration number: [160/565] 28% | Training loss: 0.6911340210586786
Epoch: 69 | Iteration number: [170/565] 30% | Training loss: 0.6908602114985971
Epoch: 69 | Iteration number: [180/565] 31% | Training loss: 0.6906232158342998
Epoch: 69 | Iteration number: [190/565] 33% | Training loss: 0.6904067500641472
Epoch: 69 | Iteration number: [200/565] 35% | Training loss: 0.6901887804269791
Epoch: 69 | Iteration number: [210/565] 37% | Training loss: 0.6900315020765577
Epoch: 69 | Iteration number: [220/565] 38% | Training loss: 0.6898910728367892
Epoch: 69 | Iteration number: [230/565] 40% | Training loss: 0.6897365917330203
Epoch: 69 | Iteration number: [240/565] 42% | Training loss: 0.6896150762836138
Epoch: 69 | Iteration number: [250/565] 44% | Training loss: 0.6895045304298401
Epoch: 69 | Iteration number: [260/565] 46% | Training loss: 0.6893921102468784
Epoch: 69 | Iteration number: [270/565] 47% | Training loss: 0.6893060785752756
Epoch: 69 | Iteration number: [280/565] 49% | Training loss: 0.6892103710344859
Epoch: 69 | Iteration number: [290/565] 51% | Training loss: 0.6891381611084116
Epoch: 69 | Iteration number: [300/565] 53% | Training loss: 0.6890754771232604
Epoch: 69 | Iteration number: [310/565] 54% | Training loss: 0.6889762101634856
Epoch: 69 | Iteration number: [320/565] 56% | Training loss: 0.6889154022559524
Epoch: 69 | Iteration number: [330/565] 58% | Training loss: 0.6888496561483903
Epoch: 69 | Iteration number: [340/565] 60% | Training loss: 0.6887698518879274
Epoch: 69 | Iteration number: [350/565] 61% | Training loss: 0.68870375088283
Epoch: 69 | Iteration number: [360/565] 63% | Training loss: 0.6886393103334639
Epoch: 69 | Iteration number: [370/565] 65% | Training loss: 0.6885904582771095
Epoch: 69 | Iteration number: [380/565] 67% | Training loss: 0.6885383566743449
Epoch: 69 | Iteration number: [390/565] 69% | Training loss: 0.6884974728792141
Epoch: 69 | Iteration number: [400/565] 70% | Training loss: 0.6884462136030197
Epoch: 69 | Iteration number: [410/565] 72% | Training loss: 0.6884032679767144
Epoch: 69 | Iteration number: [420/565] 74% | Training loss: 0.6883670064665023
Epoch: 69 | Iteration number: [430/565] 76% | Training loss: 0.6883409606855969
Epoch: 69 | Iteration number: [440/565] 77% | Training loss: 0.6882986147295345
Epoch: 69 | Iteration number: [450/565] 79% | Training loss: 0.6882716749774085
Epoch: 69 | Iteration number: [460/565] 81% | Training loss: 0.6882486544225527
Epoch: 69 | Iteration number: [470/565] 83% | Training loss: 0.6882148489038995
Epoch: 69 | Iteration number: [480/565] 84% | Training loss: 0.6881799458215634
Epoch: 69 | Iteration number: [490/565] 86% | Training loss: 0.6881614862656107
Epoch: 69 | Iteration number: [500/565] 88% | Training loss: 0.6881308733224869
Epoch: 69 | Iteration number: [510/565] 90% | Training loss: 0.68811028973729
Epoch: 69 | Iteration number: [520/565] 92% | Training loss: 0.6880871370434761
Epoch: 69 | Iteration number: [530/565] 93% | Training loss: 0.6880729468363636
Epoch: 69 | Iteration number: [540/565] 95% | Training loss: 0.6880528482022109
Epoch: 69 | Iteration number: [550/565] 97% | Training loss: 0.6880302932045677
Epoch: 69 | Iteration number: [560/565] 99% | Training loss: 0.6880113597427095

 End of epoch: 69 | Train Loss: 0.6867848029178856 | Training Time: 89 

 End of epoch: 69 | Eval Loss: 0.6902091673442295 | Evaluating Time: 6 
Epoch: 70 | Iteration number: [10/565] 1% | Training loss: 0.7553671002388
Epoch: 70 | Iteration number: [20/565] 3% | Training loss: 0.721325159072876
Epoch: 70 | Iteration number: [30/565] 5% | Training loss: 0.7097099681695302
Epoch: 70 | Iteration number: [40/565] 7% | Training loss: 0.7040390476584435
Epoch: 70 | Iteration number: [50/565] 8% | Training loss: 0.7006308770179749
Epoch: 70 | Iteration number: [60/565] 10% | Training loss: 0.6983165830373764
Epoch: 70 | Iteration number: [70/565] 12% | Training loss: 0.6966845955167498
Epoch: 70 | Iteration number: [80/565] 14% | Training loss: 0.6954396098852158
Epoch: 70 | Iteration number: [90/565] 15% | Training loss: 0.6944363686773513
Epoch: 70 | Iteration number: [100/565] 17% | Training loss: 0.6937078166007996
Epoch: 70 | Iteration number: [110/565] 19% | Training loss: 0.6930946409702301
Epoch: 70 | Iteration number: [120/565] 21% | Training loss: 0.6926142086585363
Epoch: 70 | Iteration number: [130/565] 23% | Training loss: 0.6921906122794518
Epoch: 70 | Iteration number: [140/565] 24% | Training loss: 0.6918059936591557
Epoch: 70 | Iteration number: [150/565] 26% | Training loss: 0.6914553447564443
Epoch: 70 | Iteration number: [160/565] 28% | Training loss: 0.6911598417907954
Epoch: 70 | Iteration number: [170/565] 30% | Training loss: 0.6909222907879773
Epoch: 70 | Iteration number: [180/565] 31% | Training loss: 0.6906815270582835
Epoch: 70 | Iteration number: [190/565] 33% | Training loss: 0.690466930991725
Epoch: 70 | Iteration number: [200/565] 35% | Training loss: 0.6902745413780212
Epoch: 70 | Iteration number: [210/565] 37% | Training loss: 0.6900800651028043
Epoch: 70 | Iteration number: [220/565] 38% | Training loss: 0.6899379353631626
Epoch: 70 | Iteration number: [230/565] 40% | Training loss: 0.6897975794647051
Epoch: 70 | Iteration number: [240/565] 42% | Training loss: 0.6896752424538135
Epoch: 70 | Iteration number: [250/565] 44% | Training loss: 0.6895557489395142
Epoch: 70 | Iteration number: [260/565] 46% | Training loss: 0.6894506305456162
Epoch: 70 | Iteration number: [270/565] 47% | Training loss: 0.6893577809687014
Epoch: 70 | Iteration number: [280/565] 49% | Training loss: 0.6892836010881833
Epoch: 70 | Iteration number: [290/565] 51% | Training loss: 0.6892050985632272
Epoch: 70 | Iteration number: [300/565] 53% | Training loss: 0.6891185094912847
Epoch: 70 | Iteration number: [310/565] 54% | Training loss: 0.68905402844952
Epoch: 70 | Iteration number: [320/565] 56% | Training loss: 0.688979372754693
Epoch: 70 | Iteration number: [330/565] 58% | Training loss: 0.6889035475976539
Epoch: 70 | Iteration number: [340/565] 60% | Training loss: 0.6888291856821845
Epoch: 70 | Iteration number: [350/565] 61% | Training loss: 0.688760529245649
Epoch: 70 | Iteration number: [360/565] 63% | Training loss: 0.688716639081637
Epoch: 70 | Iteration number: [370/565] 65% | Training loss: 0.6886570038022222
Epoch: 70 | Iteration number: [380/565] 67% | Training loss: 0.6886060168868617
Epoch: 70 | Iteration number: [390/565] 69% | Training loss: 0.6885446649331313
Epoch: 70 | Iteration number: [400/565] 70% | Training loss: 0.6884949840605259
Epoch: 70 | Iteration number: [410/565] 72% | Training loss: 0.688455304285375
Epoch: 70 | Iteration number: [420/565] 74% | Training loss: 0.6884107690481912
Epoch: 70 | Iteration number: [430/565] 76% | Training loss: 0.6883645179659821
Epoch: 70 | Iteration number: [440/565] 77% | Training loss: 0.6883395984768867
Epoch: 70 | Iteration number: [450/565] 79% | Training loss: 0.6883035459783342
Epoch: 70 | Iteration number: [460/565] 81% | Training loss: 0.6882751760275467
Epoch: 70 | Iteration number: [470/565] 83% | Training loss: 0.6882407728661882
Epoch: 70 | Iteration number: [480/565] 84% | Training loss: 0.6882080300400655
Epoch: 70 | Iteration number: [490/565] 86% | Training loss: 0.6881744685221691
Epoch: 70 | Iteration number: [500/565] 88% | Training loss: 0.6881476376056671
Epoch: 70 | Iteration number: [510/565] 90% | Training loss: 0.6881234324445912
Epoch: 70 | Iteration number: [520/565] 92% | Training loss: 0.6880991792449584
Epoch: 70 | Iteration number: [530/565] 93% | Training loss: 0.6880803987664996
Epoch: 70 | Iteration number: [540/565] 95% | Training loss: 0.6880600104729334
Epoch: 70 | Iteration number: [550/565] 97% | Training loss: 0.6880382930148732
Epoch: 70 | Iteration number: [560/565] 99% | Training loss: 0.6880114274365562

 End of epoch: 70 | Train Loss: 0.6867836491196556 | Training Time: 88 

 End of epoch: 70 | Eval Loss: 0.6897378649030413 | Evaluating Time: 6 
Epoch: 71 | Iteration number: [10/565] 1% | Training loss: 0.7558215022087097
Epoch: 71 | Iteration number: [20/565] 3% | Training loss: 0.7215524435043335
Epoch: 71 | Iteration number: [30/565] 5% | Training loss: 0.7099343578020731
Epoch: 71 | Iteration number: [40/565] 7% | Training loss: 0.7041686668992042
Epoch: 71 | Iteration number: [50/565] 8% | Training loss: 0.7007533371448517
Epoch: 71 | Iteration number: [60/565] 10% | Training loss: 0.6983970155318578
Epoch: 71 | Iteration number: [70/565] 12% | Training loss: 0.6966669985226223
Epoch: 71 | Iteration number: [80/565] 14% | Training loss: 0.6954730235040187
Epoch: 71 | Iteration number: [90/565] 15% | Training loss: 0.6944856623808543
Epoch: 71 | Iteration number: [100/565] 17% | Training loss: 0.6937169843912124
Epoch: 71 | Iteration number: [110/565] 19% | Training loss: 0.6931025705554269
Epoch: 71 | Iteration number: [120/565] 21% | Training loss: 0.692547174791495
Epoch: 71 | Iteration number: [130/565] 23% | Training loss: 0.6920970843388484
Epoch: 71 | Iteration number: [140/565] 24% | Training loss: 0.6917394552912031
Epoch: 71 | Iteration number: [150/565] 26% | Training loss: 0.6914185468355815
Epoch: 71 | Iteration number: [160/565] 28% | Training loss: 0.6911403018981218
Epoch: 71 | Iteration number: [170/565] 30% | Training loss: 0.6908992108176736
Epoch: 71 | Iteration number: [180/565] 31% | Training loss: 0.6906832370493147
Epoch: 71 | Iteration number: [190/565] 33% | Training loss: 0.6904742702057487
Epoch: 71 | Iteration number: [200/565] 35% | Training loss: 0.6902889129519463
Epoch: 71 | Iteration number: [210/565] 37% | Training loss: 0.6901268595740908
Epoch: 71 | Iteration number: [220/565] 38% | Training loss: 0.6899732421744954
Epoch: 71 | Iteration number: [230/565] 40% | Training loss: 0.6898368278275365
Epoch: 71 | Iteration number: [240/565] 42% | Training loss: 0.6897017009556293
Epoch: 71 | Iteration number: [250/565] 44% | Training loss: 0.6895891351699829
Epoch: 71 | Iteration number: [260/565] 46% | Training loss: 0.6894866388577682
Epoch: 71 | Iteration number: [270/565] 47% | Training loss: 0.6893844613322505
Epoch: 71 | Iteration number: [280/565] 49% | Training loss: 0.6892869621515274
Epoch: 71 | Iteration number: [290/565] 51% | Training loss: 0.6892184814502453
Epoch: 71 | Iteration number: [300/565] 53% | Training loss: 0.6891300084193548
Epoch: 71 | Iteration number: [310/565] 54% | Training loss: 0.6890417539304302
Epoch: 71 | Iteration number: [320/565] 56% | Training loss: 0.6889626402407885
Epoch: 71 | Iteration number: [330/565] 58% | Training loss: 0.6888871330203432
Epoch: 71 | Iteration number: [340/565] 60% | Training loss: 0.6888222201782115
Epoch: 71 | Iteration number: [350/565] 61% | Training loss: 0.6887589762892042
Epoch: 71 | Iteration number: [360/565] 63% | Training loss: 0.6887012054522832
Epoch: 71 | Iteration number: [370/565] 65% | Training loss: 0.6886503615894833
Epoch: 71 | Iteration number: [380/565] 67% | Training loss: 0.6886124488554503
Epoch: 71 | Iteration number: [390/565] 69% | Training loss: 0.6885525865432544
Epoch: 71 | Iteration number: [400/565] 70% | Training loss: 0.6884936173260212
Epoch: 71 | Iteration number: [410/565] 72% | Training loss: 0.6884536788230989
Epoch: 71 | Iteration number: [420/565] 74% | Training loss: 0.6884041642858869
Epoch: 71 | Iteration number: [430/565] 76% | Training loss: 0.6883640066135761
Epoch: 71 | Iteration number: [440/565] 77% | Training loss: 0.6883345545692877
Epoch: 71 | Iteration number: [450/565] 79% | Training loss: 0.6883056785000695
Epoch: 71 | Iteration number: [460/565] 81% | Training loss: 0.6882620930671692
Epoch: 71 | Iteration number: [470/565] 83% | Training loss: 0.6882307001884947
Epoch: 71 | Iteration number: [480/565] 84% | Training loss: 0.6882006018112103
Epoch: 71 | Iteration number: [490/565] 86% | Training loss: 0.6881740321918409
Epoch: 71 | Iteration number: [500/565] 88% | Training loss: 0.6881481839418411
Epoch: 71 | Iteration number: [510/565] 90% | Training loss: 0.6881314595540364
Epoch: 71 | Iteration number: [520/565] 92% | Training loss: 0.6881046030383844
Epoch: 71 | Iteration number: [530/565] 93% | Training loss: 0.688083010237172
Epoch: 71 | Iteration number: [540/565] 95% | Training loss: 0.6880522990668262
Epoch: 71 | Iteration number: [550/565] 97% | Training loss: 0.6880340070074255
Epoch: 71 | Iteration number: [560/565] 99% | Training loss: 0.6880159220525197

 End of epoch: 71 | Train Loss: 0.6867874736279513 | Training Time: 88 

 End of epoch: 71 | Eval Loss: 0.6894880107470921 | Evaluating Time: 6 
Epoch: 72 | Iteration number: [10/565] 1% | Training loss: 0.7555418312549591
Epoch: 72 | Iteration number: [20/565] 3% | Training loss: 0.7209809929132461
Epoch: 72 | Iteration number: [30/565] 5% | Training loss: 0.7095942954222362
Epoch: 72 | Iteration number: [40/565] 7% | Training loss: 0.7039967030286789
Epoch: 72 | Iteration number: [50/565] 8% | Training loss: 0.7005825078487397
Epoch: 72 | Iteration number: [60/565] 10% | Training loss: 0.6982468813657761
Epoch: 72 | Iteration number: [70/565] 12% | Training loss: 0.6966211634022849
Epoch: 72 | Iteration number: [80/565] 14% | Training loss: 0.6953787289559841
Epoch: 72 | Iteration number: [90/565] 15% | Training loss: 0.6944430801603529
Epoch: 72 | Iteration number: [100/565] 17% | Training loss: 0.6936411416530609
Epoch: 72 | Iteration number: [110/565] 19% | Training loss: 0.6929708220741966
Epoch: 72 | Iteration number: [120/565] 21% | Training loss: 0.6924321398139
Epoch: 72 | Iteration number: [130/565] 23% | Training loss: 0.692006483903298
Epoch: 72 | Iteration number: [140/565] 24% | Training loss: 0.6916565056358065
Epoch: 72 | Iteration number: [150/565] 26% | Training loss: 0.6913426001866658
Epoch: 72 | Iteration number: [160/565] 28% | Training loss: 0.6910940118134021
Epoch: 72 | Iteration number: [170/565] 30% | Training loss: 0.6908384319613962
Epoch: 72 | Iteration number: [180/565] 31% | Training loss: 0.6906106521685919
Epoch: 72 | Iteration number: [190/565] 33% | Training loss: 0.6904116847013172
Epoch: 72 | Iteration number: [200/565] 35% | Training loss: 0.6902242133021355
Epoch: 72 | Iteration number: [210/565] 37% | Training loss: 0.6900624326297216
Epoch: 72 | Iteration number: [220/565] 38% | Training loss: 0.6899065164002505
Epoch: 72 | Iteration number: [230/565] 40% | Training loss: 0.6897884848325149
Epoch: 72 | Iteration number: [240/565] 42% | Training loss: 0.689669256657362
Epoch: 72 | Iteration number: [250/565] 44% | Training loss: 0.6895441229343414
Epoch: 72 | Iteration number: [260/565] 46% | Training loss: 0.6894315772331678
Epoch: 72 | Iteration number: [270/565] 47% | Training loss: 0.689332233093403
Epoch: 72 | Iteration number: [280/565] 49% | Training loss: 0.6892371648124286
Epoch: 72 | Iteration number: [290/565] 51% | Training loss: 0.689143214349089
Epoch: 72 | Iteration number: [300/565] 53% | Training loss: 0.6890718209743499
Epoch: 72 | Iteration number: [310/565] 54% | Training loss: 0.6890006394155563
Epoch: 72 | Iteration number: [320/565] 56% | Training loss: 0.6889235300943255
Epoch: 72 | Iteration number: [330/565] 58% | Training loss: 0.6888648710467599
Epoch: 72 | Iteration number: [340/565] 60% | Training loss: 0.6888100336579716
Epoch: 72 | Iteration number: [350/565] 61% | Training loss: 0.688743040902274
Epoch: 72 | Iteration number: [360/565] 63% | Training loss: 0.6886772758430905
Epoch: 72 | Iteration number: [370/565] 65% | Training loss: 0.688627721812274
Epoch: 72 | Iteration number: [380/565] 67% | Training loss: 0.6885871468405974
Epoch: 72 | Iteration number: [390/565] 69% | Training loss: 0.6885404761020953
Epoch: 72 | Iteration number: [400/565] 70% | Training loss: 0.6885057459771633
Epoch: 72 | Iteration number: [410/565] 72% | Training loss: 0.6884572955166421
Epoch: 72 | Iteration number: [420/565] 74% | Training loss: 0.6884183272009804
Epoch: 72 | Iteration number: [430/565] 76% | Training loss: 0.688389975802843
Epoch: 72 | Iteration number: [440/565] 77% | Training loss: 0.6883501850745894
Epoch: 72 | Iteration number: [450/565] 79% | Training loss: 0.6883100888464186
Epoch: 72 | Iteration number: [460/565] 81% | Training loss: 0.6882824519406194
Epoch: 72 | Iteration number: [470/565] 83% | Training loss: 0.6882560553702902
Epoch: 72 | Iteration number: [480/565] 84% | Training loss: 0.6882126656671365
Epoch: 72 | Iteration number: [490/565] 86% | Training loss: 0.6881766700014776
Epoch: 72 | Iteration number: [500/565] 88% | Training loss: 0.6881534572839737
Epoch: 72 | Iteration number: [510/565] 90% | Training loss: 0.6881277480546166
Epoch: 72 | Iteration number: [520/565] 92% | Training loss: 0.6881030003611858
Epoch: 72 | Iteration number: [530/565] 93% | Training loss: 0.6880796159213444
Epoch: 72 | Iteration number: [540/565] 95% | Training loss: 0.6880571646822824
Epoch: 72 | Iteration number: [550/565] 97% | Training loss: 0.6880395232547413
Epoch: 72 | Iteration number: [560/565] 99% | Training loss: 0.6880199782550335

 End of epoch: 72 | Train Loss: 0.6867932856610391 | Training Time: 89 

 End of epoch: 72 | Eval Loss: 0.6900607773235866 | Evaluating Time: 6 
Epoch: 73 | Iteration number: [10/565] 1% | Training loss: 0.7552144706249238
Epoch: 73 | Iteration number: [20/565] 3% | Training loss: 0.7211566597223282
Epoch: 73 | Iteration number: [30/565] 5% | Training loss: 0.7098790268103282
Epoch: 73 | Iteration number: [40/565] 7% | Training loss: 0.7040727570652962
Epoch: 73 | Iteration number: [50/565] 8% | Training loss: 0.7005940806865693
Epoch: 73 | Iteration number: [60/565] 10% | Training loss: 0.6983369390169779
Epoch: 73 | Iteration number: [70/565] 12% | Training loss: 0.6967004588672093
Epoch: 73 | Iteration number: [80/565] 14% | Training loss: 0.6954176060855388
Epoch: 73 | Iteration number: [90/565] 15% | Training loss: 0.6944468928707971
Epoch: 73 | Iteration number: [100/565] 17% | Training loss: 0.6936940908432007
Epoch: 73 | Iteration number: [110/565] 19% | Training loss: 0.6930597776716406
Epoch: 73 | Iteration number: [120/565] 21% | Training loss: 0.6924927781025568
Epoch: 73 | Iteration number: [130/565] 23% | Training loss: 0.6920619345628298
Epoch: 73 | Iteration number: [140/565] 24% | Training loss: 0.6916396277291434
Epoch: 73 | Iteration number: [150/565] 26% | Training loss: 0.6913381735483806
Epoch: 73 | Iteration number: [160/565] 28% | Training loss: 0.6910373464226722
Epoch: 73 | Iteration number: [170/565] 30% | Training loss: 0.6908155819948982
Epoch: 73 | Iteration number: [180/565] 31% | Training loss: 0.6905949337614907
Epoch: 73 | Iteration number: [190/565] 33% | Training loss: 0.6903717950770729
Epoch: 73 | Iteration number: [200/565] 35% | Training loss: 0.6902130994200707
Epoch: 73 | Iteration number: [210/565] 37% | Training loss: 0.6900580474308559
Epoch: 73 | Iteration number: [220/565] 38% | Training loss: 0.6899205866185102
Epoch: 73 | Iteration number: [230/565] 40% | Training loss: 0.6897736751514932
Epoch: 73 | Iteration number: [240/565] 42% | Training loss: 0.6896346973876158
Epoch: 73 | Iteration number: [250/565] 44% | Training loss: 0.6895392026901245
Epoch: 73 | Iteration number: [260/565] 46% | Training loss: 0.6894372848364023
Epoch: 73 | Iteration number: [270/565] 47% | Training loss: 0.6893321242597368
Epoch: 73 | Iteration number: [280/565] 49% | Training loss: 0.689258693584374
Epoch: 73 | Iteration number: [290/565] 51% | Training loss: 0.6891582433519692
Epoch: 73 | Iteration number: [300/565] 53% | Training loss: 0.6890917058785756
Epoch: 73 | Iteration number: [310/565] 54% | Training loss: 0.6890156699765113
Epoch: 73 | Iteration number: [320/565] 56% | Training loss: 0.6889378698542714
Epoch: 73 | Iteration number: [330/565] 58% | Training loss: 0.6888574768196453
Epoch: 73 | Iteration number: [340/565] 60% | Training loss: 0.6887929136262221
Epoch: 73 | Iteration number: [350/565] 61% | Training loss: 0.6887327875409808
Epoch: 73 | Iteration number: [360/565] 63% | Training loss: 0.6886664430300394
Epoch: 73 | Iteration number: [370/565] 65% | Training loss: 0.6886240364731969
Epoch: 73 | Iteration number: [380/565] 67% | Training loss: 0.6885854426183199
Epoch: 73 | Iteration number: [390/565] 69% | Training loss: 0.6885559057578062
Epoch: 73 | Iteration number: [400/565] 70% | Training loss: 0.6885078293085098
Epoch: 73 | Iteration number: [410/565] 72% | Training loss: 0.6884592611615251
Epoch: 73 | Iteration number: [420/565] 74% | Training loss: 0.6884084224700928
Epoch: 73 | Iteration number: [430/565] 76% | Training loss: 0.6883815576863843
Epoch: 73 | Iteration number: [440/565] 77% | Training loss: 0.6883415215394714
Epoch: 73 | Iteration number: [450/565] 79% | Training loss: 0.6883018018139733
Epoch: 73 | Iteration number: [460/565] 81% | Training loss: 0.6882683584223623
Epoch: 73 | Iteration number: [470/565] 83% | Training loss: 0.6882379155209724
Epoch: 73 | Iteration number: [480/565] 84% | Training loss: 0.6882135843237241
Epoch: 73 | Iteration number: [490/565] 86% | Training loss: 0.6881820967002791
Epoch: 73 | Iteration number: [500/565] 88% | Training loss: 0.6881562888622283
Epoch: 73 | Iteration number: [510/565] 90% | Training loss: 0.6881344442274057
Epoch: 73 | Iteration number: [520/565] 92% | Training loss: 0.6881085923084846
Epoch: 73 | Iteration number: [530/565] 93% | Training loss: 0.6880882098989667
Epoch: 73 | Iteration number: [540/565] 95% | Training loss: 0.6880528579155604
Epoch: 73 | Iteration number: [550/565] 97% | Training loss: 0.6880239414085041
Epoch: 73 | Iteration number: [560/565] 99% | Training loss: 0.6880045187260423

 End of epoch: 73 | Train Loss: 0.6867800661947875 | Training Time: 89 

 End of epoch: 73 | Eval Loss: 0.6899884002549308 | Evaluating Time: 6 
Epoch: 74 | Iteration number: [10/565] 1% | Training loss: 0.7554937064647674
Epoch: 74 | Iteration number: [20/565] 3% | Training loss: 0.7210764020681382
Epoch: 74 | Iteration number: [30/565] 5% | Training loss: 0.7096169392267863
Epoch: 74 | Iteration number: [40/565] 7% | Training loss: 0.7038676500320434
Epoch: 74 | Iteration number: [50/565] 8% | Training loss: 0.7003674054145813
Epoch: 74 | Iteration number: [60/565] 10% | Training loss: 0.6981165697177251
Epoch: 74 | Iteration number: [70/565] 12% | Training loss: 0.6965363987854549
Epoch: 74 | Iteration number: [80/565] 14% | Training loss: 0.6953133560717106
Epoch: 74 | Iteration number: [90/565] 15% | Training loss: 0.6943508678012424
Epoch: 74 | Iteration number: [100/565] 17% | Training loss: 0.69357930123806
Epoch: 74 | Iteration number: [110/565] 19% | Training loss: 0.6929303581064398
Epoch: 74 | Iteration number: [120/565] 21% | Training loss: 0.6923988178372383
Epoch: 74 | Iteration number: [130/565] 23% | Training loss: 0.6919783083292154
Epoch: 74 | Iteration number: [140/565] 24% | Training loss: 0.6915878461939948
Epoch: 74 | Iteration number: [150/565] 26% | Training loss: 0.6912661715348561
Epoch: 74 | Iteration number: [160/565] 28% | Training loss: 0.6910011447966099
Epoch: 74 | Iteration number: [170/565] 30% | Training loss: 0.6907501609886394
Epoch: 74 | Iteration number: [180/565] 31% | Training loss: 0.6905255297819773
Epoch: 74 | Iteration number: [190/565] 33% | Training loss: 0.6903184310386056
Epoch: 74 | Iteration number: [200/565] 35% | Training loss: 0.6901249012351036
Epoch: 74 | Iteration number: [210/565] 37% | Training loss: 0.6899658966632116
Epoch: 74 | Iteration number: [220/565] 38% | Training loss: 0.6898233096707951
Epoch: 74 | Iteration number: [230/565] 40% | Training loss: 0.689685436953669
Epoch: 74 | Iteration number: [240/565] 42% | Training loss: 0.6895840105911096
Epoch: 74 | Iteration number: [250/565] 44% | Training loss: 0.6894636659622192
Epoch: 74 | Iteration number: [260/565] 46% | Training loss: 0.6893605429392594
Epoch: 74 | Iteration number: [270/565] 47% | Training loss: 0.689259268619396
Epoch: 74 | Iteration number: [280/565] 49% | Training loss: 0.6891680804746492
Epoch: 74 | Iteration number: [290/565] 51% | Training loss: 0.6890883375858439
Epoch: 74 | Iteration number: [300/565] 53% | Training loss: 0.6890063913663228
Epoch: 74 | Iteration number: [310/565] 54% | Training loss: 0.6889497485853011
Epoch: 74 | Iteration number: [320/565] 56% | Training loss: 0.6888797609135509
Epoch: 74 | Iteration number: [330/565] 58% | Training loss: 0.6888089640574022
Epoch: 74 | Iteration number: [340/565] 60% | Training loss: 0.6887542619424708
Epoch: 74 | Iteration number: [350/565] 61% | Training loss: 0.6887158414295741
Epoch: 74 | Iteration number: [360/565] 63% | Training loss: 0.6886634629633691
Epoch: 74 | Iteration number: [370/565] 65% | Training loss: 0.6886117331079534
Epoch: 74 | Iteration number: [380/565] 67% | Training loss: 0.6885706583136006
Epoch: 74 | Iteration number: [390/565] 69% | Training loss: 0.6885337673700773
Epoch: 74 | Iteration number: [400/565] 70% | Training loss: 0.6884958174824715
Epoch: 74 | Iteration number: [410/565] 72% | Training loss: 0.6884404883152101
Epoch: 74 | Iteration number: [420/565] 74% | Training loss: 0.688400860059829
Epoch: 74 | Iteration number: [430/565] 76% | Training loss: 0.688364986763444
Epoch: 74 | Iteration number: [440/565] 77% | Training loss: 0.6883303334767168
Epoch: 74 | Iteration number: [450/565] 79% | Training loss: 0.6882897267076704
Epoch: 74 | Iteration number: [460/565] 81% | Training loss: 0.6882602621679721
Epoch: 74 | Iteration number: [470/565] 83% | Training loss: 0.688224718038072
Epoch: 74 | Iteration number: [480/565] 84% | Training loss: 0.6881905357042949
Epoch: 74 | Iteration number: [490/565] 86% | Training loss: 0.6881613207106687
Epoch: 74 | Iteration number: [500/565] 88% | Training loss: 0.6881290537118911
Epoch: 74 | Iteration number: [510/565] 90% | Training loss: 0.6880991157363443
Epoch: 74 | Iteration number: [520/565] 92% | Training loss: 0.6880798001702015
Epoch: 74 | Iteration number: [530/565] 93% | Training loss: 0.6880591795129596
Epoch: 74 | Iteration number: [540/565] 95% | Training loss: 0.6880334993203481
Epoch: 74 | Iteration number: [550/565] 97% | Training loss: 0.6880163828893141
Epoch: 74 | Iteration number: [560/565] 99% | Training loss: 0.6879979085709368

 End of epoch: 74 | Train Loss: 0.6867767243258721 | Training Time: 89 

 End of epoch: 74 | Eval Loss: 0.6899470516613552 | Evaluating Time: 5 
Epoch: 75 | Iteration number: [10/565] 1% | Training loss: 0.7555207014083862
Epoch: 75 | Iteration number: [20/565] 3% | Training loss: 0.7211191147565842
Epoch: 75 | Iteration number: [30/565] 5% | Training loss: 0.7095097422599792
Epoch: 75 | Iteration number: [40/565] 7% | Training loss: 0.7037255793809891
Epoch: 75 | Iteration number: [50/565] 8% | Training loss: 0.7003315281867981
Epoch: 75 | Iteration number: [60/565] 10% | Training loss: 0.6981018841266632
Epoch: 75 | Iteration number: [70/565] 12% | Training loss: 0.6965109356812068
Epoch: 75 | Iteration number: [80/565] 14% | Training loss: 0.6953211300075054
Epoch: 75 | Iteration number: [90/565] 15% | Training loss: 0.6943807217809889
Epoch: 75 | Iteration number: [100/565] 17% | Training loss: 0.6936364579200744
Epoch: 75 | Iteration number: [110/565] 19% | Training loss: 0.6930078398097645
Epoch: 75 | Iteration number: [120/565] 21% | Training loss: 0.6924617533882459
Epoch: 75 | Iteration number: [130/565] 23% | Training loss: 0.69197686956479
Epoch: 75 | Iteration number: [140/565] 24% | Training loss: 0.6916478552988597
Epoch: 75 | Iteration number: [150/565] 26% | Training loss: 0.6912955963611602
Epoch: 75 | Iteration number: [160/565] 28% | Training loss: 0.6910396903753281
Epoch: 75 | Iteration number: [170/565] 30% | Training loss: 0.6907858343685375
Epoch: 75 | Iteration number: [180/565] 31% | Training loss: 0.6905500478214688
Epoch: 75 | Iteration number: [190/565] 33% | Training loss: 0.6903398971808584
Epoch: 75 | Iteration number: [200/565] 35% | Training loss: 0.6901435729861259
Epoch: 75 | Iteration number: [210/565] 37% | Training loss: 0.6899987859385354
Epoch: 75 | Iteration number: [220/565] 38% | Training loss: 0.6898476001891223
Epoch: 75 | Iteration number: [230/565] 40% | Training loss: 0.6896975175194119
Epoch: 75 | Iteration number: [240/565] 42% | Training loss: 0.6895593985915184
Epoch: 75 | Iteration number: [250/565] 44% | Training loss: 0.6894613387584686
Epoch: 75 | Iteration number: [260/565] 46% | Training loss: 0.6893498136447026
Epoch: 75 | Iteration number: [270/565] 47% | Training loss: 0.689254164033466
Epoch: 75 | Iteration number: [280/565] 49% | Training loss: 0.6891646551234382
Epoch: 75 | Iteration number: [290/565] 51% | Training loss: 0.689082985910876
Epoch: 75 | Iteration number: [300/565] 53% | Training loss: 0.6890109817186991
Epoch: 75 | Iteration number: [310/565] 54% | Training loss: 0.6889373892737973
Epoch: 75 | Iteration number: [320/565] 56% | Training loss: 0.6888823438435793
Epoch: 75 | Iteration number: [330/565] 58% | Training loss: 0.6888210928801334
Epoch: 75 | Iteration number: [340/565] 60% | Training loss: 0.6887627908412148
Epoch: 75 | Iteration number: [350/565] 61% | Training loss: 0.6887184969016484
Epoch: 75 | Iteration number: [360/565] 63% | Training loss: 0.688674229880174
Epoch: 75 | Iteration number: [370/565] 65% | Training loss: 0.6886166367981885
Epoch: 75 | Iteration number: [380/565] 67% | Training loss: 0.6885547259920521
Epoch: 75 | Iteration number: [390/565] 69% | Training loss: 0.6885137241620284
Epoch: 75 | Iteration number: [400/565] 70% | Training loss: 0.6884744004905223
Epoch: 75 | Iteration number: [410/565] 72% | Training loss: 0.6884350023618558
Epoch: 75 | Iteration number: [420/565] 74% | Training loss: 0.6883944339695431
Epoch: 75 | Iteration number: [430/565] 76% | Training loss: 0.6883530252201613
Epoch: 75 | Iteration number: [440/565] 77% | Training loss: 0.6883354749191891
Epoch: 75 | Iteration number: [450/565] 79% | Training loss: 0.6882935999499427
Epoch: 75 | Iteration number: [460/565] 81% | Training loss: 0.6882539109043453
Epoch: 75 | Iteration number: [470/565] 83% | Training loss: 0.6882244240730366
Epoch: 75 | Iteration number: [480/565] 84% | Training loss: 0.6881906724224488
Epoch: 75 | Iteration number: [490/565] 86% | Training loss: 0.6881624522257824
Epoch: 75 | Iteration number: [500/565] 88% | Training loss: 0.6881399441957474
Epoch: 75 | Iteration number: [510/565] 90% | Training loss: 0.6881091830777187
Epoch: 75 | Iteration number: [520/565] 92% | Training loss: 0.6880869703797193
Epoch: 75 | Iteration number: [530/565] 93% | Training loss: 0.6880630928390431
Epoch: 75 | Iteration number: [540/565] 95% | Training loss: 0.688038291644167
Epoch: 75 | Iteration number: [550/565] 97% | Training loss: 0.6880178391933441
Epoch: 75 | Iteration number: [560/565] 99% | Training loss: 0.6880022665219647

 End of epoch: 75 | Train Loss: 0.6867740613169375 | Training Time: 88 

 End of epoch: 75 | Eval Loss: 0.6896753566605704 | Evaluating Time: 6 
Epoch: 76 | Iteration number: [10/565] 1% | Training loss: 0.7555341839790344
Epoch: 76 | Iteration number: [20/565] 3% | Training loss: 0.7212743878364563
Epoch: 76 | Iteration number: [30/565] 5% | Training loss: 0.7098455131053925
Epoch: 76 | Iteration number: [40/565] 7% | Training loss: 0.7041637480258942
Epoch: 76 | Iteration number: [50/565] 8% | Training loss: 0.7006212949752808
Epoch: 76 | Iteration number: [60/565] 10% | Training loss: 0.6983011464277903
Epoch: 76 | Iteration number: [70/565] 12% | Training loss: 0.6966279447078705
Epoch: 76 | Iteration number: [80/565] 14% | Training loss: 0.6954545237123966
Epoch: 76 | Iteration number: [90/565] 15% | Training loss: 0.6945219847891065
Epoch: 76 | Iteration number: [100/565] 17% | Training loss: 0.6937140840291977
Epoch: 76 | Iteration number: [110/565] 19% | Training loss: 0.6930489951914007
Epoch: 76 | Iteration number: [120/565] 21% | Training loss: 0.692554580171903
Epoch: 76 | Iteration number: [130/565] 23% | Training loss: 0.6920894985015575
Epoch: 76 | Iteration number: [140/565] 24% | Training loss: 0.6917183646133968
Epoch: 76 | Iteration number: [150/565] 26% | Training loss: 0.6913807300726572
Epoch: 76 | Iteration number: [160/565] 28% | Training loss: 0.691098279133439
Epoch: 76 | Iteration number: [170/565] 30% | Training loss: 0.690865500534282
Epoch: 76 | Iteration number: [180/565] 31% | Training loss: 0.6906183948119481
Epoch: 76 | Iteration number: [190/565] 33% | Training loss: 0.69042014981571
Epoch: 76 | Iteration number: [200/565] 35% | Training loss: 0.6902551820874214
Epoch: 76 | Iteration number: [210/565] 37% | Training loss: 0.690096078032539
Epoch: 76 | Iteration number: [220/565] 38% | Training loss: 0.6899307451464913
Epoch: 76 | Iteration number: [230/565] 40% | Training loss: 0.6898057092791018
Epoch: 76 | Iteration number: [240/565] 42% | Training loss: 0.6896858443816503
Epoch: 76 | Iteration number: [250/565] 44% | Training loss: 0.689572598695755
Epoch: 76 | Iteration number: [260/565] 46% | Training loss: 0.6894753327736488
Epoch: 76 | Iteration number: [270/565] 47% | Training loss: 0.6893799194583187
Epoch: 76 | Iteration number: [280/565] 49% | Training loss: 0.6892880322677749
Epoch: 76 | Iteration number: [290/565] 51% | Training loss: 0.6891945530628336
Epoch: 76 | Iteration number: [300/565] 53% | Training loss: 0.6891349955399831
Epoch: 76 | Iteration number: [310/565] 54% | Training loss: 0.6890703699281139
Epoch: 76 | Iteration number: [320/565] 56% | Training loss: 0.6889974435791373
Epoch: 76 | Iteration number: [330/565] 58% | Training loss: 0.6889430811910918
Epoch: 76 | Iteration number: [340/565] 60% | Training loss: 0.6888772457838058
Epoch: 76 | Iteration number: [350/565] 61% | Training loss: 0.6888169177940914
Epoch: 76 | Iteration number: [360/565] 63% | Training loss: 0.6887570652696822
Epoch: 76 | Iteration number: [370/565] 65% | Training loss: 0.6886983001554334
Epoch: 76 | Iteration number: [380/565] 67% | Training loss: 0.6886550136302647
Epoch: 76 | Iteration number: [390/565] 69% | Training loss: 0.6886020220243014
Epoch: 76 | Iteration number: [400/565] 70% | Training loss: 0.6885452857613563
Epoch: 76 | Iteration number: [410/565] 72% | Training loss: 0.6884979143375304
Epoch: 76 | Iteration number: [420/565] 74% | Training loss: 0.6884629402841841
Epoch: 76 | Iteration number: [430/565] 76% | Training loss: 0.6884178182413412
Epoch: 76 | Iteration number: [440/565] 77% | Training loss: 0.6883692937818441
Epoch: 76 | Iteration number: [450/565] 79% | Training loss: 0.6883324392636617
Epoch: 76 | Iteration number: [460/565] 81% | Training loss: 0.6882896860008655
Epoch: 76 | Iteration number: [470/565] 83% | Training loss: 0.6882605985124061
Epoch: 76 | Iteration number: [480/565] 84% | Training loss: 0.6882294334471226
Epoch: 76 | Iteration number: [490/565] 86% | Training loss: 0.6882104102446108
Epoch: 76 | Iteration number: [500/565] 88% | Training loss: 0.6881790236234665
Epoch: 76 | Iteration number: [510/565] 90% | Training loss: 0.68814710261775
Epoch: 76 | Iteration number: [520/565] 92% | Training loss: 0.6881188792678026
Epoch: 76 | Iteration number: [530/565] 93% | Training loss: 0.6880954961731749
Epoch: 76 | Iteration number: [540/565] 95% | Training loss: 0.6880622257788976
Epoch: 76 | Iteration number: [550/565] 97% | Training loss: 0.6880525969375264
Epoch: 76 | Iteration number: [560/565] 99% | Training loss: 0.6880301452108792

 End of epoch: 76 | Train Loss: 0.686802353373671 | Training Time: 89 

 End of epoch: 76 | Eval Loss: 0.6903656465666634 | Evaluating Time: 6 
Epoch: 77 | Iteration number: [10/565] 1% | Training loss: 0.754901796579361
Epoch: 77 | Iteration number: [20/565] 3% | Training loss: 0.720850819349289
Epoch: 77 | Iteration number: [30/565] 5% | Training loss: 0.7096249918142955
Epoch: 77 | Iteration number: [40/565] 7% | Training loss: 0.7039449393749238
Epoch: 77 | Iteration number: [50/565] 8% | Training loss: 0.7004998862743378
Epoch: 77 | Iteration number: [60/565] 10% | Training loss: 0.6981382509072621
Epoch: 77 | Iteration number: [70/565] 12% | Training loss: 0.6964850153241838
Epoch: 77 | Iteration number: [80/565] 14% | Training loss: 0.6952584192156792
Epoch: 77 | Iteration number: [90/565] 15% | Training loss: 0.6943234715196821
Epoch: 77 | Iteration number: [100/565] 17% | Training loss: 0.6935531830787659
Epoch: 77 | Iteration number: [110/565] 19% | Training loss: 0.6929394228891893
Epoch: 77 | Iteration number: [120/565] 21% | Training loss: 0.6924460296829541
Epoch: 77 | Iteration number: [130/565] 23% | Training loss: 0.6919926753410927
Epoch: 77 | Iteration number: [140/565] 24% | Training loss: 0.6916380967412676
Epoch: 77 | Iteration number: [150/565] 26% | Training loss: 0.691324162085851
Epoch: 77 | Iteration number: [160/565] 28% | Training loss: 0.6910455793142318
Epoch: 77 | Iteration number: [170/565] 30% | Training loss: 0.6907839101903579
Epoch: 77 | Iteration number: [180/565] 31% | Training loss: 0.6905599994791879
Epoch: 77 | Iteration number: [190/565] 33% | Training loss: 0.69035835799418
Epoch: 77 | Iteration number: [200/565] 35% | Training loss: 0.6901588273048401
Epoch: 77 | Iteration number: [210/565] 37% | Training loss: 0.6900101295539312
Epoch: 77 | Iteration number: [220/565] 38% | Training loss: 0.6898649844256315
Epoch: 77 | Iteration number: [230/565] 40% | Training loss: 0.6897253510744675
Epoch: 77 | Iteration number: [240/565] 42% | Training loss: 0.689611128717661
Epoch: 77 | Iteration number: [250/565] 44% | Training loss: 0.6894967920780182
Epoch: 77 | Iteration number: [260/565] 46% | Training loss: 0.6893782750918315
Epoch: 77 | Iteration number: [270/565] 47% | Training loss: 0.6892776835847784
Epoch: 77 | Iteration number: [280/565] 49% | Training loss: 0.6891955907855715
Epoch: 77 | Iteration number: [290/565] 51% | Training loss: 0.6891070174759832
Epoch: 77 | Iteration number: [300/565] 53% | Training loss: 0.6890293737252553
Epoch: 77 | Iteration number: [310/565] 54% | Training loss: 0.6889564254591541
Epoch: 77 | Iteration number: [320/565] 56% | Training loss: 0.6888872506096959
Epoch: 77 | Iteration number: [330/565] 58% | Training loss: 0.6888369032830903
Epoch: 77 | Iteration number: [340/565] 60% | Training loss: 0.6887767363997067
Epoch: 77 | Iteration number: [350/565] 61% | Training loss: 0.6887071740627289
Epoch: 77 | Iteration number: [360/565] 63% | Training loss: 0.688643624054061
Epoch: 77 | Iteration number: [370/565] 65% | Training loss: 0.6885935786608103
Epoch: 77 | Iteration number: [380/565] 67% | Training loss: 0.6885440147236774
Epoch: 77 | Iteration number: [390/565] 69% | Training loss: 0.6884940936015203
Epoch: 77 | Iteration number: [400/565] 70% | Training loss: 0.68846713706851
Epoch: 77 | Iteration number: [410/565] 72% | Training loss: 0.6884236908540493
Epoch: 77 | Iteration number: [420/565] 74% | Training loss: 0.6883818169434865
Epoch: 77 | Iteration number: [430/565] 76% | Training loss: 0.6883506393709848
Epoch: 77 | Iteration number: [440/565] 77% | Training loss: 0.6883263899521395
Epoch: 77 | Iteration number: [450/565] 79% | Training loss: 0.6882880266507466
Epoch: 77 | Iteration number: [460/565] 81% | Training loss: 0.6882535432991774
Epoch: 77 | Iteration number: [470/565] 83% | Training loss: 0.6882228356726626
Epoch: 77 | Iteration number: [480/565] 84% | Training loss: 0.6881983385731777
Epoch: 77 | Iteration number: [490/565] 86% | Training loss: 0.688164235986009
Epoch: 77 | Iteration number: [500/565] 88% | Training loss: 0.6881420967578888
Epoch: 77 | Iteration number: [510/565] 90% | Training loss: 0.6881172729473488
Epoch: 77 | Iteration number: [520/565] 92% | Training loss: 0.6880961615305681
Epoch: 77 | Iteration number: [530/565] 93% | Training loss: 0.6880680090976211
Epoch: 77 | Iteration number: [540/565] 95% | Training loss: 0.6880482820449052
Epoch: 77 | Iteration number: [550/565] 97% | Training loss: 0.6880274436690591
Epoch: 77 | Iteration number: [560/565] 99% | Training loss: 0.6880019773330007

 End of epoch: 77 | Train Loss: 0.6867717308280742 | Training Time: 89 

 End of epoch: 77 | Eval Loss: 0.68949636391231 | Evaluating Time: 6 
Epoch: 78 | Iteration number: [10/565] 1% | Training loss: 0.7549984216690063
Epoch: 78 | Iteration number: [20/565] 3% | Training loss: 0.720886892080307
Epoch: 78 | Iteration number: [30/565] 5% | Training loss: 0.7094588180383047
Epoch: 78 | Iteration number: [40/565] 7% | Training loss: 0.7036290109157562
Epoch: 78 | Iteration number: [50/565] 8% | Training loss: 0.7003721153736114
Epoch: 78 | Iteration number: [60/565] 10% | Training loss: 0.6981661528348923
Epoch: 78 | Iteration number: [70/565] 12% | Training loss: 0.6965561108929771
Epoch: 78 | Iteration number: [80/565] 14% | Training loss: 0.6954183094203472
Epoch: 78 | Iteration number: [90/565] 15% | Training loss: 0.6944791773955027
Epoch: 78 | Iteration number: [100/565] 17% | Training loss: 0.6936766457557678
Epoch: 78 | Iteration number: [110/565] 19% | Training loss: 0.6930647508664565
Epoch: 78 | Iteration number: [120/565] 21% | Training loss: 0.692572737733523
Epoch: 78 | Iteration number: [130/565] 23% | Training loss: 0.6920889097910661
Epoch: 78 | Iteration number: [140/565] 24% | Training loss: 0.6917245128325054
Epoch: 78 | Iteration number: [150/565] 26% | Training loss: 0.6913911406199137
Epoch: 78 | Iteration number: [160/565] 28% | Training loss: 0.6911249443888664
Epoch: 78 | Iteration number: [170/565] 30% | Training loss: 0.6908540013958426
Epoch: 78 | Iteration number: [180/565] 31% | Training loss: 0.6906228260861502
Epoch: 78 | Iteration number: [190/565] 33% | Training loss: 0.6904252789522473
Epoch: 78 | Iteration number: [200/565] 35% | Training loss: 0.6902352741360664
Epoch: 78 | Iteration number: [210/565] 37% | Training loss: 0.6900738514605023
Epoch: 78 | Iteration number: [220/565] 38% | Training loss: 0.6899194145744497
Epoch: 78 | Iteration number: [230/565] 40% | Training loss: 0.6897797654504362
Epoch: 78 | Iteration number: [240/565] 42% | Training loss: 0.6896565869450569
Epoch: 78 | Iteration number: [250/565] 44% | Training loss: 0.6895446107387543
Epoch: 78 | Iteration number: [260/565] 46% | Training loss: 0.689430262033756
Epoch: 78 | Iteration number: [270/565] 47% | Training loss: 0.6893225312232971
Epoch: 78 | Iteration number: [280/565] 49% | Training loss: 0.689227223609175
Epoch: 78 | Iteration number: [290/565] 51% | Training loss: 0.6891462323994472
Epoch: 78 | Iteration number: [300/565] 53% | Training loss: 0.6890623635053634
Epoch: 78 | Iteration number: [310/565] 54% | Training loss: 0.6889794730371045
Epoch: 78 | Iteration number: [320/565] 56% | Training loss: 0.6889126667752862
Epoch: 78 | Iteration number: [330/565] 58% | Training loss: 0.6888440424745733
Epoch: 78 | Iteration number: [340/565] 60% | Training loss: 0.6887714459615595
Epoch: 78 | Iteration number: [350/565] 61% | Training loss: 0.6887131636483329
Epoch: 78 | Iteration number: [360/565] 63% | Training loss: 0.6886632977260484
Epoch: 78 | Iteration number: [370/565] 65% | Training loss: 0.6886129756231566
Epoch: 78 | Iteration number: [380/565] 67% | Training loss: 0.6885610186739972
Epoch: 78 | Iteration number: [390/565] 69% | Training loss: 0.6885105625177041
Epoch: 78 | Iteration number: [400/565] 70% | Training loss: 0.6884651267528534
Epoch: 78 | Iteration number: [410/565] 72% | Training loss: 0.6884213998550321
Epoch: 78 | Iteration number: [420/565] 74% | Training loss: 0.6883706676108496
Epoch: 78 | Iteration number: [430/565] 76% | Training loss: 0.6883405118487602
Epoch: 78 | Iteration number: [440/565] 77% | Training loss: 0.6883162464607846
Epoch: 78 | Iteration number: [450/565] 79% | Training loss: 0.6882748206456503
Epoch: 78 | Iteration number: [460/565] 81% | Training loss: 0.6882397729417552
Epoch: 78 | Iteration number: [470/565] 83% | Training loss: 0.6882112787124959
Epoch: 78 | Iteration number: [480/565] 84% | Training loss: 0.6881721583505471
Epoch: 78 | Iteration number: [490/565] 86% | Training loss: 0.6881484423364912
Epoch: 78 | Iteration number: [500/565] 88% | Training loss: 0.6881231294870377
Epoch: 78 | Iteration number: [510/565] 90% | Training loss: 0.6880993118473128
Epoch: 78 | Iteration number: [520/565] 92% | Training loss: 0.6880824383634787
Epoch: 78 | Iteration number: [530/565] 93% | Training loss: 0.6880556897172388
Epoch: 78 | Iteration number: [540/565] 95% | Training loss: 0.6880330555968814
Epoch: 78 | Iteration number: [550/565] 97% | Training loss: 0.6880081419511275
Epoch: 78 | Iteration number: [560/565] 99% | Training loss: 0.687990352511406

 End of epoch: 78 | Train Loss: 0.6867679003065666 | Training Time: 90 

 End of epoch: 78 | Eval Loss: 0.6900006106921605 | Evaluating Time: 6 
Epoch: 79 | Iteration number: [10/565] 1% | Training loss: 0.7549488484859467
Epoch: 79 | Iteration number: [20/565] 3% | Training loss: 0.7209946423768997
Epoch: 79 | Iteration number: [30/565] 5% | Training loss: 0.7095400015513103
Epoch: 79 | Iteration number: [40/565] 7% | Training loss: 0.7038370579481125
Epoch: 79 | Iteration number: [50/565] 8% | Training loss: 0.7004990649223327
Epoch: 79 | Iteration number: [60/565] 10% | Training loss: 0.6981845249732336
Epoch: 79 | Iteration number: [70/565] 12% | Training loss: 0.6966011422021049
Epoch: 79 | Iteration number: [80/565] 14% | Training loss: 0.6954269357025623
Epoch: 79 | Iteration number: [90/565] 15% | Training loss: 0.694438037607405
Epoch: 79 | Iteration number: [100/565] 17% | Training loss: 0.6936712020635605
Epoch: 79 | Iteration number: [110/565] 19% | Training loss: 0.6930839441039346
Epoch: 79 | Iteration number: [120/565] 21% | Training loss: 0.6925354008873303
Epoch: 79 | Iteration number: [130/565] 23% | Training loss: 0.6920703186438634
Epoch: 79 | Iteration number: [140/565] 24% | Training loss: 0.6916883387735911
Epoch: 79 | Iteration number: [150/565] 26% | Training loss: 0.6913693145910899
Epoch: 79 | Iteration number: [160/565] 28% | Training loss: 0.6910532265901566
Epoch: 79 | Iteration number: [170/565] 30% | Training loss: 0.6907955579897936
Epoch: 79 | Iteration number: [180/565] 31% | Training loss: 0.6905493587255478
Epoch: 79 | Iteration number: [190/565] 33% | Training loss: 0.6903622504911925
Epoch: 79 | Iteration number: [200/565] 35% | Training loss: 0.6902024459838867
Epoch: 79 | Iteration number: [210/565] 37% | Training loss: 0.6900334690298353
Epoch: 79 | Iteration number: [220/565] 38% | Training loss: 0.6899078970605677
Epoch: 79 | Iteration number: [230/565] 40% | Training loss: 0.6897789929224097
Epoch: 79 | Iteration number: [240/565] 42% | Training loss: 0.6896381273865699
Epoch: 79 | Iteration number: [250/565] 44% | Training loss: 0.6895151472091675
Epoch: 79 | Iteration number: [260/565] 46% | Training loss: 0.6894238203763962
Epoch: 79 | Iteration number: [270/565] 47% | Training loss: 0.6892974116184093
Epoch: 79 | Iteration number: [280/565] 49% | Training loss: 0.6892109023673194
Epoch: 79 | Iteration number: [290/565] 51% | Training loss: 0.6891407565823917
Epoch: 79 | Iteration number: [300/565] 53% | Training loss: 0.6890631357828776
Epoch: 79 | Iteration number: [310/565] 54% | Training loss: 0.6890016478876914
Epoch: 79 | Iteration number: [320/565] 56% | Training loss: 0.6889318497851491
Epoch: 79 | Iteration number: [330/565] 58% | Training loss: 0.6888693693912391
Epoch: 79 | Iteration number: [340/565] 60% | Training loss: 0.6888178495799794
Epoch: 79 | Iteration number: [350/565] 61% | Training loss: 0.6887707992962429
Epoch: 79 | Iteration number: [360/565] 63% | Training loss: 0.6887150231334899
Epoch: 79 | Iteration number: [370/565] 65% | Training loss: 0.6886665895178511
Epoch: 79 | Iteration number: [380/565] 67% | Training loss: 0.688618350656409
Epoch: 79 | Iteration number: [390/565] 69% | Training loss: 0.6885736006956834
Epoch: 79 | Iteration number: [400/565] 70% | Training loss: 0.6885416319966317
Epoch: 79 | Iteration number: [410/565] 72% | Training loss: 0.6884802767416326
Epoch: 79 | Iteration number: [420/565] 74% | Training loss: 0.6884418290285838
Epoch: 79 | Iteration number: [430/565] 76% | Training loss: 0.6883996403494547
Epoch: 79 | Iteration number: [440/565] 77% | Training loss: 0.6883630663156509
Epoch: 79 | Iteration number: [450/565] 79% | Training loss: 0.688321692943573
Epoch: 79 | Iteration number: [460/565] 81% | Training loss: 0.6882826912662258
Epoch: 79 | Iteration number: [470/565] 83% | Training loss: 0.6882570818383643
Epoch: 79 | Iteration number: [480/565] 84% | Training loss: 0.6882236114392678
Epoch: 79 | Iteration number: [490/565] 86% | Training loss: 0.6881924600017314
Epoch: 79 | Iteration number: [500/565] 88% | Training loss: 0.6881665765047074
Epoch: 79 | Iteration number: [510/565] 90% | Training loss: 0.6881363140601738
Epoch: 79 | Iteration number: [520/565] 92% | Training loss: 0.6881100606459838
Epoch: 79 | Iteration number: [530/565] 93% | Training loss: 0.6880779185385074
Epoch: 79 | Iteration number: [540/565] 95% | Training loss: 0.6880550189150705
Epoch: 79 | Iteration number: [550/565] 97% | Training loss: 0.6880288500135595
Epoch: 79 | Iteration number: [560/565] 99% | Training loss: 0.6880099742540291

 End of epoch: 79 | Train Loss: 0.6867859639952668 | Training Time: 87 

 End of epoch: 79 | Eval Loss: 0.6899258324078151 | Evaluating Time: 6 
Epoch: 80 | Iteration number: [10/565] 1% | Training loss: 0.7558047950267792
Epoch: 80 | Iteration number: [20/565] 3% | Training loss: 0.7213298112154007
Epoch: 80 | Iteration number: [30/565] 5% | Training loss: 0.7097214500109355
Epoch: 80 | Iteration number: [40/565] 7% | Training loss: 0.703978817164898
Epoch: 80 | Iteration number: [50/565] 8% | Training loss: 0.7005358016490937
Epoch: 80 | Iteration number: [60/565] 10% | Training loss: 0.698266081015269
Epoch: 80 | Iteration number: [70/565] 12% | Training loss: 0.6966345369815826
Epoch: 80 | Iteration number: [80/565] 14% | Training loss: 0.6954407252371311
Epoch: 80 | Iteration number: [90/565] 15% | Training loss: 0.6944581071535746
Epoch: 80 | Iteration number: [100/565] 17% | Training loss: 0.6937190401554107
Epoch: 80 | Iteration number: [110/565] 19% | Training loss: 0.6930617890574715
Epoch: 80 | Iteration number: [120/565] 21% | Training loss: 0.6925704434514046
Epoch: 80 | Iteration number: [130/565] 23% | Training loss: 0.6921110377861903
Epoch: 80 | Iteration number: [140/565] 24% | Training loss: 0.6917625005756106
Epoch: 80 | Iteration number: [150/565] 26% | Training loss: 0.69142129778862
Epoch: 80 | Iteration number: [160/565] 28% | Training loss: 0.6911184567958116
Epoch: 80 | Iteration number: [170/565] 30% | Training loss: 0.6908488789025475
Epoch: 80 | Iteration number: [180/565] 31% | Training loss: 0.6906353563070298
Epoch: 80 | Iteration number: [190/565] 33% | Training loss: 0.6904241439543273
Epoch: 80 | Iteration number: [200/565] 35% | Training loss: 0.690227926671505
Epoch: 80 | Iteration number: [210/565] 37% | Training loss: 0.6900708524953751
Epoch: 80 | Iteration number: [220/565] 38% | Training loss: 0.6899272325364026
Epoch: 80 | Iteration number: [230/565] 40% | Training loss: 0.6897823797619861
Epoch: 80 | Iteration number: [240/565] 42% | Training loss: 0.6896487519145011
Epoch: 80 | Iteration number: [250/565] 44% | Training loss: 0.6895354344844818
Epoch: 80 | Iteration number: [260/565] 46% | Training loss: 0.6894322542043833
Epoch: 80 | Iteration number: [270/565] 47% | Training loss: 0.689335087272856
Epoch: 80 | Iteration number: [280/565] 49% | Training loss: 0.6892596180949893
Epoch: 80 | Iteration number: [290/565] 51% | Training loss: 0.6891574691081869
Epoch: 80 | Iteration number: [300/565] 53% | Training loss: 0.689069394270579
Epoch: 80 | Iteration number: [310/565] 54% | Training loss: 0.6889957799065498
Epoch: 80 | Iteration number: [320/565] 56% | Training loss: 0.688905649073422
Epoch: 80 | Iteration number: [330/565] 58% | Training loss: 0.6888424311623429
Epoch: 80 | Iteration number: [340/565] 60% | Training loss: 0.688778683718513
Epoch: 80 | Iteration number: [350/565] 61% | Training loss: 0.6887303049223764
Epoch: 80 | Iteration number: [360/565] 63% | Training loss: 0.6886809503038724
Epoch: 80 | Iteration number: [370/565] 65% | Training loss: 0.6886271462247179
Epoch: 80 | Iteration number: [380/565] 67% | Training loss: 0.6885857296617408
Epoch: 80 | Iteration number: [390/565] 69% | Training loss: 0.6885426733738337
Epoch: 80 | Iteration number: [400/565] 70% | Training loss: 0.6884883305430413
Epoch: 80 | Iteration number: [410/565] 72% | Training loss: 0.6884589218511814
Epoch: 80 | Iteration number: [420/565] 74% | Training loss: 0.6884180107286998
Epoch: 80 | Iteration number: [430/565] 76% | Training loss: 0.6883808382721834
Epoch: 80 | Iteration number: [440/565] 77% | Training loss: 0.6883452679623258
Epoch: 80 | Iteration number: [450/565] 79% | Training loss: 0.6883119126160939
Epoch: 80 | Iteration number: [460/565] 81% | Training loss: 0.688275831549064
Epoch: 80 | Iteration number: [470/565] 83% | Training loss: 0.6882451994622008
Epoch: 80 | Iteration number: [480/565] 84% | Training loss: 0.6882063167790572
Epoch: 80 | Iteration number: [490/565] 86% | Training loss: 0.6881825257320793
Epoch: 80 | Iteration number: [500/565] 88% | Training loss: 0.6881522340774536
Epoch: 80 | Iteration number: [510/565] 90% | Training loss: 0.6881269915431154
Epoch: 80 | Iteration number: [520/565] 92% | Training loss: 0.6880926181490604
Epoch: 80 | Iteration number: [530/565] 93% | Training loss: 0.6880738660974323
Epoch: 80 | Iteration number: [540/565] 95% | Training loss: 0.6880422607616142
Epoch: 80 | Iteration number: [550/565] 97% | Training loss: 0.6880230894955722
Epoch: 80 | Iteration number: [560/565] 99% | Training loss: 0.6880018103335585

 End of epoch: 80 | Train Loss: 0.6867734479693185 | Training Time: 90 

 End of epoch: 80 | Eval Loss: 0.6900079761232648 | Evaluating Time: 6 
Epoch: 81 | Iteration number: [10/565] 1% | Training loss: 0.7551400184631347
Epoch: 81 | Iteration number: [20/565] 3% | Training loss: 0.720901620388031
Epoch: 81 | Iteration number: [30/565] 5% | Training loss: 0.7095252553621928
Epoch: 81 | Iteration number: [40/565] 7% | Training loss: 0.7038538292050361
Epoch: 81 | Iteration number: [50/565] 8% | Training loss: 0.7004344594478608
Epoch: 81 | Iteration number: [60/565] 10% | Training loss: 0.6981455425421397
Epoch: 81 | Iteration number: [70/565] 12% | Training loss: 0.6965010855879102
Epoch: 81 | Iteration number: [80/565] 14% | Training loss: 0.6952928200364112
Epoch: 81 | Iteration number: [90/565] 15% | Training loss: 0.6943537069691552
Epoch: 81 | Iteration number: [100/565] 17% | Training loss: 0.6935331827402115
Epoch: 81 | Iteration number: [110/565] 19% | Training loss: 0.6929341186176646
Epoch: 81 | Iteration number: [120/565] 21% | Training loss: 0.6924572870135307
Epoch: 81 | Iteration number: [130/565] 23% | Training loss: 0.6920125168103438
Epoch: 81 | Iteration number: [140/565] 24% | Training loss: 0.6916246086359024
Epoch: 81 | Iteration number: [150/565] 26% | Training loss: 0.6913120949268341
Epoch: 81 | Iteration number: [160/565] 28% | Training loss: 0.6910299349576234
Epoch: 81 | Iteration number: [170/565] 30% | Training loss: 0.6907566161716685
Epoch: 81 | Iteration number: [180/565] 31% | Training loss: 0.6905205524630017
Epoch: 81 | Iteration number: [190/565] 33% | Training loss: 0.6903065286184612
Epoch: 81 | Iteration number: [200/565] 35% | Training loss: 0.6901409789919853
Epoch: 81 | Iteration number: [210/565] 37% | Training loss: 0.6899815831865583
Epoch: 81 | Iteration number: [220/565] 38% | Training loss: 0.6898352696136995
Epoch: 81 | Iteration number: [230/565] 40% | Training loss: 0.6897085226100425
Epoch: 81 | Iteration number: [240/565] 42% | Training loss: 0.6895832009613514
Epoch: 81 | Iteration number: [250/565] 44% | Training loss: 0.6894868466854095
Epoch: 81 | Iteration number: [260/565] 46% | Training loss: 0.6893825730452171
Epoch: 81 | Iteration number: [270/565] 47% | Training loss: 0.6892883978508136
Epoch: 81 | Iteration number: [280/565] 49% | Training loss: 0.689179336811815
Epoch: 81 | Iteration number: [290/565] 51% | Training loss: 0.6891047506496824
Epoch: 81 | Iteration number: [300/565] 53% | Training loss: 0.6890418926874796
Epoch: 81 | Iteration number: [310/565] 54% | Training loss: 0.6889767018056685
Epoch: 81 | Iteration number: [320/565] 56% | Training loss: 0.6889060216024518
Epoch: 81 | Iteration number: [330/565] 58% | Training loss: 0.6888338332826441
Epoch: 81 | Iteration number: [340/565] 60% | Training loss: 0.6887733520830379
Epoch: 81 | Iteration number: [350/565] 61% | Training loss: 0.6887049770355225
Epoch: 81 | Iteration number: [360/565] 63% | Training loss: 0.68865045822329
Epoch: 81 | Iteration number: [370/565] 65% | Training loss: 0.6886085681013159
Epoch: 81 | Iteration number: [380/565] 67% | Training loss: 0.6885597443894336
Epoch: 81 | Iteration number: [390/565] 69% | Training loss: 0.6885327360568902
Epoch: 81 | Iteration number: [400/565] 70% | Training loss: 0.6884839636087418
Epoch: 81 | Iteration number: [410/565] 72% | Training loss: 0.6884355178693445
Epoch: 81 | Iteration number: [420/565] 74% | Training loss: 0.6883968996150153
Epoch: 81 | Iteration number: [430/565] 76% | Training loss: 0.6883575828962548
Epoch: 81 | Iteration number: [440/565] 77% | Training loss: 0.6883256183429198
Epoch: 81 | Iteration number: [450/565] 79% | Training loss: 0.6882839202880859
Epoch: 81 | Iteration number: [460/565] 81% | Training loss: 0.6882539154394813
Epoch: 81 | Iteration number: [470/565] 83% | Training loss: 0.6882271192175277
Epoch: 81 | Iteration number: [480/565] 84% | Training loss: 0.6881919992466767
Epoch: 81 | Iteration number: [490/565] 86% | Training loss: 0.6881703407180553
Epoch: 81 | Iteration number: [500/565] 88% | Training loss: 0.6881461110115051
Epoch: 81 | Iteration number: [510/565] 90% | Training loss: 0.6881185116721135
Epoch: 81 | Iteration number: [520/565] 92% | Training loss: 0.6880887619577921
Epoch: 81 | Iteration number: [530/565] 93% | Training loss: 0.6880626080171117
Epoch: 81 | Iteration number: [540/565] 95% | Training loss: 0.6880444770609891
Epoch: 81 | Iteration number: [550/565] 97% | Training loss: 0.6880186726830222
Epoch: 81 | Iteration number: [560/565] 99% | Training loss: 0.6879961701376097

 End of epoch: 81 | Train Loss: 0.6867689261394264 | Training Time: 91 

 End of epoch: 81 | Eval Loss: 0.6901242392403739 | Evaluating Time: 6 
Epoch: 82 | Iteration number: [10/565] 1% | Training loss: 0.7547545015811921
Epoch: 82 | Iteration number: [20/565] 3% | Training loss: 0.720843380689621
Epoch: 82 | Iteration number: [30/565] 5% | Training loss: 0.709416514635086
Epoch: 82 | Iteration number: [40/565] 7% | Training loss: 0.7037709891796112
Epoch: 82 | Iteration number: [50/565] 8% | Training loss: 0.7001711010932923
Epoch: 82 | Iteration number: [60/565] 10% | Training loss: 0.6980048636595408
Epoch: 82 | Iteration number: [70/565] 12% | Training loss: 0.6963749740804944
Epoch: 82 | Iteration number: [80/565] 14% | Training loss: 0.6951519243419171
Epoch: 82 | Iteration number: [90/565] 15% | Training loss: 0.6942081034183503
Epoch: 82 | Iteration number: [100/565] 17% | Training loss: 0.6934502840042114
Epoch: 82 | Iteration number: [110/565] 19% | Training loss: 0.6928386438976635
Epoch: 82 | Iteration number: [120/565] 21% | Training loss: 0.6923719634612401
Epoch: 82 | Iteration number: [130/565] 23% | Training loss: 0.6919429169251369
Epoch: 82 | Iteration number: [140/565] 24% | Training loss: 0.6915587186813354
Epoch: 82 | Iteration number: [150/565] 26% | Training loss: 0.6911919462680817
Epoch: 82 | Iteration number: [160/565] 28% | Training loss: 0.690906110405922
Epoch: 82 | Iteration number: [170/565] 30% | Training loss: 0.6906646763577181
Epoch: 82 | Iteration number: [180/565] 31% | Training loss: 0.6904650224579705
Epoch: 82 | Iteration number: [190/565] 33% | Training loss: 0.6902744798283827
Epoch: 82 | Iteration number: [200/565] 35% | Training loss: 0.6901174053549767
Epoch: 82 | Iteration number: [210/565] 37% | Training loss: 0.689957620984032
Epoch: 82 | Iteration number: [220/565] 38% | Training loss: 0.6898140433159742
Epoch: 82 | Iteration number: [230/565] 40% | Training loss: 0.6896761702454608
Epoch: 82 | Iteration number: [240/565] 42% | Training loss: 0.6895642690360546
Epoch: 82 | Iteration number: [250/565] 44% | Training loss: 0.6894559133052826
Epoch: 82 | Iteration number: [260/565] 46% | Training loss: 0.6893572018696712
Epoch: 82 | Iteration number: [270/565] 47% | Training loss: 0.6892580498147893
Epoch: 82 | Iteration number: [280/565] 49% | Training loss: 0.6891747059566634
Epoch: 82 | Iteration number: [290/565] 51% | Training loss: 0.6890961677863681
Epoch: 82 | Iteration number: [300/565] 53% | Training loss: 0.6890205109119415
Epoch: 82 | Iteration number: [310/565] 54% | Training loss: 0.6889519212707397
Epoch: 82 | Iteration number: [320/565] 56% | Training loss: 0.6888867227360607
Epoch: 82 | Iteration number: [330/565] 58% | Training loss: 0.6888227598233656
Epoch: 82 | Iteration number: [340/565] 60% | Training loss: 0.6887611019260743
Epoch: 82 | Iteration number: [350/565] 61% | Training loss: 0.6887079051562718
Epoch: 82 | Iteration number: [360/565] 63% | Training loss: 0.6886504463023609
Epoch: 82 | Iteration number: [370/565] 65% | Training loss: 0.6885951414301589
Epoch: 82 | Iteration number: [380/565] 67% | Training loss: 0.6885423451662064
Epoch: 82 | Iteration number: [390/565] 69% | Training loss: 0.6884936954730596
Epoch: 82 | Iteration number: [400/565] 70% | Training loss: 0.6884460280835628
Epoch: 82 | Iteration number: [410/565] 72% | Training loss: 0.6884103854981865
Epoch: 82 | Iteration number: [420/565] 74% | Training loss: 0.6883743393988836
Epoch: 82 | Iteration number: [430/565] 76% | Training loss: 0.6883401748745941
Epoch: 82 | Iteration number: [440/565] 77% | Training loss: 0.6883030180226672
Epoch: 82 | Iteration number: [450/565] 79% | Training loss: 0.6882659880320231
Epoch: 82 | Iteration number: [460/565] 81% | Training loss: 0.6882302251846893
Epoch: 82 | Iteration number: [470/565] 83% | Training loss: 0.6882013719132606
Epoch: 82 | Iteration number: [480/565] 84% | Training loss: 0.6881692931056023
Epoch: 82 | Iteration number: [490/565] 86% | Training loss: 0.6881404177266724
Epoch: 82 | Iteration number: [500/565] 88% | Training loss: 0.6881182043552398
Epoch: 82 | Iteration number: [510/565] 90% | Training loss: 0.6880844602397844
Epoch: 82 | Iteration number: [520/565] 92% | Training loss: 0.6880618520654165
Epoch: 82 | Iteration number: [530/565] 93% | Training loss: 0.6880390952218254
Epoch: 82 | Iteration number: [540/565] 95% | Training loss: 0.6880174066181536
Epoch: 82 | Iteration number: [550/565] 97% | Training loss: 0.6879998125813224
Epoch: 82 | Iteration number: [560/565] 99% | Training loss: 0.6879845352045127

 End of epoch: 82 | Train Loss: 0.6867651435126245 | Training Time: 90 

 End of epoch: 82 | Eval Loss: 0.6901203138487679 | Evaluating Time: 6 
Epoch: 83 | Iteration number: [10/565] 1% | Training loss: 0.7552226543426513
Epoch: 83 | Iteration number: [20/565] 3% | Training loss: 0.7209740281105042
Epoch: 83 | Iteration number: [30/565] 5% | Training loss: 0.7095192849636078
Epoch: 83 | Iteration number: [40/565] 7% | Training loss: 0.7038694649934769
Epoch: 83 | Iteration number: [50/565] 8% | Training loss: 0.7004208552837372
Epoch: 83 | Iteration number: [60/565] 10% | Training loss: 0.6981804996728898
Epoch: 83 | Iteration number: [70/565] 12% | Training loss: 0.6964984587260655
Epoch: 83 | Iteration number: [80/565] 14% | Training loss: 0.6952896445989609
Epoch: 83 | Iteration number: [90/565] 15% | Training loss: 0.6943225688404507
Epoch: 83 | Iteration number: [100/565] 17% | Training loss: 0.6935868430137634
Epoch: 83 | Iteration number: [110/565] 19% | Training loss: 0.6929118866270239
Epoch: 83 | Iteration number: [120/565] 21% | Training loss: 0.6923724705974261
Epoch: 83 | Iteration number: [130/565] 23% | Training loss: 0.6918787140112657
Epoch: 83 | Iteration number: [140/565] 24% | Training loss: 0.6915122176919665
Epoch: 83 | Iteration number: [150/565] 26% | Training loss: 0.6911994008223216
Epoch: 83 | Iteration number: [160/565] 28% | Training loss: 0.6909308943897485
Epoch: 83 | Iteration number: [170/565] 30% | Training loss: 0.6906895641018362
Epoch: 83 | Iteration number: [180/565] 31% | Training loss: 0.6904849370320638
Epoch: 83 | Iteration number: [190/565] 33% | Training loss: 0.6903164691046665
Epoch: 83 | Iteration number: [200/565] 35% | Training loss: 0.6901437112689018
Epoch: 83 | Iteration number: [210/565] 37% | Training loss: 0.6899960449763707
Epoch: 83 | Iteration number: [220/565] 38% | Training loss: 0.6898761830546639
Epoch: 83 | Iteration number: [230/565] 40% | Training loss: 0.6897499351397804
Epoch: 83 | Iteration number: [240/565] 42% | Training loss: 0.6896219914158185
Epoch: 83 | Iteration number: [250/565] 44% | Training loss: 0.6895007526874543
Epoch: 83 | Iteration number: [260/565] 46% | Training loss: 0.6894019280488675
Epoch: 83 | Iteration number: [270/565] 47% | Training loss: 0.6893015574525904
Epoch: 83 | Iteration number: [280/565] 49% | Training loss: 0.6892205270273345
Epoch: 83 | Iteration number: [290/565] 51% | Training loss: 0.6891401675240747
Epoch: 83 | Iteration number: [300/565] 53% | Training loss: 0.6890586912631989
Epoch: 83 | Iteration number: [310/565] 54% | Training loss: 0.6889891332195651
Epoch: 83 | Iteration number: [320/565] 56% | Training loss: 0.6889253940433264
Epoch: 83 | Iteration number: [330/565] 58% | Training loss: 0.6888547942493901
Epoch: 83 | Iteration number: [340/565] 60% | Training loss: 0.6887837452047011
Epoch: 83 | Iteration number: [350/565] 61% | Training loss: 0.6887226242678506
Epoch: 83 | Iteration number: [360/565] 63% | Training loss: 0.6886804062459204
Epoch: 83 | Iteration number: [370/565] 65% | Training loss: 0.6886377829152185
Epoch: 83 | Iteration number: [380/565] 67% | Training loss: 0.6885920595181616
Epoch: 83 | Iteration number: [390/565] 69% | Training loss: 0.6885472039381663
Epoch: 83 | Iteration number: [400/565] 70% | Training loss: 0.688500447422266
Epoch: 83 | Iteration number: [410/565] 72% | Training loss: 0.6884688329405901
Epoch: 83 | Iteration number: [420/565] 74% | Training loss: 0.6884229640165965
Epoch: 83 | Iteration number: [430/565] 76% | Training loss: 0.6883852996105372
Epoch: 83 | Iteration number: [440/565] 77% | Training loss: 0.6883481738242236
Epoch: 83 | Iteration number: [450/565] 79% | Training loss: 0.6883224011792077
Epoch: 83 | Iteration number: [460/565] 81% | Training loss: 0.6882872480413188
Epoch: 83 | Iteration number: [470/565] 83% | Training loss: 0.6882528589126912
Epoch: 83 | Iteration number: [480/565] 84% | Training loss: 0.6882244134942691
Epoch: 83 | Iteration number: [490/565] 86% | Training loss: 0.6881985005067319
Epoch: 83 | Iteration number: [500/565] 88% | Training loss: 0.6881625759601593
Epoch: 83 | Iteration number: [510/565] 90% | Training loss: 0.6881323251069761
Epoch: 83 | Iteration number: [520/565] 92% | Training loss: 0.688103295977299
Epoch: 83 | Iteration number: [530/565] 93% | Training loss: 0.6880876164391355
Epoch: 83 | Iteration number: [540/565] 95% | Training loss: 0.6880699739412025
Epoch: 83 | Iteration number: [550/565] 97% | Training loss: 0.6880397267775102
Epoch: 83 | Iteration number: [560/565] 99% | Training loss: 0.6880070749138083

 End of epoch: 83 | Train Loss: 0.6867758860630272 | Training Time: 90 

 End of epoch: 83 | Eval Loss: 0.6897327899932861 | Evaluating Time: 5 
Epoch: 84 | Iteration number: [10/565] 1% | Training loss: 0.7551874160766602
Epoch: 84 | Iteration number: [20/565] 3% | Training loss: 0.7209940820932388
Epoch: 84 | Iteration number: [30/565] 5% | Training loss: 0.7097517887751261
Epoch: 84 | Iteration number: [40/565] 7% | Training loss: 0.703975385427475
Epoch: 84 | Iteration number: [50/565] 8% | Training loss: 0.7006610202789306
Epoch: 84 | Iteration number: [60/565] 10% | Training loss: 0.6983307590087254
Epoch: 84 | Iteration number: [70/565] 12% | Training loss: 0.6966869711875916
Epoch: 84 | Iteration number: [80/565] 14% | Training loss: 0.6954656414687633
Epoch: 84 | Iteration number: [90/565] 15% | Training loss: 0.6944988230864207
Epoch: 84 | Iteration number: [100/565] 17% | Training loss: 0.6937233364582062
Epoch: 84 | Iteration number: [110/565] 19% | Training loss: 0.6930778557604009
Epoch: 84 | Iteration number: [120/565] 21% | Training loss: 0.6925678089261055
Epoch: 84 | Iteration number: [130/565] 23% | Training loss: 0.6921360671520234
Epoch: 84 | Iteration number: [140/565] 24% | Training loss: 0.6917563408613205
Epoch: 84 | Iteration number: [150/565] 26% | Training loss: 0.6914282457033794
Epoch: 84 | Iteration number: [160/565] 28% | Training loss: 0.6911441776901484
Epoch: 84 | Iteration number: [170/565] 30% | Training loss: 0.6908713568659389
Epoch: 84 | Iteration number: [180/565] 31% | Training loss: 0.6906558911005656
Epoch: 84 | Iteration number: [190/565] 33% | Training loss: 0.6904677290665476
Epoch: 84 | Iteration number: [200/565] 35% | Training loss: 0.6902666053175927
Epoch: 84 | Iteration number: [210/565] 37% | Training loss: 0.6901056366307395
Epoch: 84 | Iteration number: [220/565] 38% | Training loss: 0.6899542984637347
Epoch: 84 | Iteration number: [230/565] 40% | Training loss: 0.6898013589174851
Epoch: 84 | Iteration number: [240/565] 42% | Training loss: 0.6896862300733725
Epoch: 84 | Iteration number: [250/565] 44% | Training loss: 0.6895594854354858
Epoch: 84 | Iteration number: [260/565] 46% | Training loss: 0.6894751452482664
Epoch: 84 | Iteration number: [270/565] 47% | Training loss: 0.6893752159895721
Epoch: 84 | Iteration number: [280/565] 49% | Training loss: 0.6892833675657
Epoch: 84 | Iteration number: [290/565] 51% | Training loss: 0.6891734852873046
Epoch: 84 | Iteration number: [300/565] 53% | Training loss: 0.6890968137979507
Epoch: 84 | Iteration number: [310/565] 54% | Training loss: 0.6890009309014966
Epoch: 84 | Iteration number: [320/565] 56% | Training loss: 0.6889349147677422
Epoch: 84 | Iteration number: [330/565] 58% | Training loss: 0.6888657320629467
Epoch: 84 | Iteration number: [340/565] 60% | Training loss: 0.6887957881478702
Epoch: 84 | Iteration number: [350/565] 61% | Training loss: 0.6887360768658775
Epoch: 84 | Iteration number: [360/565] 63% | Training loss: 0.6886893338627286
Epoch: 84 | Iteration number: [370/565] 65% | Training loss: 0.6886430904671953
Epoch: 84 | Iteration number: [380/565] 67% | Training loss: 0.6885898804978321
Epoch: 84 | Iteration number: [390/565] 69% | Training loss: 0.6885375739672245
Epoch: 84 | Iteration number: [400/565] 70% | Training loss: 0.6884970566630364
Epoch: 84 | Iteration number: [410/565] 72% | Training loss: 0.6884441116961038
Epoch: 84 | Iteration number: [420/565] 74% | Training loss: 0.6883992102884111
Epoch: 84 | Iteration number: [430/565] 76% | Training loss: 0.6883604508499767
Epoch: 84 | Iteration number: [440/565] 77% | Training loss: 0.68832053352486
Epoch: 84 | Iteration number: [450/565] 79% | Training loss: 0.688285039001041
Epoch: 84 | Iteration number: [460/565] 81% | Training loss: 0.6882578510305156
Epoch: 84 | Iteration number: [470/565] 83% | Training loss: 0.6882209791782055
Epoch: 84 | Iteration number: [480/565] 84% | Training loss: 0.6881946045905352
Epoch: 84 | Iteration number: [490/565] 86% | Training loss: 0.6881653088696149
Epoch: 84 | Iteration number: [500/565] 88% | Training loss: 0.6881377410888672
Epoch: 84 | Iteration number: [510/565] 90% | Training loss: 0.6881205909392413
Epoch: 84 | Iteration number: [520/565] 92% | Training loss: 0.6880981917564686
Epoch: 84 | Iteration number: [530/565] 93% | Training loss: 0.6880629385417363
Epoch: 84 | Iteration number: [540/565] 95% | Training loss: 0.6880401646649396
Epoch: 84 | Iteration number: [550/565] 97% | Training loss: 0.6880199908126484
Epoch: 84 | Iteration number: [560/565] 99% | Training loss: 0.6880079518471446

 End of epoch: 84 | Train Loss: 0.6867797982376234 | Training Time: 91 

 End of epoch: 84 | Eval Loss: 0.6904441543987819 | Evaluating Time: 6 
Epoch: 85 | Iteration number: [10/565] 1% | Training loss: 0.7550598382949829
Epoch: 85 | Iteration number: [20/565] 3% | Training loss: 0.7209412187337876
Epoch: 85 | Iteration number: [30/565] 5% | Training loss: 0.7094129423300425
Epoch: 85 | Iteration number: [40/565] 7% | Training loss: 0.7037293374538421
Epoch: 85 | Iteration number: [50/565] 8% | Training loss: 0.7002739298343659
Epoch: 85 | Iteration number: [60/565] 10% | Training loss: 0.6979468981424968
Epoch: 85 | Iteration number: [70/565] 12% | Training loss: 0.6963662326335907
Epoch: 85 | Iteration number: [80/565] 14% | Training loss: 0.69519187733531
Epoch: 85 | Iteration number: [90/565] 15% | Training loss: 0.6942494405640496
Epoch: 85 | Iteration number: [100/565] 17% | Training loss: 0.6935132652521133
Epoch: 85 | Iteration number: [110/565] 19% | Training loss: 0.6928943487730893
Epoch: 85 | Iteration number: [120/565] 21% | Training loss: 0.6923760185639064
Epoch: 85 | Iteration number: [130/565] 23% | Training loss: 0.6919091848226694
Epoch: 85 | Iteration number: [140/565] 24% | Training loss: 0.6915477735655648
Epoch: 85 | Iteration number: [150/565] 26% | Training loss: 0.691246102253596
Epoch: 85 | Iteration number: [160/565] 28% | Training loss: 0.6909358348697424
Epoch: 85 | Iteration number: [170/565] 30% | Training loss: 0.6907220412703121
Epoch: 85 | Iteration number: [180/565] 31% | Training loss: 0.690517023536894
Epoch: 85 | Iteration number: [190/565] 33% | Training loss: 0.6903353615810996
Epoch: 85 | Iteration number: [200/565] 35% | Training loss: 0.690148546397686
Epoch: 85 | Iteration number: [210/565] 37% | Training loss: 0.6899884289219266
Epoch: 85 | Iteration number: [220/565] 38% | Training loss: 0.689860507033088
Epoch: 85 | Iteration number: [230/565] 40% | Training loss: 0.6897193592527638
Epoch: 85 | Iteration number: [240/565] 42% | Training loss: 0.6896037437021733
Epoch: 85 | Iteration number: [250/565] 44% | Training loss: 0.6894991023540497
Epoch: 85 | Iteration number: [260/565] 46% | Training loss: 0.6893843740224839
Epoch: 85 | Iteration number: [270/565] 47% | Training loss: 0.6892804110491717
Epoch: 85 | Iteration number: [280/565] 49% | Training loss: 0.6891975145254816
Epoch: 85 | Iteration number: [290/565] 51% | Training loss: 0.6891067599428111
Epoch: 85 | Iteration number: [300/565] 53% | Training loss: 0.689020387729009
Epoch: 85 | Iteration number: [310/565] 54% | Training loss: 0.6889386999991632
Epoch: 85 | Iteration number: [320/565] 56% | Training loss: 0.688884293474257
Epoch: 85 | Iteration number: [330/565] 58% | Training loss: 0.6888037728540826
Epoch: 85 | Iteration number: [340/565] 60% | Training loss: 0.688751260322683
Epoch: 85 | Iteration number: [350/565] 61% | Training loss: 0.6887026151588985
Epoch: 85 | Iteration number: [360/565] 63% | Training loss: 0.6886444432867898
Epoch: 85 | Iteration number: [370/565] 65% | Training loss: 0.6885936058856346
Epoch: 85 | Iteration number: [380/565] 67% | Training loss: 0.6885513368405793
Epoch: 85 | Iteration number: [390/565] 69% | Training loss: 0.6885025802331093
Epoch: 85 | Iteration number: [400/565] 70% | Training loss: 0.688464678376913
Epoch: 85 | Iteration number: [410/565] 72% | Training loss: 0.688420253410572
Epoch: 85 | Iteration number: [420/565] 74% | Training loss: 0.688387348822185
Epoch: 85 | Iteration number: [430/565] 76% | Training loss: 0.6883529918138371
Epoch: 85 | Iteration number: [440/565] 77% | Training loss: 0.6883092847737399
Epoch: 85 | Iteration number: [450/565] 79% | Training loss: 0.6882727034886678
Epoch: 85 | Iteration number: [460/565] 81% | Training loss: 0.6882302752007609
Epoch: 85 | Iteration number: [470/565] 83% | Training loss: 0.6882030251178336
Epoch: 85 | Iteration number: [480/565] 84% | Training loss: 0.6881760248293479
Epoch: 85 | Iteration number: [490/565] 86% | Training loss: 0.6881536829228304
Epoch: 85 | Iteration number: [500/565] 88% | Training loss: 0.6881250525712967
Epoch: 85 | Iteration number: [510/565] 90% | Training loss: 0.6880990425745647
Epoch: 85 | Iteration number: [520/565] 92% | Training loss: 0.6880657749680372
Epoch: 85 | Iteration number: [530/565] 93% | Training loss: 0.6880463211041576
Epoch: 85 | Iteration number: [540/565] 95% | Training loss: 0.688028284907341
Epoch: 85 | Iteration number: [550/565] 97% | Training loss: 0.688012526252053
Epoch: 85 | Iteration number: [560/565] 99% | Training loss: 0.687999309280089

 End of epoch: 85 | Train Loss: 0.6867708649255533 | Training Time: 88 

 End of epoch: 85 | Eval Loss: 0.6898080876895359 | Evaluating Time: 6 
Epoch: 86 | Iteration number: [10/565] 1% | Training loss: 0.7556845545768738
Epoch: 86 | Iteration number: [20/565] 3% | Training loss: 0.7212931841611863
Epoch: 86 | Iteration number: [30/565] 5% | Training loss: 0.709694908062617
Epoch: 86 | Iteration number: [40/565] 7% | Training loss: 0.7040228396654129
Epoch: 86 | Iteration number: [50/565] 8% | Training loss: 0.7005952310562134
Epoch: 86 | Iteration number: [60/565] 10% | Training loss: 0.6982919265826543
Epoch: 86 | Iteration number: [70/565] 12% | Training loss: 0.6966331728867122
Epoch: 86 | Iteration number: [80/565] 14% | Training loss: 0.6953844942152501
Epoch: 86 | Iteration number: [90/565] 15% | Training loss: 0.6944310082329644
Epoch: 86 | Iteration number: [100/565] 17% | Training loss: 0.6936053651571273
Epoch: 86 | Iteration number: [110/565] 19% | Training loss: 0.6929698803208091
Epoch: 86 | Iteration number: [120/565] 21% | Training loss: 0.6924911181131999
Epoch: 86 | Iteration number: [130/565] 23% | Training loss: 0.6920582537467663
Epoch: 86 | Iteration number: [140/565] 24% | Training loss: 0.691713092156819
Epoch: 86 | Iteration number: [150/565] 26% | Training loss: 0.6914079022407532
Epoch: 86 | Iteration number: [160/565] 28% | Training loss: 0.691111983731389
Epoch: 86 | Iteration number: [170/565] 30% | Training loss: 0.6908365982420305
Epoch: 86 | Iteration number: [180/565] 31% | Training loss: 0.6906041052606371
Epoch: 86 | Iteration number: [190/565] 33% | Training loss: 0.6903767268908652
Epoch: 86 | Iteration number: [200/565] 35% | Training loss: 0.6901783913373947
Epoch: 86 | Iteration number: [210/565] 37% | Training loss: 0.6900086158797855
Epoch: 86 | Iteration number: [220/565] 38% | Training loss: 0.6898677704009143
Epoch: 86 | Iteration number: [230/565] 40% | Training loss: 0.6897295775620834
Epoch: 86 | Iteration number: [240/565] 42% | Training loss: 0.6895853879551093
Epoch: 86 | Iteration number: [250/565] 44% | Training loss: 0.6894878187179565
Epoch: 86 | Iteration number: [260/565] 46% | Training loss: 0.6893925118904848
Epoch: 86 | Iteration number: [270/565] 47% | Training loss: 0.6892981368082541
Epoch: 86 | Iteration number: [280/565] 49% | Training loss: 0.6892060631087848
Epoch: 86 | Iteration number: [290/565] 51% | Training loss: 0.6891236911559927
Epoch: 86 | Iteration number: [300/565] 53% | Training loss: 0.6890409445762634
Epoch: 86 | Iteration number: [310/565] 54% | Training loss: 0.6889634395799329
Epoch: 86 | Iteration number: [320/565] 56% | Training loss: 0.6888890391215682
Epoch: 86 | Iteration number: [330/565] 58% | Training loss: 0.6888097837115779
Epoch: 86 | Iteration number: [340/565] 60% | Training loss: 0.6887650048031526
Epoch: 86 | Iteration number: [350/565] 61% | Training loss: 0.6887199238368443
Epoch: 86 | Iteration number: [360/565] 63% | Training loss: 0.6886605635285378
Epoch: 86 | Iteration number: [370/565] 65% | Training loss: 0.6886198390174556
Epoch: 86 | Iteration number: [380/565] 67% | Training loss: 0.6885745388896842
Epoch: 86 | Iteration number: [390/565] 69% | Training loss: 0.6885187738981002
Epoch: 86 | Iteration number: [400/565] 70% | Training loss: 0.6884699626266957
Epoch: 86 | Iteration number: [410/565] 72% | Training loss: 0.6884362920028407
Epoch: 86 | Iteration number: [420/565] 74% | Training loss: 0.6883938166357222
Epoch: 86 | Iteration number: [430/565] 76% | Training loss: 0.6883615093175754
Epoch: 86 | Iteration number: [440/565] 77% | Training loss: 0.6883242867209695
Epoch: 86 | Iteration number: [450/565] 79% | Training loss: 0.6882979044649336
Epoch: 86 | Iteration number: [460/565] 81% | Training loss: 0.6882616329452266
Epoch: 86 | Iteration number: [470/565] 83% | Training loss: 0.6882330850083778
Epoch: 86 | Iteration number: [480/565] 84% | Training loss: 0.6881953939795494
Epoch: 86 | Iteration number: [490/565] 86% | Training loss: 0.6881638867514474
Epoch: 86 | Iteration number: [500/565] 88% | Training loss: 0.6881298785209655
Epoch: 86 | Iteration number: [510/565] 90% | Training loss: 0.6881043681911394
Epoch: 86 | Iteration number: [520/565] 92% | Training loss: 0.6880792518074695
Epoch: 86 | Iteration number: [530/565] 93% | Training loss: 0.6880583948684189
Epoch: 86 | Iteration number: [540/565] 95% | Training loss: 0.6880301018555959
Epoch: 86 | Iteration number: [550/565] 97% | Training loss: 0.6880232851071791
Epoch: 86 | Iteration number: [560/565] 99% | Training loss: 0.6879912738289152

 End of epoch: 86 | Train Loss: 0.6867601543401195 | Training Time: 89 

 End of epoch: 86 | Eval Loss: 0.6901488644736153 | Evaluating Time: 6 
Epoch: 87 | Iteration number: [10/565] 1% | Training loss: 0.7556040585041046
Epoch: 87 | Iteration number: [20/565] 3% | Training loss: 0.7214050650596618
Epoch: 87 | Iteration number: [30/565] 5% | Training loss: 0.7097861111164093
Epoch: 87 | Iteration number: [40/565] 7% | Training loss: 0.7040486291050911
Epoch: 87 | Iteration number: [50/565] 8% | Training loss: 0.7005529141426087
Epoch: 87 | Iteration number: [60/565] 10% | Training loss: 0.6982347110907237
Epoch: 87 | Iteration number: [70/565] 12% | Training loss: 0.6966349993433271
Epoch: 87 | Iteration number: [80/565] 14% | Training loss: 0.6953822717070579
Epoch: 87 | Iteration number: [90/565] 15% | Training loss: 0.6944614675309922
Epoch: 87 | Iteration number: [100/565] 17% | Training loss: 0.6936589241027832
Epoch: 87 | Iteration number: [110/565] 19% | Training loss: 0.6930434438315305
Epoch: 87 | Iteration number: [120/565] 21% | Training loss: 0.6925024350484212
Epoch: 87 | Iteration number: [130/565] 23% | Training loss: 0.6920544395079979
Epoch: 87 | Iteration number: [140/565] 24% | Training loss: 0.6916427442005703
Epoch: 87 | Iteration number: [150/565] 26% | Training loss: 0.6913103159268698
Epoch: 87 | Iteration number: [160/565] 28% | Training loss: 0.6910062592476607
Epoch: 87 | Iteration number: [170/565] 30% | Training loss: 0.6907435294459848
Epoch: 87 | Iteration number: [180/565] 31% | Training loss: 0.6905389000972112
Epoch: 87 | Iteration number: [190/565] 33% | Training loss: 0.6903641556438647
Epoch: 87 | Iteration number: [200/565] 35% | Training loss: 0.6901937836408615
Epoch: 87 | Iteration number: [210/565] 37% | Training loss: 0.6900319252695356
Epoch: 87 | Iteration number: [220/565] 38% | Training loss: 0.6898802711205049
Epoch: 87 | Iteration number: [230/565] 40% | Training loss: 0.6897663577743198
Epoch: 87 | Iteration number: [240/565] 42% | Training loss: 0.6896417851249377
Epoch: 87 | Iteration number: [250/565] 44% | Training loss: 0.6895212070941925
Epoch: 87 | Iteration number: [260/565] 46% | Training loss: 0.6894204121369581
Epoch: 87 | Iteration number: [270/565] 47% | Training loss: 0.6893182085620032
Epoch: 87 | Iteration number: [280/565] 49% | Training loss: 0.6892179244330952
Epoch: 87 | Iteration number: [290/565] 51% | Training loss: 0.6891252470427546
Epoch: 87 | Iteration number: [300/565] 53% | Training loss: 0.6890424869457881
Epoch: 87 | Iteration number: [310/565] 54% | Training loss: 0.6889846357607072
Epoch: 87 | Iteration number: [320/565] 56% | Training loss: 0.6889047602191567
Epoch: 87 | Iteration number: [330/565] 58% | Training loss: 0.6888521006613066
Epoch: 87 | Iteration number: [340/565] 60% | Training loss: 0.6888002423679127
Epoch: 87 | Iteration number: [350/565] 61% | Training loss: 0.6887413801465716
Epoch: 87 | Iteration number: [360/565] 63% | Training loss: 0.6886898760994276
Epoch: 87 | Iteration number: [370/565] 65% | Training loss: 0.6886322026317184
Epoch: 87 | Iteration number: [380/565] 67% | Training loss: 0.688582285611253
Epoch: 87 | Iteration number: [390/565] 69% | Training loss: 0.6885396216160212
Epoch: 87 | Iteration number: [400/565] 70% | Training loss: 0.6884915553033352
Epoch: 87 | Iteration number: [410/565] 72% | Training loss: 0.6884433489020277
Epoch: 87 | Iteration number: [420/565] 74% | Training loss: 0.6884023920411155
Epoch: 87 | Iteration number: [430/565] 76% | Training loss: 0.6883645922638649
Epoch: 87 | Iteration number: [440/565] 77% | Training loss: 0.688320697166703
Epoch: 87 | Iteration number: [450/565] 79% | Training loss: 0.6882860284381442
Epoch: 87 | Iteration number: [460/565] 81% | Training loss: 0.6882558860208677
Epoch: 87 | Iteration number: [470/565] 83% | Training loss: 0.6882215493537011
Epoch: 87 | Iteration number: [480/565] 84% | Training loss: 0.6881859711060921
Epoch: 87 | Iteration number: [490/565] 86% | Training loss: 0.6881499792848315
Epoch: 87 | Iteration number: [500/565] 88% | Training loss: 0.6881325522661209
Epoch: 87 | Iteration number: [510/565] 90% | Training loss: 0.6881116586572984
Epoch: 87 | Iteration number: [520/565] 92% | Training loss: 0.6880850362089964
Epoch: 87 | Iteration number: [530/565] 93% | Training loss: 0.6880634772327711
Epoch: 87 | Iteration number: [540/565] 95% | Training loss: 0.6880370261492552
Epoch: 87 | Iteration number: [550/565] 97% | Training loss: 0.6880141525918787
Epoch: 87 | Iteration number: [560/565] 99% | Training loss: 0.6879951380193233

 End of epoch: 87 | Train Loss: 0.6867642503924074 | Training Time: 90 

 End of epoch: 87 | Eval Loss: 0.6897679311888558 | Evaluating Time: 6 
Epoch: 88 | Iteration number: [10/565] 1% | Training loss: 0.7557375073432923
Epoch: 88 | Iteration number: [20/565] 3% | Training loss: 0.7212285369634628
Epoch: 88 | Iteration number: [30/565] 5% | Training loss: 0.7099260926246643
Epoch: 88 | Iteration number: [40/565] 7% | Training loss: 0.7042170405387879
Epoch: 88 | Iteration number: [50/565] 8% | Training loss: 0.7007688951492309
Epoch: 88 | Iteration number: [60/565] 10% | Training loss: 0.6984550565481186
Epoch: 88 | Iteration number: [70/565] 12% | Training loss: 0.696766814163753
Epoch: 88 | Iteration number: [80/565] 14% | Training loss: 0.6955220349133014
Epoch: 88 | Iteration number: [90/565] 15% | Training loss: 0.6945746699968974
Epoch: 88 | Iteration number: [100/565] 17% | Training loss: 0.6937925785779953
Epoch: 88 | Iteration number: [110/565] 19% | Training loss: 0.6931478012691844
Epoch: 88 | Iteration number: [120/565] 21% | Training loss: 0.6925846502184868
Epoch: 88 | Iteration number: [130/565] 23% | Training loss: 0.6921368012061486
Epoch: 88 | Iteration number: [140/565] 24% | Training loss: 0.6917388928788049
Epoch: 88 | Iteration number: [150/565] 26% | Training loss: 0.6913938677310943
Epoch: 88 | Iteration number: [160/565] 28% | Training loss: 0.6911171693354845
Epoch: 88 | Iteration number: [170/565] 30% | Training loss: 0.6908665604451123
Epoch: 88 | Iteration number: [180/565] 31% | Training loss: 0.6906357480420007
Epoch: 88 | Iteration number: [190/565] 33% | Training loss: 0.6904229330389123
Epoch: 88 | Iteration number: [200/565] 35% | Training loss: 0.6902396291494369
Epoch: 88 | Iteration number: [210/565] 37% | Training loss: 0.6900838772455852
Epoch: 88 | Iteration number: [220/565] 38% | Training loss: 0.6899276744235646
Epoch: 88 | Iteration number: [230/565] 40% | Training loss: 0.6897862185602602
Epoch: 88 | Iteration number: [240/565] 42% | Training loss: 0.6896410959462325
Epoch: 88 | Iteration number: [250/565] 44% | Training loss: 0.6895303571224213
Epoch: 88 | Iteration number: [260/565] 46% | Training loss: 0.6894188112937487
Epoch: 88 | Iteration number: [270/565] 47% | Training loss: 0.689327292530625
Epoch: 88 | Iteration number: [280/565] 49% | Training loss: 0.6892324790358544
Epoch: 88 | Iteration number: [290/565] 51% | Training loss: 0.6891573659304915
Epoch: 88 | Iteration number: [300/565] 53% | Training loss: 0.6890815921624501
Epoch: 88 | Iteration number: [310/565] 54% | Training loss: 0.6890096358714565
Epoch: 88 | Iteration number: [320/565] 56% | Training loss: 0.6889400307089091
Epoch: 88 | Iteration number: [330/565] 58% | Training loss: 0.6888741601597179
Epoch: 88 | Iteration number: [340/565] 60% | Training loss: 0.688807313933092
Epoch: 88 | Iteration number: [350/565] 61% | Training loss: 0.688727959905352
Epoch: 88 | Iteration number: [360/565] 63% | Training loss: 0.6886695191264153
Epoch: 88 | Iteration number: [370/565] 65% | Training loss: 0.6886252031132981
Epoch: 88 | Iteration number: [380/565] 67% | Training loss: 0.6885733841281189
Epoch: 88 | Iteration number: [390/565] 69% | Training loss: 0.688515030267911
Epoch: 88 | Iteration number: [400/565] 70% | Training loss: 0.688468227982521
Epoch: 88 | Iteration number: [410/565] 72% | Training loss: 0.6884259734211898
Epoch: 88 | Iteration number: [420/565] 74% | Training loss: 0.6883776825098764
Epoch: 88 | Iteration number: [430/565] 76% | Training loss: 0.6883365166741748
Epoch: 88 | Iteration number: [440/565] 77% | Training loss: 0.6883084668354554
Epoch: 88 | Iteration number: [450/565] 79% | Training loss: 0.6882704685793982
Epoch: 88 | Iteration number: [460/565] 81% | Training loss: 0.6882378906011581
Epoch: 88 | Iteration number: [470/565] 83% | Training loss: 0.6882004470267195
Epoch: 88 | Iteration number: [480/565] 84% | Training loss: 0.688174436117212
Epoch: 88 | Iteration number: [490/565] 86% | Training loss: 0.6881454168533793
Epoch: 88 | Iteration number: [500/565] 88% | Training loss: 0.6881163541078568
Epoch: 88 | Iteration number: [510/565] 90% | Training loss: 0.6880877255224714
Epoch: 88 | Iteration number: [520/565] 92% | Training loss: 0.6880658839757626
Epoch: 88 | Iteration number: [530/565] 93% | Training loss: 0.688035477332349
Epoch: 88 | Iteration number: [540/565] 95% | Training loss: 0.6880222493851627
Epoch: 88 | Iteration number: [550/565] 97% | Training loss: 0.6880023083903573
Epoch: 88 | Iteration number: [560/565] 99% | Training loss: 0.6879855443324362

 End of epoch: 88 | Train Loss: 0.6867597872177057 | Training Time: 89 

 End of epoch: 88 | Eval Loss: 0.6896076628140041 | Evaluating Time: 6 
Epoch: 89 | Iteration number: [10/565] 1% | Training loss: 0.7557104885578155
Epoch: 89 | Iteration number: [20/565] 3% | Training loss: 0.7212662130594254
Epoch: 89 | Iteration number: [30/565] 5% | Training loss: 0.7099496165911356
Epoch: 89 | Iteration number: [40/565] 7% | Training loss: 0.7042413368821144
Epoch: 89 | Iteration number: [50/565] 8% | Training loss: 0.7007576858997345
Epoch: 89 | Iteration number: [60/565] 10% | Training loss: 0.6983694364627202
Epoch: 89 | Iteration number: [70/565] 12% | Training loss: 0.6967262540544782
Epoch: 89 | Iteration number: [80/565] 14% | Training loss: 0.6954779006540776
Epoch: 89 | Iteration number: [90/565] 15% | Training loss: 0.6945479876465268
Epoch: 89 | Iteration number: [100/565] 17% | Training loss: 0.6937482327222824
Epoch: 89 | Iteration number: [110/565] 19% | Training loss: 0.6931050896644593
Epoch: 89 | Iteration number: [120/565] 21% | Training loss: 0.6925534908970197
Epoch: 89 | Iteration number: [130/565] 23% | Training loss: 0.6921325096717248
Epoch: 89 | Iteration number: [140/565] 24% | Training loss: 0.6917402837957655
Epoch: 89 | Iteration number: [150/565] 26% | Training loss: 0.6914199618498484
Epoch: 89 | Iteration number: [160/565] 28% | Training loss: 0.6911231797188521
Epoch: 89 | Iteration number: [170/565] 30% | Training loss: 0.6908629992428947
Epoch: 89 | Iteration number: [180/565] 31% | Training loss: 0.6906230274173949
Epoch: 89 | Iteration number: [190/565] 33% | Training loss: 0.6904155561798497
Epoch: 89 | Iteration number: [200/565] 35% | Training loss: 0.6902461439371109
Epoch: 89 | Iteration number: [210/565] 37% | Training loss: 0.690090787410736
Epoch: 89 | Iteration number: [220/565] 38% | Training loss: 0.6899308732964776
Epoch: 89 | Iteration number: [230/565] 40% | Training loss: 0.6898004811743031
Epoch: 89 | Iteration number: [240/565] 42% | Training loss: 0.6896728905538718
Epoch: 89 | Iteration number: [250/565] 44% | Training loss: 0.6895639936923981
Epoch: 89 | Iteration number: [260/565] 46% | Training loss: 0.6894615819820991
Epoch: 89 | Iteration number: [270/565] 47% | Training loss: 0.6893777677306423
Epoch: 89 | Iteration number: [280/565] 49% | Training loss: 0.6892928366150175
Epoch: 89 | Iteration number: [290/565] 51% | Training loss: 0.6892159182449867
Epoch: 89 | Iteration number: [300/565] 53% | Training loss: 0.6891206659873327
Epoch: 89 | Iteration number: [310/565] 54% | Training loss: 0.6890494179341101
Epoch: 89 | Iteration number: [320/565] 56% | Training loss: 0.6889616502448916
Epoch: 89 | Iteration number: [330/565] 58% | Training loss: 0.6888866359537298
Epoch: 89 | Iteration number: [340/565] 60% | Training loss: 0.6888118649230284
Epoch: 89 | Iteration number: [350/565] 61% | Training loss: 0.6887537922177996
Epoch: 89 | Iteration number: [360/565] 63% | Training loss: 0.6886974599626329
Epoch: 89 | Iteration number: [370/565] 65% | Training loss: 0.68864849676957
Epoch: 89 | Iteration number: [380/565] 67% | Training loss: 0.6885878520576577
Epoch: 89 | Iteration number: [390/565] 69% | Training loss: 0.6885516805526538
Epoch: 89 | Iteration number: [400/565] 70% | Training loss: 0.6885097847878933
Epoch: 89 | Iteration number: [410/565] 72% | Training loss: 0.6884696992432199
Epoch: 89 | Iteration number: [420/565] 74% | Training loss: 0.6884274083943595
Epoch: 89 | Iteration number: [430/565] 76% | Training loss: 0.6883807868458504
Epoch: 89 | Iteration number: [440/565] 77% | Training loss: 0.6883440841328013
Epoch: 89 | Iteration number: [450/565] 79% | Training loss: 0.6883163469367557
Epoch: 89 | Iteration number: [460/565] 81% | Training loss: 0.6882915929607724
Epoch: 89 | Iteration number: [470/565] 83% | Training loss: 0.6882444667055252
Epoch: 89 | Iteration number: [480/565] 84% | Training loss: 0.6882176781694095
Epoch: 89 | Iteration number: [490/565] 86% | Training loss: 0.6881881086193785
Epoch: 89 | Iteration number: [500/565] 88% | Training loss: 0.6881621879339218
Epoch: 89 | Iteration number: [510/565] 90% | Training loss: 0.6881321707192589
Epoch: 89 | Iteration number: [520/565] 92% | Training loss: 0.6880951532950768
Epoch: 89 | Iteration number: [530/565] 93% | Training loss: 0.6880649035831667
Epoch: 89 | Iteration number: [540/565] 95% | Training loss: 0.6880449832589538
Epoch: 89 | Iteration number: [550/565] 97% | Training loss: 0.6880167463692752
Epoch: 89 | Iteration number: [560/565] 99% | Training loss: 0.6879920344267573

 End of epoch: 89 | Train Loss: 0.6867642857332146 | Training Time: 90 

 End of epoch: 89 | Eval Loss: 0.690183332988194 | Evaluating Time: 5 
Epoch: 90 | Iteration number: [10/565] 1% | Training loss: 0.7555917382240296
Epoch: 90 | Iteration number: [20/565] 3% | Training loss: 0.7213330715894699
Epoch: 90 | Iteration number: [30/565] 5% | Training loss: 0.7099048991998037
Epoch: 90 | Iteration number: [40/565] 7% | Training loss: 0.7040054634213447
Epoch: 90 | Iteration number: [50/565] 8% | Training loss: 0.7004425954818726
Epoch: 90 | Iteration number: [60/565] 10% | Training loss: 0.69811891913414
Epoch: 90 | Iteration number: [70/565] 12% | Training loss: 0.6964463055133819
Epoch: 90 | Iteration number: [80/565] 14% | Training loss: 0.695270013064146
Epoch: 90 | Iteration number: [90/565] 15% | Training loss: 0.6943433165550232
Epoch: 90 | Iteration number: [100/565] 17% | Training loss: 0.6936178350448609
Epoch: 90 | Iteration number: [110/565] 19% | Training loss: 0.6929605267264626
Epoch: 90 | Iteration number: [120/565] 21% | Training loss: 0.6924663017193476
Epoch: 90 | Iteration number: [130/565] 23% | Training loss: 0.6920295376044053
Epoch: 90 | Iteration number: [140/565] 24% | Training loss: 0.6916493922472
Epoch: 90 | Iteration number: [150/565] 26% | Training loss: 0.6913011598587037
Epoch: 90 | Iteration number: [160/565] 28% | Training loss: 0.6910007618367672
Epoch: 90 | Iteration number: [170/565] 30% | Training loss: 0.6907377586645238
Epoch: 90 | Iteration number: [180/565] 31% | Training loss: 0.6904766341050466
Epoch: 90 | Iteration number: [190/565] 33% | Training loss: 0.6902683154532784
Epoch: 90 | Iteration number: [200/565] 35% | Training loss: 0.6900718259811401
Epoch: 90 | Iteration number: [210/565] 37% | Training loss: 0.6898996092024303
Epoch: 90 | Iteration number: [220/565] 38% | Training loss: 0.6897674495523626
Epoch: 90 | Iteration number: [230/565] 40% | Training loss: 0.6896490908187368
Epoch: 90 | Iteration number: [240/565] 42% | Training loss: 0.6895161899427573
Epoch: 90 | Iteration number: [250/565] 44% | Training loss: 0.6894072318077087
Epoch: 90 | Iteration number: [260/565] 46% | Training loss: 0.6893120316358713
Epoch: 90 | Iteration number: [270/565] 47% | Training loss: 0.6892247871116356
Epoch: 90 | Iteration number: [280/565] 49% | Training loss: 0.6891305674399648
Epoch: 90 | Iteration number: [290/565] 51% | Training loss: 0.6890515512433545
Epoch: 90 | Iteration number: [300/565] 53% | Training loss: 0.6889730054140091
Epoch: 90 | Iteration number: [310/565] 54% | Training loss: 0.6889186359220936
Epoch: 90 | Iteration number: [320/565] 56% | Training loss: 0.688858070038259
Epoch: 90 | Iteration number: [330/565] 58% | Training loss: 0.6887814485665523
Epoch: 90 | Iteration number: [340/565] 60% | Training loss: 0.6887327772729537
Epoch: 90 | Iteration number: [350/565] 61% | Training loss: 0.6886773254190173
Epoch: 90 | Iteration number: [360/565] 63% | Training loss: 0.688627369205157
Epoch: 90 | Iteration number: [370/565] 65% | Training loss: 0.6885799269418459
Epoch: 90 | Iteration number: [380/565] 67% | Training loss: 0.688536072875324
Epoch: 90 | Iteration number: [390/565] 69% | Training loss: 0.6884777481739338
Epoch: 90 | Iteration number: [400/565] 70% | Training loss: 0.6884378783404828
Epoch: 90 | Iteration number: [410/565] 72% | Training loss: 0.6884073155682261
Epoch: 90 | Iteration number: [420/565] 74% | Training loss: 0.6883745928605397
Epoch: 90 | Iteration number: [430/565] 76% | Training loss: 0.6883377844511076
Epoch: 90 | Iteration number: [440/565] 77% | Training loss: 0.6883010667833415
Epoch: 90 | Iteration number: [450/565] 79% | Training loss: 0.6882677940527598
Epoch: 90 | Iteration number: [460/565] 81% | Training loss: 0.6882341344719348
Epoch: 90 | Iteration number: [470/565] 83% | Training loss: 0.6882059399117815
Epoch: 90 | Iteration number: [480/565] 84% | Training loss: 0.6881770395984252
Epoch: 90 | Iteration number: [490/565] 86% | Training loss: 0.6881479854486426
Epoch: 90 | Iteration number: [500/565] 88% | Training loss: 0.688122146844864
Epoch: 90 | Iteration number: [510/565] 90% | Training loss: 0.6880989904497185
Epoch: 90 | Iteration number: [520/565] 92% | Training loss: 0.6880724449570362
Epoch: 90 | Iteration number: [530/565] 93% | Training loss: 0.688046886785975
Epoch: 90 | Iteration number: [540/565] 95% | Training loss: 0.6880213608344395
Epoch: 90 | Iteration number: [550/565] 97% | Training loss: 0.6880096503821286
Epoch: 90 | Iteration number: [560/565] 99% | Training loss: 0.6879872333790574

 End of epoch: 90 | Train Loss: 0.6867594329656753 | Training Time: 89 

 End of epoch: 90 | Eval Loss: 0.6903113978249686 | Evaluating Time: 6 
Epoch: 91 | Iteration number: [10/565] 1% | Training loss: 0.7555470645427704
Epoch: 91 | Iteration number: [20/565] 3% | Training loss: 0.7210444241762162
Epoch: 91 | Iteration number: [30/565] 5% | Training loss: 0.7096891562143962
Epoch: 91 | Iteration number: [40/565] 7% | Training loss: 0.7040180459618568
Epoch: 91 | Iteration number: [50/565] 8% | Training loss: 0.700632119178772
Epoch: 91 | Iteration number: [60/565] 10% | Training loss: 0.6982366432746251
Epoch: 91 | Iteration number: [70/565] 12% | Training loss: 0.6965584823063442
Epoch: 91 | Iteration number: [80/565] 14% | Training loss: 0.695312287658453
Epoch: 91 | Iteration number: [90/565] 15% | Training loss: 0.6943642973899842
Epoch: 91 | Iteration number: [100/565] 17% | Training loss: 0.6935741150379181
Epoch: 91 | Iteration number: [110/565] 19% | Training loss: 0.692975328727202
Epoch: 91 | Iteration number: [120/565] 21% | Training loss: 0.6924623916546504
Epoch: 91 | Iteration number: [130/565] 23% | Training loss: 0.692001274915842
Epoch: 91 | Iteration number: [140/565] 24% | Training loss: 0.6916309556790761
Epoch: 91 | Iteration number: [150/565] 26% | Training loss: 0.6912633506457011
Epoch: 91 | Iteration number: [160/565] 28% | Training loss: 0.6909609626978636
Epoch: 91 | Iteration number: [170/565] 30% | Training loss: 0.69072707435664
Epoch: 91 | Iteration number: [180/565] 31% | Training loss: 0.6904996835523182
Epoch: 91 | Iteration number: [190/565] 33% | Training loss: 0.6902822475684317
Epoch: 91 | Iteration number: [200/565] 35% | Training loss: 0.6901439562439918
Epoch: 91 | Iteration number: [210/565] 37% | Training loss: 0.6899733855610802
Epoch: 91 | Iteration number: [220/565] 38% | Training loss: 0.6898348009044474
Epoch: 91 | Iteration number: [230/565] 40% | Training loss: 0.6897049559199292
Epoch: 91 | Iteration number: [240/565] 42% | Training loss: 0.6896011466781299
Epoch: 91 | Iteration number: [250/565] 44% | Training loss: 0.6894935736656189
Epoch: 91 | Iteration number: [260/565] 46% | Training loss: 0.6894023418426514
Epoch: 91 | Iteration number: [270/565] 47% | Training loss: 0.689304412956591
Epoch: 91 | Iteration number: [280/565] 49% | Training loss: 0.6892138862184116
Epoch: 91 | Iteration number: [290/565] 51% | Training loss: 0.689134682046956
Epoch: 91 | Iteration number: [300/565] 53% | Training loss: 0.689055994550387
Epoch: 91 | Iteration number: [310/565] 54% | Training loss: 0.6889894256668706
Epoch: 91 | Iteration number: [320/565] 56% | Training loss: 0.688920078240335
Epoch: 91 | Iteration number: [330/565] 58% | Training loss: 0.6888581438498064
Epoch: 91 | Iteration number: [340/565] 60% | Training loss: 0.6887991949039347
Epoch: 91 | Iteration number: [350/565] 61% | Training loss: 0.6887371974331992
Epoch: 91 | Iteration number: [360/565] 63% | Training loss: 0.6886813006467289
Epoch: 91 | Iteration number: [370/565] 65% | Training loss: 0.688637085379781
Epoch: 91 | Iteration number: [380/565] 67% | Training loss: 0.688574565084357
Epoch: 91 | Iteration number: [390/565] 69% | Training loss: 0.6885356734960507
Epoch: 91 | Iteration number: [400/565] 70% | Training loss: 0.6884826520085334
Epoch: 91 | Iteration number: [410/565] 72% | Training loss: 0.6884406832660117
Epoch: 91 | Iteration number: [420/565] 74% | Training loss: 0.6884111431382951
Epoch: 91 | Iteration number: [430/565] 76% | Training loss: 0.6883691071077834
Epoch: 91 | Iteration number: [440/565] 77% | Training loss: 0.688343999738043
Epoch: 91 | Iteration number: [450/565] 79% | Training loss: 0.6882975871033139
Epoch: 91 | Iteration number: [460/565] 81% | Training loss: 0.6882716714040092
Epoch: 91 | Iteration number: [470/565] 83% | Training loss: 0.6882335393986804
Epoch: 91 | Iteration number: [480/565] 84% | Training loss: 0.6881987361858288
Epoch: 91 | Iteration number: [490/565] 86% | Training loss: 0.688171641559017
Epoch: 91 | Iteration number: [500/565] 88% | Training loss: 0.6881336177587509
Epoch: 91 | Iteration number: [510/565] 90% | Training loss: 0.6881149609883627
Epoch: 91 | Iteration number: [520/565] 92% | Training loss: 0.6880886867642403
Epoch: 91 | Iteration number: [530/565] 93% | Training loss: 0.6880645854293176
Epoch: 91 | Iteration number: [540/565] 95% | Training loss: 0.6880338027521417
Epoch: 91 | Iteration number: [550/565] 97% | Training loss: 0.6880110069838438
Epoch: 91 | Iteration number: [560/565] 99% | Training loss: 0.6879831316215651

 End of epoch: 91 | Train Loss: 0.6867579235439807 | Training Time: 89 

 End of epoch: 91 | Eval Loss: 0.6899692671639579 | Evaluating Time: 6 
Epoch: 92 | Iteration number: [10/565] 1% | Training loss: 0.7556567490100861
Epoch: 92 | Iteration number: [20/565] 3% | Training loss: 0.7213147044181824
Epoch: 92 | Iteration number: [30/565] 5% | Training loss: 0.7096429785092672
Epoch: 92 | Iteration number: [40/565] 7% | Training loss: 0.7040003448724746
Epoch: 92 | Iteration number: [50/565] 8% | Training loss: 0.7005809950828552
Epoch: 92 | Iteration number: [60/565] 10% | Training loss: 0.6982725381851196
Epoch: 92 | Iteration number: [70/565] 12% | Training loss: 0.6966576048306057
Epoch: 92 | Iteration number: [80/565] 14% | Training loss: 0.6953786797821522
Epoch: 92 | Iteration number: [90/565] 15% | Training loss: 0.6944096273846097
Epoch: 92 | Iteration number: [100/565] 17% | Training loss: 0.6936238896846771
Epoch: 92 | Iteration number: [110/565] 19% | Training loss: 0.6930568245324221
Epoch: 92 | Iteration number: [120/565] 21% | Training loss: 0.6925221676627795
Epoch: 92 | Iteration number: [130/565] 23% | Training loss: 0.6920990962248582
Epoch: 92 | Iteration number: [140/565] 24% | Training loss: 0.6917112167392458
Epoch: 92 | Iteration number: [150/565] 26% | Training loss: 0.6913736915588379
Epoch: 92 | Iteration number: [160/565] 28% | Training loss: 0.6910853996872902
Epoch: 92 | Iteration number: [170/565] 30% | Training loss: 0.6908344426575829
Epoch: 92 | Iteration number: [180/565] 31% | Training loss: 0.6906126807133357
Epoch: 92 | Iteration number: [190/565] 33% | Training loss: 0.6904038859041114
Epoch: 92 | Iteration number: [200/565] 35% | Training loss: 0.6902117595076561
Epoch: 92 | Iteration number: [210/565] 37% | Training loss: 0.690045017855508
Epoch: 92 | Iteration number: [220/565] 38% | Training loss: 0.6898950284177606
Epoch: 92 | Iteration number: [230/565] 40% | Training loss: 0.6897462805976038
Epoch: 92 | Iteration number: [240/565] 42% | Training loss: 0.6896413420637448
Epoch: 92 | Iteration number: [250/565] 44% | Training loss: 0.6895196895599365
Epoch: 92 | Iteration number: [260/565] 46% | Training loss: 0.6894077021342058
Epoch: 92 | Iteration number: [270/565] 47% | Training loss: 0.6893093720630363
Epoch: 92 | Iteration number: [280/565] 49% | Training loss: 0.6892042179192815
Epoch: 92 | Iteration number: [290/565] 51% | Training loss: 0.689115008403515
Epoch: 92 | Iteration number: [300/565] 53% | Training loss: 0.6890361738204956
Epoch: 92 | Iteration number: [310/565] 54% | Training loss: 0.6889631527085458
Epoch: 92 | Iteration number: [320/565] 56% | Training loss: 0.6888993658125401
Epoch: 92 | Iteration number: [330/565] 58% | Training loss: 0.6888380359519611
Epoch: 92 | Iteration number: [340/565] 60% | Training loss: 0.6887809746405658
Epoch: 92 | Iteration number: [350/565] 61% | Training loss: 0.6887221300601959
Epoch: 92 | Iteration number: [360/565] 63% | Training loss: 0.6886593396464984
Epoch: 92 | Iteration number: [370/565] 65% | Training loss: 0.688594357226346
Epoch: 92 | Iteration number: [380/565] 67% | Training loss: 0.6885500002848475
Epoch: 92 | Iteration number: [390/565] 69% | Training loss: 0.6885055057513408
Epoch: 92 | Iteration number: [400/565] 70% | Training loss: 0.6884665659070015
Epoch: 92 | Iteration number: [410/565] 72% | Training loss: 0.6884220847269383
Epoch: 92 | Iteration number: [420/565] 74% | Training loss: 0.6883717871847607
Epoch: 92 | Iteration number: [430/565] 76% | Training loss: 0.68833422924197
Epoch: 92 | Iteration number: [440/565] 77% | Training loss: 0.6882954776287079
Epoch: 92 | Iteration number: [450/565] 79% | Training loss: 0.688265047205819
Epoch: 92 | Iteration number: [460/565] 81% | Training loss: 0.6882370278887127
Epoch: 92 | Iteration number: [470/565] 83% | Training loss: 0.6882003681456789
Epoch: 92 | Iteration number: [480/565] 84% | Training loss: 0.6881754245609045
Epoch: 92 | Iteration number: [490/565] 86% | Training loss: 0.6881433010101319
Epoch: 92 | Iteration number: [500/565] 88% | Training loss: 0.6881123766899109
Epoch: 92 | Iteration number: [510/565] 90% | Training loss: 0.6880859784051484
Epoch: 92 | Iteration number: [520/565] 92% | Training loss: 0.6880700441507193
Epoch: 92 | Iteration number: [530/565] 93% | Training loss: 0.6880392889931517
Epoch: 92 | Iteration number: [540/565] 95% | Training loss: 0.6880207635738231
Epoch: 92 | Iteration number: [550/565] 97% | Training loss: 0.6879981109229001
Epoch: 92 | Iteration number: [560/565] 99% | Training loss: 0.6879803812929562

 End of epoch: 92 | Train Loss: 0.6867534508747337 | Training Time: 88 

 End of epoch: 92 | Eval Loss: 0.6902783172471183 | Evaluating Time: 6 
Epoch: 93 | Iteration number: [10/565] 1% | Training loss: 0.7557349562644958
Epoch: 93 | Iteration number: [20/565] 3% | Training loss: 0.7212544023990631
Epoch: 93 | Iteration number: [30/565] 5% | Training loss: 0.7097693383693695
Epoch: 93 | Iteration number: [40/565] 7% | Training loss: 0.7040798932313919
Epoch: 93 | Iteration number: [50/565] 8% | Training loss: 0.7006918263435363
Epoch: 93 | Iteration number: [60/565] 10% | Training loss: 0.6983677248160044
Epoch: 93 | Iteration number: [70/565] 12% | Training loss: 0.6967235514095851
Epoch: 93 | Iteration number: [80/565] 14% | Training loss: 0.695494544506073
Epoch: 93 | Iteration number: [90/565] 15% | Training loss: 0.694536832968394
Epoch: 93 | Iteration number: [100/565] 17% | Training loss: 0.6937415659427643
Epoch: 93 | Iteration number: [110/565] 19% | Training loss: 0.693131210045381
Epoch: 93 | Iteration number: [120/565] 21% | Training loss: 0.6925867274403572
Epoch: 93 | Iteration number: [130/565] 23% | Training loss: 0.692104897590784
Epoch: 93 | Iteration number: [140/565] 24% | Training loss: 0.691713861482484
Epoch: 93 | Iteration number: [150/565] 26% | Training loss: 0.6913677302996317
Epoch: 93 | Iteration number: [160/565] 28% | Training loss: 0.6910723444074393
Epoch: 93 | Iteration number: [170/565] 30% | Training loss: 0.6908092565396253
Epoch: 93 | Iteration number: [180/565] 31% | Training loss: 0.6906021515528361
Epoch: 93 | Iteration number: [190/565] 33% | Training loss: 0.6903909137374477
Epoch: 93 | Iteration number: [200/565] 35% | Training loss: 0.6902129074931145
Epoch: 93 | Iteration number: [210/565] 37% | Training loss: 0.6900412182013194
Epoch: 93 | Iteration number: [220/565] 38% | Training loss: 0.6898883938789367
Epoch: 93 | Iteration number: [230/565] 40% | Training loss: 0.6897743517937868
Epoch: 93 | Iteration number: [240/565] 42% | Training loss: 0.6896418000260989
Epoch: 93 | Iteration number: [250/565] 44% | Training loss: 0.689515035867691
Epoch: 93 | Iteration number: [260/565] 46% | Training loss: 0.6894087323775658
Epoch: 93 | Iteration number: [270/565] 47% | Training loss: 0.6893277355918178
Epoch: 93 | Iteration number: [280/565] 49% | Training loss: 0.6892460405826568
Epoch: 93 | Iteration number: [290/565] 51% | Training loss: 0.6891555085264404
Epoch: 93 | Iteration number: [300/565] 53% | Training loss: 0.6890840633710226
Epoch: 93 | Iteration number: [310/565] 54% | Training loss: 0.6890057759900247
Epoch: 93 | Iteration number: [320/565] 56% | Training loss: 0.6889218913391233
Epoch: 93 | Iteration number: [330/565] 58% | Training loss: 0.6888531935937476
Epoch: 93 | Iteration number: [340/565] 60% | Training loss: 0.6887943862115635
Epoch: 93 | Iteration number: [350/565] 61% | Training loss: 0.6887429404258728
Epoch: 93 | Iteration number: [360/565] 63% | Training loss: 0.688674615489112
Epoch: 93 | Iteration number: [370/565] 65% | Training loss: 0.6886200581047986
Epoch: 93 | Iteration number: [380/565] 67% | Training loss: 0.6885685522305338
Epoch: 93 | Iteration number: [390/565] 69% | Training loss: 0.688509442561712
Epoch: 93 | Iteration number: [400/565] 70% | Training loss: 0.6884641560912133
Epoch: 93 | Iteration number: [410/565] 72% | Training loss: 0.6884199719603469
Epoch: 93 | Iteration number: [420/565] 74% | Training loss: 0.6883730286643619
Epoch: 93 | Iteration number: [430/565] 76% | Training loss: 0.6883299858071084
Epoch: 93 | Iteration number: [440/565] 77% | Training loss: 0.688295203582807
Epoch: 93 | Iteration number: [450/565] 79% | Training loss: 0.6882636057005989
Epoch: 93 | Iteration number: [460/565] 81% | Training loss: 0.6882348936537038
Epoch: 93 | Iteration number: [470/565] 83% | Training loss: 0.6882120192050933
Epoch: 93 | Iteration number: [480/565] 84% | Training loss: 0.6881725105146567
Epoch: 93 | Iteration number: [490/565] 86% | Training loss: 0.6881310432541127
Epoch: 93 | Iteration number: [500/565] 88% | Training loss: 0.6881020271778107
Epoch: 93 | Iteration number: [510/565] 90% | Training loss: 0.6880839571064594
Epoch: 93 | Iteration number: [520/565] 92% | Training loss: 0.6880597302546868
Epoch: 93 | Iteration number: [530/565] 93% | Training loss: 0.6880324144408388
Epoch: 93 | Iteration number: [540/565] 95% | Training loss: 0.6880181514554553
Epoch: 93 | Iteration number: [550/565] 97% | Training loss: 0.6880003837021914
Epoch: 93 | Iteration number: [560/565] 99% | Training loss: 0.6879888602665493

 End of epoch: 93 | Train Loss: 0.6867611016847391 | Training Time: 89 

 End of epoch: 93 | Eval Loss: 0.6902552247047424 | Evaluating Time: 6 
Epoch: 94 | Iteration number: [10/565] 1% | Training loss: 0.7556327700614929
Epoch: 94 | Iteration number: [20/565] 3% | Training loss: 0.7212559103965759
Epoch: 94 | Iteration number: [30/565] 5% | Training loss: 0.7097170551617941
Epoch: 94 | Iteration number: [40/565] 7% | Training loss: 0.7039572313427925
Epoch: 94 | Iteration number: [50/565] 8% | Training loss: 0.70040354013443
Epoch: 94 | Iteration number: [60/565] 10% | Training loss: 0.6980845997730891
Epoch: 94 | Iteration number: [70/565] 12% | Training loss: 0.6964497881276267
Epoch: 94 | Iteration number: [80/565] 14% | Training loss: 0.6952497512102127
Epoch: 94 | Iteration number: [90/565] 15% | Training loss: 0.694350579712126
Epoch: 94 | Iteration number: [100/565] 17% | Training loss: 0.693608216047287
Epoch: 94 | Iteration number: [110/565] 19% | Training loss: 0.6929999985478141
Epoch: 94 | Iteration number: [120/565] 21% | Training loss: 0.6924667413036029
Epoch: 94 | Iteration number: [130/565] 23% | Training loss: 0.6920088584606464
Epoch: 94 | Iteration number: [140/565] 24% | Training loss: 0.6916391909122467
Epoch: 94 | Iteration number: [150/565] 26% | Training loss: 0.6913030612468719
Epoch: 94 | Iteration number: [160/565] 28% | Training loss: 0.6910122752189636
Epoch: 94 | Iteration number: [170/565] 30% | Training loss: 0.6907405720037573
Epoch: 94 | Iteration number: [180/565] 31% | Training loss: 0.6905531297127406
Epoch: 94 | Iteration number: [190/565] 33% | Training loss: 0.6903681708009619
Epoch: 94 | Iteration number: [200/565] 35% | Training loss: 0.6901970794796943
Epoch: 94 | Iteration number: [210/565] 37% | Training loss: 0.6900313448338281
Epoch: 94 | Iteration number: [220/565] 38% | Training loss: 0.6899002993648703
Epoch: 94 | Iteration number: [230/565] 40% | Training loss: 0.6897674617560013
Epoch: 94 | Iteration number: [240/565] 42% | Training loss: 0.6896577929457028
Epoch: 94 | Iteration number: [250/565] 44% | Training loss: 0.6895426456928253
Epoch: 94 | Iteration number: [260/565] 46% | Training loss: 0.6894338958538495
Epoch: 94 | Iteration number: [270/565] 47% | Training loss: 0.6893335379936077
Epoch: 94 | Iteration number: [280/565] 49% | Training loss: 0.6892415979078838
Epoch: 94 | Iteration number: [290/565] 51% | Training loss: 0.6891519643109421
Epoch: 94 | Iteration number: [300/565] 53% | Training loss: 0.6890775376558304
Epoch: 94 | Iteration number: [310/565] 54% | Training loss: 0.6890184596661598
Epoch: 94 | Iteration number: [320/565] 56% | Training loss: 0.6889403982087969
Epoch: 94 | Iteration number: [330/565] 58% | Training loss: 0.6888865640669158
Epoch: 94 | Iteration number: [340/565] 60% | Training loss: 0.6888214958064697
Epoch: 94 | Iteration number: [350/565] 61% | Training loss: 0.6887630065849849
Epoch: 94 | Iteration number: [360/565] 63% | Training loss: 0.6887127401100265
Epoch: 94 | Iteration number: [370/565] 65% | Training loss: 0.6886574741956349
Epoch: 94 | Iteration number: [380/565] 67% | Training loss: 0.6886068105697631
Epoch: 94 | Iteration number: [390/565] 69% | Training loss: 0.6885546471828069
Epoch: 94 | Iteration number: [400/565] 70% | Training loss: 0.6885130628943443
Epoch: 94 | Iteration number: [410/565] 72% | Training loss: 0.6884731265102945
Epoch: 94 | Iteration number: [420/565] 74% | Training loss: 0.6884254390285128
Epoch: 94 | Iteration number: [430/565] 76% | Training loss: 0.6883909754974897
Epoch: 94 | Iteration number: [440/565] 77% | Training loss: 0.6883486204526641
Epoch: 94 | Iteration number: [450/565] 79% | Training loss: 0.6883080222871568
Epoch: 94 | Iteration number: [460/565] 81% | Training loss: 0.6882834225893021
Epoch: 94 | Iteration number: [470/565] 83% | Training loss: 0.6882551387269447
Epoch: 94 | Iteration number: [480/565] 84% | Training loss: 0.6882186913241942
Epoch: 94 | Iteration number: [490/565] 86% | Training loss: 0.6881938386936577
Epoch: 94 | Iteration number: [500/565] 88% | Training loss: 0.6881636905670167
Epoch: 94 | Iteration number: [510/565] 90% | Training loss: 0.6881261047194985
Epoch: 94 | Iteration number: [520/565] 92% | Training loss: 0.6880953102157666
Epoch: 94 | Iteration number: [530/565] 93% | Training loss: 0.6880648130515836
Epoch: 94 | Iteration number: [540/565] 95% | Training loss: 0.6880337559514575
Epoch: 94 | Iteration number: [550/565] 97% | Training loss: 0.6880132063952359
Epoch: 94 | Iteration number: [560/565] 99% | Training loss: 0.6879870867090566

 End of epoch: 94 | Train Loss: 0.6867540573651811 | Training Time: 90 

 End of epoch: 94 | Eval Loss: 0.6899255428995404 | Evaluating Time: 6 
Epoch: 95 | Iteration number: [10/565] 1% | Training loss: 0.7553820610046387
Epoch: 95 | Iteration number: [20/565] 3% | Training loss: 0.7210027813911438
Epoch: 95 | Iteration number: [30/565] 5% | Training loss: 0.7096302231152852
Epoch: 95 | Iteration number: [40/565] 7% | Training loss: 0.7039819374680519
Epoch: 95 | Iteration number: [50/565] 8% | Training loss: 0.7004215824604034
Epoch: 95 | Iteration number: [60/565] 10% | Training loss: 0.698087360461553
Epoch: 95 | Iteration number: [70/565] 12% | Training loss: 0.6965180967535292
Epoch: 95 | Iteration number: [80/565] 14% | Training loss: 0.6953184068202972
Epoch: 95 | Iteration number: [90/565] 15% | Training loss: 0.6943549328380161
Epoch: 95 | Iteration number: [100/565] 17% | Training loss: 0.6935709178447723
Epoch: 95 | Iteration number: [110/565] 19% | Training loss: 0.6929123071106997
Epoch: 95 | Iteration number: [120/565] 21% | Training loss: 0.6924203877647718
Epoch: 95 | Iteration number: [130/565] 23% | Training loss: 0.6920137588794415
Epoch: 95 | Iteration number: [140/565] 24% | Training loss: 0.6916583372013909
Epoch: 95 | Iteration number: [150/565] 26% | Training loss: 0.6913258524735769
Epoch: 95 | Iteration number: [160/565] 28% | Training loss: 0.6910536054521799
Epoch: 95 | Iteration number: [170/565] 30% | Training loss: 0.6908249388722812
Epoch: 95 | Iteration number: [180/565] 31% | Training loss: 0.6905848731597265
Epoch: 95 | Iteration number: [190/565] 33% | Training loss: 0.6904050544688576
Epoch: 95 | Iteration number: [200/565] 35% | Training loss: 0.6902025702595711
Epoch: 95 | Iteration number: [210/565] 37% | Training loss: 0.6900397141774496
Epoch: 95 | Iteration number: [220/565] 38% | Training loss: 0.689892712506381
Epoch: 95 | Iteration number: [230/565] 40% | Training loss: 0.6897788540176724
Epoch: 95 | Iteration number: [240/565] 42% | Training loss: 0.6896553640564282
Epoch: 95 | Iteration number: [250/565] 44% | Training loss: 0.6895415072441101
Epoch: 95 | Iteration number: [260/565] 46% | Training loss: 0.6894390855844205
Epoch: 95 | Iteration number: [270/565] 47% | Training loss: 0.6893346431078734
Epoch: 95 | Iteration number: [280/565] 49% | Training loss: 0.6892323415194239
Epoch: 95 | Iteration number: [290/565] 51% | Training loss: 0.6891400822277727
Epoch: 95 | Iteration number: [300/565] 53% | Training loss: 0.6890560833613077
Epoch: 95 | Iteration number: [310/565] 54% | Training loss: 0.688969143744438
Epoch: 95 | Iteration number: [320/565] 56% | Training loss: 0.6889109620824456
Epoch: 95 | Iteration number: [330/565] 58% | Training loss: 0.6888448536396027
Epoch: 95 | Iteration number: [340/565] 60% | Training loss: 0.6887856797260397
Epoch: 95 | Iteration number: [350/565] 61% | Training loss: 0.6887360170909337
Epoch: 95 | Iteration number: [360/565] 63% | Training loss: 0.6886830831567446
Epoch: 95 | Iteration number: [370/565] 65% | Training loss: 0.6886264971784644
Epoch: 95 | Iteration number: [380/565] 67% | Training loss: 0.6885781992422907
Epoch: 95 | Iteration number: [390/565] 69% | Training loss: 0.6885382568224883
Epoch: 95 | Iteration number: [400/565] 70% | Training loss: 0.6885015484690666
Epoch: 95 | Iteration number: [410/565] 72% | Training loss: 0.6884600530310375
Epoch: 95 | Iteration number: [420/565] 74% | Training loss: 0.6884132483175822
Epoch: 95 | Iteration number: [430/565] 76% | Training loss: 0.6883688255797985
Epoch: 95 | Iteration number: [440/565] 77% | Training loss: 0.6883295387029648
Epoch: 95 | Iteration number: [450/565] 79% | Training loss: 0.6882917104827033
Epoch: 95 | Iteration number: [460/565] 81% | Training loss: 0.688263016420862
Epoch: 95 | Iteration number: [470/565] 83% | Training loss: 0.6882241255425392
Epoch: 95 | Iteration number: [480/565] 84% | Training loss: 0.6882023980220159
Epoch: 95 | Iteration number: [490/565] 86% | Training loss: 0.6881721775142514
Epoch: 95 | Iteration number: [500/565] 88% | Training loss: 0.6881519134044647
Epoch: 95 | Iteration number: [510/565] 90% | Training loss: 0.688126668509315
Epoch: 95 | Iteration number: [520/565] 92% | Training loss: 0.6881018289006673
Epoch: 95 | Iteration number: [530/565] 93% | Training loss: 0.6880717369745363
Epoch: 95 | Iteration number: [540/565] 95% | Training loss: 0.688045753814556
Epoch: 95 | Iteration number: [550/565] 97% | Training loss: 0.688014789277857
Epoch: 95 | Iteration number: [560/565] 99% | Training loss: 0.6879920166518007

 End of epoch: 95 | Train Loss: 0.686767432225489 | Training Time: 89 

 End of epoch: 95 | Eval Loss: 0.6897538559777396 | Evaluating Time: 6 
Epoch: 96 | Iteration number: [10/565] 1% | Training loss: 0.7549697399139405
Epoch: 96 | Iteration number: [20/565] 3% | Training loss: 0.7209237098693848
Epoch: 96 | Iteration number: [30/565] 5% | Training loss: 0.7095741013685862
Epoch: 96 | Iteration number: [40/565] 7% | Training loss: 0.7038350209593773
Epoch: 96 | Iteration number: [50/565] 8% | Training loss: 0.7003465819358826
Epoch: 96 | Iteration number: [60/565] 10% | Training loss: 0.698206369082133
Epoch: 96 | Iteration number: [70/565] 12% | Training loss: 0.6965772603239332
Epoch: 96 | Iteration number: [80/565] 14% | Training loss: 0.6953374482691288
Epoch: 96 | Iteration number: [90/565] 15% | Training loss: 0.6943425370587243
Epoch: 96 | Iteration number: [100/565] 17% | Training loss: 0.693584942817688
Epoch: 96 | Iteration number: [110/565] 19% | Training loss: 0.6930080722678792
Epoch: 96 | Iteration number: [120/565] 21% | Training loss: 0.692508202791214
Epoch: 96 | Iteration number: [130/565] 23% | Training loss: 0.6920832092945393
Epoch: 96 | Iteration number: [140/565] 24% | Training loss: 0.6917103086199079
Epoch: 96 | Iteration number: [150/565] 26% | Training loss: 0.6914006312688191
Epoch: 96 | Iteration number: [160/565] 28% | Training loss: 0.6910988509654998
Epoch: 96 | Iteration number: [170/565] 30% | Training loss: 0.6908335896099315
Epoch: 96 | Iteration number: [180/565] 31% | Training loss: 0.6906099600924386
Epoch: 96 | Iteration number: [190/565] 33% | Training loss: 0.6904215498974449
Epoch: 96 | Iteration number: [200/565] 35% | Training loss: 0.6902288898825646
Epoch: 96 | Iteration number: [210/565] 37% | Training loss: 0.6900774683271136
Epoch: 96 | Iteration number: [220/565] 38% | Training loss: 0.6899030230262063
Epoch: 96 | Iteration number: [230/565] 40% | Training loss: 0.6897199164266171
Epoch: 96 | Iteration number: [240/565] 42% | Training loss: 0.6895882738133271
Epoch: 96 | Iteration number: [250/565] 44% | Training loss: 0.6894791378974915
Epoch: 96 | Iteration number: [260/565] 46% | Training loss: 0.6893818600819661
Epoch: 96 | Iteration number: [270/565] 47% | Training loss: 0.689289320619018
Epoch: 96 | Iteration number: [280/565] 49% | Training loss: 0.6891986116766929
Epoch: 96 | Iteration number: [290/565] 51% | Training loss: 0.6890979364000518
Epoch: 96 | Iteration number: [300/565] 53% | Training loss: 0.6890248384078344
Epoch: 96 | Iteration number: [310/565] 54% | Training loss: 0.6889768563931988
Epoch: 96 | Iteration number: [320/565] 56% | Training loss: 0.6889016123488545
Epoch: 96 | Iteration number: [330/565] 58% | Training loss: 0.6888289467854933
Epoch: 96 | Iteration number: [340/565] 60% | Training loss: 0.688770715804661
Epoch: 96 | Iteration number: [350/565] 61% | Training loss: 0.6887190491812569
Epoch: 96 | Iteration number: [360/565] 63% | Training loss: 0.6886753961443901
Epoch: 96 | Iteration number: [370/565] 65% | Training loss: 0.688622849857485
Epoch: 96 | Iteration number: [380/565] 67% | Training loss: 0.6885667725613243
Epoch: 96 | Iteration number: [390/565] 69% | Training loss: 0.688521138827006
Epoch: 96 | Iteration number: [400/565] 70% | Training loss: 0.6884772236645221
Epoch: 96 | Iteration number: [410/565] 72% | Training loss: 0.688432843074566
Epoch: 96 | Iteration number: [420/565] 74% | Training loss: 0.6883986484436762
Epoch: 96 | Iteration number: [430/565] 76% | Training loss: 0.6883628853531771
Epoch: 96 | Iteration number: [440/565] 77% | Training loss: 0.6883120007135651
Epoch: 96 | Iteration number: [450/565] 79% | Training loss: 0.6882791672812568
Epoch: 96 | Iteration number: [460/565] 81% | Training loss: 0.6882486892783124
Epoch: 96 | Iteration number: [470/565] 83% | Training loss: 0.688222233538932
Epoch: 96 | Iteration number: [480/565] 84% | Training loss: 0.6881945641090472
Epoch: 96 | Iteration number: [490/565] 86% | Training loss: 0.6881509503539728
Epoch: 96 | Iteration number: [500/565] 88% | Training loss: 0.6881261487007141
Epoch: 96 | Iteration number: [510/565] 90% | Training loss: 0.6880947662334816
Epoch: 96 | Iteration number: [520/565] 92% | Training loss: 0.688065437399424
Epoch: 96 | Iteration number: [530/565] 93% | Training loss: 0.6880403622141424
Epoch: 96 | Iteration number: [540/565] 95% | Training loss: 0.6880165507396062
Epoch: 96 | Iteration number: [550/565] 97% | Training loss: 0.6879965576258573
Epoch: 96 | Iteration number: [560/565] 99% | Training loss: 0.6879809710596289

 End of epoch: 96 | Train Loss: 0.6867574376342571 | Training Time: 89 

 End of epoch: 96 | Eval Loss: 0.6900508744376046 | Evaluating Time: 5 
Epoch: 97 | Iteration number: [10/565] 1% | Training loss: 0.7555209636688233
Epoch: 97 | Iteration number: [20/565] 3% | Training loss: 0.7211371093988419
Epoch: 97 | Iteration number: [30/565] 5% | Training loss: 0.7095266064008077
Epoch: 97 | Iteration number: [40/565] 7% | Training loss: 0.7037244483828544
Epoch: 97 | Iteration number: [50/565] 8% | Training loss: 0.7002962613105774
Epoch: 97 | Iteration number: [60/565] 10% | Training loss: 0.6980247795581818
Epoch: 97 | Iteration number: [70/565] 12% | Training loss: 0.6965133547782898
Epoch: 97 | Iteration number: [80/565] 14% | Training loss: 0.6953128121793271
Epoch: 97 | Iteration number: [90/565] 15% | Training loss: 0.6944237159358131
Epoch: 97 | Iteration number: [100/565] 17% | Training loss: 0.6936103266477585
Epoch: 97 | Iteration number: [110/565] 19% | Training loss: 0.6930009885267778
Epoch: 97 | Iteration number: [120/565] 21% | Training loss: 0.6924856980641683
Epoch: 97 | Iteration number: [130/565] 23% | Training loss: 0.692040511736503
Epoch: 97 | Iteration number: [140/565] 24% | Training loss: 0.6916860005685261
Epoch: 97 | Iteration number: [150/565] 26% | Training loss: 0.691334947347641
Epoch: 97 | Iteration number: [160/565] 28% | Training loss: 0.691074813529849
Epoch: 97 | Iteration number: [170/565] 30% | Training loss: 0.6908031993052539
Epoch: 97 | Iteration number: [180/565] 31% | Training loss: 0.6905693895286984
Epoch: 97 | Iteration number: [190/565] 33% | Training loss: 0.6903380365748154
Epoch: 97 | Iteration number: [200/565] 35% | Training loss: 0.6901666176319122
Epoch: 97 | Iteration number: [210/565] 37% | Training loss: 0.6899879166058132
Epoch: 97 | Iteration number: [220/565] 38% | Training loss: 0.6898600475354628
Epoch: 97 | Iteration number: [230/565] 40% | Training loss: 0.6897231060525645
Epoch: 97 | Iteration number: [240/565] 42% | Training loss: 0.6896023040016492
Epoch: 97 | Iteration number: [250/565] 44% | Training loss: 0.6894923226833344
Epoch: 97 | Iteration number: [260/565] 46% | Training loss: 0.689381236067185
Epoch: 97 | Iteration number: [270/565] 47% | Training loss: 0.6892886258937695
Epoch: 97 | Iteration number: [280/565] 49% | Training loss: 0.6891849081431116
Epoch: 97 | Iteration number: [290/565] 51% | Training loss: 0.6891047325627557
Epoch: 97 | Iteration number: [300/565] 53% | Training loss: 0.6890263950824738
Epoch: 97 | Iteration number: [310/565] 54% | Training loss: 0.6889425729551623
Epoch: 97 | Iteration number: [320/565] 56% | Training loss: 0.688876836001873
Epoch: 97 | Iteration number: [330/565] 58% | Training loss: 0.6888243133371527
Epoch: 97 | Iteration number: [340/565] 60% | Training loss: 0.6887602041749393
Epoch: 97 | Iteration number: [350/565] 61% | Training loss: 0.6887072598934174
Epoch: 97 | Iteration number: [360/565] 63% | Training loss: 0.6886555050810178
Epoch: 97 | Iteration number: [370/565] 65% | Training loss: 0.6886085793778703
Epoch: 97 | Iteration number: [380/565] 67% | Training loss: 0.6885562823006981
Epoch: 97 | Iteration number: [390/565] 69% | Training loss: 0.6885051293250842
Epoch: 97 | Iteration number: [400/565] 70% | Training loss: 0.6884654235839843
Epoch: 97 | Iteration number: [410/565] 72% | Training loss: 0.6884206395323683
Epoch: 97 | Iteration number: [420/565] 74% | Training loss: 0.6883786239794323
Epoch: 97 | Iteration number: [430/565] 76% | Training loss: 0.6883289775183035
Epoch: 97 | Iteration number: [440/565] 77% | Training loss: 0.6883055877956477
Epoch: 97 | Iteration number: [450/565] 79% | Training loss: 0.688286711110009
Epoch: 97 | Iteration number: [460/565] 81% | Training loss: 0.688253434455913
Epoch: 97 | Iteration number: [470/565] 83% | Training loss: 0.6882262281914975
Epoch: 97 | Iteration number: [480/565] 84% | Training loss: 0.6881856745729844
Epoch: 97 | Iteration number: [490/565] 86% | Training loss: 0.6881557884264965
Epoch: 97 | Iteration number: [500/565] 88% | Training loss: 0.688124305486679
Epoch: 97 | Iteration number: [510/565] 90% | Training loss: 0.6881045278380898
Epoch: 97 | Iteration number: [520/565] 92% | Training loss: 0.6880696661197222
Epoch: 97 | Iteration number: [530/565] 93% | Training loss: 0.6880384089811793
Epoch: 97 | Iteration number: [540/565] 95% | Training loss: 0.6880227484084942
Epoch: 97 | Iteration number: [550/565] 97% | Training loss: 0.6879955382780595
Epoch: 97 | Iteration number: [560/565] 99% | Training loss: 0.6879777346338545

 End of epoch: 97 | Train Loss: 0.6867504539742934 | Training Time: 90 

 End of epoch: 97 | Eval Loss: 0.6901283093861171 | Evaluating Time: 6 
Epoch: 98 | Iteration number: [10/565] 1% | Training loss: 0.7554979979991913
Epoch: 98 | Iteration number: [20/565] 3% | Training loss: 0.7211413294076919
Epoch: 98 | Iteration number: [30/565] 5% | Training loss: 0.70950515071551
Epoch: 98 | Iteration number: [40/565] 7% | Training loss: 0.7038284376263618
Epoch: 98 | Iteration number: [50/565] 8% | Training loss: 0.7003843605518341
Epoch: 98 | Iteration number: [60/565] 10% | Training loss: 0.6981407314538955
Epoch: 98 | Iteration number: [70/565] 12% | Training loss: 0.6965560282979693
Epoch: 98 | Iteration number: [80/565] 14% | Training loss: 0.6953752167522907
Epoch: 98 | Iteration number: [90/565] 15% | Training loss: 0.6943914545906915
Epoch: 98 | Iteration number: [100/565] 17% | Training loss: 0.6936567276716232
Epoch: 98 | Iteration number: [110/565] 19% | Training loss: 0.6930356567556207
Epoch: 98 | Iteration number: [120/565] 21% | Training loss: 0.692518009742101
Epoch: 98 | Iteration number: [130/565] 23% | Training loss: 0.6920787591200609
Epoch: 98 | Iteration number: [140/565] 24% | Training loss: 0.6916883792196001
Epoch: 98 | Iteration number: [150/565] 26% | Training loss: 0.6913413914044698
Epoch: 98 | Iteration number: [160/565] 28% | Training loss: 0.6910623192787171
Epoch: 98 | Iteration number: [170/565] 30% | Training loss: 0.6907867407097535
Epoch: 98 | Iteration number: [180/565] 31% | Training loss: 0.6905530091789034
Epoch: 98 | Iteration number: [190/565] 33% | Training loss: 0.6903660454248127
Epoch: 98 | Iteration number: [200/565] 35% | Training loss: 0.6901854228973389
Epoch: 98 | Iteration number: [210/565] 37% | Training loss: 0.6900267209325518
Epoch: 98 | Iteration number: [220/565] 38% | Training loss: 0.6898827452551235
Epoch: 98 | Iteration number: [230/565] 40% | Training loss: 0.6897527207498965
Epoch: 98 | Iteration number: [240/565] 42% | Training loss: 0.6896248812476794
Epoch: 98 | Iteration number: [250/565] 44% | Training loss: 0.6895016217231751
Epoch: 98 | Iteration number: [260/565] 46% | Training loss: 0.6893976252812606
Epoch: 98 | Iteration number: [270/565] 47% | Training loss: 0.6892998313462293
Epoch: 98 | Iteration number: [280/565] 49% | Training loss: 0.6892068488257271
Epoch: 98 | Iteration number: [290/565] 51% | Training loss: 0.6891311448195885
Epoch: 98 | Iteration number: [300/565] 53% | Training loss: 0.6890442881981532
Epoch: 98 | Iteration number: [310/565] 54% | Training loss: 0.6889700120495211
Epoch: 98 | Iteration number: [320/565] 56% | Training loss: 0.6888948438689113
Epoch: 98 | Iteration number: [330/565] 58% | Training loss: 0.6888172742092248
Epoch: 98 | Iteration number: [340/565] 60% | Training loss: 0.6887549870154437
Epoch: 98 | Iteration number: [350/565] 61% | Training loss: 0.6886958151204245
Epoch: 98 | Iteration number: [360/565] 63% | Training loss: 0.6886529972155889
Epoch: 98 | Iteration number: [370/565] 65% | Training loss: 0.6885913939089389
Epoch: 98 | Iteration number: [380/565] 67% | Training loss: 0.6885422849341443
Epoch: 98 | Iteration number: [390/565] 69% | Training loss: 0.6884834156586573
Epoch: 98 | Iteration number: [400/565] 70% | Training loss: 0.6884470136463642
Epoch: 98 | Iteration number: [410/565] 72% | Training loss: 0.688412700775193
Epoch: 98 | Iteration number: [420/565] 74% | Training loss: 0.6883795399041402
Epoch: 98 | Iteration number: [430/565] 76% | Training loss: 0.6883408913778705
Epoch: 98 | Iteration number: [440/565] 77% | Training loss: 0.688301442834464
Epoch: 98 | Iteration number: [450/565] 79% | Training loss: 0.6882685199048784
Epoch: 98 | Iteration number: [460/565] 81% | Training loss: 0.6882356786209604
Epoch: 98 | Iteration number: [470/565] 83% | Training loss: 0.688212033916027
Epoch: 98 | Iteration number: [480/565] 84% | Training loss: 0.6881796201070149
Epoch: 98 | Iteration number: [490/565] 86% | Training loss: 0.6881518350572002
Epoch: 98 | Iteration number: [500/565] 88% | Training loss: 0.6881160718202591
Epoch: 98 | Iteration number: [510/565] 90% | Training loss: 0.6880982640911552
Epoch: 98 | Iteration number: [520/565] 92% | Training loss: 0.6880696481237045
Epoch: 98 | Iteration number: [530/565] 93% | Training loss: 0.6880444030716734
Epoch: 98 | Iteration number: [540/565] 95% | Training loss: 0.68802473809984
Epoch: 98 | Iteration number: [550/565] 97% | Training loss: 0.688003664450212
Epoch: 98 | Iteration number: [560/565] 99% | Training loss: 0.6879741238696234

 End of epoch: 98 | Train Loss: 0.6867491340215227 | Training Time: 90 

 End of epoch: 98 | Eval Loss: 0.6901163629123143 | Evaluating Time: 6 
Epoch: 99 | Iteration number: [10/565] 1% | Training loss: 0.7557441174983979
Epoch: 99 | Iteration number: [20/565] 3% | Training loss: 0.7214604407548905
Epoch: 99 | Iteration number: [30/565] 5% | Training loss: 0.7098123530546824
Epoch: 99 | Iteration number: [40/565] 7% | Training loss: 0.7041560888290406
Epoch: 99 | Iteration number: [50/565] 8% | Training loss: 0.7006160509586334
Epoch: 99 | Iteration number: [60/565] 10% | Training loss: 0.6982004523277283
Epoch: 99 | Iteration number: [70/565] 12% | Training loss: 0.6965424580233438
Epoch: 99 | Iteration number: [80/565] 14% | Training loss: 0.6953630745410919
Epoch: 99 | Iteration number: [90/565] 15% | Training loss: 0.6943865974744161
Epoch: 99 | Iteration number: [100/565] 17% | Training loss: 0.6936612945795059
Epoch: 99 | Iteration number: [110/565] 19% | Training loss: 0.6930329761721871
Epoch: 99 | Iteration number: [120/565] 21% | Training loss: 0.6924923439820607
Epoch: 99 | Iteration number: [130/565] 23% | Training loss: 0.6920285348708813
Epoch: 99 | Iteration number: [140/565] 24% | Training loss: 0.6916578897408077
Epoch: 99 | Iteration number: [150/565] 26% | Training loss: 0.691321656703949
Epoch: 99 | Iteration number: [160/565] 28% | Training loss: 0.691032811999321
Epoch: 99 | Iteration number: [170/565] 30% | Training loss: 0.6907641771961661
Epoch: 99 | Iteration number: [180/565] 31% | Training loss: 0.6905087898174922
Epoch: 99 | Iteration number: [190/565] 33% | Training loss: 0.6902943309984709
Epoch: 99 | Iteration number: [200/565] 35% | Training loss: 0.6901255017518997
Epoch: 99 | Iteration number: [210/565] 37% | Training loss: 0.6899520334743318
Epoch: 99 | Iteration number: [220/565] 38% | Training loss: 0.6898145120252263
Epoch: 99 | Iteration number: [230/565] 40% | Training loss: 0.6896917978058691
Epoch: 99 | Iteration number: [240/565] 42% | Training loss: 0.6895601928234101
Epoch: 99 | Iteration number: [250/565] 44% | Training loss: 0.6894334149360657
Epoch: 99 | Iteration number: [260/565] 46% | Training loss: 0.6893282965971873
Epoch: 99 | Iteration number: [270/565] 47% | Training loss: 0.6892339165563937
Epoch: 99 | Iteration number: [280/565] 49% | Training loss: 0.6891397476196289
Epoch: 99 | Iteration number: [290/565] 51% | Training loss: 0.6890606859634663
Epoch: 99 | Iteration number: [300/565] 53% | Training loss: 0.6889890664815903
Epoch: 99 | Iteration number: [310/565] 54% | Training loss: 0.6889274276071979
Epoch: 99 | Iteration number: [320/565] 56% | Training loss: 0.6888705402612686
Epoch: 99 | Iteration number: [330/565] 58% | Training loss: 0.6887963710409222
Epoch: 99 | Iteration number: [340/565] 60% | Training loss: 0.6887525430497001
Epoch: 99 | Iteration number: [350/565] 61% | Training loss: 0.6886880006108965
Epoch: 99 | Iteration number: [360/565] 63% | Training loss: 0.6886210703187519
Epoch: 99 | Iteration number: [370/565] 65% | Training loss: 0.6885760449074411
Epoch: 99 | Iteration number: [380/565] 67% | Training loss: 0.6885290931714209
Epoch: 99 | Iteration number: [390/565] 69% | Training loss: 0.6884873630144657
Epoch: 99 | Iteration number: [400/565] 70% | Training loss: 0.6884465156495572
Epoch: 99 | Iteration number: [410/565] 72% | Training loss: 0.6884135836508216
Epoch: 99 | Iteration number: [420/565] 74% | Training loss: 0.688374455627941
Epoch: 99 | Iteration number: [430/565] 76% | Training loss: 0.6883390799511311
Epoch: 99 | Iteration number: [440/565] 77% | Training loss: 0.6883041097359224
Epoch: 99 | Iteration number: [450/565] 79% | Training loss: 0.6882763020197551
Epoch: 99 | Iteration number: [460/565] 81% | Training loss: 0.688240473166756
Epoch: 99 | Iteration number: [470/565] 83% | Training loss: 0.6882094839785962
Epoch: 99 | Iteration number: [480/565] 84% | Training loss: 0.6881795247395833
Epoch: 99 | Iteration number: [490/565] 86% | Training loss: 0.6881431363066849
Epoch: 99 | Iteration number: [500/565] 88% | Training loss: 0.6881163483858108
Epoch: 99 | Iteration number: [510/565] 90% | Training loss: 0.6880890777298049
Epoch: 99 | Iteration number: [520/565] 92% | Training loss: 0.688065667794301
Epoch: 99 | Iteration number: [530/565] 93% | Training loss: 0.6880418790961211
Epoch: 99 | Iteration number: [540/565] 95% | Training loss: 0.6880148849001637
Epoch: 99 | Iteration number: [550/565] 97% | Training loss: 0.6879892777312886
Epoch: 99 | Iteration number: [560/565] 99% | Training loss: 0.6879706476415907

 End of epoch: 99 | Train Loss: 0.68674606306363 | Training Time: 90 

 End of epoch: 99 | Eval Loss: 0.6897931098937988 | Evaluating Time: 6 
Epoch: 100 | Iteration number: [10/565] 1% | Training loss: 0.7554372429847718
Epoch: 100 | Iteration number: [20/565] 3% | Training loss: 0.7212883353233337
Epoch: 100 | Iteration number: [30/565] 5% | Training loss: 0.7097618162631989
Epoch: 100 | Iteration number: [40/565] 7% | Training loss: 0.7040901958942414
Epoch: 100 | Iteration number: [50/565] 8% | Training loss: 0.7006496596336365
Epoch: 100 | Iteration number: [60/565] 10% | Training loss: 0.6983613560597102
Epoch: 100 | Iteration number: [70/565] 12% | Training loss: 0.6967034092971257
Epoch: 100 | Iteration number: [80/565] 14% | Training loss: 0.6954620495438576
Epoch: 100 | Iteration number: [90/565] 15% | Training loss: 0.6945085995727115
Epoch: 100 | Iteration number: [100/565] 17% | Training loss: 0.6937080907821656
Epoch: 100 | Iteration number: [110/565] 19% | Training loss: 0.6929985263130881
Epoch: 100 | Iteration number: [120/565] 21% | Training loss: 0.69247990300258
Epoch: 100 | Iteration number: [130/565] 23% | Training loss: 0.6920347929000854
Epoch: 100 | Iteration number: [140/565] 24% | Training loss: 0.6916328251361847
Epoch: 100 | Iteration number: [150/565] 26% | Training loss: 0.6913134586811066
Epoch: 100 | Iteration number: [160/565] 28% | Training loss: 0.6910466134548188
Epoch: 100 | Iteration number: [170/565] 30% | Training loss: 0.6907890768612133
Epoch: 100 | Iteration number: [180/565] 31% | Training loss: 0.6905751999881532
Epoch: 100 | Iteration number: [190/565] 33% | Training loss: 0.6903893188426369
Epoch: 100 | Iteration number: [200/565] 35% | Training loss: 0.6901836061477661
Epoch: 100 | Iteration number: [210/565] 37% | Training loss: 0.690037358942486
Epoch: 100 | Iteration number: [220/565] 38% | Training loss: 0.6899032283913006
Epoch: 100 | Iteration number: [230/565] 40% | Training loss: 0.6897740148979684
Epoch: 100 | Iteration number: [240/565] 42% | Training loss: 0.6896400548517704
Epoch: 100 | Iteration number: [250/565] 44% | Training loss: 0.6895212800502777
Epoch: 100 | Iteration number: [260/565] 46% | Training loss: 0.6894137728672761
Epoch: 100 | Iteration number: [270/565] 47% | Training loss: 0.6892984867095947
Epoch: 100 | Iteration number: [280/565] 49% | Training loss: 0.689216959476471
Epoch: 100 | Iteration number: [290/565] 51% | Training loss: 0.6891334636458035
Epoch: 100 | Iteration number: [300/565] 53% | Training loss: 0.6890448121229807
Epoch: 100 | Iteration number: [310/565] 54% | Training loss: 0.6889647130043276
Epoch: 100 | Iteration number: [320/565] 56% | Training loss: 0.6888917235657572
Epoch: 100 | Iteration number: [330/565] 58% | Training loss: 0.6888132014057853
Epoch: 100 | Iteration number: [340/565] 60% | Training loss: 0.6887575987507315
Epoch: 100 | Iteration number: [350/565] 61% | Training loss: 0.6886984317643302
Epoch: 100 | Iteration number: [360/565] 63% | Training loss: 0.6886522392431895
Epoch: 100 | Iteration number: [370/565] 65% | Training loss: 0.6886019022078127
Epoch: 100 | Iteration number: [380/565] 67% | Training loss: 0.6885560313337727
Epoch: 100 | Iteration number: [390/565] 69% | Training loss: 0.6884977175639226
Epoch: 100 | Iteration number: [400/565] 70% | Training loss: 0.688445742726326
Epoch: 100 | Iteration number: [410/565] 72% | Training loss: 0.6884106979137514
Epoch: 100 | Iteration number: [420/565] 74% | Training loss: 0.6883769918055761
Epoch: 100 | Iteration number: [430/565] 76% | Training loss: 0.6883330712484759
Epoch: 100 | Iteration number: [440/565] 77% | Training loss: 0.6883072448047725
Epoch: 100 | Iteration number: [450/565] 79% | Training loss: 0.6882717884911431
Epoch: 100 | Iteration number: [460/565] 81% | Training loss: 0.6882359075805415
Epoch: 100 | Iteration number: [470/565] 83% | Training loss: 0.6882121204061711
Epoch: 100 | Iteration number: [480/565] 84% | Training loss: 0.6881842680275441
Epoch: 100 | Iteration number: [490/565] 86% | Training loss: 0.6881623789972189
Epoch: 100 | Iteration number: [500/565] 88% | Training loss: 0.6881345719099045
Epoch: 100 | Iteration number: [510/565] 90% | Training loss: 0.6881057819899391
Epoch: 100 | Iteration number: [520/565] 92% | Training loss: 0.688078747001978
Epoch: 100 | Iteration number: [530/565] 93% | Training loss: 0.6880489349365234
Epoch: 100 | Iteration number: [540/565] 95% | Training loss: 0.6880280048758896
Epoch: 100 | Iteration number: [550/565] 97% | Training loss: 0.6880029152740131
Epoch: 100 | Iteration number: [560/565] 99% | Training loss: 0.6879761980048248

 End of epoch: 100 | Train Loss: 0.6867444513118373 | Training Time: 89 

 End of epoch: 100 | Eval Loss: 0.6900195564542498 | Evaluating Time: 6 

 End of Test | Dice Loss: 0.9651937484741211 | Binary Cross Entropy With Logits Loss: 0.6895816837038312 
