Epoch: 1 | Iteration number: [10/4518] 0% | Training loss: 0.7603682339191437
Epoch: 1 | Iteration number: [20/4518] 0% | Training loss: 0.7255585998296737
Epoch: 1 | Iteration number: [30/4518] 0% | Training loss: 0.7139191488424937
Epoch: 1 | Iteration number: [40/4518] 0% | Training loss: 0.7083335593342781
Epoch: 1 | Iteration number: [50/4518] 1% | Training loss: 0.7047539019584655
Epoch: 1 | Iteration number: [60/4518] 1% | Training loss: 0.702525211373965
Epoch: 1 | Iteration number: [70/4518] 1% | Training loss: 0.7009929708072118
Epoch: 1 | Iteration number: [80/4518] 1% | Training loss: 0.6997835531830787
Epoch: 1 | Iteration number: [90/4518] 1% | Training loss: 0.6988037129243215
Epoch: 1 | Iteration number: [100/4518] 2% | Training loss: 0.6980661988258362
Epoch: 1 | Iteration number: [110/4518] 2% | Training loss: 0.697386494549838
Epoch: 1 | Iteration number: [120/4518] 2% | Training loss: 0.6968444774548213
Epoch: 1 | Iteration number: [130/4518] 2% | Training loss: 0.6964302108838007
Epoch: 1 | Iteration number: [140/4518] 3% | Training loss: 0.6960839109761374
Epoch: 1 | Iteration number: [150/4518] 3% | Training loss: 0.6957508885860443
Epoch: 1 | Iteration number: [160/4518] 3% | Training loss: 0.6954714149236679
Epoch: 1 | Iteration number: [170/4518] 3% | Training loss: 0.6951611666118398
Epoch: 1 | Iteration number: [180/4518] 3% | Training loss: 0.6949019031392203
Epoch: 1 | Iteration number: [190/4518] 4% | Training loss: 0.6946943097992947
Epoch: 1 | Iteration number: [200/4518] 4% | Training loss: 0.6945067957043648
Epoch: 1 | Iteration number: [210/4518] 4% | Training loss: 0.6943101457187107
Epoch: 1 | Iteration number: [220/4518] 4% | Training loss: 0.6941188777034933
Epoch: 1 | Iteration number: [230/4518] 5% | Training loss: 0.6939898301725802
Epoch: 1 | Iteration number: [240/4518] 5% | Training loss: 0.6938477645317713
Epoch: 1 | Iteration number: [250/4518] 5% | Training loss: 0.6936809048652649
Epoch: 1 | Iteration number: [260/4518] 5% | Training loss: 0.693578978914481
Epoch: 1 | Iteration number: [270/4518] 5% | Training loss: 0.6934799585077498
Epoch: 1 | Iteration number: [280/4518] 6% | Training loss: 0.6933808092560086
Epoch: 1 | Iteration number: [290/4518] 6% | Training loss: 0.6932797557321088
Epoch: 1 | Iteration number: [300/4518] 6% | Training loss: 0.6931919602553049
Epoch: 1 | Iteration number: [310/4518] 6% | Training loss: 0.6930802095320917
Epoch: 1 | Iteration number: [320/4518] 7% | Training loss: 0.692996277846396
Epoch: 1 | Iteration number: [330/4518] 7% | Training loss: 0.6929109602263479
Epoch: 1 | Iteration number: [340/4518] 7% | Training loss: 0.6928420541917577
Epoch: 1 | Iteration number: [350/4518] 7% | Training loss: 0.6927622357436589
Epoch: 1 | Iteration number: [360/4518] 7% | Training loss: 0.6926717874076631
Epoch: 1 | Iteration number: [370/4518] 8% | Training loss: 0.6926207257283701
Epoch: 1 | Iteration number: [380/4518] 8% | Training loss: 0.6925481215903634
Epoch: 1 | Iteration number: [390/4518] 8% | Training loss: 0.692464585793324
Epoch: 1 | Iteration number: [400/4518] 8% | Training loss: 0.6924054405093193
Epoch: 1 | Iteration number: [410/4518] 9% | Training loss: 0.6923303531437386
Epoch: 1 | Iteration number: [420/4518] 9% | Training loss: 0.6922656260785602
Epoch: 1 | Iteration number: [430/4518] 9% | Training loss: 0.6921992999176646
Epoch: 1 | Iteration number: [440/4518] 9% | Training loss: 0.6921589237722483
Epoch: 1 | Iteration number: [450/4518] 9% | Training loss: 0.6921323641141256
Epoch: 1 | Iteration number: [460/4518] 10% | Training loss: 0.6921042016018992
Epoch: 1 | Iteration number: [470/4518] 10% | Training loss: 0.6920604751465168
Epoch: 1 | Iteration number: [480/4518] 10% | Training loss: 0.6920220962415139
Epoch: 1 | Iteration number: [490/4518] 10% | Training loss: 0.6919659849332304
Epoch: 1 | Iteration number: [500/4518] 11% | Training loss: 0.6919190728664398
Epoch: 1 | Iteration number: [510/4518] 11% | Training loss: 0.6918623585326998
Epoch: 1 | Iteration number: [520/4518] 11% | Training loss: 0.6918325125024869
Epoch: 1 | Iteration number: [530/4518] 11% | Training loss: 0.6917924112868759
Epoch: 1 | Iteration number: [540/4518] 11% | Training loss: 0.6917493058575525
Epoch: 1 | Iteration number: [550/4518] 12% | Training loss: 0.6917129205573689
Epoch: 1 | Iteration number: [560/4518] 12% | Training loss: 0.691664473925318
Epoch: 1 | Iteration number: [570/4518] 12% | Training loss: 0.691627204731891
Epoch: 1 | Iteration number: [580/4518] 12% | Training loss: 0.6916040518160524
Epoch: 1 | Iteration number: [590/4518] 13% | Training loss: 0.6915737403651415
Epoch: 1 | Iteration number: [600/4518] 13% | Training loss: 0.6915372849504153
Epoch: 1 | Iteration number: [610/4518] 13% | Training loss: 0.691488267456899
Epoch: 1 | Iteration number: [620/4518] 13% | Training loss: 0.6914791921454091
Epoch: 1 | Iteration number: [630/4518] 13% | Training loss: 0.6914676949145302
Epoch: 1 | Iteration number: [640/4518] 14% | Training loss: 0.6914389538578689
Epoch: 1 | Iteration number: [650/4518] 14% | Training loss: 0.6914142880989955
Epoch: 1 | Iteration number: [660/4518] 14% | Training loss: 0.6913901127649076
Epoch: 1 | Iteration number: [670/4518] 14% | Training loss: 0.6913730946049761
Epoch: 1 | Iteration number: [680/4518] 15% | Training loss: 0.6913407780668315
Epoch: 1 | Iteration number: [690/4518] 15% | Training loss: 0.6913128411424333
Epoch: 1 | Iteration number: [700/4518] 15% | Training loss: 0.6912759861775807
Epoch: 1 | Iteration number: [710/4518] 15% | Training loss: 0.6912397194916093
Epoch: 1 | Iteration number: [720/4518] 15% | Training loss: 0.6912195915149317
Epoch: 1 | Iteration number: [730/4518] 16% | Training loss: 0.691188838465573
Epoch: 1 | Iteration number: [740/4518] 16% | Training loss: 0.6911550171471931
Epoch: 1 | Iteration number: [750/4518] 16% | Training loss: 0.6911447595755259
Epoch: 1 | Iteration number: [760/4518] 16% | Training loss: 0.6911317931978326
Epoch: 1 | Iteration number: [770/4518] 17% | Training loss: 0.6911020119468887
Epoch: 1 | Iteration number: [780/4518] 17% | Training loss: 0.6910832901031543
Epoch: 1 | Iteration number: [790/4518] 17% | Training loss: 0.6910786451418188
Epoch: 1 | Iteration number: [800/4518] 17% | Training loss: 0.691069431528449
Epoch: 1 | Iteration number: [810/4518] 17% | Training loss: 0.6910472435715758
Epoch: 1 | Iteration number: [820/4518] 18% | Training loss: 0.691024120697161
Epoch: 1 | Iteration number: [830/4518] 18% | Training loss: 0.6910063100866525
Epoch: 1 | Iteration number: [840/4518] 18% | Training loss: 0.6909908465686299
Epoch: 1 | Iteration number: [850/4518] 18% | Training loss: 0.690966682363959
Epoch: 1 | Iteration number: [860/4518] 19% | Training loss: 0.6909517813560575
Epoch: 1 | Iteration number: [870/4518] 19% | Training loss: 0.6909289112721366
Epoch: 1 | Iteration number: [880/4518] 19% | Training loss: 0.6909052174199711
Epoch: 1 | Iteration number: [890/4518] 19% | Training loss: 0.6908758437365629
Epoch: 1 | Iteration number: [900/4518] 19% | Training loss: 0.6908504617214203
Epoch: 1 | Iteration number: [910/4518] 20% | Training loss: 0.6908333720086695
Epoch: 1 | Iteration number: [920/4518] 20% | Training loss: 0.6908201505308565
Epoch: 1 | Iteration number: [930/4518] 20% | Training loss: 0.690815088313113
Epoch: 1 | Iteration number: [940/4518] 20% | Training loss: 0.690809451582584
Epoch: 1 | Iteration number: [950/4518] 21% | Training loss: 0.6907776778622677
Epoch: 1 | Iteration number: [960/4518] 21% | Training loss: 0.6907674693812926
Epoch: 1 | Iteration number: [970/4518] 21% | Training loss: 0.6907583117485047
Epoch: 1 | Iteration number: [980/4518] 21% | Training loss: 0.690737088298311
Epoch: 1 | Iteration number: [990/4518] 21% | Training loss: 0.6907066792550713
Epoch: 1 | Iteration number: [1000/4518] 22% | Training loss: 0.6906908915638924
Epoch: 1 | Iteration number: [1010/4518] 22% | Training loss: 0.6906787672845444
Epoch: 1 | Iteration number: [1020/4518] 22% | Training loss: 0.6906724357137493
Epoch: 1 | Iteration number: [1030/4518] 22% | Training loss: 0.6906522317418774
Epoch: 1 | Iteration number: [1040/4518] 23% | Training loss: 0.6906401503544587
Epoch: 1 | Iteration number: [1050/4518] 23% | Training loss: 0.6906239291032156
Epoch: 1 | Iteration number: [1060/4518] 23% | Training loss: 0.6906153936431093
Epoch: 1 | Iteration number: [1070/4518] 23% | Training loss: 0.6906154142918988
Epoch: 1 | Iteration number: [1080/4518] 23% | Training loss: 0.690592969181361
Epoch: 1 | Iteration number: [1090/4518] 24% | Training loss: 0.6905751050065417
Epoch: 1 | Iteration number: [1100/4518] 24% | Training loss: 0.6905601575699719
Epoch: 1 | Iteration number: [1110/4518] 24% | Training loss: 0.6905509900402378
Epoch: 1 | Iteration number: [1120/4518] 24% | Training loss: 0.6905330133225237
Epoch: 1 | Iteration number: [1130/4518] 25% | Training loss: 0.6905240171778518
Epoch: 1 | Iteration number: [1140/4518] 25% | Training loss: 0.690518237624252
Epoch: 1 | Iteration number: [1150/4518] 25% | Training loss: 0.6905094014561695
Epoch: 1 | Iteration number: [1160/4518] 25% | Training loss: 0.6904926128942391
Epoch: 1 | Iteration number: [1170/4518] 25% | Training loss: 0.6904782396096449
Epoch: 1 | Iteration number: [1180/4518] 26% | Training loss: 0.6904679988400411
Epoch: 1 | Iteration number: [1190/4518] 26% | Training loss: 0.6904610856741417
Epoch: 1 | Iteration number: [1200/4518] 26% | Training loss: 0.6904495120048523
Epoch: 1 | Iteration number: [1210/4518] 26% | Training loss: 0.6904373692086906
Epoch: 1 | Iteration number: [1220/4518] 27% | Training loss: 0.6904246697660352
Epoch: 1 | Iteration number: [1230/4518] 27% | Training loss: 0.6904084522065108
Epoch: 1 | Iteration number: [1240/4518] 27% | Training loss: 0.6903953751248698
Epoch: 1 | Iteration number: [1250/4518] 27% | Training loss: 0.6903910706996917
Epoch: 1 | Iteration number: [1260/4518] 27% | Training loss: 0.6903755948657081
Epoch: 1 | Iteration number: [1270/4518] 28% | Training loss: 0.6903654133710335
Epoch: 1 | Iteration number: [1280/4518] 28% | Training loss: 0.6903562431689352
Epoch: 1 | Iteration number: [1290/4518] 28% | Training loss: 0.6903478672338087
Epoch: 1 | Iteration number: [1300/4518] 28% | Training loss: 0.6903270170321831
Epoch: 1 | Iteration number: [1310/4518] 28% | Training loss: 0.6903193546160487
Epoch: 1 | Iteration number: [1320/4518] 29% | Training loss: 0.6903120523600867
Epoch: 1 | Iteration number: [1330/4518] 29% | Training loss: 0.6903079989261197
Epoch: 1 | Iteration number: [1340/4518] 29% | Training loss: 0.6903004643187594
Epoch: 1 | Iteration number: [1350/4518] 29% | Training loss: 0.6902903927697076
Epoch: 1 | Iteration number: [1360/4518] 30% | Training loss: 0.6902769725988893
Epoch: 1 | Iteration number: [1370/4518] 30% | Training loss: 0.6902561794667348
Epoch: 1 | Iteration number: [1380/4518] 30% | Training loss: 0.6902417578127074
Epoch: 1 | Iteration number: [1390/4518] 30% | Training loss: 0.6902353559037764
Epoch: 1 | Iteration number: [1400/4518] 30% | Training loss: 0.6902252416525568
Epoch: 1 | Iteration number: [1410/4518] 31% | Training loss: 0.6902120120981906
Epoch: 1 | Iteration number: [1420/4518] 31% | Training loss: 0.6902116862401156
Epoch: 1 | Iteration number: [1430/4518] 31% | Training loss: 0.6902087589660725
Epoch: 1 | Iteration number: [1440/4518] 31% | Training loss: 0.6901987058420976
Epoch: 1 | Iteration number: [1450/4518] 32% | Training loss: 0.6901854298854696
Epoch: 1 | Iteration number: [1460/4518] 32% | Training loss: 0.6901816410969381
Epoch: 1 | Iteration number: [1470/4518] 32% | Training loss: 0.6901665436167296
Epoch: 1 | Iteration number: [1480/4518] 32% | Training loss: 0.6901578980925921
Epoch: 1 | Iteration number: [1490/4518] 32% | Training loss: 0.690154084983288
Epoch: 1 | Iteration number: [1500/4518] 33% | Training loss: 0.6901454916000366
Epoch: 1 | Iteration number: [1510/4518] 33% | Training loss: 0.69013784050152
Epoch: 1 | Iteration number: [1520/4518] 33% | Training loss: 0.6901395246778664
Epoch: 1 | Iteration number: [1530/4518] 33% | Training loss: 0.6901360276088216
Epoch: 1 | Iteration number: [1540/4518] 34% | Training loss: 0.6901222440329465
Epoch: 1 | Iteration number: [1550/4518] 34% | Training loss: 0.6901104357934768
Epoch: 1 | Iteration number: [1560/4518] 34% | Training loss: 0.6901042558443852
Epoch: 1 | Iteration number: [1570/4518] 34% | Training loss: 0.6900967513679699
Epoch: 1 | Iteration number: [1580/4518] 34% | Training loss: 0.690094164127036
Epoch: 1 | Iteration number: [1590/4518] 35% | Training loss: 0.6900959051630032
Epoch: 1 | Iteration number: [1600/4518] 35% | Training loss: 0.6900898787379265
Epoch: 1 | Iteration number: [1610/4518] 35% | Training loss: 0.69008038999131
Epoch: 1 | Iteration number: [1620/4518] 35% | Training loss: 0.6900760782721602
Epoch: 1 | Iteration number: [1630/4518] 36% | Training loss: 0.6900612283338067
Epoch: 1 | Iteration number: [1640/4518] 36% | Training loss: 0.6900526068196065
Epoch: 1 | Iteration number: [1650/4518] 36% | Training loss: 0.6900473716403499
Epoch: 1 | Iteration number: [1660/4518] 36% | Training loss: 0.6900339257645319
Epoch: 1 | Iteration number: [1670/4518] 36% | Training loss: 0.6900271944657057
Epoch: 1 | Iteration number: [1680/4518] 37% | Training loss: 0.6900218603156861
Epoch: 1 | Iteration number: [1690/4518] 37% | Training loss: 0.6900182639000684
Epoch: 1 | Iteration number: [1700/4518] 37% | Training loss: 0.6900113856441834
Epoch: 1 | Iteration number: [1710/4518] 37% | Training loss: 0.6899956377277597
Epoch: 1 | Iteration number: [1720/4518] 38% | Training loss: 0.6899897925728975
Epoch: 1 | Iteration number: [1730/4518] 38% | Training loss: 0.689986615925166
Epoch: 1 | Iteration number: [1740/4518] 38% | Training loss: 0.6899802221306439
Epoch: 1 | Iteration number: [1750/4518] 38% | Training loss: 0.6899726433413369
Epoch: 1 | Iteration number: [1760/4518] 38% | Training loss: 0.6899623033336618
Epoch: 1 | Iteration number: [1770/4518] 39% | Training loss: 0.6899565661357621
Epoch: 1 | Iteration number: [1780/4518] 39% | Training loss: 0.6899505196327573
Epoch: 1 | Iteration number: [1790/4518] 39% | Training loss: 0.6899439955223872
Epoch: 1 | Iteration number: [1800/4518] 39% | Training loss: 0.6899396040373378
Epoch: 1 | Iteration number: [1810/4518] 40% | Training loss: 0.6899339010373005
Epoch: 1 | Iteration number: [1820/4518] 40% | Training loss: 0.6899304845830896
Epoch: 1 | Iteration number: [1830/4518] 40% | Training loss: 0.6899256148299233
Epoch: 1 | Iteration number: [1840/4518] 40% | Training loss: 0.6899169828580773
Epoch: 1 | Iteration number: [1850/4518] 40% | Training loss: 0.6899060586980871
Epoch: 1 | Iteration number: [1860/4518] 41% | Training loss: 0.6899031988715613
Epoch: 1 | Iteration number: [1870/4518] 41% | Training loss: 0.6898951835810819
Epoch: 1 | Iteration number: [1880/4518] 41% | Training loss: 0.6898910790681839
Epoch: 1 | Iteration number: [1890/4518] 41% | Training loss: 0.6898834956701471
Epoch: 1 | Iteration number: [1900/4518] 42% | Training loss: 0.6898777024683199
Epoch: 1 | Iteration number: [1910/4518] 42% | Training loss: 0.6898747822689136
Epoch: 1 | Iteration number: [1920/4518] 42% | Training loss: 0.6898678014054894
Epoch: 1 | Iteration number: [1930/4518] 42% | Training loss: 0.6898674048290352
Epoch: 1 | Iteration number: [1940/4518] 42% | Training loss: 0.6898606315716026
Epoch: 1 | Iteration number: [1950/4518] 43% | Training loss: 0.6898581384389828
Epoch: 1 | Iteration number: [1960/4518] 43% | Training loss: 0.6898513362419848
Epoch: 1 | Iteration number: [1970/4518] 43% | Training loss: 0.6898462008703784
Epoch: 1 | Iteration number: [1980/4518] 43% | Training loss: 0.6898385090057296
Epoch: 1 | Iteration number: [1990/4518] 44% | Training loss: 0.6898335167211503
Epoch: 1 | Iteration number: [2000/4518] 44% | Training loss: 0.6898279099166393
Epoch: 1 | Iteration number: [2010/4518] 44% | Training loss: 0.6898179925199764
Epoch: 1 | Iteration number: [2020/4518] 44% | Training loss: 0.6898146637005381
Epoch: 1 | Iteration number: [2030/4518] 44% | Training loss: 0.6898123888840229
Epoch: 1 | Iteration number: [2040/4518] 45% | Training loss: 0.6898075725518021
Epoch: 1 | Iteration number: [2050/4518] 45% | Training loss: 0.6898033637244527
Epoch: 1 | Iteration number: [2060/4518] 45% | Training loss: 0.6897961469240559
Epoch: 1 | Iteration number: [2070/4518] 45% | Training loss: 0.6897877976226346
Epoch: 1 | Iteration number: [2080/4518] 46% | Training loss: 0.6897841152376853
Epoch: 1 | Iteration number: [2090/4518] 46% | Training loss: 0.6897766267568871
Epoch: 1 | Iteration number: [2100/4518] 46% | Training loss: 0.6897723658879598
Epoch: 1 | Iteration number: [2110/4518] 46% | Training loss: 0.6897729888346523
Epoch: 1 | Iteration number: [2120/4518] 46% | Training loss: 0.6897698465102123
Epoch: 1 | Iteration number: [2130/4518] 47% | Training loss: 0.6897665202057978
Epoch: 1 | Iteration number: [2140/4518] 47% | Training loss: 0.6897644633166143
Epoch: 1 | Iteration number: [2150/4518] 47% | Training loss: 0.6897619483082793
Epoch: 1 | Iteration number: [2160/4518] 47% | Training loss: 0.6897574641638332
Epoch: 1 | Iteration number: [2170/4518] 48% | Training loss: 0.6897533632917887
Epoch: 1 | Iteration number: [2180/4518] 48% | Training loss: 0.6897501911592046
Epoch: 1 | Iteration number: [2190/4518] 48% | Training loss: 0.6897418809263673
Epoch: 1 | Iteration number: [2200/4518] 48% | Training loss: 0.68973978262056
Epoch: 1 | Iteration number: [2210/4518] 48% | Training loss: 0.6897332346007835
Epoch: 1 | Iteration number: [2220/4518] 49% | Training loss: 0.6897265762359173
Epoch: 1 | Iteration number: [2230/4518] 49% | Training loss: 0.6897232298359208
Epoch: 1 | Iteration number: [2240/4518] 49% | Training loss: 0.6897137376080666
Epoch: 1 | Iteration number: [2250/4518] 49% | Training loss: 0.6897161518467797
Epoch: 1 | Iteration number: [2260/4518] 50% | Training loss: 0.6897134353629256
Epoch: 1 | Iteration number: [2270/4518] 50% | Training loss: 0.689706665277481
Epoch: 1 | Iteration number: [2280/4518] 50% | Training loss: 0.6896998140372728
Epoch: 1 | Iteration number: [2290/4518] 50% | Training loss: 0.6896953011704324
Epoch: 1 | Iteration number: [2300/4518] 50% | Training loss: 0.6896900473729424
Epoch: 1 | Iteration number: [2310/4518] 51% | Training loss: 0.6896814443074264
Epoch: 1 | Iteration number: [2320/4518] 51% | Training loss: 0.6896802886292852
Epoch: 1 | Iteration number: [2330/4518] 51% | Training loss: 0.6896720055858465
Epoch: 1 | Iteration number: [2340/4518] 51% | Training loss: 0.6896630237754594
Epoch: 1 | Iteration number: [2350/4518] 52% | Training loss: 0.6896626870682899
Epoch: 1 | Iteration number: [2360/4518] 52% | Training loss: 0.689660447558104
Epoch: 1 | Iteration number: [2370/4518] 52% | Training loss: 0.6896503564929157
Epoch: 1 | Iteration number: [2380/4518] 52% | Training loss: 0.6896458672124799
Epoch: 1 | Iteration number: [2390/4518] 52% | Training loss: 0.6896452745633145
Epoch: 1 | Iteration number: [2400/4518] 53% | Training loss: 0.689643331716458
Epoch: 1 | Iteration number: [2410/4518] 53% | Training loss: 0.6896383338449407
Epoch: 1 | Iteration number: [2420/4518] 53% | Training loss: 0.6896363030534145
Epoch: 1 | Iteration number: [2430/4518] 53% | Training loss: 0.6896347658624374
Epoch: 1 | Iteration number: [2440/4518] 54% | Training loss: 0.6896328483204373
Epoch: 1 | Iteration number: [2450/4518] 54% | Training loss: 0.6896316786201633
Epoch: 1 | Iteration number: [2460/4518] 54% | Training loss: 0.6896274153536898
Epoch: 1 | Iteration number: [2470/4518] 54% | Training loss: 0.68962294107024
Epoch: 1 | Iteration number: [2480/4518] 54% | Training loss: 0.6896219022812382
Epoch: 1 | Iteration number: [2490/4518] 55% | Training loss: 0.6896169824293819
Epoch: 1 | Iteration number: [2500/4518] 55% | Training loss: 0.6896132737874985
Epoch: 1 | Iteration number: [2510/4518] 55% | Training loss: 0.6896112588534792
Epoch: 1 | Iteration number: [2520/4518] 55% | Training loss: 0.6896023126585143
Epoch: 1 | Iteration number: [2530/4518] 55% | Training loss: 0.689598952852219
Epoch: 1 | Iteration number: [2540/4518] 56% | Training loss: 0.689594943809697
Epoch: 1 | Iteration number: [2550/4518] 56% | Training loss: 0.689589000753328
Epoch: 1 | Iteration number: [2560/4518] 56% | Training loss: 0.6895880137104541
Epoch: 1 | Iteration number: [2570/4518] 56% | Training loss: 0.6895848993429414
Epoch: 1 | Iteration number: [2580/4518] 57% | Training loss: 0.6895812584910281
Epoch: 1 | Iteration number: [2590/4518] 57% | Training loss: 0.6895808102081181
Epoch: 1 | Iteration number: [2600/4518] 57% | Training loss: 0.6895759774171389
Epoch: 1 | Iteration number: [2610/4518] 57% | Training loss: 0.6895739215315531
Epoch: 1 | Iteration number: [2620/4518] 57% | Training loss: 0.6895662118005389
Epoch: 1 | Iteration number: [2630/4518] 58% | Training loss: 0.6895659365581469
Epoch: 1 | Iteration number: [2640/4518] 58% | Training loss: 0.6895621315999465
Epoch: 1 | Iteration number: [2650/4518] 58% | Training loss: 0.6895623578665392
Epoch: 1 | Iteration number: [2660/4518] 58% | Training loss: 0.6895613491759265
Epoch: 1 | Iteration number: [2670/4518] 59% | Training loss: 0.6895600575409578
Epoch: 1 | Iteration number: [2680/4518] 59% | Training loss: 0.6895562199514303
Epoch: 1 | Iteration number: [2690/4518] 59% | Training loss: 0.6895505461772579
Epoch: 1 | Iteration number: [2700/4518] 59% | Training loss: 0.6895432899395625
Epoch: 1 | Iteration number: [2710/4518] 59% | Training loss: 0.6895396741113979
Epoch: 1 | Iteration number: [2720/4518] 60% | Training loss: 0.6895362921716536
Epoch: 1 | Iteration number: [2730/4518] 60% | Training loss: 0.6895313480398158
Epoch: 1 | Iteration number: [2740/4518] 60% | Training loss: 0.6895276880177268
Epoch: 1 | Iteration number: [2750/4518] 60% | Training loss: 0.6895250551700592
Epoch: 1 | Iteration number: [2760/4518] 61% | Training loss: 0.689520790093187
Epoch: 1 | Iteration number: [2770/4518] 61% | Training loss: 0.6895171946782067
Epoch: 1 | Iteration number: [2780/4518] 61% | Training loss: 0.6895166813255214
Epoch: 1 | Iteration number: [2790/4518] 61% | Training loss: 0.689507209613759
Epoch: 1 | Iteration number: [2800/4518] 61% | Training loss: 0.6895049761235714
Epoch: 1 | Iteration number: [2810/4518] 62% | Training loss: 0.6895021719016214
Epoch: 1 | Iteration number: [2820/4518] 62% | Training loss: 0.6894927832885837
Epoch: 1 | Iteration number: [2830/4518] 62% | Training loss: 0.6894912325240697
Epoch: 1 | Iteration number: [2840/4518] 62% | Training loss: 0.6894879950394093
Epoch: 1 | Iteration number: [2850/4518] 63% | Training loss: 0.68948078569613
Epoch: 1 | Iteration number: [2860/4518] 63% | Training loss: 0.6894773364692302
Epoch: 1 | Iteration number: [2870/4518] 63% | Training loss: 0.6894691650668088
Epoch: 1 | Iteration number: [2880/4518] 63% | Training loss: 0.6894664582899875
Epoch: 1 | Iteration number: [2890/4518] 63% | Training loss: 0.6894618496556596
Epoch: 1 | Iteration number: [2900/4518] 64% | Training loss: 0.6894588378380084
Epoch: 1 | Iteration number: [2910/4518] 64% | Training loss: 0.6894524109937071
Epoch: 1 | Iteration number: [2920/4518] 64% | Training loss: 0.6894467393012896
Epoch: 1 | Iteration number: [2930/4518] 64% | Training loss: 0.6894447453396312
Epoch: 1 | Iteration number: [2940/4518] 65% | Training loss: 0.689439547528215
Epoch: 1 | Iteration number: [2950/4518] 65% | Training loss: 0.6894369530879845
Epoch: 1 | Iteration number: [2960/4518] 65% | Training loss: 0.6894347778043232
Epoch: 1 | Iteration number: [2970/4518] 65% | Training loss: 0.6894297486001795
Epoch: 1 | Iteration number: [2980/4518] 65% | Training loss: 0.689429731477027
Epoch: 1 | Iteration number: [2990/4518] 66% | Training loss: 0.6894287540362432
Epoch: 1 | Iteration number: [3000/4518] 66% | Training loss: 0.6894259979526202
Epoch: 1 | Iteration number: [3010/4518] 66% | Training loss: 0.6894250573905996
Epoch: 1 | Iteration number: [3020/4518] 66% | Training loss: 0.689421972040309
Epoch: 1 | Iteration number: [3030/4518] 67% | Training loss: 0.6894192469592142
Epoch: 1 | Iteration number: [3040/4518] 67% | Training loss: 0.6894128321817047
Epoch: 1 | Iteration number: [3050/4518] 67% | Training loss: 0.6894105966560177
Epoch: 1 | Iteration number: [3060/4518] 67% | Training loss: 0.6894121999054953
Epoch: 1 | Iteration number: [3070/4518] 67% | Training loss: 0.6894105836894691
Epoch: 1 | Iteration number: [3080/4518] 68% | Training loss: 0.6894069771875034
Epoch: 1 | Iteration number: [3090/4518] 68% | Training loss: 0.6893984300611861
Epoch: 1 | Iteration number: [3100/4518] 68% | Training loss: 0.6893956283407826
Epoch: 1 | Iteration number: [3110/4518] 68% | Training loss: 0.6893967200513821
Epoch: 1 | Iteration number: [3120/4518] 69% | Training loss: 0.689393388862029
Epoch: 1 | Iteration number: [3130/4518] 69% | Training loss: 0.6893911610396144
Epoch: 1 | Iteration number: [3140/4518] 69% | Training loss: 0.6893884593134473
Epoch: 1 | Iteration number: [3150/4518] 69% | Training loss: 0.6893868898210072
Epoch: 1 | Iteration number: [3160/4518] 69% | Training loss: 0.6893824296472948
Epoch: 1 | Iteration number: [3170/4518] 70% | Training loss: 0.6893782181694681
Epoch: 1 | Iteration number: [3180/4518] 70% | Training loss: 0.6893772450070711
Epoch: 1 | Iteration number: [3190/4518] 70% | Training loss: 0.6893747581396731
Epoch: 1 | Iteration number: [3200/4518] 70% | Training loss: 0.6893717494048178
Epoch: 1 | Iteration number: [3210/4518] 71% | Training loss: 0.6893680300853705
Epoch: 1 | Iteration number: [3220/4518] 71% | Training loss: 0.6893669040121647
Epoch: 1 | Iteration number: [3230/4518] 71% | Training loss: 0.6893623210328282
Epoch: 1 | Iteration number: [3240/4518] 71% | Training loss: 0.6893591134636491
Epoch: 1 | Iteration number: [3250/4518] 71% | Training loss: 0.6893564953987416
Epoch: 1 | Iteration number: [3260/4518] 72% | Training loss: 0.6893531519576815
Epoch: 1 | Iteration number: [3270/4518] 72% | Training loss: 0.6893504338344667
Epoch: 1 | Iteration number: [3280/4518] 72% | Training loss: 0.6893475215064316
Epoch: 1 | Iteration number: [3290/4518] 72% | Training loss: 0.6893447571974757
Epoch: 1 | Iteration number: [3300/4518] 73% | Training loss: 0.6893412378340057
Epoch: 1 | Iteration number: [3310/4518] 73% | Training loss: 0.6893347042024676
Epoch: 1 | Iteration number: [3320/4518] 73% | Training loss: 0.6893342176295189
Epoch: 1 | Iteration number: [3330/4518] 73% | Training loss: 0.6893298669978305
Epoch: 1 | Iteration number: [3340/4518] 73% | Training loss: 0.6893279864224131
Epoch: 1 | Iteration number: [3350/4518] 74% | Training loss: 0.6893218629929557
Epoch: 1 | Iteration number: [3360/4518] 74% | Training loss: 0.6893156846896523
Epoch: 1 | Iteration number: [3370/4518] 74% | Training loss: 0.6893070944338948
Epoch: 1 | Iteration number: [3380/4518] 74% | Training loss: 0.689306345811257
Epoch: 1 | Iteration number: [3390/4518] 75% | Training loss: 0.6893044600092908
Epoch: 1 | Iteration number: [3400/4518] 75% | Training loss: 0.6893000073117368
Epoch: 1 | Iteration number: [3410/4518] 75% | Training loss: 0.6892939383682967
Epoch: 1 | Iteration number: [3420/4518] 75% | Training loss: 0.6892914960433169
Epoch: 1 | Iteration number: [3430/4518] 75% | Training loss: 0.6892888537475041
Epoch: 1 | Iteration number: [3440/4518] 76% | Training loss: 0.6892857700239781
Epoch: 1 | Iteration number: [3450/4518] 76% | Training loss: 0.6892839554427327
Epoch: 1 | Iteration number: [3460/4518] 76% | Training loss: 0.6892799789161351
Epoch: 1 | Iteration number: [3470/4518] 76% | Training loss: 0.6892796629787522
Epoch: 1 | Iteration number: [3480/4518] 77% | Training loss: 0.689272644242336
Epoch: 1 | Iteration number: [3490/4518] 77% | Training loss: 0.6892703349405852
Epoch: 1 | Iteration number: [3500/4518] 77% | Training loss: 0.6892683796031135
Epoch: 1 | Iteration number: [3510/4518] 77% | Training loss: 0.6892658084715874
Epoch: 1 | Iteration number: [3520/4518] 77% | Training loss: 0.6892613832415505
Epoch: 1 | Iteration number: [3530/4518] 78% | Training loss: 0.6892620193215335
Epoch: 1 | Iteration number: [3540/4518] 78% | Training loss: 0.6892575324423569
Epoch: 1 | Iteration number: [3550/4518] 78% | Training loss: 0.6892570345166703
Epoch: 1 | Iteration number: [3560/4518] 78% | Training loss: 0.6892529950717862
Epoch: 1 | Iteration number: [3570/4518] 79% | Training loss: 0.6892479294655369
Epoch: 1 | Iteration number: [3580/4518] 79% | Training loss: 0.6892466717259178
Epoch: 1 | Iteration number: [3590/4518] 79% | Training loss: 0.689245042362585
Epoch: 1 | Iteration number: [3600/4518] 79% | Training loss: 0.6892416374882062
Epoch: 1 | Iteration number: [3610/4518] 79% | Training loss: 0.6892385752577531
Epoch: 1 | Iteration number: [3620/4518] 80% | Training loss: 0.6892337775197477
Epoch: 1 | Iteration number: [3630/4518] 80% | Training loss: 0.689228730063793
Epoch: 1 | Iteration number: [3640/4518] 80% | Training loss: 0.6892270740735662
Epoch: 1 | Iteration number: [3650/4518] 80% | Training loss: 0.6892253255680816
Epoch: 1 | Iteration number: [3660/4518] 81% | Training loss: 0.6892244535391447
Epoch: 1 | Iteration number: [3670/4518] 81% | Training loss: 0.6892224265866449
Epoch: 1 | Iteration number: [3680/4518] 81% | Training loss: 0.6892177151921003
Epoch: 1 | Iteration number: [3690/4518] 81% | Training loss: 0.6892157814851622
Epoch: 1 | Iteration number: [3700/4518] 81% | Training loss: 0.6892146808070105
Epoch: 1 | Iteration number: [3710/4518] 82% | Training loss: 0.6892165244750257
Epoch: 1 | Iteration number: [3720/4518] 82% | Training loss: 0.6892125844154307
Epoch: 1 | Iteration number: [3730/4518] 82% | Training loss: 0.6892102661784788
Epoch: 1 | Iteration number: [3740/4518] 82% | Training loss: 0.6892097025950324
Epoch: 1 | Iteration number: [3750/4518] 83% | Training loss: 0.6892104691823323
Epoch: 1 | Iteration number: [3760/4518] 83% | Training loss: 0.689210092339744
Epoch: 1 | Iteration number: [3770/4518] 83% | Training loss: 0.6892096083423503
Epoch: 1 | Iteration number: [3780/4518] 83% | Training loss: 0.6892033708158625
Epoch: 1 | Iteration number: [3790/4518] 83% | Training loss: 0.6891979445096371
Epoch: 1 | Iteration number: [3800/4518] 84% | Training loss: 0.6891964964176479
Epoch: 1 | Iteration number: [3810/4518] 84% | Training loss: 0.6891927278417302
Epoch: 1 | Iteration number: [3820/4518] 84% | Training loss: 0.6891882377769311
Epoch: 1 | Iteration number: [3830/4518] 84% | Training loss: 0.6891853446281921
Epoch: 1 | Iteration number: [3840/4518] 84% | Training loss: 0.6891840308283766
Epoch: 1 | Iteration number: [3850/4518] 85% | Training loss: 0.6891797511918204
Epoch: 1 | Iteration number: [3860/4518] 85% | Training loss: 0.6891784879518914
Epoch: 1 | Iteration number: [3870/4518] 85% | Training loss: 0.6891768662966499
Epoch: 1 | Iteration number: [3880/4518] 85% | Training loss: 0.6891744348345343
Epoch: 1 | Iteration number: [3890/4518] 86% | Training loss: 0.6891699040916708
Epoch: 1 | Iteration number: [3900/4518] 86% | Training loss: 0.6891685097339826
Epoch: 1 | Iteration number: [3910/4518] 86% | Training loss: 0.6891680918233779
Epoch: 1 | Iteration number: [3920/4518] 86% | Training loss: 0.6891682024512972
Epoch: 1 | Iteration number: [3930/4518] 86% | Training loss: 0.6891684028938526
Epoch: 1 | Iteration number: [3940/4518] 87% | Training loss: 0.6891659405933419
Epoch: 1 | Iteration number: [3950/4518] 87% | Training loss: 0.6891626908960222
Epoch: 1 | Iteration number: [3960/4518] 87% | Training loss: 0.6891580196492599
Epoch: 1 | Iteration number: [3970/4518] 87% | Training loss: 0.6891569298670934
Epoch: 1 | Iteration number: [3980/4518] 88% | Training loss: 0.6891524859109716
Epoch: 1 | Iteration number: [3990/4518] 88% | Training loss: 0.6891484783705614
Epoch: 1 | Iteration number: [4000/4518] 88% | Training loss: 0.6891455942839384
Epoch: 1 | Iteration number: [4010/4518] 88% | Training loss: 0.6891404022451053
Epoch: 1 | Iteration number: [4020/4518] 88% | Training loss: 0.689136659253889
Epoch: 1 | Iteration number: [4030/4518] 89% | Training loss: 0.6891322823671194
Epoch: 1 | Iteration number: [4040/4518] 89% | Training loss: 0.6891301231366573
Epoch: 1 | Iteration number: [4050/4518] 89% | Training loss: 0.6891302468452924
Epoch: 1 | Iteration number: [4060/4518] 89% | Training loss: 0.6891293878625766
Epoch: 1 | Iteration number: [4070/4518] 90% | Training loss: 0.6891242877564208
Epoch: 1 | Iteration number: [4080/4518] 90% | Training loss: 0.6891225922195351
Epoch: 1 | Iteration number: [4090/4518] 90% | Training loss: 0.6891225110785011
Epoch: 1 | Iteration number: [4100/4518] 90% | Training loss: 0.6891194446348562
Epoch: 1 | Iteration number: [4110/4518] 90% | Training loss: 0.6891148887266498
Epoch: 1 | Iteration number: [4120/4518] 91% | Training loss: 0.689113905288062
Epoch: 1 | Iteration number: [4130/4518] 91% | Training loss: 0.6891105763271415
Epoch: 1 | Iteration number: [4140/4518] 91% | Training loss: 0.6891102016835973
Epoch: 1 | Iteration number: [4150/4518] 91% | Training loss: 0.6891088297280921
Epoch: 1 | Iteration number: [4160/4518] 92% | Training loss: 0.6891068355538524
Epoch: 1 | Iteration number: [4170/4518] 92% | Training loss: 0.6891054472048506
Epoch: 1 | Iteration number: [4180/4518] 92% | Training loss: 0.689103752788174
Epoch: 1 | Iteration number: [4190/4518] 92% | Training loss: 0.6891012096035167
Epoch: 1 | Iteration number: [4200/4518] 92% | Training loss: 0.6890998197311446
Epoch: 1 | Iteration number: [4210/4518] 93% | Training loss: 0.6890998142348899
Epoch: 1 | Iteration number: [4220/4518] 93% | Training loss: 0.6890965215826487
Epoch: 1 | Iteration number: [4230/4518] 93% | Training loss: 0.6890954846608723
Epoch: 1 | Iteration number: [4240/4518] 93% | Training loss: 0.6890925273861526
Epoch: 1 | Iteration number: [4250/4518] 94% | Training loss: 0.6890868353002212
Epoch: 1 | Iteration number: [4260/4518] 94% | Training loss: 0.6890820995322975
Epoch: 1 | Iteration number: [4270/4518] 94% | Training loss: 0.6890809881882589
Epoch: 1 | Iteration number: [4280/4518] 94% | Training loss: 0.6890780379421243
Epoch: 1 | Iteration number: [4290/4518] 94% | Training loss: 0.6890759182004106
Epoch: 1 | Iteration number: [4300/4518] 95% | Training loss: 0.6890735056372576
Epoch: 1 | Iteration number: [4310/4518] 95% | Training loss: 0.6890735478937764
Epoch: 1 | Iteration number: [4320/4518] 95% | Training loss: 0.6890705247720083
Epoch: 1 | Iteration number: [4330/4518] 95% | Training loss: 0.689067991845327
Epoch: 1 | Iteration number: [4340/4518] 96% | Training loss: 0.6890653121031923
Epoch: 1 | Iteration number: [4350/4518] 96% | Training loss: 0.689060635662627
Epoch: 1 | Iteration number: [4360/4518] 96% | Training loss: 0.6890586077756838
Epoch: 1 | Iteration number: [4370/4518] 96% | Training loss: 0.6890553470198022
Epoch: 1 | Iteration number: [4380/4518] 96% | Training loss: 0.6890516852271067
Epoch: 1 | Iteration number: [4390/4518] 97% | Training loss: 0.6890489267189573
Epoch: 1 | Iteration number: [4400/4518] 97% | Training loss: 0.6890460931712931
Epoch: 1 | Iteration number: [4410/4518] 97% | Training loss: 0.6890436184108933
Epoch: 1 | Iteration number: [4420/4518] 97% | Training loss: 0.68903810075775
Epoch: 1 | Iteration number: [4430/4518] 98% | Training loss: 0.6890347806379434
Epoch: 1 | Iteration number: [4440/4518] 98% | Training loss: 0.6890330628903063
Epoch: 1 | Iteration number: [4450/4518] 98% | Training loss: 0.6890316073546249
Epoch: 1 | Iteration number: [4460/4518] 98% | Training loss: 0.6890336483048751
Epoch: 1 | Iteration number: [4470/4518] 98% | Training loss: 0.6890302609143908
Epoch: 1 | Iteration number: [4480/4518] 99% | Training loss: 0.6890285718919975
Epoch: 1 | Iteration number: [4490/4518] 99% | Training loss: 0.6890281394223593
Epoch: 1 | Iteration number: [4500/4518] 99% | Training loss: 0.6890248072544733
Epoch: 1 | Iteration number: [4510/4518] 99% | Training loss: 0.6890220088731424

 End of epoch: 1 | Train Loss: 0.6888677310289245 | Training Time: 632 

 End of epoch: 1 | Eval Loss: 0.6904243194327062 | Evaluating Time: 16 
Epoch: 2 | Iteration number: [10/4518] 0% | Training loss: 0.7572541296482086
Epoch: 2 | Iteration number: [20/4518] 0% | Training loss: 0.7234782963991165
Epoch: 2 | Iteration number: [30/4518] 0% | Training loss: 0.7117613593737284
Epoch: 2 | Iteration number: [40/4518] 0% | Training loss: 0.7060779884457589
Epoch: 2 | Iteration number: [50/4518] 1% | Training loss: 0.7025418972969055
Epoch: 2 | Iteration number: [60/4518] 1% | Training loss: 0.7001285185416539
Epoch: 2 | Iteration number: [70/4518] 1% | Training loss: 0.6982628975595747
Epoch: 2 | Iteration number: [80/4518] 1% | Training loss: 0.6969709023833275
Epoch: 2 | Iteration number: [90/4518] 1% | Training loss: 0.6960560792022281
Epoch: 2 | Iteration number: [100/4518] 2% | Training loss: 0.6952572882175445
Epoch: 2 | Iteration number: [110/4518] 2% | Training loss: 0.6944985796104778
Epoch: 2 | Iteration number: [120/4518] 2% | Training loss: 0.6939091682434082
Epoch: 2 | Iteration number: [130/4518] 2% | Training loss: 0.6934777342356169
Epoch: 2 | Iteration number: [140/4518] 3% | Training loss: 0.6930526524782181
Epoch: 2 | Iteration number: [150/4518] 3% | Training loss: 0.6927213871479034
Epoch: 2 | Iteration number: [160/4518] 3% | Training loss: 0.6924983996897935
Epoch: 2 | Iteration number: [170/4518] 3% | Training loss: 0.6922840181519003
Epoch: 2 | Iteration number: [180/4518] 3% | Training loss: 0.6920631398757299
Epoch: 2 | Iteration number: [190/4518] 4% | Training loss: 0.6918739303162224
Epoch: 2 | Iteration number: [200/4518] 4% | Training loss: 0.6916417762637138
Epoch: 2 | Iteration number: [210/4518] 4% | Training loss: 0.6915333784761883
Epoch: 2 | Iteration number: [220/4518] 4% | Training loss: 0.6913304253058
Epoch: 2 | Iteration number: [230/4518] 5% | Training loss: 0.6911736869293711
Epoch: 2 | Iteration number: [240/4518] 5% | Training loss: 0.6910353248318036
Epoch: 2 | Iteration number: [250/4518] 5% | Training loss: 0.6908725605010987
Epoch: 2 | Iteration number: [260/4518] 5% | Training loss: 0.690766715315672
Epoch: 2 | Iteration number: [270/4518] 5% | Training loss: 0.6906531382490088
Epoch: 2 | Iteration number: [280/4518] 6% | Training loss: 0.6905722992760794
Epoch: 2 | Iteration number: [290/4518] 6% | Training loss: 0.690519571098788
Epoch: 2 | Iteration number: [300/4518] 6% | Training loss: 0.6904147164026896
Epoch: 2 | Iteration number: [310/4518] 6% | Training loss: 0.6903449396933279
Epoch: 2 | Iteration number: [320/4518] 7% | Training loss: 0.690282155200839
Epoch: 2 | Iteration number: [330/4518] 7% | Training loss: 0.6902307869810047
Epoch: 2 | Iteration number: [340/4518] 7% | Training loss: 0.6901554694947074
Epoch: 2 | Iteration number: [350/4518] 7% | Training loss: 0.6901235583850316
Epoch: 2 | Iteration number: [360/4518] 7% | Training loss: 0.6900712894068823
Epoch: 2 | Iteration number: [370/4518] 8% | Training loss: 0.6899986818030074
Epoch: 2 | Iteration number: [380/4518] 8% | Training loss: 0.6899381047800968
Epoch: 2 | Iteration number: [390/4518] 8% | Training loss: 0.6898713299861321
Epoch: 2 | Iteration number: [400/4518] 8% | Training loss: 0.689813920110464
Epoch: 2 | Iteration number: [410/4518] 9% | Training loss: 0.6897858087609454
Epoch: 2 | Iteration number: [420/4518] 9% | Training loss: 0.689731682340304
Epoch: 2 | Iteration number: [430/4518] 9% | Training loss: 0.689720521416775
Epoch: 2 | Iteration number: [440/4518] 9% | Training loss: 0.6896848361600529
Epoch: 2 | Iteration number: [450/4518] 9% | Training loss: 0.689680786397722
Epoch: 2 | Iteration number: [460/4518] 10% | Training loss: 0.6896609651005786
Epoch: 2 | Iteration number: [470/4518] 10% | Training loss: 0.6896031889509647
Epoch: 2 | Iteration number: [480/4518] 10% | Training loss: 0.6895618213961522
Epoch: 2 | Iteration number: [490/4518] 10% | Training loss: 0.6895261455555352
Epoch: 2 | Iteration number: [500/4518] 11% | Training loss: 0.6895058125257492
Epoch: 2 | Iteration number: [510/4518] 11% | Training loss: 0.6894942737093159
Epoch: 2 | Iteration number: [520/4518] 11% | Training loss: 0.6894466724533301
Epoch: 2 | Iteration number: [530/4518] 11% | Training loss: 0.6894276845005324
Epoch: 2 | Iteration number: [540/4518] 11% | Training loss: 0.689372060475526
Epoch: 2 | Iteration number: [550/4518] 12% | Training loss: 0.6893575065786188
Epoch: 2 | Iteration number: [560/4518] 12% | Training loss: 0.6893631702022893
Epoch: 2 | Iteration number: [570/4518] 12% | Training loss: 0.6893487515156729
Epoch: 2 | Iteration number: [580/4518] 12% | Training loss: 0.689338230778431
Epoch: 2 | Iteration number: [590/4518] 13% | Training loss: 0.6893086076793024
Epoch: 2 | Iteration number: [600/4518] 13% | Training loss: 0.6892863608400027
Epoch: 2 | Iteration number: [610/4518] 13% | Training loss: 0.6892783281255941
Epoch: 2 | Iteration number: [620/4518] 13% | Training loss: 0.6892608885803531
Epoch: 2 | Iteration number: [630/4518] 13% | Training loss: 0.6892519473083436
Epoch: 2 | Iteration number: [640/4518] 14% | Training loss: 0.6892255891114474
Epoch: 2 | Iteration number: [650/4518] 14% | Training loss: 0.6892068277872526
Epoch: 2 | Iteration number: [660/4518] 14% | Training loss: 0.6891953231710376
Epoch: 2 | Iteration number: [670/4518] 14% | Training loss: 0.6891758952567827
Epoch: 2 | Iteration number: [680/4518] 15% | Training loss: 0.6891640334444887
Epoch: 2 | Iteration number: [690/4518] 15% | Training loss: 0.689131554313328
Epoch: 2 | Iteration number: [700/4518] 15% | Training loss: 0.6891039885793413
Epoch: 2 | Iteration number: [710/4518] 15% | Training loss: 0.689078713722632
Epoch: 2 | Iteration number: [720/4518] 15% | Training loss: 0.6890680175688532
Epoch: 2 | Iteration number: [730/4518] 16% | Training loss: 0.6890485276914623
Epoch: 2 | Iteration number: [740/4518] 16% | Training loss: 0.6890296335961368
Epoch: 2 | Iteration number: [750/4518] 16% | Training loss: 0.6890266185601552
Epoch: 2 | Iteration number: [760/4518] 16% | Training loss: 0.6890195022288121
Epoch: 2 | Iteration number: [770/4518] 17% | Training loss: 0.6889971471452093
Epoch: 2 | Iteration number: [780/4518] 17% | Training loss: 0.6889706947100468
Epoch: 2 | Iteration number: [790/4518] 17% | Training loss: 0.688952851521818
Epoch: 2 | Iteration number: [800/4518] 17% | Training loss: 0.6889252694696189
Epoch: 2 | Iteration number: [810/4518] 17% | Training loss: 0.6889096535282371
Epoch: 2 | Iteration number: [820/4518] 18% | Training loss: 0.6888953206742682
Epoch: 2 | Iteration number: [830/4518] 18% | Training loss: 0.6888888542192528
Epoch: 2 | Iteration number: [840/4518] 18% | Training loss: 0.6888876003168878
Epoch: 2 | Iteration number: [850/4518] 18% | Training loss: 0.6888793908848482
Epoch: 2 | Iteration number: [860/4518] 19% | Training loss: 0.688874253907869
Epoch: 2 | Iteration number: [870/4518] 19% | Training loss: 0.6888665581571645
Epoch: 2 | Iteration number: [880/4518] 19% | Training loss: 0.688855234736746
Epoch: 2 | Iteration number: [890/4518] 19% | Training loss: 0.6888387442974562
Epoch: 2 | Iteration number: [900/4518] 19% | Training loss: 0.6888217655817668
Epoch: 2 | Iteration number: [910/4518] 20% | Training loss: 0.6888043179616823
Epoch: 2 | Iteration number: [920/4518] 20% | Training loss: 0.6887924444416295
Epoch: 2 | Iteration number: [930/4518] 20% | Training loss: 0.6887908897092265
Epoch: 2 | Iteration number: [940/4518] 20% | Training loss: 0.6887808821936872
Epoch: 2 | Iteration number: [950/4518] 21% | Training loss: 0.68876359425093
Epoch: 2 | Iteration number: [960/4518] 21% | Training loss: 0.6887581352765362
Epoch: 2 | Iteration number: [970/4518] 21% | Training loss: 0.6887518452614853
Epoch: 2 | Iteration number: [980/4518] 21% | Training loss: 0.6887437928087857
Epoch: 2 | Iteration number: [990/4518] 21% | Training loss: 0.6887258799389155
Epoch: 2 | Iteration number: [1000/4518] 22% | Training loss: 0.688734116435051
Epoch: 2 | Iteration number: [1010/4518] 22% | Training loss: 0.688728537712947
Epoch: 2 | Iteration number: [1020/4518] 22% | Training loss: 0.6887203517497754
Epoch: 2 | Iteration number: [1030/4518] 22% | Training loss: 0.6887167479806733
Epoch: 2 | Iteration number: [1040/4518] 23% | Training loss: 0.6887050040639364
Epoch: 2 | Iteration number: [1050/4518] 23% | Training loss: 0.6886950354916709
Epoch: 2 | Iteration number: [1060/4518] 23% | Training loss: 0.6886897484086595
Epoch: 2 | Iteration number: [1070/4518] 23% | Training loss: 0.6886876483386922
Epoch: 2 | Iteration number: [1080/4518] 23% | Training loss: 0.6886782116912029
Epoch: 2 | Iteration number: [1090/4518] 24% | Training loss: 0.6886799199318667
Epoch: 2 | Iteration number: [1100/4518] 24% | Training loss: 0.6886592931639064
Epoch: 2 | Iteration number: [1110/4518] 24% | Training loss: 0.6886346469054351
Epoch: 2 | Iteration number: [1120/4518] 24% | Training loss: 0.6886308837149825
Epoch: 2 | Iteration number: [1130/4518] 25% | Training loss: 0.6886200501855496
Epoch: 2 | Iteration number: [1140/4518] 25% | Training loss: 0.6886202445155696
Epoch: 2 | Iteration number: [1150/4518] 25% | Training loss: 0.6886072675559831
Epoch: 2 | Iteration number: [1160/4518] 25% | Training loss: 0.6886093806603859
Epoch: 2 | Iteration number: [1170/4518] 25% | Training loss: 0.68859882018505
Epoch: 2 | Iteration number: [1180/4518] 26% | Training loss: 0.6886037175433111
Epoch: 2 | Iteration number: [1190/4518] 26% | Training loss: 0.6885985429046535
Epoch: 2 | Iteration number: [1200/4518] 26% | Training loss: 0.688596327950557
Epoch: 2 | Iteration number: [1210/4518] 26% | Training loss: 0.6885821826694426
Epoch: 2 | Iteration number: [1220/4518] 27% | Training loss: 0.6885802044731671
Epoch: 2 | Iteration number: [1230/4518] 27% | Training loss: 0.6885737042116925
Epoch: 2 | Iteration number: [1240/4518] 27% | Training loss: 0.6885671443516208
Epoch: 2 | Iteration number: [1250/4518] 27% | Training loss: 0.6885672183036804
Epoch: 2 | Iteration number: [1260/4518] 27% | Training loss: 0.6885685309058144
Epoch: 2 | Iteration number: [1270/4518] 28% | Training loss: 0.688557864502659
Epoch: 2 | Iteration number: [1280/4518] 28% | Training loss: 0.6885572280269117
Epoch: 2 | Iteration number: [1290/4518] 28% | Training loss: 0.6885565630225248
Epoch: 2 | Iteration number: [1300/4518] 28% | Training loss: 0.6885465582517477
Epoch: 2 | Iteration number: [1310/4518] 28% | Training loss: 0.6885497696527088
Epoch: 2 | Iteration number: [1320/4518] 29% | Training loss: 0.6885398149941907
Epoch: 2 | Iteration number: [1330/4518] 29% | Training loss: 0.6885287244517104
Epoch: 2 | Iteration number: [1340/4518] 29% | Training loss: 0.6885212877793099
Epoch: 2 | Iteration number: [1350/4518] 29% | Training loss: 0.6885185528684545
Epoch: 2 | Iteration number: [1360/4518] 30% | Training loss: 0.6885128210134366
Epoch: 2 | Iteration number: [1370/4518] 30% | Training loss: 0.6885071275443057
Epoch: 2 | Iteration number: [1380/4518] 30% | Training loss: 0.6885058586148248
Epoch: 2 | Iteration number: [1390/4518] 30% | Training loss: 0.6885017111575861
Epoch: 2 | Iteration number: [1400/4518] 30% | Training loss: 0.6885000449419022
Epoch: 2 | Iteration number: [1410/4518] 31% | Training loss: 0.6884984059536711
Epoch: 2 | Iteration number: [1420/4518] 31% | Training loss: 0.6884949942709695
Epoch: 2 | Iteration number: [1430/4518] 31% | Training loss: 0.6884966463475795
Epoch: 2 | Iteration number: [1440/4518] 31% | Training loss: 0.6884937280168136
Epoch: 2 | Iteration number: [1450/4518] 32% | Training loss: 0.6884891156081495
Epoch: 2 | Iteration number: [1460/4518] 32% | Training loss: 0.6884856833170538
Epoch: 2 | Iteration number: [1470/4518] 32% | Training loss: 0.6884718907122709
Epoch: 2 | Iteration number: [1480/4518] 32% | Training loss: 0.688468781355265
Epoch: 2 | Iteration number: [1490/4518] 32% | Training loss: 0.688463714978839
Epoch: 2 | Iteration number: [1500/4518] 33% | Training loss: 0.6884627049366633
Epoch: 2 | Iteration number: [1510/4518] 33% | Training loss: 0.6884490780483018
Epoch: 2 | Iteration number: [1520/4518] 33% | Training loss: 0.6884484108733503
Epoch: 2 | Iteration number: [1530/4518] 33% | Training loss: 0.6884490346596911
Epoch: 2 | Iteration number: [1540/4518] 34% | Training loss: 0.6884522905984483
Epoch: 2 | Iteration number: [1550/4518] 34% | Training loss: 0.6884464621159339
Epoch: 2 | Iteration number: [1560/4518] 34% | Training loss: 0.6884441033387796
Epoch: 2 | Iteration number: [1570/4518] 34% | Training loss: 0.6884404192304915
Epoch: 2 | Iteration number: [1580/4518] 34% | Training loss: 0.6884371988758257
Epoch: 2 | Iteration number: [1590/4518] 35% | Training loss: 0.6884369859530491
Epoch: 2 | Iteration number: [1600/4518] 35% | Training loss: 0.6884285735338926
Epoch: 2 | Iteration number: [1610/4518] 35% | Training loss: 0.6884217367779394
Epoch: 2 | Iteration number: [1620/4518] 35% | Training loss: 0.6884116466766522
Epoch: 2 | Iteration number: [1630/4518] 36% | Training loss: 0.6884104627773074
Epoch: 2 | Iteration number: [1640/4518] 36% | Training loss: 0.6884111752233855
Epoch: 2 | Iteration number: [1650/4518] 36% | Training loss: 0.6884088816787257
Epoch: 2 | Iteration number: [1660/4518] 36% | Training loss: 0.6883978677083211
Epoch: 2 | Iteration number: [1670/4518] 36% | Training loss: 0.6883907754264192
Epoch: 2 | Iteration number: [1680/4518] 37% | Training loss: 0.688386527165061
Epoch: 2 | Iteration number: [1690/4518] 37% | Training loss: 0.6883920066808102
Epoch: 2 | Iteration number: [1700/4518] 37% | Training loss: 0.6883916836977005
Epoch: 2 | Iteration number: [1710/4518] 37% | Training loss: 0.6883921965172416
Epoch: 2 | Iteration number: [1720/4518] 38% | Training loss: 0.68838479667902
Epoch: 2 | Iteration number: [1730/4518] 38% | Training loss: 0.6883814523330314
Epoch: 2 | Iteration number: [1740/4518] 38% | Training loss: 0.688386007321292
Epoch: 2 | Iteration number: [1750/4518] 38% | Training loss: 0.6883801363195692
Epoch: 2 | Iteration number: [1760/4518] 38% | Training loss: 0.6883727050979029
Epoch: 2 | Iteration number: [1770/4518] 39% | Training loss: 0.6883665300695236
Epoch: 2 | Iteration number: [1780/4518] 39% | Training loss: 0.6883649591984374
Epoch: 2 | Iteration number: [1790/4518] 39% | Training loss: 0.688363469412873
Epoch: 2 | Iteration number: [1800/4518] 39% | Training loss: 0.6883593677481016
Epoch: 2 | Iteration number: [1810/4518] 40% | Training loss: 0.6883548067748876
Epoch: 2 | Iteration number: [1820/4518] 40% | Training loss: 0.6883490185161213
Epoch: 2 | Iteration number: [1830/4518] 40% | Training loss: 0.6883503577748283
Epoch: 2 | Iteration number: [1840/4518] 40% | Training loss: 0.6883500815085742
Epoch: 2 | Iteration number: [1850/4518] 40% | Training loss: 0.688351824154725
Epoch: 2 | Iteration number: [1860/4518] 41% | Training loss: 0.6883520265420278
Epoch: 2 | Iteration number: [1870/4518] 41% | Training loss: 0.6883516261603105
Epoch: 2 | Iteration number: [1880/4518] 41% | Training loss: 0.6883542595708624
Epoch: 2 | Iteration number: [1890/4518] 41% | Training loss: 0.6883559876648837
Epoch: 2 | Iteration number: [1900/4518] 42% | Training loss: 0.6883538949175885
Epoch: 2 | Iteration number: [1910/4518] 42% | Training loss: 0.6883484791086606
Epoch: 2 | Iteration number: [1920/4518] 42% | Training loss: 0.6883476071370145
Epoch: 2 | Iteration number: [1930/4518] 42% | Training loss: 0.6883405074863236
Epoch: 2 | Iteration number: [1940/4518] 42% | Training loss: 0.6883381799938753
Epoch: 2 | Iteration number: [1950/4518] 43% | Training loss: 0.6883264180024465
Epoch: 2 | Iteration number: [1960/4518] 43% | Training loss: 0.6883248959877053
Epoch: 2 | Iteration number: [1970/4518] 43% | Training loss: 0.688320428163267
Epoch: 2 | Iteration number: [1980/4518] 43% | Training loss: 0.6883124286478216
Epoch: 2 | Iteration number: [1990/4518] 44% | Training loss: 0.6883127917596443
Epoch: 2 | Iteration number: [2000/4518] 44% | Training loss: 0.6883058126270771
Epoch: 2 | Iteration number: [2010/4518] 44% | Training loss: 0.6882994378384073
Epoch: 2 | Iteration number: [2020/4518] 44% | Training loss: 0.6882936212686028
Epoch: 2 | Iteration number: [2030/4518] 44% | Training loss: 0.6882900749521302
Epoch: 2 | Iteration number: [2040/4518] 45% | Training loss: 0.6882889056322621
Epoch: 2 | Iteration number: [2050/4518] 45% | Training loss: 0.6882847737102974
Epoch: 2 | Iteration number: [2060/4518] 45% | Training loss: 0.6882778911335954
Epoch: 2 | Iteration number: [2070/4518] 45% | Training loss: 0.6882823173550592
Epoch: 2 | Iteration number: [2080/4518] 46% | Training loss: 0.6882822416722775
Epoch: 2 | Iteration number: [2090/4518] 46% | Training loss: 0.6882838073244506
Epoch: 2 | Iteration number: [2100/4518] 46% | Training loss: 0.6882872951030731
Epoch: 2 | Iteration number: [2110/4518] 46% | Training loss: 0.6882854098957297
Epoch: 2 | Iteration number: [2120/4518] 46% | Training loss: 0.6882829635210757
Epoch: 2 | Iteration number: [2130/4518] 47% | Training loss: 0.6882813667187668
Epoch: 2 | Iteration number: [2140/4518] 47% | Training loss: 0.6882805944324654
Epoch: 2 | Iteration number: [2150/4518] 47% | Training loss: 0.6882810890397361
Epoch: 2 | Iteration number: [2160/4518] 47% | Training loss: 0.6882804904271055
Epoch: 2 | Iteration number: [2170/4518] 48% | Training loss: 0.6882814958897604
Epoch: 2 | Iteration number: [2180/4518] 48% | Training loss: 0.6882795505294013
Epoch: 2 | Iteration number: [2190/4518] 48% | Training loss: 0.6882776854517253
Epoch: 2 | Iteration number: [2200/4518] 48% | Training loss: 0.6882762684334408
Epoch: 2 | Iteration number: [2210/4518] 48% | Training loss: 0.6882720436985137
Epoch: 2 | Iteration number: [2220/4518] 49% | Training loss: 0.6882699009802964
Epoch: 2 | Iteration number: [2230/4518] 49% | Training loss: 0.6882691861535402
Epoch: 2 | Iteration number: [2240/4518] 49% | Training loss: 0.6882665945483105
Epoch: 2 | Iteration number: [2250/4518] 49% | Training loss: 0.6882639555931092
Epoch: 2 | Iteration number: [2260/4518] 50% | Training loss: 0.6882590967996985
Epoch: 2 | Iteration number: [2270/4518] 50% | Training loss: 0.6882592485602207
Epoch: 2 | Iteration number: [2280/4518] 50% | Training loss: 0.6882585859089567
Epoch: 2 | Iteration number: [2290/4518] 50% | Training loss: 0.688259239436237
Epoch: 2 | Iteration number: [2300/4518] 50% | Training loss: 0.6882569992023966
Epoch: 2 | Iteration number: [2310/4518] 51% | Training loss: 0.6882548104891013
Epoch: 2 | Iteration number: [2320/4518] 51% | Training loss: 0.6882508189770682
Epoch: 2 | Iteration number: [2330/4518] 51% | Training loss: 0.6882501402382175
Epoch: 2 | Iteration number: [2340/4518] 51% | Training loss: 0.6882442279249175
Epoch: 2 | Iteration number: [2350/4518] 52% | Training loss: 0.6882428288713415
Epoch: 2 | Iteration number: [2360/4518] 52% | Training loss: 0.6882423472859092
Epoch: 2 | Iteration number: [2370/4518] 52% | Training loss: 0.6882415472706662
Epoch: 2 | Iteration number: [2380/4518] 52% | Training loss: 0.688246025858807
Epoch: 2 | Iteration number: [2390/4518] 52% | Training loss: 0.6882450472360875
Epoch: 2 | Iteration number: [2400/4518] 53% | Training loss: 0.6882441297670205
Epoch: 2 | Iteration number: [2410/4518] 53% | Training loss: 0.6882426697683532
Epoch: 2 | Iteration number: [2420/4518] 53% | Training loss: 0.6882392654241609
Epoch: 2 | Iteration number: [2430/4518] 53% | Training loss: 0.6882380890993425
Epoch: 2 | Iteration number: [2440/4518] 54% | Training loss: 0.6882339316557665
Epoch: 2 | Iteration number: [2450/4518] 54% | Training loss: 0.6882366043694166
Epoch: 2 | Iteration number: [2460/4518] 54% | Training loss: 0.6882380535205205
Epoch: 2 | Iteration number: [2470/4518] 54% | Training loss: 0.6882348405687433
Epoch: 2 | Iteration number: [2480/4518] 54% | Training loss: 0.6882325432954296
Epoch: 2 | Iteration number: [2490/4518] 55% | Training loss: 0.6882302883877812
Epoch: 2 | Iteration number: [2500/4518] 55% | Training loss: 0.6882348522663116
Epoch: 2 | Iteration number: [2510/4518] 55% | Training loss: 0.6882331995850065
Epoch: 2 | Iteration number: [2520/4518] 55% | Training loss: 0.6882324555090495
Epoch: 2 | Iteration number: [2530/4518] 55% | Training loss: 0.6882330200417711
Epoch: 2 | Iteration number: [2540/4518] 56% | Training loss: 0.6882357873785214
Epoch: 2 | Iteration number: [2550/4518] 56% | Training loss: 0.6882330420437981
Epoch: 2 | Iteration number: [2560/4518] 56% | Training loss: 0.6882317322539165
Epoch: 2 | Iteration number: [2570/4518] 56% | Training loss: 0.6882309428680732
Epoch: 2 | Iteration number: [2580/4518] 57% | Training loss: 0.6882268848807312
Epoch: 2 | Iteration number: [2590/4518] 57% | Training loss: 0.688220810176783
Epoch: 2 | Iteration number: [2600/4518] 57% | Training loss: 0.6882215550541878
Epoch: 2 | Iteration number: [2610/4518] 57% | Training loss: 0.688223256576107
Epoch: 2 | Iteration number: [2620/4518] 57% | Training loss: 0.6882183226920267
Epoch: 2 | Iteration number: [2630/4518] 58% | Training loss: 0.688211041938216
Epoch: 2 | Iteration number: [2640/4518] 58% | Training loss: 0.6882110433370778
Epoch: 2 | Iteration number: [2650/4518] 58% | Training loss: 0.6882114023082662
Epoch: 2 | Iteration number: [2660/4518] 58% | Training loss: 0.6882104469645293
Epoch: 2 | Iteration number: [2670/4518] 59% | Training loss: 0.6882084883554151
Epoch: 2 | Iteration number: [2680/4518] 59% | Training loss: 0.688204353046951
Epoch: 2 | Iteration number: [2690/4518] 59% | Training loss: 0.6882026774954175
Epoch: 2 | Iteration number: [2700/4518] 59% | Training loss: 0.6882017233195128
Epoch: 2 | Iteration number: [2710/4518] 59% | Training loss: 0.6881978197071386
Epoch: 2 | Iteration number: [2720/4518] 60% | Training loss: 0.6881943787502892
Epoch: 2 | Iteration number: [2730/4518] 60% | Training loss: 0.688194713072899
Epoch: 2 | Iteration number: [2740/4518] 60% | Training loss: 0.6881967285253706
Epoch: 2 | Iteration number: [2750/4518] 60% | Training loss: 0.6881901989199899
Epoch: 2 | Iteration number: [2760/4518] 61% | Training loss: 0.6881918281532716
Epoch: 2 | Iteration number: [2770/4518] 61% | Training loss: 0.6881915784699822
Epoch: 2 | Iteration number: [2780/4518] 61% | Training loss: 0.6881844385922384
Epoch: 2 | Iteration number: [2790/4518] 61% | Training loss: 0.6881823101992248
Epoch: 2 | Iteration number: [2800/4518] 61% | Training loss: 0.688180013618299
Epoch: 2 | Iteration number: [2810/4518] 62% | Training loss: 0.6881819058567604
Epoch: 2 | Iteration number: [2820/4518] 62% | Training loss: 0.6881812904532074
Epoch: 2 | Iteration number: [2830/4518] 62% | Training loss: 0.6881826107999041
Epoch: 2 | Iteration number: [2840/4518] 62% | Training loss: 0.6881768291475068
Epoch: 2 | Iteration number: [2850/4518] 63% | Training loss: 0.6881769672611303
Epoch: 2 | Iteration number: [2860/4518] 63% | Training loss: 0.6881767034530639
Epoch: 2 | Iteration number: [2870/4518] 63% | Training loss: 0.6881760113122987
Epoch: 2 | Iteration number: [2880/4518] 63% | Training loss: 0.6881707878576384
Epoch: 2 | Iteration number: [2890/4518] 63% | Training loss: 0.6881675035895773
Epoch: 2 | Iteration number: [2900/4518] 64% | Training loss: 0.6881621968335119
Epoch: 2 | Iteration number: [2910/4518] 64% | Training loss: 0.6881609949868979
Epoch: 2 | Iteration number: [2920/4518] 64% | Training loss: 0.6881606429407041
Epoch: 2 | Iteration number: [2930/4518] 64% | Training loss: 0.6881586211940127
Epoch: 2 | Iteration number: [2940/4518] 65% | Training loss: 0.6881596989169413
Epoch: 2 | Iteration number: [2950/4518] 65% | Training loss: 0.6881538644281484
Epoch: 2 | Iteration number: [2960/4518] 65% | Training loss: 0.6881539596093668
Epoch: 2 | Iteration number: [2970/4518] 65% | Training loss: 0.6881476035021772
Epoch: 2 | Iteration number: [2980/4518] 65% | Training loss: 0.6881460433838351
Epoch: 2 | Iteration number: [2990/4518] 66% | Training loss: 0.6881413180094499
Epoch: 2 | Iteration number: [3000/4518] 66% | Training loss: 0.6881394776304562
Epoch: 2 | Iteration number: [3010/4518] 66% | Training loss: 0.6881371292759018
Epoch: 2 | Iteration number: [3020/4518] 66% | Training loss: 0.6881341630851986
Epoch: 2 | Iteration number: [3030/4518] 67% | Training loss: 0.6881289747091803
Epoch: 2 | Iteration number: [3040/4518] 67% | Training loss: 0.6881281113938281
Epoch: 2 | Iteration number: [3050/4518] 67% | Training loss: 0.6881265211691622
Epoch: 2 | Iteration number: [3060/4518] 67% | Training loss: 0.6881215671113893
Epoch: 2 | Iteration number: [3070/4518] 67% | Training loss: 0.6881206457700325
Epoch: 2 | Iteration number: [3080/4518] 68% | Training loss: 0.6881223841727554
Epoch: 2 | Iteration number: [3090/4518] 68% | Training loss: 0.6881190336637898
Epoch: 2 | Iteration number: [3100/4518] 68% | Training loss: 0.6881178380981569
Epoch: 2 | Iteration number: [3110/4518] 68% | Training loss: 0.6881143873910812
Epoch: 2 | Iteration number: [3120/4518] 69% | Training loss: 0.6881123689886851
Epoch: 2 | Iteration number: [3130/4518] 69% | Training loss: 0.688114185245654
Epoch: 2 | Iteration number: [3140/4518] 69% | Training loss: 0.6881165589306765
Epoch: 2 | Iteration number: [3150/4518] 69% | Training loss: 0.6881105927626292
Epoch: 2 | Iteration number: [3160/4518] 69% | Training loss: 0.6881089811083637
Epoch: 2 | Iteration number: [3170/4518] 70% | Training loss: 0.6881066577479666
Epoch: 2 | Iteration number: [3180/4518] 70% | Training loss: 0.6881063532529387
Epoch: 2 | Iteration number: [3190/4518] 70% | Training loss: 0.6881030434538205
Epoch: 2 | Iteration number: [3200/4518] 70% | Training loss: 0.6881053818389773
Epoch: 2 | Iteration number: [3210/4518] 71% | Training loss: 0.6881060905359987
Epoch: 2 | Iteration number: [3220/4518] 71% | Training loss: 0.688109189494056
Epoch: 2 | Iteration number: [3230/4518] 71% | Training loss: 0.6881061121959804
Epoch: 2 | Iteration number: [3240/4518] 71% | Training loss: 0.6881011735509943
Epoch: 2 | Iteration number: [3250/4518] 71% | Training loss: 0.6880981009740096
Epoch: 2 | Iteration number: [3260/4518] 72% | Training loss: 0.6880978262863277
Epoch: 2 | Iteration number: [3270/4518] 72% | Training loss: 0.6880948596408972
Epoch: 2 | Iteration number: [3280/4518] 72% | Training loss: 0.6880940866543026
Epoch: 2 | Iteration number: [3290/4518] 72% | Training loss: 0.6880921053306672
Epoch: 2 | Iteration number: [3300/4518] 73% | Training loss: 0.6880889255350287
Epoch: 2 | Iteration number: [3310/4518] 73% | Training loss: 0.6880909934504875
Epoch: 2 | Iteration number: [3320/4518] 73% | Training loss: 0.6880925998450762
Epoch: 2 | Iteration number: [3330/4518] 73% | Training loss: 0.6880918550419736
Epoch: 2 | Iteration number: [3340/4518] 73% | Training loss: 0.6880890571785544
Epoch: 2 | Iteration number: [3350/4518] 74% | Training loss: 0.6880862545433329
Epoch: 2 | Iteration number: [3360/4518] 74% | Training loss: 0.6880848563497974
Epoch: 2 | Iteration number: [3370/4518] 74% | Training loss: 0.6880815161618705
Epoch: 2 | Iteration number: [3380/4518] 74% | Training loss: 0.6880790235904547
Epoch: 2 | Iteration number: [3390/4518] 75% | Training loss: 0.6880807703575201
Epoch: 2 | Iteration number: [3400/4518] 75% | Training loss: 0.6880751649597112
Epoch: 2 | Iteration number: [3410/4518] 75% | Training loss: 0.688072110550844
Epoch: 2 | Iteration number: [3420/4518] 75% | Training loss: 0.6880724910058473
Epoch: 2 | Iteration number: [3430/4518] 75% | Training loss: 0.6880676308282958
Epoch: 2 | Iteration number: [3440/4518] 76% | Training loss: 0.6880652005589285
Epoch: 2 | Iteration number: [3450/4518] 76% | Training loss: 0.6880657244592473
Epoch: 2 | Iteration number: [3460/4518] 76% | Training loss: 0.6880663985117322
Epoch: 2 | Iteration number: [3470/4518] 76% | Training loss: 0.6880670967809749
Epoch: 2 | Iteration number: [3480/4518] 77% | Training loss: 0.6880661409819263
Epoch: 2 | Iteration number: [3490/4518] 77% | Training loss: 0.6880654266194832
Epoch: 2 | Iteration number: [3500/4518] 77% | Training loss: 0.688057600736618
Epoch: 2 | Iteration number: [3510/4518] 77% | Training loss: 0.6880565074773936
Epoch: 2 | Iteration number: [3520/4518] 77% | Training loss: 0.6880560011856935
Epoch: 2 | Iteration number: [3530/4518] 78% | Training loss: 0.6880602822425346
Epoch: 2 | Iteration number: [3540/4518] 78% | Training loss: 0.6880562232880942
Epoch: 2 | Iteration number: [3550/4518] 78% | Training loss: 0.688056181148744
Epoch: 2 | Iteration number: [3560/4518] 78% | Training loss: 0.6880566431900089
Epoch: 2 | Iteration number: [3570/4518] 79% | Training loss: 0.688058753324156
Epoch: 2 | Iteration number: [3580/4518] 79% | Training loss: 0.6880577749380187
Epoch: 2 | Iteration number: [3590/4518] 79% | Training loss: 0.6880544559205143
Epoch: 2 | Iteration number: [3600/4518] 79% | Training loss: 0.6880536073446274
Epoch: 2 | Iteration number: [3610/4518] 79% | Training loss: 0.6880507996703119
Epoch: 2 | Iteration number: [3620/4518] 80% | Training loss: 0.6880477722178506
Epoch: 2 | Iteration number: [3630/4518] 80% | Training loss: 0.6880478297383332
Epoch: 2 | Iteration number: [3640/4518] 80% | Training loss: 0.6880485159682703
Epoch: 2 | Iteration number: [3650/4518] 80% | Training loss: 0.6880472421809418
Epoch: 2 | Iteration number: [3660/4518] 81% | Training loss: 0.688045510258831
Epoch: 2 | Iteration number: [3670/4518] 81% | Training loss: 0.6880442171070816
Epoch: 2 | Iteration number: [3680/4518] 81% | Training loss: 0.6880430196290431
Epoch: 2 | Iteration number: [3690/4518] 81% | Training loss: 0.6880381656533011
Epoch: 2 | Iteration number: [3700/4518] 81% | Training loss: 0.6880375984230557
Epoch: 2 | Iteration number: [3710/4518] 82% | Training loss: 0.688037067812408
Epoch: 2 | Iteration number: [3720/4518] 82% | Training loss: 0.6880341492833629
Epoch: 2 | Iteration number: [3730/4518] 82% | Training loss: 0.6880303443117372
Epoch: 2 | Iteration number: [3740/4518] 82% | Training loss: 0.6880287446758964
Epoch: 2 | Iteration number: [3750/4518] 83% | Training loss: 0.6880253815015157
Epoch: 2 | Iteration number: [3760/4518] 83% | Training loss: 0.6880258694608161
Epoch: 2 | Iteration number: [3770/4518] 83% | Training loss: 0.6880239768433002
Epoch: 2 | Iteration number: [3780/4518] 83% | Training loss: 0.6880237518794953
Epoch: 2 | Iteration number: [3790/4518] 83% | Training loss: 0.6880253865725132
Epoch: 2 | Iteration number: [3800/4518] 84% | Training loss: 0.6880220081461104
Epoch: 2 | Iteration number: [3810/4518] 84% | Training loss: 0.6880191226174512
Epoch: 2 | Iteration number: [3820/4518] 84% | Training loss: 0.6880177279105362
Epoch: 2 | Iteration number: [3830/4518] 84% | Training loss: 0.6880147184155317
Epoch: 2 | Iteration number: [3840/4518] 84% | Training loss: 0.6880137130618096
Epoch: 2 | Iteration number: [3850/4518] 85% | Training loss: 0.6880121410976757
Epoch: 2 | Iteration number: [3860/4518] 85% | Training loss: 0.6880109535288934
Epoch: 2 | Iteration number: [3870/4518] 85% | Training loss: 0.6880102941386151
Epoch: 2 | Iteration number: [3880/4518] 85% | Training loss: 0.6880105370713263
Epoch: 2 | Iteration number: [3890/4518] 86% | Training loss: 0.6880102177512063
Epoch: 2 | Iteration number: [3900/4518] 86% | Training loss: 0.6880093899445656
Epoch: 2 | Iteration number: [3910/4518] 86% | Training loss: 0.6880101497825759
Epoch: 2 | Iteration number: [3920/4518] 86% | Training loss: 0.6880108352826566
Epoch: 2 | Iteration number: [3930/4518] 86% | Training loss: 0.6880101552294714
Epoch: 2 | Iteration number: [3940/4518] 87% | Training loss: 0.6880117715917868
Epoch: 2 | Iteration number: [3950/4518] 87% | Training loss: 0.6880088671551475
Epoch: 2 | Iteration number: [3960/4518] 87% | Training loss: 0.6880068030321237
Epoch: 2 | Iteration number: [3970/4518] 87% | Training loss: 0.6880020923668552
Epoch: 2 | Iteration number: [3980/4518] 88% | Training loss: 0.6879998871729003
Epoch: 2 | Iteration number: [3990/4518] 88% | Training loss: 0.688001155898087
Epoch: 2 | Iteration number: [4000/4518] 88% | Training loss: 0.6879999472945929
Epoch: 2 | Iteration number: [4010/4518] 88% | Training loss: 0.6879996489854228
Epoch: 2 | Iteration number: [4020/4518] 88% | Training loss: 0.6880007036586306
Epoch: 2 | Iteration number: [4030/4518] 89% | Training loss: 0.6880036840219947
Epoch: 2 | Iteration number: [4040/4518] 89% | Training loss: 0.6880059275444191
Epoch: 2 | Iteration number: [4050/4518] 89% | Training loss: 0.6880052294260189
Epoch: 2 | Iteration number: [4060/4518] 89% | Training loss: 0.6880044415519743
Epoch: 2 | Iteration number: [4070/4518] 90% | Training loss: 0.6880050885882366
Epoch: 2 | Iteration number: [4080/4518] 90% | Training loss: 0.6880048796534538
Epoch: 2 | Iteration number: [4090/4518] 90% | Training loss: 0.6880023967665974
Epoch: 2 | Iteration number: [4100/4518] 90% | Training loss: 0.6880023090723084
Epoch: 2 | Iteration number: [4110/4518] 90% | Training loss: 0.688003373479611
Epoch: 2 | Iteration number: [4120/4518] 91% | Training loss: 0.6879991077682347
Epoch: 2 | Iteration number: [4130/4518] 91% | Training loss: 0.6880028009703315
Epoch: 2 | Iteration number: [4140/4518] 91% | Training loss: 0.6880036080661027
Epoch: 2 | Iteration number: [4150/4518] 91% | Training loss: 0.6880036831620228
Epoch: 2 | Iteration number: [4160/4518] 92% | Training loss: 0.6880040656631956
Epoch: 2 | Iteration number: [4170/4518] 92% | Training loss: 0.6880010067844848
Epoch: 2 | Iteration number: [4180/4518] 92% | Training loss: 0.6880001156809228
Epoch: 2 | Iteration number: [4190/4518] 92% | Training loss: 0.6879981982395017
Epoch: 2 | Iteration number: [4200/4518] 92% | Training loss: 0.6879966233174006
Epoch: 2 | Iteration number: [4210/4518] 93% | Training loss: 0.6879949145390699
Epoch: 2 | Iteration number: [4220/4518] 93% | Training loss: 0.6879958202488614
Epoch: 2 | Iteration number: [4230/4518] 93% | Training loss: 0.6879942588490515
Epoch: 2 | Iteration number: [4240/4518] 93% | Training loss: 0.6879912054341919
Epoch: 2 | Iteration number: [4250/4518] 94% | Training loss: 0.6879903317199034
Epoch: 2 | Iteration number: [4260/4518] 94% | Training loss: 0.6879894310040093
Epoch: 2 | Iteration number: [4270/4518] 94% | Training loss: 0.6879872516111691
Epoch: 2 | Iteration number: [4280/4518] 94% | Training loss: 0.6879860808637654
Epoch: 2 | Iteration number: [4290/4518] 94% | Training loss: 0.6879835403326786
Epoch: 2 | Iteration number: [4300/4518] 95% | Training loss: 0.6879823660850525
Epoch: 2 | Iteration number: [4310/4518] 95% | Training loss: 0.6879825668655802
Epoch: 2 | Iteration number: [4320/4518] 95% | Training loss: 0.6879827549336133
Epoch: 2 | Iteration number: [4330/4518] 95% | Training loss: 0.6879809513516019
Epoch: 2 | Iteration number: [4340/4518] 96% | Training loss: 0.6879776479599113
Epoch: 2 | Iteration number: [4350/4518] 96% | Training loss: 0.6879786767630741
Epoch: 2 | Iteration number: [4360/4518] 96% | Training loss: 0.6879775896395018
Epoch: 2 | Iteration number: [4370/4518] 96% | Training loss: 0.6879779745703158
Epoch: 2 | Iteration number: [4380/4518] 96% | Training loss: 0.6879788370573358
Epoch: 2 | Iteration number: [4390/4518] 97% | Training loss: 0.6879781052028943
Epoch: 2 | Iteration number: [4400/4518] 97% | Training loss: 0.6879781826111403
Epoch: 2 | Iteration number: [4410/4518] 97% | Training loss: 0.6879798821851509
Epoch: 2 | Iteration number: [4420/4518] 97% | Training loss: 0.6879813656413177
Epoch: 2 | Iteration number: [4430/4518] 98% | Training loss: 0.6879791495627797
Epoch: 2 | Iteration number: [4440/4518] 98% | Training loss: 0.6879789573920739
Epoch: 2 | Iteration number: [4450/4518] 98% | Training loss: 0.6879769429597962
Epoch: 2 | Iteration number: [4460/4518] 98% | Training loss: 0.6879732730677309
Epoch: 2 | Iteration number: [4470/4518] 98% | Training loss: 0.6879706329280632
Epoch: 2 | Iteration number: [4480/4518] 99% | Training loss: 0.6879700631834567
Epoch: 2 | Iteration number: [4490/4518] 99% | Training loss: 0.687971866635278
Epoch: 2 | Iteration number: [4500/4518] 99% | Training loss: 0.6879698401954439
Epoch: 2 | Iteration number: [4510/4518] 99% | Training loss: 0.6879645972981421

 End of epoch: 2 | Train Loss: 0.687812905453538 | Training Time: 630 

 End of epoch: 2 | Eval Loss: 0.6905265024730137 | Evaluating Time: 17 
Epoch: 3 | Iteration number: [10/4518] 0% | Training loss: 0.756533807516098
Epoch: 3 | Iteration number: [20/4518] 0% | Training loss: 0.7215474992990494
Epoch: 3 | Iteration number: [30/4518] 0% | Training loss: 0.7104891975720723
Epoch: 3 | Iteration number: [40/4518] 0% | Training loss: 0.7050283715128899
Epoch: 3 | Iteration number: [50/4518] 1% | Training loss: 0.7016331493854523
Epoch: 3 | Iteration number: [60/4518] 1% | Training loss: 0.6992487162351608
Epoch: 3 | Iteration number: [70/4518] 1% | Training loss: 0.6975189464432853
Epoch: 3 | Iteration number: [80/4518] 1% | Training loss: 0.6962449327111244
Epoch: 3 | Iteration number: [90/4518] 1% | Training loss: 0.6952384253342946
Epoch: 3 | Iteration number: [100/4518] 2% | Training loss: 0.694545469880104
Epoch: 3 | Iteration number: [110/4518] 2% | Training loss: 0.6938439011573792
Epoch: 3 | Iteration number: [120/4518] 2% | Training loss: 0.6933214376370113
Epoch: 3 | Iteration number: [130/4518] 2% | Training loss: 0.6929030024088346
Epoch: 3 | Iteration number: [140/4518] 3% | Training loss: 0.6926263655935015
Epoch: 3 | Iteration number: [150/4518] 3% | Training loss: 0.6922762966156006
Epoch: 3 | Iteration number: [160/4518] 3% | Training loss: 0.6920267645269632
Epoch: 3 | Iteration number: [170/4518] 3% | Training loss: 0.6918080452610464
Epoch: 3 | Iteration number: [180/4518] 3% | Training loss: 0.6915896270010207
Epoch: 3 | Iteration number: [190/4518] 4% | Training loss: 0.6914658750358381
Epoch: 3 | Iteration number: [200/4518] 4% | Training loss: 0.6912403926253319
Epoch: 3 | Iteration number: [210/4518] 4% | Training loss: 0.6909836397284553
Epoch: 3 | Iteration number: [220/4518] 4% | Training loss: 0.6908278676596555
Epoch: 3 | Iteration number: [230/4518] 5% | Training loss: 0.6906820636728536
Epoch: 3 | Iteration number: [240/4518] 5% | Training loss: 0.6905536157389481
Epoch: 3 | Iteration number: [250/4518] 5% | Training loss: 0.6904709424972534
Epoch: 3 | Iteration number: [260/4518] 5% | Training loss: 0.690321653852096
Epoch: 3 | Iteration number: [270/4518] 5% | Training loss: 0.6902624057398902
Epoch: 3 | Iteration number: [280/4518] 6% | Training loss: 0.6901256165334156
Epoch: 3 | Iteration number: [290/4518] 6% | Training loss: 0.690043411583736
Epoch: 3 | Iteration number: [300/4518] 6% | Training loss: 0.6899410863717397
Epoch: 3 | Iteration number: [310/4518] 6% | Training loss: 0.6899057109509745
Epoch: 3 | Iteration number: [320/4518] 7% | Training loss: 0.6898020742461085
Epoch: 3 | Iteration number: [330/4518] 7% | Training loss: 0.6897627118862036
Epoch: 3 | Iteration number: [340/4518] 7% | Training loss: 0.6896989974905463
Epoch: 3 | Iteration number: [350/4518] 7% | Training loss: 0.6896175720010485
Epoch: 3 | Iteration number: [360/4518] 7% | Training loss: 0.6895423909028371
Epoch: 3 | Iteration number: [370/4518] 8% | Training loss: 0.6894949532843925
Epoch: 3 | Iteration number: [380/4518] 8% | Training loss: 0.6894739194920189
Epoch: 3 | Iteration number: [390/4518] 8% | Training loss: 0.6894024790861668
Epoch: 3 | Iteration number: [400/4518] 8% | Training loss: 0.6893290191888809
Epoch: 3 | Iteration number: [410/4518] 9% | Training loss: 0.6892811634191652
Epoch: 3 | Iteration number: [420/4518] 9% | Training loss: 0.6892009268204371
Epoch: 3 | Iteration number: [430/4518] 9% | Training loss: 0.6891535412433536
Epoch: 3 | Iteration number: [440/4518] 9% | Training loss: 0.6891014731743119
Epoch: 3 | Iteration number: [450/4518] 9% | Training loss: 0.6890322119659847
Epoch: 3 | Iteration number: [460/4518] 10% | Training loss: 0.6889712366073028
Epoch: 3 | Iteration number: [470/4518] 10% | Training loss: 0.6889587664857824
Epoch: 3 | Iteration number: [480/4518] 10% | Training loss: 0.6889078218489886
Epoch: 3 | Iteration number: [490/4518] 10% | Training loss: 0.6888832705361503
Epoch: 3 | Iteration number: [500/4518] 11% | Training loss: 0.6888834952116013
Epoch: 3 | Iteration number: [510/4518] 11% | Training loss: 0.6888342263651829
Epoch: 3 | Iteration number: [520/4518] 11% | Training loss: 0.688795410325894
Epoch: 3 | Iteration number: [530/4518] 11% | Training loss: 0.6887622788267316
Epoch: 3 | Iteration number: [540/4518] 11% | Training loss: 0.6887549878270538
Epoch: 3 | Iteration number: [550/4518] 12% | Training loss: 0.6887337246808138
Epoch: 3 | Iteration number: [560/4518] 12% | Training loss: 0.6887258679739067
Epoch: 3 | Iteration number: [570/4518] 12% | Training loss: 0.6886941715290672
Epoch: 3 | Iteration number: [580/4518] 12% | Training loss: 0.6886560021803296
Epoch: 3 | Iteration number: [590/4518] 13% | Training loss: 0.6886238388085769
Epoch: 3 | Iteration number: [600/4518] 13% | Training loss: 0.6886084757248561
Epoch: 3 | Iteration number: [610/4518] 13% | Training loss: 0.6885893741592032
Epoch: 3 | Iteration number: [620/4518] 13% | Training loss: 0.6885749628466945
Epoch: 3 | Iteration number: [630/4518] 13% | Training loss: 0.6885499395075299
Epoch: 3 | Iteration number: [640/4518] 14% | Training loss: 0.6885579340159893
Epoch: 3 | Iteration number: [650/4518] 14% | Training loss: 0.6885267173326932
Epoch: 3 | Iteration number: [660/4518] 14% | Training loss: 0.6885155450214039
Epoch: 3 | Iteration number: [670/4518] 14% | Training loss: 0.6884855668046581
Epoch: 3 | Iteration number: [680/4518] 15% | Training loss: 0.6884730103261331
Epoch: 3 | Iteration number: [690/4518] 15% | Training loss: 0.6884565002676369
Epoch: 3 | Iteration number: [700/4518] 15% | Training loss: 0.6884414256470544
Epoch: 3 | Iteration number: [710/4518] 15% | Training loss: 0.6884171935873972
Epoch: 3 | Iteration number: [720/4518] 15% | Training loss: 0.688390575018194
Epoch: 3 | Iteration number: [730/4518] 16% | Training loss: 0.6883777957256526
Epoch: 3 | Iteration number: [740/4518] 16% | Training loss: 0.6883814210021818
Epoch: 3 | Iteration number: [750/4518] 16% | Training loss: 0.6883532202243805
Epoch: 3 | Iteration number: [760/4518] 16% | Training loss: 0.6883284422127824
Epoch: 3 | Iteration number: [770/4518] 17% | Training loss: 0.6883173551652338
Epoch: 3 | Iteration number: [780/4518] 17% | Training loss: 0.6883092318589871
Epoch: 3 | Iteration number: [790/4518] 17% | Training loss: 0.6883024887193607
Epoch: 3 | Iteration number: [800/4518] 17% | Training loss: 0.6882956716418266
Epoch: 3 | Iteration number: [810/4518] 17% | Training loss: 0.6882928564224714
Epoch: 3 | Iteration number: [820/4518] 18% | Training loss: 0.6882786766784947
Epoch: 3 | Iteration number: [830/4518] 18% | Training loss: 0.6882844533546861
Epoch: 3 | Iteration number: [840/4518] 18% | Training loss: 0.6882892181475957
Epoch: 3 | Iteration number: [850/4518] 18% | Training loss: 0.6882803692537196
Epoch: 3 | Iteration number: [860/4518] 19% | Training loss: 0.6882745665866276
Epoch: 3 | Iteration number: [870/4518] 19% | Training loss: 0.6882642471242225
Epoch: 3 | Iteration number: [880/4518] 19% | Training loss: 0.6882555685937405
Epoch: 3 | Iteration number: [890/4518] 19% | Training loss: 0.688254549530115
Epoch: 3 | Iteration number: [900/4518] 19% | Training loss: 0.6882467446724574
Epoch: 3 | Iteration number: [910/4518] 20% | Training loss: 0.6882336481586917
Epoch: 3 | Iteration number: [920/4518] 20% | Training loss: 0.6882281493881475
Epoch: 3 | Iteration number: [930/4518] 20% | Training loss: 0.6882181863630972
Epoch: 3 | Iteration number: [940/4518] 20% | Training loss: 0.6882038293366737
Epoch: 3 | Iteration number: [950/4518] 21% | Training loss: 0.6881984151037116
Epoch: 3 | Iteration number: [960/4518] 21% | Training loss: 0.6882043035080035
Epoch: 3 | Iteration number: [970/4518] 21% | Training loss: 0.6882004911752091
Epoch: 3 | Iteration number: [980/4518] 21% | Training loss: 0.6881975717690526
Epoch: 3 | Iteration number: [990/4518] 21% | Training loss: 0.6882000238004357
Epoch: 3 | Iteration number: [1000/4518] 22% | Training loss: 0.6881977793574333
Epoch: 3 | Iteration number: [1010/4518] 22% | Training loss: 0.6881832974972111
Epoch: 3 | Iteration number: [1020/4518] 22% | Training loss: 0.688172545152552
Epoch: 3 | Iteration number: [1030/4518] 22% | Training loss: 0.6881653253893251
Epoch: 3 | Iteration number: [1040/4518] 23% | Training loss: 0.6881466383544298
Epoch: 3 | Iteration number: [1050/4518] 23% | Training loss: 0.6881395720300221
Epoch: 3 | Iteration number: [1060/4518] 23% | Training loss: 0.6881418883238198
Epoch: 3 | Iteration number: [1070/4518] 23% | Training loss: 0.6881305077365626
Epoch: 3 | Iteration number: [1080/4518] 23% | Training loss: 0.6881333019446444
Epoch: 3 | Iteration number: [1090/4518] 24% | Training loss: 0.6881338879055933
Epoch: 3 | Iteration number: [1100/4518] 24% | Training loss: 0.6881326167149977
Epoch: 3 | Iteration number: [1110/4518] 24% | Training loss: 0.6881322651833027
Epoch: 3 | Iteration number: [1120/4518] 24% | Training loss: 0.6881324267813138
Epoch: 3 | Iteration number: [1130/4518] 25% | Training loss: 0.6881254117573257
Epoch: 3 | Iteration number: [1140/4518] 25% | Training loss: 0.6881185110200916
Epoch: 3 | Iteration number: [1150/4518] 25% | Training loss: 0.6881081523065982
Epoch: 3 | Iteration number: [1160/4518] 25% | Training loss: 0.6881037004548928
Epoch: 3 | Iteration number: [1170/4518] 25% | Training loss: 0.688101235516051
Epoch: 3 | Iteration number: [1180/4518] 26% | Training loss: 0.6880783231581672
Epoch: 3 | Iteration number: [1190/4518] 26% | Training loss: 0.6880733408847777
Epoch: 3 | Iteration number: [1200/4518] 26% | Training loss: 0.6880680234233538
Epoch: 3 | Iteration number: [1210/4518] 26% | Training loss: 0.6880656508374805
Epoch: 3 | Iteration number: [1220/4518] 27% | Training loss: 0.6880627996608859
Epoch: 3 | Iteration number: [1230/4518] 27% | Training loss: 0.6880630527085405
Epoch: 3 | Iteration number: [1240/4518] 27% | Training loss: 0.6880607917424171
Epoch: 3 | Iteration number: [1250/4518] 27% | Training loss: 0.6880587057113647
Epoch: 3 | Iteration number: [1260/4518] 27% | Training loss: 0.6880556638278659
Epoch: 3 | Iteration number: [1270/4518] 28% | Training loss: 0.6880516949131733
Epoch: 3 | Iteration number: [1280/4518] 28% | Training loss: 0.6880405757576227
Epoch: 3 | Iteration number: [1290/4518] 28% | Training loss: 0.6880275561828022
Epoch: 3 | Iteration number: [1300/4518] 28% | Training loss: 0.6880261865028968
Epoch: 3 | Iteration number: [1310/4518] 28% | Training loss: 0.6880258831359048
Epoch: 3 | Iteration number: [1320/4518] 29% | Training loss: 0.6880224835240479
Epoch: 3 | Iteration number: [1330/4518] 29% | Training loss: 0.6880108797012415
Epoch: 3 | Iteration number: [1340/4518] 29% | Training loss: 0.6880113563430843
Epoch: 3 | Iteration number: [1350/4518] 29% | Training loss: 0.6880050551008295
Epoch: 3 | Iteration number: [1360/4518] 30% | Training loss: 0.6880002670866602
Epoch: 3 | Iteration number: [1370/4518] 30% | Training loss: 0.6879942724739548
Epoch: 3 | Iteration number: [1380/4518] 30% | Training loss: 0.6879974620065827
Epoch: 3 | Iteration number: [1390/4518] 30% | Training loss: 0.6879891371555465
Epoch: 3 | Iteration number: [1400/4518] 30% | Training loss: 0.6879946995207241
Epoch: 3 | Iteration number: [1410/4518] 31% | Training loss: 0.6879818814443358
Epoch: 3 | Iteration number: [1420/4518] 31% | Training loss: 0.6879844472861626
Epoch: 3 | Iteration number: [1430/4518] 31% | Training loss: 0.6879805902501086
Epoch: 3 | Iteration number: [1440/4518] 31% | Training loss: 0.6879828789167934
Epoch: 3 | Iteration number: [1450/4518] 32% | Training loss: 0.6879845914758485
Epoch: 3 | Iteration number: [1460/4518] 32% | Training loss: 0.6879819722208258
Epoch: 3 | Iteration number: [1470/4518] 32% | Training loss: 0.6879765319986408
Epoch: 3 | Iteration number: [1480/4518] 32% | Training loss: 0.6879774632486138
Epoch: 3 | Iteration number: [1490/4518] 32% | Training loss: 0.6879703578532942
Epoch: 3 | Iteration number: [1500/4518] 33% | Training loss: 0.6879601611296335
Epoch: 3 | Iteration number: [1510/4518] 33% | Training loss: 0.6879567231563543
Epoch: 3 | Iteration number: [1520/4518] 33% | Training loss: 0.6879479230234498
Epoch: 3 | Iteration number: [1530/4518] 33% | Training loss: 0.6879509522244821
Epoch: 3 | Iteration number: [1540/4518] 34% | Training loss: 0.6879525362284152
Epoch: 3 | Iteration number: [1550/4518] 34% | Training loss: 0.6879583708317049
Epoch: 3 | Iteration number: [1560/4518] 34% | Training loss: 0.6879559444311337
Epoch: 3 | Iteration number: [1570/4518] 34% | Training loss: 0.6879480680462661
Epoch: 3 | Iteration number: [1580/4518] 34% | Training loss: 0.687952955576438
Epoch: 3 | Iteration number: [1590/4518] 35% | Training loss: 0.6879451427444722
Epoch: 3 | Iteration number: [1600/4518] 35% | Training loss: 0.687941194921732
Epoch: 3 | Iteration number: [1610/4518] 35% | Training loss: 0.6879403591896436
Epoch: 3 | Iteration number: [1620/4518] 35% | Training loss: 0.6879360242022409
Epoch: 3 | Iteration number: [1630/4518] 36% | Training loss: 0.6879312214310184
Epoch: 3 | Iteration number: [1640/4518] 36% | Training loss: 0.6879306961850422
Epoch: 3 | Iteration number: [1650/4518] 36% | Training loss: 0.6879226407137784
Epoch: 3 | Iteration number: [1660/4518] 36% | Training loss: 0.6879281418151166
Epoch: 3 | Iteration number: [1670/4518] 36% | Training loss: 0.6879157814437044
Epoch: 3 | Iteration number: [1680/4518] 37% | Training loss: 0.6879160491483552
Epoch: 3 | Iteration number: [1690/4518] 37% | Training loss: 0.6879119603591558
Epoch: 3 | Iteration number: [1700/4518] 37% | Training loss: 0.687913900754031
Epoch: 3 | Iteration number: [1710/4518] 37% | Training loss: 0.6879111618326421
Epoch: 3 | Iteration number: [1720/4518] 38% | Training loss: 0.6879078085685886
Epoch: 3 | Iteration number: [1730/4518] 38% | Training loss: 0.68790742141663
Epoch: 3 | Iteration number: [1740/4518] 38% | Training loss: 0.6879009340343805
Epoch: 3 | Iteration number: [1750/4518] 38% | Training loss: 0.6878954333237239
Epoch: 3 | Iteration number: [1760/4518] 38% | Training loss: 0.6878924962133169
Epoch: 3 | Iteration number: [1770/4518] 39% | Training loss: 0.6878923257191976
Epoch: 3 | Iteration number: [1780/4518] 39% | Training loss: 0.6878866448161307
Epoch: 3 | Iteration number: [1790/4518] 39% | Training loss: 0.687879770927589
Epoch: 3 | Iteration number: [1800/4518] 39% | Training loss: 0.6878733784622616
Epoch: 3 | Iteration number: [1810/4518] 40% | Training loss: 0.6878581116541973
Epoch: 3 | Iteration number: [1820/4518] 40% | Training loss: 0.6878539738091793
Epoch: 3 | Iteration number: [1830/4518] 40% | Training loss: 0.6878503747325126
Epoch: 3 | Iteration number: [1840/4518] 40% | Training loss: 0.6878478422437025
Epoch: 3 | Iteration number: [1850/4518] 40% | Training loss: 0.687838753784025
Epoch: 3 | Iteration number: [1860/4518] 41% | Training loss: 0.6878369380709946
Epoch: 3 | Iteration number: [1870/4518] 41% | Training loss: 0.6878357007860499
Epoch: 3 | Iteration number: [1880/4518] 41% | Training loss: 0.6878301612557249
Epoch: 3 | Iteration number: [1890/4518] 41% | Training loss: 0.6878358933345351
Epoch: 3 | Iteration number: [1900/4518] 42% | Training loss: 0.6878259624305524
Epoch: 3 | Iteration number: [1910/4518] 42% | Training loss: 0.6878242792571402
Epoch: 3 | Iteration number: [1920/4518] 42% | Training loss: 0.6878238018291692
Epoch: 3 | Iteration number: [1930/4518] 42% | Training loss: 0.6878200251512577
Epoch: 3 | Iteration number: [1940/4518] 42% | Training loss: 0.687821952891104
Epoch: 3 | Iteration number: [1950/4518] 43% | Training loss: 0.6878114230510516
Epoch: 3 | Iteration number: [1960/4518] 43% | Training loss: 0.6878107141171182
Epoch: 3 | Iteration number: [1970/4518] 43% | Training loss: 0.6878061010147715
Epoch: 3 | Iteration number: [1980/4518] 43% | Training loss: 0.6877992210063067
Epoch: 3 | Iteration number: [1990/4518] 44% | Training loss: 0.6877986592863073
Epoch: 3 | Iteration number: [2000/4518] 44% | Training loss: 0.6877998314797878
Epoch: 3 | Iteration number: [2010/4518] 44% | Training loss: 0.6877978236224521
Epoch: 3 | Iteration number: [2020/4518] 44% | Training loss: 0.6877932011491001
Epoch: 3 | Iteration number: [2030/4518] 44% | Training loss: 0.687791379948555
Epoch: 3 | Iteration number: [2040/4518] 45% | Training loss: 0.6877926138686199
Epoch: 3 | Iteration number: [2050/4518] 45% | Training loss: 0.6877854457134154
Epoch: 3 | Iteration number: [2060/4518] 45% | Training loss: 0.6877808524856289
Epoch: 3 | Iteration number: [2070/4518] 45% | Training loss: 0.6877812633479851
Epoch: 3 | Iteration number: [2080/4518] 46% | Training loss: 0.6877706244874459
Epoch: 3 | Iteration number: [2090/4518] 46% | Training loss: 0.6877720835676604
Epoch: 3 | Iteration number: [2100/4518] 46% | Training loss: 0.6877714145467395
Epoch: 3 | Iteration number: [2110/4518] 46% | Training loss: 0.6877776985484841
Epoch: 3 | Iteration number: [2120/4518] 46% | Training loss: 0.6877762759069227
Epoch: 3 | Iteration number: [2130/4518] 47% | Training loss: 0.6877745122137204
Epoch: 3 | Iteration number: [2140/4518] 47% | Training loss: 0.6877713362190211
Epoch: 3 | Iteration number: [2150/4518] 47% | Training loss: 0.687767891856127
Epoch: 3 | Iteration number: [2160/4518] 47% | Training loss: 0.6877665412646753
Epoch: 3 | Iteration number: [2170/4518] 48% | Training loss: 0.687761087049537
Epoch: 3 | Iteration number: [2180/4518] 48% | Training loss: 0.6877633025886816
Epoch: 3 | Iteration number: [2190/4518] 48% | Training loss: 0.6877655592955411
Epoch: 3 | Iteration number: [2200/4518] 48% | Training loss: 0.6877610077370296
Epoch: 3 | Iteration number: [2210/4518] 48% | Training loss: 0.6877631572576669
Epoch: 3 | Iteration number: [2220/4518] 49% | Training loss: 0.687758876020844
Epoch: 3 | Iteration number: [2230/4518] 49% | Training loss: 0.6877571579319479
Epoch: 3 | Iteration number: [2240/4518] 49% | Training loss: 0.6877506739326886
Epoch: 3 | Iteration number: [2250/4518] 49% | Training loss: 0.6877448725700378
Epoch: 3 | Iteration number: [2260/4518] 50% | Training loss: 0.6877382651894494
Epoch: 3 | Iteration number: [2270/4518] 50% | Training loss: 0.6877357307772279
Epoch: 3 | Iteration number: [2280/4518] 50% | Training loss: 0.6877357703813335
Epoch: 3 | Iteration number: [2290/4518] 50% | Training loss: 0.6877295948011907
Epoch: 3 | Iteration number: [2300/4518] 50% | Training loss: 0.6877282273769378
Epoch: 3 | Iteration number: [2310/4518] 51% | Training loss: 0.6877221944528225
Epoch: 3 | Iteration number: [2320/4518] 51% | Training loss: 0.6877237973028216
Epoch: 3 | Iteration number: [2330/4518] 51% | Training loss: 0.6877213303879095
Epoch: 3 | Iteration number: [2340/4518] 51% | Training loss: 0.6877183222617859
Epoch: 3 | Iteration number: [2350/4518] 52% | Training loss: 0.6877211422108589
Epoch: 3 | Iteration number: [2360/4518] 52% | Training loss: 0.6877227820582309
Epoch: 3 | Iteration number: [2370/4518] 52% | Training loss: 0.6877250139220354
Epoch: 3 | Iteration number: [2380/4518] 52% | Training loss: 0.687726104209403
Epoch: 3 | Iteration number: [2390/4518] 52% | Training loss: 0.6877242688354588
Epoch: 3 | Iteration number: [2400/4518] 53% | Training loss: 0.6877252449095249
Epoch: 3 | Iteration number: [2410/4518] 53% | Training loss: 0.6877210754081916
Epoch: 3 | Iteration number: [2420/4518] 53% | Training loss: 0.6877180540610937
Epoch: 3 | Iteration number: [2430/4518] 53% | Training loss: 0.6877201361911287
Epoch: 3 | Iteration number: [2440/4518] 54% | Training loss: 0.6877178721740598
Epoch: 3 | Iteration number: [2450/4518] 54% | Training loss: 0.6877217858421559
Epoch: 3 | Iteration number: [2460/4518] 54% | Training loss: 0.6877189851146404
Epoch: 3 | Iteration number: [2470/4518] 54% | Training loss: 0.6877169056701274
Epoch: 3 | Iteration number: [2480/4518] 54% | Training loss: 0.6877201812642236
Epoch: 3 | Iteration number: [2490/4518] 55% | Training loss: 0.6877172022459498
Epoch: 3 | Iteration number: [2500/4518] 55% | Training loss: 0.6877146152973175
Epoch: 3 | Iteration number: [2510/4518] 55% | Training loss: 0.6877158576036354
Epoch: 3 | Iteration number: [2520/4518] 55% | Training loss: 0.6877191133915432
Epoch: 3 | Iteration number: [2530/4518] 55% | Training loss: 0.6877123995025167
Epoch: 3 | Iteration number: [2540/4518] 56% | Training loss: 0.6877096563812316
Epoch: 3 | Iteration number: [2550/4518] 56% | Training loss: 0.6877094911594017
Epoch: 3 | Iteration number: [2560/4518] 56% | Training loss: 0.6877036850200966
Epoch: 3 | Iteration number: [2570/4518] 56% | Training loss: 0.6877065571133728
Epoch: 3 | Iteration number: [2580/4518] 57% | Training loss: 0.6877052824164546
Epoch: 3 | Iteration number: [2590/4518] 57% | Training loss: 0.6877025520709491
Epoch: 3 | Iteration number: [2600/4518] 57% | Training loss: 0.6876995922051943
Epoch: 3 | Iteration number: [2610/4518] 57% | Training loss: 0.6876952708452597
Epoch: 3 | Iteration number: [2620/4518] 57% | Training loss: 0.6876947124950759
Epoch: 3 | Iteration number: [2630/4518] 58% | Training loss: 0.6876903361467355
Epoch: 3 | Iteration number: [2640/4518] 58% | Training loss: 0.6876910649240017
Epoch: 3 | Iteration number: [2650/4518] 58% | Training loss: 0.6876909249458673
Epoch: 3 | Iteration number: [2660/4518] 58% | Training loss: 0.6876905463243785
Epoch: 3 | Iteration number: [2670/4518] 59% | Training loss: 0.687690583552314
Epoch: 3 | Iteration number: [2680/4518] 59% | Training loss: 0.6876899692994445
Epoch: 3 | Iteration number: [2690/4518] 59% | Training loss: 0.6876913151998059
Epoch: 3 | Iteration number: [2700/4518] 59% | Training loss: 0.6876889872109448
Epoch: 3 | Iteration number: [2710/4518] 59% | Training loss: 0.6876846503287664
Epoch: 3 | Iteration number: [2720/4518] 60% | Training loss: 0.6876879650661174
Epoch: 3 | Iteration number: [2730/4518] 60% | Training loss: 0.6876836313214494
Epoch: 3 | Iteration number: [2740/4518] 60% | Training loss: 0.6876791707573146
Epoch: 3 | Iteration number: [2750/4518] 60% | Training loss: 0.6876779169169339
Epoch: 3 | Iteration number: [2760/4518] 61% | Training loss: 0.6876800801011099
Epoch: 3 | Iteration number: [2770/4518] 61% | Training loss: 0.6876750478890828
Epoch: 3 | Iteration number: [2780/4518] 61% | Training loss: 0.6876739688485647
Epoch: 3 | Iteration number: [2790/4518] 61% | Training loss: 0.6876815963389625
Epoch: 3 | Iteration number: [2800/4518] 61% | Training loss: 0.6876827742585114
Epoch: 3 | Iteration number: [2810/4518] 62% | Training loss: 0.687680738018925
Epoch: 3 | Iteration number: [2820/4518] 62% | Training loss: 0.6876730820177295
Epoch: 3 | Iteration number: [2830/4518] 62% | Training loss: 0.6876724163761408
Epoch: 3 | Iteration number: [2840/4518] 62% | Training loss: 0.6876709595322609
Epoch: 3 | Iteration number: [2850/4518] 63% | Training loss: 0.6876722525295458
Epoch: 3 | Iteration number: [2860/4518] 63% | Training loss: 0.6876683873938514
Epoch: 3 | Iteration number: [2870/4518] 63% | Training loss: 0.6876729462827955
Epoch: 3 | Iteration number: [2880/4518] 63% | Training loss: 0.6876777830223243
Epoch: 3 | Iteration number: [2890/4518] 63% | Training loss: 0.6876724063112661
Epoch: 3 | Iteration number: [2900/4518] 64% | Training loss: 0.687672964211168
Epoch: 3 | Iteration number: [2910/4518] 64% | Training loss: 0.6876719735127544
Epoch: 3 | Iteration number: [2920/4518] 64% | Training loss: 0.6876722223138156
Epoch: 3 | Iteration number: [2930/4518] 64% | Training loss: 0.6876683851557787
Epoch: 3 | Iteration number: [2940/4518] 65% | Training loss: 0.6876609898343378
Epoch: 3 | Iteration number: [2950/4518] 65% | Training loss: 0.6876604886984421
Epoch: 3 | Iteration number: [2960/4518] 65% | Training loss: 0.6876570236038517
Epoch: 3 | Iteration number: [2970/4518] 65% | Training loss: 0.6876563620286357
Epoch: 3 | Iteration number: [2980/4518] 65% | Training loss: 0.6876575629783157
Epoch: 3 | Iteration number: [2990/4518] 66% | Training loss: 0.6876583389414592
Epoch: 3 | Iteration number: [3000/4518] 66% | Training loss: 0.6876547106107076
Epoch: 3 | Iteration number: [3010/4518] 66% | Training loss: 0.6876518308522297
Epoch: 3 | Iteration number: [3020/4518] 66% | Training loss: 0.6876470173628915
Epoch: 3 | Iteration number: [3030/4518] 67% | Training loss: 0.6876482124375825
Epoch: 3 | Iteration number: [3040/4518] 67% | Training loss: 0.6876515951007605
Epoch: 3 | Iteration number: [3050/4518] 67% | Training loss: 0.6876500615526419
Epoch: 3 | Iteration number: [3060/4518] 67% | Training loss: 0.6876476463344362
Epoch: 3 | Iteration number: [3070/4518] 67% | Training loss: 0.6876452447925406
Epoch: 3 | Iteration number: [3080/4518] 68% | Training loss: 0.6876431623449574
Epoch: 3 | Iteration number: [3090/4518] 68% | Training loss: 0.6876390105119415
Epoch: 3 | Iteration number: [3100/4518] 68% | Training loss: 0.6876396939062304
Epoch: 3 | Iteration number: [3110/4518] 68% | Training loss: 0.6876334826662609
Epoch: 3 | Iteration number: [3120/4518] 69% | Training loss: 0.6876354348583099
Epoch: 3 | Iteration number: [3130/4518] 69% | Training loss: 0.6876340126458067
Epoch: 3 | Iteration number: [3140/4518] 69% | Training loss: 0.6876331166287136
Epoch: 3 | Iteration number: [3150/4518] 69% | Training loss: 0.6876307085582188
Epoch: 3 | Iteration number: [3160/4518] 69% | Training loss: 0.6876271754126005
Epoch: 3 | Iteration number: [3170/4518] 70% | Training loss: 0.6876288764108243
Epoch: 3 | Iteration number: [3180/4518] 70% | Training loss: 0.6876274044971046
Epoch: 3 | Iteration number: [3190/4518] 70% | Training loss: 0.6876260454751855
Epoch: 3 | Iteration number: [3200/4518] 70% | Training loss: 0.687627588417381
Epoch: 3 | Iteration number: [3210/4518] 71% | Training loss: 0.6876281731782301
Epoch: 3 | Iteration number: [3220/4518] 71% | Training loss: 0.6876299757579839
Epoch: 3 | Iteration number: [3230/4518] 71% | Training loss: 0.6876293784878202
Epoch: 3 | Iteration number: [3240/4518] 71% | Training loss: 0.6876308394067081
Epoch: 3 | Iteration number: [3250/4518] 71% | Training loss: 0.6876319110026726
Epoch: 3 | Iteration number: [3260/4518] 72% | Training loss: 0.6876338889993773
Epoch: 3 | Iteration number: [3270/4518] 72% | Training loss: 0.6876296563615129
Epoch: 3 | Iteration number: [3280/4518] 72% | Training loss: 0.6876289881220679
Epoch: 3 | Iteration number: [3290/4518] 72% | Training loss: 0.6876307193269121
Epoch: 3 | Iteration number: [3300/4518] 73% | Training loss: 0.6876279865250443
Epoch: 3 | Iteration number: [3310/4518] 73% | Training loss: 0.6876264835232334
Epoch: 3 | Iteration number: [3320/4518] 73% | Training loss: 0.6876267018986035
Epoch: 3 | Iteration number: [3330/4518] 73% | Training loss: 0.6876254963445234
Epoch: 3 | Iteration number: [3340/4518] 73% | Training loss: 0.6876240385328224
Epoch: 3 | Iteration number: [3350/4518] 74% | Training loss: 0.6876223922843364
Epoch: 3 | Iteration number: [3360/4518] 74% | Training loss: 0.6876216660652842
Epoch: 3 | Iteration number: [3370/4518] 74% | Training loss: 0.6876205331847647
Epoch: 3 | Iteration number: [3380/4518] 74% | Training loss: 0.6876178180501306
Epoch: 3 | Iteration number: [3390/4518] 75% | Training loss: 0.6876200920360982
Epoch: 3 | Iteration number: [3400/4518] 75% | Training loss: 0.6876162863128326
Epoch: 3 | Iteration number: [3410/4518] 75% | Training loss: 0.6876126931384862
Epoch: 3 | Iteration number: [3420/4518] 75% | Training loss: 0.687612183400762
Epoch: 3 | Iteration number: [3430/4518] 75% | Training loss: 0.6876109306562052
Epoch: 3 | Iteration number: [3440/4518] 76% | Training loss: 0.6876099751439205
Epoch: 3 | Iteration number: [3450/4518] 76% | Training loss: 0.6876091908371966
Epoch: 3 | Iteration number: [3460/4518] 76% | Training loss: 0.6876061168192439
Epoch: 3 | Iteration number: [3470/4518] 76% | Training loss: 0.6876078382864466
Epoch: 3 | Iteration number: [3480/4518] 77% | Training loss: 0.6876078334861788
Epoch: 3 | Iteration number: [3490/4518] 77% | Training loss: 0.6876055257880586
Epoch: 3 | Iteration number: [3500/4518] 77% | Training loss: 0.6876026195117405
Epoch: 3 | Iteration number: [3510/4518] 77% | Training loss: 0.6876006706317945
Epoch: 3 | Iteration number: [3520/4518] 77% | Training loss: 0.6875972159037536
Epoch: 3 | Iteration number: [3530/4518] 78% | Training loss: 0.6875969795599876
Epoch: 3 | Iteration number: [3540/4518] 78% | Training loss: 0.6875942160517482
Epoch: 3 | Iteration number: [3550/4518] 78% | Training loss: 0.6875952175133665
Epoch: 3 | Iteration number: [3560/4518] 78% | Training loss: 0.6875924218236731
Epoch: 3 | Iteration number: [3570/4518] 79% | Training loss: 0.6875893942114352
Epoch: 3 | Iteration number: [3580/4518] 79% | Training loss: 0.6875874316059677
Epoch: 3 | Iteration number: [3590/4518] 79% | Training loss: 0.687584107915007
Epoch: 3 | Iteration number: [3600/4518] 79% | Training loss: 0.6875846150020758
Epoch: 3 | Iteration number: [3610/4518] 79% | Training loss: 0.6875841344162368
Epoch: 3 | Iteration number: [3620/4518] 80% | Training loss: 0.6875816274249092
Epoch: 3 | Iteration number: [3630/4518] 80% | Training loss: 0.6875804861550817
Epoch: 3 | Iteration number: [3640/4518] 80% | Training loss: 0.6875823526919543
Epoch: 3 | Iteration number: [3650/4518] 80% | Training loss: 0.6875797582815771
Epoch: 3 | Iteration number: [3660/4518] 81% | Training loss: 0.68757453458231
Epoch: 3 | Iteration number: [3670/4518] 81% | Training loss: 0.6875749445416297
Epoch: 3 | Iteration number: [3680/4518] 81% | Training loss: 0.6875776858433433
Epoch: 3 | Iteration number: [3690/4518] 81% | Training loss: 0.6875775075055719
Epoch: 3 | Iteration number: [3700/4518] 81% | Training loss: 0.6875762369020565
Epoch: 3 | Iteration number: [3710/4518] 82% | Training loss: 0.6875751230915923
Epoch: 3 | Iteration number: [3720/4518] 82% | Training loss: 0.6875732704195925
Epoch: 3 | Iteration number: [3730/4518] 82% | Training loss: 0.6875740888930517
Epoch: 3 | Iteration number: [3740/4518] 82% | Training loss: 0.6875724469754785
Epoch: 3 | Iteration number: [3750/4518] 83% | Training loss: 0.6875725159962972
Epoch: 3 | Iteration number: [3760/4518] 83% | Training loss: 0.68757364588215
Epoch: 3 | Iteration number: [3770/4518] 83% | Training loss: 0.6875730682905536
Epoch: 3 | Iteration number: [3780/4518] 83% | Training loss: 0.6875709973788136
Epoch: 3 | Iteration number: [3790/4518] 83% | Training loss: 0.6875686480376211
Epoch: 3 | Iteration number: [3800/4518] 84% | Training loss: 0.6875679581573135
Epoch: 3 | Iteration number: [3810/4518] 84% | Training loss: 0.6875656217414876
Epoch: 3 | Iteration number: [3820/4518] 84% | Training loss: 0.6875649415229628
Epoch: 3 | Iteration number: [3830/4518] 84% | Training loss: 0.6875648278324784
Epoch: 3 | Iteration number: [3840/4518] 84% | Training loss: 0.6875598709875097
Epoch: 3 | Iteration number: [3850/4518] 85% | Training loss: 0.6875599178555724
Epoch: 3 | Iteration number: [3860/4518] 85% | Training loss: 0.6875610109746765
Epoch: 3 | Iteration number: [3870/4518] 85% | Training loss: 0.6875605072161948
Epoch: 3 | Iteration number: [3880/4518] 85% | Training loss: 0.6875615831195694
Epoch: 3 | Iteration number: [3890/4518] 86% | Training loss: 0.6875601741985674
Epoch: 3 | Iteration number: [3900/4518] 86% | Training loss: 0.6875659703749877
Epoch: 3 | Iteration number: [3910/4518] 86% | Training loss: 0.6875665574427456
Epoch: 3 | Iteration number: [3920/4518] 86% | Training loss: 0.6875630115367928
Epoch: 3 | Iteration number: [3930/4518] 86% | Training loss: 0.6875622331337771
Epoch: 3 | Iteration number: [3940/4518] 87% | Training loss: 0.6875614242807863
Epoch: 3 | Iteration number: [3950/4518] 87% | Training loss: 0.6875582726544972
Epoch: 3 | Iteration number: [3960/4518] 87% | Training loss: 0.6875583834118313
Epoch: 3 | Iteration number: [3970/4518] 87% | Training loss: 0.6875545352772441
Epoch: 3 | Iteration number: [3980/4518] 88% | Training loss: 0.6875565371920715
Epoch: 3 | Iteration number: [3990/4518] 88% | Training loss: 0.6875537191865438
Epoch: 3 | Iteration number: [4000/4518] 88% | Training loss: 0.6875516085922718
Epoch: 3 | Iteration number: [4010/4518] 88% | Training loss: 0.6875497874030448
Epoch: 3 | Iteration number: [4020/4518] 88% | Training loss: 0.687550601378009
Epoch: 3 | Iteration number: [4030/4518] 89% | Training loss: 0.6875500141686897
Epoch: 3 | Iteration number: [4040/4518] 89% | Training loss: 0.6875482655692808
Epoch: 3 | Iteration number: [4050/4518] 89% | Training loss: 0.687548582215368
Epoch: 3 | Iteration number: [4060/4518] 89% | Training loss: 0.6875463750415247
Epoch: 3 | Iteration number: [4070/4518] 90% | Training loss: 0.6875450830348294
Epoch: 3 | Iteration number: [4080/4518] 90% | Training loss: 0.6875422538787711
Epoch: 3 | Iteration number: [4090/4518] 90% | Training loss: 0.6875431087168621
Epoch: 3 | Iteration number: [4100/4518] 90% | Training loss: 0.6875440871424792
Epoch: 3 | Iteration number: [4110/4518] 90% | Training loss: 0.6875436399394869
Epoch: 3 | Iteration number: [4120/4518] 91% | Training loss: 0.6875447739819879
Epoch: 3 | Iteration number: [4130/4518] 91% | Training loss: 0.6875451896005912
Epoch: 3 | Iteration number: [4140/4518] 91% | Training loss: 0.6875423956752399
Epoch: 3 | Iteration number: [4150/4518] 91% | Training loss: 0.6875380501546056
Epoch: 3 | Iteration number: [4160/4518] 92% | Training loss: 0.6875382299463336
Epoch: 3 | Iteration number: [4170/4518] 92% | Training loss: 0.6875386471799809
Epoch: 3 | Iteration number: [4180/4518] 92% | Training loss: 0.6875363998863686
Epoch: 3 | Iteration number: [4190/4518] 92% | Training loss: 0.6875373049681397
Epoch: 3 | Iteration number: [4200/4518] 92% | Training loss: 0.6875350371996561
Epoch: 3 | Iteration number: [4210/4518] 93% | Training loss: 0.6875334357280912
Epoch: 3 | Iteration number: [4220/4518] 93% | Training loss: 0.6875355215151728
Epoch: 3 | Iteration number: [4230/4518] 93% | Training loss: 0.6875337978345001
Epoch: 3 | Iteration number: [4240/4518] 93% | Training loss: 0.6875331702800291
Epoch: 3 | Iteration number: [4250/4518] 94% | Training loss: 0.6875315369718215
Epoch: 3 | Iteration number: [4260/4518] 94% | Training loss: 0.6875308803129644
Epoch: 3 | Iteration number: [4270/4518] 94% | Training loss: 0.6875341236032981
Epoch: 3 | Iteration number: [4280/4518] 94% | Training loss: 0.6875357916979032
Epoch: 3 | Iteration number: [4290/4518] 94% | Training loss: 0.687535936029363
Epoch: 3 | Iteration number: [4300/4518] 95% | Training loss: 0.687533947880878
Epoch: 3 | Iteration number: [4310/4518] 95% | Training loss: 0.6875325697204077
Epoch: 3 | Iteration number: [4320/4518] 95% | Training loss: 0.6875326907745114
Epoch: 3 | Iteration number: [4330/4518] 95% | Training loss: 0.6875336887241786
Epoch: 3 | Iteration number: [4340/4518] 96% | Training loss: 0.6875323180504109
Epoch: 3 | Iteration number: [4350/4518] 96% | Training loss: 0.6875321258621654
Epoch: 3 | Iteration number: [4360/4518] 96% | Training loss: 0.6875348092765983
Epoch: 3 | Iteration number: [4370/4518] 96% | Training loss: 0.6875350101043213
Epoch: 3 | Iteration number: [4380/4518] 96% | Training loss: 0.687534611301335
Epoch: 3 | Iteration number: [4390/4518] 97% | Training loss: 0.6875304423187751
Epoch: 3 | Iteration number: [4400/4518] 97% | Training loss: 0.6875310194898735
Epoch: 3 | Iteration number: [4410/4518] 97% | Training loss: 0.6875310915667995
Epoch: 3 | Iteration number: [4420/4518] 97% | Training loss: 0.6875311556984397
Epoch: 3 | Iteration number: [4430/4518] 98% | Training loss: 0.6875305139318815
Epoch: 3 | Iteration number: [4440/4518] 98% | Training loss: 0.6875318720399797
Epoch: 3 | Iteration number: [4450/4518] 98% | Training loss: 0.6875281418977158
Epoch: 3 | Iteration number: [4460/4518] 98% | Training loss: 0.6875268832851419
Epoch: 3 | Iteration number: [4470/4518] 98% | Training loss: 0.6875251036762391
Epoch: 3 | Iteration number: [4480/4518] 99% | Training loss: 0.6875255930769656
Epoch: 3 | Iteration number: [4490/4518] 99% | Training loss: 0.6875220949240941
Epoch: 3 | Iteration number: [4500/4518] 99% | Training loss: 0.687521053565873
Epoch: 3 | Iteration number: [4510/4518] 99% | Training loss: 0.6875227990541648

 End of epoch: 3 | Train Loss: 0.6873714776364191 | Training Time: 633 

 End of epoch: 3 | Eval Loss: 0.6903233272688729 | Evaluating Time: 17 
Epoch: 4 | Iteration number: [10/4518] 0% | Training loss: 0.7558600902557373
Epoch: 4 | Iteration number: [20/4518] 0% | Training loss: 0.7222168326377869
Epoch: 4 | Iteration number: [30/4518] 0% | Training loss: 0.7109669963518779
Epoch: 4 | Iteration number: [40/4518] 0% | Training loss: 0.7049532681703568
Epoch: 4 | Iteration number: [50/4518] 1% | Training loss: 0.701252920627594
Epoch: 4 | Iteration number: [60/4518] 1% | Training loss: 0.6988002717494964
Epoch: 4 | Iteration number: [70/4518] 1% | Training loss: 0.6971949509211949
Epoch: 4 | Iteration number: [80/4518] 1% | Training loss: 0.695972652733326
Epoch: 4 | Iteration number: [90/4518] 1% | Training loss: 0.6950317197375827
Epoch: 4 | Iteration number: [100/4518] 2% | Training loss: 0.6941716438531875
Epoch: 4 | Iteration number: [110/4518] 2% | Training loss: 0.6936137584122745
Epoch: 4 | Iteration number: [120/4518] 2% | Training loss: 0.6930775627493858
Epoch: 4 | Iteration number: [130/4518] 2% | Training loss: 0.6925880977740655
Epoch: 4 | Iteration number: [140/4518] 3% | Training loss: 0.6922676473855972
Epoch: 4 | Iteration number: [150/4518] 3% | Training loss: 0.6919488032658895
Epoch: 4 | Iteration number: [160/4518] 3% | Training loss: 0.6916998784989119
Epoch: 4 | Iteration number: [170/4518] 3% | Training loss: 0.6914855739649605
Epoch: 4 | Iteration number: [180/4518] 3% | Training loss: 0.6912422766288121
Epoch: 4 | Iteration number: [190/4518] 4% | Training loss: 0.6910118924944024
Epoch: 4 | Iteration number: [200/4518] 4% | Training loss: 0.6908071291446686
Epoch: 4 | Iteration number: [210/4518] 4% | Training loss: 0.6906642553352175
Epoch: 4 | Iteration number: [220/4518] 4% | Training loss: 0.6905007459900596
Epoch: 4 | Iteration number: [230/4518] 5% | Training loss: 0.6903600552807684
Epoch: 4 | Iteration number: [240/4518] 5% | Training loss: 0.6901928998529911
Epoch: 4 | Iteration number: [250/4518] 5% | Training loss: 0.6900902204513549
Epoch: 4 | Iteration number: [260/4518] 5% | Training loss: 0.6899518159719614
Epoch: 4 | Iteration number: [270/4518] 5% | Training loss: 0.6898573771671013
Epoch: 4 | Iteration number: [280/4518] 6% | Training loss: 0.6897772171667644
Epoch: 4 | Iteration number: [290/4518] 6% | Training loss: 0.6896939842865385
Epoch: 4 | Iteration number: [300/4518] 6% | Training loss: 0.6896078924338023
Epoch: 4 | Iteration number: [310/4518] 6% | Training loss: 0.6895409005303537
Epoch: 4 | Iteration number: [320/4518] 7% | Training loss: 0.6894262671470642
Epoch: 4 | Iteration number: [330/4518] 7% | Training loss: 0.689392272270087
Epoch: 4 | Iteration number: [340/4518] 7% | Training loss: 0.6893577894743751
Epoch: 4 | Iteration number: [350/4518] 7% | Training loss: 0.689341002362115
Epoch: 4 | Iteration number: [360/4518] 7% | Training loss: 0.6892774742510583
Epoch: 4 | Iteration number: [370/4518] 8% | Training loss: 0.6891864649347357
Epoch: 4 | Iteration number: [380/4518] 8% | Training loss: 0.6891291643443861
Epoch: 4 | Iteration number: [390/4518] 8% | Training loss: 0.6890848447114993
Epoch: 4 | Iteration number: [400/4518] 8% | Training loss: 0.689030097424984
Epoch: 4 | Iteration number: [410/4518] 9% | Training loss: 0.6889930758534408
Epoch: 4 | Iteration number: [420/4518] 9% | Training loss: 0.6889717869815373
Epoch: 4 | Iteration number: [430/4518] 9% | Training loss: 0.6889463172402492
Epoch: 4 | Iteration number: [440/4518] 9% | Training loss: 0.6888819766315547
Epoch: 4 | Iteration number: [450/4518] 9% | Training loss: 0.6888552269670698
Epoch: 4 | Iteration number: [460/4518] 10% | Training loss: 0.6888233210729516
Epoch: 4 | Iteration number: [470/4518] 10% | Training loss: 0.6887967233962201
Epoch: 4 | Iteration number: [480/4518] 10% | Training loss: 0.6887811639656624
Epoch: 4 | Iteration number: [490/4518] 10% | Training loss: 0.6887342534503158
Epoch: 4 | Iteration number: [500/4518] 11% | Training loss: 0.6886881946325302
Epoch: 4 | Iteration number: [510/4518] 11% | Training loss: 0.6886686671013925
Epoch: 4 | Iteration number: [520/4518] 11% | Training loss: 0.6886324924918321
Epoch: 4 | Iteration number: [530/4518] 11% | Training loss: 0.6886000496036602
Epoch: 4 | Iteration number: [540/4518] 11% | Training loss: 0.6885819410836255
Epoch: 4 | Iteration number: [550/4518] 12% | Training loss: 0.6885245563767173
Epoch: 4 | Iteration number: [560/4518] 12% | Training loss: 0.6884877831808158
Epoch: 4 | Iteration number: [570/4518] 12% | Training loss: 0.6884476662727824
Epoch: 4 | Iteration number: [580/4518] 12% | Training loss: 0.6884195730603975
Epoch: 4 | Iteration number: [590/4518] 13% | Training loss: 0.6884080334235045
Epoch: 4 | Iteration number: [600/4518] 13% | Training loss: 0.6883792117238045
Epoch: 4 | Iteration number: [610/4518] 13% | Training loss: 0.6883539871114199
Epoch: 4 | Iteration number: [620/4518] 13% | Training loss: 0.688322302506816
Epoch: 4 | Iteration number: [630/4518] 13% | Training loss: 0.6882759547422803
Epoch: 4 | Iteration number: [640/4518] 14% | Training loss: 0.6882468181662261
Epoch: 4 | Iteration number: [650/4518] 14% | Training loss: 0.6882431309039776
Epoch: 4 | Iteration number: [660/4518] 14% | Training loss: 0.6882234191352671
Epoch: 4 | Iteration number: [670/4518] 14% | Training loss: 0.6882222688909787
Epoch: 4 | Iteration number: [680/4518] 15% | Training loss: 0.688208888120511
Epoch: 4 | Iteration number: [690/4518] 15% | Training loss: 0.6881995409295179
Epoch: 4 | Iteration number: [700/4518] 15% | Training loss: 0.6881799393892288
Epoch: 4 | Iteration number: [710/4518] 15% | Training loss: 0.688156529967214
Epoch: 4 | Iteration number: [720/4518] 15% | Training loss: 0.6881254591047764
Epoch: 4 | Iteration number: [730/4518] 16% | Training loss: 0.6881305091185113
Epoch: 4 | Iteration number: [740/4518] 16% | Training loss: 0.6881148913422146
Epoch: 4 | Iteration number: [750/4518] 16% | Training loss: 0.6881112927595774
Epoch: 4 | Iteration number: [760/4518] 16% | Training loss: 0.6880972724211843
Epoch: 4 | Iteration number: [770/4518] 17% | Training loss: 0.6880774423673556
Epoch: 4 | Iteration number: [780/4518] 17% | Training loss: 0.6880463620791069
Epoch: 4 | Iteration number: [790/4518] 17% | Training loss: 0.6880486672437643
Epoch: 4 | Iteration number: [800/4518] 17% | Training loss: 0.6880448071658611
Epoch: 4 | Iteration number: [810/4518] 17% | Training loss: 0.6880293953565904
Epoch: 4 | Iteration number: [820/4518] 18% | Training loss: 0.6880325273042772
Epoch: 4 | Iteration number: [830/4518] 18% | Training loss: 0.6880178954227861
Epoch: 4 | Iteration number: [840/4518] 18% | Training loss: 0.6879933836204665
Epoch: 4 | Iteration number: [850/4518] 18% | Training loss: 0.6879855056370006
Epoch: 4 | Iteration number: [860/4518] 19% | Training loss: 0.6879716713761175
Epoch: 4 | Iteration number: [870/4518] 19% | Training loss: 0.6879697146771968
Epoch: 4 | Iteration number: [880/4518] 19% | Training loss: 0.6879565457051451
Epoch: 4 | Iteration number: [890/4518] 19% | Training loss: 0.6879516680588883
Epoch: 4 | Iteration number: [900/4518] 19% | Training loss: 0.6879371682802836
Epoch: 4 | Iteration number: [910/4518] 20% | Training loss: 0.6879341394691677
Epoch: 4 | Iteration number: [920/4518] 20% | Training loss: 0.6879189408991648
Epoch: 4 | Iteration number: [930/4518] 20% | Training loss: 0.6879104507866726
Epoch: 4 | Iteration number: [940/4518] 20% | Training loss: 0.6879091551963319
Epoch: 4 | Iteration number: [950/4518] 21% | Training loss: 0.687892366710462
Epoch: 4 | Iteration number: [960/4518] 21% | Training loss: 0.6878856095174949
Epoch: 4 | Iteration number: [970/4518] 21% | Training loss: 0.6878630780682121
Epoch: 4 | Iteration number: [980/4518] 21% | Training loss: 0.6878551221015502
Epoch: 4 | Iteration number: [990/4518] 21% | Training loss: 0.6878387869608523
Epoch: 4 | Iteration number: [1000/4518] 22% | Training loss: 0.6878350024819374
Epoch: 4 | Iteration number: [1010/4518] 22% | Training loss: 0.6878278089631902
Epoch: 4 | Iteration number: [1020/4518] 22% | Training loss: 0.6878110941134247
Epoch: 4 | Iteration number: [1030/4518] 22% | Training loss: 0.6878044135362199
Epoch: 4 | Iteration number: [1040/4518] 23% | Training loss: 0.6878095998213841
Epoch: 4 | Iteration number: [1050/4518] 23% | Training loss: 0.6878019223326729
Epoch: 4 | Iteration number: [1060/4518] 23% | Training loss: 0.6877951765960117
Epoch: 4 | Iteration number: [1070/4518] 23% | Training loss: 0.6877898427927606
Epoch: 4 | Iteration number: [1080/4518] 23% | Training loss: 0.6877835207515293
Epoch: 4 | Iteration number: [1090/4518] 24% | Training loss: 0.6877841574336411
Epoch: 4 | Iteration number: [1100/4518] 24% | Training loss: 0.6877635775912891
Epoch: 4 | Iteration number: [1110/4518] 24% | Training loss: 0.6877625800467826
Epoch: 4 | Iteration number: [1120/4518] 24% | Training loss: 0.6877603048192603
Epoch: 4 | Iteration number: [1130/4518] 25% | Training loss: 0.6877449771999258
Epoch: 4 | Iteration number: [1140/4518] 25% | Training loss: 0.6877448116478168
Epoch: 4 | Iteration number: [1150/4518] 25% | Training loss: 0.6877483802774678
Epoch: 4 | Iteration number: [1160/4518] 25% | Training loss: 0.6877499924137674
Epoch: 4 | Iteration number: [1170/4518] 25% | Training loss: 0.6877323141974262
Epoch: 4 | Iteration number: [1180/4518] 26% | Training loss: 0.6877240046101102
Epoch: 4 | Iteration number: [1190/4518] 26% | Training loss: 0.6877230681792027
Epoch: 4 | Iteration number: [1200/4518] 26% | Training loss: 0.6877249174813429
Epoch: 4 | Iteration number: [1210/4518] 26% | Training loss: 0.6877196225253018
Epoch: 4 | Iteration number: [1220/4518] 27% | Training loss: 0.6877162759909864
Epoch: 4 | Iteration number: [1230/4518] 27% | Training loss: 0.6877151544501142
Epoch: 4 | Iteration number: [1240/4518] 27% | Training loss: 0.6877113090407464
Epoch: 4 | Iteration number: [1250/4518] 27% | Training loss: 0.6877011812686921
Epoch: 4 | Iteration number: [1260/4518] 27% | Training loss: 0.687689643436008
Epoch: 4 | Iteration number: [1270/4518] 28% | Training loss: 0.6876784008318984
Epoch: 4 | Iteration number: [1280/4518] 28% | Training loss: 0.6876742057967931
Epoch: 4 | Iteration number: [1290/4518] 28% | Training loss: 0.6876709432564965
Epoch: 4 | Iteration number: [1300/4518] 28% | Training loss: 0.687678348834698
Epoch: 4 | Iteration number: [1310/4518] 28% | Training loss: 0.6876672782515751
Epoch: 4 | Iteration number: [1320/4518] 29% | Training loss: 0.6876772253350778
Epoch: 4 | Iteration number: [1330/4518] 29% | Training loss: 0.6876750034049042
Epoch: 4 | Iteration number: [1340/4518] 29% | Training loss: 0.6876797654290697
Epoch: 4 | Iteration number: [1350/4518] 29% | Training loss: 0.6876688530710009
Epoch: 4 | Iteration number: [1360/4518] 30% | Training loss: 0.6876657627961215
Epoch: 4 | Iteration number: [1370/4518] 30% | Training loss: 0.6876611948013306
Epoch: 4 | Iteration number: [1380/4518] 30% | Training loss: 0.687667563341666
Epoch: 4 | Iteration number: [1390/4518] 30% | Training loss: 0.6876655464120907
Epoch: 4 | Iteration number: [1400/4518] 30% | Training loss: 0.687669211753777
Epoch: 4 | Iteration number: [1410/4518] 31% | Training loss: 0.6876771418760854
Epoch: 4 | Iteration number: [1420/4518] 31% | Training loss: 0.6876724790519392
Epoch: 4 | Iteration number: [1430/4518] 31% | Training loss: 0.6876674873428745
Epoch: 4 | Iteration number: [1440/4518] 31% | Training loss: 0.6876622103982502
Epoch: 4 | Iteration number: [1450/4518] 32% | Training loss: 0.6876643487502788
Epoch: 4 | Iteration number: [1460/4518] 32% | Training loss: 0.6876658520469927
Epoch: 4 | Iteration number: [1470/4518] 32% | Training loss: 0.6876645993618739
Epoch: 4 | Iteration number: [1480/4518] 32% | Training loss: 0.6876588880210309
Epoch: 4 | Iteration number: [1490/4518] 32% | Training loss: 0.6876557162544071
Epoch: 4 | Iteration number: [1500/4518] 33% | Training loss: 0.6876525193452835
Epoch: 4 | Iteration number: [1510/4518] 33% | Training loss: 0.6876479550702682
Epoch: 4 | Iteration number: [1520/4518] 33% | Training loss: 0.6876512481585929
Epoch: 4 | Iteration number: [1530/4518] 33% | Training loss: 0.6876445482758915
Epoch: 4 | Iteration number: [1540/4518] 34% | Training loss: 0.6876458935536347
Epoch: 4 | Iteration number: [1550/4518] 34% | Training loss: 0.6876454163366749
Epoch: 4 | Iteration number: [1560/4518] 34% | Training loss: 0.6876370599254583
Epoch: 4 | Iteration number: [1570/4518] 34% | Training loss: 0.687635722509615
Epoch: 4 | Iteration number: [1580/4518] 34% | Training loss: 0.6876288083535207
Epoch: 4 | Iteration number: [1590/4518] 35% | Training loss: 0.6876252427041156
Epoch: 4 | Iteration number: [1600/4518] 35% | Training loss: 0.6876209440082311
Epoch: 4 | Iteration number: [1610/4518] 35% | Training loss: 0.6876104089043895
Epoch: 4 | Iteration number: [1620/4518] 35% | Training loss: 0.6876142822665933
Epoch: 4 | Iteration number: [1630/4518] 36% | Training loss: 0.6876129608212804
Epoch: 4 | Iteration number: [1640/4518] 36% | Training loss: 0.6876035745187503
Epoch: 4 | Iteration number: [1650/4518] 36% | Training loss: 0.6875984131206165
Epoch: 4 | Iteration number: [1660/4518] 36% | Training loss: 0.6875972669167691
Epoch: 4 | Iteration number: [1670/4518] 36% | Training loss: 0.6876001437624057
Epoch: 4 | Iteration number: [1680/4518] 37% | Training loss: 0.6876001787327585
Epoch: 4 | Iteration number: [1690/4518] 37% | Training loss: 0.68759604336242
Epoch: 4 | Iteration number: [1700/4518] 37% | Training loss: 0.6875966925130171
Epoch: 4 | Iteration number: [1710/4518] 37% | Training loss: 0.6875951875720108
Epoch: 4 | Iteration number: [1720/4518] 38% | Training loss: 0.6875934810139412
Epoch: 4 | Iteration number: [1730/4518] 38% | Training loss: 0.6875948484577885
Epoch: 4 | Iteration number: [1740/4518] 38% | Training loss: 0.6875878227510671
Epoch: 4 | Iteration number: [1750/4518] 38% | Training loss: 0.6875912804262979
Epoch: 4 | Iteration number: [1760/4518] 38% | Training loss: 0.6875897213139317
Epoch: 4 | Iteration number: [1770/4518] 39% | Training loss: 0.6875864252869018
Epoch: 4 | Iteration number: [1780/4518] 39% | Training loss: 0.6875816797272543
Epoch: 4 | Iteration number: [1790/4518] 39% | Training loss: 0.687585841610445
Epoch: 4 | Iteration number: [1800/4518] 39% | Training loss: 0.6875842942463027
Epoch: 4 | Iteration number: [1810/4518] 40% | Training loss: 0.6875879871911107
Epoch: 4 | Iteration number: [1820/4518] 40% | Training loss: 0.687590408030447
Epoch: 4 | Iteration number: [1830/4518] 40% | Training loss: 0.6875888395179165
Epoch: 4 | Iteration number: [1840/4518] 40% | Training loss: 0.6875822161202846
Epoch: 4 | Iteration number: [1850/4518] 40% | Training loss: 0.6875750110278258
Epoch: 4 | Iteration number: [1860/4518] 41% | Training loss: 0.6875697942510728
Epoch: 4 | Iteration number: [1870/4518] 41% | Training loss: 0.6875741313166797
Epoch: 4 | Iteration number: [1880/4518] 41% | Training loss: 0.6875703887419498
Epoch: 4 | Iteration number: [1890/4518] 41% | Training loss: 0.6875639539231699
Epoch: 4 | Iteration number: [1900/4518] 42% | Training loss: 0.6875620341614673
Epoch: 4 | Iteration number: [1910/4518] 42% | Training loss: 0.6875633799592862
Epoch: 4 | Iteration number: [1920/4518] 42% | Training loss: 0.6875584976747632
Epoch: 4 | Iteration number: [1930/4518] 42% | Training loss: 0.6875583300318743
Epoch: 4 | Iteration number: [1940/4518] 42% | Training loss: 0.6875590182764014
Epoch: 4 | Iteration number: [1950/4518] 43% | Training loss: 0.6875537642148825
Epoch: 4 | Iteration number: [1960/4518] 43% | Training loss: 0.6875514930000111
Epoch: 4 | Iteration number: [1970/4518] 43% | Training loss: 0.6875522284035755
Epoch: 4 | Iteration number: [1980/4518] 43% | Training loss: 0.6875513261616832
Epoch: 4 | Iteration number: [1990/4518] 44% | Training loss: 0.6875561490130784
Epoch: 4 | Iteration number: [2000/4518] 44% | Training loss: 0.6875479918718338
Epoch: 4 | Iteration number: [2010/4518] 44% | Training loss: 0.6875419402596963
Epoch: 4 | Iteration number: [2020/4518] 44% | Training loss: 0.6875418810856224
Epoch: 4 | Iteration number: [2030/4518] 44% | Training loss: 0.6875443458557129
Epoch: 4 | Iteration number: [2040/4518] 45% | Training loss: 0.6875462668199165
Epoch: 4 | Iteration number: [2050/4518] 45% | Training loss: 0.6875446340805147
Epoch: 4 | Iteration number: [2060/4518] 45% | Training loss: 0.6875474557714555
Epoch: 4 | Iteration number: [2070/4518] 45% | Training loss: 0.6875498351555516
Epoch: 4 | Iteration number: [2080/4518] 46% | Training loss: 0.6875476352297343
Epoch: 4 | Iteration number: [2090/4518] 46% | Training loss: 0.6875452198480305
Epoch: 4 | Iteration number: [2100/4518] 46% | Training loss: 0.6875468660820098
Epoch: 4 | Iteration number: [2110/4518] 46% | Training loss: 0.6875444795000609
Epoch: 4 | Iteration number: [2120/4518] 46% | Training loss: 0.6875394296252503
Epoch: 4 | Iteration number: [2130/4518] 47% | Training loss: 0.6875345180292085
Epoch: 4 | Iteration number: [2140/4518] 47% | Training loss: 0.6875348827270704
Epoch: 4 | Iteration number: [2150/4518] 47% | Training loss: 0.6875345744088639
Epoch: 4 | Iteration number: [2160/4518] 47% | Training loss: 0.6875337618092696
Epoch: 4 | Iteration number: [2170/4518] 48% | Training loss: 0.6875347459096514
Epoch: 4 | Iteration number: [2180/4518] 48% | Training loss: 0.6875313470123011
Epoch: 4 | Iteration number: [2190/4518] 48% | Training loss: 0.6875325766872598
Epoch: 4 | Iteration number: [2200/4518] 48% | Training loss: 0.6875373735482042
Epoch: 4 | Iteration number: [2210/4518] 48% | Training loss: 0.6875396627646226
Epoch: 4 | Iteration number: [2220/4518] 49% | Training loss: 0.6875383982518771
Epoch: 4 | Iteration number: [2230/4518] 49% | Training loss: 0.6875384228646488
Epoch: 4 | Iteration number: [2240/4518] 49% | Training loss: 0.6875438387904849
Epoch: 4 | Iteration number: [2250/4518] 49% | Training loss: 0.6875434905158149
Epoch: 4 | Iteration number: [2260/4518] 50% | Training loss: 0.6875377060565273
Epoch: 4 | Iteration number: [2270/4518] 50% | Training loss: 0.6875372893484678
Epoch: 4 | Iteration number: [2280/4518] 50% | Training loss: 0.6875349547517927
Epoch: 4 | Iteration number: [2290/4518] 50% | Training loss: 0.6875317476722351
Epoch: 4 | Iteration number: [2300/4518] 50% | Training loss: 0.6875328797101975
Epoch: 4 | Iteration number: [2310/4518] 51% | Training loss: 0.6875282544336278
Epoch: 4 | Iteration number: [2320/4518] 51% | Training loss: 0.6875320945834291
Epoch: 4 | Iteration number: [2330/4518] 51% | Training loss: 0.6875334945871083
Epoch: 4 | Iteration number: [2340/4518] 51% | Training loss: 0.687533621961235
Epoch: 4 | Iteration number: [2350/4518] 52% | Training loss: 0.6875340184759586
Epoch: 4 | Iteration number: [2360/4518] 52% | Training loss: 0.6875311250403776
Epoch: 4 | Iteration number: [2370/4518] 52% | Training loss: 0.6875293407259108
Epoch: 4 | Iteration number: [2380/4518] 52% | Training loss: 0.68752515098127
Epoch: 4 | Iteration number: [2390/4518] 52% | Training loss: 0.6875197409585929
Epoch: 4 | Iteration number: [2400/4518] 53% | Training loss: 0.687515333245198
Epoch: 4 | Iteration number: [2410/4518] 53% | Training loss: 0.6875184096241393
Epoch: 4 | Iteration number: [2420/4518] 53% | Training loss: 0.687515497823392
Epoch: 4 | Iteration number: [2430/4518] 53% | Training loss: 0.6875159192968298
Epoch: 4 | Iteration number: [2440/4518] 54% | Training loss: 0.6875179170829351
Epoch: 4 | Iteration number: [2450/4518] 54% | Training loss: 0.6875214397177404
Epoch: 4 | Iteration number: [2460/4518] 54% | Training loss: 0.6875203796760823
Epoch: 4 | Iteration number: [2470/4518] 54% | Training loss: 0.6875157056791097
Epoch: 4 | Iteration number: [2480/4518] 54% | Training loss: 0.6875130043635446
Epoch: 4 | Iteration number: [2490/4518] 55% | Training loss: 0.6875081760816306
Epoch: 4 | Iteration number: [2500/4518] 55% | Training loss: 0.6875046972990037
Epoch: 4 | Iteration number: [2510/4518] 55% | Training loss: 0.6874998363128222
Epoch: 4 | Iteration number: [2520/4518] 55% | Training loss: 0.6874972230148694
Epoch: 4 | Iteration number: [2530/4518] 55% | Training loss: 0.6874991984706622
Epoch: 4 | Iteration number: [2540/4518] 56% | Training loss: 0.6875001433562106
Epoch: 4 | Iteration number: [2550/4518] 56% | Training loss: 0.6875022810113196
Epoch: 4 | Iteration number: [2560/4518] 56% | Training loss: 0.6874965248862281
Epoch: 4 | Iteration number: [2570/4518] 56% | Training loss: 0.6874945825176016
Epoch: 4 | Iteration number: [2580/4518] 57% | Training loss: 0.6874962777130363
Epoch: 4 | Iteration number: [2590/4518] 57% | Training loss: 0.6874968676953702
Epoch: 4 | Iteration number: [2600/4518] 57% | Training loss: 0.687496612576338
Epoch: 4 | Iteration number: [2610/4518] 57% | Training loss: 0.6874922848524262
Epoch: 4 | Iteration number: [2620/4518] 57% | Training loss: 0.687488285435065
Epoch: 4 | Iteration number: [2630/4518] 58% | Training loss: 0.6874907927141444
Epoch: 4 | Iteration number: [2640/4518] 58% | Training loss: 0.6874892042667576
Epoch: 4 | Iteration number: [2650/4518] 58% | Training loss: 0.687486762348211
Epoch: 4 | Iteration number: [2660/4518] 58% | Training loss: 0.6874859753632008
Epoch: 4 | Iteration number: [2670/4518] 59% | Training loss: 0.6874882723061779
Epoch: 4 | Iteration number: [2680/4518] 59% | Training loss: 0.6874825299230974
Epoch: 4 | Iteration number: [2690/4518] 59% | Training loss: 0.6874842575270004
Epoch: 4 | Iteration number: [2700/4518] 59% | Training loss: 0.6874813720252779
Epoch: 4 | Iteration number: [2710/4518] 59% | Training loss: 0.687478077895527
Epoch: 4 | Iteration number: [2720/4518] 60% | Training loss: 0.6874788698904655
Epoch: 4 | Iteration number: [2730/4518] 60% | Training loss: 0.6874797805543348
Epoch: 4 | Iteration number: [2740/4518] 60% | Training loss: 0.6874774906539569
Epoch: 4 | Iteration number: [2750/4518] 60% | Training loss: 0.6874761686325074
Epoch: 4 | Iteration number: [2760/4518] 61% | Training loss: 0.6874747788992481
Epoch: 4 | Iteration number: [2770/4518] 61% | Training loss: 0.6874740306005581
Epoch: 4 | Iteration number: [2780/4518] 61% | Training loss: 0.687471139238035
Epoch: 4 | Iteration number: [2790/4518] 61% | Training loss: 0.6874680324053679
Epoch: 4 | Iteration number: [2800/4518] 61% | Training loss: 0.6874643014584269
Epoch: 4 | Iteration number: [2810/4518] 62% | Training loss: 0.6874644854102695
Epoch: 4 | Iteration number: [2820/4518] 62% | Training loss: 0.6874635490753972
Epoch: 4 | Iteration number: [2830/4518] 62% | Training loss: 0.6874629478151301
Epoch: 4 | Iteration number: [2840/4518] 62% | Training loss: 0.6874602814795265
Epoch: 4 | Iteration number: [2850/4518] 63% | Training loss: 0.6874619920630204
Epoch: 4 | Iteration number: [2860/4518] 63% | Training loss: 0.6874601563998869
Epoch: 4 | Iteration number: [2870/4518] 63% | Training loss: 0.6874563680500935
Epoch: 4 | Iteration number: [2880/4518] 63% | Training loss: 0.6874515549797151
Epoch: 4 | Iteration number: [2890/4518] 63% | Training loss: 0.6874500269295848
Epoch: 4 | Iteration number: [2900/4518] 64% | Training loss: 0.6874477782948264
Epoch: 4 | Iteration number: [2910/4518] 64% | Training loss: 0.6874478620966685
Epoch: 4 | Iteration number: [2920/4518] 64% | Training loss: 0.6874501418169231
Epoch: 4 | Iteration number: [2930/4518] 64% | Training loss: 0.6874449376970427
Epoch: 4 | Iteration number: [2940/4518] 65% | Training loss: 0.687444892586494
Epoch: 4 | Iteration number: [2950/4518] 65% | Training loss: 0.6874434864521026
Epoch: 4 | Iteration number: [2960/4518] 65% | Training loss: 0.6874412907539187
Epoch: 4 | Iteration number: [2970/4518] 65% | Training loss: 0.6874401714866009
Epoch: 4 | Iteration number: [2980/4518] 65% | Training loss: 0.6874379213824369
Epoch: 4 | Iteration number: [2990/4518] 66% | Training loss: 0.6874383090929842
Epoch: 4 | Iteration number: [3000/4518] 66% | Training loss: 0.6874352672894796
Epoch: 4 | Iteration number: [3010/4518] 66% | Training loss: 0.6874335707818154
Epoch: 4 | Iteration number: [3020/4518] 66% | Training loss: 0.6874297215054367
Epoch: 4 | Iteration number: [3030/4518] 67% | Training loss: 0.68742993373682
Epoch: 4 | Iteration number: [3040/4518] 67% | Training loss: 0.6874283574325474
Epoch: 4 | Iteration number: [3050/4518] 67% | Training loss: 0.6874288147785624
Epoch: 4 | Iteration number: [3060/4518] 67% | Training loss: 0.6874265235428717
Epoch: 4 | Iteration number: [3070/4518] 67% | Training loss: 0.6874299068016028
Epoch: 4 | Iteration number: [3080/4518] 68% | Training loss: 0.687431411716071
Epoch: 4 | Iteration number: [3090/4518] 68% | Training loss: 0.6874364346555136
Epoch: 4 | Iteration number: [3100/4518] 68% | Training loss: 0.6874402113114634
Epoch: 4 | Iteration number: [3110/4518] 68% | Training loss: 0.6874425706181112
Epoch: 4 | Iteration number: [3120/4518] 69% | Training loss: 0.687443149338166
Epoch: 4 | Iteration number: [3130/4518] 69% | Training loss: 0.6874437882306096
Epoch: 4 | Iteration number: [3140/4518] 69% | Training loss: 0.6874405578443199
Epoch: 4 | Iteration number: [3150/4518] 69% | Training loss: 0.6874397889394609
Epoch: 4 | Iteration number: [3160/4518] 69% | Training loss: 0.6874394073893753
Epoch: 4 | Iteration number: [3170/4518] 70% | Training loss: 0.6874408994751398
Epoch: 4 | Iteration number: [3180/4518] 70% | Training loss: 0.6874408043405544
Epoch: 4 | Iteration number: [3190/4518] 70% | Training loss: 0.6874391740952913
Epoch: 4 | Iteration number: [3200/4518] 70% | Training loss: 0.6874375165067613
Epoch: 4 | Iteration number: [3210/4518] 71% | Training loss: 0.6874387796794142
Epoch: 4 | Iteration number: [3220/4518] 71% | Training loss: 0.6874375503440822
Epoch: 4 | Iteration number: [3230/4518] 71% | Training loss: 0.6874352230929738
Epoch: 4 | Iteration number: [3240/4518] 71% | Training loss: 0.6874342896504166
Epoch: 4 | Iteration number: [3250/4518] 71% | Training loss: 0.6874287683413579
Epoch: 4 | Iteration number: [3260/4518] 72% | Training loss: 0.6874312968159014
Epoch: 4 | Iteration number: [3270/4518] 72% | Training loss: 0.6874322865898821
Epoch: 4 | Iteration number: [3280/4518] 72% | Training loss: 0.6874326927996264
Epoch: 4 | Iteration number: [3290/4518] 72% | Training loss: 0.6874330654876211
Epoch: 4 | Iteration number: [3300/4518] 73% | Training loss: 0.6874316504146114
Epoch: 4 | Iteration number: [3310/4518] 73% | Training loss: 0.6874275907288865
Epoch: 4 | Iteration number: [3320/4518] 73% | Training loss: 0.6874292122491871
Epoch: 4 | Iteration number: [3330/4518] 73% | Training loss: 0.6874291353039556
Epoch: 4 | Iteration number: [3340/4518] 73% | Training loss: 0.6874313865771551
Epoch: 4 | Iteration number: [3350/4518] 74% | Training loss: 0.6874290469333307
Epoch: 4 | Iteration number: [3360/4518] 74% | Training loss: 0.687428830191493
Epoch: 4 | Iteration number: [3370/4518] 74% | Training loss: 0.6874277248403793
Epoch: 4 | Iteration number: [3380/4518] 74% | Training loss: 0.6874259857560051
Epoch: 4 | Iteration number: [3390/4518] 75% | Training loss: 0.687424983967722
Epoch: 4 | Iteration number: [3400/4518] 75% | Training loss: 0.6874270365869297
Epoch: 4 | Iteration number: [3410/4518] 75% | Training loss: 0.6874221874996365
Epoch: 4 | Iteration number: [3420/4518] 75% | Training loss: 0.687421310784524
Epoch: 4 | Iteration number: [3430/4518] 75% | Training loss: 0.6874202477862467
Epoch: 4 | Iteration number: [3440/4518] 76% | Training loss: 0.687414965328089
Epoch: 4 | Iteration number: [3450/4518] 76% | Training loss: 0.6874120816804361
Epoch: 4 | Iteration number: [3460/4518] 76% | Training loss: 0.6874076328697921
Epoch: 4 | Iteration number: [3470/4518] 76% | Training loss: 0.6874039418243881
Epoch: 4 | Iteration number: [3480/4518] 77% | Training loss: 0.6874022680795056
Epoch: 4 | Iteration number: [3490/4518] 77% | Training loss: 0.687404174654395
Epoch: 4 | Iteration number: [3500/4518] 77% | Training loss: 0.6874035630737032
Epoch: 4 | Iteration number: [3510/4518] 77% | Training loss: 0.6874043494038432
Epoch: 4 | Iteration number: [3520/4518] 77% | Training loss: 0.6874001730402762
Epoch: 4 | Iteration number: [3530/4518] 78% | Training loss: 0.6874052588223736
Epoch: 4 | Iteration number: [3540/4518] 78% | Training loss: 0.6874041734105449
Epoch: 4 | Iteration number: [3550/4518] 78% | Training loss: 0.6874046277496176
Epoch: 4 | Iteration number: [3560/4518] 78% | Training loss: 0.687404010721137
Epoch: 4 | Iteration number: [3570/4518] 79% | Training loss: 0.6874033114823307
Epoch: 4 | Iteration number: [3580/4518] 79% | Training loss: 0.6874033126251657
Epoch: 4 | Iteration number: [3590/4518] 79% | Training loss: 0.6874080711586562
Epoch: 4 | Iteration number: [3600/4518] 79% | Training loss: 0.6874052100049125
Epoch: 4 | Iteration number: [3610/4518] 79% | Training loss: 0.687403698096315
Epoch: 4 | Iteration number: [3620/4518] 80% | Training loss: 0.6874039074333992
Epoch: 4 | Iteration number: [3630/4518] 80% | Training loss: 0.6874036611604296
Epoch: 4 | Iteration number: [3640/4518] 80% | Training loss: 0.6874022726992984
Epoch: 4 | Iteration number: [3650/4518] 80% | Training loss: 0.6874016032806815
Epoch: 4 | Iteration number: [3660/4518] 81% | Training loss: 0.6874000812814536
Epoch: 4 | Iteration number: [3670/4518] 81% | Training loss: 0.6873942637800845
Epoch: 4 | Iteration number: [3680/4518] 81% | Training loss: 0.6873930769608073
Epoch: 4 | Iteration number: [3690/4518] 81% | Training loss: 0.6873915167358833
Epoch: 4 | Iteration number: [3700/4518] 81% | Training loss: 0.6873925039091626
Epoch: 4 | Iteration number: [3710/4518] 82% | Training loss: 0.6873920822882588
Epoch: 4 | Iteration number: [3720/4518] 82% | Training loss: 0.6873928836917365
Epoch: 4 | Iteration number: [3730/4518] 82% | Training loss: 0.6873923334135766
Epoch: 4 | Iteration number: [3740/4518] 82% | Training loss: 0.687392905386374
Epoch: 4 | Iteration number: [3750/4518] 83% | Training loss: 0.6873878263791402
Epoch: 4 | Iteration number: [3760/4518] 83% | Training loss: 0.6873900595339055
Epoch: 4 | Iteration number: [3770/4518] 83% | Training loss: 0.687387361513841
Epoch: 4 | Iteration number: [3780/4518] 83% | Training loss: 0.6873821229688705
Epoch: 4 | Iteration number: [3790/4518] 83% | Training loss: 0.6873836816143549
Epoch: 4 | Iteration number: [3800/4518] 84% | Training loss: 0.6873834091738651
Epoch: 4 | Iteration number: [3810/4518] 84% | Training loss: 0.6873844267815117
Epoch: 4 | Iteration number: [3820/4518] 84% | Training loss: 0.6873863545699893
Epoch: 4 | Iteration number: [3830/4518] 84% | Training loss: 0.6873884775308654
Epoch: 4 | Iteration number: [3840/4518] 84% | Training loss: 0.6873895487437646
Epoch: 4 | Iteration number: [3850/4518] 85% | Training loss: 0.6873869602556353
Epoch: 4 | Iteration number: [3860/4518] 85% | Training loss: 0.6873895339860817
Epoch: 4 | Iteration number: [3870/4518] 85% | Training loss: 0.6873872741402274
Epoch: 4 | Iteration number: [3880/4518] 85% | Training loss: 0.6873829290424426
Epoch: 4 | Iteration number: [3890/4518] 86% | Training loss: 0.6873815033613563
Epoch: 4 | Iteration number: [3900/4518] 86% | Training loss: 0.6873813039064407
Epoch: 4 | Iteration number: [3910/4518] 86% | Training loss: 0.6873819296012449
Epoch: 4 | Iteration number: [3920/4518] 86% | Training loss: 0.6873822820734005
Epoch: 4 | Iteration number: [3930/4518] 86% | Training loss: 0.6873799483436361
Epoch: 4 | Iteration number: [3940/4518] 87% | Training loss: 0.6873780544639239
Epoch: 4 | Iteration number: [3950/4518] 87% | Training loss: 0.6873804185360293
Epoch: 4 | Iteration number: [3960/4518] 87% | Training loss: 0.6873809034475172
Epoch: 4 | Iteration number: [3970/4518] 87% | Training loss: 0.6873826380040243
Epoch: 4 | Iteration number: [3980/4518] 88% | Training loss: 0.6873754642716604
Epoch: 4 | Iteration number: [3990/4518] 88% | Training loss: 0.6873720353408564
Epoch: 4 | Iteration number: [4000/4518] 88% | Training loss: 0.6873734782487154
Epoch: 4 | Iteration number: [4010/4518] 88% | Training loss: 0.6873728807133035
Epoch: 4 | Iteration number: [4020/4518] 88% | Training loss: 0.6873737276638325
Epoch: 4 | Iteration number: [4030/4518] 89% | Training loss: 0.6873750450297561
Epoch: 4 | Iteration number: [4040/4518] 89% | Training loss: 0.6873772130891829
Epoch: 4 | Iteration number: [4050/4518] 89% | Training loss: 0.6873766356780205
Epoch: 4 | Iteration number: [4060/4518] 89% | Training loss: 0.6873766310843341
Epoch: 4 | Iteration number: [4070/4518] 90% | Training loss: 0.6873756274690792
Epoch: 4 | Iteration number: [4080/4518] 90% | Training loss: 0.6873731848363783
Epoch: 4 | Iteration number: [4090/4518] 90% | Training loss: 0.6873735723547947
Epoch: 4 | Iteration number: [4100/4518] 90% | Training loss: 0.6873745812730091
Epoch: 4 | Iteration number: [4110/4518] 90% | Training loss: 0.687374188183578
Epoch: 4 | Iteration number: [4120/4518] 91% | Training loss: 0.6873745343204841
Epoch: 4 | Iteration number: [4130/4518] 91% | Training loss: 0.6873757937052637
Epoch: 4 | Iteration number: [4140/4518] 91% | Training loss: 0.6873726653304078
Epoch: 4 | Iteration number: [4150/4518] 91% | Training loss: 0.6873721187947744
Epoch: 4 | Iteration number: [4160/4518] 92% | Training loss: 0.6873694782073682
Epoch: 4 | Iteration number: [4170/4518] 92% | Training loss: 0.6873707954546244
Epoch: 4 | Iteration number: [4180/4518] 92% | Training loss: 0.6873714036063144
Epoch: 4 | Iteration number: [4190/4518] 92% | Training loss: 0.6873734913464093
Epoch: 4 | Iteration number: [4200/4518] 92% | Training loss: 0.6873724039111818
Epoch: 4 | Iteration number: [4210/4518] 93% | Training loss: 0.687370295705818
Epoch: 4 | Iteration number: [4220/4518] 93% | Training loss: 0.6873701420158007
Epoch: 4 | Iteration number: [4230/4518] 93% | Training loss: 0.6873698981518441
Epoch: 4 | Iteration number: [4240/4518] 93% | Training loss: 0.687370540665568
Epoch: 4 | Iteration number: [4250/4518] 94% | Training loss: 0.6873709146415486
Epoch: 4 | Iteration number: [4260/4518] 94% | Training loss: 0.6873720877607103
Epoch: 4 | Iteration number: [4270/4518] 94% | Training loss: 0.6873688650633747
Epoch: 4 | Iteration number: [4280/4518] 94% | Training loss: 0.6873721707786355
Epoch: 4 | Iteration number: [4290/4518] 94% | Training loss: 0.6873726529952807
Epoch: 4 | Iteration number: [4300/4518] 95% | Training loss: 0.6873737521920094
Epoch: 4 | Iteration number: [4310/4518] 95% | Training loss: 0.6873718731502922
Epoch: 4 | Iteration number: [4320/4518] 95% | Training loss: 0.6873723000150036
Epoch: 4 | Iteration number: [4330/4518] 95% | Training loss: 0.6873733475769915
Epoch: 4 | Iteration number: [4340/4518] 96% | Training loss: 0.687373633469854
Epoch: 4 | Iteration number: [4350/4518] 96% | Training loss: 0.6873725085696955
Epoch: 4 | Iteration number: [4360/4518] 96% | Training loss: 0.6873707258646641
Epoch: 4 | Iteration number: [4370/4518] 96% | Training loss: 0.6873702332684323
Epoch: 4 | Iteration number: [4380/4518] 96% | Training loss: 0.6873697572647164
Epoch: 4 | Iteration number: [4390/4518] 97% | Training loss: 0.6873702670148402
Epoch: 4 | Iteration number: [4400/4518] 97% | Training loss: 0.6873678426309066
Epoch: 4 | Iteration number: [4410/4518] 97% | Training loss: 0.6873668600912808
Epoch: 4 | Iteration number: [4420/4518] 97% | Training loss: 0.6873677205580931
Epoch: 4 | Iteration number: [4430/4518] 98% | Training loss: 0.687368070312332
Epoch: 4 | Iteration number: [4440/4518] 98% | Training loss: 0.6873652460473078
Epoch: 4 | Iteration number: [4450/4518] 98% | Training loss: 0.6873645192719577
Epoch: 4 | Iteration number: [4460/4518] 98% | Training loss: 0.6873629104128868
Epoch: 4 | Iteration number: [4470/4518] 98% | Training loss: 0.6873629338122588
Epoch: 4 | Iteration number: [4480/4518] 99% | Training loss: 0.6873624694001462
Epoch: 4 | Iteration number: [4490/4518] 99% | Training loss: 0.6873627706864364
Epoch: 4 | Iteration number: [4500/4518] 99% | Training loss: 0.6873597277270423
Epoch: 4 | Iteration number: [4510/4518] 99% | Training loss: 0.6873623198389742

 End of epoch: 4 | Train Loss: 0.6872057854575149 | Training Time: 633 

 End of epoch: 4 | Eval Loss: 0.69022449790215 | Evaluating Time: 17 
Epoch: 5 | Iteration number: [10/4518] 0% | Training loss: 0.7567627787590027
Epoch: 5 | Iteration number: [20/4518] 0% | Training loss: 0.72225062251091
Epoch: 5 | Iteration number: [30/4518] 0% | Training loss: 0.7104406992594401
Epoch: 5 | Iteration number: [40/4518] 0% | Training loss: 0.7047065809369087
Epoch: 5 | Iteration number: [50/4518] 1% | Training loss: 0.7011683046817779
Epoch: 5 | Iteration number: [60/4518] 1% | Training loss: 0.6986375550429026
Epoch: 5 | Iteration number: [70/4518] 1% | Training loss: 0.6970764585903713
Epoch: 5 | Iteration number: [80/4518] 1% | Training loss: 0.6957058772444725
Epoch: 5 | Iteration number: [90/4518] 1% | Training loss: 0.6947615875138177
Epoch: 5 | Iteration number: [100/4518] 2% | Training loss: 0.693942306637764
Epoch: 5 | Iteration number: [110/4518] 2% | Training loss: 0.6934317101131786
Epoch: 5 | Iteration number: [120/4518] 2% | Training loss: 0.6929357513785362
Epoch: 5 | Iteration number: [130/4518] 2% | Training loss: 0.692422528908803
Epoch: 5 | Iteration number: [140/4518] 3% | Training loss: 0.6920958970274244
Epoch: 5 | Iteration number: [150/4518] 3% | Training loss: 0.6917565643787384
Epoch: 5 | Iteration number: [160/4518] 3% | Training loss: 0.6914542324841022
Epoch: 5 | Iteration number: [170/4518] 3% | Training loss: 0.6911998317522161
Epoch: 5 | Iteration number: [180/4518] 3% | Training loss: 0.690974533226755
Epoch: 5 | Iteration number: [190/4518] 4% | Training loss: 0.6907787225748363
Epoch: 5 | Iteration number: [200/4518] 4% | Training loss: 0.6906302252411842
Epoch: 5 | Iteration number: [210/4518] 4% | Training loss: 0.6904503683249156
Epoch: 5 | Iteration number: [220/4518] 4% | Training loss: 0.6903085505420511
Epoch: 5 | Iteration number: [230/4518] 5% | Training loss: 0.6902218080085257
Epoch: 5 | Iteration number: [240/4518] 5% | Training loss: 0.690147141367197
Epoch: 5 | Iteration number: [250/4518] 5% | Training loss: 0.6900734996795654
Epoch: 5 | Iteration number: [260/4518] 5% | Training loss: 0.6899897848184292
Epoch: 5 | Iteration number: [270/4518] 5% | Training loss: 0.6898587059091639
Epoch: 5 | Iteration number: [280/4518] 6% | Training loss: 0.6897949697715896
Epoch: 5 | Iteration number: [290/4518] 6% | Training loss: 0.6897096144741979
Epoch: 5 | Iteration number: [300/4518] 6% | Training loss: 0.68963006178538
Epoch: 5 | Iteration number: [310/4518] 6% | Training loss: 0.6895560837561084
Epoch: 5 | Iteration number: [320/4518] 7% | Training loss: 0.6894852504134178
Epoch: 5 | Iteration number: [330/4518] 7% | Training loss: 0.6894007467862332
Epoch: 5 | Iteration number: [340/4518] 7% | Training loss: 0.6892963824903264
Epoch: 5 | Iteration number: [350/4518] 7% | Training loss: 0.6892024844033378
Epoch: 5 | Iteration number: [360/4518] 7% | Training loss: 0.6891533298624887
Epoch: 5 | Iteration number: [370/4518] 8% | Training loss: 0.6891299748742903
Epoch: 5 | Iteration number: [380/4518] 8% | Training loss: 0.6890661089043868
Epoch: 5 | Iteration number: [390/4518] 8% | Training loss: 0.6890213634723272
Epoch: 5 | Iteration number: [400/4518] 8% | Training loss: 0.6889688175916672
Epoch: 5 | Iteration number: [410/4518] 9% | Training loss: 0.6889105164423222
Epoch: 5 | Iteration number: [420/4518] 9% | Training loss: 0.6888739104781832
Epoch: 5 | Iteration number: [430/4518] 9% | Training loss: 0.6888323706249858
Epoch: 5 | Iteration number: [440/4518] 9% | Training loss: 0.6888190228830684
Epoch: 5 | Iteration number: [450/4518] 9% | Training loss: 0.6887649073865678
Epoch: 5 | Iteration number: [460/4518] 10% | Training loss: 0.6887277182029641
Epoch: 5 | Iteration number: [470/4518] 10% | Training loss: 0.688710847687214
Epoch: 5 | Iteration number: [480/4518] 10% | Training loss: 0.6886612613995869
Epoch: 5 | Iteration number: [490/4518] 10% | Training loss: 0.6886281953782452
Epoch: 5 | Iteration number: [500/4518] 11% | Training loss: 0.6885882620811462
Epoch: 5 | Iteration number: [510/4518] 11% | Training loss: 0.6885745608339122
Epoch: 5 | Iteration number: [520/4518] 11% | Training loss: 0.6885251089930534
Epoch: 5 | Iteration number: [530/4518] 11% | Training loss: 0.6885159160730974
Epoch: 5 | Iteration number: [540/4518] 11% | Training loss: 0.6884881056017346
Epoch: 5 | Iteration number: [550/4518] 12% | Training loss: 0.6884709910912947
Epoch: 5 | Iteration number: [560/4518] 12% | Training loss: 0.6884408316441945
Epoch: 5 | Iteration number: [570/4518] 12% | Training loss: 0.6884270780964902
Epoch: 5 | Iteration number: [580/4518] 12% | Training loss: 0.688409602744826
Epoch: 5 | Iteration number: [590/4518] 13% | Training loss: 0.6883840997340316
Epoch: 5 | Iteration number: [600/4518] 13% | Training loss: 0.6883486363291741
Epoch: 5 | Iteration number: [610/4518] 13% | Training loss: 0.6883184197496195
Epoch: 5 | Iteration number: [620/4518] 13% | Training loss: 0.6883127645138771
Epoch: 5 | Iteration number: [630/4518] 13% | Training loss: 0.6882923244483887
Epoch: 5 | Iteration number: [640/4518] 14% | Training loss: 0.6882825241424143
Epoch: 5 | Iteration number: [650/4518] 14% | Training loss: 0.688262106180191
Epoch: 5 | Iteration number: [660/4518] 14% | Training loss: 0.6882497782960083
Epoch: 5 | Iteration number: [670/4518] 14% | Training loss: 0.6882218069994628
Epoch: 5 | Iteration number: [680/4518] 15% | Training loss: 0.6882145140100928
Epoch: 5 | Iteration number: [690/4518] 15% | Training loss: 0.6881767806799516
Epoch: 5 | Iteration number: [700/4518] 15% | Training loss: 0.6881717154809407
Epoch: 5 | Iteration number: [710/4518] 15% | Training loss: 0.688152175386187
Epoch: 5 | Iteration number: [720/4518] 15% | Training loss: 0.6881449487474229
Epoch: 5 | Iteration number: [730/4518] 16% | Training loss: 0.6881349831411283
Epoch: 5 | Iteration number: [740/4518] 16% | Training loss: 0.6881284054872152
Epoch: 5 | Iteration number: [750/4518] 16% | Training loss: 0.6881176999409994
Epoch: 5 | Iteration number: [760/4518] 16% | Training loss: 0.6881266416687715
Epoch: 5 | Iteration number: [770/4518] 17% | Training loss: 0.6880983550827224
Epoch: 5 | Iteration number: [780/4518] 17% | Training loss: 0.6880982134586725
Epoch: 5 | Iteration number: [790/4518] 17% | Training loss: 0.6880967137179798
Epoch: 5 | Iteration number: [800/4518] 17% | Training loss: 0.6880815828591585
Epoch: 5 | Iteration number: [810/4518] 17% | Training loss: 0.6880594040140694
Epoch: 5 | Iteration number: [820/4518] 18% | Training loss: 0.6880390948638684
Epoch: 5 | Iteration number: [830/4518] 18% | Training loss: 0.6880351619548108
Epoch: 5 | Iteration number: [840/4518] 18% | Training loss: 0.6880429151512327
Epoch: 5 | Iteration number: [850/4518] 18% | Training loss: 0.6880385249502519
Epoch: 5 | Iteration number: [860/4518] 19% | Training loss: 0.688011132631191
Epoch: 5 | Iteration number: [870/4518] 19% | Training loss: 0.6879931983591496
Epoch: 5 | Iteration number: [880/4518] 19% | Training loss: 0.6879828842526132
Epoch: 5 | Iteration number: [890/4518] 19% | Training loss: 0.6879803337407916
Epoch: 5 | Iteration number: [900/4518] 19% | Training loss: 0.6879523150126139
Epoch: 5 | Iteration number: [910/4518] 20% | Training loss: 0.6879491801445301
Epoch: 5 | Iteration number: [920/4518] 20% | Training loss: 0.6879384518965431
Epoch: 5 | Iteration number: [930/4518] 20% | Training loss: 0.6879300436665935
Epoch: 5 | Iteration number: [940/4518] 20% | Training loss: 0.68792165517807
Epoch: 5 | Iteration number: [950/4518] 21% | Training loss: 0.6879095524235775
Epoch: 5 | Iteration number: [960/4518] 21% | Training loss: 0.687897837224106
Epoch: 5 | Iteration number: [970/4518] 21% | Training loss: 0.6878945915969377
Epoch: 5 | Iteration number: [980/4518] 21% | Training loss: 0.6878990384388943
Epoch: 5 | Iteration number: [990/4518] 21% | Training loss: 0.6878882521330708
Epoch: 5 | Iteration number: [1000/4518] 22% | Training loss: 0.6878923285603523
Epoch: 5 | Iteration number: [1010/4518] 22% | Training loss: 0.6878833842749643
Epoch: 5 | Iteration number: [1020/4518] 22% | Training loss: 0.6878680160232619
Epoch: 5 | Iteration number: [1030/4518] 22% | Training loss: 0.6878569769627839
Epoch: 5 | Iteration number: [1040/4518] 23% | Training loss: 0.687851595821289
Epoch: 5 | Iteration number: [1050/4518] 23% | Training loss: 0.6878456715742747
Epoch: 5 | Iteration number: [1060/4518] 23% | Training loss: 0.6878465916188258
Epoch: 5 | Iteration number: [1070/4518] 23% | Training loss: 0.6878416166684338
Epoch: 5 | Iteration number: [1080/4518] 23% | Training loss: 0.6878283522195286
Epoch: 5 | Iteration number: [1090/4518] 24% | Training loss: 0.6878143440145965
Epoch: 5 | Iteration number: [1100/4518] 24% | Training loss: 0.6878176352652636
Epoch: 5 | Iteration number: [1110/4518] 24% | Training loss: 0.6878162580567437
Epoch: 5 | Iteration number: [1120/4518] 24% | Training loss: 0.6878156270831823
Epoch: 5 | Iteration number: [1130/4518] 25% | Training loss: 0.6878075967847773
Epoch: 5 | Iteration number: [1140/4518] 25% | Training loss: 0.6878054220425455
Epoch: 5 | Iteration number: [1150/4518] 25% | Training loss: 0.6878027299694393
Epoch: 5 | Iteration number: [1160/4518] 25% | Training loss: 0.6877865362783958
Epoch: 5 | Iteration number: [1170/4518] 25% | Training loss: 0.68778090135664
Epoch: 5 | Iteration number: [1180/4518] 26% | Training loss: 0.6877739243588206
Epoch: 5 | Iteration number: [1190/4518] 26% | Training loss: 0.6877584748909253
Epoch: 5 | Iteration number: [1200/4518] 26% | Training loss: 0.6877489587167899
Epoch: 5 | Iteration number: [1210/4518] 26% | Training loss: 0.6877348591473477
Epoch: 5 | Iteration number: [1220/4518] 27% | Training loss: 0.687727788676981
Epoch: 5 | Iteration number: [1230/4518] 27% | Training loss: 0.6877250543939389
Epoch: 5 | Iteration number: [1240/4518] 27% | Training loss: 0.6877284515288569
Epoch: 5 | Iteration number: [1250/4518] 27% | Training loss: 0.6877199355125427
Epoch: 5 | Iteration number: [1260/4518] 27% | Training loss: 0.6877129085007168
Epoch: 5 | Iteration number: [1270/4518] 28% | Training loss: 0.6877023604441815
Epoch: 5 | Iteration number: [1280/4518] 28% | Training loss: 0.6876897801179439
Epoch: 5 | Iteration number: [1290/4518] 28% | Training loss: 0.6876939025498175
Epoch: 5 | Iteration number: [1300/4518] 28% | Training loss: 0.6876991768983695
Epoch: 5 | Iteration number: [1310/4518] 28% | Training loss: 0.6877004473263981
Epoch: 5 | Iteration number: [1320/4518] 29% | Training loss: 0.6877065354224408
Epoch: 5 | Iteration number: [1330/4518] 29% | Training loss: 0.6877073515178566
Epoch: 5 | Iteration number: [1340/4518] 29% | Training loss: 0.6876970818238471
Epoch: 5 | Iteration number: [1350/4518] 29% | Training loss: 0.687682097002312
Epoch: 5 | Iteration number: [1360/4518] 30% | Training loss: 0.6876809666700223
Epoch: 5 | Iteration number: [1370/4518] 30% | Training loss: 0.6876753162728609
Epoch: 5 | Iteration number: [1380/4518] 30% | Training loss: 0.6876708139975866
Epoch: 5 | Iteration number: [1390/4518] 30% | Training loss: 0.6876607564713457
Epoch: 5 | Iteration number: [1400/4518] 30% | Training loss: 0.6876556524634361
Epoch: 5 | Iteration number: [1410/4518] 31% | Training loss: 0.6876493403252135
Epoch: 5 | Iteration number: [1420/4518] 31% | Training loss: 0.6876496760778024
Epoch: 5 | Iteration number: [1430/4518] 31% | Training loss: 0.6876519899685066
Epoch: 5 | Iteration number: [1440/4518] 31% | Training loss: 0.6876547902822494
Epoch: 5 | Iteration number: [1450/4518] 32% | Training loss: 0.6876498297576247
Epoch: 5 | Iteration number: [1460/4518] 32% | Training loss: 0.6876425543060042
Epoch: 5 | Iteration number: [1470/4518] 32% | Training loss: 0.6876354619353807
Epoch: 5 | Iteration number: [1480/4518] 32% | Training loss: 0.6876421720997707
Epoch: 5 | Iteration number: [1490/4518] 32% | Training loss: 0.6876393656202611
Epoch: 5 | Iteration number: [1500/4518] 33% | Training loss: 0.6876375852823258
Epoch: 5 | Iteration number: [1510/4518] 33% | Training loss: 0.6876389685845533
Epoch: 5 | Iteration number: [1520/4518] 33% | Training loss: 0.6876354419479245
Epoch: 5 | Iteration number: [1530/4518] 33% | Training loss: 0.6876343565439087
Epoch: 5 | Iteration number: [1540/4518] 34% | Training loss: 0.6876334458202511
Epoch: 5 | Iteration number: [1550/4518] 34% | Training loss: 0.6876331941927633
Epoch: 5 | Iteration number: [1560/4518] 34% | Training loss: 0.6876342367285337
Epoch: 5 | Iteration number: [1570/4518] 34% | Training loss: 0.687636676981191
Epoch: 5 | Iteration number: [1580/4518] 34% | Training loss: 0.6876254549132118
Epoch: 5 | Iteration number: [1590/4518] 35% | Training loss: 0.6876296989572873
Epoch: 5 | Iteration number: [1600/4518] 35% | Training loss: 0.6876219487562776
Epoch: 5 | Iteration number: [1610/4518] 35% | Training loss: 0.6876142604380661
Epoch: 5 | Iteration number: [1620/4518] 35% | Training loss: 0.6876065637962318
Epoch: 5 | Iteration number: [1630/4518] 36% | Training loss: 0.6876101295275191
Epoch: 5 | Iteration number: [1640/4518] 36% | Training loss: 0.687609950580248
Epoch: 5 | Iteration number: [1650/4518] 36% | Training loss: 0.6876101325858723
Epoch: 5 | Iteration number: [1660/4518] 36% | Training loss: 0.687613037551742
Epoch: 5 | Iteration number: [1670/4518] 36% | Training loss: 0.6876156222320602
Epoch: 5 | Iteration number: [1680/4518] 37% | Training loss: 0.6876163959148385
Epoch: 5 | Iteration number: [1690/4518] 37% | Training loss: 0.6876198276965576
Epoch: 5 | Iteration number: [1700/4518] 37% | Training loss: 0.687622729084071
Epoch: 5 | Iteration number: [1710/4518] 37% | Training loss: 0.6876178366747516
Epoch: 5 | Iteration number: [1720/4518] 38% | Training loss: 0.6876134925456934
Epoch: 5 | Iteration number: [1730/4518] 38% | Training loss: 0.687604574006417
Epoch: 5 | Iteration number: [1740/4518] 38% | Training loss: 0.6876090883523568
Epoch: 5 | Iteration number: [1750/4518] 38% | Training loss: 0.6876088614123208
Epoch: 5 | Iteration number: [1760/4518] 38% | Training loss: 0.6876071718944745
Epoch: 5 | Iteration number: [1770/4518] 39% | Training loss: 0.6876054876268247
Epoch: 5 | Iteration number: [1780/4518] 39% | Training loss: 0.6876058215170764
Epoch: 5 | Iteration number: [1790/4518] 39% | Training loss: 0.6876052813157023
Epoch: 5 | Iteration number: [1800/4518] 39% | Training loss: 0.6875932519965702
Epoch: 5 | Iteration number: [1810/4518] 40% | Training loss: 0.6875911228893871
Epoch: 5 | Iteration number: [1820/4518] 40% | Training loss: 0.6875885454507974
Epoch: 5 | Iteration number: [1830/4518] 40% | Training loss: 0.6875826826512488
Epoch: 5 | Iteration number: [1840/4518] 40% | Training loss: 0.6875802055649135
Epoch: 5 | Iteration number: [1850/4518] 40% | Training loss: 0.6875786844781927
Epoch: 5 | Iteration number: [1860/4518] 41% | Training loss: 0.6875719757810715
Epoch: 5 | Iteration number: [1870/4518] 41% | Training loss: 0.6875733002303118
Epoch: 5 | Iteration number: [1880/4518] 41% | Training loss: 0.6875634281242148
Epoch: 5 | Iteration number: [1890/4518] 41% | Training loss: 0.6875639690608575
Epoch: 5 | Iteration number: [1900/4518] 42% | Training loss: 0.6875620363260571
Epoch: 5 | Iteration number: [1910/4518] 42% | Training loss: 0.6875545790994354
Epoch: 5 | Iteration number: [1920/4518] 42% | Training loss: 0.6875447519433995
Epoch: 5 | Iteration number: [1930/4518] 42% | Training loss: 0.6875455110493102
Epoch: 5 | Iteration number: [1940/4518] 42% | Training loss: 0.687542311186643
Epoch: 5 | Iteration number: [1950/4518] 43% | Training loss: 0.6875441700678605
Epoch: 5 | Iteration number: [1960/4518] 43% | Training loss: 0.6875426161350037
Epoch: 5 | Iteration number: [1970/4518] 43% | Training loss: 0.687544085440902
Epoch: 5 | Iteration number: [1980/4518] 43% | Training loss: 0.6875481021223646
Epoch: 5 | Iteration number: [1990/4518] 44% | Training loss: 0.6875465124995265
Epoch: 5 | Iteration number: [2000/4518] 44% | Training loss: 0.6875507421791553
Epoch: 5 | Iteration number: [2010/4518] 44% | Training loss: 0.6875491949456248
Epoch: 5 | Iteration number: [2020/4518] 44% | Training loss: 0.6875483763985114
Epoch: 5 | Iteration number: [2030/4518] 44% | Training loss: 0.6875478300848618
Epoch: 5 | Iteration number: [2040/4518] 45% | Training loss: 0.6875470836665116
Epoch: 5 | Iteration number: [2050/4518] 45% | Training loss: 0.6875426791353924
Epoch: 5 | Iteration number: [2060/4518] 45% | Training loss: 0.6875480732292805
Epoch: 5 | Iteration number: [2070/4518] 45% | Training loss: 0.6875488324153827
Epoch: 5 | Iteration number: [2080/4518] 46% | Training loss: 0.6875465031713247
Epoch: 5 | Iteration number: [2090/4518] 46% | Training loss: 0.6875502004577783
Epoch: 5 | Iteration number: [2100/4518] 46% | Training loss: 0.6875475420554479
Epoch: 5 | Iteration number: [2110/4518] 46% | Training loss: 0.6875439137926599
Epoch: 5 | Iteration number: [2120/4518] 46% | Training loss: 0.6875325126186856
Epoch: 5 | Iteration number: [2130/4518] 47% | Training loss: 0.6875299994654499
Epoch: 5 | Iteration number: [2140/4518] 47% | Training loss: 0.6875255935938559
Epoch: 5 | Iteration number: [2150/4518] 47% | Training loss: 0.6875242261276688
Epoch: 5 | Iteration number: [2160/4518] 47% | Training loss: 0.6875281587794975
Epoch: 5 | Iteration number: [2170/4518] 48% | Training loss: 0.6875326725469756
Epoch: 5 | Iteration number: [2180/4518] 48% | Training loss: 0.6875306021456324
Epoch: 5 | Iteration number: [2190/4518] 48% | Training loss: 0.687523813552508
Epoch: 5 | Iteration number: [2200/4518] 48% | Training loss: 0.6875263530015946
Epoch: 5 | Iteration number: [2210/4518] 48% | Training loss: 0.6875258621586934
Epoch: 5 | Iteration number: [2220/4518] 49% | Training loss: 0.6875265542719815
Epoch: 5 | Iteration number: [2230/4518] 49% | Training loss: 0.6875248462897245
Epoch: 5 | Iteration number: [2240/4518] 49% | Training loss: 0.6875211418473295
Epoch: 5 | Iteration number: [2250/4518] 49% | Training loss: 0.6875178357495202
Epoch: 5 | Iteration number: [2260/4518] 50% | Training loss: 0.6875194293207827
Epoch: 5 | Iteration number: [2270/4518] 50% | Training loss: 0.6875160656048863
Epoch: 5 | Iteration number: [2280/4518] 50% | Training loss: 0.6875148234137317
Epoch: 5 | Iteration number: [2290/4518] 50% | Training loss: 0.6875140597986863
Epoch: 5 | Iteration number: [2300/4518] 50% | Training loss: 0.6875150777464327
Epoch: 5 | Iteration number: [2310/4518] 51% | Training loss: 0.6875154292944706
Epoch: 5 | Iteration number: [2320/4518] 51% | Training loss: 0.6875116422258575
Epoch: 5 | Iteration number: [2330/4518] 51% | Training loss: 0.6875105872686329
Epoch: 5 | Iteration number: [2340/4518] 51% | Training loss: 0.6875127061564699
Epoch: 5 | Iteration number: [2350/4518] 52% | Training loss: 0.6875106086375865
Epoch: 5 | Iteration number: [2360/4518] 52% | Training loss: 0.6875119211562609
Epoch: 5 | Iteration number: [2370/4518] 52% | Training loss: 0.6875080994412869
Epoch: 5 | Iteration number: [2380/4518] 52% | Training loss: 0.6875063297628354
Epoch: 5 | Iteration number: [2390/4518] 52% | Training loss: 0.687505081083984
Epoch: 5 | Iteration number: [2400/4518] 53% | Training loss: 0.6875042860706647
Epoch: 5 | Iteration number: [2410/4518] 53% | Training loss: 0.6875012915906075
Epoch: 5 | Iteration number: [2420/4518] 53% | Training loss: 0.6874991750914203
Epoch: 5 | Iteration number: [2430/4518] 53% | Training loss: 0.6874968549842206
Epoch: 5 | Iteration number: [2440/4518] 54% | Training loss: 0.6874923396794522
Epoch: 5 | Iteration number: [2450/4518] 54% | Training loss: 0.6874880108541371
Epoch: 5 | Iteration number: [2460/4518] 54% | Training loss: 0.6874900027988403
Epoch: 5 | Iteration number: [2470/4518] 54% | Training loss: 0.6874906871965539
Epoch: 5 | Iteration number: [2480/4518] 54% | Training loss: 0.6874822986702765
Epoch: 5 | Iteration number: [2490/4518] 55% | Training loss: 0.6874804569056714
Epoch: 5 | Iteration number: [2500/4518] 55% | Training loss: 0.6874742550849915
Epoch: 5 | Iteration number: [2510/4518] 55% | Training loss: 0.6874723061147439
Epoch: 5 | Iteration number: [2520/4518] 55% | Training loss: 0.6874725263270121
Epoch: 5 | Iteration number: [2530/4518] 55% | Training loss: 0.6874718783872401
Epoch: 5 | Iteration number: [2540/4518] 56% | Training loss: 0.687469358026512
Epoch: 5 | Iteration number: [2550/4518] 56% | Training loss: 0.6874667060141469
Epoch: 5 | Iteration number: [2560/4518] 56% | Training loss: 0.6874624316813425
Epoch: 5 | Iteration number: [2570/4518] 56% | Training loss: 0.687460119483072
Epoch: 5 | Iteration number: [2580/4518] 57% | Training loss: 0.6874559209559314
Epoch: 5 | Iteration number: [2590/4518] 57% | Training loss: 0.6874537548273226
Epoch: 5 | Iteration number: [2600/4518] 57% | Training loss: 0.6874539857644301
Epoch: 5 | Iteration number: [2610/4518] 57% | Training loss: 0.687451263519996
Epoch: 5 | Iteration number: [2620/4518] 57% | Training loss: 0.6874477841471898
Epoch: 5 | Iteration number: [2630/4518] 58% | Training loss: 0.6874470586332532
Epoch: 5 | Iteration number: [2640/4518] 58% | Training loss: 0.6874474150890654
Epoch: 5 | Iteration number: [2650/4518] 58% | Training loss: 0.687446131863684
Epoch: 5 | Iteration number: [2660/4518] 58% | Training loss: 0.6874432791892747
Epoch: 5 | Iteration number: [2670/4518] 59% | Training loss: 0.6874447562944577
Epoch: 5 | Iteration number: [2680/4518] 59% | Training loss: 0.6874430328829965
Epoch: 5 | Iteration number: [2690/4518] 59% | Training loss: 0.687444545256604
Epoch: 5 | Iteration number: [2700/4518] 59% | Training loss: 0.6874415870507559
Epoch: 5 | Iteration number: [2710/4518] 59% | Training loss: 0.6874400928891453
Epoch: 5 | Iteration number: [2720/4518] 60% | Training loss: 0.6874395743669832
Epoch: 5 | Iteration number: [2730/4518] 60% | Training loss: 0.6874399895196432
Epoch: 5 | Iteration number: [2740/4518] 60% | Training loss: 0.6874350910421706
Epoch: 5 | Iteration number: [2750/4518] 60% | Training loss: 0.6874278341640125
Epoch: 5 | Iteration number: [2760/4518] 61% | Training loss: 0.6874296921750773
Epoch: 5 | Iteration number: [2770/4518] 61% | Training loss: 0.6874272047397462
Epoch: 5 | Iteration number: [2780/4518] 61% | Training loss: 0.6874236423549035
Epoch: 5 | Iteration number: [2790/4518] 61% | Training loss: 0.6874209691546724
Epoch: 5 | Iteration number: [2800/4518] 61% | Training loss: 0.6874214415465082
Epoch: 5 | Iteration number: [2810/4518] 62% | Training loss: 0.6874171951911627
Epoch: 5 | Iteration number: [2820/4518] 62% | Training loss: 0.6874143071631168
Epoch: 5 | Iteration number: [2830/4518] 62% | Training loss: 0.6874145446312301
Epoch: 5 | Iteration number: [2840/4518] 62% | Training loss: 0.6874126516807247
Epoch: 5 | Iteration number: [2850/4518] 63% | Training loss: 0.6874164006793708
Epoch: 5 | Iteration number: [2860/4518] 63% | Training loss: 0.6874135900210667
Epoch: 5 | Iteration number: [2870/4518] 63% | Training loss: 0.6874160057160913
Epoch: 5 | Iteration number: [2880/4518] 63% | Training loss: 0.6874162242023482
Epoch: 5 | Iteration number: [2890/4518] 63% | Training loss: 0.6874104500023139
Epoch: 5 | Iteration number: [2900/4518] 64% | Training loss: 0.6874115766327956
Epoch: 5 | Iteration number: [2910/4518] 64% | Training loss: 0.6874111080907055
Epoch: 5 | Iteration number: [2920/4518] 64% | Training loss: 0.6874089653361334
Epoch: 5 | Iteration number: [2930/4518] 64% | Training loss: 0.6874084880937895
Epoch: 5 | Iteration number: [2940/4518] 65% | Training loss: 0.6874086027648173
Epoch: 5 | Iteration number: [2950/4518] 65% | Training loss: 0.6874060162851366
Epoch: 5 | Iteration number: [2960/4518] 65% | Training loss: 0.6873998780508299
Epoch: 5 | Iteration number: [2970/4518] 65% | Training loss: 0.6873982752413059
Epoch: 5 | Iteration number: [2980/4518] 65% | Training loss: 0.6873946799727895
Epoch: 5 | Iteration number: [2990/4518] 66% | Training loss: 0.6873941240900735
Epoch: 5 | Iteration number: [3000/4518] 66% | Training loss: 0.6873897062937419
Epoch: 5 | Iteration number: [3010/4518] 66% | Training loss: 0.6873845977244583
Epoch: 5 | Iteration number: [3020/4518] 66% | Training loss: 0.6873812389294833
Epoch: 5 | Iteration number: [3030/4518] 67% | Training loss: 0.6873803343513224
Epoch: 5 | Iteration number: [3040/4518] 67% | Training loss: 0.6873789276339506
Epoch: 5 | Iteration number: [3050/4518] 67% | Training loss: 0.6873773069459884
Epoch: 5 | Iteration number: [3060/4518] 67% | Training loss: 0.6873746606843923
Epoch: 5 | Iteration number: [3070/4518] 67% | Training loss: 0.6873699915913883
Epoch: 5 | Iteration number: [3080/4518] 68% | Training loss: 0.6873717979564296
Epoch: 5 | Iteration number: [3090/4518] 68% | Training loss: 0.6873702218810331
Epoch: 5 | Iteration number: [3100/4518] 68% | Training loss: 0.687367543520466
Epoch: 5 | Iteration number: [3110/4518] 68% | Training loss: 0.6873655965857184
Epoch: 5 | Iteration number: [3120/4518] 69% | Training loss: 0.6873658355420981
Epoch: 5 | Iteration number: [3130/4518] 69% | Training loss: 0.6873627537355637
Epoch: 5 | Iteration number: [3140/4518] 69% | Training loss: 0.6873649193033291
Epoch: 5 | Iteration number: [3150/4518] 69% | Training loss: 0.687363506498791
Epoch: 5 | Iteration number: [3160/4518] 69% | Training loss: 0.6873653130818017
Epoch: 5 | Iteration number: [3170/4518] 70% | Training loss: 0.6873616325930466
Epoch: 5 | Iteration number: [3180/4518] 70% | Training loss: 0.6873646449180519
Epoch: 5 | Iteration number: [3190/4518] 70% | Training loss: 0.687365135597211
Epoch: 5 | Iteration number: [3200/4518] 70% | Training loss: 0.6873640850372612
Epoch: 5 | Iteration number: [3210/4518] 71% | Training loss: 0.6873603087162303
Epoch: 5 | Iteration number: [3220/4518] 71% | Training loss: 0.6873621127620246
Epoch: 5 | Iteration number: [3230/4518] 71% | Training loss: 0.6873603390650852
Epoch: 5 | Iteration number: [3240/4518] 71% | Training loss: 0.6873596856807485
Epoch: 5 | Iteration number: [3250/4518] 71% | Training loss: 0.6873639884361854
Epoch: 5 | Iteration number: [3260/4518] 72% | Training loss: 0.6873624574918689
Epoch: 5 | Iteration number: [3270/4518] 72% | Training loss: 0.6873607109810599
Epoch: 5 | Iteration number: [3280/4518] 72% | Training loss: 0.6873620288582837
Epoch: 5 | Iteration number: [3290/4518] 72% | Training loss: 0.6873621769589131
Epoch: 5 | Iteration number: [3300/4518] 73% | Training loss: 0.6873609034400998
Epoch: 5 | Iteration number: [3310/4518] 73% | Training loss: 0.6873588283796686
Epoch: 5 | Iteration number: [3320/4518] 73% | Training loss: 0.6873567114393395
Epoch: 5 | Iteration number: [3330/4518] 73% | Training loss: 0.687357416686353
Epoch: 5 | Iteration number: [3340/4518] 73% | Training loss: 0.6873582227679784
Epoch: 5 | Iteration number: [3350/4518] 74% | Training loss: 0.6873557411378889
Epoch: 5 | Iteration number: [3360/4518] 74% | Training loss: 0.6873550655941169
Epoch: 5 | Iteration number: [3370/4518] 74% | Training loss: 0.6873560095399353
Epoch: 5 | Iteration number: [3380/4518] 74% | Training loss: 0.6873593863298202
Epoch: 5 | Iteration number: [3390/4518] 75% | Training loss: 0.6873581888225578
Epoch: 5 | Iteration number: [3400/4518] 75% | Training loss: 0.6873583588530036
Epoch: 5 | Iteration number: [3410/4518] 75% | Training loss: 0.6873572962724568
Epoch: 5 | Iteration number: [3420/4518] 75% | Training loss: 0.6873594265757945
Epoch: 5 | Iteration number: [3430/4518] 75% | Training loss: 0.6873556585075556
Epoch: 5 | Iteration number: [3440/4518] 76% | Training loss: 0.687351949651574
Epoch: 5 | Iteration number: [3450/4518] 76% | Training loss: 0.6873517095524332
Epoch: 5 | Iteration number: [3460/4518] 76% | Training loss: 0.687347658538405
Epoch: 5 | Iteration number: [3470/4518] 76% | Training loss: 0.6873470782203015
Epoch: 5 | Iteration number: [3480/4518] 77% | Training loss: 0.6873455316170879
Epoch: 5 | Iteration number: [3490/4518] 77% | Training loss: 0.6873438978775867
Epoch: 5 | Iteration number: [3500/4518] 77% | Training loss: 0.687345540029662
Epoch: 5 | Iteration number: [3510/4518] 77% | Training loss: 0.687341957791918
Epoch: 5 | Iteration number: [3520/4518] 77% | Training loss: 0.6873426509682428
Epoch: 5 | Iteration number: [3530/4518] 78% | Training loss: 0.687342816405526
Epoch: 5 | Iteration number: [3540/4518] 78% | Training loss: 0.6873404641946157
Epoch: 5 | Iteration number: [3550/4518] 78% | Training loss: 0.6873394279580721
Epoch: 5 | Iteration number: [3560/4518] 78% | Training loss: 0.6873420850447055
Epoch: 5 | Iteration number: [3570/4518] 79% | Training loss: 0.6873416488744966
Epoch: 5 | Iteration number: [3580/4518] 79% | Training loss: 0.687338366938037
Epoch: 5 | Iteration number: [3590/4518] 79% | Training loss: 0.6873386174191339
Epoch: 5 | Iteration number: [3600/4518] 79% | Training loss: 0.687338141053915
Epoch: 5 | Iteration number: [3610/4518] 79% | Training loss: 0.6873397198740465
Epoch: 5 | Iteration number: [3620/4518] 80% | Training loss: 0.6873374536880472
Epoch: 5 | Iteration number: [3630/4518] 80% | Training loss: 0.687337422830671
Epoch: 5 | Iteration number: [3640/4518] 80% | Training loss: 0.687332378245972
Epoch: 5 | Iteration number: [3650/4518] 80% | Training loss: 0.6873346199238137
Epoch: 5 | Iteration number: [3660/4518] 81% | Training loss: 0.6873321607138941
Epoch: 5 | Iteration number: [3670/4518] 81% | Training loss: 0.6873335029026468
Epoch: 5 | Iteration number: [3680/4518] 81% | Training loss: 0.6873375407055669
Epoch: 5 | Iteration number: [3690/4518] 81% | Training loss: 0.6873370297717531
Epoch: 5 | Iteration number: [3700/4518] 81% | Training loss: 0.6873414789019404
Epoch: 5 | Iteration number: [3710/4518] 82% | Training loss: 0.6873387820155151
Epoch: 5 | Iteration number: [3720/4518] 82% | Training loss: 0.6873370786027242
Epoch: 5 | Iteration number: [3730/4518] 82% | Training loss: 0.6873386673409562
Epoch: 5 | Iteration number: [3740/4518] 82% | Training loss: 0.6873330290942269
Epoch: 5 | Iteration number: [3750/4518] 83% | Training loss: 0.6873287743409475
Epoch: 5 | Iteration number: [3760/4518] 83% | Training loss: 0.68732824308124
Epoch: 5 | Iteration number: [3770/4518] 83% | Training loss: 0.6873286555553305
Epoch: 5 | Iteration number: [3780/4518] 83% | Training loss: 0.6873306615958138
Epoch: 5 | Iteration number: [3790/4518] 83% | Training loss: 0.6873322967646305
Epoch: 5 | Iteration number: [3800/4518] 84% | Training loss: 0.6873285607287758
Epoch: 5 | Iteration number: [3810/4518] 84% | Training loss: 0.6873246566830031
Epoch: 5 | Iteration number: [3820/4518] 84% | Training loss: 0.6873219949100654
Epoch: 5 | Iteration number: [3830/4518] 84% | Training loss: 0.6873208389581028
Epoch: 5 | Iteration number: [3840/4518] 84% | Training loss: 0.6873229647210489
Epoch: 5 | Iteration number: [3850/4518] 85% | Training loss: 0.6873152029514312
Epoch: 5 | Iteration number: [3860/4518] 85% | Training loss: 0.6873170840925503
Epoch: 5 | Iteration number: [3870/4518] 85% | Training loss: 0.6873181756152663
Epoch: 5 | Iteration number: [3880/4518] 85% | Training loss: 0.687316639967186
Epoch: 5 | Iteration number: [3890/4518] 86% | Training loss: 0.6873173763022631
Epoch: 5 | Iteration number: [3900/4518] 86% | Training loss: 0.6873160190460009
Epoch: 5 | Iteration number: [3910/4518] 86% | Training loss: 0.6873140564812419
Epoch: 5 | Iteration number: [3920/4518] 86% | Training loss: 0.6873147837361511
Epoch: 5 | Iteration number: [3930/4518] 86% | Training loss: 0.6873128152075615
Epoch: 5 | Iteration number: [3940/4518] 87% | Training loss: 0.6873103118487421
Epoch: 5 | Iteration number: [3950/4518] 87% | Training loss: 0.6873094051095504
Epoch: 5 | Iteration number: [3960/4518] 87% | Training loss: 0.6873118721626021
Epoch: 5 | Iteration number: [3970/4518] 87% | Training loss: 0.6873122413452687
Epoch: 5 | Iteration number: [3980/4518] 88% | Training loss: 0.6873103458527944
Epoch: 5 | Iteration number: [3990/4518] 88% | Training loss: 0.6873106173853528
Epoch: 5 | Iteration number: [4000/4518] 88% | Training loss: 0.6873079475015402
Epoch: 5 | Iteration number: [4010/4518] 88% | Training loss: 0.6873085732471913
Epoch: 5 | Iteration number: [4020/4518] 88% | Training loss: 0.6873092857907661
Epoch: 5 | Iteration number: [4030/4518] 89% | Training loss: 0.6873120400213426
Epoch: 5 | Iteration number: [4040/4518] 89% | Training loss: 0.6873089815277864
Epoch: 5 | Iteration number: [4050/4518] 89% | Training loss: 0.6873043067808504
Epoch: 5 | Iteration number: [4060/4518] 89% | Training loss: 0.687303045494803
Epoch: 5 | Iteration number: [4070/4518] 90% | Training loss: 0.6873001534757216
Epoch: 5 | Iteration number: [4080/4518] 90% | Training loss: 0.6872968481305768
Epoch: 5 | Iteration number: [4090/4518] 90% | Training loss: 0.6872954627558189
Epoch: 5 | Iteration number: [4100/4518] 90% | Training loss: 0.6872958552546617
Epoch: 5 | Iteration number: [4110/4518] 90% | Training loss: 0.687294846918171
Epoch: 5 | Iteration number: [4120/4518] 91% | Training loss: 0.6872922216080924
Epoch: 5 | Iteration number: [4130/4518] 91% | Training loss: 0.6872917093174221
Epoch: 5 | Iteration number: [4140/4518] 91% | Training loss: 0.6872899569031121
Epoch: 5 | Iteration number: [4150/4518] 91% | Training loss: 0.6872879054029304
Epoch: 5 | Iteration number: [4160/4518] 92% | Training loss: 0.6872893326127758
Epoch: 5 | Iteration number: [4170/4518] 92% | Training loss: 0.6872869576481606
Epoch: 5 | Iteration number: [4180/4518] 92% | Training loss: 0.6872851025544856
Epoch: 5 | Iteration number: [4190/4518] 92% | Training loss: 0.68728211495074
Epoch: 5 | Iteration number: [4200/4518] 92% | Training loss: 0.6872833333128975
Epoch: 5 | Iteration number: [4210/4518] 93% | Training loss: 0.6872838462475077
Epoch: 5 | Iteration number: [4220/4518] 93% | Training loss: 0.6872824084984748
Epoch: 5 | Iteration number: [4230/4518] 93% | Training loss: 0.6872845175277539
Epoch: 5 | Iteration number: [4240/4518] 93% | Training loss: 0.6872846036024813
Epoch: 5 | Iteration number: [4250/4518] 94% | Training loss: 0.6872850232825559
Epoch: 5 | Iteration number: [4260/4518] 94% | Training loss: 0.687285131132099
Epoch: 5 | Iteration number: [4270/4518] 94% | Training loss: 0.6872824448472722
Epoch: 5 | Iteration number: [4280/4518] 94% | Training loss: 0.6872837958770378
Epoch: 5 | Iteration number: [4290/4518] 94% | Training loss: 0.6872846464454989
Epoch: 5 | Iteration number: [4300/4518] 95% | Training loss: 0.6872843182502791
Epoch: 5 | Iteration number: [4310/4518] 95% | Training loss: 0.6872817722937901
Epoch: 5 | Iteration number: [4320/4518] 95% | Training loss: 0.6872808935327662
Epoch: 5 | Iteration number: [4330/4518] 95% | Training loss: 0.6872801379711468
Epoch: 5 | Iteration number: [4340/4518] 96% | Training loss: 0.6872817586369229
Epoch: 5 | Iteration number: [4350/4518] 96% | Training loss: 0.6872797852275015
Epoch: 5 | Iteration number: [4360/4518] 96% | Training loss: 0.6872825836096335
Epoch: 5 | Iteration number: [4370/4518] 96% | Training loss: 0.6872799216064217
Epoch: 5 | Iteration number: [4380/4518] 96% | Training loss: 0.6872778721596008
Epoch: 5 | Iteration number: [4390/4518] 97% | Training loss: 0.6872774621756039
Epoch: 5 | Iteration number: [4400/4518] 97% | Training loss: 0.6872744734856215
Epoch: 5 | Iteration number: [4410/4518] 97% | Training loss: 0.6872735256510797
Epoch: 5 | Iteration number: [4420/4518] 97% | Training loss: 0.687275284825407
Epoch: 5 | Iteration number: [4430/4518] 98% | Training loss: 0.6872743423717017
Epoch: 5 | Iteration number: [4440/4518] 98% | Training loss: 0.687272993911494
Epoch: 5 | Iteration number: [4450/4518] 98% | Training loss: 0.6872712269659792
Epoch: 5 | Iteration number: [4460/4518] 98% | Training loss: 0.687271090433202
Epoch: 5 | Iteration number: [4470/4518] 98% | Training loss: 0.6872719035185957
Epoch: 5 | Iteration number: [4480/4518] 99% | Training loss: 0.6872700568288564
Epoch: 5 | Iteration number: [4490/4518] 99% | Training loss: 0.6872726008860199
Epoch: 5 | Iteration number: [4500/4518] 99% | Training loss: 0.687269372092353
Epoch: 5 | Iteration number: [4510/4518] 99% | Training loss: 0.6872686005220181

 End of epoch: 5 | Train Loss: 0.687118328240341 | Training Time: 632 

 End of epoch: 5 | Eval Loss: 0.6902403685511375 | Evaluating Time: 17 
Epoch: 6 | Iteration number: [10/4518] 0% | Training loss: 0.7565910637378692
Epoch: 6 | Iteration number: [20/4518] 0% | Training loss: 0.7220690101385117
Epoch: 6 | Iteration number: [30/4518] 0% | Training loss: 0.7102451344331105
Epoch: 6 | Iteration number: [40/4518] 0% | Training loss: 0.7044372975826263
Epoch: 6 | Iteration number: [50/4518] 1% | Training loss: 0.7010802304744721
Epoch: 6 | Iteration number: [60/4518] 1% | Training loss: 0.6988230367501577
Epoch: 6 | Iteration number: [70/4518] 1% | Training loss: 0.6971648139613015
Epoch: 6 | Iteration number: [80/4518] 1% | Training loss: 0.6957983717322349
Epoch: 6 | Iteration number: [90/4518] 1% | Training loss: 0.6948864777882894
Epoch: 6 | Iteration number: [100/4518] 2% | Training loss: 0.6941761791706085
Epoch: 6 | Iteration number: [110/4518] 2% | Training loss: 0.6935466316613283
Epoch: 6 | Iteration number: [120/4518] 2% | Training loss: 0.69298455119133
Epoch: 6 | Iteration number: [130/4518] 2% | Training loss: 0.6924564081888932
Epoch: 6 | Iteration number: [140/4518] 3% | Training loss: 0.6921281090804509
Epoch: 6 | Iteration number: [150/4518] 3% | Training loss: 0.6917873589197795
Epoch: 6 | Iteration number: [160/4518] 3% | Training loss: 0.6914416454732418
Epoch: 6 | Iteration number: [170/4518] 3% | Training loss: 0.6911667213720434
Epoch: 6 | Iteration number: [180/4518] 3% | Training loss: 0.6908728924062517
Epoch: 6 | Iteration number: [190/4518] 4% | Training loss: 0.6906907153756995
Epoch: 6 | Iteration number: [200/4518] 4% | Training loss: 0.6905312755703926
Epoch: 6 | Iteration number: [210/4518] 4% | Training loss: 0.6903533861750648
Epoch: 6 | Iteration number: [220/4518] 4% | Training loss: 0.6902229956605218
Epoch: 6 | Iteration number: [230/4518] 5% | Training loss: 0.6901100200155507
Epoch: 6 | Iteration number: [240/4518] 5% | Training loss: 0.6900095390776794
Epoch: 6 | Iteration number: [250/4518] 5% | Training loss: 0.6899366681575775
Epoch: 6 | Iteration number: [260/4518] 5% | Training loss: 0.6898435051624592
Epoch: 6 | Iteration number: [270/4518] 5% | Training loss: 0.6897330654991998
Epoch: 6 | Iteration number: [280/4518] 6% | Training loss: 0.6896919320736613
Epoch: 6 | Iteration number: [290/4518] 6% | Training loss: 0.6895853996276855
Epoch: 6 | Iteration number: [300/4518] 6% | Training loss: 0.6895159316062928
Epoch: 6 | Iteration number: [310/4518] 6% | Training loss: 0.6894689784895989
Epoch: 6 | Iteration number: [320/4518] 7% | Training loss: 0.6893844982609153
Epoch: 6 | Iteration number: [330/4518] 7% | Training loss: 0.6893511542768189
Epoch: 6 | Iteration number: [340/4518] 7% | Training loss: 0.689263772613862
Epoch: 6 | Iteration number: [350/4518] 7% | Training loss: 0.6891797736712865
Epoch: 6 | Iteration number: [360/4518] 7% | Training loss: 0.689123327864541
Epoch: 6 | Iteration number: [370/4518] 8% | Training loss: 0.6890674858479886
Epoch: 6 | Iteration number: [380/4518] 8% | Training loss: 0.6890115116771899
Epoch: 6 | Iteration number: [390/4518] 8% | Training loss: 0.6889425288408231
Epoch: 6 | Iteration number: [400/4518] 8% | Training loss: 0.6889282016456127
Epoch: 6 | Iteration number: [410/4518] 9% | Training loss: 0.6889073129107313
Epoch: 6 | Iteration number: [420/4518] 9% | Training loss: 0.6888662568160466
Epoch: 6 | Iteration number: [430/4518] 9% | Training loss: 0.6888516227866328
Epoch: 6 | Iteration number: [440/4518] 9% | Training loss: 0.6887681485577063
Epoch: 6 | Iteration number: [450/4518] 9% | Training loss: 0.6887345977624257
Epoch: 6 | Iteration number: [460/4518] 10% | Training loss: 0.6886742650166802
Epoch: 6 | Iteration number: [470/4518] 10% | Training loss: 0.6886838999200374
Epoch: 6 | Iteration number: [480/4518] 10% | Training loss: 0.6886671372999748
Epoch: 6 | Iteration number: [490/4518] 10% | Training loss: 0.6886496547533542
Epoch: 6 | Iteration number: [500/4518] 11% | Training loss: 0.6886156784296036
Epoch: 6 | Iteration number: [510/4518] 11% | Training loss: 0.6886089746858559
Epoch: 6 | Iteration number: [520/4518] 11% | Training loss: 0.6885941007962594
Epoch: 6 | Iteration number: [530/4518] 11% | Training loss: 0.6885578686336301
Epoch: 6 | Iteration number: [540/4518] 11% | Training loss: 0.6885142622170625
Epoch: 6 | Iteration number: [550/4518] 12% | Training loss: 0.6885064800219103
Epoch: 6 | Iteration number: [560/4518] 12% | Training loss: 0.6884941354393959
Epoch: 6 | Iteration number: [570/4518] 12% | Training loss: 0.6884778004989289
Epoch: 6 | Iteration number: [580/4518] 12% | Training loss: 0.6884301042762296
Epoch: 6 | Iteration number: [590/4518] 13% | Training loss: 0.6884068140539072
Epoch: 6 | Iteration number: [600/4518] 13% | Training loss: 0.688377189040184
Epoch: 6 | Iteration number: [610/4518] 13% | Training loss: 0.6883676579741181
Epoch: 6 | Iteration number: [620/4518] 13% | Training loss: 0.688328759324166
Epoch: 6 | Iteration number: [630/4518] 13% | Training loss: 0.6883128380964673
Epoch: 6 | Iteration number: [640/4518] 14% | Training loss: 0.6883048134855926
Epoch: 6 | Iteration number: [650/4518] 14% | Training loss: 0.6883181321620941
Epoch: 6 | Iteration number: [660/4518] 14% | Training loss: 0.6883075472080347
Epoch: 6 | Iteration number: [670/4518] 14% | Training loss: 0.6882790742525414
Epoch: 6 | Iteration number: [680/4518] 15% | Training loss: 0.6882785734884879
Epoch: 6 | Iteration number: [690/4518] 15% | Training loss: 0.6882474888925967
Epoch: 6 | Iteration number: [700/4518] 15% | Training loss: 0.688247166275978
Epoch: 6 | Iteration number: [710/4518] 15% | Training loss: 0.6882173751441526
Epoch: 6 | Iteration number: [720/4518] 15% | Training loss: 0.6882014726599057
Epoch: 6 | Iteration number: [730/4518] 16% | Training loss: 0.6881791578580255
Epoch: 6 | Iteration number: [740/4518] 16% | Training loss: 0.6881700111402048
Epoch: 6 | Iteration number: [750/4518] 16% | Training loss: 0.6881600964864095
Epoch: 6 | Iteration number: [760/4518] 16% | Training loss: 0.6881444365570419
Epoch: 6 | Iteration number: [770/4518] 17% | Training loss: 0.6881367459699705
Epoch: 6 | Iteration number: [780/4518] 17% | Training loss: 0.6881114829045075
Epoch: 6 | Iteration number: [790/4518] 17% | Training loss: 0.6881080933009522
Epoch: 6 | Iteration number: [800/4518] 17% | Training loss: 0.6880943132191897
Epoch: 6 | Iteration number: [810/4518] 17% | Training loss: 0.6880879406575804
Epoch: 6 | Iteration number: [820/4518] 18% | Training loss: 0.6880882353317447
Epoch: 6 | Iteration number: [830/4518] 18% | Training loss: 0.6880786046924361
Epoch: 6 | Iteration number: [840/4518] 18% | Training loss: 0.6880748986488296
Epoch: 6 | Iteration number: [850/4518] 18% | Training loss: 0.6880458689437193
Epoch: 6 | Iteration number: [860/4518] 19% | Training loss: 0.6880406118409578
Epoch: 6 | Iteration number: [870/4518] 19% | Training loss: 0.6880229608765964
Epoch: 6 | Iteration number: [880/4518] 19% | Training loss: 0.688019732656804
Epoch: 6 | Iteration number: [890/4518] 19% | Training loss: 0.6880211592390296
Epoch: 6 | Iteration number: [900/4518] 19% | Training loss: 0.6880133332146539
Epoch: 6 | Iteration number: [910/4518] 20% | Training loss: 0.6880087845928067
Epoch: 6 | Iteration number: [920/4518] 20% | Training loss: 0.6880105985247571
Epoch: 6 | Iteration number: [930/4518] 20% | Training loss: 0.6880058470592704
Epoch: 6 | Iteration number: [940/4518] 20% | Training loss: 0.688000128624287
Epoch: 6 | Iteration number: [950/4518] 21% | Training loss: 0.6879967042019492
Epoch: 6 | Iteration number: [960/4518] 21% | Training loss: 0.687994371727109
Epoch: 6 | Iteration number: [970/4518] 21% | Training loss: 0.6879890913201362
Epoch: 6 | Iteration number: [980/4518] 21% | Training loss: 0.6879899327244078
Epoch: 6 | Iteration number: [990/4518] 21% | Training loss: 0.6879830952244576
Epoch: 6 | Iteration number: [1000/4518] 22% | Training loss: 0.6879784901142121
Epoch: 6 | Iteration number: [1010/4518] 22% | Training loss: 0.6879672759830362
Epoch: 6 | Iteration number: [1020/4518] 22% | Training loss: 0.6879702638177311
Epoch: 6 | Iteration number: [1030/4518] 22% | Training loss: 0.6879554019969644
Epoch: 6 | Iteration number: [1040/4518] 23% | Training loss: 0.6879461422562599
Epoch: 6 | Iteration number: [1050/4518] 23% | Training loss: 0.6879450615814754
Epoch: 6 | Iteration number: [1060/4518] 23% | Training loss: 0.6879387911198274
Epoch: 6 | Iteration number: [1070/4518] 23% | Training loss: 0.6879300778157244
Epoch: 6 | Iteration number: [1080/4518] 23% | Training loss: 0.6879330103596052
Epoch: 6 | Iteration number: [1090/4518] 24% | Training loss: 0.6879218397884194
Epoch: 6 | Iteration number: [1100/4518] 24% | Training loss: 0.6879126473990353
Epoch: 6 | Iteration number: [1110/4518] 24% | Training loss: 0.6878967536999299
Epoch: 6 | Iteration number: [1120/4518] 24% | Training loss: 0.6878948241472245
Epoch: 6 | Iteration number: [1130/4518] 25% | Training loss: 0.6878858472921152
Epoch: 6 | Iteration number: [1140/4518] 25% | Training loss: 0.6878715746758277
Epoch: 6 | Iteration number: [1150/4518] 25% | Training loss: 0.6878660589715709
Epoch: 6 | Iteration number: [1160/4518] 25% | Training loss: 0.687865495887296
Epoch: 6 | Iteration number: [1170/4518] 25% | Training loss: 0.6878640227847629
Epoch: 6 | Iteration number: [1180/4518] 26% | Training loss: 0.6878589039636871
Epoch: 6 | Iteration number: [1190/4518] 26% | Training loss: 0.6878591126253625
Epoch: 6 | Iteration number: [1200/4518] 26% | Training loss: 0.6878566158811251
Epoch: 6 | Iteration number: [1210/4518] 26% | Training loss: 0.6878432370907019
Epoch: 6 | Iteration number: [1220/4518] 27% | Training loss: 0.6878354320272071
Epoch: 6 | Iteration number: [1230/4518] 27% | Training loss: 0.6878099427959783
Epoch: 6 | Iteration number: [1240/4518] 27% | Training loss: 0.6878107501614479
Epoch: 6 | Iteration number: [1250/4518] 27% | Training loss: 0.6878032641410827
Epoch: 6 | Iteration number: [1260/4518] 27% | Training loss: 0.687800140134872
Epoch: 6 | Iteration number: [1270/4518] 28% | Training loss: 0.6877993551295574
Epoch: 6 | Iteration number: [1280/4518] 28% | Training loss: 0.6877951421309263
Epoch: 6 | Iteration number: [1290/4518] 28% | Training loss: 0.6877958026967307
Epoch: 6 | Iteration number: [1300/4518] 28% | Training loss: 0.6877925557356614
Epoch: 6 | Iteration number: [1310/4518] 28% | Training loss: 0.6877814166873466
Epoch: 6 | Iteration number: [1320/4518] 29% | Training loss: 0.6877850085948453
Epoch: 6 | Iteration number: [1330/4518] 29% | Training loss: 0.6877783633264384
Epoch: 6 | Iteration number: [1340/4518] 29% | Training loss: 0.6877689770798185
Epoch: 6 | Iteration number: [1350/4518] 29% | Training loss: 0.6877546692336047
Epoch: 6 | Iteration number: [1360/4518] 30% | Training loss: 0.6877525820451624
Epoch: 6 | Iteration number: [1370/4518] 30% | Training loss: 0.6877519979529138
Epoch: 6 | Iteration number: [1380/4518] 30% | Training loss: 0.6877480058134466
Epoch: 6 | Iteration number: [1390/4518] 30% | Training loss: 0.6877318082953529
Epoch: 6 | Iteration number: [1400/4518] 30% | Training loss: 0.6877256656544549
Epoch: 6 | Iteration number: [1410/4518] 31% | Training loss: 0.6877187126071741
Epoch: 6 | Iteration number: [1420/4518] 31% | Training loss: 0.6877243880654724
Epoch: 6 | Iteration number: [1430/4518] 31% | Training loss: 0.6877135280962591
Epoch: 6 | Iteration number: [1440/4518] 31% | Training loss: 0.6877233579754829
Epoch: 6 | Iteration number: [1450/4518] 32% | Training loss: 0.6877144330945508
Epoch: 6 | Iteration number: [1460/4518] 32% | Training loss: 0.6877074492712544
Epoch: 6 | Iteration number: [1470/4518] 32% | Training loss: 0.6876909120553205
Epoch: 6 | Iteration number: [1480/4518] 32% | Training loss: 0.6876820158716794
Epoch: 6 | Iteration number: [1490/4518] 32% | Training loss: 0.6876693668781511
Epoch: 6 | Iteration number: [1500/4518] 33% | Training loss: 0.6876708382368087
Epoch: 6 | Iteration number: [1510/4518] 33% | Training loss: 0.6876639912460024
Epoch: 6 | Iteration number: [1520/4518] 33% | Training loss: 0.6876576007981049
Epoch: 6 | Iteration number: [1530/4518] 33% | Training loss: 0.6876556498942032
Epoch: 6 | Iteration number: [1540/4518] 34% | Training loss: 0.6876586275828349
Epoch: 6 | Iteration number: [1550/4518] 34% | Training loss: 0.6876586815618699
Epoch: 6 | Iteration number: [1560/4518] 34% | Training loss: 0.6876456262973639
Epoch: 6 | Iteration number: [1570/4518] 34% | Training loss: 0.6876457475552893
Epoch: 6 | Iteration number: [1580/4518] 34% | Training loss: 0.6876431932932214
Epoch: 6 | Iteration number: [1590/4518] 35% | Training loss: 0.6876443420566103
Epoch: 6 | Iteration number: [1600/4518] 35% | Training loss: 0.6876357989385724
Epoch: 6 | Iteration number: [1610/4518] 35% | Training loss: 0.6876375837725882
Epoch: 6 | Iteration number: [1620/4518] 35% | Training loss: 0.6876358573451454
Epoch: 6 | Iteration number: [1630/4518] 36% | Training loss: 0.6876201393779802
Epoch: 6 | Iteration number: [1640/4518] 36% | Training loss: 0.687609339632639
Epoch: 6 | Iteration number: [1650/4518] 36% | Training loss: 0.687604014042652
Epoch: 6 | Iteration number: [1660/4518] 36% | Training loss: 0.6876022695776928
Epoch: 6 | Iteration number: [1670/4518] 36% | Training loss: 0.6875931975370395
Epoch: 6 | Iteration number: [1680/4518] 37% | Training loss: 0.6875942406555017
Epoch: 6 | Iteration number: [1690/4518] 37% | Training loss: 0.6875827464478961
Epoch: 6 | Iteration number: [1700/4518] 37% | Training loss: 0.6875835916224649
Epoch: 6 | Iteration number: [1710/4518] 37% | Training loss: 0.6875775572500731
Epoch: 6 | Iteration number: [1720/4518] 38% | Training loss: 0.6875734471304472
Epoch: 6 | Iteration number: [1730/4518] 38% | Training loss: 0.6875654474848267
Epoch: 6 | Iteration number: [1740/4518] 38% | Training loss: 0.6875640345715929
Epoch: 6 | Iteration number: [1750/4518] 38% | Training loss: 0.6875560257434845
Epoch: 6 | Iteration number: [1760/4518] 38% | Training loss: 0.6875560138713229
Epoch: 6 | Iteration number: [1770/4518] 39% | Training loss: 0.6875558485755813
Epoch: 6 | Iteration number: [1780/4518] 39% | Training loss: 0.6875426230470786
Epoch: 6 | Iteration number: [1790/4518] 39% | Training loss: 0.687539422345561
Epoch: 6 | Iteration number: [1800/4518] 39% | Training loss: 0.6875389790534974
Epoch: 6 | Iteration number: [1810/4518] 40% | Training loss: 0.6875368292489763
Epoch: 6 | Iteration number: [1820/4518] 40% | Training loss: 0.6875277697385013
Epoch: 6 | Iteration number: [1830/4518] 40% | Training loss: 0.6875334817203668
Epoch: 6 | Iteration number: [1840/4518] 40% | Training loss: 0.6875313971353614
Epoch: 6 | Iteration number: [1850/4518] 40% | Training loss: 0.6875290888708991
Epoch: 6 | Iteration number: [1860/4518] 41% | Training loss: 0.6875285230977561
Epoch: 6 | Iteration number: [1870/4518] 41% | Training loss: 0.6875267969095771
Epoch: 6 | Iteration number: [1880/4518] 41% | Training loss: 0.6875223739667141
Epoch: 6 | Iteration number: [1890/4518] 41% | Training loss: 0.6875175960164852
Epoch: 6 | Iteration number: [1900/4518] 42% | Training loss: 0.6875192789341275
Epoch: 6 | Iteration number: [1910/4518] 42% | Training loss: 0.6875175905165248
Epoch: 6 | Iteration number: [1920/4518] 42% | Training loss: 0.6875106422851484
Epoch: 6 | Iteration number: [1930/4518] 42% | Training loss: 0.6875068971530144
Epoch: 6 | Iteration number: [1940/4518] 42% | Training loss: 0.6875011259133054
Epoch: 6 | Iteration number: [1950/4518] 43% | Training loss: 0.6875020972887675
Epoch: 6 | Iteration number: [1960/4518] 43% | Training loss: 0.6875026120215046
Epoch: 6 | Iteration number: [1970/4518] 43% | Training loss: 0.6875037139744928
Epoch: 6 | Iteration number: [1980/4518] 43% | Training loss: 0.6875011365221004
Epoch: 6 | Iteration number: [1990/4518] 44% | Training loss: 0.6874899079751728
Epoch: 6 | Iteration number: [2000/4518] 44% | Training loss: 0.6874824424088001
Epoch: 6 | Iteration number: [2010/4518] 44% | Training loss: 0.6874892241919218
Epoch: 6 | Iteration number: [2020/4518] 44% | Training loss: 0.687480406507407
Epoch: 6 | Iteration number: [2030/4518] 44% | Training loss: 0.6874758987297566
Epoch: 6 | Iteration number: [2040/4518] 45% | Training loss: 0.6874755256316241
Epoch: 6 | Iteration number: [2050/4518] 45% | Training loss: 0.6874709879770512
Epoch: 6 | Iteration number: [2060/4518] 45% | Training loss: 0.687464346931976
Epoch: 6 | Iteration number: [2070/4518] 45% | Training loss: 0.687465995175827
Epoch: 6 | Iteration number: [2080/4518] 46% | Training loss: 0.6874647673219443
Epoch: 6 | Iteration number: [2090/4518] 46% | Training loss: 0.6874662437222221
Epoch: 6 | Iteration number: [2100/4518] 46% | Training loss: 0.6874702336958477
Epoch: 6 | Iteration number: [2110/4518] 46% | Training loss: 0.6874619662761688
Epoch: 6 | Iteration number: [2120/4518] 46% | Training loss: 0.6874555873139849
Epoch: 6 | Iteration number: [2130/4518] 47% | Training loss: 0.687453723205647
Epoch: 6 | Iteration number: [2140/4518] 47% | Training loss: 0.6874521085592074
Epoch: 6 | Iteration number: [2150/4518] 47% | Training loss: 0.6874470289363418
Epoch: 6 | Iteration number: [2160/4518] 47% | Training loss: 0.6874419246558789
Epoch: 6 | Iteration number: [2170/4518] 48% | Training loss: 0.6874361065675586
Epoch: 6 | Iteration number: [2180/4518] 48% | Training loss: 0.6874361221943427
Epoch: 6 | Iteration number: [2190/4518] 48% | Training loss: 0.6874360724126911
Epoch: 6 | Iteration number: [2200/4518] 48% | Training loss: 0.6874365104328503
Epoch: 6 | Iteration number: [2210/4518] 48% | Training loss: 0.6874292170839612
Epoch: 6 | Iteration number: [2220/4518] 49% | Training loss: 0.6874256973868018
Epoch: 6 | Iteration number: [2230/4518] 49% | Training loss: 0.6874252858450595
Epoch: 6 | Iteration number: [2240/4518] 49% | Training loss: 0.6874246693083218
Epoch: 6 | Iteration number: [2250/4518] 49% | Training loss: 0.6874246159129672
Epoch: 6 | Iteration number: [2260/4518] 50% | Training loss: 0.687422674287737
Epoch: 6 | Iteration number: [2270/4518] 50% | Training loss: 0.6874247698006651
Epoch: 6 | Iteration number: [2280/4518] 50% | Training loss: 0.6874244402113714
Epoch: 6 | Iteration number: [2290/4518] 50% | Training loss: 0.6874240156344451
Epoch: 6 | Iteration number: [2300/4518] 50% | Training loss: 0.6874191617965698
Epoch: 6 | Iteration number: [2310/4518] 51% | Training loss: 0.6874204607753011
Epoch: 6 | Iteration number: [2320/4518] 51% | Training loss: 0.6874172489190924
Epoch: 6 | Iteration number: [2330/4518] 51% | Training loss: 0.6874148930091203
Epoch: 6 | Iteration number: [2340/4518] 51% | Training loss: 0.6874185603398543
Epoch: 6 | Iteration number: [2350/4518] 52% | Training loss: 0.6874156105264704
Epoch: 6 | Iteration number: [2360/4518] 52% | Training loss: 0.687416860587516
Epoch: 6 | Iteration number: [2370/4518] 52% | Training loss: 0.6874070838785372
Epoch: 6 | Iteration number: [2380/4518] 52% | Training loss: 0.6874072632118433
Epoch: 6 | Iteration number: [2390/4518] 52% | Training loss: 0.6874072687645837
Epoch: 6 | Iteration number: [2400/4518] 53% | Training loss: 0.6874061554918687
Epoch: 6 | Iteration number: [2410/4518] 53% | Training loss: 0.687406358060995
Epoch: 6 | Iteration number: [2420/4518] 53% | Training loss: 0.6874022352055085
Epoch: 6 | Iteration number: [2430/4518] 53% | Training loss: 0.6874018005628154
Epoch: 6 | Iteration number: [2440/4518] 54% | Training loss: 0.6873938535080582
Epoch: 6 | Iteration number: [2450/4518] 54% | Training loss: 0.6873947245490795
Epoch: 6 | Iteration number: [2460/4518] 54% | Training loss: 0.687391755324069
Epoch: 6 | Iteration number: [2470/4518] 54% | Training loss: 0.6873864529345199
Epoch: 6 | Iteration number: [2480/4518] 54% | Training loss: 0.6873822903681186
Epoch: 6 | Iteration number: [2490/4518] 55% | Training loss: 0.6873742812129867
Epoch: 6 | Iteration number: [2500/4518] 55% | Training loss: 0.6873706551551819
Epoch: 6 | Iteration number: [2510/4518] 55% | Training loss: 0.6873669048467005
Epoch: 6 | Iteration number: [2520/4518] 55% | Training loss: 0.6873613493073554
Epoch: 6 | Iteration number: [2530/4518] 55% | Training loss: 0.6873548838225279
Epoch: 6 | Iteration number: [2540/4518] 56% | Training loss: 0.6873584889051483
Epoch: 6 | Iteration number: [2550/4518] 56% | Training loss: 0.6873544417643079
Epoch: 6 | Iteration number: [2560/4518] 56% | Training loss: 0.6873588365735486
Epoch: 6 | Iteration number: [2570/4518] 56% | Training loss: 0.6873529469920503
Epoch: 6 | Iteration number: [2580/4518] 57% | Training loss: 0.6873546587173329
Epoch: 6 | Iteration number: [2590/4518] 57% | Training loss: 0.6873525318491873
Epoch: 6 | Iteration number: [2600/4518] 57% | Training loss: 0.6873521618659679
Epoch: 6 | Iteration number: [2610/4518] 57% | Training loss: 0.6873516413900588
Epoch: 6 | Iteration number: [2620/4518] 57% | Training loss: 0.6873526628690821
Epoch: 6 | Iteration number: [2630/4518] 58% | Training loss: 0.6873509310270897
Epoch: 6 | Iteration number: [2640/4518] 58% | Training loss: 0.6873509285350641
Epoch: 6 | Iteration number: [2650/4518] 58% | Training loss: 0.6873459302929212
Epoch: 6 | Iteration number: [2660/4518] 58% | Training loss: 0.6873463709551589
Epoch: 6 | Iteration number: [2670/4518] 59% | Training loss: 0.687347789002715
Epoch: 6 | Iteration number: [2680/4518] 59% | Training loss: 0.6873461507816813
Epoch: 6 | Iteration number: [2690/4518] 59% | Training loss: 0.6873431889319509
Epoch: 6 | Iteration number: [2700/4518] 59% | Training loss: 0.6873406277100245
Epoch: 6 | Iteration number: [2710/4518] 59% | Training loss: 0.6873403764298921
Epoch: 6 | Iteration number: [2720/4518] 60% | Training loss: 0.6873418097986894
Epoch: 6 | Iteration number: [2730/4518] 60% | Training loss: 0.6873439460228651
Epoch: 6 | Iteration number: [2740/4518] 60% | Training loss: 0.6873453337128145
Epoch: 6 | Iteration number: [2750/4518] 60% | Training loss: 0.6873415635932576
Epoch: 6 | Iteration number: [2760/4518] 61% | Training loss: 0.6873398219113764
Epoch: 6 | Iteration number: [2770/4518] 61% | Training loss: 0.6873371028297645
Epoch: 6 | Iteration number: [2780/4518] 61% | Training loss: 0.6873368686266083
Epoch: 6 | Iteration number: [2790/4518] 61% | Training loss: 0.6873310420675517
Epoch: 6 | Iteration number: [2800/4518] 61% | Training loss: 0.6873298204158034
Epoch: 6 | Iteration number: [2810/4518] 62% | Training loss: 0.6873316905464566
Epoch: 6 | Iteration number: [2820/4518] 62% | Training loss: 0.687330999378617
Epoch: 6 | Iteration number: [2830/4518] 62% | Training loss: 0.6873318928290593
Epoch: 6 | Iteration number: [2840/4518] 62% | Training loss: 0.6873300914823169
Epoch: 6 | Iteration number: [2850/4518] 63% | Training loss: 0.6873295657676562
Epoch: 6 | Iteration number: [2860/4518] 63% | Training loss: 0.6873294048167609
Epoch: 6 | Iteration number: [2870/4518] 63% | Training loss: 0.6873230009128823
Epoch: 6 | Iteration number: [2880/4518] 63% | Training loss: 0.6873282982864314
Epoch: 6 | Iteration number: [2890/4518] 63% | Training loss: 0.6873272877869722
Epoch: 6 | Iteration number: [2900/4518] 64% | Training loss: 0.6873301769125051
Epoch: 6 | Iteration number: [2910/4518] 64% | Training loss: 0.6873298396564431
Epoch: 6 | Iteration number: [2920/4518] 64% | Training loss: 0.6873257711325607
Epoch: 6 | Iteration number: [2930/4518] 64% | Training loss: 0.6873210028169912
Epoch: 6 | Iteration number: [2940/4518] 65% | Training loss: 0.6873190671813731
Epoch: 6 | Iteration number: [2950/4518] 65% | Training loss: 0.6873226705850181
Epoch: 6 | Iteration number: [2960/4518] 65% | Training loss: 0.6873248478045335
Epoch: 6 | Iteration number: [2970/4518] 65% | Training loss: 0.6873221771283583
Epoch: 6 | Iteration number: [2980/4518] 65% | Training loss: 0.6873259356957954
Epoch: 6 | Iteration number: [2990/4518] 66% | Training loss: 0.6873231656575283
Epoch: 6 | Iteration number: [3000/4518] 66% | Training loss: 0.6873230655789375
Epoch: 6 | Iteration number: [3010/4518] 66% | Training loss: 0.6873225554279315
Epoch: 6 | Iteration number: [3020/4518] 66% | Training loss: 0.6873196319831129
Epoch: 6 | Iteration number: [3030/4518] 67% | Training loss: 0.6873139371376227
Epoch: 6 | Iteration number: [3040/4518] 67% | Training loss: 0.6873124897480011
Epoch: 6 | Iteration number: [3050/4518] 67% | Training loss: 0.6873118487342459
Epoch: 6 | Iteration number: [3060/4518] 67% | Training loss: 0.6873081243505665
Epoch: 6 | Iteration number: [3070/4518] 67% | Training loss: 0.6873040764844379
Epoch: 6 | Iteration number: [3080/4518] 68% | Training loss: 0.6872979537039609
Epoch: 6 | Iteration number: [3090/4518] 68% | Training loss: 0.6872995118493015
Epoch: 6 | Iteration number: [3100/4518] 68% | Training loss: 0.6872974700120188
Epoch: 6 | Iteration number: [3110/4518] 68% | Training loss: 0.6872938456834321
Epoch: 6 | Iteration number: [3120/4518] 69% | Training loss: 0.687292833167773
Epoch: 6 | Iteration number: [3130/4518] 69% | Training loss: 0.6872930828184366
Epoch: 6 | Iteration number: [3140/4518] 69% | Training loss: 0.6872920957340556
Epoch: 6 | Iteration number: [3150/4518] 69% | Training loss: 0.6872914889880589
Epoch: 6 | Iteration number: [3160/4518] 69% | Training loss: 0.6872901314044301
Epoch: 6 | Iteration number: [3170/4518] 70% | Training loss: 0.6872856959747591
Epoch: 6 | Iteration number: [3180/4518] 70% | Training loss: 0.6872810786437689
Epoch: 6 | Iteration number: [3190/4518] 70% | Training loss: 0.687278463436892
Epoch: 6 | Iteration number: [3200/4518] 70% | Training loss: 0.6872788058407605
Epoch: 6 | Iteration number: [3210/4518] 71% | Training loss: 0.6872747496095402
Epoch: 6 | Iteration number: [3220/4518] 71% | Training loss: 0.6872724086046219
Epoch: 6 | Iteration number: [3230/4518] 71% | Training loss: 0.6872715822867934
Epoch: 6 | Iteration number: [3240/4518] 71% | Training loss: 0.6872681887245472
Epoch: 6 | Iteration number: [3250/4518] 71% | Training loss: 0.6872665283863361
Epoch: 6 | Iteration number: [3260/4518] 72% | Training loss: 0.6872654104159653
Epoch: 6 | Iteration number: [3270/4518] 72% | Training loss: 0.6872658303389126
Epoch: 6 | Iteration number: [3280/4518] 72% | Training loss: 0.6872630738085364
Epoch: 6 | Iteration number: [3290/4518] 72% | Training loss: 0.6872647750341421
Epoch: 6 | Iteration number: [3300/4518] 73% | Training loss: 0.6872621340282036
Epoch: 6 | Iteration number: [3310/4518] 73% | Training loss: 0.6872628876449839
Epoch: 6 | Iteration number: [3320/4518] 73% | Training loss: 0.6872570622398193
Epoch: 6 | Iteration number: [3330/4518] 73% | Training loss: 0.6872560699243804
Epoch: 6 | Iteration number: [3340/4518] 73% | Training loss: 0.6872596252642705
Epoch: 6 | Iteration number: [3350/4518] 74% | Training loss: 0.687258177675418
Epoch: 6 | Iteration number: [3360/4518] 74% | Training loss: 0.6872538576700857
Epoch: 6 | Iteration number: [3370/4518] 74% | Training loss: 0.6872531848420729
Epoch: 6 | Iteration number: [3380/4518] 74% | Training loss: 0.6872553419961026
Epoch: 6 | Iteration number: [3390/4518] 75% | Training loss: 0.6872589212779099
Epoch: 6 | Iteration number: [3400/4518] 75% | Training loss: 0.6872615376816077
Epoch: 6 | Iteration number: [3410/4518] 75% | Training loss: 0.6872645646246298
Epoch: 6 | Iteration number: [3420/4518] 75% | Training loss: 0.6872671114073859
Epoch: 6 | Iteration number: [3430/4518] 75% | Training loss: 0.6872668209993457
Epoch: 6 | Iteration number: [3440/4518] 76% | Training loss: 0.6872677742915098
Epoch: 6 | Iteration number: [3450/4518] 76% | Training loss: 0.6872665997346242
Epoch: 6 | Iteration number: [3460/4518] 76% | Training loss: 0.6872659126974944
Epoch: 6 | Iteration number: [3470/4518] 76% | Training loss: 0.6872630834064154
Epoch: 6 | Iteration number: [3480/4518] 77% | Training loss: 0.6872646684961757
Epoch: 6 | Iteration number: [3490/4518] 77% | Training loss: 0.6872625142592073
Epoch: 6 | Iteration number: [3500/4518] 77% | Training loss: 0.6872617597409657
Epoch: 6 | Iteration number: [3510/4518] 77% | Training loss: 0.6872596272036561
Epoch: 6 | Iteration number: [3520/4518] 77% | Training loss: 0.6872614762830463
Epoch: 6 | Iteration number: [3530/4518] 78% | Training loss: 0.6872609732171294
Epoch: 6 | Iteration number: [3540/4518] 78% | Training loss: 0.6872642927755743
Epoch: 6 | Iteration number: [3550/4518] 78% | Training loss: 0.6872662855537844
Epoch: 6 | Iteration number: [3560/4518] 78% | Training loss: 0.687267531889878
Epoch: 6 | Iteration number: [3570/4518] 79% | Training loss: 0.6872700992752524
Epoch: 6 | Iteration number: [3580/4518] 79% | Training loss: 0.6872692720184113
Epoch: 6 | Iteration number: [3590/4518] 79% | Training loss: 0.6872704046516366
Epoch: 6 | Iteration number: [3600/4518] 79% | Training loss: 0.6872680747509002
Epoch: 6 | Iteration number: [3610/4518] 79% | Training loss: 0.6872686291005142
Epoch: 6 | Iteration number: [3620/4518] 80% | Training loss: 0.6872686846974146
Epoch: 6 | Iteration number: [3630/4518] 80% | Training loss: 0.6872720097543122
Epoch: 6 | Iteration number: [3640/4518] 80% | Training loss: 0.687269761470648
Epoch: 6 | Iteration number: [3650/4518] 80% | Training loss: 0.6872692498278944
Epoch: 6 | Iteration number: [3660/4518] 81% | Training loss: 0.6872675362994762
Epoch: 6 | Iteration number: [3670/4518] 81% | Training loss: 0.6872655214178465
Epoch: 6 | Iteration number: [3680/4518] 81% | Training loss: 0.6872660458087921
Epoch: 6 | Iteration number: [3690/4518] 81% | Training loss: 0.6872686350410223
Epoch: 6 | Iteration number: [3700/4518] 81% | Training loss: 0.6872651839578474
Epoch: 6 | Iteration number: [3710/4518] 82% | Training loss: 0.6872668183235466
Epoch: 6 | Iteration number: [3720/4518] 82% | Training loss: 0.6872674864786927
Epoch: 6 | Iteration number: [3730/4518] 82% | Training loss: 0.6872654399187891
Epoch: 6 | Iteration number: [3740/4518] 82% | Training loss: 0.6872651628472588
Epoch: 6 | Iteration number: [3750/4518] 83% | Training loss: 0.6872646282196045
Epoch: 6 | Iteration number: [3760/4518] 83% | Training loss: 0.6872632135102089
Epoch: 6 | Iteration number: [3770/4518] 83% | Training loss: 0.6872597888230645
Epoch: 6 | Iteration number: [3780/4518] 83% | Training loss: 0.687256758585178
Epoch: 6 | Iteration number: [3790/4518] 83% | Training loss: 0.687257283501386
Epoch: 6 | Iteration number: [3800/4518] 84% | Training loss: 0.6872589662043672
Epoch: 6 | Iteration number: [3810/4518] 84% | Training loss: 0.6872566892719019
Epoch: 6 | Iteration number: [3820/4518] 84% | Training loss: 0.6872580005392355
Epoch: 6 | Iteration number: [3830/4518] 84% | Training loss: 0.6872600356530272
Epoch: 6 | Iteration number: [3840/4518] 84% | Training loss: 0.687258792296052
Epoch: 6 | Iteration number: [3850/4518] 85% | Training loss: 0.6872576514621833
Epoch: 6 | Iteration number: [3860/4518] 85% | Training loss: 0.6872594468951843
Epoch: 6 | Iteration number: [3870/4518] 85% | Training loss: 0.6872575436759673
Epoch: 6 | Iteration number: [3880/4518] 85% | Training loss: 0.6872566427766662
Epoch: 6 | Iteration number: [3890/4518] 86% | Training loss: 0.6872556072121108
Epoch: 6 | Iteration number: [3900/4518] 86% | Training loss: 0.6872546924994543
Epoch: 6 | Iteration number: [3910/4518] 86% | Training loss: 0.6872518477994768
Epoch: 6 | Iteration number: [3920/4518] 86% | Training loss: 0.6872512658487777
Epoch: 6 | Iteration number: [3930/4518] 86% | Training loss: 0.687252082093678
Epoch: 6 | Iteration number: [3940/4518] 87% | Training loss: 0.6872527457735865
Epoch: 6 | Iteration number: [3950/4518] 87% | Training loss: 0.6872540021093586
Epoch: 6 | Iteration number: [3960/4518] 87% | Training loss: 0.6872521490009144
Epoch: 6 | Iteration number: [3970/4518] 87% | Training loss: 0.6872507647242895
Epoch: 6 | Iteration number: [3980/4518] 88% | Training loss: 0.6872529616307973
Epoch: 6 | Iteration number: [3990/4518] 88% | Training loss: 0.6872510878812699
Epoch: 6 | Iteration number: [4000/4518] 88% | Training loss: 0.6872506565004587
Epoch: 6 | Iteration number: [4010/4518] 88% | Training loss: 0.6872494489177504
Epoch: 6 | Iteration number: [4020/4518] 88% | Training loss: 0.6872470936816724
Epoch: 6 | Iteration number: [4030/4518] 89% | Training loss: 0.6872473517659284
Epoch: 6 | Iteration number: [4040/4518] 89% | Training loss: 0.6872441291809082
Epoch: 6 | Iteration number: [4050/4518] 89% | Training loss: 0.687245035936803
Epoch: 6 | Iteration number: [4060/4518] 89% | Training loss: 0.6872449609593217
Epoch: 6 | Iteration number: [4070/4518] 90% | Training loss: 0.6872452162700438
Epoch: 6 | Iteration number: [4080/4518] 90% | Training loss: 0.6872444776635543
Epoch: 6 | Iteration number: [4090/4518] 90% | Training loss: 0.687243772412862
Epoch: 6 | Iteration number: [4100/4518] 90% | Training loss: 0.687241585472735
Epoch: 6 | Iteration number: [4110/4518] 90% | Training loss: 0.6872396864450181
Epoch: 6 | Iteration number: [4120/4518] 91% | Training loss: 0.6872392964594572
Epoch: 6 | Iteration number: [4130/4518] 91% | Training loss: 0.6872357069435766
Epoch: 6 | Iteration number: [4140/4518] 91% | Training loss: 0.6872331136522661
Epoch: 6 | Iteration number: [4150/4518] 91% | Training loss: 0.6872316419072898
Epoch: 6 | Iteration number: [4160/4518] 92% | Training loss: 0.6872324028124029
Epoch: 6 | Iteration number: [4170/4518] 92% | Training loss: 0.6872316915068409
Epoch: 6 | Iteration number: [4180/4518] 92% | Training loss: 0.6872315342916826
Epoch: 6 | Iteration number: [4190/4518] 92% | Training loss: 0.6872333136407174
Epoch: 6 | Iteration number: [4200/4518] 92% | Training loss: 0.6872318587416695
Epoch: 6 | Iteration number: [4210/4518] 93% | Training loss: 0.6872364879079216
Epoch: 6 | Iteration number: [4220/4518] 93% | Training loss: 0.6872338607695431
Epoch: 6 | Iteration number: [4230/4518] 93% | Training loss: 0.6872346499005672
Epoch: 6 | Iteration number: [4240/4518] 93% | Training loss: 0.6872359545866273
Epoch: 6 | Iteration number: [4250/4518] 94% | Training loss: 0.6872362901603475
Epoch: 6 | Iteration number: [4260/4518] 94% | Training loss: 0.6872368430867442
Epoch: 6 | Iteration number: [4270/4518] 94% | Training loss: 0.6872362898021448
Epoch: 6 | Iteration number: [4280/4518] 94% | Training loss: 0.6872369782250618
Epoch: 6 | Iteration number: [4290/4518] 94% | Training loss: 0.6872340035605264
Epoch: 6 | Iteration number: [4300/4518] 95% | Training loss: 0.6872310228125994
Epoch: 6 | Iteration number: [4310/4518] 95% | Training loss: 0.6872280294408378
Epoch: 6 | Iteration number: [4320/4518] 95% | Training loss: 0.6872285583228976
Epoch: 6 | Iteration number: [4330/4518] 95% | Training loss: 0.6872279168001223
Epoch: 6 | Iteration number: [4340/4518] 96% | Training loss: 0.6872290475302577
Epoch: 6 | Iteration number: [4350/4518] 96% | Training loss: 0.6872314375296407
Epoch: 6 | Iteration number: [4360/4518] 96% | Training loss: 0.6872284672675877
Epoch: 6 | Iteration number: [4370/4518] 96% | Training loss: 0.6872268230336754
Epoch: 6 | Iteration number: [4380/4518] 96% | Training loss: 0.6872258244720224
Epoch: 6 | Iteration number: [4390/4518] 97% | Training loss: 0.6872284394597681
Epoch: 6 | Iteration number: [4400/4518] 97% | Training loss: 0.6872273257374764
Epoch: 6 | Iteration number: [4410/4518] 97% | Training loss: 0.6872286577884302
Epoch: 6 | Iteration number: [4420/4518] 97% | Training loss: 0.687230107579296
Epoch: 6 | Iteration number: [4430/4518] 98% | Training loss: 0.6872311074766025
Epoch: 6 | Iteration number: [4440/4518] 98% | Training loss: 0.6872305961342545
Epoch: 6 | Iteration number: [4450/4518] 98% | Training loss: 0.6872310795944728
Epoch: 6 | Iteration number: [4460/4518] 98% | Training loss: 0.6872301639195515
Epoch: 6 | Iteration number: [4470/4518] 98% | Training loss: 0.6872281784712602
Epoch: 6 | Iteration number: [4480/4518] 99% | Training loss: 0.6872282691566007
Epoch: 6 | Iteration number: [4490/4518] 99% | Training loss: 0.6872268271738278
Epoch: 6 | Iteration number: [4500/4518] 99% | Training loss: 0.6872263339360555
Epoch: 6 | Iteration number: [4510/4518] 99% | Training loss: 0.6872288336114185

 End of epoch: 6 | Train Loss: 0.6870750818251508 | Training Time: 638 

 End of epoch: 6 | Eval Loss: 0.690123227177834 | Evaluating Time: 17 
Epoch: 7 | Iteration number: [10/4518] 0% | Training loss: 0.7562526106834412
Epoch: 7 | Iteration number: [20/4518] 0% | Training loss: 0.7225509613752366
Epoch: 7 | Iteration number: [30/4518] 0% | Training loss: 0.7108155469099681
Epoch: 7 | Iteration number: [40/4518] 0% | Training loss: 0.7047542497515679
Epoch: 7 | Iteration number: [50/4518] 1% | Training loss: 0.7009341931343078
Epoch: 7 | Iteration number: [60/4518] 1% | Training loss: 0.6985949059327443
Epoch: 7 | Iteration number: [70/4518] 1% | Training loss: 0.6968680960791451
Epoch: 7 | Iteration number: [80/4518] 1% | Training loss: 0.6955354265868664
Epoch: 7 | Iteration number: [90/4518] 1% | Training loss: 0.6944828338093227
Epoch: 7 | Iteration number: [100/4518] 2% | Training loss: 0.6937259197235107
Epoch: 7 | Iteration number: [110/4518] 2% | Training loss: 0.693065077608282
Epoch: 7 | Iteration number: [120/4518] 2% | Training loss: 0.692599430680275
Epoch: 7 | Iteration number: [130/4518] 2% | Training loss: 0.6922285442168896
Epoch: 7 | Iteration number: [140/4518] 3% | Training loss: 0.6917859443596431
Epoch: 7 | Iteration number: [150/4518] 3% | Training loss: 0.6914210442701976
Epoch: 7 | Iteration number: [160/4518] 3% | Training loss: 0.6911352898925542
Epoch: 7 | Iteration number: [170/4518] 3% | Training loss: 0.690842485778472
Epoch: 7 | Iteration number: [180/4518] 3% | Training loss: 0.6907000925805834
Epoch: 7 | Iteration number: [190/4518] 4% | Training loss: 0.6905260346437755
Epoch: 7 | Iteration number: [200/4518] 4% | Training loss: 0.6903100517392159
Epoch: 7 | Iteration number: [210/4518] 4% | Training loss: 0.6901784025487445
Epoch: 7 | Iteration number: [220/4518] 4% | Training loss: 0.6900271036408164
Epoch: 7 | Iteration number: [230/4518] 5% | Training loss: 0.6899479702762935
Epoch: 7 | Iteration number: [240/4518] 5% | Training loss: 0.6898737070461114
Epoch: 7 | Iteration number: [250/4518] 5% | Training loss: 0.689774915933609
Epoch: 7 | Iteration number: [260/4518] 5% | Training loss: 0.689663757956945
Epoch: 7 | Iteration number: [270/4518] 5% | Training loss: 0.6895695249239604
Epoch: 7 | Iteration number: [280/4518] 6% | Training loss: 0.689472364953586
Epoch: 7 | Iteration number: [290/4518] 6% | Training loss: 0.6893967799071608
Epoch: 7 | Iteration number: [300/4518] 6% | Training loss: 0.6893344513575236
Epoch: 7 | Iteration number: [310/4518] 6% | Training loss: 0.6892762137997535
Epoch: 7 | Iteration number: [320/4518] 7% | Training loss: 0.6891950061544776
Epoch: 7 | Iteration number: [330/4518] 7% | Training loss: 0.6891656861160741
Epoch: 7 | Iteration number: [340/4518] 7% | Training loss: 0.6890613301711924
Epoch: 7 | Iteration number: [350/4518] 7% | Training loss: 0.6889619958400727
Epoch: 7 | Iteration number: [360/4518] 7% | Training loss: 0.6888857237166829
Epoch: 7 | Iteration number: [370/4518] 8% | Training loss: 0.6888334678637015
Epoch: 7 | Iteration number: [380/4518] 8% | Training loss: 0.6887687590561415
Epoch: 7 | Iteration number: [390/4518] 8% | Training loss: 0.6887187670438718
Epoch: 7 | Iteration number: [400/4518] 8% | Training loss: 0.6886917316913604
Epoch: 7 | Iteration number: [410/4518] 9% | Training loss: 0.6886882388010258
Epoch: 7 | Iteration number: [420/4518] 9% | Training loss: 0.6886594383489518
Epoch: 7 | Iteration number: [430/4518] 9% | Training loss: 0.6886298882406812
Epoch: 7 | Iteration number: [440/4518] 9% | Training loss: 0.6885916342789477
Epoch: 7 | Iteration number: [450/4518] 9% | Training loss: 0.6885533146063487
Epoch: 7 | Iteration number: [460/4518] 10% | Training loss: 0.6884825710369193
Epoch: 7 | Iteration number: [470/4518] 10% | Training loss: 0.6884318420227538
Epoch: 7 | Iteration number: [480/4518] 10% | Training loss: 0.6883916225284338
Epoch: 7 | Iteration number: [490/4518] 10% | Training loss: 0.6883609294891357
Epoch: 7 | Iteration number: [500/4518] 11% | Training loss: 0.6883253623247146
Epoch: 7 | Iteration number: [510/4518] 11% | Training loss: 0.6883117428012923
Epoch: 7 | Iteration number: [520/4518] 11% | Training loss: 0.6882603170780035
Epoch: 7 | Iteration number: [530/4518] 11% | Training loss: 0.6882051675949457
Epoch: 7 | Iteration number: [540/4518] 11% | Training loss: 0.6882072493985847
Epoch: 7 | Iteration number: [550/4518] 12% | Training loss: 0.6882007799365304
Epoch: 7 | Iteration number: [560/4518] 12% | Training loss: 0.6881676483367171
Epoch: 7 | Iteration number: [570/4518] 12% | Training loss: 0.6881389215327146
Epoch: 7 | Iteration number: [580/4518] 12% | Training loss: 0.6881181212334797
Epoch: 7 | Iteration number: [590/4518] 13% | Training loss: 0.6881035364280312
Epoch: 7 | Iteration number: [600/4518] 13% | Training loss: 0.6880872884392738
Epoch: 7 | Iteration number: [610/4518] 13% | Training loss: 0.6880639217916082
Epoch: 7 | Iteration number: [620/4518] 13% | Training loss: 0.6880388025314578
Epoch: 7 | Iteration number: [630/4518] 13% | Training loss: 0.6879945261137826
Epoch: 7 | Iteration number: [640/4518] 14% | Training loss: 0.687958178948611
Epoch: 7 | Iteration number: [650/4518] 14% | Training loss: 0.687946984217717
Epoch: 7 | Iteration number: [660/4518] 14% | Training loss: 0.687937404531421
Epoch: 7 | Iteration number: [670/4518] 14% | Training loss: 0.6879211399092603
Epoch: 7 | Iteration number: [680/4518] 15% | Training loss: 0.6879249780493624
Epoch: 7 | Iteration number: [690/4518] 15% | Training loss: 0.6879140904848127
Epoch: 7 | Iteration number: [700/4518] 15% | Training loss: 0.6878943338564464
Epoch: 7 | Iteration number: [710/4518] 15% | Training loss: 0.6878857474092027
Epoch: 7 | Iteration number: [720/4518] 15% | Training loss: 0.6878659331964122
Epoch: 7 | Iteration number: [730/4518] 16% | Training loss: 0.6878459237209739
Epoch: 7 | Iteration number: [740/4518] 16% | Training loss: 0.6878340755765503
Epoch: 7 | Iteration number: [750/4518] 16% | Training loss: 0.6878307392597198
Epoch: 7 | Iteration number: [760/4518] 16% | Training loss: 0.6878120165122182
Epoch: 7 | Iteration number: [770/4518] 17% | Training loss: 0.687804837660356
Epoch: 7 | Iteration number: [780/4518] 17% | Training loss: 0.6878201779646751
Epoch: 7 | Iteration number: [790/4518] 17% | Training loss: 0.6878001537504076
Epoch: 7 | Iteration number: [800/4518] 17% | Training loss: 0.6877739585191012
Epoch: 7 | Iteration number: [810/4518] 17% | Training loss: 0.687769364942739
Epoch: 7 | Iteration number: [820/4518] 18% | Training loss: 0.6877500387226663
Epoch: 7 | Iteration number: [830/4518] 18% | Training loss: 0.6877277096351945
Epoch: 7 | Iteration number: [840/4518] 18% | Training loss: 0.6877196326142265
Epoch: 7 | Iteration number: [850/4518] 18% | Training loss: 0.687714601614896
Epoch: 7 | Iteration number: [860/4518] 19% | Training loss: 0.6877002528240515
Epoch: 7 | Iteration number: [870/4518] 19% | Training loss: 0.6876872020206232
Epoch: 7 | Iteration number: [880/4518] 19% | Training loss: 0.6876940661533313
Epoch: 7 | Iteration number: [890/4518] 19% | Training loss: 0.6876725853159187
Epoch: 7 | Iteration number: [900/4518] 19% | Training loss: 0.687672575712204
Epoch: 7 | Iteration number: [910/4518] 20% | Training loss: 0.6876758401210491
Epoch: 7 | Iteration number: [920/4518] 20% | Training loss: 0.6876713327091674
Epoch: 7 | Iteration number: [930/4518] 20% | Training loss: 0.6876753961527219
Epoch: 7 | Iteration number: [940/4518] 20% | Training loss: 0.6876602352299589
Epoch: 7 | Iteration number: [950/4518] 21% | Training loss: 0.6876567396992131
Epoch: 7 | Iteration number: [960/4518] 21% | Training loss: 0.6876405304297805
Epoch: 7 | Iteration number: [970/4518] 21% | Training loss: 0.6876246666785368
Epoch: 7 | Iteration number: [980/4518] 21% | Training loss: 0.6876086665051324
Epoch: 7 | Iteration number: [990/4518] 21% | Training loss: 0.6876128782527615
Epoch: 7 | Iteration number: [1000/4518] 22% | Training loss: 0.6876063640117646
Epoch: 7 | Iteration number: [1010/4518] 22% | Training loss: 0.6876065089560971
Epoch: 7 | Iteration number: [1020/4518] 22% | Training loss: 0.6876064745818867
Epoch: 7 | Iteration number: [1030/4518] 22% | Training loss: 0.6876148870269072
Epoch: 7 | Iteration number: [1040/4518] 23% | Training loss: 0.6876132583962037
Epoch: 7 | Iteration number: [1050/4518] 23% | Training loss: 0.6876150086380186
Epoch: 7 | Iteration number: [1060/4518] 23% | Training loss: 0.6876150224006401
Epoch: 7 | Iteration number: [1070/4518] 23% | Training loss: 0.6876005427859654
Epoch: 7 | Iteration number: [1080/4518] 23% | Training loss: 0.6876015372850277
Epoch: 7 | Iteration number: [1090/4518] 24% | Training loss: 0.6876032126059226
Epoch: 7 | Iteration number: [1100/4518] 24% | Training loss: 0.6875948839295994
Epoch: 7 | Iteration number: [1110/4518] 24% | Training loss: 0.6876014149403787
Epoch: 7 | Iteration number: [1120/4518] 24% | Training loss: 0.6875993401344334
Epoch: 7 | Iteration number: [1130/4518] 25% | Training loss: 0.6875870200385035
Epoch: 7 | Iteration number: [1140/4518] 25% | Training loss: 0.6875839731672354
Epoch: 7 | Iteration number: [1150/4518] 25% | Training loss: 0.6875871583171512
Epoch: 7 | Iteration number: [1160/4518] 25% | Training loss: 0.6875775678404447
Epoch: 7 | Iteration number: [1170/4518] 25% | Training loss: 0.6875702834027445
Epoch: 7 | Iteration number: [1180/4518] 26% | Training loss: 0.6875724723783591
Epoch: 7 | Iteration number: [1190/4518] 26% | Training loss: 0.6875658798618477
Epoch: 7 | Iteration number: [1200/4518] 26% | Training loss: 0.6875644278526306
Epoch: 7 | Iteration number: [1210/4518] 26% | Training loss: 0.6875582747222964
Epoch: 7 | Iteration number: [1220/4518] 27% | Training loss: 0.6875661122994344
Epoch: 7 | Iteration number: [1230/4518] 27% | Training loss: 0.6875669013678543
Epoch: 7 | Iteration number: [1240/4518] 27% | Training loss: 0.687567978857025
Epoch: 7 | Iteration number: [1250/4518] 27% | Training loss: 0.6875600555896759
Epoch: 7 | Iteration number: [1260/4518] 27% | Training loss: 0.6875565916772872
Epoch: 7 | Iteration number: [1270/4518] 28% | Training loss: 0.6875447754315503
Epoch: 7 | Iteration number: [1280/4518] 28% | Training loss: 0.6875324131920934
Epoch: 7 | Iteration number: [1290/4518] 28% | Training loss: 0.6875281801057417
Epoch: 7 | Iteration number: [1300/4518] 28% | Training loss: 0.6875218073679851
Epoch: 7 | Iteration number: [1310/4518] 28% | Training loss: 0.6875202047005865
Epoch: 7 | Iteration number: [1320/4518] 29% | Training loss: 0.6875173300053135
Epoch: 7 | Iteration number: [1330/4518] 29% | Training loss: 0.6875252835732654
Epoch: 7 | Iteration number: [1340/4518] 29% | Training loss: 0.6875228711918219
Epoch: 7 | Iteration number: [1350/4518] 29% | Training loss: 0.6875221317344241
Epoch: 7 | Iteration number: [1360/4518] 30% | Training loss: 0.6875259270124575
Epoch: 7 | Iteration number: [1370/4518] 30% | Training loss: 0.6875214484051196
Epoch: 7 | Iteration number: [1380/4518] 30% | Training loss: 0.6875189726335414
Epoch: 7 | Iteration number: [1390/4518] 30% | Training loss: 0.6875058961857995
Epoch: 7 | Iteration number: [1400/4518] 30% | Training loss: 0.687499882195677
Epoch: 7 | Iteration number: [1410/4518] 31% | Training loss: 0.6874970889683311
Epoch: 7 | Iteration number: [1420/4518] 31% | Training loss: 0.6874869543901632
Epoch: 7 | Iteration number: [1430/4518] 31% | Training loss: 0.6874831627298902
Epoch: 7 | Iteration number: [1440/4518] 31% | Training loss: 0.6874723082615269
Epoch: 7 | Iteration number: [1450/4518] 32% | Training loss: 0.6874669156814444
Epoch: 7 | Iteration number: [1460/4518] 32% | Training loss: 0.6874706265044539
Epoch: 7 | Iteration number: [1470/4518] 32% | Training loss: 0.6874560509814697
Epoch: 7 | Iteration number: [1480/4518] 32% | Training loss: 0.6874616050236934
Epoch: 7 | Iteration number: [1490/4518] 32% | Training loss: 0.6874573668377512
Epoch: 7 | Iteration number: [1500/4518] 33% | Training loss: 0.6874516936937968
Epoch: 7 | Iteration number: [1510/4518] 33% | Training loss: 0.6874578590819378
Epoch: 7 | Iteration number: [1520/4518] 33% | Training loss: 0.6874594789978705
Epoch: 7 | Iteration number: [1530/4518] 33% | Training loss: 0.6874467615598168
Epoch: 7 | Iteration number: [1540/4518] 34% | Training loss: 0.6874434061638721
Epoch: 7 | Iteration number: [1550/4518] 34% | Training loss: 0.6874462642592769
Epoch: 7 | Iteration number: [1560/4518] 34% | Training loss: 0.6874484537121577
Epoch: 7 | Iteration number: [1570/4518] 34% | Training loss: 0.687446960977688
Epoch: 7 | Iteration number: [1580/4518] 34% | Training loss: 0.6874424811782717
Epoch: 7 | Iteration number: [1590/4518] 35% | Training loss: 0.6874342170901269
Epoch: 7 | Iteration number: [1600/4518] 35% | Training loss: 0.687432946190238
Epoch: 7 | Iteration number: [1610/4518] 35% | Training loss: 0.6874383869378463
Epoch: 7 | Iteration number: [1620/4518] 35% | Training loss: 0.6874273949567182
Epoch: 7 | Iteration number: [1630/4518] 36% | Training loss: 0.687427788204942
Epoch: 7 | Iteration number: [1640/4518] 36% | Training loss: 0.6874191906394028
Epoch: 7 | Iteration number: [1650/4518] 36% | Training loss: 0.687414790428046
Epoch: 7 | Iteration number: [1660/4518] 36% | Training loss: 0.6874116479632366
Epoch: 7 | Iteration number: [1670/4518] 36% | Training loss: 0.6874222677267954
Epoch: 7 | Iteration number: [1680/4518] 37% | Training loss: 0.6874171601519699
Epoch: 7 | Iteration number: [1690/4518] 37% | Training loss: 0.6874202982561123
Epoch: 7 | Iteration number: [1700/4518] 37% | Training loss: 0.6874202094358557
Epoch: 7 | Iteration number: [1710/4518] 37% | Training loss: 0.6874172325719867
Epoch: 7 | Iteration number: [1720/4518] 38% | Training loss: 0.6874122563489647
Epoch: 7 | Iteration number: [1730/4518] 38% | Training loss: 0.6874121992574261
Epoch: 7 | Iteration number: [1740/4518] 38% | Training loss: 0.6874129397773194
Epoch: 7 | Iteration number: [1750/4518] 38% | Training loss: 0.6874125182628632
Epoch: 7 | Iteration number: [1760/4518] 38% | Training loss: 0.687408291480758
Epoch: 7 | Iteration number: [1770/4518] 39% | Training loss: 0.6874029785226294
Epoch: 7 | Iteration number: [1780/4518] 39% | Training loss: 0.687398906805542
Epoch: 7 | Iteration number: [1790/4518] 39% | Training loss: 0.687398288769429
Epoch: 7 | Iteration number: [1800/4518] 39% | Training loss: 0.6873939339651002
Epoch: 7 | Iteration number: [1810/4518] 40% | Training loss: 0.6873853287644149
Epoch: 7 | Iteration number: [1820/4518] 40% | Training loss: 0.6873837574170186
Epoch: 7 | Iteration number: [1830/4518] 40% | Training loss: 0.6873746305215555
Epoch: 7 | Iteration number: [1840/4518] 40% | Training loss: 0.687369842082262
Epoch: 7 | Iteration number: [1850/4518] 40% | Training loss: 0.6873710568853326
Epoch: 7 | Iteration number: [1860/4518] 41% | Training loss: 0.6873734181606641
Epoch: 7 | Iteration number: [1870/4518] 41% | Training loss: 0.6873789845622159
Epoch: 7 | Iteration number: [1880/4518] 41% | Training loss: 0.6873796734404056
Epoch: 7 | Iteration number: [1890/4518] 41% | Training loss: 0.687378799221503
Epoch: 7 | Iteration number: [1900/4518] 42% | Training loss: 0.6873732684787951
Epoch: 7 | Iteration number: [1910/4518] 42% | Training loss: 0.687371733706659
Epoch: 7 | Iteration number: [1920/4518] 42% | Training loss: 0.6873672805105646
Epoch: 7 | Iteration number: [1930/4518] 42% | Training loss: 0.6873628272602595
Epoch: 7 | Iteration number: [1940/4518] 42% | Training loss: 0.6873626481933692
Epoch: 7 | Iteration number: [1950/4518] 43% | Training loss: 0.687361862384356
Epoch: 7 | Iteration number: [1960/4518] 43% | Training loss: 0.6873578081629714
Epoch: 7 | Iteration number: [1970/4518] 43% | Training loss: 0.6873544212827828
Epoch: 7 | Iteration number: [1980/4518] 43% | Training loss: 0.6873568795546137
Epoch: 7 | Iteration number: [1990/4518] 44% | Training loss: 0.6873536114417129
Epoch: 7 | Iteration number: [2000/4518] 44% | Training loss: 0.6873563549816608
Epoch: 7 | Iteration number: [2010/4518] 44% | Training loss: 0.6873511928230969
Epoch: 7 | Iteration number: [2020/4518] 44% | Training loss: 0.687352517011142
Epoch: 7 | Iteration number: [2030/4518] 44% | Training loss: 0.6873502644412036
Epoch: 7 | Iteration number: [2040/4518] 45% | Training loss: 0.6873491271453745
Epoch: 7 | Iteration number: [2050/4518] 45% | Training loss: 0.6873496639147038
Epoch: 7 | Iteration number: [2060/4518] 45% | Training loss: 0.6873510173512895
Epoch: 7 | Iteration number: [2070/4518] 45% | Training loss: 0.6873541523868911
Epoch: 7 | Iteration number: [2080/4518] 46% | Training loss: 0.6873501217995699
Epoch: 7 | Iteration number: [2090/4518] 46% | Training loss: 0.6873520706544082
Epoch: 7 | Iteration number: [2100/4518] 46% | Training loss: 0.6873431846925191
Epoch: 7 | Iteration number: [2110/4518] 46% | Training loss: 0.6873421731153371
Epoch: 7 | Iteration number: [2120/4518] 46% | Training loss: 0.6873400179844982
Epoch: 7 | Iteration number: [2130/4518] 47% | Training loss: 0.6873436211980005
Epoch: 7 | Iteration number: [2140/4518] 47% | Training loss: 0.6873407886964138
Epoch: 7 | Iteration number: [2150/4518] 47% | Training loss: 0.6873423424432444
Epoch: 7 | Iteration number: [2160/4518] 47% | Training loss: 0.6873417783114645
Epoch: 7 | Iteration number: [2170/4518] 48% | Training loss: 0.6873470142415042
Epoch: 7 | Iteration number: [2180/4518] 48% | Training loss: 0.6873449309976822
Epoch: 7 | Iteration number: [2190/4518] 48% | Training loss: 0.68734435929011
Epoch: 7 | Iteration number: [2200/4518] 48% | Training loss: 0.6873454882339998
Epoch: 7 | Iteration number: [2210/4518] 48% | Training loss: 0.6873457059871018
Epoch: 7 | Iteration number: [2220/4518] 49% | Training loss: 0.6873386310832994
Epoch: 7 | Iteration number: [2230/4518] 49% | Training loss: 0.6873376998666156
Epoch: 7 | Iteration number: [2240/4518] 49% | Training loss: 0.6873363331758551
Epoch: 7 | Iteration number: [2250/4518] 49% | Training loss: 0.6873320700327555
Epoch: 7 | Iteration number: [2260/4518] 50% | Training loss: 0.6873315171857851
Epoch: 7 | Iteration number: [2270/4518] 50% | Training loss: 0.6873287087495107
Epoch: 7 | Iteration number: [2280/4518] 50% | Training loss: 0.6873291567490812
Epoch: 7 | Iteration number: [2290/4518] 50% | Training loss: 0.6873310217951063
Epoch: 7 | Iteration number: [2300/4518] 50% | Training loss: 0.6873335918395416
Epoch: 7 | Iteration number: [2310/4518] 51% | Training loss: 0.6873355444117542
Epoch: 7 | Iteration number: [2320/4518] 51% | Training loss: 0.6873313181359192
Epoch: 7 | Iteration number: [2330/4518] 51% | Training loss: 0.6873238244281817
Epoch: 7 | Iteration number: [2340/4518] 51% | Training loss: 0.6873227714473366
Epoch: 7 | Iteration number: [2350/4518] 52% | Training loss: 0.6873231527906783
Epoch: 7 | Iteration number: [2360/4518] 52% | Training loss: 0.6873191104602006
Epoch: 7 | Iteration number: [2370/4518] 52% | Training loss: 0.6873154064271018
Epoch: 7 | Iteration number: [2380/4518] 52% | Training loss: 0.6873174647824103
Epoch: 7 | Iteration number: [2390/4518] 52% | Training loss: 0.6873163317287317
Epoch: 7 | Iteration number: [2400/4518] 53% | Training loss: 0.6873137581845125
Epoch: 7 | Iteration number: [2410/4518] 53% | Training loss: 0.6873135918403562
Epoch: 7 | Iteration number: [2420/4518] 53% | Training loss: 0.6873146013287473
Epoch: 7 | Iteration number: [2430/4518] 53% | Training loss: 0.6873140911997101
Epoch: 7 | Iteration number: [2440/4518] 54% | Training loss: 0.6873128168895596
Epoch: 7 | Iteration number: [2450/4518] 54% | Training loss: 0.6873103234962541
Epoch: 7 | Iteration number: [2460/4518] 54% | Training loss: 0.6873159663221701
Epoch: 7 | Iteration number: [2470/4518] 54% | Training loss: 0.6873158336409673
Epoch: 7 | Iteration number: [2480/4518] 54% | Training loss: 0.6873120699678698
Epoch: 7 | Iteration number: [2490/4518] 55% | Training loss: 0.6873073298768346
Epoch: 7 | Iteration number: [2500/4518] 55% | Training loss: 0.6873071819067001
Epoch: 7 | Iteration number: [2510/4518] 55% | Training loss: 0.6873089866334223
Epoch: 7 | Iteration number: [2520/4518] 55% | Training loss: 0.6873112656767406
Epoch: 7 | Iteration number: [2530/4518] 55% | Training loss: 0.6873071061057064
Epoch: 7 | Iteration number: [2540/4518] 56% | Training loss: 0.6873057811044333
Epoch: 7 | Iteration number: [2550/4518] 56% | Training loss: 0.6873066305412966
Epoch: 7 | Iteration number: [2560/4518] 56% | Training loss: 0.6873133568326011
Epoch: 7 | Iteration number: [2570/4518] 56% | Training loss: 0.6873135981624693
Epoch: 7 | Iteration number: [2580/4518] 57% | Training loss: 0.6873132013073263
Epoch: 7 | Iteration number: [2590/4518] 57% | Training loss: 0.6873109074633094
Epoch: 7 | Iteration number: [2600/4518] 57% | Training loss: 0.6873102102600611
Epoch: 7 | Iteration number: [2610/4518] 57% | Training loss: 0.687309562657528
Epoch: 7 | Iteration number: [2620/4518] 57% | Training loss: 0.6873078098506418
Epoch: 7 | Iteration number: [2630/4518] 58% | Training loss: 0.6873078876575136
Epoch: 7 | Iteration number: [2640/4518] 58% | Training loss: 0.6873044746617476
Epoch: 7 | Iteration number: [2650/4518] 58% | Training loss: 0.6873035065632946
Epoch: 7 | Iteration number: [2660/4518] 58% | Training loss: 0.6873027075726287
Epoch: 7 | Iteration number: [2670/4518] 59% | Training loss: 0.6873042951808886
Epoch: 7 | Iteration number: [2680/4518] 59% | Training loss: 0.6873017632249576
Epoch: 7 | Iteration number: [2690/4518] 59% | Training loss: 0.6872977201823408
Epoch: 7 | Iteration number: [2700/4518] 59% | Training loss: 0.687304274506039
Epoch: 7 | Iteration number: [2710/4518] 59% | Training loss: 0.6873050194384867
Epoch: 7 | Iteration number: [2720/4518] 60% | Training loss: 0.6873033522683032
Epoch: 7 | Iteration number: [2730/4518] 60% | Training loss: 0.6873014529764434
Epoch: 7 | Iteration number: [2740/4518] 60% | Training loss: 0.6873002888512437
Epoch: 7 | Iteration number: [2750/4518] 60% | Training loss: 0.6873014093312351
Epoch: 7 | Iteration number: [2760/4518] 61% | Training loss: 0.6873032280716344
Epoch: 7 | Iteration number: [2770/4518] 61% | Training loss: 0.6872989200728035
Epoch: 7 | Iteration number: [2780/4518] 61% | Training loss: 0.6872984109379405
Epoch: 7 | Iteration number: [2790/4518] 61% | Training loss: 0.687294469212973
Epoch: 7 | Iteration number: [2800/4518] 61% | Training loss: 0.6872952738404274
Epoch: 7 | Iteration number: [2810/4518] 62% | Training loss: 0.6872966261945161
Epoch: 7 | Iteration number: [2820/4518] 62% | Training loss: 0.6872951477343309
Epoch: 7 | Iteration number: [2830/4518] 62% | Training loss: 0.6873011676877632
Epoch: 7 | Iteration number: [2840/4518] 62% | Training loss: 0.6873007675921413
Epoch: 7 | Iteration number: [2850/4518] 63% | Training loss: 0.6872999405651762
Epoch: 7 | Iteration number: [2860/4518] 63% | Training loss: 0.6873027202132699
Epoch: 7 | Iteration number: [2870/4518] 63% | Training loss: 0.687302724554979
Epoch: 7 | Iteration number: [2880/4518] 63% | Training loss: 0.68730085167206
Epoch: 7 | Iteration number: [2890/4518] 63% | Training loss: 0.6873008005140562
Epoch: 7 | Iteration number: [2900/4518] 64% | Training loss: 0.6872985632460693
Epoch: 7 | Iteration number: [2910/4518] 64% | Training loss: 0.6873010180455302
Epoch: 7 | Iteration number: [2920/4518] 64% | Training loss: 0.6873035875493533
Epoch: 7 | Iteration number: [2930/4518] 64% | Training loss: 0.6873072122957926
Epoch: 7 | Iteration number: [2940/4518] 65% | Training loss: 0.6873094660287
Epoch: 7 | Iteration number: [2950/4518] 65% | Training loss: 0.687307079101013
Epoch: 7 | Iteration number: [2960/4518] 65% | Training loss: 0.68730496202369
Epoch: 7 | Iteration number: [2970/4518] 65% | Training loss: 0.6873019718160533
Epoch: 7 | Iteration number: [2980/4518] 65% | Training loss: 0.6873007524333544
Epoch: 7 | Iteration number: [2990/4518] 66% | Training loss: 0.6873025130268722
Epoch: 7 | Iteration number: [3000/4518] 66% | Training loss: 0.6873013301889102
Epoch: 7 | Iteration number: [3010/4518] 66% | Training loss: 0.6872992981509909
Epoch: 7 | Iteration number: [3020/4518] 66% | Training loss: 0.6872984683671535
Epoch: 7 | Iteration number: [3030/4518] 67% | Training loss: 0.687292479524518
Epoch: 7 | Iteration number: [3040/4518] 67% | Training loss: 0.6872909321204612
Epoch: 7 | Iteration number: [3050/4518] 67% | Training loss: 0.687291145129282
Epoch: 7 | Iteration number: [3060/4518] 67% | Training loss: 0.6872860016386494
Epoch: 7 | Iteration number: [3070/4518] 67% | Training loss: 0.6872860577867551
Epoch: 7 | Iteration number: [3080/4518] 68% | Training loss: 0.6872866679128115
Epoch: 7 | Iteration number: [3090/4518] 68% | Training loss: 0.6872808522776879
Epoch: 7 | Iteration number: [3100/4518] 68% | Training loss: 0.6872810427219637
Epoch: 7 | Iteration number: [3110/4518] 68% | Training loss: 0.687280241220327
Epoch: 7 | Iteration number: [3120/4518] 69% | Training loss: 0.6872812870794381
Epoch: 7 | Iteration number: [3130/4518] 69% | Training loss: 0.6872809887122803
Epoch: 7 | Iteration number: [3140/4518] 69% | Training loss: 0.6872857195176896
Epoch: 7 | Iteration number: [3150/4518] 69% | Training loss: 0.6872824981666746
Epoch: 7 | Iteration number: [3160/4518] 69% | Training loss: 0.6872801975736135
Epoch: 7 | Iteration number: [3170/4518] 70% | Training loss: 0.6872762722735901
Epoch: 7 | Iteration number: [3180/4518] 70% | Training loss: 0.6872759055041667
Epoch: 7 | Iteration number: [3190/4518] 70% | Training loss: 0.6872752685905624
Epoch: 7 | Iteration number: [3200/4518] 70% | Training loss: 0.6872768555395306
Epoch: 7 | Iteration number: [3210/4518] 71% | Training loss: 0.6872777158411864
Epoch: 7 | Iteration number: [3220/4518] 71% | Training loss: 0.687276340512015
Epoch: 7 | Iteration number: [3230/4518] 71% | Training loss: 0.6872736533175312
Epoch: 7 | Iteration number: [3240/4518] 71% | Training loss: 0.6872725993762782
Epoch: 7 | Iteration number: [3250/4518] 71% | Training loss: 0.6872702109630291
Epoch: 7 | Iteration number: [3260/4518] 72% | Training loss: 0.6872682786609497
Epoch: 7 | Iteration number: [3270/4518] 72% | Training loss: 0.6872695121378709
Epoch: 7 | Iteration number: [3280/4518] 72% | Training loss: 0.687268894620058
Epoch: 7 | Iteration number: [3290/4518] 72% | Training loss: 0.6872710795569202
Epoch: 7 | Iteration number: [3300/4518] 73% | Training loss: 0.6872679672638575
Epoch: 7 | Iteration number: [3310/4518] 73% | Training loss: 0.687266765332294
Epoch: 7 | Iteration number: [3320/4518] 73% | Training loss: 0.687263859718679
Epoch: 7 | Iteration number: [3330/4518] 73% | Training loss: 0.6872600261155549
Epoch: 7 | Iteration number: [3340/4518] 73% | Training loss: 0.6872574303321496
Epoch: 7 | Iteration number: [3350/4518] 74% | Training loss: 0.6872575166154263
Epoch: 7 | Iteration number: [3360/4518] 74% | Training loss: 0.6872578844428062
Epoch: 7 | Iteration number: [3370/4518] 74% | Training loss: 0.6872574945055059
Epoch: 7 | Iteration number: [3380/4518] 74% | Training loss: 0.6872543990435684
Epoch: 7 | Iteration number: [3390/4518] 75% | Training loss: 0.6872510005942488
Epoch: 7 | Iteration number: [3400/4518] 75% | Training loss: 0.6872528359995169
Epoch: 7 | Iteration number: [3410/4518] 75% | Training loss: 0.6872531342366573
Epoch: 7 | Iteration number: [3420/4518] 75% | Training loss: 0.6872534522710488
Epoch: 7 | Iteration number: [3430/4518] 75% | Training loss: 0.6872516780309705
Epoch: 7 | Iteration number: [3440/4518] 76% | Training loss: 0.6872511222092218
Epoch: 7 | Iteration number: [3450/4518] 76% | Training loss: 0.6872502328001935
Epoch: 7 | Iteration number: [3460/4518] 76% | Training loss: 0.6872488010136378
Epoch: 7 | Iteration number: [3470/4518] 76% | Training loss: 0.6872478311103084
Epoch: 7 | Iteration number: [3480/4518] 77% | Training loss: 0.6872465686380178
Epoch: 7 | Iteration number: [3490/4518] 77% | Training loss: 0.6872409810138637
Epoch: 7 | Iteration number: [3500/4518] 77% | Training loss: 0.6872383345024926
Epoch: 7 | Iteration number: [3510/4518] 77% | Training loss: 0.6872376817583699
Epoch: 7 | Iteration number: [3520/4518] 77% | Training loss: 0.6872371610254049
Epoch: 7 | Iteration number: [3530/4518] 78% | Training loss: 0.6872374213619881
Epoch: 7 | Iteration number: [3540/4518] 78% | Training loss: 0.6872358997494488
Epoch: 7 | Iteration number: [3550/4518] 78% | Training loss: 0.6872356452236713
Epoch: 7 | Iteration number: [3560/4518] 78% | Training loss: 0.6872310343250799
Epoch: 7 | Iteration number: [3570/4518] 79% | Training loss: 0.687231251939672
Epoch: 7 | Iteration number: [3580/4518] 79% | Training loss: 0.6872308843295667
Epoch: 7 | Iteration number: [3590/4518] 79% | Training loss: 0.6872274669598072
Epoch: 7 | Iteration number: [3600/4518] 79% | Training loss: 0.6872258914510408
Epoch: 7 | Iteration number: [3610/4518] 79% | Training loss: 0.6872224652040698
Epoch: 7 | Iteration number: [3620/4518] 80% | Training loss: 0.6872225548516321
Epoch: 7 | Iteration number: [3630/4518] 80% | Training loss: 0.6872208918421722
Epoch: 7 | Iteration number: [3640/4518] 80% | Training loss: 0.6872222879430749
Epoch: 7 | Iteration number: [3650/4518] 80% | Training loss: 0.6872219997399474
Epoch: 7 | Iteration number: [3660/4518] 81% | Training loss: 0.6872199406063622
Epoch: 7 | Iteration number: [3670/4518] 81% | Training loss: 0.6872216311235194
Epoch: 7 | Iteration number: [3680/4518] 81% | Training loss: 0.6872208734083435
Epoch: 7 | Iteration number: [3690/4518] 81% | Training loss: 0.6872218369629971
Epoch: 7 | Iteration number: [3700/4518] 81% | Training loss: 0.68722286103545
Epoch: 7 | Iteration number: [3710/4518] 82% | Training loss: 0.6872233433382852
Epoch: 7 | Iteration number: [3720/4518] 82% | Training loss: 0.687223790762245
Epoch: 7 | Iteration number: [3730/4518] 82% | Training loss: 0.6872206215884027
Epoch: 7 | Iteration number: [3740/4518] 82% | Training loss: 0.687220050721245
Epoch: 7 | Iteration number: [3750/4518] 83% | Training loss: 0.6872230463663737
Epoch: 7 | Iteration number: [3760/4518] 83% | Training loss: 0.6872231235688037
Epoch: 7 | Iteration number: [3770/4518] 83% | Training loss: 0.6872233368673755
Epoch: 7 | Iteration number: [3780/4518] 83% | Training loss: 0.6872247917311533
Epoch: 7 | Iteration number: [3790/4518] 83% | Training loss: 0.6872232433988426
Epoch: 7 | Iteration number: [3800/4518] 84% | Training loss: 0.6872232735470721
Epoch: 7 | Iteration number: [3810/4518] 84% | Training loss: 0.6872192675516674
Epoch: 7 | Iteration number: [3820/4518] 84% | Training loss: 0.68721913288089
Epoch: 7 | Iteration number: [3830/4518] 84% | Training loss: 0.6872201221885631
Epoch: 7 | Iteration number: [3840/4518] 84% | Training loss: 0.6872191392816603
Epoch: 7 | Iteration number: [3850/4518] 85% | Training loss: 0.687221389126468
Epoch: 7 | Iteration number: [3860/4518] 85% | Training loss: 0.6872189194890501
Epoch: 7 | Iteration number: [3870/4518] 85% | Training loss: 0.6872175574918742
Epoch: 7 | Iteration number: [3880/4518] 85% | Training loss: 0.6872140398498663
Epoch: 7 | Iteration number: [3890/4518] 86% | Training loss: 0.6872140217562874
Epoch: 7 | Iteration number: [3900/4518] 86% | Training loss: 0.6872163155598519
Epoch: 7 | Iteration number: [3910/4518] 86% | Training loss: 0.6872136749270017
Epoch: 7 | Iteration number: [3920/4518] 86% | Training loss: 0.6872146167317216
Epoch: 7 | Iteration number: [3930/4518] 86% | Training loss: 0.6872156568459276
Epoch: 7 | Iteration number: [3940/4518] 87% | Training loss: 0.6872153365369981
Epoch: 7 | Iteration number: [3950/4518] 87% | Training loss: 0.6872144279902495
Epoch: 7 | Iteration number: [3960/4518] 87% | Training loss: 0.6872168119056056
Epoch: 7 | Iteration number: [3970/4518] 87% | Training loss: 0.6872130227929699
Epoch: 7 | Iteration number: [3980/4518] 88% | Training loss: 0.687214343332166
Epoch: 7 | Iteration number: [3990/4518] 88% | Training loss: 0.6872136037301898
Epoch: 7 | Iteration number: [4000/4518] 88% | Training loss: 0.6872122576832771
Epoch: 7 | Iteration number: [4010/4518] 88% | Training loss: 0.6872113682088115
Epoch: 7 | Iteration number: [4020/4518] 88% | Training loss: 0.6872102552533743
Epoch: 7 | Iteration number: [4030/4518] 89% | Training loss: 0.6872110005791666
Epoch: 7 | Iteration number: [4040/4518] 89% | Training loss: 0.6872107397506733
Epoch: 7 | Iteration number: [4050/4518] 89% | Training loss: 0.6872100695857295
Epoch: 7 | Iteration number: [4060/4518] 89% | Training loss: 0.6872102059460626
Epoch: 7 | Iteration number: [4070/4518] 90% | Training loss: 0.6872120804956563
Epoch: 7 | Iteration number: [4080/4518] 90% | Training loss: 0.6872100862802244
Epoch: 7 | Iteration number: [4090/4518] 90% | Training loss: 0.687210490315934
Epoch: 7 | Iteration number: [4100/4518] 90% | Training loss: 0.6872068445711601
Epoch: 7 | Iteration number: [4110/4518] 90% | Training loss: 0.687205046835897
Epoch: 7 | Iteration number: [4120/4518] 91% | Training loss: 0.6872043251267914
Epoch: 7 | Iteration number: [4130/4518] 91% | Training loss: 0.687204672508032
Epoch: 7 | Iteration number: [4140/4518] 91% | Training loss: 0.6872053142619018
Epoch: 7 | Iteration number: [4150/4518] 91% | Training loss: 0.6872044529685055
Epoch: 7 | Iteration number: [4160/4518] 92% | Training loss: 0.6872046656620044
Epoch: 7 | Iteration number: [4170/4518] 92% | Training loss: 0.6872068566669949
Epoch: 7 | Iteration number: [4180/4518] 92% | Training loss: 0.6872048715084934
Epoch: 7 | Iteration number: [4190/4518] 92% | Training loss: 0.6872023864549214
Epoch: 7 | Iteration number: [4200/4518] 92% | Training loss: 0.6872035777001154
Epoch: 7 | Iteration number: [4210/4518] 93% | Training loss: 0.6872027268460698
Epoch: 7 | Iteration number: [4220/4518] 93% | Training loss: 0.6872028204502088
Epoch: 7 | Iteration number: [4230/4518] 93% | Training loss: 0.6872019994061608
Epoch: 7 | Iteration number: [4240/4518] 93% | Training loss: 0.6872021062897061
Epoch: 7 | Iteration number: [4250/4518] 94% | Training loss: 0.6872006909987506
Epoch: 7 | Iteration number: [4260/4518] 94% | Training loss: 0.6872008795609497
Epoch: 7 | Iteration number: [4270/4518] 94% | Training loss: 0.6872014698853817
Epoch: 7 | Iteration number: [4280/4518] 94% | Training loss: 0.6871995182098629
Epoch: 7 | Iteration number: [4290/4518] 94% | Training loss: 0.6871987106083156
Epoch: 7 | Iteration number: [4300/4518] 95% | Training loss: 0.6871978973787884
Epoch: 7 | Iteration number: [4310/4518] 95% | Training loss: 0.6871966000084534
Epoch: 7 | Iteration number: [4320/4518] 95% | Training loss: 0.6871965413844144
Epoch: 7 | Iteration number: [4330/4518] 95% | Training loss: 0.6871961101098094
Epoch: 7 | Iteration number: [4340/4518] 96% | Training loss: 0.6871970789086435
Epoch: 7 | Iteration number: [4350/4518] 96% | Training loss: 0.6871970186836418
Epoch: 7 | Iteration number: [4360/4518] 96% | Training loss: 0.6872003526179069
Epoch: 7 | Iteration number: [4370/4518] 96% | Training loss: 0.6872029140830312
Epoch: 7 | Iteration number: [4380/4518] 96% | Training loss: 0.6872042912190364
Epoch: 7 | Iteration number: [4390/4518] 97% | Training loss: 0.6872046352111668
Epoch: 7 | Iteration number: [4400/4518] 97% | Training loss: 0.6872043436630205
Epoch: 7 | Iteration number: [4410/4518] 97% | Training loss: 0.6872028532752644
Epoch: 7 | Iteration number: [4420/4518] 97% | Training loss: 0.6872026242147204
Epoch: 7 | Iteration number: [4430/4518] 98% | Training loss: 0.687201738532456
Epoch: 7 | Iteration number: [4440/4518] 98% | Training loss: 0.6872012662189501
Epoch: 7 | Iteration number: [4450/4518] 98% | Training loss: 0.687201721427146
Epoch: 7 | Iteration number: [4460/4518] 98% | Training loss: 0.6872032223394633
Epoch: 7 | Iteration number: [4470/4518] 98% | Training loss: 0.6871998134075396
Epoch: 7 | Iteration number: [4480/4518] 99% | Training loss: 0.6872008966415056
Epoch: 7 | Iteration number: [4490/4518] 99% | Training loss: 0.6872007236183354
Epoch: 7 | Iteration number: [4500/4518] 99% | Training loss: 0.6871996455457475
Epoch: 7 | Iteration number: [4510/4518] 99% | Training loss: 0.6871971171076705

 End of epoch: 7 | Train Loss: 0.6870422860250477 | Training Time: 631 

 End of epoch: 7 | Eval Loss: 0.6901498449092008 | Evaluating Time: 17 
Epoch: 8 | Iteration number: [10/4518] 0% | Training loss: 0.7548059821128845
Epoch: 8 | Iteration number: [20/4518] 0% | Training loss: 0.7210355252027512
Epoch: 8 | Iteration number: [30/4518] 0% | Training loss: 0.7094794690608979
Epoch: 8 | Iteration number: [40/4518] 0% | Training loss: 0.7042662918567657
Epoch: 8 | Iteration number: [50/4518] 1% | Training loss: 0.7009670460224151
Epoch: 8 | Iteration number: [60/4518] 1% | Training loss: 0.6987896541754405
Epoch: 8 | Iteration number: [70/4518] 1% | Training loss: 0.6971838670117515
Epoch: 8 | Iteration number: [80/4518] 1% | Training loss: 0.6958426363766194
Epoch: 8 | Iteration number: [90/4518] 1% | Training loss: 0.6948701865143246
Epoch: 8 | Iteration number: [100/4518] 2% | Training loss: 0.6940840822458267
Epoch: 8 | Iteration number: [110/4518] 2% | Training loss: 0.6934889755465767
Epoch: 8 | Iteration number: [120/4518] 2% | Training loss: 0.6929954692721367
Epoch: 8 | Iteration number: [130/4518] 2% | Training loss: 0.6925668528446784
Epoch: 8 | Iteration number: [140/4518] 3% | Training loss: 0.692141798564366
Epoch: 8 | Iteration number: [150/4518] 3% | Training loss: 0.6918094352881113
Epoch: 8 | Iteration number: [160/4518] 3% | Training loss: 0.6914743706583977
Epoch: 8 | Iteration number: [170/4518] 3% | Training loss: 0.6912547290325165
Epoch: 8 | Iteration number: [180/4518] 3% | Training loss: 0.691048303577635
Epoch: 8 | Iteration number: [190/4518] 4% | Training loss: 0.6908538617585834
Epoch: 8 | Iteration number: [200/4518] 4% | Training loss: 0.6906368073821068
Epoch: 8 | Iteration number: [210/4518] 4% | Training loss: 0.690453660204297
Epoch: 8 | Iteration number: [220/4518] 4% | Training loss: 0.690263300592249
Epoch: 8 | Iteration number: [230/4518] 5% | Training loss: 0.6901403696640678
Epoch: 8 | Iteration number: [240/4518] 5% | Training loss: 0.6900406633814176
Epoch: 8 | Iteration number: [250/4518] 5% | Training loss: 0.6899301249980927
Epoch: 8 | Iteration number: [260/4518] 5% | Training loss: 0.6898222758219792
Epoch: 8 | Iteration number: [270/4518] 5% | Training loss: 0.6896478613217671
Epoch: 8 | Iteration number: [280/4518] 6% | Training loss: 0.6895425566605159
Epoch: 8 | Iteration number: [290/4518] 6% | Training loss: 0.6894644030209245
Epoch: 8 | Iteration number: [300/4518] 6% | Training loss: 0.6894308509429296
Epoch: 8 | Iteration number: [310/4518] 6% | Training loss: 0.6893650724041847
Epoch: 8 | Iteration number: [320/4518] 7% | Training loss: 0.6892842940986157
Epoch: 8 | Iteration number: [330/4518] 7% | Training loss: 0.6891986268939394
Epoch: 8 | Iteration number: [340/4518] 7% | Training loss: 0.6891088853864109
Epoch: 8 | Iteration number: [350/4518] 7% | Training loss: 0.6890626834120069
Epoch: 8 | Iteration number: [360/4518] 7% | Training loss: 0.6889751984013451
Epoch: 8 | Iteration number: [370/4518] 8% | Training loss: 0.6889246996995565
Epoch: 8 | Iteration number: [380/4518] 8% | Training loss: 0.6888507554405614
Epoch: 8 | Iteration number: [390/4518] 8% | Training loss: 0.6887856767727778
Epoch: 8 | Iteration number: [400/4518] 8% | Training loss: 0.6887259776890278
Epoch: 8 | Iteration number: [410/4518] 9% | Training loss: 0.6886757952411
Epoch: 8 | Iteration number: [420/4518] 9% | Training loss: 0.6886209540423893
Epoch: 8 | Iteration number: [430/4518] 9% | Training loss: 0.6886131505633509
Epoch: 8 | Iteration number: [440/4518] 9% | Training loss: 0.6885689944028854
Epoch: 8 | Iteration number: [450/4518] 9% | Training loss: 0.6885173446602292
Epoch: 8 | Iteration number: [460/4518] 10% | Training loss: 0.6884828081597453
Epoch: 8 | Iteration number: [470/4518] 10% | Training loss: 0.688459930014103
Epoch: 8 | Iteration number: [480/4518] 10% | Training loss: 0.6884195717672507
Epoch: 8 | Iteration number: [490/4518] 10% | Training loss: 0.6884026858271385
Epoch: 8 | Iteration number: [500/4518] 11% | Training loss: 0.6883702472448349
Epoch: 8 | Iteration number: [510/4518] 11% | Training loss: 0.688342549870996
Epoch: 8 | Iteration number: [520/4518] 11% | Training loss: 0.6883170122137436
Epoch: 8 | Iteration number: [530/4518] 11% | Training loss: 0.6883094829208446
Epoch: 8 | Iteration number: [540/4518] 11% | Training loss: 0.6882768437818244
Epoch: 8 | Iteration number: [550/4518] 12% | Training loss: 0.6882786129821431
Epoch: 8 | Iteration number: [560/4518] 12% | Training loss: 0.6882394691663128
Epoch: 8 | Iteration number: [570/4518] 12% | Training loss: 0.6882038599566409
Epoch: 8 | Iteration number: [580/4518] 12% | Training loss: 0.6881685357669304
Epoch: 8 | Iteration number: [590/4518] 13% | Training loss: 0.6881494635242527
Epoch: 8 | Iteration number: [600/4518] 13% | Training loss: 0.6881531912088394
Epoch: 8 | Iteration number: [610/4518] 13% | Training loss: 0.6881362564251071
Epoch: 8 | Iteration number: [620/4518] 13% | Training loss: 0.6881330940992602
Epoch: 8 | Iteration number: [630/4518] 13% | Training loss: 0.6881161631099761
Epoch: 8 | Iteration number: [640/4518] 14% | Training loss: 0.6881114489398896
Epoch: 8 | Iteration number: [650/4518] 14% | Training loss: 0.6880994650950799
Epoch: 8 | Iteration number: [660/4518] 14% | Training loss: 0.6880797902743022
Epoch: 8 | Iteration number: [670/4518] 14% | Training loss: 0.688063101003419
Epoch: 8 | Iteration number: [680/4518] 15% | Training loss: 0.6880300366703201
Epoch: 8 | Iteration number: [690/4518] 15% | Training loss: 0.6880269138709358
Epoch: 8 | Iteration number: [700/4518] 15% | Training loss: 0.6880370834895543
Epoch: 8 | Iteration number: [710/4518] 15% | Training loss: 0.6880122952897784
Epoch: 8 | Iteration number: [720/4518] 15% | Training loss: 0.6879961435993512
Epoch: 8 | Iteration number: [730/4518] 16% | Training loss: 0.6879992903095402
Epoch: 8 | Iteration number: [740/4518] 16% | Training loss: 0.6879916456905572
Epoch: 8 | Iteration number: [750/4518] 16% | Training loss: 0.6879901457627614
Epoch: 8 | Iteration number: [760/4518] 16% | Training loss: 0.6879896943506442
Epoch: 8 | Iteration number: [770/4518] 17% | Training loss: 0.6879742108382187
Epoch: 8 | Iteration number: [780/4518] 17% | Training loss: 0.6879716071562889
Epoch: 8 | Iteration number: [790/4518] 17% | Training loss: 0.6879532949079441
Epoch: 8 | Iteration number: [800/4518] 17% | Training loss: 0.6879494274407625
Epoch: 8 | Iteration number: [810/4518] 17% | Training loss: 0.6879346044711124
Epoch: 8 | Iteration number: [820/4518] 18% | Training loss: 0.6879144324035179
Epoch: 8 | Iteration number: [830/4518] 18% | Training loss: 0.687911485117602
Epoch: 8 | Iteration number: [840/4518] 18% | Training loss: 0.6879011639526912
Epoch: 8 | Iteration number: [850/4518] 18% | Training loss: 0.6878980153448442
Epoch: 8 | Iteration number: [860/4518] 19% | Training loss: 0.6878919340150301
Epoch: 8 | Iteration number: [870/4518] 19% | Training loss: 0.6878952587472982
Epoch: 8 | Iteration number: [880/4518] 19% | Training loss: 0.6878852720287714
Epoch: 8 | Iteration number: [890/4518] 19% | Training loss: 0.6878726711433925
Epoch: 8 | Iteration number: [900/4518] 19% | Training loss: 0.6878659890095393
Epoch: 8 | Iteration number: [910/4518] 20% | Training loss: 0.6878602299716446
Epoch: 8 | Iteration number: [920/4518] 20% | Training loss: 0.6878625599586445
Epoch: 8 | Iteration number: [930/4518] 20% | Training loss: 0.6878657237175972
Epoch: 8 | Iteration number: [940/4518] 20% | Training loss: 0.6878563665963234
Epoch: 8 | Iteration number: [950/4518] 21% | Training loss: 0.6878578130195016
Epoch: 8 | Iteration number: [960/4518] 21% | Training loss: 0.6878448926533262
Epoch: 8 | Iteration number: [970/4518] 21% | Training loss: 0.6878378867488546
Epoch: 8 | Iteration number: [980/4518] 21% | Training loss: 0.6878323725291661
Epoch: 8 | Iteration number: [990/4518] 21% | Training loss: 0.6878074550267422
Epoch: 8 | Iteration number: [1000/4518] 22% | Training loss: 0.6877945078611374
Epoch: 8 | Iteration number: [1010/4518] 22% | Training loss: 0.6877839496230135
Epoch: 8 | Iteration number: [1020/4518] 22% | Training loss: 0.6877712527910869
Epoch: 8 | Iteration number: [1030/4518] 22% | Training loss: 0.6877659252546366
Epoch: 8 | Iteration number: [1040/4518] 23% | Training loss: 0.6877704669649785
Epoch: 8 | Iteration number: [1050/4518] 23% | Training loss: 0.6877725164663224
Epoch: 8 | Iteration number: [1060/4518] 23% | Training loss: 0.6877555801621024
Epoch: 8 | Iteration number: [1070/4518] 23% | Training loss: 0.6877526372392601
Epoch: 8 | Iteration number: [1080/4518] 23% | Training loss: 0.6877471092122572
Epoch: 8 | Iteration number: [1090/4518] 24% | Training loss: 0.6877381727782959
Epoch: 8 | Iteration number: [1100/4518] 24% | Training loss: 0.6877395994013006
Epoch: 8 | Iteration number: [1110/4518] 24% | Training loss: 0.6877370837572458
Epoch: 8 | Iteration number: [1120/4518] 24% | Training loss: 0.6877259316188948
Epoch: 8 | Iteration number: [1130/4518] 25% | Training loss: 0.6877275112455925
Epoch: 8 | Iteration number: [1140/4518] 25% | Training loss: 0.6877166699944881
Epoch: 8 | Iteration number: [1150/4518] 25% | Training loss: 0.6877166235965231
Epoch: 8 | Iteration number: [1160/4518] 25% | Training loss: 0.6877113515960759
Epoch: 8 | Iteration number: [1170/4518] 25% | Training loss: 0.6877154727267404
Epoch: 8 | Iteration number: [1180/4518] 26% | Training loss: 0.6877110390844992
Epoch: 8 | Iteration number: [1190/4518] 26% | Training loss: 0.6877044778411128
Epoch: 8 | Iteration number: [1200/4518] 26% | Training loss: 0.6876984868943691
Epoch: 8 | Iteration number: [1210/4518] 26% | Training loss: 0.6876810546748894
Epoch: 8 | Iteration number: [1220/4518] 27% | Training loss: 0.6876757221143753
Epoch: 8 | Iteration number: [1230/4518] 27% | Training loss: 0.687660816481443
Epoch: 8 | Iteration number: [1240/4518] 27% | Training loss: 0.6876579870620082
Epoch: 8 | Iteration number: [1250/4518] 27% | Training loss: 0.6876604053974151
Epoch: 8 | Iteration number: [1260/4518] 27% | Training loss: 0.6876433795406705
Epoch: 8 | Iteration number: [1270/4518] 28% | Training loss: 0.687636948288895
Epoch: 8 | Iteration number: [1280/4518] 28% | Training loss: 0.6876319063827395
Epoch: 8 | Iteration number: [1290/4518] 28% | Training loss: 0.6876303695893102
Epoch: 8 | Iteration number: [1300/4518] 28% | Training loss: 0.6876323902148467
Epoch: 8 | Iteration number: [1310/4518] 28% | Training loss: 0.6876230090629053
Epoch: 8 | Iteration number: [1320/4518] 29% | Training loss: 0.687619443915107
Epoch: 8 | Iteration number: [1330/4518] 29% | Training loss: 0.6876162226038768
Epoch: 8 | Iteration number: [1340/4518] 29% | Training loss: 0.6876088269610903
Epoch: 8 | Iteration number: [1350/4518] 29% | Training loss: 0.6876033827110574
Epoch: 8 | Iteration number: [1360/4518] 30% | Training loss: 0.6875946200507529
Epoch: 8 | Iteration number: [1370/4518] 30% | Training loss: 0.6875978072194288
Epoch: 8 | Iteration number: [1380/4518] 30% | Training loss: 0.6875913613948269
Epoch: 8 | Iteration number: [1390/4518] 30% | Training loss: 0.687592169792532
Epoch: 8 | Iteration number: [1400/4518] 30% | Training loss: 0.6875908814157758
Epoch: 8 | Iteration number: [1410/4518] 31% | Training loss: 0.6875981967077187
Epoch: 8 | Iteration number: [1420/4518] 31% | Training loss: 0.6875915794725149
Epoch: 8 | Iteration number: [1430/4518] 31% | Training loss: 0.6875912760104332
Epoch: 8 | Iteration number: [1440/4518] 31% | Training loss: 0.6875808495614264
Epoch: 8 | Iteration number: [1450/4518] 32% | Training loss: 0.6875773750913554
Epoch: 8 | Iteration number: [1460/4518] 32% | Training loss: 0.6875788816033978
Epoch: 8 | Iteration number: [1470/4518] 32% | Training loss: 0.6875859479109446
Epoch: 8 | Iteration number: [1480/4518] 32% | Training loss: 0.6875783467614973
Epoch: 8 | Iteration number: [1490/4518] 32% | Training loss: 0.6875689377720724
Epoch: 8 | Iteration number: [1500/4518] 33% | Training loss: 0.6875601239204406
Epoch: 8 | Iteration number: [1510/4518] 33% | Training loss: 0.6875592919769666
Epoch: 8 | Iteration number: [1520/4518] 33% | Training loss: 0.6875528570852781
Epoch: 8 | Iteration number: [1530/4518] 33% | Training loss: 0.6875488763151605
Epoch: 8 | Iteration number: [1540/4518] 34% | Training loss: 0.687543276919947
Epoch: 8 | Iteration number: [1550/4518] 34% | Training loss: 0.6875407228931304
Epoch: 8 | Iteration number: [1560/4518] 34% | Training loss: 0.6875352279498027
Epoch: 8 | Iteration number: [1570/4518] 34% | Training loss: 0.6875348637438125
Epoch: 8 | Iteration number: [1580/4518] 34% | Training loss: 0.6875333489496497
Epoch: 8 | Iteration number: [1590/4518] 35% | Training loss: 0.6875290072189187
Epoch: 8 | Iteration number: [1600/4518] 35% | Training loss: 0.6875336725264788
Epoch: 8 | Iteration number: [1610/4518] 35% | Training loss: 0.6875366967657338
Epoch: 8 | Iteration number: [1620/4518] 35% | Training loss: 0.6875246142531619
Epoch: 8 | Iteration number: [1630/4518] 36% | Training loss: 0.6875167780127263
Epoch: 8 | Iteration number: [1640/4518] 36% | Training loss: 0.6875199825661938
Epoch: 8 | Iteration number: [1650/4518] 36% | Training loss: 0.6875090501886426
Epoch: 8 | Iteration number: [1660/4518] 36% | Training loss: 0.6875094929014344
Epoch: 8 | Iteration number: [1670/4518] 36% | Training loss: 0.6875067590596433
Epoch: 8 | Iteration number: [1680/4518] 37% | Training loss: 0.6875010616722561
Epoch: 8 | Iteration number: [1690/4518] 37% | Training loss: 0.6874976425481266
Epoch: 8 | Iteration number: [1700/4518] 37% | Training loss: 0.6874897321182138
Epoch: 8 | Iteration number: [1710/4518] 37% | Training loss: 0.6874878473100606
Epoch: 8 | Iteration number: [1720/4518] 38% | Training loss: 0.6874761976474939
Epoch: 8 | Iteration number: [1730/4518] 38% | Training loss: 0.6874746607907246
Epoch: 8 | Iteration number: [1740/4518] 38% | Training loss: 0.6874729217811563
Epoch: 8 | Iteration number: [1750/4518] 38% | Training loss: 0.6874632331984384
Epoch: 8 | Iteration number: [1760/4518] 38% | Training loss: 0.6874596799639139
Epoch: 8 | Iteration number: [1770/4518] 39% | Training loss: 0.6874556755615493
Epoch: 8 | Iteration number: [1780/4518] 39% | Training loss: 0.6874530367636948
Epoch: 8 | Iteration number: [1790/4518] 39% | Training loss: 0.6874455192235595
Epoch: 8 | Iteration number: [1800/4518] 39% | Training loss: 0.6874448348416222
Epoch: 8 | Iteration number: [1810/4518] 40% | Training loss: 0.6874431547209703
Epoch: 8 | Iteration number: [1820/4518] 40% | Training loss: 0.6874420188612991
Epoch: 8 | Iteration number: [1830/4518] 40% | Training loss: 0.6874454310682954
Epoch: 8 | Iteration number: [1840/4518] 40% | Training loss: 0.6874429904572342
Epoch: 8 | Iteration number: [1850/4518] 40% | Training loss: 0.687441682074521
Epoch: 8 | Iteration number: [1860/4518] 41% | Training loss: 0.6874320919154793
Epoch: 8 | Iteration number: [1870/4518] 41% | Training loss: 0.6874365533099455
Epoch: 8 | Iteration number: [1880/4518] 41% | Training loss: 0.6874327683702428
Epoch: 8 | Iteration number: [1890/4518] 41% | Training loss: 0.6874314811179247
Epoch: 8 | Iteration number: [1900/4518] 42% | Training loss: 0.6874252263495797
Epoch: 8 | Iteration number: [1910/4518] 42% | Training loss: 0.6874216314073632
Epoch: 8 | Iteration number: [1920/4518] 42% | Training loss: 0.6874231557361782
Epoch: 8 | Iteration number: [1930/4518] 42% | Training loss: 0.6874183475044725
Epoch: 8 | Iteration number: [1940/4518] 42% | Training loss: 0.6874167505613308
Epoch: 8 | Iteration number: [1950/4518] 43% | Training loss: 0.6874169010076767
Epoch: 8 | Iteration number: [1960/4518] 43% | Training loss: 0.6874150261587026
Epoch: 8 | Iteration number: [1970/4518] 43% | Training loss: 0.6874108769264318
Epoch: 8 | Iteration number: [1980/4518] 43% | Training loss: 0.6874138709571627
Epoch: 8 | Iteration number: [1990/4518] 44% | Training loss: 0.6874179631621394
Epoch: 8 | Iteration number: [2000/4518] 44% | Training loss: 0.687413258343935
Epoch: 8 | Iteration number: [2010/4518] 44% | Training loss: 0.6874098109665202
Epoch: 8 | Iteration number: [2020/4518] 44% | Training loss: 0.6874058234809649
Epoch: 8 | Iteration number: [2030/4518] 44% | Training loss: 0.6873917193248354
Epoch: 8 | Iteration number: [2040/4518] 45% | Training loss: 0.6873899620245485
Epoch: 8 | Iteration number: [2050/4518] 45% | Training loss: 0.6873838355483078
Epoch: 8 | Iteration number: [2060/4518] 45% | Training loss: 0.6873827166348985
Epoch: 8 | Iteration number: [2070/4518] 45% | Training loss: 0.6873798804582605
Epoch: 8 | Iteration number: [2080/4518] 46% | Training loss: 0.6873761026332011
Epoch: 8 | Iteration number: [2090/4518] 46% | Training loss: 0.6873716477572063
Epoch: 8 | Iteration number: [2100/4518] 46% | Training loss: 0.6873780372880754
Epoch: 8 | Iteration number: [2110/4518] 46% | Training loss: 0.6873744714316599
Epoch: 8 | Iteration number: [2120/4518] 46% | Training loss: 0.6873763067542382
Epoch: 8 | Iteration number: [2130/4518] 47% | Training loss: 0.687373230910637
Epoch: 8 | Iteration number: [2140/4518] 47% | Training loss: 0.687370344940747
Epoch: 8 | Iteration number: [2150/4518] 47% | Training loss: 0.6873656962638678
Epoch: 8 | Iteration number: [2160/4518] 47% | Training loss: 0.687365925450016
Epoch: 8 | Iteration number: [2170/4518] 48% | Training loss: 0.6873614203545355
Epoch: 8 | Iteration number: [2180/4518] 48% | Training loss: 0.6873558729613592
Epoch: 8 | Iteration number: [2190/4518] 48% | Training loss: 0.6873574785173756
Epoch: 8 | Iteration number: [2200/4518] 48% | Training loss: 0.6873580745946277
Epoch: 8 | Iteration number: [2210/4518] 48% | Training loss: 0.6873472079702092
Epoch: 8 | Iteration number: [2220/4518] 49% | Training loss: 0.6873442246838732
Epoch: 8 | Iteration number: [2230/4518] 49% | Training loss: 0.6873423879723912
Epoch: 8 | Iteration number: [2240/4518] 49% | Training loss: 0.6873407248407603
Epoch: 8 | Iteration number: [2250/4518] 49% | Training loss: 0.6873347243997786
Epoch: 8 | Iteration number: [2260/4518] 50% | Training loss: 0.6873329090069881
Epoch: 8 | Iteration number: [2270/4518] 50% | Training loss: 0.6873319352775944
Epoch: 8 | Iteration number: [2280/4518] 50% | Training loss: 0.6873360827303769
Epoch: 8 | Iteration number: [2290/4518] 50% | Training loss: 0.6873338251394997
Epoch: 8 | Iteration number: [2300/4518] 50% | Training loss: 0.6873347302364267
Epoch: 8 | Iteration number: [2310/4518] 51% | Training loss: 0.6873259395747989
Epoch: 8 | Iteration number: [2320/4518] 51% | Training loss: 0.6873222741073576
Epoch: 8 | Iteration number: [2330/4518] 51% | Training loss: 0.6873271207952704
Epoch: 8 | Iteration number: [2340/4518] 51% | Training loss: 0.6873217176677834
Epoch: 8 | Iteration number: [2350/4518] 52% | Training loss: 0.6873204213761269
Epoch: 8 | Iteration number: [2360/4518] 52% | Training loss: 0.6873164735355619
Epoch: 8 | Iteration number: [2370/4518] 52% | Training loss: 0.6873158884953849
Epoch: 8 | Iteration number: [2380/4518] 52% | Training loss: 0.6873138702967587
Epoch: 8 | Iteration number: [2390/4518] 52% | Training loss: 0.6873153517934568
Epoch: 8 | Iteration number: [2400/4518] 53% | Training loss: 0.6873182003448407
Epoch: 8 | Iteration number: [2410/4518] 53% | Training loss: 0.6873167144312403
Epoch: 8 | Iteration number: [2420/4518] 53% | Training loss: 0.6873150185612608
Epoch: 8 | Iteration number: [2430/4518] 53% | Training loss: 0.6873172143113957
Epoch: 8 | Iteration number: [2440/4518] 54% | Training loss: 0.6873143713738098
Epoch: 8 | Iteration number: [2450/4518] 54% | Training loss: 0.6873140775914095
Epoch: 8 | Iteration number: [2460/4518] 54% | Training loss: 0.687311207497023
Epoch: 8 | Iteration number: [2470/4518] 54% | Training loss: 0.6873095958339058
Epoch: 8 | Iteration number: [2480/4518] 54% | Training loss: 0.6873081366140996
Epoch: 8 | Iteration number: [2490/4518] 55% | Training loss: 0.6873076685221798
Epoch: 8 | Iteration number: [2500/4518] 55% | Training loss: 0.6873027520179749
Epoch: 8 | Iteration number: [2510/4518] 55% | Training loss: 0.6873033433558932
Epoch: 8 | Iteration number: [2520/4518] 55% | Training loss: 0.6872993994326818
Epoch: 8 | Iteration number: [2530/4518] 55% | Training loss: 0.6873012556624507
Epoch: 8 | Iteration number: [2540/4518] 56% | Training loss: 0.687295638740532
Epoch: 8 | Iteration number: [2550/4518] 56% | Training loss: 0.6872953387101491
Epoch: 8 | Iteration number: [2560/4518] 56% | Training loss: 0.6872934576123952
Epoch: 8 | Iteration number: [2570/4518] 56% | Training loss: 0.6872916062054467
Epoch: 8 | Iteration number: [2580/4518] 57% | Training loss: 0.6872936532478924
Epoch: 8 | Iteration number: [2590/4518] 57% | Training loss: 0.6872969397706875
Epoch: 8 | Iteration number: [2600/4518] 57% | Training loss: 0.6872906681895256
Epoch: 8 | Iteration number: [2610/4518] 57% | Training loss: 0.6872932742153548
Epoch: 8 | Iteration number: [2620/4518] 57% | Training loss: 0.6872988317531484
Epoch: 8 | Iteration number: [2630/4518] 58% | Training loss: 0.687298402382847
Epoch: 8 | Iteration number: [2640/4518] 58% | Training loss: 0.6872973277261762
Epoch: 8 | Iteration number: [2650/4518] 58% | Training loss: 0.6872974134391209
Epoch: 8 | Iteration number: [2660/4518] 58% | Training loss: 0.687295279870356
Epoch: 8 | Iteration number: [2670/4518] 59% | Training loss: 0.6872947351986103
Epoch: 8 | Iteration number: [2680/4518] 59% | Training loss: 0.6872974530752025
Epoch: 8 | Iteration number: [2690/4518] 59% | Training loss: 0.6873015619343541
Epoch: 8 | Iteration number: [2700/4518] 59% | Training loss: 0.687303919725948
Epoch: 8 | Iteration number: [2710/4518] 59% | Training loss: 0.687309440849452
Epoch: 8 | Iteration number: [2720/4518] 60% | Training loss: 0.6873105126268724
Epoch: 8 | Iteration number: [2730/4518] 60% | Training loss: 0.6873122806295807
Epoch: 8 | Iteration number: [2740/4518] 60% | Training loss: 0.6873045756651537
Epoch: 8 | Iteration number: [2750/4518] 60% | Training loss: 0.687301673000509
Epoch: 8 | Iteration number: [2760/4518] 61% | Training loss: 0.6873036834640779
Epoch: 8 | Iteration number: [2770/4518] 61% | Training loss: 0.6873027206327941
Epoch: 8 | Iteration number: [2780/4518] 61% | Training loss: 0.6873005180050143
Epoch: 8 | Iteration number: [2790/4518] 61% | Training loss: 0.6872960452324174
Epoch: 8 | Iteration number: [2800/4518] 61% | Training loss: 0.6872924315290792
Epoch: 8 | Iteration number: [2810/4518] 62% | Training loss: 0.6872897139435561
Epoch: 8 | Iteration number: [2820/4518] 62% | Training loss: 0.6872885057689451
Epoch: 8 | Iteration number: [2830/4518] 62% | Training loss: 0.6872868303696595
Epoch: 8 | Iteration number: [2840/4518] 62% | Training loss: 0.687287353923623
Epoch: 8 | Iteration number: [2850/4518] 63% | Training loss: 0.6872904754103276
Epoch: 8 | Iteration number: [2860/4518] 63% | Training loss: 0.687291244631047
Epoch: 8 | Iteration number: [2870/4518] 63% | Training loss: 0.687289623287912
Epoch: 8 | Iteration number: [2880/4518] 63% | Training loss: 0.6872889074600406
Epoch: 8 | Iteration number: [2890/4518] 63% | Training loss: 0.6872904227885408
Epoch: 8 | Iteration number: [2900/4518] 64% | Training loss: 0.6872912207554127
Epoch: 8 | Iteration number: [2910/4518] 64% | Training loss: 0.6872922145623931
Epoch: 8 | Iteration number: [2920/4518] 64% | Training loss: 0.6872873631038078
Epoch: 8 | Iteration number: [2930/4518] 64% | Training loss: 0.6872814299913803
Epoch: 8 | Iteration number: [2940/4518] 65% | Training loss: 0.6872781268796142
Epoch: 8 | Iteration number: [2950/4518] 65% | Training loss: 0.6872760251821097
Epoch: 8 | Iteration number: [2960/4518] 65% | Training loss: 0.6872765426297446
Epoch: 8 | Iteration number: [2970/4518] 65% | Training loss: 0.6872708208031124
Epoch: 8 | Iteration number: [2980/4518] 65% | Training loss: 0.6872672135797923
Epoch: 8 | Iteration number: [2990/4518] 66% | Training loss: 0.6872704859362
Epoch: 8 | Iteration number: [3000/4518] 66% | Training loss: 0.6872727754712105
Epoch: 8 | Iteration number: [3010/4518] 66% | Training loss: 0.6872765450976616
Epoch: 8 | Iteration number: [3020/4518] 66% | Training loss: 0.6872734955801869
Epoch: 8 | Iteration number: [3030/4518] 67% | Training loss: 0.6872730106410414
Epoch: 8 | Iteration number: [3040/4518] 67% | Training loss: 0.687270308148704
Epoch: 8 | Iteration number: [3050/4518] 67% | Training loss: 0.687270422001354
Epoch: 8 | Iteration number: [3060/4518] 67% | Training loss: 0.6872720573462692
Epoch: 8 | Iteration number: [3070/4518] 67% | Training loss: 0.6872708296348684
Epoch: 8 | Iteration number: [3080/4518] 68% | Training loss: 0.6872671471981259
Epoch: 8 | Iteration number: [3090/4518] 68% | Training loss: 0.687266111142427
Epoch: 8 | Iteration number: [3100/4518] 68% | Training loss: 0.6872674721287143
Epoch: 8 | Iteration number: [3110/4518] 68% | Training loss: 0.6872665318070501
Epoch: 8 | Iteration number: [3120/4518] 69% | Training loss: 0.6872618979368454
Epoch: 8 | Iteration number: [3130/4518] 69% | Training loss: 0.6872588272102343
Epoch: 8 | Iteration number: [3140/4518] 69% | Training loss: 0.6872576339609304
Epoch: 8 | Iteration number: [3150/4518] 69% | Training loss: 0.6872600474433294
Epoch: 8 | Iteration number: [3160/4518] 69% | Training loss: 0.6872597478990313
Epoch: 8 | Iteration number: [3170/4518] 70% | Training loss: 0.6872581467455494
Epoch: 8 | Iteration number: [3180/4518] 70% | Training loss: 0.6872581300870427
Epoch: 8 | Iteration number: [3190/4518] 70% | Training loss: 0.687258438462374
Epoch: 8 | Iteration number: [3200/4518] 70% | Training loss: 0.6872570158541202
Epoch: 8 | Iteration number: [3210/4518] 71% | Training loss: 0.6872544770857255
Epoch: 8 | Iteration number: [3220/4518] 71% | Training loss: 0.687254350618546
Epoch: 8 | Iteration number: [3230/4518] 71% | Training loss: 0.6872514022208589
Epoch: 8 | Iteration number: [3240/4518] 71% | Training loss: 0.6872529900920243
Epoch: 8 | Iteration number: [3250/4518] 71% | Training loss: 0.6872507532193111
Epoch: 8 | Iteration number: [3260/4518] 72% | Training loss: 0.6872532027996391
Epoch: 8 | Iteration number: [3270/4518] 72% | Training loss: 0.6872530799940092
Epoch: 8 | Iteration number: [3280/4518] 72% | Training loss: 0.6872538405402404
Epoch: 8 | Iteration number: [3290/4518] 72% | Training loss: 0.6872531229964143
Epoch: 8 | Iteration number: [3300/4518] 73% | Training loss: 0.6872547201857422
Epoch: 8 | Iteration number: [3310/4518] 73% | Training loss: 0.6872499056633146
Epoch: 8 | Iteration number: [3320/4518] 73% | Training loss: 0.6872512069990836
Epoch: 8 | Iteration number: [3330/4518] 73% | Training loss: 0.6872484993827236
Epoch: 8 | Iteration number: [3340/4518] 73% | Training loss: 0.6872459126803689
Epoch: 8 | Iteration number: [3350/4518] 74% | Training loss: 0.6872496057802172
Epoch: 8 | Iteration number: [3360/4518] 74% | Training loss: 0.6872454848850057
Epoch: 8 | Iteration number: [3370/4518] 74% | Training loss: 0.6872443922726266
Epoch: 8 | Iteration number: [3380/4518] 74% | Training loss: 0.6872487133776648
Epoch: 8 | Iteration number: [3390/4518] 75% | Training loss: 0.6872510527966649
Epoch: 8 | Iteration number: [3400/4518] 75% | Training loss: 0.6872466669889057
Epoch: 8 | Iteration number: [3410/4518] 75% | Training loss: 0.6872435316661936
Epoch: 8 | Iteration number: [3420/4518] 75% | Training loss: 0.6872403584899958
Epoch: 8 | Iteration number: [3430/4518] 75% | Training loss: 0.6872407885404092
Epoch: 8 | Iteration number: [3440/4518] 76% | Training loss: 0.6872429325830105
Epoch: 8 | Iteration number: [3450/4518] 76% | Training loss: 0.6872374158147453
Epoch: 8 | Iteration number: [3460/4518] 76% | Training loss: 0.6872384134744633
Epoch: 8 | Iteration number: [3470/4518] 76% | Training loss: 0.6872360624909745
Epoch: 8 | Iteration number: [3480/4518] 77% | Training loss: 0.6872345924206164
Epoch: 8 | Iteration number: [3490/4518] 77% | Training loss: 0.6872365292300467
Epoch: 8 | Iteration number: [3500/4518] 77% | Training loss: 0.6872373578889029
Epoch: 8 | Iteration number: [3510/4518] 77% | Training loss: 0.6872390693578965
Epoch: 8 | Iteration number: [3520/4518] 77% | Training loss: 0.687237745794383
Epoch: 8 | Iteration number: [3530/4518] 78% | Training loss: 0.6872374983752415
Epoch: 8 | Iteration number: [3540/4518] 78% | Training loss: 0.6872376073888466
Epoch: 8 | Iteration number: [3550/4518] 78% | Training loss: 0.6872346589430957
Epoch: 8 | Iteration number: [3560/4518] 78% | Training loss: 0.687234311709913
Epoch: 8 | Iteration number: [3570/4518] 79% | Training loss: 0.6872307396402546
Epoch: 8 | Iteration number: [3580/4518] 79% | Training loss: 0.6872289477779878
Epoch: 8 | Iteration number: [3590/4518] 79% | Training loss: 0.6872272925788646
Epoch: 8 | Iteration number: [3600/4518] 79% | Training loss: 0.6872230515049563
Epoch: 8 | Iteration number: [3610/4518] 79% | Training loss: 0.6872234852030007
Epoch: 8 | Iteration number: [3620/4518] 80% | Training loss: 0.6872230068425447
Epoch: 8 | Iteration number: [3630/4518] 80% | Training loss: 0.687219666925672
Epoch: 8 | Iteration number: [3640/4518] 80% | Training loss: 0.6872221206079473
Epoch: 8 | Iteration number: [3650/4518] 80% | Training loss: 0.6872197383397246
Epoch: 8 | Iteration number: [3660/4518] 81% | Training loss: 0.6872177747755103
Epoch: 8 | Iteration number: [3670/4518] 81% | Training loss: 0.6872171774222351
Epoch: 8 | Iteration number: [3680/4518] 81% | Training loss: 0.6872181783875694
Epoch: 8 | Iteration number: [3690/4518] 81% | Training loss: 0.6872160485281854
Epoch: 8 | Iteration number: [3700/4518] 81% | Training loss: 0.6872171519736986
Epoch: 8 | Iteration number: [3710/4518] 82% | Training loss: 0.6872152563053964
Epoch: 8 | Iteration number: [3720/4518] 82% | Training loss: 0.6872163191437721
Epoch: 8 | Iteration number: [3730/4518] 82% | Training loss: 0.6872184752459181
Epoch: 8 | Iteration number: [3740/4518] 82% | Training loss: 0.6872163447944876
Epoch: 8 | Iteration number: [3750/4518] 83% | Training loss: 0.6872136115233104
Epoch: 8 | Iteration number: [3760/4518] 83% | Training loss: 0.6872130292210173
Epoch: 8 | Iteration number: [3770/4518] 83% | Training loss: 0.6872120860558922
Epoch: 8 | Iteration number: [3780/4518] 83% | Training loss: 0.6872109249155357
Epoch: 8 | Iteration number: [3790/4518] 83% | Training loss: 0.6872104218893127
Epoch: 8 | Iteration number: [3800/4518] 84% | Training loss: 0.68721195012331
Epoch: 8 | Iteration number: [3810/4518] 84% | Training loss: 0.6872106768953519
Epoch: 8 | Iteration number: [3820/4518] 84% | Training loss: 0.6872125271571244
Epoch: 8 | Iteration number: [3830/4518] 84% | Training loss: 0.6872106074975614
Epoch: 8 | Iteration number: [3840/4518] 84% | Training loss: 0.6872071864704291
Epoch: 8 | Iteration number: [3850/4518] 85% | Training loss: 0.6872044671975173
Epoch: 8 | Iteration number: [3860/4518] 85% | Training loss: 0.6872045209988411
Epoch: 8 | Iteration number: [3870/4518] 85% | Training loss: 0.6872062155288627
Epoch: 8 | Iteration number: [3880/4518] 85% | Training loss: 0.6872071463576297
Epoch: 8 | Iteration number: [3890/4518] 86% | Training loss: 0.6872079084342427
Epoch: 8 | Iteration number: [3900/4518] 86% | Training loss: 0.6872073778586509
Epoch: 8 | Iteration number: [3910/4518] 86% | Training loss: 0.6872079659758321
Epoch: 8 | Iteration number: [3920/4518] 86% | Training loss: 0.6872090695615933
Epoch: 8 | Iteration number: [3930/4518] 86% | Training loss: 0.6872064128935186
Epoch: 8 | Iteration number: [3940/4518] 87% | Training loss: 0.687209667046058
Epoch: 8 | Iteration number: [3950/4518] 87% | Training loss: 0.6872079217886623
Epoch: 8 | Iteration number: [3960/4518] 87% | Training loss: 0.6872047661380334
Epoch: 8 | Iteration number: [3970/4518] 87% | Training loss: 0.6872032311611271
Epoch: 8 | Iteration number: [3980/4518] 88% | Training loss: 0.6872024089547258
Epoch: 8 | Iteration number: [3990/4518] 88% | Training loss: 0.687204199879988
Epoch: 8 | Iteration number: [4000/4518] 88% | Training loss: 0.6872073971778154
Epoch: 8 | Iteration number: [4010/4518] 88% | Training loss: 0.6872071527632098
Epoch: 8 | Iteration number: [4020/4518] 88% | Training loss: 0.687207381701588
Epoch: 8 | Iteration number: [4030/4518] 89% | Training loss: 0.6872057194745275
Epoch: 8 | Iteration number: [4040/4518] 89% | Training loss: 0.6872060633089283
Epoch: 8 | Iteration number: [4050/4518] 89% | Training loss: 0.6872088620250608
Epoch: 8 | Iteration number: [4060/4518] 89% | Training loss: 0.6872054615044242
Epoch: 8 | Iteration number: [4070/4518] 90% | Training loss: 0.6872030780707882
Epoch: 8 | Iteration number: [4080/4518] 90% | Training loss: 0.6871986861760709
Epoch: 8 | Iteration number: [4090/4518] 90% | Training loss: 0.6871965213189206
Epoch: 8 | Iteration number: [4100/4518] 90% | Training loss: 0.6871958392713128
Epoch: 8 | Iteration number: [4110/4518] 90% | Training loss: 0.6871976031149101
Epoch: 8 | Iteration number: [4120/4518] 91% | Training loss: 0.6871979739046791
Epoch: 8 | Iteration number: [4130/4518] 91% | Training loss: 0.6871967655117229
Epoch: 8 | Iteration number: [4140/4518] 91% | Training loss: 0.6871976460667624
Epoch: 8 | Iteration number: [4150/4518] 91% | Training loss: 0.6871978885868946
Epoch: 8 | Iteration number: [4160/4518] 92% | Training loss: 0.6871989655953187
Epoch: 8 | Iteration number: [4170/4518] 92% | Training loss: 0.687198461860204
Epoch: 8 | Iteration number: [4180/4518] 92% | Training loss: 0.6871963196679165
Epoch: 8 | Iteration number: [4190/4518] 92% | Training loss: 0.6871965802370221
Epoch: 8 | Iteration number: [4200/4518] 92% | Training loss: 0.6871944552943821
Epoch: 8 | Iteration number: [4210/4518] 93% | Training loss: 0.6871971758697492
Epoch: 8 | Iteration number: [4220/4518] 93% | Training loss: 0.6871971105794771
Epoch: 8 | Iteration number: [4230/4518] 93% | Training loss: 0.6871968914994675
Epoch: 8 | Iteration number: [4240/4518] 93% | Training loss: 0.6871955993040553
Epoch: 8 | Iteration number: [4250/4518] 94% | Training loss: 0.6871928155001472
Epoch: 8 | Iteration number: [4260/4518] 94% | Training loss: 0.6871914523728017
Epoch: 8 | Iteration number: [4270/4518] 94% | Training loss: 0.6871902635840119
Epoch: 8 | Iteration number: [4280/4518] 94% | Training loss: 0.6871898486792484
Epoch: 8 | Iteration number: [4290/4518] 94% | Training loss: 0.6871907485392822
Epoch: 8 | Iteration number: [4300/4518] 95% | Training loss: 0.6871895469343939
Epoch: 8 | Iteration number: [4310/4518] 95% | Training loss: 0.6871874987664189
Epoch: 8 | Iteration number: [4320/4518] 95% | Training loss: 0.6871873333636257
Epoch: 8 | Iteration number: [4330/4518] 95% | Training loss: 0.6871848263448711
Epoch: 8 | Iteration number: [4340/4518] 96% | Training loss: 0.6871851357996189
Epoch: 8 | Iteration number: [4350/4518] 96% | Training loss: 0.6871843183451686
Epoch: 8 | Iteration number: [4360/4518] 96% | Training loss: 0.6871825979390276
Epoch: 8 | Iteration number: [4370/4518] 96% | Training loss: 0.6871824747501304
Epoch: 8 | Iteration number: [4380/4518] 96% | Training loss: 0.6871809861975717
Epoch: 8 | Iteration number: [4390/4518] 97% | Training loss: 0.6871797415145708
Epoch: 8 | Iteration number: [4400/4518] 97% | Training loss: 0.6871809397366914
Epoch: 8 | Iteration number: [4410/4518] 97% | Training loss: 0.6871788681499542
Epoch: 8 | Iteration number: [4420/4518] 97% | Training loss: 0.687178241545798
Epoch: 8 | Iteration number: [4430/4518] 98% | Training loss: 0.6871758621783074
Epoch: 8 | Iteration number: [4440/4518] 98% | Training loss: 0.6871764448311952
Epoch: 8 | Iteration number: [4450/4518] 98% | Training loss: 0.6871773503469617
Epoch: 8 | Iteration number: [4460/4518] 98% | Training loss: 0.6871759531476572
Epoch: 8 | Iteration number: [4470/4518] 98% | Training loss: 0.6871734654210024
Epoch: 8 | Iteration number: [4480/4518] 99% | Training loss: 0.6871720673649439
Epoch: 8 | Iteration number: [4490/4518] 99% | Training loss: 0.6871694285381079
Epoch: 8 | Iteration number: [4500/4518] 99% | Training loss: 0.6871696571906407
Epoch: 8 | Iteration number: [4510/4518] 99% | Training loss: 0.6871703335953393

 End of epoch: 8 | Train Loss: 0.6870159560624031 | Training Time: 631 

 End of epoch: 8 | Eval Loss: 0.6901170209962495 | Evaluating Time: 17 
Epoch: 9 | Iteration number: [10/4518] 0% | Training loss: 0.7547602951526642
Epoch: 9 | Iteration number: [20/4518] 0% | Training loss: 0.7211364507675171
Epoch: 9 | Iteration number: [30/4518] 0% | Training loss: 0.7095261832078298
Epoch: 9 | Iteration number: [40/4518] 0% | Training loss: 0.7038856521248817
Epoch: 9 | Iteration number: [50/4518] 1% | Training loss: 0.7004423487186432
Epoch: 9 | Iteration number: [60/4518] 1% | Training loss: 0.6982662002245585
Epoch: 9 | Iteration number: [70/4518] 1% | Training loss: 0.6965810673577445
Epoch: 9 | Iteration number: [80/4518] 1% | Training loss: 0.6951126024127007
Epoch: 9 | Iteration number: [90/4518] 1% | Training loss: 0.6941438761022356
Epoch: 9 | Iteration number: [100/4518] 2% | Training loss: 0.6933611422777176
Epoch: 9 | Iteration number: [110/4518] 2% | Training loss: 0.6928368438373912
Epoch: 9 | Iteration number: [120/4518] 2% | Training loss: 0.6924740831057231
Epoch: 9 | Iteration number: [130/4518] 2% | Training loss: 0.6920635677300967
Epoch: 9 | Iteration number: [140/4518] 3% | Training loss: 0.6916421238865171
Epoch: 9 | Iteration number: [150/4518] 3% | Training loss: 0.6913622609774271
Epoch: 9 | Iteration number: [160/4518] 3% | Training loss: 0.6911424119025469
Epoch: 9 | Iteration number: [170/4518] 3% | Training loss: 0.6908869508434744
Epoch: 9 | Iteration number: [180/4518] 3% | Training loss: 0.6906920353571574
Epoch: 9 | Iteration number: [190/4518] 4% | Training loss: 0.6904333033059773
Epoch: 9 | Iteration number: [200/4518] 4% | Training loss: 0.6902959609031677
Epoch: 9 | Iteration number: [210/4518] 4% | Training loss: 0.6900784279618944
Epoch: 9 | Iteration number: [220/4518] 4% | Training loss: 0.6898747525431893
Epoch: 9 | Iteration number: [230/4518] 5% | Training loss: 0.689715613230415
Epoch: 9 | Iteration number: [240/4518] 5% | Training loss: 0.6896131674448649
Epoch: 9 | Iteration number: [250/4518] 5% | Training loss: 0.6895120298862457
Epoch: 9 | Iteration number: [260/4518] 5% | Training loss: 0.6894222408533096
Epoch: 9 | Iteration number: [270/4518] 5% | Training loss: 0.6892840500231142
Epoch: 9 | Iteration number: [280/4518] 6% | Training loss: 0.6892164922186307
Epoch: 9 | Iteration number: [290/4518] 6% | Training loss: 0.6891179931574855
Epoch: 9 | Iteration number: [300/4518] 6% | Training loss: 0.6890445069471995
Epoch: 9 | Iteration number: [310/4518] 6% | Training loss: 0.6889376813365568
Epoch: 9 | Iteration number: [320/4518] 7% | Training loss: 0.688869834691286
Epoch: 9 | Iteration number: [330/4518] 7% | Training loss: 0.6888575140273933
Epoch: 9 | Iteration number: [340/4518] 7% | Training loss: 0.688781579803018
Epoch: 9 | Iteration number: [350/4518] 7% | Training loss: 0.6887491975511824
Epoch: 9 | Iteration number: [360/4518] 7% | Training loss: 0.6887405008077622
Epoch: 9 | Iteration number: [370/4518] 8% | Training loss: 0.6886797983904143
Epoch: 9 | Iteration number: [380/4518] 8% | Training loss: 0.6886606252507159
Epoch: 9 | Iteration number: [390/4518] 8% | Training loss: 0.6886084394577222
Epoch: 9 | Iteration number: [400/4518] 8% | Training loss: 0.6885683627426624
Epoch: 9 | Iteration number: [410/4518] 9% | Training loss: 0.6885464315007372
Epoch: 9 | Iteration number: [420/4518] 9% | Training loss: 0.6885260171833493
Epoch: 9 | Iteration number: [430/4518] 9% | Training loss: 0.6884927365668985
Epoch: 9 | Iteration number: [440/4518] 9% | Training loss: 0.6884933104569262
Epoch: 9 | Iteration number: [450/4518] 9% | Training loss: 0.6884689691331651
Epoch: 9 | Iteration number: [460/4518] 10% | Training loss: 0.6884491105442462
Epoch: 9 | Iteration number: [470/4518] 10% | Training loss: 0.6884123112293
Epoch: 9 | Iteration number: [480/4518] 10% | Training loss: 0.6884116869419813
Epoch: 9 | Iteration number: [490/4518] 10% | Training loss: 0.6883735717559347
Epoch: 9 | Iteration number: [500/4518] 11% | Training loss: 0.6883500325679779
Epoch: 9 | Iteration number: [510/4518] 11% | Training loss: 0.6883271912733714
Epoch: 9 | Iteration number: [520/4518] 11% | Training loss: 0.6883127413116968
Epoch: 9 | Iteration number: [530/4518] 11% | Training loss: 0.6882741766155891
Epoch: 9 | Iteration number: [540/4518] 11% | Training loss: 0.6882551914011991
Epoch: 9 | Iteration number: [550/4518] 12% | Training loss: 0.6882345324212854
Epoch: 9 | Iteration number: [560/4518] 12% | Training loss: 0.6882015609315464
Epoch: 9 | Iteration number: [570/4518] 12% | Training loss: 0.6881826167566735
Epoch: 9 | Iteration number: [580/4518] 12% | Training loss: 0.6881474065369573
Epoch: 9 | Iteration number: [590/4518] 13% | Training loss: 0.688139539653972
Epoch: 9 | Iteration number: [600/4518] 13% | Training loss: 0.6881284177303314
Epoch: 9 | Iteration number: [610/4518] 13% | Training loss: 0.6880853426261027
Epoch: 9 | Iteration number: [620/4518] 13% | Training loss: 0.6880752349092114
Epoch: 9 | Iteration number: [630/4518] 13% | Training loss: 0.6880642651565492
Epoch: 9 | Iteration number: [640/4518] 14% | Training loss: 0.6880343236960471
Epoch: 9 | Iteration number: [650/4518] 14% | Training loss: 0.6880065420957712
Epoch: 9 | Iteration number: [660/4518] 14% | Training loss: 0.6879839315558924
Epoch: 9 | Iteration number: [670/4518] 14% | Training loss: 0.6879698186667997
Epoch: 9 | Iteration number: [680/4518] 15% | Training loss: 0.687949309980168
Epoch: 9 | Iteration number: [690/4518] 15% | Training loss: 0.6879354249739993
Epoch: 9 | Iteration number: [700/4518] 15% | Training loss: 0.6879177627393177
Epoch: 9 | Iteration number: [710/4518] 15% | Training loss: 0.6878947160613369
Epoch: 9 | Iteration number: [720/4518] 15% | Training loss: 0.6878827311098575
Epoch: 9 | Iteration number: [730/4518] 16% | Training loss: 0.687855149703483
Epoch: 9 | Iteration number: [740/4518] 16% | Training loss: 0.6878409600741154
Epoch: 9 | Iteration number: [750/4518] 16% | Training loss: 0.6878323362668355
Epoch: 9 | Iteration number: [760/4518] 16% | Training loss: 0.6878123224565857
Epoch: 9 | Iteration number: [770/4518] 17% | Training loss: 0.6877975381039954
Epoch: 9 | Iteration number: [780/4518] 17% | Training loss: 0.6877923097365942
Epoch: 9 | Iteration number: [790/4518] 17% | Training loss: 0.6877940709077859
Epoch: 9 | Iteration number: [800/4518] 17% | Training loss: 0.6877830372005701
Epoch: 9 | Iteration number: [810/4518] 17% | Training loss: 0.6877855063220601
Epoch: 9 | Iteration number: [820/4518] 18% | Training loss: 0.6877624068318344
Epoch: 9 | Iteration number: [830/4518] 18% | Training loss: 0.6877621192529977
Epoch: 9 | Iteration number: [840/4518] 18% | Training loss: 0.6877519253463972
Epoch: 9 | Iteration number: [850/4518] 18% | Training loss: 0.6877498537652633
Epoch: 9 | Iteration number: [860/4518] 19% | Training loss: 0.6877310484647751
Epoch: 9 | Iteration number: [870/4518] 19% | Training loss: 0.6877354635589424
Epoch: 9 | Iteration number: [880/4518] 19% | Training loss: 0.6877213440158151
Epoch: 9 | Iteration number: [890/4518] 19% | Training loss: 0.6877136331595731
Epoch: 9 | Iteration number: [900/4518] 19% | Training loss: 0.6877000605397754
Epoch: 9 | Iteration number: [910/4518] 20% | Training loss: 0.6876960074508583
Epoch: 9 | Iteration number: [920/4518] 20% | Training loss: 0.6876819021675897
Epoch: 9 | Iteration number: [930/4518] 20% | Training loss: 0.6876778277017737
Epoch: 9 | Iteration number: [940/4518] 20% | Training loss: 0.6876717814105622
Epoch: 9 | Iteration number: [950/4518] 21% | Training loss: 0.6876701118444142
Epoch: 9 | Iteration number: [960/4518] 21% | Training loss: 0.687663858756423
Epoch: 9 | Iteration number: [970/4518] 21% | Training loss: 0.6876585023919332
Epoch: 9 | Iteration number: [980/4518] 21% | Training loss: 0.6876539113570233
Epoch: 9 | Iteration number: [990/4518] 21% | Training loss: 0.687648740681735
Epoch: 9 | Iteration number: [1000/4518] 22% | Training loss: 0.6876303203701973
Epoch: 9 | Iteration number: [1010/4518] 22% | Training loss: 0.6876278015646604
Epoch: 9 | Iteration number: [1020/4518] 22% | Training loss: 0.6876157517526664
Epoch: 9 | Iteration number: [1030/4518] 22% | Training loss: 0.6876012571807046
Epoch: 9 | Iteration number: [1040/4518] 23% | Training loss: 0.6876024259397617
Epoch: 9 | Iteration number: [1050/4518] 23% | Training loss: 0.6875871004944756
Epoch: 9 | Iteration number: [1060/4518] 23% | Training loss: 0.6875726697579869
Epoch: 9 | Iteration number: [1070/4518] 23% | Training loss: 0.6875631046629398
Epoch: 9 | Iteration number: [1080/4518] 23% | Training loss: 0.6875670688019858
Epoch: 9 | Iteration number: [1090/4518] 24% | Training loss: 0.6875426332884972
Epoch: 9 | Iteration number: [1100/4518] 24% | Training loss: 0.6875450979579579
Epoch: 9 | Iteration number: [1110/4518] 24% | Training loss: 0.6875386021158717
Epoch: 9 | Iteration number: [1120/4518] 24% | Training loss: 0.6875345242874963
Epoch: 9 | Iteration number: [1130/4518] 25% | Training loss: 0.6875296901812595
Epoch: 9 | Iteration number: [1140/4518] 25% | Training loss: 0.6875337365426515
Epoch: 9 | Iteration number: [1150/4518] 25% | Training loss: 0.6875234149331632
Epoch: 9 | Iteration number: [1160/4518] 25% | Training loss: 0.6875257804475982
Epoch: 9 | Iteration number: [1170/4518] 25% | Training loss: 0.6875339095918541
Epoch: 9 | Iteration number: [1180/4518] 26% | Training loss: 0.6875342350389998
Epoch: 9 | Iteration number: [1190/4518] 26% | Training loss: 0.6875362696767855
Epoch: 9 | Iteration number: [1200/4518] 26% | Training loss: 0.6875279233853022
Epoch: 9 | Iteration number: [1210/4518] 26% | Training loss: 0.6875195425404005
Epoch: 9 | Iteration number: [1220/4518] 27% | Training loss: 0.6875112287822317
Epoch: 9 | Iteration number: [1230/4518] 27% | Training loss: 0.687500007171941
Epoch: 9 | Iteration number: [1240/4518] 27% | Training loss: 0.6874918459403899
Epoch: 9 | Iteration number: [1250/4518] 27% | Training loss: 0.687499575471878
Epoch: 9 | Iteration number: [1260/4518] 27% | Training loss: 0.6874922253309734
Epoch: 9 | Iteration number: [1270/4518] 28% | Training loss: 0.6874889581222233
Epoch: 9 | Iteration number: [1280/4518] 28% | Training loss: 0.6874771222006529
Epoch: 9 | Iteration number: [1290/4518] 28% | Training loss: 0.6874709600626037
Epoch: 9 | Iteration number: [1300/4518] 28% | Training loss: 0.6874668037432891
Epoch: 9 | Iteration number: [1310/4518] 28% | Training loss: 0.6874631288852401
Epoch: 9 | Iteration number: [1320/4518] 29% | Training loss: 0.6874583117889635
Epoch: 9 | Iteration number: [1330/4518] 29% | Training loss: 0.68744533944847
Epoch: 9 | Iteration number: [1340/4518] 29% | Training loss: 0.6874446731005142
Epoch: 9 | Iteration number: [1350/4518] 29% | Training loss: 0.6874422166965626
Epoch: 9 | Iteration number: [1360/4518] 30% | Training loss: 0.6874446015585871
Epoch: 9 | Iteration number: [1370/4518] 30% | Training loss: 0.6874444768376594
Epoch: 9 | Iteration number: [1380/4518] 30% | Training loss: 0.687440941169642
Epoch: 9 | Iteration number: [1390/4518] 30% | Training loss: 0.6874369715615142
Epoch: 9 | Iteration number: [1400/4518] 30% | Training loss: 0.6874341569202287
Epoch: 9 | Iteration number: [1410/4518] 31% | Training loss: 0.687436493914178
Epoch: 9 | Iteration number: [1420/4518] 31% | Training loss: 0.6874356302577005
Epoch: 9 | Iteration number: [1430/4518] 31% | Training loss: 0.6874312068198944
Epoch: 9 | Iteration number: [1440/4518] 31% | Training loss: 0.6874308336112235
Epoch: 9 | Iteration number: [1450/4518] 32% | Training loss: 0.687422021175253
Epoch: 9 | Iteration number: [1460/4518] 32% | Training loss: 0.6874219349394106
Epoch: 9 | Iteration number: [1470/4518] 32% | Training loss: 0.6874252251216344
Epoch: 9 | Iteration number: [1480/4518] 32% | Training loss: 0.6874229845162985
Epoch: 9 | Iteration number: [1490/4518] 32% | Training loss: 0.6874267804542644
Epoch: 9 | Iteration number: [1500/4518] 33% | Training loss: 0.6874254130919775
Epoch: 9 | Iteration number: [1510/4518] 33% | Training loss: 0.6874113996297319
Epoch: 9 | Iteration number: [1520/4518] 33% | Training loss: 0.6874093702357066
Epoch: 9 | Iteration number: [1530/4518] 33% | Training loss: 0.6874136615422816
Epoch: 9 | Iteration number: [1540/4518] 34% | Training loss: 0.6874138596383008
Epoch: 9 | Iteration number: [1550/4518] 34% | Training loss: 0.6873979185473534
Epoch: 9 | Iteration number: [1560/4518] 34% | Training loss: 0.6873940414343125
Epoch: 9 | Iteration number: [1570/4518] 34% | Training loss: 0.6873932452338516
Epoch: 9 | Iteration number: [1580/4518] 34% | Training loss: 0.6873964249710494
Epoch: 9 | Iteration number: [1590/4518] 35% | Training loss: 0.6874001855745255
Epoch: 9 | Iteration number: [1600/4518] 35% | Training loss: 0.6873888975381851
Epoch: 9 | Iteration number: [1610/4518] 35% | Training loss: 0.6873874347402442
Epoch: 9 | Iteration number: [1620/4518] 35% | Training loss: 0.6873797408592554
Epoch: 9 | Iteration number: [1630/4518] 36% | Training loss: 0.6873773719269806
Epoch: 9 | Iteration number: [1640/4518] 36% | Training loss: 0.6873683953794038
Epoch: 9 | Iteration number: [1650/4518] 36% | Training loss: 0.6873620998498166
Epoch: 9 | Iteration number: [1660/4518] 36% | Training loss: 0.6873595195721431
Epoch: 9 | Iteration number: [1670/4518] 36% | Training loss: 0.6873630626829799
Epoch: 9 | Iteration number: [1680/4518] 37% | Training loss: 0.6873634594891752
Epoch: 9 | Iteration number: [1690/4518] 37% | Training loss: 0.6873599322942587
Epoch: 9 | Iteration number: [1700/4518] 37% | Training loss: 0.6873583178309833
Epoch: 9 | Iteration number: [1710/4518] 37% | Training loss: 0.6873539385042693
Epoch: 9 | Iteration number: [1720/4518] 38% | Training loss: 0.6873493382750555
Epoch: 9 | Iteration number: [1730/4518] 38% | Training loss: 0.6873510064417228
Epoch: 9 | Iteration number: [1740/4518] 38% | Training loss: 0.687340512666209
Epoch: 9 | Iteration number: [1750/4518] 38% | Training loss: 0.6873444824559348
Epoch: 9 | Iteration number: [1760/4518] 38% | Training loss: 0.6873460765250704
Epoch: 9 | Iteration number: [1770/4518] 39% | Training loss: 0.6873452342836197
Epoch: 9 | Iteration number: [1780/4518] 39% | Training loss: 0.6873455355006657
Epoch: 9 | Iteration number: [1790/4518] 39% | Training loss: 0.6873401854291309
Epoch: 9 | Iteration number: [1800/4518] 39% | Training loss: 0.6873412695527077
Epoch: 9 | Iteration number: [1810/4518] 40% | Training loss: 0.6873348315447075
Epoch: 9 | Iteration number: [1820/4518] 40% | Training loss: 0.6873354246000667
Epoch: 9 | Iteration number: [1830/4518] 40% | Training loss: 0.6873345511532872
Epoch: 9 | Iteration number: [1840/4518] 40% | Training loss: 0.6873330047920995
Epoch: 9 | Iteration number: [1850/4518] 40% | Training loss: 0.6873231792449951
Epoch: 9 | Iteration number: [1860/4518] 41% | Training loss: 0.6873192959895698
Epoch: 9 | Iteration number: [1870/4518] 41% | Training loss: 0.687317859807754
Epoch: 9 | Iteration number: [1880/4518] 41% | Training loss: 0.6873137397017884
Epoch: 9 | Iteration number: [1890/4518] 41% | Training loss: 0.6873165780589694
Epoch: 9 | Iteration number: [1900/4518] 42% | Training loss: 0.6873165994882584
Epoch: 9 | Iteration number: [1910/4518] 42% | Training loss: 0.6873153270227123
Epoch: 9 | Iteration number: [1920/4518] 42% | Training loss: 0.6873160313193997
Epoch: 9 | Iteration number: [1930/4518] 42% | Training loss: 0.6873151448724183
Epoch: 9 | Iteration number: [1940/4518] 42% | Training loss: 0.6873196676219862
Epoch: 9 | Iteration number: [1950/4518] 43% | Training loss: 0.6873253836081579
Epoch: 9 | Iteration number: [1960/4518] 43% | Training loss: 0.6873273208737374
Epoch: 9 | Iteration number: [1970/4518] 43% | Training loss: 0.6873302129016915
Epoch: 9 | Iteration number: [1980/4518] 43% | Training loss: 0.6873278214172883
Epoch: 9 | Iteration number: [1990/4518] 44% | Training loss: 0.6873325959521921
Epoch: 9 | Iteration number: [2000/4518] 44% | Training loss: 0.6873219329416752
Epoch: 9 | Iteration number: [2010/4518] 44% | Training loss: 0.6873228347123559
Epoch: 9 | Iteration number: [2020/4518] 44% | Training loss: 0.6873241099390653
Epoch: 9 | Iteration number: [2030/4518] 44% | Training loss: 0.6873250386985065
Epoch: 9 | Iteration number: [2040/4518] 45% | Training loss: 0.6873246610749002
Epoch: 9 | Iteration number: [2050/4518] 45% | Training loss: 0.6873193327101266
Epoch: 9 | Iteration number: [2060/4518] 45% | Training loss: 0.6873159812492075
Epoch: 9 | Iteration number: [2070/4518] 45% | Training loss: 0.6873128597287165
Epoch: 9 | Iteration number: [2080/4518] 46% | Training loss: 0.6873101472854615
Epoch: 9 | Iteration number: [2090/4518] 46% | Training loss: 0.6873088389492491
Epoch: 9 | Iteration number: [2100/4518] 46% | Training loss: 0.6873076933906191
Epoch: 9 | Iteration number: [2110/4518] 46% | Training loss: 0.68730166825638
Epoch: 9 | Iteration number: [2120/4518] 46% | Training loss: 0.687306990404174
Epoch: 9 | Iteration number: [2130/4518] 47% | Training loss: 0.6873094612164117
Epoch: 9 | Iteration number: [2140/4518] 47% | Training loss: 0.6873113956406852
Epoch: 9 | Iteration number: [2150/4518] 47% | Training loss: 0.6873056400931159
Epoch: 9 | Iteration number: [2160/4518] 47% | Training loss: 0.6873094266211545
Epoch: 9 | Iteration number: [2170/4518] 48% | Training loss: 0.6873145042751242
Epoch: 9 | Iteration number: [2180/4518] 48% | Training loss: 0.6873202457887317
Epoch: 9 | Iteration number: [2190/4518] 48% | Training loss: 0.6873155330958431
Epoch: 9 | Iteration number: [2200/4518] 48% | Training loss: 0.6873170930959962
Epoch: 9 | Iteration number: [2210/4518] 48% | Training loss: 0.6873146815537328
Epoch: 9 | Iteration number: [2220/4518] 49% | Training loss: 0.6873141785462697
Epoch: 9 | Iteration number: [2230/4518] 49% | Training loss: 0.687311578732435
Epoch: 9 | Iteration number: [2240/4518] 49% | Training loss: 0.6873074237257242
Epoch: 9 | Iteration number: [2250/4518] 49% | Training loss: 0.687304418987698
Epoch: 9 | Iteration number: [2260/4518] 50% | Training loss: 0.6872943188500615
Epoch: 9 | Iteration number: [2270/4518] 50% | Training loss: 0.6872938320762786
Epoch: 9 | Iteration number: [2280/4518] 50% | Training loss: 0.687288792666636
Epoch: 9 | Iteration number: [2290/4518] 50% | Training loss: 0.6872901176000786
Epoch: 9 | Iteration number: [2300/4518] 50% | Training loss: 0.6872955280801524
Epoch: 9 | Iteration number: [2310/4518] 51% | Training loss: 0.6872968351686156
Epoch: 9 | Iteration number: [2320/4518] 51% | Training loss: 0.6872989481636163
Epoch: 9 | Iteration number: [2330/4518] 51% | Training loss: 0.6872990082517714
Epoch: 9 | Iteration number: [2340/4518] 51% | Training loss: 0.6873000669937868
Epoch: 9 | Iteration number: [2350/4518] 52% | Training loss: 0.6872980135045152
Epoch: 9 | Iteration number: [2360/4518] 52% | Training loss: 0.6872984103479628
Epoch: 9 | Iteration number: [2370/4518] 52% | Training loss: 0.6872950585079596
Epoch: 9 | Iteration number: [2380/4518] 52% | Training loss: 0.6872916781852225
Epoch: 9 | Iteration number: [2390/4518] 52% | Training loss: 0.6872908225867539
Epoch: 9 | Iteration number: [2400/4518] 53% | Training loss: 0.687288321480155
Epoch: 9 | Iteration number: [2410/4518] 53% | Training loss: 0.6872880248607937
Epoch: 9 | Iteration number: [2420/4518] 53% | Training loss: 0.6872829614099393
Epoch: 9 | Iteration number: [2430/4518] 53% | Training loss: 0.6872866004582786
Epoch: 9 | Iteration number: [2440/4518] 54% | Training loss: 0.6872880742686693
Epoch: 9 | Iteration number: [2450/4518] 54% | Training loss: 0.6872885285591592
Epoch: 9 | Iteration number: [2460/4518] 54% | Training loss: 0.6872898237976601
Epoch: 9 | Iteration number: [2470/4518] 54% | Training loss: 0.6872933894033857
Epoch: 9 | Iteration number: [2480/4518] 54% | Training loss: 0.6872898719724148
Epoch: 9 | Iteration number: [2490/4518] 55% | Training loss: 0.6872924717554606
Epoch: 9 | Iteration number: [2500/4518] 55% | Training loss: 0.6872957691907883
Epoch: 9 | Iteration number: [2510/4518] 55% | Training loss: 0.6873020006365985
Epoch: 9 | Iteration number: [2520/4518] 55% | Training loss: 0.6873009988003307
Epoch: 9 | Iteration number: [2530/4518] 55% | Training loss: 0.6873023773606116
Epoch: 9 | Iteration number: [2540/4518] 56% | Training loss: 0.6872990899902629
Epoch: 9 | Iteration number: [2550/4518] 56% | Training loss: 0.6873008099256778
Epoch: 9 | Iteration number: [2560/4518] 56% | Training loss: 0.6872948999749496
Epoch: 9 | Iteration number: [2570/4518] 56% | Training loss: 0.6872962353294462
Epoch: 9 | Iteration number: [2580/4518] 57% | Training loss: 0.6872938222432321
Epoch: 9 | Iteration number: [2590/4518] 57% | Training loss: 0.6872924662004567
Epoch: 9 | Iteration number: [2600/4518] 57% | Training loss: 0.687288786310416
Epoch: 9 | Iteration number: [2610/4518] 57% | Training loss: 0.6872837052948173
Epoch: 9 | Iteration number: [2620/4518] 57% | Training loss: 0.6872820510664059
Epoch: 9 | Iteration number: [2630/4518] 58% | Training loss: 0.6872763761096128
Epoch: 9 | Iteration number: [2640/4518] 58% | Training loss: 0.6872772064850186
Epoch: 9 | Iteration number: [2650/4518] 58% | Training loss: 0.6872711915564987
Epoch: 9 | Iteration number: [2660/4518] 58% | Training loss: 0.687271025418339
Epoch: 9 | Iteration number: [2670/4518] 59% | Training loss: 0.6872679533583395
Epoch: 9 | Iteration number: [2680/4518] 59% | Training loss: 0.6872688151784797
Epoch: 9 | Iteration number: [2690/4518] 59% | Training loss: 0.6872648651715105
Epoch: 9 | Iteration number: [2700/4518] 59% | Training loss: 0.6872600092269756
Epoch: 9 | Iteration number: [2710/4518] 59% | Training loss: 0.6872561985496225
Epoch: 9 | Iteration number: [2720/4518] 60% | Training loss: 0.687253020024475
Epoch: 9 | Iteration number: [2730/4518] 60% | Training loss: 0.6872519752918146
Epoch: 9 | Iteration number: [2740/4518] 60% | Training loss: 0.6872526703959834
Epoch: 9 | Iteration number: [2750/4518] 60% | Training loss: 0.6872486793127927
Epoch: 9 | Iteration number: [2760/4518] 61% | Training loss: 0.6872477929445281
Epoch: 9 | Iteration number: [2770/4518] 61% | Training loss: 0.6872515454834549
Epoch: 9 | Iteration number: [2780/4518] 61% | Training loss: 0.6872492997123183
Epoch: 9 | Iteration number: [2790/4518] 61% | Training loss: 0.6872492100602837
Epoch: 9 | Iteration number: [2800/4518] 61% | Training loss: 0.6872479127560343
Epoch: 9 | Iteration number: [2810/4518] 62% | Training loss: 0.6872432822646619
Epoch: 9 | Iteration number: [2820/4518] 62% | Training loss: 0.687241722463716
Epoch: 9 | Iteration number: [2830/4518] 62% | Training loss: 0.6872417101169223
Epoch: 9 | Iteration number: [2840/4518] 62% | Training loss: 0.6872377224371466
Epoch: 9 | Iteration number: [2850/4518] 63% | Training loss: 0.6872373882929484
Epoch: 9 | Iteration number: [2860/4518] 63% | Training loss: 0.6872347156484644
Epoch: 9 | Iteration number: [2870/4518] 63% | Training loss: 0.6872302496059431
Epoch: 9 | Iteration number: [2880/4518] 63% | Training loss: 0.6872256882074806
Epoch: 9 | Iteration number: [2890/4518] 63% | Training loss: 0.6872226311673755
Epoch: 9 | Iteration number: [2900/4518] 64% | Training loss: 0.6872197657823562
Epoch: 9 | Iteration number: [2910/4518] 64% | Training loss: 0.6872199915733535
Epoch: 9 | Iteration number: [2920/4518] 64% | Training loss: 0.6872176596359031
Epoch: 9 | Iteration number: [2930/4518] 64% | Training loss: 0.6872153069175551
Epoch: 9 | Iteration number: [2940/4518] 65% | Training loss: 0.6872143929101983
Epoch: 9 | Iteration number: [2950/4518] 65% | Training loss: 0.6872178495334367
Epoch: 9 | Iteration number: [2960/4518] 65% | Training loss: 0.6872174564245584
Epoch: 9 | Iteration number: [2970/4518] 65% | Training loss: 0.6872173736793826
Epoch: 9 | Iteration number: [2980/4518] 65% | Training loss: 0.6872182852069804
Epoch: 9 | Iteration number: [2990/4518] 66% | Training loss: 0.6872146165091856
Epoch: 9 | Iteration number: [3000/4518] 66% | Training loss: 0.6872129693627358
Epoch: 9 | Iteration number: [3010/4518] 66% | Training loss: 0.6872095113378822
Epoch: 9 | Iteration number: [3020/4518] 66% | Training loss: 0.6872122145646455
Epoch: 9 | Iteration number: [3030/4518] 67% | Training loss: 0.6872074623902639
Epoch: 9 | Iteration number: [3040/4518] 67% | Training loss: 0.6872036179821742
Epoch: 9 | Iteration number: [3050/4518] 67% | Training loss: 0.6872008373502825
Epoch: 9 | Iteration number: [3060/4518] 67% | Training loss: 0.6872018578005772
Epoch: 9 | Iteration number: [3070/4518] 67% | Training loss: 0.6872026396690828
Epoch: 9 | Iteration number: [3080/4518] 68% | Training loss: 0.6871985403941824
Epoch: 9 | Iteration number: [3090/4518] 68% | Training loss: 0.6872019527413699
Epoch: 9 | Iteration number: [3100/4518] 68% | Training loss: 0.6872004631450099
Epoch: 9 | Iteration number: [3110/4518] 68% | Training loss: 0.6872010414431716
Epoch: 9 | Iteration number: [3120/4518] 69% | Training loss: 0.6871971301925488
Epoch: 9 | Iteration number: [3130/4518] 69% | Training loss: 0.6871970794642696
Epoch: 9 | Iteration number: [3140/4518] 69% | Training loss: 0.6871985340953632
Epoch: 9 | Iteration number: [3150/4518] 69% | Training loss: 0.687199968951089
Epoch: 9 | Iteration number: [3160/4518] 69% | Training loss: 0.6872003275382368
Epoch: 9 | Iteration number: [3170/4518] 70% | Training loss: 0.687198101139219
Epoch: 9 | Iteration number: [3180/4518] 70% | Training loss: 0.687195044924628
Epoch: 9 | Iteration number: [3190/4518] 70% | Training loss: 0.6871981452998697
Epoch: 9 | Iteration number: [3200/4518] 70% | Training loss: 0.6872014744207263
Epoch: 9 | Iteration number: [3210/4518] 71% | Training loss: 0.6872019337345135
Epoch: 9 | Iteration number: [3220/4518] 71% | Training loss: 0.6872040107013276
Epoch: 9 | Iteration number: [3230/4518] 71% | Training loss: 0.6872028587218778
Epoch: 9 | Iteration number: [3240/4518] 71% | Training loss: 0.6871980361548471
Epoch: 9 | Iteration number: [3250/4518] 71% | Training loss: 0.6872003825994638
Epoch: 9 | Iteration number: [3260/4518] 72% | Training loss: 0.6871973849330212
Epoch: 9 | Iteration number: [3270/4518] 72% | Training loss: 0.6871910641135062
Epoch: 9 | Iteration number: [3280/4518] 72% | Training loss: 0.6871925080513082
Epoch: 9 | Iteration number: [3290/4518] 72% | Training loss: 0.6871903977676728
Epoch: 9 | Iteration number: [3300/4518] 73% | Training loss: 0.687187523896044
Epoch: 9 | Iteration number: [3310/4518] 73% | Training loss: 0.6871875636347111
Epoch: 9 | Iteration number: [3320/4518] 73% | Training loss: 0.6871897516839476
Epoch: 9 | Iteration number: [3330/4518] 73% | Training loss: 0.6871842897690095
Epoch: 9 | Iteration number: [3340/4518] 73% | Training loss: 0.6871784159344827
Epoch: 9 | Iteration number: [3350/4518] 74% | Training loss: 0.687180741224716
Epoch: 9 | Iteration number: [3360/4518] 74% | Training loss: 0.6871790053056819
Epoch: 9 | Iteration number: [3370/4518] 74% | Training loss: 0.6871786067853696
Epoch: 9 | Iteration number: [3380/4518] 74% | Training loss: 0.6871806355975789
Epoch: 9 | Iteration number: [3390/4518] 75% | Training loss: 0.6871816970957416
Epoch: 9 | Iteration number: [3400/4518] 75% | Training loss: 0.6871797901917907
Epoch: 9 | Iteration number: [3410/4518] 75% | Training loss: 0.6871804391184161
Epoch: 9 | Iteration number: [3420/4518] 75% | Training loss: 0.6871781799179769
Epoch: 9 | Iteration number: [3430/4518] 75% | Training loss: 0.6871790159547989
Epoch: 9 | Iteration number: [3440/4518] 76% | Training loss: 0.6871812354859917
Epoch: 9 | Iteration number: [3450/4518] 76% | Training loss: 0.6871791653874991
Epoch: 9 | Iteration number: [3460/4518] 76% | Training loss: 0.6871810110490446
Epoch: 9 | Iteration number: [3470/4518] 76% | Training loss: 0.6871781723643586
Epoch: 9 | Iteration number: [3480/4518] 77% | Training loss: 0.6871775063975104
Epoch: 9 | Iteration number: [3490/4518] 77% | Training loss: 0.6871773839167674
Epoch: 9 | Iteration number: [3500/4518] 77% | Training loss: 0.6871749618564333
Epoch: 9 | Iteration number: [3510/4518] 77% | Training loss: 0.6871768817602739
Epoch: 9 | Iteration number: [3520/4518] 77% | Training loss: 0.6871775419535961
Epoch: 9 | Iteration number: [3530/4518] 78% | Training loss: 0.6871763180740832
Epoch: 9 | Iteration number: [3540/4518] 78% | Training loss: 0.6871724107339557
Epoch: 9 | Iteration number: [3550/4518] 78% | Training loss: 0.6871733391452843
Epoch: 9 | Iteration number: [3560/4518] 78% | Training loss: 0.6871735328703784
Epoch: 9 | Iteration number: [3570/4518] 79% | Training loss: 0.6871725904173543
Epoch: 9 | Iteration number: [3580/4518] 79% | Training loss: 0.6871733084570762
Epoch: 9 | Iteration number: [3590/4518] 79% | Training loss: 0.6871717008707583
Epoch: 9 | Iteration number: [3600/4518] 79% | Training loss: 0.6871707550353474
Epoch: 9 | Iteration number: [3610/4518] 79% | Training loss: 0.6871712419960307
Epoch: 9 | Iteration number: [3620/4518] 80% | Training loss: 0.6871721609027346
Epoch: 9 | Iteration number: [3630/4518] 80% | Training loss: 0.6871741009645226
Epoch: 9 | Iteration number: [3640/4518] 80% | Training loss: 0.6871758072749599
Epoch: 9 | Iteration number: [3650/4518] 80% | Training loss: 0.6871759249739451
Epoch: 9 | Iteration number: [3660/4518] 81% | Training loss: 0.6871750178558579
Epoch: 9 | Iteration number: [3670/4518] 81% | Training loss: 0.6871753434556707
Epoch: 9 | Iteration number: [3680/4518] 81% | Training loss: 0.6871765187253123
Epoch: 9 | Iteration number: [3690/4518] 81% | Training loss: 0.687176912279956
Epoch: 9 | Iteration number: [3700/4518] 81% | Training loss: 0.6871760156025758
Epoch: 9 | Iteration number: [3710/4518] 82% | Training loss: 0.687174977735689
Epoch: 9 | Iteration number: [3720/4518] 82% | Training loss: 0.6871753355187754
Epoch: 9 | Iteration number: [3730/4518] 82% | Training loss: 0.687174597422495
Epoch: 9 | Iteration number: [3740/4518] 82% | Training loss: 0.6871725736454847
Epoch: 9 | Iteration number: [3750/4518] 83% | Training loss: 0.6871732439200083
Epoch: 9 | Iteration number: [3760/4518] 83% | Training loss: 0.687172261023141
Epoch: 9 | Iteration number: [3770/4518] 83% | Training loss: 0.6871727660733129
Epoch: 9 | Iteration number: [3780/4518] 83% | Training loss: 0.6871755859208486
Epoch: 9 | Iteration number: [3790/4518] 83% | Training loss: 0.6871703832319356
Epoch: 9 | Iteration number: [3800/4518] 84% | Training loss: 0.6871709510370305
Epoch: 9 | Iteration number: [3810/4518] 84% | Training loss: 0.6871666131057138
Epoch: 9 | Iteration number: [3820/4518] 84% | Training loss: 0.6871674639080207
Epoch: 9 | Iteration number: [3830/4518] 84% | Training loss: 0.6871658313212133
Epoch: 9 | Iteration number: [3840/4518] 84% | Training loss: 0.6871679159036527
Epoch: 9 | Iteration number: [3850/4518] 85% | Training loss: 0.6871665051540771
Epoch: 9 | Iteration number: [3860/4518] 85% | Training loss: 0.6871654754166776
Epoch: 9 | Iteration number: [3870/4518] 85% | Training loss: 0.687164007154238
Epoch: 9 | Iteration number: [3880/4518] 85% | Training loss: 0.6871650258136779
Epoch: 9 | Iteration number: [3890/4518] 86% | Training loss: 0.6871647950462939
Epoch: 9 | Iteration number: [3900/4518] 86% | Training loss: 0.687161265703348
Epoch: 9 | Iteration number: [3910/4518] 86% | Training loss: 0.6871629524261446
Epoch: 9 | Iteration number: [3920/4518] 86% | Training loss: 0.6871625018667201
Epoch: 9 | Iteration number: [3930/4518] 86% | Training loss: 0.6871656625325443
Epoch: 9 | Iteration number: [3940/4518] 87% | Training loss: 0.6871681328957456
Epoch: 9 | Iteration number: [3950/4518] 87% | Training loss: 0.687169270304185
Epoch: 9 | Iteration number: [3960/4518] 87% | Training loss: 0.6871656676434508
Epoch: 9 | Iteration number: [3970/4518] 87% | Training loss: 0.6871660697970643
Epoch: 9 | Iteration number: [3980/4518] 88% | Training loss: 0.6871652311416128
Epoch: 9 | Iteration number: [3990/4518] 88% | Training loss: 0.6871639809512853
Epoch: 9 | Iteration number: [4000/4518] 88% | Training loss: 0.687159840375185
Epoch: 9 | Iteration number: [4010/4518] 88% | Training loss: 0.6871623000599202
Epoch: 9 | Iteration number: [4020/4518] 88% | Training loss: 0.6871611747575637
Epoch: 9 | Iteration number: [4030/4518] 89% | Training loss: 0.687163489139997
Epoch: 9 | Iteration number: [4040/4518] 89% | Training loss: 0.6871627234733931
Epoch: 9 | Iteration number: [4050/4518] 89% | Training loss: 0.6871620061956806
Epoch: 9 | Iteration number: [4060/4518] 89% | Training loss: 0.6871609517653
Epoch: 9 | Iteration number: [4070/4518] 90% | Training loss: 0.6871614300355279
Epoch: 9 | Iteration number: [4080/4518] 90% | Training loss: 0.6871591149007573
Epoch: 9 | Iteration number: [4090/4518] 90% | Training loss: 0.6871621682620573
Epoch: 9 | Iteration number: [4100/4518] 90% | Training loss: 0.6871595962163879
Epoch: 9 | Iteration number: [4110/4518] 90% | Training loss: 0.6871600358735616
Epoch: 9 | Iteration number: [4120/4518] 91% | Training loss: 0.6871626416890366
Epoch: 9 | Iteration number: [4130/4518] 91% | Training loss: 0.68716326314081
Epoch: 9 | Iteration number: [4140/4518] 91% | Training loss: 0.6871606320286718
Epoch: 9 | Iteration number: [4150/4518] 91% | Training loss: 0.6871590975106481
Epoch: 9 | Iteration number: [4160/4518] 92% | Training loss: 0.6871578420440738
Epoch: 9 | Iteration number: [4170/4518] 92% | Training loss: 0.6871571756952958
Epoch: 9 | Iteration number: [4180/4518] 92% | Training loss: 0.6871552337157099
Epoch: 9 | Iteration number: [4190/4518] 92% | Training loss: 0.6871585091713789
Epoch: 9 | Iteration number: [4200/4518] 92% | Training loss: 0.687157456889039
Epoch: 9 | Iteration number: [4210/4518] 93% | Training loss: 0.6871585699979597
Epoch: 9 | Iteration number: [4220/4518] 93% | Training loss: 0.6871582977862155
Epoch: 9 | Iteration number: [4230/4518] 93% | Training loss: 0.6871564106174677
Epoch: 9 | Iteration number: [4240/4518] 93% | Training loss: 0.6871566144081781
Epoch: 9 | Iteration number: [4250/4518] 94% | Training loss: 0.6871574434252347
Epoch: 9 | Iteration number: [4260/4518] 94% | Training loss: 0.6871547598933949
Epoch: 9 | Iteration number: [4270/4518] 94% | Training loss: 0.6871523598038899
Epoch: 9 | Iteration number: [4280/4518] 94% | Training loss: 0.6871539940761628
Epoch: 9 | Iteration number: [4290/4518] 94% | Training loss: 0.6871529533868626
Epoch: 9 | Iteration number: [4300/4518] 95% | Training loss: 0.6871532092676607
Epoch: 9 | Iteration number: [4310/4518] 95% | Training loss: 0.6871508356175124
Epoch: 9 | Iteration number: [4320/4518] 95% | Training loss: 0.6871486662300649
Epoch: 9 | Iteration number: [4330/4518] 95% | Training loss: 0.6871493655319302
Epoch: 9 | Iteration number: [4340/4518] 96% | Training loss: 0.6871525792756937
Epoch: 9 | Iteration number: [4350/4518] 96% | Training loss: 0.6871483738532012
Epoch: 9 | Iteration number: [4360/4518] 96% | Training loss: 0.6871445955759888
Epoch: 9 | Iteration number: [4370/4518] 96% | Training loss: 0.6871422936769045
Epoch: 9 | Iteration number: [4380/4518] 96% | Training loss: 0.6871437695200585
Epoch: 9 | Iteration number: [4390/4518] 97% | Training loss: 0.687141269472574
Epoch: 9 | Iteration number: [4400/4518] 97% | Training loss: 0.6871425851637667
Epoch: 9 | Iteration number: [4410/4518] 97% | Training loss: 0.6871452128265451
Epoch: 9 | Iteration number: [4420/4518] 97% | Training loss: 0.6871470522287205
Epoch: 9 | Iteration number: [4430/4518] 98% | Training loss: 0.6871474297401867
Epoch: 9 | Iteration number: [4440/4518] 98% | Training loss: 0.6871463745295464
Epoch: 9 | Iteration number: [4450/4518] 98% | Training loss: 0.6871433716275719
Epoch: 9 | Iteration number: [4460/4518] 98% | Training loss: 0.6871423802300953
Epoch: 9 | Iteration number: [4470/4518] 98% | Training loss: 0.6871407040280251
Epoch: 9 | Iteration number: [4480/4518] 99% | Training loss: 0.6871418579747635
Epoch: 9 | Iteration number: [4490/4518] 99% | Training loss: 0.6871412232617758
Epoch: 9 | Iteration number: [4500/4518] 99% | Training loss: 0.6871403614282608
Epoch: 9 | Iteration number: [4510/4518] 99% | Training loss: 0.6871397294913586

 End of epoch: 9 | Train Loss: 0.6869891494736834 | Training Time: 633 

 End of epoch: 9 | Eval Loss: 0.6902450943479732 | Evaluating Time: 18 
Epoch: 10 | Iteration number: [10/4518] 0% | Training loss: 0.7565088212490082
Epoch: 10 | Iteration number: [20/4518] 0% | Training loss: 0.721393632888794
Epoch: 10 | Iteration number: [30/4518] 0% | Training loss: 0.7098747968673706
Epoch: 10 | Iteration number: [40/4518] 0% | Training loss: 0.7042476803064346
Epoch: 10 | Iteration number: [50/4518] 1% | Training loss: 0.7005814337730407
Epoch: 10 | Iteration number: [60/4518] 1% | Training loss: 0.6984144568443298
Epoch: 10 | Iteration number: [70/4518] 1% | Training loss: 0.6967521437576839
Epoch: 10 | Iteration number: [80/4518] 1% | Training loss: 0.6956954769790172
Epoch: 10 | Iteration number: [90/4518] 1% | Training loss: 0.6947089744938745
Epoch: 10 | Iteration number: [100/4518] 2% | Training loss: 0.6941017520427704
Epoch: 10 | Iteration number: [110/4518] 2% | Training loss: 0.6934520678086714
Epoch: 10 | Iteration number: [120/4518] 2% | Training loss: 0.6929930200179418
Epoch: 10 | Iteration number: [130/4518] 2% | Training loss: 0.6925358781447777
Epoch: 10 | Iteration number: [140/4518] 3% | Training loss: 0.6921622480664934
Epoch: 10 | Iteration number: [150/4518] 3% | Training loss: 0.6919286580880483
Epoch: 10 | Iteration number: [160/4518] 3% | Training loss: 0.6916572079062462
Epoch: 10 | Iteration number: [170/4518] 3% | Training loss: 0.6913316102588878
Epoch: 10 | Iteration number: [180/4518] 3% | Training loss: 0.691054082579083
Epoch: 10 | Iteration number: [190/4518] 4% | Training loss: 0.6908564868726228
Epoch: 10 | Iteration number: [200/4518] 4% | Training loss: 0.690695832669735
Epoch: 10 | Iteration number: [210/4518] 4% | Training loss: 0.6904647287868318
Epoch: 10 | Iteration number: [220/4518] 4% | Training loss: 0.6903526325117458
Epoch: 10 | Iteration number: [230/4518] 5% | Training loss: 0.6901997908301976
Epoch: 10 | Iteration number: [240/4518] 5% | Training loss: 0.6901294318338235
Epoch: 10 | Iteration number: [250/4518] 5% | Training loss: 0.6899705650806427
Epoch: 10 | Iteration number: [260/4518] 5% | Training loss: 0.689859694471726
Epoch: 10 | Iteration number: [270/4518] 5% | Training loss: 0.6897222132594497
Epoch: 10 | Iteration number: [280/4518] 6% | Training loss: 0.6896054127386638
Epoch: 10 | Iteration number: [290/4518] 6% | Training loss: 0.6895043667020468
Epoch: 10 | Iteration number: [300/4518] 6% | Training loss: 0.6894521894057591
Epoch: 10 | Iteration number: [310/4518] 6% | Training loss: 0.6893679557308074
Epoch: 10 | Iteration number: [320/4518] 7% | Training loss: 0.6892896497622132
Epoch: 10 | Iteration number: [330/4518] 7% | Training loss: 0.6892337927312562
Epoch: 10 | Iteration number: [340/4518] 7% | Training loss: 0.6892164360074436
Epoch: 10 | Iteration number: [350/4518] 7% | Training loss: 0.6891596806049347
Epoch: 10 | Iteration number: [360/4518] 7% | Training loss: 0.6891031819913123
Epoch: 10 | Iteration number: [370/4518] 8% | Training loss: 0.6890460069115097
Epoch: 10 | Iteration number: [380/4518] 8% | Training loss: 0.6889791637659073
Epoch: 10 | Iteration number: [390/4518] 8% | Training loss: 0.688914985075975
Epoch: 10 | Iteration number: [400/4518] 8% | Training loss: 0.6888456520438194
Epoch: 10 | Iteration number: [410/4518] 9% | Training loss: 0.6888179209174179
Epoch: 10 | Iteration number: [420/4518] 9% | Training loss: 0.6887787659962972
Epoch: 10 | Iteration number: [430/4518] 9% | Training loss: 0.6887452602386475
Epoch: 10 | Iteration number: [440/4518] 9% | Training loss: 0.6887180518020283
Epoch: 10 | Iteration number: [450/4518] 9% | Training loss: 0.6886805913183425
Epoch: 10 | Iteration number: [460/4518] 10% | Training loss: 0.6886378439872162
Epoch: 10 | Iteration number: [470/4518] 10% | Training loss: 0.6885826100694372
Epoch: 10 | Iteration number: [480/4518] 10% | Training loss: 0.6885332254072031
Epoch: 10 | Iteration number: [490/4518] 10% | Training loss: 0.6884984447031605
Epoch: 10 | Iteration number: [500/4518] 11% | Training loss: 0.6884431427717209
Epoch: 10 | Iteration number: [510/4518] 11% | Training loss: 0.6884100979449702
Epoch: 10 | Iteration number: [520/4518] 11% | Training loss: 0.6883736634483704
Epoch: 10 | Iteration number: [530/4518] 11% | Training loss: 0.6883601601393717
Epoch: 10 | Iteration number: [540/4518] 11% | Training loss: 0.6883129223629281
Epoch: 10 | Iteration number: [550/4518] 12% | Training loss: 0.6882660999081351
Epoch: 10 | Iteration number: [560/4518] 12% | Training loss: 0.6882564605346748
Epoch: 10 | Iteration number: [570/4518] 12% | Training loss: 0.6882382394974692
Epoch: 10 | Iteration number: [580/4518] 12% | Training loss: 0.6882171750068664
Epoch: 10 | Iteration number: [590/4518] 13% | Training loss: 0.6882091405028004
Epoch: 10 | Iteration number: [600/4518] 13% | Training loss: 0.6881891478101413
Epoch: 10 | Iteration number: [610/4518] 13% | Training loss: 0.6881645901281326
Epoch: 10 | Iteration number: [620/4518] 13% | Training loss: 0.6881403566368165
Epoch: 10 | Iteration number: [630/4518] 13% | Training loss: 0.6881194232002137
Epoch: 10 | Iteration number: [640/4518] 14% | Training loss: 0.6880970203317702
Epoch: 10 | Iteration number: [650/4518] 14% | Training loss: 0.6880649269544161
Epoch: 10 | Iteration number: [660/4518] 14% | Training loss: 0.6880355567643137
Epoch: 10 | Iteration number: [670/4518] 14% | Training loss: 0.6880011353030133
Epoch: 10 | Iteration number: [680/4518] 15% | Training loss: 0.6879897222799414
Epoch: 10 | Iteration number: [690/4518] 15% | Training loss: 0.6879880275415338
Epoch: 10 | Iteration number: [700/4518] 15% | Training loss: 0.6879728300230844
Epoch: 10 | Iteration number: [710/4518] 15% | Training loss: 0.6879575922455586
Epoch: 10 | Iteration number: [720/4518] 15% | Training loss: 0.6879537547628085
Epoch: 10 | Iteration number: [730/4518] 16% | Training loss: 0.6879235599138965
Epoch: 10 | Iteration number: [740/4518] 16% | Training loss: 0.6879048781620489
Epoch: 10 | Iteration number: [750/4518] 16% | Training loss: 0.687885019938151
Epoch: 10 | Iteration number: [760/4518] 16% | Training loss: 0.6878635949994388
Epoch: 10 | Iteration number: [770/4518] 17% | Training loss: 0.6878513746447378
Epoch: 10 | Iteration number: [780/4518] 17% | Training loss: 0.6878461516056306
Epoch: 10 | Iteration number: [790/4518] 17% | Training loss: 0.6878312422504907
Epoch: 10 | Iteration number: [800/4518] 17% | Training loss: 0.6878213702142238
Epoch: 10 | Iteration number: [810/4518] 17% | Training loss: 0.6878077038276342
Epoch: 10 | Iteration number: [820/4518] 18% | Training loss: 0.6877983782349564
Epoch: 10 | Iteration number: [830/4518] 18% | Training loss: 0.6877871618931553
Epoch: 10 | Iteration number: [840/4518] 18% | Training loss: 0.6877842771865073
Epoch: 10 | Iteration number: [850/4518] 18% | Training loss: 0.6877827583341037
Epoch: 10 | Iteration number: [860/4518] 19% | Training loss: 0.6877687277488931
Epoch: 10 | Iteration number: [870/4518] 19% | Training loss: 0.6877584021666955
Epoch: 10 | Iteration number: [880/4518] 19% | Training loss: 0.6877491021698171
Epoch: 10 | Iteration number: [890/4518] 19% | Training loss: 0.6877401614457034
Epoch: 10 | Iteration number: [900/4518] 19% | Training loss: 0.6877336863014433
Epoch: 10 | Iteration number: [910/4518] 20% | Training loss: 0.6877260587372622
Epoch: 10 | Iteration number: [920/4518] 20% | Training loss: 0.6877119333847709
Epoch: 10 | Iteration number: [930/4518] 20% | Training loss: 0.6877036579834518
Epoch: 10 | Iteration number: [940/4518] 20% | Training loss: 0.6877015662954209
Epoch: 10 | Iteration number: [950/4518] 21% | Training loss: 0.6876781363236276
Epoch: 10 | Iteration number: [960/4518] 21% | Training loss: 0.6876879064366221
Epoch: 10 | Iteration number: [970/4518] 21% | Training loss: 0.687671377916926
Epoch: 10 | Iteration number: [980/4518] 21% | Training loss: 0.6876738183960622
Epoch: 10 | Iteration number: [990/4518] 21% | Training loss: 0.6876745242061038
Epoch: 10 | Iteration number: [1000/4518] 22% | Training loss: 0.6876656922698021
Epoch: 10 | Iteration number: [1010/4518] 22% | Training loss: 0.6876692067868638
Epoch: 10 | Iteration number: [1020/4518] 22% | Training loss: 0.6876690368441974
Epoch: 10 | Iteration number: [1030/4518] 22% | Training loss: 0.6876476208561833
Epoch: 10 | Iteration number: [1040/4518] 23% | Training loss: 0.6876494056903399
Epoch: 10 | Iteration number: [1050/4518] 23% | Training loss: 0.6876503543626694
Epoch: 10 | Iteration number: [1060/4518] 23% | Training loss: 0.6876522727732388
Epoch: 10 | Iteration number: [1070/4518] 23% | Training loss: 0.6876374373369127
Epoch: 10 | Iteration number: [1080/4518] 23% | Training loss: 0.6876423680671939
Epoch: 10 | Iteration number: [1090/4518] 24% | Training loss: 0.6876411356510372
Epoch: 10 | Iteration number: [1100/4518] 24% | Training loss: 0.6876181359724565
Epoch: 10 | Iteration number: [1110/4518] 24% | Training loss: 0.6876012998658257
Epoch: 10 | Iteration number: [1120/4518] 24% | Training loss: 0.6875887193317924
Epoch: 10 | Iteration number: [1130/4518] 25% | Training loss: 0.6875835996286004
Epoch: 10 | Iteration number: [1140/4518] 25% | Training loss: 0.6875864778694354
Epoch: 10 | Iteration number: [1150/4518] 25% | Training loss: 0.6875839370748271
Epoch: 10 | Iteration number: [1160/4518] 25% | Training loss: 0.6875870349592176
Epoch: 10 | Iteration number: [1170/4518] 25% | Training loss: 0.6875887589067475
Epoch: 10 | Iteration number: [1180/4518] 26% | Training loss: 0.6875841238236023
Epoch: 10 | Iteration number: [1190/4518] 26% | Training loss: 0.6875774467692656
Epoch: 10 | Iteration number: [1200/4518] 26% | Training loss: 0.6875607816378275
Epoch: 10 | Iteration number: [1210/4518] 26% | Training loss: 0.6875575560183564
Epoch: 10 | Iteration number: [1220/4518] 27% | Training loss: 0.6875487486358549
Epoch: 10 | Iteration number: [1230/4518] 27% | Training loss: 0.6875435218578432
Epoch: 10 | Iteration number: [1240/4518] 27% | Training loss: 0.687530622751482
Epoch: 10 | Iteration number: [1250/4518] 27% | Training loss: 0.6875230946540832
Epoch: 10 | Iteration number: [1260/4518] 27% | Training loss: 0.6875287013867545
Epoch: 10 | Iteration number: [1270/4518] 28% | Training loss: 0.6875278089928815
Epoch: 10 | Iteration number: [1280/4518] 28% | Training loss: 0.6875199625268579
Epoch: 10 | Iteration number: [1290/4518] 28% | Training loss: 0.6875101700309635
Epoch: 10 | Iteration number: [1300/4518] 28% | Training loss: 0.6875139785729921
Epoch: 10 | Iteration number: [1310/4518] 28% | Training loss: 0.687507766530714
Epoch: 10 | Iteration number: [1320/4518] 29% | Training loss: 0.6875155718940678
Epoch: 10 | Iteration number: [1330/4518] 29% | Training loss: 0.6875121500707211
Epoch: 10 | Iteration number: [1340/4518] 29% | Training loss: 0.6874994758349746
Epoch: 10 | Iteration number: [1350/4518] 29% | Training loss: 0.6874988938702478
Epoch: 10 | Iteration number: [1360/4518] 30% | Training loss: 0.6874942040618728
Epoch: 10 | Iteration number: [1370/4518] 30% | Training loss: 0.6874861345673999
Epoch: 10 | Iteration number: [1380/4518] 30% | Training loss: 0.6874952991371569
Epoch: 10 | Iteration number: [1390/4518] 30% | Training loss: 0.6874869809733878
Epoch: 10 | Iteration number: [1400/4518] 30% | Training loss: 0.6874864801764489
Epoch: 10 | Iteration number: [1410/4518] 31% | Training loss: 0.6874840257438362
Epoch: 10 | Iteration number: [1420/4518] 31% | Training loss: 0.6874812226480161
Epoch: 10 | Iteration number: [1430/4518] 31% | Training loss: 0.6874745613211518
Epoch: 10 | Iteration number: [1440/4518] 31% | Training loss: 0.6874696142971516
Epoch: 10 | Iteration number: [1450/4518] 32% | Training loss: 0.687465606064632
Epoch: 10 | Iteration number: [1460/4518] 32% | Training loss: 0.6874550289895437
Epoch: 10 | Iteration number: [1470/4518] 32% | Training loss: 0.6874563075247265
Epoch: 10 | Iteration number: [1480/4518] 32% | Training loss: 0.6874507607237713
Epoch: 10 | Iteration number: [1490/4518] 32% | Training loss: 0.6874424787575767
Epoch: 10 | Iteration number: [1500/4518] 33% | Training loss: 0.6874422324895859
Epoch: 10 | Iteration number: [1510/4518] 33% | Training loss: 0.6874409462837194
Epoch: 10 | Iteration number: [1520/4518] 33% | Training loss: 0.6874437492536871
Epoch: 10 | Iteration number: [1530/4518] 33% | Training loss: 0.6874526675620111
Epoch: 10 | Iteration number: [1540/4518] 34% | Training loss: 0.6874478457810043
Epoch: 10 | Iteration number: [1550/4518] 34% | Training loss: 0.6874442995748212
Epoch: 10 | Iteration number: [1560/4518] 34% | Training loss: 0.6874435832867256
Epoch: 10 | Iteration number: [1570/4518] 34% | Training loss: 0.6874361225374185
Epoch: 10 | Iteration number: [1580/4518] 34% | Training loss: 0.6874307011501699
Epoch: 10 | Iteration number: [1590/4518] 35% | Training loss: 0.6874322953838972
Epoch: 10 | Iteration number: [1600/4518] 35% | Training loss: 0.6874326116591692
Epoch: 10 | Iteration number: [1610/4518] 35% | Training loss: 0.6874336996804113
Epoch: 10 | Iteration number: [1620/4518] 35% | Training loss: 0.6874347422961835
Epoch: 10 | Iteration number: [1630/4518] 36% | Training loss: 0.6874361468239064
Epoch: 10 | Iteration number: [1640/4518] 36% | Training loss: 0.6874428059996628
Epoch: 10 | Iteration number: [1650/4518] 36% | Training loss: 0.687440129554633
Epoch: 10 | Iteration number: [1660/4518] 36% | Training loss: 0.6874362532632897
Epoch: 10 | Iteration number: [1670/4518] 36% | Training loss: 0.6874319431667556
Epoch: 10 | Iteration number: [1680/4518] 37% | Training loss: 0.6874376345958029
Epoch: 10 | Iteration number: [1690/4518] 37% | Training loss: 0.6874237354690507
Epoch: 10 | Iteration number: [1700/4518] 37% | Training loss: 0.6874260436787325
Epoch: 10 | Iteration number: [1710/4518] 37% | Training loss: 0.6874255978921701
Epoch: 10 | Iteration number: [1720/4518] 38% | Training loss: 0.6874226096064545
Epoch: 10 | Iteration number: [1730/4518] 38% | Training loss: 0.6874288702975808
Epoch: 10 | Iteration number: [1740/4518] 38% | Training loss: 0.6874213389281569
Epoch: 10 | Iteration number: [1750/4518] 38% | Training loss: 0.6874077607904162
Epoch: 10 | Iteration number: [1760/4518] 38% | Training loss: 0.6874062538146972
Epoch: 10 | Iteration number: [1770/4518] 39% | Training loss: 0.6874116140233595
Epoch: 10 | Iteration number: [1780/4518] 39% | Training loss: 0.6874050339286247
Epoch: 10 | Iteration number: [1790/4518] 39% | Training loss: 0.6873998145151404
Epoch: 10 | Iteration number: [1800/4518] 39% | Training loss: 0.6873975077271461
Epoch: 10 | Iteration number: [1810/4518] 40% | Training loss: 0.6873881516864945
Epoch: 10 | Iteration number: [1820/4518] 40% | Training loss: 0.687383033318834
Epoch: 10 | Iteration number: [1830/4518] 40% | Training loss: 0.6873800343177358
Epoch: 10 | Iteration number: [1840/4518] 40% | Training loss: 0.6873790620461754
Epoch: 10 | Iteration number: [1850/4518] 40% | Training loss: 0.6873761334612563
Epoch: 10 | Iteration number: [1860/4518] 41% | Training loss: 0.6873737494471253
Epoch: 10 | Iteration number: [1870/4518] 41% | Training loss: 0.6873672702095726
Epoch: 10 | Iteration number: [1880/4518] 41% | Training loss: 0.6873663280238497
Epoch: 10 | Iteration number: [1890/4518] 41% | Training loss: 0.6873600905219083
Epoch: 10 | Iteration number: [1900/4518] 42% | Training loss: 0.6873573031550959
Epoch: 10 | Iteration number: [1910/4518] 42% | Training loss: 0.6873413040063768
Epoch: 10 | Iteration number: [1920/4518] 42% | Training loss: 0.6873410791469117
Epoch: 10 | Iteration number: [1930/4518] 42% | Training loss: 0.6873398849074704
Epoch: 10 | Iteration number: [1940/4518] 42% | Training loss: 0.6873360503887392
Epoch: 10 | Iteration number: [1950/4518] 43% | Training loss: 0.6873355560119335
Epoch: 10 | Iteration number: [1960/4518] 43% | Training loss: 0.6873308069243723
Epoch: 10 | Iteration number: [1970/4518] 43% | Training loss: 0.6873339163772951
Epoch: 10 | Iteration number: [1980/4518] 43% | Training loss: 0.6873286904409678
Epoch: 10 | Iteration number: [1990/4518] 44% | Training loss: 0.6873245045467837
Epoch: 10 | Iteration number: [2000/4518] 44% | Training loss: 0.6873235847651958
Epoch: 10 | Iteration number: [2010/4518] 44% | Training loss: 0.6873245416885585
Epoch: 10 | Iteration number: [2020/4518] 44% | Training loss: 0.6873227536088169
Epoch: 10 | Iteration number: [2030/4518] 44% | Training loss: 0.6873284319645079
Epoch: 10 | Iteration number: [2040/4518] 45% | Training loss: 0.6873281200142468
Epoch: 10 | Iteration number: [2050/4518] 45% | Training loss: 0.6873258533419633
Epoch: 10 | Iteration number: [2060/4518] 45% | Training loss: 0.6873253922439316
Epoch: 10 | Iteration number: [2070/4518] 45% | Training loss: 0.6873175890837314
Epoch: 10 | Iteration number: [2080/4518] 46% | Training loss: 0.6873147501395299
Epoch: 10 | Iteration number: [2090/4518] 46% | Training loss: 0.6873103696478611
Epoch: 10 | Iteration number: [2100/4518] 46% | Training loss: 0.687304759252639
Epoch: 10 | Iteration number: [2110/4518] 46% | Training loss: 0.6873006085648921
Epoch: 10 | Iteration number: [2120/4518] 46% | Training loss: 0.687296971060195
Epoch: 10 | Iteration number: [2130/4518] 47% | Training loss: 0.6872890335573277
Epoch: 10 | Iteration number: [2140/4518] 47% | Training loss: 0.6872856236785372
Epoch: 10 | Iteration number: [2150/4518] 47% | Training loss: 0.6872834991854291
Epoch: 10 | Iteration number: [2160/4518] 47% | Training loss: 0.6872879005416676
Epoch: 10 | Iteration number: [2170/4518] 48% | Training loss: 0.6872828912075764
Epoch: 10 | Iteration number: [2180/4518] 48% | Training loss: 0.6872804708437088
Epoch: 10 | Iteration number: [2190/4518] 48% | Training loss: 0.687284796150852
Epoch: 10 | Iteration number: [2200/4518] 48% | Training loss: 0.6872872750596567
Epoch: 10 | Iteration number: [2210/4518] 48% | Training loss: 0.6872810895896065
Epoch: 10 | Iteration number: [2220/4518] 49% | Training loss: 0.6872721448943422
Epoch: 10 | Iteration number: [2230/4518] 49% | Training loss: 0.6872657805814871
Epoch: 10 | Iteration number: [2240/4518] 49% | Training loss: 0.6872624288978321
Epoch: 10 | Iteration number: [2250/4518] 49% | Training loss: 0.687254085275862
Epoch: 10 | Iteration number: [2260/4518] 50% | Training loss: 0.6872610866495993
Epoch: 10 | Iteration number: [2270/4518] 50% | Training loss: 0.6872562757410142
Epoch: 10 | Iteration number: [2280/4518] 50% | Training loss: 0.6872580682499367
Epoch: 10 | Iteration number: [2290/4518] 50% | Training loss: 0.6872614769435866
Epoch: 10 | Iteration number: [2300/4518] 50% | Training loss: 0.6872620379147323
Epoch: 10 | Iteration number: [2310/4518] 51% | Training loss: 0.6872592639613461
Epoch: 10 | Iteration number: [2320/4518] 51% | Training loss: 0.68725641297883
Epoch: 10 | Iteration number: [2330/4518] 51% | Training loss: 0.6872492780245425
Epoch: 10 | Iteration number: [2340/4518] 51% | Training loss: 0.6872427926104293
Epoch: 10 | Iteration number: [2350/4518] 52% | Training loss: 0.6872429742965293
Epoch: 10 | Iteration number: [2360/4518] 52% | Training loss: 0.6872378539230863
Epoch: 10 | Iteration number: [2370/4518] 52% | Training loss: 0.6872367962000239
Epoch: 10 | Iteration number: [2380/4518] 52% | Training loss: 0.6872356985546961
Epoch: 10 | Iteration number: [2390/4518] 52% | Training loss: 0.6872327018981199
Epoch: 10 | Iteration number: [2400/4518] 53% | Training loss: 0.6872343946993351
Epoch: 10 | Iteration number: [2410/4518] 53% | Training loss: 0.6872342593442355
Epoch: 10 | Iteration number: [2420/4518] 53% | Training loss: 0.6872352168579732
Epoch: 10 | Iteration number: [2430/4518] 53% | Training loss: 0.6872328482292317
Epoch: 10 | Iteration number: [2440/4518] 54% | Training loss: 0.6872339483655867
Epoch: 10 | Iteration number: [2450/4518] 54% | Training loss: 0.6872335165860701
Epoch: 10 | Iteration number: [2460/4518] 54% | Training loss: 0.6872348538743771
Epoch: 10 | Iteration number: [2470/4518] 54% | Training loss: 0.687229905968253
Epoch: 10 | Iteration number: [2480/4518] 54% | Training loss: 0.6872263020565433
Epoch: 10 | Iteration number: [2490/4518] 55% | Training loss: 0.6872265276181171
Epoch: 10 | Iteration number: [2500/4518] 55% | Training loss: 0.6872278954744339
Epoch: 10 | Iteration number: [2510/4518] 55% | Training loss: 0.6872249691134905
Epoch: 10 | Iteration number: [2520/4518] 55% | Training loss: 0.6872287446071231
Epoch: 10 | Iteration number: [2530/4518] 55% | Training loss: 0.6872299252291442
Epoch: 10 | Iteration number: [2540/4518] 56% | Training loss: 0.6872329171482973
Epoch: 10 | Iteration number: [2550/4518] 56% | Training loss: 0.6872346323144202
Epoch: 10 | Iteration number: [2560/4518] 56% | Training loss: 0.6872344886185602
Epoch: 10 | Iteration number: [2570/4518] 56% | Training loss: 0.6872318346676659
Epoch: 10 | Iteration number: [2580/4518] 57% | Training loss: 0.687229044746983
Epoch: 10 | Iteration number: [2590/4518] 57% | Training loss: 0.6872266697607445
Epoch: 10 | Iteration number: [2600/4518] 57% | Training loss: 0.687228693320201
Epoch: 10 | Iteration number: [2610/4518] 57% | Training loss: 0.6872268075458848
Epoch: 10 | Iteration number: [2620/4518] 57% | Training loss: 0.6872243008995784
Epoch: 10 | Iteration number: [2630/4518] 58% | Training loss: 0.687224993325005
Epoch: 10 | Iteration number: [2640/4518] 58% | Training loss: 0.6872218372695373
Epoch: 10 | Iteration number: [2650/4518] 58% | Training loss: 0.687216325975814
Epoch: 10 | Iteration number: [2660/4518] 58% | Training loss: 0.6872151837761241
Epoch: 10 | Iteration number: [2670/4518] 59% | Training loss: 0.6872130620792117
Epoch: 10 | Iteration number: [2680/4518] 59% | Training loss: 0.6872120449124877
Epoch: 10 | Iteration number: [2690/4518] 59% | Training loss: 0.6872100828083918
Epoch: 10 | Iteration number: [2700/4518] 59% | Training loss: 0.6872078375021616
Epoch: 10 | Iteration number: [2710/4518] 59% | Training loss: 0.6872065441414879
Epoch: 10 | Iteration number: [2720/4518] 60% | Training loss: 0.6872034530867549
Epoch: 10 | Iteration number: [2730/4518] 60% | Training loss: 0.6872014870573749
Epoch: 10 | Iteration number: [2740/4518] 60% | Training loss: 0.687201135567505
Epoch: 10 | Iteration number: [2750/4518] 60% | Training loss: 0.6872012872695923
Epoch: 10 | Iteration number: [2760/4518] 61% | Training loss: 0.687204283065554
Epoch: 10 | Iteration number: [2770/4518] 61% | Training loss: 0.6872023522853852
Epoch: 10 | Iteration number: [2780/4518] 61% | Training loss: 0.68719906360983
Epoch: 10 | Iteration number: [2790/4518] 61% | Training loss: 0.6871988393927133
Epoch: 10 | Iteration number: [2800/4518] 61% | Training loss: 0.6871942869041647
Epoch: 10 | Iteration number: [2810/4518] 62% | Training loss: 0.6871945493374007
Epoch: 10 | Iteration number: [2820/4518] 62% | Training loss: 0.6871910832875164
Epoch: 10 | Iteration number: [2830/4518] 62% | Training loss: 0.6871925189301319
Epoch: 10 | Iteration number: [2840/4518] 62% | Training loss: 0.6871890401336509
Epoch: 10 | Iteration number: [2850/4518] 63% | Training loss: 0.6871898043992226
Epoch: 10 | Iteration number: [2860/4518] 63% | Training loss: 0.6871919820983927
Epoch: 10 | Iteration number: [2870/4518] 63% | Training loss: 0.6871896520931962
Epoch: 10 | Iteration number: [2880/4518] 63% | Training loss: 0.6871921810218029
Epoch: 10 | Iteration number: [2890/4518] 63% | Training loss: 0.687189101636616
Epoch: 10 | Iteration number: [2900/4518] 64% | Training loss: 0.6871857591744127
Epoch: 10 | Iteration number: [2910/4518] 64% | Training loss: 0.6871841372698033
Epoch: 10 | Iteration number: [2920/4518] 64% | Training loss: 0.6871859572113377
Epoch: 10 | Iteration number: [2930/4518] 64% | Training loss: 0.6871845698397314
Epoch: 10 | Iteration number: [2940/4518] 65% | Training loss: 0.6871894092584143
Epoch: 10 | Iteration number: [2950/4518] 65% | Training loss: 0.6871923067003993
Epoch: 10 | Iteration number: [2960/4518] 65% | Training loss: 0.687189988691259
Epoch: 10 | Iteration number: [2970/4518] 65% | Training loss: 0.6871867613358931
Epoch: 10 | Iteration number: [2980/4518] 65% | Training loss: 0.6871845421375045
Epoch: 10 | Iteration number: [2990/4518] 66% | Training loss: 0.6871864581187832
Epoch: 10 | Iteration number: [3000/4518] 66% | Training loss: 0.6871839332183202
Epoch: 10 | Iteration number: [3010/4518] 66% | Training loss: 0.6871869890792821
Epoch: 10 | Iteration number: [3020/4518] 66% | Training loss: 0.6871842542231478
Epoch: 10 | Iteration number: [3030/4518] 67% | Training loss: 0.6871859208191976
Epoch: 10 | Iteration number: [3040/4518] 67% | Training loss: 0.6871882659628203
Epoch: 10 | Iteration number: [3050/4518] 67% | Training loss: 0.6871903868386002
Epoch: 10 | Iteration number: [3060/4518] 67% | Training loss: 0.6871917603841794
Epoch: 10 | Iteration number: [3070/4518] 67% | Training loss: 0.6871897242162437
Epoch: 10 | Iteration number: [3080/4518] 68% | Training loss: 0.6871891852903675
Epoch: 10 | Iteration number: [3090/4518] 68% | Training loss: 0.6871876191745684
Epoch: 10 | Iteration number: [3100/4518] 68% | Training loss: 0.6871898525953293
Epoch: 10 | Iteration number: [3110/4518] 68% | Training loss: 0.6871918024740802
Epoch: 10 | Iteration number: [3120/4518] 69% | Training loss: 0.6871893023260128
Epoch: 10 | Iteration number: [3130/4518] 69% | Training loss: 0.6871869223757674
Epoch: 10 | Iteration number: [3140/4518] 69% | Training loss: 0.6871882080652152
Epoch: 10 | Iteration number: [3150/4518] 69% | Training loss: 0.6871877797633883
Epoch: 10 | Iteration number: [3160/4518] 69% | Training loss: 0.6871890384185163
Epoch: 10 | Iteration number: [3170/4518] 70% | Training loss: 0.6871934550417711
Epoch: 10 | Iteration number: [3180/4518] 70% | Training loss: 0.6871927592364497
Epoch: 10 | Iteration number: [3190/4518] 70% | Training loss: 0.6871948621489785
Epoch: 10 | Iteration number: [3200/4518] 70% | Training loss: 0.6871930611878634
Epoch: 10 | Iteration number: [3210/4518] 71% | Training loss: 0.6871944325735264
Epoch: 10 | Iteration number: [3220/4518] 71% | Training loss: 0.6871899372487335
Epoch: 10 | Iteration number: [3230/4518] 71% | Training loss: 0.6871903155794823
Epoch: 10 | Iteration number: [3240/4518] 71% | Training loss: 0.6871864835789174
Epoch: 10 | Iteration number: [3250/4518] 71% | Training loss: 0.6871849910112527
Epoch: 10 | Iteration number: [3260/4518] 72% | Training loss: 0.687178797023428
Epoch: 10 | Iteration number: [3270/4518] 72% | Training loss: 0.6871778141285666
Epoch: 10 | Iteration number: [3280/4518] 72% | Training loss: 0.6871774792489482
Epoch: 10 | Iteration number: [3290/4518] 72% | Training loss: 0.6871769715768588
Epoch: 10 | Iteration number: [3300/4518] 73% | Training loss: 0.687174168120731
Epoch: 10 | Iteration number: [3310/4518] 73% | Training loss: 0.6871751946625032
Epoch: 10 | Iteration number: [3320/4518] 73% | Training loss: 0.687169170415545
Epoch: 10 | Iteration number: [3330/4518] 73% | Training loss: 0.6871644138573885
Epoch: 10 | Iteration number: [3340/4518] 73% | Training loss: 0.687165559373216
Epoch: 10 | Iteration number: [3350/4518] 74% | Training loss: 0.687164971472612
Epoch: 10 | Iteration number: [3360/4518] 74% | Training loss: 0.6871634431360732
Epoch: 10 | Iteration number: [3370/4518] 74% | Training loss: 0.6871610384666601
Epoch: 10 | Iteration number: [3380/4518] 74% | Training loss: 0.6871601989283365
Epoch: 10 | Iteration number: [3390/4518] 75% | Training loss: 0.6871589143191819
Epoch: 10 | Iteration number: [3400/4518] 75% | Training loss: 0.687159915285952
Epoch: 10 | Iteration number: [3410/4518] 75% | Training loss: 0.6871598963338958
Epoch: 10 | Iteration number: [3420/4518] 75% | Training loss: 0.687160538668521
Epoch: 10 | Iteration number: [3430/4518] 75% | Training loss: 0.6871604167685217
Epoch: 10 | Iteration number: [3440/4518] 76% | Training loss: 0.6871607177999131
Epoch: 10 | Iteration number: [3450/4518] 76% | Training loss: 0.6871593014399211
Epoch: 10 | Iteration number: [3460/4518] 76% | Training loss: 0.6871586495741254
Epoch: 10 | Iteration number: [3470/4518] 76% | Training loss: 0.6871599752209029
Epoch: 10 | Iteration number: [3480/4518] 77% | Training loss: 0.6871602270452456
Epoch: 10 | Iteration number: [3490/4518] 77% | Training loss: 0.6871585130008381
Epoch: 10 | Iteration number: [3500/4518] 77% | Training loss: 0.6871595405340195
Epoch: 10 | Iteration number: [3510/4518] 77% | Training loss: 0.6871615992991673
Epoch: 10 | Iteration number: [3520/4518] 77% | Training loss: 0.687160004760054
Epoch: 10 | Iteration number: [3530/4518] 78% | Training loss: 0.6871621170226305
Epoch: 10 | Iteration number: [3540/4518] 78% | Training loss: 0.687161925889678
Epoch: 10 | Iteration number: [3550/4518] 78% | Training loss: 0.6871636543979107
Epoch: 10 | Iteration number: [3560/4518] 78% | Training loss: 0.6871647149491846
Epoch: 10 | Iteration number: [3570/4518] 79% | Training loss: 0.6871656636397044
Epoch: 10 | Iteration number: [3580/4518] 79% | Training loss: 0.6871636682382509
Epoch: 10 | Iteration number: [3590/4518] 79% | Training loss: 0.6871585049336999
Epoch: 10 | Iteration number: [3600/4518] 79% | Training loss: 0.6871601815687286
Epoch: 10 | Iteration number: [3610/4518] 79% | Training loss: 0.6871588200413289
Epoch: 10 | Iteration number: [3620/4518] 80% | Training loss: 0.6871586480028722
Epoch: 10 | Iteration number: [3630/4518] 80% | Training loss: 0.6871532817517431
Epoch: 10 | Iteration number: [3640/4518] 80% | Training loss: 0.6871554403187154
Epoch: 10 | Iteration number: [3650/4518] 80% | Training loss: 0.6871550910113609
Epoch: 10 | Iteration number: [3660/4518] 81% | Training loss: 0.6871542335045142
Epoch: 10 | Iteration number: [3670/4518] 81% | Training loss: 0.6871517020447703
Epoch: 10 | Iteration number: [3680/4518] 81% | Training loss: 0.687146892171839
Epoch: 10 | Iteration number: [3690/4518] 81% | Training loss: 0.6871445762432687
Epoch: 10 | Iteration number: [3700/4518] 81% | Training loss: 0.6871454818506498
Epoch: 10 | Iteration number: [3710/4518] 82% | Training loss: 0.687143938689219
Epoch: 10 | Iteration number: [3720/4518] 82% | Training loss: 0.6871387730843277
Epoch: 10 | Iteration number: [3730/4518] 82% | Training loss: 0.6871396669753436
Epoch: 10 | Iteration number: [3740/4518] 82% | Training loss: 0.687137728993268
Epoch: 10 | Iteration number: [3750/4518] 83% | Training loss: 0.687135716120402
Epoch: 10 | Iteration number: [3760/4518] 83% | Training loss: 0.6871401654278978
Epoch: 10 | Iteration number: [3770/4518] 83% | Training loss: 0.6871392961048005
Epoch: 10 | Iteration number: [3780/4518] 83% | Training loss: 0.6871385736597909
Epoch: 10 | Iteration number: [3790/4518] 83% | Training loss: 0.6871415178348018
Epoch: 10 | Iteration number: [3800/4518] 84% | Training loss: 0.6871440794279701
Epoch: 10 | Iteration number: [3810/4518] 84% | Training loss: 0.6871460233617017
Epoch: 10 | Iteration number: [3820/4518] 84% | Training loss: 0.6871442442477061
Epoch: 10 | Iteration number: [3830/4518] 84% | Training loss: 0.687144205479958
Epoch: 10 | Iteration number: [3840/4518] 84% | Training loss: 0.6871426007865618
Epoch: 10 | Iteration number: [3850/4518] 85% | Training loss: 0.6871423522063664
Epoch: 10 | Iteration number: [3860/4518] 85% | Training loss: 0.6871434885757575
Epoch: 10 | Iteration number: [3870/4518] 85% | Training loss: 0.6871434026294284
Epoch: 10 | Iteration number: [3880/4518] 85% | Training loss: 0.6871446244495432
Epoch: 10 | Iteration number: [3890/4518] 86% | Training loss: 0.6871466941882528
Epoch: 10 | Iteration number: [3900/4518] 86% | Training loss: 0.6871443797380496
Epoch: 10 | Iteration number: [3910/4518] 86% | Training loss: 0.6871471951989566
Epoch: 10 | Iteration number: [3920/4518] 86% | Training loss: 0.6871473067573138
Epoch: 10 | Iteration number: [3930/4518] 86% | Training loss: 0.6871432381276866
Epoch: 10 | Iteration number: [3940/4518] 87% | Training loss: 0.687143016012792
Epoch: 10 | Iteration number: [3950/4518] 87% | Training loss: 0.6871444748775869
Epoch: 10 | Iteration number: [3960/4518] 87% | Training loss: 0.6871454466021423
Epoch: 10 | Iteration number: [3970/4518] 87% | Training loss: 0.6871478937284772
Epoch: 10 | Iteration number: [3980/4518] 88% | Training loss: 0.6871447407420556
Epoch: 10 | Iteration number: [3990/4518] 88% | Training loss: 0.6871442549957667
Epoch: 10 | Iteration number: [4000/4518] 88% | Training loss: 0.6871431832313537
Epoch: 10 | Iteration number: [4010/4518] 88% | Training loss: 0.6871439518476662
Epoch: 10 | Iteration number: [4020/4518] 88% | Training loss: 0.6871428754792285
Epoch: 10 | Iteration number: [4030/4518] 89% | Training loss: 0.687139919511142
Epoch: 10 | Iteration number: [4040/4518] 89% | Training loss: 0.6871431639436448
Epoch: 10 | Iteration number: [4050/4518] 89% | Training loss: 0.687143190054246
Epoch: 10 | Iteration number: [4060/4518] 89% | Training loss: 0.6871411486359066
Epoch: 10 | Iteration number: [4070/4518] 90% | Training loss: 0.687139984723684
Epoch: 10 | Iteration number: [4080/4518] 90% | Training loss: 0.6871405275575087
Epoch: 10 | Iteration number: [4090/4518] 90% | Training loss: 0.6871429052067269
Epoch: 10 | Iteration number: [4100/4518] 90% | Training loss: 0.6871438914973561
Epoch: 10 | Iteration number: [4110/4518] 90% | Training loss: 0.6871441985278814
Epoch: 10 | Iteration number: [4120/4518] 91% | Training loss: 0.6871460302796178
Epoch: 10 | Iteration number: [4130/4518] 91% | Training loss: 0.6871465348591239
Epoch: 10 | Iteration number: [4140/4518] 91% | Training loss: 0.6871446036198289
Epoch: 10 | Iteration number: [4150/4518] 91% | Training loss: 0.6871435629747
Epoch: 10 | Iteration number: [4160/4518] 92% | Training loss: 0.687143843420423
Epoch: 10 | Iteration number: [4170/4518] 92% | Training loss: 0.6871441989636822
Epoch: 10 | Iteration number: [4180/4518] 92% | Training loss: 0.687144911317734
Epoch: 10 | Iteration number: [4190/4518] 92% | Training loss: 0.6871462668041056
Epoch: 10 | Iteration number: [4200/4518] 92% | Training loss: 0.6871441046396891
Epoch: 10 | Iteration number: [4210/4518] 93% | Training loss: 0.6871453766726542
Epoch: 10 | Iteration number: [4220/4518] 93% | Training loss: 0.6871461820263434
Epoch: 10 | Iteration number: [4230/4518] 93% | Training loss: 0.6871470486300493
Epoch: 10 | Iteration number: [4240/4518] 93% | Training loss: 0.6871485975693982
Epoch: 10 | Iteration number: [4250/4518] 94% | Training loss: 0.6871465803875643
Epoch: 10 | Iteration number: [4260/4518] 94% | Training loss: 0.6871468523858298
Epoch: 10 | Iteration number: [4270/4518] 94% | Training loss: 0.6871462857695319
Epoch: 10 | Iteration number: [4280/4518] 94% | Training loss: 0.6871478211935436
Epoch: 10 | Iteration number: [4290/4518] 94% | Training loss: 0.6871474721631804
Epoch: 10 | Iteration number: [4300/4518] 95% | Training loss: 0.687148486916409
Epoch: 10 | Iteration number: [4310/4518] 95% | Training loss: 0.6871484122807354
Epoch: 10 | Iteration number: [4320/4518] 95% | Training loss: 0.6871459666363618
Epoch: 10 | Iteration number: [4330/4518] 95% | Training loss: 0.687145634735429
Epoch: 10 | Iteration number: [4340/4518] 96% | Training loss: 0.6871434065191427
Epoch: 10 | Iteration number: [4350/4518] 96% | Training loss: 0.6871440297981788
Epoch: 10 | Iteration number: [4360/4518] 96% | Training loss: 0.6871427470937781
Epoch: 10 | Iteration number: [4370/4518] 96% | Training loss: 0.6871426409523874
Epoch: 10 | Iteration number: [4380/4518] 96% | Training loss: 0.6871421955355771
Epoch: 10 | Iteration number: [4390/4518] 97% | Training loss: 0.6871454315467956
Epoch: 10 | Iteration number: [4400/4518] 97% | Training loss: 0.6871429291773926
Epoch: 10 | Iteration number: [4410/4518] 97% | Training loss: 0.6871434896711319
Epoch: 10 | Iteration number: [4420/4518] 97% | Training loss: 0.6871442003487462
Epoch: 10 | Iteration number: [4430/4518] 98% | Training loss: 0.6871423209897551
Epoch: 10 | Iteration number: [4440/4518] 98% | Training loss: 0.6871449801835928
Epoch: 10 | Iteration number: [4450/4518] 98% | Training loss: 0.6871428605813659
Epoch: 10 | Iteration number: [4460/4518] 98% | Training loss: 0.6871452850744864
Epoch: 10 | Iteration number: [4470/4518] 98% | Training loss: 0.6871410636827183
Epoch: 10 | Iteration number: [4480/4518] 99% | Training loss: 0.687142462655902
Epoch: 10 | Iteration number: [4490/4518] 99% | Training loss: 0.6871428525129246
Epoch: 10 | Iteration number: [4500/4518] 99% | Training loss: 0.6871415431102117
Epoch: 10 | Iteration number: [4510/4518] 99% | Training loss: 0.6871442858369282

 End of epoch: 10 | Train Loss: 0.6869887975978345 | Training Time: 634 

 End of epoch: 10 | Eval Loss: 0.6902426335276389 | Evaluating Time: 18 
Epoch: 11 | Iteration number: [10/4518] 0% | Training loss: 0.7550958454608917
Epoch: 11 | Iteration number: [20/4518] 0% | Training loss: 0.7211512625217438
Epoch: 11 | Iteration number: [30/4518] 0% | Training loss: 0.7091886778672536
Epoch: 11 | Iteration number: [40/4518] 0% | Training loss: 0.7037725627422333
Epoch: 11 | Iteration number: [50/4518] 1% | Training loss: 0.7004271924495697
Epoch: 11 | Iteration number: [60/4518] 1% | Training loss: 0.6980682303508122
Epoch: 11 | Iteration number: [70/4518] 1% | Training loss: 0.6966079831123352
Epoch: 11 | Iteration number: [80/4518] 1% | Training loss: 0.6953108549118042
Epoch: 11 | Iteration number: [90/4518] 1% | Training loss: 0.6944227384196388
Epoch: 11 | Iteration number: [100/4518] 2% | Training loss: 0.6937928348779678
Epoch: 11 | Iteration number: [110/4518] 2% | Training loss: 0.6930723910981959
Epoch: 11 | Iteration number: [120/4518] 2% | Training loss: 0.6926423236727715
Epoch: 11 | Iteration number: [130/4518] 2% | Training loss: 0.6921391120323768
Epoch: 11 | Iteration number: [140/4518] 3% | Training loss: 0.6917421400547028
Epoch: 11 | Iteration number: [150/4518] 3% | Training loss: 0.6913642772038777
Epoch: 11 | Iteration number: [160/4518] 3% | Training loss: 0.6911419168114662
Epoch: 11 | Iteration number: [170/4518] 3% | Training loss: 0.6908597423749812
Epoch: 11 | Iteration number: [180/4518] 3% | Training loss: 0.6905819876326456
Epoch: 11 | Iteration number: [190/4518] 4% | Training loss: 0.69039753863686
Epoch: 11 | Iteration number: [200/4518] 4% | Training loss: 0.6902285221219063
Epoch: 11 | Iteration number: [210/4518] 4% | Training loss: 0.6900657480671293
Epoch: 11 | Iteration number: [220/4518] 4% | Training loss: 0.6899398112838918
Epoch: 11 | Iteration number: [230/4518] 5% | Training loss: 0.6898702235325523
Epoch: 11 | Iteration number: [240/4518] 5% | Training loss: 0.6897613411148389
Epoch: 11 | Iteration number: [250/4518] 5% | Training loss: 0.689689884185791
Epoch: 11 | Iteration number: [260/4518] 5% | Training loss: 0.689637883580648
Epoch: 11 | Iteration number: [270/4518] 5% | Training loss: 0.689540006937804
Epoch: 11 | Iteration number: [280/4518] 6% | Training loss: 0.6894453732030732
Epoch: 11 | Iteration number: [290/4518] 6% | Training loss: 0.6894243867232882
Epoch: 11 | Iteration number: [300/4518] 6% | Training loss: 0.6893530042966207
Epoch: 11 | Iteration number: [310/4518] 6% | Training loss: 0.6892748588515866
Epoch: 11 | Iteration number: [320/4518] 7% | Training loss: 0.6891960293054581
Epoch: 11 | Iteration number: [330/4518] 7% | Training loss: 0.6891613978328127
Epoch: 11 | Iteration number: [340/4518] 7% | Training loss: 0.689127595109098
Epoch: 11 | Iteration number: [350/4518] 7% | Training loss: 0.6891035979134695
Epoch: 11 | Iteration number: [360/4518] 7% | Training loss: 0.6890708537565338
Epoch: 11 | Iteration number: [370/4518] 8% | Training loss: 0.6889939127741633
Epoch: 11 | Iteration number: [380/4518] 8% | Training loss: 0.6889239199851689
Epoch: 11 | Iteration number: [390/4518] 8% | Training loss: 0.6888890211398785
Epoch: 11 | Iteration number: [400/4518] 8% | Training loss: 0.6888700805604457
Epoch: 11 | Iteration number: [410/4518] 9% | Training loss: 0.6888392426618716
Epoch: 11 | Iteration number: [420/4518] 9% | Training loss: 0.6888049179599398
Epoch: 11 | Iteration number: [430/4518] 9% | Training loss: 0.6887647167194721
Epoch: 11 | Iteration number: [440/4518] 9% | Training loss: 0.6887190616943619
Epoch: 11 | Iteration number: [450/4518] 9% | Training loss: 0.6886901375982496
Epoch: 11 | Iteration number: [460/4518] 10% | Training loss: 0.6886490360550258
Epoch: 11 | Iteration number: [470/4518] 10% | Training loss: 0.688616749834507
Epoch: 11 | Iteration number: [480/4518] 10% | Training loss: 0.6885800123214721
Epoch: 11 | Iteration number: [490/4518] 10% | Training loss: 0.6885467412520428
Epoch: 11 | Iteration number: [500/4518] 11% | Training loss: 0.6885468927621842
Epoch: 11 | Iteration number: [510/4518] 11% | Training loss: 0.688502965370814
Epoch: 11 | Iteration number: [520/4518] 11% | Training loss: 0.6884666359195343
Epoch: 11 | Iteration number: [530/4518] 11% | Training loss: 0.6884374696128773
Epoch: 11 | Iteration number: [540/4518] 11% | Training loss: 0.6883928771372194
Epoch: 11 | Iteration number: [550/4518] 12% | Training loss: 0.6883714289014989
Epoch: 11 | Iteration number: [560/4518] 12% | Training loss: 0.6883377941591399
Epoch: 11 | Iteration number: [570/4518] 12% | Training loss: 0.6882896431705408
Epoch: 11 | Iteration number: [580/4518] 12% | Training loss: 0.688278098969624
Epoch: 11 | Iteration number: [590/4518] 13% | Training loss: 0.6882461116475574
Epoch: 11 | Iteration number: [600/4518] 13% | Training loss: 0.6882151035467784
Epoch: 11 | Iteration number: [610/4518] 13% | Training loss: 0.6881951279327517
Epoch: 11 | Iteration number: [620/4518] 13% | Training loss: 0.6881694346666336
Epoch: 11 | Iteration number: [630/4518] 13% | Training loss: 0.6881683316495684
Epoch: 11 | Iteration number: [640/4518] 14% | Training loss: 0.6881568991579116
Epoch: 11 | Iteration number: [650/4518] 14% | Training loss: 0.6881404609863575
Epoch: 11 | Iteration number: [660/4518] 14% | Training loss: 0.6881080063906583
Epoch: 11 | Iteration number: [670/4518] 14% | Training loss: 0.6880877099820037
Epoch: 11 | Iteration number: [680/4518] 15% | Training loss: 0.6880664743921336
Epoch: 11 | Iteration number: [690/4518] 15% | Training loss: 0.688061820683272
Epoch: 11 | Iteration number: [700/4518] 15% | Training loss: 0.6880602495159421
Epoch: 11 | Iteration number: [710/4518] 15% | Training loss: 0.6880442562237592
Epoch: 11 | Iteration number: [720/4518] 15% | Training loss: 0.6880264561209414
Epoch: 11 | Iteration number: [730/4518] 16% | Training loss: 0.6880273340499564
Epoch: 11 | Iteration number: [740/4518] 16% | Training loss: 0.6880171857975624
Epoch: 11 | Iteration number: [750/4518] 16% | Training loss: 0.687990642229716
Epoch: 11 | Iteration number: [760/4518] 16% | Training loss: 0.6879806049560245
Epoch: 11 | Iteration number: [770/4518] 17% | Training loss: 0.6879627251779878
Epoch: 11 | Iteration number: [780/4518] 17% | Training loss: 0.6879506645294337
Epoch: 11 | Iteration number: [790/4518] 17% | Training loss: 0.6879267988325675
Epoch: 11 | Iteration number: [800/4518] 17% | Training loss: 0.6879176994413138
Epoch: 11 | Iteration number: [810/4518] 17% | Training loss: 0.6879204476321185
Epoch: 11 | Iteration number: [820/4518] 18% | Training loss: 0.6879149790217237
Epoch: 11 | Iteration number: [830/4518] 18% | Training loss: 0.6878992298999465
Epoch: 11 | Iteration number: [840/4518] 18% | Training loss: 0.6878947743347713
Epoch: 11 | Iteration number: [850/4518] 18% | Training loss: 0.687867187612197
Epoch: 11 | Iteration number: [860/4518] 19% | Training loss: 0.6878661700459414
Epoch: 11 | Iteration number: [870/4518] 19% | Training loss: 0.6878534911692827
Epoch: 11 | Iteration number: [880/4518] 19% | Training loss: 0.6878400957719846
Epoch: 11 | Iteration number: [890/4518] 19% | Training loss: 0.6878369869810812
Epoch: 11 | Iteration number: [900/4518] 19% | Training loss: 0.6878299279345407
Epoch: 11 | Iteration number: [910/4518] 20% | Training loss: 0.687824014713476
Epoch: 11 | Iteration number: [920/4518] 20% | Training loss: 0.6878247025220291
Epoch: 11 | Iteration number: [930/4518] 20% | Training loss: 0.687824450833823
Epoch: 11 | Iteration number: [940/4518] 20% | Training loss: 0.6878122190211682
Epoch: 11 | Iteration number: [950/4518] 21% | Training loss: 0.6878256931430415
Epoch: 11 | Iteration number: [960/4518] 21% | Training loss: 0.6878220872953534
Epoch: 11 | Iteration number: [970/4518] 21% | Training loss: 0.6877783468703633
Epoch: 11 | Iteration number: [980/4518] 21% | Training loss: 0.6877773059874165
Epoch: 11 | Iteration number: [990/4518] 21% | Training loss: 0.6877843893537617
Epoch: 11 | Iteration number: [1000/4518] 22% | Training loss: 0.6877785193324089
Epoch: 11 | Iteration number: [1010/4518] 22% | Training loss: 0.6877616234345011
Epoch: 11 | Iteration number: [1020/4518] 22% | Training loss: 0.6877601095274383
Epoch: 11 | Iteration number: [1030/4518] 22% | Training loss: 0.6877537229107421
Epoch: 11 | Iteration number: [1040/4518] 23% | Training loss: 0.6877443459744637
Epoch: 11 | Iteration number: [1050/4518] 23% | Training loss: 0.6877372892129989
Epoch: 11 | Iteration number: [1060/4518] 23% | Training loss: 0.6877412505869596
Epoch: 11 | Iteration number: [1070/4518] 23% | Training loss: 0.6877216527952212
Epoch: 11 | Iteration number: [1080/4518] 23% | Training loss: 0.6877134820377385
Epoch: 11 | Iteration number: [1090/4518] 24% | Training loss: 0.6877071501465019
Epoch: 11 | Iteration number: [1100/4518] 24% | Training loss: 0.6876945557919416
Epoch: 11 | Iteration number: [1110/4518] 24% | Training loss: 0.6876908270088402
Epoch: 11 | Iteration number: [1120/4518] 24% | Training loss: 0.687686604953238
Epoch: 11 | Iteration number: [1130/4518] 25% | Training loss: 0.6876765547600467
Epoch: 11 | Iteration number: [1140/4518] 25% | Training loss: 0.687667239130589
Epoch: 11 | Iteration number: [1150/4518] 25% | Training loss: 0.6876582599204519
Epoch: 11 | Iteration number: [1160/4518] 25% | Training loss: 0.6876525126654526
Epoch: 11 | Iteration number: [1170/4518] 25% | Training loss: 0.6876543049628918
Epoch: 11 | Iteration number: [1180/4518] 26% | Training loss: 0.6876550695148566
Epoch: 11 | Iteration number: [1190/4518] 26% | Training loss: 0.68764236729686
Epoch: 11 | Iteration number: [1200/4518] 26% | Training loss: 0.6876328734556834
Epoch: 11 | Iteration number: [1210/4518] 26% | Training loss: 0.6876244567642528
Epoch: 11 | Iteration number: [1220/4518] 27% | Training loss: 0.6876332386595304
Epoch: 11 | Iteration number: [1230/4518] 27% | Training loss: 0.687634557970171
Epoch: 11 | Iteration number: [1240/4518] 27% | Training loss: 0.6876388607967284
Epoch: 11 | Iteration number: [1250/4518] 27% | Training loss: 0.6876478394031524
Epoch: 11 | Iteration number: [1260/4518] 27% | Training loss: 0.6876390983187963
Epoch: 11 | Iteration number: [1270/4518] 28% | Training loss: 0.6876314854058694
Epoch: 11 | Iteration number: [1280/4518] 28% | Training loss: 0.6876237956341356
Epoch: 11 | Iteration number: [1290/4518] 28% | Training loss: 0.6876096478266309
Epoch: 11 | Iteration number: [1300/4518] 28% | Training loss: 0.6876080899055188
Epoch: 11 | Iteration number: [1310/4518] 28% | Training loss: 0.6876071487674277
Epoch: 11 | Iteration number: [1320/4518] 29% | Training loss: 0.6876061919060621
Epoch: 11 | Iteration number: [1330/4518] 29% | Training loss: 0.68760614301029
Epoch: 11 | Iteration number: [1340/4518] 29% | Training loss: 0.6875925988403719
Epoch: 11 | Iteration number: [1350/4518] 29% | Training loss: 0.6875907511181302
Epoch: 11 | Iteration number: [1360/4518] 30% | Training loss: 0.6875880843576263
Epoch: 11 | Iteration number: [1370/4518] 30% | Training loss: 0.6875765547700172
Epoch: 11 | Iteration number: [1380/4518] 30% | Training loss: 0.6875752769086672
Epoch: 11 | Iteration number: [1390/4518] 30% | Training loss: 0.6875692484618948
Epoch: 11 | Iteration number: [1400/4518] 30% | Training loss: 0.687563074529171
Epoch: 11 | Iteration number: [1410/4518] 31% | Training loss: 0.6875567045194882
Epoch: 11 | Iteration number: [1420/4518] 31% | Training loss: 0.6875510472646902
Epoch: 11 | Iteration number: [1430/4518] 31% | Training loss: 0.6875397719703354
Epoch: 11 | Iteration number: [1440/4518] 31% | Training loss: 0.6875341910868883
Epoch: 11 | Iteration number: [1450/4518] 32% | Training loss: 0.6875393824330691
Epoch: 11 | Iteration number: [1460/4518] 32% | Training loss: 0.6875456242936931
Epoch: 11 | Iteration number: [1470/4518] 32% | Training loss: 0.6875383003228376
Epoch: 11 | Iteration number: [1480/4518] 32% | Training loss: 0.6875480512106741
Epoch: 11 | Iteration number: [1490/4518] 32% | Training loss: 0.6875471805166078
Epoch: 11 | Iteration number: [1500/4518] 33% | Training loss: 0.6875415788094202
Epoch: 11 | Iteration number: [1510/4518] 33% | Training loss: 0.6875358867724211
Epoch: 11 | Iteration number: [1520/4518] 33% | Training loss: 0.6875288201790107
Epoch: 11 | Iteration number: [1530/4518] 33% | Training loss: 0.6875279389175715
Epoch: 11 | Iteration number: [1540/4518] 34% | Training loss: 0.6875280952298796
Epoch: 11 | Iteration number: [1550/4518] 34% | Training loss: 0.6875234141272883
Epoch: 11 | Iteration number: [1560/4518] 34% | Training loss: 0.6875204917330008
Epoch: 11 | Iteration number: [1570/4518] 34% | Training loss: 0.6875121204716385
Epoch: 11 | Iteration number: [1580/4518] 34% | Training loss: 0.6875087990790982
Epoch: 11 | Iteration number: [1590/4518] 35% | Training loss: 0.6875106808899334
Epoch: 11 | Iteration number: [1600/4518] 35% | Training loss: 0.6875000249966979
Epoch: 11 | Iteration number: [1610/4518] 35% | Training loss: 0.6874923637935093
Epoch: 11 | Iteration number: [1620/4518] 35% | Training loss: 0.687482033982689
Epoch: 11 | Iteration number: [1630/4518] 36% | Training loss: 0.6874760702709479
Epoch: 11 | Iteration number: [1640/4518] 36% | Training loss: 0.6874739895506603
Epoch: 11 | Iteration number: [1650/4518] 36% | Training loss: 0.6874655031074177
Epoch: 11 | Iteration number: [1660/4518] 36% | Training loss: 0.687464842272092
Epoch: 11 | Iteration number: [1670/4518] 36% | Training loss: 0.6874726847617212
Epoch: 11 | Iteration number: [1680/4518] 37% | Training loss: 0.6874732783507733
Epoch: 11 | Iteration number: [1690/4518] 37% | Training loss: 0.6874607038215773
Epoch: 11 | Iteration number: [1700/4518] 37% | Training loss: 0.6874571076912038
Epoch: 11 | Iteration number: [1710/4518] 37% | Training loss: 0.6874469407469208
Epoch: 11 | Iteration number: [1720/4518] 38% | Training loss: 0.687440913187903
Epoch: 11 | Iteration number: [1730/4518] 38% | Training loss: 0.6874382221629853
Epoch: 11 | Iteration number: [1740/4518] 38% | Training loss: 0.6874363569007522
Epoch: 11 | Iteration number: [1750/4518] 38% | Training loss: 0.6874307781628199
Epoch: 11 | Iteration number: [1760/4518] 38% | Training loss: 0.6874335177242756
Epoch: 11 | Iteration number: [1770/4518] 39% | Training loss: 0.6874312673584889
Epoch: 11 | Iteration number: [1780/4518] 39% | Training loss: 0.6874288546905089
Epoch: 11 | Iteration number: [1790/4518] 39% | Training loss: 0.6874229357562252
Epoch: 11 | Iteration number: [1800/4518] 39% | Training loss: 0.6874250244763163
Epoch: 11 | Iteration number: [1810/4518] 40% | Training loss: 0.6874161976806367
Epoch: 11 | Iteration number: [1820/4518] 40% | Training loss: 0.6874124142167333
Epoch: 11 | Iteration number: [1830/4518] 40% | Training loss: 0.687409507414031
Epoch: 11 | Iteration number: [1840/4518] 40% | Training loss: 0.6873974834447322
Epoch: 11 | Iteration number: [1850/4518] 40% | Training loss: 0.687391582405245
Epoch: 11 | Iteration number: [1860/4518] 41% | Training loss: 0.6873945997927778
Epoch: 11 | Iteration number: [1870/4518] 41% | Training loss: 0.6873874788297052
Epoch: 11 | Iteration number: [1880/4518] 41% | Training loss: 0.6873851053258206
Epoch: 11 | Iteration number: [1890/4518] 41% | Training loss: 0.687387701317116
Epoch: 11 | Iteration number: [1900/4518] 42% | Training loss: 0.6873858139075731
Epoch: 11 | Iteration number: [1910/4518] 42% | Training loss: 0.6873799547787112
Epoch: 11 | Iteration number: [1920/4518] 42% | Training loss: 0.6873775632120669
Epoch: 11 | Iteration number: [1930/4518] 42% | Training loss: 0.6873763230798158
Epoch: 11 | Iteration number: [1940/4518] 42% | Training loss: 0.6873722822703037
Epoch: 11 | Iteration number: [1950/4518] 43% | Training loss: 0.687366405970011
Epoch: 11 | Iteration number: [1960/4518] 43% | Training loss: 0.687359471375845
Epoch: 11 | Iteration number: [1970/4518] 43% | Training loss: 0.687346098780027
Epoch: 11 | Iteration number: [1980/4518] 43% | Training loss: 0.6873506195015378
Epoch: 11 | Iteration number: [1990/4518] 44% | Training loss: 0.6873454528537827
Epoch: 11 | Iteration number: [2000/4518] 44% | Training loss: 0.6873447441458702
Epoch: 11 | Iteration number: [2010/4518] 44% | Training loss: 0.6873444331226064
Epoch: 11 | Iteration number: [2020/4518] 44% | Training loss: 0.6873472508227471
Epoch: 11 | Iteration number: [2030/4518] 44% | Training loss: 0.6873395759190245
Epoch: 11 | Iteration number: [2040/4518] 45% | Training loss: 0.6873372338566126
Epoch: 11 | Iteration number: [2050/4518] 45% | Training loss: 0.6873337757878187
Epoch: 11 | Iteration number: [2060/4518] 45% | Training loss: 0.6873218422086493
Epoch: 11 | Iteration number: [2070/4518] 45% | Training loss: 0.687314750491709
Epoch: 11 | Iteration number: [2080/4518] 46% | Training loss: 0.6873169242476042
Epoch: 11 | Iteration number: [2090/4518] 46% | Training loss: 0.6873165797959104
Epoch: 11 | Iteration number: [2100/4518] 46% | Training loss: 0.6873125664393107
Epoch: 11 | Iteration number: [2110/4518] 46% | Training loss: 0.6873129764439371
Epoch: 11 | Iteration number: [2120/4518] 46% | Training loss: 0.6873077122951453
Epoch: 11 | Iteration number: [2130/4518] 47% | Training loss: 0.6873040716692875
Epoch: 11 | Iteration number: [2140/4518] 47% | Training loss: 0.6873053653496448
Epoch: 11 | Iteration number: [2150/4518] 47% | Training loss: 0.6873048269748687
Epoch: 11 | Iteration number: [2160/4518] 47% | Training loss: 0.687300697217385
Epoch: 11 | Iteration number: [2170/4518] 48% | Training loss: 0.6873039592520982
Epoch: 11 | Iteration number: [2180/4518] 48% | Training loss: 0.6873007460745103
Epoch: 11 | Iteration number: [2190/4518] 48% | Training loss: 0.6873013827626564
Epoch: 11 | Iteration number: [2200/4518] 48% | Training loss: 0.6873014734549956
Epoch: 11 | Iteration number: [2210/4518] 48% | Training loss: 0.6873047243955448
Epoch: 11 | Iteration number: [2220/4518] 49% | Training loss: 0.6873041663889412
Epoch: 11 | Iteration number: [2230/4518] 49% | Training loss: 0.6873046617604157
Epoch: 11 | Iteration number: [2240/4518] 49% | Training loss: 0.6873069324929799
Epoch: 11 | Iteration number: [2250/4518] 49% | Training loss: 0.6873036477300856
Epoch: 11 | Iteration number: [2260/4518] 50% | Training loss: 0.6873117946681723
Epoch: 11 | Iteration number: [2270/4518] 50% | Training loss: 0.6873080345765085
Epoch: 11 | Iteration number: [2280/4518] 50% | Training loss: 0.6873047849849651
Epoch: 11 | Iteration number: [2290/4518] 50% | Training loss: 0.6873037597237716
Epoch: 11 | Iteration number: [2300/4518] 50% | Training loss: 0.687299707506014
Epoch: 11 | Iteration number: [2310/4518] 51% | Training loss: 0.6872984996089687
Epoch: 11 | Iteration number: [2320/4518] 51% | Training loss: 0.6873013786457736
Epoch: 11 | Iteration number: [2330/4518] 51% | Training loss: 0.6873071347183424
Epoch: 11 | Iteration number: [2340/4518] 51% | Training loss: 0.6873018234458744
Epoch: 11 | Iteration number: [2350/4518] 52% | Training loss: 0.6872938876456403
Epoch: 11 | Iteration number: [2360/4518] 52% | Training loss: 0.6872934477056487
Epoch: 11 | Iteration number: [2370/4518] 52% | Training loss: 0.6872921444947206
Epoch: 11 | Iteration number: [2380/4518] 52% | Training loss: 0.687287836490559
Epoch: 11 | Iteration number: [2390/4518] 52% | Training loss: 0.6872874255459678
Epoch: 11 | Iteration number: [2400/4518] 53% | Training loss: 0.6872855105747779
Epoch: 11 | Iteration number: [2410/4518] 53% | Training loss: 0.6872837749754245
Epoch: 11 | Iteration number: [2420/4518] 53% | Training loss: 0.6872827256760321
Epoch: 11 | Iteration number: [2430/4518] 53% | Training loss: 0.6872826306417645
Epoch: 11 | Iteration number: [2440/4518] 54% | Training loss: 0.6872796127786401
Epoch: 11 | Iteration number: [2450/4518] 54% | Training loss: 0.6872775424256616
Epoch: 11 | Iteration number: [2460/4518] 54% | Training loss: 0.6872730999215831
Epoch: 11 | Iteration number: [2470/4518] 54% | Training loss: 0.6872698822002179
Epoch: 11 | Iteration number: [2480/4518] 54% | Training loss: 0.6872697402392665
Epoch: 11 | Iteration number: [2490/4518] 55% | Training loss: 0.6872737086920374
Epoch: 11 | Iteration number: [2500/4518] 55% | Training loss: 0.6872754148244857
Epoch: 11 | Iteration number: [2510/4518] 55% | Training loss: 0.687272248681323
Epoch: 11 | Iteration number: [2520/4518] 55% | Training loss: 0.6872681658182825
Epoch: 11 | Iteration number: [2530/4518] 55% | Training loss: 0.687270215212592
Epoch: 11 | Iteration number: [2540/4518] 56% | Training loss: 0.6872715896039497
Epoch: 11 | Iteration number: [2550/4518] 56% | Training loss: 0.6872714838327146
Epoch: 11 | Iteration number: [2560/4518] 56% | Training loss: 0.6872699185973034
Epoch: 11 | Iteration number: [2570/4518] 56% | Training loss: 0.6872703501686512
Epoch: 11 | Iteration number: [2580/4518] 57% | Training loss: 0.6872710336086362
Epoch: 11 | Iteration number: [2590/4518] 57% | Training loss: 0.687272971684408
Epoch: 11 | Iteration number: [2600/4518] 57% | Training loss: 0.6872756565992649
Epoch: 11 | Iteration number: [2610/4518] 57% | Training loss: 0.6872735916197985
Epoch: 11 | Iteration number: [2620/4518] 57% | Training loss: 0.6872626060747918
Epoch: 11 | Iteration number: [2630/4518] 58% | Training loss: 0.6872610101908332
Epoch: 11 | Iteration number: [2640/4518] 58% | Training loss: 0.687257560681213
Epoch: 11 | Iteration number: [2650/4518] 58% | Training loss: 0.6872565387554889
Epoch: 11 | Iteration number: [2660/4518] 58% | Training loss: 0.6872544972968281
Epoch: 11 | Iteration number: [2670/4518] 59% | Training loss: 0.6872531792867497
Epoch: 11 | Iteration number: [2680/4518] 59% | Training loss: 0.6872461998863006
Epoch: 11 | Iteration number: [2690/4518] 59% | Training loss: 0.6872426554616056
Epoch: 11 | Iteration number: [2700/4518] 59% | Training loss: 0.6872380142962491
Epoch: 11 | Iteration number: [2710/4518] 59% | Training loss: 0.687238238438469
Epoch: 11 | Iteration number: [2720/4518] 60% | Training loss: 0.6872388164129327
Epoch: 11 | Iteration number: [2730/4518] 60% | Training loss: 0.6872375273879194
Epoch: 11 | Iteration number: [2740/4518] 60% | Training loss: 0.6872330145026646
Epoch: 11 | Iteration number: [2750/4518] 60% | Training loss: 0.687229798598723
Epoch: 11 | Iteration number: [2760/4518] 61% | Training loss: 0.687229304857876
Epoch: 11 | Iteration number: [2770/4518] 61% | Training loss: 0.6872299030799728
Epoch: 11 | Iteration number: [2780/4518] 61% | Training loss: 0.6872265912217201
Epoch: 11 | Iteration number: [2790/4518] 61% | Training loss: 0.6872247751254762
Epoch: 11 | Iteration number: [2800/4518] 61% | Training loss: 0.6872256209594862
Epoch: 11 | Iteration number: [2810/4518] 62% | Training loss: 0.6872236583156518
Epoch: 11 | Iteration number: [2820/4518] 62% | Training loss: 0.6872207804774562
Epoch: 11 | Iteration number: [2830/4518] 62% | Training loss: 0.6872204641992549
Epoch: 11 | Iteration number: [2840/4518] 62% | Training loss: 0.6872225525933252
Epoch: 11 | Iteration number: [2850/4518] 63% | Training loss: 0.6872214150010494
Epoch: 11 | Iteration number: [2860/4518] 63% | Training loss: 0.687219220358175
Epoch: 11 | Iteration number: [2870/4518] 63% | Training loss: 0.687218197359856
Epoch: 11 | Iteration number: [2880/4518] 63% | Training loss: 0.6872173481310407
Epoch: 11 | Iteration number: [2890/4518] 63% | Training loss: 0.6872170950095958
Epoch: 11 | Iteration number: [2900/4518] 64% | Training loss: 0.6872160401426513
Epoch: 11 | Iteration number: [2910/4518] 64% | Training loss: 0.6872137199152786
Epoch: 11 | Iteration number: [2920/4518] 64% | Training loss: 0.6872099017035471
Epoch: 11 | Iteration number: [2930/4518] 64% | Training loss: 0.6872092043987313
Epoch: 11 | Iteration number: [2940/4518] 65% | Training loss: 0.687207497423198
Epoch: 11 | Iteration number: [2950/4518] 65% | Training loss: 0.6872102298979031
Epoch: 11 | Iteration number: [2960/4518] 65% | Training loss: 0.6872062364140072
Epoch: 11 | Iteration number: [2970/4518] 65% | Training loss: 0.6872031940153552
Epoch: 11 | Iteration number: [2980/4518] 65% | Training loss: 0.6871976294773537
Epoch: 11 | Iteration number: [2990/4518] 66% | Training loss: 0.6871983375637029
Epoch: 11 | Iteration number: [3000/4518] 66% | Training loss: 0.6871978488365809
Epoch: 11 | Iteration number: [3010/4518] 66% | Training loss: 0.6871958519533227
Epoch: 11 | Iteration number: [3020/4518] 66% | Training loss: 0.6871960156998097
Epoch: 11 | Iteration number: [3030/4518] 67% | Training loss: 0.6871940405455359
Epoch: 11 | Iteration number: [3040/4518] 67% | Training loss: 0.6871919514121194
Epoch: 11 | Iteration number: [3050/4518] 67% | Training loss: 0.6871883749571003
Epoch: 11 | Iteration number: [3060/4518] 67% | Training loss: 0.6871906318111357
Epoch: 11 | Iteration number: [3070/4518] 67% | Training loss: 0.6871883853638988
Epoch: 11 | Iteration number: [3080/4518] 68% | Training loss: 0.6871879214783767
Epoch: 11 | Iteration number: [3090/4518] 68% | Training loss: 0.6871909146555805
Epoch: 11 | Iteration number: [3100/4518] 68% | Training loss: 0.6871884963973875
Epoch: 11 | Iteration number: [3110/4518] 68% | Training loss: 0.6871854165742635
Epoch: 11 | Iteration number: [3120/4518] 69% | Training loss: 0.6871846238389994
Epoch: 11 | Iteration number: [3130/4518] 69% | Training loss: 0.6871815814949073
Epoch: 11 | Iteration number: [3140/4518] 69% | Training loss: 0.687176448581325
Epoch: 11 | Iteration number: [3150/4518] 69% | Training loss: 0.6871751162362477
Epoch: 11 | Iteration number: [3160/4518] 69% | Training loss: 0.6871747025583363
Epoch: 11 | Iteration number: [3170/4518] 70% | Training loss: 0.6871752776934146
Epoch: 11 | Iteration number: [3180/4518] 70% | Training loss: 0.6871715181466168
Epoch: 11 | Iteration number: [3190/4518] 70% | Training loss: 0.6871688458239397
Epoch: 11 | Iteration number: [3200/4518] 70% | Training loss: 0.6871683883294463
Epoch: 11 | Iteration number: [3210/4518] 71% | Training loss: 0.6871652624317419
Epoch: 11 | Iteration number: [3220/4518] 71% | Training loss: 0.6871657157351512
Epoch: 11 | Iteration number: [3230/4518] 71% | Training loss: 0.687167273604833
Epoch: 11 | Iteration number: [3240/4518] 71% | Training loss: 0.6871666180130876
Epoch: 11 | Iteration number: [3250/4518] 71% | Training loss: 0.6871656903303587
Epoch: 11 | Iteration number: [3260/4518] 72% | Training loss: 0.6871636074379178
Epoch: 11 | Iteration number: [3270/4518] 72% | Training loss: 0.6871611199247728
Epoch: 11 | Iteration number: [3280/4518] 72% | Training loss: 0.6871603330642712
Epoch: 11 | Iteration number: [3290/4518] 72% | Training loss: 0.6871572179453713
Epoch: 11 | Iteration number: [3300/4518] 73% | Training loss: 0.6871538145072532
Epoch: 11 | Iteration number: [3310/4518] 73% | Training loss: 0.6871545377994952
Epoch: 11 | Iteration number: [3320/4518] 73% | Training loss: 0.6871571055916419
Epoch: 11 | Iteration number: [3330/4518] 73% | Training loss: 0.6871579979096089
Epoch: 11 | Iteration number: [3340/4518] 73% | Training loss: 0.6871585071086883
Epoch: 11 | Iteration number: [3350/4518] 74% | Training loss: 0.6871576654733117
Epoch: 11 | Iteration number: [3360/4518] 74% | Training loss: 0.6871595469081686
Epoch: 11 | Iteration number: [3370/4518] 74% | Training loss: 0.6871571251652715
Epoch: 11 | Iteration number: [3380/4518] 74% | Training loss: 0.6871585993724462
Epoch: 11 | Iteration number: [3390/4518] 75% | Training loss: 0.6871577523802586
Epoch: 11 | Iteration number: [3400/4518] 75% | Training loss: 0.6871602531391031
Epoch: 11 | Iteration number: [3410/4518] 75% | Training loss: 0.6871589174193721
Epoch: 11 | Iteration number: [3420/4518] 75% | Training loss: 0.6871588228564514
Epoch: 11 | Iteration number: [3430/4518] 75% | Training loss: 0.6871570616352315
Epoch: 11 | Iteration number: [3440/4518] 76% | Training loss: 0.6871566135176392
Epoch: 11 | Iteration number: [3450/4518] 76% | Training loss: 0.6871571093192999
Epoch: 11 | Iteration number: [3460/4518] 76% | Training loss: 0.687158298457978
Epoch: 11 | Iteration number: [3470/4518] 76% | Training loss: 0.6871553659267315
Epoch: 11 | Iteration number: [3480/4518] 77% | Training loss: 0.6871522055446416
Epoch: 11 | Iteration number: [3490/4518] 77% | Training loss: 0.6871508270075123
Epoch: 11 | Iteration number: [3500/4518] 77% | Training loss: 0.6871497169051851
Epoch: 11 | Iteration number: [3510/4518] 77% | Training loss: 0.6871501637829674
Epoch: 11 | Iteration number: [3520/4518] 77% | Training loss: 0.6871496476402337
Epoch: 11 | Iteration number: [3530/4518] 78% | Training loss: 0.6871461636452769
Epoch: 11 | Iteration number: [3540/4518] 78% | Training loss: 0.6871479314599334
Epoch: 11 | Iteration number: [3550/4518] 78% | Training loss: 0.687147915447262
Epoch: 11 | Iteration number: [3560/4518] 78% | Training loss: 0.6871526521745692
Epoch: 11 | Iteration number: [3570/4518] 79% | Training loss: 0.6871534405803146
Epoch: 11 | Iteration number: [3580/4518] 79% | Training loss: 0.6871496093339761
Epoch: 11 | Iteration number: [3590/4518] 79% | Training loss: 0.6871472175240849
Epoch: 11 | Iteration number: [3600/4518] 79% | Training loss: 0.6871473748981952
Epoch: 11 | Iteration number: [3610/4518] 79% | Training loss: 0.6871476633727055
Epoch: 11 | Iteration number: [3620/4518] 80% | Training loss: 0.6871457924335701
Epoch: 11 | Iteration number: [3630/4518] 80% | Training loss: 0.6871444749438073
Epoch: 11 | Iteration number: [3640/4518] 80% | Training loss: 0.6871460281721838
Epoch: 11 | Iteration number: [3650/4518] 80% | Training loss: 0.6871467078385288
Epoch: 11 | Iteration number: [3660/4518] 81% | Training loss: 0.6871446420586175
Epoch: 11 | Iteration number: [3670/4518] 81% | Training loss: 0.6871447931680758
Epoch: 11 | Iteration number: [3680/4518] 81% | Training loss: 0.6871478322245504
Epoch: 11 | Iteration number: [3690/4518] 81% | Training loss: 0.6871484729332652
Epoch: 11 | Iteration number: [3700/4518] 81% | Training loss: 0.6871477881798873
Epoch: 11 | Iteration number: [3710/4518] 82% | Training loss: 0.6871465211448001
Epoch: 11 | Iteration number: [3720/4518] 82% | Training loss: 0.6871478947099819
Epoch: 11 | Iteration number: [3730/4518] 82% | Training loss: 0.6871497547179061
Epoch: 11 | Iteration number: [3740/4518] 82% | Training loss: 0.6871477447091577
Epoch: 11 | Iteration number: [3750/4518] 83% | Training loss: 0.6871479895909627
Epoch: 11 | Iteration number: [3760/4518] 83% | Training loss: 0.6871450395343152
Epoch: 11 | Iteration number: [3770/4518] 83% | Training loss: 0.687145328932795
Epoch: 11 | Iteration number: [3780/4518] 83% | Training loss: 0.6871451872366446
Epoch: 11 | Iteration number: [3790/4518] 83% | Training loss: 0.687145174603349
Epoch: 11 | Iteration number: [3800/4518] 84% | Training loss: 0.6871434833658369
Epoch: 11 | Iteration number: [3810/4518] 84% | Training loss: 0.6871410059334412
Epoch: 11 | Iteration number: [3820/4518] 84% | Training loss: 0.6871391146126842
Epoch: 11 | Iteration number: [3830/4518] 84% | Training loss: 0.6871386383127606
Epoch: 11 | Iteration number: [3840/4518] 84% | Training loss: 0.6871409045687566
Epoch: 11 | Iteration number: [3850/4518] 85% | Training loss: 0.687144312270276
Epoch: 11 | Iteration number: [3860/4518] 85% | Training loss: 0.6871427032459585
Epoch: 11 | Iteration number: [3870/4518] 85% | Training loss: 0.6871375585249228
Epoch: 11 | Iteration number: [3880/4518] 85% | Training loss: 0.6871322697585391
Epoch: 11 | Iteration number: [3890/4518] 86% | Training loss: 0.68713027451829
Epoch: 11 | Iteration number: [3900/4518] 86% | Training loss: 0.6871314790768501
Epoch: 11 | Iteration number: [3910/4518] 86% | Training loss: 0.6871315590103569
Epoch: 11 | Iteration number: [3920/4518] 86% | Training loss: 0.6871307574516656
Epoch: 11 | Iteration number: [3930/4518] 86% | Training loss: 0.6871286799586153
Epoch: 11 | Iteration number: [3940/4518] 87% | Training loss: 0.6871266389407482
Epoch: 11 | Iteration number: [3950/4518] 87% | Training loss: 0.6871268658094768
Epoch: 11 | Iteration number: [3960/4518] 87% | Training loss: 0.687126261597932
Epoch: 11 | Iteration number: [3970/4518] 87% | Training loss: 0.6871273690867484
Epoch: 11 | Iteration number: [3980/4518] 88% | Training loss: 0.6871264760967475
Epoch: 11 | Iteration number: [3990/4518] 88% | Training loss: 0.68712718796013
Epoch: 11 | Iteration number: [4000/4518] 88% | Training loss: 0.6871262880414725
Epoch: 11 | Iteration number: [4010/4518] 88% | Training loss: 0.6871244310143583
Epoch: 11 | Iteration number: [4020/4518] 88% | Training loss: 0.6871234316582704
Epoch: 11 | Iteration number: [4030/4518] 89% | Training loss: 0.6871231685796979
Epoch: 11 | Iteration number: [4040/4518] 89% | Training loss: 0.6871237518026097
Epoch: 11 | Iteration number: [4050/4518] 89% | Training loss: 0.6871227215690378
Epoch: 11 | Iteration number: [4060/4518] 89% | Training loss: 0.6871237982376456
Epoch: 11 | Iteration number: [4070/4518] 90% | Training loss: 0.6871219721560982
Epoch: 11 | Iteration number: [4080/4518] 90% | Training loss: 0.6871210692852151
Epoch: 11 | Iteration number: [4090/4518] 90% | Training loss: 0.6871201589667126
Epoch: 11 | Iteration number: [4100/4518] 90% | Training loss: 0.6871227367622096
Epoch: 11 | Iteration number: [4110/4518] 90% | Training loss: 0.6871208820754884
Epoch: 11 | Iteration number: [4120/4518] 91% | Training loss: 0.6871199645463703
Epoch: 11 | Iteration number: [4130/4518] 91% | Training loss: 0.6871194060720486
Epoch: 11 | Iteration number: [4140/4518] 91% | Training loss: 0.6871199758588404
Epoch: 11 | Iteration number: [4150/4518] 91% | Training loss: 0.6871200018474855
Epoch: 11 | Iteration number: [4160/4518] 92% | Training loss: 0.6871214004806601
Epoch: 11 | Iteration number: [4170/4518] 92% | Training loss: 0.6871237721517504
Epoch: 11 | Iteration number: [4180/4518] 92% | Training loss: 0.6871228039977653
Epoch: 11 | Iteration number: [4190/4518] 92% | Training loss: 0.6871190449218477
Epoch: 11 | Iteration number: [4200/4518] 92% | Training loss: 0.6871208532083602
Epoch: 11 | Iteration number: [4210/4518] 93% | Training loss: 0.6871244799779317
Epoch: 11 | Iteration number: [4220/4518] 93% | Training loss: 0.6871261965465771
Epoch: 11 | Iteration number: [4230/4518] 93% | Training loss: 0.6871303327258316
Epoch: 11 | Iteration number: [4240/4518] 93% | Training loss: 0.6871287655577345
Epoch: 11 | Iteration number: [4250/4518] 94% | Training loss: 0.6871288894625271
Epoch: 11 | Iteration number: [4260/4518] 94% | Training loss: 0.6871299668936662
Epoch: 11 | Iteration number: [4270/4518] 94% | Training loss: 0.6871290876379617
Epoch: 11 | Iteration number: [4280/4518] 94% | Training loss: 0.6871280641060009
Epoch: 11 | Iteration number: [4290/4518] 94% | Training loss: 0.6871286403743815
Epoch: 11 | Iteration number: [4300/4518] 95% | Training loss: 0.6871251206065333
Epoch: 11 | Iteration number: [4310/4518] 95% | Training loss: 0.6871257694165834
Epoch: 11 | Iteration number: [4320/4518] 95% | Training loss: 0.6871263893390144
Epoch: 11 | Iteration number: [4330/4518] 95% | Training loss: 0.6871239706082377
Epoch: 11 | Iteration number: [4340/4518] 96% | Training loss: 0.6871228299382645
Epoch: 11 | Iteration number: [4350/4518] 96% | Training loss: 0.6871194579135412
Epoch: 11 | Iteration number: [4360/4518] 96% | Training loss: 0.6871189281891246
Epoch: 11 | Iteration number: [4370/4518] 96% | Training loss: 0.6871195146093653
Epoch: 11 | Iteration number: [4380/4518] 96% | Training loss: 0.687117562296728
Epoch: 11 | Iteration number: [4390/4518] 97% | Training loss: 0.6871191389332599
Epoch: 11 | Iteration number: [4400/4518] 97% | Training loss: 0.6871206189827486
Epoch: 11 | Iteration number: [4410/4518] 97% | Training loss: 0.687117669925668
Epoch: 11 | Iteration number: [4420/4518] 97% | Training loss: 0.687116360246326
Epoch: 11 | Iteration number: [4430/4518] 98% | Training loss: 0.6871161631079344
Epoch: 11 | Iteration number: [4440/4518] 98% | Training loss: 0.6871174750832824
Epoch: 11 | Iteration number: [4450/4518] 98% | Training loss: 0.6871180820063258
Epoch: 11 | Iteration number: [4460/4518] 98% | Training loss: 0.6871180524740519
Epoch: 11 | Iteration number: [4470/4518] 98% | Training loss: 0.6871194378641627
Epoch: 11 | Iteration number: [4480/4518] 99% | Training loss: 0.6871193582325109
Epoch: 11 | Iteration number: [4490/4518] 99% | Training loss: 0.6871197657489564
Epoch: 11 | Iteration number: [4500/4518] 99% | Training loss: 0.6871185757848951
Epoch: 11 | Iteration number: [4510/4518] 99% | Training loss: 0.6871168542991984

 End of epoch: 11 | Train Loss: 0.6869634087500502 | Training Time: 631 

 End of epoch: 11 | Eval Loss: 0.690117597579956 | Evaluating Time: 17 
Epoch: 12 | Iteration number: [10/4518] 0% | Training loss: 0.7552694797515869
Epoch: 12 | Iteration number: [20/4518] 0% | Training loss: 0.7216562807559967
Epoch: 12 | Iteration number: [30/4518] 0% | Training loss: 0.7097710072994232
Epoch: 12 | Iteration number: [40/4518] 0% | Training loss: 0.7042310044169426
Epoch: 12 | Iteration number: [50/4518] 1% | Training loss: 0.7005826711654664
Epoch: 12 | Iteration number: [60/4518] 1% | Training loss: 0.6985302656888962
Epoch: 12 | Iteration number: [70/4518] 1% | Training loss: 0.6967047878674099
Epoch: 12 | Iteration number: [80/4518] 1% | Training loss: 0.6954757206141948
Epoch: 12 | Iteration number: [90/4518] 1% | Training loss: 0.6944646563794877
Epoch: 12 | Iteration number: [100/4518] 2% | Training loss: 0.693653981089592
Epoch: 12 | Iteration number: [110/4518] 2% | Training loss: 0.6928825367580761
Epoch: 12 | Iteration number: [120/4518] 2% | Training loss: 0.6924536575873693
Epoch: 12 | Iteration number: [130/4518] 2% | Training loss: 0.6920875342992636
Epoch: 12 | Iteration number: [140/4518] 3% | Training loss: 0.6917079048497337
Epoch: 12 | Iteration number: [150/4518] 3% | Training loss: 0.6914304025967916
Epoch: 12 | Iteration number: [160/4518] 3% | Training loss: 0.6911169592291116
Epoch: 12 | Iteration number: [170/4518] 3% | Training loss: 0.6908845873440013
Epoch: 12 | Iteration number: [180/4518] 3% | Training loss: 0.6907277348968718
Epoch: 12 | Iteration number: [190/4518] 4% | Training loss: 0.6904828868414227
Epoch: 12 | Iteration number: [200/4518] 4% | Training loss: 0.690303452014923
Epoch: 12 | Iteration number: [210/4518] 4% | Training loss: 0.6901326806772323
Epoch: 12 | Iteration number: [220/4518] 4% | Training loss: 0.6899981620636854
Epoch: 12 | Iteration number: [230/4518] 5% | Training loss: 0.6898480195066203
Epoch: 12 | Iteration number: [240/4518] 5% | Training loss: 0.6896886813143889
Epoch: 12 | Iteration number: [250/4518] 5% | Training loss: 0.6896151764392853
Epoch: 12 | Iteration number: [260/4518] 5% | Training loss: 0.6895241466852334
Epoch: 12 | Iteration number: [270/4518] 5% | Training loss: 0.6894358853499095
Epoch: 12 | Iteration number: [280/4518] 6% | Training loss: 0.6893753775528499
Epoch: 12 | Iteration number: [290/4518] 6% | Training loss: 0.6893004783268633
Epoch: 12 | Iteration number: [300/4518] 6% | Training loss: 0.6892705722649892
Epoch: 12 | Iteration number: [310/4518] 6% | Training loss: 0.6891674214793789
Epoch: 12 | Iteration number: [320/4518] 7% | Training loss: 0.6891442265361547
Epoch: 12 | Iteration number: [330/4518] 7% | Training loss: 0.6890905970876867
Epoch: 12 | Iteration number: [340/4518] 7% | Training loss: 0.689054131157258
Epoch: 12 | Iteration number: [350/4518] 7% | Training loss: 0.6889887647969383
Epoch: 12 | Iteration number: [360/4518] 7% | Training loss: 0.688945198390219
Epoch: 12 | Iteration number: [370/4518] 8% | Training loss: 0.6889194517522245
Epoch: 12 | Iteration number: [380/4518] 8% | Training loss: 0.688847521731728
Epoch: 12 | Iteration number: [390/4518] 8% | Training loss: 0.6888368537792793
Epoch: 12 | Iteration number: [400/4518] 8% | Training loss: 0.6887868735194206
Epoch: 12 | Iteration number: [410/4518] 9% | Training loss: 0.6887459536878074
Epoch: 12 | Iteration number: [420/4518] 9% | Training loss: 0.6887041195517495
Epoch: 12 | Iteration number: [430/4518] 9% | Training loss: 0.6886673259180646
Epoch: 12 | Iteration number: [440/4518] 9% | Training loss: 0.6886073959144678
Epoch: 12 | Iteration number: [450/4518] 9% | Training loss: 0.6885842838552263
Epoch: 12 | Iteration number: [460/4518] 10% | Training loss: 0.6885807651540508
Epoch: 12 | Iteration number: [470/4518] 10% | Training loss: 0.6885668885200582
Epoch: 12 | Iteration number: [480/4518] 10% | Training loss: 0.6885576643049717
Epoch: 12 | Iteration number: [490/4518] 10% | Training loss: 0.688550319963572
Epoch: 12 | Iteration number: [500/4518] 11% | Training loss: 0.6885359860658645
Epoch: 12 | Iteration number: [510/4518] 11% | Training loss: 0.6885128326275769
Epoch: 12 | Iteration number: [520/4518] 11% | Training loss: 0.6884973214222835
Epoch: 12 | Iteration number: [530/4518] 11% | Training loss: 0.6884683571896463
Epoch: 12 | Iteration number: [540/4518] 11% | Training loss: 0.6884485950072606
Epoch: 12 | Iteration number: [550/4518] 12% | Training loss: 0.688429399728775
Epoch: 12 | Iteration number: [560/4518] 12% | Training loss: 0.688403412273952
Epoch: 12 | Iteration number: [570/4518] 12% | Training loss: 0.6883734114337385
Epoch: 12 | Iteration number: [580/4518] 12% | Training loss: 0.6883531282688009
Epoch: 12 | Iteration number: [590/4518] 13% | Training loss: 0.6883301926871478
Epoch: 12 | Iteration number: [600/4518] 13% | Training loss: 0.6883179246385892
Epoch: 12 | Iteration number: [610/4518] 13% | Training loss: 0.6882985501992898
Epoch: 12 | Iteration number: [620/4518] 13% | Training loss: 0.6882854906782028
Epoch: 12 | Iteration number: [630/4518] 13% | Training loss: 0.6882716237552582
Epoch: 12 | Iteration number: [640/4518] 14% | Training loss: 0.6882719373330474
Epoch: 12 | Iteration number: [650/4518] 14% | Training loss: 0.6882483834486741
Epoch: 12 | Iteration number: [660/4518] 14% | Training loss: 0.6882349366491491
Epoch: 12 | Iteration number: [670/4518] 14% | Training loss: 0.6882254042732182
Epoch: 12 | Iteration number: [680/4518] 15% | Training loss: 0.6882073955500827
Epoch: 12 | Iteration number: [690/4518] 15% | Training loss: 0.6881898080957108
Epoch: 12 | Iteration number: [700/4518] 15% | Training loss: 0.6882013301338469
Epoch: 12 | Iteration number: [710/4518] 15% | Training loss: 0.6881731747741431
Epoch: 12 | Iteration number: [720/4518] 15% | Training loss: 0.6881562392744753
Epoch: 12 | Iteration number: [730/4518] 16% | Training loss: 0.6881188327319001
Epoch: 12 | Iteration number: [740/4518] 16% | Training loss: 0.6880926841819609
Epoch: 12 | Iteration number: [750/4518] 16% | Training loss: 0.6880803594589233
Epoch: 12 | Iteration number: [760/4518] 16% | Training loss: 0.68805345704681
Epoch: 12 | Iteration number: [770/4518] 17% | Training loss: 0.6880410469971694
Epoch: 12 | Iteration number: [780/4518] 17% | Training loss: 0.6880473297375899
Epoch: 12 | Iteration number: [790/4518] 17% | Training loss: 0.688042161962654
Epoch: 12 | Iteration number: [800/4518] 17% | Training loss: 0.6880262955278158
Epoch: 12 | Iteration number: [810/4518] 17% | Training loss: 0.6880166322360804
Epoch: 12 | Iteration number: [820/4518] 18% | Training loss: 0.6879919747753841
Epoch: 12 | Iteration number: [830/4518] 18% | Training loss: 0.6879834768283798
Epoch: 12 | Iteration number: [840/4518] 18% | Training loss: 0.6879641749319576
Epoch: 12 | Iteration number: [850/4518] 18% | Training loss: 0.6879570898588966
Epoch: 12 | Iteration number: [860/4518] 19% | Training loss: 0.6879502458627834
Epoch: 12 | Iteration number: [870/4518] 19% | Training loss: 0.6879361550013224
Epoch: 12 | Iteration number: [880/4518] 19% | Training loss: 0.6879105566577478
Epoch: 12 | Iteration number: [890/4518] 19% | Training loss: 0.6878985421711139
Epoch: 12 | Iteration number: [900/4518] 19% | Training loss: 0.6878863517443339
Epoch: 12 | Iteration number: [910/4518] 20% | Training loss: 0.687884416946998
Epoch: 12 | Iteration number: [920/4518] 20% | Training loss: 0.6878680881598721
Epoch: 12 | Iteration number: [930/4518] 20% | Training loss: 0.6878662040156703
Epoch: 12 | Iteration number: [940/4518] 20% | Training loss: 0.687858505198296
Epoch: 12 | Iteration number: [950/4518] 21% | Training loss: 0.6878511026031092
Epoch: 12 | Iteration number: [960/4518] 21% | Training loss: 0.6878522890309493
Epoch: 12 | Iteration number: [970/4518] 21% | Training loss: 0.6878467589924016
Epoch: 12 | Iteration number: [980/4518] 21% | Training loss: 0.6878327803952353
Epoch: 12 | Iteration number: [990/4518] 21% | Training loss: 0.6878227949744523
Epoch: 12 | Iteration number: [1000/4518] 22% | Training loss: 0.687810122847557
Epoch: 12 | Iteration number: [1010/4518] 22% | Training loss: 0.6877905429589867
Epoch: 12 | Iteration number: [1020/4518] 22% | Training loss: 0.6877797365188598
Epoch: 12 | Iteration number: [1030/4518] 22% | Training loss: 0.6877681052221836
Epoch: 12 | Iteration number: [1040/4518] 23% | Training loss: 0.6877531414421705
Epoch: 12 | Iteration number: [1050/4518] 23% | Training loss: 0.6877498789060683
Epoch: 12 | Iteration number: [1060/4518] 23% | Training loss: 0.687735179347812
Epoch: 12 | Iteration number: [1070/4518] 23% | Training loss: 0.6877279826970858
Epoch: 12 | Iteration number: [1080/4518] 23% | Training loss: 0.6877220690802291
Epoch: 12 | Iteration number: [1090/4518] 24% | Training loss: 0.6877262583566368
Epoch: 12 | Iteration number: [1100/4518] 24% | Training loss: 0.6877207015861164
Epoch: 12 | Iteration number: [1110/4518] 24% | Training loss: 0.6877188394198547
Epoch: 12 | Iteration number: [1120/4518] 24% | Training loss: 0.6877062544226646
Epoch: 12 | Iteration number: [1130/4518] 25% | Training loss: 0.687691529187481
Epoch: 12 | Iteration number: [1140/4518] 25% | Training loss: 0.6876795919840796
Epoch: 12 | Iteration number: [1150/4518] 25% | Training loss: 0.6876805355237878
Epoch: 12 | Iteration number: [1160/4518] 25% | Training loss: 0.6876747836840564
Epoch: 12 | Iteration number: [1170/4518] 25% | Training loss: 0.6876690573162503
Epoch: 12 | Iteration number: [1180/4518] 26% | Training loss: 0.6876623611328966
Epoch: 12 | Iteration number: [1190/4518] 26% | Training loss: 0.6876552251707606
Epoch: 12 | Iteration number: [1200/4518] 26% | Training loss: 0.6876512942214806
Epoch: 12 | Iteration number: [1210/4518] 26% | Training loss: 0.6876494892372572
Epoch: 12 | Iteration number: [1220/4518] 27% | Training loss: 0.6876330350754691
Epoch: 12 | Iteration number: [1230/4518] 27% | Training loss: 0.6876399849973074
Epoch: 12 | Iteration number: [1240/4518] 27% | Training loss: 0.6876399868438321
Epoch: 12 | Iteration number: [1250/4518] 27% | Training loss: 0.6876309394836426
Epoch: 12 | Iteration number: [1260/4518] 27% | Training loss: 0.687627272946494
Epoch: 12 | Iteration number: [1270/4518] 28% | Training loss: 0.6876216059125314
Epoch: 12 | Iteration number: [1280/4518] 28% | Training loss: 0.6876174332108349
Epoch: 12 | Iteration number: [1290/4518] 28% | Training loss: 0.687614241773768
Epoch: 12 | Iteration number: [1300/4518] 28% | Training loss: 0.6876138120431167
Epoch: 12 | Iteration number: [1310/4518] 28% | Training loss: 0.6876001818489482
Epoch: 12 | Iteration number: [1320/4518] 29% | Training loss: 0.6875910727363644
Epoch: 12 | Iteration number: [1330/4518] 29% | Training loss: 0.6875856471240969
Epoch: 12 | Iteration number: [1340/4518] 29% | Training loss: 0.687584064033494
Epoch: 12 | Iteration number: [1350/4518] 29% | Training loss: 0.6875818443739856
Epoch: 12 | Iteration number: [1360/4518] 30% | Training loss: 0.6875689142328851
Epoch: 12 | Iteration number: [1370/4518] 30% | Training loss: 0.68756259566676
Epoch: 12 | Iteration number: [1380/4518] 30% | Training loss: 0.6875661535107571
Epoch: 12 | Iteration number: [1390/4518] 30% | Training loss: 0.6875548423194199
Epoch: 12 | Iteration number: [1400/4518] 30% | Training loss: 0.6875532771008356
Epoch: 12 | Iteration number: [1410/4518] 31% | Training loss: 0.6875496293636079
Epoch: 12 | Iteration number: [1420/4518] 31% | Training loss: 0.6875379849487627
Epoch: 12 | Iteration number: [1430/4518] 31% | Training loss: 0.6875312926052334
Epoch: 12 | Iteration number: [1440/4518] 31% | Training loss: 0.6875295557909542
Epoch: 12 | Iteration number: [1450/4518] 32% | Training loss: 0.687511510848999
Epoch: 12 | Iteration number: [1460/4518] 32% | Training loss: 0.6874993328770546
Epoch: 12 | Iteration number: [1470/4518] 32% | Training loss: 0.6874910080919461
Epoch: 12 | Iteration number: [1480/4518] 32% | Training loss: 0.6874853608576027
Epoch: 12 | Iteration number: [1490/4518] 32% | Training loss: 0.6874777755481285
Epoch: 12 | Iteration number: [1500/4518] 33% | Training loss: 0.6874740774234136
Epoch: 12 | Iteration number: [1510/4518] 33% | Training loss: 0.6874808251463025
Epoch: 12 | Iteration number: [1520/4518] 33% | Training loss: 0.6874746842211799
Epoch: 12 | Iteration number: [1530/4518] 33% | Training loss: 0.6874655742271274
Epoch: 12 | Iteration number: [1540/4518] 34% | Training loss: 0.6874732886428957
Epoch: 12 | Iteration number: [1550/4518] 34% | Training loss: 0.687474691906283
Epoch: 12 | Iteration number: [1560/4518] 34% | Training loss: 0.6874644551139611
Epoch: 12 | Iteration number: [1570/4518] 34% | Training loss: 0.6874584485011496
Epoch: 12 | Iteration number: [1580/4518] 34% | Training loss: 0.6874574309285683
Epoch: 12 | Iteration number: [1590/4518] 35% | Training loss: 0.6874592315850768
Epoch: 12 | Iteration number: [1600/4518] 35% | Training loss: 0.6874551396444439
Epoch: 12 | Iteration number: [1610/4518] 35% | Training loss: 0.6874541459986883
Epoch: 12 | Iteration number: [1620/4518] 35% | Training loss: 0.6874577601382762
Epoch: 12 | Iteration number: [1630/4518] 36% | Training loss: 0.6874568526364543
Epoch: 12 | Iteration number: [1640/4518] 36% | Training loss: 0.6874455290233217
Epoch: 12 | Iteration number: [1650/4518] 36% | Training loss: 0.6874452832250884
Epoch: 12 | Iteration number: [1660/4518] 36% | Training loss: 0.6874447910900575
Epoch: 12 | Iteration number: [1670/4518] 36% | Training loss: 0.6874440605055072
Epoch: 12 | Iteration number: [1680/4518] 37% | Training loss: 0.6874422850353378
Epoch: 12 | Iteration number: [1690/4518] 37% | Training loss: 0.6874417893279939
Epoch: 12 | Iteration number: [1700/4518] 37% | Training loss: 0.6874366308310452
Epoch: 12 | Iteration number: [1710/4518] 37% | Training loss: 0.6874331929878882
Epoch: 12 | Iteration number: [1720/4518] 38% | Training loss: 0.6874324702592783
Epoch: 12 | Iteration number: [1730/4518] 38% | Training loss: 0.6874372575324394
Epoch: 12 | Iteration number: [1740/4518] 38% | Training loss: 0.6874335987814542
Epoch: 12 | Iteration number: [1750/4518] 38% | Training loss: 0.6874300653253282
Epoch: 12 | Iteration number: [1760/4518] 38% | Training loss: 0.6874268405816771
Epoch: 12 | Iteration number: [1770/4518] 39% | Training loss: 0.6874179365944728
Epoch: 12 | Iteration number: [1780/4518] 39% | Training loss: 0.687410828169812
Epoch: 12 | Iteration number: [1790/4518] 39% | Training loss: 0.6874062724952591
Epoch: 12 | Iteration number: [1800/4518] 39% | Training loss: 0.6874135963453187
Epoch: 12 | Iteration number: [1810/4518] 40% | Training loss: 0.6874074503203124
Epoch: 12 | Iteration number: [1820/4518] 40% | Training loss: 0.687403205037117
Epoch: 12 | Iteration number: [1830/4518] 40% | Training loss: 0.687401142341843
Epoch: 12 | Iteration number: [1840/4518] 40% | Training loss: 0.6873987147341604
Epoch: 12 | Iteration number: [1850/4518] 40% | Training loss: 0.6873956815294318
Epoch: 12 | Iteration number: [1860/4518] 41% | Training loss: 0.6873896401095134
Epoch: 12 | Iteration number: [1870/4518] 41% | Training loss: 0.6873839021047806
Epoch: 12 | Iteration number: [1880/4518] 41% | Training loss: 0.687373958591451
Epoch: 12 | Iteration number: [1890/4518] 41% | Training loss: 0.6873762605682252
Epoch: 12 | Iteration number: [1900/4518] 42% | Training loss: 0.6873787903158288
Epoch: 12 | Iteration number: [1910/4518] 42% | Training loss: 0.6873767311660407
Epoch: 12 | Iteration number: [1920/4518] 42% | Training loss: 0.6873732799353699
Epoch: 12 | Iteration number: [1930/4518] 42% | Training loss: 0.6873608375460373
Epoch: 12 | Iteration number: [1940/4518] 42% | Training loss: 0.6873643758063464
Epoch: 12 | Iteration number: [1950/4518] 43% | Training loss: 0.6873617219619262
Epoch: 12 | Iteration number: [1960/4518] 43% | Training loss: 0.6873638121753323
Epoch: 12 | Iteration number: [1970/4518] 43% | Training loss: 0.687367209020605
Epoch: 12 | Iteration number: [1980/4518] 43% | Training loss: 0.6873620070893355
Epoch: 12 | Iteration number: [1990/4518] 44% | Training loss: 0.6873563003899464
Epoch: 12 | Iteration number: [2000/4518] 44% | Training loss: 0.687353695601225
Epoch: 12 | Iteration number: [2010/4518] 44% | Training loss: 0.6873481465809381
Epoch: 12 | Iteration number: [2020/4518] 44% | Training loss: 0.6873445584042237
Epoch: 12 | Iteration number: [2030/4518] 44% | Training loss: 0.6873432294194921
Epoch: 12 | Iteration number: [2040/4518] 45% | Training loss: 0.6873387181291393
Epoch: 12 | Iteration number: [2050/4518] 45% | Training loss: 0.687337961836559
Epoch: 12 | Iteration number: [2060/4518] 45% | Training loss: 0.6873393683178911
Epoch: 12 | Iteration number: [2070/4518] 45% | Training loss: 0.6873407953891202
Epoch: 12 | Iteration number: [2080/4518] 46% | Training loss: 0.6873424140020059
Epoch: 12 | Iteration number: [2090/4518] 46% | Training loss: 0.68733853692073
Epoch: 12 | Iteration number: [2100/4518] 46% | Training loss: 0.687335777481397
Epoch: 12 | Iteration number: [2110/4518] 46% | Training loss: 0.6873365110978131
Epoch: 12 | Iteration number: [2120/4518] 46% | Training loss: 0.6873390384721306
Epoch: 12 | Iteration number: [2130/4518] 47% | Training loss: 0.687337377625452
Epoch: 12 | Iteration number: [2140/4518] 47% | Training loss: 0.6873402527002531
Epoch: 12 | Iteration number: [2150/4518] 47% | Training loss: 0.6873287565209145
Epoch: 12 | Iteration number: [2160/4518] 47% | Training loss: 0.6873305602758019
Epoch: 12 | Iteration number: [2170/4518] 48% | Training loss: 0.6873177116367674
Epoch: 12 | Iteration number: [2180/4518] 48% | Training loss: 0.6873197188891402
Epoch: 12 | Iteration number: [2190/4518] 48% | Training loss: 0.6873195442979194
Epoch: 12 | Iteration number: [2200/4518] 48% | Training loss: 0.6873152536153794
Epoch: 12 | Iteration number: [2210/4518] 48% | Training loss: 0.6873180588715756
Epoch: 12 | Iteration number: [2220/4518] 49% | Training loss: 0.6873161301956521
Epoch: 12 | Iteration number: [2230/4518] 49% | Training loss: 0.6873193393908275
Epoch: 12 | Iteration number: [2240/4518] 49% | Training loss: 0.6873184994661382
Epoch: 12 | Iteration number: [2250/4518] 49% | Training loss: 0.6873129869567023
Epoch: 12 | Iteration number: [2260/4518] 50% | Training loss: 0.6873156883547792
Epoch: 12 | Iteration number: [2270/4518] 50% | Training loss: 0.6873154177539674
Epoch: 12 | Iteration number: [2280/4518] 50% | Training loss: 0.6873196426190828
Epoch: 12 | Iteration number: [2290/4518] 50% | Training loss: 0.6873167659257697
Epoch: 12 | Iteration number: [2300/4518] 50% | Training loss: 0.6873130354155664
Epoch: 12 | Iteration number: [2310/4518] 51% | Training loss: 0.6873057744203708
Epoch: 12 | Iteration number: [2320/4518] 51% | Training loss: 0.6873076512895782
Epoch: 12 | Iteration number: [2330/4518] 51% | Training loss: 0.6873040440768131
Epoch: 12 | Iteration number: [2340/4518] 51% | Training loss: 0.6873036523150583
Epoch: 12 | Iteration number: [2350/4518] 52% | Training loss: 0.687305559046725
Epoch: 12 | Iteration number: [2360/4518] 52% | Training loss: 0.6873052401057744
Epoch: 12 | Iteration number: [2370/4518] 52% | Training loss: 0.6873016339062639
Epoch: 12 | Iteration number: [2380/4518] 52% | Training loss: 0.6872982189434917
Epoch: 12 | Iteration number: [2390/4518] 52% | Training loss: 0.6873023829200776
Epoch: 12 | Iteration number: [2400/4518] 53% | Training loss: 0.6872991319994132
Epoch: 12 | Iteration number: [2410/4518] 53% | Training loss: 0.6872977335670677
Epoch: 12 | Iteration number: [2420/4518] 53% | Training loss: 0.6872980353014528
Epoch: 12 | Iteration number: [2430/4518] 53% | Training loss: 0.6872969407358287
Epoch: 12 | Iteration number: [2440/4518] 54% | Training loss: 0.6872976240808847
Epoch: 12 | Iteration number: [2450/4518] 54% | Training loss: 0.6872949036043517
Epoch: 12 | Iteration number: [2460/4518] 54% | Training loss: 0.6872951734114469
Epoch: 12 | Iteration number: [2470/4518] 54% | Training loss: 0.6872888795277368
Epoch: 12 | Iteration number: [2480/4518] 54% | Training loss: 0.6872876502813832
Epoch: 12 | Iteration number: [2490/4518] 55% | Training loss: 0.6872838291298433
Epoch: 12 | Iteration number: [2500/4518] 55% | Training loss: 0.6872848818063736
Epoch: 12 | Iteration number: [2510/4518] 55% | Training loss: 0.6872865854981411
Epoch: 12 | Iteration number: [2520/4518] 55% | Training loss: 0.6872899537521695
Epoch: 12 | Iteration number: [2530/4518] 55% | Training loss: 0.6872828855580492
Epoch: 12 | Iteration number: [2540/4518] 56% | Training loss: 0.6872813625833181
Epoch: 12 | Iteration number: [2550/4518] 56% | Training loss: 0.6872832901805055
Epoch: 12 | Iteration number: [2560/4518] 56% | Training loss: 0.6872780090663582
Epoch: 12 | Iteration number: [2570/4518] 56% | Training loss: 0.6872773553610776
Epoch: 12 | Iteration number: [2580/4518] 57% | Training loss: 0.687272744654685
Epoch: 12 | Iteration number: [2590/4518] 57% | Training loss: 0.6872747848853181
Epoch: 12 | Iteration number: [2600/4518] 57% | Training loss: 0.687276122707587
Epoch: 12 | Iteration number: [2610/4518] 57% | Training loss: 0.6872752523513589
Epoch: 12 | Iteration number: [2620/4518] 57% | Training loss: 0.687274118575431
Epoch: 12 | Iteration number: [2630/4518] 58% | Training loss: 0.6872733786985448
Epoch: 12 | Iteration number: [2640/4518] 58% | Training loss: 0.6872712096030061
Epoch: 12 | Iteration number: [2650/4518] 58% | Training loss: 0.6872697979774115
Epoch: 12 | Iteration number: [2660/4518] 58% | Training loss: 0.6872693058243371
Epoch: 12 | Iteration number: [2670/4518] 59% | Training loss: 0.6872683871774637
Epoch: 12 | Iteration number: [2680/4518] 59% | Training loss: 0.6872626744989139
Epoch: 12 | Iteration number: [2690/4518] 59% | Training loss: 0.6872639786798271
Epoch: 12 | Iteration number: [2700/4518] 59% | Training loss: 0.6872631799953955
Epoch: 12 | Iteration number: [2710/4518] 59% | Training loss: 0.6872662983697279
Epoch: 12 | Iteration number: [2720/4518] 60% | Training loss: 0.6872620291350519
Epoch: 12 | Iteration number: [2730/4518] 60% | Training loss: 0.6872644163313366
Epoch: 12 | Iteration number: [2740/4518] 60% | Training loss: 0.687262869903641
Epoch: 12 | Iteration number: [2750/4518] 60% | Training loss: 0.6872627556540749
Epoch: 12 | Iteration number: [2760/4518] 61% | Training loss: 0.6872614485198173
Epoch: 12 | Iteration number: [2770/4518] 61% | Training loss: 0.6872577138110618
Epoch: 12 | Iteration number: [2780/4518] 61% | Training loss: 0.6872578037085293
Epoch: 12 | Iteration number: [2790/4518] 61% | Training loss: 0.687259620833995
Epoch: 12 | Iteration number: [2800/4518] 61% | Training loss: 0.6872564455228193
Epoch: 12 | Iteration number: [2810/4518] 62% | Training loss: 0.6872606120711968
Epoch: 12 | Iteration number: [2820/4518] 62% | Training loss: 0.6872595283156591
Epoch: 12 | Iteration number: [2830/4518] 62% | Training loss: 0.687261124339626
Epoch: 12 | Iteration number: [2840/4518] 62% | Training loss: 0.6872613735811811
Epoch: 12 | Iteration number: [2850/4518] 63% | Training loss: 0.6872576088863507
Epoch: 12 | Iteration number: [2860/4518] 63% | Training loss: 0.6872548160644678
Epoch: 12 | Iteration number: [2870/4518] 63% | Training loss: 0.6872511118546596
Epoch: 12 | Iteration number: [2880/4518] 63% | Training loss: 0.6872522644077738
Epoch: 12 | Iteration number: [2890/4518] 63% | Training loss: 0.6872494050788219
Epoch: 12 | Iteration number: [2900/4518] 64% | Training loss: 0.6872513562646405
Epoch: 12 | Iteration number: [2910/4518] 64% | Training loss: 0.6872444671044236
Epoch: 12 | Iteration number: [2920/4518] 64% | Training loss: 0.687242320057464
Epoch: 12 | Iteration number: [2930/4518] 64% | Training loss: 0.6872416326210361
Epoch: 12 | Iteration number: [2940/4518] 65% | Training loss: 0.6872376667804458
Epoch: 12 | Iteration number: [2950/4518] 65% | Training loss: 0.6872332881264768
Epoch: 12 | Iteration number: [2960/4518] 65% | Training loss: 0.6872358271600427
Epoch: 12 | Iteration number: [2970/4518] 65% | Training loss: 0.6872363547082702
Epoch: 12 | Iteration number: [2980/4518] 65% | Training loss: 0.6872376073926887
Epoch: 12 | Iteration number: [2990/4518] 66% | Training loss: 0.6872353794782058
Epoch: 12 | Iteration number: [3000/4518] 66% | Training loss: 0.6872343045274416
Epoch: 12 | Iteration number: [3010/4518] 66% | Training loss: 0.6872376854831594
Epoch: 12 | Iteration number: [3020/4518] 66% | Training loss: 0.6872391178710571
Epoch: 12 | Iteration number: [3030/4518] 67% | Training loss: 0.6872377209734208
Epoch: 12 | Iteration number: [3040/4518] 67% | Training loss: 0.6872367499690307
Epoch: 12 | Iteration number: [3050/4518] 67% | Training loss: 0.6872352124237623
Epoch: 12 | Iteration number: [3060/4518] 67% | Training loss: 0.6872350754885892
Epoch: 12 | Iteration number: [3070/4518] 67% | Training loss: 0.68723515120702
Epoch: 12 | Iteration number: [3080/4518] 68% | Training loss: 0.6872364313958528
Epoch: 12 | Iteration number: [3090/4518] 68% | Training loss: 0.6872365381339607
Epoch: 12 | Iteration number: [3100/4518] 68% | Training loss: 0.6872380566020165
Epoch: 12 | Iteration number: [3110/4518] 68% | Training loss: 0.6872356906197845
Epoch: 12 | Iteration number: [3120/4518] 69% | Training loss: 0.6872327878498115
Epoch: 12 | Iteration number: [3130/4518] 69% | Training loss: 0.6872278667486513
Epoch: 12 | Iteration number: [3140/4518] 69% | Training loss: 0.6872235023102183
Epoch: 12 | Iteration number: [3150/4518] 69% | Training loss: 0.6872240942054325
Epoch: 12 | Iteration number: [3160/4518] 69% | Training loss: 0.6872251352743257
Epoch: 12 | Iteration number: [3170/4518] 70% | Training loss: 0.6872195138728205
Epoch: 12 | Iteration number: [3180/4518] 70% | Training loss: 0.6872195109068973
Epoch: 12 | Iteration number: [3190/4518] 70% | Training loss: 0.6872209928813026
Epoch: 12 | Iteration number: [3200/4518] 70% | Training loss: 0.6872184267267585
Epoch: 12 | Iteration number: [3210/4518] 71% | Training loss: 0.6872145984774438
Epoch: 12 | Iteration number: [3220/4518] 71% | Training loss: 0.6872139631776336
Epoch: 12 | Iteration number: [3230/4518] 71% | Training loss: 0.6872140914847608
Epoch: 12 | Iteration number: [3240/4518] 71% | Training loss: 0.6872123441762394
Epoch: 12 | Iteration number: [3250/4518] 71% | Training loss: 0.6872152190758631
Epoch: 12 | Iteration number: [3260/4518] 72% | Training loss: 0.6872155464865679
Epoch: 12 | Iteration number: [3270/4518] 72% | Training loss: 0.6872112436396631
Epoch: 12 | Iteration number: [3280/4518] 72% | Training loss: 0.6872094016067866
Epoch: 12 | Iteration number: [3290/4518] 72% | Training loss: 0.687205893381026
Epoch: 12 | Iteration number: [3300/4518] 73% | Training loss: 0.6872049552021604
Epoch: 12 | Iteration number: [3310/4518] 73% | Training loss: 0.6872069838724107
Epoch: 12 | Iteration number: [3320/4518] 73% | Training loss: 0.6872055274894439
Epoch: 12 | Iteration number: [3330/4518] 73% | Training loss: 0.6872055195831321
Epoch: 12 | Iteration number: [3340/4518] 73% | Training loss: 0.6872034364296291
Epoch: 12 | Iteration number: [3350/4518] 74% | Training loss: 0.6872023932257695
Epoch: 12 | Iteration number: [3360/4518] 74% | Training loss: 0.6871990541084891
Epoch: 12 | Iteration number: [3370/4518] 74% | Training loss: 0.6871971236315255
Epoch: 12 | Iteration number: [3380/4518] 74% | Training loss: 0.6871991092813086
Epoch: 12 | Iteration number: [3390/4518] 75% | Training loss: 0.6871994757546788
Epoch: 12 | Iteration number: [3400/4518] 75% | Training loss: 0.6871974755385343
Epoch: 12 | Iteration number: [3410/4518] 75% | Training loss: 0.6871952864431565
Epoch: 12 | Iteration number: [3420/4518] 75% | Training loss: 0.6871950357455259
Epoch: 12 | Iteration number: [3430/4518] 75% | Training loss: 0.6871964583070216
Epoch: 12 | Iteration number: [3440/4518] 76% | Training loss: 0.6871915875652502
Epoch: 12 | Iteration number: [3450/4518] 76% | Training loss: 0.6871887322785197
Epoch: 12 | Iteration number: [3460/4518] 76% | Training loss: 0.6871851470945888
Epoch: 12 | Iteration number: [3470/4518] 76% | Training loss: 0.6871887314216548
Epoch: 12 | Iteration number: [3480/4518] 77% | Training loss: 0.6871886809324396
Epoch: 12 | Iteration number: [3490/4518] 77% | Training loss: 0.6871890699282758
Epoch: 12 | Iteration number: [3500/4518] 77% | Training loss: 0.6871865729093551
Epoch: 12 | Iteration number: [3510/4518] 77% | Training loss: 0.6871838831663811
Epoch: 12 | Iteration number: [3520/4518] 77% | Training loss: 0.687181836315854
Epoch: 12 | Iteration number: [3530/4518] 78% | Training loss: 0.6871785365319455
Epoch: 12 | Iteration number: [3540/4518] 78% | Training loss: 0.6871794598082365
Epoch: 12 | Iteration number: [3550/4518] 78% | Training loss: 0.6871764464445517
Epoch: 12 | Iteration number: [3560/4518] 78% | Training loss: 0.6871760277098484
Epoch: 12 | Iteration number: [3570/4518] 79% | Training loss: 0.6871784805583687
Epoch: 12 | Iteration number: [3580/4518] 79% | Training loss: 0.687179458973794
Epoch: 12 | Iteration number: [3590/4518] 79% | Training loss: 0.6871765909088687
Epoch: 12 | Iteration number: [3600/4518] 79% | Training loss: 0.6871747523546219
Epoch: 12 | Iteration number: [3610/4518] 79% | Training loss: 0.68717509357883
Epoch: 12 | Iteration number: [3620/4518] 80% | Training loss: 0.68717503926372
Epoch: 12 | Iteration number: [3630/4518] 80% | Training loss: 0.68717572152122
Epoch: 12 | Iteration number: [3640/4518] 80% | Training loss: 0.6871742937754799
Epoch: 12 | Iteration number: [3650/4518] 80% | Training loss: 0.6871703068034289
Epoch: 12 | Iteration number: [3660/4518] 81% | Training loss: 0.6871693067863339
Epoch: 12 | Iteration number: [3670/4518] 81% | Training loss: 0.687166320774146
Epoch: 12 | Iteration number: [3680/4518] 81% | Training loss: 0.6871666198353404
Epoch: 12 | Iteration number: [3690/4518] 81% | Training loss: 0.6871646674667916
Epoch: 12 | Iteration number: [3700/4518] 81% | Training loss: 0.6871659007426855
Epoch: 12 | Iteration number: [3710/4518] 82% | Training loss: 0.6871655672868949
Epoch: 12 | Iteration number: [3720/4518] 82% | Training loss: 0.6871644826025092
Epoch: 12 | Iteration number: [3730/4518] 82% | Training loss: 0.6871665665355509
Epoch: 12 | Iteration number: [3740/4518] 82% | Training loss: 0.6871670709893027
Epoch: 12 | Iteration number: [3750/4518] 83% | Training loss: 0.6871650530338287
Epoch: 12 | Iteration number: [3760/4518] 83% | Training loss: 0.6871647636782616
Epoch: 12 | Iteration number: [3770/4518] 83% | Training loss: 0.687163074263211
Epoch: 12 | Iteration number: [3780/4518] 83% | Training loss: 0.6871618357915726
Epoch: 12 | Iteration number: [3790/4518] 83% | Training loss: 0.6871591759860358
Epoch: 12 | Iteration number: [3800/4518] 84% | Training loss: 0.6871601385348721
Epoch: 12 | Iteration number: [3810/4518] 84% | Training loss: 0.6871579032401087
Epoch: 12 | Iteration number: [3820/4518] 84% | Training loss: 0.6871582047477443
Epoch: 12 | Iteration number: [3830/4518] 84% | Training loss: 0.6871560985207869
Epoch: 12 | Iteration number: [3840/4518] 84% | Training loss: 0.6871547101841619
Epoch: 12 | Iteration number: [3850/4518] 85% | Training loss: 0.6871523060736718
Epoch: 12 | Iteration number: [3860/4518] 85% | Training loss: 0.6871492295376378
Epoch: 12 | Iteration number: [3870/4518] 85% | Training loss: 0.6871481661340679
Epoch: 12 | Iteration number: [3880/4518] 85% | Training loss: 0.6871436605594822
Epoch: 12 | Iteration number: [3890/4518] 86% | Training loss: 0.6871440089606994
Epoch: 12 | Iteration number: [3900/4518] 86% | Training loss: 0.6871394692323147
Epoch: 12 | Iteration number: [3910/4518] 86% | Training loss: 0.6871389225163423
Epoch: 12 | Iteration number: [3920/4518] 86% | Training loss: 0.6871379167145613
Epoch: 12 | Iteration number: [3930/4518] 86% | Training loss: 0.6871384647056347
Epoch: 12 | Iteration number: [3940/4518] 87% | Training loss: 0.6871382426489429
Epoch: 12 | Iteration number: [3950/4518] 87% | Training loss: 0.6871391108217119
Epoch: 12 | Iteration number: [3960/4518] 87% | Training loss: 0.6871398902601666
Epoch: 12 | Iteration number: [3970/4518] 87% | Training loss: 0.6871377856365078
Epoch: 12 | Iteration number: [3980/4518] 88% | Training loss: 0.6871377122312335
Epoch: 12 | Iteration number: [3990/4518] 88% | Training loss: 0.6871386322760045
Epoch: 12 | Iteration number: [4000/4518] 88% | Training loss: 0.6871361936181783
Epoch: 12 | Iteration number: [4010/4518] 88% | Training loss: 0.6871361257578072
Epoch: 12 | Iteration number: [4020/4518] 88% | Training loss: 0.6871390975529875
Epoch: 12 | Iteration number: [4030/4518] 89% | Training loss: 0.6871402732639691
Epoch: 12 | Iteration number: [4040/4518] 89% | Training loss: 0.6871372276456049
Epoch: 12 | Iteration number: [4050/4518] 89% | Training loss: 0.6871350124147203
Epoch: 12 | Iteration number: [4060/4518] 89% | Training loss: 0.6871351051506738
Epoch: 12 | Iteration number: [4070/4518] 90% | Training loss: 0.6871343451430815
Epoch: 12 | Iteration number: [4080/4518] 90% | Training loss: 0.6871319672786722
Epoch: 12 | Iteration number: [4090/4518] 90% | Training loss: 0.6871294556007992
Epoch: 12 | Iteration number: [4100/4518] 90% | Training loss: 0.6871280958739723
Epoch: 12 | Iteration number: [4110/4518] 90% | Training loss: 0.6871262642443905
Epoch: 12 | Iteration number: [4120/4518] 91% | Training loss: 0.6871265351772309
Epoch: 12 | Iteration number: [4130/4518] 91% | Training loss: 0.6871248420300842
Epoch: 12 | Iteration number: [4140/4518] 91% | Training loss: 0.6871294721169172
Epoch: 12 | Iteration number: [4150/4518] 91% | Training loss: 0.6871312470033945
Epoch: 12 | Iteration number: [4160/4518] 92% | Training loss: 0.6871320848997969
Epoch: 12 | Iteration number: [4170/4518] 92% | Training loss: 0.6871291974894435
Epoch: 12 | Iteration number: [4180/4518] 92% | Training loss: 0.6871309811703896
Epoch: 12 | Iteration number: [4190/4518] 92% | Training loss: 0.6871310283716653
Epoch: 12 | Iteration number: [4200/4518] 92% | Training loss: 0.6871317937118666
Epoch: 12 | Iteration number: [4210/4518] 93% | Training loss: 0.6871305949472758
Epoch: 12 | Iteration number: [4220/4518] 93% | Training loss: 0.6871299939839196
Epoch: 12 | Iteration number: [4230/4518] 93% | Training loss: 0.687127346378128
Epoch: 12 | Iteration number: [4240/4518] 93% | Training loss: 0.6871254221167205
Epoch: 12 | Iteration number: [4250/4518] 94% | Training loss: 0.6871223925983204
Epoch: 12 | Iteration number: [4260/4518] 94% | Training loss: 0.6871174511775164
Epoch: 12 | Iteration number: [4270/4518] 94% | Training loss: 0.6871192956696629
Epoch: 12 | Iteration number: [4280/4518] 94% | Training loss: 0.6871173440017433
Epoch: 12 | Iteration number: [4290/4518] 94% | Training loss: 0.6871166407784104
Epoch: 12 | Iteration number: [4300/4518] 95% | Training loss: 0.687117534196654
Epoch: 12 | Iteration number: [4310/4518] 95% | Training loss: 0.6871198914858692
Epoch: 12 | Iteration number: [4320/4518] 95% | Training loss: 0.6871210302191751
Epoch: 12 | Iteration number: [4330/4518] 95% | Training loss: 0.6871199345203249
Epoch: 12 | Iteration number: [4340/4518] 96% | Training loss: 0.6871216192086171
Epoch: 12 | Iteration number: [4350/4518] 96% | Training loss: 0.6871229502250409
Epoch: 12 | Iteration number: [4360/4518] 96% | Training loss: 0.6871225211871873
Epoch: 12 | Iteration number: [4370/4518] 96% | Training loss: 0.6871199101550628
Epoch: 12 | Iteration number: [4380/4518] 96% | Training loss: 0.6871187275947501
Epoch: 12 | Iteration number: [4390/4518] 97% | Training loss: 0.6871169926772628
Epoch: 12 | Iteration number: [4400/4518] 97% | Training loss: 0.6871163040128622
Epoch: 12 | Iteration number: [4410/4518] 97% | Training loss: 0.6871158406847999
Epoch: 12 | Iteration number: [4420/4518] 97% | Training loss: 0.6871153682065765
Epoch: 12 | Iteration number: [4430/4518] 98% | Training loss: 0.6871184720546344
Epoch: 12 | Iteration number: [4440/4518] 98% | Training loss: 0.6871192164517738
Epoch: 12 | Iteration number: [4450/4518] 98% | Training loss: 0.687120170874542
Epoch: 12 | Iteration number: [4460/4518] 98% | Training loss: 0.6871205894669076
Epoch: 12 | Iteration number: [4470/4518] 98% | Training loss: 0.6871158312631134
Epoch: 12 | Iteration number: [4480/4518] 99% | Training loss: 0.6871163050111916
Epoch: 12 | Iteration number: [4490/4518] 99% | Training loss: 0.6871185159364628
Epoch: 12 | Iteration number: [4500/4518] 99% | Training loss: 0.6871158740123113
Epoch: 12 | Iteration number: [4510/4518] 99% | Training loss: 0.6871109802548478

 End of epoch: 12 | Train Loss: 0.6869593420325258 | Training Time: 631 

 End of epoch: 12 | Eval Loss: 0.6902510645438213 | Evaluating Time: 17 
Epoch: 13 | Iteration number: [10/4518] 0% | Training loss: 0.7565657675266266
Epoch: 13 | Iteration number: [20/4518] 0% | Training loss: 0.7219045490026474
Epoch: 13 | Iteration number: [30/4518] 0% | Training loss: 0.7101703763008118
Epoch: 13 | Iteration number: [40/4518] 0% | Training loss: 0.7043781265616417
Epoch: 13 | Iteration number: [50/4518] 1% | Training loss: 0.7010049915313721
Epoch: 13 | Iteration number: [60/4518] 1% | Training loss: 0.6986822525660197
Epoch: 13 | Iteration number: [70/4518] 1% | Training loss: 0.6968094391482217
Epoch: 13 | Iteration number: [80/4518] 1% | Training loss: 0.6956201016902923
Epoch: 13 | Iteration number: [90/4518] 1% | Training loss: 0.6946604523393843
Epoch: 13 | Iteration number: [100/4518] 2% | Training loss: 0.6938460528850555
Epoch: 13 | Iteration number: [110/4518] 2% | Training loss: 0.6932577431201935
Epoch: 13 | Iteration number: [120/4518] 2% | Training loss: 0.6926856994628906
Epoch: 13 | Iteration number: [130/4518] 2% | Training loss: 0.6922267239827377
Epoch: 13 | Iteration number: [140/4518] 3% | Training loss: 0.6918212396757943
Epoch: 13 | Iteration number: [150/4518] 3% | Training loss: 0.6915749482313792
Epoch: 13 | Iteration number: [160/4518] 3% | Training loss: 0.6912642505019904
Epoch: 13 | Iteration number: [170/4518] 3% | Training loss: 0.6910573307205649
Epoch: 13 | Iteration number: [180/4518] 3% | Training loss: 0.6909024599525664
Epoch: 13 | Iteration number: [190/4518] 4% | Training loss: 0.6907537601496044
Epoch: 13 | Iteration number: [200/4518] 4% | Training loss: 0.6904821389913559
Epoch: 13 | Iteration number: [210/4518] 4% | Training loss: 0.6903442345914387
Epoch: 13 | Iteration number: [220/4518] 4% | Training loss: 0.6901753997260874
Epoch: 13 | Iteration number: [230/4518] 5% | Training loss: 0.6899995630202086
Epoch: 13 | Iteration number: [240/4518] 5% | Training loss: 0.6898627827564875
Epoch: 13 | Iteration number: [250/4518] 5% | Training loss: 0.6897051413059234
Epoch: 13 | Iteration number: [260/4518] 5% | Training loss: 0.6896057660763081
Epoch: 13 | Iteration number: [270/4518] 5% | Training loss: 0.6895008857603426
Epoch: 13 | Iteration number: [280/4518] 6% | Training loss: 0.6893670148083142
Epoch: 13 | Iteration number: [290/4518] 6% | Training loss: 0.6893070239445259
Epoch: 13 | Iteration number: [300/4518] 6% | Training loss: 0.6892419173320135
Epoch: 13 | Iteration number: [310/4518] 6% | Training loss: 0.6891786269603237
Epoch: 13 | Iteration number: [320/4518] 7% | Training loss: 0.689126031473279
Epoch: 13 | Iteration number: [330/4518] 7% | Training loss: 0.689061025055972
Epoch: 13 | Iteration number: [340/4518] 7% | Training loss: 0.688988158808035
Epoch: 13 | Iteration number: [350/4518] 7% | Training loss: 0.6889183866977692
Epoch: 13 | Iteration number: [360/4518] 7% | Training loss: 0.6888857669300503
Epoch: 13 | Iteration number: [370/4518] 8% | Training loss: 0.6888178325988151
Epoch: 13 | Iteration number: [380/4518] 8% | Training loss: 0.6887625258219869
Epoch: 13 | Iteration number: [390/4518] 8% | Training loss: 0.6887106267305521
Epoch: 13 | Iteration number: [400/4518] 8% | Training loss: 0.6886777590215206
Epoch: 13 | Iteration number: [410/4518] 9% | Training loss: 0.688611610633571
Epoch: 13 | Iteration number: [420/4518] 9% | Training loss: 0.6885684583868299
Epoch: 13 | Iteration number: [430/4518] 9% | Training loss: 0.6885501620381378
Epoch: 13 | Iteration number: [440/4518] 9% | Training loss: 0.6885236776687882
Epoch: 13 | Iteration number: [450/4518] 9% | Training loss: 0.6884683969285753
Epoch: 13 | Iteration number: [460/4518] 10% | Training loss: 0.6884495327006216
Epoch: 13 | Iteration number: [470/4518] 10% | Training loss: 0.6884518528238256
Epoch: 13 | Iteration number: [480/4518] 10% | Training loss: 0.6884044881910085
Epoch: 13 | Iteration number: [490/4518] 10% | Training loss: 0.6883801263205859
Epoch: 13 | Iteration number: [500/4518] 11% | Training loss: 0.6883472998142243
Epoch: 13 | Iteration number: [510/4518] 11% | Training loss: 0.6883266467674106
Epoch: 13 | Iteration number: [520/4518] 11% | Training loss: 0.6882714007909482
Epoch: 13 | Iteration number: [530/4518] 11% | Training loss: 0.6882515289873447
Epoch: 13 | Iteration number: [540/4518] 11% | Training loss: 0.6882225781679153
Epoch: 13 | Iteration number: [550/4518] 12% | Training loss: 0.6881981108405373
Epoch: 13 | Iteration number: [560/4518] 12% | Training loss: 0.6881606359566961
Epoch: 13 | Iteration number: [570/4518] 12% | Training loss: 0.6881349606472149
Epoch: 13 | Iteration number: [580/4518] 12% | Training loss: 0.6881301666128224
Epoch: 13 | Iteration number: [590/4518] 13% | Training loss: 0.6881001753322149
Epoch: 13 | Iteration number: [600/4518] 13% | Training loss: 0.6880885658661524
Epoch: 13 | Iteration number: [610/4518] 13% | Training loss: 0.688088008223987
Epoch: 13 | Iteration number: [620/4518] 13% | Training loss: 0.6880718527301666
Epoch: 13 | Iteration number: [630/4518] 13% | Training loss: 0.6880671609961797
Epoch: 13 | Iteration number: [640/4518] 14% | Training loss: 0.6880383687093854
Epoch: 13 | Iteration number: [650/4518] 14% | Training loss: 0.688029358295294
Epoch: 13 | Iteration number: [660/4518] 14% | Training loss: 0.6879936363660928
Epoch: 13 | Iteration number: [670/4518] 14% | Training loss: 0.6879860564843933
Epoch: 13 | Iteration number: [680/4518] 15% | Training loss: 0.6879794850068934
Epoch: 13 | Iteration number: [690/4518] 15% | Training loss: 0.6879646005837814
Epoch: 13 | Iteration number: [700/4518] 15% | Training loss: 0.6879591983556748
Epoch: 13 | Iteration number: [710/4518] 15% | Training loss: 0.6879453099109757
Epoch: 13 | Iteration number: [720/4518] 15% | Training loss: 0.6879371744063165
Epoch: 13 | Iteration number: [730/4518] 16% | Training loss: 0.687911789466257
Epoch: 13 | Iteration number: [740/4518] 16% | Training loss: 0.6878965433384922
Epoch: 13 | Iteration number: [750/4518] 16% | Training loss: 0.687878665526708
Epoch: 13 | Iteration number: [760/4518] 16% | Training loss: 0.6878792575315426
Epoch: 13 | Iteration number: [770/4518] 17% | Training loss: 0.6878745880219843
Epoch: 13 | Iteration number: [780/4518] 17% | Training loss: 0.687867786639776
Epoch: 13 | Iteration number: [790/4518] 17% | Training loss: 0.6878657473039024
Epoch: 13 | Iteration number: [800/4518] 17% | Training loss: 0.6878609628230333
Epoch: 13 | Iteration number: [810/4518] 17% | Training loss: 0.6878278855188393
Epoch: 13 | Iteration number: [820/4518] 18% | Training loss: 0.6878128637627857
Epoch: 13 | Iteration number: [830/4518] 18% | Training loss: 0.6878067472613002
Epoch: 13 | Iteration number: [840/4518] 18% | Training loss: 0.6877893203780765
Epoch: 13 | Iteration number: [850/4518] 18% | Training loss: 0.6877780070024379
Epoch: 13 | Iteration number: [860/4518] 19% | Training loss: 0.6877753391515377
Epoch: 13 | Iteration number: [870/4518] 19% | Training loss: 0.6877505603877977
Epoch: 13 | Iteration number: [880/4518] 19% | Training loss: 0.6877518554980104
Epoch: 13 | Iteration number: [890/4518] 19% | Training loss: 0.6877481554331405
Epoch: 13 | Iteration number: [900/4518] 19% | Training loss: 0.6877410558197233
Epoch: 13 | Iteration number: [910/4518] 20% | Training loss: 0.6877283751309573
Epoch: 13 | Iteration number: [920/4518] 20% | Training loss: 0.6877241539566413
Epoch: 13 | Iteration number: [930/4518] 20% | Training loss: 0.6877303818220734
Epoch: 13 | Iteration number: [940/4518] 20% | Training loss: 0.6877256018050173
Epoch: 13 | Iteration number: [950/4518] 21% | Training loss: 0.6877141304392563
Epoch: 13 | Iteration number: [960/4518] 21% | Training loss: 0.6877274621898929
Epoch: 13 | Iteration number: [970/4518] 21% | Training loss: 0.6877231409254763
Epoch: 13 | Iteration number: [980/4518] 21% | Training loss: 0.6877095170775238
Epoch: 13 | Iteration number: [990/4518] 21% | Training loss: 0.6877102057139078
Epoch: 13 | Iteration number: [1000/4518] 22% | Training loss: 0.6877053083181381
Epoch: 13 | Iteration number: [1010/4518] 22% | Training loss: 0.6876972155405743
Epoch: 13 | Iteration number: [1020/4518] 22% | Training loss: 0.6876910056553635
Epoch: 13 | Iteration number: [1030/4518] 22% | Training loss: 0.6876851648381613
Epoch: 13 | Iteration number: [1040/4518] 23% | Training loss: 0.6876703194127634
Epoch: 13 | Iteration number: [1050/4518] 23% | Training loss: 0.6876720293362936
Epoch: 13 | Iteration number: [1060/4518] 23% | Training loss: 0.687665815454609
Epoch: 13 | Iteration number: [1070/4518] 23% | Training loss: 0.6876687375184531
Epoch: 13 | Iteration number: [1080/4518] 23% | Training loss: 0.687672051621808
Epoch: 13 | Iteration number: [1090/4518] 24% | Training loss: 0.6876711768841525
Epoch: 13 | Iteration number: [1100/4518] 24% | Training loss: 0.6876666581088846
Epoch: 13 | Iteration number: [1110/4518] 24% | Training loss: 0.6876710504024952
Epoch: 13 | Iteration number: [1120/4518] 24% | Training loss: 0.6876695145453725
Epoch: 13 | Iteration number: [1130/4518] 25% | Training loss: 0.6876547589766241
Epoch: 13 | Iteration number: [1140/4518] 25% | Training loss: 0.687646710454372
Epoch: 13 | Iteration number: [1150/4518] 25% | Training loss: 0.6876317158989285
Epoch: 13 | Iteration number: [1160/4518] 25% | Training loss: 0.6876282748991045
Epoch: 13 | Iteration number: [1170/4518] 25% | Training loss: 0.6876256205077864
Epoch: 13 | Iteration number: [1180/4518] 26% | Training loss: 0.6876250855498395
Epoch: 13 | Iteration number: [1190/4518] 26% | Training loss: 0.687621468155324
Epoch: 13 | Iteration number: [1200/4518] 26% | Training loss: 0.6876202661295732
Epoch: 13 | Iteration number: [1210/4518] 26% | Training loss: 0.6876196886389708
Epoch: 13 | Iteration number: [1220/4518] 27% | Training loss: 0.6876134822114569
Epoch: 13 | Iteration number: [1230/4518] 27% | Training loss: 0.6876120369124219
Epoch: 13 | Iteration number: [1240/4518] 27% | Training loss: 0.687603892626301
Epoch: 13 | Iteration number: [1250/4518] 27% | Training loss: 0.6876042746543884
Epoch: 13 | Iteration number: [1260/4518] 27% | Training loss: 0.6875872644167098
Epoch: 13 | Iteration number: [1270/4518] 28% | Training loss: 0.6875766884154222
Epoch: 13 | Iteration number: [1280/4518] 28% | Training loss: 0.6875718072988093
Epoch: 13 | Iteration number: [1290/4518] 28% | Training loss: 0.6875633115454237
Epoch: 13 | Iteration number: [1300/4518] 28% | Training loss: 0.6875596293577781
Epoch: 13 | Iteration number: [1310/4518] 28% | Training loss: 0.6875573925389589
Epoch: 13 | Iteration number: [1320/4518] 29% | Training loss: 0.687545761014476
Epoch: 13 | Iteration number: [1330/4518] 29% | Training loss: 0.6875306906108569
Epoch: 13 | Iteration number: [1340/4518] 29% | Training loss: 0.6875263037966258
Epoch: 13 | Iteration number: [1350/4518] 29% | Training loss: 0.6875206074008235
Epoch: 13 | Iteration number: [1360/4518] 30% | Training loss: 0.6875082843443927
Epoch: 13 | Iteration number: [1370/4518] 30% | Training loss: 0.6875025222771359
Epoch: 13 | Iteration number: [1380/4518] 30% | Training loss: 0.6875003223401913
Epoch: 13 | Iteration number: [1390/4518] 30% | Training loss: 0.687508622562285
Epoch: 13 | Iteration number: [1400/4518] 30% | Training loss: 0.6874925134011677
Epoch: 13 | Iteration number: [1410/4518] 31% | Training loss: 0.6874932456523815
Epoch: 13 | Iteration number: [1420/4518] 31% | Training loss: 0.6874997359346336
Epoch: 13 | Iteration number: [1430/4518] 31% | Training loss: 0.6874982097765783
Epoch: 13 | Iteration number: [1440/4518] 31% | Training loss: 0.6874898667964671
Epoch: 13 | Iteration number: [1450/4518] 32% | Training loss: 0.6874847557626922
Epoch: 13 | Iteration number: [1460/4518] 32% | Training loss: 0.6874763881506986
Epoch: 13 | Iteration number: [1470/4518] 32% | Training loss: 0.687464441693559
Epoch: 13 | Iteration number: [1480/4518] 32% | Training loss: 0.6874593867240726
Epoch: 13 | Iteration number: [1490/4518] 32% | Training loss: 0.6874627163746213
Epoch: 13 | Iteration number: [1500/4518] 33% | Training loss: 0.6874583037694295
Epoch: 13 | Iteration number: [1510/4518] 33% | Training loss: 0.6874578473189019
Epoch: 13 | Iteration number: [1520/4518] 33% | Training loss: 0.6874581329132381
Epoch: 13 | Iteration number: [1530/4518] 33% | Training loss: 0.6874561522131651
Epoch: 13 | Iteration number: [1540/4518] 34% | Training loss: 0.6874552482521379
Epoch: 13 | Iteration number: [1550/4518] 34% | Training loss: 0.6874541297651107
Epoch: 13 | Iteration number: [1560/4518] 34% | Training loss: 0.6874460693353261
Epoch: 13 | Iteration number: [1570/4518] 34% | Training loss: 0.6874349781282388
Epoch: 13 | Iteration number: [1580/4518] 34% | Training loss: 0.68743413117113
Epoch: 13 | Iteration number: [1590/4518] 35% | Training loss: 0.6874301176775927
Epoch: 13 | Iteration number: [1600/4518] 35% | Training loss: 0.6874231591448188
Epoch: 13 | Iteration number: [1610/4518] 35% | Training loss: 0.6874195307678317
Epoch: 13 | Iteration number: [1620/4518] 35% | Training loss: 0.6874161315552982
Epoch: 13 | Iteration number: [1630/4518] 36% | Training loss: 0.6874080241092143
Epoch: 13 | Iteration number: [1640/4518] 36% | Training loss: 0.6874069033962924
Epoch: 13 | Iteration number: [1650/4518] 36% | Training loss: 0.6874039946541641
Epoch: 13 | Iteration number: [1660/4518] 36% | Training loss: 0.687409936914961
Epoch: 13 | Iteration number: [1670/4518] 36% | Training loss: 0.6874161097817792
Epoch: 13 | Iteration number: [1680/4518] 37% | Training loss: 0.6874181288693633
Epoch: 13 | Iteration number: [1690/4518] 37% | Training loss: 0.6874114568769579
Epoch: 13 | Iteration number: [1700/4518] 37% | Training loss: 0.6873996023220175
Epoch: 13 | Iteration number: [1710/4518] 37% | Training loss: 0.6873947369773485
Epoch: 13 | Iteration number: [1720/4518] 38% | Training loss: 0.6873884646351948
Epoch: 13 | Iteration number: [1730/4518] 38% | Training loss: 0.6873810515927442
Epoch: 13 | Iteration number: [1740/4518] 38% | Training loss: 0.6873792039594431
Epoch: 13 | Iteration number: [1750/4518] 38% | Training loss: 0.6873801118986947
Epoch: 13 | Iteration number: [1760/4518] 38% | Training loss: 0.6873787773603742
Epoch: 13 | Iteration number: [1770/4518] 39% | Training loss: 0.6873844047387441
Epoch: 13 | Iteration number: [1780/4518] 39% | Training loss: 0.6873838749159588
Epoch: 13 | Iteration number: [1790/4518] 39% | Training loss: 0.6873763242580371
Epoch: 13 | Iteration number: [1800/4518] 39% | Training loss: 0.6873728016018867
Epoch: 13 | Iteration number: [1810/4518] 40% | Training loss: 0.6873737981306255
Epoch: 13 | Iteration number: [1820/4518] 40% | Training loss: 0.6873724550008774
Epoch: 13 | Iteration number: [1830/4518] 40% | Training loss: 0.687368698458854
Epoch: 13 | Iteration number: [1840/4518] 40% | Training loss: 0.6873629424882972
Epoch: 13 | Iteration number: [1850/4518] 40% | Training loss: 0.6873542901631948
Epoch: 13 | Iteration number: [1860/4518] 41% | Training loss: 0.6873613925390346
Epoch: 13 | Iteration number: [1870/4518] 41% | Training loss: 0.6873644165814241
Epoch: 13 | Iteration number: [1880/4518] 41% | Training loss: 0.6873625014373597
Epoch: 13 | Iteration number: [1890/4518] 41% | Training loss: 0.6873596910131041
Epoch: 13 | Iteration number: [1900/4518] 42% | Training loss: 0.687353571684737
Epoch: 13 | Iteration number: [1910/4518] 42% | Training loss: 0.6873535553822343
Epoch: 13 | Iteration number: [1920/4518] 42% | Training loss: 0.6873475329640011
Epoch: 13 | Iteration number: [1930/4518] 42% | Training loss: 0.6873458420674418
Epoch: 13 | Iteration number: [1940/4518] 42% | Training loss: 0.6873496352397289
Epoch: 13 | Iteration number: [1950/4518] 43% | Training loss: 0.6873486586106129
Epoch: 13 | Iteration number: [1960/4518] 43% | Training loss: 0.687347425003441
Epoch: 13 | Iteration number: [1970/4518] 43% | Training loss: 0.6873395974260902
Epoch: 13 | Iteration number: [1980/4518] 43% | Training loss: 0.687338101261794
Epoch: 13 | Iteration number: [1990/4518] 44% | Training loss: 0.6873317301572867
Epoch: 13 | Iteration number: [2000/4518] 44% | Training loss: 0.6873254167437554
Epoch: 13 | Iteration number: [2010/4518] 44% | Training loss: 0.6873239007755299
Epoch: 13 | Iteration number: [2020/4518] 44% | Training loss: 0.6873217097898521
Epoch: 13 | Iteration number: [2030/4518] 44% | Training loss: 0.6873205149115013
Epoch: 13 | Iteration number: [2040/4518] 45% | Training loss: 0.6873198063058011
Epoch: 13 | Iteration number: [2050/4518] 45% | Training loss: 0.6873146075155677
Epoch: 13 | Iteration number: [2060/4518] 45% | Training loss: 0.6873039329804264
Epoch: 13 | Iteration number: [2070/4518] 45% | Training loss: 0.687299515746066
Epoch: 13 | Iteration number: [2080/4518] 46% | Training loss: 0.6872968009458138
Epoch: 13 | Iteration number: [2090/4518] 46% | Training loss: 0.6872941233609852
Epoch: 13 | Iteration number: [2100/4518] 46% | Training loss: 0.687288910150528
Epoch: 13 | Iteration number: [2110/4518] 46% | Training loss: 0.6872855895785924
Epoch: 13 | Iteration number: [2120/4518] 46% | Training loss: 0.6872879436274745
Epoch: 13 | Iteration number: [2130/4518] 47% | Training loss: 0.6872855425440649
Epoch: 13 | Iteration number: [2140/4518] 47% | Training loss: 0.6872881574886982
Epoch: 13 | Iteration number: [2150/4518] 47% | Training loss: 0.6872825589013654
Epoch: 13 | Iteration number: [2160/4518] 47% | Training loss: 0.6872871486953012
Epoch: 13 | Iteration number: [2170/4518] 48% | Training loss: 0.6872827767227102
Epoch: 13 | Iteration number: [2180/4518] 48% | Training loss: 0.6872797434756516
Epoch: 13 | Iteration number: [2190/4518] 48% | Training loss: 0.687274473633396
Epoch: 13 | Iteration number: [2200/4518] 48% | Training loss: 0.6872707741097971
Epoch: 13 | Iteration number: [2210/4518] 48% | Training loss: 0.6872669300881986
Epoch: 13 | Iteration number: [2220/4518] 49% | Training loss: 0.6872683079124571
Epoch: 13 | Iteration number: [2230/4518] 49% | Training loss: 0.68727371243618
Epoch: 13 | Iteration number: [2240/4518] 49% | Training loss: 0.6872737947585327
Epoch: 13 | Iteration number: [2250/4518] 49% | Training loss: 0.6872735132906173
Epoch: 13 | Iteration number: [2260/4518] 50% | Training loss: 0.6872741515130069
Epoch: 13 | Iteration number: [2270/4518] 50% | Training loss: 0.687267853168664
Epoch: 13 | Iteration number: [2280/4518] 50% | Training loss: 0.6872712754889538
Epoch: 13 | Iteration number: [2290/4518] 50% | Training loss: 0.6872662510153508
Epoch: 13 | Iteration number: [2300/4518] 50% | Training loss: 0.6872644372608351
Epoch: 13 | Iteration number: [2310/4518] 51% | Training loss: 0.6872690229446857
Epoch: 13 | Iteration number: [2320/4518] 51% | Training loss: 0.6872724383812526
Epoch: 13 | Iteration number: [2330/4518] 51% | Training loss: 0.687266575266875
Epoch: 13 | Iteration number: [2340/4518] 51% | Training loss: 0.6872701208560895
Epoch: 13 | Iteration number: [2350/4518] 52% | Training loss: 0.6872699389305521
Epoch: 13 | Iteration number: [2360/4518] 52% | Training loss: 0.6872718593831789
Epoch: 13 | Iteration number: [2370/4518] 52% | Training loss: 0.6872695221679623
Epoch: 13 | Iteration number: [2380/4518] 52% | Training loss: 0.6872626028892372
Epoch: 13 | Iteration number: [2390/4518] 52% | Training loss: 0.68726189872211
Epoch: 13 | Iteration number: [2400/4518] 53% | Training loss: 0.6872532094766697
Epoch: 13 | Iteration number: [2410/4518] 53% | Training loss: 0.6872495610436958
Epoch: 13 | Iteration number: [2420/4518] 53% | Training loss: 0.6872452409553134
Epoch: 13 | Iteration number: [2430/4518] 53% | Training loss: 0.6872453102359065
Epoch: 13 | Iteration number: [2440/4518] 54% | Training loss: 0.6872416013332664
Epoch: 13 | Iteration number: [2450/4518] 54% | Training loss: 0.6872373905960394
Epoch: 13 | Iteration number: [2460/4518] 54% | Training loss: 0.687233127229582
Epoch: 13 | Iteration number: [2470/4518] 54% | Training loss: 0.6872308518963787
Epoch: 13 | Iteration number: [2480/4518] 54% | Training loss: 0.6872322065455299
Epoch: 13 | Iteration number: [2490/4518] 55% | Training loss: 0.687229385912179
Epoch: 13 | Iteration number: [2500/4518] 55% | Training loss: 0.6872313835859298
Epoch: 13 | Iteration number: [2510/4518] 55% | Training loss: 0.6872285240199937
Epoch: 13 | Iteration number: [2520/4518] 55% | Training loss: 0.6872282030563506
Epoch: 13 | Iteration number: [2530/4518] 55% | Training loss: 0.6872270851502776
Epoch: 13 | Iteration number: [2540/4518] 56% | Training loss: 0.6872234831175467
Epoch: 13 | Iteration number: [2550/4518] 56% | Training loss: 0.6872214613942539
Epoch: 13 | Iteration number: [2560/4518] 56% | Training loss: 0.6872185451677069
Epoch: 13 | Iteration number: [2570/4518] 56% | Training loss: 0.6872172261722357
Epoch: 13 | Iteration number: [2580/4518] 57% | Training loss: 0.6872157161318979
Epoch: 13 | Iteration number: [2590/4518] 57% | Training loss: 0.6872125661511219
Epoch: 13 | Iteration number: [2600/4518] 57% | Training loss: 0.6872132114263682
Epoch: 13 | Iteration number: [2610/4518] 57% | Training loss: 0.6872110847997482
Epoch: 13 | Iteration number: [2620/4518] 57% | Training loss: 0.687216314127427
Epoch: 13 | Iteration number: [2630/4518] 58% | Training loss: 0.6872113023873971
Epoch: 13 | Iteration number: [2640/4518] 58% | Training loss: 0.6872075598574046
Epoch: 13 | Iteration number: [2650/4518] 58% | Training loss: 0.6872058091748435
Epoch: 13 | Iteration number: [2660/4518] 58% | Training loss: 0.687205346679329
Epoch: 13 | Iteration number: [2670/4518] 59% | Training loss: 0.6872100261936473
Epoch: 13 | Iteration number: [2680/4518] 59% | Training loss: 0.6872137354158644
Epoch: 13 | Iteration number: [2690/4518] 59% | Training loss: 0.6872146775288209
Epoch: 13 | Iteration number: [2700/4518] 59% | Training loss: 0.6872134913117798
Epoch: 13 | Iteration number: [2710/4518] 59% | Training loss: 0.6872080004083274
Epoch: 13 | Iteration number: [2720/4518] 60% | Training loss: 0.6872028196120963
Epoch: 13 | Iteration number: [2730/4518] 60% | Training loss: 0.687201151852206
Epoch: 13 | Iteration number: [2740/4518] 60% | Training loss: 0.6872008104611488
Epoch: 13 | Iteration number: [2750/4518] 60% | Training loss: 0.6871985901702534
Epoch: 13 | Iteration number: [2760/4518] 61% | Training loss: 0.6872012481741283
Epoch: 13 | Iteration number: [2770/4518] 61% | Training loss: 0.6871992818500161
Epoch: 13 | Iteration number: [2780/4518] 61% | Training loss: 0.6872036182194305
Epoch: 13 | Iteration number: [2790/4518] 61% | Training loss: 0.6872025003356318
Epoch: 13 | Iteration number: [2800/4518] 61% | Training loss: 0.6871994855574199
Epoch: 13 | Iteration number: [2810/4518] 62% | Training loss: 0.6871991359042103
Epoch: 13 | Iteration number: [2820/4518] 62% | Training loss: 0.6871974633306476
Epoch: 13 | Iteration number: [2830/4518] 62% | Training loss: 0.6872016214229193
Epoch: 13 | Iteration number: [2840/4518] 62% | Training loss: 0.6871958842579747
Epoch: 13 | Iteration number: [2850/4518] 63% | Training loss: 0.6871960977085849
Epoch: 13 | Iteration number: [2860/4518] 63% | Training loss: 0.6871951867025216
Epoch: 13 | Iteration number: [2870/4518] 63% | Training loss: 0.6871957221305329
Epoch: 13 | Iteration number: [2880/4518] 63% | Training loss: 0.6871947818332248
Epoch: 13 | Iteration number: [2890/4518] 63% | Training loss: 0.6871975607938008
Epoch: 13 | Iteration number: [2900/4518] 64% | Training loss: 0.6871979885882344
Epoch: 13 | Iteration number: [2910/4518] 64% | Training loss: 0.6871974805581201
Epoch: 13 | Iteration number: [2920/4518] 64% | Training loss: 0.6872013226355592
Epoch: 13 | Iteration number: [2930/4518] 64% | Training loss: 0.6872022376125583
Epoch: 13 | Iteration number: [2940/4518] 65% | Training loss: 0.6872030923358438
Epoch: 13 | Iteration number: [2950/4518] 65% | Training loss: 0.687202619718293
Epoch: 13 | Iteration number: [2960/4518] 65% | Training loss: 0.6872020065180353
Epoch: 13 | Iteration number: [2970/4518] 65% | Training loss: 0.6872005281223592
Epoch: 13 | Iteration number: [2980/4518] 65% | Training loss: 0.6871962574704381
Epoch: 13 | Iteration number: [2990/4518] 66% | Training loss: 0.6871963839666501
Epoch: 13 | Iteration number: [3000/4518] 66% | Training loss: 0.6871904824972153
Epoch: 13 | Iteration number: [3010/4518] 66% | Training loss: 0.6871882086180373
Epoch: 13 | Iteration number: [3020/4518] 66% | Training loss: 0.6871877277726369
Epoch: 13 | Iteration number: [3030/4518] 67% | Training loss: 0.6871906551984277
Epoch: 13 | Iteration number: [3040/4518] 67% | Training loss: 0.687186289029686
Epoch: 13 | Iteration number: [3050/4518] 67% | Training loss: 0.687182582616806
Epoch: 13 | Iteration number: [3060/4518] 67% | Training loss: 0.6871795678255604
Epoch: 13 | Iteration number: [3070/4518] 67% | Training loss: 0.6871765406395791
Epoch: 13 | Iteration number: [3080/4518] 68% | Training loss: 0.687182112579996
Epoch: 13 | Iteration number: [3090/4518] 68% | Training loss: 0.6871866373375396
Epoch: 13 | Iteration number: [3100/4518] 68% | Training loss: 0.6871888719066497
Epoch: 13 | Iteration number: [3110/4518] 68% | Training loss: 0.6871899568574605
Epoch: 13 | Iteration number: [3120/4518] 69% | Training loss: 0.6871854662131041
Epoch: 13 | Iteration number: [3130/4518] 69% | Training loss: 0.6871822672720534
Epoch: 13 | Iteration number: [3140/4518] 69% | Training loss: 0.6871807493221987
Epoch: 13 | Iteration number: [3150/4518] 69% | Training loss: 0.6871788409021166
Epoch: 13 | Iteration number: [3160/4518] 69% | Training loss: 0.6871782441871076
Epoch: 13 | Iteration number: [3170/4518] 70% | Training loss: 0.6871814373351798
Epoch: 13 | Iteration number: [3180/4518] 70% | Training loss: 0.6871782653736618
Epoch: 13 | Iteration number: [3190/4518] 70% | Training loss: 0.6871756635676357
Epoch: 13 | Iteration number: [3200/4518] 70% | Training loss: 0.6871741494722664
Epoch: 13 | Iteration number: [3210/4518] 71% | Training loss: 0.6871730619130476
Epoch: 13 | Iteration number: [3220/4518] 71% | Training loss: 0.6871727462510885
Epoch: 13 | Iteration number: [3230/4518] 71% | Training loss: 0.6871662773953133
Epoch: 13 | Iteration number: [3240/4518] 71% | Training loss: 0.6871620782547527
Epoch: 13 | Iteration number: [3250/4518] 71% | Training loss: 0.6871603959707113
Epoch: 13 | Iteration number: [3260/4518] 72% | Training loss: 0.6871544249035829
Epoch: 13 | Iteration number: [3270/4518] 72% | Training loss: 0.6871530074227477
Epoch: 13 | Iteration number: [3280/4518] 72% | Training loss: 0.6871548472562942
Epoch: 13 | Iteration number: [3290/4518] 72% | Training loss: 0.6871559860496174
Epoch: 13 | Iteration number: [3300/4518] 73% | Training loss: 0.687156419356664
Epoch: 13 | Iteration number: [3310/4518] 73% | Training loss: 0.6871555815110394
Epoch: 13 | Iteration number: [3320/4518] 73% | Training loss: 0.6871542681771589
Epoch: 13 | Iteration number: [3330/4518] 73% | Training loss: 0.6871541351169437
Epoch: 13 | Iteration number: [3340/4518] 73% | Training loss: 0.6871519210452806
Epoch: 13 | Iteration number: [3350/4518] 74% | Training loss: 0.6871506914985713
Epoch: 13 | Iteration number: [3360/4518] 74% | Training loss: 0.6871477027201937
Epoch: 13 | Iteration number: [3370/4518] 74% | Training loss: 0.6871450200102096
Epoch: 13 | Iteration number: [3380/4518] 74% | Training loss: 0.6871475561836062
Epoch: 13 | Iteration number: [3390/4518] 75% | Training loss: 0.6871446764398816
Epoch: 13 | Iteration number: [3400/4518] 75% | Training loss: 0.6871438817241613
Epoch: 13 | Iteration number: [3410/4518] 75% | Training loss: 0.687145389489764
Epoch: 13 | Iteration number: [3420/4518] 75% | Training loss: 0.6871460901540623
Epoch: 13 | Iteration number: [3430/4518] 75% | Training loss: 0.687146102113557
Epoch: 13 | Iteration number: [3440/4518] 76% | Training loss: 0.6871448490162229
Epoch: 13 | Iteration number: [3450/4518] 76% | Training loss: 0.6871458543038023
Epoch: 13 | Iteration number: [3460/4518] 76% | Training loss: 0.6871470158155254
Epoch: 13 | Iteration number: [3470/4518] 76% | Training loss: 0.6871494552415798
Epoch: 13 | Iteration number: [3480/4518] 77% | Training loss: 0.6871496033908306
Epoch: 13 | Iteration number: [3490/4518] 77% | Training loss: 0.6871495297440143
Epoch: 13 | Iteration number: [3500/4518] 77% | Training loss: 0.6871500965186528
Epoch: 13 | Iteration number: [3510/4518] 77% | Training loss: 0.6871480532860824
Epoch: 13 | Iteration number: [3520/4518] 77% | Training loss: 0.6871474323794245
Epoch: 13 | Iteration number: [3530/4518] 78% | Training loss: 0.6871455398733826
Epoch: 13 | Iteration number: [3540/4518] 78% | Training loss: 0.6871461727356507
Epoch: 13 | Iteration number: [3550/4518] 78% | Training loss: 0.6871450250921115
Epoch: 13 | Iteration number: [3560/4518] 78% | Training loss: 0.6871464199229572
Epoch: 13 | Iteration number: [3570/4518] 79% | Training loss: 0.6871438937527793
Epoch: 13 | Iteration number: [3580/4518] 79% | Training loss: 0.6871426740505175
Epoch: 13 | Iteration number: [3590/4518] 79% | Training loss: 0.687144070249414
Epoch: 13 | Iteration number: [3600/4518] 79% | Training loss: 0.6871429864068826
Epoch: 13 | Iteration number: [3610/4518] 79% | Training loss: 0.6871394711683332
Epoch: 13 | Iteration number: [3620/4518] 80% | Training loss: 0.6871373489581419
Epoch: 13 | Iteration number: [3630/4518] 80% | Training loss: 0.6871379336542335
Epoch: 13 | Iteration number: [3640/4518] 80% | Training loss: 0.6871375112906917
Epoch: 13 | Iteration number: [3650/4518] 80% | Training loss: 0.687135934846042
Epoch: 13 | Iteration number: [3660/4518] 81% | Training loss: 0.6871341786912231
Epoch: 13 | Iteration number: [3670/4518] 81% | Training loss: 0.6871322517498962
Epoch: 13 | Iteration number: [3680/4518] 81% | Training loss: 0.6871337626939235
Epoch: 13 | Iteration number: [3690/4518] 81% | Training loss: 0.687130594269693
Epoch: 13 | Iteration number: [3700/4518] 81% | Training loss: 0.6871275948672682
Epoch: 13 | Iteration number: [3710/4518] 82% | Training loss: 0.6871276044781317
Epoch: 13 | Iteration number: [3720/4518] 82% | Training loss: 0.6871260728086195
Epoch: 13 | Iteration number: [3730/4518] 82% | Training loss: 0.6871255220420879
Epoch: 13 | Iteration number: [3740/4518] 82% | Training loss: 0.6871268721825299
Epoch: 13 | Iteration number: [3750/4518] 83% | Training loss: 0.6871254631360372
Epoch: 13 | Iteration number: [3760/4518] 83% | Training loss: 0.6871268908869713
Epoch: 13 | Iteration number: [3770/4518] 83% | Training loss: 0.6871246296309665
Epoch: 13 | Iteration number: [3780/4518] 83% | Training loss: 0.68712291059986
Epoch: 13 | Iteration number: [3790/4518] 83% | Training loss: 0.6871208820934346
Epoch: 13 | Iteration number: [3800/4518] 84% | Training loss: 0.6871208315146596
Epoch: 13 | Iteration number: [3810/4518] 84% | Training loss: 0.6871214210048435
Epoch: 13 | Iteration number: [3820/4518] 84% | Training loss: 0.687120405510458
Epoch: 13 | Iteration number: [3830/4518] 84% | Training loss: 0.6871190395741177
Epoch: 13 | Iteration number: [3840/4518] 84% | Training loss: 0.6871190630209942
Epoch: 13 | Iteration number: [3850/4518] 85% | Training loss: 0.6871197846028712
Epoch: 13 | Iteration number: [3860/4518] 85% | Training loss: 0.6871201764425465
Epoch: 13 | Iteration number: [3870/4518] 85% | Training loss: 0.6871207307783517
Epoch: 13 | Iteration number: [3880/4518] 85% | Training loss: 0.6871222178960584
Epoch: 13 | Iteration number: [3890/4518] 86% | Training loss: 0.6871203328466048
Epoch: 13 | Iteration number: [3900/4518] 86% | Training loss: 0.6871214220462701
Epoch: 13 | Iteration number: [3910/4518] 86% | Training loss: 0.6871239994645424
Epoch: 13 | Iteration number: [3920/4518] 86% | Training loss: 0.687126269100272
Epoch: 13 | Iteration number: [3930/4518] 86% | Training loss: 0.6871245778395626
Epoch: 13 | Iteration number: [3940/4518] 87% | Training loss: 0.6871241474363404
Epoch: 13 | Iteration number: [3950/4518] 87% | Training loss: 0.6871236735054209
Epoch: 13 | Iteration number: [3960/4518] 87% | Training loss: 0.6871240017239494
Epoch: 13 | Iteration number: [3970/4518] 87% | Training loss: 0.6871231766731973
Epoch: 13 | Iteration number: [3980/4518] 88% | Training loss: 0.6871261315130109
Epoch: 13 | Iteration number: [3990/4518] 88% | Training loss: 0.6871263840443509
Epoch: 13 | Iteration number: [4000/4518] 88% | Training loss: 0.6871259394884109
Epoch: 13 | Iteration number: [4010/4518] 88% | Training loss: 0.6871285518803204
Epoch: 13 | Iteration number: [4020/4518] 88% | Training loss: 0.6871282002226037
Epoch: 13 | Iteration number: [4030/4518] 89% | Training loss: 0.6871265723746705
Epoch: 13 | Iteration number: [4040/4518] 89% | Training loss: 0.6871288296757359
Epoch: 13 | Iteration number: [4050/4518] 89% | Training loss: 0.6871284581996776
Epoch: 13 | Iteration number: [4060/4518] 89% | Training loss: 0.687128642362914
Epoch: 13 | Iteration number: [4070/4518] 90% | Training loss: 0.6871323495297819
Epoch: 13 | Iteration number: [4080/4518] 90% | Training loss: 0.687133268427615
Epoch: 13 | Iteration number: [4090/4518] 90% | Training loss: 0.6871343351809495
Epoch: 13 | Iteration number: [4100/4518] 90% | Training loss: 0.687136646901689
Epoch: 13 | Iteration number: [4110/4518] 90% | Training loss: 0.687130954491831
Epoch: 13 | Iteration number: [4120/4518] 91% | Training loss: 0.6871320492723613
Epoch: 13 | Iteration number: [4130/4518] 91% | Training loss: 0.6871308224397479
Epoch: 13 | Iteration number: [4140/4518] 91% | Training loss: 0.6871268406006449
Epoch: 13 | Iteration number: [4150/4518] 91% | Training loss: 0.6871245689277189
Epoch: 13 | Iteration number: [4160/4518] 92% | Training loss: 0.687124831831226
Epoch: 13 | Iteration number: [4170/4518] 92% | Training loss: 0.687126460621397
Epoch: 13 | Iteration number: [4180/4518] 92% | Training loss: 0.6871261012896396
Epoch: 13 | Iteration number: [4190/4518] 92% | Training loss: 0.6871234799341825
Epoch: 13 | Iteration number: [4200/4518] 92% | Training loss: 0.6871222905459858
Epoch: 13 | Iteration number: [4210/4518] 93% | Training loss: 0.6871230799483573
Epoch: 13 | Iteration number: [4220/4518] 93% | Training loss: 0.6871204080033642
Epoch: 13 | Iteration number: [4230/4518] 93% | Training loss: 0.6871205600722744
Epoch: 13 | Iteration number: [4240/4518] 93% | Training loss: 0.6871203697514984
Epoch: 13 | Iteration number: [4250/4518] 94% | Training loss: 0.6871174742614522
Epoch: 13 | Iteration number: [4260/4518] 94% | Training loss: 0.6871145552172907
Epoch: 13 | Iteration number: [4270/4518] 94% | Training loss: 0.6871159683206322
Epoch: 13 | Iteration number: [4280/4518] 94% | Training loss: 0.6871139962957284
Epoch: 13 | Iteration number: [4290/4518] 94% | Training loss: 0.6871110509325574
Epoch: 13 | Iteration number: [4300/4518] 95% | Training loss: 0.687111301851827
Epoch: 13 | Iteration number: [4310/4518] 95% | Training loss: 0.6871061758209547
Epoch: 13 | Iteration number: [4320/4518] 95% | Training loss: 0.6871012013129614
Epoch: 13 | Iteration number: [4330/4518] 95% | Training loss: 0.6870985495713787
Epoch: 13 | Iteration number: [4340/4518] 96% | Training loss: 0.6870963266368286
Epoch: 13 | Iteration number: [4350/4518] 96% | Training loss: 0.687094500010041
Epoch: 13 | Iteration number: [4360/4518] 96% | Training loss: 0.6870911110568484
Epoch: 13 | Iteration number: [4370/4518] 96% | Training loss: 0.6870874484971131
Epoch: 13 | Iteration number: [4380/4518] 96% | Training loss: 0.6870893833844085
Epoch: 13 | Iteration number: [4390/4518] 97% | Training loss: 0.6870882077613562
Epoch: 13 | Iteration number: [4400/4518] 97% | Training loss: 0.687086522443728
Epoch: 13 | Iteration number: [4410/4518] 97% | Training loss: 0.6870886962159691
Epoch: 13 | Iteration number: [4420/4518] 97% | Training loss: 0.6870879746670098
Epoch: 13 | Iteration number: [4430/4518] 98% | Training loss: 0.6870865969033596
Epoch: 13 | Iteration number: [4440/4518] 98% | Training loss: 0.6870848824849
Epoch: 13 | Iteration number: [4450/4518] 98% | Training loss: 0.6870854843332527
Epoch: 13 | Iteration number: [4460/4518] 98% | Training loss: 0.6870844041953706
Epoch: 13 | Iteration number: [4470/4518] 98% | Training loss: 0.6870867599976943
Epoch: 13 | Iteration number: [4480/4518] 99% | Training loss: 0.6870872419194451
Epoch: 13 | Iteration number: [4490/4518] 99% | Training loss: 0.6870854680416048
Epoch: 13 | Iteration number: [4500/4518] 99% | Training loss: 0.6870867818858888
Epoch: 13 | Iteration number: [4510/4518] 99% | Training loss: 0.6870845729522325

 End of epoch: 13 | Train Loss: 0.6869338417987266 | Training Time: 633 

 End of epoch: 13 | Eval Loss: 0.6902996605756332 | Evaluating Time: 17 
Epoch: 14 | Iteration number: [10/4518] 0% | Training loss: 0.7555222928524017
Epoch: 14 | Iteration number: [20/4518] 0% | Training loss: 0.7214479446411133
Epoch: 14 | Iteration number: [30/4518] 0% | Training loss: 0.7102449138959249
Epoch: 14 | Iteration number: [40/4518] 0% | Training loss: 0.704704861342907
Epoch: 14 | Iteration number: [50/4518] 1% | Training loss: 0.7011065781116486
Epoch: 14 | Iteration number: [60/4518] 1% | Training loss: 0.6987928638855616
Epoch: 14 | Iteration number: [70/4518] 1% | Training loss: 0.6971265171255384
Epoch: 14 | Iteration number: [80/4518] 1% | Training loss: 0.696127413213253
Epoch: 14 | Iteration number: [90/4518] 1% | Training loss: 0.6950405346022712
Epoch: 14 | Iteration number: [100/4518] 2% | Training loss: 0.6942598378658295
Epoch: 14 | Iteration number: [110/4518] 2% | Training loss: 0.6934947143901479
Epoch: 14 | Iteration number: [120/4518] 2% | Training loss: 0.6928523932894071
Epoch: 14 | Iteration number: [130/4518] 2% | Training loss: 0.6923545447679667
Epoch: 14 | Iteration number: [140/4518] 3% | Training loss: 0.6919266551733017
Epoch: 14 | Iteration number: [150/4518] 3% | Training loss: 0.69156920115153
Epoch: 14 | Iteration number: [160/4518] 3% | Training loss: 0.6913331307470798
Epoch: 14 | Iteration number: [170/4518] 3% | Training loss: 0.6910993940689985
Epoch: 14 | Iteration number: [180/4518] 3% | Training loss: 0.6908729963832432
Epoch: 14 | Iteration number: [190/4518] 4% | Training loss: 0.6906227930596001
Epoch: 14 | Iteration number: [200/4518] 4% | Training loss: 0.6904483017325401
Epoch: 14 | Iteration number: [210/4518] 4% | Training loss: 0.6902145771753221
Epoch: 14 | Iteration number: [220/4518] 4% | Training loss: 0.690145685726946
Epoch: 14 | Iteration number: [230/4518] 5% | Training loss: 0.6900113429712212
Epoch: 14 | Iteration number: [240/4518] 5% | Training loss: 0.689865260074536
Epoch: 14 | Iteration number: [250/4518] 5% | Training loss: 0.6897754859924317
Epoch: 14 | Iteration number: [260/4518] 5% | Training loss: 0.6896379562524649
Epoch: 14 | Iteration number: [270/4518] 5% | Training loss: 0.689512512198201
Epoch: 14 | Iteration number: [280/4518] 6% | Training loss: 0.6894387602806091
Epoch: 14 | Iteration number: [290/4518] 6% | Training loss: 0.6893066959134464
Epoch: 14 | Iteration number: [300/4518] 6% | Training loss: 0.6892266708612442
Epoch: 14 | Iteration number: [310/4518] 6% | Training loss: 0.6891515804875281
Epoch: 14 | Iteration number: [320/4518] 7% | Training loss: 0.6891287168487906
Epoch: 14 | Iteration number: [330/4518] 7% | Training loss: 0.689050324938514
Epoch: 14 | Iteration number: [340/4518] 7% | Training loss: 0.6889678606215646
Epoch: 14 | Iteration number: [350/4518] 7% | Training loss: 0.6889095083304814
Epoch: 14 | Iteration number: [360/4518] 7% | Training loss: 0.688856742448277
Epoch: 14 | Iteration number: [370/4518] 8% | Training loss: 0.6888357147977159
Epoch: 14 | Iteration number: [380/4518] 8% | Training loss: 0.6887596291931052
Epoch: 14 | Iteration number: [390/4518] 8% | Training loss: 0.6887215032027318
Epoch: 14 | Iteration number: [400/4518] 8% | Training loss: 0.6886984911561013
Epoch: 14 | Iteration number: [410/4518] 9% | Training loss: 0.6886580313124308
Epoch: 14 | Iteration number: [420/4518] 9% | Training loss: 0.6886009349709465
Epoch: 14 | Iteration number: [430/4518] 9% | Training loss: 0.6885556542596152
Epoch: 14 | Iteration number: [440/4518] 9% | Training loss: 0.6884916855530305
Epoch: 14 | Iteration number: [450/4518] 9% | Training loss: 0.6884693545765347
Epoch: 14 | Iteration number: [460/4518] 10% | Training loss: 0.6884722170622453
Epoch: 14 | Iteration number: [470/4518] 10% | Training loss: 0.6884279239684977
Epoch: 14 | Iteration number: [480/4518] 10% | Training loss: 0.6883674727131923
Epoch: 14 | Iteration number: [490/4518] 10% | Training loss: 0.6883427966614158
Epoch: 14 | Iteration number: [500/4518] 11% | Training loss: 0.6883079248666764
Epoch: 14 | Iteration number: [510/4518] 11% | Training loss: 0.6882735466255862
Epoch: 14 | Iteration number: [520/4518] 11% | Training loss: 0.6882474318146705
Epoch: 14 | Iteration number: [530/4518] 11% | Training loss: 0.6882111190624957
Epoch: 14 | Iteration number: [540/4518] 11% | Training loss: 0.6881787440291157
Epoch: 14 | Iteration number: [550/4518] 12% | Training loss: 0.6881631047075445
Epoch: 14 | Iteration number: [560/4518] 12% | Training loss: 0.688132325134107
Epoch: 14 | Iteration number: [570/4518] 12% | Training loss: 0.6881137283224809
Epoch: 14 | Iteration number: [580/4518] 12% | Training loss: 0.6880848516677988
Epoch: 14 | Iteration number: [590/4518] 13% | Training loss: 0.6880565952446501
Epoch: 14 | Iteration number: [600/4518] 13% | Training loss: 0.6880406348903974
Epoch: 14 | Iteration number: [610/4518] 13% | Training loss: 0.6880187651173013
Epoch: 14 | Iteration number: [620/4518] 13% | Training loss: 0.6879950027312002
Epoch: 14 | Iteration number: [630/4518] 13% | Training loss: 0.6879823715913863
Epoch: 14 | Iteration number: [640/4518] 14% | Training loss: 0.6879569410346449
Epoch: 14 | Iteration number: [650/4518] 14% | Training loss: 0.6879367047089797
Epoch: 14 | Iteration number: [660/4518] 14% | Training loss: 0.68790506837946
Epoch: 14 | Iteration number: [670/4518] 14% | Training loss: 0.687875433021517
Epoch: 14 | Iteration number: [680/4518] 15% | Training loss: 0.6878714632462053
Epoch: 14 | Iteration number: [690/4518] 15% | Training loss: 0.6878476542839106
Epoch: 14 | Iteration number: [700/4518] 15% | Training loss: 0.6878305800471987
Epoch: 14 | Iteration number: [710/4518] 15% | Training loss: 0.6878192475983794
Epoch: 14 | Iteration number: [720/4518] 15% | Training loss: 0.6878146083818542
Epoch: 14 | Iteration number: [730/4518] 16% | Training loss: 0.6877985243927942
Epoch: 14 | Iteration number: [740/4518] 16% | Training loss: 0.6877894446656511
Epoch: 14 | Iteration number: [750/4518] 16% | Training loss: 0.6877727854251862
Epoch: 14 | Iteration number: [760/4518] 16% | Training loss: 0.6877743279463366
Epoch: 14 | Iteration number: [770/4518] 17% | Training loss: 0.6877404590705772
Epoch: 14 | Iteration number: [780/4518] 17% | Training loss: 0.6877391877082678
Epoch: 14 | Iteration number: [790/4518] 17% | Training loss: 0.6877310454090939
Epoch: 14 | Iteration number: [800/4518] 17% | Training loss: 0.6877207597345114
Epoch: 14 | Iteration number: [810/4518] 17% | Training loss: 0.6877190736340888
Epoch: 14 | Iteration number: [820/4518] 18% | Training loss: 0.6877018474951023
Epoch: 14 | Iteration number: [830/4518] 18% | Training loss: 0.6876924483172865
Epoch: 14 | Iteration number: [840/4518] 18% | Training loss: 0.687693074132715
Epoch: 14 | Iteration number: [850/4518] 18% | Training loss: 0.6876810801029205
Epoch: 14 | Iteration number: [860/4518] 19% | Training loss: 0.6876769282790117
Epoch: 14 | Iteration number: [870/4518] 19% | Training loss: 0.6876696329007204
Epoch: 14 | Iteration number: [880/4518] 19% | Training loss: 0.687675919722427
Epoch: 14 | Iteration number: [890/4518] 19% | Training loss: 0.6876747437407461
Epoch: 14 | Iteration number: [900/4518] 19% | Training loss: 0.6876723277568817
Epoch: 14 | Iteration number: [910/4518] 20% | Training loss: 0.6876544544985006
Epoch: 14 | Iteration number: [920/4518] 20% | Training loss: 0.6876478258682334
Epoch: 14 | Iteration number: [930/4518] 20% | Training loss: 0.6876279884769071
Epoch: 14 | Iteration number: [940/4518] 20% | Training loss: 0.6875922992508462
Epoch: 14 | Iteration number: [950/4518] 21% | Training loss: 0.6875784884628496
Epoch: 14 | Iteration number: [960/4518] 21% | Training loss: 0.6875544573490818
Epoch: 14 | Iteration number: [970/4518] 21% | Training loss: 0.6875498449065022
Epoch: 14 | Iteration number: [980/4518] 21% | Training loss: 0.6875402640931461
Epoch: 14 | Iteration number: [990/4518] 21% | Training loss: 0.6875279717975192
Epoch: 14 | Iteration number: [1000/4518] 22% | Training loss: 0.6875339611172676
Epoch: 14 | Iteration number: [1010/4518] 22% | Training loss: 0.6875371887542233
Epoch: 14 | Iteration number: [1020/4518] 22% | Training loss: 0.6875266506975772
Epoch: 14 | Iteration number: [1030/4518] 22% | Training loss: 0.6875287453526432
Epoch: 14 | Iteration number: [1040/4518] 23% | Training loss: 0.6875272204669622
Epoch: 14 | Iteration number: [1050/4518] 23% | Training loss: 0.687519612142018
Epoch: 14 | Iteration number: [1060/4518] 23% | Training loss: 0.6875235949484807
Epoch: 14 | Iteration number: [1070/4518] 23% | Training loss: 0.6875094083982093
Epoch: 14 | Iteration number: [1080/4518] 23% | Training loss: 0.6875148657847334
Epoch: 14 | Iteration number: [1090/4518] 24% | Training loss: 0.6875236922447835
Epoch: 14 | Iteration number: [1100/4518] 24% | Training loss: 0.6875147794051604
Epoch: 14 | Iteration number: [1110/4518] 24% | Training loss: 0.687509096420563
Epoch: 14 | Iteration number: [1120/4518] 24% | Training loss: 0.6875109629439456
Epoch: 14 | Iteration number: [1130/4518] 25% | Training loss: 0.6875142362792935
Epoch: 14 | Iteration number: [1140/4518] 25% | Training loss: 0.6875090155162309
Epoch: 14 | Iteration number: [1150/4518] 25% | Training loss: 0.687509122931439
Epoch: 14 | Iteration number: [1160/4518] 25% | Training loss: 0.6875092012615039
Epoch: 14 | Iteration number: [1170/4518] 25% | Training loss: 0.6874830742677053
Epoch: 14 | Iteration number: [1180/4518] 26% | Training loss: 0.6874846988815372
Epoch: 14 | Iteration number: [1190/4518] 26% | Training loss: 0.6874756705861131
Epoch: 14 | Iteration number: [1200/4518] 26% | Training loss: 0.6874912169078986
Epoch: 14 | Iteration number: [1210/4518] 26% | Training loss: 0.68748282760628
Epoch: 14 | Iteration number: [1220/4518] 27% | Training loss: 0.6874831206974436
Epoch: 14 | Iteration number: [1230/4518] 27% | Training loss: 0.687475262376351
Epoch: 14 | Iteration number: [1240/4518] 27% | Training loss: 0.6874640521983947
Epoch: 14 | Iteration number: [1250/4518] 27% | Training loss: 0.6874642744541168
Epoch: 14 | Iteration number: [1260/4518] 27% | Training loss: 0.6874645001358456
Epoch: 14 | Iteration number: [1270/4518] 28% | Training loss: 0.687456859847692
Epoch: 14 | Iteration number: [1280/4518] 28% | Training loss: 0.6874452266376465
Epoch: 14 | Iteration number: [1290/4518] 28% | Training loss: 0.6874337267968081
Epoch: 14 | Iteration number: [1300/4518] 28% | Training loss: 0.6874233039067341
Epoch: 14 | Iteration number: [1310/4518] 28% | Training loss: 0.6874135098384537
Epoch: 14 | Iteration number: [1320/4518] 29% | Training loss: 0.6874061052546356
Epoch: 14 | Iteration number: [1330/4518] 29% | Training loss: 0.6874057551075642
Epoch: 14 | Iteration number: [1340/4518] 29% | Training loss: 0.6873927350809325
Epoch: 14 | Iteration number: [1350/4518] 29% | Training loss: 0.6873901851088913
Epoch: 14 | Iteration number: [1360/4518] 30% | Training loss: 0.6873901035417529
Epoch: 14 | Iteration number: [1370/4518] 30% | Training loss: 0.687392535000822
Epoch: 14 | Iteration number: [1380/4518] 30% | Training loss: 0.6873950763025145
Epoch: 14 | Iteration number: [1390/4518] 30% | Training loss: 0.687390012621022
Epoch: 14 | Iteration number: [1400/4518] 30% | Training loss: 0.6873821603400366
Epoch: 14 | Iteration number: [1410/4518] 31% | Training loss: 0.6873839218988487
Epoch: 14 | Iteration number: [1420/4518] 31% | Training loss: 0.6873824903243024
Epoch: 14 | Iteration number: [1430/4518] 31% | Training loss: 0.6873764057259459
Epoch: 14 | Iteration number: [1440/4518] 31% | Training loss: 0.687366560060117
Epoch: 14 | Iteration number: [1450/4518] 32% | Training loss: 0.687366963994914
Epoch: 14 | Iteration number: [1460/4518] 32% | Training loss: 0.6873663145385377
Epoch: 14 | Iteration number: [1470/4518] 32% | Training loss: 0.6873630464076996
Epoch: 14 | Iteration number: [1480/4518] 32% | Training loss: 0.6873542014006022
Epoch: 14 | Iteration number: [1490/4518] 32% | Training loss: 0.6873626249348557
Epoch: 14 | Iteration number: [1500/4518] 33% | Training loss: 0.6873651444911957
Epoch: 14 | Iteration number: [1510/4518] 33% | Training loss: 0.6873597808231581
Epoch: 14 | Iteration number: [1520/4518] 33% | Training loss: 0.6873583153674477
Epoch: 14 | Iteration number: [1530/4518] 33% | Training loss: 0.6873646437732223
Epoch: 14 | Iteration number: [1540/4518] 34% | Training loss: 0.6873660130547239
Epoch: 14 | Iteration number: [1550/4518] 34% | Training loss: 0.6873671908147874
Epoch: 14 | Iteration number: [1560/4518] 34% | Training loss: 0.6873555541038513
Epoch: 14 | Iteration number: [1570/4518] 34% | Training loss: 0.6873448225343304
Epoch: 14 | Iteration number: [1580/4518] 34% | Training loss: 0.6873453587670869
Epoch: 14 | Iteration number: [1590/4518] 35% | Training loss: 0.6873390922381443
Epoch: 14 | Iteration number: [1600/4518] 35% | Training loss: 0.6873330388963222
Epoch: 14 | Iteration number: [1610/4518] 35% | Training loss: 0.6873296127186058
Epoch: 14 | Iteration number: [1620/4518] 35% | Training loss: 0.687325762009915
Epoch: 14 | Iteration number: [1630/4518] 36% | Training loss: 0.6873256118019666
Epoch: 14 | Iteration number: [1640/4518] 36% | Training loss: 0.6873172310794272
Epoch: 14 | Iteration number: [1650/4518] 36% | Training loss: 0.6873178501201398
Epoch: 14 | Iteration number: [1660/4518] 36% | Training loss: 0.6873228575450828
Epoch: 14 | Iteration number: [1670/4518] 36% | Training loss: 0.6873286804753149
Epoch: 14 | Iteration number: [1680/4518] 37% | Training loss: 0.6873231061867305
Epoch: 14 | Iteration number: [1690/4518] 37% | Training loss: 0.6873184450279326
Epoch: 14 | Iteration number: [1700/4518] 37% | Training loss: 0.6873153411991456
Epoch: 14 | Iteration number: [1710/4518] 37% | Training loss: 0.6873020608871304
Epoch: 14 | Iteration number: [1720/4518] 38% | Training loss: 0.6872993990432384
Epoch: 14 | Iteration number: [1730/4518] 38% | Training loss: 0.6872897012729865
Epoch: 14 | Iteration number: [1740/4518] 38% | Training loss: 0.6872891094835325
Epoch: 14 | Iteration number: [1750/4518] 38% | Training loss: 0.6872890687329428
Epoch: 14 | Iteration number: [1760/4518] 38% | Training loss: 0.6872878490862522
Epoch: 14 | Iteration number: [1770/4518] 39% | Training loss: 0.687279190990211
Epoch: 14 | Iteration number: [1780/4518] 39% | Training loss: 0.6872762747694937
Epoch: 14 | Iteration number: [1790/4518] 39% | Training loss: 0.6872731232110348
Epoch: 14 | Iteration number: [1800/4518] 39% | Training loss: 0.6872763672471046
Epoch: 14 | Iteration number: [1810/4518] 40% | Training loss: 0.6872746506119302
Epoch: 14 | Iteration number: [1820/4518] 40% | Training loss: 0.6872728589144382
Epoch: 14 | Iteration number: [1830/4518] 40% | Training loss: 0.6872765193220045
Epoch: 14 | Iteration number: [1840/4518] 40% | Training loss: 0.6872708944198878
Epoch: 14 | Iteration number: [1850/4518] 40% | Training loss: 0.6872699807785653
Epoch: 14 | Iteration number: [1860/4518] 41% | Training loss: 0.6872682005487463
Epoch: 14 | Iteration number: [1870/4518] 41% | Training loss: 0.6872741307166809
Epoch: 14 | Iteration number: [1880/4518] 41% | Training loss: 0.6872675357663885
Epoch: 14 | Iteration number: [1890/4518] 41% | Training loss: 0.6872669069855302
Epoch: 14 | Iteration number: [1900/4518] 42% | Training loss: 0.6872646353433006
Epoch: 14 | Iteration number: [1910/4518] 42% | Training loss: 0.6872609056727425
Epoch: 14 | Iteration number: [1920/4518] 42% | Training loss: 0.6872606429581841
Epoch: 14 | Iteration number: [1930/4518] 42% | Training loss: 0.6872576418318279
Epoch: 14 | Iteration number: [1940/4518] 42% | Training loss: 0.6872499467478586
Epoch: 14 | Iteration number: [1950/4518] 43% | Training loss: 0.687243618965149
Epoch: 14 | Iteration number: [1960/4518] 43% | Training loss: 0.6872402354770777
Epoch: 14 | Iteration number: [1970/4518] 43% | Training loss: 0.6872416199463878
Epoch: 14 | Iteration number: [1980/4518] 43% | Training loss: 0.6872377222234552
Epoch: 14 | Iteration number: [1990/4518] 44% | Training loss: 0.687231426143167
Epoch: 14 | Iteration number: [2000/4518] 44% | Training loss: 0.6872340022921563
Epoch: 14 | Iteration number: [2010/4518] 44% | Training loss: 0.6872280407011212
Epoch: 14 | Iteration number: [2020/4518] 44% | Training loss: 0.6872240423861117
Epoch: 14 | Iteration number: [2030/4518] 44% | Training loss: 0.6872216095771696
Epoch: 14 | Iteration number: [2040/4518] 45% | Training loss: 0.687222868788476
Epoch: 14 | Iteration number: [2050/4518] 45% | Training loss: 0.6872250721512771
Epoch: 14 | Iteration number: [2060/4518] 45% | Training loss: 0.6872207276450778
Epoch: 14 | Iteration number: [2070/4518] 45% | Training loss: 0.6872230659648416
Epoch: 14 | Iteration number: [2080/4518] 46% | Training loss: 0.687217658958756
Epoch: 14 | Iteration number: [2090/4518] 46% | Training loss: 0.6872202865815049
Epoch: 14 | Iteration number: [2100/4518] 46% | Training loss: 0.6872138758500417
Epoch: 14 | Iteration number: [2110/4518] 46% | Training loss: 0.6872164984732443
Epoch: 14 | Iteration number: [2120/4518] 46% | Training loss: 0.6872135950990443
Epoch: 14 | Iteration number: [2130/4518] 47% | Training loss: 0.6872122035339965
Epoch: 14 | Iteration number: [2140/4518] 47% | Training loss: 0.6872134350449125
Epoch: 14 | Iteration number: [2150/4518] 47% | Training loss: 0.6872094730720963
Epoch: 14 | Iteration number: [2160/4518] 47% | Training loss: 0.6872107324224931
Epoch: 14 | Iteration number: [2170/4518] 48% | Training loss: 0.6872082171077553
Epoch: 14 | Iteration number: [2180/4518] 48% | Training loss: 0.6872075224141462
Epoch: 14 | Iteration number: [2190/4518] 48% | Training loss: 0.6872129481404884
Epoch: 14 | Iteration number: [2200/4518] 48% | Training loss: 0.6872092645276676
Epoch: 14 | Iteration number: [2210/4518] 48% | Training loss: 0.6872079697129952
Epoch: 14 | Iteration number: [2220/4518] 49% | Training loss: 0.6872037440538407
Epoch: 14 | Iteration number: [2230/4518] 49% | Training loss: 0.6872087133572241
Epoch: 14 | Iteration number: [2240/4518] 49% | Training loss: 0.6872098176873156
Epoch: 14 | Iteration number: [2250/4518] 49% | Training loss: 0.6872090232637194
Epoch: 14 | Iteration number: [2260/4518] 50% | Training loss: 0.6872037073152255
Epoch: 14 | Iteration number: [2270/4518] 50% | Training loss: 0.6872006998713321
Epoch: 14 | Iteration number: [2280/4518] 50% | Training loss: 0.6871980919388303
Epoch: 14 | Iteration number: [2290/4518] 50% | Training loss: 0.6871931347524235
Epoch: 14 | Iteration number: [2300/4518] 50% | Training loss: 0.6871980925228285
Epoch: 14 | Iteration number: [2310/4518] 51% | Training loss: 0.6871942987173667
Epoch: 14 | Iteration number: [2320/4518] 51% | Training loss: 0.6871882418620175
Epoch: 14 | Iteration number: [2330/4518] 51% | Training loss: 0.6871864786987141
Epoch: 14 | Iteration number: [2340/4518] 51% | Training loss: 0.687184476495808
Epoch: 14 | Iteration number: [2350/4518] 52% | Training loss: 0.6871870224019314
Epoch: 14 | Iteration number: [2360/4518] 52% | Training loss: 0.6871888580716262
Epoch: 14 | Iteration number: [2370/4518] 52% | Training loss: 0.6871910106783677
Epoch: 14 | Iteration number: [2380/4518] 52% | Training loss: 0.6871903083404574
Epoch: 14 | Iteration number: [2390/4518] 52% | Training loss: 0.6871811141528844
Epoch: 14 | Iteration number: [2400/4518] 53% | Training loss: 0.6871705699463685
Epoch: 14 | Iteration number: [2410/4518] 53% | Training loss: 0.6871601072584445
Epoch: 14 | Iteration number: [2420/4518] 53% | Training loss: 0.6871624901521305
Epoch: 14 | Iteration number: [2430/4518] 53% | Training loss: 0.6871672214058692
Epoch: 14 | Iteration number: [2440/4518] 54% | Training loss: 0.6871658312248402
Epoch: 14 | Iteration number: [2450/4518] 54% | Training loss: 0.6871647616551847
Epoch: 14 | Iteration number: [2460/4518] 54% | Training loss: 0.6871677501414849
Epoch: 14 | Iteration number: [2470/4518] 54% | Training loss: 0.6871666247545466
Epoch: 14 | Iteration number: [2480/4518] 54% | Training loss: 0.6871615543961525
Epoch: 14 | Iteration number: [2490/4518] 55% | Training loss: 0.6871614828645943
Epoch: 14 | Iteration number: [2500/4518] 55% | Training loss: 0.6871558807134628
Epoch: 14 | Iteration number: [2510/4518] 55% | Training loss: 0.6871504823287645
Epoch: 14 | Iteration number: [2520/4518] 55% | Training loss: 0.6871529417851615
Epoch: 14 | Iteration number: [2530/4518] 55% | Training loss: 0.6871519893761209
Epoch: 14 | Iteration number: [2540/4518] 56% | Training loss: 0.6871522483159238
Epoch: 14 | Iteration number: [2550/4518] 56% | Training loss: 0.6871521232642379
Epoch: 14 | Iteration number: [2560/4518] 56% | Training loss: 0.6871537283994258
Epoch: 14 | Iteration number: [2570/4518] 56% | Training loss: 0.6871545820848487
Epoch: 14 | Iteration number: [2580/4518] 57% | Training loss: 0.6871509226948715
Epoch: 14 | Iteration number: [2590/4518] 57% | Training loss: 0.6871514928847207
Epoch: 14 | Iteration number: [2600/4518] 57% | Training loss: 0.6871530505327078
Epoch: 14 | Iteration number: [2610/4518] 57% | Training loss: 0.6871543430962325
Epoch: 14 | Iteration number: [2620/4518] 57% | Training loss: 0.6871508216357413
Epoch: 14 | Iteration number: [2630/4518] 58% | Training loss: 0.6871507708110737
Epoch: 14 | Iteration number: [2640/4518] 58% | Training loss: 0.6871527642463193
Epoch: 14 | Iteration number: [2650/4518] 58% | Training loss: 0.687158696111643
Epoch: 14 | Iteration number: [2660/4518] 58% | Training loss: 0.6871563013558998
Epoch: 14 | Iteration number: [2670/4518] 59% | Training loss: 0.6871602272719479
Epoch: 14 | Iteration number: [2680/4518] 59% | Training loss: 0.6871562936190349
Epoch: 14 | Iteration number: [2690/4518] 59% | Training loss: 0.6871524509222534
Epoch: 14 | Iteration number: [2700/4518] 59% | Training loss: 0.6871559383913323
Epoch: 14 | Iteration number: [2710/4518] 59% | Training loss: 0.6871562683274385
Epoch: 14 | Iteration number: [2720/4518] 60% | Training loss: 0.687160678799538
Epoch: 14 | Iteration number: [2730/4518] 60% | Training loss: 0.6871588663085476
Epoch: 14 | Iteration number: [2740/4518] 60% | Training loss: 0.6871537988855891
Epoch: 14 | Iteration number: [2750/4518] 60% | Training loss: 0.6871571872884576
Epoch: 14 | Iteration number: [2760/4518] 61% | Training loss: 0.6871527672029923
Epoch: 14 | Iteration number: [2770/4518] 61% | Training loss: 0.6871532780599078
Epoch: 14 | Iteration number: [2780/4518] 61% | Training loss: 0.6871427866194746
Epoch: 14 | Iteration number: [2790/4518] 61% | Training loss: 0.6871392672207193
Epoch: 14 | Iteration number: [2800/4518] 61% | Training loss: 0.6871363298594951
Epoch: 14 | Iteration number: [2810/4518] 62% | Training loss: 0.687137886404567
Epoch: 14 | Iteration number: [2820/4518] 62% | Training loss: 0.6871358584427665
Epoch: 14 | Iteration number: [2830/4518] 62% | Training loss: 0.6871339355467065
Epoch: 14 | Iteration number: [2840/4518] 62% | Training loss: 0.6871318620695195
Epoch: 14 | Iteration number: [2850/4518] 63% | Training loss: 0.6871297278738858
Epoch: 14 | Iteration number: [2860/4518] 63% | Training loss: 0.6871272422008581
Epoch: 14 | Iteration number: [2870/4518] 63% | Training loss: 0.6871279821578634
Epoch: 14 | Iteration number: [2880/4518] 63% | Training loss: 0.687130615611871
Epoch: 14 | Iteration number: [2890/4518] 63% | Training loss: 0.6871310284805958
Epoch: 14 | Iteration number: [2900/4518] 64% | Training loss: 0.6871300887650457
Epoch: 14 | Iteration number: [2910/4518] 64% | Training loss: 0.6871308303370918
Epoch: 14 | Iteration number: [2920/4518] 64% | Training loss: 0.6871289479814163
Epoch: 14 | Iteration number: [2930/4518] 64% | Training loss: 0.6871277388045406
Epoch: 14 | Iteration number: [2940/4518] 65% | Training loss: 0.6871270644826953
Epoch: 14 | Iteration number: [2950/4518] 65% | Training loss: 0.6871262873835483
Epoch: 14 | Iteration number: [2960/4518] 65% | Training loss: 0.6871273399607555
Epoch: 14 | Iteration number: [2970/4518] 65% | Training loss: 0.6871252735255142
Epoch: 14 | Iteration number: [2980/4518] 65% | Training loss: 0.6871227617831838
Epoch: 14 | Iteration number: [2990/4518] 66% | Training loss: 0.6871187593825286
Epoch: 14 | Iteration number: [3000/4518] 66% | Training loss: 0.6871163440148036
Epoch: 14 | Iteration number: [3010/4518] 66% | Training loss: 0.6871162698910482
Epoch: 14 | Iteration number: [3020/4518] 66% | Training loss: 0.6871172913455016
Epoch: 14 | Iteration number: [3030/4518] 67% | Training loss: 0.6871221822873987
Epoch: 14 | Iteration number: [3040/4518] 67% | Training loss: 0.6871215972069062
Epoch: 14 | Iteration number: [3050/4518] 67% | Training loss: 0.6871209334350024
Epoch: 14 | Iteration number: [3060/4518] 67% | Training loss: 0.6871249971631306
Epoch: 14 | Iteration number: [3070/4518] 67% | Training loss: 0.6871254632449694
Epoch: 14 | Iteration number: [3080/4518] 68% | Training loss: 0.6871239229649693
Epoch: 14 | Iteration number: [3090/4518] 68% | Training loss: 0.6871224392193421
Epoch: 14 | Iteration number: [3100/4518] 68% | Training loss: 0.6871198988729907
Epoch: 14 | Iteration number: [3110/4518] 68% | Training loss: 0.6871148899820456
Epoch: 14 | Iteration number: [3120/4518] 69% | Training loss: 0.6871158457337282
Epoch: 14 | Iteration number: [3130/4518] 69% | Training loss: 0.6871167232243779
Epoch: 14 | Iteration number: [3140/4518] 69% | Training loss: 0.6871113813986445
Epoch: 14 | Iteration number: [3150/4518] 69% | Training loss: 0.6871135448841822
Epoch: 14 | Iteration number: [3160/4518] 69% | Training loss: 0.6871116536327555
Epoch: 14 | Iteration number: [3170/4518] 70% | Training loss: 0.6871117505929447
Epoch: 14 | Iteration number: [3180/4518] 70% | Training loss: 0.6871143902622678
Epoch: 14 | Iteration number: [3190/4518] 70% | Training loss: 0.6871187408142329
Epoch: 14 | Iteration number: [3200/4518] 70% | Training loss: 0.6871203585714102
Epoch: 14 | Iteration number: [3210/4518] 71% | Training loss: 0.6871173253683286
Epoch: 14 | Iteration number: [3220/4518] 71% | Training loss: 0.6871178605726787
Epoch: 14 | Iteration number: [3230/4518] 71% | Training loss: 0.6871183352573738
Epoch: 14 | Iteration number: [3240/4518] 71% | Training loss: 0.6871168356618763
Epoch: 14 | Iteration number: [3250/4518] 71% | Training loss: 0.687115088719588
Epoch: 14 | Iteration number: [3260/4518] 72% | Training loss: 0.6871104501507765
Epoch: 14 | Iteration number: [3270/4518] 72% | Training loss: 0.6871117834651143
Epoch: 14 | Iteration number: [3280/4518] 72% | Training loss: 0.6871137837811214
Epoch: 14 | Iteration number: [3290/4518] 72% | Training loss: 0.6871110871570089
Epoch: 14 | Iteration number: [3300/4518] 73% | Training loss: 0.6871122518994591
Epoch: 14 | Iteration number: [3310/4518] 73% | Training loss: 0.6871128196442595
Epoch: 14 | Iteration number: [3320/4518] 73% | Training loss: 0.6871159052094781
Epoch: 14 | Iteration number: [3330/4518] 73% | Training loss: 0.6871187691394989
Epoch: 14 | Iteration number: [3340/4518] 73% | Training loss: 0.6871180439602115
Epoch: 14 | Iteration number: [3350/4518] 74% | Training loss: 0.687119666053288
Epoch: 14 | Iteration number: [3360/4518] 74% | Training loss: 0.6871217968031055
Epoch: 14 | Iteration number: [3370/4518] 74% | Training loss: 0.6871241224095093
Epoch: 14 | Iteration number: [3380/4518] 74% | Training loss: 0.6871231328629883
Epoch: 14 | Iteration number: [3390/4518] 75% | Training loss: 0.6871183743870716
Epoch: 14 | Iteration number: [3400/4518] 75% | Training loss: 0.6871145792743739
Epoch: 14 | Iteration number: [3410/4518] 75% | Training loss: 0.6871132310359709
Epoch: 14 | Iteration number: [3420/4518] 75% | Training loss: 0.687114445176738
Epoch: 14 | Iteration number: [3430/4518] 75% | Training loss: 0.6871140423738574
Epoch: 14 | Iteration number: [3440/4518] 76% | Training loss: 0.6871154564930949
Epoch: 14 | Iteration number: [3450/4518] 76% | Training loss: 0.6871145589282547
Epoch: 14 | Iteration number: [3460/4518] 76% | Training loss: 0.68711556809486
Epoch: 14 | Iteration number: [3470/4518] 76% | Training loss: 0.6871140565411845
Epoch: 14 | Iteration number: [3480/4518] 77% | Training loss: 0.6871126276494443
Epoch: 14 | Iteration number: [3490/4518] 77% | Training loss: 0.6871157716714209
Epoch: 14 | Iteration number: [3500/4518] 77% | Training loss: 0.6871150129352297
Epoch: 14 | Iteration number: [3510/4518] 77% | Training loss: 0.6871138585428906
Epoch: 14 | Iteration number: [3520/4518] 77% | Training loss: 0.6871138380163095
Epoch: 14 | Iteration number: [3530/4518] 78% | Training loss: 0.6871151877361384
Epoch: 14 | Iteration number: [3540/4518] 78% | Training loss: 0.6871149267685616
Epoch: 14 | Iteration number: [3550/4518] 78% | Training loss: 0.6871137255346271
Epoch: 14 | Iteration number: [3560/4518] 78% | Training loss: 0.6871103077457192
Epoch: 14 | Iteration number: [3570/4518] 79% | Training loss: 0.6871101628999416
Epoch: 14 | Iteration number: [3580/4518] 79% | Training loss: 0.6871095518826107
Epoch: 14 | Iteration number: [3590/4518] 79% | Training loss: 0.6871102271969936
Epoch: 14 | Iteration number: [3600/4518] 79% | Training loss: 0.6871110366947121
Epoch: 14 | Iteration number: [3610/4518] 79% | Training loss: 0.6871103189658591
Epoch: 14 | Iteration number: [3620/4518] 80% | Training loss: 0.6871068643930868
Epoch: 14 | Iteration number: [3630/4518] 80% | Training loss: 0.6871074834638391
Epoch: 14 | Iteration number: [3640/4518] 80% | Training loss: 0.6871038781908843
Epoch: 14 | Iteration number: [3650/4518] 80% | Training loss: 0.6871055707539597
Epoch: 14 | Iteration number: [3660/4518] 81% | Training loss: 0.6871011145127927
Epoch: 14 | Iteration number: [3670/4518] 81% | Training loss: 0.6871008559046389
Epoch: 14 | Iteration number: [3680/4518] 81% | Training loss: 0.6871002014402462
Epoch: 14 | Iteration number: [3690/4518] 81% | Training loss: 0.6870999517641093
Epoch: 14 | Iteration number: [3700/4518] 81% | Training loss: 0.6871002434395455
Epoch: 14 | Iteration number: [3710/4518] 82% | Training loss: 0.6871009630976983
Epoch: 14 | Iteration number: [3720/4518] 82% | Training loss: 0.6870997985844971
Epoch: 14 | Iteration number: [3730/4518] 82% | Training loss: 0.6870993741715562
Epoch: 14 | Iteration number: [3740/4518] 82% | Training loss: 0.6871010798343362
Epoch: 14 | Iteration number: [3750/4518] 83% | Training loss: 0.6871006944815318
Epoch: 14 | Iteration number: [3760/4518] 83% | Training loss: 0.6870994222608019
Epoch: 14 | Iteration number: [3770/4518] 83% | Training loss: 0.6871010683101432
Epoch: 14 | Iteration number: [3780/4518] 83% | Training loss: 0.6871001920687458
Epoch: 14 | Iteration number: [3790/4518] 83% | Training loss: 0.6870991868677114
Epoch: 14 | Iteration number: [3800/4518] 84% | Training loss: 0.6870973862629187
Epoch: 14 | Iteration number: [3810/4518] 84% | Training loss: 0.6870940034314403
Epoch: 14 | Iteration number: [3820/4518] 84% | Training loss: 0.6870990306763125
Epoch: 14 | Iteration number: [3830/4518] 84% | Training loss: 0.6871010577087303
Epoch: 14 | Iteration number: [3840/4518] 84% | Training loss: 0.6871036614601811
Epoch: 14 | Iteration number: [3850/4518] 85% | Training loss: 0.687103696024263
Epoch: 14 | Iteration number: [3860/4518] 85% | Training loss: 0.6871049804236605
Epoch: 14 | Iteration number: [3870/4518] 85% | Training loss: 0.6871040147558355
Epoch: 14 | Iteration number: [3880/4518] 85% | Training loss: 0.6871031210748191
Epoch: 14 | Iteration number: [3890/4518] 86% | Training loss: 0.68710271166039
Epoch: 14 | Iteration number: [3900/4518] 86% | Training loss: 0.6871017758051554
Epoch: 14 | Iteration number: [3910/4518] 86% | Training loss: 0.6871019351055555
Epoch: 14 | Iteration number: [3920/4518] 86% | Training loss: 0.6871047043982818
Epoch: 14 | Iteration number: [3930/4518] 86% | Training loss: 0.6871037722240574
Epoch: 14 | Iteration number: [3940/4518] 87% | Training loss: 0.6871032855988759
Epoch: 14 | Iteration number: [3950/4518] 87% | Training loss: 0.6871026360234128
Epoch: 14 | Iteration number: [3960/4518] 87% | Training loss: 0.6871039190978715
Epoch: 14 | Iteration number: [3970/4518] 87% | Training loss: 0.6871021702998231
Epoch: 14 | Iteration number: [3980/4518] 88% | Training loss: 0.6870999863099813
Epoch: 14 | Iteration number: [3990/4518] 88% | Training loss: 0.6871015414408873
Epoch: 14 | Iteration number: [4000/4518] 88% | Training loss: 0.6871004792153835
Epoch: 14 | Iteration number: [4010/4518] 88% | Training loss: 0.6870983121698336
Epoch: 14 | Iteration number: [4020/4518] 88% | Training loss: 0.6870995492632709
Epoch: 14 | Iteration number: [4030/4518] 89% | Training loss: 0.6870967637960136
Epoch: 14 | Iteration number: [4040/4518] 89% | Training loss: 0.687098023280649
Epoch: 14 | Iteration number: [4050/4518] 89% | Training loss: 0.6870981916233345
Epoch: 14 | Iteration number: [4060/4518] 89% | Training loss: 0.6870996018935894
Epoch: 14 | Iteration number: [4070/4518] 90% | Training loss: 0.687097031932498
Epoch: 14 | Iteration number: [4080/4518] 90% | Training loss: 0.6870966209646534
Epoch: 14 | Iteration number: [4090/4518] 90% | Training loss: 0.6870973437368724
Epoch: 14 | Iteration number: [4100/4518] 90% | Training loss: 0.6870974596535288
Epoch: 14 | Iteration number: [4110/4518] 90% | Training loss: 0.6871005923353553
Epoch: 14 | Iteration number: [4120/4518] 91% | Training loss: 0.687101651409876
Epoch: 14 | Iteration number: [4130/4518] 91% | Training loss: 0.6871018645116839
Epoch: 14 | Iteration number: [4140/4518] 91% | Training loss: 0.6871006038165899
Epoch: 14 | Iteration number: [4150/4518] 91% | Training loss: 0.6871009242965515
Epoch: 14 | Iteration number: [4160/4518] 92% | Training loss: 0.6871022975788666
Epoch: 14 | Iteration number: [4170/4518] 92% | Training loss: 0.6871002127369531
Epoch: 14 | Iteration number: [4180/4518] 92% | Training loss: 0.6870977867590754
Epoch: 14 | Iteration number: [4190/4518] 92% | Training loss: 0.6870957961799421
Epoch: 14 | Iteration number: [4200/4518] 92% | Training loss: 0.6870958416092964
Epoch: 14 | Iteration number: [4210/4518] 93% | Training loss: 0.6870940950449176
Epoch: 14 | Iteration number: [4220/4518] 93% | Training loss: 0.6870927066599588
Epoch: 14 | Iteration number: [4230/4518] 93% | Training loss: 0.6870909943507355
Epoch: 14 | Iteration number: [4240/4518] 93% | Training loss: 0.6870901187495241
Epoch: 14 | Iteration number: [4250/4518] 94% | Training loss: 0.6870892810260548
Epoch: 14 | Iteration number: [4260/4518] 94% | Training loss: 0.6870890261981409
Epoch: 14 | Iteration number: [4270/4518] 94% | Training loss: 0.6870871865358509
Epoch: 14 | Iteration number: [4280/4518] 94% | Training loss: 0.687087223490822
Epoch: 14 | Iteration number: [4290/4518] 94% | Training loss: 0.6870872130899718
Epoch: 14 | Iteration number: [4300/4518] 95% | Training loss: 0.6870847627589869
Epoch: 14 | Iteration number: [4310/4518] 95% | Training loss: 0.6870871099131289
Epoch: 14 | Iteration number: [4320/4518] 95% | Training loss: 0.687085694640323
Epoch: 14 | Iteration number: [4330/4518] 95% | Training loss: 0.6870869745145494
Epoch: 14 | Iteration number: [4340/4518] 96% | Training loss: 0.6870865907949236
Epoch: 14 | Iteration number: [4350/4518] 96% | Training loss: 0.6870870491005908
Epoch: 14 | Iteration number: [4360/4518] 96% | Training loss: 0.6870869453483766
Epoch: 14 | Iteration number: [4370/4518] 96% | Training loss: 0.6870864616378767
Epoch: 14 | Iteration number: [4380/4518] 96% | Training loss: 0.6870876085404392
Epoch: 14 | Iteration number: [4390/4518] 97% | Training loss: 0.6870904389709438
Epoch: 14 | Iteration number: [4400/4518] 97% | Training loss: 0.6870905537090518
Epoch: 14 | Iteration number: [4410/4518] 97% | Training loss: 0.6870909485146572
Epoch: 14 | Iteration number: [4420/4518] 97% | Training loss: 0.6870909111801855
Epoch: 14 | Iteration number: [4430/4518] 98% | Training loss: 0.6870886512857528
Epoch: 14 | Iteration number: [4440/4518] 98% | Training loss: 0.6870892101714203
Epoch: 14 | Iteration number: [4450/4518] 98% | Training loss: 0.6870889585607507
Epoch: 14 | Iteration number: [4460/4518] 98% | Training loss: 0.6870907479604798
Epoch: 14 | Iteration number: [4470/4518] 98% | Training loss: 0.6870921114413797
Epoch: 14 | Iteration number: [4480/4518] 99% | Training loss: 0.6870897322494004
Epoch: 14 | Iteration number: [4490/4518] 99% | Training loss: 0.6870896951127424
Epoch: 14 | Iteration number: [4500/4518] 99% | Training loss: 0.6870889804495706
Epoch: 14 | Iteration number: [4510/4518] 99% | Training loss: 0.6870890568074525

 End of epoch: 14 | Train Loss: 0.6869357483689897 | Training Time: 632 

 End of epoch: 14 | Eval Loss: 0.6902028492518834 | Evaluating Time: 17 
Epoch: 15 | Iteration number: [10/4518] 0% | Training loss: 0.7557275533676148
Epoch: 15 | Iteration number: [20/4518] 0% | Training loss: 0.721468722820282
Epoch: 15 | Iteration number: [30/4518] 0% | Training loss: 0.7098329842090607
Epoch: 15 | Iteration number: [40/4518] 0% | Training loss: 0.7041088327765465
Epoch: 15 | Iteration number: [50/4518] 1% | Training loss: 0.70055260181427
Epoch: 15 | Iteration number: [60/4518] 1% | Training loss: 0.6982467909653981
Epoch: 15 | Iteration number: [70/4518] 1% | Training loss: 0.6966830602713994
Epoch: 15 | Iteration number: [80/4518] 1% | Training loss: 0.6953672640025615
Epoch: 15 | Iteration number: [90/4518] 1% | Training loss: 0.6944141732321845
Epoch: 15 | Iteration number: [100/4518] 2% | Training loss: 0.6936822259426116
Epoch: 15 | Iteration number: [110/4518] 2% | Training loss: 0.6929759914224798
Epoch: 15 | Iteration number: [120/4518] 2% | Training loss: 0.6924321085214615
Epoch: 15 | Iteration number: [130/4518] 2% | Training loss: 0.6921026825904846
Epoch: 15 | Iteration number: [140/4518] 3% | Training loss: 0.6916954440729959
Epoch: 15 | Iteration number: [150/4518] 3% | Training loss: 0.6913704303900401
Epoch: 15 | Iteration number: [160/4518] 3% | Training loss: 0.6911452554166317
Epoch: 15 | Iteration number: [170/4518] 3% | Training loss: 0.6908475686522091
Epoch: 15 | Iteration number: [180/4518] 3% | Training loss: 0.6906138744619158
Epoch: 15 | Iteration number: [190/4518] 4% | Training loss: 0.6903771805135828
Epoch: 15 | Iteration number: [200/4518] 4% | Training loss: 0.6902107354998589
Epoch: 15 | Iteration number: [210/4518] 4% | Training loss: 0.690012925011771
Epoch: 15 | Iteration number: [220/4518] 4% | Training loss: 0.6899099442091855
Epoch: 15 | Iteration number: [230/4518] 5% | Training loss: 0.6898315484109132
Epoch: 15 | Iteration number: [240/4518] 5% | Training loss: 0.6896812565624714
Epoch: 15 | Iteration number: [250/4518] 5% | Training loss: 0.689575623035431
Epoch: 15 | Iteration number: [260/4518] 5% | Training loss: 0.6894716127560689
Epoch: 15 | Iteration number: [270/4518] 5% | Training loss: 0.6893847430193866
Epoch: 15 | Iteration number: [280/4518] 6% | Training loss: 0.6893216062869344
Epoch: 15 | Iteration number: [290/4518] 6% | Training loss: 0.6892898925419512
Epoch: 15 | Iteration number: [300/4518] 6% | Training loss: 0.6891971906026204
Epoch: 15 | Iteration number: [310/4518] 6% | Training loss: 0.6890928014632194
Epoch: 15 | Iteration number: [320/4518] 7% | Training loss: 0.68904684279114
Epoch: 15 | Iteration number: [330/4518] 7% | Training loss: 0.6889751734155597
Epoch: 15 | Iteration number: [340/4518] 7% | Training loss: 0.6889170955209171
Epoch: 15 | Iteration number: [350/4518] 7% | Training loss: 0.688880044392177
Epoch: 15 | Iteration number: [360/4518] 7% | Training loss: 0.6888467984067069
Epoch: 15 | Iteration number: [370/4518] 8% | Training loss: 0.6887403233631237
Epoch: 15 | Iteration number: [380/4518] 8% | Training loss: 0.6887262901193217
Epoch: 15 | Iteration number: [390/4518] 8% | Training loss: 0.6886749987418835
Epoch: 15 | Iteration number: [400/4518] 8% | Training loss: 0.6886314840614796
Epoch: 15 | Iteration number: [410/4518] 9% | Training loss: 0.6886009587020409
Epoch: 15 | Iteration number: [420/4518] 9% | Training loss: 0.6885578867934999
Epoch: 15 | Iteration number: [430/4518] 9% | Training loss: 0.6885113928207132
Epoch: 15 | Iteration number: [440/4518] 9% | Training loss: 0.6884711199186065
Epoch: 15 | Iteration number: [450/4518] 9% | Training loss: 0.6884184451897939
Epoch: 15 | Iteration number: [460/4518] 10% | Training loss: 0.6884133950523709
Epoch: 15 | Iteration number: [470/4518] 10% | Training loss: 0.6883551465704086
Epoch: 15 | Iteration number: [480/4518] 10% | Training loss: 0.6883266061544419
Epoch: 15 | Iteration number: [490/4518] 10% | Training loss: 0.6883127744100532
Epoch: 15 | Iteration number: [500/4518] 11% | Training loss: 0.6882871747016907
Epoch: 15 | Iteration number: [510/4518] 11% | Training loss: 0.6882584361469044
Epoch: 15 | Iteration number: [520/4518] 11% | Training loss: 0.6882437465282587
Epoch: 15 | Iteration number: [530/4518] 11% | Training loss: 0.6882016565439836
Epoch: 15 | Iteration number: [540/4518] 11% | Training loss: 0.6881759702055542
Epoch: 15 | Iteration number: [550/4518] 12% | Training loss: 0.6881523211435838
Epoch: 15 | Iteration number: [560/4518] 12% | Training loss: 0.6881484293511936
Epoch: 15 | Iteration number: [570/4518] 12% | Training loss: 0.6881244606093356
Epoch: 15 | Iteration number: [580/4518] 12% | Training loss: 0.6881021968249617
Epoch: 15 | Iteration number: [590/4518] 13% | Training loss: 0.6881029963493347
Epoch: 15 | Iteration number: [600/4518] 13% | Training loss: 0.6880553804834684
Epoch: 15 | Iteration number: [610/4518] 13% | Training loss: 0.6880390124242813
Epoch: 15 | Iteration number: [620/4518] 13% | Training loss: 0.6880026178013894
Epoch: 15 | Iteration number: [630/4518] 13% | Training loss: 0.6879964449102917
Epoch: 15 | Iteration number: [640/4518] 14% | Training loss: 0.6879649436101317
Epoch: 15 | Iteration number: [650/4518] 14% | Training loss: 0.6879377381618206
Epoch: 15 | Iteration number: [660/4518] 14% | Training loss: 0.6879174814079747
Epoch: 15 | Iteration number: [670/4518] 14% | Training loss: 0.6878978775508369
Epoch: 15 | Iteration number: [680/4518] 15% | Training loss: 0.6878838781924809
Epoch: 15 | Iteration number: [690/4518] 15% | Training loss: 0.6878646591435308
Epoch: 15 | Iteration number: [700/4518] 15% | Training loss: 0.687853416459901
Epoch: 15 | Iteration number: [710/4518] 15% | Training loss: 0.6878604175339282
Epoch: 15 | Iteration number: [720/4518] 15% | Training loss: 0.687855931205882
Epoch: 15 | Iteration number: [730/4518] 16% | Training loss: 0.687863677740097
Epoch: 15 | Iteration number: [740/4518] 16% | Training loss: 0.687839347446287
Epoch: 15 | Iteration number: [750/4518] 16% | Training loss: 0.6878334782123565
Epoch: 15 | Iteration number: [760/4518] 16% | Training loss: 0.6878302880807927
Epoch: 15 | Iteration number: [770/4518] 17% | Training loss: 0.6878173526231345
Epoch: 15 | Iteration number: [780/4518] 17% | Training loss: 0.6878079464802376
Epoch: 15 | Iteration number: [790/4518] 17% | Training loss: 0.6877996236463136
Epoch: 15 | Iteration number: [800/4518] 17% | Training loss: 0.6877909141778946
Epoch: 15 | Iteration number: [810/4518] 17% | Training loss: 0.687778197320891
Epoch: 15 | Iteration number: [820/4518] 18% | Training loss: 0.6877475284221696
Epoch: 15 | Iteration number: [830/4518] 18% | Training loss: 0.6877414507320129
Epoch: 15 | Iteration number: [840/4518] 18% | Training loss: 0.6877402737736702
Epoch: 15 | Iteration number: [850/4518] 18% | Training loss: 0.6877203191027922
Epoch: 15 | Iteration number: [860/4518] 19% | Training loss: 0.6877026719409366
Epoch: 15 | Iteration number: [870/4518] 19% | Training loss: 0.6877007259034562
Epoch: 15 | Iteration number: [880/4518] 19% | Training loss: 0.6876836385916579
Epoch: 15 | Iteration number: [890/4518] 19% | Training loss: 0.6876760793535897
Epoch: 15 | Iteration number: [900/4518] 19% | Training loss: 0.6876541298627853
Epoch: 15 | Iteration number: [910/4518] 20% | Training loss: 0.6876528642989777
Epoch: 15 | Iteration number: [920/4518] 20% | Training loss: 0.6876474420013635
Epoch: 15 | Iteration number: [930/4518] 20% | Training loss: 0.6876306581881738
Epoch: 15 | Iteration number: [940/4518] 20% | Training loss: 0.6876241076499858
Epoch: 15 | Iteration number: [950/4518] 21% | Training loss: 0.6876238959713986
Epoch: 15 | Iteration number: [960/4518] 21% | Training loss: 0.6875908666600784
Epoch: 15 | Iteration number: [970/4518] 21% | Training loss: 0.6875899749318349
Epoch: 15 | Iteration number: [980/4518] 21% | Training loss: 0.6875863205413429
Epoch: 15 | Iteration number: [990/4518] 21% | Training loss: 0.6875667290254073
Epoch: 15 | Iteration number: [1000/4518] 22% | Training loss: 0.6875653164386749
Epoch: 15 | Iteration number: [1010/4518] 22% | Training loss: 0.6875674994275122
Epoch: 15 | Iteration number: [1020/4518] 22% | Training loss: 0.6875609937251783
Epoch: 15 | Iteration number: [1030/4518] 22% | Training loss: 0.6875611216697878
Epoch: 15 | Iteration number: [1040/4518] 23% | Training loss: 0.6875466584586181
Epoch: 15 | Iteration number: [1050/4518] 23% | Training loss: 0.6875332778408414
Epoch: 15 | Iteration number: [1060/4518] 23% | Training loss: 0.6875297875899189
Epoch: 15 | Iteration number: [1070/4518] 23% | Training loss: 0.687531223865313
Epoch: 15 | Iteration number: [1080/4518] 23% | Training loss: 0.6875220635974849
Epoch: 15 | Iteration number: [1090/4518] 24% | Training loss: 0.6875163177284626
Epoch: 15 | Iteration number: [1100/4518] 24% | Training loss: 0.6875053335319866
Epoch: 15 | Iteration number: [1110/4518] 24% | Training loss: 0.6875077811984328
Epoch: 15 | Iteration number: [1120/4518] 24% | Training loss: 0.6875005119613239
Epoch: 15 | Iteration number: [1130/4518] 25% | Training loss: 0.6874953164991024
Epoch: 15 | Iteration number: [1140/4518] 25% | Training loss: 0.6874866382071846
Epoch: 15 | Iteration number: [1150/4518] 25% | Training loss: 0.6874722692240839
Epoch: 15 | Iteration number: [1160/4518] 25% | Training loss: 0.6874650278481944
Epoch: 15 | Iteration number: [1170/4518] 25% | Training loss: 0.687450398848607
Epoch: 15 | Iteration number: [1180/4518] 26% | Training loss: 0.6874462234771858
Epoch: 15 | Iteration number: [1190/4518] 26% | Training loss: 0.6874364904495849
Epoch: 15 | Iteration number: [1200/4518] 26% | Training loss: 0.6874436219036579
Epoch: 15 | Iteration number: [1210/4518] 26% | Training loss: 0.6874404265860881
Epoch: 15 | Iteration number: [1220/4518] 27% | Training loss: 0.6874382104052872
Epoch: 15 | Iteration number: [1230/4518] 27% | Training loss: 0.6874211152879203
Epoch: 15 | Iteration number: [1240/4518] 27% | Training loss: 0.6874235587254647
Epoch: 15 | Iteration number: [1250/4518] 27% | Training loss: 0.6874266519069672
Epoch: 15 | Iteration number: [1260/4518] 27% | Training loss: 0.6874250414825621
Epoch: 15 | Iteration number: [1270/4518] 28% | Training loss: 0.6874190685317272
Epoch: 15 | Iteration number: [1280/4518] 28% | Training loss: 0.6874118544626981
Epoch: 15 | Iteration number: [1290/4518] 28% | Training loss: 0.6874113514903903
Epoch: 15 | Iteration number: [1300/4518] 28% | Training loss: 0.6874074309605819
Epoch: 15 | Iteration number: [1310/4518] 28% | Training loss: 0.6874043074727968
Epoch: 15 | Iteration number: [1320/4518] 29% | Training loss: 0.6873882924516995
Epoch: 15 | Iteration number: [1330/4518] 29% | Training loss: 0.6873922312170043
Epoch: 15 | Iteration number: [1340/4518] 29% | Training loss: 0.6873901333826692
Epoch: 15 | Iteration number: [1350/4518] 29% | Training loss: 0.6873876841862997
Epoch: 15 | Iteration number: [1360/4518] 30% | Training loss: 0.6873908439979833
Epoch: 15 | Iteration number: [1370/4518] 30% | Training loss: 0.6873847836995647
Epoch: 15 | Iteration number: [1380/4518] 30% | Training loss: 0.6873881016088569
Epoch: 15 | Iteration number: [1390/4518] 30% | Training loss: 0.6873860276431488
Epoch: 15 | Iteration number: [1400/4518] 30% | Training loss: 0.6873816734978131
Epoch: 15 | Iteration number: [1410/4518] 31% | Training loss: 0.6873860280987218
Epoch: 15 | Iteration number: [1420/4518] 31% | Training loss: 0.687386273288391
Epoch: 15 | Iteration number: [1430/4518] 31% | Training loss: 0.6873818266641843
Epoch: 15 | Iteration number: [1440/4518] 31% | Training loss: 0.6873757024192148
Epoch: 15 | Iteration number: [1450/4518] 32% | Training loss: 0.6873667178071778
Epoch: 15 | Iteration number: [1460/4518] 32% | Training loss: 0.6873545463771036
Epoch: 15 | Iteration number: [1470/4518] 32% | Training loss: 0.6873498286519731
Epoch: 15 | Iteration number: [1480/4518] 32% | Training loss: 0.6873443713462031
Epoch: 15 | Iteration number: [1490/4518] 32% | Training loss: 0.6873426881012501
Epoch: 15 | Iteration number: [1500/4518] 33% | Training loss: 0.6873398306369781
Epoch: 15 | Iteration number: [1510/4518] 33% | Training loss: 0.6873332622430183
Epoch: 15 | Iteration number: [1520/4518] 33% | Training loss: 0.6873252016541205
Epoch: 15 | Iteration number: [1530/4518] 33% | Training loss: 0.6873254691463669
Epoch: 15 | Iteration number: [1540/4518] 34% | Training loss: 0.6873229292693076
Epoch: 15 | Iteration number: [1550/4518] 34% | Training loss: 0.68732299558578
Epoch: 15 | Iteration number: [1560/4518] 34% | Training loss: 0.6873179761645122
Epoch: 15 | Iteration number: [1570/4518] 34% | Training loss: 0.6873141443653471
Epoch: 15 | Iteration number: [1580/4518] 34% | Training loss: 0.6873049715274497
Epoch: 15 | Iteration number: [1590/4518] 35% | Training loss: 0.6873027353916528
Epoch: 15 | Iteration number: [1600/4518] 35% | Training loss: 0.6873024635016918
Epoch: 15 | Iteration number: [1610/4518] 35% | Training loss: 0.6872935910032403
Epoch: 15 | Iteration number: [1620/4518] 35% | Training loss: 0.6872862990623639
Epoch: 15 | Iteration number: [1630/4518] 36% | Training loss: 0.687284125469945
Epoch: 15 | Iteration number: [1640/4518] 36% | Training loss: 0.687276837011663
Epoch: 15 | Iteration number: [1650/4518] 36% | Training loss: 0.6872780461383589
Epoch: 15 | Iteration number: [1660/4518] 36% | Training loss: 0.6872796216283936
Epoch: 15 | Iteration number: [1670/4518] 36% | Training loss: 0.6872801606883546
Epoch: 15 | Iteration number: [1680/4518] 37% | Training loss: 0.6872818477097011
Epoch: 15 | Iteration number: [1690/4518] 37% | Training loss: 0.6872751070197517
Epoch: 15 | Iteration number: [1700/4518] 37% | Training loss: 0.6872743900733835
Epoch: 15 | Iteration number: [1710/4518] 37% | Training loss: 0.6872743358737544
Epoch: 15 | Iteration number: [1720/4518] 38% | Training loss: 0.6872743377158809
Epoch: 15 | Iteration number: [1730/4518] 38% | Training loss: 0.687265992612508
Epoch: 15 | Iteration number: [1740/4518] 38% | Training loss: 0.6872581373343523
Epoch: 15 | Iteration number: [1750/4518] 38% | Training loss: 0.6872475712980542
Epoch: 15 | Iteration number: [1760/4518] 38% | Training loss: 0.6872485623779622
Epoch: 15 | Iteration number: [1770/4518] 39% | Training loss: 0.6872484189642352
Epoch: 15 | Iteration number: [1780/4518] 39% | Training loss: 0.6872556744331724
Epoch: 15 | Iteration number: [1790/4518] 39% | Training loss: 0.6872534214451327
Epoch: 15 | Iteration number: [1800/4518] 39% | Training loss: 0.6872535733381907
Epoch: 15 | Iteration number: [1810/4518] 40% | Training loss: 0.6872505557800525
Epoch: 15 | Iteration number: [1820/4518] 40% | Training loss: 0.6872475618189507
Epoch: 15 | Iteration number: [1830/4518] 40% | Training loss: 0.6872457689600564
Epoch: 15 | Iteration number: [1840/4518] 40% | Training loss: 0.6872375542378943
Epoch: 15 | Iteration number: [1850/4518] 40% | Training loss: 0.6872319468614217
Epoch: 15 | Iteration number: [1860/4518] 41% | Training loss: 0.6872364833470314
Epoch: 15 | Iteration number: [1870/4518] 41% | Training loss: 0.6872371089968452
Epoch: 15 | Iteration number: [1880/4518] 41% | Training loss: 0.6872383883341829
Epoch: 15 | Iteration number: [1890/4518] 41% | Training loss: 0.6872366476311255
Epoch: 15 | Iteration number: [1900/4518] 42% | Training loss: 0.687233624458313
Epoch: 15 | Iteration number: [1910/4518] 42% | Training loss: 0.6872347036893455
Epoch: 15 | Iteration number: [1920/4518] 42% | Training loss: 0.6872321107735236
Epoch: 15 | Iteration number: [1930/4518] 42% | Training loss: 0.6872334958358132
Epoch: 15 | Iteration number: [1940/4518] 42% | Training loss: 0.6872361955876203
Epoch: 15 | Iteration number: [1950/4518] 43% | Training loss: 0.6872384506311172
Epoch: 15 | Iteration number: [1960/4518] 43% | Training loss: 0.6872389465874555
Epoch: 15 | Iteration number: [1970/4518] 43% | Training loss: 0.6872414066101694
Epoch: 15 | Iteration number: [1980/4518] 43% | Training loss: 0.6872401217619578
Epoch: 15 | Iteration number: [1990/4518] 44% | Training loss: 0.6872360716213533
Epoch: 15 | Iteration number: [2000/4518] 44% | Training loss: 0.6872414399981499
Epoch: 15 | Iteration number: [2010/4518] 44% | Training loss: 0.6872476478121174
Epoch: 15 | Iteration number: [2020/4518] 44% | Training loss: 0.687240735493084
Epoch: 15 | Iteration number: [2030/4518] 44% | Training loss: 0.6872453539242298
Epoch: 15 | Iteration number: [2040/4518] 45% | Training loss: 0.6872443962330912
Epoch: 15 | Iteration number: [2050/4518] 45% | Training loss: 0.6872483494223618
Epoch: 15 | Iteration number: [2060/4518] 45% | Training loss: 0.6872462653998033
Epoch: 15 | Iteration number: [2070/4518] 45% | Training loss: 0.6872398448163185
Epoch: 15 | Iteration number: [2080/4518] 46% | Training loss: 0.6872335333377123
Epoch: 15 | Iteration number: [2090/4518] 46% | Training loss: 0.6872349852865393
Epoch: 15 | Iteration number: [2100/4518] 46% | Training loss: 0.6872402797710327
Epoch: 15 | Iteration number: [2110/4518] 46% | Training loss: 0.687244467204216
Epoch: 15 | Iteration number: [2120/4518] 46% | Training loss: 0.6872474245024177
Epoch: 15 | Iteration number: [2130/4518] 47% | Training loss: 0.6872461074114965
Epoch: 15 | Iteration number: [2140/4518] 47% | Training loss: 0.687243323877593
Epoch: 15 | Iteration number: [2150/4518] 47% | Training loss: 0.6872452740059343
Epoch: 15 | Iteration number: [2160/4518] 47% | Training loss: 0.6872401176779358
Epoch: 15 | Iteration number: [2170/4518] 48% | Training loss: 0.6872349883828844
Epoch: 15 | Iteration number: [2180/4518] 48% | Training loss: 0.6872313177093453
Epoch: 15 | Iteration number: [2190/4518] 48% | Training loss: 0.687224574257794
Epoch: 15 | Iteration number: [2200/4518] 48% | Training loss: 0.6872233983603391
Epoch: 15 | Iteration number: [2210/4518] 48% | Training loss: 0.6872242597433237
Epoch: 15 | Iteration number: [2220/4518] 49% | Training loss: 0.687220017168973
Epoch: 15 | Iteration number: [2230/4518] 49% | Training loss: 0.6872145345927354
Epoch: 15 | Iteration number: [2240/4518] 49% | Training loss: 0.6872157919353672
Epoch: 15 | Iteration number: [2250/4518] 49% | Training loss: 0.6872130539417267
Epoch: 15 | Iteration number: [2260/4518] 50% | Training loss: 0.6872095988651292
Epoch: 15 | Iteration number: [2270/4518] 50% | Training loss: 0.6872081693311095
Epoch: 15 | Iteration number: [2280/4518] 50% | Training loss: 0.6872088473616985
Epoch: 15 | Iteration number: [2290/4518] 50% | Training loss: 0.6872085058272666
Epoch: 15 | Iteration number: [2300/4518] 50% | Training loss: 0.6872064229198124
Epoch: 15 | Iteration number: [2310/4518] 51% | Training loss: 0.6872005784924412
Epoch: 15 | Iteration number: [2320/4518] 51% | Training loss: 0.6871963664632419
Epoch: 15 | Iteration number: [2330/4518] 51% | Training loss: 0.6871953303977655
Epoch: 15 | Iteration number: [2340/4518] 51% | Training loss: 0.6871940840258558
Epoch: 15 | Iteration number: [2350/4518] 52% | Training loss: 0.6871950063553263
Epoch: 15 | Iteration number: [2360/4518] 52% | Training loss: 0.6871969694808379
Epoch: 15 | Iteration number: [2370/4518] 52% | Training loss: 0.6871940132434861
Epoch: 15 | Iteration number: [2380/4518] 52% | Training loss: 0.6871936357822739
Epoch: 15 | Iteration number: [2390/4518] 52% | Training loss: 0.6871897462771028
Epoch: 15 | Iteration number: [2400/4518] 53% | Training loss: 0.6871901574730873
Epoch: 15 | Iteration number: [2410/4518] 53% | Training loss: 0.6871879871702787
Epoch: 15 | Iteration number: [2420/4518] 53% | Training loss: 0.6871841869324692
Epoch: 15 | Iteration number: [2430/4518] 53% | Training loss: 0.6871835202346613
Epoch: 15 | Iteration number: [2440/4518] 54% | Training loss: 0.6871815349723472
Epoch: 15 | Iteration number: [2450/4518] 54% | Training loss: 0.6871802208131673
Epoch: 15 | Iteration number: [2460/4518] 54% | Training loss: 0.6871806150044852
Epoch: 15 | Iteration number: [2470/4518] 54% | Training loss: 0.6871856698864385
Epoch: 15 | Iteration number: [2480/4518] 54% | Training loss: 0.6871857933219402
Epoch: 15 | Iteration number: [2490/4518] 55% | Training loss: 0.687192249705035
Epoch: 15 | Iteration number: [2500/4518] 55% | Training loss: 0.687190448975563
Epoch: 15 | Iteration number: [2510/4518] 55% | Training loss: 0.6871910588437342
Epoch: 15 | Iteration number: [2520/4518] 55% | Training loss: 0.6871868697423783
Epoch: 15 | Iteration number: [2530/4518] 55% | Training loss: 0.6871899025713503
Epoch: 15 | Iteration number: [2540/4518] 56% | Training loss: 0.687189234546789
Epoch: 15 | Iteration number: [2550/4518] 56% | Training loss: 0.687193618849212
Epoch: 15 | Iteration number: [2560/4518] 56% | Training loss: 0.6871921602636576
Epoch: 15 | Iteration number: [2570/4518] 56% | Training loss: 0.6871903064881781
Epoch: 15 | Iteration number: [2580/4518] 57% | Training loss: 0.6871918923170992
Epoch: 15 | Iteration number: [2590/4518] 57% | Training loss: 0.6871930210056453
Epoch: 15 | Iteration number: [2600/4518] 57% | Training loss: 0.6871928757199874
Epoch: 15 | Iteration number: [2610/4518] 57% | Training loss: 0.6871885226147385
Epoch: 15 | Iteration number: [2620/4518] 57% | Training loss: 0.687187115085944
Epoch: 15 | Iteration number: [2630/4518] 58% | Training loss: 0.6871858831140931
Epoch: 15 | Iteration number: [2640/4518] 58% | Training loss: 0.6871875704463685
Epoch: 15 | Iteration number: [2650/4518] 58% | Training loss: 0.6871893838441597
Epoch: 15 | Iteration number: [2660/4518] 58% | Training loss: 0.6871846801580344
Epoch: 15 | Iteration number: [2670/4518] 59% | Training loss: 0.6871830872158879
Epoch: 15 | Iteration number: [2680/4518] 59% | Training loss: 0.6871798504199554
Epoch: 15 | Iteration number: [2690/4518] 59% | Training loss: 0.6871838243698986
Epoch: 15 | Iteration number: [2700/4518] 59% | Training loss: 0.68718047550431
Epoch: 15 | Iteration number: [2710/4518] 59% | Training loss: 0.6871790880426709
Epoch: 15 | Iteration number: [2720/4518] 60% | Training loss: 0.6871771003174432
Epoch: 15 | Iteration number: [2730/4518] 60% | Training loss: 0.6871720954175398
Epoch: 15 | Iteration number: [2740/4518] 60% | Training loss: 0.6871667173657104
Epoch: 15 | Iteration number: [2750/4518] 60% | Training loss: 0.6871678098548543
Epoch: 15 | Iteration number: [2760/4518] 61% | Training loss: 0.6871687521969063
Epoch: 15 | Iteration number: [2770/4518] 61% | Training loss: 0.6871659098119082
Epoch: 15 | Iteration number: [2780/4518] 61% | Training loss: 0.6871666697718257
Epoch: 15 | Iteration number: [2790/4518] 61% | Training loss: 0.6871620753759979
Epoch: 15 | Iteration number: [2800/4518] 61% | Training loss: 0.6871595858037471
Epoch: 15 | Iteration number: [2810/4518] 62% | Training loss: 0.6871566543799702
Epoch: 15 | Iteration number: [2820/4518] 62% | Training loss: 0.6871568697564145
Epoch: 15 | Iteration number: [2830/4518] 62% | Training loss: 0.6871562526841045
Epoch: 15 | Iteration number: [2840/4518] 62% | Training loss: 0.6871584676101175
Epoch: 15 | Iteration number: [2850/4518] 63% | Training loss: 0.6871622531664999
Epoch: 15 | Iteration number: [2860/4518] 63% | Training loss: 0.6871577016748749
Epoch: 15 | Iteration number: [2870/4518] 63% | Training loss: 0.6871549388880513
Epoch: 15 | Iteration number: [2880/4518] 63% | Training loss: 0.6871523970117172
Epoch: 15 | Iteration number: [2890/4518] 63% | Training loss: 0.6871473463555108
Epoch: 15 | Iteration number: [2900/4518] 64% | Training loss: 0.6871482072410913
Epoch: 15 | Iteration number: [2910/4518] 64% | Training loss: 0.687150249714704
Epoch: 15 | Iteration number: [2920/4518] 64% | Training loss: 0.6871469357854699
Epoch: 15 | Iteration number: [2930/4518] 64% | Training loss: 0.6871431411736655
Epoch: 15 | Iteration number: [2940/4518] 65% | Training loss: 0.687139513804799
Epoch: 15 | Iteration number: [2950/4518] 65% | Training loss: 0.6871447897765596
Epoch: 15 | Iteration number: [2960/4518] 65% | Training loss: 0.6871419836943214
Epoch: 15 | Iteration number: [2970/4518] 65% | Training loss: 0.6871450436837745
Epoch: 15 | Iteration number: [2980/4518] 65% | Training loss: 0.687147135002501
Epoch: 15 | Iteration number: [2990/4518] 66% | Training loss: 0.6871504833666378
Epoch: 15 | Iteration number: [3000/4518] 66% | Training loss: 0.68714412043492
Epoch: 15 | Iteration number: [3010/4518] 66% | Training loss: 0.6871432286164293
Epoch: 15 | Iteration number: [3020/4518] 66% | Training loss: 0.6871400522869944
Epoch: 15 | Iteration number: [3030/4518] 67% | Training loss: 0.6871357920933084
Epoch: 15 | Iteration number: [3040/4518] 67% | Training loss: 0.6871382318633167
Epoch: 15 | Iteration number: [3050/4518] 67% | Training loss: 0.6871386183089897
Epoch: 15 | Iteration number: [3060/4518] 67% | Training loss: 0.6871353015206219
Epoch: 15 | Iteration number: [3070/4518] 67% | Training loss: 0.6871291974274266
Epoch: 15 | Iteration number: [3080/4518] 68% | Training loss: 0.6871295026370458
Epoch: 15 | Iteration number: [3090/4518] 68% | Training loss: 0.687126054964405
Epoch: 15 | Iteration number: [3100/4518] 68% | Training loss: 0.6871275389002216
Epoch: 15 | Iteration number: [3110/4518] 68% | Training loss: 0.6871289792168179
Epoch: 15 | Iteration number: [3120/4518] 69% | Training loss: 0.6871294827988514
Epoch: 15 | Iteration number: [3130/4518] 69% | Training loss: 0.6871290236235427
Epoch: 15 | Iteration number: [3140/4518] 69% | Training loss: 0.687126661580839
Epoch: 15 | Iteration number: [3150/4518] 69% | Training loss: 0.6871269733754415
Epoch: 15 | Iteration number: [3160/4518] 69% | Training loss: 0.6871272660131695
Epoch: 15 | Iteration number: [3170/4518] 70% | Training loss: 0.6871250409997224
Epoch: 15 | Iteration number: [3180/4518] 70% | Training loss: 0.687130276699486
Epoch: 15 | Iteration number: [3190/4518] 70% | Training loss: 0.6871304383472215
Epoch: 15 | Iteration number: [3200/4518] 70% | Training loss: 0.6871241343021393
Epoch: 15 | Iteration number: [3210/4518] 71% | Training loss: 0.6871218616903014
Epoch: 15 | Iteration number: [3220/4518] 71% | Training loss: 0.6871153871465173
Epoch: 15 | Iteration number: [3230/4518] 71% | Training loss: 0.6871136898042248
Epoch: 15 | Iteration number: [3240/4518] 71% | Training loss: 0.687112336817347
Epoch: 15 | Iteration number: [3250/4518] 71% | Training loss: 0.687109948194944
Epoch: 15 | Iteration number: [3260/4518] 72% | Training loss: 0.687108625371032
Epoch: 15 | Iteration number: [3270/4518] 72% | Training loss: 0.687110181321427
Epoch: 15 | Iteration number: [3280/4518] 72% | Training loss: 0.6871062123193974
Epoch: 15 | Iteration number: [3290/4518] 72% | Training loss: 0.687103330002005
Epoch: 15 | Iteration number: [3300/4518] 73% | Training loss: 0.6870969424825726
Epoch: 15 | Iteration number: [3310/4518] 73% | Training loss: 0.687097039971827
Epoch: 15 | Iteration number: [3320/4518] 73% | Training loss: 0.6871002140533493
Epoch: 15 | Iteration number: [3330/4518] 73% | Training loss: 0.6871022188806677
Epoch: 15 | Iteration number: [3340/4518] 73% | Training loss: 0.6871018958305884
Epoch: 15 | Iteration number: [3350/4518] 74% | Training loss: 0.6871008113782797
Epoch: 15 | Iteration number: [3360/4518] 74% | Training loss: 0.6871005903752078
Epoch: 15 | Iteration number: [3370/4518] 74% | Training loss: 0.6870976403841986
Epoch: 15 | Iteration number: [3380/4518] 74% | Training loss: 0.6871007246202265
Epoch: 15 | Iteration number: [3390/4518] 75% | Training loss: 0.6870993428174021
Epoch: 15 | Iteration number: [3400/4518] 75% | Training loss: 0.6870970328590449
Epoch: 15 | Iteration number: [3410/4518] 75% | Training loss: 0.6870947168195003
Epoch: 15 | Iteration number: [3420/4518] 75% | Training loss: 0.6870951101968162
Epoch: 15 | Iteration number: [3430/4518] 75% | Training loss: 0.6870923546938438
Epoch: 15 | Iteration number: [3440/4518] 76% | Training loss: 0.687092151510161
Epoch: 15 | Iteration number: [3450/4518] 76% | Training loss: 0.6870945655090221
Epoch: 15 | Iteration number: [3460/4518] 76% | Training loss: 0.6870923075028238
Epoch: 15 | Iteration number: [3470/4518] 76% | Training loss: 0.6870917355808126
Epoch: 15 | Iteration number: [3480/4518] 77% | Training loss: 0.6870885851910744
Epoch: 15 | Iteration number: [3490/4518] 77% | Training loss: 0.6870853121779368
Epoch: 15 | Iteration number: [3500/4518] 77% | Training loss: 0.6870849348987852
Epoch: 15 | Iteration number: [3510/4518] 77% | Training loss: 0.6870835489187486
Epoch: 15 | Iteration number: [3520/4518] 77% | Training loss: 0.6870840422470461
Epoch: 15 | Iteration number: [3530/4518] 78% | Training loss: 0.6870845154560997
Epoch: 15 | Iteration number: [3540/4518] 78% | Training loss: 0.6870867806639375
Epoch: 15 | Iteration number: [3550/4518] 78% | Training loss: 0.6870865260043615
Epoch: 15 | Iteration number: [3560/4518] 78% | Training loss: 0.6870867579505685
Epoch: 15 | Iteration number: [3570/4518] 79% | Training loss: 0.6870868706235699
Epoch: 15 | Iteration number: [3580/4518] 79% | Training loss: 0.6870886467355589
Epoch: 15 | Iteration number: [3590/4518] 79% | Training loss: 0.6870891545974445
Epoch: 15 | Iteration number: [3600/4518] 79% | Training loss: 0.687090987910827
Epoch: 15 | Iteration number: [3610/4518] 79% | Training loss: 0.6870922299468286
Epoch: 15 | Iteration number: [3620/4518] 80% | Training loss: 0.6870924340262597
Epoch: 15 | Iteration number: [3630/4518] 80% | Training loss: 0.6870899509956686
Epoch: 15 | Iteration number: [3640/4518] 80% | Training loss: 0.687089152928892
Epoch: 15 | Iteration number: [3650/4518] 80% | Training loss: 0.6870861795503799
Epoch: 15 | Iteration number: [3660/4518] 81% | Training loss: 0.6870885947688681
Epoch: 15 | Iteration number: [3670/4518] 81% | Training loss: 0.6870872072205556
Epoch: 15 | Iteration number: [3680/4518] 81% | Training loss: 0.6870859950942838
Epoch: 15 | Iteration number: [3690/4518] 81% | Training loss: 0.687086523273773
Epoch: 15 | Iteration number: [3700/4518] 81% | Training loss: 0.6870854186689531
Epoch: 15 | Iteration number: [3710/4518] 82% | Training loss: 0.6870908088118561
Epoch: 15 | Iteration number: [3720/4518] 82% | Training loss: 0.6870919703636118
Epoch: 15 | Iteration number: [3730/4518] 82% | Training loss: 0.6870950312461035
Epoch: 15 | Iteration number: [3740/4518] 82% | Training loss: 0.6870964244247121
Epoch: 15 | Iteration number: [3750/4518] 83% | Training loss: 0.6870954660097758
Epoch: 15 | Iteration number: [3760/4518] 83% | Training loss: 0.6870949022313382
Epoch: 15 | Iteration number: [3770/4518] 83% | Training loss: 0.6870934920538642
Epoch: 15 | Iteration number: [3780/4518] 83% | Training loss: 0.6870894330361533
Epoch: 15 | Iteration number: [3790/4518] 83% | Training loss: 0.6870852097043262
Epoch: 15 | Iteration number: [3800/4518] 84% | Training loss: 0.6870866245972482
Epoch: 15 | Iteration number: [3810/4518] 84% | Training loss: 0.6870846791373776
Epoch: 15 | Iteration number: [3820/4518] 84% | Training loss: 0.687085926719985
Epoch: 15 | Iteration number: [3830/4518] 84% | Training loss: 0.687085874631573
Epoch: 15 | Iteration number: [3840/4518] 84% | Training loss: 0.6870874636030445
Epoch: 15 | Iteration number: [3850/4518] 85% | Training loss: 0.6870905941028099
Epoch: 15 | Iteration number: [3860/4518] 85% | Training loss: 0.687091383801223
Epoch: 15 | Iteration number: [3870/4518] 85% | Training loss: 0.6870936634928682
Epoch: 15 | Iteration number: [3880/4518] 85% | Training loss: 0.6870953780320502
Epoch: 15 | Iteration number: [3890/4518] 86% | Training loss: 0.687095294620813
Epoch: 15 | Iteration number: [3900/4518] 86% | Training loss: 0.6870926893521578
Epoch: 15 | Iteration number: [3910/4518] 86% | Training loss: 0.6870960094282389
Epoch: 15 | Iteration number: [3920/4518] 86% | Training loss: 0.6870974617649098
Epoch: 15 | Iteration number: [3930/4518] 86% | Training loss: 0.6870966411728895
Epoch: 15 | Iteration number: [3940/4518] 87% | Training loss: 0.6870978460245326
Epoch: 15 | Iteration number: [3950/4518] 87% | Training loss: 0.6870970076247107
Epoch: 15 | Iteration number: [3960/4518] 87% | Training loss: 0.6870969760899592
Epoch: 15 | Iteration number: [3970/4518] 87% | Training loss: 0.6870940001545385
Epoch: 15 | Iteration number: [3980/4518] 88% | Training loss: 0.6870959087981651
Epoch: 15 | Iteration number: [3990/4518] 88% | Training loss: 0.6870936468878486
Epoch: 15 | Iteration number: [4000/4518] 88% | Training loss: 0.6870929634571076
Epoch: 15 | Iteration number: [4010/4518] 88% | Training loss: 0.6870946754243903
Epoch: 15 | Iteration number: [4020/4518] 88% | Training loss: 0.6870963364543013
Epoch: 15 | Iteration number: [4030/4518] 89% | Training loss: 0.6870970284228881
Epoch: 15 | Iteration number: [4040/4518] 89% | Training loss: 0.6870965884758694
Epoch: 15 | Iteration number: [4050/4518] 89% | Training loss: 0.6870935474796059
Epoch: 15 | Iteration number: [4060/4518] 89% | Training loss: 0.6870919932579173
Epoch: 15 | Iteration number: [4070/4518] 90% | Training loss: 0.6870928773423085
Epoch: 15 | Iteration number: [4080/4518] 90% | Training loss: 0.6870897619455468
Epoch: 15 | Iteration number: [4090/4518] 90% | Training loss: 0.6870913977436448
Epoch: 15 | Iteration number: [4100/4518] 90% | Training loss: 0.6870902229954556
Epoch: 15 | Iteration number: [4110/4518] 90% | Training loss: 0.6870912101582018
Epoch: 15 | Iteration number: [4120/4518] 91% | Training loss: 0.6870888942509021
Epoch: 15 | Iteration number: [4130/4518] 91% | Training loss: 0.6870888310685285
Epoch: 15 | Iteration number: [4140/4518] 91% | Training loss: 0.6870862712750688
Epoch: 15 | Iteration number: [4150/4518] 91% | Training loss: 0.6870833346642644
Epoch: 15 | Iteration number: [4160/4518] 92% | Training loss: 0.6870829923508259
Epoch: 15 | Iteration number: [4170/4518] 92% | Training loss: 0.6870814121312661
Epoch: 15 | Iteration number: [4180/4518] 92% | Training loss: 0.6870834520701586
Epoch: 15 | Iteration number: [4190/4518] 92% | Training loss: 0.6870827265883972
Epoch: 15 | Iteration number: [4200/4518] 92% | Training loss: 0.6870817669516518
Epoch: 15 | Iteration number: [4210/4518] 93% | Training loss: 0.6870848408504223
Epoch: 15 | Iteration number: [4220/4518] 93% | Training loss: 0.6870858390466862
Epoch: 15 | Iteration number: [4230/4518] 93% | Training loss: 0.6870853465358698
Epoch: 15 | Iteration number: [4240/4518] 93% | Training loss: 0.6870870035352572
Epoch: 15 | Iteration number: [4250/4518] 94% | Training loss: 0.6870870947978076
Epoch: 15 | Iteration number: [4260/4518] 94% | Training loss: 0.6870909083477208
Epoch: 15 | Iteration number: [4270/4518] 94% | Training loss: 0.6870924911677698
Epoch: 15 | Iteration number: [4280/4518] 94% | Training loss: 0.6870872843209829
Epoch: 15 | Iteration number: [4290/4518] 94% | Training loss: 0.6870812966690197
Epoch: 15 | Iteration number: [4300/4518] 95% | Training loss: 0.6870818120934242
Epoch: 15 | Iteration number: [4310/4518] 95% | Training loss: 0.6870828038716814
Epoch: 15 | Iteration number: [4320/4518] 95% | Training loss: 0.6870843678850819
Epoch: 15 | Iteration number: [4330/4518] 95% | Training loss: 0.687085224092695
Epoch: 15 | Iteration number: [4340/4518] 96% | Training loss: 0.6870851469342061
Epoch: 15 | Iteration number: [4350/4518] 96% | Training loss: 0.6870840961494665
Epoch: 15 | Iteration number: [4360/4518] 96% | Training loss: 0.687079190469663
Epoch: 15 | Iteration number: [4370/4518] 96% | Training loss: 0.6870783045035478
Epoch: 15 | Iteration number: [4380/4518] 96% | Training loss: 0.6870783317442898
Epoch: 15 | Iteration number: [4390/4518] 97% | Training loss: 0.6870761898764174
Epoch: 15 | Iteration number: [4400/4518] 97% | Training loss: 0.6870763761753386
Epoch: 15 | Iteration number: [4410/4518] 97% | Training loss: 0.6870754387373287
Epoch: 15 | Iteration number: [4420/4518] 97% | Training loss: 0.6870733934559973
Epoch: 15 | Iteration number: [4430/4518] 98% | Training loss: 0.6870709090550382
Epoch: 15 | Iteration number: [4440/4518] 98% | Training loss: 0.6870690183730813
Epoch: 15 | Iteration number: [4450/4518] 98% | Training loss: 0.6870696902275085
Epoch: 15 | Iteration number: [4460/4518] 98% | Training loss: 0.6870692804923506
Epoch: 15 | Iteration number: [4470/4518] 98% | Training loss: 0.6870713293285712
Epoch: 15 | Iteration number: [4480/4518] 99% | Training loss: 0.6870723899853016
Epoch: 15 | Iteration number: [4490/4518] 99% | Training loss: 0.6870733763035263
Epoch: 15 | Iteration number: [4500/4518] 99% | Training loss: 0.6870740896860759
Epoch: 15 | Iteration number: [4510/4518] 99% | Training loss: 0.6870733270756156

 End of epoch: 15 | Train Loss: 0.6869195209186971 | Training Time: 633 

 End of epoch: 15 | Eval Loss: 0.6900626469631584 | Evaluating Time: 18 
Epoch: 16 | Iteration number: [10/4518] 0% | Training loss: 0.7560892581939698
Epoch: 16 | Iteration number: [20/4518] 0% | Training loss: 0.7216882169246673
Epoch: 16 | Iteration number: [30/4518] 0% | Training loss: 0.710149637858073
Epoch: 16 | Iteration number: [40/4518] 0% | Training loss: 0.7045145437121392
Epoch: 16 | Iteration number: [50/4518] 1% | Training loss: 0.7011268150806427
Epoch: 16 | Iteration number: [60/4518] 1% | Training loss: 0.698888553182284
Epoch: 16 | Iteration number: [70/4518] 1% | Training loss: 0.6972559332847595
Epoch: 16 | Iteration number: [80/4518] 1% | Training loss: 0.6959442347288132
Epoch: 16 | Iteration number: [90/4518] 1% | Training loss: 0.6949035942554473
Epoch: 16 | Iteration number: [100/4518] 2% | Training loss: 0.6941141694784164
Epoch: 16 | Iteration number: [110/4518] 2% | Training loss: 0.693519611792131
Epoch: 16 | Iteration number: [120/4518] 2% | Training loss: 0.6930321221550305
Epoch: 16 | Iteration number: [130/4518] 2% | Training loss: 0.6925832638373741
Epoch: 16 | Iteration number: [140/4518] 3% | Training loss: 0.6921509627785002
Epoch: 16 | Iteration number: [150/4518] 3% | Training loss: 0.6917633044719697
Epoch: 16 | Iteration number: [160/4518] 3% | Training loss: 0.6914869908243417
Epoch: 16 | Iteration number: [170/4518] 3% | Training loss: 0.6912147676243502
Epoch: 16 | Iteration number: [180/4518] 3% | Training loss: 0.6910184575451745
Epoch: 16 | Iteration number: [190/4518] 4% | Training loss: 0.6908286424059616
Epoch: 16 | Iteration number: [200/4518] 4% | Training loss: 0.6906274157762528
Epoch: 16 | Iteration number: [210/4518] 4% | Training loss: 0.6904815628415062
Epoch: 16 | Iteration number: [220/4518] 4% | Training loss: 0.6902864873409271
Epoch: 16 | Iteration number: [230/4518] 5% | Training loss: 0.6901404567386793
Epoch: 16 | Iteration number: [240/4518] 5% | Training loss: 0.6899603920678298
Epoch: 16 | Iteration number: [250/4518] 5% | Training loss: 0.6898251850605011
Epoch: 16 | Iteration number: [260/4518] 5% | Training loss: 0.6897113784001424
Epoch: 16 | Iteration number: [270/4518] 5% | Training loss: 0.689584391646915
Epoch: 16 | Iteration number: [280/4518] 6% | Training loss: 0.6894838339516095
Epoch: 16 | Iteration number: [290/4518] 6% | Training loss: 0.6893772384216046
Epoch: 16 | Iteration number: [300/4518] 6% | Training loss: 0.6892750759919485
Epoch: 16 | Iteration number: [310/4518] 6% | Training loss: 0.6891711311955606
Epoch: 16 | Iteration number: [320/4518] 7% | Training loss: 0.6891247611492872
Epoch: 16 | Iteration number: [330/4518] 7% | Training loss: 0.6890477429736744
Epoch: 16 | Iteration number: [340/4518] 7% | Training loss: 0.6890014581820544
Epoch: 16 | Iteration number: [350/4518] 7% | Training loss: 0.6889435275963375
Epoch: 16 | Iteration number: [360/4518] 7% | Training loss: 0.6888885989785194
Epoch: 16 | Iteration number: [370/4518] 8% | Training loss: 0.688857170697805
Epoch: 16 | Iteration number: [380/4518] 8% | Training loss: 0.6887907909719567
Epoch: 16 | Iteration number: [390/4518] 8% | Training loss: 0.6887675548211122
Epoch: 16 | Iteration number: [400/4518] 8% | Training loss: 0.6887426602840424
Epoch: 16 | Iteration number: [410/4518] 9% | Training loss: 0.6887085216801341
Epoch: 16 | Iteration number: [420/4518] 9% | Training loss: 0.6886625153677804
Epoch: 16 | Iteration number: [430/4518] 9% | Training loss: 0.6886332736458889
Epoch: 16 | Iteration number: [440/4518] 9% | Training loss: 0.6885782587257299
Epoch: 16 | Iteration number: [450/4518] 9% | Training loss: 0.688534015417099
Epoch: 16 | Iteration number: [460/4518] 10% | Training loss: 0.6885438932024914
Epoch: 16 | Iteration number: [470/4518] 10% | Training loss: 0.6885038595250312
Epoch: 16 | Iteration number: [480/4518] 10% | Training loss: 0.6885108197728793
Epoch: 16 | Iteration number: [490/4518] 10% | Training loss: 0.6884733195207557
Epoch: 16 | Iteration number: [500/4518] 11% | Training loss: 0.6884317998886108
Epoch: 16 | Iteration number: [510/4518] 11% | Training loss: 0.6883878388825585
Epoch: 16 | Iteration number: [520/4518] 11% | Training loss: 0.688360459300188
Epoch: 16 | Iteration number: [530/4518] 11% | Training loss: 0.6883285966684234
Epoch: 16 | Iteration number: [540/4518] 11% | Training loss: 0.6883188145028221
Epoch: 16 | Iteration number: [550/4518] 12% | Training loss: 0.6882955658435822
Epoch: 16 | Iteration number: [560/4518] 12% | Training loss: 0.688252693521125
Epoch: 16 | Iteration number: [570/4518] 12% | Training loss: 0.6881937617795509
Epoch: 16 | Iteration number: [580/4518] 12% | Training loss: 0.6881841311167026
Epoch: 16 | Iteration number: [590/4518] 13% | Training loss: 0.6881472423925238
Epoch: 16 | Iteration number: [600/4518] 13% | Training loss: 0.688138851026694
Epoch: 16 | Iteration number: [610/4518] 13% | Training loss: 0.6881353753512023
Epoch: 16 | Iteration number: [620/4518] 13% | Training loss: 0.6881064563028274
Epoch: 16 | Iteration number: [630/4518] 13% | Training loss: 0.6880924967546311
Epoch: 16 | Iteration number: [640/4518] 14% | Training loss: 0.6880917592905462
Epoch: 16 | Iteration number: [650/4518] 14% | Training loss: 0.6880781151698185
Epoch: 16 | Iteration number: [660/4518] 14% | Training loss: 0.6880648209290071
Epoch: 16 | Iteration number: [670/4518] 14% | Training loss: 0.688035142777571
Epoch: 16 | Iteration number: [680/4518] 15% | Training loss: 0.6880187542999492
Epoch: 16 | Iteration number: [690/4518] 15% | Training loss: 0.6879908755205679
Epoch: 16 | Iteration number: [700/4518] 15% | Training loss: 0.687978208746229
Epoch: 16 | Iteration number: [710/4518] 15% | Training loss: 0.6879663766269952
Epoch: 16 | Iteration number: [720/4518] 15% | Training loss: 0.6879623715248373
Epoch: 16 | Iteration number: [730/4518] 16% | Training loss: 0.6879553967142759
Epoch: 16 | Iteration number: [740/4518] 16% | Training loss: 0.6879397477652576
Epoch: 16 | Iteration number: [750/4518] 16% | Training loss: 0.687934822320938
Epoch: 16 | Iteration number: [760/4518] 16% | Training loss: 0.687924657918905
Epoch: 16 | Iteration number: [770/4518] 17% | Training loss: 0.6879051343961196
Epoch: 16 | Iteration number: [780/4518] 17% | Training loss: 0.6879071611624498
Epoch: 16 | Iteration number: [790/4518] 17% | Training loss: 0.6879005043566981
Epoch: 16 | Iteration number: [800/4518] 17% | Training loss: 0.6878804266452789
Epoch: 16 | Iteration number: [810/4518] 17% | Training loss: 0.6878674773522365
Epoch: 16 | Iteration number: [820/4518] 18% | Training loss: 0.6878670821102654
Epoch: 16 | Iteration number: [830/4518] 18% | Training loss: 0.687861078115831
Epoch: 16 | Iteration number: [840/4518] 18% | Training loss: 0.6878680486764227
Epoch: 16 | Iteration number: [850/4518] 18% | Training loss: 0.6878587161793428
Epoch: 16 | Iteration number: [860/4518] 19% | Training loss: 0.6878427702327107
Epoch: 16 | Iteration number: [870/4518] 19% | Training loss: 0.6878270591812572
Epoch: 16 | Iteration number: [880/4518] 19% | Training loss: 0.6878279997543855
Epoch: 16 | Iteration number: [890/4518] 19% | Training loss: 0.6878194934196686
Epoch: 16 | Iteration number: [900/4518] 19% | Training loss: 0.6878009618653191
Epoch: 16 | Iteration number: [910/4518] 20% | Training loss: 0.6877817358289446
Epoch: 16 | Iteration number: [920/4518] 20% | Training loss: 0.6877818044760953
Epoch: 16 | Iteration number: [930/4518] 20% | Training loss: 0.6877625241074511
Epoch: 16 | Iteration number: [940/4518] 20% | Training loss: 0.6877695134979613
Epoch: 16 | Iteration number: [950/4518] 21% | Training loss: 0.6877648733791553
Epoch: 16 | Iteration number: [960/4518] 21% | Training loss: 0.6877587842444579
Epoch: 16 | Iteration number: [970/4518] 21% | Training loss: 0.6877615325844165
Epoch: 16 | Iteration number: [980/4518] 21% | Training loss: 0.6877447207363284
Epoch: 16 | Iteration number: [990/4518] 21% | Training loss: 0.6877266556927653
Epoch: 16 | Iteration number: [1000/4518] 22% | Training loss: 0.6877208657860756
Epoch: 16 | Iteration number: [1010/4518] 22% | Training loss: 0.6877253779680422
Epoch: 16 | Iteration number: [1020/4518] 22% | Training loss: 0.6877175667122298
Epoch: 16 | Iteration number: [1030/4518] 22% | Training loss: 0.6876937031745911
Epoch: 16 | Iteration number: [1040/4518] 23% | Training loss: 0.6876902682276872
Epoch: 16 | Iteration number: [1050/4518] 23% | Training loss: 0.6876865340414502
Epoch: 16 | Iteration number: [1060/4518] 23% | Training loss: 0.6876890545746066
Epoch: 16 | Iteration number: [1070/4518] 23% | Training loss: 0.687685265607923
Epoch: 16 | Iteration number: [1080/4518] 23% | Training loss: 0.6876853803793589
Epoch: 16 | Iteration number: [1090/4518] 24% | Training loss: 0.6876842171227167
Epoch: 16 | Iteration number: [1100/4518] 24% | Training loss: 0.6876695987311277
Epoch: 16 | Iteration number: [1110/4518] 24% | Training loss: 0.6876518430473568
Epoch: 16 | Iteration number: [1120/4518] 24% | Training loss: 0.6876430438033172
Epoch: 16 | Iteration number: [1130/4518] 25% | Training loss: 0.6876355718194911
Epoch: 16 | Iteration number: [1140/4518] 25% | Training loss: 0.687625466417848
Epoch: 16 | Iteration number: [1150/4518] 25% | Training loss: 0.6876184889544611
Epoch: 16 | Iteration number: [1160/4518] 25% | Training loss: 0.6876125836680675
Epoch: 16 | Iteration number: [1170/4518] 25% | Training loss: 0.6876067909929487
Epoch: 16 | Iteration number: [1180/4518] 26% | Training loss: 0.6875915056062957
Epoch: 16 | Iteration number: [1190/4518] 26% | Training loss: 0.6875791089374478
Epoch: 16 | Iteration number: [1200/4518] 26% | Training loss: 0.6875635076562564
Epoch: 16 | Iteration number: [1210/4518] 26% | Training loss: 0.687555394832753
Epoch: 16 | Iteration number: [1220/4518] 27% | Training loss: 0.6875455932539017
Epoch: 16 | Iteration number: [1230/4518] 27% | Training loss: 0.6875273047423944
Epoch: 16 | Iteration number: [1240/4518] 27% | Training loss: 0.6875358688735193
Epoch: 16 | Iteration number: [1250/4518] 27% | Training loss: 0.6875329827785492
Epoch: 16 | Iteration number: [1260/4518] 27% | Training loss: 0.6875273702163545
Epoch: 16 | Iteration number: [1270/4518] 28% | Training loss: 0.6875239070006243
Epoch: 16 | Iteration number: [1280/4518] 28% | Training loss: 0.6875193594954908
Epoch: 16 | Iteration number: [1290/4518] 28% | Training loss: 0.6875111938446992
Epoch: 16 | Iteration number: [1300/4518] 28% | Training loss: 0.6874938211991237
Epoch: 16 | Iteration number: [1310/4518] 28% | Training loss: 0.6874895353808658
Epoch: 16 | Iteration number: [1320/4518] 29% | Training loss: 0.6874793121308992
Epoch: 16 | Iteration number: [1330/4518] 29% | Training loss: 0.6874666823480362
Epoch: 16 | Iteration number: [1340/4518] 29% | Training loss: 0.6874608812937096
Epoch: 16 | Iteration number: [1350/4518] 29% | Training loss: 0.6874514327225861
Epoch: 16 | Iteration number: [1360/4518] 30% | Training loss: 0.6874466639669502
Epoch: 16 | Iteration number: [1370/4518] 30% | Training loss: 0.6874364205085448
Epoch: 16 | Iteration number: [1380/4518] 30% | Training loss: 0.6874272343473158
Epoch: 16 | Iteration number: [1390/4518] 30% | Training loss: 0.6874234511269083
Epoch: 16 | Iteration number: [1400/4518] 30% | Training loss: 0.6874229115673474
Epoch: 16 | Iteration number: [1410/4518] 31% | Training loss: 0.6874143793650552
Epoch: 16 | Iteration number: [1420/4518] 31% | Training loss: 0.6874070810180315
Epoch: 16 | Iteration number: [1430/4518] 31% | Training loss: 0.6874005204730934
Epoch: 16 | Iteration number: [1440/4518] 31% | Training loss: 0.687396181623141
Epoch: 16 | Iteration number: [1450/4518] 32% | Training loss: 0.6873931705129558
Epoch: 16 | Iteration number: [1460/4518] 32% | Training loss: 0.6873997828731798
Epoch: 16 | Iteration number: [1470/4518] 32% | Training loss: 0.6874006220678083
Epoch: 16 | Iteration number: [1480/4518] 32% | Training loss: 0.6874010496848338
Epoch: 16 | Iteration number: [1490/4518] 32% | Training loss: 0.687395248837119
Epoch: 16 | Iteration number: [1500/4518] 33% | Training loss: 0.6873934646844864
Epoch: 16 | Iteration number: [1510/4518] 33% | Training loss: 0.6873909811705153
Epoch: 16 | Iteration number: [1520/4518] 33% | Training loss: 0.6873888495329179
Epoch: 16 | Iteration number: [1530/4518] 33% | Training loss: 0.6873828927675883
Epoch: 16 | Iteration number: [1540/4518] 34% | Training loss: 0.6873716561825245
Epoch: 16 | Iteration number: [1550/4518] 34% | Training loss: 0.6873667871952057
Epoch: 16 | Iteration number: [1560/4518] 34% | Training loss: 0.6873737954940551
Epoch: 16 | Iteration number: [1570/4518] 34% | Training loss: 0.6873701556093373
Epoch: 16 | Iteration number: [1580/4518] 34% | Training loss: 0.687360862010642
Epoch: 16 | Iteration number: [1590/4518] 35% | Training loss: 0.6873551803564876
Epoch: 16 | Iteration number: [1600/4518] 35% | Training loss: 0.6873578774556518
Epoch: 16 | Iteration number: [1610/4518] 35% | Training loss: 0.6873571729437905
Epoch: 16 | Iteration number: [1620/4518] 35% | Training loss: 0.6873613317439585
Epoch: 16 | Iteration number: [1630/4518] 36% | Training loss: 0.6873616131902472
Epoch: 16 | Iteration number: [1640/4518] 36% | Training loss: 0.6873529030055534
Epoch: 16 | Iteration number: [1650/4518] 36% | Training loss: 0.6873472630977631
Epoch: 16 | Iteration number: [1660/4518] 36% | Training loss: 0.6873470843556415
Epoch: 16 | Iteration number: [1670/4518] 36% | Training loss: 0.6873405743858771
Epoch: 16 | Iteration number: [1680/4518] 37% | Training loss: 0.6873401342758111
Epoch: 16 | Iteration number: [1690/4518] 37% | Training loss: 0.687343267717305
Epoch: 16 | Iteration number: [1700/4518] 37% | Training loss: 0.6873409777178484
Epoch: 16 | Iteration number: [1710/4518] 37% | Training loss: 0.6873427013556163
Epoch: 16 | Iteration number: [1720/4518] 38% | Training loss: 0.6873239055275917
Epoch: 16 | Iteration number: [1730/4518] 38% | Training loss: 0.6873254501750703
Epoch: 16 | Iteration number: [1740/4518] 38% | Training loss: 0.6873164666452627
Epoch: 16 | Iteration number: [1750/4518] 38% | Training loss: 0.6873230475017003
Epoch: 16 | Iteration number: [1760/4518] 38% | Training loss: 0.6873225615444508
Epoch: 16 | Iteration number: [1770/4518] 39% | Training loss: 0.6873182626093848
Epoch: 16 | Iteration number: [1780/4518] 39% | Training loss: 0.6873114105021016
Epoch: 16 | Iteration number: [1790/4518] 39% | Training loss: 0.6873134897407873
Epoch: 16 | Iteration number: [1800/4518] 39% | Training loss: 0.6873119224111239
Epoch: 16 | Iteration number: [1810/4518] 40% | Training loss: 0.6873059306355471
Epoch: 16 | Iteration number: [1820/4518] 40% | Training loss: 0.6873058619407507
Epoch: 16 | Iteration number: [1830/4518] 40% | Training loss: 0.6873019865953206
Epoch: 16 | Iteration number: [1840/4518] 40% | Training loss: 0.6872978157647278
Epoch: 16 | Iteration number: [1850/4518] 40% | Training loss: 0.6872927806506286
Epoch: 16 | Iteration number: [1860/4518] 41% | Training loss: 0.6872934354248867
Epoch: 16 | Iteration number: [1870/4518] 41% | Training loss: 0.6872946357982044
Epoch: 16 | Iteration number: [1880/4518] 41% | Training loss: 0.6872896351078723
Epoch: 16 | Iteration number: [1890/4518] 41% | Training loss: 0.687282902759219
Epoch: 16 | Iteration number: [1900/4518] 42% | Training loss: 0.6872806657301752
Epoch: 16 | Iteration number: [1910/4518] 42% | Training loss: 0.6872836566720334
Epoch: 16 | Iteration number: [1920/4518] 42% | Training loss: 0.6872880415059626
Epoch: 16 | Iteration number: [1930/4518] 42% | Training loss: 0.687287782881544
Epoch: 16 | Iteration number: [1940/4518] 42% | Training loss: 0.6872863596554883
Epoch: 16 | Iteration number: [1950/4518] 43% | Training loss: 0.6872908759117127
Epoch: 16 | Iteration number: [1960/4518] 43% | Training loss: 0.6872931671994073
Epoch: 16 | Iteration number: [1970/4518] 43% | Training loss: 0.6872974897096605
Epoch: 16 | Iteration number: [1980/4518] 43% | Training loss: 0.6872949833821769
Epoch: 16 | Iteration number: [1990/4518] 44% | Training loss: 0.6872939189175266
Epoch: 16 | Iteration number: [2000/4518] 44% | Training loss: 0.6872910743951798
Epoch: 16 | Iteration number: [2010/4518] 44% | Training loss: 0.6872803185413133
Epoch: 16 | Iteration number: [2020/4518] 44% | Training loss: 0.6872834475323706
Epoch: 16 | Iteration number: [2030/4518] 44% | Training loss: 0.6872815958678429
Epoch: 16 | Iteration number: [2040/4518] 45% | Training loss: 0.6872791939798524
Epoch: 16 | Iteration number: [2050/4518] 45% | Training loss: 0.687273274631035
Epoch: 16 | Iteration number: [2060/4518] 45% | Training loss: 0.6872687658927973
Epoch: 16 | Iteration number: [2070/4518] 45% | Training loss: 0.6872685663078142
Epoch: 16 | Iteration number: [2080/4518] 46% | Training loss: 0.6872714567069824
Epoch: 16 | Iteration number: [2090/4518] 46% | Training loss: 0.6872682204657194
Epoch: 16 | Iteration number: [2100/4518] 46% | Training loss: 0.6872641886699767
Epoch: 16 | Iteration number: [2110/4518] 46% | Training loss: 0.6872557633013522
Epoch: 16 | Iteration number: [2120/4518] 46% | Training loss: 0.6872531182642253
Epoch: 16 | Iteration number: [2130/4518] 47% | Training loss: 0.6872550532291752
Epoch: 16 | Iteration number: [2140/4518] 47% | Training loss: 0.6872580578672551
Epoch: 16 | Iteration number: [2150/4518] 47% | Training loss: 0.6872521438709526
Epoch: 16 | Iteration number: [2160/4518] 47% | Training loss: 0.6872494210799535
Epoch: 16 | Iteration number: [2170/4518] 48% | Training loss: 0.6872475438952995
Epoch: 16 | Iteration number: [2180/4518] 48% | Training loss: 0.6872453810971811
Epoch: 16 | Iteration number: [2190/4518] 48% | Training loss: 0.6872481372258434
Epoch: 16 | Iteration number: [2200/4518] 48% | Training loss: 0.6872514306144281
Epoch: 16 | Iteration number: [2210/4518] 48% | Training loss: 0.6872559865675361
Epoch: 16 | Iteration number: [2220/4518] 49% | Training loss: 0.6872502065188176
Epoch: 16 | Iteration number: [2230/4518] 49% | Training loss: 0.6872503523602079
Epoch: 16 | Iteration number: [2240/4518] 49% | Training loss: 0.6872499076649546
Epoch: 16 | Iteration number: [2250/4518] 49% | Training loss: 0.687244099855423
Epoch: 16 | Iteration number: [2260/4518] 50% | Training loss: 0.6872434175119991
Epoch: 16 | Iteration number: [2270/4518] 50% | Training loss: 0.6872366882630907
Epoch: 16 | Iteration number: [2280/4518] 50% | Training loss: 0.6872395052721626
Epoch: 16 | Iteration number: [2290/4518] 50% | Training loss: 0.6872376012229503
Epoch: 16 | Iteration number: [2300/4518] 50% | Training loss: 0.6872428883417793
Epoch: 16 | Iteration number: [2310/4518] 51% | Training loss: 0.6872420349936464
Epoch: 16 | Iteration number: [2320/4518] 51% | Training loss: 0.6872378072091218
Epoch: 16 | Iteration number: [2330/4518] 51% | Training loss: 0.687237505953711
Epoch: 16 | Iteration number: [2340/4518] 51% | Training loss: 0.6872363231885128
Epoch: 16 | Iteration number: [2350/4518] 52% | Training loss: 0.6872344230083709
Epoch: 16 | Iteration number: [2360/4518] 52% | Training loss: 0.6872324893535193
Epoch: 16 | Iteration number: [2370/4518] 52% | Training loss: 0.6872337439643683
Epoch: 16 | Iteration number: [2380/4518] 52% | Training loss: 0.6872351707530623
Epoch: 16 | Iteration number: [2390/4518] 52% | Training loss: 0.6872297430138209
Epoch: 16 | Iteration number: [2400/4518] 53% | Training loss: 0.6872278020282586
Epoch: 16 | Iteration number: [2410/4518] 53% | Training loss: 0.6872264057026859
Epoch: 16 | Iteration number: [2420/4518] 53% | Training loss: 0.6872286864794975
Epoch: 16 | Iteration number: [2430/4518] 53% | Training loss: 0.6872287398012578
Epoch: 16 | Iteration number: [2440/4518] 54% | Training loss: 0.6872266947001707
Epoch: 16 | Iteration number: [2450/4518] 54% | Training loss: 0.6872227776050568
Epoch: 16 | Iteration number: [2460/4518] 54% | Training loss: 0.6872278700514538
Epoch: 16 | Iteration number: [2470/4518] 54% | Training loss: 0.6872273812651152
Epoch: 16 | Iteration number: [2480/4518] 54% | Training loss: 0.6872276220590837
Epoch: 16 | Iteration number: [2490/4518] 55% | Training loss: 0.6872220230389791
Epoch: 16 | Iteration number: [2500/4518] 55% | Training loss: 0.6872206179857254
Epoch: 16 | Iteration number: [2510/4518] 55% | Training loss: 0.6872220442827004
Epoch: 16 | Iteration number: [2520/4518] 55% | Training loss: 0.687219852351007
Epoch: 16 | Iteration number: [2530/4518] 55% | Training loss: 0.68721946920802
Epoch: 16 | Iteration number: [2540/4518] 56% | Training loss: 0.6872178348969287
Epoch: 16 | Iteration number: [2550/4518] 56% | Training loss: 0.6872183304206998
Epoch: 16 | Iteration number: [2560/4518] 56% | Training loss: 0.687216771952808
Epoch: 16 | Iteration number: [2570/4518] 56% | Training loss: 0.6872145146943252
Epoch: 16 | Iteration number: [2580/4518] 57% | Training loss: 0.6872096959934678
Epoch: 16 | Iteration number: [2590/4518] 57% | Training loss: 0.6872062249533458
Epoch: 16 | Iteration number: [2600/4518] 57% | Training loss: 0.6872010266780854
Epoch: 16 | Iteration number: [2610/4518] 57% | Training loss: 0.6872039943819301
Epoch: 16 | Iteration number: [2620/4518] 57% | Training loss: 0.6872045991529945
Epoch: 16 | Iteration number: [2630/4518] 58% | Training loss: 0.6872009355758986
Epoch: 16 | Iteration number: [2640/4518] 58% | Training loss: 0.6871981982931946
Epoch: 16 | Iteration number: [2650/4518] 58% | Training loss: 0.6871988468350104
Epoch: 16 | Iteration number: [2660/4518] 58% | Training loss: 0.6871988013498765
Epoch: 16 | Iteration number: [2670/4518] 59% | Training loss: 0.6871985298417481
Epoch: 16 | Iteration number: [2680/4518] 59% | Training loss: 0.6872003453880994
Epoch: 16 | Iteration number: [2690/4518] 59% | Training loss: 0.68720130787463
Epoch: 16 | Iteration number: [2700/4518] 59% | Training loss: 0.6871993348112813
Epoch: 16 | Iteration number: [2710/4518] 59% | Training loss: 0.6871950478791311
Epoch: 16 | Iteration number: [2720/4518] 60% | Training loss: 0.6871913076761891
Epoch: 16 | Iteration number: [2730/4518] 60% | Training loss: 0.68718980659932
Epoch: 16 | Iteration number: [2740/4518] 60% | Training loss: 0.6871955399748183
Epoch: 16 | Iteration number: [2750/4518] 60% | Training loss: 0.6871914257786491
Epoch: 16 | Iteration number: [2760/4518] 61% | Training loss: 0.687190025396969
Epoch: 16 | Iteration number: [2770/4518] 61% | Training loss: 0.6871897023722583
Epoch: 16 | Iteration number: [2780/4518] 61% | Training loss: 0.6871917467537544
Epoch: 16 | Iteration number: [2790/4518] 61% | Training loss: 0.6871879856859912
Epoch: 16 | Iteration number: [2800/4518] 61% | Training loss: 0.6871839030512742
Epoch: 16 | Iteration number: [2810/4518] 62% | Training loss: 0.6871824676031744
Epoch: 16 | Iteration number: [2820/4518] 62% | Training loss: 0.6871838271829254
Epoch: 16 | Iteration number: [2830/4518] 62% | Training loss: 0.6871808153159206
Epoch: 16 | Iteration number: [2840/4518] 62% | Training loss: 0.6871787476497637
Epoch: 16 | Iteration number: [2850/4518] 63% | Training loss: 0.6871737126718488
Epoch: 16 | Iteration number: [2860/4518] 63% | Training loss: 0.6871767774745301
Epoch: 16 | Iteration number: [2870/4518] 63% | Training loss: 0.6871795745053774
Epoch: 16 | Iteration number: [2880/4518] 63% | Training loss: 0.6871770033612847
Epoch: 16 | Iteration number: [2890/4518] 63% | Training loss: 0.6871785162641928
Epoch: 16 | Iteration number: [2900/4518] 64% | Training loss: 0.6871735545890084
Epoch: 16 | Iteration number: [2910/4518] 64% | Training loss: 0.6871685387342656
Epoch: 16 | Iteration number: [2920/4518] 64% | Training loss: 0.6871640754276759
Epoch: 16 | Iteration number: [2930/4518] 64% | Training loss: 0.6871642611335975
Epoch: 16 | Iteration number: [2940/4518] 65% | Training loss: 0.6871596244322199
Epoch: 16 | Iteration number: [2950/4518] 65% | Training loss: 0.687163112567643
Epoch: 16 | Iteration number: [2960/4518] 65% | Training loss: 0.6871618218518593
Epoch: 16 | Iteration number: [2970/4518] 65% | Training loss: 0.687165418598387
Epoch: 16 | Iteration number: [2980/4518] 65% | Training loss: 0.687160795006976
Epoch: 16 | Iteration number: [2990/4518] 66% | Training loss: 0.6871622839500274
Epoch: 16 | Iteration number: [3000/4518] 66% | Training loss: 0.6871596344908079
Epoch: 16 | Iteration number: [3010/4518] 66% | Training loss: 0.6871591157889445
Epoch: 16 | Iteration number: [3020/4518] 66% | Training loss: 0.6871642942657534
Epoch: 16 | Iteration number: [3030/4518] 67% | Training loss: 0.687161128198353
Epoch: 16 | Iteration number: [3040/4518] 67% | Training loss: 0.6871588189743068
Epoch: 16 | Iteration number: [3050/4518] 67% | Training loss: 0.6871581334950494
Epoch: 16 | Iteration number: [3060/4518] 67% | Training loss: 0.6871583400208966
Epoch: 16 | Iteration number: [3070/4518] 67% | Training loss: 0.687156945544656
Epoch: 16 | Iteration number: [3080/4518] 68% | Training loss: 0.6871548256316742
Epoch: 16 | Iteration number: [3090/4518] 68% | Training loss: 0.6871501093929254
Epoch: 16 | Iteration number: [3100/4518] 68% | Training loss: 0.6871505486003814
Epoch: 16 | Iteration number: [3110/4518] 68% | Training loss: 0.6871498597779842
Epoch: 16 | Iteration number: [3120/4518] 69% | Training loss: 0.6871491581965715
Epoch: 16 | Iteration number: [3130/4518] 69% | Training loss: 0.6871441966618974
Epoch: 16 | Iteration number: [3140/4518] 69% | Training loss: 0.6871439472125594
Epoch: 16 | Iteration number: [3150/4518] 69% | Training loss: 0.6871449131246598
Epoch: 16 | Iteration number: [3160/4518] 69% | Training loss: 0.6871478136958955
Epoch: 16 | Iteration number: [3170/4518] 70% | Training loss: 0.6871485506510508
Epoch: 16 | Iteration number: [3180/4518] 70% | Training loss: 0.6871482151859212
Epoch: 16 | Iteration number: [3190/4518] 70% | Training loss: 0.687150370196489
Epoch: 16 | Iteration number: [3200/4518] 70% | Training loss: 0.687151152100414
Epoch: 16 | Iteration number: [3210/4518] 71% | Training loss: 0.6871501621984618
Epoch: 16 | Iteration number: [3220/4518] 71% | Training loss: 0.6871495202276278
Epoch: 16 | Iteration number: [3230/4518] 71% | Training loss: 0.6871500801375776
Epoch: 16 | Iteration number: [3240/4518] 71% | Training loss: 0.68714811415584
Epoch: 16 | Iteration number: [3250/4518] 71% | Training loss: 0.6871461128638341
Epoch: 16 | Iteration number: [3260/4518] 72% | Training loss: 0.6871505297400469
Epoch: 16 | Iteration number: [3270/4518] 72% | Training loss: 0.6871486516538381
Epoch: 16 | Iteration number: [3280/4518] 72% | Training loss: 0.6871474468308251
Epoch: 16 | Iteration number: [3290/4518] 72% | Training loss: 0.6871484505550477
Epoch: 16 | Iteration number: [3300/4518] 73% | Training loss: 0.6871456644751809
Epoch: 16 | Iteration number: [3310/4518] 73% | Training loss: 0.6871467504976739
Epoch: 16 | Iteration number: [3320/4518] 73% | Training loss: 0.687146169826927
Epoch: 16 | Iteration number: [3330/4518] 73% | Training loss: 0.6871454863039939
Epoch: 16 | Iteration number: [3340/4518] 73% | Training loss: 0.6871408295845557
Epoch: 16 | Iteration number: [3350/4518] 74% | Training loss: 0.687139548757183
Epoch: 16 | Iteration number: [3360/4518] 74% | Training loss: 0.6871382152040799
Epoch: 16 | Iteration number: [3370/4518] 74% | Training loss: 0.6871364362162016
Epoch: 16 | Iteration number: [3380/4518] 74% | Training loss: 0.6871352462020851
Epoch: 16 | Iteration number: [3390/4518] 75% | Training loss: 0.6871322116844774
Epoch: 16 | Iteration number: [3400/4518] 75% | Training loss: 0.6871314937752836
Epoch: 16 | Iteration number: [3410/4518] 75% | Training loss: 0.6871315335073779
Epoch: 16 | Iteration number: [3420/4518] 75% | Training loss: 0.6871335409363808
Epoch: 16 | Iteration number: [3430/4518] 75% | Training loss: 0.687130811228349
Epoch: 16 | Iteration number: [3440/4518] 76% | Training loss: 0.6871285662055016
Epoch: 16 | Iteration number: [3450/4518] 76% | Training loss: 0.6871264060683873
Epoch: 16 | Iteration number: [3460/4518] 76% | Training loss: 0.6871269748217798
Epoch: 16 | Iteration number: [3470/4518] 76% | Training loss: 0.6871225374404566
Epoch: 16 | Iteration number: [3480/4518] 77% | Training loss: 0.6871223606083585
Epoch: 16 | Iteration number: [3490/4518] 77% | Training loss: 0.6871217627750769
Epoch: 16 | Iteration number: [3500/4518] 77% | Training loss: 0.6871227200712476
Epoch: 16 | Iteration number: [3510/4518] 77% | Training loss: 0.6871201290703907
Epoch: 16 | Iteration number: [3520/4518] 77% | Training loss: 0.6871192558414557
Epoch: 16 | Iteration number: [3530/4518] 78% | Training loss: 0.6871173227643832
Epoch: 16 | Iteration number: [3540/4518] 78% | Training loss: 0.6871158759977858
Epoch: 16 | Iteration number: [3550/4518] 78% | Training loss: 0.6871169137618911
Epoch: 16 | Iteration number: [3560/4518] 78% | Training loss: 0.6871186980705583
Epoch: 16 | Iteration number: [3570/4518] 79% | Training loss: 0.6871169947609514
Epoch: 16 | Iteration number: [3580/4518] 79% | Training loss: 0.6871149237428964
Epoch: 16 | Iteration number: [3590/4518] 79% | Training loss: 0.6871178475927178
Epoch: 16 | Iteration number: [3600/4518] 79% | Training loss: 0.6871141568322976
Epoch: 16 | Iteration number: [3610/4518] 79% | Training loss: 0.6871144057641069
Epoch: 16 | Iteration number: [3620/4518] 80% | Training loss: 0.6871105099251257
Epoch: 16 | Iteration number: [3630/4518] 80% | Training loss: 0.6871109859181501
Epoch: 16 | Iteration number: [3640/4518] 80% | Training loss: 0.6871108016961224
Epoch: 16 | Iteration number: [3650/4518] 80% | Training loss: 0.6871113492038152
Epoch: 16 | Iteration number: [3660/4518] 81% | Training loss: 0.68711262633566
Epoch: 16 | Iteration number: [3670/4518] 81% | Training loss: 0.687112194705724
Epoch: 16 | Iteration number: [3680/4518] 81% | Training loss: 0.6871101790796156
Epoch: 16 | Iteration number: [3690/4518] 81% | Training loss: 0.6871138376110615
Epoch: 16 | Iteration number: [3700/4518] 81% | Training loss: 0.6871164189158259
Epoch: 16 | Iteration number: [3710/4518] 82% | Training loss: 0.6871154126452629
Epoch: 16 | Iteration number: [3720/4518] 82% | Training loss: 0.6871129011595121
Epoch: 16 | Iteration number: [3730/4518] 82% | Training loss: 0.6871148862244296
Epoch: 16 | Iteration number: [3740/4518] 82% | Training loss: 0.6871175309553503
Epoch: 16 | Iteration number: [3750/4518] 83% | Training loss: 0.6871161522388458
Epoch: 16 | Iteration number: [3760/4518] 83% | Training loss: 0.6871143698216753
Epoch: 16 | Iteration number: [3770/4518] 83% | Training loss: 0.6871168310035128
Epoch: 16 | Iteration number: [3780/4518] 83% | Training loss: 0.6871160043610467
Epoch: 16 | Iteration number: [3790/4518] 83% | Training loss: 0.6871173547408826
Epoch: 16 | Iteration number: [3800/4518] 84% | Training loss: 0.6871187519713452
Epoch: 16 | Iteration number: [3810/4518] 84% | Training loss: 0.6871161134537124
Epoch: 16 | Iteration number: [3820/4518] 84% | Training loss: 0.6871150241472335
Epoch: 16 | Iteration number: [3830/4518] 84% | Training loss: 0.6871172070970112
Epoch: 16 | Iteration number: [3840/4518] 84% | Training loss: 0.6871210072965671
Epoch: 16 | Iteration number: [3850/4518] 85% | Training loss: 0.6871155523479759
Epoch: 16 | Iteration number: [3860/4518] 85% | Training loss: 0.6871136799995146
Epoch: 16 | Iteration number: [3870/4518] 85% | Training loss: 0.6871122969059366
Epoch: 16 | Iteration number: [3880/4518] 85% | Training loss: 0.6871131039925458
Epoch: 16 | Iteration number: [3890/4518] 86% | Training loss: 0.687115357360374
Epoch: 16 | Iteration number: [3900/4518] 86% | Training loss: 0.6871146043905845
Epoch: 16 | Iteration number: [3910/4518] 86% | Training loss: 0.6871146544166233
Epoch: 16 | Iteration number: [3920/4518] 86% | Training loss: 0.687110792526177
Epoch: 16 | Iteration number: [3930/4518] 86% | Training loss: 0.687111290750916
Epoch: 16 | Iteration number: [3940/4518] 87% | Training loss: 0.6871110443233839
Epoch: 16 | Iteration number: [3950/4518] 87% | Training loss: 0.6871093832692013
Epoch: 16 | Iteration number: [3960/4518] 87% | Training loss: 0.6871114404063032
Epoch: 16 | Iteration number: [3970/4518] 87% | Training loss: 0.6871094721991109
Epoch: 16 | Iteration number: [3980/4518] 88% | Training loss: 0.6871082206467288
Epoch: 16 | Iteration number: [3990/4518] 88% | Training loss: 0.6871077168854257
Epoch: 16 | Iteration number: [4000/4518] 88% | Training loss: 0.6871074630916119
Epoch: 16 | Iteration number: [4010/4518] 88% | Training loss: 0.6871032019357134
Epoch: 16 | Iteration number: [4020/4518] 88% | Training loss: 0.6871017341738317
Epoch: 16 | Iteration number: [4030/4518] 89% | Training loss: 0.6870999559131509
Epoch: 16 | Iteration number: [4040/4518] 89% | Training loss: 0.6870978321474377
Epoch: 16 | Iteration number: [4050/4518] 89% | Training loss: 0.6871002727526205
Epoch: 16 | Iteration number: [4060/4518] 89% | Training loss: 0.6870997425370615
Epoch: 16 | Iteration number: [4070/4518] 90% | Training loss: 0.6870993037920912
Epoch: 16 | Iteration number: [4080/4518] 90% | Training loss: 0.6870993464308627
Epoch: 16 | Iteration number: [4090/4518] 90% | Training loss: 0.687097307274569
Epoch: 16 | Iteration number: [4100/4518] 90% | Training loss: 0.6870949386096582
Epoch: 16 | Iteration number: [4110/4518] 90% | Training loss: 0.6870946596138668
Epoch: 16 | Iteration number: [4120/4518] 91% | Training loss: 0.6870922548099629
Epoch: 16 | Iteration number: [4130/4518] 91% | Training loss: 0.6870925542517378
Epoch: 16 | Iteration number: [4140/4518] 91% | Training loss: 0.6870913233733983
Epoch: 16 | Iteration number: [4150/4518] 91% | Training loss: 0.6870891965440957
Epoch: 16 | Iteration number: [4160/4518] 92% | Training loss: 0.6870855524419592
Epoch: 16 | Iteration number: [4170/4518] 92% | Training loss: 0.687086373839161
Epoch: 16 | Iteration number: [4180/4518] 92% | Training loss: 0.6870864171160466
Epoch: 16 | Iteration number: [4190/4518] 92% | Training loss: 0.6870851435638555
Epoch: 16 | Iteration number: [4200/4518] 92% | Training loss: 0.6870829689928464
Epoch: 16 | Iteration number: [4210/4518] 93% | Training loss: 0.6870828391961984
Epoch: 16 | Iteration number: [4220/4518] 93% | Training loss: 0.6870849066718495
Epoch: 16 | Iteration number: [4230/4518] 93% | Training loss: 0.6870848930332959
Epoch: 16 | Iteration number: [4240/4518] 93% | Training loss: 0.6870859301736895
Epoch: 16 | Iteration number: [4250/4518] 94% | Training loss: 0.6870881032102248
Epoch: 16 | Iteration number: [4260/4518] 94% | Training loss: 0.6870863839634148
Epoch: 16 | Iteration number: [4270/4518] 94% | Training loss: 0.6870843635928715
Epoch: 16 | Iteration number: [4280/4518] 94% | Training loss: 0.6870834529399872
Epoch: 16 | Iteration number: [4290/4518] 94% | Training loss: 0.6870840171695033
Epoch: 16 | Iteration number: [4300/4518] 95% | Training loss: 0.6870836452689282
Epoch: 16 | Iteration number: [4310/4518] 95% | Training loss: 0.6870856600405169
Epoch: 16 | Iteration number: [4320/4518] 95% | Training loss: 0.6870864701767763
Epoch: 16 | Iteration number: [4330/4518] 95% | Training loss: 0.6870833770645133
Epoch: 16 | Iteration number: [4340/4518] 96% | Training loss: 0.6870834533794684
Epoch: 16 | Iteration number: [4350/4518] 96% | Training loss: 0.6870844932534229
Epoch: 16 | Iteration number: [4360/4518] 96% | Training loss: 0.6870831845003531
Epoch: 16 | Iteration number: [4370/4518] 96% | Training loss: 0.6870835889940676
Epoch: 16 | Iteration number: [4380/4518] 96% | Training loss: 0.6870777008468157
Epoch: 16 | Iteration number: [4390/4518] 97% | Training loss: 0.687074752250402
Epoch: 16 | Iteration number: [4400/4518] 97% | Training loss: 0.6870727894522927
Epoch: 16 | Iteration number: [4410/4518] 97% | Training loss: 0.6870707048715647
Epoch: 16 | Iteration number: [4420/4518] 97% | Training loss: 0.6870728611811254
Epoch: 16 | Iteration number: [4430/4518] 98% | Training loss: 0.6870718772066904
Epoch: 16 | Iteration number: [4440/4518] 98% | Training loss: 0.6870702603781546
Epoch: 16 | Iteration number: [4450/4518] 98% | Training loss: 0.687068421010221
Epoch: 16 | Iteration number: [4460/4518] 98% | Training loss: 0.687066721234621
Epoch: 16 | Iteration number: [4470/4518] 98% | Training loss: 0.6870647565097083
Epoch: 16 | Iteration number: [4480/4518] 99% | Training loss: 0.6870652806146869
Epoch: 16 | Iteration number: [4490/4518] 99% | Training loss: 0.6870665417614917
Epoch: 16 | Iteration number: [4500/4518] 99% | Training loss: 0.6870642056862514
Epoch: 16 | Iteration number: [4510/4518] 99% | Training loss: 0.6870650919868783

 End of epoch: 16 | Train Loss: 0.6869106824654507 | Training Time: 632 

 End of epoch: 16 | Eval Loss: 0.6900210319733133 | Evaluating Time: 17 
Epoch: 17 | Iteration number: [10/4518] 0% | Training loss: 0.7544492781162262
Epoch: 17 | Iteration number: [20/4518] 0% | Training loss: 0.720507675409317
Epoch: 17 | Iteration number: [30/4518] 0% | Training loss: 0.7091999888420105
Epoch: 17 | Iteration number: [40/4518] 0% | Training loss: 0.7036467954516411
Epoch: 17 | Iteration number: [50/4518] 1% | Training loss: 0.7003385090827942
Epoch: 17 | Iteration number: [60/4518] 1% | Training loss: 0.6979499826828639
Epoch: 17 | Iteration number: [70/4518] 1% | Training loss: 0.6963443730558668
Epoch: 17 | Iteration number: [80/4518] 1% | Training loss: 0.694905760884285
Epoch: 17 | Iteration number: [90/4518] 1% | Training loss: 0.6941380739212036
Epoch: 17 | Iteration number: [100/4518] 2% | Training loss: 0.6933527511358261
Epoch: 17 | Iteration number: [110/4518] 2% | Training loss: 0.6928630086508665
Epoch: 17 | Iteration number: [120/4518] 2% | Training loss: 0.6924499397476515
Epoch: 17 | Iteration number: [130/4518] 2% | Training loss: 0.6920226463904747
Epoch: 17 | Iteration number: [140/4518] 3% | Training loss: 0.6917875017438616
Epoch: 17 | Iteration number: [150/4518] 3% | Training loss: 0.6915714470545451
Epoch: 17 | Iteration number: [160/4518] 3% | Training loss: 0.6912586435675621
Epoch: 17 | Iteration number: [170/4518] 3% | Training loss: 0.6910409899318919
Epoch: 17 | Iteration number: [180/4518] 3% | Training loss: 0.6908635348081589
Epoch: 17 | Iteration number: [190/4518] 4% | Training loss: 0.69066794765623
Epoch: 17 | Iteration number: [200/4518] 4% | Training loss: 0.6904839611053467
Epoch: 17 | Iteration number: [210/4518] 4% | Training loss: 0.6903497630641574
Epoch: 17 | Iteration number: [220/4518] 4% | Training loss: 0.690133229710839
Epoch: 17 | Iteration number: [230/4518] 5% | Training loss: 0.6899645289649134
Epoch: 17 | Iteration number: [240/4518] 5% | Training loss: 0.6898262063662212
Epoch: 17 | Iteration number: [250/4518] 5% | Training loss: 0.6897019934654236
Epoch: 17 | Iteration number: [260/4518] 5% | Training loss: 0.6895837857173039
Epoch: 17 | Iteration number: [270/4518] 5% | Training loss: 0.689501596600921
Epoch: 17 | Iteration number: [280/4518] 6% | Training loss: 0.6894303990261895
Epoch: 17 | Iteration number: [290/4518] 6% | Training loss: 0.6893213611224602
Epoch: 17 | Iteration number: [300/4518] 6% | Training loss: 0.6892684531211853
Epoch: 17 | Iteration number: [310/4518] 6% | Training loss: 0.6892435535307854
Epoch: 17 | Iteration number: [320/4518] 7% | Training loss: 0.6891762407496571
Epoch: 17 | Iteration number: [330/4518] 7% | Training loss: 0.6891269040830208
Epoch: 17 | Iteration number: [340/4518] 7% | Training loss: 0.6890274743823445
Epoch: 17 | Iteration number: [350/4518] 7% | Training loss: 0.6889613044261932
Epoch: 17 | Iteration number: [360/4518] 7% | Training loss: 0.6889516346984439
Epoch: 17 | Iteration number: [370/4518] 8% | Training loss: 0.688886958360672
Epoch: 17 | Iteration number: [380/4518] 8% | Training loss: 0.688811151448049
Epoch: 17 | Iteration number: [390/4518] 8% | Training loss: 0.6887668817471235
Epoch: 17 | Iteration number: [400/4518] 8% | Training loss: 0.6886803835630417
Epoch: 17 | Iteration number: [410/4518] 9% | Training loss: 0.6886340309933918
Epoch: 17 | Iteration number: [420/4518] 9% | Training loss: 0.6885910882836297
Epoch: 17 | Iteration number: [430/4518] 9% | Training loss: 0.6885692123756852
Epoch: 17 | Iteration number: [440/4518] 9% | Training loss: 0.6885287020694125
Epoch: 17 | Iteration number: [450/4518] 9% | Training loss: 0.6884719332059225
Epoch: 17 | Iteration number: [460/4518] 10% | Training loss: 0.6884376527174659
Epoch: 17 | Iteration number: [470/4518] 10% | Training loss: 0.6884165607868357
Epoch: 17 | Iteration number: [480/4518] 10% | Training loss: 0.6883980506410201
Epoch: 17 | Iteration number: [490/4518] 10% | Training loss: 0.6883510644338569
Epoch: 17 | Iteration number: [500/4518] 11% | Training loss: 0.6883145887851715
Epoch: 17 | Iteration number: [510/4518] 11% | Training loss: 0.688316997126037
Epoch: 17 | Iteration number: [520/4518] 11% | Training loss: 0.6882781848311424
Epoch: 17 | Iteration number: [530/4518] 11% | Training loss: 0.6882613703889667
Epoch: 17 | Iteration number: [540/4518] 11% | Training loss: 0.6882393822625831
Epoch: 17 | Iteration number: [550/4518] 12% | Training loss: 0.6882213933901353
Epoch: 17 | Iteration number: [560/4518] 12% | Training loss: 0.6881854111594813
Epoch: 17 | Iteration number: [570/4518] 12% | Training loss: 0.6881693877671894
Epoch: 17 | Iteration number: [580/4518] 12% | Training loss: 0.6881304316479584
Epoch: 17 | Iteration number: [590/4518] 13% | Training loss: 0.6881167841159691
Epoch: 17 | Iteration number: [600/4518] 13% | Training loss: 0.6881037676334381
Epoch: 17 | Iteration number: [610/4518] 13% | Training loss: 0.6880698310547188
Epoch: 17 | Iteration number: [620/4518] 13% | Training loss: 0.6880535891940517
Epoch: 17 | Iteration number: [630/4518] 13% | Training loss: 0.6880338146573022
Epoch: 17 | Iteration number: [640/4518] 14% | Training loss: 0.6880352973937989
Epoch: 17 | Iteration number: [650/4518] 14% | Training loss: 0.6880190419233763
Epoch: 17 | Iteration number: [660/4518] 14% | Training loss: 0.6879951563748447
Epoch: 17 | Iteration number: [670/4518] 14% | Training loss: 0.687982958822108
Epoch: 17 | Iteration number: [680/4518] 15% | Training loss: 0.6879635028979357
Epoch: 17 | Iteration number: [690/4518] 15% | Training loss: 0.6879482235597527
Epoch: 17 | Iteration number: [700/4518] 15% | Training loss: 0.6879231843778065
Epoch: 17 | Iteration number: [710/4518] 15% | Training loss: 0.6879190224157252
Epoch: 17 | Iteration number: [720/4518] 15% | Training loss: 0.6878958837853537
Epoch: 17 | Iteration number: [730/4518] 16% | Training loss: 0.6878839802252104
Epoch: 17 | Iteration number: [740/4518] 16% | Training loss: 0.6878410895128508
Epoch: 17 | Iteration number: [750/4518] 16% | Training loss: 0.6878336806297303
Epoch: 17 | Iteration number: [760/4518] 16% | Training loss: 0.6878128498008377
Epoch: 17 | Iteration number: [770/4518] 17% | Training loss: 0.6878120882944627
Epoch: 17 | Iteration number: [780/4518] 17% | Training loss: 0.6878026703229317
Epoch: 17 | Iteration number: [790/4518] 17% | Training loss: 0.6877984793880317
Epoch: 17 | Iteration number: [800/4518] 17% | Training loss: 0.6878036586940288
Epoch: 17 | Iteration number: [810/4518] 17% | Training loss: 0.6877960011546994
Epoch: 17 | Iteration number: [820/4518] 18% | Training loss: 0.6877764040377082
Epoch: 17 | Iteration number: [830/4518] 18% | Training loss: 0.6877662214888147
Epoch: 17 | Iteration number: [840/4518] 18% | Training loss: 0.6877524018287658
Epoch: 17 | Iteration number: [850/4518] 18% | Training loss: 0.6877252114520354
Epoch: 17 | Iteration number: [860/4518] 19% | Training loss: 0.6877140941314919
Epoch: 17 | Iteration number: [870/4518] 19% | Training loss: 0.6877200091707295
Epoch: 17 | Iteration number: [880/4518] 19% | Training loss: 0.6877076935361732
Epoch: 17 | Iteration number: [890/4518] 19% | Training loss: 0.6876959638649158
Epoch: 17 | Iteration number: [900/4518] 19% | Training loss: 0.6876976101928287
Epoch: 17 | Iteration number: [910/4518] 20% | Training loss: 0.687668732889406
Epoch: 17 | Iteration number: [920/4518] 20% | Training loss: 0.6876728112930837
Epoch: 17 | Iteration number: [930/4518] 20% | Training loss: 0.6876676847216904
Epoch: 17 | Iteration number: [940/4518] 20% | Training loss: 0.6876655299612816
Epoch: 17 | Iteration number: [950/4518] 21% | Training loss: 0.6876652624105153
Epoch: 17 | Iteration number: [960/4518] 21% | Training loss: 0.6876556257406871
Epoch: 17 | Iteration number: [970/4518] 21% | Training loss: 0.6876538648433292
Epoch: 17 | Iteration number: [980/4518] 21% | Training loss: 0.6876475236853775
Epoch: 17 | Iteration number: [990/4518] 21% | Training loss: 0.687642633613914
Epoch: 17 | Iteration number: [1000/4518] 22% | Training loss: 0.6876266099810601
Epoch: 17 | Iteration number: [1010/4518] 22% | Training loss: 0.6876320687260958
Epoch: 17 | Iteration number: [1020/4518] 22% | Training loss: 0.6876274974322787
Epoch: 17 | Iteration number: [1030/4518] 22% | Training loss: 0.6876161442798319
Epoch: 17 | Iteration number: [1040/4518] 23% | Training loss: 0.687605622697335
Epoch: 17 | Iteration number: [1050/4518] 23% | Training loss: 0.6875941707406725
Epoch: 17 | Iteration number: [1060/4518] 23% | Training loss: 0.6875914077151496
Epoch: 17 | Iteration number: [1070/4518] 23% | Training loss: 0.6875902505121498
Epoch: 17 | Iteration number: [1080/4518] 23% | Training loss: 0.6875829323022454
Epoch: 17 | Iteration number: [1090/4518] 24% | Training loss: 0.6875790175494798
Epoch: 17 | Iteration number: [1100/4518] 24% | Training loss: 0.6875637677040967
Epoch: 17 | Iteration number: [1110/4518] 24% | Training loss: 0.6875563872290087
Epoch: 17 | Iteration number: [1120/4518] 24% | Training loss: 0.6875410706869194
Epoch: 17 | Iteration number: [1130/4518] 25% | Training loss: 0.6875489862091774
Epoch: 17 | Iteration number: [1140/4518] 25% | Training loss: 0.6875420216405601
Epoch: 17 | Iteration number: [1150/4518] 25% | Training loss: 0.6875462982447251
Epoch: 17 | Iteration number: [1160/4518] 25% | Training loss: 0.6875382176760969
Epoch: 17 | Iteration number: [1170/4518] 25% | Training loss: 0.6875332761014629
Epoch: 17 | Iteration number: [1180/4518] 26% | Training loss: 0.6875346025167886
Epoch: 17 | Iteration number: [1190/4518] 26% | Training loss: 0.6875218231137059
Epoch: 17 | Iteration number: [1200/4518] 26% | Training loss: 0.6875181750456492
Epoch: 17 | Iteration number: [1210/4518] 26% | Training loss: 0.6875076807234898
Epoch: 17 | Iteration number: [1220/4518] 27% | Training loss: 0.6875099321369265
Epoch: 17 | Iteration number: [1230/4518] 27% | Training loss: 0.6875104952149275
Epoch: 17 | Iteration number: [1240/4518] 27% | Training loss: 0.6875042546660669
Epoch: 17 | Iteration number: [1250/4518] 27% | Training loss: 0.6874990308761597
Epoch: 17 | Iteration number: [1260/4518] 27% | Training loss: 0.6874945503378671
Epoch: 17 | Iteration number: [1270/4518] 28% | Training loss: 0.6874889179477541
Epoch: 17 | Iteration number: [1280/4518] 28% | Training loss: 0.6874955473933368
Epoch: 17 | Iteration number: [1290/4518] 28% | Training loss: 0.6874887547289679
Epoch: 17 | Iteration number: [1300/4518] 28% | Training loss: 0.6874792975187302
Epoch: 17 | Iteration number: [1310/4518] 28% | Training loss: 0.6874802779150373
Epoch: 17 | Iteration number: [1320/4518] 29% | Training loss: 0.6874793836113179
Epoch: 17 | Iteration number: [1330/4518] 29% | Training loss: 0.6874803377721542
Epoch: 17 | Iteration number: [1340/4518] 29% | Training loss: 0.6874779707905072
Epoch: 17 | Iteration number: [1350/4518] 29% | Training loss: 0.6874698097176022
Epoch: 17 | Iteration number: [1360/4518] 30% | Training loss: 0.6874643377083189
Epoch: 17 | Iteration number: [1370/4518] 30% | Training loss: 0.6874532105278794
Epoch: 17 | Iteration number: [1380/4518] 30% | Training loss: 0.6874519323525221
Epoch: 17 | Iteration number: [1390/4518] 30% | Training loss: 0.6874454737138405
Epoch: 17 | Iteration number: [1400/4518] 30% | Training loss: 0.6874502781459263
Epoch: 17 | Iteration number: [1410/4518] 31% | Training loss: 0.6874425485624489
Epoch: 17 | Iteration number: [1420/4518] 31% | Training loss: 0.6874444498562478
Epoch: 17 | Iteration number: [1430/4518] 31% | Training loss: 0.6874427338163336
Epoch: 17 | Iteration number: [1440/4518] 31% | Training loss: 0.6874377299514082
Epoch: 17 | Iteration number: [1450/4518] 32% | Training loss: 0.6874380864768193
Epoch: 17 | Iteration number: [1460/4518] 32% | Training loss: 0.6874259647849488
Epoch: 17 | Iteration number: [1470/4518] 32% | Training loss: 0.6874233817162156
Epoch: 17 | Iteration number: [1480/4518] 32% | Training loss: 0.687422490401848
Epoch: 17 | Iteration number: [1490/4518] 32% | Training loss: 0.6874143422850026
Epoch: 17 | Iteration number: [1500/4518] 33% | Training loss: 0.6874211088021597
Epoch: 17 | Iteration number: [1510/4518] 33% | Training loss: 0.6874257680201372
Epoch: 17 | Iteration number: [1520/4518] 33% | Training loss: 0.6874193644445193
Epoch: 17 | Iteration number: [1530/4518] 33% | Training loss: 0.6874044906859305
Epoch: 17 | Iteration number: [1540/4518] 34% | Training loss: 0.6873929676297423
Epoch: 17 | Iteration number: [1550/4518] 34% | Training loss: 0.6873876855834838
Epoch: 17 | Iteration number: [1560/4518] 34% | Training loss: 0.6873772112222818
Epoch: 17 | Iteration number: [1570/4518] 34% | Training loss: 0.6873733087330107
Epoch: 17 | Iteration number: [1580/4518] 34% | Training loss: 0.6873708519000041
Epoch: 17 | Iteration number: [1590/4518] 35% | Training loss: 0.6873737913632543
Epoch: 17 | Iteration number: [1600/4518] 35% | Training loss: 0.6873733578249812
Epoch: 17 | Iteration number: [1610/4518] 35% | Training loss: 0.6873550190688661
Epoch: 17 | Iteration number: [1620/4518] 35% | Training loss: 0.6873582613320999
Epoch: 17 | Iteration number: [1630/4518] 36% | Training loss: 0.6873564276227191
Epoch: 17 | Iteration number: [1640/4518] 36% | Training loss: 0.6873573962144736
Epoch: 17 | Iteration number: [1650/4518] 36% | Training loss: 0.6873546219594551
Epoch: 17 | Iteration number: [1660/4518] 36% | Training loss: 0.6873412418078227
Epoch: 17 | Iteration number: [1670/4518] 36% | Training loss: 0.6873372122199236
Epoch: 17 | Iteration number: [1680/4518] 37% | Training loss: 0.6873289248418241
Epoch: 17 | Iteration number: [1690/4518] 37% | Training loss: 0.6873339488308811
Epoch: 17 | Iteration number: [1700/4518] 37% | Training loss: 0.6873344212770462
Epoch: 17 | Iteration number: [1710/4518] 37% | Training loss: 0.6873309779236888
Epoch: 17 | Iteration number: [1720/4518] 38% | Training loss: 0.6873282963106798
Epoch: 17 | Iteration number: [1730/4518] 38% | Training loss: 0.6873222576055913
Epoch: 17 | Iteration number: [1740/4518] 38% | Training loss: 0.6873192206538957
Epoch: 17 | Iteration number: [1750/4518] 38% | Training loss: 0.6873121084485735
Epoch: 17 | Iteration number: [1760/4518] 38% | Training loss: 0.6873071667484262
Epoch: 17 | Iteration number: [1770/4518] 39% | Training loss: 0.6873060379998158
Epoch: 17 | Iteration number: [1780/4518] 39% | Training loss: 0.6873044727893358
Epoch: 17 | Iteration number: [1790/4518] 39% | Training loss: 0.6872981950890419
Epoch: 17 | Iteration number: [1800/4518] 39% | Training loss: 0.6872961414853732
Epoch: 17 | Iteration number: [1810/4518] 40% | Training loss: 0.6873009732415004
Epoch: 17 | Iteration number: [1820/4518] 40% | Training loss: 0.687298612673204
Epoch: 17 | Iteration number: [1830/4518] 40% | Training loss: 0.6872948789205707
Epoch: 17 | Iteration number: [1840/4518] 40% | Training loss: 0.6872881788598455
Epoch: 17 | Iteration number: [1850/4518] 40% | Training loss: 0.6872920022139678
Epoch: 17 | Iteration number: [1860/4518] 41% | Training loss: 0.6872879750626062
Epoch: 17 | Iteration number: [1870/4518] 41% | Training loss: 0.6872762199072915
Epoch: 17 | Iteration number: [1880/4518] 41% | Training loss: 0.6872698925911112
Epoch: 17 | Iteration number: [1890/4518] 41% | Training loss: 0.6872699777915995
Epoch: 17 | Iteration number: [1900/4518] 42% | Training loss: 0.6872702768601869
Epoch: 17 | Iteration number: [1910/4518] 42% | Training loss: 0.6872722369838136
Epoch: 17 | Iteration number: [1920/4518] 42% | Training loss: 0.6872704423032701
Epoch: 17 | Iteration number: [1930/4518] 42% | Training loss: 0.6872674516136782
Epoch: 17 | Iteration number: [1940/4518] 42% | Training loss: 0.6872667515707999
Epoch: 17 | Iteration number: [1950/4518] 43% | Training loss: 0.6872663469192309
Epoch: 17 | Iteration number: [1960/4518] 43% | Training loss: 0.6872637109184752
Epoch: 17 | Iteration number: [1970/4518] 43% | Training loss: 0.6872621292692755
Epoch: 17 | Iteration number: [1980/4518] 43% | Training loss: 0.6872611386005325
Epoch: 17 | Iteration number: [1990/4518] 44% | Training loss: 0.6872536178210273
Epoch: 17 | Iteration number: [2000/4518] 44% | Training loss: 0.6872540512681007
Epoch: 17 | Iteration number: [2010/4518] 44% | Training loss: 0.6872632534053195
Epoch: 17 | Iteration number: [2020/4518] 44% | Training loss: 0.6872576018371205
Epoch: 17 | Iteration number: [2030/4518] 44% | Training loss: 0.6872542874272821
Epoch: 17 | Iteration number: [2040/4518] 45% | Training loss: 0.6872554672407168
Epoch: 17 | Iteration number: [2050/4518] 45% | Training loss: 0.6872502155420257
Epoch: 17 | Iteration number: [2060/4518] 45% | Training loss: 0.6872550593128482
Epoch: 17 | Iteration number: [2070/4518] 45% | Training loss: 0.687258230459287
Epoch: 17 | Iteration number: [2080/4518] 46% | Training loss: 0.6872530567244841
Epoch: 17 | Iteration number: [2090/4518] 46% | Training loss: 0.6872500521714607
Epoch: 17 | Iteration number: [2100/4518] 46% | Training loss: 0.6872504918632053
Epoch: 17 | Iteration number: [2110/4518] 46% | Training loss: 0.6872490234567091
Epoch: 17 | Iteration number: [2120/4518] 46% | Training loss: 0.6872442905070647
Epoch: 17 | Iteration number: [2130/4518] 47% | Training loss: 0.6872443890627561
Epoch: 17 | Iteration number: [2140/4518] 47% | Training loss: 0.6872427984932873
Epoch: 17 | Iteration number: [2150/4518] 47% | Training loss: 0.6872349652024202
Epoch: 17 | Iteration number: [2160/4518] 47% | Training loss: 0.687236959680363
Epoch: 17 | Iteration number: [2170/4518] 48% | Training loss: 0.6872369973340892
Epoch: 17 | Iteration number: [2180/4518] 48% | Training loss: 0.6872294857961322
Epoch: 17 | Iteration number: [2190/4518] 48% | Training loss: 0.6872273175411573
Epoch: 17 | Iteration number: [2200/4518] 48% | Training loss: 0.6872312174331058
Epoch: 17 | Iteration number: [2210/4518] 48% | Training loss: 0.6872327818859756
Epoch: 17 | Iteration number: [2220/4518] 49% | Training loss: 0.6872303062999571
Epoch: 17 | Iteration number: [2230/4518] 49% | Training loss: 0.6872285298702429
Epoch: 17 | Iteration number: [2240/4518] 49% | Training loss: 0.6872284202171224
Epoch: 17 | Iteration number: [2250/4518] 49% | Training loss: 0.6872271003193325
Epoch: 17 | Iteration number: [2260/4518] 50% | Training loss: 0.6872290657684866
Epoch: 17 | Iteration number: [2270/4518] 50% | Training loss: 0.687222875004823
Epoch: 17 | Iteration number: [2280/4518] 50% | Training loss: 0.6872192664627443
Epoch: 17 | Iteration number: [2290/4518] 50% | Training loss: 0.687220994588069
Epoch: 17 | Iteration number: [2300/4518] 50% | Training loss: 0.6872196354814197
Epoch: 17 | Iteration number: [2310/4518] 51% | Training loss: 0.6872166719529536
Epoch: 17 | Iteration number: [2320/4518] 51% | Training loss: 0.6872177147916678
Epoch: 17 | Iteration number: [2330/4518] 51% | Training loss: 0.6872198140928162
Epoch: 17 | Iteration number: [2340/4518] 51% | Training loss: 0.6872180099415983
Epoch: 17 | Iteration number: [2350/4518] 52% | Training loss: 0.687217081227201
Epoch: 17 | Iteration number: [2360/4518] 52% | Training loss: 0.6872155130162078
Epoch: 17 | Iteration number: [2370/4518] 52% | Training loss: 0.6872121381105752
Epoch: 17 | Iteration number: [2380/4518] 52% | Training loss: 0.687215691654622
Epoch: 17 | Iteration number: [2390/4518] 52% | Training loss: 0.6872159759120462
Epoch: 17 | Iteration number: [2400/4518] 53% | Training loss: 0.6872161774833997
Epoch: 17 | Iteration number: [2410/4518] 53% | Training loss: 0.6872156597024672
Epoch: 17 | Iteration number: [2420/4518] 53% | Training loss: 0.6872131092735558
Epoch: 17 | Iteration number: [2430/4518] 53% | Training loss: 0.6872081053109816
Epoch: 17 | Iteration number: [2440/4518] 54% | Training loss: 0.6872042672311673
Epoch: 17 | Iteration number: [2450/4518] 54% | Training loss: 0.6872013180839772
Epoch: 17 | Iteration number: [2460/4518] 54% | Training loss: 0.6872037278442849
Epoch: 17 | Iteration number: [2470/4518] 54% | Training loss: 0.6871986452625831
Epoch: 17 | Iteration number: [2480/4518] 54% | Training loss: 0.6871958588880878
Epoch: 17 | Iteration number: [2490/4518] 55% | Training loss: 0.687188340358466
Epoch: 17 | Iteration number: [2500/4518] 55% | Training loss: 0.6871891022920609
Epoch: 17 | Iteration number: [2510/4518] 55% | Training loss: 0.6871853395524727
Epoch: 17 | Iteration number: [2520/4518] 55% | Training loss: 0.6871822539539564
Epoch: 17 | Iteration number: [2530/4518] 55% | Training loss: 0.6871808363279335
Epoch: 17 | Iteration number: [2540/4518] 56% | Training loss: 0.6871787456780907
Epoch: 17 | Iteration number: [2550/4518] 56% | Training loss: 0.6871768753902585
Epoch: 17 | Iteration number: [2560/4518] 56% | Training loss: 0.6871743877884
Epoch: 17 | Iteration number: [2570/4518] 56% | Training loss: 0.6871741027451674
Epoch: 17 | Iteration number: [2580/4518] 57% | Training loss: 0.6871729881033417
Epoch: 17 | Iteration number: [2590/4518] 57% | Training loss: 0.687171862760566
Epoch: 17 | Iteration number: [2600/4518] 57% | Training loss: 0.687174310867603
Epoch: 17 | Iteration number: [2610/4518] 57% | Training loss: 0.6871763294684019
Epoch: 17 | Iteration number: [2620/4518] 57% | Training loss: 0.6871739507403992
Epoch: 17 | Iteration number: [2630/4518] 58% | Training loss: 0.6871759866127043
Epoch: 17 | Iteration number: [2640/4518] 58% | Training loss: 0.6871762041341175
Epoch: 17 | Iteration number: [2650/4518] 58% | Training loss: 0.6871719112036363
Epoch: 17 | Iteration number: [2660/4518] 58% | Training loss: 0.6871755812401162
Epoch: 17 | Iteration number: [2670/4518] 59% | Training loss: 0.6871744569990965
Epoch: 17 | Iteration number: [2680/4518] 59% | Training loss: 0.6871718134897858
Epoch: 17 | Iteration number: [2690/4518] 59% | Training loss: 0.6871716044206159
Epoch: 17 | Iteration number: [2700/4518] 59% | Training loss: 0.6871754115819931
Epoch: 17 | Iteration number: [2710/4518] 59% | Training loss: 0.6871737040716783
Epoch: 17 | Iteration number: [2720/4518] 60% | Training loss: 0.6871720819131416
Epoch: 17 | Iteration number: [2730/4518] 60% | Training loss: 0.6871719916443249
Epoch: 17 | Iteration number: [2740/4518] 60% | Training loss: 0.6871740350540537
Epoch: 17 | Iteration number: [2750/4518] 60% | Training loss: 0.6871745637330142
Epoch: 17 | Iteration number: [2760/4518] 61% | Training loss: 0.6871695454137913
Epoch: 17 | Iteration number: [2770/4518] 61% | Training loss: 0.6871660254061868
Epoch: 17 | Iteration number: [2780/4518] 61% | Training loss: 0.6871664852547131
Epoch: 17 | Iteration number: [2790/4518] 61% | Training loss: 0.6871660366280532
Epoch: 17 | Iteration number: [2800/4518] 61% | Training loss: 0.6871655304091318
Epoch: 17 | Iteration number: [2810/4518] 62% | Training loss: 0.6871639457037441
Epoch: 17 | Iteration number: [2820/4518] 62% | Training loss: 0.6871634847517555
Epoch: 17 | Iteration number: [2830/4518] 62% | Training loss: 0.6871633185304096
Epoch: 17 | Iteration number: [2840/4518] 62% | Training loss: 0.6871580141321034
Epoch: 17 | Iteration number: [2850/4518] 63% | Training loss: 0.6871566899617513
Epoch: 17 | Iteration number: [2860/4518] 63% | Training loss: 0.6871550239883103
Epoch: 17 | Iteration number: [2870/4518] 63% | Training loss: 0.6871543789989857
Epoch: 17 | Iteration number: [2880/4518] 63% | Training loss: 0.6871506138808198
Epoch: 17 | Iteration number: [2890/4518] 63% | Training loss: 0.6871512435918036
Epoch: 17 | Iteration number: [2900/4518] 64% | Training loss: 0.6871444943855549
Epoch: 17 | Iteration number: [2910/4518] 64% | Training loss: 0.6871409510009477
Epoch: 17 | Iteration number: [2920/4518] 64% | Training loss: 0.6871448259647578
Epoch: 17 | Iteration number: [2930/4518] 64% | Training loss: 0.6871455751181462
Epoch: 17 | Iteration number: [2940/4518] 65% | Training loss: 0.6871435592571894
Epoch: 17 | Iteration number: [2950/4518] 65% | Training loss: 0.6871413383847577
Epoch: 17 | Iteration number: [2960/4518] 65% | Training loss: 0.6871411870862987
Epoch: 17 | Iteration number: [2970/4518] 65% | Training loss: 0.6871397290366266
Epoch: 17 | Iteration number: [2980/4518] 65% | Training loss: 0.6871343452058383
Epoch: 17 | Iteration number: [2990/4518] 66% | Training loss: 0.6871293826047393
Epoch: 17 | Iteration number: [3000/4518] 66% | Training loss: 0.6871266052126884
Epoch: 17 | Iteration number: [3010/4518] 66% | Training loss: 0.6871262692731877
Epoch: 17 | Iteration number: [3020/4518] 66% | Training loss: 0.6871238535800517
Epoch: 17 | Iteration number: [3030/4518] 67% | Training loss: 0.6871234518466609
Epoch: 17 | Iteration number: [3040/4518] 67% | Training loss: 0.6871277801888553
Epoch: 17 | Iteration number: [3050/4518] 67% | Training loss: 0.6871311580939371
Epoch: 17 | Iteration number: [3060/4518] 67% | Training loss: 0.6871296291063035
Epoch: 17 | Iteration number: [3070/4518] 67% | Training loss: 0.6871332679004545
Epoch: 17 | Iteration number: [3080/4518] 68% | Training loss: 0.6871372257347231
Epoch: 17 | Iteration number: [3090/4518] 68% | Training loss: 0.687141447873563
Epoch: 17 | Iteration number: [3100/4518] 68% | Training loss: 0.687144836398863
Epoch: 17 | Iteration number: [3110/4518] 68% | Training loss: 0.6871447413105674
Epoch: 17 | Iteration number: [3120/4518] 69% | Training loss: 0.6871412881864951
Epoch: 17 | Iteration number: [3130/4518] 69% | Training loss: 0.6871437165493401
Epoch: 17 | Iteration number: [3140/4518] 69% | Training loss: 0.6871439973450011
Epoch: 17 | Iteration number: [3150/4518] 69% | Training loss: 0.6871429395107996
Epoch: 17 | Iteration number: [3160/4518] 69% | Training loss: 0.6871382277223128
Epoch: 17 | Iteration number: [3170/4518] 70% | Training loss: 0.687134553731804
Epoch: 17 | Iteration number: [3180/4518] 70% | Training loss: 0.6871342679801977
Epoch: 17 | Iteration number: [3190/4518] 70% | Training loss: 0.6871340663642345
Epoch: 17 | Iteration number: [3200/4518] 70% | Training loss: 0.6871301797777414
Epoch: 17 | Iteration number: [3210/4518] 71% | Training loss: 0.6871263306460277
Epoch: 17 | Iteration number: [3220/4518] 71% | Training loss: 0.6871269450794836
Epoch: 17 | Iteration number: [3230/4518] 71% | Training loss: 0.687123114128969
Epoch: 17 | Iteration number: [3240/4518] 71% | Training loss: 0.687122960333471
Epoch: 17 | Iteration number: [3250/4518] 71% | Training loss: 0.6871226558135106
Epoch: 17 | Iteration number: [3260/4518] 72% | Training loss: 0.6871190939030033
Epoch: 17 | Iteration number: [3270/4518] 72% | Training loss: 0.6871216239914617
Epoch: 17 | Iteration number: [3280/4518] 72% | Training loss: 0.6871193539260364
Epoch: 17 | Iteration number: [3290/4518] 72% | Training loss: 0.6871199519438584
Epoch: 17 | Iteration number: [3300/4518] 73% | Training loss: 0.6871200306849046
Epoch: 17 | Iteration number: [3310/4518] 73% | Training loss: 0.6871176612701301
Epoch: 17 | Iteration number: [3320/4518] 73% | Training loss: 0.6871177986264229
Epoch: 17 | Iteration number: [3330/4518] 73% | Training loss: 0.6871159339094305
Epoch: 17 | Iteration number: [3340/4518] 73% | Training loss: 0.6871099174379589
Epoch: 17 | Iteration number: [3350/4518] 74% | Training loss: 0.6871099131142915
Epoch: 17 | Iteration number: [3360/4518] 74% | Training loss: 0.6871088084365641
Epoch: 17 | Iteration number: [3370/4518] 74% | Training loss: 0.6871079529958946
Epoch: 17 | Iteration number: [3380/4518] 74% | Training loss: 0.6871098508143566
Epoch: 17 | Iteration number: [3390/4518] 75% | Training loss: 0.6871086135726411
Epoch: 17 | Iteration number: [3400/4518] 75% | Training loss: 0.6871081084188293
Epoch: 17 | Iteration number: [3410/4518] 75% | Training loss: 0.6871062145030393
Epoch: 17 | Iteration number: [3420/4518] 75% | Training loss: 0.6871059450489736
Epoch: 17 | Iteration number: [3430/4518] 75% | Training loss: 0.6871042626244681
Epoch: 17 | Iteration number: [3440/4518] 76% | Training loss: 0.6871024479699689
Epoch: 17 | Iteration number: [3450/4518] 76% | Training loss: 0.6870988417017287
Epoch: 17 | Iteration number: [3460/4518] 76% | Training loss: 0.6870971067620151
Epoch: 17 | Iteration number: [3470/4518] 76% | Training loss: 0.6870987478697335
Epoch: 17 | Iteration number: [3480/4518] 77% | Training loss: 0.6870976594158973
Epoch: 17 | Iteration number: [3490/4518] 77% | Training loss: 0.6870965554413618
Epoch: 17 | Iteration number: [3500/4518] 77% | Training loss: 0.6870968715122768
Epoch: 17 | Iteration number: [3510/4518] 77% | Training loss: 0.6870983686372425
Epoch: 17 | Iteration number: [3520/4518] 77% | Training loss: 0.6870983277701519
Epoch: 17 | Iteration number: [3530/4518] 78% | Training loss: 0.6870984708790063
Epoch: 17 | Iteration number: [3540/4518] 78% | Training loss: 0.6870996536339744
Epoch: 17 | Iteration number: [3550/4518] 78% | Training loss: 0.6871007269536945
Epoch: 17 | Iteration number: [3560/4518] 78% | Training loss: 0.6870999627233891
Epoch: 17 | Iteration number: [3570/4518] 79% | Training loss: 0.6871015626175397
Epoch: 17 | Iteration number: [3580/4518] 79% | Training loss: 0.6871023762326001
Epoch: 17 | Iteration number: [3590/4518] 79% | Training loss: 0.6871008727211806
Epoch: 17 | Iteration number: [3600/4518] 79% | Training loss: 0.6870989928146204
Epoch: 17 | Iteration number: [3610/4518] 79% | Training loss: 0.6870961400940808
Epoch: 17 | Iteration number: [3620/4518] 80% | Training loss: 0.6870937287478157
Epoch: 17 | Iteration number: [3630/4518] 80% | Training loss: 0.6870937792066043
Epoch: 17 | Iteration number: [3640/4518] 80% | Training loss: 0.6870941962187107
Epoch: 17 | Iteration number: [3650/4518] 80% | Training loss: 0.6870974464122563
Epoch: 17 | Iteration number: [3660/4518] 81% | Training loss: 0.6870944379294505
Epoch: 17 | Iteration number: [3670/4518] 81% | Training loss: 0.6870964801603832
Epoch: 17 | Iteration number: [3680/4518] 81% | Training loss: 0.6870931602204623
Epoch: 17 | Iteration number: [3690/4518] 81% | Training loss: 0.6870919727697605
Epoch: 17 | Iteration number: [3700/4518] 81% | Training loss: 0.6870939816816433
Epoch: 17 | Iteration number: [3710/4518] 82% | Training loss: 0.6870953353428134
Epoch: 17 | Iteration number: [3720/4518] 82% | Training loss: 0.6870921578779016
Epoch: 17 | Iteration number: [3730/4518] 82% | Training loss: 0.6870901233389295
Epoch: 17 | Iteration number: [3740/4518] 82% | Training loss: 0.6870935203557346
Epoch: 17 | Iteration number: [3750/4518] 83% | Training loss: 0.6870932937463125
Epoch: 17 | Iteration number: [3760/4518] 83% | Training loss: 0.6870931409457897
Epoch: 17 | Iteration number: [3770/4518] 83% | Training loss: 0.6870926721500781
Epoch: 17 | Iteration number: [3780/4518] 83% | Training loss: 0.6870905828381342
Epoch: 17 | Iteration number: [3790/4518] 83% | Training loss: 0.6870899669098666
Epoch: 17 | Iteration number: [3800/4518] 84% | Training loss: 0.6870906888968066
Epoch: 17 | Iteration number: [3810/4518] 84% | Training loss: 0.6870889025566772
Epoch: 17 | Iteration number: [3820/4518] 84% | Training loss: 0.687088674634539
Epoch: 17 | Iteration number: [3830/4518] 84% | Training loss: 0.6870878546262845
Epoch: 17 | Iteration number: [3840/4518] 84% | Training loss: 0.6870865056446444
Epoch: 17 | Iteration number: [3850/4518] 85% | Training loss: 0.6870856200100539
Epoch: 17 | Iteration number: [3860/4518] 85% | Training loss: 0.6870832448487455
Epoch: 17 | Iteration number: [3870/4518] 85% | Training loss: 0.687082239223081
Epoch: 17 | Iteration number: [3880/4518] 85% | Training loss: 0.6870805373972224
Epoch: 17 | Iteration number: [3890/4518] 86% | Training loss: 0.6870785873163022
Epoch: 17 | Iteration number: [3900/4518] 86% | Training loss: 0.6870783263292068
Epoch: 17 | Iteration number: [3910/4518] 86% | Training loss: 0.6870784739856525
Epoch: 17 | Iteration number: [3920/4518] 86% | Training loss: 0.687078376829016
Epoch: 17 | Iteration number: [3930/4518] 86% | Training loss: 0.687079848694134
Epoch: 17 | Iteration number: [3940/4518] 87% | Training loss: 0.6870793474507211
Epoch: 17 | Iteration number: [3950/4518] 87% | Training loss: 0.6870810856094843
Epoch: 17 | Iteration number: [3960/4518] 87% | Training loss: 0.6870800142787924
Epoch: 17 | Iteration number: [3970/4518] 87% | Training loss: 0.6870784964309231
Epoch: 17 | Iteration number: [3980/4518] 88% | Training loss: 0.6870781454908189
Epoch: 17 | Iteration number: [3990/4518] 88% | Training loss: 0.6870769903175813
Epoch: 17 | Iteration number: [4000/4518] 88% | Training loss: 0.6870795665532351
Epoch: 17 | Iteration number: [4010/4518] 88% | Training loss: 0.6870791495589544
Epoch: 17 | Iteration number: [4020/4518] 88% | Training loss: 0.6870836287440352
Epoch: 17 | Iteration number: [4030/4518] 89% | Training loss: 0.6870828884263193
Epoch: 17 | Iteration number: [4040/4518] 89% | Training loss: 0.6870811730328172
Epoch: 17 | Iteration number: [4050/4518] 89% | Training loss: 0.6870828344939668
Epoch: 17 | Iteration number: [4060/4518] 89% | Training loss: 0.6870820586464088
Epoch: 17 | Iteration number: [4070/4518] 90% | Training loss: 0.6870818195091126
Epoch: 17 | Iteration number: [4080/4518] 90% | Training loss: 0.6870813378370275
Epoch: 17 | Iteration number: [4090/4518] 90% | Training loss: 0.6870815354629367
Epoch: 17 | Iteration number: [4100/4518] 90% | Training loss: 0.6870780008885918
Epoch: 17 | Iteration number: [4110/4518] 90% | Training loss: 0.6870793765768808
Epoch: 17 | Iteration number: [4120/4518] 91% | Training loss: 0.6870790875941805
Epoch: 17 | Iteration number: [4130/4518] 91% | Training loss: 0.687078996359869
Epoch: 17 | Iteration number: [4140/4518] 91% | Training loss: 0.6870816255105291
Epoch: 17 | Iteration number: [4150/4518] 91% | Training loss: 0.6870768574490604
Epoch: 17 | Iteration number: [4160/4518] 92% | Training loss: 0.6870755324140191
Epoch: 17 | Iteration number: [4170/4518] 92% | Training loss: 0.6870740996419097
Epoch: 17 | Iteration number: [4180/4518] 92% | Training loss: 0.6870733932017139
Epoch: 17 | Iteration number: [4190/4518] 92% | Training loss: 0.6870700429333707
Epoch: 17 | Iteration number: [4200/4518] 92% | Training loss: 0.6870674687056314
Epoch: 17 | Iteration number: [4210/4518] 93% | Training loss: 0.6870700334143469
Epoch: 17 | Iteration number: [4220/4518] 93% | Training loss: 0.6870706990149349
Epoch: 17 | Iteration number: [4230/4518] 93% | Training loss: 0.687070308269902
Epoch: 17 | Iteration number: [4240/4518] 93% | Training loss: 0.6870704600974074
Epoch: 17 | Iteration number: [4250/4518] 94% | Training loss: 0.6870724721375634
Epoch: 17 | Iteration number: [4260/4518] 94% | Training loss: 0.6870730865729247
Epoch: 17 | Iteration number: [4270/4518] 94% | Training loss: 0.6870741377111341
Epoch: 17 | Iteration number: [4280/4518] 94% | Training loss: 0.687076518747294
Epoch: 17 | Iteration number: [4290/4518] 94% | Training loss: 0.6870761884398116
Epoch: 17 | Iteration number: [4300/4518] 95% | Training loss: 0.6870760150149812
Epoch: 17 | Iteration number: [4310/4518] 95% | Training loss: 0.6870756572194553
Epoch: 17 | Iteration number: [4320/4518] 95% | Training loss: 0.6870757218036386
Epoch: 17 | Iteration number: [4330/4518] 95% | Training loss: 0.6870750894722707
Epoch: 17 | Iteration number: [4340/4518] 96% | Training loss: 0.68707454486102
Epoch: 17 | Iteration number: [4350/4518] 96% | Training loss: 0.6870743913075019
Epoch: 17 | Iteration number: [4360/4518] 96% | Training loss: 0.6870748660569891
Epoch: 17 | Iteration number: [4370/4518] 96% | Training loss: 0.687074065153877
Epoch: 17 | Iteration number: [4380/4518] 96% | Training loss: 0.6870734792593952
Epoch: 17 | Iteration number: [4390/4518] 97% | Training loss: 0.687073621853066
Epoch: 17 | Iteration number: [4400/4518] 97% | Training loss: 0.6870707731897181
Epoch: 17 | Iteration number: [4410/4518] 97% | Training loss: 0.6870691233751726
Epoch: 17 | Iteration number: [4420/4518] 97% | Training loss: 0.6870692088188629
Epoch: 17 | Iteration number: [4430/4518] 98% | Training loss: 0.6870660794238743
Epoch: 17 | Iteration number: [4440/4518] 98% | Training loss: 0.6870674508111971
Epoch: 17 | Iteration number: [4450/4518] 98% | Training loss: 0.6870645653799679
Epoch: 17 | Iteration number: [4460/4518] 98% | Training loss: 0.6870649862316157
Epoch: 17 | Iteration number: [4470/4518] 98% | Training loss: 0.6870661910081604
Epoch: 17 | Iteration number: [4480/4518] 99% | Training loss: 0.6870638303325645
Epoch: 17 | Iteration number: [4490/4518] 99% | Training loss: 0.6870681139833412
Epoch: 17 | Iteration number: [4500/4518] 99% | Training loss: 0.6870691610574722
Epoch: 17 | Iteration number: [4510/4518] 99% | Training loss: 0.6870673190463673

 End of epoch: 17 | Train Loss: 0.6869146727444377 | Training Time: 633 

 End of epoch: 17 | Eval Loss: 0.690087937578863 | Evaluating Time: 17 
Epoch: 18 | Iteration number: [10/4518] 0% | Training loss: 0.757501745223999
Epoch: 18 | Iteration number: [20/4518] 0% | Training loss: 0.7223461121320724
Epoch: 18 | Iteration number: [30/4518] 0% | Training loss: 0.7109811266263326
Epoch: 18 | Iteration number: [40/4518] 0% | Training loss: 0.7050267517566681
Epoch: 18 | Iteration number: [50/4518] 1% | Training loss: 0.7015056705474854
Epoch: 18 | Iteration number: [60/4518] 1% | Training loss: 0.6991319934527079
Epoch: 18 | Iteration number: [70/4518] 1% | Training loss: 0.6974399983882904
Epoch: 18 | Iteration number: [80/4518] 1% | Training loss: 0.6962226063013077
Epoch: 18 | Iteration number: [90/4518] 1% | Training loss: 0.6951082845528921
Epoch: 18 | Iteration number: [100/4518] 2% | Training loss: 0.6943241167068481
Epoch: 18 | Iteration number: [110/4518] 2% | Training loss: 0.6936518728733063
Epoch: 18 | Iteration number: [120/4518] 2% | Training loss: 0.6930315638581912
Epoch: 18 | Iteration number: [130/4518] 2% | Training loss: 0.6925452076471769
Epoch: 18 | Iteration number: [140/4518] 3% | Training loss: 0.6920974518571581
Epoch: 18 | Iteration number: [150/4518] 3% | Training loss: 0.6916986179351806
Epoch: 18 | Iteration number: [160/4518] 3% | Training loss: 0.6914547126740217
Epoch: 18 | Iteration number: [170/4518] 3% | Training loss: 0.6911828370655284
Epoch: 18 | Iteration number: [180/4518] 3% | Training loss: 0.690984704097112
Epoch: 18 | Iteration number: [190/4518] 4% | Training loss: 0.690778658891979
Epoch: 18 | Iteration number: [200/4518] 4% | Training loss: 0.690666392147541
Epoch: 18 | Iteration number: [210/4518] 4% | Training loss: 0.690465312628519
Epoch: 18 | Iteration number: [220/4518] 4% | Training loss: 0.6903086930513382
Epoch: 18 | Iteration number: [230/4518] 5% | Training loss: 0.6901699244976044
Epoch: 18 | Iteration number: [240/4518] 5% | Training loss: 0.6899637155234813
Epoch: 18 | Iteration number: [250/4518] 5% | Training loss: 0.6898768565654755
Epoch: 18 | Iteration number: [260/4518] 5% | Training loss: 0.6897537190180558
Epoch: 18 | Iteration number: [270/4518] 5% | Training loss: 0.6896167463726468
Epoch: 18 | Iteration number: [280/4518] 6% | Training loss: 0.6895590801324163
Epoch: 18 | Iteration number: [290/4518] 6% | Training loss: 0.6894515090975268
Epoch: 18 | Iteration number: [300/4518] 6% | Training loss: 0.6893414068222046
Epoch: 18 | Iteration number: [310/4518] 6% | Training loss: 0.6892617066060344
Epoch: 18 | Iteration number: [320/4518] 7% | Training loss: 0.6892031330615283
Epoch: 18 | Iteration number: [330/4518] 7% | Training loss: 0.6891428683743333
Epoch: 18 | Iteration number: [340/4518] 7% | Training loss: 0.6891026786145042
Epoch: 18 | Iteration number: [350/4518] 7% | Training loss: 0.6890228153978075
Epoch: 18 | Iteration number: [360/4518] 7% | Training loss: 0.6889754739072588
Epoch: 18 | Iteration number: [370/4518] 8% | Training loss: 0.6889111979587658
Epoch: 18 | Iteration number: [380/4518] 8% | Training loss: 0.6888407365271919
Epoch: 18 | Iteration number: [390/4518] 8% | Training loss: 0.688805238253031
Epoch: 18 | Iteration number: [400/4518] 8% | Training loss: 0.6887849879264831
Epoch: 18 | Iteration number: [410/4518] 9% | Training loss: 0.6887442978417001
Epoch: 18 | Iteration number: [420/4518] 9% | Training loss: 0.6886934514556612
Epoch: 18 | Iteration number: [430/4518] 9% | Training loss: 0.6886596054531807
Epoch: 18 | Iteration number: [440/4518] 9% | Training loss: 0.6886079354719682
Epoch: 18 | Iteration number: [450/4518] 9% | Training loss: 0.6885704012711843
Epoch: 18 | Iteration number: [460/4518] 10% | Training loss: 0.6885214862616166
Epoch: 18 | Iteration number: [470/4518] 10% | Training loss: 0.6884819562130786
Epoch: 18 | Iteration number: [480/4518] 10% | Training loss: 0.68843103411297
Epoch: 18 | Iteration number: [490/4518] 10% | Training loss: 0.6883938302799147
Epoch: 18 | Iteration number: [500/4518] 11% | Training loss: 0.6883496022224427
Epoch: 18 | Iteration number: [510/4518] 11% | Training loss: 0.6883326518769358
Epoch: 18 | Iteration number: [520/4518] 11% | Training loss: 0.6882918134331704
Epoch: 18 | Iteration number: [530/4518] 11% | Training loss: 0.6882807029868072
Epoch: 18 | Iteration number: [540/4518] 11% | Training loss: 0.6882560005894414
Epoch: 18 | Iteration number: [550/4518] 12% | Training loss: 0.6882418898018924
Epoch: 18 | Iteration number: [560/4518] 12% | Training loss: 0.6882314634110246
Epoch: 18 | Iteration number: [570/4518] 12% | Training loss: 0.68818301924488
Epoch: 18 | Iteration number: [580/4518] 12% | Training loss: 0.6881622326785121
Epoch: 18 | Iteration number: [590/4518] 13% | Training loss: 0.688144288224689
Epoch: 18 | Iteration number: [600/4518] 13% | Training loss: 0.6881322252750397
Epoch: 18 | Iteration number: [610/4518] 13% | Training loss: 0.6881137750187858
Epoch: 18 | Iteration number: [620/4518] 13% | Training loss: 0.6880806154781772
Epoch: 18 | Iteration number: [630/4518] 13% | Training loss: 0.6880481895946321
Epoch: 18 | Iteration number: [640/4518] 14% | Training loss: 0.6880235099233687
Epoch: 18 | Iteration number: [650/4518] 14% | Training loss: 0.6879913679453042
Epoch: 18 | Iteration number: [660/4518] 14% | Training loss: 0.6879527597716361
Epoch: 18 | Iteration number: [670/4518] 14% | Training loss: 0.6879432430907861
Epoch: 18 | Iteration number: [680/4518] 15% | Training loss: 0.6879498575540149
Epoch: 18 | Iteration number: [690/4518] 15% | Training loss: 0.687917191049327
Epoch: 18 | Iteration number: [700/4518] 15% | Training loss: 0.6879093344722476
Epoch: 18 | Iteration number: [710/4518] 15% | Training loss: 0.6879184824480138
Epoch: 18 | Iteration number: [720/4518] 15% | Training loss: 0.6879034503466553
Epoch: 18 | Iteration number: [730/4518] 16% | Training loss: 0.6878978595341722
Epoch: 18 | Iteration number: [740/4518] 16% | Training loss: 0.6878808468580246
Epoch: 18 | Iteration number: [750/4518] 16% | Training loss: 0.6878645619551341
Epoch: 18 | Iteration number: [760/4518] 16% | Training loss: 0.6878499376930689
Epoch: 18 | Iteration number: [770/4518] 17% | Training loss: 0.6878467854741331
Epoch: 18 | Iteration number: [780/4518] 17% | Training loss: 0.6878403631540445
Epoch: 18 | Iteration number: [790/4518] 17% | Training loss: 0.6878236874749389
Epoch: 18 | Iteration number: [800/4518] 17% | Training loss: 0.6878153936564922
Epoch: 18 | Iteration number: [810/4518] 17% | Training loss: 0.6878208863146511
Epoch: 18 | Iteration number: [820/4518] 18% | Training loss: 0.6877976025023111
Epoch: 18 | Iteration number: [830/4518] 18% | Training loss: 0.6877828043627452
Epoch: 18 | Iteration number: [840/4518] 18% | Training loss: 0.6877832501417115
Epoch: 18 | Iteration number: [850/4518] 18% | Training loss: 0.6877843523726744
Epoch: 18 | Iteration number: [860/4518] 19% | Training loss: 0.6877493588037269
Epoch: 18 | Iteration number: [870/4518] 19% | Training loss: 0.6877448762285299
Epoch: 18 | Iteration number: [880/4518] 19% | Training loss: 0.6877509941431609
Epoch: 18 | Iteration number: [890/4518] 19% | Training loss: 0.6877384022380529
Epoch: 18 | Iteration number: [900/4518] 19% | Training loss: 0.6877314915259679
Epoch: 18 | Iteration number: [910/4518] 20% | Training loss: 0.6877252540090582
Epoch: 18 | Iteration number: [920/4518] 20% | Training loss: 0.6877164897063505
Epoch: 18 | Iteration number: [930/4518] 20% | Training loss: 0.6877114303650395
Epoch: 18 | Iteration number: [940/4518] 20% | Training loss: 0.6877050719996716
Epoch: 18 | Iteration number: [950/4518] 21% | Training loss: 0.687690467520764
Epoch: 18 | Iteration number: [960/4518] 21% | Training loss: 0.6876936320215463
Epoch: 18 | Iteration number: [970/4518] 21% | Training loss: 0.6876925896737993
Epoch: 18 | Iteration number: [980/4518] 21% | Training loss: 0.6876983924179662
Epoch: 18 | Iteration number: [990/4518] 21% | Training loss: 0.6876961534673517
Epoch: 18 | Iteration number: [1000/4518] 22% | Training loss: 0.6876883533596992
Epoch: 18 | Iteration number: [1010/4518] 22% | Training loss: 0.6876864599709464
Epoch: 18 | Iteration number: [1020/4518] 22% | Training loss: 0.6876943784017189
Epoch: 18 | Iteration number: [1030/4518] 22% | Training loss: 0.6876841970439096
Epoch: 18 | Iteration number: [1040/4518] 23% | Training loss: 0.6876676067709923
Epoch: 18 | Iteration number: [1050/4518] 23% | Training loss: 0.6876692420528049
Epoch: 18 | Iteration number: [1060/4518] 23% | Training loss: 0.6876522656319276
Epoch: 18 | Iteration number: [1070/4518] 23% | Training loss: 0.6876486295294539
Epoch: 18 | Iteration number: [1080/4518] 23% | Training loss: 0.6876490809851222
Epoch: 18 | Iteration number: [1090/4518] 24% | Training loss: 0.6876292628979465
Epoch: 18 | Iteration number: [1100/4518] 24% | Training loss: 0.6876277719844471
Epoch: 18 | Iteration number: [1110/4518] 24% | Training loss: 0.6876170532660442
Epoch: 18 | Iteration number: [1120/4518] 24% | Training loss: 0.6875998818980796
Epoch: 18 | Iteration number: [1130/4518] 25% | Training loss: 0.6875909210306353
Epoch: 18 | Iteration number: [1140/4518] 25% | Training loss: 0.6875882112666181
Epoch: 18 | Iteration number: [1150/4518] 25% | Training loss: 0.6875788190053856
Epoch: 18 | Iteration number: [1160/4518] 25% | Training loss: 0.687567140470291
Epoch: 18 | Iteration number: [1170/4518] 25% | Training loss: 0.6875592729984186
Epoch: 18 | Iteration number: [1180/4518] 26% | Training loss: 0.6875498118036885
Epoch: 18 | Iteration number: [1190/4518] 26% | Training loss: 0.6875469151665182
Epoch: 18 | Iteration number: [1200/4518] 26% | Training loss: 0.6875345177451769
Epoch: 18 | Iteration number: [1210/4518] 26% | Training loss: 0.6875103627847245
Epoch: 18 | Iteration number: [1220/4518] 27% | Training loss: 0.6875078170514498
Epoch: 18 | Iteration number: [1230/4518] 27% | Training loss: 0.6874945258706566
Epoch: 18 | Iteration number: [1240/4518] 27% | Training loss: 0.6874924516485583
Epoch: 18 | Iteration number: [1250/4518] 27% | Training loss: 0.687502351808548
Epoch: 18 | Iteration number: [1260/4518] 27% | Training loss: 0.6875023131805753
Epoch: 18 | Iteration number: [1270/4518] 28% | Training loss: 0.6874976340710648
Epoch: 18 | Iteration number: [1280/4518] 28% | Training loss: 0.6875032272655517
Epoch: 18 | Iteration number: [1290/4518] 28% | Training loss: 0.6875044659126637
Epoch: 18 | Iteration number: [1300/4518] 28% | Training loss: 0.6874795148922846
Epoch: 18 | Iteration number: [1310/4518] 28% | Training loss: 0.6874612339580332
Epoch: 18 | Iteration number: [1320/4518] 29% | Training loss: 0.687450611410719
Epoch: 18 | Iteration number: [1330/4518] 29% | Training loss: 0.6874492008883254
Epoch: 18 | Iteration number: [1340/4518] 29% | Training loss: 0.6874530069418807
Epoch: 18 | Iteration number: [1350/4518] 29% | Training loss: 0.6874413911501567
Epoch: 18 | Iteration number: [1360/4518] 30% | Training loss: 0.6874305211884134
Epoch: 18 | Iteration number: [1370/4518] 30% | Training loss: 0.6874277196226329
Epoch: 18 | Iteration number: [1380/4518] 30% | Training loss: 0.6874249005231304
Epoch: 18 | Iteration number: [1390/4518] 30% | Training loss: 0.6874240218735427
Epoch: 18 | Iteration number: [1400/4518] 30% | Training loss: 0.6874079416479383
Epoch: 18 | Iteration number: [1410/4518] 31% | Training loss: 0.6874018870346935
Epoch: 18 | Iteration number: [1420/4518] 31% | Training loss: 0.6873937609749781
Epoch: 18 | Iteration number: [1430/4518] 31% | Training loss: 0.6873838451775638
Epoch: 18 | Iteration number: [1440/4518] 31% | Training loss: 0.6873727404408985
Epoch: 18 | Iteration number: [1450/4518] 32% | Training loss: 0.6873699099030988
Epoch: 18 | Iteration number: [1460/4518] 32% | Training loss: 0.6873652221405343
Epoch: 18 | Iteration number: [1470/4518] 32% | Training loss: 0.6873627026875814
Epoch: 18 | Iteration number: [1480/4518] 32% | Training loss: 0.6873584453721304
Epoch: 18 | Iteration number: [1490/4518] 32% | Training loss: 0.6873545028219287
Epoch: 18 | Iteration number: [1500/4518] 33% | Training loss: 0.6873542115688324
Epoch: 18 | Iteration number: [1510/4518] 33% | Training loss: 0.687355692733992
Epoch: 18 | Iteration number: [1520/4518] 33% | Training loss: 0.687348909205512
Epoch: 18 | Iteration number: [1530/4518] 33% | Training loss: 0.6873424865841087
Epoch: 18 | Iteration number: [1540/4518] 34% | Training loss: 0.6873355715692817
Epoch: 18 | Iteration number: [1550/4518] 34% | Training loss: 0.6873302563159697
Epoch: 18 | Iteration number: [1560/4518] 34% | Training loss: 0.6873210950539662
Epoch: 18 | Iteration number: [1570/4518] 34% | Training loss: 0.6873202618140324
Epoch: 18 | Iteration number: [1580/4518] 34% | Training loss: 0.6873205187199991
Epoch: 18 | Iteration number: [1590/4518] 35% | Training loss: 0.6873115102450053
Epoch: 18 | Iteration number: [1600/4518] 35% | Training loss: 0.6873075730726123
Epoch: 18 | Iteration number: [1610/4518] 35% | Training loss: 0.6873027461656133
Epoch: 18 | Iteration number: [1620/4518] 35% | Training loss: 0.6872938326111546
Epoch: 18 | Iteration number: [1630/4518] 36% | Training loss: 0.6872855864419528
Epoch: 18 | Iteration number: [1640/4518] 36% | Training loss: 0.6872863597259289
Epoch: 18 | Iteration number: [1650/4518] 36% | Training loss: 0.6872838725826957
Epoch: 18 | Iteration number: [1660/4518] 36% | Training loss: 0.68727825126016
Epoch: 18 | Iteration number: [1670/4518] 36% | Training loss: 0.6872682379748293
Epoch: 18 | Iteration number: [1680/4518] 37% | Training loss: 0.6872669787633987
Epoch: 18 | Iteration number: [1690/4518] 37% | Training loss: 0.6872715752858382
Epoch: 18 | Iteration number: [1700/4518] 37% | Training loss: 0.687265957979595
Epoch: 18 | Iteration number: [1710/4518] 37% | Training loss: 0.6872617133528168
Epoch: 18 | Iteration number: [1720/4518] 38% | Training loss: 0.6872668283276779
Epoch: 18 | Iteration number: [1730/4518] 38% | Training loss: 0.6872609112993141
Epoch: 18 | Iteration number: [1740/4518] 38% | Training loss: 0.6872591780862589
Epoch: 18 | Iteration number: [1750/4518] 38% | Training loss: 0.6872618897983006
Epoch: 18 | Iteration number: [1760/4518] 38% | Training loss: 0.6872590084306218
Epoch: 18 | Iteration number: [1770/4518] 39% | Training loss: 0.687258453726095
Epoch: 18 | Iteration number: [1780/4518] 39% | Training loss: 0.6872504587253828
Epoch: 18 | Iteration number: [1790/4518] 39% | Training loss: 0.687250292401074
Epoch: 18 | Iteration number: [1800/4518] 39% | Training loss: 0.6872430955701404
Epoch: 18 | Iteration number: [1810/4518] 40% | Training loss: 0.6872464355842843
Epoch: 18 | Iteration number: [1820/4518] 40% | Training loss: 0.6872431539244704
Epoch: 18 | Iteration number: [1830/4518] 40% | Training loss: 0.6872410670655673
Epoch: 18 | Iteration number: [1840/4518] 40% | Training loss: 0.6872468458569568
Epoch: 18 | Iteration number: [1850/4518] 40% | Training loss: 0.6872411269110602
Epoch: 18 | Iteration number: [1860/4518] 41% | Training loss: 0.6872431420510815
Epoch: 18 | Iteration number: [1870/4518] 41% | Training loss: 0.6872381366829183
Epoch: 18 | Iteration number: [1880/4518] 41% | Training loss: 0.687237872880824
Epoch: 18 | Iteration number: [1890/4518] 41% | Training loss: 0.6872373090849982
Epoch: 18 | Iteration number: [1900/4518] 42% | Training loss: 0.6872348952920814
Epoch: 18 | Iteration number: [1910/4518] 42% | Training loss: 0.6872276473107762
Epoch: 18 | Iteration number: [1920/4518] 42% | Training loss: 0.6872188822987179
Epoch: 18 | Iteration number: [1930/4518] 42% | Training loss: 0.6872112581149284
Epoch: 18 | Iteration number: [1940/4518] 42% | Training loss: 0.687210287998632
Epoch: 18 | Iteration number: [1950/4518] 43% | Training loss: 0.6872106393789633
Epoch: 18 | Iteration number: [1960/4518] 43% | Training loss: 0.6872115304275435
Epoch: 18 | Iteration number: [1970/4518] 43% | Training loss: 0.6872031012767462
Epoch: 18 | Iteration number: [1980/4518] 43% | Training loss: 0.6871944855258922
Epoch: 18 | Iteration number: [1990/4518] 44% | Training loss: 0.6871927976907797
Epoch: 18 | Iteration number: [2000/4518] 44% | Training loss: 0.6871916187107563
Epoch: 18 | Iteration number: [2010/4518] 44% | Training loss: 0.6871892417544749
Epoch: 18 | Iteration number: [2020/4518] 44% | Training loss: 0.6871829935819795
Epoch: 18 | Iteration number: [2030/4518] 44% | Training loss: 0.6871868766587356
Epoch: 18 | Iteration number: [2040/4518] 45% | Training loss: 0.6871819873066509
Epoch: 18 | Iteration number: [2050/4518] 45% | Training loss: 0.6871811111961923
Epoch: 18 | Iteration number: [2060/4518] 45% | Training loss: 0.6871839023909523
Epoch: 18 | Iteration number: [2070/4518] 45% | Training loss: 0.6871846435438608
Epoch: 18 | Iteration number: [2080/4518] 46% | Training loss: 0.6871852190735248
Epoch: 18 | Iteration number: [2090/4518] 46% | Training loss: 0.6871882055935107
Epoch: 18 | Iteration number: [2100/4518] 46% | Training loss: 0.687186689206532
Epoch: 18 | Iteration number: [2110/4518] 46% | Training loss: 0.6871887280477732
Epoch: 18 | Iteration number: [2120/4518] 46% | Training loss: 0.6871858183786554
Epoch: 18 | Iteration number: [2130/4518] 47% | Training loss: 0.6871868787796844
Epoch: 18 | Iteration number: [2140/4518] 47% | Training loss: 0.6871856865481796
Epoch: 18 | Iteration number: [2150/4518] 47% | Training loss: 0.6871809243878653
Epoch: 18 | Iteration number: [2160/4518] 47% | Training loss: 0.6871804761389891
Epoch: 18 | Iteration number: [2170/4518] 48% | Training loss: 0.6871775099209376
Epoch: 18 | Iteration number: [2180/4518] 48% | Training loss: 0.6871815059709987
Epoch: 18 | Iteration number: [2190/4518] 48% | Training loss: 0.6871787688231359
Epoch: 18 | Iteration number: [2200/4518] 48% | Training loss: 0.6871779497103258
Epoch: 18 | Iteration number: [2210/4518] 48% | Training loss: 0.6871729253104369
Epoch: 18 | Iteration number: [2220/4518] 49% | Training loss: 0.6871745031427693
Epoch: 18 | Iteration number: [2230/4518] 49% | Training loss: 0.6871777932472828
Epoch: 18 | Iteration number: [2240/4518] 49% | Training loss: 0.687179742407586
Epoch: 18 | Iteration number: [2250/4518] 49% | Training loss: 0.6871804094579484
Epoch: 18 | Iteration number: [2260/4518] 50% | Training loss: 0.6871796275398373
Epoch: 18 | Iteration number: [2270/4518] 50% | Training loss: 0.6871797275438183
Epoch: 18 | Iteration number: [2280/4518] 50% | Training loss: 0.687184247740528
Epoch: 18 | Iteration number: [2290/4518] 50% | Training loss: 0.6871810897729282
Epoch: 18 | Iteration number: [2300/4518] 50% | Training loss: 0.6871796351930369
Epoch: 18 | Iteration number: [2310/4518] 51% | Training loss: 0.687181602824818
Epoch: 18 | Iteration number: [2320/4518] 51% | Training loss: 0.6871823842155522
Epoch: 18 | Iteration number: [2330/4518] 51% | Training loss: 0.6871876682846332
Epoch: 18 | Iteration number: [2340/4518] 51% | Training loss: 0.6871875690089332
Epoch: 18 | Iteration number: [2350/4518] 52% | Training loss: 0.6871854364111069
Epoch: 18 | Iteration number: [2360/4518] 52% | Training loss: 0.6871858304334899
Epoch: 18 | Iteration number: [2370/4518] 52% | Training loss: 0.6871868003521288
Epoch: 18 | Iteration number: [2380/4518] 52% | Training loss: 0.6871830421585997
Epoch: 18 | Iteration number: [2390/4518] 52% | Training loss: 0.6871863554711123
Epoch: 18 | Iteration number: [2400/4518] 53% | Training loss: 0.6871848806987206
Epoch: 18 | Iteration number: [2410/4518] 53% | Training loss: 0.6871831899856631
Epoch: 18 | Iteration number: [2420/4518] 53% | Training loss: 0.6871849065723498
Epoch: 18 | Iteration number: [2430/4518] 53% | Training loss: 0.6871812260199966
Epoch: 18 | Iteration number: [2440/4518] 54% | Training loss: 0.6871779628220152
Epoch: 18 | Iteration number: [2450/4518] 54% | Training loss: 0.6871791455453756
Epoch: 18 | Iteration number: [2460/4518] 54% | Training loss: 0.6871762698258811
Epoch: 18 | Iteration number: [2470/4518] 54% | Training loss: 0.6871739113861732
Epoch: 18 | Iteration number: [2480/4518] 54% | Training loss: 0.6871765572697885
Epoch: 18 | Iteration number: [2490/4518] 55% | Training loss: 0.6871726989267342
Epoch: 18 | Iteration number: [2500/4518] 55% | Training loss: 0.6871709910869599
Epoch: 18 | Iteration number: [2510/4518] 55% | Training loss: 0.6871692730136126
Epoch: 18 | Iteration number: [2520/4518] 55% | Training loss: 0.6871657657481375
Epoch: 18 | Iteration number: [2530/4518] 55% | Training loss: 0.6871653579911695
Epoch: 18 | Iteration number: [2540/4518] 56% | Training loss: 0.6871662405062848
Epoch: 18 | Iteration number: [2550/4518] 56% | Training loss: 0.6871616006131266
Epoch: 18 | Iteration number: [2560/4518] 56% | Training loss: 0.6871577787445858
Epoch: 18 | Iteration number: [2570/4518] 56% | Training loss: 0.6871543127043238
Epoch: 18 | Iteration number: [2580/4518] 57% | Training loss: 0.687154510732769
Epoch: 18 | Iteration number: [2590/4518] 57% | Training loss: 0.6871533144624997
Epoch: 18 | Iteration number: [2600/4518] 57% | Training loss: 0.6871537195260708
Epoch: 18 | Iteration number: [2610/4518] 57% | Training loss: 0.6871486093577754
Epoch: 18 | Iteration number: [2620/4518] 57% | Training loss: 0.6871459542112496
Epoch: 18 | Iteration number: [2630/4518] 58% | Training loss: 0.6871449836533332
Epoch: 18 | Iteration number: [2640/4518] 58% | Training loss: 0.687145876907038
Epoch: 18 | Iteration number: [2650/4518] 58% | Training loss: 0.6871443747124582
Epoch: 18 | Iteration number: [2660/4518] 58% | Training loss: 0.6871489491229666
Epoch: 18 | Iteration number: [2670/4518] 59% | Training loss: 0.6871479639399811
Epoch: 18 | Iteration number: [2680/4518] 59% | Training loss: 0.6871492172132677
Epoch: 18 | Iteration number: [2690/4518] 59% | Training loss: 0.6871473413860931
Epoch: 18 | Iteration number: [2700/4518] 59% | Training loss: 0.6871431564843213
Epoch: 18 | Iteration number: [2710/4518] 59% | Training loss: 0.6871472344407297
Epoch: 18 | Iteration number: [2720/4518] 60% | Training loss: 0.6871459348675083
Epoch: 18 | Iteration number: [2730/4518] 60% | Training loss: 0.6871464059903072
Epoch: 18 | Iteration number: [2740/4518] 60% | Training loss: 0.6871443342335903
Epoch: 18 | Iteration number: [2750/4518] 60% | Training loss: 0.6871416219147769
Epoch: 18 | Iteration number: [2760/4518] 61% | Training loss: 0.687140487242436
Epoch: 18 | Iteration number: [2770/4518] 61% | Training loss: 0.6871430024773636
Epoch: 18 | Iteration number: [2780/4518] 61% | Training loss: 0.6871444960721105
Epoch: 18 | Iteration number: [2790/4518] 61% | Training loss: 0.6871409678758259
Epoch: 18 | Iteration number: [2800/4518] 61% | Training loss: 0.6871417833651815
Epoch: 18 | Iteration number: [2810/4518] 62% | Training loss: 0.687137566427319
Epoch: 18 | Iteration number: [2820/4518] 62% | Training loss: 0.6871344959904961
Epoch: 18 | Iteration number: [2830/4518] 62% | Training loss: 0.687135105419496
Epoch: 18 | Iteration number: [2840/4518] 62% | Training loss: 0.6871317504577233
Epoch: 18 | Iteration number: [2850/4518] 63% | Training loss: 0.6871313762664795
Epoch: 18 | Iteration number: [2860/4518] 63% | Training loss: 0.6871329588073117
Epoch: 18 | Iteration number: [2870/4518] 63% | Training loss: 0.6871299841678101
Epoch: 18 | Iteration number: [2880/4518] 63% | Training loss: 0.6871271740852131
Epoch: 18 | Iteration number: [2890/4518] 63% | Training loss: 0.6871281288899352
Epoch: 18 | Iteration number: [2900/4518] 64% | Training loss: 0.6871328554687829
Epoch: 18 | Iteration number: [2910/4518] 64% | Training loss: 0.6871342813845762
Epoch: 18 | Iteration number: [2920/4518] 64% | Training loss: 0.6871341060898075
Epoch: 18 | Iteration number: [2930/4518] 64% | Training loss: 0.6871362690429231
Epoch: 18 | Iteration number: [2940/4518] 65% | Training loss: 0.6871294420187165
Epoch: 18 | Iteration number: [2950/4518] 65% | Training loss: 0.6871313690735122
Epoch: 18 | Iteration number: [2960/4518] 65% | Training loss: 0.6871333215889093
Epoch: 18 | Iteration number: [2970/4518] 65% | Training loss: 0.6871344606483023
Epoch: 18 | Iteration number: [2980/4518] 65% | Training loss: 0.6871297369667347
Epoch: 18 | Iteration number: [2990/4518] 66% | Training loss: 0.6871314181930644
Epoch: 18 | Iteration number: [3000/4518] 66% | Training loss: 0.6871262064576149
Epoch: 18 | Iteration number: [3010/4518] 66% | Training loss: 0.6871254715214536
Epoch: 18 | Iteration number: [3020/4518] 66% | Training loss: 0.6871269734687363
Epoch: 18 | Iteration number: [3030/4518] 67% | Training loss: 0.6871253082854519
Epoch: 18 | Iteration number: [3040/4518] 67% | Training loss: 0.6871267391858916
Epoch: 18 | Iteration number: [3050/4518] 67% | Training loss: 0.6871264372692734
Epoch: 18 | Iteration number: [3060/4518] 67% | Training loss: 0.6871255157235401
Epoch: 18 | Iteration number: [3070/4518] 67% | Training loss: 0.6871233848290645
Epoch: 18 | Iteration number: [3080/4518] 68% | Training loss: 0.6871240903804828
Epoch: 18 | Iteration number: [3090/4518] 68% | Training loss: 0.6871234729644936
Epoch: 18 | Iteration number: [3100/4518] 68% | Training loss: 0.687124175352435
Epoch: 18 | Iteration number: [3110/4518] 68% | Training loss: 0.6871260626523058
Epoch: 18 | Iteration number: [3120/4518] 69% | Training loss: 0.6871273617331798
Epoch: 18 | Iteration number: [3130/4518] 69% | Training loss: 0.6871286945982863
Epoch: 18 | Iteration number: [3140/4518] 69% | Training loss: 0.6871268091497907
Epoch: 18 | Iteration number: [3150/4518] 69% | Training loss: 0.6871241800557999
Epoch: 18 | Iteration number: [3160/4518] 69% | Training loss: 0.6871215739204913
Epoch: 18 | Iteration number: [3170/4518] 70% | Training loss: 0.6871198518419115
Epoch: 18 | Iteration number: [3180/4518] 70% | Training loss: 0.6871202248822218
Epoch: 18 | Iteration number: [3190/4518] 70% | Training loss: 0.6871193740808852
Epoch: 18 | Iteration number: [3200/4518] 70% | Training loss: 0.6871147968620062
Epoch: 18 | Iteration number: [3210/4518] 71% | Training loss: 0.6871131938751612
Epoch: 18 | Iteration number: [3220/4518] 71% | Training loss: 0.6871094901369225
Epoch: 18 | Iteration number: [3230/4518] 71% | Training loss: 0.6871073619869102
Epoch: 18 | Iteration number: [3240/4518] 71% | Training loss: 0.6871082425669387
Epoch: 18 | Iteration number: [3250/4518] 71% | Training loss: 0.6871080788649045
Epoch: 18 | Iteration number: [3260/4518] 72% | Training loss: 0.687104160251793
Epoch: 18 | Iteration number: [3270/4518] 72% | Training loss: 0.6871035262714468
Epoch: 18 | Iteration number: [3280/4518] 72% | Training loss: 0.6871047899853893
Epoch: 18 | Iteration number: [3290/4518] 72% | Training loss: 0.6871045284539371
Epoch: 18 | Iteration number: [3300/4518] 73% | Training loss: 0.6871067581032262
Epoch: 18 | Iteration number: [3310/4518] 73% | Training loss: 0.6871047167439475
Epoch: 18 | Iteration number: [3320/4518] 73% | Training loss: 0.6871017330202711
Epoch: 18 | Iteration number: [3330/4518] 73% | Training loss: 0.6871055060320789
Epoch: 18 | Iteration number: [3340/4518] 73% | Training loss: 0.687109248509664
Epoch: 18 | Iteration number: [3350/4518] 74% | Training loss: 0.6871077727915635
Epoch: 18 | Iteration number: [3360/4518] 74% | Training loss: 0.6871069168405873
Epoch: 18 | Iteration number: [3370/4518] 74% | Training loss: 0.6871064937786815
Epoch: 18 | Iteration number: [3380/4518] 74% | Training loss: 0.6871043245644259
Epoch: 18 | Iteration number: [3390/4518] 75% | Training loss: 0.6871056583427047
Epoch: 18 | Iteration number: [3400/4518] 75% | Training loss: 0.687107643660377
Epoch: 18 | Iteration number: [3410/4518] 75% | Training loss: 0.6871073779647301
Epoch: 18 | Iteration number: [3420/4518] 75% | Training loss: 0.6871065801870057
Epoch: 18 | Iteration number: [3430/4518] 75% | Training loss: 0.68710472418685
Epoch: 18 | Iteration number: [3440/4518] 76% | Training loss: 0.6871006532290648
Epoch: 18 | Iteration number: [3450/4518] 76% | Training loss: 0.6871040183910425
Epoch: 18 | Iteration number: [3460/4518] 76% | Training loss: 0.6871049567798658
Epoch: 18 | Iteration number: [3470/4518] 76% | Training loss: 0.6871022813945408
Epoch: 18 | Iteration number: [3480/4518] 77% | Training loss: 0.6871025213736227
Epoch: 18 | Iteration number: [3490/4518] 77% | Training loss: 0.6870959460222961
Epoch: 18 | Iteration number: [3500/4518] 77% | Training loss: 0.6870971565416881
Epoch: 18 | Iteration number: [3510/4518] 77% | Training loss: 0.6871018544561164
Epoch: 18 | Iteration number: [3520/4518] 77% | Training loss: 0.6871013557369059
Epoch: 18 | Iteration number: [3530/4518] 78% | Training loss: 0.6871036698392701
Epoch: 18 | Iteration number: [3540/4518] 78% | Training loss: 0.6871027962972889
Epoch: 18 | Iteration number: [3550/4518] 78% | Training loss: 0.6871036326549422
Epoch: 18 | Iteration number: [3560/4518] 78% | Training loss: 0.6871006891801116
Epoch: 18 | Iteration number: [3570/4518] 79% | Training loss: 0.6870968947724468
Epoch: 18 | Iteration number: [3580/4518] 79% | Training loss: 0.6870966386195667
Epoch: 18 | Iteration number: [3590/4518] 79% | Training loss: 0.6870914524976257
Epoch: 18 | Iteration number: [3600/4518] 79% | Training loss: 0.6870898932218552
Epoch: 18 | Iteration number: [3610/4518] 79% | Training loss: 0.6870903246125356
Epoch: 18 | Iteration number: [3620/4518] 80% | Training loss: 0.6870919727159468
Epoch: 18 | Iteration number: [3630/4518] 80% | Training loss: 0.6870904837758088
Epoch: 18 | Iteration number: [3640/4518] 80% | Training loss: 0.6870902595120472
Epoch: 18 | Iteration number: [3650/4518] 80% | Training loss: 0.6870879877266819
Epoch: 18 | Iteration number: [3660/4518] 81% | Training loss: 0.6870905707442695
Epoch: 18 | Iteration number: [3670/4518] 81% | Training loss: 0.6870906977140286
Epoch: 18 | Iteration number: [3680/4518] 81% | Training loss: 0.6870903656048619
Epoch: 18 | Iteration number: [3690/4518] 81% | Training loss: 0.6870896098251912
Epoch: 18 | Iteration number: [3700/4518] 81% | Training loss: 0.687090843013815
Epoch: 18 | Iteration number: [3710/4518] 82% | Training loss: 0.6870931034621524
Epoch: 18 | Iteration number: [3720/4518] 82% | Training loss: 0.6870975998460606
Epoch: 18 | Iteration number: [3730/4518] 82% | Training loss: 0.6870954261069003
Epoch: 18 | Iteration number: [3740/4518] 82% | Training loss: 0.6870981625694642
Epoch: 18 | Iteration number: [3750/4518] 83% | Training loss: 0.6870978997866313
Epoch: 18 | Iteration number: [3760/4518] 83% | Training loss: 0.6870960610185531
Epoch: 18 | Iteration number: [3770/4518] 83% | Training loss: 0.6870975665293575
Epoch: 18 | Iteration number: [3780/4518] 83% | Training loss: 0.6870963711271841
Epoch: 18 | Iteration number: [3790/4518] 83% | Training loss: 0.6870958801938865
Epoch: 18 | Iteration number: [3800/4518] 84% | Training loss: 0.687094965702609
Epoch: 18 | Iteration number: [3810/4518] 84% | Training loss: 0.6870926460568986
Epoch: 18 | Iteration number: [3820/4518] 84% | Training loss: 0.6870913854288181
Epoch: 18 | Iteration number: [3830/4518] 84% | Training loss: 0.6870908647697838
Epoch: 18 | Iteration number: [3840/4518] 84% | Training loss: 0.6870906070806087
Epoch: 18 | Iteration number: [3850/4518] 85% | Training loss: 0.6870946546963282
Epoch: 18 | Iteration number: [3860/4518] 85% | Training loss: 0.6870945889251837
Epoch: 18 | Iteration number: [3870/4518] 85% | Training loss: 0.6870902591897535
Epoch: 18 | Iteration number: [3880/4518] 85% | Training loss: 0.6870881777602372
Epoch: 18 | Iteration number: [3890/4518] 86% | Training loss: 0.6870851713618154
Epoch: 18 | Iteration number: [3900/4518] 86% | Training loss: 0.6870831604187305
Epoch: 18 | Iteration number: [3910/4518] 86% | Training loss: 0.6870825633368529
Epoch: 18 | Iteration number: [3920/4518] 86% | Training loss: 0.6870854415151537
Epoch: 18 | Iteration number: [3930/4518] 86% | Training loss: 0.6870850142935153
Epoch: 18 | Iteration number: [3940/4518] 87% | Training loss: 0.6870835856283982
Epoch: 18 | Iteration number: [3950/4518] 87% | Training loss: 0.6870835112016412
Epoch: 18 | Iteration number: [3960/4518] 87% | Training loss: 0.6870802376005385
Epoch: 18 | Iteration number: [3970/4518] 87% | Training loss: 0.6870815518821216
Epoch: 18 | Iteration number: [3980/4518] 88% | Training loss: 0.6870785754080394
Epoch: 18 | Iteration number: [3990/4518] 88% | Training loss: 0.6870791512623168
Epoch: 18 | Iteration number: [4000/4518] 88% | Training loss: 0.6870772140771151
Epoch: 18 | Iteration number: [4010/4518] 88% | Training loss: 0.6870762820107087
Epoch: 18 | Iteration number: [4020/4518] 88% | Training loss: 0.6870745853849904
Epoch: 18 | Iteration number: [4030/4518] 89% | Training loss: 0.6870788888659134
Epoch: 18 | Iteration number: [4040/4518] 89% | Training loss: 0.6870768377834028
Epoch: 18 | Iteration number: [4050/4518] 89% | Training loss: 0.6870763813271935
Epoch: 18 | Iteration number: [4060/4518] 89% | Training loss: 0.6870747798182107
Epoch: 18 | Iteration number: [4070/4518] 90% | Training loss: 0.687078193452493
Epoch: 18 | Iteration number: [4080/4518] 90% | Training loss: 0.6870769714315732
Epoch: 18 | Iteration number: [4090/4518] 90% | Training loss: 0.6870761184937214
Epoch: 18 | Iteration number: [4100/4518] 90% | Training loss: 0.6870736503891829
Epoch: 18 | Iteration number: [4110/4518] 90% | Training loss: 0.6870752223796798
Epoch: 18 | Iteration number: [4120/4518] 91% | Training loss: 0.6870755760849101
Epoch: 18 | Iteration number: [4130/4518] 91% | Training loss: 0.6870746276136172
Epoch: 18 | Iteration number: [4140/4518] 91% | Training loss: 0.6870733702240359
Epoch: 18 | Iteration number: [4150/4518] 91% | Training loss: 0.6870754574436739
Epoch: 18 | Iteration number: [4160/4518] 92% | Training loss: 0.6870749330004821
Epoch: 18 | Iteration number: [4170/4518] 92% | Training loss: 0.6870711556727366
Epoch: 18 | Iteration number: [4180/4518] 92% | Training loss: 0.6870712857212176
Epoch: 18 | Iteration number: [4190/4518] 92% | Training loss: 0.6870674933055705
Epoch: 18 | Iteration number: [4200/4518] 92% | Training loss: 0.6870649842421214
Epoch: 18 | Iteration number: [4210/4518] 93% | Training loss: 0.6870612336167814
Epoch: 18 | Iteration number: [4220/4518] 93% | Training loss: 0.687060728556172
Epoch: 18 | Iteration number: [4230/4518] 93% | Training loss: 0.6870620344829333
Epoch: 18 | Iteration number: [4240/4518] 93% | Training loss: 0.6870598571902176
Epoch: 18 | Iteration number: [4250/4518] 94% | Training loss: 0.6870578700093662
Epoch: 18 | Iteration number: [4260/4518] 94% | Training loss: 0.6870531907943492
Epoch: 18 | Iteration number: [4270/4518] 94% | Training loss: 0.6870509529141687
Epoch: 18 | Iteration number: [4280/4518] 94% | Training loss: 0.6870528811884817
Epoch: 18 | Iteration number: [4290/4518] 94% | Training loss: 0.6870518960180261
Epoch: 18 | Iteration number: [4300/4518] 95% | Training loss: 0.6870530723832374
Epoch: 18 | Iteration number: [4310/4518] 95% | Training loss: 0.6870530848436732
Epoch: 18 | Iteration number: [4320/4518] 95% | Training loss: 0.6870541088421036
Epoch: 18 | Iteration number: [4330/4518] 95% | Training loss: 0.6870523996083345
Epoch: 18 | Iteration number: [4340/4518] 96% | Training loss: 0.6870486610908113
Epoch: 18 | Iteration number: [4350/4518] 96% | Training loss: 0.6870498824119567
Epoch: 18 | Iteration number: [4360/4518] 96% | Training loss: 0.6870498653398741
Epoch: 18 | Iteration number: [4370/4518] 96% | Training loss: 0.6870494216748724
Epoch: 18 | Iteration number: [4380/4518] 96% | Training loss: 0.6870509799076542
Epoch: 18 | Iteration number: [4390/4518] 97% | Training loss: 0.6870495349779759
Epoch: 18 | Iteration number: [4400/4518] 97% | Training loss: 0.6870506989278576
Epoch: 18 | Iteration number: [4410/4518] 97% | Training loss: 0.6870538708979851
Epoch: 18 | Iteration number: [4420/4518] 97% | Training loss: 0.6870524129986224
Epoch: 18 | Iteration number: [4430/4518] 98% | Training loss: 0.6870550033739404
Epoch: 18 | Iteration number: [4440/4518] 98% | Training loss: 0.6870579331979021
Epoch: 18 | Iteration number: [4450/4518] 98% | Training loss: 0.6870563138200996
Epoch: 18 | Iteration number: [4460/4518] 98% | Training loss: 0.6870554447441357
Epoch: 18 | Iteration number: [4470/4518] 98% | Training loss: 0.6870540757040583
Epoch: 18 | Iteration number: [4480/4518] 99% | Training loss: 0.6870551952693079
Epoch: 18 | Iteration number: [4490/4518] 99% | Training loss: 0.6870572568446331
Epoch: 18 | Iteration number: [4500/4518] 99% | Training loss: 0.6870568488438924
Epoch: 18 | Iteration number: [4510/4518] 99% | Training loss: 0.6870582478405896

 End of epoch: 18 | Train Loss: 0.6869080685682664 | Training Time: 633 

 End of epoch: 18 | Eval Loss: 0.6901065913998351 | Evaluating Time: 17 
Epoch: 19 | Iteration number: [10/4518] 0% | Training loss: 0.7565091550350189
Epoch: 19 | Iteration number: [20/4518] 0% | Training loss: 0.7218993186950684
Epoch: 19 | Iteration number: [30/4518] 0% | Training loss: 0.7101019223531088
Epoch: 19 | Iteration number: [40/4518] 0% | Training loss: 0.7043341130018235
Epoch: 19 | Iteration number: [50/4518] 1% | Training loss: 0.7009247207641601
Epoch: 19 | Iteration number: [60/4518] 1% | Training loss: 0.6985481222470601
Epoch: 19 | Iteration number: [70/4518] 1% | Training loss: 0.6968081653118133
Epoch: 19 | Iteration number: [80/4518] 1% | Training loss: 0.695401006937027
Epoch: 19 | Iteration number: [90/4518] 1% | Training loss: 0.6944783336586422
Epoch: 19 | Iteration number: [100/4518] 2% | Training loss: 0.6937646847963334
Epoch: 19 | Iteration number: [110/4518] 2% | Training loss: 0.6930933107029308
Epoch: 19 | Iteration number: [120/4518] 2% | Training loss: 0.6924383103847503
Epoch: 19 | Iteration number: [130/4518] 2% | Training loss: 0.6920944172602433
Epoch: 19 | Iteration number: [140/4518] 3% | Training loss: 0.6916885393006461
Epoch: 19 | Iteration number: [150/4518] 3% | Training loss: 0.6913577739397685
Epoch: 19 | Iteration number: [160/4518] 3% | Training loss: 0.6910180982202292
Epoch: 19 | Iteration number: [170/4518] 3% | Training loss: 0.6907345000435324
Epoch: 19 | Iteration number: [180/4518] 3% | Training loss: 0.6905326584974925
Epoch: 19 | Iteration number: [190/4518] 4% | Training loss: 0.6903363412932346
Epoch: 19 | Iteration number: [200/4518] 4% | Training loss: 0.6901687499880791
Epoch: 19 | Iteration number: [210/4518] 4% | Training loss: 0.6900497635205587
Epoch: 19 | Iteration number: [220/4518] 4% | Training loss: 0.6899110636927864
Epoch: 19 | Iteration number: [230/4518] 5% | Training loss: 0.6897535391475843
Epoch: 19 | Iteration number: [240/4518] 5% | Training loss: 0.6895607749621073
Epoch: 19 | Iteration number: [250/4518] 5% | Training loss: 0.6894184193611145
Epoch: 19 | Iteration number: [260/4518] 5% | Training loss: 0.689304431126668
Epoch: 19 | Iteration number: [270/4518] 5% | Training loss: 0.6891912893012718
Epoch: 19 | Iteration number: [280/4518] 6% | Training loss: 0.6890882785831179
Epoch: 19 | Iteration number: [290/4518] 6% | Training loss: 0.688999264815758
Epoch: 19 | Iteration number: [300/4518] 6% | Training loss: 0.6889206997553508
Epoch: 19 | Iteration number: [310/4518] 6% | Training loss: 0.6888424861815667
Epoch: 19 | Iteration number: [320/4518] 7% | Training loss: 0.6888165794312954
Epoch: 19 | Iteration number: [330/4518] 7% | Training loss: 0.688764657757499
Epoch: 19 | Iteration number: [340/4518] 7% | Training loss: 0.6887157496284037
Epoch: 19 | Iteration number: [350/4518] 7% | Training loss: 0.688725198166711
Epoch: 19 | Iteration number: [360/4518] 7% | Training loss: 0.6886815425422457
Epoch: 19 | Iteration number: [370/4518] 8% | Training loss: 0.6886319617967348
Epoch: 19 | Iteration number: [380/4518] 8% | Training loss: 0.6885793103983527
Epoch: 19 | Iteration number: [390/4518] 8% | Training loss: 0.6885392974584531
Epoch: 19 | Iteration number: [400/4518] 8% | Training loss: 0.6885078413784504
Epoch: 19 | Iteration number: [410/4518] 9% | Training loss: 0.6884593505684923
Epoch: 19 | Iteration number: [420/4518] 9% | Training loss: 0.688412460117113
Epoch: 19 | Iteration number: [430/4518] 9% | Training loss: 0.6883722240148589
Epoch: 19 | Iteration number: [440/4518] 9% | Training loss: 0.6883399532599883
Epoch: 19 | Iteration number: [450/4518] 9% | Training loss: 0.6882957598898146
Epoch: 19 | Iteration number: [460/4518] 10% | Training loss: 0.688263908158178
Epoch: 19 | Iteration number: [470/4518] 10% | Training loss: 0.6882161288819415
Epoch: 19 | Iteration number: [480/4518] 10% | Training loss: 0.6881771743297577
Epoch: 19 | Iteration number: [490/4518] 10% | Training loss: 0.6881557602055218
Epoch: 19 | Iteration number: [500/4518] 11% | Training loss: 0.6881208698749542
Epoch: 19 | Iteration number: [510/4518] 11% | Training loss: 0.6881130155395059
Epoch: 19 | Iteration number: [520/4518] 11% | Training loss: 0.6881011682061049
Epoch: 19 | Iteration number: [530/4518] 11% | Training loss: 0.6880518554516558
Epoch: 19 | Iteration number: [540/4518] 11% | Training loss: 0.6880239546298981
Epoch: 19 | Iteration number: [550/4518] 12% | Training loss: 0.6880034188790755
Epoch: 19 | Iteration number: [560/4518] 12% | Training loss: 0.6879879241543156
Epoch: 19 | Iteration number: [570/4518] 12% | Training loss: 0.6879892884639272
Epoch: 19 | Iteration number: [580/4518] 12% | Training loss: 0.687995177918467
Epoch: 19 | Iteration number: [590/4518] 13% | Training loss: 0.6879865088705289
Epoch: 19 | Iteration number: [600/4518] 13% | Training loss: 0.687966871658961
Epoch: 19 | Iteration number: [610/4518] 13% | Training loss: 0.6879394253746408
Epoch: 19 | Iteration number: [620/4518] 13% | Training loss: 0.6879288605143947
Epoch: 19 | Iteration number: [630/4518] 13% | Training loss: 0.6879009665950896
Epoch: 19 | Iteration number: [640/4518] 14% | Training loss: 0.6878848679363727
Epoch: 19 | Iteration number: [650/4518] 14% | Training loss: 0.6878897159833175
Epoch: 19 | Iteration number: [660/4518] 14% | Training loss: 0.6878805087371306
Epoch: 19 | Iteration number: [670/4518] 14% | Training loss: 0.6878764396283163
Epoch: 19 | Iteration number: [680/4518] 15% | Training loss: 0.687855407157365
Epoch: 19 | Iteration number: [690/4518] 15% | Training loss: 0.6878329419571421
Epoch: 19 | Iteration number: [700/4518] 15% | Training loss: 0.6878105274268559
Epoch: 19 | Iteration number: [710/4518] 15% | Training loss: 0.6877968989627462
Epoch: 19 | Iteration number: [720/4518] 15% | Training loss: 0.6877922428978814
Epoch: 19 | Iteration number: [730/4518] 16% | Training loss: 0.6877781558526705
Epoch: 19 | Iteration number: [740/4518] 16% | Training loss: 0.6877620448131819
Epoch: 19 | Iteration number: [750/4518] 16% | Training loss: 0.6877371625900268
Epoch: 19 | Iteration number: [760/4518] 16% | Training loss: 0.6877239617077928
Epoch: 19 | Iteration number: [770/4518] 17% | Training loss: 0.687712703974216
Epoch: 19 | Iteration number: [780/4518] 17% | Training loss: 0.6877002886472604
Epoch: 19 | Iteration number: [790/4518] 17% | Training loss: 0.6876953880243664
Epoch: 19 | Iteration number: [800/4518] 17% | Training loss: 0.6876740318536758
Epoch: 19 | Iteration number: [810/4518] 17% | Training loss: 0.6876780594572609
Epoch: 19 | Iteration number: [820/4518] 18% | Training loss: 0.6876722825009648
Epoch: 19 | Iteration number: [830/4518] 18% | Training loss: 0.6876508254602731
Epoch: 19 | Iteration number: [840/4518] 18% | Training loss: 0.6876446237166722
Epoch: 19 | Iteration number: [850/4518] 18% | Training loss: 0.6876247174599591
Epoch: 19 | Iteration number: [860/4518] 19% | Training loss: 0.6876217581505
Epoch: 19 | Iteration number: [870/4518] 19% | Training loss: 0.687616616487503
Epoch: 19 | Iteration number: [880/4518] 19% | Training loss: 0.6876039492135698
Epoch: 19 | Iteration number: [890/4518] 19% | Training loss: 0.6875946591409404
Epoch: 19 | Iteration number: [900/4518] 19% | Training loss: 0.6875889068841934
Epoch: 19 | Iteration number: [910/4518] 20% | Training loss: 0.687578814959788
Epoch: 19 | Iteration number: [920/4518] 20% | Training loss: 0.6875659597956616
Epoch: 19 | Iteration number: [930/4518] 20% | Training loss: 0.6875530560170451
Epoch: 19 | Iteration number: [940/4518] 20% | Training loss: 0.6875338225922686
Epoch: 19 | Iteration number: [950/4518] 21% | Training loss: 0.6875181380071138
Epoch: 19 | Iteration number: [960/4518] 21% | Training loss: 0.6875056649868687
Epoch: 19 | Iteration number: [970/4518] 21% | Training loss: 0.6875029258506814
Epoch: 19 | Iteration number: [980/4518] 21% | Training loss: 0.6874927025668475
Epoch: 19 | Iteration number: [990/4518] 21% | Training loss: 0.687493375515697
Epoch: 19 | Iteration number: [1000/4518] 22% | Training loss: 0.6874968066215515
Epoch: 19 | Iteration number: [1010/4518] 22% | Training loss: 0.6874900322149295
Epoch: 19 | Iteration number: [1020/4518] 22% | Training loss: 0.6874930664020427
Epoch: 19 | Iteration number: [1030/4518] 22% | Training loss: 0.6874768699257119
Epoch: 19 | Iteration number: [1040/4518] 23% | Training loss: 0.6874665902784237
Epoch: 19 | Iteration number: [1050/4518] 23% | Training loss: 0.6874531412692297
Epoch: 19 | Iteration number: [1060/4518] 23% | Training loss: 0.6874544779647072
Epoch: 19 | Iteration number: [1070/4518] 23% | Training loss: 0.6874549548202586
Epoch: 19 | Iteration number: [1080/4518] 23% | Training loss: 0.6874524232965928
Epoch: 19 | Iteration number: [1090/4518] 24% | Training loss: 0.6874397854739372
Epoch: 19 | Iteration number: [1100/4518] 24% | Training loss: 0.6874357769164172
Epoch: 19 | Iteration number: [1110/4518] 24% | Training loss: 0.6874320349714778
Epoch: 19 | Iteration number: [1120/4518] 24% | Training loss: 0.6874212972819805
Epoch: 19 | Iteration number: [1130/4518] 25% | Training loss: 0.6874223497061602
Epoch: 19 | Iteration number: [1140/4518] 25% | Training loss: 0.6874160329500835
Epoch: 19 | Iteration number: [1150/4518] 25% | Training loss: 0.6874150855126588
Epoch: 19 | Iteration number: [1160/4518] 25% | Training loss: 0.6874157331113158
Epoch: 19 | Iteration number: [1170/4518] 25% | Training loss: 0.6874216633474725
Epoch: 19 | Iteration number: [1180/4518] 26% | Training loss: 0.6874151055590582
Epoch: 19 | Iteration number: [1190/4518] 26% | Training loss: 0.6874092325943859
Epoch: 19 | Iteration number: [1200/4518] 26% | Training loss: 0.6874101916948955
Epoch: 19 | Iteration number: [1210/4518] 26% | Training loss: 0.6874068196647424
Epoch: 19 | Iteration number: [1220/4518] 27% | Training loss: 0.6873972454520523
Epoch: 19 | Iteration number: [1230/4518] 27% | Training loss: 0.6873914150687738
Epoch: 19 | Iteration number: [1240/4518] 27% | Training loss: 0.687391145911909
Epoch: 19 | Iteration number: [1250/4518] 27% | Training loss: 0.6873845522403716
Epoch: 19 | Iteration number: [1260/4518] 27% | Training loss: 0.687385311817366
Epoch: 19 | Iteration number: [1270/4518] 28% | Training loss: 0.6873878904684322
Epoch: 19 | Iteration number: [1280/4518] 28% | Training loss: 0.6873785137198866
Epoch: 19 | Iteration number: [1290/4518] 28% | Training loss: 0.6873752735843954
Epoch: 19 | Iteration number: [1300/4518] 28% | Training loss: 0.6873788167880132
Epoch: 19 | Iteration number: [1310/4518] 28% | Training loss: 0.6873707320398956
Epoch: 19 | Iteration number: [1320/4518] 29% | Training loss: 0.6873729329217564
Epoch: 19 | Iteration number: [1330/4518] 29% | Training loss: 0.6873661126409258
Epoch: 19 | Iteration number: [1340/4518] 29% | Training loss: 0.6873559245422705
Epoch: 19 | Iteration number: [1350/4518] 29% | Training loss: 0.6873582052742994
Epoch: 19 | Iteration number: [1360/4518] 30% | Training loss: 0.6873570695957717
Epoch: 19 | Iteration number: [1370/4518] 30% | Training loss: 0.6873556715728593
Epoch: 19 | Iteration number: [1380/4518] 30% | Training loss: 0.6873412673456082
Epoch: 19 | Iteration number: [1390/4518] 30% | Training loss: 0.6873402207875423
Epoch: 19 | Iteration number: [1400/4518] 30% | Training loss: 0.687329264155456
Epoch: 19 | Iteration number: [1410/4518] 31% | Training loss: 0.6873196042598562
Epoch: 19 | Iteration number: [1420/4518] 31% | Training loss: 0.6873201802582808
Epoch: 19 | Iteration number: [1430/4518] 31% | Training loss: 0.6873143599166737
Epoch: 19 | Iteration number: [1440/4518] 31% | Training loss: 0.687317787648903
Epoch: 19 | Iteration number: [1450/4518] 32% | Training loss: 0.6873203095485424
Epoch: 19 | Iteration number: [1460/4518] 32% | Training loss: 0.687315681658379
Epoch: 19 | Iteration number: [1470/4518] 32% | Training loss: 0.6873080421467217
Epoch: 19 | Iteration number: [1480/4518] 32% | Training loss: 0.6873094134234093
Epoch: 19 | Iteration number: [1490/4518] 32% | Training loss: 0.6873034572841337
Epoch: 19 | Iteration number: [1500/4518] 33% | Training loss: 0.6873077077468236
Epoch: 19 | Iteration number: [1510/4518] 33% | Training loss: 0.6873081228590959
Epoch: 19 | Iteration number: [1520/4518] 33% | Training loss: 0.687309966040285
Epoch: 19 | Iteration number: [1530/4518] 33% | Training loss: 0.6873061466840358
Epoch: 19 | Iteration number: [1540/4518] 34% | Training loss: 0.6872969639378709
Epoch: 19 | Iteration number: [1550/4518] 34% | Training loss: 0.68728531825927
Epoch: 19 | Iteration number: [1560/4518] 34% | Training loss: 0.6872830895659251
Epoch: 19 | Iteration number: [1570/4518] 34% | Training loss: 0.6872750775449595
Epoch: 19 | Iteration number: [1580/4518] 34% | Training loss: 0.6872721974608265
Epoch: 19 | Iteration number: [1590/4518] 35% | Training loss: 0.6872685472545383
Epoch: 19 | Iteration number: [1600/4518] 35% | Training loss: 0.6872679521888494
Epoch: 19 | Iteration number: [1610/4518] 35% | Training loss: 0.6872642973194951
Epoch: 19 | Iteration number: [1620/4518] 35% | Training loss: 0.6872609386841456
Epoch: 19 | Iteration number: [1630/4518] 36% | Training loss: 0.6872566589548544
Epoch: 19 | Iteration number: [1640/4518] 36% | Training loss: 0.6872521541467527
Epoch: 19 | Iteration number: [1650/4518] 36% | Training loss: 0.6872572187943892
Epoch: 19 | Iteration number: [1660/4518] 36% | Training loss: 0.687255067638604
Epoch: 19 | Iteration number: [1670/4518] 36% | Training loss: 0.6872503946641249
Epoch: 19 | Iteration number: [1680/4518] 37% | Training loss: 0.6872501156869388
Epoch: 19 | Iteration number: [1690/4518] 37% | Training loss: 0.6872448732161663
Epoch: 19 | Iteration number: [1700/4518] 37% | Training loss: 0.6872441924670163
Epoch: 19 | Iteration number: [1710/4518] 37% | Training loss: 0.6872388538561369
Epoch: 19 | Iteration number: [1720/4518] 38% | Training loss: 0.6872281748195027
Epoch: 19 | Iteration number: [1730/4518] 38% | Training loss: 0.6872336964731272
Epoch: 19 | Iteration number: [1740/4518] 38% | Training loss: 0.6872287335409515
Epoch: 19 | Iteration number: [1750/4518] 38% | Training loss: 0.6872247396537235
Epoch: 19 | Iteration number: [1760/4518] 38% | Training loss: 0.6872283082116734
Epoch: 19 | Iteration number: [1770/4518] 39% | Training loss: 0.6872310959349918
Epoch: 19 | Iteration number: [1780/4518] 39% | Training loss: 0.6872310882538892
Epoch: 19 | Iteration number: [1790/4518] 39% | Training loss: 0.6872320169177135
Epoch: 19 | Iteration number: [1800/4518] 39% | Training loss: 0.6872261266244782
Epoch: 19 | Iteration number: [1810/4518] 40% | Training loss: 0.6872347759607748
Epoch: 19 | Iteration number: [1820/4518] 40% | Training loss: 0.6872353566216899
Epoch: 19 | Iteration number: [1830/4518] 40% | Training loss: 0.6872273852264946
Epoch: 19 | Iteration number: [1840/4518] 40% | Training loss: 0.6872234399551931
Epoch: 19 | Iteration number: [1850/4518] 40% | Training loss: 0.687221910212491
Epoch: 19 | Iteration number: [1860/4518] 41% | Training loss: 0.6872181941424647
Epoch: 19 | Iteration number: [1870/4518] 41% | Training loss: 0.6872206545768574
Epoch: 19 | Iteration number: [1880/4518] 41% | Training loss: 0.6872188668301765
Epoch: 19 | Iteration number: [1890/4518] 41% | Training loss: 0.6872083988454607
Epoch: 19 | Iteration number: [1900/4518] 42% | Training loss: 0.6872114560478612
Epoch: 19 | Iteration number: [1910/4518] 42% | Training loss: 0.6872059401417278
Epoch: 19 | Iteration number: [1920/4518] 42% | Training loss: 0.6872086986278494
Epoch: 19 | Iteration number: [1930/4518] 42% | Training loss: 0.6872094439410175
Epoch: 19 | Iteration number: [1940/4518] 42% | Training loss: 0.6872064349270358
Epoch: 19 | Iteration number: [1950/4518] 43% | Training loss: 0.6871972911174481
Epoch: 19 | Iteration number: [1960/4518] 43% | Training loss: 0.6871938740112343
Epoch: 19 | Iteration number: [1970/4518] 43% | Training loss: 0.6871860207034852
Epoch: 19 | Iteration number: [1980/4518] 43% | Training loss: 0.6871909960050776
Epoch: 19 | Iteration number: [1990/4518] 44% | Training loss: 0.687187572579887
Epoch: 19 | Iteration number: [2000/4518] 44% | Training loss: 0.6871905430853367
Epoch: 19 | Iteration number: [2010/4518] 44% | Training loss: 0.6871873099412491
Epoch: 19 | Iteration number: [2020/4518] 44% | Training loss: 0.6871928545212982
Epoch: 19 | Iteration number: [2030/4518] 44% | Training loss: 0.6871876701639203
Epoch: 19 | Iteration number: [2040/4518] 45% | Training loss: 0.6871799624725884
Epoch: 19 | Iteration number: [2050/4518] 45% | Training loss: 0.6871748831795483
Epoch: 19 | Iteration number: [2060/4518] 45% | Training loss: 0.6871725617971235
Epoch: 19 | Iteration number: [2070/4518] 45% | Training loss: 0.6871669557647428
Epoch: 19 | Iteration number: [2080/4518] 46% | Training loss: 0.6871580746311408
Epoch: 19 | Iteration number: [2090/4518] 46% | Training loss: 0.6871643434871327
Epoch: 19 | Iteration number: [2100/4518] 46% | Training loss: 0.6871642101094836
Epoch: 19 | Iteration number: [2110/4518] 46% | Training loss: 0.6871604132426293
Epoch: 19 | Iteration number: [2120/4518] 46% | Training loss: 0.6871613547205925
Epoch: 19 | Iteration number: [2130/4518] 47% | Training loss: 0.6871605883461769
Epoch: 19 | Iteration number: [2140/4518] 47% | Training loss: 0.6871622501689697
Epoch: 19 | Iteration number: [2150/4518] 47% | Training loss: 0.6871654468913411
Epoch: 19 | Iteration number: [2160/4518] 47% | Training loss: 0.68715819561923
Epoch: 19 | Iteration number: [2170/4518] 48% | Training loss: 0.6871569292061889
Epoch: 19 | Iteration number: [2180/4518] 48% | Training loss: 0.6871515290999631
Epoch: 19 | Iteration number: [2190/4518] 48% | Training loss: 0.6871478464777612
Epoch: 19 | Iteration number: [2200/4518] 48% | Training loss: 0.6871478141166947
Epoch: 19 | Iteration number: [2210/4518] 48% | Training loss: 0.6871457559220931
Epoch: 19 | Iteration number: [2220/4518] 49% | Training loss: 0.6871463210733088
Epoch: 19 | Iteration number: [2230/4518] 49% | Training loss: 0.6871417153576564
Epoch: 19 | Iteration number: [2240/4518] 49% | Training loss: 0.687136297806033
Epoch: 19 | Iteration number: [2250/4518] 49% | Training loss: 0.6871330223613316
Epoch: 19 | Iteration number: [2260/4518] 50% | Training loss: 0.6871320148748634
Epoch: 19 | Iteration number: [2270/4518] 50% | Training loss: 0.6871327794858537
Epoch: 19 | Iteration number: [2280/4518] 50% | Training loss: 0.6871286946953389
Epoch: 19 | Iteration number: [2290/4518] 50% | Training loss: 0.6871252638023493
Epoch: 19 | Iteration number: [2300/4518] 50% | Training loss: 0.6871228516879289
Epoch: 19 | Iteration number: [2310/4518] 51% | Training loss: 0.6871193125392452
Epoch: 19 | Iteration number: [2320/4518] 51% | Training loss: 0.6871182866651436
Epoch: 19 | Iteration number: [2330/4518] 51% | Training loss: 0.6871137862809227
Epoch: 19 | Iteration number: [2340/4518] 51% | Training loss: 0.6871120928189693
Epoch: 19 | Iteration number: [2350/4518] 52% | Training loss: 0.6871110764462897
Epoch: 19 | Iteration number: [2360/4518] 52% | Training loss: 0.6871099245497736
Epoch: 19 | Iteration number: [2370/4518] 52% | Training loss: 0.687112593852015
Epoch: 19 | Iteration number: [2380/4518] 52% | Training loss: 0.687111268674626
Epoch: 19 | Iteration number: [2390/4518] 52% | Training loss: 0.687109606685
Epoch: 19 | Iteration number: [2400/4518] 53% | Training loss: 0.6871116751432419
Epoch: 19 | Iteration number: [2410/4518] 53% | Training loss: 0.6871101364060557
Epoch: 19 | Iteration number: [2420/4518] 53% | Training loss: 0.6871080082310133
Epoch: 19 | Iteration number: [2430/4518] 53% | Training loss: 0.6871045544314286
Epoch: 19 | Iteration number: [2440/4518] 54% | Training loss: 0.68710826906513
Epoch: 19 | Iteration number: [2450/4518] 54% | Training loss: 0.6871107119686749
Epoch: 19 | Iteration number: [2460/4518] 54% | Training loss: 0.6871139795557271
Epoch: 19 | Iteration number: [2470/4518] 54% | Training loss: 0.6871114192703958
Epoch: 19 | Iteration number: [2480/4518] 54% | Training loss: 0.6871138399647129
Epoch: 19 | Iteration number: [2490/4518] 55% | Training loss: 0.6871130043483642
Epoch: 19 | Iteration number: [2500/4518] 55% | Training loss: 0.6871141526699066
Epoch: 19 | Iteration number: [2510/4518] 55% | Training loss: 0.6871126375350344
Epoch: 19 | Iteration number: [2520/4518] 55% | Training loss: 0.68710888531946
Epoch: 19 | Iteration number: [2530/4518] 55% | Training loss: 0.6871082164788905
Epoch: 19 | Iteration number: [2540/4518] 56% | Training loss: 0.687103723869549
Epoch: 19 | Iteration number: [2550/4518] 56% | Training loss: 0.6871104518338745
Epoch: 19 | Iteration number: [2560/4518] 56% | Training loss: 0.6871068729786203
Epoch: 19 | Iteration number: [2570/4518] 56% | Training loss: 0.6871107161972774
Epoch: 19 | Iteration number: [2580/4518] 57% | Training loss: 0.6871089462624039
Epoch: 19 | Iteration number: [2590/4518] 57% | Training loss: 0.6871076991889468
Epoch: 19 | Iteration number: [2600/4518] 57% | Training loss: 0.6871054998498697
Epoch: 19 | Iteration number: [2610/4518] 57% | Training loss: 0.6871065345303765
Epoch: 19 | Iteration number: [2620/4518] 57% | Training loss: 0.6871012892431885
Epoch: 19 | Iteration number: [2630/4518] 58% | Training loss: 0.6870945267124321
Epoch: 19 | Iteration number: [2640/4518] 58% | Training loss: 0.6871009602916963
Epoch: 19 | Iteration number: [2650/4518] 58% | Training loss: 0.6870983165390087
Epoch: 19 | Iteration number: [2660/4518] 58% | Training loss: 0.687097904735938
Epoch: 19 | Iteration number: [2670/4518] 59% | Training loss: 0.6870987263734868
Epoch: 19 | Iteration number: [2680/4518] 59% | Training loss: 0.6871050849556923
Epoch: 19 | Iteration number: [2690/4518] 59% | Training loss: 0.6871029814601388
Epoch: 19 | Iteration number: [2700/4518] 59% | Training loss: 0.6871016072785413
Epoch: 19 | Iteration number: [2710/4518] 59% | Training loss: 0.6871016441236123
Epoch: 19 | Iteration number: [2720/4518] 60% | Training loss: 0.68710519809495
Epoch: 19 | Iteration number: [2730/4518] 60% | Training loss: 0.6871076068817041
Epoch: 19 | Iteration number: [2740/4518] 60% | Training loss: 0.687106906018988
Epoch: 19 | Iteration number: [2750/4518] 60% | Training loss: 0.6871100624041124
Epoch: 19 | Iteration number: [2760/4518] 61% | Training loss: 0.6871123656414557
Epoch: 19 | Iteration number: [2770/4518] 61% | Training loss: 0.6871098696970337
Epoch: 19 | Iteration number: [2780/4518] 61% | Training loss: 0.687103872740869
Epoch: 19 | Iteration number: [2790/4518] 61% | Training loss: 0.6871023569483057
Epoch: 19 | Iteration number: [2800/4518] 61% | Training loss: 0.6871019274847848
Epoch: 19 | Iteration number: [2810/4518] 62% | Training loss: 0.6871022910834207
Epoch: 19 | Iteration number: [2820/4518] 62% | Training loss: 0.6871001336591464
Epoch: 19 | Iteration number: [2830/4518] 62% | Training loss: 0.6870944253968687
Epoch: 19 | Iteration number: [2840/4518] 62% | Training loss: 0.6870890250298339
Epoch: 19 | Iteration number: [2850/4518] 63% | Training loss: 0.687082213121548
Epoch: 19 | Iteration number: [2860/4518] 63% | Training loss: 0.6870787203103512
Epoch: 19 | Iteration number: [2870/4518] 63% | Training loss: 0.6870784137514826
Epoch: 19 | Iteration number: [2880/4518] 63% | Training loss: 0.687079517584708
Epoch: 19 | Iteration number: [2890/4518] 63% | Training loss: 0.6870840538744283
Epoch: 19 | Iteration number: [2900/4518] 64% | Training loss: 0.6870825378031566
Epoch: 19 | Iteration number: [2910/4518] 64% | Training loss: 0.6870834338091493
Epoch: 19 | Iteration number: [2920/4518] 64% | Training loss: 0.6870813931912592
Epoch: 19 | Iteration number: [2930/4518] 64% | Training loss: 0.6870778668659132
Epoch: 19 | Iteration number: [2940/4518] 65% | Training loss: 0.6870745478438682
Epoch: 19 | Iteration number: [2950/4518] 65% | Training loss: 0.6870695348311279
Epoch: 19 | Iteration number: [2960/4518] 65% | Training loss: 0.6870692141152717
Epoch: 19 | Iteration number: [2970/4518] 65% | Training loss: 0.6870685519995513
Epoch: 19 | Iteration number: [2980/4518] 65% | Training loss: 0.6870689793921158
Epoch: 19 | Iteration number: [2990/4518] 66% | Training loss: 0.6870712675777167
Epoch: 19 | Iteration number: [3000/4518] 66% | Training loss: 0.6870686707496643
Epoch: 19 | Iteration number: [3010/4518] 66% | Training loss: 0.6870685639175466
Epoch: 19 | Iteration number: [3020/4518] 66% | Training loss: 0.6870687751185816
Epoch: 19 | Iteration number: [3030/4518] 67% | Training loss: 0.687069555084304
Epoch: 19 | Iteration number: [3040/4518] 67% | Training loss: 0.6870687362394835
Epoch: 19 | Iteration number: [3050/4518] 67% | Training loss: 0.6870658498318469
Epoch: 19 | Iteration number: [3060/4518] 67% | Training loss: 0.6870643086682737
Epoch: 19 | Iteration number: [3070/4518] 67% | Training loss: 0.6870597435713591
Epoch: 19 | Iteration number: [3080/4518] 68% | Training loss: 0.6870592945001343
Epoch: 19 | Iteration number: [3090/4518] 68% | Training loss: 0.6870580436149462
Epoch: 19 | Iteration number: [3100/4518] 68% | Training loss: 0.687053786170098
Epoch: 19 | Iteration number: [3110/4518] 68% | Training loss: 0.6870535768113336
Epoch: 19 | Iteration number: [3120/4518] 69% | Training loss: 0.6870505646253243
Epoch: 19 | Iteration number: [3130/4518] 69% | Training loss: 0.6870538010764807
Epoch: 19 | Iteration number: [3140/4518] 69% | Training loss: 0.6870475702794494
Epoch: 19 | Iteration number: [3150/4518] 69% | Training loss: 0.6870470506047446
Epoch: 19 | Iteration number: [3160/4518] 69% | Training loss: 0.6870493995992443
Epoch: 19 | Iteration number: [3170/4518] 70% | Training loss: 0.6870490116275824
Epoch: 19 | Iteration number: [3180/4518] 70% | Training loss: 0.6870489332660938
Epoch: 19 | Iteration number: [3190/4518] 70% | Training loss: 0.6870470086795782
Epoch: 19 | Iteration number: [3200/4518] 70% | Training loss: 0.6870473764464259
Epoch: 19 | Iteration number: [3210/4518] 71% | Training loss: 0.6870505718798652
Epoch: 19 | Iteration number: [3220/4518] 71% | Training loss: 0.6870500895177355
Epoch: 19 | Iteration number: [3230/4518] 71% | Training loss: 0.687049671057208
Epoch: 19 | Iteration number: [3240/4518] 71% | Training loss: 0.6870497047717189
Epoch: 19 | Iteration number: [3250/4518] 71% | Training loss: 0.6870468403926262
Epoch: 19 | Iteration number: [3260/4518] 72% | Training loss: 0.6870447073977418
Epoch: 19 | Iteration number: [3270/4518] 72% | Training loss: 0.6870445513944013
Epoch: 19 | Iteration number: [3280/4518] 72% | Training loss: 0.6870421892986065
Epoch: 19 | Iteration number: [3290/4518] 72% | Training loss: 0.6870417509941344
Epoch: 19 | Iteration number: [3300/4518] 73% | Training loss: 0.6870439898064642
Epoch: 19 | Iteration number: [3310/4518] 73% | Training loss: 0.6870453427385348
Epoch: 19 | Iteration number: [3320/4518] 73% | Training loss: 0.6870482983897968
Epoch: 19 | Iteration number: [3330/4518] 73% | Training loss: 0.687052049328973
Epoch: 19 | Iteration number: [3340/4518] 73% | Training loss: 0.6870478207479694
Epoch: 19 | Iteration number: [3350/4518] 74% | Training loss: 0.6870484772191119
Epoch: 19 | Iteration number: [3360/4518] 74% | Training loss: 0.687046383906688
Epoch: 19 | Iteration number: [3370/4518] 74% | Training loss: 0.6870464643667996
Epoch: 19 | Iteration number: [3380/4518] 74% | Training loss: 0.6870481400094794
Epoch: 19 | Iteration number: [3390/4518] 75% | Training loss: 0.6870498958062985
Epoch: 19 | Iteration number: [3400/4518] 75% | Training loss: 0.6870479932076791
Epoch: 19 | Iteration number: [3410/4518] 75% | Training loss: 0.6870491868414836
Epoch: 19 | Iteration number: [3420/4518] 75% | Training loss: 0.6870453987030956
Epoch: 19 | Iteration number: [3430/4518] 75% | Training loss: 0.6870480994962742
Epoch: 19 | Iteration number: [3440/4518] 76% | Training loss: 0.6870504107412904
Epoch: 19 | Iteration number: [3450/4518] 76% | Training loss: 0.6870522489236749
Epoch: 19 | Iteration number: [3460/4518] 76% | Training loss: 0.6870515860574093
Epoch: 19 | Iteration number: [3470/4518] 76% | Training loss: 0.6870538241238003
Epoch: 19 | Iteration number: [3480/4518] 77% | Training loss: 0.6870531732323526
Epoch: 19 | Iteration number: [3490/4518] 77% | Training loss: 0.6870527638576093
Epoch: 19 | Iteration number: [3500/4518] 77% | Training loss: 0.6870521592072079
Epoch: 19 | Iteration number: [3510/4518] 77% | Training loss: 0.6870528808855942
Epoch: 19 | Iteration number: [3520/4518] 77% | Training loss: 0.6870544054460797
Epoch: 19 | Iteration number: [3530/4518] 78% | Training loss: 0.6870557756498245
Epoch: 19 | Iteration number: [3540/4518] 78% | Training loss: 0.6870555015943818
Epoch: 19 | Iteration number: [3550/4518] 78% | Training loss: 0.6870586837849146
Epoch: 19 | Iteration number: [3560/4518] 78% | Training loss: 0.6870562090465192
Epoch: 19 | Iteration number: [3570/4518] 79% | Training loss: 0.6870556002738429
Epoch: 19 | Iteration number: [3580/4518] 79% | Training loss: 0.6870511038509827
Epoch: 19 | Iteration number: [3590/4518] 79% | Training loss: 0.687051363774993
Epoch: 19 | Iteration number: [3600/4518] 79% | Training loss: 0.6870520555476347
Epoch: 19 | Iteration number: [3610/4518] 79% | Training loss: 0.6870509632076253
Epoch: 19 | Iteration number: [3620/4518] 80% | Training loss: 0.6870471922567536
Epoch: 19 | Iteration number: [3630/4518] 80% | Training loss: 0.6870478865857295
Epoch: 19 | Iteration number: [3640/4518] 80% | Training loss: 0.6870456993088617
Epoch: 19 | Iteration number: [3650/4518] 80% | Training loss: 0.6870446446987047
Epoch: 19 | Iteration number: [3660/4518] 81% | Training loss: 0.6870443558269511
Epoch: 19 | Iteration number: [3670/4518] 81% | Training loss: 0.6870453729778935
Epoch: 19 | Iteration number: [3680/4518] 81% | Training loss: 0.6870464560454307
Epoch: 19 | Iteration number: [3690/4518] 81% | Training loss: 0.6870463036586275
Epoch: 19 | Iteration number: [3700/4518] 81% | Training loss: 0.6870444469516341
Epoch: 19 | Iteration number: [3710/4518] 82% | Training loss: 0.6870435878272969
Epoch: 19 | Iteration number: [3720/4518] 82% | Training loss: 0.6870424736411341
Epoch: 19 | Iteration number: [3730/4518] 82% | Training loss: 0.6870458925057992
Epoch: 19 | Iteration number: [3740/4518] 82% | Training loss: 0.6870442968479452
Epoch: 19 | Iteration number: [3750/4518] 83% | Training loss: 0.6870437327861786
Epoch: 19 | Iteration number: [3760/4518] 83% | Training loss: 0.687044099971969
Epoch: 19 | Iteration number: [3770/4518] 83% | Training loss: 0.6870446317233837
Epoch: 19 | Iteration number: [3780/4518] 83% | Training loss: 0.6870460656900255
Epoch: 19 | Iteration number: [3790/4518] 83% | Training loss: 0.6870450809951822
Epoch: 19 | Iteration number: [3800/4518] 84% | Training loss: 0.6870471482057321
Epoch: 19 | Iteration number: [3810/4518] 84% | Training loss: 0.687048731544825
Epoch: 19 | Iteration number: [3820/4518] 84% | Training loss: 0.6870492106644895
Epoch: 19 | Iteration number: [3830/4518] 84% | Training loss: 0.6870482976691841
Epoch: 19 | Iteration number: [3840/4518] 84% | Training loss: 0.6870490738190711
Epoch: 19 | Iteration number: [3850/4518] 85% | Training loss: 0.6870503549297134
Epoch: 19 | Iteration number: [3860/4518] 85% | Training loss: 0.6870476489240024
Epoch: 19 | Iteration number: [3870/4518] 85% | Training loss: 0.6870444405140494
Epoch: 19 | Iteration number: [3880/4518] 85% | Training loss: 0.6870462816093386
Epoch: 19 | Iteration number: [3890/4518] 86% | Training loss: 0.6870446182768265
Epoch: 19 | Iteration number: [3900/4518] 86% | Training loss: 0.6870417506878193
Epoch: 19 | Iteration number: [3910/4518] 86% | Training loss: 0.6870395291491848
Epoch: 19 | Iteration number: [3920/4518] 86% | Training loss: 0.6870406761917532
Epoch: 19 | Iteration number: [3930/4518] 86% | Training loss: 0.6870381187998308
Epoch: 19 | Iteration number: [3940/4518] 87% | Training loss: 0.6870420827024479
Epoch: 19 | Iteration number: [3950/4518] 87% | Training loss: 0.6870401315900344
Epoch: 19 | Iteration number: [3960/4518] 87% | Training loss: 0.6870414382731072
Epoch: 19 | Iteration number: [3970/4518] 87% | Training loss: 0.6870418143963033
Epoch: 19 | Iteration number: [3980/4518] 88% | Training loss: 0.687042925795119
Epoch: 19 | Iteration number: [3990/4518] 88% | Training loss: 0.6870426794341333
Epoch: 19 | Iteration number: [4000/4518] 88% | Training loss: 0.687043515264988
Epoch: 19 | Iteration number: [4010/4518] 88% | Training loss: 0.6870421580394307
Epoch: 19 | Iteration number: [4020/4518] 88% | Training loss: 0.6870439717573906
Epoch: 19 | Iteration number: [4030/4518] 89% | Training loss: 0.6870446750750908
Epoch: 19 | Iteration number: [4040/4518] 89% | Training loss: 0.6870401253499607
Epoch: 19 | Iteration number: [4050/4518] 89% | Training loss: 0.6870373257001241
Epoch: 19 | Iteration number: [4060/4518] 89% | Training loss: 0.6870328864734161
Epoch: 19 | Iteration number: [4070/4518] 90% | Training loss: 0.6870312629665731
Epoch: 19 | Iteration number: [4080/4518] 90% | Training loss: 0.6870326023767976
Epoch: 19 | Iteration number: [4090/4518] 90% | Training loss: 0.687033578819051
Epoch: 19 | Iteration number: [4100/4518] 90% | Training loss: 0.6870311801462639
Epoch: 19 | Iteration number: [4110/4518] 90% | Training loss: 0.6870319164727436
Epoch: 19 | Iteration number: [4120/4518] 91% | Training loss: 0.6870342263897646
Epoch: 19 | Iteration number: [4130/4518] 91% | Training loss: 0.6870360085808336
Epoch: 19 | Iteration number: [4140/4518] 91% | Training loss: 0.6870400810587234
Epoch: 19 | Iteration number: [4150/4518] 91% | Training loss: 0.6870392968281206
Epoch: 19 | Iteration number: [4160/4518] 92% | Training loss: 0.6870384603308943
Epoch: 19 | Iteration number: [4170/4518] 92% | Training loss: 0.6870387220840088
Epoch: 19 | Iteration number: [4180/4518] 92% | Training loss: 0.6870368491662177
Epoch: 19 | Iteration number: [4190/4518] 92% | Training loss: 0.6870389988428084
Epoch: 19 | Iteration number: [4200/4518] 92% | Training loss: 0.6870417741082964
Epoch: 19 | Iteration number: [4210/4518] 93% | Training loss: 0.6870404329407527
Epoch: 19 | Iteration number: [4220/4518] 93% | Training loss: 0.6870408938676825
Epoch: 19 | Iteration number: [4230/4518] 93% | Training loss: 0.6870388112733268
Epoch: 19 | Iteration number: [4240/4518] 93% | Training loss: 0.6870399592620022
Epoch: 19 | Iteration number: [4250/4518] 94% | Training loss: 0.6870389112023746
Epoch: 19 | Iteration number: [4260/4518] 94% | Training loss: 0.687040655377885
Epoch: 19 | Iteration number: [4270/4518] 94% | Training loss: 0.6870395775422
Epoch: 19 | Iteration number: [4280/4518] 94% | Training loss: 0.6870408279037922
Epoch: 19 | Iteration number: [4290/4518] 94% | Training loss: 0.6870412959641232
Epoch: 19 | Iteration number: [4300/4518] 95% | Training loss: 0.6870386522453885
Epoch: 19 | Iteration number: [4310/4518] 95% | Training loss: 0.6870378389021083
Epoch: 19 | Iteration number: [4320/4518] 95% | Training loss: 0.6870397855562193
Epoch: 19 | Iteration number: [4330/4518] 95% | Training loss: 0.6870412351215134
Epoch: 19 | Iteration number: [4340/4518] 96% | Training loss: 0.687039969373958
Epoch: 19 | Iteration number: [4350/4518] 96% | Training loss: 0.6870378043185705
Epoch: 19 | Iteration number: [4360/4518] 96% | Training loss: 0.6870397926197139
Epoch: 19 | Iteration number: [4370/4518] 96% | Training loss: 0.6870374097431279
Epoch: 19 | Iteration number: [4380/4518] 96% | Training loss: 0.6870395997615709
Epoch: 19 | Iteration number: [4390/4518] 97% | Training loss: 0.6870407935698646
Epoch: 19 | Iteration number: [4400/4518] 97% | Training loss: 0.6870464515686036
Epoch: 19 | Iteration number: [4410/4518] 97% | Training loss: 0.6870486949441654
Epoch: 19 | Iteration number: [4420/4518] 97% | Training loss: 0.6870482896922401
Epoch: 19 | Iteration number: [4430/4518] 98% | Training loss: 0.6870501589156166
Epoch: 19 | Iteration number: [4440/4518] 98% | Training loss: 0.6870498996328663
Epoch: 19 | Iteration number: [4450/4518] 98% | Training loss: 0.687052625270372
Epoch: 19 | Iteration number: [4460/4518] 98% | Training loss: 0.6870503752220907
Epoch: 19 | Iteration number: [4470/4518] 98% | Training loss: 0.687049337041458
Epoch: 19 | Iteration number: [4480/4518] 99% | Training loss: 0.6870488711100604
Epoch: 19 | Iteration number: [4490/4518] 99% | Training loss: 0.6870502687243948
Epoch: 19 | Iteration number: [4500/4518] 99% | Training loss: 0.6870519282817841
Epoch: 19 | Iteration number: [4510/4518] 99% | Training loss: 0.6870514237299198

 End of epoch: 19 | Train Loss: 0.686899368229457 | Training Time: 632 

 End of epoch: 19 | Eval Loss: 0.6901317920003619 | Evaluating Time: 17 
Epoch: 20 | Iteration number: [10/4518] 0% | Training loss: 0.7555031657218934
Epoch: 20 | Iteration number: [20/4518] 0% | Training loss: 0.7208807647228241
Epoch: 20 | Iteration number: [30/4518] 0% | Training loss: 0.7095162987709045
Epoch: 20 | Iteration number: [40/4518] 0% | Training loss: 0.7036289617419242
Epoch: 20 | Iteration number: [50/4518] 1% | Training loss: 0.7005516958236694
Epoch: 20 | Iteration number: [60/4518] 1% | Training loss: 0.6981669455766678
Epoch: 20 | Iteration number: [70/4518] 1% | Training loss: 0.6964766672679357
Epoch: 20 | Iteration number: [80/4518] 1% | Training loss: 0.6956027388572693
Epoch: 20 | Iteration number: [90/4518] 1% | Training loss: 0.6946705043315887
Epoch: 20 | Iteration number: [100/4518] 2% | Training loss: 0.6939976924657821
Epoch: 20 | Iteration number: [110/4518] 2% | Training loss: 0.6933624294671146
Epoch: 20 | Iteration number: [120/4518] 2% | Training loss: 0.6926420703530312
Epoch: 20 | Iteration number: [130/4518] 2% | Training loss: 0.692174650155581
Epoch: 20 | Iteration number: [140/4518] 3% | Training loss: 0.6918075433799199
Epoch: 20 | Iteration number: [150/4518] 3% | Training loss: 0.6914013592402141
Epoch: 20 | Iteration number: [160/4518] 3% | Training loss: 0.6910838790237903
Epoch: 20 | Iteration number: [170/4518] 3% | Training loss: 0.6908323305494645
Epoch: 20 | Iteration number: [180/4518] 3% | Training loss: 0.6905752453539107
Epoch: 20 | Iteration number: [190/4518] 4% | Training loss: 0.6904278996743654
Epoch: 20 | Iteration number: [200/4518] 4% | Training loss: 0.6902506276965141
Epoch: 20 | Iteration number: [210/4518] 4% | Training loss: 0.6901045288358416
Epoch: 20 | Iteration number: [220/4518] 4% | Training loss: 0.6900028938596899
Epoch: 20 | Iteration number: [230/4518] 5% | Training loss: 0.6898877294167228
Epoch: 20 | Iteration number: [240/4518] 5% | Training loss: 0.689720701177915
Epoch: 20 | Iteration number: [250/4518] 5% | Training loss: 0.6896425855159759
Epoch: 20 | Iteration number: [260/4518] 5% | Training loss: 0.6895020629350955
Epoch: 20 | Iteration number: [270/4518] 5% | Training loss: 0.6894534230232239
Epoch: 20 | Iteration number: [280/4518] 6% | Training loss: 0.689400156055178
Epoch: 20 | Iteration number: [290/4518] 6% | Training loss: 0.6893044445021399
Epoch: 20 | Iteration number: [300/4518] 6% | Training loss: 0.6892143535614014
Epoch: 20 | Iteration number: [310/4518] 6% | Training loss: 0.6891253379083448
Epoch: 20 | Iteration number: [320/4518] 7% | Training loss: 0.6890188915655017
Epoch: 20 | Iteration number: [330/4518] 7% | Training loss: 0.6889420287175612
Epoch: 20 | Iteration number: [340/4518] 7% | Training loss: 0.6888587416971431
Epoch: 20 | Iteration number: [350/4518] 7% | Training loss: 0.6888029275621687
Epoch: 20 | Iteration number: [360/4518] 7% | Training loss: 0.688764972322517
Epoch: 20 | Iteration number: [370/4518] 8% | Training loss: 0.6887040333167926
Epoch: 20 | Iteration number: [380/4518] 8% | Training loss: 0.6886689325696543
Epoch: 20 | Iteration number: [390/4518] 8% | Training loss: 0.6886454137472006
Epoch: 20 | Iteration number: [400/4518] 8% | Training loss: 0.688576949685812
Epoch: 20 | Iteration number: [410/4518] 9% | Training loss: 0.6885382150731436
Epoch: 20 | Iteration number: [420/4518] 9% | Training loss: 0.6885098004624957
Epoch: 20 | Iteration number: [430/4518] 9% | Training loss: 0.6884514269440674
Epoch: 20 | Iteration number: [440/4518] 9% | Training loss: 0.6884083368561484
Epoch: 20 | Iteration number: [450/4518] 9% | Training loss: 0.6883583456940121
Epoch: 20 | Iteration number: [460/4518] 10% | Training loss: 0.6883295674686847
Epoch: 20 | Iteration number: [470/4518] 10% | Training loss: 0.688289057701192
Epoch: 20 | Iteration number: [480/4518] 10% | Training loss: 0.6882573409626881
Epoch: 20 | Iteration number: [490/4518] 10% | Training loss: 0.6882562634896259
Epoch: 20 | Iteration number: [500/4518] 11% | Training loss: 0.6882446035146713
Epoch: 20 | Iteration number: [510/4518] 11% | Training loss: 0.688216276028577
Epoch: 20 | Iteration number: [520/4518] 11% | Training loss: 0.6881741469869247
Epoch: 20 | Iteration number: [530/4518] 11% | Training loss: 0.6881543564346602
Epoch: 20 | Iteration number: [540/4518] 11% | Training loss: 0.6881286819775899
Epoch: 20 | Iteration number: [550/4518] 12% | Training loss: 0.6881083133003928
Epoch: 20 | Iteration number: [560/4518] 12% | Training loss: 0.6881030718130725
Epoch: 20 | Iteration number: [570/4518] 12% | Training loss: 0.6880898165075402
Epoch: 20 | Iteration number: [580/4518] 12% | Training loss: 0.6880716980531298
Epoch: 20 | Iteration number: [590/4518] 13% | Training loss: 0.6880559901059684
Epoch: 20 | Iteration number: [600/4518] 13% | Training loss: 0.6880327785015106
Epoch: 20 | Iteration number: [610/4518] 13% | Training loss: 0.6880111771528838
Epoch: 20 | Iteration number: [620/4518] 13% | Training loss: 0.688003438999576
Epoch: 20 | Iteration number: [630/4518] 13% | Training loss: 0.6879853734894404
Epoch: 20 | Iteration number: [640/4518] 14% | Training loss: 0.6879651080816984
Epoch: 20 | Iteration number: [650/4518] 14% | Training loss: 0.6879466221882746
Epoch: 20 | Iteration number: [660/4518] 14% | Training loss: 0.6879378366650957
Epoch: 20 | Iteration number: [670/4518] 14% | Training loss: 0.6879321023599425
Epoch: 20 | Iteration number: [680/4518] 15% | Training loss: 0.6879191715051146
Epoch: 20 | Iteration number: [690/4518] 15% | Training loss: 0.6879006333109261
Epoch: 20 | Iteration number: [700/4518] 15% | Training loss: 0.6878861316612789
Epoch: 20 | Iteration number: [710/4518] 15% | Training loss: 0.6878625552419205
Epoch: 20 | Iteration number: [720/4518] 15% | Training loss: 0.6878538474440574
Epoch: 20 | Iteration number: [730/4518] 16% | Training loss: 0.6878299416744545
Epoch: 20 | Iteration number: [740/4518] 16% | Training loss: 0.6878177687928483
Epoch: 20 | Iteration number: [750/4518] 16% | Training loss: 0.6878206427097321
Epoch: 20 | Iteration number: [760/4518] 16% | Training loss: 0.6878136877166597
Epoch: 20 | Iteration number: [770/4518] 17% | Training loss: 0.6878002781372565
Epoch: 20 | Iteration number: [780/4518] 17% | Training loss: 0.6877897612559489
Epoch: 20 | Iteration number: [790/4518] 17% | Training loss: 0.6877766431132449
Epoch: 20 | Iteration number: [800/4518] 17% | Training loss: 0.6877647141367197
Epoch: 20 | Iteration number: [810/4518] 17% | Training loss: 0.6877718782719271
Epoch: 20 | Iteration number: [820/4518] 18% | Training loss: 0.6877480935032775
Epoch: 20 | Iteration number: [830/4518] 18% | Training loss: 0.6877458148692027
Epoch: 20 | Iteration number: [840/4518] 18% | Training loss: 0.6877448757489523
Epoch: 20 | Iteration number: [850/4518] 18% | Training loss: 0.687741616824094
Epoch: 20 | Iteration number: [860/4518] 19% | Training loss: 0.6877250015042549
Epoch: 20 | Iteration number: [870/4518] 19% | Training loss: 0.6877034298989965
Epoch: 20 | Iteration number: [880/4518] 19% | Training loss: 0.6877026956867088
Epoch: 20 | Iteration number: [890/4518] 19% | Training loss: 0.6877014712671216
Epoch: 20 | Iteration number: [900/4518] 19% | Training loss: 0.6877023923397064
Epoch: 20 | Iteration number: [910/4518] 20% | Training loss: 0.6876813317393209
Epoch: 20 | Iteration number: [920/4518] 20% | Training loss: 0.6876583025507305
Epoch: 20 | Iteration number: [930/4518] 20% | Training loss: 0.6876407065699177
Epoch: 20 | Iteration number: [940/4518] 20% | Training loss: 0.6876331773844171
Epoch: 20 | Iteration number: [950/4518] 21% | Training loss: 0.6876248224785454
Epoch: 20 | Iteration number: [960/4518] 21% | Training loss: 0.6876389759903153
Epoch: 20 | Iteration number: [970/4518] 21% | Training loss: 0.6876266223868144
Epoch: 20 | Iteration number: [980/4518] 21% | Training loss: 0.6876298636806254
Epoch: 20 | Iteration number: [990/4518] 21% | Training loss: 0.6876199556119514
Epoch: 20 | Iteration number: [1000/4518] 22% | Training loss: 0.6876296911835671
Epoch: 20 | Iteration number: [1010/4518] 22% | Training loss: 0.6876293857498924
Epoch: 20 | Iteration number: [1020/4518] 22% | Training loss: 0.6876264441831439
Epoch: 20 | Iteration number: [1030/4518] 22% | Training loss: 0.6876185401550774
Epoch: 20 | Iteration number: [1040/4518] 23% | Training loss: 0.6876057294698862
Epoch: 20 | Iteration number: [1050/4518] 23% | Training loss: 0.6875949429330371
Epoch: 20 | Iteration number: [1060/4518] 23% | Training loss: 0.6875733246218484
Epoch: 20 | Iteration number: [1070/4518] 23% | Training loss: 0.6875623800487162
Epoch: 20 | Iteration number: [1080/4518] 23% | Training loss: 0.6875515757335557
Epoch: 20 | Iteration number: [1090/4518] 24% | Training loss: 0.6875497028915161
Epoch: 20 | Iteration number: [1100/4518] 24% | Training loss: 0.687553402131254
Epoch: 20 | Iteration number: [1110/4518] 24% | Training loss: 0.687549567759574
Epoch: 20 | Iteration number: [1120/4518] 24% | Training loss: 0.6875449549406767
Epoch: 20 | Iteration number: [1130/4518] 25% | Training loss: 0.6875411020443503
Epoch: 20 | Iteration number: [1140/4518] 25% | Training loss: 0.6875377990174711
Epoch: 20 | Iteration number: [1150/4518] 25% | Training loss: 0.6875308009334232
Epoch: 20 | Iteration number: [1160/4518] 25% | Training loss: 0.6875287696205337
Epoch: 20 | Iteration number: [1170/4518] 25% | Training loss: 0.6875304715246217
Epoch: 20 | Iteration number: [1180/4518] 26% | Training loss: 0.6875362230559526
Epoch: 20 | Iteration number: [1190/4518] 26% | Training loss: 0.6875367567819708
Epoch: 20 | Iteration number: [1200/4518] 26% | Training loss: 0.6875406891604264
Epoch: 20 | Iteration number: [1210/4518] 26% | Training loss: 0.6875377803794609
Epoch: 20 | Iteration number: [1220/4518] 27% | Training loss: 0.6875477705334053
Epoch: 20 | Iteration number: [1230/4518] 27% | Training loss: 0.6875463332587142
Epoch: 20 | Iteration number: [1240/4518] 27% | Training loss: 0.6875423040120833
Epoch: 20 | Iteration number: [1250/4518] 27% | Training loss: 0.6875335189819336
Epoch: 20 | Iteration number: [1260/4518] 27% | Training loss: 0.6875251495175891
Epoch: 20 | Iteration number: [1270/4518] 28% | Training loss: 0.6875197204079215
Epoch: 20 | Iteration number: [1280/4518] 28% | Training loss: 0.6875078133307397
Epoch: 20 | Iteration number: [1290/4518] 28% | Training loss: 0.6874887304250584
Epoch: 20 | Iteration number: [1300/4518] 28% | Training loss: 0.6874814946834857
Epoch: 20 | Iteration number: [1310/4518] 28% | Training loss: 0.6874766778854924
Epoch: 20 | Iteration number: [1320/4518] 29% | Training loss: 0.6874763317180402
Epoch: 20 | Iteration number: [1330/4518] 29% | Training loss: 0.687469502319967
Epoch: 20 | Iteration number: [1340/4518] 29% | Training loss: 0.6874594286751391
Epoch: 20 | Iteration number: [1350/4518] 29% | Training loss: 0.687451562528257
Epoch: 20 | Iteration number: [1360/4518] 30% | Training loss: 0.6874474919894162
Epoch: 20 | Iteration number: [1370/4518] 30% | Training loss: 0.6874324959560032
Epoch: 20 | Iteration number: [1380/4518] 30% | Training loss: 0.6874351582665374
Epoch: 20 | Iteration number: [1390/4518] 30% | Training loss: 0.6874330487611483
Epoch: 20 | Iteration number: [1400/4518] 30% | Training loss: 0.6874266599331583
Epoch: 20 | Iteration number: [1410/4518] 31% | Training loss: 0.6874176393586693
Epoch: 20 | Iteration number: [1420/4518] 31% | Training loss: 0.6874079135102286
Epoch: 20 | Iteration number: [1430/4518] 31% | Training loss: 0.6874029392545874
Epoch: 20 | Iteration number: [1440/4518] 31% | Training loss: 0.687397139146924
Epoch: 20 | Iteration number: [1450/4518] 32% | Training loss: 0.6873932265002152
Epoch: 20 | Iteration number: [1460/4518] 32% | Training loss: 0.6873962533392318
Epoch: 20 | Iteration number: [1470/4518] 32% | Training loss: 0.6873953389878176
Epoch: 20 | Iteration number: [1480/4518] 32% | Training loss: 0.6873898971725154
Epoch: 20 | Iteration number: [1490/4518] 32% | Training loss: 0.6873807127443736
Epoch: 20 | Iteration number: [1500/4518] 33% | Training loss: 0.6873704830408096
Epoch: 20 | Iteration number: [1510/4518] 33% | Training loss: 0.6873691752651669
Epoch: 20 | Iteration number: [1520/4518] 33% | Training loss: 0.6873630921699498
Epoch: 20 | Iteration number: [1530/4518] 33% | Training loss: 0.6873586230028689
Epoch: 20 | Iteration number: [1540/4518] 34% | Training loss: 0.6873455564697067
Epoch: 20 | Iteration number: [1550/4518] 34% | Training loss: 0.6873400903132654
Epoch: 20 | Iteration number: [1560/4518] 34% | Training loss: 0.6873305519803976
Epoch: 20 | Iteration number: [1570/4518] 34% | Training loss: 0.6873296023554103
Epoch: 20 | Iteration number: [1580/4518] 34% | Training loss: 0.6873231152944927
Epoch: 20 | Iteration number: [1590/4518] 35% | Training loss: 0.687318657629145
Epoch: 20 | Iteration number: [1600/4518] 35% | Training loss: 0.6873157615959644
Epoch: 20 | Iteration number: [1610/4518] 35% | Training loss: 0.687305599228936
Epoch: 20 | Iteration number: [1620/4518] 35% | Training loss: 0.6873067654577303
Epoch: 20 | Iteration number: [1630/4518] 36% | Training loss: 0.6873016130339149
Epoch: 20 | Iteration number: [1640/4518] 36% | Training loss: 0.6872996547600118
Epoch: 20 | Iteration number: [1650/4518] 36% | Training loss: 0.6872963097239986
Epoch: 20 | Iteration number: [1660/4518] 36% | Training loss: 0.6872911897050329
Epoch: 20 | Iteration number: [1670/4518] 36% | Training loss: 0.6872899882807703
Epoch: 20 | Iteration number: [1680/4518] 37% | Training loss: 0.6872900700285322
Epoch: 20 | Iteration number: [1690/4518] 37% | Training loss: 0.6872812355058433
Epoch: 20 | Iteration number: [1700/4518] 37% | Training loss: 0.6872731399886748
Epoch: 20 | Iteration number: [1710/4518] 37% | Training loss: 0.6872728325121584
Epoch: 20 | Iteration number: [1720/4518] 38% | Training loss: 0.6872684455195138
Epoch: 20 | Iteration number: [1730/4518] 38% | Training loss: 0.6872673204179444
Epoch: 20 | Iteration number: [1740/4518] 38% | Training loss: 0.6872680168384793
Epoch: 20 | Iteration number: [1750/4518] 38% | Training loss: 0.687266140631267
Epoch: 20 | Iteration number: [1760/4518] 38% | Training loss: 0.6872678221626716
Epoch: 20 | Iteration number: [1770/4518] 39% | Training loss: 0.6872700493551244
Epoch: 20 | Iteration number: [1780/4518] 39% | Training loss: 0.6872713163662493
Epoch: 20 | Iteration number: [1790/4518] 39% | Training loss: 0.6872686215286148
Epoch: 20 | Iteration number: [1800/4518] 39% | Training loss: 0.687266962826252
Epoch: 20 | Iteration number: [1810/4518] 40% | Training loss: 0.6872636232257548
Epoch: 20 | Iteration number: [1820/4518] 40% | Training loss: 0.6872543963429693
Epoch: 20 | Iteration number: [1830/4518] 40% | Training loss: 0.6872583683722657
Epoch: 20 | Iteration number: [1840/4518] 40% | Training loss: 0.6872568328419457
Epoch: 20 | Iteration number: [1850/4518] 40% | Training loss: 0.6872578719499949
Epoch: 20 | Iteration number: [1860/4518] 41% | Training loss: 0.6872608620953816
Epoch: 20 | Iteration number: [1870/4518] 41% | Training loss: 0.6872606173237378
Epoch: 20 | Iteration number: [1880/4518] 41% | Training loss: 0.6872614761616321
Epoch: 20 | Iteration number: [1890/4518] 41% | Training loss: 0.68726080662359
Epoch: 20 | Iteration number: [1900/4518] 42% | Training loss: 0.6872613670637733
Epoch: 20 | Iteration number: [1910/4518] 42% | Training loss: 0.687263978463817
Epoch: 20 | Iteration number: [1920/4518] 42% | Training loss: 0.6872676258906723
Epoch: 20 | Iteration number: [1930/4518] 42% | Training loss: 0.6872637986210344
Epoch: 20 | Iteration number: [1940/4518] 42% | Training loss: 0.687261090389232
Epoch: 20 | Iteration number: [1950/4518] 43% | Training loss: 0.6872519209751716
Epoch: 20 | Iteration number: [1960/4518] 43% | Training loss: 0.6872590147414986
Epoch: 20 | Iteration number: [1970/4518] 43% | Training loss: 0.68725908171707
Epoch: 20 | Iteration number: [1980/4518] 43% | Training loss: 0.6872554357605751
Epoch: 20 | Iteration number: [1990/4518] 44% | Training loss: 0.6872532479727088
Epoch: 20 | Iteration number: [2000/4518] 44% | Training loss: 0.6872564466297626
Epoch: 20 | Iteration number: [2010/4518] 44% | Training loss: 0.6872555036449907
Epoch: 20 | Iteration number: [2020/4518] 44% | Training loss: 0.6872534973786609
Epoch: 20 | Iteration number: [2030/4518] 44% | Training loss: 0.6872463484996645
Epoch: 20 | Iteration number: [2040/4518] 45% | Training loss: 0.6872422852644733
Epoch: 20 | Iteration number: [2050/4518] 45% | Training loss: 0.6872439287348492
Epoch: 20 | Iteration number: [2060/4518] 45% | Training loss: 0.6872444023785081
Epoch: 20 | Iteration number: [2070/4518] 45% | Training loss: 0.6872361581106693
Epoch: 20 | Iteration number: [2080/4518] 46% | Training loss: 0.6872290909003753
Epoch: 20 | Iteration number: [2090/4518] 46% | Training loss: 0.687229861625644
Epoch: 20 | Iteration number: [2100/4518] 46% | Training loss: 0.6872283408755347
Epoch: 20 | Iteration number: [2110/4518] 46% | Training loss: 0.687222969362521
Epoch: 20 | Iteration number: [2120/4518] 46% | Training loss: 0.6872161446877245
Epoch: 20 | Iteration number: [2130/4518] 47% | Training loss: 0.6872155936670975
Epoch: 20 | Iteration number: [2140/4518] 47% | Training loss: 0.6872101135343035
Epoch: 20 | Iteration number: [2150/4518] 47% | Training loss: 0.6872014284411142
Epoch: 20 | Iteration number: [2160/4518] 47% | Training loss: 0.6871989001278525
Epoch: 20 | Iteration number: [2170/4518] 48% | Training loss: 0.6872019315370217
Epoch: 20 | Iteration number: [2180/4518] 48% | Training loss: 0.6872009417059225
Epoch: 20 | Iteration number: [2190/4518] 48% | Training loss: 0.6871937285003052
Epoch: 20 | Iteration number: [2200/4518] 48% | Training loss: 0.6871890705552968
Epoch: 20 | Iteration number: [2210/4518] 48% | Training loss: 0.6871842451225039
Epoch: 20 | Iteration number: [2220/4518] 49% | Training loss: 0.6871863516601356
Epoch: 20 | Iteration number: [2230/4518] 49% | Training loss: 0.6871874671345869
Epoch: 20 | Iteration number: [2240/4518] 49% | Training loss: 0.6871837895629661
Epoch: 20 | Iteration number: [2250/4518] 49% | Training loss: 0.6871842722362942
Epoch: 20 | Iteration number: [2260/4518] 50% | Training loss: 0.6871834924263237
Epoch: 20 | Iteration number: [2270/4518] 50% | Training loss: 0.6871781711273781
Epoch: 20 | Iteration number: [2280/4518] 50% | Training loss: 0.68718102503764
Epoch: 20 | Iteration number: [2290/4518] 50% | Training loss: 0.6871818816037157
Epoch: 20 | Iteration number: [2300/4518] 50% | Training loss: 0.6871810516585475
Epoch: 20 | Iteration number: [2310/4518] 51% | Training loss: 0.6871818943715199
Epoch: 20 | Iteration number: [2320/4518] 51% | Training loss: 0.6871791114837958
Epoch: 20 | Iteration number: [2330/4518] 51% | Training loss: 0.6871733796698852
Epoch: 20 | Iteration number: [2340/4518] 51% | Training loss: 0.6871690443438343
Epoch: 20 | Iteration number: [2350/4518] 52% | Training loss: 0.6871682282965234
Epoch: 20 | Iteration number: [2360/4518] 52% | Training loss: 0.6871653331033254
Epoch: 20 | Iteration number: [2370/4518] 52% | Training loss: 0.6871673895588404
Epoch: 20 | Iteration number: [2380/4518] 52% | Training loss: 0.6871619867176569
Epoch: 20 | Iteration number: [2390/4518] 52% | Training loss: 0.6871574805870215
Epoch: 20 | Iteration number: [2400/4518] 53% | Training loss: 0.6871588706473509
Epoch: 20 | Iteration number: [2410/4518] 53% | Training loss: 0.687160575835042
Epoch: 20 | Iteration number: [2420/4518] 53% | Training loss: 0.6871569835450039
Epoch: 20 | Iteration number: [2430/4518] 53% | Training loss: 0.6871548486344609
Epoch: 20 | Iteration number: [2440/4518] 54% | Training loss: 0.6871557068873624
Epoch: 20 | Iteration number: [2450/4518] 54% | Training loss: 0.6871543342726572
Epoch: 20 | Iteration number: [2460/4518] 54% | Training loss: 0.6871531968678886
Epoch: 20 | Iteration number: [2470/4518] 54% | Training loss: 0.6871531035494708
Epoch: 20 | Iteration number: [2480/4518] 54% | Training loss: 0.6871576005172345
Epoch: 20 | Iteration number: [2490/4518] 55% | Training loss: 0.6871572735558552
Epoch: 20 | Iteration number: [2500/4518] 55% | Training loss: 0.6871603907585144
Epoch: 20 | Iteration number: [2510/4518] 55% | Training loss: 0.6871552841121932
Epoch: 20 | Iteration number: [2520/4518] 55% | Training loss: 0.6871526198254692
Epoch: 20 | Iteration number: [2530/4518] 55% | Training loss: 0.6871531424079488
Epoch: 20 | Iteration number: [2540/4518] 56% | Training loss: 0.687152795622668
Epoch: 20 | Iteration number: [2550/4518] 56% | Training loss: 0.6871515697357702
Epoch: 20 | Iteration number: [2560/4518] 56% | Training loss: 0.6871516299666837
Epoch: 20 | Iteration number: [2570/4518] 56% | Training loss: 0.6871511248762969
Epoch: 20 | Iteration number: [2580/4518] 57% | Training loss: 0.6871466285036516
Epoch: 20 | Iteration number: [2590/4518] 57% | Training loss: 0.6871421329993539
Epoch: 20 | Iteration number: [2600/4518] 57% | Training loss: 0.6871410982425397
Epoch: 20 | Iteration number: [2610/4518] 57% | Training loss: 0.6871377453036692
Epoch: 20 | Iteration number: [2620/4518] 57% | Training loss: 0.6871301838914856
Epoch: 20 | Iteration number: [2630/4518] 58% | Training loss: 0.6871252182998585
Epoch: 20 | Iteration number: [2640/4518] 58% | Training loss: 0.6871235078257142
Epoch: 20 | Iteration number: [2650/4518] 58% | Training loss: 0.6871210766963239
Epoch: 20 | Iteration number: [2660/4518] 58% | Training loss: 0.6871221844190941
Epoch: 20 | Iteration number: [2670/4518] 59% | Training loss: 0.6871258229798592
Epoch: 20 | Iteration number: [2680/4518] 59% | Training loss: 0.6871246367248136
Epoch: 20 | Iteration number: [2690/4518] 59% | Training loss: 0.6871222598180452
Epoch: 20 | Iteration number: [2700/4518] 59% | Training loss: 0.6871190087883561
Epoch: 20 | Iteration number: [2710/4518] 59% | Training loss: 0.6871160514020392
Epoch: 20 | Iteration number: [2720/4518] 60% | Training loss: 0.6871162884813897
Epoch: 20 | Iteration number: [2730/4518] 60% | Training loss: 0.6871147922107151
Epoch: 20 | Iteration number: [2740/4518] 60% | Training loss: 0.6871133178907589
Epoch: 20 | Iteration number: [2750/4518] 60% | Training loss: 0.6871136933456767
Epoch: 20 | Iteration number: [2760/4518] 61% | Training loss: 0.687111265482246
Epoch: 20 | Iteration number: [2770/4518] 61% | Training loss: 0.6871124505351166
Epoch: 20 | Iteration number: [2780/4518] 61% | Training loss: 0.6871122187633308
Epoch: 20 | Iteration number: [2790/4518] 61% | Training loss: 0.6871115630031914
Epoch: 20 | Iteration number: [2800/4518] 61% | Training loss: 0.6871131462071624
Epoch: 20 | Iteration number: [2810/4518] 62% | Training loss: 0.6871142523992952
Epoch: 20 | Iteration number: [2820/4518] 62% | Training loss: 0.6871154571255893
Epoch: 20 | Iteration number: [2830/4518] 62% | Training loss: 0.6871175962496984
Epoch: 20 | Iteration number: [2840/4518] 62% | Training loss: 0.6871174968044523
Epoch: 20 | Iteration number: [2850/4518] 63% | Training loss: 0.687118842162584
Epoch: 20 | Iteration number: [2860/4518] 63% | Training loss: 0.6871170460135787
Epoch: 20 | Iteration number: [2870/4518] 63% | Training loss: 0.687115402524895
Epoch: 20 | Iteration number: [2880/4518] 63% | Training loss: 0.6871154213945071
Epoch: 20 | Iteration number: [2890/4518] 63% | Training loss: 0.6871144119224747
Epoch: 20 | Iteration number: [2900/4518] 64% | Training loss: 0.687115985113999
Epoch: 20 | Iteration number: [2910/4518] 64% | Training loss: 0.6871125130309272
Epoch: 20 | Iteration number: [2920/4518] 64% | Training loss: 0.6871118185250726
Epoch: 20 | Iteration number: [2930/4518] 64% | Training loss: 0.6871114594537651
Epoch: 20 | Iteration number: [2940/4518] 65% | Training loss: 0.6871114659674313
Epoch: 20 | Iteration number: [2950/4518] 65% | Training loss: 0.6871107213982081
Epoch: 20 | Iteration number: [2960/4518] 65% | Training loss: 0.687112116652566
Epoch: 20 | Iteration number: [2970/4518] 65% | Training loss: 0.6871109972497831
Epoch: 20 | Iteration number: [2980/4518] 65% | Training loss: 0.6871081519646932
Epoch: 20 | Iteration number: [2990/4518] 66% | Training loss: 0.6871085930229429
Epoch: 20 | Iteration number: [3000/4518] 66% | Training loss: 0.6871063131093978
Epoch: 20 | Iteration number: [3010/4518] 66% | Training loss: 0.6871093775148803
Epoch: 20 | Iteration number: [3020/4518] 66% | Training loss: 0.6871104920542004
Epoch: 20 | Iteration number: [3030/4518] 67% | Training loss: 0.6871115200196949
Epoch: 20 | Iteration number: [3040/4518] 67% | Training loss: 0.6871112800938518
Epoch: 20 | Iteration number: [3050/4518] 67% | Training loss: 0.6871099393094172
Epoch: 20 | Iteration number: [3060/4518] 67% | Training loss: 0.6871114196535809
Epoch: 20 | Iteration number: [3070/4518] 67% | Training loss: 0.6871112849890991
Epoch: 20 | Iteration number: [3080/4518] 68% | Training loss: 0.6871095747529686
Epoch: 20 | Iteration number: [3090/4518] 68% | Training loss: 0.6871055368852461
Epoch: 20 | Iteration number: [3100/4518] 68% | Training loss: 0.6871066411272172
Epoch: 20 | Iteration number: [3110/4518] 68% | Training loss: 0.6871088554813164
Epoch: 20 | Iteration number: [3120/4518] 69% | Training loss: 0.6871099665952034
Epoch: 20 | Iteration number: [3130/4518] 69% | Training loss: 0.6871153267618185
Epoch: 20 | Iteration number: [3140/4518] 69% | Training loss: 0.6871121371058142
Epoch: 20 | Iteration number: [3150/4518] 69% | Training loss: 0.6871086489965045
Epoch: 20 | Iteration number: [3160/4518] 69% | Training loss: 0.6871063029275665
Epoch: 20 | Iteration number: [3170/4518] 70% | Training loss: 0.6871076465405124
Epoch: 20 | Iteration number: [3180/4518] 70% | Training loss: 0.6871097664788084
Epoch: 20 | Iteration number: [3190/4518] 70% | Training loss: 0.6871072446477824
Epoch: 20 | Iteration number: [3200/4518] 70% | Training loss: 0.6871060818061232
Epoch: 20 | Iteration number: [3210/4518] 71% | Training loss: 0.68710749214312
Epoch: 20 | Iteration number: [3220/4518] 71% | Training loss: 0.6871075016741427
Epoch: 20 | Iteration number: [3230/4518] 71% | Training loss: 0.6871092956132564
Epoch: 20 | Iteration number: [3240/4518] 71% | Training loss: 0.6871098790271782
Epoch: 20 | Iteration number: [3250/4518] 71% | Training loss: 0.6871060502895943
Epoch: 20 | Iteration number: [3260/4518] 72% | Training loss: 0.6871063038615361
Epoch: 20 | Iteration number: [3270/4518] 72% | Training loss: 0.6871075876809042
Epoch: 20 | Iteration number: [3280/4518] 72% | Training loss: 0.6871040135258581
Epoch: 20 | Iteration number: [3290/4518] 72% | Training loss: 0.687105199051483
Epoch: 20 | Iteration number: [3300/4518] 73% | Training loss: 0.6871049253687714
Epoch: 20 | Iteration number: [3310/4518] 73% | Training loss: 0.6871044403476657
Epoch: 20 | Iteration number: [3320/4518] 73% | Training loss: 0.6871032457394772
Epoch: 20 | Iteration number: [3330/4518] 73% | Training loss: 0.6871067012573505
Epoch: 20 | Iteration number: [3340/4518] 73% | Training loss: 0.6871061057387712
Epoch: 20 | Iteration number: [3350/4518] 74% | Training loss: 0.6871066531672406
Epoch: 20 | Iteration number: [3360/4518] 74% | Training loss: 0.6871087844527903
Epoch: 20 | Iteration number: [3370/4518] 74% | Training loss: 0.6871040399244348
Epoch: 20 | Iteration number: [3380/4518] 74% | Training loss: 0.6871032478541312
Epoch: 20 | Iteration number: [3390/4518] 75% | Training loss: 0.6871018078123222
Epoch: 20 | Iteration number: [3400/4518] 75% | Training loss: 0.6871015587799689
Epoch: 20 | Iteration number: [3410/4518] 75% | Training loss: 0.6870960938091502
Epoch: 20 | Iteration number: [3420/4518] 75% | Training loss: 0.6870961813550246
Epoch: 20 | Iteration number: [3430/4518] 75% | Training loss: 0.6870961741699074
Epoch: 20 | Iteration number: [3440/4518] 76% | Training loss: 0.6870968121082284
Epoch: 20 | Iteration number: [3450/4518] 76% | Training loss: 0.6870980516723965
Epoch: 20 | Iteration number: [3460/4518] 76% | Training loss: 0.6870965286830946
Epoch: 20 | Iteration number: [3470/4518] 76% | Training loss: 0.6870971997979739
Epoch: 20 | Iteration number: [3480/4518] 77% | Training loss: 0.687102360732254
Epoch: 20 | Iteration number: [3490/4518] 77% | Training loss: 0.6871045130200919
Epoch: 20 | Iteration number: [3500/4518] 77% | Training loss: 0.6871033553055355
Epoch: 20 | Iteration number: [3510/4518] 77% | Training loss: 0.6871025000372504
Epoch: 20 | Iteration number: [3520/4518] 77% | Training loss: 0.6871030015024272
Epoch: 20 | Iteration number: [3530/4518] 78% | Training loss: 0.6871001686489279
Epoch: 20 | Iteration number: [3540/4518] 78% | Training loss: 0.687097644940608
Epoch: 20 | Iteration number: [3550/4518] 78% | Training loss: 0.6870959915241726
Epoch: 20 | Iteration number: [3560/4518] 78% | Training loss: 0.6870950240767404
Epoch: 20 | Iteration number: [3570/4518] 79% | Training loss: 0.6870951191884797
Epoch: 20 | Iteration number: [3580/4518] 79% | Training loss: 0.6870954898316101
Epoch: 20 | Iteration number: [3590/4518] 79% | Training loss: 0.6870928071833586
Epoch: 20 | Iteration number: [3600/4518] 79% | Training loss: 0.6870943903260761
Epoch: 20 | Iteration number: [3610/4518] 79% | Training loss: 0.6870951371675053
Epoch: 20 | Iteration number: [3620/4518] 80% | Training loss: 0.6870946426911907
Epoch: 20 | Iteration number: [3630/4518] 80% | Training loss: 0.6870947506637941
Epoch: 20 | Iteration number: [3640/4518] 80% | Training loss: 0.6870938955755024
Epoch: 20 | Iteration number: [3650/4518] 80% | Training loss: 0.6870905873220261
Epoch: 20 | Iteration number: [3660/4518] 81% | Training loss: 0.6870954885671698
Epoch: 20 | Iteration number: [3670/4518] 81% | Training loss: 0.6870921979970438
Epoch: 20 | Iteration number: [3680/4518] 81% | Training loss: 0.6870935646736104
Epoch: 20 | Iteration number: [3690/4518] 81% | Training loss: 0.6870919215646862
Epoch: 20 | Iteration number: [3700/4518] 81% | Training loss: 0.6870917370834866
Epoch: 20 | Iteration number: [3710/4518] 82% | Training loss: 0.6870955198280252
Epoch: 20 | Iteration number: [3720/4518] 82% | Training loss: 0.6870924741510422
Epoch: 20 | Iteration number: [3730/4518] 82% | Training loss: 0.6870936823114953
Epoch: 20 | Iteration number: [3740/4518] 82% | Training loss: 0.6870927111350279
Epoch: 20 | Iteration number: [3750/4518] 83% | Training loss: 0.6870942195733388
Epoch: 20 | Iteration number: [3760/4518] 83% | Training loss: 0.6870910537686754
Epoch: 20 | Iteration number: [3770/4518] 83% | Training loss: 0.6870887341960988
Epoch: 20 | Iteration number: [3780/4518] 83% | Training loss: 0.6870874565429789
Epoch: 20 | Iteration number: [3790/4518] 83% | Training loss: 0.687085266776953
Epoch: 20 | Iteration number: [3800/4518] 84% | Training loss: 0.6870873803214023
Epoch: 20 | Iteration number: [3810/4518] 84% | Training loss: 0.6870873170418377
Epoch: 20 | Iteration number: [3820/4518] 84% | Training loss: 0.6870843373200032
Epoch: 20 | Iteration number: [3830/4518] 84% | Training loss: 0.6870846035586324
Epoch: 20 | Iteration number: [3840/4518] 84% | Training loss: 0.687083723085622
Epoch: 20 | Iteration number: [3850/4518] 85% | Training loss: 0.6870848155331302
Epoch: 20 | Iteration number: [3860/4518] 85% | Training loss: 0.6870840247585366
Epoch: 20 | Iteration number: [3870/4518] 85% | Training loss: 0.687085060093754
Epoch: 20 | Iteration number: [3880/4518] 85% | Training loss: 0.6870863704951768
Epoch: 20 | Iteration number: [3890/4518] 86% | Training loss: 0.6870876579174345
Epoch: 20 | Iteration number: [3900/4518] 86% | Training loss: 0.6870879317399783
Epoch: 20 | Iteration number: [3910/4518] 86% | Training loss: 0.6870861997689738
Epoch: 20 | Iteration number: [3920/4518] 86% | Training loss: 0.6870843695134533
Epoch: 20 | Iteration number: [3930/4518] 86% | Training loss: 0.6870880309558703
Epoch: 20 | Iteration number: [3940/4518] 87% | Training loss: 0.6870859301332289
Epoch: 20 | Iteration number: [3950/4518] 87% | Training loss: 0.6870851091644432
Epoch: 20 | Iteration number: [3960/4518] 87% | Training loss: 0.6870821026088011
Epoch: 20 | Iteration number: [3970/4518] 87% | Training loss: 0.6870832623402477
Epoch: 20 | Iteration number: [3980/4518] 88% | Training loss: 0.6870785149198082
Epoch: 20 | Iteration number: [3990/4518] 88% | Training loss: 0.6870789201636064
Epoch: 20 | Iteration number: [4000/4518] 88% | Training loss: 0.6870790643244982
Epoch: 20 | Iteration number: [4010/4518] 88% | Training loss: 0.6870786572929629
Epoch: 20 | Iteration number: [4020/4518] 88% | Training loss: 0.6870752362914346
Epoch: 20 | Iteration number: [4030/4518] 89% | Training loss: 0.6870721684644003
Epoch: 20 | Iteration number: [4040/4518] 89% | Training loss: 0.6870712748258421
Epoch: 20 | Iteration number: [4050/4518] 89% | Training loss: 0.6870692537301852
Epoch: 20 | Iteration number: [4060/4518] 89% | Training loss: 0.6870690465707497
Epoch: 20 | Iteration number: [4070/4518] 90% | Training loss: 0.6870663191381777
Epoch: 20 | Iteration number: [4080/4518] 90% | Training loss: 0.6870644898537327
Epoch: 20 | Iteration number: [4090/4518] 90% | Training loss: 0.6870643271502189
Epoch: 20 | Iteration number: [4100/4518] 90% | Training loss: 0.6870633708703808
Epoch: 20 | Iteration number: [4110/4518] 90% | Training loss: 0.6870611315371056
Epoch: 20 | Iteration number: [4120/4518] 91% | Training loss: 0.6870580958075894
Epoch: 20 | Iteration number: [4130/4518] 91% | Training loss: 0.6870618955275049
Epoch: 20 | Iteration number: [4140/4518] 91% | Training loss: 0.6870594286112394
Epoch: 20 | Iteration number: [4150/4518] 91% | Training loss: 0.6870580252394619
Epoch: 20 | Iteration number: [4160/4518] 92% | Training loss: 0.6870594966440247
Epoch: 20 | Iteration number: [4170/4518] 92% | Training loss: 0.6870566457009716
Epoch: 20 | Iteration number: [4180/4518] 92% | Training loss: 0.687058017356544
Epoch: 20 | Iteration number: [4190/4518] 92% | Training loss: 0.6870586856879596
Epoch: 20 | Iteration number: [4200/4518] 92% | Training loss: 0.6870586920919872
Epoch: 20 | Iteration number: [4210/4518] 93% | Training loss: 0.6870583818955546
Epoch: 20 | Iteration number: [4220/4518] 93% | Training loss: 0.6870582320396369
Epoch: 20 | Iteration number: [4230/4518] 93% | Training loss: 0.6870579783234472
Epoch: 20 | Iteration number: [4240/4518] 93% | Training loss: 0.6870592658952722
Epoch: 20 | Iteration number: [4250/4518] 94% | Training loss: 0.6870585047357223
Epoch: 20 | Iteration number: [4260/4518] 94% | Training loss: 0.687058406018875
Epoch: 20 | Iteration number: [4270/4518] 94% | Training loss: 0.6870587481268675
Epoch: 20 | Iteration number: [4280/4518] 94% | Training loss: 0.6870584119285379
Epoch: 20 | Iteration number: [4290/4518] 94% | Training loss: 0.6870578266107119
Epoch: 20 | Iteration number: [4300/4518] 95% | Training loss: 0.6870581590852072
Epoch: 20 | Iteration number: [4310/4518] 95% | Training loss: 0.6870582658010956
Epoch: 20 | Iteration number: [4320/4518] 95% | Training loss: 0.6870573493893499
Epoch: 20 | Iteration number: [4330/4518] 95% | Training loss: 0.6870601089116333
Epoch: 20 | Iteration number: [4340/4518] 96% | Training loss: 0.687057581763663
Epoch: 20 | Iteration number: [4350/4518] 96% | Training loss: 0.6870573843758682
Epoch: 20 | Iteration number: [4360/4518] 96% | Training loss: 0.6870573132820086
Epoch: 20 | Iteration number: [4370/4518] 96% | Training loss: 0.6870596803844111
Epoch: 20 | Iteration number: [4380/4518] 96% | Training loss: 0.6870593345464637
Epoch: 20 | Iteration number: [4390/4518] 97% | Training loss: 0.687061460523236
Epoch: 20 | Iteration number: [4400/4518] 97% | Training loss: 0.6870579369772565
Epoch: 20 | Iteration number: [4410/4518] 97% | Training loss: 0.6870551867414765
Epoch: 20 | Iteration number: [4420/4518] 97% | Training loss: 0.6870588088332258
Epoch: 20 | Iteration number: [4430/4518] 98% | Training loss: 0.6870580588318155
Epoch: 20 | Iteration number: [4440/4518] 98% | Training loss: 0.6870598633278597
Epoch: 20 | Iteration number: [4450/4518] 98% | Training loss: 0.6870587627673417
Epoch: 20 | Iteration number: [4460/4518] 98% | Training loss: 0.6870587806263312
Epoch: 20 | Iteration number: [4470/4518] 98% | Training loss: 0.6870582547897194
Epoch: 20 | Iteration number: [4480/4518] 99% | Training loss: 0.6870582215221864
Epoch: 20 | Iteration number: [4490/4518] 99% | Training loss: 0.6870535716845888
Epoch: 20 | Iteration number: [4500/4518] 99% | Training loss: 0.6870527898603015
Epoch: 20 | Iteration number: [4510/4518] 99% | Training loss: 0.6870509470777871

 End of epoch: 20 | Train Loss: 0.6868959491682454 | Training Time: 632 

 End of epoch: 20 | Eval Loss: 0.6899777541355211 | Evaluating Time: 17 
Epoch: 21 | Iteration number: [10/4518] 0% | Training loss: 0.7551381051540375
Epoch: 21 | Iteration number: [20/4518] 0% | Training loss: 0.7208313256502151
Epoch: 21 | Iteration number: [30/4518] 0% | Training loss: 0.709111483891805
Epoch: 21 | Iteration number: [40/4518] 0% | Training loss: 0.7033753037452698
Epoch: 21 | Iteration number: [50/4518] 1% | Training loss: 0.7000057518482208
Epoch: 21 | Iteration number: [60/4518] 1% | Training loss: 0.697744631767273
Epoch: 21 | Iteration number: [70/4518] 1% | Training loss: 0.6962171912193298
Epoch: 21 | Iteration number: [80/4518] 1% | Training loss: 0.6950849987566471
Epoch: 21 | Iteration number: [90/4518] 1% | Training loss: 0.6941692120499081
Epoch: 21 | Iteration number: [100/4518] 2% | Training loss: 0.6933671194314956
Epoch: 21 | Iteration number: [110/4518] 2% | Training loss: 0.6926457220857793
Epoch: 21 | Iteration number: [120/4518] 2% | Training loss: 0.6921502113342285
Epoch: 21 | Iteration number: [130/4518] 2% | Training loss: 0.6917607004825885
Epoch: 21 | Iteration number: [140/4518] 3% | Training loss: 0.6914114058017731
Epoch: 21 | Iteration number: [150/4518] 3% | Training loss: 0.6910002851486206
Epoch: 21 | Iteration number: [160/4518] 3% | Training loss: 0.6906620636582375
Epoch: 21 | Iteration number: [170/4518] 3% | Training loss: 0.6905123079524321
Epoch: 21 | Iteration number: [180/4518] 3% | Training loss: 0.6903672417004904
Epoch: 21 | Iteration number: [190/4518] 4% | Training loss: 0.6902002234207957
Epoch: 21 | Iteration number: [200/4518] 4% | Training loss: 0.6899886959791184
Epoch: 21 | Iteration number: [210/4518] 4% | Training loss: 0.6898955813476018
Epoch: 21 | Iteration number: [220/4518] 4% | Training loss: 0.6897554996338757
Epoch: 21 | Iteration number: [230/4518] 5% | Training loss: 0.6896467421365821
Epoch: 21 | Iteration number: [240/4518] 5% | Training loss: 0.6895158795018991
Epoch: 21 | Iteration number: [250/4518] 5% | Training loss: 0.6894503793716431
Epoch: 21 | Iteration number: [260/4518] 5% | Training loss: 0.6893383298928921
Epoch: 21 | Iteration number: [270/4518] 5% | Training loss: 0.6892184206732997
Epoch: 21 | Iteration number: [280/4518] 6% | Training loss: 0.6891666050468173
Epoch: 21 | Iteration number: [290/4518] 6% | Training loss: 0.6890492022037507
Epoch: 21 | Iteration number: [300/4518] 6% | Training loss: 0.6890207310517629
Epoch: 21 | Iteration number: [310/4518] 6% | Training loss: 0.6889297281542132
Epoch: 21 | Iteration number: [320/4518] 7% | Training loss: 0.6888500789180398
Epoch: 21 | Iteration number: [330/4518] 7% | Training loss: 0.6887958028099753
Epoch: 21 | Iteration number: [340/4518] 7% | Training loss: 0.6886965851573383
Epoch: 21 | Iteration number: [350/4518] 7% | Training loss: 0.6886495343276433
Epoch: 21 | Iteration number: [360/4518] 7% | Training loss: 0.6886182907554839
Epoch: 21 | Iteration number: [370/4518] 8% | Training loss: 0.6885339751436904
Epoch: 21 | Iteration number: [380/4518] 8% | Training loss: 0.6884991487390116
Epoch: 21 | Iteration number: [390/4518] 8% | Training loss: 0.6884702274432549
Epoch: 21 | Iteration number: [400/4518] 8% | Training loss: 0.6884220118820668
Epoch: 21 | Iteration number: [410/4518] 9% | Training loss: 0.6883682399261288
Epoch: 21 | Iteration number: [420/4518] 9% | Training loss: 0.6883169335978372
Epoch: 21 | Iteration number: [430/4518] 9% | Training loss: 0.6882839358130167
Epoch: 21 | Iteration number: [440/4518] 9% | Training loss: 0.6882645323872566
Epoch: 21 | Iteration number: [450/4518] 9% | Training loss: 0.688235805299547
Epoch: 21 | Iteration number: [460/4518] 10% | Training loss: 0.6881670284530391
Epoch: 21 | Iteration number: [470/4518] 10% | Training loss: 0.6881502287184939
Epoch: 21 | Iteration number: [480/4518] 10% | Training loss: 0.6881225476662318
Epoch: 21 | Iteration number: [490/4518] 10% | Training loss: 0.6880971897621544
Epoch: 21 | Iteration number: [500/4518] 11% | Training loss: 0.6880920610427856
Epoch: 21 | Iteration number: [510/4518] 11% | Training loss: 0.6880540003963546
Epoch: 21 | Iteration number: [520/4518] 11% | Training loss: 0.6880620125394601
Epoch: 21 | Iteration number: [530/4518] 11% | Training loss: 0.6880182514775474
Epoch: 21 | Iteration number: [540/4518] 11% | Training loss: 0.6879994887996603
Epoch: 21 | Iteration number: [550/4518] 12% | Training loss: 0.6879663337360729
Epoch: 21 | Iteration number: [560/4518] 12% | Training loss: 0.6879728173570974
Epoch: 21 | Iteration number: [570/4518] 12% | Training loss: 0.6879596097427502
Epoch: 21 | Iteration number: [580/4518] 12% | Training loss: 0.6879289097827056
Epoch: 21 | Iteration number: [590/4518] 13% | Training loss: 0.6879029331570965
Epoch: 21 | Iteration number: [600/4518] 13% | Training loss: 0.6878969220320383
Epoch: 21 | Iteration number: [610/4518] 13% | Training loss: 0.6878869092855298
Epoch: 21 | Iteration number: [620/4518] 13% | Training loss: 0.6878732875470193
Epoch: 21 | Iteration number: [630/4518] 13% | Training loss: 0.687861279551945
Epoch: 21 | Iteration number: [640/4518] 14% | Training loss: 0.6878479004837572
Epoch: 21 | Iteration number: [650/4518] 14% | Training loss: 0.6878276787354396
Epoch: 21 | Iteration number: [660/4518] 14% | Training loss: 0.6878056973218918
Epoch: 21 | Iteration number: [670/4518] 14% | Training loss: 0.687780032940765
Epoch: 21 | Iteration number: [680/4518] 15% | Training loss: 0.6877740831936107
Epoch: 21 | Iteration number: [690/4518] 15% | Training loss: 0.6877450926580291
Epoch: 21 | Iteration number: [700/4518] 15% | Training loss: 0.6877234994513648
Epoch: 21 | Iteration number: [710/4518] 15% | Training loss: 0.6877056096641111
Epoch: 21 | Iteration number: [720/4518] 15% | Training loss: 0.6877000711858272
Epoch: 21 | Iteration number: [730/4518] 16% | Training loss: 0.6876784725548469
Epoch: 21 | Iteration number: [740/4518] 16% | Training loss: 0.6876669768546079
Epoch: 21 | Iteration number: [750/4518] 16% | Training loss: 0.6876554018656412
Epoch: 21 | Iteration number: [760/4518] 16% | Training loss: 0.6876397481090144
Epoch: 21 | Iteration number: [770/4518] 17% | Training loss: 0.6876054506023209
Epoch: 21 | Iteration number: [780/4518] 17% | Training loss: 0.6875976999600728
Epoch: 21 | Iteration number: [790/4518] 17% | Training loss: 0.6875779213030127
Epoch: 21 | Iteration number: [800/4518] 17% | Training loss: 0.6875675497204066
Epoch: 21 | Iteration number: [810/4518] 17% | Training loss: 0.6875784710601524
Epoch: 21 | Iteration number: [820/4518] 18% | Training loss: 0.6875681174237553
Epoch: 21 | Iteration number: [830/4518] 18% | Training loss: 0.6875436861112894
Epoch: 21 | Iteration number: [840/4518] 18% | Training loss: 0.6875355890109426
Epoch: 21 | Iteration number: [850/4518] 18% | Training loss: 0.6875334095954895
Epoch: 21 | Iteration number: [860/4518] 19% | Training loss: 0.6875306236882542
Epoch: 21 | Iteration number: [870/4518] 19% | Training loss: 0.687523113927622
Epoch: 21 | Iteration number: [880/4518] 19% | Training loss: 0.6875183226032691
Epoch: 21 | Iteration number: [890/4518] 19% | Training loss: 0.6875263699654782
Epoch: 21 | Iteration number: [900/4518] 19% | Training loss: 0.687513965566953
Epoch: 21 | Iteration number: [910/4518] 20% | Training loss: 0.6875193659420852
Epoch: 21 | Iteration number: [920/4518] 20% | Training loss: 0.6875279654627261
Epoch: 21 | Iteration number: [930/4518] 20% | Training loss: 0.6875246377401455
Epoch: 21 | Iteration number: [940/4518] 20% | Training loss: 0.6875150889158249
Epoch: 21 | Iteration number: [950/4518] 21% | Training loss: 0.6875167262554168
Epoch: 21 | Iteration number: [960/4518] 21% | Training loss: 0.6875113203500708
Epoch: 21 | Iteration number: [970/4518] 21% | Training loss: 0.687502586718687
Epoch: 21 | Iteration number: [980/4518] 21% | Training loss: 0.6874900401246791
Epoch: 21 | Iteration number: [990/4518] 21% | Training loss: 0.6874952996620024
Epoch: 21 | Iteration number: [1000/4518] 22% | Training loss: 0.6874992590546608
Epoch: 21 | Iteration number: [1010/4518] 22% | Training loss: 0.6874999703747211
Epoch: 21 | Iteration number: [1020/4518] 22% | Training loss: 0.6875026477902544
Epoch: 21 | Iteration number: [1030/4518] 22% | Training loss: 0.6874951182638557
Epoch: 21 | Iteration number: [1040/4518] 23% | Training loss: 0.6874760956718371
Epoch: 21 | Iteration number: [1050/4518] 23% | Training loss: 0.6874753640946888
Epoch: 21 | Iteration number: [1060/4518] 23% | Training loss: 0.6874670130464265
Epoch: 21 | Iteration number: [1070/4518] 23% | Training loss: 0.6874684747691466
Epoch: 21 | Iteration number: [1080/4518] 23% | Training loss: 0.687456340039218
Epoch: 21 | Iteration number: [1090/4518] 24% | Training loss: 0.687449867080111
Epoch: 21 | Iteration number: [1100/4518] 24% | Training loss: 0.687448526837609
Epoch: 21 | Iteration number: [1110/4518] 24% | Training loss: 0.6874421588472418
Epoch: 21 | Iteration number: [1120/4518] 24% | Training loss: 0.6874379608780146
Epoch: 21 | Iteration number: [1130/4518] 25% | Training loss: 0.6874335476782469
Epoch: 21 | Iteration number: [1140/4518] 25% | Training loss: 0.6874214184911628
Epoch: 21 | Iteration number: [1150/4518] 25% | Training loss: 0.6874130460490351
Epoch: 21 | Iteration number: [1160/4518] 25% | Training loss: 0.6874032020055014
Epoch: 21 | Iteration number: [1170/4518] 25% | Training loss: 0.6874080392540011
Epoch: 21 | Iteration number: [1180/4518] 26% | Training loss: 0.6874018619626255
Epoch: 21 | Iteration number: [1190/4518] 26% | Training loss: 0.6874052316701713
Epoch: 21 | Iteration number: [1200/4518] 26% | Training loss: 0.6874053493142128
Epoch: 21 | Iteration number: [1210/4518] 26% | Training loss: 0.6874083253962935
Epoch: 21 | Iteration number: [1220/4518] 27% | Training loss: 0.6874037295091348
Epoch: 21 | Iteration number: [1230/4518] 27% | Training loss: 0.6873957568067846
Epoch: 21 | Iteration number: [1240/4518] 27% | Training loss: 0.6873903371634021
Epoch: 21 | Iteration number: [1250/4518] 27% | Training loss: 0.6873809700489044
Epoch: 21 | Iteration number: [1260/4518] 27% | Training loss: 0.6873777795405615
Epoch: 21 | Iteration number: [1270/4518] 28% | Training loss: 0.6873785811615741
Epoch: 21 | Iteration number: [1280/4518] 28% | Training loss: 0.6873783119488508
Epoch: 21 | Iteration number: [1290/4518] 28% | Training loss: 0.6873639298039813
Epoch: 21 | Iteration number: [1300/4518] 28% | Training loss: 0.68737105516287
Epoch: 21 | Iteration number: [1310/4518] 28% | Training loss: 0.6873658609299259
Epoch: 21 | Iteration number: [1320/4518] 29% | Training loss: 0.6873613651954766
Epoch: 21 | Iteration number: [1330/4518] 29% | Training loss: 0.6873516160294526
Epoch: 21 | Iteration number: [1340/4518] 29% | Training loss: 0.68735784536867
Epoch: 21 | Iteration number: [1350/4518] 29% | Training loss: 0.687356158848162
Epoch: 21 | Iteration number: [1360/4518] 30% | Training loss: 0.6873584342791753
Epoch: 21 | Iteration number: [1370/4518] 30% | Training loss: 0.6873555772495966
Epoch: 21 | Iteration number: [1380/4518] 30% | Training loss: 0.6873507525609888
Epoch: 21 | Iteration number: [1390/4518] 30% | Training loss: 0.6873353931114828
Epoch: 21 | Iteration number: [1400/4518] 30% | Training loss: 0.6873406101976122
Epoch: 21 | Iteration number: [1410/4518] 31% | Training loss: 0.6873293164774036
Epoch: 21 | Iteration number: [1420/4518] 31% | Training loss: 0.687328672534983
Epoch: 21 | Iteration number: [1430/4518] 31% | Training loss: 0.6873243333576442
Epoch: 21 | Iteration number: [1440/4518] 31% | Training loss: 0.6873246987660726
Epoch: 21 | Iteration number: [1450/4518] 32% | Training loss: 0.6873258412295374
Epoch: 21 | Iteration number: [1460/4518] 32% | Training loss: 0.6873230970069154
Epoch: 21 | Iteration number: [1470/4518] 32% | Training loss: 0.6873229766784071
Epoch: 21 | Iteration number: [1480/4518] 32% | Training loss: 0.687313122282157
Epoch: 21 | Iteration number: [1490/4518] 32% | Training loss: 0.6873098024585903
Epoch: 21 | Iteration number: [1500/4518] 33% | Training loss: 0.6873058235645294
Epoch: 21 | Iteration number: [1510/4518] 33% | Training loss: 0.6872955139504363
Epoch: 21 | Iteration number: [1520/4518] 33% | Training loss: 0.687290331054675
Epoch: 21 | Iteration number: [1530/4518] 33% | Training loss: 0.6872912635990217
Epoch: 21 | Iteration number: [1540/4518] 34% | Training loss: 0.687281877847461
Epoch: 21 | Iteration number: [1550/4518] 34% | Training loss: 0.687277201144926
Epoch: 21 | Iteration number: [1560/4518] 34% | Training loss: 0.6872795711343105
Epoch: 21 | Iteration number: [1570/4518] 34% | Training loss: 0.6872794205216086
Epoch: 21 | Iteration number: [1580/4518] 34% | Training loss: 0.687266057390201
Epoch: 21 | Iteration number: [1590/4518] 35% | Training loss: 0.6872745558900654
Epoch: 21 | Iteration number: [1600/4518] 35% | Training loss: 0.6872710299119353
Epoch: 21 | Iteration number: [1610/4518] 35% | Training loss: 0.6872684098918986
Epoch: 21 | Iteration number: [1620/4518] 35% | Training loss: 0.6872675476618755
Epoch: 21 | Iteration number: [1630/4518] 36% | Training loss: 0.6872617626848396
Epoch: 21 | Iteration number: [1640/4518] 36% | Training loss: 0.6872682854169753
Epoch: 21 | Iteration number: [1650/4518] 36% | Training loss: 0.6872745415658662
Epoch: 21 | Iteration number: [1660/4518] 36% | Training loss: 0.687276731844408
Epoch: 21 | Iteration number: [1670/4518] 36% | Training loss: 0.6872719276451065
Epoch: 21 | Iteration number: [1680/4518] 37% | Training loss: 0.6872721211896056
Epoch: 21 | Iteration number: [1690/4518] 37% | Training loss: 0.6872657420014489
Epoch: 21 | Iteration number: [1700/4518] 37% | Training loss: 0.687261415404432
Epoch: 21 | Iteration number: [1710/4518] 37% | Training loss: 0.6872620157331054
Epoch: 21 | Iteration number: [1720/4518] 38% | Training loss: 0.6872583004970884
Epoch: 21 | Iteration number: [1730/4518] 38% | Training loss: 0.6872520431617781
Epoch: 21 | Iteration number: [1740/4518] 38% | Training loss: 0.6872462976938006
Epoch: 21 | Iteration number: [1750/4518] 38% | Training loss: 0.6872449272019523
Epoch: 21 | Iteration number: [1760/4518] 38% | Training loss: 0.6872488822788
Epoch: 21 | Iteration number: [1770/4518] 39% | Training loss: 0.6872471333223548
Epoch: 21 | Iteration number: [1780/4518] 39% | Training loss: 0.6872480310750811
Epoch: 21 | Iteration number: [1790/4518] 39% | Training loss: 0.6872536331914657
Epoch: 21 | Iteration number: [1800/4518] 39% | Training loss: 0.6872519142760171
Epoch: 21 | Iteration number: [1810/4518] 40% | Training loss: 0.6872450977069897
Epoch: 21 | Iteration number: [1820/4518] 40% | Training loss: 0.6872408887187204
Epoch: 21 | Iteration number: [1830/4518] 40% | Training loss: 0.6872422725450797
Epoch: 21 | Iteration number: [1840/4518] 40% | Training loss: 0.6872384466554807
Epoch: 21 | Iteration number: [1850/4518] 40% | Training loss: 0.6872428892109845
Epoch: 21 | Iteration number: [1860/4518] 41% | Training loss: 0.6872440996349499
Epoch: 21 | Iteration number: [1870/4518] 41% | Training loss: 0.6872415825007434
Epoch: 21 | Iteration number: [1880/4518] 41% | Training loss: 0.6872365044152483
Epoch: 21 | Iteration number: [1890/4518] 41% | Training loss: 0.6872294267018636
Epoch: 21 | Iteration number: [1900/4518] 42% | Training loss: 0.6872331799017756
Epoch: 21 | Iteration number: [1910/4518] 42% | Training loss: 0.6872427123691399
Epoch: 21 | Iteration number: [1920/4518] 42% | Training loss: 0.687242692646881
Epoch: 21 | Iteration number: [1930/4518] 42% | Training loss: 0.6872459366840402
Epoch: 21 | Iteration number: [1940/4518] 42% | Training loss: 0.6872473518872998
Epoch: 21 | Iteration number: [1950/4518] 43% | Training loss: 0.6872462209982749
Epoch: 21 | Iteration number: [1960/4518] 43% | Training loss: 0.6872395377378074
Epoch: 21 | Iteration number: [1970/4518] 43% | Training loss: 0.6872379378921489
Epoch: 21 | Iteration number: [1980/4518] 43% | Training loss: 0.6872431165341175
Epoch: 21 | Iteration number: [1990/4518] 44% | Training loss: 0.6872500094636601
Epoch: 21 | Iteration number: [2000/4518] 44% | Training loss: 0.6872503585219383
Epoch: 21 | Iteration number: [2010/4518] 44% | Training loss: 0.6872440213291207
Epoch: 21 | Iteration number: [2020/4518] 44% | Training loss: 0.6872398053360458
Epoch: 21 | Iteration number: [2030/4518] 44% | Training loss: 0.6872343190785112
Epoch: 21 | Iteration number: [2040/4518] 45% | Training loss: 0.6872334168822157
Epoch: 21 | Iteration number: [2050/4518] 45% | Training loss: 0.6872323478431236
Epoch: 21 | Iteration number: [2060/4518] 45% | Training loss: 0.6872286889159563
Epoch: 21 | Iteration number: [2070/4518] 45% | Training loss: 0.68722364122165
Epoch: 21 | Iteration number: [2080/4518] 46% | Training loss: 0.6872261707312786
Epoch: 21 | Iteration number: [2090/4518] 46% | Training loss: 0.6872299176368987
Epoch: 21 | Iteration number: [2100/4518] 46% | Training loss: 0.6872257826725642
Epoch: 21 | Iteration number: [2110/4518] 46% | Training loss: 0.6872254020512386
Epoch: 21 | Iteration number: [2120/4518] 46% | Training loss: 0.6872251614084783
Epoch: 21 | Iteration number: [2130/4518] 47% | Training loss: 0.68722325236025
Epoch: 21 | Iteration number: [2140/4518] 47% | Training loss: 0.6872129612715445
Epoch: 21 | Iteration number: [2150/4518] 47% | Training loss: 0.687207267201224
Epoch: 21 | Iteration number: [2160/4518] 47% | Training loss: 0.6872013043750216
Epoch: 21 | Iteration number: [2170/4518] 48% | Training loss: 0.6871991085566683
Epoch: 21 | Iteration number: [2180/4518] 48% | Training loss: 0.6872038051349307
Epoch: 21 | Iteration number: [2190/4518] 48% | Training loss: 0.6872001938623925
Epoch: 21 | Iteration number: [2200/4518] 48% | Training loss: 0.6872084202007814
Epoch: 21 | Iteration number: [2210/4518] 48% | Training loss: 0.6872007312278402
Epoch: 21 | Iteration number: [2220/4518] 49% | Training loss: 0.6872011923843676
Epoch: 21 | Iteration number: [2230/4518] 49% | Training loss: 0.6872014397462922
Epoch: 21 | Iteration number: [2240/4518] 49% | Training loss: 0.6872001614421606
Epoch: 21 | Iteration number: [2250/4518] 49% | Training loss: 0.6871926925182342
Epoch: 21 | Iteration number: [2260/4518] 50% | Training loss: 0.6871921658779667
Epoch: 21 | Iteration number: [2270/4518] 50% | Training loss: 0.6871909331382634
Epoch: 21 | Iteration number: [2280/4518] 50% | Training loss: 0.6871840586526352
Epoch: 21 | Iteration number: [2290/4518] 50% | Training loss: 0.6871903348697845
Epoch: 21 | Iteration number: [2300/4518] 50% | Training loss: 0.6871896094083786
Epoch: 21 | Iteration number: [2310/4518] 51% | Training loss: 0.6871907246319247
Epoch: 21 | Iteration number: [2320/4518] 51% | Training loss: 0.6871913891414116
Epoch: 21 | Iteration number: [2330/4518] 51% | Training loss: 0.687191522223755
Epoch: 21 | Iteration number: [2340/4518] 51% | Training loss: 0.687192449432153
Epoch: 21 | Iteration number: [2350/4518] 52% | Training loss: 0.6871933038944894
Epoch: 21 | Iteration number: [2360/4518] 52% | Training loss: 0.6871906061546277
Epoch: 21 | Iteration number: [2370/4518] 52% | Training loss: 0.6871943940341724
Epoch: 21 | Iteration number: [2380/4518] 52% | Training loss: 0.6871910960984831
Epoch: 21 | Iteration number: [2390/4518] 52% | Training loss: 0.6871886436659921
Epoch: 21 | Iteration number: [2400/4518] 53% | Training loss: 0.6871868757655223
Epoch: 21 | Iteration number: [2410/4518] 53% | Training loss: 0.687184796689457
Epoch: 21 | Iteration number: [2420/4518] 53% | Training loss: 0.6871931914209334
Epoch: 21 | Iteration number: [2430/4518] 53% | Training loss: 0.687195026163211
Epoch: 21 | Iteration number: [2440/4518] 54% | Training loss: 0.6871911523283505
Epoch: 21 | Iteration number: [2450/4518] 54% | Training loss: 0.6871912289638908
Epoch: 21 | Iteration number: [2460/4518] 54% | Training loss: 0.6871878299528991
Epoch: 21 | Iteration number: [2470/4518] 54% | Training loss: 0.687188840660489
Epoch: 21 | Iteration number: [2480/4518] 54% | Training loss: 0.6871892822846289
Epoch: 21 | Iteration number: [2490/4518] 55% | Training loss: 0.6871869410376951
Epoch: 21 | Iteration number: [2500/4518] 55% | Training loss: 0.6871831258296967
Epoch: 21 | Iteration number: [2510/4518] 55% | Training loss: 0.6871778688345297
Epoch: 21 | Iteration number: [2520/4518] 55% | Training loss: 0.6871758804198296
Epoch: 21 | Iteration number: [2530/4518] 55% | Training loss: 0.6871802365355812
Epoch: 21 | Iteration number: [2540/4518] 56% | Training loss: 0.6871784715905903
Epoch: 21 | Iteration number: [2550/4518] 56% | Training loss: 0.6871785085107766
Epoch: 21 | Iteration number: [2560/4518] 56% | Training loss: 0.687176123750396
Epoch: 21 | Iteration number: [2570/4518] 56% | Training loss: 0.6871726190997469
Epoch: 21 | Iteration number: [2580/4518] 57% | Training loss: 0.6871720894593601
Epoch: 21 | Iteration number: [2590/4518] 57% | Training loss: 0.6871739234012987
Epoch: 21 | Iteration number: [2600/4518] 57% | Training loss: 0.687173434816874
Epoch: 21 | Iteration number: [2610/4518] 57% | Training loss: 0.6871723355918095
Epoch: 21 | Iteration number: [2620/4518] 57% | Training loss: 0.6871733549214502
Epoch: 21 | Iteration number: [2630/4518] 58% | Training loss: 0.6871671643547232
Epoch: 21 | Iteration number: [2640/4518] 58% | Training loss: 0.6871645012136661
Epoch: 21 | Iteration number: [2650/4518] 58% | Training loss: 0.6871635942863968
Epoch: 21 | Iteration number: [2660/4518] 58% | Training loss: 0.6871642817007868
Epoch: 21 | Iteration number: [2670/4518] 59% | Training loss: 0.6871642293108536
Epoch: 21 | Iteration number: [2680/4518] 59% | Training loss: 0.6871648385231175
Epoch: 21 | Iteration number: [2690/4518] 59% | Training loss: 0.687164655937138
Epoch: 21 | Iteration number: [2700/4518] 59% | Training loss: 0.6871645037774686
Epoch: 21 | Iteration number: [2710/4518] 59% | Training loss: 0.6871663920553848
Epoch: 21 | Iteration number: [2720/4518] 60% | Training loss: 0.6871664021383314
Epoch: 21 | Iteration number: [2730/4518] 60% | Training loss: 0.6871638282751426
Epoch: 21 | Iteration number: [2740/4518] 60% | Training loss: 0.6871660837944407
Epoch: 21 | Iteration number: [2750/4518] 60% | Training loss: 0.6871622973138636
Epoch: 21 | Iteration number: [2760/4518] 61% | Training loss: 0.6871627468993698
Epoch: 21 | Iteration number: [2770/4518] 61% | Training loss: 0.6871581559146784
Epoch: 21 | Iteration number: [2780/4518] 61% | Training loss: 0.6871546627806245
Epoch: 21 | Iteration number: [2790/4518] 61% | Training loss: 0.6871567459943901
Epoch: 21 | Iteration number: [2800/4518] 61% | Training loss: 0.6871534469723701
Epoch: 21 | Iteration number: [2810/4518] 62% | Training loss: 0.6871540845713158
Epoch: 21 | Iteration number: [2820/4518] 62% | Training loss: 0.6871529612346744
Epoch: 21 | Iteration number: [2830/4518] 62% | Training loss: 0.6871487400557043
Epoch: 21 | Iteration number: [2840/4518] 62% | Training loss: 0.6871445319392312
Epoch: 21 | Iteration number: [2850/4518] 63% | Training loss: 0.6871422060748987
Epoch: 21 | Iteration number: [2860/4518] 63% | Training loss: 0.6871375309837447
Epoch: 21 | Iteration number: [2870/4518] 63% | Training loss: 0.6871326996058953
Epoch: 21 | Iteration number: [2880/4518] 63% | Training loss: 0.6871321533289221
Epoch: 21 | Iteration number: [2890/4518] 63% | Training loss: 0.687135262039706
Epoch: 21 | Iteration number: [2900/4518] 64% | Training loss: 0.6871337738530389
Epoch: 21 | Iteration number: [2910/4518] 64% | Training loss: 0.6871329016906699
Epoch: 21 | Iteration number: [2920/4518] 64% | Training loss: 0.6871320193352765
Epoch: 21 | Iteration number: [2930/4518] 64% | Training loss: 0.6871309045842077
Epoch: 21 | Iteration number: [2940/4518] 65% | Training loss: 0.6871353975161403
Epoch: 21 | Iteration number: [2950/4518] 65% | Training loss: 0.6871346359939898
Epoch: 21 | Iteration number: [2960/4518] 65% | Training loss: 0.6871331325656659
Epoch: 21 | Iteration number: [2970/4518] 65% | Training loss: 0.6871270168108571
Epoch: 21 | Iteration number: [2980/4518] 65% | Training loss: 0.6871269754515398
Epoch: 21 | Iteration number: [2990/4518] 66% | Training loss: 0.6871238059024747
Epoch: 21 | Iteration number: [3000/4518] 66% | Training loss: 0.6871206182241439
Epoch: 21 | Iteration number: [3010/4518] 66% | Training loss: 0.6871185557786809
Epoch: 21 | Iteration number: [3020/4518] 66% | Training loss: 0.6871209273669894
Epoch: 21 | Iteration number: [3030/4518] 67% | Training loss: 0.6871237516599913
Epoch: 21 | Iteration number: [3040/4518] 67% | Training loss: 0.6871229174693948
Epoch: 21 | Iteration number: [3050/4518] 67% | Training loss: 0.6871214746647194
Epoch: 21 | Iteration number: [3060/4518] 67% | Training loss: 0.6871219397370332
Epoch: 21 | Iteration number: [3070/4518] 67% | Training loss: 0.6871214718500256
Epoch: 21 | Iteration number: [3080/4518] 68% | Training loss: 0.6871197436730583
Epoch: 21 | Iteration number: [3090/4518] 68% | Training loss: 0.6871227493178111
Epoch: 21 | Iteration number: [3100/4518] 68% | Training loss: 0.6871216290420101
Epoch: 21 | Iteration number: [3110/4518] 68% | Training loss: 0.6871180961753011
Epoch: 21 | Iteration number: [3120/4518] 69% | Training loss: 0.6871141379842391
Epoch: 21 | Iteration number: [3130/4518] 69% | Training loss: 0.6871108085964435
Epoch: 21 | Iteration number: [3140/4518] 69% | Training loss: 0.6871084077912532
Epoch: 21 | Iteration number: [3150/4518] 69% | Training loss: 0.687107857806342
Epoch: 21 | Iteration number: [3160/4518] 69% | Training loss: 0.6871048931079575
Epoch: 21 | Iteration number: [3170/4518] 70% | Training loss: 0.6870984803990987
Epoch: 21 | Iteration number: [3180/4518] 70% | Training loss: 0.6870985717705961
Epoch: 21 | Iteration number: [3190/4518] 70% | Training loss: 0.6870982790254874
Epoch: 21 | Iteration number: [3200/4518] 70% | Training loss: 0.6870985975116491
Epoch: 21 | Iteration number: [3210/4518] 71% | Training loss: 0.6870975355864314
Epoch: 21 | Iteration number: [3220/4518] 71% | Training loss: 0.6870953880852053
Epoch: 21 | Iteration number: [3230/4518] 71% | Training loss: 0.6870932264962801
Epoch: 21 | Iteration number: [3240/4518] 71% | Training loss: 0.6870980947289937
Epoch: 21 | Iteration number: [3250/4518] 71% | Training loss: 0.6870911625165206
Epoch: 21 | Iteration number: [3260/4518] 72% | Training loss: 0.6870924181550558
Epoch: 21 | Iteration number: [3270/4518] 72% | Training loss: 0.6870900073547247
Epoch: 21 | Iteration number: [3280/4518] 72% | Training loss: 0.6870849662074229
Epoch: 21 | Iteration number: [3290/4518] 72% | Training loss: 0.6870857233696795
Epoch: 21 | Iteration number: [3300/4518] 73% | Training loss: 0.6870840841712373
Epoch: 21 | Iteration number: [3310/4518] 73% | Training loss: 0.687085245058976
Epoch: 21 | Iteration number: [3320/4518] 73% | Training loss: 0.687088000289647
Epoch: 21 | Iteration number: [3330/4518] 73% | Training loss: 0.6870862832477501
Epoch: 21 | Iteration number: [3340/4518] 73% | Training loss: 0.6870856463373778
Epoch: 21 | Iteration number: [3350/4518] 74% | Training loss: 0.6870817388171581
Epoch: 21 | Iteration number: [3360/4518] 74% | Training loss: 0.6870795173659211
Epoch: 21 | Iteration number: [3370/4518] 74% | Training loss: 0.6870810972830662
Epoch: 21 | Iteration number: [3380/4518] 74% | Training loss: 0.6870796490879454
Epoch: 21 | Iteration number: [3390/4518] 75% | Training loss: 0.6870805519696183
Epoch: 21 | Iteration number: [3400/4518] 75% | Training loss: 0.6870824016192381
Epoch: 21 | Iteration number: [3410/4518] 75% | Training loss: 0.6870827644626416
Epoch: 21 | Iteration number: [3420/4518] 75% | Training loss: 0.6870858747882452
Epoch: 21 | Iteration number: [3430/4518] 75% | Training loss: 0.6870869062037231
Epoch: 21 | Iteration number: [3440/4518] 76% | Training loss: 0.6870848295300506
Epoch: 21 | Iteration number: [3450/4518] 76% | Training loss: 0.6870837837889574
Epoch: 21 | Iteration number: [3460/4518] 76% | Training loss: 0.687083201532419
Epoch: 21 | Iteration number: [3470/4518] 76% | Training loss: 0.6870814575585577
Epoch: 21 | Iteration number: [3480/4518] 77% | Training loss: 0.6870823468798879
Epoch: 21 | Iteration number: [3490/4518] 77% | Training loss: 0.6870806617518209
Epoch: 21 | Iteration number: [3500/4518] 77% | Training loss: 0.6870834537914821
Epoch: 21 | Iteration number: [3510/4518] 77% | Training loss: 0.687085213416662
Epoch: 21 | Iteration number: [3520/4518] 77% | Training loss: 0.6870874621820721
Epoch: 21 | Iteration number: [3530/4518] 78% | Training loss: 0.6870875148192344
Epoch: 21 | Iteration number: [3540/4518] 78% | Training loss: 0.6870852268179931
Epoch: 21 | Iteration number: [3550/4518] 78% | Training loss: 0.6870833948800261
Epoch: 21 | Iteration number: [3560/4518] 78% | Training loss: 0.6870823645022478
Epoch: 21 | Iteration number: [3570/4518] 79% | Training loss: 0.6870835568056721
Epoch: 21 | Iteration number: [3580/4518] 79% | Training loss: 0.6870779817330771
Epoch: 21 | Iteration number: [3590/4518] 79% | Training loss: 0.6870766785981596
Epoch: 21 | Iteration number: [3600/4518] 79% | Training loss: 0.6870757885773977
Epoch: 21 | Iteration number: [3610/4518] 79% | Training loss: 0.6870760950025099
Epoch: 21 | Iteration number: [3620/4518] 80% | Training loss: 0.687075309397766
Epoch: 21 | Iteration number: [3630/4518] 80% | Training loss: 0.6870713469739131
Epoch: 21 | Iteration number: [3640/4518] 80% | Training loss: 0.6870689814562326
Epoch: 21 | Iteration number: [3650/4518] 80% | Training loss: 0.6870694515313188
Epoch: 21 | Iteration number: [3660/4518] 81% | Training loss: 0.6870656384470685
Epoch: 21 | Iteration number: [3670/4518] 81% | Training loss: 0.6870640117888229
Epoch: 21 | Iteration number: [3680/4518] 81% | Training loss: 0.6870638268311386
Epoch: 21 | Iteration number: [3690/4518] 81% | Training loss: 0.6870627209746094
Epoch: 21 | Iteration number: [3700/4518] 81% | Training loss: 0.687059248830821
Epoch: 21 | Iteration number: [3710/4518] 82% | Training loss: 0.6870577111719753
Epoch: 21 | Iteration number: [3720/4518] 82% | Training loss: 0.6870592858842625
Epoch: 21 | Iteration number: [3730/4518] 82% | Training loss: 0.6870580575741009
Epoch: 21 | Iteration number: [3740/4518] 82% | Training loss: 0.6870561874167804
Epoch: 21 | Iteration number: [3750/4518] 83% | Training loss: 0.6870560069084167
Epoch: 21 | Iteration number: [3760/4518] 83% | Training loss: 0.6870554747733664
Epoch: 21 | Iteration number: [3770/4518] 83% | Training loss: 0.6870552905832741
Epoch: 21 | Iteration number: [3780/4518] 83% | Training loss: 0.6870556205826461
Epoch: 21 | Iteration number: [3790/4518] 83% | Training loss: 0.6870520693331091
Epoch: 21 | Iteration number: [3800/4518] 84% | Training loss: 0.6870507202179809
Epoch: 21 | Iteration number: [3810/4518] 84% | Training loss: 0.687054852441227
Epoch: 21 | Iteration number: [3820/4518] 84% | Training loss: 0.687052756454308
Epoch: 21 | Iteration number: [3830/4518] 84% | Training loss: 0.6870483890681603
Epoch: 21 | Iteration number: [3840/4518] 84% | Training loss: 0.6870478425795833
Epoch: 21 | Iteration number: [3850/4518] 85% | Training loss: 0.6870455604559416
Epoch: 21 | Iteration number: [3860/4518] 85% | Training loss: 0.6870452202972352
Epoch: 21 | Iteration number: [3870/4518] 85% | Training loss: 0.6870437172340176
Epoch: 21 | Iteration number: [3880/4518] 85% | Training loss: 0.6870442156171062
Epoch: 21 | Iteration number: [3890/4518] 86% | Training loss: 0.6870430191409006
Epoch: 21 | Iteration number: [3900/4518] 86% | Training loss: 0.6870433411689905
Epoch: 21 | Iteration number: [3910/4518] 86% | Training loss: 0.6870462366687062
Epoch: 21 | Iteration number: [3920/4518] 86% | Training loss: 0.6870481649071586
Epoch: 21 | Iteration number: [3930/4518] 86% | Training loss: 0.6870481084321292
Epoch: 21 | Iteration number: [3940/4518] 87% | Training loss: 0.6870477472918893
Epoch: 21 | Iteration number: [3950/4518] 87% | Training loss: 0.6870480533642105
Epoch: 21 | Iteration number: [3960/4518] 87% | Training loss: 0.6870501060678501
Epoch: 21 | Iteration number: [3970/4518] 87% | Training loss: 0.6870515599058618
Epoch: 21 | Iteration number: [3980/4518] 88% | Training loss: 0.6870540660829401
Epoch: 21 | Iteration number: [3990/4518] 88% | Training loss: 0.6870553044000066
Epoch: 21 | Iteration number: [4000/4518] 88% | Training loss: 0.6870552368760109
Epoch: 21 | Iteration number: [4010/4518] 88% | Training loss: 0.6870577657014652
Epoch: 21 | Iteration number: [4020/4518] 88% | Training loss: 0.6870557706302671
Epoch: 21 | Iteration number: [4030/4518] 89% | Training loss: 0.6870536031705274
Epoch: 21 | Iteration number: [4040/4518] 89% | Training loss: 0.6870565481262632
Epoch: 21 | Iteration number: [4050/4518] 89% | Training loss: 0.6870585131203687
Epoch: 21 | Iteration number: [4060/4518] 89% | Training loss: 0.6870578689087787
Epoch: 21 | Iteration number: [4070/4518] 90% | Training loss: 0.687056915795188
Epoch: 21 | Iteration number: [4080/4518] 90% | Training loss: 0.6870561560433285
Epoch: 21 | Iteration number: [4090/4518] 90% | Training loss: 0.6870574554487662
Epoch: 21 | Iteration number: [4100/4518] 90% | Training loss: 0.6870555114600717
Epoch: 21 | Iteration number: [4110/4518] 90% | Training loss: 0.6870587475398451
Epoch: 21 | Iteration number: [4120/4518] 91% | Training loss: 0.6870539857345878
Epoch: 21 | Iteration number: [4130/4518] 91% | Training loss: 0.6870535314371742
Epoch: 21 | Iteration number: [4140/4518] 91% | Training loss: 0.6870557312516199
Epoch: 21 | Iteration number: [4150/4518] 91% | Training loss: 0.6870504152918436
Epoch: 21 | Iteration number: [4160/4518] 92% | Training loss: 0.6870503409264179
Epoch: 21 | Iteration number: [4170/4518] 92% | Training loss: 0.6870499735970578
Epoch: 21 | Iteration number: [4180/4518] 92% | Training loss: 0.6870500239886735
Epoch: 21 | Iteration number: [4190/4518] 92% | Training loss: 0.6870493664519599
Epoch: 21 | Iteration number: [4200/4518] 92% | Training loss: 0.6870473276149659
Epoch: 21 | Iteration number: [4210/4518] 93% | Training loss: 0.6870466899277196
Epoch: 21 | Iteration number: [4220/4518] 93% | Training loss: 0.6870465158709983
Epoch: 21 | Iteration number: [4230/4518] 93% | Training loss: 0.6870497760056886
Epoch: 21 | Iteration number: [4240/4518] 93% | Training loss: 0.6870491392629327
Epoch: 21 | Iteration number: [4250/4518] 94% | Training loss: 0.6870516519686755
Epoch: 21 | Iteration number: [4260/4518] 94% | Training loss: 0.6870525852055617
Epoch: 21 | Iteration number: [4270/4518] 94% | Training loss: 0.6870538198975824
Epoch: 21 | Iteration number: [4280/4518] 94% | Training loss: 0.6870507710169409
Epoch: 21 | Iteration number: [4290/4518] 94% | Training loss: 0.6870506208120803
Epoch: 21 | Iteration number: [4300/4518] 95% | Training loss: 0.6870499799002049
Epoch: 21 | Iteration number: [4310/4518] 95% | Training loss: 0.6870491834499997
Epoch: 21 | Iteration number: [4320/4518] 95% | Training loss: 0.6870474423385329
Epoch: 21 | Iteration number: [4330/4518] 95% | Training loss: 0.6870490974697174
Epoch: 21 | Iteration number: [4340/4518] 96% | Training loss: 0.6870452946506888
Epoch: 21 | Iteration number: [4350/4518] 96% | Training loss: 0.687046359681535
Epoch: 21 | Iteration number: [4360/4518] 96% | Training loss: 0.6870465592643537
Epoch: 21 | Iteration number: [4370/4518] 96% | Training loss: 0.687047940519909
Epoch: 21 | Iteration number: [4380/4518] 96% | Training loss: 0.6870465497720187
Epoch: 21 | Iteration number: [4390/4518] 97% | Training loss: 0.6870484198823333
Epoch: 21 | Iteration number: [4400/4518] 97% | Training loss: 0.6870459449426695
Epoch: 21 | Iteration number: [4410/4518] 97% | Training loss: 0.6870447065689667
Epoch: 21 | Iteration number: [4420/4518] 97% | Training loss: 0.6870448263926744
Epoch: 21 | Iteration number: [4430/4518] 98% | Training loss: 0.68704577119302
Epoch: 21 | Iteration number: [4440/4518] 98% | Training loss: 0.6870446165939709
Epoch: 21 | Iteration number: [4450/4518] 98% | Training loss: 0.6870437112685
Epoch: 21 | Iteration number: [4460/4518] 98% | Training loss: 0.6870428163107201
Epoch: 21 | Iteration number: [4470/4518] 98% | Training loss: 0.6870418742332416
Epoch: 21 | Iteration number: [4480/4518] 99% | Training loss: 0.687039603093373
Epoch: 21 | Iteration number: [4490/4518] 99% | Training loss: 0.6870389839190417
Epoch: 21 | Iteration number: [4500/4518] 99% | Training loss: 0.6870403002632989
Epoch: 21 | Iteration number: [4510/4518] 99% | Training loss: 0.687039945580214

 End of epoch: 21 | Train Loss: 0.6868857203225427 | Training Time: 633 

 End of epoch: 21 | Eval Loss: 0.6899981097299226 | Evaluating Time: 18 
Epoch: 22 | Iteration number: [10/4518] 0% | Training loss: 0.755655187368393
Epoch: 22 | Iteration number: [20/4518] 0% | Training loss: 0.7203987807035446
Epoch: 22 | Iteration number: [30/4518] 0% | Training loss: 0.7090799748897553
Epoch: 22 | Iteration number: [40/4518] 0% | Training loss: 0.7036970958113671
Epoch: 22 | Iteration number: [50/4518] 1% | Training loss: 0.699991934299469
Epoch: 22 | Iteration number: [60/4518] 1% | Training loss: 0.6976735264062881
Epoch: 22 | Iteration number: [70/4518] 1% | Training loss: 0.6961176889283317
Epoch: 22 | Iteration number: [80/4518] 1% | Training loss: 0.6950623378157615
Epoch: 22 | Iteration number: [90/4518] 1% | Training loss: 0.6942218018902673
Epoch: 22 | Iteration number: [100/4518] 2% | Training loss: 0.6934374856948853
Epoch: 22 | Iteration number: [110/4518] 2% | Training loss: 0.6926545842127366
Epoch: 22 | Iteration number: [120/4518] 2% | Training loss: 0.6921344742178916
Epoch: 22 | Iteration number: [130/4518] 2% | Training loss: 0.6916804075241089
Epoch: 22 | Iteration number: [140/4518] 3% | Training loss: 0.691366468157087
Epoch: 22 | Iteration number: [150/4518] 3% | Training loss: 0.6910197071234385
Epoch: 22 | Iteration number: [160/4518] 3% | Training loss: 0.6907576620578766
Epoch: 22 | Iteration number: [170/4518] 3% | Training loss: 0.6904212327564464
Epoch: 22 | Iteration number: [180/4518] 3% | Training loss: 0.6901754392517938
Epoch: 22 | Iteration number: [190/4518] 4% | Training loss: 0.690006801329161
Epoch: 22 | Iteration number: [200/4518] 4% | Training loss: 0.6899090239405632
Epoch: 22 | Iteration number: [210/4518] 4% | Training loss: 0.6896910548210144
Epoch: 22 | Iteration number: [220/4518] 4% | Training loss: 0.6895342138680545
Epoch: 22 | Iteration number: [230/4518] 5% | Training loss: 0.6894169232119685
Epoch: 22 | Iteration number: [240/4518] 5% | Training loss: 0.6893031008541584
Epoch: 22 | Iteration number: [250/4518] 5% | Training loss: 0.6892651166915894
Epoch: 22 | Iteration number: [260/4518] 5% | Training loss: 0.6891673984435889
Epoch: 22 | Iteration number: [270/4518] 5% | Training loss: 0.6891184224022759
Epoch: 22 | Iteration number: [280/4518] 6% | Training loss: 0.6890811764768192
Epoch: 22 | Iteration number: [290/4518] 6% | Training loss: 0.6890123936636695
Epoch: 22 | Iteration number: [300/4518] 6% | Training loss: 0.6889229347308476
Epoch: 22 | Iteration number: [310/4518] 6% | Training loss: 0.6888481797710542
Epoch: 22 | Iteration number: [320/4518] 7% | Training loss: 0.6887658728286624
Epoch: 22 | Iteration number: [330/4518] 7% | Training loss: 0.68869489124327
Epoch: 22 | Iteration number: [340/4518] 7% | Training loss: 0.6886285380405538
Epoch: 22 | Iteration number: [350/4518] 7% | Training loss: 0.6885389862741743
Epoch: 22 | Iteration number: [360/4518] 7% | Training loss: 0.6884810177816285
Epoch: 22 | Iteration number: [370/4518] 8% | Training loss: 0.6884229948391786
Epoch: 22 | Iteration number: [380/4518] 8% | Training loss: 0.6884036813911639
Epoch: 22 | Iteration number: [390/4518] 8% | Training loss: 0.6883537283310524
Epoch: 22 | Iteration number: [400/4518] 8% | Training loss: 0.688320125490427
Epoch: 22 | Iteration number: [410/4518] 9% | Training loss: 0.6883112619562847
Epoch: 22 | Iteration number: [420/4518] 9% | Training loss: 0.6882659524679184
Epoch: 22 | Iteration number: [430/4518] 9% | Training loss: 0.6882514030434365
Epoch: 22 | Iteration number: [440/4518] 9% | Training loss: 0.6882251725955443
Epoch: 22 | Iteration number: [450/4518] 9% | Training loss: 0.6881796566645304
Epoch: 22 | Iteration number: [460/4518] 10% | Training loss: 0.688155643965887
Epoch: 22 | Iteration number: [470/4518] 10% | Training loss: 0.6881259117988829
Epoch: 22 | Iteration number: [480/4518] 10% | Training loss: 0.6881085798144341
Epoch: 22 | Iteration number: [490/4518] 10% | Training loss: 0.6880649850076559
Epoch: 22 | Iteration number: [500/4518] 11% | Training loss: 0.6880278416872024
Epoch: 22 | Iteration number: [510/4518] 11% | Training loss: 0.6879725812696943
Epoch: 22 | Iteration number: [520/4518] 11% | Training loss: 0.6879605535131235
Epoch: 22 | Iteration number: [530/4518] 11% | Training loss: 0.6879231353975692
Epoch: 22 | Iteration number: [540/4518] 11% | Training loss: 0.6879088471333186
Epoch: 22 | Iteration number: [550/4518] 12% | Training loss: 0.6878852266615088
Epoch: 22 | Iteration number: [560/4518] 12% | Training loss: 0.6878472508064338
Epoch: 22 | Iteration number: [570/4518] 12% | Training loss: 0.6878197517311364
Epoch: 22 | Iteration number: [580/4518] 12% | Training loss: 0.6877858198922256
Epoch: 22 | Iteration number: [590/4518] 13% | Training loss: 0.6877642016289598
Epoch: 22 | Iteration number: [600/4518] 13% | Training loss: 0.6877553191781044
Epoch: 22 | Iteration number: [610/4518] 13% | Training loss: 0.6877455394776141
Epoch: 22 | Iteration number: [620/4518] 13% | Training loss: 0.6877253561250625
Epoch: 22 | Iteration number: [630/4518] 13% | Training loss: 0.6877348818476238
Epoch: 22 | Iteration number: [640/4518] 14% | Training loss: 0.6876950612291693
Epoch: 22 | Iteration number: [650/4518] 14% | Training loss: 0.6876968044501085
Epoch: 22 | Iteration number: [660/4518] 14% | Training loss: 0.6876755490447536
Epoch: 22 | Iteration number: [670/4518] 14% | Training loss: 0.6876596189256924
Epoch: 22 | Iteration number: [680/4518] 15% | Training loss: 0.687661109689404
Epoch: 22 | Iteration number: [690/4518] 15% | Training loss: 0.6876582405705383
Epoch: 22 | Iteration number: [700/4518] 15% | Training loss: 0.6876551193850381
Epoch: 22 | Iteration number: [710/4518] 15% | Training loss: 0.687630008391931
Epoch: 22 | Iteration number: [720/4518] 15% | Training loss: 0.6876214270790418
Epoch: 22 | Iteration number: [730/4518] 16% | Training loss: 0.6876166200801118
Epoch: 22 | Iteration number: [740/4518] 16% | Training loss: 0.6875946852806453
Epoch: 22 | Iteration number: [750/4518] 16% | Training loss: 0.6875758392810821
Epoch: 22 | Iteration number: [760/4518] 16% | Training loss: 0.6875674823397084
Epoch: 22 | Iteration number: [770/4518] 17% | Training loss: 0.6875525048800877
Epoch: 22 | Iteration number: [780/4518] 17% | Training loss: 0.6875372253167323
Epoch: 22 | Iteration number: [790/4518] 17% | Training loss: 0.6875228135646144
Epoch: 22 | Iteration number: [800/4518] 17% | Training loss: 0.6875344532728195
Epoch: 22 | Iteration number: [810/4518] 17% | Training loss: 0.6875227662516229
Epoch: 22 | Iteration number: [820/4518] 18% | Training loss: 0.6875189298536719
Epoch: 22 | Iteration number: [830/4518] 18% | Training loss: 0.6875107460711376
Epoch: 22 | Iteration number: [840/4518] 18% | Training loss: 0.6874980104821069
Epoch: 22 | Iteration number: [850/4518] 18% | Training loss: 0.6874907868048724
Epoch: 22 | Iteration number: [860/4518] 19% | Training loss: 0.6874750725058623
Epoch: 22 | Iteration number: [870/4518] 19% | Training loss: 0.687465386007024
Epoch: 22 | Iteration number: [880/4518] 19% | Training loss: 0.6874577919867906
Epoch: 22 | Iteration number: [890/4518] 19% | Training loss: 0.6874464316314526
Epoch: 22 | Iteration number: [900/4518] 19% | Training loss: 0.6874483892652723
Epoch: 22 | Iteration number: [910/4518] 20% | Training loss: 0.687448646734049
Epoch: 22 | Iteration number: [920/4518] 20% | Training loss: 0.6874439069110414
Epoch: 22 | Iteration number: [930/4518] 20% | Training loss: 0.6874379209933742
Epoch: 22 | Iteration number: [940/4518] 20% | Training loss: 0.6874265146382311
Epoch: 22 | Iteration number: [950/4518] 21% | Training loss: 0.6874197031322279
Epoch: 22 | Iteration number: [960/4518] 21% | Training loss: 0.687421198685964
Epoch: 22 | Iteration number: [970/4518] 21% | Training loss: 0.6874195570183783
Epoch: 22 | Iteration number: [980/4518] 21% | Training loss: 0.6874144123525036
Epoch: 22 | Iteration number: [990/4518] 21% | Training loss: 0.6873955761543428
Epoch: 22 | Iteration number: [1000/4518] 22% | Training loss: 0.6873987951874733
Epoch: 22 | Iteration number: [1010/4518] 22% | Training loss: 0.6874045423942037
Epoch: 22 | Iteration number: [1020/4518] 22% | Training loss: 0.6873906171789357
Epoch: 22 | Iteration number: [1030/4518] 22% | Training loss: 0.6873791897759854
Epoch: 22 | Iteration number: [1040/4518] 23% | Training loss: 0.6873658339564617
Epoch: 22 | Iteration number: [1050/4518] 23% | Training loss: 0.6873712603818802
Epoch: 22 | Iteration number: [1060/4518] 23% | Training loss: 0.6873597955366351
Epoch: 22 | Iteration number: [1070/4518] 23% | Training loss: 0.6873614993607886
Epoch: 22 | Iteration number: [1080/4518] 23% | Training loss: 0.6873613544636302
Epoch: 22 | Iteration number: [1090/4518] 24% | Training loss: 0.6873608221701526
Epoch: 22 | Iteration number: [1100/4518] 24% | Training loss: 0.6873464086380872
Epoch: 22 | Iteration number: [1110/4518] 24% | Training loss: 0.6873482030254227
Epoch: 22 | Iteration number: [1120/4518] 24% | Training loss: 0.6873408147799117
Epoch: 22 | Iteration number: [1130/4518] 25% | Training loss: 0.6873328963212207
Epoch: 22 | Iteration number: [1140/4518] 25% | Training loss: 0.6873403402796963
Epoch: 22 | Iteration number: [1150/4518] 25% | Training loss: 0.68733727802401
Epoch: 22 | Iteration number: [1160/4518] 25% | Training loss: 0.6873396628375711
Epoch: 22 | Iteration number: [1170/4518] 25% | Training loss: 0.6873423611506437
Epoch: 22 | Iteration number: [1180/4518] 26% | Training loss: 0.6873485244936862
Epoch: 22 | Iteration number: [1190/4518] 26% | Training loss: 0.6873441569945391
Epoch: 22 | Iteration number: [1200/4518] 26% | Training loss: 0.6873535461723804
Epoch: 22 | Iteration number: [1210/4518] 26% | Training loss: 0.6873566086627235
Epoch: 22 | Iteration number: [1220/4518] 27% | Training loss: 0.6873434169859183
Epoch: 22 | Iteration number: [1230/4518] 27% | Training loss: 0.6873422289766916
Epoch: 22 | Iteration number: [1240/4518] 27% | Training loss: 0.6873455884475862
Epoch: 22 | Iteration number: [1250/4518] 27% | Training loss: 0.6873365325927734
Epoch: 22 | Iteration number: [1260/4518] 27% | Training loss: 0.687343050184704
Epoch: 22 | Iteration number: [1270/4518] 28% | Training loss: 0.6873483090888797
Epoch: 22 | Iteration number: [1280/4518] 28% | Training loss: 0.687341270595789
Epoch: 22 | Iteration number: [1290/4518] 28% | Training loss: 0.6873445049274799
Epoch: 22 | Iteration number: [1300/4518] 28% | Training loss: 0.6873485320806503
Epoch: 22 | Iteration number: [1310/4518] 28% | Training loss: 0.6873464342292028
Epoch: 22 | Iteration number: [1320/4518] 29% | Training loss: 0.6873400620890386
Epoch: 22 | Iteration number: [1330/4518] 29% | Training loss: 0.6873489163871994
Epoch: 22 | Iteration number: [1340/4518] 29% | Training loss: 0.6873435144104175
Epoch: 22 | Iteration number: [1350/4518] 29% | Training loss: 0.6873476917213864
Epoch: 22 | Iteration number: [1360/4518] 30% | Training loss: 0.6873395339969326
Epoch: 22 | Iteration number: [1370/4518] 30% | Training loss: 0.6873292845531102
Epoch: 22 | Iteration number: [1380/4518] 30% | Training loss: 0.6873211158358532
Epoch: 22 | Iteration number: [1390/4518] 30% | Training loss: 0.6873129016203846
Epoch: 22 | Iteration number: [1400/4518] 30% | Training loss: 0.6873154039893832
Epoch: 22 | Iteration number: [1410/4518] 31% | Training loss: 0.6873041005422037
Epoch: 22 | Iteration number: [1420/4518] 31% | Training loss: 0.6872968251436529
Epoch: 22 | Iteration number: [1430/4518] 31% | Training loss: 0.6872921874056329
Epoch: 22 | Iteration number: [1440/4518] 31% | Training loss: 0.687297514370746
Epoch: 22 | Iteration number: [1450/4518] 32% | Training loss: 0.687296492971223
Epoch: 22 | Iteration number: [1460/4518] 32% | Training loss: 0.687291704016189
Epoch: 22 | Iteration number: [1470/4518] 32% | Training loss: 0.6872918140320551
Epoch: 22 | Iteration number: [1480/4518] 32% | Training loss: 0.6872915963868838
Epoch: 22 | Iteration number: [1490/4518] 32% | Training loss: 0.6872803822859822
Epoch: 22 | Iteration number: [1500/4518] 33% | Training loss: 0.6872761486371358
Epoch: 22 | Iteration number: [1510/4518] 33% | Training loss: 0.6872711414138213
Epoch: 22 | Iteration number: [1520/4518] 33% | Training loss: 0.6872658470351445
Epoch: 22 | Iteration number: [1530/4518] 33% | Training loss: 0.6872631424003177
Epoch: 22 | Iteration number: [1540/4518] 34% | Training loss: 0.6872634690303308
Epoch: 22 | Iteration number: [1550/4518] 34% | Training loss: 0.687253852582747
Epoch: 22 | Iteration number: [1560/4518] 34% | Training loss: 0.687241875170133
Epoch: 22 | Iteration number: [1570/4518] 34% | Training loss: 0.6872386800635393
Epoch: 22 | Iteration number: [1580/4518] 34% | Training loss: 0.6872438261780558
Epoch: 22 | Iteration number: [1590/4518] 35% | Training loss: 0.6872420449676754
Epoch: 22 | Iteration number: [1600/4518] 35% | Training loss: 0.6872328213974833
Epoch: 22 | Iteration number: [1610/4518] 35% | Training loss: 0.6872397761907637
Epoch: 22 | Iteration number: [1620/4518] 35% | Training loss: 0.6872338084894933
Epoch: 22 | Iteration number: [1630/4518] 36% | Training loss: 0.6872320693694741
Epoch: 22 | Iteration number: [1640/4518] 36% | Training loss: 0.6872222122259256
Epoch: 22 | Iteration number: [1650/4518] 36% | Training loss: 0.6872135836066622
Epoch: 22 | Iteration number: [1660/4518] 36% | Training loss: 0.6872103532035667
Epoch: 22 | Iteration number: [1670/4518] 36% | Training loss: 0.6872065004831303
Epoch: 22 | Iteration number: [1680/4518] 37% | Training loss: 0.6872148247701781
Epoch: 22 | Iteration number: [1690/4518] 37% | Training loss: 0.6872095671631175
Epoch: 22 | Iteration number: [1700/4518] 37% | Training loss: 0.6872099331196617
Epoch: 22 | Iteration number: [1710/4518] 37% | Training loss: 0.6872097870411231
Epoch: 22 | Iteration number: [1720/4518] 38% | Training loss: 0.6872080620291621
Epoch: 22 | Iteration number: [1730/4518] 38% | Training loss: 0.6872029013716416
Epoch: 22 | Iteration number: [1740/4518] 38% | Training loss: 0.6872135559717815
Epoch: 22 | Iteration number: [1750/4518] 38% | Training loss: 0.6872055798598699
Epoch: 22 | Iteration number: [1760/4518] 38% | Training loss: 0.6872016001492739
Epoch: 22 | Iteration number: [1770/4518] 39% | Training loss: 0.687198158307264
Epoch: 22 | Iteration number: [1780/4518] 39% | Training loss: 0.6872002019641105
Epoch: 22 | Iteration number: [1790/4518] 39% | Training loss: 0.687194817359221
Epoch: 22 | Iteration number: [1800/4518] 39% | Training loss: 0.6871914931469494
Epoch: 22 | Iteration number: [1810/4518] 40% | Training loss: 0.6871911718700472
Epoch: 22 | Iteration number: [1820/4518] 40% | Training loss: 0.6871927848556539
Epoch: 22 | Iteration number: [1830/4518] 40% | Training loss: 0.6871904381963073
Epoch: 22 | Iteration number: [1840/4518] 40% | Training loss: 0.6871829990135587
Epoch: 22 | Iteration number: [1850/4518] 40% | Training loss: 0.6871825169228218
Epoch: 22 | Iteration number: [1860/4518] 41% | Training loss: 0.6871877334451163
Epoch: 22 | Iteration number: [1870/4518] 41% | Training loss: 0.6871883752830525
Epoch: 22 | Iteration number: [1880/4518] 41% | Training loss: 0.6871859327592749
Epoch: 22 | Iteration number: [1890/4518] 41% | Training loss: 0.6871840786050867
Epoch: 22 | Iteration number: [1900/4518] 42% | Training loss: 0.6871809669231114
Epoch: 22 | Iteration number: [1910/4518] 42% | Training loss: 0.6871836128347207
Epoch: 22 | Iteration number: [1920/4518] 42% | Training loss: 0.6871810505477091
Epoch: 22 | Iteration number: [1930/4518] 42% | Training loss: 0.6871793041883972
Epoch: 22 | Iteration number: [1940/4518] 42% | Training loss: 0.687176401191151
Epoch: 22 | Iteration number: [1950/4518] 43% | Training loss: 0.6871722499223856
Epoch: 22 | Iteration number: [1960/4518] 43% | Training loss: 0.6871731864250437
Epoch: 22 | Iteration number: [1970/4518] 43% | Training loss: 0.6871719437807344
Epoch: 22 | Iteration number: [1980/4518] 43% | Training loss: 0.6871676392025418
Epoch: 22 | Iteration number: [1990/4518] 44% | Training loss: 0.6871713276184983
Epoch: 22 | Iteration number: [2000/4518] 44% | Training loss: 0.6871736722290516
Epoch: 22 | Iteration number: [2010/4518] 44% | Training loss: 0.6871670069386117
Epoch: 22 | Iteration number: [2020/4518] 44% | Training loss: 0.6871658915340311
Epoch: 22 | Iteration number: [2030/4518] 44% | Training loss: 0.687164884629508
Epoch: 22 | Iteration number: [2040/4518] 45% | Training loss: 0.6871618634637664
Epoch: 22 | Iteration number: [2050/4518] 45% | Training loss: 0.6871628908703967
Epoch: 22 | Iteration number: [2060/4518] 45% | Training loss: 0.6871588775255147
Epoch: 22 | Iteration number: [2070/4518] 45% | Training loss: 0.6871643553897379
Epoch: 22 | Iteration number: [2080/4518] 46% | Training loss: 0.6871626551048113
Epoch: 22 | Iteration number: [2090/4518] 46% | Training loss: 0.6871560032573043
Epoch: 22 | Iteration number: [2100/4518] 46% | Training loss: 0.6871537567036492
Epoch: 22 | Iteration number: [2110/4518] 46% | Training loss: 0.6871494606490384
Epoch: 22 | Iteration number: [2120/4518] 46% | Training loss: 0.687146424375615
Epoch: 22 | Iteration number: [2130/4518] 47% | Training loss: 0.6871385700266126
Epoch: 22 | Iteration number: [2140/4518] 47% | Training loss: 0.6871389604060449
Epoch: 22 | Iteration number: [2150/4518] 47% | Training loss: 0.6871404772303825
Epoch: 22 | Iteration number: [2160/4518] 47% | Training loss: 0.6871404801529867
Epoch: 22 | Iteration number: [2170/4518] 48% | Training loss: 0.6871351073963851
Epoch: 22 | Iteration number: [2180/4518] 48% | Training loss: 0.6871343883625958
Epoch: 22 | Iteration number: [2190/4518] 48% | Training loss: 0.6871348868766332
Epoch: 22 | Iteration number: [2200/4518] 48% | Training loss: 0.687135668694973
Epoch: 22 | Iteration number: [2210/4518] 48% | Training loss: 0.6871354348788974
Epoch: 22 | Iteration number: [2220/4518] 49% | Training loss: 0.6871350058295705
Epoch: 22 | Iteration number: [2230/4518] 49% | Training loss: 0.687137182411057
Epoch: 22 | Iteration number: [2240/4518] 49% | Training loss: 0.6871405589261226
Epoch: 22 | Iteration number: [2250/4518] 49% | Training loss: 0.6871366957293616
Epoch: 22 | Iteration number: [2260/4518] 50% | Training loss: 0.6871337497920061
Epoch: 22 | Iteration number: [2270/4518] 50% | Training loss: 0.6871319853261704
Epoch: 22 | Iteration number: [2280/4518] 50% | Training loss: 0.6871342139285908
Epoch: 22 | Iteration number: [2290/4518] 50% | Training loss: 0.6871336646475646
Epoch: 22 | Iteration number: [2300/4518] 50% | Training loss: 0.6871330592684124
Epoch: 22 | Iteration number: [2310/4518] 51% | Training loss: 0.6871325309400435
Epoch: 22 | Iteration number: [2320/4518] 51% | Training loss: 0.6871372064125949
Epoch: 22 | Iteration number: [2330/4518] 51% | Training loss: 0.6871312665069563
Epoch: 22 | Iteration number: [2340/4518] 51% | Training loss: 0.6871269739336437
Epoch: 22 | Iteration number: [2350/4518] 52% | Training loss: 0.6871253072708211
Epoch: 22 | Iteration number: [2360/4518] 52% | Training loss: 0.687120946357816
Epoch: 22 | Iteration number: [2370/4518] 52% | Training loss: 0.6871220966683158
Epoch: 22 | Iteration number: [2380/4518] 52% | Training loss: 0.6871152547227234
Epoch: 22 | Iteration number: [2390/4518] 52% | Training loss: 0.6871176929404047
Epoch: 22 | Iteration number: [2400/4518] 53% | Training loss: 0.6871189842373133
Epoch: 22 | Iteration number: [2410/4518] 53% | Training loss: 0.6871124556203106
Epoch: 22 | Iteration number: [2420/4518] 53% | Training loss: 0.6871142864473595
Epoch: 22 | Iteration number: [2430/4518] 53% | Training loss: 0.6871188022226954
Epoch: 22 | Iteration number: [2440/4518] 54% | Training loss: 0.687121065596088
Epoch: 22 | Iteration number: [2450/4518] 54% | Training loss: 0.6871205760021599
Epoch: 22 | Iteration number: [2460/4518] 54% | Training loss: 0.6871155499685101
Epoch: 22 | Iteration number: [2470/4518] 54% | Training loss: 0.6871109065497935
Epoch: 22 | Iteration number: [2480/4518] 54% | Training loss: 0.6871095246605334
Epoch: 22 | Iteration number: [2490/4518] 55% | Training loss: 0.6871132461421461
Epoch: 22 | Iteration number: [2500/4518] 55% | Training loss: 0.6871113886833191
Epoch: 22 | Iteration number: [2510/4518] 55% | Training loss: 0.6871075291320147
Epoch: 22 | Iteration number: [2520/4518] 55% | Training loss: 0.6871051724941012
Epoch: 22 | Iteration number: [2530/4518] 55% | Training loss: 0.6871072667625111
Epoch: 22 | Iteration number: [2540/4518] 56% | Training loss: 0.6871033397481198
Epoch: 22 | Iteration number: [2550/4518] 56% | Training loss: 0.6871029459027683
Epoch: 22 | Iteration number: [2560/4518] 56% | Training loss: 0.6871029756264762
Epoch: 22 | Iteration number: [2570/4518] 56% | Training loss: 0.6871041091035777
Epoch: 22 | Iteration number: [2580/4518] 57% | Training loss: 0.6871043914510299
Epoch: 22 | Iteration number: [2590/4518] 57% | Training loss: 0.6871060610047639
Epoch: 22 | Iteration number: [2600/4518] 57% | Training loss: 0.6871003640156526
Epoch: 22 | Iteration number: [2610/4518] 57% | Training loss: 0.6870985590406762
Epoch: 22 | Iteration number: [2620/4518] 57% | Training loss: 0.6870993915404983
Epoch: 22 | Iteration number: [2630/4518] 58% | Training loss: 0.6870950615677996
Epoch: 22 | Iteration number: [2640/4518] 58% | Training loss: 0.687097673750285
Epoch: 22 | Iteration number: [2650/4518] 58% | Training loss: 0.6870969365902667
Epoch: 22 | Iteration number: [2660/4518] 58% | Training loss: 0.6870918492177376
Epoch: 22 | Iteration number: [2670/4518] 59% | Training loss: 0.6870923026893916
Epoch: 22 | Iteration number: [2680/4518] 59% | Training loss: 0.6870874158704459
Epoch: 22 | Iteration number: [2690/4518] 59% | Training loss: 0.6870904905866956
Epoch: 22 | Iteration number: [2700/4518] 59% | Training loss: 0.6870918769748122
Epoch: 22 | Iteration number: [2710/4518] 59% | Training loss: 0.6870897257459999
Epoch: 22 | Iteration number: [2720/4518] 60% | Training loss: 0.6870892268769881
Epoch: 22 | Iteration number: [2730/4518] 60% | Training loss: 0.6870901788984026
Epoch: 22 | Iteration number: [2740/4518] 60% | Training loss: 0.6870900248306511
Epoch: 22 | Iteration number: [2750/4518] 60% | Training loss: 0.6870919592814012
Epoch: 22 | Iteration number: [2760/4518] 61% | Training loss: 0.6870901122905206
Epoch: 22 | Iteration number: [2770/4518] 61% | Training loss: 0.6870915438293981
Epoch: 22 | Iteration number: [2780/4518] 61% | Training loss: 0.6870952688318362
Epoch: 22 | Iteration number: [2790/4518] 61% | Training loss: 0.6870935286672312
Epoch: 22 | Iteration number: [2800/4518] 61% | Training loss: 0.6870947155569281
Epoch: 22 | Iteration number: [2810/4518] 62% | Training loss: 0.6870961032516167
Epoch: 22 | Iteration number: [2820/4518] 62% | Training loss: 0.6870978156302837
Epoch: 22 | Iteration number: [2830/4518] 62% | Training loss: 0.6870973344405211
Epoch: 22 | Iteration number: [2840/4518] 62% | Training loss: 0.6870959598833406
Epoch: 22 | Iteration number: [2850/4518] 63% | Training loss: 0.6870979850752312
Epoch: 22 | Iteration number: [2860/4518] 63% | Training loss: 0.6870957665093296
Epoch: 22 | Iteration number: [2870/4518] 63% | Training loss: 0.6870941015278421
Epoch: 22 | Iteration number: [2880/4518] 63% | Training loss: 0.6870936935767531
Epoch: 22 | Iteration number: [2890/4518] 63% | Training loss: 0.6870919807353234
Epoch: 22 | Iteration number: [2900/4518] 64% | Training loss: 0.6870949930158154
Epoch: 22 | Iteration number: [2910/4518] 64% | Training loss: 0.6870939298388884
Epoch: 22 | Iteration number: [2920/4518] 64% | Training loss: 0.6870962394222822
Epoch: 22 | Iteration number: [2930/4518] 64% | Training loss: 0.6870952616169184
Epoch: 22 | Iteration number: [2940/4518] 65% | Training loss: 0.6870939294902646
Epoch: 22 | Iteration number: [2950/4518] 65% | Training loss: 0.6870931620921119
Epoch: 22 | Iteration number: [2960/4518] 65% | Training loss: 0.6870934520822924
Epoch: 22 | Iteration number: [2970/4518] 65% | Training loss: 0.6870927657543208
Epoch: 22 | Iteration number: [2980/4518] 65% | Training loss: 0.6870936406938821
Epoch: 22 | Iteration number: [2990/4518] 66% | Training loss: 0.6870961982470293
Epoch: 22 | Iteration number: [3000/4518] 66% | Training loss: 0.6871011145114899
Epoch: 22 | Iteration number: [3010/4518] 66% | Training loss: 0.6870979074623894
Epoch: 22 | Iteration number: [3020/4518] 66% | Training loss: 0.6870939601730827
Epoch: 22 | Iteration number: [3030/4518] 67% | Training loss: 0.6870972614280462
Epoch: 22 | Iteration number: [3040/4518] 67% | Training loss: 0.687091729731152
Epoch: 22 | Iteration number: [3050/4518] 67% | Training loss: 0.6870940363211709
Epoch: 22 | Iteration number: [3060/4518] 67% | Training loss: 0.6870958767295663
Epoch: 22 | Iteration number: [3070/4518] 67% | Training loss: 0.6870964444033097
Epoch: 22 | Iteration number: [3080/4518] 68% | Training loss: 0.6870980528074425
Epoch: 22 | Iteration number: [3090/4518] 68% | Training loss: 0.6870994893092554
Epoch: 22 | Iteration number: [3100/4518] 68% | Training loss: 0.6870993552669402
Epoch: 22 | Iteration number: [3110/4518] 68% | Training loss: 0.6871016791395819
Epoch: 22 | Iteration number: [3120/4518] 69% | Training loss: 0.6871034124149726
Epoch: 22 | Iteration number: [3130/4518] 69% | Training loss: 0.6870992807153695
Epoch: 22 | Iteration number: [3140/4518] 69% | Training loss: 0.6870920694367901
Epoch: 22 | Iteration number: [3150/4518] 69% | Training loss: 0.6870893326449016
Epoch: 22 | Iteration number: [3160/4518] 69% | Training loss: 0.6870906157395508
Epoch: 22 | Iteration number: [3170/4518] 70% | Training loss: 0.6870933819268404
Epoch: 22 | Iteration number: [3180/4518] 70% | Training loss: 0.6870909414201413
Epoch: 22 | Iteration number: [3190/4518] 70% | Training loss: 0.6870901839299636
Epoch: 22 | Iteration number: [3200/4518] 70% | Training loss: 0.6870923816598952
Epoch: 22 | Iteration number: [3210/4518] 71% | Training loss: 0.6870906095267085
Epoch: 22 | Iteration number: [3220/4518] 71% | Training loss: 0.6870909647911972
Epoch: 22 | Iteration number: [3230/4518] 71% | Training loss: 0.687091336752239
Epoch: 22 | Iteration number: [3240/4518] 71% | Training loss: 0.68709402218645
Epoch: 22 | Iteration number: [3250/4518] 71% | Training loss: 0.6870921830947583
Epoch: 22 | Iteration number: [3260/4518] 72% | Training loss: 0.687090583520433
Epoch: 22 | Iteration number: [3270/4518] 72% | Training loss: 0.6870900636601521
Epoch: 22 | Iteration number: [3280/4518] 72% | Training loss: 0.6870907918890802
Epoch: 22 | Iteration number: [3290/4518] 72% | Training loss: 0.6870903530381733
Epoch: 22 | Iteration number: [3300/4518] 73% | Training loss: 0.6870904983173717
Epoch: 22 | Iteration number: [3310/4518] 73% | Training loss: 0.6870870513858391
Epoch: 22 | Iteration number: [3320/4518] 73% | Training loss: 0.6870885881135262
Epoch: 22 | Iteration number: [3330/4518] 73% | Training loss: 0.6870886055556862
Epoch: 22 | Iteration number: [3340/4518] 73% | Training loss: 0.6870866644525242
Epoch: 22 | Iteration number: [3350/4518] 74% | Training loss: 0.6870874482126378
Epoch: 22 | Iteration number: [3360/4518] 74% | Training loss: 0.6870876367070845
Epoch: 22 | Iteration number: [3370/4518] 74% | Training loss: 0.6870867015876827
Epoch: 22 | Iteration number: [3380/4518] 74% | Training loss: 0.6870892123886819
Epoch: 22 | Iteration number: [3390/4518] 75% | Training loss: 0.6870907147373774
Epoch: 22 | Iteration number: [3400/4518] 75% | Training loss: 0.6870884455652798
Epoch: 22 | Iteration number: [3410/4518] 75% | Training loss: 0.687086139990787
Epoch: 22 | Iteration number: [3420/4518] 75% | Training loss: 0.6870880937890003
Epoch: 22 | Iteration number: [3430/4518] 75% | Training loss: 0.6870883912803828
Epoch: 22 | Iteration number: [3440/4518] 76% | Training loss: 0.6870870347459649
Epoch: 22 | Iteration number: [3450/4518] 76% | Training loss: 0.6870858726466912
Epoch: 22 | Iteration number: [3460/4518] 76% | Training loss: 0.6870860050868437
Epoch: 22 | Iteration number: [3470/4518] 76% | Training loss: 0.6870893562217955
Epoch: 22 | Iteration number: [3480/4518] 77% | Training loss: 0.6870885317695552
Epoch: 22 | Iteration number: [3490/4518] 77% | Training loss: 0.6870838487728961
Epoch: 22 | Iteration number: [3500/4518] 77% | Training loss: 0.6870831744841167
Epoch: 22 | Iteration number: [3510/4518] 77% | Training loss: 0.6870815326855053
Epoch: 22 | Iteration number: [3520/4518] 77% | Training loss: 0.687080263397233
Epoch: 22 | Iteration number: [3530/4518] 78% | Training loss: 0.6870811081641794
Epoch: 22 | Iteration number: [3540/4518] 78% | Training loss: 0.6870781200585392
Epoch: 22 | Iteration number: [3550/4518] 78% | Training loss: 0.6870737960305012
Epoch: 22 | Iteration number: [3560/4518] 78% | Training loss: 0.687076371472873
Epoch: 22 | Iteration number: [3570/4518] 79% | Training loss: 0.6870733951487127
Epoch: 22 | Iteration number: [3580/4518] 79% | Training loss: 0.6870710099875594
Epoch: 22 | Iteration number: [3590/4518] 79% | Training loss: 0.6870704666319664
Epoch: 22 | Iteration number: [3600/4518] 79% | Training loss: 0.6870719585650497
Epoch: 22 | Iteration number: [3610/4518] 79% | Training loss: 0.6870693838167058
Epoch: 22 | Iteration number: [3620/4518] 80% | Training loss: 0.6870683405939386
Epoch: 22 | Iteration number: [3630/4518] 80% | Training loss: 0.6870679092144506
Epoch: 22 | Iteration number: [3640/4518] 80% | Training loss: 0.6870674574604401
Epoch: 22 | Iteration number: [3650/4518] 80% | Training loss: 0.6870625701995745
Epoch: 22 | Iteration number: [3660/4518] 81% | Training loss: 0.6870631101515775
Epoch: 22 | Iteration number: [3670/4518] 81% | Training loss: 0.6870618614091535
Epoch: 22 | Iteration number: [3680/4518] 81% | Training loss: 0.6870599846639063
Epoch: 22 | Iteration number: [3690/4518] 81% | Training loss: 0.6870646718071728
Epoch: 22 | Iteration number: [3700/4518] 81% | Training loss: 0.6870646280211371
Epoch: 22 | Iteration number: [3710/4518] 82% | Training loss: 0.6870653248700813
Epoch: 22 | Iteration number: [3720/4518] 82% | Training loss: 0.6870622648667264
Epoch: 22 | Iteration number: [3730/4518] 82% | Training loss: 0.6870618181477922
Epoch: 22 | Iteration number: [3740/4518] 82% | Training loss: 0.6870630718807486
Epoch: 22 | Iteration number: [3750/4518] 83% | Training loss: 0.687065206638972
Epoch: 22 | Iteration number: [3760/4518] 83% | Training loss: 0.6870678002371433
Epoch: 22 | Iteration number: [3770/4518] 83% | Training loss: 0.6870675680966213
Epoch: 22 | Iteration number: [3780/4518] 83% | Training loss: 0.6870666562407105
Epoch: 22 | Iteration number: [3790/4518] 83% | Training loss: 0.6870699539190861
Epoch: 22 | Iteration number: [3800/4518] 84% | Training loss: 0.6870731992627445
Epoch: 22 | Iteration number: [3810/4518] 84% | Training loss: 0.6870744101018731
Epoch: 22 | Iteration number: [3820/4518] 84% | Training loss: 0.6870755465398908
Epoch: 22 | Iteration number: [3830/4518] 84% | Training loss: 0.6870723814628142
Epoch: 22 | Iteration number: [3840/4518] 84% | Training loss: 0.6870751909135531
Epoch: 22 | Iteration number: [3850/4518] 85% | Training loss: 0.6870764299956235
Epoch: 22 | Iteration number: [3860/4518] 85% | Training loss: 0.687074591875694
Epoch: 22 | Iteration number: [3870/4518] 85% | Training loss: 0.687072793473261
Epoch: 22 | Iteration number: [3880/4518] 85% | Training loss: 0.6870726185975615
Epoch: 22 | Iteration number: [3890/4518] 86% | Training loss: 0.687071077146383
Epoch: 22 | Iteration number: [3900/4518] 86% | Training loss: 0.6870706342122493
Epoch: 22 | Iteration number: [3910/4518] 86% | Training loss: 0.687068757529149
Epoch: 22 | Iteration number: [3920/4518] 86% | Training loss: 0.6870681714342565
Epoch: 22 | Iteration number: [3930/4518] 86% | Training loss: 0.6870669887266087
Epoch: 22 | Iteration number: [3940/4518] 87% | Training loss: 0.6870651851753293
Epoch: 22 | Iteration number: [3950/4518] 87% | Training loss: 0.6870645621154882
Epoch: 22 | Iteration number: [3960/4518] 87% | Training loss: 0.6870634113748868
Epoch: 22 | Iteration number: [3970/4518] 87% | Training loss: 0.6870666846970768
Epoch: 22 | Iteration number: [3980/4518] 88% | Training loss: 0.6870674860387591
Epoch: 22 | Iteration number: [3990/4518] 88% | Training loss: 0.6870636209210657
Epoch: 22 | Iteration number: [4000/4518] 88% | Training loss: 0.6870632137209177
Epoch: 22 | Iteration number: [4010/4518] 88% | Training loss: 0.6870621106422453
Epoch: 22 | Iteration number: [4020/4518] 88% | Training loss: 0.6870592454476143
Epoch: 22 | Iteration number: [4030/4518] 89% | Training loss: 0.687059644197412
Epoch: 22 | Iteration number: [4040/4518] 89% | Training loss: 0.6870548753012525
Epoch: 22 | Iteration number: [4050/4518] 89% | Training loss: 0.6870554628048414
Epoch: 22 | Iteration number: [4060/4518] 89% | Training loss: 0.6870564288693696
Epoch: 22 | Iteration number: [4070/4518] 90% | Training loss: 0.6870586630606828
Epoch: 22 | Iteration number: [4080/4518] 90% | Training loss: 0.6870587673987828
Epoch: 22 | Iteration number: [4090/4518] 90% | Training loss: 0.6870550191344142
Epoch: 22 | Iteration number: [4100/4518] 90% | Training loss: 0.6870556630012465
Epoch: 22 | Iteration number: [4110/4518] 90% | Training loss: 0.6870549975085433
Epoch: 22 | Iteration number: [4120/4518] 91% | Training loss: 0.6870527004153983
Epoch: 22 | Iteration number: [4130/4518] 91% | Training loss: 0.6870563263321615
Epoch: 22 | Iteration number: [4140/4518] 91% | Training loss: 0.6870571486040014
Epoch: 22 | Iteration number: [4150/4518] 91% | Training loss: 0.6870555896356881
Epoch: 22 | Iteration number: [4160/4518] 92% | Training loss: 0.6870564225201423
Epoch: 22 | Iteration number: [4170/4518] 92% | Training loss: 0.6870553612423171
Epoch: 22 | Iteration number: [4180/4518] 92% | Training loss: 0.6870532918061937
Epoch: 22 | Iteration number: [4190/4518] 92% | Training loss: 0.6870530044548836
Epoch: 22 | Iteration number: [4200/4518] 92% | Training loss: 0.6870521539023944
Epoch: 22 | Iteration number: [4210/4518] 93% | Training loss: 0.6870496552517182
Epoch: 22 | Iteration number: [4220/4518] 93% | Training loss: 0.6870489099296914
Epoch: 22 | Iteration number: [4230/4518] 93% | Training loss: 0.6870495913017445
Epoch: 22 | Iteration number: [4240/4518] 93% | Training loss: 0.6870496359355045
Epoch: 22 | Iteration number: [4250/4518] 94% | Training loss: 0.6870479416145998
Epoch: 22 | Iteration number: [4260/4518] 94% | Training loss: 0.6870458587094652
Epoch: 22 | Iteration number: [4270/4518] 94% | Training loss: 0.687041610660821
Epoch: 22 | Iteration number: [4280/4518] 94% | Training loss: 0.6870424226065662
Epoch: 22 | Iteration number: [4290/4518] 94% | Training loss: 0.6870412475579268
Epoch: 22 | Iteration number: [4300/4518] 95% | Training loss: 0.6870411044220591
Epoch: 22 | Iteration number: [4310/4518] 95% | Training loss: 0.6870400429325147
Epoch: 22 | Iteration number: [4320/4518] 95% | Training loss: 0.6870384428236219
Epoch: 22 | Iteration number: [4330/4518] 95% | Training loss: 0.6870371089934202
Epoch: 22 | Iteration number: [4340/4518] 96% | Training loss: 0.6870366762585355
Epoch: 22 | Iteration number: [4350/4518] 96% | Training loss: 0.68703787254191
Epoch: 22 | Iteration number: [4360/4518] 96% | Training loss: 0.6870354254311378
Epoch: 22 | Iteration number: [4370/4518] 96% | Training loss: 0.687034803751677
Epoch: 22 | Iteration number: [4380/4518] 96% | Training loss: 0.6870327351436223
Epoch: 22 | Iteration number: [4390/4518] 97% | Training loss: 0.6870346190038737
Epoch: 22 | Iteration number: [4400/4518] 97% | Training loss: 0.6870335699888793
Epoch: 22 | Iteration number: [4410/4518] 97% | Training loss: 0.6870312921854914
Epoch: 22 | Iteration number: [4420/4518] 97% | Training loss: 0.6870309922355332
Epoch: 22 | Iteration number: [4430/4518] 98% | Training loss: 0.6870309640403257
Epoch: 22 | Iteration number: [4440/4518] 98% | Training loss: 0.6870338787635167
Epoch: 22 | Iteration number: [4450/4518] 98% | Training loss: 0.6870326486866126
Epoch: 22 | Iteration number: [4460/4518] 98% | Training loss: 0.6870312812082436
Epoch: 22 | Iteration number: [4470/4518] 98% | Training loss: 0.6870305600582354
Epoch: 22 | Iteration number: [4480/4518] 99% | Training loss: 0.6870324984059802
Epoch: 22 | Iteration number: [4490/4518] 99% | Training loss: 0.6870301287397245
Epoch: 22 | Iteration number: [4500/4518] 99% | Training loss: 0.6870276868873172
Epoch: 22 | Iteration number: [4510/4518] 99% | Training loss: 0.6870274656363443

 End of epoch: 22 | Train Loss: 0.6868762667330032 | Training Time: 632 

 End of epoch: 22 | Eval Loss: 0.6900382492007041 | Evaluating Time: 17 
Epoch: 23 | Iteration number: [10/4518] 0% | Training loss: 0.7545482575893402
Epoch: 23 | Iteration number: [20/4518] 0% | Training loss: 0.7201378285884857
Epoch: 23 | Iteration number: [30/4518] 0% | Training loss: 0.709373144308726
Epoch: 23 | Iteration number: [40/4518] 0% | Training loss: 0.7036996617913246
Epoch: 23 | Iteration number: [50/4518] 1% | Training loss: 0.7004492092132568
Epoch: 23 | Iteration number: [60/4518] 1% | Training loss: 0.6983139077822368
Epoch: 23 | Iteration number: [70/4518] 1% | Training loss: 0.6967147852693285
Epoch: 23 | Iteration number: [80/4518] 1% | Training loss: 0.6954549513757229
Epoch: 23 | Iteration number: [90/4518] 1% | Training loss: 0.6944110174973805
Epoch: 23 | Iteration number: [100/4518] 2% | Training loss: 0.6936746799945831
Epoch: 23 | Iteration number: [110/4518] 2% | Training loss: 0.6930214415897022
Epoch: 23 | Iteration number: [120/4518] 2% | Training loss: 0.6925940290093422
Epoch: 23 | Iteration number: [130/4518] 2% | Training loss: 0.6922266244888305
Epoch: 23 | Iteration number: [140/4518] 3% | Training loss: 0.6918307644980294
Epoch: 23 | Iteration number: [150/4518] 3% | Training loss: 0.6915209114551544
Epoch: 23 | Iteration number: [160/4518] 3% | Training loss: 0.6912178296595812
Epoch: 23 | Iteration number: [170/4518] 3% | Training loss: 0.6910010944394505
Epoch: 23 | Iteration number: [180/4518] 3% | Training loss: 0.6907336658901638
Epoch: 23 | Iteration number: [190/4518] 4% | Training loss: 0.690560749957436
Epoch: 23 | Iteration number: [200/4518] 4% | Training loss: 0.6903809013962746
Epoch: 23 | Iteration number: [210/4518] 4% | Training loss: 0.6902142978849866
Epoch: 23 | Iteration number: [220/4518] 4% | Training loss: 0.6900171092965386
Epoch: 23 | Iteration number: [230/4518] 5% | Training loss: 0.6899676180404165
Epoch: 23 | Iteration number: [240/4518] 5% | Training loss: 0.6898379166920979
Epoch: 23 | Iteration number: [250/4518] 5% | Training loss: 0.6897438554763794
Epoch: 23 | Iteration number: [260/4518] 5% | Training loss: 0.6895762626941387
Epoch: 23 | Iteration number: [270/4518] 5% | Training loss: 0.6894119216336144
Epoch: 23 | Iteration number: [280/4518] 6% | Training loss: 0.6892955056258611
Epoch: 23 | Iteration number: [290/4518] 6% | Training loss: 0.6892163527422938
Epoch: 23 | Iteration number: [300/4518] 6% | Training loss: 0.6891474493344625
Epoch: 23 | Iteration number: [310/4518] 6% | Training loss: 0.6890700290280004
Epoch: 23 | Iteration number: [320/4518] 7% | Training loss: 0.689006625302136
Epoch: 23 | Iteration number: [330/4518] 7% | Training loss: 0.6889306706009489
Epoch: 23 | Iteration number: [340/4518] 7% | Training loss: 0.688913195624071
Epoch: 23 | Iteration number: [350/4518] 7% | Training loss: 0.688858677489417
Epoch: 23 | Iteration number: [360/4518] 7% | Training loss: 0.6887934216194682
Epoch: 23 | Iteration number: [370/4518] 8% | Training loss: 0.6887372463136106
Epoch: 23 | Iteration number: [380/4518] 8% | Training loss: 0.6886685351007863
Epoch: 23 | Iteration number: [390/4518] 8% | Training loss: 0.6886220490321134
Epoch: 23 | Iteration number: [400/4518] 8% | Training loss: 0.6885814030468463
Epoch: 23 | Iteration number: [410/4518] 9% | Training loss: 0.688507052165706
Epoch: 23 | Iteration number: [420/4518] 9% | Training loss: 0.688439777351561
Epoch: 23 | Iteration number: [430/4518] 9% | Training loss: 0.6884254495764888
Epoch: 23 | Iteration number: [440/4518] 9% | Training loss: 0.6883496929298748
Epoch: 23 | Iteration number: [450/4518] 9% | Training loss: 0.6883018170462715
Epoch: 23 | Iteration number: [460/4518] 10% | Training loss: 0.688266017385151
Epoch: 23 | Iteration number: [470/4518] 10% | Training loss: 0.688253575309794
Epoch: 23 | Iteration number: [480/4518] 10% | Training loss: 0.6882293917238712
Epoch: 23 | Iteration number: [490/4518] 10% | Training loss: 0.6882098560430565
Epoch: 23 | Iteration number: [500/4518] 11% | Training loss: 0.68817112159729
Epoch: 23 | Iteration number: [510/4518] 11% | Training loss: 0.68815504359264
Epoch: 23 | Iteration number: [520/4518] 11% | Training loss: 0.6881382348445746
Epoch: 23 | Iteration number: [530/4518] 11% | Training loss: 0.6881152001191985
Epoch: 23 | Iteration number: [540/4518] 11% | Training loss: 0.6881015480668456
Epoch: 23 | Iteration number: [550/4518] 12% | Training loss: 0.6880849851261486
Epoch: 23 | Iteration number: [560/4518] 12% | Training loss: 0.688054148959262
Epoch: 23 | Iteration number: [570/4518] 12% | Training loss: 0.6880536507096207
Epoch: 23 | Iteration number: [580/4518] 12% | Training loss: 0.6880292178227984
Epoch: 23 | Iteration number: [590/4518] 13% | Training loss: 0.6880076030553397
Epoch: 23 | Iteration number: [600/4518] 13% | Training loss: 0.6879882294933001
Epoch: 23 | Iteration number: [610/4518] 13% | Training loss: 0.6879638518466324
Epoch: 23 | Iteration number: [620/4518] 13% | Training loss: 0.6879387718054556
Epoch: 23 | Iteration number: [630/4518] 13% | Training loss: 0.6879310808484517
Epoch: 23 | Iteration number: [640/4518] 14% | Training loss: 0.6879218941554427
Epoch: 23 | Iteration number: [650/4518] 14% | Training loss: 0.6879026183715233
Epoch: 23 | Iteration number: [660/4518] 14% | Training loss: 0.6878832438678453
Epoch: 23 | Iteration number: [670/4518] 14% | Training loss: 0.6878730209016088
Epoch: 23 | Iteration number: [680/4518] 15% | Training loss: 0.6878871244542739
Epoch: 23 | Iteration number: [690/4518] 15% | Training loss: 0.6878595426462699
Epoch: 23 | Iteration number: [700/4518] 15% | Training loss: 0.6878432875871658
Epoch: 23 | Iteration number: [710/4518] 15% | Training loss: 0.6878213130252462
Epoch: 23 | Iteration number: [720/4518] 15% | Training loss: 0.6877967048850324
Epoch: 23 | Iteration number: [730/4518] 16% | Training loss: 0.687795382166562
Epoch: 23 | Iteration number: [740/4518] 16% | Training loss: 0.6877758039010538
Epoch: 23 | Iteration number: [750/4518] 16% | Training loss: 0.6877560412883759
Epoch: 23 | Iteration number: [760/4518] 16% | Training loss: 0.6877485449376859
Epoch: 23 | Iteration number: [770/4518] 17% | Training loss: 0.6877367147377559
Epoch: 23 | Iteration number: [780/4518] 17% | Training loss: 0.6877229917507905
Epoch: 23 | Iteration number: [790/4518] 17% | Training loss: 0.6877205752119233
Epoch: 23 | Iteration number: [800/4518] 17% | Training loss: 0.6877213196456432
Epoch: 23 | Iteration number: [810/4518] 17% | Training loss: 0.6877125420688112
Epoch: 23 | Iteration number: [820/4518] 18% | Training loss: 0.6876899085393766
Epoch: 23 | Iteration number: [830/4518] 18% | Training loss: 0.6876889670469675
Epoch: 23 | Iteration number: [840/4518] 18% | Training loss: 0.6877024059494337
Epoch: 23 | Iteration number: [850/4518] 18% | Training loss: 0.6877013479260837
Epoch: 23 | Iteration number: [860/4518] 19% | Training loss: 0.6876888539208922
Epoch: 23 | Iteration number: [870/4518] 19% | Training loss: 0.687684930055991
Epoch: 23 | Iteration number: [880/4518] 19% | Training loss: 0.687669962644577
Epoch: 23 | Iteration number: [890/4518] 19% | Training loss: 0.6876609344160959
Epoch: 23 | Iteration number: [900/4518] 19% | Training loss: 0.6876491485039393
Epoch: 23 | Iteration number: [910/4518] 20% | Training loss: 0.6876417391247802
Epoch: 23 | Iteration number: [920/4518] 20% | Training loss: 0.6876393848139307
Epoch: 23 | Iteration number: [930/4518] 20% | Training loss: 0.6876321982952857
Epoch: 23 | Iteration number: [940/4518] 20% | Training loss: 0.6876179642499761
Epoch: 23 | Iteration number: [950/4518] 21% | Training loss: 0.6875993452574077
Epoch: 23 | Iteration number: [960/4518] 21% | Training loss: 0.6876015601679683
Epoch: 23 | Iteration number: [970/4518] 21% | Training loss: 0.6875813570219217
Epoch: 23 | Iteration number: [980/4518] 21% | Training loss: 0.6875720757610944
Epoch: 23 | Iteration number: [990/4518] 21% | Training loss: 0.6875726508371758
Epoch: 23 | Iteration number: [1000/4518] 22% | Training loss: 0.6875734816789627
Epoch: 23 | Iteration number: [1010/4518] 22% | Training loss: 0.6875631459278635
Epoch: 23 | Iteration number: [1020/4518] 22% | Training loss: 0.6875481722985997
Epoch: 23 | Iteration number: [1030/4518] 22% | Training loss: 0.6875512248104059
Epoch: 23 | Iteration number: [1040/4518] 23% | Training loss: 0.6875484009774832
Epoch: 23 | Iteration number: [1050/4518] 23% | Training loss: 0.6875363063244593
Epoch: 23 | Iteration number: [1060/4518] 23% | Training loss: 0.6875302202296707
Epoch: 23 | Iteration number: [1070/4518] 23% | Training loss: 0.6875290828887547
Epoch: 23 | Iteration number: [1080/4518] 23% | Training loss: 0.6875200164538843
Epoch: 23 | Iteration number: [1090/4518] 24% | Training loss: 0.6875240234060025
Epoch: 23 | Iteration number: [1100/4518] 24% | Training loss: 0.6875203947587447
Epoch: 23 | Iteration number: [1110/4518] 24% | Training loss: 0.6875093639433921
Epoch: 23 | Iteration number: [1120/4518] 24% | Training loss: 0.6875041566789151
Epoch: 23 | Iteration number: [1130/4518] 25% | Training loss: 0.6874996344600104
Epoch: 23 | Iteration number: [1140/4518] 25% | Training loss: 0.6874937482570347
Epoch: 23 | Iteration number: [1150/4518] 25% | Training loss: 0.6874906722877336
Epoch: 23 | Iteration number: [1160/4518] 25% | Training loss: 0.6874789855089681
Epoch: 23 | Iteration number: [1170/4518] 25% | Training loss: 0.6874686936027984
Epoch: 23 | Iteration number: [1180/4518] 26% | Training loss: 0.6874661656254429
Epoch: 23 | Iteration number: [1190/4518] 26% | Training loss: 0.6874531599653869
Epoch: 23 | Iteration number: [1200/4518] 26% | Training loss: 0.6874500790735086
Epoch: 23 | Iteration number: [1210/4518] 26% | Training loss: 0.6874528702625559
Epoch: 23 | Iteration number: [1220/4518] 27% | Training loss: 0.6874479996864913
Epoch: 23 | Iteration number: [1230/4518] 27% | Training loss: 0.6874424558829486
Epoch: 23 | Iteration number: [1240/4518] 27% | Training loss: 0.6874356477010635
Epoch: 23 | Iteration number: [1250/4518] 27% | Training loss: 0.6874299643039703
Epoch: 23 | Iteration number: [1260/4518] 27% | Training loss: 0.6874312515296633
Epoch: 23 | Iteration number: [1270/4518] 28% | Training loss: 0.687428245535047
Epoch: 23 | Iteration number: [1280/4518] 28% | Training loss: 0.6874216385651379
Epoch: 23 | Iteration number: [1290/4518] 28% | Training loss: 0.687425234474877
Epoch: 23 | Iteration number: [1300/4518] 28% | Training loss: 0.6874100250005722
Epoch: 23 | Iteration number: [1310/4518] 28% | Training loss: 0.6874053040988573
Epoch: 23 | Iteration number: [1320/4518] 29% | Training loss: 0.687394572252577
Epoch: 23 | Iteration number: [1330/4518] 29% | Training loss: 0.6873809154768635
Epoch: 23 | Iteration number: [1340/4518] 29% | Training loss: 0.6873743534977756
Epoch: 23 | Iteration number: [1350/4518] 29% | Training loss: 0.6873769258569788
Epoch: 23 | Iteration number: [1360/4518] 30% | Training loss: 0.6873826152699836
Epoch: 23 | Iteration number: [1370/4518] 30% | Training loss: 0.6873872783062231
Epoch: 23 | Iteration number: [1380/4518] 30% | Training loss: 0.6873891912508702
Epoch: 23 | Iteration number: [1390/4518] 30% | Training loss: 0.6873901882617593
Epoch: 23 | Iteration number: [1400/4518] 30% | Training loss: 0.6873919630476407
Epoch: 23 | Iteration number: [1410/4518] 31% | Training loss: 0.6873922505699996
Epoch: 23 | Iteration number: [1420/4518] 31% | Training loss: 0.6873915938004641
Epoch: 23 | Iteration number: [1430/4518] 31% | Training loss: 0.6873912988009153
Epoch: 23 | Iteration number: [1440/4518] 31% | Training loss: 0.6873962454497814
Epoch: 23 | Iteration number: [1450/4518] 32% | Training loss: 0.6873991088209481
Epoch: 23 | Iteration number: [1460/4518] 32% | Training loss: 0.6873876443464462
Epoch: 23 | Iteration number: [1470/4518] 32% | Training loss: 0.6873821985964872
Epoch: 23 | Iteration number: [1480/4518] 32% | Training loss: 0.6873805932096533
Epoch: 23 | Iteration number: [1490/4518] 32% | Training loss: 0.6873785109727975
Epoch: 23 | Iteration number: [1500/4518] 33% | Training loss: 0.6873761497338613
Epoch: 23 | Iteration number: [1510/4518] 33% | Training loss: 0.6873758525248395
Epoch: 23 | Iteration number: [1520/4518] 33% | Training loss: 0.68737399923174
Epoch: 23 | Iteration number: [1530/4518] 33% | Training loss: 0.687377904599009
Epoch: 23 | Iteration number: [1540/4518] 34% | Training loss: 0.68736808063922
Epoch: 23 | Iteration number: [1550/4518] 34% | Training loss: 0.6873585995166532
Epoch: 23 | Iteration number: [1560/4518] 34% | Training loss: 0.6873542725657805
Epoch: 23 | Iteration number: [1570/4518] 34% | Training loss: 0.6873465525496537
Epoch: 23 | Iteration number: [1580/4518] 34% | Training loss: 0.6873457743774487
Epoch: 23 | Iteration number: [1590/4518] 35% | Training loss: 0.6873418391125757
Epoch: 23 | Iteration number: [1600/4518] 35% | Training loss: 0.687344412356615
Epoch: 23 | Iteration number: [1610/4518] 35% | Training loss: 0.6873403032744153
Epoch: 23 | Iteration number: [1620/4518] 35% | Training loss: 0.6873375062957222
Epoch: 23 | Iteration number: [1630/4518] 36% | Training loss: 0.687333516511449
Epoch: 23 | Iteration number: [1640/4518] 36% | Training loss: 0.6873359850267085
Epoch: 23 | Iteration number: [1650/4518] 36% | Training loss: 0.6873218239798691
Epoch: 23 | Iteration number: [1660/4518] 36% | Training loss: 0.6873237205198012
Epoch: 23 | Iteration number: [1670/4518] 36% | Training loss: 0.687321740103339
Epoch: 23 | Iteration number: [1680/4518] 37% | Training loss: 0.6873250877573377
Epoch: 23 | Iteration number: [1690/4518] 37% | Training loss: 0.6873246526929754
Epoch: 23 | Iteration number: [1700/4518] 37% | Training loss: 0.6873098316613365
Epoch: 23 | Iteration number: [1710/4518] 37% | Training loss: 0.6873149066640619
Epoch: 23 | Iteration number: [1720/4518] 38% | Training loss: 0.6873084802267163
Epoch: 23 | Iteration number: [1730/4518] 38% | Training loss: 0.6873054920248902
Epoch: 23 | Iteration number: [1740/4518] 38% | Training loss: 0.6873078856317476
Epoch: 23 | Iteration number: [1750/4518] 38% | Training loss: 0.6873013051918575
Epoch: 23 | Iteration number: [1760/4518] 38% | Training loss: 0.6872987736693837
Epoch: 23 | Iteration number: [1770/4518] 39% | Training loss: 0.6872972310599634
Epoch: 23 | Iteration number: [1780/4518] 39% | Training loss: 0.6872984814844775
Epoch: 23 | Iteration number: [1790/4518] 39% | Training loss: 0.687298585249725
Epoch: 23 | Iteration number: [1800/4518] 39% | Training loss: 0.6872962597674793
Epoch: 23 | Iteration number: [1810/4518] 40% | Training loss: 0.6872879653016507
Epoch: 23 | Iteration number: [1820/4518] 40% | Training loss: 0.6872832409300647
Epoch: 23 | Iteration number: [1830/4518] 40% | Training loss: 0.6872829239550835
Epoch: 23 | Iteration number: [1840/4518] 40% | Training loss: 0.6872830156722795
Epoch: 23 | Iteration number: [1850/4518] 40% | Training loss: 0.6872855300838883
Epoch: 23 | Iteration number: [1860/4518] 41% | Training loss: 0.6872738252724371
Epoch: 23 | Iteration number: [1870/4518] 41% | Training loss: 0.68727029727742
Epoch: 23 | Iteration number: [1880/4518] 41% | Training loss: 0.6872731782971544
Epoch: 23 | Iteration number: [1890/4518] 41% | Training loss: 0.6872733356460693
Epoch: 23 | Iteration number: [1900/4518] 42% | Training loss: 0.6872672850520988
Epoch: 23 | Iteration number: [1910/4518] 42% | Training loss: 0.6872744159860761
Epoch: 23 | Iteration number: [1920/4518] 42% | Training loss: 0.687268037845691
Epoch: 23 | Iteration number: [1930/4518] 42% | Training loss: 0.6872646544572603
Epoch: 23 | Iteration number: [1940/4518] 42% | Training loss: 0.6872635213984657
Epoch: 23 | Iteration number: [1950/4518] 43% | Training loss: 0.6872699279968555
Epoch: 23 | Iteration number: [1960/4518] 43% | Training loss: 0.6872721537339445
Epoch: 23 | Iteration number: [1970/4518] 43% | Training loss: 0.6872650110176978
Epoch: 23 | Iteration number: [1980/4518] 43% | Training loss: 0.6872599942816628
Epoch: 23 | Iteration number: [1990/4518] 44% | Training loss: 0.6872506181199347
Epoch: 23 | Iteration number: [2000/4518] 44% | Training loss: 0.6872497265934944
Epoch: 23 | Iteration number: [2010/4518] 44% | Training loss: 0.6872441869766558
Epoch: 23 | Iteration number: [2020/4518] 44% | Training loss: 0.6872354048018409
Epoch: 23 | Iteration number: [2030/4518] 44% | Training loss: 0.6872275868072886
Epoch: 23 | Iteration number: [2040/4518] 45% | Training loss: 0.6872292307954209
Epoch: 23 | Iteration number: [2050/4518] 45% | Training loss: 0.6872195469170082
Epoch: 23 | Iteration number: [2060/4518] 45% | Training loss: 0.6872170513984069
Epoch: 23 | Iteration number: [2070/4518] 45% | Training loss: 0.6872114044168721
Epoch: 23 | Iteration number: [2080/4518] 46% | Training loss: 0.6872104452206538
Epoch: 23 | Iteration number: [2090/4518] 46% | Training loss: 0.687209101099717
Epoch: 23 | Iteration number: [2100/4518] 46% | Training loss: 0.6872075716370628
Epoch: 23 | Iteration number: [2110/4518] 46% | Training loss: 0.6871977876147952
Epoch: 23 | Iteration number: [2120/4518] 46% | Training loss: 0.6871995930964092
Epoch: 23 | Iteration number: [2130/4518] 47% | Training loss: 0.6871998694301211
Epoch: 23 | Iteration number: [2140/4518] 47% | Training loss: 0.6871961262181541
Epoch: 23 | Iteration number: [2150/4518] 47% | Training loss: 0.6871963719988978
Epoch: 23 | Iteration number: [2160/4518] 47% | Training loss: 0.6872015103697777
Epoch: 23 | Iteration number: [2170/4518] 48% | Training loss: 0.6871959089134146
Epoch: 23 | Iteration number: [2180/4518] 48% | Training loss: 0.6871915974474828
Epoch: 23 | Iteration number: [2190/4518] 48% | Training loss: 0.6871898789111882
Epoch: 23 | Iteration number: [2200/4518] 48% | Training loss: 0.6871878263625232
Epoch: 23 | Iteration number: [2210/4518] 48% | Training loss: 0.6871862805267265
Epoch: 23 | Iteration number: [2220/4518] 49% | Training loss: 0.6871849560791308
Epoch: 23 | Iteration number: [2230/4518] 49% | Training loss: 0.6871810747101702
Epoch: 23 | Iteration number: [2240/4518] 49% | Training loss: 0.6871788520099861
Epoch: 23 | Iteration number: [2250/4518] 49% | Training loss: 0.687172457297643
Epoch: 23 | Iteration number: [2260/4518] 50% | Training loss: 0.687170408652947
Epoch: 23 | Iteration number: [2270/4518] 50% | Training loss: 0.687170550003976
Epoch: 23 | Iteration number: [2280/4518] 50% | Training loss: 0.6871669590211751
Epoch: 23 | Iteration number: [2290/4518] 50% | Training loss: 0.6871629166811314
Epoch: 23 | Iteration number: [2300/4518] 50% | Training loss: 0.6871611042644666
Epoch: 23 | Iteration number: [2310/4518] 51% | Training loss: 0.6871613770852357
Epoch: 23 | Iteration number: [2320/4518] 51% | Training loss: 0.687160020963899
Epoch: 23 | Iteration number: [2330/4518] 51% | Training loss: 0.6871517419047621
Epoch: 23 | Iteration number: [2340/4518] 51% | Training loss: 0.6871515399115717
Epoch: 23 | Iteration number: [2350/4518] 52% | Training loss: 0.6871506724966333
Epoch: 23 | Iteration number: [2360/4518] 52% | Training loss: 0.6871465831742448
Epoch: 23 | Iteration number: [2370/4518] 52% | Training loss: 0.6871495453617241
Epoch: 23 | Iteration number: [2380/4518] 52% | Training loss: 0.6871482085029618
Epoch: 23 | Iteration number: [2390/4518] 52% | Training loss: 0.687149986038647
Epoch: 23 | Iteration number: [2400/4518] 53% | Training loss: 0.6871488597740729
Epoch: 23 | Iteration number: [2410/4518] 53% | Training loss: 0.6871417672554981
Epoch: 23 | Iteration number: [2420/4518] 53% | Training loss: 0.6871474266052247
Epoch: 23 | Iteration number: [2430/4518] 53% | Training loss: 0.6871473676873823
Epoch: 23 | Iteration number: [2440/4518] 54% | Training loss: 0.6871465379830266
Epoch: 23 | Iteration number: [2450/4518] 54% | Training loss: 0.6871456101719214
Epoch: 23 | Iteration number: [2460/4518] 54% | Training loss: 0.6871456754886038
Epoch: 23 | Iteration number: [2470/4518] 54% | Training loss: 0.6871439113790689
Epoch: 23 | Iteration number: [2480/4518] 54% | Training loss: 0.6871441117457805
Epoch: 23 | Iteration number: [2490/4518] 55% | Training loss: 0.6871442072123409
Epoch: 23 | Iteration number: [2500/4518] 55% | Training loss: 0.6871477596998214
Epoch: 23 | Iteration number: [2510/4518] 55% | Training loss: 0.6871444301538734
Epoch: 23 | Iteration number: [2520/4518] 55% | Training loss: 0.687147179624391
Epoch: 23 | Iteration number: [2530/4518] 55% | Training loss: 0.68714341580161
Epoch: 23 | Iteration number: [2540/4518] 56% | Training loss: 0.6871390511435786
Epoch: 23 | Iteration number: [2550/4518] 56% | Training loss: 0.6871396787493836
Epoch: 23 | Iteration number: [2560/4518] 56% | Training loss: 0.6871410254621878
Epoch: 23 | Iteration number: [2570/4518] 56% | Training loss: 0.6871375068152461
Epoch: 23 | Iteration number: [2580/4518] 57% | Training loss: 0.6871336451103521
Epoch: 23 | Iteration number: [2590/4518] 57% | Training loss: 0.6871328874674543
Epoch: 23 | Iteration number: [2600/4518] 57% | Training loss: 0.687133443240936
Epoch: 23 | Iteration number: [2610/4518] 57% | Training loss: 0.6871359753197637
Epoch: 23 | Iteration number: [2620/4518] 57% | Training loss: 0.687135652412895
Epoch: 23 | Iteration number: [2630/4518] 58% | Training loss: 0.6871386317699127
Epoch: 23 | Iteration number: [2640/4518] 58% | Training loss: 0.6871370062909343
Epoch: 23 | Iteration number: [2650/4518] 58% | Training loss: 0.6871357864703772
Epoch: 23 | Iteration number: [2660/4518] 58% | Training loss: 0.68713488802874
Epoch: 23 | Iteration number: [2670/4518] 59% | Training loss: 0.6871341828549846
Epoch: 23 | Iteration number: [2680/4518] 59% | Training loss: 0.6871334951092948
Epoch: 23 | Iteration number: [2690/4518] 59% | Training loss: 0.6871308026925339
Epoch: 23 | Iteration number: [2700/4518] 59% | Training loss: 0.6871306420697106
Epoch: 23 | Iteration number: [2710/4518] 59% | Training loss: 0.6871306576851989
Epoch: 23 | Iteration number: [2720/4518] 60% | Training loss: 0.687128376478658
Epoch: 23 | Iteration number: [2730/4518] 60% | Training loss: 0.6871304994756049
Epoch: 23 | Iteration number: [2740/4518] 60% | Training loss: 0.6871295391208064
Epoch: 23 | Iteration number: [2750/4518] 60% | Training loss: 0.6871272310126911
Epoch: 23 | Iteration number: [2760/4518] 61% | Training loss: 0.6871252814496773
Epoch: 23 | Iteration number: [2770/4518] 61% | Training loss: 0.6871295820719929
Epoch: 23 | Iteration number: [2780/4518] 61% | Training loss: 0.687129475530103
Epoch: 23 | Iteration number: [2790/4518] 61% | Training loss: 0.687129449865724
Epoch: 23 | Iteration number: [2800/4518] 61% | Training loss: 0.6871283595689706
Epoch: 23 | Iteration number: [2810/4518] 62% | Training loss: 0.6871275375958439
Epoch: 23 | Iteration number: [2820/4518] 62% | Training loss: 0.687129031872073
Epoch: 23 | Iteration number: [2830/4518] 62% | Training loss: 0.6871252625022255
Epoch: 23 | Iteration number: [2840/4518] 62% | Training loss: 0.6871270616919222
Epoch: 23 | Iteration number: [2850/4518] 63% | Training loss: 0.6871269919579489
Epoch: 23 | Iteration number: [2860/4518] 63% | Training loss: 0.6871223427198984
Epoch: 23 | Iteration number: [2870/4518] 63% | Training loss: 0.6871245553892249
Epoch: 23 | Iteration number: [2880/4518] 63% | Training loss: 0.6871292349778944
Epoch: 23 | Iteration number: [2890/4518] 63% | Training loss: 0.6871265488512376
Epoch: 23 | Iteration number: [2900/4518] 64% | Training loss: 0.6871228297208918
Epoch: 23 | Iteration number: [2910/4518] 64% | Training loss: 0.6871266780645168
Epoch: 23 | Iteration number: [2920/4518] 64% | Training loss: 0.6871237108560457
Epoch: 23 | Iteration number: [2930/4518] 64% | Training loss: 0.6871228676200319
Epoch: 23 | Iteration number: [2940/4518] 65% | Training loss: 0.68712102103801
Epoch: 23 | Iteration number: [2950/4518] 65% | Training loss: 0.6871188011815993
Epoch: 23 | Iteration number: [2960/4518] 65% | Training loss: 0.6871243311948068
Epoch: 23 | Iteration number: [2970/4518] 65% | Training loss: 0.6871216846234871
Epoch: 23 | Iteration number: [2980/4518] 65% | Training loss: 0.6871194943885676
Epoch: 23 | Iteration number: [2990/4518] 66% | Training loss: 0.6871170437056883
Epoch: 23 | Iteration number: [3000/4518] 66% | Training loss: 0.6871175332069397
Epoch: 23 | Iteration number: [3010/4518] 66% | Training loss: 0.6871155601205223
Epoch: 23 | Iteration number: [3020/4518] 66% | Training loss: 0.6871152034855836
Epoch: 23 | Iteration number: [3030/4518] 67% | Training loss: 0.6871166016992563
Epoch: 23 | Iteration number: [3040/4518] 67% | Training loss: 0.6871157796563286
Epoch: 23 | Iteration number: [3050/4518] 67% | Training loss: 0.6871166129190414
Epoch: 23 | Iteration number: [3060/4518] 67% | Training loss: 0.6871150032757154
Epoch: 23 | Iteration number: [3070/4518] 67% | Training loss: 0.6871184873464441
Epoch: 23 | Iteration number: [3080/4518] 68% | Training loss: 0.687115524380238
Epoch: 23 | Iteration number: [3090/4518] 68% | Training loss: 0.6871176793737319
Epoch: 23 | Iteration number: [3100/4518] 68% | Training loss: 0.6871155147783218
Epoch: 23 | Iteration number: [3110/4518] 68% | Training loss: 0.6871154026969836
Epoch: 23 | Iteration number: [3120/4518] 69% | Training loss: 0.6871165811060331
Epoch: 23 | Iteration number: [3130/4518] 69% | Training loss: 0.6871144049274274
Epoch: 23 | Iteration number: [3140/4518] 69% | Training loss: 0.6871159008733786
Epoch: 23 | Iteration number: [3150/4518] 69% | Training loss: 0.6871133980486128
Epoch: 23 | Iteration number: [3160/4518] 69% | Training loss: 0.6871114441488363
Epoch: 23 | Iteration number: [3170/4518] 70% | Training loss: 0.687108807007221
Epoch: 23 | Iteration number: [3180/4518] 70% | Training loss: 0.6871096679062213
Epoch: 23 | Iteration number: [3190/4518] 70% | Training loss: 0.6871098147477476
Epoch: 23 | Iteration number: [3200/4518] 70% | Training loss: 0.6871079944446683
Epoch: 23 | Iteration number: [3210/4518] 71% | Training loss: 0.6871040450635357
Epoch: 23 | Iteration number: [3220/4518] 71% | Training loss: 0.6871059815150611
Epoch: 23 | Iteration number: [3230/4518] 71% | Training loss: 0.6871058867258184
Epoch: 23 | Iteration number: [3240/4518] 71% | Training loss: 0.6871008003199542
Epoch: 23 | Iteration number: [3250/4518] 71% | Training loss: 0.6870983721476335
Epoch: 23 | Iteration number: [3260/4518] 72% | Training loss: 0.6870965680278883
Epoch: 23 | Iteration number: [3270/4518] 72% | Training loss: 0.6870978211408726
Epoch: 23 | Iteration number: [3280/4518] 72% | Training loss: 0.6871002453492909
Epoch: 23 | Iteration number: [3290/4518] 72% | Training loss: 0.687102539869065
Epoch: 23 | Iteration number: [3300/4518] 73% | Training loss: 0.6870976530060624
Epoch: 23 | Iteration number: [3310/4518] 73% | Training loss: 0.6870960720356137
Epoch: 23 | Iteration number: [3320/4518] 73% | Training loss: 0.6870955067944814
Epoch: 23 | Iteration number: [3330/4518] 73% | Training loss: 0.6870972006707579
Epoch: 23 | Iteration number: [3340/4518] 73% | Training loss: 0.687098184013795
Epoch: 23 | Iteration number: [3350/4518] 74% | Training loss: 0.6870947001229472
Epoch: 23 | Iteration number: [3360/4518] 74% | Training loss: 0.6870952250169856
Epoch: 23 | Iteration number: [3370/4518] 74% | Training loss: 0.6870905325922131
Epoch: 23 | Iteration number: [3380/4518] 74% | Training loss: 0.6870900849795201
Epoch: 23 | Iteration number: [3390/4518] 75% | Training loss: 0.687090223359499
Epoch: 23 | Iteration number: [3400/4518] 75% | Training loss: 0.6870883698498501
Epoch: 23 | Iteration number: [3410/4518] 75% | Training loss: 0.6870871218768033
Epoch: 23 | Iteration number: [3420/4518] 75% | Training loss: 0.6870877889513273
Epoch: 23 | Iteration number: [3430/4518] 75% | Training loss: 0.6870892000267874
Epoch: 23 | Iteration number: [3440/4518] 76% | Training loss: 0.6870857136713904
Epoch: 23 | Iteration number: [3450/4518] 76% | Training loss: 0.6870831981085349
Epoch: 23 | Iteration number: [3460/4518] 76% | Training loss: 0.6870809154703438
Epoch: 23 | Iteration number: [3470/4518] 76% | Training loss: 0.6870809244662953
Epoch: 23 | Iteration number: [3480/4518] 77% | Training loss: 0.6870848841023172
Epoch: 23 | Iteration number: [3490/4518] 77% | Training loss: 0.6870862674064144
Epoch: 23 | Iteration number: [3500/4518] 77% | Training loss: 0.687085608295032
Epoch: 23 | Iteration number: [3510/4518] 77% | Training loss: 0.6870850216629159
Epoch: 23 | Iteration number: [3520/4518] 77% | Training loss: 0.6870817001231692
Epoch: 23 | Iteration number: [3530/4518] 78% | Training loss: 0.6870823016078884
Epoch: 23 | Iteration number: [3540/4518] 78% | Training loss: 0.687077512680474
Epoch: 23 | Iteration number: [3550/4518] 78% | Training loss: 0.6870727302994527
Epoch: 23 | Iteration number: [3560/4518] 78% | Training loss: 0.6870699777529481
Epoch: 23 | Iteration number: [3570/4518] 79% | Training loss: 0.6870676295763972
Epoch: 23 | Iteration number: [3580/4518] 79% | Training loss: 0.6870685112709439
Epoch: 23 | Iteration number: [3590/4518] 79% | Training loss: 0.6870655945416613
Epoch: 23 | Iteration number: [3600/4518] 79% | Training loss: 0.6870654545724392
Epoch: 23 | Iteration number: [3610/4518] 79% | Training loss: 0.6870678488732705
Epoch: 23 | Iteration number: [3620/4518] 80% | Training loss: 0.6870674589720879
Epoch: 23 | Iteration number: [3630/4518] 80% | Training loss: 0.6870643297995418
Epoch: 23 | Iteration number: [3640/4518] 80% | Training loss: 0.6870642021625907
Epoch: 23 | Iteration number: [3650/4518] 80% | Training loss: 0.6870625439245407
Epoch: 23 | Iteration number: [3660/4518] 81% | Training loss: 0.6870611370912667
Epoch: 23 | Iteration number: [3670/4518] 81% | Training loss: 0.6870619071439437
Epoch: 23 | Iteration number: [3680/4518] 81% | Training loss: 0.6870627360499424
Epoch: 23 | Iteration number: [3690/4518] 81% | Training loss: 0.687063253087403
Epoch: 23 | Iteration number: [3700/4518] 81% | Training loss: 0.6870624397252058
Epoch: 23 | Iteration number: [3710/4518] 82% | Training loss: 0.6870619022621298
Epoch: 23 | Iteration number: [3720/4518] 82% | Training loss: 0.6870596568430624
Epoch: 23 | Iteration number: [3730/4518] 82% | Training loss: 0.6870606824795619
Epoch: 23 | Iteration number: [3740/4518] 82% | Training loss: 0.687061774858179
Epoch: 23 | Iteration number: [3750/4518] 83% | Training loss: 0.6870604979515076
Epoch: 23 | Iteration number: [3760/4518] 83% | Training loss: 0.6870579276630219
Epoch: 23 | Iteration number: [3770/4518] 83% | Training loss: 0.6870577861206602
Epoch: 23 | Iteration number: [3780/4518] 83% | Training loss: 0.687059391128323
Epoch: 23 | Iteration number: [3790/4518] 83% | Training loss: 0.6870574864988905
Epoch: 23 | Iteration number: [3800/4518] 84% | Training loss: 0.6870543311771593
Epoch: 23 | Iteration number: [3810/4518] 84% | Training loss: 0.6870520774304397
Epoch: 23 | Iteration number: [3820/4518] 84% | Training loss: 0.6870505404722004
Epoch: 23 | Iteration number: [3830/4518] 84% | Training loss: 0.6870487701488226
Epoch: 23 | Iteration number: [3840/4518] 84% | Training loss: 0.6870476704401275
Epoch: 23 | Iteration number: [3850/4518] 85% | Training loss: 0.687045057315331
Epoch: 23 | Iteration number: [3860/4518] 85% | Training loss: 0.6870436589798161
Epoch: 23 | Iteration number: [3870/4518] 85% | Training loss: 0.6870440221572107
Epoch: 23 | Iteration number: [3880/4518] 85% | Training loss: 0.6870431677275097
Epoch: 23 | Iteration number: [3890/4518] 86% | Training loss: 0.6870442128579843
Epoch: 23 | Iteration number: [3900/4518] 86% | Training loss: 0.6870439639152625
Epoch: 23 | Iteration number: [3910/4518] 86% | Training loss: 0.6870443759671867
Epoch: 23 | Iteration number: [3920/4518] 86% | Training loss: 0.6870459114562492
Epoch: 23 | Iteration number: [3930/4518] 86% | Training loss: 0.6870464649212573
Epoch: 23 | Iteration number: [3940/4518] 87% | Training loss: 0.6870462980367206
Epoch: 23 | Iteration number: [3950/4518] 87% | Training loss: 0.687048532268669
Epoch: 23 | Iteration number: [3960/4518] 87% | Training loss: 0.6870501982894811
Epoch: 23 | Iteration number: [3970/4518] 87% | Training loss: 0.6870505126057104
Epoch: 23 | Iteration number: [3980/4518] 88% | Training loss: 0.6870509771545927
Epoch: 23 | Iteration number: [3990/4518] 88% | Training loss: 0.6870526635109033
Epoch: 23 | Iteration number: [4000/4518] 88% | Training loss: 0.6870548646748066
Epoch: 23 | Iteration number: [4010/4518] 88% | Training loss: 0.6870552513962077
Epoch: 23 | Iteration number: [4020/4518] 88% | Training loss: 0.6870571436277076
Epoch: 23 | Iteration number: [4030/4518] 89% | Training loss: 0.6870604565214579
Epoch: 23 | Iteration number: [4040/4518] 89% | Training loss: 0.687058914106081
Epoch: 23 | Iteration number: [4050/4518] 89% | Training loss: 0.6870587416489919
Epoch: 23 | Iteration number: [4060/4518] 89% | Training loss: 0.6870598757208275
Epoch: 23 | Iteration number: [4070/4518] 90% | Training loss: 0.6870592806497429
Epoch: 23 | Iteration number: [4080/4518] 90% | Training loss: 0.6870561727121764
Epoch: 23 | Iteration number: [4090/4518] 90% | Training loss: 0.6870564293453337
Epoch: 23 | Iteration number: [4100/4518] 90% | Training loss: 0.6870559918735085
Epoch: 23 | Iteration number: [4110/4518] 90% | Training loss: 0.6870571619837823
Epoch: 23 | Iteration number: [4120/4518] 91% | Training loss: 0.6870543731069102
Epoch: 23 | Iteration number: [4130/4518] 91% | Training loss: 0.6870530818189894
Epoch: 23 | Iteration number: [4140/4518] 91% | Training loss: 0.6870528929619397
Epoch: 23 | Iteration number: [4150/4518] 91% | Training loss: 0.6870541004244104
Epoch: 23 | Iteration number: [4160/4518] 92% | Training loss: 0.6870522731771835
Epoch: 23 | Iteration number: [4170/4518] 92% | Training loss: 0.6870485221739295
Epoch: 23 | Iteration number: [4180/4518] 92% | Training loss: 0.6870462498026031
Epoch: 23 | Iteration number: [4190/4518] 92% | Training loss: 0.6870448351902154
Epoch: 23 | Iteration number: [4200/4518] 92% | Training loss: 0.6870443365971247
Epoch: 23 | Iteration number: [4210/4518] 93% | Training loss: 0.6870448324147992
Epoch: 23 | Iteration number: [4220/4518] 93% | Training loss: 0.6870443268974811
Epoch: 23 | Iteration number: [4230/4518] 93% | Training loss: 0.6870425096076713
Epoch: 23 | Iteration number: [4240/4518] 93% | Training loss: 0.6870427781540268
Epoch: 23 | Iteration number: [4250/4518] 94% | Training loss: 0.6870435996055603
Epoch: 23 | Iteration number: [4260/4518] 94% | Training loss: 0.6870431765004503
Epoch: 23 | Iteration number: [4270/4518] 94% | Training loss: 0.6870436270426811
Epoch: 23 | Iteration number: [4280/4518] 94% | Training loss: 0.6870430853043761
Epoch: 23 | Iteration number: [4290/4518] 94% | Training loss: 0.6870439715318747
Epoch: 23 | Iteration number: [4300/4518] 95% | Training loss: 0.6870452693451282
Epoch: 23 | Iteration number: [4310/4518] 95% | Training loss: 0.687042401298846
Epoch: 23 | Iteration number: [4320/4518] 95% | Training loss: 0.6870419037562829
Epoch: 23 | Iteration number: [4330/4518] 95% | Training loss: 0.6870427110729261
Epoch: 23 | Iteration number: [4340/4518] 96% | Training loss: 0.6870425409435676
Epoch: 23 | Iteration number: [4350/4518] 96% | Training loss: 0.6870405490645047
Epoch: 23 | Iteration number: [4360/4518] 96% | Training loss: 0.6870400918186258
Epoch: 23 | Iteration number: [4370/4518] 96% | Training loss: 0.687039479892914
Epoch: 23 | Iteration number: [4380/4518] 96% | Training loss: 0.6870385399828218
Epoch: 23 | Iteration number: [4390/4518] 97% | Training loss: 0.687039915263517
Epoch: 23 | Iteration number: [4400/4518] 97% | Training loss: 0.6870389764281837
Epoch: 23 | Iteration number: [4410/4518] 97% | Training loss: 0.6870407415220257
Epoch: 23 | Iteration number: [4420/4518] 97% | Training loss: 0.6870418914572686
Epoch: 23 | Iteration number: [4430/4518] 98% | Training loss: 0.6870431981560339
Epoch: 23 | Iteration number: [4440/4518] 98% | Training loss: 0.6870391648363423
Epoch: 23 | Iteration number: [4450/4518] 98% | Training loss: 0.6870394030447756
Epoch: 23 | Iteration number: [4460/4518] 98% | Training loss: 0.6870373506984369
Epoch: 23 | Iteration number: [4470/4518] 98% | Training loss: 0.6870348154031723
Epoch: 23 | Iteration number: [4480/4518] 99% | Training loss: 0.6870328671964151
Epoch: 23 | Iteration number: [4490/4518] 99% | Training loss: 0.6870318194540147
Epoch: 23 | Iteration number: [4500/4518] 99% | Training loss: 0.6870306448671553
Epoch: 23 | Iteration number: [4510/4518] 99% | Training loss: 0.68703031098499

 End of epoch: 23 | Train Loss: 0.6868776898301772 | Training Time: 633 

 End of epoch: 23 | Eval Loss: 0.6899509490752707 | Evaluating Time: 17 
Epoch: 24 | Iteration number: [10/4518] 0% | Training loss: 0.7552342593669892
Epoch: 24 | Iteration number: [20/4518] 0% | Training loss: 0.7207923114299775
Epoch: 24 | Iteration number: [30/4518] 0% | Training loss: 0.7095148285230001
Epoch: 24 | Iteration number: [40/4518] 0% | Training loss: 0.7039670661091805
Epoch: 24 | Iteration number: [50/4518] 1% | Training loss: 0.7005609059333802
Epoch: 24 | Iteration number: [60/4518] 1% | Training loss: 0.698271827896436
Epoch: 24 | Iteration number: [70/4518] 1% | Training loss: 0.6966909570353371
Epoch: 24 | Iteration number: [80/4518] 1% | Training loss: 0.6955571807920933
Epoch: 24 | Iteration number: [90/4518] 1% | Training loss: 0.6945096731185914
Epoch: 24 | Iteration number: [100/4518] 2% | Training loss: 0.693809124827385
Epoch: 24 | Iteration number: [110/4518] 2% | Training loss: 0.6932488013397563
Epoch: 24 | Iteration number: [120/4518] 2% | Training loss: 0.6927609195311865
Epoch: 24 | Iteration number: [130/4518] 2% | Training loss: 0.6922926966960613
Epoch: 24 | Iteration number: [140/4518] 3% | Training loss: 0.6919851481914521
Epoch: 24 | Iteration number: [150/4518] 3% | Training loss: 0.6915874393781026
Epoch: 24 | Iteration number: [160/4518] 3% | Training loss: 0.6912624444812536
Epoch: 24 | Iteration number: [170/4518] 3% | Training loss: 0.6909931452835307
Epoch: 24 | Iteration number: [180/4518] 3% | Training loss: 0.6908309479554494
Epoch: 24 | Iteration number: [190/4518] 4% | Training loss: 0.690646756636469
Epoch: 24 | Iteration number: [200/4518] 4% | Training loss: 0.6905193814635276
Epoch: 24 | Iteration number: [210/4518] 4% | Training loss: 0.690288903315862
Epoch: 24 | Iteration number: [220/4518] 4% | Training loss: 0.6901528290726922
Epoch: 24 | Iteration number: [230/4518] 5% | Training loss: 0.6900137442609539
Epoch: 24 | Iteration number: [240/4518] 5% | Training loss: 0.6898249377806981
Epoch: 24 | Iteration number: [250/4518] 5% | Training loss: 0.6897230062484742
Epoch: 24 | Iteration number: [260/4518] 5% | Training loss: 0.6896297475466362
Epoch: 24 | Iteration number: [270/4518] 5% | Training loss: 0.6894969293364772
Epoch: 24 | Iteration number: [280/4518] 6% | Training loss: 0.6894494808145932
Epoch: 24 | Iteration number: [290/4518] 6% | Training loss: 0.6893592108940256
Epoch: 24 | Iteration number: [300/4518] 6% | Training loss: 0.6892532022794088
Epoch: 24 | Iteration number: [310/4518] 6% | Training loss: 0.6891743684968641
Epoch: 24 | Iteration number: [320/4518] 7% | Training loss: 0.6891402969136834
Epoch: 24 | Iteration number: [330/4518] 7% | Training loss: 0.6890770444364259
Epoch: 24 | Iteration number: [340/4518] 7% | Training loss: 0.6890272093169829
Epoch: 24 | Iteration number: [350/4518] 7% | Training loss: 0.688952728509903
Epoch: 24 | Iteration number: [360/4518] 7% | Training loss: 0.6888944346043798
Epoch: 24 | Iteration number: [370/4518] 8% | Training loss: 0.6888563713511905
Epoch: 24 | Iteration number: [380/4518] 8% | Training loss: 0.6887980029771202
Epoch: 24 | Iteration number: [390/4518] 8% | Training loss: 0.6887698042087066
Epoch: 24 | Iteration number: [400/4518] 8% | Training loss: 0.6886804082989693
Epoch: 24 | Iteration number: [410/4518] 9% | Training loss: 0.6886132183598309
Epoch: 24 | Iteration number: [420/4518] 9% | Training loss: 0.6885270763011205
Epoch: 24 | Iteration number: [430/4518] 9% | Training loss: 0.6884891223075777
Epoch: 24 | Iteration number: [440/4518] 9% | Training loss: 0.6884620807387613
Epoch: 24 | Iteration number: [450/4518] 9% | Training loss: 0.688469788895713
Epoch: 24 | Iteration number: [460/4518] 10% | Training loss: 0.6884285286716793
Epoch: 24 | Iteration number: [470/4518] 10% | Training loss: 0.6884120187860854
Epoch: 24 | Iteration number: [480/4518] 10% | Training loss: 0.688385599354903
Epoch: 24 | Iteration number: [490/4518] 10% | Training loss: 0.6883777105078406
Epoch: 24 | Iteration number: [500/4518] 11% | Training loss: 0.688345519065857
Epoch: 24 | Iteration number: [510/4518] 11% | Training loss: 0.6883138996713302
Epoch: 24 | Iteration number: [520/4518] 11% | Training loss: 0.6883136902864163
Epoch: 24 | Iteration number: [530/4518] 11% | Training loss: 0.6882581661332329
Epoch: 24 | Iteration number: [540/4518] 11% | Training loss: 0.6882370783223046
Epoch: 24 | Iteration number: [550/4518] 12% | Training loss: 0.6882193543694236
Epoch: 24 | Iteration number: [560/4518] 12% | Training loss: 0.6881907641887665
Epoch: 24 | Iteration number: [570/4518] 12% | Training loss: 0.6881683521103441
Epoch: 24 | Iteration number: [580/4518] 12% | Training loss: 0.6881383889708026
Epoch: 24 | Iteration number: [590/4518] 13% | Training loss: 0.6881101122346975
Epoch: 24 | Iteration number: [600/4518] 13% | Training loss: 0.688086766898632
Epoch: 24 | Iteration number: [610/4518] 13% | Training loss: 0.6880502845420212
Epoch: 24 | Iteration number: [620/4518] 13% | Training loss: 0.6880204546836115
Epoch: 24 | Iteration number: [630/4518] 13% | Training loss: 0.6880064523409284
Epoch: 24 | Iteration number: [640/4518] 14% | Training loss: 0.6879936457611621
Epoch: 24 | Iteration number: [650/4518] 14% | Training loss: 0.6879602087461031
Epoch: 24 | Iteration number: [660/4518] 14% | Training loss: 0.6879354724378297
Epoch: 24 | Iteration number: [670/4518] 14% | Training loss: 0.6879095425356679
Epoch: 24 | Iteration number: [680/4518] 15% | Training loss: 0.6878922656178474
Epoch: 24 | Iteration number: [690/4518] 15% | Training loss: 0.6878611908442732
Epoch: 24 | Iteration number: [700/4518] 15% | Training loss: 0.6878460832153048
Epoch: 24 | Iteration number: [710/4518] 15% | Training loss: 0.6878241287990355
Epoch: 24 | Iteration number: [720/4518] 15% | Training loss: 0.6878127083182335
Epoch: 24 | Iteration number: [730/4518] 16% | Training loss: 0.6877987806927668
Epoch: 24 | Iteration number: [740/4518] 16% | Training loss: 0.6877777257481137
Epoch: 24 | Iteration number: [750/4518] 16% | Training loss: 0.6877669603824615
Epoch: 24 | Iteration number: [760/4518] 16% | Training loss: 0.6877643875385585
Epoch: 24 | Iteration number: [770/4518] 17% | Training loss: 0.6877351854528699
Epoch: 24 | Iteration number: [780/4518] 17% | Training loss: 0.687723087805968
Epoch: 24 | Iteration number: [790/4518] 17% | Training loss: 0.6877073434334767
Epoch: 24 | Iteration number: [800/4518] 17% | Training loss: 0.6876959628611803
Epoch: 24 | Iteration number: [810/4518] 17% | Training loss: 0.687701744797789
Epoch: 24 | Iteration number: [820/4518] 18% | Training loss: 0.6876927447755162
Epoch: 24 | Iteration number: [830/4518] 18% | Training loss: 0.6876898583159389
Epoch: 24 | Iteration number: [840/4518] 18% | Training loss: 0.6876720295775505
Epoch: 24 | Iteration number: [850/4518] 18% | Training loss: 0.6876575030298794
Epoch: 24 | Iteration number: [860/4518] 19% | Training loss: 0.6876293169897656
Epoch: 24 | Iteration number: [870/4518] 19% | Training loss: 0.6876233151589317
Epoch: 24 | Iteration number: [880/4518] 19% | Training loss: 0.6876113048331304
Epoch: 24 | Iteration number: [890/4518] 19% | Training loss: 0.6875924708468191
Epoch: 24 | Iteration number: [900/4518] 19% | Training loss: 0.6875909495353699
Epoch: 24 | Iteration number: [910/4518] 20% | Training loss: 0.6875968278109372
Epoch: 24 | Iteration number: [920/4518] 20% | Training loss: 0.6875848489611045
Epoch: 24 | Iteration number: [930/4518] 20% | Training loss: 0.6875826667072953
Epoch: 24 | Iteration number: [940/4518] 20% | Training loss: 0.6875729738397801
Epoch: 24 | Iteration number: [950/4518] 21% | Training loss: 0.6875654052433214
Epoch: 24 | Iteration number: [960/4518] 21% | Training loss: 0.6875629621247451
Epoch: 24 | Iteration number: [970/4518] 21% | Training loss: 0.6875562610085477
Epoch: 24 | Iteration number: [980/4518] 21% | Training loss: 0.6875613002752771
Epoch: 24 | Iteration number: [990/4518] 21% | Training loss: 0.6875589396616425
Epoch: 24 | Iteration number: [1000/4518] 22% | Training loss: 0.6875365378856659
Epoch: 24 | Iteration number: [1010/4518] 22% | Training loss: 0.6875259762353236
Epoch: 24 | Iteration number: [1020/4518] 22% | Training loss: 0.687524520240578
Epoch: 24 | Iteration number: [1030/4518] 22% | Training loss: 0.6875184409826705
Epoch: 24 | Iteration number: [1040/4518] 23% | Training loss: 0.6874996981368615
Epoch: 24 | Iteration number: [1050/4518] 23% | Training loss: 0.6874942846525283
Epoch: 24 | Iteration number: [1060/4518] 23% | Training loss: 0.6874923708866227
Epoch: 24 | Iteration number: [1070/4518] 23% | Training loss: 0.6874861238158751
Epoch: 24 | Iteration number: [1080/4518] 23% | Training loss: 0.6874823528859351
Epoch: 24 | Iteration number: [1090/4518] 24% | Training loss: 0.6874711806074195
Epoch: 24 | Iteration number: [1100/4518] 24% | Training loss: 0.6874585541269996
Epoch: 24 | Iteration number: [1110/4518] 24% | Training loss: 0.6874590506961754
Epoch: 24 | Iteration number: [1120/4518] 24% | Training loss: 0.6874609037701572
Epoch: 24 | Iteration number: [1130/4518] 25% | Training loss: 0.6874556500299842
Epoch: 24 | Iteration number: [1140/4518] 25% | Training loss: 0.6874538817949463
Epoch: 24 | Iteration number: [1150/4518] 25% | Training loss: 0.6874478480090266
Epoch: 24 | Iteration number: [1160/4518] 25% | Training loss: 0.6874368865942133
Epoch: 24 | Iteration number: [1170/4518] 25% | Training loss: 0.6874159178672693
Epoch: 24 | Iteration number: [1180/4518] 26% | Training loss: 0.6874001540369906
Epoch: 24 | Iteration number: [1190/4518] 26% | Training loss: 0.6874005758962711
Epoch: 24 | Iteration number: [1200/4518] 26% | Training loss: 0.6874015748004119
Epoch: 24 | Iteration number: [1210/4518] 26% | Training loss: 0.6873959599447644
Epoch: 24 | Iteration number: [1220/4518] 27% | Training loss: 0.6873902600319659
Epoch: 24 | Iteration number: [1230/4518] 27% | Training loss: 0.6873933875948433
Epoch: 24 | Iteration number: [1240/4518] 27% | Training loss: 0.6873971199797045
Epoch: 24 | Iteration number: [1250/4518] 27% | Training loss: 0.6873953774929047
Epoch: 24 | Iteration number: [1260/4518] 27% | Training loss: 0.6873937482871707
Epoch: 24 | Iteration number: [1270/4518] 28% | Training loss: 0.6873946264034181
Epoch: 24 | Iteration number: [1280/4518] 28% | Training loss: 0.6873943044338375
Epoch: 24 | Iteration number: [1290/4518] 28% | Training loss: 0.6873934858067091
Epoch: 24 | Iteration number: [1300/4518] 28% | Training loss: 0.6873905601409765
Epoch: 24 | Iteration number: [1310/4518] 28% | Training loss: 0.6873897300876733
Epoch: 24 | Iteration number: [1320/4518] 29% | Training loss: 0.6873789697433963
Epoch: 24 | Iteration number: [1330/4518] 29% | Training loss: 0.687361749043142
Epoch: 24 | Iteration number: [1340/4518] 29% | Training loss: 0.6873697111855692
Epoch: 24 | Iteration number: [1350/4518] 29% | Training loss: 0.6873755697850827
Epoch: 24 | Iteration number: [1360/4518] 30% | Training loss: 0.6873802348971367
Epoch: 24 | Iteration number: [1370/4518] 30% | Training loss: 0.6873760707186957
Epoch: 24 | Iteration number: [1380/4518] 30% | Training loss: 0.6873722430588542
Epoch: 24 | Iteration number: [1390/4518] 30% | Training loss: 0.6873631016813594
Epoch: 24 | Iteration number: [1400/4518] 30% | Training loss: 0.6873565020731517
Epoch: 24 | Iteration number: [1410/4518] 31% | Training loss: 0.6873555768466165
Epoch: 24 | Iteration number: [1420/4518] 31% | Training loss: 0.6873481431477506
Epoch: 24 | Iteration number: [1430/4518] 31% | Training loss: 0.68734892415
Epoch: 24 | Iteration number: [1440/4518] 31% | Training loss: 0.687342892587185
Epoch: 24 | Iteration number: [1450/4518] 32% | Training loss: 0.687343166491081
Epoch: 24 | Iteration number: [1460/4518] 32% | Training loss: 0.6873386180155898
Epoch: 24 | Iteration number: [1470/4518] 32% | Training loss: 0.6873441666567407
Epoch: 24 | Iteration number: [1480/4518] 32% | Training loss: 0.6873363049449147
Epoch: 24 | Iteration number: [1490/4518] 32% | Training loss: 0.6873264601566648
Epoch: 24 | Iteration number: [1500/4518] 33% | Training loss: 0.6873306869268417
Epoch: 24 | Iteration number: [1510/4518] 33% | Training loss: 0.6873297509768151
Epoch: 24 | Iteration number: [1520/4518] 33% | Training loss: 0.6873303376530346
Epoch: 24 | Iteration number: [1530/4518] 33% | Training loss: 0.6873217251565721
Epoch: 24 | Iteration number: [1540/4518] 34% | Training loss: 0.6873174946416508
Epoch: 24 | Iteration number: [1550/4518] 34% | Training loss: 0.6873137251407869
Epoch: 24 | Iteration number: [1560/4518] 34% | Training loss: 0.6873173936055257
Epoch: 24 | Iteration number: [1570/4518] 34% | Training loss: 0.6873136169971175
Epoch: 24 | Iteration number: [1580/4518] 34% | Training loss: 0.6873087441619439
Epoch: 24 | Iteration number: [1590/4518] 35% | Training loss: 0.6873111150549642
Epoch: 24 | Iteration number: [1600/4518] 35% | Training loss: 0.6873130946978927
Epoch: 24 | Iteration number: [1610/4518] 35% | Training loss: 0.6873142374228246
Epoch: 24 | Iteration number: [1620/4518] 35% | Training loss: 0.6873132358362646
Epoch: 24 | Iteration number: [1630/4518] 36% | Training loss: 0.6873121850329674
Epoch: 24 | Iteration number: [1640/4518] 36% | Training loss: 0.6873126673989179
Epoch: 24 | Iteration number: [1650/4518] 36% | Training loss: 0.6873110055562222
Epoch: 24 | Iteration number: [1660/4518] 36% | Training loss: 0.6873020260807979
Epoch: 24 | Iteration number: [1670/4518] 36% | Training loss: 0.6872957490518421
Epoch: 24 | Iteration number: [1680/4518] 37% | Training loss: 0.6872980465846402
Epoch: 24 | Iteration number: [1690/4518] 37% | Training loss: 0.6872990010758123
Epoch: 24 | Iteration number: [1700/4518] 37% | Training loss: 0.6872848716202904
Epoch: 24 | Iteration number: [1710/4518] 37% | Training loss: 0.6872877575152102
Epoch: 24 | Iteration number: [1720/4518] 38% | Training loss: 0.687281126373036
Epoch: 24 | Iteration number: [1730/4518] 38% | Training loss: 0.6872771388878023
Epoch: 24 | Iteration number: [1740/4518] 38% | Training loss: 0.6872799535934953
Epoch: 24 | Iteration number: [1750/4518] 38% | Training loss: 0.6872788387366704
Epoch: 24 | Iteration number: [1760/4518] 38% | Training loss: 0.6872744673016397
Epoch: 24 | Iteration number: [1770/4518] 39% | Training loss: 0.687275288098276
Epoch: 24 | Iteration number: [1780/4518] 39% | Training loss: 0.6872742086314083
Epoch: 24 | Iteration number: [1790/4518] 39% | Training loss: 0.6872682877093054
Epoch: 24 | Iteration number: [1800/4518] 39% | Training loss: 0.6872614076071315
Epoch: 24 | Iteration number: [1810/4518] 40% | Training loss: 0.6872594703626896
Epoch: 24 | Iteration number: [1820/4518] 40% | Training loss: 0.6872486229781266
Epoch: 24 | Iteration number: [1830/4518] 40% | Training loss: 0.6872495147374158
Epoch: 24 | Iteration number: [1840/4518] 40% | Training loss: 0.6872464716758417
Epoch: 24 | Iteration number: [1850/4518] 40% | Training loss: 0.6872408732208046
Epoch: 24 | Iteration number: [1860/4518] 41% | Training loss: 0.6872468625986448
Epoch: 24 | Iteration number: [1870/4518] 41% | Training loss: 0.6872426533444043
Epoch: 24 | Iteration number: [1880/4518] 41% | Training loss: 0.687242296845355
Epoch: 24 | Iteration number: [1890/4518] 41% | Training loss: 0.6872357540975803
Epoch: 24 | Iteration number: [1900/4518] 42% | Training loss: 0.6872367295465971
Epoch: 24 | Iteration number: [1910/4518] 42% | Training loss: 0.6872324011712798
Epoch: 24 | Iteration number: [1920/4518] 42% | Training loss: 0.6872353945858777
Epoch: 24 | Iteration number: [1930/4518] 42% | Training loss: 0.6872403964168667
Epoch: 24 | Iteration number: [1940/4518] 42% | Training loss: 0.6872442628919464
Epoch: 24 | Iteration number: [1950/4518] 43% | Training loss: 0.6872452923884759
Epoch: 24 | Iteration number: [1960/4518] 43% | Training loss: 0.6872446812537252
Epoch: 24 | Iteration number: [1970/4518] 43% | Training loss: 0.6872489944932424
Epoch: 24 | Iteration number: [1980/4518] 43% | Training loss: 0.6872430053323206
Epoch: 24 | Iteration number: [1990/4518] 44% | Training loss: 0.6872430402130337
Epoch: 24 | Iteration number: [2000/4518] 44% | Training loss: 0.6872361809015274
Epoch: 24 | Iteration number: [2010/4518] 44% | Training loss: 0.6872244381489445
Epoch: 24 | Iteration number: [2020/4518] 44% | Training loss: 0.6872311318569845
Epoch: 24 | Iteration number: [2030/4518] 44% | Training loss: 0.6872303905745445
Epoch: 24 | Iteration number: [2040/4518] 45% | Training loss: 0.6872232998410861
Epoch: 24 | Iteration number: [2050/4518] 45% | Training loss: 0.6872252412249402
Epoch: 24 | Iteration number: [2060/4518] 45% | Training loss: 0.6872254298149961
Epoch: 24 | Iteration number: [2070/4518] 45% | Training loss: 0.6872205073418824
Epoch: 24 | Iteration number: [2080/4518] 46% | Training loss: 0.6872121395973059
Epoch: 24 | Iteration number: [2090/4518] 46% | Training loss: 0.6872139686032346
Epoch: 24 | Iteration number: [2100/4518] 46% | Training loss: 0.687214256070909
Epoch: 24 | Iteration number: [2110/4518] 46% | Training loss: 0.6872176925717937
Epoch: 24 | Iteration number: [2120/4518] 46% | Training loss: 0.6872162123896041
Epoch: 24 | Iteration number: [2130/4518] 47% | Training loss: 0.6872209811714334
Epoch: 24 | Iteration number: [2140/4518] 47% | Training loss: 0.6872198131039878
Epoch: 24 | Iteration number: [2150/4518] 47% | Training loss: 0.687219288460044
Epoch: 24 | Iteration number: [2160/4518] 47% | Training loss: 0.687216097806339
Epoch: 24 | Iteration number: [2170/4518] 48% | Training loss: 0.68720867957937
Epoch: 24 | Iteration number: [2180/4518] 48% | Training loss: 0.687209876852298
Epoch: 24 | Iteration number: [2190/4518] 48% | Training loss: 0.6872113175860278
Epoch: 24 | Iteration number: [2200/4518] 48% | Training loss: 0.6872106665643779
Epoch: 24 | Iteration number: [2210/4518] 48% | Training loss: 0.6872103509859802
Epoch: 24 | Iteration number: [2220/4518] 49% | Training loss: 0.6872067177617872
Epoch: 24 | Iteration number: [2230/4518] 49% | Training loss: 0.6872036174273811
Epoch: 24 | Iteration number: [2240/4518] 49% | Training loss: 0.6872005744438087
Epoch: 24 | Iteration number: [2250/4518] 49% | Training loss: 0.6871937717331781
Epoch: 24 | Iteration number: [2260/4518] 50% | Training loss: 0.6871913837384334
Epoch: 24 | Iteration number: [2270/4518] 50% | Training loss: 0.6871933780315164
Epoch: 24 | Iteration number: [2280/4518] 50% | Training loss: 0.6871873695076558
Epoch: 24 | Iteration number: [2290/4518] 50% | Training loss: 0.6871860312582624
Epoch: 24 | Iteration number: [2300/4518] 50% | Training loss: 0.6871853116802548
Epoch: 24 | Iteration number: [2310/4518] 51% | Training loss: 0.6871797419471658
Epoch: 24 | Iteration number: [2320/4518] 51% | Training loss: 0.6871833167713264
Epoch: 24 | Iteration number: [2330/4518] 51% | Training loss: 0.6871855561569525
Epoch: 24 | Iteration number: [2340/4518] 51% | Training loss: 0.6871873593737936
Epoch: 24 | Iteration number: [2350/4518] 52% | Training loss: 0.6871825089099559
Epoch: 24 | Iteration number: [2360/4518] 52% | Training loss: 0.6871831020056192
Epoch: 24 | Iteration number: [2370/4518] 52% | Training loss: 0.6871751784272335
Epoch: 24 | Iteration number: [2380/4518] 52% | Training loss: 0.6871765566723688
Epoch: 24 | Iteration number: [2390/4518] 52% | Training loss: 0.6871795522368602
Epoch: 24 | Iteration number: [2400/4518] 53% | Training loss: 0.6871787327776353
Epoch: 24 | Iteration number: [2410/4518] 53% | Training loss: 0.6871710078350242
Epoch: 24 | Iteration number: [2420/4518] 53% | Training loss: 0.6871736256790555
Epoch: 24 | Iteration number: [2430/4518] 53% | Training loss: 0.6871775424284209
Epoch: 24 | Iteration number: [2440/4518] 54% | Training loss: 0.6871733033266224
Epoch: 24 | Iteration number: [2450/4518] 54% | Training loss: 0.6871751643930163
Epoch: 24 | Iteration number: [2460/4518] 54% | Training loss: 0.687176217877768
Epoch: 24 | Iteration number: [2470/4518] 54% | Training loss: 0.6871770080284552
Epoch: 24 | Iteration number: [2480/4518] 54% | Training loss: 0.6871780638492877
Epoch: 24 | Iteration number: [2490/4518] 55% | Training loss: 0.6871697620933793
Epoch: 24 | Iteration number: [2500/4518] 55% | Training loss: 0.6871743391752243
Epoch: 24 | Iteration number: [2510/4518] 55% | Training loss: 0.6871760547161102
Epoch: 24 | Iteration number: [2520/4518] 55% | Training loss: 0.6871725543623879
Epoch: 24 | Iteration number: [2530/4518] 55% | Training loss: 0.6871719274360671
Epoch: 24 | Iteration number: [2540/4518] 56% | Training loss: 0.6871716712872813
Epoch: 24 | Iteration number: [2550/4518] 56% | Training loss: 0.6871764928920596
Epoch: 24 | Iteration number: [2560/4518] 56% | Training loss: 0.6871696471003815
Epoch: 24 | Iteration number: [2570/4518] 56% | Training loss: 0.6871678038561855
Epoch: 24 | Iteration number: [2580/4518] 57% | Training loss: 0.6871697029864141
Epoch: 24 | Iteration number: [2590/4518] 57% | Training loss: 0.6871696503696294
Epoch: 24 | Iteration number: [2600/4518] 57% | Training loss: 0.6871722498994607
Epoch: 24 | Iteration number: [2610/4518] 57% | Training loss: 0.6871719929221947
Epoch: 24 | Iteration number: [2620/4518] 57% | Training loss: 0.6871689316425614
Epoch: 24 | Iteration number: [2630/4518] 58% | Training loss: 0.6871644606608401
Epoch: 24 | Iteration number: [2640/4518] 58% | Training loss: 0.6871660063438343
Epoch: 24 | Iteration number: [2650/4518] 58% | Training loss: 0.6871623342217139
Epoch: 24 | Iteration number: [2660/4518] 58% | Training loss: 0.6871659765566202
Epoch: 24 | Iteration number: [2670/4518] 59% | Training loss: 0.6871649184253779
Epoch: 24 | Iteration number: [2680/4518] 59% | Training loss: 0.6871585953146664
Epoch: 24 | Iteration number: [2690/4518] 59% | Training loss: 0.6871616890439314
Epoch: 24 | Iteration number: [2700/4518] 59% | Training loss: 0.6871613167833399
Epoch: 24 | Iteration number: [2710/4518] 59% | Training loss: 0.6871577034577232
Epoch: 24 | Iteration number: [2720/4518] 60% | Training loss: 0.6871507808346958
Epoch: 24 | Iteration number: [2730/4518] 60% | Training loss: 0.6871497392436087
Epoch: 24 | Iteration number: [2740/4518] 60% | Training loss: 0.6871496336738558
Epoch: 24 | Iteration number: [2750/4518] 60% | Training loss: 0.6871499868739736
Epoch: 24 | Iteration number: [2760/4518] 61% | Training loss: 0.6871522173285485
Epoch: 24 | Iteration number: [2770/4518] 61% | Training loss: 0.6871554876707952
Epoch: 24 | Iteration number: [2780/4518] 61% | Training loss: 0.6871552966267085
Epoch: 24 | Iteration number: [2790/4518] 61% | Training loss: 0.6871548077538877
Epoch: 24 | Iteration number: [2800/4518] 61% | Training loss: 0.6871532940225942
Epoch: 24 | Iteration number: [2810/4518] 62% | Training loss: 0.6871519950997362
Epoch: 24 | Iteration number: [2820/4518] 62% | Training loss: 0.6871472661376845
Epoch: 24 | Iteration number: [2830/4518] 62% | Training loss: 0.6871448252310601
Epoch: 24 | Iteration number: [2840/4518] 62% | Training loss: 0.6871388982928974
Epoch: 24 | Iteration number: [2850/4518] 63% | Training loss: 0.6871372843834391
Epoch: 24 | Iteration number: [2860/4518] 63% | Training loss: 0.6871392316334731
Epoch: 24 | Iteration number: [2870/4518] 63% | Training loss: 0.687137151948251
Epoch: 24 | Iteration number: [2880/4518] 63% | Training loss: 0.6871393385446734
Epoch: 24 | Iteration number: [2890/4518] 63% | Training loss: 0.6871405685442954
Epoch: 24 | Iteration number: [2900/4518] 64% | Training loss: 0.6871359931394971
Epoch: 24 | Iteration number: [2910/4518] 64% | Training loss: 0.6871370034938825
Epoch: 24 | Iteration number: [2920/4518] 64% | Training loss: 0.6871357378077834
Epoch: 24 | Iteration number: [2930/4518] 64% | Training loss: 0.6871339649674022
Epoch: 24 | Iteration number: [2940/4518] 65% | Training loss: 0.6871320760574471
Epoch: 24 | Iteration number: [2950/4518] 65% | Training loss: 0.6871275848251278
Epoch: 24 | Iteration number: [2960/4518] 65% | Training loss: 0.6871203033706627
Epoch: 24 | Iteration number: [2970/4518] 65% | Training loss: 0.6871219611729837
Epoch: 24 | Iteration number: [2980/4518] 65% | Training loss: 0.6871175958806236
Epoch: 24 | Iteration number: [2990/4518] 66% | Training loss: 0.6871176646106618
Epoch: 24 | Iteration number: [3000/4518] 66% | Training loss: 0.6871155307292939
Epoch: 24 | Iteration number: [3010/4518] 66% | Training loss: 0.6871174411520213
Epoch: 24 | Iteration number: [3020/4518] 66% | Training loss: 0.6871199571138976
Epoch: 24 | Iteration number: [3030/4518] 67% | Training loss: 0.6871190910488859
Epoch: 24 | Iteration number: [3040/4518] 67% | Training loss: 0.6871165629280241
Epoch: 24 | Iteration number: [3050/4518] 67% | Training loss: 0.6871129745733543
Epoch: 24 | Iteration number: [3060/4518] 67% | Training loss: 0.6871155315170101
Epoch: 24 | Iteration number: [3070/4518] 67% | Training loss: 0.6871143668016315
Epoch: 24 | Iteration number: [3080/4518] 68% | Training loss: 0.6871194994875363
Epoch: 24 | Iteration number: [3090/4518] 68% | Training loss: 0.687116912614952
Epoch: 24 | Iteration number: [3100/4518] 68% | Training loss: 0.6871181526299446
Epoch: 24 | Iteration number: [3110/4518] 68% | Training loss: 0.6871194562344689
Epoch: 24 | Iteration number: [3120/4518] 69% | Training loss: 0.6871170385716817
Epoch: 24 | Iteration number: [3130/4518] 69% | Training loss: 0.6871125345032055
Epoch: 24 | Iteration number: [3140/4518] 69% | Training loss: 0.6871121494063905
Epoch: 24 | Iteration number: [3150/4518] 69% | Training loss: 0.6871103759985121
Epoch: 24 | Iteration number: [3160/4518] 69% | Training loss: 0.6871091511619242
Epoch: 24 | Iteration number: [3170/4518] 70% | Training loss: 0.6871113338116968
Epoch: 24 | Iteration number: [3180/4518] 70% | Training loss: 0.6871107792329488
Epoch: 24 | Iteration number: [3190/4518] 70% | Training loss: 0.6871101093890152
Epoch: 24 | Iteration number: [3200/4518] 70% | Training loss: 0.6871044255420565
Epoch: 24 | Iteration number: [3210/4518] 71% | Training loss: 0.6870994121300469
Epoch: 24 | Iteration number: [3220/4518] 71% | Training loss: 0.6870981658282487
Epoch: 24 | Iteration number: [3230/4518] 71% | Training loss: 0.6871018386108587
Epoch: 24 | Iteration number: [3240/4518] 71% | Training loss: 0.6871037994086007
Epoch: 24 | Iteration number: [3250/4518] 71% | Training loss: 0.6871040562116183
Epoch: 24 | Iteration number: [3260/4518] 72% | Training loss: 0.6871049509092343
Epoch: 24 | Iteration number: [3270/4518] 72% | Training loss: 0.6871093391460745
Epoch: 24 | Iteration number: [3280/4518] 72% | Training loss: 0.6871057026633403
Epoch: 24 | Iteration number: [3290/4518] 72% | Training loss: 0.6871087838632357
Epoch: 24 | Iteration number: [3300/4518] 73% | Training loss: 0.6871086461977525
Epoch: 24 | Iteration number: [3310/4518] 73% | Training loss: 0.6871069960003533
Epoch: 24 | Iteration number: [3320/4518] 73% | Training loss: 0.6871069004736751
Epoch: 24 | Iteration number: [3330/4518] 73% | Training loss: 0.687103864666936
Epoch: 24 | Iteration number: [3340/4518] 73% | Training loss: 0.6871047322978516
Epoch: 24 | Iteration number: [3350/4518] 74% | Training loss: 0.6871021254027068
Epoch: 24 | Iteration number: [3360/4518] 74% | Training loss: 0.687101025134325
Epoch: 24 | Iteration number: [3370/4518] 74% | Training loss: 0.6870980284511159
Epoch: 24 | Iteration number: [3380/4518] 74% | Training loss: 0.687100581322196
Epoch: 24 | Iteration number: [3390/4518] 75% | Training loss: 0.6870938738714629
Epoch: 24 | Iteration number: [3400/4518] 75% | Training loss: 0.687095023709185
Epoch: 24 | Iteration number: [3410/4518] 75% | Training loss: 0.6870950657426437
Epoch: 24 | Iteration number: [3420/4518] 75% | Training loss: 0.6870910068004452
Epoch: 24 | Iteration number: [3430/4518] 75% | Training loss: 0.6870924846423958
Epoch: 24 | Iteration number: [3440/4518] 76% | Training loss: 0.6870963314418183
Epoch: 24 | Iteration number: [3450/4518] 76% | Training loss: 0.6870940498338229
Epoch: 24 | Iteration number: [3460/4518] 76% | Training loss: 0.6870940198615796
Epoch: 24 | Iteration number: [3470/4518] 76% | Training loss: 0.6870909774509562
Epoch: 24 | Iteration number: [3480/4518] 77% | Training loss: 0.6870926929958936
Epoch: 24 | Iteration number: [3490/4518] 77% | Training loss: 0.6870950221161446
Epoch: 24 | Iteration number: [3500/4518] 77% | Training loss: 0.6870952167340687
Epoch: 24 | Iteration number: [3510/4518] 77% | Training loss: 0.6870954772685668
Epoch: 24 | Iteration number: [3520/4518] 77% | Training loss: 0.6870988635684956
Epoch: 24 | Iteration number: [3530/4518] 78% | Training loss: 0.6870989820268268
Epoch: 24 | Iteration number: [3540/4518] 78% | Training loss: 0.6870953467942901
Epoch: 24 | Iteration number: [3550/4518] 78% | Training loss: 0.6870970465767552
Epoch: 24 | Iteration number: [3560/4518] 78% | Training loss: 0.6870986418610209
Epoch: 24 | Iteration number: [3570/4518] 79% | Training loss: 0.6870974954770727
Epoch: 24 | Iteration number: [3580/4518] 79% | Training loss: 0.6870965671772398
Epoch: 24 | Iteration number: [3590/4518] 79% | Training loss: 0.6870983548483145
Epoch: 24 | Iteration number: [3600/4518] 79% | Training loss: 0.6871002716157172
Epoch: 24 | Iteration number: [3610/4518] 79% | Training loss: 0.6871027721097265
Epoch: 24 | Iteration number: [3620/4518] 80% | Training loss: 0.687101282220519
Epoch: 24 | Iteration number: [3630/4518] 80% | Training loss: 0.6871014020331306
Epoch: 24 | Iteration number: [3640/4518] 80% | Training loss: 0.6871007429374443
Epoch: 24 | Iteration number: [3650/4518] 80% | Training loss: 0.6870984909632435
Epoch: 24 | Iteration number: [3660/4518] 81% | Training loss: 0.6870973792232451
Epoch: 24 | Iteration number: [3670/4518] 81% | Training loss: 0.6871008096501353
Epoch: 24 | Iteration number: [3680/4518] 81% | Training loss: 0.6871014335395201
Epoch: 24 | Iteration number: [3690/4518] 81% | Training loss: 0.6871014139516567
Epoch: 24 | Iteration number: [3700/4518] 81% | Training loss: 0.6871007120287096
Epoch: 24 | Iteration number: [3710/4518] 82% | Training loss: 0.687097188999068
Epoch: 24 | Iteration number: [3720/4518] 82% | Training loss: 0.6870967379340561
Epoch: 24 | Iteration number: [3730/4518] 82% | Training loss: 0.6870937626419374
Epoch: 24 | Iteration number: [3740/4518] 82% | Training loss: 0.6870906465512546
Epoch: 24 | Iteration number: [3750/4518] 83% | Training loss: 0.6870880919297536
Epoch: 24 | Iteration number: [3760/4518] 83% | Training loss: 0.687087704415651
Epoch: 24 | Iteration number: [3770/4518] 83% | Training loss: 0.6870856471814274
Epoch: 24 | Iteration number: [3780/4518] 83% | Training loss: 0.6870838063103812
Epoch: 24 | Iteration number: [3790/4518] 83% | Training loss: 0.6870834352787693
Epoch: 24 | Iteration number: [3800/4518] 84% | Training loss: 0.6870864736720136
Epoch: 24 | Iteration number: [3810/4518] 84% | Training loss: 0.6870863143071102
Epoch: 24 | Iteration number: [3820/4518] 84% | Training loss: 0.6870868280295926
Epoch: 24 | Iteration number: [3830/4518] 84% | Training loss: 0.6870838126221152
Epoch: 24 | Iteration number: [3840/4518] 84% | Training loss: 0.6870850993165125
Epoch: 24 | Iteration number: [3850/4518] 85% | Training loss: 0.6870846414101588
Epoch: 24 | Iteration number: [3860/4518] 85% | Training loss: 0.6870840131927648
Epoch: 24 | Iteration number: [3870/4518] 85% | Training loss: 0.6870821188586627
Epoch: 24 | Iteration number: [3880/4518] 85% | Training loss: 0.6870836275447275
Epoch: 24 | Iteration number: [3890/4518] 86% | Training loss: 0.6870853359717636
Epoch: 24 | Iteration number: [3900/4518] 86% | Training loss: 0.6870853178164897
Epoch: 24 | Iteration number: [3910/4518] 86% | Training loss: 0.6870835310053033
Epoch: 24 | Iteration number: [3920/4518] 86% | Training loss: 0.6870822179834454
Epoch: 24 | Iteration number: [3930/4518] 86% | Training loss: 0.6870803587460943
Epoch: 24 | Iteration number: [3940/4518] 87% | Training loss: 0.6870771294469156
Epoch: 24 | Iteration number: [3950/4518] 87% | Training loss: 0.6870706254922891
Epoch: 24 | Iteration number: [3960/4518] 87% | Training loss: 0.6870695266308207
Epoch: 24 | Iteration number: [3970/4518] 87% | Training loss: 0.687067074979883
Epoch: 24 | Iteration number: [3980/4518] 88% | Training loss: 0.6870656144678893
Epoch: 24 | Iteration number: [3990/4518] 88% | Training loss: 0.6870656238014536
Epoch: 24 | Iteration number: [4000/4518] 88% | Training loss: 0.6870641214698553
Epoch: 24 | Iteration number: [4010/4518] 88% | Training loss: 0.6870644850921155
Epoch: 24 | Iteration number: [4020/4518] 88% | Training loss: 0.6870653228825004
Epoch: 24 | Iteration number: [4030/4518] 89% | Training loss: 0.6870624367415757
Epoch: 24 | Iteration number: [4040/4518] 89% | Training loss: 0.6870636226812211
Epoch: 24 | Iteration number: [4050/4518] 89% | Training loss: 0.6870633414792425
Epoch: 24 | Iteration number: [4060/4518] 89% | Training loss: 0.6870635253895679
Epoch: 24 | Iteration number: [4070/4518] 90% | Training loss: 0.687061686290277
Epoch: 24 | Iteration number: [4080/4518] 90% | Training loss: 0.6870608328312051
Epoch: 24 | Iteration number: [4090/4518] 90% | Training loss: 0.6870583515441213
Epoch: 24 | Iteration number: [4100/4518] 90% | Training loss: 0.6870585227303388
Epoch: 24 | Iteration number: [4110/4518] 90% | Training loss: 0.6870567119759655
Epoch: 24 | Iteration number: [4120/4518] 91% | Training loss: 0.6870590240631289
Epoch: 24 | Iteration number: [4130/4518] 91% | Training loss: 0.6870581204752656
Epoch: 24 | Iteration number: [4140/4518] 91% | Training loss: 0.6870573178725542
Epoch: 24 | Iteration number: [4150/4518] 91% | Training loss: 0.6870580063957766
Epoch: 24 | Iteration number: [4160/4518] 92% | Training loss: 0.6870546965931471
Epoch: 24 | Iteration number: [4170/4518] 92% | Training loss: 0.6870526238168172
Epoch: 24 | Iteration number: [4180/4518] 92% | Training loss: 0.6870514692587145
Epoch: 24 | Iteration number: [4190/4518] 92% | Training loss: 0.6870518094884467
Epoch: 24 | Iteration number: [4200/4518] 92% | Training loss: 0.6870566652786164
Epoch: 24 | Iteration number: [4210/4518] 93% | Training loss: 0.6870539543181304
Epoch: 24 | Iteration number: [4220/4518] 93% | Training loss: 0.6870533092185784
Epoch: 24 | Iteration number: [4230/4518] 93% | Training loss: 0.6870533765771428
Epoch: 24 | Iteration number: [4240/4518] 93% | Training loss: 0.6870533519336638
Epoch: 24 | Iteration number: [4250/4518] 94% | Training loss: 0.687053227817311
Epoch: 24 | Iteration number: [4260/4518] 94% | Training loss: 0.6870483376750364
Epoch: 24 | Iteration number: [4270/4518] 94% | Training loss: 0.6870498165174167
Epoch: 24 | Iteration number: [4280/4518] 94% | Training loss: 0.6870468865209651
Epoch: 24 | Iteration number: [4290/4518] 94% | Training loss: 0.687047123575544
Epoch: 24 | Iteration number: [4300/4518] 95% | Training loss: 0.6870454802208169
Epoch: 24 | Iteration number: [4310/4518] 95% | Training loss: 0.6870421858093855
Epoch: 24 | Iteration number: [4320/4518] 95% | Training loss: 0.687040407859065
Epoch: 24 | Iteration number: [4330/4518] 95% | Training loss: 0.6870389753759045
Epoch: 24 | Iteration number: [4340/4518] 96% | Training loss: 0.6870389856226433
Epoch: 24 | Iteration number: [4350/4518] 96% | Training loss: 0.6870391186352434
Epoch: 24 | Iteration number: [4360/4518] 96% | Training loss: 0.6870371921073406
Epoch: 24 | Iteration number: [4370/4518] 96% | Training loss: 0.6870350065165853
Epoch: 24 | Iteration number: [4380/4518] 96% | Training loss: 0.6870344930723922
Epoch: 24 | Iteration number: [4390/4518] 97% | Training loss: 0.6870348237913128
Epoch: 24 | Iteration number: [4400/4518] 97% | Training loss: 0.6870336186479439
Epoch: 24 | Iteration number: [4410/4518] 97% | Training loss: 0.6870359427669421
Epoch: 24 | Iteration number: [4420/4518] 97% | Training loss: 0.6870347379424453
Epoch: 24 | Iteration number: [4430/4518] 98% | Training loss: 0.6870329215752621
Epoch: 24 | Iteration number: [4440/4518] 98% | Training loss: 0.6870313883767472
Epoch: 24 | Iteration number: [4450/4518] 98% | Training loss: 0.6870317450266206
Epoch: 24 | Iteration number: [4460/4518] 98% | Training loss: 0.6870302588282144
Epoch: 24 | Iteration number: [4470/4518] 98% | Training loss: 0.6870306712802358
Epoch: 24 | Iteration number: [4480/4518] 99% | Training loss: 0.6870309431504991
Epoch: 24 | Iteration number: [4490/4518] 99% | Training loss: 0.6870306844036935
Epoch: 24 | Iteration number: [4500/4518] 99% | Training loss: 0.6870303204456966
Epoch: 24 | Iteration number: [4510/4518] 99% | Training loss: 0.6870322116330564

 End of epoch: 24 | Train Loss: 0.686879290013041 | Training Time: 633 

 End of epoch: 24 | Eval Loss: 0.6899296264259183 | Evaluating Time: 17 
Epoch: 25 | Iteration number: [10/4518] 0% | Training loss: 0.7555191397666932
Epoch: 25 | Iteration number: [20/4518] 0% | Training loss: 0.7209821075201035
Epoch: 25 | Iteration number: [30/4518] 0% | Training loss: 0.7090118587017059
Epoch: 25 | Iteration number: [40/4518] 0% | Training loss: 0.7035653263330459
Epoch: 25 | Iteration number: [50/4518] 1% | Training loss: 0.700302402973175
Epoch: 25 | Iteration number: [60/4518] 1% | Training loss: 0.697770357131958
Epoch: 25 | Iteration number: [70/4518] 1% | Training loss: 0.6960646527154105
Epoch: 25 | Iteration number: [80/4518] 1% | Training loss: 0.6948617897927761
Epoch: 25 | Iteration number: [90/4518] 1% | Training loss: 0.6938585605886247
Epoch: 25 | Iteration number: [100/4518] 2% | Training loss: 0.6931120389699936
Epoch: 25 | Iteration number: [110/4518] 2% | Training loss: 0.6924658406864513
Epoch: 25 | Iteration number: [120/4518] 2% | Training loss: 0.6919748043020566
Epoch: 25 | Iteration number: [130/4518] 2% | Training loss: 0.6915899198788863
Epoch: 25 | Iteration number: [140/4518] 3% | Training loss: 0.6911841064691544
Epoch: 25 | Iteration number: [150/4518] 3% | Training loss: 0.6909939102331797
Epoch: 25 | Iteration number: [160/4518] 3% | Training loss: 0.6907915607094764
Epoch: 25 | Iteration number: [170/4518] 3% | Training loss: 0.6905905029352973
Epoch: 25 | Iteration number: [180/4518] 3% | Training loss: 0.690302512049675
Epoch: 25 | Iteration number: [190/4518] 4% | Training loss: 0.6900798129407983
Epoch: 25 | Iteration number: [200/4518] 4% | Training loss: 0.6899624663591385
Epoch: 25 | Iteration number: [210/4518] 4% | Training loss: 0.6898465116818746
Epoch: 25 | Iteration number: [220/4518] 4% | Training loss: 0.6897719472646713
Epoch: 25 | Iteration number: [230/4518] 5% | Training loss: 0.6896156562411266
Epoch: 25 | Iteration number: [240/4518] 5% | Training loss: 0.6895060032606125
Epoch: 25 | Iteration number: [250/4518] 5% | Training loss: 0.6893794956207275
Epoch: 25 | Iteration number: [260/4518] 5% | Training loss: 0.689292406806579
Epoch: 25 | Iteration number: [270/4518] 5% | Training loss: 0.6892205618045948
Epoch: 25 | Iteration number: [280/4518] 6% | Training loss: 0.6891472005418369
Epoch: 25 | Iteration number: [290/4518] 6% | Training loss: 0.6890221256634285
Epoch: 25 | Iteration number: [300/4518] 6% | Training loss: 0.6889810234308242
Epoch: 25 | Iteration number: [310/4518] 6% | Training loss: 0.688945883512497
Epoch: 25 | Iteration number: [320/4518] 7% | Training loss: 0.6888374311849474
Epoch: 25 | Iteration number: [330/4518] 7% | Training loss: 0.688767189690561
Epoch: 25 | Iteration number: [340/4518] 7% | Training loss: 0.6887579661958357
Epoch: 25 | Iteration number: [350/4518] 7% | Training loss: 0.6887052513871874
Epoch: 25 | Iteration number: [360/4518] 7% | Training loss: 0.6886738626493348
Epoch: 25 | Iteration number: [370/4518] 8% | Training loss: 0.6886294791827331
Epoch: 25 | Iteration number: [380/4518] 8% | Training loss: 0.6885599115961476
Epoch: 25 | Iteration number: [390/4518] 8% | Training loss: 0.6885296917878665
Epoch: 25 | Iteration number: [400/4518] 8% | Training loss: 0.68847157984972
Epoch: 25 | Iteration number: [410/4518] 9% | Training loss: 0.6884188527014198
Epoch: 25 | Iteration number: [420/4518] 9% | Training loss: 0.6883813785655158
Epoch: 25 | Iteration number: [430/4518] 9% | Training loss: 0.6883505121219989
Epoch: 25 | Iteration number: [440/4518] 9% | Training loss: 0.6883056285706434
Epoch: 25 | Iteration number: [450/4518] 9% | Training loss: 0.6882711137665642
Epoch: 25 | Iteration number: [460/4518] 10% | Training loss: 0.6882307379142097
Epoch: 25 | Iteration number: [470/4518] 10% | Training loss: 0.6882282872149285
Epoch: 25 | Iteration number: [480/4518] 10% | Training loss: 0.6882329302529494
Epoch: 25 | Iteration number: [490/4518] 10% | Training loss: 0.6882300447444527
Epoch: 25 | Iteration number: [500/4518] 11% | Training loss: 0.6881830983161926
Epoch: 25 | Iteration number: [510/4518] 11% | Training loss: 0.6881561403181039
Epoch: 25 | Iteration number: [520/4518] 11% | Training loss: 0.6881158808102974
Epoch: 25 | Iteration number: [530/4518] 11% | Training loss: 0.6880944011346349
Epoch: 25 | Iteration number: [540/4518] 11% | Training loss: 0.6880903441596914
Epoch: 25 | Iteration number: [550/4518] 12% | Training loss: 0.6880811861428348
Epoch: 25 | Iteration number: [560/4518] 12% | Training loss: 0.6880774195705142
Epoch: 25 | Iteration number: [570/4518] 12% | Training loss: 0.6880521351831002
Epoch: 25 | Iteration number: [580/4518] 12% | Training loss: 0.6880382156577604
Epoch: 25 | Iteration number: [590/4518] 13% | Training loss: 0.6880076858956935
Epoch: 25 | Iteration number: [600/4518] 13% | Training loss: 0.6880113340417544
Epoch: 25 | Iteration number: [610/4518] 13% | Training loss: 0.687988510288176
Epoch: 25 | Iteration number: [620/4518] 13% | Training loss: 0.6879786992265332
Epoch: 25 | Iteration number: [630/4518] 13% | Training loss: 0.6879498950072698
Epoch: 25 | Iteration number: [640/4518] 14% | Training loss: 0.6879343475215137
Epoch: 25 | Iteration number: [650/4518] 14% | Training loss: 0.6879150492411393
Epoch: 25 | Iteration number: [660/4518] 14% | Training loss: 0.6879025613719767
Epoch: 25 | Iteration number: [670/4518] 14% | Training loss: 0.6878939501385191
Epoch: 25 | Iteration number: [680/4518] 15% | Training loss: 0.6878637082436505
Epoch: 25 | Iteration number: [690/4518] 15% | Training loss: 0.6878555886987326
Epoch: 25 | Iteration number: [700/4518] 15% | Training loss: 0.6878332414797375
Epoch: 25 | Iteration number: [710/4518] 15% | Training loss: 0.6878333271389276
Epoch: 25 | Iteration number: [720/4518] 15% | Training loss: 0.6878298976355128
Epoch: 25 | Iteration number: [730/4518] 16% | Training loss: 0.6878269460919785
Epoch: 25 | Iteration number: [740/4518] 16% | Training loss: 0.6878327497759381
Epoch: 25 | Iteration number: [750/4518] 16% | Training loss: 0.6878282198905945
Epoch: 25 | Iteration number: [760/4518] 16% | Training loss: 0.687816091587669
Epoch: 25 | Iteration number: [770/4518] 17% | Training loss: 0.6877895798776057
Epoch: 25 | Iteration number: [780/4518] 17% | Training loss: 0.6877723239935362
Epoch: 25 | Iteration number: [790/4518] 17% | Training loss: 0.6877510004405734
Epoch: 25 | Iteration number: [800/4518] 17% | Training loss: 0.6877367136627436
Epoch: 25 | Iteration number: [810/4518] 17% | Training loss: 0.6877275967303618
Epoch: 25 | Iteration number: [820/4518] 18% | Training loss: 0.687707578917829
Epoch: 25 | Iteration number: [830/4518] 18% | Training loss: 0.6877155334116465
Epoch: 25 | Iteration number: [840/4518] 18% | Training loss: 0.6877175038769132
Epoch: 25 | Iteration number: [850/4518] 18% | Training loss: 0.6877003937609055
Epoch: 25 | Iteration number: [860/4518] 19% | Training loss: 0.6876737700645313
Epoch: 25 | Iteration number: [870/4518] 19% | Training loss: 0.6876597751146075
Epoch: 25 | Iteration number: [880/4518] 19% | Training loss: 0.6876530922949314
Epoch: 25 | Iteration number: [890/4518] 19% | Training loss: 0.6876517870452966
Epoch: 25 | Iteration number: [900/4518] 19% | Training loss: 0.6876456883218554
Epoch: 25 | Iteration number: [910/4518] 20% | Training loss: 0.6876412251493433
Epoch: 25 | Iteration number: [920/4518] 20% | Training loss: 0.6876328106159749
Epoch: 25 | Iteration number: [930/4518] 20% | Training loss: 0.6876002686638986
Epoch: 25 | Iteration number: [940/4518] 20% | Training loss: 0.6875891588469769
Epoch: 25 | Iteration number: [950/4518] 21% | Training loss: 0.6875817515348134
Epoch: 25 | Iteration number: [960/4518] 21% | Training loss: 0.6875702595959107
Epoch: 25 | Iteration number: [970/4518] 21% | Training loss: 0.6875588386329179
Epoch: 25 | Iteration number: [980/4518] 21% | Training loss: 0.6875384715138649
Epoch: 25 | Iteration number: [990/4518] 21% | Training loss: 0.6875445717512959
Epoch: 25 | Iteration number: [1000/4518] 22% | Training loss: 0.6875354301929474
Epoch: 25 | Iteration number: [1010/4518] 22% | Training loss: 0.6875298058042432
Epoch: 25 | Iteration number: [1020/4518] 22% | Training loss: 0.6875259681075228
Epoch: 25 | Iteration number: [1030/4518] 22% | Training loss: 0.6875288381159884
Epoch: 25 | Iteration number: [1040/4518] 23% | Training loss: 0.6875173600247273
Epoch: 25 | Iteration number: [1050/4518] 23% | Training loss: 0.687513208332516
Epoch: 25 | Iteration number: [1060/4518] 23% | Training loss: 0.6875217632865006
Epoch: 25 | Iteration number: [1070/4518] 23% | Training loss: 0.6875106858872921
Epoch: 25 | Iteration number: [1080/4518] 23% | Training loss: 0.6874990518446322
Epoch: 25 | Iteration number: [1090/4518] 24% | Training loss: 0.6874964586091697
Epoch: 25 | Iteration number: [1100/4518] 24% | Training loss: 0.6874889799681577
Epoch: 25 | Iteration number: [1110/4518] 24% | Training loss: 0.6874758786446339
Epoch: 25 | Iteration number: [1120/4518] 24% | Training loss: 0.6874684005443539
Epoch: 25 | Iteration number: [1130/4518] 25% | Training loss: 0.68745642251673
Epoch: 25 | Iteration number: [1140/4518] 25% | Training loss: 0.6874547381150095
Epoch: 25 | Iteration number: [1150/4518] 25% | Training loss: 0.6874589115122091
Epoch: 25 | Iteration number: [1160/4518] 25% | Training loss: 0.6874488053650691
Epoch: 25 | Iteration number: [1170/4518] 25% | Training loss: 0.6874535660458426
Epoch: 25 | Iteration number: [1180/4518] 26% | Training loss: 0.6874393460609145
Epoch: 25 | Iteration number: [1190/4518] 26% | Training loss: 0.6874325187266374
Epoch: 25 | Iteration number: [1200/4518] 26% | Training loss: 0.687418959637483
Epoch: 25 | Iteration number: [1210/4518] 26% | Training loss: 0.6874151568274852
Epoch: 25 | Iteration number: [1220/4518] 27% | Training loss: 0.6873974187940848
Epoch: 25 | Iteration number: [1230/4518] 27% | Training loss: 0.6873960004104831
Epoch: 25 | Iteration number: [1240/4518] 27% | Training loss: 0.6873881099685546
Epoch: 25 | Iteration number: [1250/4518] 27% | Training loss: 0.6873756585597992
Epoch: 25 | Iteration number: [1260/4518] 27% | Training loss: 0.6873654941244731
Epoch: 25 | Iteration number: [1270/4518] 28% | Training loss: 0.6873566153950579
Epoch: 25 | Iteration number: [1280/4518] 28% | Training loss: 0.6873417890630662
Epoch: 25 | Iteration number: [1290/4518] 28% | Training loss: 0.6873314007770184
Epoch: 25 | Iteration number: [1300/4518] 28% | Training loss: 0.687325352705442
Epoch: 25 | Iteration number: [1310/4518] 28% | Training loss: 0.6873291279523427
Epoch: 25 | Iteration number: [1320/4518] 29% | Training loss: 0.687334375670462
Epoch: 25 | Iteration number: [1330/4518] 29% | Training loss: 0.6873287495813871
Epoch: 25 | Iteration number: [1340/4518] 29% | Training loss: 0.687324760431674
Epoch: 25 | Iteration number: [1350/4518] 29% | Training loss: 0.6873272618982527
Epoch: 25 | Iteration number: [1360/4518] 30% | Training loss: 0.6873263166669537
Epoch: 25 | Iteration number: [1370/4518] 30% | Training loss: 0.6873293037832219
Epoch: 25 | Iteration number: [1380/4518] 30% | Training loss: 0.687325480191604
Epoch: 25 | Iteration number: [1390/4518] 30% | Training loss: 0.687328529272148
Epoch: 25 | Iteration number: [1400/4518] 30% | Training loss: 0.6873316592829568
Epoch: 25 | Iteration number: [1410/4518] 31% | Training loss: 0.6873307157070079
Epoch: 25 | Iteration number: [1420/4518] 31% | Training loss: 0.6873279466175697
Epoch: 25 | Iteration number: [1430/4518] 31% | Training loss: 0.687319444192873
Epoch: 25 | Iteration number: [1440/4518] 31% | Training loss: 0.6873182656864325
Epoch: 25 | Iteration number: [1450/4518] 32% | Training loss: 0.6873136145082014
Epoch: 25 | Iteration number: [1460/4518] 32% | Training loss: 0.6873076453600844
Epoch: 25 | Iteration number: [1470/4518] 32% | Training loss: 0.6873075767033765
Epoch: 25 | Iteration number: [1480/4518] 32% | Training loss: 0.6873157724738121
Epoch: 25 | Iteration number: [1490/4518] 32% | Training loss: 0.6873147888071585
Epoch: 25 | Iteration number: [1500/4518] 33% | Training loss: 0.6873084336121877
Epoch: 25 | Iteration number: [1510/4518] 33% | Training loss: 0.6873015383221456
Epoch: 25 | Iteration number: [1520/4518] 33% | Training loss: 0.687291007488966
Epoch: 25 | Iteration number: [1530/4518] 33% | Training loss: 0.6872920646386989
Epoch: 25 | Iteration number: [1540/4518] 34% | Training loss: 0.6872908763297192
Epoch: 25 | Iteration number: [1550/4518] 34% | Training loss: 0.687283621872625
Epoch: 25 | Iteration number: [1560/4518] 34% | Training loss: 0.6872771136271648
Epoch: 25 | Iteration number: [1570/4518] 34% | Training loss: 0.6872701778913
Epoch: 25 | Iteration number: [1580/4518] 34% | Training loss: 0.6872675842122187
Epoch: 25 | Iteration number: [1590/4518] 35% | Training loss: 0.6872664634536647
Epoch: 25 | Iteration number: [1600/4518] 35% | Training loss: 0.6872620185464621
Epoch: 25 | Iteration number: [1610/4518] 35% | Training loss: 0.6872573010299516
Epoch: 25 | Iteration number: [1620/4518] 35% | Training loss: 0.6872555255154033
Epoch: 25 | Iteration number: [1630/4518] 36% | Training loss: 0.6872509298149062
Epoch: 25 | Iteration number: [1640/4518] 36% | Training loss: 0.68724589082526
Epoch: 25 | Iteration number: [1650/4518] 36% | Training loss: 0.6872412982492736
Epoch: 25 | Iteration number: [1660/4518] 36% | Training loss: 0.6872402120426476
Epoch: 25 | Iteration number: [1670/4518] 36% | Training loss: 0.6872407030202672
Epoch: 25 | Iteration number: [1680/4518] 37% | Training loss: 0.6872313016936893
Epoch: 25 | Iteration number: [1690/4518] 37% | Training loss: 0.6872269755989843
Epoch: 25 | Iteration number: [1700/4518] 37% | Training loss: 0.6872316450581831
Epoch: 25 | Iteration number: [1710/4518] 37% | Training loss: 0.6872338560938138
Epoch: 25 | Iteration number: [1720/4518] 38% | Training loss: 0.6872279321038446
Epoch: 25 | Iteration number: [1730/4518] 38% | Training loss: 0.6872344477672797
Epoch: 25 | Iteration number: [1740/4518] 38% | Training loss: 0.6872294164252007
Epoch: 25 | Iteration number: [1750/4518] 38% | Training loss: 0.6872205488000597
Epoch: 25 | Iteration number: [1760/4518] 38% | Training loss: 0.6872189484875311
Epoch: 25 | Iteration number: [1770/4518] 39% | Training loss: 0.6872166287427568
Epoch: 25 | Iteration number: [1780/4518] 39% | Training loss: 0.687216335869907
Epoch: 25 | Iteration number: [1790/4518] 39% | Training loss: 0.6872035612274149
Epoch: 25 | Iteration number: [1800/4518] 39% | Training loss: 0.6872006888190906
Epoch: 25 | Iteration number: [1810/4518] 40% | Training loss: 0.68719702442048
Epoch: 25 | Iteration number: [1820/4518] 40% | Training loss: 0.6872005343437195
Epoch: 25 | Iteration number: [1830/4518] 40% | Training loss: 0.6872032539440635
Epoch: 25 | Iteration number: [1840/4518] 40% | Training loss: 0.6872081116813681
Epoch: 25 | Iteration number: [1850/4518] 40% | Training loss: 0.6872104312278129
Epoch: 25 | Iteration number: [1860/4518] 41% | Training loss: 0.6872083234530624
Epoch: 25 | Iteration number: [1870/4518] 41% | Training loss: 0.6872167702983407
Epoch: 25 | Iteration number: [1880/4518] 41% | Training loss: 0.6872086569983908
Epoch: 25 | Iteration number: [1890/4518] 41% | Training loss: 0.687204516249359
Epoch: 25 | Iteration number: [1900/4518] 42% | Training loss: 0.6872017787945898
Epoch: 25 | Iteration number: [1910/4518] 42% | Training loss: 0.6871982388159368
Epoch: 25 | Iteration number: [1920/4518] 42% | Training loss: 0.6871981097695729
Epoch: 25 | Iteration number: [1930/4518] 42% | Training loss: 0.6871960943226987
Epoch: 25 | Iteration number: [1940/4518] 42% | Training loss: 0.6872004516960419
Epoch: 25 | Iteration number: [1950/4518] 43% | Training loss: 0.6872001673013736
Epoch: 25 | Iteration number: [1960/4518] 43% | Training loss: 0.6871934317508522
Epoch: 25 | Iteration number: [1970/4518] 43% | Training loss: 0.6871920788348629
Epoch: 25 | Iteration number: [1980/4518] 43% | Training loss: 0.6871937151810136
Epoch: 25 | Iteration number: [1990/4518] 44% | Training loss: 0.6871889022426989
Epoch: 25 | Iteration number: [2000/4518] 44% | Training loss: 0.6871882412433624
Epoch: 25 | Iteration number: [2010/4518] 44% | Training loss: 0.68719007174174
Epoch: 25 | Iteration number: [2020/4518] 44% | Training loss: 0.6871875621894799
Epoch: 25 | Iteration number: [2030/4518] 44% | Training loss: 0.6871886540809876
Epoch: 25 | Iteration number: [2040/4518] 45% | Training loss: 0.6871935323757283
Epoch: 25 | Iteration number: [2050/4518] 45% | Training loss: 0.687194066018593
Epoch: 25 | Iteration number: [2060/4518] 45% | Training loss: 0.6871923861283701
Epoch: 25 | Iteration number: [2070/4518] 45% | Training loss: 0.6871908669310491
Epoch: 25 | Iteration number: [2080/4518] 46% | Training loss: 0.6871879587093225
Epoch: 25 | Iteration number: [2090/4518] 46% | Training loss: 0.6871908014185691
Epoch: 25 | Iteration number: [2100/4518] 46% | Training loss: 0.6871890036548887
Epoch: 25 | Iteration number: [2110/4518] 46% | Training loss: 0.6871829541373592
Epoch: 25 | Iteration number: [2120/4518] 46% | Training loss: 0.6871838628402296
Epoch: 25 | Iteration number: [2130/4518] 47% | Training loss: 0.6871801425033892
Epoch: 25 | Iteration number: [2140/4518] 47% | Training loss: 0.6871792530623552
Epoch: 25 | Iteration number: [2150/4518] 47% | Training loss: 0.6871816538655481
Epoch: 25 | Iteration number: [2160/4518] 47% | Training loss: 0.6871787996203811
Epoch: 25 | Iteration number: [2170/4518] 48% | Training loss: 0.6871803297699871
Epoch: 25 | Iteration number: [2180/4518] 48% | Training loss: 0.6871818987874809
Epoch: 25 | Iteration number: [2190/4518] 48% | Training loss: 0.6871814398188569
Epoch: 25 | Iteration number: [2200/4518] 48% | Training loss: 0.6871759932962331
Epoch: 25 | Iteration number: [2210/4518] 48% | Training loss: 0.6871806503690745
Epoch: 25 | Iteration number: [2220/4518] 49% | Training loss: 0.6871792727225535
Epoch: 25 | Iteration number: [2230/4518] 49% | Training loss: 0.6871670146426813
Epoch: 25 | Iteration number: [2240/4518] 49% | Training loss: 0.6871668806831751
Epoch: 25 | Iteration number: [2250/4518] 49% | Training loss: 0.6871627278327942
Epoch: 25 | Iteration number: [2260/4518] 50% | Training loss: 0.6871666008392266
Epoch: 25 | Iteration number: [2270/4518] 50% | Training loss: 0.6871666876755097
Epoch: 25 | Iteration number: [2280/4518] 50% | Training loss: 0.6871724205058918
Epoch: 25 | Iteration number: [2290/4518] 50% | Training loss: 0.6871689257923692
Epoch: 25 | Iteration number: [2300/4518] 50% | Training loss: 0.6871729745813038
Epoch: 25 | Iteration number: [2310/4518] 51% | Training loss: 0.6871729617253011
Epoch: 25 | Iteration number: [2320/4518] 51% | Training loss: 0.6871688560679041
Epoch: 25 | Iteration number: [2330/4518] 51% | Training loss: 0.6871640206150743
Epoch: 25 | Iteration number: [2340/4518] 51% | Training loss: 0.6871606735337493
Epoch: 25 | Iteration number: [2350/4518] 52% | Training loss: 0.6871666730464773
Epoch: 25 | Iteration number: [2360/4518] 52% | Training loss: 0.6871725028854305
Epoch: 25 | Iteration number: [2370/4518] 52% | Training loss: 0.6871740327857214
Epoch: 25 | Iteration number: [2380/4518] 52% | Training loss: 0.6871721568227817
Epoch: 25 | Iteration number: [2390/4518] 52% | Training loss: 0.6871727261832569
Epoch: 25 | Iteration number: [2400/4518] 53% | Training loss: 0.6871638217568398
Epoch: 25 | Iteration number: [2410/4518] 53% | Training loss: 0.6871623123335145
Epoch: 25 | Iteration number: [2420/4518] 53% | Training loss: 0.6871621562675996
Epoch: 25 | Iteration number: [2430/4518] 53% | Training loss: 0.687163724403813
Epoch: 25 | Iteration number: [2440/4518] 54% | Training loss: 0.6871655453668266
Epoch: 25 | Iteration number: [2450/4518] 54% | Training loss: 0.68716802317269
Epoch: 25 | Iteration number: [2460/4518] 54% | Training loss: 0.6871707917713538
Epoch: 25 | Iteration number: [2470/4518] 54% | Training loss: 0.6871708411195501
Epoch: 25 | Iteration number: [2480/4518] 54% | Training loss: 0.6871667158699805
Epoch: 25 | Iteration number: [2490/4518] 55% | Training loss: 0.6871664113069634
Epoch: 25 | Iteration number: [2500/4518] 55% | Training loss: 0.6871623510837555
Epoch: 25 | Iteration number: [2510/4518] 55% | Training loss: 0.6871569109865394
Epoch: 25 | Iteration number: [2520/4518] 55% | Training loss: 0.6871589429794795
Epoch: 25 | Iteration number: [2530/4518] 55% | Training loss: 0.6871607474423209
Epoch: 25 | Iteration number: [2540/4518] 56% | Training loss: 0.6871598536339332
Epoch: 25 | Iteration number: [2550/4518] 56% | Training loss: 0.6871528325595108
Epoch: 25 | Iteration number: [2560/4518] 56% | Training loss: 0.6871507075848058
Epoch: 25 | Iteration number: [2570/4518] 56% | Training loss: 0.6871509281809692
Epoch: 25 | Iteration number: [2580/4518] 57% | Training loss: 0.6871468071096627
Epoch: 25 | Iteration number: [2590/4518] 57% | Training loss: 0.68714493708721
Epoch: 25 | Iteration number: [2600/4518] 57% | Training loss: 0.6871451231608025
Epoch: 25 | Iteration number: [2610/4518] 57% | Training loss: 0.687144187401081
Epoch: 25 | Iteration number: [2620/4518] 57% | Training loss: 0.6871372138498394
Epoch: 25 | Iteration number: [2630/4518] 58% | Training loss: 0.6871355902559404
Epoch: 25 | Iteration number: [2640/4518] 58% | Training loss: 0.6871350118833961
Epoch: 25 | Iteration number: [2650/4518] 58% | Training loss: 0.6871351926956537
Epoch: 25 | Iteration number: [2660/4518] 58% | Training loss: 0.6871379048080373
Epoch: 25 | Iteration number: [2670/4518] 59% | Training loss: 0.6871370094099295
Epoch: 25 | Iteration number: [2680/4518] 59% | Training loss: 0.6871368591687572
Epoch: 25 | Iteration number: [2690/4518] 59% | Training loss: 0.6871373462854264
Epoch: 25 | Iteration number: [2700/4518] 59% | Training loss: 0.6871375426760427
Epoch: 25 | Iteration number: [2710/4518] 59% | Training loss: 0.6871352898458714
Epoch: 25 | Iteration number: [2720/4518] 60% | Training loss: 0.6871377661605091
Epoch: 25 | Iteration number: [2730/4518] 60% | Training loss: 0.6871393108542585
Epoch: 25 | Iteration number: [2740/4518] 60% | Training loss: 0.6871364701620853
Epoch: 25 | Iteration number: [2750/4518] 60% | Training loss: 0.6871406824805519
Epoch: 25 | Iteration number: [2760/4518] 61% | Training loss: 0.6871403449687405
Epoch: 25 | Iteration number: [2770/4518] 61% | Training loss: 0.6871392030147869
Epoch: 25 | Iteration number: [2780/4518] 61% | Training loss: 0.6871348178643975
Epoch: 25 | Iteration number: [2790/4518] 61% | Training loss: 0.6871319931467802
Epoch: 25 | Iteration number: [2800/4518] 61% | Training loss: 0.6871284985329423
Epoch: 25 | Iteration number: [2810/4518] 62% | Training loss: 0.6871275962035427
Epoch: 25 | Iteration number: [2820/4518] 62% | Training loss: 0.6871257226729224
Epoch: 25 | Iteration number: [2830/4518] 62% | Training loss: 0.6871266121999113
Epoch: 25 | Iteration number: [2840/4518] 62% | Training loss: 0.6871297967475904
Epoch: 25 | Iteration number: [2850/4518] 63% | Training loss: 0.6871272107174522
Epoch: 25 | Iteration number: [2860/4518] 63% | Training loss: 0.6871193467737078
Epoch: 25 | Iteration number: [2870/4518] 63% | Training loss: 0.6871218861810837
Epoch: 25 | Iteration number: [2880/4518] 63% | Training loss: 0.6871229784149263
Epoch: 25 | Iteration number: [2890/4518] 63% | Training loss: 0.6871219405665943
Epoch: 25 | Iteration number: [2900/4518] 64% | Training loss: 0.6871174342673401
Epoch: 25 | Iteration number: [2910/4518] 64% | Training loss: 0.6871176382315528
Epoch: 25 | Iteration number: [2920/4518] 64% | Training loss: 0.6871179253271181
Epoch: 25 | Iteration number: [2930/4518] 64% | Training loss: 0.6871180456856412
Epoch: 25 | Iteration number: [2940/4518] 65% | Training loss: 0.6871156210193828
Epoch: 25 | Iteration number: [2950/4518] 65% | Training loss: 0.68711201469777
Epoch: 25 | Iteration number: [2960/4518] 65% | Training loss: 0.6871118609969681
Epoch: 25 | Iteration number: [2970/4518] 65% | Training loss: 0.6871090596773809
Epoch: 25 | Iteration number: [2980/4518] 65% | Training loss: 0.6871105032879234
Epoch: 25 | Iteration number: [2990/4518] 66% | Training loss: 0.6871072270399751
Epoch: 25 | Iteration number: [3000/4518] 66% | Training loss: 0.6871083026925723
Epoch: 25 | Iteration number: [3010/4518] 66% | Training loss: 0.6871082767695683
Epoch: 25 | Iteration number: [3020/4518] 66% | Training loss: 0.687110412614235
Epoch: 25 | Iteration number: [3030/4518] 67% | Training loss: 0.6871121213971192
Epoch: 25 | Iteration number: [3040/4518] 67% | Training loss: 0.6871150914187494
Epoch: 25 | Iteration number: [3050/4518] 67% | Training loss: 0.6871138046413171
Epoch: 25 | Iteration number: [3060/4518] 67% | Training loss: 0.6871075104069866
Epoch: 25 | Iteration number: [3070/4518] 67% | Training loss: 0.6871054304733338
Epoch: 25 | Iteration number: [3080/4518] 68% | Training loss: 0.6870998728971976
Epoch: 25 | Iteration number: [3090/4518] 68% | Training loss: 0.6870968233613135
Epoch: 25 | Iteration number: [3100/4518] 68% | Training loss: 0.6870940557602914
Epoch: 25 | Iteration number: [3110/4518] 68% | Training loss: 0.6870946375120108
Epoch: 25 | Iteration number: [3120/4518] 69% | Training loss: 0.6870947327369299
Epoch: 25 | Iteration number: [3130/4518] 69% | Training loss: 0.687092212518564
Epoch: 25 | Iteration number: [3140/4518] 69% | Training loss: 0.6870927268722254
Epoch: 25 | Iteration number: [3150/4518] 69% | Training loss: 0.6870950734993768
Epoch: 25 | Iteration number: [3160/4518] 69% | Training loss: 0.6870963504797296
Epoch: 25 | Iteration number: [3170/4518] 70% | Training loss: 0.6870893808945496
Epoch: 25 | Iteration number: [3180/4518] 70% | Training loss: 0.687088287176576
Epoch: 25 | Iteration number: [3190/4518] 70% | Training loss: 0.6870867683969695
Epoch: 25 | Iteration number: [3200/4518] 70% | Training loss: 0.6870872016996146
Epoch: 25 | Iteration number: [3210/4518] 71% | Training loss: 0.6870847988908536
Epoch: 25 | Iteration number: [3220/4518] 71% | Training loss: 0.6870871271220793
Epoch: 25 | Iteration number: [3230/4518] 71% | Training loss: 0.6870897071649416
Epoch: 25 | Iteration number: [3240/4518] 71% | Training loss: 0.6870881296050402
Epoch: 25 | Iteration number: [3250/4518] 71% | Training loss: 0.6870828793782454
Epoch: 25 | Iteration number: [3260/4518] 72% | Training loss: 0.6870816760085112
Epoch: 25 | Iteration number: [3270/4518] 72% | Training loss: 0.6870826810507235
Epoch: 25 | Iteration number: [3280/4518] 72% | Training loss: 0.6870814443724912
Epoch: 25 | Iteration number: [3290/4518] 72% | Training loss: 0.6870803799853861
Epoch: 25 | Iteration number: [3300/4518] 73% | Training loss: 0.6870806985732281
Epoch: 25 | Iteration number: [3310/4518] 73% | Training loss: 0.6870798768593825
Epoch: 25 | Iteration number: [3320/4518] 73% | Training loss: 0.6870788040290395
Epoch: 25 | Iteration number: [3330/4518] 73% | Training loss: 0.6870782626104784
Epoch: 25 | Iteration number: [3340/4518] 73% | Training loss: 0.6870746766378779
Epoch: 25 | Iteration number: [3350/4518] 74% | Training loss: 0.6870752478357571
Epoch: 25 | Iteration number: [3360/4518] 74% | Training loss: 0.6870735500540052
Epoch: 25 | Iteration number: [3370/4518] 74% | Training loss: 0.6870707290993247
Epoch: 25 | Iteration number: [3380/4518] 74% | Training loss: 0.6870705464535211
Epoch: 25 | Iteration number: [3390/4518] 75% | Training loss: 0.6870723958036541
Epoch: 25 | Iteration number: [3400/4518] 75% | Training loss: 0.6870731382159626
Epoch: 25 | Iteration number: [3410/4518] 75% | Training loss: 0.6870728222855375
Epoch: 25 | Iteration number: [3420/4518] 75% | Training loss: 0.6870704619333758
Epoch: 25 | Iteration number: [3430/4518] 75% | Training loss: 0.687066124201516
Epoch: 25 | Iteration number: [3440/4518] 76% | Training loss: 0.6870670618359432
Epoch: 25 | Iteration number: [3450/4518] 76% | Training loss: 0.6870679610017417
Epoch: 25 | Iteration number: [3460/4518] 76% | Training loss: 0.6870653347817459
Epoch: 25 | Iteration number: [3470/4518] 76% | Training loss: 0.6870634701650493
Epoch: 25 | Iteration number: [3480/4518] 77% | Training loss: 0.6870611176408571
Epoch: 25 | Iteration number: [3490/4518] 77% | Training loss: 0.6870625623830069
Epoch: 25 | Iteration number: [3500/4518] 77% | Training loss: 0.6870637017999377
Epoch: 25 | Iteration number: [3510/4518] 77% | Training loss: 0.6870633935826457
Epoch: 25 | Iteration number: [3520/4518] 77% | Training loss: 0.6870603015646338
Epoch: 25 | Iteration number: [3530/4518] 78% | Training loss: 0.6870578311489256
Epoch: 25 | Iteration number: [3540/4518] 78% | Training loss: 0.6870570655091334
Epoch: 25 | Iteration number: [3550/4518] 78% | Training loss: 0.687057640653261
Epoch: 25 | Iteration number: [3560/4518] 78% | Training loss: 0.6870559947376841
Epoch: 25 | Iteration number: [3570/4518] 79% | Training loss: 0.6870549484461296
Epoch: 25 | Iteration number: [3580/4518] 79% | Training loss: 0.6870583715385565
Epoch: 25 | Iteration number: [3590/4518] 79% | Training loss: 0.6870584473470459
Epoch: 25 | Iteration number: [3600/4518] 79% | Training loss: 0.6870575414597988
Epoch: 25 | Iteration number: [3610/4518] 79% | Training loss: 0.6870560359921812
Epoch: 25 | Iteration number: [3620/4518] 80% | Training loss: 0.6870588399757996
Epoch: 25 | Iteration number: [3630/4518] 80% | Training loss: 0.6870539344210926
Epoch: 25 | Iteration number: [3640/4518] 80% | Training loss: 0.6870539008424832
Epoch: 25 | Iteration number: [3650/4518] 80% | Training loss: 0.6870520622762916
Epoch: 25 | Iteration number: [3660/4518] 81% | Training loss: 0.6870504014804715
Epoch: 25 | Iteration number: [3670/4518] 81% | Training loss: 0.6870492462890999
Epoch: 25 | Iteration number: [3680/4518] 81% | Training loss: 0.687050561606884
Epoch: 25 | Iteration number: [3690/4518] 81% | Training loss: 0.6870498728299852
Epoch: 25 | Iteration number: [3700/4518] 81% | Training loss: 0.6870464017745611
Epoch: 25 | Iteration number: [3710/4518] 82% | Training loss: 0.6870467190472584
Epoch: 25 | Iteration number: [3720/4518] 82% | Training loss: 0.6870480033018256
Epoch: 25 | Iteration number: [3730/4518] 82% | Training loss: 0.6870473869684235
Epoch: 25 | Iteration number: [3740/4518] 82% | Training loss: 0.6870457020672884
Epoch: 25 | Iteration number: [3750/4518] 83% | Training loss: 0.6870479877948761
Epoch: 25 | Iteration number: [3760/4518] 83% | Training loss: 0.6870463781534357
Epoch: 25 | Iteration number: [3770/4518] 83% | Training loss: 0.687047351181349
Epoch: 25 | Iteration number: [3780/4518] 83% | Training loss: 0.6870450341512286
Epoch: 25 | Iteration number: [3790/4518] 83% | Training loss: 0.6870449125452218
Epoch: 25 | Iteration number: [3800/4518] 84% | Training loss: 0.6870467693084165
Epoch: 25 | Iteration number: [3810/4518] 84% | Training loss: 0.687047324499746
Epoch: 25 | Iteration number: [3820/4518] 84% | Training loss: 0.6870469193496005
Epoch: 25 | Iteration number: [3830/4518] 84% | Training loss: 0.6870473202775104
Epoch: 25 | Iteration number: [3840/4518] 84% | Training loss: 0.6870455066518237
Epoch: 25 | Iteration number: [3850/4518] 85% | Training loss: 0.687048322333918
Epoch: 25 | Iteration number: [3860/4518] 85% | Training loss: 0.6870453610475817
Epoch: 25 | Iteration number: [3870/4518] 85% | Training loss: 0.687047893471188
Epoch: 25 | Iteration number: [3880/4518] 85% | Training loss: 0.6870469980940377
Epoch: 25 | Iteration number: [3890/4518] 86% | Training loss: 0.6870450198803585
Epoch: 25 | Iteration number: [3900/4518] 86% | Training loss: 0.687044375477693
Epoch: 25 | Iteration number: [3910/4518] 86% | Training loss: 0.6870450202461399
Epoch: 25 | Iteration number: [3920/4518] 86% | Training loss: 0.6870449271433208
Epoch: 25 | Iteration number: [3930/4518] 86% | Training loss: 0.6870420552088711
Epoch: 25 | Iteration number: [3940/4518] 87% | Training loss: 0.6870408818806488
Epoch: 25 | Iteration number: [3950/4518] 87% | Training loss: 0.6870414475851421
Epoch: 25 | Iteration number: [3960/4518] 87% | Training loss: 0.6870414496521757
Epoch: 25 | Iteration number: [3970/4518] 87% | Training loss: 0.6870377073660305
Epoch: 25 | Iteration number: [3980/4518] 88% | Training loss: 0.6870331765868556
Epoch: 25 | Iteration number: [3990/4518] 88% | Training loss: 0.6870326429829562
Epoch: 25 | Iteration number: [4000/4518] 88% | Training loss: 0.6870324947237968
Epoch: 25 | Iteration number: [4010/4518] 88% | Training loss: 0.687033485786576
Epoch: 25 | Iteration number: [4020/4518] 88% | Training loss: 0.6870325060181357
Epoch: 25 | Iteration number: [4030/4518] 89% | Training loss: 0.6870308671192851
Epoch: 25 | Iteration number: [4040/4518] 89% | Training loss: 0.687028560721048
Epoch: 25 | Iteration number: [4050/4518] 89% | Training loss: 0.6870280916013836
Epoch: 25 | Iteration number: [4060/4518] 89% | Training loss: 0.6870245880828115
Epoch: 25 | Iteration number: [4070/4518] 90% | Training loss: 0.6870233717216614
Epoch: 25 | Iteration number: [4080/4518] 90% | Training loss: 0.6870245317910232
Epoch: 25 | Iteration number: [4090/4518] 90% | Training loss: 0.6870252040604216
Epoch: 25 | Iteration number: [4100/4518] 90% | Training loss: 0.6870250423506993
Epoch: 25 | Iteration number: [4110/4518] 90% | Training loss: 0.6870196442099383
Epoch: 25 | Iteration number: [4120/4518] 91% | Training loss: 0.6870206283423507
Epoch: 25 | Iteration number: [4130/4518] 91% | Training loss: 0.687022235780305
Epoch: 25 | Iteration number: [4140/4518] 91% | Training loss: 0.6870188559886914
Epoch: 25 | Iteration number: [4150/4518] 91% | Training loss: 0.6870200798884932
Epoch: 25 | Iteration number: [4160/4518] 92% | Training loss: 0.6870212309492322
Epoch: 25 | Iteration number: [4170/4518] 92% | Training loss: 0.6870200677741346
Epoch: 25 | Iteration number: [4180/4518] 92% | Training loss: 0.6870212321503881
Epoch: 25 | Iteration number: [4190/4518] 92% | Training loss: 0.6870239224951705
Epoch: 25 | Iteration number: [4200/4518] 92% | Training loss: 0.6870224822277115
Epoch: 25 | Iteration number: [4210/4518] 93% | Training loss: 0.6870203158351418
Epoch: 25 | Iteration number: [4220/4518] 93% | Training loss: 0.6870221715544073
Epoch: 25 | Iteration number: [4230/4518] 93% | Training loss: 0.6870209286539831
Epoch: 25 | Iteration number: [4240/4518] 93% | Training loss: 0.6870165392475308
Epoch: 25 | Iteration number: [4250/4518] 94% | Training loss: 0.6870166032454547
Epoch: 25 | Iteration number: [4260/4518] 94% | Training loss: 0.6870173662761008
Epoch: 25 | Iteration number: [4270/4518] 94% | Training loss: 0.6870167646670509
Epoch: 25 | Iteration number: [4280/4518] 94% | Training loss: 0.6870135990537216
Epoch: 25 | Iteration number: [4290/4518] 94% | Training loss: 0.6870164800635029
Epoch: 25 | Iteration number: [4300/4518] 95% | Training loss: 0.6870164069186809
Epoch: 25 | Iteration number: [4310/4518] 95% | Training loss: 0.6870144967413281
Epoch: 25 | Iteration number: [4320/4518] 95% | Training loss: 0.6870166500271471
Epoch: 25 | Iteration number: [4330/4518] 95% | Training loss: 0.6870195578620285
Epoch: 25 | Iteration number: [4340/4518] 96% | Training loss: 0.6870213876671506
Epoch: 25 | Iteration number: [4350/4518] 96% | Training loss: 0.687019224344999
Epoch: 25 | Iteration number: [4360/4518] 96% | Training loss: 0.6870181865648393
Epoch: 25 | Iteration number: [4370/4518] 96% | Training loss: 0.6870186475921823
Epoch: 25 | Iteration number: [4380/4518] 96% | Training loss: 0.6870185871102494
Epoch: 25 | Iteration number: [4390/4518] 97% | Training loss: 0.6870197483510254
Epoch: 25 | Iteration number: [4400/4518] 97% | Training loss: 0.6870223473012448
Epoch: 25 | Iteration number: [4410/4518] 97% | Training loss: 0.6870210089245621
Epoch: 25 | Iteration number: [4420/4518] 97% | Training loss: 0.6870212951666629
Epoch: 25 | Iteration number: [4430/4518] 98% | Training loss: 0.687018473974469
Epoch: 25 | Iteration number: [4440/4518] 98% | Training loss: 0.6870144071745443
Epoch: 25 | Iteration number: [4450/4518] 98% | Training loss: 0.6870140573014034
Epoch: 25 | Iteration number: [4460/4518] 98% | Training loss: 0.6870138367863514
Epoch: 25 | Iteration number: [4470/4518] 98% | Training loss: 0.6870150281145535
Epoch: 25 | Iteration number: [4480/4518] 99% | Training loss: 0.6870164217693465
Epoch: 25 | Iteration number: [4490/4518] 99% | Training loss: 0.6870169525024354
Epoch: 25 | Iteration number: [4500/4518] 99% | Training loss: 0.6870181345409817
Epoch: 25 | Iteration number: [4510/4518] 99% | Training loss: 0.6870189765604531

 End of epoch: 25 | Train Loss: 0.6868679126499501 | Training Time: 633 

 End of epoch: 25 | Eval Loss: 0.6899277531370824 | Evaluating Time: 18 
Epoch: 26 | Iteration number: [10/4518] 0% | Training loss: 0.7552151501178741
Epoch: 26 | Iteration number: [20/4518] 0% | Training loss: 0.7212676465511322
Epoch: 26 | Iteration number: [30/4518] 0% | Training loss: 0.7099475065867106
Epoch: 26 | Iteration number: [40/4518] 0% | Training loss: 0.7039435893297196
Epoch: 26 | Iteration number: [50/4518] 1% | Training loss: 0.7007706356048584
Epoch: 26 | Iteration number: [60/4518] 1% | Training loss: 0.6984112481276195
Epoch: 26 | Iteration number: [70/4518] 1% | Training loss: 0.6968464953558785
Epoch: 26 | Iteration number: [80/4518] 1% | Training loss: 0.6955706618726254
Epoch: 26 | Iteration number: [90/4518] 1% | Training loss: 0.6944438868098789
Epoch: 26 | Iteration number: [100/4518] 2% | Training loss: 0.6937537378072739
Epoch: 26 | Iteration number: [110/4518] 2% | Training loss: 0.6930020971731706
Epoch: 26 | Iteration number: [120/4518] 2% | Training loss: 0.6925030504663785
Epoch: 26 | Iteration number: [130/4518] 2% | Training loss: 0.6921090135207543
Epoch: 26 | Iteration number: [140/4518] 3% | Training loss: 0.6918160659926278
Epoch: 26 | Iteration number: [150/4518] 3% | Training loss: 0.6914485045274099
Epoch: 26 | Iteration number: [160/4518] 3% | Training loss: 0.691086246073246
Epoch: 26 | Iteration number: [170/4518] 3% | Training loss: 0.690823467689402
Epoch: 26 | Iteration number: [180/4518] 3% | Training loss: 0.6906919423076842
Epoch: 26 | Iteration number: [190/4518] 4% | Training loss: 0.6905257557567798
Epoch: 26 | Iteration number: [200/4518] 4% | Training loss: 0.6903319364786148
Epoch: 26 | Iteration number: [210/4518] 4% | Training loss: 0.6901668625218528
Epoch: 26 | Iteration number: [220/4518] 4% | Training loss: 0.6900039827281779
Epoch: 26 | Iteration number: [230/4518] 5% | Training loss: 0.6898580828438634
Epoch: 26 | Iteration number: [240/4518] 5% | Training loss: 0.689715335269769
Epoch: 26 | Iteration number: [250/4518] 5% | Training loss: 0.6896671357154847
Epoch: 26 | Iteration number: [260/4518] 5% | Training loss: 0.6895380625357994
Epoch: 26 | Iteration number: [270/4518] 5% | Training loss: 0.6894597188190178
Epoch: 26 | Iteration number: [280/4518] 6% | Training loss: 0.6893748208880425
Epoch: 26 | Iteration number: [290/4518] 6% | Training loss: 0.6892991666136117
Epoch: 26 | Iteration number: [300/4518] 6% | Training loss: 0.6892728308836619
Epoch: 26 | Iteration number: [310/4518] 6% | Training loss: 0.6892135116361803
Epoch: 26 | Iteration number: [320/4518] 7% | Training loss: 0.6891505159437656
Epoch: 26 | Iteration number: [330/4518] 7% | Training loss: 0.6890490625843857
Epoch: 26 | Iteration number: [340/4518] 7% | Training loss: 0.688999037006322
Epoch: 26 | Iteration number: [350/4518] 7% | Training loss: 0.6889369399206979
Epoch: 26 | Iteration number: [360/4518] 7% | Training loss: 0.6888654251893361
Epoch: 26 | Iteration number: [370/4518] 8% | Training loss: 0.6887903572739782
Epoch: 26 | Iteration number: [380/4518] 8% | Training loss: 0.6887685982804549
Epoch: 26 | Iteration number: [390/4518] 8% | Training loss: 0.6887318809827169
Epoch: 26 | Iteration number: [400/4518] 8% | Training loss: 0.6886825561523438
Epoch: 26 | Iteration number: [410/4518] 9% | Training loss: 0.688665807392539
Epoch: 26 | Iteration number: [420/4518] 9% | Training loss: 0.6886311488492148
Epoch: 26 | Iteration number: [430/4518] 9% | Training loss: 0.6885455107966135
Epoch: 26 | Iteration number: [440/4518] 9% | Training loss: 0.6885078226978129
Epoch: 26 | Iteration number: [450/4518] 9% | Training loss: 0.6884874284267426
Epoch: 26 | Iteration number: [460/4518] 10% | Training loss: 0.6884451816911282
Epoch: 26 | Iteration number: [470/4518] 10% | Training loss: 0.6883999370514078
Epoch: 26 | Iteration number: [480/4518] 10% | Training loss: 0.6883688391496737
Epoch: 26 | Iteration number: [490/4518] 10% | Training loss: 0.6883501207341953
Epoch: 26 | Iteration number: [500/4518] 11% | Training loss: 0.6883130365610123
Epoch: 26 | Iteration number: [510/4518] 11% | Training loss: 0.6882802953907088
Epoch: 26 | Iteration number: [520/4518] 11% | Training loss: 0.6882149290580016
Epoch: 26 | Iteration number: [530/4518] 11% | Training loss: 0.6882088880493956
Epoch: 26 | Iteration number: [540/4518] 11% | Training loss: 0.6881743507252799
Epoch: 26 | Iteration number: [550/4518] 12% | Training loss: 0.688167625990781
Epoch: 26 | Iteration number: [560/4518] 12% | Training loss: 0.6881422361092908
Epoch: 26 | Iteration number: [570/4518] 12% | Training loss: 0.6881146486391101
Epoch: 26 | Iteration number: [580/4518] 12% | Training loss: 0.6880746043961624
Epoch: 26 | Iteration number: [590/4518] 13% | Training loss: 0.6880671495098178
Epoch: 26 | Iteration number: [600/4518] 13% | Training loss: 0.6880349095662435
Epoch: 26 | Iteration number: [610/4518] 13% | Training loss: 0.6880258219163926
Epoch: 26 | Iteration number: [620/4518] 13% | Training loss: 0.6880250072286975
Epoch: 26 | Iteration number: [630/4518] 13% | Training loss: 0.6879967520161281
Epoch: 26 | Iteration number: [640/4518] 14% | Training loss: 0.6879621245898306
Epoch: 26 | Iteration number: [650/4518] 14% | Training loss: 0.687950388101431
Epoch: 26 | Iteration number: [660/4518] 14% | Training loss: 0.6879414487065691
Epoch: 26 | Iteration number: [670/4518] 14% | Training loss: 0.6879226769973983
Epoch: 26 | Iteration number: [680/4518] 15% | Training loss: 0.6879110389772584
Epoch: 26 | Iteration number: [690/4518] 15% | Training loss: 0.6878921367120052
Epoch: 26 | Iteration number: [700/4518] 15% | Training loss: 0.6878568607568741
Epoch: 26 | Iteration number: [710/4518] 15% | Training loss: 0.6878098643161881
Epoch: 26 | Iteration number: [720/4518] 15% | Training loss: 0.6877902659277121
Epoch: 26 | Iteration number: [730/4518] 16% | Training loss: 0.6878039471907158
Epoch: 26 | Iteration number: [740/4518] 16% | Training loss: 0.687781823567442
Epoch: 26 | Iteration number: [750/4518] 16% | Training loss: 0.6877826269467672
Epoch: 26 | Iteration number: [760/4518] 16% | Training loss: 0.6877599372675545
Epoch: 26 | Iteration number: [770/4518] 17% | Training loss: 0.6877529496496374
Epoch: 26 | Iteration number: [780/4518] 17% | Training loss: 0.6877274628633108
Epoch: 26 | Iteration number: [790/4518] 17% | Training loss: 0.6877123334739782
Epoch: 26 | Iteration number: [800/4518] 17% | Training loss: 0.6877018296718598
Epoch: 26 | Iteration number: [810/4518] 17% | Training loss: 0.6876919130484264
Epoch: 26 | Iteration number: [820/4518] 18% | Training loss: 0.6876838931950128
Epoch: 26 | Iteration number: [830/4518] 18% | Training loss: 0.687670666123011
Epoch: 26 | Iteration number: [840/4518] 18% | Training loss: 0.6876619332603046
Epoch: 26 | Iteration number: [850/4518] 18% | Training loss: 0.6876571306761573
Epoch: 26 | Iteration number: [860/4518] 19% | Training loss: 0.6876250750103662
Epoch: 26 | Iteration number: [870/4518] 19% | Training loss: 0.687624894476485
Epoch: 26 | Iteration number: [880/4518] 19% | Training loss: 0.6876338810405948
Epoch: 26 | Iteration number: [890/4518] 19% | Training loss: 0.6876163986291778
Epoch: 26 | Iteration number: [900/4518] 19% | Training loss: 0.687612302435769
Epoch: 26 | Iteration number: [910/4518] 20% | Training loss: 0.6875996966938396
Epoch: 26 | Iteration number: [920/4518] 20% | Training loss: 0.6875865086913109
Epoch: 26 | Iteration number: [930/4518] 20% | Training loss: 0.6875667881581091
Epoch: 26 | Iteration number: [940/4518] 20% | Training loss: 0.6875542690145209
Epoch: 26 | Iteration number: [950/4518] 21% | Training loss: 0.6875420334464626
Epoch: 26 | Iteration number: [960/4518] 21% | Training loss: 0.6875307263806463
Epoch: 26 | Iteration number: [970/4518] 21% | Training loss: 0.6875254615065978
Epoch: 26 | Iteration number: [980/4518] 21% | Training loss: 0.6875237365158237
Epoch: 26 | Iteration number: [990/4518] 21% | Training loss: 0.6875135248959666
Epoch: 26 | Iteration number: [1000/4518] 22% | Training loss: 0.6875042765140533
Epoch: 26 | Iteration number: [1010/4518] 22% | Training loss: 0.6874856353396236
Epoch: 26 | Iteration number: [1020/4518] 22% | Training loss: 0.687482601462626
Epoch: 26 | Iteration number: [1030/4518] 22% | Training loss: 0.6874689215595282
Epoch: 26 | Iteration number: [1040/4518] 23% | Training loss: 0.6874554437513535
Epoch: 26 | Iteration number: [1050/4518] 23% | Training loss: 0.6874475131716047
Epoch: 26 | Iteration number: [1060/4518] 23% | Training loss: 0.6874414501887447
Epoch: 26 | Iteration number: [1070/4518] 23% | Training loss: 0.6874301796204576
Epoch: 26 | Iteration number: [1080/4518] 23% | Training loss: 0.6874279001796687
Epoch: 26 | Iteration number: [1090/4518] 24% | Training loss: 0.6874187334961848
Epoch: 26 | Iteration number: [1100/4518] 24% | Training loss: 0.6874175622246482
Epoch: 26 | Iteration number: [1110/4518] 24% | Training loss: 0.6874132712145109
Epoch: 26 | Iteration number: [1120/4518] 24% | Training loss: 0.6874178013631276
Epoch: 26 | Iteration number: [1130/4518] 25% | Training loss: 0.687414863310029
Epoch: 26 | Iteration number: [1140/4518] 25% | Training loss: 0.6874025018068782
Epoch: 26 | Iteration number: [1150/4518] 25% | Training loss: 0.6874024035101352
Epoch: 26 | Iteration number: [1160/4518] 25% | Training loss: 0.6873933646185645
Epoch: 26 | Iteration number: [1170/4518] 25% | Training loss: 0.6873931282096439
Epoch: 26 | Iteration number: [1180/4518] 26% | Training loss: 0.6873756690550659
Epoch: 26 | Iteration number: [1190/4518] 26% | Training loss: 0.6873705260392998
Epoch: 26 | Iteration number: [1200/4518] 26% | Training loss: 0.6873543912172317
Epoch: 26 | Iteration number: [1210/4518] 26% | Training loss: 0.6873506559320718
Epoch: 26 | Iteration number: [1220/4518] 27% | Training loss: 0.6873443359722856
Epoch: 26 | Iteration number: [1230/4518] 27% | Training loss: 0.6873360328558015
Epoch: 26 | Iteration number: [1240/4518] 27% | Training loss: 0.6873301955000046
Epoch: 26 | Iteration number: [1250/4518] 27% | Training loss: 0.6873173395156861
Epoch: 26 | Iteration number: [1260/4518] 27% | Training loss: 0.6873143799721249
Epoch: 26 | Iteration number: [1270/4518] 28% | Training loss: 0.6873159763850565
Epoch: 26 | Iteration number: [1280/4518] 28% | Training loss: 0.6873204222414643
Epoch: 26 | Iteration number: [1290/4518] 28% | Training loss: 0.6873092660146166
Epoch: 26 | Iteration number: [1300/4518] 28% | Training loss: 0.6873091397835658
Epoch: 26 | Iteration number: [1310/4518] 28% | Training loss: 0.6873017566349671
Epoch: 26 | Iteration number: [1320/4518] 29% | Training loss: 0.6872988365364797
Epoch: 26 | Iteration number: [1330/4518] 29% | Training loss: 0.6872932454249017
Epoch: 26 | Iteration number: [1340/4518] 29% | Training loss: 0.6873020519516362
Epoch: 26 | Iteration number: [1350/4518] 29% | Training loss: 0.6872952493914851
Epoch: 26 | Iteration number: [1360/4518] 30% | Training loss: 0.6872963065610213
Epoch: 26 | Iteration number: [1370/4518] 30% | Training loss: 0.6873025940282501
Epoch: 26 | Iteration number: [1380/4518] 30% | Training loss: 0.6873002703639044
Epoch: 26 | Iteration number: [1390/4518] 30% | Training loss: 0.6873035261956908
Epoch: 26 | Iteration number: [1400/4518] 30% | Training loss: 0.6872973159807069
Epoch: 26 | Iteration number: [1410/4518] 31% | Training loss: 0.6872872049504138
Epoch: 26 | Iteration number: [1420/4518] 31% | Training loss: 0.6872816239024552
Epoch: 26 | Iteration number: [1430/4518] 31% | Training loss: 0.68727868320225
Epoch: 26 | Iteration number: [1440/4518] 31% | Training loss: 0.6872732448909018
Epoch: 26 | Iteration number: [1450/4518] 32% | Training loss: 0.6872698769076118
Epoch: 26 | Iteration number: [1460/4518] 32% | Training loss: 0.6872748799519997
Epoch: 26 | Iteration number: [1470/4518] 32% | Training loss: 0.6872702756301076
Epoch: 26 | Iteration number: [1480/4518] 32% | Training loss: 0.6872678628241694
Epoch: 26 | Iteration number: [1490/4518] 32% | Training loss: 0.6872516890900247
Epoch: 26 | Iteration number: [1500/4518] 33% | Training loss: 0.6872502562602361
Epoch: 26 | Iteration number: [1510/4518] 33% | Training loss: 0.6872505777324273
Epoch: 26 | Iteration number: [1520/4518] 33% | Training loss: 0.6872430859035568
Epoch: 26 | Iteration number: [1530/4518] 33% | Training loss: 0.6872502847045076
Epoch: 26 | Iteration number: [1540/4518] 34% | Training loss: 0.6872436691027183
Epoch: 26 | Iteration number: [1550/4518] 34% | Training loss: 0.6872423505013989
Epoch: 26 | Iteration number: [1560/4518] 34% | Training loss: 0.6872391298031195
Epoch: 26 | Iteration number: [1570/4518] 34% | Training loss: 0.6872335373596021
Epoch: 26 | Iteration number: [1580/4518] 34% | Training loss: 0.6872327027818824
Epoch: 26 | Iteration number: [1590/4518] 35% | Training loss: 0.6872254576698039
Epoch: 26 | Iteration number: [1600/4518] 35% | Training loss: 0.6872301354631781
Epoch: 26 | Iteration number: [1610/4518] 35% | Training loss: 0.6872233478549105
Epoch: 26 | Iteration number: [1620/4518] 35% | Training loss: 0.6872211751378613
Epoch: 26 | Iteration number: [1630/4518] 36% | Training loss: 0.6872181589252379
Epoch: 26 | Iteration number: [1640/4518] 36% | Training loss: 0.6872199474311457
Epoch: 26 | Iteration number: [1650/4518] 36% | Training loss: 0.6872197289539106
Epoch: 26 | Iteration number: [1660/4518] 36% | Training loss: 0.6872122363153711
Epoch: 26 | Iteration number: [1670/4518] 36% | Training loss: 0.6872120616678706
Epoch: 26 | Iteration number: [1680/4518] 37% | Training loss: 0.687201270851351
Epoch: 26 | Iteration number: [1690/4518] 37% | Training loss: 0.6872063684392963
Epoch: 26 | Iteration number: [1700/4518] 37% | Training loss: 0.6872052578715717
Epoch: 26 | Iteration number: [1710/4518] 37% | Training loss: 0.6871968023609697
Epoch: 26 | Iteration number: [1720/4518] 38% | Training loss: 0.6871993727462237
Epoch: 26 | Iteration number: [1730/4518] 38% | Training loss: 0.6871991086901957
Epoch: 26 | Iteration number: [1740/4518] 38% | Training loss: 0.6871826573349964
Epoch: 26 | Iteration number: [1750/4518] 38% | Training loss: 0.687184874194009
Epoch: 26 | Iteration number: [1760/4518] 38% | Training loss: 0.6871898926455866
Epoch: 26 | Iteration number: [1770/4518] 39% | Training loss: 0.6871982357596274
Epoch: 26 | Iteration number: [1780/4518] 39% | Training loss: 0.6871922507044974
Epoch: 26 | Iteration number: [1790/4518] 39% | Training loss: 0.6871881090395944
Epoch: 26 | Iteration number: [1800/4518] 39% | Training loss: 0.6871870632966359
Epoch: 26 | Iteration number: [1810/4518] 40% | Training loss: 0.687187680750262
Epoch: 26 | Iteration number: [1820/4518] 40% | Training loss: 0.6871906984638382
Epoch: 26 | Iteration number: [1830/4518] 40% | Training loss: 0.6871893748559587
Epoch: 26 | Iteration number: [1840/4518] 40% | Training loss: 0.6871811981110469
Epoch: 26 | Iteration number: [1850/4518] 40% | Training loss: 0.6871860201938732
Epoch: 26 | Iteration number: [1860/4518] 41% | Training loss: 0.6871774675384644
Epoch: 26 | Iteration number: [1870/4518] 41% | Training loss: 0.6871756458027477
Epoch: 26 | Iteration number: [1880/4518] 41% | Training loss: 0.6871679486429437
Epoch: 26 | Iteration number: [1890/4518] 41% | Training loss: 0.6871754300657403
Epoch: 26 | Iteration number: [1900/4518] 42% | Training loss: 0.6871740387615405
Epoch: 26 | Iteration number: [1910/4518] 42% | Training loss: 0.6871717369369187
Epoch: 26 | Iteration number: [1920/4518] 42% | Training loss: 0.6871684311889112
Epoch: 26 | Iteration number: [1930/4518] 42% | Training loss: 0.6871657810989439
Epoch: 26 | Iteration number: [1940/4518] 42% | Training loss: 0.6871715837532713
Epoch: 26 | Iteration number: [1950/4518] 43% | Training loss: 0.6871724922534747
Epoch: 26 | Iteration number: [1960/4518] 43% | Training loss: 0.6871728539466858
Epoch: 26 | Iteration number: [1970/4518] 43% | Training loss: 0.6871710338568324
Epoch: 26 | Iteration number: [1980/4518] 43% | Training loss: 0.6871649927262103
Epoch: 26 | Iteration number: [1990/4518] 44% | Training loss: 0.6871621363726094
Epoch: 26 | Iteration number: [2000/4518] 44% | Training loss: 0.6871565646231175
Epoch: 26 | Iteration number: [2010/4518] 44% | Training loss: 0.6871554878220629
Epoch: 26 | Iteration number: [2020/4518] 44% | Training loss: 0.6871532750011671
Epoch: 26 | Iteration number: [2030/4518] 44% | Training loss: 0.6871541166540437
Epoch: 26 | Iteration number: [2040/4518] 45% | Training loss: 0.6871550238892143
Epoch: 26 | Iteration number: [2050/4518] 45% | Training loss: 0.68715252460503
Epoch: 26 | Iteration number: [2060/4518] 45% | Training loss: 0.6871519987733619
Epoch: 26 | Iteration number: [2070/4518] 45% | Training loss: 0.6871528778387153
Epoch: 26 | Iteration number: [2080/4518] 46% | Training loss: 0.6871517701504323
Epoch: 26 | Iteration number: [2090/4518] 46% | Training loss: 0.687154092686028
Epoch: 26 | Iteration number: [2100/4518] 46% | Training loss: 0.687155632745652
Epoch: 26 | Iteration number: [2110/4518] 46% | Training loss: 0.6871467513213225
Epoch: 26 | Iteration number: [2120/4518] 46% | Training loss: 0.687141297082856
Epoch: 26 | Iteration number: [2130/4518] 47% | Training loss: 0.6871480649905586
Epoch: 26 | Iteration number: [2140/4518] 47% | Training loss: 0.6871493359592473
Epoch: 26 | Iteration number: [2150/4518] 47% | Training loss: 0.6871459813450658
Epoch: 26 | Iteration number: [2160/4518] 47% | Training loss: 0.6871451784339216
Epoch: 26 | Iteration number: [2170/4518] 48% | Training loss: 0.6871440759452258
Epoch: 26 | Iteration number: [2180/4518] 48% | Training loss: 0.6871428142720406
Epoch: 26 | Iteration number: [2190/4518] 48% | Training loss: 0.6871402577450286
Epoch: 26 | Iteration number: [2200/4518] 48% | Training loss: 0.6871387053619732
Epoch: 26 | Iteration number: [2210/4518] 48% | Training loss: 0.6871387514053966
Epoch: 26 | Iteration number: [2220/4518] 49% | Training loss: 0.6871370034443366
Epoch: 26 | Iteration number: [2230/4518] 49% | Training loss: 0.6871348563063839
Epoch: 26 | Iteration number: [2240/4518] 49% | Training loss: 0.6871348819562367
Epoch: 26 | Iteration number: [2250/4518] 49% | Training loss: 0.6871301035351224
Epoch: 26 | Iteration number: [2260/4518] 50% | Training loss: 0.6871288792485685
Epoch: 26 | Iteration number: [2270/4518] 50% | Training loss: 0.6871213781150952
Epoch: 26 | Iteration number: [2280/4518] 50% | Training loss: 0.6871199028533802
Epoch: 26 | Iteration number: [2290/4518] 50% | Training loss: 0.6871118339909216
Epoch: 26 | Iteration number: [2300/4518] 50% | Training loss: 0.68711102179859
Epoch: 26 | Iteration number: [2310/4518] 51% | Training loss: 0.6871072177247052
Epoch: 26 | Iteration number: [2320/4518] 51% | Training loss: 0.6871042818858706
Epoch: 26 | Iteration number: [2330/4518] 51% | Training loss: 0.6870960865665403
Epoch: 26 | Iteration number: [2340/4518] 51% | Training loss: 0.6870910600209847
Epoch: 26 | Iteration number: [2350/4518] 52% | Training loss: 0.6870845972730758
Epoch: 26 | Iteration number: [2360/4518] 52% | Training loss: 0.6870875750305289
Epoch: 26 | Iteration number: [2370/4518] 52% | Training loss: 0.6870887896682643
Epoch: 26 | Iteration number: [2380/4518] 52% | Training loss: 0.6870868086814881
Epoch: 26 | Iteration number: [2390/4518] 52% | Training loss: 0.6870879782792415
Epoch: 26 | Iteration number: [2400/4518] 53% | Training loss: 0.6870831659932931
Epoch: 26 | Iteration number: [2410/4518] 53% | Training loss: 0.6870834929319832
Epoch: 26 | Iteration number: [2420/4518] 53% | Training loss: 0.6870877628237748
Epoch: 26 | Iteration number: [2430/4518] 53% | Training loss: 0.6870892888233986
Epoch: 26 | Iteration number: [2440/4518] 54% | Training loss: 0.6870877359245644
Epoch: 26 | Iteration number: [2450/4518] 54% | Training loss: 0.6870892516690857
Epoch: 26 | Iteration number: [2460/4518] 54% | Training loss: 0.6870896600368547
Epoch: 26 | Iteration number: [2470/4518] 54% | Training loss: 0.6870922355758033
Epoch: 26 | Iteration number: [2480/4518] 54% | Training loss: 0.6870934841853957
Epoch: 26 | Iteration number: [2490/4518] 55% | Training loss: 0.6870948456138013
Epoch: 26 | Iteration number: [2500/4518] 55% | Training loss: 0.6870881843090058
Epoch: 26 | Iteration number: [2510/4518] 55% | Training loss: 0.6870857049506974
Epoch: 26 | Iteration number: [2520/4518] 55% | Training loss: 0.6870794353267503
Epoch: 26 | Iteration number: [2530/4518] 55% | Training loss: 0.6870768986200627
Epoch: 26 | Iteration number: [2540/4518] 56% | Training loss: 0.6870733970966865
Epoch: 26 | Iteration number: [2550/4518] 56% | Training loss: 0.6870719294220794
Epoch: 26 | Iteration number: [2560/4518] 56% | Training loss: 0.6870734204305335
Epoch: 26 | Iteration number: [2570/4518] 56% | Training loss: 0.687073073707202
Epoch: 26 | Iteration number: [2580/4518] 57% | Training loss: 0.6870740424986034
Epoch: 26 | Iteration number: [2590/4518] 57% | Training loss: 0.6870693883150241
Epoch: 26 | Iteration number: [2600/4518] 57% | Training loss: 0.687063970886744
Epoch: 26 | Iteration number: [2610/4518] 57% | Training loss: 0.6870617101704024
Epoch: 26 | Iteration number: [2620/4518] 57% | Training loss: 0.6870657260408838
Epoch: 26 | Iteration number: [2630/4518] 58% | Training loss: 0.6870648344886621
Epoch: 26 | Iteration number: [2640/4518] 58% | Training loss: 0.6870669879696586
Epoch: 26 | Iteration number: [2650/4518] 58% | Training loss: 0.6870676243080283
Epoch: 26 | Iteration number: [2660/4518] 58% | Training loss: 0.6870644470578746
Epoch: 26 | Iteration number: [2670/4518] 59% | Training loss: 0.6870657352026036
Epoch: 26 | Iteration number: [2680/4518] 59% | Training loss: 0.6870648161466442
Epoch: 26 | Iteration number: [2690/4518] 59% | Training loss: 0.687067271962928
Epoch: 26 | Iteration number: [2700/4518] 59% | Training loss: 0.6870684955296693
Epoch: 26 | Iteration number: [2710/4518] 59% | Training loss: 0.6870682478170993
Epoch: 26 | Iteration number: [2720/4518] 60% | Training loss: 0.6870679497937946
Epoch: 26 | Iteration number: [2730/4518] 60% | Training loss: 0.6870677063971649
Epoch: 26 | Iteration number: [2740/4518] 60% | Training loss: 0.6870613081611856
Epoch: 26 | Iteration number: [2750/4518] 60% | Training loss: 0.6870633182959123
Epoch: 26 | Iteration number: [2760/4518] 61% | Training loss: 0.6870591448916905
Epoch: 26 | Iteration number: [2770/4518] 61% | Training loss: 0.6870547711634033
Epoch: 26 | Iteration number: [2780/4518] 61% | Training loss: 0.6870556258897987
Epoch: 26 | Iteration number: [2790/4518] 61% | Training loss: 0.6870523041508104
Epoch: 26 | Iteration number: [2800/4518] 61% | Training loss: 0.6870521655891623
Epoch: 26 | Iteration number: [2810/4518] 62% | Training loss: 0.6870557886849943
Epoch: 26 | Iteration number: [2820/4518] 62% | Training loss: 0.6870545303567926
Epoch: 26 | Iteration number: [2830/4518] 62% | Training loss: 0.687055992869522
Epoch: 26 | Iteration number: [2840/4518] 62% | Training loss: 0.6870549428001256
Epoch: 26 | Iteration number: [2850/4518] 63% | Training loss: 0.6870540124282503
Epoch: 26 | Iteration number: [2860/4518] 63% | Training loss: 0.6870554070372682
Epoch: 26 | Iteration number: [2870/4518] 63% | Training loss: 0.6870573022224347
Epoch: 26 | Iteration number: [2880/4518] 63% | Training loss: 0.687056783773005
Epoch: 26 | Iteration number: [2890/4518] 63% | Training loss: 0.6870581871498003
Epoch: 26 | Iteration number: [2900/4518] 64% | Training loss: 0.6870593726634979
Epoch: 26 | Iteration number: [2910/4518] 64% | Training loss: 0.6870581382328702
Epoch: 26 | Iteration number: [2920/4518] 64% | Training loss: 0.687055820063369
Epoch: 26 | Iteration number: [2930/4518] 64% | Training loss: 0.6870563628323656
Epoch: 26 | Iteration number: [2940/4518] 65% | Training loss: 0.6870527238870153
Epoch: 26 | Iteration number: [2950/4518] 65% | Training loss: 0.6870521010382701
Epoch: 26 | Iteration number: [2960/4518] 65% | Training loss: 0.687051605815823
Epoch: 26 | Iteration number: [2970/4518] 65% | Training loss: 0.6870522770616744
Epoch: 26 | Iteration number: [2980/4518] 65% | Training loss: 0.6870500994008659
Epoch: 26 | Iteration number: [2990/4518] 66% | Training loss: 0.6870468132272612
Epoch: 26 | Iteration number: [3000/4518] 66% | Training loss: 0.6870448125203451
Epoch: 26 | Iteration number: [3010/4518] 66% | Training loss: 0.687045207134513
Epoch: 26 | Iteration number: [3020/4518] 66% | Training loss: 0.6870455567213084
Epoch: 26 | Iteration number: [3030/4518] 67% | Training loss: 0.6870523562132329
Epoch: 26 | Iteration number: [3040/4518] 67% | Training loss: 0.6870542806034026
Epoch: 26 | Iteration number: [3050/4518] 67% | Training loss: 0.6870538133285085
Epoch: 26 | Iteration number: [3060/4518] 67% | Training loss: 0.687050783458878
Epoch: 26 | Iteration number: [3070/4518] 67% | Training loss: 0.6870516718598841
Epoch: 26 | Iteration number: [3080/4518] 68% | Training loss: 0.6870530567192412
Epoch: 26 | Iteration number: [3090/4518] 68% | Training loss: 0.6870555661835717
Epoch: 26 | Iteration number: [3100/4518] 68% | Training loss: 0.6870535520392079
Epoch: 26 | Iteration number: [3110/4518] 68% | Training loss: 0.687050050535386
Epoch: 26 | Iteration number: [3120/4518] 69% | Training loss: 0.6870532428798003
Epoch: 26 | Iteration number: [3130/4518] 69% | Training loss: 0.6870546060248305
Epoch: 26 | Iteration number: [3140/4518] 69% | Training loss: 0.6870556000121839
Epoch: 26 | Iteration number: [3150/4518] 69% | Training loss: 0.6870562241380177
Epoch: 26 | Iteration number: [3160/4518] 69% | Training loss: 0.687059739948828
Epoch: 26 | Iteration number: [3170/4518] 70% | Training loss: 0.6870617443266728
Epoch: 26 | Iteration number: [3180/4518] 70% | Training loss: 0.6870591266725048
Epoch: 26 | Iteration number: [3190/4518] 70% | Training loss: 0.6870596861017162
Epoch: 26 | Iteration number: [3200/4518] 70% | Training loss: 0.6870620847865939
Epoch: 26 | Iteration number: [3210/4518] 71% | Training loss: 0.6870613931124084
Epoch: 26 | Iteration number: [3220/4518] 71% | Training loss: 0.68705822927241
Epoch: 26 | Iteration number: [3230/4518] 71% | Training loss: 0.6870571088126569
Epoch: 26 | Iteration number: [3240/4518] 71% | Training loss: 0.6870527424746089
Epoch: 26 | Iteration number: [3250/4518] 71% | Training loss: 0.6870566787352929
Epoch: 26 | Iteration number: [3260/4518] 72% | Training loss: 0.6870571233926375
Epoch: 26 | Iteration number: [3270/4518] 72% | Training loss: 0.6870579968898668
Epoch: 26 | Iteration number: [3280/4518] 72% | Training loss: 0.6870567876391295
Epoch: 26 | Iteration number: [3290/4518] 72% | Training loss: 0.6870588881085347
Epoch: 26 | Iteration number: [3300/4518] 73% | Training loss: 0.6870584417834427
Epoch: 26 | Iteration number: [3310/4518] 73% | Training loss: 0.6870565714612829
Epoch: 26 | Iteration number: [3320/4518] 73% | Training loss: 0.6870557048593658
Epoch: 26 | Iteration number: [3330/4518] 73% | Training loss: 0.6870572834043531
Epoch: 26 | Iteration number: [3340/4518] 73% | Training loss: 0.687060435839042
Epoch: 26 | Iteration number: [3350/4518] 74% | Training loss: 0.6870624487969412
Epoch: 26 | Iteration number: [3360/4518] 74% | Training loss: 0.6870603835121507
Epoch: 26 | Iteration number: [3370/4518] 74% | Training loss: 0.6870572660195722
Epoch: 26 | Iteration number: [3380/4518] 74% | Training loss: 0.6870575904317157
Epoch: 26 | Iteration number: [3390/4518] 75% | Training loss: 0.6870566524411373
Epoch: 26 | Iteration number: [3400/4518] 75% | Training loss: 0.6870573563786114
Epoch: 26 | Iteration number: [3410/4518] 75% | Training loss: 0.687057847326452
Epoch: 26 | Iteration number: [3420/4518] 75% | Training loss: 0.6870606626683509
Epoch: 26 | Iteration number: [3430/4518] 75% | Training loss: 0.6870611523747792
Epoch: 26 | Iteration number: [3440/4518] 76% | Training loss: 0.6870638130016105
Epoch: 26 | Iteration number: [3450/4518] 76% | Training loss: 0.6870667618253957
Epoch: 26 | Iteration number: [3460/4518] 76% | Training loss: 0.687071266684229
Epoch: 26 | Iteration number: [3470/4518] 76% | Training loss: 0.6870695241761826
Epoch: 26 | Iteration number: [3480/4518] 77% | Training loss: 0.6870722558649107
Epoch: 26 | Iteration number: [3490/4518] 77% | Training loss: 0.6870709696608491
Epoch: 26 | Iteration number: [3500/4518] 77% | Training loss: 0.6870696234362466
Epoch: 26 | Iteration number: [3510/4518] 77% | Training loss: 0.6870698342465947
Epoch: 26 | Iteration number: [3520/4518] 77% | Training loss: 0.6870661774819548
Epoch: 26 | Iteration number: [3530/4518] 78% | Training loss: 0.6870669629857493
Epoch: 26 | Iteration number: [3540/4518] 78% | Training loss: 0.6870642405782043
Epoch: 26 | Iteration number: [3550/4518] 78% | Training loss: 0.687065836829199
Epoch: 26 | Iteration number: [3560/4518] 78% | Training loss: 0.6870640728413389
Epoch: 26 | Iteration number: [3570/4518] 79% | Training loss: 0.6870609134185214
Epoch: 26 | Iteration number: [3580/4518] 79% | Training loss: 0.6870590582906201
Epoch: 26 | Iteration number: [3590/4518] 79% | Training loss: 0.6870569313469039
Epoch: 26 | Iteration number: [3600/4518] 79% | Training loss: 0.6870560707814164
Epoch: 26 | Iteration number: [3610/4518] 79% | Training loss: 0.6870541570754592
Epoch: 26 | Iteration number: [3620/4518] 80% | Training loss: 0.6870536718579286
Epoch: 26 | Iteration number: [3630/4518] 80% | Training loss: 0.6870503001140825
Epoch: 26 | Iteration number: [3640/4518] 80% | Training loss: 0.6870512972493749
Epoch: 26 | Iteration number: [3650/4518] 80% | Training loss: 0.6870467376872285
Epoch: 26 | Iteration number: [3660/4518] 81% | Training loss: 0.6870485577915536
Epoch: 26 | Iteration number: [3670/4518] 81% | Training loss: 0.6870454213599743
Epoch: 26 | Iteration number: [3680/4518] 81% | Training loss: 0.6870437389482622
Epoch: 26 | Iteration number: [3690/4518] 81% | Training loss: 0.6870440975114259
Epoch: 26 | Iteration number: [3700/4518] 81% | Training loss: 0.6870433723604357
Epoch: 26 | Iteration number: [3710/4518] 82% | Training loss: 0.6870425984544574
Epoch: 26 | Iteration number: [3720/4518] 82% | Training loss: 0.6870405317634665
Epoch: 26 | Iteration number: [3730/4518] 82% | Training loss: 0.6870391842027772
Epoch: 26 | Iteration number: [3740/4518] 82% | Training loss: 0.6870358869672459
Epoch: 26 | Iteration number: [3750/4518] 83% | Training loss: 0.6870351762612661
Epoch: 26 | Iteration number: [3760/4518] 83% | Training loss: 0.6870326982058109
Epoch: 26 | Iteration number: [3770/4518] 83% | Training loss: 0.6870286436232711
Epoch: 26 | Iteration number: [3780/4518] 83% | Training loss: 0.6870265966843045
Epoch: 26 | Iteration number: [3790/4518] 83% | Training loss: 0.6870273801613609
Epoch: 26 | Iteration number: [3800/4518] 84% | Training loss: 0.6870284526599081
Epoch: 26 | Iteration number: [3810/4518] 84% | Training loss: 0.6870275871960196
Epoch: 26 | Iteration number: [3820/4518] 84% | Training loss: 0.68702797764883
Epoch: 26 | Iteration number: [3830/4518] 84% | Training loss: 0.6870290105710142
Epoch: 26 | Iteration number: [3840/4518] 84% | Training loss: 0.6870275630926093
Epoch: 26 | Iteration number: [3850/4518] 85% | Training loss: 0.6870235810806224
Epoch: 26 | Iteration number: [3860/4518] 85% | Training loss: 0.6870210523586817
Epoch: 26 | Iteration number: [3870/4518] 85% | Training loss: 0.6870190383851991
Epoch: 26 | Iteration number: [3880/4518] 85% | Training loss: 0.6870202257000294
Epoch: 26 | Iteration number: [3890/4518] 86% | Training loss: 0.6870200620978535
Epoch: 26 | Iteration number: [3900/4518] 86% | Training loss: 0.6870229883377369
Epoch: 26 | Iteration number: [3910/4518] 86% | Training loss: 0.6870221094554647
Epoch: 26 | Iteration number: [3920/4518] 86% | Training loss: 0.6870245732367039
Epoch: 26 | Iteration number: [3930/4518] 86% | Training loss: 0.6870229601101717
Epoch: 26 | Iteration number: [3940/4518] 87% | Training loss: 0.6870264402500869
Epoch: 26 | Iteration number: [3950/4518] 87% | Training loss: 0.6870306818998313
Epoch: 26 | Iteration number: [3960/4518] 87% | Training loss: 0.6870318737144422
Epoch: 26 | Iteration number: [3970/4518] 87% | Training loss: 0.6870306674419182
Epoch: 26 | Iteration number: [3980/4518] 88% | Training loss: 0.6870297725326452
Epoch: 26 | Iteration number: [3990/4518] 88% | Training loss: 0.687028927298118
Epoch: 26 | Iteration number: [4000/4518] 88% | Training loss: 0.687030350074172
Epoch: 26 | Iteration number: [4010/4518] 88% | Training loss: 0.6870306254473708
Epoch: 26 | Iteration number: [4020/4518] 88% | Training loss: 0.6870278488344221
Epoch: 26 | Iteration number: [4030/4518] 89% | Training loss: 0.6870285003120196
Epoch: 26 | Iteration number: [4040/4518] 89% | Training loss: 0.6870283281449044
Epoch: 26 | Iteration number: [4050/4518] 89% | Training loss: 0.6870260846614837
Epoch: 26 | Iteration number: [4060/4518] 89% | Training loss: 0.6870260304124485
Epoch: 26 | Iteration number: [4070/4518] 90% | Training loss: 0.6870240861426408
Epoch: 26 | Iteration number: [4080/4518] 90% | Training loss: 0.6870251327606978
Epoch: 26 | Iteration number: [4090/4518] 90% | Training loss: 0.6870273946404165
Epoch: 26 | Iteration number: [4100/4518] 90% | Training loss: 0.6870310222230307
Epoch: 26 | Iteration number: [4110/4518] 90% | Training loss: 0.6870340595135144
Epoch: 26 | Iteration number: [4120/4518] 91% | Training loss: 0.6870312428734835
Epoch: 26 | Iteration number: [4130/4518] 91% | Training loss: 0.6870296254717986
Epoch: 26 | Iteration number: [4140/4518] 91% | Training loss: 0.6870267484355088
Epoch: 26 | Iteration number: [4150/4518] 91% | Training loss: 0.6870258362034717
Epoch: 26 | Iteration number: [4160/4518] 92% | Training loss: 0.6870288410868782
Epoch: 26 | Iteration number: [4170/4518] 92% | Training loss: 0.6870317782572419
Epoch: 26 | Iteration number: [4180/4518] 92% | Training loss: 0.6870272156581925
Epoch: 26 | Iteration number: [4190/4518] 92% | Training loss: 0.6870278494454796
Epoch: 26 | Iteration number: [4200/4518] 92% | Training loss: 0.687026147814024
Epoch: 26 | Iteration number: [4210/4518] 93% | Training loss: 0.6870264998949055
Epoch: 26 | Iteration number: [4220/4518] 93% | Training loss: 0.6870244113613644
Epoch: 26 | Iteration number: [4230/4518] 93% | Training loss: 0.6870246654143006
Epoch: 26 | Iteration number: [4240/4518] 93% | Training loss: 0.6870255327027923
Epoch: 26 | Iteration number: [4250/4518] 94% | Training loss: 0.6870249424120959
Epoch: 26 | Iteration number: [4260/4518] 94% | Training loss: 0.6870252694042636
Epoch: 26 | Iteration number: [4270/4518] 94% | Training loss: 0.6870215334155241
Epoch: 26 | Iteration number: [4280/4518] 94% | Training loss: 0.6870217953190625
Epoch: 26 | Iteration number: [4290/4518] 94% | Training loss: 0.6870199561813772
Epoch: 26 | Iteration number: [4300/4518] 95% | Training loss: 0.6870218725121299
Epoch: 26 | Iteration number: [4310/4518] 95% | Training loss: 0.6870219525217733
Epoch: 26 | Iteration number: [4320/4518] 95% | Training loss: 0.6870237012014345
Epoch: 26 | Iteration number: [4330/4518] 95% | Training loss: 0.6870248914453229
Epoch: 26 | Iteration number: [4340/4518] 96% | Training loss: 0.6870226296137005
Epoch: 26 | Iteration number: [4350/4518] 96% | Training loss: 0.6870199260629457
Epoch: 26 | Iteration number: [4360/4518] 96% | Training loss: 0.6870194277358711
Epoch: 26 | Iteration number: [4370/4518] 96% | Training loss: 0.687019274477555
Epoch: 26 | Iteration number: [4380/4518] 96% | Training loss: 0.6870204110123795
Epoch: 26 | Iteration number: [4390/4518] 97% | Training loss: 0.6870229892415718
Epoch: 26 | Iteration number: [4400/4518] 97% | Training loss: 0.6870233732868325
Epoch: 26 | Iteration number: [4410/4518] 97% | Training loss: 0.687026997826267
Epoch: 26 | Iteration number: [4420/4518] 97% | Training loss: 0.6870268166469773
Epoch: 26 | Iteration number: [4430/4518] 98% | Training loss: 0.6870270062246387
Epoch: 26 | Iteration number: [4440/4518] 98% | Training loss: 0.6870274006380691
Epoch: 26 | Iteration number: [4450/4518] 98% | Training loss: 0.6870261895924472
Epoch: 26 | Iteration number: [4460/4518] 98% | Training loss: 0.6870259366227907
Epoch: 26 | Iteration number: [4470/4518] 98% | Training loss: 0.6870278144442795
Epoch: 26 | Iteration number: [4480/4518] 99% | Training loss: 0.6870232664580856
Epoch: 26 | Iteration number: [4490/4518] 99% | Training loss: 0.6870231420531836
Epoch: 26 | Iteration number: [4500/4518] 99% | Training loss: 0.6870227673980924
Epoch: 26 | Iteration number: [4510/4518] 99% | Training loss: 0.6870199627463939

 End of epoch: 26 | Train Loss: 0.6868688695169012 | Training Time: 632 

 End of epoch: 26 | Eval Loss: 0.6899252229807328 | Evaluating Time: 17 
Epoch: 27 | Iteration number: [10/4518] 0% | Training loss: 0.7558210074901581
Epoch: 27 | Iteration number: [20/4518] 0% | Training loss: 0.7223442643880844
Epoch: 27 | Iteration number: [30/4518] 0% | Training loss: 0.7106152753035228
Epoch: 27 | Iteration number: [40/4518] 0% | Training loss: 0.7045355215668678
Epoch: 27 | Iteration number: [50/4518] 1% | Training loss: 0.7008397281169891
Epoch: 27 | Iteration number: [60/4518] 1% | Training loss: 0.6984949270884196
Epoch: 27 | Iteration number: [70/4518] 1% | Training loss: 0.6968453364712851
Epoch: 27 | Iteration number: [80/4518] 1% | Training loss: 0.6956677906215191
Epoch: 27 | Iteration number: [90/4518] 1% | Training loss: 0.6946165091461606
Epoch: 27 | Iteration number: [100/4518] 2% | Training loss: 0.6938818734884262
Epoch: 27 | Iteration number: [110/4518] 2% | Training loss: 0.6932275512001731
Epoch: 27 | Iteration number: [120/4518] 2% | Training loss: 0.6926417713363965
Epoch: 27 | Iteration number: [130/4518] 2% | Training loss: 0.6921826000397022
Epoch: 27 | Iteration number: [140/4518] 3% | Training loss: 0.6917570705924715
Epoch: 27 | Iteration number: [150/4518] 3% | Training loss: 0.6914520271619161
Epoch: 27 | Iteration number: [160/4518] 3% | Training loss: 0.6911275923252106
Epoch: 27 | Iteration number: [170/4518] 3% | Training loss: 0.6908581600469701
Epoch: 27 | Iteration number: [180/4518] 3% | Training loss: 0.6905456629064348
Epoch: 27 | Iteration number: [190/4518] 4% | Training loss: 0.6903540987717478
Epoch: 27 | Iteration number: [200/4518] 4% | Training loss: 0.690209798514843
Epoch: 27 | Iteration number: [210/4518] 4% | Training loss: 0.689959355479195
Epoch: 27 | Iteration number: [220/4518] 4% | Training loss: 0.6898050351576371
Epoch: 27 | Iteration number: [230/4518] 5% | Training loss: 0.6896496490291927
Epoch: 27 | Iteration number: [240/4518] 5% | Training loss: 0.6895298033952713
Epoch: 27 | Iteration number: [250/4518] 5% | Training loss: 0.6894551262855529
Epoch: 27 | Iteration number: [260/4518] 5% | Training loss: 0.6893429714899797
Epoch: 27 | Iteration number: [270/4518] 5% | Training loss: 0.6892614768611061
Epoch: 27 | Iteration number: [280/4518] 6% | Training loss: 0.6892283509884561
Epoch: 27 | Iteration number: [290/4518] 6% | Training loss: 0.6891344142371211
Epoch: 27 | Iteration number: [300/4518] 6% | Training loss: 0.6890959346294403
Epoch: 27 | Iteration number: [310/4518] 6% | Training loss: 0.6890321554676179
Epoch: 27 | Iteration number: [320/4518] 7% | Training loss: 0.6889838932082057
Epoch: 27 | Iteration number: [330/4518] 7% | Training loss: 0.6889684041341145
Epoch: 27 | Iteration number: [340/4518] 7% | Training loss: 0.6888934191535501
Epoch: 27 | Iteration number: [350/4518] 7% | Training loss: 0.6888512463229043
Epoch: 27 | Iteration number: [360/4518] 7% | Training loss: 0.6888300077782736
Epoch: 27 | Iteration number: [370/4518] 8% | Training loss: 0.6887846155746563
Epoch: 27 | Iteration number: [380/4518] 8% | Training loss: 0.6887075323807565
Epoch: 27 | Iteration number: [390/4518] 8% | Training loss: 0.6886604278515547
Epoch: 27 | Iteration number: [400/4518] 8% | Training loss: 0.6885729740560055
Epoch: 27 | Iteration number: [410/4518] 9% | Training loss: 0.6885279558053831
Epoch: 27 | Iteration number: [420/4518] 9% | Training loss: 0.6884855791216805
Epoch: 27 | Iteration number: [430/4518] 9% | Training loss: 0.688444774649864
Epoch: 27 | Iteration number: [440/4518] 9% | Training loss: 0.6884158551692963
Epoch: 27 | Iteration number: [450/4518] 9% | Training loss: 0.6883972108364105
Epoch: 27 | Iteration number: [460/4518] 10% | Training loss: 0.6883488123831542
Epoch: 27 | Iteration number: [470/4518] 10% | Training loss: 0.6883225329378818
Epoch: 27 | Iteration number: [480/4518] 10% | Training loss: 0.6883074508359035
Epoch: 27 | Iteration number: [490/4518] 10% | Training loss: 0.6882970020479086
Epoch: 27 | Iteration number: [500/4518] 11% | Training loss: 0.6882658085823059
Epoch: 27 | Iteration number: [510/4518] 11% | Training loss: 0.6882529812700608
Epoch: 27 | Iteration number: [520/4518] 11% | Training loss: 0.6882509604096413
Epoch: 27 | Iteration number: [530/4518] 11% | Training loss: 0.6882296874838055
Epoch: 27 | Iteration number: [540/4518] 11% | Training loss: 0.6882180527404502
Epoch: 27 | Iteration number: [550/4518] 12% | Training loss: 0.6881862516836686
Epoch: 27 | Iteration number: [560/4518] 12% | Training loss: 0.6881493278912135
Epoch: 27 | Iteration number: [570/4518] 12% | Training loss: 0.6881298771030024
Epoch: 27 | Iteration number: [580/4518] 12% | Training loss: 0.6881135279762334
Epoch: 27 | Iteration number: [590/4518] 13% | Training loss: 0.688095197839252
Epoch: 27 | Iteration number: [600/4518] 13% | Training loss: 0.6880707496404648
Epoch: 27 | Iteration number: [610/4518] 13% | Training loss: 0.6880646099809741
Epoch: 27 | Iteration number: [620/4518] 13% | Training loss: 0.6880359935183679
Epoch: 27 | Iteration number: [630/4518] 13% | Training loss: 0.6880241568126376
Epoch: 27 | Iteration number: [640/4518] 14% | Training loss: 0.6880199618637561
Epoch: 27 | Iteration number: [650/4518] 14% | Training loss: 0.6879969141116509
Epoch: 27 | Iteration number: [660/4518] 14% | Training loss: 0.6879545548648546
Epoch: 27 | Iteration number: [670/4518] 14% | Training loss: 0.6879561345079052
Epoch: 27 | Iteration number: [680/4518] 15% | Training loss: 0.6879228785634041
Epoch: 27 | Iteration number: [690/4518] 15% | Training loss: 0.6879152012044105
Epoch: 27 | Iteration number: [700/4518] 15% | Training loss: 0.6878661048412323
Epoch: 27 | Iteration number: [710/4518] 15% | Training loss: 0.687855136478451
Epoch: 27 | Iteration number: [720/4518] 15% | Training loss: 0.6878501507971022
Epoch: 27 | Iteration number: [730/4518] 16% | Training loss: 0.6878410238925725
Epoch: 27 | Iteration number: [740/4518] 16% | Training loss: 0.6878189835999463
Epoch: 27 | Iteration number: [750/4518] 16% | Training loss: 0.6878070647716522
Epoch: 27 | Iteration number: [760/4518] 16% | Training loss: 0.6877895175626404
Epoch: 27 | Iteration number: [770/4518] 17% | Training loss: 0.6877815140532209
Epoch: 27 | Iteration number: [780/4518] 17% | Training loss: 0.6877782456385784
Epoch: 27 | Iteration number: [790/4518] 17% | Training loss: 0.6877674235573298
Epoch: 27 | Iteration number: [800/4518] 17% | Training loss: 0.6877583472430706
Epoch: 27 | Iteration number: [810/4518] 17% | Training loss: 0.6877446059827451
Epoch: 27 | Iteration number: [820/4518] 18% | Training loss: 0.6877389440449273
Epoch: 27 | Iteration number: [830/4518] 18% | Training loss: 0.6877388931900622
Epoch: 27 | Iteration number: [840/4518] 18% | Training loss: 0.687735279755933
Epoch: 27 | Iteration number: [850/4518] 18% | Training loss: 0.6877042636450599
Epoch: 27 | Iteration number: [860/4518] 19% | Training loss: 0.6876946791659954
Epoch: 27 | Iteration number: [870/4518] 19% | Training loss: 0.6877099631161525
Epoch: 27 | Iteration number: [880/4518] 19% | Training loss: 0.6877112174575979
Epoch: 27 | Iteration number: [890/4518] 19% | Training loss: 0.6876930373438289
Epoch: 27 | Iteration number: [900/4518] 19% | Training loss: 0.687692657576667
Epoch: 27 | Iteration number: [910/4518] 20% | Training loss: 0.6876887052923768
Epoch: 27 | Iteration number: [920/4518] 20% | Training loss: 0.6876686718800794
Epoch: 27 | Iteration number: [930/4518] 20% | Training loss: 0.6876433559643325
Epoch: 27 | Iteration number: [940/4518] 20% | Training loss: 0.6876239539460933
Epoch: 27 | Iteration number: [950/4518] 21% | Training loss: 0.6876332023896669
Epoch: 27 | Iteration number: [960/4518] 21% | Training loss: 0.6876145000879963
Epoch: 27 | Iteration number: [970/4518] 21% | Training loss: 0.6876009412647522
Epoch: 27 | Iteration number: [980/4518] 21% | Training loss: 0.6876067125067419
Epoch: 27 | Iteration number: [990/4518] 21% | Training loss: 0.6876005695323751
Epoch: 27 | Iteration number: [1000/4518] 22% | Training loss: 0.6875916426181793
Epoch: 27 | Iteration number: [1010/4518] 22% | Training loss: 0.6875951562187459
Epoch: 27 | Iteration number: [1020/4518] 22% | Training loss: 0.6875744492984286
Epoch: 27 | Iteration number: [1030/4518] 22% | Training loss: 0.687564212025948
Epoch: 27 | Iteration number: [1040/4518] 23% | Training loss: 0.6875550909684255
Epoch: 27 | Iteration number: [1050/4518] 23% | Training loss: 0.6875393865222023
Epoch: 27 | Iteration number: [1060/4518] 23% | Training loss: 0.6875317165874085
Epoch: 27 | Iteration number: [1070/4518] 23% | Training loss: 0.6875385960685872
Epoch: 27 | Iteration number: [1080/4518] 23% | Training loss: 0.6875274736572194
Epoch: 27 | Iteration number: [1090/4518] 24% | Training loss: 0.6875263820547577
Epoch: 27 | Iteration number: [1100/4518] 24% | Training loss: 0.6875167232751846
Epoch: 27 | Iteration number: [1110/4518] 24% | Training loss: 0.6875129770051251
Epoch: 27 | Iteration number: [1120/4518] 24% | Training loss: 0.6874927220599992
Epoch: 27 | Iteration number: [1130/4518] 25% | Training loss: 0.6875011592839672
Epoch: 27 | Iteration number: [1140/4518] 25% | Training loss: 0.6874964021277009
Epoch: 27 | Iteration number: [1150/4518] 25% | Training loss: 0.6874920792683311
Epoch: 27 | Iteration number: [1160/4518] 25% | Training loss: 0.6874834320154684
Epoch: 27 | Iteration number: [1170/4518] 25% | Training loss: 0.6874767420128879
Epoch: 27 | Iteration number: [1180/4518] 26% | Training loss: 0.6874638144747686
Epoch: 27 | Iteration number: [1190/4518] 26% | Training loss: 0.6874614284819915
Epoch: 27 | Iteration number: [1200/4518] 26% | Training loss: 0.6874540167053541
Epoch: 27 | Iteration number: [1210/4518] 26% | Training loss: 0.6874526371640607
Epoch: 27 | Iteration number: [1220/4518] 27% | Training loss: 0.6874451953856672
Epoch: 27 | Iteration number: [1230/4518] 27% | Training loss: 0.6874486648454898
Epoch: 27 | Iteration number: [1240/4518] 27% | Training loss: 0.6874330500441213
Epoch: 27 | Iteration number: [1250/4518] 27% | Training loss: 0.6874324558258057
Epoch: 27 | Iteration number: [1260/4518] 27% | Training loss: 0.6874310324589411
Epoch: 27 | Iteration number: [1270/4518] 28% | Training loss: 0.687415850631834
Epoch: 27 | Iteration number: [1280/4518] 28% | Training loss: 0.6874186180066317
Epoch: 27 | Iteration number: [1290/4518] 28% | Training loss: 0.6874193431795106
Epoch: 27 | Iteration number: [1300/4518] 28% | Training loss: 0.6874124028132512
Epoch: 27 | Iteration number: [1310/4518] 28% | Training loss: 0.6874074720699369
Epoch: 27 | Iteration number: [1320/4518] 29% | Training loss: 0.687405328317122
Epoch: 27 | Iteration number: [1330/4518] 29% | Training loss: 0.6873939490856085
Epoch: 27 | Iteration number: [1340/4518] 29% | Training loss: 0.6873900524271068
Epoch: 27 | Iteration number: [1350/4518] 29% | Training loss: 0.687385061846839
Epoch: 27 | Iteration number: [1360/4518] 30% | Training loss: 0.6873813847846845
Epoch: 27 | Iteration number: [1370/4518] 30% | Training loss: 0.6873605512354496
Epoch: 27 | Iteration number: [1380/4518] 30% | Training loss: 0.6873606158339459
Epoch: 27 | Iteration number: [1390/4518] 30% | Training loss: 0.6873496683381444
Epoch: 27 | Iteration number: [1400/4518] 30% | Training loss: 0.6873437739695821
Epoch: 27 | Iteration number: [1410/4518] 31% | Training loss: 0.6873369298082717
Epoch: 27 | Iteration number: [1420/4518] 31% | Training loss: 0.6873346625499323
Epoch: 27 | Iteration number: [1430/4518] 31% | Training loss: 0.6873312286563686
Epoch: 27 | Iteration number: [1440/4518] 31% | Training loss: 0.6873199890057246
Epoch: 27 | Iteration number: [1450/4518] 32% | Training loss: 0.6873192112199191
Epoch: 27 | Iteration number: [1460/4518] 32% | Training loss: 0.6873225077374341
Epoch: 27 | Iteration number: [1470/4518] 32% | Training loss: 0.6873175799441176
Epoch: 27 | Iteration number: [1480/4518] 32% | Training loss: 0.6873183980986879
Epoch: 27 | Iteration number: [1490/4518] 32% | Training loss: 0.6873167508400526
Epoch: 27 | Iteration number: [1500/4518] 33% | Training loss: 0.687312151948611
Epoch: 27 | Iteration number: [1510/4518] 33% | Training loss: 0.687308538473205
Epoch: 27 | Iteration number: [1520/4518] 33% | Training loss: 0.6873036129694235
Epoch: 27 | Iteration number: [1530/4518] 33% | Training loss: 0.6872978441465913
Epoch: 27 | Iteration number: [1540/4518] 34% | Training loss: 0.6873098548356589
Epoch: 27 | Iteration number: [1550/4518] 34% | Training loss: 0.6873125453533665
Epoch: 27 | Iteration number: [1560/4518] 34% | Training loss: 0.6873091293833195
Epoch: 27 | Iteration number: [1570/4518] 34% | Training loss: 0.687305209818919
Epoch: 27 | Iteration number: [1580/4518] 34% | Training loss: 0.6873018402464782
Epoch: 27 | Iteration number: [1590/4518] 35% | Training loss: 0.6872979889125944
Epoch: 27 | Iteration number: [1600/4518] 35% | Training loss: 0.6872985905408859
Epoch: 27 | Iteration number: [1610/4518] 35% | Training loss: 0.6873007792123357
Epoch: 27 | Iteration number: [1620/4518] 35% | Training loss: 0.6872887606238142
Epoch: 27 | Iteration number: [1630/4518] 36% | Training loss: 0.6872912767840309
Epoch: 27 | Iteration number: [1640/4518] 36% | Training loss: 0.6872940405476384
Epoch: 27 | Iteration number: [1650/4518] 36% | Training loss: 0.6872879709980705
Epoch: 27 | Iteration number: [1660/4518] 36% | Training loss: 0.6872900604842657
Epoch: 27 | Iteration number: [1670/4518] 36% | Training loss: 0.6872884015837115
Epoch: 27 | Iteration number: [1680/4518] 37% | Training loss: 0.6872833033402761
Epoch: 27 | Iteration number: [1690/4518] 37% | Training loss: 0.6872834147080867
Epoch: 27 | Iteration number: [1700/4518] 37% | Training loss: 0.6872747114826652
Epoch: 27 | Iteration number: [1710/4518] 37% | Training loss: 0.6872690075670767
Epoch: 27 | Iteration number: [1720/4518] 38% | Training loss: 0.6872646927487018
Epoch: 27 | Iteration number: [1730/4518] 38% | Training loss: 0.6872592198710911
Epoch: 27 | Iteration number: [1740/4518] 38% | Training loss: 0.6872600016237675
Epoch: 27 | Iteration number: [1750/4518] 38% | Training loss: 0.6872568991524832
Epoch: 27 | Iteration number: [1760/4518] 38% | Training loss: 0.6872488396411592
Epoch: 27 | Iteration number: [1770/4518] 39% | Training loss: 0.6872419990725437
Epoch: 27 | Iteration number: [1780/4518] 39% | Training loss: 0.687239280845342
Epoch: 27 | Iteration number: [1790/4518] 39% | Training loss: 0.6872397268950606
Epoch: 27 | Iteration number: [1800/4518] 39% | Training loss: 0.6872318546639549
Epoch: 27 | Iteration number: [1810/4518] 40% | Training loss: 0.687238411975829
Epoch: 27 | Iteration number: [1820/4518] 40% | Training loss: 0.6872385691482942
Epoch: 27 | Iteration number: [1830/4518] 40% | Training loss: 0.6872386057845882
Epoch: 27 | Iteration number: [1840/4518] 40% | Training loss: 0.6872342307606469
Epoch: 27 | Iteration number: [1850/4518] 40% | Training loss: 0.6872307341807598
Epoch: 27 | Iteration number: [1860/4518] 41% | Training loss: 0.6872293631235759
Epoch: 27 | Iteration number: [1870/4518] 41% | Training loss: 0.6872340338115386
Epoch: 27 | Iteration number: [1880/4518] 41% | Training loss: 0.6872352608023806
Epoch: 27 | Iteration number: [1890/4518] 41% | Training loss: 0.6872366465273357
Epoch: 27 | Iteration number: [1900/4518] 42% | Training loss: 0.6872423668911583
Epoch: 27 | Iteration number: [1910/4518] 42% | Training loss: 0.6872406395630063
Epoch: 27 | Iteration number: [1920/4518] 42% | Training loss: 0.687237216749539
Epoch: 27 | Iteration number: [1930/4518] 42% | Training loss: 0.6872364365992768
Epoch: 27 | Iteration number: [1940/4518] 42% | Training loss: 0.6872385208446955
Epoch: 27 | Iteration number: [1950/4518] 43% | Training loss: 0.687237396087402
Epoch: 27 | Iteration number: [1960/4518] 43% | Training loss: 0.6872350375871269
Epoch: 27 | Iteration number: [1970/4518] 43% | Training loss: 0.6872387122986886
Epoch: 27 | Iteration number: [1980/4518] 43% | Training loss: 0.6872345814199159
Epoch: 27 | Iteration number: [1990/4518] 44% | Training loss: 0.6872348668886789
Epoch: 27 | Iteration number: [2000/4518] 44% | Training loss: 0.6872342673838139
Epoch: 27 | Iteration number: [2010/4518] 44% | Training loss: 0.6872322858862616
Epoch: 27 | Iteration number: [2020/4518] 44% | Training loss: 0.6872328368448976
Epoch: 27 | Iteration number: [2030/4518] 44% | Training loss: 0.6872348103910831
Epoch: 27 | Iteration number: [2040/4518] 45% | Training loss: 0.6872357202219028
Epoch: 27 | Iteration number: [2050/4518] 45% | Training loss: 0.6872319807948136
Epoch: 27 | Iteration number: [2060/4518] 45% | Training loss: 0.6872320708429929
Epoch: 27 | Iteration number: [2070/4518] 45% | Training loss: 0.6872283361672203
Epoch: 27 | Iteration number: [2080/4518] 46% | Training loss: 0.6872249222145631
Epoch: 27 | Iteration number: [2090/4518] 46% | Training loss: 0.687224690223995
Epoch: 27 | Iteration number: [2100/4518] 46% | Training loss: 0.6872221536295755
Epoch: 27 | Iteration number: [2110/4518] 46% | Training loss: 0.6872186445229427
Epoch: 27 | Iteration number: [2120/4518] 46% | Training loss: 0.6872135766834583
Epoch: 27 | Iteration number: [2130/4518] 47% | Training loss: 0.687218816683326
Epoch: 27 | Iteration number: [2140/4518] 47% | Training loss: 0.6872191329425741
Epoch: 27 | Iteration number: [2150/4518] 47% | Training loss: 0.6872177722842194
Epoch: 27 | Iteration number: [2160/4518] 47% | Training loss: 0.6872106244166692
Epoch: 27 | Iteration number: [2170/4518] 48% | Training loss: 0.6872018627856734
Epoch: 27 | Iteration number: [2180/4518] 48% | Training loss: 0.6872056553670026
Epoch: 27 | Iteration number: [2190/4518] 48% | Training loss: 0.6872043068822661
Epoch: 27 | Iteration number: [2200/4518] 48% | Training loss: 0.687207517054948
Epoch: 27 | Iteration number: [2210/4518] 48% | Training loss: 0.6872062139111946
Epoch: 27 | Iteration number: [2220/4518] 49% | Training loss: 0.687202152690372
Epoch: 27 | Iteration number: [2230/4518] 49% | Training loss: 0.6872020913613751
Epoch: 27 | Iteration number: [2240/4518] 49% | Training loss: 0.6872005115928395
Epoch: 27 | Iteration number: [2250/4518] 49% | Training loss: 0.6872009719742669
Epoch: 27 | Iteration number: [2260/4518] 50% | Training loss: 0.6872005264052248
Epoch: 27 | Iteration number: [2270/4518] 50% | Training loss: 0.6871920099867598
Epoch: 27 | Iteration number: [2280/4518] 50% | Training loss: 0.6871844025034654
Epoch: 27 | Iteration number: [2290/4518] 50% | Training loss: 0.6871808982572181
Epoch: 27 | Iteration number: [2300/4518] 50% | Training loss: 0.6871780682387559
Epoch: 27 | Iteration number: [2310/4518] 51% | Training loss: 0.6871791388565328
Epoch: 27 | Iteration number: [2320/4518] 51% | Training loss: 0.6871832104592488
Epoch: 27 | Iteration number: [2330/4518] 51% | Training loss: 0.6871841575966372
Epoch: 27 | Iteration number: [2340/4518] 51% | Training loss: 0.6871871219740974
Epoch: 27 | Iteration number: [2350/4518] 52% | Training loss: 0.6871866022272313
Epoch: 27 | Iteration number: [2360/4518] 52% | Training loss: 0.6871913737412226
Epoch: 27 | Iteration number: [2370/4518] 52% | Training loss: 0.6871923414715232
Epoch: 27 | Iteration number: [2380/4518] 52% | Training loss: 0.6871956241481444
Epoch: 27 | Iteration number: [2390/4518] 52% | Training loss: 0.6871949733550579
Epoch: 27 | Iteration number: [2400/4518] 53% | Training loss: 0.6871966354300578
Epoch: 27 | Iteration number: [2410/4518] 53% | Training loss: 0.6871995666709678
Epoch: 27 | Iteration number: [2420/4518] 53% | Training loss: 0.6871925378141325
Epoch: 27 | Iteration number: [2430/4518] 53% | Training loss: 0.6871886232752858
Epoch: 27 | Iteration number: [2440/4518] 54% | Training loss: 0.6871880360802666
Epoch: 27 | Iteration number: [2450/4518] 54% | Training loss: 0.687184426419589
Epoch: 27 | Iteration number: [2460/4518] 54% | Training loss: 0.6871836261536047
Epoch: 27 | Iteration number: [2470/4518] 54% | Training loss: 0.6871846435282395
Epoch: 27 | Iteration number: [2480/4518] 54% | Training loss: 0.6871840187138126
Epoch: 27 | Iteration number: [2490/4518] 55% | Training loss: 0.6871854210713781
Epoch: 27 | Iteration number: [2500/4518] 55% | Training loss: 0.6871822252511978
Epoch: 27 | Iteration number: [2510/4518] 55% | Training loss: 0.6871833219946143
Epoch: 27 | Iteration number: [2520/4518] 55% | Training loss: 0.6871833999242102
Epoch: 27 | Iteration number: [2530/4518] 55% | Training loss: 0.6871745094009067
Epoch: 27 | Iteration number: [2540/4518] 56% | Training loss: 0.6871675723884988
Epoch: 27 | Iteration number: [2550/4518] 56% | Training loss: 0.6871602865995146
Epoch: 27 | Iteration number: [2560/4518] 56% | Training loss: 0.6871558238752187
Epoch: 27 | Iteration number: [2570/4518] 56% | Training loss: 0.6871522680330833
Epoch: 27 | Iteration number: [2580/4518] 57% | Training loss: 0.6871564512798028
Epoch: 27 | Iteration number: [2590/4518] 57% | Training loss: 0.6871555445046958
Epoch: 27 | Iteration number: [2600/4518] 57% | Training loss: 0.6871540371959026
Epoch: 27 | Iteration number: [2610/4518] 57% | Training loss: 0.6871492433136908
Epoch: 27 | Iteration number: [2620/4518] 57% | Training loss: 0.6871502438346848
Epoch: 27 | Iteration number: [2630/4518] 58% | Training loss: 0.6871482130692486
Epoch: 27 | Iteration number: [2640/4518] 58% | Training loss: 0.6871492481818705
Epoch: 27 | Iteration number: [2650/4518] 58% | Training loss: 0.6871505636764023
Epoch: 27 | Iteration number: [2660/4518] 58% | Training loss: 0.6871522180119851
Epoch: 27 | Iteration number: [2670/4518] 59% | Training loss: 0.6871501863449254
Epoch: 27 | Iteration number: [2680/4518] 59% | Training loss: 0.6871524915099144
Epoch: 27 | Iteration number: [2690/4518] 59% | Training loss: 0.6871506729090524
Epoch: 27 | Iteration number: [2700/4518] 59% | Training loss: 0.6871524954945952
Epoch: 27 | Iteration number: [2710/4518] 59% | Training loss: 0.6871529064275241
Epoch: 27 | Iteration number: [2720/4518] 60% | Training loss: 0.6871515442781588
Epoch: 27 | Iteration number: [2730/4518] 60% | Training loss: 0.6871538162013113
Epoch: 27 | Iteration number: [2740/4518] 60% | Training loss: 0.687151578351529
Epoch: 27 | Iteration number: [2750/4518] 60% | Training loss: 0.6871470221606167
Epoch: 27 | Iteration number: [2760/4518] 61% | Training loss: 0.6871479504998179
Epoch: 27 | Iteration number: [2770/4518] 61% | Training loss: 0.6871424092712816
Epoch: 27 | Iteration number: [2780/4518] 61% | Training loss: 0.6871471072701242
Epoch: 27 | Iteration number: [2790/4518] 61% | Training loss: 0.6871430736075166
Epoch: 27 | Iteration number: [2800/4518] 61% | Training loss: 0.6871405322424003
Epoch: 27 | Iteration number: [2810/4518] 62% | Training loss: 0.6871420710536509
Epoch: 27 | Iteration number: [2820/4518] 62% | Training loss: 0.6871435550299096
Epoch: 27 | Iteration number: [2830/4518] 62% | Training loss: 0.6871412880218493
Epoch: 27 | Iteration number: [2840/4518] 62% | Training loss: 0.6871399702740387
Epoch: 27 | Iteration number: [2850/4518] 63% | Training loss: 0.6871348633682519
Epoch: 27 | Iteration number: [2860/4518] 63% | Training loss: 0.6871343302976834
Epoch: 27 | Iteration number: [2870/4518] 63% | Training loss: 0.6871390303460563
Epoch: 27 | Iteration number: [2880/4518] 63% | Training loss: 0.6871369399958187
Epoch: 27 | Iteration number: [2890/4518] 63% | Training loss: 0.6871367177336274
Epoch: 27 | Iteration number: [2900/4518] 64% | Training loss: 0.6871356252349656
Epoch: 27 | Iteration number: [2910/4518] 64% | Training loss: 0.687135132952654
Epoch: 27 | Iteration number: [2920/4518] 64% | Training loss: 0.687135647094413
Epoch: 27 | Iteration number: [2930/4518] 64% | Training loss: 0.6871309637616518
Epoch: 27 | Iteration number: [2940/4518] 65% | Training loss: 0.6871252824660061
Epoch: 27 | Iteration number: [2950/4518] 65% | Training loss: 0.6871270197326854
Epoch: 27 | Iteration number: [2960/4518] 65% | Training loss: 0.6871279682259301
Epoch: 27 | Iteration number: [2970/4518] 65% | Training loss: 0.6871280932065212
Epoch: 27 | Iteration number: [2980/4518] 65% | Training loss: 0.6871321293731664
Epoch: 27 | Iteration number: [2990/4518] 66% | Training loss: 0.6871342375924356
Epoch: 27 | Iteration number: [3000/4518] 66% | Training loss: 0.6871297507683436
Epoch: 27 | Iteration number: [3010/4518] 66% | Training loss: 0.6871252579348428
Epoch: 27 | Iteration number: [3020/4518] 66% | Training loss: 0.6871214165198093
Epoch: 27 | Iteration number: [3030/4518] 67% | Training loss: 0.6871198798366899
Epoch: 27 | Iteration number: [3040/4518] 67% | Training loss: 0.6871196326456572
Epoch: 27 | Iteration number: [3050/4518] 67% | Training loss: 0.6871168970280006
Epoch: 27 | Iteration number: [3060/4518] 67% | Training loss: 0.6871160494735817
Epoch: 27 | Iteration number: [3070/4518] 67% | Training loss: 0.6871130157565449
Epoch: 27 | Iteration number: [3080/4518] 68% | Training loss: 0.6871085219375499
Epoch: 27 | Iteration number: [3090/4518] 68% | Training loss: 0.6871048169807323
Epoch: 27 | Iteration number: [3100/4518] 68% | Training loss: 0.6870989853143692
Epoch: 27 | Iteration number: [3110/4518] 68% | Training loss: 0.6870961740852553
Epoch: 27 | Iteration number: [3120/4518] 69% | Training loss: 0.6870974468115049
Epoch: 27 | Iteration number: [3130/4518] 69% | Training loss: 0.68709613753203
Epoch: 27 | Iteration number: [3140/4518] 69% | Training loss: 0.6870950346349911
Epoch: 27 | Iteration number: [3150/4518] 69% | Training loss: 0.6870924410555098
Epoch: 27 | Iteration number: [3160/4518] 69% | Training loss: 0.6870901432784298
Epoch: 27 | Iteration number: [3170/4518] 70% | Training loss: 0.687088936736531
Epoch: 27 | Iteration number: [3180/4518] 70% | Training loss: 0.6870878687257287
Epoch: 27 | Iteration number: [3190/4518] 70% | Training loss: 0.6870907137573325
Epoch: 27 | Iteration number: [3200/4518] 70% | Training loss: 0.6870878730528056
Epoch: 27 | Iteration number: [3210/4518] 71% | Training loss: 0.6870868885814215
Epoch: 27 | Iteration number: [3220/4518] 71% | Training loss: 0.6870789071787958
Epoch: 27 | Iteration number: [3230/4518] 71% | Training loss: 0.6870743586552033
Epoch: 27 | Iteration number: [3240/4518] 71% | Training loss: 0.6870746579803066
Epoch: 27 | Iteration number: [3250/4518] 71% | Training loss: 0.6870710562192477
Epoch: 27 | Iteration number: [3260/4518] 72% | Training loss: 0.6870683230688236
Epoch: 27 | Iteration number: [3270/4518] 72% | Training loss: 0.6870670980087479
Epoch: 27 | Iteration number: [3280/4518] 72% | Training loss: 0.687062168630158
Epoch: 27 | Iteration number: [3290/4518] 72% | Training loss: 0.6870619056434979
Epoch: 27 | Iteration number: [3300/4518] 73% | Training loss: 0.6870622037938147
Epoch: 27 | Iteration number: [3310/4518] 73% | Training loss: 0.6870606483109408
Epoch: 27 | Iteration number: [3320/4518] 73% | Training loss: 0.6870608483093331
Epoch: 27 | Iteration number: [3330/4518] 73% | Training loss: 0.6870558263124288
Epoch: 27 | Iteration number: [3340/4518] 73% | Training loss: 0.6870597834715586
Epoch: 27 | Iteration number: [3350/4518] 74% | Training loss: 0.6870579599800395
Epoch: 27 | Iteration number: [3360/4518] 74% | Training loss: 0.6870593653903121
Epoch: 27 | Iteration number: [3370/4518] 74% | Training loss: 0.6870615817672775
Epoch: 27 | Iteration number: [3380/4518] 74% | Training loss: 0.6870616606530353
Epoch: 27 | Iteration number: [3390/4518] 75% | Training loss: 0.6870593797492418
Epoch: 27 | Iteration number: [3400/4518] 75% | Training loss: 0.6870579476566876
Epoch: 27 | Iteration number: [3410/4518] 75% | Training loss: 0.6870561815077258
Epoch: 27 | Iteration number: [3420/4518] 75% | Training loss: 0.687053169318807
Epoch: 27 | Iteration number: [3430/4518] 75% | Training loss: 0.6870524967898433
Epoch: 27 | Iteration number: [3440/4518] 76% | Training loss: 0.6870569834528968
Epoch: 27 | Iteration number: [3450/4518] 76% | Training loss: 0.6870548612484033
Epoch: 27 | Iteration number: [3460/4518] 76% | Training loss: 0.6870551373228172
Epoch: 27 | Iteration number: [3470/4518] 76% | Training loss: 0.6870568301904442
Epoch: 27 | Iteration number: [3480/4518] 77% | Training loss: 0.6870586913036204
Epoch: 27 | Iteration number: [3490/4518] 77% | Training loss: 0.6870574715144313
Epoch: 27 | Iteration number: [3500/4518] 77% | Training loss: 0.6870589141334806
Epoch: 27 | Iteration number: [3510/4518] 77% | Training loss: 0.6870567440477192
Epoch: 27 | Iteration number: [3520/4518] 77% | Training loss: 0.6870554653081027
Epoch: 27 | Iteration number: [3530/4518] 78% | Training loss: 0.687049914605219
Epoch: 27 | Iteration number: [3540/4518] 78% | Training loss: 0.6870464463186803
Epoch: 27 | Iteration number: [3550/4518] 78% | Training loss: 0.6870456083727554
Epoch: 27 | Iteration number: [3560/4518] 78% | Training loss: 0.68704707563928
Epoch: 27 | Iteration number: [3570/4518] 79% | Training loss: 0.687044284607516
Epoch: 27 | Iteration number: [3580/4518] 79% | Training loss: 0.6870427375232707
Epoch: 27 | Iteration number: [3590/4518] 79% | Training loss: 0.6870435110373749
Epoch: 27 | Iteration number: [3600/4518] 79% | Training loss: 0.6870475708113777
Epoch: 27 | Iteration number: [3610/4518] 79% | Training loss: 0.6870476752106833
Epoch: 27 | Iteration number: [3620/4518] 80% | Training loss: 0.687044872977457
Epoch: 27 | Iteration number: [3630/4518] 80% | Training loss: 0.687045435127148
Epoch: 27 | Iteration number: [3640/4518] 80% | Training loss: 0.6870475242262358
Epoch: 27 | Iteration number: [3650/4518] 80% | Training loss: 0.6870461777464985
Epoch: 27 | Iteration number: [3660/4518] 81% | Training loss: 0.6870440656044444
Epoch: 27 | Iteration number: [3670/4518] 81% | Training loss: 0.6870438361687621
Epoch: 27 | Iteration number: [3680/4518] 81% | Training loss: 0.6870444397077612
Epoch: 27 | Iteration number: [3690/4518] 81% | Training loss: 0.6870402760621978
Epoch: 27 | Iteration number: [3700/4518] 81% | Training loss: 0.6870380564638087
Epoch: 27 | Iteration number: [3710/4518] 82% | Training loss: 0.6870364932358426
Epoch: 27 | Iteration number: [3720/4518] 82% | Training loss: 0.6870359867650976
Epoch: 27 | Iteration number: [3730/4518] 82% | Training loss: 0.6870386114388944
Epoch: 27 | Iteration number: [3740/4518] 82% | Training loss: 0.6870386886246064
Epoch: 27 | Iteration number: [3750/4518] 83% | Training loss: 0.6870417157649994
Epoch: 27 | Iteration number: [3760/4518] 83% | Training loss: 0.6870425976178748
Epoch: 27 | Iteration number: [3770/4518] 83% | Training loss: 0.6870403291217845
Epoch: 27 | Iteration number: [3780/4518] 83% | Training loss: 0.6870398061143027
Epoch: 27 | Iteration number: [3790/4518] 83% | Training loss: 0.6870407527543624
Epoch: 27 | Iteration number: [3800/4518] 84% | Training loss: 0.687040448596603
Epoch: 27 | Iteration number: [3810/4518] 84% | Training loss: 0.6870404247067419
Epoch: 27 | Iteration number: [3820/4518] 84% | Training loss: 0.6870409448265405
Epoch: 27 | Iteration number: [3830/4518] 84% | Training loss: 0.6870437285140663
Epoch: 27 | Iteration number: [3840/4518] 84% | Training loss: 0.6870455681967239
Epoch: 27 | Iteration number: [3850/4518] 85% | Training loss: 0.6870445883274079
Epoch: 27 | Iteration number: [3860/4518] 85% | Training loss: 0.6870463788663785
Epoch: 27 | Iteration number: [3870/4518] 85% | Training loss: 0.6870448808491384
Epoch: 27 | Iteration number: [3880/4518] 85% | Training loss: 0.6870462401165176
Epoch: 27 | Iteration number: [3890/4518] 86% | Training loss: 0.6870445958139964
Epoch: 27 | Iteration number: [3900/4518] 86% | Training loss: 0.6870471582198754
Epoch: 27 | Iteration number: [3910/4518] 86% | Training loss: 0.6870468507947215
Epoch: 27 | Iteration number: [3920/4518] 86% | Training loss: 0.6870484010449478
Epoch: 27 | Iteration number: [3930/4518] 86% | Training loss: 0.6870490601044574
Epoch: 27 | Iteration number: [3940/4518] 87% | Training loss: 0.6870487274554781
Epoch: 27 | Iteration number: [3950/4518] 87% | Training loss: 0.6870477566085285
Epoch: 27 | Iteration number: [3960/4518] 87% | Training loss: 0.6870415880523547
Epoch: 27 | Iteration number: [3970/4518] 87% | Training loss: 0.6870399264904954
Epoch: 27 | Iteration number: [3980/4518] 88% | Training loss: 0.6870333997598246
Epoch: 27 | Iteration number: [3990/4518] 88% | Training loss: 0.6870319226182493
Epoch: 27 | Iteration number: [4000/4518] 88% | Training loss: 0.6870301174372435
Epoch: 27 | Iteration number: [4010/4518] 88% | Training loss: 0.6870288994544165
Epoch: 27 | Iteration number: [4020/4518] 88% | Training loss: 0.6870289192863958
Epoch: 27 | Iteration number: [4030/4518] 89% | Training loss: 0.687027053841882
Epoch: 27 | Iteration number: [4040/4518] 89% | Training loss: 0.687023404211101
Epoch: 27 | Iteration number: [4050/4518] 89% | Training loss: 0.687022647931252
Epoch: 27 | Iteration number: [4060/4518] 89% | Training loss: 0.6870197608846749
Epoch: 27 | Iteration number: [4070/4518] 90% | Training loss: 0.6870230925317479
Epoch: 27 | Iteration number: [4080/4518] 90% | Training loss: 0.6870217013300634
Epoch: 27 | Iteration number: [4090/4518] 90% | Training loss: 0.6870200248539885
Epoch: 27 | Iteration number: [4100/4518] 90% | Training loss: 0.687020228069003
Epoch: 27 | Iteration number: [4110/4518] 90% | Training loss: 0.6870182943605159
Epoch: 27 | Iteration number: [4120/4518] 91% | Training loss: 0.6870184593987696
Epoch: 27 | Iteration number: [4130/4518] 91% | Training loss: 0.6870203413484172
Epoch: 27 | Iteration number: [4140/4518] 91% | Training loss: 0.6870185002180689
Epoch: 27 | Iteration number: [4150/4518] 91% | Training loss: 0.6870219332769693
Epoch: 27 | Iteration number: [4160/4518] 92% | Training loss: 0.6870255434885622
Epoch: 27 | Iteration number: [4170/4518] 92% | Training loss: 0.6870254190705662
Epoch: 27 | Iteration number: [4180/4518] 92% | Training loss: 0.6870234553893787
Epoch: 27 | Iteration number: [4190/4518] 92% | Training loss: 0.6870252836433401
Epoch: 27 | Iteration number: [4200/4518] 92% | Training loss: 0.6870262055879548
Epoch: 27 | Iteration number: [4210/4518] 93% | Training loss: 0.6870276881934911
Epoch: 27 | Iteration number: [4220/4518] 93% | Training loss: 0.6870316745404383
Epoch: 27 | Iteration number: [4230/4518] 93% | Training loss: 0.6870324114676627
Epoch: 27 | Iteration number: [4240/4518] 93% | Training loss: 0.6870322193739549
Epoch: 27 | Iteration number: [4250/4518] 94% | Training loss: 0.6870298472853268
Epoch: 27 | Iteration number: [4260/4518] 94% | Training loss: 0.6870286121474745
Epoch: 27 | Iteration number: [4270/4518] 94% | Training loss: 0.6870301708125398
Epoch: 27 | Iteration number: [4280/4518] 94% | Training loss: 0.6870325872413466
Epoch: 27 | Iteration number: [4290/4518] 94% | Training loss: 0.6870318257864261
Epoch: 27 | Iteration number: [4300/4518] 95% | Training loss: 0.6870335029862648
Epoch: 27 | Iteration number: [4310/4518] 95% | Training loss: 0.6870336504380831
Epoch: 27 | Iteration number: [4320/4518] 95% | Training loss: 0.6870349633748885
Epoch: 27 | Iteration number: [4330/4518] 95% | Training loss: 0.6870350109236896
Epoch: 27 | Iteration number: [4340/4518] 96% | Training loss: 0.6870330232766366
Epoch: 27 | Iteration number: [4350/4518] 96% | Training loss: 0.6870294189590147
Epoch: 27 | Iteration number: [4360/4518] 96% | Training loss: 0.6870312624841655
Epoch: 27 | Iteration number: [4370/4518] 96% | Training loss: 0.6870331062468565
Epoch: 27 | Iteration number: [4380/4518] 96% | Training loss: 0.6870316928924491
Epoch: 27 | Iteration number: [4390/4518] 97% | Training loss: 0.6870327477438847
Epoch: 27 | Iteration number: [4400/4518] 97% | Training loss: 0.6870338656821035
Epoch: 27 | Iteration number: [4410/4518] 97% | Training loss: 0.6870335159658575
Epoch: 27 | Iteration number: [4420/4518] 97% | Training loss: 0.6870340815631513
Epoch: 27 | Iteration number: [4430/4518] 98% | Training loss: 0.6870327518702092
Epoch: 27 | Iteration number: [4440/4518] 98% | Training loss: 0.6870303737016411
Epoch: 27 | Iteration number: [4450/4518] 98% | Training loss: 0.6870287449976031
Epoch: 27 | Iteration number: [4460/4518] 98% | Training loss: 0.6870276306509437
Epoch: 27 | Iteration number: [4470/4518] 98% | Training loss: 0.6870280609034852
Epoch: 27 | Iteration number: [4480/4518] 99% | Training loss: 0.6870268758120281
Epoch: 27 | Iteration number: [4490/4518] 99% | Training loss: 0.6870248441972286
Epoch: 27 | Iteration number: [4500/4518] 99% | Training loss: 0.6870242433945338
Epoch: 27 | Iteration number: [4510/4518] 99% | Training loss: 0.687020875926557

 End of epoch: 27 | Train Loss: 0.6868704164803899 | Training Time: 632 

 End of epoch: 27 | Eval Loss: 0.6899208414311312 | Evaluating Time: 17 
Epoch: 28 | Iteration number: [10/4518] 0% | Training loss: 0.7553579568862915
Epoch: 28 | Iteration number: [20/4518] 0% | Training loss: 0.7210033029317856
Epoch: 28 | Iteration number: [30/4518] 0% | Training loss: 0.709731795390447
Epoch: 28 | Iteration number: [40/4518] 0% | Training loss: 0.7041654288768768
Epoch: 28 | Iteration number: [50/4518] 1% | Training loss: 0.7006807780265808
Epoch: 28 | Iteration number: [60/4518] 1% | Training loss: 0.6983982563018799
Epoch: 28 | Iteration number: [70/4518] 1% | Training loss: 0.6967328216348375
Epoch: 28 | Iteration number: [80/4518] 1% | Training loss: 0.6954183667898178
Epoch: 28 | Iteration number: [90/4518] 1% | Training loss: 0.6945627239015367
Epoch: 28 | Iteration number: [100/4518] 2% | Training loss: 0.6937299263477326
Epoch: 28 | Iteration number: [110/4518] 2% | Training loss: 0.6931546005335721
Epoch: 28 | Iteration number: [120/4518] 2% | Training loss: 0.6926345840096474
Epoch: 28 | Iteration number: [130/4518] 2% | Training loss: 0.692192335312183
Epoch: 28 | Iteration number: [140/4518] 3% | Training loss: 0.6918085349457604
Epoch: 28 | Iteration number: [150/4518] 3% | Training loss: 0.6915089698632558
Epoch: 28 | Iteration number: [160/4518] 3% | Training loss: 0.6912153892219066
Epoch: 28 | Iteration number: [170/4518] 3% | Training loss: 0.6910409601295695
Epoch: 28 | Iteration number: [180/4518] 3% | Training loss: 0.6907983524931802
Epoch: 28 | Iteration number: [190/4518] 4% | Training loss: 0.6905862067875109
Epoch: 28 | Iteration number: [200/4518] 4% | Training loss: 0.6904283952713013
Epoch: 28 | Iteration number: [210/4518] 4% | Training loss: 0.6903195804073697
Epoch: 28 | Iteration number: [220/4518] 4% | Training loss: 0.6901236748153513
Epoch: 28 | Iteration number: [230/4518] 5% | Training loss: 0.6899831595628158
Epoch: 28 | Iteration number: [240/4518] 5% | Training loss: 0.6898612519105275
Epoch: 28 | Iteration number: [250/4518] 5% | Training loss: 0.689750504732132
Epoch: 28 | Iteration number: [260/4518] 5% | Training loss: 0.6896683692932128
Epoch: 28 | Iteration number: [270/4518] 5% | Training loss: 0.6895758675204383
Epoch: 28 | Iteration number: [280/4518] 6% | Training loss: 0.6894958587629455
Epoch: 28 | Iteration number: [290/4518] 6% | Training loss: 0.6894044654122714
Epoch: 28 | Iteration number: [300/4518] 6% | Training loss: 0.6892960214614868
Epoch: 28 | Iteration number: [310/4518] 6% | Training loss: 0.6891800007512493
Epoch: 28 | Iteration number: [320/4518] 7% | Training loss: 0.6891045838594436
Epoch: 28 | Iteration number: [330/4518] 7% | Training loss: 0.6890392574397001
Epoch: 28 | Iteration number: [340/4518] 7% | Training loss: 0.68898224392358
Epoch: 28 | Iteration number: [350/4518] 7% | Training loss: 0.6889491600649698
Epoch: 28 | Iteration number: [360/4518] 7% | Training loss: 0.6888424514068497
Epoch: 28 | Iteration number: [370/4518] 8% | Training loss: 0.6887929911549027
Epoch: 28 | Iteration number: [380/4518] 8% | Training loss: 0.6887505961091895
Epoch: 28 | Iteration number: [390/4518] 8% | Training loss: 0.6886775588377928
Epoch: 28 | Iteration number: [400/4518] 8% | Training loss: 0.688625295907259
Epoch: 28 | Iteration number: [410/4518] 9% | Training loss: 0.6885842423613479
Epoch: 28 | Iteration number: [420/4518] 9% | Training loss: 0.6885355374642781
Epoch: 28 | Iteration number: [430/4518] 9% | Training loss: 0.688473866152209
Epoch: 28 | Iteration number: [440/4518] 9% | Training loss: 0.6884644076228141
Epoch: 28 | Iteration number: [450/4518] 9% | Training loss: 0.6884348290496403
Epoch: 28 | Iteration number: [460/4518] 10% | Training loss: 0.6883755029543587
Epoch: 28 | Iteration number: [470/4518] 10% | Training loss: 0.6883104396627304
Epoch: 28 | Iteration number: [480/4518] 10% | Training loss: 0.6883041276286046
Epoch: 28 | Iteration number: [490/4518] 10% | Training loss: 0.6882895108388395
Epoch: 28 | Iteration number: [500/4518] 11% | Training loss: 0.6882514029741287
Epoch: 28 | Iteration number: [510/4518] 11% | Training loss: 0.6882026734305363
Epoch: 28 | Iteration number: [520/4518] 11% | Training loss: 0.6881876984467873
Epoch: 28 | Iteration number: [530/4518] 11% | Training loss: 0.68815985985522
Epoch: 28 | Iteration number: [540/4518] 11% | Training loss: 0.6881344858143065
Epoch: 28 | Iteration number: [550/4518] 12% | Training loss: 0.6880941135233098
Epoch: 28 | Iteration number: [560/4518] 12% | Training loss: 0.6880919460739409
Epoch: 28 | Iteration number: [570/4518] 12% | Training loss: 0.6880693967927967
Epoch: 28 | Iteration number: [580/4518] 12% | Training loss: 0.6880364127200226
Epoch: 28 | Iteration number: [590/4518] 13% | Training loss: 0.6880052173541764
Epoch: 28 | Iteration number: [600/4518] 13% | Training loss: 0.6879786734779676
Epoch: 28 | Iteration number: [610/4518] 13% | Training loss: 0.6879325618509387
Epoch: 28 | Iteration number: [620/4518] 13% | Training loss: 0.6879164824562688
Epoch: 28 | Iteration number: [630/4518] 13% | Training loss: 0.6878815312234182
Epoch: 28 | Iteration number: [640/4518] 14% | Training loss: 0.6878718932159245
Epoch: 28 | Iteration number: [650/4518] 14% | Training loss: 0.6878812387356391
Epoch: 28 | Iteration number: [660/4518] 14% | Training loss: 0.6878496791377212
Epoch: 28 | Iteration number: [670/4518] 14% | Training loss: 0.6878187346814284
Epoch: 28 | Iteration number: [680/4518] 15% | Training loss: 0.6877994283157236
Epoch: 28 | Iteration number: [690/4518] 15% | Training loss: 0.6877807294976884
Epoch: 28 | Iteration number: [700/4518] 15% | Training loss: 0.6877731747286661
Epoch: 28 | Iteration number: [710/4518] 15% | Training loss: 0.6877714871520727
Epoch: 28 | Iteration number: [720/4518] 15% | Training loss: 0.687762108279599
Epoch: 28 | Iteration number: [730/4518] 16% | Training loss: 0.6877697747047633
Epoch: 28 | Iteration number: [740/4518] 16% | Training loss: 0.687764349177077
Epoch: 28 | Iteration number: [750/4518] 16% | Training loss: 0.6877595578034719
Epoch: 28 | Iteration number: [760/4518] 16% | Training loss: 0.6877483502814644
Epoch: 28 | Iteration number: [770/4518] 17% | Training loss: 0.6877320536545345
Epoch: 28 | Iteration number: [780/4518] 17% | Training loss: 0.6877276716323999
Epoch: 28 | Iteration number: [790/4518] 17% | Training loss: 0.6877180121367491
Epoch: 28 | Iteration number: [800/4518] 17% | Training loss: 0.6877137607336045
Epoch: 28 | Iteration number: [810/4518] 17% | Training loss: 0.6877022437107416
Epoch: 28 | Iteration number: [820/4518] 18% | Training loss: 0.6876984516294992
Epoch: 28 | Iteration number: [830/4518] 18% | Training loss: 0.6876853694398719
Epoch: 28 | Iteration number: [840/4518] 18% | Training loss: 0.6876684029187475
Epoch: 28 | Iteration number: [850/4518] 18% | Training loss: 0.6876815314853892
Epoch: 28 | Iteration number: [860/4518] 19% | Training loss: 0.6876666784286499
Epoch: 28 | Iteration number: [870/4518] 19% | Training loss: 0.6876678812092748
Epoch: 28 | Iteration number: [880/4518] 19% | Training loss: 0.6876686358316378
Epoch: 28 | Iteration number: [890/4518] 19% | Training loss: 0.6876598303907373
Epoch: 28 | Iteration number: [900/4518] 19% | Training loss: 0.6876584419276979
Epoch: 28 | Iteration number: [910/4518] 20% | Training loss: 0.6876536615602262
Epoch: 28 | Iteration number: [920/4518] 20% | Training loss: 0.6876461742364842
Epoch: 28 | Iteration number: [930/4518] 20% | Training loss: 0.6876469007743302
Epoch: 28 | Iteration number: [940/4518] 20% | Training loss: 0.6876310077753472
Epoch: 28 | Iteration number: [950/4518] 21% | Training loss: 0.6876274434516304
Epoch: 28 | Iteration number: [960/4518] 21% | Training loss: 0.6876150431111455
Epoch: 28 | Iteration number: [970/4518] 21% | Training loss: 0.6875999073392337
Epoch: 28 | Iteration number: [980/4518] 21% | Training loss: 0.687599485504384
Epoch: 28 | Iteration number: [990/4518] 21% | Training loss: 0.6875918625581144
Epoch: 28 | Iteration number: [1000/4518] 22% | Training loss: 0.6875972271561622
Epoch: 28 | Iteration number: [1010/4518] 22% | Training loss: 0.6875855129544097
Epoch: 28 | Iteration number: [1020/4518] 22% | Training loss: 0.6875983342236164
Epoch: 28 | Iteration number: [1030/4518] 22% | Training loss: 0.6875925674021822
Epoch: 28 | Iteration number: [1040/4518] 23% | Training loss: 0.6875957977886383
Epoch: 28 | Iteration number: [1050/4518] 23% | Training loss: 0.6875894056047712
Epoch: 28 | Iteration number: [1060/4518] 23% | Training loss: 0.6875696608480417
Epoch: 28 | Iteration number: [1070/4518] 23% | Training loss: 0.6875669869307046
Epoch: 28 | Iteration number: [1080/4518] 23% | Training loss: 0.6875650038873707
Epoch: 28 | Iteration number: [1090/4518] 24% | Training loss: 0.6875466051998489
Epoch: 28 | Iteration number: [1100/4518] 24% | Training loss: 0.6875359973040494
Epoch: 28 | Iteration number: [1110/4518] 24% | Training loss: 0.6875356300994082
Epoch: 28 | Iteration number: [1120/4518] 24% | Training loss: 0.6875353284712349
Epoch: 28 | Iteration number: [1130/4518] 25% | Training loss: 0.6875329819400754
Epoch: 28 | Iteration number: [1140/4518] 25% | Training loss: 0.6875237590388248
Epoch: 28 | Iteration number: [1150/4518] 25% | Training loss: 0.6875075843023217
Epoch: 28 | Iteration number: [1160/4518] 25% | Training loss: 0.6875090735739675
Epoch: 28 | Iteration number: [1170/4518] 25% | Training loss: 0.6875045884368766
Epoch: 28 | Iteration number: [1180/4518] 26% | Training loss: 0.6874925716953763
Epoch: 28 | Iteration number: [1190/4518] 26% | Training loss: 0.6874841120563635
Epoch: 28 | Iteration number: [1200/4518] 26% | Training loss: 0.6874830051759879
Epoch: 28 | Iteration number: [1210/4518] 26% | Training loss: 0.6874674827106728
Epoch: 28 | Iteration number: [1220/4518] 27% | Training loss: 0.687454876889948
Epoch: 28 | Iteration number: [1230/4518] 27% | Training loss: 0.6874663289000348
Epoch: 28 | Iteration number: [1240/4518] 27% | Training loss: 0.6874533043753717
Epoch: 28 | Iteration number: [1250/4518] 27% | Training loss: 0.6874500265598297
Epoch: 28 | Iteration number: [1260/4518] 27% | Training loss: 0.6874442403278653
Epoch: 28 | Iteration number: [1270/4518] 28% | Training loss: 0.6874334483634769
Epoch: 28 | Iteration number: [1280/4518] 28% | Training loss: 0.6874123480636627
Epoch: 28 | Iteration number: [1290/4518] 28% | Training loss: 0.6874031878256983
Epoch: 28 | Iteration number: [1300/4518] 28% | Training loss: 0.6873926427731147
Epoch: 28 | Iteration number: [1310/4518] 28% | Training loss: 0.6873898614453905
Epoch: 28 | Iteration number: [1320/4518] 29% | Training loss: 0.6873866469571085
Epoch: 28 | Iteration number: [1330/4518] 29% | Training loss: 0.6873857560462522
Epoch: 28 | Iteration number: [1340/4518] 29% | Training loss: 0.6873808693529955
Epoch: 28 | Iteration number: [1350/4518] 29% | Training loss: 0.6873847843541039
Epoch: 28 | Iteration number: [1360/4518] 30% | Training loss: 0.6873873744379072
Epoch: 28 | Iteration number: [1370/4518] 30% | Training loss: 0.6873882584763269
Epoch: 28 | Iteration number: [1380/4518] 30% | Training loss: 0.6873814883871355
Epoch: 28 | Iteration number: [1390/4518] 30% | Training loss: 0.6873778771582267
Epoch: 28 | Iteration number: [1400/4518] 30% | Training loss: 0.6873725653971945
Epoch: 28 | Iteration number: [1410/4518] 31% | Training loss: 0.6873714317666724
Epoch: 28 | Iteration number: [1420/4518] 31% | Training loss: 0.6873762481649157
Epoch: 28 | Iteration number: [1430/4518] 31% | Training loss: 0.6873734521282303
Epoch: 28 | Iteration number: [1440/4518] 31% | Training loss: 0.6873783902161651
Epoch: 28 | Iteration number: [1450/4518] 32% | Training loss: 0.6873721122330633
Epoch: 28 | Iteration number: [1460/4518] 32% | Training loss: 0.6873589318500806
Epoch: 28 | Iteration number: [1470/4518] 32% | Training loss: 0.6873397557102904
Epoch: 28 | Iteration number: [1480/4518] 32% | Training loss: 0.6873446423056964
Epoch: 28 | Iteration number: [1490/4518] 32% | Training loss: 0.6873433167502384
Epoch: 28 | Iteration number: [1500/4518] 33% | Training loss: 0.6873428732951482
Epoch: 28 | Iteration number: [1510/4518] 33% | Training loss: 0.687341574880461
Epoch: 28 | Iteration number: [1520/4518] 33% | Training loss: 0.6873398369864414
Epoch: 28 | Iteration number: [1530/4518] 33% | Training loss: 0.6873410935884987
Epoch: 28 | Iteration number: [1540/4518] 34% | Training loss: 0.6873274555841049
Epoch: 28 | Iteration number: [1550/4518] 34% | Training loss: 0.6873245098898487
Epoch: 28 | Iteration number: [1560/4518] 34% | Training loss: 0.6873190808754701
Epoch: 28 | Iteration number: [1570/4518] 34% | Training loss: 0.6873196465574253
Epoch: 28 | Iteration number: [1580/4518] 34% | Training loss: 0.6873198071235342
Epoch: 28 | Iteration number: [1590/4518] 35% | Training loss: 0.6873196911137059
Epoch: 28 | Iteration number: [1600/4518] 35% | Training loss: 0.6873260719329118
Epoch: 28 | Iteration number: [1610/4518] 35% | Training loss: 0.6873168519935252
Epoch: 28 | Iteration number: [1620/4518] 35% | Training loss: 0.6873188516975921
Epoch: 28 | Iteration number: [1630/4518] 36% | Training loss: 0.6873189693945317
Epoch: 28 | Iteration number: [1640/4518] 36% | Training loss: 0.6873154157545508
Epoch: 28 | Iteration number: [1650/4518] 36% | Training loss: 0.6873164976004398
Epoch: 28 | Iteration number: [1660/4518] 36% | Training loss: 0.6873108608895038
Epoch: 28 | Iteration number: [1670/4518] 36% | Training loss: 0.6873078125679565
Epoch: 28 | Iteration number: [1680/4518] 37% | Training loss: 0.6873047909211545
Epoch: 28 | Iteration number: [1690/4518] 37% | Training loss: 0.6872998072903537
Epoch: 28 | Iteration number: [1700/4518] 37% | Training loss: 0.6872862990463481
Epoch: 28 | Iteration number: [1710/4518] 37% | Training loss: 0.6872833463532185
Epoch: 28 | Iteration number: [1720/4518] 38% | Training loss: 0.6872813246277876
Epoch: 28 | Iteration number: [1730/4518] 38% | Training loss: 0.6872786729322004
Epoch: 28 | Iteration number: [1740/4518] 38% | Training loss: 0.687278600259759
Epoch: 28 | Iteration number: [1750/4518] 38% | Training loss: 0.687280589239938
Epoch: 28 | Iteration number: [1760/4518] 38% | Training loss: 0.6872768377038565
Epoch: 28 | Iteration number: [1770/4518] 39% | Training loss: 0.6872778833922694
Epoch: 28 | Iteration number: [1780/4518] 39% | Training loss: 0.687272541442614
Epoch: 28 | Iteration number: [1790/4518] 39% | Training loss: 0.6872718881628367
Epoch: 28 | Iteration number: [1800/4518] 39% | Training loss: 0.6872664836049079
Epoch: 28 | Iteration number: [1810/4518] 40% | Training loss: 0.6872666990559404
Epoch: 28 | Iteration number: [1820/4518] 40% | Training loss: 0.6872604983193534
Epoch: 28 | Iteration number: [1830/4518] 40% | Training loss: 0.6872578704292005
Epoch: 28 | Iteration number: [1840/4518] 40% | Training loss: 0.6872594194567722
Epoch: 28 | Iteration number: [1850/4518] 40% | Training loss: 0.6872656537068856
Epoch: 28 | Iteration number: [1860/4518] 41% | Training loss: 0.6872626079987454
Epoch: 28 | Iteration number: [1870/4518] 41% | Training loss: 0.687252934253152
Epoch: 28 | Iteration number: [1880/4518] 41% | Training loss: 0.6872494289532621
Epoch: 28 | Iteration number: [1890/4518] 41% | Training loss: 0.6872502936572625
Epoch: 28 | Iteration number: [1900/4518] 42% | Training loss: 0.6872533760259026
Epoch: 28 | Iteration number: [1910/4518] 42% | Training loss: 0.6872559416668578
Epoch: 28 | Iteration number: [1920/4518] 42% | Training loss: 0.6872555040133496
Epoch: 28 | Iteration number: [1930/4518] 42% | Training loss: 0.687249917996362
Epoch: 28 | Iteration number: [1940/4518] 42% | Training loss: 0.6872468367679831
Epoch: 28 | Iteration number: [1950/4518] 43% | Training loss: 0.6872388189266889
Epoch: 28 | Iteration number: [1960/4518] 43% | Training loss: 0.6872357585904549
Epoch: 28 | Iteration number: [1970/4518] 43% | Training loss: 0.687234472744356
Epoch: 28 | Iteration number: [1980/4518] 43% | Training loss: 0.6872309084793534
Epoch: 28 | Iteration number: [1990/4518] 44% | Training loss: 0.68723125721342
Epoch: 28 | Iteration number: [2000/4518] 44% | Training loss: 0.6872325052917003
Epoch: 28 | Iteration number: [2010/4518] 44% | Training loss: 0.6872288520063334
Epoch: 28 | Iteration number: [2020/4518] 44% | Training loss: 0.6872281106686828
Epoch: 28 | Iteration number: [2030/4518] 44% | Training loss: 0.6872260192932167
Epoch: 28 | Iteration number: [2040/4518] 45% | Training loss: 0.6872244589176832
Epoch: 28 | Iteration number: [2050/4518] 45% | Training loss: 0.6872202722037711
Epoch: 28 | Iteration number: [2060/4518] 45% | Training loss: 0.6872138342521723
Epoch: 28 | Iteration number: [2070/4518] 45% | Training loss: 0.6872140237098731
Epoch: 28 | Iteration number: [2080/4518] 46% | Training loss: 0.6872165160970046
Epoch: 28 | Iteration number: [2090/4518] 46% | Training loss: 0.6872188677342885
Epoch: 28 | Iteration number: [2100/4518] 46% | Training loss: 0.6872174484673
Epoch: 28 | Iteration number: [2110/4518] 46% | Training loss: 0.6872115478413929
Epoch: 28 | Iteration number: [2120/4518] 46% | Training loss: 0.687210073729731
Epoch: 28 | Iteration number: [2130/4518] 47% | Training loss: 0.6872117951722212
Epoch: 28 | Iteration number: [2140/4518] 47% | Training loss: 0.6872068168403946
Epoch: 28 | Iteration number: [2150/4518] 47% | Training loss: 0.6872044042099353
Epoch: 28 | Iteration number: [2160/4518] 47% | Training loss: 0.6871994845569134
Epoch: 28 | Iteration number: [2170/4518] 48% | Training loss: 0.687197506153089
Epoch: 28 | Iteration number: [2180/4518] 48% | Training loss: 0.6871942710439
Epoch: 28 | Iteration number: [2190/4518] 48% | Training loss: 0.6871842153540485
Epoch: 28 | Iteration number: [2200/4518] 48% | Training loss: 0.6871744890646501
Epoch: 28 | Iteration number: [2210/4518] 48% | Training loss: 0.687172689049492
Epoch: 28 | Iteration number: [2220/4518] 49% | Training loss: 0.6871705294192374
Epoch: 28 | Iteration number: [2230/4518] 49% | Training loss: 0.6871723614733315
Epoch: 28 | Iteration number: [2240/4518] 49% | Training loss: 0.6871646629380328
Epoch: 28 | Iteration number: [2250/4518] 49% | Training loss: 0.6871619713836246
Epoch: 28 | Iteration number: [2260/4518] 50% | Training loss: 0.6871614291340904
Epoch: 28 | Iteration number: [2270/4518] 50% | Training loss: 0.6871681266944314
Epoch: 28 | Iteration number: [2280/4518] 50% | Training loss: 0.6871703090113506
Epoch: 28 | Iteration number: [2290/4518] 50% | Training loss: 0.6871716879080477
Epoch: 28 | Iteration number: [2300/4518] 50% | Training loss: 0.6871718580308168
Epoch: 28 | Iteration number: [2310/4518] 51% | Training loss: 0.6871696438882258
Epoch: 28 | Iteration number: [2320/4518] 51% | Training loss: 0.6871684823827496
Epoch: 28 | Iteration number: [2330/4518] 51% | Training loss: 0.6871655108591006
Epoch: 28 | Iteration number: [2340/4518] 51% | Training loss: 0.6871685969778615
Epoch: 28 | Iteration number: [2350/4518] 52% | Training loss: 0.687161445998131
Epoch: 28 | Iteration number: [2360/4518] 52% | Training loss: 0.6871608351499348
Epoch: 28 | Iteration number: [2370/4518] 52% | Training loss: 0.6871586501095366
Epoch: 28 | Iteration number: [2380/4518] 52% | Training loss: 0.687155831586413
Epoch: 28 | Iteration number: [2390/4518] 52% | Training loss: 0.687152666352284
Epoch: 28 | Iteration number: [2400/4518] 53% | Training loss: 0.6871504787604014
Epoch: 28 | Iteration number: [2410/4518] 53% | Training loss: 0.6871478200700768
Epoch: 28 | Iteration number: [2420/4518] 53% | Training loss: 0.6871493339045974
Epoch: 28 | Iteration number: [2430/4518] 53% | Training loss: 0.6871508741575013
Epoch: 28 | Iteration number: [2440/4518] 54% | Training loss: 0.6871523614056775
Epoch: 28 | Iteration number: [2450/4518] 54% | Training loss: 0.6871485052789961
Epoch: 28 | Iteration number: [2460/4518] 54% | Training loss: 0.6871469114369493
Epoch: 28 | Iteration number: [2470/4518] 54% | Training loss: 0.687142287574799
Epoch: 28 | Iteration number: [2480/4518] 54% | Training loss: 0.6871415835955451
Epoch: 28 | Iteration number: [2490/4518] 55% | Training loss: 0.687141537594508
Epoch: 28 | Iteration number: [2500/4518] 55% | Training loss: 0.6871386508703232
Epoch: 28 | Iteration number: [2510/4518] 55% | Training loss: 0.6871372533509456
Epoch: 28 | Iteration number: [2520/4518] 55% | Training loss: 0.6871391304192089
Epoch: 28 | Iteration number: [2530/4518] 55% | Training loss: 0.6871370214718604
Epoch: 28 | Iteration number: [2540/4518] 56% | Training loss: 0.6871351892788579
Epoch: 28 | Iteration number: [2550/4518] 56% | Training loss: 0.6871300745010376
Epoch: 28 | Iteration number: [2560/4518] 56% | Training loss: 0.6871300326427445
Epoch: 28 | Iteration number: [2570/4518] 56% | Training loss: 0.6871306382960383
Epoch: 28 | Iteration number: [2580/4518] 57% | Training loss: 0.6871303426202877
Epoch: 28 | Iteration number: [2590/4518] 57% | Training loss: 0.6871264292236461
Epoch: 28 | Iteration number: [2600/4518] 57% | Training loss: 0.6871255006698461
Epoch: 28 | Iteration number: [2610/4518] 57% | Training loss: 0.6871216192784437
Epoch: 28 | Iteration number: [2620/4518] 57% | Training loss: 0.6871212264053694
Epoch: 28 | Iteration number: [2630/4518] 58% | Training loss: 0.6871207029647247
Epoch: 28 | Iteration number: [2640/4518] 58% | Training loss: 0.6871216158975254
Epoch: 28 | Iteration number: [2650/4518] 58% | Training loss: 0.6871210515274192
Epoch: 28 | Iteration number: [2660/4518] 58% | Training loss: 0.68712303380769
Epoch: 28 | Iteration number: [2670/4518] 59% | Training loss: 0.6871211814523189
Epoch: 28 | Iteration number: [2680/4518] 59% | Training loss: 0.6871220760603449
Epoch: 28 | Iteration number: [2690/4518] 59% | Training loss: 0.6871236666427669
Epoch: 28 | Iteration number: [2700/4518] 59% | Training loss: 0.687119482755661
Epoch: 28 | Iteration number: [2710/4518] 59% | Training loss: 0.6871149648379575
Epoch: 28 | Iteration number: [2720/4518] 60% | Training loss: 0.6871167231570272
Epoch: 28 | Iteration number: [2730/4518] 60% | Training loss: 0.6871159810504633
Epoch: 28 | Iteration number: [2740/4518] 60% | Training loss: 0.6871064344461817
Epoch: 28 | Iteration number: [2750/4518] 60% | Training loss: 0.6871065216064454
Epoch: 28 | Iteration number: [2760/4518] 61% | Training loss: 0.6871077980036321
Epoch: 28 | Iteration number: [2770/4518] 61% | Training loss: 0.6871054740804197
Epoch: 28 | Iteration number: [2780/4518] 61% | Training loss: 0.6871041696920669
Epoch: 28 | Iteration number: [2790/4518] 61% | Training loss: 0.6870988333737978
Epoch: 28 | Iteration number: [2800/4518] 61% | Training loss: 0.687099227649825
Epoch: 28 | Iteration number: [2810/4518] 62% | Training loss: 0.6870954876692694
Epoch: 28 | Iteration number: [2820/4518] 62% | Training loss: 0.6870989311671426
Epoch: 28 | Iteration number: [2830/4518] 62% | Training loss: 0.687095278038153
Epoch: 28 | Iteration number: [2840/4518] 62% | Training loss: 0.6870935449297999
Epoch: 28 | Iteration number: [2850/4518] 63% | Training loss: 0.6870953129258072
Epoch: 28 | Iteration number: [2860/4518] 63% | Training loss: 0.6870960074913252
Epoch: 28 | Iteration number: [2870/4518] 63% | Training loss: 0.6870937416154749
Epoch: 28 | Iteration number: [2880/4518] 63% | Training loss: 0.6870928378982677
Epoch: 28 | Iteration number: [2890/4518] 63% | Training loss: 0.6870956223522503
Epoch: 28 | Iteration number: [2900/4518] 64% | Training loss: 0.6870940845588158
Epoch: 28 | Iteration number: [2910/4518] 64% | Training loss: 0.6870921844674139
Epoch: 28 | Iteration number: [2920/4518] 64% | Training loss: 0.6870932528213279
Epoch: 28 | Iteration number: [2930/4518] 64% | Training loss: 0.687092565859544
Epoch: 28 | Iteration number: [2940/4518] 65% | Training loss: 0.6870926696832488
Epoch: 28 | Iteration number: [2950/4518] 65% | Training loss: 0.6870972963106834
Epoch: 28 | Iteration number: [2960/4518] 65% | Training loss: 0.6870988912679054
Epoch: 28 | Iteration number: [2970/4518] 65% | Training loss: 0.6870997026311829
Epoch: 28 | Iteration number: [2980/4518] 65% | Training loss: 0.687093541546156
Epoch: 28 | Iteration number: [2990/4518] 66% | Training loss: 0.6870929223438569
Epoch: 28 | Iteration number: [3000/4518] 66% | Training loss: 0.6870928618907929
Epoch: 28 | Iteration number: [3010/4518] 66% | Training loss: 0.6870969753724792
Epoch: 28 | Iteration number: [3020/4518] 66% | Training loss: 0.6870978404749308
Epoch: 28 | Iteration number: [3030/4518] 67% | Training loss: 0.6870973822897417
Epoch: 28 | Iteration number: [3040/4518] 67% | Training loss: 0.6870953520661907
Epoch: 28 | Iteration number: [3050/4518] 67% | Training loss: 0.6870945524192247
Epoch: 28 | Iteration number: [3060/4518] 67% | Training loss: 0.6870947730307485
Epoch: 28 | Iteration number: [3070/4518] 67% | Training loss: 0.687095860083639
Epoch: 28 | Iteration number: [3080/4518] 68% | Training loss: 0.6870966477053506
Epoch: 28 | Iteration number: [3090/4518] 68% | Training loss: 0.6870921475794709
Epoch: 28 | Iteration number: [3100/4518] 68% | Training loss: 0.6870941971002087
Epoch: 28 | Iteration number: [3110/4518] 68% | Training loss: 0.6870916702356369
Epoch: 28 | Iteration number: [3120/4518] 69% | Training loss: 0.6870938778687746
Epoch: 28 | Iteration number: [3130/4518] 69% | Training loss: 0.6870967661610807
Epoch: 28 | Iteration number: [3140/4518] 69% | Training loss: 0.6870955857122021
Epoch: 28 | Iteration number: [3150/4518] 69% | Training loss: 0.6870930901784745
Epoch: 28 | Iteration number: [3160/4518] 69% | Training loss: 0.6870960640567767
Epoch: 28 | Iteration number: [3170/4518] 70% | Training loss: 0.6870960797797242
Epoch: 28 | Iteration number: [3180/4518] 70% | Training loss: 0.6870913720543279
Epoch: 28 | Iteration number: [3190/4518] 70% | Training loss: 0.6870908276974969
Epoch: 28 | Iteration number: [3200/4518] 70% | Training loss: 0.6870890231058001
Epoch: 28 | Iteration number: [3210/4518] 71% | Training loss: 0.6870920061693756
Epoch: 28 | Iteration number: [3220/4518] 71% | Training loss: 0.6870949514163948
Epoch: 28 | Iteration number: [3230/4518] 71% | Training loss: 0.687092345436291
Epoch: 28 | Iteration number: [3240/4518] 71% | Training loss: 0.6870899240175883
Epoch: 28 | Iteration number: [3250/4518] 71% | Training loss: 0.6870912030843588
Epoch: 28 | Iteration number: [3260/4518] 72% | Training loss: 0.6870854557474698
Epoch: 28 | Iteration number: [3270/4518] 72% | Training loss: 0.6870829118136601
Epoch: 28 | Iteration number: [3280/4518] 72% | Training loss: 0.6870859659663061
Epoch: 28 | Iteration number: [3290/4518] 72% | Training loss: 0.687081700291677
Epoch: 28 | Iteration number: [3300/4518] 73% | Training loss: 0.6870798935492833
Epoch: 28 | Iteration number: [3310/4518] 73% | Training loss: 0.6870783858969133
Epoch: 28 | Iteration number: [3320/4518] 73% | Training loss: 0.6870787784457206
Epoch: 28 | Iteration number: [3330/4518] 73% | Training loss: 0.6870757989876263
Epoch: 28 | Iteration number: [3340/4518] 73% | Training loss: 0.6870746109300031
Epoch: 28 | Iteration number: [3350/4518] 74% | Training loss: 0.6870763899497132
Epoch: 28 | Iteration number: [3360/4518] 74% | Training loss: 0.6870795117247672
Epoch: 28 | Iteration number: [3370/4518] 74% | Training loss: 0.6870792467799314
Epoch: 28 | Iteration number: [3380/4518] 74% | Training loss: 0.6870832125639774
Epoch: 28 | Iteration number: [3390/4518] 75% | Training loss: 0.6870785279963221
Epoch: 28 | Iteration number: [3400/4518] 75% | Training loss: 0.6870758011411218
Epoch: 28 | Iteration number: [3410/4518] 75% | Training loss: 0.6870741831592101
Epoch: 28 | Iteration number: [3420/4518] 75% | Training loss: 0.6870749092590042
Epoch: 28 | Iteration number: [3430/4518] 75% | Training loss: 0.6870751578501988
Epoch: 28 | Iteration number: [3440/4518] 76% | Training loss: 0.6870749834145224
Epoch: 28 | Iteration number: [3450/4518] 76% | Training loss: 0.6870747446841088
Epoch: 28 | Iteration number: [3460/4518] 76% | Training loss: 0.6870731871941186
Epoch: 28 | Iteration number: [3470/4518] 76% | Training loss: 0.6870730255625777
Epoch: 28 | Iteration number: [3480/4518] 77% | Training loss: 0.6870709152228531
Epoch: 28 | Iteration number: [3490/4518] 77% | Training loss: 0.6870702330567434
Epoch: 28 | Iteration number: [3500/4518] 77% | Training loss: 0.687066346849714
Epoch: 28 | Iteration number: [3510/4518] 77% | Training loss: 0.6870648088788035
Epoch: 28 | Iteration number: [3520/4518] 77% | Training loss: 0.6870660918680105
Epoch: 28 | Iteration number: [3530/4518] 78% | Training loss: 0.6870620781909305
Epoch: 28 | Iteration number: [3540/4518] 78% | Training loss: 0.6870643238900072
Epoch: 28 | Iteration number: [3550/4518] 78% | Training loss: 0.6870646344775885
Epoch: 28 | Iteration number: [3560/4518] 78% | Training loss: 0.6870637174067872
Epoch: 28 | Iteration number: [3570/4518] 79% | Training loss: 0.6870659487755025
Epoch: 28 | Iteration number: [3580/4518] 79% | Training loss: 0.6870655844497947
Epoch: 28 | Iteration number: [3590/4518] 79% | Training loss: 0.6870628865814474
Epoch: 28 | Iteration number: [3600/4518] 79% | Training loss: 0.6870583735075262
Epoch: 28 | Iteration number: [3610/4518] 79% | Training loss: 0.687063399857101
Epoch: 28 | Iteration number: [3620/4518] 80% | Training loss: 0.6870628944747356
Epoch: 28 | Iteration number: [3630/4518] 80% | Training loss: 0.6870650471734606
Epoch: 28 | Iteration number: [3640/4518] 80% | Training loss: 0.687060518186171
Epoch: 28 | Iteration number: [3650/4518] 80% | Training loss: 0.6870602391190724
Epoch: 28 | Iteration number: [3660/4518] 81% | Training loss: 0.6870528810988359
Epoch: 28 | Iteration number: [3670/4518] 81% | Training loss: 0.6870525542007155
Epoch: 28 | Iteration number: [3680/4518] 81% | Training loss: 0.6870517842957508
Epoch: 28 | Iteration number: [3690/4518] 81% | Training loss: 0.687048854818189
Epoch: 28 | Iteration number: [3700/4518] 81% | Training loss: 0.6870476203351408
Epoch: 28 | Iteration number: [3710/4518] 82% | Training loss: 0.6870499539086118
Epoch: 28 | Iteration number: [3720/4518] 82% | Training loss: 0.6870495889616269
Epoch: 28 | Iteration number: [3730/4518] 82% | Training loss: 0.6870485078873008
Epoch: 28 | Iteration number: [3740/4518] 82% | Training loss: 0.6870460460689616
Epoch: 28 | Iteration number: [3750/4518] 83% | Training loss: 0.687045422188441
Epoch: 28 | Iteration number: [3760/4518] 83% | Training loss: 0.6870455178967182
Epoch: 28 | Iteration number: [3770/4518] 83% | Training loss: 0.6870427337976602
Epoch: 28 | Iteration number: [3780/4518] 83% | Training loss: 0.6870425304250112
Epoch: 28 | Iteration number: [3790/4518] 83% | Training loss: 0.687041057508665
Epoch: 28 | Iteration number: [3800/4518] 84% | Training loss: 0.6870431141476883
Epoch: 28 | Iteration number: [3810/4518] 84% | Training loss: 0.6870415884052987
Epoch: 28 | Iteration number: [3820/4518] 84% | Training loss: 0.6870403076653705
Epoch: 28 | Iteration number: [3830/4518] 84% | Training loss: 0.6870387776557833
Epoch: 28 | Iteration number: [3840/4518] 84% | Training loss: 0.6870367891155184
Epoch: 28 | Iteration number: [3850/4518] 85% | Training loss: 0.687037426047511
Epoch: 28 | Iteration number: [3860/4518] 85% | Training loss: 0.6870362056506113
Epoch: 28 | Iteration number: [3870/4518] 85% | Training loss: 0.6870335040782465
Epoch: 28 | Iteration number: [3880/4518] 85% | Training loss: 0.6870330047054389
Epoch: 28 | Iteration number: [3890/4518] 86% | Training loss: 0.6870311272328188
Epoch: 28 | Iteration number: [3900/4518] 86% | Training loss: 0.6870297009975482
Epoch: 28 | Iteration number: [3910/4518] 86% | Training loss: 0.6870263127567213
Epoch: 28 | Iteration number: [3920/4518] 86% | Training loss: 0.6870217130804549
Epoch: 28 | Iteration number: [3930/4518] 86% | Training loss: 0.687019424538576
Epoch: 28 | Iteration number: [3940/4518] 87% | Training loss: 0.6870196730503576
Epoch: 28 | Iteration number: [3950/4518] 87% | Training loss: 0.6870190155355236
Epoch: 28 | Iteration number: [3960/4518] 87% | Training loss: 0.6870193368708244
Epoch: 28 | Iteration number: [3970/4518] 87% | Training loss: 0.6870178549956315
Epoch: 28 | Iteration number: [3980/4518] 88% | Training loss: 0.6870196880407669
Epoch: 28 | Iteration number: [3990/4518] 88% | Training loss: 0.6870225843032799
Epoch: 28 | Iteration number: [4000/4518] 88% | Training loss: 0.687020945429802
Epoch: 28 | Iteration number: [4010/4518] 88% | Training loss: 0.6870190311994339
Epoch: 28 | Iteration number: [4020/4518] 88% | Training loss: 0.6870180880104131
Epoch: 28 | Iteration number: [4030/4518] 89% | Training loss: 0.6870181034131914
Epoch: 28 | Iteration number: [4040/4518] 89% | Training loss: 0.6870158736953641
Epoch: 28 | Iteration number: [4050/4518] 89% | Training loss: 0.6870147464304794
Epoch: 28 | Iteration number: [4060/4518] 89% | Training loss: 0.6870142977813195
Epoch: 28 | Iteration number: [4070/4518] 90% | Training loss: 0.6870115346785552
Epoch: 28 | Iteration number: [4080/4518] 90% | Training loss: 0.6870107383412474
Epoch: 28 | Iteration number: [4090/4518] 90% | Training loss: 0.6870114278531017
Epoch: 28 | Iteration number: [4100/4518] 90% | Training loss: 0.6870096429092128
Epoch: 28 | Iteration number: [4110/4518] 90% | Training loss: 0.6870109655271192
Epoch: 28 | Iteration number: [4120/4518] 91% | Training loss: 0.687012135635302
Epoch: 28 | Iteration number: [4130/4518] 91% | Training loss: 0.6870134790786531
Epoch: 28 | Iteration number: [4140/4518] 91% | Training loss: 0.6870126640883045
Epoch: 28 | Iteration number: [4150/4518] 91% | Training loss: 0.6870127537882472
Epoch: 28 | Iteration number: [4160/4518] 92% | Training loss: 0.6870112623446263
Epoch: 28 | Iteration number: [4170/4518] 92% | Training loss: 0.6870137524404686
Epoch: 28 | Iteration number: [4180/4518] 92% | Training loss: 0.687012901346079
Epoch: 28 | Iteration number: [4190/4518] 92% | Training loss: 0.6870114755089926
Epoch: 28 | Iteration number: [4200/4518] 92% | Training loss: 0.6870131189198722
Epoch: 28 | Iteration number: [4210/4518] 93% | Training loss: 0.6870131239471979
Epoch: 28 | Iteration number: [4220/4518] 93% | Training loss: 0.6870132278209614
Epoch: 28 | Iteration number: [4230/4518] 93% | Training loss: 0.6870144193758637
Epoch: 28 | Iteration number: [4240/4518] 93% | Training loss: 0.6870168303965397
Epoch: 28 | Iteration number: [4250/4518] 94% | Training loss: 0.6870197839035708
Epoch: 28 | Iteration number: [4260/4518] 94% | Training loss: 0.6870221958473814
Epoch: 28 | Iteration number: [4270/4518] 94% | Training loss: 0.6870225589643876
Epoch: 28 | Iteration number: [4280/4518] 94% | Training loss: 0.6870214371341411
Epoch: 28 | Iteration number: [4290/4518] 94% | Training loss: 0.6870179953691843
Epoch: 28 | Iteration number: [4300/4518] 95% | Training loss: 0.6870176283564678
Epoch: 28 | Iteration number: [4310/4518] 95% | Training loss: 0.6870170237846551
Epoch: 28 | Iteration number: [4320/4518] 95% | Training loss: 0.6870174285714273
Epoch: 28 | Iteration number: [4330/4518] 95% | Training loss: 0.687016944480548
Epoch: 28 | Iteration number: [4340/4518] 96% | Training loss: 0.6870163006579272
Epoch: 28 | Iteration number: [4350/4518] 96% | Training loss: 0.6870160941968019
Epoch: 28 | Iteration number: [4360/4518] 96% | Training loss: 0.6870142059588651
Epoch: 28 | Iteration number: [4370/4518] 96% | Training loss: 0.6870143580354869
Epoch: 28 | Iteration number: [4380/4518] 96% | Training loss: 0.6870107896251766
Epoch: 28 | Iteration number: [4390/4518] 97% | Training loss: 0.6870087839883661
Epoch: 28 | Iteration number: [4400/4518] 97% | Training loss: 0.6870087968896735
Epoch: 28 | Iteration number: [4410/4518] 97% | Training loss: 0.6870078146727988
Epoch: 28 | Iteration number: [4420/4518] 97% | Training loss: 0.6870088178782442
Epoch: 28 | Iteration number: [4430/4518] 98% | Training loss: 0.6870093075470246
Epoch: 28 | Iteration number: [4440/4518] 98% | Training loss: 0.6870093402159106
Epoch: 28 | Iteration number: [4450/4518] 98% | Training loss: 0.6870076805688022
Epoch: 28 | Iteration number: [4460/4518] 98% | Training loss: 0.6870097122919399
Epoch: 28 | Iteration number: [4470/4518] 98% | Training loss: 0.6870079368686249
Epoch: 28 | Iteration number: [4480/4518] 99% | Training loss: 0.6870074123410242
Epoch: 28 | Iteration number: [4490/4518] 99% | Training loss: 0.6870108758420881
Epoch: 28 | Iteration number: [4500/4518] 99% | Training loss: 0.6870117458634907
Epoch: 28 | Iteration number: [4510/4518] 99% | Training loss: 0.687012629458751

 End of epoch: 28 | Train Loss: 0.686861396798944 | Training Time: 633 

 End of epoch: 28 | Eval Loss: 0.6899278212566765 | Evaluating Time: 17 
Epoch: 29 | Iteration number: [10/4518] 0% | Training loss: 0.7554470896720886
Epoch: 29 | Iteration number: [20/4518] 0% | Training loss: 0.7212193846702576
Epoch: 29 | Iteration number: [30/4518] 0% | Training loss: 0.7096783320109049
Epoch: 29 | Iteration number: [40/4518] 0% | Training loss: 0.7032924607396126
Epoch: 29 | Iteration number: [50/4518] 1% | Training loss: 0.6999633920192718
Epoch: 29 | Iteration number: [60/4518] 1% | Training loss: 0.6976810584465662
Epoch: 29 | Iteration number: [70/4518] 1% | Training loss: 0.6961608035223824
Epoch: 29 | Iteration number: [80/4518] 1% | Training loss: 0.6952861458063125
Epoch: 29 | Iteration number: [90/4518] 1% | Training loss: 0.69443721903695
Epoch: 29 | Iteration number: [100/4518] 2% | Training loss: 0.6937292098999024
Epoch: 29 | Iteration number: [110/4518] 2% | Training loss: 0.6932378064502369
Epoch: 29 | Iteration number: [120/4518] 2% | Training loss: 0.692754153907299
Epoch: 29 | Iteration number: [130/4518] 2% | Training loss: 0.6923439007539015
Epoch: 29 | Iteration number: [140/4518] 3% | Training loss: 0.6920058203595025
Epoch: 29 | Iteration number: [150/4518] 3% | Training loss: 0.6917118096351623
Epoch: 29 | Iteration number: [160/4518] 3% | Training loss: 0.6914100244641304
Epoch: 29 | Iteration number: [170/4518] 3% | Training loss: 0.6910511458621306
Epoch: 29 | Iteration number: [180/4518] 3% | Training loss: 0.6908710055881077
Epoch: 29 | Iteration number: [190/4518] 4% | Training loss: 0.6907475091909108
Epoch: 29 | Iteration number: [200/4518] 4% | Training loss: 0.6905887240171432
Epoch: 29 | Iteration number: [210/4518] 4% | Training loss: 0.6903952521937234
Epoch: 29 | Iteration number: [220/4518] 4% | Training loss: 0.6901956490494988
Epoch: 29 | Iteration number: [230/4518] 5% | Training loss: 0.6900886872540349
Epoch: 29 | Iteration number: [240/4518] 5% | Training loss: 0.6899441291888555
Epoch: 29 | Iteration number: [250/4518] 5% | Training loss: 0.689835816860199
Epoch: 29 | Iteration number: [260/4518] 5% | Training loss: 0.6896622249713311
Epoch: 29 | Iteration number: [270/4518] 5% | Training loss: 0.6895125400137019
Epoch: 29 | Iteration number: [280/4518] 6% | Training loss: 0.6894429085510118
Epoch: 29 | Iteration number: [290/4518] 6% | Training loss: 0.6893898559027705
Epoch: 29 | Iteration number: [300/4518] 6% | Training loss: 0.6893432287375132
Epoch: 29 | Iteration number: [310/4518] 6% | Training loss: 0.6892783426469372
Epoch: 29 | Iteration number: [320/4518] 7% | Training loss: 0.6891744829714298
Epoch: 29 | Iteration number: [330/4518] 7% | Training loss: 0.6891190839536262
Epoch: 29 | Iteration number: [340/4518] 7% | Training loss: 0.6890425880165661
Epoch: 29 | Iteration number: [350/4518] 7% | Training loss: 0.6890152420316423
Epoch: 29 | Iteration number: [360/4518] 7% | Training loss: 0.688905680179596
Epoch: 29 | Iteration number: [370/4518] 8% | Training loss: 0.6888278616441262
Epoch: 29 | Iteration number: [380/4518] 8% | Training loss: 0.6887670661273756
Epoch: 29 | Iteration number: [390/4518] 8% | Training loss: 0.6887170073313591
Epoch: 29 | Iteration number: [400/4518] 8% | Training loss: 0.6887002328038215
Epoch: 29 | Iteration number: [410/4518] 9% | Training loss: 0.6886519905997486
Epoch: 29 | Iteration number: [420/4518] 9% | Training loss: 0.6886136834110532
Epoch: 29 | Iteration number: [430/4518] 9% | Training loss: 0.6885819045610206
Epoch: 29 | Iteration number: [440/4518] 9% | Training loss: 0.6885430894114755
Epoch: 29 | Iteration number: [450/4518] 9% | Training loss: 0.6885010886192322
Epoch: 29 | Iteration number: [460/4518] 10% | Training loss: 0.6884663625903752
Epoch: 29 | Iteration number: [470/4518] 10% | Training loss: 0.6884485126809871
Epoch: 29 | Iteration number: [480/4518] 10% | Training loss: 0.6884092134733995
Epoch: 29 | Iteration number: [490/4518] 10% | Training loss: 0.6883919343656423
Epoch: 29 | Iteration number: [500/4518] 11% | Training loss: 0.6883739272356033
Epoch: 29 | Iteration number: [510/4518] 11% | Training loss: 0.6883193603917664
Epoch: 29 | Iteration number: [520/4518] 11% | Training loss: 0.6882953553245618
Epoch: 29 | Iteration number: [530/4518] 11% | Training loss: 0.6882969457023549
Epoch: 29 | Iteration number: [540/4518] 11% | Training loss: 0.6882410285649476
Epoch: 29 | Iteration number: [550/4518] 12% | Training loss: 0.6882144880294799
Epoch: 29 | Iteration number: [560/4518] 12% | Training loss: 0.6881767845579556
Epoch: 29 | Iteration number: [570/4518] 12% | Training loss: 0.6881529657464278
Epoch: 29 | Iteration number: [580/4518] 12% | Training loss: 0.6881232583317264
Epoch: 29 | Iteration number: [590/4518] 13% | Training loss: 0.688089523679119
Epoch: 29 | Iteration number: [600/4518] 13% | Training loss: 0.6880515382687251
Epoch: 29 | Iteration number: [610/4518] 13% | Training loss: 0.6880254934068586
Epoch: 29 | Iteration number: [620/4518] 13% | Training loss: 0.6880079285752388
Epoch: 29 | Iteration number: [630/4518] 13% | Training loss: 0.6879921041783832
Epoch: 29 | Iteration number: [640/4518] 14% | Training loss: 0.6879829679615795
Epoch: 29 | Iteration number: [650/4518] 14% | Training loss: 0.6879651171427507
Epoch: 29 | Iteration number: [660/4518] 14% | Training loss: 0.6879508780710625
Epoch: 29 | Iteration number: [670/4518] 14% | Training loss: 0.6879422209156093
Epoch: 29 | Iteration number: [680/4518] 15% | Training loss: 0.6879398876253296
Epoch: 29 | Iteration number: [690/4518] 15% | Training loss: 0.6879275670949964
Epoch: 29 | Iteration number: [700/4518] 15% | Training loss: 0.6879067796468735
Epoch: 29 | Iteration number: [710/4518] 15% | Training loss: 0.6879063183153179
Epoch: 29 | Iteration number: [720/4518] 15% | Training loss: 0.6878759950399399
Epoch: 29 | Iteration number: [730/4518] 16% | Training loss: 0.6878607098370382
Epoch: 29 | Iteration number: [740/4518] 16% | Training loss: 0.6878535021801253
Epoch: 29 | Iteration number: [750/4518] 16% | Training loss: 0.6878354844252268
Epoch: 29 | Iteration number: [760/4518] 16% | Training loss: 0.6878133974577251
Epoch: 29 | Iteration number: [770/4518] 17% | Training loss: 0.6877722348485674
Epoch: 29 | Iteration number: [780/4518] 17% | Training loss: 0.6877614867992891
Epoch: 29 | Iteration number: [790/4518] 17% | Training loss: 0.687759352258489
Epoch: 29 | Iteration number: [800/4518] 17% | Training loss: 0.6877554236352443
Epoch: 29 | Iteration number: [810/4518] 17% | Training loss: 0.6877443658716884
Epoch: 29 | Iteration number: [820/4518] 18% | Training loss: 0.6877490433250986
Epoch: 29 | Iteration number: [830/4518] 18% | Training loss: 0.6877291920673416
Epoch: 29 | Iteration number: [840/4518] 18% | Training loss: 0.6877180217277437
Epoch: 29 | Iteration number: [850/4518] 18% | Training loss: 0.6877053977461423
Epoch: 29 | Iteration number: [860/4518] 19% | Training loss: 0.6877035944960838
Epoch: 29 | Iteration number: [870/4518] 19% | Training loss: 0.6876979370226806
Epoch: 29 | Iteration number: [880/4518] 19% | Training loss: 0.6876826078376986
Epoch: 29 | Iteration number: [890/4518] 19% | Training loss: 0.6876777348223697
Epoch: 29 | Iteration number: [900/4518] 19% | Training loss: 0.6876832311020957
Epoch: 29 | Iteration number: [910/4518] 20% | Training loss: 0.6876729437283107
Epoch: 29 | Iteration number: [920/4518] 20% | Training loss: 0.6876564378323762
Epoch: 29 | Iteration number: [930/4518] 20% | Training loss: 0.6876444302579408
Epoch: 29 | Iteration number: [940/4518] 20% | Training loss: 0.6876304826203813
Epoch: 29 | Iteration number: [950/4518] 21% | Training loss: 0.6876251883883225
Epoch: 29 | Iteration number: [960/4518] 21% | Training loss: 0.6876157270744443
Epoch: 29 | Iteration number: [970/4518] 21% | Training loss: 0.6875985649443165
Epoch: 29 | Iteration number: [980/4518] 21% | Training loss: 0.6875810468075226
Epoch: 29 | Iteration number: [990/4518] 21% | Training loss: 0.6875731088898399
Epoch: 29 | Iteration number: [1000/4518] 22% | Training loss: 0.6875533728599549
Epoch: 29 | Iteration number: [1010/4518] 22% | Training loss: 0.6875476123082755
Epoch: 29 | Iteration number: [1020/4518] 22% | Training loss: 0.6875248671162362
Epoch: 29 | Iteration number: [1030/4518] 22% | Training loss: 0.6875353635514824
Epoch: 29 | Iteration number: [1040/4518] 23% | Training loss: 0.6875236255618242
Epoch: 29 | Iteration number: [1050/4518] 23% | Training loss: 0.6875261017822084
Epoch: 29 | Iteration number: [1060/4518] 23% | Training loss: 0.6875211049925606
Epoch: 29 | Iteration number: [1070/4518] 23% | Training loss: 0.6875120572954695
Epoch: 29 | Iteration number: [1080/4518] 23% | Training loss: 0.6875078151623408
Epoch: 29 | Iteration number: [1090/4518] 24% | Training loss: 0.6875082164729407
Epoch: 29 | Iteration number: [1100/4518] 24% | Training loss: 0.6875094390999187
Epoch: 29 | Iteration number: [1110/4518] 24% | Training loss: 0.6875021625209499
Epoch: 29 | Iteration number: [1120/4518] 24% | Training loss: 0.6874978861638478
Epoch: 29 | Iteration number: [1130/4518] 25% | Training loss: 0.6874913121219229
Epoch: 29 | Iteration number: [1140/4518] 25% | Training loss: 0.6874950754015069
Epoch: 29 | Iteration number: [1150/4518] 25% | Training loss: 0.6874955256607221
Epoch: 29 | Iteration number: [1160/4518] 25% | Training loss: 0.6874885989674206
Epoch: 29 | Iteration number: [1170/4518] 25% | Training loss: 0.6874934773669283
Epoch: 29 | Iteration number: [1180/4518] 26% | Training loss: 0.6874885161044234
Epoch: 29 | Iteration number: [1190/4518] 26% | Training loss: 0.6874905154484661
Epoch: 29 | Iteration number: [1200/4518] 26% | Training loss: 0.6874866251647472
Epoch: 29 | Iteration number: [1210/4518] 26% | Training loss: 0.687472679890877
Epoch: 29 | Iteration number: [1220/4518] 27% | Training loss: 0.6874748396091774
Epoch: 29 | Iteration number: [1230/4518] 27% | Training loss: 0.687476360749423
Epoch: 29 | Iteration number: [1240/4518] 27% | Training loss: 0.6874730120743474
Epoch: 29 | Iteration number: [1250/4518] 27% | Training loss: 0.6874719673633576
Epoch: 29 | Iteration number: [1260/4518] 27% | Training loss: 0.6874626597714802
Epoch: 29 | Iteration number: [1270/4518] 28% | Training loss: 0.6874644055610567
Epoch: 29 | Iteration number: [1280/4518] 28% | Training loss: 0.6874602506868541
Epoch: 29 | Iteration number: [1290/4518] 28% | Training loss: 0.687450206094934
Epoch: 29 | Iteration number: [1300/4518] 28% | Training loss: 0.6874506159012135
Epoch: 29 | Iteration number: [1310/4518] 28% | Training loss: 0.6874318312142641
Epoch: 29 | Iteration number: [1320/4518] 29% | Training loss: 0.6874317161964648
Epoch: 29 | Iteration number: [1330/4518] 29% | Training loss: 0.6874250697014027
Epoch: 29 | Iteration number: [1340/4518] 29% | Training loss: 0.6874104932617785
Epoch: 29 | Iteration number: [1350/4518] 29% | Training loss: 0.6874042180732445
Epoch: 29 | Iteration number: [1360/4518] 30% | Training loss: 0.6874002525473342
Epoch: 29 | Iteration number: [1370/4518] 30% | Training loss: 0.6874008542429791
Epoch: 29 | Iteration number: [1380/4518] 30% | Training loss: 0.6874030497626982
Epoch: 29 | Iteration number: [1390/4518] 30% | Training loss: 0.6873963967930499
Epoch: 29 | Iteration number: [1400/4518] 30% | Training loss: 0.6873911979368755
Epoch: 29 | Iteration number: [1410/4518] 31% | Training loss: 0.6873892050262884
Epoch: 29 | Iteration number: [1420/4518] 31% | Training loss: 0.6873747820585546
Epoch: 29 | Iteration number: [1430/4518] 31% | Training loss: 0.6873682241339784
Epoch: 29 | Iteration number: [1440/4518] 31% | Training loss: 0.6873611632320616
Epoch: 29 | Iteration number: [1450/4518] 32% | Training loss: 0.6873513834640897
Epoch: 29 | Iteration number: [1460/4518] 32% | Training loss: 0.6873450527044191
Epoch: 29 | Iteration number: [1470/4518] 32% | Training loss: 0.6873433251770176
Epoch: 29 | Iteration number: [1480/4518] 32% | Training loss: 0.6873401033717232
Epoch: 29 | Iteration number: [1490/4518] 32% | Training loss: 0.6873336933603222
Epoch: 29 | Iteration number: [1500/4518] 33% | Training loss: 0.6873259732325872
Epoch: 29 | Iteration number: [1510/4518] 33% | Training loss: 0.6873198593294384
Epoch: 29 | Iteration number: [1520/4518] 33% | Training loss: 0.6873201504349709
Epoch: 29 | Iteration number: [1530/4518] 33% | Training loss: 0.6873152433657179
Epoch: 29 | Iteration number: [1540/4518] 34% | Training loss: 0.6873055930261488
Epoch: 29 | Iteration number: [1550/4518] 34% | Training loss: 0.6873119350402586
Epoch: 29 | Iteration number: [1560/4518] 34% | Training loss: 0.6873047756460997
Epoch: 29 | Iteration number: [1570/4518] 34% | Training loss: 0.6873014637619067
Epoch: 29 | Iteration number: [1580/4518] 34% | Training loss: 0.687298014571395
Epoch: 29 | Iteration number: [1590/4518] 35% | Training loss: 0.6873068802011838
Epoch: 29 | Iteration number: [1600/4518] 35% | Training loss: 0.6872932719811797
Epoch: 29 | Iteration number: [1610/4518] 35% | Training loss: 0.6872974004064287
Epoch: 29 | Iteration number: [1620/4518] 35% | Training loss: 0.6872929801911484
Epoch: 29 | Iteration number: [1630/4518] 36% | Training loss: 0.6872844757112258
Epoch: 29 | Iteration number: [1640/4518] 36% | Training loss: 0.6872816217018337
Epoch: 29 | Iteration number: [1650/4518] 36% | Training loss: 0.6872784743525765
Epoch: 29 | Iteration number: [1660/4518] 36% | Training loss: 0.6872783576867667
Epoch: 29 | Iteration number: [1670/4518] 36% | Training loss: 0.6872834336614895
Epoch: 29 | Iteration number: [1680/4518] 37% | Training loss: 0.6872843534109139
Epoch: 29 | Iteration number: [1690/4518] 37% | Training loss: 0.6872830978512059
Epoch: 29 | Iteration number: [1700/4518] 37% | Training loss: 0.6872802523304434
Epoch: 29 | Iteration number: [1710/4518] 37% | Training loss: 0.6872787887589973
Epoch: 29 | Iteration number: [1720/4518] 38% | Training loss: 0.6872805738864943
Epoch: 29 | Iteration number: [1730/4518] 38% | Training loss: 0.6872754892861912
Epoch: 29 | Iteration number: [1740/4518] 38% | Training loss: 0.687275350059586
Epoch: 29 | Iteration number: [1750/4518] 38% | Training loss: 0.6872711202417101
Epoch: 29 | Iteration number: [1760/4518] 38% | Training loss: 0.6872681479562412
Epoch: 29 | Iteration number: [1770/4518] 39% | Training loss: 0.6872659766404642
Epoch: 29 | Iteration number: [1780/4518] 39% | Training loss: 0.6872573526052946
Epoch: 29 | Iteration number: [1790/4518] 39% | Training loss: 0.6872643248994923
Epoch: 29 | Iteration number: [1800/4518] 39% | Training loss: 0.6872626188066271
Epoch: 29 | Iteration number: [1810/4518] 40% | Training loss: 0.6872642239154373
Epoch: 29 | Iteration number: [1820/4518] 40% | Training loss: 0.6872584609539955
Epoch: 29 | Iteration number: [1830/4518] 40% | Training loss: 0.687250729271623
Epoch: 29 | Iteration number: [1840/4518] 40% | Training loss: 0.6872511613952077
Epoch: 29 | Iteration number: [1850/4518] 40% | Training loss: 0.6872561075236346
Epoch: 29 | Iteration number: [1860/4518] 41% | Training loss: 0.6872550759584674
Epoch: 29 | Iteration number: [1870/4518] 41% | Training loss: 0.6872529128018547
Epoch: 29 | Iteration number: [1880/4518] 41% | Training loss: 0.6872552961745161
Epoch: 29 | Iteration number: [1890/4518] 41% | Training loss: 0.6872475486899179
Epoch: 29 | Iteration number: [1900/4518] 42% | Training loss: 0.6872442305088043
Epoch: 29 | Iteration number: [1910/4518] 42% | Training loss: 0.6872466281446487
Epoch: 29 | Iteration number: [1920/4518] 42% | Training loss: 0.6872436680210133
Epoch: 29 | Iteration number: [1930/4518] 42% | Training loss: 0.68724200855265
Epoch: 29 | Iteration number: [1940/4518] 42% | Training loss: 0.6872345654005857
Epoch: 29 | Iteration number: [1950/4518] 43% | Training loss: 0.687236820031435
Epoch: 29 | Iteration number: [1960/4518] 43% | Training loss: 0.6872338995641591
Epoch: 29 | Iteration number: [1970/4518] 43% | Training loss: 0.6872346874118457
Epoch: 29 | Iteration number: [1980/4518] 43% | Training loss: 0.687233529518349
Epoch: 29 | Iteration number: [1990/4518] 44% | Training loss: 0.6872383094612677
Epoch: 29 | Iteration number: [2000/4518] 44% | Training loss: 0.6872332894802093
Epoch: 29 | Iteration number: [2010/4518] 44% | Training loss: 0.687227989963038
Epoch: 29 | Iteration number: [2020/4518] 44% | Training loss: 0.6872280366054856
Epoch: 29 | Iteration number: [2030/4518] 44% | Training loss: 0.68723102658253
Epoch: 29 | Iteration number: [2040/4518] 45% | Training loss: 0.6872294361392657
Epoch: 29 | Iteration number: [2050/4518] 45% | Training loss: 0.6872239202697102
Epoch: 29 | Iteration number: [2060/4518] 45% | Training loss: 0.6872196170022187
Epoch: 29 | Iteration number: [2070/4518] 45% | Training loss: 0.6872141018005961
Epoch: 29 | Iteration number: [2080/4518] 46% | Training loss: 0.6872070885908145
Epoch: 29 | Iteration number: [2090/4518] 46% | Training loss: 0.6872047596000599
Epoch: 29 | Iteration number: [2100/4518] 46% | Training loss: 0.6872038863670258
Epoch: 29 | Iteration number: [2110/4518] 46% | Training loss: 0.6872057600326448
Epoch: 29 | Iteration number: [2120/4518] 46% | Training loss: 0.6872060360211246
Epoch: 29 | Iteration number: [2130/4518] 47% | Training loss: 0.6872037088367301
Epoch: 29 | Iteration number: [2140/4518] 47% | Training loss: 0.6872018497123896
Epoch: 29 | Iteration number: [2150/4518] 47% | Training loss: 0.6872098644389663
Epoch: 29 | Iteration number: [2160/4518] 47% | Training loss: 0.6872106017613853
Epoch: 29 | Iteration number: [2170/4518] 48% | Training loss: 0.6872040596151132
Epoch: 29 | Iteration number: [2180/4518] 48% | Training loss: 0.6871982951776697
Epoch: 29 | Iteration number: [2190/4518] 48% | Training loss: 0.6871983220043792
Epoch: 29 | Iteration number: [2200/4518] 48% | Training loss: 0.6871911651437933
Epoch: 29 | Iteration number: [2210/4518] 48% | Training loss: 0.6871895524171683
Epoch: 29 | Iteration number: [2220/4518] 49% | Training loss: 0.6871873100330164
Epoch: 29 | Iteration number: [2230/4518] 49% | Training loss: 0.6871860458177301
Epoch: 29 | Iteration number: [2240/4518] 49% | Training loss: 0.6871830845517771
Epoch: 29 | Iteration number: [2250/4518] 49% | Training loss: 0.6871769480970171
Epoch: 29 | Iteration number: [2260/4518] 50% | Training loss: 0.6871701369770861
Epoch: 29 | Iteration number: [2270/4518] 50% | Training loss: 0.6871658801244744
Epoch: 29 | Iteration number: [2280/4518] 50% | Training loss: 0.6871637346974591
Epoch: 29 | Iteration number: [2290/4518] 50% | Training loss: 0.687159984757286
Epoch: 29 | Iteration number: [2300/4518] 50% | Training loss: 0.6871644736372906
Epoch: 29 | Iteration number: [2310/4518] 51% | Training loss: 0.6871633801625404
Epoch: 29 | Iteration number: [2320/4518] 51% | Training loss: 0.6871606578857734
Epoch: 29 | Iteration number: [2330/4518] 51% | Training loss: 0.6871609151107558
Epoch: 29 | Iteration number: [2340/4518] 51% | Training loss: 0.6871635785724363
Epoch: 29 | Iteration number: [2350/4518] 52% | Training loss: 0.687162796132108
Epoch: 29 | Iteration number: [2360/4518] 52% | Training loss: 0.6871574885764364
Epoch: 29 | Iteration number: [2370/4518] 52% | Training loss: 0.6871545202369931
Epoch: 29 | Iteration number: [2380/4518] 52% | Training loss: 0.6871524524538457
Epoch: 29 | Iteration number: [2390/4518] 52% | Training loss: 0.687148503803309
Epoch: 29 | Iteration number: [2400/4518] 53% | Training loss: 0.6871437486509482
Epoch: 29 | Iteration number: [2410/4518] 53% | Training loss: 0.6871448446606204
Epoch: 29 | Iteration number: [2420/4518] 53% | Training loss: 0.6871430443091826
Epoch: 29 | Iteration number: [2430/4518] 53% | Training loss: 0.6871447047578945
Epoch: 29 | Iteration number: [2440/4518] 54% | Training loss: 0.687145050383005
Epoch: 29 | Iteration number: [2450/4518] 54% | Training loss: 0.6871435926155168
Epoch: 29 | Iteration number: [2460/4518] 54% | Training loss: 0.687138395580819
Epoch: 29 | Iteration number: [2470/4518] 54% | Training loss: 0.6871409695640749
Epoch: 29 | Iteration number: [2480/4518] 54% | Training loss: 0.687138308368383
Epoch: 29 | Iteration number: [2490/4518] 55% | Training loss: 0.6871387729683076
Epoch: 29 | Iteration number: [2500/4518] 55% | Training loss: 0.6871349630594253
Epoch: 29 | Iteration number: [2510/4518] 55% | Training loss: 0.6871256954166519
Epoch: 29 | Iteration number: [2520/4518] 55% | Training loss: 0.6871283825427766
Epoch: 29 | Iteration number: [2530/4518] 55% | Training loss: 0.687130079910218
Epoch: 29 | Iteration number: [2540/4518] 56% | Training loss: 0.687127255407844
Epoch: 29 | Iteration number: [2550/4518] 56% | Training loss: 0.6871294241559271
Epoch: 29 | Iteration number: [2560/4518] 56% | Training loss: 0.6871283040614798
Epoch: 29 | Iteration number: [2570/4518] 56% | Training loss: 0.6871232829669106
Epoch: 29 | Iteration number: [2580/4518] 57% | Training loss: 0.6871248866236487
Epoch: 29 | Iteration number: [2590/4518] 57% | Training loss: 0.6871210112074627
Epoch: 29 | Iteration number: [2600/4518] 57% | Training loss: 0.6871244368415612
Epoch: 29 | Iteration number: [2610/4518] 57% | Training loss: 0.6871264433952127
Epoch: 29 | Iteration number: [2620/4518] 57% | Training loss: 0.6871216435241335
Epoch: 29 | Iteration number: [2630/4518] 58% | Training loss: 0.687117174369754
Epoch: 29 | Iteration number: [2640/4518] 58% | Training loss: 0.6871170061781551
Epoch: 29 | Iteration number: [2650/4518] 58% | Training loss: 0.6871199179595372
Epoch: 29 | Iteration number: [2660/4518] 58% | Training loss: 0.6871145252222405
Epoch: 29 | Iteration number: [2670/4518] 59% | Training loss: 0.6871175221959304
Epoch: 29 | Iteration number: [2680/4518] 59% | Training loss: 0.6871172878946831
Epoch: 29 | Iteration number: [2690/4518] 59% | Training loss: 0.6871180377041983
Epoch: 29 | Iteration number: [2700/4518] 59% | Training loss: 0.6871201355589761
Epoch: 29 | Iteration number: [2710/4518] 59% | Training loss: 0.6871197177915116
Epoch: 29 | Iteration number: [2720/4518] 60% | Training loss: 0.6871221058289795
Epoch: 29 | Iteration number: [2730/4518] 60% | Training loss: 0.6871178401258838
Epoch: 29 | Iteration number: [2740/4518] 60% | Training loss: 0.6871156173900966
Epoch: 29 | Iteration number: [2750/4518] 60% | Training loss: 0.6871193246191198
Epoch: 29 | Iteration number: [2760/4518] 61% | Training loss: 0.6871164673696394
Epoch: 29 | Iteration number: [2770/4518] 61% | Training loss: 0.6871197594417131
Epoch: 29 | Iteration number: [2780/4518] 61% | Training loss: 0.6871162839287477
Epoch: 29 | Iteration number: [2790/4518] 61% | Training loss: 0.6871139218943948
Epoch: 29 | Iteration number: [2800/4518] 61% | Training loss: 0.6871118938071387
Epoch: 29 | Iteration number: [2810/4518] 62% | Training loss: 0.6871116579427413
Epoch: 29 | Iteration number: [2820/4518] 62% | Training loss: 0.687111291099102
Epoch: 29 | Iteration number: [2830/4518] 62% | Training loss: 0.6871098969302835
Epoch: 29 | Iteration number: [2840/4518] 62% | Training loss: 0.6871073968393702
Epoch: 29 | Iteration number: [2850/4518] 63% | Training loss: 0.687108344404321
Epoch: 29 | Iteration number: [2860/4518] 63% | Training loss: 0.6871067865745171
Epoch: 29 | Iteration number: [2870/4518] 63% | Training loss: 0.6871014221204698
Epoch: 29 | Iteration number: [2880/4518] 63% | Training loss: 0.6871022290239731
Epoch: 29 | Iteration number: [2890/4518] 63% | Training loss: 0.6870999259107253
Epoch: 29 | Iteration number: [2900/4518] 64% | Training loss: 0.6870979163564485
Epoch: 29 | Iteration number: [2910/4518] 64% | Training loss: 0.6870972144849522
Epoch: 29 | Iteration number: [2920/4518] 64% | Training loss: 0.687096525075501
Epoch: 29 | Iteration number: [2930/4518] 64% | Training loss: 0.6870940228777941
Epoch: 29 | Iteration number: [2940/4518] 65% | Training loss: 0.6870896330901555
Epoch: 29 | Iteration number: [2950/4518] 65% | Training loss: 0.687091585034031
Epoch: 29 | Iteration number: [2960/4518] 65% | Training loss: 0.6870877704306229
Epoch: 29 | Iteration number: [2970/4518] 65% | Training loss: 0.6870872238870421
Epoch: 29 | Iteration number: [2980/4518] 65% | Training loss: 0.6870902226675277
Epoch: 29 | Iteration number: [2990/4518] 66% | Training loss: 0.687085130581489
Epoch: 29 | Iteration number: [3000/4518] 66% | Training loss: 0.6870809492071469
Epoch: 29 | Iteration number: [3010/4518] 66% | Training loss: 0.6870794149926335
Epoch: 29 | Iteration number: [3020/4518] 66% | Training loss: 0.6870755068513731
Epoch: 29 | Iteration number: [3030/4518] 67% | Training loss: 0.6870787645723954
Epoch: 29 | Iteration number: [3040/4518] 67% | Training loss: 0.6870758262707999
Epoch: 29 | Iteration number: [3050/4518] 67% | Training loss: 0.6870791817297701
Epoch: 29 | Iteration number: [3060/4518] 67% | Training loss: 0.6870805714644638
Epoch: 29 | Iteration number: [3070/4518] 67% | Training loss: 0.6870799054346178
Epoch: 29 | Iteration number: [3080/4518] 68% | Training loss: 0.6870804475112395
Epoch: 29 | Iteration number: [3090/4518] 68% | Training loss: 0.687079970157648
Epoch: 29 | Iteration number: [3100/4518] 68% | Training loss: 0.6870795217252547
Epoch: 29 | Iteration number: [3110/4518] 68% | Training loss: 0.6870773487535704
Epoch: 29 | Iteration number: [3120/4518] 69% | Training loss: 0.6870798824498286
Epoch: 29 | Iteration number: [3130/4518] 69% | Training loss: 0.6870811181136975
Epoch: 29 | Iteration number: [3140/4518] 69% | Training loss: 0.6870762177903181
Epoch: 29 | Iteration number: [3150/4518] 69% | Training loss: 0.687073223609773
Epoch: 29 | Iteration number: [3160/4518] 69% | Training loss: 0.6870739552605001
Epoch: 29 | Iteration number: [3170/4518] 70% | Training loss: 0.6870735529657418
Epoch: 29 | Iteration number: [3180/4518] 70% | Training loss: 0.6870728753460278
Epoch: 29 | Iteration number: [3190/4518] 70% | Training loss: 0.6870751774796872
Epoch: 29 | Iteration number: [3200/4518] 70% | Training loss: 0.6870733651518822
Epoch: 29 | Iteration number: [3210/4518] 71% | Training loss: 0.6870713237847124
Epoch: 29 | Iteration number: [3220/4518] 71% | Training loss: 0.687067332604657
Epoch: 29 | Iteration number: [3230/4518] 71% | Training loss: 0.6870657404325325
Epoch: 29 | Iteration number: [3240/4518] 71% | Training loss: 0.6870635707621221
Epoch: 29 | Iteration number: [3250/4518] 71% | Training loss: 0.6870592257242937
Epoch: 29 | Iteration number: [3260/4518] 72% | Training loss: 0.6870584158443965
Epoch: 29 | Iteration number: [3270/4518] 72% | Training loss: 0.687060389660914
Epoch: 29 | Iteration number: [3280/4518] 72% | Training loss: 0.6870643496695088
Epoch: 29 | Iteration number: [3290/4518] 72% | Training loss: 0.6870647167905848
Epoch: 29 | Iteration number: [3300/4518] 73% | Training loss: 0.687061933965394
Epoch: 29 | Iteration number: [3310/4518] 73% | Training loss: 0.6870641717017597
Epoch: 29 | Iteration number: [3320/4518] 73% | Training loss: 0.6870638306061906
Epoch: 29 | Iteration number: [3330/4518] 73% | Training loss: 0.6870633865261937
Epoch: 29 | Iteration number: [3340/4518] 73% | Training loss: 0.6870616306801756
Epoch: 29 | Iteration number: [3350/4518] 74% | Training loss: 0.6870584945358447
Epoch: 29 | Iteration number: [3360/4518] 74% | Training loss: 0.6870562220790557
Epoch: 29 | Iteration number: [3370/4518] 74% | Training loss: 0.6870564300157903
Epoch: 29 | Iteration number: [3380/4518] 74% | Training loss: 0.6870545614400559
Epoch: 29 | Iteration number: [3390/4518] 75% | Training loss: 0.6870571252870701
Epoch: 29 | Iteration number: [3400/4518] 75% | Training loss: 0.6870537906534532
Epoch: 29 | Iteration number: [3410/4518] 75% | Training loss: 0.6870535499888781
Epoch: 29 | Iteration number: [3420/4518] 75% | Training loss: 0.6870568291659941
Epoch: 29 | Iteration number: [3430/4518] 75% | Training loss: 0.6870613541443216
Epoch: 29 | Iteration number: [3440/4518] 76% | Training loss: 0.6870578387795493
Epoch: 29 | Iteration number: [3450/4518] 76% | Training loss: 0.6870580721074256
Epoch: 29 | Iteration number: [3460/4518] 76% | Training loss: 0.6870541401336648
Epoch: 29 | Iteration number: [3470/4518] 76% | Training loss: 0.6870525208089812
Epoch: 29 | Iteration number: [3480/4518] 77% | Training loss: 0.6870514856501557
Epoch: 29 | Iteration number: [3490/4518] 77% | Training loss: 0.6870500233760878
Epoch: 29 | Iteration number: [3500/4518] 77% | Training loss: 0.6870489471299308
Epoch: 29 | Iteration number: [3510/4518] 77% | Training loss: 0.6870484635700868
Epoch: 29 | Iteration number: [3520/4518] 77% | Training loss: 0.6870460383255373
Epoch: 29 | Iteration number: [3530/4518] 78% | Training loss: 0.6870469448248996
Epoch: 29 | Iteration number: [3540/4518] 78% | Training loss: 0.6870484962975238
Epoch: 29 | Iteration number: [3550/4518] 78% | Training loss: 0.6870437044157108
Epoch: 29 | Iteration number: [3560/4518] 78% | Training loss: 0.6870403371165308
Epoch: 29 | Iteration number: [3570/4518] 79% | Training loss: 0.6870382351367748
Epoch: 29 | Iteration number: [3580/4518] 79% | Training loss: 0.6870337182749583
Epoch: 29 | Iteration number: [3590/4518] 79% | Training loss: 0.6870348854483336
Epoch: 29 | Iteration number: [3600/4518] 79% | Training loss: 0.6870340629915397
Epoch: 29 | Iteration number: [3610/4518] 79% | Training loss: 0.6870340845426364
Epoch: 29 | Iteration number: [3620/4518] 80% | Training loss: 0.6870330801326267
Epoch: 29 | Iteration number: [3630/4518] 80% | Training loss: 0.6870289065621116
Epoch: 29 | Iteration number: [3640/4518] 80% | Training loss: 0.6870284700295427
Epoch: 29 | Iteration number: [3650/4518] 80% | Training loss: 0.6870289742783324
Epoch: 29 | Iteration number: [3660/4518] 81% | Training loss: 0.6870286748057506
Epoch: 29 | Iteration number: [3670/4518] 81% | Training loss: 0.6870261644797364
Epoch: 29 | Iteration number: [3680/4518] 81% | Training loss: 0.6870249734300634
Epoch: 29 | Iteration number: [3690/4518] 81% | Training loss: 0.6870246974594871
Epoch: 29 | Iteration number: [3700/4518] 81% | Training loss: 0.6870232258132987
Epoch: 29 | Iteration number: [3710/4518] 82% | Training loss: 0.6870233402258623
Epoch: 29 | Iteration number: [3720/4518] 82% | Training loss: 0.6870237166362424
Epoch: 29 | Iteration number: [3730/4518] 82% | Training loss: 0.6870227126909005
Epoch: 29 | Iteration number: [3740/4518] 82% | Training loss: 0.6870213937153791
Epoch: 29 | Iteration number: [3750/4518] 83% | Training loss: 0.6870181779225667
Epoch: 29 | Iteration number: [3760/4518] 83% | Training loss: 0.6870196641442624
Epoch: 29 | Iteration number: [3770/4518] 83% | Training loss: 0.6870209310352011
Epoch: 29 | Iteration number: [3780/4518] 83% | Training loss: 0.6870209443190741
Epoch: 29 | Iteration number: [3790/4518] 83% | Training loss: 0.6870219662195775
Epoch: 29 | Iteration number: [3800/4518] 84% | Training loss: 0.6870229740362418
Epoch: 29 | Iteration number: [3810/4518] 84% | Training loss: 0.687024555181268
Epoch: 29 | Iteration number: [3820/4518] 84% | Training loss: 0.6870216012937236
Epoch: 29 | Iteration number: [3830/4518] 84% | Training loss: 0.6870202378878083
Epoch: 29 | Iteration number: [3840/4518] 84% | Training loss: 0.6870176532926658
Epoch: 29 | Iteration number: [3850/4518] 85% | Training loss: 0.6870177831897488
Epoch: 29 | Iteration number: [3860/4518] 85% | Training loss: 0.6870162991970932
Epoch: 29 | Iteration number: [3870/4518] 85% | Training loss: 0.6870181310854525
Epoch: 29 | Iteration number: [3880/4518] 85% | Training loss: 0.6870176170750991
Epoch: 29 | Iteration number: [3890/4518] 86% | Training loss: 0.687015083730987
Epoch: 29 | Iteration number: [3900/4518] 86% | Training loss: 0.6870142092001744
Epoch: 29 | Iteration number: [3910/4518] 86% | Training loss: 0.6870127930818006
Epoch: 29 | Iteration number: [3920/4518] 86% | Training loss: 0.6870119452172396
Epoch: 29 | Iteration number: [3930/4518] 86% | Training loss: 0.6870108381330815
Epoch: 29 | Iteration number: [3940/4518] 87% | Training loss: 0.6870096620871936
Epoch: 29 | Iteration number: [3950/4518] 87% | Training loss: 0.6870096301277981
Epoch: 29 | Iteration number: [3960/4518] 87% | Training loss: 0.687009046174059
Epoch: 29 | Iteration number: [3970/4518] 87% | Training loss: 0.6870097460914919
Epoch: 29 | Iteration number: [3980/4518] 88% | Training loss: 0.6870099014822563
Epoch: 29 | Iteration number: [3990/4518] 88% | Training loss: 0.6870094292892848
Epoch: 29 | Iteration number: [4000/4518] 88% | Training loss: 0.6870098587721586
Epoch: 29 | Iteration number: [4010/4518] 88% | Training loss: 0.6870116395100097
Epoch: 29 | Iteration number: [4020/4518] 88% | Training loss: 0.6870123177915071
Epoch: 29 | Iteration number: [4030/4518] 89% | Training loss: 0.6870124523012573
Epoch: 29 | Iteration number: [4040/4518] 89% | Training loss: 0.6870135928882231
Epoch: 29 | Iteration number: [4050/4518] 89% | Training loss: 0.6870166566195312
Epoch: 29 | Iteration number: [4060/4518] 89% | Training loss: 0.687015706961378
Epoch: 29 | Iteration number: [4070/4518] 90% | Training loss: 0.6870158524419517
Epoch: 29 | Iteration number: [4080/4518] 90% | Training loss: 0.6870183918698162
Epoch: 29 | Iteration number: [4090/4518] 90% | Training loss: 0.687018636167778
Epoch: 29 | Iteration number: [4100/4518] 90% | Training loss: 0.6870174383971749
Epoch: 29 | Iteration number: [4110/4518] 90% | Training loss: 0.6870168403842444
Epoch: 29 | Iteration number: [4120/4518] 91% | Training loss: 0.6870184605850757
Epoch: 29 | Iteration number: [4130/4518] 91% | Training loss: 0.6870187829972468
Epoch: 29 | Iteration number: [4140/4518] 91% | Training loss: 0.6870191535943948
Epoch: 29 | Iteration number: [4150/4518] 91% | Training loss: 0.6870179127641471
Epoch: 29 | Iteration number: [4160/4518] 92% | Training loss: 0.6870163062873941
Epoch: 29 | Iteration number: [4170/4518] 92% | Training loss: 0.6870166734254046
Epoch: 29 | Iteration number: [4180/4518] 92% | Training loss: 0.6870189457989195
Epoch: 29 | Iteration number: [4190/4518] 92% | Training loss: 0.6870154465297525
Epoch: 29 | Iteration number: [4200/4518] 92% | Training loss: 0.6870161040198235
Epoch: 29 | Iteration number: [4210/4518] 93% | Training loss: 0.6870132907269403
Epoch: 29 | Iteration number: [4220/4518] 93% | Training loss: 0.687012859854088
Epoch: 29 | Iteration number: [4230/4518] 93% | Training loss: 0.6870087497905073
Epoch: 29 | Iteration number: [4240/4518] 93% | Training loss: 0.6870071874334003
Epoch: 29 | Iteration number: [4250/4518] 94% | Training loss: 0.6870098335181966
Epoch: 29 | Iteration number: [4260/4518] 94% | Training loss: 0.687008446636894
Epoch: 29 | Iteration number: [4270/4518] 94% | Training loss: 0.6870075762271881
Epoch: 29 | Iteration number: [4280/4518] 94% | Training loss: 0.6870050824969729
Epoch: 29 | Iteration number: [4290/4518] 94% | Training loss: 0.6870026631510897
Epoch: 29 | Iteration number: [4300/4518] 95% | Training loss: 0.6870009591413099
Epoch: 29 | Iteration number: [4310/4518] 95% | Training loss: 0.6870013351230223
Epoch: 29 | Iteration number: [4320/4518] 95% | Training loss: 0.687003258160419
Epoch: 29 | Iteration number: [4330/4518] 95% | Training loss: 0.6870056900223739
Epoch: 29 | Iteration number: [4340/4518] 96% | Training loss: 0.6870037331559141
Epoch: 29 | Iteration number: [4350/4518] 96% | Training loss: 0.68700601288642
Epoch: 29 | Iteration number: [4360/4518] 96% | Training loss: 0.6870076340956426
Epoch: 29 | Iteration number: [4370/4518] 96% | Training loss: 0.6870070331975033
Epoch: 29 | Iteration number: [4380/4518] 96% | Training loss: 0.6870079159328383
Epoch: 29 | Iteration number: [4390/4518] 97% | Training loss: 0.6870087772539917
Epoch: 29 | Iteration number: [4400/4518] 97% | Training loss: 0.6870093513076956
Epoch: 29 | Iteration number: [4410/4518] 97% | Training loss: 0.6870102729791957
Epoch: 29 | Iteration number: [4420/4518] 97% | Training loss: 0.6870101142657828
Epoch: 29 | Iteration number: [4430/4518] 98% | Training loss: 0.6870092157585627
Epoch: 29 | Iteration number: [4440/4518] 98% | Training loss: 0.6870083434356226
Epoch: 29 | Iteration number: [4450/4518] 98% | Training loss: 0.6870074932896689
Epoch: 29 | Iteration number: [4460/4518] 98% | Training loss: 0.6870094034837501
Epoch: 29 | Iteration number: [4470/4518] 98% | Training loss: 0.6870093337508123
Epoch: 29 | Iteration number: [4480/4518] 99% | Training loss: 0.6870076453047139
Epoch: 29 | Iteration number: [4490/4518] 99% | Training loss: 0.6870046677992976
Epoch: 29 | Iteration number: [4500/4518] 99% | Training loss: 0.6870045133431752
Epoch: 29 | Iteration number: [4510/4518] 99% | Training loss: 0.6870036340737818

 End of epoch: 29 | Train Loss: 0.6868529734541854 | Training Time: 632 

 End of epoch: 29 | Eval Loss: 0.6899057055006221 | Evaluating Time: 17 
Epoch: 30 | Iteration number: [10/4518] 0% | Training loss: 0.7565305352210998
Epoch: 30 | Iteration number: [20/4518] 0% | Training loss: 0.722040182352066
Epoch: 30 | Iteration number: [30/4518] 0% | Training loss: 0.7107449909051259
Epoch: 30 | Iteration number: [40/4518] 0% | Training loss: 0.7046045109629631
Epoch: 30 | Iteration number: [50/4518] 1% | Training loss: 0.7009639871120453
Epoch: 30 | Iteration number: [60/4518] 1% | Training loss: 0.6983772218227386
Epoch: 30 | Iteration number: [70/4518] 1% | Training loss: 0.6967459074088506
Epoch: 30 | Iteration number: [80/4518] 1% | Training loss: 0.6955685757100583
Epoch: 30 | Iteration number: [90/4518] 1% | Training loss: 0.6946288737985823
Epoch: 30 | Iteration number: [100/4518] 2% | Training loss: 0.6938349187374115
Epoch: 30 | Iteration number: [110/4518] 2% | Training loss: 0.6932436964728615
Epoch: 30 | Iteration number: [120/4518] 2% | Training loss: 0.692670509715875
Epoch: 30 | Iteration number: [130/4518] 2% | Training loss: 0.6922470789689285
Epoch: 30 | Iteration number: [140/4518] 3% | Training loss: 0.6918655612639019
Epoch: 30 | Iteration number: [150/4518] 3% | Training loss: 0.6915855189164479
Epoch: 30 | Iteration number: [160/4518] 3% | Training loss: 0.6913034323602915
Epoch: 30 | Iteration number: [170/4518] 3% | Training loss: 0.6910212110070622
Epoch: 30 | Iteration number: [180/4518] 3% | Training loss: 0.6907638708750407
Epoch: 30 | Iteration number: [190/4518] 4% | Training loss: 0.6905294653616454
Epoch: 30 | Iteration number: [200/4518] 4% | Training loss: 0.6903085678815841
Epoch: 30 | Iteration number: [210/4518] 4% | Training loss: 0.6901011472656613
Epoch: 30 | Iteration number: [220/4518] 4% | Training loss: 0.6899972517382015
Epoch: 30 | Iteration number: [230/4518] 5% | Training loss: 0.6898489542629408
Epoch: 30 | Iteration number: [240/4518] 5% | Training loss: 0.6897157572209835
Epoch: 30 | Iteration number: [250/4518] 5% | Training loss: 0.6896326689720154
Epoch: 30 | Iteration number: [260/4518] 5% | Training loss: 0.6894995418878702
Epoch: 30 | Iteration number: [270/4518] 5% | Training loss: 0.6893891703199457
Epoch: 30 | Iteration number: [280/4518] 6% | Training loss: 0.6892987549304962
Epoch: 30 | Iteration number: [290/4518] 6% | Training loss: 0.689189211870062
Epoch: 30 | Iteration number: [300/4518] 6% | Training loss: 0.6891422744592031
Epoch: 30 | Iteration number: [310/4518] 6% | Training loss: 0.6890598268278183
Epoch: 30 | Iteration number: [320/4518] 7% | Training loss: 0.6889989914372563
Epoch: 30 | Iteration number: [330/4518] 7% | Training loss: 0.6889016030412731
Epoch: 30 | Iteration number: [340/4518] 7% | Training loss: 0.6888776956235662
Epoch: 30 | Iteration number: [350/4518] 7% | Training loss: 0.6888255946976798
Epoch: 30 | Iteration number: [360/4518] 7% | Training loss: 0.6887774207525783
Epoch: 30 | Iteration number: [370/4518] 8% | Training loss: 0.6887882810992163
Epoch: 30 | Iteration number: [380/4518] 8% | Training loss: 0.6886933091439699
Epoch: 30 | Iteration number: [390/4518] 8% | Training loss: 0.6886393482868488
Epoch: 30 | Iteration number: [400/4518] 8% | Training loss: 0.6885841479897499
Epoch: 30 | Iteration number: [410/4518] 9% | Training loss: 0.6885630992854513
Epoch: 30 | Iteration number: [420/4518] 9% | Training loss: 0.6885149524325416
Epoch: 30 | Iteration number: [430/4518] 9% | Training loss: 0.6884680122830147
Epoch: 30 | Iteration number: [440/4518] 9% | Training loss: 0.688451388342814
Epoch: 30 | Iteration number: [450/4518] 9% | Training loss: 0.6884266608291202
Epoch: 30 | Iteration number: [460/4518] 10% | Training loss: 0.6883989039970481
Epoch: 30 | Iteration number: [470/4518] 10% | Training loss: 0.6883626721006759
Epoch: 30 | Iteration number: [480/4518] 10% | Training loss: 0.6883529655635356
Epoch: 30 | Iteration number: [490/4518] 10% | Training loss: 0.6883315274910051
Epoch: 30 | Iteration number: [500/4518] 11% | Training loss: 0.6882824286222458
Epoch: 30 | Iteration number: [510/4518] 11% | Training loss: 0.6882543649159226
Epoch: 30 | Iteration number: [520/4518] 11% | Training loss: 0.6882341038722258
Epoch: 30 | Iteration number: [530/4518] 11% | Training loss: 0.6882021973717888
Epoch: 30 | Iteration number: [540/4518] 11% | Training loss: 0.6881707556821682
Epoch: 30 | Iteration number: [550/4518] 12% | Training loss: 0.688155387098139
Epoch: 30 | Iteration number: [560/4518] 12% | Training loss: 0.688134980414595
Epoch: 30 | Iteration number: [570/4518] 12% | Training loss: 0.6881114857238636
Epoch: 30 | Iteration number: [580/4518] 12% | Training loss: 0.6880964419965087
Epoch: 30 | Iteration number: [590/4518] 13% | Training loss: 0.6880749799437442
Epoch: 30 | Iteration number: [600/4518] 13% | Training loss: 0.6880784686406454
Epoch: 30 | Iteration number: [610/4518] 13% | Training loss: 0.6880618366061664
Epoch: 30 | Iteration number: [620/4518] 13% | Training loss: 0.6880299941185982
Epoch: 30 | Iteration number: [630/4518] 13% | Training loss: 0.6880099820712257
Epoch: 30 | Iteration number: [640/4518] 14% | Training loss: 0.6879900462925435
Epoch: 30 | Iteration number: [650/4518] 14% | Training loss: 0.6879664272528428
Epoch: 30 | Iteration number: [660/4518] 14% | Training loss: 0.6879589460112832
Epoch: 30 | Iteration number: [670/4518] 14% | Training loss: 0.6879526129409449
Epoch: 30 | Iteration number: [680/4518] 15% | Training loss: 0.6879395853070652
Epoch: 30 | Iteration number: [690/4518] 15% | Training loss: 0.6879164137702057
Epoch: 30 | Iteration number: [700/4518] 15% | Training loss: 0.6879021440233503
Epoch: 30 | Iteration number: [710/4518] 15% | Training loss: 0.6878900604348787
Epoch: 30 | Iteration number: [720/4518] 15% | Training loss: 0.6878688462078572
Epoch: 30 | Iteration number: [730/4518] 16% | Training loss: 0.6878729095197704
Epoch: 30 | Iteration number: [740/4518] 16% | Training loss: 0.6878647877557857
Epoch: 30 | Iteration number: [750/4518] 16% | Training loss: 0.6878646077315013
Epoch: 30 | Iteration number: [760/4518] 16% | Training loss: 0.6878744264182292
Epoch: 30 | Iteration number: [770/4518] 17% | Training loss: 0.687865426013996
Epoch: 30 | Iteration number: [780/4518] 17% | Training loss: 0.6878645101418862
Epoch: 30 | Iteration number: [790/4518] 17% | Training loss: 0.6878465666046626
Epoch: 30 | Iteration number: [800/4518] 17% | Training loss: 0.6878288201987743
Epoch: 30 | Iteration number: [810/4518] 17% | Training loss: 0.6878234485049307
Epoch: 30 | Iteration number: [820/4518] 18% | Training loss: 0.6878085901097554
Epoch: 30 | Iteration number: [830/4518] 18% | Training loss: 0.6877930914063052
Epoch: 30 | Iteration number: [840/4518] 18% | Training loss: 0.6877815502740088
Epoch: 30 | Iteration number: [850/4518] 18% | Training loss: 0.6877808727937587
Epoch: 30 | Iteration number: [860/4518] 19% | Training loss: 0.6877472557300746
Epoch: 30 | Iteration number: [870/4518] 19% | Training loss: 0.6877445881394134
Epoch: 30 | Iteration number: [880/4518] 19% | Training loss: 0.6877390609546141
Epoch: 30 | Iteration number: [890/4518] 19% | Training loss: 0.6877281663792857
Epoch: 30 | Iteration number: [900/4518] 19% | Training loss: 0.6877180442545149
Epoch: 30 | Iteration number: [910/4518] 20% | Training loss: 0.6877102640303937
Epoch: 30 | Iteration number: [920/4518] 20% | Training loss: 0.6876984098035356
Epoch: 30 | Iteration number: [930/4518] 20% | Training loss: 0.687692904215987
Epoch: 30 | Iteration number: [940/4518] 20% | Training loss: 0.6876763088906065
Epoch: 30 | Iteration number: [950/4518] 21% | Training loss: 0.6876603800999491
Epoch: 30 | Iteration number: [960/4518] 21% | Training loss: 0.6876478563373287
Epoch: 30 | Iteration number: [970/4518] 21% | Training loss: 0.6876424987906034
Epoch: 30 | Iteration number: [980/4518] 21% | Training loss: 0.6876418711579576
Epoch: 30 | Iteration number: [990/4518] 21% | Training loss: 0.6876294809158402
Epoch: 30 | Iteration number: [1000/4518] 22% | Training loss: 0.6876105652451515
Epoch: 30 | Iteration number: [1010/4518] 22% | Training loss: 0.6876011765239263
Epoch: 30 | Iteration number: [1020/4518] 22% | Training loss: 0.6875924135540046
Epoch: 30 | Iteration number: [1030/4518] 22% | Training loss: 0.6875869114422104
Epoch: 30 | Iteration number: [1040/4518] 23% | Training loss: 0.6875823981486834
Epoch: 30 | Iteration number: [1050/4518] 23% | Training loss: 0.6875796450319744
Epoch: 30 | Iteration number: [1060/4518] 23% | Training loss: 0.6875765786418375
Epoch: 30 | Iteration number: [1070/4518] 23% | Training loss: 0.6875599970884412
Epoch: 30 | Iteration number: [1080/4518] 23% | Training loss: 0.6875534430146217
Epoch: 30 | Iteration number: [1090/4518] 24% | Training loss: 0.6875492111805382
Epoch: 30 | Iteration number: [1100/4518] 24% | Training loss: 0.6875401040640744
Epoch: 30 | Iteration number: [1110/4518] 24% | Training loss: 0.6875344783336192
Epoch: 30 | Iteration number: [1120/4518] 24% | Training loss: 0.6875226757888283
Epoch: 30 | Iteration number: [1130/4518] 25% | Training loss: 0.6875170645988093
Epoch: 30 | Iteration number: [1140/4518] 25% | Training loss: 0.6875260536607943
Epoch: 30 | Iteration number: [1150/4518] 25% | Training loss: 0.6875110318868056
Epoch: 30 | Iteration number: [1160/4518] 25% | Training loss: 0.6875123045567808
Epoch: 30 | Iteration number: [1170/4518] 25% | Training loss: 0.6874886262620616
Epoch: 30 | Iteration number: [1180/4518] 26% | Training loss: 0.6874682186013561
Epoch: 30 | Iteration number: [1190/4518] 26% | Training loss: 0.6874761775762093
Epoch: 30 | Iteration number: [1200/4518] 26% | Training loss: 0.6874740784366925
Epoch: 30 | Iteration number: [1210/4518] 26% | Training loss: 0.6874748330963545
Epoch: 30 | Iteration number: [1220/4518] 27% | Training loss: 0.6874743152348721
Epoch: 30 | Iteration number: [1230/4518] 27% | Training loss: 0.6874663540987465
Epoch: 30 | Iteration number: [1240/4518] 27% | Training loss: 0.6874601154077438
Epoch: 30 | Iteration number: [1250/4518] 27% | Training loss: 0.6874521328449249
Epoch: 30 | Iteration number: [1260/4518] 27% | Training loss: 0.6874378876553642
Epoch: 30 | Iteration number: [1270/4518] 28% | Training loss: 0.6874294354221013
Epoch: 30 | Iteration number: [1280/4518] 28% | Training loss: 0.6874165711458773
Epoch: 30 | Iteration number: [1290/4518] 28% | Training loss: 0.6874135329279789
Epoch: 30 | Iteration number: [1300/4518] 28% | Training loss: 0.6874126079907784
Epoch: 30 | Iteration number: [1310/4518] 28% | Training loss: 0.6874058464101253
Epoch: 30 | Iteration number: [1320/4518] 29% | Training loss: 0.6874043961366018
Epoch: 30 | Iteration number: [1330/4518] 29% | Training loss: 0.6873999281485278
Epoch: 30 | Iteration number: [1340/4518] 29% | Training loss: 0.6873894252883854
Epoch: 30 | Iteration number: [1350/4518] 29% | Training loss: 0.6873930608343195
Epoch: 30 | Iteration number: [1360/4518] 30% | Training loss: 0.6873834142790122
Epoch: 30 | Iteration number: [1370/4518] 30% | Training loss: 0.6873891656851246
Epoch: 30 | Iteration number: [1380/4518] 30% | Training loss: 0.6873859462962635
Epoch: 30 | Iteration number: [1390/4518] 30% | Training loss: 0.6873875731186901
Epoch: 30 | Iteration number: [1400/4518] 30% | Training loss: 0.6873745550853866
Epoch: 30 | Iteration number: [1410/4518] 31% | Training loss: 0.6873703661117148
Epoch: 30 | Iteration number: [1420/4518] 31% | Training loss: 0.6873680027018131
Epoch: 30 | Iteration number: [1430/4518] 31% | Training loss: 0.6873699615885328
Epoch: 30 | Iteration number: [1440/4518] 31% | Training loss: 0.6873761251982715
Epoch: 30 | Iteration number: [1450/4518] 32% | Training loss: 0.6873688983095103
Epoch: 30 | Iteration number: [1460/4518] 32% | Training loss: 0.6873688950522305
Epoch: 30 | Iteration number: [1470/4518] 32% | Training loss: 0.687354264048492
Epoch: 30 | Iteration number: [1480/4518] 32% | Training loss: 0.6873568205011857
Epoch: 30 | Iteration number: [1490/4518] 32% | Training loss: 0.6873508155745948
Epoch: 30 | Iteration number: [1500/4518] 33% | Training loss: 0.6873414128224055
Epoch: 30 | Iteration number: [1510/4518] 33% | Training loss: 0.6873358620713089
Epoch: 30 | Iteration number: [1520/4518] 33% | Training loss: 0.6873379006589714
Epoch: 30 | Iteration number: [1530/4518] 33% | Training loss: 0.6873358908821555
Epoch: 30 | Iteration number: [1540/4518] 34% | Training loss: 0.6873306257771207
Epoch: 30 | Iteration number: [1550/4518] 34% | Training loss: 0.6873280517516598
Epoch: 30 | Iteration number: [1560/4518] 34% | Training loss: 0.687331446317526
Epoch: 30 | Iteration number: [1570/4518] 34% | Training loss: 0.6873328244610197
Epoch: 30 | Iteration number: [1580/4518] 34% | Training loss: 0.6873320711941658
Epoch: 30 | Iteration number: [1590/4518] 35% | Training loss: 0.6873327205765922
Epoch: 30 | Iteration number: [1600/4518] 35% | Training loss: 0.6873282532766462
Epoch: 30 | Iteration number: [1610/4518] 35% | Training loss: 0.6873215722741548
Epoch: 30 | Iteration number: [1620/4518] 35% | Training loss: 0.6873166179215466
Epoch: 30 | Iteration number: [1630/4518] 36% | Training loss: 0.6873078918164494
Epoch: 30 | Iteration number: [1640/4518] 36% | Training loss: 0.6873134028257393
Epoch: 30 | Iteration number: [1650/4518] 36% | Training loss: 0.6873143900524487
Epoch: 30 | Iteration number: [1660/4518] 36% | Training loss: 0.6873078604778612
Epoch: 30 | Iteration number: [1670/4518] 36% | Training loss: 0.6873028615634599
Epoch: 30 | Iteration number: [1680/4518] 37% | Training loss: 0.6872969485109761
Epoch: 30 | Iteration number: [1690/4518] 37% | Training loss: 0.6872902795055209
Epoch: 30 | Iteration number: [1700/4518] 37% | Training loss: 0.6872848882745294
Epoch: 30 | Iteration number: [1710/4518] 37% | Training loss: 0.6872900891025164
Epoch: 30 | Iteration number: [1720/4518] 38% | Training loss: 0.6872856705341228
Epoch: 30 | Iteration number: [1730/4518] 38% | Training loss: 0.6872832109473345
Epoch: 30 | Iteration number: [1740/4518] 38% | Training loss: 0.68727877003023
Epoch: 30 | Iteration number: [1750/4518] 38% | Training loss: 0.6872824292864118
Epoch: 30 | Iteration number: [1760/4518] 38% | Training loss: 0.6872835866768252
Epoch: 30 | Iteration number: [1770/4518] 39% | Training loss: 0.6872676532484043
Epoch: 30 | Iteration number: [1780/4518] 39% | Training loss: 0.6872675849145717
Epoch: 30 | Iteration number: [1790/4518] 39% | Training loss: 0.6872644279256214
Epoch: 30 | Iteration number: [1800/4518] 39% | Training loss: 0.6872540768649843
Epoch: 30 | Iteration number: [1810/4518] 40% | Training loss: 0.6872584392352658
Epoch: 30 | Iteration number: [1820/4518] 40% | Training loss: 0.6872590018825216
Epoch: 30 | Iteration number: [1830/4518] 40% | Training loss: 0.6872566139437462
Epoch: 30 | Iteration number: [1840/4518] 40% | Training loss: 0.6872569954589657
Epoch: 30 | Iteration number: [1850/4518] 40% | Training loss: 0.6872524948377867
Epoch: 30 | Iteration number: [1860/4518] 41% | Training loss: 0.6872559447762787
Epoch: 30 | Iteration number: [1870/4518] 41% | Training loss: 0.6872479909244068
Epoch: 30 | Iteration number: [1880/4518] 41% | Training loss: 0.687252082120865
Epoch: 30 | Iteration number: [1890/4518] 41% | Training loss: 0.6872436845428729
Epoch: 30 | Iteration number: [1900/4518] 42% | Training loss: 0.6872410583809803
Epoch: 30 | Iteration number: [1910/4518] 42% | Training loss: 0.6872405128641278
Epoch: 30 | Iteration number: [1920/4518] 42% | Training loss: 0.6872445697585742
Epoch: 30 | Iteration number: [1930/4518] 42% | Training loss: 0.6872430259699649
Epoch: 30 | Iteration number: [1940/4518] 42% | Training loss: 0.6872463499147867
Epoch: 30 | Iteration number: [1950/4518] 43% | Training loss: 0.687240212238752
Epoch: 30 | Iteration number: [1960/4518] 43% | Training loss: 0.6872449041325219
Epoch: 30 | Iteration number: [1970/4518] 43% | Training loss: 0.6872430185073524
Epoch: 30 | Iteration number: [1980/4518] 43% | Training loss: 0.6872397164804767
Epoch: 30 | Iteration number: [1990/4518] 44% | Training loss: 0.687237210998583
Epoch: 30 | Iteration number: [2000/4518] 44% | Training loss: 0.6872295278906823
Epoch: 30 | Iteration number: [2010/4518] 44% | Training loss: 0.6872282449878864
Epoch: 30 | Iteration number: [2020/4518] 44% | Training loss: 0.6872273125565879
Epoch: 30 | Iteration number: [2030/4518] 44% | Training loss: 0.6872210764238987
Epoch: 30 | Iteration number: [2040/4518] 45% | Training loss: 0.6872221245777373
Epoch: 30 | Iteration number: [2050/4518] 45% | Training loss: 0.687212884164438
Epoch: 30 | Iteration number: [2060/4518] 45% | Training loss: 0.6872178080012498
Epoch: 30 | Iteration number: [2070/4518] 45% | Training loss: 0.6872193336486816
Epoch: 30 | Iteration number: [2080/4518] 46% | Training loss: 0.6872206290180867
Epoch: 30 | Iteration number: [2090/4518] 46% | Training loss: 0.6872169338915337
Epoch: 30 | Iteration number: [2100/4518] 46% | Training loss: 0.6872145436207453
Epoch: 30 | Iteration number: [2110/4518] 46% | Training loss: 0.6872132168844413
Epoch: 30 | Iteration number: [2120/4518] 46% | Training loss: 0.6872094418361502
Epoch: 30 | Iteration number: [2130/4518] 47% | Training loss: 0.687211740352738
Epoch: 30 | Iteration number: [2140/4518] 47% | Training loss: 0.6872122740355607
Epoch: 30 | Iteration number: [2150/4518] 47% | Training loss: 0.6872089323886605
Epoch: 30 | Iteration number: [2160/4518] 47% | Training loss: 0.6872006789401726
Epoch: 30 | Iteration number: [2170/4518] 48% | Training loss: 0.6872009187799445
Epoch: 30 | Iteration number: [2180/4518] 48% | Training loss: 0.6871980245780507
Epoch: 30 | Iteration number: [2190/4518] 48% | Training loss: 0.6871910870075226
Epoch: 30 | Iteration number: [2200/4518] 48% | Training loss: 0.6871885393695398
Epoch: 30 | Iteration number: [2210/4518] 48% | Training loss: 0.6871882289243499
Epoch: 30 | Iteration number: [2220/4518] 49% | Training loss: 0.6871919190829938
Epoch: 30 | Iteration number: [2230/4518] 49% | Training loss: 0.6871890788121073
Epoch: 30 | Iteration number: [2240/4518] 49% | Training loss: 0.6871845752532993
Epoch: 30 | Iteration number: [2250/4518] 49% | Training loss: 0.6871811157332526
Epoch: 30 | Iteration number: [2260/4518] 50% | Training loss: 0.687176413636292
Epoch: 30 | Iteration number: [2270/4518] 50% | Training loss: 0.6871758990613375
Epoch: 30 | Iteration number: [2280/4518] 50% | Training loss: 0.6871756671813496
Epoch: 30 | Iteration number: [2290/4518] 50% | Training loss: 0.6871696667639969
Epoch: 30 | Iteration number: [2300/4518] 50% | Training loss: 0.6871650421360265
Epoch: 30 | Iteration number: [2310/4518] 51% | Training loss: 0.6871656834563136
Epoch: 30 | Iteration number: [2320/4518] 51% | Training loss: 0.6871651310088306
Epoch: 30 | Iteration number: [2330/4518] 51% | Training loss: 0.6871682847518266
Epoch: 30 | Iteration number: [2340/4518] 51% | Training loss: 0.6871686954783578
Epoch: 30 | Iteration number: [2350/4518] 52% | Training loss: 0.6871652096129478
Epoch: 30 | Iteration number: [2360/4518] 52% | Training loss: 0.6871685396059085
Epoch: 30 | Iteration number: [2370/4518] 52% | Training loss: 0.6871696188228543
Epoch: 30 | Iteration number: [2380/4518] 52% | Training loss: 0.6871636638621322
Epoch: 30 | Iteration number: [2390/4518] 52% | Training loss: 0.6871613335160531
Epoch: 30 | Iteration number: [2400/4518] 53% | Training loss: 0.687161142528057
Epoch: 30 | Iteration number: [2410/4518] 53% | Training loss: 0.6871661116968052
Epoch: 30 | Iteration number: [2420/4518] 53% | Training loss: 0.6871637486968158
Epoch: 30 | Iteration number: [2430/4518] 53% | Training loss: 0.6871596279948827
Epoch: 30 | Iteration number: [2440/4518] 54% | Training loss: 0.6871598520728408
Epoch: 30 | Iteration number: [2450/4518] 54% | Training loss: 0.6871642944520834
Epoch: 30 | Iteration number: [2460/4518] 54% | Training loss: 0.6871612116573302
Epoch: 30 | Iteration number: [2470/4518] 54% | Training loss: 0.6871558542434986
Epoch: 30 | Iteration number: [2480/4518] 54% | Training loss: 0.6871489535656667
Epoch: 30 | Iteration number: [2490/4518] 55% | Training loss: 0.6871489396535728
Epoch: 30 | Iteration number: [2500/4518] 55% | Training loss: 0.687142548418045
Epoch: 30 | Iteration number: [2510/4518] 55% | Training loss: 0.6871357116803705
Epoch: 30 | Iteration number: [2520/4518] 55% | Training loss: 0.6871345980063317
Epoch: 30 | Iteration number: [2530/4518] 55% | Training loss: 0.6871347615134574
Epoch: 30 | Iteration number: [2540/4518] 56% | Training loss: 0.6871316045053362
Epoch: 30 | Iteration number: [2550/4518] 56% | Training loss: 0.6871272337904163
Epoch: 30 | Iteration number: [2560/4518] 56% | Training loss: 0.6871196200372651
Epoch: 30 | Iteration number: [2570/4518] 56% | Training loss: 0.6871179682735339
Epoch: 30 | Iteration number: [2580/4518] 57% | Training loss: 0.6871176087810088
Epoch: 30 | Iteration number: [2590/4518] 57% | Training loss: 0.687115313785877
Epoch: 30 | Iteration number: [2600/4518] 57% | Training loss: 0.6871171657167948
Epoch: 30 | Iteration number: [2610/4518] 57% | Training loss: 0.6871171441571465
Epoch: 30 | Iteration number: [2620/4518] 57% | Training loss: 0.687116790159058
Epoch: 30 | Iteration number: [2630/4518] 58% | Training loss: 0.6871155247488856
Epoch: 30 | Iteration number: [2640/4518] 58% | Training loss: 0.6871110628048579
Epoch: 30 | Iteration number: [2650/4518] 58% | Training loss: 0.6871093952430869
Epoch: 30 | Iteration number: [2660/4518] 58% | Training loss: 0.687103906072172
Epoch: 30 | Iteration number: [2670/4518] 59% | Training loss: 0.6871064408664846
Epoch: 30 | Iteration number: [2680/4518] 59% | Training loss: 0.6871023707425417
Epoch: 30 | Iteration number: [2690/4518] 59% | Training loss: 0.6871039885570569
Epoch: 30 | Iteration number: [2700/4518] 59% | Training loss: 0.687103167352853
Epoch: 30 | Iteration number: [2710/4518] 59% | Training loss: 0.6870995705637984
Epoch: 30 | Iteration number: [2720/4518] 60% | Training loss: 0.6870968468048994
Epoch: 30 | Iteration number: [2730/4518] 60% | Training loss: 0.6870985784591772
Epoch: 30 | Iteration number: [2740/4518] 60% | Training loss: 0.6870975976442769
Epoch: 30 | Iteration number: [2750/4518] 60% | Training loss: 0.6870983688397841
Epoch: 30 | Iteration number: [2760/4518] 61% | Training loss: 0.68709715285163
Epoch: 30 | Iteration number: [2770/4518] 61% | Training loss: 0.6870948352753471
Epoch: 30 | Iteration number: [2780/4518] 61% | Training loss: 0.6870942926235336
Epoch: 30 | Iteration number: [2790/4518] 61% | Training loss: 0.6870916192463222
Epoch: 30 | Iteration number: [2800/4518] 61% | Training loss: 0.6870926760988576
Epoch: 30 | Iteration number: [2810/4518] 62% | Training loss: 0.6870868024028493
Epoch: 30 | Iteration number: [2820/4518] 62% | Training loss: 0.6870849004239901
Epoch: 30 | Iteration number: [2830/4518] 62% | Training loss: 0.6870773834811503
Epoch: 30 | Iteration number: [2840/4518] 62% | Training loss: 0.687075201474445
Epoch: 30 | Iteration number: [2850/4518] 63% | Training loss: 0.6870767360193688
Epoch: 30 | Iteration number: [2860/4518] 63% | Training loss: 0.687076128821273
Epoch: 30 | Iteration number: [2870/4518] 63% | Training loss: 0.6870754420549612
Epoch: 30 | Iteration number: [2880/4518] 63% | Training loss: 0.6870779496307174
Epoch: 30 | Iteration number: [2890/4518] 63% | Training loss: 0.6870789706500756
Epoch: 30 | Iteration number: [2900/4518] 64% | Training loss: 0.6870778258504538
Epoch: 30 | Iteration number: [2910/4518] 64% | Training loss: 0.6870805573832128
Epoch: 30 | Iteration number: [2920/4518] 64% | Training loss: 0.6870766475796699
Epoch: 30 | Iteration number: [2930/4518] 64% | Training loss: 0.6870757385528942
Epoch: 30 | Iteration number: [2940/4518] 65% | Training loss: 0.6870751324559555
Epoch: 30 | Iteration number: [2950/4518] 65% | Training loss: 0.6870738012103711
Epoch: 30 | Iteration number: [2960/4518] 65% | Training loss: 0.6870802767977521
Epoch: 30 | Iteration number: [2970/4518] 65% | Training loss: 0.6870773006368567
Epoch: 30 | Iteration number: [2980/4518] 65% | Training loss: 0.6870765355809423
Epoch: 30 | Iteration number: [2990/4518] 66% | Training loss: 0.6870697670357682
Epoch: 30 | Iteration number: [3000/4518] 66% | Training loss: 0.6870653719305992
Epoch: 30 | Iteration number: [3010/4518] 66% | Training loss: 0.6870645861689039
Epoch: 30 | Iteration number: [3020/4518] 66% | Training loss: 0.6870654523570017
Epoch: 30 | Iteration number: [3030/4518] 67% | Training loss: 0.6870641612770534
Epoch: 30 | Iteration number: [3040/4518] 67% | Training loss: 0.6870648506636682
Epoch: 30 | Iteration number: [3050/4518] 67% | Training loss: 0.6870639970849772
Epoch: 30 | Iteration number: [3060/4518] 67% | Training loss: 0.6870642812033884
Epoch: 30 | Iteration number: [3070/4518] 67% | Training loss: 0.6870598217175139
Epoch: 30 | Iteration number: [3080/4518] 68% | Training loss: 0.6870594441310152
Epoch: 30 | Iteration number: [3090/4518] 68% | Training loss: 0.6870610211852299
Epoch: 30 | Iteration number: [3100/4518] 68% | Training loss: 0.6870592782766588
Epoch: 30 | Iteration number: [3110/4518] 68% | Training loss: 0.6870567700870551
Epoch: 30 | Iteration number: [3120/4518] 69% | Training loss: 0.6870559446704694
Epoch: 30 | Iteration number: [3130/4518] 69% | Training loss: 0.6870567650459826
Epoch: 30 | Iteration number: [3140/4518] 69% | Training loss: 0.6870554660725745
Epoch: 30 | Iteration number: [3150/4518] 69% | Training loss: 0.6870552551367927
Epoch: 30 | Iteration number: [3160/4518] 69% | Training loss: 0.6870558487840845
Epoch: 30 | Iteration number: [3170/4518] 70% | Training loss: 0.6870531209259755
Epoch: 30 | Iteration number: [3180/4518] 70% | Training loss: 0.6870519013149933
Epoch: 30 | Iteration number: [3190/4518] 70% | Training loss: 0.687047068639235
Epoch: 30 | Iteration number: [3200/4518] 70% | Training loss: 0.6870462069660426
Epoch: 30 | Iteration number: [3210/4518] 71% | Training loss: 0.6870449777704162
Epoch: 30 | Iteration number: [3220/4518] 71% | Training loss: 0.6870469672339303
Epoch: 30 | Iteration number: [3230/4518] 71% | Training loss: 0.687046889771618
Epoch: 30 | Iteration number: [3240/4518] 71% | Training loss: 0.6870419051176236
Epoch: 30 | Iteration number: [3250/4518] 71% | Training loss: 0.6870357940013592
Epoch: 30 | Iteration number: [3260/4518] 72% | Training loss: 0.6870310292836347
Epoch: 30 | Iteration number: [3270/4518] 72% | Training loss: 0.6870312247618987
Epoch: 30 | Iteration number: [3280/4518] 72% | Training loss: 0.6870272622966185
Epoch: 30 | Iteration number: [3290/4518] 72% | Training loss: 0.687024385316756
Epoch: 30 | Iteration number: [3300/4518] 73% | Training loss: 0.6870269057064345
Epoch: 30 | Iteration number: [3310/4518] 73% | Training loss: 0.6870241168042324
Epoch: 30 | Iteration number: [3320/4518] 73% | Training loss: 0.6870221569954631
Epoch: 30 | Iteration number: [3330/4518] 73% | Training loss: 0.6870201020985395
Epoch: 30 | Iteration number: [3340/4518] 73% | Training loss: 0.6870226114452956
Epoch: 30 | Iteration number: [3350/4518] 74% | Training loss: 0.6870198318673604
Epoch: 30 | Iteration number: [3360/4518] 74% | Training loss: 0.6870201474144345
Epoch: 30 | Iteration number: [3370/4518] 74% | Training loss: 0.6870179751860281
Epoch: 30 | Iteration number: [3380/4518] 74% | Training loss: 0.6870157732766056
Epoch: 30 | Iteration number: [3390/4518] 75% | Training loss: 0.687014343534599
Epoch: 30 | Iteration number: [3400/4518] 75% | Training loss: 0.6870109290235182
Epoch: 30 | Iteration number: [3410/4518] 75% | Training loss: 0.6870090306679175
Epoch: 30 | Iteration number: [3420/4518] 75% | Training loss: 0.6870080613079127
Epoch: 30 | Iteration number: [3430/4518] 75% | Training loss: 0.6870084393823808
Epoch: 30 | Iteration number: [3440/4518] 76% | Training loss: 0.6870054186949897
Epoch: 30 | Iteration number: [3450/4518] 76% | Training loss: 0.6870038428168366
Epoch: 30 | Iteration number: [3460/4518] 76% | Training loss: 0.6870047607518345
Epoch: 30 | Iteration number: [3470/4518] 76% | Training loss: 0.6870070412969727
Epoch: 30 | Iteration number: [3480/4518] 77% | Training loss: 0.6870099470361896
Epoch: 30 | Iteration number: [3490/4518] 77% | Training loss: 0.6870093025416563
Epoch: 30 | Iteration number: [3500/4518] 77% | Training loss: 0.6870105026108878
Epoch: 30 | Iteration number: [3510/4518] 77% | Training loss: 0.6870045679077463
Epoch: 30 | Iteration number: [3520/4518] 77% | Training loss: 0.687006720087745
Epoch: 30 | Iteration number: [3530/4518] 78% | Training loss: 0.6870058419684175
Epoch: 30 | Iteration number: [3540/4518] 78% | Training loss: 0.6870032930273121
Epoch: 30 | Iteration number: [3550/4518] 78% | Training loss: 0.6870050908814014
Epoch: 30 | Iteration number: [3560/4518] 78% | Training loss: 0.6870069405670917
Epoch: 30 | Iteration number: [3570/4518] 79% | Training loss: 0.6870014122220315
Epoch: 30 | Iteration number: [3580/4518] 79% | Training loss: 0.6869993208673413
Epoch: 30 | Iteration number: [3590/4518] 79% | Training loss: 0.6869986662957661
Epoch: 30 | Iteration number: [3600/4518] 79% | Training loss: 0.6869987290766504
Epoch: 30 | Iteration number: [3610/4518] 79% | Training loss: 0.6869987597756109
Epoch: 30 | Iteration number: [3620/4518] 80% | Training loss: 0.6869938497385267
Epoch: 30 | Iteration number: [3630/4518] 80% | Training loss: 0.6869948009978313
Epoch: 30 | Iteration number: [3640/4518] 80% | Training loss: 0.6869957889174367
Epoch: 30 | Iteration number: [3650/4518] 80% | Training loss: 0.6869975992588148
Epoch: 30 | Iteration number: [3660/4518] 81% | Training loss: 0.6869996432398187
Epoch: 30 | Iteration number: [3670/4518] 81% | Training loss: 0.6870021546731528
Epoch: 30 | Iteration number: [3680/4518] 81% | Training loss: 0.6869974417045065
Epoch: 30 | Iteration number: [3690/4518] 81% | Training loss: 0.6870006733470493
Epoch: 30 | Iteration number: [3700/4518] 81% | Training loss: 0.6870003241300583
Epoch: 30 | Iteration number: [3710/4518] 82% | Training loss: 0.6869999430250286
Epoch: 30 | Iteration number: [3720/4518] 82% | Training loss: 0.6869989142302544
Epoch: 30 | Iteration number: [3730/4518] 82% | Training loss: 0.6869991127990845
Epoch: 30 | Iteration number: [3740/4518] 82% | Training loss: 0.6870006860896228
Epoch: 30 | Iteration number: [3750/4518] 83% | Training loss: 0.6870040695985158
Epoch: 30 | Iteration number: [3760/4518] 83% | Training loss: 0.6870044922099469
Epoch: 30 | Iteration number: [3770/4518] 83% | Training loss: 0.6870021039358185
Epoch: 30 | Iteration number: [3780/4518] 83% | Training loss: 0.6869981486645956
Epoch: 30 | Iteration number: [3790/4518] 83% | Training loss: 0.6869984798192349
Epoch: 30 | Iteration number: [3800/4518] 84% | Training loss: 0.6869991570397427
Epoch: 30 | Iteration number: [3810/4518] 84% | Training loss: 0.6869973964109195
Epoch: 30 | Iteration number: [3820/4518] 84% | Training loss: 0.6869982705222375
Epoch: 30 | Iteration number: [3830/4518] 84% | Training loss: 0.6869994313536363
Epoch: 30 | Iteration number: [3840/4518] 84% | Training loss: 0.6870018750429153
Epoch: 30 | Iteration number: [3850/4518] 85% | Training loss: 0.6870020178076509
Epoch: 30 | Iteration number: [3860/4518] 85% | Training loss: 0.6870048153276889
Epoch: 30 | Iteration number: [3870/4518] 85% | Training loss: 0.6870051278778441
Epoch: 30 | Iteration number: [3880/4518] 85% | Training loss: 0.6870070427195313
Epoch: 30 | Iteration number: [3890/4518] 86% | Training loss: 0.6870102892344899
Epoch: 30 | Iteration number: [3900/4518] 86% | Training loss: 0.6870125499596963
Epoch: 30 | Iteration number: [3910/4518] 86% | Training loss: 0.6870113956958741
Epoch: 30 | Iteration number: [3920/4518] 86% | Training loss: 0.6870125579894806
Epoch: 30 | Iteration number: [3930/4518] 86% | Training loss: 0.6870140082660219
Epoch: 30 | Iteration number: [3940/4518] 87% | Training loss: 0.6870134293579208
Epoch: 30 | Iteration number: [3950/4518] 87% | Training loss: 0.687012395904034
Epoch: 30 | Iteration number: [3960/4518] 87% | Training loss: 0.6870152980540738
Epoch: 30 | Iteration number: [3970/4518] 87% | Training loss: 0.6870159939944894
Epoch: 30 | Iteration number: [3980/4518] 88% | Training loss: 0.6870114867261906
Epoch: 30 | Iteration number: [3990/4518] 88% | Training loss: 0.6870139976790675
Epoch: 30 | Iteration number: [4000/4518] 88% | Training loss: 0.6870162661522626
Epoch: 30 | Iteration number: [4010/4518] 88% | Training loss: 0.6870118521246826
Epoch: 30 | Iteration number: [4020/4518] 88% | Training loss: 0.6870106426341024
Epoch: 30 | Iteration number: [4030/4518] 89% | Training loss: 0.6870109296909929
Epoch: 30 | Iteration number: [4040/4518] 89% | Training loss: 0.687011680198778
Epoch: 30 | Iteration number: [4050/4518] 89% | Training loss: 0.6870101133393652
Epoch: 30 | Iteration number: [4060/4518] 89% | Training loss: 0.687009032973515
Epoch: 30 | Iteration number: [4070/4518] 90% | Training loss: 0.6870117716619365
Epoch: 30 | Iteration number: [4080/4518] 90% | Training loss: 0.6870131274356561
Epoch: 30 | Iteration number: [4090/4518] 90% | Training loss: 0.6870138759572232
Epoch: 30 | Iteration number: [4100/4518] 90% | Training loss: 0.6870161606625813
Epoch: 30 | Iteration number: [4110/4518] 90% | Training loss: 0.6870167929180637
Epoch: 30 | Iteration number: [4120/4518] 91% | Training loss: 0.6870159080740318
Epoch: 30 | Iteration number: [4130/4518] 91% | Training loss: 0.6870147028067499
Epoch: 30 | Iteration number: [4140/4518] 91% | Training loss: 0.6870159644003652
Epoch: 30 | Iteration number: [4150/4518] 91% | Training loss: 0.6870125438506345
Epoch: 30 | Iteration number: [4160/4518] 92% | Training loss: 0.6870094849942968
Epoch: 30 | Iteration number: [4170/4518] 92% | Training loss: 0.6870100902853538
Epoch: 30 | Iteration number: [4180/4518] 92% | Training loss: 0.6870098133834355
Epoch: 30 | Iteration number: [4190/4518] 92% | Training loss: 0.6870088484662814
Epoch: 30 | Iteration number: [4200/4518] 92% | Training loss: 0.687010261288711
Epoch: 30 | Iteration number: [4210/4518] 93% | Training loss: 0.6870120707855089
Epoch: 30 | Iteration number: [4220/4518] 93% | Training loss: 0.6870094524175635
Epoch: 30 | Iteration number: [4230/4518] 93% | Training loss: 0.6870088978580268
Epoch: 30 | Iteration number: [4240/4518] 93% | Training loss: 0.687008503234049
Epoch: 30 | Iteration number: [4250/4518] 94% | Training loss: 0.6870039634985082
Epoch: 30 | Iteration number: [4260/4518] 94% | Training loss: 0.6870035065731532
Epoch: 30 | Iteration number: [4270/4518] 94% | Training loss: 0.6870052586394674
Epoch: 30 | Iteration number: [4280/4518] 94% | Training loss: 0.6870069809745405
Epoch: 30 | Iteration number: [4290/4518] 94% | Training loss: 0.6870096867734735
Epoch: 30 | Iteration number: [4300/4518] 95% | Training loss: 0.687009783026784
Epoch: 30 | Iteration number: [4310/4518] 95% | Training loss: 0.6870094148299534
Epoch: 30 | Iteration number: [4320/4518] 95% | Training loss: 0.6870087918721968
Epoch: 30 | Iteration number: [4330/4518] 95% | Training loss: 0.6870067086010552
Epoch: 30 | Iteration number: [4340/4518] 96% | Training loss: 0.6870053754012156
Epoch: 30 | Iteration number: [4350/4518] 96% | Training loss: 0.6870060862206865
Epoch: 30 | Iteration number: [4360/4518] 96% | Training loss: 0.6870061059200435
Epoch: 30 | Iteration number: [4370/4518] 96% | Training loss: 0.6870046311985164
Epoch: 30 | Iteration number: [4380/4518] 96% | Training loss: 0.6870009807555099
Epoch: 30 | Iteration number: [4390/4518] 97% | Training loss: 0.6870014417687418
Epoch: 30 | Iteration number: [4400/4518] 97% | Training loss: 0.6870037412914363
Epoch: 30 | Iteration number: [4410/4518] 97% | Training loss: 0.6870025397157994
Epoch: 30 | Iteration number: [4420/4518] 97% | Training loss: 0.6870028617560054
Epoch: 30 | Iteration number: [4430/4518] 98% | Training loss: 0.6869999408183733
Epoch: 30 | Iteration number: [4440/4518] 98% | Training loss: 0.6869996164430369
Epoch: 30 | Iteration number: [4450/4518] 98% | Training loss: 0.6869990737116739
Epoch: 30 | Iteration number: [4460/4518] 98% | Training loss: 0.6869948603647172
Epoch: 30 | Iteration number: [4470/4518] 98% | Training loss: 0.6869933960688461
Epoch: 30 | Iteration number: [4480/4518] 99% | Training loss: 0.6869965034403971
Epoch: 30 | Iteration number: [4490/4518] 99% | Training loss: 0.6869974274943295
Epoch: 30 | Iteration number: [4500/4518] 99% | Training loss: 0.6869970884720484
Epoch: 30 | Iteration number: [4510/4518] 99% | Training loss: 0.6869979464954917

 End of epoch: 30 | Train Loss: 0.6868481181690576 | Training Time: 632 

 End of epoch: 30 | Eval Loss: 0.6899514453751701 | Evaluating Time: 17 
Epoch: 31 | Iteration number: [10/4518] 0% | Training loss: 0.7555442869663238
Epoch: 31 | Iteration number: [20/4518] 0% | Training loss: 0.721060836315155
Epoch: 31 | Iteration number: [30/4518] 0% | Training loss: 0.709733776251475
Epoch: 31 | Iteration number: [40/4518] 0% | Training loss: 0.7040896773338318
Epoch: 31 | Iteration number: [50/4518] 1% | Training loss: 0.7007789969444275
Epoch: 31 | Iteration number: [60/4518] 1% | Training loss: 0.6984608550866445
Epoch: 31 | Iteration number: [70/4518] 1% | Training loss: 0.696726621048791
Epoch: 31 | Iteration number: [80/4518] 1% | Training loss: 0.6953857213258743
Epoch: 31 | Iteration number: [90/4518] 1% | Training loss: 0.6943056874805027
Epoch: 31 | Iteration number: [100/4518] 2% | Training loss: 0.693562273979187
Epoch: 31 | Iteration number: [110/4518] 2% | Training loss: 0.6928082498637113
Epoch: 31 | Iteration number: [120/4518] 2% | Training loss: 0.692314013838768
Epoch: 31 | Iteration number: [130/4518] 2% | Training loss: 0.691894099345574
Epoch: 31 | Iteration number: [140/4518] 3% | Training loss: 0.6914989986589977
Epoch: 31 | Iteration number: [150/4518] 3% | Training loss: 0.6913220342000326
Epoch: 31 | Iteration number: [160/4518] 3% | Training loss: 0.691091251000762
Epoch: 31 | Iteration number: [170/4518] 3% | Training loss: 0.6908784494680517
Epoch: 31 | Iteration number: [180/4518] 3% | Training loss: 0.6906590229935117
Epoch: 31 | Iteration number: [190/4518] 4% | Training loss: 0.6903421797250446
Epoch: 31 | Iteration number: [200/4518] 4% | Training loss: 0.6901399844884872
Epoch: 31 | Iteration number: [210/4518] 4% | Training loss: 0.6898961808000292
Epoch: 31 | Iteration number: [220/4518] 4% | Training loss: 0.6897146585312757
Epoch: 31 | Iteration number: [230/4518] 5% | Training loss: 0.6895984079526818
Epoch: 31 | Iteration number: [240/4518] 5% | Training loss: 0.6894088767468929
Epoch: 31 | Iteration number: [250/4518] 5% | Training loss: 0.6893053891658782
Epoch: 31 | Iteration number: [260/4518] 5% | Training loss: 0.6892397630673188
Epoch: 31 | Iteration number: [270/4518] 5% | Training loss: 0.6890753185307538
Epoch: 31 | Iteration number: [280/4518] 6% | Training loss: 0.6890166829739298
Epoch: 31 | Iteration number: [290/4518] 6% | Training loss: 0.688941829368986
Epoch: 31 | Iteration number: [300/4518] 6% | Training loss: 0.6889175204435984
Epoch: 31 | Iteration number: [310/4518] 6% | Training loss: 0.6888415507731899
Epoch: 31 | Iteration number: [320/4518] 7% | Training loss: 0.6887577645480633
Epoch: 31 | Iteration number: [330/4518] 7% | Training loss: 0.6886823571089542
Epoch: 31 | Iteration number: [340/4518] 7% | Training loss: 0.6886531417860704
Epoch: 31 | Iteration number: [350/4518] 7% | Training loss: 0.6885993254184722
Epoch: 31 | Iteration number: [360/4518] 7% | Training loss: 0.6885476190182898
Epoch: 31 | Iteration number: [370/4518] 8% | Training loss: 0.6885216205506711
Epoch: 31 | Iteration number: [380/4518] 8% | Training loss: 0.6884519208418696
Epoch: 31 | Iteration number: [390/4518] 8% | Training loss: 0.6884071700083904
Epoch: 31 | Iteration number: [400/4518] 8% | Training loss: 0.6883239810168743
Epoch: 31 | Iteration number: [410/4518] 9% | Training loss: 0.6882661297553923
Epoch: 31 | Iteration number: [420/4518] 9% | Training loss: 0.6882585908685411
Epoch: 31 | Iteration number: [430/4518] 9% | Training loss: 0.688218876927398
Epoch: 31 | Iteration number: [440/4518] 9% | Training loss: 0.6881869142705744
Epoch: 31 | Iteration number: [450/4518] 9% | Training loss: 0.6881701993942261
Epoch: 31 | Iteration number: [460/4518] 10% | Training loss: 0.6881316038577453
Epoch: 31 | Iteration number: [470/4518] 10% | Training loss: 0.688120040868191
Epoch: 31 | Iteration number: [480/4518] 10% | Training loss: 0.6881143619616826
Epoch: 31 | Iteration number: [490/4518] 10% | Training loss: 0.6881204810677742
Epoch: 31 | Iteration number: [500/4518] 11% | Training loss: 0.6880986301898956
Epoch: 31 | Iteration number: [510/4518] 11% | Training loss: 0.6880769073963166
Epoch: 31 | Iteration number: [520/4518] 11% | Training loss: 0.6880440678734046
Epoch: 31 | Iteration number: [530/4518] 11% | Training loss: 0.6880203275185711
Epoch: 31 | Iteration number: [540/4518] 11% | Training loss: 0.6879989007004985
Epoch: 31 | Iteration number: [550/4518] 12% | Training loss: 0.6879758098992435
Epoch: 31 | Iteration number: [560/4518] 12% | Training loss: 0.6879529774188995
Epoch: 31 | Iteration number: [570/4518] 12% | Training loss: 0.6879431337640997
Epoch: 31 | Iteration number: [580/4518] 12% | Training loss: 0.6879272517459146
Epoch: 31 | Iteration number: [590/4518] 13% | Training loss: 0.6878947528742128
Epoch: 31 | Iteration number: [600/4518] 13% | Training loss: 0.6878766401608785
Epoch: 31 | Iteration number: [610/4518] 13% | Training loss: 0.6878384761145857
Epoch: 31 | Iteration number: [620/4518] 13% | Training loss: 0.6878215033200479
Epoch: 31 | Iteration number: [630/4518] 13% | Training loss: 0.6878107229868571
Epoch: 31 | Iteration number: [640/4518] 14% | Training loss: 0.6878186252899468
Epoch: 31 | Iteration number: [650/4518] 14% | Training loss: 0.6877825604035304
Epoch: 31 | Iteration number: [660/4518] 14% | Training loss: 0.6877561289252657
Epoch: 31 | Iteration number: [670/4518] 14% | Training loss: 0.687731091655902
Epoch: 31 | Iteration number: [680/4518] 15% | Training loss: 0.6877172839115647
Epoch: 31 | Iteration number: [690/4518] 15% | Training loss: 0.6876927734285161
Epoch: 31 | Iteration number: [700/4518] 15% | Training loss: 0.6877065143414907
Epoch: 31 | Iteration number: [710/4518] 15% | Training loss: 0.6876979789263765
Epoch: 31 | Iteration number: [720/4518] 15% | Training loss: 0.687700633621878
Epoch: 31 | Iteration number: [730/4518] 16% | Training loss: 0.6876885297363752
Epoch: 31 | Iteration number: [740/4518] 16% | Training loss: 0.6876763937441078
Epoch: 31 | Iteration number: [750/4518] 16% | Training loss: 0.6876645081043243
Epoch: 31 | Iteration number: [760/4518] 16% | Training loss: 0.6876473939732501
Epoch: 31 | Iteration number: [770/4518] 17% | Training loss: 0.6876563104716215
Epoch: 31 | Iteration number: [780/4518] 17% | Training loss: 0.6876307444694715
Epoch: 31 | Iteration number: [790/4518] 17% | Training loss: 0.6876239326181292
Epoch: 31 | Iteration number: [800/4518] 17% | Training loss: 0.6876022032648325
Epoch: 31 | Iteration number: [810/4518] 17% | Training loss: 0.6875965946986351
Epoch: 31 | Iteration number: [820/4518] 18% | Training loss: 0.687587520116713
Epoch: 31 | Iteration number: [830/4518] 18% | Training loss: 0.6875662576003247
Epoch: 31 | Iteration number: [840/4518] 18% | Training loss: 0.6875832276684898
Epoch: 31 | Iteration number: [850/4518] 18% | Training loss: 0.687575832675485
Epoch: 31 | Iteration number: [860/4518] 19% | Training loss: 0.687576438243999
Epoch: 31 | Iteration number: [870/4518] 19% | Training loss: 0.6875633407598254
Epoch: 31 | Iteration number: [880/4518] 19% | Training loss: 0.6875651889903979
Epoch: 31 | Iteration number: [890/4518] 19% | Training loss: 0.6875571325253904
Epoch: 31 | Iteration number: [900/4518] 19% | Training loss: 0.6875558394855923
Epoch: 31 | Iteration number: [910/4518] 20% | Training loss: 0.6875231138952486
Epoch: 31 | Iteration number: [920/4518] 20% | Training loss: 0.6875116984481396
Epoch: 31 | Iteration number: [930/4518] 20% | Training loss: 0.6875051795795399
Epoch: 31 | Iteration number: [940/4518] 20% | Training loss: 0.6874987708761336
Epoch: 31 | Iteration number: [950/4518] 21% | Training loss: 0.6874894778979452
Epoch: 31 | Iteration number: [960/4518] 21% | Training loss: 0.6874784165372451
Epoch: 31 | Iteration number: [970/4518] 21% | Training loss: 0.6874803014637269
Epoch: 31 | Iteration number: [980/4518] 21% | Training loss: 0.6874640405786281
Epoch: 31 | Iteration number: [990/4518] 21% | Training loss: 0.687461151017083
Epoch: 31 | Iteration number: [1000/4518] 22% | Training loss: 0.6874597775936127
Epoch: 31 | Iteration number: [1010/4518] 22% | Training loss: 0.6874564125986382
Epoch: 31 | Iteration number: [1020/4518] 22% | Training loss: 0.6874559089249256
Epoch: 31 | Iteration number: [1030/4518] 22% | Training loss: 0.6874543500756755
Epoch: 31 | Iteration number: [1040/4518] 23% | Training loss: 0.6874479323625564
Epoch: 31 | Iteration number: [1050/4518] 23% | Training loss: 0.6874341286364056
Epoch: 31 | Iteration number: [1060/4518] 23% | Training loss: 0.6874322370538172
Epoch: 31 | Iteration number: [1070/4518] 23% | Training loss: 0.6874241310302343
Epoch: 31 | Iteration number: [1080/4518] 23% | Training loss: 0.6874226576752133
Epoch: 31 | Iteration number: [1090/4518] 24% | Training loss: 0.6874124143648586
Epoch: 31 | Iteration number: [1100/4518] 24% | Training loss: 0.6874157045104287
Epoch: 31 | Iteration number: [1110/4518] 24% | Training loss: 0.6874180432912466
Epoch: 31 | Iteration number: [1120/4518] 24% | Training loss: 0.6873954501003027
Epoch: 31 | Iteration number: [1130/4518] 25% | Training loss: 0.6873949379520079
Epoch: 31 | Iteration number: [1140/4518] 25% | Training loss: 0.6873962181701995
Epoch: 31 | Iteration number: [1150/4518] 25% | Training loss: 0.6873893620656885
Epoch: 31 | Iteration number: [1160/4518] 25% | Training loss: 0.6873830619557151
Epoch: 31 | Iteration number: [1170/4518] 25% | Training loss: 0.6873854858243568
Epoch: 31 | Iteration number: [1180/4518] 26% | Training loss: 0.6873859770722308
Epoch: 31 | Iteration number: [1190/4518] 26% | Training loss: 0.6873870881665655
Epoch: 31 | Iteration number: [1200/4518] 26% | Training loss: 0.6873845961193243
Epoch: 31 | Iteration number: [1210/4518] 26% | Training loss: 0.6873787027745207
Epoch: 31 | Iteration number: [1220/4518] 27% | Training loss: 0.687378656619885
Epoch: 31 | Iteration number: [1230/4518] 27% | Training loss: 0.687381485564922
Epoch: 31 | Iteration number: [1240/4518] 27% | Training loss: 0.6873899650669867
Epoch: 31 | Iteration number: [1250/4518] 27% | Training loss: 0.6873939732074738
Epoch: 31 | Iteration number: [1260/4518] 27% | Training loss: 0.6873820430702633
Epoch: 31 | Iteration number: [1270/4518] 28% | Training loss: 0.6873773571543806
Epoch: 31 | Iteration number: [1280/4518] 28% | Training loss: 0.6873622453771532
Epoch: 31 | Iteration number: [1290/4518] 28% | Training loss: 0.6873625669368478
Epoch: 31 | Iteration number: [1300/4518] 28% | Training loss: 0.6873389923114043
Epoch: 31 | Iteration number: [1310/4518] 28% | Training loss: 0.6873354663375679
Epoch: 31 | Iteration number: [1320/4518] 29% | Training loss: 0.6873328177314816
Epoch: 31 | Iteration number: [1330/4518] 29% | Training loss: 0.6873278526883376
Epoch: 31 | Iteration number: [1340/4518] 29% | Training loss: 0.68732048415426
Epoch: 31 | Iteration number: [1350/4518] 29% | Training loss: 0.6873163855075837
Epoch: 31 | Iteration number: [1360/4518] 30% | Training loss: 0.6873070267631727
Epoch: 31 | Iteration number: [1370/4518] 30% | Training loss: 0.6873052640988009
Epoch: 31 | Iteration number: [1380/4518] 30% | Training loss: 0.6872977422631306
Epoch: 31 | Iteration number: [1390/4518] 30% | Training loss: 0.6872917725027894
Epoch: 31 | Iteration number: [1400/4518] 30% | Training loss: 0.6872830447554589
Epoch: 31 | Iteration number: [1410/4518] 31% | Training loss: 0.6872915843277113
Epoch: 31 | Iteration number: [1420/4518] 31% | Training loss: 0.6872811126457133
Epoch: 31 | Iteration number: [1430/4518] 31% | Training loss: 0.6872725571785774
Epoch: 31 | Iteration number: [1440/4518] 31% | Training loss: 0.6872746215926276
Epoch: 31 | Iteration number: [1450/4518] 32% | Training loss: 0.6872647347121403
Epoch: 31 | Iteration number: [1460/4518] 32% | Training loss: 0.6872686142382557
Epoch: 31 | Iteration number: [1470/4518] 32% | Training loss: 0.6872759367332978
Epoch: 31 | Iteration number: [1480/4518] 32% | Training loss: 0.6872737394796835
Epoch: 31 | Iteration number: [1490/4518] 32% | Training loss: 0.6872726895265131
Epoch: 31 | Iteration number: [1500/4518] 33% | Training loss: 0.6872761965195338
Epoch: 31 | Iteration number: [1510/4518] 33% | Training loss: 0.6872680553142598
Epoch: 31 | Iteration number: [1520/4518] 33% | Training loss: 0.6872637762835151
Epoch: 31 | Iteration number: [1530/4518] 33% | Training loss: 0.6872632241716572
Epoch: 31 | Iteration number: [1540/4518] 34% | Training loss: 0.6872556490944578
Epoch: 31 | Iteration number: [1550/4518] 34% | Training loss: 0.6872513376128289
Epoch: 31 | Iteration number: [1560/4518] 34% | Training loss: 0.6872448565104069
Epoch: 31 | Iteration number: [1570/4518] 34% | Training loss: 0.6872410089347013
Epoch: 31 | Iteration number: [1580/4518] 34% | Training loss: 0.6872346957650366
Epoch: 31 | Iteration number: [1590/4518] 35% | Training loss: 0.6872344346541279
Epoch: 31 | Iteration number: [1600/4518] 35% | Training loss: 0.6872240472957492
Epoch: 31 | Iteration number: [1610/4518] 35% | Training loss: 0.6872253519777926
Epoch: 31 | Iteration number: [1620/4518] 35% | Training loss: 0.6872263976821193
Epoch: 31 | Iteration number: [1630/4518] 36% | Training loss: 0.687228562934267
Epoch: 31 | Iteration number: [1640/4518] 36% | Training loss: 0.6872247678841032
Epoch: 31 | Iteration number: [1650/4518] 36% | Training loss: 0.687217296145179
Epoch: 31 | Iteration number: [1660/4518] 36% | Training loss: 0.687218312757561
Epoch: 31 | Iteration number: [1670/4518] 36% | Training loss: 0.6872217551319899
Epoch: 31 | Iteration number: [1680/4518] 37% | Training loss: 0.6872208318894818
Epoch: 31 | Iteration number: [1690/4518] 37% | Training loss: 0.687214411539439
Epoch: 31 | Iteration number: [1700/4518] 37% | Training loss: 0.6872176340047051
Epoch: 31 | Iteration number: [1710/4518] 37% | Training loss: 0.6872152403432723
Epoch: 31 | Iteration number: [1720/4518] 38% | Training loss: 0.687217799244925
Epoch: 31 | Iteration number: [1730/4518] 38% | Training loss: 0.6872245897102908
Epoch: 31 | Iteration number: [1740/4518] 38% | Training loss: 0.6872197315610689
Epoch: 31 | Iteration number: [1750/4518] 38% | Training loss: 0.687220977306366
Epoch: 31 | Iteration number: [1760/4518] 38% | Training loss: 0.6872142238373106
Epoch: 31 | Iteration number: [1770/4518] 39% | Training loss: 0.6872195450262835
Epoch: 31 | Iteration number: [1780/4518] 39% | Training loss: 0.687215459648143
Epoch: 31 | Iteration number: [1790/4518] 39% | Training loss: 0.6872164708609022
Epoch: 31 | Iteration number: [1800/4518] 39% | Training loss: 0.6872175096140968
Epoch: 31 | Iteration number: [1810/4518] 40% | Training loss: 0.6872172129746958
Epoch: 31 | Iteration number: [1820/4518] 40% | Training loss: 0.6872262564661739
Epoch: 31 | Iteration number: [1830/4518] 40% | Training loss: 0.6872185691783989
Epoch: 31 | Iteration number: [1840/4518] 40% | Training loss: 0.6872119187984778
Epoch: 31 | Iteration number: [1850/4518] 40% | Training loss: 0.6872131779709377
Epoch: 31 | Iteration number: [1860/4518] 41% | Training loss: 0.6872151956122409
Epoch: 31 | Iteration number: [1870/4518] 41% | Training loss: 0.6872063926515732
Epoch: 31 | Iteration number: [1880/4518] 41% | Training loss: 0.6872057756527942
Epoch: 31 | Iteration number: [1890/4518] 41% | Training loss: 0.6872031051330465
Epoch: 31 | Iteration number: [1900/4518] 42% | Training loss: 0.6871990758494327
Epoch: 31 | Iteration number: [1910/4518] 42% | Training loss: 0.6871992070013316
Epoch: 31 | Iteration number: [1920/4518] 42% | Training loss: 0.6871989518093566
Epoch: 31 | Iteration number: [1930/4518] 42% | Training loss: 0.6871944681350431
Epoch: 31 | Iteration number: [1940/4518] 42% | Training loss: 0.687195801519856
Epoch: 31 | Iteration number: [1950/4518] 43% | Training loss: 0.6871870538515923
Epoch: 31 | Iteration number: [1960/4518] 43% | Training loss: 0.6871825174713622
Epoch: 31 | Iteration number: [1970/4518] 43% | Training loss: 0.6871819720655529
Epoch: 31 | Iteration number: [1980/4518] 43% | Training loss: 0.6871817308844942
Epoch: 31 | Iteration number: [1990/4518] 44% | Training loss: 0.6871823724490315
Epoch: 31 | Iteration number: [2000/4518] 44% | Training loss: 0.6871774758398533
Epoch: 31 | Iteration number: [2010/4518] 44% | Training loss: 0.687174290507587
Epoch: 31 | Iteration number: [2020/4518] 44% | Training loss: 0.687172736714382
Epoch: 31 | Iteration number: [2030/4518] 44% | Training loss: 0.687172120016784
Epoch: 31 | Iteration number: [2040/4518] 45% | Training loss: 0.6871667952806342
Epoch: 31 | Iteration number: [2050/4518] 45% | Training loss: 0.6871679061505853
Epoch: 31 | Iteration number: [2060/4518] 45% | Training loss: 0.6871680405244086
Epoch: 31 | Iteration number: [2070/4518] 45% | Training loss: 0.6871579372652487
Epoch: 31 | Iteration number: [2080/4518] 46% | Training loss: 0.6871514458209276
Epoch: 31 | Iteration number: [2090/4518] 46% | Training loss: 0.687155934982893
Epoch: 31 | Iteration number: [2100/4518] 46% | Training loss: 0.6871515045279548
Epoch: 31 | Iteration number: [2110/4518] 46% | Training loss: 0.6871471122260342
Epoch: 31 | Iteration number: [2120/4518] 46% | Training loss: 0.6871458678313022
Epoch: 31 | Iteration number: [2130/4518] 47% | Training loss: 0.6871431374773733
Epoch: 31 | Iteration number: [2140/4518] 47% | Training loss: 0.6871489693071241
Epoch: 31 | Iteration number: [2150/4518] 47% | Training loss: 0.6871519556156425
Epoch: 31 | Iteration number: [2160/4518] 47% | Training loss: 0.6871488394284689
Epoch: 31 | Iteration number: [2170/4518] 48% | Training loss: 0.6871479530762967
Epoch: 31 | Iteration number: [2180/4518] 48% | Training loss: 0.6871515377945856
Epoch: 31 | Iteration number: [2190/4518] 48% | Training loss: 0.6871457670921605
Epoch: 31 | Iteration number: [2200/4518] 48% | Training loss: 0.6871503151546825
Epoch: 31 | Iteration number: [2210/4518] 48% | Training loss: 0.6871409663787255
Epoch: 31 | Iteration number: [2220/4518] 49% | Training loss: 0.6871390725041295
Epoch: 31 | Iteration number: [2230/4518] 49% | Training loss: 0.687140698309971
Epoch: 31 | Iteration number: [2240/4518] 49% | Training loss: 0.6871413725827421
Epoch: 31 | Iteration number: [2250/4518] 49% | Training loss: 0.6871432472334967
Epoch: 31 | Iteration number: [2260/4518] 50% | Training loss: 0.6871402829621746
Epoch: 31 | Iteration number: [2270/4518] 50% | Training loss: 0.6871333764775734
Epoch: 31 | Iteration number: [2280/4518] 50% | Training loss: 0.6871356513416558
Epoch: 31 | Iteration number: [2290/4518] 50% | Training loss: 0.6871299408929317
Epoch: 31 | Iteration number: [2300/4518] 50% | Training loss: 0.6871247786542644
Epoch: 31 | Iteration number: [2310/4518] 51% | Training loss: 0.6871273090829065
Epoch: 31 | Iteration number: [2320/4518] 51% | Training loss: 0.6871282315716661
Epoch: 31 | Iteration number: [2330/4518] 51% | Training loss: 0.6871223983079067
Epoch: 31 | Iteration number: [2340/4518] 51% | Training loss: 0.6871186894738776
Epoch: 31 | Iteration number: [2350/4518] 52% | Training loss: 0.6871222497808173
Epoch: 31 | Iteration number: [2360/4518] 52% | Training loss: 0.6871222381369543
Epoch: 31 | Iteration number: [2370/4518] 52% | Training loss: 0.6871223592556982
Epoch: 31 | Iteration number: [2380/4518] 52% | Training loss: 0.6871203724326206
Epoch: 31 | Iteration number: [2390/4518] 52% | Training loss: 0.6871231595342628
Epoch: 31 | Iteration number: [2400/4518] 53% | Training loss: 0.6871216658006112
Epoch: 31 | Iteration number: [2410/4518] 53% | Training loss: 0.6871241038518328
Epoch: 31 | Iteration number: [2420/4518] 53% | Training loss: 0.6871197735967715
Epoch: 31 | Iteration number: [2430/4518] 53% | Training loss: 0.6871191754262633
Epoch: 31 | Iteration number: [2440/4518] 54% | Training loss: 0.687120520702151
Epoch: 31 | Iteration number: [2450/4518] 54% | Training loss: 0.6871220868460987
Epoch: 31 | Iteration number: [2460/4518] 54% | Training loss: 0.6871196606779486
Epoch: 31 | Iteration number: [2470/4518] 54% | Training loss: 0.6871191134095674
Epoch: 31 | Iteration number: [2480/4518] 54% | Training loss: 0.6871164058966022
Epoch: 31 | Iteration number: [2490/4518] 55% | Training loss: 0.6871184887895623
Epoch: 31 | Iteration number: [2500/4518] 55% | Training loss: 0.6871170534133911
Epoch: 31 | Iteration number: [2510/4518] 55% | Training loss: 0.6871188895873339
Epoch: 31 | Iteration number: [2520/4518] 55% | Training loss: 0.6871173316287615
Epoch: 31 | Iteration number: [2530/4518] 55% | Training loss: 0.6871192112741734
Epoch: 31 | Iteration number: [2540/4518] 56% | Training loss: 0.6871219002355741
Epoch: 31 | Iteration number: [2550/4518] 56% | Training loss: 0.6871195673475079
Epoch: 31 | Iteration number: [2560/4518] 56% | Training loss: 0.687116272491403
Epoch: 31 | Iteration number: [2570/4518] 56% | Training loss: 0.6871189014689004
Epoch: 31 | Iteration number: [2580/4518] 57% | Training loss: 0.6871187825535618
Epoch: 31 | Iteration number: [2590/4518] 57% | Training loss: 0.6871180889689325
Epoch: 31 | Iteration number: [2600/4518] 57% | Training loss: 0.6871194680378987
Epoch: 31 | Iteration number: [2610/4518] 57% | Training loss: 0.6871192777522223
Epoch: 31 | Iteration number: [2620/4518] 57% | Training loss: 0.687117152769147
Epoch: 31 | Iteration number: [2630/4518] 58% | Training loss: 0.6871164394422176
Epoch: 31 | Iteration number: [2640/4518] 58% | Training loss: 0.6871156676474846
Epoch: 31 | Iteration number: [2650/4518] 58% | Training loss: 0.68711739645814
Epoch: 31 | Iteration number: [2660/4518] 58% | Training loss: 0.6871165709387987
Epoch: 31 | Iteration number: [2670/4518] 59% | Training loss: 0.6871162154924557
Epoch: 31 | Iteration number: [2680/4518] 59% | Training loss: 0.6871163705391671
Epoch: 31 | Iteration number: [2690/4518] 59% | Training loss: 0.6871123253856006
Epoch: 31 | Iteration number: [2700/4518] 59% | Training loss: 0.6871097066667344
Epoch: 31 | Iteration number: [2710/4518] 59% | Training loss: 0.6871096625539209
Epoch: 31 | Iteration number: [2720/4518] 60% | Training loss: 0.6871057046029497
Epoch: 31 | Iteration number: [2730/4518] 60% | Training loss: 0.6871050309567225
Epoch: 31 | Iteration number: [2740/4518] 60% | Training loss: 0.6871088974232221
Epoch: 31 | Iteration number: [2750/4518] 60% | Training loss: 0.6871065749471837
Epoch: 31 | Iteration number: [2760/4518] 61% | Training loss: 0.6871051933238472
Epoch: 31 | Iteration number: [2770/4518] 61% | Training loss: 0.6871065687831989
Epoch: 31 | Iteration number: [2780/4518] 61% | Training loss: 0.6871076985872049
Epoch: 31 | Iteration number: [2790/4518] 61% | Training loss: 0.6871080892487667
Epoch: 31 | Iteration number: [2800/4518] 61% | Training loss: 0.6871080051788262
Epoch: 31 | Iteration number: [2810/4518] 62% | Training loss: 0.6871076834795738
Epoch: 31 | Iteration number: [2820/4518] 62% | Training loss: 0.6871084560527869
Epoch: 31 | Iteration number: [2830/4518] 62% | Training loss: 0.6871042341520424
Epoch: 31 | Iteration number: [2840/4518] 62% | Training loss: 0.6871003478975363
Epoch: 31 | Iteration number: [2850/4518] 63% | Training loss: 0.6871009931438847
Epoch: 31 | Iteration number: [2860/4518] 63% | Training loss: 0.6870948938639847
Epoch: 31 | Iteration number: [2870/4518] 63% | Training loss: 0.6870942538000565
Epoch: 31 | Iteration number: [2880/4518] 63% | Training loss: 0.6870958077617817
Epoch: 31 | Iteration number: [2890/4518] 63% | Training loss: 0.6870891036253074
Epoch: 31 | Iteration number: [2900/4518] 64% | Training loss: 0.6870888027857089
Epoch: 31 | Iteration number: [2910/4518] 64% | Training loss: 0.6870898905693461
Epoch: 31 | Iteration number: [2920/4518] 64% | Training loss: 0.6870899687891137
Epoch: 31 | Iteration number: [2930/4518] 64% | Training loss: 0.6870880458542105
Epoch: 31 | Iteration number: [2940/4518] 65% | Training loss: 0.6870867112664139
Epoch: 31 | Iteration number: [2950/4518] 65% | Training loss: 0.6870842216378551
Epoch: 31 | Iteration number: [2960/4518] 65% | Training loss: 0.6870859926214089
Epoch: 31 | Iteration number: [2970/4518] 65% | Training loss: 0.6870847225389898
Epoch: 31 | Iteration number: [2980/4518] 65% | Training loss: 0.6870792130895909
Epoch: 31 | Iteration number: [2990/4518] 66% | Training loss: 0.6870739215193784
Epoch: 31 | Iteration number: [3000/4518] 66% | Training loss: 0.6870738250414531
Epoch: 31 | Iteration number: [3010/4518] 66% | Training loss: 0.6870750063875585
Epoch: 31 | Iteration number: [3020/4518] 66% | Training loss: 0.6870701935709707
Epoch: 31 | Iteration number: [3030/4518] 67% | Training loss: 0.6870702041061011
Epoch: 31 | Iteration number: [3040/4518] 67% | Training loss: 0.6870668644967832
Epoch: 31 | Iteration number: [3050/4518] 67% | Training loss: 0.6870666944589772
Epoch: 31 | Iteration number: [3060/4518] 67% | Training loss: 0.6870657254667843
Epoch: 31 | Iteration number: [3070/4518] 67% | Training loss: 0.6870663262733807
Epoch: 31 | Iteration number: [3080/4518] 68% | Training loss: 0.6870597269627955
Epoch: 31 | Iteration number: [3090/4518] 68% | Training loss: 0.6870546863881516
Epoch: 31 | Iteration number: [3100/4518] 68% | Training loss: 0.687056328385107
Epoch: 31 | Iteration number: [3110/4518] 68% | Training loss: 0.6870570990241992
Epoch: 31 | Iteration number: [3120/4518] 69% | Training loss: 0.6870559385762764
Epoch: 31 | Iteration number: [3130/4518] 69% | Training loss: 0.6870567191903965
Epoch: 31 | Iteration number: [3140/4518] 69% | Training loss: 0.6870556032961341
Epoch: 31 | Iteration number: [3150/4518] 69% | Training loss: 0.6870546700462462
Epoch: 31 | Iteration number: [3160/4518] 69% | Training loss: 0.6870551881345013
Epoch: 31 | Iteration number: [3170/4518] 70% | Training loss: 0.68704984616782
Epoch: 31 | Iteration number: [3180/4518] 70% | Training loss: 0.6870544079902037
Epoch: 31 | Iteration number: [3190/4518] 70% | Training loss: 0.6870541383480203
Epoch: 31 | Iteration number: [3200/4518] 70% | Training loss: 0.6870508680306375
Epoch: 31 | Iteration number: [3210/4518] 71% | Training loss: 0.6870464337949069
Epoch: 31 | Iteration number: [3220/4518] 71% | Training loss: 0.6870484619592288
Epoch: 31 | Iteration number: [3230/4518] 71% | Training loss: 0.6870497969466466
Epoch: 31 | Iteration number: [3240/4518] 71% | Training loss: 0.6870519700793573
Epoch: 31 | Iteration number: [3250/4518] 71% | Training loss: 0.6870495568788969
Epoch: 31 | Iteration number: [3260/4518] 72% | Training loss: 0.68704862848747
Epoch: 31 | Iteration number: [3270/4518] 72% | Training loss: 0.687051870899463
Epoch: 31 | Iteration number: [3280/4518] 72% | Training loss: 0.6870503508099696
Epoch: 31 | Iteration number: [3290/4518] 72% | Training loss: 0.6870509458167937
Epoch: 31 | Iteration number: [3300/4518] 73% | Training loss: 0.687052461215944
Epoch: 31 | Iteration number: [3310/4518] 73% | Training loss: 0.6870558370636309
Epoch: 31 | Iteration number: [3320/4518] 73% | Training loss: 0.6870571575430502
Epoch: 31 | Iteration number: [3330/4518] 73% | Training loss: 0.687055519124767
Epoch: 31 | Iteration number: [3340/4518] 73% | Training loss: 0.6870553809190225
Epoch: 31 | Iteration number: [3350/4518] 74% | Training loss: 0.6870555506179582
Epoch: 31 | Iteration number: [3360/4518] 74% | Training loss: 0.687057451531291
Epoch: 31 | Iteration number: [3370/4518] 74% | Training loss: 0.6870579365983561
Epoch: 31 | Iteration number: [3380/4518] 74% | Training loss: 0.6870584531824969
Epoch: 31 | Iteration number: [3390/4518] 75% | Training loss: 0.6870533682779577
Epoch: 31 | Iteration number: [3400/4518] 75% | Training loss: 0.687052811384201
Epoch: 31 | Iteration number: [3410/4518] 75% | Training loss: 0.6870536712956918
Epoch: 31 | Iteration number: [3420/4518] 75% | Training loss: 0.6870522108517195
Epoch: 31 | Iteration number: [3430/4518] 75% | Training loss: 0.6870486331229307
Epoch: 31 | Iteration number: [3440/4518] 76% | Training loss: 0.6870495713900688
Epoch: 31 | Iteration number: [3450/4518] 76% | Training loss: 0.6870552676656971
Epoch: 31 | Iteration number: [3460/4518] 76% | Training loss: 0.6870562193538412
Epoch: 31 | Iteration number: [3470/4518] 76% | Training loss: 0.6870520855748344
Epoch: 31 | Iteration number: [3480/4518] 77% | Training loss: 0.6870507908107221
Epoch: 31 | Iteration number: [3490/4518] 77% | Training loss: 0.6870514159387026
Epoch: 31 | Iteration number: [3500/4518] 77% | Training loss: 0.6870505385058266
Epoch: 31 | Iteration number: [3510/4518] 77% | Training loss: 0.687050989278701
Epoch: 31 | Iteration number: [3520/4518] 77% | Training loss: 0.6870505927807905
Epoch: 31 | Iteration number: [3530/4518] 78% | Training loss: 0.6870496638773521
Epoch: 31 | Iteration number: [3540/4518] 78% | Training loss: 0.6870488673280188
Epoch: 31 | Iteration number: [3550/4518] 78% | Training loss: 0.6870444082374304
Epoch: 31 | Iteration number: [3560/4518] 78% | Training loss: 0.6870442301369785
Epoch: 31 | Iteration number: [3570/4518] 79% | Training loss: 0.6870396580682749
Epoch: 31 | Iteration number: [3580/4518] 79% | Training loss: 0.6870392245620323
Epoch: 31 | Iteration number: [3590/4518] 79% | Training loss: 0.6870362866389719
Epoch: 31 | Iteration number: [3600/4518] 79% | Training loss: 0.6870377805497911
Epoch: 31 | Iteration number: [3610/4518] 79% | Training loss: 0.687036385942364
Epoch: 31 | Iteration number: [3620/4518] 80% | Training loss: 0.6870379170166194
Epoch: 31 | Iteration number: [3630/4518] 80% | Training loss: 0.6870383153605395
Epoch: 31 | Iteration number: [3640/4518] 80% | Training loss: 0.6870354434946081
Epoch: 31 | Iteration number: [3650/4518] 80% | Training loss: 0.6870385318749571
Epoch: 31 | Iteration number: [3660/4518] 81% | Training loss: 0.6870381480194832
Epoch: 31 | Iteration number: [3670/4518] 81% | Training loss: 0.6870385517378919
Epoch: 31 | Iteration number: [3680/4518] 81% | Training loss: 0.6870409281033537
Epoch: 31 | Iteration number: [3690/4518] 81% | Training loss: 0.6870362581922433
Epoch: 31 | Iteration number: [3700/4518] 81% | Training loss: 0.6870339083027195
Epoch: 31 | Iteration number: [3710/4518] 82% | Training loss: 0.6870345944182249
Epoch: 31 | Iteration number: [3720/4518] 82% | Training loss: 0.6870345369462044
Epoch: 31 | Iteration number: [3730/4518] 82% | Training loss: 0.6870336237126318
Epoch: 31 | Iteration number: [3740/4518] 82% | Training loss: 0.6870312930587779
Epoch: 31 | Iteration number: [3750/4518] 83% | Training loss: 0.6870311785697937
Epoch: 31 | Iteration number: [3760/4518] 83% | Training loss: 0.6870245154075166
Epoch: 31 | Iteration number: [3770/4518] 83% | Training loss: 0.6870269670568664
Epoch: 31 | Iteration number: [3780/4518] 83% | Training loss: 0.687023099705025
Epoch: 31 | Iteration number: [3790/4518] 83% | Training loss: 0.6870220023126276
Epoch: 31 | Iteration number: [3800/4518] 84% | Training loss: 0.6870213796276795
Epoch: 31 | Iteration number: [3810/4518] 84% | Training loss: 0.6870228047133118
Epoch: 31 | Iteration number: [3820/4518] 84% | Training loss: 0.6870206287706085
Epoch: 31 | Iteration number: [3830/4518] 84% | Training loss: 0.6870194668091308
Epoch: 31 | Iteration number: [3840/4518] 84% | Training loss: 0.6870184687587122
Epoch: 31 | Iteration number: [3850/4518] 85% | Training loss: 0.6870188715241172
Epoch: 31 | Iteration number: [3860/4518] 85% | Training loss: 0.6870191243028394
Epoch: 31 | Iteration number: [3870/4518] 85% | Training loss: 0.6870213136654492
Epoch: 31 | Iteration number: [3880/4518] 85% | Training loss: 0.6870199207946197
Epoch: 31 | Iteration number: [3890/4518] 86% | Training loss: 0.6870211916135331
Epoch: 31 | Iteration number: [3900/4518] 86% | Training loss: 0.687020305685508
Epoch: 31 | Iteration number: [3910/4518] 86% | Training loss: 0.6870222117894751
Epoch: 31 | Iteration number: [3920/4518] 86% | Training loss: 0.6870225641344275
Epoch: 31 | Iteration number: [3930/4518] 86% | Training loss: 0.6870237242022846
Epoch: 31 | Iteration number: [3940/4518] 87% | Training loss: 0.6870281585279455
Epoch: 31 | Iteration number: [3950/4518] 87% | Training loss: 0.6870289011695717
Epoch: 31 | Iteration number: [3960/4518] 87% | Training loss: 0.6870323221791874
Epoch: 31 | Iteration number: [3970/4518] 87% | Training loss: 0.6870299170539721
Epoch: 31 | Iteration number: [3980/4518] 88% | Training loss: 0.6870274990797043
Epoch: 31 | Iteration number: [3990/4518] 88% | Training loss: 0.687027065452179
Epoch: 31 | Iteration number: [4000/4518] 88% | Training loss: 0.6870277169942856
Epoch: 31 | Iteration number: [4010/4518] 88% | Training loss: 0.6870292661641899
Epoch: 31 | Iteration number: [4020/4518] 88% | Training loss: 0.6870262527792015
Epoch: 31 | Iteration number: [4030/4518] 89% | Training loss: 0.6870253859619349
Epoch: 31 | Iteration number: [4040/4518] 89% | Training loss: 0.6870280252234771
Epoch: 31 | Iteration number: [4050/4518] 89% | Training loss: 0.6870260918434755
Epoch: 31 | Iteration number: [4060/4518] 89% | Training loss: 0.6870278735025763
Epoch: 31 | Iteration number: [4070/4518] 90% | Training loss: 0.6870267525351897
Epoch: 31 | Iteration number: [4080/4518] 90% | Training loss: 0.6870274628056031
Epoch: 31 | Iteration number: [4090/4518] 90% | Training loss: 0.6870260857719664
Epoch: 31 | Iteration number: [4100/4518] 90% | Training loss: 0.6870254223521163
Epoch: 31 | Iteration number: [4110/4518] 90% | Training loss: 0.6870245135468578
Epoch: 31 | Iteration number: [4120/4518] 91% | Training loss: 0.6870222828775934
Epoch: 31 | Iteration number: [4130/4518] 91% | Training loss: 0.6870206152122765
Epoch: 31 | Iteration number: [4140/4518] 91% | Training loss: 0.6870217802012024
Epoch: 31 | Iteration number: [4150/4518] 91% | Training loss: 0.6870217383338745
Epoch: 31 | Iteration number: [4160/4518] 92% | Training loss: 0.6870218882480493
Epoch: 31 | Iteration number: [4170/4518] 92% | Training loss: 0.6870208894749054
Epoch: 31 | Iteration number: [4180/4518] 92% | Training loss: 0.6870178587841645
Epoch: 31 | Iteration number: [4190/4518] 92% | Training loss: 0.6870185847783146
Epoch: 31 | Iteration number: [4200/4518] 92% | Training loss: 0.6870167800074531
Epoch: 31 | Iteration number: [4210/4518] 93% | Training loss: 0.6870170493165557
Epoch: 31 | Iteration number: [4220/4518] 93% | Training loss: 0.6870171711908133
Epoch: 31 | Iteration number: [4230/4518] 93% | Training loss: 0.6870168800331459
Epoch: 31 | Iteration number: [4240/4518] 93% | Training loss: 0.6870146375500931
Epoch: 31 | Iteration number: [4250/4518] 94% | Training loss: 0.6870180967274834
Epoch: 31 | Iteration number: [4260/4518] 94% | Training loss: 0.687017637449251
Epoch: 31 | Iteration number: [4270/4518] 94% | Training loss: 0.6870134443951993
Epoch: 31 | Iteration number: [4280/4518] 94% | Training loss: 0.6870153163777334
Epoch: 31 | Iteration number: [4290/4518] 94% | Training loss: 0.6870132804194808
Epoch: 31 | Iteration number: [4300/4518] 95% | Training loss: 0.6870108482726784
Epoch: 31 | Iteration number: [4310/4518] 95% | Training loss: 0.6870108450648403
Epoch: 31 | Iteration number: [4320/4518] 95% | Training loss: 0.6870119826109321
Epoch: 31 | Iteration number: [4330/4518] 95% | Training loss: 0.6870118956092324
Epoch: 31 | Iteration number: [4340/4518] 96% | Training loss: 0.6870136943006295
Epoch: 31 | Iteration number: [4350/4518] 96% | Training loss: 0.687012384650351
Epoch: 31 | Iteration number: [4360/4518] 96% | Training loss: 0.6870148721227952
Epoch: 31 | Iteration number: [4370/4518] 96% | Training loss: 0.6870161628423075
Epoch: 31 | Iteration number: [4380/4518] 96% | Training loss: 0.6870145138268057
Epoch: 31 | Iteration number: [4390/4518] 97% | Training loss: 0.6870134097840085
Epoch: 31 | Iteration number: [4400/4518] 97% | Training loss: 0.6870167631723664
Epoch: 31 | Iteration number: [4410/4518] 97% | Training loss: 0.6870167257834454
Epoch: 31 | Iteration number: [4420/4518] 97% | Training loss: 0.6870136479851348
Epoch: 31 | Iteration number: [4430/4518] 98% | Training loss: 0.6870134655428256
Epoch: 31 | Iteration number: [4440/4518] 98% | Training loss: 0.6870137793523772
Epoch: 31 | Iteration number: [4450/4518] 98% | Training loss: 0.6870140399155992
Epoch: 31 | Iteration number: [4460/4518] 98% | Training loss: 0.6870116356108755
Epoch: 31 | Iteration number: [4470/4518] 98% | Training loss: 0.687008914984846
Epoch: 31 | Iteration number: [4480/4518] 99% | Training loss: 0.6870109628087708
Epoch: 31 | Iteration number: [4490/4518] 99% | Training loss: 0.687010675867841
Epoch: 31 | Iteration number: [4500/4518] 99% | Training loss: 0.6870121166441175
Epoch: 31 | Iteration number: [4510/4518] 99% | Training loss: 0.6870093978032833

 End of epoch: 31 | Train Loss: 0.6868571894867539 | Training Time: 632 

 End of epoch: 31 | Eval Loss: 0.6898607587327763 | Evaluating Time: 17 
Epoch: 32 | Iteration number: [10/4518] 0% | Training loss: 0.7556826770305634
Epoch: 32 | Iteration number: [20/4518] 0% | Training loss: 0.72126404941082
Epoch: 32 | Iteration number: [30/4518] 0% | Training loss: 0.7096358517805735
Epoch: 32 | Iteration number: [40/4518] 0% | Training loss: 0.7034772634506226
Epoch: 32 | Iteration number: [50/4518] 1% | Training loss: 0.6999601602554322
Epoch: 32 | Iteration number: [60/4518] 1% | Training loss: 0.6978451877832412
Epoch: 32 | Iteration number: [70/4518] 1% | Training loss: 0.6961810682501112
Epoch: 32 | Iteration number: [80/4518] 1% | Training loss: 0.6951175943017006
Epoch: 32 | Iteration number: [90/4518] 1% | Training loss: 0.6942930082480113
Epoch: 32 | Iteration number: [100/4518] 2% | Training loss: 0.6934922516345978
Epoch: 32 | Iteration number: [110/4518] 2% | Training loss: 0.6928394209254872
Epoch: 32 | Iteration number: [120/4518] 2% | Training loss: 0.6922549893458684
Epoch: 32 | Iteration number: [130/4518] 2% | Training loss: 0.6919295774056361
Epoch: 32 | Iteration number: [140/4518] 3% | Training loss: 0.6915242212159293
Epoch: 32 | Iteration number: [150/4518] 3% | Training loss: 0.691223204533259
Epoch: 32 | Iteration number: [160/4518] 3% | Training loss: 0.6909930150955915
Epoch: 32 | Iteration number: [170/4518] 3% | Training loss: 0.690834952101988
Epoch: 32 | Iteration number: [180/4518] 3% | Training loss: 0.6906146019697189
Epoch: 32 | Iteration number: [190/4518] 4% | Training loss: 0.6903587560904654
Epoch: 32 | Iteration number: [200/4518] 4% | Training loss: 0.6901558965444565
Epoch: 32 | Iteration number: [210/4518] 4% | Training loss: 0.6900027397133055
Epoch: 32 | Iteration number: [220/4518] 4% | Training loss: 0.6899218645962801
Epoch: 32 | Iteration number: [230/4518] 5% | Training loss: 0.6898155619268832
Epoch: 32 | Iteration number: [240/4518] 5% | Training loss: 0.6896286144852638
Epoch: 32 | Iteration number: [250/4518] 5% | Training loss: 0.6895697636604309
Epoch: 32 | Iteration number: [260/4518] 5% | Training loss: 0.6894305722071574
Epoch: 32 | Iteration number: [270/4518] 5% | Training loss: 0.689340039977321
Epoch: 32 | Iteration number: [280/4518] 6% | Training loss: 0.6892218393938881
Epoch: 32 | Iteration number: [290/4518] 6% | Training loss: 0.6891448758799454
Epoch: 32 | Iteration number: [300/4518] 6% | Training loss: 0.6890800017118454
Epoch: 32 | Iteration number: [310/4518] 6% | Training loss: 0.6890323771584419
Epoch: 32 | Iteration number: [320/4518] 7% | Training loss: 0.6889486517757177
Epoch: 32 | Iteration number: [330/4518] 7% | Training loss: 0.688934620402076
Epoch: 32 | Iteration number: [340/4518] 7% | Training loss: 0.6888912938973483
Epoch: 32 | Iteration number: [350/4518] 7% | Training loss: 0.6888609531947545
Epoch: 32 | Iteration number: [360/4518] 7% | Training loss: 0.6887885492708948
Epoch: 32 | Iteration number: [370/4518] 8% | Training loss: 0.6887345789252101
Epoch: 32 | Iteration number: [380/4518] 8% | Training loss: 0.6886799785651658
Epoch: 32 | Iteration number: [390/4518] 8% | Training loss: 0.688651020710285
Epoch: 32 | Iteration number: [400/4518] 8% | Training loss: 0.6886295737326145
Epoch: 32 | Iteration number: [410/4518] 9% | Training loss: 0.6886012113675839
Epoch: 32 | Iteration number: [420/4518] 9% | Training loss: 0.688588741847447
Epoch: 32 | Iteration number: [430/4518] 9% | Training loss: 0.6885706028272939
Epoch: 32 | Iteration number: [440/4518] 9% | Training loss: 0.6885194949128411
Epoch: 32 | Iteration number: [450/4518] 9% | Training loss: 0.6884619439972771
Epoch: 32 | Iteration number: [460/4518] 10% | Training loss: 0.688394611944323
Epoch: 32 | Iteration number: [470/4518] 10% | Training loss: 0.6883544231982941
Epoch: 32 | Iteration number: [480/4518] 10% | Training loss: 0.6882982242852449
Epoch: 32 | Iteration number: [490/4518] 10% | Training loss: 0.6882693600897887
Epoch: 32 | Iteration number: [500/4518] 11% | Training loss: 0.6882354001998902
Epoch: 32 | Iteration number: [510/4518] 11% | Training loss: 0.6882193454340393
Epoch: 32 | Iteration number: [520/4518] 11% | Training loss: 0.6881920631115254
Epoch: 32 | Iteration number: [530/4518] 11% | Training loss: 0.6881744873973559
Epoch: 32 | Iteration number: [540/4518] 11% | Training loss: 0.688147598946536
Epoch: 32 | Iteration number: [550/4518] 12% | Training loss: 0.6881090837175196
Epoch: 32 | Iteration number: [560/4518] 12% | Training loss: 0.6880772446947439
Epoch: 32 | Iteration number: [570/4518] 12% | Training loss: 0.6880704520041483
Epoch: 32 | Iteration number: [580/4518] 12% | Training loss: 0.6880317717790604
Epoch: 32 | Iteration number: [590/4518] 13% | Training loss: 0.6880004632270942
Epoch: 32 | Iteration number: [600/4518] 13% | Training loss: 0.687969419658184
Epoch: 32 | Iteration number: [610/4518] 13% | Training loss: 0.6879424815295172
Epoch: 32 | Iteration number: [620/4518] 13% | Training loss: 0.6879185011309962
Epoch: 32 | Iteration number: [630/4518] 13% | Training loss: 0.6879183896950313
Epoch: 32 | Iteration number: [640/4518] 14% | Training loss: 0.6878957056440413
Epoch: 32 | Iteration number: [650/4518] 14% | Training loss: 0.6878701287049513
Epoch: 32 | Iteration number: [660/4518] 14% | Training loss: 0.6878623267014822
Epoch: 32 | Iteration number: [670/4518] 14% | Training loss: 0.6878550725196725
Epoch: 32 | Iteration number: [680/4518] 15% | Training loss: 0.6878547465976547
Epoch: 32 | Iteration number: [690/4518] 15% | Training loss: 0.6878421724706456
Epoch: 32 | Iteration number: [700/4518] 15% | Training loss: 0.6878374474389213
Epoch: 32 | Iteration number: [710/4518] 15% | Training loss: 0.6878325554686533
Epoch: 32 | Iteration number: [720/4518] 15% | Training loss: 0.6878232421146498
Epoch: 32 | Iteration number: [730/4518] 16% | Training loss: 0.687809546842967
Epoch: 32 | Iteration number: [740/4518] 16% | Training loss: 0.6878106552201348
Epoch: 32 | Iteration number: [750/4518] 16% | Training loss: 0.6878042860825857
Epoch: 32 | Iteration number: [760/4518] 16% | Training loss: 0.6878072442977052
Epoch: 32 | Iteration number: [770/4518] 17% | Training loss: 0.6877912968010097
Epoch: 32 | Iteration number: [780/4518] 17% | Training loss: 0.687775461261089
Epoch: 32 | Iteration number: [790/4518] 17% | Training loss: 0.6877709221990803
Epoch: 32 | Iteration number: [800/4518] 17% | Training loss: 0.6877624846994876
Epoch: 32 | Iteration number: [810/4518] 17% | Training loss: 0.6877466950887515
Epoch: 32 | Iteration number: [820/4518] 18% | Training loss: 0.6877304481297004
Epoch: 32 | Iteration number: [830/4518] 18% | Training loss: 0.6877252602433583
Epoch: 32 | Iteration number: [840/4518] 18% | Training loss: 0.6877262466010593
Epoch: 32 | Iteration number: [850/4518] 18% | Training loss: 0.687716345576679
Epoch: 32 | Iteration number: [860/4518] 19% | Training loss: 0.6877190651588662
Epoch: 32 | Iteration number: [870/4518] 19% | Training loss: 0.6877156298736046
Epoch: 32 | Iteration number: [880/4518] 19% | Training loss: 0.687706109881401
Epoch: 32 | Iteration number: [890/4518] 19% | Training loss: 0.6877001466376058
Epoch: 32 | Iteration number: [900/4518] 19% | Training loss: 0.6876800431807836
Epoch: 32 | Iteration number: [910/4518] 20% | Training loss: 0.6876690954297453
Epoch: 32 | Iteration number: [920/4518] 20% | Training loss: 0.6876749768853188
Epoch: 32 | Iteration number: [930/4518] 20% | Training loss: 0.6876709423398459
Epoch: 32 | Iteration number: [940/4518] 20% | Training loss: 0.6876659716063357
Epoch: 32 | Iteration number: [950/4518] 21% | Training loss: 0.6876614088761179
Epoch: 32 | Iteration number: [960/4518] 21% | Training loss: 0.6876486733555793
Epoch: 32 | Iteration number: [970/4518] 21% | Training loss: 0.6876450372110937
Epoch: 32 | Iteration number: [980/4518] 21% | Training loss: 0.6876349163298704
Epoch: 32 | Iteration number: [990/4518] 21% | Training loss: 0.6876265233213251
Epoch: 32 | Iteration number: [1000/4518] 22% | Training loss: 0.6876159533262253
Epoch: 32 | Iteration number: [1010/4518] 22% | Training loss: 0.6876032614471889
Epoch: 32 | Iteration number: [1020/4518] 22% | Training loss: 0.6875883533674128
Epoch: 32 | Iteration number: [1030/4518] 22% | Training loss: 0.6875777996859505
Epoch: 32 | Iteration number: [1040/4518] 23% | Training loss: 0.687565122372829
Epoch: 32 | Iteration number: [1050/4518] 23% | Training loss: 0.6875486297834488
Epoch: 32 | Iteration number: [1060/4518] 23% | Training loss: 0.687545738298938
Epoch: 32 | Iteration number: [1070/4518] 23% | Training loss: 0.6875484196939201
Epoch: 32 | Iteration number: [1080/4518] 23% | Training loss: 0.6875338588599805
Epoch: 32 | Iteration number: [1090/4518] 24% | Training loss: 0.6875334817335146
Epoch: 32 | Iteration number: [1100/4518] 24% | Training loss: 0.687521148703315
Epoch: 32 | Iteration number: [1110/4518] 24% | Training loss: 0.6875203382324528
Epoch: 32 | Iteration number: [1120/4518] 24% | Training loss: 0.6875118033162185
Epoch: 32 | Iteration number: [1130/4518] 25% | Training loss: 0.6875027417081647
Epoch: 32 | Iteration number: [1140/4518] 25% | Training loss: 0.6874898155530293
Epoch: 32 | Iteration number: [1150/4518] 25% | Training loss: 0.6874760510092196
Epoch: 32 | Iteration number: [1160/4518] 25% | Training loss: 0.6874774168791442
Epoch: 32 | Iteration number: [1170/4518] 25% | Training loss: 0.6874656347637502
Epoch: 32 | Iteration number: [1180/4518] 26% | Training loss: 0.687457476177458
Epoch: 32 | Iteration number: [1190/4518] 26% | Training loss: 0.6874382333094332
Epoch: 32 | Iteration number: [1200/4518] 26% | Training loss: 0.6874453926583132
Epoch: 32 | Iteration number: [1210/4518] 26% | Training loss: 0.6874366545972745
Epoch: 32 | Iteration number: [1220/4518] 27% | Training loss: 0.6874385553305267
Epoch: 32 | Iteration number: [1230/4518] 27% | Training loss: 0.6874267710418236
Epoch: 32 | Iteration number: [1240/4518] 27% | Training loss: 0.6874266986404696
Epoch: 32 | Iteration number: [1250/4518] 27% | Training loss: 0.6874218341827393
Epoch: 32 | Iteration number: [1260/4518] 27% | Training loss: 0.687426749865214
Epoch: 32 | Iteration number: [1270/4518] 28% | Training loss: 0.6874265039060998
Epoch: 32 | Iteration number: [1280/4518] 28% | Training loss: 0.6874089584220201
Epoch: 32 | Iteration number: [1290/4518] 28% | Training loss: 0.6874046518821125
Epoch: 32 | Iteration number: [1300/4518] 28% | Training loss: 0.6873998102774986
Epoch: 32 | Iteration number: [1310/4518] 28% | Training loss: 0.6873976410800264
Epoch: 32 | Iteration number: [1320/4518] 29% | Training loss: 0.6873953994927984
Epoch: 32 | Iteration number: [1330/4518] 29% | Training loss: 0.687396103143692
Epoch: 32 | Iteration number: [1340/4518] 29% | Training loss: 0.6873984359538378
Epoch: 32 | Iteration number: [1350/4518] 29% | Training loss: 0.6873979944652981
Epoch: 32 | Iteration number: [1360/4518] 30% | Training loss: 0.6873931569211623
Epoch: 32 | Iteration number: [1370/4518] 30% | Training loss: 0.6873866539366924
Epoch: 32 | Iteration number: [1380/4518] 30% | Training loss: 0.6873732229073842
Epoch: 32 | Iteration number: [1390/4518] 30% | Training loss: 0.6873742249372194
Epoch: 32 | Iteration number: [1400/4518] 30% | Training loss: 0.6873688505802835
Epoch: 32 | Iteration number: [1410/4518] 31% | Training loss: 0.6873720620540862
Epoch: 32 | Iteration number: [1420/4518] 31% | Training loss: 0.687365295307737
Epoch: 32 | Iteration number: [1430/4518] 31% | Training loss: 0.6873650995167819
Epoch: 32 | Iteration number: [1440/4518] 31% | Training loss: 0.6873631164017651
Epoch: 32 | Iteration number: [1450/4518] 32% | Training loss: 0.6873646138043239
Epoch: 32 | Iteration number: [1460/4518] 32% | Training loss: 0.6873656380258194
Epoch: 32 | Iteration number: [1470/4518] 32% | Training loss: 0.6873466953128373
Epoch: 32 | Iteration number: [1480/4518] 32% | Training loss: 0.6873330685737971
Epoch: 32 | Iteration number: [1490/4518] 32% | Training loss: 0.6873376430281056
Epoch: 32 | Iteration number: [1500/4518] 33% | Training loss: 0.6873316190640132
Epoch: 32 | Iteration number: [1510/4518] 33% | Training loss: 0.6873344225599276
Epoch: 32 | Iteration number: [1520/4518] 33% | Training loss: 0.6873262517154217
Epoch: 32 | Iteration number: [1530/4518] 33% | Training loss: 0.6873238006058862
Epoch: 32 | Iteration number: [1540/4518] 34% | Training loss: 0.6873124706667739
Epoch: 32 | Iteration number: [1550/4518] 34% | Training loss: 0.6873013412183331
Epoch: 32 | Iteration number: [1560/4518] 34% | Training loss: 0.6872944731742908
Epoch: 32 | Iteration number: [1570/4518] 34% | Training loss: 0.6872860241088138
Epoch: 32 | Iteration number: [1580/4518] 34% | Training loss: 0.6872836289903785
Epoch: 32 | Iteration number: [1590/4518] 35% | Training loss: 0.6872864121910911
Epoch: 32 | Iteration number: [1600/4518] 35% | Training loss: 0.6872912393510342
Epoch: 32 | Iteration number: [1610/4518] 35% | Training loss: 0.6872848802471754
Epoch: 32 | Iteration number: [1620/4518] 35% | Training loss: 0.6872770920947746
Epoch: 32 | Iteration number: [1630/4518] 36% | Training loss: 0.6872698430269042
Epoch: 32 | Iteration number: [1640/4518] 36% | Training loss: 0.6872665708021419
Epoch: 32 | Iteration number: [1650/4518] 36% | Training loss: 0.6872593172391256
Epoch: 32 | Iteration number: [1660/4518] 36% | Training loss: 0.6872537152953895
Epoch: 32 | Iteration number: [1670/4518] 36% | Training loss: 0.6872475356755856
Epoch: 32 | Iteration number: [1680/4518] 37% | Training loss: 0.6872431429723899
Epoch: 32 | Iteration number: [1690/4518] 37% | Training loss: 0.6872448396047897
Epoch: 32 | Iteration number: [1700/4518] 37% | Training loss: 0.6872466589422787
Epoch: 32 | Iteration number: [1710/4518] 37% | Training loss: 0.6872428294859434
Epoch: 32 | Iteration number: [1720/4518] 38% | Training loss: 0.6872384289322897
Epoch: 32 | Iteration number: [1730/4518] 38% | Training loss: 0.6872356187056944
Epoch: 32 | Iteration number: [1740/4518] 38% | Training loss: 0.6872389647467383
Epoch: 32 | Iteration number: [1750/4518] 38% | Training loss: 0.6872326711586544
Epoch: 32 | Iteration number: [1760/4518] 38% | Training loss: 0.6872227635573257
Epoch: 32 | Iteration number: [1770/4518] 39% | Training loss: 0.6872258534202468
Epoch: 32 | Iteration number: [1780/4518] 39% | Training loss: 0.6872278319985679
Epoch: 32 | Iteration number: [1790/4518] 39% | Training loss: 0.6872316869610515
Epoch: 32 | Iteration number: [1800/4518] 39% | Training loss: 0.6872373994853761
Epoch: 32 | Iteration number: [1810/4518] 40% | Training loss: 0.6872292296991822
Epoch: 32 | Iteration number: [1820/4518] 40% | Training loss: 0.687231742811727
Epoch: 32 | Iteration number: [1830/4518] 40% | Training loss: 0.6872310043032703
Epoch: 32 | Iteration number: [1840/4518] 40% | Training loss: 0.6872294584370178
Epoch: 32 | Iteration number: [1850/4518] 40% | Training loss: 0.6872287842711887
Epoch: 32 | Iteration number: [1860/4518] 41% | Training loss: 0.6872223436191518
Epoch: 32 | Iteration number: [1870/4518] 41% | Training loss: 0.6872187164059297
Epoch: 32 | Iteration number: [1880/4518] 41% | Training loss: 0.6872228332973541
Epoch: 32 | Iteration number: [1890/4518] 41% | Training loss: 0.6872182151943288
Epoch: 32 | Iteration number: [1900/4518] 42% | Training loss: 0.6872185452674564
Epoch: 32 | Iteration number: [1910/4518] 42% | Training loss: 0.6872192685516717
Epoch: 32 | Iteration number: [1920/4518] 42% | Training loss: 0.6872108076699078
Epoch: 32 | Iteration number: [1930/4518] 42% | Training loss: 0.6872085866223963
Epoch: 32 | Iteration number: [1940/4518] 42% | Training loss: 0.6872104484703123
Epoch: 32 | Iteration number: [1950/4518] 43% | Training loss: 0.6872080052815951
Epoch: 32 | Iteration number: [1960/4518] 43% | Training loss: 0.6872025730354445
Epoch: 32 | Iteration number: [1970/4518] 43% | Training loss: 0.6872075479647834
Epoch: 32 | Iteration number: [1980/4518] 43% | Training loss: 0.6872120446026927
Epoch: 32 | Iteration number: [1990/4518] 44% | Training loss: 0.6871963374279252
Epoch: 32 | Iteration number: [2000/4518] 44% | Training loss: 0.6871918624341488
Epoch: 32 | Iteration number: [2010/4518] 44% | Training loss: 0.6871917129452548
Epoch: 32 | Iteration number: [2020/4518] 44% | Training loss: 0.6871863716014541
Epoch: 32 | Iteration number: [2030/4518] 44% | Training loss: 0.6871844218282277
Epoch: 32 | Iteration number: [2040/4518] 45% | Training loss: 0.6871824765614435
Epoch: 32 | Iteration number: [2050/4518] 45% | Training loss: 0.6871786775821592
Epoch: 32 | Iteration number: [2060/4518] 45% | Training loss: 0.6871670387034278
Epoch: 32 | Iteration number: [2070/4518] 45% | Training loss: 0.6871659532261355
Epoch: 32 | Iteration number: [2080/4518] 46% | Training loss: 0.6871584834101109
Epoch: 32 | Iteration number: [2090/4518] 46% | Training loss: 0.6871547160536479
Epoch: 32 | Iteration number: [2100/4518] 46% | Training loss: 0.6871550930397851
Epoch: 32 | Iteration number: [2110/4518] 46% | Training loss: 0.6871503113852858
Epoch: 32 | Iteration number: [2120/4518] 46% | Training loss: 0.6871470485655766
Epoch: 32 | Iteration number: [2130/4518] 47% | Training loss: 0.687143367500932
Epoch: 32 | Iteration number: [2140/4518] 47% | Training loss: 0.6871434094192825
Epoch: 32 | Iteration number: [2150/4518] 47% | Training loss: 0.6871388591167539
Epoch: 32 | Iteration number: [2160/4518] 47% | Training loss: 0.6871393123434649
Epoch: 32 | Iteration number: [2170/4518] 48% | Training loss: 0.6871379862732602
Epoch: 32 | Iteration number: [2180/4518] 48% | Training loss: 0.687131942685591
Epoch: 32 | Iteration number: [2190/4518] 48% | Training loss: 0.6871293255183251
Epoch: 32 | Iteration number: [2200/4518] 48% | Training loss: 0.6871247680078854
Epoch: 32 | Iteration number: [2210/4518] 48% | Training loss: 0.6871260586367474
Epoch: 32 | Iteration number: [2220/4518] 49% | Training loss: 0.6871245854341232
Epoch: 32 | Iteration number: [2230/4518] 49% | Training loss: 0.687127665954855
Epoch: 32 | Iteration number: [2240/4518] 49% | Training loss: 0.6871258386809911
Epoch: 32 | Iteration number: [2250/4518] 49% | Training loss: 0.6871266400019328
Epoch: 32 | Iteration number: [2260/4518] 50% | Training loss: 0.6871251999804404
Epoch: 32 | Iteration number: [2270/4518] 50% | Training loss: 0.6871249772641103
Epoch: 32 | Iteration number: [2280/4518] 50% | Training loss: 0.6871237709072598
Epoch: 32 | Iteration number: [2290/4518] 50% | Training loss: 0.6871220642041952
Epoch: 32 | Iteration number: [2300/4518] 50% | Training loss: 0.6871158147635668
Epoch: 32 | Iteration number: [2310/4518] 51% | Training loss: 0.6871145699447367
Epoch: 32 | Iteration number: [2320/4518] 51% | Training loss: 0.6871118788318388
Epoch: 32 | Iteration number: [2330/4518] 51% | Training loss: 0.6871110179393588
Epoch: 32 | Iteration number: [2340/4518] 51% | Training loss: 0.6871126782945078
Epoch: 32 | Iteration number: [2350/4518] 52% | Training loss: 0.6871112662173332
Epoch: 32 | Iteration number: [2360/4518] 52% | Training loss: 0.6871096698661981
Epoch: 32 | Iteration number: [2370/4518] 52% | Training loss: 0.687107510456053
Epoch: 32 | Iteration number: [2380/4518] 52% | Training loss: 0.6871105978468887
Epoch: 32 | Iteration number: [2390/4518] 52% | Training loss: 0.6871066891249253
Epoch: 32 | Iteration number: [2400/4518] 53% | Training loss: 0.6871097539613644
Epoch: 32 | Iteration number: [2410/4518] 53% | Training loss: 0.6871095491148129
Epoch: 32 | Iteration number: [2420/4518] 53% | Training loss: 0.6871074923060158
Epoch: 32 | Iteration number: [2430/4518] 53% | Training loss: 0.6871102580808318
Epoch: 32 | Iteration number: [2440/4518] 54% | Training loss: 0.6871065689159221
Epoch: 32 | Iteration number: [2450/4518] 54% | Training loss: 0.6871049618234439
Epoch: 32 | Iteration number: [2460/4518] 54% | Training loss: 0.6871036906310213
Epoch: 32 | Iteration number: [2470/4518] 54% | Training loss: 0.6870978975585598
Epoch: 32 | Iteration number: [2480/4518] 54% | Training loss: 0.6870939105028107
Epoch: 32 | Iteration number: [2490/4518] 55% | Training loss: 0.6870935725160392
Epoch: 32 | Iteration number: [2500/4518] 55% | Training loss: 0.6870930954933167
Epoch: 32 | Iteration number: [2510/4518] 55% | Training loss: 0.6870908739082366
Epoch: 32 | Iteration number: [2520/4518] 55% | Training loss: 0.6870862651202414
Epoch: 32 | Iteration number: [2530/4518] 55% | Training loss: 0.6870916523009892
Epoch: 32 | Iteration number: [2540/4518] 56% | Training loss: 0.6870949766532642
Epoch: 32 | Iteration number: [2550/4518] 56% | Training loss: 0.6870974906753091
Epoch: 32 | Iteration number: [2560/4518] 56% | Training loss: 0.6871013878844678
Epoch: 32 | Iteration number: [2570/4518] 56% | Training loss: 0.6871006270790843
Epoch: 32 | Iteration number: [2580/4518] 57% | Training loss: 0.6871050520460735
Epoch: 32 | Iteration number: [2590/4518] 57% | Training loss: 0.6871045794266071
Epoch: 32 | Iteration number: [2600/4518] 57% | Training loss: 0.6871004310708779
Epoch: 32 | Iteration number: [2610/4518] 57% | Training loss: 0.6871043537311627
Epoch: 32 | Iteration number: [2620/4518] 57% | Training loss: 0.6871030572716517
Epoch: 32 | Iteration number: [2630/4518] 58% | Training loss: 0.6871029379476612
Epoch: 32 | Iteration number: [2640/4518] 58% | Training loss: 0.6871024956305821
Epoch: 32 | Iteration number: [2650/4518] 58% | Training loss: 0.6870986877747302
Epoch: 32 | Iteration number: [2660/4518] 58% | Training loss: 0.6870942391847309
Epoch: 32 | Iteration number: [2670/4518] 59% | Training loss: 0.6870930018719662
Epoch: 32 | Iteration number: [2680/4518] 59% | Training loss: 0.6870927521764343
Epoch: 32 | Iteration number: [2690/4518] 59% | Training loss: 0.687086230317013
Epoch: 32 | Iteration number: [2700/4518] 59% | Training loss: 0.6870825931319484
Epoch: 32 | Iteration number: [2710/4518] 59% | Training loss: 0.68708148812016
Epoch: 32 | Iteration number: [2720/4518] 60% | Training loss: 0.6870800544453017
Epoch: 32 | Iteration number: [2730/4518] 60% | Training loss: 0.6870799019004836
Epoch: 32 | Iteration number: [2740/4518] 60% | Training loss: 0.6870885625155303
Epoch: 32 | Iteration number: [2750/4518] 60% | Training loss: 0.6870854581919583
Epoch: 32 | Iteration number: [2760/4518] 61% | Training loss: 0.6870847733340402
Epoch: 32 | Iteration number: [2770/4518] 61% | Training loss: 0.6870863185247359
Epoch: 32 | Iteration number: [2780/4518] 61% | Training loss: 0.6870855127735961
Epoch: 32 | Iteration number: [2790/4518] 61% | Training loss: 0.6870806409253014
Epoch: 32 | Iteration number: [2800/4518] 61% | Training loss: 0.6870754298142024
Epoch: 32 | Iteration number: [2810/4518] 62% | Training loss: 0.6870749388088959
Epoch: 32 | Iteration number: [2820/4518] 62% | Training loss: 0.6870736099726765
Epoch: 32 | Iteration number: [2830/4518] 62% | Training loss: 0.6870779707659259
Epoch: 32 | Iteration number: [2840/4518] 62% | Training loss: 0.6870779080080315
Epoch: 32 | Iteration number: [2850/4518] 63% | Training loss: 0.687080248615198
Epoch: 32 | Iteration number: [2860/4518] 63% | Training loss: 0.6870793949473988
Epoch: 32 | Iteration number: [2870/4518] 63% | Training loss: 0.6870787602060763
Epoch: 32 | Iteration number: [2880/4518] 63% | Training loss: 0.6870779817923903
Epoch: 32 | Iteration number: [2890/4518] 63% | Training loss: 0.6870799108360053
Epoch: 32 | Iteration number: [2900/4518] 64% | Training loss: 0.687080816009949
Epoch: 32 | Iteration number: [2910/4518] 64% | Training loss: 0.6870783433881412
Epoch: 32 | Iteration number: [2920/4518] 64% | Training loss: 0.6870794904150375
Epoch: 32 | Iteration number: [2930/4518] 64% | Training loss: 0.6870826243337104
Epoch: 32 | Iteration number: [2940/4518] 65% | Training loss: 0.687086573972994
Epoch: 32 | Iteration number: [2950/4518] 65% | Training loss: 0.6870853152517545
Epoch: 32 | Iteration number: [2960/4518] 65% | Training loss: 0.6870836515080284
Epoch: 32 | Iteration number: [2970/4518] 65% | Training loss: 0.6870817876424051
Epoch: 32 | Iteration number: [2980/4518] 65% | Training loss: 0.6870810114297291
Epoch: 32 | Iteration number: [2990/4518] 66% | Training loss: 0.6870812111474998
Epoch: 32 | Iteration number: [3000/4518] 66% | Training loss: 0.6870806419253349
Epoch: 32 | Iteration number: [3010/4518] 66% | Training loss: 0.6870809220198381
Epoch: 32 | Iteration number: [3020/4518] 66% | Training loss: 0.6870849039775646
Epoch: 32 | Iteration number: [3030/4518] 67% | Training loss: 0.6870852793010548
Epoch: 32 | Iteration number: [3040/4518] 67% | Training loss: 0.6870829029498916
Epoch: 32 | Iteration number: [3050/4518] 67% | Training loss: 0.6870794410979162
Epoch: 32 | Iteration number: [3060/4518] 67% | Training loss: 0.6870800902835684
Epoch: 32 | Iteration number: [3070/4518] 67% | Training loss: 0.6870771774251608
Epoch: 32 | Iteration number: [3080/4518] 68% | Training loss: 0.6870791467753323
Epoch: 32 | Iteration number: [3090/4518] 68% | Training loss: 0.6870761160904536
Epoch: 32 | Iteration number: [3100/4518] 68% | Training loss: 0.6870719077317945
Epoch: 32 | Iteration number: [3110/4518] 68% | Training loss: 0.6870722215658599
Epoch: 32 | Iteration number: [3120/4518] 69% | Training loss: 0.6870686170764458
Epoch: 32 | Iteration number: [3130/4518] 69% | Training loss: 0.6870726532829455
Epoch: 32 | Iteration number: [3140/4518] 69% | Training loss: 0.6870723464876224
Epoch: 32 | Iteration number: [3150/4518] 69% | Training loss: 0.6870704445574018
Epoch: 32 | Iteration number: [3160/4518] 69% | Training loss: 0.6870673158500767
Epoch: 32 | Iteration number: [3170/4518] 70% | Training loss: 0.6870643314502969
Epoch: 32 | Iteration number: [3180/4518] 70% | Training loss: 0.6870639054092971
Epoch: 32 | Iteration number: [3190/4518] 70% | Training loss: 0.6870619868036348
Epoch: 32 | Iteration number: [3200/4518] 70% | Training loss: 0.6870574306696653
Epoch: 32 | Iteration number: [3210/4518] 71% | Training loss: 0.687053848612717
Epoch: 32 | Iteration number: [3220/4518] 71% | Training loss: 0.6870508870908192
Epoch: 32 | Iteration number: [3230/4518] 71% | Training loss: 0.6870489854561656
Epoch: 32 | Iteration number: [3240/4518] 71% | Training loss: 0.687045482095377
Epoch: 32 | Iteration number: [3250/4518] 71% | Training loss: 0.6870417633240039
Epoch: 32 | Iteration number: [3260/4518] 72% | Training loss: 0.6870403135115384
Epoch: 32 | Iteration number: [3270/4518] 72% | Training loss: 0.6870434985066044
Epoch: 32 | Iteration number: [3280/4518] 72% | Training loss: 0.6870392274384092
Epoch: 32 | Iteration number: [3290/4518] 72% | Training loss: 0.6870393265525621
Epoch: 32 | Iteration number: [3300/4518] 73% | Training loss: 0.6870411384105682
Epoch: 32 | Iteration number: [3310/4518] 73% | Training loss: 0.6870425268602516
Epoch: 32 | Iteration number: [3320/4518] 73% | Training loss: 0.6870431126600288
Epoch: 32 | Iteration number: [3330/4518] 73% | Training loss: 0.6870411635877134
Epoch: 32 | Iteration number: [3340/4518] 73% | Training loss: 0.6870385355578211
Epoch: 32 | Iteration number: [3350/4518] 74% | Training loss: 0.6870368627469932
Epoch: 32 | Iteration number: [3360/4518] 74% | Training loss: 0.6870351156840722
Epoch: 32 | Iteration number: [3370/4518] 74% | Training loss: 0.6870374853957655
Epoch: 32 | Iteration number: [3380/4518] 74% | Training loss: 0.6870364563881293
Epoch: 32 | Iteration number: [3390/4518] 75% | Training loss: 0.6870367675404281
Epoch: 32 | Iteration number: [3400/4518] 75% | Training loss: 0.6870344486131388
Epoch: 32 | Iteration number: [3410/4518] 75% | Training loss: 0.6870340633252499
Epoch: 32 | Iteration number: [3420/4518] 75% | Training loss: 0.6870329661676061
Epoch: 32 | Iteration number: [3430/4518] 75% | Training loss: 0.6870331183293122
Epoch: 32 | Iteration number: [3440/4518] 76% | Training loss: 0.687031505048968
Epoch: 32 | Iteration number: [3450/4518] 76% | Training loss: 0.6870262673454008
Epoch: 32 | Iteration number: [3460/4518] 76% | Training loss: 0.6870238761509085
Epoch: 32 | Iteration number: [3470/4518] 76% | Training loss: 0.6870214787958678
Epoch: 32 | Iteration number: [3480/4518] 77% | Training loss: 0.6870218517451451
Epoch: 32 | Iteration number: [3490/4518] 77% | Training loss: 0.6870228738019665
Epoch: 32 | Iteration number: [3500/4518] 77% | Training loss: 0.6870236000163215
Epoch: 32 | Iteration number: [3510/4518] 77% | Training loss: 0.687024472581695
Epoch: 32 | Iteration number: [3520/4518] 77% | Training loss: 0.6870245986702768
Epoch: 32 | Iteration number: [3530/4518] 78% | Training loss: 0.6870196725930439
Epoch: 32 | Iteration number: [3540/4518] 78% | Training loss: 0.6870194482264546
Epoch: 32 | Iteration number: [3550/4518] 78% | Training loss: 0.6870182711473654
Epoch: 32 | Iteration number: [3560/4518] 78% | Training loss: 0.687019257515334
Epoch: 32 | Iteration number: [3570/4518] 79% | Training loss: 0.6870176938401551
Epoch: 32 | Iteration number: [3580/4518] 79% | Training loss: 0.6870156779469059
Epoch: 32 | Iteration number: [3590/4518] 79% | Training loss: 0.687014102470908
Epoch: 32 | Iteration number: [3600/4518] 79% | Training loss: 0.6870127460194959
Epoch: 32 | Iteration number: [3610/4518] 79% | Training loss: 0.6870122904097274
Epoch: 32 | Iteration number: [3620/4518] 80% | Training loss: 0.6870117021529055
Epoch: 32 | Iteration number: [3630/4518] 80% | Training loss: 0.6870107832362172
Epoch: 32 | Iteration number: [3640/4518] 80% | Training loss: 0.6870112711092928
Epoch: 32 | Iteration number: [3650/4518] 80% | Training loss: 0.6870106850421592
Epoch: 32 | Iteration number: [3660/4518] 81% | Training loss: 0.6870120875008119
Epoch: 32 | Iteration number: [3670/4518] 81% | Training loss: 0.6870124320080885
Epoch: 32 | Iteration number: [3680/4518] 81% | Training loss: 0.6870124260530523
Epoch: 32 | Iteration number: [3690/4518] 81% | Training loss: 0.6870128043298799
Epoch: 32 | Iteration number: [3700/4518] 81% | Training loss: 0.6870140956704681
Epoch: 32 | Iteration number: [3710/4518] 82% | Training loss: 0.6870122310125603
Epoch: 32 | Iteration number: [3720/4518] 82% | Training loss: 0.6870116811445964
Epoch: 32 | Iteration number: [3730/4518] 82% | Training loss: 0.6870130091825695
Epoch: 32 | Iteration number: [3740/4518] 82% | Training loss: 0.687012746611381
Epoch: 32 | Iteration number: [3750/4518] 83% | Training loss: 0.6870136556466421
Epoch: 32 | Iteration number: [3760/4518] 83% | Training loss: 0.6870120814664566
Epoch: 32 | Iteration number: [3770/4518] 83% | Training loss: 0.6870103816929167
Epoch: 32 | Iteration number: [3780/4518] 83% | Training loss: 0.6870106039066163
Epoch: 32 | Iteration number: [3790/4518] 83% | Training loss: 0.687009499318367
Epoch: 32 | Iteration number: [3800/4518] 84% | Training loss: 0.687010555157536
Epoch: 32 | Iteration number: [3810/4518] 84% | Training loss: 0.6870113094804168
Epoch: 32 | Iteration number: [3820/4518] 84% | Training loss: 0.6870112421156849
Epoch: 32 | Iteration number: [3830/4518] 84% | Training loss: 0.6870128782393105
Epoch: 32 | Iteration number: [3840/4518] 84% | Training loss: 0.6870103644828002
Epoch: 32 | Iteration number: [3850/4518] 85% | Training loss: 0.6870124462053373
Epoch: 32 | Iteration number: [3860/4518] 85% | Training loss: 0.6870126471000632
Epoch: 32 | Iteration number: [3870/4518] 85% | Training loss: 0.6870163095705885
Epoch: 32 | Iteration number: [3880/4518] 85% | Training loss: 0.6870192039719561
Epoch: 32 | Iteration number: [3890/4518] 86% | Training loss: 0.6870188850670057
Epoch: 32 | Iteration number: [3900/4518] 86% | Training loss: 0.6870151966198896
Epoch: 32 | Iteration number: [3910/4518] 86% | Training loss: 0.68701555122195
Epoch: 32 | Iteration number: [3920/4518] 86% | Training loss: 0.6870142921957434
Epoch: 32 | Iteration number: [3930/4518] 86% | Training loss: 0.6870147348815249
Epoch: 32 | Iteration number: [3940/4518] 87% | Training loss: 0.6870173036447031
Epoch: 32 | Iteration number: [3950/4518] 87% | Training loss: 0.6870146747178669
Epoch: 32 | Iteration number: [3960/4518] 87% | Training loss: 0.6870142120454047
Epoch: 32 | Iteration number: [3970/4518] 87% | Training loss: 0.6870137454730738
Epoch: 32 | Iteration number: [3980/4518] 88% | Training loss: 0.6870174030562741
Epoch: 32 | Iteration number: [3990/4518] 88% | Training loss: 0.6870172495083103
Epoch: 32 | Iteration number: [4000/4518] 88% | Training loss: 0.6870190861225128
Epoch: 32 | Iteration number: [4010/4518] 88% | Training loss: 0.6870194354854022
Epoch: 32 | Iteration number: [4020/4518] 88% | Training loss: 0.6870147153364485
Epoch: 32 | Iteration number: [4030/4518] 89% | Training loss: 0.687013550091618
Epoch: 32 | Iteration number: [4040/4518] 89% | Training loss: 0.6870150257012632
Epoch: 32 | Iteration number: [4050/4518] 89% | Training loss: 0.6870153784310377
Epoch: 32 | Iteration number: [4060/4518] 89% | Training loss: 0.6870135115138416
Epoch: 32 | Iteration number: [4070/4518] 90% | Training loss: 0.6870107083707242
Epoch: 32 | Iteration number: [4080/4518] 90% | Training loss: 0.6870091613893415
Epoch: 32 | Iteration number: [4090/4518] 90% | Training loss: 0.6870105296009036
Epoch: 32 | Iteration number: [4100/4518] 90% | Training loss: 0.6870125801534187
Epoch: 32 | Iteration number: [4110/4518] 90% | Training loss: 0.6870101724517896
Epoch: 32 | Iteration number: [4120/4518] 91% | Training loss: 0.6870085853830125
Epoch: 32 | Iteration number: [4130/4518] 91% | Training loss: 0.6870057544032829
Epoch: 32 | Iteration number: [4140/4518] 91% | Training loss: 0.6870033343776989
Epoch: 32 | Iteration number: [4150/4518] 91% | Training loss: 0.6870055723621185
Epoch: 32 | Iteration number: [4160/4518] 92% | Training loss: 0.6870086761621329
Epoch: 32 | Iteration number: [4170/4518] 92% | Training loss: 0.6870073805610053
Epoch: 32 | Iteration number: [4180/4518] 92% | Training loss: 0.6870070890376442
Epoch: 32 | Iteration number: [4190/4518] 92% | Training loss: 0.687004535366072
Epoch: 32 | Iteration number: [4200/4518] 92% | Training loss: 0.6870019645492236
Epoch: 32 | Iteration number: [4210/4518] 93% | Training loss: 0.6870007604714528
Epoch: 32 | Iteration number: [4220/4518] 93% | Training loss: 0.6869958156516767
Epoch: 32 | Iteration number: [4230/4518] 93% | Training loss: 0.6869972245772116
Epoch: 32 | Iteration number: [4240/4518] 93% | Training loss: 0.6869967121560618
Epoch: 32 | Iteration number: [4250/4518] 94% | Training loss: 0.6870001270490534
Epoch: 32 | Iteration number: [4260/4518] 94% | Training loss: 0.6870014168427024
Epoch: 32 | Iteration number: [4270/4518] 94% | Training loss: 0.6870004718141757
Epoch: 32 | Iteration number: [4280/4518] 94% | Training loss: 0.6869999154009552
Epoch: 32 | Iteration number: [4290/4518] 94% | Training loss: 0.6869988261958658
Epoch: 32 | Iteration number: [4300/4518] 95% | Training loss: 0.6870007374952006
Epoch: 32 | Iteration number: [4310/4518] 95% | Training loss: 0.6870000269047899
Epoch: 32 | Iteration number: [4320/4518] 95% | Training loss: 0.6870013496804016
Epoch: 32 | Iteration number: [4330/4518] 95% | Training loss: 0.687003108976069
Epoch: 32 | Iteration number: [4340/4518] 96% | Training loss: 0.6870030872008768
Epoch: 32 | Iteration number: [4350/4518] 96% | Training loss: 0.6870059263980252
Epoch: 32 | Iteration number: [4360/4518] 96% | Training loss: 0.6870082680785328
Epoch: 32 | Iteration number: [4370/4518] 96% | Training loss: 0.6870045159719629
Epoch: 32 | Iteration number: [4380/4518] 96% | Training loss: 0.6870036508122536
Epoch: 32 | Iteration number: [4390/4518] 97% | Training loss: 0.6870033662384355
Epoch: 32 | Iteration number: [4400/4518] 97% | Training loss: 0.6870020640167323
Epoch: 32 | Iteration number: [4410/4518] 97% | Training loss: 0.6870024499709374
Epoch: 32 | Iteration number: [4420/4518] 97% | Training loss: 0.6870023457308161
Epoch: 32 | Iteration number: [4430/4518] 98% | Training loss: 0.6870012193178215
Epoch: 32 | Iteration number: [4440/4518] 98% | Training loss: 0.6869989975884154
Epoch: 32 | Iteration number: [4450/4518] 98% | Training loss: 0.6869992875115255
Epoch: 32 | Iteration number: [4460/4518] 98% | Training loss: 0.6869993830609215
Epoch: 32 | Iteration number: [4470/4518] 98% | Training loss: 0.6869956078412015
Epoch: 32 | Iteration number: [4480/4518] 99% | Training loss: 0.6869960449502936
Epoch: 32 | Iteration number: [4490/4518] 99% | Training loss: 0.6869951093249969
Epoch: 32 | Iteration number: [4500/4518] 99% | Training loss: 0.6869944920010037
Epoch: 32 | Iteration number: [4510/4518] 99% | Training loss: 0.6869970243415917

 End of epoch: 32 | Train Loss: 0.6868428073661841 | Training Time: 633 

 End of epoch: 32 | Eval Loss: 0.6898937906537738 | Evaluating Time: 18 
Epoch: 33 | Iteration number: [10/4518] 0% | Training loss: 0.7568260729312897
Epoch: 33 | Iteration number: [20/4518] 0% | Training loss: 0.7215564340353012
Epoch: 33 | Iteration number: [30/4518] 0% | Training loss: 0.7098941286404927
Epoch: 33 | Iteration number: [40/4518] 0% | Training loss: 0.7040995746850968
Epoch: 33 | Iteration number: [50/4518] 1% | Training loss: 0.7007439684867859
Epoch: 33 | Iteration number: [60/4518] 1% | Training loss: 0.698518717288971
Epoch: 33 | Iteration number: [70/4518] 1% | Training loss: 0.6967726417950222
Epoch: 33 | Iteration number: [80/4518] 1% | Training loss: 0.6954612493515014
Epoch: 33 | Iteration number: [90/4518] 1% | Training loss: 0.6944676597913106
Epoch: 33 | Iteration number: [100/4518] 2% | Training loss: 0.6937697070837021
Epoch: 33 | Iteration number: [110/4518] 2% | Training loss: 0.6932378205386075
Epoch: 33 | Iteration number: [120/4518] 2% | Training loss: 0.6926274408896764
Epoch: 33 | Iteration number: [130/4518] 2% | Training loss: 0.6921061630432422
Epoch: 33 | Iteration number: [140/4518] 3% | Training loss: 0.6916735683168683
Epoch: 33 | Iteration number: [150/4518] 3% | Training loss: 0.6913334397474925
Epoch: 33 | Iteration number: [160/4518] 3% | Training loss: 0.6910807687789202
Epoch: 33 | Iteration number: [170/4518] 3% | Training loss: 0.6908694323371438
Epoch: 33 | Iteration number: [180/4518] 3% | Training loss: 0.6906440850761202
Epoch: 33 | Iteration number: [190/4518] 4% | Training loss: 0.6904542976304104
Epoch: 33 | Iteration number: [200/4518] 4% | Training loss: 0.6903216034173966
Epoch: 33 | Iteration number: [210/4518] 4% | Training loss: 0.6901477231865838
Epoch: 33 | Iteration number: [220/4518] 4% | Training loss: 0.6899502366781235
Epoch: 33 | Iteration number: [230/4518] 5% | Training loss: 0.6898605608421823
Epoch: 33 | Iteration number: [240/4518] 5% | Training loss: 0.689749492953221
Epoch: 33 | Iteration number: [250/4518] 5% | Training loss: 0.6896247189044953
Epoch: 33 | Iteration number: [260/4518] 5% | Training loss: 0.6894817794744785
Epoch: 33 | Iteration number: [270/4518] 5% | Training loss: 0.6894053386317359
Epoch: 33 | Iteration number: [280/4518] 6% | Training loss: 0.6893298745155334
Epoch: 33 | Iteration number: [290/4518] 6% | Training loss: 0.6892375754898992
Epoch: 33 | Iteration number: [300/4518] 6% | Training loss: 0.6891372070709865
Epoch: 33 | Iteration number: [310/4518] 6% | Training loss: 0.6890611956196446
Epoch: 33 | Iteration number: [320/4518] 7% | Training loss: 0.6889745581895113
Epoch: 33 | Iteration number: [330/4518] 7% | Training loss: 0.6888914433392611
Epoch: 33 | Iteration number: [340/4518] 7% | Training loss: 0.6888577366576475
Epoch: 33 | Iteration number: [350/4518] 7% | Training loss: 0.6888058904239109
Epoch: 33 | Iteration number: [360/4518] 7% | Training loss: 0.6887674899564848
Epoch: 33 | Iteration number: [370/4518] 8% | Training loss: 0.6887644371470889
Epoch: 33 | Iteration number: [380/4518] 8% | Training loss: 0.6887111299916318
Epoch: 33 | Iteration number: [390/4518] 8% | Training loss: 0.688636281245794
Epoch: 33 | Iteration number: [400/4518] 8% | Training loss: 0.6885733892023563
Epoch: 33 | Iteration number: [410/4518] 9% | Training loss: 0.688538837142107
Epoch: 33 | Iteration number: [420/4518] 9% | Training loss: 0.6884965490727197
Epoch: 33 | Iteration number: [430/4518] 9% | Training loss: 0.6884514462116152
Epoch: 33 | Iteration number: [440/4518] 9% | Training loss: 0.6884242294864221
Epoch: 33 | Iteration number: [450/4518] 9% | Training loss: 0.6884114257494609
Epoch: 33 | Iteration number: [460/4518] 10% | Training loss: 0.6883458877387254
Epoch: 33 | Iteration number: [470/4518] 10% | Training loss: 0.6883156288177409
Epoch: 33 | Iteration number: [480/4518] 10% | Training loss: 0.6882946668813626
Epoch: 33 | Iteration number: [490/4518] 10% | Training loss: 0.6882568636719062
Epoch: 33 | Iteration number: [500/4518] 11% | Training loss: 0.6882245243787766
Epoch: 33 | Iteration number: [510/4518] 11% | Training loss: 0.6881839197055967
Epoch: 33 | Iteration number: [520/4518] 11% | Training loss: 0.6881541630396476
Epoch: 33 | Iteration number: [530/4518] 11% | Training loss: 0.6880978655140355
Epoch: 33 | Iteration number: [540/4518] 11% | Training loss: 0.6880730242640883
Epoch: 33 | Iteration number: [550/4518] 12% | Training loss: 0.6880704219774766
Epoch: 33 | Iteration number: [560/4518] 12% | Training loss: 0.6880496202835015
Epoch: 33 | Iteration number: [570/4518] 12% | Training loss: 0.688024737228427
Epoch: 33 | Iteration number: [580/4518] 12% | Training loss: 0.6880161829035858
Epoch: 33 | Iteration number: [590/4518] 13% | Training loss: 0.6880150633343195
Epoch: 33 | Iteration number: [600/4518] 13% | Training loss: 0.6880121161540349
Epoch: 33 | Iteration number: [610/4518] 13% | Training loss: 0.6879851580643263
Epoch: 33 | Iteration number: [620/4518] 13% | Training loss: 0.6879883740217455
Epoch: 33 | Iteration number: [630/4518] 13% | Training loss: 0.6879676106430236
Epoch: 33 | Iteration number: [640/4518] 14% | Training loss: 0.6879488776437939
Epoch: 33 | Iteration number: [650/4518] 14% | Training loss: 0.6879310838992779
Epoch: 33 | Iteration number: [660/4518] 14% | Training loss: 0.687911938627561
Epoch: 33 | Iteration number: [670/4518] 14% | Training loss: 0.6878806822335543
Epoch: 33 | Iteration number: [680/4518] 15% | Training loss: 0.6878567394088296
Epoch: 33 | Iteration number: [690/4518] 15% | Training loss: 0.6878592370212941
Epoch: 33 | Iteration number: [700/4518] 15% | Training loss: 0.6878377800328391
Epoch: 33 | Iteration number: [710/4518] 15% | Training loss: 0.6878432997515503
Epoch: 33 | Iteration number: [720/4518] 15% | Training loss: 0.6878225985500548
Epoch: 33 | Iteration number: [730/4518] 16% | Training loss: 0.6878032988881412
Epoch: 33 | Iteration number: [740/4518] 16% | Training loss: 0.6877966657683656
Epoch: 33 | Iteration number: [750/4518] 16% | Training loss: 0.6877840693791707
Epoch: 33 | Iteration number: [760/4518] 16% | Training loss: 0.6877764355195196
Epoch: 33 | Iteration number: [770/4518] 17% | Training loss: 0.6877727610724312
Epoch: 33 | Iteration number: [780/4518] 17% | Training loss: 0.6877659618854522
Epoch: 33 | Iteration number: [790/4518] 17% | Training loss: 0.6877513076685652
Epoch: 33 | Iteration number: [800/4518] 17% | Training loss: 0.6877470352500678
Epoch: 33 | Iteration number: [810/4518] 17% | Training loss: 0.6877368812207822
Epoch: 33 | Iteration number: [820/4518] 18% | Training loss: 0.6877167853640347
Epoch: 33 | Iteration number: [830/4518] 18% | Training loss: 0.6877015345067863
Epoch: 33 | Iteration number: [840/4518] 18% | Training loss: 0.6876928042088236
Epoch: 33 | Iteration number: [850/4518] 18% | Training loss: 0.6876824211373048
Epoch: 33 | Iteration number: [860/4518] 19% | Training loss: 0.6876827983662139
Epoch: 33 | Iteration number: [870/4518] 19% | Training loss: 0.6876802076553477
Epoch: 33 | Iteration number: [880/4518] 19% | Training loss: 0.6876853175461293
Epoch: 33 | Iteration number: [890/4518] 19% | Training loss: 0.6876858033490985
Epoch: 33 | Iteration number: [900/4518] 19% | Training loss: 0.6876681625180774
Epoch: 33 | Iteration number: [910/4518] 20% | Training loss: 0.687670666372383
Epoch: 33 | Iteration number: [920/4518] 20% | Training loss: 0.6876650502500327
Epoch: 33 | Iteration number: [930/4518] 20% | Training loss: 0.6876582376418575
Epoch: 33 | Iteration number: [940/4518] 20% | Training loss: 0.6876533342802779
Epoch: 33 | Iteration number: [950/4518] 21% | Training loss: 0.6876484379015471
Epoch: 33 | Iteration number: [960/4518] 21% | Training loss: 0.6876370443652073
Epoch: 33 | Iteration number: [970/4518] 21% | Training loss: 0.6876357589800334
Epoch: 33 | Iteration number: [980/4518] 21% | Training loss: 0.6876131069903471
Epoch: 33 | Iteration number: [990/4518] 21% | Training loss: 0.6876149914481423
Epoch: 33 | Iteration number: [1000/4518] 22% | Training loss: 0.6876147097945213
Epoch: 33 | Iteration number: [1010/4518] 22% | Training loss: 0.6875988148226596
Epoch: 33 | Iteration number: [1020/4518] 22% | Training loss: 0.6875889747750525
Epoch: 33 | Iteration number: [1030/4518] 22% | Training loss: 0.6875838037254741
Epoch: 33 | Iteration number: [1040/4518] 23% | Training loss: 0.6875784062422239
Epoch: 33 | Iteration number: [1050/4518] 23% | Training loss: 0.6875637306485858
Epoch: 33 | Iteration number: [1060/4518] 23% | Training loss: 0.6875450826478454
Epoch: 33 | Iteration number: [1070/4518] 23% | Training loss: 0.687530157053582
Epoch: 33 | Iteration number: [1080/4518] 23% | Training loss: 0.6875234075718456
Epoch: 33 | Iteration number: [1090/4518] 24% | Training loss: 0.6875292505692998
Epoch: 33 | Iteration number: [1100/4518] 24% | Training loss: 0.6875332883271305
Epoch: 33 | Iteration number: [1110/4518] 24% | Training loss: 0.6875215057317201
Epoch: 33 | Iteration number: [1120/4518] 24% | Training loss: 0.6875071254691907
Epoch: 33 | Iteration number: [1130/4518] 25% | Training loss: 0.6875041587162862
Epoch: 33 | Iteration number: [1140/4518] 25% | Training loss: 0.6874923974798437
Epoch: 33 | Iteration number: [1150/4518] 25% | Training loss: 0.6874898571035136
Epoch: 33 | Iteration number: [1160/4518] 25% | Training loss: 0.6874896955387345
Epoch: 33 | Iteration number: [1170/4518] 25% | Training loss: 0.6874935928572956
Epoch: 33 | Iteration number: [1180/4518] 26% | Training loss: 0.6874836497892768
Epoch: 33 | Iteration number: [1190/4518] 26% | Training loss: 0.687474204061412
Epoch: 33 | Iteration number: [1200/4518] 26% | Training loss: 0.6874665900071462
Epoch: 33 | Iteration number: [1210/4518] 26% | Training loss: 0.6874565426475746
Epoch: 33 | Iteration number: [1220/4518] 27% | Training loss: 0.6874536889009788
Epoch: 33 | Iteration number: [1230/4518] 27% | Training loss: 0.6874490243148028
Epoch: 33 | Iteration number: [1240/4518] 27% | Training loss: 0.6874462274293746
Epoch: 33 | Iteration number: [1250/4518] 27% | Training loss: 0.6874388401508331
Epoch: 33 | Iteration number: [1260/4518] 27% | Training loss: 0.6874283786803957
Epoch: 33 | Iteration number: [1270/4518] 28% | Training loss: 0.6874223576286647
Epoch: 33 | Iteration number: [1280/4518] 28% | Training loss: 0.6874021367635578
Epoch: 33 | Iteration number: [1290/4518] 28% | Training loss: 0.6873982056628826
Epoch: 33 | Iteration number: [1300/4518] 28% | Training loss: 0.6873929325892375
Epoch: 33 | Iteration number: [1310/4518] 28% | Training loss: 0.6873871529375324
Epoch: 33 | Iteration number: [1320/4518] 29% | Training loss: 0.6873825455705325
Epoch: 33 | Iteration number: [1330/4518] 29% | Training loss: 0.6873801102315573
Epoch: 33 | Iteration number: [1340/4518] 29% | Training loss: 0.6873751788886625
Epoch: 33 | Iteration number: [1350/4518] 29% | Training loss: 0.6873720203947138
Epoch: 33 | Iteration number: [1360/4518] 30% | Training loss: 0.6873710503473002
Epoch: 33 | Iteration number: [1370/4518] 30% | Training loss: 0.6873743028971401
Epoch: 33 | Iteration number: [1380/4518] 30% | Training loss: 0.6873711920734765
Epoch: 33 | Iteration number: [1390/4518] 30% | Training loss: 0.6873687827329842
Epoch: 33 | Iteration number: [1400/4518] 30% | Training loss: 0.6873612559267452
Epoch: 33 | Iteration number: [1410/4518] 31% | Training loss: 0.6873563356010627
Epoch: 33 | Iteration number: [1420/4518] 31% | Training loss: 0.6873489487758825
Epoch: 33 | Iteration number: [1430/4518] 31% | Training loss: 0.687340715381649
Epoch: 33 | Iteration number: [1440/4518] 31% | Training loss: 0.6873284543967909
Epoch: 33 | Iteration number: [1450/4518] 32% | Training loss: 0.6873141541974298
Epoch: 33 | Iteration number: [1460/4518] 32% | Training loss: 0.687305580467394
Epoch: 33 | Iteration number: [1470/4518] 32% | Training loss: 0.6873028362689375
Epoch: 33 | Iteration number: [1480/4518] 32% | Training loss: 0.6872948129032109
Epoch: 33 | Iteration number: [1490/4518] 32% | Training loss: 0.6872974182135306
Epoch: 33 | Iteration number: [1500/4518] 33% | Training loss: 0.6872848540147145
Epoch: 33 | Iteration number: [1510/4518] 33% | Training loss: 0.68728709374832
Epoch: 33 | Iteration number: [1520/4518] 33% | Training loss: 0.6872816206593263
Epoch: 33 | Iteration number: [1530/4518] 33% | Training loss: 0.6872848682543811
Epoch: 33 | Iteration number: [1540/4518] 34% | Training loss: 0.6872793999198196
Epoch: 33 | Iteration number: [1550/4518] 34% | Training loss: 0.6872772524433751
Epoch: 33 | Iteration number: [1560/4518] 34% | Training loss: 0.6872737312928224
Epoch: 33 | Iteration number: [1570/4518] 34% | Training loss: 0.6872725091542408
Epoch: 33 | Iteration number: [1580/4518] 34% | Training loss: 0.6872712881881979
Epoch: 33 | Iteration number: [1590/4518] 35% | Training loss: 0.6872670941007962
Epoch: 33 | Iteration number: [1600/4518] 35% | Training loss: 0.6872661961615085
Epoch: 33 | Iteration number: [1610/4518] 35% | Training loss: 0.6872646970038088
Epoch: 33 | Iteration number: [1620/4518] 35% | Training loss: 0.6872636668843988
Epoch: 33 | Iteration number: [1630/4518] 36% | Training loss: 0.687260431563196
Epoch: 33 | Iteration number: [1640/4518] 36% | Training loss: 0.6872524344703046
Epoch: 33 | Iteration number: [1650/4518] 36% | Training loss: 0.687248103763118
Epoch: 33 | Iteration number: [1660/4518] 36% | Training loss: 0.6872530647789139
Epoch: 33 | Iteration number: [1670/4518] 36% | Training loss: 0.6872476838306039
Epoch: 33 | Iteration number: [1680/4518] 37% | Training loss: 0.6872444928401993
Epoch: 33 | Iteration number: [1690/4518] 37% | Training loss: 0.6872393105157029
Epoch: 33 | Iteration number: [1700/4518] 37% | Training loss: 0.6872388595693252
Epoch: 33 | Iteration number: [1710/4518] 37% | Training loss: 0.6872368799315558
Epoch: 33 | Iteration number: [1720/4518] 38% | Training loss: 0.6872347859449165
Epoch: 33 | Iteration number: [1730/4518] 38% | Training loss: 0.6872359574530166
Epoch: 33 | Iteration number: [1740/4518] 38% | Training loss: 0.6872389834845203
Epoch: 33 | Iteration number: [1750/4518] 38% | Training loss: 0.6872351378372737
Epoch: 33 | Iteration number: [1760/4518] 38% | Training loss: 0.6872427765280008
Epoch: 33 | Iteration number: [1770/4518] 39% | Training loss: 0.6872381931307625
Epoch: 33 | Iteration number: [1780/4518] 39% | Training loss: 0.6872381105181876
Epoch: 33 | Iteration number: [1790/4518] 39% | Training loss: 0.6872426062655849
Epoch: 33 | Iteration number: [1800/4518] 39% | Training loss: 0.6872409130136172
Epoch: 33 | Iteration number: [1810/4518] 40% | Training loss: 0.6872379443263481
Epoch: 33 | Iteration number: [1820/4518] 40% | Training loss: 0.6872327221291405
Epoch: 33 | Iteration number: [1830/4518] 40% | Training loss: 0.6872278575363054
Epoch: 33 | Iteration number: [1840/4518] 40% | Training loss: 0.6872197145029254
Epoch: 33 | Iteration number: [1850/4518] 40% | Training loss: 0.6872190566965052
Epoch: 33 | Iteration number: [1860/4518] 41% | Training loss: 0.6872183824739149
Epoch: 33 | Iteration number: [1870/4518] 41% | Training loss: 0.6872162772372444
Epoch: 33 | Iteration number: [1880/4518] 41% | Training loss: 0.6872119272325902
Epoch: 33 | Iteration number: [1890/4518] 41% | Training loss: 0.687210083323181
Epoch: 33 | Iteration number: [1900/4518] 42% | Training loss: 0.6872041936297165
Epoch: 33 | Iteration number: [1910/4518] 42% | Training loss: 0.6871994504129699
Epoch: 33 | Iteration number: [1920/4518] 42% | Training loss: 0.6872028194367885
Epoch: 33 | Iteration number: [1930/4518] 42% | Training loss: 0.6872026419083689
Epoch: 33 | Iteration number: [1940/4518] 42% | Training loss: 0.687196838579227
Epoch: 33 | Iteration number: [1950/4518] 43% | Training loss: 0.6872015579541524
Epoch: 33 | Iteration number: [1960/4518] 43% | Training loss: 0.6872027652604239
Epoch: 33 | Iteration number: [1970/4518] 43% | Training loss: 0.6872020528703777
Epoch: 33 | Iteration number: [1980/4518] 43% | Training loss: 0.6871953488600374
Epoch: 33 | Iteration number: [1990/4518] 44% | Training loss: 0.6871927265845351
Epoch: 33 | Iteration number: [2000/4518] 44% | Training loss: 0.687190730959177
Epoch: 33 | Iteration number: [2010/4518] 44% | Training loss: 0.687195296933995
Epoch: 33 | Iteration number: [2020/4518] 44% | Training loss: 0.6871988632006221
Epoch: 33 | Iteration number: [2030/4518] 44% | Training loss: 0.6872002180867595
Epoch: 33 | Iteration number: [2040/4518] 45% | Training loss: 0.6871979190730582
Epoch: 33 | Iteration number: [2050/4518] 45% | Training loss: 0.6871951417806672
Epoch: 33 | Iteration number: [2060/4518] 45% | Training loss: 0.6871915648573811
Epoch: 33 | Iteration number: [2070/4518] 45% | Training loss: 0.6871863837403376
Epoch: 33 | Iteration number: [2080/4518] 46% | Training loss: 0.6871827555103944
Epoch: 33 | Iteration number: [2090/4518] 46% | Training loss: 0.6871793799137955
Epoch: 33 | Iteration number: [2100/4518] 46% | Training loss: 0.6871806848616827
Epoch: 33 | Iteration number: [2110/4518] 46% | Training loss: 0.6871814541059648
Epoch: 33 | Iteration number: [2120/4518] 46% | Training loss: 0.6871813147416654
Epoch: 33 | Iteration number: [2130/4518] 47% | Training loss: 0.6871816540827773
Epoch: 33 | Iteration number: [2140/4518] 47% | Training loss: 0.6871803211831601
Epoch: 33 | Iteration number: [2150/4518] 47% | Training loss: 0.6871824418666751
Epoch: 33 | Iteration number: [2160/4518] 47% | Training loss: 0.6871790352518912
Epoch: 33 | Iteration number: [2170/4518] 48% | Training loss: 0.6871793169305072
Epoch: 33 | Iteration number: [2180/4518] 48% | Training loss: 0.6871710615967391
Epoch: 33 | Iteration number: [2190/4518] 48% | Training loss: 0.6871735466941851
Epoch: 33 | Iteration number: [2200/4518] 48% | Training loss: 0.687173587788235
Epoch: 33 | Iteration number: [2210/4518] 48% | Training loss: 0.6871698148380038
Epoch: 33 | Iteration number: [2220/4518] 49% | Training loss: 0.6871700780348735
Epoch: 33 | Iteration number: [2230/4518] 49% | Training loss: 0.6871664771050081
Epoch: 33 | Iteration number: [2240/4518] 49% | Training loss: 0.6871658018124955
Epoch: 33 | Iteration number: [2250/4518] 49% | Training loss: 0.6871649226612515
Epoch: 33 | Iteration number: [2260/4518] 50% | Training loss: 0.6871632228646658
Epoch: 33 | Iteration number: [2270/4518] 50% | Training loss: 0.687165059838526
Epoch: 33 | Iteration number: [2280/4518] 50% | Training loss: 0.6871639931933922
Epoch: 33 | Iteration number: [2290/4518] 50% | Training loss: 0.6871617939534667
Epoch: 33 | Iteration number: [2300/4518] 50% | Training loss: 0.6871593523802965
Epoch: 33 | Iteration number: [2310/4518] 51% | Training loss: 0.6871636606140055
Epoch: 33 | Iteration number: [2320/4518] 51% | Training loss: 0.6871626784061563
Epoch: 33 | Iteration number: [2330/4518] 51% | Training loss: 0.6871620300245899
Epoch: 33 | Iteration number: [2340/4518] 51% | Training loss: 0.6871559886341421
Epoch: 33 | Iteration number: [2350/4518] 52% | Training loss: 0.6871522986635249
Epoch: 33 | Iteration number: [2360/4518] 52% | Training loss: 0.6871534568525977
Epoch: 33 | Iteration number: [2370/4518] 52% | Training loss: 0.6871497030499615
Epoch: 33 | Iteration number: [2380/4518] 52% | Training loss: 0.6871452844193002
Epoch: 33 | Iteration number: [2390/4518] 52% | Training loss: 0.6871460389891428
Epoch: 33 | Iteration number: [2400/4518] 53% | Training loss: 0.6871459323912859
Epoch: 33 | Iteration number: [2410/4518] 53% | Training loss: 0.6871498750700495
Epoch: 33 | Iteration number: [2420/4518] 53% | Training loss: 0.6871454348002584
Epoch: 33 | Iteration number: [2430/4518] 53% | Training loss: 0.6871432750803943
Epoch: 33 | Iteration number: [2440/4518] 54% | Training loss: 0.687141717921515
Epoch: 33 | Iteration number: [2450/4518] 54% | Training loss: 0.6871474439757211
Epoch: 33 | Iteration number: [2460/4518] 54% | Training loss: 0.6871412862122543
Epoch: 33 | Iteration number: [2470/4518] 54% | Training loss: 0.6871423537190626
Epoch: 33 | Iteration number: [2480/4518] 54% | Training loss: 0.6871366251620554
Epoch: 33 | Iteration number: [2490/4518] 55% | Training loss: 0.6871345956162755
Epoch: 33 | Iteration number: [2500/4518] 55% | Training loss: 0.6871275466918946
Epoch: 33 | Iteration number: [2510/4518] 55% | Training loss: 0.6871213674545288
Epoch: 33 | Iteration number: [2520/4518] 55% | Training loss: 0.6871213608554432
Epoch: 33 | Iteration number: [2530/4518] 55% | Training loss: 0.6871178466340769
Epoch: 33 | Iteration number: [2540/4518] 56% | Training loss: 0.6871231715744874
Epoch: 33 | Iteration number: [2550/4518] 56% | Training loss: 0.6871193127772387
Epoch: 33 | Iteration number: [2560/4518] 56% | Training loss: 0.6871201981557533
Epoch: 33 | Iteration number: [2570/4518] 56% | Training loss: 0.6871193744097238
Epoch: 33 | Iteration number: [2580/4518] 57% | Training loss: 0.6871206801067027
Epoch: 33 | Iteration number: [2590/4518] 57% | Training loss: 0.6871217378778347
Epoch: 33 | Iteration number: [2600/4518] 57% | Training loss: 0.687115115064841
Epoch: 33 | Iteration number: [2610/4518] 57% | Training loss: 0.6871141145740889
Epoch: 33 | Iteration number: [2620/4518] 57% | Training loss: 0.6871128600972299
Epoch: 33 | Iteration number: [2630/4518] 58% | Training loss: 0.687109940473571
Epoch: 33 | Iteration number: [2640/4518] 58% | Training loss: 0.6871066311317863
Epoch: 33 | Iteration number: [2650/4518] 58% | Training loss: 0.6871030094488612
Epoch: 33 | Iteration number: [2660/4518] 58% | Training loss: 0.6871023524524574
Epoch: 33 | Iteration number: [2670/4518] 59% | Training loss: 0.6870996398202489
Epoch: 33 | Iteration number: [2680/4518] 59% | Training loss: 0.6870972178542792
Epoch: 33 | Iteration number: [2690/4518] 59% | Training loss: 0.6870963623310997
Epoch: 33 | Iteration number: [2700/4518] 59% | Training loss: 0.6870912418321327
Epoch: 33 | Iteration number: [2710/4518] 59% | Training loss: 0.6870885356106001
Epoch: 33 | Iteration number: [2720/4518] 60% | Training loss: 0.6870897907325451
Epoch: 33 | Iteration number: [2730/4518] 60% | Training loss: 0.6870863063431485
Epoch: 33 | Iteration number: [2740/4518] 60% | Training loss: 0.6870903368196348
Epoch: 33 | Iteration number: [2750/4518] 60% | Training loss: 0.6870900821035558
Epoch: 33 | Iteration number: [2760/4518] 61% | Training loss: 0.6870934118179307
Epoch: 33 | Iteration number: [2770/4518] 61% | Training loss: 0.6870924200391941
Epoch: 33 | Iteration number: [2780/4518] 61% | Training loss: 0.6870908872257891
Epoch: 33 | Iteration number: [2790/4518] 61% | Training loss: 0.6870895650224447
Epoch: 33 | Iteration number: [2800/4518] 61% | Training loss: 0.6870885115223272
Epoch: 33 | Iteration number: [2810/4518] 62% | Training loss: 0.6870887485475302
Epoch: 33 | Iteration number: [2820/4518] 62% | Training loss: 0.6870900993228805
Epoch: 33 | Iteration number: [2830/4518] 62% | Training loss: 0.6870909548900995
Epoch: 33 | Iteration number: [2840/4518] 62% | Training loss: 0.6870874968213094
Epoch: 33 | Iteration number: [2850/4518] 63% | Training loss: 0.6870883396633884
Epoch: 33 | Iteration number: [2860/4518] 63% | Training loss: 0.6870905683590816
Epoch: 33 | Iteration number: [2870/4518] 63% | Training loss: 0.6870892066988795
Epoch: 33 | Iteration number: [2880/4518] 63% | Training loss: 0.6870892804529932
Epoch: 33 | Iteration number: [2890/4518] 63% | Training loss: 0.6870905703739312
Epoch: 33 | Iteration number: [2900/4518] 64% | Training loss: 0.6870931433398149
Epoch: 33 | Iteration number: [2910/4518] 64% | Training loss: 0.687092143665884
Epoch: 33 | Iteration number: [2920/4518] 64% | Training loss: 0.6870902623419892
Epoch: 33 | Iteration number: [2930/4518] 64% | Training loss: 0.6870885832928146
Epoch: 33 | Iteration number: [2940/4518] 65% | Training loss: 0.6870870203793454
Epoch: 33 | Iteration number: [2950/4518] 65% | Training loss: 0.687086833048675
Epoch: 33 | Iteration number: [2960/4518] 65% | Training loss: 0.6870812071940383
Epoch: 33 | Iteration number: [2970/4518] 65% | Training loss: 0.6870779800696004
Epoch: 33 | Iteration number: [2980/4518] 65% | Training loss: 0.6870780665002413
Epoch: 33 | Iteration number: [2990/4518] 66% | Training loss: 0.6870780336617626
Epoch: 33 | Iteration number: [3000/4518] 66% | Training loss: 0.6870695981582006
Epoch: 33 | Iteration number: [3010/4518] 66% | Training loss: 0.6870719439563561
Epoch: 33 | Iteration number: [3020/4518] 66% | Training loss: 0.6870744435400363
Epoch: 33 | Iteration number: [3030/4518] 67% | Training loss: 0.6870728783088156
Epoch: 33 | Iteration number: [3040/4518] 67% | Training loss: 0.6870730709872748
Epoch: 33 | Iteration number: [3050/4518] 67% | Training loss: 0.6870710895491428
Epoch: 33 | Iteration number: [3060/4518] 67% | Training loss: 0.6870712545572543
Epoch: 33 | Iteration number: [3070/4518] 67% | Training loss: 0.6870726550829138
Epoch: 33 | Iteration number: [3080/4518] 68% | Training loss: 0.6870720531259265
Epoch: 33 | Iteration number: [3090/4518] 68% | Training loss: 0.6870740974798172
Epoch: 33 | Iteration number: [3100/4518] 68% | Training loss: 0.6870711253727636
Epoch: 33 | Iteration number: [3110/4518] 68% | Training loss: 0.687073200193632
Epoch: 33 | Iteration number: [3120/4518] 69% | Training loss: 0.6870725769072007
Epoch: 33 | Iteration number: [3130/4518] 69% | Training loss: 0.68707509895864
Epoch: 33 | Iteration number: [3140/4518] 69% | Training loss: 0.6870702905070251
Epoch: 33 | Iteration number: [3150/4518] 69% | Training loss: 0.6870668602368188
Epoch: 33 | Iteration number: [3160/4518] 69% | Training loss: 0.6870628032126004
Epoch: 33 | Iteration number: [3170/4518] 70% | Training loss: 0.687064565318616
Epoch: 33 | Iteration number: [3180/4518] 70% | Training loss: 0.6870598860131869
Epoch: 33 | Iteration number: [3190/4518] 70% | Training loss: 0.687061733474552
Epoch: 33 | Iteration number: [3200/4518] 70% | Training loss: 0.6870604311861098
Epoch: 33 | Iteration number: [3210/4518] 71% | Training loss: 0.6870647553899949
Epoch: 33 | Iteration number: [3220/4518] 71% | Training loss: 0.6870624121116555
Epoch: 33 | Iteration number: [3230/4518] 71% | Training loss: 0.6870608076222541
Epoch: 33 | Iteration number: [3240/4518] 71% | Training loss: 0.6870592709124824
Epoch: 33 | Iteration number: [3250/4518] 71% | Training loss: 0.6870577673361852
Epoch: 33 | Iteration number: [3260/4518] 72% | Training loss: 0.687057277212845
Epoch: 33 | Iteration number: [3270/4518] 72% | Training loss: 0.6870553060591403
Epoch: 33 | Iteration number: [3280/4518] 72% | Training loss: 0.687053296696849
Epoch: 33 | Iteration number: [3290/4518] 72% | Training loss: 0.6870507575095968
Epoch: 33 | Iteration number: [3300/4518] 73% | Training loss: 0.6870473265647888
Epoch: 33 | Iteration number: [3310/4518] 73% | Training loss: 0.6870499614322294
Epoch: 33 | Iteration number: [3320/4518] 73% | Training loss: 0.6870490308626589
Epoch: 33 | Iteration number: [3330/4518] 73% | Training loss: 0.6870491477999243
Epoch: 33 | Iteration number: [3340/4518] 73% | Training loss: 0.6870473700190732
Epoch: 33 | Iteration number: [3350/4518] 74% | Training loss: 0.6870476620054957
Epoch: 33 | Iteration number: [3360/4518] 74% | Training loss: 0.6870509398657652
Epoch: 33 | Iteration number: [3370/4518] 74% | Training loss: 0.6870517655720697
Epoch: 33 | Iteration number: [3380/4518] 74% | Training loss: 0.6870468615780215
Epoch: 33 | Iteration number: [3390/4518] 75% | Training loss: 0.687047370608929
Epoch: 33 | Iteration number: [3400/4518] 75% | Training loss: 0.6870466798368622
Epoch: 33 | Iteration number: [3410/4518] 75% | Training loss: 0.6870464918550508
Epoch: 33 | Iteration number: [3420/4518] 75% | Training loss: 0.6870474234833355
Epoch: 33 | Iteration number: [3430/4518] 75% | Training loss: 0.6870454224309838
Epoch: 33 | Iteration number: [3440/4518] 76% | Training loss: 0.6870470245736976
Epoch: 33 | Iteration number: [3450/4518] 76% | Training loss: 0.6870464909422225
Epoch: 33 | Iteration number: [3460/4518] 76% | Training loss: 0.6870451668438884
Epoch: 33 | Iteration number: [3470/4518] 76% | Training loss: 0.6870424629116608
Epoch: 33 | Iteration number: [3480/4518] 77% | Training loss: 0.6870442605395427
Epoch: 33 | Iteration number: [3490/4518] 77% | Training loss: 0.6870434950279302
Epoch: 33 | Iteration number: [3500/4518] 77% | Training loss: 0.6870415234054837
Epoch: 33 | Iteration number: [3510/4518] 77% | Training loss: 0.6870413733853235
Epoch: 33 | Iteration number: [3520/4518] 77% | Training loss: 0.687044043127786
Epoch: 33 | Iteration number: [3530/4518] 78% | Training loss: 0.6870458495346751
Epoch: 33 | Iteration number: [3540/4518] 78% | Training loss: 0.6870405136023537
Epoch: 33 | Iteration number: [3550/4518] 78% | Training loss: 0.6870401150911627
Epoch: 33 | Iteration number: [3560/4518] 78% | Training loss: 0.6870393606886435
Epoch: 33 | Iteration number: [3570/4518] 79% | Training loss: 0.687036353883957
Epoch: 33 | Iteration number: [3580/4518] 79% | Training loss: 0.687035496607839
Epoch: 33 | Iteration number: [3590/4518] 79% | Training loss: 0.6870344305768983
Epoch: 33 | Iteration number: [3600/4518] 79% | Training loss: 0.6870323790775406
Epoch: 33 | Iteration number: [3610/4518] 79% | Training loss: 0.6870362622420874
Epoch: 33 | Iteration number: [3620/4518] 80% | Training loss: 0.6870369699284516
Epoch: 33 | Iteration number: [3630/4518] 80% | Training loss: 0.6870352863772842
Epoch: 33 | Iteration number: [3640/4518] 80% | Training loss: 0.6870358476926992
Epoch: 33 | Iteration number: [3650/4518] 80% | Training loss: 0.6870322845896629
Epoch: 33 | Iteration number: [3660/4518] 81% | Training loss: 0.6870351345812689
Epoch: 33 | Iteration number: [3670/4518] 81% | Training loss: 0.6870370332324213
Epoch: 33 | Iteration number: [3680/4518] 81% | Training loss: 0.687035896629095
Epoch: 33 | Iteration number: [3690/4518] 81% | Training loss: 0.6870344216907573
Epoch: 33 | Iteration number: [3700/4518] 81% | Training loss: 0.6870364296919591
Epoch: 33 | Iteration number: [3710/4518] 82% | Training loss: 0.6870352192709067
Epoch: 33 | Iteration number: [3720/4518] 82% | Training loss: 0.6870346505475301
Epoch: 33 | Iteration number: [3730/4518] 82% | Training loss: 0.6870349634588564
Epoch: 33 | Iteration number: [3740/4518] 82% | Training loss: 0.6870390895694335
Epoch: 33 | Iteration number: [3750/4518] 83% | Training loss: 0.6870364901065826
Epoch: 33 | Iteration number: [3760/4518] 83% | Training loss: 0.687038664107627
Epoch: 33 | Iteration number: [3770/4518] 83% | Training loss: 0.6870357031531296
Epoch: 33 | Iteration number: [3780/4518] 83% | Training loss: 0.6870369668517794
Epoch: 33 | Iteration number: [3790/4518] 83% | Training loss: 0.6870341574768277
Epoch: 33 | Iteration number: [3800/4518] 84% | Training loss: 0.6870370249528633
Epoch: 33 | Iteration number: [3810/4518] 84% | Training loss: 0.6870397818995899
Epoch: 33 | Iteration number: [3820/4518] 84% | Training loss: 0.6870402616356056
Epoch: 33 | Iteration number: [3830/4518] 84% | Training loss: 0.6870384487875448
Epoch: 33 | Iteration number: [3840/4518] 84% | Training loss: 0.6870343643240631
Epoch: 33 | Iteration number: [3850/4518] 85% | Training loss: 0.6870369063104902
Epoch: 33 | Iteration number: [3860/4518] 85% | Training loss: 0.6870358555428104
Epoch: 33 | Iteration number: [3870/4518] 85% | Training loss: 0.6870352074465395
Epoch: 33 | Iteration number: [3880/4518] 85% | Training loss: 0.6870370298777659
Epoch: 33 | Iteration number: [3890/4518] 86% | Training loss: 0.6870378237303854
Epoch: 33 | Iteration number: [3900/4518] 86% | Training loss: 0.687036103101877
Epoch: 33 | Iteration number: [3910/4518] 86% | Training loss: 0.6870358608110482
Epoch: 33 | Iteration number: [3920/4518] 86% | Training loss: 0.6870331552259776
Epoch: 33 | Iteration number: [3930/4518] 86% | Training loss: 0.6870314986347849
Epoch: 33 | Iteration number: [3940/4518] 87% | Training loss: 0.6870298082907188
Epoch: 33 | Iteration number: [3950/4518] 87% | Training loss: 0.687029866764817
Epoch: 33 | Iteration number: [3960/4518] 87% | Training loss: 0.6870279618585953
Epoch: 33 | Iteration number: [3970/4518] 87% | Training loss: 0.6870274570186432
Epoch: 33 | Iteration number: [3980/4518] 88% | Training loss: 0.6870274110355569
Epoch: 33 | Iteration number: [3990/4518] 88% | Training loss: 0.6870304946612594
Epoch: 33 | Iteration number: [4000/4518] 88% | Training loss: 0.6870271346271039
Epoch: 33 | Iteration number: [4010/4518] 88% | Training loss: 0.6870232785877741
Epoch: 33 | Iteration number: [4020/4518] 88% | Training loss: 0.6870238799509124
Epoch: 33 | Iteration number: [4030/4518] 89% | Training loss: 0.6870211299092834
Epoch: 33 | Iteration number: [4040/4518] 89% | Training loss: 0.6870241742470476
Epoch: 33 | Iteration number: [4050/4518] 89% | Training loss: 0.6870232972981017
Epoch: 33 | Iteration number: [4060/4518] 89% | Training loss: 0.6870211396017686
Epoch: 33 | Iteration number: [4070/4518] 90% | Training loss: 0.687019084741794
Epoch: 33 | Iteration number: [4080/4518] 90% | Training loss: 0.6870195481268798
Epoch: 33 | Iteration number: [4090/4518] 90% | Training loss: 0.6870164780715858
Epoch: 33 | Iteration number: [4100/4518] 90% | Training loss: 0.6870089730402319
Epoch: 33 | Iteration number: [4110/4518] 90% | Training loss: 0.6870079168147994
Epoch: 33 | Iteration number: [4120/4518] 91% | Training loss: 0.6870062521215782
Epoch: 33 | Iteration number: [4130/4518] 91% | Training loss: 0.6870035061680376
Epoch: 33 | Iteration number: [4140/4518] 91% | Training loss: 0.6870015118721027
Epoch: 33 | Iteration number: [4150/4518] 91% | Training loss: 0.6870004590591753
Epoch: 33 | Iteration number: [4160/4518] 92% | Training loss: 0.6869988428572049
Epoch: 33 | Iteration number: [4170/4518] 92% | Training loss: 0.6869975217812353
Epoch: 33 | Iteration number: [4180/4518] 92% | Training loss: 0.6869982559002187
Epoch: 33 | Iteration number: [4190/4518] 92% | Training loss: 0.6869980943515932
Epoch: 33 | Iteration number: [4200/4518] 92% | Training loss: 0.6870002871326037
Epoch: 33 | Iteration number: [4210/4518] 93% | Training loss: 0.6870022229230885
Epoch: 33 | Iteration number: [4220/4518] 93% | Training loss: 0.6870018928678114
Epoch: 33 | Iteration number: [4230/4518] 93% | Training loss: 0.6870021490763265
Epoch: 33 | Iteration number: [4240/4518] 93% | Training loss: 0.6869994800186382
Epoch: 33 | Iteration number: [4250/4518] 94% | Training loss: 0.6869978659433477
Epoch: 33 | Iteration number: [4260/4518] 94% | Training loss: 0.6869943539861222
Epoch: 33 | Iteration number: [4270/4518] 94% | Training loss: 0.6869947561893865
Epoch: 33 | Iteration number: [4280/4518] 94% | Training loss: 0.6869937886840829
Epoch: 33 | Iteration number: [4290/4518] 94% | Training loss: 0.6869951490616742
Epoch: 33 | Iteration number: [4300/4518] 95% | Training loss: 0.6869945807928263
Epoch: 33 | Iteration number: [4310/4518] 95% | Training loss: 0.6869957979206696
Epoch: 33 | Iteration number: [4320/4518] 95% | Training loss: 0.6870003642307387
Epoch: 33 | Iteration number: [4330/4518] 95% | Training loss: 0.6869987054454813
Epoch: 33 | Iteration number: [4340/4518] 96% | Training loss: 0.6869997148140234
Epoch: 33 | Iteration number: [4350/4518] 96% | Training loss: 0.6869989627120139
Epoch: 33 | Iteration number: [4360/4518] 96% | Training loss: 0.6869995795395396
Epoch: 33 | Iteration number: [4370/4518] 96% | Training loss: 0.6869995516961445
Epoch: 33 | Iteration number: [4380/4518] 96% | Training loss: 0.6870007736906069
Epoch: 33 | Iteration number: [4390/4518] 97% | Training loss: 0.6869986518233132
Epoch: 33 | Iteration number: [4400/4518] 97% | Training loss: 0.687000568563288
Epoch: 33 | Iteration number: [4410/4518] 97% | Training loss: 0.6869995045959274
Epoch: 33 | Iteration number: [4420/4518] 97% | Training loss: 0.6869972229947872
Epoch: 33 | Iteration number: [4430/4518] 98% | Training loss: 0.6869967269305451
Epoch: 33 | Iteration number: [4440/4518] 98% | Training loss: 0.6869968570701711
Epoch: 33 | Iteration number: [4450/4518] 98% | Training loss: 0.6869956769166368
Epoch: 33 | Iteration number: [4460/4518] 98% | Training loss: 0.68699531120837
Epoch: 33 | Iteration number: [4470/4518] 98% | Training loss: 0.6869943618107696
Epoch: 33 | Iteration number: [4480/4518] 99% | Training loss: 0.6869939057821673
Epoch: 33 | Iteration number: [4490/4518] 99% | Training loss: 0.6869926016686488
Epoch: 33 | Iteration number: [4500/4518] 99% | Training loss: 0.6869902582698398
Epoch: 33 | Iteration number: [4510/4518] 99% | Training loss: 0.686989908591078

 End of epoch: 33 | Train Loss: 0.6868390734346633 | Training Time: 633 

 End of epoch: 33 | Eval Loss: 0.6898368438895868 | Evaluating Time: 17 
Epoch: 34 | Iteration number: [10/4518] 0% | Training loss: 0.7555126070976257
Epoch: 34 | Iteration number: [20/4518] 0% | Training loss: 0.721930530667305
Epoch: 34 | Iteration number: [30/4518] 0% | Training loss: 0.7103376189867655
Epoch: 34 | Iteration number: [40/4518] 0% | Training loss: 0.7045228704810143
Epoch: 34 | Iteration number: [50/4518] 1% | Training loss: 0.7012245762348175
Epoch: 34 | Iteration number: [60/4518] 1% | Training loss: 0.6989327579736709
Epoch: 34 | Iteration number: [70/4518] 1% | Training loss: 0.6971469036170415
Epoch: 34 | Iteration number: [80/4518] 1% | Training loss: 0.6959068842232228
Epoch: 34 | Iteration number: [90/4518] 1% | Training loss: 0.6950088673167758
Epoch: 34 | Iteration number: [100/4518] 2% | Training loss: 0.6940367257595063
Epoch: 34 | Iteration number: [110/4518] 2% | Training loss: 0.6933620371601799
Epoch: 34 | Iteration number: [120/4518] 2% | Training loss: 0.6928088883558909
Epoch: 34 | Iteration number: [130/4518] 2% | Training loss: 0.692436530498358
Epoch: 34 | Iteration number: [140/4518] 3% | Training loss: 0.6920623621770314
Epoch: 34 | Iteration number: [150/4518] 3% | Training loss: 0.6917353292306264
Epoch: 34 | Iteration number: [160/4518] 3% | Training loss: 0.6914384167641401
Epoch: 34 | Iteration number: [170/4518] 3% | Training loss: 0.6911107578698327
Epoch: 34 | Iteration number: [180/4518] 3% | Training loss: 0.6908494273821513
Epoch: 34 | Iteration number: [190/4518] 4% | Training loss: 0.690616384305452
Epoch: 34 | Iteration number: [200/4518] 4% | Training loss: 0.6903673884272575
Epoch: 34 | Iteration number: [210/4518] 4% | Training loss: 0.6901893127532233
Epoch: 34 | Iteration number: [220/4518] 4% | Training loss: 0.6900740065357902
Epoch: 34 | Iteration number: [230/4518] 5% | Training loss: 0.6899369244990141
Epoch: 34 | Iteration number: [240/4518] 5% | Training loss: 0.689841075738271
Epoch: 34 | Iteration number: [250/4518] 5% | Training loss: 0.689635178565979
Epoch: 34 | Iteration number: [260/4518] 5% | Training loss: 0.6894908192066046
Epoch: 34 | Iteration number: [270/4518] 5% | Training loss: 0.6893941221413789
Epoch: 34 | Iteration number: [280/4518] 6% | Training loss: 0.6893144837447576
Epoch: 34 | Iteration number: [290/4518] 6% | Training loss: 0.689258853525951
Epoch: 34 | Iteration number: [300/4518] 6% | Training loss: 0.689180058836937
Epoch: 34 | Iteration number: [310/4518] 6% | Training loss: 0.6891030286588976
Epoch: 34 | Iteration number: [320/4518] 7% | Training loss: 0.6890366991981864
Epoch: 34 | Iteration number: [330/4518] 7% | Training loss: 0.6889650933670275
Epoch: 34 | Iteration number: [340/4518] 7% | Training loss: 0.6889392872067058
Epoch: 34 | Iteration number: [350/4518] 7% | Training loss: 0.6889370495932443
Epoch: 34 | Iteration number: [360/4518] 7% | Training loss: 0.6888917851779196
Epoch: 34 | Iteration number: [370/4518] 8% | Training loss: 0.688868310161539
Epoch: 34 | Iteration number: [380/4518] 8% | Training loss: 0.6888465977028797
Epoch: 34 | Iteration number: [390/4518] 8% | Training loss: 0.6888083641345685
Epoch: 34 | Iteration number: [400/4518] 8% | Training loss: 0.6887416619062424
Epoch: 34 | Iteration number: [410/4518] 9% | Training loss: 0.6886915062985769
Epoch: 34 | Iteration number: [420/4518] 9% | Training loss: 0.6886422097682953
Epoch: 34 | Iteration number: [430/4518] 9% | Training loss: 0.6886167987834576
Epoch: 34 | Iteration number: [440/4518] 9% | Training loss: 0.6885882091793147
Epoch: 34 | Iteration number: [450/4518] 9% | Training loss: 0.688527131345537
Epoch: 34 | Iteration number: [460/4518] 10% | Training loss: 0.688494828991268
Epoch: 34 | Iteration number: [470/4518] 10% | Training loss: 0.6884486466012103
Epoch: 34 | Iteration number: [480/4518] 10% | Training loss: 0.6883957266807557
Epoch: 34 | Iteration number: [490/4518] 10% | Training loss: 0.6883547257403938
Epoch: 34 | Iteration number: [500/4518] 11% | Training loss: 0.6883045120239257
Epoch: 34 | Iteration number: [510/4518] 11% | Training loss: 0.6882480310458763
Epoch: 34 | Iteration number: [520/4518] 11% | Training loss: 0.6882162286685063
Epoch: 34 | Iteration number: [530/4518] 11% | Training loss: 0.6882126094035382
Epoch: 34 | Iteration number: [540/4518] 11% | Training loss: 0.6881701638301213
Epoch: 34 | Iteration number: [550/4518] 12% | Training loss: 0.6881576042825526
Epoch: 34 | Iteration number: [560/4518] 12% | Training loss: 0.6881512249154704
Epoch: 34 | Iteration number: [570/4518] 12% | Training loss: 0.6881157633505369
Epoch: 34 | Iteration number: [580/4518] 12% | Training loss: 0.6881168127059937
Epoch: 34 | Iteration number: [590/4518] 13% | Training loss: 0.6880846424628112
Epoch: 34 | Iteration number: [600/4518] 13% | Training loss: 0.6880603007475535
Epoch: 34 | Iteration number: [610/4518] 13% | Training loss: 0.6880271753326791
Epoch: 34 | Iteration number: [620/4518] 13% | Training loss: 0.6880136790775484
Epoch: 34 | Iteration number: [630/4518] 13% | Training loss: 0.6879842319185772
Epoch: 34 | Iteration number: [640/4518] 14% | Training loss: 0.6879523138515651
Epoch: 34 | Iteration number: [650/4518] 14% | Training loss: 0.687941144154622
Epoch: 34 | Iteration number: [660/4518] 14% | Training loss: 0.6879247299649499
Epoch: 34 | Iteration number: [670/4518] 14% | Training loss: 0.6878992473901208
Epoch: 34 | Iteration number: [680/4518] 15% | Training loss: 0.6878843251396628
Epoch: 34 | Iteration number: [690/4518] 15% | Training loss: 0.6878770889579386
Epoch: 34 | Iteration number: [700/4518] 15% | Training loss: 0.687857608965465
Epoch: 34 | Iteration number: [710/4518] 15% | Training loss: 0.687859690357262
Epoch: 34 | Iteration number: [720/4518] 15% | Training loss: 0.6878325679235988
Epoch: 34 | Iteration number: [730/4518] 16% | Training loss: 0.6878246166934706
Epoch: 34 | Iteration number: [740/4518] 16% | Training loss: 0.687807534836434
Epoch: 34 | Iteration number: [750/4518] 16% | Training loss: 0.6878073521455129
Epoch: 34 | Iteration number: [760/4518] 16% | Training loss: 0.6877789019754058
Epoch: 34 | Iteration number: [770/4518] 17% | Training loss: 0.6877744748220815
Epoch: 34 | Iteration number: [780/4518] 17% | Training loss: 0.687758584970083
Epoch: 34 | Iteration number: [790/4518] 17% | Training loss: 0.6877503308314311
Epoch: 34 | Iteration number: [800/4518] 17% | Training loss: 0.6877490562200547
Epoch: 34 | Iteration number: [810/4518] 17% | Training loss: 0.6877597674911404
Epoch: 34 | Iteration number: [820/4518] 18% | Training loss: 0.6877561914484676
Epoch: 34 | Iteration number: [830/4518] 18% | Training loss: 0.6877377573266087
Epoch: 34 | Iteration number: [840/4518] 18% | Training loss: 0.687725078917685
Epoch: 34 | Iteration number: [850/4518] 18% | Training loss: 0.6877146352038664
Epoch: 34 | Iteration number: [860/4518] 19% | Training loss: 0.6877165169909943
Epoch: 34 | Iteration number: [870/4518] 19% | Training loss: 0.6877240563946209
Epoch: 34 | Iteration number: [880/4518] 19% | Training loss: 0.6877104024995457
Epoch: 34 | Iteration number: [890/4518] 19% | Training loss: 0.6877102310068152
Epoch: 34 | Iteration number: [900/4518] 19% | Training loss: 0.6876946908235549
Epoch: 34 | Iteration number: [910/4518] 20% | Training loss: 0.6876851102808019
Epoch: 34 | Iteration number: [920/4518] 20% | Training loss: 0.6876688844483831
Epoch: 34 | Iteration number: [930/4518] 20% | Training loss: 0.6876652422771659
Epoch: 34 | Iteration number: [940/4518] 20% | Training loss: 0.6876686165307431
Epoch: 34 | Iteration number: [950/4518] 21% | Training loss: 0.6876521175158651
Epoch: 34 | Iteration number: [960/4518] 21% | Training loss: 0.6876415465027094
Epoch: 34 | Iteration number: [970/4518] 21% | Training loss: 0.6876298363675776
Epoch: 34 | Iteration number: [980/4518] 21% | Training loss: 0.6876362379716368
Epoch: 34 | Iteration number: [990/4518] 21% | Training loss: 0.6876059795268858
Epoch: 34 | Iteration number: [1000/4518] 22% | Training loss: 0.6875892399549485
Epoch: 34 | Iteration number: [1010/4518] 22% | Training loss: 0.6875699294675695
Epoch: 34 | Iteration number: [1020/4518] 22% | Training loss: 0.687568667063526
Epoch: 34 | Iteration number: [1030/4518] 22% | Training loss: 0.6875610747962322
Epoch: 34 | Iteration number: [1040/4518] 23% | Training loss: 0.6875652657105372
Epoch: 34 | Iteration number: [1050/4518] 23% | Training loss: 0.6875626285303207
Epoch: 34 | Iteration number: [1060/4518] 23% | Training loss: 0.6875562744882872
Epoch: 34 | Iteration number: [1070/4518] 23% | Training loss: 0.6875465102841921
Epoch: 34 | Iteration number: [1080/4518] 23% | Training loss: 0.6875442838779202
Epoch: 34 | Iteration number: [1090/4518] 24% | Training loss: 0.6875532756704803
Epoch: 34 | Iteration number: [1100/4518] 24% | Training loss: 0.6875438517332078
Epoch: 34 | Iteration number: [1110/4518] 24% | Training loss: 0.6875317446283392
Epoch: 34 | Iteration number: [1120/4518] 24% | Training loss: 0.687510935696108
Epoch: 34 | Iteration number: [1130/4518] 25% | Training loss: 0.6875107547878164
Epoch: 34 | Iteration number: [1140/4518] 25% | Training loss: 0.6875035839645486
Epoch: 34 | Iteration number: [1150/4518] 25% | Training loss: 0.6874994867262633
Epoch: 34 | Iteration number: [1160/4518] 25% | Training loss: 0.6874806607591695
Epoch: 34 | Iteration number: [1170/4518] 25% | Training loss: 0.687471597826379
Epoch: 34 | Iteration number: [1180/4518] 26% | Training loss: 0.6874652874166682
Epoch: 34 | Iteration number: [1190/4518] 26% | Training loss: 0.6874614391507221
Epoch: 34 | Iteration number: [1200/4518] 26% | Training loss: 0.6874532729387284
Epoch: 34 | Iteration number: [1210/4518] 26% | Training loss: 0.6874333941246853
Epoch: 34 | Iteration number: [1220/4518] 27% | Training loss: 0.6874212676872973
Epoch: 34 | Iteration number: [1230/4518] 27% | Training loss: 0.6874132527568476
Epoch: 34 | Iteration number: [1240/4518] 27% | Training loss: 0.6874133091780448
Epoch: 34 | Iteration number: [1250/4518] 27% | Training loss: 0.6874178298950195
Epoch: 34 | Iteration number: [1260/4518] 27% | Training loss: 0.6874066406299197
Epoch: 34 | Iteration number: [1270/4518] 28% | Training loss: 0.6874037306139789
Epoch: 34 | Iteration number: [1280/4518] 28% | Training loss: 0.687402876606211
Epoch: 34 | Iteration number: [1290/4518] 28% | Training loss: 0.6873891040798306
Epoch: 34 | Iteration number: [1300/4518] 28% | Training loss: 0.6873875573965219
Epoch: 34 | Iteration number: [1310/4518] 28% | Training loss: 0.6873816004236236
Epoch: 34 | Iteration number: [1320/4518] 29% | Training loss: 0.6873745126254631
Epoch: 34 | Iteration number: [1330/4518] 29% | Training loss: 0.6873634616235145
Epoch: 34 | Iteration number: [1340/4518] 29% | Training loss: 0.6873559289014162
Epoch: 34 | Iteration number: [1350/4518] 29% | Training loss: 0.6873456635740068
Epoch: 34 | Iteration number: [1360/4518] 30% | Training loss: 0.6873471360434504
Epoch: 34 | Iteration number: [1370/4518] 30% | Training loss: 0.6873432674547182
Epoch: 34 | Iteration number: [1380/4518] 30% | Training loss: 0.6873359287562577
Epoch: 34 | Iteration number: [1390/4518] 30% | Training loss: 0.6873258644299541
Epoch: 34 | Iteration number: [1400/4518] 30% | Training loss: 0.6873118977035795
Epoch: 34 | Iteration number: [1410/4518] 31% | Training loss: 0.6873117688699817
Epoch: 34 | Iteration number: [1420/4518] 31% | Training loss: 0.6873059571209088
Epoch: 34 | Iteration number: [1430/4518] 31% | Training loss: 0.6873000205813588
Epoch: 34 | Iteration number: [1440/4518] 31% | Training loss: 0.6872964180592034
Epoch: 34 | Iteration number: [1450/4518] 32% | Training loss: 0.687292038654459
Epoch: 34 | Iteration number: [1460/4518] 32% | Training loss: 0.6872918355138334
Epoch: 34 | Iteration number: [1470/4518] 32% | Training loss: 0.6872775375437574
Epoch: 34 | Iteration number: [1480/4518] 32% | Training loss: 0.6872678328607533
Epoch: 34 | Iteration number: [1490/4518] 32% | Training loss: 0.6872652413461032
Epoch: 34 | Iteration number: [1500/4518] 33% | Training loss: 0.6872642774979274
Epoch: 34 | Iteration number: [1510/4518] 33% | Training loss: 0.687263233377444
Epoch: 34 | Iteration number: [1520/4518] 33% | Training loss: 0.6872617768613916
Epoch: 34 | Iteration number: [1530/4518] 33% | Training loss: 0.6872577727620118
Epoch: 34 | Iteration number: [1540/4518] 34% | Training loss: 0.6872531701992084
Epoch: 34 | Iteration number: [1550/4518] 34% | Training loss: 0.6872480329390495
Epoch: 34 | Iteration number: [1560/4518] 34% | Training loss: 0.6872502125608615
Epoch: 34 | Iteration number: [1570/4518] 34% | Training loss: 0.6872546014892068
Epoch: 34 | Iteration number: [1580/4518] 34% | Training loss: 0.6872522447305389
Epoch: 34 | Iteration number: [1590/4518] 35% | Training loss: 0.6872419283450024
Epoch: 34 | Iteration number: [1600/4518] 35% | Training loss: 0.6872418459132313
Epoch: 34 | Iteration number: [1610/4518] 35% | Training loss: 0.6872397754133118
Epoch: 34 | Iteration number: [1620/4518] 35% | Training loss: 0.6872404871531475
Epoch: 34 | Iteration number: [1630/4518] 36% | Training loss: 0.6872297530525301
Epoch: 34 | Iteration number: [1640/4518] 36% | Training loss: 0.6872280387616739
Epoch: 34 | Iteration number: [1650/4518] 36% | Training loss: 0.6872278279969186
Epoch: 34 | Iteration number: [1660/4518] 36% | Training loss: 0.6872147400695158
Epoch: 34 | Iteration number: [1670/4518] 36% | Training loss: 0.6872147643994428
Epoch: 34 | Iteration number: [1680/4518] 37% | Training loss: 0.6872125089523338
Epoch: 34 | Iteration number: [1690/4518] 37% | Training loss: 0.6872031214674549
Epoch: 34 | Iteration number: [1700/4518] 37% | Training loss: 0.6871998549559537
Epoch: 34 | Iteration number: [1710/4518] 37% | Training loss: 0.6872014095211587
Epoch: 34 | Iteration number: [1720/4518] 38% | Training loss: 0.6872006516817004
Epoch: 34 | Iteration number: [1730/4518] 38% | Training loss: 0.6871988855000866
Epoch: 34 | Iteration number: [1740/4518] 38% | Training loss: 0.6871978669673547
Epoch: 34 | Iteration number: [1750/4518] 38% | Training loss: 0.6871959199224199
Epoch: 34 | Iteration number: [1760/4518] 38% | Training loss: 0.6871831675822084
Epoch: 34 | Iteration number: [1770/4518] 39% | Training loss: 0.6871832046468379
Epoch: 34 | Iteration number: [1780/4518] 39% | Training loss: 0.6871812653005793
Epoch: 34 | Iteration number: [1790/4518] 39% | Training loss: 0.6871822876970195
Epoch: 34 | Iteration number: [1800/4518] 39% | Training loss: 0.687181482050154
Epoch: 34 | Iteration number: [1810/4518] 40% | Training loss: 0.6871846390363261
Epoch: 34 | Iteration number: [1820/4518] 40% | Training loss: 0.6871890948368953
Epoch: 34 | Iteration number: [1830/4518] 40% | Training loss: 0.6871824409466624
Epoch: 34 | Iteration number: [1840/4518] 40% | Training loss: 0.6871839192574439
Epoch: 34 | Iteration number: [1850/4518] 40% | Training loss: 0.6871819980724437
Epoch: 34 | Iteration number: [1860/4518] 41% | Training loss: 0.687177594759131
Epoch: 34 | Iteration number: [1870/4518] 41% | Training loss: 0.6871757878657968
Epoch: 34 | Iteration number: [1880/4518] 41% | Training loss: 0.6871707673085496
Epoch: 34 | Iteration number: [1890/4518] 41% | Training loss: 0.6871689346732286
Epoch: 34 | Iteration number: [1900/4518] 42% | Training loss: 0.6871727868130333
Epoch: 34 | Iteration number: [1910/4518] 42% | Training loss: 0.6871720769954601
Epoch: 34 | Iteration number: [1920/4518] 42% | Training loss: 0.6871683517781396
Epoch: 34 | Iteration number: [1930/4518] 42% | Training loss: 0.6871650065165109
Epoch: 34 | Iteration number: [1940/4518] 42% | Training loss: 0.6871668643250908
Epoch: 34 | Iteration number: [1950/4518] 43% | Training loss: 0.6871667080964797
Epoch: 34 | Iteration number: [1960/4518] 43% | Training loss: 0.6871639985819252
Epoch: 34 | Iteration number: [1970/4518] 43% | Training loss: 0.6871661385908949
Epoch: 34 | Iteration number: [1980/4518] 43% | Training loss: 0.6871741843042951
Epoch: 34 | Iteration number: [1990/4518] 44% | Training loss: 0.6871725719178742
Epoch: 34 | Iteration number: [2000/4518] 44% | Training loss: 0.6871663691699504
Epoch: 34 | Iteration number: [2010/4518] 44% | Training loss: 0.6871591830431525
Epoch: 34 | Iteration number: [2020/4518] 44% | Training loss: 0.6871591953062776
Epoch: 34 | Iteration number: [2030/4518] 44% | Training loss: 0.6871600977892947
Epoch: 34 | Iteration number: [2040/4518] 45% | Training loss: 0.6871550742902007
Epoch: 34 | Iteration number: [2050/4518] 45% | Training loss: 0.6871562786800105
Epoch: 34 | Iteration number: [2060/4518] 45% | Training loss: 0.6871513619295602
Epoch: 34 | Iteration number: [2070/4518] 45% | Training loss: 0.6871509892929003
Epoch: 34 | Iteration number: [2080/4518] 46% | Training loss: 0.6871566650099479
Epoch: 34 | Iteration number: [2090/4518] 46% | Training loss: 0.6871549497665971
Epoch: 34 | Iteration number: [2100/4518] 46% | Training loss: 0.6871563724109104
Epoch: 34 | Iteration number: [2110/4518] 46% | Training loss: 0.6871538620706983
Epoch: 34 | Iteration number: [2120/4518] 46% | Training loss: 0.6871498599086168
Epoch: 34 | Iteration number: [2130/4518] 47% | Training loss: 0.6871442518603634
Epoch: 34 | Iteration number: [2140/4518] 47% | Training loss: 0.6871466332228384
Epoch: 34 | Iteration number: [2150/4518] 47% | Training loss: 0.6871410387338593
Epoch: 34 | Iteration number: [2160/4518] 47% | Training loss: 0.6871438810670817
Epoch: 34 | Iteration number: [2170/4518] 48% | Training loss: 0.6871412678522998
Epoch: 34 | Iteration number: [2180/4518] 48% | Training loss: 0.6871407131262876
Epoch: 34 | Iteration number: [2190/4518] 48% | Training loss: 0.6871385725938022
Epoch: 34 | Iteration number: [2200/4518] 48% | Training loss: 0.6871352571790869
Epoch: 34 | Iteration number: [2210/4518] 48% | Training loss: 0.6871354955623592
Epoch: 34 | Iteration number: [2220/4518] 49% | Training loss: 0.6871394044912613
Epoch: 34 | Iteration number: [2230/4518] 49% | Training loss: 0.6871426716513698
Epoch: 34 | Iteration number: [2240/4518] 49% | Training loss: 0.6871347640507988
Epoch: 34 | Iteration number: [2250/4518] 49% | Training loss: 0.6871314279503292
Epoch: 34 | Iteration number: [2260/4518] 50% | Training loss: 0.6871319864439753
Epoch: 34 | Iteration number: [2270/4518] 50% | Training loss: 0.6871265983529028
Epoch: 34 | Iteration number: [2280/4518] 50% | Training loss: 0.6871337388691149
Epoch: 34 | Iteration number: [2290/4518] 50% | Training loss: 0.6871354621310422
Epoch: 34 | Iteration number: [2300/4518] 50% | Training loss: 0.6871355393140213
Epoch: 34 | Iteration number: [2310/4518] 51% | Training loss: 0.6871374357830394
Epoch: 34 | Iteration number: [2320/4518] 51% | Training loss: 0.6871348707583443
Epoch: 34 | Iteration number: [2330/4518] 51% | Training loss: 0.6871318511696844
Epoch: 34 | Iteration number: [2340/4518] 51% | Training loss: 0.6871331862150094
Epoch: 34 | Iteration number: [2350/4518] 52% | Training loss: 0.68713062534941
Epoch: 34 | Iteration number: [2360/4518] 52% | Training loss: 0.6871263895246942
Epoch: 34 | Iteration number: [2370/4518] 52% | Training loss: 0.6871278989918624
Epoch: 34 | Iteration number: [2380/4518] 52% | Training loss: 0.6871258346974349
Epoch: 34 | Iteration number: [2390/4518] 52% | Training loss: 0.6871193706989288
Epoch: 34 | Iteration number: [2400/4518] 53% | Training loss: 0.6871147848665714
Epoch: 34 | Iteration number: [2410/4518] 53% | Training loss: 0.6871181490757653
Epoch: 34 | Iteration number: [2420/4518] 53% | Training loss: 0.6871201436381694
Epoch: 34 | Iteration number: [2430/4518] 53% | Training loss: 0.6871132372583382
Epoch: 34 | Iteration number: [2440/4518] 54% | Training loss: 0.687106353068938
Epoch: 34 | Iteration number: [2450/4518] 54% | Training loss: 0.6871109661520743
Epoch: 34 | Iteration number: [2460/4518] 54% | Training loss: 0.6871060969626032
Epoch: 34 | Iteration number: [2470/4518] 54% | Training loss: 0.6871113405777858
Epoch: 34 | Iteration number: [2480/4518] 54% | Training loss: 0.6871089050125692
Epoch: 34 | Iteration number: [2490/4518] 55% | Training loss: 0.6871051598504844
Epoch: 34 | Iteration number: [2500/4518] 55% | Training loss: 0.6871024516105652
Epoch: 34 | Iteration number: [2510/4518] 55% | Training loss: 0.687104282222421
Epoch: 34 | Iteration number: [2520/4518] 55% | Training loss: 0.6871058728723299
Epoch: 34 | Iteration number: [2530/4518] 55% | Training loss: 0.6871050458651757
Epoch: 34 | Iteration number: [2540/4518] 56% | Training loss: 0.6871078661576969
Epoch: 34 | Iteration number: [2550/4518] 56% | Training loss: 0.6871057443759021
Epoch: 34 | Iteration number: [2560/4518] 56% | Training loss: 0.6870924650225788
Epoch: 34 | Iteration number: [2570/4518] 56% | Training loss: 0.6870912154129043
Epoch: 34 | Iteration number: [2580/4518] 57% | Training loss: 0.6870934829231381
Epoch: 34 | Iteration number: [2590/4518] 57% | Training loss: 0.6870935345478499
Epoch: 34 | Iteration number: [2600/4518] 57% | Training loss: 0.6870920075361545
Epoch: 34 | Iteration number: [2610/4518] 57% | Training loss: 0.6870886575444904
Epoch: 34 | Iteration number: [2620/4518] 57% | Training loss: 0.687080572443154
Epoch: 34 | Iteration number: [2630/4518] 58% | Training loss: 0.6870764192746166
Epoch: 34 | Iteration number: [2640/4518] 58% | Training loss: 0.6870739144131993
Epoch: 34 | Iteration number: [2650/4518] 58% | Training loss: 0.6870782872415938
Epoch: 34 | Iteration number: [2660/4518] 58% | Training loss: 0.6870798103343275
Epoch: 34 | Iteration number: [2670/4518] 59% | Training loss: 0.6870809846156546
Epoch: 34 | Iteration number: [2680/4518] 59% | Training loss: 0.6870809758109833
Epoch: 34 | Iteration number: [2690/4518] 59% | Training loss: 0.6870812715207777
Epoch: 34 | Iteration number: [2700/4518] 59% | Training loss: 0.6870824919806586
Epoch: 34 | Iteration number: [2710/4518] 59% | Training loss: 0.6870804921067509
Epoch: 34 | Iteration number: [2720/4518] 60% | Training loss: 0.6870789057191681
Epoch: 34 | Iteration number: [2730/4518] 60% | Training loss: 0.6870815634290814
Epoch: 34 | Iteration number: [2740/4518] 60% | Training loss: 0.6870814081526151
Epoch: 34 | Iteration number: [2750/4518] 60% | Training loss: 0.6870788338834589
Epoch: 34 | Iteration number: [2760/4518] 61% | Training loss: 0.6870762128328931
Epoch: 34 | Iteration number: [2770/4518] 61% | Training loss: 0.6870716633779478
Epoch: 34 | Iteration number: [2780/4518] 61% | Training loss: 0.6870741757343142
Epoch: 34 | Iteration number: [2790/4518] 61% | Training loss: 0.6870739215804684
Epoch: 34 | Iteration number: [2800/4518] 61% | Training loss: 0.6870704221299716
Epoch: 34 | Iteration number: [2810/4518] 62% | Training loss: 0.6870700255407557
Epoch: 34 | Iteration number: [2820/4518] 62% | Training loss: 0.6870732502945771
Epoch: 34 | Iteration number: [2830/4518] 62% | Training loss: 0.6870698242431816
Epoch: 34 | Iteration number: [2840/4518] 62% | Training loss: 0.6870741291365153
Epoch: 34 | Iteration number: [2850/4518] 63% | Training loss: 0.6870726556317848
Epoch: 34 | Iteration number: [2860/4518] 63% | Training loss: 0.6870729901782282
Epoch: 34 | Iteration number: [2870/4518] 63% | Training loss: 0.6870709998474719
Epoch: 34 | Iteration number: [2880/4518] 63% | Training loss: 0.6870724629403816
Epoch: 34 | Iteration number: [2890/4518] 63% | Training loss: 0.6870731964655813
Epoch: 34 | Iteration number: [2900/4518] 64% | Training loss: 0.6870674241616808
Epoch: 34 | Iteration number: [2910/4518] 64% | Training loss: 0.6870648197701706
Epoch: 34 | Iteration number: [2920/4518] 64% | Training loss: 0.6870600195576066
Epoch: 34 | Iteration number: [2930/4518] 64% | Training loss: 0.6870604561864313
Epoch: 34 | Iteration number: [2940/4518] 65% | Training loss: 0.6870587618983521
Epoch: 34 | Iteration number: [2950/4518] 65% | Training loss: 0.6870615359484139
Epoch: 34 | Iteration number: [2960/4518] 65% | Training loss: 0.6870535899859828
Epoch: 34 | Iteration number: [2970/4518] 65% | Training loss: 0.6870562750683088
Epoch: 34 | Iteration number: [2980/4518] 65% | Training loss: 0.6870556140506028
Epoch: 34 | Iteration number: [2990/4518] 66% | Training loss: 0.6870525958147335
Epoch: 34 | Iteration number: [3000/4518] 66% | Training loss: 0.6870513329505921
Epoch: 34 | Iteration number: [3010/4518] 66% | Training loss: 0.6870488600279405
Epoch: 34 | Iteration number: [3020/4518] 66% | Training loss: 0.6870481411747585
Epoch: 34 | Iteration number: [3030/4518] 67% | Training loss: 0.6870409983612916
Epoch: 34 | Iteration number: [3040/4518] 67% | Training loss: 0.687040780896419
Epoch: 34 | Iteration number: [3050/4518] 67% | Training loss: 0.6870413050690636
Epoch: 34 | Iteration number: [3060/4518] 67% | Training loss: 0.6870465904279472
Epoch: 34 | Iteration number: [3070/4518] 67% | Training loss: 0.6870475068736931
Epoch: 34 | Iteration number: [3080/4518] 68% | Training loss: 0.6870486182632385
Epoch: 34 | Iteration number: [3090/4518] 68% | Training loss: 0.6870473897187069
Epoch: 34 | Iteration number: [3100/4518] 68% | Training loss: 0.6870490720771975
Epoch: 34 | Iteration number: [3110/4518] 68% | Training loss: 0.6870476485831944
Epoch: 34 | Iteration number: [3120/4518] 69% | Training loss: 0.6870451959279867
Epoch: 34 | Iteration number: [3130/4518] 69% | Training loss: 0.6870489525909241
Epoch: 34 | Iteration number: [3140/4518] 69% | Training loss: 0.6870531738563708
Epoch: 34 | Iteration number: [3150/4518] 69% | Training loss: 0.6870494611868783
Epoch: 34 | Iteration number: [3160/4518] 69% | Training loss: 0.6870473106639294
Epoch: 34 | Iteration number: [3170/4518] 70% | Training loss: 0.6870467221511275
Epoch: 34 | Iteration number: [3180/4518] 70% | Training loss: 0.6870439267383431
Epoch: 34 | Iteration number: [3190/4518] 70% | Training loss: 0.6870466446614938
Epoch: 34 | Iteration number: [3200/4518] 70% | Training loss: 0.6870476850494742
Epoch: 34 | Iteration number: [3210/4518] 71% | Training loss: 0.6870492076762369
Epoch: 34 | Iteration number: [3220/4518] 71% | Training loss: 0.6870475285912152
Epoch: 34 | Iteration number: [3230/4518] 71% | Training loss: 0.6870499325241467
Epoch: 34 | Iteration number: [3240/4518] 71% | Training loss: 0.6870515779948528
Epoch: 34 | Iteration number: [3250/4518] 71% | Training loss: 0.6870506902107826
Epoch: 34 | Iteration number: [3260/4518] 72% | Training loss: 0.6870512451679429
Epoch: 34 | Iteration number: [3270/4518] 72% | Training loss: 0.6870506900895261
Epoch: 34 | Iteration number: [3280/4518] 72% | Training loss: 0.6870497456774479
Epoch: 34 | Iteration number: [3290/4518] 72% | Training loss: 0.6870520299510028
Epoch: 34 | Iteration number: [3300/4518] 73% | Training loss: 0.6870547752669364
Epoch: 34 | Iteration number: [3310/4518] 73% | Training loss: 0.6870584865891322
Epoch: 34 | Iteration number: [3320/4518] 73% | Training loss: 0.6870593485882484
Epoch: 34 | Iteration number: [3330/4518] 73% | Training loss: 0.6870584400029511
Epoch: 34 | Iteration number: [3340/4518] 73% | Training loss: 0.6870602632354119
Epoch: 34 | Iteration number: [3350/4518] 74% | Training loss: 0.687060681901761
Epoch: 34 | Iteration number: [3360/4518] 74% | Training loss: 0.6870611314794847
Epoch: 34 | Iteration number: [3370/4518] 74% | Training loss: 0.6870593173744417
Epoch: 34 | Iteration number: [3380/4518] 74% | Training loss: 0.6870609958319974
Epoch: 34 | Iteration number: [3390/4518] 75% | Training loss: 0.6870612923902044
Epoch: 34 | Iteration number: [3400/4518] 75% | Training loss: 0.6870571093173587
Epoch: 34 | Iteration number: [3410/4518] 75% | Training loss: 0.6870563492397409
Epoch: 34 | Iteration number: [3420/4518] 75% | Training loss: 0.6870508220286398
Epoch: 34 | Iteration number: [3430/4518] 75% | Training loss: 0.6870508482087805
Epoch: 34 | Iteration number: [3440/4518] 76% | Training loss: 0.6870475491812063
Epoch: 34 | Iteration number: [3450/4518] 76% | Training loss: 0.6870474805520929
Epoch: 34 | Iteration number: [3460/4518] 76% | Training loss: 0.6870452256388747
Epoch: 34 | Iteration number: [3470/4518] 76% | Training loss: 0.687042559533023
Epoch: 34 | Iteration number: [3480/4518] 77% | Training loss: 0.6870429180819413
Epoch: 34 | Iteration number: [3490/4518] 77% | Training loss: 0.6870445534288029
Epoch: 34 | Iteration number: [3500/4518] 77% | Training loss: 0.6870440880911691
Epoch: 34 | Iteration number: [3510/4518] 77% | Training loss: 0.687048737411825
Epoch: 34 | Iteration number: [3520/4518] 77% | Training loss: 0.6870495184070685
Epoch: 34 | Iteration number: [3530/4518] 78% | Training loss: 0.6870488340388614
Epoch: 34 | Iteration number: [3540/4518] 78% | Training loss: 0.6870491511235803
Epoch: 34 | Iteration number: [3550/4518] 78% | Training loss: 0.6870495082291079
Epoch: 34 | Iteration number: [3560/4518] 78% | Training loss: 0.6870496496725618
Epoch: 34 | Iteration number: [3570/4518] 79% | Training loss: 0.6870490016055708
Epoch: 34 | Iteration number: [3580/4518] 79% | Training loss: 0.6870485886681679
Epoch: 34 | Iteration number: [3590/4518] 79% | Training loss: 0.687049223254318
Epoch: 34 | Iteration number: [3600/4518] 79% | Training loss: 0.6870471615758207
Epoch: 34 | Iteration number: [3610/4518] 79% | Training loss: 0.6870476723377724
Epoch: 34 | Iteration number: [3620/4518] 80% | Training loss: 0.6870457709164909
Epoch: 34 | Iteration number: [3630/4518] 80% | Training loss: 0.687044955909088
Epoch: 34 | Iteration number: [3640/4518] 80% | Training loss: 0.6870442789498267
Epoch: 34 | Iteration number: [3650/4518] 80% | Training loss: 0.6870445088980949
Epoch: 34 | Iteration number: [3660/4518] 81% | Training loss: 0.6870388211285482
Epoch: 34 | Iteration number: [3670/4518] 81% | Training loss: 0.687036896044292
Epoch: 34 | Iteration number: [3680/4518] 81% | Training loss: 0.6870350837221612
Epoch: 34 | Iteration number: [3690/4518] 81% | Training loss: 0.6870325041172627
Epoch: 34 | Iteration number: [3700/4518] 81% | Training loss: 0.6870315997020618
Epoch: 34 | Iteration number: [3710/4518] 82% | Training loss: 0.6870261889262341
Epoch: 34 | Iteration number: [3720/4518] 82% | Training loss: 0.6870220315712754
Epoch: 34 | Iteration number: [3730/4518] 82% | Training loss: 0.687020138968731
Epoch: 34 | Iteration number: [3740/4518] 82% | Training loss: 0.6870203123532514
Epoch: 34 | Iteration number: [3750/4518] 83% | Training loss: 0.6870231135368348
Epoch: 34 | Iteration number: [3760/4518] 83% | Training loss: 0.687016708467235
Epoch: 34 | Iteration number: [3770/4518] 83% | Training loss: 0.6870168426624976
Epoch: 34 | Iteration number: [3780/4518] 83% | Training loss: 0.6870160170175411
Epoch: 34 | Iteration number: [3790/4518] 83% | Training loss: 0.6870128295509671
Epoch: 34 | Iteration number: [3800/4518] 84% | Training loss: 0.687014474492324
Epoch: 34 | Iteration number: [3810/4518] 84% | Training loss: 0.6870107492436887
Epoch: 34 | Iteration number: [3820/4518] 84% | Training loss: 0.6870125575215404
Epoch: 34 | Iteration number: [3830/4518] 84% | Training loss: 0.6870118336173324
Epoch: 34 | Iteration number: [3840/4518] 84% | Training loss: 0.6870128510054201
Epoch: 34 | Iteration number: [3850/4518] 85% | Training loss: 0.6870148894693945
Epoch: 34 | Iteration number: [3860/4518] 85% | Training loss: 0.6870137201998517
Epoch: 34 | Iteration number: [3870/4518] 85% | Training loss: 0.6870134832323059
Epoch: 34 | Iteration number: [3880/4518] 85% | Training loss: 0.6870127106450268
Epoch: 34 | Iteration number: [3890/4518] 86% | Training loss: 0.68700986506087
Epoch: 34 | Iteration number: [3900/4518] 86% | Training loss: 0.6870092506286426
Epoch: 34 | Iteration number: [3910/4518] 86% | Training loss: 0.6870086313361097
Epoch: 34 | Iteration number: [3920/4518] 86% | Training loss: 0.6870096872351608
Epoch: 34 | Iteration number: [3930/4518] 86% | Training loss: 0.687008145246797
Epoch: 34 | Iteration number: [3940/4518] 87% | Training loss: 0.687008006772414
Epoch: 34 | Iteration number: [3950/4518] 87% | Training loss: 0.6870082764082317
Epoch: 34 | Iteration number: [3960/4518] 87% | Training loss: 0.6870056138646723
Epoch: 34 | Iteration number: [3970/4518] 87% | Training loss: 0.6870025984736474
Epoch: 34 | Iteration number: [3980/4518] 88% | Training loss: 0.6869979181930648
Epoch: 34 | Iteration number: [3990/4518] 88% | Training loss: 0.6869982968147536
Epoch: 34 | Iteration number: [4000/4518] 88% | Training loss: 0.68700036264956
Epoch: 34 | Iteration number: [4010/4518] 88% | Training loss: 0.6870018054125018
Epoch: 34 | Iteration number: [4020/4518] 88% | Training loss: 0.6870041489304595
Epoch: 34 | Iteration number: [4030/4518] 89% | Training loss: 0.687003140828154
Epoch: 34 | Iteration number: [4040/4518] 89% | Training loss: 0.6870025540342425
Epoch: 34 | Iteration number: [4050/4518] 89% | Training loss: 0.6870000000500385
Epoch: 34 | Iteration number: [4060/4518] 89% | Training loss: 0.6870017398901174
Epoch: 34 | Iteration number: [4070/4518] 90% | Training loss: 0.6870037452008859
Epoch: 34 | Iteration number: [4080/4518] 90% | Training loss: 0.6870035636950942
Epoch: 34 | Iteration number: [4090/4518] 90% | Training loss: 0.6870027565285746
Epoch: 34 | Iteration number: [4100/4518] 90% | Training loss: 0.6870025146298292
Epoch: 34 | Iteration number: [4110/4518] 90% | Training loss: 0.6870023228971337
Epoch: 34 | Iteration number: [4120/4518] 91% | Training loss: 0.6870035727770584
Epoch: 34 | Iteration number: [4130/4518] 91% | Training loss: 0.6870048794994631
Epoch: 34 | Iteration number: [4140/4518] 91% | Training loss: 0.6870014061242486
Epoch: 34 | Iteration number: [4150/4518] 91% | Training loss: 0.6869992267223726
Epoch: 34 | Iteration number: [4160/4518] 92% | Training loss: 0.6870012819766999
Epoch: 34 | Iteration number: [4170/4518] 92% | Training loss: 0.6869997208209918
Epoch: 34 | Iteration number: [4180/4518] 92% | Training loss: 0.6870003373999345
Epoch: 34 | Iteration number: [4190/4518] 92% | Training loss: 0.6869986410641727
Epoch: 34 | Iteration number: [4200/4518] 92% | Training loss: 0.6869977045343035
Epoch: 34 | Iteration number: [4210/4518] 93% | Training loss: 0.6870006427062663
Epoch: 34 | Iteration number: [4220/4518] 93% | Training loss: 0.6869994274106636
Epoch: 34 | Iteration number: [4230/4518] 93% | Training loss: 0.6870010947927515
Epoch: 34 | Iteration number: [4240/4518] 93% | Training loss: 0.6869982721108311
Epoch: 34 | Iteration number: [4250/4518] 94% | Training loss: 0.686996935858446
Epoch: 34 | Iteration number: [4260/4518] 94% | Training loss: 0.6869956260136035
Epoch: 34 | Iteration number: [4270/4518] 94% | Training loss: 0.686995650091551
Epoch: 34 | Iteration number: [4280/4518] 94% | Training loss: 0.6869960945900355
Epoch: 34 | Iteration number: [4290/4518] 94% | Training loss: 0.6869963056001908
Epoch: 34 | Iteration number: [4300/4518] 95% | Training loss: 0.6869993992600331
Epoch: 34 | Iteration number: [4310/4518] 95% | Training loss: 0.6869959233116938
Epoch: 34 | Iteration number: [4320/4518] 95% | Training loss: 0.686995356971467
Epoch: 34 | Iteration number: [4330/4518] 95% | Training loss: 0.68699511790661
Epoch: 34 | Iteration number: [4340/4518] 96% | Training loss: 0.6869940763656994
Epoch: 34 | Iteration number: [4350/4518] 96% | Training loss: 0.6869911206042629
Epoch: 34 | Iteration number: [4360/4518] 96% | Training loss: 0.6869889825172381
Epoch: 34 | Iteration number: [4370/4518] 96% | Training loss: 0.6869886923436442
Epoch: 34 | Iteration number: [4380/4518] 96% | Training loss: 0.6869883478912588
Epoch: 34 | Iteration number: [4390/4518] 97% | Training loss: 0.6869892529718968
Epoch: 34 | Iteration number: [4400/4518] 97% | Training loss: 0.6869884999096394
Epoch: 34 | Iteration number: [4410/4518] 97% | Training loss: 0.6869869977979163
Epoch: 34 | Iteration number: [4420/4518] 97% | Training loss: 0.6869842950979509
Epoch: 34 | Iteration number: [4430/4518] 98% | Training loss: 0.6869829648100765
Epoch: 34 | Iteration number: [4440/4518] 98% | Training loss: 0.6869831555195757
Epoch: 34 | Iteration number: [4450/4518] 98% | Training loss: 0.6869814976011769
Epoch: 34 | Iteration number: [4460/4518] 98% | Training loss: 0.686981974495366
Epoch: 34 | Iteration number: [4470/4518] 98% | Training loss: 0.6869818315409973
Epoch: 34 | Iteration number: [4480/4518] 99% | Training loss: 0.6869838331293847
Epoch: 34 | Iteration number: [4490/4518] 99% | Training loss: 0.6869843546823828
Epoch: 34 | Iteration number: [4500/4518] 99% | Training loss: 0.6869875245889028
Epoch: 34 | Iteration number: [4510/4518] 99% | Training loss: 0.6869877574845586

 End of epoch: 34 | Train Loss: 0.6868355767211854 | Training Time: 633 

 End of epoch: 34 | Eval Loss: 0.6898372234130392 | Evaluating Time: 17 
Epoch: 35 | Iteration number: [10/4518] 0% | Training loss: 0.7554004967212677
Epoch: 35 | Iteration number: [20/4518] 0% | Training loss: 0.7207245856523514
Epoch: 35 | Iteration number: [30/4518] 0% | Training loss: 0.7090339541435242
Epoch: 35 | Iteration number: [40/4518] 0% | Training loss: 0.7034380719065666
Epoch: 35 | Iteration number: [50/4518] 1% | Training loss: 0.7002703678607941
Epoch: 35 | Iteration number: [60/4518] 1% | Training loss: 0.6979870935281117
Epoch: 35 | Iteration number: [70/4518] 1% | Training loss: 0.6963481588023049
Epoch: 35 | Iteration number: [80/4518] 1% | Training loss: 0.6950348861515522
Epoch: 35 | Iteration number: [90/4518] 1% | Training loss: 0.6942676742871602
Epoch: 35 | Iteration number: [100/4518] 2% | Training loss: 0.6934566682577133
Epoch: 35 | Iteration number: [110/4518] 2% | Training loss: 0.6929391134868969
Epoch: 35 | Iteration number: [120/4518] 2% | Training loss: 0.6922712703545888
Epoch: 35 | Iteration number: [130/4518] 2% | Training loss: 0.6918929320115309
Epoch: 35 | Iteration number: [140/4518] 3% | Training loss: 0.6915294374738421
Epoch: 35 | Iteration number: [150/4518] 3% | Training loss: 0.691224996248881
Epoch: 35 | Iteration number: [160/4518] 3% | Training loss: 0.6908735930919647
Epoch: 35 | Iteration number: [170/4518] 3% | Training loss: 0.6906427909346188
Epoch: 35 | Iteration number: [180/4518] 3% | Training loss: 0.6904392742448383
Epoch: 35 | Iteration number: [190/4518] 4% | Training loss: 0.6901597534355365
Epoch: 35 | Iteration number: [200/4518] 4% | Training loss: 0.6900220635533333
Epoch: 35 | Iteration number: [210/4518] 4% | Training loss: 0.6898256338777996
Epoch: 35 | Iteration number: [220/4518] 4% | Training loss: 0.6897405228831551
Epoch: 35 | Iteration number: [230/4518] 5% | Training loss: 0.6895894555941872
Epoch: 35 | Iteration number: [240/4518] 5% | Training loss: 0.6894907392561436
Epoch: 35 | Iteration number: [250/4518] 5% | Training loss: 0.6893782801628113
Epoch: 35 | Iteration number: [260/4518] 5% | Training loss: 0.6893005873148258
Epoch: 35 | Iteration number: [270/4518] 5% | Training loss: 0.6892478466033936
Epoch: 35 | Iteration number: [280/4518] 6% | Training loss: 0.6892070546746254
Epoch: 35 | Iteration number: [290/4518] 6% | Training loss: 0.6891200990512454
Epoch: 35 | Iteration number: [300/4518] 6% | Training loss: 0.6890623839696248
Epoch: 35 | Iteration number: [310/4518] 6% | Training loss: 0.6890345981044154
Epoch: 35 | Iteration number: [320/4518] 7% | Training loss: 0.688934925198555
Epoch: 35 | Iteration number: [330/4518] 7% | Training loss: 0.6888752243735573
Epoch: 35 | Iteration number: [340/4518] 7% | Training loss: 0.6887788167771172
Epoch: 35 | Iteration number: [350/4518] 7% | Training loss: 0.6886803734302521
Epoch: 35 | Iteration number: [360/4518] 7% | Training loss: 0.6886373081141048
Epoch: 35 | Iteration number: [370/4518] 8% | Training loss: 0.688563087663135
Epoch: 35 | Iteration number: [380/4518] 8% | Training loss: 0.6885171036971243
Epoch: 35 | Iteration number: [390/4518] 8% | Training loss: 0.6884696205457052
Epoch: 35 | Iteration number: [400/4518] 8% | Training loss: 0.688439146578312
Epoch: 35 | Iteration number: [410/4518] 9% | Training loss: 0.688409889325863
Epoch: 35 | Iteration number: [420/4518] 9% | Training loss: 0.688378968834877
Epoch: 35 | Iteration number: [430/4518] 9% | Training loss: 0.6883299478264742
Epoch: 35 | Iteration number: [440/4518] 9% | Training loss: 0.6882988417690451
Epoch: 35 | Iteration number: [450/4518] 9% | Training loss: 0.6882827831639184
Epoch: 35 | Iteration number: [460/4518] 10% | Training loss: 0.6882423187079637
Epoch: 35 | Iteration number: [470/4518] 10% | Training loss: 0.6882125144309186
Epoch: 35 | Iteration number: [480/4518] 10% | Training loss: 0.6881744073083004
Epoch: 35 | Iteration number: [490/4518] 10% | Training loss: 0.6881556813814202
Epoch: 35 | Iteration number: [500/4518] 11% | Training loss: 0.6881292160749436
Epoch: 35 | Iteration number: [510/4518] 11% | Training loss: 0.6880814077807408
Epoch: 35 | Iteration number: [520/4518] 11% | Training loss: 0.6880377625043576
Epoch: 35 | Iteration number: [530/4518] 11% | Training loss: 0.6880057002013584
Epoch: 35 | Iteration number: [540/4518] 11% | Training loss: 0.6879962282048331
Epoch: 35 | Iteration number: [550/4518] 12% | Training loss: 0.6879593088410118
Epoch: 35 | Iteration number: [560/4518] 12% | Training loss: 0.6879118646894182
Epoch: 35 | Iteration number: [570/4518] 12% | Training loss: 0.687891400592369
Epoch: 35 | Iteration number: [580/4518] 12% | Training loss: 0.6878698254453725
Epoch: 35 | Iteration number: [590/4518] 13% | Training loss: 0.6878421930943506
Epoch: 35 | Iteration number: [600/4518] 13% | Training loss: 0.6878348535299301
Epoch: 35 | Iteration number: [610/4518] 13% | Training loss: 0.68783432186627
Epoch: 35 | Iteration number: [620/4518] 13% | Training loss: 0.6878159813342556
Epoch: 35 | Iteration number: [630/4518] 13% | Training loss: 0.6878086032375457
Epoch: 35 | Iteration number: [640/4518] 14% | Training loss: 0.6878021853975952
Epoch: 35 | Iteration number: [650/4518] 14% | Training loss: 0.6877917261307056
Epoch: 35 | Iteration number: [660/4518] 14% | Training loss: 0.6877581614436525
Epoch: 35 | Iteration number: [670/4518] 14% | Training loss: 0.6877257140714731
Epoch: 35 | Iteration number: [680/4518] 15% | Training loss: 0.6877101001494071
Epoch: 35 | Iteration number: [690/4518] 15% | Training loss: 0.6876863345719766
Epoch: 35 | Iteration number: [700/4518] 15% | Training loss: 0.6876759535925729
Epoch: 35 | Iteration number: [710/4518] 15% | Training loss: 0.6876665093529393
Epoch: 35 | Iteration number: [720/4518] 15% | Training loss: 0.6876476121445497
Epoch: 35 | Iteration number: [730/4518] 16% | Training loss: 0.6876433326773448
Epoch: 35 | Iteration number: [740/4518] 16% | Training loss: 0.6876357638352626
Epoch: 35 | Iteration number: [750/4518] 16% | Training loss: 0.6876177900632222
Epoch: 35 | Iteration number: [760/4518] 16% | Training loss: 0.6876049953855966
Epoch: 35 | Iteration number: [770/4518] 17% | Training loss: 0.6875868546498286
Epoch: 35 | Iteration number: [780/4518] 17% | Training loss: 0.6875613651214502
Epoch: 35 | Iteration number: [790/4518] 17% | Training loss: 0.6875544666489468
Epoch: 35 | Iteration number: [800/4518] 17% | Training loss: 0.6875228021293879
Epoch: 35 | Iteration number: [810/4518] 17% | Training loss: 0.6875051191559545
Epoch: 35 | Iteration number: [820/4518] 18% | Training loss: 0.6874933989309683
Epoch: 35 | Iteration number: [830/4518] 18% | Training loss: 0.6874855381178568
Epoch: 35 | Iteration number: [840/4518] 18% | Training loss: 0.6874842716824441
Epoch: 35 | Iteration number: [850/4518] 18% | Training loss: 0.6874787321511437
Epoch: 35 | Iteration number: [860/4518] 19% | Training loss: 0.6874776423670524
Epoch: 35 | Iteration number: [870/4518] 19% | Training loss: 0.6874655492689418
Epoch: 35 | Iteration number: [880/4518] 19% | Training loss: 0.6874688283286311
Epoch: 35 | Iteration number: [890/4518] 19% | Training loss: 0.6874675564551621
Epoch: 35 | Iteration number: [900/4518] 19% | Training loss: 0.6874700067440669
Epoch: 35 | Iteration number: [910/4518] 20% | Training loss: 0.6874644664617685
Epoch: 35 | Iteration number: [920/4518] 20% | Training loss: 0.6874755370876063
Epoch: 35 | Iteration number: [930/4518] 20% | Training loss: 0.6874760519432765
Epoch: 35 | Iteration number: [940/4518] 20% | Training loss: 0.6874771711674142
Epoch: 35 | Iteration number: [950/4518] 21% | Training loss: 0.6874685472563693
Epoch: 35 | Iteration number: [960/4518] 21% | Training loss: 0.6874547728026906
Epoch: 35 | Iteration number: [970/4518] 21% | Training loss: 0.6874449557250308
Epoch: 35 | Iteration number: [980/4518] 21% | Training loss: 0.6874438307723221
Epoch: 35 | Iteration number: [990/4518] 21% | Training loss: 0.6874453406743329
Epoch: 35 | Iteration number: [1000/4518] 22% | Training loss: 0.6874432860612869
Epoch: 35 | Iteration number: [1010/4518] 22% | Training loss: 0.687413894835085
Epoch: 35 | Iteration number: [1020/4518] 22% | Training loss: 0.6874199565719156
Epoch: 35 | Iteration number: [1030/4518] 22% | Training loss: 0.6874162591198115
Epoch: 35 | Iteration number: [1040/4518] 23% | Training loss: 0.6874217129670657
Epoch: 35 | Iteration number: [1050/4518] 23% | Training loss: 0.6874228461583456
Epoch: 35 | Iteration number: [1060/4518] 23% | Training loss: 0.6874194925686099
Epoch: 35 | Iteration number: [1070/4518] 23% | Training loss: 0.6874097074303671
Epoch: 35 | Iteration number: [1080/4518] 23% | Training loss: 0.6873999614406515
Epoch: 35 | Iteration number: [1090/4518] 24% | Training loss: 0.6873990157328614
Epoch: 35 | Iteration number: [1100/4518] 24% | Training loss: 0.6873940604925156
Epoch: 35 | Iteration number: [1110/4518] 24% | Training loss: 0.687386385223887
Epoch: 35 | Iteration number: [1120/4518] 24% | Training loss: 0.6873792219907046
Epoch: 35 | Iteration number: [1130/4518] 25% | Training loss: 0.6873839001739974
Epoch: 35 | Iteration number: [1140/4518] 25% | Training loss: 0.6873744522793251
Epoch: 35 | Iteration number: [1150/4518] 25% | Training loss: 0.6873656989698824
Epoch: 35 | Iteration number: [1160/4518] 25% | Training loss: 0.6873593007696086
Epoch: 35 | Iteration number: [1170/4518] 25% | Training loss: 0.6873516930474175
Epoch: 35 | Iteration number: [1180/4518] 26% | Training loss: 0.6873493365312027
Epoch: 35 | Iteration number: [1190/4518] 26% | Training loss: 0.6873413669461964
Epoch: 35 | Iteration number: [1200/4518] 26% | Training loss: 0.6873393909136454
Epoch: 35 | Iteration number: [1210/4518] 26% | Training loss: 0.6873340499302573
Epoch: 35 | Iteration number: [1220/4518] 27% | Training loss: 0.687330547561411
Epoch: 35 | Iteration number: [1230/4518] 27% | Training loss: 0.6873330853334287
Epoch: 35 | Iteration number: [1240/4518] 27% | Training loss: 0.687340371502984
Epoch: 35 | Iteration number: [1250/4518] 27% | Training loss: 0.6873375180244445
Epoch: 35 | Iteration number: [1260/4518] 27% | Training loss: 0.6873362953227664
Epoch: 35 | Iteration number: [1270/4518] 28% | Training loss: 0.6873366920966801
Epoch: 35 | Iteration number: [1280/4518] 28% | Training loss: 0.6873391869477927
Epoch: 35 | Iteration number: [1290/4518] 28% | Training loss: 0.6873439153959585
Epoch: 35 | Iteration number: [1300/4518] 28% | Training loss: 0.6873474111465308
Epoch: 35 | Iteration number: [1310/4518] 28% | Training loss: 0.687340407198622
Epoch: 35 | Iteration number: [1320/4518] 29% | Training loss: 0.687336479082252
Epoch: 35 | Iteration number: [1330/4518] 29% | Training loss: 0.6873300867869442
Epoch: 35 | Iteration number: [1340/4518] 29% | Training loss: 0.6873271283818715
Epoch: 35 | Iteration number: [1350/4518] 29% | Training loss: 0.6873245659580937
Epoch: 35 | Iteration number: [1360/4518] 30% | Training loss: 0.6873212379129494
Epoch: 35 | Iteration number: [1370/4518] 30% | Training loss: 0.6873213130192165
Epoch: 35 | Iteration number: [1380/4518] 30% | Training loss: 0.6873135596081831
Epoch: 35 | Iteration number: [1390/4518] 30% | Training loss: 0.6873128397430447
Epoch: 35 | Iteration number: [1400/4518] 30% | Training loss: 0.6873105985777719
Epoch: 35 | Iteration number: [1410/4518] 31% | Training loss: 0.6872992433554738
Epoch: 35 | Iteration number: [1420/4518] 31% | Training loss: 0.687302850459663
Epoch: 35 | Iteration number: [1430/4518] 31% | Training loss: 0.6872992748980755
Epoch: 35 | Iteration number: [1440/4518] 31% | Training loss: 0.6872970644798544
Epoch: 35 | Iteration number: [1450/4518] 32% | Training loss: 0.6872883099112017
Epoch: 35 | Iteration number: [1460/4518] 32% | Training loss: 0.6872912271790308
Epoch: 35 | Iteration number: [1470/4518] 32% | Training loss: 0.6872921426280015
Epoch: 35 | Iteration number: [1480/4518] 32% | Training loss: 0.6872922225578412
Epoch: 35 | Iteration number: [1490/4518] 32% | Training loss: 0.6872841247376179
Epoch: 35 | Iteration number: [1500/4518] 33% | Training loss: 0.6872802804311117
Epoch: 35 | Iteration number: [1510/4518] 33% | Training loss: 0.6872770855363631
Epoch: 35 | Iteration number: [1520/4518] 33% | Training loss: 0.6872705524689273
Epoch: 35 | Iteration number: [1530/4518] 33% | Training loss: 0.6872656362119064
Epoch: 35 | Iteration number: [1540/4518] 34% | Training loss: 0.687260545616026
Epoch: 35 | Iteration number: [1550/4518] 34% | Training loss: 0.6872606284772196
Epoch: 35 | Iteration number: [1560/4518] 34% | Training loss: 0.6872545330188213
Epoch: 35 | Iteration number: [1570/4518] 34% | Training loss: 0.6872579844134629
Epoch: 35 | Iteration number: [1580/4518] 34% | Training loss: 0.6872572415991675
Epoch: 35 | Iteration number: [1590/4518] 35% | Training loss: 0.6872587583349936
Epoch: 35 | Iteration number: [1600/4518] 35% | Training loss: 0.6872485058754683
Epoch: 35 | Iteration number: [1610/4518] 35% | Training loss: 0.6872460030620883
Epoch: 35 | Iteration number: [1620/4518] 35% | Training loss: 0.687242101960712
Epoch: 35 | Iteration number: [1630/4518] 36% | Training loss: 0.6872394252042829
Epoch: 35 | Iteration number: [1640/4518] 36% | Training loss: 0.6872360507526049
Epoch: 35 | Iteration number: [1650/4518] 36% | Training loss: 0.687233073241783
Epoch: 35 | Iteration number: [1660/4518] 36% | Training loss: 0.6872311757989676
Epoch: 35 | Iteration number: [1670/4518] 36% | Training loss: 0.6872210024359697
Epoch: 35 | Iteration number: [1680/4518] 37% | Training loss: 0.6872141770308926
Epoch: 35 | Iteration number: [1690/4518] 37% | Training loss: 0.6872130178488218
Epoch: 35 | Iteration number: [1700/4518] 37% | Training loss: 0.6872028863430023
Epoch: 35 | Iteration number: [1710/4518] 37% | Training loss: 0.6871952401615723
Epoch: 35 | Iteration number: [1720/4518] 38% | Training loss: 0.6872001774089281
Epoch: 35 | Iteration number: [1730/4518] 38% | Training loss: 0.6871971232698143
Epoch: 35 | Iteration number: [1740/4518] 38% | Training loss: 0.6871967905211722
Epoch: 35 | Iteration number: [1750/4518] 38% | Training loss: 0.687193772997175
Epoch: 35 | Iteration number: [1760/4518] 38% | Training loss: 0.6871778977188197
Epoch: 35 | Iteration number: [1770/4518] 39% | Training loss: 0.6871779737836223
Epoch: 35 | Iteration number: [1780/4518] 39% | Training loss: 0.6871811454885461
Epoch: 35 | Iteration number: [1790/4518] 39% | Training loss: 0.6871793838186637
Epoch: 35 | Iteration number: [1800/4518] 39% | Training loss: 0.6871719469957881
Epoch: 35 | Iteration number: [1810/4518] 40% | Training loss: 0.6871674111534878
Epoch: 35 | Iteration number: [1820/4518] 40% | Training loss: 0.6871650333915438
Epoch: 35 | Iteration number: [1830/4518] 40% | Training loss: 0.687163833321118
Epoch: 35 | Iteration number: [1840/4518] 40% | Training loss: 0.6871618660571782
Epoch: 35 | Iteration number: [1850/4518] 40% | Training loss: 0.6871608902956988
Epoch: 35 | Iteration number: [1860/4518] 41% | Training loss: 0.6871504791321293
Epoch: 35 | Iteration number: [1870/4518] 41% | Training loss: 0.6871475865496671
Epoch: 35 | Iteration number: [1880/4518] 41% | Training loss: 0.6871385380308679
Epoch: 35 | Iteration number: [1890/4518] 41% | Training loss: 0.6871357672744327
Epoch: 35 | Iteration number: [1900/4518] 42% | Training loss: 0.687138575189992
Epoch: 35 | Iteration number: [1910/4518] 42% | Training loss: 0.6871305309977207
Epoch: 35 | Iteration number: [1920/4518] 42% | Training loss: 0.6871313137933612
Epoch: 35 | Iteration number: [1930/4518] 42% | Training loss: 0.6871320014481718
Epoch: 35 | Iteration number: [1940/4518] 42% | Training loss: 0.6871278265395115
Epoch: 35 | Iteration number: [1950/4518] 43% | Training loss: 0.6871249547065833
Epoch: 35 | Iteration number: [1960/4518] 43% | Training loss: 0.687121926613
Epoch: 35 | Iteration number: [1970/4518] 43% | Training loss: 0.6871211608654352
Epoch: 35 | Iteration number: [1980/4518] 43% | Training loss: 0.6871197116495383
Epoch: 35 | Iteration number: [1990/4518] 44% | Training loss: 0.6871238651886658
Epoch: 35 | Iteration number: [2000/4518] 44% | Training loss: 0.6871242257654667
Epoch: 35 | Iteration number: [2010/4518] 44% | Training loss: 0.6871239215876925
Epoch: 35 | Iteration number: [2020/4518] 44% | Training loss: 0.6871247129275067
Epoch: 35 | Iteration number: [2030/4518] 44% | Training loss: 0.6871236270871656
Epoch: 35 | Iteration number: [2040/4518] 45% | Training loss: 0.6871220257352381
Epoch: 35 | Iteration number: [2050/4518] 45% | Training loss: 0.6871189657944005
Epoch: 35 | Iteration number: [2060/4518] 45% | Training loss: 0.6871150889442962
Epoch: 35 | Iteration number: [2070/4518] 45% | Training loss: 0.6871099434325084
Epoch: 35 | Iteration number: [2080/4518] 46% | Training loss: 0.6871059323446109
Epoch: 35 | Iteration number: [2090/4518] 46% | Training loss: 0.6871046061721144
Epoch: 35 | Iteration number: [2100/4518] 46% | Training loss: 0.6871137597731182
Epoch: 35 | Iteration number: [2110/4518] 46% | Training loss: 0.6871073377640892
Epoch: 35 | Iteration number: [2120/4518] 46% | Training loss: 0.6871108002257797
Epoch: 35 | Iteration number: [2130/4518] 47% | Training loss: 0.6871134891196595
Epoch: 35 | Iteration number: [2140/4518] 47% | Training loss: 0.6871171116550392
Epoch: 35 | Iteration number: [2150/4518] 47% | Training loss: 0.6871120893400768
Epoch: 35 | Iteration number: [2160/4518] 47% | Training loss: 0.6871107882371655
Epoch: 35 | Iteration number: [2170/4518] 48% | Training loss: 0.6871077804246806
Epoch: 35 | Iteration number: [2180/4518] 48% | Training loss: 0.6871051600493422
Epoch: 35 | Iteration number: [2190/4518] 48% | Training loss: 0.6870930845062482
Epoch: 35 | Iteration number: [2200/4518] 48% | Training loss: 0.6870969799431887
Epoch: 35 | Iteration number: [2210/4518] 48% | Training loss: 0.6870922759916988
Epoch: 35 | Iteration number: [2220/4518] 49% | Training loss: 0.6870918059671247
Epoch: 35 | Iteration number: [2230/4518] 49% | Training loss: 0.6870919900892026
Epoch: 35 | Iteration number: [2240/4518] 49% | Training loss: 0.6870871309457081
Epoch: 35 | Iteration number: [2250/4518] 49% | Training loss: 0.6870868325498369
Epoch: 35 | Iteration number: [2260/4518] 50% | Training loss: 0.6870850411400331
Epoch: 35 | Iteration number: [2270/4518] 50% | Training loss: 0.687086067693349
Epoch: 35 | Iteration number: [2280/4518] 50% | Training loss: 0.6870885601692033
Epoch: 35 | Iteration number: [2290/4518] 50% | Training loss: 0.6870864416834569
Epoch: 35 | Iteration number: [2300/4518] 50% | Training loss: 0.6870807968274407
Epoch: 35 | Iteration number: [2310/4518] 51% | Training loss: 0.6870707234520933
Epoch: 35 | Iteration number: [2320/4518] 51% | Training loss: 0.6870696334746377
Epoch: 35 | Iteration number: [2330/4518] 51% | Training loss: 0.6870657461651405
Epoch: 35 | Iteration number: [2340/4518] 51% | Training loss: 0.6870632757743199
Epoch: 35 | Iteration number: [2350/4518] 52% | Training loss: 0.6870633781717179
Epoch: 35 | Iteration number: [2360/4518] 52% | Training loss: 0.6870610614196729
Epoch: 35 | Iteration number: [2370/4518] 52% | Training loss: 0.6870631780805467
Epoch: 35 | Iteration number: [2380/4518] 52% | Training loss: 0.6870599316699164
Epoch: 35 | Iteration number: [2390/4518] 52% | Training loss: 0.6870576455253936
Epoch: 35 | Iteration number: [2400/4518] 53% | Training loss: 0.6870578312377135
Epoch: 35 | Iteration number: [2410/4518] 53% | Training loss: 0.687058494570839
Epoch: 35 | Iteration number: [2420/4518] 53% | Training loss: 0.68705608726533
Epoch: 35 | Iteration number: [2430/4518] 53% | Training loss: 0.6870486904564218
Epoch: 35 | Iteration number: [2440/4518] 54% | Training loss: 0.6870482003346818
Epoch: 35 | Iteration number: [2450/4518] 54% | Training loss: 0.6870533504048172
Epoch: 35 | Iteration number: [2460/4518] 54% | Training loss: 0.6870551449254276
Epoch: 35 | Iteration number: [2470/4518] 54% | Training loss: 0.6870550508682545
Epoch: 35 | Iteration number: [2480/4518] 54% | Training loss: 0.6870533819400495
Epoch: 35 | Iteration number: [2490/4518] 55% | Training loss: 0.6870519451348178
Epoch: 35 | Iteration number: [2500/4518] 55% | Training loss: 0.6870500834941864
Epoch: 35 | Iteration number: [2510/4518] 55% | Training loss: 0.6870443445515347
Epoch: 35 | Iteration number: [2520/4518] 55% | Training loss: 0.6870414314288942
Epoch: 35 | Iteration number: [2530/4518] 55% | Training loss: 0.6870398247666039
Epoch: 35 | Iteration number: [2540/4518] 56% | Training loss: 0.6870447412015885
Epoch: 35 | Iteration number: [2550/4518] 56% | Training loss: 0.6870443435743744
Epoch: 35 | Iteration number: [2560/4518] 56% | Training loss: 0.6870447482913733
Epoch: 35 | Iteration number: [2570/4518] 56% | Training loss: 0.6870409836333086
Epoch: 35 | Iteration number: [2580/4518] 57% | Training loss: 0.6870421892912812
Epoch: 35 | Iteration number: [2590/4518] 57% | Training loss: 0.687045549886107
Epoch: 35 | Iteration number: [2600/4518] 57% | Training loss: 0.6870453694233527
Epoch: 35 | Iteration number: [2610/4518] 57% | Training loss: 0.6870432713479374
Epoch: 35 | Iteration number: [2620/4518] 57% | Training loss: 0.6870402018532498
Epoch: 35 | Iteration number: [2630/4518] 58% | Training loss: 0.6870385696906101
Epoch: 35 | Iteration number: [2640/4518] 58% | Training loss: 0.6870361497230602
Epoch: 35 | Iteration number: [2650/4518] 58% | Training loss: 0.6870417531481329
Epoch: 35 | Iteration number: [2660/4518] 58% | Training loss: 0.6870408459041352
Epoch: 35 | Iteration number: [2670/4518] 59% | Training loss: 0.6870418734318308
Epoch: 35 | Iteration number: [2680/4518] 59% | Training loss: 0.6870446047676143
Epoch: 35 | Iteration number: [2690/4518] 59% | Training loss: 0.6870477740427818
Epoch: 35 | Iteration number: [2700/4518] 59% | Training loss: 0.687041269827772
Epoch: 35 | Iteration number: [2710/4518] 59% | Training loss: 0.6870372280203548
Epoch: 35 | Iteration number: [2720/4518] 60% | Training loss: 0.6870398826897144
Epoch: 35 | Iteration number: [2730/4518] 60% | Training loss: 0.687038798275448
Epoch: 35 | Iteration number: [2740/4518] 60% | Training loss: 0.6870397875561332
Epoch: 35 | Iteration number: [2750/4518] 60% | Training loss: 0.6870390919555317
Epoch: 35 | Iteration number: [2760/4518] 61% | Training loss: 0.6870398490109305
Epoch: 35 | Iteration number: [2770/4518] 61% | Training loss: 0.6870331305243909
Epoch: 35 | Iteration number: [2780/4518] 61% | Training loss: 0.6870358840595904
Epoch: 35 | Iteration number: [2790/4518] 61% | Training loss: 0.6870336344165187
Epoch: 35 | Iteration number: [2800/4518] 61% | Training loss: 0.687035770884582
Epoch: 35 | Iteration number: [2810/4518] 62% | Training loss: 0.6870303137658754
Epoch: 35 | Iteration number: [2820/4518] 62% | Training loss: 0.6870266290843909
Epoch: 35 | Iteration number: [2830/4518] 62% | Training loss: 0.6870271178311257
Epoch: 35 | Iteration number: [2840/4518] 62% | Training loss: 0.687027088059506
Epoch: 35 | Iteration number: [2850/4518] 63% | Training loss: 0.6870299564537249
Epoch: 35 | Iteration number: [2860/4518] 63% | Training loss: 0.6870370229641041
Epoch: 35 | Iteration number: [2870/4518] 63% | Training loss: 0.687043232120288
Epoch: 35 | Iteration number: [2880/4518] 63% | Training loss: 0.6870442576085528
Epoch: 35 | Iteration number: [2890/4518] 63% | Training loss: 0.6870457386475534
Epoch: 35 | Iteration number: [2900/4518] 64% | Training loss: 0.6870416014153382
Epoch: 35 | Iteration number: [2910/4518] 64% | Training loss: 0.6870406654692188
Epoch: 35 | Iteration number: [2920/4518] 64% | Training loss: 0.6870415539774176
Epoch: 35 | Iteration number: [2930/4518] 64% | Training loss: 0.6870418082121696
Epoch: 35 | Iteration number: [2940/4518] 65% | Training loss: 0.6870424809910002
Epoch: 35 | Iteration number: [2950/4518] 65% | Training loss: 0.6870431498955872
Epoch: 35 | Iteration number: [2960/4518] 65% | Training loss: 0.6870400646449746
Epoch: 35 | Iteration number: [2970/4518] 65% | Training loss: 0.6870362741979285
Epoch: 35 | Iteration number: [2980/4518] 65% | Training loss: 0.6870390937032316
Epoch: 35 | Iteration number: [2990/4518] 66% | Training loss: 0.6870385946039372
Epoch: 35 | Iteration number: [3000/4518] 66% | Training loss: 0.6870418192346891
Epoch: 35 | Iteration number: [3010/4518] 66% | Training loss: 0.6870416774306186
Epoch: 35 | Iteration number: [3020/4518] 66% | Training loss: 0.6870370310071289
Epoch: 35 | Iteration number: [3030/4518] 67% | Training loss: 0.6870363234883488
Epoch: 35 | Iteration number: [3040/4518] 67% | Training loss: 0.6870378455833385
Epoch: 35 | Iteration number: [3050/4518] 67% | Training loss: 0.6870403277092293
Epoch: 35 | Iteration number: [3060/4518] 67% | Training loss: 0.6870410361710717
Epoch: 35 | Iteration number: [3070/4518] 67% | Training loss: 0.6870439292941886
Epoch: 35 | Iteration number: [3080/4518] 68% | Training loss: 0.6870410979181141
Epoch: 35 | Iteration number: [3090/4518] 68% | Training loss: 0.6870395469819843
Epoch: 35 | Iteration number: [3100/4518] 68% | Training loss: 0.6870437622070312
Epoch: 35 | Iteration number: [3110/4518] 68% | Training loss: 0.6870393466911132
Epoch: 35 | Iteration number: [3120/4518] 69% | Training loss: 0.687042629145659
Epoch: 35 | Iteration number: [3130/4518] 69% | Training loss: 0.6870448797655563
Epoch: 35 | Iteration number: [3140/4518] 69% | Training loss: 0.687044577120216
Epoch: 35 | Iteration number: [3150/4518] 69% | Training loss: 0.6870445311069489
Epoch: 35 | Iteration number: [3160/4518] 69% | Training loss: 0.6870440556467334
Epoch: 35 | Iteration number: [3170/4518] 70% | Training loss: 0.6870422164348398
Epoch: 35 | Iteration number: [3180/4518] 70% | Training loss: 0.6870443960780618
Epoch: 35 | Iteration number: [3190/4518] 70% | Training loss: 0.6870429408774481
Epoch: 35 | Iteration number: [3200/4518] 70% | Training loss: 0.6870405794121325
Epoch: 35 | Iteration number: [3210/4518] 71% | Training loss: 0.6870411132912027
Epoch: 35 | Iteration number: [3220/4518] 71% | Training loss: 0.6870406448285772
Epoch: 35 | Iteration number: [3230/4518] 71% | Training loss: 0.6870359694441036
Epoch: 35 | Iteration number: [3240/4518] 71% | Training loss: 0.6870341192057103
Epoch: 35 | Iteration number: [3250/4518] 71% | Training loss: 0.6870306518261249
Epoch: 35 | Iteration number: [3260/4518] 72% | Training loss: 0.6870236724066588
Epoch: 35 | Iteration number: [3270/4518] 72% | Training loss: 0.6870246607046973
Epoch: 35 | Iteration number: [3280/4518] 72% | Training loss: 0.687025759877955
Epoch: 35 | Iteration number: [3290/4518] 72% | Training loss: 0.687026615092095
Epoch: 35 | Iteration number: [3300/4518] 73% | Training loss: 0.6870261080517913
Epoch: 35 | Iteration number: [3310/4518] 73% | Training loss: 0.6870229029403352
Epoch: 35 | Iteration number: [3320/4518] 73% | Training loss: 0.687018289946648
Epoch: 35 | Iteration number: [3330/4518] 73% | Training loss: 0.6870175372372876
Epoch: 35 | Iteration number: [3340/4518] 73% | Training loss: 0.6870163821888541
Epoch: 35 | Iteration number: [3350/4518] 74% | Training loss: 0.6870183756991999
Epoch: 35 | Iteration number: [3360/4518] 74% | Training loss: 0.687020389859875
Epoch: 35 | Iteration number: [3370/4518] 74% | Training loss: 0.6870205529012029
Epoch: 35 | Iteration number: [3380/4518] 74% | Training loss: 0.6870215199226458
Epoch: 35 | Iteration number: [3390/4518] 75% | Training loss: 0.6870200531320938
Epoch: 35 | Iteration number: [3400/4518] 75% | Training loss: 0.6870222478929688
Epoch: 35 | Iteration number: [3410/4518] 75% | Training loss: 0.687019642741799
Epoch: 35 | Iteration number: [3420/4518] 75% | Training loss: 0.6870157924660465
Epoch: 35 | Iteration number: [3430/4518] 75% | Training loss: 0.6870139335404332
Epoch: 35 | Iteration number: [3440/4518] 76% | Training loss: 0.6870120366472144
Epoch: 35 | Iteration number: [3450/4518] 76% | Training loss: 0.687014067656752
Epoch: 35 | Iteration number: [3460/4518] 76% | Training loss: 0.6870147039090967
Epoch: 35 | Iteration number: [3470/4518] 76% | Training loss: 0.6870142742948505
Epoch: 35 | Iteration number: [3480/4518] 77% | Training loss: 0.6870155526646252
Epoch: 35 | Iteration number: [3490/4518] 77% | Training loss: 0.6870179827711985
Epoch: 35 | Iteration number: [3500/4518] 77% | Training loss: 0.6870186419316701
Epoch: 35 | Iteration number: [3510/4518] 77% | Training loss: 0.6870168042658401
Epoch: 35 | Iteration number: [3520/4518] 77% | Training loss: 0.6870140224525875
Epoch: 35 | Iteration number: [3530/4518] 78% | Training loss: 0.6870151241676665
Epoch: 35 | Iteration number: [3540/4518] 78% | Training loss: 0.687014449871866
Epoch: 35 | Iteration number: [3550/4518] 78% | Training loss: 0.6870116255652736
Epoch: 35 | Iteration number: [3560/4518] 78% | Training loss: 0.6870110730441769
Epoch: 35 | Iteration number: [3570/4518] 79% | Training loss: 0.6870108449158548
Epoch: 35 | Iteration number: [3580/4518] 79% | Training loss: 0.6870132715508924
Epoch: 35 | Iteration number: [3590/4518] 79% | Training loss: 0.6870139548207392
Epoch: 35 | Iteration number: [3600/4518] 79% | Training loss: 0.6870119451814227
Epoch: 35 | Iteration number: [3610/4518] 79% | Training loss: 0.6870130610432982
Epoch: 35 | Iteration number: [3620/4518] 80% | Training loss: 0.6870136569218083
Epoch: 35 | Iteration number: [3630/4518] 80% | Training loss: 0.6870090456048319
Epoch: 35 | Iteration number: [3640/4518] 80% | Training loss: 0.6870112796733667
Epoch: 35 | Iteration number: [3650/4518] 80% | Training loss: 0.6870065095163371
Epoch: 35 | Iteration number: [3660/4518] 81% | Training loss: 0.6870034199757654
Epoch: 35 | Iteration number: [3670/4518] 81% | Training loss: 0.6870036735196854
Epoch: 35 | Iteration number: [3680/4518] 81% | Training loss: 0.6870046496391297
Epoch: 35 | Iteration number: [3690/4518] 81% | Training loss: 0.6870040504105369
Epoch: 35 | Iteration number: [3700/4518] 81% | Training loss: 0.6870028553943376
Epoch: 35 | Iteration number: [3710/4518] 82% | Training loss: 0.687002615674808
Epoch: 35 | Iteration number: [3720/4518] 82% | Training loss: 0.6870042994938871
Epoch: 35 | Iteration number: [3730/4518] 82% | Training loss: 0.6870032876010874
Epoch: 35 | Iteration number: [3740/4518] 82% | Training loss: 0.6870035596072355
Epoch: 35 | Iteration number: [3750/4518] 83% | Training loss: 0.6870045798460642
Epoch: 35 | Iteration number: [3760/4518] 83% | Training loss: 0.6870049322380665
Epoch: 35 | Iteration number: [3770/4518] 83% | Training loss: 0.6870053743335865
Epoch: 35 | Iteration number: [3780/4518] 83% | Training loss: 0.6870081131578123
Epoch: 35 | Iteration number: [3790/4518] 83% | Training loss: 0.6870073310303499
Epoch: 35 | Iteration number: [3800/4518] 84% | Training loss: 0.6870090111462693
Epoch: 35 | Iteration number: [3810/4518] 84% | Training loss: 0.6870111758940489
Epoch: 35 | Iteration number: [3820/4518] 84% | Training loss: 0.6870111874104794
Epoch: 35 | Iteration number: [3830/4518] 84% | Training loss: 0.6870104963567798
Epoch: 35 | Iteration number: [3840/4518] 84% | Training loss: 0.6870107069301109
Epoch: 35 | Iteration number: [3850/4518] 85% | Training loss: 0.6870078098928774
Epoch: 35 | Iteration number: [3860/4518] 85% | Training loss: 0.6870068799491991
Epoch: 35 | Iteration number: [3870/4518] 85% | Training loss: 0.6870096085145492
Epoch: 35 | Iteration number: [3880/4518] 85% | Training loss: 0.6870116895467965
Epoch: 35 | Iteration number: [3890/4518] 86% | Training loss: 0.6870105095571601
Epoch: 35 | Iteration number: [3900/4518] 86% | Training loss: 0.68701007717695
Epoch: 35 | Iteration number: [3910/4518] 86% | Training loss: 0.6870084972027928
Epoch: 35 | Iteration number: [3920/4518] 86% | Training loss: 0.6870068560753549
Epoch: 35 | Iteration number: [3930/4518] 86% | Training loss: 0.6870084006367749
Epoch: 35 | Iteration number: [3940/4518] 87% | Training loss: 0.6870074437203141
Epoch: 35 | Iteration number: [3950/4518] 87% | Training loss: 0.6870085082476652
Epoch: 35 | Iteration number: [3960/4518] 87% | Training loss: 0.6870083849990006
Epoch: 35 | Iteration number: [3970/4518] 87% | Training loss: 0.6870058710539071
Epoch: 35 | Iteration number: [3980/4518] 88% | Training loss: 0.6870057933743875
Epoch: 35 | Iteration number: [3990/4518] 88% | Training loss: 0.6870050123759679
Epoch: 35 | Iteration number: [4000/4518] 88% | Training loss: 0.6870058963745832
Epoch: 35 | Iteration number: [4010/4518] 88% | Training loss: 0.6870066066483904
Epoch: 35 | Iteration number: [4020/4518] 88% | Training loss: 0.6870065924391817
Epoch: 35 | Iteration number: [4030/4518] 89% | Training loss: 0.6870039595711616
Epoch: 35 | Iteration number: [4040/4518] 89% | Training loss: 0.6870044689662386
Epoch: 35 | Iteration number: [4050/4518] 89% | Training loss: 0.6870035338107451
Epoch: 35 | Iteration number: [4060/4518] 89% | Training loss: 0.68700493008926
Epoch: 35 | Iteration number: [4070/4518] 90% | Training loss: 0.6870057263889828
Epoch: 35 | Iteration number: [4080/4518] 90% | Training loss: 0.687006760958363
Epoch: 35 | Iteration number: [4090/4518] 90% | Training loss: 0.6870057059383625
Epoch: 35 | Iteration number: [4100/4518] 90% | Training loss: 0.6870047861192284
Epoch: 35 | Iteration number: [4110/4518] 90% | Training loss: 0.6870049439497528
Epoch: 35 | Iteration number: [4120/4518] 91% | Training loss: 0.6870062562013135
Epoch: 35 | Iteration number: [4130/4518] 91% | Training loss: 0.6870049925173743
Epoch: 35 | Iteration number: [4140/4518] 91% | Training loss: 0.6870029652464217
Epoch: 35 | Iteration number: [4150/4518] 91% | Training loss: 0.687000987156328
Epoch: 35 | Iteration number: [4160/4518] 92% | Training loss: 0.6869973972439766
Epoch: 35 | Iteration number: [4170/4518] 92% | Training loss: 0.6869960605526428
Epoch: 35 | Iteration number: [4180/4518] 92% | Training loss: 0.6869955931554
Epoch: 35 | Iteration number: [4190/4518] 92% | Training loss: 0.6869966511367898
Epoch: 35 | Iteration number: [4200/4518] 92% | Training loss: 0.6869961622925032
Epoch: 35 | Iteration number: [4210/4518] 93% | Training loss: 0.6869958911117635
Epoch: 35 | Iteration number: [4220/4518] 93% | Training loss: 0.6869947601268642
Epoch: 35 | Iteration number: [4230/4518] 93% | Training loss: 0.6869941562061896
Epoch: 35 | Iteration number: [4240/4518] 93% | Training loss: 0.68699627316223
Epoch: 35 | Iteration number: [4250/4518] 94% | Training loss: 0.6869968100856332
Epoch: 35 | Iteration number: [4260/4518] 94% | Training loss: 0.6869969091365035
Epoch: 35 | Iteration number: [4270/4518] 94% | Training loss: 0.6869966609556167
Epoch: 35 | Iteration number: [4280/4518] 94% | Training loss: 0.6869946541490956
Epoch: 35 | Iteration number: [4290/4518] 94% | Training loss: 0.6869955098851299
Epoch: 35 | Iteration number: [4300/4518] 95% | Training loss: 0.6869965193160744
Epoch: 35 | Iteration number: [4310/4518] 95% | Training loss: 0.6869930101657965
Epoch: 35 | Iteration number: [4320/4518] 95% | Training loss: 0.6869948612319099
Epoch: 35 | Iteration number: [4330/4518] 95% | Training loss: 0.6869946500170313
Epoch: 35 | Iteration number: [4340/4518] 96% | Training loss: 0.6869955861486048
Epoch: 35 | Iteration number: [4350/4518] 96% | Training loss: 0.6869954101244609
Epoch: 35 | Iteration number: [4360/4518] 96% | Training loss: 0.686995648531192
Epoch: 35 | Iteration number: [4370/4518] 96% | Training loss: 0.6869966505730453
Epoch: 35 | Iteration number: [4380/4518] 96% | Training loss: 0.6869928466130609
Epoch: 35 | Iteration number: [4390/4518] 97% | Training loss: 0.6869925035159518
Epoch: 35 | Iteration number: [4400/4518] 97% | Training loss: 0.6869944994287057
Epoch: 35 | Iteration number: [4410/4518] 97% | Training loss: 0.6869932120484289
Epoch: 35 | Iteration number: [4420/4518] 97% | Training loss: 0.6869910059876032
Epoch: 35 | Iteration number: [4430/4518] 98% | Training loss: 0.6869926657283817
Epoch: 35 | Iteration number: [4440/4518] 98% | Training loss: 0.6869947552949459
Epoch: 35 | Iteration number: [4450/4518] 98% | Training loss: 0.6869941573464469
Epoch: 35 | Iteration number: [4460/4518] 98% | Training loss: 0.6869946172151865
Epoch: 35 | Iteration number: [4470/4518] 98% | Training loss: 0.686991311053035
Epoch: 35 | Iteration number: [4480/4518] 99% | Training loss: 0.6869905496149191
Epoch: 35 | Iteration number: [4490/4518] 99% | Training loss: 0.6869897404731249
Epoch: 35 | Iteration number: [4500/4518] 99% | Training loss: 0.6869894017775854
Epoch: 35 | Iteration number: [4510/4518] 99% | Training loss: 0.6869885656363155

 End of epoch: 35 | Train Loss: 0.6868356627244345 | Training Time: 632 

 End of epoch: 35 | Eval Loss: 0.6898916254238207 | Evaluating Time: 17 
Epoch: 36 | Iteration number: [10/4518] 0% | Training loss: 0.7550550639629364
Epoch: 36 | Iteration number: [20/4518] 0% | Training loss: 0.7215130895376205
Epoch: 36 | Iteration number: [30/4518] 0% | Training loss: 0.7093724191188813
Epoch: 36 | Iteration number: [40/4518] 0% | Training loss: 0.7038596123456955
Epoch: 36 | Iteration number: [50/4518] 1% | Training loss: 0.7005614149570465
Epoch: 36 | Iteration number: [60/4518] 1% | Training loss: 0.6981999466816584
Epoch: 36 | Iteration number: [70/4518] 1% | Training loss: 0.6966438778809139
Epoch: 36 | Iteration number: [80/4518] 1% | Training loss: 0.6953334666788578
Epoch: 36 | Iteration number: [90/4518] 1% | Training loss: 0.6943354056941138
Epoch: 36 | Iteration number: [100/4518] 2% | Training loss: 0.6936142498254776
Epoch: 36 | Iteration number: [110/4518] 2% | Training loss: 0.6928589024327018
Epoch: 36 | Iteration number: [120/4518] 2% | Training loss: 0.6923093462983767
Epoch: 36 | Iteration number: [130/4518] 2% | Training loss: 0.6918509423732757
Epoch: 36 | Iteration number: [140/4518] 3% | Training loss: 0.6914719615663801
Epoch: 36 | Iteration number: [150/4518] 3% | Training loss: 0.6912271742026012
Epoch: 36 | Iteration number: [160/4518] 3% | Training loss: 0.6909080080687999
Epoch: 36 | Iteration number: [170/4518] 3% | Training loss: 0.690674667148029
Epoch: 36 | Iteration number: [180/4518] 3% | Training loss: 0.6905020693937938
Epoch: 36 | Iteration number: [190/4518] 4% | Training loss: 0.6903151173340647
Epoch: 36 | Iteration number: [200/4518] 4% | Training loss: 0.6901356568932533
Epoch: 36 | Iteration number: [210/4518] 4% | Training loss: 0.689973132950919
Epoch: 36 | Iteration number: [220/4518] 4% | Training loss: 0.6898235001347282
Epoch: 36 | Iteration number: [230/4518] 5% | Training loss: 0.6896850083185279
Epoch: 36 | Iteration number: [240/4518] 5% | Training loss: 0.68958279962341
Epoch: 36 | Iteration number: [250/4518] 5% | Training loss: 0.6895087103843689
Epoch: 36 | Iteration number: [260/4518] 5% | Training loss: 0.6894124260315528
Epoch: 36 | Iteration number: [270/4518] 5% | Training loss: 0.6892747616326368
Epoch: 36 | Iteration number: [280/4518] 6% | Training loss: 0.6891604082924979
Epoch: 36 | Iteration number: [290/4518] 6% | Training loss: 0.6890651226043701
Epoch: 36 | Iteration number: [300/4518] 6% | Training loss: 0.6890396185715993
Epoch: 36 | Iteration number: [310/4518] 6% | Training loss: 0.6889520589382417
Epoch: 36 | Iteration number: [320/4518] 7% | Training loss: 0.6888675516471267
Epoch: 36 | Iteration number: [330/4518] 7% | Training loss: 0.6887955551797693
Epoch: 36 | Iteration number: [340/4518] 7% | Training loss: 0.6887436475823907
Epoch: 36 | Iteration number: [350/4518] 7% | Training loss: 0.6886851377146584
Epoch: 36 | Iteration number: [360/4518] 7% | Training loss: 0.6886297424634298
Epoch: 36 | Iteration number: [370/4518] 8% | Training loss: 0.6885925906735497
Epoch: 36 | Iteration number: [380/4518] 8% | Training loss: 0.6885403004131819
Epoch: 36 | Iteration number: [390/4518] 8% | Training loss: 0.6885001103083292
Epoch: 36 | Iteration number: [400/4518] 8% | Training loss: 0.6884945100545883
Epoch: 36 | Iteration number: [410/4518] 9% | Training loss: 0.6884738221401121
Epoch: 36 | Iteration number: [420/4518] 9% | Training loss: 0.6884258512939726
Epoch: 36 | Iteration number: [430/4518] 9% | Training loss: 0.6884024477282236
Epoch: 36 | Iteration number: [440/4518] 9% | Training loss: 0.6884042038158937
Epoch: 36 | Iteration number: [450/4518] 9% | Training loss: 0.6883871551354727
Epoch: 36 | Iteration number: [460/4518] 10% | Training loss: 0.6883569380511408
Epoch: 36 | Iteration number: [470/4518] 10% | Training loss: 0.6883269733570991
Epoch: 36 | Iteration number: [480/4518] 10% | Training loss: 0.6883308039357264
Epoch: 36 | Iteration number: [490/4518] 10% | Training loss: 0.6883038286043673
Epoch: 36 | Iteration number: [500/4518] 11% | Training loss: 0.6882684624195099
Epoch: 36 | Iteration number: [510/4518] 11% | Training loss: 0.6882487743508582
Epoch: 36 | Iteration number: [520/4518] 11% | Training loss: 0.6882196592596861
Epoch: 36 | Iteration number: [530/4518] 11% | Training loss: 0.6881926696255521
Epoch: 36 | Iteration number: [540/4518] 11% | Training loss: 0.6881251701602229
Epoch: 36 | Iteration number: [550/4518] 12% | Training loss: 0.6880995820869099
Epoch: 36 | Iteration number: [560/4518] 12% | Training loss: 0.6880909455674035
Epoch: 36 | Iteration number: [570/4518] 12% | Training loss: 0.688055459867444
Epoch: 36 | Iteration number: [580/4518] 12% | Training loss: 0.6880241038470433
Epoch: 36 | Iteration number: [590/4518] 13% | Training loss: 0.6880130942595207
Epoch: 36 | Iteration number: [600/4518] 13% | Training loss: 0.6880076203743617
Epoch: 36 | Iteration number: [610/4518] 13% | Training loss: 0.6879861357759257
Epoch: 36 | Iteration number: [620/4518] 13% | Training loss: 0.6879694186872052
Epoch: 36 | Iteration number: [630/4518] 13% | Training loss: 0.6879697114702255
Epoch: 36 | Iteration number: [640/4518] 14% | Training loss: 0.6879359442740679
Epoch: 36 | Iteration number: [650/4518] 14% | Training loss: 0.6879051909996913
Epoch: 36 | Iteration number: [660/4518] 14% | Training loss: 0.6878873857584866
Epoch: 36 | Iteration number: [670/4518] 14% | Training loss: 0.6878746336075797
Epoch: 36 | Iteration number: [680/4518] 15% | Training loss: 0.6878626847968382
Epoch: 36 | Iteration number: [690/4518] 15% | Training loss: 0.6878500966922096
Epoch: 36 | Iteration number: [700/4518] 15% | Training loss: 0.6878295013734272
Epoch: 36 | Iteration number: [710/4518] 15% | Training loss: 0.6878169790120192
Epoch: 36 | Iteration number: [720/4518] 15% | Training loss: 0.6878095130953524
Epoch: 36 | Iteration number: [730/4518] 16% | Training loss: 0.6877944053035893
Epoch: 36 | Iteration number: [740/4518] 16% | Training loss: 0.68779281538886
Epoch: 36 | Iteration number: [750/4518] 16% | Training loss: 0.6877801144123077
Epoch: 36 | Iteration number: [760/4518] 16% | Training loss: 0.6877728478688943
Epoch: 36 | Iteration number: [770/4518] 17% | Training loss: 0.6877791710488208
Epoch: 36 | Iteration number: [780/4518] 17% | Training loss: 0.6877777747618846
Epoch: 36 | Iteration number: [790/4518] 17% | Training loss: 0.6877552177332624
Epoch: 36 | Iteration number: [800/4518] 17% | Training loss: 0.6877447693794966
Epoch: 36 | Iteration number: [810/4518] 17% | Training loss: 0.687725818377954
Epoch: 36 | Iteration number: [820/4518] 18% | Training loss: 0.6877110067664123
Epoch: 36 | Iteration number: [830/4518] 18% | Training loss: 0.6877089445849499
Epoch: 36 | Iteration number: [840/4518] 18% | Training loss: 0.6876911511023839
Epoch: 36 | Iteration number: [850/4518] 18% | Training loss: 0.687669176494374
Epoch: 36 | Iteration number: [860/4518] 19% | Training loss: 0.6876613127630811
Epoch: 36 | Iteration number: [870/4518] 19% | Training loss: 0.6876525258880922
Epoch: 36 | Iteration number: [880/4518] 19% | Training loss: 0.6876489274203778
Epoch: 36 | Iteration number: [890/4518] 19% | Training loss: 0.6876466487900594
Epoch: 36 | Iteration number: [900/4518] 19% | Training loss: 0.6876425841781828
Epoch: 36 | Iteration number: [910/4518] 20% | Training loss: 0.6876287216013605
Epoch: 36 | Iteration number: [920/4518] 20% | Training loss: 0.6876220415467801
Epoch: 36 | Iteration number: [930/4518] 20% | Training loss: 0.6876091955169554
Epoch: 36 | Iteration number: [940/4518] 20% | Training loss: 0.6876029197205888
Epoch: 36 | Iteration number: [950/4518] 21% | Training loss: 0.6876007447117254
Epoch: 36 | Iteration number: [960/4518] 21% | Training loss: 0.6875868452092012
Epoch: 36 | Iteration number: [970/4518] 21% | Training loss: 0.6875772157280715
Epoch: 36 | Iteration number: [980/4518] 21% | Training loss: 0.6875803527783374
Epoch: 36 | Iteration number: [990/4518] 21% | Training loss: 0.6875774660495797
Epoch: 36 | Iteration number: [1000/4518] 22% | Training loss: 0.6875727999210358
Epoch: 36 | Iteration number: [1010/4518] 22% | Training loss: 0.6875675912540737
Epoch: 36 | Iteration number: [1020/4518] 22% | Training loss: 0.6875527161009172
Epoch: 36 | Iteration number: [1030/4518] 22% | Training loss: 0.6875606174607879
Epoch: 36 | Iteration number: [1040/4518] 23% | Training loss: 0.6875479599031118
Epoch: 36 | Iteration number: [1050/4518] 23% | Training loss: 0.6875367047105516
Epoch: 36 | Iteration number: [1060/4518] 23% | Training loss: 0.6875291766985407
Epoch: 36 | Iteration number: [1070/4518] 23% | Training loss: 0.6875297212712118
Epoch: 36 | Iteration number: [1080/4518] 23% | Training loss: 0.6875298385818799
Epoch: 36 | Iteration number: [1090/4518] 24% | Training loss: 0.687507061509911
Epoch: 36 | Iteration number: [1100/4518] 24% | Training loss: 0.6875073815475811
Epoch: 36 | Iteration number: [1110/4518] 24% | Training loss: 0.687501324565561
Epoch: 36 | Iteration number: [1120/4518] 24% | Training loss: 0.6874958619475364
Epoch: 36 | Iteration number: [1130/4518] 25% | Training loss: 0.6874910371493449
Epoch: 36 | Iteration number: [1140/4518] 25% | Training loss: 0.6874806803569459
Epoch: 36 | Iteration number: [1150/4518] 25% | Training loss: 0.687465552298919
Epoch: 36 | Iteration number: [1160/4518] 25% | Training loss: 0.6874655645982972
Epoch: 36 | Iteration number: [1170/4518] 25% | Training loss: 0.6874709124748524
Epoch: 36 | Iteration number: [1180/4518] 26% | Training loss: 0.6874722697977292
Epoch: 36 | Iteration number: [1190/4518] 26% | Training loss: 0.6874701745870735
Epoch: 36 | Iteration number: [1200/4518] 26% | Training loss: 0.6874660739302635
Epoch: 36 | Iteration number: [1210/4518] 26% | Training loss: 0.6874669855291193
Epoch: 36 | Iteration number: [1220/4518] 27% | Training loss: 0.6874624818563462
Epoch: 36 | Iteration number: [1230/4518] 27% | Training loss: 0.6874488994358031
Epoch: 36 | Iteration number: [1240/4518] 27% | Training loss: 0.6874477269668733
Epoch: 36 | Iteration number: [1250/4518] 27% | Training loss: 0.6874571581840515
Epoch: 36 | Iteration number: [1260/4518] 27% | Training loss: 0.6874484870168898
Epoch: 36 | Iteration number: [1270/4518] 28% | Training loss: 0.6874428755185735
Epoch: 36 | Iteration number: [1280/4518] 28% | Training loss: 0.6874453751835972
Epoch: 36 | Iteration number: [1290/4518] 28% | Training loss: 0.687443687010181
Epoch: 36 | Iteration number: [1300/4518] 28% | Training loss: 0.6874468747010598
Epoch: 36 | Iteration number: [1310/4518] 28% | Training loss: 0.6874382518629991
Epoch: 36 | Iteration number: [1320/4518] 29% | Training loss: 0.6874306990341706
Epoch: 36 | Iteration number: [1330/4518] 29% | Training loss: 0.6874208081933789
Epoch: 36 | Iteration number: [1340/4518] 29% | Training loss: 0.6874099529501217
Epoch: 36 | Iteration number: [1350/4518] 29% | Training loss: 0.6874044388311881
Epoch: 36 | Iteration number: [1360/4518] 30% | Training loss: 0.6873892874840428
Epoch: 36 | Iteration number: [1370/4518] 30% | Training loss: 0.6873731608373406
Epoch: 36 | Iteration number: [1380/4518] 30% | Training loss: 0.6873758234407591
Epoch: 36 | Iteration number: [1390/4518] 30% | Training loss: 0.6873596674675564
Epoch: 36 | Iteration number: [1400/4518] 30% | Training loss: 0.6873599689773151
Epoch: 36 | Iteration number: [1410/4518] 31% | Training loss: 0.6873560027873262
Epoch: 36 | Iteration number: [1420/4518] 31% | Training loss: 0.6873555532643493
Epoch: 36 | Iteration number: [1430/4518] 31% | Training loss: 0.6873538068541281
Epoch: 36 | Iteration number: [1440/4518] 31% | Training loss: 0.6873459226555294
Epoch: 36 | Iteration number: [1450/4518] 32% | Training loss: 0.6873380288584479
Epoch: 36 | Iteration number: [1460/4518] 32% | Training loss: 0.687345985966186
Epoch: 36 | Iteration number: [1470/4518] 32% | Training loss: 0.6873310413490348
Epoch: 36 | Iteration number: [1480/4518] 32% | Training loss: 0.6873291437690322
Epoch: 36 | Iteration number: [1490/4518] 32% | Training loss: 0.6873312932932937
Epoch: 36 | Iteration number: [1500/4518] 33% | Training loss: 0.6873257298469544
Epoch: 36 | Iteration number: [1510/4518] 33% | Training loss: 0.6873129386380809
Epoch: 36 | Iteration number: [1520/4518] 33% | Training loss: 0.6873031578173763
Epoch: 36 | Iteration number: [1530/4518] 33% | Training loss: 0.6873055956722085
Epoch: 36 | Iteration number: [1540/4518] 34% | Training loss: 0.6873000578833864
Epoch: 36 | Iteration number: [1550/4518] 34% | Training loss: 0.6872950994968414
Epoch: 36 | Iteration number: [1560/4518] 34% | Training loss: 0.687289729485145
Epoch: 36 | Iteration number: [1570/4518] 34% | Training loss: 0.6872886109883618
Epoch: 36 | Iteration number: [1580/4518] 34% | Training loss: 0.687287842774693
Epoch: 36 | Iteration number: [1590/4518] 35% | Training loss: 0.6872861973144723
Epoch: 36 | Iteration number: [1600/4518] 35% | Training loss: 0.6872895110398531
Epoch: 36 | Iteration number: [1610/4518] 35% | Training loss: 0.6872853108814785
Epoch: 36 | Iteration number: [1620/4518] 35% | Training loss: 0.6872876482245363
Epoch: 36 | Iteration number: [1630/4518] 36% | Training loss: 0.6872864214554886
Epoch: 36 | Iteration number: [1640/4518] 36% | Training loss: 0.6872836883475141
Epoch: 36 | Iteration number: [1650/4518] 36% | Training loss: 0.687287279511943
Epoch: 36 | Iteration number: [1660/4518] 36% | Training loss: 0.6872911906026932
Epoch: 36 | Iteration number: [1670/4518] 36% | Training loss: 0.6872934834685868
Epoch: 36 | Iteration number: [1680/4518] 37% | Training loss: 0.6872967931486311
Epoch: 36 | Iteration number: [1690/4518] 37% | Training loss: 0.6872903699352897
Epoch: 36 | Iteration number: [1700/4518] 37% | Training loss: 0.6872842449300429
Epoch: 36 | Iteration number: [1710/4518] 37% | Training loss: 0.687280015220419
Epoch: 36 | Iteration number: [1720/4518] 38% | Training loss: 0.6872807410220767
Epoch: 36 | Iteration number: [1730/4518] 38% | Training loss: 0.6872828735092472
Epoch: 36 | Iteration number: [1740/4518] 38% | Training loss: 0.6872794198236246
Epoch: 36 | Iteration number: [1750/4518] 38% | Training loss: 0.6872773953165326
Epoch: 36 | Iteration number: [1760/4518] 38% | Training loss: 0.6872719148343259
Epoch: 36 | Iteration number: [1770/4518] 39% | Training loss: 0.6872674986804272
Epoch: 36 | Iteration number: [1780/4518] 39% | Training loss: 0.687263930748018
Epoch: 36 | Iteration number: [1790/4518] 39% | Training loss: 0.6872729361390268
Epoch: 36 | Iteration number: [1800/4518] 39% | Training loss: 0.6872633312808143
Epoch: 36 | Iteration number: [1810/4518] 40% | Training loss: 0.68726025312645
Epoch: 36 | Iteration number: [1820/4518] 40% | Training loss: 0.687262147468525
Epoch: 36 | Iteration number: [1830/4518] 40% | Training loss: 0.6872606780685362
Epoch: 36 | Iteration number: [1840/4518] 40% | Training loss: 0.6872603769859542
Epoch: 36 | Iteration number: [1850/4518] 40% | Training loss: 0.6872480590923412
Epoch: 36 | Iteration number: [1860/4518] 41% | Training loss: 0.6872539374136155
Epoch: 36 | Iteration number: [1870/4518] 41% | Training loss: 0.6872577670423742
Epoch: 36 | Iteration number: [1880/4518] 41% | Training loss: 0.6872582722217478
Epoch: 36 | Iteration number: [1890/4518] 41% | Training loss: 0.6872565033574584
Epoch: 36 | Iteration number: [1900/4518] 42% | Training loss: 0.68725343898723
Epoch: 36 | Iteration number: [1910/4518] 42% | Training loss: 0.687252346258513
Epoch: 36 | Iteration number: [1920/4518] 42% | Training loss: 0.687250374412785
Epoch: 36 | Iteration number: [1930/4518] 42% | Training loss: 0.6872509334989162
Epoch: 36 | Iteration number: [1940/4518] 42% | Training loss: 0.6872463350750736
Epoch: 36 | Iteration number: [1950/4518] 43% | Training loss: 0.6872392051647871
Epoch: 36 | Iteration number: [1960/4518] 43% | Training loss: 0.6872401301654018
Epoch: 36 | Iteration number: [1970/4518] 43% | Training loss: 0.6872338310413554
Epoch: 36 | Iteration number: [1980/4518] 43% | Training loss: 0.6872389312344368
Epoch: 36 | Iteration number: [1990/4518] 44% | Training loss: 0.6872292620452805
Epoch: 36 | Iteration number: [2000/4518] 44% | Training loss: 0.6872289425432682
Epoch: 36 | Iteration number: [2010/4518] 44% | Training loss: 0.6872233388732322
Epoch: 36 | Iteration number: [2020/4518] 44% | Training loss: 0.6872217217589369
Epoch: 36 | Iteration number: [2030/4518] 44% | Training loss: 0.6872223436538809
Epoch: 36 | Iteration number: [2040/4518] 45% | Training loss: 0.6872230013211568
Epoch: 36 | Iteration number: [2050/4518] 45% | Training loss: 0.6872245294001045
Epoch: 36 | Iteration number: [2060/4518] 45% | Training loss: 0.6872135813085778
Epoch: 36 | Iteration number: [2070/4518] 45% | Training loss: 0.6872070717638817
Epoch: 36 | Iteration number: [2080/4518] 46% | Training loss: 0.6872014350616015
Epoch: 36 | Iteration number: [2090/4518] 46% | Training loss: 0.6871892756252198
Epoch: 36 | Iteration number: [2100/4518] 46% | Training loss: 0.6871777630987621
Epoch: 36 | Iteration number: [2110/4518] 46% | Training loss: 0.6871670866747038
Epoch: 36 | Iteration number: [2120/4518] 46% | Training loss: 0.6871676224301446
Epoch: 36 | Iteration number: [2130/4518] 47% | Training loss: 0.6871664515963183
Epoch: 36 | Iteration number: [2140/4518] 47% | Training loss: 0.6871651822439978
Epoch: 36 | Iteration number: [2150/4518] 47% | Training loss: 0.6871649218437283
Epoch: 36 | Iteration number: [2160/4518] 47% | Training loss: 0.6871621128861551
Epoch: 36 | Iteration number: [2170/4518] 48% | Training loss: 0.6871633299759456
Epoch: 36 | Iteration number: [2180/4518] 48% | Training loss: 0.6871600516892354
Epoch: 36 | Iteration number: [2190/4518] 48% | Training loss: 0.6871566325562185
Epoch: 36 | Iteration number: [2200/4518] 48% | Training loss: 0.6871589746800336
Epoch: 36 | Iteration number: [2210/4518] 48% | Training loss: 0.6871578129707958
Epoch: 36 | Iteration number: [2220/4518] 49% | Training loss: 0.6871584916973973
Epoch: 36 | Iteration number: [2230/4518] 49% | Training loss: 0.6871572313821904
Epoch: 36 | Iteration number: [2240/4518] 49% | Training loss: 0.6871550995590431
Epoch: 36 | Iteration number: [2250/4518] 49% | Training loss: 0.6871531096564399
Epoch: 36 | Iteration number: [2260/4518] 50% | Training loss: 0.6871577876331532
Epoch: 36 | Iteration number: [2270/4518] 50% | Training loss: 0.6871571587045813
Epoch: 36 | Iteration number: [2280/4518] 50% | Training loss: 0.6871581885636898
Epoch: 36 | Iteration number: [2290/4518] 50% | Training loss: 0.6871573533293461
Epoch: 36 | Iteration number: [2300/4518] 50% | Training loss: 0.6871563454296278
Epoch: 36 | Iteration number: [2310/4518] 51% | Training loss: 0.6871573295170095
Epoch: 36 | Iteration number: [2320/4518] 51% | Training loss: 0.687151929684754
Epoch: 36 | Iteration number: [2330/4518] 51% | Training loss: 0.6871511174629686
Epoch: 36 | Iteration number: [2340/4518] 51% | Training loss: 0.6871489104806867
Epoch: 36 | Iteration number: [2350/4518] 52% | Training loss: 0.6871493496539745
Epoch: 36 | Iteration number: [2360/4518] 52% | Training loss: 0.6871498548378379
Epoch: 36 | Iteration number: [2370/4518] 52% | Training loss: 0.6871438338535244
Epoch: 36 | Iteration number: [2380/4518] 52% | Training loss: 0.687149503852139
Epoch: 36 | Iteration number: [2390/4518] 52% | Training loss: 0.6871492629520065
Epoch: 36 | Iteration number: [2400/4518] 53% | Training loss: 0.6871480859816075
Epoch: 36 | Iteration number: [2410/4518] 53% | Training loss: 0.6871446246922758
Epoch: 36 | Iteration number: [2420/4518] 53% | Training loss: 0.6871396961537275
Epoch: 36 | Iteration number: [2430/4518] 53% | Training loss: 0.6871340714119099
Epoch: 36 | Iteration number: [2440/4518] 54% | Training loss: 0.6871318625133546
Epoch: 36 | Iteration number: [2450/4518] 54% | Training loss: 0.6871273450462185
Epoch: 36 | Iteration number: [2460/4518] 54% | Training loss: 0.6871288416589179
Epoch: 36 | Iteration number: [2470/4518] 54% | Training loss: 0.687127067637347
Epoch: 36 | Iteration number: [2480/4518] 54% | Training loss: 0.6871270765700648
Epoch: 36 | Iteration number: [2490/4518] 55% | Training loss: 0.6871270527322608
Epoch: 36 | Iteration number: [2500/4518] 55% | Training loss: 0.6871292845010758
Epoch: 36 | Iteration number: [2510/4518] 55% | Training loss: 0.6871292745924565
Epoch: 36 | Iteration number: [2520/4518] 55% | Training loss: 0.6871290567375364
Epoch: 36 | Iteration number: [2530/4518] 55% | Training loss: 0.6871280476981001
Epoch: 36 | Iteration number: [2540/4518] 56% | Training loss: 0.6871273084418981
Epoch: 36 | Iteration number: [2550/4518] 56% | Training loss: 0.6871216156903435
Epoch: 36 | Iteration number: [2560/4518] 56% | Training loss: 0.6871219275286421
Epoch: 36 | Iteration number: [2570/4518] 56% | Training loss: 0.6871182838534566
Epoch: 36 | Iteration number: [2580/4518] 57% | Training loss: 0.687120340498843
Epoch: 36 | Iteration number: [2590/4518] 57% | Training loss: 0.6871161284594002
Epoch: 36 | Iteration number: [2600/4518] 57% | Training loss: 0.6871165269154769
Epoch: 36 | Iteration number: [2610/4518] 57% | Training loss: 0.6871198864047098
Epoch: 36 | Iteration number: [2620/4518] 57% | Training loss: 0.6871197030516981
Epoch: 36 | Iteration number: [2630/4518] 58% | Training loss: 0.6871174121764223
Epoch: 36 | Iteration number: [2640/4518] 58% | Training loss: 0.6871145685288039
Epoch: 36 | Iteration number: [2650/4518] 58% | Training loss: 0.6871139952596629
Epoch: 36 | Iteration number: [2660/4518] 58% | Training loss: 0.6871130546008734
Epoch: 36 | Iteration number: [2670/4518] 59% | Training loss: 0.6871097010619631
Epoch: 36 | Iteration number: [2680/4518] 59% | Training loss: 0.6871071856858125
Epoch: 36 | Iteration number: [2690/4518] 59% | Training loss: 0.6871016805056746
Epoch: 36 | Iteration number: [2700/4518] 59% | Training loss: 0.6871005364259084
Epoch: 36 | Iteration number: [2710/4518] 59% | Training loss: 0.6870962596247557
Epoch: 36 | Iteration number: [2720/4518] 60% | Training loss: 0.6870971007820438
Epoch: 36 | Iteration number: [2730/4518] 60% | Training loss: 0.6871009014246665
Epoch: 36 | Iteration number: [2740/4518] 60% | Training loss: 0.6870960228199506
Epoch: 36 | Iteration number: [2750/4518] 60% | Training loss: 0.6870946621461348
Epoch: 36 | Iteration number: [2760/4518] 61% | Training loss: 0.6870930202197337
Epoch: 36 | Iteration number: [2770/4518] 61% | Training loss: 0.6870922687251645
Epoch: 36 | Iteration number: [2780/4518] 61% | Training loss: 0.6870912405441133
Epoch: 36 | Iteration number: [2790/4518] 61% | Training loss: 0.6870908808323645
Epoch: 36 | Iteration number: [2800/4518] 61% | Training loss: 0.6870918654544013
Epoch: 36 | Iteration number: [2810/4518] 62% | Training loss: 0.6870918885244593
Epoch: 36 | Iteration number: [2820/4518] 62% | Training loss: 0.6870870546880343
Epoch: 36 | Iteration number: [2830/4518] 62% | Training loss: 0.6870878456127517
Epoch: 36 | Iteration number: [2840/4518] 62% | Training loss: 0.6870853767218724
Epoch: 36 | Iteration number: [2850/4518] 63% | Training loss: 0.6870814650100574
Epoch: 36 | Iteration number: [2860/4518] 63% | Training loss: 0.6870784272472341
Epoch: 36 | Iteration number: [2870/4518] 63% | Training loss: 0.6870802958252538
Epoch: 36 | Iteration number: [2880/4518] 63% | Training loss: 0.6870821778352062
Epoch: 36 | Iteration number: [2890/4518] 63% | Training loss: 0.6870828490150016
Epoch: 36 | Iteration number: [2900/4518] 64% | Training loss: 0.6870832746193327
Epoch: 36 | Iteration number: [2910/4518] 64% | Training loss: 0.6870815389754437
Epoch: 36 | Iteration number: [2920/4518] 64% | Training loss: 0.6870767358231218
Epoch: 36 | Iteration number: [2930/4518] 64% | Training loss: 0.6870748279444594
Epoch: 36 | Iteration number: [2940/4518] 65% | Training loss: 0.6870716188635145
Epoch: 36 | Iteration number: [2950/4518] 65% | Training loss: 0.6870718653121237
Epoch: 36 | Iteration number: [2960/4518] 65% | Training loss: 0.6870745641154212
Epoch: 36 | Iteration number: [2970/4518] 65% | Training loss: 0.6870715587026743
Epoch: 36 | Iteration number: [2980/4518] 65% | Training loss: 0.687069372702765
Epoch: 36 | Iteration number: [2990/4518] 66% | Training loss: 0.68706899253421
Epoch: 36 | Iteration number: [3000/4518] 66% | Training loss: 0.6870682467420896
Epoch: 36 | Iteration number: [3010/4518] 66% | Training loss: 0.6870685672641197
Epoch: 36 | Iteration number: [3020/4518] 66% | Training loss: 0.6870643820983685
Epoch: 36 | Iteration number: [3030/4518] 67% | Training loss: 0.6870642281404816
Epoch: 36 | Iteration number: [3040/4518] 67% | Training loss: 0.6870617804754722
Epoch: 36 | Iteration number: [3050/4518] 67% | Training loss: 0.687058308847615
Epoch: 36 | Iteration number: [3060/4518] 67% | Training loss: 0.6870556510157055
Epoch: 36 | Iteration number: [3070/4518] 67% | Training loss: 0.6870539497863198
Epoch: 36 | Iteration number: [3080/4518] 68% | Training loss: 0.6870491251542971
Epoch: 36 | Iteration number: [3090/4518] 68% | Training loss: 0.6870508053156165
Epoch: 36 | Iteration number: [3100/4518] 68% | Training loss: 0.6870543437811636
Epoch: 36 | Iteration number: [3110/4518] 68% | Training loss: 0.6870588786157381
Epoch: 36 | Iteration number: [3120/4518] 69% | Training loss: 0.6870613626371591
Epoch: 36 | Iteration number: [3130/4518] 69% | Training loss: 0.6870631332785938
Epoch: 36 | Iteration number: [3140/4518] 69% | Training loss: 0.6870596630178439
Epoch: 36 | Iteration number: [3150/4518] 69% | Training loss: 0.6870587689157516
Epoch: 36 | Iteration number: [3160/4518] 69% | Training loss: 0.6870583664955973
Epoch: 36 | Iteration number: [3170/4518] 70% | Training loss: 0.6870599012645637
Epoch: 36 | Iteration number: [3180/4518] 70% | Training loss: 0.687057696404697
Epoch: 36 | Iteration number: [3190/4518] 70% | Training loss: 0.6870545036553589
Epoch: 36 | Iteration number: [3200/4518] 70% | Training loss: 0.687054231557995
Epoch: 36 | Iteration number: [3210/4518] 71% | Training loss: 0.6870498814686807
Epoch: 36 | Iteration number: [3220/4518] 71% | Training loss: 0.6870493440709499
Epoch: 36 | Iteration number: [3230/4518] 71% | Training loss: 0.6870489490475079
Epoch: 36 | Iteration number: [3240/4518] 71% | Training loss: 0.6870471119512747
Epoch: 36 | Iteration number: [3250/4518] 71% | Training loss: 0.6870492345736577
Epoch: 36 | Iteration number: [3260/4518] 72% | Training loss: 0.6870463010723605
Epoch: 36 | Iteration number: [3270/4518] 72% | Training loss: 0.6870467700724937
Epoch: 36 | Iteration number: [3280/4518] 72% | Training loss: 0.6870424947542388
Epoch: 36 | Iteration number: [3290/4518] 72% | Training loss: 0.6870397629346529
Epoch: 36 | Iteration number: [3300/4518] 73% | Training loss: 0.6870386197892102
Epoch: 36 | Iteration number: [3310/4518] 73% | Training loss: 0.687039122066469
Epoch: 36 | Iteration number: [3320/4518] 73% | Training loss: 0.6870342344404703
Epoch: 36 | Iteration number: [3330/4518] 73% | Training loss: 0.687032412193917
Epoch: 36 | Iteration number: [3340/4518] 73% | Training loss: 0.6870318979203344
Epoch: 36 | Iteration number: [3350/4518] 74% | Training loss: 0.6870289407203447
Epoch: 36 | Iteration number: [3360/4518] 74% | Training loss: 0.6870310913239207
Epoch: 36 | Iteration number: [3370/4518] 74% | Training loss: 0.6870285437616467
Epoch: 36 | Iteration number: [3380/4518] 74% | Training loss: 0.6870279070364653
Epoch: 36 | Iteration number: [3390/4518] 75% | Training loss: 0.6870272832985824
Epoch: 36 | Iteration number: [3400/4518] 75% | Training loss: 0.6870246047482771
Epoch: 36 | Iteration number: [3410/4518] 75% | Training loss: 0.6870195153696446
Epoch: 36 | Iteration number: [3420/4518] 75% | Training loss: 0.687020588618273
Epoch: 36 | Iteration number: [3430/4518] 75% | Training loss: 0.687019994794106
Epoch: 36 | Iteration number: [3440/4518] 76% | Training loss: 0.6870186289729074
Epoch: 36 | Iteration number: [3450/4518] 76% | Training loss: 0.6870163362095322
Epoch: 36 | Iteration number: [3460/4518] 76% | Training loss: 0.6870158257684267
Epoch: 36 | Iteration number: [3470/4518] 76% | Training loss: 0.6870147166403295
Epoch: 36 | Iteration number: [3480/4518] 77% | Training loss: 0.6870113494067357
Epoch: 36 | Iteration number: [3490/4518] 77% | Training loss: 0.68701193870651
Epoch: 36 | Iteration number: [3500/4518] 77% | Training loss: 0.6870130670922143
Epoch: 36 | Iteration number: [3510/4518] 77% | Training loss: 0.6870152491110343
Epoch: 36 | Iteration number: [3520/4518] 77% | Training loss: 0.6870155472816392
Epoch: 36 | Iteration number: [3530/4518] 78% | Training loss: 0.687016851098274
Epoch: 36 | Iteration number: [3540/4518] 78% | Training loss: 0.6870160960208225
Epoch: 36 | Iteration number: [3550/4518] 78% | Training loss: 0.6870136020217144
Epoch: 36 | Iteration number: [3560/4518] 78% | Training loss: 0.687011647542541
Epoch: 36 | Iteration number: [3570/4518] 79% | Training loss: 0.6870099179217127
Epoch: 36 | Iteration number: [3580/4518] 79% | Training loss: 0.6870078797613443
Epoch: 36 | Iteration number: [3590/4518] 79% | Training loss: 0.68701196103707
Epoch: 36 | Iteration number: [3600/4518] 79% | Training loss: 0.6870108059876495
Epoch: 36 | Iteration number: [3610/4518] 79% | Training loss: 0.6870097657980351
Epoch: 36 | Iteration number: [3620/4518] 80% | Training loss: 0.6870123773648594
Epoch: 36 | Iteration number: [3630/4518] 80% | Training loss: 0.6870153210872461
Epoch: 36 | Iteration number: [3640/4518] 80% | Training loss: 0.6870162865454024
Epoch: 36 | Iteration number: [3650/4518] 80% | Training loss: 0.6870107881010395
Epoch: 36 | Iteration number: [3660/4518] 81% | Training loss: 0.6870119421208492
Epoch: 36 | Iteration number: [3670/4518] 81% | Training loss: 0.6870132767536985
Epoch: 36 | Iteration number: [3680/4518] 81% | Training loss: 0.6870097423539213
Epoch: 36 | Iteration number: [3690/4518] 81% | Training loss: 0.6870094947214049
Epoch: 36 | Iteration number: [3700/4518] 81% | Training loss: 0.6870091312318235
Epoch: 36 | Iteration number: [3710/4518] 82% | Training loss: 0.687008697581741
Epoch: 36 | Iteration number: [3720/4518] 82% | Training loss: 0.6870071085390225
Epoch: 36 | Iteration number: [3730/4518] 82% | Training loss: 0.6870099256888791
Epoch: 36 | Iteration number: [3740/4518] 82% | Training loss: 0.687010379765123
Epoch: 36 | Iteration number: [3750/4518] 83% | Training loss: 0.6870111594994863
Epoch: 36 | Iteration number: [3760/4518] 83% | Training loss: 0.6870085669007707
Epoch: 36 | Iteration number: [3770/4518] 83% | Training loss: 0.687010493819214
Epoch: 36 | Iteration number: [3780/4518] 83% | Training loss: 0.6870106056096061
Epoch: 36 | Iteration number: [3790/4518] 83% | Training loss: 0.6870108884997607
Epoch: 36 | Iteration number: [3800/4518] 84% | Training loss: 0.6870100074535922
Epoch: 36 | Iteration number: [3810/4518] 84% | Training loss: 0.6870102438870378
Epoch: 36 | Iteration number: [3820/4518] 84% | Training loss: 0.687009811042491
Epoch: 36 | Iteration number: [3830/4518] 84% | Training loss: 0.6870067166752977
Epoch: 36 | Iteration number: [3840/4518] 84% | Training loss: 0.687006634954984
Epoch: 36 | Iteration number: [3850/4518] 85% | Training loss: 0.6870099386456725
Epoch: 36 | Iteration number: [3860/4518] 85% | Training loss: 0.6870107097946918
Epoch: 36 | Iteration number: [3870/4518] 85% | Training loss: 0.6870103475043324
Epoch: 36 | Iteration number: [3880/4518] 85% | Training loss: 0.6870125634154094
Epoch: 36 | Iteration number: [3890/4518] 86% | Training loss: 0.6870113491705573
Epoch: 36 | Iteration number: [3900/4518] 86% | Training loss: 0.6870106561672993
Epoch: 36 | Iteration number: [3910/4518] 86% | Training loss: 0.6870085554049753
Epoch: 36 | Iteration number: [3920/4518] 86% | Training loss: 0.6870065106269048
Epoch: 36 | Iteration number: [3930/4518] 86% | Training loss: 0.6870016687092284
Epoch: 36 | Iteration number: [3940/4518] 87% | Training loss: 0.6870017879051605
Epoch: 36 | Iteration number: [3950/4518] 87% | Training loss: 0.6869973053207881
Epoch: 36 | Iteration number: [3960/4518] 87% | Training loss: 0.6869972019032998
Epoch: 36 | Iteration number: [3970/4518] 87% | Training loss: 0.6869966547795447
Epoch: 36 | Iteration number: [3980/4518] 88% | Training loss: 0.6869965598661096
Epoch: 36 | Iteration number: [3990/4518] 88% | Training loss: 0.6869955077505948
Epoch: 36 | Iteration number: [4000/4518] 88% | Training loss: 0.6869993396401405
Epoch: 36 | Iteration number: [4010/4518] 88% | Training loss: 0.6870008271085354
Epoch: 36 | Iteration number: [4020/4518] 88% | Training loss: 0.687002291845445
Epoch: 36 | Iteration number: [4030/4518] 89% | Training loss: 0.687002982794499
Epoch: 36 | Iteration number: [4040/4518] 89% | Training loss: 0.6870001610700447
Epoch: 36 | Iteration number: [4050/4518] 89% | Training loss: 0.6869991150461597
Epoch: 36 | Iteration number: [4060/4518] 89% | Training loss: 0.6869956517454439
Epoch: 36 | Iteration number: [4070/4518] 90% | Training loss: 0.6869960772610414
Epoch: 36 | Iteration number: [4080/4518] 90% | Training loss: 0.6869925430154099
Epoch: 36 | Iteration number: [4090/4518] 90% | Training loss: 0.6869905297359802
Epoch: 36 | Iteration number: [4100/4518] 90% | Training loss: 0.6869879892831895
Epoch: 36 | Iteration number: [4110/4518] 90% | Training loss: 0.6869886897631226
Epoch: 36 | Iteration number: [4120/4518] 91% | Training loss: 0.6869880982539028
Epoch: 36 | Iteration number: [4130/4518] 91% | Training loss: 0.6869852447047938
Epoch: 36 | Iteration number: [4140/4518] 91% | Training loss: 0.68698789688988
Epoch: 36 | Iteration number: [4150/4518] 91% | Training loss: 0.6869877171660044
Epoch: 36 | Iteration number: [4160/4518] 92% | Training loss: 0.6869854986237792
Epoch: 36 | Iteration number: [4170/4518] 92% | Training loss: 0.6869849229745156
Epoch: 36 | Iteration number: [4180/4518] 92% | Training loss: 0.6869834974907232
Epoch: 36 | Iteration number: [4190/4518] 92% | Training loss: 0.686983086727115
Epoch: 36 | Iteration number: [4200/4518] 92% | Training loss: 0.6869842034436408
Epoch: 36 | Iteration number: [4210/4518] 93% | Training loss: 0.6869830594634784
Epoch: 36 | Iteration number: [4220/4518] 93% | Training loss: 0.6869836235922094
Epoch: 36 | Iteration number: [4230/4518] 93% | Training loss: 0.6869872249750945
Epoch: 36 | Iteration number: [4240/4518] 93% | Training loss: 0.6869874782016817
Epoch: 36 | Iteration number: [4250/4518] 94% | Training loss: 0.6869854107604307
Epoch: 36 | Iteration number: [4260/4518] 94% | Training loss: 0.6869877984965911
Epoch: 36 | Iteration number: [4270/4518] 94% | Training loss: 0.6869878800188909
Epoch: 36 | Iteration number: [4280/4518] 94% | Training loss: 0.686990319387378
Epoch: 36 | Iteration number: [4290/4518] 94% | Training loss: 0.6869884556823677
Epoch: 36 | Iteration number: [4300/4518] 95% | Training loss: 0.6869869425269061
Epoch: 36 | Iteration number: [4310/4518] 95% | Training loss: 0.6869873073289123
Epoch: 36 | Iteration number: [4320/4518] 95% | Training loss: 0.686983478386645
Epoch: 36 | Iteration number: [4330/4518] 95% | Training loss: 0.6869840390963037
Epoch: 36 | Iteration number: [4340/4518] 96% | Training loss: 0.6869821357012894
Epoch: 36 | Iteration number: [4350/4518] 96% | Training loss: 0.6869820043684423
Epoch: 36 | Iteration number: [4360/4518] 96% | Training loss: 0.6869777150793906
Epoch: 36 | Iteration number: [4370/4518] 96% | Training loss: 0.6869787192590177
Epoch: 36 | Iteration number: [4380/4518] 96% | Training loss: 0.6869810030204521
Epoch: 36 | Iteration number: [4390/4518] 97% | Training loss: 0.6869816365709066
Epoch: 36 | Iteration number: [4400/4518] 97% | Training loss: 0.6869803701883013
Epoch: 36 | Iteration number: [4410/4518] 97% | Training loss: 0.6869795821691587
Epoch: 36 | Iteration number: [4420/4518] 97% | Training loss: 0.6869787766518096
Epoch: 36 | Iteration number: [4430/4518] 98% | Training loss: 0.686981841497981
Epoch: 36 | Iteration number: [4440/4518] 98% | Training loss: 0.6869788229196995
Epoch: 36 | Iteration number: [4450/4518] 98% | Training loss: 0.6869766734021433
Epoch: 36 | Iteration number: [4460/4518] 98% | Training loss: 0.6869758833817837
Epoch: 36 | Iteration number: [4470/4518] 98% | Training loss: 0.6869765548631382
Epoch: 36 | Iteration number: [4480/4518] 99% | Training loss: 0.686977357350822
Epoch: 36 | Iteration number: [4490/4518] 99% | Training loss: 0.6869782071071107
Epoch: 36 | Iteration number: [4500/4518] 99% | Training loss: 0.6869813484880659
Epoch: 36 | Iteration number: [4510/4518] 99% | Training loss: 0.6869812551596741

 End of epoch: 36 | Train Loss: 0.6868319890308084 | Training Time: 632 

 End of epoch: 36 | Eval Loss: 0.6898843329779956 | Evaluating Time: 17 
Epoch: 37 | Iteration number: [10/4518] 0% | Training loss: 0.7552087545394898
Epoch: 37 | Iteration number: [20/4518] 0% | Training loss: 0.7215188354253769
Epoch: 37 | Iteration number: [30/4518] 0% | Training loss: 0.7097867429256439
Epoch: 37 | Iteration number: [40/4518] 0% | Training loss: 0.7040392339229584
Epoch: 37 | Iteration number: [50/4518] 1% | Training loss: 0.7007046067714691
Epoch: 37 | Iteration number: [60/4518] 1% | Training loss: 0.6983949740727743
Epoch: 37 | Iteration number: [70/4518] 1% | Training loss: 0.6967228412628174
Epoch: 37 | Iteration number: [80/4518] 1% | Training loss: 0.6954503402113914
Epoch: 37 | Iteration number: [90/4518] 1% | Training loss: 0.6944858345720503
Epoch: 37 | Iteration number: [100/4518] 2% | Training loss: 0.6937758004665375
Epoch: 37 | Iteration number: [110/4518] 2% | Training loss: 0.6932004993612116
Epoch: 37 | Iteration number: [120/4518] 2% | Training loss: 0.6927711213628451
Epoch: 37 | Iteration number: [130/4518] 2% | Training loss: 0.6923878972346966
Epoch: 37 | Iteration number: [140/4518] 3% | Training loss: 0.6920655195202147
Epoch: 37 | Iteration number: [150/4518] 3% | Training loss: 0.6916108254591624
Epoch: 37 | Iteration number: [160/4518] 3% | Training loss: 0.6913233198225498
Epoch: 37 | Iteration number: [170/4518] 3% | Training loss: 0.6910065889358521
Epoch: 37 | Iteration number: [180/4518] 3% | Training loss: 0.6907855775621202
Epoch: 37 | Iteration number: [190/4518] 4% | Training loss: 0.690590258648521
Epoch: 37 | Iteration number: [200/4518] 4% | Training loss: 0.6903955301642418
Epoch: 37 | Iteration number: [210/4518] 4% | Training loss: 0.6902411531834375
Epoch: 37 | Iteration number: [220/4518] 4% | Training loss: 0.6900649198076941
Epoch: 37 | Iteration number: [230/4518] 5% | Training loss: 0.6899586182573567
Epoch: 37 | Iteration number: [240/4518] 5% | Training loss: 0.6898014043768247
Epoch: 37 | Iteration number: [250/4518] 5% | Training loss: 0.6896440825462341
Epoch: 37 | Iteration number: [260/4518] 5% | Training loss: 0.6895344819013889
Epoch: 37 | Iteration number: [270/4518] 5% | Training loss: 0.689456491779398
Epoch: 37 | Iteration number: [280/4518] 6% | Training loss: 0.6893635873283659
Epoch: 37 | Iteration number: [290/4518] 6% | Training loss: 0.6892349331543364
Epoch: 37 | Iteration number: [300/4518] 6% | Training loss: 0.6891343295574188
Epoch: 37 | Iteration number: [310/4518] 6% | Training loss: 0.689022990580528
Epoch: 37 | Iteration number: [320/4518] 7% | Training loss: 0.6889624958857894
Epoch: 37 | Iteration number: [330/4518] 7% | Training loss: 0.6889022178722151
Epoch: 37 | Iteration number: [340/4518] 7% | Training loss: 0.6888250549049938
Epoch: 37 | Iteration number: [350/4518] 7% | Training loss: 0.6887918773719243
Epoch: 37 | Iteration number: [360/4518] 7% | Training loss: 0.6887285540501277
Epoch: 37 | Iteration number: [370/4518] 8% | Training loss: 0.6886770950781332
Epoch: 37 | Iteration number: [380/4518] 8% | Training loss: 0.6886267373436376
Epoch: 37 | Iteration number: [390/4518] 8% | Training loss: 0.6886037805141547
Epoch: 37 | Iteration number: [400/4518] 8% | Training loss: 0.6885535821318627
Epoch: 37 | Iteration number: [410/4518] 9% | Training loss: 0.6885209343782286
Epoch: 37 | Iteration number: [420/4518] 9% | Training loss: 0.6884821314187277
Epoch: 37 | Iteration number: [430/4518] 9% | Training loss: 0.6884275164715079
Epoch: 37 | Iteration number: [440/4518] 9% | Training loss: 0.6884099360216748
Epoch: 37 | Iteration number: [450/4518] 9% | Training loss: 0.688366692463557
Epoch: 37 | Iteration number: [460/4518] 10% | Training loss: 0.6883160725883816
Epoch: 37 | Iteration number: [470/4518] 10% | Training loss: 0.688268843610236
Epoch: 37 | Iteration number: [480/4518] 10% | Training loss: 0.688226027538379
Epoch: 37 | Iteration number: [490/4518] 10% | Training loss: 0.6882059268805445
Epoch: 37 | Iteration number: [500/4518] 11% | Training loss: 0.6881601349115372
Epoch: 37 | Iteration number: [510/4518] 11% | Training loss: 0.6881540511168686
Epoch: 37 | Iteration number: [520/4518] 11% | Training loss: 0.6881119691408597
Epoch: 37 | Iteration number: [530/4518] 11% | Training loss: 0.6881179797199537
Epoch: 37 | Iteration number: [540/4518] 11% | Training loss: 0.6880824776711287
Epoch: 37 | Iteration number: [550/4518] 12% | Training loss: 0.6880693171241067
Epoch: 37 | Iteration number: [560/4518] 12% | Training loss: 0.6880469473344939
Epoch: 37 | Iteration number: [570/4518] 12% | Training loss: 0.6880182079055853
Epoch: 37 | Iteration number: [580/4518] 12% | Training loss: 0.6879694427909522
Epoch: 37 | Iteration number: [590/4518] 13% | Training loss: 0.6879665800070358
Epoch: 37 | Iteration number: [600/4518] 13% | Training loss: 0.6879470889767011
Epoch: 37 | Iteration number: [610/4518] 13% | Training loss: 0.6879408963391038
Epoch: 37 | Iteration number: [620/4518] 13% | Training loss: 0.6879257047368634
Epoch: 37 | Iteration number: [630/4518] 13% | Training loss: 0.6879218044735137
Epoch: 37 | Iteration number: [640/4518] 14% | Training loss: 0.6879054483957588
Epoch: 37 | Iteration number: [650/4518] 14% | Training loss: 0.6878854177548335
Epoch: 37 | Iteration number: [660/4518] 14% | Training loss: 0.6878714212865541
Epoch: 37 | Iteration number: [670/4518] 14% | Training loss: 0.6878561381083815
Epoch: 37 | Iteration number: [680/4518] 15% | Training loss: 0.6878150028340957
Epoch: 37 | Iteration number: [690/4518] 15% | Training loss: 0.6878035258555758
Epoch: 37 | Iteration number: [700/4518] 15% | Training loss: 0.6877744839021138
Epoch: 37 | Iteration number: [710/4518] 15% | Training loss: 0.6877651182698532
Epoch: 37 | Iteration number: [720/4518] 15% | Training loss: 0.6877524324589306
Epoch: 37 | Iteration number: [730/4518] 16% | Training loss: 0.687744232808074
Epoch: 37 | Iteration number: [740/4518] 16% | Training loss: 0.6877251221521481
Epoch: 37 | Iteration number: [750/4518] 16% | Training loss: 0.6877053308486939
Epoch: 37 | Iteration number: [760/4518] 16% | Training loss: 0.6877260232442304
Epoch: 37 | Iteration number: [770/4518] 17% | Training loss: 0.6877164058096997
Epoch: 37 | Iteration number: [780/4518] 17% | Training loss: 0.68771237830321
Epoch: 37 | Iteration number: [790/4518] 17% | Training loss: 0.6877145340171041
Epoch: 37 | Iteration number: [800/4518] 17% | Training loss: 0.6876995573192834
Epoch: 37 | Iteration number: [810/4518] 17% | Training loss: 0.6876783200988064
Epoch: 37 | Iteration number: [820/4518] 18% | Training loss: 0.6876645754750182
Epoch: 37 | Iteration number: [830/4518] 18% | Training loss: 0.6876447788922183
Epoch: 37 | Iteration number: [840/4518] 18% | Training loss: 0.6876359897710028
Epoch: 37 | Iteration number: [850/4518] 18% | Training loss: 0.6876333076813642
Epoch: 37 | Iteration number: [860/4518] 19% | Training loss: 0.6876272632632144
Epoch: 37 | Iteration number: [870/4518] 19% | Training loss: 0.6876117347985848
Epoch: 37 | Iteration number: [880/4518] 19% | Training loss: 0.687602029334415
Epoch: 37 | Iteration number: [890/4518] 19% | Training loss: 0.6876055866814731
Epoch: 37 | Iteration number: [900/4518] 19% | Training loss: 0.6875974141889148
Epoch: 37 | Iteration number: [910/4518] 20% | Training loss: 0.6875763640953945
Epoch: 37 | Iteration number: [920/4518] 20% | Training loss: 0.6875491124132406
Epoch: 37 | Iteration number: [930/4518] 20% | Training loss: 0.6875460824658793
Epoch: 37 | Iteration number: [940/4518] 20% | Training loss: 0.687528359509529
Epoch: 37 | Iteration number: [950/4518] 21% | Training loss: 0.687517676478938
Epoch: 37 | Iteration number: [960/4518] 21% | Training loss: 0.6875033374254902
Epoch: 37 | Iteration number: [970/4518] 21% | Training loss: 0.6875001397329508
Epoch: 37 | Iteration number: [980/4518] 21% | Training loss: 0.6875050054520977
Epoch: 37 | Iteration number: [990/4518] 21% | Training loss: 0.6874942706690894
Epoch: 37 | Iteration number: [1000/4518] 22% | Training loss: 0.6874876075387001
Epoch: 37 | Iteration number: [1010/4518] 22% | Training loss: 0.6874841771503486
Epoch: 37 | Iteration number: [1020/4518] 22% | Training loss: 0.6874730182629005
Epoch: 37 | Iteration number: [1030/4518] 22% | Training loss: 0.6874618934774862
Epoch: 37 | Iteration number: [1040/4518] 23% | Training loss: 0.6874489558430819
Epoch: 37 | Iteration number: [1050/4518] 23% | Training loss: 0.687455396879287
Epoch: 37 | Iteration number: [1060/4518] 23% | Training loss: 0.6874559139867998
Epoch: 37 | Iteration number: [1070/4518] 23% | Training loss: 0.6874518992187821
Epoch: 37 | Iteration number: [1080/4518] 23% | Training loss: 0.6874485275259724
Epoch: 37 | Iteration number: [1090/4518] 24% | Training loss: 0.6874366869620226
Epoch: 37 | Iteration number: [1100/4518] 24% | Training loss: 0.6874206850203601
Epoch: 37 | Iteration number: [1110/4518] 24% | Training loss: 0.6874111692110697
Epoch: 37 | Iteration number: [1120/4518] 24% | Training loss: 0.6874028057924338
Epoch: 37 | Iteration number: [1130/4518] 25% | Training loss: 0.687395429716701
Epoch: 37 | Iteration number: [1140/4518] 25% | Training loss: 0.6873729244658822
Epoch: 37 | Iteration number: [1150/4518] 25% | Training loss: 0.6873657879103785
Epoch: 37 | Iteration number: [1160/4518] 25% | Training loss: 0.6873642011963088
Epoch: 37 | Iteration number: [1170/4518] 25% | Training loss: 0.6873666333846556
Epoch: 37 | Iteration number: [1180/4518] 26% | Training loss: 0.6873559673458843
Epoch: 37 | Iteration number: [1190/4518] 26% | Training loss: 0.6873573687397131
Epoch: 37 | Iteration number: [1200/4518] 26% | Training loss: 0.6873451848328114
Epoch: 37 | Iteration number: [1210/4518] 26% | Training loss: 0.6873406993948724
Epoch: 37 | Iteration number: [1220/4518] 27% | Training loss: 0.6873470487653232
Epoch: 37 | Iteration number: [1230/4518] 27% | Training loss: 0.6873409883762763
Epoch: 37 | Iteration number: [1240/4518] 27% | Training loss: 0.6873298642616118
Epoch: 37 | Iteration number: [1250/4518] 27% | Training loss: 0.6873198134899139
Epoch: 37 | Iteration number: [1260/4518] 27% | Training loss: 0.6873121734176363
Epoch: 37 | Iteration number: [1270/4518] 28% | Training loss: 0.6873160929661097
Epoch: 37 | Iteration number: [1280/4518] 28% | Training loss: 0.6873128360603005
Epoch: 37 | Iteration number: [1290/4518] 28% | Training loss: 0.6873148271279742
Epoch: 37 | Iteration number: [1300/4518] 28% | Training loss: 0.6873207629643954
Epoch: 37 | Iteration number: [1310/4518] 28% | Training loss: 0.687311388700063
Epoch: 37 | Iteration number: [1320/4518] 29% | Training loss: 0.6873088138573098
Epoch: 37 | Iteration number: [1330/4518] 29% | Training loss: 0.6872985253208562
Epoch: 37 | Iteration number: [1340/4518] 29% | Training loss: 0.6872898470554779
Epoch: 37 | Iteration number: [1350/4518] 29% | Training loss: 0.6872823279875296
Epoch: 37 | Iteration number: [1360/4518] 30% | Training loss: 0.6872766595991219
Epoch: 37 | Iteration number: [1370/4518] 30% | Training loss: 0.6872762661345684
Epoch: 37 | Iteration number: [1380/4518] 30% | Training loss: 0.6872675942769949
Epoch: 37 | Iteration number: [1390/4518] 30% | Training loss: 0.6872713496359132
Epoch: 37 | Iteration number: [1400/4518] 30% | Training loss: 0.687267004762377
Epoch: 37 | Iteration number: [1410/4518] 31% | Training loss: 0.6872604988990946
Epoch: 37 | Iteration number: [1420/4518] 31% | Training loss: 0.6872538773106857
Epoch: 37 | Iteration number: [1430/4518] 31% | Training loss: 0.6872517426530798
Epoch: 37 | Iteration number: [1440/4518] 31% | Training loss: 0.6872465045087868
Epoch: 37 | Iteration number: [1450/4518] 32% | Training loss: 0.6872452086004718
Epoch: 37 | Iteration number: [1460/4518] 32% | Training loss: 0.6872372076527713
Epoch: 37 | Iteration number: [1470/4518] 32% | Training loss: 0.687232049873897
Epoch: 37 | Iteration number: [1480/4518] 32% | Training loss: 0.6872294724390313
Epoch: 37 | Iteration number: [1490/4518] 32% | Training loss: 0.6872320300380655
Epoch: 37 | Iteration number: [1500/4518] 33% | Training loss: 0.6872321829001109
Epoch: 37 | Iteration number: [1510/4518] 33% | Training loss: 0.687233570395716
Epoch: 37 | Iteration number: [1520/4518] 33% | Training loss: 0.6872323462445485
Epoch: 37 | Iteration number: [1530/4518] 33% | Training loss: 0.6872315136825338
Epoch: 37 | Iteration number: [1540/4518] 34% | Training loss: 0.6872318089008331
Epoch: 37 | Iteration number: [1550/4518] 34% | Training loss: 0.6872339740107136
Epoch: 37 | Iteration number: [1560/4518] 34% | Training loss: 0.6872286641826997
Epoch: 37 | Iteration number: [1570/4518] 34% | Training loss: 0.6872290387275113
Epoch: 37 | Iteration number: [1580/4518] 34% | Training loss: 0.6872290925889075
Epoch: 37 | Iteration number: [1590/4518] 35% | Training loss: 0.6872261776864154
Epoch: 37 | Iteration number: [1600/4518] 35% | Training loss: 0.6872225971147418
Epoch: 37 | Iteration number: [1610/4518] 35% | Training loss: 0.6872260021126788
Epoch: 37 | Iteration number: [1620/4518] 35% | Training loss: 0.6872258201793388
Epoch: 37 | Iteration number: [1630/4518] 36% | Training loss: 0.6872228419853865
Epoch: 37 | Iteration number: [1640/4518] 36% | Training loss: 0.6872283954082465
Epoch: 37 | Iteration number: [1650/4518] 36% | Training loss: 0.687217001951102
Epoch: 37 | Iteration number: [1660/4518] 36% | Training loss: 0.6872053758207574
Epoch: 37 | Iteration number: [1670/4518] 36% | Training loss: 0.6872094081547446
Epoch: 37 | Iteration number: [1680/4518] 37% | Training loss: 0.6872156639893849
Epoch: 37 | Iteration number: [1690/4518] 37% | Training loss: 0.6872158008566975
Epoch: 37 | Iteration number: [1700/4518] 37% | Training loss: 0.6872150380120557
Epoch: 37 | Iteration number: [1710/4518] 37% | Training loss: 0.6872137649017468
Epoch: 37 | Iteration number: [1720/4518] 38% | Training loss: 0.687213902036811
Epoch: 37 | Iteration number: [1730/4518] 38% | Training loss: 0.6872095102864194
Epoch: 37 | Iteration number: [1740/4518] 38% | Training loss: 0.6872074175155026
Epoch: 37 | Iteration number: [1750/4518] 38% | Training loss: 0.6872091329438346
Epoch: 37 | Iteration number: [1760/4518] 38% | Training loss: 0.6872035799040036
Epoch: 37 | Iteration number: [1770/4518] 39% | Training loss: 0.6871973791364896
Epoch: 37 | Iteration number: [1780/4518] 39% | Training loss: 0.6871999745288592
Epoch: 37 | Iteration number: [1790/4518] 39% | Training loss: 0.6871944549696406
Epoch: 37 | Iteration number: [1800/4518] 39% | Training loss: 0.6871922468476825
Epoch: 37 | Iteration number: [1810/4518] 40% | Training loss: 0.6871934109300539
Epoch: 37 | Iteration number: [1820/4518] 40% | Training loss: 0.6871884826447937
Epoch: 37 | Iteration number: [1830/4518] 40% | Training loss: 0.6871782513915515
Epoch: 37 | Iteration number: [1840/4518] 40% | Training loss: 0.687176809783863
Epoch: 37 | Iteration number: [1850/4518] 40% | Training loss: 0.6871799117810017
Epoch: 37 | Iteration number: [1860/4518] 41% | Training loss: 0.6871736813937465
Epoch: 37 | Iteration number: [1870/4518] 41% | Training loss: 0.687178156337636
Epoch: 37 | Iteration number: [1880/4518] 41% | Training loss: 0.6871683176527632
Epoch: 37 | Iteration number: [1890/4518] 41% | Training loss: 0.6871633516102241
Epoch: 37 | Iteration number: [1900/4518] 42% | Training loss: 0.6871606323279833
Epoch: 37 | Iteration number: [1910/4518] 42% | Training loss: 0.6871590393375976
Epoch: 37 | Iteration number: [1920/4518] 42% | Training loss: 0.6871460763116678
Epoch: 37 | Iteration number: [1930/4518] 42% | Training loss: 0.6871455286759787
Epoch: 37 | Iteration number: [1940/4518] 42% | Training loss: 0.6871483563147869
Epoch: 37 | Iteration number: [1950/4518] 43% | Training loss: 0.6871418995734973
Epoch: 37 | Iteration number: [1960/4518] 43% | Training loss: 0.6871403128516917
Epoch: 37 | Iteration number: [1970/4518] 43% | Training loss: 0.6871424603583244
Epoch: 37 | Iteration number: [1980/4518] 43% | Training loss: 0.6871380615716028
Epoch: 37 | Iteration number: [1990/4518] 44% | Training loss: 0.6871395201539274
Epoch: 37 | Iteration number: [2000/4518] 44% | Training loss: 0.6871381770074367
Epoch: 37 | Iteration number: [2010/4518] 44% | Training loss: 0.6871341274745428
Epoch: 37 | Iteration number: [2020/4518] 44% | Training loss: 0.6871313369215125
Epoch: 37 | Iteration number: [2030/4518] 44% | Training loss: 0.6871248086097792
Epoch: 37 | Iteration number: [2040/4518] 45% | Training loss: 0.6871227981705291
Epoch: 37 | Iteration number: [2050/4518] 45% | Training loss: 0.687122011824352
Epoch: 37 | Iteration number: [2060/4518] 45% | Training loss: 0.6871180308096617
Epoch: 37 | Iteration number: [2070/4518] 45% | Training loss: 0.6871157664319744
Epoch: 37 | Iteration number: [2080/4518] 46% | Training loss: 0.6871138019630543
Epoch: 37 | Iteration number: [2090/4518] 46% | Training loss: 0.6871087100517237
Epoch: 37 | Iteration number: [2100/4518] 46% | Training loss: 0.6871044002828144
Epoch: 37 | Iteration number: [2110/4518] 46% | Training loss: 0.6871093499999475
Epoch: 37 | Iteration number: [2120/4518] 46% | Training loss: 0.6871070214037626
Epoch: 37 | Iteration number: [2130/4518] 47% | Training loss: 0.6871061167526693
Epoch: 37 | Iteration number: [2140/4518] 47% | Training loss: 0.6871067689400967
Epoch: 37 | Iteration number: [2150/4518] 47% | Training loss: 0.687102782449057
Epoch: 37 | Iteration number: [2160/4518] 47% | Training loss: 0.6871019056549779
Epoch: 37 | Iteration number: [2170/4518] 48% | Training loss: 0.6871019683675282
Epoch: 37 | Iteration number: [2180/4518] 48% | Training loss: 0.6871015255057483
Epoch: 37 | Iteration number: [2190/4518] 48% | Training loss: 0.6870995317692081
Epoch: 37 | Iteration number: [2200/4518] 48% | Training loss: 0.6870978841998361
Epoch: 37 | Iteration number: [2210/4518] 48% | Training loss: 0.687099243208294
Epoch: 37 | Iteration number: [2220/4518] 49% | Training loss: 0.6871013050680762
Epoch: 37 | Iteration number: [2230/4518] 49% | Training loss: 0.6870994421933264
Epoch: 37 | Iteration number: [2240/4518] 49% | Training loss: 0.6870979236172778
Epoch: 37 | Iteration number: [2250/4518] 49% | Training loss: 0.6870887786812252
Epoch: 37 | Iteration number: [2260/4518] 50% | Training loss: 0.6870912334032818
Epoch: 37 | Iteration number: [2270/4518] 50% | Training loss: 0.6870865390689362
Epoch: 37 | Iteration number: [2280/4518] 50% | Training loss: 0.687089439363856
Epoch: 37 | Iteration number: [2290/4518] 50% | Training loss: 0.6870902766827413
Epoch: 37 | Iteration number: [2300/4518] 50% | Training loss: 0.6870895033815633
Epoch: 37 | Iteration number: [2310/4518] 51% | Training loss: 0.687086262847438
Epoch: 37 | Iteration number: [2320/4518] 51% | Training loss: 0.6870890705749906
Epoch: 37 | Iteration number: [2330/4518] 51% | Training loss: 0.6870911955321807
Epoch: 37 | Iteration number: [2340/4518] 51% | Training loss: 0.6870917091766994
Epoch: 37 | Iteration number: [2350/4518] 52% | Training loss: 0.6870936240541174
Epoch: 37 | Iteration number: [2360/4518] 52% | Training loss: 0.6870936732423507
Epoch: 37 | Iteration number: [2370/4518] 52% | Training loss: 0.68708731104553
Epoch: 37 | Iteration number: [2380/4518] 52% | Training loss: 0.687090940109822
Epoch: 37 | Iteration number: [2390/4518] 52% | Training loss: 0.6870883302209766
Epoch: 37 | Iteration number: [2400/4518] 53% | Training loss: 0.6870874011268219
Epoch: 37 | Iteration number: [2410/4518] 53% | Training loss: 0.6870910965555437
Epoch: 37 | Iteration number: [2420/4518] 53% | Training loss: 0.6870864978506546
Epoch: 37 | Iteration number: [2430/4518] 53% | Training loss: 0.6870874931537565
Epoch: 37 | Iteration number: [2440/4518] 54% | Training loss: 0.6870862730458135
Epoch: 37 | Iteration number: [2450/4518] 54% | Training loss: 0.687084737870158
Epoch: 37 | Iteration number: [2460/4518] 54% | Training loss: 0.6870774049099868
Epoch: 37 | Iteration number: [2470/4518] 54% | Training loss: 0.6870762773853565
Epoch: 37 | Iteration number: [2480/4518] 54% | Training loss: 0.6870765894651413
Epoch: 37 | Iteration number: [2490/4518] 55% | Training loss: 0.6870781553078846
Epoch: 37 | Iteration number: [2500/4518] 55% | Training loss: 0.6870739614725113
Epoch: 37 | Iteration number: [2510/4518] 55% | Training loss: 0.6870725661159987
Epoch: 37 | Iteration number: [2520/4518] 55% | Training loss: 0.6870741517534331
Epoch: 37 | Iteration number: [2530/4518] 55% | Training loss: 0.6870781925827147
Epoch: 37 | Iteration number: [2540/4518] 56% | Training loss: 0.6870849207395644
Epoch: 37 | Iteration number: [2550/4518] 56% | Training loss: 0.6870835643422369
Epoch: 37 | Iteration number: [2560/4518] 56% | Training loss: 0.6870783393736929
Epoch: 37 | Iteration number: [2570/4518] 56% | Training loss: 0.6870801302013694
Epoch: 37 | Iteration number: [2580/4518] 57% | Training loss: 0.6870765342037807
Epoch: 37 | Iteration number: [2590/4518] 57% | Training loss: 0.6870722027588996
Epoch: 37 | Iteration number: [2600/4518] 57% | Training loss: 0.6870724449707911
Epoch: 37 | Iteration number: [2610/4518] 57% | Training loss: 0.6870695445272658
Epoch: 37 | Iteration number: [2620/4518] 57% | Training loss: 0.6870663997098689
Epoch: 37 | Iteration number: [2630/4518] 58% | Training loss: 0.6870628289623405
Epoch: 37 | Iteration number: [2640/4518] 58% | Training loss: 0.687062256128499
Epoch: 37 | Iteration number: [2650/4518] 58% | Training loss: 0.6870567138240022
Epoch: 37 | Iteration number: [2660/4518] 58% | Training loss: 0.6870540045481875
Epoch: 37 | Iteration number: [2670/4518] 59% | Training loss: 0.6870528472273537
Epoch: 37 | Iteration number: [2680/4518] 59% | Training loss: 0.6870526526846102
Epoch: 37 | Iteration number: [2690/4518] 59% | Training loss: 0.687047988464398
Epoch: 37 | Iteration number: [2700/4518] 59% | Training loss: 0.687046490046713
Epoch: 37 | Iteration number: [2710/4518] 59% | Training loss: 0.6870449331193832
Epoch: 37 | Iteration number: [2720/4518] 60% | Training loss: 0.6870460997390396
Epoch: 37 | Iteration number: [2730/4518] 60% | Training loss: 0.6870475200724689
Epoch: 37 | Iteration number: [2740/4518] 60% | Training loss: 0.687045737491907
Epoch: 37 | Iteration number: [2750/4518] 60% | Training loss: 0.6870447972687808
Epoch: 37 | Iteration number: [2760/4518] 61% | Training loss: 0.6870443160119264
Epoch: 37 | Iteration number: [2770/4518] 61% | Training loss: 0.6870436727139924
Epoch: 37 | Iteration number: [2780/4518] 61% | Training loss: 0.6870422827039692
Epoch: 37 | Iteration number: [2790/4518] 61% | Training loss: 0.687041180706366
Epoch: 37 | Iteration number: [2800/4518] 61% | Training loss: 0.687038109430245
Epoch: 37 | Iteration number: [2810/4518] 62% | Training loss: 0.6870366338733253
Epoch: 37 | Iteration number: [2820/4518] 62% | Training loss: 0.6870351806811407
Epoch: 37 | Iteration number: [2830/4518] 62% | Training loss: 0.6870365389876146
Epoch: 37 | Iteration number: [2840/4518] 62% | Training loss: 0.6870372842105341
Epoch: 37 | Iteration number: [2850/4518] 63% | Training loss: 0.687036740947188
Epoch: 37 | Iteration number: [2860/4518] 63% | Training loss: 0.6870370816517544
Epoch: 37 | Iteration number: [2870/4518] 63% | Training loss: 0.6870351287130695
Epoch: 37 | Iteration number: [2880/4518] 63% | Training loss: 0.6870393168181181
Epoch: 37 | Iteration number: [2890/4518] 63% | Training loss: 0.6870401650976558
Epoch: 37 | Iteration number: [2900/4518] 64% | Training loss: 0.6870384344972413
Epoch: 37 | Iteration number: [2910/4518] 64% | Training loss: 0.6870363561148496
Epoch: 37 | Iteration number: [2920/4518] 64% | Training loss: 0.6870355234162449
Epoch: 37 | Iteration number: [2930/4518] 64% | Training loss: 0.6870335209898575
Epoch: 37 | Iteration number: [2940/4518] 65% | Training loss: 0.6870352120018329
Epoch: 37 | Iteration number: [2950/4518] 65% | Training loss: 0.6870343840122223
Epoch: 37 | Iteration number: [2960/4518] 65% | Training loss: 0.6870355786906707
Epoch: 37 | Iteration number: [2970/4518] 65% | Training loss: 0.687036005756269
Epoch: 37 | Iteration number: [2980/4518] 65% | Training loss: 0.687035479401582
Epoch: 37 | Iteration number: [2990/4518] 66% | Training loss: 0.6870368075211312
Epoch: 37 | Iteration number: [3000/4518] 66% | Training loss: 0.6870396433671315
Epoch: 37 | Iteration number: [3010/4518] 66% | Training loss: 0.687040688528175
Epoch: 37 | Iteration number: [3020/4518] 66% | Training loss: 0.6870409238417416
Epoch: 37 | Iteration number: [3030/4518] 67% | Training loss: 0.6870447042751627
Epoch: 37 | Iteration number: [3040/4518] 67% | Training loss: 0.6870418680929824
Epoch: 37 | Iteration number: [3050/4518] 67% | Training loss: 0.6870432043466411
Epoch: 37 | Iteration number: [3060/4518] 67% | Training loss: 0.6870393406331928
Epoch: 37 | Iteration number: [3070/4518] 67% | Training loss: 0.6870332251736706
Epoch: 37 | Iteration number: [3080/4518] 68% | Training loss: 0.6870340831674538
Epoch: 37 | Iteration number: [3090/4518] 68% | Training loss: 0.6870353184085833
Epoch: 37 | Iteration number: [3100/4518] 68% | Training loss: 0.6870356888348056
Epoch: 37 | Iteration number: [3110/4518] 68% | Training loss: 0.6870337761483392
Epoch: 37 | Iteration number: [3120/4518] 69% | Training loss: 0.6870304623666482
Epoch: 37 | Iteration number: [3130/4518] 69% | Training loss: 0.6870284074792465
Epoch: 37 | Iteration number: [3140/4518] 69% | Training loss: 0.6870299929835993
Epoch: 37 | Iteration number: [3150/4518] 69% | Training loss: 0.6870310535128155
Epoch: 37 | Iteration number: [3160/4518] 69% | Training loss: 0.6870310534027558
Epoch: 37 | Iteration number: [3170/4518] 70% | Training loss: 0.6870334320639963
Epoch: 37 | Iteration number: [3180/4518] 70% | Training loss: 0.6870319700278577
Epoch: 37 | Iteration number: [3190/4518] 70% | Training loss: 0.6870330230008845
Epoch: 37 | Iteration number: [3200/4518] 70% | Training loss: 0.6870345262810588
Epoch: 37 | Iteration number: [3210/4518] 71% | Training loss: 0.6870351789153625
Epoch: 37 | Iteration number: [3220/4518] 71% | Training loss: 0.6870362218122305
Epoch: 37 | Iteration number: [3230/4518] 71% | Training loss: 0.687033986141069
Epoch: 37 | Iteration number: [3240/4518] 71% | Training loss: 0.6870347843493945
Epoch: 37 | Iteration number: [3250/4518] 71% | Training loss: 0.687035714002756
Epoch: 37 | Iteration number: [3260/4518] 72% | Training loss: 0.6870389889720028
Epoch: 37 | Iteration number: [3270/4518] 72% | Training loss: 0.6870386111809208
Epoch: 37 | Iteration number: [3280/4518] 72% | Training loss: 0.6870437743278538
Epoch: 37 | Iteration number: [3290/4518] 72% | Training loss: 0.6870456560947975
Epoch: 37 | Iteration number: [3300/4518] 73% | Training loss: 0.6870459292693571
Epoch: 37 | Iteration number: [3310/4518] 73% | Training loss: 0.6870458484236207
Epoch: 37 | Iteration number: [3320/4518] 73% | Training loss: 0.6870483665940273
Epoch: 37 | Iteration number: [3330/4518] 73% | Training loss: 0.6870490017774943
Epoch: 37 | Iteration number: [3340/4518] 73% | Training loss: 0.6870458269369103
Epoch: 37 | Iteration number: [3350/4518] 74% | Training loss: 0.6870466359159839
Epoch: 37 | Iteration number: [3360/4518] 74% | Training loss: 0.6870484854316428
Epoch: 37 | Iteration number: [3370/4518] 74% | Training loss: 0.6870471742811118
Epoch: 37 | Iteration number: [3380/4518] 74% | Training loss: 0.6870447135888613
Epoch: 37 | Iteration number: [3390/4518] 75% | Training loss: 0.6870414125884177
Epoch: 37 | Iteration number: [3400/4518] 75% | Training loss: 0.6870404268012328
Epoch: 37 | Iteration number: [3410/4518] 75% | Training loss: 0.6870462879407441
Epoch: 37 | Iteration number: [3420/4518] 75% | Training loss: 0.68704644818055
Epoch: 37 | Iteration number: [3430/4518] 75% | Training loss: 0.6870460119956436
Epoch: 37 | Iteration number: [3440/4518] 76% | Training loss: 0.6870457173433415
Epoch: 37 | Iteration number: [3450/4518] 76% | Training loss: 0.6870478180698727
Epoch: 37 | Iteration number: [3460/4518] 76% | Training loss: 0.6870475590056767
Epoch: 37 | Iteration number: [3470/4518] 76% | Training loss: 0.6870456182647507
Epoch: 37 | Iteration number: [3480/4518] 77% | Training loss: 0.687046753538066
Epoch: 37 | Iteration number: [3490/4518] 77% | Training loss: 0.6870475502786118
Epoch: 37 | Iteration number: [3500/4518] 77% | Training loss: 0.6870502968175071
Epoch: 37 | Iteration number: [3510/4518] 77% | Training loss: 0.6870482115833848
Epoch: 37 | Iteration number: [3520/4518] 77% | Training loss: 0.6870492962612347
Epoch: 37 | Iteration number: [3530/4518] 78% | Training loss: 0.6870492918295495
Epoch: 37 | Iteration number: [3540/4518] 78% | Training loss: 0.6870466048434629
Epoch: 37 | Iteration number: [3550/4518] 78% | Training loss: 0.6870468645028665
Epoch: 37 | Iteration number: [3560/4518] 78% | Training loss: 0.6870452396487922
Epoch: 37 | Iteration number: [3570/4518] 79% | Training loss: 0.6870409229723345
Epoch: 37 | Iteration number: [3580/4518] 79% | Training loss: 0.687038332357087
Epoch: 37 | Iteration number: [3590/4518] 79% | Training loss: 0.6870387345801489
Epoch: 37 | Iteration number: [3600/4518] 79% | Training loss: 0.6870359253055519
Epoch: 37 | Iteration number: [3610/4518] 79% | Training loss: 0.6870368043141352
Epoch: 37 | Iteration number: [3620/4518] 80% | Training loss: 0.6870342052773217
Epoch: 37 | Iteration number: [3630/4518] 80% | Training loss: 0.6870326063849709
Epoch: 37 | Iteration number: [3640/4518] 80% | Training loss: 0.6870301326061343
Epoch: 37 | Iteration number: [3650/4518] 80% | Training loss: 0.6870302024116255
Epoch: 37 | Iteration number: [3660/4518] 81% | Training loss: 0.6870312391734514
Epoch: 37 | Iteration number: [3670/4518] 81% | Training loss: 0.6870335639984796
Epoch: 37 | Iteration number: [3680/4518] 81% | Training loss: 0.6870344659718483
Epoch: 37 | Iteration number: [3690/4518] 81% | Training loss: 0.6870352126880067
Epoch: 37 | Iteration number: [3700/4518] 81% | Training loss: 0.6870365264931241
Epoch: 37 | Iteration number: [3710/4518] 82% | Training loss: 0.6870352303242747
Epoch: 37 | Iteration number: [3720/4518] 82% | Training loss: 0.6870334857894528
Epoch: 37 | Iteration number: [3730/4518] 82% | Training loss: 0.6870317451436142
Epoch: 37 | Iteration number: [3740/4518] 82% | Training loss: 0.6870308052887891
Epoch: 37 | Iteration number: [3750/4518] 83% | Training loss: 0.6870279446760813
Epoch: 37 | Iteration number: [3760/4518] 83% | Training loss: 0.6870235878102323
Epoch: 37 | Iteration number: [3770/4518] 83% | Training loss: 0.687022909229567
Epoch: 37 | Iteration number: [3780/4518] 83% | Training loss: 0.6870202904025083
Epoch: 37 | Iteration number: [3790/4518] 83% | Training loss: 0.6870188911074384
Epoch: 37 | Iteration number: [3800/4518] 84% | Training loss: 0.6870154116185088
Epoch: 37 | Iteration number: [3810/4518] 84% | Training loss: 0.6870177617849015
Epoch: 37 | Iteration number: [3820/4518] 84% | Training loss: 0.6870163282642814
Epoch: 37 | Iteration number: [3830/4518] 84% | Training loss: 0.6870155332760773
Epoch: 37 | Iteration number: [3840/4518] 84% | Training loss: 0.6870162146010746
Epoch: 37 | Iteration number: [3850/4518] 85% | Training loss: 0.6870171592142675
Epoch: 37 | Iteration number: [3860/4518] 85% | Training loss: 0.6870170327665892
Epoch: 37 | Iteration number: [3870/4518] 85% | Training loss: 0.6870168051208329
Epoch: 37 | Iteration number: [3880/4518] 85% | Training loss: 0.6870173918985829
Epoch: 37 | Iteration number: [3890/4518] 86% | Training loss: 0.687015847130116
Epoch: 37 | Iteration number: [3900/4518] 86% | Training loss: 0.6870131764656459
Epoch: 37 | Iteration number: [3910/4518] 86% | Training loss: 0.6870136973193235
Epoch: 37 | Iteration number: [3920/4518] 86% | Training loss: 0.6870106528152008
Epoch: 37 | Iteration number: [3930/4518] 86% | Training loss: 0.6870135769437591
Epoch: 37 | Iteration number: [3940/4518] 87% | Training loss: 0.6870101533716705
Epoch: 37 | Iteration number: [3950/4518] 87% | Training loss: 0.6870106873029395
Epoch: 37 | Iteration number: [3960/4518] 87% | Training loss: 0.687008576712223
Epoch: 37 | Iteration number: [3970/4518] 87% | Training loss: 0.6870100135466914
Epoch: 37 | Iteration number: [3980/4518] 88% | Training loss: 0.6870110391821693
Epoch: 37 | Iteration number: [3990/4518] 88% | Training loss: 0.687011780774683
Epoch: 37 | Iteration number: [4000/4518] 88% | Training loss: 0.6870122821480036
Epoch: 37 | Iteration number: [4010/4518] 88% | Training loss: 0.687011956722659
Epoch: 37 | Iteration number: [4020/4518] 88% | Training loss: 0.6870077926721145
Epoch: 37 | Iteration number: [4030/4518] 89% | Training loss: 0.6870076382426411
Epoch: 37 | Iteration number: [4040/4518] 89% | Training loss: 0.6870048723598517
Epoch: 37 | Iteration number: [4050/4518] 89% | Training loss: 0.6870018145625973
Epoch: 37 | Iteration number: [4060/4518] 89% | Training loss: 0.687004592500884
Epoch: 37 | Iteration number: [4070/4518] 90% | Training loss: 0.6870028154270069
Epoch: 37 | Iteration number: [4080/4518] 90% | Training loss: 0.6870008137442317
Epoch: 37 | Iteration number: [4090/4518] 90% | Training loss: 0.6869997397757392
Epoch: 37 | Iteration number: [4100/4518] 90% | Training loss: 0.6869995158038488
Epoch: 37 | Iteration number: [4110/4518] 90% | Training loss: 0.6870000391836004
Epoch: 37 | Iteration number: [4120/4518] 91% | Training loss: 0.6870015680355933
Epoch: 37 | Iteration number: [4130/4518] 91% | Training loss: 0.6870024525224441
Epoch: 37 | Iteration number: [4140/4518] 91% | Training loss: 0.6870005189220686
Epoch: 37 | Iteration number: [4150/4518] 91% | Training loss: 0.6869973900375596
Epoch: 37 | Iteration number: [4160/4518] 92% | Training loss: 0.6869967374377526
Epoch: 37 | Iteration number: [4170/4518] 92% | Training loss: 0.686995833054435
Epoch: 37 | Iteration number: [4180/4518] 92% | Training loss: 0.6869905557786449
Epoch: 37 | Iteration number: [4190/4518] 92% | Training loss: 0.6869894655621421
Epoch: 37 | Iteration number: [4200/4518] 92% | Training loss: 0.6869869450444267
Epoch: 37 | Iteration number: [4210/4518] 93% | Training loss: 0.6869862411339323
Epoch: 37 | Iteration number: [4220/4518] 93% | Training loss: 0.6869821471201865
Epoch: 37 | Iteration number: [4230/4518] 93% | Training loss: 0.6869776961087617
Epoch: 37 | Iteration number: [4240/4518] 93% | Training loss: 0.6869813596021455
Epoch: 37 | Iteration number: [4250/4518] 94% | Training loss: 0.686982927869348
Epoch: 37 | Iteration number: [4260/4518] 94% | Training loss: 0.6869796975817479
Epoch: 37 | Iteration number: [4270/4518] 94% | Training loss: 0.6869832230535547
Epoch: 37 | Iteration number: [4280/4518] 94% | Training loss: 0.6869837047340714
Epoch: 37 | Iteration number: [4290/4518] 94% | Training loss: 0.6869824647625565
Epoch: 37 | Iteration number: [4300/4518] 95% | Training loss: 0.6869818916570308
Epoch: 37 | Iteration number: [4310/4518] 95% | Training loss: 0.6869793811834606
Epoch: 37 | Iteration number: [4320/4518] 95% | Training loss: 0.6869786207184747
Epoch: 37 | Iteration number: [4330/4518] 95% | Training loss: 0.6869778280032425
Epoch: 37 | Iteration number: [4340/4518] 96% | Training loss: 0.6869774660893849
Epoch: 37 | Iteration number: [4350/4518] 96% | Training loss: 0.6869787791131556
Epoch: 37 | Iteration number: [4360/4518] 96% | Training loss: 0.6869774117929126
Epoch: 37 | Iteration number: [4370/4518] 96% | Training loss: 0.6869778894587021
Epoch: 37 | Iteration number: [4380/4518] 96% | Training loss: 0.6869807314246756
Epoch: 37 | Iteration number: [4390/4518] 97% | Training loss: 0.6869784355299348
Epoch: 37 | Iteration number: [4400/4518] 97% | Training loss: 0.6869811614535072
Epoch: 37 | Iteration number: [4410/4518] 97% | Training loss: 0.6869794672443753
Epoch: 37 | Iteration number: [4420/4518] 97% | Training loss: 0.6869783928761115
Epoch: 37 | Iteration number: [4430/4518] 98% | Training loss: 0.6869762798329777
Epoch: 37 | Iteration number: [4440/4518] 98% | Training loss: 0.6869764329076887
Epoch: 37 | Iteration number: [4450/4518] 98% | Training loss: 0.686978307359674
Epoch: 37 | Iteration number: [4460/4518] 98% | Training loss: 0.6869801755309639
Epoch: 37 | Iteration number: [4470/4518] 98% | Training loss: 0.686982784935292
Epoch: 37 | Iteration number: [4480/4518] 99% | Training loss: 0.6869798109068402
Epoch: 37 | Iteration number: [4490/4518] 99% | Training loss: 0.6869784461097888
Epoch: 37 | Iteration number: [4500/4518] 99% | Training loss: 0.6869787799384859
Epoch: 37 | Iteration number: [4510/4518] 99% | Training loss: 0.6869798633449622

 End of epoch: 37 | Train Loss: 0.686829607602293 | Training Time: 632 

 End of epoch: 37 | Eval Loss: 0.6898629081492521 | Evaluating Time: 17 
Epoch: 38 | Iteration number: [10/4518] 0% | Training loss: 0.7568232953548432
Epoch: 38 | Iteration number: [20/4518] 0% | Training loss: 0.7216693788766861
Epoch: 38 | Iteration number: [30/4518] 0% | Training loss: 0.7098243554433187
Epoch: 38 | Iteration number: [40/4518] 0% | Training loss: 0.7037153825163841
Epoch: 38 | Iteration number: [50/4518] 1% | Training loss: 0.7004943907260894
Epoch: 38 | Iteration number: [60/4518] 1% | Training loss: 0.6981968422730763
Epoch: 38 | Iteration number: [70/4518] 1% | Training loss: 0.6964609052453722
Epoch: 38 | Iteration number: [80/4518] 1% | Training loss: 0.6953154802322388
Epoch: 38 | Iteration number: [90/4518] 1% | Training loss: 0.6943558004167345
Epoch: 38 | Iteration number: [100/4518] 2% | Training loss: 0.6935681456327438
Epoch: 38 | Iteration number: [110/4518] 2% | Training loss: 0.6929516949436881
Epoch: 38 | Iteration number: [120/4518] 2% | Training loss: 0.6924933314323425
Epoch: 38 | Iteration number: [130/4518] 2% | Training loss: 0.6921048677884616
Epoch: 38 | Iteration number: [140/4518] 3% | Training loss: 0.691831950204713
Epoch: 38 | Iteration number: [150/4518] 3% | Training loss: 0.6914411532878876
Epoch: 38 | Iteration number: [160/4518] 3% | Training loss: 0.6912033554166556
Epoch: 38 | Iteration number: [170/4518] 3% | Training loss: 0.6910322659155902
Epoch: 38 | Iteration number: [180/4518] 3% | Training loss: 0.6908084488577313
Epoch: 38 | Iteration number: [190/4518] 4% | Training loss: 0.690594648687463
Epoch: 38 | Iteration number: [200/4518] 4% | Training loss: 0.6904889380931855
Epoch: 38 | Iteration number: [210/4518] 4% | Training loss: 0.6903807506674812
Epoch: 38 | Iteration number: [220/4518] 4% | Training loss: 0.6902274996042251
Epoch: 38 | Iteration number: [230/4518] 5% | Training loss: 0.6900966369587442
Epoch: 38 | Iteration number: [240/4518] 5% | Training loss: 0.6899488486349583
Epoch: 38 | Iteration number: [250/4518] 5% | Training loss: 0.6898373789787292
Epoch: 38 | Iteration number: [260/4518] 5% | Training loss: 0.6897672398732259
Epoch: 38 | Iteration number: [270/4518] 5% | Training loss: 0.6896323078208499
Epoch: 38 | Iteration number: [280/4518] 6% | Training loss: 0.6896107041410038
Epoch: 38 | Iteration number: [290/4518] 6% | Training loss: 0.689483308586581
Epoch: 38 | Iteration number: [300/4518] 6% | Training loss: 0.689387955268224
Epoch: 38 | Iteration number: [310/4518] 6% | Training loss: 0.6892939196478935
Epoch: 38 | Iteration number: [320/4518] 7% | Training loss: 0.6892429549247027
Epoch: 38 | Iteration number: [330/4518] 7% | Training loss: 0.6891751795104055
Epoch: 38 | Iteration number: [340/4518] 7% | Training loss: 0.6891048704876619
Epoch: 38 | Iteration number: [350/4518] 7% | Training loss: 0.6890495434829167
Epoch: 38 | Iteration number: [360/4518] 7% | Training loss: 0.6889994197421604
Epoch: 38 | Iteration number: [370/4518] 8% | Training loss: 0.6889657800262039
Epoch: 38 | Iteration number: [380/4518] 8% | Training loss: 0.6889359905531532
Epoch: 38 | Iteration number: [390/4518] 8% | Training loss: 0.6888724203293141
Epoch: 38 | Iteration number: [400/4518] 8% | Training loss: 0.6888034158945083
Epoch: 38 | Iteration number: [410/4518] 9% | Training loss: 0.6887529772956197
Epoch: 38 | Iteration number: [420/4518] 9% | Training loss: 0.6886935516482308
Epoch: 38 | Iteration number: [430/4518] 9% | Training loss: 0.6886661582214888
Epoch: 38 | Iteration number: [440/4518] 9% | Training loss: 0.6886024381626736
Epoch: 38 | Iteration number: [450/4518] 9% | Training loss: 0.6885609730084737
Epoch: 38 | Iteration number: [460/4518] 10% | Training loss: 0.6885392244743265
Epoch: 38 | Iteration number: [470/4518] 10% | Training loss: 0.6885116244884247
Epoch: 38 | Iteration number: [480/4518] 10% | Training loss: 0.6884812969714403
Epoch: 38 | Iteration number: [490/4518] 10% | Training loss: 0.6884418236966036
Epoch: 38 | Iteration number: [500/4518] 11% | Training loss: 0.6884434324502945
Epoch: 38 | Iteration number: [510/4518] 11% | Training loss: 0.6884338837043912
Epoch: 38 | Iteration number: [520/4518] 11% | Training loss: 0.6883732698284662
Epoch: 38 | Iteration number: [530/4518] 11% | Training loss: 0.6883403084188138
Epoch: 38 | Iteration number: [540/4518] 11% | Training loss: 0.6883254438638687
Epoch: 38 | Iteration number: [550/4518] 12% | Training loss: 0.6883018907633695
Epoch: 38 | Iteration number: [560/4518] 12% | Training loss: 0.6882847210126264
Epoch: 38 | Iteration number: [570/4518] 12% | Training loss: 0.6882709720678497
Epoch: 38 | Iteration number: [580/4518] 12% | Training loss: 0.6882470853369812
Epoch: 38 | Iteration number: [590/4518] 13% | Training loss: 0.6882144856250892
Epoch: 38 | Iteration number: [600/4518] 13% | Training loss: 0.688166740934054
Epoch: 38 | Iteration number: [610/4518] 13% | Training loss: 0.6881512960449594
Epoch: 38 | Iteration number: [620/4518] 13% | Training loss: 0.6881329201882885
Epoch: 38 | Iteration number: [630/4518] 13% | Training loss: 0.6881087335329207
Epoch: 38 | Iteration number: [640/4518] 14% | Training loss: 0.6880599680356682
Epoch: 38 | Iteration number: [650/4518] 14% | Training loss: 0.6880297957016872
Epoch: 38 | Iteration number: [660/4518] 14% | Training loss: 0.6880223872986707
Epoch: 38 | Iteration number: [670/4518] 14% | Training loss: 0.6880052716874364
Epoch: 38 | Iteration number: [680/4518] 15% | Training loss: 0.6879958978470634
Epoch: 38 | Iteration number: [690/4518] 15% | Training loss: 0.6880016299261563
Epoch: 38 | Iteration number: [700/4518] 15% | Training loss: 0.6879945940630776
Epoch: 38 | Iteration number: [710/4518] 15% | Training loss: 0.6879727333364353
Epoch: 38 | Iteration number: [720/4518] 15% | Training loss: 0.687943084206846
Epoch: 38 | Iteration number: [730/4518] 16% | Training loss: 0.6879198215595663
Epoch: 38 | Iteration number: [740/4518] 16% | Training loss: 0.6879119883517961
Epoch: 38 | Iteration number: [750/4518] 16% | Training loss: 0.6878906738758087
Epoch: 38 | Iteration number: [760/4518] 16% | Training loss: 0.687886186257789
Epoch: 38 | Iteration number: [770/4518] 17% | Training loss: 0.6878601362178852
Epoch: 38 | Iteration number: [780/4518] 17% | Training loss: 0.6878394139882845
Epoch: 38 | Iteration number: [790/4518] 17% | Training loss: 0.6878413453132292
Epoch: 38 | Iteration number: [800/4518] 17% | Training loss: 0.6878331396728754
Epoch: 38 | Iteration number: [810/4518] 17% | Training loss: 0.687814125823386
Epoch: 38 | Iteration number: [820/4518] 18% | Training loss: 0.6878015476029093
Epoch: 38 | Iteration number: [830/4518] 18% | Training loss: 0.6877986648714686
Epoch: 38 | Iteration number: [840/4518] 18% | Training loss: 0.6877863903130804
Epoch: 38 | Iteration number: [850/4518] 18% | Training loss: 0.6877865764674018
Epoch: 38 | Iteration number: [860/4518] 19% | Training loss: 0.6877730408380198
Epoch: 38 | Iteration number: [870/4518] 19% | Training loss: 0.6877679894710409
Epoch: 38 | Iteration number: [880/4518] 19% | Training loss: 0.6877414201470938
Epoch: 38 | Iteration number: [890/4518] 19% | Training loss: 0.6877230366964019
Epoch: 38 | Iteration number: [900/4518] 19% | Training loss: 0.6877046021487978
Epoch: 38 | Iteration number: [910/4518] 20% | Training loss: 0.6876963337699136
Epoch: 38 | Iteration number: [920/4518] 20% | Training loss: 0.6876891333771789
Epoch: 38 | Iteration number: [930/4518] 20% | Training loss: 0.6876707637181846
Epoch: 38 | Iteration number: [940/4518] 20% | Training loss: 0.6876784596037357
Epoch: 38 | Iteration number: [950/4518] 21% | Training loss: 0.687654711447264
Epoch: 38 | Iteration number: [960/4518] 21% | Training loss: 0.687645923656722
Epoch: 38 | Iteration number: [970/4518] 21% | Training loss: 0.6876350811461812
Epoch: 38 | Iteration number: [980/4518] 21% | Training loss: 0.687630182565475
Epoch: 38 | Iteration number: [990/4518] 21% | Training loss: 0.6876255530299562
Epoch: 38 | Iteration number: [1000/4518] 22% | Training loss: 0.687627050280571
Epoch: 38 | Iteration number: [1010/4518] 22% | Training loss: 0.687614763550239
Epoch: 38 | Iteration number: [1020/4518] 22% | Training loss: 0.6876158343810661
Epoch: 38 | Iteration number: [1030/4518] 22% | Training loss: 0.6876136771104868
Epoch: 38 | Iteration number: [1040/4518] 23% | Training loss: 0.6876057608196369
Epoch: 38 | Iteration number: [1050/4518] 23% | Training loss: 0.6875884115695954
Epoch: 38 | Iteration number: [1060/4518] 23% | Training loss: 0.6875846291488071
Epoch: 38 | Iteration number: [1070/4518] 23% | Training loss: 0.6875767282793455
Epoch: 38 | Iteration number: [1080/4518] 23% | Training loss: 0.6875613825740637
Epoch: 38 | Iteration number: [1090/4518] 24% | Training loss: 0.6875605551474685
Epoch: 38 | Iteration number: [1100/4518] 24% | Training loss: 0.6875569216771559
Epoch: 38 | Iteration number: [1110/4518] 24% | Training loss: 0.6875517507394154
Epoch: 38 | Iteration number: [1120/4518] 24% | Training loss: 0.6875470518533673
Epoch: 38 | Iteration number: [1130/4518] 25% | Training loss: 0.687541441843573
Epoch: 38 | Iteration number: [1140/4518] 25% | Training loss: 0.6875397284825643
Epoch: 38 | Iteration number: [1150/4518] 25% | Training loss: 0.6875244130258975
Epoch: 38 | Iteration number: [1160/4518] 25% | Training loss: 0.6875101807816275
Epoch: 38 | Iteration number: [1170/4518] 25% | Training loss: 0.6874973953279675
Epoch: 38 | Iteration number: [1180/4518] 26% | Training loss: 0.6874984953868187
Epoch: 38 | Iteration number: [1190/4518] 26% | Training loss: 0.6874859077589852
Epoch: 38 | Iteration number: [1200/4518] 26% | Training loss: 0.6874685785671075
Epoch: 38 | Iteration number: [1210/4518] 26% | Training loss: 0.6874734444559113
Epoch: 38 | Iteration number: [1220/4518] 27% | Training loss: 0.6874692288089971
Epoch: 38 | Iteration number: [1230/4518] 27% | Training loss: 0.6874632576616799
Epoch: 38 | Iteration number: [1240/4518] 27% | Training loss: 0.6874590967451373
Epoch: 38 | Iteration number: [1250/4518] 27% | Training loss: 0.687443667602539
Epoch: 38 | Iteration number: [1260/4518] 27% | Training loss: 0.6874470992220773
Epoch: 38 | Iteration number: [1270/4518] 28% | Training loss: 0.6874467582214536
Epoch: 38 | Iteration number: [1280/4518] 28% | Training loss: 0.6874460346531123
Epoch: 38 | Iteration number: [1290/4518] 28% | Training loss: 0.6874466053737226
Epoch: 38 | Iteration number: [1300/4518] 28% | Training loss: 0.6874395538293399
Epoch: 38 | Iteration number: [1310/4518] 28% | Training loss: 0.6874268368910287
Epoch: 38 | Iteration number: [1320/4518] 29% | Training loss: 0.6874226754813483
Epoch: 38 | Iteration number: [1330/4518] 29% | Training loss: 0.6874182827042458
Epoch: 38 | Iteration number: [1340/4518] 29% | Training loss: 0.6874091077651551
Epoch: 38 | Iteration number: [1350/4518] 29% | Training loss: 0.6873990125126309
Epoch: 38 | Iteration number: [1360/4518] 30% | Training loss: 0.6873967622571132
Epoch: 38 | Iteration number: [1370/4518] 30% | Training loss: 0.6873938677084707
Epoch: 38 | Iteration number: [1380/4518] 30% | Training loss: 0.6873962925828021
Epoch: 38 | Iteration number: [1390/4518] 30% | Training loss: 0.6873954923461667
Epoch: 38 | Iteration number: [1400/4518] 30% | Training loss: 0.6873998034426144
Epoch: 38 | Iteration number: [1410/4518] 31% | Training loss: 0.6873970082465638
Epoch: 38 | Iteration number: [1420/4518] 31% | Training loss: 0.6873896435532771
Epoch: 38 | Iteration number: [1430/4518] 31% | Training loss: 0.6873898546595674
Epoch: 38 | Iteration number: [1440/4518] 31% | Training loss: 0.6873912973950307
Epoch: 38 | Iteration number: [1450/4518] 32% | Training loss: 0.6873883425778357
Epoch: 38 | Iteration number: [1460/4518] 32% | Training loss: 0.6873789708091788
Epoch: 38 | Iteration number: [1470/4518] 32% | Training loss: 0.6873759401087858
Epoch: 38 | Iteration number: [1480/4518] 32% | Training loss: 0.6873661111335496
Epoch: 38 | Iteration number: [1490/4518] 32% | Training loss: 0.6873615894541645
Epoch: 38 | Iteration number: [1500/4518] 33% | Training loss: 0.6873576671679814
Epoch: 38 | Iteration number: [1510/4518] 33% | Training loss: 0.6873572698886821
Epoch: 38 | Iteration number: [1520/4518] 33% | Training loss: 0.6873558109136004
Epoch: 38 | Iteration number: [1530/4518] 33% | Training loss: 0.6873562827998516
Epoch: 38 | Iteration number: [1540/4518] 34% | Training loss: 0.6873463766141371
Epoch: 38 | Iteration number: [1550/4518] 34% | Training loss: 0.6873398538558714
Epoch: 38 | Iteration number: [1560/4518] 34% | Training loss: 0.6873370218735475
Epoch: 38 | Iteration number: [1570/4518] 34% | Training loss: 0.6873411995590113
Epoch: 38 | Iteration number: [1580/4518] 34% | Training loss: 0.6873353777429726
Epoch: 38 | Iteration number: [1590/4518] 35% | Training loss: 0.6873304731815866
Epoch: 38 | Iteration number: [1600/4518] 35% | Training loss: 0.6873291909322142
Epoch: 38 | Iteration number: [1610/4518] 35% | Training loss: 0.6873261626092544
Epoch: 38 | Iteration number: [1620/4518] 35% | Training loss: 0.6873277930565822
Epoch: 38 | Iteration number: [1630/4518] 36% | Training loss: 0.6873271195435086
Epoch: 38 | Iteration number: [1640/4518] 36% | Training loss: 0.6873261800262986
Epoch: 38 | Iteration number: [1650/4518] 36% | Training loss: 0.6873249832789103
Epoch: 38 | Iteration number: [1660/4518] 36% | Training loss: 0.6873166501163
Epoch: 38 | Iteration number: [1670/4518] 36% | Training loss: 0.6873012755802291
Epoch: 38 | Iteration number: [1680/4518] 37% | Training loss: 0.687302840572028
Epoch: 38 | Iteration number: [1690/4518] 37% | Training loss: 0.6872946794216449
Epoch: 38 | Iteration number: [1700/4518] 37% | Training loss: 0.6872969123545815
Epoch: 38 | Iteration number: [1710/4518] 37% | Training loss: 0.6872914084217004
Epoch: 38 | Iteration number: [1720/4518] 38% | Training loss: 0.6872919921265092
Epoch: 38 | Iteration number: [1730/4518] 38% | Training loss: 0.6872886493715936
Epoch: 38 | Iteration number: [1740/4518] 38% | Training loss: 0.6872945933506407
Epoch: 38 | Iteration number: [1750/4518] 38% | Training loss: 0.6872958930901119
Epoch: 38 | Iteration number: [1760/4518] 38% | Training loss: 0.6872966086999936
Epoch: 38 | Iteration number: [1770/4518] 39% | Training loss: 0.687283810383856
Epoch: 38 | Iteration number: [1780/4518] 39% | Training loss: 0.6872795924042048
Epoch: 38 | Iteration number: [1790/4518] 39% | Training loss: 0.6872756343314101
Epoch: 38 | Iteration number: [1800/4518] 39% | Training loss: 0.6872768112685945
Epoch: 38 | Iteration number: [1810/4518] 40% | Training loss: 0.6872808244346914
Epoch: 38 | Iteration number: [1820/4518] 40% | Training loss: 0.6872785175239647
Epoch: 38 | Iteration number: [1830/4518] 40% | Training loss: 0.687285272117521
Epoch: 38 | Iteration number: [1840/4518] 40% | Training loss: 0.6872820967565412
Epoch: 38 | Iteration number: [1850/4518] 40% | Training loss: 0.6872783121224996
Epoch: 38 | Iteration number: [1860/4518] 41% | Training loss: 0.6872741701782391
Epoch: 38 | Iteration number: [1870/4518] 41% | Training loss: 0.6872712939499533
Epoch: 38 | Iteration number: [1880/4518] 41% | Training loss: 0.6872666387164846
Epoch: 38 | Iteration number: [1890/4518] 41% | Training loss: 0.6872645282240771
Epoch: 38 | Iteration number: [1900/4518] 42% | Training loss: 0.6872646862582157
Epoch: 38 | Iteration number: [1910/4518] 42% | Training loss: 0.6872663307564421
Epoch: 38 | Iteration number: [1920/4518] 42% | Training loss: 0.6872549888988336
Epoch: 38 | Iteration number: [1930/4518] 42% | Training loss: 0.6872543983200053
Epoch: 38 | Iteration number: [1940/4518] 42% | Training loss: 0.6872533769337172
Epoch: 38 | Iteration number: [1950/4518] 43% | Training loss: 0.6872478359173506
Epoch: 38 | Iteration number: [1960/4518] 43% | Training loss: 0.6872425992878116
Epoch: 38 | Iteration number: [1970/4518] 43% | Training loss: 0.6872467327541506
Epoch: 38 | Iteration number: [1980/4518] 43% | Training loss: 0.687245953474382
Epoch: 38 | Iteration number: [1990/4518] 44% | Training loss: 0.6872446750875694
Epoch: 38 | Iteration number: [2000/4518] 44% | Training loss: 0.6872400412261486
Epoch: 38 | Iteration number: [2010/4518] 44% | Training loss: 0.6872436232827789
Epoch: 38 | Iteration number: [2020/4518] 44% | Training loss: 0.6872423045706041
Epoch: 38 | Iteration number: [2030/4518] 44% | Training loss: 0.6872453978496232
Epoch: 38 | Iteration number: [2040/4518] 45% | Training loss: 0.6872405490454505
Epoch: 38 | Iteration number: [2050/4518] 45% | Training loss: 0.6872378514161924
Epoch: 38 | Iteration number: [2060/4518] 45% | Training loss: 0.6872320052778836
Epoch: 38 | Iteration number: [2070/4518] 45% | Training loss: 0.6872312399500234
Epoch: 38 | Iteration number: [2080/4518] 46% | Training loss: 0.6872361099204192
Epoch: 38 | Iteration number: [2090/4518] 46% | Training loss: 0.6872389775714235
Epoch: 38 | Iteration number: [2100/4518] 46% | Training loss: 0.6872366283904938
Epoch: 38 | Iteration number: [2110/4518] 46% | Training loss: 0.6872399082963501
Epoch: 38 | Iteration number: [2120/4518] 46% | Training loss: 0.6872370558527281
Epoch: 38 | Iteration number: [2130/4518] 47% | Training loss: 0.6872330006579278
Epoch: 38 | Iteration number: [2140/4518] 47% | Training loss: 0.6872303813138855
Epoch: 38 | Iteration number: [2150/4518] 47% | Training loss: 0.6872275577035061
Epoch: 38 | Iteration number: [2160/4518] 47% | Training loss: 0.687220858341014
Epoch: 38 | Iteration number: [2170/4518] 48% | Training loss: 0.6872161834745363
Epoch: 38 | Iteration number: [2180/4518] 48% | Training loss: 0.6872114304829081
Epoch: 38 | Iteration number: [2190/4518] 48% | Training loss: 0.6872123763441496
Epoch: 38 | Iteration number: [2200/4518] 48% | Training loss: 0.6872149394588037
Epoch: 38 | Iteration number: [2210/4518] 48% | Training loss: 0.687211801266778
Epoch: 38 | Iteration number: [2220/4518] 49% | Training loss: 0.6872152104302569
Epoch: 38 | Iteration number: [2230/4518] 49% | Training loss: 0.687211605438737
Epoch: 38 | Iteration number: [2240/4518] 49% | Training loss: 0.687206502551479
Epoch: 38 | Iteration number: [2250/4518] 49% | Training loss: 0.6872013796965282
Epoch: 38 | Iteration number: [2260/4518] 50% | Training loss: 0.6872036356577831
Epoch: 38 | Iteration number: [2270/4518] 50% | Training loss: 0.6871974073317607
Epoch: 38 | Iteration number: [2280/4518] 50% | Training loss: 0.6871908522750202
Epoch: 38 | Iteration number: [2290/4518] 50% | Training loss: 0.687190378753379
Epoch: 38 | Iteration number: [2300/4518] 50% | Training loss: 0.6871835678297541
Epoch: 38 | Iteration number: [2310/4518] 51% | Training loss: 0.6871786866869245
Epoch: 38 | Iteration number: [2320/4518] 51% | Training loss: 0.6871790327388665
Epoch: 38 | Iteration number: [2330/4518] 51% | Training loss: 0.6871763787811918
Epoch: 38 | Iteration number: [2340/4518] 51% | Training loss: 0.6871719208028582
Epoch: 38 | Iteration number: [2350/4518] 52% | Training loss: 0.6871714751771156
Epoch: 38 | Iteration number: [2360/4518] 52% | Training loss: 0.6871661302649369
Epoch: 38 | Iteration number: [2370/4518] 52% | Training loss: 0.6871665418148041
Epoch: 38 | Iteration number: [2380/4518] 52% | Training loss: 0.6871660139129944
Epoch: 38 | Iteration number: [2390/4518] 52% | Training loss: 0.6871643450469651
Epoch: 38 | Iteration number: [2400/4518] 53% | Training loss: 0.6871629616369804
Epoch: 38 | Iteration number: [2410/4518] 53% | Training loss: 0.6871681717174182
Epoch: 38 | Iteration number: [2420/4518] 53% | Training loss: 0.6871626456906973
Epoch: 38 | Iteration number: [2430/4518] 53% | Training loss: 0.6871638341695684
Epoch: 38 | Iteration number: [2440/4518] 54% | Training loss: 0.687159264283102
Epoch: 38 | Iteration number: [2450/4518] 54% | Training loss: 0.6871641081936506
Epoch: 38 | Iteration number: [2460/4518] 54% | Training loss: 0.6871591658369313
Epoch: 38 | Iteration number: [2470/4518] 54% | Training loss: 0.6871555463987806
Epoch: 38 | Iteration number: [2480/4518] 54% | Training loss: 0.6871585568112711
Epoch: 38 | Iteration number: [2490/4518] 55% | Training loss: 0.6871608326952141
Epoch: 38 | Iteration number: [2500/4518] 55% | Training loss: 0.6871533139705658
Epoch: 38 | Iteration number: [2510/4518] 55% | Training loss: 0.6871525584226585
Epoch: 38 | Iteration number: [2520/4518] 55% | Training loss: 0.6871524258501946
Epoch: 38 | Iteration number: [2530/4518] 55% | Training loss: 0.6871473485066486
Epoch: 38 | Iteration number: [2540/4518] 56% | Training loss: 0.6871438977051908
Epoch: 38 | Iteration number: [2550/4518] 56% | Training loss: 0.6871404325962067
Epoch: 38 | Iteration number: [2560/4518] 56% | Training loss: 0.6871371852932497
Epoch: 38 | Iteration number: [2570/4518] 56% | Training loss: 0.6871364606957491
Epoch: 38 | Iteration number: [2580/4518] 57% | Training loss: 0.6871327216311018
Epoch: 38 | Iteration number: [2590/4518] 57% | Training loss: 0.6871336552397165
Epoch: 38 | Iteration number: [2600/4518] 57% | Training loss: 0.687132491996655
Epoch: 38 | Iteration number: [2610/4518] 57% | Training loss: 0.6871333135498895
Epoch: 38 | Iteration number: [2620/4518] 57% | Training loss: 0.6871359537120993
Epoch: 38 | Iteration number: [2630/4518] 58% | Training loss: 0.6871316657320174
Epoch: 38 | Iteration number: [2640/4518] 58% | Training loss: 0.6871327574731726
Epoch: 38 | Iteration number: [2650/4518] 58% | Training loss: 0.687130791173791
Epoch: 38 | Iteration number: [2660/4518] 58% | Training loss: 0.6871310223314099
Epoch: 38 | Iteration number: [2670/4518] 59% | Training loss: 0.6871252381399776
Epoch: 38 | Iteration number: [2680/4518] 59% | Training loss: 0.6871254832219722
Epoch: 38 | Iteration number: [2690/4518] 59% | Training loss: 0.687124253582334
Epoch: 38 | Iteration number: [2700/4518] 59% | Training loss: 0.6871270732305668
Epoch: 38 | Iteration number: [2710/4518] 59% | Training loss: 0.687125067363366
Epoch: 38 | Iteration number: [2720/4518] 60% | Training loss: 0.687125391359715
Epoch: 38 | Iteration number: [2730/4518] 60% | Training loss: 0.6871257599020179
Epoch: 38 | Iteration number: [2740/4518] 60% | Training loss: 0.6871226824983193
Epoch: 38 | Iteration number: [2750/4518] 60% | Training loss: 0.6871207300316203
Epoch: 38 | Iteration number: [2760/4518] 61% | Training loss: 0.6871150887530783
Epoch: 38 | Iteration number: [2770/4518] 61% | Training loss: 0.6871107921703627
Epoch: 38 | Iteration number: [2780/4518] 61% | Training loss: 0.6871066495025758
Epoch: 38 | Iteration number: [2790/4518] 61% | Training loss: 0.6871014476890632
Epoch: 38 | Iteration number: [2800/4518] 61% | Training loss: 0.6871000472562654
Epoch: 38 | Iteration number: [2810/4518] 62% | Training loss: 0.6870992650553001
Epoch: 38 | Iteration number: [2820/4518] 62% | Training loss: 0.6870973079128468
Epoch: 38 | Iteration number: [2830/4518] 62% | Training loss: 0.6870958467043752
Epoch: 38 | Iteration number: [2840/4518] 62% | Training loss: 0.6870922639756135
Epoch: 38 | Iteration number: [2850/4518] 63% | Training loss: 0.6870876916458732
Epoch: 38 | Iteration number: [2860/4518] 63% | Training loss: 0.6870896876066714
Epoch: 38 | Iteration number: [2870/4518] 63% | Training loss: 0.6870901528966551
Epoch: 38 | Iteration number: [2880/4518] 63% | Training loss: 0.6870887449011207
Epoch: 38 | Iteration number: [2890/4518] 63% | Training loss: 0.6870870044487158
Epoch: 38 | Iteration number: [2900/4518] 64% | Training loss: 0.6870858579051906
Epoch: 38 | Iteration number: [2910/4518] 64% | Training loss: 0.6870856568780551
Epoch: 38 | Iteration number: [2920/4518] 64% | Training loss: 0.6870847450135505
Epoch: 38 | Iteration number: [2930/4518] 64% | Training loss: 0.687083928454858
Epoch: 38 | Iteration number: [2940/4518] 65% | Training loss: 0.6870810672944906
Epoch: 38 | Iteration number: [2950/4518] 65% | Training loss: 0.687084245479713
Epoch: 38 | Iteration number: [2960/4518] 65% | Training loss: 0.6870842127783878
Epoch: 38 | Iteration number: [2970/4518] 65% | Training loss: 0.687083513166768
Epoch: 38 | Iteration number: [2980/4518] 65% | Training loss: 0.6870796244616476
Epoch: 38 | Iteration number: [2990/4518] 66% | Training loss: 0.6870791040136662
Epoch: 38 | Iteration number: [3000/4518] 66% | Training loss: 0.6870814041097959
Epoch: 38 | Iteration number: [3010/4518] 66% | Training loss: 0.6870805427679588
Epoch: 38 | Iteration number: [3020/4518] 66% | Training loss: 0.6870838531792559
Epoch: 38 | Iteration number: [3030/4518] 67% | Training loss: 0.6870810039169324
Epoch: 38 | Iteration number: [3040/4518] 67% | Training loss: 0.6870793836093263
Epoch: 38 | Iteration number: [3050/4518] 67% | Training loss: 0.6870773215958329
Epoch: 38 | Iteration number: [3060/4518] 67% | Training loss: 0.687074914633059
Epoch: 38 | Iteration number: [3070/4518] 67% | Training loss: 0.6870731438021707
Epoch: 38 | Iteration number: [3080/4518] 68% | Training loss: 0.6870702992011974
Epoch: 38 | Iteration number: [3090/4518] 68% | Training loss: 0.687067791019057
Epoch: 38 | Iteration number: [3100/4518] 68% | Training loss: 0.6870624730663915
Epoch: 38 | Iteration number: [3110/4518] 68% | Training loss: 0.6870640975102734
Epoch: 38 | Iteration number: [3120/4518] 69% | Training loss: 0.6870592332039124
Epoch: 38 | Iteration number: [3130/4518] 69% | Training loss: 0.6870617864802242
Epoch: 38 | Iteration number: [3140/4518] 69% | Training loss: 0.6870600870460462
Epoch: 38 | Iteration number: [3150/4518] 69% | Training loss: 0.6870563818348778
Epoch: 38 | Iteration number: [3160/4518] 69% | Training loss: 0.6870552689968785
Epoch: 38 | Iteration number: [3170/4518] 70% | Training loss: 0.6870584642661482
Epoch: 38 | Iteration number: [3180/4518] 70% | Training loss: 0.6870636605991507
Epoch: 38 | Iteration number: [3190/4518] 70% | Training loss: 0.6870653465810614
Epoch: 38 | Iteration number: [3200/4518] 70% | Training loss: 0.6870645166188478
Epoch: 38 | Iteration number: [3210/4518] 71% | Training loss: 0.6870643915231354
Epoch: 38 | Iteration number: [3220/4518] 71% | Training loss: 0.6870632328787205
Epoch: 38 | Iteration number: [3230/4518] 71% | Training loss: 0.6870644417894145
Epoch: 38 | Iteration number: [3240/4518] 71% | Training loss: 0.6870657745150872
Epoch: 38 | Iteration number: [3250/4518] 71% | Training loss: 0.6870643406831302
Epoch: 38 | Iteration number: [3260/4518] 72% | Training loss: 0.6870621633493096
Epoch: 38 | Iteration number: [3270/4518] 72% | Training loss: 0.6870596088218397
Epoch: 38 | Iteration number: [3280/4518] 72% | Training loss: 0.6870598920961706
Epoch: 38 | Iteration number: [3290/4518] 72% | Training loss: 0.6870582576761854
Epoch: 38 | Iteration number: [3300/4518] 73% | Training loss: 0.6870565339471355
Epoch: 38 | Iteration number: [3310/4518] 73% | Training loss: 0.6870568336857049
Epoch: 38 | Iteration number: [3320/4518] 73% | Training loss: 0.6870572209358216
Epoch: 38 | Iteration number: [3330/4518] 73% | Training loss: 0.6870516985207349
Epoch: 38 | Iteration number: [3340/4518] 73% | Training loss: 0.6870532533544266
Epoch: 38 | Iteration number: [3350/4518] 74% | Training loss: 0.6870518361988353
Epoch: 38 | Iteration number: [3360/4518] 74% | Training loss: 0.6870495617567074
Epoch: 38 | Iteration number: [3370/4518] 74% | Training loss: 0.6870497871930946
Epoch: 38 | Iteration number: [3380/4518] 74% | Training loss: 0.6870504761235954
Epoch: 38 | Iteration number: [3390/4518] 75% | Training loss: 0.6870498787688646
Epoch: 38 | Iteration number: [3400/4518] 75% | Training loss: 0.687045941370375
Epoch: 38 | Iteration number: [3410/4518] 75% | Training loss: 0.6870470230705228
Epoch: 38 | Iteration number: [3420/4518] 75% | Training loss: 0.6870447174847475
Epoch: 38 | Iteration number: [3430/4518] 75% | Training loss: 0.6870419906283954
Epoch: 38 | Iteration number: [3440/4518] 76% | Training loss: 0.687044735304838
Epoch: 38 | Iteration number: [3450/4518] 76% | Training loss: 0.6870421926180522
Epoch: 38 | Iteration number: [3460/4518] 76% | Training loss: 0.6870435154506926
Epoch: 38 | Iteration number: [3470/4518] 76% | Training loss: 0.6870435014410047
Epoch: 38 | Iteration number: [3480/4518] 77% | Training loss: 0.6870458680494078
Epoch: 38 | Iteration number: [3490/4518] 77% | Training loss: 0.6870486717852617
Epoch: 38 | Iteration number: [3500/4518] 77% | Training loss: 0.6870468986545291
Epoch: 38 | Iteration number: [3510/4518] 77% | Training loss: 0.6870479710760958
Epoch: 38 | Iteration number: [3520/4518] 77% | Training loss: 0.6870454977689819
Epoch: 38 | Iteration number: [3530/4518] 78% | Training loss: 0.6870462095264672
Epoch: 38 | Iteration number: [3540/4518] 78% | Training loss: 0.6870437492253416
Epoch: 38 | Iteration number: [3550/4518] 78% | Training loss: 0.6870405805446732
Epoch: 38 | Iteration number: [3560/4518] 78% | Training loss: 0.6870382791489698
Epoch: 38 | Iteration number: [3570/4518] 79% | Training loss: 0.6870393670907542
Epoch: 38 | Iteration number: [3580/4518] 79% | Training loss: 0.6870369654960472
Epoch: 38 | Iteration number: [3590/4518] 79% | Training loss: 0.6870386096096305
Epoch: 38 | Iteration number: [3600/4518] 79% | Training loss: 0.6870374642809232
Epoch: 38 | Iteration number: [3610/4518] 79% | Training loss: 0.6870365689996207
Epoch: 38 | Iteration number: [3620/4518] 80% | Training loss: 0.6870376621985304
Epoch: 38 | Iteration number: [3630/4518] 80% | Training loss: 0.6870325640541791
Epoch: 38 | Iteration number: [3640/4518] 80% | Training loss: 0.6870323785222494
Epoch: 38 | Iteration number: [3650/4518] 80% | Training loss: 0.6870316943893694
Epoch: 38 | Iteration number: [3660/4518] 81% | Training loss: 0.6870329954747946
Epoch: 38 | Iteration number: [3670/4518] 81% | Training loss: 0.6870344367111736
Epoch: 38 | Iteration number: [3680/4518] 81% | Training loss: 0.6870306655926549
Epoch: 38 | Iteration number: [3690/4518] 81% | Training loss: 0.6870304614709322
Epoch: 38 | Iteration number: [3700/4518] 81% | Training loss: 0.6870294669995437
Epoch: 38 | Iteration number: [3710/4518] 82% | Training loss: 0.6870302331897448
Epoch: 38 | Iteration number: [3720/4518] 82% | Training loss: 0.6870303322711299
Epoch: 38 | Iteration number: [3730/4518] 82% | Training loss: 0.6870305975544548
Epoch: 38 | Iteration number: [3740/4518] 82% | Training loss: 0.6870324510941531
Epoch: 38 | Iteration number: [3750/4518] 83% | Training loss: 0.6870313047568003
Epoch: 38 | Iteration number: [3760/4518] 83% | Training loss: 0.6870347081188192
Epoch: 38 | Iteration number: [3770/4518] 83% | Training loss: 0.6870345643407786
Epoch: 38 | Iteration number: [3780/4518] 83% | Training loss: 0.6870331536998193
Epoch: 38 | Iteration number: [3790/4518] 83% | Training loss: 0.6870304069135309
Epoch: 38 | Iteration number: [3800/4518] 84% | Training loss: 0.6870292082742641
Epoch: 38 | Iteration number: [3810/4518] 84% | Training loss: 0.6870264699609261
Epoch: 38 | Iteration number: [3820/4518] 84% | Training loss: 0.6870276086461482
Epoch: 38 | Iteration number: [3830/4518] 84% | Training loss: 0.6870265296794105
Epoch: 38 | Iteration number: [3840/4518] 84% | Training loss: 0.6870277157674233
Epoch: 38 | Iteration number: [3850/4518] 85% | Training loss: 0.6870296710342556
Epoch: 38 | Iteration number: [3860/4518] 85% | Training loss: 0.6870270332524195
Epoch: 38 | Iteration number: [3870/4518] 85% | Training loss: 0.6870266193413304
Epoch: 38 | Iteration number: [3880/4518] 85% | Training loss: 0.6870267501350531
Epoch: 38 | Iteration number: [3890/4518] 86% | Training loss: 0.6870283315144958
Epoch: 38 | Iteration number: [3900/4518] 86% | Training loss: 0.6870260537129182
Epoch: 38 | Iteration number: [3910/4518] 86% | Training loss: 0.6870223658164138
Epoch: 38 | Iteration number: [3920/4518] 86% | Training loss: 0.6870192271562255
Epoch: 38 | Iteration number: [3930/4518] 86% | Training loss: 0.6870175210877533
Epoch: 38 | Iteration number: [3940/4518] 87% | Training loss: 0.6870140999404307
Epoch: 38 | Iteration number: [3950/4518] 87% | Training loss: 0.6870139857485325
Epoch: 38 | Iteration number: [3960/4518] 87% | Training loss: 0.6870104042117042
Epoch: 38 | Iteration number: [3970/4518] 87% | Training loss: 0.687007684326292
Epoch: 38 | Iteration number: [3980/4518] 88% | Training loss: 0.6870044655985569
Epoch: 38 | Iteration number: [3990/4518] 88% | Training loss: 0.6870078386967642
Epoch: 38 | Iteration number: [4000/4518] 88% | Training loss: 0.6870057195425033
Epoch: 38 | Iteration number: [4010/4518] 88% | Training loss: 0.6870066113900068
Epoch: 38 | Iteration number: [4020/4518] 88% | Training loss: 0.6870046212453748
Epoch: 38 | Iteration number: [4030/4518] 89% | Training loss: 0.6870072383442825
Epoch: 38 | Iteration number: [4040/4518] 89% | Training loss: 0.6870067222578691
Epoch: 38 | Iteration number: [4050/4518] 89% | Training loss: 0.6870061642593808
Epoch: 38 | Iteration number: [4060/4518] 89% | Training loss: 0.6870053128362289
Epoch: 38 | Iteration number: [4070/4518] 90% | Training loss: 0.6870049351556295
Epoch: 38 | Iteration number: [4080/4518] 90% | Training loss: 0.6870036646577657
Epoch: 38 | Iteration number: [4090/4518] 90% | Training loss: 0.687003057247852
Epoch: 38 | Iteration number: [4100/4518] 90% | Training loss: 0.6870010558861058
Epoch: 38 | Iteration number: [4110/4518] 90% | Training loss: 0.6869971909082139
Epoch: 38 | Iteration number: [4120/4518] 91% | Training loss: 0.6869952498419771
Epoch: 38 | Iteration number: [4130/4518] 91% | Training loss: 0.6869938247428968
Epoch: 38 | Iteration number: [4140/4518] 91% | Training loss: 0.6869952955395703
Epoch: 38 | Iteration number: [4150/4518] 91% | Training loss: 0.686992687389075
Epoch: 38 | Iteration number: [4160/4518] 92% | Training loss: 0.6869930317338843
Epoch: 38 | Iteration number: [4170/4518] 92% | Training loss: 0.6869923419231991
Epoch: 38 | Iteration number: [4180/4518] 92% | Training loss: 0.6869909649402901
Epoch: 38 | Iteration number: [4190/4518] 92% | Training loss: 0.6869900655490402
Epoch: 38 | Iteration number: [4200/4518] 92% | Training loss: 0.6869879296705836
Epoch: 38 | Iteration number: [4210/4518] 93% | Training loss: 0.6869909520103926
Epoch: 38 | Iteration number: [4220/4518] 93% | Training loss: 0.6869901350182944
Epoch: 38 | Iteration number: [4230/4518] 93% | Training loss: 0.6869895527126095
Epoch: 38 | Iteration number: [4240/4518] 93% | Training loss: 0.6869873229343936
Epoch: 38 | Iteration number: [4250/4518] 94% | Training loss: 0.6869872137378243
Epoch: 38 | Iteration number: [4260/4518] 94% | Training loss: 0.686985677508681
Epoch: 38 | Iteration number: [4270/4518] 94% | Training loss: 0.6869893129871377
Epoch: 38 | Iteration number: [4280/4518] 94% | Training loss: 0.6869916007619038
Epoch: 38 | Iteration number: [4290/4518] 94% | Training loss: 0.6869902616197413
Epoch: 38 | Iteration number: [4300/4518] 95% | Training loss: 0.6869866483156071
Epoch: 38 | Iteration number: [4310/4518] 95% | Training loss: 0.6869881785939298
Epoch: 38 | Iteration number: [4320/4518] 95% | Training loss: 0.6869878394874158
Epoch: 38 | Iteration number: [4330/4518] 95% | Training loss: 0.6869881219318777
Epoch: 38 | Iteration number: [4340/4518] 96% | Training loss: 0.6869882950035657
Epoch: 38 | Iteration number: [4350/4518] 96% | Training loss: 0.6869879458827534
Epoch: 38 | Iteration number: [4360/4518] 96% | Training loss: 0.6869903119195492
Epoch: 38 | Iteration number: [4370/4518] 96% | Training loss: 0.6869917867249155
Epoch: 38 | Iteration number: [4380/4518] 96% | Training loss: 0.6869910006109438
Epoch: 38 | Iteration number: [4390/4518] 97% | Training loss: 0.686989542998051
Epoch: 38 | Iteration number: [4400/4518] 97% | Training loss: 0.6869905317642472
Epoch: 38 | Iteration number: [4410/4518] 97% | Training loss: 0.6869929215129541
Epoch: 38 | Iteration number: [4420/4518] 97% | Training loss: 0.6869939793963238
Epoch: 38 | Iteration number: [4430/4518] 98% | Training loss: 0.686992967882221
Epoch: 38 | Iteration number: [4440/4518] 98% | Training loss: 0.6869908864165212
Epoch: 38 | Iteration number: [4450/4518] 98% | Training loss: 0.6869885240913777
Epoch: 38 | Iteration number: [4460/4518] 98% | Training loss: 0.6869897471281445
Epoch: 38 | Iteration number: [4470/4518] 98% | Training loss: 0.6869918183325654
Epoch: 38 | Iteration number: [4480/4518] 99% | Training loss: 0.6869904492848686
Epoch: 38 | Iteration number: [4490/4518] 99% | Training loss: 0.6869884162809377
Epoch: 38 | Iteration number: [4500/4518] 99% | Training loss: 0.6869876466857062
Epoch: 38 | Iteration number: [4510/4518] 99% | Training loss: 0.6869865451049382

 End of epoch: 38 | Train Loss: 0.6868327744057771 | Training Time: 632 

 End of epoch: 38 | Eval Loss: 0.6898689695766994 | Evaluating Time: 17 
Epoch: 39 | Iteration number: [10/4518] 0% | Training loss: 0.7538411855697632
Epoch: 39 | Iteration number: [20/4518] 0% | Training loss: 0.7196698635816574
Epoch: 39 | Iteration number: [30/4518] 0% | Training loss: 0.7087184270222981
Epoch: 39 | Iteration number: [40/4518] 0% | Training loss: 0.7029524967074394
Epoch: 39 | Iteration number: [50/4518] 1% | Training loss: 0.6999087238311767
Epoch: 39 | Iteration number: [60/4518] 1% | Training loss: 0.6978931158781052
Epoch: 39 | Iteration number: [70/4518] 1% | Training loss: 0.6963956866945539
Epoch: 39 | Iteration number: [80/4518] 1% | Training loss: 0.6949706979095935
Epoch: 39 | Iteration number: [90/4518] 1% | Training loss: 0.6941152069303724
Epoch: 39 | Iteration number: [100/4518] 2% | Training loss: 0.693377400636673
Epoch: 39 | Iteration number: [110/4518] 2% | Training loss: 0.6926820527423512
Epoch: 39 | Iteration number: [120/4518] 2% | Training loss: 0.6922035530209542
Epoch: 39 | Iteration number: [130/4518] 2% | Training loss: 0.691857162805704
Epoch: 39 | Iteration number: [140/4518] 3% | Training loss: 0.6914768721376147
Epoch: 39 | Iteration number: [150/4518] 3% | Training loss: 0.6911952181657155
Epoch: 39 | Iteration number: [160/4518] 3% | Training loss: 0.6909082189202309
Epoch: 39 | Iteration number: [170/4518] 3% | Training loss: 0.6906637296957128
Epoch: 39 | Iteration number: [180/4518] 3% | Training loss: 0.6903319865465164
Epoch: 39 | Iteration number: [190/4518] 4% | Training loss: 0.6901566445827484
Epoch: 39 | Iteration number: [200/4518] 4% | Training loss: 0.6899593484401703
Epoch: 39 | Iteration number: [210/4518] 4% | Training loss: 0.6898401240507762
Epoch: 39 | Iteration number: [220/4518] 4% | Training loss: 0.689698864384131
Epoch: 39 | Iteration number: [230/4518] 5% | Training loss: 0.6895871553732001
Epoch: 39 | Iteration number: [240/4518] 5% | Training loss: 0.6894503297905127
Epoch: 39 | Iteration number: [250/4518] 5% | Training loss: 0.6893784217834472
Epoch: 39 | Iteration number: [260/4518] 5% | Training loss: 0.6892832056834147
Epoch: 39 | Iteration number: [270/4518] 5% | Training loss: 0.689202324770115
Epoch: 39 | Iteration number: [280/4518] 6% | Training loss: 0.6890789172479085
Epoch: 39 | Iteration number: [290/4518] 6% | Training loss: 0.6889903859845523
Epoch: 39 | Iteration number: [300/4518] 6% | Training loss: 0.6889165167013804
Epoch: 39 | Iteration number: [310/4518] 6% | Training loss: 0.6888461410999298
Epoch: 39 | Iteration number: [320/4518] 7% | Training loss: 0.6888121301308274
Epoch: 39 | Iteration number: [330/4518] 7% | Training loss: 0.6887717857505335
Epoch: 39 | Iteration number: [340/4518] 7% | Training loss: 0.6886902225368163
Epoch: 39 | Iteration number: [350/4518] 7% | Training loss: 0.6886366735185896
Epoch: 39 | Iteration number: [360/4518] 7% | Training loss: 0.6885864833990732
Epoch: 39 | Iteration number: [370/4518] 8% | Training loss: 0.6885351464555071
Epoch: 39 | Iteration number: [380/4518] 8% | Training loss: 0.6885059639027244
Epoch: 39 | Iteration number: [390/4518] 8% | Training loss: 0.6884444433909196
Epoch: 39 | Iteration number: [400/4518] 8% | Training loss: 0.6884010830521583
Epoch: 39 | Iteration number: [410/4518] 9% | Training loss: 0.6883730670300926
Epoch: 39 | Iteration number: [420/4518] 9% | Training loss: 0.688344336549441
Epoch: 39 | Iteration number: [430/4518] 9% | Training loss: 0.6882917487344077
Epoch: 39 | Iteration number: [440/4518] 9% | Training loss: 0.6882913907820528
Epoch: 39 | Iteration number: [450/4518] 9% | Training loss: 0.6882774409982894
Epoch: 39 | Iteration number: [460/4518] 10% | Training loss: 0.6882535895575648
Epoch: 39 | Iteration number: [470/4518] 10% | Training loss: 0.6882194515238417
Epoch: 39 | Iteration number: [480/4518] 10% | Training loss: 0.6882153547058503
Epoch: 39 | Iteration number: [490/4518] 10% | Training loss: 0.6881900187657803
Epoch: 39 | Iteration number: [500/4518] 11% | Training loss: 0.6881730436086655
Epoch: 39 | Iteration number: [510/4518] 11% | Training loss: 0.6881481958370582
Epoch: 39 | Iteration number: [520/4518] 11% | Training loss: 0.6881168582118474
Epoch: 39 | Iteration number: [530/4518] 11% | Training loss: 0.6881053212678657
Epoch: 39 | Iteration number: [540/4518] 11% | Training loss: 0.6880692531665166
Epoch: 39 | Iteration number: [550/4518] 12% | Training loss: 0.6880352840640328
Epoch: 39 | Iteration number: [560/4518] 12% | Training loss: 0.6880309658391135
Epoch: 39 | Iteration number: [570/4518] 12% | Training loss: 0.6880053780580822
Epoch: 39 | Iteration number: [580/4518] 12% | Training loss: 0.6879942007105926
Epoch: 39 | Iteration number: [590/4518] 13% | Training loss: 0.6879728305137763
Epoch: 39 | Iteration number: [600/4518] 13% | Training loss: 0.6879536140958468
Epoch: 39 | Iteration number: [610/4518] 13% | Training loss: 0.6879447868612946
Epoch: 39 | Iteration number: [620/4518] 13% | Training loss: 0.6878993535234083
Epoch: 39 | Iteration number: [630/4518] 13% | Training loss: 0.6878789578165326
Epoch: 39 | Iteration number: [640/4518] 14% | Training loss: 0.6878407341428101
Epoch: 39 | Iteration number: [650/4518] 14% | Training loss: 0.6878294763198266
Epoch: 39 | Iteration number: [660/4518] 14% | Training loss: 0.687817658258207
Epoch: 39 | Iteration number: [670/4518] 14% | Training loss: 0.687821324013952
Epoch: 39 | Iteration number: [680/4518] 15% | Training loss: 0.6878105993656551
Epoch: 39 | Iteration number: [690/4518] 15% | Training loss: 0.6878005886423415
Epoch: 39 | Iteration number: [700/4518] 15% | Training loss: 0.6877597205127989
Epoch: 39 | Iteration number: [710/4518] 15% | Training loss: 0.6877580892032301
Epoch: 39 | Iteration number: [720/4518] 15% | Training loss: 0.6877334425846736
Epoch: 39 | Iteration number: [730/4518] 16% | Training loss: 0.6877211044912469
Epoch: 39 | Iteration number: [740/4518] 16% | Training loss: 0.6877228437243281
Epoch: 39 | Iteration number: [750/4518] 16% | Training loss: 0.6876973796685537
Epoch: 39 | Iteration number: [760/4518] 16% | Training loss: 0.687692201294397
Epoch: 39 | Iteration number: [770/4518] 17% | Training loss: 0.6876735014574868
Epoch: 39 | Iteration number: [780/4518] 17% | Training loss: 0.687671378102058
Epoch: 39 | Iteration number: [790/4518] 17% | Training loss: 0.68765562274788
Epoch: 39 | Iteration number: [800/4518] 17% | Training loss: 0.6876450430601835
Epoch: 39 | Iteration number: [810/4518] 17% | Training loss: 0.6876354109357905
Epoch: 39 | Iteration number: [820/4518] 18% | Training loss: 0.687637948481048
Epoch: 39 | Iteration number: [830/4518] 18% | Training loss: 0.6876256672014673
Epoch: 39 | Iteration number: [840/4518] 18% | Training loss: 0.6876126599453745
Epoch: 39 | Iteration number: [850/4518] 18% | Training loss: 0.6876032592969782
Epoch: 39 | Iteration number: [860/4518] 19% | Training loss: 0.6875967364671618
Epoch: 39 | Iteration number: [870/4518] 19% | Training loss: 0.6875961316042933
Epoch: 39 | Iteration number: [880/4518] 19% | Training loss: 0.6875938972966238
Epoch: 39 | Iteration number: [890/4518] 19% | Training loss: 0.6876041851016913
Epoch: 39 | Iteration number: [900/4518] 19% | Training loss: 0.6876022717025545
Epoch: 39 | Iteration number: [910/4518] 20% | Training loss: 0.6875918153223101
Epoch: 39 | Iteration number: [920/4518] 20% | Training loss: 0.68759148788193
Epoch: 39 | Iteration number: [930/4518] 20% | Training loss: 0.6875721607156979
Epoch: 39 | Iteration number: [940/4518] 20% | Training loss: 0.6875656185632056
Epoch: 39 | Iteration number: [950/4518] 21% | Training loss: 0.687565223417784
Epoch: 39 | Iteration number: [960/4518] 21% | Training loss: 0.687568357338508
Epoch: 39 | Iteration number: [970/4518] 21% | Training loss: 0.6875546816698055
Epoch: 39 | Iteration number: [980/4518] 21% | Training loss: 0.6875537003181419
Epoch: 39 | Iteration number: [990/4518] 21% | Training loss: 0.6875454472773003
Epoch: 39 | Iteration number: [1000/4518] 22% | Training loss: 0.6875310260653495
Epoch: 39 | Iteration number: [1010/4518] 22% | Training loss: 0.6875147699719608
Epoch: 39 | Iteration number: [1020/4518] 22% | Training loss: 0.687514598287788
Epoch: 39 | Iteration number: [1030/4518] 22% | Training loss: 0.6875056545711258
Epoch: 39 | Iteration number: [1040/4518] 23% | Training loss: 0.6874944288570147
Epoch: 39 | Iteration number: [1050/4518] 23% | Training loss: 0.6874865466072446
Epoch: 39 | Iteration number: [1060/4518] 23% | Training loss: 0.6874780796608835
Epoch: 39 | Iteration number: [1070/4518] 23% | Training loss: 0.6874772434479722
Epoch: 39 | Iteration number: [1080/4518] 23% | Training loss: 0.687475856034844
Epoch: 39 | Iteration number: [1090/4518] 24% | Training loss: 0.6874702926622618
Epoch: 39 | Iteration number: [1100/4518] 24% | Training loss: 0.6874637965722518
Epoch: 39 | Iteration number: [1110/4518] 24% | Training loss: 0.6874593768033895
Epoch: 39 | Iteration number: [1120/4518] 24% | Training loss: 0.6874469390405076
Epoch: 39 | Iteration number: [1130/4518] 25% | Training loss: 0.6874432189274678
Epoch: 39 | Iteration number: [1140/4518] 25% | Training loss: 0.6874363117050706
Epoch: 39 | Iteration number: [1150/4518] 25% | Training loss: 0.6874290525913238
Epoch: 39 | Iteration number: [1160/4518] 25% | Training loss: 0.6874261791336125
Epoch: 39 | Iteration number: [1170/4518] 25% | Training loss: 0.6874202414965018
Epoch: 39 | Iteration number: [1180/4518] 26% | Training loss: 0.6874065192574161
Epoch: 39 | Iteration number: [1190/4518] 26% | Training loss: 0.6874039175129738
Epoch: 39 | Iteration number: [1200/4518] 26% | Training loss: 0.687408639540275
Epoch: 39 | Iteration number: [1210/4518] 26% | Training loss: 0.6874100310743347
Epoch: 39 | Iteration number: [1220/4518] 27% | Training loss: 0.6874166839435453
Epoch: 39 | Iteration number: [1230/4518] 27% | Training loss: 0.6874151977581706
Epoch: 39 | Iteration number: [1240/4518] 27% | Training loss: 0.6874180738483706
Epoch: 39 | Iteration number: [1250/4518] 27% | Training loss: 0.6874141330242157
Epoch: 39 | Iteration number: [1260/4518] 27% | Training loss: 0.6874111118297729
Epoch: 39 | Iteration number: [1270/4518] 28% | Training loss: 0.6874051533815428
Epoch: 39 | Iteration number: [1280/4518] 28% | Training loss: 0.6874006454832852
Epoch: 39 | Iteration number: [1290/4518] 28% | Training loss: 0.6874038476352544
Epoch: 39 | Iteration number: [1300/4518] 28% | Training loss: 0.6873961820510718
Epoch: 39 | Iteration number: [1310/4518] 28% | Training loss: 0.6873926276924046
Epoch: 39 | Iteration number: [1320/4518] 29% | Training loss: 0.6873990216941545
Epoch: 39 | Iteration number: [1330/4518] 29% | Training loss: 0.6873923741785207
Epoch: 39 | Iteration number: [1340/4518] 29% | Training loss: 0.6873716568768914
Epoch: 39 | Iteration number: [1350/4518] 29% | Training loss: 0.6873607995775011
Epoch: 39 | Iteration number: [1360/4518] 30% | Training loss: 0.6873664321268306
Epoch: 39 | Iteration number: [1370/4518] 30% | Training loss: 0.6873595469624457
Epoch: 39 | Iteration number: [1380/4518] 30% | Training loss: 0.6873597589091979
Epoch: 39 | Iteration number: [1390/4518] 30% | Training loss: 0.6873603099970509
Epoch: 39 | Iteration number: [1400/4518] 30% | Training loss: 0.6873586738109588
Epoch: 39 | Iteration number: [1410/4518] 31% | Training loss: 0.6873570351313192
Epoch: 39 | Iteration number: [1420/4518] 31% | Training loss: 0.6873516655723814
Epoch: 39 | Iteration number: [1430/4518] 31% | Training loss: 0.6873523663807583
Epoch: 39 | Iteration number: [1440/4518] 31% | Training loss: 0.6873456618852085
Epoch: 39 | Iteration number: [1450/4518] 32% | Training loss: 0.6873366307801214
Epoch: 39 | Iteration number: [1460/4518] 32% | Training loss: 0.6873331495752073
Epoch: 39 | Iteration number: [1470/4518] 32% | Training loss: 0.6873244048786812
Epoch: 39 | Iteration number: [1480/4518] 32% | Training loss: 0.6873141248483916
Epoch: 39 | Iteration number: [1490/4518] 32% | Training loss: 0.6873111741654825
Epoch: 39 | Iteration number: [1500/4518] 33% | Training loss: 0.6873083662589391
Epoch: 39 | Iteration number: [1510/4518] 33% | Training loss: 0.6873133416207421
Epoch: 39 | Iteration number: [1520/4518] 33% | Training loss: 0.6873073795908375
Epoch: 39 | Iteration number: [1530/4518] 33% | Training loss: 0.6873062641402475
Epoch: 39 | Iteration number: [1540/4518] 34% | Training loss: 0.6872960088701991
Epoch: 39 | Iteration number: [1550/4518] 34% | Training loss: 0.6872929322335027
Epoch: 39 | Iteration number: [1560/4518] 34% | Training loss: 0.6872914297458453
Epoch: 39 | Iteration number: [1570/4518] 34% | Training loss: 0.687286447415686
Epoch: 39 | Iteration number: [1580/4518] 34% | Training loss: 0.6872913559780846
Epoch: 39 | Iteration number: [1590/4518] 35% | Training loss: 0.687285607603361
Epoch: 39 | Iteration number: [1600/4518] 35% | Training loss: 0.6872748362645507
Epoch: 39 | Iteration number: [1610/4518] 35% | Training loss: 0.6872765906849263
Epoch: 39 | Iteration number: [1620/4518] 35% | Training loss: 0.6872700523079177
Epoch: 39 | Iteration number: [1630/4518] 36% | Training loss: 0.6872580172094099
Epoch: 39 | Iteration number: [1640/4518] 36% | Training loss: 0.687250950096584
Epoch: 39 | Iteration number: [1650/4518] 36% | Training loss: 0.6872481709538084
Epoch: 39 | Iteration number: [1660/4518] 36% | Training loss: 0.687248628398022
Epoch: 39 | Iteration number: [1670/4518] 36% | Training loss: 0.6872426210049384
Epoch: 39 | Iteration number: [1680/4518] 37% | Training loss: 0.6872422525570506
Epoch: 39 | Iteration number: [1690/4518] 37% | Training loss: 0.6872488453896088
Epoch: 39 | Iteration number: [1700/4518] 37% | Training loss: 0.6872448027133942
Epoch: 39 | Iteration number: [1710/4518] 37% | Training loss: 0.6872406276694515
Epoch: 39 | Iteration number: [1720/4518] 38% | Training loss: 0.6872430574755336
Epoch: 39 | Iteration number: [1730/4518] 38% | Training loss: 0.6872423266055266
Epoch: 39 | Iteration number: [1740/4518] 38% | Training loss: 0.6872414605028327
Epoch: 39 | Iteration number: [1750/4518] 38% | Training loss: 0.6872436322484697
Epoch: 39 | Iteration number: [1760/4518] 38% | Training loss: 0.687244198132645
Epoch: 39 | Iteration number: [1770/4518] 39% | Training loss: 0.6872470373824492
Epoch: 39 | Iteration number: [1780/4518] 39% | Training loss: 0.687243155883939
Epoch: 39 | Iteration number: [1790/4518] 39% | Training loss: 0.6872437269994001
Epoch: 39 | Iteration number: [1800/4518] 39% | Training loss: 0.68723701003525
Epoch: 39 | Iteration number: [1810/4518] 40% | Training loss: 0.6872375303869089
Epoch: 39 | Iteration number: [1820/4518] 40% | Training loss: 0.6872304014124713
Epoch: 39 | Iteration number: [1830/4518] 40% | Training loss: 0.687233321067414
Epoch: 39 | Iteration number: [1840/4518] 40% | Training loss: 0.687236071669537
Epoch: 39 | Iteration number: [1850/4518] 40% | Training loss: 0.6872378766536713
Epoch: 39 | Iteration number: [1860/4518] 41% | Training loss: 0.6872348634786504
Epoch: 39 | Iteration number: [1870/4518] 41% | Training loss: 0.6872382540116335
Epoch: 39 | Iteration number: [1880/4518] 41% | Training loss: 0.687237427050763
Epoch: 39 | Iteration number: [1890/4518] 41% | Training loss: 0.6872350422478227
Epoch: 39 | Iteration number: [1900/4518] 42% | Training loss: 0.687227999222906
Epoch: 39 | Iteration number: [1910/4518] 42% | Training loss: 0.687221301850224
Epoch: 39 | Iteration number: [1920/4518] 42% | Training loss: 0.6872240123338997
Epoch: 39 | Iteration number: [1930/4518] 42% | Training loss: 0.6872144205273741
Epoch: 39 | Iteration number: [1940/4518] 42% | Training loss: 0.6872159032477546
Epoch: 39 | Iteration number: [1950/4518] 43% | Training loss: 0.6872186728012868
Epoch: 39 | Iteration number: [1960/4518] 43% | Training loss: 0.6872203507897805
Epoch: 39 | Iteration number: [1970/4518] 43% | Training loss: 0.6872127678793699
Epoch: 39 | Iteration number: [1980/4518] 43% | Training loss: 0.6872093132348975
Epoch: 39 | Iteration number: [1990/4518] 44% | Training loss: 0.6871978477916526
Epoch: 39 | Iteration number: [2000/4518] 44% | Training loss: 0.6871990393102169
Epoch: 39 | Iteration number: [2010/4518] 44% | Training loss: 0.6872045314134057
Epoch: 39 | Iteration number: [2020/4518] 44% | Training loss: 0.6872030464139315
Epoch: 39 | Iteration number: [2030/4518] 44% | Training loss: 0.687203766941437
Epoch: 39 | Iteration number: [2040/4518] 45% | Training loss: 0.6872024497857281
Epoch: 39 | Iteration number: [2050/4518] 45% | Training loss: 0.6872065596754958
Epoch: 39 | Iteration number: [2060/4518] 45% | Training loss: 0.6872071664310196
Epoch: 39 | Iteration number: [2070/4518] 45% | Training loss: 0.6872091139860199
Epoch: 39 | Iteration number: [2080/4518] 46% | Training loss: 0.6872030261330879
Epoch: 39 | Iteration number: [2090/4518] 46% | Training loss: 0.6872058835326199
Epoch: 39 | Iteration number: [2100/4518] 46% | Training loss: 0.6872028246663866
Epoch: 39 | Iteration number: [2110/4518] 46% | Training loss: 0.6871992897648382
Epoch: 39 | Iteration number: [2120/4518] 46% | Training loss: 0.6871965549183342
Epoch: 39 | Iteration number: [2130/4518] 47% | Training loss: 0.6871968507766724
Epoch: 39 | Iteration number: [2140/4518] 47% | Training loss: 0.6871889195431059
Epoch: 39 | Iteration number: [2150/4518] 47% | Training loss: 0.6871892889155898
Epoch: 39 | Iteration number: [2160/4518] 47% | Training loss: 0.6871887405437452
Epoch: 39 | Iteration number: [2170/4518] 48% | Training loss: 0.6871919620421625
Epoch: 39 | Iteration number: [2180/4518] 48% | Training loss: 0.6871861623788099
Epoch: 39 | Iteration number: [2190/4518] 48% | Training loss: 0.6871905734277751
Epoch: 39 | Iteration number: [2200/4518] 48% | Training loss: 0.6871905917200175
Epoch: 39 | Iteration number: [2210/4518] 48% | Training loss: 0.6871880735207467
Epoch: 39 | Iteration number: [2220/4518] 49% | Training loss: 0.6871889683845881
Epoch: 39 | Iteration number: [2230/4518] 49% | Training loss: 0.687188201527959
Epoch: 39 | Iteration number: [2240/4518] 49% | Training loss: 0.6871827201917767
Epoch: 39 | Iteration number: [2250/4518] 49% | Training loss: 0.6871807033750746
Epoch: 39 | Iteration number: [2260/4518] 50% | Training loss: 0.6871773026949537
Epoch: 39 | Iteration number: [2270/4518] 50% | Training loss: 0.6871756110684987
Epoch: 39 | Iteration number: [2280/4518] 50% | Training loss: 0.687171972739069
Epoch: 39 | Iteration number: [2290/4518] 50% | Training loss: 0.6871742747756592
Epoch: 39 | Iteration number: [2300/4518] 50% | Training loss: 0.687170716886935
Epoch: 39 | Iteration number: [2310/4518] 51% | Training loss: 0.687169776540814
Epoch: 39 | Iteration number: [2320/4518] 51% | Training loss: 0.6871687958209679
Epoch: 39 | Iteration number: [2330/4518] 51% | Training loss: 0.6871642807266742
Epoch: 39 | Iteration number: [2340/4518] 51% | Training loss: 0.6871646030845805
Epoch: 39 | Iteration number: [2350/4518] 52% | Training loss: 0.6871680114117075
Epoch: 39 | Iteration number: [2360/4518] 52% | Training loss: 0.6871654311226586
Epoch: 39 | Iteration number: [2370/4518] 52% | Training loss: 0.6871695954588395
Epoch: 39 | Iteration number: [2380/4518] 52% | Training loss: 0.687164770955799
Epoch: 39 | Iteration number: [2390/4518] 52% | Training loss: 0.6871601415478534
Epoch: 39 | Iteration number: [2400/4518] 53% | Training loss: 0.6871601176013549
Epoch: 39 | Iteration number: [2410/4518] 53% | Training loss: 0.6871563036906768
Epoch: 39 | Iteration number: [2420/4518] 53% | Training loss: 0.6871528390764204
Epoch: 39 | Iteration number: [2430/4518] 53% | Training loss: 0.6871515248783331
Epoch: 39 | Iteration number: [2440/4518] 54% | Training loss: 0.687146548877974
Epoch: 39 | Iteration number: [2450/4518] 54% | Training loss: 0.6871456848358621
Epoch: 39 | Iteration number: [2460/4518] 54% | Training loss: 0.6871321626310426
Epoch: 39 | Iteration number: [2470/4518] 54% | Training loss: 0.6871340153912301
Epoch: 39 | Iteration number: [2480/4518] 54% | Training loss: 0.6871331124055771
Epoch: 39 | Iteration number: [2490/4518] 55% | Training loss: 0.6871316132057144
Epoch: 39 | Iteration number: [2500/4518] 55% | Training loss: 0.6871325345277787
Epoch: 39 | Iteration number: [2510/4518] 55% | Training loss: 0.6871369163116136
Epoch: 39 | Iteration number: [2520/4518] 55% | Training loss: 0.6871369529101584
Epoch: 39 | Iteration number: [2530/4518] 55% | Training loss: 0.6871348403894855
Epoch: 39 | Iteration number: [2540/4518] 56% | Training loss: 0.6871342176058161
Epoch: 39 | Iteration number: [2550/4518] 56% | Training loss: 0.6871323043224858
Epoch: 39 | Iteration number: [2560/4518] 56% | Training loss: 0.6871278704842553
Epoch: 39 | Iteration number: [2570/4518] 56% | Training loss: 0.6871215535045134
Epoch: 39 | Iteration number: [2580/4518] 57% | Training loss: 0.6871212341526682
Epoch: 39 | Iteration number: [2590/4518] 57% | Training loss: 0.6871219377720218
Epoch: 39 | Iteration number: [2600/4518] 57% | Training loss: 0.6871150240072837
Epoch: 39 | Iteration number: [2610/4518] 57% | Training loss: 0.6871152076684652
Epoch: 39 | Iteration number: [2620/4518] 57% | Training loss: 0.687114375442949
Epoch: 39 | Iteration number: [2630/4518] 58% | Training loss: 0.6871074390048764
Epoch: 39 | Iteration number: [2640/4518] 58% | Training loss: 0.6871069831830082
Epoch: 39 | Iteration number: [2650/4518] 58% | Training loss: 0.6871047259051845
Epoch: 39 | Iteration number: [2660/4518] 58% | Training loss: 0.6871031140250371
Epoch: 39 | Iteration number: [2670/4518] 59% | Training loss: 0.6871053028419223
Epoch: 39 | Iteration number: [2680/4518] 59% | Training loss: 0.6871021321237977
Epoch: 39 | Iteration number: [2690/4518] 59% | Training loss: 0.687100105746528
Epoch: 39 | Iteration number: [2700/4518] 59% | Training loss: 0.68709969010618
Epoch: 39 | Iteration number: [2710/4518] 59% | Training loss: 0.6871004021695619
Epoch: 39 | Iteration number: [2720/4518] 60% | Training loss: 0.6871002357453108
Epoch: 39 | Iteration number: [2730/4518] 60% | Training loss: 0.6870984857553964
Epoch: 39 | Iteration number: [2740/4518] 60% | Training loss: 0.6870997943147256
Epoch: 39 | Iteration number: [2750/4518] 60% | Training loss: 0.6871006991863251
Epoch: 39 | Iteration number: [2760/4518] 61% | Training loss: 0.6870991951313572
Epoch: 39 | Iteration number: [2770/4518] 61% | Training loss: 0.6871002486466501
Epoch: 39 | Iteration number: [2780/4518] 61% | Training loss: 0.6871051484732319
Epoch: 39 | Iteration number: [2790/4518] 61% | Training loss: 0.6870983839035034
Epoch: 39 | Iteration number: [2800/4518] 61% | Training loss: 0.6871002028456756
Epoch: 39 | Iteration number: [2810/4518] 62% | Training loss: 0.6871001260772719
Epoch: 39 | Iteration number: [2820/4518] 62% | Training loss: 0.6870989933927009
Epoch: 39 | Iteration number: [2830/4518] 62% | Training loss: 0.6870960250128284
Epoch: 39 | Iteration number: [2840/4518] 62% | Training loss: 0.6870982089093034
Epoch: 39 | Iteration number: [2850/4518] 63% | Training loss: 0.6870992594225365
Epoch: 39 | Iteration number: [2860/4518] 63% | Training loss: 0.6871023950460073
Epoch: 39 | Iteration number: [2870/4518] 63% | Training loss: 0.6871042828734328
Epoch: 39 | Iteration number: [2880/4518] 63% | Training loss: 0.6871021581399772
Epoch: 39 | Iteration number: [2890/4518] 63% | Training loss: 0.6871007683574122
Epoch: 39 | Iteration number: [2900/4518] 64% | Training loss: 0.6871001644175628
Epoch: 39 | Iteration number: [2910/4518] 64% | Training loss: 0.6870980435630301
Epoch: 39 | Iteration number: [2920/4518] 64% | Training loss: 0.6870965625937671
Epoch: 39 | Iteration number: [2930/4518] 64% | Training loss: 0.687091347788788
Epoch: 39 | Iteration number: [2940/4518] 65% | Training loss: 0.6870929877774246
Epoch: 39 | Iteration number: [2950/4518] 65% | Training loss: 0.6870947932590873
Epoch: 39 | Iteration number: [2960/4518] 65% | Training loss: 0.6870950488625346
Epoch: 39 | Iteration number: [2970/4518] 65% | Training loss: 0.687091921455531
Epoch: 39 | Iteration number: [2980/4518] 65% | Training loss: 0.6870921904208677
Epoch: 39 | Iteration number: [2990/4518] 66% | Training loss: 0.6870921104050002
Epoch: 39 | Iteration number: [3000/4518] 66% | Training loss: 0.6870905963977177
Epoch: 39 | Iteration number: [3010/4518] 66% | Training loss: 0.6870878483369897
Epoch: 39 | Iteration number: [3020/4518] 66% | Training loss: 0.6870859162302206
Epoch: 39 | Iteration number: [3030/4518] 67% | Training loss: 0.6870860925208617
Epoch: 39 | Iteration number: [3040/4518] 67% | Training loss: 0.6870877060843141
Epoch: 39 | Iteration number: [3050/4518] 67% | Training loss: 0.6870860688412775
Epoch: 39 | Iteration number: [3060/4518] 67% | Training loss: 0.6870845537170086
Epoch: 39 | Iteration number: [3070/4518] 67% | Training loss: 0.6870856137928046
Epoch: 39 | Iteration number: [3080/4518] 68% | Training loss: 0.6870863035708279
Epoch: 39 | Iteration number: [3090/4518] 68% | Training loss: 0.6870871926588534
Epoch: 39 | Iteration number: [3100/4518] 68% | Training loss: 0.6870847790279696
Epoch: 39 | Iteration number: [3110/4518] 68% | Training loss: 0.6870849234881509
Epoch: 39 | Iteration number: [3120/4518] 69% | Training loss: 0.687084054068113
Epoch: 39 | Iteration number: [3130/4518] 69% | Training loss: 0.6870816425012705
Epoch: 39 | Iteration number: [3140/4518] 69% | Training loss: 0.6870808145422844
Epoch: 39 | Iteration number: [3150/4518] 69% | Training loss: 0.6870781033758133
Epoch: 39 | Iteration number: [3160/4518] 69% | Training loss: 0.6870774644650991
Epoch: 39 | Iteration number: [3170/4518] 70% | Training loss: 0.687078841101108
Epoch: 39 | Iteration number: [3180/4518] 70% | Training loss: 0.6870755704318953
Epoch: 39 | Iteration number: [3190/4518] 70% | Training loss: 0.6870752673164057
Epoch: 39 | Iteration number: [3200/4518] 70% | Training loss: 0.6870753790065646
Epoch: 39 | Iteration number: [3210/4518] 71% | Training loss: 0.6870750164317193
Epoch: 39 | Iteration number: [3220/4518] 71% | Training loss: 0.6870727967216361
Epoch: 39 | Iteration number: [3230/4518] 71% | Training loss: 0.6870706482937462
Epoch: 39 | Iteration number: [3240/4518] 71% | Training loss: 0.6870749734802011
Epoch: 39 | Iteration number: [3250/4518] 71% | Training loss: 0.6870689738530379
Epoch: 39 | Iteration number: [3260/4518] 72% | Training loss: 0.6870688638438477
Epoch: 39 | Iteration number: [3270/4518] 72% | Training loss: 0.6870714414010354
Epoch: 39 | Iteration number: [3280/4518] 72% | Training loss: 0.6870706681979866
Epoch: 39 | Iteration number: [3290/4518] 72% | Training loss: 0.6870680145579631
Epoch: 39 | Iteration number: [3300/4518] 73% | Training loss: 0.6870675647078138
Epoch: 39 | Iteration number: [3310/4518] 73% | Training loss: 0.6870699023011948
Epoch: 39 | Iteration number: [3320/4518] 73% | Training loss: 0.6870681709912886
Epoch: 39 | Iteration number: [3330/4518] 73% | Training loss: 0.6870715365216539
Epoch: 39 | Iteration number: [3340/4518] 73% | Training loss: 0.6870744300459674
Epoch: 39 | Iteration number: [3350/4518] 74% | Training loss: 0.68707131962278
Epoch: 39 | Iteration number: [3360/4518] 74% | Training loss: 0.6870715768919105
Epoch: 39 | Iteration number: [3370/4518] 74% | Training loss: 0.6870673878787179
Epoch: 39 | Iteration number: [3380/4518] 74% | Training loss: 0.6870649967496917
Epoch: 39 | Iteration number: [3390/4518] 75% | Training loss: 0.6870654622713724
Epoch: 39 | Iteration number: [3400/4518] 75% | Training loss: 0.6870625111986609
Epoch: 39 | Iteration number: [3410/4518] 75% | Training loss: 0.687064840646783
Epoch: 39 | Iteration number: [3420/4518] 75% | Training loss: 0.68706284409378
Epoch: 39 | Iteration number: [3430/4518] 75% | Training loss: 0.6870658802395312
Epoch: 39 | Iteration number: [3440/4518] 76% | Training loss: 0.6870600776963456
Epoch: 39 | Iteration number: [3450/4518] 76% | Training loss: 0.6870593494090481
Epoch: 39 | Iteration number: [3460/4518] 76% | Training loss: 0.6870585526861896
Epoch: 39 | Iteration number: [3470/4518] 76% | Training loss: 0.687054209149193
Epoch: 39 | Iteration number: [3480/4518] 77% | Training loss: 0.6870503367534999
Epoch: 39 | Iteration number: [3490/4518] 77% | Training loss: 0.6870476924075096
Epoch: 39 | Iteration number: [3500/4518] 77% | Training loss: 0.6870475610154015
Epoch: 39 | Iteration number: [3510/4518] 77% | Training loss: 0.6870461746498391
Epoch: 39 | Iteration number: [3520/4518] 77% | Training loss: 0.6870464930310846
Epoch: 39 | Iteration number: [3530/4518] 78% | Training loss: 0.687047379398481
Epoch: 39 | Iteration number: [3540/4518] 78% | Training loss: 0.6870448657179956
Epoch: 39 | Iteration number: [3550/4518] 78% | Training loss: 0.6870425169064965
Epoch: 39 | Iteration number: [3560/4518] 78% | Training loss: 0.6870446194088861
Epoch: 39 | Iteration number: [3570/4518] 79% | Training loss: 0.6870413847330238
Epoch: 39 | Iteration number: [3580/4518] 79% | Training loss: 0.6870374165600238
Epoch: 39 | Iteration number: [3590/4518] 79% | Training loss: 0.6870340440598703
Epoch: 39 | Iteration number: [3600/4518] 79% | Training loss: 0.6870359574258328
Epoch: 39 | Iteration number: [3610/4518] 79% | Training loss: 0.6870319320224328
Epoch: 39 | Iteration number: [3620/4518] 80% | Training loss: 0.6870322748936343
Epoch: 39 | Iteration number: [3630/4518] 80% | Training loss: 0.6870298636353706
Epoch: 39 | Iteration number: [3640/4518] 80% | Training loss: 0.6870306708655515
Epoch: 39 | Iteration number: [3650/4518] 80% | Training loss: 0.6870305721400535
Epoch: 39 | Iteration number: [3660/4518] 81% | Training loss: 0.6870271270229517
Epoch: 39 | Iteration number: [3670/4518] 81% | Training loss: 0.6870279738623699
Epoch: 39 | Iteration number: [3680/4518] 81% | Training loss: 0.6870292902640674
Epoch: 39 | Iteration number: [3690/4518] 81% | Training loss: 0.6870310443688215
Epoch: 39 | Iteration number: [3700/4518] 81% | Training loss: 0.6870314460187344
Epoch: 39 | Iteration number: [3710/4518] 82% | Training loss: 0.6870279830421078
Epoch: 39 | Iteration number: [3720/4518] 82% | Training loss: 0.687031163980243
Epoch: 39 | Iteration number: [3730/4518] 82% | Training loss: 0.6870299047023937
Epoch: 39 | Iteration number: [3740/4518] 82% | Training loss: 0.6870298392154316
Epoch: 39 | Iteration number: [3750/4518] 83% | Training loss: 0.6870292958736419
Epoch: 39 | Iteration number: [3760/4518] 83% | Training loss: 0.6870295532523317
Epoch: 39 | Iteration number: [3770/4518] 83% | Training loss: 0.6870340501123777
Epoch: 39 | Iteration number: [3780/4518] 83% | Training loss: 0.6870330005095749
Epoch: 39 | Iteration number: [3790/4518] 83% | Training loss: 0.6870338106218303
Epoch: 39 | Iteration number: [3800/4518] 84% | Training loss: 0.6870293845471583
Epoch: 39 | Iteration number: [3810/4518] 84% | Training loss: 0.6870290022353175
Epoch: 39 | Iteration number: [3820/4518] 84% | Training loss: 0.6870303683568045
Epoch: 39 | Iteration number: [3830/4518] 84% | Training loss: 0.6870299503323926
Epoch: 39 | Iteration number: [3840/4518] 84% | Training loss: 0.6870272049835573
Epoch: 39 | Iteration number: [3850/4518] 85% | Training loss: 0.6870277082765257
Epoch: 39 | Iteration number: [3860/4518] 85% | Training loss: 0.6870250878401989
Epoch: 39 | Iteration number: [3870/4518] 85% | Training loss: 0.6870220079440479
Epoch: 39 | Iteration number: [3880/4518] 85% | Training loss: 0.6870202274666619
Epoch: 39 | Iteration number: [3890/4518] 86% | Training loss: 0.6870207840801817
Epoch: 39 | Iteration number: [3900/4518] 86% | Training loss: 0.6870199109499271
Epoch: 39 | Iteration number: [3910/4518] 86% | Training loss: 0.6870181803813066
Epoch: 39 | Iteration number: [3920/4518] 86% | Training loss: 0.6870164561788646
Epoch: 39 | Iteration number: [3930/4518] 86% | Training loss: 0.6870168008573789
Epoch: 39 | Iteration number: [3940/4518] 87% | Training loss: 0.6870163601667143
Epoch: 39 | Iteration number: [3950/4518] 87% | Training loss: 0.6870162406903279
Epoch: 39 | Iteration number: [3960/4518] 87% | Training loss: 0.6870178594131663
Epoch: 39 | Iteration number: [3970/4518] 87% | Training loss: 0.6870149942579438
Epoch: 39 | Iteration number: [3980/4518] 88% | Training loss: 0.6870135304466564
Epoch: 39 | Iteration number: [3990/4518] 88% | Training loss: 0.6870122140511534
Epoch: 39 | Iteration number: [4000/4518] 88% | Training loss: 0.6870123704969883
Epoch: 39 | Iteration number: [4010/4518] 88% | Training loss: 0.6870140557723152
Epoch: 39 | Iteration number: [4020/4518] 88% | Training loss: 0.6870116215143631
Epoch: 39 | Iteration number: [4030/4518] 89% | Training loss: 0.6870120211807137
Epoch: 39 | Iteration number: [4040/4518] 89% | Training loss: 0.6870104683950395
Epoch: 39 | Iteration number: [4050/4518] 89% | Training loss: 0.6870119287202388
Epoch: 39 | Iteration number: [4060/4518] 89% | Training loss: 0.687010372008009
Epoch: 39 | Iteration number: [4070/4518] 90% | Training loss: 0.6870115743222343
Epoch: 39 | Iteration number: [4080/4518] 90% | Training loss: 0.6870084617944324
Epoch: 39 | Iteration number: [4090/4518] 90% | Training loss: 0.6870084206166069
Epoch: 39 | Iteration number: [4100/4518] 90% | Training loss: 0.6870075954460516
Epoch: 39 | Iteration number: [4110/4518] 90% | Training loss: 0.6870050224654576
Epoch: 39 | Iteration number: [4120/4518] 91% | Training loss: 0.6870032651187147
Epoch: 39 | Iteration number: [4130/4518] 91% | Training loss: 0.6870038495802706
Epoch: 39 | Iteration number: [4140/4518] 91% | Training loss: 0.6870030533720329
Epoch: 39 | Iteration number: [4150/4518] 91% | Training loss: 0.6870035010648061
Epoch: 39 | Iteration number: [4160/4518] 92% | Training loss: 0.6870045526096454
Epoch: 39 | Iteration number: [4170/4518] 92% | Training loss: 0.6870045171938925
Epoch: 39 | Iteration number: [4180/4518] 92% | Training loss: 0.6870052837726602
Epoch: 39 | Iteration number: [4190/4518] 92% | Training loss: 0.6870009273930779
Epoch: 39 | Iteration number: [4200/4518] 92% | Training loss: 0.6870021875273614
Epoch: 39 | Iteration number: [4210/4518] 93% | Training loss: 0.6870031574134872
Epoch: 39 | Iteration number: [4220/4518] 93% | Training loss: 0.6870028230251294
Epoch: 39 | Iteration number: [4230/4518] 93% | Training loss: 0.6870021385644908
Epoch: 39 | Iteration number: [4240/4518] 93% | Training loss: 0.6870036161030239
Epoch: 39 | Iteration number: [4250/4518] 94% | Training loss: 0.6870058180163888
Epoch: 39 | Iteration number: [4260/4518] 94% | Training loss: 0.6870048340357525
Epoch: 39 | Iteration number: [4270/4518] 94% | Training loss: 0.6870055066897104
Epoch: 39 | Iteration number: [4280/4518] 94% | Training loss: 0.6870041434731439
Epoch: 39 | Iteration number: [4290/4518] 94% | Training loss: 0.6870033304869156
Epoch: 39 | Iteration number: [4300/4518] 95% | Training loss: 0.6870046203358229
Epoch: 39 | Iteration number: [4310/4518] 95% | Training loss: 0.6870036516001495
Epoch: 39 | Iteration number: [4320/4518] 95% | Training loss: 0.6870006663793767
Epoch: 39 | Iteration number: [4330/4518] 95% | Training loss: 0.6870016363008469
Epoch: 39 | Iteration number: [4340/4518] 96% | Training loss: 0.6870015621459978
Epoch: 39 | Iteration number: [4350/4518] 96% | Training loss: 0.6870026209573636
Epoch: 39 | Iteration number: [4360/4518] 96% | Training loss: 0.6870016638018669
Epoch: 39 | Iteration number: [4370/4518] 96% | Training loss: 0.6870018720763226
Epoch: 39 | Iteration number: [4380/4518] 96% | Training loss: 0.6869975420165824
Epoch: 39 | Iteration number: [4390/4518] 97% | Training loss: 0.6869970730741366
Epoch: 39 | Iteration number: [4400/4518] 97% | Training loss: 0.6869927425140684
Epoch: 39 | Iteration number: [4410/4518] 97% | Training loss: 0.6869915798542992
Epoch: 39 | Iteration number: [4420/4518] 97% | Training loss: 0.6869936434796493
Epoch: 39 | Iteration number: [4430/4518] 98% | Training loss: 0.6869945220430602
Epoch: 39 | Iteration number: [4440/4518] 98% | Training loss: 0.6869955008362865
Epoch: 39 | Iteration number: [4450/4518] 98% | Training loss: 0.6869925182588984
Epoch: 39 | Iteration number: [4460/4518] 98% | Training loss: 0.6869910934848101
Epoch: 39 | Iteration number: [4470/4518] 98% | Training loss: 0.6869896465366585
Epoch: 39 | Iteration number: [4480/4518] 99% | Training loss: 0.6869870122256023
Epoch: 39 | Iteration number: [4490/4518] 99% | Training loss: 0.6869851608451597
Epoch: 39 | Iteration number: [4500/4518] 99% | Training loss: 0.6869827540980445
Epoch: 39 | Iteration number: [4510/4518] 99% | Training loss: 0.6869821505773887

 End of epoch: 39 | Train Loss: 0.6868283078569182 | Training Time: 632 

 End of epoch: 39 | Eval Loss: 0.6898051488156222 | Evaluating Time: 17 
Epoch: 40 | Iteration number: [10/4518] 0% | Training loss: 0.7561526477336884
Epoch: 40 | Iteration number: [20/4518] 0% | Training loss: 0.7220744341611862
Epoch: 40 | Iteration number: [30/4518] 0% | Training loss: 0.710360997915268
Epoch: 40 | Iteration number: [40/4518] 0% | Training loss: 0.7039222732186318
Epoch: 40 | Iteration number: [50/4518] 1% | Training loss: 0.7005272901058197
Epoch: 40 | Iteration number: [60/4518] 1% | Training loss: 0.6982353597879409
Epoch: 40 | Iteration number: [70/4518] 1% | Training loss: 0.6965379629816327
Epoch: 40 | Iteration number: [80/4518] 1% | Training loss: 0.6951150692999363
Epoch: 40 | Iteration number: [90/4518] 1% | Training loss: 0.6940359115600586
Epoch: 40 | Iteration number: [100/4518] 2% | Training loss: 0.6932750719785691
Epoch: 40 | Iteration number: [110/4518] 2% | Training loss: 0.6925984122536399
Epoch: 40 | Iteration number: [120/4518] 2% | Training loss: 0.6920270010828972
Epoch: 40 | Iteration number: [130/4518] 2% | Training loss: 0.6915478972288278
Epoch: 40 | Iteration number: [140/4518] 3% | Training loss: 0.6911963390452521
Epoch: 40 | Iteration number: [150/4518] 3% | Training loss: 0.6908331727981567
Epoch: 40 | Iteration number: [160/4518] 3% | Training loss: 0.6904631961137057
Epoch: 40 | Iteration number: [170/4518] 3% | Training loss: 0.6902464074247023
Epoch: 40 | Iteration number: [180/4518] 3% | Training loss: 0.69010608361827
Epoch: 40 | Iteration number: [190/4518] 4% | Training loss: 0.6899632143346887
Epoch: 40 | Iteration number: [200/4518] 4% | Training loss: 0.6897855353355408
Epoch: 40 | Iteration number: [210/4518] 4% | Training loss: 0.6897112500099909
Epoch: 40 | Iteration number: [220/4518] 4% | Training loss: 0.6896003465760838
Epoch: 40 | Iteration number: [230/4518] 5% | Training loss: 0.6895110855931821
Epoch: 40 | Iteration number: [240/4518] 5% | Training loss: 0.6894162587821484
Epoch: 40 | Iteration number: [250/4518] 5% | Training loss: 0.68928875041008
Epoch: 40 | Iteration number: [260/4518] 5% | Training loss: 0.6891800559484041
Epoch: 40 | Iteration number: [270/4518] 5% | Training loss: 0.6890831278430091
Epoch: 40 | Iteration number: [280/4518] 6% | Training loss: 0.6890032972608294
Epoch: 40 | Iteration number: [290/4518] 6% | Training loss: 0.6889353178698441
Epoch: 40 | Iteration number: [300/4518] 6% | Training loss: 0.6888801179329554
Epoch: 40 | Iteration number: [310/4518] 6% | Training loss: 0.6888084384702867
Epoch: 40 | Iteration number: [320/4518] 7% | Training loss: 0.688702286966145
Epoch: 40 | Iteration number: [330/4518] 7% | Training loss: 0.6886379440625509
Epoch: 40 | Iteration number: [340/4518] 7% | Training loss: 0.6885301593471976
Epoch: 40 | Iteration number: [350/4518] 7% | Training loss: 0.6884746365887778
Epoch: 40 | Iteration number: [360/4518] 7% | Training loss: 0.6884527857104937
Epoch: 40 | Iteration number: [370/4518] 8% | Training loss: 0.688402090523694
Epoch: 40 | Iteration number: [380/4518] 8% | Training loss: 0.6883360078460292
Epoch: 40 | Iteration number: [390/4518] 8% | Training loss: 0.6883028750236218
Epoch: 40 | Iteration number: [400/4518] 8% | Training loss: 0.6882190865278244
Epoch: 40 | Iteration number: [410/4518] 9% | Training loss: 0.6881888580031511
Epoch: 40 | Iteration number: [420/4518] 9% | Training loss: 0.6881796459356944
Epoch: 40 | Iteration number: [430/4518] 9% | Training loss: 0.6881294064743574
Epoch: 40 | Iteration number: [440/4518] 9% | Training loss: 0.6880990689451044
Epoch: 40 | Iteration number: [450/4518] 9% | Training loss: 0.6880793586042192
Epoch: 40 | Iteration number: [460/4518] 10% | Training loss: 0.688074559232463
Epoch: 40 | Iteration number: [470/4518] 10% | Training loss: 0.6880872756876844
Epoch: 40 | Iteration number: [480/4518] 10% | Training loss: 0.6880717355757952
Epoch: 40 | Iteration number: [490/4518] 10% | Training loss: 0.6880715472357614
Epoch: 40 | Iteration number: [500/4518] 11% | Training loss: 0.6880526858568191
Epoch: 40 | Iteration number: [510/4518] 11% | Training loss: 0.6880433180752923
Epoch: 40 | Iteration number: [520/4518] 11% | Training loss: 0.6880275670152444
Epoch: 40 | Iteration number: [530/4518] 11% | Training loss: 0.6879881826211821
Epoch: 40 | Iteration number: [540/4518] 11% | Training loss: 0.6879806996495635
Epoch: 40 | Iteration number: [550/4518] 12% | Training loss: 0.687948408018459
Epoch: 40 | Iteration number: [560/4518] 12% | Training loss: 0.6879388366426741
Epoch: 40 | Iteration number: [570/4518] 12% | Training loss: 0.6879205880457895
Epoch: 40 | Iteration number: [580/4518] 12% | Training loss: 0.6879055975840009
Epoch: 40 | Iteration number: [590/4518] 13% | Training loss: 0.6878718037726516
Epoch: 40 | Iteration number: [600/4518] 13% | Training loss: 0.6878698573509852
Epoch: 40 | Iteration number: [610/4518] 13% | Training loss: 0.6878399077986107
Epoch: 40 | Iteration number: [620/4518] 13% | Training loss: 0.6878362772926208
Epoch: 40 | Iteration number: [630/4518] 13% | Training loss: 0.687819188549405
Epoch: 40 | Iteration number: [640/4518] 14% | Training loss: 0.6877831707708537
Epoch: 40 | Iteration number: [650/4518] 14% | Training loss: 0.687761569573329
Epoch: 40 | Iteration number: [660/4518] 14% | Training loss: 0.6877551701935855
Epoch: 40 | Iteration number: [670/4518] 14% | Training loss: 0.6877386053106678
Epoch: 40 | Iteration number: [680/4518] 15% | Training loss: 0.6877087140784545
Epoch: 40 | Iteration number: [690/4518] 15% | Training loss: 0.6877030475416045
Epoch: 40 | Iteration number: [700/4518] 15% | Training loss: 0.6876932387692588
Epoch: 40 | Iteration number: [710/4518] 15% | Training loss: 0.6876816403697914
Epoch: 40 | Iteration number: [720/4518] 15% | Training loss: 0.6876549723247687
Epoch: 40 | Iteration number: [730/4518] 16% | Training loss: 0.6876494664851933
Epoch: 40 | Iteration number: [740/4518] 16% | Training loss: 0.6876496440655476
Epoch: 40 | Iteration number: [750/4518] 16% | Training loss: 0.6876468308766683
Epoch: 40 | Iteration number: [760/4518] 16% | Training loss: 0.6876242638418549
Epoch: 40 | Iteration number: [770/4518] 17% | Training loss: 0.6876141631758058
Epoch: 40 | Iteration number: [780/4518] 17% | Training loss: 0.6875891469992124
Epoch: 40 | Iteration number: [790/4518] 17% | Training loss: 0.6875705931760088
Epoch: 40 | Iteration number: [800/4518] 17% | Training loss: 0.6875729865580797
Epoch: 40 | Iteration number: [810/4518] 17% | Training loss: 0.6875684905935217
Epoch: 40 | Iteration number: [820/4518] 18% | Training loss: 0.6875575098322659
Epoch: 40 | Iteration number: [830/4518] 18% | Training loss: 0.6875472728028355
Epoch: 40 | Iteration number: [840/4518] 18% | Training loss: 0.6875538127053351
Epoch: 40 | Iteration number: [850/4518] 18% | Training loss: 0.6875564842364368
Epoch: 40 | Iteration number: [860/4518] 19% | Training loss: 0.6875526205051777
Epoch: 40 | Iteration number: [870/4518] 19% | Training loss: 0.6875612855642691
Epoch: 40 | Iteration number: [880/4518] 19% | Training loss: 0.6875570730052211
Epoch: 40 | Iteration number: [890/4518] 19% | Training loss: 0.6875322485907694
Epoch: 40 | Iteration number: [900/4518] 19% | Training loss: 0.6875336003303528
Epoch: 40 | Iteration number: [910/4518] 20% | Training loss: 0.6875141471951872
Epoch: 40 | Iteration number: [920/4518] 20% | Training loss: 0.6875014339452205
Epoch: 40 | Iteration number: [930/4518] 20% | Training loss: 0.6875020636025295
Epoch: 40 | Iteration number: [940/4518] 20% | Training loss: 0.6874924891172571
Epoch: 40 | Iteration number: [950/4518] 21% | Training loss: 0.6874819858450638
Epoch: 40 | Iteration number: [960/4518] 21% | Training loss: 0.6874828631058335
Epoch: 40 | Iteration number: [970/4518] 21% | Training loss: 0.6874771357811603
Epoch: 40 | Iteration number: [980/4518] 21% | Training loss: 0.6874525833494809
Epoch: 40 | Iteration number: [990/4518] 21% | Training loss: 0.6874418040116628
Epoch: 40 | Iteration number: [1000/4518] 22% | Training loss: 0.6874402402043343
Epoch: 40 | Iteration number: [1010/4518] 22% | Training loss: 0.6874340036127827
Epoch: 40 | Iteration number: [1020/4518] 22% | Training loss: 0.6874156903402479
Epoch: 40 | Iteration number: [1030/4518] 22% | Training loss: 0.687414747302972
Epoch: 40 | Iteration number: [1040/4518] 23% | Training loss: 0.6874050691723823
Epoch: 40 | Iteration number: [1050/4518] 23% | Training loss: 0.6873985669726417
Epoch: 40 | Iteration number: [1060/4518] 23% | Training loss: 0.6873931862273306
Epoch: 40 | Iteration number: [1070/4518] 23% | Training loss: 0.6873845890860691
Epoch: 40 | Iteration number: [1080/4518] 23% | Training loss: 0.6873735870476122
Epoch: 40 | Iteration number: [1090/4518] 24% | Training loss: 0.687363481357557
Epoch: 40 | Iteration number: [1100/4518] 24% | Training loss: 0.687372571500865
Epoch: 40 | Iteration number: [1110/4518] 24% | Training loss: 0.6873751922770663
Epoch: 40 | Iteration number: [1120/4518] 24% | Training loss: 0.6873742118477821
Epoch: 40 | Iteration number: [1130/4518] 25% | Training loss: 0.6873665564883071
Epoch: 40 | Iteration number: [1140/4518] 25% | Training loss: 0.6873731032798165
Epoch: 40 | Iteration number: [1150/4518] 25% | Training loss: 0.6873668899743454
Epoch: 40 | Iteration number: [1160/4518] 25% | Training loss: 0.687358656371462
Epoch: 40 | Iteration number: [1170/4518] 25% | Training loss: 0.6873608802118872
Epoch: 40 | Iteration number: [1180/4518] 26% | Training loss: 0.6873502973782815
Epoch: 40 | Iteration number: [1190/4518] 26% | Training loss: 0.6873403456030773
Epoch: 40 | Iteration number: [1200/4518] 26% | Training loss: 0.6873396660387516
Epoch: 40 | Iteration number: [1210/4518] 26% | Training loss: 0.6873292391457834
Epoch: 40 | Iteration number: [1220/4518] 27% | Training loss: 0.6873294676913589
Epoch: 40 | Iteration number: [1230/4518] 27% | Training loss: 0.6873241844700604
Epoch: 40 | Iteration number: [1240/4518] 27% | Training loss: 0.6873175150925114
Epoch: 40 | Iteration number: [1250/4518] 27% | Training loss: 0.6873173496723175
Epoch: 40 | Iteration number: [1260/4518] 27% | Training loss: 0.6873027576340569
Epoch: 40 | Iteration number: [1270/4518] 28% | Training loss: 0.687298612097117
Epoch: 40 | Iteration number: [1280/4518] 28% | Training loss: 0.6872892063111067
Epoch: 40 | Iteration number: [1290/4518] 28% | Training loss: 0.6872971562914146
Epoch: 40 | Iteration number: [1300/4518] 28% | Training loss: 0.6872880517519437
Epoch: 40 | Iteration number: [1310/4518] 28% | Training loss: 0.6872869142594228
Epoch: 40 | Iteration number: [1320/4518] 29% | Training loss: 0.6872784342729684
Epoch: 40 | Iteration number: [1330/4518] 29% | Training loss: 0.6872804894035024
Epoch: 40 | Iteration number: [1340/4518] 29% | Training loss: 0.6872824995375392
Epoch: 40 | Iteration number: [1350/4518] 29% | Training loss: 0.6872858416592633
Epoch: 40 | Iteration number: [1360/4518] 30% | Training loss: 0.6872782552066972
Epoch: 40 | Iteration number: [1370/4518] 30% | Training loss: 0.6872704980147146
Epoch: 40 | Iteration number: [1380/4518] 30% | Training loss: 0.6872679288836493
Epoch: 40 | Iteration number: [1390/4518] 30% | Training loss: 0.6872591829128403
Epoch: 40 | Iteration number: [1400/4518] 30% | Training loss: 0.6872612965532712
Epoch: 40 | Iteration number: [1410/4518] 31% | Training loss: 0.6872635484164489
Epoch: 40 | Iteration number: [1420/4518] 31% | Training loss: 0.6872627280127834
Epoch: 40 | Iteration number: [1430/4518] 31% | Training loss: 0.6872556153294089
Epoch: 40 | Iteration number: [1440/4518] 31% | Training loss: 0.6872497841301891
Epoch: 40 | Iteration number: [1450/4518] 32% | Training loss: 0.6872469743366899
Epoch: 40 | Iteration number: [1460/4518] 32% | Training loss: 0.6872484867295173
Epoch: 40 | Iteration number: [1470/4518] 32% | Training loss: 0.6872429520905423
Epoch: 40 | Iteration number: [1480/4518] 32% | Training loss: 0.6872404549170185
Epoch: 40 | Iteration number: [1490/4518] 32% | Training loss: 0.6872349329042755
Epoch: 40 | Iteration number: [1500/4518] 33% | Training loss: 0.6872435563405355
Epoch: 40 | Iteration number: [1510/4518] 33% | Training loss: 0.6872461386074293
Epoch: 40 | Iteration number: [1520/4518] 33% | Training loss: 0.6872415940228261
Epoch: 40 | Iteration number: [1530/4518] 33% | Training loss: 0.6872382152703852
Epoch: 40 | Iteration number: [1540/4518] 34% | Training loss: 0.6872387496294914
Epoch: 40 | Iteration number: [1550/4518] 34% | Training loss: 0.6872352842361696
Epoch: 40 | Iteration number: [1560/4518] 34% | Training loss: 0.6872291247049968
Epoch: 40 | Iteration number: [1570/4518] 34% | Training loss: 0.6872251699684532
Epoch: 40 | Iteration number: [1580/4518] 34% | Training loss: 0.687213498995274
Epoch: 40 | Iteration number: [1590/4518] 35% | Training loss: 0.6872157361522411
Epoch: 40 | Iteration number: [1600/4518] 35% | Training loss: 0.6872157771140337
Epoch: 40 | Iteration number: [1610/4518] 35% | Training loss: 0.6872155343523677
Epoch: 40 | Iteration number: [1620/4518] 35% | Training loss: 0.6872191082548212
Epoch: 40 | Iteration number: [1630/4518] 36% | Training loss: 0.6872143059420439
Epoch: 40 | Iteration number: [1640/4518] 36% | Training loss: 0.6872124320850139
Epoch: 40 | Iteration number: [1650/4518] 36% | Training loss: 0.6872079729311394
Epoch: 40 | Iteration number: [1660/4518] 36% | Training loss: 0.6871983143938594
Epoch: 40 | Iteration number: [1670/4518] 36% | Training loss: 0.6871949949307357
Epoch: 40 | Iteration number: [1680/4518] 37% | Training loss: 0.6871912029527483
Epoch: 40 | Iteration number: [1690/4518] 37% | Training loss: 0.6871847912757354
Epoch: 40 | Iteration number: [1700/4518] 37% | Training loss: 0.687185529295136
Epoch: 40 | Iteration number: [1710/4518] 37% | Training loss: 0.6871821423023068
Epoch: 40 | Iteration number: [1720/4518] 38% | Training loss: 0.6871856860296671
Epoch: 40 | Iteration number: [1730/4518] 38% | Training loss: 0.6871866965224978
Epoch: 40 | Iteration number: [1740/4518] 38% | Training loss: 0.6871818231782694
Epoch: 40 | Iteration number: [1750/4518] 38% | Training loss: 0.6871803914478847
Epoch: 40 | Iteration number: [1760/4518] 38% | Training loss: 0.6871782114559953
Epoch: 40 | Iteration number: [1770/4518] 39% | Training loss: 0.6871775800898924
Epoch: 40 | Iteration number: [1780/4518] 39% | Training loss: 0.687185117234005
Epoch: 40 | Iteration number: [1790/4518] 39% | Training loss: 0.6871809250149647
Epoch: 40 | Iteration number: [1800/4518] 39% | Training loss: 0.6871759825944901
Epoch: 40 | Iteration number: [1810/4518] 40% | Training loss: 0.6871709097156209
Epoch: 40 | Iteration number: [1820/4518] 40% | Training loss: 0.6871699469757604
Epoch: 40 | Iteration number: [1830/4518] 40% | Training loss: 0.6871626056934315
Epoch: 40 | Iteration number: [1840/4518] 40% | Training loss: 0.6871649324570013
Epoch: 40 | Iteration number: [1850/4518] 40% | Training loss: 0.6871729111349261
Epoch: 40 | Iteration number: [1860/4518] 41% | Training loss: 0.6871725026317822
Epoch: 40 | Iteration number: [1870/4518] 41% | Training loss: 0.6871755824688284
Epoch: 40 | Iteration number: [1880/4518] 41% | Training loss: 0.6871723877939772
Epoch: 40 | Iteration number: [1890/4518] 41% | Training loss: 0.6871601409697659
Epoch: 40 | Iteration number: [1900/4518] 42% | Training loss: 0.6871615151982559
Epoch: 40 | Iteration number: [1910/4518] 42% | Training loss: 0.6871590039492902
Epoch: 40 | Iteration number: [1920/4518] 42% | Training loss: 0.6871559513111909
Epoch: 40 | Iteration number: [1930/4518] 42% | Training loss: 0.6871511395422288
Epoch: 40 | Iteration number: [1940/4518] 42% | Training loss: 0.6871507813942801
Epoch: 40 | Iteration number: [1950/4518] 43% | Training loss: 0.6871504597786146
Epoch: 40 | Iteration number: [1960/4518] 43% | Training loss: 0.6871453852677832
Epoch: 40 | Iteration number: [1970/4518] 43% | Training loss: 0.6871504975757018
Epoch: 40 | Iteration number: [1980/4518] 43% | Training loss: 0.6871385759777493
Epoch: 40 | Iteration number: [1990/4518] 44% | Training loss: 0.6871371493567174
Epoch: 40 | Iteration number: [2000/4518] 44% | Training loss: 0.6871409282982349
Epoch: 40 | Iteration number: [2010/4518] 44% | Training loss: 0.6871325304555655
Epoch: 40 | Iteration number: [2020/4518] 44% | Training loss: 0.6871274467742089
Epoch: 40 | Iteration number: [2030/4518] 44% | Training loss: 0.6871252502420265
Epoch: 40 | Iteration number: [2040/4518] 45% | Training loss: 0.6871196173569736
Epoch: 40 | Iteration number: [2050/4518] 45% | Training loss: 0.6871218089068808
Epoch: 40 | Iteration number: [2060/4518] 45% | Training loss: 0.687112878595741
Epoch: 40 | Iteration number: [2070/4518] 45% | Training loss: 0.6871120999112798
Epoch: 40 | Iteration number: [2080/4518] 46% | Training loss: 0.6871064809365914
Epoch: 40 | Iteration number: [2090/4518] 46% | Training loss: 0.6871007940985939
Epoch: 40 | Iteration number: [2100/4518] 46% | Training loss: 0.6870988313924699
Epoch: 40 | Iteration number: [2110/4518] 46% | Training loss: 0.6871019665663841
Epoch: 40 | Iteration number: [2120/4518] 46% | Training loss: 0.6870919440714818
Epoch: 40 | Iteration number: [2130/4518] 47% | Training loss: 0.687088387952724
Epoch: 40 | Iteration number: [2140/4518] 47% | Training loss: 0.6870908289312202
Epoch: 40 | Iteration number: [2150/4518] 47% | Training loss: 0.6870911219508149
Epoch: 40 | Iteration number: [2160/4518] 47% | Training loss: 0.6870931782656245
Epoch: 40 | Iteration number: [2170/4518] 48% | Training loss: 0.6870917357332695
Epoch: 40 | Iteration number: [2180/4518] 48% | Training loss: 0.6870873176996861
Epoch: 40 | Iteration number: [2190/4518] 48% | Training loss: 0.6870884521911134
Epoch: 40 | Iteration number: [2200/4518] 48% | Training loss: 0.6870879232883453
Epoch: 40 | Iteration number: [2210/4518] 48% | Training loss: 0.6870821368100956
Epoch: 40 | Iteration number: [2220/4518] 49% | Training loss: 0.6870788505485466
Epoch: 40 | Iteration number: [2230/4518] 49% | Training loss: 0.6870748823533678
Epoch: 40 | Iteration number: [2240/4518] 49% | Training loss: 0.687072422674724
Epoch: 40 | Iteration number: [2250/4518] 49% | Training loss: 0.6870719374815623
Epoch: 40 | Iteration number: [2260/4518] 50% | Training loss: 0.6870708191553049
Epoch: 40 | Iteration number: [2270/4518] 50% | Training loss: 0.6870656061802667
Epoch: 40 | Iteration number: [2280/4518] 50% | Training loss: 0.6870665818714259
Epoch: 40 | Iteration number: [2290/4518] 50% | Training loss: 0.6870671563013152
Epoch: 40 | Iteration number: [2300/4518] 50% | Training loss: 0.6870641465549884
Epoch: 40 | Iteration number: [2310/4518] 51% | Training loss: 0.6870637201901638
Epoch: 40 | Iteration number: [2320/4518] 51% | Training loss: 0.6870644121848304
Epoch: 40 | Iteration number: [2330/4518] 51% | Training loss: 0.6870651961651995
Epoch: 40 | Iteration number: [2340/4518] 51% | Training loss: 0.687063275061102
Epoch: 40 | Iteration number: [2350/4518] 52% | Training loss: 0.6870575715633149
Epoch: 40 | Iteration number: [2360/4518] 52% | Training loss: 0.6870605396517252
Epoch: 40 | Iteration number: [2370/4518] 52% | Training loss: 0.6870523596866221
Epoch: 40 | Iteration number: [2380/4518] 52% | Training loss: 0.6870522455007089
Epoch: 40 | Iteration number: [2390/4518] 52% | Training loss: 0.6870545162815429
Epoch: 40 | Iteration number: [2400/4518] 53% | Training loss: 0.6870544321089983
Epoch: 40 | Iteration number: [2410/4518] 53% | Training loss: 0.6870481100072504
Epoch: 40 | Iteration number: [2420/4518] 53% | Training loss: 0.6870458070650574
Epoch: 40 | Iteration number: [2430/4518] 53% | Training loss: 0.6870444688777374
Epoch: 40 | Iteration number: [2440/4518] 54% | Training loss: 0.6870476894447061
Epoch: 40 | Iteration number: [2450/4518] 54% | Training loss: 0.6870477898023566
Epoch: 40 | Iteration number: [2460/4518] 54% | Training loss: 0.6870453014606382
Epoch: 40 | Iteration number: [2470/4518] 54% | Training loss: 0.6870437619657169
Epoch: 40 | Iteration number: [2480/4518] 54% | Training loss: 0.6870442339729879
Epoch: 40 | Iteration number: [2490/4518] 55% | Training loss: 0.687044192006789
Epoch: 40 | Iteration number: [2500/4518] 55% | Training loss: 0.6870419752597808
Epoch: 40 | Iteration number: [2510/4518] 55% | Training loss: 0.6870432020421047
Epoch: 40 | Iteration number: [2520/4518] 55% | Training loss: 0.6870467997259564
Epoch: 40 | Iteration number: [2530/4518] 55% | Training loss: 0.6870453774222273
Epoch: 40 | Iteration number: [2540/4518] 56% | Training loss: 0.6870439122042318
Epoch: 40 | Iteration number: [2550/4518] 56% | Training loss: 0.687043926856097
Epoch: 40 | Iteration number: [2560/4518] 56% | Training loss: 0.6870423000538721
Epoch: 40 | Iteration number: [2570/4518] 56% | Training loss: 0.6870418920359259
Epoch: 40 | Iteration number: [2580/4518] 57% | Training loss: 0.6870401032211244
Epoch: 40 | Iteration number: [2590/4518] 57% | Training loss: 0.6870379101355564
Epoch: 40 | Iteration number: [2600/4518] 57% | Training loss: 0.687032460982983
Epoch: 40 | Iteration number: [2610/4518] 57% | Training loss: 0.687030254881044
Epoch: 40 | Iteration number: [2620/4518] 57% | Training loss: 0.6870363700025864
Epoch: 40 | Iteration number: [2630/4518] 58% | Training loss: 0.6870361193051356
Epoch: 40 | Iteration number: [2640/4518] 58% | Training loss: 0.6870329896834764
Epoch: 40 | Iteration number: [2650/4518] 58% | Training loss: 0.6870310650906473
Epoch: 40 | Iteration number: [2660/4518] 58% | Training loss: 0.6870338079848683
Epoch: 40 | Iteration number: [2670/4518] 59% | Training loss: 0.6870311187894157
Epoch: 40 | Iteration number: [2680/4518] 59% | Training loss: 0.6870296249861148
Epoch: 40 | Iteration number: [2690/4518] 59% | Training loss: 0.6870309394974691
Epoch: 40 | Iteration number: [2700/4518] 59% | Training loss: 0.6870278273688423
Epoch: 40 | Iteration number: [2710/4518] 59% | Training loss: 0.6870327003327683
Epoch: 40 | Iteration number: [2720/4518] 60% | Training loss: 0.6870346444932853
Epoch: 40 | Iteration number: [2730/4518] 60% | Training loss: 0.6870362421750149
Epoch: 40 | Iteration number: [2740/4518] 60% | Training loss: 0.6870411761920817
Epoch: 40 | Iteration number: [2750/4518] 60% | Training loss: 0.6870391162525524
Epoch: 40 | Iteration number: [2760/4518] 61% | Training loss: 0.6870340423739475
Epoch: 40 | Iteration number: [2770/4518] 61% | Training loss: 0.6870272386805676
Epoch: 40 | Iteration number: [2780/4518] 61% | Training loss: 0.6870283173785793
Epoch: 40 | Iteration number: [2790/4518] 61% | Training loss: 0.6870269110553153
Epoch: 40 | Iteration number: [2800/4518] 61% | Training loss: 0.6870263227181775
Epoch: 40 | Iteration number: [2810/4518] 62% | Training loss: 0.6870278101798902
Epoch: 40 | Iteration number: [2820/4518] 62% | Training loss: 0.6870248014199818
Epoch: 40 | Iteration number: [2830/4518] 62% | Training loss: 0.6870267937335024
Epoch: 40 | Iteration number: [2840/4518] 62% | Training loss: 0.6870275007587083
Epoch: 40 | Iteration number: [2850/4518] 63% | Training loss: 0.6870298661265457
Epoch: 40 | Iteration number: [2860/4518] 63% | Training loss: 0.6870284627575974
Epoch: 40 | Iteration number: [2870/4518] 63% | Training loss: 0.6870287894787274
Epoch: 40 | Iteration number: [2880/4518] 63% | Training loss: 0.6870359779645999
Epoch: 40 | Iteration number: [2890/4518] 63% | Training loss: 0.6870332803486953
Epoch: 40 | Iteration number: [2900/4518] 64% | Training loss: 0.6870339216034987
Epoch: 40 | Iteration number: [2910/4518] 64% | Training loss: 0.6870318185218012
Epoch: 40 | Iteration number: [2920/4518] 64% | Training loss: 0.6870289297748918
Epoch: 40 | Iteration number: [2930/4518] 64% | Training loss: 0.6870288842163802
Epoch: 40 | Iteration number: [2940/4518] 65% | Training loss: 0.687023179243211
Epoch: 40 | Iteration number: [2950/4518] 65% | Training loss: 0.6870221331968146
Epoch: 40 | Iteration number: [2960/4518] 65% | Training loss: 0.6870242570904461
Epoch: 40 | Iteration number: [2970/4518] 65% | Training loss: 0.6870246110540448
Epoch: 40 | Iteration number: [2980/4518] 65% | Training loss: 0.6870224322848673
Epoch: 40 | Iteration number: [2990/4518] 66% | Training loss: 0.6870180664652566
Epoch: 40 | Iteration number: [3000/4518] 66% | Training loss: 0.6870189732909202
Epoch: 40 | Iteration number: [3010/4518] 66% | Training loss: 0.6870163121096715
Epoch: 40 | Iteration number: [3020/4518] 66% | Training loss: 0.687017665260675
Epoch: 40 | Iteration number: [3030/4518] 67% | Training loss: 0.6870223875289703
Epoch: 40 | Iteration number: [3040/4518] 67% | Training loss: 0.6870206181744212
Epoch: 40 | Iteration number: [3050/4518] 67% | Training loss: 0.6870184452221042
Epoch: 40 | Iteration number: [3060/4518] 67% | Training loss: 0.6870153055276746
Epoch: 40 | Iteration number: [3070/4518] 67% | Training loss: 0.6870137395998555
Epoch: 40 | Iteration number: [3080/4518] 68% | Training loss: 0.6870130939723609
Epoch: 40 | Iteration number: [3090/4518] 68% | Training loss: 0.6870134448349283
Epoch: 40 | Iteration number: [3100/4518] 68% | Training loss: 0.6870121918186065
Epoch: 40 | Iteration number: [3110/4518] 68% | Training loss: 0.6870089944919205
Epoch: 40 | Iteration number: [3120/4518] 69% | Training loss: 0.6870077830094558
Epoch: 40 | Iteration number: [3130/4518] 69% | Training loss: 0.6870101589745226
Epoch: 40 | Iteration number: [3140/4518] 69% | Training loss: 0.6870136081792746
Epoch: 40 | Iteration number: [3150/4518] 69% | Training loss: 0.6870129057339259
Epoch: 40 | Iteration number: [3160/4518] 69% | Training loss: 0.6870136296070075
Epoch: 40 | Iteration number: [3170/4518] 70% | Training loss: 0.6870135920468942
Epoch: 40 | Iteration number: [3180/4518] 70% | Training loss: 0.6870133381782088
Epoch: 40 | Iteration number: [3190/4518] 70% | Training loss: 0.6870122441864313
Epoch: 40 | Iteration number: [3200/4518] 70% | Training loss: 0.6870108723454177
Epoch: 40 | Iteration number: [3210/4518] 71% | Training loss: 0.6870071103268324
Epoch: 40 | Iteration number: [3220/4518] 71% | Training loss: 0.6870038749638552
Epoch: 40 | Iteration number: [3230/4518] 71% | Training loss: 0.6869992403423085
Epoch: 40 | Iteration number: [3240/4518] 71% | Training loss: 0.686998030120208
Epoch: 40 | Iteration number: [3250/4518] 71% | Training loss: 0.6869996386674734
Epoch: 40 | Iteration number: [3260/4518] 72% | Training loss: 0.6870012863830555
Epoch: 40 | Iteration number: [3270/4518] 72% | Training loss: 0.687003427926189
Epoch: 40 | Iteration number: [3280/4518] 72% | Training loss: 0.6870000750008153
Epoch: 40 | Iteration number: [3290/4518] 72% | Training loss: 0.686996452116314
Epoch: 40 | Iteration number: [3300/4518] 73% | Training loss: 0.6869966873616883
Epoch: 40 | Iteration number: [3310/4518] 73% | Training loss: 0.6869984455339138
Epoch: 40 | Iteration number: [3320/4518] 73% | Training loss: 0.6870023619877287
Epoch: 40 | Iteration number: [3330/4518] 73% | Training loss: 0.6869995287051788
Epoch: 40 | Iteration number: [3340/4518] 73% | Training loss: 0.6869953467103536
Epoch: 40 | Iteration number: [3350/4518] 74% | Training loss: 0.6869966062503075
Epoch: 40 | Iteration number: [3360/4518] 74% | Training loss: 0.6869953315172876
Epoch: 40 | Iteration number: [3370/4518] 74% | Training loss: 0.6869983862168003
Epoch: 40 | Iteration number: [3380/4518] 74% | Training loss: 0.6869936233088815
Epoch: 40 | Iteration number: [3390/4518] 75% | Training loss: 0.6869912003345546
Epoch: 40 | Iteration number: [3400/4518] 75% | Training loss: 0.6869962732756839
Epoch: 40 | Iteration number: [3410/4518] 75% | Training loss: 0.6869935466397193
Epoch: 40 | Iteration number: [3420/4518] 75% | Training loss: 0.6869925617125996
Epoch: 40 | Iteration number: [3430/4518] 75% | Training loss: 0.6869928460600773
Epoch: 40 | Iteration number: [3440/4518] 76% | Training loss: 0.6869946644923022
Epoch: 40 | Iteration number: [3450/4518] 76% | Training loss: 0.6869949710023576
Epoch: 40 | Iteration number: [3460/4518] 76% | Training loss: 0.6869962108273038
Epoch: 40 | Iteration number: [3470/4518] 76% | Training loss: 0.6869924222701564
Epoch: 40 | Iteration number: [3480/4518] 77% | Training loss: 0.6869943799814958
Epoch: 40 | Iteration number: [3490/4518] 77% | Training loss: 0.6869875131842058
Epoch: 40 | Iteration number: [3500/4518] 77% | Training loss: 0.6869888898815427
Epoch: 40 | Iteration number: [3510/4518] 77% | Training loss: 0.6869900930980671
Epoch: 40 | Iteration number: [3520/4518] 77% | Training loss: 0.686992082270709
Epoch: 40 | Iteration number: [3530/4518] 78% | Training loss: 0.6869877359515885
Epoch: 40 | Iteration number: [3540/4518] 78% | Training loss: 0.6869898608007
Epoch: 40 | Iteration number: [3550/4518] 78% | Training loss: 0.6869879490892652
Epoch: 40 | Iteration number: [3560/4518] 78% | Training loss: 0.6869881677995907
Epoch: 40 | Iteration number: [3570/4518] 79% | Training loss: 0.6869931057888586
Epoch: 40 | Iteration number: [3580/4518] 79% | Training loss: 0.6869901233212242
Epoch: 40 | Iteration number: [3590/4518] 79% | Training loss: 0.6869910369510438
Epoch: 40 | Iteration number: [3600/4518] 79% | Training loss: 0.6869905502431922
Epoch: 40 | Iteration number: [3610/4518] 79% | Training loss: 0.6869911690002664
Epoch: 40 | Iteration number: [3620/4518] 80% | Training loss: 0.6869907589742492
Epoch: 40 | Iteration number: [3630/4518] 80% | Training loss: 0.6869864569715232
Epoch: 40 | Iteration number: [3640/4518] 80% | Training loss: 0.6869860359109365
Epoch: 40 | Iteration number: [3650/4518] 80% | Training loss: 0.68698538203762
Epoch: 40 | Iteration number: [3660/4518] 81% | Training loss: 0.6869818886772531
Epoch: 40 | Iteration number: [3670/4518] 81% | Training loss: 0.68698402120242
Epoch: 40 | Iteration number: [3680/4518] 81% | Training loss: 0.6869821456301471
Epoch: 40 | Iteration number: [3690/4518] 81% | Training loss: 0.6869817675613775
Epoch: 40 | Iteration number: [3700/4518] 81% | Training loss: 0.6869815323642783
Epoch: 40 | Iteration number: [3710/4518] 82% | Training loss: 0.6869805330857434
Epoch: 40 | Iteration number: [3720/4518] 82% | Training loss: 0.6869831739253895
Epoch: 40 | Iteration number: [3730/4518] 82% | Training loss: 0.6869837458747322
Epoch: 40 | Iteration number: [3740/4518] 82% | Training loss: 0.686986144452809
Epoch: 40 | Iteration number: [3750/4518] 83% | Training loss: 0.6869864797592163
Epoch: 40 | Iteration number: [3760/4518] 83% | Training loss: 0.6869833899939314
Epoch: 40 | Iteration number: [3770/4518] 83% | Training loss: 0.6869837903375651
Epoch: 40 | Iteration number: [3780/4518] 83% | Training loss: 0.6869817795261505
Epoch: 40 | Iteration number: [3790/4518] 83% | Training loss: 0.6869805477225371
Epoch: 40 | Iteration number: [3800/4518] 84% | Training loss: 0.6869805089580385
Epoch: 40 | Iteration number: [3810/4518] 84% | Training loss: 0.6869816959060709
Epoch: 40 | Iteration number: [3820/4518] 84% | Training loss: 0.6869819445135705
Epoch: 40 | Iteration number: [3830/4518] 84% | Training loss: 0.6869820121996708
Epoch: 40 | Iteration number: [3840/4518] 84% | Training loss: 0.6869821114310374
Epoch: 40 | Iteration number: [3850/4518] 85% | Training loss: 0.6869811679171277
Epoch: 40 | Iteration number: [3860/4518] 85% | Training loss: 0.6869819515418513
Epoch: 40 | Iteration number: [3870/4518] 85% | Training loss: 0.686982845921233
Epoch: 40 | Iteration number: [3880/4518] 85% | Training loss: 0.6869800521540887
Epoch: 40 | Iteration number: [3890/4518] 86% | Training loss: 0.6869794878830946
Epoch: 40 | Iteration number: [3900/4518] 86% | Training loss: 0.6869817108221543
Epoch: 40 | Iteration number: [3910/4518] 86% | Training loss: 0.6869825935882071
Epoch: 40 | Iteration number: [3920/4518] 86% | Training loss: 0.6869834532391051
Epoch: 40 | Iteration number: [3930/4518] 86% | Training loss: 0.6869844920307625
Epoch: 40 | Iteration number: [3940/4518] 87% | Training loss: 0.6869839159819076
Epoch: 40 | Iteration number: [3950/4518] 87% | Training loss: 0.6869851132586032
Epoch: 40 | Iteration number: [3960/4518] 87% | Training loss: 0.6869835677321511
Epoch: 40 | Iteration number: [3970/4518] 87% | Training loss: 0.6869802879596537
Epoch: 40 | Iteration number: [3980/4518] 88% | Training loss: 0.6869811393807281
Epoch: 40 | Iteration number: [3990/4518] 88% | Training loss: 0.6869823827928768
Epoch: 40 | Iteration number: [4000/4518] 88% | Training loss: 0.6869810054898262
Epoch: 40 | Iteration number: [4010/4518] 88% | Training loss: 0.6869832322633177
Epoch: 40 | Iteration number: [4020/4518] 88% | Training loss: 0.6869834663263008
Epoch: 40 | Iteration number: [4030/4518] 89% | Training loss: 0.6869849740571479
Epoch: 40 | Iteration number: [4040/4518] 89% | Training loss: 0.6869839403888967
Epoch: 40 | Iteration number: [4050/4518] 89% | Training loss: 0.686981905904817
Epoch: 40 | Iteration number: [4060/4518] 89% | Training loss: 0.686981293118646
Epoch: 40 | Iteration number: [4070/4518] 90% | Training loss: 0.6869809442861075
Epoch: 40 | Iteration number: [4080/4518] 90% | Training loss: 0.6869821294411724
Epoch: 40 | Iteration number: [4090/4518] 90% | Training loss: 0.6869786311624103
Epoch: 40 | Iteration number: [4100/4518] 90% | Training loss: 0.6869813877489509
Epoch: 40 | Iteration number: [4110/4518] 90% | Training loss: 0.6869816405059648
Epoch: 40 | Iteration number: [4120/4518] 91% | Training loss: 0.6869803533247374
Epoch: 40 | Iteration number: [4130/4518] 91% | Training loss: 0.6869793086305946
Epoch: 40 | Iteration number: [4140/4518] 91% | Training loss: 0.6869749238381639
Epoch: 40 | Iteration number: [4150/4518] 91% | Training loss: 0.6869773039616734
Epoch: 40 | Iteration number: [4160/4518] 92% | Training loss: 0.6869791075157431
Epoch: 40 | Iteration number: [4170/4518] 92% | Training loss: 0.6869777855970305
Epoch: 40 | Iteration number: [4180/4518] 92% | Training loss: 0.6869786715536026
Epoch: 40 | Iteration number: [4190/4518] 92% | Training loss: 0.6869769846055843
Epoch: 40 | Iteration number: [4200/4518] 92% | Training loss: 0.686977732252507
Epoch: 40 | Iteration number: [4210/4518] 93% | Training loss: 0.6869763024912311
Epoch: 40 | Iteration number: [4220/4518] 93% | Training loss: 0.6869754739423499
Epoch: 40 | Iteration number: [4230/4518] 93% | Training loss: 0.6869736344679027
Epoch: 40 | Iteration number: [4240/4518] 93% | Training loss: 0.6869730902730294
Epoch: 40 | Iteration number: [4250/4518] 94% | Training loss: 0.6869733655312482
Epoch: 40 | Iteration number: [4260/4518] 94% | Training loss: 0.6869733767890035
Epoch: 40 | Iteration number: [4270/4518] 94% | Training loss: 0.6869745029498598
Epoch: 40 | Iteration number: [4280/4518] 94% | Training loss: 0.6869705263281537
Epoch: 40 | Iteration number: [4290/4518] 94% | Training loss: 0.6869708506794242
Epoch: 40 | Iteration number: [4300/4518] 95% | Training loss: 0.6869722559147103
Epoch: 40 | Iteration number: [4310/4518] 95% | Training loss: 0.6869739767431936
Epoch: 40 | Iteration number: [4320/4518] 95% | Training loss: 0.6869757139434417
Epoch: 40 | Iteration number: [4330/4518] 95% | Training loss: 0.6869731107567529
Epoch: 40 | Iteration number: [4340/4518] 96% | Training loss: 0.686975784661583
Epoch: 40 | Iteration number: [4350/4518] 96% | Training loss: 0.6869747115688762
Epoch: 40 | Iteration number: [4360/4518] 96% | Training loss: 0.6869739105668636
Epoch: 40 | Iteration number: [4370/4518] 96% | Training loss: 0.6869767815897612
Epoch: 40 | Iteration number: [4380/4518] 96% | Training loss: 0.6869794335539483
Epoch: 40 | Iteration number: [4390/4518] 97% | Training loss: 0.6869797626225986
Epoch: 40 | Iteration number: [4400/4518] 97% | Training loss: 0.6869763466444883
Epoch: 40 | Iteration number: [4410/4518] 97% | Training loss: 0.6869742434851978
Epoch: 40 | Iteration number: [4420/4518] 97% | Training loss: 0.6869730174002064
Epoch: 40 | Iteration number: [4430/4518] 98% | Training loss: 0.68697366123813
Epoch: 40 | Iteration number: [4440/4518] 98% | Training loss: 0.6869784974837089
Epoch: 40 | Iteration number: [4450/4518] 98% | Training loss: 0.68697881725397
Epoch: 40 | Iteration number: [4460/4518] 98% | Training loss: 0.686980929315892
Epoch: 40 | Iteration number: [4470/4518] 98% | Training loss: 0.6869801703448797
Epoch: 40 | Iteration number: [4480/4518] 99% | Training loss: 0.6869785886257886
Epoch: 40 | Iteration number: [4490/4518] 99% | Training loss: 0.6869783222675323
Epoch: 40 | Iteration number: [4500/4518] 99% | Training loss: 0.6869765781296624
Epoch: 40 | Iteration number: [4510/4518] 99% | Training loss: 0.6869754893023793

 End of epoch: 40 | Train Loss: 0.6868205699919598 | Training Time: 632 

 End of epoch: 40 | Eval Loss: 0.6897968807998969 | Evaluating Time: 17 
Epoch: 41 | Iteration number: [10/4518] 0% | Training loss: 0.7547555387020111
Epoch: 41 | Iteration number: [20/4518] 0% | Training loss: 0.7206654787063599
Epoch: 41 | Iteration number: [30/4518] 0% | Training loss: 0.7094866911570231
Epoch: 41 | Iteration number: [40/4518] 0% | Training loss: 0.7038996130228042
Epoch: 41 | Iteration number: [50/4518] 1% | Training loss: 0.700131266117096
Epoch: 41 | Iteration number: [60/4518] 1% | Training loss: 0.697870331009229
Epoch: 41 | Iteration number: [70/4518] 1% | Training loss: 0.6963984889643533
Epoch: 41 | Iteration number: [80/4518] 1% | Training loss: 0.6950891338288784
Epoch: 41 | Iteration number: [90/4518] 1% | Training loss: 0.6940629965729184
Epoch: 41 | Iteration number: [100/4518] 2% | Training loss: 0.6933751684427262
Epoch: 41 | Iteration number: [110/4518] 2% | Training loss: 0.6926462151787498
Epoch: 41 | Iteration number: [120/4518] 2% | Training loss: 0.6922578578193982
Epoch: 41 | Iteration number: [130/4518] 2% | Training loss: 0.6918818831443787
Epoch: 41 | Iteration number: [140/4518] 3% | Training loss: 0.6915145524910518
Epoch: 41 | Iteration number: [150/4518] 3% | Training loss: 0.6911655108133952
Epoch: 41 | Iteration number: [160/4518] 3% | Training loss: 0.6908734768629075
Epoch: 41 | Iteration number: [170/4518] 3% | Training loss: 0.6906885767684263
Epoch: 41 | Iteration number: [180/4518] 3% | Training loss: 0.6904560102356805
Epoch: 41 | Iteration number: [190/4518] 4% | Training loss: 0.6902564227581024
Epoch: 41 | Iteration number: [200/4518] 4% | Training loss: 0.6900397735834122
Epoch: 41 | Iteration number: [210/4518] 4% | Training loss: 0.6898627406074888
Epoch: 41 | Iteration number: [220/4518] 4% | Training loss: 0.689747805757956
Epoch: 41 | Iteration number: [230/4518] 5% | Training loss: 0.6896710141845371
Epoch: 41 | Iteration number: [240/4518] 5% | Training loss: 0.6896194477876028
Epoch: 41 | Iteration number: [250/4518] 5% | Training loss: 0.6895104608535767
Epoch: 41 | Iteration number: [260/4518] 5% | Training loss: 0.6893848980848606
Epoch: 41 | Iteration number: [270/4518] 5% | Training loss: 0.6892861465613047
Epoch: 41 | Iteration number: [280/4518] 6% | Training loss: 0.6892053235854422
Epoch: 41 | Iteration number: [290/4518] 6% | Training loss: 0.6891188761283611
Epoch: 41 | Iteration number: [300/4518] 6% | Training loss: 0.689041384657224
Epoch: 41 | Iteration number: [310/4518] 6% | Training loss: 0.6889927691028964
Epoch: 41 | Iteration number: [320/4518] 7% | Training loss: 0.6889235764741898
Epoch: 41 | Iteration number: [330/4518] 7% | Training loss: 0.6888568767995545
Epoch: 41 | Iteration number: [340/4518] 7% | Training loss: 0.6887659756576314
Epoch: 41 | Iteration number: [350/4518] 7% | Training loss: 0.6887110926423754
Epoch: 41 | Iteration number: [360/4518] 7% | Training loss: 0.6886663042836719
Epoch: 41 | Iteration number: [370/4518] 8% | Training loss: 0.6886136398122117
Epoch: 41 | Iteration number: [380/4518] 8% | Training loss: 0.6885736495256424
Epoch: 41 | Iteration number: [390/4518] 8% | Training loss: 0.6885350844798944
Epoch: 41 | Iteration number: [400/4518] 8% | Training loss: 0.6884957301616669
Epoch: 41 | Iteration number: [410/4518] 9% | Training loss: 0.6884658146195295
Epoch: 41 | Iteration number: [420/4518] 9% | Training loss: 0.688426186073394
Epoch: 41 | Iteration number: [430/4518] 9% | Training loss: 0.688378019111101
Epoch: 41 | Iteration number: [440/4518] 9% | Training loss: 0.6883399122140624
Epoch: 41 | Iteration number: [450/4518] 9% | Training loss: 0.6883177071147495
Epoch: 41 | Iteration number: [460/4518] 10% | Training loss: 0.6883042047853055
Epoch: 41 | Iteration number: [470/4518] 10% | Training loss: 0.6882791407564853
Epoch: 41 | Iteration number: [480/4518] 10% | Training loss: 0.6882360974947611
Epoch: 41 | Iteration number: [490/4518] 10% | Training loss: 0.6882123175932436
Epoch: 41 | Iteration number: [500/4518] 11% | Training loss: 0.6881673009395599
Epoch: 41 | Iteration number: [510/4518] 11% | Training loss: 0.6881247563689363
Epoch: 41 | Iteration number: [520/4518] 11% | Training loss: 0.6880802911061507
Epoch: 41 | Iteration number: [530/4518] 11% | Training loss: 0.6880726112509673
Epoch: 41 | Iteration number: [540/4518] 11% | Training loss: 0.6880534697462011
Epoch: 41 | Iteration number: [550/4518] 12% | Training loss: 0.6880400009588762
Epoch: 41 | Iteration number: [560/4518] 12% | Training loss: 0.6880095961902822
Epoch: 41 | Iteration number: [570/4518] 12% | Training loss: 0.6879995624224345
Epoch: 41 | Iteration number: [580/4518] 12% | Training loss: 0.687979345177782
Epoch: 41 | Iteration number: [590/4518] 13% | Training loss: 0.6879445119429443
Epoch: 41 | Iteration number: [600/4518] 13% | Training loss: 0.6879168573021889
Epoch: 41 | Iteration number: [610/4518] 13% | Training loss: 0.6879026062175876
Epoch: 41 | Iteration number: [620/4518] 13% | Training loss: 0.6878829087941877
Epoch: 41 | Iteration number: [630/4518] 13% | Training loss: 0.6878726399134076
Epoch: 41 | Iteration number: [640/4518] 14% | Training loss: 0.6878812340088188
Epoch: 41 | Iteration number: [650/4518] 14% | Training loss: 0.6878731399316054
Epoch: 41 | Iteration number: [660/4518] 14% | Training loss: 0.6878456624168339
Epoch: 41 | Iteration number: [670/4518] 14% | Training loss: 0.6878302849050778
Epoch: 41 | Iteration number: [680/4518] 15% | Training loss: 0.6878271106411429
Epoch: 41 | Iteration number: [690/4518] 15% | Training loss: 0.6878027471943178
Epoch: 41 | Iteration number: [700/4518] 15% | Training loss: 0.6877859233958381
Epoch: 41 | Iteration number: [710/4518] 15% | Training loss: 0.6877726989732662
Epoch: 41 | Iteration number: [720/4518] 15% | Training loss: 0.6877556014392111
Epoch: 41 | Iteration number: [730/4518] 16% | Training loss: 0.687725779863253
Epoch: 41 | Iteration number: [740/4518] 16% | Training loss: 0.6877158625705823
Epoch: 41 | Iteration number: [750/4518] 16% | Training loss: 0.6877016251087189
Epoch: 41 | Iteration number: [760/4518] 16% | Training loss: 0.6876936741565404
Epoch: 41 | Iteration number: [770/4518] 17% | Training loss: 0.6876555742381455
Epoch: 41 | Iteration number: [780/4518] 17% | Training loss: 0.6876526409234756
Epoch: 41 | Iteration number: [790/4518] 17% | Training loss: 0.6876323644873462
Epoch: 41 | Iteration number: [800/4518] 17% | Training loss: 0.6876251612603664
Epoch: 41 | Iteration number: [810/4518] 17% | Training loss: 0.6876279912613056
Epoch: 41 | Iteration number: [820/4518] 18% | Training loss: 0.6876239959059692
Epoch: 41 | Iteration number: [830/4518] 18% | Training loss: 0.6876141732715698
Epoch: 41 | Iteration number: [840/4518] 18% | Training loss: 0.6876086925466856
Epoch: 41 | Iteration number: [850/4518] 18% | Training loss: 0.6876005639749415
Epoch: 41 | Iteration number: [860/4518] 19% | Training loss: 0.6875948273165281
Epoch: 41 | Iteration number: [870/4518] 19% | Training loss: 0.6875834136173643
Epoch: 41 | Iteration number: [880/4518] 19% | Training loss: 0.6875796525993131
Epoch: 41 | Iteration number: [890/4518] 19% | Training loss: 0.6875807611460096
Epoch: 41 | Iteration number: [900/4518] 19% | Training loss: 0.6875811368889279
Epoch: 41 | Iteration number: [910/4518] 20% | Training loss: 0.6875750813510392
Epoch: 41 | Iteration number: [920/4518] 20% | Training loss: 0.687573541506477
Epoch: 41 | Iteration number: [930/4518] 20% | Training loss: 0.6875675084129457
Epoch: 41 | Iteration number: [940/4518] 20% | Training loss: 0.6875503001060892
Epoch: 41 | Iteration number: [950/4518] 21% | Training loss: 0.6875463265494296
Epoch: 41 | Iteration number: [960/4518] 21% | Training loss: 0.6875438106556734
Epoch: 41 | Iteration number: [970/4518] 21% | Training loss: 0.6875384712956615
Epoch: 41 | Iteration number: [980/4518] 21% | Training loss: 0.6875300808828704
Epoch: 41 | Iteration number: [990/4518] 21% | Training loss: 0.6875077039906473
Epoch: 41 | Iteration number: [1000/4518] 22% | Training loss: 0.6875039942264557
Epoch: 41 | Iteration number: [1010/4518] 22% | Training loss: 0.6874974398919852
Epoch: 41 | Iteration number: [1020/4518] 22% | Training loss: 0.6874858178928787
Epoch: 41 | Iteration number: [1030/4518] 22% | Training loss: 0.6874909966316038
Epoch: 41 | Iteration number: [1040/4518] 23% | Training loss: 0.68750048617904
Epoch: 41 | Iteration number: [1050/4518] 23% | Training loss: 0.6874976419834864
Epoch: 41 | Iteration number: [1060/4518] 23% | Training loss: 0.6874816665671907
Epoch: 41 | Iteration number: [1070/4518] 23% | Training loss: 0.687467631446981
Epoch: 41 | Iteration number: [1080/4518] 23% | Training loss: 0.6874623595012559
Epoch: 41 | Iteration number: [1090/4518] 24% | Training loss: 0.6874531363675354
Epoch: 41 | Iteration number: [1100/4518] 24% | Training loss: 0.6874543258276853
Epoch: 41 | Iteration number: [1110/4518] 24% | Training loss: 0.6874572322712288
Epoch: 41 | Iteration number: [1120/4518] 24% | Training loss: 0.6874462086707354
Epoch: 41 | Iteration number: [1130/4518] 25% | Training loss: 0.6874378926458612
Epoch: 41 | Iteration number: [1140/4518] 25% | Training loss: 0.6874290885109651
Epoch: 41 | Iteration number: [1150/4518] 25% | Training loss: 0.6874231934547425
Epoch: 41 | Iteration number: [1160/4518] 25% | Training loss: 0.687418495940751
Epoch: 41 | Iteration number: [1170/4518] 25% | Training loss: 0.6874132488527869
Epoch: 41 | Iteration number: [1180/4518] 26% | Training loss: 0.687413791175616
Epoch: 41 | Iteration number: [1190/4518] 26% | Training loss: 0.6874076761117502
Epoch: 41 | Iteration number: [1200/4518] 26% | Training loss: 0.6873864485323429
Epoch: 41 | Iteration number: [1210/4518] 26% | Training loss: 0.6873853983465305
Epoch: 41 | Iteration number: [1220/4518] 27% | Training loss: 0.6873865666448092
Epoch: 41 | Iteration number: [1230/4518] 27% | Training loss: 0.687374193542372
Epoch: 41 | Iteration number: [1240/4518] 27% | Training loss: 0.6873659143044103
Epoch: 41 | Iteration number: [1250/4518] 27% | Training loss: 0.6873646003246308
Epoch: 41 | Iteration number: [1260/4518] 27% | Training loss: 0.687357002260193
Epoch: 41 | Iteration number: [1270/4518] 28% | Training loss: 0.6873554055146345
Epoch: 41 | Iteration number: [1280/4518] 28% | Training loss: 0.6873569467570633
Epoch: 41 | Iteration number: [1290/4518] 28% | Training loss: 0.6873498175957407
Epoch: 41 | Iteration number: [1300/4518] 28% | Training loss: 0.6873297385527537
Epoch: 41 | Iteration number: [1310/4518] 28% | Training loss: 0.6873226612578821
Epoch: 41 | Iteration number: [1320/4518] 29% | Training loss: 0.6873146076545571
Epoch: 41 | Iteration number: [1330/4518] 29% | Training loss: 0.6872985955915953
Epoch: 41 | Iteration number: [1340/4518] 29% | Training loss: 0.6872872684873752
Epoch: 41 | Iteration number: [1350/4518] 29% | Training loss: 0.6872835741219697
Epoch: 41 | Iteration number: [1360/4518] 30% | Training loss: 0.6872882691814619
Epoch: 41 | Iteration number: [1370/4518] 30% | Training loss: 0.6872867403239229
Epoch: 41 | Iteration number: [1380/4518] 30% | Training loss: 0.6872780552376871
Epoch: 41 | Iteration number: [1390/4518] 30% | Training loss: 0.6872630697360141
Epoch: 41 | Iteration number: [1400/4518] 30% | Training loss: 0.6872529166936875
Epoch: 41 | Iteration number: [1410/4518] 31% | Training loss: 0.6872566398576642
Epoch: 41 | Iteration number: [1420/4518] 31% | Training loss: 0.6872589405993341
Epoch: 41 | Iteration number: [1430/4518] 31% | Training loss: 0.6872554293462446
Epoch: 41 | Iteration number: [1440/4518] 31% | Training loss: 0.6872553117573261
Epoch: 41 | Iteration number: [1450/4518] 32% | Training loss: 0.6872522413730622
Epoch: 41 | Iteration number: [1460/4518] 32% | Training loss: 0.6872468149417067
Epoch: 41 | Iteration number: [1470/4518] 32% | Training loss: 0.6872425299112489
Epoch: 41 | Iteration number: [1480/4518] 32% | Training loss: 0.6872453062518223
Epoch: 41 | Iteration number: [1490/4518] 32% | Training loss: 0.6872481361731587
Epoch: 41 | Iteration number: [1500/4518] 33% | Training loss: 0.6872475199302037
Epoch: 41 | Iteration number: [1510/4518] 33% | Training loss: 0.6872372108184739
Epoch: 41 | Iteration number: [1520/4518] 33% | Training loss: 0.6872378508119207
Epoch: 41 | Iteration number: [1530/4518] 33% | Training loss: 0.6872401994427825
Epoch: 41 | Iteration number: [1540/4518] 34% | Training loss: 0.6872298205827738
Epoch: 41 | Iteration number: [1550/4518] 34% | Training loss: 0.6872319912910462
Epoch: 41 | Iteration number: [1560/4518] 34% | Training loss: 0.6872360989451408
Epoch: 41 | Iteration number: [1570/4518] 34% | Training loss: 0.6872384430876204
Epoch: 41 | Iteration number: [1580/4518] 34% | Training loss: 0.6872419127935095
Epoch: 41 | Iteration number: [1590/4518] 35% | Training loss: 0.6872442637974361
Epoch: 41 | Iteration number: [1600/4518] 35% | Training loss: 0.6872412194684148
Epoch: 41 | Iteration number: [1610/4518] 35% | Training loss: 0.6872443121042311
Epoch: 41 | Iteration number: [1620/4518] 35% | Training loss: 0.6872375288863241
Epoch: 41 | Iteration number: [1630/4518] 36% | Training loss: 0.687237033229664
Epoch: 41 | Iteration number: [1640/4518] 36% | Training loss: 0.6872306382147277
Epoch: 41 | Iteration number: [1650/4518] 36% | Training loss: 0.6872245335940159
Epoch: 41 | Iteration number: [1660/4518] 36% | Training loss: 0.6872268372989563
Epoch: 41 | Iteration number: [1670/4518] 36% | Training loss: 0.687223578677206
Epoch: 41 | Iteration number: [1680/4518] 37% | Training loss: 0.6872260223187151
Epoch: 41 | Iteration number: [1690/4518] 37% | Training loss: 0.6872157069705647
Epoch: 41 | Iteration number: [1700/4518] 37% | Training loss: 0.687211962833124
Epoch: 41 | Iteration number: [1710/4518] 37% | Training loss: 0.6872128117851346
Epoch: 41 | Iteration number: [1720/4518] 38% | Training loss: 0.6872129697439282
Epoch: 41 | Iteration number: [1730/4518] 38% | Training loss: 0.6872142450313348
Epoch: 41 | Iteration number: [1740/4518] 38% | Training loss: 0.6872015641338524
Epoch: 41 | Iteration number: [1750/4518] 38% | Training loss: 0.6871988630975996
Epoch: 41 | Iteration number: [1760/4518] 38% | Training loss: 0.6871992303566499
Epoch: 41 | Iteration number: [1770/4518] 39% | Training loss: 0.6871913576866947
Epoch: 41 | Iteration number: [1780/4518] 39% | Training loss: 0.6871900554118532
Epoch: 41 | Iteration number: [1790/4518] 39% | Training loss: 0.687184581676675
Epoch: 41 | Iteration number: [1800/4518] 39% | Training loss: 0.687188925312625
Epoch: 41 | Iteration number: [1810/4518] 40% | Training loss: 0.6871842740649018
Epoch: 41 | Iteration number: [1820/4518] 40% | Training loss: 0.6871857104393152
Epoch: 41 | Iteration number: [1830/4518] 40% | Training loss: 0.6871845543058843
Epoch: 41 | Iteration number: [1840/4518] 40% | Training loss: 0.6871775600573291
Epoch: 41 | Iteration number: [1850/4518] 40% | Training loss: 0.6871781428440197
Epoch: 41 | Iteration number: [1860/4518] 41% | Training loss: 0.6871763949753136
Epoch: 41 | Iteration number: [1870/4518] 41% | Training loss: 0.6871693162675847
Epoch: 41 | Iteration number: [1880/4518] 41% | Training loss: 0.6871647635672955
Epoch: 41 | Iteration number: [1890/4518] 41% | Training loss: 0.6871647630734419
Epoch: 41 | Iteration number: [1900/4518] 42% | Training loss: 0.6871584356144855
Epoch: 41 | Iteration number: [1910/4518] 42% | Training loss: 0.6871557033186808
Epoch: 41 | Iteration number: [1920/4518] 42% | Training loss: 0.6871535086693863
Epoch: 41 | Iteration number: [1930/4518] 42% | Training loss: 0.6871502065596803
Epoch: 41 | Iteration number: [1940/4518] 42% | Training loss: 0.6871545089581578
Epoch: 41 | Iteration number: [1950/4518] 43% | Training loss: 0.6871570381140097
Epoch: 41 | Iteration number: [1960/4518] 43% | Training loss: 0.6871489244152088
Epoch: 41 | Iteration number: [1970/4518] 43% | Training loss: 0.6871464140221553
Epoch: 41 | Iteration number: [1980/4518] 43% | Training loss: 0.6871446378303296
Epoch: 41 | Iteration number: [1990/4518] 44% | Training loss: 0.6871484674401019
Epoch: 41 | Iteration number: [2000/4518] 44% | Training loss: 0.6871516122221947
Epoch: 41 | Iteration number: [2010/4518] 44% | Training loss: 0.6871526771220402
Epoch: 41 | Iteration number: [2020/4518] 44% | Training loss: 0.6871530367301242
Epoch: 41 | Iteration number: [2030/4518] 44% | Training loss: 0.6871551644919541
Epoch: 41 | Iteration number: [2040/4518] 45% | Training loss: 0.6871599964651407
Epoch: 41 | Iteration number: [2050/4518] 45% | Training loss: 0.6871620555621821
Epoch: 41 | Iteration number: [2060/4518] 45% | Training loss: 0.6871612736901034
Epoch: 41 | Iteration number: [2070/4518] 45% | Training loss: 0.6871587206200125
Epoch: 41 | Iteration number: [2080/4518] 46% | Training loss: 0.6871547650832396
Epoch: 41 | Iteration number: [2090/4518] 46% | Training loss: 0.6871556951383655
Epoch: 41 | Iteration number: [2100/4518] 46% | Training loss: 0.6871489712170192
Epoch: 41 | Iteration number: [2110/4518] 46% | Training loss: 0.6871475627919509
Epoch: 41 | Iteration number: [2120/4518] 46% | Training loss: 0.6871435941671425
Epoch: 41 | Iteration number: [2130/4518] 47% | Training loss: 0.6871429595589078
Epoch: 41 | Iteration number: [2140/4518] 47% | Training loss: 0.6871383908753083
Epoch: 41 | Iteration number: [2150/4518] 47% | Training loss: 0.6871443080347638
Epoch: 41 | Iteration number: [2160/4518] 47% | Training loss: 0.6871417563546587
Epoch: 41 | Iteration number: [2170/4518] 48% | Training loss: 0.6871420865509367
Epoch: 41 | Iteration number: [2180/4518] 48% | Training loss: 0.6871450458371311
Epoch: 41 | Iteration number: [2190/4518] 48% | Training loss: 0.6871385041981527
Epoch: 41 | Iteration number: [2200/4518] 48% | Training loss: 0.6871424120122737
Epoch: 41 | Iteration number: [2210/4518] 48% | Training loss: 0.687145597497802
Epoch: 41 | Iteration number: [2220/4518] 49% | Training loss: 0.6871391204294858
Epoch: 41 | Iteration number: [2230/4518] 49% | Training loss: 0.6871359201022862
Epoch: 41 | Iteration number: [2240/4518] 49% | Training loss: 0.6871339081919619
Epoch: 41 | Iteration number: [2250/4518] 49% | Training loss: 0.6871280734803942
Epoch: 41 | Iteration number: [2260/4518] 50% | Training loss: 0.6871295706888215
Epoch: 41 | Iteration number: [2270/4518] 50% | Training loss: 0.6871219420485559
Epoch: 41 | Iteration number: [2280/4518] 50% | Training loss: 0.687122712454252
Epoch: 41 | Iteration number: [2290/4518] 50% | Training loss: 0.6871270447318731
Epoch: 41 | Iteration number: [2300/4518] 50% | Training loss: 0.6871265367321346
Epoch: 41 | Iteration number: [2310/4518] 51% | Training loss: 0.687124968658794
Epoch: 41 | Iteration number: [2320/4518] 51% | Training loss: 0.6871169108512073
Epoch: 41 | Iteration number: [2330/4518] 51% | Training loss: 0.6871160773248631
Epoch: 41 | Iteration number: [2340/4518] 51% | Training loss: 0.6871116457077173
Epoch: 41 | Iteration number: [2350/4518] 52% | Training loss: 0.6871101836701657
Epoch: 41 | Iteration number: [2360/4518] 52% | Training loss: 0.687110335392467
Epoch: 41 | Iteration number: [2370/4518] 52% | Training loss: 0.687108753879362
Epoch: 41 | Iteration number: [2380/4518] 52% | Training loss: 0.6871053207070887
Epoch: 41 | Iteration number: [2390/4518] 52% | Training loss: 0.687100736915317
Epoch: 41 | Iteration number: [2400/4518] 53% | Training loss: 0.6871014657616615
Epoch: 41 | Iteration number: [2410/4518] 53% | Training loss: 0.6870963000904969
Epoch: 41 | Iteration number: [2420/4518] 53% | Training loss: 0.6870947962211184
Epoch: 41 | Iteration number: [2430/4518] 53% | Training loss: 0.6870932402679459
Epoch: 41 | Iteration number: [2440/4518] 54% | Training loss: 0.687093252090157
Epoch: 41 | Iteration number: [2450/4518] 54% | Training loss: 0.6870969959911035
Epoch: 41 | Iteration number: [2460/4518] 54% | Training loss: 0.6870903560058857
Epoch: 41 | Iteration number: [2470/4518] 54% | Training loss: 0.687090723500078
Epoch: 41 | Iteration number: [2480/4518] 54% | Training loss: 0.68708304383101
Epoch: 41 | Iteration number: [2490/4518] 55% | Training loss: 0.6870830387954252
Epoch: 41 | Iteration number: [2500/4518] 55% | Training loss: 0.6870800972700118
Epoch: 41 | Iteration number: [2510/4518] 55% | Training loss: 0.687080847029667
Epoch: 41 | Iteration number: [2520/4518] 55% | Training loss: 0.6870778154995706
Epoch: 41 | Iteration number: [2530/4518] 55% | Training loss: 0.6870810120473266
Epoch: 41 | Iteration number: [2540/4518] 56% | Training loss: 0.6870792427635568
Epoch: 41 | Iteration number: [2550/4518] 56% | Training loss: 0.6870813532202852
Epoch: 41 | Iteration number: [2560/4518] 56% | Training loss: 0.687083087512292
Epoch: 41 | Iteration number: [2570/4518] 56% | Training loss: 0.6870848207158338
Epoch: 41 | Iteration number: [2580/4518] 57% | Training loss: 0.6870897488769635
Epoch: 41 | Iteration number: [2590/4518] 57% | Training loss: 0.6870875487226317
Epoch: 41 | Iteration number: [2600/4518] 57% | Training loss: 0.6870875373941201
Epoch: 41 | Iteration number: [2610/4518] 57% | Training loss: 0.6870868465681186
Epoch: 41 | Iteration number: [2620/4518] 57% | Training loss: 0.6870800557027337
Epoch: 41 | Iteration number: [2630/4518] 58% | Training loss: 0.6870757193619761
Epoch: 41 | Iteration number: [2640/4518] 58% | Training loss: 0.6870761704038489
Epoch: 41 | Iteration number: [2650/4518] 58% | Training loss: 0.6870719818124231
Epoch: 41 | Iteration number: [2660/4518] 58% | Training loss: 0.68707348354777
Epoch: 41 | Iteration number: [2670/4518] 59% | Training loss: 0.6870735231187013
Epoch: 41 | Iteration number: [2680/4518] 59% | Training loss: 0.6870707320410814
Epoch: 41 | Iteration number: [2690/4518] 59% | Training loss: 0.6870718010074587
Epoch: 41 | Iteration number: [2700/4518] 59% | Training loss: 0.6870681683884726
Epoch: 41 | Iteration number: [2710/4518] 59% | Training loss: 0.6870687619346534
Epoch: 41 | Iteration number: [2720/4518] 60% | Training loss: 0.6870696968234637
Epoch: 41 | Iteration number: [2730/4518] 60% | Training loss: 0.6870688448895464
Epoch: 41 | Iteration number: [2740/4518] 60% | Training loss: 0.6870693730611871
Epoch: 41 | Iteration number: [2750/4518] 60% | Training loss: 0.6870671550360593
Epoch: 41 | Iteration number: [2760/4518] 61% | Training loss: 0.6870631697601166
Epoch: 41 | Iteration number: [2770/4518] 61% | Training loss: 0.6870609989235117
Epoch: 41 | Iteration number: [2780/4518] 61% | Training loss: 0.6870595625621809
Epoch: 41 | Iteration number: [2790/4518] 61% | Training loss: 0.6870543441464824
Epoch: 41 | Iteration number: [2800/4518] 61% | Training loss: 0.6870587609921183
Epoch: 41 | Iteration number: [2810/4518] 62% | Training loss: 0.6870547524974864
Epoch: 41 | Iteration number: [2820/4518] 62% | Training loss: 0.687059201712304
Epoch: 41 | Iteration number: [2830/4518] 62% | Training loss: 0.6870623189231954
Epoch: 41 | Iteration number: [2840/4518] 62% | Training loss: 0.6870603562450744
Epoch: 41 | Iteration number: [2850/4518] 63% | Training loss: 0.6870559676069963
Epoch: 41 | Iteration number: [2860/4518] 63% | Training loss: 0.6870573618195274
Epoch: 41 | Iteration number: [2870/4518] 63% | Training loss: 0.6870583329674259
Epoch: 41 | Iteration number: [2880/4518] 63% | Training loss: 0.687053792240719
Epoch: 41 | Iteration number: [2890/4518] 63% | Training loss: 0.6870515476254856
Epoch: 41 | Iteration number: [2900/4518] 64% | Training loss: 0.6870511752778086
Epoch: 41 | Iteration number: [2910/4518] 64% | Training loss: 0.6870518537935932
Epoch: 41 | Iteration number: [2920/4518] 64% | Training loss: 0.6870499913823115
Epoch: 41 | Iteration number: [2930/4518] 64% | Training loss: 0.6870528893666056
Epoch: 41 | Iteration number: [2940/4518] 65% | Training loss: 0.6870549557363095
Epoch: 41 | Iteration number: [2950/4518] 65% | Training loss: 0.6870558604951632
Epoch: 41 | Iteration number: [2960/4518] 65% | Training loss: 0.6870551018094694
Epoch: 41 | Iteration number: [2970/4518] 65% | Training loss: 0.6870571570163624
Epoch: 41 | Iteration number: [2980/4518] 65% | Training loss: 0.6870497459933261
Epoch: 41 | Iteration number: [2990/4518] 66% | Training loss: 0.6870495128990416
Epoch: 41 | Iteration number: [3000/4518] 66% | Training loss: 0.6870495558977127
Epoch: 41 | Iteration number: [3010/4518] 66% | Training loss: 0.6870505566414804
Epoch: 41 | Iteration number: [3020/4518] 66% | Training loss: 0.6870543809718643
Epoch: 41 | Iteration number: [3030/4518] 67% | Training loss: 0.6870520265385656
Epoch: 41 | Iteration number: [3040/4518] 67% | Training loss: 0.6870519689823452
Epoch: 41 | Iteration number: [3050/4518] 67% | Training loss: 0.6870530025099144
Epoch: 41 | Iteration number: [3060/4518] 67% | Training loss: 0.6870568829034668
Epoch: 41 | Iteration number: [3070/4518] 67% | Training loss: 0.6870587953721273
Epoch: 41 | Iteration number: [3080/4518] 68% | Training loss: 0.6870544315352068
Epoch: 41 | Iteration number: [3090/4518] 68% | Training loss: 0.687052834361888
Epoch: 41 | Iteration number: [3100/4518] 68% | Training loss: 0.6870551737854558
Epoch: 41 | Iteration number: [3110/4518] 68% | Training loss: 0.6870562626426243
Epoch: 41 | Iteration number: [3120/4518] 69% | Training loss: 0.687056855742748
Epoch: 41 | Iteration number: [3130/4518] 69% | Training loss: 0.6870596777135952
Epoch: 41 | Iteration number: [3140/4518] 69% | Training loss: 0.6870559501230337
Epoch: 41 | Iteration number: [3150/4518] 69% | Training loss: 0.6870524436140817
Epoch: 41 | Iteration number: [3160/4518] 69% | Training loss: 0.6870501091585883
Epoch: 41 | Iteration number: [3170/4518] 70% | Training loss: 0.687049449994361
Epoch: 41 | Iteration number: [3180/4518] 70% | Training loss: 0.6870515029010533
Epoch: 41 | Iteration number: [3190/4518] 70% | Training loss: 0.6870485492260853
Epoch: 41 | Iteration number: [3200/4518] 70% | Training loss: 0.6870427063852549
Epoch: 41 | Iteration number: [3210/4518] 71% | Training loss: 0.6870367450877514
Epoch: 41 | Iteration number: [3220/4518] 71% | Training loss: 0.6870348404838432
Epoch: 41 | Iteration number: [3230/4518] 71% | Training loss: 0.6870345728500709
Epoch: 41 | Iteration number: [3240/4518] 71% | Training loss: 0.6870366705052646
Epoch: 41 | Iteration number: [3250/4518] 71% | Training loss: 0.6870334779482622
Epoch: 41 | Iteration number: [3260/4518] 72% | Training loss: 0.6870336277536088
Epoch: 41 | Iteration number: [3270/4518] 72% | Training loss: 0.6870307903771007
Epoch: 41 | Iteration number: [3280/4518] 72% | Training loss: 0.687028503327108
Epoch: 41 | Iteration number: [3290/4518] 72% | Training loss: 0.687025985438773
Epoch: 41 | Iteration number: [3300/4518] 73% | Training loss: 0.6870228038954013
Epoch: 41 | Iteration number: [3310/4518] 73% | Training loss: 0.6870255325856166
Epoch: 41 | Iteration number: [3320/4518] 73% | Training loss: 0.6870250753070934
Epoch: 41 | Iteration number: [3330/4518] 73% | Training loss: 0.6870235032147474
Epoch: 41 | Iteration number: [3340/4518] 73% | Training loss: 0.687021867457978
Epoch: 41 | Iteration number: [3350/4518] 74% | Training loss: 0.6870194196878974
Epoch: 41 | Iteration number: [3360/4518] 74% | Training loss: 0.6870179532894066
Epoch: 41 | Iteration number: [3370/4518] 74% | Training loss: 0.6870201221913188
Epoch: 41 | Iteration number: [3380/4518] 74% | Training loss: 0.6870180501034979
Epoch: 41 | Iteration number: [3390/4518] 75% | Training loss: 0.6870169035101359
Epoch: 41 | Iteration number: [3400/4518] 75% | Training loss: 0.6870150599234245
Epoch: 41 | Iteration number: [3410/4518] 75% | Training loss: 0.6870133635060878
Epoch: 41 | Iteration number: [3420/4518] 75% | Training loss: 0.6870109930547358
Epoch: 41 | Iteration number: [3430/4518] 75% | Training loss: 0.6870108290594451
Epoch: 41 | Iteration number: [3440/4518] 76% | Training loss: 0.6870084113679653
Epoch: 41 | Iteration number: [3450/4518] 76% | Training loss: 0.6870061468559763
Epoch: 41 | Iteration number: [3460/4518] 76% | Training loss: 0.6870071632152348
Epoch: 41 | Iteration number: [3470/4518] 76% | Training loss: 0.687008875316433
Epoch: 41 | Iteration number: [3480/4518] 77% | Training loss: 0.68700853923614
Epoch: 41 | Iteration number: [3490/4518] 77% | Training loss: 0.6870107585003861
Epoch: 41 | Iteration number: [3500/4518] 77% | Training loss: 0.6870120483636856
Epoch: 41 | Iteration number: [3510/4518] 77% | Training loss: 0.6870081928380873
Epoch: 41 | Iteration number: [3520/4518] 77% | Training loss: 0.6870081210508943
Epoch: 41 | Iteration number: [3530/4518] 78% | Training loss: 0.68700682731931
Epoch: 41 | Iteration number: [3540/4518] 78% | Training loss: 0.6870034017636951
Epoch: 41 | Iteration number: [3550/4518] 78% | Training loss: 0.6870024241695941
Epoch: 41 | Iteration number: [3560/4518] 78% | Training loss: 0.6870038462488839
Epoch: 41 | Iteration number: [3570/4518] 79% | Training loss: 0.6870018210898594
Epoch: 41 | Iteration number: [3580/4518] 79% | Training loss: 0.6869992587985939
Epoch: 41 | Iteration number: [3590/4518] 79% | Training loss: 0.6869983136819929
Epoch: 41 | Iteration number: [3600/4518] 79% | Training loss: 0.6869957111941444
Epoch: 41 | Iteration number: [3610/4518] 79% | Training loss: 0.6869975185295221
Epoch: 41 | Iteration number: [3620/4518] 80% | Training loss: 0.6869983123152296
Epoch: 41 | Iteration number: [3630/4518] 80% | Training loss: 0.6869984578823584
Epoch: 41 | Iteration number: [3640/4518] 80% | Training loss: 0.6869971974210425
Epoch: 41 | Iteration number: [3650/4518] 80% | Training loss: 0.6869962852295131
Epoch: 41 | Iteration number: [3660/4518] 81% | Training loss: 0.6869953386933426
Epoch: 41 | Iteration number: [3670/4518] 81% | Training loss: 0.6869972921522177
Epoch: 41 | Iteration number: [3680/4518] 81% | Training loss: 0.6869972601208998
Epoch: 41 | Iteration number: [3690/4518] 81% | Training loss: 0.6869972070865837
Epoch: 41 | Iteration number: [3700/4518] 81% | Training loss: 0.6869959913878827
Epoch: 41 | Iteration number: [3710/4518] 82% | Training loss: 0.6869959603101417
Epoch: 41 | Iteration number: [3720/4518] 82% | Training loss: 0.6869964875040516
Epoch: 41 | Iteration number: [3730/4518] 82% | Training loss: 0.6869995720904251
Epoch: 41 | Iteration number: [3740/4518] 82% | Training loss: 0.6869985414380059
Epoch: 41 | Iteration number: [3750/4518] 83% | Training loss: 0.6869978866736094
Epoch: 41 | Iteration number: [3760/4518] 83% | Training loss: 0.686997246504464
Epoch: 41 | Iteration number: [3770/4518] 83% | Training loss: 0.6869979279427061
Epoch: 41 | Iteration number: [3780/4518] 83% | Training loss: 0.6869948098741511
Epoch: 41 | Iteration number: [3790/4518] 83% | Training loss: 0.6869978209441444
Epoch: 41 | Iteration number: [3800/4518] 84% | Training loss: 0.6869952616252397
Epoch: 41 | Iteration number: [3810/4518] 84% | Training loss: 0.6869959122239762
Epoch: 41 | Iteration number: [3820/4518] 84% | Training loss: 0.686998007840511
Epoch: 41 | Iteration number: [3830/4518] 84% | Training loss: 0.686997262958447
Epoch: 41 | Iteration number: [3840/4518] 84% | Training loss: 0.6869971613554905
Epoch: 41 | Iteration number: [3850/4518] 85% | Training loss: 0.6870007896113706
Epoch: 41 | Iteration number: [3860/4518] 85% | Training loss: 0.6870007247659209
Epoch: 41 | Iteration number: [3870/4518] 85% | Training loss: 0.6870020270809647
Epoch: 41 | Iteration number: [3880/4518] 85% | Training loss: 0.6870015973590083
Epoch: 41 | Iteration number: [3890/4518] 86% | Training loss: 0.6870009210391645
Epoch: 41 | Iteration number: [3900/4518] 86% | Training loss: 0.6869986458008106
Epoch: 41 | Iteration number: [3910/4518] 86% | Training loss: 0.6869991096846588
Epoch: 41 | Iteration number: [3920/4518] 86% | Training loss: 0.6869984423171501
Epoch: 41 | Iteration number: [3930/4518] 86% | Training loss: 0.6869969522376703
Epoch: 41 | Iteration number: [3940/4518] 87% | Training loss: 0.6869967996317723
Epoch: 41 | Iteration number: [3950/4518] 87% | Training loss: 0.6869986943655376
Epoch: 41 | Iteration number: [3960/4518] 87% | Training loss: 0.68700240925707
Epoch: 41 | Iteration number: [3970/4518] 87% | Training loss: 0.6870022588773098
Epoch: 41 | Iteration number: [3980/4518] 88% | Training loss: 0.6869984791206954
Epoch: 41 | Iteration number: [3990/4518] 88% | Training loss: 0.6869984471110772
Epoch: 41 | Iteration number: [4000/4518] 88% | Training loss: 0.6869987904429435
Epoch: 41 | Iteration number: [4010/4518] 88% | Training loss: 0.6869987954522606
Epoch: 41 | Iteration number: [4020/4518] 88% | Training loss: 0.6869975987803284
Epoch: 41 | Iteration number: [4030/4518] 89% | Training loss: 0.686994327342244
Epoch: 41 | Iteration number: [4040/4518] 89% | Training loss: 0.6869926750955015
Epoch: 41 | Iteration number: [4050/4518] 89% | Training loss: 0.6869934363571214
Epoch: 41 | Iteration number: [4060/4518] 89% | Training loss: 0.6869949611683784
Epoch: 41 | Iteration number: [4070/4518] 90% | Training loss: 0.6869908785351372
Epoch: 41 | Iteration number: [4080/4518] 90% | Training loss: 0.686991480416527
Epoch: 41 | Iteration number: [4090/4518] 90% | Training loss: 0.6869898926949443
Epoch: 41 | Iteration number: [4100/4518] 90% | Training loss: 0.6869903915829775
Epoch: 41 | Iteration number: [4110/4518] 90% | Training loss: 0.686990610192872
Epoch: 41 | Iteration number: [4120/4518] 91% | Training loss: 0.6869891547317644
Epoch: 41 | Iteration number: [4130/4518] 91% | Training loss: 0.686989542921288
Epoch: 41 | Iteration number: [4140/4518] 91% | Training loss: 0.6869905839939624
Epoch: 41 | Iteration number: [4150/4518] 91% | Training loss: 0.6869887149908457
Epoch: 41 | Iteration number: [4160/4518] 92% | Training loss: 0.686989752919628
Epoch: 41 | Iteration number: [4170/4518] 92% | Training loss: 0.6869880973006324
Epoch: 41 | Iteration number: [4180/4518] 92% | Training loss: 0.6869904051557112
Epoch: 41 | Iteration number: [4190/4518] 92% | Training loss: 0.6869906380239136
Epoch: 41 | Iteration number: [4200/4518] 92% | Training loss: 0.686990545136588
Epoch: 41 | Iteration number: [4210/4518] 93% | Training loss: 0.6869898644309146
Epoch: 41 | Iteration number: [4220/4518] 93% | Training loss: 0.6869907652173562
Epoch: 41 | Iteration number: [4230/4518] 93% | Training loss: 0.6869897752507077
Epoch: 41 | Iteration number: [4240/4518] 93% | Training loss: 0.6869881754495063
Epoch: 41 | Iteration number: [4250/4518] 94% | Training loss: 0.686984288818696
Epoch: 41 | Iteration number: [4260/4518] 94% | Training loss: 0.6869861651614239
Epoch: 41 | Iteration number: [4270/4518] 94% | Training loss: 0.686988768337482
Epoch: 41 | Iteration number: [4280/4518] 94% | Training loss: 0.6869852761520403
Epoch: 41 | Iteration number: [4290/4518] 94% | Training loss: 0.6869876683730901
Epoch: 41 | Iteration number: [4300/4518] 95% | Training loss: 0.6869888268099275
Epoch: 41 | Iteration number: [4310/4518] 95% | Training loss: 0.6869880309375975
Epoch: 41 | Iteration number: [4320/4518] 95% | Training loss: 0.6869825248503023
Epoch: 41 | Iteration number: [4330/4518] 95% | Training loss: 0.686979785072886
Epoch: 41 | Iteration number: [4340/4518] 96% | Training loss: 0.6869774919226422
Epoch: 41 | Iteration number: [4350/4518] 96% | Training loss: 0.6869799324972876
Epoch: 41 | Iteration number: [4360/4518] 96% | Training loss: 0.6869788771375603
Epoch: 41 | Iteration number: [4370/4518] 96% | Training loss: 0.6869780215982442
Epoch: 41 | Iteration number: [4380/4518] 96% | Training loss: 0.6869770871041573
Epoch: 41 | Iteration number: [4390/4518] 97% | Training loss: 0.6869755300003738
Epoch: 41 | Iteration number: [4400/4518] 97% | Training loss: 0.6869764076986096
Epoch: 41 | Iteration number: [4410/4518] 97% | Training loss: 0.6869763646806989
Epoch: 41 | Iteration number: [4420/4518] 97% | Training loss: 0.6869721836903516
Epoch: 41 | Iteration number: [4430/4518] 98% | Training loss: 0.6869728253065329
Epoch: 41 | Iteration number: [4440/4518] 98% | Training loss: 0.6869703160212921
Epoch: 41 | Iteration number: [4450/4518] 98% | Training loss: 0.6869699843813865
Epoch: 41 | Iteration number: [4460/4518] 98% | Training loss: 0.6869692710082093
Epoch: 41 | Iteration number: [4470/4518] 98% | Training loss: 0.6869698555677529
Epoch: 41 | Iteration number: [4480/4518] 99% | Training loss: 0.6869714482554368
Epoch: 41 | Iteration number: [4490/4518] 99% | Training loss: 0.6869711570458317
Epoch: 41 | Iteration number: [4500/4518] 99% | Training loss: 0.686968641002973
Epoch: 41 | Iteration number: [4510/4518] 99% | Training loss: 0.6869714443673052

 End of epoch: 41 | Train Loss: 0.6868183589736251 | Training Time: 632 

 End of epoch: 41 | Eval Loss: 0.6899003374333285 | Evaluating Time: 17 
Epoch: 42 | Iteration number: [10/4518] 0% | Training loss: 0.7549659192562104
Epoch: 42 | Iteration number: [20/4518] 0% | Training loss: 0.7210232347249985
Epoch: 42 | Iteration number: [30/4518] 0% | Training loss: 0.7094685177008311
Epoch: 42 | Iteration number: [40/4518] 0% | Training loss: 0.7041129797697068
Epoch: 42 | Iteration number: [50/4518] 1% | Training loss: 0.7006557881832123
Epoch: 42 | Iteration number: [60/4518] 1% | Training loss: 0.6981120963891347
Epoch: 42 | Iteration number: [70/4518] 1% | Training loss: 0.6963952115603855
Epoch: 42 | Iteration number: [80/4518] 1% | Training loss: 0.6951973773539066
Epoch: 42 | Iteration number: [90/4518] 1% | Training loss: 0.6942485709985097
Epoch: 42 | Iteration number: [100/4518] 2% | Training loss: 0.6934842121601105
Epoch: 42 | Iteration number: [110/4518] 2% | Training loss: 0.6927785754203797
Epoch: 42 | Iteration number: [120/4518] 2% | Training loss: 0.6922208542625109
Epoch: 42 | Iteration number: [130/4518] 2% | Training loss: 0.6917645202233241
Epoch: 42 | Iteration number: [140/4518] 3% | Training loss: 0.6914363133055823
Epoch: 42 | Iteration number: [150/4518] 3% | Training loss: 0.6910878793398539
Epoch: 42 | Iteration number: [160/4518] 3% | Training loss: 0.6907790780067444
Epoch: 42 | Iteration number: [170/4518] 3% | Training loss: 0.6906438094728133
Epoch: 42 | Iteration number: [180/4518] 3% | Training loss: 0.6903900285561879
Epoch: 42 | Iteration number: [190/4518] 4% | Training loss: 0.6902511715888977
Epoch: 42 | Iteration number: [200/4518] 4% | Training loss: 0.6900973290205001
Epoch: 42 | Iteration number: [210/4518] 4% | Training loss: 0.689938314471926
Epoch: 42 | Iteration number: [220/4518] 4% | Training loss: 0.6898213562640276
Epoch: 42 | Iteration number: [230/4518] 5% | Training loss: 0.6896803000698919
Epoch: 42 | Iteration number: [240/4518] 5% | Training loss: 0.6896032194296519
Epoch: 42 | Iteration number: [250/4518] 5% | Training loss: 0.6894605188369751
Epoch: 42 | Iteration number: [260/4518] 5% | Training loss: 0.6893918248323294
Epoch: 42 | Iteration number: [270/4518] 5% | Training loss: 0.6893138326980449
Epoch: 42 | Iteration number: [280/4518] 6% | Training loss: 0.6892133966088295
Epoch: 42 | Iteration number: [290/4518] 6% | Training loss: 0.6891111223862089
Epoch: 42 | Iteration number: [300/4518] 6% | Training loss: 0.6890608982245128
Epoch: 42 | Iteration number: [310/4518] 6% | Training loss: 0.6890036757915251
Epoch: 42 | Iteration number: [320/4518] 7% | Training loss: 0.68894998524338
Epoch: 42 | Iteration number: [330/4518] 7% | Training loss: 0.6888803500117677
Epoch: 42 | Iteration number: [340/4518] 7% | Training loss: 0.6888419603600221
Epoch: 42 | Iteration number: [350/4518] 7% | Training loss: 0.6887849640846252
Epoch: 42 | Iteration number: [360/4518] 7% | Training loss: 0.6887188376651869
Epoch: 42 | Iteration number: [370/4518] 8% | Training loss: 0.688675514105204
Epoch: 42 | Iteration number: [380/4518] 8% | Training loss: 0.6886686273311314
Epoch: 42 | Iteration number: [390/4518] 8% | Training loss: 0.6886138131985298
Epoch: 42 | Iteration number: [400/4518] 8% | Training loss: 0.68860137373209
Epoch: 42 | Iteration number: [410/4518] 9% | Training loss: 0.6885436203421615
Epoch: 42 | Iteration number: [420/4518] 9% | Training loss: 0.6884726769867398
Epoch: 42 | Iteration number: [430/4518] 9% | Training loss: 0.6884370633336001
Epoch: 42 | Iteration number: [440/4518] 9% | Training loss: 0.6883757870305668
Epoch: 42 | Iteration number: [450/4518] 9% | Training loss: 0.6883406219217513
Epoch: 42 | Iteration number: [460/4518] 10% | Training loss: 0.6883148159669793
Epoch: 42 | Iteration number: [470/4518] 10% | Training loss: 0.6883096034222461
Epoch: 42 | Iteration number: [480/4518] 10% | Training loss: 0.688265705977877
Epoch: 42 | Iteration number: [490/4518] 10% | Training loss: 0.6882553534848349
Epoch: 42 | Iteration number: [500/4518] 11% | Training loss: 0.6882065250873566
Epoch: 42 | Iteration number: [510/4518] 11% | Training loss: 0.6881600334363825
Epoch: 42 | Iteration number: [520/4518] 11% | Training loss: 0.6881079036455888
Epoch: 42 | Iteration number: [530/4518] 11% | Training loss: 0.6881005888839937
Epoch: 42 | Iteration number: [540/4518] 11% | Training loss: 0.6880755014993526
Epoch: 42 | Iteration number: [550/4518] 12% | Training loss: 0.6880583976615559
Epoch: 42 | Iteration number: [560/4518] 12% | Training loss: 0.6880564115941524
Epoch: 42 | Iteration number: [570/4518] 12% | Training loss: 0.6880382214721881
Epoch: 42 | Iteration number: [580/4518] 12% | Training loss: 0.6880261524997908
Epoch: 42 | Iteration number: [590/4518] 13% | Training loss: 0.6880281049316213
Epoch: 42 | Iteration number: [600/4518] 13% | Training loss: 0.6880043468872706
Epoch: 42 | Iteration number: [610/4518] 13% | Training loss: 0.6879816773484965
Epoch: 42 | Iteration number: [620/4518] 13% | Training loss: 0.6879725949418161
Epoch: 42 | Iteration number: [630/4518] 13% | Training loss: 0.6879680522850582
Epoch: 42 | Iteration number: [640/4518] 14% | Training loss: 0.6879412376321852
Epoch: 42 | Iteration number: [650/4518] 14% | Training loss: 0.6879274031749139
Epoch: 42 | Iteration number: [660/4518] 14% | Training loss: 0.6879060387611389
Epoch: 42 | Iteration number: [670/4518] 14% | Training loss: 0.687900091196174
Epoch: 42 | Iteration number: [680/4518] 15% | Training loss: 0.6879016219693072
Epoch: 42 | Iteration number: [690/4518] 15% | Training loss: 0.6878859060398047
Epoch: 42 | Iteration number: [700/4518] 15% | Training loss: 0.6878440636396408
Epoch: 42 | Iteration number: [710/4518] 15% | Training loss: 0.6878080303400336
Epoch: 42 | Iteration number: [720/4518] 15% | Training loss: 0.687770873390966
Epoch: 42 | Iteration number: [730/4518] 16% | Training loss: 0.6877676013397844
Epoch: 42 | Iteration number: [740/4518] 16% | Training loss: 0.6877448624855763
Epoch: 42 | Iteration number: [750/4518] 16% | Training loss: 0.6877374177773794
Epoch: 42 | Iteration number: [760/4518] 16% | Training loss: 0.6877217815110558
Epoch: 42 | Iteration number: [770/4518] 17% | Training loss: 0.6877127884270309
Epoch: 42 | Iteration number: [780/4518] 17% | Training loss: 0.687692365126732
Epoch: 42 | Iteration number: [790/4518] 17% | Training loss: 0.6876720164395586
Epoch: 42 | Iteration number: [800/4518] 17% | Training loss: 0.6876644361764193
Epoch: 42 | Iteration number: [810/4518] 17% | Training loss: 0.6876437199704442
Epoch: 42 | Iteration number: [820/4518] 18% | Training loss: 0.6876230003630243
Epoch: 42 | Iteration number: [830/4518] 18% | Training loss: 0.687613387208387
Epoch: 42 | Iteration number: [840/4518] 18% | Training loss: 0.6875941427690643
Epoch: 42 | Iteration number: [850/4518] 18% | Training loss: 0.6875867882195641
Epoch: 42 | Iteration number: [860/4518] 19% | Training loss: 0.6875703921844792
Epoch: 42 | Iteration number: [870/4518] 19% | Training loss: 0.6875717059634198
Epoch: 42 | Iteration number: [880/4518] 19% | Training loss: 0.6875478186390617
Epoch: 42 | Iteration number: [890/4518] 19% | Training loss: 0.6875293424959933
Epoch: 42 | Iteration number: [900/4518] 19% | Training loss: 0.687512742612097
Epoch: 42 | Iteration number: [910/4518] 20% | Training loss: 0.6875074214987702
Epoch: 42 | Iteration number: [920/4518] 20% | Training loss: 0.6874765887856483
Epoch: 42 | Iteration number: [930/4518] 20% | Training loss: 0.6874706248442332
Epoch: 42 | Iteration number: [940/4518] 20% | Training loss: 0.6874702612770365
Epoch: 42 | Iteration number: [950/4518] 21% | Training loss: 0.6874634531924599
Epoch: 42 | Iteration number: [960/4518] 21% | Training loss: 0.6874509247019887
Epoch: 42 | Iteration number: [970/4518] 21% | Training loss: 0.6874307542732081
Epoch: 42 | Iteration number: [980/4518] 21% | Training loss: 0.6874244365156913
Epoch: 42 | Iteration number: [990/4518] 21% | Training loss: 0.6874201074393108
Epoch: 42 | Iteration number: [1000/4518] 22% | Training loss: 0.687414690554142
Epoch: 42 | Iteration number: [1010/4518] 22% | Training loss: 0.6874265585795487
Epoch: 42 | Iteration number: [1020/4518] 22% | Training loss: 0.6874093368357304
Epoch: 42 | Iteration number: [1030/4518] 22% | Training loss: 0.6873962037192966
Epoch: 42 | Iteration number: [1040/4518] 23% | Training loss: 0.6873911678791046
Epoch: 42 | Iteration number: [1050/4518] 23% | Training loss: 0.6873891540368398
Epoch: 42 | Iteration number: [1060/4518] 23% | Training loss: 0.6873697488937738
Epoch: 42 | Iteration number: [1070/4518] 23% | Training loss: 0.6873577429312412
Epoch: 42 | Iteration number: [1080/4518] 23% | Training loss: 0.6873492092997939
Epoch: 42 | Iteration number: [1090/4518] 24% | Training loss: 0.6873423032804367
Epoch: 42 | Iteration number: [1100/4518] 24% | Training loss: 0.6873322078314694
Epoch: 42 | Iteration number: [1110/4518] 24% | Training loss: 0.6873322045480883
Epoch: 42 | Iteration number: [1120/4518] 24% | Training loss: 0.6873272094875574
Epoch: 42 | Iteration number: [1130/4518] 25% | Training loss: 0.6873172393942302
Epoch: 42 | Iteration number: [1140/4518] 25% | Training loss: 0.6873201577286971
Epoch: 42 | Iteration number: [1150/4518] 25% | Training loss: 0.6873098035998967
Epoch: 42 | Iteration number: [1160/4518] 25% | Training loss: 0.6873157959046035
Epoch: 42 | Iteration number: [1170/4518] 25% | Training loss: 0.6873008072885692
Epoch: 42 | Iteration number: [1180/4518] 26% | Training loss: 0.6872989308531001
Epoch: 42 | Iteration number: [1190/4518] 26% | Training loss: 0.6872983246290383
Epoch: 42 | Iteration number: [1200/4518] 26% | Training loss: 0.6872931823631128
Epoch: 42 | Iteration number: [1210/4518] 26% | Training loss: 0.6872931908970037
Epoch: 42 | Iteration number: [1220/4518] 27% | Training loss: 0.6872941255080895
Epoch: 42 | Iteration number: [1230/4518] 27% | Training loss: 0.6872947834371551
Epoch: 42 | Iteration number: [1240/4518] 27% | Training loss: 0.6872769886447537
Epoch: 42 | Iteration number: [1250/4518] 27% | Training loss: 0.6872590394973754
Epoch: 42 | Iteration number: [1260/4518] 27% | Training loss: 0.6872725289019327
Epoch: 42 | Iteration number: [1270/4518] 28% | Training loss: 0.6872783490991968
Epoch: 42 | Iteration number: [1280/4518] 28% | Training loss: 0.6872801373712718
Epoch: 42 | Iteration number: [1290/4518] 28% | Training loss: 0.687266885495001
Epoch: 42 | Iteration number: [1300/4518] 28% | Training loss: 0.6872649259292163
Epoch: 42 | Iteration number: [1310/4518] 28% | Training loss: 0.6872694733488651
Epoch: 42 | Iteration number: [1320/4518] 29% | Training loss: 0.6872675609408003
Epoch: 42 | Iteration number: [1330/4518] 29% | Training loss: 0.6872657358198238
Epoch: 42 | Iteration number: [1340/4518] 29% | Training loss: 0.6872639245506543
Epoch: 42 | Iteration number: [1350/4518] 29% | Training loss: 0.6872547588524995
Epoch: 42 | Iteration number: [1360/4518] 30% | Training loss: 0.687253652600681
Epoch: 42 | Iteration number: [1370/4518] 30% | Training loss: 0.6872567782871914
Epoch: 42 | Iteration number: [1380/4518] 30% | Training loss: 0.6872573844332626
Epoch: 42 | Iteration number: [1390/4518] 30% | Training loss: 0.6872527111777299
Epoch: 42 | Iteration number: [1400/4518] 30% | Training loss: 0.687242764873164
Epoch: 42 | Iteration number: [1410/4518] 31% | Training loss: 0.6872410592457927
Epoch: 42 | Iteration number: [1420/4518] 31% | Training loss: 0.687233823747702
Epoch: 42 | Iteration number: [1430/4518] 31% | Training loss: 0.6872276481214937
Epoch: 42 | Iteration number: [1440/4518] 31% | Training loss: 0.687220145513614
Epoch: 42 | Iteration number: [1450/4518] 32% | Training loss: 0.6872262633257898
Epoch: 42 | Iteration number: [1460/4518] 32% | Training loss: 0.687222545930784
Epoch: 42 | Iteration number: [1470/4518] 32% | Training loss: 0.6872261200226895
Epoch: 42 | Iteration number: [1480/4518] 32% | Training loss: 0.6872225839141253
Epoch: 42 | Iteration number: [1490/4518] 32% | Training loss: 0.6872191209121038
Epoch: 42 | Iteration number: [1500/4518] 33% | Training loss: 0.6872170978784561
Epoch: 42 | Iteration number: [1510/4518] 33% | Training loss: 0.6872166419266076
Epoch: 42 | Iteration number: [1520/4518] 33% | Training loss: 0.6872153478233438
Epoch: 42 | Iteration number: [1530/4518] 33% | Training loss: 0.6872029488382776
Epoch: 42 | Iteration number: [1540/4518] 34% | Training loss: 0.6871918644610937
Epoch: 42 | Iteration number: [1550/4518] 34% | Training loss: 0.6871876281692135
Epoch: 42 | Iteration number: [1560/4518] 34% | Training loss: 0.6871825176171767
Epoch: 42 | Iteration number: [1570/4518] 34% | Training loss: 0.6871664053695217
Epoch: 42 | Iteration number: [1580/4518] 34% | Training loss: 0.6871658906151977
Epoch: 42 | Iteration number: [1590/4518] 35% | Training loss: 0.6871715157661797
Epoch: 42 | Iteration number: [1600/4518] 35% | Training loss: 0.6871688702702522
Epoch: 42 | Iteration number: [1610/4518] 35% | Training loss: 0.6871615992569775
Epoch: 42 | Iteration number: [1620/4518] 35% | Training loss: 0.6871586003789195
Epoch: 42 | Iteration number: [1630/4518] 36% | Training loss: 0.6871501910174551
Epoch: 42 | Iteration number: [1640/4518] 36% | Training loss: 0.6871525624176351
Epoch: 42 | Iteration number: [1650/4518] 36% | Training loss: 0.6871465936935309
Epoch: 42 | Iteration number: [1660/4518] 36% | Training loss: 0.6871500684913382
Epoch: 42 | Iteration number: [1670/4518] 36% | Training loss: 0.6871508802839382
Epoch: 42 | Iteration number: [1680/4518] 37% | Training loss: 0.6871449583343097
Epoch: 42 | Iteration number: [1690/4518] 37% | Training loss: 0.6871437397581586
Epoch: 42 | Iteration number: [1700/4518] 37% | Training loss: 0.6871444137306775
Epoch: 42 | Iteration number: [1710/4518] 37% | Training loss: 0.6871412011963582
Epoch: 42 | Iteration number: [1720/4518] 38% | Training loss: 0.6871480951129004
Epoch: 42 | Iteration number: [1730/4518] 38% | Training loss: 0.6871470782453614
Epoch: 42 | Iteration number: [1740/4518] 38% | Training loss: 0.6871442949292303
Epoch: 42 | Iteration number: [1750/4518] 38% | Training loss: 0.6871385800838471
Epoch: 42 | Iteration number: [1760/4518] 38% | Training loss: 0.6871328539807688
Epoch: 42 | Iteration number: [1770/4518] 39% | Training loss: 0.6871326648582846
Epoch: 42 | Iteration number: [1780/4518] 39% | Training loss: 0.6871357219272785
Epoch: 42 | Iteration number: [1790/4518] 39% | Training loss: 0.6871303239015227
Epoch: 42 | Iteration number: [1800/4518] 39% | Training loss: 0.6871203940113385
Epoch: 42 | Iteration number: [1810/4518] 40% | Training loss: 0.6871163982712761
Epoch: 42 | Iteration number: [1820/4518] 40% | Training loss: 0.6871126642921469
Epoch: 42 | Iteration number: [1830/4518] 40% | Training loss: 0.6871111455836583
Epoch: 42 | Iteration number: [1840/4518] 40% | Training loss: 0.6871129678643269
Epoch: 42 | Iteration number: [1850/4518] 40% | Training loss: 0.6871128862935143
Epoch: 42 | Iteration number: [1860/4518] 41% | Training loss: 0.6871161642574495
Epoch: 42 | Iteration number: [1870/4518] 41% | Training loss: 0.6871216099848722
Epoch: 42 | Iteration number: [1880/4518] 41% | Training loss: 0.6871216149089184
Epoch: 42 | Iteration number: [1890/4518] 41% | Training loss: 0.687119073495663
Epoch: 42 | Iteration number: [1900/4518] 42% | Training loss: 0.6871226780979257
Epoch: 42 | Iteration number: [1910/4518] 42% | Training loss: 0.6871163970512869
Epoch: 42 | Iteration number: [1920/4518] 42% | Training loss: 0.6871125968173146
Epoch: 42 | Iteration number: [1930/4518] 42% | Training loss: 0.687110542787789
Epoch: 42 | Iteration number: [1940/4518] 42% | Training loss: 0.6871078677705883
Epoch: 42 | Iteration number: [1950/4518] 43% | Training loss: 0.6871115100995088
Epoch: 42 | Iteration number: [1960/4518] 43% | Training loss: 0.6871081753044712
Epoch: 42 | Iteration number: [1970/4518] 43% | Training loss: 0.6870986943620111
Epoch: 42 | Iteration number: [1980/4518] 43% | Training loss: 0.6870944026443694
Epoch: 42 | Iteration number: [1990/4518] 44% | Training loss: 0.6870928306974957
Epoch: 42 | Iteration number: [2000/4518] 44% | Training loss: 0.6870897350609303
Epoch: 42 | Iteration number: [2010/4518] 44% | Training loss: 0.6870899350192416
Epoch: 42 | Iteration number: [2020/4518] 44% | Training loss: 0.6870892257383554
Epoch: 42 | Iteration number: [2030/4518] 44% | Training loss: 0.6870871405002519
Epoch: 42 | Iteration number: [2040/4518] 45% | Training loss: 0.687085368206688
Epoch: 42 | Iteration number: [2050/4518] 45% | Training loss: 0.687085163913122
Epoch: 42 | Iteration number: [2060/4518] 45% | Training loss: 0.6870758122900157
Epoch: 42 | Iteration number: [2070/4518] 45% | Training loss: 0.687079418828522
Epoch: 42 | Iteration number: [2080/4518] 46% | Training loss: 0.6870806592874802
Epoch: 42 | Iteration number: [2090/4518] 46% | Training loss: 0.6870763179502989
Epoch: 42 | Iteration number: [2100/4518] 46% | Training loss: 0.6870780951636178
Epoch: 42 | Iteration number: [2110/4518] 46% | Training loss: 0.6870736663092935
Epoch: 42 | Iteration number: [2120/4518] 46% | Training loss: 0.6870766058283032
Epoch: 42 | Iteration number: [2130/4518] 47% | Training loss: 0.6870727575440921
Epoch: 42 | Iteration number: [2140/4518] 47% | Training loss: 0.6870780369110197
Epoch: 42 | Iteration number: [2150/4518] 47% | Training loss: 0.6870813759814861
Epoch: 42 | Iteration number: [2160/4518] 47% | Training loss: 0.6870792013075616
Epoch: 42 | Iteration number: [2170/4518] 48% | Training loss: 0.6870793035502807
Epoch: 42 | Iteration number: [2180/4518] 48% | Training loss: 0.6870838049901735
Epoch: 42 | Iteration number: [2190/4518] 48% | Training loss: 0.6870851691455058
Epoch: 42 | Iteration number: [2200/4518] 48% | Training loss: 0.687079010551626
Epoch: 42 | Iteration number: [2210/4518] 48% | Training loss: 0.6870796751922073
Epoch: 42 | Iteration number: [2220/4518] 49% | Training loss: 0.6870827303007916
Epoch: 42 | Iteration number: [2230/4518] 49% | Training loss: 0.6870814876171506
Epoch: 42 | Iteration number: [2240/4518] 49% | Training loss: 0.6870757772454194
Epoch: 42 | Iteration number: [2250/4518] 49% | Training loss: 0.6870715891785092
Epoch: 42 | Iteration number: [2260/4518] 50% | Training loss: 0.6870754110602151
Epoch: 42 | Iteration number: [2270/4518] 50% | Training loss: 0.6870703493971131
Epoch: 42 | Iteration number: [2280/4518] 50% | Training loss: 0.6870676162211519
Epoch: 42 | Iteration number: [2290/4518] 50% | Training loss: 0.6870705999661741
Epoch: 42 | Iteration number: [2300/4518] 50% | Training loss: 0.6870687485518663
Epoch: 42 | Iteration number: [2310/4518] 51% | Training loss: 0.6870652927980795
Epoch: 42 | Iteration number: [2320/4518] 51% | Training loss: 0.6870639757092657
Epoch: 42 | Iteration number: [2330/4518] 51% | Training loss: 0.6870609002051947
Epoch: 42 | Iteration number: [2340/4518] 51% | Training loss: 0.6870589179106248
Epoch: 42 | Iteration number: [2350/4518] 52% | Training loss: 0.6870557046190221
Epoch: 42 | Iteration number: [2360/4518] 52% | Training loss: 0.6870517372579897
Epoch: 42 | Iteration number: [2370/4518] 52% | Training loss: 0.6870492304176218
Epoch: 42 | Iteration number: [2380/4518] 52% | Training loss: 0.6870440569244513
Epoch: 42 | Iteration number: [2390/4518] 52% | Training loss: 0.6870477622024185
Epoch: 42 | Iteration number: [2400/4518] 53% | Training loss: 0.6870432318995396
Epoch: 42 | Iteration number: [2410/4518] 53% | Training loss: 0.68704403920787
Epoch: 42 | Iteration number: [2420/4518] 53% | Training loss: 0.687044111879404
Epoch: 42 | Iteration number: [2430/4518] 53% | Training loss: 0.6870409492847851
Epoch: 42 | Iteration number: [2440/4518] 54% | Training loss: 0.6870371955095744
Epoch: 42 | Iteration number: [2450/4518] 54% | Training loss: 0.6870329307293406
Epoch: 42 | Iteration number: [2460/4518] 54% | Training loss: 0.6870323387830238
Epoch: 42 | Iteration number: [2470/4518] 54% | Training loss: 0.6870295112190942
Epoch: 42 | Iteration number: [2480/4518] 54% | Training loss: 0.6870352493899484
Epoch: 42 | Iteration number: [2490/4518] 55% | Training loss: 0.6870372311417836
Epoch: 42 | Iteration number: [2500/4518] 55% | Training loss: 0.6870317666530609
Epoch: 42 | Iteration number: [2510/4518] 55% | Training loss: 0.6870318394258202
Epoch: 42 | Iteration number: [2520/4518] 55% | Training loss: 0.6870301923581532
Epoch: 42 | Iteration number: [2530/4518] 55% | Training loss: 0.6870285532691262
Epoch: 42 | Iteration number: [2540/4518] 56% | Training loss: 0.687028056265801
Epoch: 42 | Iteration number: [2550/4518] 56% | Training loss: 0.6870270157561583
Epoch: 42 | Iteration number: [2560/4518] 56% | Training loss: 0.6870272502303123
Epoch: 42 | Iteration number: [2570/4518] 56% | Training loss: 0.6870276494016907
Epoch: 42 | Iteration number: [2580/4518] 57% | Training loss: 0.6870273627745088
Epoch: 42 | Iteration number: [2590/4518] 57% | Training loss: 0.6870250912476691
Epoch: 42 | Iteration number: [2600/4518] 57% | Training loss: 0.6870245819137647
Epoch: 42 | Iteration number: [2610/4518] 57% | Training loss: 0.6870260358085121
Epoch: 42 | Iteration number: [2620/4518] 57% | Training loss: 0.6870305122992465
Epoch: 42 | Iteration number: [2630/4518] 58% | Training loss: 0.6870331868019394
Epoch: 42 | Iteration number: [2640/4518] 58% | Training loss: 0.6870331413592353
Epoch: 42 | Iteration number: [2650/4518] 58% | Training loss: 0.6870304534570226
Epoch: 42 | Iteration number: [2660/4518] 58% | Training loss: 0.687033530464746
Epoch: 42 | Iteration number: [2670/4518] 59% | Training loss: 0.6870339287577497
Epoch: 42 | Iteration number: [2680/4518] 59% | Training loss: 0.6870328022028083
Epoch: 42 | Iteration number: [2690/4518] 59% | Training loss: 0.6870371603168076
Epoch: 42 | Iteration number: [2700/4518] 59% | Training loss: 0.6870348988638983
Epoch: 42 | Iteration number: [2710/4518] 59% | Training loss: 0.6870319541310033
Epoch: 42 | Iteration number: [2720/4518] 60% | Training loss: 0.6870309590855066
Epoch: 42 | Iteration number: [2730/4518] 60% | Training loss: 0.6870331525147616
Epoch: 42 | Iteration number: [2740/4518] 60% | Training loss: 0.6870337215218231
Epoch: 42 | Iteration number: [2750/4518] 60% | Training loss: 0.6870348137725484
Epoch: 42 | Iteration number: [2760/4518] 61% | Training loss: 0.6870346309266229
Epoch: 42 | Iteration number: [2770/4518] 61% | Training loss: 0.6870405346693115
Epoch: 42 | Iteration number: [2780/4518] 61% | Training loss: 0.6870370267106475
Epoch: 42 | Iteration number: [2790/4518] 61% | Training loss: 0.6870361734889314
Epoch: 42 | Iteration number: [2800/4518] 61% | Training loss: 0.687033085078001
Epoch: 42 | Iteration number: [2810/4518] 62% | Training loss: 0.6870249146244279
Epoch: 42 | Iteration number: [2820/4518] 62% | Training loss: 0.6870218293886659
Epoch: 42 | Iteration number: [2830/4518] 62% | Training loss: 0.6870225893103192
Epoch: 42 | Iteration number: [2840/4518] 62% | Training loss: 0.6870212656721263
Epoch: 42 | Iteration number: [2850/4518] 63% | Training loss: 0.6870211589336396
Epoch: 42 | Iteration number: [2860/4518] 63% | Training loss: 0.6870206973144225
Epoch: 42 | Iteration number: [2870/4518] 63% | Training loss: 0.6870226594213825
Epoch: 42 | Iteration number: [2880/4518] 63% | Training loss: 0.6870314508883489
Epoch: 42 | Iteration number: [2890/4518] 63% | Training loss: 0.6870360113345215
Epoch: 42 | Iteration number: [2900/4518] 64% | Training loss: 0.6870322750149102
Epoch: 42 | Iteration number: [2910/4518] 64% | Training loss: 0.6870333447489132
Epoch: 42 | Iteration number: [2920/4518] 64% | Training loss: 0.687032541918428
Epoch: 42 | Iteration number: [2930/4518] 64% | Training loss: 0.6870309859209093
Epoch: 42 | Iteration number: [2940/4518] 65% | Training loss: 0.6870337968780881
Epoch: 42 | Iteration number: [2950/4518] 65% | Training loss: 0.6870356983047421
Epoch: 42 | Iteration number: [2960/4518] 65% | Training loss: 0.6870365125101966
Epoch: 42 | Iteration number: [2970/4518] 65% | Training loss: 0.6870349651233917
Epoch: 42 | Iteration number: [2980/4518] 65% | Training loss: 0.6870327188264603
Epoch: 42 | Iteration number: [2990/4518] 66% | Training loss: 0.687031628714756
Epoch: 42 | Iteration number: [3000/4518] 66% | Training loss: 0.6870328135093053
Epoch: 42 | Iteration number: [3010/4518] 66% | Training loss: 0.6870335939516656
Epoch: 42 | Iteration number: [3020/4518] 66% | Training loss: 0.6870324965739092
Epoch: 42 | Iteration number: [3030/4518] 67% | Training loss: 0.6870355208911518
Epoch: 42 | Iteration number: [3040/4518] 67% | Training loss: 0.6870334290752286
Epoch: 42 | Iteration number: [3050/4518] 67% | Training loss: 0.6870305386723065
Epoch: 42 | Iteration number: [3060/4518] 67% | Training loss: 0.6870298938813553
Epoch: 42 | Iteration number: [3070/4518] 67% | Training loss: 0.6870340985855761
Epoch: 42 | Iteration number: [3080/4518] 68% | Training loss: 0.6870296467434276
Epoch: 42 | Iteration number: [3090/4518] 68% | Training loss: 0.6870307261504016
Epoch: 42 | Iteration number: [3100/4518] 68% | Training loss: 0.6870261803942342
Epoch: 42 | Iteration number: [3110/4518] 68% | Training loss: 0.6870281061367207
Epoch: 42 | Iteration number: [3120/4518] 69% | Training loss: 0.6870285148421923
Epoch: 42 | Iteration number: [3130/4518] 69% | Training loss: 0.6870323804811167
Epoch: 42 | Iteration number: [3140/4518] 69% | Training loss: 0.687030506532663
Epoch: 42 | Iteration number: [3150/4518] 69% | Training loss: 0.687025386095047
Epoch: 42 | Iteration number: [3160/4518] 69% | Training loss: 0.6870218727973443
Epoch: 42 | Iteration number: [3170/4518] 70% | Training loss: 0.6870265043308306
Epoch: 42 | Iteration number: [3180/4518] 70% | Training loss: 0.6870256234639845
Epoch: 42 | Iteration number: [3190/4518] 70% | Training loss: 0.6870234026991088
Epoch: 42 | Iteration number: [3200/4518] 70% | Training loss: 0.6870193761028349
Epoch: 42 | Iteration number: [3210/4518] 71% | Training loss: 0.6870228498895592
Epoch: 42 | Iteration number: [3220/4518] 71% | Training loss: 0.6870237912820734
Epoch: 42 | Iteration number: [3230/4518] 71% | Training loss: 0.6870241079721657
Epoch: 42 | Iteration number: [3240/4518] 71% | Training loss: 0.6870185244414542
Epoch: 42 | Iteration number: [3250/4518] 71% | Training loss: 0.6870217389326829
Epoch: 42 | Iteration number: [3260/4518] 72% | Training loss: 0.6870194900620934
Epoch: 42 | Iteration number: [3270/4518] 72% | Training loss: 0.6870200909423536
Epoch: 42 | Iteration number: [3280/4518] 72% | Training loss: 0.6870196156022025
Epoch: 42 | Iteration number: [3290/4518] 72% | Training loss: 0.6870150290542822
Epoch: 42 | Iteration number: [3300/4518] 73% | Training loss: 0.6870134056156332
Epoch: 42 | Iteration number: [3310/4518] 73% | Training loss: 0.6870126827605901
Epoch: 42 | Iteration number: [3320/4518] 73% | Training loss: 0.6870095766811486
Epoch: 42 | Iteration number: [3330/4518] 73% | Training loss: 0.6870077461988718
Epoch: 42 | Iteration number: [3340/4518] 73% | Training loss: 0.6870058434987496
Epoch: 42 | Iteration number: [3350/4518] 74% | Training loss: 0.6870044250452696
Epoch: 42 | Iteration number: [3360/4518] 74% | Training loss: 0.6870024287984484
Epoch: 42 | Iteration number: [3370/4518] 74% | Training loss: 0.6870048653478085
Epoch: 42 | Iteration number: [3380/4518] 74% | Training loss: 0.6870067748974061
Epoch: 42 | Iteration number: [3390/4518] 75% | Training loss: 0.6870054796382038
Epoch: 42 | Iteration number: [3400/4518] 75% | Training loss: 0.6870074158030398
Epoch: 42 | Iteration number: [3410/4518] 75% | Training loss: 0.6870092482685694
Epoch: 42 | Iteration number: [3420/4518] 75% | Training loss: 0.6870092437455528
Epoch: 42 | Iteration number: [3430/4518] 75% | Training loss: 0.6870119919929838
Epoch: 42 | Iteration number: [3440/4518] 76% | Training loss: 0.687013842442701
Epoch: 42 | Iteration number: [3450/4518] 76% | Training loss: 0.6870126094334368
Epoch: 42 | Iteration number: [3460/4518] 76% | Training loss: 0.6870097286956158
Epoch: 42 | Iteration number: [3470/4518] 76% | Training loss: 0.687012445634655
Epoch: 42 | Iteration number: [3480/4518] 77% | Training loss: 0.6870130309942125
Epoch: 42 | Iteration number: [3490/4518] 77% | Training loss: 0.6870142404363627
Epoch: 42 | Iteration number: [3500/4518] 77% | Training loss: 0.6870143628801618
Epoch: 42 | Iteration number: [3510/4518] 77% | Training loss: 0.6870119650309582
Epoch: 42 | Iteration number: [3520/4518] 77% | Training loss: 0.6870060648430477
Epoch: 42 | Iteration number: [3530/4518] 78% | Training loss: 0.6870047326803883
Epoch: 42 | Iteration number: [3540/4518] 78% | Training loss: 0.6870104481439806
Epoch: 42 | Iteration number: [3550/4518] 78% | Training loss: 0.6870114827995569
Epoch: 42 | Iteration number: [3560/4518] 78% | Training loss: 0.6870143722449795
Epoch: 42 | Iteration number: [3570/4518] 79% | Training loss: 0.687015743148761
Epoch: 42 | Iteration number: [3580/4518] 79% | Training loss: 0.6870159172479001
Epoch: 42 | Iteration number: [3590/4518] 79% | Training loss: 0.6870143607798394
Epoch: 42 | Iteration number: [3600/4518] 79% | Training loss: 0.6870118472311232
Epoch: 42 | Iteration number: [3610/4518] 79% | Training loss: 0.6870127227993222
Epoch: 42 | Iteration number: [3620/4518] 80% | Training loss: 0.6870108693673466
Epoch: 42 | Iteration number: [3630/4518] 80% | Training loss: 0.6870087340022578
Epoch: 42 | Iteration number: [3640/4518] 80% | Training loss: 0.6870123974897049
Epoch: 42 | Iteration number: [3650/4518] 80% | Training loss: 0.6870106741826828
Epoch: 42 | Iteration number: [3660/4518] 81% | Training loss: 0.6870140486727647
Epoch: 42 | Iteration number: [3670/4518] 81% | Training loss: 0.6870174640693196
Epoch: 42 | Iteration number: [3680/4518] 81% | Training loss: 0.6870188802480698
Epoch: 42 | Iteration number: [3690/4518] 81% | Training loss: 0.6870201985687421
Epoch: 42 | Iteration number: [3700/4518] 81% | Training loss: 0.6870229834479255
Epoch: 42 | Iteration number: [3710/4518] 82% | Training loss: 0.687027656164452
Epoch: 42 | Iteration number: [3720/4518] 82% | Training loss: 0.6870295411796981
Epoch: 42 | Iteration number: [3730/4518] 82% | Training loss: 0.6870283341919129
Epoch: 42 | Iteration number: [3740/4518] 82% | Training loss: 0.687029710762641
Epoch: 42 | Iteration number: [3750/4518] 83% | Training loss: 0.6870277831713358
Epoch: 42 | Iteration number: [3760/4518] 83% | Training loss: 0.6870287718132455
Epoch: 42 | Iteration number: [3770/4518] 83% | Training loss: 0.687028463939773
Epoch: 42 | Iteration number: [3780/4518] 83% | Training loss: 0.687031101328986
Epoch: 42 | Iteration number: [3790/4518] 83% | Training loss: 0.6870308739371539
Epoch: 42 | Iteration number: [3800/4518] 84% | Training loss: 0.6870325078776008
Epoch: 42 | Iteration number: [3810/4518] 84% | Training loss: 0.687031298062307
Epoch: 42 | Iteration number: [3820/4518] 84% | Training loss: 0.6870286191789268
Epoch: 42 | Iteration number: [3830/4518] 84% | Training loss: 0.6870296853951935
Epoch: 42 | Iteration number: [3840/4518] 84% | Training loss: 0.6870268784618626
Epoch: 42 | Iteration number: [3850/4518] 85% | Training loss: 0.687025989866876
Epoch: 42 | Iteration number: [3860/4518] 85% | Training loss: 0.6870258043312656
Epoch: 42 | Iteration number: [3870/4518] 85% | Training loss: 0.6870199774278842
Epoch: 42 | Iteration number: [3880/4518] 85% | Training loss: 0.6870202326436633
Epoch: 42 | Iteration number: [3890/4518] 86% | Training loss: 0.6870153928017555
Epoch: 42 | Iteration number: [3900/4518] 86% | Training loss: 0.6870131841989664
Epoch: 42 | Iteration number: [3910/4518] 86% | Training loss: 0.6870143630010698
Epoch: 42 | Iteration number: [3920/4518] 86% | Training loss: 0.6870117566263189
Epoch: 42 | Iteration number: [3930/4518] 86% | Training loss: 0.6870133852837347
Epoch: 42 | Iteration number: [3940/4518] 87% | Training loss: 0.6870135339080985
Epoch: 42 | Iteration number: [3950/4518] 87% | Training loss: 0.6870128222809562
Epoch: 42 | Iteration number: [3960/4518] 87% | Training loss: 0.6870121972578944
Epoch: 42 | Iteration number: [3970/4518] 87% | Training loss: 0.6870116899235723
Epoch: 42 | Iteration number: [3980/4518] 88% | Training loss: 0.6870148612775995
Epoch: 42 | Iteration number: [3990/4518] 88% | Training loss: 0.6870139403301373
Epoch: 42 | Iteration number: [4000/4518] 88% | Training loss: 0.6870121283531189
Epoch: 42 | Iteration number: [4010/4518] 88% | Training loss: 0.6870091236588961
Epoch: 42 | Iteration number: [4020/4518] 88% | Training loss: 0.6870091570550529
Epoch: 42 | Iteration number: [4030/4518] 89% | Training loss: 0.6870078256201212
Epoch: 42 | Iteration number: [4040/4518] 89% | Training loss: 0.687007293828053
Epoch: 42 | Iteration number: [4050/4518] 89% | Training loss: 0.6870086443718568
Epoch: 42 | Iteration number: [4060/4518] 89% | Training loss: 0.687005780013324
Epoch: 42 | Iteration number: [4070/4518] 90% | Training loss: 0.6870017169734477
Epoch: 42 | Iteration number: [4080/4518] 90% | Training loss: 0.6870044225132933
Epoch: 42 | Iteration number: [4090/4518] 90% | Training loss: 0.6870015443828694
Epoch: 42 | Iteration number: [4100/4518] 90% | Training loss: 0.687000626907116
Epoch: 42 | Iteration number: [4110/4518] 90% | Training loss: 0.6870009603871626
Epoch: 42 | Iteration number: [4120/4518] 91% | Training loss: 0.6870020483593339
Epoch: 42 | Iteration number: [4130/4518] 91% | Training loss: 0.6870002267724377
Epoch: 42 | Iteration number: [4140/4518] 91% | Training loss: 0.6870011522862071
Epoch: 42 | Iteration number: [4150/4518] 91% | Training loss: 0.6870014397063887
Epoch: 42 | Iteration number: [4160/4518] 92% | Training loss: 0.6869981287763669
Epoch: 42 | Iteration number: [4170/4518] 92% | Training loss: 0.6869966368166377
Epoch: 42 | Iteration number: [4180/4518] 92% | Training loss: 0.6869980517329212
Epoch: 42 | Iteration number: [4190/4518] 92% | Training loss: 0.6869973129190522
Epoch: 42 | Iteration number: [4200/4518] 92% | Training loss: 0.6869961676711128
Epoch: 42 | Iteration number: [4210/4518] 93% | Training loss: 0.6869981993122508
Epoch: 42 | Iteration number: [4220/4518] 93% | Training loss: 0.6869945261009497
Epoch: 42 | Iteration number: [4230/4518] 93% | Training loss: 0.6869916840507065
Epoch: 42 | Iteration number: [4240/4518] 93% | Training loss: 0.6869881791747966
Epoch: 42 | Iteration number: [4250/4518] 94% | Training loss: 0.6869896020328298
Epoch: 42 | Iteration number: [4260/4518] 94% | Training loss: 0.6869876146876196
Epoch: 42 | Iteration number: [4270/4518] 94% | Training loss: 0.6869870454003157
Epoch: 42 | Iteration number: [4280/4518] 94% | Training loss: 0.6869854884587716
Epoch: 42 | Iteration number: [4290/4518] 94% | Training loss: 0.6869830763284421
Epoch: 42 | Iteration number: [4300/4518] 95% | Training loss: 0.6869820144425991
Epoch: 42 | Iteration number: [4310/4518] 95% | Training loss: 0.6869821390668643
Epoch: 42 | Iteration number: [4320/4518] 95% | Training loss: 0.6869809387872616
Epoch: 42 | Iteration number: [4330/4518] 95% | Training loss: 0.6869810457868334
Epoch: 42 | Iteration number: [4340/4518] 96% | Training loss: 0.6869811670159415
Epoch: 42 | Iteration number: [4350/4518] 96% | Training loss: 0.686980718415359
Epoch: 42 | Iteration number: [4360/4518] 96% | Training loss: 0.6869802129104596
Epoch: 42 | Iteration number: [4370/4518] 96% | Training loss: 0.6869810929151094
Epoch: 42 | Iteration number: [4380/4518] 96% | Training loss: 0.6869813467405702
Epoch: 42 | Iteration number: [4390/4518] 97% | Training loss: 0.6869848672512724
Epoch: 42 | Iteration number: [4400/4518] 97% | Training loss: 0.6869866372238506
Epoch: 42 | Iteration number: [4410/4518] 97% | Training loss: 0.6869870064480235
Epoch: 42 | Iteration number: [4420/4518] 97% | Training loss: 0.6869865518619572
Epoch: 42 | Iteration number: [4430/4518] 98% | Training loss: 0.6869853760803257
Epoch: 42 | Iteration number: [4440/4518] 98% | Training loss: 0.6869815050213186
Epoch: 42 | Iteration number: [4450/4518] 98% | Training loss: 0.6869777692167947
Epoch: 42 | Iteration number: [4460/4518] 98% | Training loss: 0.6869745780801559
Epoch: 42 | Iteration number: [4470/4518] 98% | Training loss: 0.6869734645023176
Epoch: 42 | Iteration number: [4480/4518] 99% | Training loss: 0.6869713461558734
Epoch: 42 | Iteration number: [4490/4518] 99% | Training loss: 0.6869718668322786
Epoch: 42 | Iteration number: [4500/4518] 99% | Training loss: 0.6869691373507182
Epoch: 42 | Iteration number: [4510/4518] 99% | Training loss: 0.6869704472912918

 End of epoch: 42 | Train Loss: 0.6868199576393278 | Training Time: 633 

 End of epoch: 42 | Eval Loss: 0.6897843540931234 | Evaluating Time: 17 
Epoch: 43 | Iteration number: [10/4518] 0% | Training loss: 0.7568156003952027
Epoch: 43 | Iteration number: [20/4518] 0% | Training loss: 0.7222061306238174
Epoch: 43 | Iteration number: [30/4518] 0% | Training loss: 0.7108882407347361
Epoch: 43 | Iteration number: [40/4518] 0% | Training loss: 0.7048514544963836
Epoch: 43 | Iteration number: [50/4518] 1% | Training loss: 0.7014154040813446
Epoch: 43 | Iteration number: [60/4518] 1% | Training loss: 0.6990604480107625
Epoch: 43 | Iteration number: [70/4518] 1% | Training loss: 0.6974016376904079
Epoch: 43 | Iteration number: [80/4518] 1% | Training loss: 0.6959967195987702
Epoch: 43 | Iteration number: [90/4518] 1% | Training loss: 0.694799855682585
Epoch: 43 | Iteration number: [100/4518] 2% | Training loss: 0.6941176110506058
Epoch: 43 | Iteration number: [110/4518] 2% | Training loss: 0.6934493232857097
Epoch: 43 | Iteration number: [120/4518] 2% | Training loss: 0.6928039302428564
Epoch: 43 | Iteration number: [130/4518] 2% | Training loss: 0.6924013357896072
Epoch: 43 | Iteration number: [140/4518] 3% | Training loss: 0.6919831378119332
Epoch: 43 | Iteration number: [150/4518] 3% | Training loss: 0.6915759992599487
Epoch: 43 | Iteration number: [160/4518] 3% | Training loss: 0.6913400523364543
Epoch: 43 | Iteration number: [170/4518] 3% | Training loss: 0.6910442145431743
Epoch: 43 | Iteration number: [180/4518] 3% | Training loss: 0.6908328387472364
Epoch: 43 | Iteration number: [190/4518] 4% | Training loss: 0.6906577806723745
Epoch: 43 | Iteration number: [200/4518] 4% | Training loss: 0.6904484891891479
Epoch: 43 | Iteration number: [210/4518] 4% | Training loss: 0.6902370799155463
Epoch: 43 | Iteration number: [220/4518] 4% | Training loss: 0.6900856381112879
Epoch: 43 | Iteration number: [230/4518] 5% | Training loss: 0.6899346525254457
Epoch: 43 | Iteration number: [240/4518] 5% | Training loss: 0.6898269861936569
Epoch: 43 | Iteration number: [250/4518] 5% | Training loss: 0.6897422699928284
Epoch: 43 | Iteration number: [260/4518] 5% | Training loss: 0.6896573495406371
Epoch: 43 | Iteration number: [270/4518] 5% | Training loss: 0.6895603413935061
Epoch: 43 | Iteration number: [280/4518] 6% | Training loss: 0.6894832236426217
Epoch: 43 | Iteration number: [290/4518] 6% | Training loss: 0.689329836697414
Epoch: 43 | Iteration number: [300/4518] 6% | Training loss: 0.6892495979865392
Epoch: 43 | Iteration number: [310/4518] 6% | Training loss: 0.6891443419841028
Epoch: 43 | Iteration number: [320/4518] 7% | Training loss: 0.689047173038125
Epoch: 43 | Iteration number: [330/4518] 7% | Training loss: 0.6889625688393911
Epoch: 43 | Iteration number: [340/4518] 7% | Training loss: 0.6888913673513076
Epoch: 43 | Iteration number: [350/4518] 7% | Training loss: 0.6888382511479514
Epoch: 43 | Iteration number: [360/4518] 7% | Training loss: 0.6887960422370168
Epoch: 43 | Iteration number: [370/4518] 8% | Training loss: 0.6887301417621406
Epoch: 43 | Iteration number: [380/4518] 8% | Training loss: 0.6886755657823462
Epoch: 43 | Iteration number: [390/4518] 8% | Training loss: 0.6886448867810078
Epoch: 43 | Iteration number: [400/4518] 8% | Training loss: 0.688592988550663
Epoch: 43 | Iteration number: [410/4518] 9% | Training loss: 0.6885539845722478
Epoch: 43 | Iteration number: [420/4518] 9% | Training loss: 0.6884931159870965
Epoch: 43 | Iteration number: [430/4518] 9% | Training loss: 0.6884481869464697
Epoch: 43 | Iteration number: [440/4518] 9% | Training loss: 0.6884083674712614
Epoch: 43 | Iteration number: [450/4518] 9% | Training loss: 0.6883356704976824
Epoch: 43 | Iteration number: [460/4518] 10% | Training loss: 0.6883026049188946
Epoch: 43 | Iteration number: [470/4518] 10% | Training loss: 0.6882690820288151
Epoch: 43 | Iteration number: [480/4518] 10% | Training loss: 0.6882550075650216
Epoch: 43 | Iteration number: [490/4518] 10% | Training loss: 0.6882241904735565
Epoch: 43 | Iteration number: [500/4518] 11% | Training loss: 0.6881985739469528
Epoch: 43 | Iteration number: [510/4518] 11% | Training loss: 0.6881779445152657
Epoch: 43 | Iteration number: [520/4518] 11% | Training loss: 0.6881556846774541
Epoch: 43 | Iteration number: [530/4518] 11% | Training loss: 0.6881295423462706
Epoch: 43 | Iteration number: [540/4518] 11% | Training loss: 0.6881223649890335
Epoch: 43 | Iteration number: [550/4518] 12% | Training loss: 0.6880564212799072
Epoch: 43 | Iteration number: [560/4518] 12% | Training loss: 0.6880354853613037
Epoch: 43 | Iteration number: [570/4518] 12% | Training loss: 0.6880185683568318
Epoch: 43 | Iteration number: [580/4518] 12% | Training loss: 0.687983227598256
Epoch: 43 | Iteration number: [590/4518] 13% | Training loss: 0.6879502124705557
Epoch: 43 | Iteration number: [600/4518] 13% | Training loss: 0.6879225866993268
Epoch: 43 | Iteration number: [610/4518] 13% | Training loss: 0.6879032261058933
Epoch: 43 | Iteration number: [620/4518] 13% | Training loss: 0.6878850461975221
Epoch: 43 | Iteration number: [630/4518] 13% | Training loss: 0.6878483757140145
Epoch: 43 | Iteration number: [640/4518] 14% | Training loss: 0.6878547023981809
Epoch: 43 | Iteration number: [650/4518] 14% | Training loss: 0.6878236580812014
Epoch: 43 | Iteration number: [660/4518] 14% | Training loss: 0.6878109955426418
Epoch: 43 | Iteration number: [670/4518] 14% | Training loss: 0.6878219209500214
Epoch: 43 | Iteration number: [680/4518] 15% | Training loss: 0.6877975196522825
Epoch: 43 | Iteration number: [690/4518] 15% | Training loss: 0.6877796760503797
Epoch: 43 | Iteration number: [700/4518] 15% | Training loss: 0.6877569669485092
Epoch: 43 | Iteration number: [710/4518] 15% | Training loss: 0.6877662405161791
Epoch: 43 | Iteration number: [720/4518] 15% | Training loss: 0.687741709417767
Epoch: 43 | Iteration number: [730/4518] 16% | Training loss: 0.6877304193091719
Epoch: 43 | Iteration number: [740/4518] 16% | Training loss: 0.687728129206477
Epoch: 43 | Iteration number: [750/4518] 16% | Training loss: 0.68773894794782
Epoch: 43 | Iteration number: [760/4518] 16% | Training loss: 0.6877384501068216
Epoch: 43 | Iteration number: [770/4518] 17% | Training loss: 0.6877414451017008
Epoch: 43 | Iteration number: [780/4518] 17% | Training loss: 0.6877363809408286
Epoch: 43 | Iteration number: [790/4518] 17% | Training loss: 0.6877220257928099
Epoch: 43 | Iteration number: [800/4518] 17% | Training loss: 0.6877106889337301
Epoch: 43 | Iteration number: [810/4518] 17% | Training loss: 0.6877064606289804
Epoch: 43 | Iteration number: [820/4518] 18% | Training loss: 0.6876941846638192
Epoch: 43 | Iteration number: [830/4518] 18% | Training loss: 0.687681152231722
Epoch: 43 | Iteration number: [840/4518] 18% | Training loss: 0.6876783314205351
Epoch: 43 | Iteration number: [850/4518] 18% | Training loss: 0.6876675030063181
Epoch: 43 | Iteration number: [860/4518] 19% | Training loss: 0.6876396463360898
Epoch: 43 | Iteration number: [870/4518] 19% | Training loss: 0.6876240869363149
Epoch: 43 | Iteration number: [880/4518] 19% | Training loss: 0.6876229963519357
Epoch: 43 | Iteration number: [890/4518] 19% | Training loss: 0.6876134654109398
Epoch: 43 | Iteration number: [900/4518] 19% | Training loss: 0.6875929710600112
Epoch: 43 | Iteration number: [910/4518] 20% | Training loss: 0.6875934831388704
Epoch: 43 | Iteration number: [920/4518] 20% | Training loss: 0.6875794968527297
Epoch: 43 | Iteration number: [930/4518] 20% | Training loss: 0.6875778460374442
Epoch: 43 | Iteration number: [940/4518] 20% | Training loss: 0.6875804476915521
Epoch: 43 | Iteration number: [950/4518] 21% | Training loss: 0.687574057704524
Epoch: 43 | Iteration number: [960/4518] 21% | Training loss: 0.6875663729384541
Epoch: 43 | Iteration number: [970/4518] 21% | Training loss: 0.6875688419514095
Epoch: 43 | Iteration number: [980/4518] 21% | Training loss: 0.6875670556511198
Epoch: 43 | Iteration number: [990/4518] 21% | Training loss: 0.6875735579717038
Epoch: 43 | Iteration number: [1000/4518] 22% | Training loss: 0.6875640486478806
Epoch: 43 | Iteration number: [1010/4518] 22% | Training loss: 0.6875633360135673
Epoch: 43 | Iteration number: [1020/4518] 22% | Training loss: 0.6875537862964705
Epoch: 43 | Iteration number: [1030/4518] 22% | Training loss: 0.6875493962209202
Epoch: 43 | Iteration number: [1040/4518] 23% | Training loss: 0.6875439752179843
Epoch: 43 | Iteration number: [1050/4518] 23% | Training loss: 0.6875506641751244
Epoch: 43 | Iteration number: [1060/4518] 23% | Training loss: 0.6875450310842046
Epoch: 43 | Iteration number: [1070/4518] 23% | Training loss: 0.6875302470733072
Epoch: 43 | Iteration number: [1080/4518] 23% | Training loss: 0.6875175684690475
Epoch: 43 | Iteration number: [1090/4518] 24% | Training loss: 0.6875080759372186
Epoch: 43 | Iteration number: [1100/4518] 24% | Training loss: 0.6875047588348389
Epoch: 43 | Iteration number: [1110/4518] 24% | Training loss: 0.6874969966239758
Epoch: 43 | Iteration number: [1120/4518] 24% | Training loss: 0.6874833472073079
Epoch: 43 | Iteration number: [1130/4518] 25% | Training loss: 0.6874757879075751
Epoch: 43 | Iteration number: [1140/4518] 25% | Training loss: 0.6874655188698517
Epoch: 43 | Iteration number: [1150/4518] 25% | Training loss: 0.6874600472657577
Epoch: 43 | Iteration number: [1160/4518] 25% | Training loss: 0.687458429973701
Epoch: 43 | Iteration number: [1170/4518] 25% | Training loss: 0.6874499230812757
Epoch: 43 | Iteration number: [1180/4518] 26% | Training loss: 0.6874441110986774
Epoch: 43 | Iteration number: [1190/4518] 26% | Training loss: 0.6874374199815158
Epoch: 43 | Iteration number: [1200/4518] 26% | Training loss: 0.6874288945396742
Epoch: 43 | Iteration number: [1210/4518] 26% | Training loss: 0.6874301597599156
Epoch: 43 | Iteration number: [1220/4518] 27% | Training loss: 0.6874267192160497
Epoch: 43 | Iteration number: [1230/4518] 27% | Training loss: 0.6874188737171453
Epoch: 43 | Iteration number: [1240/4518] 27% | Training loss: 0.6874175196213107
Epoch: 43 | Iteration number: [1250/4518] 27% | Training loss: 0.6874159463882447
Epoch: 43 | Iteration number: [1260/4518] 27% | Training loss: 0.6874108801285426
Epoch: 43 | Iteration number: [1270/4518] 28% | Training loss: 0.6874151075918843
Epoch: 43 | Iteration number: [1280/4518] 28% | Training loss: 0.687403132719919
Epoch: 43 | Iteration number: [1290/4518] 28% | Training loss: 0.6873959759409114
Epoch: 43 | Iteration number: [1300/4518] 28% | Training loss: 0.6873942262851275
Epoch: 43 | Iteration number: [1310/4518] 28% | Training loss: 0.6873853436408152
Epoch: 43 | Iteration number: [1320/4518] 29% | Training loss: 0.687390027624188
Epoch: 43 | Iteration number: [1330/4518] 29% | Training loss: 0.6873814766120193
Epoch: 43 | Iteration number: [1340/4518] 29% | Training loss: 0.6873762041775149
Epoch: 43 | Iteration number: [1350/4518] 29% | Training loss: 0.6873790777612615
Epoch: 43 | Iteration number: [1360/4518] 30% | Training loss: 0.6873774069635307
Epoch: 43 | Iteration number: [1370/4518] 30% | Training loss: 0.6873748881538418
Epoch: 43 | Iteration number: [1380/4518] 30% | Training loss: 0.6873790055945299
Epoch: 43 | Iteration number: [1390/4518] 30% | Training loss: 0.6873678029441147
Epoch: 43 | Iteration number: [1400/4518] 30% | Training loss: 0.6873679774573871
Epoch: 43 | Iteration number: [1410/4518] 31% | Training loss: 0.6873654064557231
Epoch: 43 | Iteration number: [1420/4518] 31% | Training loss: 0.6873688596235195
Epoch: 43 | Iteration number: [1430/4518] 31% | Training loss: 0.6873634855230372
Epoch: 43 | Iteration number: [1440/4518] 31% | Training loss: 0.6873643604003721
Epoch: 43 | Iteration number: [1450/4518] 32% | Training loss: 0.6873546511551429
Epoch: 43 | Iteration number: [1460/4518] 32% | Training loss: 0.6873419501193582
Epoch: 43 | Iteration number: [1470/4518] 32% | Training loss: 0.6873409179197688
Epoch: 43 | Iteration number: [1480/4518] 32% | Training loss: 0.6873425526393426
Epoch: 43 | Iteration number: [1490/4518] 32% | Training loss: 0.6873504929094506
Epoch: 43 | Iteration number: [1500/4518] 33% | Training loss: 0.6873505310614904
Epoch: 43 | Iteration number: [1510/4518] 33% | Training loss: 0.6873493354052108
Epoch: 43 | Iteration number: [1520/4518] 33% | Training loss: 0.6873549211574228
Epoch: 43 | Iteration number: [1530/4518] 33% | Training loss: 0.6873566721389496
Epoch: 43 | Iteration number: [1540/4518] 34% | Training loss: 0.6873464928044901
Epoch: 43 | Iteration number: [1550/4518] 34% | Training loss: 0.6873496658186758
Epoch: 43 | Iteration number: [1560/4518] 34% | Training loss: 0.6873548173369506
Epoch: 43 | Iteration number: [1570/4518] 34% | Training loss: 0.6873485837392747
Epoch: 43 | Iteration number: [1580/4518] 34% | Training loss: 0.6873532023233704
Epoch: 43 | Iteration number: [1590/4518] 35% | Training loss: 0.6873472698829459
Epoch: 43 | Iteration number: [1600/4518] 35% | Training loss: 0.6873426459357143
Epoch: 43 | Iteration number: [1610/4518] 35% | Training loss: 0.6873335207841411
Epoch: 43 | Iteration number: [1620/4518] 35% | Training loss: 0.6873259238990737
Epoch: 43 | Iteration number: [1630/4518] 36% | Training loss: 0.6873180734233623
Epoch: 43 | Iteration number: [1640/4518] 36% | Training loss: 0.6873177547280381
Epoch: 43 | Iteration number: [1650/4518] 36% | Training loss: 0.6873147154938091
Epoch: 43 | Iteration number: [1660/4518] 36% | Training loss: 0.6873132124363658
Epoch: 43 | Iteration number: [1670/4518] 36% | Training loss: 0.6873036021957855
Epoch: 43 | Iteration number: [1680/4518] 37% | Training loss: 0.6873026340135506
Epoch: 43 | Iteration number: [1690/4518] 37% | Training loss: 0.6872995211880588
Epoch: 43 | Iteration number: [1700/4518] 37% | Training loss: 0.6873032216464772
Epoch: 43 | Iteration number: [1710/4518] 37% | Training loss: 0.6872958691496598
Epoch: 43 | Iteration number: [1720/4518] 38% | Training loss: 0.6872859452006429
Epoch: 43 | Iteration number: [1730/4518] 38% | Training loss: 0.6872828127676351
Epoch: 43 | Iteration number: [1740/4518] 38% | Training loss: 0.6872812881209385
Epoch: 43 | Iteration number: [1750/4518] 38% | Training loss: 0.6872786561080387
Epoch: 43 | Iteration number: [1760/4518] 38% | Training loss: 0.6872711106118831
Epoch: 43 | Iteration number: [1770/4518] 39% | Training loss: 0.68727213632589
Epoch: 43 | Iteration number: [1780/4518] 39% | Training loss: 0.687268924813592
Epoch: 43 | Iteration number: [1790/4518] 39% | Training loss: 0.6872691694251651
Epoch: 43 | Iteration number: [1800/4518] 39% | Training loss: 0.6872718495461676
Epoch: 43 | Iteration number: [1810/4518] 40% | Training loss: 0.6872674828076231
Epoch: 43 | Iteration number: [1820/4518] 40% | Training loss: 0.6872594752482005
Epoch: 43 | Iteration number: [1830/4518] 40% | Training loss: 0.6872552208236007
Epoch: 43 | Iteration number: [1840/4518] 40% | Training loss: 0.6872480128446351
Epoch: 43 | Iteration number: [1850/4518] 40% | Training loss: 0.6872489318654343
Epoch: 43 | Iteration number: [1860/4518] 41% | Training loss: 0.6872446695643086
Epoch: 43 | Iteration number: [1870/4518] 41% | Training loss: 0.6872505717099031
Epoch: 43 | Iteration number: [1880/4518] 41% | Training loss: 0.6872490111500659
Epoch: 43 | Iteration number: [1890/4518] 41% | Training loss: 0.6872403632396112
Epoch: 43 | Iteration number: [1900/4518] 42% | Training loss: 0.6872440121989501
Epoch: 43 | Iteration number: [1910/4518] 42% | Training loss: 0.6872419272417798
Epoch: 43 | Iteration number: [1920/4518] 42% | Training loss: 0.6872428060819705
Epoch: 43 | Iteration number: [1930/4518] 42% | Training loss: 0.6872377152578818
Epoch: 43 | Iteration number: [1940/4518] 42% | Training loss: 0.6872363890569234
Epoch: 43 | Iteration number: [1950/4518] 43% | Training loss: 0.6872304966816536
Epoch: 43 | Iteration number: [1960/4518] 43% | Training loss: 0.6872356959751674
Epoch: 43 | Iteration number: [1970/4518] 43% | Training loss: 0.6872342473661839
Epoch: 43 | Iteration number: [1980/4518] 43% | Training loss: 0.6872233087065244
Epoch: 43 | Iteration number: [1990/4518] 44% | Training loss: 0.6872241450015025
Epoch: 43 | Iteration number: [2000/4518] 44% | Training loss: 0.6872192503809929
Epoch: 43 | Iteration number: [2010/4518] 44% | Training loss: 0.6872123510683353
Epoch: 43 | Iteration number: [2020/4518] 44% | Training loss: 0.6872073919171154
Epoch: 43 | Iteration number: [2030/4518] 44% | Training loss: 0.6872106841925917
Epoch: 43 | Iteration number: [2040/4518] 45% | Training loss: 0.687210430497048
Epoch: 43 | Iteration number: [2050/4518] 45% | Training loss: 0.6871991856795986
Epoch: 43 | Iteration number: [2060/4518] 45% | Training loss: 0.6871983491679997
Epoch: 43 | Iteration number: [2070/4518] 45% | Training loss: 0.6871959321164854
Epoch: 43 | Iteration number: [2080/4518] 46% | Training loss: 0.6871961163500181
Epoch: 43 | Iteration number: [2090/4518] 46% | Training loss: 0.6871972517533735
Epoch: 43 | Iteration number: [2100/4518] 46% | Training loss: 0.687194523413976
Epoch: 43 | Iteration number: [2110/4518] 46% | Training loss: 0.6871921302865467
Epoch: 43 | Iteration number: [2120/4518] 46% | Training loss: 0.6871911750649506
Epoch: 43 | Iteration number: [2130/4518] 47% | Training loss: 0.6871913035430819
Epoch: 43 | Iteration number: [2140/4518] 47% | Training loss: 0.6871880264761292
Epoch: 43 | Iteration number: [2150/4518] 47% | Training loss: 0.6871858976330868
Epoch: 43 | Iteration number: [2160/4518] 47% | Training loss: 0.687181350643988
Epoch: 43 | Iteration number: [2170/4518] 48% | Training loss: 0.6871796708777204
Epoch: 43 | Iteration number: [2180/4518] 48% | Training loss: 0.6871786537793798
Epoch: 43 | Iteration number: [2190/4518] 48% | Training loss: 0.6871765188974877
Epoch: 43 | Iteration number: [2200/4518] 48% | Training loss: 0.6871728809855201
Epoch: 43 | Iteration number: [2210/4518] 48% | Training loss: 0.6871763530360088
Epoch: 43 | Iteration number: [2220/4518] 49% | Training loss: 0.6871769705065736
Epoch: 43 | Iteration number: [2230/4518] 49% | Training loss: 0.6871762296544062
Epoch: 43 | Iteration number: [2240/4518] 49% | Training loss: 0.6871698355834399
Epoch: 43 | Iteration number: [2250/4518] 49% | Training loss: 0.6871684198644427
Epoch: 43 | Iteration number: [2260/4518] 50% | Training loss: 0.6871602927952741
Epoch: 43 | Iteration number: [2270/4518] 50% | Training loss: 0.6871615735707304
Epoch: 43 | Iteration number: [2280/4518] 50% | Training loss: 0.6871536214100687
Epoch: 43 | Iteration number: [2290/4518] 50% | Training loss: 0.6871498385631362
Epoch: 43 | Iteration number: [2300/4518] 50% | Training loss: 0.6871524269425351
Epoch: 43 | Iteration number: [2310/4518] 51% | Training loss: 0.6871512132547635
Epoch: 43 | Iteration number: [2320/4518] 51% | Training loss: 0.6871479493276826
Epoch: 43 | Iteration number: [2330/4518] 51% | Training loss: 0.687142298073216
Epoch: 43 | Iteration number: [2340/4518] 51% | Training loss: 0.6871392422506952
Epoch: 43 | Iteration number: [2350/4518] 52% | Training loss: 0.6871394807227115
Epoch: 43 | Iteration number: [2360/4518] 52% | Training loss: 0.6871401718612444
Epoch: 43 | Iteration number: [2370/4518] 52% | Training loss: 0.6871339359112429
Epoch: 43 | Iteration number: [2380/4518] 52% | Training loss: 0.6871334710541893
Epoch: 43 | Iteration number: [2390/4518] 52% | Training loss: 0.687131098748251
Epoch: 43 | Iteration number: [2400/4518] 53% | Training loss: 0.6871354433149099
Epoch: 43 | Iteration number: [2410/4518] 53% | Training loss: 0.6871331563876377
Epoch: 43 | Iteration number: [2420/4518] 53% | Training loss: 0.6871346244634675
Epoch: 43 | Iteration number: [2430/4518] 53% | Training loss: 0.687132814563351
Epoch: 43 | Iteration number: [2440/4518] 54% | Training loss: 0.6871284692990975
Epoch: 43 | Iteration number: [2450/4518] 54% | Training loss: 0.687130316301268
Epoch: 43 | Iteration number: [2460/4518] 54% | Training loss: 0.6871284791851432
Epoch: 43 | Iteration number: [2470/4518] 54% | Training loss: 0.6871254270134667
Epoch: 43 | Iteration number: [2480/4518] 54% | Training loss: 0.6871265231120971
Epoch: 43 | Iteration number: [2490/4518] 55% | Training loss: 0.6871197818273521
Epoch: 43 | Iteration number: [2500/4518] 55% | Training loss: 0.6871183752536774
Epoch: 43 | Iteration number: [2510/4518] 55% | Training loss: 0.6871183600321233
Epoch: 43 | Iteration number: [2520/4518] 55% | Training loss: 0.687118910702448
Epoch: 43 | Iteration number: [2530/4518] 55% | Training loss: 0.687115341424942
Epoch: 43 | Iteration number: [2540/4518] 56% | Training loss: 0.6871129582716724
Epoch: 43 | Iteration number: [2550/4518] 56% | Training loss: 0.6871115271016663
Epoch: 43 | Iteration number: [2560/4518] 56% | Training loss: 0.687105497252196
Epoch: 43 | Iteration number: [2570/4518] 56% | Training loss: 0.6871055554091234
Epoch: 43 | Iteration number: [2580/4518] 57% | Training loss: 0.687104495874671
Epoch: 43 | Iteration number: [2590/4518] 57% | Training loss: 0.6871014177108824
Epoch: 43 | Iteration number: [2600/4518] 57% | Training loss: 0.687095881150319
Epoch: 43 | Iteration number: [2610/4518] 57% | Training loss: 0.6870939570825219
Epoch: 43 | Iteration number: [2620/4518] 57% | Training loss: 0.6870883517592918
Epoch: 43 | Iteration number: [2630/4518] 58% | Training loss: 0.6870890135774141
Epoch: 43 | Iteration number: [2640/4518] 58% | Training loss: 0.6870854897932572
Epoch: 43 | Iteration number: [2650/4518] 58% | Training loss: 0.6870807847886715
Epoch: 43 | Iteration number: [2660/4518] 58% | Training loss: 0.6870810583121795
Epoch: 43 | Iteration number: [2670/4518] 59% | Training loss: 0.6870779614323533
Epoch: 43 | Iteration number: [2680/4518] 59% | Training loss: 0.6870761799056139
Epoch: 43 | Iteration number: [2690/4518] 59% | Training loss: 0.6870690063473017
Epoch: 43 | Iteration number: [2700/4518] 59% | Training loss: 0.6870657596985499
Epoch: 43 | Iteration number: [2710/4518] 59% | Training loss: 0.6870627800476947
Epoch: 43 | Iteration number: [2720/4518] 60% | Training loss: 0.6870585864738507
Epoch: 43 | Iteration number: [2730/4518] 60% | Training loss: 0.6870556225488474
Epoch: 43 | Iteration number: [2740/4518] 60% | Training loss: 0.6870562376549644
Epoch: 43 | Iteration number: [2750/4518] 60% | Training loss: 0.6870584695772691
Epoch: 43 | Iteration number: [2760/4518] 61% | Training loss: 0.6870598242334698
Epoch: 43 | Iteration number: [2770/4518] 61% | Training loss: 0.6870581710381628
Epoch: 43 | Iteration number: [2780/4518] 61% | Training loss: 0.6870614380502015
Epoch: 43 | Iteration number: [2790/4518] 61% | Training loss: 0.687061243458888
Epoch: 43 | Iteration number: [2800/4518] 61% | Training loss: 0.6870592982854162
Epoch: 43 | Iteration number: [2810/4518] 62% | Training loss: 0.6870566009202461
Epoch: 43 | Iteration number: [2820/4518] 62% | Training loss: 0.6870560598077503
Epoch: 43 | Iteration number: [2830/4518] 62% | Training loss: 0.6870586380731091
Epoch: 43 | Iteration number: [2840/4518] 62% | Training loss: 0.6870595454330176
Epoch: 43 | Iteration number: [2850/4518] 63% | Training loss: 0.6870608432251111
Epoch: 43 | Iteration number: [2860/4518] 63% | Training loss: 0.6870589493246345
Epoch: 43 | Iteration number: [2870/4518] 63% | Training loss: 0.6870613346116468
Epoch: 43 | Iteration number: [2880/4518] 63% | Training loss: 0.687062314318286
Epoch: 43 | Iteration number: [2890/4518] 63% | Training loss: 0.6870649358186754
Epoch: 43 | Iteration number: [2900/4518] 64% | Training loss: 0.6870662672149724
Epoch: 43 | Iteration number: [2910/4518] 64% | Training loss: 0.68706341033539
Epoch: 43 | Iteration number: [2920/4518] 64% | Training loss: 0.6870626580021153
Epoch: 43 | Iteration number: [2930/4518] 64% | Training loss: 0.6870633056749663
Epoch: 43 | Iteration number: [2940/4518] 65% | Training loss: 0.6870568546308141
Epoch: 43 | Iteration number: [2950/4518] 65% | Training loss: 0.6870565184698266
Epoch: 43 | Iteration number: [2960/4518] 65% | Training loss: 0.687056081077537
Epoch: 43 | Iteration number: [2970/4518] 65% | Training loss: 0.6870537499586741
Epoch: 43 | Iteration number: [2980/4518] 65% | Training loss: 0.6870487087124946
Epoch: 43 | Iteration number: [2990/4518] 66% | Training loss: 0.6870460494904215
Epoch: 43 | Iteration number: [3000/4518] 66% | Training loss: 0.6870533507863681
Epoch: 43 | Iteration number: [3010/4518] 66% | Training loss: 0.6870499965162372
Epoch: 43 | Iteration number: [3020/4518] 66% | Training loss: 0.6870480225180948
Epoch: 43 | Iteration number: [3030/4518] 67% | Training loss: 0.6870489156285529
Epoch: 43 | Iteration number: [3040/4518] 67% | Training loss: 0.6870458070776965
Epoch: 43 | Iteration number: [3050/4518] 67% | Training loss: 0.6870454294955144
Epoch: 43 | Iteration number: [3060/4518] 67% | Training loss: 0.6870464612261142
Epoch: 43 | Iteration number: [3070/4518] 67% | Training loss: 0.687043387377301
Epoch: 43 | Iteration number: [3080/4518] 68% | Training loss: 0.6870473221331448
Epoch: 43 | Iteration number: [3090/4518] 68% | Training loss: 0.6870448677670994
Epoch: 43 | Iteration number: [3100/4518] 68% | Training loss: 0.6870471176793498
Epoch: 43 | Iteration number: [3110/4518] 68% | Training loss: 0.6870462608874036
Epoch: 43 | Iteration number: [3120/4518] 69% | Training loss: 0.6870467956822652
Epoch: 43 | Iteration number: [3130/4518] 69% | Training loss: 0.6870424437446716
Epoch: 43 | Iteration number: [3140/4518] 69% | Training loss: 0.6870417593960549
Epoch: 43 | Iteration number: [3150/4518] 69% | Training loss: 0.6870404379897648
Epoch: 43 | Iteration number: [3160/4518] 69% | Training loss: 0.6870409110113035
Epoch: 43 | Iteration number: [3170/4518] 70% | Training loss: 0.6870391715024172
Epoch: 43 | Iteration number: [3180/4518] 70% | Training loss: 0.6870407820122797
Epoch: 43 | Iteration number: [3190/4518] 70% | Training loss: 0.6870405521138708
Epoch: 43 | Iteration number: [3200/4518] 70% | Training loss: 0.6870347154140473
Epoch: 43 | Iteration number: [3210/4518] 71% | Training loss: 0.6870362213653196
Epoch: 43 | Iteration number: [3220/4518] 71% | Training loss: 0.6870398027926499
Epoch: 43 | Iteration number: [3230/4518] 71% | Training loss: 0.687041786543725
Epoch: 43 | Iteration number: [3240/4518] 71% | Training loss: 0.687042770985468
Epoch: 43 | Iteration number: [3250/4518] 71% | Training loss: 0.6870442247207348
Epoch: 43 | Iteration number: [3260/4518] 72% | Training loss: 0.6870430494561517
Epoch: 43 | Iteration number: [3270/4518] 72% | Training loss: 0.6870404134649749
Epoch: 43 | Iteration number: [3280/4518] 72% | Training loss: 0.6870401989032583
Epoch: 43 | Iteration number: [3290/4518] 72% | Training loss: 0.6870365325803091
Epoch: 43 | Iteration number: [3300/4518] 73% | Training loss: 0.6870375034845236
Epoch: 43 | Iteration number: [3310/4518] 73% | Training loss: 0.6870383301890509
Epoch: 43 | Iteration number: [3320/4518] 73% | Training loss: 0.6870370231299515
Epoch: 43 | Iteration number: [3330/4518] 73% | Training loss: 0.687035438176748
Epoch: 43 | Iteration number: [3340/4518] 73% | Training loss: 0.687034067725707
Epoch: 43 | Iteration number: [3350/4518] 74% | Training loss: 0.6870349930649373
Epoch: 43 | Iteration number: [3360/4518] 74% | Training loss: 0.6870321707179149
Epoch: 43 | Iteration number: [3370/4518] 74% | Training loss: 0.6870307348602249
Epoch: 43 | Iteration number: [3380/4518] 74% | Training loss: 0.6870292976586776
Epoch: 43 | Iteration number: [3390/4518] 75% | Training loss: 0.6870261427399683
Epoch: 43 | Iteration number: [3400/4518] 75% | Training loss: 0.6870263341069222
Epoch: 43 | Iteration number: [3410/4518] 75% | Training loss: 0.6870222556451199
Epoch: 43 | Iteration number: [3420/4518] 75% | Training loss: 0.6870209295150133
Epoch: 43 | Iteration number: [3430/4518] 75% | Training loss: 0.6870162875068431
Epoch: 43 | Iteration number: [3440/4518] 76% | Training loss: 0.6870191242979017
Epoch: 43 | Iteration number: [3450/4518] 76% | Training loss: 0.6870156853095345
Epoch: 43 | Iteration number: [3460/4518] 76% | Training loss: 0.6870116003848225
Epoch: 43 | Iteration number: [3470/4518] 76% | Training loss: 0.6870109318999804
Epoch: 43 | Iteration number: [3480/4518] 77% | Training loss: 0.6870112715952698
Epoch: 43 | Iteration number: [3490/4518] 77% | Training loss: 0.6870093043519979
Epoch: 43 | Iteration number: [3500/4518] 77% | Training loss: 0.6870093771389553
Epoch: 43 | Iteration number: [3510/4518] 77% | Training loss: 0.6870073742506511
Epoch: 43 | Iteration number: [3520/4518] 77% | Training loss: 0.6870042675598101
Epoch: 43 | Iteration number: [3530/4518] 78% | Training loss: 0.6870062354772692
Epoch: 43 | Iteration number: [3540/4518] 78% | Training loss: 0.6870079061574181
Epoch: 43 | Iteration number: [3550/4518] 78% | Training loss: 0.6870063327903478
Epoch: 43 | Iteration number: [3560/4518] 78% | Training loss: 0.6870061682683698
Epoch: 43 | Iteration number: [3570/4518] 79% | Training loss: 0.6870025942305557
Epoch: 43 | Iteration number: [3580/4518] 79% | Training loss: 0.6870036749200448
Epoch: 43 | Iteration number: [3590/4518] 79% | Training loss: 0.6870039206859461
Epoch: 43 | Iteration number: [3600/4518] 79% | Training loss: 0.6870066924889883
Epoch: 43 | Iteration number: [3610/4518] 79% | Training loss: 0.6870057716759288
Epoch: 43 | Iteration number: [3620/4518] 80% | Training loss: 0.6870045023893124
Epoch: 43 | Iteration number: [3630/4518] 80% | Training loss: 0.6870048793386822
Epoch: 43 | Iteration number: [3640/4518] 80% | Training loss: 0.6870049387544066
Epoch: 43 | Iteration number: [3650/4518] 80% | Training loss: 0.6870017619982157
Epoch: 43 | Iteration number: [3660/4518] 81% | Training loss: 0.6870018739029358
Epoch: 43 | Iteration number: [3670/4518] 81% | Training loss: 0.6870022261175213
Epoch: 43 | Iteration number: [3680/4518] 81% | Training loss: 0.6870023162144682
Epoch: 43 | Iteration number: [3690/4518] 81% | Training loss: 0.6869996226092341
Epoch: 43 | Iteration number: [3700/4518] 81% | Training loss: 0.6869980943041879
Epoch: 43 | Iteration number: [3710/4518] 82% | Training loss: 0.6869940927729131
Epoch: 43 | Iteration number: [3720/4518] 82% | Training loss: 0.6869913042232555
Epoch: 43 | Iteration number: [3730/4518] 82% | Training loss: 0.6869916607004068
Epoch: 43 | Iteration number: [3740/4518] 82% | Training loss: 0.6869901896160554
Epoch: 43 | Iteration number: [3750/4518] 83% | Training loss: 0.6869900909105937
Epoch: 43 | Iteration number: [3760/4518] 83% | Training loss: 0.6869894292918926
Epoch: 43 | Iteration number: [3770/4518] 83% | Training loss: 0.6869868746170631
Epoch: 43 | Iteration number: [3780/4518] 83% | Training loss: 0.6869841799691871
Epoch: 43 | Iteration number: [3790/4518] 83% | Training loss: 0.6869881498310371
Epoch: 43 | Iteration number: [3800/4518] 84% | Training loss: 0.6869884498025242
Epoch: 43 | Iteration number: [3810/4518] 84% | Training loss: 0.6869866037775525
Epoch: 43 | Iteration number: [3820/4518] 84% | Training loss: 0.6869847289086637
Epoch: 43 | Iteration number: [3830/4518] 84% | Training loss: 0.6869848573799233
Epoch: 43 | Iteration number: [3840/4518] 84% | Training loss: 0.6869835551207264
Epoch: 43 | Iteration number: [3850/4518] 85% | Training loss: 0.6869845775350347
Epoch: 43 | Iteration number: [3860/4518] 85% | Training loss: 0.6869828657937174
Epoch: 43 | Iteration number: [3870/4518] 85% | Training loss: 0.6869831293898343
Epoch: 43 | Iteration number: [3880/4518] 85% | Training loss: 0.6869797458968212
Epoch: 43 | Iteration number: [3890/4518] 86% | Training loss: 0.6869798586730173
Epoch: 43 | Iteration number: [3900/4518] 86% | Training loss: 0.6869789898395539
Epoch: 43 | Iteration number: [3910/4518] 86% | Training loss: 0.6869802832603454
Epoch: 43 | Iteration number: [3920/4518] 86% | Training loss: 0.6869822751198497
Epoch: 43 | Iteration number: [3930/4518] 86% | Training loss: 0.6869824434964712
Epoch: 43 | Iteration number: [3940/4518] 87% | Training loss: 0.6869819058833389
Epoch: 43 | Iteration number: [3950/4518] 87% | Training loss: 0.6869826668727247
Epoch: 43 | Iteration number: [3960/4518] 87% | Training loss: 0.6869841782884164
Epoch: 43 | Iteration number: [3970/4518] 87% | Training loss: 0.6869857761961987
Epoch: 43 | Iteration number: [3980/4518] 88% | Training loss: 0.6869869995057283
Epoch: 43 | Iteration number: [3990/4518] 88% | Training loss: 0.6869867295250857
Epoch: 43 | Iteration number: [4000/4518] 88% | Training loss: 0.6869853897243738
Epoch: 43 | Iteration number: [4010/4518] 88% | Training loss: 0.6869855199817411
Epoch: 43 | Iteration number: [4020/4518] 88% | Training loss: 0.6869829865682184
Epoch: 43 | Iteration number: [4030/4518] 89% | Training loss: 0.6869861717111715
Epoch: 43 | Iteration number: [4040/4518] 89% | Training loss: 0.6869838978099351
Epoch: 43 | Iteration number: [4050/4518] 89% | Training loss: 0.686986701871142
Epoch: 43 | Iteration number: [4060/4518] 89% | Training loss: 0.6869886036870515
Epoch: 43 | Iteration number: [4070/4518] 90% | Training loss: 0.6869884726017055
Epoch: 43 | Iteration number: [4080/4518] 90% | Training loss: 0.6869846475182795
Epoch: 43 | Iteration number: [4090/4518] 90% | Training loss: 0.6869828704225405
Epoch: 43 | Iteration number: [4100/4518] 90% | Training loss: 0.6869827394805303
Epoch: 43 | Iteration number: [4110/4518] 90% | Training loss: 0.6869795096906722
Epoch: 43 | Iteration number: [4120/4518] 91% | Training loss: 0.6869807146272613
Epoch: 43 | Iteration number: [4130/4518] 91% | Training loss: 0.686978423653157
Epoch: 43 | Iteration number: [4140/4518] 91% | Training loss: 0.6869796239955414
Epoch: 43 | Iteration number: [4150/4518] 91% | Training loss: 0.6869721036933991
Epoch: 43 | Iteration number: [4160/4518] 92% | Training loss: 0.6869715535869965
Epoch: 43 | Iteration number: [4170/4518] 92% | Training loss: 0.6869724625306164
Epoch: 43 | Iteration number: [4180/4518] 92% | Training loss: 0.6869717205255226
Epoch: 43 | Iteration number: [4190/4518] 92% | Training loss: 0.6869718292305749
Epoch: 43 | Iteration number: [4200/4518] 92% | Training loss: 0.68696794180643
Epoch: 43 | Iteration number: [4210/4518] 93% | Training loss: 0.6869688565968901
Epoch: 43 | Iteration number: [4220/4518] 93% | Training loss: 0.6869675674850907
Epoch: 43 | Iteration number: [4230/4518] 93% | Training loss: 0.6869693271375436
Epoch: 43 | Iteration number: [4240/4518] 93% | Training loss: 0.6869708916769838
Epoch: 43 | Iteration number: [4250/4518] 94% | Training loss: 0.6869734165668487
Epoch: 43 | Iteration number: [4260/4518] 94% | Training loss: 0.6869705123380876
Epoch: 43 | Iteration number: [4270/4518] 94% | Training loss: 0.6869685397913082
Epoch: 43 | Iteration number: [4280/4518] 94% | Training loss: 0.6869676895369993
Epoch: 43 | Iteration number: [4290/4518] 94% | Training loss: 0.686966856806984
Epoch: 43 | Iteration number: [4300/4518] 95% | Training loss: 0.6869657018295554
Epoch: 43 | Iteration number: [4310/4518] 95% | Training loss: 0.6869663049201125
Epoch: 43 | Iteration number: [4320/4518] 95% | Training loss: 0.6869660915461955
Epoch: 43 | Iteration number: [4330/4518] 95% | Training loss: 0.6869694212292413
Epoch: 43 | Iteration number: [4340/4518] 96% | Training loss: 0.6869669493442306
Epoch: 43 | Iteration number: [4350/4518] 96% | Training loss: 0.686963887803856
Epoch: 43 | Iteration number: [4360/4518] 96% | Training loss: 0.6869641352274002
Epoch: 43 | Iteration number: [4370/4518] 96% | Training loss: 0.6869663748642946
Epoch: 43 | Iteration number: [4380/4518] 96% | Training loss: 0.6869688405429936
Epoch: 43 | Iteration number: [4390/4518] 97% | Training loss: 0.6869695301479523
Epoch: 43 | Iteration number: [4400/4518] 97% | Training loss: 0.6869713650779291
Epoch: 43 | Iteration number: [4410/4518] 97% | Training loss: 0.6869719672500412
Epoch: 43 | Iteration number: [4420/4518] 97% | Training loss: 0.6869745334483919
Epoch: 43 | Iteration number: [4430/4518] 98% | Training loss: 0.6869711643147953
Epoch: 43 | Iteration number: [4440/4518] 98% | Training loss: 0.6869712417592874
Epoch: 43 | Iteration number: [4450/4518] 98% | Training loss: 0.6869717210598206
Epoch: 43 | Iteration number: [4460/4518] 98% | Training loss: 0.6869719657529095
Epoch: 43 | Iteration number: [4470/4518] 98% | Training loss: 0.6869706222274959
Epoch: 43 | Iteration number: [4480/4518] 99% | Training loss: 0.6869723134008902
Epoch: 43 | Iteration number: [4490/4518] 99% | Training loss: 0.6869738204574798
Epoch: 43 | Iteration number: [4500/4518] 99% | Training loss: 0.6869722740782632
Epoch: 43 | Iteration number: [4510/4518] 99% | Training loss: 0.6869701263645536

 End of epoch: 43 | Train Loss: 0.6868156639017221 | Training Time: 632 

 End of epoch: 43 | Eval Loss: 0.6898116919459129 | Evaluating Time: 17 
Epoch: 44 | Iteration number: [10/4518] 0% | Training loss: 0.7553196430206299
Epoch: 44 | Iteration number: [20/4518] 0% | Training loss: 0.7212758421897888
Epoch: 44 | Iteration number: [30/4518] 0% | Training loss: 0.7098645051320394
Epoch: 44 | Iteration number: [40/4518] 0% | Training loss: 0.7042194366455078
Epoch: 44 | Iteration number: [50/4518] 1% | Training loss: 0.7008642554283142
Epoch: 44 | Iteration number: [60/4518] 1% | Training loss: 0.6987516075372696
Epoch: 44 | Iteration number: [70/4518] 1% | Training loss: 0.6970470402921949
Epoch: 44 | Iteration number: [80/4518] 1% | Training loss: 0.6957310326397419
Epoch: 44 | Iteration number: [90/4518] 1% | Training loss: 0.6947921898629931
Epoch: 44 | Iteration number: [100/4518] 2% | Training loss: 0.694088158607483
Epoch: 44 | Iteration number: [110/4518] 2% | Training loss: 0.6935449080033735
Epoch: 44 | Iteration number: [120/4518] 2% | Training loss: 0.6929700468977292
Epoch: 44 | Iteration number: [130/4518] 2% | Training loss: 0.6924518800698793
Epoch: 44 | Iteration number: [140/4518] 3% | Training loss: 0.6921104209763663
Epoch: 44 | Iteration number: [150/4518] 3% | Training loss: 0.6917665835221608
Epoch: 44 | Iteration number: [160/4518] 3% | Training loss: 0.6914110515266657
Epoch: 44 | Iteration number: [170/4518] 3% | Training loss: 0.6911047399044037
Epoch: 44 | Iteration number: [180/4518] 3% | Training loss: 0.6908478485213385
Epoch: 44 | Iteration number: [190/4518] 4% | Training loss: 0.6906241627115952
Epoch: 44 | Iteration number: [200/4518] 4% | Training loss: 0.6903627467155456
Epoch: 44 | Iteration number: [210/4518] 4% | Training loss: 0.6902247417540778
Epoch: 44 | Iteration number: [220/4518] 4% | Training loss: 0.690112518993291
Epoch: 44 | Iteration number: [230/4518] 5% | Training loss: 0.6899408288623976
Epoch: 44 | Iteration number: [240/4518] 5% | Training loss: 0.6897776529192925
Epoch: 44 | Iteration number: [250/4518] 5% | Training loss: 0.6896284184455872
Epoch: 44 | Iteration number: [260/4518] 5% | Training loss: 0.6895405824367816
Epoch: 44 | Iteration number: [270/4518] 5% | Training loss: 0.689457521394447
Epoch: 44 | Iteration number: [280/4518] 6% | Training loss: 0.6893517673015594
Epoch: 44 | Iteration number: [290/4518] 6% | Training loss: 0.6892950201856679
Epoch: 44 | Iteration number: [300/4518] 6% | Training loss: 0.6891575558980306
Epoch: 44 | Iteration number: [310/4518] 6% | Training loss: 0.6890967513284375
Epoch: 44 | Iteration number: [320/4518] 7% | Training loss: 0.689037304930389
Epoch: 44 | Iteration number: [330/4518] 7% | Training loss: 0.68895114588015
Epoch: 44 | Iteration number: [340/4518] 7% | Training loss: 0.6889099676819409
Epoch: 44 | Iteration number: [350/4518] 7% | Training loss: 0.6888276851177215
Epoch: 44 | Iteration number: [360/4518] 7% | Training loss: 0.6887945357296202
Epoch: 44 | Iteration number: [370/4518] 8% | Training loss: 0.688758069115716
Epoch: 44 | Iteration number: [380/4518] 8% | Training loss: 0.6886945591161125
Epoch: 44 | Iteration number: [390/4518] 8% | Training loss: 0.6886396314853277
Epoch: 44 | Iteration number: [400/4518] 8% | Training loss: 0.6886343155801297
Epoch: 44 | Iteration number: [410/4518] 9% | Training loss: 0.688584107015191
Epoch: 44 | Iteration number: [420/4518] 9% | Training loss: 0.6885044808898654
Epoch: 44 | Iteration number: [430/4518] 9% | Training loss: 0.6884689806505692
Epoch: 44 | Iteration number: [440/4518] 9% | Training loss: 0.6884395037185062
Epoch: 44 | Iteration number: [450/4518] 9% | Training loss: 0.6883866175015767
Epoch: 44 | Iteration number: [460/4518] 10% | Training loss: 0.6883593758811122
Epoch: 44 | Iteration number: [470/4518] 10% | Training loss: 0.6883369038713739
Epoch: 44 | Iteration number: [480/4518] 10% | Training loss: 0.6883313671996196
Epoch: 44 | Iteration number: [490/4518] 10% | Training loss: 0.6883120676692651
Epoch: 44 | Iteration number: [500/4518] 11% | Training loss: 0.6882774232625961
Epoch: 44 | Iteration number: [510/4518] 11% | Training loss: 0.6882574263740988
Epoch: 44 | Iteration number: [520/4518] 11% | Training loss: 0.6882328898860858
Epoch: 44 | Iteration number: [530/4518] 11% | Training loss: 0.688206328985826
Epoch: 44 | Iteration number: [540/4518] 11% | Training loss: 0.6881731007938032
Epoch: 44 | Iteration number: [550/4518] 12% | Training loss: 0.6881358400258151
Epoch: 44 | Iteration number: [560/4518] 12% | Training loss: 0.6881346028830324
Epoch: 44 | Iteration number: [570/4518] 12% | Training loss: 0.6881225413397739
Epoch: 44 | Iteration number: [580/4518] 12% | Training loss: 0.6880914618229044
Epoch: 44 | Iteration number: [590/4518] 13% | Training loss: 0.6880485181081093
Epoch: 44 | Iteration number: [600/4518] 13% | Training loss: 0.6880475105841954
Epoch: 44 | Iteration number: [610/4518] 13% | Training loss: 0.6880275626651576
Epoch: 44 | Iteration number: [620/4518] 13% | Training loss: 0.6880107357617348
Epoch: 44 | Iteration number: [630/4518] 13% | Training loss: 0.6879795141636379
Epoch: 44 | Iteration number: [640/4518] 14% | Training loss: 0.6879655103199184
Epoch: 44 | Iteration number: [650/4518] 14% | Training loss: 0.6879347708592048
Epoch: 44 | Iteration number: [660/4518] 14% | Training loss: 0.6879324330524965
Epoch: 44 | Iteration number: [670/4518] 14% | Training loss: 0.6879271116719317
Epoch: 44 | Iteration number: [680/4518] 15% | Training loss: 0.6879156077609343
Epoch: 44 | Iteration number: [690/4518] 15% | Training loss: 0.6878917466903078
Epoch: 44 | Iteration number: [700/4518] 15% | Training loss: 0.6878852621998106
Epoch: 44 | Iteration number: [710/4518] 15% | Training loss: 0.687863175466027
Epoch: 44 | Iteration number: [720/4518] 15% | Training loss: 0.6878490770856539
Epoch: 44 | Iteration number: [730/4518] 16% | Training loss: 0.6878354122377421
Epoch: 44 | Iteration number: [740/4518] 16% | Training loss: 0.6878274522117667
Epoch: 44 | Iteration number: [750/4518] 16% | Training loss: 0.6877995931307475
Epoch: 44 | Iteration number: [760/4518] 16% | Training loss: 0.6877725401991293
Epoch: 44 | Iteration number: [770/4518] 17% | Training loss: 0.6877563511396383
Epoch: 44 | Iteration number: [780/4518] 17% | Training loss: 0.6877531067683147
Epoch: 44 | Iteration number: [790/4518] 17% | Training loss: 0.6877318396598477
Epoch: 44 | Iteration number: [800/4518] 17% | Training loss: 0.6877272089570761
Epoch: 44 | Iteration number: [810/4518] 17% | Training loss: 0.6877102869528311
Epoch: 44 | Iteration number: [820/4518] 18% | Training loss: 0.6877086977406246
Epoch: 44 | Iteration number: [830/4518] 18% | Training loss: 0.6877007470073471
Epoch: 44 | Iteration number: [840/4518] 18% | Training loss: 0.6876859616665613
Epoch: 44 | Iteration number: [850/4518] 18% | Training loss: 0.6876761953970966
Epoch: 44 | Iteration number: [860/4518] 19% | Training loss: 0.6876619595427845
Epoch: 44 | Iteration number: [870/4518] 19% | Training loss: 0.6876443085999324
Epoch: 44 | Iteration number: [880/4518] 19% | Training loss: 0.6876391399990428
Epoch: 44 | Iteration number: [890/4518] 19% | Training loss: 0.687624600898014
Epoch: 44 | Iteration number: [900/4518] 19% | Training loss: 0.687609526846144
Epoch: 44 | Iteration number: [910/4518] 20% | Training loss: 0.6876092230225658
Epoch: 44 | Iteration number: [920/4518] 20% | Training loss: 0.6876089872225472
Epoch: 44 | Iteration number: [930/4518] 20% | Training loss: 0.6876042043009112
Epoch: 44 | Iteration number: [940/4518] 20% | Training loss: 0.6875956016652127
Epoch: 44 | Iteration number: [950/4518] 21% | Training loss: 0.6876035576745083
Epoch: 44 | Iteration number: [960/4518] 21% | Training loss: 0.6876066255072752
Epoch: 44 | Iteration number: [970/4518] 21% | Training loss: 0.6875913250077631
Epoch: 44 | Iteration number: [980/4518] 21% | Training loss: 0.6875700093653737
Epoch: 44 | Iteration number: [990/4518] 21% | Training loss: 0.6875605154519129
Epoch: 44 | Iteration number: [1000/4518] 22% | Training loss: 0.6875698058605194
Epoch: 44 | Iteration number: [1010/4518] 22% | Training loss: 0.6875582471932515
Epoch: 44 | Iteration number: [1020/4518] 22% | Training loss: 0.6875596108974195
Epoch: 44 | Iteration number: [1030/4518] 22% | Training loss: 0.687543643157459
Epoch: 44 | Iteration number: [1040/4518] 23% | Training loss: 0.687542106383122
Epoch: 44 | Iteration number: [1050/4518] 23% | Training loss: 0.6875265681743622
Epoch: 44 | Iteration number: [1060/4518] 23% | Training loss: 0.687518791039035
Epoch: 44 | Iteration number: [1070/4518] 23% | Training loss: 0.6875142363744361
Epoch: 44 | Iteration number: [1080/4518] 23% | Training loss: 0.6875146200259526
Epoch: 44 | Iteration number: [1090/4518] 24% | Training loss: 0.6875069249113765
Epoch: 44 | Iteration number: [1100/4518] 24% | Training loss: 0.6875069862604142
Epoch: 44 | Iteration number: [1110/4518] 24% | Training loss: 0.6875082694732391
Epoch: 44 | Iteration number: [1120/4518] 24% | Training loss: 0.6875079524836369
Epoch: 44 | Iteration number: [1130/4518] 25% | Training loss: 0.6874986428075132
Epoch: 44 | Iteration number: [1140/4518] 25% | Training loss: 0.6874997058458495
Epoch: 44 | Iteration number: [1150/4518] 25% | Training loss: 0.6874898988267649
Epoch: 44 | Iteration number: [1160/4518] 25% | Training loss: 0.6874881741815599
Epoch: 44 | Iteration number: [1170/4518] 25% | Training loss: 0.6874849388232598
Epoch: 44 | Iteration number: [1180/4518] 26% | Training loss: 0.6874812752513563
Epoch: 44 | Iteration number: [1190/4518] 26% | Training loss: 0.6874776137977087
Epoch: 44 | Iteration number: [1200/4518] 26% | Training loss: 0.687476260860761
Epoch: 44 | Iteration number: [1210/4518] 26% | Training loss: 0.6874643776042402
Epoch: 44 | Iteration number: [1220/4518] 27% | Training loss: 0.6874524219114272
Epoch: 44 | Iteration number: [1230/4518] 27% | Training loss: 0.687451043458489
Epoch: 44 | Iteration number: [1240/4518] 27% | Training loss: 0.6874526663653312
Epoch: 44 | Iteration number: [1250/4518] 27% | Training loss: 0.6874398716926575
Epoch: 44 | Iteration number: [1260/4518] 27% | Training loss: 0.6874314059340765
Epoch: 44 | Iteration number: [1270/4518] 28% | Training loss: 0.6874371840728549
Epoch: 44 | Iteration number: [1280/4518] 28% | Training loss: 0.6874279054813087
Epoch: 44 | Iteration number: [1290/4518] 28% | Training loss: 0.6874213582323503
Epoch: 44 | Iteration number: [1300/4518] 28% | Training loss: 0.6874114230504402
Epoch: 44 | Iteration number: [1310/4518] 28% | Training loss: 0.6874042867249205
Epoch: 44 | Iteration number: [1320/4518] 29% | Training loss: 0.6873955900470415
Epoch: 44 | Iteration number: [1330/4518] 29% | Training loss: 0.6873931362664789
Epoch: 44 | Iteration number: [1340/4518] 29% | Training loss: 0.6873788395479544
Epoch: 44 | Iteration number: [1350/4518] 29% | Training loss: 0.6873724906091336
Epoch: 44 | Iteration number: [1360/4518] 30% | Training loss: 0.6873602034414515
Epoch: 44 | Iteration number: [1370/4518] 30% | Training loss: 0.687345336910582
Epoch: 44 | Iteration number: [1380/4518] 30% | Training loss: 0.6873422996289488
Epoch: 44 | Iteration number: [1390/4518] 30% | Training loss: 0.6873350490340226
Epoch: 44 | Iteration number: [1400/4518] 30% | Training loss: 0.687332763160978
Epoch: 44 | Iteration number: [1410/4518] 31% | Training loss: 0.687330436917907
Epoch: 44 | Iteration number: [1420/4518] 31% | Training loss: 0.687326941313878
Epoch: 44 | Iteration number: [1430/4518] 31% | Training loss: 0.6873178820926826
Epoch: 44 | Iteration number: [1440/4518] 31% | Training loss: 0.6873130817794137
Epoch: 44 | Iteration number: [1450/4518] 32% | Training loss: 0.6873114774144929
Epoch: 44 | Iteration number: [1460/4518] 32% | Training loss: 0.6873111677496401
Epoch: 44 | Iteration number: [1470/4518] 32% | Training loss: 0.6873094187707317
Epoch: 44 | Iteration number: [1480/4518] 32% | Training loss: 0.6873116409053673
Epoch: 44 | Iteration number: [1490/4518] 32% | Training loss: 0.68730366166006
Epoch: 44 | Iteration number: [1500/4518] 33% | Training loss: 0.6872973551750183
Epoch: 44 | Iteration number: [1510/4518] 33% | Training loss: 0.6873004453071695
Epoch: 44 | Iteration number: [1520/4518] 33% | Training loss: 0.6872902853708518
Epoch: 44 | Iteration number: [1530/4518] 33% | Training loss: 0.6872862026192783
Epoch: 44 | Iteration number: [1540/4518] 34% | Training loss: 0.6872825957350917
Epoch: 44 | Iteration number: [1550/4518] 34% | Training loss: 0.6872817124089887
Epoch: 44 | Iteration number: [1560/4518] 34% | Training loss: 0.6872780627547166
Epoch: 44 | Iteration number: [1570/4518] 34% | Training loss: 0.6872755404110926
Epoch: 44 | Iteration number: [1580/4518] 34% | Training loss: 0.6872678865737553
Epoch: 44 | Iteration number: [1590/4518] 35% | Training loss: 0.6872613610336615
Epoch: 44 | Iteration number: [1600/4518] 35% | Training loss: 0.6872557325661183
Epoch: 44 | Iteration number: [1610/4518] 35% | Training loss: 0.6872509398815795
Epoch: 44 | Iteration number: [1620/4518] 35% | Training loss: 0.6872569963152027
Epoch: 44 | Iteration number: [1630/4518] 36% | Training loss: 0.6872536866942798
Epoch: 44 | Iteration number: [1640/4518] 36% | Training loss: 0.6872508742823833
Epoch: 44 | Iteration number: [1650/4518] 36% | Training loss: 0.6872419964905941
Epoch: 44 | Iteration number: [1660/4518] 36% | Training loss: 0.6872486952557622
Epoch: 44 | Iteration number: [1670/4518] 36% | Training loss: 0.6872457360079188
Epoch: 44 | Iteration number: [1680/4518] 37% | Training loss: 0.6872524053567932
Epoch: 44 | Iteration number: [1690/4518] 37% | Training loss: 0.6872624730922766
Epoch: 44 | Iteration number: [1700/4518] 37% | Training loss: 0.6872533061925102
Epoch: 44 | Iteration number: [1710/4518] 37% | Training loss: 0.6872548227421722
Epoch: 44 | Iteration number: [1720/4518] 38% | Training loss: 0.6872448776003927
Epoch: 44 | Iteration number: [1730/4518] 38% | Training loss: 0.6872445760779298
Epoch: 44 | Iteration number: [1740/4518] 38% | Training loss: 0.6872419284678054
Epoch: 44 | Iteration number: [1750/4518] 38% | Training loss: 0.687238872391837
Epoch: 44 | Iteration number: [1760/4518] 38% | Training loss: 0.6872440283271399
Epoch: 44 | Iteration number: [1770/4518] 39% | Training loss: 0.6872382024250462
Epoch: 44 | Iteration number: [1780/4518] 39% | Training loss: 0.6872367489873693
Epoch: 44 | Iteration number: [1790/4518] 39% | Training loss: 0.6872354718559948
Epoch: 44 | Iteration number: [1800/4518] 39% | Training loss: 0.687233889732096
Epoch: 44 | Iteration number: [1810/4518] 40% | Training loss: 0.6872368883032826
Epoch: 44 | Iteration number: [1820/4518] 40% | Training loss: 0.687233527479591
Epoch: 44 | Iteration number: [1830/4518] 40% | Training loss: 0.6872306000339529
Epoch: 44 | Iteration number: [1840/4518] 40% | Training loss: 0.6872290721406107
Epoch: 44 | Iteration number: [1850/4518] 40% | Training loss: 0.687230283827395
Epoch: 44 | Iteration number: [1860/4518] 41% | Training loss: 0.6872291588655082
Epoch: 44 | Iteration number: [1870/4518] 41% | Training loss: 0.6872293312281849
Epoch: 44 | Iteration number: [1880/4518] 41% | Training loss: 0.6872311622855511
Epoch: 44 | Iteration number: [1890/4518] 41% | Training loss: 0.6872269302448898
Epoch: 44 | Iteration number: [1900/4518] 42% | Training loss: 0.6872286302792399
Epoch: 44 | Iteration number: [1910/4518] 42% | Training loss: 0.6872257544108086
Epoch: 44 | Iteration number: [1920/4518] 42% | Training loss: 0.6872164982681473
Epoch: 44 | Iteration number: [1930/4518] 42% | Training loss: 0.6872159915266877
Epoch: 44 | Iteration number: [1940/4518] 42% | Training loss: 0.6872231883793762
Epoch: 44 | Iteration number: [1950/4518] 43% | Training loss: 0.6872195663818946
Epoch: 44 | Iteration number: [1960/4518] 43% | Training loss: 0.6872193499183168
Epoch: 44 | Iteration number: [1970/4518] 43% | Training loss: 0.6872222662577169
Epoch: 44 | Iteration number: [1980/4518] 43% | Training loss: 0.6872273515872281
Epoch: 44 | Iteration number: [1990/4518] 44% | Training loss: 0.6872275802957353
Epoch: 44 | Iteration number: [2000/4518] 44% | Training loss: 0.687229042738676
Epoch: 44 | Iteration number: [2010/4518] 44% | Training loss: 0.6872248274473408
Epoch: 44 | Iteration number: [2020/4518] 44% | Training loss: 0.6872293375801332
Epoch: 44 | Iteration number: [2030/4518] 44% | Training loss: 0.6872300364701032
Epoch: 44 | Iteration number: [2040/4518] 45% | Training loss: 0.6872310710011744
Epoch: 44 | Iteration number: [2050/4518] 45% | Training loss: 0.687233358330843
Epoch: 44 | Iteration number: [2060/4518] 45% | Training loss: 0.6872319093317661
Epoch: 44 | Iteration number: [2070/4518] 45% | Training loss: 0.6872282208451902
Epoch: 44 | Iteration number: [2080/4518] 46% | Training loss: 0.6872316374801672
Epoch: 44 | Iteration number: [2090/4518] 46% | Training loss: 0.6872236234149294
Epoch: 44 | Iteration number: [2100/4518] 46% | Training loss: 0.6872265356495267
Epoch: 44 | Iteration number: [2110/4518] 46% | Training loss: 0.6872231560013305
Epoch: 44 | Iteration number: [2120/4518] 46% | Training loss: 0.687221862713121
Epoch: 44 | Iteration number: [2130/4518] 47% | Training loss: 0.6872164060252374
Epoch: 44 | Iteration number: [2140/4518] 47% | Training loss: 0.6872160045064498
Epoch: 44 | Iteration number: [2150/4518] 47% | Training loss: 0.6872154544397842
Epoch: 44 | Iteration number: [2160/4518] 47% | Training loss: 0.6872140416116627
Epoch: 44 | Iteration number: [2170/4518] 48% | Training loss: 0.6872059470772194
Epoch: 44 | Iteration number: [2180/4518] 48% | Training loss: 0.6871958636089203
Epoch: 44 | Iteration number: [2190/4518] 48% | Training loss: 0.6871912453000404
Epoch: 44 | Iteration number: [2200/4518] 48% | Training loss: 0.6871887640519576
Epoch: 44 | Iteration number: [2210/4518] 48% | Training loss: 0.6871911842089433
Epoch: 44 | Iteration number: [2220/4518] 49% | Training loss: 0.6871894389659435
Epoch: 44 | Iteration number: [2230/4518] 49% | Training loss: 0.687189977238531
Epoch: 44 | Iteration number: [2240/4518] 49% | Training loss: 0.6871896517862167
Epoch: 44 | Iteration number: [2250/4518] 49% | Training loss: 0.6871918210718366
Epoch: 44 | Iteration number: [2260/4518] 50% | Training loss: 0.6871923065818517
Epoch: 44 | Iteration number: [2270/4518] 50% | Training loss: 0.687195776921537
Epoch: 44 | Iteration number: [2280/4518] 50% | Training loss: 0.6871918320917246
Epoch: 44 | Iteration number: [2290/4518] 50% | Training loss: 0.6871930097908953
Epoch: 44 | Iteration number: [2300/4518] 50% | Training loss: 0.687188789041146
Epoch: 44 | Iteration number: [2310/4518] 51% | Training loss: 0.6871843893806656
Epoch: 44 | Iteration number: [2320/4518] 51% | Training loss: 0.687184582984653
Epoch: 44 | Iteration number: [2330/4518] 51% | Training loss: 0.6871815535899396
Epoch: 44 | Iteration number: [2340/4518] 51% | Training loss: 0.6871836542319029
Epoch: 44 | Iteration number: [2350/4518] 52% | Training loss: 0.6871840342054976
Epoch: 44 | Iteration number: [2360/4518] 52% | Training loss: 0.6871818521012694
Epoch: 44 | Iteration number: [2370/4518] 52% | Training loss: 0.6871804212970573
Epoch: 44 | Iteration number: [2380/4518] 52% | Training loss: 0.6871783004338
Epoch: 44 | Iteration number: [2390/4518] 52% | Training loss: 0.687173891765802
Epoch: 44 | Iteration number: [2400/4518] 53% | Training loss: 0.6871720270812511
Epoch: 44 | Iteration number: [2410/4518] 53% | Training loss: 0.6871683704407878
Epoch: 44 | Iteration number: [2420/4518] 53% | Training loss: 0.6871626292132149
Epoch: 44 | Iteration number: [2430/4518] 53% | Training loss: 0.6871574653274238
Epoch: 44 | Iteration number: [2440/4518] 54% | Training loss: 0.6871583249725279
Epoch: 44 | Iteration number: [2450/4518] 54% | Training loss: 0.687155415135987
Epoch: 44 | Iteration number: [2460/4518] 54% | Training loss: 0.687156241865662
Epoch: 44 | Iteration number: [2470/4518] 54% | Training loss: 0.6871507075392765
Epoch: 44 | Iteration number: [2480/4518] 54% | Training loss: 0.6871514290330871
Epoch: 44 | Iteration number: [2490/4518] 55% | Training loss: 0.6871531925526968
Epoch: 44 | Iteration number: [2500/4518] 55% | Training loss: 0.6871528399705887
Epoch: 44 | Iteration number: [2510/4518] 55% | Training loss: 0.6871551511059719
Epoch: 44 | Iteration number: [2520/4518] 55% | Training loss: 0.6871518167474914
Epoch: 44 | Iteration number: [2530/4518] 55% | Training loss: 0.6871517811839288
Epoch: 44 | Iteration number: [2540/4518] 56% | Training loss: 0.6871482439397827
Epoch: 44 | Iteration number: [2550/4518] 56% | Training loss: 0.6871426691027248
Epoch: 44 | Iteration number: [2560/4518] 56% | Training loss: 0.687141998601146
Epoch: 44 | Iteration number: [2570/4518] 56% | Training loss: 0.6871426933470404
Epoch: 44 | Iteration number: [2580/4518] 57% | Training loss: 0.6871420606393223
Epoch: 44 | Iteration number: [2590/4518] 57% | Training loss: 0.6871452818506013
Epoch: 44 | Iteration number: [2600/4518] 57% | Training loss: 0.6871399409725116
Epoch: 44 | Iteration number: [2610/4518] 57% | Training loss: 0.6871387584912823
Epoch: 44 | Iteration number: [2620/4518] 57% | Training loss: 0.6871387782215163
Epoch: 44 | Iteration number: [2630/4518] 58% | Training loss: 0.6871382135402114
Epoch: 44 | Iteration number: [2640/4518] 58% | Training loss: 0.687135503079855
Epoch: 44 | Iteration number: [2650/4518] 58% | Training loss: 0.6871248415506112
Epoch: 44 | Iteration number: [2660/4518] 58% | Training loss: 0.6871226725049485
Epoch: 44 | Iteration number: [2670/4518] 59% | Training loss: 0.687125086762039
Epoch: 44 | Iteration number: [2680/4518] 59% | Training loss: 0.6871238569492725
Epoch: 44 | Iteration number: [2690/4518] 59% | Training loss: 0.687118516380459
Epoch: 44 | Iteration number: [2700/4518] 59% | Training loss: 0.687120252582762
Epoch: 44 | Iteration number: [2710/4518] 59% | Training loss: 0.6871200388208086
Epoch: 44 | Iteration number: [2720/4518] 60% | Training loss: 0.6871154956519604
Epoch: 44 | Iteration number: [2730/4518] 60% | Training loss: 0.6871167794907049
Epoch: 44 | Iteration number: [2740/4518] 60% | Training loss: 0.6871197961107658
Epoch: 44 | Iteration number: [2750/4518] 60% | Training loss: 0.6871205761866136
Epoch: 44 | Iteration number: [2760/4518] 61% | Training loss: 0.687112301674442
Epoch: 44 | Iteration number: [2770/4518] 61% | Training loss: 0.6871106211459164
Epoch: 44 | Iteration number: [2780/4518] 61% | Training loss: 0.6871096308068406
Epoch: 44 | Iteration number: [2790/4518] 61% | Training loss: 0.6871122950721386
Epoch: 44 | Iteration number: [2800/4518] 61% | Training loss: 0.6871144837992532
Epoch: 44 | Iteration number: [2810/4518] 62% | Training loss: 0.6871181532369389
Epoch: 44 | Iteration number: [2820/4518] 62% | Training loss: 0.6871203332928055
Epoch: 44 | Iteration number: [2830/4518] 62% | Training loss: 0.687112913072741
Epoch: 44 | Iteration number: [2840/4518] 62% | Training loss: 0.6871158516532938
Epoch: 44 | Iteration number: [2850/4518] 63% | Training loss: 0.6871197023308068
Epoch: 44 | Iteration number: [2860/4518] 63% | Training loss: 0.687116246206777
Epoch: 44 | Iteration number: [2870/4518] 63% | Training loss: 0.6871134795585991
Epoch: 44 | Iteration number: [2880/4518] 63% | Training loss: 0.68711676231275
Epoch: 44 | Iteration number: [2890/4518] 63% | Training loss: 0.6871119244082163
Epoch: 44 | Iteration number: [2900/4518] 64% | Training loss: 0.6871102958301017
Epoch: 44 | Iteration number: [2910/4518] 64% | Training loss: 0.6871110382358643
Epoch: 44 | Iteration number: [2920/4518] 64% | Training loss: 0.6871095476697568
Epoch: 44 | Iteration number: [2930/4518] 64% | Training loss: 0.6871107752819517
Epoch: 44 | Iteration number: [2940/4518] 65% | Training loss: 0.6871096574935783
Epoch: 44 | Iteration number: [2950/4518] 65% | Training loss: 0.6871081518318694
Epoch: 44 | Iteration number: [2960/4518] 65% | Training loss: 0.687105684002509
Epoch: 44 | Iteration number: [2970/4518] 65% | Training loss: 0.6871057075081449
Epoch: 44 | Iteration number: [2980/4518] 65% | Training loss: 0.6870997142471723
Epoch: 44 | Iteration number: [2990/4518] 66% | Training loss: 0.6870957717050278
Epoch: 44 | Iteration number: [3000/4518] 66% | Training loss: 0.6870974492033323
Epoch: 44 | Iteration number: [3010/4518] 66% | Training loss: 0.6870956941300452
Epoch: 44 | Iteration number: [3020/4518] 66% | Training loss: 0.6870947419412878
Epoch: 44 | Iteration number: [3030/4518] 67% | Training loss: 0.6870946030215461
Epoch: 44 | Iteration number: [3040/4518] 67% | Training loss: 0.6870924817496225
Epoch: 44 | Iteration number: [3050/4518] 67% | Training loss: 0.6870904391906301
Epoch: 44 | Iteration number: [3060/4518] 67% | Training loss: 0.6870944051960715
Epoch: 44 | Iteration number: [3070/4518] 67% | Training loss: 0.6870951003476928
Epoch: 44 | Iteration number: [3080/4518] 68% | Training loss: 0.6870973012083537
Epoch: 44 | Iteration number: [3090/4518] 68% | Training loss: 0.6870983413893814
Epoch: 44 | Iteration number: [3100/4518] 68% | Training loss: 0.6870990475916093
Epoch: 44 | Iteration number: [3110/4518] 68% | Training loss: 0.6870960836625176
Epoch: 44 | Iteration number: [3120/4518] 69% | Training loss: 0.6870904478507164
Epoch: 44 | Iteration number: [3130/4518] 69% | Training loss: 0.687088596459014
Epoch: 44 | Iteration number: [3140/4518] 69% | Training loss: 0.6870840267011314
Epoch: 44 | Iteration number: [3150/4518] 69% | Training loss: 0.6870820516631717
Epoch: 44 | Iteration number: [3160/4518] 69% | Training loss: 0.6870814572783965
Epoch: 44 | Iteration number: [3170/4518] 70% | Training loss: 0.6870821938529752
Epoch: 44 | Iteration number: [3180/4518] 70% | Training loss: 0.6870803367791686
Epoch: 44 | Iteration number: [3190/4518] 70% | Training loss: 0.6870781324873897
Epoch: 44 | Iteration number: [3200/4518] 70% | Training loss: 0.6870716666989028
Epoch: 44 | Iteration number: [3210/4518] 71% | Training loss: 0.687066044595754
Epoch: 44 | Iteration number: [3220/4518] 71% | Training loss: 0.6870652575670562
Epoch: 44 | Iteration number: [3230/4518] 71% | Training loss: 0.6870646697079803
Epoch: 44 | Iteration number: [3240/4518] 71% | Training loss: 0.6870648353372091
Epoch: 44 | Iteration number: [3250/4518] 71% | Training loss: 0.6870634157474225
Epoch: 44 | Iteration number: [3260/4518] 72% | Training loss: 0.6870669259066962
Epoch: 44 | Iteration number: [3270/4518] 72% | Training loss: 0.6870726483859783
Epoch: 44 | Iteration number: [3280/4518] 72% | Training loss: 0.6870726816719626
Epoch: 44 | Iteration number: [3290/4518] 72% | Training loss: 0.6870733983429732
Epoch: 44 | Iteration number: [3300/4518] 73% | Training loss: 0.6870742906765505
Epoch: 44 | Iteration number: [3310/4518] 73% | Training loss: 0.6870764565251745
Epoch: 44 | Iteration number: [3320/4518] 73% | Training loss: 0.6870742561228304
Epoch: 44 | Iteration number: [3330/4518] 73% | Training loss: 0.68707328257976
Epoch: 44 | Iteration number: [3340/4518] 73% | Training loss: 0.6870727454830786
Epoch: 44 | Iteration number: [3350/4518] 74% | Training loss: 0.6870713821809683
Epoch: 44 | Iteration number: [3360/4518] 74% | Training loss: 0.6870722187594289
Epoch: 44 | Iteration number: [3370/4518] 74% | Training loss: 0.6870737547690507
Epoch: 44 | Iteration number: [3380/4518] 74% | Training loss: 0.687075142200882
Epoch: 44 | Iteration number: [3390/4518] 75% | Training loss: 0.6870746526394622
Epoch: 44 | Iteration number: [3400/4518] 75% | Training loss: 0.6870709837710156
Epoch: 44 | Iteration number: [3410/4518] 75% | Training loss: 0.6870745265588732
Epoch: 44 | Iteration number: [3420/4518] 75% | Training loss: 0.6870734131475639
Epoch: 44 | Iteration number: [3430/4518] 75% | Training loss: 0.6870689889258615
Epoch: 44 | Iteration number: [3440/4518] 76% | Training loss: 0.6870709863686284
Epoch: 44 | Iteration number: [3450/4518] 76% | Training loss: 0.6870691713388415
Epoch: 44 | Iteration number: [3460/4518] 76% | Training loss: 0.6870691796430962
Epoch: 44 | Iteration number: [3470/4518] 76% | Training loss: 0.6870709296777544
Epoch: 44 | Iteration number: [3480/4518] 77% | Training loss: 0.6870701858880877
Epoch: 44 | Iteration number: [3490/4518] 77% | Training loss: 0.6870674287179821
Epoch: 44 | Iteration number: [3500/4518] 77% | Training loss: 0.6870686057465417
Epoch: 44 | Iteration number: [3510/4518] 77% | Training loss: 0.6870644081861544
Epoch: 44 | Iteration number: [3520/4518] 77% | Training loss: 0.6870673923837868
Epoch: 44 | Iteration number: [3530/4518] 78% | Training loss: 0.6870642417382249
Epoch: 44 | Iteration number: [3540/4518] 78% | Training loss: 0.6870644536227156
Epoch: 44 | Iteration number: [3550/4518] 78% | Training loss: 0.6870628457673839
Epoch: 44 | Iteration number: [3560/4518] 78% | Training loss: 0.6870587260703023
Epoch: 44 | Iteration number: [3570/4518] 79% | Training loss: 0.6870548496059343
Epoch: 44 | Iteration number: [3580/4518] 79% | Training loss: 0.6870521657626723
Epoch: 44 | Iteration number: [3590/4518] 79% | Training loss: 0.6870477995666621
Epoch: 44 | Iteration number: [3600/4518] 79% | Training loss: 0.6870429440670544
Epoch: 44 | Iteration number: [3610/4518] 79% | Training loss: 0.6870411676217975
Epoch: 44 | Iteration number: [3620/4518] 80% | Training loss: 0.6870410699541397
Epoch: 44 | Iteration number: [3630/4518] 80% | Training loss: 0.6870381793699973
Epoch: 44 | Iteration number: [3640/4518] 80% | Training loss: 0.6870373201566738
Epoch: 44 | Iteration number: [3650/4518] 80% | Training loss: 0.6870304232590819
Epoch: 44 | Iteration number: [3660/4518] 81% | Training loss: 0.6870285303540569
Epoch: 44 | Iteration number: [3670/4518] 81% | Training loss: 0.6870239814718023
Epoch: 44 | Iteration number: [3680/4518] 81% | Training loss: 0.6870221771461809
Epoch: 44 | Iteration number: [3690/4518] 81% | Training loss: 0.6870223323181069
Epoch: 44 | Iteration number: [3700/4518] 81% | Training loss: 0.6870199629744967
Epoch: 44 | Iteration number: [3710/4518] 82% | Training loss: 0.6870179168618914
Epoch: 44 | Iteration number: [3720/4518] 82% | Training loss: 0.6870191710610544
Epoch: 44 | Iteration number: [3730/4518] 82% | Training loss: 0.6870161416223797
Epoch: 44 | Iteration number: [3740/4518] 82% | Training loss: 0.6870162829039569
Epoch: 44 | Iteration number: [3750/4518] 83% | Training loss: 0.6870140181859334
Epoch: 44 | Iteration number: [3760/4518] 83% | Training loss: 0.6870126065897181
Epoch: 44 | Iteration number: [3770/4518] 83% | Training loss: 0.6870075918477158
Epoch: 44 | Iteration number: [3780/4518] 83% | Training loss: 0.6870075584561737
Epoch: 44 | Iteration number: [3790/4518] 83% | Training loss: 0.6870084270166533
Epoch: 44 | Iteration number: [3800/4518] 84% | Training loss: 0.6870062802496709
Epoch: 44 | Iteration number: [3810/4518] 84% | Training loss: 0.6870071672548459
Epoch: 44 | Iteration number: [3820/4518] 84% | Training loss: 0.6870078756235033
Epoch: 44 | Iteration number: [3830/4518] 84% | Training loss: 0.6870070328756038
Epoch: 44 | Iteration number: [3840/4518] 84% | Training loss: 0.6870083084174742
Epoch: 44 | Iteration number: [3850/4518] 85% | Training loss: 0.6870094958528296
Epoch: 44 | Iteration number: [3860/4518] 85% | Training loss: 0.6870121468225291
Epoch: 44 | Iteration number: [3870/4518] 85% | Training loss: 0.6870122414688732
Epoch: 44 | Iteration number: [3880/4518] 85% | Training loss: 0.6870118407398155
Epoch: 44 | Iteration number: [3890/4518] 86% | Training loss: 0.6870123466060217
Epoch: 44 | Iteration number: [3900/4518] 86% | Training loss: 0.6870118436752222
Epoch: 44 | Iteration number: [3910/4518] 86% | Training loss: 0.6870150023409168
Epoch: 44 | Iteration number: [3920/4518] 86% | Training loss: 0.6870155791695021
Epoch: 44 | Iteration number: [3930/4518] 86% | Training loss: 0.687015230616237
Epoch: 44 | Iteration number: [3940/4518] 87% | Training loss: 0.6870135321381129
Epoch: 44 | Iteration number: [3950/4518] 87% | Training loss: 0.687013836842549
Epoch: 44 | Iteration number: [3960/4518] 87% | Training loss: 0.6870132767341354
Epoch: 44 | Iteration number: [3970/4518] 87% | Training loss: 0.6870132223785074
Epoch: 44 | Iteration number: [3980/4518] 88% | Training loss: 0.6870136213512277
Epoch: 44 | Iteration number: [3990/4518] 88% | Training loss: 0.6870122461988215
Epoch: 44 | Iteration number: [4000/4518] 88% | Training loss: 0.6870107016861439
Epoch: 44 | Iteration number: [4010/4518] 88% | Training loss: 0.6870144487021868
Epoch: 44 | Iteration number: [4020/4518] 88% | Training loss: 0.6870124028541555
Epoch: 44 | Iteration number: [4030/4518] 89% | Training loss: 0.6870123068984626
Epoch: 44 | Iteration number: [4040/4518] 89% | Training loss: 0.6870092819675361
Epoch: 44 | Iteration number: [4050/4518] 89% | Training loss: 0.6870087855244861
Epoch: 44 | Iteration number: [4060/4518] 89% | Training loss: 0.6870079176913342
Epoch: 44 | Iteration number: [4070/4518] 90% | Training loss: 0.6870048576842362
Epoch: 44 | Iteration number: [4080/4518] 90% | Training loss: 0.6870033170078315
Epoch: 44 | Iteration number: [4090/4518] 90% | Training loss: 0.6870023483897771
Epoch: 44 | Iteration number: [4100/4518] 90% | Training loss: 0.6869982570264398
Epoch: 44 | Iteration number: [4110/4518] 90% | Training loss: 0.6869996044467546
Epoch: 44 | Iteration number: [4120/4518] 91% | Training loss: 0.6869974784191373
Epoch: 44 | Iteration number: [4130/4518] 91% | Training loss: 0.6869961697454892
Epoch: 44 | Iteration number: [4140/4518] 91% | Training loss: 0.6869974376354816
Epoch: 44 | Iteration number: [4150/4518] 91% | Training loss: 0.6869923655527184
Epoch: 44 | Iteration number: [4160/4518] 92% | Training loss: 0.6869907280143637
Epoch: 44 | Iteration number: [4170/4518] 92% | Training loss: 0.6869908215330659
Epoch: 44 | Iteration number: [4180/4518] 92% | Training loss: 0.6869880628500259
Epoch: 44 | Iteration number: [4190/4518] 92% | Training loss: 0.6869899342765672
Epoch: 44 | Iteration number: [4200/4518] 92% | Training loss: 0.6869855251340639
Epoch: 44 | Iteration number: [4210/4518] 93% | Training loss: 0.686984236619818
Epoch: 44 | Iteration number: [4220/4518] 93% | Training loss: 0.6869839822229051
Epoch: 44 | Iteration number: [4230/4518] 93% | Training loss: 0.6869844635327657
Epoch: 44 | Iteration number: [4240/4518] 93% | Training loss: 0.686984768734788
Epoch: 44 | Iteration number: [4250/4518] 94% | Training loss: 0.6869857238460989
Epoch: 44 | Iteration number: [4260/4518] 94% | Training loss: 0.686984058095256
Epoch: 44 | Iteration number: [4270/4518] 94% | Training loss: 0.6869820993733908
Epoch: 44 | Iteration number: [4280/4518] 94% | Training loss: 0.6869812052522865
Epoch: 44 | Iteration number: [4290/4518] 94% | Training loss: 0.6869820073073283
Epoch: 44 | Iteration number: [4300/4518] 95% | Training loss: 0.6869808725007744
Epoch: 44 | Iteration number: [4310/4518] 95% | Training loss: 0.6869822336460211
Epoch: 44 | Iteration number: [4320/4518] 95% | Training loss: 0.6869797025703721
Epoch: 44 | Iteration number: [4330/4518] 95% | Training loss: 0.6869775983532912
Epoch: 44 | Iteration number: [4340/4518] 96% | Training loss: 0.6869754938348647
Epoch: 44 | Iteration number: [4350/4518] 96% | Training loss: 0.6869776862654192
Epoch: 44 | Iteration number: [4360/4518] 96% | Training loss: 0.6869773194467256
Epoch: 44 | Iteration number: [4370/4518] 96% | Training loss: 0.686974902433989
Epoch: 44 | Iteration number: [4380/4518] 96% | Training loss: 0.6869733272622165
Epoch: 44 | Iteration number: [4390/4518] 97% | Training loss: 0.6869726135953412
Epoch: 44 | Iteration number: [4400/4518] 97% | Training loss: 0.6869735910675743
Epoch: 44 | Iteration number: [4410/4518] 97% | Training loss: 0.6869712191374123
Epoch: 44 | Iteration number: [4420/4518] 97% | Training loss: 0.6869709504675542
Epoch: 44 | Iteration number: [4430/4518] 98% | Training loss: 0.6869699771194372
Epoch: 44 | Iteration number: [4440/4518] 98% | Training loss: 0.6869690716669367
Epoch: 44 | Iteration number: [4450/4518] 98% | Training loss: 0.6869637460655041
Epoch: 44 | Iteration number: [4460/4518] 98% | Training loss: 0.6869619645078086
Epoch: 44 | Iteration number: [4470/4518] 98% | Training loss: 0.6869634468416773
Epoch: 44 | Iteration number: [4480/4518] 99% | Training loss: 0.6869620379725737
Epoch: 44 | Iteration number: [4490/4518] 99% | Training loss: 0.6869630841077834
Epoch: 44 | Iteration number: [4500/4518] 99% | Training loss: 0.6869598881006241
Epoch: 44 | Iteration number: [4510/4518] 99% | Training loss: 0.6869602618222754

 End of epoch: 44 | Train Loss: 0.6868095969853015 | Training Time: 633 

 End of epoch: 44 | Eval Loss: 0.6897882393428257 | Evaluating Time: 17 
Epoch: 45 | Iteration number: [10/4518] 0% | Training loss: 0.7547481596469879
Epoch: 45 | Iteration number: [20/4518] 0% | Training loss: 0.7206878989934922
Epoch: 45 | Iteration number: [30/4518] 0% | Training loss: 0.7093547185262045
Epoch: 45 | Iteration number: [40/4518] 0% | Training loss: 0.7035685122013092
Epoch: 45 | Iteration number: [50/4518] 1% | Training loss: 0.7001345109939575
Epoch: 45 | Iteration number: [60/4518] 1% | Training loss: 0.6980125655730566
Epoch: 45 | Iteration number: [70/4518] 1% | Training loss: 0.6963636347225735
Epoch: 45 | Iteration number: [80/4518] 1% | Training loss: 0.6952726796269417
Epoch: 45 | Iteration number: [90/4518] 1% | Training loss: 0.6943429463439518
Epoch: 45 | Iteration number: [100/4518] 2% | Training loss: 0.6936146408319473
Epoch: 45 | Iteration number: [110/4518] 2% | Training loss: 0.6930276220495051
Epoch: 45 | Iteration number: [120/4518] 2% | Training loss: 0.6924073005716006
Epoch: 45 | Iteration number: [130/4518] 2% | Training loss: 0.6920448738795061
Epoch: 45 | Iteration number: [140/4518] 3% | Training loss: 0.6916969784668514
Epoch: 45 | Iteration number: [150/4518] 3% | Training loss: 0.6913439945379893
Epoch: 45 | Iteration number: [160/4518] 3% | Training loss: 0.6911681745201349
Epoch: 45 | Iteration number: [170/4518] 3% | Training loss: 0.6908678324783549
Epoch: 45 | Iteration number: [180/4518] 3% | Training loss: 0.6906707462337282
Epoch: 45 | Iteration number: [190/4518] 4% | Training loss: 0.6904758942754645
Epoch: 45 | Iteration number: [200/4518] 4% | Training loss: 0.6903333869576455
Epoch: 45 | Iteration number: [210/4518] 4% | Training loss: 0.6902005516347431
Epoch: 45 | Iteration number: [220/4518] 4% | Training loss: 0.6900530701333826
Epoch: 45 | Iteration number: [230/4518] 5% | Training loss: 0.6899470987527266
Epoch: 45 | Iteration number: [240/4518] 5% | Training loss: 0.6897793104251225
Epoch: 45 | Iteration number: [250/4518] 5% | Training loss: 0.6896503293514251
Epoch: 45 | Iteration number: [260/4518] 5% | Training loss: 0.6894864025024268
Epoch: 45 | Iteration number: [270/4518] 5% | Training loss: 0.6893961915263424
Epoch: 45 | Iteration number: [280/4518] 6% | Training loss: 0.6893032395413944
Epoch: 45 | Iteration number: [290/4518] 6% | Training loss: 0.6892354510981461
Epoch: 45 | Iteration number: [300/4518] 6% | Training loss: 0.6892181072632472
Epoch: 45 | Iteration number: [310/4518] 6% | Training loss: 0.6891219212162879
Epoch: 45 | Iteration number: [320/4518] 7% | Training loss: 0.6890884391963482
Epoch: 45 | Iteration number: [330/4518] 7% | Training loss: 0.6890546115961942
Epoch: 45 | Iteration number: [340/4518] 7% | Training loss: 0.6889745631638695
Epoch: 45 | Iteration number: [350/4518] 7% | Training loss: 0.6889223045962197
Epoch: 45 | Iteration number: [360/4518] 7% | Training loss: 0.6888683353861172
Epoch: 45 | Iteration number: [370/4518] 8% | Training loss: 0.6888427653828183
Epoch: 45 | Iteration number: [380/4518] 8% | Training loss: 0.6888137781306317
Epoch: 45 | Iteration number: [390/4518] 8% | Training loss: 0.6887540496312655
Epoch: 45 | Iteration number: [400/4518] 8% | Training loss: 0.6887466634809971
Epoch: 45 | Iteration number: [410/4518] 9% | Training loss: 0.6887082642171442
Epoch: 45 | Iteration number: [420/4518] 9% | Training loss: 0.6886698272966203
Epoch: 45 | Iteration number: [430/4518] 9% | Training loss: 0.688621057466019
Epoch: 45 | Iteration number: [440/4518] 9% | Training loss: 0.6885859417644414
Epoch: 45 | Iteration number: [450/4518] 9% | Training loss: 0.6885546004772186
Epoch: 45 | Iteration number: [460/4518] 10% | Training loss: 0.6885154290043789
Epoch: 45 | Iteration number: [470/4518] 10% | Training loss: 0.688474311853977
Epoch: 45 | Iteration number: [480/4518] 10% | Training loss: 0.6884530482192834
Epoch: 45 | Iteration number: [490/4518] 10% | Training loss: 0.6884329764210448
Epoch: 45 | Iteration number: [500/4518] 11% | Training loss: 0.6884131220579147
Epoch: 45 | Iteration number: [510/4518] 11% | Training loss: 0.6884058355116377
Epoch: 45 | Iteration number: [520/4518] 11% | Training loss: 0.6883799814260922
Epoch: 45 | Iteration number: [530/4518] 11% | Training loss: 0.688362557820554
Epoch: 45 | Iteration number: [540/4518] 11% | Training loss: 0.6883437863102666
Epoch: 45 | Iteration number: [550/4518] 12% | Training loss: 0.6883206386999651
Epoch: 45 | Iteration number: [560/4518] 12% | Training loss: 0.6883041953401906
Epoch: 45 | Iteration number: [570/4518] 12% | Training loss: 0.6882860819498698
Epoch: 45 | Iteration number: [580/4518] 12% | Training loss: 0.6882651153309592
Epoch: 45 | Iteration number: [590/4518] 13% | Training loss: 0.688238643791716
Epoch: 45 | Iteration number: [600/4518] 13% | Training loss: 0.6882359243432681
Epoch: 45 | Iteration number: [610/4518] 13% | Training loss: 0.6881905877199329
Epoch: 45 | Iteration number: [620/4518] 13% | Training loss: 0.6881640017993989
Epoch: 45 | Iteration number: [630/4518] 13% | Training loss: 0.6881295900496226
Epoch: 45 | Iteration number: [640/4518] 14% | Training loss: 0.6881133837625384
Epoch: 45 | Iteration number: [650/4518] 14% | Training loss: 0.68809339092328
Epoch: 45 | Iteration number: [660/4518] 14% | Training loss: 0.6880662377133514
Epoch: 45 | Iteration number: [670/4518] 14% | Training loss: 0.6880407455252178
Epoch: 45 | Iteration number: [680/4518] 15% | Training loss: 0.688038385878591
Epoch: 45 | Iteration number: [690/4518] 15% | Training loss: 0.6880072882209999
Epoch: 45 | Iteration number: [700/4518] 15% | Training loss: 0.6879952038185937
Epoch: 45 | Iteration number: [710/4518] 15% | Training loss: 0.6879858482051903
Epoch: 45 | Iteration number: [720/4518] 15% | Training loss: 0.6879932307534747
Epoch: 45 | Iteration number: [730/4518] 16% | Training loss: 0.6879627518457909
Epoch: 45 | Iteration number: [740/4518] 16% | Training loss: 0.6879483983323381
Epoch: 45 | Iteration number: [750/4518] 16% | Training loss: 0.6879382889270782
Epoch: 45 | Iteration number: [760/4518] 16% | Training loss: 0.6879303297714183
Epoch: 45 | Iteration number: [770/4518] 17% | Training loss: 0.687907784712779
Epoch: 45 | Iteration number: [780/4518] 17% | Training loss: 0.6878999123206505
Epoch: 45 | Iteration number: [790/4518] 17% | Training loss: 0.6878820936136608
Epoch: 45 | Iteration number: [800/4518] 17% | Training loss: 0.6878524120897055
Epoch: 45 | Iteration number: [810/4518] 17% | Training loss: 0.6878490272863411
Epoch: 45 | Iteration number: [820/4518] 18% | Training loss: 0.6878371485849706
Epoch: 45 | Iteration number: [830/4518] 18% | Training loss: 0.6878288516079086
Epoch: 45 | Iteration number: [840/4518] 18% | Training loss: 0.687813122286683
Epoch: 45 | Iteration number: [850/4518] 18% | Training loss: 0.6877911390276517
Epoch: 45 | Iteration number: [860/4518] 19% | Training loss: 0.6877886803344239
Epoch: 45 | Iteration number: [870/4518] 19% | Training loss: 0.6877682211755336
Epoch: 45 | Iteration number: [880/4518] 19% | Training loss: 0.6877530524676496
Epoch: 45 | Iteration number: [890/4518] 19% | Training loss: 0.6877471176426062
Epoch: 45 | Iteration number: [900/4518] 19% | Training loss: 0.6877344114912881
Epoch: 45 | Iteration number: [910/4518] 20% | Training loss: 0.687725173837536
Epoch: 45 | Iteration number: [920/4518] 20% | Training loss: 0.6877241470891496
Epoch: 45 | Iteration number: [930/4518] 20% | Training loss: 0.68771919031297
Epoch: 45 | Iteration number: [940/4518] 20% | Training loss: 0.6877178968267238
Epoch: 45 | Iteration number: [950/4518] 21% | Training loss: 0.6877031648159027
Epoch: 45 | Iteration number: [960/4518] 21% | Training loss: 0.6876930523042878
Epoch: 45 | Iteration number: [970/4518] 21% | Training loss: 0.6876925327728705
Epoch: 45 | Iteration number: [980/4518] 21% | Training loss: 0.6876944628905277
Epoch: 45 | Iteration number: [990/4518] 21% | Training loss: 0.6876954265315123
Epoch: 45 | Iteration number: [1000/4518] 22% | Training loss: 0.6876771256923676
Epoch: 45 | Iteration number: [1010/4518] 22% | Training loss: 0.6876717776945321
Epoch: 45 | Iteration number: [1020/4518] 22% | Training loss: 0.6876665845221164
Epoch: 45 | Iteration number: [1030/4518] 22% | Training loss: 0.687645585039287
Epoch: 45 | Iteration number: [1040/4518] 23% | Training loss: 0.6876381216714016
Epoch: 45 | Iteration number: [1050/4518] 23% | Training loss: 0.6876353665760585
Epoch: 45 | Iteration number: [1060/4518] 23% | Training loss: 0.6876220978655905
Epoch: 45 | Iteration number: [1070/4518] 23% | Training loss: 0.6876115001807703
Epoch: 45 | Iteration number: [1080/4518] 23% | Training loss: 0.6876067476692023
Epoch: 45 | Iteration number: [1090/4518] 24% | Training loss: 0.6876009369115217
Epoch: 45 | Iteration number: [1100/4518] 24% | Training loss: 0.6875861425833268
Epoch: 45 | Iteration number: [1110/4518] 24% | Training loss: 0.6875765647437121
Epoch: 45 | Iteration number: [1120/4518] 24% | Training loss: 0.6875692630984953
Epoch: 45 | Iteration number: [1130/4518] 25% | Training loss: 0.6875639185968754
Epoch: 45 | Iteration number: [1140/4518] 25% | Training loss: 0.6875664968762482
Epoch: 45 | Iteration number: [1150/4518] 25% | Training loss: 0.6875684121380682
Epoch: 45 | Iteration number: [1160/4518] 25% | Training loss: 0.6875625539956421
Epoch: 45 | Iteration number: [1170/4518] 25% | Training loss: 0.6875613954332139
Epoch: 45 | Iteration number: [1180/4518] 26% | Training loss: 0.6875550280688173
Epoch: 45 | Iteration number: [1190/4518] 26% | Training loss: 0.6875561712168846
Epoch: 45 | Iteration number: [1200/4518] 26% | Training loss: 0.6875493564705054
Epoch: 45 | Iteration number: [1210/4518] 26% | Training loss: 0.6875456574041982
Epoch: 45 | Iteration number: [1220/4518] 27% | Training loss: 0.6875454515707298
Epoch: 45 | Iteration number: [1230/4518] 27% | Training loss: 0.6875488374775988
Epoch: 45 | Iteration number: [1240/4518] 27% | Training loss: 0.6875387425384214
Epoch: 45 | Iteration number: [1250/4518] 27% | Training loss: 0.687536210489273
Epoch: 45 | Iteration number: [1260/4518] 27% | Training loss: 0.6875290563182225
Epoch: 45 | Iteration number: [1270/4518] 28% | Training loss: 0.6875345462419855
Epoch: 45 | Iteration number: [1280/4518] 28% | Training loss: 0.6875301858875901
Epoch: 45 | Iteration number: [1290/4518] 28% | Training loss: 0.6875294272751771
Epoch: 45 | Iteration number: [1300/4518] 28% | Training loss: 0.6875219975068019
Epoch: 45 | Iteration number: [1310/4518] 28% | Training loss: 0.6875163955542878
Epoch: 45 | Iteration number: [1320/4518] 29% | Training loss: 0.6875191827163551
Epoch: 45 | Iteration number: [1330/4518] 29% | Training loss: 0.6875094017588106
Epoch: 45 | Iteration number: [1340/4518] 29% | Training loss: 0.6875054149485346
Epoch: 45 | Iteration number: [1350/4518] 29% | Training loss: 0.6875019974178738
Epoch: 45 | Iteration number: [1360/4518] 30% | Training loss: 0.6874998936758322
Epoch: 45 | Iteration number: [1370/4518] 30% | Training loss: 0.6874897753235197
Epoch: 45 | Iteration number: [1380/4518] 30% | Training loss: 0.6874762735073118
Epoch: 45 | Iteration number: [1390/4518] 30% | Training loss: 0.6874870421217499
Epoch: 45 | Iteration number: [1400/4518] 30% | Training loss: 0.6874901371342795
Epoch: 45 | Iteration number: [1410/4518] 31% | Training loss: 0.6874864910088533
Epoch: 45 | Iteration number: [1420/4518] 31% | Training loss: 0.687482832351201
Epoch: 45 | Iteration number: [1430/4518] 31% | Training loss: 0.687488457873151
Epoch: 45 | Iteration number: [1440/4518] 31% | Training loss: 0.6874817832476563
Epoch: 45 | Iteration number: [1450/4518] 32% | Training loss: 0.6874719893932343
Epoch: 45 | Iteration number: [1460/4518] 32% | Training loss: 0.6874670407135193
Epoch: 45 | Iteration number: [1470/4518] 32% | Training loss: 0.6874553501200513
Epoch: 45 | Iteration number: [1480/4518] 32% | Training loss: 0.6874490921964517
Epoch: 45 | Iteration number: [1490/4518] 32% | Training loss: 0.6874442358144978
Epoch: 45 | Iteration number: [1500/4518] 33% | Training loss: 0.6874493309259415
Epoch: 45 | Iteration number: [1510/4518] 33% | Training loss: 0.6874358282973435
Epoch: 45 | Iteration number: [1520/4518] 33% | Training loss: 0.6874272688439018
Epoch: 45 | Iteration number: [1530/4518] 33% | Training loss: 0.6874245068606208
Epoch: 45 | Iteration number: [1540/4518] 34% | Training loss: 0.6874232387000864
Epoch: 45 | Iteration number: [1550/4518] 34% | Training loss: 0.6874254961552159
Epoch: 45 | Iteration number: [1560/4518] 34% | Training loss: 0.6874201229749581
Epoch: 45 | Iteration number: [1570/4518] 34% | Training loss: 0.6874147247736621
Epoch: 45 | Iteration number: [1580/4518] 34% | Training loss: 0.6874102489857734
Epoch: 45 | Iteration number: [1590/4518] 35% | Training loss: 0.6874025064444392
Epoch: 45 | Iteration number: [1600/4518] 35% | Training loss: 0.6874023989960552
Epoch: 45 | Iteration number: [1610/4518] 35% | Training loss: 0.6873921282172943
Epoch: 45 | Iteration number: [1620/4518] 35% | Training loss: 0.6873928919986442
Epoch: 45 | Iteration number: [1630/4518] 36% | Training loss: 0.6873867605727143
Epoch: 45 | Iteration number: [1640/4518] 36% | Training loss: 0.6873896687859442
Epoch: 45 | Iteration number: [1650/4518] 36% | Training loss: 0.6873859836477222
Epoch: 45 | Iteration number: [1660/4518] 36% | Training loss: 0.6873831139630582
Epoch: 45 | Iteration number: [1670/4518] 36% | Training loss: 0.6873760031725832
Epoch: 45 | Iteration number: [1680/4518] 37% | Training loss: 0.6873695669429642
Epoch: 45 | Iteration number: [1690/4518] 37% | Training loss: 0.6873663381006591
Epoch: 45 | Iteration number: [1700/4518] 37% | Training loss: 0.6873612207524916
Epoch: 45 | Iteration number: [1710/4518] 37% | Training loss: 0.6873626012899722
Epoch: 45 | Iteration number: [1720/4518] 38% | Training loss: 0.6873591129169908
Epoch: 45 | Iteration number: [1730/4518] 38% | Training loss: 0.6873614079345858
Epoch: 45 | Iteration number: [1740/4518] 38% | Training loss: 0.6873582052088332
Epoch: 45 | Iteration number: [1750/4518] 38% | Training loss: 0.687358131817409
Epoch: 45 | Iteration number: [1760/4518] 38% | Training loss: 0.6873546233570034
Epoch: 45 | Iteration number: [1770/4518] 39% | Training loss: 0.6873557879763135
Epoch: 45 | Iteration number: [1780/4518] 39% | Training loss: 0.6873574370413684
Epoch: 45 | Iteration number: [1790/4518] 39% | Training loss: 0.6873561169182122
Epoch: 45 | Iteration number: [1800/4518] 39% | Training loss: 0.6873556287421121
Epoch: 45 | Iteration number: [1810/4518] 40% | Training loss: 0.6873497453842374
Epoch: 45 | Iteration number: [1820/4518] 40% | Training loss: 0.6873383327499851
Epoch: 45 | Iteration number: [1830/4518] 40% | Training loss: 0.6873277093543381
Epoch: 45 | Iteration number: [1840/4518] 40% | Training loss: 0.6873217377649701
Epoch: 45 | Iteration number: [1850/4518] 40% | Training loss: 0.6873093856669761
Epoch: 45 | Iteration number: [1860/4518] 41% | Training loss: 0.6873055529209875
Epoch: 45 | Iteration number: [1870/4518] 41% | Training loss: 0.687299329552421
Epoch: 45 | Iteration number: [1880/4518] 41% | Training loss: 0.6872931072369535
Epoch: 45 | Iteration number: [1890/4518] 41% | Training loss: 0.6872922928560348
Epoch: 45 | Iteration number: [1900/4518] 42% | Training loss: 0.6872884238079975
Epoch: 45 | Iteration number: [1910/4518] 42% | Training loss: 0.6872853604910886
Epoch: 45 | Iteration number: [1920/4518] 42% | Training loss: 0.6872861901298165
Epoch: 45 | Iteration number: [1930/4518] 42% | Training loss: 0.6872811214602673
Epoch: 45 | Iteration number: [1940/4518] 42% | Training loss: 0.6872725966050452
Epoch: 45 | Iteration number: [1950/4518] 43% | Training loss: 0.687266162267098
Epoch: 45 | Iteration number: [1960/4518] 43% | Training loss: 0.6872603271080523
Epoch: 45 | Iteration number: [1970/4518] 43% | Training loss: 0.6872524888382345
Epoch: 45 | Iteration number: [1980/4518] 43% | Training loss: 0.6872450216852053
Epoch: 45 | Iteration number: [1990/4518] 44% | Training loss: 0.6872428664909536
Epoch: 45 | Iteration number: [2000/4518] 44% | Training loss: 0.6872404671013356
Epoch: 45 | Iteration number: [2010/4518] 44% | Training loss: 0.6872437335068907
Epoch: 45 | Iteration number: [2020/4518] 44% | Training loss: 0.6872450764226441
Epoch: 45 | Iteration number: [2030/4518] 44% | Training loss: 0.6872443538581209
Epoch: 45 | Iteration number: [2040/4518] 45% | Training loss: 0.6872404876000741
Epoch: 45 | Iteration number: [2050/4518] 45% | Training loss: 0.6872330039012723
Epoch: 45 | Iteration number: [2060/4518] 45% | Training loss: 0.6872285101888249
Epoch: 45 | Iteration number: [2070/4518] 45% | Training loss: 0.6872343154921048
Epoch: 45 | Iteration number: [2080/4518] 46% | Training loss: 0.6872327555830662
Epoch: 45 | Iteration number: [2090/4518] 46% | Training loss: 0.687235874650581
Epoch: 45 | Iteration number: [2100/4518] 46% | Training loss: 0.687236342827479
Epoch: 45 | Iteration number: [2110/4518] 46% | Training loss: 0.6872325187045816
Epoch: 45 | Iteration number: [2120/4518] 46% | Training loss: 0.687230044828271
Epoch: 45 | Iteration number: [2130/4518] 47% | Training loss: 0.6872215731882714
Epoch: 45 | Iteration number: [2140/4518] 47% | Training loss: 0.6872210856353012
Epoch: 45 | Iteration number: [2150/4518] 47% | Training loss: 0.6872194702126259
Epoch: 45 | Iteration number: [2160/4518] 47% | Training loss: 0.6872143754528628
Epoch: 45 | Iteration number: [2170/4518] 48% | Training loss: 0.6872146900897751
Epoch: 45 | Iteration number: [2180/4518] 48% | Training loss: 0.6872115989890667
Epoch: 45 | Iteration number: [2190/4518] 48% | Training loss: 0.6872114883982428
Epoch: 45 | Iteration number: [2200/4518] 48% | Training loss: 0.6872121619636362
Epoch: 45 | Iteration number: [2210/4518] 48% | Training loss: 0.6872110048570245
Epoch: 45 | Iteration number: [2220/4518] 49% | Training loss: 0.68720453113049
Epoch: 45 | Iteration number: [2230/4518] 49% | Training loss: 0.6872002394210063
Epoch: 45 | Iteration number: [2240/4518] 49% | Training loss: 0.6872054106156741
Epoch: 45 | Iteration number: [2250/4518] 49% | Training loss: 0.6871969232559204
Epoch: 45 | Iteration number: [2260/4518] 50% | Training loss: 0.6871958246537014
Epoch: 45 | Iteration number: [2270/4518] 50% | Training loss: 0.6871963117878868
Epoch: 45 | Iteration number: [2280/4518] 50% | Training loss: 0.6871962812908908
Epoch: 45 | Iteration number: [2290/4518] 50% | Training loss: 0.6871937875404108
Epoch: 45 | Iteration number: [2300/4518] 50% | Training loss: 0.6871905151657436
Epoch: 45 | Iteration number: [2310/4518] 51% | Training loss: 0.687192775212325
Epoch: 45 | Iteration number: [2320/4518] 51% | Training loss: 0.6871950367915219
Epoch: 45 | Iteration number: [2330/4518] 51% | Training loss: 0.6871897126983675
Epoch: 45 | Iteration number: [2340/4518] 51% | Training loss: 0.6871838313646805
Epoch: 45 | Iteration number: [2350/4518] 52% | Training loss: 0.6871854510713131
Epoch: 45 | Iteration number: [2360/4518] 52% | Training loss: 0.6871847069869608
Epoch: 45 | Iteration number: [2370/4518] 52% | Training loss: 0.6871841444999357
Epoch: 45 | Iteration number: [2380/4518] 52% | Training loss: 0.6871835114324794
Epoch: 45 | Iteration number: [2390/4518] 52% | Training loss: 0.6871787307152688
Epoch: 45 | Iteration number: [2400/4518] 53% | Training loss: 0.6871714558204015
Epoch: 45 | Iteration number: [2410/4518] 53% | Training loss: 0.6871700920751975
Epoch: 45 | Iteration number: [2420/4518] 53% | Training loss: 0.6871667144712338
Epoch: 45 | Iteration number: [2430/4518] 53% | Training loss: 0.6871605417120114
Epoch: 45 | Iteration number: [2440/4518] 54% | Training loss: 0.6871609008703076
Epoch: 45 | Iteration number: [2450/4518] 54% | Training loss: 0.6871582535334996
Epoch: 45 | Iteration number: [2460/4518] 54% | Training loss: 0.6871534659368236
Epoch: 45 | Iteration number: [2470/4518] 54% | Training loss: 0.6871495397226048
Epoch: 45 | Iteration number: [2480/4518] 54% | Training loss: 0.6871488379374627
Epoch: 45 | Iteration number: [2490/4518] 55% | Training loss: 0.6871493712486513
Epoch: 45 | Iteration number: [2500/4518] 55% | Training loss: 0.687150464630127
Epoch: 45 | Iteration number: [2510/4518] 55% | Training loss: 0.6871483577200141
Epoch: 45 | Iteration number: [2520/4518] 55% | Training loss: 0.6871533382270071
Epoch: 45 | Iteration number: [2530/4518] 55% | Training loss: 0.6871469275753489
Epoch: 45 | Iteration number: [2540/4518] 56% | Training loss: 0.6871428061188676
Epoch: 45 | Iteration number: [2550/4518] 56% | Training loss: 0.6871350880230175
Epoch: 45 | Iteration number: [2560/4518] 56% | Training loss: 0.6871391788590699
Epoch: 45 | Iteration number: [2570/4518] 56% | Training loss: 0.687134360037889
Epoch: 45 | Iteration number: [2580/4518] 57% | Training loss: 0.6871354374774666
Epoch: 45 | Iteration number: [2590/4518] 57% | Training loss: 0.6871384629181453
Epoch: 45 | Iteration number: [2600/4518] 57% | Training loss: 0.6871418486191676
Epoch: 45 | Iteration number: [2610/4518] 57% | Training loss: 0.68713556984832
Epoch: 45 | Iteration number: [2620/4518] 57% | Training loss: 0.6871351616300699
Epoch: 45 | Iteration number: [2630/4518] 58% | Training loss: 0.6871390765384123
Epoch: 45 | Iteration number: [2640/4518] 58% | Training loss: 0.6871364286451629
Epoch: 45 | Iteration number: [2650/4518] 58% | Training loss: 0.6871371344350419
Epoch: 45 | Iteration number: [2660/4518] 58% | Training loss: 0.6871389995168026
Epoch: 45 | Iteration number: [2670/4518] 59% | Training loss: 0.6871406887577715
Epoch: 45 | Iteration number: [2680/4518] 59% | Training loss: 0.6871416840980302
Epoch: 45 | Iteration number: [2690/4518] 59% | Training loss: 0.6871416034973243
Epoch: 45 | Iteration number: [2700/4518] 59% | Training loss: 0.6871418501933416
Epoch: 45 | Iteration number: [2710/4518] 59% | Training loss: 0.6871341980471383
Epoch: 45 | Iteration number: [2720/4518] 60% | Training loss: 0.6871289614149753
Epoch: 45 | Iteration number: [2730/4518] 60% | Training loss: 0.6871279088568775
Epoch: 45 | Iteration number: [2740/4518] 60% | Training loss: 0.6871274010325871
Epoch: 45 | Iteration number: [2750/4518] 60% | Training loss: 0.6871265416795557
Epoch: 45 | Iteration number: [2760/4518] 61% | Training loss: 0.6871297353851622
Epoch: 45 | Iteration number: [2770/4518] 61% | Training loss: 0.6871268360193026
Epoch: 45 | Iteration number: [2780/4518] 61% | Training loss: 0.6871258949204314
Epoch: 45 | Iteration number: [2790/4518] 61% | Training loss: 0.6871239983480036
Epoch: 45 | Iteration number: [2800/4518] 61% | Training loss: 0.6871225516072341
Epoch: 45 | Iteration number: [2810/4518] 62% | Training loss: 0.6871199909902552
Epoch: 45 | Iteration number: [2820/4518] 62% | Training loss: 0.687117849343212
Epoch: 45 | Iteration number: [2830/4518] 62% | Training loss: 0.6871200950112023
Epoch: 45 | Iteration number: [2840/4518] 62% | Training loss: 0.6871183893210452
Epoch: 45 | Iteration number: [2850/4518] 63% | Training loss: 0.6871174637685742
Epoch: 45 | Iteration number: [2860/4518] 63% | Training loss: 0.6871141506658568
Epoch: 45 | Iteration number: [2870/4518] 63% | Training loss: 0.6871071670321222
Epoch: 45 | Iteration number: [2880/4518] 63% | Training loss: 0.6870989989696278
Epoch: 45 | Iteration number: [2890/4518] 63% | Training loss: 0.6871001964209401
Epoch: 45 | Iteration number: [2900/4518] 64% | Training loss: 0.6871026448751318
Epoch: 45 | Iteration number: [2910/4518] 64% | Training loss: 0.6871066178857665
Epoch: 45 | Iteration number: [2920/4518] 64% | Training loss: 0.6871079027856866
Epoch: 45 | Iteration number: [2930/4518] 64% | Training loss: 0.6870988471312734
Epoch: 45 | Iteration number: [2940/4518] 65% | Training loss: 0.68709651683869
Epoch: 45 | Iteration number: [2950/4518] 65% | Training loss: 0.6870959282527536
Epoch: 45 | Iteration number: [2960/4518] 65% | Training loss: 0.6870879895582392
Epoch: 45 | Iteration number: [2970/4518] 65% | Training loss: 0.687087619525415
Epoch: 45 | Iteration number: [2980/4518] 65% | Training loss: 0.6870876091438652
Epoch: 45 | Iteration number: [2990/4518] 66% | Training loss: 0.687084631138422
Epoch: 45 | Iteration number: [3000/4518] 66% | Training loss: 0.6870819780230523
Epoch: 45 | Iteration number: [3010/4518] 66% | Training loss: 0.6870839490248911
Epoch: 45 | Iteration number: [3020/4518] 66% | Training loss: 0.6870843845290064
Epoch: 45 | Iteration number: [3030/4518] 67% | Training loss: 0.6870819317232264
Epoch: 45 | Iteration number: [3040/4518] 67% | Training loss: 0.6870760707478775
Epoch: 45 | Iteration number: [3050/4518] 67% | Training loss: 0.687075719911544
Epoch: 45 | Iteration number: [3060/4518] 67% | Training loss: 0.6870716370203915
Epoch: 45 | Iteration number: [3070/4518] 67% | Training loss: 0.6870703436458538
Epoch: 45 | Iteration number: [3080/4518] 68% | Training loss: 0.6870722843067987
Epoch: 45 | Iteration number: [3090/4518] 68% | Training loss: 0.6870749274889628
Epoch: 45 | Iteration number: [3100/4518] 68% | Training loss: 0.687075003904681
Epoch: 45 | Iteration number: [3110/4518] 68% | Training loss: 0.6870749155233143
Epoch: 45 | Iteration number: [3120/4518] 69% | Training loss: 0.687074859898824
Epoch: 45 | Iteration number: [3130/4518] 69% | Training loss: 0.6870709862191076
Epoch: 45 | Iteration number: [3140/4518] 69% | Training loss: 0.687069077305733
Epoch: 45 | Iteration number: [3150/4518] 69% | Training loss: 0.6870673999521467
Epoch: 45 | Iteration number: [3160/4518] 69% | Training loss: 0.6870687619417528
Epoch: 45 | Iteration number: [3170/4518] 70% | Training loss: 0.6870665063241302
Epoch: 45 | Iteration number: [3180/4518] 70% | Training loss: 0.6870638190013058
Epoch: 45 | Iteration number: [3190/4518] 70% | Training loss: 0.6870610274491266
Epoch: 45 | Iteration number: [3200/4518] 70% | Training loss: 0.6870616053044796
Epoch: 45 | Iteration number: [3210/4518] 71% | Training loss: 0.6870573751094556
Epoch: 45 | Iteration number: [3220/4518] 71% | Training loss: 0.6870561435355903
Epoch: 45 | Iteration number: [3230/4518] 71% | Training loss: 0.6870542242615585
Epoch: 45 | Iteration number: [3240/4518] 71% | Training loss: 0.6870575245331835
Epoch: 45 | Iteration number: [3250/4518] 71% | Training loss: 0.6870586078533759
Epoch: 45 | Iteration number: [3260/4518] 72% | Training loss: 0.6870616275657174
Epoch: 45 | Iteration number: [3270/4518] 72% | Training loss: 0.6870561015168462
Epoch: 45 | Iteration number: [3280/4518] 72% | Training loss: 0.6870544509189885
Epoch: 45 | Iteration number: [3290/4518] 72% | Training loss: 0.687049322215257
Epoch: 45 | Iteration number: [3300/4518] 73% | Training loss: 0.687049542015249
Epoch: 45 | Iteration number: [3310/4518] 73% | Training loss: 0.6870480820311521
Epoch: 45 | Iteration number: [3320/4518] 73% | Training loss: 0.6870477668492191
Epoch: 45 | Iteration number: [3330/4518] 73% | Training loss: 0.6870471986027451
Epoch: 45 | Iteration number: [3340/4518] 73% | Training loss: 0.687045788140354
Epoch: 45 | Iteration number: [3350/4518] 74% | Training loss: 0.6870438323803802
Epoch: 45 | Iteration number: [3360/4518] 74% | Training loss: 0.6870432723668359
Epoch: 45 | Iteration number: [3370/4518] 74% | Training loss: 0.6870422148563035
Epoch: 45 | Iteration number: [3380/4518] 74% | Training loss: 0.6870398579969914
Epoch: 45 | Iteration number: [3390/4518] 75% | Training loss: 0.6870372590941314
Epoch: 45 | Iteration number: [3400/4518] 75% | Training loss: 0.687041039221427
Epoch: 45 | Iteration number: [3410/4518] 75% | Training loss: 0.6870394159971445
Epoch: 45 | Iteration number: [3420/4518] 75% | Training loss: 0.6870373123570492
Epoch: 45 | Iteration number: [3430/4518] 75% | Training loss: 0.6870370997284314
Epoch: 45 | Iteration number: [3440/4518] 76% | Training loss: 0.6870355145529259
Epoch: 45 | Iteration number: [3450/4518] 76% | Training loss: 0.6870361209434012
Epoch: 45 | Iteration number: [3460/4518] 76% | Training loss: 0.68703636769959
Epoch: 45 | Iteration number: [3470/4518] 76% | Training loss: 0.6870350281683787
Epoch: 45 | Iteration number: [3480/4518] 77% | Training loss: 0.6870317945535156
Epoch: 45 | Iteration number: [3490/4518] 77% | Training loss: 0.6870289889311039
Epoch: 45 | Iteration number: [3500/4518] 77% | Training loss: 0.6870285343783242
Epoch: 45 | Iteration number: [3510/4518] 77% | Training loss: 0.6870274668745165
Epoch: 45 | Iteration number: [3520/4518] 77% | Training loss: 0.6870291110128164
Epoch: 45 | Iteration number: [3530/4518] 78% | Training loss: 0.6870306916007239
Epoch: 45 | Iteration number: [3540/4518] 78% | Training loss: 0.6870309374426717
Epoch: 45 | Iteration number: [3550/4518] 78% | Training loss: 0.6870317874995755
Epoch: 45 | Iteration number: [3560/4518] 78% | Training loss: 0.6870292807395538
Epoch: 45 | Iteration number: [3570/4518] 79% | Training loss: 0.6870326572606543
Epoch: 45 | Iteration number: [3580/4518] 79% | Training loss: 0.6870344506462193
Epoch: 45 | Iteration number: [3590/4518] 79% | Training loss: 0.6870321202410961
Epoch: 45 | Iteration number: [3600/4518] 79% | Training loss: 0.6870279839966033
Epoch: 45 | Iteration number: [3610/4518] 79% | Training loss: 0.687023639811043
Epoch: 45 | Iteration number: [3620/4518] 80% | Training loss: 0.6870213224084338
Epoch: 45 | Iteration number: [3630/4518] 80% | Training loss: 0.6870168647982857
Epoch: 45 | Iteration number: [3640/4518] 80% | Training loss: 0.687015228661207
Epoch: 45 | Iteration number: [3650/4518] 80% | Training loss: 0.6870145491377948
Epoch: 45 | Iteration number: [3660/4518] 81% | Training loss: 0.6870136526601562
Epoch: 45 | Iteration number: [3670/4518] 81% | Training loss: 0.6870126636703917
Epoch: 45 | Iteration number: [3680/4518] 81% | Training loss: 0.687010924032201
Epoch: 45 | Iteration number: [3690/4518] 81% | Training loss: 0.687012460916669
Epoch: 45 | Iteration number: [3700/4518] 81% | Training loss: 0.6870117491322595
Epoch: 45 | Iteration number: [3710/4518] 82% | Training loss: 0.6870160655833961
Epoch: 45 | Iteration number: [3720/4518] 82% | Training loss: 0.6870154246527661
Epoch: 45 | Iteration number: [3730/4518] 82% | Training loss: 0.6870150483006127
Epoch: 45 | Iteration number: [3740/4518] 82% | Training loss: 0.6870159316827906
Epoch: 45 | Iteration number: [3750/4518] 83% | Training loss: 0.6870148002147675
Epoch: 45 | Iteration number: [3760/4518] 83% | Training loss: 0.6870125486178601
Epoch: 45 | Iteration number: [3770/4518] 83% | Training loss: 0.6870128710959255
Epoch: 45 | Iteration number: [3780/4518] 83% | Training loss: 0.6870071451026927
Epoch: 45 | Iteration number: [3790/4518] 83% | Training loss: 0.6870066475427874
Epoch: 45 | Iteration number: [3800/4518] 84% | Training loss: 0.6870024586508149
Epoch: 45 | Iteration number: [3810/4518] 84% | Training loss: 0.6870016003843993
Epoch: 45 | Iteration number: [3820/4518] 84% | Training loss: 0.6869961573971504
Epoch: 45 | Iteration number: [3830/4518] 84% | Training loss: 0.6869981527172866
Epoch: 45 | Iteration number: [3840/4518] 84% | Training loss: 0.6869959403915952
Epoch: 45 | Iteration number: [3850/4518] 85% | Training loss: 0.6869945948619347
Epoch: 45 | Iteration number: [3860/4518] 85% | Training loss: 0.6869933846392162
Epoch: 45 | Iteration number: [3870/4518] 85% | Training loss: 0.6869948192776327
Epoch: 45 | Iteration number: [3880/4518] 85% | Training loss: 0.6869949879259178
Epoch: 45 | Iteration number: [3890/4518] 86% | Training loss: 0.6869943779660987
Epoch: 45 | Iteration number: [3900/4518] 86% | Training loss: 0.6869944635110024
Epoch: 45 | Iteration number: [3910/4518] 86% | Training loss: 0.6869931905623288
Epoch: 45 | Iteration number: [3920/4518] 86% | Training loss: 0.6869905180468852
Epoch: 45 | Iteration number: [3930/4518] 86% | Training loss: 0.6869918113901415
Epoch: 45 | Iteration number: [3940/4518] 87% | Training loss: 0.6869909286801585
Epoch: 45 | Iteration number: [3950/4518] 87% | Training loss: 0.6869905825958976
Epoch: 45 | Iteration number: [3960/4518] 87% | Training loss: 0.6869918566159527
Epoch: 45 | Iteration number: [3970/4518] 87% | Training loss: 0.6869902132590412
Epoch: 45 | Iteration number: [3980/4518] 88% | Training loss: 0.6869895377650332
Epoch: 45 | Iteration number: [3990/4518] 88% | Training loss: 0.6869902297368922
Epoch: 45 | Iteration number: [4000/4518] 88% | Training loss: 0.6869904561191797
Epoch: 45 | Iteration number: [4010/4518] 88% | Training loss: 0.6869902982081558
Epoch: 45 | Iteration number: [4020/4518] 88% | Training loss: 0.6869921226110032
Epoch: 45 | Iteration number: [4030/4518] 89% | Training loss: 0.6869909025303483
Epoch: 45 | Iteration number: [4040/4518] 89% | Training loss: 0.6869908803465343
Epoch: 45 | Iteration number: [4050/4518] 89% | Training loss: 0.6869906091837236
Epoch: 45 | Iteration number: [4060/4518] 89% | Training loss: 0.686990867826739
Epoch: 45 | Iteration number: [4070/4518] 90% | Training loss: 0.6869911184621385
Epoch: 45 | Iteration number: [4080/4518] 90% | Training loss: 0.6869907328165045
Epoch: 45 | Iteration number: [4090/4518] 90% | Training loss: 0.686990152113595
Epoch: 45 | Iteration number: [4100/4518] 90% | Training loss: 0.6869885454236008
Epoch: 45 | Iteration number: [4110/4518] 90% | Training loss: 0.6869862672911363
Epoch: 45 | Iteration number: [4120/4518] 91% | Training loss: 0.6869855031081774
Epoch: 45 | Iteration number: [4130/4518] 91% | Training loss: 0.6869851951593349
Epoch: 45 | Iteration number: [4140/4518] 91% | Training loss: 0.6869839317412768
Epoch: 45 | Iteration number: [4150/4518] 91% | Training loss: 0.6869837320999926
Epoch: 45 | Iteration number: [4160/4518] 92% | Training loss: 0.6869825047082626
Epoch: 45 | Iteration number: [4170/4518] 92% | Training loss: 0.6869820171837613
Epoch: 45 | Iteration number: [4180/4518] 92% | Training loss: 0.6869827392426404
Epoch: 45 | Iteration number: [4190/4518] 92% | Training loss: 0.6869798000359593
Epoch: 45 | Iteration number: [4200/4518] 92% | Training loss: 0.686979477987403
Epoch: 45 | Iteration number: [4210/4518] 93% | Training loss: 0.6869785548247521
Epoch: 45 | Iteration number: [4220/4518] 93% | Training loss: 0.6869801319747174
Epoch: 45 | Iteration number: [4230/4518] 93% | Training loss: 0.6869777412842916
Epoch: 45 | Iteration number: [4240/4518] 93% | Training loss: 0.6869770222396221
Epoch: 45 | Iteration number: [4250/4518] 94% | Training loss: 0.686975655149011
Epoch: 45 | Iteration number: [4260/4518] 94% | Training loss: 0.6869777652579294
Epoch: 45 | Iteration number: [4270/4518] 94% | Training loss: 0.6869787800507468
Epoch: 45 | Iteration number: [4280/4518] 94% | Training loss: 0.6869798792717613
Epoch: 45 | Iteration number: [4290/4518] 94% | Training loss: 0.6869796966339324
Epoch: 45 | Iteration number: [4300/4518] 95% | Training loss: 0.6869809294162794
Epoch: 45 | Iteration number: [4310/4518] 95% | Training loss: 0.6869821063465419
Epoch: 45 | Iteration number: [4320/4518] 95% | Training loss: 0.6869824462190822
Epoch: 45 | Iteration number: [4330/4518] 95% | Training loss: 0.6869835906023242
Epoch: 45 | Iteration number: [4340/4518] 96% | Training loss: 0.686981380136881
Epoch: 45 | Iteration number: [4350/4518] 96% | Training loss: 0.6869801993753718
Epoch: 45 | Iteration number: [4360/4518] 96% | Training loss: 0.6869786104341166
Epoch: 45 | Iteration number: [4370/4518] 96% | Training loss: 0.6869798042545057
Epoch: 45 | Iteration number: [4380/4518] 96% | Training loss: 0.6869799950895789
Epoch: 45 | Iteration number: [4390/4518] 97% | Training loss: 0.6869797440894916
Epoch: 45 | Iteration number: [4400/4518] 97% | Training loss: 0.6869789344072342
Epoch: 45 | Iteration number: [4410/4518] 97% | Training loss: 0.686978323200122
Epoch: 45 | Iteration number: [4420/4518] 97% | Training loss: 0.68697814105323
Epoch: 45 | Iteration number: [4430/4518] 98% | Training loss: 0.6869805100943649
Epoch: 45 | Iteration number: [4440/4518] 98% | Training loss: 0.6869761664185438
Epoch: 45 | Iteration number: [4450/4518] 98% | Training loss: 0.6869744091891171
Epoch: 45 | Iteration number: [4460/4518] 98% | Training loss: 0.6869736826874215
Epoch: 45 | Iteration number: [4470/4518] 98% | Training loss: 0.6869735574428933
Epoch: 45 | Iteration number: [4480/4518] 99% | Training loss: 0.68697176446606
Epoch: 45 | Iteration number: [4490/4518] 99% | Training loss: 0.6869706771819788
Epoch: 45 | Iteration number: [4500/4518] 99% | Training loss: 0.6869706503152847
Epoch: 45 | Iteration number: [4510/4518] 99% | Training loss: 0.6869694602463039

 End of epoch: 45 | Train Loss: 0.6868149363503829 | Training Time: 633 

 End of epoch: 45 | Eval Loss: 0.6897682109657599 | Evaluating Time: 17 
Epoch: 46 | Iteration number: [10/4518] 0% | Training loss: 0.7550451219081878
Epoch: 46 | Iteration number: [20/4518] 0% | Training loss: 0.720841321349144
Epoch: 46 | Iteration number: [30/4518] 0% | Training loss: 0.7094047943751017
Epoch: 46 | Iteration number: [40/4518] 0% | Training loss: 0.7037286356091499
Epoch: 46 | Iteration number: [50/4518] 1% | Training loss: 0.7003104591369629
Epoch: 46 | Iteration number: [60/4518] 1% | Training loss: 0.6981282899777095
Epoch: 46 | Iteration number: [70/4518] 1% | Training loss: 0.6964746917997088
Epoch: 46 | Iteration number: [80/4518] 1% | Training loss: 0.6953019589185715
Epoch: 46 | Iteration number: [90/4518] 1% | Training loss: 0.6942493961917029
Epoch: 46 | Iteration number: [100/4518] 2% | Training loss: 0.6935166215896607
Epoch: 46 | Iteration number: [110/4518] 2% | Training loss: 0.6928071981126612
Epoch: 46 | Iteration number: [120/4518] 2% | Training loss: 0.6923412342866262
Epoch: 46 | Iteration number: [130/4518] 2% | Training loss: 0.6918630668750176
Epoch: 46 | Iteration number: [140/4518] 3% | Training loss: 0.6913411455495017
Epoch: 46 | Iteration number: [150/4518] 3% | Training loss: 0.6909696261088053
Epoch: 46 | Iteration number: [160/4518] 3% | Training loss: 0.6906957045197487
Epoch: 46 | Iteration number: [170/4518] 3% | Training loss: 0.6904961053062888
Epoch: 46 | Iteration number: [180/4518] 3% | Training loss: 0.6902947571542528
Epoch: 46 | Iteration number: [190/4518] 4% | Training loss: 0.6901160155472003
Epoch: 46 | Iteration number: [200/4518] 4% | Training loss: 0.689950003027916
Epoch: 46 | Iteration number: [210/4518] 4% | Training loss: 0.6897864449591864
Epoch: 46 | Iteration number: [220/4518] 4% | Training loss: 0.6896892859177156
Epoch: 46 | Iteration number: [230/4518] 5% | Training loss: 0.6895391212857288
Epoch: 46 | Iteration number: [240/4518] 5% | Training loss: 0.6894106817742188
Epoch: 46 | Iteration number: [250/4518] 5% | Training loss: 0.6893020098209381
Epoch: 46 | Iteration number: [260/4518] 5% | Training loss: 0.6891863960486192
Epoch: 46 | Iteration number: [270/4518] 5% | Training loss: 0.6891461866873282
Epoch: 46 | Iteration number: [280/4518] 6% | Training loss: 0.689057146012783
Epoch: 46 | Iteration number: [290/4518] 6% | Training loss: 0.688951836372244
Epoch: 46 | Iteration number: [300/4518] 6% | Training loss: 0.6888705106576284
Epoch: 46 | Iteration number: [310/4518] 6% | Training loss: 0.6887960680069461
Epoch: 46 | Iteration number: [320/4518] 7% | Training loss: 0.6887262752279639
Epoch: 46 | Iteration number: [330/4518] 7% | Training loss: 0.6886840318188523
Epoch: 46 | Iteration number: [340/4518] 7% | Training loss: 0.6886363020714592
Epoch: 46 | Iteration number: [350/4518] 7% | Training loss: 0.6885732551983424
Epoch: 46 | Iteration number: [360/4518] 7% | Training loss: 0.6885321550899082
Epoch: 46 | Iteration number: [370/4518] 8% | Training loss: 0.6885225075322229
Epoch: 46 | Iteration number: [380/4518] 8% | Training loss: 0.6884895635278602
Epoch: 46 | Iteration number: [390/4518] 8% | Training loss: 0.6884666198339218
Epoch: 46 | Iteration number: [400/4518] 8% | Training loss: 0.6884342594444752
Epoch: 46 | Iteration number: [410/4518] 9% | Training loss: 0.6883637942918917
Epoch: 46 | Iteration number: [420/4518] 9% | Training loss: 0.6883486133246195
Epoch: 46 | Iteration number: [430/4518] 9% | Training loss: 0.6883143984994223
Epoch: 46 | Iteration number: [440/4518] 9% | Training loss: 0.6882918650453741
Epoch: 46 | Iteration number: [450/4518] 9% | Training loss: 0.6882802455955082
Epoch: 46 | Iteration number: [460/4518] 10% | Training loss: 0.6882321256658305
Epoch: 46 | Iteration number: [470/4518] 10% | Training loss: 0.6882249449161773
Epoch: 46 | Iteration number: [480/4518] 10% | Training loss: 0.6882066297034423
Epoch: 46 | Iteration number: [490/4518] 10% | Training loss: 0.6881988789354052
Epoch: 46 | Iteration number: [500/4518] 11% | Training loss: 0.6881924947500229
Epoch: 46 | Iteration number: [510/4518] 11% | Training loss: 0.6881764797603382
Epoch: 46 | Iteration number: [520/4518] 11% | Training loss: 0.6881390996850454
Epoch: 46 | Iteration number: [530/4518] 11% | Training loss: 0.6881310524805537
Epoch: 46 | Iteration number: [540/4518] 11% | Training loss: 0.6881059517463048
Epoch: 46 | Iteration number: [550/4518] 12% | Training loss: 0.6881101782755418
Epoch: 46 | Iteration number: [560/4518] 12% | Training loss: 0.6881016452397619
Epoch: 46 | Iteration number: [570/4518] 12% | Training loss: 0.688092639571742
Epoch: 46 | Iteration number: [580/4518] 12% | Training loss: 0.6880641350458409
Epoch: 46 | Iteration number: [590/4518] 13% | Training loss: 0.6880461562488038
Epoch: 46 | Iteration number: [600/4518] 13% | Training loss: 0.6879999311765035
Epoch: 46 | Iteration number: [610/4518] 13% | Training loss: 0.6880001517592883
Epoch: 46 | Iteration number: [620/4518] 13% | Training loss: 0.6879839405898125
Epoch: 46 | Iteration number: [630/4518] 13% | Training loss: 0.6879590400627681
Epoch: 46 | Iteration number: [640/4518] 14% | Training loss: 0.6879396805539727
Epoch: 46 | Iteration number: [650/4518] 14% | Training loss: 0.6879148535545055
Epoch: 46 | Iteration number: [660/4518] 14% | Training loss: 0.6878962829257502
Epoch: 46 | Iteration number: [670/4518] 14% | Training loss: 0.6878707093089375
Epoch: 46 | Iteration number: [680/4518] 15% | Training loss: 0.687846147751107
Epoch: 46 | Iteration number: [690/4518] 15% | Training loss: 0.6878423281337904
Epoch: 46 | Iteration number: [700/4518] 15% | Training loss: 0.6878152305739267
Epoch: 46 | Iteration number: [710/4518] 15% | Training loss: 0.6877951181270707
Epoch: 46 | Iteration number: [720/4518] 15% | Training loss: 0.687764601657788
Epoch: 46 | Iteration number: [730/4518] 16% | Training loss: 0.6877503066030267
Epoch: 46 | Iteration number: [740/4518] 16% | Training loss: 0.6877324099476273
Epoch: 46 | Iteration number: [750/4518] 16% | Training loss: 0.6877151132424673
Epoch: 46 | Iteration number: [760/4518] 16% | Training loss: 0.6877058306022694
Epoch: 46 | Iteration number: [770/4518] 17% | Training loss: 0.6877051764494413
Epoch: 46 | Iteration number: [780/4518] 17% | Training loss: 0.687682212698154
Epoch: 46 | Iteration number: [790/4518] 17% | Training loss: 0.6876591385919837
Epoch: 46 | Iteration number: [800/4518] 17% | Training loss: 0.6876442947238683
Epoch: 46 | Iteration number: [810/4518] 17% | Training loss: 0.6876394930445118
Epoch: 46 | Iteration number: [820/4518] 18% | Training loss: 0.6876267585085659
Epoch: 46 | Iteration number: [830/4518] 18% | Training loss: 0.687621164465525
Epoch: 46 | Iteration number: [840/4518] 18% | Training loss: 0.6876144125348046
Epoch: 46 | Iteration number: [850/4518] 18% | Training loss: 0.6876145658072303
Epoch: 46 | Iteration number: [860/4518] 19% | Training loss: 0.6875981230375379
Epoch: 46 | Iteration number: [870/4518] 19% | Training loss: 0.6875909321609585
Epoch: 46 | Iteration number: [880/4518] 19% | Training loss: 0.6875633442266421
Epoch: 46 | Iteration number: [890/4518] 19% | Training loss: 0.6875595770525129
Epoch: 46 | Iteration number: [900/4518] 19% | Training loss: 0.687553820543819
Epoch: 46 | Iteration number: [910/4518] 20% | Training loss: 0.6875425554893829
Epoch: 46 | Iteration number: [920/4518] 20% | Training loss: 0.6875345704996068
Epoch: 46 | Iteration number: [930/4518] 20% | Training loss: 0.6875222868175916
Epoch: 46 | Iteration number: [940/4518] 20% | Training loss: 0.6875137916270723
Epoch: 46 | Iteration number: [950/4518] 21% | Training loss: 0.6874945798673128
Epoch: 46 | Iteration number: [960/4518] 21% | Training loss: 0.6874797749643524
Epoch: 46 | Iteration number: [970/4518] 21% | Training loss: 0.6874781859904221
Epoch: 46 | Iteration number: [980/4518] 21% | Training loss: 0.6874733154871026
Epoch: 46 | Iteration number: [990/4518] 21% | Training loss: 0.6874756052638545
Epoch: 46 | Iteration number: [1000/4518] 22% | Training loss: 0.6874773016571999
Epoch: 46 | Iteration number: [1010/4518] 22% | Training loss: 0.6874746264207481
Epoch: 46 | Iteration number: [1020/4518] 22% | Training loss: 0.687466251148897
Epoch: 46 | Iteration number: [1030/4518] 22% | Training loss: 0.6874515115636066
Epoch: 46 | Iteration number: [1040/4518] 23% | Training loss: 0.6874367842307457
Epoch: 46 | Iteration number: [1050/4518] 23% | Training loss: 0.6874344045207614
Epoch: 46 | Iteration number: [1060/4518] 23% | Training loss: 0.687421333058825
Epoch: 46 | Iteration number: [1070/4518] 23% | Training loss: 0.6874227878089263
Epoch: 46 | Iteration number: [1080/4518] 23% | Training loss: 0.6874089954627884
Epoch: 46 | Iteration number: [1090/4518] 24% | Training loss: 0.6873965640133674
Epoch: 46 | Iteration number: [1100/4518] 24% | Training loss: 0.6873985972187736
Epoch: 46 | Iteration number: [1110/4518] 24% | Training loss: 0.6873927274802784
Epoch: 46 | Iteration number: [1120/4518] 24% | Training loss: 0.6873850932078702
Epoch: 46 | Iteration number: [1130/4518] 25% | Training loss: 0.6873859431891315
Epoch: 46 | Iteration number: [1140/4518] 25% | Training loss: 0.6873860371740241
Epoch: 46 | Iteration number: [1150/4518] 25% | Training loss: 0.6873920230243517
Epoch: 46 | Iteration number: [1160/4518] 25% | Training loss: 0.6873800021307221
Epoch: 46 | Iteration number: [1170/4518] 25% | Training loss: 0.6873786578830491
Epoch: 46 | Iteration number: [1180/4518] 26% | Training loss: 0.6873798049102395
Epoch: 46 | Iteration number: [1190/4518] 26% | Training loss: 0.6873658536862927
Epoch: 46 | Iteration number: [1200/4518] 26% | Training loss: 0.6873663501441478
Epoch: 46 | Iteration number: [1210/4518] 26% | Training loss: 0.6873643296316636
Epoch: 46 | Iteration number: [1220/4518] 27% | Training loss: 0.6873503418242345
Epoch: 46 | Iteration number: [1230/4518] 27% | Training loss: 0.6873357755866477
Epoch: 46 | Iteration number: [1240/4518] 27% | Training loss: 0.687333679247287
Epoch: 46 | Iteration number: [1250/4518] 27% | Training loss: 0.6873294954299927
Epoch: 46 | Iteration number: [1260/4518] 27% | Training loss: 0.6873190659852255
Epoch: 46 | Iteration number: [1270/4518] 28% | Training loss: 0.687310614360599
Epoch: 46 | Iteration number: [1280/4518] 28% | Training loss: 0.6873107245191932
Epoch: 46 | Iteration number: [1290/4518] 28% | Training loss: 0.687301004579825
Epoch: 46 | Iteration number: [1300/4518] 28% | Training loss: 0.6873042044272789
Epoch: 46 | Iteration number: [1310/4518] 28% | Training loss: 0.6873072542762029
Epoch: 46 | Iteration number: [1320/4518] 29% | Training loss: 0.687294352054596
Epoch: 46 | Iteration number: [1330/4518] 29% | Training loss: 0.6872936117917972
Epoch: 46 | Iteration number: [1340/4518] 29% | Training loss: 0.6872914341403478
Epoch: 46 | Iteration number: [1350/4518] 29% | Training loss: 0.6872931032710605
Epoch: 46 | Iteration number: [1360/4518] 30% | Training loss: 0.6872722414924818
Epoch: 46 | Iteration number: [1370/4518] 30% | Training loss: 0.6872687700021006
Epoch: 46 | Iteration number: [1380/4518] 30% | Training loss: 0.6872694667266763
Epoch: 46 | Iteration number: [1390/4518] 30% | Training loss: 0.6872595751885887
Epoch: 46 | Iteration number: [1400/4518] 30% | Training loss: 0.6872591909766197
Epoch: 46 | Iteration number: [1410/4518] 31% | Training loss: 0.6872601616467144
Epoch: 46 | Iteration number: [1420/4518] 31% | Training loss: 0.6872559626337508
Epoch: 46 | Iteration number: [1430/4518] 31% | Training loss: 0.6872551542062025
Epoch: 46 | Iteration number: [1440/4518] 31% | Training loss: 0.6872564809189903
Epoch: 46 | Iteration number: [1450/4518] 32% | Training loss: 0.687249983795758
Epoch: 46 | Iteration number: [1460/4518] 32% | Training loss: 0.6872454074964132
Epoch: 46 | Iteration number: [1470/4518] 32% | Training loss: 0.6872406171698149
Epoch: 46 | Iteration number: [1480/4518] 32% | Training loss: 0.687241769118889
Epoch: 46 | Iteration number: [1490/4518] 32% | Training loss: 0.6872406445893665
Epoch: 46 | Iteration number: [1500/4518] 33% | Training loss: 0.6872452178796132
Epoch: 46 | Iteration number: [1510/4518] 33% | Training loss: 0.6872447163853425
Epoch: 46 | Iteration number: [1520/4518] 33% | Training loss: 0.6872544908601986
Epoch: 46 | Iteration number: [1530/4518] 33% | Training loss: 0.6872446025508682
Epoch: 46 | Iteration number: [1540/4518] 34% | Training loss: 0.6872448502422928
Epoch: 46 | Iteration number: [1550/4518] 34% | Training loss: 0.6872425699618555
Epoch: 46 | Iteration number: [1560/4518] 34% | Training loss: 0.6872371200567636
Epoch: 46 | Iteration number: [1570/4518] 34% | Training loss: 0.6872363186945581
Epoch: 46 | Iteration number: [1580/4518] 34% | Training loss: 0.6872361631333074
Epoch: 46 | Iteration number: [1590/4518] 35% | Training loss: 0.6872287752493372
Epoch: 46 | Iteration number: [1600/4518] 35% | Training loss: 0.6872219435498118
Epoch: 46 | Iteration number: [1610/4518] 35% | Training loss: 0.6872246075861203
Epoch: 46 | Iteration number: [1620/4518] 35% | Training loss: 0.6872206217344896
Epoch: 46 | Iteration number: [1630/4518] 36% | Training loss: 0.6872256801172268
Epoch: 46 | Iteration number: [1640/4518] 36% | Training loss: 0.6872275098067958
Epoch: 46 | Iteration number: [1650/4518] 36% | Training loss: 0.6872140417315743
Epoch: 46 | Iteration number: [1660/4518] 36% | Training loss: 0.6872064799788486
Epoch: 46 | Iteration number: [1670/4518] 36% | Training loss: 0.6872085623755426
Epoch: 46 | Iteration number: [1680/4518] 37% | Training loss: 0.6872055523452305
Epoch: 46 | Iteration number: [1690/4518] 37% | Training loss: 0.687198161338208
Epoch: 46 | Iteration number: [1700/4518] 37% | Training loss: 0.6871973308745553
Epoch: 46 | Iteration number: [1710/4518] 37% | Training loss: 0.6871960132791285
Epoch: 46 | Iteration number: [1720/4518] 38% | Training loss: 0.6872006200427233
Epoch: 46 | Iteration number: [1730/4518] 38% | Training loss: 0.6871962835678476
Epoch: 46 | Iteration number: [1740/4518] 38% | Training loss: 0.6871902516175961
Epoch: 46 | Iteration number: [1750/4518] 38% | Training loss: 0.6871945398535048
Epoch: 46 | Iteration number: [1760/4518] 38% | Training loss: 0.6871923045339909
Epoch: 46 | Iteration number: [1770/4518] 39% | Training loss: 0.6871829109676814
Epoch: 46 | Iteration number: [1780/4518] 39% | Training loss: 0.687185949221086
Epoch: 46 | Iteration number: [1790/4518] 39% | Training loss: 0.6871855704811032
Epoch: 46 | Iteration number: [1800/4518] 39% | Training loss: 0.6871821787291102
Epoch: 46 | Iteration number: [1810/4518] 40% | Training loss: 0.6871824731154995
Epoch: 46 | Iteration number: [1820/4518] 40% | Training loss: 0.687177441572095
Epoch: 46 | Iteration number: [1830/4518] 40% | Training loss: 0.6871707903882844
Epoch: 46 | Iteration number: [1840/4518] 40% | Training loss: 0.6871652741795001
Epoch: 46 | Iteration number: [1850/4518] 40% | Training loss: 0.6871585204472412
Epoch: 46 | Iteration number: [1860/4518] 41% | Training loss: 0.6871596267146449
Epoch: 46 | Iteration number: [1870/4518] 41% | Training loss: 0.6871598628115526
Epoch: 46 | Iteration number: [1880/4518] 41% | Training loss: 0.6871516787625374
Epoch: 46 | Iteration number: [1890/4518] 41% | Training loss: 0.6871511361586353
Epoch: 46 | Iteration number: [1900/4518] 42% | Training loss: 0.6871471912923612
Epoch: 46 | Iteration number: [1910/4518] 42% | Training loss: 0.6871442859709574
Epoch: 46 | Iteration number: [1920/4518] 42% | Training loss: 0.6871415150351823
Epoch: 46 | Iteration number: [1930/4518] 42% | Training loss: 0.6871412413107917
Epoch: 46 | Iteration number: [1940/4518] 42% | Training loss: 0.6871393867681936
Epoch: 46 | Iteration number: [1950/4518] 43% | Training loss: 0.6871381124166341
Epoch: 46 | Iteration number: [1960/4518] 43% | Training loss: 0.6871360120420553
Epoch: 46 | Iteration number: [1970/4518] 43% | Training loss: 0.6871351845978481
Epoch: 46 | Iteration number: [1980/4518] 43% | Training loss: 0.687136272107712
Epoch: 46 | Iteration number: [1990/4518] 44% | Training loss: 0.687126483509888
Epoch: 46 | Iteration number: [2000/4518] 44% | Training loss: 0.6871288990974427
Epoch: 46 | Iteration number: [2010/4518] 44% | Training loss: 0.6871231610798717
Epoch: 46 | Iteration number: [2020/4518] 44% | Training loss: 0.687126408266549
Epoch: 46 | Iteration number: [2030/4518] 44% | Training loss: 0.6871231949975338
Epoch: 46 | Iteration number: [2040/4518] 45% | Training loss: 0.6871230538277066
Epoch: 46 | Iteration number: [2050/4518] 45% | Training loss: 0.6871195528856138
Epoch: 46 | Iteration number: [2060/4518] 45% | Training loss: 0.6871186908298326
Epoch: 46 | Iteration number: [2070/4518] 45% | Training loss: 0.6871113295716365
Epoch: 46 | Iteration number: [2080/4518] 46% | Training loss: 0.6871191848929111
Epoch: 46 | Iteration number: [2090/4518] 46% | Training loss: 0.6871153632419531
Epoch: 46 | Iteration number: [2100/4518] 46% | Training loss: 0.6871143645048141
Epoch: 46 | Iteration number: [2110/4518] 46% | Training loss: 0.6871105058215806
Epoch: 46 | Iteration number: [2120/4518] 46% | Training loss: 0.6871063525103173
Epoch: 46 | Iteration number: [2130/4518] 47% | Training loss: 0.6871073335828916
Epoch: 46 | Iteration number: [2140/4518] 47% | Training loss: 0.6871054186442188
Epoch: 46 | Iteration number: [2150/4518] 47% | Training loss: 0.6870987469650979
Epoch: 46 | Iteration number: [2160/4518] 47% | Training loss: 0.6870988369539932
Epoch: 46 | Iteration number: [2170/4518] 48% | Training loss: 0.6870937701743869
Epoch: 46 | Iteration number: [2180/4518] 48% | Training loss: 0.6870912145310586
Epoch: 46 | Iteration number: [2190/4518] 48% | Training loss: 0.6870885590712229
Epoch: 46 | Iteration number: [2200/4518] 48% | Training loss: 0.6870906951752576
Epoch: 46 | Iteration number: [2210/4518] 48% | Training loss: 0.687089461115151
Epoch: 46 | Iteration number: [2220/4518] 49% | Training loss: 0.6870916950810063
Epoch: 46 | Iteration number: [2230/4518] 49% | Training loss: 0.6870879613765152
Epoch: 46 | Iteration number: [2240/4518] 49% | Training loss: 0.6870863255645547
Epoch: 46 | Iteration number: [2250/4518] 49% | Training loss: 0.6870826097859276
Epoch: 46 | Iteration number: [2260/4518] 50% | Training loss: 0.6870760018055417
Epoch: 46 | Iteration number: [2270/4518] 50% | Training loss: 0.6870746901381909
Epoch: 46 | Iteration number: [2280/4518] 50% | Training loss: 0.687072858057524
Epoch: 46 | Iteration number: [2290/4518] 50% | Training loss: 0.6870750039946044
Epoch: 46 | Iteration number: [2300/4518] 50% | Training loss: 0.6870763958018758
Epoch: 46 | Iteration number: [2310/4518] 51% | Training loss: 0.6870739140035786
Epoch: 46 | Iteration number: [2320/4518] 51% | Training loss: 0.6870707945833946
Epoch: 46 | Iteration number: [2330/4518] 51% | Training loss: 0.6870696419554206
Epoch: 46 | Iteration number: [2340/4518] 51% | Training loss: 0.6870682097398317
Epoch: 46 | Iteration number: [2350/4518] 52% | Training loss: 0.6870667084988127
Epoch: 46 | Iteration number: [2360/4518] 52% | Training loss: 0.687072029583535
Epoch: 46 | Iteration number: [2370/4518] 52% | Training loss: 0.6870729696650042
Epoch: 46 | Iteration number: [2380/4518] 52% | Training loss: 0.6870693732960885
Epoch: 46 | Iteration number: [2390/4518] 52% | Training loss: 0.6870704112192577
Epoch: 46 | Iteration number: [2400/4518] 53% | Training loss: 0.6870653921862443
Epoch: 46 | Iteration number: [2410/4518] 53% | Training loss: 0.6870597076613874
Epoch: 46 | Iteration number: [2420/4518] 53% | Training loss: 0.6870624256528114
Epoch: 46 | Iteration number: [2430/4518] 53% | Training loss: 0.687062757348818
Epoch: 46 | Iteration number: [2440/4518] 54% | Training loss: 0.6870657859034226
Epoch: 46 | Iteration number: [2450/4518] 54% | Training loss: 0.6870651101092903
Epoch: 46 | Iteration number: [2460/4518] 54% | Training loss: 0.687066339840734
Epoch: 46 | Iteration number: [2470/4518] 54% | Training loss: 0.6870706820294925
Epoch: 46 | Iteration number: [2480/4518] 54% | Training loss: 0.6870772329789977
Epoch: 46 | Iteration number: [2490/4518] 55% | Training loss: 0.6870765142412071
Epoch: 46 | Iteration number: [2500/4518] 55% | Training loss: 0.6870799235105515
Epoch: 46 | Iteration number: [2510/4518] 55% | Training loss: 0.6870779207503178
Epoch: 46 | Iteration number: [2520/4518] 55% | Training loss: 0.687080644922597
Epoch: 46 | Iteration number: [2530/4518] 55% | Training loss: 0.6870762487880797
Epoch: 46 | Iteration number: [2540/4518] 56% | Training loss: 0.6870742634994778
Epoch: 46 | Iteration number: [2550/4518] 56% | Training loss: 0.6870688967143788
Epoch: 46 | Iteration number: [2560/4518] 56% | Training loss: 0.687064858735539
Epoch: 46 | Iteration number: [2570/4518] 56% | Training loss: 0.6870662439426095
Epoch: 46 | Iteration number: [2580/4518] 57% | Training loss: 0.6870656662209089
Epoch: 46 | Iteration number: [2590/4518] 57% | Training loss: 0.6870674509109217
Epoch: 46 | Iteration number: [2600/4518] 57% | Training loss: 0.687067456314197
Epoch: 46 | Iteration number: [2610/4518] 57% | Training loss: 0.687069338263223
Epoch: 46 | Iteration number: [2620/4518] 57% | Training loss: 0.6870707390872577
Epoch: 46 | Iteration number: [2630/4518] 58% | Training loss: 0.6870699005435175
Epoch: 46 | Iteration number: [2640/4518] 58% | Training loss: 0.6870655966979085
Epoch: 46 | Iteration number: [2650/4518] 58% | Training loss: 0.6870679972081815
Epoch: 46 | Iteration number: [2660/4518] 58% | Training loss: 0.6870643109083175
Epoch: 46 | Iteration number: [2670/4518] 59% | Training loss: 0.6870580124274622
Epoch: 46 | Iteration number: [2680/4518] 59% | Training loss: 0.6870548171116345
Epoch: 46 | Iteration number: [2690/4518] 59% | Training loss: 0.6870535483147575
Epoch: 46 | Iteration number: [2700/4518] 59% | Training loss: 0.6870510870218277
Epoch: 46 | Iteration number: [2710/4518] 59% | Training loss: 0.6870456953990064
Epoch: 46 | Iteration number: [2720/4518] 60% | Training loss: 0.6870421885129283
Epoch: 46 | Iteration number: [2730/4518] 60% | Training loss: 0.6870422885749803
Epoch: 46 | Iteration number: [2740/4518] 60% | Training loss: 0.6870404088584176
Epoch: 46 | Iteration number: [2750/4518] 60% | Training loss: 0.6870413005135276
Epoch: 46 | Iteration number: [2760/4518] 61% | Training loss: 0.6870407543968463
Epoch: 46 | Iteration number: [2770/4518] 61% | Training loss: 0.6870410805359645
Epoch: 46 | Iteration number: [2780/4518] 61% | Training loss: 0.6870380820130273
Epoch: 46 | Iteration number: [2790/4518] 61% | Training loss: 0.6870371230186955
Epoch: 46 | Iteration number: [2800/4518] 61% | Training loss: 0.687036431240184
Epoch: 46 | Iteration number: [2810/4518] 62% | Training loss: 0.6870372885486834
Epoch: 46 | Iteration number: [2820/4518] 62% | Training loss: 0.6870390375243857
Epoch: 46 | Iteration number: [2830/4518] 62% | Training loss: 0.6870349102854307
Epoch: 46 | Iteration number: [2840/4518] 62% | Training loss: 0.6870312066145347
Epoch: 46 | Iteration number: [2850/4518] 63% | Training loss: 0.6870312356948852
Epoch: 46 | Iteration number: [2860/4518] 63% | Training loss: 0.6870272573057589
Epoch: 46 | Iteration number: [2870/4518] 63% | Training loss: 0.6870254702476675
Epoch: 46 | Iteration number: [2880/4518] 63% | Training loss: 0.687025961631702
Epoch: 46 | Iteration number: [2890/4518] 63% | Training loss: 0.6870231340706967
Epoch: 46 | Iteration number: [2900/4518] 64% | Training loss: 0.68702558671606
Epoch: 46 | Iteration number: [2910/4518] 64% | Training loss: 0.687027348439718
Epoch: 46 | Iteration number: [2920/4518] 64% | Training loss: 0.6870290459427115
Epoch: 46 | Iteration number: [2930/4518] 64% | Training loss: 0.6870211376265047
Epoch: 46 | Iteration number: [2940/4518] 65% | Training loss: 0.6870236117823594
Epoch: 46 | Iteration number: [2950/4518] 65% | Training loss: 0.687017468840389
Epoch: 46 | Iteration number: [2960/4518] 65% | Training loss: 0.6870163814642944
Epoch: 46 | Iteration number: [2970/4518] 65% | Training loss: 0.6870148186330443
Epoch: 46 | Iteration number: [2980/4518] 65% | Training loss: 0.6870167207797901
Epoch: 46 | Iteration number: [2990/4518] 66% | Training loss: 0.6870155837424224
Epoch: 46 | Iteration number: [3000/4518] 66% | Training loss: 0.6870176187554995
Epoch: 46 | Iteration number: [3010/4518] 66% | Training loss: 0.6870179392768695
Epoch: 46 | Iteration number: [3020/4518] 66% | Training loss: 0.687014262723607
Epoch: 46 | Iteration number: [3030/4518] 67% | Training loss: 0.6870121769779193
Epoch: 46 | Iteration number: [3040/4518] 67% | Training loss: 0.6870120514184237
Epoch: 46 | Iteration number: [3050/4518] 67% | Training loss: 0.6870124848944242
Epoch: 46 | Iteration number: [3060/4518] 67% | Training loss: 0.6870125154264612
Epoch: 46 | Iteration number: [3070/4518] 67% | Training loss: 0.6870132554819995
Epoch: 46 | Iteration number: [3080/4518] 68% | Training loss: 0.6870148438137847
Epoch: 46 | Iteration number: [3090/4518] 68% | Training loss: 0.6870142650449932
Epoch: 46 | Iteration number: [3100/4518] 68% | Training loss: 0.6870141719233606
Epoch: 46 | Iteration number: [3110/4518] 68% | Training loss: 0.6870134975557541
Epoch: 46 | Iteration number: [3120/4518] 69% | Training loss: 0.687014894015514
Epoch: 46 | Iteration number: [3130/4518] 69% | Training loss: 0.68701485265939
Epoch: 46 | Iteration number: [3140/4518] 69% | Training loss: 0.6870125105046923
Epoch: 46 | Iteration number: [3150/4518] 69% | Training loss: 0.6870150455406734
Epoch: 46 | Iteration number: [3160/4518] 69% | Training loss: 0.6870140479335302
Epoch: 46 | Iteration number: [3170/4518] 70% | Training loss: 0.6870134971119252
Epoch: 46 | Iteration number: [3180/4518] 70% | Training loss: 0.6870102434225802
Epoch: 46 | Iteration number: [3190/4518] 70% | Training loss: 0.687011495540882
Epoch: 46 | Iteration number: [3200/4518] 70% | Training loss: 0.6870084109529853
Epoch: 46 | Iteration number: [3210/4518] 71% | Training loss: 0.6870032773025311
Epoch: 46 | Iteration number: [3220/4518] 71% | Training loss: 0.6870060758190866
Epoch: 46 | Iteration number: [3230/4518] 71% | Training loss: 0.6870084849304459
Epoch: 46 | Iteration number: [3240/4518] 71% | Training loss: 0.6870088605417146
Epoch: 46 | Iteration number: [3250/4518] 71% | Training loss: 0.6870057456309979
Epoch: 46 | Iteration number: [3260/4518] 72% | Training loss: 0.687006887245032
Epoch: 46 | Iteration number: [3270/4518] 72% | Training loss: 0.687006576418512
Epoch: 46 | Iteration number: [3280/4518] 72% | Training loss: 0.6870059087690784
Epoch: 46 | Iteration number: [3290/4518] 72% | Training loss: 0.6870085660809804
Epoch: 46 | Iteration number: [3300/4518] 73% | Training loss: 0.6870068941694317
Epoch: 46 | Iteration number: [3310/4518] 73% | Training loss: 0.6870073424725374
Epoch: 46 | Iteration number: [3320/4518] 73% | Training loss: 0.6870085681238807
Epoch: 46 | Iteration number: [3330/4518] 73% | Training loss: 0.6870110469358461
Epoch: 46 | Iteration number: [3340/4518] 73% | Training loss: 0.6870170334855953
Epoch: 46 | Iteration number: [3350/4518] 74% | Training loss: 0.6870147137499567
Epoch: 46 | Iteration number: [3360/4518] 74% | Training loss: 0.687010479168523
Epoch: 46 | Iteration number: [3370/4518] 74% | Training loss: 0.6870089088243264
Epoch: 46 | Iteration number: [3380/4518] 74% | Training loss: 0.6870046360429222
Epoch: 46 | Iteration number: [3390/4518] 75% | Training loss: 0.687004630175312
Epoch: 46 | Iteration number: [3400/4518] 75% | Training loss: 0.6870013473314397
Epoch: 46 | Iteration number: [3410/4518] 75% | Training loss: 0.6870036555350352
Epoch: 46 | Iteration number: [3420/4518] 75% | Training loss: 0.6870012237663158
Epoch: 46 | Iteration number: [3430/4518] 75% | Training loss: 0.6869982946544625
Epoch: 46 | Iteration number: [3440/4518] 76% | Training loss: 0.6869995152014633
Epoch: 46 | Iteration number: [3450/4518] 76% | Training loss: 0.68699789783229
Epoch: 46 | Iteration number: [3460/4518] 76% | Training loss: 0.6869987048854718
Epoch: 46 | Iteration number: [3470/4518] 76% | Training loss: 0.6869983235078861
Epoch: 46 | Iteration number: [3480/4518] 77% | Training loss: 0.686994510615009
Epoch: 46 | Iteration number: [3490/4518] 77% | Training loss: 0.6869999124532443
Epoch: 46 | Iteration number: [3500/4518] 77% | Training loss: 0.687000103371484
Epoch: 46 | Iteration number: [3510/4518] 77% | Training loss: 0.687005536016236
Epoch: 46 | Iteration number: [3520/4518] 77% | Training loss: 0.6870015838776122
Epoch: 46 | Iteration number: [3530/4518] 78% | Training loss: 0.687002122385306
Epoch: 46 | Iteration number: [3540/4518] 78% | Training loss: 0.6870006987604044
Epoch: 46 | Iteration number: [3550/4518] 78% | Training loss: 0.687000489503565
Epoch: 46 | Iteration number: [3560/4518] 78% | Training loss: 0.6870017903072111
Epoch: 46 | Iteration number: [3570/4518] 79% | Training loss: 0.6870014709918772
Epoch: 46 | Iteration number: [3580/4518] 79% | Training loss: 0.6870039805187194
Epoch: 46 | Iteration number: [3590/4518] 79% | Training loss: 0.6870052441581046
Epoch: 46 | Iteration number: [3600/4518] 79% | Training loss: 0.6870051067570845
Epoch: 46 | Iteration number: [3610/4518] 79% | Training loss: 0.6870034675684001
Epoch: 46 | Iteration number: [3620/4518] 80% | Training loss: 0.687003281004521
Epoch: 46 | Iteration number: [3630/4518] 80% | Training loss: 0.6870037570800992
Epoch: 46 | Iteration number: [3640/4518] 80% | Training loss: 0.687000057887245
Epoch: 46 | Iteration number: [3650/4518] 80% | Training loss: 0.6869986197393234
Epoch: 46 | Iteration number: [3660/4518] 81% | Training loss: 0.6870021317500234
Epoch: 46 | Iteration number: [3670/4518] 81% | Training loss: 0.6869991998581535
Epoch: 46 | Iteration number: [3680/4518] 81% | Training loss: 0.6870017193257809
Epoch: 46 | Iteration number: [3690/4518] 81% | Training loss: 0.6870003787321127
Epoch: 46 | Iteration number: [3700/4518] 81% | Training loss: 0.6870019903376295
Epoch: 46 | Iteration number: [3710/4518] 82% | Training loss: 0.6870006922281013
Epoch: 46 | Iteration number: [3720/4518] 82% | Training loss: 0.6870011568229686
Epoch: 46 | Iteration number: [3730/4518] 82% | Training loss: 0.6869987491787918
Epoch: 46 | Iteration number: [3740/4518] 82% | Training loss: 0.6870002480114208
Epoch: 46 | Iteration number: [3750/4518] 83% | Training loss: 0.6870019802570343
Epoch: 46 | Iteration number: [3760/4518] 83% | Training loss: 0.6870027183852297
Epoch: 46 | Iteration number: [3770/4518] 83% | Training loss: 0.6870007162543127
Epoch: 46 | Iteration number: [3780/4518] 83% | Training loss: 0.687001034917024
Epoch: 46 | Iteration number: [3790/4518] 83% | Training loss: 0.6870019932063715
Epoch: 46 | Iteration number: [3800/4518] 84% | Training loss: 0.6870038846919411
Epoch: 46 | Iteration number: [3810/4518] 84% | Training loss: 0.6870048435341342
Epoch: 46 | Iteration number: [3820/4518] 84% | Training loss: 0.6870022806353594
Epoch: 46 | Iteration number: [3830/4518] 84% | Training loss: 0.6870025415333382
Epoch: 46 | Iteration number: [3840/4518] 84% | Training loss: 0.6870013573362181
Epoch: 46 | Iteration number: [3850/4518] 85% | Training loss: 0.6869994917937687
Epoch: 46 | Iteration number: [3860/4518] 85% | Training loss: 0.6869992608387854
Epoch: 46 | Iteration number: [3870/4518] 85% | Training loss: 0.6870004161999823
Epoch: 46 | Iteration number: [3880/4518] 85% | Training loss: 0.6870011656708324
Epoch: 46 | Iteration number: [3890/4518] 86% | Training loss: 0.6869989897260935
Epoch: 46 | Iteration number: [3900/4518] 86% | Training loss: 0.6869970913728078
Epoch: 46 | Iteration number: [3910/4518] 86% | Training loss: 0.6869938562593192
Epoch: 46 | Iteration number: [3920/4518] 86% | Training loss: 0.6869896768155147
Epoch: 46 | Iteration number: [3930/4518] 86% | Training loss: 0.6869898148620401
Epoch: 46 | Iteration number: [3940/4518] 87% | Training loss: 0.6869911745568823
Epoch: 46 | Iteration number: [3950/4518] 87% | Training loss: 0.6869902899295469
Epoch: 46 | Iteration number: [3960/4518] 87% | Training loss: 0.6869915318910522
Epoch: 46 | Iteration number: [3970/4518] 87% | Training loss: 0.6869913499961873
Epoch: 46 | Iteration number: [3980/4518] 88% | Training loss: 0.6869888931363072
Epoch: 46 | Iteration number: [3990/4518] 88% | Training loss: 0.6869900383596731
Epoch: 46 | Iteration number: [4000/4518] 88% | Training loss: 0.6869911944270134
Epoch: 46 | Iteration number: [4010/4518] 88% | Training loss: 0.6869883481403836
Epoch: 46 | Iteration number: [4020/4518] 88% | Training loss: 0.6869878736004901
Epoch: 46 | Iteration number: [4030/4518] 89% | Training loss: 0.6869862284317206
Epoch: 46 | Iteration number: [4040/4518] 89% | Training loss: 0.6869858485489788
Epoch: 46 | Iteration number: [4050/4518] 89% | Training loss: 0.6869869575529922
Epoch: 46 | Iteration number: [4060/4518] 89% | Training loss: 0.686984455541437
Epoch: 46 | Iteration number: [4070/4518] 90% | Training loss: 0.686981743749881
Epoch: 46 | Iteration number: [4080/4518] 90% | Training loss: 0.6869811370968819
Epoch: 46 | Iteration number: [4090/4518] 90% | Training loss: 0.6869824715377649
Epoch: 46 | Iteration number: [4100/4518] 90% | Training loss: 0.6869821518804969
Epoch: 46 | Iteration number: [4110/4518] 90% | Training loss: 0.6869821492047785
Epoch: 46 | Iteration number: [4120/4518] 91% | Training loss: 0.6869786330507797
Epoch: 46 | Iteration number: [4130/4518] 91% | Training loss: 0.6869764639736665
Epoch: 46 | Iteration number: [4140/4518] 91% | Training loss: 0.6869773661168878
Epoch: 46 | Iteration number: [4150/4518] 91% | Training loss: 0.6869774568942656
Epoch: 46 | Iteration number: [4160/4518] 92% | Training loss: 0.6869713302415151
Epoch: 46 | Iteration number: [4170/4518] 92% | Training loss: 0.6869705034531564
Epoch: 46 | Iteration number: [4180/4518] 92% | Training loss: 0.6869685759955045
Epoch: 46 | Iteration number: [4190/4518] 92% | Training loss: 0.6869716469456302
Epoch: 46 | Iteration number: [4200/4518] 92% | Training loss: 0.6869713964916411
Epoch: 46 | Iteration number: [4210/4518] 93% | Training loss: 0.6869714040229553
Epoch: 46 | Iteration number: [4220/4518] 93% | Training loss: 0.6869740581766689
Epoch: 46 | Iteration number: [4230/4518] 93% | Training loss: 0.6869741603696882
Epoch: 46 | Iteration number: [4240/4518] 93% | Training loss: 0.6869752878569207
Epoch: 46 | Iteration number: [4250/4518] 94% | Training loss: 0.6869780309761272
Epoch: 46 | Iteration number: [4260/4518] 94% | Training loss: 0.6869768245119444
Epoch: 46 | Iteration number: [4270/4518] 94% | Training loss: 0.6869773715245919
Epoch: 46 | Iteration number: [4280/4518] 94% | Training loss: 0.6869751948201768
Epoch: 46 | Iteration number: [4290/4518] 94% | Training loss: 0.6869729530422282
Epoch: 46 | Iteration number: [4300/4518] 95% | Training loss: 0.6869733762879704
Epoch: 46 | Iteration number: [4310/4518] 95% | Training loss: 0.6869721705288455
Epoch: 46 | Iteration number: [4320/4518] 95% | Training loss: 0.6869735710874751
Epoch: 46 | Iteration number: [4330/4518] 95% | Training loss: 0.6869750319534856
Epoch: 46 | Iteration number: [4340/4518] 96% | Training loss: 0.6869723804260729
Epoch: 46 | Iteration number: [4350/4518] 96% | Training loss: 0.6869728097285347
Epoch: 46 | Iteration number: [4360/4518] 96% | Training loss: 0.6869692634278481
Epoch: 46 | Iteration number: [4370/4518] 96% | Training loss: 0.6869707251440742
Epoch: 46 | Iteration number: [4380/4518] 96% | Training loss: 0.6869698046957521
Epoch: 46 | Iteration number: [4390/4518] 97% | Training loss: 0.6869690220013838
Epoch: 46 | Iteration number: [4400/4518] 97% | Training loss: 0.6869701482355595
Epoch: 46 | Iteration number: [4410/4518] 97% | Training loss: 0.6869699161609555
Epoch: 46 | Iteration number: [4420/4518] 97% | Training loss: 0.6869689248535967
Epoch: 46 | Iteration number: [4430/4518] 98% | Training loss: 0.6869673249145662
Epoch: 46 | Iteration number: [4440/4518] 98% | Training loss: 0.686965643339329
Epoch: 46 | Iteration number: [4450/4518] 98% | Training loss: 0.686967965752891
Epoch: 46 | Iteration number: [4460/4518] 98% | Training loss: 0.6869707337008464
Epoch: 46 | Iteration number: [4470/4518] 98% | Training loss: 0.6869695794795717
Epoch: 46 | Iteration number: [4480/4518] 99% | Training loss: 0.686971317644098
Epoch: 46 | Iteration number: [4490/4518] 99% | Training loss: 0.6869678278808339
Epoch: 46 | Iteration number: [4500/4518] 99% | Training loss: 0.6869659598271052
Epoch: 46 | Iteration number: [4510/4518] 99% | Training loss: 0.6869658568085165

 End of epoch: 46 | Train Loss: 0.6868141123339792 | Training Time: 632 

 End of epoch: 46 | Eval Loss: 0.6897802316412633 | Evaluating Time: 17 
Epoch: 47 | Iteration number: [10/4518] 0% | Training loss: 0.7571888566017151
Epoch: 47 | Iteration number: [20/4518] 0% | Training loss: 0.7219687283039093
Epoch: 47 | Iteration number: [30/4518] 0% | Training loss: 0.7100127677122752
Epoch: 47 | Iteration number: [40/4518] 0% | Training loss: 0.7041287750005722
Epoch: 47 | Iteration number: [50/4518] 1% | Training loss: 0.7008149147033691
Epoch: 47 | Iteration number: [60/4518] 1% | Training loss: 0.6981696943442027
Epoch: 47 | Iteration number: [70/4518] 1% | Training loss: 0.6966562441417149
Epoch: 47 | Iteration number: [80/4518] 1% | Training loss: 0.6953787796199322
Epoch: 47 | Iteration number: [90/4518] 1% | Training loss: 0.6944314645396339
Epoch: 47 | Iteration number: [100/4518] 2% | Training loss: 0.693582975268364
Epoch: 47 | Iteration number: [110/4518] 2% | Training loss: 0.6929705522277139
Epoch: 47 | Iteration number: [120/4518] 2% | Training loss: 0.6923802455266317
Epoch: 47 | Iteration number: [130/4518] 2% | Training loss: 0.6920347718092111
Epoch: 47 | Iteration number: [140/4518] 3% | Training loss: 0.6915924246822085
Epoch: 47 | Iteration number: [150/4518] 3% | Training loss: 0.6913359737396241
Epoch: 47 | Iteration number: [160/4518] 3% | Training loss: 0.6909710988402367
Epoch: 47 | Iteration number: [170/4518] 3% | Training loss: 0.6906413358800552
Epoch: 47 | Iteration number: [180/4518] 3% | Training loss: 0.6904242111576928
Epoch: 47 | Iteration number: [190/4518] 4% | Training loss: 0.6902265762027942
Epoch: 47 | Iteration number: [200/4518] 4% | Training loss: 0.6900467553734779
Epoch: 47 | Iteration number: [210/4518] 4% | Training loss: 0.6899101461683
Epoch: 47 | Iteration number: [220/4518] 4% | Training loss: 0.6897632132877003
Epoch: 47 | Iteration number: [230/4518] 5% | Training loss: 0.6896000071712162
Epoch: 47 | Iteration number: [240/4518] 5% | Training loss: 0.6894930258393288
Epoch: 47 | Iteration number: [250/4518] 5% | Training loss: 0.6893676166534424
Epoch: 47 | Iteration number: [260/4518] 5% | Training loss: 0.6892713688887082
Epoch: 47 | Iteration number: [270/4518] 5% | Training loss: 0.689205593974502
Epoch: 47 | Iteration number: [280/4518] 6% | Training loss: 0.6891024146761213
Epoch: 47 | Iteration number: [290/4518] 6% | Training loss: 0.689030762787523
Epoch: 47 | Iteration number: [300/4518] 6% | Training loss: 0.6889910380045573
Epoch: 47 | Iteration number: [310/4518] 6% | Training loss: 0.6888753414154053
Epoch: 47 | Iteration number: [320/4518] 7% | Training loss: 0.688813385181129
Epoch: 47 | Iteration number: [330/4518] 7% | Training loss: 0.6887257037740765
Epoch: 47 | Iteration number: [340/4518] 7% | Training loss: 0.6886683884788962
Epoch: 47 | Iteration number: [350/4518] 7% | Training loss: 0.688658172573362
Epoch: 47 | Iteration number: [360/4518] 7% | Training loss: 0.6885904146565331
Epoch: 47 | Iteration number: [370/4518] 8% | Training loss: 0.6885306155359423
Epoch: 47 | Iteration number: [380/4518] 8% | Training loss: 0.6884912018713198
Epoch: 47 | Iteration number: [390/4518] 8% | Training loss: 0.6884486863246331
Epoch: 47 | Iteration number: [400/4518] 8% | Training loss: 0.6884205220639705
Epoch: 47 | Iteration number: [410/4518] 9% | Training loss: 0.688376970843571
Epoch: 47 | Iteration number: [420/4518] 9% | Training loss: 0.688337898680142
Epoch: 47 | Iteration number: [430/4518] 9% | Training loss: 0.688315734197927
Epoch: 47 | Iteration number: [440/4518] 9% | Training loss: 0.6882924883203073
Epoch: 47 | Iteration number: [450/4518] 9% | Training loss: 0.6882695659001669
Epoch: 47 | Iteration number: [460/4518] 10% | Training loss: 0.6882494958846466
Epoch: 47 | Iteration number: [470/4518] 10% | Training loss: 0.6882224088019513
Epoch: 47 | Iteration number: [480/4518] 10% | Training loss: 0.6881779576341311
Epoch: 47 | Iteration number: [490/4518] 10% | Training loss: 0.6881330484030198
Epoch: 47 | Iteration number: [500/4518] 11% | Training loss: 0.6881004687547684
Epoch: 47 | Iteration number: [510/4518] 11% | Training loss: 0.6880683182501326
Epoch: 47 | Iteration number: [520/4518] 11% | Training loss: 0.688031335060413
Epoch: 47 | Iteration number: [530/4518] 11% | Training loss: 0.6880080043144946
Epoch: 47 | Iteration number: [540/4518] 11% | Training loss: 0.6879871100187301
Epoch: 47 | Iteration number: [550/4518] 12% | Training loss: 0.6879786679961465
Epoch: 47 | Iteration number: [560/4518] 12% | Training loss: 0.6879534831004483
Epoch: 47 | Iteration number: [570/4518] 12% | Training loss: 0.6879330838981428
Epoch: 47 | Iteration number: [580/4518] 12% | Training loss: 0.6879167681110316
Epoch: 47 | Iteration number: [590/4518] 13% | Training loss: 0.6878899772288436
Epoch: 47 | Iteration number: [600/4518] 13% | Training loss: 0.6878894515832266
Epoch: 47 | Iteration number: [610/4518] 13% | Training loss: 0.6878856340392692
Epoch: 47 | Iteration number: [620/4518] 13% | Training loss: 0.6878764455356906
Epoch: 47 | Iteration number: [630/4518] 13% | Training loss: 0.6878420138169848
Epoch: 47 | Iteration number: [640/4518] 14% | Training loss: 0.6878281163983047
Epoch: 47 | Iteration number: [650/4518] 14% | Training loss: 0.6877975459282215
Epoch: 47 | Iteration number: [660/4518] 14% | Training loss: 0.6877691419738712
Epoch: 47 | Iteration number: [670/4518] 14% | Training loss: 0.6877331346718233
Epoch: 47 | Iteration number: [680/4518] 15% | Training loss: 0.6877199421910679
Epoch: 47 | Iteration number: [690/4518] 15% | Training loss: 0.6877063000547713
Epoch: 47 | Iteration number: [700/4518] 15% | Training loss: 0.6876780083349773
Epoch: 47 | Iteration number: [710/4518] 15% | Training loss: 0.6876803432551908
Epoch: 47 | Iteration number: [720/4518] 15% | Training loss: 0.6876642848054568
Epoch: 47 | Iteration number: [730/4518] 16% | Training loss: 0.6876627895930042
Epoch: 47 | Iteration number: [740/4518] 16% | Training loss: 0.6876592507233491
Epoch: 47 | Iteration number: [750/4518] 16% | Training loss: 0.6876375548044841
Epoch: 47 | Iteration number: [760/4518] 16% | Training loss: 0.6875933705976135
Epoch: 47 | Iteration number: [770/4518] 17% | Training loss: 0.6875920691273429
Epoch: 47 | Iteration number: [780/4518] 17% | Training loss: 0.6875931329452074
Epoch: 47 | Iteration number: [790/4518] 17% | Training loss: 0.6875861395763445
Epoch: 47 | Iteration number: [800/4518] 17% | Training loss: 0.6875746236741542
Epoch: 47 | Iteration number: [810/4518] 17% | Training loss: 0.687572051787082
Epoch: 47 | Iteration number: [820/4518] 18% | Training loss: 0.687567562737116
Epoch: 47 | Iteration number: [830/4518] 18% | Training loss: 0.6875630890748587
Epoch: 47 | Iteration number: [840/4518] 18% | Training loss: 0.687534777323405
Epoch: 47 | Iteration number: [850/4518] 18% | Training loss: 0.6875393995116739
Epoch: 47 | Iteration number: [860/4518] 19% | Training loss: 0.6875441401503807
Epoch: 47 | Iteration number: [870/4518] 19% | Training loss: 0.6875240708219594
Epoch: 47 | Iteration number: [880/4518] 19% | Training loss: 0.6875413334505125
Epoch: 47 | Iteration number: [890/4518] 19% | Training loss: 0.6875367089603724
Epoch: 47 | Iteration number: [900/4518] 19% | Training loss: 0.6875354199277031
Epoch: 47 | Iteration number: [910/4518] 20% | Training loss: 0.6875364348128602
Epoch: 47 | Iteration number: [920/4518] 20% | Training loss: 0.6875310001165971
Epoch: 47 | Iteration number: [930/4518] 20% | Training loss: 0.6875201995654773
Epoch: 47 | Iteration number: [940/4518] 20% | Training loss: 0.6875062570926991
Epoch: 47 | Iteration number: [950/4518] 21% | Training loss: 0.6875089617779381
Epoch: 47 | Iteration number: [960/4518] 21% | Training loss: 0.6875010622665286
Epoch: 47 | Iteration number: [970/4518] 21% | Training loss: 0.6874919280563433
Epoch: 47 | Iteration number: [980/4518] 21% | Training loss: 0.6874757441330929
Epoch: 47 | Iteration number: [990/4518] 21% | Training loss: 0.6874628923156044
Epoch: 47 | Iteration number: [1000/4518] 22% | Training loss: 0.6874597967267037
Epoch: 47 | Iteration number: [1010/4518] 22% | Training loss: 0.6874427544008387
Epoch: 47 | Iteration number: [1020/4518] 22% | Training loss: 0.6874445452409632
Epoch: 47 | Iteration number: [1030/4518] 22% | Training loss: 0.6874415118138767
Epoch: 47 | Iteration number: [1040/4518] 23% | Training loss: 0.6874350519707569
Epoch: 47 | Iteration number: [1050/4518] 23% | Training loss: 0.687439492997669
Epoch: 47 | Iteration number: [1060/4518] 23% | Training loss: 0.6874290494423992
Epoch: 47 | Iteration number: [1070/4518] 23% | Training loss: 0.6874259345999388
Epoch: 47 | Iteration number: [1080/4518] 23% | Training loss: 0.6874260906819945
Epoch: 47 | Iteration number: [1090/4518] 24% | Training loss: 0.6874147771695338
Epoch: 47 | Iteration number: [1100/4518] 24% | Training loss: 0.6874170648509805
Epoch: 47 | Iteration number: [1110/4518] 24% | Training loss: 0.6873993506839683
Epoch: 47 | Iteration number: [1120/4518] 24% | Training loss: 0.6873914977269513
Epoch: 47 | Iteration number: [1130/4518] 25% | Training loss: 0.6873787476953152
Epoch: 47 | Iteration number: [1140/4518] 25% | Training loss: 0.6873777021441543
Epoch: 47 | Iteration number: [1150/4518] 25% | Training loss: 0.687369480703188
Epoch: 47 | Iteration number: [1160/4518] 25% | Training loss: 0.6873504975232585
Epoch: 47 | Iteration number: [1170/4518] 25% | Training loss: 0.6873500532574124
Epoch: 47 | Iteration number: [1180/4518] 26% | Training loss: 0.6873391384795561
Epoch: 47 | Iteration number: [1190/4518] 26% | Training loss: 0.6873324148795183
Epoch: 47 | Iteration number: [1200/4518] 26% | Training loss: 0.6873266199727853
Epoch: 47 | Iteration number: [1210/4518] 26% | Training loss: 0.6873357567412794
Epoch: 47 | Iteration number: [1220/4518] 27% | Training loss: 0.6873273847044491
Epoch: 47 | Iteration number: [1230/4518] 27% | Training loss: 0.6873149725479808
Epoch: 47 | Iteration number: [1240/4518] 27% | Training loss: 0.6873170662310816
Epoch: 47 | Iteration number: [1250/4518] 27% | Training loss: 0.687307026052475
Epoch: 47 | Iteration number: [1260/4518] 27% | Training loss: 0.6872974911852489
Epoch: 47 | Iteration number: [1270/4518] 28% | Training loss: 0.6872907083334885
Epoch: 47 | Iteration number: [1280/4518] 28% | Training loss: 0.6872771851718426
Epoch: 47 | Iteration number: [1290/4518] 28% | Training loss: 0.687285657816155
Epoch: 47 | Iteration number: [1300/4518] 28% | Training loss: 0.6872723137415372
Epoch: 47 | Iteration number: [1310/4518] 28% | Training loss: 0.687260564820457
Epoch: 47 | Iteration number: [1320/4518] 29% | Training loss: 0.6872553635275725
Epoch: 47 | Iteration number: [1330/4518] 29% | Training loss: 0.6872475920315075
Epoch: 47 | Iteration number: [1340/4518] 29% | Training loss: 0.6872513091386254
Epoch: 47 | Iteration number: [1350/4518] 29% | Training loss: 0.6872473101262693
Epoch: 47 | Iteration number: [1360/4518] 30% | Training loss: 0.6872465343598058
Epoch: 47 | Iteration number: [1370/4518] 30% | Training loss: 0.6872293257800332
Epoch: 47 | Iteration number: [1380/4518] 30% | Training loss: 0.6872254962074584
Epoch: 47 | Iteration number: [1390/4518] 30% | Training loss: 0.6872225653353355
Epoch: 47 | Iteration number: [1400/4518] 30% | Training loss: 0.6872161059294428
Epoch: 47 | Iteration number: [1410/4518] 31% | Training loss: 0.6872063775434561
Epoch: 47 | Iteration number: [1420/4518] 31% | Training loss: 0.6872047372687031
Epoch: 47 | Iteration number: [1430/4518] 31% | Training loss: 0.6871948356395001
Epoch: 47 | Iteration number: [1440/4518] 31% | Training loss: 0.687205375234286
Epoch: 47 | Iteration number: [1450/4518] 32% | Training loss: 0.6872071606537391
Epoch: 47 | Iteration number: [1460/4518] 32% | Training loss: 0.6871963075987281
Epoch: 47 | Iteration number: [1470/4518] 32% | Training loss: 0.6871898453251846
Epoch: 47 | Iteration number: [1480/4518] 32% | Training loss: 0.687184703430614
Epoch: 47 | Iteration number: [1490/4518] 32% | Training loss: 0.6871751394847896
Epoch: 47 | Iteration number: [1500/4518] 33% | Training loss: 0.6871755240360896
Epoch: 47 | Iteration number: [1510/4518] 33% | Training loss: 0.6871737079904569
Epoch: 47 | Iteration number: [1520/4518] 33% | Training loss: 0.6871709417747823
Epoch: 47 | Iteration number: [1530/4518] 33% | Training loss: 0.6871602398118163
Epoch: 47 | Iteration number: [1540/4518] 34% | Training loss: 0.6871669639240612
Epoch: 47 | Iteration number: [1550/4518] 34% | Training loss: 0.6871623346497936
Epoch: 47 | Iteration number: [1560/4518] 34% | Training loss: 0.6871652904993448
Epoch: 47 | Iteration number: [1570/4518] 34% | Training loss: 0.687171613790427
Epoch: 47 | Iteration number: [1580/4518] 34% | Training loss: 0.6871675175956533
Epoch: 47 | Iteration number: [1590/4518] 35% | Training loss: 0.6871724559451049
Epoch: 47 | Iteration number: [1600/4518] 35% | Training loss: 0.6871736530959606
Epoch: 47 | Iteration number: [1610/4518] 35% | Training loss: 0.6871690644240528
Epoch: 47 | Iteration number: [1620/4518] 35% | Training loss: 0.6871581219228697
Epoch: 47 | Iteration number: [1630/4518] 36% | Training loss: 0.6871562425709941
Epoch: 47 | Iteration number: [1640/4518] 36% | Training loss: 0.6871476388195666
Epoch: 47 | Iteration number: [1650/4518] 36% | Training loss: 0.6871477502765078
Epoch: 47 | Iteration number: [1660/4518] 36% | Training loss: 0.6871505681290684
Epoch: 47 | Iteration number: [1670/4518] 36% | Training loss: 0.6871444872753348
Epoch: 47 | Iteration number: [1680/4518] 37% | Training loss: 0.6871370233240581
Epoch: 47 | Iteration number: [1690/4518] 37% | Training loss: 0.6871354232525685
Epoch: 47 | Iteration number: [1700/4518] 37% | Training loss: 0.6871333169937134
Epoch: 47 | Iteration number: [1710/4518] 37% | Training loss: 0.6871364535295476
Epoch: 47 | Iteration number: [1720/4518] 38% | Training loss: 0.6871283969906874
Epoch: 47 | Iteration number: [1730/4518] 38% | Training loss: 0.687126235224608
Epoch: 47 | Iteration number: [1740/4518] 38% | Training loss: 0.6871313765816305
Epoch: 47 | Iteration number: [1750/4518] 38% | Training loss: 0.6871253851481847
Epoch: 47 | Iteration number: [1760/4518] 38% | Training loss: 0.6871226439421827
Epoch: 47 | Iteration number: [1770/4518] 39% | Training loss: 0.6871207642016438
Epoch: 47 | Iteration number: [1780/4518] 39% | Training loss: 0.6871186234977807
Epoch: 47 | Iteration number: [1790/4518] 39% | Training loss: 0.6871240263544648
Epoch: 47 | Iteration number: [1800/4518] 39% | Training loss: 0.6871214893791411
Epoch: 47 | Iteration number: [1810/4518] 40% | Training loss: 0.6871227413580563
Epoch: 47 | Iteration number: [1820/4518] 40% | Training loss: 0.6871204787230754
Epoch: 47 | Iteration number: [1830/4518] 40% | Training loss: 0.68712158473463
Epoch: 47 | Iteration number: [1840/4518] 40% | Training loss: 0.6871188351641531
Epoch: 47 | Iteration number: [1850/4518] 40% | Training loss: 0.6871221030725015
Epoch: 47 | Iteration number: [1860/4518] 41% | Training loss: 0.687115341040396
Epoch: 47 | Iteration number: [1870/4518] 41% | Training loss: 0.6871082086614109
Epoch: 47 | Iteration number: [1880/4518] 41% | Training loss: 0.6871044906212929
Epoch: 47 | Iteration number: [1890/4518] 41% | Training loss: 0.6870987501409319
Epoch: 47 | Iteration number: [1900/4518] 42% | Training loss: 0.6871014835646277
Epoch: 47 | Iteration number: [1910/4518] 42% | Training loss: 0.6870934231431073
Epoch: 47 | Iteration number: [1920/4518] 42% | Training loss: 0.6870857955267032
Epoch: 47 | Iteration number: [1930/4518] 42% | Training loss: 0.6870924160270493
Epoch: 47 | Iteration number: [1940/4518] 42% | Training loss: 0.6870949508910327
Epoch: 47 | Iteration number: [1950/4518] 43% | Training loss: 0.6870938834165915
Epoch: 47 | Iteration number: [1960/4518] 43% | Training loss: 0.6870936260843764
Epoch: 47 | Iteration number: [1970/4518] 43% | Training loss: 0.687094579705127
Epoch: 47 | Iteration number: [1980/4518] 43% | Training loss: 0.687094196767518
Epoch: 47 | Iteration number: [1990/4518] 44% | Training loss: 0.6870908121367795
Epoch: 47 | Iteration number: [2000/4518] 44% | Training loss: 0.6870905188918114
Epoch: 47 | Iteration number: [2010/4518] 44% | Training loss: 0.6870895012990752
Epoch: 47 | Iteration number: [2020/4518] 44% | Training loss: 0.687090862889101
Epoch: 47 | Iteration number: [2030/4518] 44% | Training loss: 0.6870866631052177
Epoch: 47 | Iteration number: [2040/4518] 45% | Training loss: 0.687084907848461
Epoch: 47 | Iteration number: [2050/4518] 45% | Training loss: 0.6870825452630113
Epoch: 47 | Iteration number: [2060/4518] 45% | Training loss: 0.6870765059897043
Epoch: 47 | Iteration number: [2070/4518] 45% | Training loss: 0.687075322146577
Epoch: 47 | Iteration number: [2080/4518] 46% | Training loss: 0.6870714668184519
Epoch: 47 | Iteration number: [2090/4518] 46% | Training loss: 0.6870631474912452
Epoch: 47 | Iteration number: [2100/4518] 46% | Training loss: 0.6870548877545766
Epoch: 47 | Iteration number: [2110/4518] 46% | Training loss: 0.6870509364028677
Epoch: 47 | Iteration number: [2120/4518] 46% | Training loss: 0.6870510954058395
Epoch: 47 | Iteration number: [2130/4518] 47% | Training loss: 0.687047483747554
Epoch: 47 | Iteration number: [2140/4518] 47% | Training loss: 0.6870483454978354
Epoch: 47 | Iteration number: [2150/4518] 47% | Training loss: 0.6870424860854482
Epoch: 47 | Iteration number: [2160/4518] 47% | Training loss: 0.6870358882954827
Epoch: 47 | Iteration number: [2170/4518] 48% | Training loss: 0.6870405431167321
Epoch: 47 | Iteration number: [2180/4518] 48% | Training loss: 0.6870365978380956
Epoch: 47 | Iteration number: [2190/4518] 48% | Training loss: 0.6870372479092585
Epoch: 47 | Iteration number: [2200/4518] 48% | Training loss: 0.6870350189913403
Epoch: 47 | Iteration number: [2210/4518] 48% | Training loss: 0.6870381850732398
Epoch: 47 | Iteration number: [2220/4518] 49% | Training loss: 0.6870372537557069
Epoch: 47 | Iteration number: [2230/4518] 49% | Training loss: 0.6870314884613448
Epoch: 47 | Iteration number: [2240/4518] 49% | Training loss: 0.6870309775429112
Epoch: 47 | Iteration number: [2250/4518] 49% | Training loss: 0.6870268419848548
Epoch: 47 | Iteration number: [2260/4518] 50% | Training loss: 0.687029141873385
Epoch: 47 | Iteration number: [2270/4518] 50% | Training loss: 0.6870306613161701
Epoch: 47 | Iteration number: [2280/4518] 50% | Training loss: 0.6870272021806031
Epoch: 47 | Iteration number: [2290/4518] 50% | Training loss: 0.6870266078340955
Epoch: 47 | Iteration number: [2300/4518] 50% | Training loss: 0.6870298962748569
Epoch: 47 | Iteration number: [2310/4518] 51% | Training loss: 0.6870244870196173
Epoch: 47 | Iteration number: [2320/4518] 51% | Training loss: 0.6870168222692506
Epoch: 47 | Iteration number: [2330/4518] 51% | Training loss: 0.6870132600800674
Epoch: 47 | Iteration number: [2340/4518] 51% | Training loss: 0.6870118536246128
Epoch: 47 | Iteration number: [2350/4518] 52% | Training loss: 0.6870104678387338
Epoch: 47 | Iteration number: [2360/4518] 52% | Training loss: 0.6870155292547355
Epoch: 47 | Iteration number: [2370/4518] 52% | Training loss: 0.687019220208317
Epoch: 47 | Iteration number: [2380/4518] 52% | Training loss: 0.6870200984868683
Epoch: 47 | Iteration number: [2390/4518] 52% | Training loss: 0.6870237730287607
Epoch: 47 | Iteration number: [2400/4518] 53% | Training loss: 0.6870268020778895
Epoch: 47 | Iteration number: [2410/4518] 53% | Training loss: 0.687027068578356
Epoch: 47 | Iteration number: [2420/4518] 53% | Training loss: 0.6870290464359867
Epoch: 47 | Iteration number: [2430/4518] 53% | Training loss: 0.6870317954585385
Epoch: 47 | Iteration number: [2440/4518] 54% | Training loss: 0.6870320935474068
Epoch: 47 | Iteration number: [2450/4518] 54% | Training loss: 0.6870364573780371
Epoch: 47 | Iteration number: [2460/4518] 54% | Training loss: 0.687039980873829
Epoch: 47 | Iteration number: [2470/4518] 54% | Training loss: 0.6870394369851239
Epoch: 47 | Iteration number: [2480/4518] 54% | Training loss: 0.6870356678722366
Epoch: 47 | Iteration number: [2490/4518] 55% | Training loss: 0.6870310562920857
Epoch: 47 | Iteration number: [2500/4518] 55% | Training loss: 0.6870253071546555
Epoch: 47 | Iteration number: [2510/4518] 55% | Training loss: 0.6870215559385687
Epoch: 47 | Iteration number: [2520/4518] 55% | Training loss: 0.6870224076131034
Epoch: 47 | Iteration number: [2530/4518] 55% | Training loss: 0.6870254918049447
Epoch: 47 | Iteration number: [2540/4518] 56% | Training loss: 0.6870189264534027
Epoch: 47 | Iteration number: [2550/4518] 56% | Training loss: 0.687018696046343
Epoch: 47 | Iteration number: [2560/4518] 56% | Training loss: 0.6870183484628797
Epoch: 47 | Iteration number: [2570/4518] 56% | Training loss: 0.6870182528570005
Epoch: 47 | Iteration number: [2580/4518] 57% | Training loss: 0.6870199741319168
Epoch: 47 | Iteration number: [2590/4518] 57% | Training loss: 0.6870152014332849
Epoch: 47 | Iteration number: [2600/4518] 57% | Training loss: 0.6870203566780457
Epoch: 47 | Iteration number: [2610/4518] 57% | Training loss: 0.6870174804181431
Epoch: 47 | Iteration number: [2620/4518] 57% | Training loss: 0.6870217953246969
Epoch: 47 | Iteration number: [2630/4518] 58% | Training loss: 0.6870185978738981
Epoch: 47 | Iteration number: [2640/4518] 58% | Training loss: 0.6870139834781488
Epoch: 47 | Iteration number: [2650/4518] 58% | Training loss: 0.6870125367056649
Epoch: 47 | Iteration number: [2660/4518] 58% | Training loss: 0.6870124356863194
Epoch: 47 | Iteration number: [2670/4518] 59% | Training loss: 0.6870153112134684
Epoch: 47 | Iteration number: [2680/4518] 59% | Training loss: 0.6870117290251291
Epoch: 47 | Iteration number: [2690/4518] 59% | Training loss: 0.6870084656880248
Epoch: 47 | Iteration number: [2700/4518] 59% | Training loss: 0.6870130579780649
Epoch: 47 | Iteration number: [2710/4518] 59% | Training loss: 0.6870096843620948
Epoch: 47 | Iteration number: [2720/4518] 60% | Training loss: 0.6870151363751468
Epoch: 47 | Iteration number: [2730/4518] 60% | Training loss: 0.6870130349646558
Epoch: 47 | Iteration number: [2740/4518] 60% | Training loss: 0.6870104318117574
Epoch: 47 | Iteration number: [2750/4518] 60% | Training loss: 0.687012180371718
Epoch: 47 | Iteration number: [2760/4518] 61% | Training loss: 0.687012971073821
Epoch: 47 | Iteration number: [2770/4518] 61% | Training loss: 0.6870145601486041
Epoch: 47 | Iteration number: [2780/4518] 61% | Training loss: 0.6870119946680481
Epoch: 47 | Iteration number: [2790/4518] 61% | Training loss: 0.6870096766606881
Epoch: 47 | Iteration number: [2800/4518] 61% | Training loss: 0.6870128584972449
Epoch: 47 | Iteration number: [2810/4518] 62% | Training loss: 0.6870096266057568
Epoch: 47 | Iteration number: [2820/4518] 62% | Training loss: 0.6870098646650923
Epoch: 47 | Iteration number: [2830/4518] 62% | Training loss: 0.6870116437071204
Epoch: 47 | Iteration number: [2840/4518] 62% | Training loss: 0.6870153469099125
Epoch: 47 | Iteration number: [2850/4518] 63% | Training loss: 0.6870158761426022
Epoch: 47 | Iteration number: [2860/4518] 63% | Training loss: 0.6870144095454183
Epoch: 47 | Iteration number: [2870/4518] 63% | Training loss: 0.6870114863126535
Epoch: 47 | Iteration number: [2880/4518] 63% | Training loss: 0.6870051227716936
Epoch: 47 | Iteration number: [2890/4518] 63% | Training loss: 0.6869980559835797
Epoch: 47 | Iteration number: [2900/4518] 64% | Training loss: 0.6869966801487166
Epoch: 47 | Iteration number: [2910/4518] 64% | Training loss: 0.6869921843415683
Epoch: 47 | Iteration number: [2920/4518] 64% | Training loss: 0.6869884055975365
Epoch: 47 | Iteration number: [2930/4518] 64% | Training loss: 0.68698806280569
Epoch: 47 | Iteration number: [2940/4518] 65% | Training loss: 0.686986397744036
Epoch: 47 | Iteration number: [2950/4518] 65% | Training loss: 0.686991163370973
Epoch: 47 | Iteration number: [2960/4518] 65% | Training loss: 0.6869889604884225
Epoch: 47 | Iteration number: [2970/4518] 65% | Training loss: 0.6869892049718787
Epoch: 47 | Iteration number: [2980/4518] 65% | Training loss: 0.686990444752194
Epoch: 47 | Iteration number: [2990/4518] 66% | Training loss: 0.686988493730392
Epoch: 47 | Iteration number: [3000/4518] 66% | Training loss: 0.6869922173817953
Epoch: 47 | Iteration number: [3010/4518] 66% | Training loss: 0.6869920195139128
Epoch: 47 | Iteration number: [3020/4518] 66% | Training loss: 0.6869921222822556
Epoch: 47 | Iteration number: [3030/4518] 67% | Training loss: 0.6869936610999281
Epoch: 47 | Iteration number: [3040/4518] 67% | Training loss: 0.686993323560608
Epoch: 47 | Iteration number: [3050/4518] 67% | Training loss: 0.6869924699673887
Epoch: 47 | Iteration number: [3060/4518] 67% | Training loss: 0.6869923789516773
Epoch: 47 | Iteration number: [3070/4518] 67% | Training loss: 0.6869913252246497
Epoch: 47 | Iteration number: [3080/4518] 68% | Training loss: 0.686989162262384
Epoch: 47 | Iteration number: [3090/4518] 68% | Training loss: 0.686985176126548
Epoch: 47 | Iteration number: [3100/4518] 68% | Training loss: 0.6869807490802581
Epoch: 47 | Iteration number: [3110/4518] 68% | Training loss: 0.6869798701484103
Epoch: 47 | Iteration number: [3120/4518] 69% | Training loss: 0.686979700720463
Epoch: 47 | Iteration number: [3130/4518] 69% | Training loss: 0.686979073857347
Epoch: 47 | Iteration number: [3140/4518] 69% | Training loss: 0.6869798174329624
Epoch: 47 | Iteration number: [3150/4518] 69% | Training loss: 0.686982482217607
Epoch: 47 | Iteration number: [3160/4518] 69% | Training loss: 0.6869754833699782
Epoch: 47 | Iteration number: [3170/4518] 70% | Training loss: 0.6869798426372395
Epoch: 47 | Iteration number: [3180/4518] 70% | Training loss: 0.6869808113612469
Epoch: 47 | Iteration number: [3190/4518] 70% | Training loss: 0.6869807629562844
Epoch: 47 | Iteration number: [3200/4518] 70% | Training loss: 0.68698450230062
Epoch: 47 | Iteration number: [3210/4518] 71% | Training loss: 0.6869793439022849
Epoch: 47 | Iteration number: [3220/4518] 71% | Training loss: 0.686982713389841
Epoch: 47 | Iteration number: [3230/4518] 71% | Training loss: 0.6869819351209575
Epoch: 47 | Iteration number: [3240/4518] 71% | Training loss: 0.6869813471848583
Epoch: 47 | Iteration number: [3250/4518] 71% | Training loss: 0.6869820896845598
Epoch: 47 | Iteration number: [3260/4518] 72% | Training loss: 0.6869871830099199
Epoch: 47 | Iteration number: [3270/4518] 72% | Training loss: 0.6869849837701255
Epoch: 47 | Iteration number: [3280/4518] 72% | Training loss: 0.6869853599224148
Epoch: 47 | Iteration number: [3290/4518] 72% | Training loss: 0.6869858269633493
Epoch: 47 | Iteration number: [3300/4518] 73% | Training loss: 0.6869865953199791
Epoch: 47 | Iteration number: [3310/4518] 73% | Training loss: 0.686984479643427
Epoch: 47 | Iteration number: [3320/4518] 73% | Training loss: 0.6869816101100071
Epoch: 47 | Iteration number: [3330/4518] 73% | Training loss: 0.6869828485153817
Epoch: 47 | Iteration number: [3340/4518] 73% | Training loss: 0.6869850624642686
Epoch: 47 | Iteration number: [3350/4518] 74% | Training loss: 0.68698718818266
Epoch: 47 | Iteration number: [3360/4518] 74% | Training loss: 0.6869910946736734
Epoch: 47 | Iteration number: [3370/4518] 74% | Training loss: 0.6869882817791902
Epoch: 47 | Iteration number: [3380/4518] 74% | Training loss: 0.6869869429860594
Epoch: 47 | Iteration number: [3390/4518] 75% | Training loss: 0.6869832690134864
Epoch: 47 | Iteration number: [3400/4518] 75% | Training loss: 0.686982529531507
Epoch: 47 | Iteration number: [3410/4518] 75% | Training loss: 0.6869858839295128
Epoch: 47 | Iteration number: [3420/4518] 75% | Training loss: 0.6869826573203182
Epoch: 47 | Iteration number: [3430/4518] 75% | Training loss: 0.68698475234015
Epoch: 47 | Iteration number: [3440/4518] 76% | Training loss: 0.6869837414040122
Epoch: 47 | Iteration number: [3450/4518] 76% | Training loss: 0.6869808737609697
Epoch: 47 | Iteration number: [3460/4518] 76% | Training loss: 0.6869793274843624
Epoch: 47 | Iteration number: [3470/4518] 76% | Training loss: 0.6869807008192244
Epoch: 47 | Iteration number: [3480/4518] 77% | Training loss: 0.686984131545171
Epoch: 47 | Iteration number: [3490/4518] 77% | Training loss: 0.686980088563225
Epoch: 47 | Iteration number: [3500/4518] 77% | Training loss: 0.6869829492058073
Epoch: 47 | Iteration number: [3510/4518] 77% | Training loss: 0.6869832054672078
Epoch: 47 | Iteration number: [3520/4518] 77% | Training loss: 0.6869820910082622
Epoch: 47 | Iteration number: [3530/4518] 78% | Training loss: 0.6869849010162246
Epoch: 47 | Iteration number: [3540/4518] 78% | Training loss: 0.6869862326457675
Epoch: 47 | Iteration number: [3550/4518] 78% | Training loss: 0.6869845179269012
Epoch: 47 | Iteration number: [3560/4518] 78% | Training loss: 0.6869851635245795
Epoch: 47 | Iteration number: [3570/4518] 79% | Training loss: 0.6869864025536705
Epoch: 47 | Iteration number: [3580/4518] 79% | Training loss: 0.6869843197101987
Epoch: 47 | Iteration number: [3590/4518] 79% | Training loss: 0.6869854791582793
Epoch: 47 | Iteration number: [3600/4518] 79% | Training loss: 0.6869851383897994
Epoch: 47 | Iteration number: [3610/4518] 79% | Training loss: 0.6869853456429827
Epoch: 47 | Iteration number: [3620/4518] 80% | Training loss: 0.6869876571781728
Epoch: 47 | Iteration number: [3630/4518] 80% | Training loss: 0.6869861326270196
Epoch: 47 | Iteration number: [3640/4518] 80% | Training loss: 0.6869874542067339
Epoch: 47 | Iteration number: [3650/4518] 80% | Training loss: 0.6869875093682172
Epoch: 47 | Iteration number: [3660/4518] 81% | Training loss: 0.6869806962260783
Epoch: 47 | Iteration number: [3670/4518] 81% | Training loss: 0.6869776842054944
Epoch: 47 | Iteration number: [3680/4518] 81% | Training loss: 0.6869794106839792
Epoch: 47 | Iteration number: [3690/4518] 81% | Training loss: 0.6869779603429603
Epoch: 47 | Iteration number: [3700/4518] 81% | Training loss: 0.6869761705237466
Epoch: 47 | Iteration number: [3710/4518] 82% | Training loss: 0.6869782693302535
Epoch: 47 | Iteration number: [3720/4518] 82% | Training loss: 0.6869733392070698
Epoch: 47 | Iteration number: [3730/4518] 82% | Training loss: 0.6869733764562785
Epoch: 47 | Iteration number: [3740/4518] 82% | Training loss: 0.686972138317511
Epoch: 47 | Iteration number: [3750/4518] 83% | Training loss: 0.6869692874272665
Epoch: 47 | Iteration number: [3760/4518] 83% | Training loss: 0.686968330515826
Epoch: 47 | Iteration number: [3770/4518] 83% | Training loss: 0.6869665173541962
Epoch: 47 | Iteration number: [3780/4518] 83% | Training loss: 0.6869664213014027
Epoch: 47 | Iteration number: [3790/4518] 83% | Training loss: 0.6869650147992892
Epoch: 47 | Iteration number: [3800/4518] 84% | Training loss: 0.6869643107997744
Epoch: 47 | Iteration number: [3810/4518] 84% | Training loss: 0.686966629588385
Epoch: 47 | Iteration number: [3820/4518] 84% | Training loss: 0.6869617852709056
Epoch: 47 | Iteration number: [3830/4518] 84% | Training loss: 0.6869600293374871
Epoch: 47 | Iteration number: [3840/4518] 84% | Training loss: 0.6869575864169747
Epoch: 47 | Iteration number: [3850/4518] 85% | Training loss: 0.6869564324539977
Epoch: 47 | Iteration number: [3860/4518] 85% | Training loss: 0.6869535264419151
Epoch: 47 | Iteration number: [3870/4518] 85% | Training loss: 0.6869519571309249
Epoch: 47 | Iteration number: [3880/4518] 85% | Training loss: 0.6869489207556567
Epoch: 47 | Iteration number: [3890/4518] 86% | Training loss: 0.6869505461659713
Epoch: 47 | Iteration number: [3900/4518] 86% | Training loss: 0.686948736111323
Epoch: 47 | Iteration number: [3910/4518] 86% | Training loss: 0.6869517918133065
Epoch: 47 | Iteration number: [3920/4518] 86% | Training loss: 0.6869543689398133
Epoch: 47 | Iteration number: [3930/4518] 86% | Training loss: 0.6869513754171269
Epoch: 47 | Iteration number: [3940/4518] 87% | Training loss: 0.6869522792887567
Epoch: 47 | Iteration number: [3950/4518] 87% | Training loss: 0.6869523695903489
Epoch: 47 | Iteration number: [3960/4518] 87% | Training loss: 0.6869530958057654
Epoch: 47 | Iteration number: [3970/4518] 87% | Training loss: 0.6869523185776824
Epoch: 47 | Iteration number: [3980/4518] 88% | Training loss: 0.6869510750974243
Epoch: 47 | Iteration number: [3990/4518] 88% | Training loss: 0.6869497961567756
Epoch: 47 | Iteration number: [4000/4518] 88% | Training loss: 0.6869483646154404
Epoch: 47 | Iteration number: [4010/4518] 88% | Training loss: 0.686944216980304
Epoch: 47 | Iteration number: [4020/4518] 88% | Training loss: 0.6869463089241911
Epoch: 47 | Iteration number: [4030/4518] 89% | Training loss: 0.6869474560983719
Epoch: 47 | Iteration number: [4040/4518] 89% | Training loss: 0.6869480167580123
Epoch: 47 | Iteration number: [4050/4518] 89% | Training loss: 0.6869500730214295
Epoch: 47 | Iteration number: [4060/4518] 89% | Training loss: 0.6869489957693176
Epoch: 47 | Iteration number: [4070/4518] 90% | Training loss: 0.6869491164602284
Epoch: 47 | Iteration number: [4080/4518] 90% | Training loss: 0.6869510522660087
Epoch: 47 | Iteration number: [4090/4518] 90% | Training loss: 0.686953259272214
Epoch: 47 | Iteration number: [4100/4518] 90% | Training loss: 0.6869514760156957
Epoch: 47 | Iteration number: [4110/4518] 90% | Training loss: 0.6869531714568173
Epoch: 47 | Iteration number: [4120/4518] 91% | Training loss: 0.6869532560983908
Epoch: 47 | Iteration number: [4130/4518] 91% | Training loss: 0.6869527554396567
Epoch: 47 | Iteration number: [4140/4518] 91% | Training loss: 0.6869557674380317
Epoch: 47 | Iteration number: [4150/4518] 91% | Training loss: 0.6869553594991386
Epoch: 47 | Iteration number: [4160/4518] 92% | Training loss: 0.6869572408067492
Epoch: 47 | Iteration number: [4170/4518] 92% | Training loss: 0.686958598204368
Epoch: 47 | Iteration number: [4180/4518] 92% | Training loss: 0.6869562670517196
Epoch: 47 | Iteration number: [4190/4518] 92% | Training loss: 0.6869579208210146
Epoch: 47 | Iteration number: [4200/4518] 92% | Training loss: 0.6869584472264563
Epoch: 47 | Iteration number: [4210/4518] 93% | Training loss: 0.6869598034866632
Epoch: 47 | Iteration number: [4220/4518] 93% | Training loss: 0.6869583927907085
Epoch: 47 | Iteration number: [4230/4518] 93% | Training loss: 0.6869578566393391
Epoch: 47 | Iteration number: [4240/4518] 93% | Training loss: 0.6869553236607111
Epoch: 47 | Iteration number: [4250/4518] 94% | Training loss: 0.6869592621326447
Epoch: 47 | Iteration number: [4260/4518] 94% | Training loss: 0.6869602831736417
Epoch: 47 | Iteration number: [4270/4518] 94% | Training loss: 0.6869602639446214
Epoch: 47 | Iteration number: [4280/4518] 94% | Training loss: 0.6869609208725324
Epoch: 47 | Iteration number: [4290/4518] 94% | Training loss: 0.6869594619963275
Epoch: 47 | Iteration number: [4300/4518] 95% | Training loss: 0.6869599163255026
Epoch: 47 | Iteration number: [4310/4518] 95% | Training loss: 0.6869609854475804
Epoch: 47 | Iteration number: [4320/4518] 95% | Training loss: 0.6869629931946596
Epoch: 47 | Iteration number: [4330/4518] 95% | Training loss: 0.6869613154793447
Epoch: 47 | Iteration number: [4340/4518] 96% | Training loss: 0.6869600947002112
Epoch: 47 | Iteration number: [4350/4518] 96% | Training loss: 0.6869584340062634
Epoch: 47 | Iteration number: [4360/4518] 96% | Training loss: 0.686958196950615
Epoch: 47 | Iteration number: [4370/4518] 96% | Training loss: 0.6869595863862769
Epoch: 47 | Iteration number: [4380/4518] 96% | Training loss: 0.6869593755295288
Epoch: 47 | Iteration number: [4390/4518] 97% | Training loss: 0.6869593221261452
Epoch: 47 | Iteration number: [4400/4518] 97% | Training loss: 0.6869613407010382
Epoch: 47 | Iteration number: [4410/4518] 97% | Training loss: 0.6869614107403356
Epoch: 47 | Iteration number: [4420/4518] 97% | Training loss: 0.686961229813045
Epoch: 47 | Iteration number: [4430/4518] 98% | Training loss: 0.6869630808754914
Epoch: 47 | Iteration number: [4440/4518] 98% | Training loss: 0.6869613947229343
Epoch: 47 | Iteration number: [4450/4518] 98% | Training loss: 0.6869618974642807
Epoch: 47 | Iteration number: [4460/4518] 98% | Training loss: 0.6869642192472791
Epoch: 47 | Iteration number: [4470/4518] 98% | Training loss: 0.6869647534101602
Epoch: 47 | Iteration number: [4480/4518] 99% | Training loss: 0.6869666344885316
Epoch: 47 | Iteration number: [4490/4518] 99% | Training loss: 0.6869646525728145
Epoch: 47 | Iteration number: [4500/4518] 99% | Training loss: 0.6869643783039517
Epoch: 47 | Iteration number: [4510/4518] 99% | Training loss: 0.6869605824714754

 End of epoch: 47 | Train Loss: 0.6868079702719063 | Training Time: 631 

 End of epoch: 47 | Eval Loss: 0.6897952398475335 | Evaluating Time: 17 
Epoch: 48 | Iteration number: [10/4518] 0% | Training loss: 0.7536737501621247
Epoch: 48 | Iteration number: [20/4518] 0% | Training loss: 0.720080578327179
Epoch: 48 | Iteration number: [30/4518] 0% | Training loss: 0.7085742731889089
Epoch: 48 | Iteration number: [40/4518] 0% | Training loss: 0.7031411692500115
Epoch: 48 | Iteration number: [50/4518] 1% | Training loss: 0.6997108602523804
Epoch: 48 | Iteration number: [60/4518] 1% | Training loss: 0.6975936730702718
Epoch: 48 | Iteration number: [70/4518] 1% | Training loss: 0.6959247044154576
Epoch: 48 | Iteration number: [80/4518] 1% | Training loss: 0.6946398109197617
Epoch: 48 | Iteration number: [90/4518] 1% | Training loss: 0.6937020334932539
Epoch: 48 | Iteration number: [100/4518] 2% | Training loss: 0.6930691033601761
Epoch: 48 | Iteration number: [110/4518] 2% | Training loss: 0.6924337690526788
Epoch: 48 | Iteration number: [120/4518] 2% | Training loss: 0.692032643655936
Epoch: 48 | Iteration number: [130/4518] 2% | Training loss: 0.6915456056594849
Epoch: 48 | Iteration number: [140/4518] 3% | Training loss: 0.691145813039371
Epoch: 48 | Iteration number: [150/4518] 3% | Training loss: 0.6909212076663971
Epoch: 48 | Iteration number: [160/4518] 3% | Training loss: 0.6906628429889679
Epoch: 48 | Iteration number: [170/4518] 3% | Training loss: 0.6903678501353544
Epoch: 48 | Iteration number: [180/4518] 3% | Training loss: 0.6901993801196417
Epoch: 48 | Iteration number: [190/4518] 4% | Training loss: 0.6901100324956995
Epoch: 48 | Iteration number: [200/4518] 4% | Training loss: 0.6899127143621445
Epoch: 48 | Iteration number: [210/4518] 4% | Training loss: 0.6897760467869894
Epoch: 48 | Iteration number: [220/4518] 4% | Training loss: 0.6896450367840854
Epoch: 48 | Iteration number: [230/4518] 5% | Training loss: 0.6895202942516493
Epoch: 48 | Iteration number: [240/4518] 5% | Training loss: 0.6894241313139597
Epoch: 48 | Iteration number: [250/4518] 5% | Training loss: 0.6892786407470703
Epoch: 48 | Iteration number: [260/4518] 5% | Training loss: 0.6891903276626881
Epoch: 48 | Iteration number: [270/4518] 5% | Training loss: 0.6891162353533286
Epoch: 48 | Iteration number: [280/4518] 6% | Training loss: 0.689064957840102
Epoch: 48 | Iteration number: [290/4518] 6% | Training loss: 0.6889935197501347
Epoch: 48 | Iteration number: [300/4518] 6% | Training loss: 0.6889358351627985
Epoch: 48 | Iteration number: [310/4518] 6% | Training loss: 0.6888464102821965
Epoch: 48 | Iteration number: [320/4518] 7% | Training loss: 0.6887888263911008
Epoch: 48 | Iteration number: [330/4518] 7% | Training loss: 0.6887466342160196
Epoch: 48 | Iteration number: [340/4518] 7% | Training loss: 0.6886881318162469
Epoch: 48 | Iteration number: [350/4518] 7% | Training loss: 0.6886107310226985
Epoch: 48 | Iteration number: [360/4518] 7% | Training loss: 0.6885506515701612
Epoch: 48 | Iteration number: [370/4518] 8% | Training loss: 0.6884903865891534
Epoch: 48 | Iteration number: [380/4518] 8% | Training loss: 0.6884136397587626
Epoch: 48 | Iteration number: [390/4518] 8% | Training loss: 0.6883823805894607
Epoch: 48 | Iteration number: [400/4518] 8% | Training loss: 0.6883414743840695
Epoch: 48 | Iteration number: [410/4518] 9% | Training loss: 0.6882717469843422
Epoch: 48 | Iteration number: [420/4518] 9% | Training loss: 0.6882500458331335
Epoch: 48 | Iteration number: [430/4518] 9% | Training loss: 0.6882013031216555
Epoch: 48 | Iteration number: [440/4518] 9% | Training loss: 0.6881708154624159
Epoch: 48 | Iteration number: [450/4518] 9% | Training loss: 0.6881193182203504
Epoch: 48 | Iteration number: [460/4518] 10% | Training loss: 0.6880881060724673
Epoch: 48 | Iteration number: [470/4518] 10% | Training loss: 0.6880721707293328
Epoch: 48 | Iteration number: [480/4518] 10% | Training loss: 0.6880708501984676
Epoch: 48 | Iteration number: [490/4518] 10% | Training loss: 0.688027071222967
Epoch: 48 | Iteration number: [500/4518] 11% | Training loss: 0.6879973055124283
Epoch: 48 | Iteration number: [510/4518] 11% | Training loss: 0.6879858154876559
Epoch: 48 | Iteration number: [520/4518] 11% | Training loss: 0.6879587646860342
Epoch: 48 | Iteration number: [530/4518] 11% | Training loss: 0.6879376537394973
Epoch: 48 | Iteration number: [540/4518] 11% | Training loss: 0.687918554522373
Epoch: 48 | Iteration number: [550/4518] 12% | Training loss: 0.6878770007870414
Epoch: 48 | Iteration number: [560/4518] 12% | Training loss: 0.6878640544201646
Epoch: 48 | Iteration number: [570/4518] 12% | Training loss: 0.6878501472765939
Epoch: 48 | Iteration number: [580/4518] 12% | Training loss: 0.6878354930672153
Epoch: 48 | Iteration number: [590/4518] 13% | Training loss: 0.687806808342368
Epoch: 48 | Iteration number: [600/4518] 13% | Training loss: 0.6877783969044685
Epoch: 48 | Iteration number: [610/4518] 13% | Training loss: 0.6877751036745603
Epoch: 48 | Iteration number: [620/4518] 13% | Training loss: 0.6877553866755578
Epoch: 48 | Iteration number: [630/4518] 13% | Training loss: 0.6877530302320208
Epoch: 48 | Iteration number: [640/4518] 14% | Training loss: 0.687721498310566
Epoch: 48 | Iteration number: [650/4518] 14% | Training loss: 0.6877274609529055
Epoch: 48 | Iteration number: [660/4518] 14% | Training loss: 0.6877065566453067
Epoch: 48 | Iteration number: [670/4518] 14% | Training loss: 0.6877009021702097
Epoch: 48 | Iteration number: [680/4518] 15% | Training loss: 0.6876873678144286
Epoch: 48 | Iteration number: [690/4518] 15% | Training loss: 0.6876748534216397
Epoch: 48 | Iteration number: [700/4518] 15% | Training loss: 0.6876814669370651
Epoch: 48 | Iteration number: [710/4518] 15% | Training loss: 0.687686068910948
Epoch: 48 | Iteration number: [720/4518] 15% | Training loss: 0.6876734297308656
Epoch: 48 | Iteration number: [730/4518] 16% | Training loss: 0.6876626006544453
Epoch: 48 | Iteration number: [740/4518] 16% | Training loss: 0.6876753765988994
Epoch: 48 | Iteration number: [750/4518] 16% | Training loss: 0.687661187728246
Epoch: 48 | Iteration number: [760/4518] 16% | Training loss: 0.6876536981839882
Epoch: 48 | Iteration number: [770/4518] 17% | Training loss: 0.6876268328784348
Epoch: 48 | Iteration number: [780/4518] 17% | Training loss: 0.6876260649699432
Epoch: 48 | Iteration number: [790/4518] 17% | Training loss: 0.6875950073139577
Epoch: 48 | Iteration number: [800/4518] 17% | Training loss: 0.6875996155291796
Epoch: 48 | Iteration number: [810/4518] 17% | Training loss: 0.6876049208052364
Epoch: 48 | Iteration number: [820/4518] 18% | Training loss: 0.6876030701689604
Epoch: 48 | Iteration number: [830/4518] 18% | Training loss: 0.6875879835651582
Epoch: 48 | Iteration number: [840/4518] 18% | Training loss: 0.687578274380593
Epoch: 48 | Iteration number: [850/4518] 18% | Training loss: 0.6875749014405643
Epoch: 48 | Iteration number: [860/4518] 19% | Training loss: 0.6875590254401052
Epoch: 48 | Iteration number: [870/4518] 19% | Training loss: 0.6875501277803004
Epoch: 48 | Iteration number: [880/4518] 19% | Training loss: 0.6875306648286906
Epoch: 48 | Iteration number: [890/4518] 19% | Training loss: 0.6875246925300427
Epoch: 48 | Iteration number: [900/4518] 19% | Training loss: 0.6875122543176015
Epoch: 48 | Iteration number: [910/4518] 20% | Training loss: 0.687499800488189
Epoch: 48 | Iteration number: [920/4518] 20% | Training loss: 0.6875069689491521
Epoch: 48 | Iteration number: [930/4518] 20% | Training loss: 0.6874879958168153
Epoch: 48 | Iteration number: [940/4518] 20% | Training loss: 0.6874779398771043
Epoch: 48 | Iteration number: [950/4518] 21% | Training loss: 0.6874601231123272
Epoch: 48 | Iteration number: [960/4518] 21% | Training loss: 0.6874560913691918
Epoch: 48 | Iteration number: [970/4518] 21% | Training loss: 0.6874552076624841
Epoch: 48 | Iteration number: [980/4518] 21% | Training loss: 0.6874510042521418
Epoch: 48 | Iteration number: [990/4518] 21% | Training loss: 0.6874406877792243
Epoch: 48 | Iteration number: [1000/4518] 22% | Training loss: 0.6874396799206733
Epoch: 48 | Iteration number: [1010/4518] 22% | Training loss: 0.6874254654539693
Epoch: 48 | Iteration number: [1020/4518] 22% | Training loss: 0.6874065854970146
Epoch: 48 | Iteration number: [1030/4518] 22% | Training loss: 0.6874021909769299
Epoch: 48 | Iteration number: [1040/4518] 23% | Training loss: 0.6873961985111237
Epoch: 48 | Iteration number: [1050/4518] 23% | Training loss: 0.6873891924108778
Epoch: 48 | Iteration number: [1060/4518] 23% | Training loss: 0.6873764471063074
Epoch: 48 | Iteration number: [1070/4518] 23% | Training loss: 0.6873674544218544
Epoch: 48 | Iteration number: [1080/4518] 23% | Training loss: 0.6873728466254694
Epoch: 48 | Iteration number: [1090/4518] 24% | Training loss: 0.6873719597081526
Epoch: 48 | Iteration number: [1100/4518] 24% | Training loss: 0.6873757204684344
Epoch: 48 | Iteration number: [1110/4518] 24% | Training loss: 0.6873679057971851
Epoch: 48 | Iteration number: [1120/4518] 24% | Training loss: 0.6873505146907909
Epoch: 48 | Iteration number: [1130/4518] 25% | Training loss: 0.6873502515586076
Epoch: 48 | Iteration number: [1140/4518] 25% | Training loss: 0.687349366357452
Epoch: 48 | Iteration number: [1150/4518] 25% | Training loss: 0.6873502989437269
Epoch: 48 | Iteration number: [1160/4518] 25% | Training loss: 0.6873392787472955
Epoch: 48 | Iteration number: [1170/4518] 25% | Training loss: 0.687337727781035
Epoch: 48 | Iteration number: [1180/4518] 26% | Training loss: 0.6873306807319997
Epoch: 48 | Iteration number: [1190/4518] 26% | Training loss: 0.6873299084290737
Epoch: 48 | Iteration number: [1200/4518] 26% | Training loss: 0.6873280350863934
Epoch: 48 | Iteration number: [1210/4518] 26% | Training loss: 0.6873292670762243
Epoch: 48 | Iteration number: [1220/4518] 27% | Training loss: 0.6873262100532407
Epoch: 48 | Iteration number: [1230/4518] 27% | Training loss: 0.6873161265035955
Epoch: 48 | Iteration number: [1240/4518] 27% | Training loss: 0.6873182028532028
Epoch: 48 | Iteration number: [1250/4518] 27% | Training loss: 0.6873185280323029
Epoch: 48 | Iteration number: [1260/4518] 27% | Training loss: 0.6873152022796963
Epoch: 48 | Iteration number: [1270/4518] 28% | Training loss: 0.6873009831417264
Epoch: 48 | Iteration number: [1280/4518] 28% | Training loss: 0.6872965204995125
Epoch: 48 | Iteration number: [1290/4518] 28% | Training loss: 0.6872923659723859
Epoch: 48 | Iteration number: [1300/4518] 28% | Training loss: 0.6872925530030177
Epoch: 48 | Iteration number: [1310/4518] 28% | Training loss: 0.6872800776066671
Epoch: 48 | Iteration number: [1320/4518] 29% | Training loss: 0.6872775900092992
Epoch: 48 | Iteration number: [1330/4518] 29% | Training loss: 0.6872796336959179
Epoch: 48 | Iteration number: [1340/4518] 29% | Training loss: 0.6872799046448808
Epoch: 48 | Iteration number: [1350/4518] 29% | Training loss: 0.687273418461835
Epoch: 48 | Iteration number: [1360/4518] 30% | Training loss: 0.6872747433536193
Epoch: 48 | Iteration number: [1370/4518] 30% | Training loss: 0.6872719431445546
Epoch: 48 | Iteration number: [1380/4518] 30% | Training loss: 0.6872687874928765
Epoch: 48 | Iteration number: [1390/4518] 30% | Training loss: 0.6872688346200709
Epoch: 48 | Iteration number: [1400/4518] 30% | Training loss: 0.6872651103990418
Epoch: 48 | Iteration number: [1410/4518] 31% | Training loss: 0.68725537163146
Epoch: 48 | Iteration number: [1420/4518] 31% | Training loss: 0.6872607489287014
Epoch: 48 | Iteration number: [1430/4518] 31% | Training loss: 0.6872614391617008
Epoch: 48 | Iteration number: [1440/4518] 31% | Training loss: 0.6872542733533515
Epoch: 48 | Iteration number: [1450/4518] 32% | Training loss: 0.6872490541277261
Epoch: 48 | Iteration number: [1460/4518] 32% | Training loss: 0.6872454478724362
Epoch: 48 | Iteration number: [1470/4518] 32% | Training loss: 0.6872373121936305
Epoch: 48 | Iteration number: [1480/4518] 32% | Training loss: 0.687235122556622
Epoch: 48 | Iteration number: [1490/4518] 32% | Training loss: 0.6872248095153962
Epoch: 48 | Iteration number: [1500/4518] 33% | Training loss: 0.68722332072258
Epoch: 48 | Iteration number: [1510/4518] 33% | Training loss: 0.6872248367363254
Epoch: 48 | Iteration number: [1520/4518] 33% | Training loss: 0.6872207710617467
Epoch: 48 | Iteration number: [1530/4518] 33% | Training loss: 0.6872226450567931
Epoch: 48 | Iteration number: [1540/4518] 34% | Training loss: 0.6872222765699609
Epoch: 48 | Iteration number: [1550/4518] 34% | Training loss: 0.6872131077704892
Epoch: 48 | Iteration number: [1560/4518] 34% | Training loss: 0.6872104329558519
Epoch: 48 | Iteration number: [1570/4518] 34% | Training loss: 0.6872053371493224
Epoch: 48 | Iteration number: [1580/4518] 34% | Training loss: 0.6872083165223085
Epoch: 48 | Iteration number: [1590/4518] 35% | Training loss: 0.6872097844597679
Epoch: 48 | Iteration number: [1600/4518] 35% | Training loss: 0.6872065919265151
Epoch: 48 | Iteration number: [1610/4518] 35% | Training loss: 0.6872131032232912
Epoch: 48 | Iteration number: [1620/4518] 35% | Training loss: 0.6872083681968995
Epoch: 48 | Iteration number: [1630/4518] 36% | Training loss: 0.6872094563911297
Epoch: 48 | Iteration number: [1640/4518] 36% | Training loss: 0.6872136863266549
Epoch: 48 | Iteration number: [1650/4518] 36% | Training loss: 0.6872208380337917
Epoch: 48 | Iteration number: [1660/4518] 36% | Training loss: 0.687215519130948
Epoch: 48 | Iteration number: [1670/4518] 36% | Training loss: 0.6872127308816967
Epoch: 48 | Iteration number: [1680/4518] 37% | Training loss: 0.6871987655404068
Epoch: 48 | Iteration number: [1690/4518] 37% | Training loss: 0.6871878227538611
Epoch: 48 | Iteration number: [1700/4518] 37% | Training loss: 0.6871923491183449
Epoch: 48 | Iteration number: [1710/4518] 37% | Training loss: 0.6871913811965296
Epoch: 48 | Iteration number: [1720/4518] 38% | Training loss: 0.6871932680523672
Epoch: 48 | Iteration number: [1730/4518] 38% | Training loss: 0.6871924464413196
Epoch: 48 | Iteration number: [1740/4518] 38% | Training loss: 0.6871873399306988
Epoch: 48 | Iteration number: [1750/4518] 38% | Training loss: 0.6871851003170013
Epoch: 48 | Iteration number: [1760/4518] 38% | Training loss: 0.6871781421655958
Epoch: 48 | Iteration number: [1770/4518] 39% | Training loss: 0.6871824615082498
Epoch: 48 | Iteration number: [1780/4518] 39% | Training loss: 0.6871757160411792
Epoch: 48 | Iteration number: [1790/4518] 39% | Training loss: 0.6871812970278649
Epoch: 48 | Iteration number: [1800/4518] 39% | Training loss: 0.6871767091751099
Epoch: 48 | Iteration number: [1810/4518] 40% | Training loss: 0.6871798101709693
Epoch: 48 | Iteration number: [1820/4518] 40% | Training loss: 0.6871777649764176
Epoch: 48 | Iteration number: [1830/4518] 40% | Training loss: 0.6871826596924516
Epoch: 48 | Iteration number: [1840/4518] 40% | Training loss: 0.6871744068420451
Epoch: 48 | Iteration number: [1850/4518] 40% | Training loss: 0.6871702355629689
Epoch: 48 | Iteration number: [1860/4518] 41% | Training loss: 0.6871689791320472
Epoch: 48 | Iteration number: [1870/4518] 41% | Training loss: 0.687168418118023
Epoch: 48 | Iteration number: [1880/4518] 41% | Training loss: 0.6871704756579501
Epoch: 48 | Iteration number: [1890/4518] 41% | Training loss: 0.6871729148758783
Epoch: 48 | Iteration number: [1900/4518] 42% | Training loss: 0.6871751924564964
Epoch: 48 | Iteration number: [1910/4518] 42% | Training loss: 0.6871733007630753
Epoch: 48 | Iteration number: [1920/4518] 42% | Training loss: 0.6871771789776783
Epoch: 48 | Iteration number: [1930/4518] 42% | Training loss: 0.6871769191996421
Epoch: 48 | Iteration number: [1940/4518] 42% | Training loss: 0.6871690843830404
Epoch: 48 | Iteration number: [1950/4518] 43% | Training loss: 0.6871603529269878
Epoch: 48 | Iteration number: [1960/4518] 43% | Training loss: 0.6871609692366756
Epoch: 48 | Iteration number: [1970/4518] 43% | Training loss: 0.6871591297805612
Epoch: 48 | Iteration number: [1980/4518] 43% | Training loss: 0.6871592851600261
Epoch: 48 | Iteration number: [1990/4518] 44% | Training loss: 0.6871588056410977
Epoch: 48 | Iteration number: [2000/4518] 44% | Training loss: 0.6871563320457935
Epoch: 48 | Iteration number: [2010/4518] 44% | Training loss: 0.6871543925199936
Epoch: 48 | Iteration number: [2020/4518] 44% | Training loss: 0.68715397131325
Epoch: 48 | Iteration number: [2030/4518] 44% | Training loss: 0.6871527698239669
Epoch: 48 | Iteration number: [2040/4518] 45% | Training loss: 0.6871461519423653
Epoch: 48 | Iteration number: [2050/4518] 45% | Training loss: 0.6871403232725655
Epoch: 48 | Iteration number: [2060/4518] 45% | Training loss: 0.6871404296275482
Epoch: 48 | Iteration number: [2070/4518] 45% | Training loss: 0.6871337854343912
Epoch: 48 | Iteration number: [2080/4518] 46% | Training loss: 0.6871288120460052
Epoch: 48 | Iteration number: [2090/4518] 46% | Training loss: 0.6871253984111347
Epoch: 48 | Iteration number: [2100/4518] 46% | Training loss: 0.6871251076176053
Epoch: 48 | Iteration number: [2110/4518] 46% | Training loss: 0.6871203694580855
Epoch: 48 | Iteration number: [2120/4518] 46% | Training loss: 0.6871179217718683
Epoch: 48 | Iteration number: [2130/4518] 47% | Training loss: 0.6871201345898176
Epoch: 48 | Iteration number: [2140/4518] 47% | Training loss: 0.6871152355292133
Epoch: 48 | Iteration number: [2150/4518] 47% | Training loss: 0.6871174604948177
Epoch: 48 | Iteration number: [2160/4518] 47% | Training loss: 0.6871173712666387
Epoch: 48 | Iteration number: [2170/4518] 48% | Training loss: 0.6871125701385709
Epoch: 48 | Iteration number: [2180/4518] 48% | Training loss: 0.6871096054074961
Epoch: 48 | Iteration number: [2190/4518] 48% | Training loss: 0.6871063176355405
Epoch: 48 | Iteration number: [2200/4518] 48% | Training loss: 0.6871072715520858
Epoch: 48 | Iteration number: [2210/4518] 48% | Training loss: 0.6871075797404639
Epoch: 48 | Iteration number: [2220/4518] 49% | Training loss: 0.6871070781538079
Epoch: 48 | Iteration number: [2230/4518] 49% | Training loss: 0.6871108612672095
Epoch: 48 | Iteration number: [2240/4518] 49% | Training loss: 0.6871100854394692
Epoch: 48 | Iteration number: [2250/4518] 49% | Training loss: 0.6871122305658128
Epoch: 48 | Iteration number: [2260/4518] 50% | Training loss: 0.687112121587306
Epoch: 48 | Iteration number: [2270/4518] 50% | Training loss: 0.6871107303623586
Epoch: 48 | Iteration number: [2280/4518] 50% | Training loss: 0.6871037452890162
Epoch: 48 | Iteration number: [2290/4518] 50% | Training loss: 0.6871104410381816
Epoch: 48 | Iteration number: [2300/4518] 50% | Training loss: 0.6871111842601195
Epoch: 48 | Iteration number: [2310/4518] 51% | Training loss: 0.6871137548318673
Epoch: 48 | Iteration number: [2320/4518] 51% | Training loss: 0.6871089729255644
Epoch: 48 | Iteration number: [2330/4518] 51% | Training loss: 0.6871019866077686
Epoch: 48 | Iteration number: [2340/4518] 51% | Training loss: 0.6871016773912642
Epoch: 48 | Iteration number: [2350/4518] 52% | Training loss: 0.6870928467080948
Epoch: 48 | Iteration number: [2360/4518] 52% | Training loss: 0.6870922539951437
Epoch: 48 | Iteration number: [2370/4518] 52% | Training loss: 0.6870909764545376
Epoch: 48 | Iteration number: [2380/4518] 52% | Training loss: 0.6870913351032915
Epoch: 48 | Iteration number: [2390/4518] 52% | Training loss: 0.6870882922884809
Epoch: 48 | Iteration number: [2400/4518] 53% | Training loss: 0.687084454720219
Epoch: 48 | Iteration number: [2410/4518] 53% | Training loss: 0.6870806703429004
Epoch: 48 | Iteration number: [2420/4518] 53% | Training loss: 0.6870798422777948
Epoch: 48 | Iteration number: [2430/4518] 53% | Training loss: 0.6870778178972472
Epoch: 48 | Iteration number: [2440/4518] 54% | Training loss: 0.6870754061663737
Epoch: 48 | Iteration number: [2450/4518] 54% | Training loss: 0.687067658925543
Epoch: 48 | Iteration number: [2460/4518] 54% | Training loss: 0.687070158075511
Epoch: 48 | Iteration number: [2470/4518] 54% | Training loss: 0.6870686444676357
Epoch: 48 | Iteration number: [2480/4518] 54% | Training loss: 0.6870650475063632
Epoch: 48 | Iteration number: [2490/4518] 55% | Training loss: 0.6870648229696664
Epoch: 48 | Iteration number: [2500/4518] 55% | Training loss: 0.6870632608890533
Epoch: 48 | Iteration number: [2510/4518] 55% | Training loss: 0.6870671871173905
Epoch: 48 | Iteration number: [2520/4518] 55% | Training loss: 0.6870668595508923
Epoch: 48 | Iteration number: [2530/4518] 55% | Training loss: 0.6870670614035234
Epoch: 48 | Iteration number: [2540/4518] 56% | Training loss: 0.6870639789996185
Epoch: 48 | Iteration number: [2550/4518] 56% | Training loss: 0.6870635682227565
Epoch: 48 | Iteration number: [2560/4518] 56% | Training loss: 0.6870629974175244
Epoch: 48 | Iteration number: [2570/4518] 56% | Training loss: 0.6870592414868945
Epoch: 48 | Iteration number: [2580/4518] 57% | Training loss: 0.6870592993128207
Epoch: 48 | Iteration number: [2590/4518] 57% | Training loss: 0.6870570044029634
Epoch: 48 | Iteration number: [2600/4518] 57% | Training loss: 0.6870596949183024
Epoch: 48 | Iteration number: [2610/4518] 57% | Training loss: 0.6870610569628719
Epoch: 48 | Iteration number: [2620/4518] 57% | Training loss: 0.687064177776111
Epoch: 48 | Iteration number: [2630/4518] 58% | Training loss: 0.6870594676229891
Epoch: 48 | Iteration number: [2640/4518] 58% | Training loss: 0.6870584536456701
Epoch: 48 | Iteration number: [2650/4518] 58% | Training loss: 0.6870540327396033
Epoch: 48 | Iteration number: [2660/4518] 58% | Training loss: 0.6870554048540001
Epoch: 48 | Iteration number: [2670/4518] 59% | Training loss: 0.68705127388797
Epoch: 48 | Iteration number: [2680/4518] 59% | Training loss: 0.6870488633860403
Epoch: 48 | Iteration number: [2690/4518] 59% | Training loss: 0.6870508177572909
Epoch: 48 | Iteration number: [2700/4518] 59% | Training loss: 0.6870477086747134
Epoch: 48 | Iteration number: [2710/4518] 59% | Training loss: 0.6870458747188104
Epoch: 48 | Iteration number: [2720/4518] 60% | Training loss: 0.6870459932395641
Epoch: 48 | Iteration number: [2730/4518] 60% | Training loss: 0.6870433441011897
Epoch: 48 | Iteration number: [2740/4518] 60% | Training loss: 0.687045095458518
Epoch: 48 | Iteration number: [2750/4518] 60% | Training loss: 0.6870474741242149
Epoch: 48 | Iteration number: [2760/4518] 61% | Training loss: 0.687047057458456
Epoch: 48 | Iteration number: [2770/4518] 61% | Training loss: 0.6870506634350718
Epoch: 48 | Iteration number: [2780/4518] 61% | Training loss: 0.6870493462188638
Epoch: 48 | Iteration number: [2790/4518] 61% | Training loss: 0.6870473272484263
Epoch: 48 | Iteration number: [2800/4518] 61% | Training loss: 0.6870467066977706
Epoch: 48 | Iteration number: [2810/4518] 62% | Training loss: 0.6870419962126165
Epoch: 48 | Iteration number: [2820/4518] 62% | Training loss: 0.6870429578613728
Epoch: 48 | Iteration number: [2830/4518] 62% | Training loss: 0.6870418077644106
Epoch: 48 | Iteration number: [2840/4518] 62% | Training loss: 0.6870403142462314
Epoch: 48 | Iteration number: [2850/4518] 63% | Training loss: 0.6870390794360847
Epoch: 48 | Iteration number: [2860/4518] 63% | Training loss: 0.6870382173703267
Epoch: 48 | Iteration number: [2870/4518] 63% | Training loss: 0.6870422291423386
Epoch: 48 | Iteration number: [2880/4518] 63% | Training loss: 0.6870390553027391
Epoch: 48 | Iteration number: [2890/4518] 63% | Training loss: 0.6870374756700852
Epoch: 48 | Iteration number: [2900/4518] 64% | Training loss: 0.6870387110833464
Epoch: 48 | Iteration number: [2910/4518] 64% | Training loss: 0.6870351409584387
Epoch: 48 | Iteration number: [2920/4518] 64% | Training loss: 0.6870299530968275
Epoch: 48 | Iteration number: [2930/4518] 64% | Training loss: 0.6870317024379053
Epoch: 48 | Iteration number: [2940/4518] 65% | Training loss: 0.6870267226379745
Epoch: 48 | Iteration number: [2950/4518] 65% | Training loss: 0.6870256492849124
Epoch: 48 | Iteration number: [2960/4518] 65% | Training loss: 0.6870191531608234
Epoch: 48 | Iteration number: [2970/4518] 65% | Training loss: 0.6870204644572454
Epoch: 48 | Iteration number: [2980/4518] 65% | Training loss: 0.687021700847869
Epoch: 48 | Iteration number: [2990/4518] 66% | Training loss: 0.6870179886203944
Epoch: 48 | Iteration number: [3000/4518] 66% | Training loss: 0.6870162564118704
Epoch: 48 | Iteration number: [3010/4518] 66% | Training loss: 0.6870189866552321
Epoch: 48 | Iteration number: [3020/4518] 66% | Training loss: 0.6870203557788142
Epoch: 48 | Iteration number: [3030/4518] 67% | Training loss: 0.6870194760092808
Epoch: 48 | Iteration number: [3040/4518] 67% | Training loss: 0.6870245420030857
Epoch: 48 | Iteration number: [3050/4518] 67% | Training loss: 0.6870247218452517
Epoch: 48 | Iteration number: [3060/4518] 67% | Training loss: 0.6870239251384548
Epoch: 48 | Iteration number: [3070/4518] 67% | Training loss: 0.6870232768478145
Epoch: 48 | Iteration number: [3080/4518] 68% | Training loss: 0.6870199562280209
Epoch: 48 | Iteration number: [3090/4518] 68% | Training loss: 0.6870172175195997
Epoch: 48 | Iteration number: [3100/4518] 68% | Training loss: 0.6870187770935797
Epoch: 48 | Iteration number: [3110/4518] 68% | Training loss: 0.6870251208256295
Epoch: 48 | Iteration number: [3120/4518] 69% | Training loss: 0.6870185832755688
Epoch: 48 | Iteration number: [3130/4518] 69% | Training loss: 0.6870193260546309
Epoch: 48 | Iteration number: [3140/4518] 69% | Training loss: 0.6870212207744076
Epoch: 48 | Iteration number: [3150/4518] 69% | Training loss: 0.6870229458430457
Epoch: 48 | Iteration number: [3160/4518] 69% | Training loss: 0.6870232616044298
Epoch: 48 | Iteration number: [3170/4518] 70% | Training loss: 0.6870233097287006
Epoch: 48 | Iteration number: [3180/4518] 70% | Training loss: 0.6870201325641488
Epoch: 48 | Iteration number: [3190/4518] 70% | Training loss: 0.6870162481237728
Epoch: 48 | Iteration number: [3200/4518] 70% | Training loss: 0.6870192353054881
Epoch: 48 | Iteration number: [3210/4518] 71% | Training loss: 0.6870148555883366
Epoch: 48 | Iteration number: [3220/4518] 71% | Training loss: 0.687014939696152
Epoch: 48 | Iteration number: [3230/4518] 71% | Training loss: 0.6870127776274371
Epoch: 48 | Iteration number: [3240/4518] 71% | Training loss: 0.6870059398405346
Epoch: 48 | Iteration number: [3250/4518] 71% | Training loss: 0.6870055235349215
Epoch: 48 | Iteration number: [3260/4518] 72% | Training loss: 0.6870071614081142
Epoch: 48 | Iteration number: [3270/4518] 72% | Training loss: 0.6870077119325644
Epoch: 48 | Iteration number: [3280/4518] 72% | Training loss: 0.6870099527443327
Epoch: 48 | Iteration number: [3290/4518] 72% | Training loss: 0.6870092383271655
Epoch: 48 | Iteration number: [3300/4518] 73% | Training loss: 0.6870055550336838
Epoch: 48 | Iteration number: [3310/4518] 73% | Training loss: 0.6870060690220029
Epoch: 48 | Iteration number: [3320/4518] 73% | Training loss: 0.6870019662990627
Epoch: 48 | Iteration number: [3330/4518] 73% | Training loss: 0.6870019822686284
Epoch: 48 | Iteration number: [3340/4518] 73% | Training loss: 0.6869986157038969
Epoch: 48 | Iteration number: [3350/4518] 74% | Training loss: 0.6869968295275275
Epoch: 48 | Iteration number: [3360/4518] 74% | Training loss: 0.6869990270584821
Epoch: 48 | Iteration number: [3370/4518] 74% | Training loss: 0.686998470105474
Epoch: 48 | Iteration number: [3380/4518] 74% | Training loss: 0.6869998194762236
Epoch: 48 | Iteration number: [3390/4518] 75% | Training loss: 0.6870015406854736
Epoch: 48 | Iteration number: [3400/4518] 75% | Training loss: 0.6870049097082194
Epoch: 48 | Iteration number: [3410/4518] 75% | Training loss: 0.6870085095555202
Epoch: 48 | Iteration number: [3420/4518] 75% | Training loss: 0.6870083574663128
Epoch: 48 | Iteration number: [3430/4518] 75% | Training loss: 0.6870054806460445
Epoch: 48 | Iteration number: [3440/4518] 76% | Training loss: 0.6870036058994227
Epoch: 48 | Iteration number: [3450/4518] 76% | Training loss: 0.687005219615024
Epoch: 48 | Iteration number: [3460/4518] 76% | Training loss: 0.6870062004624075
Epoch: 48 | Iteration number: [3470/4518] 76% | Training loss: 0.6870100524995787
Epoch: 48 | Iteration number: [3480/4518] 77% | Training loss: 0.6870135835703762
Epoch: 48 | Iteration number: [3490/4518] 77% | Training loss: 0.6870159120306928
Epoch: 48 | Iteration number: [3500/4518] 77% | Training loss: 0.6870144617046628
Epoch: 48 | Iteration number: [3510/4518] 77% | Training loss: 0.6870136787748744
Epoch: 48 | Iteration number: [3520/4518] 77% | Training loss: 0.6870148420164531
Epoch: 48 | Iteration number: [3530/4518] 78% | Training loss: 0.6870172494025136
Epoch: 48 | Iteration number: [3540/4518] 78% | Training loss: 0.6870200948695006
Epoch: 48 | Iteration number: [3550/4518] 78% | Training loss: 0.6870160133905814
Epoch: 48 | Iteration number: [3560/4518] 78% | Training loss: 0.6870104116167915
Epoch: 48 | Iteration number: [3570/4518] 79% | Training loss: 0.6870108435801765
Epoch: 48 | Iteration number: [3580/4518] 79% | Training loss: 0.6870132023895253
Epoch: 48 | Iteration number: [3590/4518] 79% | Training loss: 0.6870136449928071
Epoch: 48 | Iteration number: [3600/4518] 79% | Training loss: 0.6870142276916239
Epoch: 48 | Iteration number: [3610/4518] 79% | Training loss: 0.6870119739437367
Epoch: 48 | Iteration number: [3620/4518] 80% | Training loss: 0.6870108346748088
Epoch: 48 | Iteration number: [3630/4518] 80% | Training loss: 0.6870107987531289
Epoch: 48 | Iteration number: [3640/4518] 80% | Training loss: 0.6870082324350273
Epoch: 48 | Iteration number: [3650/4518] 80% | Training loss: 0.6870069290677162
Epoch: 48 | Iteration number: [3660/4518] 81% | Training loss: 0.6870094892431478
Epoch: 48 | Iteration number: [3670/4518] 81% | Training loss: 0.6870054336594625
Epoch: 48 | Iteration number: [3680/4518] 81% | Training loss: 0.6869981282593115
Epoch: 48 | Iteration number: [3690/4518] 81% | Training loss: 0.6870021292510717
Epoch: 48 | Iteration number: [3700/4518] 81% | Training loss: 0.687002207540177
Epoch: 48 | Iteration number: [3710/4518] 82% | Training loss: 0.6870051116634893
Epoch: 48 | Iteration number: [3720/4518] 82% | Training loss: 0.6870056485617032
Epoch: 48 | Iteration number: [3730/4518] 82% | Training loss: 0.6870022747056413
Epoch: 48 | Iteration number: [3740/4518] 82% | Training loss: 0.6870003738345947
Epoch: 48 | Iteration number: [3750/4518] 83% | Training loss: 0.6869970075925191
Epoch: 48 | Iteration number: [3760/4518] 83% | Training loss: 0.6869981066343632
Epoch: 48 | Iteration number: [3770/4518] 83% | Training loss: 0.6869974467419186
Epoch: 48 | Iteration number: [3780/4518] 83% | Training loss: 0.6869970014328679
Epoch: 48 | Iteration number: [3790/4518] 83% | Training loss: 0.6869944464248214
Epoch: 48 | Iteration number: [3800/4518] 84% | Training loss: 0.686994407851445
Epoch: 48 | Iteration number: [3810/4518] 84% | Training loss: 0.686994384577268
Epoch: 48 | Iteration number: [3820/4518] 84% | Training loss: 0.6869922371746982
Epoch: 48 | Iteration number: [3830/4518] 84% | Training loss: 0.68699370151089
Epoch: 48 | Iteration number: [3840/4518] 84% | Training loss: 0.6869936541343729
Epoch: 48 | Iteration number: [3850/4518] 85% | Training loss: 0.6869940570112947
Epoch: 48 | Iteration number: [3860/4518] 85% | Training loss: 0.6869930576938421
Epoch: 48 | Iteration number: [3870/4518] 85% | Training loss: 0.6869935904054371
Epoch: 48 | Iteration number: [3880/4518] 85% | Training loss: 0.6869938094591357
Epoch: 48 | Iteration number: [3890/4518] 86% | Training loss: 0.6869949490521439
Epoch: 48 | Iteration number: [3900/4518] 86% | Training loss: 0.6869965464182389
Epoch: 48 | Iteration number: [3910/4518] 86% | Training loss: 0.686996409853401
Epoch: 48 | Iteration number: [3920/4518] 86% | Training loss: 0.6869945706153403
Epoch: 48 | Iteration number: [3930/4518] 86% | Training loss: 0.6869927829761845
Epoch: 48 | Iteration number: [3940/4518] 87% | Training loss: 0.6869912068402102
Epoch: 48 | Iteration number: [3950/4518] 87% | Training loss: 0.6869874461240406
Epoch: 48 | Iteration number: [3960/4518] 87% | Training loss: 0.686990986388139
Epoch: 48 | Iteration number: [3970/4518] 87% | Training loss: 0.6869899200101943
Epoch: 48 | Iteration number: [3980/4518] 88% | Training loss: 0.686989425879028
Epoch: 48 | Iteration number: [3990/4518] 88% | Training loss: 0.6869888114003012
Epoch: 48 | Iteration number: [4000/4518] 88% | Training loss: 0.6869868345111608
Epoch: 48 | Iteration number: [4010/4518] 88% | Training loss: 0.6869874681469211
Epoch: 48 | Iteration number: [4020/4518] 88% | Training loss: 0.6869882853766579
Epoch: 48 | Iteration number: [4030/4518] 89% | Training loss: 0.6869881613230883
Epoch: 48 | Iteration number: [4040/4518] 89% | Training loss: 0.686986946956356
Epoch: 48 | Iteration number: [4050/4518] 89% | Training loss: 0.68698433081309
Epoch: 48 | Iteration number: [4060/4518] 89% | Training loss: 0.6869846880582753
Epoch: 48 | Iteration number: [4070/4518] 90% | Training loss: 0.6869825672458958
Epoch: 48 | Iteration number: [4080/4518] 90% | Training loss: 0.6869827570722383
Epoch: 48 | Iteration number: [4090/4518] 90% | Training loss: 0.6869804142885512
Epoch: 48 | Iteration number: [4100/4518] 90% | Training loss: 0.6869781777480753
Epoch: 48 | Iteration number: [4110/4518] 90% | Training loss: 0.686978059368992
Epoch: 48 | Iteration number: [4120/4518] 91% | Training loss: 0.6869752402155145
Epoch: 48 | Iteration number: [4130/4518] 91% | Training loss: 0.6869721331838834
Epoch: 48 | Iteration number: [4140/4518] 91% | Training loss: 0.6869736829817583
Epoch: 48 | Iteration number: [4150/4518] 91% | Training loss: 0.6869717003782112
Epoch: 48 | Iteration number: [4160/4518] 92% | Training loss: 0.6869695868056555
Epoch: 48 | Iteration number: [4170/4518] 92% | Training loss: 0.6869695771226494
Epoch: 48 | Iteration number: [4180/4518] 92% | Training loss: 0.6869683002313358
Epoch: 48 | Iteration number: [4190/4518] 92% | Training loss: 0.6869715521329912
Epoch: 48 | Iteration number: [4200/4518] 92% | Training loss: 0.6869747674890927
Epoch: 48 | Iteration number: [4210/4518] 93% | Training loss: 0.6869749812077457
Epoch: 48 | Iteration number: [4220/4518] 93% | Training loss: 0.6869748462432934
Epoch: 48 | Iteration number: [4230/4518] 93% | Training loss: 0.6869741710083422
Epoch: 48 | Iteration number: [4240/4518] 93% | Training loss: 0.6869721274752661
Epoch: 48 | Iteration number: [4250/4518] 94% | Training loss: 0.6869727003153633
Epoch: 48 | Iteration number: [4260/4518] 94% | Training loss: 0.6869707420678206
Epoch: 48 | Iteration number: [4270/4518] 94% | Training loss: 0.6869698786623863
Epoch: 48 | Iteration number: [4280/4518] 94% | Training loss: 0.686972745222466
Epoch: 48 | Iteration number: [4290/4518] 94% | Training loss: 0.6869724124322683
Epoch: 48 | Iteration number: [4300/4518] 95% | Training loss: 0.6869742900271748
Epoch: 48 | Iteration number: [4310/4518] 95% | Training loss: 0.6869716241437155
Epoch: 48 | Iteration number: [4320/4518] 95% | Training loss: 0.6869722901119126
Epoch: 48 | Iteration number: [4330/4518] 95% | Training loss: 0.6869738058597882
Epoch: 48 | Iteration number: [4340/4518] 96% | Training loss: 0.6869780783142362
Epoch: 48 | Iteration number: [4350/4518] 96% | Training loss: 0.6869748585388579
Epoch: 48 | Iteration number: [4360/4518] 96% | Training loss: 0.6869734783648351
Epoch: 48 | Iteration number: [4370/4518] 96% | Training loss: 0.68697172972103
Epoch: 48 | Iteration number: [4380/4518] 96% | Training loss: 0.6869698363352039
Epoch: 48 | Iteration number: [4390/4518] 97% | Training loss: 0.6869676920846274
Epoch: 48 | Iteration number: [4400/4518] 97% | Training loss: 0.6869677944210443
Epoch: 48 | Iteration number: [4410/4518] 97% | Training loss: 0.6869652331145712
Epoch: 48 | Iteration number: [4420/4518] 97% | Training loss: 0.6869646633642291
Epoch: 48 | Iteration number: [4430/4518] 98% | Training loss: 0.6869673057280599
Epoch: 48 | Iteration number: [4440/4518] 98% | Training loss: 0.6869672359378488
Epoch: 48 | Iteration number: [4450/4518] 98% | Training loss: 0.6869645120722524
Epoch: 48 | Iteration number: [4460/4518] 98% | Training loss: 0.6869653813908453
Epoch: 48 | Iteration number: [4470/4518] 98% | Training loss: 0.6869648468441077
Epoch: 48 | Iteration number: [4480/4518] 99% | Training loss: 0.6869660354618515
Epoch: 48 | Iteration number: [4490/4518] 99% | Training loss: 0.6869641041171577
Epoch: 48 | Iteration number: [4500/4518] 99% | Training loss: 0.6869626547495524
Epoch: 48 | Iteration number: [4510/4518] 99% | Training loss: 0.6869611885489487

 End of epoch: 48 | Train Loss: 0.6868077343599414 | Training Time: 633 

 End of epoch: 48 | Eval Loss: 0.6897687486239842 | Evaluating Time: 17 
Epoch: 49 | Iteration number: [10/4518] 0% | Training loss: 0.7568796217441559
Epoch: 49 | Iteration number: [20/4518] 0% | Training loss: 0.7218875706195831
Epoch: 49 | Iteration number: [30/4518] 0% | Training loss: 0.7097607354323069
Epoch: 49 | Iteration number: [40/4518] 0% | Training loss: 0.7041302993893623
Epoch: 49 | Iteration number: [50/4518] 1% | Training loss: 0.7005334031581879
Epoch: 49 | Iteration number: [60/4518] 1% | Training loss: 0.698517859975497
Epoch: 49 | Iteration number: [70/4518] 1% | Training loss: 0.6968285313674382
Epoch: 49 | Iteration number: [80/4518] 1% | Training loss: 0.695476109534502
Epoch: 49 | Iteration number: [90/4518] 1% | Training loss: 0.694325617286894
Epoch: 49 | Iteration number: [100/4518] 2% | Training loss: 0.6935619056224823
Epoch: 49 | Iteration number: [110/4518] 2% | Training loss: 0.693079262971878
Epoch: 49 | Iteration number: [120/4518] 2% | Training loss: 0.6925737842917442
Epoch: 49 | Iteration number: [130/4518] 2% | Training loss: 0.6921293863883385
Epoch: 49 | Iteration number: [140/4518] 3% | Training loss: 0.6916860116379602
Epoch: 49 | Iteration number: [150/4518] 3% | Training loss: 0.6912834537029267
Epoch: 49 | Iteration number: [160/4518] 3% | Training loss: 0.6910655781626701
Epoch: 49 | Iteration number: [170/4518] 3% | Training loss: 0.6907936120734496
Epoch: 49 | Iteration number: [180/4518] 3% | Training loss: 0.6905184199412664
Epoch: 49 | Iteration number: [190/4518] 4% | Training loss: 0.6902791506365726
Epoch: 49 | Iteration number: [200/4518] 4% | Training loss: 0.6901021975278855
Epoch: 49 | Iteration number: [210/4518] 4% | Training loss: 0.68992727853003
Epoch: 49 | Iteration number: [220/4518] 4% | Training loss: 0.6898045753890818
Epoch: 49 | Iteration number: [230/4518] 5% | Training loss: 0.689651011902353
Epoch: 49 | Iteration number: [240/4518] 5% | Training loss: 0.689547319461902
Epoch: 49 | Iteration number: [250/4518] 5% | Training loss: 0.6894677455425262
Epoch: 49 | Iteration number: [260/4518] 5% | Training loss: 0.6893496742615333
Epoch: 49 | Iteration number: [270/4518] 5% | Training loss: 0.6892626667464221
Epoch: 49 | Iteration number: [280/4518] 6% | Training loss: 0.6891605885965484
Epoch: 49 | Iteration number: [290/4518] 6% | Training loss: 0.6890767611306289
Epoch: 49 | Iteration number: [300/4518] 6% | Training loss: 0.6889632467428843
Epoch: 49 | Iteration number: [310/4518] 6% | Training loss: 0.6888858056837512
Epoch: 49 | Iteration number: [320/4518] 7% | Training loss: 0.6888171438127756
Epoch: 49 | Iteration number: [330/4518] 7% | Training loss: 0.6887656737457623
Epoch: 49 | Iteration number: [340/4518] 7% | Training loss: 0.6887231491944369
Epoch: 49 | Iteration number: [350/4518] 7% | Training loss: 0.6886974428381238
Epoch: 49 | Iteration number: [360/4518] 7% | Training loss: 0.6886558709873094
Epoch: 49 | Iteration number: [370/4518] 8% | Training loss: 0.6886193170740798
Epoch: 49 | Iteration number: [380/4518] 8% | Training loss: 0.6885987717854349
Epoch: 49 | Iteration number: [390/4518] 8% | Training loss: 0.6885668873786926
Epoch: 49 | Iteration number: [400/4518] 8% | Training loss: 0.6885623624920845
Epoch: 49 | Iteration number: [410/4518] 9% | Training loss: 0.6885349792678181
Epoch: 49 | Iteration number: [420/4518] 9% | Training loss: 0.6885082918973197
Epoch: 49 | Iteration number: [430/4518] 9% | Training loss: 0.6884702521701191
Epoch: 49 | Iteration number: [440/4518] 9% | Training loss: 0.6884279302575371
Epoch: 49 | Iteration number: [450/4518] 9% | Training loss: 0.6883760268158383
Epoch: 49 | Iteration number: [460/4518] 10% | Training loss: 0.6883541192697442
Epoch: 49 | Iteration number: [470/4518] 10% | Training loss: 0.688312000163058
Epoch: 49 | Iteration number: [480/4518] 10% | Training loss: 0.6882927654931943
Epoch: 49 | Iteration number: [490/4518] 10% | Training loss: 0.688260815703139
Epoch: 49 | Iteration number: [500/4518] 11% | Training loss: 0.6882343723773956
Epoch: 49 | Iteration number: [510/4518] 11% | Training loss: 0.6881939596989576
Epoch: 49 | Iteration number: [520/4518] 11% | Training loss: 0.6881589048183882
Epoch: 49 | Iteration number: [530/4518] 11% | Training loss: 0.688147994594754
Epoch: 49 | Iteration number: [540/4518] 11% | Training loss: 0.6881424114659981
Epoch: 49 | Iteration number: [550/4518] 12% | Training loss: 0.6881278359889984
Epoch: 49 | Iteration number: [560/4518] 12% | Training loss: 0.6881050392985344
Epoch: 49 | Iteration number: [570/4518] 12% | Training loss: 0.6880961255023353
Epoch: 49 | Iteration number: [580/4518] 12% | Training loss: 0.6880767454361093
Epoch: 49 | Iteration number: [590/4518] 13% | Training loss: 0.6880257301411387
Epoch: 49 | Iteration number: [600/4518] 13% | Training loss: 0.688017447590828
Epoch: 49 | Iteration number: [610/4518] 13% | Training loss: 0.6879912366632556
Epoch: 49 | Iteration number: [620/4518] 13% | Training loss: 0.6879727518366229
Epoch: 49 | Iteration number: [630/4518] 13% | Training loss: 0.6879529547123682
Epoch: 49 | Iteration number: [640/4518] 14% | Training loss: 0.687949001044035
Epoch: 49 | Iteration number: [650/4518] 14% | Training loss: 0.6879390798165248
Epoch: 49 | Iteration number: [660/4518] 14% | Training loss: 0.6879208173715707
Epoch: 49 | Iteration number: [670/4518] 14% | Training loss: 0.687901047450393
Epoch: 49 | Iteration number: [680/4518] 15% | Training loss: 0.6878878845011487
Epoch: 49 | Iteration number: [690/4518] 15% | Training loss: 0.687881818111392
Epoch: 49 | Iteration number: [700/4518] 15% | Training loss: 0.687877842273031
Epoch: 49 | Iteration number: [710/4518] 15% | Training loss: 0.6878595480616664
Epoch: 49 | Iteration number: [720/4518] 15% | Training loss: 0.6878669307463698
Epoch: 49 | Iteration number: [730/4518] 16% | Training loss: 0.68784523051079
Epoch: 49 | Iteration number: [740/4518] 16% | Training loss: 0.6878389584051596
Epoch: 49 | Iteration number: [750/4518] 16% | Training loss: 0.6878097223440806
Epoch: 49 | Iteration number: [760/4518] 16% | Training loss: 0.6878045899303336
Epoch: 49 | Iteration number: [770/4518] 17% | Training loss: 0.6877876696648536
Epoch: 49 | Iteration number: [780/4518] 17% | Training loss: 0.6877749008245957
Epoch: 49 | Iteration number: [790/4518] 17% | Training loss: 0.6877535838869554
Epoch: 49 | Iteration number: [800/4518] 17% | Training loss: 0.6877441447973252
Epoch: 49 | Iteration number: [810/4518] 17% | Training loss: 0.687742695911431
Epoch: 49 | Iteration number: [820/4518] 18% | Training loss: 0.6877278564906701
Epoch: 49 | Iteration number: [830/4518] 18% | Training loss: 0.6877143414623766
Epoch: 49 | Iteration number: [840/4518] 18% | Training loss: 0.6876770103971164
Epoch: 49 | Iteration number: [850/4518] 18% | Training loss: 0.687675873041153
Epoch: 49 | Iteration number: [860/4518] 19% | Training loss: 0.6876610785722732
Epoch: 49 | Iteration number: [870/4518] 19% | Training loss: 0.6876526931921642
Epoch: 49 | Iteration number: [880/4518] 19% | Training loss: 0.6876441367647864
Epoch: 49 | Iteration number: [890/4518] 19% | Training loss: 0.6876487180088343
Epoch: 49 | Iteration number: [900/4518] 19% | Training loss: 0.6876407868332333
Epoch: 49 | Iteration number: [910/4518] 20% | Training loss: 0.6876368681808095
Epoch: 49 | Iteration number: [920/4518] 20% | Training loss: 0.6876163118559381
Epoch: 49 | Iteration number: [930/4518] 20% | Training loss: 0.6876187230310132
Epoch: 49 | Iteration number: [940/4518] 20% | Training loss: 0.6876122943264373
Epoch: 49 | Iteration number: [950/4518] 21% | Training loss: 0.6876059156342557
Epoch: 49 | Iteration number: [960/4518] 21% | Training loss: 0.6875892059877515
Epoch: 49 | Iteration number: [970/4518] 21% | Training loss: 0.6875810505188618
Epoch: 49 | Iteration number: [980/4518] 21% | Training loss: 0.687576062460335
Epoch: 49 | Iteration number: [990/4518] 21% | Training loss: 0.6875643956540811
Epoch: 49 | Iteration number: [1000/4518] 22% | Training loss: 0.6875541861057282
Epoch: 49 | Iteration number: [1010/4518] 22% | Training loss: 0.6875572340323193
Epoch: 49 | Iteration number: [1020/4518] 22% | Training loss: 0.6875508268674214
Epoch: 49 | Iteration number: [1030/4518] 22% | Training loss: 0.6875466660967151
Epoch: 49 | Iteration number: [1040/4518] 23% | Training loss: 0.6875343361153052
Epoch: 49 | Iteration number: [1050/4518] 23% | Training loss: 0.6875300842807407
Epoch: 49 | Iteration number: [1060/4518] 23% | Training loss: 0.6875117401469428
Epoch: 49 | Iteration number: [1070/4518] 23% | Training loss: 0.6875130751422632
Epoch: 49 | Iteration number: [1080/4518] 23% | Training loss: 0.6875049835553876
Epoch: 49 | Iteration number: [1090/4518] 24% | Training loss: 0.6875036365395292
Epoch: 49 | Iteration number: [1100/4518] 24% | Training loss: 0.6875104371526024
Epoch: 49 | Iteration number: [1110/4518] 24% | Training loss: 0.6874908451561456
Epoch: 49 | Iteration number: [1120/4518] 24% | Training loss: 0.6874843917787075
Epoch: 49 | Iteration number: [1130/4518] 25% | Training loss: 0.687486400751941
Epoch: 49 | Iteration number: [1140/4518] 25% | Training loss: 0.6874935805274729
Epoch: 49 | Iteration number: [1150/4518] 25% | Training loss: 0.6874953109285106
Epoch: 49 | Iteration number: [1160/4518] 25% | Training loss: 0.6874849386256316
Epoch: 49 | Iteration number: [1170/4518] 25% | Training loss: 0.6874834308257469
Epoch: 49 | Iteration number: [1180/4518] 26% | Training loss: 0.6874790557865369
Epoch: 49 | Iteration number: [1190/4518] 26% | Training loss: 0.6874699394742981
Epoch: 49 | Iteration number: [1200/4518] 26% | Training loss: 0.6874622659385204
Epoch: 49 | Iteration number: [1210/4518] 26% | Training loss: 0.6874529344976441
Epoch: 49 | Iteration number: [1220/4518] 27% | Training loss: 0.687445306582529
Epoch: 49 | Iteration number: [1230/4518] 27% | Training loss: 0.687439119476613
Epoch: 49 | Iteration number: [1240/4518] 27% | Training loss: 0.6874357439817921
Epoch: 49 | Iteration number: [1250/4518] 27% | Training loss: 0.6874299919605256
Epoch: 49 | Iteration number: [1260/4518] 27% | Training loss: 0.6874274524904432
Epoch: 49 | Iteration number: [1270/4518] 28% | Training loss: 0.6874206154365239
Epoch: 49 | Iteration number: [1280/4518] 28% | Training loss: 0.6874191098380834
Epoch: 49 | Iteration number: [1290/4518] 28% | Training loss: 0.6874094983866048
Epoch: 49 | Iteration number: [1300/4518] 28% | Training loss: 0.6874071971728252
Epoch: 49 | Iteration number: [1310/4518] 28% | Training loss: 0.6873988435013604
Epoch: 49 | Iteration number: [1320/4518] 29% | Training loss: 0.6873965372641881
Epoch: 49 | Iteration number: [1330/4518] 29% | Training loss: 0.6873887707416276
Epoch: 49 | Iteration number: [1340/4518] 29% | Training loss: 0.6873912996765393
Epoch: 49 | Iteration number: [1350/4518] 29% | Training loss: 0.6873882844713
Epoch: 49 | Iteration number: [1360/4518] 30% | Training loss: 0.6873847594594255
Epoch: 49 | Iteration number: [1370/4518] 30% | Training loss: 0.6873785382639752
Epoch: 49 | Iteration number: [1380/4518] 30% | Training loss: 0.6873736445886501
Epoch: 49 | Iteration number: [1390/4518] 30% | Training loss: 0.6873689521130898
Epoch: 49 | Iteration number: [1400/4518] 30% | Training loss: 0.687371920645237
Epoch: 49 | Iteration number: [1410/4518] 31% | Training loss: 0.6873655210995505
Epoch: 49 | Iteration number: [1420/4518] 31% | Training loss: 0.6873690575781003
Epoch: 49 | Iteration number: [1430/4518] 31% | Training loss: 0.6873602748333991
Epoch: 49 | Iteration number: [1440/4518] 31% | Training loss: 0.6873587425798178
Epoch: 49 | Iteration number: [1450/4518] 32% | Training loss: 0.6873619744284399
Epoch: 49 | Iteration number: [1460/4518] 32% | Training loss: 0.6873571736763602
Epoch: 49 | Iteration number: [1470/4518] 32% | Training loss: 0.6873504101419124
Epoch: 49 | Iteration number: [1480/4518] 32% | Training loss: 0.687341852526407
Epoch: 49 | Iteration number: [1490/4518] 32% | Training loss: 0.6873375182183797
Epoch: 49 | Iteration number: [1500/4518] 33% | Training loss: 0.6873385331630707
Epoch: 49 | Iteration number: [1510/4518] 33% | Training loss: 0.687330137814907
Epoch: 49 | Iteration number: [1520/4518] 33% | Training loss: 0.6873202401164331
Epoch: 49 | Iteration number: [1530/4518] 33% | Training loss: 0.687321046949212
Epoch: 49 | Iteration number: [1540/4518] 34% | Training loss: 0.6873205717507895
Epoch: 49 | Iteration number: [1550/4518] 34% | Training loss: 0.6873240823899546
Epoch: 49 | Iteration number: [1560/4518] 34% | Training loss: 0.6873205686991032
Epoch: 49 | Iteration number: [1570/4518] 34% | Training loss: 0.6873152236270297
Epoch: 49 | Iteration number: [1580/4518] 34% | Training loss: 0.687315153622929
Epoch: 49 | Iteration number: [1590/4518] 35% | Training loss: 0.6873104863571671
Epoch: 49 | Iteration number: [1600/4518] 35% | Training loss: 0.6873072856292128
Epoch: 49 | Iteration number: [1610/4518] 35% | Training loss: 0.6873043574161412
Epoch: 49 | Iteration number: [1620/4518] 35% | Training loss: 0.6873001380835051
Epoch: 49 | Iteration number: [1630/4518] 36% | Training loss: 0.6872999550374739
Epoch: 49 | Iteration number: [1640/4518] 36% | Training loss: 0.6872910860471609
Epoch: 49 | Iteration number: [1650/4518] 36% | Training loss: 0.6872928098115054
Epoch: 49 | Iteration number: [1660/4518] 36% | Training loss: 0.687288672701422
Epoch: 49 | Iteration number: [1670/4518] 36% | Training loss: 0.687284854714742
Epoch: 49 | Iteration number: [1680/4518] 37% | Training loss: 0.6872826374357655
Epoch: 49 | Iteration number: [1690/4518] 37% | Training loss: 0.6872791284287469
Epoch: 49 | Iteration number: [1700/4518] 37% | Training loss: 0.6872752727831111
Epoch: 49 | Iteration number: [1710/4518] 37% | Training loss: 0.6872771048057846
Epoch: 49 | Iteration number: [1720/4518] 38% | Training loss: 0.6872736682725508
Epoch: 49 | Iteration number: [1730/4518] 38% | Training loss: 0.6872646286997491
Epoch: 49 | Iteration number: [1740/4518] 38% | Training loss: 0.6872718112564635
Epoch: 49 | Iteration number: [1750/4518] 38% | Training loss: 0.6872716906070709
Epoch: 49 | Iteration number: [1760/4518] 38% | Training loss: 0.6872713652524081
Epoch: 49 | Iteration number: [1770/4518] 39% | Training loss: 0.687263455465015
Epoch: 49 | Iteration number: [1780/4518] 39% | Training loss: 0.687264340915037
Epoch: 49 | Iteration number: [1790/4518] 39% | Training loss: 0.6872560958622554
Epoch: 49 | Iteration number: [1800/4518] 39% | Training loss: 0.6872544264793397
Epoch: 49 | Iteration number: [1810/4518] 40% | Training loss: 0.6872519698261556
Epoch: 49 | Iteration number: [1820/4518] 40% | Training loss: 0.6872488005803181
Epoch: 49 | Iteration number: [1830/4518] 40% | Training loss: 0.6872460422620096
Epoch: 49 | Iteration number: [1840/4518] 40% | Training loss: 0.6872464121683785
Epoch: 49 | Iteration number: [1850/4518] 40% | Training loss: 0.6872475022238654
Epoch: 49 | Iteration number: [1860/4518] 41% | Training loss: 0.6872414117218346
Epoch: 49 | Iteration number: [1870/4518] 41% | Training loss: 0.6872404653758288
Epoch: 49 | Iteration number: [1880/4518] 41% | Training loss: 0.6872413958640808
Epoch: 49 | Iteration number: [1890/4518] 41% | Training loss: 0.6872393128102419
Epoch: 49 | Iteration number: [1900/4518] 42% | Training loss: 0.6872409283173712
Epoch: 49 | Iteration number: [1910/4518] 42% | Training loss: 0.6872414215072912
Epoch: 49 | Iteration number: [1920/4518] 42% | Training loss: 0.6872354874076942
Epoch: 49 | Iteration number: [1930/4518] 42% | Training loss: 0.6872384476229317
Epoch: 49 | Iteration number: [1940/4518] 42% | Training loss: 0.687232939392021
Epoch: 49 | Iteration number: [1950/4518] 43% | Training loss: 0.68723233965727
Epoch: 49 | Iteration number: [1960/4518] 43% | Training loss: 0.6872350909272019
Epoch: 49 | Iteration number: [1970/4518] 43% | Training loss: 0.687231626819233
Epoch: 49 | Iteration number: [1980/4518] 43% | Training loss: 0.6872222102350659
Epoch: 49 | Iteration number: [1990/4518] 44% | Training loss: 0.6872087404057009
Epoch: 49 | Iteration number: [2000/4518] 44% | Training loss: 0.6872071577310562
Epoch: 49 | Iteration number: [2010/4518] 44% | Training loss: 0.6872043093638633
Epoch: 49 | Iteration number: [2020/4518] 44% | Training loss: 0.6872000369990227
Epoch: 49 | Iteration number: [2030/4518] 44% | Training loss: 0.6871932769056611
Epoch: 49 | Iteration number: [2040/4518] 45% | Training loss: 0.687187868970282
Epoch: 49 | Iteration number: [2050/4518] 45% | Training loss: 0.6871878296282233
Epoch: 49 | Iteration number: [2060/4518] 45% | Training loss: 0.6871882753754125
Epoch: 49 | Iteration number: [2070/4518] 45% | Training loss: 0.6871798570893237
Epoch: 49 | Iteration number: [2080/4518] 46% | Training loss: 0.6871800154447556
Epoch: 49 | Iteration number: [2090/4518] 46% | Training loss: 0.687181832231403
Epoch: 49 | Iteration number: [2100/4518] 46% | Training loss: 0.6871799615735099
Epoch: 49 | Iteration number: [2110/4518] 46% | Training loss: 0.6871783346361459
Epoch: 49 | Iteration number: [2120/4518] 46% | Training loss: 0.6871763814732713
Epoch: 49 | Iteration number: [2130/4518] 47% | Training loss: 0.6871813473287323
Epoch: 49 | Iteration number: [2140/4518] 47% | Training loss: 0.6871800346073703
Epoch: 49 | Iteration number: [2150/4518] 47% | Training loss: 0.6871749542757523
Epoch: 49 | Iteration number: [2160/4518] 47% | Training loss: 0.6871671398204786
Epoch: 49 | Iteration number: [2170/4518] 48% | Training loss: 0.687161010558704
Epoch: 49 | Iteration number: [2180/4518] 48% | Training loss: 0.6871552451488074
Epoch: 49 | Iteration number: [2190/4518] 48% | Training loss: 0.6871487388055618
Epoch: 49 | Iteration number: [2200/4518] 48% | Training loss: 0.6871450132944367
Epoch: 49 | Iteration number: [2210/4518] 48% | Training loss: 0.687141093220646
Epoch: 49 | Iteration number: [2220/4518] 49% | Training loss: 0.687138865096075
Epoch: 49 | Iteration number: [2230/4518] 49% | Training loss: 0.6871393668811953
Epoch: 49 | Iteration number: [2240/4518] 49% | Training loss: 0.6871407813259534
Epoch: 49 | Iteration number: [2250/4518] 49% | Training loss: 0.6871407391230265
Epoch: 49 | Iteration number: [2260/4518] 50% | Training loss: 0.6871412468167533
Epoch: 49 | Iteration number: [2270/4518] 50% | Training loss: 0.6871332817403231
Epoch: 49 | Iteration number: [2280/4518] 50% | Training loss: 0.6871339402700726
Epoch: 49 | Iteration number: [2290/4518] 50% | Training loss: 0.6871327452524261
Epoch: 49 | Iteration number: [2300/4518] 50% | Training loss: 0.6871278558606687
Epoch: 49 | Iteration number: [2310/4518] 51% | Training loss: 0.6871238168441888
Epoch: 49 | Iteration number: [2320/4518] 51% | Training loss: 0.6871240128730906
Epoch: 49 | Iteration number: [2330/4518] 51% | Training loss: 0.6871229872171459
Epoch: 49 | Iteration number: [2340/4518] 51% | Training loss: 0.6871229528361915
Epoch: 49 | Iteration number: [2350/4518] 52% | Training loss: 0.6871249170252617
Epoch: 49 | Iteration number: [2360/4518] 52% | Training loss: 0.6871276338221664
Epoch: 49 | Iteration number: [2370/4518] 52% | Training loss: 0.687125140856087
Epoch: 49 | Iteration number: [2380/4518] 52% | Training loss: 0.6871240067131379
Epoch: 49 | Iteration number: [2390/4518] 52% | Training loss: 0.687120157629875
Epoch: 49 | Iteration number: [2400/4518] 53% | Training loss: 0.6871162924667199
Epoch: 49 | Iteration number: [2410/4518] 53% | Training loss: 0.6871127707829614
Epoch: 49 | Iteration number: [2420/4518] 53% | Training loss: 0.687110140451715
Epoch: 49 | Iteration number: [2430/4518] 53% | Training loss: 0.6871105909592821
Epoch: 49 | Iteration number: [2440/4518] 54% | Training loss: 0.6871065238215884
Epoch: 49 | Iteration number: [2450/4518] 54% | Training loss: 0.6871068131680391
Epoch: 49 | Iteration number: [2460/4518] 54% | Training loss: 0.6871050391982242
Epoch: 49 | Iteration number: [2470/4518] 54% | Training loss: 0.6871060902531813
Epoch: 49 | Iteration number: [2480/4518] 54% | Training loss: 0.6871067867884713
Epoch: 49 | Iteration number: [2490/4518] 55% | Training loss: 0.6871058387928698
Epoch: 49 | Iteration number: [2500/4518] 55% | Training loss: 0.6871008137226104
Epoch: 49 | Iteration number: [2510/4518] 55% | Training loss: 0.6871034455251883
Epoch: 49 | Iteration number: [2520/4518] 55% | Training loss: 0.6870996443052141
Epoch: 49 | Iteration number: [2530/4518] 55% | Training loss: 0.6870932247563313
Epoch: 49 | Iteration number: [2540/4518] 56% | Training loss: 0.6870909332290409
Epoch: 49 | Iteration number: [2550/4518] 56% | Training loss: 0.6870890465203453
Epoch: 49 | Iteration number: [2560/4518] 56% | Training loss: 0.6870855315588414
Epoch: 49 | Iteration number: [2570/4518] 56% | Training loss: 0.6870874579778441
Epoch: 49 | Iteration number: [2580/4518] 57% | Training loss: 0.6870815449906874
Epoch: 49 | Iteration number: [2590/4518] 57% | Training loss: 0.6870799599006829
Epoch: 49 | Iteration number: [2600/4518] 57% | Training loss: 0.6870773150141423
Epoch: 49 | Iteration number: [2610/4518] 57% | Training loss: 0.6870778683044901
Epoch: 49 | Iteration number: [2620/4518] 57% | Training loss: 0.6870824031474936
Epoch: 49 | Iteration number: [2630/4518] 58% | Training loss: 0.6870803097808316
Epoch: 49 | Iteration number: [2640/4518] 58% | Training loss: 0.6870798104414434
Epoch: 49 | Iteration number: [2650/4518] 58% | Training loss: 0.6870799212410765
Epoch: 49 | Iteration number: [2660/4518] 58% | Training loss: 0.6870755421263831
Epoch: 49 | Iteration number: [2670/4518] 59% | Training loss: 0.6870761952150181
Epoch: 49 | Iteration number: [2680/4518] 59% | Training loss: 0.6870787383015476
Epoch: 49 | Iteration number: [2690/4518] 59% | Training loss: 0.6870748756543411
Epoch: 49 | Iteration number: [2700/4518] 59% | Training loss: 0.6870716908242968
Epoch: 49 | Iteration number: [2710/4518] 59% | Training loss: 0.6870680176903841
Epoch: 49 | Iteration number: [2720/4518] 60% | Training loss: 0.6870684032931047
Epoch: 49 | Iteration number: [2730/4518] 60% | Training loss: 0.6870694250414223
Epoch: 49 | Iteration number: [2740/4518] 60% | Training loss: 0.6870711488227774
Epoch: 49 | Iteration number: [2750/4518] 60% | Training loss: 0.6870674604285847
Epoch: 49 | Iteration number: [2760/4518] 61% | Training loss: 0.687062190991381
Epoch: 49 | Iteration number: [2770/4518] 61% | Training loss: 0.6870626953319522
Epoch: 49 | Iteration number: [2780/4518] 61% | Training loss: 0.6870541326004824
Epoch: 49 | Iteration number: [2790/4518] 61% | Training loss: 0.6870511455988798
Epoch: 49 | Iteration number: [2800/4518] 61% | Training loss: 0.6870466208032199
Epoch: 49 | Iteration number: [2810/4518] 62% | Training loss: 0.6870430163429301
Epoch: 49 | Iteration number: [2820/4518] 62% | Training loss: 0.6870431727340035
Epoch: 49 | Iteration number: [2830/4518] 62% | Training loss: 0.6870431816409418
Epoch: 49 | Iteration number: [2840/4518] 62% | Training loss: 0.6870377939771598
Epoch: 49 | Iteration number: [2850/4518] 63% | Training loss: 0.6870372951867287
Epoch: 49 | Iteration number: [2860/4518] 63% | Training loss: 0.6870359913452522
Epoch: 49 | Iteration number: [2870/4518] 63% | Training loss: 0.6870384456180945
Epoch: 49 | Iteration number: [2880/4518] 63% | Training loss: 0.6870435215739741
Epoch: 49 | Iteration number: [2890/4518] 63% | Training loss: 0.687041108975361
Epoch: 49 | Iteration number: [2900/4518] 64% | Training loss: 0.6870406713567931
Epoch: 49 | Iteration number: [2910/4518] 64% | Training loss: 0.6870459601846347
Epoch: 49 | Iteration number: [2920/4518] 64% | Training loss: 0.6870440871748206
Epoch: 49 | Iteration number: [2930/4518] 64% | Training loss: 0.6870439822763307
Epoch: 49 | Iteration number: [2940/4518] 65% | Training loss: 0.6870411884419773
Epoch: 49 | Iteration number: [2950/4518] 65% | Training loss: 0.6870403494673261
Epoch: 49 | Iteration number: [2960/4518] 65% | Training loss: 0.6870361783617251
Epoch: 49 | Iteration number: [2970/4518] 65% | Training loss: 0.6870307719667351
Epoch: 49 | Iteration number: [2980/4518] 65% | Training loss: 0.6870316102200706
Epoch: 49 | Iteration number: [2990/4518] 66% | Training loss: 0.6870305244340545
Epoch: 49 | Iteration number: [3000/4518] 66% | Training loss: 0.6870267211397489
Epoch: 49 | Iteration number: [3010/4518] 66% | Training loss: 0.6870272463144258
Epoch: 49 | Iteration number: [3020/4518] 66% | Training loss: 0.6870296812807487
Epoch: 49 | Iteration number: [3030/4518] 67% | Training loss: 0.6870251290082144
Epoch: 49 | Iteration number: [3040/4518] 67% | Training loss: 0.6870285656695303
Epoch: 49 | Iteration number: [3050/4518] 67% | Training loss: 0.6870322809844721
Epoch: 49 | Iteration number: [3060/4518] 67% | Training loss: 0.6870326168007321
Epoch: 49 | Iteration number: [3070/4518] 67% | Training loss: 0.6870337933981457
Epoch: 49 | Iteration number: [3080/4518] 68% | Training loss: 0.6870308796500231
Epoch: 49 | Iteration number: [3090/4518] 68% | Training loss: 0.687029910434797
Epoch: 49 | Iteration number: [3100/4518] 68% | Training loss: 0.687029712776984
Epoch: 49 | Iteration number: [3110/4518] 68% | Training loss: 0.6870259172855083
Epoch: 49 | Iteration number: [3120/4518] 69% | Training loss: 0.687024352986079
Epoch: 49 | Iteration number: [3130/4518] 69% | Training loss: 0.6870249304146813
Epoch: 49 | Iteration number: [3140/4518] 69% | Training loss: 0.6870263818722622
Epoch: 49 | Iteration number: [3150/4518] 69% | Training loss: 0.6870237368439871
Epoch: 49 | Iteration number: [3160/4518] 69% | Training loss: 0.6870188050066368
Epoch: 49 | Iteration number: [3170/4518] 70% | Training loss: 0.6870138676572674
Epoch: 49 | Iteration number: [3180/4518] 70% | Training loss: 0.6870084229317851
Epoch: 49 | Iteration number: [3190/4518] 70% | Training loss: 0.6870111596061145
Epoch: 49 | Iteration number: [3200/4518] 70% | Training loss: 0.687012455444783
Epoch: 49 | Iteration number: [3210/4518] 71% | Training loss: 0.687012840895638
Epoch: 49 | Iteration number: [3220/4518] 71% | Training loss: 0.6870103164489225
Epoch: 49 | Iteration number: [3230/4518] 71% | Training loss: 0.6870053795469065
Epoch: 49 | Iteration number: [3240/4518] 71% | Training loss: 0.6870051620367132
Epoch: 49 | Iteration number: [3250/4518] 71% | Training loss: 0.6870027812811045
Epoch: 49 | Iteration number: [3260/4518] 72% | Training loss: 0.6870018870369788
Epoch: 49 | Iteration number: [3270/4518] 72% | Training loss: 0.6870034572181352
Epoch: 49 | Iteration number: [3280/4518] 72% | Training loss: 0.6870030290469891
Epoch: 49 | Iteration number: [3290/4518] 72% | Training loss: 0.6869975118832747
Epoch: 49 | Iteration number: [3300/4518] 73% | Training loss: 0.6870027060400355
Epoch: 49 | Iteration number: [3310/4518] 73% | Training loss: 0.6870019054124723
Epoch: 49 | Iteration number: [3320/4518] 73% | Training loss: 0.687006306612348
Epoch: 49 | Iteration number: [3330/4518] 73% | Training loss: 0.6870110018475277
Epoch: 49 | Iteration number: [3340/4518] 73% | Training loss: 0.6870096971353371
Epoch: 49 | Iteration number: [3350/4518] 74% | Training loss: 0.6870137225336104
Epoch: 49 | Iteration number: [3360/4518] 74% | Training loss: 0.687013214684668
Epoch: 49 | Iteration number: [3370/4518] 74% | Training loss: 0.6870180704827125
Epoch: 49 | Iteration number: [3380/4518] 74% | Training loss: 0.6870163136861733
Epoch: 49 | Iteration number: [3390/4518] 75% | Training loss: 0.6870164238773616
Epoch: 49 | Iteration number: [3400/4518] 75% | Training loss: 0.6870190721925568
Epoch: 49 | Iteration number: [3410/4518] 75% | Training loss: 0.6870197244228855
Epoch: 49 | Iteration number: [3420/4518] 75% | Training loss: 0.6870192424595705
Epoch: 49 | Iteration number: [3430/4518] 75% | Training loss: 0.687018821208192
Epoch: 49 | Iteration number: [3440/4518] 76% | Training loss: 0.6870206316023372
Epoch: 49 | Iteration number: [3450/4518] 76% | Training loss: 0.6870222907308219
Epoch: 49 | Iteration number: [3460/4518] 76% | Training loss: 0.6870210749910057
Epoch: 49 | Iteration number: [3470/4518] 76% | Training loss: 0.6870207865403091
Epoch: 49 | Iteration number: [3480/4518] 77% | Training loss: 0.6870186779519607
Epoch: 49 | Iteration number: [3490/4518] 77% | Training loss: 0.6870194083981664
Epoch: 49 | Iteration number: [3500/4518] 77% | Training loss: 0.6870207562616893
Epoch: 49 | Iteration number: [3510/4518] 77% | Training loss: 0.6870191559322879
Epoch: 49 | Iteration number: [3520/4518] 77% | Training loss: 0.6870221018113873
Epoch: 49 | Iteration number: [3530/4518] 78% | Training loss: 0.6870265888931393
Epoch: 49 | Iteration number: [3540/4518] 78% | Training loss: 0.6870270501085594
Epoch: 49 | Iteration number: [3550/4518] 78% | Training loss: 0.6870272407061617
Epoch: 49 | Iteration number: [3560/4518] 78% | Training loss: 0.6870226628492387
Epoch: 49 | Iteration number: [3570/4518] 79% | Training loss: 0.6870183477548658
Epoch: 49 | Iteration number: [3580/4518] 79% | Training loss: 0.6870189423834145
Epoch: 49 | Iteration number: [3590/4518] 79% | Training loss: 0.6870183617125647
Epoch: 49 | Iteration number: [3600/4518] 79% | Training loss: 0.6870180013941394
Epoch: 49 | Iteration number: [3610/4518] 79% | Training loss: 0.6870193829661921
Epoch: 49 | Iteration number: [3620/4518] 80% | Training loss: 0.6870213177981298
Epoch: 49 | Iteration number: [3630/4518] 80% | Training loss: 0.6870229488726162
Epoch: 49 | Iteration number: [3640/4518] 80% | Training loss: 0.6870248408435465
Epoch: 49 | Iteration number: [3650/4518] 80% | Training loss: 0.6870273531626349
Epoch: 49 | Iteration number: [3660/4518] 81% | Training loss: 0.6870264922171994
Epoch: 49 | Iteration number: [3670/4518] 81% | Training loss: 0.6870245775669732
Epoch: 49 | Iteration number: [3680/4518] 81% | Training loss: 0.6870223790245211
Epoch: 49 | Iteration number: [3690/4518] 81% | Training loss: 0.6870229442914327
Epoch: 49 | Iteration number: [3700/4518] 81% | Training loss: 0.6870199072038805
Epoch: 49 | Iteration number: [3710/4518] 82% | Training loss: 0.687018303874368
Epoch: 49 | Iteration number: [3720/4518] 82% | Training loss: 0.6870164229824979
Epoch: 49 | Iteration number: [3730/4518] 82% | Training loss: 0.6870191874996268
Epoch: 49 | Iteration number: [3740/4518] 82% | Training loss: 0.6870146966394893
Epoch: 49 | Iteration number: [3750/4518] 83% | Training loss: 0.6870147235870361
Epoch: 49 | Iteration number: [3760/4518] 83% | Training loss: 0.6870157350568061
Epoch: 49 | Iteration number: [3770/4518] 83% | Training loss: 0.6870182359566422
Epoch: 49 | Iteration number: [3780/4518] 83% | Training loss: 0.6870172187134072
Epoch: 49 | Iteration number: [3790/4518] 83% | Training loss: 0.6870158658335894
Epoch: 49 | Iteration number: [3800/4518] 84% | Training loss: 0.6870164326617593
Epoch: 49 | Iteration number: [3810/4518] 84% | Training loss: 0.6870170606715785
Epoch: 49 | Iteration number: [3820/4518] 84% | Training loss: 0.6870157890762958
Epoch: 49 | Iteration number: [3830/4518] 84% | Training loss: 0.687016349486209
Epoch: 49 | Iteration number: [3840/4518] 84% | Training loss: 0.687013812083751
Epoch: 49 | Iteration number: [3850/4518] 85% | Training loss: 0.6870149520000854
Epoch: 49 | Iteration number: [3860/4518] 85% | Training loss: 0.6870156839258312
Epoch: 49 | Iteration number: [3870/4518] 85% | Training loss: 0.6870171753011008
Epoch: 49 | Iteration number: [3880/4518] 85% | Training loss: 0.6870152397714939
Epoch: 49 | Iteration number: [3890/4518] 86% | Training loss: 0.6870142030532072
Epoch: 49 | Iteration number: [3900/4518] 86% | Training loss: 0.6870141280767245
Epoch: 49 | Iteration number: [3910/4518] 86% | Training loss: 0.6870140863196624
Epoch: 49 | Iteration number: [3920/4518] 86% | Training loss: 0.6870144270664575
Epoch: 49 | Iteration number: [3930/4518] 86% | Training loss: 0.6870133329135467
Epoch: 49 | Iteration number: [3940/4518] 87% | Training loss: 0.6870080240335561
Epoch: 49 | Iteration number: [3950/4518] 87% | Training loss: 0.6870085429692571
Epoch: 49 | Iteration number: [3960/4518] 87% | Training loss: 0.6870047433057217
Epoch: 49 | Iteration number: [3970/4518] 87% | Training loss: 0.6870026559463376
Epoch: 49 | Iteration number: [3980/4518] 88% | Training loss: 0.6870009675397346
Epoch: 49 | Iteration number: [3990/4518] 88% | Training loss: 0.6870005027841506
Epoch: 49 | Iteration number: [4000/4518] 88% | Training loss: 0.68699869517982
Epoch: 49 | Iteration number: [4010/4518] 88% | Training loss: 0.6869993200325907
Epoch: 49 | Iteration number: [4020/4518] 88% | Training loss: 0.6869963837796775
Epoch: 49 | Iteration number: [4030/4518] 89% | Training loss: 0.686993679737039
Epoch: 49 | Iteration number: [4040/4518] 89% | Training loss: 0.6869894652378441
Epoch: 49 | Iteration number: [4050/4518] 89% | Training loss: 0.6869898458027546
Epoch: 49 | Iteration number: [4060/4518] 89% | Training loss: 0.6869908195264234
Epoch: 49 | Iteration number: [4070/4518] 90% | Training loss: 0.6869925475969947
Epoch: 49 | Iteration number: [4080/4518] 90% | Training loss: 0.6869861686346578
Epoch: 49 | Iteration number: [4090/4518] 90% | Training loss: 0.6869857206904217
Epoch: 49 | Iteration number: [4100/4518] 90% | Training loss: 0.6869845015392071
Epoch: 49 | Iteration number: [4110/4518] 90% | Training loss: 0.6869853085555009
Epoch: 49 | Iteration number: [4120/4518] 91% | Training loss: 0.6869818972007742
Epoch: 49 | Iteration number: [4130/4518] 91% | Training loss: 0.6869828678793827
Epoch: 49 | Iteration number: [4140/4518] 91% | Training loss: 0.686983022324129
Epoch: 49 | Iteration number: [4150/4518] 91% | Training loss: 0.6869846766253552
Epoch: 49 | Iteration number: [4160/4518] 92% | Training loss: 0.686984095006035
Epoch: 49 | Iteration number: [4170/4518] 92% | Training loss: 0.6869832229128273
Epoch: 49 | Iteration number: [4180/4518] 92% | Training loss: 0.6869834491795901
Epoch: 49 | Iteration number: [4190/4518] 92% | Training loss: 0.6869823869059933
Epoch: 49 | Iteration number: [4200/4518] 92% | Training loss: 0.6869825831055641
Epoch: 49 | Iteration number: [4210/4518] 93% | Training loss: 0.6869833408795173
Epoch: 49 | Iteration number: [4220/4518] 93% | Training loss: 0.6869825422057608
Epoch: 49 | Iteration number: [4230/4518] 93% | Training loss: 0.6869794711717195
Epoch: 49 | Iteration number: [4240/4518] 93% | Training loss: 0.6869801678466347
Epoch: 49 | Iteration number: [4250/4518] 94% | Training loss: 0.6869789707800922
Epoch: 49 | Iteration number: [4260/4518] 94% | Training loss: 0.6869760961459835
Epoch: 49 | Iteration number: [4270/4518] 94% | Training loss: 0.6869729227427855
Epoch: 49 | Iteration number: [4280/4518] 94% | Training loss: 0.6869719487345107
Epoch: 49 | Iteration number: [4290/4518] 94% | Training loss: 0.6869740712337005
Epoch: 49 | Iteration number: [4300/4518] 95% | Training loss: 0.6869741400175317
Epoch: 49 | Iteration number: [4310/4518] 95% | Training loss: 0.6869732155600723
Epoch: 49 | Iteration number: [4320/4518] 95% | Training loss: 0.686970191711077
Epoch: 49 | Iteration number: [4330/4518] 95% | Training loss: 0.6869686516823449
Epoch: 49 | Iteration number: [4340/4518] 96% | Training loss: 0.6869703646903763
Epoch: 49 | Iteration number: [4350/4518] 96% | Training loss: 0.6869728274866083
Epoch: 49 | Iteration number: [4360/4518] 96% | Training loss: 0.6869768327665985
Epoch: 49 | Iteration number: [4370/4518] 96% | Training loss: 0.6869748872532179
Epoch: 49 | Iteration number: [4380/4518] 96% | Training loss: 0.6869741225351481
Epoch: 49 | Iteration number: [4390/4518] 97% | Training loss: 0.6869736499286729
Epoch: 49 | Iteration number: [4400/4518] 97% | Training loss: 0.6869746079499072
Epoch: 49 | Iteration number: [4410/4518] 97% | Training loss: 0.686972729297452
Epoch: 49 | Iteration number: [4420/4518] 97% | Training loss: 0.6869715480513163
Epoch: 49 | Iteration number: [4430/4518] 98% | Training loss: 0.6869687013782174
Epoch: 49 | Iteration number: [4440/4518] 98% | Training loss: 0.6869670156423036
Epoch: 49 | Iteration number: [4450/4518] 98% | Training loss: 0.686963048543823
Epoch: 49 | Iteration number: [4460/4518] 98% | Training loss: 0.6869639489549157
Epoch: 49 | Iteration number: [4470/4518] 98% | Training loss: 0.6869633721691917
Epoch: 49 | Iteration number: [4480/4518] 99% | Training loss: 0.6869619530891734
Epoch: 49 | Iteration number: [4490/4518] 99% | Training loss: 0.686961023061472
Epoch: 49 | Iteration number: [4500/4518] 99% | Training loss: 0.6869602175951004
Epoch: 49 | Iteration number: [4510/4518] 99% | Training loss: 0.6869578280892975

 End of epoch: 49 | Train Loss: 0.6868058133964361 | Training Time: 632 

 End of epoch: 49 | Eval Loss: 0.6897744061995525 | Evaluating Time: 17 
Epoch: 50 | Iteration number: [10/4518] 0% | Training loss: 0.7537349700927735
Epoch: 50 | Iteration number: [20/4518] 0% | Training loss: 0.7208538472652435
Epoch: 50 | Iteration number: [30/4518] 0% | Training loss: 0.7096644202868144
Epoch: 50 | Iteration number: [40/4518] 0% | Training loss: 0.7040114790201187
Epoch: 50 | Iteration number: [50/4518] 1% | Training loss: 0.7005339360237122
Epoch: 50 | Iteration number: [60/4518] 1% | Training loss: 0.6980719109376271
Epoch: 50 | Iteration number: [70/4518] 1% | Training loss: 0.6964043557643891
Epoch: 50 | Iteration number: [80/4518] 1% | Training loss: 0.6951005615293979
Epoch: 50 | Iteration number: [90/4518] 1% | Training loss: 0.6942280458079444
Epoch: 50 | Iteration number: [100/4518] 2% | Training loss: 0.6934204137325287
Epoch: 50 | Iteration number: [110/4518] 2% | Training loss: 0.6928504770452326
Epoch: 50 | Iteration number: [120/4518] 2% | Training loss: 0.6923071414232254
Epoch: 50 | Iteration number: [130/4518] 2% | Training loss: 0.6918546694975632
Epoch: 50 | Iteration number: [140/4518] 3% | Training loss: 0.6915139364344733
Epoch: 50 | Iteration number: [150/4518] 3% | Training loss: 0.691250460545222
Epoch: 50 | Iteration number: [160/4518] 3% | Training loss: 0.6909868836402893
Epoch: 50 | Iteration number: [170/4518] 3% | Training loss: 0.6907352948890013
Epoch: 50 | Iteration number: [180/4518] 3% | Training loss: 0.6905059556166331
Epoch: 50 | Iteration number: [190/4518] 4% | Training loss: 0.6902971167313425
Epoch: 50 | Iteration number: [200/4518] 4% | Training loss: 0.6901376885175705
Epoch: 50 | Iteration number: [210/4518] 4% | Training loss: 0.6900114698069436
Epoch: 50 | Iteration number: [220/4518] 4% | Training loss: 0.6898829324678941
Epoch: 50 | Iteration number: [230/4518] 5% | Training loss: 0.6897533121316329
Epoch: 50 | Iteration number: [240/4518] 5% | Training loss: 0.6896053098142148
Epoch: 50 | Iteration number: [250/4518] 5% | Training loss: 0.6894759426116943
Epoch: 50 | Iteration number: [260/4518] 5% | Training loss: 0.6894016089347693
Epoch: 50 | Iteration number: [270/4518] 5% | Training loss: 0.6893183460942021
Epoch: 50 | Iteration number: [280/4518] 6% | Training loss: 0.6892450332641602
Epoch: 50 | Iteration number: [290/4518] 6% | Training loss: 0.6891324238530521
Epoch: 50 | Iteration number: [300/4518] 6% | Training loss: 0.6890550724665324
Epoch: 50 | Iteration number: [310/4518] 6% | Training loss: 0.689001137979569
Epoch: 50 | Iteration number: [320/4518] 7% | Training loss: 0.6889857279136777
Epoch: 50 | Iteration number: [330/4518] 7% | Training loss: 0.6889138362624428
Epoch: 50 | Iteration number: [340/4518] 7% | Training loss: 0.6888423453359043
Epoch: 50 | Iteration number: [350/4518] 7% | Training loss: 0.6887861164978573
Epoch: 50 | Iteration number: [360/4518] 7% | Training loss: 0.688714609709051
Epoch: 50 | Iteration number: [370/4518] 8% | Training loss: 0.6886477700761846
Epoch: 50 | Iteration number: [380/4518] 8% | Training loss: 0.6886316547268315
Epoch: 50 | Iteration number: [390/4518] 8% | Training loss: 0.688534615895687
Epoch: 50 | Iteration number: [400/4518] 8% | Training loss: 0.6885080401599407
Epoch: 50 | Iteration number: [410/4518] 9% | Training loss: 0.6884526118999574
Epoch: 50 | Iteration number: [420/4518] 9% | Training loss: 0.688416891012873
Epoch: 50 | Iteration number: [430/4518] 9% | Training loss: 0.6883790472219157
Epoch: 50 | Iteration number: [440/4518] 9% | Training loss: 0.6883823933926496
Epoch: 50 | Iteration number: [450/4518] 9% | Training loss: 0.6883699599901835
Epoch: 50 | Iteration number: [460/4518] 10% | Training loss: 0.6883097528115563
Epoch: 50 | Iteration number: [470/4518] 10% | Training loss: 0.6882850539177022
Epoch: 50 | Iteration number: [480/4518] 10% | Training loss: 0.6882770143449306
Epoch: 50 | Iteration number: [490/4518] 10% | Training loss: 0.6882431741879911
Epoch: 50 | Iteration number: [500/4518] 11% | Training loss: 0.6882084064483642
Epoch: 50 | Iteration number: [510/4518] 11% | Training loss: 0.6881860744719411
Epoch: 50 | Iteration number: [520/4518] 11% | Training loss: 0.6881475115051636
Epoch: 50 | Iteration number: [530/4518] 11% | Training loss: 0.6881116611777611
Epoch: 50 | Iteration number: [540/4518] 11% | Training loss: 0.6881073817058846
Epoch: 50 | Iteration number: [550/4518] 12% | Training loss: 0.6880982531200756
Epoch: 50 | Iteration number: [560/4518] 12% | Training loss: 0.6880749676908765
Epoch: 50 | Iteration number: [570/4518] 12% | Training loss: 0.6880430694211993
Epoch: 50 | Iteration number: [580/4518] 12% | Training loss: 0.6880145542580506
Epoch: 50 | Iteration number: [590/4518] 13% | Training loss: 0.687967682793989
Epoch: 50 | Iteration number: [600/4518] 13% | Training loss: 0.6879646151264509
Epoch: 50 | Iteration number: [610/4518] 13% | Training loss: 0.6879364443607018
Epoch: 50 | Iteration number: [620/4518] 13% | Training loss: 0.6879219622381272
Epoch: 50 | Iteration number: [630/4518] 13% | Training loss: 0.6878910757246471
Epoch: 50 | Iteration number: [640/4518] 14% | Training loss: 0.6878570822998882
Epoch: 50 | Iteration number: [650/4518] 14% | Training loss: 0.6878353574642768
Epoch: 50 | Iteration number: [660/4518] 14% | Training loss: 0.6878291540976726
Epoch: 50 | Iteration number: [670/4518] 14% | Training loss: 0.6878056937189244
Epoch: 50 | Iteration number: [680/4518] 15% | Training loss: 0.687777939351166
Epoch: 50 | Iteration number: [690/4518] 15% | Training loss: 0.687751783495364
Epoch: 50 | Iteration number: [700/4518] 15% | Training loss: 0.6877531730277198
Epoch: 50 | Iteration number: [710/4518] 15% | Training loss: 0.6877480745315552
Epoch: 50 | Iteration number: [720/4518] 15% | Training loss: 0.6877388991415501
Epoch: 50 | Iteration number: [730/4518] 16% | Training loss: 0.6877154894887585
Epoch: 50 | Iteration number: [740/4518] 16% | Training loss: 0.687688597150751
Epoch: 50 | Iteration number: [750/4518] 16% | Training loss: 0.6876911557515463
Epoch: 50 | Iteration number: [760/4518] 16% | Training loss: 0.6876747780724576
Epoch: 50 | Iteration number: [770/4518] 17% | Training loss: 0.6876733393638165
Epoch: 50 | Iteration number: [780/4518] 17% | Training loss: 0.6876687007836807
Epoch: 50 | Iteration number: [790/4518] 17% | Training loss: 0.6876610534100593
Epoch: 50 | Iteration number: [800/4518] 17% | Training loss: 0.6876478964090347
Epoch: 50 | Iteration number: [810/4518] 17% | Training loss: 0.6876342364299445
Epoch: 50 | Iteration number: [820/4518] 18% | Training loss: 0.6876185909277055
Epoch: 50 | Iteration number: [830/4518] 18% | Training loss: 0.6876091514725283
Epoch: 50 | Iteration number: [840/4518] 18% | Training loss: 0.687588438746475
Epoch: 50 | Iteration number: [850/4518] 18% | Training loss: 0.6875769876732546
Epoch: 50 | Iteration number: [860/4518] 19% | Training loss: 0.6875765698593717
Epoch: 50 | Iteration number: [870/4518] 19% | Training loss: 0.6875563473537051
Epoch: 50 | Iteration number: [880/4518] 19% | Training loss: 0.687542542273348
Epoch: 50 | Iteration number: [890/4518] 19% | Training loss: 0.6875294886278303
Epoch: 50 | Iteration number: [900/4518] 19% | Training loss: 0.6875272460116281
Epoch: 50 | Iteration number: [910/4518] 20% | Training loss: 0.6875172224673596
Epoch: 50 | Iteration number: [920/4518] 20% | Training loss: 0.6875188039048858
Epoch: 50 | Iteration number: [930/4518] 20% | Training loss: 0.6875153838306345
Epoch: 50 | Iteration number: [940/4518] 20% | Training loss: 0.6875031794005252
Epoch: 50 | Iteration number: [950/4518] 21% | Training loss: 0.6875052649096439
Epoch: 50 | Iteration number: [960/4518] 21% | Training loss: 0.6874923029293617
Epoch: 50 | Iteration number: [970/4518] 21% | Training loss: 0.6874794401458858
Epoch: 50 | Iteration number: [980/4518] 21% | Training loss: 0.6874752359730857
Epoch: 50 | Iteration number: [990/4518] 21% | Training loss: 0.6874725731936369
Epoch: 50 | Iteration number: [1000/4518] 22% | Training loss: 0.6874616312980651
Epoch: 50 | Iteration number: [1010/4518] 22% | Training loss: 0.6874553826185736
Epoch: 50 | Iteration number: [1020/4518] 22% | Training loss: 0.6874420329636218
Epoch: 50 | Iteration number: [1030/4518] 22% | Training loss: 0.6874334790174244
Epoch: 50 | Iteration number: [1040/4518] 23% | Training loss: 0.6874231502986872
Epoch: 50 | Iteration number: [1050/4518] 23% | Training loss: 0.6874152450902121
Epoch: 50 | Iteration number: [1060/4518] 23% | Training loss: 0.6874023997558738
Epoch: 50 | Iteration number: [1070/4518] 23% | Training loss: 0.6873875363407848
Epoch: 50 | Iteration number: [1080/4518] 23% | Training loss: 0.6873888026784968
Epoch: 50 | Iteration number: [1090/4518] 24% | Training loss: 0.6873764670770103
Epoch: 50 | Iteration number: [1100/4518] 24% | Training loss: 0.6873696607893164
Epoch: 50 | Iteration number: [1110/4518] 24% | Training loss: 0.687365684745548
Epoch: 50 | Iteration number: [1120/4518] 24% | Training loss: 0.6873626536556653
Epoch: 50 | Iteration number: [1130/4518] 25% | Training loss: 0.6873595137511734
Epoch: 50 | Iteration number: [1140/4518] 25% | Training loss: 0.687345505963292
Epoch: 50 | Iteration number: [1150/4518] 25% | Training loss: 0.6873405493342358
Epoch: 50 | Iteration number: [1160/4518] 25% | Training loss: 0.6873271778225899
Epoch: 50 | Iteration number: [1170/4518] 25% | Training loss: 0.6873268322048024
Epoch: 50 | Iteration number: [1180/4518] 26% | Training loss: 0.6873085697828714
Epoch: 50 | Iteration number: [1190/4518] 26% | Training loss: 0.6872936170141236
Epoch: 50 | Iteration number: [1200/4518] 26% | Training loss: 0.6872873323659102
Epoch: 50 | Iteration number: [1210/4518] 26% | Training loss: 0.6872781143700781
Epoch: 50 | Iteration number: [1220/4518] 27% | Training loss: 0.6872745247649364
Epoch: 50 | Iteration number: [1230/4518] 27% | Training loss: 0.6872699275733979
Epoch: 50 | Iteration number: [1240/4518] 27% | Training loss: 0.6872591710379047
Epoch: 50 | Iteration number: [1250/4518] 27% | Training loss: 0.6872568437099457
Epoch: 50 | Iteration number: [1260/4518] 27% | Training loss: 0.6872568644228436
Epoch: 50 | Iteration number: [1270/4518] 28% | Training loss: 0.6872608066074491
Epoch: 50 | Iteration number: [1280/4518] 28% | Training loss: 0.6872524667531252
Epoch: 50 | Iteration number: [1290/4518] 28% | Training loss: 0.6872507737588512
Epoch: 50 | Iteration number: [1300/4518] 28% | Training loss: 0.6872480389246574
Epoch: 50 | Iteration number: [1310/4518] 28% | Training loss: 0.6872546144114196
Epoch: 50 | Iteration number: [1320/4518] 29% | Training loss: 0.6872503086924553
Epoch: 50 | Iteration number: [1330/4518] 29% | Training loss: 0.6872375635724318
Epoch: 50 | Iteration number: [1340/4518] 29% | Training loss: 0.6872305097864635
Epoch: 50 | Iteration number: [1350/4518] 29% | Training loss: 0.6872315979003907
Epoch: 50 | Iteration number: [1360/4518] 30% | Training loss: 0.6872286086135051
Epoch: 50 | Iteration number: [1370/4518] 30% | Training loss: 0.6872267987606299
Epoch: 50 | Iteration number: [1380/4518] 30% | Training loss: 0.6872332448544709
Epoch: 50 | Iteration number: [1390/4518] 30% | Training loss: 0.6872215231974348
Epoch: 50 | Iteration number: [1400/4518] 30% | Training loss: 0.6872193250485829
Epoch: 50 | Iteration number: [1410/4518] 31% | Training loss: 0.6872113786267896
Epoch: 50 | Iteration number: [1420/4518] 31% | Training loss: 0.6872116595086917
Epoch: 50 | Iteration number: [1430/4518] 31% | Training loss: 0.6872086916353319
Epoch: 50 | Iteration number: [1440/4518] 31% | Training loss: 0.6872074176039961
Epoch: 50 | Iteration number: [1450/4518] 32% | Training loss: 0.6871999770608441
Epoch: 50 | Iteration number: [1460/4518] 32% | Training loss: 0.6872089080206335
Epoch: 50 | Iteration number: [1470/4518] 32% | Training loss: 0.6872039146163836
Epoch: 50 | Iteration number: [1480/4518] 32% | Training loss: 0.6871934643468341
Epoch: 50 | Iteration number: [1490/4518] 32% | Training loss: 0.6871955070319592
Epoch: 50 | Iteration number: [1500/4518] 33% | Training loss: 0.6871931445598602
Epoch: 50 | Iteration number: [1510/4518] 33% | Training loss: 0.6871971785232721
Epoch: 50 | Iteration number: [1520/4518] 33% | Training loss: 0.6871893719622963
Epoch: 50 | Iteration number: [1530/4518] 33% | Training loss: 0.687191535366906
Epoch: 50 | Iteration number: [1540/4518] 34% | Training loss: 0.6871845090931112
Epoch: 50 | Iteration number: [1550/4518] 34% | Training loss: 0.6871814810460614
Epoch: 50 | Iteration number: [1560/4518] 34% | Training loss: 0.6871805058457913
Epoch: 50 | Iteration number: [1570/4518] 34% | Training loss: 0.6871821113832437
Epoch: 50 | Iteration number: [1580/4518] 34% | Training loss: 0.6871850896485244
Epoch: 50 | Iteration number: [1590/4518] 35% | Training loss: 0.6871873415116244
Epoch: 50 | Iteration number: [1600/4518] 35% | Training loss: 0.6871876189112663
Epoch: 50 | Iteration number: [1610/4518] 35% | Training loss: 0.6871851143629655
Epoch: 50 | Iteration number: [1620/4518] 35% | Training loss: 0.687182656482414
Epoch: 50 | Iteration number: [1630/4518] 36% | Training loss: 0.6871892795240953
Epoch: 50 | Iteration number: [1640/4518] 36% | Training loss: 0.6871823980677418
Epoch: 50 | Iteration number: [1650/4518] 36% | Training loss: 0.6871778088627439
Epoch: 50 | Iteration number: [1660/4518] 36% | Training loss: 0.6871795389666615
Epoch: 50 | Iteration number: [1670/4518] 36% | Training loss: 0.6871705746579313
Epoch: 50 | Iteration number: [1680/4518] 37% | Training loss: 0.6871642198945794
Epoch: 50 | Iteration number: [1690/4518] 37% | Training loss: 0.6871636076791752
Epoch: 50 | Iteration number: [1700/4518] 37% | Training loss: 0.6871584491869983
Epoch: 50 | Iteration number: [1710/4518] 37% | Training loss: 0.6871581292640396
Epoch: 50 | Iteration number: [1720/4518] 38% | Training loss: 0.68715617344823
Epoch: 50 | Iteration number: [1730/4518] 38% | Training loss: 0.6871514247676541
Epoch: 50 | Iteration number: [1740/4518] 38% | Training loss: 0.6871542615109476
Epoch: 50 | Iteration number: [1750/4518] 38% | Training loss: 0.6871530614580427
Epoch: 50 | Iteration number: [1760/4518] 38% | Training loss: 0.6871554861691865
Epoch: 50 | Iteration number: [1770/4518] 39% | Training loss: 0.6871590336500588
Epoch: 50 | Iteration number: [1780/4518] 39% | Training loss: 0.6871614736117674
Epoch: 50 | Iteration number: [1790/4518] 39% | Training loss: 0.6871662583098065
Epoch: 50 | Iteration number: [1800/4518] 39% | Training loss: 0.6871630261010594
Epoch: 50 | Iteration number: [1810/4518] 40% | Training loss: 0.6871596053818971
Epoch: 50 | Iteration number: [1820/4518] 40% | Training loss: 0.6871597655199386
Epoch: 50 | Iteration number: [1830/4518] 40% | Training loss: 0.6871549837576235
Epoch: 50 | Iteration number: [1840/4518] 40% | Training loss: 0.6871574154690556
Epoch: 50 | Iteration number: [1850/4518] 40% | Training loss: 0.6871553594679446
Epoch: 50 | Iteration number: [1860/4518] 41% | Training loss: 0.6871436728905606
Epoch: 50 | Iteration number: [1870/4518] 41% | Training loss: 0.6871338005690651
Epoch: 50 | Iteration number: [1880/4518] 41% | Training loss: 0.6871291577498964
Epoch: 50 | Iteration number: [1890/4518] 41% | Training loss: 0.6871264556728343
Epoch: 50 | Iteration number: [1900/4518] 42% | Training loss: 0.6871270766070015
Epoch: 50 | Iteration number: [1910/4518] 42% | Training loss: 0.6871259525184232
Epoch: 50 | Iteration number: [1920/4518] 42% | Training loss: 0.6871313597696523
Epoch: 50 | Iteration number: [1930/4518] 42% | Training loss: 0.687134965621128
Epoch: 50 | Iteration number: [1940/4518] 42% | Training loss: 0.6871313934780888
Epoch: 50 | Iteration number: [1950/4518] 43% | Training loss: 0.6871302606814947
Epoch: 50 | Iteration number: [1960/4518] 43% | Training loss: 0.6871258667233039
Epoch: 50 | Iteration number: [1970/4518] 43% | Training loss: 0.6871311027386466
Epoch: 50 | Iteration number: [1980/4518] 43% | Training loss: 0.6871255681370244
Epoch: 50 | Iteration number: [1990/4518] 44% | Training loss: 0.6871172539552851
Epoch: 50 | Iteration number: [2000/4518] 44% | Training loss: 0.6871145863234996
Epoch: 50 | Iteration number: [2010/4518] 44% | Training loss: 0.687118412843391
Epoch: 50 | Iteration number: [2020/4518] 44% | Training loss: 0.6871226699635534
Epoch: 50 | Iteration number: [2030/4518] 44% | Training loss: 0.6871183371602608
Epoch: 50 | Iteration number: [2040/4518] 45% | Training loss: 0.6871182246827612
Epoch: 50 | Iteration number: [2050/4518] 45% | Training loss: 0.6871144565721837
Epoch: 50 | Iteration number: [2060/4518] 45% | Training loss: 0.6871101265393414
Epoch: 50 | Iteration number: [2070/4518] 45% | Training loss: 0.6871075321510794
Epoch: 50 | Iteration number: [2080/4518] 46% | Training loss: 0.6871072238167891
Epoch: 50 | Iteration number: [2090/4518] 46% | Training loss: 0.6871081254413823
Epoch: 50 | Iteration number: [2100/4518] 46% | Training loss: 0.6871072478521438
Epoch: 50 | Iteration number: [2110/4518] 46% | Training loss: 0.6871093690395356
Epoch: 50 | Iteration number: [2120/4518] 46% | Training loss: 0.6871088824182187
Epoch: 50 | Iteration number: [2130/4518] 47% | Training loss: 0.687104499172157
Epoch: 50 | Iteration number: [2140/4518] 47% | Training loss: 0.6871013858886522
Epoch: 50 | Iteration number: [2150/4518] 47% | Training loss: 0.6870976253997448
Epoch: 50 | Iteration number: [2160/4518] 47% | Training loss: 0.687097008443541
Epoch: 50 | Iteration number: [2170/4518] 48% | Training loss: 0.6870983934896883
Epoch: 50 | Iteration number: [2180/4518] 48% | Training loss: 0.6871036414432963
Epoch: 50 | Iteration number: [2190/4518] 48% | Training loss: 0.6871006053876659
Epoch: 50 | Iteration number: [2200/4518] 48% | Training loss: 0.6870987263592807
Epoch: 50 | Iteration number: [2210/4518] 48% | Training loss: 0.6870967823455776
Epoch: 50 | Iteration number: [2220/4518] 49% | Training loss: 0.6870966959644008
Epoch: 50 | Iteration number: [2230/4518] 49% | Training loss: 0.6871012274459873
Epoch: 50 | Iteration number: [2240/4518] 49% | Training loss: 0.6870967142550009
Epoch: 50 | Iteration number: [2250/4518] 49% | Training loss: 0.6870923096073999
Epoch: 50 | Iteration number: [2260/4518] 50% | Training loss: 0.6870941783738347
Epoch: 50 | Iteration number: [2270/4518] 50% | Training loss: 0.6870936910486432
Epoch: 50 | Iteration number: [2280/4518] 50% | Training loss: 0.6870854623223606
Epoch: 50 | Iteration number: [2290/4518] 50% | Training loss: 0.6870832665778664
Epoch: 50 | Iteration number: [2300/4518] 50% | Training loss: 0.6870845533194749
Epoch: 50 | Iteration number: [2310/4518] 51% | Training loss: 0.6870809734641732
Epoch: 50 | Iteration number: [2320/4518] 51% | Training loss: 0.6870800537538939
Epoch: 50 | Iteration number: [2330/4518] 51% | Training loss: 0.687082962877249
Epoch: 50 | Iteration number: [2340/4518] 51% | Training loss: 0.6870787928501765
Epoch: 50 | Iteration number: [2350/4518] 52% | Training loss: 0.687079183294418
Epoch: 50 | Iteration number: [2360/4518] 52% | Training loss: 0.6870769045110476
Epoch: 50 | Iteration number: [2370/4518] 52% | Training loss: 0.6870760549221361
Epoch: 50 | Iteration number: [2380/4518] 52% | Training loss: 0.6870779597709159
Epoch: 50 | Iteration number: [2390/4518] 52% | Training loss: 0.6870780820627093
Epoch: 50 | Iteration number: [2400/4518] 53% | Training loss: 0.6870789174983899
Epoch: 50 | Iteration number: [2410/4518] 53% | Training loss: 0.6870790969286716
Epoch: 50 | Iteration number: [2420/4518] 53% | Training loss: 0.6870758990364626
Epoch: 50 | Iteration number: [2430/4518] 53% | Training loss: 0.687078574287548
Epoch: 50 | Iteration number: [2440/4518] 54% | Training loss: 0.6870769960469887
Epoch: 50 | Iteration number: [2450/4518] 54% | Training loss: 0.6870761671358225
Epoch: 50 | Iteration number: [2460/4518] 54% | Training loss: 0.6870793775087449
Epoch: 50 | Iteration number: [2470/4518] 54% | Training loss: 0.6870785075160656
Epoch: 50 | Iteration number: [2480/4518] 54% | Training loss: 0.6870756846762472
Epoch: 50 | Iteration number: [2490/4518] 55% | Training loss: 0.6870773759711698
Epoch: 50 | Iteration number: [2500/4518] 55% | Training loss: 0.6870791333913803
Epoch: 50 | Iteration number: [2510/4518] 55% | Training loss: 0.6870768211989764
Epoch: 50 | Iteration number: [2520/4518] 55% | Training loss: 0.6870749122566647
Epoch: 50 | Iteration number: [2530/4518] 55% | Training loss: 0.687068157304417
Epoch: 50 | Iteration number: [2540/4518] 56% | Training loss: 0.6870700981203965
Epoch: 50 | Iteration number: [2550/4518] 56% | Training loss: 0.6870645924876718
Epoch: 50 | Iteration number: [2560/4518] 56% | Training loss: 0.687064347602427
Epoch: 50 | Iteration number: [2570/4518] 56% | Training loss: 0.687055002019563
Epoch: 50 | Iteration number: [2580/4518] 57% | Training loss: 0.6870528535787449
Epoch: 50 | Iteration number: [2590/4518] 57% | Training loss: 0.6870519844491509
Epoch: 50 | Iteration number: [2600/4518] 57% | Training loss: 0.6870480205921027
Epoch: 50 | Iteration number: [2610/4518] 57% | Training loss: 0.68704311000433
Epoch: 50 | Iteration number: [2620/4518] 57% | Training loss: 0.6870423573574037
Epoch: 50 | Iteration number: [2630/4518] 58% | Training loss: 0.6870436133313995
Epoch: 50 | Iteration number: [2640/4518] 58% | Training loss: 0.6870480252034736
Epoch: 50 | Iteration number: [2650/4518] 58% | Training loss: 0.6870501816272736
Epoch: 50 | Iteration number: [2660/4518] 58% | Training loss: 0.687051656349261
Epoch: 50 | Iteration number: [2670/4518] 59% | Training loss: 0.6870544115479073
Epoch: 50 | Iteration number: [2680/4518] 59% | Training loss: 0.6870525999967732
Epoch: 50 | Iteration number: [2690/4518] 59% | Training loss: 0.6870546928568844
Epoch: 50 | Iteration number: [2700/4518] 59% | Training loss: 0.6870509826695478
Epoch: 50 | Iteration number: [2710/4518] 59% | Training loss: 0.6870497193063757
Epoch: 50 | Iteration number: [2720/4518] 60% | Training loss: 0.687046651279225
Epoch: 50 | Iteration number: [2730/4518] 60% | Training loss: 0.687047675546709
Epoch: 50 | Iteration number: [2740/4518] 60% | Training loss: 0.6870463136991445
Epoch: 50 | Iteration number: [2750/4518] 60% | Training loss: 0.6870473092252558
Epoch: 50 | Iteration number: [2760/4518] 61% | Training loss: 0.6870435289930606
Epoch: 50 | Iteration number: [2770/4518] 61% | Training loss: 0.6870435956152768
Epoch: 50 | Iteration number: [2780/4518] 61% | Training loss: 0.6870453809662689
Epoch: 50 | Iteration number: [2790/4518] 61% | Training loss: 0.6870437199710517
Epoch: 50 | Iteration number: [2800/4518] 61% | Training loss: 0.6870437102658408
Epoch: 50 | Iteration number: [2810/4518] 62% | Training loss: 0.6870417562031661
Epoch: 50 | Iteration number: [2820/4518] 62% | Training loss: 0.6870440641616253
Epoch: 50 | Iteration number: [2830/4518] 62% | Training loss: 0.6870460570490402
Epoch: 50 | Iteration number: [2840/4518] 62% | Training loss: 0.6870477524021982
Epoch: 50 | Iteration number: [2850/4518] 63% | Training loss: 0.6870474957374104
Epoch: 50 | Iteration number: [2860/4518] 63% | Training loss: 0.6870475236560915
Epoch: 50 | Iteration number: [2870/4518] 63% | Training loss: 0.6870500296042771
Epoch: 50 | Iteration number: [2880/4518] 63% | Training loss: 0.6870464161659281
Epoch: 50 | Iteration number: [2890/4518] 63% | Training loss: 0.6870455737551191
Epoch: 50 | Iteration number: [2900/4518] 64% | Training loss: 0.6870387477710329
Epoch: 50 | Iteration number: [2910/4518] 64% | Training loss: 0.68703731019882
Epoch: 50 | Iteration number: [2920/4518] 64% | Training loss: 0.6870361138492415
Epoch: 50 | Iteration number: [2930/4518] 64% | Training loss: 0.6870325826337313
Epoch: 50 | Iteration number: [2940/4518] 65% | Training loss: 0.6870317159664063
Epoch: 50 | Iteration number: [2950/4518] 65% | Training loss: 0.6870270155446004
Epoch: 50 | Iteration number: [2960/4518] 65% | Training loss: 0.687026818076501
Epoch: 50 | Iteration number: [2970/4518] 65% | Training loss: 0.6870244723578495
Epoch: 50 | Iteration number: [2980/4518] 65% | Training loss: 0.6870248277915404
Epoch: 50 | Iteration number: [2990/4518] 66% | Training loss: 0.6870236214586724
Epoch: 50 | Iteration number: [3000/4518] 66% | Training loss: 0.6870211433768273
Epoch: 50 | Iteration number: [3010/4518] 66% | Training loss: 0.6870203212250111
Epoch: 50 | Iteration number: [3020/4518] 66% | Training loss: 0.6870181668081031
Epoch: 50 | Iteration number: [3030/4518] 67% | Training loss: 0.6870137263839394
Epoch: 50 | Iteration number: [3040/4518] 67% | Training loss: 0.6870098422036359
Epoch: 50 | Iteration number: [3050/4518] 67% | Training loss: 0.6870108191888841
Epoch: 50 | Iteration number: [3060/4518] 67% | Training loss: 0.6870099318183326
Epoch: 50 | Iteration number: [3070/4518] 67% | Training loss: 0.6870092647665875
Epoch: 50 | Iteration number: [3080/4518] 68% | Training loss: 0.6870095411871935
Epoch: 50 | Iteration number: [3090/4518] 68% | Training loss: 0.6870099188633335
Epoch: 50 | Iteration number: [3100/4518] 68% | Training loss: 0.6870095453531512
Epoch: 50 | Iteration number: [3110/4518] 68% | Training loss: 0.687013345899306
Epoch: 50 | Iteration number: [3120/4518] 69% | Training loss: 0.6870137275029451
Epoch: 50 | Iteration number: [3130/4518] 69% | Training loss: 0.6870128653300837
Epoch: 50 | Iteration number: [3140/4518] 69% | Training loss: 0.6870068635340709
Epoch: 50 | Iteration number: [3150/4518] 69% | Training loss: 0.6870059714241633
Epoch: 50 | Iteration number: [3160/4518] 69% | Training loss: 0.6870027289926252
Epoch: 50 | Iteration number: [3170/4518] 70% | Training loss: 0.68700526121663
Epoch: 50 | Iteration number: [3180/4518] 70% | Training loss: 0.6870041650796087
Epoch: 50 | Iteration number: [3190/4518] 70% | Training loss: 0.6870026535001295
Epoch: 50 | Iteration number: [3200/4518] 70% | Training loss: 0.6870048139244318
Epoch: 50 | Iteration number: [3210/4518] 71% | Training loss: 0.6870077041079322
Epoch: 50 | Iteration number: [3220/4518] 71% | Training loss: 0.6870119900251768
Epoch: 50 | Iteration number: [3230/4518] 71% | Training loss: 0.6870092169234627
Epoch: 50 | Iteration number: [3240/4518] 71% | Training loss: 0.6870028425329997
Epoch: 50 | Iteration number: [3250/4518] 71% | Training loss: 0.686998886511876
Epoch: 50 | Iteration number: [3260/4518] 72% | Training loss: 0.686999371483282
Epoch: 50 | Iteration number: [3270/4518] 72% | Training loss: 0.686996678620668
Epoch: 50 | Iteration number: [3280/4518] 72% | Training loss: 0.686994418138411
Epoch: 50 | Iteration number: [3290/4518] 72% | Training loss: 0.6869943357709694
Epoch: 50 | Iteration number: [3300/4518] 73% | Training loss: 0.6869940733006507
Epoch: 50 | Iteration number: [3310/4518] 73% | Training loss: 0.6869939282581525
Epoch: 50 | Iteration number: [3320/4518] 73% | Training loss: 0.6869926523731416
Epoch: 50 | Iteration number: [3330/4518] 73% | Training loss: 0.6869897854399752
Epoch: 50 | Iteration number: [3340/4518] 73% | Training loss: 0.6869848921627342
Epoch: 50 | Iteration number: [3350/4518] 74% | Training loss: 0.6869846317661342
Epoch: 50 | Iteration number: [3360/4518] 74% | Training loss: 0.6869828128566344
Epoch: 50 | Iteration number: [3370/4518] 74% | Training loss: 0.6869827201175407
Epoch: 50 | Iteration number: [3380/4518] 74% | Training loss: 0.6869860607667787
Epoch: 50 | Iteration number: [3390/4518] 75% | Training loss: 0.686985571370364
Epoch: 50 | Iteration number: [3400/4518] 75% | Training loss: 0.6869879298525698
Epoch: 50 | Iteration number: [3410/4518] 75% | Training loss: 0.6869858343929839
Epoch: 50 | Iteration number: [3420/4518] 75% | Training loss: 0.6869886512644807
Epoch: 50 | Iteration number: [3430/4518] 75% | Training loss: 0.6869882760868128
Epoch: 50 | Iteration number: [3440/4518] 76% | Training loss: 0.6869877871039302
Epoch: 50 | Iteration number: [3450/4518] 76% | Training loss: 0.6869871039839759
Epoch: 50 | Iteration number: [3460/4518] 76% | Training loss: 0.6869869751737296
Epoch: 50 | Iteration number: [3470/4518] 76% | Training loss: 0.6869850204897889
Epoch: 50 | Iteration number: [3480/4518] 77% | Training loss: 0.6869874101603168
Epoch: 50 | Iteration number: [3490/4518] 77% | Training loss: 0.6869843814810231
Epoch: 50 | Iteration number: [3500/4518] 77% | Training loss: 0.6869854507105692
Epoch: 50 | Iteration number: [3510/4518] 77% | Training loss: 0.686987860912611
Epoch: 50 | Iteration number: [3520/4518] 77% | Training loss: 0.6869838541542942
Epoch: 50 | Iteration number: [3530/4518] 78% | Training loss: 0.6869834291360871
Epoch: 50 | Iteration number: [3540/4518] 78% | Training loss: 0.6869843984559431
Epoch: 50 | Iteration number: [3550/4518] 78% | Training loss: 0.6869847959363964
Epoch: 50 | Iteration number: [3560/4518] 78% | Training loss: 0.6869844266203012
Epoch: 50 | Iteration number: [3570/4518] 79% | Training loss: 0.6869872239290499
Epoch: 50 | Iteration number: [3580/4518] 79% | Training loss: 0.686986004973257
Epoch: 50 | Iteration number: [3590/4518] 79% | Training loss: 0.6869840028392239
Epoch: 50 | Iteration number: [3600/4518] 79% | Training loss: 0.6869853911962774
Epoch: 50 | Iteration number: [3610/4518] 79% | Training loss: 0.6869853076677244
Epoch: 50 | Iteration number: [3620/4518] 80% | Training loss: 0.6869891219046893
Epoch: 50 | Iteration number: [3630/4518] 80% | Training loss: 0.6869899380962382
Epoch: 50 | Iteration number: [3640/4518] 80% | Training loss: 0.6869851129886868
Epoch: 50 | Iteration number: [3650/4518] 80% | Training loss: 0.6869840966185479
Epoch: 50 | Iteration number: [3660/4518] 81% | Training loss: 0.6869847523547261
Epoch: 50 | Iteration number: [3670/4518] 81% | Training loss: 0.68698251076875
Epoch: 50 | Iteration number: [3680/4518] 81% | Training loss: 0.6869800166429385
Epoch: 50 | Iteration number: [3690/4518] 81% | Training loss: 0.6869758137034853
Epoch: 50 | Iteration number: [3700/4518] 81% | Training loss: 0.6869753195627316
Epoch: 50 | Iteration number: [3710/4518] 82% | Training loss: 0.6869759025278117
Epoch: 50 | Iteration number: [3720/4518] 82% | Training loss: 0.6869807188389122
Epoch: 50 | Iteration number: [3730/4518] 82% | Training loss: 0.6869824589097787
Epoch: 50 | Iteration number: [3740/4518] 82% | Training loss: 0.6869830185398061
Epoch: 50 | Iteration number: [3750/4518] 83% | Training loss: 0.6869823569615682
Epoch: 50 | Iteration number: [3760/4518] 83% | Training loss: 0.6869837259675594
Epoch: 50 | Iteration number: [3770/4518] 83% | Training loss: 0.6869806430067877
Epoch: 50 | Iteration number: [3780/4518] 83% | Training loss: 0.6869828122633475
Epoch: 50 | Iteration number: [3790/4518] 83% | Training loss: 0.6869811931040167
Epoch: 50 | Iteration number: [3800/4518] 84% | Training loss: 0.6869816516104498
Epoch: 50 | Iteration number: [3810/4518] 84% | Training loss: 0.6869790991773129
Epoch: 50 | Iteration number: [3820/4518] 84% | Training loss: 0.6869737184640625
Epoch: 50 | Iteration number: [3830/4518] 84% | Training loss: 0.6869731398226386
Epoch: 50 | Iteration number: [3840/4518] 84% | Training loss: 0.6869730792008341
Epoch: 50 | Iteration number: [3850/4518] 85% | Training loss: 0.6869738839353834
Epoch: 50 | Iteration number: [3860/4518] 85% | Training loss: 0.6869755663865589
Epoch: 50 | Iteration number: [3870/4518] 85% | Training loss: 0.6869762581602239
Epoch: 50 | Iteration number: [3880/4518] 85% | Training loss: 0.6869758123282305
Epoch: 50 | Iteration number: [3890/4518] 86% | Training loss: 0.6869765381580147
Epoch: 50 | Iteration number: [3900/4518] 86% | Training loss: 0.686977598804694
Epoch: 50 | Iteration number: [3910/4518] 86% | Training loss: 0.6869762402056429
Epoch: 50 | Iteration number: [3920/4518] 86% | Training loss: 0.6869782050349275
Epoch: 50 | Iteration number: [3930/4518] 86% | Training loss: 0.6869784645451844
Epoch: 50 | Iteration number: [3940/4518] 87% | Training loss: 0.68697988363692
Epoch: 50 | Iteration number: [3950/4518] 87% | Training loss: 0.686974445174012
Epoch: 50 | Iteration number: [3960/4518] 87% | Training loss: 0.686973145634237
Epoch: 50 | Iteration number: [3970/4518] 87% | Training loss: 0.686972261345957
Epoch: 50 | Iteration number: [3980/4518] 88% | Training loss: 0.6869715963775788
Epoch: 50 | Iteration number: [3990/4518] 88% | Training loss: 0.6869732334500267
Epoch: 50 | Iteration number: [4000/4518] 88% | Training loss: 0.6869711740165949
Epoch: 50 | Iteration number: [4010/4518] 88% | Training loss: 0.6869702129441306
Epoch: 50 | Iteration number: [4020/4518] 88% | Training loss: 0.6869679087578361
Epoch: 50 | Iteration number: [4030/4518] 89% | Training loss: 0.6869696112631568
Epoch: 50 | Iteration number: [4040/4518] 89% | Training loss: 0.6869682546151746
Epoch: 50 | Iteration number: [4050/4518] 89% | Training loss: 0.6869682976051613
Epoch: 50 | Iteration number: [4060/4518] 89% | Training loss: 0.6869688729640886
Epoch: 50 | Iteration number: [4070/4518] 90% | Training loss: 0.6869709455117546
Epoch: 50 | Iteration number: [4080/4518] 90% | Training loss: 0.6869706333414012
Epoch: 50 | Iteration number: [4090/4518] 90% | Training loss: 0.6869726688471284
Epoch: 50 | Iteration number: [4100/4518] 90% | Training loss: 0.686974832197515
Epoch: 50 | Iteration number: [4110/4518] 90% | Training loss: 0.6869759273935119
Epoch: 50 | Iteration number: [4120/4518] 91% | Training loss: 0.686973833271022
Epoch: 50 | Iteration number: [4130/4518] 91% | Training loss: 0.6869729889795797
Epoch: 50 | Iteration number: [4140/4518] 91% | Training loss: 0.6869704710544595
Epoch: 50 | Iteration number: [4150/4518] 91% | Training loss: 0.6869685699709926
Epoch: 50 | Iteration number: [4160/4518] 92% | Training loss: 0.6869692750848256
Epoch: 50 | Iteration number: [4170/4518] 92% | Training loss: 0.6869678568496979
Epoch: 50 | Iteration number: [4180/4518] 92% | Training loss: 0.6869679225546321
Epoch: 50 | Iteration number: [4190/4518] 92% | Training loss: 0.6869696839470283
Epoch: 50 | Iteration number: [4200/4518] 92% | Training loss: 0.6869700742619378
Epoch: 50 | Iteration number: [4210/4518] 93% | Training loss: 0.6869684175754103
Epoch: 50 | Iteration number: [4220/4518] 93% | Training loss: 0.6869686496201285
Epoch: 50 | Iteration number: [4230/4518] 93% | Training loss: 0.6869686920451216
Epoch: 50 | Iteration number: [4240/4518] 93% | Training loss: 0.6869693341963696
Epoch: 50 | Iteration number: [4250/4518] 94% | Training loss: 0.6869697781170115
Epoch: 50 | Iteration number: [4260/4518] 94% | Training loss: 0.6869709875522085
Epoch: 50 | Iteration number: [4270/4518] 94% | Training loss: 0.6869694622534499
Epoch: 50 | Iteration number: [4280/4518] 94% | Training loss: 0.6869694036161789
Epoch: 50 | Iteration number: [4290/4518] 94% | Training loss: 0.6869666190830978
Epoch: 50 | Iteration number: [4300/4518] 95% | Training loss: 0.6869641460097113
Epoch: 50 | Iteration number: [4310/4518] 95% | Training loss: 0.6869620004137265
Epoch: 50 | Iteration number: [4320/4518] 95% | Training loss: 0.6869584544803258
Epoch: 50 | Iteration number: [4330/4518] 95% | Training loss: 0.686960194237513
Epoch: 50 | Iteration number: [4340/4518] 96% | Training loss: 0.6869597568764665
Epoch: 50 | Iteration number: [4350/4518] 96% | Training loss: 0.686960014913274
Epoch: 50 | Iteration number: [4360/4518] 96% | Training loss: 0.6869609526264558
Epoch: 50 | Iteration number: [4370/4518] 96% | Training loss: 0.6869590739363663
Epoch: 50 | Iteration number: [4380/4518] 96% | Training loss: 0.6869613449867458
Epoch: 50 | Iteration number: [4390/4518] 97% | Training loss: 0.6869598151339485
Epoch: 50 | Iteration number: [4400/4518] 97% | Training loss: 0.6869599284231662
Epoch: 50 | Iteration number: [4410/4518] 97% | Training loss: 0.6869610369340633
Epoch: 50 | Iteration number: [4420/4518] 97% | Training loss: 0.6869617903529249
Epoch: 50 | Iteration number: [4430/4518] 98% | Training loss: 0.6869613559063078
Epoch: 50 | Iteration number: [4440/4518] 98% | Training loss: 0.686961147752968
Epoch: 50 | Iteration number: [4450/4518] 98% | Training loss: 0.6869587391547942
Epoch: 50 | Iteration number: [4460/4518] 98% | Training loss: 0.6869584948492692
Epoch: 50 | Iteration number: [4470/4518] 98% | Training loss: 0.6869556847434716
Epoch: 50 | Iteration number: [4480/4518] 99% | Training loss: 0.6869558774467025
Epoch: 50 | Iteration number: [4490/4518] 99% | Training loss: 0.6869529371537716
Epoch: 50 | Iteration number: [4500/4518] 99% | Training loss: 0.6869544835355547
Epoch: 50 | Iteration number: [4510/4518] 99% | Training loss: 0.6869563816920616

 End of epoch: 50 | Train Loss: 0.6868026898254489 | Training Time: 631 

 End of epoch: 50 | Eval Loss: 0.689759838337801 | Evaluating Time: 17 
Epoch: 51 | Iteration number: [10/4518] 0% | Training loss: 0.7560078740119934
Epoch: 51 | Iteration number: [20/4518] 0% | Training loss: 0.7216205567121505
Epoch: 51 | Iteration number: [30/4518] 0% | Training loss: 0.709836318095525
Epoch: 51 | Iteration number: [40/4518] 0% | Training loss: 0.7040520668029785
Epoch: 51 | Iteration number: [50/4518] 1% | Training loss: 0.7005929028987885
Epoch: 51 | Iteration number: [60/4518] 1% | Training loss: 0.6982239087422689
Epoch: 51 | Iteration number: [70/4518] 1% | Training loss: 0.6965892442635128
Epoch: 51 | Iteration number: [80/4518] 1% | Training loss: 0.6952665470540523
Epoch: 51 | Iteration number: [90/4518] 1% | Training loss: 0.694387196832233
Epoch: 51 | Iteration number: [100/4518] 2% | Training loss: 0.693546159863472
Epoch: 51 | Iteration number: [110/4518] 2% | Training loss: 0.6929306442087347
Epoch: 51 | Iteration number: [120/4518] 2% | Training loss: 0.6924715181191762
Epoch: 51 | Iteration number: [130/4518] 2% | Training loss: 0.6920902110063113
Epoch: 51 | Iteration number: [140/4518] 3% | Training loss: 0.691803326351302
Epoch: 51 | Iteration number: [150/4518] 3% | Training loss: 0.6913830252488454
Epoch: 51 | Iteration number: [160/4518] 3% | Training loss: 0.6911043919622898
Epoch: 51 | Iteration number: [170/4518] 3% | Training loss: 0.6909325820558211
Epoch: 51 | Iteration number: [180/4518] 3% | Training loss: 0.6907011770539814
Epoch: 51 | Iteration number: [190/4518] 4% | Training loss: 0.6905054770017925
Epoch: 51 | Iteration number: [200/4518] 4% | Training loss: 0.6903284886479377
Epoch: 51 | Iteration number: [210/4518] 4% | Training loss: 0.6901675499620892
Epoch: 51 | Iteration number: [220/4518] 4% | Training loss: 0.6899549142880873
Epoch: 51 | Iteration number: [230/4518] 5% | Training loss: 0.6897934203562529
Epoch: 51 | Iteration number: [240/4518] 5% | Training loss: 0.6896174835662047
Epoch: 51 | Iteration number: [250/4518] 5% | Training loss: 0.6895401039123535
Epoch: 51 | Iteration number: [260/4518] 5% | Training loss: 0.6894362030120996
Epoch: 51 | Iteration number: [270/4518] 5% | Training loss: 0.689305184284846
Epoch: 51 | Iteration number: [280/4518] 6% | Training loss: 0.68917113670281
Epoch: 51 | Iteration number: [290/4518] 6% | Training loss: 0.6890763510917796
Epoch: 51 | Iteration number: [300/4518] 6% | Training loss: 0.6890125588575999
Epoch: 51 | Iteration number: [310/4518] 6% | Training loss: 0.6889302286409562
Epoch: 51 | Iteration number: [320/4518] 7% | Training loss: 0.6888220461085439
Epoch: 51 | Iteration number: [330/4518] 7% | Training loss: 0.6887966932672442
Epoch: 51 | Iteration number: [340/4518] 7% | Training loss: 0.6887296422439463
Epoch: 51 | Iteration number: [350/4518] 7% | Training loss: 0.6886339507784163
Epoch: 51 | Iteration number: [360/4518] 7% | Training loss: 0.6885523796081543
Epoch: 51 | Iteration number: [370/4518] 8% | Training loss: 0.6885288062933329
Epoch: 51 | Iteration number: [380/4518] 8% | Training loss: 0.6884829652936835
Epoch: 51 | Iteration number: [390/4518] 8% | Training loss: 0.6884094343735622
Epoch: 51 | Iteration number: [400/4518] 8% | Training loss: 0.6883699452877045
Epoch: 51 | Iteration number: [410/4518] 9% | Training loss: 0.6883234909394892
Epoch: 51 | Iteration number: [420/4518] 9% | Training loss: 0.6882752089273362
Epoch: 51 | Iteration number: [430/4518] 9% | Training loss: 0.6882406082264213
Epoch: 51 | Iteration number: [440/4518] 9% | Training loss: 0.6882095079530369
Epoch: 51 | Iteration number: [450/4518] 9% | Training loss: 0.6881490961710612
Epoch: 51 | Iteration number: [460/4518] 10% | Training loss: 0.6881303300028262
Epoch: 51 | Iteration number: [470/4518] 10% | Training loss: 0.6881019782512746
Epoch: 51 | Iteration number: [480/4518] 10% | Training loss: 0.6880677219480276
Epoch: 51 | Iteration number: [490/4518] 10% | Training loss: 0.6880402155068456
Epoch: 51 | Iteration number: [500/4518] 11% | Training loss: 0.6880103462934494
Epoch: 51 | Iteration number: [510/4518] 11% | Training loss: 0.6879851185807995
Epoch: 51 | Iteration number: [520/4518] 11% | Training loss: 0.6879664458907567
Epoch: 51 | Iteration number: [530/4518] 11% | Training loss: 0.6879507504544168
Epoch: 51 | Iteration number: [540/4518] 11% | Training loss: 0.6879401432143317
Epoch: 51 | Iteration number: [550/4518] 12% | Training loss: 0.6879142854430459
Epoch: 51 | Iteration number: [560/4518] 12% | Training loss: 0.6879030120159898
Epoch: 51 | Iteration number: [570/4518] 12% | Training loss: 0.68789336440856
Epoch: 51 | Iteration number: [580/4518] 12% | Training loss: 0.687883493201486
Epoch: 51 | Iteration number: [590/4518] 13% | Training loss: 0.6878597931336549
Epoch: 51 | Iteration number: [600/4518] 13% | Training loss: 0.6878421835104624
Epoch: 51 | Iteration number: [610/4518] 13% | Training loss: 0.6878230125200553
Epoch: 51 | Iteration number: [620/4518] 13% | Training loss: 0.6878282850788485
Epoch: 51 | Iteration number: [630/4518] 13% | Training loss: 0.6878010105519068
Epoch: 51 | Iteration number: [640/4518] 14% | Training loss: 0.6877760084345936
Epoch: 51 | Iteration number: [650/4518] 14% | Training loss: 0.6877801860295809
Epoch: 51 | Iteration number: [660/4518] 14% | Training loss: 0.6877529548876213
Epoch: 51 | Iteration number: [670/4518] 14% | Training loss: 0.687727855835388
Epoch: 51 | Iteration number: [680/4518] 15% | Training loss: 0.6877275704460986
Epoch: 51 | Iteration number: [690/4518] 15% | Training loss: 0.6877416132152945
Epoch: 51 | Iteration number: [700/4518] 15% | Training loss: 0.687723560503551
Epoch: 51 | Iteration number: [710/4518] 15% | Training loss: 0.6877220070697891
Epoch: 51 | Iteration number: [720/4518] 15% | Training loss: 0.687708096123404
Epoch: 51 | Iteration number: [730/4518] 16% | Training loss: 0.6876622060390368
Epoch: 51 | Iteration number: [740/4518] 16% | Training loss: 0.6876344726697818
Epoch: 51 | Iteration number: [750/4518] 16% | Training loss: 0.6876271335283916
Epoch: 51 | Iteration number: [760/4518] 16% | Training loss: 0.6876020153886393
Epoch: 51 | Iteration number: [770/4518] 17% | Training loss: 0.6876022529292416
Epoch: 51 | Iteration number: [780/4518] 17% | Training loss: 0.6876010392720883
Epoch: 51 | Iteration number: [790/4518] 17% | Training loss: 0.6875932946989808
Epoch: 51 | Iteration number: [800/4518] 17% | Training loss: 0.6875738797336817
Epoch: 51 | Iteration number: [810/4518] 17% | Training loss: 0.6875740592126494
Epoch: 51 | Iteration number: [820/4518] 18% | Training loss: 0.6875573879334985
Epoch: 51 | Iteration number: [830/4518] 18% | Training loss: 0.6875380760933979
Epoch: 51 | Iteration number: [840/4518] 18% | Training loss: 0.6875378085034234
Epoch: 51 | Iteration number: [850/4518] 18% | Training loss: 0.6875257888962241
Epoch: 51 | Iteration number: [860/4518] 19% | Training loss: 0.6875180371972017
Epoch: 51 | Iteration number: [870/4518] 19% | Training loss: 0.687509969459183
Epoch: 51 | Iteration number: [880/4518] 19% | Training loss: 0.6875041960315271
Epoch: 51 | Iteration number: [890/4518] 19% | Training loss: 0.6874959916880962
Epoch: 51 | Iteration number: [900/4518] 19% | Training loss: 0.6874784149726232
Epoch: 51 | Iteration number: [910/4518] 20% | Training loss: 0.6874880575216733
Epoch: 51 | Iteration number: [920/4518] 20% | Training loss: 0.6874787837266922
Epoch: 51 | Iteration number: [930/4518] 20% | Training loss: 0.6874734943271965
Epoch: 51 | Iteration number: [940/4518] 20% | Training loss: 0.6874663424618701
Epoch: 51 | Iteration number: [950/4518] 21% | Training loss: 0.68747016316966
Epoch: 51 | Iteration number: [960/4518] 21% | Training loss: 0.6874629326164723
Epoch: 51 | Iteration number: [970/4518] 21% | Training loss: 0.6874603818372352
Epoch: 51 | Iteration number: [980/4518] 21% | Training loss: 0.6874498395287261
Epoch: 51 | Iteration number: [990/4518] 21% | Training loss: 0.6874494305162718
Epoch: 51 | Iteration number: [1000/4518] 22% | Training loss: 0.6874453152418136
Epoch: 51 | Iteration number: [1010/4518] 22% | Training loss: 0.6874335040550421
Epoch: 51 | Iteration number: [1020/4518] 22% | Training loss: 0.6874199284057991
Epoch: 51 | Iteration number: [1030/4518] 22% | Training loss: 0.6874199119007703
Epoch: 51 | Iteration number: [1040/4518] 23% | Training loss: 0.6874074071072616
Epoch: 51 | Iteration number: [1050/4518] 23% | Training loss: 0.6874025468031565
Epoch: 51 | Iteration number: [1060/4518] 23% | Training loss: 0.687392062567315
Epoch: 51 | Iteration number: [1070/4518] 23% | Training loss: 0.687392766564806
Epoch: 51 | Iteration number: [1080/4518] 23% | Training loss: 0.6873918198325016
Epoch: 51 | Iteration number: [1090/4518] 24% | Training loss: 0.6873996474327297
Epoch: 51 | Iteration number: [1100/4518] 24% | Training loss: 0.6873808228969573
Epoch: 51 | Iteration number: [1110/4518] 24% | Training loss: 0.6873796693913572
Epoch: 51 | Iteration number: [1120/4518] 24% | Training loss: 0.6873804752847978
Epoch: 51 | Iteration number: [1130/4518] 25% | Training loss: 0.6873851682760019
Epoch: 51 | Iteration number: [1140/4518] 25% | Training loss: 0.68738123309194
Epoch: 51 | Iteration number: [1150/4518] 25% | Training loss: 0.6873685238154038
Epoch: 51 | Iteration number: [1160/4518] 25% | Training loss: 0.6873609596285327
Epoch: 51 | Iteration number: [1170/4518] 25% | Training loss: 0.6873531926900912
Epoch: 51 | Iteration number: [1180/4518] 26% | Training loss: 0.687342614238545
Epoch: 51 | Iteration number: [1190/4518] 26% | Training loss: 0.687322081337456
Epoch: 51 | Iteration number: [1200/4518] 26% | Training loss: 0.6873214876155058
Epoch: 51 | Iteration number: [1210/4518] 26% | Training loss: 0.6873207792762882
Epoch: 51 | Iteration number: [1220/4518] 27% | Training loss: 0.6873201296466296
Epoch: 51 | Iteration number: [1230/4518] 27% | Training loss: 0.6873151117708625
Epoch: 51 | Iteration number: [1240/4518] 27% | Training loss: 0.6873163421788523
Epoch: 51 | Iteration number: [1250/4518] 27% | Training loss: 0.687307349729538
Epoch: 51 | Iteration number: [1260/4518] 27% | Training loss: 0.6872992707623375
Epoch: 51 | Iteration number: [1270/4518] 28% | Training loss: 0.6872927855318925
Epoch: 51 | Iteration number: [1280/4518] 28% | Training loss: 0.6872952246572822
Epoch: 51 | Iteration number: [1290/4518] 28% | Training loss: 0.6872856459876363
Epoch: 51 | Iteration number: [1300/4518] 28% | Training loss: 0.6872912384913518
Epoch: 51 | Iteration number: [1310/4518] 28% | Training loss: 0.6872924684568216
Epoch: 51 | Iteration number: [1320/4518] 29% | Training loss: 0.6872894608161666
Epoch: 51 | Iteration number: [1330/4518] 29% | Training loss: 0.6872861807059525
Epoch: 51 | Iteration number: [1340/4518] 29% | Training loss: 0.6872818468221977
Epoch: 51 | Iteration number: [1350/4518] 29% | Training loss: 0.6872715822855632
Epoch: 51 | Iteration number: [1360/4518] 30% | Training loss: 0.6872706312028801
Epoch: 51 | Iteration number: [1370/4518] 30% | Training loss: 0.6872740028548414
Epoch: 51 | Iteration number: [1380/4518] 30% | Training loss: 0.6872789075841075
Epoch: 51 | Iteration number: [1390/4518] 30% | Training loss: 0.6872684274646018
Epoch: 51 | Iteration number: [1400/4518] 30% | Training loss: 0.6872683988724436
Epoch: 51 | Iteration number: [1410/4518] 31% | Training loss: 0.6872677608161953
Epoch: 51 | Iteration number: [1420/4518] 31% | Training loss: 0.6872616069837355
Epoch: 51 | Iteration number: [1430/4518] 31% | Training loss: 0.687248791389532
Epoch: 51 | Iteration number: [1440/4518] 31% | Training loss: 0.6872486789193418
Epoch: 51 | Iteration number: [1450/4518] 32% | Training loss: 0.6872511616246454
Epoch: 51 | Iteration number: [1460/4518] 32% | Training loss: 0.687242150470002
Epoch: 51 | Iteration number: [1470/4518] 32% | Training loss: 0.687246141709438
Epoch: 51 | Iteration number: [1480/4518] 32% | Training loss: 0.6872500228720743
Epoch: 51 | Iteration number: [1490/4518] 32% | Training loss: 0.6872457335459305
Epoch: 51 | Iteration number: [1500/4518] 33% | Training loss: 0.6872441187302272
Epoch: 51 | Iteration number: [1510/4518] 33% | Training loss: 0.6872534072951765
Epoch: 51 | Iteration number: [1520/4518] 33% | Training loss: 0.6872562994690318
Epoch: 51 | Iteration number: [1530/4518] 33% | Training loss: 0.6872578595198837
Epoch: 51 | Iteration number: [1540/4518] 34% | Training loss: 0.6872589128358023
Epoch: 51 | Iteration number: [1550/4518] 34% | Training loss: 0.6872572680058018
Epoch: 51 | Iteration number: [1560/4518] 34% | Training loss: 0.6872472999187617
Epoch: 51 | Iteration number: [1570/4518] 34% | Training loss: 0.6872455112493722
Epoch: 51 | Iteration number: [1580/4518] 34% | Training loss: 0.6872433052787298
Epoch: 51 | Iteration number: [1590/4518] 35% | Training loss: 0.6872279301754334
Epoch: 51 | Iteration number: [1600/4518] 35% | Training loss: 0.6872168243676424
Epoch: 51 | Iteration number: [1610/4518] 35% | Training loss: 0.6872181972731715
Epoch: 51 | Iteration number: [1620/4518] 35% | Training loss: 0.6872111607113002
Epoch: 51 | Iteration number: [1630/4518] 36% | Training loss: 0.6872158631225305
Epoch: 51 | Iteration number: [1640/4518] 36% | Training loss: 0.6872120910664884
Epoch: 51 | Iteration number: [1650/4518] 36% | Training loss: 0.6872015315113645
Epoch: 51 | Iteration number: [1660/4518] 36% | Training loss: 0.6871967390359166
Epoch: 51 | Iteration number: [1670/4518] 36% | Training loss: 0.6871972686516311
Epoch: 51 | Iteration number: [1680/4518] 37% | Training loss: 0.6871919090903941
Epoch: 51 | Iteration number: [1690/4518] 37% | Training loss: 0.6871914548986762
Epoch: 51 | Iteration number: [1700/4518] 37% | Training loss: 0.6871968563163982
Epoch: 51 | Iteration number: [1710/4518] 37% | Training loss: 0.687191394163154
Epoch: 51 | Iteration number: [1720/4518] 38% | Training loss: 0.6871868008444476
Epoch: 51 | Iteration number: [1730/4518] 38% | Training loss: 0.6871894937374688
Epoch: 51 | Iteration number: [1740/4518] 38% | Training loss: 0.6871853838021728
Epoch: 51 | Iteration number: [1750/4518] 38% | Training loss: 0.6871838319301605
Epoch: 51 | Iteration number: [1760/4518] 38% | Training loss: 0.6871743542226878
Epoch: 51 | Iteration number: [1770/4518] 39% | Training loss: 0.6871723293921368
Epoch: 51 | Iteration number: [1780/4518] 39% | Training loss: 0.6871664471505733
Epoch: 51 | Iteration number: [1790/4518] 39% | Training loss: 0.68716875074962
Epoch: 51 | Iteration number: [1800/4518] 39% | Training loss: 0.6871666056248876
Epoch: 51 | Iteration number: [1810/4518] 40% | Training loss: 0.687161486846966
Epoch: 51 | Iteration number: [1820/4518] 40% | Training loss: 0.68715692621011
Epoch: 51 | Iteration number: [1830/4518] 40% | Training loss: 0.6871525212389524
Epoch: 51 | Iteration number: [1840/4518] 40% | Training loss: 0.6871496344066185
Epoch: 51 | Iteration number: [1850/4518] 40% | Training loss: 0.6871553844696766
Epoch: 51 | Iteration number: [1860/4518] 41% | Training loss: 0.687153890696905
Epoch: 51 | Iteration number: [1870/4518] 41% | Training loss: 0.6871576684044006
Epoch: 51 | Iteration number: [1880/4518] 41% | Training loss: 0.6871591989664321
Epoch: 51 | Iteration number: [1890/4518] 41% | Training loss: 0.6871545855330412
Epoch: 51 | Iteration number: [1900/4518] 42% | Training loss: 0.687147146745732
Epoch: 51 | Iteration number: [1910/4518] 42% | Training loss: 0.6871478234910215
Epoch: 51 | Iteration number: [1920/4518] 42% | Training loss: 0.6871456679888069
Epoch: 51 | Iteration number: [1930/4518] 42% | Training loss: 0.6871482107305774
Epoch: 51 | Iteration number: [1940/4518] 42% | Training loss: 0.6871433278027269
Epoch: 51 | Iteration number: [1950/4518] 43% | Training loss: 0.687140374764418
Epoch: 51 | Iteration number: [1960/4518] 43% | Training loss: 0.6871345254535578
Epoch: 51 | Iteration number: [1970/4518] 43% | Training loss: 0.6871338141146045
Epoch: 51 | Iteration number: [1980/4518] 43% | Training loss: 0.6871274155498756
Epoch: 51 | Iteration number: [1990/4518] 44% | Training loss: 0.6871282885122538
Epoch: 51 | Iteration number: [2000/4518] 44% | Training loss: 0.6871270429193973
Epoch: 51 | Iteration number: [2010/4518] 44% | Training loss: 0.6871282379425581
Epoch: 51 | Iteration number: [2020/4518] 44% | Training loss: 0.6871211385667915
Epoch: 51 | Iteration number: [2030/4518] 44% | Training loss: 0.687121173284324
Epoch: 51 | Iteration number: [2040/4518] 45% | Training loss: 0.6871137627491763
Epoch: 51 | Iteration number: [2050/4518] 45% | Training loss: 0.6871134313141427
Epoch: 51 | Iteration number: [2060/4518] 45% | Training loss: 0.6871119493709027
Epoch: 51 | Iteration number: [2070/4518] 45% | Training loss: 0.6871120665384376
Epoch: 51 | Iteration number: [2080/4518] 46% | Training loss: 0.6871157687730514
Epoch: 51 | Iteration number: [2090/4518] 46% | Training loss: 0.6871134275169464
Epoch: 51 | Iteration number: [2100/4518] 46% | Training loss: 0.6871167482932409
Epoch: 51 | Iteration number: [2110/4518] 46% | Training loss: 0.6871172312594138
Epoch: 51 | Iteration number: [2120/4518] 46% | Training loss: 0.6871199890971184
Epoch: 51 | Iteration number: [2130/4518] 47% | Training loss: 0.6871226114006669
Epoch: 51 | Iteration number: [2140/4518] 47% | Training loss: 0.687118169943863
Epoch: 51 | Iteration number: [2150/4518] 47% | Training loss: 0.6871089002420736
Epoch: 51 | Iteration number: [2160/4518] 47% | Training loss: 0.6871078239546882
Epoch: 51 | Iteration number: [2170/4518] 48% | Training loss: 0.6871090887054321
Epoch: 51 | Iteration number: [2180/4518] 48% | Training loss: 0.6871054318519907
Epoch: 51 | Iteration number: [2190/4518] 48% | Training loss: 0.6871068327122083
Epoch: 51 | Iteration number: [2200/4518] 48% | Training loss: 0.6871049938960508
Epoch: 51 | Iteration number: [2210/4518] 48% | Training loss: 0.6871046714922961
Epoch: 51 | Iteration number: [2220/4518] 49% | Training loss: 0.6870969023521956
Epoch: 51 | Iteration number: [2230/4518] 49% | Training loss: 0.6871015524917654
Epoch: 51 | Iteration number: [2240/4518] 49% | Training loss: 0.6871008636163813
Epoch: 51 | Iteration number: [2250/4518] 49% | Training loss: 0.6870979351467557
Epoch: 51 | Iteration number: [2260/4518] 50% | Training loss: 0.6870978464594985
Epoch: 51 | Iteration number: [2270/4518] 50% | Training loss: 0.6870981068863218
Epoch: 51 | Iteration number: [2280/4518] 50% | Training loss: 0.6870978588597816
Epoch: 51 | Iteration number: [2290/4518] 50% | Training loss: 0.6870963595319522
Epoch: 51 | Iteration number: [2300/4518] 50% | Training loss: 0.6870951125155325
Epoch: 51 | Iteration number: [2310/4518] 51% | Training loss: 0.6870939439509338
Epoch: 51 | Iteration number: [2320/4518] 51% | Training loss: 0.6870921683465613
Epoch: 51 | Iteration number: [2330/4518] 51% | Training loss: 0.6870860976210991
Epoch: 51 | Iteration number: [2340/4518] 51% | Training loss: 0.6870804651425435
Epoch: 51 | Iteration number: [2350/4518] 52% | Training loss: 0.6870796829842507
Epoch: 51 | Iteration number: [2360/4518] 52% | Training loss: 0.6870789825663728
Epoch: 51 | Iteration number: [2370/4518] 52% | Training loss: 0.687076243871375
Epoch: 51 | Iteration number: [2380/4518] 52% | Training loss: 0.6870718428317238
Epoch: 51 | Iteration number: [2390/4518] 52% | Training loss: 0.6870698771716162
Epoch: 51 | Iteration number: [2400/4518] 53% | Training loss: 0.6870668795456489
Epoch: 51 | Iteration number: [2410/4518] 53% | Training loss: 0.6870696330713534
Epoch: 51 | Iteration number: [2420/4518] 53% | Training loss: 0.6870687191890291
Epoch: 51 | Iteration number: [2430/4518] 53% | Training loss: 0.6870657971611729
Epoch: 51 | Iteration number: [2440/4518] 54% | Training loss: 0.6870644781433168
Epoch: 51 | Iteration number: [2450/4518] 54% | Training loss: 0.6870603444381636
Epoch: 51 | Iteration number: [2460/4518] 54% | Training loss: 0.6870622734713361
Epoch: 51 | Iteration number: [2470/4518] 54% | Training loss: 0.6870629500763619
Epoch: 51 | Iteration number: [2480/4518] 54% | Training loss: 0.6870560873900691
Epoch: 51 | Iteration number: [2490/4518] 55% | Training loss: 0.6870523582979379
Epoch: 51 | Iteration number: [2500/4518] 55% | Training loss: 0.6870543269395828
Epoch: 51 | Iteration number: [2510/4518] 55% | Training loss: 0.6870499384593204
Epoch: 51 | Iteration number: [2520/4518] 55% | Training loss: 0.6870519869147785
Epoch: 51 | Iteration number: [2530/4518] 55% | Training loss: 0.6870522711352397
Epoch: 51 | Iteration number: [2540/4518] 56% | Training loss: 0.687050646848566
Epoch: 51 | Iteration number: [2550/4518] 56% | Training loss: 0.6870454779793235
Epoch: 51 | Iteration number: [2560/4518] 56% | Training loss: 0.6870424097403884
Epoch: 51 | Iteration number: [2570/4518] 56% | Training loss: 0.6870416881973177
Epoch: 51 | Iteration number: [2580/4518] 57% | Training loss: 0.6870428949825523
Epoch: 51 | Iteration number: [2590/4518] 57% | Training loss: 0.6870424657254606
Epoch: 51 | Iteration number: [2600/4518] 57% | Training loss: 0.6870494447992398
Epoch: 51 | Iteration number: [2610/4518] 57% | Training loss: 0.6870465193900112
Epoch: 51 | Iteration number: [2620/4518] 57% | Training loss: 0.6870458520095767
Epoch: 51 | Iteration number: [2630/4518] 58% | Training loss: 0.6870435161508988
Epoch: 51 | Iteration number: [2640/4518] 58% | Training loss: 0.68704417993625
Epoch: 51 | Iteration number: [2650/4518] 58% | Training loss: 0.687041743633882
Epoch: 51 | Iteration number: [2660/4518] 58% | Training loss: 0.68704062776458
Epoch: 51 | Iteration number: [2670/4518] 59% | Training loss: 0.6870381544368543
Epoch: 51 | Iteration number: [2680/4518] 59% | Training loss: 0.6870377743422096
Epoch: 51 | Iteration number: [2690/4518] 59% | Training loss: 0.6870390357138055
Epoch: 51 | Iteration number: [2700/4518] 59% | Training loss: 0.6870382466139617
Epoch: 51 | Iteration number: [2710/4518] 59% | Training loss: 0.687034754779506
Epoch: 51 | Iteration number: [2720/4518] 60% | Training loss: 0.6870318260262994
Epoch: 51 | Iteration number: [2730/4518] 60% | Training loss: 0.687030177456992
Epoch: 51 | Iteration number: [2740/4518] 60% | Training loss: 0.6870288081630304
Epoch: 51 | Iteration number: [2750/4518] 60% | Training loss: 0.6870318983684887
Epoch: 51 | Iteration number: [2760/4518] 61% | Training loss: 0.6870321436420731
Epoch: 51 | Iteration number: [2770/4518] 61% | Training loss: 0.6870354871887593
Epoch: 51 | Iteration number: [2780/4518] 61% | Training loss: 0.6870290420467048
Epoch: 51 | Iteration number: [2790/4518] 61% | Training loss: 0.6870295234478503
Epoch: 51 | Iteration number: [2800/4518] 61% | Training loss: 0.6870300675715719
Epoch: 51 | Iteration number: [2810/4518] 62% | Training loss: 0.6870255401126006
Epoch: 51 | Iteration number: [2820/4518] 62% | Training loss: 0.6870242783575193
Epoch: 51 | Iteration number: [2830/4518] 62% | Training loss: 0.6870229861550955
Epoch: 51 | Iteration number: [2840/4518] 62% | Training loss: 0.6870192900300026
Epoch: 51 | Iteration number: [2850/4518] 63% | Training loss: 0.687015360050034
Epoch: 51 | Iteration number: [2860/4518] 63% | Training loss: 0.687013090615506
Epoch: 51 | Iteration number: [2870/4518] 63% | Training loss: 0.6870106777663015
Epoch: 51 | Iteration number: [2880/4518] 63% | Training loss: 0.6870123127682342
Epoch: 51 | Iteration number: [2890/4518] 63% | Training loss: 0.6870095474084769
Epoch: 51 | Iteration number: [2900/4518] 64% | Training loss: 0.6870061936049626
Epoch: 51 | Iteration number: [2910/4518] 64% | Training loss: 0.6870038075750227
Epoch: 51 | Iteration number: [2920/4518] 64% | Training loss: 0.6870026273474301
Epoch: 51 | Iteration number: [2930/4518] 64% | Training loss: 0.687003521972142
Epoch: 51 | Iteration number: [2940/4518] 65% | Training loss: 0.6870039760660963
Epoch: 51 | Iteration number: [2950/4518] 65% | Training loss: 0.6870036086187524
Epoch: 51 | Iteration number: [2960/4518] 65% | Training loss: 0.6870017069618444
Epoch: 51 | Iteration number: [2970/4518] 65% | Training loss: 0.6869994511307289
Epoch: 51 | Iteration number: [2980/4518] 65% | Training loss: 0.6869989616758871
Epoch: 51 | Iteration number: [2990/4518] 66% | Training loss: 0.6869963601480759
Epoch: 51 | Iteration number: [3000/4518] 66% | Training loss: 0.6869945484598478
Epoch: 51 | Iteration number: [3010/4518] 66% | Training loss: 0.6869928740781803
Epoch: 51 | Iteration number: [3020/4518] 66% | Training loss: 0.6869928131237725
Epoch: 51 | Iteration number: [3030/4518] 67% | Training loss: 0.6869891400384431
Epoch: 51 | Iteration number: [3040/4518] 67% | Training loss: 0.6869840804879602
Epoch: 51 | Iteration number: [3050/4518] 67% | Training loss: 0.686984414077196
Epoch: 51 | Iteration number: [3060/4518] 67% | Training loss: 0.6869868368494745
Epoch: 51 | Iteration number: [3070/4518] 67% | Training loss: 0.686988127736393
Epoch: 51 | Iteration number: [3080/4518] 68% | Training loss: 0.6869881454032737
Epoch: 51 | Iteration number: [3090/4518] 68% | Training loss: 0.6869947014310214
Epoch: 51 | Iteration number: [3100/4518] 68% | Training loss: 0.6869933062791824
Epoch: 51 | Iteration number: [3110/4518] 68% | Training loss: 0.6869962425860562
Epoch: 51 | Iteration number: [3120/4518] 69% | Training loss: 0.6869931866916327
Epoch: 51 | Iteration number: [3130/4518] 69% | Training loss: 0.6869914405452557
Epoch: 51 | Iteration number: [3140/4518] 69% | Training loss: 0.6869929164078585
Epoch: 51 | Iteration number: [3150/4518] 69% | Training loss: 0.6869906229064578
Epoch: 51 | Iteration number: [3160/4518] 69% | Training loss: 0.686994536353063
Epoch: 51 | Iteration number: [3170/4518] 70% | Training loss: 0.6869957880078806
Epoch: 51 | Iteration number: [3180/4518] 70% | Training loss: 0.6869929495472578
Epoch: 51 | Iteration number: [3190/4518] 70% | Training loss: 0.6869882225990296
Epoch: 51 | Iteration number: [3200/4518] 70% | Training loss: 0.6869910045526921
Epoch: 51 | Iteration number: [3210/4518] 71% | Training loss: 0.6869895126589363
Epoch: 51 | Iteration number: [3220/4518] 71% | Training loss: 0.6869911872266983
Epoch: 51 | Iteration number: [3230/4518] 71% | Training loss: 0.6869904667969459
Epoch: 51 | Iteration number: [3240/4518] 71% | Training loss: 0.686990412996139
Epoch: 51 | Iteration number: [3250/4518] 71% | Training loss: 0.6869923181533814
Epoch: 51 | Iteration number: [3260/4518] 72% | Training loss: 0.6869880583388673
Epoch: 51 | Iteration number: [3270/4518] 72% | Training loss: 0.6869842717224669
Epoch: 51 | Iteration number: [3280/4518] 72% | Training loss: 0.686987543215112
Epoch: 51 | Iteration number: [3290/4518] 72% | Training loss: 0.6869839794548811
Epoch: 51 | Iteration number: [3300/4518] 73% | Training loss: 0.6869800447514562
Epoch: 51 | Iteration number: [3310/4518] 73% | Training loss: 0.6869793482057277
Epoch: 51 | Iteration number: [3320/4518] 73% | Training loss: 0.6869810110115143
Epoch: 51 | Iteration number: [3330/4518] 73% | Training loss: 0.6869766240005378
Epoch: 51 | Iteration number: [3340/4518] 73% | Training loss: 0.6869780570090174
Epoch: 51 | Iteration number: [3350/4518] 74% | Training loss: 0.6869759996969308
Epoch: 51 | Iteration number: [3360/4518] 74% | Training loss: 0.6869774242596967
Epoch: 51 | Iteration number: [3370/4518] 74% | Training loss: 0.6869746726945882
Epoch: 51 | Iteration number: [3380/4518] 74% | Training loss: 0.6869754828468583
Epoch: 51 | Iteration number: [3390/4518] 75% | Training loss: 0.686977979795771
Epoch: 51 | Iteration number: [3400/4518] 75% | Training loss: 0.6869796929990544
Epoch: 51 | Iteration number: [3410/4518] 75% | Training loss: 0.6869787608073953
Epoch: 51 | Iteration number: [3420/4518] 75% | Training loss: 0.6869814749698193
Epoch: 51 | Iteration number: [3430/4518] 75% | Training loss: 0.6869798109413235
Epoch: 51 | Iteration number: [3440/4518] 76% | Training loss: 0.6869808860123158
Epoch: 51 | Iteration number: [3450/4518] 76% | Training loss: 0.6869784875538039
Epoch: 51 | Iteration number: [3460/4518] 76% | Training loss: 0.6869764452380253
Epoch: 51 | Iteration number: [3470/4518] 76% | Training loss: 0.6869740979300453
Epoch: 51 | Iteration number: [3480/4518] 77% | Training loss: 0.6869690492406658
Epoch: 51 | Iteration number: [3490/4518] 77% | Training loss: 0.6869663272341207
Epoch: 51 | Iteration number: [3500/4518] 77% | Training loss: 0.6869651820319039
Epoch: 51 | Iteration number: [3510/4518] 77% | Training loss: 0.686962792965082
Epoch: 51 | Iteration number: [3520/4518] 77% | Training loss: 0.6869647027416663
Epoch: 51 | Iteration number: [3530/4518] 78% | Training loss: 0.6869643394062269
Epoch: 51 | Iteration number: [3540/4518] 78% | Training loss: 0.6869637165197545
Epoch: 51 | Iteration number: [3550/4518] 78% | Training loss: 0.6869607557713145
Epoch: 51 | Iteration number: [3560/4518] 78% | Training loss: 0.6869597206959563
Epoch: 51 | Iteration number: [3570/4518] 79% | Training loss: 0.6869614756574818
Epoch: 51 | Iteration number: [3580/4518] 79% | Training loss: 0.6869622716191095
Epoch: 51 | Iteration number: [3590/4518] 79% | Training loss: 0.6869614209637337
Epoch: 51 | Iteration number: [3600/4518] 79% | Training loss: 0.6869613003399637
Epoch: 51 | Iteration number: [3610/4518] 79% | Training loss: 0.6869607345714464
Epoch: 51 | Iteration number: [3620/4518] 80% | Training loss: 0.6869652388174889
Epoch: 51 | Iteration number: [3630/4518] 80% | Training loss: 0.6869660600650409
Epoch: 51 | Iteration number: [3640/4518] 80% | Training loss: 0.6869674512154453
Epoch: 51 | Iteration number: [3650/4518] 80% | Training loss: 0.6869654447901739
Epoch: 51 | Iteration number: [3660/4518] 81% | Training loss: 0.6869651049375534
Epoch: 51 | Iteration number: [3670/4518] 81% | Training loss: 0.6869648429938168
Epoch: 51 | Iteration number: [3680/4518] 81% | Training loss: 0.6869657182175181
Epoch: 51 | Iteration number: [3690/4518] 81% | Training loss: 0.6869661509829162
Epoch: 51 | Iteration number: [3700/4518] 81% | Training loss: 0.6869625791182389
Epoch: 51 | Iteration number: [3710/4518] 82% | Training loss: 0.6869623496526014
Epoch: 51 | Iteration number: [3720/4518] 82% | Training loss: 0.6869592915459346
Epoch: 51 | Iteration number: [3730/4518] 82% | Training loss: 0.686956264010703
Epoch: 51 | Iteration number: [3740/4518] 82% | Training loss: 0.6869582853215264
Epoch: 51 | Iteration number: [3750/4518] 83% | Training loss: 0.6869567379792532
Epoch: 51 | Iteration number: [3760/4518] 83% | Training loss: 0.6869551470622103
Epoch: 51 | Iteration number: [3770/4518] 83% | Training loss: 0.6869549226539521
Epoch: 51 | Iteration number: [3780/4518] 83% | Training loss: 0.6869534166874709
Epoch: 51 | Iteration number: [3790/4518] 83% | Training loss: 0.6869506490262014
Epoch: 51 | Iteration number: [3800/4518] 84% | Training loss: 0.6869501237806521
Epoch: 51 | Iteration number: [3810/4518] 84% | Training loss: 0.6869499046971479
Epoch: 51 | Iteration number: [3820/4518] 84% | Training loss: 0.6869495892087827
Epoch: 51 | Iteration number: [3830/4518] 84% | Training loss: 0.6869488292356696
Epoch: 51 | Iteration number: [3840/4518] 84% | Training loss: 0.686949408504491
Epoch: 51 | Iteration number: [3850/4518] 85% | Training loss: 0.6869468672709031
Epoch: 51 | Iteration number: [3860/4518] 85% | Training loss: 0.686949513659576
Epoch: 51 | Iteration number: [3870/4518] 85% | Training loss: 0.6869493632507571
Epoch: 51 | Iteration number: [3880/4518] 85% | Training loss: 0.6869480200035056
Epoch: 51 | Iteration number: [3890/4518] 86% | Training loss: 0.6869459527010783
Epoch: 51 | Iteration number: [3900/4518] 86% | Training loss: 0.6869465659673397
Epoch: 51 | Iteration number: [3910/4518] 86% | Training loss: 0.6869451284561011
Epoch: 51 | Iteration number: [3920/4518] 86% | Training loss: 0.6869458775435175
Epoch: 51 | Iteration number: [3930/4518] 86% | Training loss: 0.6869446348142988
Epoch: 51 | Iteration number: [3940/4518] 87% | Training loss: 0.686945322987997
Epoch: 51 | Iteration number: [3950/4518] 87% | Training loss: 0.6869477945038035
Epoch: 51 | Iteration number: [3960/4518] 87% | Training loss: 0.6869458450060902
Epoch: 51 | Iteration number: [3970/4518] 87% | Training loss: 0.6869461461488786
Epoch: 51 | Iteration number: [3980/4518] 88% | Training loss: 0.6869484833586755
Epoch: 51 | Iteration number: [3990/4518] 88% | Training loss: 0.6869506069890837
Epoch: 51 | Iteration number: [4000/4518] 88% | Training loss: 0.6869515562951565
Epoch: 51 | Iteration number: [4010/4518] 88% | Training loss: 0.6869521897778547
Epoch: 51 | Iteration number: [4020/4518] 88% | Training loss: 0.686950501562351
Epoch: 51 | Iteration number: [4030/4518] 89% | Training loss: 0.6869509830812071
Epoch: 51 | Iteration number: [4040/4518] 89% | Training loss: 0.6869526201988211
Epoch: 51 | Iteration number: [4050/4518] 89% | Training loss: 0.6869518184661865
Epoch: 51 | Iteration number: [4060/4518] 89% | Training loss: 0.6869536168322774
Epoch: 51 | Iteration number: [4070/4518] 90% | Training loss: 0.6869538046071805
Epoch: 51 | Iteration number: [4080/4518] 90% | Training loss: 0.6869511212642286
Epoch: 51 | Iteration number: [4090/4518] 90% | Training loss: 0.6869511828300131
Epoch: 51 | Iteration number: [4100/4518] 90% | Training loss: 0.6869554644823075
Epoch: 51 | Iteration number: [4110/4518] 90% | Training loss: 0.6869567013424969
Epoch: 51 | Iteration number: [4120/4518] 91% | Training loss: 0.6869556902392396
Epoch: 51 | Iteration number: [4130/4518] 91% | Training loss: 0.6869554694859226
Epoch: 51 | Iteration number: [4140/4518] 91% | Training loss: 0.686953580825801
Epoch: 51 | Iteration number: [4150/4518] 91% | Training loss: 0.6869510535303368
Epoch: 51 | Iteration number: [4160/4518] 92% | Training loss: 0.6869516133832244
Epoch: 51 | Iteration number: [4170/4518] 92% | Training loss: 0.6869524350269235
Epoch: 51 | Iteration number: [4180/4518] 92% | Training loss: 0.6869512114228244
Epoch: 51 | Iteration number: [4190/4518] 92% | Training loss: 0.6869528082503908
Epoch: 51 | Iteration number: [4200/4518] 92% | Training loss: 0.686952350238959
Epoch: 51 | Iteration number: [4210/4518] 93% | Training loss: 0.6869561821576252
Epoch: 51 | Iteration number: [4220/4518] 93% | Training loss: 0.6869586295426174
Epoch: 51 | Iteration number: [4230/4518] 93% | Training loss: 0.6869601520522548
Epoch: 51 | Iteration number: [4240/4518] 93% | Training loss: 0.6869617727848719
Epoch: 51 | Iteration number: [4250/4518] 94% | Training loss: 0.6869581924466526
Epoch: 51 | Iteration number: [4260/4518] 94% | Training loss: 0.686961780537462
Epoch: 51 | Iteration number: [4270/4518] 94% | Training loss: 0.6869631737400832
Epoch: 51 | Iteration number: [4280/4518] 94% | Training loss: 0.6869601127978797
Epoch: 51 | Iteration number: [4290/4518] 94% | Training loss: 0.6869613110324442
Epoch: 51 | Iteration number: [4300/4518] 95% | Training loss: 0.686962356775306
Epoch: 51 | Iteration number: [4310/4518] 95% | Training loss: 0.686962404715766
Epoch: 51 | Iteration number: [4320/4518] 95% | Training loss: 0.6869642182632729
Epoch: 51 | Iteration number: [4330/4518] 95% | Training loss: 0.6869648983104124
Epoch: 51 | Iteration number: [4340/4518] 96% | Training loss: 0.6869638505893918
Epoch: 51 | Iteration number: [4350/4518] 96% | Training loss: 0.6869661521500554
Epoch: 51 | Iteration number: [4360/4518] 96% | Training loss: 0.6869643301181837
Epoch: 51 | Iteration number: [4370/4518] 96% | Training loss: 0.686961231215322
Epoch: 51 | Iteration number: [4380/4518] 96% | Training loss: 0.6869608209149478
Epoch: 51 | Iteration number: [4390/4518] 97% | Training loss: 0.686959641479414
Epoch: 51 | Iteration number: [4400/4518] 97% | Training loss: 0.6869591302627867
Epoch: 51 | Iteration number: [4410/4518] 97% | Training loss: 0.6869601993468883
Epoch: 51 | Iteration number: [4420/4518] 97% | Training loss: 0.6869604166546558
Epoch: 51 | Iteration number: [4430/4518] 98% | Training loss: 0.6869604649177793
Epoch: 51 | Iteration number: [4440/4518] 98% | Training loss: 0.6869592042790876
Epoch: 51 | Iteration number: [4450/4518] 98% | Training loss: 0.6869608982493368
Epoch: 51 | Iteration number: [4460/4518] 98% | Training loss: 0.6869583828967782
Epoch: 51 | Iteration number: [4470/4518] 98% | Training loss: 0.6869558276212722
Epoch: 51 | Iteration number: [4480/4518] 99% | Training loss: 0.6869562513594116
Epoch: 51 | Iteration number: [4490/4518] 99% | Training loss: 0.6869591096594498
Epoch: 51 | Iteration number: [4500/4518] 99% | Training loss: 0.6869608597358068
Epoch: 51 | Iteration number: [4510/4518] 99% | Training loss: 0.686956717645514

 End of epoch: 51 | Train Loss: 0.6868057802035884 | Training Time: 632 

 End of epoch: 51 | Eval Loss: 0.6897883171937904 | Evaluating Time: 17 
Epoch: 52 | Iteration number: [10/4518] 0% | Training loss: 0.7547933101654053
Epoch: 52 | Iteration number: [20/4518] 0% | Training loss: 0.72022265791893
Epoch: 52 | Iteration number: [30/4518] 0% | Training loss: 0.7087926089763641
Epoch: 52 | Iteration number: [40/4518] 0% | Training loss: 0.7032481923699379
Epoch: 52 | Iteration number: [50/4518] 1% | Training loss: 0.6994484460353851
Epoch: 52 | Iteration number: [60/4518] 1% | Training loss: 0.697209561864535
Epoch: 52 | Iteration number: [70/4518] 1% | Training loss: 0.6956645437649318
Epoch: 52 | Iteration number: [80/4518] 1% | Training loss: 0.6945850446820259
Epoch: 52 | Iteration number: [90/4518] 1% | Training loss: 0.6937219871415032
Epoch: 52 | Iteration number: [100/4518] 2% | Training loss: 0.6929307472705841
Epoch: 52 | Iteration number: [110/4518] 2% | Training loss: 0.6924095191738823
Epoch: 52 | Iteration number: [120/4518] 2% | Training loss: 0.6920560091733933
Epoch: 52 | Iteration number: [130/4518] 2% | Training loss: 0.6917489734979776
Epoch: 52 | Iteration number: [140/4518] 3% | Training loss: 0.6914814983095442
Epoch: 52 | Iteration number: [150/4518] 3% | Training loss: 0.691240488688151
Epoch: 52 | Iteration number: [160/4518] 3% | Training loss: 0.6909400604665279
Epoch: 52 | Iteration number: [170/4518] 3% | Training loss: 0.6906990843660691
Epoch: 52 | Iteration number: [180/4518] 3% | Training loss: 0.6905598958333333
Epoch: 52 | Iteration number: [190/4518] 4% | Training loss: 0.6903944119026787
Epoch: 52 | Iteration number: [200/4518] 4% | Training loss: 0.6902682971954346
Epoch: 52 | Iteration number: [210/4518] 4% | Training loss: 0.6901387867473421
Epoch: 52 | Iteration number: [220/4518] 4% | Training loss: 0.6899908136237751
Epoch: 52 | Iteration number: [230/4518] 5% | Training loss: 0.689869136913963
Epoch: 52 | Iteration number: [240/4518] 5% | Training loss: 0.6897139005362988
Epoch: 52 | Iteration number: [250/4518] 5% | Training loss: 0.6896071510314942
Epoch: 52 | Iteration number: [260/4518] 5% | Training loss: 0.6894894822285725
Epoch: 52 | Iteration number: [270/4518] 5% | Training loss: 0.6894286725256178
Epoch: 52 | Iteration number: [280/4518] 6% | Training loss: 0.6893277555704117
Epoch: 52 | Iteration number: [290/4518] 6% | Training loss: 0.6892081620364353
Epoch: 52 | Iteration number: [300/4518] 6% | Training loss: 0.6890858695904414
Epoch: 52 | Iteration number: [310/4518] 6% | Training loss: 0.6890149018456859
Epoch: 52 | Iteration number: [320/4518] 7% | Training loss: 0.6889488378539681
Epoch: 52 | Iteration number: [330/4518] 7% | Training loss: 0.6888821177410357
Epoch: 52 | Iteration number: [340/4518] 7% | Training loss: 0.6887842178344726
Epoch: 52 | Iteration number: [350/4518] 7% | Training loss: 0.6887286613668714
Epoch: 52 | Iteration number: [360/4518] 7% | Training loss: 0.6886521741747856
Epoch: 52 | Iteration number: [370/4518] 8% | Training loss: 0.6886228567845113
Epoch: 52 | Iteration number: [380/4518] 8% | Training loss: 0.6886051008575841
Epoch: 52 | Iteration number: [390/4518] 8% | Training loss: 0.6885205522561685
Epoch: 52 | Iteration number: [400/4518] 8% | Training loss: 0.6884845021367073
Epoch: 52 | Iteration number: [410/4518] 9% | Training loss: 0.6884608851700295
Epoch: 52 | Iteration number: [420/4518] 9% | Training loss: 0.6884388449646178
Epoch: 52 | Iteration number: [430/4518] 9% | Training loss: 0.688374874480935
Epoch: 52 | Iteration number: [440/4518] 9% | Training loss: 0.6883517621593042
Epoch: 52 | Iteration number: [450/4518] 9% | Training loss: 0.6882970690727234
Epoch: 52 | Iteration number: [460/4518] 10% | Training loss: 0.6882504174242849
Epoch: 52 | Iteration number: [470/4518] 10% | Training loss: 0.6882061144138905
Epoch: 52 | Iteration number: [480/4518] 10% | Training loss: 0.6881547946482897
Epoch: 52 | Iteration number: [490/4518] 10% | Training loss: 0.6881140486318238
Epoch: 52 | Iteration number: [500/4518] 11% | Training loss: 0.6880867557525635
Epoch: 52 | Iteration number: [510/4518] 11% | Training loss: 0.6880538654093649
Epoch: 52 | Iteration number: [520/4518] 11% | Training loss: 0.6880364615183611
Epoch: 52 | Iteration number: [530/4518] 11% | Training loss: 0.6880227074308215
Epoch: 52 | Iteration number: [540/4518] 11% | Training loss: 0.6880051097384206
Epoch: 52 | Iteration number: [550/4518] 12% | Training loss: 0.6879855811595916
Epoch: 52 | Iteration number: [560/4518] 12% | Training loss: 0.6879635263766561
Epoch: 52 | Iteration number: [570/4518] 12% | Training loss: 0.6879184457293728
Epoch: 52 | Iteration number: [580/4518] 12% | Training loss: 0.6878866868800131
Epoch: 52 | Iteration number: [590/4518] 13% | Training loss: 0.6878636133872856
Epoch: 52 | Iteration number: [600/4518] 13% | Training loss: 0.6878545675675074
Epoch: 52 | Iteration number: [610/4518] 13% | Training loss: 0.687831589530726
Epoch: 52 | Iteration number: [620/4518] 13% | Training loss: 0.6878184773268238
Epoch: 52 | Iteration number: [630/4518] 13% | Training loss: 0.6877841637248084
Epoch: 52 | Iteration number: [640/4518] 14% | Training loss: 0.6877774486318231
Epoch: 52 | Iteration number: [650/4518] 14% | Training loss: 0.6877536084101751
Epoch: 52 | Iteration number: [660/4518] 14% | Training loss: 0.6877414559776133
Epoch: 52 | Iteration number: [670/4518] 14% | Training loss: 0.6877104959381161
Epoch: 52 | Iteration number: [680/4518] 15% | Training loss: 0.6876771126599873
Epoch: 52 | Iteration number: [690/4518] 15% | Training loss: 0.6876662141171055
Epoch: 52 | Iteration number: [700/4518] 15% | Training loss: 0.6876481109006064
Epoch: 52 | Iteration number: [710/4518] 15% | Training loss: 0.6876421711814236
Epoch: 52 | Iteration number: [720/4518] 15% | Training loss: 0.6876262005004617
Epoch: 52 | Iteration number: [730/4518] 16% | Training loss: 0.6876266815074502
Epoch: 52 | Iteration number: [740/4518] 16% | Training loss: 0.6876138636389294
Epoch: 52 | Iteration number: [750/4518] 16% | Training loss: 0.6876009449164072
Epoch: 52 | Iteration number: [760/4518] 16% | Training loss: 0.6875864382637175
Epoch: 52 | Iteration number: [770/4518] 17% | Training loss: 0.6875799183721666
Epoch: 52 | Iteration number: [780/4518] 17% | Training loss: 0.6875816269562794
Epoch: 52 | Iteration number: [790/4518] 17% | Training loss: 0.687573594081251
Epoch: 52 | Iteration number: [800/4518] 17% | Training loss: 0.6875640971213579
Epoch: 52 | Iteration number: [810/4518] 17% | Training loss: 0.6875546994768543
Epoch: 52 | Iteration number: [820/4518] 18% | Training loss: 0.6875318296071959
Epoch: 52 | Iteration number: [830/4518] 18% | Training loss: 0.6875154629529241
Epoch: 52 | Iteration number: [840/4518] 18% | Training loss: 0.6875294643498603
Epoch: 52 | Iteration number: [850/4518] 18% | Training loss: 0.6875124195042779
Epoch: 52 | Iteration number: [860/4518] 19% | Training loss: 0.6874960659548294
Epoch: 52 | Iteration number: [870/4518] 19% | Training loss: 0.6874817486467033
Epoch: 52 | Iteration number: [880/4518] 19% | Training loss: 0.6874630208042535
Epoch: 52 | Iteration number: [890/4518] 19% | Training loss: 0.6874514471279102
Epoch: 52 | Iteration number: [900/4518] 19% | Training loss: 0.6874462472730213
Epoch: 52 | Iteration number: [910/4518] 20% | Training loss: 0.687443678523158
Epoch: 52 | Iteration number: [920/4518] 20% | Training loss: 0.6874275662976762
Epoch: 52 | Iteration number: [930/4518] 20% | Training loss: 0.6874253687679127
Epoch: 52 | Iteration number: [940/4518] 20% | Training loss: 0.6874201985749793
Epoch: 52 | Iteration number: [950/4518] 21% | Training loss: 0.6874227088376096
Epoch: 52 | Iteration number: [960/4518] 21% | Training loss: 0.6874311031773687
Epoch: 52 | Iteration number: [970/4518] 21% | Training loss: 0.6874208981228858
Epoch: 52 | Iteration number: [980/4518] 21% | Training loss: 0.6874258395968651
Epoch: 52 | Iteration number: [990/4518] 21% | Training loss: 0.6874229466674304
Epoch: 52 | Iteration number: [1000/4518] 22% | Training loss: 0.6874164606928825
Epoch: 52 | Iteration number: [1010/4518] 22% | Training loss: 0.6874138377680636
Epoch: 52 | Iteration number: [1020/4518] 22% | Training loss: 0.6874066893960915
Epoch: 52 | Iteration number: [1030/4518] 22% | Training loss: 0.6873965841473885
Epoch: 52 | Iteration number: [1040/4518] 23% | Training loss: 0.6873941162457833
Epoch: 52 | Iteration number: [1050/4518] 23% | Training loss: 0.6874023405143193
Epoch: 52 | Iteration number: [1060/4518] 23% | Training loss: 0.6873897306761652
Epoch: 52 | Iteration number: [1070/4518] 23% | Training loss: 0.6873802219595865
Epoch: 52 | Iteration number: [1080/4518] 23% | Training loss: 0.6873679374103193
Epoch: 52 | Iteration number: [1090/4518] 24% | Training loss: 0.6873651040803402
Epoch: 52 | Iteration number: [1100/4518] 24% | Training loss: 0.6873500868407163
Epoch: 52 | Iteration number: [1110/4518] 24% | Training loss: 0.687353227804373
Epoch: 52 | Iteration number: [1120/4518] 24% | Training loss: 0.6873420206031629
Epoch: 52 | Iteration number: [1130/4518] 25% | Training loss: 0.6873404105680179
Epoch: 52 | Iteration number: [1140/4518] 25% | Training loss: 0.6873393589990181
Epoch: 52 | Iteration number: [1150/4518] 25% | Training loss: 0.6873377714468085
Epoch: 52 | Iteration number: [1160/4518] 25% | Training loss: 0.6873418784860907
Epoch: 52 | Iteration number: [1170/4518] 25% | Training loss: 0.687325218345365
Epoch: 52 | Iteration number: [1180/4518] 26% | Training loss: 0.687325489824101
Epoch: 52 | Iteration number: [1190/4518] 26% | Training loss: 0.687325903648088
Epoch: 52 | Iteration number: [1200/4518] 26% | Training loss: 0.6873142497241497
Epoch: 52 | Iteration number: [1210/4518] 26% | Training loss: 0.6873028010868829
Epoch: 52 | Iteration number: [1220/4518] 27% | Training loss: 0.6873021972961113
Epoch: 52 | Iteration number: [1230/4518] 27% | Training loss: 0.6873006231416532
Epoch: 52 | Iteration number: [1240/4518] 27% | Training loss: 0.687295765021155
Epoch: 52 | Iteration number: [1250/4518] 27% | Training loss: 0.6872815051078797
Epoch: 52 | Iteration number: [1260/4518] 27% | Training loss: 0.687278742922677
Epoch: 52 | Iteration number: [1270/4518] 28% | Training loss: 0.6872748878997141
Epoch: 52 | Iteration number: [1280/4518] 28% | Training loss: 0.6872787784785033
Epoch: 52 | Iteration number: [1290/4518] 28% | Training loss: 0.6872679787088735
Epoch: 52 | Iteration number: [1300/4518] 28% | Training loss: 0.687264333825845
Epoch: 52 | Iteration number: [1310/4518] 28% | Training loss: 0.6872636336861676
Epoch: 52 | Iteration number: [1320/4518] 29% | Training loss: 0.6872732296586037
Epoch: 52 | Iteration number: [1330/4518] 29% | Training loss: 0.6872711848047443
Epoch: 52 | Iteration number: [1340/4518] 29% | Training loss: 0.6872659732601536
Epoch: 52 | Iteration number: [1350/4518] 29% | Training loss: 0.6872626466662796
Epoch: 52 | Iteration number: [1360/4518] 30% | Training loss: 0.6872525807250949
Epoch: 52 | Iteration number: [1370/4518] 30% | Training loss: 0.6872509448197637
Epoch: 52 | Iteration number: [1380/4518] 30% | Training loss: 0.6872446013965469
Epoch: 52 | Iteration number: [1390/4518] 30% | Training loss: 0.6872499556850187
Epoch: 52 | Iteration number: [1400/4518] 30% | Training loss: 0.6872481037037713
Epoch: 52 | Iteration number: [1410/4518] 31% | Training loss: 0.6872471830946334
Epoch: 52 | Iteration number: [1420/4518] 31% | Training loss: 0.687244958650898
Epoch: 52 | Iteration number: [1430/4518] 31% | Training loss: 0.6872364472259175
Epoch: 52 | Iteration number: [1440/4518] 31% | Training loss: 0.6872341288874547
Epoch: 52 | Iteration number: [1450/4518] 32% | Training loss: 0.6872417581903524
Epoch: 52 | Iteration number: [1460/4518] 32% | Training loss: 0.6872342301966393
Epoch: 52 | Iteration number: [1470/4518] 32% | Training loss: 0.6872392130141356
Epoch: 52 | Iteration number: [1480/4518] 32% | Training loss: 0.6872399400214891
Epoch: 52 | Iteration number: [1490/4518] 32% | Training loss: 0.6872360431907961
Epoch: 52 | Iteration number: [1500/4518] 33% | Training loss: 0.6872354714075725
Epoch: 52 | Iteration number: [1510/4518] 33% | Training loss: 0.6872275309452158
Epoch: 52 | Iteration number: [1520/4518] 33% | Training loss: 0.6872258874930833
Epoch: 52 | Iteration number: [1530/4518] 33% | Training loss: 0.6872188397092757
Epoch: 52 | Iteration number: [1540/4518] 34% | Training loss: 0.6872190931787738
Epoch: 52 | Iteration number: [1550/4518] 34% | Training loss: 0.6872172198757048
Epoch: 52 | Iteration number: [1560/4518] 34% | Training loss: 0.6872084571000857
Epoch: 52 | Iteration number: [1570/4518] 34% | Training loss: 0.6872008606127114
Epoch: 52 | Iteration number: [1580/4518] 34% | Training loss: 0.6871964414662952
Epoch: 52 | Iteration number: [1590/4518] 35% | Training loss: 0.6871929399622312
Epoch: 52 | Iteration number: [1600/4518] 35% | Training loss: 0.6871821315214038
Epoch: 52 | Iteration number: [1610/4518] 35% | Training loss: 0.687174034451846
Epoch: 52 | Iteration number: [1620/4518] 35% | Training loss: 0.6871756047746281
Epoch: 52 | Iteration number: [1630/4518] 36% | Training loss: 0.6871719687262927
Epoch: 52 | Iteration number: [1640/4518] 36% | Training loss: 0.6871738727499799
Epoch: 52 | Iteration number: [1650/4518] 36% | Training loss: 0.687166943694606
Epoch: 52 | Iteration number: [1660/4518] 36% | Training loss: 0.687166176574776
Epoch: 52 | Iteration number: [1670/4518] 36% | Training loss: 0.6871605378068136
Epoch: 52 | Iteration number: [1680/4518] 37% | Training loss: 0.6871603893382209
Epoch: 52 | Iteration number: [1690/4518] 37% | Training loss: 0.6871596998364262
Epoch: 52 | Iteration number: [1700/4518] 37% | Training loss: 0.6871521661211463
Epoch: 52 | Iteration number: [1710/4518] 37% | Training loss: 0.6871515223505902
Epoch: 52 | Iteration number: [1720/4518] 38% | Training loss: 0.6871427983392117
Epoch: 52 | Iteration number: [1730/4518] 38% | Training loss: 0.6871432247533964
Epoch: 52 | Iteration number: [1740/4518] 38% | Training loss: 0.6871359186953512
Epoch: 52 | Iteration number: [1750/4518] 38% | Training loss: 0.687136964900153
Epoch: 52 | Iteration number: [1760/4518] 38% | Training loss: 0.687141890078783
Epoch: 52 | Iteration number: [1770/4518] 39% | Training loss: 0.6871411396958733
Epoch: 52 | Iteration number: [1780/4518] 39% | Training loss: 0.6871355559383885
Epoch: 52 | Iteration number: [1790/4518] 39% | Training loss: 0.687139831408442
Epoch: 52 | Iteration number: [1800/4518] 39% | Training loss: 0.6871346564425362
Epoch: 52 | Iteration number: [1810/4518] 40% | Training loss: 0.6871312435819299
Epoch: 52 | Iteration number: [1820/4518] 40% | Training loss: 0.6871382542691388
Epoch: 52 | Iteration number: [1830/4518] 40% | Training loss: 0.687134666553612
Epoch: 52 | Iteration number: [1840/4518] 40% | Training loss: 0.6871287250648375
Epoch: 52 | Iteration number: [1850/4518] 40% | Training loss: 0.6871281269756523
Epoch: 52 | Iteration number: [1860/4518] 41% | Training loss: 0.6871229661408291
Epoch: 52 | Iteration number: [1870/4518] 41% | Training loss: 0.6871185338752155
Epoch: 52 | Iteration number: [1880/4518] 41% | Training loss: 0.6871128422148685
Epoch: 52 | Iteration number: [1890/4518] 41% | Training loss: 0.6871184162992648
Epoch: 52 | Iteration number: [1900/4518] 42% | Training loss: 0.687112329508129
Epoch: 52 | Iteration number: [1910/4518] 42% | Training loss: 0.6871095122779227
Epoch: 52 | Iteration number: [1920/4518] 42% | Training loss: 0.6871087022436162
Epoch: 52 | Iteration number: [1930/4518] 42% | Training loss: 0.6871071469289651
Epoch: 52 | Iteration number: [1940/4518] 42% | Training loss: 0.6871065435950289
Epoch: 52 | Iteration number: [1950/4518] 43% | Training loss: 0.6871069342662126
Epoch: 52 | Iteration number: [1960/4518] 43% | Training loss: 0.687107888441913
Epoch: 52 | Iteration number: [1970/4518] 43% | Training loss: 0.6871054164044142
Epoch: 52 | Iteration number: [1980/4518] 43% | Training loss: 0.6871060117928669
Epoch: 52 | Iteration number: [1990/4518] 44% | Training loss: 0.6871041082557122
Epoch: 52 | Iteration number: [2000/4518] 44% | Training loss: 0.6871054392755032
Epoch: 52 | Iteration number: [2010/4518] 44% | Training loss: 0.6871018661195366
Epoch: 52 | Iteration number: [2020/4518] 44% | Training loss: 0.6870974325307525
Epoch: 52 | Iteration number: [2030/4518] 44% | Training loss: 0.6870932072547856
Epoch: 52 | Iteration number: [2040/4518] 45% | Training loss: 0.6870914789683679
Epoch: 52 | Iteration number: [2050/4518] 45% | Training loss: 0.6870884588869607
Epoch: 52 | Iteration number: [2060/4518] 45% | Training loss: 0.6870884682946992
Epoch: 52 | Iteration number: [2070/4518] 45% | Training loss: 0.6870787619104708
Epoch: 52 | Iteration number: [2080/4518] 46% | Training loss: 0.6870791418907735
Epoch: 52 | Iteration number: [2090/4518] 46% | Training loss: 0.6870798512508994
Epoch: 52 | Iteration number: [2100/4518] 46% | Training loss: 0.6870747375488281
Epoch: 52 | Iteration number: [2110/4518] 46% | Training loss: 0.6870776771086652
Epoch: 52 | Iteration number: [2120/4518] 46% | Training loss: 0.6870733427270403
Epoch: 52 | Iteration number: [2130/4518] 47% | Training loss: 0.6870682077508578
Epoch: 52 | Iteration number: [2140/4518] 47% | Training loss: 0.6870683939936005
Epoch: 52 | Iteration number: [2150/4518] 47% | Training loss: 0.6870691330765569
Epoch: 52 | Iteration number: [2160/4518] 47% | Training loss: 0.6870632821487056
Epoch: 52 | Iteration number: [2170/4518] 48% | Training loss: 0.687060643451005
Epoch: 52 | Iteration number: [2180/4518] 48% | Training loss: 0.6870640390783275
Epoch: 52 | Iteration number: [2190/4518] 48% | Training loss: 0.6870629569166872
Epoch: 52 | Iteration number: [2200/4518] 48% | Training loss: 0.6870620409196073
Epoch: 52 | Iteration number: [2210/4518] 48% | Training loss: 0.6870559999575981
Epoch: 52 | Iteration number: [2220/4518] 49% | Training loss: 0.6870564909400166
Epoch: 52 | Iteration number: [2230/4518] 49% | Training loss: 0.6870514670562317
Epoch: 52 | Iteration number: [2240/4518] 49% | Training loss: 0.6870479522539037
Epoch: 52 | Iteration number: [2250/4518] 49% | Training loss: 0.6870460955566831
Epoch: 52 | Iteration number: [2260/4518] 50% | Training loss: 0.6870471677948943
Epoch: 52 | Iteration number: [2270/4518] 50% | Training loss: 0.6870476188901238
Epoch: 52 | Iteration number: [2280/4518] 50% | Training loss: 0.6870425824533429
Epoch: 52 | Iteration number: [2290/4518] 50% | Training loss: 0.6870403836387734
Epoch: 52 | Iteration number: [2300/4518] 50% | Training loss: 0.6870407524834509
Epoch: 52 | Iteration number: [2310/4518] 51% | Training loss: 0.687043074302343
Epoch: 52 | Iteration number: [2320/4518] 51% | Training loss: 0.6870371434709122
Epoch: 52 | Iteration number: [2330/4518] 51% | Training loss: 0.6870399810981341
Epoch: 52 | Iteration number: [2340/4518] 51% | Training loss: 0.6870443323738554
Epoch: 52 | Iteration number: [2350/4518] 52% | Training loss: 0.6870424803774408
Epoch: 52 | Iteration number: [2360/4518] 52% | Training loss: 0.6870419610859984
Epoch: 52 | Iteration number: [2370/4518] 52% | Training loss: 0.6870437835590749
Epoch: 52 | Iteration number: [2380/4518] 52% | Training loss: 0.6870392649364071
Epoch: 52 | Iteration number: [2390/4518] 52% | Training loss: 0.6870417882707828
Epoch: 52 | Iteration number: [2400/4518] 53% | Training loss: 0.6870435715466737
Epoch: 52 | Iteration number: [2410/4518] 53% | Training loss: 0.6870450548363919
Epoch: 52 | Iteration number: [2420/4518] 53% | Training loss: 0.6870402691778073
Epoch: 52 | Iteration number: [2430/4518] 53% | Training loss: 0.687038946544192
Epoch: 52 | Iteration number: [2440/4518] 54% | Training loss: 0.6870384892967881
Epoch: 52 | Iteration number: [2450/4518] 54% | Training loss: 0.6870377549103328
Epoch: 52 | Iteration number: [2460/4518] 54% | Training loss: 0.6870345939223359
Epoch: 52 | Iteration number: [2470/4518] 54% | Training loss: 0.687034522039205
Epoch: 52 | Iteration number: [2480/4518] 54% | Training loss: 0.6870341140897044
Epoch: 52 | Iteration number: [2490/4518] 55% | Training loss: 0.6870330525210584
Epoch: 52 | Iteration number: [2500/4518] 55% | Training loss: 0.6870300788640976
Epoch: 52 | Iteration number: [2510/4518] 55% | Training loss: 0.6870304474792632
Epoch: 52 | Iteration number: [2520/4518] 55% | Training loss: 0.6870340510256707
Epoch: 52 | Iteration number: [2530/4518] 55% | Training loss: 0.6870360332279808
Epoch: 52 | Iteration number: [2540/4518] 56% | Training loss: 0.6870365859720651
Epoch: 52 | Iteration number: [2550/4518] 56% | Training loss: 0.6870342638212091
Epoch: 52 | Iteration number: [2560/4518] 56% | Training loss: 0.6870323666837066
Epoch: 52 | Iteration number: [2570/4518] 56% | Training loss: 0.687034714453879
Epoch: 52 | Iteration number: [2580/4518] 57% | Training loss: 0.6870309082805648
Epoch: 52 | Iteration number: [2590/4518] 57% | Training loss: 0.687034505260497
Epoch: 52 | Iteration number: [2600/4518] 57% | Training loss: 0.6870356598267189
Epoch: 52 | Iteration number: [2610/4518] 57% | Training loss: 0.6870355164867709
Epoch: 52 | Iteration number: [2620/4518] 57% | Training loss: 0.6870316208773897
Epoch: 52 | Iteration number: [2630/4518] 58% | Training loss: 0.6870320889659708
Epoch: 52 | Iteration number: [2640/4518] 58% | Training loss: 0.6870365773412315
Epoch: 52 | Iteration number: [2650/4518] 58% | Training loss: 0.6870413632437868
Epoch: 52 | Iteration number: [2660/4518] 58% | Training loss: 0.6870346359740522
Epoch: 52 | Iteration number: [2670/4518] 59% | Training loss: 0.6870308466395189
Epoch: 52 | Iteration number: [2680/4518] 59% | Training loss: 0.6870290811826933
Epoch: 52 | Iteration number: [2690/4518] 59% | Training loss: 0.68703130725148
Epoch: 52 | Iteration number: [2700/4518] 59% | Training loss: 0.6870290233470775
Epoch: 52 | Iteration number: [2710/4518] 59% | Training loss: 0.6870326092762261
Epoch: 52 | Iteration number: [2720/4518] 60% | Training loss: 0.6870265531189301
Epoch: 52 | Iteration number: [2730/4518] 60% | Training loss: 0.687026011616319
Epoch: 52 | Iteration number: [2740/4518] 60% | Training loss: 0.6870295357965205
Epoch: 52 | Iteration number: [2750/4518] 60% | Training loss: 0.6870311085094105
Epoch: 52 | Iteration number: [2760/4518] 61% | Training loss: 0.6870268686742023
Epoch: 52 | Iteration number: [2770/4518] 61% | Training loss: 0.6870291805439477
Epoch: 52 | Iteration number: [2780/4518] 61% | Training loss: 0.6870265875360091
Epoch: 52 | Iteration number: [2790/4518] 61% | Training loss: 0.6870237409641239
Epoch: 52 | Iteration number: [2800/4518] 61% | Training loss: 0.6870239984563419
Epoch: 52 | Iteration number: [2810/4518] 62% | Training loss: 0.6870212615596867
Epoch: 52 | Iteration number: [2820/4518] 62% | Training loss: 0.6870176105211813
Epoch: 52 | Iteration number: [2830/4518] 62% | Training loss: 0.6870211688663429
Epoch: 52 | Iteration number: [2840/4518] 62% | Training loss: 0.6870260134129457
Epoch: 52 | Iteration number: [2850/4518] 63% | Training loss: 0.6870173410574595
Epoch: 52 | Iteration number: [2860/4518] 63% | Training loss: 0.6870119369530178
Epoch: 52 | Iteration number: [2870/4518] 63% | Training loss: 0.6870122271132386
Epoch: 52 | Iteration number: [2880/4518] 63% | Training loss: 0.6870158305391669
Epoch: 52 | Iteration number: [2890/4518] 63% | Training loss: 0.6870172105445994
Epoch: 52 | Iteration number: [2900/4518] 64% | Training loss: 0.6870161998271942
Epoch: 52 | Iteration number: [2910/4518] 64% | Training loss: 0.6870144993374028
Epoch: 52 | Iteration number: [2920/4518] 64% | Training loss: 0.6870139051585982
Epoch: 52 | Iteration number: [2930/4518] 64% | Training loss: 0.687017740772039
Epoch: 52 | Iteration number: [2940/4518] 65% | Training loss: 0.687020546603365
Epoch: 52 | Iteration number: [2950/4518] 65% | Training loss: 0.6870207996893737
Epoch: 52 | Iteration number: [2960/4518] 65% | Training loss: 0.6870188264226591
Epoch: 52 | Iteration number: [2970/4518] 65% | Training loss: 0.6870157784283764
Epoch: 52 | Iteration number: [2980/4518] 65% | Training loss: 0.6870124860697945
Epoch: 52 | Iteration number: [2990/4518] 66% | Training loss: 0.6870049095871457
Epoch: 52 | Iteration number: [3000/4518] 66% | Training loss: 0.6870036024451256
Epoch: 52 | Iteration number: [3010/4518] 66% | Training loss: 0.6870011221332804
Epoch: 52 | Iteration number: [3020/4518] 66% | Training loss: 0.6870001119296283
Epoch: 52 | Iteration number: [3030/4518] 67% | Training loss: 0.6869976986949593
Epoch: 52 | Iteration number: [3040/4518] 67% | Training loss: 0.6869977109330265
Epoch: 52 | Iteration number: [3050/4518] 67% | Training loss: 0.6869984603319012
Epoch: 52 | Iteration number: [3060/4518] 67% | Training loss: 0.6869988212398455
Epoch: 52 | Iteration number: [3070/4518] 67% | Training loss: 0.6869984002959845
Epoch: 52 | Iteration number: [3080/4518] 68% | Training loss: 0.6869986197391114
Epoch: 52 | Iteration number: [3090/4518] 68% | Training loss: 0.6870019794860704
Epoch: 52 | Iteration number: [3100/4518] 68% | Training loss: 0.6869951068970465
Epoch: 52 | Iteration number: [3110/4518] 68% | Training loss: 0.6869927912854689
Epoch: 52 | Iteration number: [3120/4518] 69% | Training loss: 0.6869924109906722
Epoch: 52 | Iteration number: [3130/4518] 69% | Training loss: 0.6869958124031275
Epoch: 52 | Iteration number: [3140/4518] 69% | Training loss: 0.6869963580445879
Epoch: 52 | Iteration number: [3150/4518] 69% | Training loss: 0.6869941423052833
Epoch: 52 | Iteration number: [3160/4518] 69% | Training loss: 0.6869948160987867
Epoch: 52 | Iteration number: [3170/4518] 70% | Training loss: 0.6869961218314968
Epoch: 52 | Iteration number: [3180/4518] 70% | Training loss: 0.6869963482490875
Epoch: 52 | Iteration number: [3190/4518] 70% | Training loss: 0.6869950872229932
Epoch: 52 | Iteration number: [3200/4518] 70% | Training loss: 0.6869916730374098
Epoch: 52 | Iteration number: [3210/4518] 71% | Training loss: 0.6869896390727748
Epoch: 52 | Iteration number: [3220/4518] 71% | Training loss: 0.6869884009316841
Epoch: 52 | Iteration number: [3230/4518] 71% | Training loss: 0.6869922630373538
Epoch: 52 | Iteration number: [3240/4518] 71% | Training loss: 0.6869901411327315
Epoch: 52 | Iteration number: [3250/4518] 71% | Training loss: 0.6869907736778259
Epoch: 52 | Iteration number: [3260/4518] 72% | Training loss: 0.686988250353585
Epoch: 52 | Iteration number: [3270/4518] 72% | Training loss: 0.6869872702917922
Epoch: 52 | Iteration number: [3280/4518] 72% | Training loss: 0.6869904422723665
Epoch: 52 | Iteration number: [3290/4518] 72% | Training loss: 0.68698799639125
Epoch: 52 | Iteration number: [3300/4518] 73% | Training loss: 0.6869846173849973
Epoch: 52 | Iteration number: [3310/4518] 73% | Training loss: 0.6869835332441185
Epoch: 52 | Iteration number: [3320/4518] 73% | Training loss: 0.6869831520929394
Epoch: 52 | Iteration number: [3330/4518] 73% | Training loss: 0.6869827469368954
Epoch: 52 | Iteration number: [3340/4518] 73% | Training loss: 0.6869832351714551
Epoch: 52 | Iteration number: [3350/4518] 74% | Training loss: 0.6869776385399833
Epoch: 52 | Iteration number: [3360/4518] 74% | Training loss: 0.6869778139960199
Epoch: 52 | Iteration number: [3370/4518] 74% | Training loss: 0.6869778955548737
Epoch: 52 | Iteration number: [3380/4518] 74% | Training loss: 0.6869742078012263
Epoch: 52 | Iteration number: [3390/4518] 75% | Training loss: 0.6869709059552106
Epoch: 52 | Iteration number: [3400/4518] 75% | Training loss: 0.6869706590911921
Epoch: 52 | Iteration number: [3410/4518] 75% | Training loss: 0.6869705075043038
Epoch: 52 | Iteration number: [3420/4518] 75% | Training loss: 0.6869688265679176
Epoch: 52 | Iteration number: [3430/4518] 75% | Training loss: 0.6869712033528976
Epoch: 52 | Iteration number: [3440/4518] 76% | Training loss: 0.6869707189673602
Epoch: 52 | Iteration number: [3450/4518] 76% | Training loss: 0.6869684285357378
Epoch: 52 | Iteration number: [3460/4518] 76% | Training loss: 0.6869669470139321
Epoch: 52 | Iteration number: [3470/4518] 76% | Training loss: 0.6869685840881523
Epoch: 52 | Iteration number: [3480/4518] 77% | Training loss: 0.6869704618707471
Epoch: 52 | Iteration number: [3490/4518] 77% | Training loss: 0.6869716042433905
Epoch: 52 | Iteration number: [3500/4518] 77% | Training loss: 0.6869707510130746
Epoch: 52 | Iteration number: [3510/4518] 77% | Training loss: 0.6869718010608966
Epoch: 52 | Iteration number: [3520/4518] 77% | Training loss: 0.6869742448187687
Epoch: 52 | Iteration number: [3530/4518] 78% | Training loss: 0.6869778402972829
Epoch: 52 | Iteration number: [3540/4518] 78% | Training loss: 0.6869783640412961
Epoch: 52 | Iteration number: [3550/4518] 78% | Training loss: 0.6869793169431283
Epoch: 52 | Iteration number: [3560/4518] 78% | Training loss: 0.6869738618142149
Epoch: 52 | Iteration number: [3570/4518] 79% | Training loss: 0.6869719619176635
Epoch: 52 | Iteration number: [3580/4518] 79% | Training loss: 0.6869759511681243
Epoch: 52 | Iteration number: [3590/4518] 79% | Training loss: 0.6869734816232431
Epoch: 52 | Iteration number: [3600/4518] 79% | Training loss: 0.6869758222500483
Epoch: 52 | Iteration number: [3610/4518] 79% | Training loss: 0.6869732083376094
Epoch: 52 | Iteration number: [3620/4518] 80% | Training loss: 0.6869780454846377
Epoch: 52 | Iteration number: [3630/4518] 80% | Training loss: 0.6869767198221086
Epoch: 52 | Iteration number: [3640/4518] 80% | Training loss: 0.6869759710771697
Epoch: 52 | Iteration number: [3650/4518] 80% | Training loss: 0.686977455109766
Epoch: 52 | Iteration number: [3660/4518] 81% | Training loss: 0.6869738295104334
Epoch: 52 | Iteration number: [3670/4518] 81% | Training loss: 0.6869736657318043
Epoch: 52 | Iteration number: [3680/4518] 81% | Training loss: 0.6869734290339377
Epoch: 52 | Iteration number: [3690/4518] 81% | Training loss: 0.6869740322514925
Epoch: 52 | Iteration number: [3700/4518] 81% | Training loss: 0.6869717325068809
Epoch: 52 | Iteration number: [3710/4518] 82% | Training loss: 0.6869711554436028
Epoch: 52 | Iteration number: [3720/4518] 82% | Training loss: 0.6869711925105382
Epoch: 52 | Iteration number: [3730/4518] 82% | Training loss: 0.6869669045743609
Epoch: 52 | Iteration number: [3740/4518] 82% | Training loss: 0.6869687651089806
Epoch: 52 | Iteration number: [3750/4518] 83% | Training loss: 0.6869667533874512
Epoch: 52 | Iteration number: [3760/4518] 83% | Training loss: 0.6869656208823336
Epoch: 52 | Iteration number: [3770/4518] 83% | Training loss: 0.6869603151667972
Epoch: 52 | Iteration number: [3780/4518] 83% | Training loss: 0.6869594875309203
Epoch: 52 | Iteration number: [3790/4518] 83% | Training loss: 0.6869571271703866
Epoch: 52 | Iteration number: [3800/4518] 84% | Training loss: 0.6869582113623619
Epoch: 52 | Iteration number: [3810/4518] 84% | Training loss: 0.6869569631386304
Epoch: 52 | Iteration number: [3820/4518] 84% | Training loss: 0.686955005726265
Epoch: 52 | Iteration number: [3830/4518] 84% | Training loss: 0.6869553631186174
Epoch: 52 | Iteration number: [3840/4518] 84% | Training loss: 0.686957434611395
Epoch: 52 | Iteration number: [3850/4518] 85% | Training loss: 0.6869538071712891
Epoch: 52 | Iteration number: [3860/4518] 85% | Training loss: 0.6869534656637073
Epoch: 52 | Iteration number: [3870/4518] 85% | Training loss: 0.6869508886984153
Epoch: 52 | Iteration number: [3880/4518] 85% | Training loss: 0.6869500155301438
Epoch: 52 | Iteration number: [3890/4518] 86% | Training loss: 0.6869502083961025
Epoch: 52 | Iteration number: [3900/4518] 86% | Training loss: 0.6869542457965704
Epoch: 52 | Iteration number: [3910/4518] 86% | Training loss: 0.68695563783731
Epoch: 52 | Iteration number: [3920/4518] 86% | Training loss: 0.6869556362987781
Epoch: 52 | Iteration number: [3930/4518] 86% | Training loss: 0.6869553960764985
Epoch: 52 | Iteration number: [3940/4518] 87% | Training loss: 0.6869563489547236
Epoch: 52 | Iteration number: [3950/4518] 87% | Training loss: 0.6869598305074475
Epoch: 52 | Iteration number: [3960/4518] 87% | Training loss: 0.6869608570529957
Epoch: 52 | Iteration number: [3970/4518] 87% | Training loss: 0.6869601264408314
Epoch: 52 | Iteration number: [3980/4518] 88% | Training loss: 0.6869572979121951
Epoch: 52 | Iteration number: [3990/4518] 88% | Training loss: 0.6869596419179052
Epoch: 52 | Iteration number: [4000/4518] 88% | Training loss: 0.686960862442851
Epoch: 52 | Iteration number: [4010/4518] 88% | Training loss: 0.6869628931518802
Epoch: 52 | Iteration number: [4020/4518] 88% | Training loss: 0.6869641758316192
Epoch: 52 | Iteration number: [4030/4518] 89% | Training loss: 0.6869624646218776
Epoch: 52 | Iteration number: [4040/4518] 89% | Training loss: 0.6869656138638459
Epoch: 52 | Iteration number: [4050/4518] 89% | Training loss: 0.6869620290656149
Epoch: 52 | Iteration number: [4060/4518] 89% | Training loss: 0.6869582680939453
Epoch: 52 | Iteration number: [4070/4518] 90% | Training loss: 0.6869578787970015
Epoch: 52 | Iteration number: [4080/4518] 90% | Training loss: 0.6869586550137576
Epoch: 52 | Iteration number: [4090/4518] 90% | Training loss: 0.6869553489032176
Epoch: 52 | Iteration number: [4100/4518] 90% | Training loss: 0.6869555147973503
Epoch: 52 | Iteration number: [4110/4518] 90% | Training loss: 0.6869556865987987
Epoch: 52 | Iteration number: [4120/4518] 91% | Training loss: 0.6869528439438459
Epoch: 52 | Iteration number: [4130/4518] 91% | Training loss: 0.6869531277305566
Epoch: 52 | Iteration number: [4140/4518] 91% | Training loss: 0.6869524724961479
Epoch: 52 | Iteration number: [4150/4518] 91% | Training loss: 0.6869507501067885
Epoch: 52 | Iteration number: [4160/4518] 92% | Training loss: 0.6869497447919387
Epoch: 52 | Iteration number: [4170/4518] 92% | Training loss: 0.6869495106543855
Epoch: 52 | Iteration number: [4180/4518] 92% | Training loss: 0.6869486314828316
Epoch: 52 | Iteration number: [4190/4518] 92% | Training loss: 0.6869469742501835
Epoch: 52 | Iteration number: [4200/4518] 92% | Training loss: 0.6869467073537054
Epoch: 52 | Iteration number: [4210/4518] 93% | Training loss: 0.6869480199457064
Epoch: 52 | Iteration number: [4220/4518] 93% | Training loss: 0.6869491164011978
Epoch: 52 | Iteration number: [4230/4518] 93% | Training loss: 0.6869510905680645
Epoch: 52 | Iteration number: [4240/4518] 93% | Training loss: 0.6869512383667928
Epoch: 52 | Iteration number: [4250/4518] 94% | Training loss: 0.68694864766738
Epoch: 52 | Iteration number: [4260/4518] 94% | Training loss: 0.6869517057714328
Epoch: 52 | Iteration number: [4270/4518] 94% | Training loss: 0.6869499011257493
Epoch: 52 | Iteration number: [4280/4518] 94% | Training loss: 0.6869499484512294
Epoch: 52 | Iteration number: [4290/4518] 94% | Training loss: 0.6869481777950323
Epoch: 52 | Iteration number: [4300/4518] 95% | Training loss: 0.6869477629107098
Epoch: 52 | Iteration number: [4310/4518] 95% | Training loss: 0.6869472006357463
Epoch: 52 | Iteration number: [4320/4518] 95% | Training loss: 0.6869478314287133
Epoch: 52 | Iteration number: [4330/4518] 95% | Training loss: 0.6869459137354932
Epoch: 52 | Iteration number: [4340/4518] 96% | Training loss: 0.68694573378508
Epoch: 52 | Iteration number: [4350/4518] 96% | Training loss: 0.6869477049783729
Epoch: 52 | Iteration number: [4360/4518] 96% | Training loss: 0.686945070736452
Epoch: 52 | Iteration number: [4370/4518] 96% | Training loss: 0.6869437029350813
Epoch: 52 | Iteration number: [4380/4518] 96% | Training loss: 0.686943842436625
Epoch: 52 | Iteration number: [4390/4518] 97% | Training loss: 0.6869440543352878
Epoch: 52 | Iteration number: [4400/4518] 97% | Training loss: 0.6869452950629321
Epoch: 52 | Iteration number: [4410/4518] 97% | Training loss: 0.6869449676840214
Epoch: 52 | Iteration number: [4420/4518] 97% | Training loss: 0.6869459165302337
Epoch: 52 | Iteration number: [4430/4518] 98% | Training loss: 0.6869473998621947
Epoch: 52 | Iteration number: [4440/4518] 98% | Training loss: 0.6869463375962532
Epoch: 52 | Iteration number: [4450/4518] 98% | Training loss: 0.6869477054912053
Epoch: 52 | Iteration number: [4460/4518] 98% | Training loss: 0.6869480496832073
Epoch: 52 | Iteration number: [4470/4518] 98% | Training loss: 0.6869476898271232
Epoch: 52 | Iteration number: [4480/4518] 99% | Training loss: 0.6869490205044193
Epoch: 52 | Iteration number: [4490/4518] 99% | Training loss: 0.6869516791107926
Epoch: 52 | Iteration number: [4500/4518] 99% | Training loss: 0.68695030605793
Epoch: 52 | Iteration number: [4510/4518] 99% | Training loss: 0.6869506272534838

 End of epoch: 52 | Train Loss: 0.6868001009020567 | Training Time: 632 

 End of epoch: 52 | Eval Loss: 0.6897333458978303 | Evaluating Time: 17 
Epoch: 53 | Iteration number: [10/4518] 0% | Training loss: 0.7563704133033753
Epoch: 53 | Iteration number: [20/4518] 0% | Training loss: 0.7220191538333893
Epoch: 53 | Iteration number: [30/4518] 0% | Training loss: 0.7104805906613668
Epoch: 53 | Iteration number: [40/4518] 0% | Training loss: 0.7044388428330421
Epoch: 53 | Iteration number: [50/4518] 1% | Training loss: 0.7006705474853515
Epoch: 53 | Iteration number: [60/4518] 1% | Training loss: 0.6986734926700592
Epoch: 53 | Iteration number: [70/4518] 1% | Training loss: 0.6966652640274593
Epoch: 53 | Iteration number: [80/4518] 1% | Training loss: 0.6955134950578212
Epoch: 53 | Iteration number: [90/4518] 1% | Training loss: 0.6946041345596313
Epoch: 53 | Iteration number: [100/4518] 2% | Training loss: 0.6937384521961212
Epoch: 53 | Iteration number: [110/4518] 2% | Training loss: 0.6931117567149075
Epoch: 53 | Iteration number: [120/4518] 2% | Training loss: 0.6926154633363087
Epoch: 53 | Iteration number: [130/4518] 2% | Training loss: 0.6921901762485504
Epoch: 53 | Iteration number: [140/4518] 3% | Training loss: 0.6918171346187592
Epoch: 53 | Iteration number: [150/4518] 3% | Training loss: 0.6916065140565236
Epoch: 53 | Iteration number: [160/4518] 3% | Training loss: 0.6913207363337278
Epoch: 53 | Iteration number: [170/4518] 3% | Training loss: 0.691000499795465
Epoch: 53 | Iteration number: [180/4518] 3% | Training loss: 0.6908775829606586
Epoch: 53 | Iteration number: [190/4518] 4% | Training loss: 0.6907066364037363
Epoch: 53 | Iteration number: [200/4518] 4% | Training loss: 0.6905020898580552
Epoch: 53 | Iteration number: [210/4518] 4% | Training loss: 0.6903221391496204
Epoch: 53 | Iteration number: [220/4518] 4% | Training loss: 0.6901314784180034
Epoch: 53 | Iteration number: [230/4518] 5% | Training loss: 0.690033699636874
Epoch: 53 | Iteration number: [240/4518] 5% | Training loss: 0.6899207976957162
Epoch: 53 | Iteration number: [250/4518] 5% | Training loss: 0.6897593929767608
Epoch: 53 | Iteration number: [260/4518] 5% | Training loss: 0.6896615920158533
Epoch: 53 | Iteration number: [270/4518] 5% | Training loss: 0.6895617597632938
Epoch: 53 | Iteration number: [280/4518] 6% | Training loss: 0.6894467426197869
Epoch: 53 | Iteration number: [290/4518] 6% | Training loss: 0.6893995885191293
Epoch: 53 | Iteration number: [300/4518] 6% | Training loss: 0.6893157881498336
Epoch: 53 | Iteration number: [310/4518] 6% | Training loss: 0.6892133326299729
Epoch: 53 | Iteration number: [320/4518] 7% | Training loss: 0.6891718490049243
Epoch: 53 | Iteration number: [330/4518] 7% | Training loss: 0.6891087259307053
Epoch: 53 | Iteration number: [340/4518] 7% | Training loss: 0.6890476053251939
Epoch: 53 | Iteration number: [350/4518] 7% | Training loss: 0.6889939752646855
Epoch: 53 | Iteration number: [360/4518] 7% | Training loss: 0.688930369913578
Epoch: 53 | Iteration number: [370/4518] 8% | Training loss: 0.6888796614634024
Epoch: 53 | Iteration number: [380/4518] 8% | Training loss: 0.688844516089088
Epoch: 53 | Iteration number: [390/4518] 8% | Training loss: 0.688806534730471
Epoch: 53 | Iteration number: [400/4518] 8% | Training loss: 0.6887560920417308
Epoch: 53 | Iteration number: [410/4518] 9% | Training loss: 0.688697201013565
Epoch: 53 | Iteration number: [420/4518] 9% | Training loss: 0.6886796826408023
Epoch: 53 | Iteration number: [430/4518] 9% | Training loss: 0.6886359285476595
Epoch: 53 | Iteration number: [440/4518] 9% | Training loss: 0.6885899317535487
Epoch: 53 | Iteration number: [450/4518] 9% | Training loss: 0.6885621651013693
Epoch: 53 | Iteration number: [460/4518] 10% | Training loss: 0.6885389462761257
Epoch: 53 | Iteration number: [470/4518] 10% | Training loss: 0.6885233383229439
Epoch: 53 | Iteration number: [480/4518] 10% | Training loss: 0.68851822540164
Epoch: 53 | Iteration number: [490/4518] 10% | Training loss: 0.688469112770898
Epoch: 53 | Iteration number: [500/4518] 11% | Training loss: 0.688447459578514
Epoch: 53 | Iteration number: [510/4518] 11% | Training loss: 0.6883992324857151
Epoch: 53 | Iteration number: [520/4518] 11% | Training loss: 0.6883239622299487
Epoch: 53 | Iteration number: [530/4518] 11% | Training loss: 0.6883006718923461
Epoch: 53 | Iteration number: [540/4518] 11% | Training loss: 0.6882682708678423
Epoch: 53 | Iteration number: [550/4518] 12% | Training loss: 0.6882288242470135
Epoch: 53 | Iteration number: [560/4518] 12% | Training loss: 0.6881839053971427
Epoch: 53 | Iteration number: [570/4518] 12% | Training loss: 0.6881271942665702
Epoch: 53 | Iteration number: [580/4518] 12% | Training loss: 0.6880876193786489
Epoch: 53 | Iteration number: [590/4518] 13% | Training loss: 0.6880598916845807
Epoch: 53 | Iteration number: [600/4518] 13% | Training loss: 0.688019066353639
Epoch: 53 | Iteration number: [610/4518] 13% | Training loss: 0.6879859397645857
Epoch: 53 | Iteration number: [620/4518] 13% | Training loss: 0.6879633197861333
Epoch: 53 | Iteration number: [630/4518] 13% | Training loss: 0.6879641392874339
Epoch: 53 | Iteration number: [640/4518] 14% | Training loss: 0.6879480088129639
Epoch: 53 | Iteration number: [650/4518] 14% | Training loss: 0.6879499609653766
Epoch: 53 | Iteration number: [660/4518] 14% | Training loss: 0.6879479821884271
Epoch: 53 | Iteration number: [670/4518] 14% | Training loss: 0.6879499581322741
Epoch: 53 | Iteration number: [680/4518] 15% | Training loss: 0.6879343237947015
Epoch: 53 | Iteration number: [690/4518] 15% | Training loss: 0.687925043054249
Epoch: 53 | Iteration number: [700/4518] 15% | Training loss: 0.6879077879020146
Epoch: 53 | Iteration number: [710/4518] 15% | Training loss: 0.6878998152806726
Epoch: 53 | Iteration number: [720/4518] 15% | Training loss: 0.6878765149248971
Epoch: 53 | Iteration number: [730/4518] 16% | Training loss: 0.6878719747066497
Epoch: 53 | Iteration number: [740/4518] 16% | Training loss: 0.6878520516124932
Epoch: 53 | Iteration number: [750/4518] 16% | Training loss: 0.6878326942920685
Epoch: 53 | Iteration number: [760/4518] 16% | Training loss: 0.6878080211971935
Epoch: 53 | Iteration number: [770/4518] 17% | Training loss: 0.6878141520085272
Epoch: 53 | Iteration number: [780/4518] 17% | Training loss: 0.6878088848713116
Epoch: 53 | Iteration number: [790/4518] 17% | Training loss: 0.6877868373937245
Epoch: 53 | Iteration number: [800/4518] 17% | Training loss: 0.6877802991867066
Epoch: 53 | Iteration number: [810/4518] 17% | Training loss: 0.6877675361839342
Epoch: 53 | Iteration number: [820/4518] 18% | Training loss: 0.6877494760402819
Epoch: 53 | Iteration number: [830/4518] 18% | Training loss: 0.6877216656524014
Epoch: 53 | Iteration number: [840/4518] 18% | Training loss: 0.6877036199683235
Epoch: 53 | Iteration number: [850/4518] 18% | Training loss: 0.687693571062649
Epoch: 53 | Iteration number: [860/4518] 19% | Training loss: 0.6876827711282775
Epoch: 53 | Iteration number: [870/4518] 19% | Training loss: 0.687665497229017
Epoch: 53 | Iteration number: [880/4518] 19% | Training loss: 0.6876589726318013
Epoch: 53 | Iteration number: [890/4518] 19% | Training loss: 0.6876392607608538
Epoch: 53 | Iteration number: [900/4518] 19% | Training loss: 0.6876276488436593
Epoch: 53 | Iteration number: [910/4518] 20% | Training loss: 0.6876268612159477
Epoch: 53 | Iteration number: [920/4518] 20% | Training loss: 0.6876197488411613
Epoch: 53 | Iteration number: [930/4518] 20% | Training loss: 0.6876214666392213
Epoch: 53 | Iteration number: [940/4518] 20% | Training loss: 0.6876023900001607
Epoch: 53 | Iteration number: [950/4518] 21% | Training loss: 0.6876041003904845
Epoch: 53 | Iteration number: [960/4518] 21% | Training loss: 0.6875980754072467
Epoch: 53 | Iteration number: [970/4518] 21% | Training loss: 0.6876002425999985
Epoch: 53 | Iteration number: [980/4518] 21% | Training loss: 0.6875968548716331
Epoch: 53 | Iteration number: [990/4518] 21% | Training loss: 0.6875920835769538
Epoch: 53 | Iteration number: [1000/4518] 22% | Training loss: 0.6875738456249237
Epoch: 53 | Iteration number: [1010/4518] 22% | Training loss: 0.6875669997517425
Epoch: 53 | Iteration number: [1020/4518] 22% | Training loss: 0.6875765576082118
Epoch: 53 | Iteration number: [1030/4518] 22% | Training loss: 0.6875758782173823
Epoch: 53 | Iteration number: [1040/4518] 23% | Training loss: 0.6875601448691808
Epoch: 53 | Iteration number: [1050/4518] 23% | Training loss: 0.6875502135072435
Epoch: 53 | Iteration number: [1060/4518] 23% | Training loss: 0.6875440671758831
Epoch: 53 | Iteration number: [1070/4518] 23% | Training loss: 0.6875385110066315
Epoch: 53 | Iteration number: [1080/4518] 23% | Training loss: 0.6875353804892964
Epoch: 53 | Iteration number: [1090/4518] 24% | Training loss: 0.6875248315684293
Epoch: 53 | Iteration number: [1100/4518] 24% | Training loss: 0.6875198019634594
Epoch: 53 | Iteration number: [1110/4518] 24% | Training loss: 0.6875113805135091
Epoch: 53 | Iteration number: [1120/4518] 24% | Training loss: 0.6874986108392477
Epoch: 53 | Iteration number: [1130/4518] 25% | Training loss: 0.6874925922503513
Epoch: 53 | Iteration number: [1140/4518] 25% | Training loss: 0.6874832151228921
Epoch: 53 | Iteration number: [1150/4518] 25% | Training loss: 0.6874684442126233
Epoch: 53 | Iteration number: [1160/4518] 25% | Training loss: 0.6874692625526724
Epoch: 53 | Iteration number: [1170/4518] 25% | Training loss: 0.6874521051716601
Epoch: 53 | Iteration number: [1180/4518] 26% | Training loss: 0.6874417291354324
Epoch: 53 | Iteration number: [1190/4518] 26% | Training loss: 0.6874228493005288
Epoch: 53 | Iteration number: [1200/4518] 26% | Training loss: 0.6874245097239812
Epoch: 53 | Iteration number: [1210/4518] 26% | Training loss: 0.6874155413513341
Epoch: 53 | Iteration number: [1220/4518] 27% | Training loss: 0.6873973718432129
Epoch: 53 | Iteration number: [1230/4518] 27% | Training loss: 0.6873922988166654
Epoch: 53 | Iteration number: [1240/4518] 27% | Training loss: 0.6873930193243488
Epoch: 53 | Iteration number: [1250/4518] 27% | Training loss: 0.6873896577835082
Epoch: 53 | Iteration number: [1260/4518] 27% | Training loss: 0.6873803077709107
Epoch: 53 | Iteration number: [1270/4518] 28% | Training loss: 0.6873926025675976
Epoch: 53 | Iteration number: [1280/4518] 28% | Training loss: 0.6873927635140717
Epoch: 53 | Iteration number: [1290/4518] 28% | Training loss: 0.6873945386834847
Epoch: 53 | Iteration number: [1300/4518] 28% | Training loss: 0.6873980570756472
Epoch: 53 | Iteration number: [1310/4518] 28% | Training loss: 0.6873863488663244
Epoch: 53 | Iteration number: [1320/4518] 29% | Training loss: 0.6873907511432965
Epoch: 53 | Iteration number: [1330/4518] 29% | Training loss: 0.68738174604294
Epoch: 53 | Iteration number: [1340/4518] 29% | Training loss: 0.6873707119653474
Epoch: 53 | Iteration number: [1350/4518] 29% | Training loss: 0.6873594903945923
Epoch: 53 | Iteration number: [1360/4518] 30% | Training loss: 0.6873580334817662
Epoch: 53 | Iteration number: [1370/4518] 30% | Training loss: 0.687358799772541
Epoch: 53 | Iteration number: [1380/4518] 30% | Training loss: 0.6873549311057381
Epoch: 53 | Iteration number: [1390/4518] 30% | Training loss: 0.6873408366021493
Epoch: 53 | Iteration number: [1400/4518] 30% | Training loss: 0.6873347858445985
Epoch: 53 | Iteration number: [1410/4518] 31% | Training loss: 0.6873363501636695
Epoch: 53 | Iteration number: [1420/4518] 31% | Training loss: 0.687340225006493
Epoch: 53 | Iteration number: [1430/4518] 31% | Training loss: 0.6873412353175503
Epoch: 53 | Iteration number: [1440/4518] 31% | Training loss: 0.6873373782883088
Epoch: 53 | Iteration number: [1450/4518] 32% | Training loss: 0.6873393335835687
Epoch: 53 | Iteration number: [1460/4518] 32% | Training loss: 0.6873356570527979
Epoch: 53 | Iteration number: [1470/4518] 32% | Training loss: 0.6873268498449909
Epoch: 53 | Iteration number: [1480/4518] 32% | Training loss: 0.6873255662015967
Epoch: 53 | Iteration number: [1490/4518] 32% | Training loss: 0.6873281317269242
Epoch: 53 | Iteration number: [1500/4518] 33% | Training loss: 0.6873293596506119
Epoch: 53 | Iteration number: [1510/4518] 33% | Training loss: 0.6873184318968791
Epoch: 53 | Iteration number: [1520/4518] 33% | Training loss: 0.6873072552837823
Epoch: 53 | Iteration number: [1530/4518] 33% | Training loss: 0.6873030658640893
Epoch: 53 | Iteration number: [1540/4518] 34% | Training loss: 0.6872996680535279
Epoch: 53 | Iteration number: [1550/4518] 34% | Training loss: 0.6873085431129702
Epoch: 53 | Iteration number: [1560/4518] 34% | Training loss: 0.6872987919510939
Epoch: 53 | Iteration number: [1570/4518] 34% | Training loss: 0.6872963333205813
Epoch: 53 | Iteration number: [1580/4518] 34% | Training loss: 0.6872824448573438
Epoch: 53 | Iteration number: [1590/4518] 35% | Training loss: 0.687278605032267
Epoch: 53 | Iteration number: [1600/4518] 35% | Training loss: 0.6872684805095196
Epoch: 53 | Iteration number: [1610/4518] 35% | Training loss: 0.6872627426748691
Epoch: 53 | Iteration number: [1620/4518] 35% | Training loss: 0.687264206196055
Epoch: 53 | Iteration number: [1630/4518] 36% | Training loss: 0.6872589186656695
Epoch: 53 | Iteration number: [1640/4518] 36% | Training loss: 0.6872515425812907
Epoch: 53 | Iteration number: [1650/4518] 36% | Training loss: 0.6872495156707186
Epoch: 53 | Iteration number: [1660/4518] 36% | Training loss: 0.6872480896223022
Epoch: 53 | Iteration number: [1670/4518] 36% | Training loss: 0.6872491493553459
Epoch: 53 | Iteration number: [1680/4518] 37% | Training loss: 0.687241408441748
Epoch: 53 | Iteration number: [1690/4518] 37% | Training loss: 0.6872429705935822
Epoch: 53 | Iteration number: [1700/4518] 37% | Training loss: 0.6872376902313794
Epoch: 53 | Iteration number: [1710/4518] 37% | Training loss: 0.6872365942126826
Epoch: 53 | Iteration number: [1720/4518] 38% | Training loss: 0.6872381413745325
Epoch: 53 | Iteration number: [1730/4518] 38% | Training loss: 0.6872341579440012
Epoch: 53 | Iteration number: [1740/4518] 38% | Training loss: 0.6872300784820797
Epoch: 53 | Iteration number: [1750/4518] 38% | Training loss: 0.6872344556876592
Epoch: 53 | Iteration number: [1760/4518] 38% | Training loss: 0.6872190434485674
Epoch: 53 | Iteration number: [1770/4518] 39% | Training loss: 0.6872211641511001
Epoch: 53 | Iteration number: [1780/4518] 39% | Training loss: 0.6872216766804792
Epoch: 53 | Iteration number: [1790/4518] 39% | Training loss: 0.6872181968981993
Epoch: 53 | Iteration number: [1800/4518] 39% | Training loss: 0.6872177688280742
Epoch: 53 | Iteration number: [1810/4518] 40% | Training loss: 0.6872182118299917
Epoch: 53 | Iteration number: [1820/4518] 40% | Training loss: 0.6872130375642043
Epoch: 53 | Iteration number: [1830/4518] 40% | Training loss: 0.6872132931250692
Epoch: 53 | Iteration number: [1840/4518] 40% | Training loss: 0.6872071876150111
Epoch: 53 | Iteration number: [1850/4518] 40% | Training loss: 0.6872053707934714
Epoch: 53 | Iteration number: [1860/4518] 41% | Training loss: 0.687201276934275
Epoch: 53 | Iteration number: [1870/4518] 41% | Training loss: 0.6872025332667611
Epoch: 53 | Iteration number: [1880/4518] 41% | Training loss: 0.6871912946092321
Epoch: 53 | Iteration number: [1890/4518] 41% | Training loss: 0.6871833419989026
Epoch: 53 | Iteration number: [1900/4518] 42% | Training loss: 0.6871817372347179
Epoch: 53 | Iteration number: [1910/4518] 42% | Training loss: 0.6871787734680775
Epoch: 53 | Iteration number: [1920/4518] 42% | Training loss: 0.6871798283110062
Epoch: 53 | Iteration number: [1930/4518] 42% | Training loss: 0.6871767289280274
Epoch: 53 | Iteration number: [1940/4518] 42% | Training loss: 0.6871737823351143
Epoch: 53 | Iteration number: [1950/4518] 43% | Training loss: 0.6871750009671236
Epoch: 53 | Iteration number: [1960/4518] 43% | Training loss: 0.6871681806384301
Epoch: 53 | Iteration number: [1970/4518] 43% | Training loss: 0.6871614587791075
Epoch: 53 | Iteration number: [1980/4518] 43% | Training loss: 0.6871616107947899
Epoch: 53 | Iteration number: [1990/4518] 44% | Training loss: 0.6871657004907502
Epoch: 53 | Iteration number: [2000/4518] 44% | Training loss: 0.6871626449823379
Epoch: 53 | Iteration number: [2010/4518] 44% | Training loss: 0.6871646297215229
Epoch: 53 | Iteration number: [2020/4518] 44% | Training loss: 0.687168557455044
Epoch: 53 | Iteration number: [2030/4518] 44% | Training loss: 0.687169459975999
Epoch: 53 | Iteration number: [2040/4518] 45% | Training loss: 0.6871698884987364
Epoch: 53 | Iteration number: [2050/4518] 45% | Training loss: 0.6871688617148051
Epoch: 53 | Iteration number: [2060/4518] 45% | Training loss: 0.68716961657538
Epoch: 53 | Iteration number: [2070/4518] 45% | Training loss: 0.6871692122468626
Epoch: 53 | Iteration number: [2080/4518] 46% | Training loss: 0.6871638292590013
Epoch: 53 | Iteration number: [2090/4518] 46% | Training loss: 0.6871580135308955
Epoch: 53 | Iteration number: [2100/4518] 46% | Training loss: 0.6871564774853842
Epoch: 53 | Iteration number: [2110/4518] 46% | Training loss: 0.6871550652088148
Epoch: 53 | Iteration number: [2120/4518] 46% | Training loss: 0.6871526658253849
Epoch: 53 | Iteration number: [2130/4518] 47% | Training loss: 0.6871492407411477
Epoch: 53 | Iteration number: [2140/4518] 47% | Training loss: 0.687149368741802
Epoch: 53 | Iteration number: [2150/4518] 47% | Training loss: 0.6871506206933842
Epoch: 53 | Iteration number: [2160/4518] 47% | Training loss: 0.6871492119850936
Epoch: 53 | Iteration number: [2170/4518] 48% | Training loss: 0.6871386852407235
Epoch: 53 | Iteration number: [2180/4518] 48% | Training loss: 0.6871313177117514
Epoch: 53 | Iteration number: [2190/4518] 48% | Training loss: 0.6871326310993874
Epoch: 53 | Iteration number: [2200/4518] 48% | Training loss: 0.6871297830614177
Epoch: 53 | Iteration number: [2210/4518] 48% | Training loss: 0.6871301014498887
Epoch: 53 | Iteration number: [2220/4518] 49% | Training loss: 0.6871286984768
Epoch: 53 | Iteration number: [2230/4518] 49% | Training loss: 0.6871304013803935
Epoch: 53 | Iteration number: [2240/4518] 49% | Training loss: 0.6871236410258071
Epoch: 53 | Iteration number: [2250/4518] 49% | Training loss: 0.687117763015959
Epoch: 53 | Iteration number: [2260/4518] 50% | Training loss: 0.6871194840796226
Epoch: 53 | Iteration number: [2270/4518] 50% | Training loss: 0.687120919947057
Epoch: 53 | Iteration number: [2280/4518] 50% | Training loss: 0.6871184311937868
Epoch: 53 | Iteration number: [2290/4518] 50% | Training loss: 0.6871190494324964
Epoch: 53 | Iteration number: [2300/4518] 50% | Training loss: 0.6871220195293426
Epoch: 53 | Iteration number: [2310/4518] 51% | Training loss: 0.6871149576329566
Epoch: 53 | Iteration number: [2320/4518] 51% | Training loss: 0.6871218425189627
Epoch: 53 | Iteration number: [2330/4518] 51% | Training loss: 0.6871182720292791
Epoch: 53 | Iteration number: [2340/4518] 51% | Training loss: 0.6871193119348624
Epoch: 53 | Iteration number: [2350/4518] 52% | Training loss: 0.6871180194489499
Epoch: 53 | Iteration number: [2360/4518] 52% | Training loss: 0.6871168893525156
Epoch: 53 | Iteration number: [2370/4518] 52% | Training loss: 0.6871156952049159
Epoch: 53 | Iteration number: [2380/4518] 52% | Training loss: 0.6871105423494548
Epoch: 53 | Iteration number: [2390/4518] 52% | Training loss: 0.6871070828148511
Epoch: 53 | Iteration number: [2400/4518] 53% | Training loss: 0.6871068186312914
Epoch: 53 | Iteration number: [2410/4518] 53% | Training loss: 0.6871033732327189
Epoch: 53 | Iteration number: [2420/4518] 53% | Training loss: 0.687104269788285
Epoch: 53 | Iteration number: [2430/4518] 53% | Training loss: 0.6871088131955622
Epoch: 53 | Iteration number: [2440/4518] 54% | Training loss: 0.687106518593968
Epoch: 53 | Iteration number: [2450/4518] 54% | Training loss: 0.6871013194930796
Epoch: 53 | Iteration number: [2460/4518] 54% | Training loss: 0.687098736685466
Epoch: 53 | Iteration number: [2470/4518] 54% | Training loss: 0.6871005112101675
Epoch: 53 | Iteration number: [2480/4518] 54% | Training loss: 0.6871052392067448
Epoch: 53 | Iteration number: [2490/4518] 55% | Training loss: 0.687099583201619
Epoch: 53 | Iteration number: [2500/4518] 55% | Training loss: 0.687102267408371
Epoch: 53 | Iteration number: [2510/4518] 55% | Training loss: 0.687095151242032
Epoch: 53 | Iteration number: [2520/4518] 55% | Training loss: 0.6870908081058472
Epoch: 53 | Iteration number: [2530/4518] 55% | Training loss: 0.6870884060388497
Epoch: 53 | Iteration number: [2540/4518] 56% | Training loss: 0.6870897117092853
Epoch: 53 | Iteration number: [2550/4518] 56% | Training loss: 0.687088546776304
Epoch: 53 | Iteration number: [2560/4518] 56% | Training loss: 0.6870849228696898
Epoch: 53 | Iteration number: [2570/4518] 56% | Training loss: 0.6870803409977182
Epoch: 53 | Iteration number: [2580/4518] 57% | Training loss: 0.6870805444643479
Epoch: 53 | Iteration number: [2590/4518] 57% | Training loss: 0.6870782032896653
Epoch: 53 | Iteration number: [2600/4518] 57% | Training loss: 0.6870756613978973
Epoch: 53 | Iteration number: [2610/4518] 57% | Training loss: 0.6870765074687899
Epoch: 53 | Iteration number: [2620/4518] 57% | Training loss: 0.6870738342973112
Epoch: 53 | Iteration number: [2630/4518] 58% | Training loss: 0.6870719345350229
Epoch: 53 | Iteration number: [2640/4518] 58% | Training loss: 0.6870689067199375
Epoch: 53 | Iteration number: [2650/4518] 58% | Training loss: 0.6870705060239108
Epoch: 53 | Iteration number: [2660/4518] 58% | Training loss: 0.68707491730837
Epoch: 53 | Iteration number: [2670/4518] 59% | Training loss: 0.687072755000118
Epoch: 53 | Iteration number: [2680/4518] 59% | Training loss: 0.6870697558148583
Epoch: 53 | Iteration number: [2690/4518] 59% | Training loss: 0.6870715933218321
Epoch: 53 | Iteration number: [2700/4518] 59% | Training loss: 0.6870715743524057
Epoch: 53 | Iteration number: [2710/4518] 59% | Training loss: 0.6870716974084228
Epoch: 53 | Iteration number: [2720/4518] 60% | Training loss: 0.6870695561170578
Epoch: 53 | Iteration number: [2730/4518] 60% | Training loss: 0.687067154279122
Epoch: 53 | Iteration number: [2740/4518] 60% | Training loss: 0.6870595849560995
Epoch: 53 | Iteration number: [2750/4518] 60% | Training loss: 0.6870631108067252
Epoch: 53 | Iteration number: [2760/4518] 61% | Training loss: 0.687063679099083
Epoch: 53 | Iteration number: [2770/4518] 61% | Training loss: 0.6870608183666257
Epoch: 53 | Iteration number: [2780/4518] 61% | Training loss: 0.6870595764341972
Epoch: 53 | Iteration number: [2790/4518] 61% | Training loss: 0.6870627155867955
Epoch: 53 | Iteration number: [2800/4518] 61% | Training loss: 0.6870601394346783
Epoch: 53 | Iteration number: [2810/4518] 62% | Training loss: 0.6870625723511299
Epoch: 53 | Iteration number: [2820/4518] 62% | Training loss: 0.6870633211118955
Epoch: 53 | Iteration number: [2830/4518] 62% | Training loss: 0.6870631632661651
Epoch: 53 | Iteration number: [2840/4518] 62% | Training loss: 0.6870581413658572
Epoch: 53 | Iteration number: [2850/4518] 63% | Training loss: 0.6870539866623125
Epoch: 53 | Iteration number: [2860/4518] 63% | Training loss: 0.6870563576896708
Epoch: 53 | Iteration number: [2870/4518] 63% | Training loss: 0.6870548738627483
Epoch: 53 | Iteration number: [2880/4518] 63% | Training loss: 0.6870532306118144
Epoch: 53 | Iteration number: [2890/4518] 63% | Training loss: 0.6870547517566945
Epoch: 53 | Iteration number: [2900/4518] 64% | Training loss: 0.6870542893533049
Epoch: 53 | Iteration number: [2910/4518] 64% | Training loss: 0.6870555383438097
Epoch: 53 | Iteration number: [2920/4518] 64% | Training loss: 0.6870525199664782
Epoch: 53 | Iteration number: [2930/4518] 64% | Training loss: 0.6870502687965236
Epoch: 53 | Iteration number: [2940/4518] 65% | Training loss: 0.6870497256111936
Epoch: 53 | Iteration number: [2950/4518] 65% | Training loss: 0.6870483078794964
Epoch: 53 | Iteration number: [2960/4518] 65% | Training loss: 0.6870479545279129
Epoch: 53 | Iteration number: [2970/4518] 65% | Training loss: 0.6870486612071092
Epoch: 53 | Iteration number: [2980/4518] 65% | Training loss: 0.6870525457114981
Epoch: 53 | Iteration number: [2990/4518] 66% | Training loss: 0.6870523080777963
Epoch: 53 | Iteration number: [3000/4518] 66% | Training loss: 0.6870542512337366
Epoch: 53 | Iteration number: [3010/4518] 66% | Training loss: 0.6870520880650048
Epoch: 53 | Iteration number: [3020/4518] 66% | Training loss: 0.6870464400542493
Epoch: 53 | Iteration number: [3030/4518] 67% | Training loss: 0.6870465108270299
Epoch: 53 | Iteration number: [3040/4518] 67% | Training loss: 0.6870495362893532
Epoch: 53 | Iteration number: [3050/4518] 67% | Training loss: 0.6870494849760024
Epoch: 53 | Iteration number: [3060/4518] 67% | Training loss: 0.687044080429607
Epoch: 53 | Iteration number: [3070/4518] 67% | Training loss: 0.6870475034760342
Epoch: 53 | Iteration number: [3080/4518] 68% | Training loss: 0.6870484396428257
Epoch: 53 | Iteration number: [3090/4518] 68% | Training loss: 0.6870456043956349
Epoch: 53 | Iteration number: [3100/4518] 68% | Training loss: 0.6870439291384912
Epoch: 53 | Iteration number: [3110/4518] 68% | Training loss: 0.687041313855211
Epoch: 53 | Iteration number: [3120/4518] 69% | Training loss: 0.6870451264274426
Epoch: 53 | Iteration number: [3130/4518] 69% | Training loss: 0.6870383586175145
Epoch: 53 | Iteration number: [3140/4518] 69% | Training loss: 0.6870394528481611
Epoch: 53 | Iteration number: [3150/4518] 69% | Training loss: 0.6870414808818273
Epoch: 53 | Iteration number: [3160/4518] 69% | Training loss: 0.6870401691220984
Epoch: 53 | Iteration number: [3170/4518] 70% | Training loss: 0.6870391421137548
Epoch: 53 | Iteration number: [3180/4518] 70% | Training loss: 0.6870366818500016
Epoch: 53 | Iteration number: [3190/4518] 70% | Training loss: 0.6870380532965765
Epoch: 53 | Iteration number: [3200/4518] 70% | Training loss: 0.6870362189412117
Epoch: 53 | Iteration number: [3210/4518] 71% | Training loss: 0.6870348875396348
Epoch: 53 | Iteration number: [3220/4518] 71% | Training loss: 0.687035348104394
Epoch: 53 | Iteration number: [3230/4518] 71% | Training loss: 0.6870362402115813
Epoch: 53 | Iteration number: [3240/4518] 71% | Training loss: 0.6870364799727628
Epoch: 53 | Iteration number: [3250/4518] 71% | Training loss: 0.6870338621139527
Epoch: 53 | Iteration number: [3260/4518] 72% | Training loss: 0.687034664819577
Epoch: 53 | Iteration number: [3270/4518] 72% | Training loss: 0.6870324248020802
Epoch: 53 | Iteration number: [3280/4518] 72% | Training loss: 0.6870321114979139
Epoch: 53 | Iteration number: [3290/4518] 72% | Training loss: 0.6870294540305268
Epoch: 53 | Iteration number: [3300/4518] 73% | Training loss: 0.6870293814124483
Epoch: 53 | Iteration number: [3310/4518] 73% | Training loss: 0.6870334643611735
Epoch: 53 | Iteration number: [3320/4518] 73% | Training loss: 0.6870321578110558
Epoch: 53 | Iteration number: [3330/4518] 73% | Training loss: 0.6870293456691879
Epoch: 53 | Iteration number: [3340/4518] 73% | Training loss: 0.6870330656538467
Epoch: 53 | Iteration number: [3350/4518] 74% | Training loss: 0.6870374067327869
Epoch: 53 | Iteration number: [3360/4518] 74% | Training loss: 0.6870387875253245
Epoch: 53 | Iteration number: [3370/4518] 74% | Training loss: 0.6870386561229604
Epoch: 53 | Iteration number: [3380/4518] 74% | Training loss: 0.6870368224629284
Epoch: 53 | Iteration number: [3390/4518] 75% | Training loss: 0.68703802108413
Epoch: 53 | Iteration number: [3400/4518] 75% | Training loss: 0.687038109758321
Epoch: 53 | Iteration number: [3410/4518] 75% | Training loss: 0.6870300045111312
Epoch: 53 | Iteration number: [3420/4518] 75% | Training loss: 0.6870309764181661
Epoch: 53 | Iteration number: [3430/4518] 75% | Training loss: 0.6870273836152546
Epoch: 53 | Iteration number: [3440/4518] 76% | Training loss: 0.6870297192314336
Epoch: 53 | Iteration number: [3450/4518] 76% | Training loss: 0.6870276014355645
Epoch: 53 | Iteration number: [3460/4518] 76% | Training loss: 0.6870282466011929
Epoch: 53 | Iteration number: [3470/4518] 76% | Training loss: 0.6870289701034425
Epoch: 53 | Iteration number: [3480/4518] 77% | Training loss: 0.6870292289674967
Epoch: 53 | Iteration number: [3490/4518] 77% | Training loss: 0.6870226873367768
Epoch: 53 | Iteration number: [3500/4518] 77% | Training loss: 0.6870233330386025
Epoch: 53 | Iteration number: [3510/4518] 77% | Training loss: 0.6870239993445894
Epoch: 53 | Iteration number: [3520/4518] 77% | Training loss: 0.6870241199704734
Epoch: 53 | Iteration number: [3530/4518] 78% | Training loss: 0.6870218233244952
Epoch: 53 | Iteration number: [3540/4518] 78% | Training loss: 0.6870249720953279
Epoch: 53 | Iteration number: [3550/4518] 78% | Training loss: 0.687027849731311
Epoch: 53 | Iteration number: [3560/4518] 78% | Training loss: 0.687024097111118
Epoch: 53 | Iteration number: [3570/4518] 79% | Training loss: 0.6870233221548279
Epoch: 53 | Iteration number: [3580/4518] 79% | Training loss: 0.6870217165300966
Epoch: 53 | Iteration number: [3590/4518] 79% | Training loss: 0.6870178582276475
Epoch: 53 | Iteration number: [3600/4518] 79% | Training loss: 0.6870179664923085
Epoch: 53 | Iteration number: [3610/4518] 79% | Training loss: 0.6870189698118913
Epoch: 53 | Iteration number: [3620/4518] 80% | Training loss: 0.6870163903051977
Epoch: 53 | Iteration number: [3630/4518] 80% | Training loss: 0.6870180849529823
Epoch: 53 | Iteration number: [3640/4518] 80% | Training loss: 0.6870181735727813
Epoch: 53 | Iteration number: [3650/4518] 80% | Training loss: 0.6870202131140722
Epoch: 53 | Iteration number: [3660/4518] 81% | Training loss: 0.6870186894154939
Epoch: 53 | Iteration number: [3670/4518] 81% | Training loss: 0.6870169682951
Epoch: 53 | Iteration number: [3680/4518] 81% | Training loss: 0.6870155127152152
Epoch: 53 | Iteration number: [3690/4518] 81% | Training loss: 0.6870150138369098
Epoch: 53 | Iteration number: [3700/4518] 81% | Training loss: 0.6870150939032839
Epoch: 53 | Iteration number: [3710/4518] 82% | Training loss: 0.6870136786985269
Epoch: 53 | Iteration number: [3720/4518] 82% | Training loss: 0.6870128741027206
Epoch: 53 | Iteration number: [3730/4518] 82% | Training loss: 0.6870126960744167
Epoch: 53 | Iteration number: [3740/4518] 82% | Training loss: 0.6870113215025734
Epoch: 53 | Iteration number: [3750/4518] 83% | Training loss: 0.6870112821102142
Epoch: 53 | Iteration number: [3760/4518] 83% | Training loss: 0.6870107798024695
Epoch: 53 | Iteration number: [3770/4518] 83% | Training loss: 0.6870094129672417
Epoch: 53 | Iteration number: [3780/4518] 83% | Training loss: 0.6870092451257049
Epoch: 53 | Iteration number: [3790/4518] 83% | Training loss: 0.6870074170088705
Epoch: 53 | Iteration number: [3800/4518] 84% | Training loss: 0.6870048175360027
Epoch: 53 | Iteration number: [3810/4518] 84% | Training loss: 0.6870067555760461
Epoch: 53 | Iteration number: [3820/4518] 84% | Training loss: 0.6870056043588678
Epoch: 53 | Iteration number: [3830/4518] 84% | Training loss: 0.6870051146798595
Epoch: 53 | Iteration number: [3840/4518] 84% | Training loss: 0.6870049298896144
Epoch: 53 | Iteration number: [3850/4518] 85% | Training loss: 0.6870041234462292
Epoch: 53 | Iteration number: [3860/4518] 85% | Training loss: 0.6870007826719877
Epoch: 53 | Iteration number: [3870/4518] 85% | Training loss: 0.6870008144575804
Epoch: 53 | Iteration number: [3880/4518] 85% | Training loss: 0.6870013132845003
Epoch: 53 | Iteration number: [3890/4518] 86% | Training loss: 0.6869974600471996
Epoch: 53 | Iteration number: [3900/4518] 86% | Training loss: 0.6869969226305301
Epoch: 53 | Iteration number: [3910/4518] 86% | Training loss: 0.686993565690487
Epoch: 53 | Iteration number: [3920/4518] 86% | Training loss: 0.6869930252736929
Epoch: 53 | Iteration number: [3930/4518] 86% | Training loss: 0.6869939939059677
Epoch: 53 | Iteration number: [3940/4518] 87% | Training loss: 0.686996539156449
Epoch: 53 | Iteration number: [3950/4518] 87% | Training loss: 0.686997243784651
Epoch: 53 | Iteration number: [3960/4518] 87% | Training loss: 0.6869993290967411
Epoch: 53 | Iteration number: [3970/4518] 87% | Training loss: 0.6870011416280299
Epoch: 53 | Iteration number: [3980/4518] 88% | Training loss: 0.6870016292710999
Epoch: 53 | Iteration number: [3990/4518] 88% | Training loss: 0.6870028449031046
Epoch: 53 | Iteration number: [4000/4518] 88% | Training loss: 0.6870054575502873
Epoch: 53 | Iteration number: [4010/4518] 88% | Training loss: 0.6870035202128632
Epoch: 53 | Iteration number: [4020/4518] 88% | Training loss: 0.6870039042103943
Epoch: 53 | Iteration number: [4030/4518] 89% | Training loss: 0.6870021051863583
Epoch: 53 | Iteration number: [4040/4518] 89% | Training loss: 0.687005588013937
Epoch: 53 | Iteration number: [4050/4518] 89% | Training loss: 0.687006752917796
Epoch: 53 | Iteration number: [4060/4518] 89% | Training loss: 0.6870027781560504
Epoch: 53 | Iteration number: [4070/4518] 90% | Training loss: 0.6870008621520434
Epoch: 53 | Iteration number: [4080/4518] 90% | Training loss: 0.6870036119193423
Epoch: 53 | Iteration number: [4090/4518] 90% | Training loss: 0.6870037485014255
Epoch: 53 | Iteration number: [4100/4518] 90% | Training loss: 0.6870016639843219
Epoch: 53 | Iteration number: [4110/4518] 90% | Training loss: 0.6870004629856769
Epoch: 53 | Iteration number: [4120/4518] 91% | Training loss: 0.6869991893039167
Epoch: 53 | Iteration number: [4130/4518] 91% | Training loss: 0.6869956949721238
Epoch: 53 | Iteration number: [4140/4518] 91% | Training loss: 0.6869928767571702
Epoch: 53 | Iteration number: [4150/4518] 91% | Training loss: 0.6869938423834652
Epoch: 53 | Iteration number: [4160/4518] 92% | Training loss: 0.6869942800500072
Epoch: 53 | Iteration number: [4170/4518] 92% | Training loss: 0.6869925936634877
Epoch: 53 | Iteration number: [4180/4518] 92% | Training loss: 0.6869937569615944
Epoch: 53 | Iteration number: [4190/4518] 92% | Training loss: 0.686990960785199
Epoch: 53 | Iteration number: [4200/4518] 92% | Training loss: 0.6869917498599916
Epoch: 53 | Iteration number: [4210/4518] 93% | Training loss: 0.6869911839729816
Epoch: 53 | Iteration number: [4220/4518] 93% | Training loss: 0.6869910390738627
Epoch: 53 | Iteration number: [4230/4518] 93% | Training loss: 0.68698688946999
Epoch: 53 | Iteration number: [4240/4518] 93% | Training loss: 0.6869839496629419
Epoch: 53 | Iteration number: [4250/4518] 94% | Training loss: 0.6869807547961965
Epoch: 53 | Iteration number: [4260/4518] 94% | Training loss: 0.6869789596454638
Epoch: 53 | Iteration number: [4270/4518] 94% | Training loss: 0.6869771231114167
Epoch: 53 | Iteration number: [4280/4518] 94% | Training loss: 0.6869743663573934
Epoch: 53 | Iteration number: [4290/4518] 94% | Training loss: 0.686973836344161
Epoch: 53 | Iteration number: [4300/4518] 95% | Training loss: 0.6869724011005357
Epoch: 53 | Iteration number: [4310/4518] 95% | Training loss: 0.6869736353925099
Epoch: 53 | Iteration number: [4320/4518] 95% | Training loss: 0.6869736909452412
Epoch: 53 | Iteration number: [4330/4518] 95% | Training loss: 0.6869745068269294
Epoch: 53 | Iteration number: [4340/4518] 96% | Training loss: 0.6869740727310356
Epoch: 53 | Iteration number: [4350/4518] 96% | Training loss: 0.6869754212067045
Epoch: 53 | Iteration number: [4360/4518] 96% | Training loss: 0.6869723506066777
Epoch: 53 | Iteration number: [4370/4518] 96% | Training loss: 0.6869724096095262
Epoch: 53 | Iteration number: [4380/4518] 96% | Training loss: 0.6869712036494251
Epoch: 53 | Iteration number: [4390/4518] 97% | Training loss: 0.6869694241765963
Epoch: 53 | Iteration number: [4400/4518] 97% | Training loss: 0.6869663048061457
Epoch: 53 | Iteration number: [4410/4518] 97% | Training loss: 0.6869672812436984
Epoch: 53 | Iteration number: [4420/4518] 97% | Training loss: 0.6869636270255525
Epoch: 53 | Iteration number: [4430/4518] 98% | Training loss: 0.686962220173657
Epoch: 53 | Iteration number: [4440/4518] 98% | Training loss: 0.6869616095010225
Epoch: 53 | Iteration number: [4450/4518] 98% | Training loss: 0.6869621408387516
Epoch: 53 | Iteration number: [4460/4518] 98% | Training loss: 0.6869589573866584
Epoch: 53 | Iteration number: [4470/4518] 98% | Training loss: 0.6869587507023908
Epoch: 53 | Iteration number: [4480/4518] 99% | Training loss: 0.6869598812822785
Epoch: 53 | Iteration number: [4490/4518] 99% | Training loss: 0.686956339052366
Epoch: 53 | Iteration number: [4500/4518] 99% | Training loss: 0.6869534760183759
Epoch: 53 | Iteration number: [4510/4518] 99% | Training loss: 0.686956025914448

 End of epoch: 53 | Train Loss: 0.686801036198934 | Training Time: 632 

 End of epoch: 53 | Eval Loss: 0.6898366675084951 | Evaluating Time: 17 
Epoch: 54 | Iteration number: [10/4518] 0% | Training loss: 0.755291324853897
Epoch: 54 | Iteration number: [20/4518] 0% | Training loss: 0.7214376926422119
Epoch: 54 | Iteration number: [30/4518] 0% | Training loss: 0.7096629480520884
Epoch: 54 | Iteration number: [40/4518] 0% | Training loss: 0.7035052478313446
Epoch: 54 | Iteration number: [50/4518] 1% | Training loss: 0.7000961363315582
Epoch: 54 | Iteration number: [60/4518] 1% | Training loss: 0.6978685547908147
Epoch: 54 | Iteration number: [70/4518] 1% | Training loss: 0.6963150450161525
Epoch: 54 | Iteration number: [80/4518] 1% | Training loss: 0.6952911011874676
Epoch: 54 | Iteration number: [90/4518] 1% | Training loss: 0.6942643198702071
Epoch: 54 | Iteration number: [100/4518] 2% | Training loss: 0.6935700464248657
Epoch: 54 | Iteration number: [110/4518] 2% | Training loss: 0.6928118678656492
Epoch: 54 | Iteration number: [120/4518] 2% | Training loss: 0.6922202567259471
Epoch: 54 | Iteration number: [130/4518] 2% | Training loss: 0.6918304956876314
Epoch: 54 | Iteration number: [140/4518] 3% | Training loss: 0.6914654953139169
Epoch: 54 | Iteration number: [150/4518] 3% | Training loss: 0.6911448331673941
Epoch: 54 | Iteration number: [160/4518] 3% | Training loss: 0.690946039929986
Epoch: 54 | Iteration number: [170/4518] 3% | Training loss: 0.6907278607873356
Epoch: 54 | Iteration number: [180/4518] 3% | Training loss: 0.6905127194192674
Epoch: 54 | Iteration number: [190/4518] 4% | Training loss: 0.6902749961928317
Epoch: 54 | Iteration number: [200/4518] 4% | Training loss: 0.6900533214211464
Epoch: 54 | Iteration number: [210/4518] 4% | Training loss: 0.689855694770813
Epoch: 54 | Iteration number: [220/4518] 4% | Training loss: 0.6897188582203605
Epoch: 54 | Iteration number: [230/4518] 5% | Training loss: 0.689627519638642
Epoch: 54 | Iteration number: [240/4518] 5% | Training loss: 0.6895256233712037
Epoch: 54 | Iteration number: [250/4518] 5% | Training loss: 0.6893798294067383
Epoch: 54 | Iteration number: [260/4518] 5% | Training loss: 0.6892919570207596
Epoch: 54 | Iteration number: [270/4518] 5% | Training loss: 0.6891748966994109
Epoch: 54 | Iteration number: [280/4518] 6% | Training loss: 0.6890667195831026
Epoch: 54 | Iteration number: [290/4518] 6% | Training loss: 0.688992002298092
Epoch: 54 | Iteration number: [300/4518] 6% | Training loss: 0.688891602953275
Epoch: 54 | Iteration number: [310/4518] 6% | Training loss: 0.6888145025699369
Epoch: 54 | Iteration number: [320/4518] 7% | Training loss: 0.6887853754684329
Epoch: 54 | Iteration number: [330/4518] 7% | Training loss: 0.6887367900573846
Epoch: 54 | Iteration number: [340/4518] 7% | Training loss: 0.6887093778918771
Epoch: 54 | Iteration number: [350/4518] 7% | Training loss: 0.6886226202760424
Epoch: 54 | Iteration number: [360/4518] 7% | Training loss: 0.6885967974861463
Epoch: 54 | Iteration number: [370/4518] 8% | Training loss: 0.6885098357458372
Epoch: 54 | Iteration number: [380/4518] 8% | Training loss: 0.6884633354450527
Epoch: 54 | Iteration number: [390/4518] 8% | Training loss: 0.6884339950023554
Epoch: 54 | Iteration number: [400/4518] 8% | Training loss: 0.6883787974715233
Epoch: 54 | Iteration number: [410/4518] 9% | Training loss: 0.6883439500157426
Epoch: 54 | Iteration number: [420/4518] 9% | Training loss: 0.6882928748925526
Epoch: 54 | Iteration number: [430/4518] 9% | Training loss: 0.6882633625074874
Epoch: 54 | Iteration number: [440/4518] 9% | Training loss: 0.6882237483154644
Epoch: 54 | Iteration number: [450/4518] 9% | Training loss: 0.6881937770048777
Epoch: 54 | Iteration number: [460/4518] 10% | Training loss: 0.6881579101085663
Epoch: 54 | Iteration number: [470/4518] 10% | Training loss: 0.6881410146013219
Epoch: 54 | Iteration number: [480/4518] 10% | Training loss: 0.688124747077624
Epoch: 54 | Iteration number: [490/4518] 10% | Training loss: 0.6880933251916146
Epoch: 54 | Iteration number: [500/4518] 11% | Training loss: 0.6880772403478622
Epoch: 54 | Iteration number: [510/4518] 11% | Training loss: 0.6880476980817084
Epoch: 54 | Iteration number: [520/4518] 11% | Training loss: 0.6880228284459847
Epoch: 54 | Iteration number: [530/4518] 11% | Training loss: 0.6879924232105039
Epoch: 54 | Iteration number: [540/4518] 11% | Training loss: 0.6879914316866133
Epoch: 54 | Iteration number: [550/4518] 12% | Training loss: 0.6879755428704348
Epoch: 54 | Iteration number: [560/4518] 12% | Training loss: 0.6879628994635173
Epoch: 54 | Iteration number: [570/4518] 12% | Training loss: 0.6879309320658968
Epoch: 54 | Iteration number: [580/4518] 12% | Training loss: 0.6879282565980122
Epoch: 54 | Iteration number: [590/4518] 13% | Training loss: 0.6879240515878645
Epoch: 54 | Iteration number: [600/4518] 13% | Training loss: 0.68791478206714
Epoch: 54 | Iteration number: [610/4518] 13% | Training loss: 0.6879019084523936
Epoch: 54 | Iteration number: [620/4518] 13% | Training loss: 0.6879099322903541
Epoch: 54 | Iteration number: [630/4518] 13% | Training loss: 0.6879106356984093
Epoch: 54 | Iteration number: [640/4518] 14% | Training loss: 0.6878857028670609
Epoch: 54 | Iteration number: [650/4518] 14% | Training loss: 0.6878805751066942
Epoch: 54 | Iteration number: [660/4518] 14% | Training loss: 0.6878685087868661
Epoch: 54 | Iteration number: [670/4518] 14% | Training loss: 0.6878598935568511
Epoch: 54 | Iteration number: [680/4518] 15% | Training loss: 0.6878436344511368
Epoch: 54 | Iteration number: [690/4518] 15% | Training loss: 0.687848920148352
Epoch: 54 | Iteration number: [700/4518] 15% | Training loss: 0.6878331358943667
Epoch: 54 | Iteration number: [710/4518] 15% | Training loss: 0.6878306757396375
Epoch: 54 | Iteration number: [720/4518] 15% | Training loss: 0.6878130858143171
Epoch: 54 | Iteration number: [730/4518] 16% | Training loss: 0.687784546940294
Epoch: 54 | Iteration number: [740/4518] 16% | Training loss: 0.6877711079410604
Epoch: 54 | Iteration number: [750/4518] 16% | Training loss: 0.687762247244517
Epoch: 54 | Iteration number: [760/4518] 16% | Training loss: 0.6877489856983486
Epoch: 54 | Iteration number: [770/4518] 17% | Training loss: 0.6877233323338744
Epoch: 54 | Iteration number: [780/4518] 17% | Training loss: 0.687725833364022
Epoch: 54 | Iteration number: [790/4518] 17% | Training loss: 0.6877220106275775
Epoch: 54 | Iteration number: [800/4518] 17% | Training loss: 0.6877141005545855
Epoch: 54 | Iteration number: [810/4518] 17% | Training loss: 0.6877061330977782
Epoch: 54 | Iteration number: [820/4518] 18% | Training loss: 0.6877083534874567
Epoch: 54 | Iteration number: [830/4518] 18% | Training loss: 0.6877085518406099
Epoch: 54 | Iteration number: [840/4518] 18% | Training loss: 0.6877006473995391
Epoch: 54 | Iteration number: [850/4518] 18% | Training loss: 0.6876969150234671
Epoch: 54 | Iteration number: [860/4518] 19% | Training loss: 0.6876908490824145
Epoch: 54 | Iteration number: [870/4518] 19% | Training loss: 0.6876823945292111
Epoch: 54 | Iteration number: [880/4518] 19% | Training loss: 0.6876696162603119
Epoch: 54 | Iteration number: [890/4518] 19% | Training loss: 0.6876672946335225
Epoch: 54 | Iteration number: [900/4518] 19% | Training loss: 0.6876440836323632
Epoch: 54 | Iteration number: [910/4518] 20% | Training loss: 0.6876222366815085
Epoch: 54 | Iteration number: [920/4518] 20% | Training loss: 0.6876172186239906
Epoch: 54 | Iteration number: [930/4518] 20% | Training loss: 0.687612332067182
Epoch: 54 | Iteration number: [940/4518] 20% | Training loss: 0.6876128549271442
Epoch: 54 | Iteration number: [950/4518] 21% | Training loss: 0.6875983544399864
Epoch: 54 | Iteration number: [960/4518] 21% | Training loss: 0.6875791906689604
Epoch: 54 | Iteration number: [970/4518] 21% | Training loss: 0.6875696856950976
Epoch: 54 | Iteration number: [980/4518] 21% | Training loss: 0.6875516294216623
Epoch: 54 | Iteration number: [990/4518] 21% | Training loss: 0.6875430238969398
Epoch: 54 | Iteration number: [1000/4518] 22% | Training loss: 0.6875325645804405
Epoch: 54 | Iteration number: [1010/4518] 22% | Training loss: 0.6875012815588771
Epoch: 54 | Iteration number: [1020/4518] 22% | Training loss: 0.6874760343163622
Epoch: 54 | Iteration number: [1030/4518] 22% | Training loss: 0.687487846381456
Epoch: 54 | Iteration number: [1040/4518] 23% | Training loss: 0.6874722593678878
Epoch: 54 | Iteration number: [1050/4518] 23% | Training loss: 0.687475772471655
Epoch: 54 | Iteration number: [1060/4518] 23% | Training loss: 0.6874700184700624
Epoch: 54 | Iteration number: [1070/4518] 23% | Training loss: 0.6874822159236836
Epoch: 54 | Iteration number: [1080/4518] 23% | Training loss: 0.6874815573846852
Epoch: 54 | Iteration number: [1090/4518] 24% | Training loss: 0.6874830957946427
Epoch: 54 | Iteration number: [1100/4518] 24% | Training loss: 0.6874642701582475
Epoch: 54 | Iteration number: [1110/4518] 24% | Training loss: 0.687474804848164
Epoch: 54 | Iteration number: [1120/4518] 24% | Training loss: 0.687466065798487
Epoch: 54 | Iteration number: [1130/4518] 25% | Training loss: 0.6874569410771395
Epoch: 54 | Iteration number: [1140/4518] 25% | Training loss: 0.6874601108463188
Epoch: 54 | Iteration number: [1150/4518] 25% | Training loss: 0.6874691384253294
Epoch: 54 | Iteration number: [1160/4518] 25% | Training loss: 0.6874619937662421
Epoch: 54 | Iteration number: [1170/4518] 25% | Training loss: 0.6874612617696453
Epoch: 54 | Iteration number: [1180/4518] 26% | Training loss: 0.6874521457037683
Epoch: 54 | Iteration number: [1190/4518] 26% | Training loss: 0.687444455082677
Epoch: 54 | Iteration number: [1200/4518] 26% | Training loss: 0.687439273049434
Epoch: 54 | Iteration number: [1210/4518] 26% | Training loss: 0.6874283255131777
Epoch: 54 | Iteration number: [1220/4518] 27% | Training loss: 0.6874168698416382
Epoch: 54 | Iteration number: [1230/4518] 27% | Training loss: 0.6874097256641077
Epoch: 54 | Iteration number: [1240/4518] 27% | Training loss: 0.6874101653214424
Epoch: 54 | Iteration number: [1250/4518] 27% | Training loss: 0.687402585697174
Epoch: 54 | Iteration number: [1260/4518] 27% | Training loss: 0.68739641483814
Epoch: 54 | Iteration number: [1270/4518] 28% | Training loss: 0.6873959950105412
Epoch: 54 | Iteration number: [1280/4518] 28% | Training loss: 0.687398269586265
Epoch: 54 | Iteration number: [1290/4518] 28% | Training loss: 0.6873867434586666
Epoch: 54 | Iteration number: [1300/4518] 28% | Training loss: 0.6873746295158679
Epoch: 54 | Iteration number: [1310/4518] 28% | Training loss: 0.6873702796360919
Epoch: 54 | Iteration number: [1320/4518] 29% | Training loss: 0.6873673510370832
Epoch: 54 | Iteration number: [1330/4518] 29% | Training loss: 0.6873641189327814
Epoch: 54 | Iteration number: [1340/4518] 29% | Training loss: 0.6873683716378994
Epoch: 54 | Iteration number: [1350/4518] 29% | Training loss: 0.6873539679138748
Epoch: 54 | Iteration number: [1360/4518] 30% | Training loss: 0.6873544622870053
Epoch: 54 | Iteration number: [1370/4518] 30% | Training loss: 0.687350556841732
Epoch: 54 | Iteration number: [1380/4518] 30% | Training loss: 0.6873479604289152
Epoch: 54 | Iteration number: [1390/4518] 30% | Training loss: 0.6873431919718818
Epoch: 54 | Iteration number: [1400/4518] 30% | Training loss: 0.6873390295250075
Epoch: 54 | Iteration number: [1410/4518] 31% | Training loss: 0.6873370564575736
Epoch: 54 | Iteration number: [1420/4518] 31% | Training loss: 0.6873162468554268
Epoch: 54 | Iteration number: [1430/4518] 31% | Training loss: 0.6873098783976548
Epoch: 54 | Iteration number: [1440/4518] 31% | Training loss: 0.6873081673764521
Epoch: 54 | Iteration number: [1450/4518] 32% | Training loss: 0.6872954417508224
Epoch: 54 | Iteration number: [1460/4518] 32% | Training loss: 0.6872890579373869
Epoch: 54 | Iteration number: [1470/4518] 32% | Training loss: 0.68728240083675
Epoch: 54 | Iteration number: [1480/4518] 32% | Training loss: 0.6872830627737818
Epoch: 54 | Iteration number: [1490/4518] 32% | Training loss: 0.6872827225883535
Epoch: 54 | Iteration number: [1500/4518] 33% | Training loss: 0.6872716293732325
Epoch: 54 | Iteration number: [1510/4518] 33% | Training loss: 0.6872614042648416
Epoch: 54 | Iteration number: [1520/4518] 33% | Training loss: 0.6872534729932483
Epoch: 54 | Iteration number: [1530/4518] 33% | Training loss: 0.6872426514532052
Epoch: 54 | Iteration number: [1540/4518] 34% | Training loss: 0.6872364370079783
Epoch: 54 | Iteration number: [1550/4518] 34% | Training loss: 0.6872353116543062
Epoch: 54 | Iteration number: [1560/4518] 34% | Training loss: 0.6872323150436084
Epoch: 54 | Iteration number: [1570/4518] 34% | Training loss: 0.6872326662965641
Epoch: 54 | Iteration number: [1580/4518] 34% | Training loss: 0.6872328553395936
Epoch: 54 | Iteration number: [1590/4518] 35% | Training loss: 0.6872341179997666
Epoch: 54 | Iteration number: [1600/4518] 35% | Training loss: 0.6872418164089322
Epoch: 54 | Iteration number: [1610/4518] 35% | Training loss: 0.6872407689598036
Epoch: 54 | Iteration number: [1620/4518] 35% | Training loss: 0.6872456380982458
Epoch: 54 | Iteration number: [1630/4518] 36% | Training loss: 0.6872403585106317
Epoch: 54 | Iteration number: [1640/4518] 36% | Training loss: 0.6872391323127398
Epoch: 54 | Iteration number: [1650/4518] 36% | Training loss: 0.6872391908096545
Epoch: 54 | Iteration number: [1660/4518] 36% | Training loss: 0.6872379781610994
Epoch: 54 | Iteration number: [1670/4518] 36% | Training loss: 0.6872311633504079
Epoch: 54 | Iteration number: [1680/4518] 37% | Training loss: 0.6872264775846686
Epoch: 54 | Iteration number: [1690/4518] 37% | Training loss: 0.687220746631453
Epoch: 54 | Iteration number: [1700/4518] 37% | Training loss: 0.6872198055421604
Epoch: 54 | Iteration number: [1710/4518] 37% | Training loss: 0.6872148657054232
Epoch: 54 | Iteration number: [1720/4518] 38% | Training loss: 0.6872051390797593
Epoch: 54 | Iteration number: [1730/4518] 38% | Training loss: 0.6872024708745107
Epoch: 54 | Iteration number: [1740/4518] 38% | Training loss: 0.6872003013032606
Epoch: 54 | Iteration number: [1750/4518] 38% | Training loss: 0.6871992625508989
Epoch: 54 | Iteration number: [1760/4518] 38% | Training loss: 0.687201540409164
Epoch: 54 | Iteration number: [1770/4518] 39% | Training loss: 0.6871977501333096
Epoch: 54 | Iteration number: [1780/4518] 39% | Training loss: 0.6872019571534703
Epoch: 54 | Iteration number: [1790/4518] 39% | Training loss: 0.6872024676986247
Epoch: 54 | Iteration number: [1800/4518] 39% | Training loss: 0.6872076789206929
Epoch: 54 | Iteration number: [1810/4518] 40% | Training loss: 0.6872087062393104
Epoch: 54 | Iteration number: [1820/4518] 40% | Training loss: 0.6872043667913793
Epoch: 54 | Iteration number: [1830/4518] 40% | Training loss: 0.6872079639161219
Epoch: 54 | Iteration number: [1840/4518] 40% | Training loss: 0.6872146188888861
Epoch: 54 | Iteration number: [1850/4518] 40% | Training loss: 0.6872108884437664
Epoch: 54 | Iteration number: [1860/4518] 41% | Training loss: 0.6872098038593928
Epoch: 54 | Iteration number: [1870/4518] 41% | Training loss: 0.6871993113329067
Epoch: 54 | Iteration number: [1880/4518] 41% | Training loss: 0.6871992224708516
Epoch: 54 | Iteration number: [1890/4518] 41% | Training loss: 0.6872023640486299
Epoch: 54 | Iteration number: [1900/4518] 42% | Training loss: 0.6872031262046412
Epoch: 54 | Iteration number: [1910/4518] 42% | Training loss: 0.6871954028831102
Epoch: 54 | Iteration number: [1920/4518] 42% | Training loss: 0.6871938169933856
Epoch: 54 | Iteration number: [1930/4518] 42% | Training loss: 0.6871828018692491
Epoch: 54 | Iteration number: [1940/4518] 42% | Training loss: 0.6871823770483745
Epoch: 54 | Iteration number: [1950/4518] 43% | Training loss: 0.6871783509926919
Epoch: 54 | Iteration number: [1960/4518] 43% | Training loss: 0.6871760255219985
Epoch: 54 | Iteration number: [1970/4518] 43% | Training loss: 0.6871724982249555
Epoch: 54 | Iteration number: [1980/4518] 43% | Training loss: 0.6871674698711646
Epoch: 54 | Iteration number: [1990/4518] 44% | Training loss: 0.6871634378205592
Epoch: 54 | Iteration number: [2000/4518] 44% | Training loss: 0.6871649107336998
Epoch: 54 | Iteration number: [2010/4518] 44% | Training loss: 0.6871628593153029
Epoch: 54 | Iteration number: [2020/4518] 44% | Training loss: 0.6871539262261721
Epoch: 54 | Iteration number: [2030/4518] 44% | Training loss: 0.6871498382737484
Epoch: 54 | Iteration number: [2040/4518] 45% | Training loss: 0.6871484724037787
Epoch: 54 | Iteration number: [2050/4518] 45% | Training loss: 0.6871470594987636
Epoch: 54 | Iteration number: [2060/4518] 45% | Training loss: 0.6871484667641445
Epoch: 54 | Iteration number: [2070/4518] 45% | Training loss: 0.6871504808393654
Epoch: 54 | Iteration number: [2080/4518] 46% | Training loss: 0.6871519436343358
Epoch: 54 | Iteration number: [2090/4518] 46% | Training loss: 0.6871443972918405
Epoch: 54 | Iteration number: [2100/4518] 46% | Training loss: 0.6871425238961265
Epoch: 54 | Iteration number: [2110/4518] 46% | Training loss: 0.6871388865873147
Epoch: 54 | Iteration number: [2120/4518] 46% | Training loss: 0.6871336130038748
Epoch: 54 | Iteration number: [2130/4518] 47% | Training loss: 0.6871271480696862
Epoch: 54 | Iteration number: [2140/4518] 47% | Training loss: 0.6871251557753465
Epoch: 54 | Iteration number: [2150/4518] 47% | Training loss: 0.6871214421128118
Epoch: 54 | Iteration number: [2160/4518] 47% | Training loss: 0.6871196135602615
Epoch: 54 | Iteration number: [2170/4518] 48% | Training loss: 0.6871202707015973
Epoch: 54 | Iteration number: [2180/4518] 48% | Training loss: 0.6871201747601186
Epoch: 54 | Iteration number: [2190/4518] 48% | Training loss: 0.6871246920873041
Epoch: 54 | Iteration number: [2200/4518] 48% | Training loss: 0.6871221046556126
Epoch: 54 | Iteration number: [2210/4518] 48% | Training loss: 0.6871243104675776
Epoch: 54 | Iteration number: [2220/4518] 49% | Training loss: 0.6871249049096494
Epoch: 54 | Iteration number: [2230/4518] 49% | Training loss: 0.6871214667510559
Epoch: 54 | Iteration number: [2240/4518] 49% | Training loss: 0.6871252840118749
Epoch: 54 | Iteration number: [2250/4518] 49% | Training loss: 0.6871244583394792
Epoch: 54 | Iteration number: [2260/4518] 50% | Training loss: 0.6871221695326071
Epoch: 54 | Iteration number: [2270/4518] 50% | Training loss: 0.6871205571464505
Epoch: 54 | Iteration number: [2280/4518] 50% | Training loss: 0.6871250382118058
Epoch: 54 | Iteration number: [2290/4518] 50% | Training loss: 0.6871151392897143
Epoch: 54 | Iteration number: [2300/4518] 50% | Training loss: 0.6871129612300707
Epoch: 54 | Iteration number: [2310/4518] 51% | Training loss: 0.6871163134967094
Epoch: 54 | Iteration number: [2320/4518] 51% | Training loss: 0.6871152875238451
Epoch: 54 | Iteration number: [2330/4518] 51% | Training loss: 0.6871183324781098
Epoch: 54 | Iteration number: [2340/4518] 51% | Training loss: 0.6871175502610003
Epoch: 54 | Iteration number: [2350/4518] 52% | Training loss: 0.6871194086937195
Epoch: 54 | Iteration number: [2360/4518] 52% | Training loss: 0.6871141958034644
Epoch: 54 | Iteration number: [2370/4518] 52% | Training loss: 0.6871125627167617
Epoch: 54 | Iteration number: [2380/4518] 52% | Training loss: 0.6871133206521763
Epoch: 54 | Iteration number: [2390/4518] 52% | Training loss: 0.6871101905112486
Epoch: 54 | Iteration number: [2400/4518] 53% | Training loss: 0.687105402002732
Epoch: 54 | Iteration number: [2410/4518] 53% | Training loss: 0.6871036459548839
Epoch: 54 | Iteration number: [2420/4518] 53% | Training loss: 0.6871026167445932
Epoch: 54 | Iteration number: [2430/4518] 53% | Training loss: 0.6871019180174227
Epoch: 54 | Iteration number: [2440/4518] 54% | Training loss: 0.6871001378190322
Epoch: 54 | Iteration number: [2450/4518] 54% | Training loss: 0.6870992480492105
Epoch: 54 | Iteration number: [2460/4518] 54% | Training loss: 0.6870952481176795
Epoch: 54 | Iteration number: [2470/4518] 54% | Training loss: 0.687089659762286
Epoch: 54 | Iteration number: [2480/4518] 54% | Training loss: 0.6870886281613381
Epoch: 54 | Iteration number: [2490/4518] 55% | Training loss: 0.6870882708624185
Epoch: 54 | Iteration number: [2500/4518] 55% | Training loss: 0.6870876413583755
Epoch: 54 | Iteration number: [2510/4518] 55% | Training loss: 0.6870869028615761
Epoch: 54 | Iteration number: [2520/4518] 55% | Training loss: 0.687088485606133
Epoch: 54 | Iteration number: [2530/4518] 55% | Training loss: 0.6870830852759214
Epoch: 54 | Iteration number: [2540/4518] 56% | Training loss: 0.6870783852075967
Epoch: 54 | Iteration number: [2550/4518] 56% | Training loss: 0.6870778733842513
Epoch: 54 | Iteration number: [2560/4518] 56% | Training loss: 0.687081303447485
Epoch: 54 | Iteration number: [2570/4518] 56% | Training loss: 0.6870835584425277
Epoch: 54 | Iteration number: [2580/4518] 57% | Training loss: 0.6870829052934351
Epoch: 54 | Iteration number: [2590/4518] 57% | Training loss: 0.6870762292712812
Epoch: 54 | Iteration number: [2600/4518] 57% | Training loss: 0.6870747196903596
Epoch: 54 | Iteration number: [2610/4518] 57% | Training loss: 0.6870698333471671
Epoch: 54 | Iteration number: [2620/4518] 57% | Training loss: 0.6870706192864716
Epoch: 54 | Iteration number: [2630/4518] 58% | Training loss: 0.6870723530820114
Epoch: 54 | Iteration number: [2640/4518] 58% | Training loss: 0.6870682550199104
Epoch: 54 | Iteration number: [2650/4518] 58% | Training loss: 0.6870727062000419
Epoch: 54 | Iteration number: [2660/4518] 58% | Training loss: 0.68707440986221
Epoch: 54 | Iteration number: [2670/4518] 59% | Training loss: 0.6870706374725599
Epoch: 54 | Iteration number: [2680/4518] 59% | Training loss: 0.6870674057460543
Epoch: 54 | Iteration number: [2690/4518] 59% | Training loss: 0.6870621147652097
Epoch: 54 | Iteration number: [2700/4518] 59% | Training loss: 0.6870667737060123
Epoch: 54 | Iteration number: [2710/4518] 59% | Training loss: 0.6870676305461194
Epoch: 54 | Iteration number: [2720/4518] 60% | Training loss: 0.6870646078796948
Epoch: 54 | Iteration number: [2730/4518] 60% | Training loss: 0.6870605962180393
Epoch: 54 | Iteration number: [2740/4518] 60% | Training loss: 0.6870589313063308
Epoch: 54 | Iteration number: [2750/4518] 60% | Training loss: 0.6870537954893979
Epoch: 54 | Iteration number: [2760/4518] 61% | Training loss: 0.6870550364687823
Epoch: 54 | Iteration number: [2770/4518] 61% | Training loss: 0.687055728086926
Epoch: 54 | Iteration number: [2780/4518] 61% | Training loss: 0.6870519688017934
Epoch: 54 | Iteration number: [2790/4518] 61% | Training loss: 0.687054828119107
Epoch: 54 | Iteration number: [2800/4518] 61% | Training loss: 0.687055130813803
Epoch: 54 | Iteration number: [2810/4518] 62% | Training loss: 0.6870492811092702
Epoch: 54 | Iteration number: [2820/4518] 62% | Training loss: 0.6870502648624123
Epoch: 54 | Iteration number: [2830/4518] 62% | Training loss: 0.6870530147855779
Epoch: 54 | Iteration number: [2840/4518] 62% | Training loss: 0.6870528480326625
Epoch: 54 | Iteration number: [2850/4518] 63% | Training loss: 0.6870526897698118
Epoch: 54 | Iteration number: [2860/4518] 63% | Training loss: 0.6870505450488804
Epoch: 54 | Iteration number: [2870/4518] 63% | Training loss: 0.6870481373541031
Epoch: 54 | Iteration number: [2880/4518] 63% | Training loss: 0.6870463552160395
Epoch: 54 | Iteration number: [2890/4518] 63% | Training loss: 0.6870458742532763
Epoch: 54 | Iteration number: [2900/4518] 64% | Training loss: 0.6870473252699293
Epoch: 54 | Iteration number: [2910/4518] 64% | Training loss: 0.6870417412613675
Epoch: 54 | Iteration number: [2920/4518] 64% | Training loss: 0.6870433926990588
Epoch: 54 | Iteration number: [2930/4518] 64% | Training loss: 0.6870429340686407
Epoch: 54 | Iteration number: [2940/4518] 65% | Training loss: 0.6870425000077203
Epoch: 54 | Iteration number: [2950/4518] 65% | Training loss: 0.6870412404860481
Epoch: 54 | Iteration number: [2960/4518] 65% | Training loss: 0.6870411650554554
Epoch: 54 | Iteration number: [2970/4518] 65% | Training loss: 0.687042322223034
Epoch: 54 | Iteration number: [2980/4518] 65% | Training loss: 0.6870438319124631
Epoch: 54 | Iteration number: [2990/4518] 66% | Training loss: 0.6870422744830715
Epoch: 54 | Iteration number: [3000/4518] 66% | Training loss: 0.6870417607227961
Epoch: 54 | Iteration number: [3010/4518] 66% | Training loss: 0.6870423506066649
Epoch: 54 | Iteration number: [3020/4518] 66% | Training loss: 0.6870457001869252
Epoch: 54 | Iteration number: [3030/4518] 67% | Training loss: 0.6870484502008646
Epoch: 54 | Iteration number: [3040/4518] 67% | Training loss: 0.6870461957431153
Epoch: 54 | Iteration number: [3050/4518] 67% | Training loss: 0.6870448618052436
Epoch: 54 | Iteration number: [3060/4518] 67% | Training loss: 0.6870459432695426
Epoch: 54 | Iteration number: [3070/4518] 67% | Training loss: 0.6870417804205456
Epoch: 54 | Iteration number: [3080/4518] 68% | Training loss: 0.6870450102857181
Epoch: 54 | Iteration number: [3090/4518] 68% | Training loss: 0.6870400192282347
Epoch: 54 | Iteration number: [3100/4518] 68% | Training loss: 0.6870404990065483
Epoch: 54 | Iteration number: [3110/4518] 68% | Training loss: 0.6870406748014247
Epoch: 54 | Iteration number: [3120/4518] 69% | Training loss: 0.6870443905393283
Epoch: 54 | Iteration number: [3130/4518] 69% | Training loss: 0.6870447966046989
Epoch: 54 | Iteration number: [3140/4518] 69% | Training loss: 0.6870460279048628
Epoch: 54 | Iteration number: [3150/4518] 69% | Training loss: 0.6870471243631272
Epoch: 54 | Iteration number: [3160/4518] 69% | Training loss: 0.6870466639535336
Epoch: 54 | Iteration number: [3170/4518] 70% | Training loss: 0.6870494666535771
Epoch: 54 | Iteration number: [3180/4518] 70% | Training loss: 0.6870475309075049
Epoch: 54 | Iteration number: [3190/4518] 70% | Training loss: 0.6870463676213471
Epoch: 54 | Iteration number: [3200/4518] 70% | Training loss: 0.6870437430776656
Epoch: 54 | Iteration number: [3210/4518] 71% | Training loss: 0.687042933795311
Epoch: 54 | Iteration number: [3220/4518] 71% | Training loss: 0.6870404944101476
Epoch: 54 | Iteration number: [3230/4518] 71% | Training loss: 0.6870358273894425
Epoch: 54 | Iteration number: [3240/4518] 71% | Training loss: 0.6870357245758728
Epoch: 54 | Iteration number: [3250/4518] 71% | Training loss: 0.6870319082186772
Epoch: 54 | Iteration number: [3260/4518] 72% | Training loss: 0.6870311247790518
Epoch: 54 | Iteration number: [3270/4518] 72% | Training loss: 0.6870318335859783
Epoch: 54 | Iteration number: [3280/4518] 72% | Training loss: 0.6870249076950841
Epoch: 54 | Iteration number: [3290/4518] 72% | Training loss: 0.6870215540598953
Epoch: 54 | Iteration number: [3300/4518] 73% | Training loss: 0.6870164402687189
Epoch: 54 | Iteration number: [3310/4518] 73% | Training loss: 0.6870151769178512
Epoch: 54 | Iteration number: [3320/4518] 73% | Training loss: 0.6870158182210233
Epoch: 54 | Iteration number: [3330/4518] 73% | Training loss: 0.6870120155202734
Epoch: 54 | Iteration number: [3340/4518] 73% | Training loss: 0.6870103575690778
Epoch: 54 | Iteration number: [3350/4518] 74% | Training loss: 0.6870056463355448
Epoch: 54 | Iteration number: [3360/4518] 74% | Training loss: 0.6870057096616143
Epoch: 54 | Iteration number: [3370/4518] 74% | Training loss: 0.6870040601898726
Epoch: 54 | Iteration number: [3380/4518] 74% | Training loss: 0.6870014478292691
Epoch: 54 | Iteration number: [3390/4518] 75% | Training loss: 0.6869998099705462
Epoch: 54 | Iteration number: [3400/4518] 75% | Training loss: 0.6870003871532048
Epoch: 54 | Iteration number: [3410/4518] 75% | Training loss: 0.6869947205191134
Epoch: 54 | Iteration number: [3420/4518] 75% | Training loss: 0.6869950639225586
Epoch: 54 | Iteration number: [3430/4518] 75% | Training loss: 0.6869930693776545
Epoch: 54 | Iteration number: [3440/4518] 76% | Training loss: 0.68699357267036
Epoch: 54 | Iteration number: [3450/4518] 76% | Training loss: 0.6869946457164875
Epoch: 54 | Iteration number: [3460/4518] 76% | Training loss: 0.6869924923415818
Epoch: 54 | Iteration number: [3470/4518] 76% | Training loss: 0.6869913769558459
Epoch: 54 | Iteration number: [3480/4518] 77% | Training loss: 0.6869902803466238
Epoch: 54 | Iteration number: [3490/4518] 77% | Training loss: 0.6869882343150142
Epoch: 54 | Iteration number: [3500/4518] 77% | Training loss: 0.6869880980764117
Epoch: 54 | Iteration number: [3510/4518] 77% | Training loss: 0.6869868944173525
Epoch: 54 | Iteration number: [3520/4518] 77% | Training loss: 0.6869875549423423
Epoch: 54 | Iteration number: [3530/4518] 78% | Training loss: 0.686987062875002
Epoch: 54 | Iteration number: [3540/4518] 78% | Training loss: 0.6869859298575396
Epoch: 54 | Iteration number: [3550/4518] 78% | Training loss: 0.6869860526205788
Epoch: 54 | Iteration number: [3560/4518] 78% | Training loss: 0.6869807902849122
Epoch: 54 | Iteration number: [3570/4518] 79% | Training loss: 0.6869793482521335
Epoch: 54 | Iteration number: [3580/4518] 79% | Training loss: 0.6869832840045738
Epoch: 54 | Iteration number: [3590/4518] 79% | Training loss: 0.6869842604508307
Epoch: 54 | Iteration number: [3600/4518] 79% | Training loss: 0.6869846732914447
Epoch: 54 | Iteration number: [3610/4518] 79% | Training loss: 0.6869857269641105
Epoch: 54 | Iteration number: [3620/4518] 80% | Training loss: 0.6869837069215037
Epoch: 54 | Iteration number: [3630/4518] 80% | Training loss: 0.6869823920004295
Epoch: 54 | Iteration number: [3640/4518] 80% | Training loss: 0.6869819353078748
Epoch: 54 | Iteration number: [3650/4518] 80% | Training loss: 0.6869816560287998
Epoch: 54 | Iteration number: [3660/4518] 81% | Training loss: 0.6869817846622623
Epoch: 54 | Iteration number: [3670/4518] 81% | Training loss: 0.686981867200997
Epoch: 54 | Iteration number: [3680/4518] 81% | Training loss: 0.686983169550481
Epoch: 54 | Iteration number: [3690/4518] 81% | Training loss: 0.686979170171872
Epoch: 54 | Iteration number: [3700/4518] 81% | Training loss: 0.6869787366647978
Epoch: 54 | Iteration number: [3710/4518] 82% | Training loss: 0.6869817437990656
Epoch: 54 | Iteration number: [3720/4518] 82% | Training loss: 0.6869794746560435
Epoch: 54 | Iteration number: [3730/4518] 82% | Training loss: 0.6869744684357426
Epoch: 54 | Iteration number: [3740/4518] 82% | Training loss: 0.6869764911777833
Epoch: 54 | Iteration number: [3750/4518] 83% | Training loss: 0.686974409866333
Epoch: 54 | Iteration number: [3760/4518] 83% | Training loss: 0.6869722885495805
Epoch: 54 | Iteration number: [3770/4518] 83% | Training loss: 0.6869705864542043
Epoch: 54 | Iteration number: [3780/4518] 83% | Training loss: 0.6869704530037269
Epoch: 54 | Iteration number: [3790/4518] 83% | Training loss: 0.6869694473403739
Epoch: 54 | Iteration number: [3800/4518] 84% | Training loss: 0.6869682237662768
Epoch: 54 | Iteration number: [3810/4518] 84% | Training loss: 0.6869688440808474
Epoch: 54 | Iteration number: [3820/4518] 84% | Training loss: 0.6869670830315945
Epoch: 54 | Iteration number: [3830/4518] 84% | Training loss: 0.6869637488696345
Epoch: 54 | Iteration number: [3840/4518] 84% | Training loss: 0.6869611868324379
Epoch: 54 | Iteration number: [3850/4518] 85% | Training loss: 0.6869623318585483
Epoch: 54 | Iteration number: [3860/4518] 85% | Training loss: 0.6869635836756909
Epoch: 54 | Iteration number: [3870/4518] 85% | Training loss: 0.6869643788775116
Epoch: 54 | Iteration number: [3880/4518] 85% | Training loss: 0.6869651502555179
Epoch: 54 | Iteration number: [3890/4518] 86% | Training loss: 0.6869651536708626
Epoch: 54 | Iteration number: [3900/4518] 86% | Training loss: 0.6869665199212539
Epoch: 54 | Iteration number: [3910/4518] 86% | Training loss: 0.6869624802523562
Epoch: 54 | Iteration number: [3920/4518] 86% | Training loss: 0.6869631503005417
Epoch: 54 | Iteration number: [3930/4518] 86% | Training loss: 0.6869629359730631
Epoch: 54 | Iteration number: [3940/4518] 87% | Training loss: 0.686964545107735
Epoch: 54 | Iteration number: [3950/4518] 87% | Training loss: 0.6869650285153449
Epoch: 54 | Iteration number: [3960/4518] 87% | Training loss: 0.6869604923508384
Epoch: 54 | Iteration number: [3970/4518] 87% | Training loss: 0.6869589304893984
Epoch: 54 | Iteration number: [3980/4518] 88% | Training loss: 0.6869601962404634
Epoch: 54 | Iteration number: [3990/4518] 88% | Training loss: 0.6869589356999648
Epoch: 54 | Iteration number: [4000/4518] 88% | Training loss: 0.6869560798257589
Epoch: 54 | Iteration number: [4010/4518] 88% | Training loss: 0.6869584203063699
Epoch: 54 | Iteration number: [4020/4518] 88% | Training loss: 0.6869545120949769
Epoch: 54 | Iteration number: [4030/4518] 89% | Training loss: 0.6869532069260665
Epoch: 54 | Iteration number: [4040/4518] 89% | Training loss: 0.6869524856752688
Epoch: 54 | Iteration number: [4050/4518] 89% | Training loss: 0.6869523431195154
Epoch: 54 | Iteration number: [4060/4518] 89% | Training loss: 0.6869541836783216
Epoch: 54 | Iteration number: [4070/4518] 90% | Training loss: 0.6869558689928172
Epoch: 54 | Iteration number: [4080/4518] 90% | Training loss: 0.6869559928482654
Epoch: 54 | Iteration number: [4090/4518] 90% | Training loss: 0.6869585834680385
Epoch: 54 | Iteration number: [4100/4518] 90% | Training loss: 0.6869596539619492
Epoch: 54 | Iteration number: [4110/4518] 90% | Training loss: 0.6869569366865784
Epoch: 54 | Iteration number: [4120/4518] 91% | Training loss: 0.6869587183143329
Epoch: 54 | Iteration number: [4130/4518] 91% | Training loss: 0.6869573101293088
Epoch: 54 | Iteration number: [4140/4518] 91% | Training loss: 0.6869565106532424
Epoch: 54 | Iteration number: [4150/4518] 91% | Training loss: 0.6869571458575238
Epoch: 54 | Iteration number: [4160/4518] 92% | Training loss: 0.6869532566804152
Epoch: 54 | Iteration number: [4170/4518] 92% | Training loss: 0.6869490533995686
Epoch: 54 | Iteration number: [4180/4518] 92% | Training loss: 0.6869494239964553
Epoch: 54 | Iteration number: [4190/4518] 92% | Training loss: 0.6869466829555985
Epoch: 54 | Iteration number: [4200/4518] 92% | Training loss: 0.6869469711610249
Epoch: 54 | Iteration number: [4210/4518] 93% | Training loss: 0.6869470342462816
Epoch: 54 | Iteration number: [4220/4518] 93% | Training loss: 0.6869469937696276
Epoch: 54 | Iteration number: [4230/4518] 93% | Training loss: 0.6869460277664464
Epoch: 54 | Iteration number: [4240/4518] 93% | Training loss: 0.6869454988471742
Epoch: 54 | Iteration number: [4250/4518] 94% | Training loss: 0.6869461578341092
Epoch: 54 | Iteration number: [4260/4518] 94% | Training loss: 0.6869467600410533
Epoch: 54 | Iteration number: [4270/4518] 94% | Training loss: 0.6869459926663294
Epoch: 54 | Iteration number: [4280/4518] 94% | Training loss: 0.6869516192056309
Epoch: 54 | Iteration number: [4290/4518] 94% | Training loss: 0.6869539908595852
Epoch: 54 | Iteration number: [4300/4518] 95% | Training loss: 0.6869542516386786
Epoch: 54 | Iteration number: [4310/4518] 95% | Training loss: 0.6869572535883246
Epoch: 54 | Iteration number: [4320/4518] 95% | Training loss: 0.6869575430535608
Epoch: 54 | Iteration number: [4330/4518] 95% | Training loss: 0.6869566273744332
Epoch: 54 | Iteration number: [4340/4518] 96% | Training loss: 0.686954191588037
Epoch: 54 | Iteration number: [4350/4518] 96% | Training loss: 0.6869572979417341
Epoch: 54 | Iteration number: [4360/4518] 96% | Training loss: 0.6869576570090897
Epoch: 54 | Iteration number: [4370/4518] 96% | Training loss: 0.6869586152124733
Epoch: 54 | Iteration number: [4380/4518] 96% | Training loss: 0.686958115272326
Epoch: 54 | Iteration number: [4390/4518] 97% | Training loss: 0.6869595200570134
Epoch: 54 | Iteration number: [4400/4518] 97% | Training loss: 0.6869585418701172
Epoch: 54 | Iteration number: [4410/4518] 97% | Training loss: 0.6869586456795128
Epoch: 54 | Iteration number: [4420/4518] 97% | Training loss: 0.6869609629541501
Epoch: 54 | Iteration number: [4430/4518] 98% | Training loss: 0.6869589436404053
Epoch: 54 | Iteration number: [4440/4518] 98% | Training loss: 0.6869566666247608
Epoch: 54 | Iteration number: [4450/4518] 98% | Training loss: 0.6869567868950661
Epoch: 54 | Iteration number: [4460/4518] 98% | Training loss: 0.6869554245284855
Epoch: 54 | Iteration number: [4470/4518] 98% | Training loss: 0.6869575166995626
Epoch: 54 | Iteration number: [4480/4518] 99% | Training loss: 0.6869589793362788
Epoch: 54 | Iteration number: [4490/4518] 99% | Training loss: 0.686958433233019
Epoch: 54 | Iteration number: [4500/4518] 99% | Training loss: 0.6869561067157322
Epoch: 54 | Iteration number: [4510/4518] 99% | Training loss: 0.6869538604684521

 End of epoch: 54 | Train Loss: 0.6867978422712467 | Training Time: 632 

 End of epoch: 54 | Eval Loss: 0.6897313996237151 | Evaluating Time: 17 
Epoch: 55 | Iteration number: [10/4518] 0% | Training loss: 0.7558992683887482
Epoch: 55 | Iteration number: [20/4518] 0% | Training loss: 0.7218778401613235
Epoch: 55 | Iteration number: [30/4518] 0% | Training loss: 0.7101263463497162
Epoch: 55 | Iteration number: [40/4518] 0% | Training loss: 0.704190282523632
Epoch: 55 | Iteration number: [50/4518] 1% | Training loss: 0.7007781314849854
Epoch: 55 | Iteration number: [60/4518] 1% | Training loss: 0.698401591181755
Epoch: 55 | Iteration number: [70/4518] 1% | Training loss: 0.6967185037476676
Epoch: 55 | Iteration number: [80/4518] 1% | Training loss: 0.6954938046634197
Epoch: 55 | Iteration number: [90/4518] 1% | Training loss: 0.6943962693214416
Epoch: 55 | Iteration number: [100/4518] 2% | Training loss: 0.6936982625722885
Epoch: 55 | Iteration number: [110/4518] 2% | Training loss: 0.6930938108400865
Epoch: 55 | Iteration number: [120/4518] 2% | Training loss: 0.6925472483038903
Epoch: 55 | Iteration number: [130/4518] 2% | Training loss: 0.692072076522387
Epoch: 55 | Iteration number: [140/4518] 3% | Training loss: 0.691774491752897
Epoch: 55 | Iteration number: [150/4518] 3% | Training loss: 0.6914632892608643
Epoch: 55 | Iteration number: [160/4518] 3% | Training loss: 0.6911739591509104
Epoch: 55 | Iteration number: [170/4518] 3% | Training loss: 0.690929928597282
Epoch: 55 | Iteration number: [180/4518] 3% | Training loss: 0.6906308793359333
Epoch: 55 | Iteration number: [190/4518] 4% | Training loss: 0.6904541125423029
Epoch: 55 | Iteration number: [200/4518] 4% | Training loss: 0.6902470663189888
Epoch: 55 | Iteration number: [210/4518] 4% | Training loss: 0.690062898965109
Epoch: 55 | Iteration number: [220/4518] 4% | Training loss: 0.6899151918562976
Epoch: 55 | Iteration number: [230/4518] 5% | Training loss: 0.6897963915182197
Epoch: 55 | Iteration number: [240/4518] 5% | Training loss: 0.6896278344094753
Epoch: 55 | Iteration number: [250/4518] 5% | Training loss: 0.6895082938671112
Epoch: 55 | Iteration number: [260/4518] 5% | Training loss: 0.6894240734668878
Epoch: 55 | Iteration number: [270/4518] 5% | Training loss: 0.6893613232506646
Epoch: 55 | Iteration number: [280/4518] 6% | Training loss: 0.6892037717359406
Epoch: 55 | Iteration number: [290/4518] 6% | Training loss: 0.6891001945939558
Epoch: 55 | Iteration number: [300/4518] 6% | Training loss: 0.6890265280008316
Epoch: 55 | Iteration number: [310/4518] 6% | Training loss: 0.6889700530036803
Epoch: 55 | Iteration number: [320/4518] 7% | Training loss: 0.6888919789344072
Epoch: 55 | Iteration number: [330/4518] 7% | Training loss: 0.6888490375244256
Epoch: 55 | Iteration number: [340/4518] 7% | Training loss: 0.6887854928479475
Epoch: 55 | Iteration number: [350/4518] 7% | Training loss: 0.6887499024186815
Epoch: 55 | Iteration number: [360/4518] 7% | Training loss: 0.6886768024828699
Epoch: 55 | Iteration number: [370/4518] 8% | Training loss: 0.6886424671959233
Epoch: 55 | Iteration number: [380/4518] 8% | Training loss: 0.6885932298083054
Epoch: 55 | Iteration number: [390/4518] 8% | Training loss: 0.6885269165039063
Epoch: 55 | Iteration number: [400/4518] 8% | Training loss: 0.6885038785636425
Epoch: 55 | Iteration number: [410/4518] 9% | Training loss: 0.6884867665244312
Epoch: 55 | Iteration number: [420/4518] 9% | Training loss: 0.6884713089182264
Epoch: 55 | Iteration number: [430/4518] 9% | Training loss: 0.6884108557257541
Epoch: 55 | Iteration number: [440/4518] 9% | Training loss: 0.6883983819322153
Epoch: 55 | Iteration number: [450/4518] 9% | Training loss: 0.6883734238147735
Epoch: 55 | Iteration number: [460/4518] 10% | Training loss: 0.6883450195841168
Epoch: 55 | Iteration number: [470/4518] 10% | Training loss: 0.6883019763104459
Epoch: 55 | Iteration number: [480/4518] 10% | Training loss: 0.6882561280081669
Epoch: 55 | Iteration number: [490/4518] 10% | Training loss: 0.6882242435095262
Epoch: 55 | Iteration number: [500/4518] 11% | Training loss: 0.6881811003684998
Epoch: 55 | Iteration number: [510/4518] 11% | Training loss: 0.6881700518084507
Epoch: 55 | Iteration number: [520/4518] 11% | Training loss: 0.6881413048276535
Epoch: 55 | Iteration number: [530/4518] 11% | Training loss: 0.6881377010975244
Epoch: 55 | Iteration number: [540/4518] 11% | Training loss: 0.6881219968751625
Epoch: 55 | Iteration number: [550/4518] 12% | Training loss: 0.6881027410247109
Epoch: 55 | Iteration number: [560/4518] 12% | Training loss: 0.6880766836660249
Epoch: 55 | Iteration number: [570/4518] 12% | Training loss: 0.6880412516886728
Epoch: 55 | Iteration number: [580/4518] 12% | Training loss: 0.688009195594952
Epoch: 55 | Iteration number: [590/4518] 13% | Training loss: 0.6879921302957049
Epoch: 55 | Iteration number: [600/4518] 13% | Training loss: 0.6879463740189871
Epoch: 55 | Iteration number: [610/4518] 13% | Training loss: 0.68793461537752
Epoch: 55 | Iteration number: [620/4518] 13% | Training loss: 0.6879198550216613
Epoch: 55 | Iteration number: [630/4518] 13% | Training loss: 0.6879215732453361
Epoch: 55 | Iteration number: [640/4518] 14% | Training loss: 0.6879212719388306
Epoch: 55 | Iteration number: [650/4518] 14% | Training loss: 0.6878905371519235
Epoch: 55 | Iteration number: [660/4518] 14% | Training loss: 0.687881174864191
Epoch: 55 | Iteration number: [670/4518] 14% | Training loss: 0.6878757175224931
Epoch: 55 | Iteration number: [680/4518] 15% | Training loss: 0.687851435910253
Epoch: 55 | Iteration number: [690/4518] 15% | Training loss: 0.6878363840821861
Epoch: 55 | Iteration number: [700/4518] 15% | Training loss: 0.6878255078622273
Epoch: 55 | Iteration number: [710/4518] 15% | Training loss: 0.6877987729831481
Epoch: 55 | Iteration number: [720/4518] 15% | Training loss: 0.6878013532194827
Epoch: 55 | Iteration number: [730/4518] 16% | Training loss: 0.6877929984706722
Epoch: 55 | Iteration number: [740/4518] 16% | Training loss: 0.6877722800583452
Epoch: 55 | Iteration number: [750/4518] 16% | Training loss: 0.6877735571066539
Epoch: 55 | Iteration number: [760/4518] 16% | Training loss: 0.6877654790094024
Epoch: 55 | Iteration number: [770/4518] 17% | Training loss: 0.6877480016126261
Epoch: 55 | Iteration number: [780/4518] 17% | Training loss: 0.6877272924551597
Epoch: 55 | Iteration number: [790/4518] 17% | Training loss: 0.687719789562346
Epoch: 55 | Iteration number: [800/4518] 17% | Training loss: 0.687710400596261
Epoch: 55 | Iteration number: [810/4518] 17% | Training loss: 0.6877045721919448
Epoch: 55 | Iteration number: [820/4518] 18% | Training loss: 0.6876977464047874
Epoch: 55 | Iteration number: [830/4518] 18% | Training loss: 0.6876718211604889
Epoch: 55 | Iteration number: [840/4518] 18% | Training loss: 0.6876731717870349
Epoch: 55 | Iteration number: [850/4518] 18% | Training loss: 0.687665183544159
Epoch: 55 | Iteration number: [860/4518] 19% | Training loss: 0.6876572438450747
Epoch: 55 | Iteration number: [870/4518] 19% | Training loss: 0.6876465757687886
Epoch: 55 | Iteration number: [880/4518] 19% | Training loss: 0.6876378617503426
Epoch: 55 | Iteration number: [890/4518] 19% | Training loss: 0.6876204660099544
Epoch: 55 | Iteration number: [900/4518] 19% | Training loss: 0.6876244346963035
Epoch: 55 | Iteration number: [910/4518] 20% | Training loss: 0.6876115643061125
Epoch: 55 | Iteration number: [920/4518] 20% | Training loss: 0.6875931004467217
Epoch: 55 | Iteration number: [930/4518] 20% | Training loss: 0.6875751240279084
Epoch: 55 | Iteration number: [940/4518] 20% | Training loss: 0.687565980312672
Epoch: 55 | Iteration number: [950/4518] 21% | Training loss: 0.6875569925182744
Epoch: 55 | Iteration number: [960/4518] 21% | Training loss: 0.6875498448808988
Epoch: 55 | Iteration number: [970/4518] 21% | Training loss: 0.6875469038781431
Epoch: 55 | Iteration number: [980/4518] 21% | Training loss: 0.6875369175356262
Epoch: 55 | Iteration number: [990/4518] 21% | Training loss: 0.6875285969840156
Epoch: 55 | Iteration number: [1000/4518] 22% | Training loss: 0.6875254165530205
Epoch: 55 | Iteration number: [1010/4518] 22% | Training loss: 0.6875192906006728
Epoch: 55 | Iteration number: [1020/4518] 22% | Training loss: 0.6874973689224205
Epoch: 55 | Iteration number: [1030/4518] 22% | Training loss: 0.6874922338619973
Epoch: 55 | Iteration number: [1040/4518] 23% | Training loss: 0.6874936260282993
Epoch: 55 | Iteration number: [1050/4518] 23% | Training loss: 0.687487910702115
Epoch: 55 | Iteration number: [1060/4518] 23% | Training loss: 0.6874755013663814
Epoch: 55 | Iteration number: [1070/4518] 23% | Training loss: 0.6874655931352455
Epoch: 55 | Iteration number: [1080/4518] 23% | Training loss: 0.6874617498781946
Epoch: 55 | Iteration number: [1090/4518] 24% | Training loss: 0.6874499505266137
Epoch: 55 | Iteration number: [1100/4518] 24% | Training loss: 0.6874409727074883
Epoch: 55 | Iteration number: [1110/4518] 24% | Training loss: 0.6874410975623775
Epoch: 55 | Iteration number: [1120/4518] 24% | Training loss: 0.6874266439250537
Epoch: 55 | Iteration number: [1130/4518] 25% | Training loss: 0.6874255091743132
Epoch: 55 | Iteration number: [1140/4518] 25% | Training loss: 0.6874195545911789
Epoch: 55 | Iteration number: [1150/4518] 25% | Training loss: 0.687408456335897
Epoch: 55 | Iteration number: [1160/4518] 25% | Training loss: 0.6874081816138893
Epoch: 55 | Iteration number: [1170/4518] 25% | Training loss: 0.6874058409124358
Epoch: 55 | Iteration number: [1180/4518] 26% | Training loss: 0.6874173005253582
Epoch: 55 | Iteration number: [1190/4518] 26% | Training loss: 0.6874172928954373
Epoch: 55 | Iteration number: [1200/4518] 26% | Training loss: 0.6874097764492035
Epoch: 55 | Iteration number: [1210/4518] 26% | Training loss: 0.6874062474601524
Epoch: 55 | Iteration number: [1220/4518] 27% | Training loss: 0.6874076448991651
Epoch: 55 | Iteration number: [1230/4518] 27% | Training loss: 0.6873986984171518
Epoch: 55 | Iteration number: [1240/4518] 27% | Training loss: 0.6873898272552798
Epoch: 55 | Iteration number: [1250/4518] 27% | Training loss: 0.6873813527107239
Epoch: 55 | Iteration number: [1260/4518] 27% | Training loss: 0.6873740270497307
Epoch: 55 | Iteration number: [1270/4518] 28% | Training loss: 0.6873701670977075
Epoch: 55 | Iteration number: [1280/4518] 28% | Training loss: 0.6873631285503506
Epoch: 55 | Iteration number: [1290/4518] 28% | Training loss: 0.6873589640439943
Epoch: 55 | Iteration number: [1300/4518] 28% | Training loss: 0.6873565309322798
Epoch: 55 | Iteration number: [1310/4518] 28% | Training loss: 0.687340246630079
Epoch: 55 | Iteration number: [1320/4518] 29% | Training loss: 0.6873406460790923
Epoch: 55 | Iteration number: [1330/4518] 29% | Training loss: 0.6873285831813526
Epoch: 55 | Iteration number: [1340/4518] 29% | Training loss: 0.6873185740478003
Epoch: 55 | Iteration number: [1350/4518] 29% | Training loss: 0.6873168774004336
Epoch: 55 | Iteration number: [1360/4518] 30% | Training loss: 0.6873180155806682
Epoch: 55 | Iteration number: [1370/4518] 30% | Training loss: 0.68731395106246
Epoch: 55 | Iteration number: [1380/4518] 30% | Training loss: 0.6873109176970911
Epoch: 55 | Iteration number: [1390/4518] 30% | Training loss: 0.6873192636229152
Epoch: 55 | Iteration number: [1400/4518] 30% | Training loss: 0.6873087663735662
Epoch: 55 | Iteration number: [1410/4518] 31% | Training loss: 0.6873029149593191
Epoch: 55 | Iteration number: [1420/4518] 31% | Training loss: 0.6873041649099807
Epoch: 55 | Iteration number: [1430/4518] 31% | Training loss: 0.6872953791718382
Epoch: 55 | Iteration number: [1440/4518] 31% | Training loss: 0.6872910692873928
Epoch: 55 | Iteration number: [1450/4518] 32% | Training loss: 0.6872821371308688
Epoch: 55 | Iteration number: [1460/4518] 32% | Training loss: 0.6872801527585068
Epoch: 55 | Iteration number: [1470/4518] 32% | Training loss: 0.6872724638098762
Epoch: 55 | Iteration number: [1480/4518] 32% | Training loss: 0.6872649636623022
Epoch: 55 | Iteration number: [1490/4518] 32% | Training loss: 0.6872601798716808
Epoch: 55 | Iteration number: [1500/4518] 33% | Training loss: 0.6872590219974518
Epoch: 55 | Iteration number: [1510/4518] 33% | Training loss: 0.6872510445828469
Epoch: 55 | Iteration number: [1520/4518] 33% | Training loss: 0.6872471766252267
Epoch: 55 | Iteration number: [1530/4518] 33% | Training loss: 0.6872377021250382
Epoch: 55 | Iteration number: [1540/4518] 34% | Training loss: 0.6872257660735738
Epoch: 55 | Iteration number: [1550/4518] 34% | Training loss: 0.6872243163278026
Epoch: 55 | Iteration number: [1560/4518] 34% | Training loss: 0.6872259175548187
Epoch: 55 | Iteration number: [1570/4518] 34% | Training loss: 0.6872116807160105
Epoch: 55 | Iteration number: [1580/4518] 34% | Training loss: 0.6872123444759393
Epoch: 55 | Iteration number: [1590/4518] 35% | Training loss: 0.6872108445977265
Epoch: 55 | Iteration number: [1600/4518] 35% | Training loss: 0.6872059804946185
Epoch: 55 | Iteration number: [1610/4518] 35% | Training loss: 0.6872014841307764
Epoch: 55 | Iteration number: [1620/4518] 35% | Training loss: 0.687205296570872
Epoch: 55 | Iteration number: [1630/4518] 36% | Training loss: 0.6872031566189842
Epoch: 55 | Iteration number: [1640/4518] 36% | Training loss: 0.6872019525708222
Epoch: 55 | Iteration number: [1650/4518] 36% | Training loss: 0.6871897037823995
Epoch: 55 | Iteration number: [1660/4518] 36% | Training loss: 0.6871887516544526
Epoch: 55 | Iteration number: [1670/4518] 36% | Training loss: 0.6871814600721805
Epoch: 55 | Iteration number: [1680/4518] 37% | Training loss: 0.6871920223037402
Epoch: 55 | Iteration number: [1690/4518] 37% | Training loss: 0.6871782916184713
Epoch: 55 | Iteration number: [1700/4518] 37% | Training loss: 0.6871766837204204
Epoch: 55 | Iteration number: [1710/4518] 37% | Training loss: 0.6871751568819348
Epoch: 55 | Iteration number: [1720/4518] 38% | Training loss: 0.6871725783445114
Epoch: 55 | Iteration number: [1730/4518] 38% | Training loss: 0.6871696005322341
Epoch: 55 | Iteration number: [1740/4518] 38% | Training loss: 0.6871729314669796
Epoch: 55 | Iteration number: [1750/4518] 38% | Training loss: 0.6871651366438184
Epoch: 55 | Iteration number: [1760/4518] 38% | Training loss: 0.6871726036071777
Epoch: 55 | Iteration number: [1770/4518] 39% | Training loss: 0.6871650083253613
Epoch: 55 | Iteration number: [1780/4518] 39% | Training loss: 0.6871658935305778
Epoch: 55 | Iteration number: [1790/4518] 39% | Training loss: 0.6871591940938427
Epoch: 55 | Iteration number: [1800/4518] 39% | Training loss: 0.6871600889166196
Epoch: 55 | Iteration number: [1810/4518] 40% | Training loss: 0.687161378965852
Epoch: 55 | Iteration number: [1820/4518] 40% | Training loss: 0.6871609804394481
Epoch: 55 | Iteration number: [1830/4518] 40% | Training loss: 0.6871593216729295
Epoch: 55 | Iteration number: [1840/4518] 40% | Training loss: 0.6871578337705654
Epoch: 55 | Iteration number: [1850/4518] 40% | Training loss: 0.687165447602401
Epoch: 55 | Iteration number: [1860/4518] 41% | Training loss: 0.6871598120979083
Epoch: 55 | Iteration number: [1870/4518] 41% | Training loss: 0.6871568655266481
Epoch: 55 | Iteration number: [1880/4518] 41% | Training loss: 0.6871620686447367
Epoch: 55 | Iteration number: [1890/4518] 41% | Training loss: 0.6871575085258989
Epoch: 55 | Iteration number: [1900/4518] 42% | Training loss: 0.6871497962663048
Epoch: 55 | Iteration number: [1910/4518] 42% | Training loss: 0.6871534341604922
Epoch: 55 | Iteration number: [1920/4518] 42% | Training loss: 0.6871586638502777
Epoch: 55 | Iteration number: [1930/4518] 42% | Training loss: 0.6871543559076873
Epoch: 55 | Iteration number: [1940/4518] 42% | Training loss: 0.6871504540295945
Epoch: 55 | Iteration number: [1950/4518] 43% | Training loss: 0.6871468546146001
Epoch: 55 | Iteration number: [1960/4518] 43% | Training loss: 0.6871412878133812
Epoch: 55 | Iteration number: [1970/4518] 43% | Training loss: 0.6871363640134105
Epoch: 55 | Iteration number: [1980/4518] 43% | Training loss: 0.6871357379236607
Epoch: 55 | Iteration number: [1990/4518] 44% | Training loss: 0.6871327615862516
Epoch: 55 | Iteration number: [2000/4518] 44% | Training loss: 0.6871357280015945
Epoch: 55 | Iteration number: [2010/4518] 44% | Training loss: 0.6871248433839029
Epoch: 55 | Iteration number: [2020/4518] 44% | Training loss: 0.6871224924184308
Epoch: 55 | Iteration number: [2030/4518] 44% | Training loss: 0.6871194322708205
Epoch: 55 | Iteration number: [2040/4518] 45% | Training loss: 0.6871160120356317
Epoch: 55 | Iteration number: [2050/4518] 45% | Training loss: 0.6871134220972294
Epoch: 55 | Iteration number: [2060/4518] 45% | Training loss: 0.6871170223048589
Epoch: 55 | Iteration number: [2070/4518] 45% | Training loss: 0.6871081241662952
Epoch: 55 | Iteration number: [2080/4518] 46% | Training loss: 0.6871037472899143
Epoch: 55 | Iteration number: [2090/4518] 46% | Training loss: 0.6871098612484179
Epoch: 55 | Iteration number: [2100/4518] 46% | Training loss: 0.6871123937198094
Epoch: 55 | Iteration number: [2110/4518] 46% | Training loss: 0.6871137105175669
Epoch: 55 | Iteration number: [2120/4518] 46% | Training loss: 0.6871132644842256
Epoch: 55 | Iteration number: [2130/4518] 47% | Training loss: 0.6871146507386311
Epoch: 55 | Iteration number: [2140/4518] 47% | Training loss: 0.687119798097655
Epoch: 55 | Iteration number: [2150/4518] 47% | Training loss: 0.6871157163797423
Epoch: 55 | Iteration number: [2160/4518] 47% | Training loss: 0.6871159692605336
Epoch: 55 | Iteration number: [2170/4518] 48% | Training loss: 0.687119298074652
Epoch: 55 | Iteration number: [2180/4518] 48% | Training loss: 0.6871206505856383
Epoch: 55 | Iteration number: [2190/4518] 48% | Training loss: 0.6871179664243846
Epoch: 55 | Iteration number: [2200/4518] 48% | Training loss: 0.6871172798492692
Epoch: 55 | Iteration number: [2210/4518] 48% | Training loss: 0.6871122629933767
Epoch: 55 | Iteration number: [2220/4518] 49% | Training loss: 0.6871058502712766
Epoch: 55 | Iteration number: [2230/4518] 49% | Training loss: 0.6871087044611105
Epoch: 55 | Iteration number: [2240/4518] 49% | Training loss: 0.687106931555484
Epoch: 55 | Iteration number: [2250/4518] 49% | Training loss: 0.68710726096895
Epoch: 55 | Iteration number: [2260/4518] 50% | Training loss: 0.6871130922463088
Epoch: 55 | Iteration number: [2270/4518] 50% | Training loss: 0.6871133026047425
Epoch: 55 | Iteration number: [2280/4518] 50% | Training loss: 0.6871132016181946
Epoch: 55 | Iteration number: [2290/4518] 50% | Training loss: 0.687108876715581
Epoch: 55 | Iteration number: [2300/4518] 50% | Training loss: 0.6871069511382476
Epoch: 55 | Iteration number: [2310/4518] 51% | Training loss: 0.6871018629569512
Epoch: 55 | Iteration number: [2320/4518] 51% | Training loss: 0.6871046068339512
Epoch: 55 | Iteration number: [2330/4518] 51% | Training loss: 0.6871011724032046
Epoch: 55 | Iteration number: [2340/4518] 51% | Training loss: 0.6871008086663026
Epoch: 55 | Iteration number: [2350/4518] 52% | Training loss: 0.687100837814047
Epoch: 55 | Iteration number: [2360/4518] 52% | Training loss: 0.687098750371044
Epoch: 55 | Iteration number: [2370/4518] 52% | Training loss: 0.6871037890890983
Epoch: 55 | Iteration number: [2380/4518] 52% | Training loss: 0.6871045395356267
Epoch: 55 | Iteration number: [2390/4518] 52% | Training loss: 0.6871064177118086
Epoch: 55 | Iteration number: [2400/4518] 53% | Training loss: 0.687106192111969
Epoch: 55 | Iteration number: [2410/4518] 53% | Training loss: 0.687104353914617
Epoch: 55 | Iteration number: [2420/4518] 53% | Training loss: 0.6870992201911517
Epoch: 55 | Iteration number: [2430/4518] 53% | Training loss: 0.6871025819101452
Epoch: 55 | Iteration number: [2440/4518] 54% | Training loss: 0.6871039579637715
Epoch: 55 | Iteration number: [2450/4518] 54% | Training loss: 0.6870987308998497
Epoch: 55 | Iteration number: [2460/4518] 54% | Training loss: 0.6871040357079933
Epoch: 55 | Iteration number: [2470/4518] 54% | Training loss: 0.6871032749110388
Epoch: 55 | Iteration number: [2480/4518] 54% | Training loss: 0.6870969548100425
Epoch: 55 | Iteration number: [2490/4518] 55% | Training loss: 0.687099333963241
Epoch: 55 | Iteration number: [2500/4518] 55% | Training loss: 0.6871020456075668
Epoch: 55 | Iteration number: [2510/4518] 55% | Training loss: 0.6870976191355412
Epoch: 55 | Iteration number: [2520/4518] 55% | Training loss: 0.6870987912492147
Epoch: 55 | Iteration number: [2530/4518] 55% | Training loss: 0.6870959796217591
Epoch: 55 | Iteration number: [2540/4518] 56% | Training loss: 0.687094221715852
Epoch: 55 | Iteration number: [2550/4518] 56% | Training loss: 0.6870922139345431
Epoch: 55 | Iteration number: [2560/4518] 56% | Training loss: 0.6870927506592125
Epoch: 55 | Iteration number: [2570/4518] 56% | Training loss: 0.6870856034384627
Epoch: 55 | Iteration number: [2580/4518] 57% | Training loss: 0.6870865168959596
Epoch: 55 | Iteration number: [2590/4518] 57% | Training loss: 0.6870857350154272
Epoch: 55 | Iteration number: [2600/4518] 57% | Training loss: 0.6870890206327805
Epoch: 55 | Iteration number: [2610/4518] 57% | Training loss: 0.6870874937466734
Epoch: 55 | Iteration number: [2620/4518] 57% | Training loss: 0.687087662597649
Epoch: 55 | Iteration number: [2630/4518] 58% | Training loss: 0.6870853024970442
Epoch: 55 | Iteration number: [2640/4518] 58% | Training loss: 0.687085571320671
Epoch: 55 | Iteration number: [2650/4518] 58% | Training loss: 0.687083947883462
Epoch: 55 | Iteration number: [2660/4518] 58% | Training loss: 0.6870815950452833
Epoch: 55 | Iteration number: [2670/4518] 59% | Training loss: 0.6870841252669859
Epoch: 55 | Iteration number: [2680/4518] 59% | Training loss: 0.6870838683487764
Epoch: 55 | Iteration number: [2690/4518] 59% | Training loss: 0.6870882834200522
Epoch: 55 | Iteration number: [2700/4518] 59% | Training loss: 0.6870933441541813
Epoch: 55 | Iteration number: [2710/4518] 59% | Training loss: 0.6870936718814048
Epoch: 55 | Iteration number: [2720/4518] 60% | Training loss: 0.6870887324213981
Epoch: 55 | Iteration number: [2730/4518] 60% | Training loss: 0.6870805224874518
Epoch: 55 | Iteration number: [2740/4518] 60% | Training loss: 0.687075832790702
Epoch: 55 | Iteration number: [2750/4518] 60% | Training loss: 0.6870822620825334
Epoch: 55 | Iteration number: [2760/4518] 61% | Training loss: 0.6870808993128763
Epoch: 55 | Iteration number: [2770/4518] 61% | Training loss: 0.6870879497553898
Epoch: 55 | Iteration number: [2780/4518] 61% | Training loss: 0.6870867401790276
Epoch: 55 | Iteration number: [2790/4518] 61% | Training loss: 0.6870837273349899
Epoch: 55 | Iteration number: [2800/4518] 61% | Training loss: 0.6870795278038297
Epoch: 55 | Iteration number: [2810/4518] 62% | Training loss: 0.6870746557186507
Epoch: 55 | Iteration number: [2820/4518] 62% | Training loss: 0.687075341635562
Epoch: 55 | Iteration number: [2830/4518] 62% | Training loss: 0.6870796591359398
Epoch: 55 | Iteration number: [2840/4518] 62% | Training loss: 0.6870724006228044
Epoch: 55 | Iteration number: [2850/4518] 63% | Training loss: 0.6870706927358059
Epoch: 55 | Iteration number: [2860/4518] 63% | Training loss: 0.6870711982667029
Epoch: 55 | Iteration number: [2870/4518] 63% | Training loss: 0.6870645363156388
Epoch: 55 | Iteration number: [2880/4518] 63% | Training loss: 0.6870662992820143
Epoch: 55 | Iteration number: [2890/4518] 63% | Training loss: 0.6870674603125628
Epoch: 55 | Iteration number: [2900/4518] 64% | Training loss: 0.6870694009600015
Epoch: 55 | Iteration number: [2910/4518] 64% | Training loss: 0.68706298378325
Epoch: 55 | Iteration number: [2920/4518] 64% | Training loss: 0.6870611874208058
Epoch: 55 | Iteration number: [2930/4518] 64% | Training loss: 0.6870594782227135
Epoch: 55 | Iteration number: [2940/4518] 65% | Training loss: 0.687054735057208
Epoch: 55 | Iteration number: [2950/4518] 65% | Training loss: 0.6870515986014221
Epoch: 55 | Iteration number: [2960/4518] 65% | Training loss: 0.6870509078776514
Epoch: 55 | Iteration number: [2970/4518] 65% | Training loss: 0.6870490487175759
Epoch: 55 | Iteration number: [2980/4518] 65% | Training loss: 0.6870482108336967
Epoch: 55 | Iteration number: [2990/4518] 66% | Training loss: 0.6870478837984462
Epoch: 55 | Iteration number: [3000/4518] 66% | Training loss: 0.6870478187402089
Epoch: 55 | Iteration number: [3010/4518] 66% | Training loss: 0.6870489788609881
Epoch: 55 | Iteration number: [3020/4518] 66% | Training loss: 0.6870488099112416
Epoch: 55 | Iteration number: [3030/4518] 67% | Training loss: 0.6870449052785489
Epoch: 55 | Iteration number: [3040/4518] 67% | Training loss: 0.6870450347661972
Epoch: 55 | Iteration number: [3050/4518] 67% | Training loss: 0.6870468170525598
Epoch: 55 | Iteration number: [3060/4518] 67% | Training loss: 0.6870500384592543
Epoch: 55 | Iteration number: [3070/4518] 67% | Training loss: 0.6870492318359959
Epoch: 55 | Iteration number: [3080/4518] 68% | Training loss: 0.6870471341269356
Epoch: 55 | Iteration number: [3090/4518] 68% | Training loss: 0.6870450070567887
Epoch: 55 | Iteration number: [3100/4518] 68% | Training loss: 0.6870410664812211
Epoch: 55 | Iteration number: [3110/4518] 68% | Training loss: 0.6870416740512542
Epoch: 55 | Iteration number: [3120/4518] 69% | Training loss: 0.6870433560739725
Epoch: 55 | Iteration number: [3130/4518] 69% | Training loss: 0.6870441652715397
Epoch: 55 | Iteration number: [3140/4518] 69% | Training loss: 0.6870425964047195
Epoch: 55 | Iteration number: [3150/4518] 69% | Training loss: 0.6870399502723936
Epoch: 55 | Iteration number: [3160/4518] 69% | Training loss: 0.68704012057072
Epoch: 55 | Iteration number: [3170/4518] 70% | Training loss: 0.6870418928399071
Epoch: 55 | Iteration number: [3180/4518] 70% | Training loss: 0.6870418574262716
Epoch: 55 | Iteration number: [3190/4518] 70% | Training loss: 0.6870386404864093
Epoch: 55 | Iteration number: [3200/4518] 70% | Training loss: 0.6870353222638369
Epoch: 55 | Iteration number: [3210/4518] 71% | Training loss: 0.6870327546960469
Epoch: 55 | Iteration number: [3220/4518] 71% | Training loss: 0.6870324518924914
Epoch: 55 | Iteration number: [3230/4518] 71% | Training loss: 0.6870318346717409
Epoch: 55 | Iteration number: [3240/4518] 71% | Training loss: 0.6870318823390537
Epoch: 55 | Iteration number: [3250/4518] 71% | Training loss: 0.6870288331325237
Epoch: 55 | Iteration number: [3260/4518] 72% | Training loss: 0.687022719902495
Epoch: 55 | Iteration number: [3270/4518] 72% | Training loss: 0.6870226818304908
Epoch: 55 | Iteration number: [3280/4518] 72% | Training loss: 0.6870223659022552
Epoch: 55 | Iteration number: [3290/4518] 72% | Training loss: 0.6870201409587744
Epoch: 55 | Iteration number: [3300/4518] 73% | Training loss: 0.687016612255212
Epoch: 55 | Iteration number: [3310/4518] 73% | Training loss: 0.6870175091521618
Epoch: 55 | Iteration number: [3320/4518] 73% | Training loss: 0.6870174351585917
Epoch: 55 | Iteration number: [3330/4518] 73% | Training loss: 0.6870179635089438
Epoch: 55 | Iteration number: [3340/4518] 73% | Training loss: 0.6870178448047467
Epoch: 55 | Iteration number: [3350/4518] 74% | Training loss: 0.68701463393311
Epoch: 55 | Iteration number: [3360/4518] 74% | Training loss: 0.6870139821476879
Epoch: 55 | Iteration number: [3370/4518] 74% | Training loss: 0.687014543178881
Epoch: 55 | Iteration number: [3380/4518] 74% | Training loss: 0.6870120961814237
Epoch: 55 | Iteration number: [3390/4518] 75% | Training loss: 0.6870126339362435
Epoch: 55 | Iteration number: [3400/4518] 75% | Training loss: 0.6870095870600027
Epoch: 55 | Iteration number: [3410/4518] 75% | Training loss: 0.6870115282773273
Epoch: 55 | Iteration number: [3420/4518] 75% | Training loss: 0.6870111244289498
Epoch: 55 | Iteration number: [3430/4518] 75% | Training loss: 0.6870118141174316
Epoch: 55 | Iteration number: [3440/4518] 76% | Training loss: 0.6870117793769337
Epoch: 55 | Iteration number: [3450/4518] 76% | Training loss: 0.6870115449117578
Epoch: 55 | Iteration number: [3460/4518] 76% | Training loss: 0.6870128831594665
Epoch: 55 | Iteration number: [3470/4518] 76% | Training loss: 0.6870094321131363
Epoch: 55 | Iteration number: [3480/4518] 77% | Training loss: 0.6870125100872982
Epoch: 55 | Iteration number: [3490/4518] 77% | Training loss: 0.6870104626461565
Epoch: 55 | Iteration number: [3500/4518] 77% | Training loss: 0.6870114958456585
Epoch: 55 | Iteration number: [3510/4518] 77% | Training loss: 0.6870128678290592
Epoch: 55 | Iteration number: [3520/4518] 77% | Training loss: 0.6870058232918381
Epoch: 55 | Iteration number: [3530/4518] 78% | Training loss: 0.6870059231185373
Epoch: 55 | Iteration number: [3540/4518] 78% | Training loss: 0.6870062230838894
Epoch: 55 | Iteration number: [3550/4518] 78% | Training loss: 0.6870054457557033
Epoch: 55 | Iteration number: [3560/4518] 78% | Training loss: 0.6870086541336574
Epoch: 55 | Iteration number: [3570/4518] 79% | Training loss: 0.6870140043961234
Epoch: 55 | Iteration number: [3580/4518] 79% | Training loss: 0.6870119349583568
Epoch: 55 | Iteration number: [3590/4518] 79% | Training loss: 0.6870110906266237
Epoch: 55 | Iteration number: [3600/4518] 79% | Training loss: 0.6870087234841453
Epoch: 55 | Iteration number: [3610/4518] 79% | Training loss: 0.687008792591227
Epoch: 55 | Iteration number: [3620/4518] 80% | Training loss: 0.6870082182120223
Epoch: 55 | Iteration number: [3630/4518] 80% | Training loss: 0.6870037453562103
Epoch: 55 | Iteration number: [3640/4518] 80% | Training loss: 0.6870036906102202
Epoch: 55 | Iteration number: [3650/4518] 80% | Training loss: 0.6870007374025371
Epoch: 55 | Iteration number: [3660/4518] 81% | Training loss: 0.6869971005480147
Epoch: 55 | Iteration number: [3670/4518] 81% | Training loss: 0.6869949042634678
Epoch: 55 | Iteration number: [3680/4518] 81% | Training loss: 0.6869941437050052
Epoch: 55 | Iteration number: [3690/4518] 81% | Training loss: 0.6869952915160636
Epoch: 55 | Iteration number: [3700/4518] 81% | Training loss: 0.686993219739682
Epoch: 55 | Iteration number: [3710/4518] 82% | Training loss: 0.6869930321797527
Epoch: 55 | Iteration number: [3720/4518] 82% | Training loss: 0.6869952795646523
Epoch: 55 | Iteration number: [3730/4518] 82% | Training loss: 0.6869920469640727
Epoch: 55 | Iteration number: [3740/4518] 82% | Training loss: 0.6869925131612921
Epoch: 55 | Iteration number: [3750/4518] 83% | Training loss: 0.6869905011971792
Epoch: 55 | Iteration number: [3760/4518] 83% | Training loss: 0.6869891840251202
Epoch: 55 | Iteration number: [3770/4518] 83% | Training loss: 0.6869880096349539
Epoch: 55 | Iteration number: [3780/4518] 83% | Training loss: 0.6869866751489185
Epoch: 55 | Iteration number: [3790/4518] 83% | Training loss: 0.6869875463143502
Epoch: 55 | Iteration number: [3800/4518] 84% | Training loss: 0.6869851864952791
Epoch: 55 | Iteration number: [3810/4518] 84% | Training loss: 0.686986817071444
Epoch: 55 | Iteration number: [3820/4518] 84% | Training loss: 0.686986170170819
Epoch: 55 | Iteration number: [3830/4518] 84% | Training loss: 0.6869880731672282
Epoch: 55 | Iteration number: [3840/4518] 84% | Training loss: 0.686988564596201
Epoch: 55 | Iteration number: [3850/4518] 85% | Training loss: 0.6869877086521743
Epoch: 55 | Iteration number: [3860/4518] 85% | Training loss: 0.6869816432036266
Epoch: 55 | Iteration number: [3870/4518] 85% | Training loss: 0.6869858283559174
Epoch: 55 | Iteration number: [3880/4518] 85% | Training loss: 0.6869835995521743
Epoch: 55 | Iteration number: [3890/4518] 86% | Training loss: 0.6869839844942706
Epoch: 55 | Iteration number: [3900/4518] 86% | Training loss: 0.6869816331527172
Epoch: 55 | Iteration number: [3910/4518] 86% | Training loss: 0.6869834634958936
Epoch: 55 | Iteration number: [3920/4518] 86% | Training loss: 0.6869811401075246
Epoch: 55 | Iteration number: [3930/4518] 86% | Training loss: 0.6869847369254697
Epoch: 55 | Iteration number: [3940/4518] 87% | Training loss: 0.6869852800508441
Epoch: 55 | Iteration number: [3950/4518] 87% | Training loss: 0.6869864049742493
Epoch: 55 | Iteration number: [3960/4518] 87% | Training loss: 0.686989426658009
Epoch: 55 | Iteration number: [3970/4518] 87% | Training loss: 0.6869885178747346
Epoch: 55 | Iteration number: [3980/4518] 88% | Training loss: 0.6869898150464399
Epoch: 55 | Iteration number: [3990/4518] 88% | Training loss: 0.6869841204550033
Epoch: 55 | Iteration number: [4000/4518] 88% | Training loss: 0.686983106970787
Epoch: 55 | Iteration number: [4010/4518] 88% | Training loss: 0.6869855111079323
Epoch: 55 | Iteration number: [4020/4518] 88% | Training loss: 0.6869842966694144
Epoch: 55 | Iteration number: [4030/4518] 89% | Training loss: 0.6869820556185086
Epoch: 55 | Iteration number: [4040/4518] 89% | Training loss: 0.686983752383454
Epoch: 55 | Iteration number: [4050/4518] 89% | Training loss: 0.6869825995704274
Epoch: 55 | Iteration number: [4060/4518] 89% | Training loss: 0.6869802831575789
Epoch: 55 | Iteration number: [4070/4518] 90% | Training loss: 0.6869805757624511
Epoch: 55 | Iteration number: [4080/4518] 90% | Training loss: 0.6869793831425555
Epoch: 55 | Iteration number: [4090/4518] 90% | Training loss: 0.6869797865161102
Epoch: 55 | Iteration number: [4100/4518] 90% | Training loss: 0.6869781932162076
Epoch: 55 | Iteration number: [4110/4518] 90% | Training loss: 0.6869802006404765
Epoch: 55 | Iteration number: [4120/4518] 91% | Training loss: 0.6869809785658874
Epoch: 55 | Iteration number: [4130/4518] 91% | Training loss: 0.6869800885277857
Epoch: 55 | Iteration number: [4140/4518] 91% | Training loss: 0.6869798037596947
Epoch: 55 | Iteration number: [4150/4518] 91% | Training loss: 0.6869817580659705
Epoch: 55 | Iteration number: [4160/4518] 92% | Training loss: 0.6869831358154233
Epoch: 55 | Iteration number: [4170/4518] 92% | Training loss: 0.6869814882032591
Epoch: 55 | Iteration number: [4180/4518] 92% | Training loss: 0.6869800763267079
Epoch: 55 | Iteration number: [4190/4518] 92% | Training loss: 0.6869793584494716
Epoch: 55 | Iteration number: [4200/4518] 92% | Training loss: 0.6869767504646664
Epoch: 55 | Iteration number: [4210/4518] 93% | Training loss: 0.6869762989092892
Epoch: 55 | Iteration number: [4220/4518] 93% | Training loss: 0.6869771578583107
Epoch: 55 | Iteration number: [4230/4518] 93% | Training loss: 0.6869759136057915
Epoch: 55 | Iteration number: [4240/4518] 93% | Training loss: 0.6869752214061764
Epoch: 55 | Iteration number: [4250/4518] 94% | Training loss: 0.6869738839654361
Epoch: 55 | Iteration number: [4260/4518] 94% | Training loss: 0.6869755738637817
Epoch: 55 | Iteration number: [4270/4518] 94% | Training loss: 0.68697304031888
Epoch: 55 | Iteration number: [4280/4518] 94% | Training loss: 0.6869698578927005
Epoch: 55 | Iteration number: [4290/4518] 94% | Training loss: 0.6869689077486247
Epoch: 55 | Iteration number: [4300/4518] 95% | Training loss: 0.6869676544361336
Epoch: 55 | Iteration number: [4310/4518] 95% | Training loss: 0.6869653288698528
Epoch: 55 | Iteration number: [4320/4518] 95% | Training loss: 0.6869663644582034
Epoch: 55 | Iteration number: [4330/4518] 95% | Training loss: 0.6869658038192202
Epoch: 55 | Iteration number: [4340/4518] 96% | Training loss: 0.6869641137699927
Epoch: 55 | Iteration number: [4350/4518] 96% | Training loss: 0.6869623385078606
Epoch: 55 | Iteration number: [4360/4518] 96% | Training loss: 0.686963367284438
Epoch: 55 | Iteration number: [4370/4518] 96% | Training loss: 0.6869626395353191
Epoch: 55 | Iteration number: [4380/4518] 96% | Training loss: 0.6869632979234059
Epoch: 55 | Iteration number: [4390/4518] 97% | Training loss: 0.6869622976606148
Epoch: 55 | Iteration number: [4400/4518] 97% | Training loss: 0.6869633258337324
Epoch: 55 | Iteration number: [4410/4518] 97% | Training loss: 0.6869614240263595
Epoch: 55 | Iteration number: [4420/4518] 97% | Training loss: 0.6869628924859595
Epoch: 55 | Iteration number: [4430/4518] 98% | Training loss: 0.6869599269555869
Epoch: 55 | Iteration number: [4440/4518] 98% | Training loss: 0.6869574062861837
Epoch: 55 | Iteration number: [4450/4518] 98% | Training loss: 0.6869573450088501
Epoch: 55 | Iteration number: [4460/4518] 98% | Training loss: 0.6869590770236045
Epoch: 55 | Iteration number: [4470/4518] 98% | Training loss: 0.6869558921729692
Epoch: 55 | Iteration number: [4480/4518] 99% | Training loss: 0.6869539477197187
Epoch: 55 | Iteration number: [4490/4518] 99% | Training loss: 0.6869525631711318
Epoch: 55 | Iteration number: [4500/4518] 99% | Training loss: 0.6869497339593039
Epoch: 55 | Iteration number: [4510/4518] 99% | Training loss: 0.6869488691147045

 End of epoch: 55 | Train Loss: 0.6867966260225069 | Training Time: 632 

 End of epoch: 55 | Eval Loss: 0.6897298669328495 | Evaluating Time: 17 
Epoch: 56 | Iteration number: [10/4518] 0% | Training loss: 0.7560835719108582
Epoch: 56 | Iteration number: [20/4518] 0% | Training loss: 0.721282547712326
Epoch: 56 | Iteration number: [30/4518] 0% | Training loss: 0.7099375247955322
Epoch: 56 | Iteration number: [40/4518] 0% | Training loss: 0.704115842282772
Epoch: 56 | Iteration number: [50/4518] 1% | Training loss: 0.7007415163516998
Epoch: 56 | Iteration number: [60/4518] 1% | Training loss: 0.6982967913150787
Epoch: 56 | Iteration number: [70/4518] 1% | Training loss: 0.6966814500944954
Epoch: 56 | Iteration number: [80/4518] 1% | Training loss: 0.6954251930117608
Epoch: 56 | Iteration number: [90/4518] 1% | Training loss: 0.6945292486084832
Epoch: 56 | Iteration number: [100/4518] 2% | Training loss: 0.6937992030382156
Epoch: 56 | Iteration number: [110/4518] 2% | Training loss: 0.6931859970092773
Epoch: 56 | Iteration number: [120/4518] 2% | Training loss: 0.6927423616250356
Epoch: 56 | Iteration number: [130/4518] 2% | Training loss: 0.6923251977333655
Epoch: 56 | Iteration number: [140/4518] 3% | Training loss: 0.6919414516006197
Epoch: 56 | Iteration number: [150/4518] 3% | Training loss: 0.6915987106164296
Epoch: 56 | Iteration number: [160/4518] 3% | Training loss: 0.6912542510777712
Epoch: 56 | Iteration number: [170/4518] 3% | Training loss: 0.6909817439668319
Epoch: 56 | Iteration number: [180/4518] 3% | Training loss: 0.6907809774080912
Epoch: 56 | Iteration number: [190/4518] 4% | Training loss: 0.6905630594805667
Epoch: 56 | Iteration number: [200/4518] 4% | Training loss: 0.6902954855561256
Epoch: 56 | Iteration number: [210/4518] 4% | Training loss: 0.6901163427602677
Epoch: 56 | Iteration number: [220/4518] 4% | Training loss: 0.6899537679823962
Epoch: 56 | Iteration number: [230/4518] 5% | Training loss: 0.689817014725312
Epoch: 56 | Iteration number: [240/4518] 5% | Training loss: 0.6896317558983962
Epoch: 56 | Iteration number: [250/4518] 5% | Training loss: 0.6895190575122834
Epoch: 56 | Iteration number: [260/4518] 5% | Training loss: 0.689450815320015
Epoch: 56 | Iteration number: [270/4518] 5% | Training loss: 0.6893580048172562
Epoch: 56 | Iteration number: [280/4518] 6% | Training loss: 0.6892428191644805
Epoch: 56 | Iteration number: [290/4518] 6% | Training loss: 0.6891078539963427
Epoch: 56 | Iteration number: [300/4518] 6% | Training loss: 0.6890126192569732
Epoch: 56 | Iteration number: [310/4518] 6% | Training loss: 0.6889493138559403
Epoch: 56 | Iteration number: [320/4518] 7% | Training loss: 0.6888683574274183
Epoch: 56 | Iteration number: [330/4518] 7% | Training loss: 0.6888146310141592
Epoch: 56 | Iteration number: [340/4518] 7% | Training loss: 0.6887315904392916
Epoch: 56 | Iteration number: [350/4518] 7% | Training loss: 0.6886305664266859
Epoch: 56 | Iteration number: [360/4518] 7% | Training loss: 0.6885422122147348
Epoch: 56 | Iteration number: [370/4518] 8% | Training loss: 0.6885162184367308
Epoch: 56 | Iteration number: [380/4518] 8% | Training loss: 0.6884699801081106
Epoch: 56 | Iteration number: [390/4518] 8% | Training loss: 0.68840733842972
Epoch: 56 | Iteration number: [400/4518] 8% | Training loss: 0.6883896580338478
Epoch: 56 | Iteration number: [410/4518] 9% | Training loss: 0.6883033335208892
Epoch: 56 | Iteration number: [420/4518] 9% | Training loss: 0.688244750953856
Epoch: 56 | Iteration number: [430/4518] 9% | Training loss: 0.6881813254467276
Epoch: 56 | Iteration number: [440/4518] 9% | Training loss: 0.6881417227062312
Epoch: 56 | Iteration number: [450/4518] 9% | Training loss: 0.6880997380945417
Epoch: 56 | Iteration number: [460/4518] 10% | Training loss: 0.6880920259848885
Epoch: 56 | Iteration number: [470/4518] 10% | Training loss: 0.6880573896651573
Epoch: 56 | Iteration number: [480/4518] 10% | Training loss: 0.688018373772502
Epoch: 56 | Iteration number: [490/4518] 10% | Training loss: 0.6879900892170108
Epoch: 56 | Iteration number: [500/4518] 11% | Training loss: 0.6880003489255905
Epoch: 56 | Iteration number: [510/4518] 11% | Training loss: 0.6879838382496554
Epoch: 56 | Iteration number: [520/4518] 11% | Training loss: 0.6879928797483444
Epoch: 56 | Iteration number: [530/4518] 11% | Training loss: 0.6879673302173615
Epoch: 56 | Iteration number: [540/4518] 11% | Training loss: 0.6879559913167247
Epoch: 56 | Iteration number: [550/4518] 12% | Training loss: 0.6879423939098012
Epoch: 56 | Iteration number: [560/4518] 12% | Training loss: 0.6879219110522952
Epoch: 56 | Iteration number: [570/4518] 12% | Training loss: 0.6879171173823507
Epoch: 56 | Iteration number: [580/4518] 12% | Training loss: 0.6878835057390147
Epoch: 56 | Iteration number: [590/4518] 13% | Training loss: 0.6878550762847319
Epoch: 56 | Iteration number: [600/4518] 13% | Training loss: 0.6878235682845115
Epoch: 56 | Iteration number: [610/4518] 13% | Training loss: 0.6877976096067272
Epoch: 56 | Iteration number: [620/4518] 13% | Training loss: 0.6877820206265296
Epoch: 56 | Iteration number: [630/4518] 13% | Training loss: 0.68776034116745
Epoch: 56 | Iteration number: [640/4518] 14% | Training loss: 0.687778299767524
Epoch: 56 | Iteration number: [650/4518] 14% | Training loss: 0.6877557752682613
Epoch: 56 | Iteration number: [660/4518] 14% | Training loss: 0.6877362150134463
Epoch: 56 | Iteration number: [670/4518] 14% | Training loss: 0.6877266415909155
Epoch: 56 | Iteration number: [680/4518] 15% | Training loss: 0.6877168179434888
Epoch: 56 | Iteration number: [690/4518] 15% | Training loss: 0.6877036422922991
Epoch: 56 | Iteration number: [700/4518] 15% | Training loss: 0.6876922277893339
Epoch: 56 | Iteration number: [710/4518] 15% | Training loss: 0.6876718429612442
Epoch: 56 | Iteration number: [720/4518] 15% | Training loss: 0.6876667370398839
Epoch: 56 | Iteration number: [730/4518] 16% | Training loss: 0.6876601906671916
Epoch: 56 | Iteration number: [740/4518] 16% | Training loss: 0.6876573519126788
Epoch: 56 | Iteration number: [750/4518] 16% | Training loss: 0.6876612694263459
Epoch: 56 | Iteration number: [760/4518] 16% | Training loss: 0.6876494996641812
Epoch: 56 | Iteration number: [770/4518] 17% | Training loss: 0.6876347485300782
Epoch: 56 | Iteration number: [780/4518] 17% | Training loss: 0.6876384493632194
Epoch: 56 | Iteration number: [790/4518] 17% | Training loss: 0.6876125016544439
Epoch: 56 | Iteration number: [800/4518] 17% | Training loss: 0.6876084408909082
Epoch: 56 | Iteration number: [810/4518] 17% | Training loss: 0.6876160954987561
Epoch: 56 | Iteration number: [820/4518] 18% | Training loss: 0.6875919713479717
Epoch: 56 | Iteration number: [830/4518] 18% | Training loss: 0.6875793027590557
Epoch: 56 | Iteration number: [840/4518] 18% | Training loss: 0.6875641369393893
Epoch: 56 | Iteration number: [850/4518] 18% | Training loss: 0.6875629541453193
Epoch: 56 | Iteration number: [860/4518] 19% | Training loss: 0.6875426857277405
Epoch: 56 | Iteration number: [870/4518] 19% | Training loss: 0.6875314854342361
Epoch: 56 | Iteration number: [880/4518] 19% | Training loss: 0.6875254444777965
Epoch: 56 | Iteration number: [890/4518] 19% | Training loss: 0.6875033698055182
Epoch: 56 | Iteration number: [900/4518] 19% | Training loss: 0.6874983494149314
Epoch: 56 | Iteration number: [910/4518] 20% | Training loss: 0.6874887522105332
Epoch: 56 | Iteration number: [920/4518] 20% | Training loss: 0.6874820011465446
Epoch: 56 | Iteration number: [930/4518] 20% | Training loss: 0.6874837763847843
Epoch: 56 | Iteration number: [940/4518] 20% | Training loss: 0.6874687885984462
Epoch: 56 | Iteration number: [950/4518] 21% | Training loss: 0.6874737771561271
Epoch: 56 | Iteration number: [960/4518] 21% | Training loss: 0.6874669364343087
Epoch: 56 | Iteration number: [970/4518] 21% | Training loss: 0.6874730870281298
Epoch: 56 | Iteration number: [980/4518] 21% | Training loss: 0.6874630170209067
Epoch: 56 | Iteration number: [990/4518] 21% | Training loss: 0.6874605561747695
Epoch: 56 | Iteration number: [1000/4518] 22% | Training loss: 0.6874587218165398
Epoch: 56 | Iteration number: [1010/4518] 22% | Training loss: 0.6874536092328554
Epoch: 56 | Iteration number: [1020/4518] 22% | Training loss: 0.6874445942687053
Epoch: 56 | Iteration number: [1030/4518] 22% | Training loss: 0.6874393815554461
Epoch: 56 | Iteration number: [1040/4518] 23% | Training loss: 0.6874313724728731
Epoch: 56 | Iteration number: [1050/4518] 23% | Training loss: 0.6874343874908629
Epoch: 56 | Iteration number: [1060/4518] 23% | Training loss: 0.6874064286924758
Epoch: 56 | Iteration number: [1070/4518] 23% | Training loss: 0.687387932516704
Epoch: 56 | Iteration number: [1080/4518] 23% | Training loss: 0.6873865728576978
Epoch: 56 | Iteration number: [1090/4518] 24% | Training loss: 0.6873851052118004
Epoch: 56 | Iteration number: [1100/4518] 24% | Training loss: 0.6873972205140374
Epoch: 56 | Iteration number: [1110/4518] 24% | Training loss: 0.6873986735537245
Epoch: 56 | Iteration number: [1120/4518] 24% | Training loss: 0.6873988907252039
Epoch: 56 | Iteration number: [1130/4518] 25% | Training loss: 0.6873880815189497
Epoch: 56 | Iteration number: [1140/4518] 25% | Training loss: 0.6873828154384044
Epoch: 56 | Iteration number: [1150/4518] 25% | Training loss: 0.687391491610071
Epoch: 56 | Iteration number: [1160/4518] 25% | Training loss: 0.6873915494515979
Epoch: 56 | Iteration number: [1170/4518] 25% | Training loss: 0.6873838030374967
Epoch: 56 | Iteration number: [1180/4518] 26% | Training loss: 0.6873894619234537
Epoch: 56 | Iteration number: [1190/4518] 26% | Training loss: 0.6873799804378958
Epoch: 56 | Iteration number: [1200/4518] 26% | Training loss: 0.6873789338767529
Epoch: 56 | Iteration number: [1210/4518] 26% | Training loss: 0.6873748168965017
Epoch: 56 | Iteration number: [1220/4518] 27% | Training loss: 0.6873759645419043
Epoch: 56 | Iteration number: [1230/4518] 27% | Training loss: 0.687375923385465
Epoch: 56 | Iteration number: [1240/4518] 27% | Training loss: 0.6873694420341523
Epoch: 56 | Iteration number: [1250/4518] 27% | Training loss: 0.687368468284607
Epoch: 56 | Iteration number: [1260/4518] 27% | Training loss: 0.6873720555551468
Epoch: 56 | Iteration number: [1270/4518] 28% | Training loss: 0.6873653166876065
Epoch: 56 | Iteration number: [1280/4518] 28% | Training loss: 0.6873567563015968
Epoch: 56 | Iteration number: [1290/4518] 28% | Training loss: 0.6873575221198474
Epoch: 56 | Iteration number: [1300/4518] 28% | Training loss: 0.6873467161563727
Epoch: 56 | Iteration number: [1310/4518] 28% | Training loss: 0.687341592330059
Epoch: 56 | Iteration number: [1320/4518] 29% | Training loss: 0.687346327259685
Epoch: 56 | Iteration number: [1330/4518] 29% | Training loss: 0.6873456602706048
Epoch: 56 | Iteration number: [1340/4518] 29% | Training loss: 0.6873311439556862
Epoch: 56 | Iteration number: [1350/4518] 29% | Training loss: 0.6873145039876302
Epoch: 56 | Iteration number: [1360/4518] 30% | Training loss: 0.6873043511720265
Epoch: 56 | Iteration number: [1370/4518] 30% | Training loss: 0.6872912315991673
Epoch: 56 | Iteration number: [1380/4518] 30% | Training loss: 0.6872848359570987
Epoch: 56 | Iteration number: [1390/4518] 30% | Training loss: 0.6872837189290163
Epoch: 56 | Iteration number: [1400/4518] 30% | Training loss: 0.6872764810919761
Epoch: 56 | Iteration number: [1410/4518] 31% | Training loss: 0.6872641832270521
Epoch: 56 | Iteration number: [1420/4518] 31% | Training loss: 0.6872624967719467
Epoch: 56 | Iteration number: [1430/4518] 31% | Training loss: 0.6872616920854662
Epoch: 56 | Iteration number: [1440/4518] 31% | Training loss: 0.6872581584586037
Epoch: 56 | Iteration number: [1450/4518] 32% | Training loss: 0.6872602458246823
Epoch: 56 | Iteration number: [1460/4518] 32% | Training loss: 0.6872562839152062
Epoch: 56 | Iteration number: [1470/4518] 32% | Training loss: 0.6872592379852217
Epoch: 56 | Iteration number: [1480/4518] 32% | Training loss: 0.6872601664952329
Epoch: 56 | Iteration number: [1490/4518] 32% | Training loss: 0.6872654878053089
Epoch: 56 | Iteration number: [1500/4518] 33% | Training loss: 0.6872692784468333
Epoch: 56 | Iteration number: [1510/4518] 33% | Training loss: 0.6872705313148878
Epoch: 56 | Iteration number: [1520/4518] 33% | Training loss: 0.6872719485116633
Epoch: 56 | Iteration number: [1530/4518] 33% | Training loss: 0.6872704674215878
Epoch: 56 | Iteration number: [1540/4518] 34% | Training loss: 0.687271708520976
Epoch: 56 | Iteration number: [1550/4518] 34% | Training loss: 0.6872754899917111
Epoch: 56 | Iteration number: [1560/4518] 34% | Training loss: 0.6872708761157134
Epoch: 56 | Iteration number: [1570/4518] 34% | Training loss: 0.6872582416625539
Epoch: 56 | Iteration number: [1580/4518] 34% | Training loss: 0.6872500333604933
Epoch: 56 | Iteration number: [1590/4518] 35% | Training loss: 0.6872484322988762
Epoch: 56 | Iteration number: [1600/4518] 35% | Training loss: 0.6872390557453036
Epoch: 56 | Iteration number: [1610/4518] 35% | Training loss: 0.6872373791214842
Epoch: 56 | Iteration number: [1620/4518] 35% | Training loss: 0.6872283418973287
Epoch: 56 | Iteration number: [1630/4518] 36% | Training loss: 0.6872309446700512
Epoch: 56 | Iteration number: [1640/4518] 36% | Training loss: 0.6872370255793013
Epoch: 56 | Iteration number: [1650/4518] 36% | Training loss: 0.6872352155410882
Epoch: 56 | Iteration number: [1660/4518] 36% | Training loss: 0.6872370009680828
Epoch: 56 | Iteration number: [1670/4518] 36% | Training loss: 0.687232210536203
Epoch: 56 | Iteration number: [1680/4518] 37% | Training loss: 0.6872234257204192
Epoch: 56 | Iteration number: [1690/4518] 37% | Training loss: 0.6872215307675875
Epoch: 56 | Iteration number: [1700/4518] 37% | Training loss: 0.687219144281219
Epoch: 56 | Iteration number: [1710/4518] 37% | Training loss: 0.687216287746764
Epoch: 56 | Iteration number: [1720/4518] 38% | Training loss: 0.6872146259213603
Epoch: 56 | Iteration number: [1730/4518] 38% | Training loss: 0.6872129657020458
Epoch: 56 | Iteration number: [1740/4518] 38% | Training loss: 0.687205058404769
Epoch: 56 | Iteration number: [1750/4518] 38% | Training loss: 0.687204683985029
Epoch: 56 | Iteration number: [1760/4518] 38% | Training loss: 0.6872055165469646
Epoch: 56 | Iteration number: [1770/4518] 39% | Training loss: 0.6872022431112279
Epoch: 56 | Iteration number: [1780/4518] 39% | Training loss: 0.6871972570593438
Epoch: 56 | Iteration number: [1790/4518] 39% | Training loss: 0.6871959926029824
Epoch: 56 | Iteration number: [1800/4518] 39% | Training loss: 0.6872033430470361
Epoch: 56 | Iteration number: [1810/4518] 40% | Training loss: 0.6872042739588912
Epoch: 56 | Iteration number: [1820/4518] 40% | Training loss: 0.6872059487707012
Epoch: 56 | Iteration number: [1830/4518] 40% | Training loss: 0.687208001307451
Epoch: 56 | Iteration number: [1840/4518] 40% | Training loss: 0.6872041040788526
Epoch: 56 | Iteration number: [1850/4518] 40% | Training loss: 0.6871978762665311
Epoch: 56 | Iteration number: [1860/4518] 41% | Training loss: 0.6871948780231578
Epoch: 56 | Iteration number: [1870/4518] 41% | Training loss: 0.6871877646382479
Epoch: 56 | Iteration number: [1880/4518] 41% | Training loss: 0.687189853952286
Epoch: 56 | Iteration number: [1890/4518] 41% | Training loss: 0.6871854336173446
Epoch: 56 | Iteration number: [1900/4518] 42% | Training loss: 0.6871850397084889
Epoch: 56 | Iteration number: [1910/4518] 42% | Training loss: 0.6871801617257882
Epoch: 56 | Iteration number: [1920/4518] 42% | Training loss: 0.6871693657090266
Epoch: 56 | Iteration number: [1930/4518] 42% | Training loss: 0.6871658575658354
Epoch: 56 | Iteration number: [1940/4518] 42% | Training loss: 0.6871680781091611
Epoch: 56 | Iteration number: [1950/4518] 43% | Training loss: 0.6871633481062376
Epoch: 56 | Iteration number: [1960/4518] 43% | Training loss: 0.6871587486899629
Epoch: 56 | Iteration number: [1970/4518] 43% | Training loss: 0.6871545082724034
Epoch: 56 | Iteration number: [1980/4518] 43% | Training loss: 0.6871502681814059
Epoch: 56 | Iteration number: [1990/4518] 44% | Training loss: 0.6871449316266793
Epoch: 56 | Iteration number: [2000/4518] 44% | Training loss: 0.6871482208967209
Epoch: 56 | Iteration number: [2010/4518] 44% | Training loss: 0.687146251533755
Epoch: 56 | Iteration number: [2020/4518] 44% | Training loss: 0.6871443732540207
Epoch: 56 | Iteration number: [2030/4518] 44% | Training loss: 0.6871410276795843
Epoch: 56 | Iteration number: [2040/4518] 45% | Training loss: 0.6871390918014096
Epoch: 56 | Iteration number: [2050/4518] 45% | Training loss: 0.6871425835679217
Epoch: 56 | Iteration number: [2060/4518] 45% | Training loss: 0.6871382070108525
Epoch: 56 | Iteration number: [2070/4518] 45% | Training loss: 0.6871404036807554
Epoch: 56 | Iteration number: [2080/4518] 46% | Training loss: 0.6871443787732949
Epoch: 56 | Iteration number: [2090/4518] 46% | Training loss: 0.6871396876122963
Epoch: 56 | Iteration number: [2100/4518] 46% | Training loss: 0.6871344457637696
Epoch: 56 | Iteration number: [2110/4518] 46% | Training loss: 0.6871328927894339
Epoch: 56 | Iteration number: [2120/4518] 46% | Training loss: 0.6871274911288945
Epoch: 56 | Iteration number: [2130/4518] 47% | Training loss: 0.6871267059879124
Epoch: 56 | Iteration number: [2140/4518] 47% | Training loss: 0.6871272576468013
Epoch: 56 | Iteration number: [2150/4518] 47% | Training loss: 0.6871292261467423
Epoch: 56 | Iteration number: [2160/4518] 47% | Training loss: 0.6871246666819961
Epoch: 56 | Iteration number: [2170/4518] 48% | Training loss: 0.6871215798063761
Epoch: 56 | Iteration number: [2180/4518] 48% | Training loss: 0.6871230714364883
Epoch: 56 | Iteration number: [2190/4518] 48% | Training loss: 0.6871167170947001
Epoch: 56 | Iteration number: [2200/4518] 48% | Training loss: 0.6871180989254605
Epoch: 56 | Iteration number: [2210/4518] 48% | Training loss: 0.6871169667168441
Epoch: 56 | Iteration number: [2220/4518] 49% | Training loss: 0.6871212238932515
Epoch: 56 | Iteration number: [2230/4518] 49% | Training loss: 0.6871213707688678
Epoch: 56 | Iteration number: [2240/4518] 49% | Training loss: 0.6871227442419955
Epoch: 56 | Iteration number: [2250/4518] 49% | Training loss: 0.6871196055412292
Epoch: 56 | Iteration number: [2260/4518] 50% | Training loss: 0.6871209559978637
Epoch: 56 | Iteration number: [2270/4518] 50% | Training loss: 0.687120408344899
Epoch: 56 | Iteration number: [2280/4518] 50% | Training loss: 0.6871139691325656
Epoch: 56 | Iteration number: [2290/4518] 50% | Training loss: 0.6871128737405918
Epoch: 56 | Iteration number: [2300/4518] 50% | Training loss: 0.6871176550958468
Epoch: 56 | Iteration number: [2310/4518] 51% | Training loss: 0.68711231505716
Epoch: 56 | Iteration number: [2320/4518] 51% | Training loss: 0.6871095056163854
Epoch: 56 | Iteration number: [2330/4518] 51% | Training loss: 0.6871111271974867
Epoch: 56 | Iteration number: [2340/4518] 51% | Training loss: 0.6871151042035503
Epoch: 56 | Iteration number: [2350/4518] 52% | Training loss: 0.6871122536760695
Epoch: 56 | Iteration number: [2360/4518] 52% | Training loss: 0.6871109434861248
Epoch: 56 | Iteration number: [2370/4518] 52% | Training loss: 0.6871057338603941
Epoch: 56 | Iteration number: [2380/4518] 52% | Training loss: 0.6871087621240055
Epoch: 56 | Iteration number: [2390/4518] 52% | Training loss: 0.687102242743121
Epoch: 56 | Iteration number: [2400/4518] 53% | Training loss: 0.687096210544308
Epoch: 56 | Iteration number: [2410/4518] 53% | Training loss: 0.6870930396174989
Epoch: 56 | Iteration number: [2420/4518] 53% | Training loss: 0.6870903797386106
Epoch: 56 | Iteration number: [2430/4518] 53% | Training loss: 0.6870915732511277
Epoch: 56 | Iteration number: [2440/4518] 54% | Training loss: 0.6870934454632587
Epoch: 56 | Iteration number: [2450/4518] 54% | Training loss: 0.6870966124777891
Epoch: 56 | Iteration number: [2460/4518] 54% | Training loss: 0.6870902696033804
Epoch: 56 | Iteration number: [2470/4518] 54% | Training loss: 0.6870870063662047
Epoch: 56 | Iteration number: [2480/4518] 54% | Training loss: 0.6870808073109196
Epoch: 56 | Iteration number: [2490/4518] 55% | Training loss: 0.6870784324814517
Epoch: 56 | Iteration number: [2500/4518] 55% | Training loss: 0.6870706328630447
Epoch: 56 | Iteration number: [2510/4518] 55% | Training loss: 0.6870677857759939
Epoch: 56 | Iteration number: [2520/4518] 55% | Training loss: 0.6870671879204493
Epoch: 56 | Iteration number: [2530/4518] 55% | Training loss: 0.6870692850101606
Epoch: 56 | Iteration number: [2540/4518] 56% | Training loss: 0.6870673775672913
Epoch: 56 | Iteration number: [2550/4518] 56% | Training loss: 0.6870649116880754
Epoch: 56 | Iteration number: [2560/4518] 56% | Training loss: 0.6870570892700926
Epoch: 56 | Iteration number: [2570/4518] 56% | Training loss: 0.6870554495646332
Epoch: 56 | Iteration number: [2580/4518] 57% | Training loss: 0.6870565360830736
Epoch: 56 | Iteration number: [2590/4518] 57% | Training loss: 0.6870608722841417
Epoch: 56 | Iteration number: [2600/4518] 57% | Training loss: 0.6870568736241414
Epoch: 56 | Iteration number: [2610/4518] 57% | Training loss: 0.6870553599463569
Epoch: 56 | Iteration number: [2620/4518] 57% | Training loss: 0.6870578788846504
Epoch: 56 | Iteration number: [2630/4518] 58% | Training loss: 0.6870547449634102
Epoch: 56 | Iteration number: [2640/4518] 58% | Training loss: 0.6870507550736268
Epoch: 56 | Iteration number: [2650/4518] 58% | Training loss: 0.6870515174235938
Epoch: 56 | Iteration number: [2660/4518] 58% | Training loss: 0.6870507033919929
Epoch: 56 | Iteration number: [2670/4518] 59% | Training loss: 0.6870526897103599
Epoch: 56 | Iteration number: [2680/4518] 59% | Training loss: 0.6870526894259809
Epoch: 56 | Iteration number: [2690/4518] 59% | Training loss: 0.6870542820279926
Epoch: 56 | Iteration number: [2700/4518] 59% | Training loss: 0.6870526026134137
Epoch: 56 | Iteration number: [2710/4518] 59% | Training loss: 0.6870514454216975
Epoch: 56 | Iteration number: [2720/4518] 60% | Training loss: 0.6870486791519558
Epoch: 56 | Iteration number: [2730/4518] 60% | Training loss: 0.687046252305691
Epoch: 56 | Iteration number: [2740/4518] 60% | Training loss: 0.6870435150217836
Epoch: 56 | Iteration number: [2750/4518] 60% | Training loss: 0.6870427356633273
Epoch: 56 | Iteration number: [2760/4518] 61% | Training loss: 0.6870459484449332
Epoch: 56 | Iteration number: [2770/4518] 61% | Training loss: 0.6870480264136938
Epoch: 56 | Iteration number: [2780/4518] 61% | Training loss: 0.6870482492789948
Epoch: 56 | Iteration number: [2790/4518] 61% | Training loss: 0.6870507548786833
Epoch: 56 | Iteration number: [2800/4518] 61% | Training loss: 0.6870503873697349
Epoch: 56 | Iteration number: [2810/4518] 62% | Training loss: 0.6870466243541962
Epoch: 56 | Iteration number: [2820/4518] 62% | Training loss: 0.6870435139600267
Epoch: 56 | Iteration number: [2830/4518] 62% | Training loss: 0.6870382170795131
Epoch: 56 | Iteration number: [2840/4518] 62% | Training loss: 0.6870375318846232
Epoch: 56 | Iteration number: [2850/4518] 63% | Training loss: 0.6870425889366552
Epoch: 56 | Iteration number: [2860/4518] 63% | Training loss: 0.68704327307381
Epoch: 56 | Iteration number: [2870/4518] 63% | Training loss: 0.687037033320304
Epoch: 56 | Iteration number: [2880/4518] 63% | Training loss: 0.6870378152777751
Epoch: 56 | Iteration number: [2890/4518] 63% | Training loss: 0.6870361174885377
Epoch: 56 | Iteration number: [2900/4518] 64% | Training loss: 0.6870355370126922
Epoch: 56 | Iteration number: [2910/4518] 64% | Training loss: 0.6870323047605167
Epoch: 56 | Iteration number: [2920/4518] 64% | Training loss: 0.6870261231513872
Epoch: 56 | Iteration number: [2930/4518] 64% | Training loss: 0.6870206586736868
Epoch: 56 | Iteration number: [2940/4518] 65% | Training loss: 0.6870200356455888
Epoch: 56 | Iteration number: [2950/4518] 65% | Training loss: 0.6870187093847889
Epoch: 56 | Iteration number: [2960/4518] 65% | Training loss: 0.6870157598240956
Epoch: 56 | Iteration number: [2970/4518] 65% | Training loss: 0.6870128798765767
Epoch: 56 | Iteration number: [2980/4518] 65% | Training loss: 0.6870111496656534
Epoch: 56 | Iteration number: [2990/4518] 66% | Training loss: 0.6870123191222698
Epoch: 56 | Iteration number: [3000/4518] 66% | Training loss: 0.6870106277664503
Epoch: 56 | Iteration number: [3010/4518] 66% | Training loss: 0.6870081025698652
Epoch: 56 | Iteration number: [3020/4518] 66% | Training loss: 0.6870099265251728
Epoch: 56 | Iteration number: [3030/4518] 67% | Training loss: 0.6870156542892897
Epoch: 56 | Iteration number: [3040/4518] 67% | Training loss: 0.6870154237276629
Epoch: 56 | Iteration number: [3050/4518] 67% | Training loss: 0.6870160535906182
Epoch: 56 | Iteration number: [3060/4518] 67% | Training loss: 0.687015222022736
Epoch: 56 | Iteration number: [3070/4518] 67% | Training loss: 0.6870142690327734
Epoch: 56 | Iteration number: [3080/4518] 68% | Training loss: 0.687011100913023
Epoch: 56 | Iteration number: [3090/4518] 68% | Training loss: 0.6870115853436171
Epoch: 56 | Iteration number: [3100/4518] 68% | Training loss: 0.6870138764381408
Epoch: 56 | Iteration number: [3110/4518] 68% | Training loss: 0.6870161697412227
Epoch: 56 | Iteration number: [3120/4518] 69% | Training loss: 0.6870161808836155
Epoch: 56 | Iteration number: [3130/4518] 69% | Training loss: 0.6870129442062621
Epoch: 56 | Iteration number: [3140/4518] 69% | Training loss: 0.6870138841260011
Epoch: 56 | Iteration number: [3150/4518] 69% | Training loss: 0.6870145755533188
Epoch: 56 | Iteration number: [3160/4518] 69% | Training loss: 0.6870139634684671
Epoch: 56 | Iteration number: [3170/4518] 70% | Training loss: 0.6870144257974173
Epoch: 56 | Iteration number: [3180/4518] 70% | Training loss: 0.6870161723415806
Epoch: 56 | Iteration number: [3190/4518] 70% | Training loss: 0.6870094944317139
Epoch: 56 | Iteration number: [3200/4518] 70% | Training loss: 0.6870127304643393
Epoch: 56 | Iteration number: [3210/4518] 71% | Training loss: 0.6870152446711175
Epoch: 56 | Iteration number: [3220/4518] 71% | Training loss: 0.6870148493266254
Epoch: 56 | Iteration number: [3230/4518] 71% | Training loss: 0.6870146981149265
Epoch: 56 | Iteration number: [3240/4518] 71% | Training loss: 0.6870147657247238
Epoch: 56 | Iteration number: [3250/4518] 71% | Training loss: 0.6870124511351953
Epoch: 56 | Iteration number: [3260/4518] 72% | Training loss: 0.6870150561713002
Epoch: 56 | Iteration number: [3270/4518] 72% | Training loss: 0.687014254481056
Epoch: 56 | Iteration number: [3280/4518] 72% | Training loss: 0.687010973037743
Epoch: 56 | Iteration number: [3290/4518] 72% | Training loss: 0.6870066323178879
Epoch: 56 | Iteration number: [3300/4518] 73% | Training loss: 0.6870065266255176
Epoch: 56 | Iteration number: [3310/4518] 73% | Training loss: 0.6870058667803819
Epoch: 56 | Iteration number: [3320/4518] 73% | Training loss: 0.687005748321493
Epoch: 56 | Iteration number: [3330/4518] 73% | Training loss: 0.6870026191254636
Epoch: 56 | Iteration number: [3340/4518] 73% | Training loss: 0.6869999923391971
Epoch: 56 | Iteration number: [3350/4518] 74% | Training loss: 0.6869980460494312
Epoch: 56 | Iteration number: [3360/4518] 74% | Training loss: 0.6869968471250364
Epoch: 56 | Iteration number: [3370/4518] 74% | Training loss: 0.6869959306469303
Epoch: 56 | Iteration number: [3380/4518] 74% | Training loss: 0.6869980400306939
Epoch: 56 | Iteration number: [3390/4518] 75% | Training loss: 0.6869940882762976
Epoch: 56 | Iteration number: [3400/4518] 75% | Training loss: 0.68699402064085
Epoch: 56 | Iteration number: [3410/4518] 75% | Training loss: 0.6869971279349845
Epoch: 56 | Iteration number: [3420/4518] 75% | Training loss: 0.6869948875834371
Epoch: 56 | Iteration number: [3430/4518] 75% | Training loss: 0.6869944015849089
Epoch: 56 | Iteration number: [3440/4518] 76% | Training loss: 0.6869908196808294
Epoch: 56 | Iteration number: [3450/4518] 76% | Training loss: 0.6869918891830721
Epoch: 56 | Iteration number: [3460/4518] 76% | Training loss: 0.6869889116700674
Epoch: 56 | Iteration number: [3470/4518] 76% | Training loss: 0.6869887063413944
Epoch: 56 | Iteration number: [3480/4518] 77% | Training loss: 0.6869910694744396
Epoch: 56 | Iteration number: [3490/4518] 77% | Training loss: 0.6869911922937136
Epoch: 56 | Iteration number: [3500/4518] 77% | Training loss: 0.6869901929071971
Epoch: 56 | Iteration number: [3510/4518] 77% | Training loss: 0.686991511382948
Epoch: 56 | Iteration number: [3520/4518] 77% | Training loss: 0.68698975244029
Epoch: 56 | Iteration number: [3530/4518] 78% | Training loss: 0.6869899114535821
Epoch: 56 | Iteration number: [3540/4518] 78% | Training loss: 0.6869856771607857
Epoch: 56 | Iteration number: [3550/4518] 78% | Training loss: 0.6869869769123239
Epoch: 56 | Iteration number: [3560/4518] 78% | Training loss: 0.6869893613658594
Epoch: 56 | Iteration number: [3570/4518] 79% | Training loss: 0.686989623942629
Epoch: 56 | Iteration number: [3580/4518] 79% | Training loss: 0.6869896029460364
Epoch: 56 | Iteration number: [3590/4518] 79% | Training loss: 0.6869847904008743
Epoch: 56 | Iteration number: [3600/4518] 79% | Training loss: 0.686978338625696
Epoch: 56 | Iteration number: [3610/4518] 79% | Training loss: 0.686978087795078
Epoch: 56 | Iteration number: [3620/4518] 80% | Training loss: 0.6869748148964255
Epoch: 56 | Iteration number: [3630/4518] 80% | Training loss: 0.686975970938186
Epoch: 56 | Iteration number: [3640/4518] 80% | Training loss: 0.686972189948454
Epoch: 56 | Iteration number: [3650/4518] 80% | Training loss: 0.686969578331464
Epoch: 56 | Iteration number: [3660/4518] 81% | Training loss: 0.6869689659831303
Epoch: 56 | Iteration number: [3670/4518] 81% | Training loss: 0.6869728738670453
Epoch: 56 | Iteration number: [3680/4518] 81% | Training loss: 0.6869739714362051
Epoch: 56 | Iteration number: [3690/4518] 81% | Training loss: 0.6869722740598487
Epoch: 56 | Iteration number: [3700/4518] 81% | Training loss: 0.6869707184707796
Epoch: 56 | Iteration number: [3710/4518] 82% | Training loss: 0.6869706533989817
Epoch: 56 | Iteration number: [3720/4518] 82% | Training loss: 0.6869698743345917
Epoch: 56 | Iteration number: [3730/4518] 82% | Training loss: 0.6869726556235919
Epoch: 56 | Iteration number: [3740/4518] 82% | Training loss: 0.6869784937026029
Epoch: 56 | Iteration number: [3750/4518] 83% | Training loss: 0.6869779627482097
Epoch: 56 | Iteration number: [3760/4518] 83% | Training loss: 0.6869776211520459
Epoch: 56 | Iteration number: [3770/4518] 83% | Training loss: 0.6869766095905152
Epoch: 56 | Iteration number: [3780/4518] 83% | Training loss: 0.6869729132879347
Epoch: 56 | Iteration number: [3790/4518] 83% | Training loss: 0.6869723519266123
Epoch: 56 | Iteration number: [3800/4518] 84% | Training loss: 0.6869712398240441
Epoch: 56 | Iteration number: [3810/4518] 84% | Training loss: 0.6869677044275239
Epoch: 56 | Iteration number: [3820/4518] 84% | Training loss: 0.6869672067502406
Epoch: 56 | Iteration number: [3830/4518] 84% | Training loss: 0.6869672170662693
Epoch: 56 | Iteration number: [3840/4518] 84% | Training loss: 0.6869666230864823
Epoch: 56 | Iteration number: [3850/4518] 85% | Training loss: 0.6869650495052337
Epoch: 56 | Iteration number: [3860/4518] 85% | Training loss: 0.6869616535506717
Epoch: 56 | Iteration number: [3870/4518] 85% | Training loss: 0.6869582521514991
Epoch: 56 | Iteration number: [3880/4518] 85% | Training loss: 0.6869575383583295
Epoch: 56 | Iteration number: [3890/4518] 86% | Training loss: 0.6869568952711198
Epoch: 56 | Iteration number: [3900/4518] 86% | Training loss: 0.6869548117655974
Epoch: 56 | Iteration number: [3910/4518] 86% | Training loss: 0.6869531725221277
Epoch: 56 | Iteration number: [3920/4518] 86% | Training loss: 0.6869554292942797
Epoch: 56 | Iteration number: [3930/4518] 86% | Training loss: 0.686956867719728
Epoch: 56 | Iteration number: [3940/4518] 87% | Training loss: 0.6869591181653405
Epoch: 56 | Iteration number: [3950/4518] 87% | Training loss: 0.6869580914853495
Epoch: 56 | Iteration number: [3960/4518] 87% | Training loss: 0.6869577475117915
Epoch: 56 | Iteration number: [3970/4518] 87% | Training loss: 0.6869587014994634
Epoch: 56 | Iteration number: [3980/4518] 88% | Training loss: 0.6869582953165524
Epoch: 56 | Iteration number: [3990/4518] 88% | Training loss: 0.6869593817040436
Epoch: 56 | Iteration number: [4000/4518] 88% | Training loss: 0.6869626942574978
Epoch: 56 | Iteration number: [4010/4518] 88% | Training loss: 0.6869604415875717
Epoch: 56 | Iteration number: [4020/4518] 88% | Training loss: 0.6869596126957319
Epoch: 56 | Iteration number: [4030/4518] 89% | Training loss: 0.6869595157449357
Epoch: 56 | Iteration number: [4040/4518] 89% | Training loss: 0.6869546547974691
Epoch: 56 | Iteration number: [4050/4518] 89% | Training loss: 0.6869535795994747
Epoch: 56 | Iteration number: [4060/4518] 89% | Training loss: 0.6869522079898807
Epoch: 56 | Iteration number: [4070/4518] 90% | Training loss: 0.686950773483998
Epoch: 56 | Iteration number: [4080/4518] 90% | Training loss: 0.6869516880634953
Epoch: 56 | Iteration number: [4090/4518] 90% | Training loss: 0.686951216100772
Epoch: 56 | Iteration number: [4100/4518] 90% | Training loss: 0.686952651506517
Epoch: 56 | Iteration number: [4110/4518] 90% | Training loss: 0.6869554976767287
Epoch: 56 | Iteration number: [4120/4518] 91% | Training loss: 0.6869556622308435
Epoch: 56 | Iteration number: [4130/4518] 91% | Training loss: 0.6869564454578603
Epoch: 56 | Iteration number: [4140/4518] 91% | Training loss: 0.6869576703235147
Epoch: 56 | Iteration number: [4150/4518] 91% | Training loss: 0.6869591028862689
Epoch: 56 | Iteration number: [4160/4518] 92% | Training loss: 0.6869593247914544
Epoch: 56 | Iteration number: [4170/4518] 92% | Training loss: 0.6869603025112793
Epoch: 56 | Iteration number: [4180/4518] 92% | Training loss: 0.6869597075801147
Epoch: 56 | Iteration number: [4190/4518] 92% | Training loss: 0.686962338734356
Epoch: 56 | Iteration number: [4200/4518] 92% | Training loss: 0.6869621156652769
Epoch: 56 | Iteration number: [4210/4518] 93% | Training loss: 0.6869625314539232
Epoch: 56 | Iteration number: [4220/4518] 93% | Training loss: 0.6869595784146639
Epoch: 56 | Iteration number: [4230/4518] 93% | Training loss: 0.6869610047932212
Epoch: 56 | Iteration number: [4240/4518] 93% | Training loss: 0.6869599006648334
Epoch: 56 | Iteration number: [4250/4518] 94% | Training loss: 0.6869568688588984
Epoch: 56 | Iteration number: [4260/4518] 94% | Training loss: 0.6869529270510158
Epoch: 56 | Iteration number: [4270/4518] 94% | Training loss: 0.6869501863346725
Epoch: 56 | Iteration number: [4280/4518] 94% | Training loss: 0.6869502105863294
Epoch: 56 | Iteration number: [4290/4518] 94% | Training loss: 0.6869495855761575
Epoch: 56 | Iteration number: [4300/4518] 95% | Training loss: 0.6869521858664446
Epoch: 56 | Iteration number: [4310/4518] 95% | Training loss: 0.6869500110154916
Epoch: 56 | Iteration number: [4320/4518] 95% | Training loss: 0.6869492290610516
Epoch: 56 | Iteration number: [4330/4518] 95% | Training loss: 0.6869469813606756
Epoch: 56 | Iteration number: [4340/4518] 96% | Training loss: 0.6869441524079318
Epoch: 56 | Iteration number: [4350/4518] 96% | Training loss: 0.6869447668256431
Epoch: 56 | Iteration number: [4360/4518] 96% | Training loss: 0.6869413376948156
Epoch: 56 | Iteration number: [4370/4518] 96% | Training loss: 0.6869441544436754
Epoch: 56 | Iteration number: [4380/4518] 96% | Training loss: 0.6869425539148453
Epoch: 56 | Iteration number: [4390/4518] 97% | Training loss: 0.6869426299200514
Epoch: 56 | Iteration number: [4400/4518] 97% | Training loss: 0.6869451607357372
Epoch: 56 | Iteration number: [4410/4518] 97% | Training loss: 0.6869456943741191
Epoch: 56 | Iteration number: [4420/4518] 97% | Training loss: 0.6869467484870108
Epoch: 56 | Iteration number: [4430/4518] 98% | Training loss: 0.6869470791138591
Epoch: 56 | Iteration number: [4440/4518] 98% | Training loss: 0.6869492040024148
Epoch: 56 | Iteration number: [4450/4518] 98% | Training loss: 0.6869496209299967
Epoch: 56 | Iteration number: [4460/4518] 98% | Training loss: 0.686952876510107
Epoch: 56 | Iteration number: [4470/4518] 98% | Training loss: 0.6869532655949561
Epoch: 56 | Iteration number: [4480/4518] 99% | Training loss: 0.6869526249489614
Epoch: 56 | Iteration number: [4490/4518] 99% | Training loss: 0.6869513869816583
Epoch: 56 | Iteration number: [4500/4518] 99% | Training loss: 0.6869497998820411
Epoch: 56 | Iteration number: [4510/4518] 99% | Training loss: 0.6869481954632736

 End of epoch: 56 | Train Loss: 0.6867949022503752 | Training Time: 632 

 End of epoch: 56 | Eval Loss: 0.6898166135865815 | Evaluating Time: 17 
Epoch: 57 | Iteration number: [10/4518] 0% | Training loss: 0.7539543628692627
Epoch: 57 | Iteration number: [20/4518] 0% | Training loss: 0.7204887121915817
Epoch: 57 | Iteration number: [30/4518] 0% | Training loss: 0.7093350013097127
Epoch: 57 | Iteration number: [40/4518] 0% | Training loss: 0.7038441151380539
Epoch: 57 | Iteration number: [50/4518] 1% | Training loss: 0.7003368127346039
Epoch: 57 | Iteration number: [60/4518] 1% | Training loss: 0.6984634866317113
Epoch: 57 | Iteration number: [70/4518] 1% | Training loss: 0.6966766834259033
Epoch: 57 | Iteration number: [80/4518] 1% | Training loss: 0.6953754983842373
Epoch: 57 | Iteration number: [90/4518] 1% | Training loss: 0.6943509777386984
Epoch: 57 | Iteration number: [100/4518] 2% | Training loss: 0.6935846710205078
Epoch: 57 | Iteration number: [110/4518] 2% | Training loss: 0.6930794509974393
Epoch: 57 | Iteration number: [120/4518] 2% | Training loss: 0.6924876401821772
Epoch: 57 | Iteration number: [130/4518] 2% | Training loss: 0.6920730884258564
Epoch: 57 | Iteration number: [140/4518] 3% | Training loss: 0.6917734550578254
Epoch: 57 | Iteration number: [150/4518] 3% | Training loss: 0.6914731160799662
Epoch: 57 | Iteration number: [160/4518] 3% | Training loss: 0.6912142112851143
Epoch: 57 | Iteration number: [170/4518] 3% | Training loss: 0.6909411539049709
Epoch: 57 | Iteration number: [180/4518] 3% | Training loss: 0.6907114071978463
Epoch: 57 | Iteration number: [190/4518] 4% | Training loss: 0.690441347109644
Epoch: 57 | Iteration number: [200/4518] 4% | Training loss: 0.690221312046051
Epoch: 57 | Iteration number: [210/4518] 4% | Training loss: 0.6901209658100491
Epoch: 57 | Iteration number: [220/4518] 4% | Training loss: 0.6899452894926071
Epoch: 57 | Iteration number: [230/4518] 5% | Training loss: 0.6897945785004159
Epoch: 57 | Iteration number: [240/4518] 5% | Training loss: 0.689638884117206
Epoch: 57 | Iteration number: [250/4518] 5% | Training loss: 0.6895271458625793
Epoch: 57 | Iteration number: [260/4518] 5% | Training loss: 0.6893747955560684
Epoch: 57 | Iteration number: [270/4518] 5% | Training loss: 0.6892789681752522
Epoch: 57 | Iteration number: [280/4518] 6% | Training loss: 0.689214628296239
Epoch: 57 | Iteration number: [290/4518] 6% | Training loss: 0.6891250285609015
Epoch: 57 | Iteration number: [300/4518] 6% | Training loss: 0.6890179248650868
Epoch: 57 | Iteration number: [310/4518] 6% | Training loss: 0.6889496326446534
Epoch: 57 | Iteration number: [320/4518] 7% | Training loss: 0.6888732312247157
Epoch: 57 | Iteration number: [330/4518] 7% | Training loss: 0.6888371335737633
Epoch: 57 | Iteration number: [340/4518] 7% | Training loss: 0.6887976278277005
Epoch: 57 | Iteration number: [350/4518] 7% | Training loss: 0.6887079748085567
Epoch: 57 | Iteration number: [360/4518] 7% | Training loss: 0.6886496335268021
Epoch: 57 | Iteration number: [370/4518] 8% | Training loss: 0.6885794683082683
Epoch: 57 | Iteration number: [380/4518] 8% | Training loss: 0.6885358515538668
Epoch: 57 | Iteration number: [390/4518] 8% | Training loss: 0.6884835866781381
Epoch: 57 | Iteration number: [400/4518] 8% | Training loss: 0.6884436623752117
Epoch: 57 | Iteration number: [410/4518] 9% | Training loss: 0.6883782831633963
Epoch: 57 | Iteration number: [420/4518] 9% | Training loss: 0.6883415239197868
Epoch: 57 | Iteration number: [430/4518] 9% | Training loss: 0.6882996733798538
Epoch: 57 | Iteration number: [440/4518] 9% | Training loss: 0.6882855786518617
Epoch: 57 | Iteration number: [450/4518] 9% | Training loss: 0.6882666420936584
Epoch: 57 | Iteration number: [460/4518] 10% | Training loss: 0.6882572815470074
Epoch: 57 | Iteration number: [470/4518] 10% | Training loss: 0.6882571098652291
Epoch: 57 | Iteration number: [480/4518] 10% | Training loss: 0.6882360067218543
Epoch: 57 | Iteration number: [490/4518] 10% | Training loss: 0.6882184264611225
Epoch: 57 | Iteration number: [500/4518] 11% | Training loss: 0.6881894402503967
Epoch: 57 | Iteration number: [510/4518] 11% | Training loss: 0.6881773367816326
Epoch: 57 | Iteration number: [520/4518] 11% | Training loss: 0.6881628970687206
Epoch: 57 | Iteration number: [530/4518] 11% | Training loss: 0.6881409462892785
Epoch: 57 | Iteration number: [540/4518] 11% | Training loss: 0.6881224145491918
Epoch: 57 | Iteration number: [550/4518] 12% | Training loss: 0.6880842459201812
Epoch: 57 | Iteration number: [560/4518] 12% | Training loss: 0.6880698545702866
Epoch: 57 | Iteration number: [570/4518] 12% | Training loss: 0.6880597963667753
Epoch: 57 | Iteration number: [580/4518] 12% | Training loss: 0.6880279009712154
Epoch: 57 | Iteration number: [590/4518] 13% | Training loss: 0.688014844413531
Epoch: 57 | Iteration number: [600/4518] 13% | Training loss: 0.6879999455809593
Epoch: 57 | Iteration number: [610/4518] 13% | Training loss: 0.6879458818279329
Epoch: 57 | Iteration number: [620/4518] 13% | Training loss: 0.6879170847515906
Epoch: 57 | Iteration number: [630/4518] 13% | Training loss: 0.6879081905834259
Epoch: 57 | Iteration number: [640/4518] 14% | Training loss: 0.6879049269482493
Epoch: 57 | Iteration number: [650/4518] 14% | Training loss: 0.6878855387064127
Epoch: 57 | Iteration number: [660/4518] 14% | Training loss: 0.6878724866744244
Epoch: 57 | Iteration number: [670/4518] 14% | Training loss: 0.6878568703558907
Epoch: 57 | Iteration number: [680/4518] 15% | Training loss: 0.6878373279291041
Epoch: 57 | Iteration number: [690/4518] 15% | Training loss: 0.6878201422484025
Epoch: 57 | Iteration number: [700/4518] 15% | Training loss: 0.6878078655685698
Epoch: 57 | Iteration number: [710/4518] 15% | Training loss: 0.687784173119236
Epoch: 57 | Iteration number: [720/4518] 15% | Training loss: 0.6877671293086476
Epoch: 57 | Iteration number: [730/4518] 16% | Training loss: 0.6877218389347808
Epoch: 57 | Iteration number: [740/4518] 16% | Training loss: 0.6877194878217336
Epoch: 57 | Iteration number: [750/4518] 16% | Training loss: 0.687712916135788
Epoch: 57 | Iteration number: [760/4518] 16% | Training loss: 0.6876991455492221
Epoch: 57 | Iteration number: [770/4518] 17% | Training loss: 0.6877052379118932
Epoch: 57 | Iteration number: [780/4518] 17% | Training loss: 0.6877059808144202
Epoch: 57 | Iteration number: [790/4518] 17% | Training loss: 0.687687109014656
Epoch: 57 | Iteration number: [800/4518] 17% | Training loss: 0.6876878782361746
Epoch: 57 | Iteration number: [810/4518] 17% | Training loss: 0.6876752213195518
Epoch: 57 | Iteration number: [820/4518] 18% | Training loss: 0.687663867851583
Epoch: 57 | Iteration number: [830/4518] 18% | Training loss: 0.687639670415097
Epoch: 57 | Iteration number: [840/4518] 18% | Training loss: 0.6876251012796447
Epoch: 57 | Iteration number: [850/4518] 18% | Training loss: 0.6875979584104874
Epoch: 57 | Iteration number: [860/4518] 19% | Training loss: 0.6875828663277072
Epoch: 57 | Iteration number: [870/4518] 19% | Training loss: 0.6875630066312592
Epoch: 57 | Iteration number: [880/4518] 19% | Training loss: 0.6875693473626266
Epoch: 57 | Iteration number: [890/4518] 19% | Training loss: 0.6875564562470725
Epoch: 57 | Iteration number: [900/4518] 19% | Training loss: 0.6875481937991248
Epoch: 57 | Iteration number: [910/4518] 20% | Training loss: 0.687555906340316
Epoch: 57 | Iteration number: [920/4518] 20% | Training loss: 0.6875478802815728
Epoch: 57 | Iteration number: [930/4518] 20% | Training loss: 0.6875425610491025
Epoch: 57 | Iteration number: [940/4518] 20% | Training loss: 0.6875199818864782
Epoch: 57 | Iteration number: [950/4518] 21% | Training loss: 0.6875028656658373
Epoch: 57 | Iteration number: [960/4518] 21% | Training loss: 0.6874913409973185
Epoch: 57 | Iteration number: [970/4518] 21% | Training loss: 0.6874735810707525
Epoch: 57 | Iteration number: [980/4518] 21% | Training loss: 0.687468724165644
Epoch: 57 | Iteration number: [990/4518] 21% | Training loss: 0.6874598349585678
Epoch: 57 | Iteration number: [1000/4518] 22% | Training loss: 0.6874410265088081
Epoch: 57 | Iteration number: [1010/4518] 22% | Training loss: 0.6874329813046031
Epoch: 57 | Iteration number: [1020/4518] 22% | Training loss: 0.6874215029618319
Epoch: 57 | Iteration number: [1030/4518] 22% | Training loss: 0.6874200785044328
Epoch: 57 | Iteration number: [1040/4518] 23% | Training loss: 0.6874146597316632
Epoch: 57 | Iteration number: [1050/4518] 23% | Training loss: 0.6874017418566204
Epoch: 57 | Iteration number: [1060/4518] 23% | Training loss: 0.6873922219816244
Epoch: 57 | Iteration number: [1070/4518] 23% | Training loss: 0.6873775180255142
Epoch: 57 | Iteration number: [1080/4518] 23% | Training loss: 0.6873759928124922
Epoch: 57 | Iteration number: [1090/4518] 24% | Training loss: 0.6873616664234651
Epoch: 57 | Iteration number: [1100/4518] 24% | Training loss: 0.6873548768867146
Epoch: 57 | Iteration number: [1110/4518] 24% | Training loss: 0.6873514270997262
Epoch: 57 | Iteration number: [1120/4518] 24% | Training loss: 0.6873514963047845
Epoch: 57 | Iteration number: [1130/4518] 25% | Training loss: 0.6873512607232659
Epoch: 57 | Iteration number: [1140/4518] 25% | Training loss: 0.6873478186757941
Epoch: 57 | Iteration number: [1150/4518] 25% | Training loss: 0.6873387767439303
Epoch: 57 | Iteration number: [1160/4518] 25% | Training loss: 0.6873371170512561
Epoch: 57 | Iteration number: [1170/4518] 25% | Training loss: 0.6873353496066525
Epoch: 57 | Iteration number: [1180/4518] 26% | Training loss: 0.6873317792759104
Epoch: 57 | Iteration number: [1190/4518] 26% | Training loss: 0.6873113871121607
Epoch: 57 | Iteration number: [1200/4518] 26% | Training loss: 0.6873045794169108
Epoch: 57 | Iteration number: [1210/4518] 26% | Training loss: 0.6873089359318915
Epoch: 57 | Iteration number: [1220/4518] 27% | Training loss: 0.6873136840394286
Epoch: 57 | Iteration number: [1230/4518] 27% | Training loss: 0.6873103108832507
Epoch: 57 | Iteration number: [1240/4518] 27% | Training loss: 0.6873028029357233
Epoch: 57 | Iteration number: [1250/4518] 27% | Training loss: 0.6872978444576263
Epoch: 57 | Iteration number: [1260/4518] 27% | Training loss: 0.6873043780288999
Epoch: 57 | Iteration number: [1270/4518] 28% | Training loss: 0.6873042354902883
Epoch: 57 | Iteration number: [1280/4518] 28% | Training loss: 0.6872949532233179
Epoch: 57 | Iteration number: [1290/4518] 28% | Training loss: 0.6872837320778721
Epoch: 57 | Iteration number: [1300/4518] 28% | Training loss: 0.6872874012818704
Epoch: 57 | Iteration number: [1310/4518] 28% | Training loss: 0.6872786329902766
Epoch: 57 | Iteration number: [1320/4518] 29% | Training loss: 0.6872703265060078
Epoch: 57 | Iteration number: [1330/4518] 29% | Training loss: 0.6872726018267467
Epoch: 57 | Iteration number: [1340/4518] 29% | Training loss: 0.6872705218952093
Epoch: 57 | Iteration number: [1350/4518] 29% | Training loss: 0.6872704083389706
Epoch: 57 | Iteration number: [1360/4518] 30% | Training loss: 0.6872737975243259
Epoch: 57 | Iteration number: [1370/4518] 30% | Training loss: 0.6872851720256526
Epoch: 57 | Iteration number: [1380/4518] 30% | Training loss: 0.6872847106577693
Epoch: 57 | Iteration number: [1390/4518] 30% | Training loss: 0.687281648846839
Epoch: 57 | Iteration number: [1400/4518] 30% | Training loss: 0.6872822127171925
Epoch: 57 | Iteration number: [1410/4518] 31% | Training loss: 0.6872818233696282
Epoch: 57 | Iteration number: [1420/4518] 31% | Training loss: 0.6872801303863525
Epoch: 57 | Iteration number: [1430/4518] 31% | Training loss: 0.6872733608409242
Epoch: 57 | Iteration number: [1440/4518] 31% | Training loss: 0.6872728493478563
Epoch: 57 | Iteration number: [1450/4518] 32% | Training loss: 0.6872676759341667
Epoch: 57 | Iteration number: [1460/4518] 32% | Training loss: 0.687263572216034
Epoch: 57 | Iteration number: [1470/4518] 32% | Training loss: 0.6872681063048693
Epoch: 57 | Iteration number: [1480/4518] 32% | Training loss: 0.687269485923084
Epoch: 57 | Iteration number: [1490/4518] 32% | Training loss: 0.6872715466374519
Epoch: 57 | Iteration number: [1500/4518] 33% | Training loss: 0.6872605230808259
Epoch: 57 | Iteration number: [1510/4518] 33% | Training loss: 0.6872585405182364
Epoch: 57 | Iteration number: [1520/4518] 33% | Training loss: 0.6872418743607245
Epoch: 57 | Iteration number: [1530/4518] 33% | Training loss: 0.6872328544364256
Epoch: 57 | Iteration number: [1540/4518] 34% | Training loss: 0.6872284842001928
Epoch: 57 | Iteration number: [1550/4518] 34% | Training loss: 0.6872216331189679
Epoch: 57 | Iteration number: [1560/4518] 34% | Training loss: 0.687228127167775
Epoch: 57 | Iteration number: [1570/4518] 34% | Training loss: 0.6872267059459808
Epoch: 57 | Iteration number: [1580/4518] 34% | Training loss: 0.6872292629525631
Epoch: 57 | Iteration number: [1590/4518] 35% | Training loss: 0.687228739036704
Epoch: 57 | Iteration number: [1600/4518] 35% | Training loss: 0.6872207751125097
Epoch: 57 | Iteration number: [1610/4518] 35% | Training loss: 0.6872261868130346
Epoch: 57 | Iteration number: [1620/4518] 35% | Training loss: 0.68722072225294
Epoch: 57 | Iteration number: [1630/4518] 36% | Training loss: 0.6872282752961468
Epoch: 57 | Iteration number: [1640/4518] 36% | Training loss: 0.6872223853701498
Epoch: 57 | Iteration number: [1650/4518] 36% | Training loss: 0.6872179353237152
Epoch: 57 | Iteration number: [1660/4518] 36% | Training loss: 0.6872148070349751
Epoch: 57 | Iteration number: [1670/4518] 36% | Training loss: 0.6872148139391117
Epoch: 57 | Iteration number: [1680/4518] 37% | Training loss: 0.6872124301535742
Epoch: 57 | Iteration number: [1690/4518] 37% | Training loss: 0.6872124470549927
Epoch: 57 | Iteration number: [1700/4518] 37% | Training loss: 0.6872148692958495
Epoch: 57 | Iteration number: [1710/4518] 37% | Training loss: 0.6872083298992693
Epoch: 57 | Iteration number: [1720/4518] 38% | Training loss: 0.6872185671052268
Epoch: 57 | Iteration number: [1730/4518] 38% | Training loss: 0.6872124457634943
Epoch: 57 | Iteration number: [1740/4518] 38% | Training loss: 0.6872110498362574
Epoch: 57 | Iteration number: [1750/4518] 38% | Training loss: 0.6872092925821032
Epoch: 57 | Iteration number: [1760/4518] 38% | Training loss: 0.6872099804268642
Epoch: 57 | Iteration number: [1770/4518] 39% | Training loss: 0.6872090672032308
Epoch: 57 | Iteration number: [1780/4518] 39% | Training loss: 0.6872069894597771
Epoch: 57 | Iteration number: [1790/4518] 39% | Training loss: 0.6872047953765485
Epoch: 57 | Iteration number: [1800/4518] 39% | Training loss: 0.6872008846534623
Epoch: 57 | Iteration number: [1810/4518] 40% | Training loss: 0.6872007797106854
Epoch: 57 | Iteration number: [1820/4518] 40% | Training loss: 0.6872007177753763
Epoch: 57 | Iteration number: [1830/4518] 40% | Training loss: 0.6871999772845722
Epoch: 57 | Iteration number: [1840/4518] 40% | Training loss: 0.6872003457144551
Epoch: 57 | Iteration number: [1850/4518] 40% | Training loss: 0.6871872320690671
Epoch: 57 | Iteration number: [1860/4518] 41% | Training loss: 0.6871785792932715
Epoch: 57 | Iteration number: [1870/4518] 41% | Training loss: 0.6871669945551112
Epoch: 57 | Iteration number: [1880/4518] 41% | Training loss: 0.6871665603936987
Epoch: 57 | Iteration number: [1890/4518] 41% | Training loss: 0.6871679658296878
Epoch: 57 | Iteration number: [1900/4518] 42% | Training loss: 0.6871610951109937
Epoch: 57 | Iteration number: [1910/4518] 42% | Training loss: 0.6871588152428572
Epoch: 57 | Iteration number: [1920/4518] 42% | Training loss: 0.6871589348651469
Epoch: 57 | Iteration number: [1930/4518] 42% | Training loss: 0.68715658042715
Epoch: 57 | Iteration number: [1940/4518] 42% | Training loss: 0.687152229019047
Epoch: 57 | Iteration number: [1950/4518] 43% | Training loss: 0.6871439188871629
Epoch: 57 | Iteration number: [1960/4518] 43% | Training loss: 0.6871520155850722
Epoch: 57 | Iteration number: [1970/4518] 43% | Training loss: 0.6871472669736988
Epoch: 57 | Iteration number: [1980/4518] 43% | Training loss: 0.687142874857392
Epoch: 57 | Iteration number: [1990/4518] 44% | Training loss: 0.6871435188767898
Epoch: 57 | Iteration number: [2000/4518] 44% | Training loss: 0.687142762541771
Epoch: 57 | Iteration number: [2010/4518] 44% | Training loss: 0.6871407133429798
Epoch: 57 | Iteration number: [2020/4518] 44% | Training loss: 0.6871415296403488
Epoch: 57 | Iteration number: [2030/4518] 44% | Training loss: 0.6871382737688243
Epoch: 57 | Iteration number: [2040/4518] 45% | Training loss: 0.6871329908277474
Epoch: 57 | Iteration number: [2050/4518] 45% | Training loss: 0.687135642534349
Epoch: 57 | Iteration number: [2060/4518] 45% | Training loss: 0.6871357686889982
Epoch: 57 | Iteration number: [2070/4518] 45% | Training loss: 0.6871392558162339
Epoch: 57 | Iteration number: [2080/4518] 46% | Training loss: 0.6871394880975669
Epoch: 57 | Iteration number: [2090/4518] 46% | Training loss: 0.687129571705914
Epoch: 57 | Iteration number: [2100/4518] 46% | Training loss: 0.6871232045832134
Epoch: 57 | Iteration number: [2110/4518] 46% | Training loss: 0.687121361917794
Epoch: 57 | Iteration number: [2120/4518] 46% | Training loss: 0.6871176455099628
Epoch: 57 | Iteration number: [2130/4518] 47% | Training loss: 0.6871174979937469
Epoch: 57 | Iteration number: [2140/4518] 47% | Training loss: 0.68712177209765
Epoch: 57 | Iteration number: [2150/4518] 47% | Training loss: 0.6871175858031872
Epoch: 57 | Iteration number: [2160/4518] 47% | Training loss: 0.6871128337526763
Epoch: 57 | Iteration number: [2170/4518] 48% | Training loss: 0.6871105985707402
Epoch: 57 | Iteration number: [2180/4518] 48% | Training loss: 0.6871191863619953
Epoch: 57 | Iteration number: [2190/4518] 48% | Training loss: 0.6871215995588259
Epoch: 57 | Iteration number: [2200/4518] 48% | Training loss: 0.687127977149053
Epoch: 57 | Iteration number: [2210/4518] 48% | Training loss: 0.6871232402810145
Epoch: 57 | Iteration number: [2220/4518] 49% | Training loss: 0.6871241658926011
Epoch: 57 | Iteration number: [2230/4518] 49% | Training loss: 0.6871262972932225
Epoch: 57 | Iteration number: [2240/4518] 49% | Training loss: 0.6871258547263486
Epoch: 57 | Iteration number: [2250/4518] 49% | Training loss: 0.6871247640450795
Epoch: 57 | Iteration number: [2260/4518] 50% | Training loss: 0.6871227414207121
Epoch: 57 | Iteration number: [2270/4518] 50% | Training loss: 0.687125781611724
Epoch: 57 | Iteration number: [2280/4518] 50% | Training loss: 0.6871263823488303
Epoch: 57 | Iteration number: [2290/4518] 50% | Training loss: 0.6871182249883376
Epoch: 57 | Iteration number: [2300/4518] 50% | Training loss: 0.6871133258550064
Epoch: 57 | Iteration number: [2310/4518] 51% | Training loss: 0.687109521508733
Epoch: 57 | Iteration number: [2320/4518] 51% | Training loss: 0.6871099417065752
Epoch: 57 | Iteration number: [2330/4518] 51% | Training loss: 0.6870989103685633
Epoch: 57 | Iteration number: [2340/4518] 51% | Training loss: 0.6870952194572514
Epoch: 57 | Iteration number: [2350/4518] 52% | Training loss: 0.6870971904156056
Epoch: 57 | Iteration number: [2360/4518] 52% | Training loss: 0.6870963182742312
Epoch: 57 | Iteration number: [2370/4518] 52% | Training loss: 0.6870936112313331
Epoch: 57 | Iteration number: [2380/4518] 52% | Training loss: 0.6870916123650656
Epoch: 57 | Iteration number: [2390/4518] 52% | Training loss: 0.6870902181918651
Epoch: 57 | Iteration number: [2400/4518] 53% | Training loss: 0.6870867748310169
Epoch: 57 | Iteration number: [2410/4518] 53% | Training loss: 0.6870803605718732
Epoch: 57 | Iteration number: [2420/4518] 53% | Training loss: 0.6870754311892612
Epoch: 57 | Iteration number: [2430/4518] 53% | Training loss: 0.6870754873801651
Epoch: 57 | Iteration number: [2440/4518] 54% | Training loss: 0.6870720082619152
Epoch: 57 | Iteration number: [2450/4518] 54% | Training loss: 0.6870760451774208
Epoch: 57 | Iteration number: [2460/4518] 54% | Training loss: 0.6870799805090679
Epoch: 57 | Iteration number: [2470/4518] 54% | Training loss: 0.6870829918847876
Epoch: 57 | Iteration number: [2480/4518] 54% | Training loss: 0.6870842256372974
Epoch: 57 | Iteration number: [2490/4518] 55% | Training loss: 0.6870789916879202
Epoch: 57 | Iteration number: [2500/4518] 55% | Training loss: 0.6870748792886734
Epoch: 57 | Iteration number: [2510/4518] 55% | Training loss: 0.6870753038689434
Epoch: 57 | Iteration number: [2520/4518] 55% | Training loss: 0.6870720918925982
Epoch: 57 | Iteration number: [2530/4518] 55% | Training loss: 0.6870759566546428
Epoch: 57 | Iteration number: [2540/4518] 56% | Training loss: 0.6870762469730978
Epoch: 57 | Iteration number: [2550/4518] 56% | Training loss: 0.6870712281208412
Epoch: 57 | Iteration number: [2560/4518] 56% | Training loss: 0.6870678742649033
Epoch: 57 | Iteration number: [2570/4518] 56% | Training loss: 0.6870659836767249
Epoch: 57 | Iteration number: [2580/4518] 57% | Training loss: 0.6870680464099544
Epoch: 57 | Iteration number: [2590/4518] 57% | Training loss: 0.6870670656670015
Epoch: 57 | Iteration number: [2600/4518] 57% | Training loss: 0.68706306379575
Epoch: 57 | Iteration number: [2610/4518] 57% | Training loss: 0.6870650060560511
Epoch: 57 | Iteration number: [2620/4518] 57% | Training loss: 0.6870643272199703
Epoch: 57 | Iteration number: [2630/4518] 58% | Training loss: 0.6870620562776413
Epoch: 57 | Iteration number: [2640/4518] 58% | Training loss: 0.6870608252783617
Epoch: 57 | Iteration number: [2650/4518] 58% | Training loss: 0.6870589318140498
Epoch: 57 | Iteration number: [2660/4518] 58% | Training loss: 0.6870561895962048
Epoch: 57 | Iteration number: [2670/4518] 59% | Training loss: 0.6870553727900044
Epoch: 57 | Iteration number: [2680/4518] 59% | Training loss: 0.6870522789990724
Epoch: 57 | Iteration number: [2690/4518] 59% | Training loss: 0.6870500177034214
Epoch: 57 | Iteration number: [2700/4518] 59% | Training loss: 0.687048028199761
Epoch: 57 | Iteration number: [2710/4518] 59% | Training loss: 0.6870466496231811
Epoch: 57 | Iteration number: [2720/4518] 60% | Training loss: 0.6870411771404392
Epoch: 57 | Iteration number: [2730/4518] 60% | Training loss: 0.6870429432654119
Epoch: 57 | Iteration number: [2740/4518] 60% | Training loss: 0.6870435357963952
Epoch: 57 | Iteration number: [2750/4518] 60% | Training loss: 0.6870428349321539
Epoch: 57 | Iteration number: [2760/4518] 61% | Training loss: 0.6870441181504208
Epoch: 57 | Iteration number: [2770/4518] 61% | Training loss: 0.6870457888295074
Epoch: 57 | Iteration number: [2780/4518] 61% | Training loss: 0.6870477523306291
Epoch: 57 | Iteration number: [2790/4518] 61% | Training loss: 0.6870515723168636
Epoch: 57 | Iteration number: [2800/4518] 61% | Training loss: 0.6870526770183019
Epoch: 57 | Iteration number: [2810/4518] 62% | Training loss: 0.687048721674074
Epoch: 57 | Iteration number: [2820/4518] 62% | Training loss: 0.6870503292227468
Epoch: 57 | Iteration number: [2830/4518] 62% | Training loss: 0.6870501833753957
Epoch: 57 | Iteration number: [2840/4518] 62% | Training loss: 0.6870466764963848
Epoch: 57 | Iteration number: [2850/4518] 63% | Training loss: 0.6870426195755339
Epoch: 57 | Iteration number: [2860/4518] 63% | Training loss: 0.6870409368218242
Epoch: 57 | Iteration number: [2870/4518] 63% | Training loss: 0.6870382406154991
Epoch: 57 | Iteration number: [2880/4518] 63% | Training loss: 0.6870367270583908
Epoch: 57 | Iteration number: [2890/4518] 63% | Training loss: 0.6870359939068659
Epoch: 57 | Iteration number: [2900/4518] 64% | Training loss: 0.6870321537091815
Epoch: 57 | Iteration number: [2910/4518] 64% | Training loss: 0.6870303295936782
Epoch: 57 | Iteration number: [2920/4518] 64% | Training loss: 0.6870294399049184
Epoch: 57 | Iteration number: [2930/4518] 64% | Training loss: 0.6870281484957034
Epoch: 57 | Iteration number: [2940/4518] 65% | Training loss: 0.6870271272805273
Epoch: 57 | Iteration number: [2950/4518] 65% | Training loss: 0.6870234179900865
Epoch: 57 | Iteration number: [2960/4518] 65% | Training loss: 0.6870264632476343
Epoch: 57 | Iteration number: [2970/4518] 65% | Training loss: 0.6870244332234867
Epoch: 57 | Iteration number: [2980/4518] 65% | Training loss: 0.6870265924290523
Epoch: 57 | Iteration number: [2990/4518] 66% | Training loss: 0.6870266417396507
Epoch: 57 | Iteration number: [3000/4518] 66% | Training loss: 0.6870258098045985
Epoch: 57 | Iteration number: [3010/4518] 66% | Training loss: 0.687026855280233
Epoch: 57 | Iteration number: [3020/4518] 66% | Training loss: 0.6870238831303767
Epoch: 57 | Iteration number: [3030/4518] 67% | Training loss: 0.6870229078794864
Epoch: 57 | Iteration number: [3040/4518] 67% | Training loss: 0.6870213468608103
Epoch: 57 | Iteration number: [3050/4518] 67% | Training loss: 0.687025172143686
Epoch: 57 | Iteration number: [3060/4518] 67% | Training loss: 0.6870273132924161
Epoch: 57 | Iteration number: [3070/4518] 67% | Training loss: 0.6870235967907921
Epoch: 57 | Iteration number: [3080/4518] 68% | Training loss: 0.6870241909638628
Epoch: 57 | Iteration number: [3090/4518] 68% | Training loss: 0.6870229352446435
Epoch: 57 | Iteration number: [3100/4518] 68% | Training loss: 0.6870246328461554
Epoch: 57 | Iteration number: [3110/4518] 68% | Training loss: 0.6870221191663834
Epoch: 57 | Iteration number: [3120/4518] 69% | Training loss: 0.6870205494455802
Epoch: 57 | Iteration number: [3130/4518] 69% | Training loss: 0.6870191103924578
Epoch: 57 | Iteration number: [3140/4518] 69% | Training loss: 0.687017018646951
Epoch: 57 | Iteration number: [3150/4518] 69% | Training loss: 0.6870124154053037
Epoch: 57 | Iteration number: [3160/4518] 69% | Training loss: 0.6870099223490003
Epoch: 57 | Iteration number: [3170/4518] 70% | Training loss: 0.6870107628381591
Epoch: 57 | Iteration number: [3180/4518] 70% | Training loss: 0.6870100044416931
Epoch: 57 | Iteration number: [3190/4518] 70% | Training loss: 0.6870159233812254
Epoch: 57 | Iteration number: [3200/4518] 70% | Training loss: 0.6870177056640386
Epoch: 57 | Iteration number: [3210/4518] 71% | Training loss: 0.6870211997321833
Epoch: 57 | Iteration number: [3220/4518] 71% | Training loss: 0.687019693925514
Epoch: 57 | Iteration number: [3230/4518] 71% | Training loss: 0.6870198457233677
Epoch: 57 | Iteration number: [3240/4518] 71% | Training loss: 0.687020106576843
Epoch: 57 | Iteration number: [3250/4518] 71% | Training loss: 0.6870201439123887
Epoch: 57 | Iteration number: [3260/4518] 72% | Training loss: 0.687019473131449
Epoch: 57 | Iteration number: [3270/4518] 72% | Training loss: 0.6870188744972241
Epoch: 57 | Iteration number: [3280/4518] 72% | Training loss: 0.6870207441107529
Epoch: 57 | Iteration number: [3290/4518] 72% | Training loss: 0.6870223965507148
Epoch: 57 | Iteration number: [3300/4518] 73% | Training loss: 0.6870237104639862
Epoch: 57 | Iteration number: [3310/4518] 73% | Training loss: 0.6870233405032546
Epoch: 57 | Iteration number: [3320/4518] 73% | Training loss: 0.6870200995939324
Epoch: 57 | Iteration number: [3330/4518] 73% | Training loss: 0.6870168774693578
Epoch: 57 | Iteration number: [3340/4518] 73% | Training loss: 0.6870141136610579
Epoch: 57 | Iteration number: [3350/4518] 74% | Training loss: 0.6870154010004073
Epoch: 57 | Iteration number: [3360/4518] 74% | Training loss: 0.6870148228392714
Epoch: 57 | Iteration number: [3370/4518] 74% | Training loss: 0.6870144969631727
Epoch: 57 | Iteration number: [3380/4518] 74% | Training loss: 0.6870157351507943
Epoch: 57 | Iteration number: [3390/4518] 75% | Training loss: 0.6870159828557377
Epoch: 57 | Iteration number: [3400/4518] 75% | Training loss: 0.6870147237006355
Epoch: 57 | Iteration number: [3410/4518] 75% | Training loss: 0.687011360772544
Epoch: 57 | Iteration number: [3420/4518] 75% | Training loss: 0.6870087009947202
Epoch: 57 | Iteration number: [3430/4518] 75% | Training loss: 0.6870073952758278
Epoch: 57 | Iteration number: [3440/4518] 76% | Training loss: 0.6870067993742089
Epoch: 57 | Iteration number: [3450/4518] 76% | Training loss: 0.6870084339639415
Epoch: 57 | Iteration number: [3460/4518] 76% | Training loss: 0.6870073615471063
Epoch: 57 | Iteration number: [3470/4518] 76% | Training loss: 0.6870088383168926
Epoch: 57 | Iteration number: [3480/4518] 77% | Training loss: 0.6870096372461867
Epoch: 57 | Iteration number: [3490/4518] 77% | Training loss: 0.6870116800155203
Epoch: 57 | Iteration number: [3500/4518] 77% | Training loss: 0.6870072193826948
Epoch: 57 | Iteration number: [3510/4518] 77% | Training loss: 0.6870089890270831
Epoch: 57 | Iteration number: [3520/4518] 77% | Training loss: 0.6870066711340438
Epoch: 57 | Iteration number: [3530/4518] 78% | Training loss: 0.6870053463718371
Epoch: 57 | Iteration number: [3540/4518] 78% | Training loss: 0.6870050013233713
Epoch: 57 | Iteration number: [3550/4518] 78% | Training loss: 0.687001293578618
Epoch: 57 | Iteration number: [3560/4518] 78% | Training loss: 0.6870016660750582
Epoch: 57 | Iteration number: [3570/4518] 79% | Training loss: 0.6869980264945524
Epoch: 57 | Iteration number: [3580/4518] 79% | Training loss: 0.6869954413541869
Epoch: 57 | Iteration number: [3590/4518] 79% | Training loss: 0.6869907117155601
Epoch: 57 | Iteration number: [3600/4518] 79% | Training loss: 0.686984600805574
Epoch: 57 | Iteration number: [3610/4518] 79% | Training loss: 0.6869835617304508
Epoch: 57 | Iteration number: [3620/4518] 80% | Training loss: 0.686987747918835
Epoch: 57 | Iteration number: [3630/4518] 80% | Training loss: 0.6869866646025792
Epoch: 57 | Iteration number: [3640/4518] 80% | Training loss: 0.6869850049307058
Epoch: 57 | Iteration number: [3650/4518] 80% | Training loss: 0.686983630232615
Epoch: 57 | Iteration number: [3660/4518] 81% | Training loss: 0.686983053426925
Epoch: 57 | Iteration number: [3670/4518] 81% | Training loss: 0.6869839114454201
Epoch: 57 | Iteration number: [3680/4518] 81% | Training loss: 0.6869835803690164
Epoch: 57 | Iteration number: [3690/4518] 81% | Training loss: 0.6869819257963641
Epoch: 57 | Iteration number: [3700/4518] 81% | Training loss: 0.6869778455270303
Epoch: 57 | Iteration number: [3710/4518] 82% | Training loss: 0.6869789747215024
Epoch: 57 | Iteration number: [3720/4518] 82% | Training loss: 0.6869746161564704
Epoch: 57 | Iteration number: [3730/4518] 82% | Training loss: 0.6869756783780719
Epoch: 57 | Iteration number: [3740/4518] 82% | Training loss: 0.6869737000229524
Epoch: 57 | Iteration number: [3750/4518] 83% | Training loss: 0.6869698445955912
Epoch: 57 | Iteration number: [3760/4518] 83% | Training loss: 0.6869677661739765
Epoch: 57 | Iteration number: [3770/4518] 83% | Training loss: 0.6869695603847503
Epoch: 57 | Iteration number: [3780/4518] 83% | Training loss: 0.6869695410526618
Epoch: 57 | Iteration number: [3790/4518] 83% | Training loss: 0.6869685586807281
Epoch: 57 | Iteration number: [3800/4518] 84% | Training loss: 0.6869662824900526
Epoch: 57 | Iteration number: [3810/4518] 84% | Training loss: 0.6869664252743007
Epoch: 57 | Iteration number: [3820/4518] 84% | Training loss: 0.6869668325984665
Epoch: 57 | Iteration number: [3830/4518] 84% | Training loss: 0.6869605893254591
Epoch: 57 | Iteration number: [3840/4518] 84% | Training loss: 0.6869600064276408
Epoch: 57 | Iteration number: [3850/4518] 85% | Training loss: 0.6869606743075631
Epoch: 57 | Iteration number: [3860/4518] 85% | Training loss: 0.6869608718959779
Epoch: 57 | Iteration number: [3870/4518] 85% | Training loss: 0.6869571342486743
Epoch: 57 | Iteration number: [3880/4518] 85% | Training loss: 0.6869544492861659
Epoch: 57 | Iteration number: [3890/4518] 86% | Training loss: 0.6869536295035198
Epoch: 57 | Iteration number: [3900/4518] 86% | Training loss: 0.6869571533722755
Epoch: 57 | Iteration number: [3910/4518] 86% | Training loss: 0.6869597125236335
Epoch: 57 | Iteration number: [3920/4518] 86% | Training loss: 0.6869596419133702
Epoch: 57 | Iteration number: [3930/4518] 86% | Training loss: 0.6869582469530081
Epoch: 57 | Iteration number: [3940/4518] 87% | Training loss: 0.6869567156745697
Epoch: 57 | Iteration number: [3950/4518] 87% | Training loss: 0.6869526701939257
Epoch: 57 | Iteration number: [3960/4518] 87% | Training loss: 0.686953651242786
Epoch: 57 | Iteration number: [3970/4518] 87% | Training loss: 0.6869534148377195
Epoch: 57 | Iteration number: [3980/4518] 88% | Training loss: 0.6869547803348033
Epoch: 57 | Iteration number: [3990/4518] 88% | Training loss: 0.6869550751265427
Epoch: 57 | Iteration number: [4000/4518] 88% | Training loss: 0.6869553715139628
Epoch: 57 | Iteration number: [4010/4518] 88% | Training loss: 0.6869556153058411
Epoch: 57 | Iteration number: [4020/4518] 88% | Training loss: 0.6869567544454366
Epoch: 57 | Iteration number: [4030/4518] 89% | Training loss: 0.6869574973512228
Epoch: 57 | Iteration number: [4040/4518] 89% | Training loss: 0.6869571621760283
Epoch: 57 | Iteration number: [4050/4518] 89% | Training loss: 0.6869588105325346
Epoch: 57 | Iteration number: [4060/4518] 89% | Training loss: 0.6869596031058598
Epoch: 57 | Iteration number: [4070/4518] 90% | Training loss: 0.6869600447009178
Epoch: 57 | Iteration number: [4080/4518] 90% | Training loss: 0.6869620833472878
Epoch: 57 | Iteration number: [4090/4518] 90% | Training loss: 0.6869630937908564
Epoch: 57 | Iteration number: [4100/4518] 90% | Training loss: 0.6869639026682551
Epoch: 57 | Iteration number: [4110/4518] 90% | Training loss: 0.6869648419882549
Epoch: 57 | Iteration number: [4120/4518] 91% | Training loss: 0.6869648807835811
Epoch: 57 | Iteration number: [4130/4518] 91% | Training loss: 0.6869611125159784
Epoch: 57 | Iteration number: [4140/4518] 91% | Training loss: 0.686963592318521
Epoch: 57 | Iteration number: [4150/4518] 91% | Training loss: 0.686966034949544
Epoch: 57 | Iteration number: [4160/4518] 92% | Training loss: 0.6869658695390591
Epoch: 57 | Iteration number: [4170/4518] 92% | Training loss: 0.6869670882499476
Epoch: 57 | Iteration number: [4180/4518] 92% | Training loss: 0.6869656304423318
Epoch: 57 | Iteration number: [4190/4518] 92% | Training loss: 0.6869658891653958
Epoch: 57 | Iteration number: [4200/4518] 92% | Training loss: 0.6869656344396727
Epoch: 57 | Iteration number: [4210/4518] 93% | Training loss: 0.6869646194711717
Epoch: 57 | Iteration number: [4220/4518] 93% | Training loss: 0.6869614865401344
Epoch: 57 | Iteration number: [4230/4518] 93% | Training loss: 0.6869594925825195
Epoch: 57 | Iteration number: [4240/4518] 93% | Training loss: 0.6869569690862917
Epoch: 57 | Iteration number: [4250/4518] 94% | Training loss: 0.6869567847953123
Epoch: 57 | Iteration number: [4260/4518] 94% | Training loss: 0.6869569223111784
Epoch: 57 | Iteration number: [4270/4518] 94% | Training loss: 0.686958472273668
Epoch: 57 | Iteration number: [4280/4518] 94% | Training loss: 0.6869566332235515
Epoch: 57 | Iteration number: [4290/4518] 94% | Training loss: 0.6869574104433571
Epoch: 57 | Iteration number: [4300/4518] 95% | Training loss: 0.6869558625581652
Epoch: 57 | Iteration number: [4310/4518] 95% | Training loss: 0.6869535108176849
Epoch: 57 | Iteration number: [4320/4518] 95% | Training loss: 0.6869542500073159
Epoch: 57 | Iteration number: [4330/4518] 95% | Training loss: 0.6869518643576333
Epoch: 57 | Iteration number: [4340/4518] 96% | Training loss: 0.6869533724773864
Epoch: 57 | Iteration number: [4350/4518] 96% | Training loss: 0.6869513023584739
Epoch: 57 | Iteration number: [4360/4518] 96% | Training loss: 0.6869524489302155
Epoch: 57 | Iteration number: [4370/4518] 96% | Training loss: 0.6869515991592844
Epoch: 57 | Iteration number: [4380/4518] 96% | Training loss: 0.6869527468262198
Epoch: 57 | Iteration number: [4390/4518] 97% | Training loss: 0.686949761160957
Epoch: 57 | Iteration number: [4400/4518] 97% | Training loss: 0.6869478436491706
Epoch: 57 | Iteration number: [4410/4518] 97% | Training loss: 0.686950076423805
Epoch: 57 | Iteration number: [4420/4518] 97% | Training loss: 0.6869489163969437
Epoch: 57 | Iteration number: [4430/4518] 98% | Training loss: 0.6869504734974683
Epoch: 57 | Iteration number: [4440/4518] 98% | Training loss: 0.6869500098061991
Epoch: 57 | Iteration number: [4450/4518] 98% | Training loss: 0.6869512733850587
Epoch: 57 | Iteration number: [4460/4518] 98% | Training loss: 0.6869522026702427
Epoch: 57 | Iteration number: [4470/4518] 98% | Training loss: 0.6869483208096268
Epoch: 57 | Iteration number: [4480/4518] 99% | Training loss: 0.6869456768301981
Epoch: 57 | Iteration number: [4490/4518] 99% | Training loss: 0.6869463494864764
Epoch: 57 | Iteration number: [4500/4518] 99% | Training loss: 0.6869452688694
Epoch: 57 | Iteration number: [4510/4518] 99% | Training loss: 0.6869462831321682

 End of epoch: 57 | Train Loss: 0.6867940006080905 | Training Time: 632 

 End of epoch: 57 | Eval Loss: 0.6897270752459156 | Evaluating Time: 17 
Epoch: 58 | Iteration number: [10/4518] 0% | Training loss: 0.7554221272468566
Epoch: 58 | Iteration number: [20/4518] 0% | Training loss: 0.7211332112550736
Epoch: 58 | Iteration number: [30/4518] 0% | Training loss: 0.7093314826488495
Epoch: 58 | Iteration number: [40/4518] 0% | Training loss: 0.7038480550050735
Epoch: 58 | Iteration number: [50/4518] 1% | Training loss: 0.7002328944206238
Epoch: 58 | Iteration number: [60/4518] 1% | Training loss: 0.698309380809466
Epoch: 58 | Iteration number: [70/4518] 1% | Training loss: 0.6966864900929587
Epoch: 58 | Iteration number: [80/4518] 1% | Training loss: 0.6954697407782078
Epoch: 58 | Iteration number: [90/4518] 1% | Training loss: 0.6945351488060422
Epoch: 58 | Iteration number: [100/4518] 2% | Training loss: 0.6938576507568359
Epoch: 58 | Iteration number: [110/4518] 2% | Training loss: 0.6932793790643865
Epoch: 58 | Iteration number: [120/4518] 2% | Training loss: 0.6927540530761083
Epoch: 58 | Iteration number: [130/4518] 2% | Training loss: 0.6922387664134686
Epoch: 58 | Iteration number: [140/4518] 3% | Training loss: 0.6919220894575119
Epoch: 58 | Iteration number: [150/4518] 3% | Training loss: 0.691544329325358
Epoch: 58 | Iteration number: [160/4518] 3% | Training loss: 0.6912027698010206
Epoch: 58 | Iteration number: [170/4518] 3% | Training loss: 0.6909201804329367
Epoch: 58 | Iteration number: [180/4518] 3% | Training loss: 0.6907406452629301
Epoch: 58 | Iteration number: [190/4518] 4% | Training loss: 0.6905121818969124
Epoch: 58 | Iteration number: [200/4518] 4% | Training loss: 0.6903075438737869
Epoch: 58 | Iteration number: [210/4518] 4% | Training loss: 0.6901514263380142
Epoch: 58 | Iteration number: [220/4518] 4% | Training loss: 0.6900058150291443
Epoch: 58 | Iteration number: [230/4518] 5% | Training loss: 0.6898672987585482
Epoch: 58 | Iteration number: [240/4518] 5% | Training loss: 0.689727042367061
Epoch: 58 | Iteration number: [250/4518] 5% | Training loss: 0.6896260979175568
Epoch: 58 | Iteration number: [260/4518] 5% | Training loss: 0.6895078874551333
Epoch: 58 | Iteration number: [270/4518] 5% | Training loss: 0.6893792088384981
Epoch: 58 | Iteration number: [280/4518] 6% | Training loss: 0.6892883496625083
Epoch: 58 | Iteration number: [290/4518] 6% | Training loss: 0.6891708115051532
Epoch: 58 | Iteration number: [300/4518] 6% | Training loss: 0.6890980827808381
Epoch: 58 | Iteration number: [310/4518] 6% | Training loss: 0.6890419171702478
Epoch: 58 | Iteration number: [320/4518] 7% | Training loss: 0.6889504283666611
Epoch: 58 | Iteration number: [330/4518] 7% | Training loss: 0.6889432074445667
Epoch: 58 | Iteration number: [340/4518] 7% | Training loss: 0.688893145848723
Epoch: 58 | Iteration number: [350/4518] 7% | Training loss: 0.6888700991017478
Epoch: 58 | Iteration number: [360/4518] 7% | Training loss: 0.6888562346498172
Epoch: 58 | Iteration number: [370/4518] 8% | Training loss: 0.6887436373813732
Epoch: 58 | Iteration number: [380/4518] 8% | Training loss: 0.6886867149880058
Epoch: 58 | Iteration number: [390/4518] 8% | Training loss: 0.6886012651981451
Epoch: 58 | Iteration number: [400/4518] 8% | Training loss: 0.6885352025926114
Epoch: 58 | Iteration number: [410/4518] 9% | Training loss: 0.6884673106961134
Epoch: 58 | Iteration number: [420/4518] 9% | Training loss: 0.6884401931649162
Epoch: 58 | Iteration number: [430/4518] 9% | Training loss: 0.688402966843095
Epoch: 58 | Iteration number: [440/4518] 9% | Training loss: 0.6883304503830996
Epoch: 58 | Iteration number: [450/4518] 9% | Training loss: 0.6883201755417718
Epoch: 58 | Iteration number: [460/4518] 10% | Training loss: 0.6883030487143476
Epoch: 58 | Iteration number: [470/4518] 10% | Training loss: 0.6882628084497249
Epoch: 58 | Iteration number: [480/4518] 10% | Training loss: 0.6882312589635452
Epoch: 58 | Iteration number: [490/4518] 10% | Training loss: 0.6881894817157668
Epoch: 58 | Iteration number: [500/4518] 11% | Training loss: 0.6881656388044357
Epoch: 58 | Iteration number: [510/4518] 11% | Training loss: 0.6881667227137322
Epoch: 58 | Iteration number: [520/4518] 11% | Training loss: 0.6881539763166354
Epoch: 58 | Iteration number: [530/4518] 11% | Training loss: 0.6881265378223276
Epoch: 58 | Iteration number: [540/4518] 11% | Training loss: 0.6881051392466934
Epoch: 58 | Iteration number: [550/4518] 12% | Training loss: 0.6880754665894941
Epoch: 58 | Iteration number: [560/4518] 12% | Training loss: 0.6880393119794982
Epoch: 58 | Iteration number: [570/4518] 12% | Training loss: 0.6880128018688737
Epoch: 58 | Iteration number: [580/4518] 12% | Training loss: 0.6879985506164616
Epoch: 58 | Iteration number: [590/4518] 13% | Training loss: 0.687994082297309
Epoch: 58 | Iteration number: [600/4518] 13% | Training loss: 0.6879719307025274
Epoch: 58 | Iteration number: [610/4518] 13% | Training loss: 0.6879389679822765
Epoch: 58 | Iteration number: [620/4518] 13% | Training loss: 0.6879413057719508
Epoch: 58 | Iteration number: [630/4518] 13% | Training loss: 0.6879334887814901
Epoch: 58 | Iteration number: [640/4518] 14% | Training loss: 0.6878908623941242
Epoch: 58 | Iteration number: [650/4518] 14% | Training loss: 0.6878776658498323
Epoch: 58 | Iteration number: [660/4518] 14% | Training loss: 0.6878571997086207
Epoch: 58 | Iteration number: [670/4518] 14% | Training loss: 0.6878389732161565
Epoch: 58 | Iteration number: [680/4518] 15% | Training loss: 0.6878278351005386
Epoch: 58 | Iteration number: [690/4518] 15% | Training loss: 0.6878176633862482
Epoch: 58 | Iteration number: [700/4518] 15% | Training loss: 0.687803578547069
Epoch: 58 | Iteration number: [710/4518] 15% | Training loss: 0.6877797324892501
Epoch: 58 | Iteration number: [720/4518] 15% | Training loss: 0.6877600116862191
Epoch: 58 | Iteration number: [730/4518] 16% | Training loss: 0.687758149676127
Epoch: 58 | Iteration number: [740/4518] 16% | Training loss: 0.6877373881436682
Epoch: 58 | Iteration number: [750/4518] 16% | Training loss: 0.6877222137451172
Epoch: 58 | Iteration number: [760/4518] 16% | Training loss: 0.6876937485839191
Epoch: 58 | Iteration number: [770/4518] 17% | Training loss: 0.6876841644188026
Epoch: 58 | Iteration number: [780/4518] 17% | Training loss: 0.6876622283305878
Epoch: 58 | Iteration number: [790/4518] 17% | Training loss: 0.6876605641238297
Epoch: 58 | Iteration number: [800/4518] 17% | Training loss: 0.6876644625514746
Epoch: 58 | Iteration number: [810/4518] 17% | Training loss: 0.6876571750199353
Epoch: 58 | Iteration number: [820/4518] 18% | Training loss: 0.6876277801467151
Epoch: 58 | Iteration number: [830/4518] 18% | Training loss: 0.6876218983925969
Epoch: 58 | Iteration number: [840/4518] 18% | Training loss: 0.6876344870243754
Epoch: 58 | Iteration number: [850/4518] 18% | Training loss: 0.687637796051362
Epoch: 58 | Iteration number: [860/4518] 19% | Training loss: 0.6876269094472708
Epoch: 58 | Iteration number: [870/4518] 19% | Training loss: 0.6876343544187217
Epoch: 58 | Iteration number: [880/4518] 19% | Training loss: 0.6876132371073419
Epoch: 58 | Iteration number: [890/4518] 19% | Training loss: 0.6875956316342514
Epoch: 58 | Iteration number: [900/4518] 19% | Training loss: 0.6875760791699091
Epoch: 58 | Iteration number: [910/4518] 20% | Training loss: 0.6875607954931783
Epoch: 58 | Iteration number: [920/4518] 20% | Training loss: 0.6875498938819636
Epoch: 58 | Iteration number: [930/4518] 20% | Training loss: 0.6875343597704364
Epoch: 58 | Iteration number: [940/4518] 20% | Training loss: 0.6875279316242705
Epoch: 58 | Iteration number: [950/4518] 21% | Training loss: 0.6875304919794986
Epoch: 58 | Iteration number: [960/4518] 21% | Training loss: 0.6875167674695452
Epoch: 58 | Iteration number: [970/4518] 21% | Training loss: 0.6875103783976172
Epoch: 58 | Iteration number: [980/4518] 21% | Training loss: 0.6875009430306298
Epoch: 58 | Iteration number: [990/4518] 21% | Training loss: 0.6874889394249579
Epoch: 58 | Iteration number: [1000/4518] 22% | Training loss: 0.6874746695160866
Epoch: 58 | Iteration number: [1010/4518] 22% | Training loss: 0.6874736912769847
Epoch: 58 | Iteration number: [1020/4518] 22% | Training loss: 0.6874606661352457
Epoch: 58 | Iteration number: [1030/4518] 22% | Training loss: 0.687451906806057
Epoch: 58 | Iteration number: [1040/4518] 23% | Training loss: 0.6874387869468102
Epoch: 58 | Iteration number: [1050/4518] 23% | Training loss: 0.6874382478282565
Epoch: 58 | Iteration number: [1060/4518] 23% | Training loss: 0.6874304380056993
Epoch: 58 | Iteration number: [1070/4518] 23% | Training loss: 0.6874295653026795
Epoch: 58 | Iteration number: [1080/4518] 23% | Training loss: 0.6874273382403232
Epoch: 58 | Iteration number: [1090/4518] 24% | Training loss: 0.6874227211016034
Epoch: 58 | Iteration number: [1100/4518] 24% | Training loss: 0.6874026148427617
Epoch: 58 | Iteration number: [1110/4518] 24% | Training loss: 0.6873981914541742
Epoch: 58 | Iteration number: [1120/4518] 24% | Training loss: 0.6873883564025164
Epoch: 58 | Iteration number: [1130/4518] 25% | Training loss: 0.6873721617512998
Epoch: 58 | Iteration number: [1140/4518] 25% | Training loss: 0.6873551400084245
Epoch: 58 | Iteration number: [1150/4518] 25% | Training loss: 0.687346384058828
Epoch: 58 | Iteration number: [1160/4518] 25% | Training loss: 0.6873459641275734
Epoch: 58 | Iteration number: [1170/4518] 25% | Training loss: 0.6873380187739674
Epoch: 58 | Iteration number: [1180/4518] 26% | Training loss: 0.6873263606580637
Epoch: 58 | Iteration number: [1190/4518] 26% | Training loss: 0.6873183451780752
Epoch: 58 | Iteration number: [1200/4518] 26% | Training loss: 0.6873170954485734
Epoch: 58 | Iteration number: [1210/4518] 26% | Training loss: 0.6873193025096389
Epoch: 58 | Iteration number: [1220/4518] 27% | Training loss: 0.6873133463937728
Epoch: 58 | Iteration number: [1230/4518] 27% | Training loss: 0.6873074448205592
Epoch: 58 | Iteration number: [1240/4518] 27% | Training loss: 0.687308722686383
Epoch: 58 | Iteration number: [1250/4518] 27% | Training loss: 0.6873045912742615
Epoch: 58 | Iteration number: [1260/4518] 27% | Training loss: 0.6872880668867202
Epoch: 58 | Iteration number: [1270/4518] 28% | Training loss: 0.6872858716277626
Epoch: 58 | Iteration number: [1280/4518] 28% | Training loss: 0.6872821227647364
Epoch: 58 | Iteration number: [1290/4518] 28% | Training loss: 0.6872767478920693
Epoch: 58 | Iteration number: [1300/4518] 28% | Training loss: 0.6872756137297704
Epoch: 58 | Iteration number: [1310/4518] 28% | Training loss: 0.6872709250632133
Epoch: 58 | Iteration number: [1320/4518] 29% | Training loss: 0.6872664626349102
Epoch: 58 | Iteration number: [1330/4518] 29% | Training loss: 0.6872616764746214
Epoch: 58 | Iteration number: [1340/4518] 29% | Training loss: 0.6872506186143675
Epoch: 58 | Iteration number: [1350/4518] 29% | Training loss: 0.6872447698204606
Epoch: 58 | Iteration number: [1360/4518] 30% | Training loss: 0.6872414315448088
Epoch: 58 | Iteration number: [1370/4518] 30% | Training loss: 0.6872434422917609
Epoch: 58 | Iteration number: [1380/4518] 30% | Training loss: 0.6872364609569743
Epoch: 58 | Iteration number: [1390/4518] 30% | Training loss: 0.687238732773623
Epoch: 58 | Iteration number: [1400/4518] 30% | Training loss: 0.687236915741648
Epoch: 58 | Iteration number: [1410/4518] 31% | Training loss: 0.6872339460443944
Epoch: 58 | Iteration number: [1420/4518] 31% | Training loss: 0.6872305293318252
Epoch: 58 | Iteration number: [1430/4518] 31% | Training loss: 0.6872186543224574
Epoch: 58 | Iteration number: [1440/4518] 31% | Training loss: 0.6872103363689449
Epoch: 58 | Iteration number: [1450/4518] 32% | Training loss: 0.6872119637193351
Epoch: 58 | Iteration number: [1460/4518] 32% | Training loss: 0.6872084577606149
Epoch: 58 | Iteration number: [1470/4518] 32% | Training loss: 0.6872202635622349
Epoch: 58 | Iteration number: [1480/4518] 32% | Training loss: 0.6872170882047833
Epoch: 58 | Iteration number: [1490/4518] 32% | Training loss: 0.6872100874081554
Epoch: 58 | Iteration number: [1500/4518] 33% | Training loss: 0.6871950945059458
Epoch: 58 | Iteration number: [1510/4518] 33% | Training loss: 0.687194621168225
Epoch: 58 | Iteration number: [1520/4518] 33% | Training loss: 0.6871961724601294
Epoch: 58 | Iteration number: [1530/4518] 33% | Training loss: 0.6871990193728528
Epoch: 58 | Iteration number: [1540/4518] 34% | Training loss: 0.6871979699506388
Epoch: 58 | Iteration number: [1550/4518] 34% | Training loss: 0.6871867898971804
Epoch: 58 | Iteration number: [1560/4518] 34% | Training loss: 0.6871755517828159
Epoch: 58 | Iteration number: [1570/4518] 34% | Training loss: 0.6871784535942563
Epoch: 58 | Iteration number: [1580/4518] 34% | Training loss: 0.6871881174135812
Epoch: 58 | Iteration number: [1590/4518] 35% | Training loss: 0.6871844497491728
Epoch: 58 | Iteration number: [1600/4518] 35% | Training loss: 0.6871898967400193
Epoch: 58 | Iteration number: [1610/4518] 35% | Training loss: 0.6871846074643342
Epoch: 58 | Iteration number: [1620/4518] 35% | Training loss: 0.6871773678211518
Epoch: 58 | Iteration number: [1630/4518] 36% | Training loss: 0.6871763705841603
Epoch: 58 | Iteration number: [1640/4518] 36% | Training loss: 0.6871762033279349
Epoch: 58 | Iteration number: [1650/4518] 36% | Training loss: 0.6871780375639598
Epoch: 58 | Iteration number: [1660/4518] 36% | Training loss: 0.687168463705534
Epoch: 58 | Iteration number: [1670/4518] 36% | Training loss: 0.6871621752570489
Epoch: 58 | Iteration number: [1680/4518] 37% | Training loss: 0.6871646723222165
Epoch: 58 | Iteration number: [1690/4518] 37% | Training loss: 0.6871630971953714
Epoch: 58 | Iteration number: [1700/4518] 37% | Training loss: 0.6871561071802588
Epoch: 58 | Iteration number: [1710/4518] 37% | Training loss: 0.687159382181558
Epoch: 58 | Iteration number: [1720/4518] 38% | Training loss: 0.6871647175661353
Epoch: 58 | Iteration number: [1730/4518] 38% | Training loss: 0.687159086789699
Epoch: 58 | Iteration number: [1740/4518] 38% | Training loss: 0.6871590081645155
Epoch: 58 | Iteration number: [1750/4518] 38% | Training loss: 0.6871446837016514
Epoch: 58 | Iteration number: [1760/4518] 38% | Training loss: 0.687145718830553
Epoch: 58 | Iteration number: [1770/4518] 39% | Training loss: 0.6871435808259888
Epoch: 58 | Iteration number: [1780/4518] 39% | Training loss: 0.6871393368485269
Epoch: 58 | Iteration number: [1790/4518] 39% | Training loss: 0.6871358073956474
Epoch: 58 | Iteration number: [1800/4518] 39% | Training loss: 0.6871394970019659
Epoch: 58 | Iteration number: [1810/4518] 40% | Training loss: 0.6871370531248124
Epoch: 58 | Iteration number: [1820/4518] 40% | Training loss: 0.6871383605095056
Epoch: 58 | Iteration number: [1830/4518] 40% | Training loss: 0.6871306533044804
Epoch: 58 | Iteration number: [1840/4518] 40% | Training loss: 0.6871264940370684
Epoch: 58 | Iteration number: [1850/4518] 40% | Training loss: 0.687128032510345
Epoch: 58 | Iteration number: [1860/4518] 41% | Training loss: 0.6871240645006139
Epoch: 58 | Iteration number: [1870/4518] 41% | Training loss: 0.6871186270114572
Epoch: 58 | Iteration number: [1880/4518] 41% | Training loss: 0.6871081282483771
Epoch: 58 | Iteration number: [1890/4518] 41% | Training loss: 0.6871113791036858
Epoch: 58 | Iteration number: [1900/4518] 42% | Training loss: 0.6871110782184099
Epoch: 58 | Iteration number: [1910/4518] 42% | Training loss: 0.6871098744619579
Epoch: 58 | Iteration number: [1920/4518] 42% | Training loss: 0.6871063027220468
Epoch: 58 | Iteration number: [1930/4518] 42% | Training loss: 0.6871062563182159
Epoch: 58 | Iteration number: [1940/4518] 42% | Training loss: 0.6871055088092372
Epoch: 58 | Iteration number: [1950/4518] 43% | Training loss: 0.6871014878383049
Epoch: 58 | Iteration number: [1960/4518] 43% | Training loss: 0.687097420072069
Epoch: 58 | Iteration number: [1970/4518] 43% | Training loss: 0.6870908766228535
Epoch: 58 | Iteration number: [1980/4518] 43% | Training loss: 0.6870939166858943
Epoch: 58 | Iteration number: [1990/4518] 44% | Training loss: 0.6870941205839416
Epoch: 58 | Iteration number: [2000/4518] 44% | Training loss: 0.6870956307351589
Epoch: 58 | Iteration number: [2010/4518] 44% | Training loss: 0.6870956415857249
Epoch: 58 | Iteration number: [2020/4518] 44% | Training loss: 0.6870910228183954
Epoch: 58 | Iteration number: [2030/4518] 44% | Training loss: 0.6870921630577501
Epoch: 58 | Iteration number: [2040/4518] 45% | Training loss: 0.6870957158359827
Epoch: 58 | Iteration number: [2050/4518] 45% | Training loss: 0.6870888815565807
Epoch: 58 | Iteration number: [2060/4518] 45% | Training loss: 0.6870879614526786
Epoch: 58 | Iteration number: [2070/4518] 45% | Training loss: 0.6870804384998653
Epoch: 58 | Iteration number: [2080/4518] 46% | Training loss: 0.6870772172052126
Epoch: 58 | Iteration number: [2090/4518] 46% | Training loss: 0.6870715122473867
Epoch: 58 | Iteration number: [2100/4518] 46% | Training loss: 0.6870684383880524
Epoch: 58 | Iteration number: [2110/4518] 46% | Training loss: 0.6870740390784368
Epoch: 58 | Iteration number: [2120/4518] 46% | Training loss: 0.687077873298582
Epoch: 58 | Iteration number: [2130/4518] 47% | Training loss: 0.6870708630398406
Epoch: 58 | Iteration number: [2140/4518] 47% | Training loss: 0.6870697293326119
Epoch: 58 | Iteration number: [2150/4518] 47% | Training loss: 0.6870697645253914
Epoch: 58 | Iteration number: [2160/4518] 47% | Training loss: 0.6870720992209735
Epoch: 58 | Iteration number: [2170/4518] 48% | Training loss: 0.6870696147740711
Epoch: 58 | Iteration number: [2180/4518] 48% | Training loss: 0.6870674492569144
Epoch: 58 | Iteration number: [2190/4518] 48% | Training loss: 0.6870658602616558
Epoch: 58 | Iteration number: [2200/4518] 48% | Training loss: 0.6870650697025386
Epoch: 58 | Iteration number: [2210/4518] 48% | Training loss: 0.6870670188336351
Epoch: 58 | Iteration number: [2220/4518] 49% | Training loss: 0.6870706648708463
Epoch: 58 | Iteration number: [2230/4518] 49% | Training loss: 0.6870741344620829
Epoch: 58 | Iteration number: [2240/4518] 49% | Training loss: 0.6870747951524598
Epoch: 58 | Iteration number: [2250/4518] 49% | Training loss: 0.6870767455365923
Epoch: 58 | Iteration number: [2260/4518] 50% | Training loss: 0.6870752959388547
Epoch: 58 | Iteration number: [2270/4518] 50% | Training loss: 0.6870675741313312
Epoch: 58 | Iteration number: [2280/4518] 50% | Training loss: 0.6870647558779047
Epoch: 58 | Iteration number: [2290/4518] 50% | Training loss: 0.6870631912649979
Epoch: 58 | Iteration number: [2300/4518] 50% | Training loss: 0.6870608223521191
Epoch: 58 | Iteration number: [2310/4518] 51% | Training loss: 0.6870644286339417
Epoch: 58 | Iteration number: [2320/4518] 51% | Training loss: 0.68706314699917
Epoch: 58 | Iteration number: [2330/4518] 51% | Training loss: 0.6870633086421459
Epoch: 58 | Iteration number: [2340/4518] 51% | Training loss: 0.6870585994333284
Epoch: 58 | Iteration number: [2350/4518] 52% | Training loss: 0.6870565141769166
Epoch: 58 | Iteration number: [2360/4518] 52% | Training loss: 0.6870564119543059
Epoch: 58 | Iteration number: [2370/4518] 52% | Training loss: 0.6870531510954668
Epoch: 58 | Iteration number: [2380/4518] 52% | Training loss: 0.6870552550343906
Epoch: 58 | Iteration number: [2390/4518] 52% | Training loss: 0.6870536850336705
Epoch: 58 | Iteration number: [2400/4518] 53% | Training loss: 0.6870543862630923
Epoch: 58 | Iteration number: [2410/4518] 53% | Training loss: 0.6870541896810175
Epoch: 58 | Iteration number: [2420/4518] 53% | Training loss: 0.6870543097661547
Epoch: 58 | Iteration number: [2430/4518] 53% | Training loss: 0.6870538152294394
Epoch: 58 | Iteration number: [2440/4518] 54% | Training loss: 0.6870556736822988
Epoch: 58 | Iteration number: [2450/4518] 54% | Training loss: 0.6870551971270114
Epoch: 58 | Iteration number: [2460/4518] 54% | Training loss: 0.6870550311435529
Epoch: 58 | Iteration number: [2470/4518] 54% | Training loss: 0.6870569570827098
Epoch: 58 | Iteration number: [2480/4518] 54% | Training loss: 0.6870510725965423
Epoch: 58 | Iteration number: [2490/4518] 55% | Training loss: 0.6870484165637848
Epoch: 58 | Iteration number: [2500/4518] 55% | Training loss: 0.6870469324111939
Epoch: 58 | Iteration number: [2510/4518] 55% | Training loss: 0.6870481736868976
Epoch: 58 | Iteration number: [2520/4518] 55% | Training loss: 0.6870482391308225
Epoch: 58 | Iteration number: [2530/4518] 55% | Training loss: 0.6870490868101007
Epoch: 58 | Iteration number: [2540/4518] 56% | Training loss: 0.6870497793193877
Epoch: 58 | Iteration number: [2550/4518] 56% | Training loss: 0.6870485425696653
Epoch: 58 | Iteration number: [2560/4518] 56% | Training loss: 0.6870470727328211
Epoch: 58 | Iteration number: [2570/4518] 56% | Training loss: 0.6870476462497785
Epoch: 58 | Iteration number: [2580/4518] 57% | Training loss: 0.6870478057584097
Epoch: 58 | Iteration number: [2590/4518] 57% | Training loss: 0.6870476855734601
Epoch: 58 | Iteration number: [2600/4518] 57% | Training loss: 0.6870504843730193
Epoch: 58 | Iteration number: [2610/4518] 57% | Training loss: 0.6870508014470681
Epoch: 58 | Iteration number: [2620/4518] 57% | Training loss: 0.6870460241350509
Epoch: 58 | Iteration number: [2630/4518] 58% | Training loss: 0.6870435506218739
Epoch: 58 | Iteration number: [2640/4518] 58% | Training loss: 0.6870412767836542
Epoch: 58 | Iteration number: [2650/4518] 58% | Training loss: 0.687040486380739
Epoch: 58 | Iteration number: [2660/4518] 58% | Training loss: 0.6870388222816295
Epoch: 58 | Iteration number: [2670/4518] 59% | Training loss: 0.6870381902219651
Epoch: 58 | Iteration number: [2680/4518] 59% | Training loss: 0.6870343503000131
Epoch: 58 | Iteration number: [2690/4518] 59% | Training loss: 0.6870299655487103
Epoch: 58 | Iteration number: [2700/4518] 59% | Training loss: 0.6870260285889661
Epoch: 58 | Iteration number: [2710/4518] 59% | Training loss: 0.6870250507474386
Epoch: 58 | Iteration number: [2720/4518] 60% | Training loss: 0.687023443662945
Epoch: 58 | Iteration number: [2730/4518] 60% | Training loss: 0.687022764800669
Epoch: 58 | Iteration number: [2740/4518] 60% | Training loss: 0.6870196158868553
Epoch: 58 | Iteration number: [2750/4518] 60% | Training loss: 0.6870204889340834
Epoch: 58 | Iteration number: [2760/4518] 61% | Training loss: 0.6870226009384446
Epoch: 58 | Iteration number: [2770/4518] 61% | Training loss: 0.6870209795473284
Epoch: 58 | Iteration number: [2780/4518] 61% | Training loss: 0.6870152616029163
Epoch: 58 | Iteration number: [2790/4518] 61% | Training loss: 0.6870127667022008
Epoch: 58 | Iteration number: [2800/4518] 61% | Training loss: 0.6870155595668724
Epoch: 58 | Iteration number: [2810/4518] 62% | Training loss: 0.6870152704019987
Epoch: 58 | Iteration number: [2820/4518] 62% | Training loss: 0.6870116315200819
Epoch: 58 | Iteration number: [2830/4518] 62% | Training loss: 0.6870091343094519
Epoch: 58 | Iteration number: [2840/4518] 62% | Training loss: 0.6870102911977701
Epoch: 58 | Iteration number: [2850/4518] 63% | Training loss: 0.6870063316612913
Epoch: 58 | Iteration number: [2860/4518] 63% | Training loss: 0.6870058731182472
Epoch: 58 | Iteration number: [2870/4518] 63% | Training loss: 0.6870051841494929
Epoch: 58 | Iteration number: [2880/4518] 63% | Training loss: 0.6870074216690328
Epoch: 58 | Iteration number: [2890/4518] 63% | Training loss: 0.6870092196241795
Epoch: 58 | Iteration number: [2900/4518] 64% | Training loss: 0.6870069155405307
Epoch: 58 | Iteration number: [2910/4518] 64% | Training loss: 0.6870030984845767
Epoch: 58 | Iteration number: [2920/4518] 64% | Training loss: 0.6870011637268001
Epoch: 58 | Iteration number: [2930/4518] 64% | Training loss: 0.6870035645294515
Epoch: 58 | Iteration number: [2940/4518] 65% | Training loss: 0.6870050375153418
Epoch: 58 | Iteration number: [2950/4518] 65% | Training loss: 0.6870059898748236
Epoch: 58 | Iteration number: [2960/4518] 65% | Training loss: 0.6870027941425104
Epoch: 58 | Iteration number: [2970/4518] 65% | Training loss: 0.6870018052934396
Epoch: 58 | Iteration number: [2980/4518] 65% | Training loss: 0.6870024077244253
Epoch: 58 | Iteration number: [2990/4518] 66% | Training loss: 0.6870061392568825
Epoch: 58 | Iteration number: [3000/4518] 66% | Training loss: 0.6870031190911928
Epoch: 58 | Iteration number: [3010/4518] 66% | Training loss: 0.6870001493894381
Epoch: 58 | Iteration number: [3020/4518] 66% | Training loss: 0.6869973248401225
Epoch: 58 | Iteration number: [3030/4518] 67% | Training loss: 0.68699433707168
Epoch: 58 | Iteration number: [3040/4518] 67% | Training loss: 0.6869940854609012
Epoch: 58 | Iteration number: [3050/4518] 67% | Training loss: 0.6869916853357534
Epoch: 58 | Iteration number: [3060/4518] 67% | Training loss: 0.6869955651900348
Epoch: 58 | Iteration number: [3070/4518] 67% | Training loss: 0.6869907362453324
Epoch: 58 | Iteration number: [3080/4518] 68% | Training loss: 0.6869895454157483
Epoch: 58 | Iteration number: [3090/4518] 68% | Training loss: 0.6869848940364751
Epoch: 58 | Iteration number: [3100/4518] 68% | Training loss: 0.6869816667418326
Epoch: 58 | Iteration number: [3110/4518] 68% | Training loss: 0.6869789176048573
Epoch: 58 | Iteration number: [3120/4518] 69% | Training loss: 0.6869759627450736
Epoch: 58 | Iteration number: [3130/4518] 69% | Training loss: 0.6869761165148153
Epoch: 58 | Iteration number: [3140/4518] 69% | Training loss: 0.6869795234340011
Epoch: 58 | Iteration number: [3150/4518] 69% | Training loss: 0.6869770133495331
Epoch: 58 | Iteration number: [3160/4518] 69% | Training loss: 0.6869754766927489
Epoch: 58 | Iteration number: [3170/4518] 70% | Training loss: 0.6869724452307547
Epoch: 58 | Iteration number: [3180/4518] 70% | Training loss: 0.6869692338525124
Epoch: 58 | Iteration number: [3190/4518] 70% | Training loss: 0.6869675307998837
Epoch: 58 | Iteration number: [3200/4518] 70% | Training loss: 0.6869685379043221
Epoch: 58 | Iteration number: [3210/4518] 71% | Training loss: 0.686972446233684
Epoch: 58 | Iteration number: [3220/4518] 71% | Training loss: 0.6869708484189111
Epoch: 58 | Iteration number: [3230/4518] 71% | Training loss: 0.6869691108586987
Epoch: 58 | Iteration number: [3240/4518] 71% | Training loss: 0.6869670447927935
Epoch: 58 | Iteration number: [3250/4518] 71% | Training loss: 0.6869674613659198
Epoch: 58 | Iteration number: [3260/4518] 72% | Training loss: 0.6869711824172845
Epoch: 58 | Iteration number: [3270/4518] 72% | Training loss: 0.6869707424706275
Epoch: 58 | Iteration number: [3280/4518] 72% | Training loss: 0.6869700759830998
Epoch: 58 | Iteration number: [3290/4518] 72% | Training loss: 0.6869712588634896
Epoch: 58 | Iteration number: [3300/4518] 73% | Training loss: 0.6869698125123977
Epoch: 58 | Iteration number: [3310/4518] 73% | Training loss: 0.6869717342615848
Epoch: 58 | Iteration number: [3320/4518] 73% | Training loss: 0.6869687115930649
Epoch: 58 | Iteration number: [3330/4518] 73% | Training loss: 0.6869665067296128
Epoch: 58 | Iteration number: [3340/4518] 73% | Training loss: 0.6869675423213821
Epoch: 58 | Iteration number: [3350/4518] 74% | Training loss: 0.6869684521119986
Epoch: 58 | Iteration number: [3360/4518] 74% | Training loss: 0.6869668342705284
Epoch: 58 | Iteration number: [3370/4518] 74% | Training loss: 0.6869641813927659
Epoch: 58 | Iteration number: [3380/4518] 74% | Training loss: 0.6869667165378142
Epoch: 58 | Iteration number: [3390/4518] 75% | Training loss: 0.6869656303990908
Epoch: 58 | Iteration number: [3400/4518] 75% | Training loss: 0.6869690327609287
Epoch: 58 | Iteration number: [3410/4518] 75% | Training loss: 0.6869726084019782
Epoch: 58 | Iteration number: [3420/4518] 75% | Training loss: 0.6869737325530303
Epoch: 58 | Iteration number: [3430/4518] 75% | Training loss: 0.686973641148114
Epoch: 58 | Iteration number: [3440/4518] 76% | Training loss: 0.6869669780828233
Epoch: 58 | Iteration number: [3450/4518] 76% | Training loss: 0.6869687777325727
Epoch: 58 | Iteration number: [3460/4518] 76% | Training loss: 0.6869683205909123
Epoch: 58 | Iteration number: [3470/4518] 76% | Training loss: 0.6869708788497991
Epoch: 58 | Iteration number: [3480/4518] 77% | Training loss: 0.6869721272896077
Epoch: 58 | Iteration number: [3490/4518] 77% | Training loss: 0.6869711933812302
Epoch: 58 | Iteration number: [3500/4518] 77% | Training loss: 0.6869695400510516
Epoch: 58 | Iteration number: [3510/4518] 77% | Training loss: 0.6869677928947655
Epoch: 58 | Iteration number: [3520/4518] 77% | Training loss: 0.6869638758288188
Epoch: 58 | Iteration number: [3530/4518] 78% | Training loss: 0.686965314490937
Epoch: 58 | Iteration number: [3540/4518] 78% | Training loss: 0.6869627161214581
Epoch: 58 | Iteration number: [3550/4518] 78% | Training loss: 0.6869606522439231
Epoch: 58 | Iteration number: [3560/4518] 78% | Training loss: 0.6869563285889251
Epoch: 58 | Iteration number: [3570/4518] 79% | Training loss: 0.6869555379162315
Epoch: 58 | Iteration number: [3580/4518] 79% | Training loss: 0.6869545889300341
Epoch: 58 | Iteration number: [3590/4518] 79% | Training loss: 0.686951261891628
Epoch: 58 | Iteration number: [3600/4518] 79% | Training loss: 0.6869526026480728
Epoch: 58 | Iteration number: [3610/4518] 79% | Training loss: 0.6869503192624227
Epoch: 58 | Iteration number: [3620/4518] 80% | Training loss: 0.68694690238705
Epoch: 58 | Iteration number: [3630/4518] 80% | Training loss: 0.686944449736067
Epoch: 58 | Iteration number: [3640/4518] 80% | Training loss: 0.6869451273601134
Epoch: 58 | Iteration number: [3650/4518] 80% | Training loss: 0.6869462892453965
Epoch: 58 | Iteration number: [3660/4518] 81% | Training loss: 0.6869460697708234
Epoch: 58 | Iteration number: [3670/4518] 81% | Training loss: 0.6869428499030807
Epoch: 58 | Iteration number: [3680/4518] 81% | Training loss: 0.6869422905147076
Epoch: 58 | Iteration number: [3690/4518] 81% | Training loss: 0.6869394865623981
Epoch: 58 | Iteration number: [3700/4518] 81% | Training loss: 0.6869428880311347
Epoch: 58 | Iteration number: [3710/4518] 82% | Training loss: 0.6869427426002739
Epoch: 58 | Iteration number: [3720/4518] 82% | Training loss: 0.6869424379160327
Epoch: 58 | Iteration number: [3730/4518] 82% | Training loss: 0.6869394676615023
Epoch: 58 | Iteration number: [3740/4518] 82% | Training loss: 0.6869418183590639
Epoch: 58 | Iteration number: [3750/4518] 83% | Training loss: 0.6869439053853353
Epoch: 58 | Iteration number: [3760/4518] 83% | Training loss: 0.6869431788141424
Epoch: 58 | Iteration number: [3770/4518] 83% | Training loss: 0.6869415746285366
Epoch: 58 | Iteration number: [3780/4518] 83% | Training loss: 0.6869382672524326
Epoch: 58 | Iteration number: [3790/4518] 83% | Training loss: 0.6869366442779752
Epoch: 58 | Iteration number: [3800/4518] 84% | Training loss: 0.6869368129811789
Epoch: 58 | Iteration number: [3810/4518] 84% | Training loss: 0.6869323880497239
Epoch: 58 | Iteration number: [3820/4518] 84% | Training loss: 0.6869321681442061
Epoch: 58 | Iteration number: [3830/4518] 84% | Training loss: 0.6869317444435299
Epoch: 58 | Iteration number: [3840/4518] 84% | Training loss: 0.6869309549064686
Epoch: 58 | Iteration number: [3850/4518] 85% | Training loss: 0.686926430510236
Epoch: 58 | Iteration number: [3860/4518] 85% | Training loss: 0.686926722943474
Epoch: 58 | Iteration number: [3870/4518] 85% | Training loss: 0.6869247537558701
Epoch: 58 | Iteration number: [3880/4518] 85% | Training loss: 0.6869207876244771
Epoch: 58 | Iteration number: [3890/4518] 86% | Training loss: 0.6869228853664545
Epoch: 58 | Iteration number: [3900/4518] 86% | Training loss: 0.6869208680819242
Epoch: 58 | Iteration number: [3910/4518] 86% | Training loss: 0.6869224236749322
Epoch: 58 | Iteration number: [3920/4518] 86% | Training loss: 0.686926276890599
Epoch: 58 | Iteration number: [3930/4518] 86% | Training loss: 0.6869285069349158
Epoch: 58 | Iteration number: [3940/4518] 87% | Training loss: 0.686928121495973
Epoch: 58 | Iteration number: [3950/4518] 87% | Training loss: 0.6869269814370553
Epoch: 58 | Iteration number: [3960/4518] 87% | Training loss: 0.6869278195831511
Epoch: 58 | Iteration number: [3970/4518] 87% | Training loss: 0.6869302623668305
Epoch: 58 | Iteration number: [3980/4518] 88% | Training loss: 0.6869298591835415
Epoch: 58 | Iteration number: [3990/4518] 88% | Training loss: 0.6869312728556775
Epoch: 58 | Iteration number: [4000/4518] 88% | Training loss: 0.686928396821022
Epoch: 58 | Iteration number: [4010/4518] 88% | Training loss: 0.6869307537031293
Epoch: 58 | Iteration number: [4020/4518] 88% | Training loss: 0.6869335082188175
Epoch: 58 | Iteration number: [4030/4518] 89% | Training loss: 0.6869342048026196
Epoch: 58 | Iteration number: [4040/4518] 89% | Training loss: 0.6869330037200805
Epoch: 58 | Iteration number: [4050/4518] 89% | Training loss: 0.6869338690940244
Epoch: 58 | Iteration number: [4060/4518] 89% | Training loss: 0.6869329390414243
Epoch: 58 | Iteration number: [4070/4518] 90% | Training loss: 0.6869316790847873
Epoch: 58 | Iteration number: [4080/4518] 90% | Training loss: 0.6869303780735708
Epoch: 58 | Iteration number: [4090/4518] 90% | Training loss: 0.6869308155439885
Epoch: 58 | Iteration number: [4100/4518] 90% | Training loss: 0.6869308356540959
Epoch: 58 | Iteration number: [4110/4518] 90% | Training loss: 0.6869311454667372
Epoch: 58 | Iteration number: [4120/4518] 91% | Training loss: 0.6869317180757384
Epoch: 58 | Iteration number: [4130/4518] 91% | Training loss: 0.686935188680815
Epoch: 58 | Iteration number: [4140/4518] 91% | Training loss: 0.6869354566658177
Epoch: 58 | Iteration number: [4150/4518] 91% | Training loss: 0.6869350125416216
Epoch: 58 | Iteration number: [4160/4518] 92% | Training loss: 0.6869361671977319
Epoch: 58 | Iteration number: [4170/4518] 92% | Training loss: 0.6869369389198953
Epoch: 58 | Iteration number: [4180/4518] 92% | Training loss: 0.6869371155945307
Epoch: 58 | Iteration number: [4190/4518] 92% | Training loss: 0.686937076208984
Epoch: 58 | Iteration number: [4200/4518] 92% | Training loss: 0.6869387133916219
Epoch: 58 | Iteration number: [4210/4518] 93% | Training loss: 0.6869343341812668
Epoch: 58 | Iteration number: [4220/4518] 93% | Training loss: 0.6869330724409971
Epoch: 58 | Iteration number: [4230/4518] 93% | Training loss: 0.6869346689529735
Epoch: 58 | Iteration number: [4240/4518] 93% | Training loss: 0.6869355451245353
Epoch: 58 | Iteration number: [4250/4518] 94% | Training loss: 0.6869362155128927
Epoch: 58 | Iteration number: [4260/4518] 94% | Training loss: 0.686935152987919
Epoch: 58 | Iteration number: [4270/4518] 94% | Training loss: 0.6869359934916262
Epoch: 58 | Iteration number: [4280/4518] 94% | Training loss: 0.6869357570170243
Epoch: 58 | Iteration number: [4290/4518] 94% | Training loss: 0.6869366426151116
Epoch: 58 | Iteration number: [4300/4518] 95% | Training loss: 0.6869334504354832
Epoch: 58 | Iteration number: [4310/4518] 95% | Training loss: 0.686936463847791
Epoch: 58 | Iteration number: [4320/4518] 95% | Training loss: 0.686937477591413
Epoch: 58 | Iteration number: [4330/4518] 95% | Training loss: 0.686936600957126
Epoch: 58 | Iteration number: [4340/4518] 96% | Training loss: 0.6869373634114243
Epoch: 58 | Iteration number: [4350/4518] 96% | Training loss: 0.6869392581232663
Epoch: 58 | Iteration number: [4360/4518] 96% | Training loss: 0.6869400812398403
Epoch: 58 | Iteration number: [4370/4518] 96% | Training loss: 0.6869399535301348
Epoch: 58 | Iteration number: [4380/4518] 96% | Training loss: 0.6869396129155267
Epoch: 58 | Iteration number: [4390/4518] 97% | Training loss: 0.6869398796884237
Epoch: 58 | Iteration number: [4400/4518] 97% | Training loss: 0.6869403559917754
Epoch: 58 | Iteration number: [4410/4518] 97% | Training loss: 0.6869392605054946
Epoch: 58 | Iteration number: [4420/4518] 97% | Training loss: 0.686941751433174
Epoch: 58 | Iteration number: [4430/4518] 98% | Training loss: 0.6869444667216618
Epoch: 58 | Iteration number: [4440/4518] 98% | Training loss: 0.6869410513623341
Epoch: 58 | Iteration number: [4450/4518] 98% | Training loss: 0.6869427451390898
Epoch: 58 | Iteration number: [4460/4518] 98% | Training loss: 0.6869434651772538
Epoch: 58 | Iteration number: [4470/4518] 98% | Training loss: 0.6869433448485347
Epoch: 58 | Iteration number: [4480/4518] 99% | Training loss: 0.6869417230731675
Epoch: 58 | Iteration number: [4490/4518] 99% | Training loss: 0.6869442469027632
Epoch: 58 | Iteration number: [4500/4518] 99% | Training loss: 0.6869418904781341
Epoch: 58 | Iteration number: [4510/4518] 99% | Training loss: 0.686941592801701

 End of epoch: 58 | Train Loss: 0.6867904060706991 | Training Time: 632 

 End of epoch: 58 | Eval Loss: 0.6897575307865532 | Evaluating Time: 17 
Epoch: 59 | Iteration number: [10/4518] 0% | Training loss: 0.7558591485023498
Epoch: 59 | Iteration number: [20/4518] 0% | Training loss: 0.7214475721120834
Epoch: 59 | Iteration number: [30/4518] 0% | Training loss: 0.7092741072177887
Epoch: 59 | Iteration number: [40/4518] 0% | Training loss: 0.7034700587391853
Epoch: 59 | Iteration number: [50/4518] 1% | Training loss: 0.7003355145454406
Epoch: 59 | Iteration number: [60/4518] 1% | Training loss: 0.698112753033638
Epoch: 59 | Iteration number: [70/4518] 1% | Training loss: 0.6965544019426618
Epoch: 59 | Iteration number: [80/4518] 1% | Training loss: 0.69528593942523
Epoch: 59 | Iteration number: [90/4518] 1% | Training loss: 0.6943091293176015
Epoch: 59 | Iteration number: [100/4518] 2% | Training loss: 0.6935232311487198
Epoch: 59 | Iteration number: [110/4518] 2% | Training loss: 0.6929312472993677
Epoch: 59 | Iteration number: [120/4518] 2% | Training loss: 0.6923493708173434
Epoch: 59 | Iteration number: [130/4518] 2% | Training loss: 0.691894260278115
Epoch: 59 | Iteration number: [140/4518] 3% | Training loss: 0.6916183199201311
Epoch: 59 | Iteration number: [150/4518] 3% | Training loss: 0.6913865983486176
Epoch: 59 | Iteration number: [160/4518] 3% | Training loss: 0.6911540690809488
Epoch: 59 | Iteration number: [170/4518] 3% | Training loss: 0.6908979212536531
Epoch: 59 | Iteration number: [180/4518] 3% | Training loss: 0.6906544284688102
Epoch: 59 | Iteration number: [190/4518] 4% | Training loss: 0.6904662524399005
Epoch: 59 | Iteration number: [200/4518] 4% | Training loss: 0.6902328160405159
Epoch: 59 | Iteration number: [210/4518] 4% | Training loss: 0.6901218692461649
Epoch: 59 | Iteration number: [220/4518] 4% | Training loss: 0.6899847258221019
Epoch: 59 | Iteration number: [230/4518] 5% | Training loss: 0.6898275168045708
Epoch: 59 | Iteration number: [240/4518] 5% | Training loss: 0.6897235924998919
Epoch: 59 | Iteration number: [250/4518] 5% | Training loss: 0.689599046945572
Epoch: 59 | Iteration number: [260/4518] 5% | Training loss: 0.6895080029964447
Epoch: 59 | Iteration number: [270/4518] 5% | Training loss: 0.6893881170837968
Epoch: 59 | Iteration number: [280/4518] 6% | Training loss: 0.6893232960786139
Epoch: 59 | Iteration number: [290/4518] 6% | Training loss: 0.6891735072793632
Epoch: 59 | Iteration number: [300/4518] 6% | Training loss: 0.6891153232256572
Epoch: 59 | Iteration number: [310/4518] 6% | Training loss: 0.6890436735845381
Epoch: 59 | Iteration number: [320/4518] 7% | Training loss: 0.6890175133943558
Epoch: 59 | Iteration number: [330/4518] 7% | Training loss: 0.6889662572831818
Epoch: 59 | Iteration number: [340/4518] 7% | Training loss: 0.6889011661796008
Epoch: 59 | Iteration number: [350/4518] 7% | Training loss: 0.6888111679894584
Epoch: 59 | Iteration number: [360/4518] 7% | Training loss: 0.6887511387467384
Epoch: 59 | Iteration number: [370/4518] 8% | Training loss: 0.6887089460282713
Epoch: 59 | Iteration number: [380/4518] 8% | Training loss: 0.6886372969338769
Epoch: 59 | Iteration number: [390/4518] 8% | Training loss: 0.6885990971173995
Epoch: 59 | Iteration number: [400/4518] 8% | Training loss: 0.6885602250695229
Epoch: 59 | Iteration number: [410/4518] 9% | Training loss: 0.6885254801773444
Epoch: 59 | Iteration number: [420/4518] 9% | Training loss: 0.6884723603725433
Epoch: 59 | Iteration number: [430/4518] 9% | Training loss: 0.6884425622086192
Epoch: 59 | Iteration number: [440/4518] 9% | Training loss: 0.6884289759126576
Epoch: 59 | Iteration number: [450/4518] 9% | Training loss: 0.6883825284904904
Epoch: 59 | Iteration number: [460/4518] 10% | Training loss: 0.6883220371992692
Epoch: 59 | Iteration number: [470/4518] 10% | Training loss: 0.6882826442414142
Epoch: 59 | Iteration number: [480/4518] 10% | Training loss: 0.6882397454231978
Epoch: 59 | Iteration number: [490/4518] 10% | Training loss: 0.6882123304873097
Epoch: 59 | Iteration number: [500/4518] 11% | Training loss: 0.6881927365064621
Epoch: 59 | Iteration number: [510/4518] 11% | Training loss: 0.6881578685021867
Epoch: 59 | Iteration number: [520/4518] 11% | Training loss: 0.6881389693571971
Epoch: 59 | Iteration number: [530/4518] 11% | Training loss: 0.6880877069707186
Epoch: 59 | Iteration number: [540/4518] 11% | Training loss: 0.6880718091019877
Epoch: 59 | Iteration number: [550/4518] 12% | Training loss: 0.6880588161945344
Epoch: 59 | Iteration number: [560/4518] 12% | Training loss: 0.6880255852426801
Epoch: 59 | Iteration number: [570/4518] 12% | Training loss: 0.688007521733903
Epoch: 59 | Iteration number: [580/4518] 12% | Training loss: 0.6879820116635027
Epoch: 59 | Iteration number: [590/4518] 13% | Training loss: 0.687972769494784
Epoch: 59 | Iteration number: [600/4518] 13% | Training loss: 0.6879522383213044
Epoch: 59 | Iteration number: [610/4518] 13% | Training loss: 0.6879457253901685
Epoch: 59 | Iteration number: [620/4518] 13% | Training loss: 0.6879189335530804
Epoch: 59 | Iteration number: [630/4518] 13% | Training loss: 0.687894044035957
Epoch: 59 | Iteration number: [640/4518] 14% | Training loss: 0.6878842023201287
Epoch: 59 | Iteration number: [650/4518] 14% | Training loss: 0.6878541954664084
Epoch: 59 | Iteration number: [660/4518] 14% | Training loss: 0.6878257430864103
Epoch: 59 | Iteration number: [670/4518] 14% | Training loss: 0.6878132961579223
Epoch: 59 | Iteration number: [680/4518] 15% | Training loss: 0.6877864532610949
Epoch: 59 | Iteration number: [690/4518] 15% | Training loss: 0.6877586651539457
Epoch: 59 | Iteration number: [700/4518] 15% | Training loss: 0.6877576459305627
Epoch: 59 | Iteration number: [710/4518] 15% | Training loss: 0.6877337596785854
Epoch: 59 | Iteration number: [720/4518] 15% | Training loss: 0.6877144198450778
Epoch: 59 | Iteration number: [730/4518] 16% | Training loss: 0.6877130864417716
Epoch: 59 | Iteration number: [740/4518] 16% | Training loss: 0.6876894184866467
Epoch: 59 | Iteration number: [750/4518] 16% | Training loss: 0.6876679649353027
Epoch: 59 | Iteration number: [760/4518] 16% | Training loss: 0.6876355464521208
Epoch: 59 | Iteration number: [770/4518] 17% | Training loss: 0.687623249555563
Epoch: 59 | Iteration number: [780/4518] 17% | Training loss: 0.6876299829055101
Epoch: 59 | Iteration number: [790/4518] 17% | Training loss: 0.6876223540004296
Epoch: 59 | Iteration number: [800/4518] 17% | Training loss: 0.68759781062603
Epoch: 59 | Iteration number: [810/4518] 17% | Training loss: 0.6875792259051476
Epoch: 59 | Iteration number: [820/4518] 18% | Training loss: 0.6875870753352235
Epoch: 59 | Iteration number: [830/4518] 18% | Training loss: 0.6875957762620535
Epoch: 59 | Iteration number: [840/4518] 18% | Training loss: 0.6875852627413613
Epoch: 59 | Iteration number: [850/4518] 18% | Training loss: 0.6875726656352772
Epoch: 59 | Iteration number: [860/4518] 19% | Training loss: 0.6875572181718294
Epoch: 59 | Iteration number: [870/4518] 19% | Training loss: 0.6875509163428997
Epoch: 59 | Iteration number: [880/4518] 19% | Training loss: 0.6875438870354132
Epoch: 59 | Iteration number: [890/4518] 19% | Training loss: 0.6875394933009416
Epoch: 59 | Iteration number: [900/4518] 19% | Training loss: 0.6875278993447622
Epoch: 59 | Iteration number: [910/4518] 20% | Training loss: 0.6875193242188339
Epoch: 59 | Iteration number: [920/4518] 20% | Training loss: 0.6875275357909825
Epoch: 59 | Iteration number: [930/4518] 20% | Training loss: 0.6875163354540383
Epoch: 59 | Iteration number: [940/4518] 20% | Training loss: 0.6874907041483737
Epoch: 59 | Iteration number: [950/4518] 21% | Training loss: 0.6874747773220664
Epoch: 59 | Iteration number: [960/4518] 21% | Training loss: 0.6874674856041868
Epoch: 59 | Iteration number: [970/4518] 21% | Training loss: 0.6874618752101033
Epoch: 59 | Iteration number: [980/4518] 21% | Training loss: 0.6874456960935982
Epoch: 59 | Iteration number: [990/4518] 21% | Training loss: 0.6874442066809143
Epoch: 59 | Iteration number: [1000/4518] 22% | Training loss: 0.687426197707653
Epoch: 59 | Iteration number: [1010/4518] 22% | Training loss: 0.6874090456726527
Epoch: 59 | Iteration number: [1020/4518] 22% | Training loss: 0.687405974315662
Epoch: 59 | Iteration number: [1030/4518] 22% | Training loss: 0.6874065170589002
Epoch: 59 | Iteration number: [1040/4518] 23% | Training loss: 0.687393553268451
Epoch: 59 | Iteration number: [1050/4518] 23% | Training loss: 0.6874060349805015
Epoch: 59 | Iteration number: [1060/4518] 23% | Training loss: 0.6874134965100378
Epoch: 59 | Iteration number: [1070/4518] 23% | Training loss: 0.6874177729415002
Epoch: 59 | Iteration number: [1080/4518] 23% | Training loss: 0.6874143071196698
Epoch: 59 | Iteration number: [1090/4518] 24% | Training loss: 0.6874172261548699
Epoch: 59 | Iteration number: [1100/4518] 24% | Training loss: 0.6874154667962681
Epoch: 59 | Iteration number: [1110/4518] 24% | Training loss: 0.6874185362914661
Epoch: 59 | Iteration number: [1120/4518] 24% | Training loss: 0.687410697553839
Epoch: 59 | Iteration number: [1130/4518] 25% | Training loss: 0.6874000330414393
Epoch: 59 | Iteration number: [1140/4518] 25% | Training loss: 0.6873944237566831
Epoch: 59 | Iteration number: [1150/4518] 25% | Training loss: 0.6873852882177933
Epoch: 59 | Iteration number: [1160/4518] 25% | Training loss: 0.6873782781691387
Epoch: 59 | Iteration number: [1170/4518] 25% | Training loss: 0.6873691366269038
Epoch: 59 | Iteration number: [1180/4518] 26% | Training loss: 0.687374246625577
Epoch: 59 | Iteration number: [1190/4518] 26% | Training loss: 0.6873841672885318
Epoch: 59 | Iteration number: [1200/4518] 26% | Training loss: 0.6873713986078898
Epoch: 59 | Iteration number: [1210/4518] 26% | Training loss: 0.6873563070435169
Epoch: 59 | Iteration number: [1220/4518] 27% | Training loss: 0.6873470584388639
Epoch: 59 | Iteration number: [1230/4518] 27% | Training loss: 0.6873422812155592
Epoch: 59 | Iteration number: [1240/4518] 27% | Training loss: 0.6873431153835788
Epoch: 59 | Iteration number: [1250/4518] 27% | Training loss: 0.6873486126422882
Epoch: 59 | Iteration number: [1260/4518] 27% | Training loss: 0.6873485771436539
Epoch: 59 | Iteration number: [1270/4518] 28% | Training loss: 0.6873408156117117
Epoch: 59 | Iteration number: [1280/4518] 28% | Training loss: 0.687340637575835
Epoch: 59 | Iteration number: [1290/4518] 28% | Training loss: 0.687343587478002
Epoch: 59 | Iteration number: [1300/4518] 28% | Training loss: 0.6873381350590633
Epoch: 59 | Iteration number: [1310/4518] 28% | Training loss: 0.6873214447316323
Epoch: 59 | Iteration number: [1320/4518] 29% | Training loss: 0.6873015929352153
Epoch: 59 | Iteration number: [1330/4518] 29% | Training loss: 0.6872921867478162
Epoch: 59 | Iteration number: [1340/4518] 29% | Training loss: 0.6872830166745542
Epoch: 59 | Iteration number: [1350/4518] 29% | Training loss: 0.687272596359253
Epoch: 59 | Iteration number: [1360/4518] 30% | Training loss: 0.6872693855534582
Epoch: 59 | Iteration number: [1370/4518] 30% | Training loss: 0.6872695663549604
Epoch: 59 | Iteration number: [1380/4518] 30% | Training loss: 0.6872745841741562
Epoch: 59 | Iteration number: [1390/4518] 30% | Training loss: 0.6872727136388957
Epoch: 59 | Iteration number: [1400/4518] 30% | Training loss: 0.6872603538632392
Epoch: 59 | Iteration number: [1410/4518] 31% | Training loss: 0.6872576971848806
Epoch: 59 | Iteration number: [1420/4518] 31% | Training loss: 0.6872634131303975
Epoch: 59 | Iteration number: [1430/4518] 31% | Training loss: 0.6872675691451227
Epoch: 59 | Iteration number: [1440/4518] 31% | Training loss: 0.6872648370348745
Epoch: 59 | Iteration number: [1450/4518] 32% | Training loss: 0.6872527658117229
Epoch: 59 | Iteration number: [1460/4518] 32% | Training loss: 0.6872567564657289
Epoch: 59 | Iteration number: [1470/4518] 32% | Training loss: 0.6872563291569145
Epoch: 59 | Iteration number: [1480/4518] 32% | Training loss: 0.6872492904598648
Epoch: 59 | Iteration number: [1490/4518] 32% | Training loss: 0.6872453852787914
Epoch: 59 | Iteration number: [1500/4518] 33% | Training loss: 0.6872420386870702
Epoch: 59 | Iteration number: [1510/4518] 33% | Training loss: 0.6872401901428273
Epoch: 59 | Iteration number: [1520/4518] 33% | Training loss: 0.6872436093264505
Epoch: 59 | Iteration number: [1530/4518] 33% | Training loss: 0.6872395636209475
Epoch: 59 | Iteration number: [1540/4518] 34% | Training loss: 0.6872380264780739
Epoch: 59 | Iteration number: [1550/4518] 34% | Training loss: 0.6872390184863921
Epoch: 59 | Iteration number: [1560/4518] 34% | Training loss: 0.6872268034861638
Epoch: 59 | Iteration number: [1570/4518] 34% | Training loss: 0.6872300805939231
Epoch: 59 | Iteration number: [1580/4518] 34% | Training loss: 0.6872258669967892
Epoch: 59 | Iteration number: [1590/4518] 35% | Training loss: 0.6872181564382037
Epoch: 59 | Iteration number: [1600/4518] 35% | Training loss: 0.6872186021879315
Epoch: 59 | Iteration number: [1610/4518] 35% | Training loss: 0.6872152338116806
Epoch: 59 | Iteration number: [1620/4518] 35% | Training loss: 0.6872081967415633
Epoch: 59 | Iteration number: [1630/4518] 36% | Training loss: 0.6871951225710793
Epoch: 59 | Iteration number: [1640/4518] 36% | Training loss: 0.6871890460936034
Epoch: 59 | Iteration number: [1650/4518] 36% | Training loss: 0.6871883285406865
Epoch: 59 | Iteration number: [1660/4518] 36% | Training loss: 0.6871884066297347
Epoch: 59 | Iteration number: [1670/4518] 36% | Training loss: 0.6871892370506675
Epoch: 59 | Iteration number: [1680/4518] 37% | Training loss: 0.6871851933853966
Epoch: 59 | Iteration number: [1690/4518] 37% | Training loss: 0.6871896661950286
Epoch: 59 | Iteration number: [1700/4518] 37% | Training loss: 0.6871887353588553
Epoch: 59 | Iteration number: [1710/4518] 37% | Training loss: 0.687184706975145
Epoch: 59 | Iteration number: [1720/4518] 38% | Training loss: 0.6871811771808669
Epoch: 59 | Iteration number: [1730/4518] 38% | Training loss: 0.687182789489713
Epoch: 59 | Iteration number: [1740/4518] 38% | Training loss: 0.6871790471433223
Epoch: 59 | Iteration number: [1750/4518] 38% | Training loss: 0.6871700691495622
Epoch: 59 | Iteration number: [1760/4518] 38% | Training loss: 0.6871683984656226
Epoch: 59 | Iteration number: [1770/4518] 39% | Training loss: 0.6871737837791443
Epoch: 59 | Iteration number: [1780/4518] 39% | Training loss: 0.6871740191505197
Epoch: 59 | Iteration number: [1790/4518] 39% | Training loss: 0.6871725038443198
Epoch: 59 | Iteration number: [1800/4518] 39% | Training loss: 0.6871689799759123
Epoch: 59 | Iteration number: [1810/4518] 40% | Training loss: 0.6871641706037258
Epoch: 59 | Iteration number: [1820/4518] 40% | Training loss: 0.687166554914726
Epoch: 59 | Iteration number: [1830/4518] 40% | Training loss: 0.6871649653533769
Epoch: 59 | Iteration number: [1840/4518] 40% | Training loss: 0.687160298001507
Epoch: 59 | Iteration number: [1850/4518] 40% | Training loss: 0.6871638968506375
Epoch: 59 | Iteration number: [1860/4518] 41% | Training loss: 0.6871531247772197
Epoch: 59 | Iteration number: [1870/4518] 41% | Training loss: 0.6871503702140747
Epoch: 59 | Iteration number: [1880/4518] 41% | Training loss: 0.6871495549666121
Epoch: 59 | Iteration number: [1890/4518] 41% | Training loss: 0.687154378052111
Epoch: 59 | Iteration number: [1900/4518] 42% | Training loss: 0.6871535383400165
Epoch: 59 | Iteration number: [1910/4518] 42% | Training loss: 0.6871587621603961
Epoch: 59 | Iteration number: [1920/4518] 42% | Training loss: 0.6871489195153118
Epoch: 59 | Iteration number: [1930/4518] 42% | Training loss: 0.6871495331816105
Epoch: 59 | Iteration number: [1940/4518] 42% | Training loss: 0.6871494875740759
Epoch: 59 | Iteration number: [1950/4518] 43% | Training loss: 0.6871511002075977
Epoch: 59 | Iteration number: [1960/4518] 43% | Training loss: 0.6871476990227796
Epoch: 59 | Iteration number: [1970/4518] 43% | Training loss: 0.6871474737140733
Epoch: 59 | Iteration number: [1980/4518] 43% | Training loss: 0.6871439893739392
Epoch: 59 | Iteration number: [1990/4518] 44% | Training loss: 0.6871394202038271
Epoch: 59 | Iteration number: [2000/4518] 44% | Training loss: 0.687133168131113
Epoch: 59 | Iteration number: [2010/4518] 44% | Training loss: 0.6871290185854803
Epoch: 59 | Iteration number: [2020/4518] 44% | Training loss: 0.6871297388383658
Epoch: 59 | Iteration number: [2030/4518] 44% | Training loss: 0.6871236389200088
Epoch: 59 | Iteration number: [2040/4518] 45% | Training loss: 0.6871197343749158
Epoch: 59 | Iteration number: [2050/4518] 45% | Training loss: 0.6871207460833759
Epoch: 59 | Iteration number: [2060/4518] 45% | Training loss: 0.6871238701841206
Epoch: 59 | Iteration number: [2070/4518] 45% | Training loss: 0.6871172775392947
Epoch: 59 | Iteration number: [2080/4518] 46% | Training loss: 0.6871081383182452
Epoch: 59 | Iteration number: [2090/4518] 46% | Training loss: 0.6871047779989015
Epoch: 59 | Iteration number: [2100/4518] 46% | Training loss: 0.6871040272996539
Epoch: 59 | Iteration number: [2110/4518] 46% | Training loss: 0.6870995921828735
Epoch: 59 | Iteration number: [2120/4518] 46% | Training loss: 0.687103558373901
Epoch: 59 | Iteration number: [2130/4518] 47% | Training loss: 0.6871027873715324
Epoch: 59 | Iteration number: [2140/4518] 47% | Training loss: 0.6870987692725993
Epoch: 59 | Iteration number: [2150/4518] 47% | Training loss: 0.6871022089692049
Epoch: 59 | Iteration number: [2160/4518] 47% | Training loss: 0.6870987404275823
Epoch: 59 | Iteration number: [2170/4518] 48% | Training loss: 0.6870976409329796
Epoch: 59 | Iteration number: [2180/4518] 48% | Training loss: 0.6870965497482807
Epoch: 59 | Iteration number: [2190/4518] 48% | Training loss: 0.6870963568012464
Epoch: 59 | Iteration number: [2200/4518] 48% | Training loss: 0.6870922033624216
Epoch: 59 | Iteration number: [2210/4518] 48% | Training loss: 0.6870932747875403
Epoch: 59 | Iteration number: [2220/4518] 49% | Training loss: 0.6870909033326416
Epoch: 59 | Iteration number: [2230/4518] 49% | Training loss: 0.6870969846911494
Epoch: 59 | Iteration number: [2240/4518] 49% | Training loss: 0.6870986361056566
Epoch: 59 | Iteration number: [2250/4518] 49% | Training loss: 0.6870899521774716
Epoch: 59 | Iteration number: [2260/4518] 50% | Training loss: 0.6870853803062861
Epoch: 59 | Iteration number: [2270/4518] 50% | Training loss: 0.6870840050838067
Epoch: 59 | Iteration number: [2280/4518] 50% | Training loss: 0.6870845175364562
Epoch: 59 | Iteration number: [2290/4518] 50% | Training loss: 0.6870809056092558
Epoch: 59 | Iteration number: [2300/4518] 50% | Training loss: 0.6870768655383068
Epoch: 59 | Iteration number: [2310/4518] 51% | Training loss: 0.6870794966107323
Epoch: 59 | Iteration number: [2320/4518] 51% | Training loss: 0.6870789963366657
Epoch: 59 | Iteration number: [2330/4518] 51% | Training loss: 0.6870763328454014
Epoch: 59 | Iteration number: [2340/4518] 51% | Training loss: 0.6870786368082731
Epoch: 59 | Iteration number: [2350/4518] 52% | Training loss: 0.6870755156050337
Epoch: 59 | Iteration number: [2360/4518] 52% | Training loss: 0.6870752706618632
Epoch: 59 | Iteration number: [2370/4518] 52% | Training loss: 0.6870710597259586
Epoch: 59 | Iteration number: [2380/4518] 52% | Training loss: 0.6870706933386186
Epoch: 59 | Iteration number: [2390/4518] 52% | Training loss: 0.6870713594318932
Epoch: 59 | Iteration number: [2400/4518] 53% | Training loss: 0.6870702832192183
Epoch: 59 | Iteration number: [2410/4518] 53% | Training loss: 0.6870654248103066
Epoch: 59 | Iteration number: [2420/4518] 53% | Training loss: 0.6870574365716335
Epoch: 59 | Iteration number: [2430/4518] 53% | Training loss: 0.6870556243407874
Epoch: 59 | Iteration number: [2440/4518] 54% | Training loss: 0.6870544365194977
Epoch: 59 | Iteration number: [2450/4518] 54% | Training loss: 0.687050301177161
Epoch: 59 | Iteration number: [2460/4518] 54% | Training loss: 0.6870480294634657
Epoch: 59 | Iteration number: [2470/4518] 54% | Training loss: 0.6870464206224511
Epoch: 59 | Iteration number: [2480/4518] 54% | Training loss: 0.6870456522751239
Epoch: 59 | Iteration number: [2490/4518] 55% | Training loss: 0.6870444972831082
Epoch: 59 | Iteration number: [2500/4518] 55% | Training loss: 0.6870437763690949
Epoch: 59 | Iteration number: [2510/4518] 55% | Training loss: 0.6870438968992804
Epoch: 59 | Iteration number: [2520/4518] 55% | Training loss: 0.6870458853150171
Epoch: 59 | Iteration number: [2530/4518] 55% | Training loss: 0.6870499522318482
Epoch: 59 | Iteration number: [2540/4518] 56% | Training loss: 0.6870548018789667
Epoch: 59 | Iteration number: [2550/4518] 56% | Training loss: 0.6870549999031366
Epoch: 59 | Iteration number: [2560/4518] 56% | Training loss: 0.6870532646542415
Epoch: 59 | Iteration number: [2570/4518] 56% | Training loss: 0.6870586679603339
Epoch: 59 | Iteration number: [2580/4518] 57% | Training loss: 0.6870482244001802
Epoch: 59 | Iteration number: [2590/4518] 57% | Training loss: 0.6870507205545212
Epoch: 59 | Iteration number: [2600/4518] 57% | Training loss: 0.6870474885060237
Epoch: 59 | Iteration number: [2610/4518] 57% | Training loss: 0.6870497238361972
Epoch: 59 | Iteration number: [2620/4518] 57% | Training loss: 0.6870451983377224
Epoch: 59 | Iteration number: [2630/4518] 58% | Training loss: 0.6870427503558619
Epoch: 59 | Iteration number: [2640/4518] 58% | Training loss: 0.6870425603154934
Epoch: 59 | Iteration number: [2650/4518] 58% | Training loss: 0.687044497323486
Epoch: 59 | Iteration number: [2660/4518] 58% | Training loss: 0.6870457294067942
Epoch: 59 | Iteration number: [2670/4518] 59% | Training loss: 0.687047536207942
Epoch: 59 | Iteration number: [2680/4518] 59% | Training loss: 0.687048355812457
Epoch: 59 | Iteration number: [2690/4518] 59% | Training loss: 0.6870505359979368
Epoch: 59 | Iteration number: [2700/4518] 59% | Training loss: 0.687048166041021
Epoch: 59 | Iteration number: [2710/4518] 59% | Training loss: 0.6870439274284672
Epoch: 59 | Iteration number: [2720/4518] 60% | Training loss: 0.6870406000272317
Epoch: 59 | Iteration number: [2730/4518] 60% | Training loss: 0.6870416282515823
Epoch: 59 | Iteration number: [2740/4518] 60% | Training loss: 0.6870391334712941
Epoch: 59 | Iteration number: [2750/4518] 60% | Training loss: 0.6870387749455192
Epoch: 59 | Iteration number: [2760/4518] 61% | Training loss: 0.6870376630105834
Epoch: 59 | Iteration number: [2770/4518] 61% | Training loss: 0.6870350894299655
Epoch: 59 | Iteration number: [2780/4518] 61% | Training loss: 0.6870332865620689
Epoch: 59 | Iteration number: [2790/4518] 61% | Training loss: 0.6870318114116628
Epoch: 59 | Iteration number: [2800/4518] 61% | Training loss: 0.6870326936244965
Epoch: 59 | Iteration number: [2810/4518] 62% | Training loss: 0.6870362394008772
Epoch: 59 | Iteration number: [2820/4518] 62% | Training loss: 0.6870313723882039
Epoch: 59 | Iteration number: [2830/4518] 62% | Training loss: 0.6870267897317772
Epoch: 59 | Iteration number: [2840/4518] 62% | Training loss: 0.6870227970707584
Epoch: 59 | Iteration number: [2850/4518] 63% | Training loss: 0.6870210139374984
Epoch: 59 | Iteration number: [2860/4518] 63% | Training loss: 0.687023932762913
Epoch: 59 | Iteration number: [2870/4518] 63% | Training loss: 0.6870205916386448
Epoch: 59 | Iteration number: [2880/4518] 63% | Training loss: 0.6870179248352846
Epoch: 59 | Iteration number: [2890/4518] 63% | Training loss: 0.6870156999896554
Epoch: 59 | Iteration number: [2900/4518] 64% | Training loss: 0.6870165115183797
Epoch: 59 | Iteration number: [2910/4518] 64% | Training loss: 0.6870184346982294
Epoch: 59 | Iteration number: [2920/4518] 64% | Training loss: 0.6870174018895789
Epoch: 59 | Iteration number: [2930/4518] 64% | Training loss: 0.687013445657268
Epoch: 59 | Iteration number: [2940/4518] 65% | Training loss: 0.6870099855118057
Epoch: 59 | Iteration number: [2950/4518] 65% | Training loss: 0.6870079894389136
Epoch: 59 | Iteration number: [2960/4518] 65% | Training loss: 0.6870055152153647
Epoch: 59 | Iteration number: [2970/4518] 65% | Training loss: 0.6870012533785117
Epoch: 59 | Iteration number: [2980/4518] 65% | Training loss: 0.6869965028642808
Epoch: 59 | Iteration number: [2990/4518] 66% | Training loss: 0.6869961152906003
Epoch: 59 | Iteration number: [3000/4518] 66% | Training loss: 0.6869926977753639
Epoch: 59 | Iteration number: [3010/4518] 66% | Training loss: 0.6869917224015905
Epoch: 59 | Iteration number: [3020/4518] 66% | Training loss: 0.6869907934539365
Epoch: 59 | Iteration number: [3030/4518] 67% | Training loss: 0.6869860276924108
Epoch: 59 | Iteration number: [3040/4518] 67% | Training loss: 0.6869867978519515
Epoch: 59 | Iteration number: [3050/4518] 67% | Training loss: 0.6869854577056698
Epoch: 59 | Iteration number: [3060/4518] 67% | Training loss: 0.6869880812814813
Epoch: 59 | Iteration number: [3070/4518] 67% | Training loss: 0.6869857130105022
Epoch: 59 | Iteration number: [3080/4518] 68% | Training loss: 0.6869848733792058
Epoch: 59 | Iteration number: [3090/4518] 68% | Training loss: 0.6869845792892295
Epoch: 59 | Iteration number: [3100/4518] 68% | Training loss: 0.6869821129498943
Epoch: 59 | Iteration number: [3110/4518] 68% | Training loss: 0.6869855107793471
Epoch: 59 | Iteration number: [3120/4518] 69% | Training loss: 0.6869839909176032
Epoch: 59 | Iteration number: [3130/4518] 69% | Training loss: 0.6869804074208196
Epoch: 59 | Iteration number: [3140/4518] 69% | Training loss: 0.6869775256913179
Epoch: 59 | Iteration number: [3150/4518] 69% | Training loss: 0.6869798669739375
Epoch: 59 | Iteration number: [3160/4518] 69% | Training loss: 0.6869848963957799
Epoch: 59 | Iteration number: [3170/4518] 70% | Training loss: 0.6869823456750683
Epoch: 59 | Iteration number: [3180/4518] 70% | Training loss: 0.686982693968329
Epoch: 59 | Iteration number: [3190/4518] 70% | Training loss: 0.6869825800945019
Epoch: 59 | Iteration number: [3200/4518] 70% | Training loss: 0.6869779886677861
Epoch: 59 | Iteration number: [3210/4518] 71% | Training loss: 0.6869765020419504
Epoch: 59 | Iteration number: [3220/4518] 71% | Training loss: 0.6869799048448941
Epoch: 59 | Iteration number: [3230/4518] 71% | Training loss: 0.6869810984230632
Epoch: 59 | Iteration number: [3240/4518] 71% | Training loss: 0.6869817955810347
Epoch: 59 | Iteration number: [3250/4518] 71% | Training loss: 0.6869816858585064
Epoch: 59 | Iteration number: [3260/4518] 72% | Training loss: 0.6869750085601046
Epoch: 59 | Iteration number: [3270/4518] 72% | Training loss: 0.6869703875222337
Epoch: 59 | Iteration number: [3280/4518] 72% | Training loss: 0.686969552479866
Epoch: 59 | Iteration number: [3290/4518] 72% | Training loss: 0.6869704991488471
Epoch: 59 | Iteration number: [3300/4518] 73% | Training loss: 0.6869718452114048
Epoch: 59 | Iteration number: [3310/4518] 73% | Training loss: 0.6869716833725437
Epoch: 59 | Iteration number: [3320/4518] 73% | Training loss: 0.6869708536439632
Epoch: 59 | Iteration number: [3330/4518] 73% | Training loss: 0.6869703607695239
Epoch: 59 | Iteration number: [3340/4518] 73% | Training loss: 0.6869672811673787
Epoch: 59 | Iteration number: [3350/4518] 74% | Training loss: 0.6869664455349765
Epoch: 59 | Iteration number: [3360/4518] 74% | Training loss: 0.6869659904922758
Epoch: 59 | Iteration number: [3370/4518] 74% | Training loss: 0.6869674569598291
Epoch: 59 | Iteration number: [3380/4518] 74% | Training loss: 0.686967784889351
Epoch: 59 | Iteration number: [3390/4518] 75% | Training loss: 0.686966798280896
Epoch: 59 | Iteration number: [3400/4518] 75% | Training loss: 0.6869639455570894
Epoch: 59 | Iteration number: [3410/4518] 75% | Training loss: 0.6869621484685154
Epoch: 59 | Iteration number: [3420/4518] 75% | Training loss: 0.6869630418848574
Epoch: 59 | Iteration number: [3430/4518] 75% | Training loss: 0.6869657983063956
Epoch: 59 | Iteration number: [3440/4518] 76% | Training loss: 0.6869661034886227
Epoch: 59 | Iteration number: [3450/4518] 76% | Training loss: 0.686963442598564
Epoch: 59 | Iteration number: [3460/4518] 76% | Training loss: 0.6869630573285108
Epoch: 59 | Iteration number: [3470/4518] 76% | Training loss: 0.6869648166451743
Epoch: 59 | Iteration number: [3480/4518] 77% | Training loss: 0.6869637767473856
Epoch: 59 | Iteration number: [3490/4518] 77% | Training loss: 0.6869625030411007
Epoch: 59 | Iteration number: [3500/4518] 77% | Training loss: 0.6869600957291467
Epoch: 59 | Iteration number: [3510/4518] 77% | Training loss: 0.6869603319894894
Epoch: 59 | Iteration number: [3520/4518] 77% | Training loss: 0.6869621236385269
Epoch: 59 | Iteration number: [3530/4518] 78% | Training loss: 0.6869633164689494
Epoch: 59 | Iteration number: [3540/4518] 78% | Training loss: 0.6869633577637754
Epoch: 59 | Iteration number: [3550/4518] 78% | Training loss: 0.6869618777154197
Epoch: 59 | Iteration number: [3560/4518] 78% | Training loss: 0.6869644896367962
Epoch: 59 | Iteration number: [3570/4518] 79% | Training loss: 0.6869658149591014
Epoch: 59 | Iteration number: [3580/4518] 79% | Training loss: 0.6869642657607627
Epoch: 59 | Iteration number: [3590/4518] 79% | Training loss: 0.6869613640985781
Epoch: 59 | Iteration number: [3600/4518] 79% | Training loss: 0.6869633099933465
Epoch: 59 | Iteration number: [3610/4518] 79% | Training loss: 0.686964262357379
Epoch: 59 | Iteration number: [3620/4518] 80% | Training loss: 0.6869596534671045
Epoch: 59 | Iteration number: [3630/4518] 80% | Training loss: 0.6869578698942483
Epoch: 59 | Iteration number: [3640/4518] 80% | Training loss: 0.6869588468919744
Epoch: 59 | Iteration number: [3650/4518] 80% | Training loss: 0.6869550042446345
Epoch: 59 | Iteration number: [3660/4518] 81% | Training loss: 0.6869571549482033
Epoch: 59 | Iteration number: [3670/4518] 81% | Training loss: 0.686956669816529
Epoch: 59 | Iteration number: [3680/4518] 81% | Training loss: 0.6869566091052864
Epoch: 59 | Iteration number: [3690/4518] 81% | Training loss: 0.6869530955788888
Epoch: 59 | Iteration number: [3700/4518] 81% | Training loss: 0.6869529760367161
Epoch: 59 | Iteration number: [3710/4518] 82% | Training loss: 0.6869534416340111
Epoch: 59 | Iteration number: [3720/4518] 82% | Training loss: 0.6869525806237292
Epoch: 59 | Iteration number: [3730/4518] 82% | Training loss: 0.6869490142642013
Epoch: 59 | Iteration number: [3740/4518] 82% | Training loss: 0.6869506634014813
Epoch: 59 | Iteration number: [3750/4518] 83% | Training loss: 0.6869479834397634
Epoch: 59 | Iteration number: [3760/4518] 83% | Training loss: 0.6869467391771205
Epoch: 59 | Iteration number: [3770/4518] 83% | Training loss: 0.6869465840115787
Epoch: 59 | Iteration number: [3780/4518] 83% | Training loss: 0.6869463651426255
Epoch: 59 | Iteration number: [3790/4518] 83% | Training loss: 0.6869451220400415
Epoch: 59 | Iteration number: [3800/4518] 84% | Training loss: 0.686940709195639
Epoch: 59 | Iteration number: [3810/4518] 84% | Training loss: 0.6869401938333286
Epoch: 59 | Iteration number: [3820/4518] 84% | Training loss: 0.6869389747605898
Epoch: 59 | Iteration number: [3830/4518] 84% | Training loss: 0.6869386405297422
Epoch: 59 | Iteration number: [3840/4518] 84% | Training loss: 0.6869411378012349
Epoch: 59 | Iteration number: [3850/4518] 85% | Training loss: 0.6869394758459809
Epoch: 59 | Iteration number: [3860/4518] 85% | Training loss: 0.6869388858734635
Epoch: 59 | Iteration number: [3870/4518] 85% | Training loss: 0.6869402040652834
Epoch: 59 | Iteration number: [3880/4518] 85% | Training loss: 0.68693949044058
Epoch: 59 | Iteration number: [3890/4518] 86% | Training loss: 0.6869404439141634
Epoch: 59 | Iteration number: [3900/4518] 86% | Training loss: 0.6869408241143593
Epoch: 59 | Iteration number: [3910/4518] 86% | Training loss: 0.6869419936328898
Epoch: 59 | Iteration number: [3920/4518] 86% | Training loss: 0.6869391067447711
Epoch: 59 | Iteration number: [3930/4518] 86% | Training loss: 0.6869406967369351
Epoch: 59 | Iteration number: [3940/4518] 87% | Training loss: 0.6869444487361134
Epoch: 59 | Iteration number: [3950/4518] 87% | Training loss: 0.686943568036526
Epoch: 59 | Iteration number: [3960/4518] 87% | Training loss: 0.6869454476869468
Epoch: 59 | Iteration number: [3970/4518] 87% | Training loss: 0.6869446083190159
Epoch: 59 | Iteration number: [3980/4518] 88% | Training loss: 0.6869482219668489
Epoch: 59 | Iteration number: [3990/4518] 88% | Training loss: 0.686948168322556
Epoch: 59 | Iteration number: [4000/4518] 88% | Training loss: 0.6869505263119936
Epoch: 59 | Iteration number: [4010/4518] 88% | Training loss: 0.6869491028964073
Epoch: 59 | Iteration number: [4020/4518] 88% | Training loss: 0.6869520581035472
Epoch: 59 | Iteration number: [4030/4518] 89% | Training loss: 0.6869510894673634
Epoch: 59 | Iteration number: [4040/4518] 89% | Training loss: 0.6869511038802638
Epoch: 59 | Iteration number: [4050/4518] 89% | Training loss: 0.6869516839362957
Epoch: 59 | Iteration number: [4060/4518] 89% | Training loss: 0.686953533870246
Epoch: 59 | Iteration number: [4070/4518] 90% | Training loss: 0.6869512816758355
Epoch: 59 | Iteration number: [4080/4518] 90% | Training loss: 0.6869521251496147
Epoch: 59 | Iteration number: [4090/4518] 90% | Training loss: 0.6869532367128032
Epoch: 59 | Iteration number: [4100/4518] 90% | Training loss: 0.6869538856134182
Epoch: 59 | Iteration number: [4110/4518] 90% | Training loss: 0.6869568163606082
Epoch: 59 | Iteration number: [4120/4518] 91% | Training loss: 0.6869542880833728
Epoch: 59 | Iteration number: [4130/4518] 91% | Training loss: 0.6869547281224849
Epoch: 59 | Iteration number: [4140/4518] 91% | Training loss: 0.68695287498587
Epoch: 59 | Iteration number: [4150/4518] 91% | Training loss: 0.6869509841735104
Epoch: 59 | Iteration number: [4160/4518] 92% | Training loss: 0.686949530387154
Epoch: 59 | Iteration number: [4170/4518] 92% | Training loss: 0.6869518737855861
Epoch: 59 | Iteration number: [4180/4518] 92% | Training loss: 0.6869504767314099
Epoch: 59 | Iteration number: [4190/4518] 92% | Training loss: 0.6869497992685132
Epoch: 59 | Iteration number: [4200/4518] 92% | Training loss: 0.6869480971069563
Epoch: 59 | Iteration number: [4210/4518] 93% | Training loss: 0.6869477474066538
Epoch: 59 | Iteration number: [4220/4518] 93% | Training loss: 0.6869493859356613
Epoch: 59 | Iteration number: [4230/4518] 93% | Training loss: 0.6869513074416077
Epoch: 59 | Iteration number: [4240/4518] 93% | Training loss: 0.6869541124493446
Epoch: 59 | Iteration number: [4250/4518] 94% | Training loss: 0.6869533100969651
Epoch: 59 | Iteration number: [4260/4518] 94% | Training loss: 0.6869545033979864
Epoch: 59 | Iteration number: [4270/4518] 94% | Training loss: 0.6869536957221511
Epoch: 59 | Iteration number: [4280/4518] 94% | Training loss: 0.68695170145447
Epoch: 59 | Iteration number: [4290/4518] 94% | Training loss: 0.686952820732877
Epoch: 59 | Iteration number: [4300/4518] 95% | Training loss: 0.6869524371346762
Epoch: 59 | Iteration number: [4310/4518] 95% | Training loss: 0.6869522424972251
Epoch: 59 | Iteration number: [4320/4518] 95% | Training loss: 0.6869501909448041
Epoch: 59 | Iteration number: [4330/4518] 95% | Training loss: 0.6869507948878731
Epoch: 59 | Iteration number: [4340/4518] 96% | Training loss: 0.6869496841309807
Epoch: 59 | Iteration number: [4350/4518] 96% | Training loss: 0.6869465338361674
Epoch: 59 | Iteration number: [4360/4518] 96% | Training loss: 0.6869478304861882
Epoch: 59 | Iteration number: [4370/4518] 96% | Training loss: 0.6869448159733953
Epoch: 59 | Iteration number: [4380/4518] 96% | Training loss: 0.6869421099555002
Epoch: 59 | Iteration number: [4390/4518] 97% | Training loss: 0.6869420829829431
Epoch: 59 | Iteration number: [4400/4518] 97% | Training loss: 0.6869462596150961
Epoch: 59 | Iteration number: [4410/4518] 97% | Training loss: 0.6869479162082109
Epoch: 59 | Iteration number: [4420/4518] 97% | Training loss: 0.6869466784178402
Epoch: 59 | Iteration number: [4430/4518] 98% | Training loss: 0.6869480560380233
Epoch: 59 | Iteration number: [4440/4518] 98% | Training loss: 0.6869498953491718
Epoch: 59 | Iteration number: [4450/4518] 98% | Training loss: 0.6869462207328068
Epoch: 59 | Iteration number: [4460/4518] 98% | Training loss: 0.6869464187076808
Epoch: 59 | Iteration number: [4470/4518] 98% | Training loss: 0.6869459895479599
Epoch: 59 | Iteration number: [4480/4518] 99% | Training loss: 0.6869410965325576
Epoch: 59 | Iteration number: [4490/4518] 99% | Training loss: 0.6869424962254038
Epoch: 59 | Iteration number: [4500/4518] 99% | Training loss: 0.6869436934789022
Epoch: 59 | Iteration number: [4510/4518] 99% | Training loss: 0.6869426932276749

 End of epoch: 59 | Train Loss: 0.6867910325527191 | Training Time: 633 

 End of epoch: 59 | Eval Loss: 0.6897946352861366 | Evaluating Time: 17 
Epoch: 60 | Iteration number: [10/4518] 0% | Training loss: 0.7547452270984649
Epoch: 60 | Iteration number: [20/4518] 0% | Training loss: 0.7203253298997879
Epoch: 60 | Iteration number: [30/4518] 0% | Training loss: 0.7096337477366129
Epoch: 60 | Iteration number: [40/4518] 0% | Training loss: 0.7036522522568702
Epoch: 60 | Iteration number: [50/4518] 1% | Training loss: 0.7001270258426666
Epoch: 60 | Iteration number: [60/4518] 1% | Training loss: 0.6978910088539123
Epoch: 60 | Iteration number: [70/4518] 1% | Training loss: 0.696140821490969
Epoch: 60 | Iteration number: [80/4518] 1% | Training loss: 0.6949758626520633
Epoch: 60 | Iteration number: [90/4518] 1% | Training loss: 0.6941026310125987
Epoch: 60 | Iteration number: [100/4518] 2% | Training loss: 0.6933406084775925
Epoch: 60 | Iteration number: [110/4518] 2% | Training loss: 0.6926866439255801
Epoch: 60 | Iteration number: [120/4518] 2% | Training loss: 0.6923253163695335
Epoch: 60 | Iteration number: [130/4518] 2% | Training loss: 0.6918294764482058
Epoch: 60 | Iteration number: [140/4518] 3% | Training loss: 0.6914056492703301
Epoch: 60 | Iteration number: [150/4518] 3% | Training loss: 0.6910195672512054
Epoch: 60 | Iteration number: [160/4518] 3% | Training loss: 0.690749529749155
Epoch: 60 | Iteration number: [170/4518] 3% | Training loss: 0.6905434541842517
Epoch: 60 | Iteration number: [180/4518] 3% | Training loss: 0.6904197792212169
Epoch: 60 | Iteration number: [190/4518] 4% | Training loss: 0.6902162940878617
Epoch: 60 | Iteration number: [200/4518] 4% | Training loss: 0.6900767686963082
Epoch: 60 | Iteration number: [210/4518] 4% | Training loss: 0.6899025758107503
Epoch: 60 | Iteration number: [220/4518] 4% | Training loss: 0.6897766438397495
Epoch: 60 | Iteration number: [230/4518] 5% | Training loss: 0.6896164857822916
Epoch: 60 | Iteration number: [240/4518] 5% | Training loss: 0.6895113497972488
Epoch: 60 | Iteration number: [250/4518] 5% | Training loss: 0.6894427535533905
Epoch: 60 | Iteration number: [260/4518] 5% | Training loss: 0.6893358377309946
Epoch: 60 | Iteration number: [270/4518] 5% | Training loss: 0.6892685033656932
Epoch: 60 | Iteration number: [280/4518] 6% | Training loss: 0.6891742257135255
Epoch: 60 | Iteration number: [290/4518] 6% | Training loss: 0.6891364636092351
Epoch: 60 | Iteration number: [300/4518] 6% | Training loss: 0.6890337504943211
Epoch: 60 | Iteration number: [310/4518] 6% | Training loss: 0.6889553746869487
Epoch: 60 | Iteration number: [320/4518] 7% | Training loss: 0.6888888094574213
Epoch: 60 | Iteration number: [330/4518] 7% | Training loss: 0.6888299326101939
Epoch: 60 | Iteration number: [340/4518] 7% | Training loss: 0.6887890526477028
Epoch: 60 | Iteration number: [350/4518] 7% | Training loss: 0.6887610995769501
Epoch: 60 | Iteration number: [360/4518] 7% | Training loss: 0.6887302123838001
Epoch: 60 | Iteration number: [370/4518] 8% | Training loss: 0.6886688021389213
Epoch: 60 | Iteration number: [380/4518] 8% | Training loss: 0.6885897401132082
Epoch: 60 | Iteration number: [390/4518] 8% | Training loss: 0.6885513400420165
Epoch: 60 | Iteration number: [400/4518] 8% | Training loss: 0.6885352122783661
Epoch: 60 | Iteration number: [410/4518] 9% | Training loss: 0.6884529769420624
Epoch: 60 | Iteration number: [420/4518] 9% | Training loss: 0.6884056802306856
Epoch: 60 | Iteration number: [430/4518] 9% | Training loss: 0.6883818805217743
Epoch: 60 | Iteration number: [440/4518] 9% | Training loss: 0.6883511644872752
Epoch: 60 | Iteration number: [450/4518] 9% | Training loss: 0.6883123286565145
Epoch: 60 | Iteration number: [460/4518] 10% | Training loss: 0.6882728610349738
Epoch: 60 | Iteration number: [470/4518] 10% | Training loss: 0.6882235336810985
Epoch: 60 | Iteration number: [480/4518] 10% | Training loss: 0.6881969145188729
Epoch: 60 | Iteration number: [490/4518] 10% | Training loss: 0.6881479982210665
Epoch: 60 | Iteration number: [500/4518] 11% | Training loss: 0.6881369110345841
Epoch: 60 | Iteration number: [510/4518] 11% | Training loss: 0.6881331032397701
Epoch: 60 | Iteration number: [520/4518] 11% | Training loss: 0.6881319849536969
Epoch: 60 | Iteration number: [530/4518] 11% | Training loss: 0.6881169346143614
Epoch: 60 | Iteration number: [540/4518] 11% | Training loss: 0.6880903490163662
Epoch: 60 | Iteration number: [550/4518] 12% | Training loss: 0.6880419977144762
Epoch: 60 | Iteration number: [560/4518] 12% | Training loss: 0.688003621250391
Epoch: 60 | Iteration number: [570/4518] 12% | Training loss: 0.6880103798289048
Epoch: 60 | Iteration number: [580/4518] 12% | Training loss: 0.6879752224889295
Epoch: 60 | Iteration number: [590/4518] 13% | Training loss: 0.6879354908304699
Epoch: 60 | Iteration number: [600/4518] 13% | Training loss: 0.6879142713546753
Epoch: 60 | Iteration number: [610/4518] 13% | Training loss: 0.6879045113188321
Epoch: 60 | Iteration number: [620/4518] 13% | Training loss: 0.6879044499128095
Epoch: 60 | Iteration number: [630/4518] 13% | Training loss: 0.6878811616746207
Epoch: 60 | Iteration number: [640/4518] 14% | Training loss: 0.6878679453395307
Epoch: 60 | Iteration number: [650/4518] 14% | Training loss: 0.6878419644099015
Epoch: 60 | Iteration number: [660/4518] 14% | Training loss: 0.6878425637880962
Epoch: 60 | Iteration number: [670/4518] 14% | Training loss: 0.6878271549495298
Epoch: 60 | Iteration number: [680/4518] 15% | Training loss: 0.6878120226895108
Epoch: 60 | Iteration number: [690/4518] 15% | Training loss: 0.6878182197826496
Epoch: 60 | Iteration number: [700/4518] 15% | Training loss: 0.687785176890237
Epoch: 60 | Iteration number: [710/4518] 15% | Training loss: 0.687772156654949
Epoch: 60 | Iteration number: [720/4518] 15% | Training loss: 0.6877593620783753
Epoch: 60 | Iteration number: [730/4518] 16% | Training loss: 0.6877597788425341
Epoch: 60 | Iteration number: [740/4518] 16% | Training loss: 0.6877488417399896
Epoch: 60 | Iteration number: [750/4518] 16% | Training loss: 0.6877076880931854
Epoch: 60 | Iteration number: [760/4518] 16% | Training loss: 0.687704138379348
Epoch: 60 | Iteration number: [770/4518] 17% | Training loss: 0.6876762888648293
Epoch: 60 | Iteration number: [780/4518] 17% | Training loss: 0.6876780027762438
Epoch: 60 | Iteration number: [790/4518] 17% | Training loss: 0.6876551796363879
Epoch: 60 | Iteration number: [800/4518] 17% | Training loss: 0.6876439011842013
Epoch: 60 | Iteration number: [810/4518] 17% | Training loss: 0.6876434756649865
Epoch: 60 | Iteration number: [820/4518] 18% | Training loss: 0.6876439233378666
Epoch: 60 | Iteration number: [830/4518] 18% | Training loss: 0.6876659489539733
Epoch: 60 | Iteration number: [840/4518] 18% | Training loss: 0.6876550439567793
Epoch: 60 | Iteration number: [850/4518] 18% | Training loss: 0.687643174423891
Epoch: 60 | Iteration number: [860/4518] 19% | Training loss: 0.6876343371563179
Epoch: 60 | Iteration number: [870/4518] 19% | Training loss: 0.6876244870410568
Epoch: 60 | Iteration number: [880/4518] 19% | Training loss: 0.6876103701916608
Epoch: 60 | Iteration number: [890/4518] 19% | Training loss: 0.6875987898097949
Epoch: 60 | Iteration number: [900/4518] 19% | Training loss: 0.6875917149914635
Epoch: 60 | Iteration number: [910/4518] 20% | Training loss: 0.6875845185347966
Epoch: 60 | Iteration number: [920/4518] 20% | Training loss: 0.687575839848622
Epoch: 60 | Iteration number: [930/4518] 20% | Training loss: 0.6875685117577994
Epoch: 60 | Iteration number: [940/4518] 20% | Training loss: 0.6875584706981132
Epoch: 60 | Iteration number: [950/4518] 21% | Training loss: 0.6875524241673319
Epoch: 60 | Iteration number: [960/4518] 21% | Training loss: 0.687524859358867
Epoch: 60 | Iteration number: [970/4518] 21% | Training loss: 0.6875266579623075
Epoch: 60 | Iteration number: [980/4518] 21% | Training loss: 0.6875098621966887
Epoch: 60 | Iteration number: [990/4518] 21% | Training loss: 0.6875048007025863
Epoch: 60 | Iteration number: [1000/4518] 22% | Training loss: 0.687502562046051
Epoch: 60 | Iteration number: [1010/4518] 22% | Training loss: 0.6874944068417691
Epoch: 60 | Iteration number: [1020/4518] 22% | Training loss: 0.6874770797350828
Epoch: 60 | Iteration number: [1030/4518] 22% | Training loss: 0.687471220273416
Epoch: 60 | Iteration number: [1040/4518] 23% | Training loss: 0.6874787197663234
Epoch: 60 | Iteration number: [1050/4518] 23% | Training loss: 0.687483590443929
Epoch: 60 | Iteration number: [1060/4518] 23% | Training loss: 0.687467053926216
Epoch: 60 | Iteration number: [1070/4518] 23% | Training loss: 0.6874596097201945
Epoch: 60 | Iteration number: [1080/4518] 23% | Training loss: 0.6874462120510914
Epoch: 60 | Iteration number: [1090/4518] 24% | Training loss: 0.6874500838441586
Epoch: 60 | Iteration number: [1100/4518] 24% | Training loss: 0.6874418979883195
Epoch: 60 | Iteration number: [1110/4518] 24% | Training loss: 0.6874355848845061
Epoch: 60 | Iteration number: [1120/4518] 24% | Training loss: 0.6874329604740653
Epoch: 60 | Iteration number: [1130/4518] 25% | Training loss: 0.6874402519348448
Epoch: 60 | Iteration number: [1140/4518] 25% | Training loss: 0.6874368280172348
Epoch: 60 | Iteration number: [1150/4518] 25% | Training loss: 0.6874262608652529
Epoch: 60 | Iteration number: [1160/4518] 25% | Training loss: 0.6874211767110331
Epoch: 60 | Iteration number: [1170/4518] 25% | Training loss: 0.687423885683728
Epoch: 60 | Iteration number: [1180/4518] 26% | Training loss: 0.6874176208245553
Epoch: 60 | Iteration number: [1190/4518] 26% | Training loss: 0.6874157746298974
Epoch: 60 | Iteration number: [1200/4518] 26% | Training loss: 0.6873996081451575
Epoch: 60 | Iteration number: [1210/4518] 26% | Training loss: 0.6873940364388395
Epoch: 60 | Iteration number: [1220/4518] 27% | Training loss: 0.6873961302589198
Epoch: 60 | Iteration number: [1230/4518] 27% | Training loss: 0.6873840518598634
Epoch: 60 | Iteration number: [1240/4518] 27% | Training loss: 0.6873828838429143
Epoch: 60 | Iteration number: [1250/4518] 27% | Training loss: 0.6873766057014465
Epoch: 60 | Iteration number: [1260/4518] 27% | Training loss: 0.6873697354206963
Epoch: 60 | Iteration number: [1270/4518] 28% | Training loss: 0.6873754607410881
Epoch: 60 | Iteration number: [1280/4518] 28% | Training loss: 0.687369548343122
Epoch: 60 | Iteration number: [1290/4518] 28% | Training loss: 0.687375244059304
Epoch: 60 | Iteration number: [1300/4518] 28% | Training loss: 0.6873757488452471
Epoch: 60 | Iteration number: [1310/4518] 28% | Training loss: 0.6873676763691065
Epoch: 60 | Iteration number: [1320/4518] 29% | Training loss: 0.6873717710827336
Epoch: 60 | Iteration number: [1330/4518] 29% | Training loss: 0.6873587590411193
Epoch: 60 | Iteration number: [1340/4518] 29% | Training loss: 0.687360999833292
Epoch: 60 | Iteration number: [1350/4518] 29% | Training loss: 0.6873528797979708
Epoch: 60 | Iteration number: [1360/4518] 30% | Training loss: 0.6873446630204425
Epoch: 60 | Iteration number: [1370/4518] 30% | Training loss: 0.6873483980659151
Epoch: 60 | Iteration number: [1380/4518] 30% | Training loss: 0.687339773212654
Epoch: 60 | Iteration number: [1390/4518] 30% | Training loss: 0.6873407682068914
Epoch: 60 | Iteration number: [1400/4518] 30% | Training loss: 0.6873358740125384
Epoch: 60 | Iteration number: [1410/4518] 31% | Training loss: 0.6873321564907723
Epoch: 60 | Iteration number: [1420/4518] 31% | Training loss: 0.6873309624446949
Epoch: 60 | Iteration number: [1430/4518] 31% | Training loss: 0.6873215069720795
Epoch: 60 | Iteration number: [1440/4518] 31% | Training loss: 0.6873200250168642
Epoch: 60 | Iteration number: [1450/4518] 32% | Training loss: 0.6873129332065582
Epoch: 60 | Iteration number: [1460/4518] 32% | Training loss: 0.6873052677879595
Epoch: 60 | Iteration number: [1470/4518] 32% | Training loss: 0.6873003960872183
Epoch: 60 | Iteration number: [1480/4518] 32% | Training loss: 0.6873008746553112
Epoch: 60 | Iteration number: [1490/4518] 32% | Training loss: 0.6872924057429269
Epoch: 60 | Iteration number: [1500/4518] 33% | Training loss: 0.68729884882768
Epoch: 60 | Iteration number: [1510/4518] 33% | Training loss: 0.6873002362567068
Epoch: 60 | Iteration number: [1520/4518] 33% | Training loss: 0.687288987283644
Epoch: 60 | Iteration number: [1530/4518] 33% | Training loss: 0.6872873868038452
Epoch: 60 | Iteration number: [1540/4518] 34% | Training loss: 0.6872795375136586
Epoch: 60 | Iteration number: [1550/4518] 34% | Training loss: 0.6872768564378061
Epoch: 60 | Iteration number: [1560/4518] 34% | Training loss: 0.6872730282636789
Epoch: 60 | Iteration number: [1570/4518] 34% | Training loss: 0.6872611649856446
Epoch: 60 | Iteration number: [1580/4518] 34% | Training loss: 0.687247743561298
Epoch: 60 | Iteration number: [1590/4518] 35% | Training loss: 0.6872380083461977
Epoch: 60 | Iteration number: [1600/4518] 35% | Training loss: 0.6872322774678469
Epoch: 60 | Iteration number: [1610/4518] 35% | Training loss: 0.6872276208415535
Epoch: 60 | Iteration number: [1620/4518] 35% | Training loss: 0.6872166775258971
Epoch: 60 | Iteration number: [1630/4518] 36% | Training loss: 0.6872126380724409
Epoch: 60 | Iteration number: [1640/4518] 36% | Training loss: 0.6872055893627609
Epoch: 60 | Iteration number: [1650/4518] 36% | Training loss: 0.6872128905310775
Epoch: 60 | Iteration number: [1660/4518] 36% | Training loss: 0.6872048854109752
Epoch: 60 | Iteration number: [1670/4518] 36% | Training loss: 0.6871959563857781
Epoch: 60 | Iteration number: [1680/4518] 37% | Training loss: 0.6871977576187679
Epoch: 60 | Iteration number: [1690/4518] 37% | Training loss: 0.6871941049776134
Epoch: 60 | Iteration number: [1700/4518] 37% | Training loss: 0.6871873859096976
Epoch: 60 | Iteration number: [1710/4518] 37% | Training loss: 0.6871943205072168
Epoch: 60 | Iteration number: [1720/4518] 38% | Training loss: 0.6871954786916111
Epoch: 60 | Iteration number: [1730/4518] 38% | Training loss: 0.6871912454938613
Epoch: 60 | Iteration number: [1740/4518] 38% | Training loss: 0.6871842954350614
Epoch: 60 | Iteration number: [1750/4518] 38% | Training loss: 0.6871829399721963
Epoch: 60 | Iteration number: [1760/4518] 38% | Training loss: 0.6871822422539646
Epoch: 60 | Iteration number: [1770/4518] 39% | Training loss: 0.6871785898329847
Epoch: 60 | Iteration number: [1780/4518] 39% | Training loss: 0.6871694931823216
Epoch: 60 | Iteration number: [1790/4518] 39% | Training loss: 0.6871723113446262
Epoch: 60 | Iteration number: [1800/4518] 39% | Training loss: 0.6871616799301571
Epoch: 60 | Iteration number: [1810/4518] 40% | Training loss: 0.6871597295307982
Epoch: 60 | Iteration number: [1820/4518] 40% | Training loss: 0.6871553215351733
Epoch: 60 | Iteration number: [1830/4518] 40% | Training loss: 0.6871516309149278
Epoch: 60 | Iteration number: [1840/4518] 40% | Training loss: 0.6871506971185622
Epoch: 60 | Iteration number: [1850/4518] 40% | Training loss: 0.6871476396676657
Epoch: 60 | Iteration number: [1860/4518] 41% | Training loss: 0.6871442417944631
Epoch: 60 | Iteration number: [1870/4518] 41% | Training loss: 0.6871445824436963
Epoch: 60 | Iteration number: [1880/4518] 41% | Training loss: 0.6871341997638661
Epoch: 60 | Iteration number: [1890/4518] 41% | Training loss: 0.6871288923990159
Epoch: 60 | Iteration number: [1900/4518] 42% | Training loss: 0.6871210714076694
Epoch: 60 | Iteration number: [1910/4518] 42% | Training loss: 0.6871139161873863
Epoch: 60 | Iteration number: [1920/4518] 42% | Training loss: 0.68710892284289
Epoch: 60 | Iteration number: [1930/4518] 42% | Training loss: 0.6871117422000114
Epoch: 60 | Iteration number: [1940/4518] 42% | Training loss: 0.6871137045093418
Epoch: 60 | Iteration number: [1950/4518] 43% | Training loss: 0.6871078252486693
Epoch: 60 | Iteration number: [1960/4518] 43% | Training loss: 0.6871095147363994
Epoch: 60 | Iteration number: [1970/4518] 43% | Training loss: 0.6871139870682343
Epoch: 60 | Iteration number: [1980/4518] 43% | Training loss: 0.6871150185664495
Epoch: 60 | Iteration number: [1990/4518] 44% | Training loss: 0.6871107720549982
Epoch: 60 | Iteration number: [2000/4518] 44% | Training loss: 0.6871036248803138
Epoch: 60 | Iteration number: [2010/4518] 44% | Training loss: 0.6870981690895498
Epoch: 60 | Iteration number: [2020/4518] 44% | Training loss: 0.6870957858491652
Epoch: 60 | Iteration number: [2030/4518] 44% | Training loss: 0.6870882911928768
Epoch: 60 | Iteration number: [2040/4518] 45% | Training loss: 0.6870906062570272
Epoch: 60 | Iteration number: [2050/4518] 45% | Training loss: 0.6870850036783916
Epoch: 60 | Iteration number: [2060/4518] 45% | Training loss: 0.6870806763762409
Epoch: 60 | Iteration number: [2070/4518] 45% | Training loss: 0.6870782991250356
Epoch: 60 | Iteration number: [2080/4518] 46% | Training loss: 0.6870782244950533
Epoch: 60 | Iteration number: [2090/4518] 46% | Training loss: 0.6870737422596325
Epoch: 60 | Iteration number: [2100/4518] 46% | Training loss: 0.6870692759752274
Epoch: 60 | Iteration number: [2110/4518] 46% | Training loss: 0.6870658900500474
Epoch: 60 | Iteration number: [2120/4518] 46% | Training loss: 0.6870661352884094
Epoch: 60 | Iteration number: [2130/4518] 47% | Training loss: 0.6870629020699872
Epoch: 60 | Iteration number: [2140/4518] 47% | Training loss: 0.6870600576991233
Epoch: 60 | Iteration number: [2150/4518] 47% | Training loss: 0.687061615766481
Epoch: 60 | Iteration number: [2160/4518] 47% | Training loss: 0.6870644633692724
Epoch: 60 | Iteration number: [2170/4518] 48% | Training loss: 0.6870643596770027
Epoch: 60 | Iteration number: [2180/4518] 48% | Training loss: 0.6870583871362406
Epoch: 60 | Iteration number: [2190/4518] 48% | Training loss: 0.6870591668505647
Epoch: 60 | Iteration number: [2200/4518] 48% | Training loss: 0.6870592137087476
Epoch: 60 | Iteration number: [2210/4518] 48% | Training loss: 0.6870558297202598
Epoch: 60 | Iteration number: [2220/4518] 49% | Training loss: 0.6870522756297309
Epoch: 60 | Iteration number: [2230/4518] 49% | Training loss: 0.6870550230746847
Epoch: 60 | Iteration number: [2240/4518] 49% | Training loss: 0.6870512189609664
Epoch: 60 | Iteration number: [2250/4518] 49% | Training loss: 0.6870519483884175
Epoch: 60 | Iteration number: [2260/4518] 50% | Training loss: 0.6870542362991687
Epoch: 60 | Iteration number: [2270/4518] 50% | Training loss: 0.6870564394322786
Epoch: 60 | Iteration number: [2280/4518] 50% | Training loss: 0.6870633881081615
Epoch: 60 | Iteration number: [2290/4518] 50% | Training loss: 0.6870641379637489
Epoch: 60 | Iteration number: [2300/4518] 50% | Training loss: 0.6870593285301457
Epoch: 60 | Iteration number: [2310/4518] 51% | Training loss: 0.6870550133449175
Epoch: 60 | Iteration number: [2320/4518] 51% | Training loss: 0.6870547056711953
Epoch: 60 | Iteration number: [2330/4518] 51% | Training loss: 0.6870517912852406
Epoch: 60 | Iteration number: [2340/4518] 51% | Training loss: 0.6870525179510443
Epoch: 60 | Iteration number: [2350/4518] 52% | Training loss: 0.6870482540130616
Epoch: 60 | Iteration number: [2360/4518] 52% | Training loss: 0.6870496055332281
Epoch: 60 | Iteration number: [2370/4518] 52% | Training loss: 0.6870499531428019
Epoch: 60 | Iteration number: [2380/4518] 52% | Training loss: 0.687047484917801
Epoch: 60 | Iteration number: [2390/4518] 52% | Training loss: 0.6870500209441245
Epoch: 60 | Iteration number: [2400/4518] 53% | Training loss: 0.6870529521505038
Epoch: 60 | Iteration number: [2410/4518] 53% | Training loss: 0.6870529222290546
Epoch: 60 | Iteration number: [2420/4518] 53% | Training loss: 0.6870494398942664
Epoch: 60 | Iteration number: [2430/4518] 53% | Training loss: 0.6870505782066549
Epoch: 60 | Iteration number: [2440/4518] 54% | Training loss: 0.6870471759897764
Epoch: 60 | Iteration number: [2450/4518] 54% | Training loss: 0.6870399525700783
Epoch: 60 | Iteration number: [2460/4518] 54% | Training loss: 0.6870415319999059
Epoch: 60 | Iteration number: [2470/4518] 54% | Training loss: 0.6870372253390942
Epoch: 60 | Iteration number: [2480/4518] 54% | Training loss: 0.687037773526484
Epoch: 60 | Iteration number: [2490/4518] 55% | Training loss: 0.6870371904478494
Epoch: 60 | Iteration number: [2500/4518] 55% | Training loss: 0.6870364307880401
Epoch: 60 | Iteration number: [2510/4518] 55% | Training loss: 0.6870312629705406
Epoch: 60 | Iteration number: [2520/4518] 55% | Training loss: 0.687033975975854
Epoch: 60 | Iteration number: [2530/4518] 55% | Training loss: 0.6870282900663233
Epoch: 60 | Iteration number: [2540/4518] 56% | Training loss: 0.68702296750752
Epoch: 60 | Iteration number: [2550/4518] 56% | Training loss: 0.6870245335382573
Epoch: 60 | Iteration number: [2560/4518] 56% | Training loss: 0.6870207605417817
Epoch: 60 | Iteration number: [2570/4518] 56% | Training loss: 0.6870194479649169
Epoch: 60 | Iteration number: [2580/4518] 57% | Training loss: 0.6870151262181674
Epoch: 60 | Iteration number: [2590/4518] 57% | Training loss: 0.6870118497191249
Epoch: 60 | Iteration number: [2600/4518] 57% | Training loss: 0.6870117272780492
Epoch: 60 | Iteration number: [2610/4518] 57% | Training loss: 0.6870135998360498
Epoch: 60 | Iteration number: [2620/4518] 57% | Training loss: 0.6870198679106836
Epoch: 60 | Iteration number: [2630/4518] 58% | Training loss: 0.6870125781900529
Epoch: 60 | Iteration number: [2640/4518] 58% | Training loss: 0.687012942699772
Epoch: 60 | Iteration number: [2650/4518] 58% | Training loss: 0.6870108796965401
Epoch: 60 | Iteration number: [2660/4518] 58% | Training loss: 0.6870081476475063
Epoch: 60 | Iteration number: [2670/4518] 59% | Training loss: 0.6870086110040043
Epoch: 60 | Iteration number: [2680/4518] 59% | Training loss: 0.6870107617618433
Epoch: 60 | Iteration number: [2690/4518] 59% | Training loss: 0.687012280429606
Epoch: 60 | Iteration number: [2700/4518] 59% | Training loss: 0.6870127879469483
Epoch: 60 | Iteration number: [2710/4518] 59% | Training loss: 0.6870133011763386
Epoch: 60 | Iteration number: [2720/4518] 60% | Training loss: 0.6870160691659241
Epoch: 60 | Iteration number: [2730/4518] 60% | Training loss: 0.6870168250340681
Epoch: 60 | Iteration number: [2740/4518] 60% | Training loss: 0.687018281525939
Epoch: 60 | Iteration number: [2750/4518] 60% | Training loss: 0.6870202171802521
Epoch: 60 | Iteration number: [2760/4518] 61% | Training loss: 0.687015350162983
Epoch: 60 | Iteration number: [2770/4518] 61% | Training loss: 0.6870151493953884
Epoch: 60 | Iteration number: [2780/4518] 61% | Training loss: 0.6870136713810104
Epoch: 60 | Iteration number: [2790/4518] 61% | Training loss: 0.687009306300071
Epoch: 60 | Iteration number: [2800/4518] 61% | Training loss: 0.6870046507886478
Epoch: 60 | Iteration number: [2810/4518] 62% | Training loss: 0.6870026154874482
Epoch: 60 | Iteration number: [2820/4518] 62% | Training loss: 0.6870058625936508
Epoch: 60 | Iteration number: [2830/4518] 62% | Training loss: 0.6870106479515036
Epoch: 60 | Iteration number: [2840/4518] 62% | Training loss: 0.687009146012051
Epoch: 60 | Iteration number: [2850/4518] 63% | Training loss: 0.6870068210677097
Epoch: 60 | Iteration number: [2860/4518] 63% | Training loss: 0.6870063590836691
Epoch: 60 | Iteration number: [2870/4518] 63% | Training loss: 0.6870024196154565
Epoch: 60 | Iteration number: [2880/4518] 63% | Training loss: 0.6870039573560158
Epoch: 60 | Iteration number: [2890/4518] 63% | Training loss: 0.6870019712250125
Epoch: 60 | Iteration number: [2900/4518] 64% | Training loss: 0.6869976051922502
Epoch: 60 | Iteration number: [2910/4518] 64% | Training loss: 0.6869960435477319
Epoch: 60 | Iteration number: [2920/4518] 64% | Training loss: 0.6869974747708399
Epoch: 60 | Iteration number: [2930/4518] 64% | Training loss: 0.6869928970068389
Epoch: 60 | Iteration number: [2940/4518] 65% | Training loss: 0.6869949478681395
Epoch: 60 | Iteration number: [2950/4518] 65% | Training loss: 0.6869912312596531
Epoch: 60 | Iteration number: [2960/4518] 65% | Training loss: 0.6869890723478149
Epoch: 60 | Iteration number: [2970/4518] 65% | Training loss: 0.6869839661851876
Epoch: 60 | Iteration number: [2980/4518] 65% | Training loss: 0.6869846484805113
Epoch: 60 | Iteration number: [2990/4518] 66% | Training loss: 0.686984363547137
Epoch: 60 | Iteration number: [3000/4518] 66% | Training loss: 0.686985182483991
Epoch: 60 | Iteration number: [3010/4518] 66% | Training loss: 0.6869836087836776
Epoch: 60 | Iteration number: [3020/4518] 66% | Training loss: 0.686983850124656
Epoch: 60 | Iteration number: [3030/4518] 67% | Training loss: 0.6869750808764605
Epoch: 60 | Iteration number: [3040/4518] 67% | Training loss: 0.6869777544940773
Epoch: 60 | Iteration number: [3050/4518] 67% | Training loss: 0.6869761571727815
Epoch: 60 | Iteration number: [3060/4518] 67% | Training loss: 0.6869713010351642
Epoch: 60 | Iteration number: [3070/4518] 67% | Training loss: 0.6869702487504443
Epoch: 60 | Iteration number: [3080/4518] 68% | Training loss: 0.6869709487665784
Epoch: 60 | Iteration number: [3090/4518] 68% | Training loss: 0.6869747399705127
Epoch: 60 | Iteration number: [3100/4518] 68% | Training loss: 0.6869763031313496
Epoch: 60 | Iteration number: [3110/4518] 68% | Training loss: 0.6869722033428609
Epoch: 60 | Iteration number: [3120/4518] 69% | Training loss: 0.6869717530906201
Epoch: 60 | Iteration number: [3130/4518] 69% | Training loss: 0.6869679160011463
Epoch: 60 | Iteration number: [3140/4518] 69% | Training loss: 0.6869722770847333
Epoch: 60 | Iteration number: [3150/4518] 69% | Training loss: 0.6869740374693795
Epoch: 60 | Iteration number: [3160/4518] 69% | Training loss: 0.686975524640536
Epoch: 60 | Iteration number: [3170/4518] 70% | Training loss: 0.6869747127832299
Epoch: 60 | Iteration number: [3180/4518] 70% | Training loss: 0.6869778063687139
Epoch: 60 | Iteration number: [3190/4518] 70% | Training loss: 0.6869780382953093
Epoch: 60 | Iteration number: [3200/4518] 70% | Training loss: 0.6869758065789938
Epoch: 60 | Iteration number: [3210/4518] 71% | Training loss: 0.6869721768615402
Epoch: 60 | Iteration number: [3220/4518] 71% | Training loss: 0.6869698649978045
Epoch: 60 | Iteration number: [3230/4518] 71% | Training loss: 0.6869707311270038
Epoch: 60 | Iteration number: [3240/4518] 71% | Training loss: 0.6869741799102889
Epoch: 60 | Iteration number: [3250/4518] 71% | Training loss: 0.6869719325762529
Epoch: 60 | Iteration number: [3260/4518] 72% | Training loss: 0.6869686303146046
Epoch: 60 | Iteration number: [3270/4518] 72% | Training loss: 0.6869647659657563
Epoch: 60 | Iteration number: [3280/4518] 72% | Training loss: 0.686964179793509
Epoch: 60 | Iteration number: [3290/4518] 72% | Training loss: 0.6869628004208886
Epoch: 60 | Iteration number: [3300/4518] 73% | Training loss: 0.68696041199294
Epoch: 60 | Iteration number: [3310/4518] 73% | Training loss: 0.6869583437089833
Epoch: 60 | Iteration number: [3320/4518] 73% | Training loss: 0.6869580645338599
Epoch: 60 | Iteration number: [3330/4518] 73% | Training loss: 0.6869591421372182
Epoch: 60 | Iteration number: [3340/4518] 73% | Training loss: 0.6869612584392467
Epoch: 60 | Iteration number: [3350/4518] 74% | Training loss: 0.6869611955934496
Epoch: 60 | Iteration number: [3360/4518] 74% | Training loss: 0.6869641136555444
Epoch: 60 | Iteration number: [3370/4518] 74% | Training loss: 0.6869609831348725
Epoch: 60 | Iteration number: [3380/4518] 74% | Training loss: 0.6869618298739372
Epoch: 60 | Iteration number: [3390/4518] 75% | Training loss: 0.6869630374036356
Epoch: 60 | Iteration number: [3400/4518] 75% | Training loss: 0.6869643129846629
Epoch: 60 | Iteration number: [3410/4518] 75% | Training loss: 0.6869618388040325
Epoch: 60 | Iteration number: [3420/4518] 75% | Training loss: 0.6869639519362422
Epoch: 60 | Iteration number: [3430/4518] 75% | Training loss: 0.6869667307628488
Epoch: 60 | Iteration number: [3440/4518] 76% | Training loss: 0.6869701621317587
Epoch: 60 | Iteration number: [3450/4518] 76% | Training loss: 0.6869702961824943
Epoch: 60 | Iteration number: [3460/4518] 76% | Training loss: 0.6869698944291628
Epoch: 60 | Iteration number: [3470/4518] 76% | Training loss: 0.6869683162279706
Epoch: 60 | Iteration number: [3480/4518] 77% | Training loss: 0.6869694675179734
Epoch: 60 | Iteration number: [3490/4518] 77% | Training loss: 0.6869679558926121
Epoch: 60 | Iteration number: [3500/4518] 77% | Training loss: 0.6869707883937018
Epoch: 60 | Iteration number: [3510/4518] 77% | Training loss: 0.6869686594885639
Epoch: 60 | Iteration number: [3520/4518] 77% | Training loss: 0.6869711892848666
Epoch: 60 | Iteration number: [3530/4518] 78% | Training loss: 0.686971671959496
Epoch: 60 | Iteration number: [3540/4518] 78% | Training loss: 0.6869708408912023
Epoch: 60 | Iteration number: [3550/4518] 78% | Training loss: 0.6869671907895047
Epoch: 60 | Iteration number: [3560/4518] 78% | Training loss: 0.6869636599434895
Epoch: 60 | Iteration number: [3570/4518] 79% | Training loss: 0.6869659663081503
Epoch: 60 | Iteration number: [3580/4518] 79% | Training loss: 0.6869628980839053
Epoch: 60 | Iteration number: [3590/4518] 79% | Training loss: 0.6869621742070552
Epoch: 60 | Iteration number: [3600/4518] 79% | Training loss: 0.6869616117907895
Epoch: 60 | Iteration number: [3610/4518] 79% | Training loss: 0.6869623453002888
Epoch: 60 | Iteration number: [3620/4518] 80% | Training loss: 0.6869621100017379
Epoch: 60 | Iteration number: [3630/4518] 80% | Training loss: 0.6869601489427004
Epoch: 60 | Iteration number: [3640/4518] 80% | Training loss: 0.6869562820418851
Epoch: 60 | Iteration number: [3650/4518] 80% | Training loss: 0.6869545963692338
Epoch: 60 | Iteration number: [3660/4518] 81% | Training loss: 0.6869559937976097
Epoch: 60 | Iteration number: [3670/4518] 81% | Training loss: 0.6869573088367888
Epoch: 60 | Iteration number: [3680/4518] 81% | Training loss: 0.6869514085676359
Epoch: 60 | Iteration number: [3690/4518] 81% | Training loss: 0.6869523221884316
Epoch: 60 | Iteration number: [3700/4518] 81% | Training loss: 0.6869501082478343
Epoch: 60 | Iteration number: [3710/4518] 82% | Training loss: 0.686949073159791
Epoch: 60 | Iteration number: [3720/4518] 82% | Training loss: 0.6869477064859483
Epoch: 60 | Iteration number: [3730/4518] 82% | Training loss: 0.6869455276801183
Epoch: 60 | Iteration number: [3740/4518] 82% | Training loss: 0.6869435207410293
Epoch: 60 | Iteration number: [3750/4518] 83% | Training loss: 0.6869426853338877
Epoch: 60 | Iteration number: [3760/4518] 83% | Training loss: 0.6869451756648561
Epoch: 60 | Iteration number: [3770/4518] 83% | Training loss: 0.6869471888485258
Epoch: 60 | Iteration number: [3780/4518] 83% | Training loss: 0.6869475880785594
Epoch: 60 | Iteration number: [3790/4518] 83% | Training loss: 0.6869488743175617
Epoch: 60 | Iteration number: [3800/4518] 84% | Training loss: 0.6869461005926132
Epoch: 60 | Iteration number: [3810/4518] 84% | Training loss: 0.6869422330631045
Epoch: 60 | Iteration number: [3820/4518] 84% | Training loss: 0.6869395964588795
Epoch: 60 | Iteration number: [3830/4518] 84% | Training loss: 0.6869397139113503
Epoch: 60 | Iteration number: [3840/4518] 84% | Training loss: 0.6869406653568149
Epoch: 60 | Iteration number: [3850/4518] 85% | Training loss: 0.6869375109208095
Epoch: 60 | Iteration number: [3860/4518] 85% | Training loss: 0.6869351773373203
Epoch: 60 | Iteration number: [3870/4518] 85% | Training loss: 0.6869322192761325
Epoch: 60 | Iteration number: [3880/4518] 85% | Training loss: 0.6869342215282401
Epoch: 60 | Iteration number: [3890/4518] 86% | Training loss: 0.6869359706392019
Epoch: 60 | Iteration number: [3900/4518] 86% | Training loss: 0.6869346290826798
Epoch: 60 | Iteration number: [3910/4518] 86% | Training loss: 0.6869382121678813
Epoch: 60 | Iteration number: [3920/4518] 86% | Training loss: 0.6869384670592085
Epoch: 60 | Iteration number: [3930/4518] 86% | Training loss: 0.6869366900308138
Epoch: 60 | Iteration number: [3940/4518] 87% | Training loss: 0.6869361614364052
Epoch: 60 | Iteration number: [3950/4518] 87% | Training loss: 0.6869322617295422
Epoch: 60 | Iteration number: [3960/4518] 87% | Training loss: 0.686933937503232
Epoch: 60 | Iteration number: [3970/4518] 87% | Training loss: 0.6869334375077591
Epoch: 60 | Iteration number: [3980/4518] 88% | Training loss: 0.6869361699226514
Epoch: 60 | Iteration number: [3990/4518] 88% | Training loss: 0.6869388479935495
Epoch: 60 | Iteration number: [4000/4518] 88% | Training loss: 0.6869401336610317
Epoch: 60 | Iteration number: [4010/4518] 88% | Training loss: 0.6869415758553883
Epoch: 60 | Iteration number: [4020/4518] 88% | Training loss: 0.6869443196414122
Epoch: 60 | Iteration number: [4030/4518] 89% | Training loss: 0.6869412142792647
Epoch: 60 | Iteration number: [4040/4518] 89% | Training loss: 0.6869432229216736
Epoch: 60 | Iteration number: [4050/4518] 89% | Training loss: 0.6869430920224131
Epoch: 60 | Iteration number: [4060/4518] 89% | Training loss: 0.6869446226088284
Epoch: 60 | Iteration number: [4070/4518] 90% | Training loss: 0.6869443348350337
Epoch: 60 | Iteration number: [4080/4518] 90% | Training loss: 0.6869431054767441
Epoch: 60 | Iteration number: [4090/4518] 90% | Training loss: 0.686943603028295
Epoch: 60 | Iteration number: [4100/4518] 90% | Training loss: 0.686941800306483
Epoch: 60 | Iteration number: [4110/4518] 90% | Training loss: 0.686940681905352
Epoch: 60 | Iteration number: [4120/4518] 91% | Training loss: 0.6869381871472284
Epoch: 60 | Iteration number: [4130/4518] 91% | Training loss: 0.6869366220931452
Epoch: 60 | Iteration number: [4140/4518] 91% | Training loss: 0.6869363821503045
Epoch: 60 | Iteration number: [4150/4518] 91% | Training loss: 0.6869399997125188
Epoch: 60 | Iteration number: [4160/4518] 92% | Training loss: 0.6869384726509452
Epoch: 60 | Iteration number: [4170/4518] 92% | Training loss: 0.6869392926172673
Epoch: 60 | Iteration number: [4180/4518] 92% | Training loss: 0.6869391503373972
Epoch: 60 | Iteration number: [4190/4518] 92% | Training loss: 0.686941026432133
Epoch: 60 | Iteration number: [4200/4518] 92% | Training loss: 0.6869385613430115
Epoch: 60 | Iteration number: [4210/4518] 93% | Training loss: 0.686941988975022
Epoch: 60 | Iteration number: [4220/4518] 93% | Training loss: 0.686938733102586
Epoch: 60 | Iteration number: [4230/4518] 93% | Training loss: 0.6869388572008616
Epoch: 60 | Iteration number: [4240/4518] 93% | Training loss: 0.6869371502748075
Epoch: 60 | Iteration number: [4250/4518] 94% | Training loss: 0.6869397906836341
Epoch: 60 | Iteration number: [4260/4518] 94% | Training loss: 0.6869384476836299
Epoch: 60 | Iteration number: [4270/4518] 94% | Training loss: 0.6869386435671768
Epoch: 60 | Iteration number: [4280/4518] 94% | Training loss: 0.6869386403499362
Epoch: 60 | Iteration number: [4290/4518] 94% | Training loss: 0.6869396645983894
Epoch: 60 | Iteration number: [4300/4518] 95% | Training loss: 0.6869410353621771
Epoch: 60 | Iteration number: [4310/4518] 95% | Training loss: 0.6869397327131019
Epoch: 60 | Iteration number: [4320/4518] 95% | Training loss: 0.6869396394739549
Epoch: 60 | Iteration number: [4330/4518] 95% | Training loss: 0.6869402131913165
Epoch: 60 | Iteration number: [4340/4518] 96% | Training loss: 0.6869407506719712
Epoch: 60 | Iteration number: [4350/4518] 96% | Training loss: 0.6869390132646451
Epoch: 60 | Iteration number: [4360/4518] 96% | Training loss: 0.6869432837727967
Epoch: 60 | Iteration number: [4370/4518] 96% | Training loss: 0.6869418455070434
Epoch: 60 | Iteration number: [4380/4518] 96% | Training loss: 0.6869424940244248
Epoch: 60 | Iteration number: [4390/4518] 97% | Training loss: 0.6869430343355296
Epoch: 60 | Iteration number: [4400/4518] 97% | Training loss: 0.6869448539343748
Epoch: 60 | Iteration number: [4410/4518] 97% | Training loss: 0.6869474513054975
Epoch: 60 | Iteration number: [4420/4518] 97% | Training loss: 0.6869450610013029
Epoch: 60 | Iteration number: [4430/4518] 98% | Training loss: 0.686947837801604
Epoch: 60 | Iteration number: [4440/4518] 98% | Training loss: 0.6869495700340014
Epoch: 60 | Iteration number: [4450/4518] 98% | Training loss: 0.686946344536342
Epoch: 60 | Iteration number: [4460/4518] 98% | Training loss: 0.6869459259804054
Epoch: 60 | Iteration number: [4470/4518] 98% | Training loss: 0.6869449419863272
Epoch: 60 | Iteration number: [4480/4518] 99% | Training loss: 0.6869408054543393
Epoch: 60 | Iteration number: [4490/4518] 99% | Training loss: 0.6869411178845871
Epoch: 60 | Iteration number: [4500/4518] 99% | Training loss: 0.6869407351149454
Epoch: 60 | Iteration number: [4510/4518] 99% | Training loss: 0.6869398009750637

 End of epoch: 60 | Train Loss: 0.6867884784976483 | Training Time: 633 

 End of epoch: 60 | Eval Loss: 0.6896980635973872 | Evaluating Time: 17 
Epoch: 61 | Iteration number: [10/4518] 0% | Training loss: 0.7555384039878845
Epoch: 61 | Iteration number: [20/4518] 0% | Training loss: 0.7205516308546066
Epoch: 61 | Iteration number: [30/4518] 0% | Training loss: 0.7090632557868958
Epoch: 61 | Iteration number: [40/4518] 0% | Training loss: 0.7032370865345001
Epoch: 61 | Iteration number: [50/4518] 1% | Training loss: 0.6998347640037537
Epoch: 61 | Iteration number: [60/4518] 1% | Training loss: 0.6976148386796316
Epoch: 61 | Iteration number: [70/4518] 1% | Training loss: 0.6958366300378527
Epoch: 61 | Iteration number: [80/4518] 1% | Training loss: 0.6946380272507667
Epoch: 61 | Iteration number: [90/4518] 1% | Training loss: 0.6938237415419685
Epoch: 61 | Iteration number: [100/4518] 2% | Training loss: 0.6931792294979096
Epoch: 61 | Iteration number: [110/4518] 2% | Training loss: 0.6925272665240548
Epoch: 61 | Iteration number: [120/4518] 2% | Training loss: 0.6920417502522469
Epoch: 61 | Iteration number: [130/4518] 2% | Training loss: 0.6916638594407302
Epoch: 61 | Iteration number: [140/4518] 3% | Training loss: 0.6913684074367795
Epoch: 61 | Iteration number: [150/4518] 3% | Training loss: 0.6911200177669525
Epoch: 61 | Iteration number: [160/4518] 3% | Training loss: 0.6908444602042436
Epoch: 61 | Iteration number: [170/4518] 3% | Training loss: 0.6905784105553346
Epoch: 61 | Iteration number: [180/4518] 3% | Training loss: 0.6902950608068043
Epoch: 61 | Iteration number: [190/4518] 4% | Training loss: 0.6901547717420679
Epoch: 61 | Iteration number: [200/4518] 4% | Training loss: 0.6899447575211525
Epoch: 61 | Iteration number: [210/4518] 4% | Training loss: 0.689761587551662
Epoch: 61 | Iteration number: [220/4518] 4% | Training loss: 0.689599900895899
Epoch: 61 | Iteration number: [230/4518] 5% | Training loss: 0.6894270951333253
Epoch: 61 | Iteration number: [240/4518] 5% | Training loss: 0.6893025410672029
Epoch: 61 | Iteration number: [250/4518] 5% | Training loss: 0.6892317426204682
Epoch: 61 | Iteration number: [260/4518] 5% | Training loss: 0.6890787010009473
Epoch: 61 | Iteration number: [270/4518] 5% | Training loss: 0.6890296534255699
Epoch: 61 | Iteration number: [280/4518] 6% | Training loss: 0.6889315258179393
Epoch: 61 | Iteration number: [290/4518] 6% | Training loss: 0.6888396335059199
Epoch: 61 | Iteration number: [300/4518] 6% | Training loss: 0.6888155068953832
Epoch: 61 | Iteration number: [310/4518] 6% | Training loss: 0.6887374895234262
Epoch: 61 | Iteration number: [320/4518] 7% | Training loss: 0.6886538300663233
Epoch: 61 | Iteration number: [330/4518] 7% | Training loss: 0.6885674872181632
Epoch: 61 | Iteration number: [340/4518] 7% | Training loss: 0.6885357360629475
Epoch: 61 | Iteration number: [350/4518] 7% | Training loss: 0.6884778489385333
Epoch: 61 | Iteration number: [360/4518] 7% | Training loss: 0.688454340895017
Epoch: 61 | Iteration number: [370/4518] 8% | Training loss: 0.6884129598334029
Epoch: 61 | Iteration number: [380/4518] 8% | Training loss: 0.6883753547542973
Epoch: 61 | Iteration number: [390/4518] 8% | Training loss: 0.6883203333769089
Epoch: 61 | Iteration number: [400/4518] 8% | Training loss: 0.6882733005285263
Epoch: 61 | Iteration number: [410/4518] 9% | Training loss: 0.688261047078342
Epoch: 61 | Iteration number: [420/4518] 9% | Training loss: 0.6882256746292115
Epoch: 61 | Iteration number: [430/4518] 9% | Training loss: 0.6881705090057019
Epoch: 61 | Iteration number: [440/4518] 9% | Training loss: 0.6881411958824505
Epoch: 61 | Iteration number: [450/4518] 9% | Training loss: 0.6881119963857862
Epoch: 61 | Iteration number: [460/4518] 10% | Training loss: 0.6880949625502462
Epoch: 61 | Iteration number: [470/4518] 10% | Training loss: 0.6880537686195779
Epoch: 61 | Iteration number: [480/4518] 10% | Training loss: 0.6880343658228715
Epoch: 61 | Iteration number: [490/4518] 10% | Training loss: 0.6879718151627755
Epoch: 61 | Iteration number: [500/4518] 11% | Training loss: 0.6879582266807556
Epoch: 61 | Iteration number: [510/4518] 11% | Training loss: 0.6879299928160275
Epoch: 61 | Iteration number: [520/4518] 11% | Training loss: 0.6878863191375366
Epoch: 61 | Iteration number: [530/4518] 11% | Training loss: 0.6878876186766715
Epoch: 61 | Iteration number: [540/4518] 11% | Training loss: 0.6878649442284196
Epoch: 61 | Iteration number: [550/4518] 12% | Training loss: 0.6878712050481276
Epoch: 61 | Iteration number: [560/4518] 12% | Training loss: 0.687858783347266
Epoch: 61 | Iteration number: [570/4518] 12% | Training loss: 0.6878299553143351
Epoch: 61 | Iteration number: [580/4518] 12% | Training loss: 0.687822894495109
Epoch: 61 | Iteration number: [590/4518] 13% | Training loss: 0.6878180776612234
Epoch: 61 | Iteration number: [600/4518] 13% | Training loss: 0.6878071480989456
Epoch: 61 | Iteration number: [610/4518] 13% | Training loss: 0.6877808974414575
Epoch: 61 | Iteration number: [620/4518] 13% | Training loss: 0.687763885240401
Epoch: 61 | Iteration number: [630/4518] 13% | Training loss: 0.6877529884141589
Epoch: 61 | Iteration number: [640/4518] 14% | Training loss: 0.6877328800037503
Epoch: 61 | Iteration number: [650/4518] 14% | Training loss: 0.6877199992766747
Epoch: 61 | Iteration number: [660/4518] 14% | Training loss: 0.687697234749794
Epoch: 61 | Iteration number: [670/4518] 14% | Training loss: 0.6876766781308757
Epoch: 61 | Iteration number: [680/4518] 15% | Training loss: 0.6876743027392556
Epoch: 61 | Iteration number: [690/4518] 15% | Training loss: 0.6876433326714281
Epoch: 61 | Iteration number: [700/4518] 15% | Training loss: 0.6876345652341843
Epoch: 61 | Iteration number: [710/4518] 15% | Training loss: 0.6876162297289137
Epoch: 61 | Iteration number: [720/4518] 15% | Training loss: 0.6876112050480313
Epoch: 61 | Iteration number: [730/4518] 16% | Training loss: 0.6875931695716022
Epoch: 61 | Iteration number: [740/4518] 16% | Training loss: 0.6875928699164777
Epoch: 61 | Iteration number: [750/4518] 16% | Training loss: 0.6875834015210469
Epoch: 61 | Iteration number: [760/4518] 16% | Training loss: 0.6875811063929608
Epoch: 61 | Iteration number: [770/4518] 17% | Training loss: 0.687567457982472
Epoch: 61 | Iteration number: [780/4518] 17% | Training loss: 0.6875607644900298
Epoch: 61 | Iteration number: [790/4518] 17% | Training loss: 0.6875575134271308
Epoch: 61 | Iteration number: [800/4518] 17% | Training loss: 0.6875360728055239
Epoch: 61 | Iteration number: [810/4518] 17% | Training loss: 0.6875221922073835
Epoch: 61 | Iteration number: [820/4518] 18% | Training loss: 0.6875224209413295
Epoch: 61 | Iteration number: [830/4518] 18% | Training loss: 0.6875281248466079
Epoch: 61 | Iteration number: [840/4518] 18% | Training loss: 0.6875184899994305
Epoch: 61 | Iteration number: [850/4518] 18% | Training loss: 0.6874909013159135
Epoch: 61 | Iteration number: [860/4518] 19% | Training loss: 0.6874759230502816
Epoch: 61 | Iteration number: [870/4518] 19% | Training loss: 0.6874667582840756
Epoch: 61 | Iteration number: [880/4518] 19% | Training loss: 0.687434125285257
Epoch: 61 | Iteration number: [890/4518] 19% | Training loss: 0.687414212240262
Epoch: 61 | Iteration number: [900/4518] 19% | Training loss: 0.6874007023705376
Epoch: 61 | Iteration number: [910/4518] 20% | Training loss: 0.6873950684463584
Epoch: 61 | Iteration number: [920/4518] 20% | Training loss: 0.6873812464916188
Epoch: 61 | Iteration number: [930/4518] 20% | Training loss: 0.6873717701563271
Epoch: 61 | Iteration number: [940/4518] 20% | Training loss: 0.6873642773070234
Epoch: 61 | Iteration number: [950/4518] 21% | Training loss: 0.6873578091044175
Epoch: 61 | Iteration number: [960/4518] 21% | Training loss: 0.687359395250678
Epoch: 61 | Iteration number: [970/4518] 21% | Training loss: 0.6873594508957617
Epoch: 61 | Iteration number: [980/4518] 21% | Training loss: 0.6873475755355796
Epoch: 61 | Iteration number: [990/4518] 21% | Training loss: 0.687340291100319
Epoch: 61 | Iteration number: [1000/4518] 22% | Training loss: 0.6873282097578048
Epoch: 61 | Iteration number: [1010/4518] 22% | Training loss: 0.687327523868863
Epoch: 61 | Iteration number: [1020/4518] 22% | Training loss: 0.6873388289820914
Epoch: 61 | Iteration number: [1030/4518] 22% | Training loss: 0.6873409450054169
Epoch: 61 | Iteration number: [1040/4518] 23% | Training loss: 0.6873375536157534
Epoch: 61 | Iteration number: [1050/4518] 23% | Training loss: 0.6873359365122659
Epoch: 61 | Iteration number: [1060/4518] 23% | Training loss: 0.687330710325601
Epoch: 61 | Iteration number: [1070/4518] 23% | Training loss: 0.6873274265605712
Epoch: 61 | Iteration number: [1080/4518] 23% | Training loss: 0.6873319084445636
Epoch: 61 | Iteration number: [1090/4518] 24% | Training loss: 0.6873352251468449
Epoch: 61 | Iteration number: [1100/4518] 24% | Training loss: 0.6873399746418
Epoch: 61 | Iteration number: [1110/4518] 24% | Training loss: 0.6873485568407419
Epoch: 61 | Iteration number: [1120/4518] 24% | Training loss: 0.6873448377741235
Epoch: 61 | Iteration number: [1130/4518] 25% | Training loss: 0.6873342333114253
Epoch: 61 | Iteration number: [1140/4518] 25% | Training loss: 0.6873355691370211
Epoch: 61 | Iteration number: [1150/4518] 25% | Training loss: 0.6873414097661558
Epoch: 61 | Iteration number: [1160/4518] 25% | Training loss: 0.6873357953182582
Epoch: 61 | Iteration number: [1170/4518] 25% | Training loss: 0.6873364953403799
Epoch: 61 | Iteration number: [1180/4518] 26% | Training loss: 0.6873287868196681
Epoch: 61 | Iteration number: [1190/4518] 26% | Training loss: 0.687324753078092
Epoch: 61 | Iteration number: [1200/4518] 26% | Training loss: 0.6873166576524575
Epoch: 61 | Iteration number: [1210/4518] 26% | Training loss: 0.6873094480884961
Epoch: 61 | Iteration number: [1220/4518] 27% | Training loss: 0.6873017967235847
Epoch: 61 | Iteration number: [1230/4518] 27% | Training loss: 0.687302279423892
Epoch: 61 | Iteration number: [1240/4518] 27% | Training loss: 0.6873035646734699
Epoch: 61 | Iteration number: [1250/4518] 27% | Training loss: 0.6872968060970306
Epoch: 61 | Iteration number: [1260/4518] 27% | Training loss: 0.6873055237153219
Epoch: 61 | Iteration number: [1270/4518] 28% | Training loss: 0.6873055145496458
Epoch: 61 | Iteration number: [1280/4518] 28% | Training loss: 0.6872993806377053
Epoch: 61 | Iteration number: [1290/4518] 28% | Training loss: 0.6872985734033954
Epoch: 61 | Iteration number: [1300/4518] 28% | Training loss: 0.6872919598451027
Epoch: 61 | Iteration number: [1310/4518] 28% | Training loss: 0.6872886528495614
Epoch: 61 | Iteration number: [1320/4518] 29% | Training loss: 0.6872840876832153
Epoch: 61 | Iteration number: [1330/4518] 29% | Training loss: 0.6872773986561854
Epoch: 61 | Iteration number: [1340/4518] 29% | Training loss: 0.6872805603404544
Epoch: 61 | Iteration number: [1350/4518] 29% | Training loss: 0.6872801370532424
Epoch: 61 | Iteration number: [1360/4518] 30% | Training loss: 0.6872775264960878
Epoch: 61 | Iteration number: [1370/4518] 30% | Training loss: 0.6872743553488794
Epoch: 61 | Iteration number: [1380/4518] 30% | Training loss: 0.6872729210317998
Epoch: 61 | Iteration number: [1390/4518] 30% | Training loss: 0.6872700215243607
Epoch: 61 | Iteration number: [1400/4518] 30% | Training loss: 0.687273780788694
Epoch: 61 | Iteration number: [1410/4518] 31% | Training loss: 0.6872661237598311
Epoch: 61 | Iteration number: [1420/4518] 31% | Training loss: 0.6872760585496124
Epoch: 61 | Iteration number: [1430/4518] 31% | Training loss: 0.6872760927760517
Epoch: 61 | Iteration number: [1440/4518] 31% | Training loss: 0.6872812264081505
Epoch: 61 | Iteration number: [1450/4518] 32% | Training loss: 0.6872767605452702
Epoch: 61 | Iteration number: [1460/4518] 32% | Training loss: 0.6872714241890058
Epoch: 61 | Iteration number: [1470/4518] 32% | Training loss: 0.687255799202692
Epoch: 61 | Iteration number: [1480/4518] 32% | Training loss: 0.6872557664239729
Epoch: 61 | Iteration number: [1490/4518] 32% | Training loss: 0.6872557499664742
Epoch: 61 | Iteration number: [1500/4518] 33% | Training loss: 0.6872422633568446
Epoch: 61 | Iteration number: [1510/4518] 33% | Training loss: 0.6872423839095413
Epoch: 61 | Iteration number: [1520/4518] 33% | Training loss: 0.6872442896820997
Epoch: 61 | Iteration number: [1530/4518] 33% | Training loss: 0.687238256487192
Epoch: 61 | Iteration number: [1540/4518] 34% | Training loss: 0.6872334792242422
Epoch: 61 | Iteration number: [1550/4518] 34% | Training loss: 0.6872352175943313
Epoch: 61 | Iteration number: [1560/4518] 34% | Training loss: 0.6872304142285616
Epoch: 61 | Iteration number: [1570/4518] 34% | Training loss: 0.6872249290821658
Epoch: 61 | Iteration number: [1580/4518] 34% | Training loss: 0.68721846606158
Epoch: 61 | Iteration number: [1590/4518] 35% | Training loss: 0.6872201627905263
Epoch: 61 | Iteration number: [1600/4518] 35% | Training loss: 0.687217790260911
Epoch: 61 | Iteration number: [1610/4518] 35% | Training loss: 0.6872140832199073
Epoch: 61 | Iteration number: [1620/4518] 35% | Training loss: 0.6872069986514103
Epoch: 61 | Iteration number: [1630/4518] 36% | Training loss: 0.6872100330203589
Epoch: 61 | Iteration number: [1640/4518] 36% | Training loss: 0.6872124965961387
Epoch: 61 | Iteration number: [1650/4518] 36% | Training loss: 0.6872041701186787
Epoch: 61 | Iteration number: [1660/4518] 36% | Training loss: 0.6872016930077449
Epoch: 61 | Iteration number: [1670/4518] 36% | Training loss: 0.6872068225623604
Epoch: 61 | Iteration number: [1680/4518] 37% | Training loss: 0.6872035094669887
Epoch: 61 | Iteration number: [1690/4518] 37% | Training loss: 0.6872076276138689
Epoch: 61 | Iteration number: [1700/4518] 37% | Training loss: 0.6872058909430223
Epoch: 61 | Iteration number: [1710/4518] 37% | Training loss: 0.6872015622275615
Epoch: 61 | Iteration number: [1720/4518] 38% | Training loss: 0.6871962888989338
Epoch: 61 | Iteration number: [1730/4518] 38% | Training loss: 0.6871897525525507
Epoch: 61 | Iteration number: [1740/4518] 38% | Training loss: 0.6871825351454746
Epoch: 61 | Iteration number: [1750/4518] 38% | Training loss: 0.68717571078028
Epoch: 61 | Iteration number: [1760/4518] 38% | Training loss: 0.6871786601502787
Epoch: 61 | Iteration number: [1770/4518] 39% | Training loss: 0.6871767653920556
Epoch: 61 | Iteration number: [1780/4518] 39% | Training loss: 0.6871792829438542
Epoch: 61 | Iteration number: [1790/4518] 39% | Training loss: 0.6871748678844068
Epoch: 61 | Iteration number: [1800/4518] 39% | Training loss: 0.6871709621946017
Epoch: 61 | Iteration number: [1810/4518] 40% | Training loss: 0.6871706014509359
Epoch: 61 | Iteration number: [1820/4518] 40% | Training loss: 0.6871741548344329
Epoch: 61 | Iteration number: [1830/4518] 40% | Training loss: 0.6871753682204284
Epoch: 61 | Iteration number: [1840/4518] 40% | Training loss: 0.6871766662792019
Epoch: 61 | Iteration number: [1850/4518] 40% | Training loss: 0.6871712302839433
Epoch: 61 | Iteration number: [1860/4518] 41% | Training loss: 0.6871695141958934
Epoch: 61 | Iteration number: [1870/4518] 41% | Training loss: 0.6871655588800257
Epoch: 61 | Iteration number: [1880/4518] 41% | Training loss: 0.6871677705582152
Epoch: 61 | Iteration number: [1890/4518] 41% | Training loss: 0.6871765041477466
Epoch: 61 | Iteration number: [1900/4518] 42% | Training loss: 0.6871737354366403
Epoch: 61 | Iteration number: [1910/4518] 42% | Training loss: 0.6871799999818752
Epoch: 61 | Iteration number: [1920/4518] 42% | Training loss: 0.6871810243465006
Epoch: 61 | Iteration number: [1930/4518] 42% | Training loss: 0.6871727765532973
Epoch: 61 | Iteration number: [1940/4518] 42% | Training loss: 0.6871704844162636
Epoch: 61 | Iteration number: [1950/4518] 43% | Training loss: 0.6871656754689339
Epoch: 61 | Iteration number: [1960/4518] 43% | Training loss: 0.6871669350229964
Epoch: 61 | Iteration number: [1970/4518] 43% | Training loss: 0.6871608594347378
Epoch: 61 | Iteration number: [1980/4518] 43% | Training loss: 0.6871602953383417
Epoch: 61 | Iteration number: [1990/4518] 44% | Training loss: 0.6871621554820382
Epoch: 61 | Iteration number: [2000/4518] 44% | Training loss: 0.6871633349359035
Epoch: 61 | Iteration number: [2010/4518] 44% | Training loss: 0.687162823552516
Epoch: 61 | Iteration number: [2020/4518] 44% | Training loss: 0.687157667273342
Epoch: 61 | Iteration number: [2030/4518] 44% | Training loss: 0.6871601112957658
Epoch: 61 | Iteration number: [2040/4518] 45% | Training loss: 0.6871618485041693
Epoch: 61 | Iteration number: [2050/4518] 45% | Training loss: 0.6871635468994699
Epoch: 61 | Iteration number: [2060/4518] 45% | Training loss: 0.6871632487739174
Epoch: 61 | Iteration number: [2070/4518] 45% | Training loss: 0.6871610926545184
Epoch: 61 | Iteration number: [2080/4518] 46% | Training loss: 0.687162645218464
Epoch: 61 | Iteration number: [2090/4518] 46% | Training loss: 0.6871572525592512
Epoch: 61 | Iteration number: [2100/4518] 46% | Training loss: 0.6871582172598157
Epoch: 61 | Iteration number: [2110/4518] 46% | Training loss: 0.6871621540937378
Epoch: 61 | Iteration number: [2120/4518] 46% | Training loss: 0.6871624382037037
Epoch: 61 | Iteration number: [2130/4518] 47% | Training loss: 0.6871581940303946
Epoch: 61 | Iteration number: [2140/4518] 47% | Training loss: 0.6871591672440556
Epoch: 61 | Iteration number: [2150/4518] 47% | Training loss: 0.6871569313282191
Epoch: 61 | Iteration number: [2160/4518] 47% | Training loss: 0.687156104820746
Epoch: 61 | Iteration number: [2170/4518] 48% | Training loss: 0.6871570073789166
Epoch: 61 | Iteration number: [2180/4518] 48% | Training loss: 0.6871548826541376
Epoch: 61 | Iteration number: [2190/4518] 48% | Training loss: 0.6871546298129374
Epoch: 61 | Iteration number: [2200/4518] 48% | Training loss: 0.6871506433866241
Epoch: 61 | Iteration number: [2210/4518] 48% | Training loss: 0.6871476022366485
Epoch: 61 | Iteration number: [2220/4518] 49% | Training loss: 0.6871398848724795
Epoch: 61 | Iteration number: [2230/4518] 49% | Training loss: 0.6871338479722028
Epoch: 61 | Iteration number: [2240/4518] 49% | Training loss: 0.68712563394968
Epoch: 61 | Iteration number: [2250/4518] 49% | Training loss: 0.6871193012926313
Epoch: 61 | Iteration number: [2260/4518] 50% | Training loss: 0.687121482391273
Epoch: 61 | Iteration number: [2270/4518] 50% | Training loss: 0.6871227198760415
Epoch: 61 | Iteration number: [2280/4518] 50% | Training loss: 0.6871262760800227
Epoch: 61 | Iteration number: [2290/4518] 50% | Training loss: 0.687125448680861
Epoch: 61 | Iteration number: [2300/4518] 50% | Training loss: 0.6871259173621302
Epoch: 61 | Iteration number: [2310/4518] 51% | Training loss: 0.6871214518041322
Epoch: 61 | Iteration number: [2320/4518] 51% | Training loss: 0.6871189084803236
Epoch: 61 | Iteration number: [2330/4518] 51% | Training loss: 0.6871196020314622
Epoch: 61 | Iteration number: [2340/4518] 51% | Training loss: 0.687116019313152
Epoch: 61 | Iteration number: [2350/4518] 52% | Training loss: 0.6871172819999938
Epoch: 61 | Iteration number: [2360/4518] 52% | Training loss: 0.6871130824341612
Epoch: 61 | Iteration number: [2370/4518] 52% | Training loss: 0.6871142226683943
Epoch: 61 | Iteration number: [2380/4518] 52% | Training loss: 0.6871175113595834
Epoch: 61 | Iteration number: [2390/4518] 52% | Training loss: 0.6871186642467227
Epoch: 61 | Iteration number: [2400/4518] 53% | Training loss: 0.6871182693789403
Epoch: 61 | Iteration number: [2410/4518] 53% | Training loss: 0.6871135781662098
Epoch: 61 | Iteration number: [2420/4518] 53% | Training loss: 0.6871044140216733
Epoch: 61 | Iteration number: [2430/4518] 53% | Training loss: 0.6870987208537114
Epoch: 61 | Iteration number: [2440/4518] 54% | Training loss: 0.6870974409287093
Epoch: 61 | Iteration number: [2450/4518] 54% | Training loss: 0.6870923790153192
Epoch: 61 | Iteration number: [2460/4518] 54% | Training loss: 0.6870952471242687
Epoch: 61 | Iteration number: [2470/4518] 54% | Training loss: 0.6870900443208362
Epoch: 61 | Iteration number: [2480/4518] 54% | Training loss: 0.6870910746916647
Epoch: 61 | Iteration number: [2490/4518] 55% | Training loss: 0.6870941120697313
Epoch: 61 | Iteration number: [2500/4518] 55% | Training loss: 0.6870904705286026
Epoch: 61 | Iteration number: [2510/4518] 55% | Training loss: 0.6870888165031296
Epoch: 61 | Iteration number: [2520/4518] 55% | Training loss: 0.6870933911866612
Epoch: 61 | Iteration number: [2530/4518] 55% | Training loss: 0.6870888233655997
Epoch: 61 | Iteration number: [2540/4518] 56% | Training loss: 0.6870869539619431
Epoch: 61 | Iteration number: [2550/4518] 56% | Training loss: 0.6870867959892049
Epoch: 61 | Iteration number: [2560/4518] 56% | Training loss: 0.6870824747020379
Epoch: 61 | Iteration number: [2570/4518] 56% | Training loss: 0.6870798373500661
Epoch: 61 | Iteration number: [2580/4518] 57% | Training loss: 0.6870808251606402
Epoch: 61 | Iteration number: [2590/4518] 57% | Training loss: 0.6870713148568127
Epoch: 61 | Iteration number: [2600/4518] 57% | Training loss: 0.6870729467731256
Epoch: 61 | Iteration number: [2610/4518] 57% | Training loss: 0.687073386788825
Epoch: 61 | Iteration number: [2620/4518] 57% | Training loss: 0.6870663576453697
Epoch: 61 | Iteration number: [2630/4518] 58% | Training loss: 0.6870655209845916
Epoch: 61 | Iteration number: [2640/4518] 58% | Training loss: 0.6870679699110263
Epoch: 61 | Iteration number: [2650/4518] 58% | Training loss: 0.6870659891389451
Epoch: 61 | Iteration number: [2660/4518] 58% | Training loss: 0.6870675856681695
Epoch: 61 | Iteration number: [2670/4518] 59% | Training loss: 0.6870647460557102
Epoch: 61 | Iteration number: [2680/4518] 59% | Training loss: 0.6870638656304844
Epoch: 61 | Iteration number: [2690/4518] 59% | Training loss: 0.6870604437523172
Epoch: 61 | Iteration number: [2700/4518] 59% | Training loss: 0.687059705124961
Epoch: 61 | Iteration number: [2710/4518] 59% | Training loss: 0.6870609326116274
Epoch: 61 | Iteration number: [2720/4518] 60% | Training loss: 0.6870621538556674
Epoch: 61 | Iteration number: [2730/4518] 60% | Training loss: 0.6870606464999063
Epoch: 61 | Iteration number: [2740/4518] 60% | Training loss: 0.6870627736740739
Epoch: 61 | Iteration number: [2750/4518] 60% | Training loss: 0.687063423871994
Epoch: 61 | Iteration number: [2760/4518] 61% | Training loss: 0.68706225923438
Epoch: 61 | Iteration number: [2770/4518] 61% | Training loss: 0.6870573292570424
Epoch: 61 | Iteration number: [2780/4518] 61% | Training loss: 0.687058234600712
Epoch: 61 | Iteration number: [2790/4518] 61% | Training loss: 0.6870579267915432
Epoch: 61 | Iteration number: [2800/4518] 61% | Training loss: 0.6870578739472798
Epoch: 61 | Iteration number: [2810/4518] 62% | Training loss: 0.6870617620885584
Epoch: 61 | Iteration number: [2820/4518] 62% | Training loss: 0.6870555085281954
Epoch: 61 | Iteration number: [2830/4518] 62% | Training loss: 0.6870554590183097
Epoch: 61 | Iteration number: [2840/4518] 62% | Training loss: 0.6870523927707067
Epoch: 61 | Iteration number: [2850/4518] 63% | Training loss: 0.6870520471899133
Epoch: 61 | Iteration number: [2860/4518] 63% | Training loss: 0.6870519519269049
Epoch: 61 | Iteration number: [2870/4518] 63% | Training loss: 0.6870505767001508
Epoch: 61 | Iteration number: [2880/4518] 63% | Training loss: 0.6870444706330697
Epoch: 61 | Iteration number: [2890/4518] 63% | Training loss: 0.6870435586437634
Epoch: 61 | Iteration number: [2900/4518] 64% | Training loss: 0.687039813275995
Epoch: 61 | Iteration number: [2910/4518] 64% | Training loss: 0.6870389114540467
Epoch: 61 | Iteration number: [2920/4518] 64% | Training loss: 0.687038151817779
Epoch: 61 | Iteration number: [2930/4518] 64% | Training loss: 0.6870367851883885
Epoch: 61 | Iteration number: [2940/4518] 65% | Training loss: 0.6870352443586402
Epoch: 61 | Iteration number: [2950/4518] 65% | Training loss: 0.6870375430786003
Epoch: 61 | Iteration number: [2960/4518] 65% | Training loss: 0.6870364270902969
Epoch: 61 | Iteration number: [2970/4518] 65% | Training loss: 0.6870362404621009
Epoch: 61 | Iteration number: [2980/4518] 65% | Training loss: 0.6870347440842814
Epoch: 61 | Iteration number: [2990/4518] 66% | Training loss: 0.6870364753896975
Epoch: 61 | Iteration number: [3000/4518] 66% | Training loss: 0.6870364141464234
Epoch: 61 | Iteration number: [3010/4518] 66% | Training loss: 0.6870375121748724
Epoch: 61 | Iteration number: [3020/4518] 66% | Training loss: 0.6870357462704576
Epoch: 61 | Iteration number: [3030/4518] 67% | Training loss: 0.6870370054205652
Epoch: 61 | Iteration number: [3040/4518] 67% | Training loss: 0.6870378309762791
Epoch: 61 | Iteration number: [3050/4518] 67% | Training loss: 0.6870374853689163
Epoch: 61 | Iteration number: [3060/4518] 67% | Training loss: 0.6870359991305793
Epoch: 61 | Iteration number: [3070/4518] 67% | Training loss: 0.6870349452045142
Epoch: 61 | Iteration number: [3080/4518] 68% | Training loss: 0.6870337534647484
Epoch: 61 | Iteration number: [3090/4518] 68% | Training loss: 0.6870325932610768
Epoch: 61 | Iteration number: [3100/4518] 68% | Training loss: 0.6870330197964946
Epoch: 61 | Iteration number: [3110/4518] 68% | Training loss: 0.6870305579958238
Epoch: 61 | Iteration number: [3120/4518] 69% | Training loss: 0.6870265615674166
Epoch: 61 | Iteration number: [3130/4518] 69% | Training loss: 0.6870250045301054
Epoch: 61 | Iteration number: [3140/4518] 69% | Training loss: 0.6870275174926042
Epoch: 61 | Iteration number: [3150/4518] 69% | Training loss: 0.6870275691388146
Epoch: 61 | Iteration number: [3160/4518] 69% | Training loss: 0.6870292064698437
Epoch: 61 | Iteration number: [3170/4518] 70% | Training loss: 0.6870280005578363
Epoch: 61 | Iteration number: [3180/4518] 70% | Training loss: 0.6870296663833114
Epoch: 61 | Iteration number: [3190/4518] 70% | Training loss: 0.687023313946111
Epoch: 61 | Iteration number: [3200/4518] 70% | Training loss: 0.6870261716283858
Epoch: 61 | Iteration number: [3210/4518] 71% | Training loss: 0.6870289555405531
Epoch: 61 | Iteration number: [3220/4518] 71% | Training loss: 0.6870266610050794
Epoch: 61 | Iteration number: [3230/4518] 71% | Training loss: 0.6870248170459972
Epoch: 61 | Iteration number: [3240/4518] 71% | Training loss: 0.6870242167586161
Epoch: 61 | Iteration number: [3250/4518] 71% | Training loss: 0.6870217315783868
Epoch: 61 | Iteration number: [3260/4518] 72% | Training loss: 0.6870214292790993
Epoch: 61 | Iteration number: [3270/4518] 72% | Training loss: 0.6870163483904043
Epoch: 61 | Iteration number: [3280/4518] 72% | Training loss: 0.6870142327394427
Epoch: 61 | Iteration number: [3290/4518] 72% | Training loss: 0.6870166501919187
Epoch: 61 | Iteration number: [3300/4518] 73% | Training loss: 0.6870134777011293
Epoch: 61 | Iteration number: [3310/4518] 73% | Training loss: 0.6870104049627874
Epoch: 61 | Iteration number: [3320/4518] 73% | Training loss: 0.6870093106146319
Epoch: 61 | Iteration number: [3330/4518] 73% | Training loss: 0.6870089878549089
Epoch: 61 | Iteration number: [3340/4518] 73% | Training loss: 0.6870084993675083
Epoch: 61 | Iteration number: [3350/4518] 74% | Training loss: 0.6870084850289928
Epoch: 61 | Iteration number: [3360/4518] 74% | Training loss: 0.6870057476063569
Epoch: 61 | Iteration number: [3370/4518] 74% | Training loss: 0.6870068287283447
Epoch: 61 | Iteration number: [3380/4518] 74% | Training loss: 0.6870076196257179
Epoch: 61 | Iteration number: [3390/4518] 75% | Training loss: 0.6870059734952133
Epoch: 61 | Iteration number: [3400/4518] 75% | Training loss: 0.6870018573543605
Epoch: 61 | Iteration number: [3410/4518] 75% | Training loss: 0.6870052791935258
Epoch: 61 | Iteration number: [3420/4518] 75% | Training loss: 0.6870039433763738
Epoch: 61 | Iteration number: [3430/4518] 75% | Training loss: 0.6870051753242926
Epoch: 61 | Iteration number: [3440/4518] 76% | Training loss: 0.6870062004688174
Epoch: 61 | Iteration number: [3450/4518] 76% | Training loss: 0.6870055421884509
Epoch: 61 | Iteration number: [3460/4518] 76% | Training loss: 0.6870095907263674
Epoch: 61 | Iteration number: [3470/4518] 76% | Training loss: 0.6870089049469841
Epoch: 61 | Iteration number: [3480/4518] 77% | Training loss: 0.6870069819106452
Epoch: 61 | Iteration number: [3490/4518] 77% | Training loss: 0.6870065967811213
Epoch: 61 | Iteration number: [3500/4518] 77% | Training loss: 0.687002764923232
Epoch: 61 | Iteration number: [3510/4518] 77% | Training loss: 0.6870022205375877
Epoch: 61 | Iteration number: [3520/4518] 77% | Training loss: 0.6869994947178797
Epoch: 61 | Iteration number: [3530/4518] 78% | Training loss: 0.6870026643992145
Epoch: 61 | Iteration number: [3540/4518] 78% | Training loss: 0.6870032111635316
Epoch: 61 | Iteration number: [3550/4518] 78% | Training loss: 0.6869965390084495
Epoch: 61 | Iteration number: [3560/4518] 78% | Training loss: 0.6869909479209546
Epoch: 61 | Iteration number: [3570/4518] 79% | Training loss: 0.686989130242532
Epoch: 61 | Iteration number: [3580/4518] 79% | Training loss: 0.6869924772884592
Epoch: 61 | Iteration number: [3590/4518] 79% | Training loss: 0.686990386695915
Epoch: 61 | Iteration number: [3600/4518] 79% | Training loss: 0.6869915911224154
Epoch: 61 | Iteration number: [3610/4518] 79% | Training loss: 0.6869885469902915
Epoch: 61 | Iteration number: [3620/4518] 80% | Training loss: 0.6869910284794497
Epoch: 61 | Iteration number: [3630/4518] 80% | Training loss: 0.686990689837243
Epoch: 61 | Iteration number: [3640/4518] 80% | Training loss: 0.6869894668296144
Epoch: 61 | Iteration number: [3650/4518] 80% | Training loss: 0.6869896025527014
Epoch: 61 | Iteration number: [3660/4518] 81% | Training loss: 0.6869906731479155
Epoch: 61 | Iteration number: [3670/4518] 81% | Training loss: 0.6869888011213869
Epoch: 61 | Iteration number: [3680/4518] 81% | Training loss: 0.6869885982054731
Epoch: 61 | Iteration number: [3690/4518] 81% | Training loss: 0.6869891124689159
Epoch: 61 | Iteration number: [3700/4518] 81% | Training loss: 0.6869870845047203
Epoch: 61 | Iteration number: [3710/4518] 82% | Training loss: 0.6869874212298431
Epoch: 61 | Iteration number: [3720/4518] 82% | Training loss: 0.6869866209004515
Epoch: 61 | Iteration number: [3730/4518] 82% | Training loss: 0.6869885858517869
Epoch: 61 | Iteration number: [3740/4518] 82% | Training loss: 0.6869846934303243
Epoch: 61 | Iteration number: [3750/4518] 83% | Training loss: 0.6869829737186431
Epoch: 61 | Iteration number: [3760/4518] 83% | Training loss: 0.686983837868939
Epoch: 61 | Iteration number: [3770/4518] 83% | Training loss: 0.6869820463878723
Epoch: 61 | Iteration number: [3780/4518] 83% | Training loss: 0.6869816312241176
Epoch: 61 | Iteration number: [3790/4518] 83% | Training loss: 0.6869803238669926
Epoch: 61 | Iteration number: [3800/4518] 84% | Training loss: 0.6869804558471629
Epoch: 61 | Iteration number: [3810/4518] 84% | Training loss: 0.6869852022392543
Epoch: 61 | Iteration number: [3820/4518] 84% | Training loss: 0.6869821262141173
Epoch: 61 | Iteration number: [3830/4518] 84% | Training loss: 0.6869809355966104
Epoch: 61 | Iteration number: [3840/4518] 84% | Training loss: 0.6869777055922895
Epoch: 61 | Iteration number: [3850/4518] 85% | Training loss: 0.6869764912592901
Epoch: 61 | Iteration number: [3860/4518] 85% | Training loss: 0.6869762640542935
Epoch: 61 | Iteration number: [3870/4518] 85% | Training loss: 0.6869766606686959
Epoch: 61 | Iteration number: [3880/4518] 85% | Training loss: 0.6869759855043028
Epoch: 61 | Iteration number: [3890/4518] 86% | Training loss: 0.6869732227913825
Epoch: 61 | Iteration number: [3900/4518] 86% | Training loss: 0.6869703550980641
Epoch: 61 | Iteration number: [3910/4518] 86% | Training loss: 0.6869708005577098
Epoch: 61 | Iteration number: [3920/4518] 86% | Training loss: 0.6869705139374246
Epoch: 61 | Iteration number: [3930/4518] 86% | Training loss: 0.6869665741617139
Epoch: 61 | Iteration number: [3940/4518] 87% | Training loss: 0.6869632572692058
Epoch: 61 | Iteration number: [3950/4518] 87% | Training loss: 0.6869646183599399
Epoch: 61 | Iteration number: [3960/4518] 87% | Training loss: 0.6869637335189666
Epoch: 61 | Iteration number: [3970/4518] 87% | Training loss: 0.6869650011699205
Epoch: 61 | Iteration number: [3980/4518] 88% | Training loss: 0.6869668111429742
Epoch: 61 | Iteration number: [3990/4518] 88% | Training loss: 0.6869662044042334
Epoch: 61 | Iteration number: [4000/4518] 88% | Training loss: 0.6869644989520312
Epoch: 61 | Iteration number: [4010/4518] 88% | Training loss: 0.6869637034183131
Epoch: 61 | Iteration number: [4020/4518] 88% | Training loss: 0.6869621484285563
Epoch: 61 | Iteration number: [4030/4518] 89% | Training loss: 0.6869609806732859
Epoch: 61 | Iteration number: [4040/4518] 89% | Training loss: 0.6869599475276352
Epoch: 61 | Iteration number: [4050/4518] 89% | Training loss: 0.6869604049494237
Epoch: 61 | Iteration number: [4060/4518] 89% | Training loss: 0.686960125644806
Epoch: 61 | Iteration number: [4070/4518] 90% | Training loss: 0.6869605791803074
Epoch: 61 | Iteration number: [4080/4518] 90% | Training loss: 0.6869612395909487
Epoch: 61 | Iteration number: [4090/4518] 90% | Training loss: 0.6869636216927274
Epoch: 61 | Iteration number: [4100/4518] 90% | Training loss: 0.6869607903608461
Epoch: 61 | Iteration number: [4110/4518] 90% | Training loss: 0.686960039652177
Epoch: 61 | Iteration number: [4120/4518] 91% | Training loss: 0.6869546675421659
Epoch: 61 | Iteration number: [4130/4518] 91% | Training loss: 0.6869541824296946
Epoch: 61 | Iteration number: [4140/4518] 91% | Training loss: 0.6869527589151825
Epoch: 61 | Iteration number: [4150/4518] 91% | Training loss: 0.6869508966336767
Epoch: 61 | Iteration number: [4160/4518] 92% | Training loss: 0.6869548105133267
Epoch: 61 | Iteration number: [4170/4518] 92% | Training loss: 0.6869526497322879
Epoch: 61 | Iteration number: [4180/4518] 92% | Training loss: 0.6869494230981078
Epoch: 61 | Iteration number: [4190/4518] 92% | Training loss: 0.6869485261616672
Epoch: 61 | Iteration number: [4200/4518] 92% | Training loss: 0.6869463029787654
Epoch: 61 | Iteration number: [4210/4518] 93% | Training loss: 0.6869490068627083
Epoch: 61 | Iteration number: [4220/4518] 93% | Training loss: 0.6869474711293858
Epoch: 61 | Iteration number: [4230/4518] 93% | Training loss: 0.6869499309829504
Epoch: 61 | Iteration number: [4240/4518] 93% | Training loss: 0.6869501362572301
Epoch: 61 | Iteration number: [4250/4518] 94% | Training loss: 0.6869526066639844
Epoch: 61 | Iteration number: [4260/4518] 94% | Training loss: 0.6869487907405191
Epoch: 61 | Iteration number: [4270/4518] 94% | Training loss: 0.686947358394395
Epoch: 61 | Iteration number: [4280/4518] 94% | Training loss: 0.6869478501031332
Epoch: 61 | Iteration number: [4290/4518] 94% | Training loss: 0.6869480810798965
Epoch: 61 | Iteration number: [4300/4518] 95% | Training loss: 0.6869451404449551
Epoch: 61 | Iteration number: [4310/4518] 95% | Training loss: 0.6869432617644423
Epoch: 61 | Iteration number: [4320/4518] 95% | Training loss: 0.6869440276037764
Epoch: 61 | Iteration number: [4330/4518] 95% | Training loss: 0.6869416980077158
Epoch: 61 | Iteration number: [4340/4518] 96% | Training loss: 0.6869427548712849
Epoch: 61 | Iteration number: [4350/4518] 96% | Training loss: 0.6869418408815888
Epoch: 61 | Iteration number: [4360/4518] 96% | Training loss: 0.6869385383544712
Epoch: 61 | Iteration number: [4370/4518] 96% | Training loss: 0.6869385512251603
Epoch: 61 | Iteration number: [4380/4518] 96% | Training loss: 0.6869410930975387
Epoch: 61 | Iteration number: [4390/4518] 97% | Training loss: 0.6869425241659334
Epoch: 61 | Iteration number: [4400/4518] 97% | Training loss: 0.6869420262629335
Epoch: 61 | Iteration number: [4410/4518] 97% | Training loss: 0.6869383972653456
Epoch: 61 | Iteration number: [4420/4518] 97% | Training loss: 0.6869379494254945
Epoch: 61 | Iteration number: [4430/4518] 98% | Training loss: 0.6869364637015366
Epoch: 61 | Iteration number: [4440/4518] 98% | Training loss: 0.686938386417187
Epoch: 61 | Iteration number: [4450/4518] 98% | Training loss: 0.6869362668910723
Epoch: 61 | Iteration number: [4460/4518] 98% | Training loss: 0.6869366034130344
Epoch: 61 | Iteration number: [4470/4518] 98% | Training loss: 0.6869342007626357
Epoch: 61 | Iteration number: [4480/4518] 99% | Training loss: 0.6869350044722004
Epoch: 61 | Iteration number: [4490/4518] 99% | Training loss: 0.6869359638616609
Epoch: 61 | Iteration number: [4500/4518] 99% | Training loss: 0.6869363097879622
Epoch: 61 | Iteration number: [4510/4518] 99% | Training loss: 0.6869341329433966

 End of epoch: 61 | Train Loss: 0.6867823320160191 | Training Time: 633 

 End of epoch: 61 | Eval Loss: 0.6896760415057747 | Evaluating Time: 17 
Epoch: 62 | Iteration number: [10/4518] 0% | Training loss: 0.7566694974899292
Epoch: 62 | Iteration number: [20/4518] 0% | Training loss: 0.7219068109989166
Epoch: 62 | Iteration number: [30/4518] 0% | Training loss: 0.7098390022913615
Epoch: 62 | Iteration number: [40/4518] 0% | Training loss: 0.7038451105356216
Epoch: 62 | Iteration number: [50/4518] 1% | Training loss: 0.7002625405788422
Epoch: 62 | Iteration number: [60/4518] 1% | Training loss: 0.6978108574946721
Epoch: 62 | Iteration number: [70/4518] 1% | Training loss: 0.6962850664343153
Epoch: 62 | Iteration number: [80/4518] 1% | Training loss: 0.6950460463762284
Epoch: 62 | Iteration number: [90/4518] 1% | Training loss: 0.6940941399998135
Epoch: 62 | Iteration number: [100/4518] 2% | Training loss: 0.6933392012119293
Epoch: 62 | Iteration number: [110/4518] 2% | Training loss: 0.6926811554215171
Epoch: 62 | Iteration number: [120/4518] 2% | Training loss: 0.6921401684482892
Epoch: 62 | Iteration number: [130/4518] 2% | Training loss: 0.6918135193678049
Epoch: 62 | Iteration number: [140/4518] 3% | Training loss: 0.691491260273116
Epoch: 62 | Iteration number: [150/4518] 3% | Training loss: 0.69122647245725
Epoch: 62 | Iteration number: [160/4518] 3% | Training loss: 0.6909901421517134
Epoch: 62 | Iteration number: [170/4518] 3% | Training loss: 0.6907442489091088
Epoch: 62 | Iteration number: [180/4518] 3% | Training loss: 0.6905498640404807
Epoch: 62 | Iteration number: [190/4518] 4% | Training loss: 0.6903455583672774
Epoch: 62 | Iteration number: [200/4518] 4% | Training loss: 0.6901234605908394
Epoch: 62 | Iteration number: [210/4518] 4% | Training loss: 0.6899907500970931
Epoch: 62 | Iteration number: [220/4518] 4% | Training loss: 0.689874882589687
Epoch: 62 | Iteration number: [230/4518] 5% | Training loss: 0.6897696774938832
Epoch: 62 | Iteration number: [240/4518] 5% | Training loss: 0.6896583663920561
Epoch: 62 | Iteration number: [250/4518] 5% | Training loss: 0.68947416305542
Epoch: 62 | Iteration number: [260/4518] 5% | Training loss: 0.6893914866905946
Epoch: 62 | Iteration number: [270/4518] 5% | Training loss: 0.6892943059956586
Epoch: 62 | Iteration number: [280/4518] 6% | Training loss: 0.6892254920942443
Epoch: 62 | Iteration number: [290/4518] 6% | Training loss: 0.6891388389570959
Epoch: 62 | Iteration number: [300/4518] 6% | Training loss: 0.6890234144528707
Epoch: 62 | Iteration number: [310/4518] 6% | Training loss: 0.6889630898352592
Epoch: 62 | Iteration number: [320/4518] 7% | Training loss: 0.6888971954584122
Epoch: 62 | Iteration number: [330/4518] 7% | Training loss: 0.6888414420864799
Epoch: 62 | Iteration number: [340/4518] 7% | Training loss: 0.6887555243337855
Epoch: 62 | Iteration number: [350/4518] 7% | Training loss: 0.6886871838569641
Epoch: 62 | Iteration number: [360/4518] 7% | Training loss: 0.688631777299775
Epoch: 62 | Iteration number: [370/4518] 8% | Training loss: 0.6885574166839187
Epoch: 62 | Iteration number: [380/4518] 8% | Training loss: 0.688512785654319
Epoch: 62 | Iteration number: [390/4518] 8% | Training loss: 0.6885065427193275
Epoch: 62 | Iteration number: [400/4518] 8% | Training loss: 0.6884506867825985
Epoch: 62 | Iteration number: [410/4518] 9% | Training loss: 0.6884039082178255
Epoch: 62 | Iteration number: [420/4518] 9% | Training loss: 0.688385349654016
Epoch: 62 | Iteration number: [430/4518] 9% | Training loss: 0.6883332084777743
Epoch: 62 | Iteration number: [440/4518] 9% | Training loss: 0.6883121854879639
Epoch: 62 | Iteration number: [450/4518] 9% | Training loss: 0.6882570166058011
Epoch: 62 | Iteration number: [460/4518] 10% | Training loss: 0.6882281497768734
Epoch: 62 | Iteration number: [470/4518] 10% | Training loss: 0.6882138149535403
Epoch: 62 | Iteration number: [480/4518] 10% | Training loss: 0.6881536519775788
Epoch: 62 | Iteration number: [490/4518] 10% | Training loss: 0.688153876698747
Epoch: 62 | Iteration number: [500/4518] 11% | Training loss: 0.6881577061414719
Epoch: 62 | Iteration number: [510/4518] 11% | Training loss: 0.6881436525606641
Epoch: 62 | Iteration number: [520/4518] 11% | Training loss: 0.688159483212691
Epoch: 62 | Iteration number: [530/4518] 11% | Training loss: 0.6881520884216956
Epoch: 62 | Iteration number: [540/4518] 11% | Training loss: 0.6881227923764123
Epoch: 62 | Iteration number: [550/4518] 12% | Training loss: 0.6880924991044132
Epoch: 62 | Iteration number: [560/4518] 12% | Training loss: 0.6880709396941321
Epoch: 62 | Iteration number: [570/4518] 12% | Training loss: 0.6880616658612302
Epoch: 62 | Iteration number: [580/4518] 12% | Training loss: 0.6880686869909023
Epoch: 62 | Iteration number: [590/4518] 13% | Training loss: 0.6880457233574431
Epoch: 62 | Iteration number: [600/4518] 13% | Training loss: 0.6880234143137932
Epoch: 62 | Iteration number: [610/4518] 13% | Training loss: 0.6880234548302947
Epoch: 62 | Iteration number: [620/4518] 13% | Training loss: 0.6879927961095686
Epoch: 62 | Iteration number: [630/4518] 13% | Training loss: 0.6879678303287142
Epoch: 62 | Iteration number: [640/4518] 14% | Training loss: 0.6879543185234069
Epoch: 62 | Iteration number: [650/4518] 14% | Training loss: 0.6879346804435437
Epoch: 62 | Iteration number: [660/4518] 14% | Training loss: 0.6879112398985661
Epoch: 62 | Iteration number: [670/4518] 14% | Training loss: 0.6879028048088301
Epoch: 62 | Iteration number: [680/4518] 15% | Training loss: 0.6878858992282082
Epoch: 62 | Iteration number: [690/4518] 15% | Training loss: 0.6878761241401451
Epoch: 62 | Iteration number: [700/4518] 15% | Training loss: 0.6878730508259364
Epoch: 62 | Iteration number: [710/4518] 15% | Training loss: 0.6878640289877502
Epoch: 62 | Iteration number: [720/4518] 15% | Training loss: 0.6878458418779902
Epoch: 62 | Iteration number: [730/4518] 16% | Training loss: 0.68781785213784
Epoch: 62 | Iteration number: [740/4518] 16% | Training loss: 0.6877943705868077
Epoch: 62 | Iteration number: [750/4518] 16% | Training loss: 0.687793489853541
Epoch: 62 | Iteration number: [760/4518] 16% | Training loss: 0.6877693666439307
Epoch: 62 | Iteration number: [770/4518] 17% | Training loss: 0.687743879216058
Epoch: 62 | Iteration number: [780/4518] 17% | Training loss: 0.6877388732555585
Epoch: 62 | Iteration number: [790/4518] 17% | Training loss: 0.6877368432811544
Epoch: 62 | Iteration number: [800/4518] 17% | Training loss: 0.68772505633533
Epoch: 62 | Iteration number: [810/4518] 17% | Training loss: 0.6877068745501247
Epoch: 62 | Iteration number: [820/4518] 18% | Training loss: 0.6876898550405735
Epoch: 62 | Iteration number: [830/4518] 18% | Training loss: 0.687675995568195
Epoch: 62 | Iteration number: [840/4518] 18% | Training loss: 0.6876551718938918
Epoch: 62 | Iteration number: [850/4518] 18% | Training loss: 0.6876392914267148
Epoch: 62 | Iteration number: [860/4518] 19% | Training loss: 0.6876279164885366
Epoch: 62 | Iteration number: [870/4518] 19% | Training loss: 0.6876253069817335
Epoch: 62 | Iteration number: [880/4518] 19% | Training loss: 0.6876225310970436
Epoch: 62 | Iteration number: [890/4518] 19% | Training loss: 0.687597205263845
Epoch: 62 | Iteration number: [900/4518] 19% | Training loss: 0.6875711464219623
Epoch: 62 | Iteration number: [910/4518] 20% | Training loss: 0.6875758019122449
Epoch: 62 | Iteration number: [920/4518] 20% | Training loss: 0.6875625938824985
Epoch: 62 | Iteration number: [930/4518] 20% | Training loss: 0.6875580486430917
Epoch: 62 | Iteration number: [940/4518] 20% | Training loss: 0.6875357572068559
Epoch: 62 | Iteration number: [950/4518] 21% | Training loss: 0.6875132320429149
Epoch: 62 | Iteration number: [960/4518] 21% | Training loss: 0.6875008900339404
Epoch: 62 | Iteration number: [970/4518] 21% | Training loss: 0.6874988076613121
Epoch: 62 | Iteration number: [980/4518] 21% | Training loss: 0.6874955101280796
Epoch: 62 | Iteration number: [990/4518] 21% | Training loss: 0.6874810892524141
Epoch: 62 | Iteration number: [1000/4518] 22% | Training loss: 0.6874920033216476
Epoch: 62 | Iteration number: [1010/4518] 22% | Training loss: 0.6874843334797586
Epoch: 62 | Iteration number: [1020/4518] 22% | Training loss: 0.687478563540122
Epoch: 62 | Iteration number: [1030/4518] 22% | Training loss: 0.6874757679920752
Epoch: 62 | Iteration number: [1040/4518] 23% | Training loss: 0.6874713303951117
Epoch: 62 | Iteration number: [1050/4518] 23% | Training loss: 0.6874678019114903
Epoch: 62 | Iteration number: [1060/4518] 23% | Training loss: 0.6874597934619435
Epoch: 62 | Iteration number: [1070/4518] 23% | Training loss: 0.6874446644961277
Epoch: 62 | Iteration number: [1080/4518] 23% | Training loss: 0.6874351048359164
Epoch: 62 | Iteration number: [1090/4518] 24% | Training loss: 0.6874234757292161
Epoch: 62 | Iteration number: [1100/4518] 24% | Training loss: 0.687423508438197
Epoch: 62 | Iteration number: [1110/4518] 24% | Training loss: 0.6874213764796386
Epoch: 62 | Iteration number: [1120/4518] 24% | Training loss: 0.6874088059578624
Epoch: 62 | Iteration number: [1130/4518] 25% | Training loss: 0.6874041905445335
Epoch: 62 | Iteration number: [1140/4518] 25% | Training loss: 0.6874124983423635
Epoch: 62 | Iteration number: [1150/4518] 25% | Training loss: 0.6873997997719309
Epoch: 62 | Iteration number: [1160/4518] 25% | Training loss: 0.6873980156820396
Epoch: 62 | Iteration number: [1170/4518] 25% | Training loss: 0.687385058352071
Epoch: 62 | Iteration number: [1180/4518] 26% | Training loss: 0.6873626408940655
Epoch: 62 | Iteration number: [1190/4518] 26% | Training loss: 0.6873694499500659
Epoch: 62 | Iteration number: [1200/4518] 26% | Training loss: 0.6873672427733739
Epoch: 62 | Iteration number: [1210/4518] 26% | Training loss: 0.6873697646885863
Epoch: 62 | Iteration number: [1220/4518] 27% | Training loss: 0.6873658933600442
Epoch: 62 | Iteration number: [1230/4518] 27% | Training loss: 0.6873694877798965
Epoch: 62 | Iteration number: [1240/4518] 27% | Training loss: 0.6873684632201349
Epoch: 62 | Iteration number: [1250/4518] 27% | Training loss: 0.6873638106822968
Epoch: 62 | Iteration number: [1260/4518] 27% | Training loss: 0.6873426075492587
Epoch: 62 | Iteration number: [1270/4518] 28% | Training loss: 0.687342276535635
Epoch: 62 | Iteration number: [1280/4518] 28% | Training loss: 0.6873455539811403
Epoch: 62 | Iteration number: [1290/4518] 28% | Training loss: 0.6873455911643745
Epoch: 62 | Iteration number: [1300/4518] 28% | Training loss: 0.6873496859807234
Epoch: 62 | Iteration number: [1310/4518] 28% | Training loss: 0.6873472011726321
Epoch: 62 | Iteration number: [1320/4518] 29% | Training loss: 0.6873345440987385
Epoch: 62 | Iteration number: [1330/4518] 29% | Training loss: 0.6873386514366121
Epoch: 62 | Iteration number: [1340/4518] 29% | Training loss: 0.6873416405115554
Epoch: 62 | Iteration number: [1350/4518] 29% | Training loss: 0.6873255799434803
Epoch: 62 | Iteration number: [1360/4518] 30% | Training loss: 0.6873128660899751
Epoch: 62 | Iteration number: [1370/4518] 30% | Training loss: 0.6873147701695017
Epoch: 62 | Iteration number: [1380/4518] 30% | Training loss: 0.6873103199661642
Epoch: 62 | Iteration number: [1390/4518] 30% | Training loss: 0.6872993267268586
Epoch: 62 | Iteration number: [1400/4518] 30% | Training loss: 0.6872995026196752
Epoch: 62 | Iteration number: [1410/4518] 31% | Training loss: 0.6872901487435009
Epoch: 62 | Iteration number: [1420/4518] 31% | Training loss: 0.6872878952765129
Epoch: 62 | Iteration number: [1430/4518] 31% | Training loss: 0.6872820066405343
Epoch: 62 | Iteration number: [1440/4518] 31% | Training loss: 0.6872828352368541
Epoch: 62 | Iteration number: [1450/4518] 32% | Training loss: 0.6872779253433491
Epoch: 62 | Iteration number: [1460/4518] 32% | Training loss: 0.6872836370174199
Epoch: 62 | Iteration number: [1470/4518] 32% | Training loss: 0.6872814075881932
Epoch: 62 | Iteration number: [1480/4518] 32% | Training loss: 0.6872823364025837
Epoch: 62 | Iteration number: [1490/4518] 32% | Training loss: 0.6872770774684497
Epoch: 62 | Iteration number: [1500/4518] 33% | Training loss: 0.6872811655600866
Epoch: 62 | Iteration number: [1510/4518] 33% | Training loss: 0.6872799003361076
Epoch: 62 | Iteration number: [1520/4518] 33% | Training loss: 0.6872854203377899
Epoch: 62 | Iteration number: [1530/4518] 33% | Training loss: 0.687280972603879
Epoch: 62 | Iteration number: [1540/4518] 34% | Training loss: 0.6872739880890041
Epoch: 62 | Iteration number: [1550/4518] 34% | Training loss: 0.6872759734430621
Epoch: 62 | Iteration number: [1560/4518] 34% | Training loss: 0.6872759292140985
Epoch: 62 | Iteration number: [1570/4518] 34% | Training loss: 0.687274235980526
Epoch: 62 | Iteration number: [1580/4518] 34% | Training loss: 0.6872675517314597
Epoch: 62 | Iteration number: [1590/4518] 35% | Training loss: 0.687267041993591
Epoch: 62 | Iteration number: [1600/4518] 35% | Training loss: 0.6872704947367311
Epoch: 62 | Iteration number: [1610/4518] 35% | Training loss: 0.6872666041303125
Epoch: 62 | Iteration number: [1620/4518] 35% | Training loss: 0.6872681106314247
Epoch: 62 | Iteration number: [1630/4518] 36% | Training loss: 0.687271384337197
Epoch: 62 | Iteration number: [1640/4518] 36% | Training loss: 0.6872753345021387
Epoch: 62 | Iteration number: [1650/4518] 36% | Training loss: 0.6872714974302234
Epoch: 62 | Iteration number: [1660/4518] 36% | Training loss: 0.6872750128249088
Epoch: 62 | Iteration number: [1670/4518] 36% | Training loss: 0.6872696516042698
Epoch: 62 | Iteration number: [1680/4518] 37% | Training loss: 0.6872721311237131
Epoch: 62 | Iteration number: [1690/4518] 37% | Training loss: 0.6872677822437512
Epoch: 62 | Iteration number: [1700/4518] 37% | Training loss: 0.6872653299920699
Epoch: 62 | Iteration number: [1710/4518] 37% | Training loss: 0.6872651635206234
Epoch: 62 | Iteration number: [1720/4518] 38% | Training loss: 0.6872709524146347
Epoch: 62 | Iteration number: [1730/4518] 38% | Training loss: 0.6872612887379751
Epoch: 62 | Iteration number: [1740/4518] 38% | Training loss: 0.6872612354056589
Epoch: 62 | Iteration number: [1750/4518] 38% | Training loss: 0.687259719133377
Epoch: 62 | Iteration number: [1760/4518] 38% | Training loss: 0.6872645153579386
Epoch: 62 | Iteration number: [1770/4518] 39% | Training loss: 0.687268263539352
Epoch: 62 | Iteration number: [1780/4518] 39% | Training loss: 0.6872574044077584
Epoch: 62 | Iteration number: [1790/4518] 39% | Training loss: 0.68725070830164
Epoch: 62 | Iteration number: [1800/4518] 39% | Training loss: 0.6872536672486199
Epoch: 62 | Iteration number: [1810/4518] 40% | Training loss: 0.6872433913346813
Epoch: 62 | Iteration number: [1820/4518] 40% | Training loss: 0.6872391316916916
Epoch: 62 | Iteration number: [1830/4518] 40% | Training loss: 0.6872370176302279
Epoch: 62 | Iteration number: [1840/4518] 40% | Training loss: 0.6872373278698195
Epoch: 62 | Iteration number: [1850/4518] 40% | Training loss: 0.6872336999467902
Epoch: 62 | Iteration number: [1860/4518] 41% | Training loss: 0.6872410776794597
Epoch: 62 | Iteration number: [1870/4518] 41% | Training loss: 0.6872389984959587
Epoch: 62 | Iteration number: [1880/4518] 41% | Training loss: 0.6872312949375904
Epoch: 62 | Iteration number: [1890/4518] 41% | Training loss: 0.6872247441420479
Epoch: 62 | Iteration number: [1900/4518] 42% | Training loss: 0.6872199158292067
Epoch: 62 | Iteration number: [1910/4518] 42% | Training loss: 0.6872198983636826
Epoch: 62 | Iteration number: [1920/4518] 42% | Training loss: 0.6872094968333841
Epoch: 62 | Iteration number: [1930/4518] 42% | Training loss: 0.6872028606543269
Epoch: 62 | Iteration number: [1940/4518] 42% | Training loss: 0.6872031435216825
Epoch: 62 | Iteration number: [1950/4518] 43% | Training loss: 0.687203521820215
Epoch: 62 | Iteration number: [1960/4518] 43% | Training loss: 0.6871968736758037
Epoch: 62 | Iteration number: [1970/4518] 43% | Training loss: 0.6871978141329615
Epoch: 62 | Iteration number: [1980/4518] 43% | Training loss: 0.6872046048292005
Epoch: 62 | Iteration number: [1990/4518] 44% | Training loss: 0.6871938080344367
Epoch: 62 | Iteration number: [2000/4518] 44% | Training loss: 0.6871912797391415
Epoch: 62 | Iteration number: [2010/4518] 44% | Training loss: 0.6871893970824
Epoch: 62 | Iteration number: [2020/4518] 44% | Training loss: 0.6871914378487237
Epoch: 62 | Iteration number: [2030/4518] 44% | Training loss: 0.6871918973957963
Epoch: 62 | Iteration number: [2040/4518] 45% | Training loss: 0.6871869348427828
Epoch: 62 | Iteration number: [2050/4518] 45% | Training loss: 0.6871783221930993
Epoch: 62 | Iteration number: [2060/4518] 45% | Training loss: 0.6871736154683585
Epoch: 62 | Iteration number: [2070/4518] 45% | Training loss: 0.6871767496429204
Epoch: 62 | Iteration number: [2080/4518] 46% | Training loss: 0.687171518888611
Epoch: 62 | Iteration number: [2090/4518] 46% | Training loss: 0.6871655436794153
Epoch: 62 | Iteration number: [2100/4518] 46% | Training loss: 0.687161447377432
Epoch: 62 | Iteration number: [2110/4518] 46% | Training loss: 0.6871619882176838
Epoch: 62 | Iteration number: [2120/4518] 46% | Training loss: 0.6871607737721137
Epoch: 62 | Iteration number: [2130/4518] 47% | Training loss: 0.6871509563475148
Epoch: 62 | Iteration number: [2140/4518] 47% | Training loss: 0.687143239462487
Epoch: 62 | Iteration number: [2150/4518] 47% | Training loss: 0.6871398191673811
Epoch: 62 | Iteration number: [2160/4518] 47% | Training loss: 0.6871407434620239
Epoch: 62 | Iteration number: [2170/4518] 48% | Training loss: 0.6871409063515026
Epoch: 62 | Iteration number: [2180/4518] 48% | Training loss: 0.6871357729675573
Epoch: 62 | Iteration number: [2190/4518] 48% | Training loss: 0.6871350535791214
Epoch: 62 | Iteration number: [2200/4518] 48% | Training loss: 0.6871364138072187
Epoch: 62 | Iteration number: [2210/4518] 48% | Training loss: 0.6871324616859401
Epoch: 62 | Iteration number: [2220/4518] 49% | Training loss: 0.6871328510411151
Epoch: 62 | Iteration number: [2230/4518] 49% | Training loss: 0.6871328452777435
Epoch: 62 | Iteration number: [2240/4518] 49% | Training loss: 0.6871252502979976
Epoch: 62 | Iteration number: [2250/4518] 49% | Training loss: 0.6871207430097792
Epoch: 62 | Iteration number: [2260/4518] 50% | Training loss: 0.6871256718329624
Epoch: 62 | Iteration number: [2270/4518] 50% | Training loss: 0.6871204173774972
Epoch: 62 | Iteration number: [2280/4518] 50% | Training loss: 0.6871145617020757
Epoch: 62 | Iteration number: [2290/4518] 50% | Training loss: 0.6871195140103585
Epoch: 62 | Iteration number: [2300/4518] 50% | Training loss: 0.6871101274438526
Epoch: 62 | Iteration number: [2310/4518] 51% | Training loss: 0.6871097351565506
Epoch: 62 | Iteration number: [2320/4518] 51% | Training loss: 0.6871116314725629
Epoch: 62 | Iteration number: [2330/4518] 51% | Training loss: 0.6871095038534746
Epoch: 62 | Iteration number: [2340/4518] 51% | Training loss: 0.6871063405631954
Epoch: 62 | Iteration number: [2350/4518] 52% | Training loss: 0.6871012893636176
Epoch: 62 | Iteration number: [2360/4518] 52% | Training loss: 0.6871025748172048
Epoch: 62 | Iteration number: [2370/4518] 52% | Training loss: 0.6870972952510738
Epoch: 62 | Iteration number: [2380/4518] 52% | Training loss: 0.6870975551234574
Epoch: 62 | Iteration number: [2390/4518] 52% | Training loss: 0.6871030819964709
Epoch: 62 | Iteration number: [2400/4518] 53% | Training loss: 0.6870949506759644
Epoch: 62 | Iteration number: [2410/4518] 53% | Training loss: 0.687099381551703
Epoch: 62 | Iteration number: [2420/4518] 53% | Training loss: 0.6870996322513612
Epoch: 62 | Iteration number: [2430/4518] 53% | Training loss: 0.6870981759740492
Epoch: 62 | Iteration number: [2440/4518] 54% | Training loss: 0.687096352557667
Epoch: 62 | Iteration number: [2450/4518] 54% | Training loss: 0.6870927289797335
Epoch: 62 | Iteration number: [2460/4518] 54% | Training loss: 0.6870937457414177
Epoch: 62 | Iteration number: [2470/4518] 54% | Training loss: 0.6870970437159905
Epoch: 62 | Iteration number: [2480/4518] 54% | Training loss: 0.6870948055098134
Epoch: 62 | Iteration number: [2490/4518] 55% | Training loss: 0.6870952095133234
Epoch: 62 | Iteration number: [2500/4518] 55% | Training loss: 0.6870964014291764
Epoch: 62 | Iteration number: [2510/4518] 55% | Training loss: 0.6870912470428118
Epoch: 62 | Iteration number: [2520/4518] 55% | Training loss: 0.687088930417621
Epoch: 62 | Iteration number: [2530/4518] 55% | Training loss: 0.6870910926534253
Epoch: 62 | Iteration number: [2540/4518] 56% | Training loss: 0.6870827540403276
Epoch: 62 | Iteration number: [2550/4518] 56% | Training loss: 0.6870837227503459
Epoch: 62 | Iteration number: [2560/4518] 56% | Training loss: 0.6870838042581454
Epoch: 62 | Iteration number: [2570/4518] 56% | Training loss: 0.687084034792644
Epoch: 62 | Iteration number: [2580/4518] 57% | Training loss: 0.6870810690776322
Epoch: 62 | Iteration number: [2590/4518] 57% | Training loss: 0.6870853865468824
Epoch: 62 | Iteration number: [2600/4518] 57% | Training loss: 0.687083769096778
Epoch: 62 | Iteration number: [2610/4518] 57% | Training loss: 0.6870836416195178
Epoch: 62 | Iteration number: [2620/4518] 57% | Training loss: 0.6870805742631432
Epoch: 62 | Iteration number: [2630/4518] 58% | Training loss: 0.687078956619415
Epoch: 62 | Iteration number: [2640/4518] 58% | Training loss: 0.6870785806440945
Epoch: 62 | Iteration number: [2650/4518] 58% | Training loss: 0.6870766912316376
Epoch: 62 | Iteration number: [2660/4518] 58% | Training loss: 0.6870775403384876
Epoch: 62 | Iteration number: [2670/4518] 59% | Training loss: 0.6870761701899968
Epoch: 62 | Iteration number: [2680/4518] 59% | Training loss: 0.687068215123753
Epoch: 62 | Iteration number: [2690/4518] 59% | Training loss: 0.687068625209943
Epoch: 62 | Iteration number: [2700/4518] 59% | Training loss: 0.6870653894874784
Epoch: 62 | Iteration number: [2710/4518] 59% | Training loss: 0.6870653529448703
Epoch: 62 | Iteration number: [2720/4518] 60% | Training loss: 0.6870657855535255
Epoch: 62 | Iteration number: [2730/4518] 60% | Training loss: 0.6870632483627334
Epoch: 62 | Iteration number: [2740/4518] 60% | Training loss: 0.687061432134496
Epoch: 62 | Iteration number: [2750/4518] 60% | Training loss: 0.687065218557011
Epoch: 62 | Iteration number: [2760/4518] 61% | Training loss: 0.6870637703417004
Epoch: 62 | Iteration number: [2770/4518] 61% | Training loss: 0.687062576553021
Epoch: 62 | Iteration number: [2780/4518] 61% | Training loss: 0.687064386421828
Epoch: 62 | Iteration number: [2790/4518] 61% | Training loss: 0.6870618402317006
Epoch: 62 | Iteration number: [2800/4518] 61% | Training loss: 0.6870586799723761
Epoch: 62 | Iteration number: [2810/4518] 62% | Training loss: 0.6870581066905391
Epoch: 62 | Iteration number: [2820/4518] 62% | Training loss: 0.6870513126993856
Epoch: 62 | Iteration number: [2830/4518] 62% | Training loss: 0.6870526764923608
Epoch: 62 | Iteration number: [2840/4518] 62% | Training loss: 0.6870527310270659
Epoch: 62 | Iteration number: [2850/4518] 63% | Training loss: 0.6870523768349698
Epoch: 62 | Iteration number: [2860/4518] 63% | Training loss: 0.6870555684491471
Epoch: 62 | Iteration number: [2870/4518] 63% | Training loss: 0.6870495337434762
Epoch: 62 | Iteration number: [2880/4518] 63% | Training loss: 0.6870494814589619
Epoch: 62 | Iteration number: [2890/4518] 63% | Training loss: 0.6870469290904933
Epoch: 62 | Iteration number: [2900/4518] 64% | Training loss: 0.6870473201110445
Epoch: 62 | Iteration number: [2910/4518] 64% | Training loss: 0.6870547296869796
Epoch: 62 | Iteration number: [2920/4518] 64% | Training loss: 0.6870508858602341
Epoch: 62 | Iteration number: [2930/4518] 64% | Training loss: 0.6870493811958885
Epoch: 62 | Iteration number: [2940/4518] 65% | Training loss: 0.687049508784093
Epoch: 62 | Iteration number: [2950/4518] 65% | Training loss: 0.6870514918181856
Epoch: 62 | Iteration number: [2960/4518] 65% | Training loss: 0.6870515984860627
Epoch: 62 | Iteration number: [2970/4518] 65% | Training loss: 0.6870531377968965
Epoch: 62 | Iteration number: [2980/4518] 65% | Training loss: 0.6870505569765232
Epoch: 62 | Iteration number: [2990/4518] 66% | Training loss: 0.6870522932464064
Epoch: 62 | Iteration number: [3000/4518] 66% | Training loss: 0.6870477579236031
Epoch: 62 | Iteration number: [3010/4518] 66% | Training loss: 0.687041533884416
Epoch: 62 | Iteration number: [3020/4518] 66% | Training loss: 0.6870348580428307
Epoch: 62 | Iteration number: [3030/4518] 67% | Training loss: 0.6870364998433456
Epoch: 62 | Iteration number: [3040/4518] 67% | Training loss: 0.687038930231019
Epoch: 62 | Iteration number: [3050/4518] 67% | Training loss: 0.6870367433790301
Epoch: 62 | Iteration number: [3060/4518] 67% | Training loss: 0.6870353154497209
Epoch: 62 | Iteration number: [3070/4518] 67% | Training loss: 0.6870324021830233
Epoch: 62 | Iteration number: [3080/4518] 68% | Training loss: 0.6870328937451561
Epoch: 62 | Iteration number: [3090/4518] 68% | Training loss: 0.6870287111661967
Epoch: 62 | Iteration number: [3100/4518] 68% | Training loss: 0.687028463117538
Epoch: 62 | Iteration number: [3110/4518] 68% | Training loss: 0.6870269233582488
Epoch: 62 | Iteration number: [3120/4518] 69% | Training loss: 0.6870303650888113
Epoch: 62 | Iteration number: [3130/4518] 69% | Training loss: 0.6870278889759661
Epoch: 62 | Iteration number: [3140/4518] 69% | Training loss: 0.6870279906471823
Epoch: 62 | Iteration number: [3150/4518] 69% | Training loss: 0.6870270461317093
Epoch: 62 | Iteration number: [3160/4518] 69% | Training loss: 0.6870249432099016
Epoch: 62 | Iteration number: [3170/4518] 70% | Training loss: 0.6870235795290313
Epoch: 62 | Iteration number: [3180/4518] 70% | Training loss: 0.6870271514984047
Epoch: 62 | Iteration number: [3190/4518] 70% | Training loss: 0.6870281142314026
Epoch: 62 | Iteration number: [3200/4518] 70% | Training loss: 0.6870289972797036
Epoch: 62 | Iteration number: [3210/4518] 71% | Training loss: 0.6870296339565348
Epoch: 62 | Iteration number: [3220/4518] 71% | Training loss: 0.6870294368415145
Epoch: 62 | Iteration number: [3230/4518] 71% | Training loss: 0.6870265688320432
Epoch: 62 | Iteration number: [3240/4518] 71% | Training loss: 0.6870253465241856
Epoch: 62 | Iteration number: [3250/4518] 71% | Training loss: 0.6870207923742441
Epoch: 62 | Iteration number: [3260/4518] 72% | Training loss: 0.6870172455084105
Epoch: 62 | Iteration number: [3270/4518] 72% | Training loss: 0.6870119972695633
Epoch: 62 | Iteration number: [3280/4518] 72% | Training loss: 0.687007734833694
Epoch: 62 | Iteration number: [3290/4518] 72% | Training loss: 0.6870028840372265
Epoch: 62 | Iteration number: [3300/4518] 73% | Training loss: 0.6870009306705359
Epoch: 62 | Iteration number: [3310/4518] 73% | Training loss: 0.6869988778206517
Epoch: 62 | Iteration number: [3320/4518] 73% | Training loss: 0.686993923837162
Epoch: 62 | Iteration number: [3330/4518] 73% | Training loss: 0.6869951394227174
Epoch: 62 | Iteration number: [3340/4518] 73% | Training loss: 0.6869943320572733
Epoch: 62 | Iteration number: [3350/4518] 74% | Training loss: 0.6869985587383384
Epoch: 62 | Iteration number: [3360/4518] 74% | Training loss: 0.6869979183056525
Epoch: 62 | Iteration number: [3370/4518] 74% | Training loss: 0.6869999911735603
Epoch: 62 | Iteration number: [3380/4518] 74% | Training loss: 0.6869974189961451
Epoch: 62 | Iteration number: [3390/4518] 75% | Training loss: 0.6869965789240722
Epoch: 62 | Iteration number: [3400/4518] 75% | Training loss: 0.6869959844210568
Epoch: 62 | Iteration number: [3410/4518] 75% | Training loss: 0.6869939334056944
Epoch: 62 | Iteration number: [3420/4518] 75% | Training loss: 0.6869919174944448
Epoch: 62 | Iteration number: [3430/4518] 75% | Training loss: 0.6869899858886229
Epoch: 62 | Iteration number: [3440/4518] 76% | Training loss: 0.6869925965056863
Epoch: 62 | Iteration number: [3450/4518] 76% | Training loss: 0.6869928471765656
Epoch: 62 | Iteration number: [3460/4518] 76% | Training loss: 0.6869917290059129
Epoch: 62 | Iteration number: [3470/4518] 76% | Training loss: 0.6869847160938494
Epoch: 62 | Iteration number: [3480/4518] 77% | Training loss: 0.6869865825121431
Epoch: 62 | Iteration number: [3490/4518] 77% | Training loss: 0.686986478847214
Epoch: 62 | Iteration number: [3500/4518] 77% | Training loss: 0.6869854422807693
Epoch: 62 | Iteration number: [3510/4518] 77% | Training loss: 0.686984811498229
Epoch: 62 | Iteration number: [3520/4518] 77% | Training loss: 0.6869850290600549
Epoch: 62 | Iteration number: [3530/4518] 78% | Training loss: 0.6869811882378359
Epoch: 62 | Iteration number: [3540/4518] 78% | Training loss: 0.6869801501769804
Epoch: 62 | Iteration number: [3550/4518] 78% | Training loss: 0.6869784251736923
Epoch: 62 | Iteration number: [3560/4518] 78% | Training loss: 0.6869804543223273
Epoch: 62 | Iteration number: [3570/4518] 79% | Training loss: 0.686978032592298
Epoch: 62 | Iteration number: [3580/4518] 79% | Training loss: 0.6869768451878479
Epoch: 62 | Iteration number: [3590/4518] 79% | Training loss: 0.6869780757799122
Epoch: 62 | Iteration number: [3600/4518] 79% | Training loss: 0.6869775962167316
Epoch: 62 | Iteration number: [3610/4518] 79% | Training loss: 0.6869756749627333
Epoch: 62 | Iteration number: [3620/4518] 80% | Training loss: 0.6869724258204192
Epoch: 62 | Iteration number: [3630/4518] 80% | Training loss: 0.6869693134277649
Epoch: 62 | Iteration number: [3640/4518] 80% | Training loss: 0.6869649696481097
Epoch: 62 | Iteration number: [3650/4518] 80% | Training loss: 0.6869640513642193
Epoch: 62 | Iteration number: [3660/4518] 81% | Training loss: 0.6869637554297682
Epoch: 62 | Iteration number: [3670/4518] 81% | Training loss: 0.6869677748439748
Epoch: 62 | Iteration number: [3680/4518] 81% | Training loss: 0.6869698920165715
Epoch: 62 | Iteration number: [3690/4518] 81% | Training loss: 0.6869699279467265
Epoch: 62 | Iteration number: [3700/4518] 81% | Training loss: 0.6869683658754503
Epoch: 62 | Iteration number: [3710/4518] 82% | Training loss: 0.6869684907946625
Epoch: 62 | Iteration number: [3720/4518] 82% | Training loss: 0.6869706343579036
Epoch: 62 | Iteration number: [3730/4518] 82% | Training loss: 0.6869721026586784
Epoch: 62 | Iteration number: [3740/4518] 82% | Training loss: 0.6869731833112431
Epoch: 62 | Iteration number: [3750/4518] 83% | Training loss: 0.6869728672822316
Epoch: 62 | Iteration number: [3760/4518] 83% | Training loss: 0.6869709665153889
Epoch: 62 | Iteration number: [3770/4518] 83% | Training loss: 0.6869684674695569
Epoch: 62 | Iteration number: [3780/4518] 83% | Training loss: 0.6869711160502106
Epoch: 62 | Iteration number: [3790/4518] 83% | Training loss: 0.6869685096602327
Epoch: 62 | Iteration number: [3800/4518] 84% | Training loss: 0.6869649725211294
Epoch: 62 | Iteration number: [3810/4518] 84% | Training loss: 0.686963656881037
Epoch: 62 | Iteration number: [3820/4518] 84% | Training loss: 0.686965960014553
Epoch: 62 | Iteration number: [3830/4518] 84% | Training loss: 0.6869667169630683
Epoch: 62 | Iteration number: [3840/4518] 84% | Training loss: 0.6869655035746595
Epoch: 62 | Iteration number: [3850/4518] 85% | Training loss: 0.6869649381142158
Epoch: 62 | Iteration number: [3860/4518] 85% | Training loss: 0.6869657101254389
Epoch: 62 | Iteration number: [3870/4518] 85% | Training loss: 0.6869632686601437
Epoch: 62 | Iteration number: [3880/4518] 85% | Training loss: 0.6869605631557937
Epoch: 62 | Iteration number: [3890/4518] 86% | Training loss: 0.6869598502518279
Epoch: 62 | Iteration number: [3900/4518] 86% | Training loss: 0.6869566936370654
Epoch: 62 | Iteration number: [3910/4518] 86% | Training loss: 0.6869571358041691
Epoch: 62 | Iteration number: [3920/4518] 86% | Training loss: 0.6869580444176586
Epoch: 62 | Iteration number: [3930/4518] 86% | Training loss: 0.6869592248483468
Epoch: 62 | Iteration number: [3940/4518] 87% | Training loss: 0.6869560542596779
Epoch: 62 | Iteration number: [3950/4518] 87% | Training loss: 0.6869540635090841
Epoch: 62 | Iteration number: [3960/4518] 87% | Training loss: 0.6869527551561895
Epoch: 62 | Iteration number: [3970/4518] 87% | Training loss: 0.6869500855955128
Epoch: 62 | Iteration number: [3980/4518] 88% | Training loss: 0.6869484354652952
Epoch: 62 | Iteration number: [3990/4518] 88% | Training loss: 0.6869491450918049
Epoch: 62 | Iteration number: [4000/4518] 88% | Training loss: 0.6869467989355326
Epoch: 62 | Iteration number: [4010/4518] 88% | Training loss: 0.6869473492266829
Epoch: 62 | Iteration number: [4020/4518] 88% | Training loss: 0.6869468674879169
Epoch: 62 | Iteration number: [4030/4518] 89% | Training loss: 0.6869454012171506
Epoch: 62 | Iteration number: [4040/4518] 89% | Training loss: 0.6869470675097834
Epoch: 62 | Iteration number: [4050/4518] 89% | Training loss: 0.6869499580654097
Epoch: 62 | Iteration number: [4060/4518] 89% | Training loss: 0.6869486203334602
Epoch: 62 | Iteration number: [4070/4518] 90% | Training loss: 0.68694653140532
Epoch: 62 | Iteration number: [4080/4518] 90% | Training loss: 0.6869465464178254
Epoch: 62 | Iteration number: [4090/4518] 90% | Training loss: 0.6869440375446981
Epoch: 62 | Iteration number: [4100/4518] 90% | Training loss: 0.6869435670753805
Epoch: 62 | Iteration number: [4110/4518] 90% | Training loss: 0.6869436840941436
Epoch: 62 | Iteration number: [4120/4518] 91% | Training loss: 0.686945009000093
Epoch: 62 | Iteration number: [4130/4518] 91% | Training loss: 0.68694117489219
Epoch: 62 | Iteration number: [4140/4518] 91% | Training loss: 0.6869395859575502
Epoch: 62 | Iteration number: [4150/4518] 91% | Training loss: 0.68693738898599
Epoch: 62 | Iteration number: [4160/4518] 92% | Training loss: 0.6869342877457921
Epoch: 62 | Iteration number: [4170/4518] 92% | Training loss: 0.686936279952669
Epoch: 62 | Iteration number: [4180/4518] 92% | Training loss: 0.6869355541952489
Epoch: 62 | Iteration number: [4190/4518] 92% | Training loss: 0.6869335773452085
Epoch: 62 | Iteration number: [4200/4518] 92% | Training loss: 0.6869321075365656
Epoch: 62 | Iteration number: [4210/4518] 93% | Training loss: 0.6869312610733821
Epoch: 62 | Iteration number: [4220/4518] 93% | Training loss: 0.6869276894636064
Epoch: 62 | Iteration number: [4230/4518] 93% | Training loss: 0.6869278055133549
Epoch: 62 | Iteration number: [4240/4518] 93% | Training loss: 0.6869294723812139
Epoch: 62 | Iteration number: [4250/4518] 94% | Training loss: 0.6869311186145334
Epoch: 62 | Iteration number: [4260/4518] 94% | Training loss: 0.6869294932050884
Epoch: 62 | Iteration number: [4270/4518] 94% | Training loss: 0.6869303570139883
Epoch: 62 | Iteration number: [4280/4518] 94% | Training loss: 0.6869290477204546
Epoch: 62 | Iteration number: [4290/4518] 94% | Training loss: 0.6869290836346456
Epoch: 62 | Iteration number: [4300/4518] 95% | Training loss: 0.6869291729428048
Epoch: 62 | Iteration number: [4310/4518] 95% | Training loss: 0.6869287687775154
Epoch: 62 | Iteration number: [4320/4518] 95% | Training loss: 0.6869293721599712
Epoch: 62 | Iteration number: [4330/4518] 95% | Training loss: 0.686930485327855
Epoch: 62 | Iteration number: [4340/4518] 96% | Training loss: 0.6869298989871679
Epoch: 62 | Iteration number: [4350/4518] 96% | Training loss: 0.6869322078529445
Epoch: 62 | Iteration number: [4360/4518] 96% | Training loss: 0.686932330257302
Epoch: 62 | Iteration number: [4370/4518] 96% | Training loss: 0.6869313294609297
Epoch: 62 | Iteration number: [4380/4518] 96% | Training loss: 0.6869303088890363
Epoch: 62 | Iteration number: [4390/4518] 97% | Training loss: 0.6869327804493741
Epoch: 62 | Iteration number: [4400/4518] 97% | Training loss: 0.6869332591647451
Epoch: 62 | Iteration number: [4410/4518] 97% | Training loss: 0.6869320687388076
Epoch: 62 | Iteration number: [4420/4518] 97% | Training loss: 0.6869312106484202
Epoch: 62 | Iteration number: [4430/4518] 98% | Training loss: 0.6869320128222351
Epoch: 62 | Iteration number: [4440/4518] 98% | Training loss: 0.6869322292842307
Epoch: 62 | Iteration number: [4450/4518] 98% | Training loss: 0.686933731992593
Epoch: 62 | Iteration number: [4460/4518] 98% | Training loss: 0.6869340411082512
Epoch: 62 | Iteration number: [4470/4518] 98% | Training loss: 0.6869338789242226
Epoch: 62 | Iteration number: [4480/4518] 99% | Training loss: 0.6869352333114616
Epoch: 62 | Iteration number: [4490/4518] 99% | Training loss: 0.6869354181008244
Epoch: 62 | Iteration number: [4500/4518] 99% | Training loss: 0.6869360054334005
Epoch: 62 | Iteration number: [4510/4518] 99% | Training loss: 0.6869382051961649

 End of epoch: 62 | Train Loss: 0.6867847327454631 | Training Time: 632 

 End of epoch: 62 | Eval Loss: 0.6896919060726555 | Evaluating Time: 16 
Epoch: 63 | Iteration number: [10/4518] 0% | Training loss: 0.7555963695049286
Epoch: 63 | Iteration number: [20/4518] 0% | Training loss: 0.7209356218576431
Epoch: 63 | Iteration number: [30/4518] 0% | Training loss: 0.7096773326396942
Epoch: 63 | Iteration number: [40/4518] 0% | Training loss: 0.7036027580499649
Epoch: 63 | Iteration number: [50/4518] 1% | Training loss: 0.7000430178642273
Epoch: 63 | Iteration number: [60/4518] 1% | Training loss: 0.6979376941919326
Epoch: 63 | Iteration number: [70/4518] 1% | Training loss: 0.6962620369025639
Epoch: 63 | Iteration number: [80/4518] 1% | Training loss: 0.6950474567711353
Epoch: 63 | Iteration number: [90/4518] 1% | Training loss: 0.6940453297562069
Epoch: 63 | Iteration number: [100/4518] 2% | Training loss: 0.6934481090307236
Epoch: 63 | Iteration number: [110/4518] 2% | Training loss: 0.6928691956129941
Epoch: 63 | Iteration number: [120/4518] 2% | Training loss: 0.6923732414841652
Epoch: 63 | Iteration number: [130/4518] 2% | Training loss: 0.6920024358309232
Epoch: 63 | Iteration number: [140/4518] 3% | Training loss: 0.6915659972599575
Epoch: 63 | Iteration number: [150/4518] 3% | Training loss: 0.691208941936493
Epoch: 63 | Iteration number: [160/4518] 3% | Training loss: 0.6909716956317424
Epoch: 63 | Iteration number: [170/4518] 3% | Training loss: 0.6907496220925275
Epoch: 63 | Iteration number: [180/4518] 3% | Training loss: 0.690545474158393
Epoch: 63 | Iteration number: [190/4518] 4% | Training loss: 0.6904185408040097
Epoch: 63 | Iteration number: [200/4518] 4% | Training loss: 0.690167346894741
Epoch: 63 | Iteration number: [210/4518] 4% | Training loss: 0.6899936627774012
Epoch: 63 | Iteration number: [220/4518] 4% | Training loss: 0.6899062023921446
Epoch: 63 | Iteration number: [230/4518] 5% | Training loss: 0.6898220049298328
Epoch: 63 | Iteration number: [240/4518] 5% | Training loss: 0.6896917449931304
Epoch: 63 | Iteration number: [250/4518] 5% | Training loss: 0.6895818681716919
Epoch: 63 | Iteration number: [260/4518] 5% | Training loss: 0.689426284799209
Epoch: 63 | Iteration number: [270/4518] 5% | Training loss: 0.6893283424554048
Epoch: 63 | Iteration number: [280/4518] 6% | Training loss: 0.6892123539532934
Epoch: 63 | Iteration number: [290/4518] 6% | Training loss: 0.6891121788271543
Epoch: 63 | Iteration number: [300/4518] 6% | Training loss: 0.6890690286954244
Epoch: 63 | Iteration number: [310/4518] 6% | Training loss: 0.6890115949415392
Epoch: 63 | Iteration number: [320/4518] 7% | Training loss: 0.6889596765860915
Epoch: 63 | Iteration number: [330/4518] 7% | Training loss: 0.6888614347486784
Epoch: 63 | Iteration number: [340/4518] 7% | Training loss: 0.688779422290185
Epoch: 63 | Iteration number: [350/4518] 7% | Training loss: 0.6887449276447296
Epoch: 63 | Iteration number: [360/4518] 7% | Training loss: 0.6887034368183877
Epoch: 63 | Iteration number: [370/4518] 8% | Training loss: 0.688595043485229
Epoch: 63 | Iteration number: [380/4518] 8% | Training loss: 0.6885716490055386
Epoch: 63 | Iteration number: [390/4518] 8% | Training loss: 0.6885317429518089
Epoch: 63 | Iteration number: [400/4518] 8% | Training loss: 0.6884910148382187
Epoch: 63 | Iteration number: [410/4518] 9% | Training loss: 0.688465239507396
Epoch: 63 | Iteration number: [420/4518] 9% | Training loss: 0.6884334354173569
Epoch: 63 | Iteration number: [430/4518] 9% | Training loss: 0.6884219600710758
Epoch: 63 | Iteration number: [440/4518] 9% | Training loss: 0.6883742791685191
Epoch: 63 | Iteration number: [450/4518] 9% | Training loss: 0.6883369596799215
Epoch: 63 | Iteration number: [460/4518] 10% | Training loss: 0.6883063223050988
Epoch: 63 | Iteration number: [470/4518] 10% | Training loss: 0.6883006849187485
Epoch: 63 | Iteration number: [480/4518] 10% | Training loss: 0.6882763260354599
Epoch: 63 | Iteration number: [490/4518] 10% | Training loss: 0.6882553914371802
Epoch: 63 | Iteration number: [500/4518] 11% | Training loss: 0.6882236912250519
Epoch: 63 | Iteration number: [510/4518] 11% | Training loss: 0.688202052490384
Epoch: 63 | Iteration number: [520/4518] 11% | Training loss: 0.6881676770173586
Epoch: 63 | Iteration number: [530/4518] 11% | Training loss: 0.6881451954256813
Epoch: 63 | Iteration number: [540/4518] 11% | Training loss: 0.6881292124589284
Epoch: 63 | Iteration number: [550/4518] 12% | Training loss: 0.6881303519552404
Epoch: 63 | Iteration number: [560/4518] 12% | Training loss: 0.688129174815757
Epoch: 63 | Iteration number: [570/4518] 12% | Training loss: 0.6880873267065015
Epoch: 63 | Iteration number: [580/4518] 12% | Training loss: 0.6880664582910209
Epoch: 63 | Iteration number: [590/4518] 13% | Training loss: 0.6880493551997815
Epoch: 63 | Iteration number: [600/4518] 13% | Training loss: 0.6880115871628125
Epoch: 63 | Iteration number: [610/4518] 13% | Training loss: 0.6879725168962948
Epoch: 63 | Iteration number: [620/4518] 13% | Training loss: 0.6879267509906523
Epoch: 63 | Iteration number: [630/4518] 13% | Training loss: 0.6878898727515387
Epoch: 63 | Iteration number: [640/4518] 14% | Training loss: 0.6878678129985929
Epoch: 63 | Iteration number: [650/4518] 14% | Training loss: 0.6878409691957327
Epoch: 63 | Iteration number: [660/4518] 14% | Training loss: 0.687811061017441
Epoch: 63 | Iteration number: [670/4518] 14% | Training loss: 0.6877959367054612
Epoch: 63 | Iteration number: [680/4518] 15% | Training loss: 0.6877913720467511
Epoch: 63 | Iteration number: [690/4518] 15% | Training loss: 0.6877850317436716
Epoch: 63 | Iteration number: [700/4518] 15% | Training loss: 0.6877621329682214
Epoch: 63 | Iteration number: [710/4518] 15% | Training loss: 0.6877386923407165
Epoch: 63 | Iteration number: [720/4518] 15% | Training loss: 0.6877344879839156
Epoch: 63 | Iteration number: [730/4518] 16% | Training loss: 0.6877331149088193
Epoch: 63 | Iteration number: [740/4518] 16% | Training loss: 0.6876923818846007
Epoch: 63 | Iteration number: [750/4518] 16% | Training loss: 0.6876783147652944
Epoch: 63 | Iteration number: [760/4518] 16% | Training loss: 0.6876643500045726
Epoch: 63 | Iteration number: [770/4518] 17% | Training loss: 0.6876665842997564
Epoch: 63 | Iteration number: [780/4518] 17% | Training loss: 0.6876617366686846
Epoch: 63 | Iteration number: [790/4518] 17% | Training loss: 0.6876637710046165
Epoch: 63 | Iteration number: [800/4518] 17% | Training loss: 0.6876662430167199
Epoch: 63 | Iteration number: [810/4518] 17% | Training loss: 0.6876604495225129
Epoch: 63 | Iteration number: [820/4518] 18% | Training loss: 0.6876458644140058
Epoch: 63 | Iteration number: [830/4518] 18% | Training loss: 0.6876227133245353
Epoch: 63 | Iteration number: [840/4518] 18% | Training loss: 0.6876142235029311
Epoch: 63 | Iteration number: [850/4518] 18% | Training loss: 0.6876151682348812
Epoch: 63 | Iteration number: [860/4518] 19% | Training loss: 0.6876091936299967
Epoch: 63 | Iteration number: [870/4518] 19% | Training loss: 0.6875929750930304
Epoch: 63 | Iteration number: [880/4518] 19% | Training loss: 0.687567443603819
Epoch: 63 | Iteration number: [890/4518] 19% | Training loss: 0.6875416591596067
Epoch: 63 | Iteration number: [900/4518] 19% | Training loss: 0.6875371517075433
Epoch: 63 | Iteration number: [910/4518] 20% | Training loss: 0.6875291145764865
Epoch: 63 | Iteration number: [920/4518] 20% | Training loss: 0.6875255378044169
Epoch: 63 | Iteration number: [930/4518] 20% | Training loss: 0.687518221909
Epoch: 63 | Iteration number: [940/4518] 20% | Training loss: 0.6875119064716583
Epoch: 63 | Iteration number: [950/4518] 21% | Training loss: 0.6874944045041737
Epoch: 63 | Iteration number: [960/4518] 21% | Training loss: 0.6874960317586859
Epoch: 63 | Iteration number: [970/4518] 21% | Training loss: 0.687465732122205
Epoch: 63 | Iteration number: [980/4518] 21% | Training loss: 0.6874613168896461
Epoch: 63 | Iteration number: [990/4518] 21% | Training loss: 0.6874516104206895
Epoch: 63 | Iteration number: [1000/4518] 22% | Training loss: 0.6874662494659424
Epoch: 63 | Iteration number: [1010/4518] 22% | Training loss: 0.6874573215399639
Epoch: 63 | Iteration number: [1020/4518] 22% | Training loss: 0.6874423587439107
Epoch: 63 | Iteration number: [1030/4518] 22% | Training loss: 0.6874403366764772
Epoch: 63 | Iteration number: [1040/4518] 23% | Training loss: 0.6874245052727369
Epoch: 63 | Iteration number: [1050/4518] 23% | Training loss: 0.687420586858477
Epoch: 63 | Iteration number: [1060/4518] 23% | Training loss: 0.6874002866025241
Epoch: 63 | Iteration number: [1070/4518] 23% | Training loss: 0.6873923370771319
Epoch: 63 | Iteration number: [1080/4518] 23% | Training loss: 0.6873805280636858
Epoch: 63 | Iteration number: [1090/4518] 24% | Training loss: 0.6873749802418805
Epoch: 63 | Iteration number: [1100/4518] 24% | Training loss: 0.6873623509298671
Epoch: 63 | Iteration number: [1110/4518] 24% | Training loss: 0.6873622083986127
Epoch: 63 | Iteration number: [1120/4518] 24% | Training loss: 0.6873572881200484
Epoch: 63 | Iteration number: [1130/4518] 25% | Training loss: 0.6873532683975929
Epoch: 63 | Iteration number: [1140/4518] 25% | Training loss: 0.6873537891266639
Epoch: 63 | Iteration number: [1150/4518] 25% | Training loss: 0.6873434611507084
Epoch: 63 | Iteration number: [1160/4518] 25% | Training loss: 0.6873334013182542
Epoch: 63 | Iteration number: [1170/4518] 25% | Training loss: 0.6873346991518624
Epoch: 63 | Iteration number: [1180/4518] 26% | Training loss: 0.6873384669170541
Epoch: 63 | Iteration number: [1190/4518] 26% | Training loss: 0.687333428659359
Epoch: 63 | Iteration number: [1200/4518] 26% | Training loss: 0.6873229019343853
Epoch: 63 | Iteration number: [1210/4518] 26% | Training loss: 0.6873205480004145
Epoch: 63 | Iteration number: [1220/4518] 27% | Training loss: 0.6873266673478924
Epoch: 63 | Iteration number: [1230/4518] 27% | Training loss: 0.6873284081133401
Epoch: 63 | Iteration number: [1240/4518] 27% | Training loss: 0.6873214149186688
Epoch: 63 | Iteration number: [1250/4518] 27% | Training loss: 0.687314068365097
Epoch: 63 | Iteration number: [1260/4518] 27% | Training loss: 0.6873206402574267
Epoch: 63 | Iteration number: [1270/4518] 28% | Training loss: 0.687309288462316
Epoch: 63 | Iteration number: [1280/4518] 28% | Training loss: 0.6873172445222735
Epoch: 63 | Iteration number: [1290/4518] 28% | Training loss: 0.6873170862364214
Epoch: 63 | Iteration number: [1300/4518] 28% | Training loss: 0.6873102353627865
Epoch: 63 | Iteration number: [1310/4518] 28% | Training loss: 0.6873028698313327
Epoch: 63 | Iteration number: [1320/4518] 29% | Training loss: 0.6873014163790327
Epoch: 63 | Iteration number: [1330/4518] 29% | Training loss: 0.6873009230857505
Epoch: 63 | Iteration number: [1340/4518] 29% | Training loss: 0.6872923613929037
Epoch: 63 | Iteration number: [1350/4518] 29% | Training loss: 0.687283278880296
Epoch: 63 | Iteration number: [1360/4518] 30% | Training loss: 0.687280717097661
Epoch: 63 | Iteration number: [1370/4518] 30% | Training loss: 0.6872773025592748
Epoch: 63 | Iteration number: [1380/4518] 30% | Training loss: 0.6872728177170823
Epoch: 63 | Iteration number: [1390/4518] 30% | Training loss: 0.6872638487558571
Epoch: 63 | Iteration number: [1400/4518] 30% | Training loss: 0.6872635995915958
Epoch: 63 | Iteration number: [1410/4518] 31% | Training loss: 0.6872674292706429
Epoch: 63 | Iteration number: [1420/4518] 31% | Training loss: 0.6872681620255322
Epoch: 63 | Iteration number: [1430/4518] 31% | Training loss: 0.6872676250817893
Epoch: 63 | Iteration number: [1440/4518] 31% | Training loss: 0.6872690162310998
Epoch: 63 | Iteration number: [1450/4518] 32% | Training loss: 0.6872555681343736
Epoch: 63 | Iteration number: [1460/4518] 32% | Training loss: 0.6872521836055469
Epoch: 63 | Iteration number: [1470/4518] 32% | Training loss: 0.6872469469398057
Epoch: 63 | Iteration number: [1480/4518] 32% | Training loss: 0.6872452737109082
Epoch: 63 | Iteration number: [1490/4518] 32% | Training loss: 0.6872456819419093
Epoch: 63 | Iteration number: [1500/4518] 33% | Training loss: 0.6872351939280827
Epoch: 63 | Iteration number: [1510/4518] 33% | Training loss: 0.6872335261856484
Epoch: 63 | Iteration number: [1520/4518] 33% | Training loss: 0.687227319024111
Epoch: 63 | Iteration number: [1530/4518] 33% | Training loss: 0.6872126551235423
Epoch: 63 | Iteration number: [1540/4518] 34% | Training loss: 0.6872090013770314
Epoch: 63 | Iteration number: [1550/4518] 34% | Training loss: 0.6872073631517349
Epoch: 63 | Iteration number: [1560/4518] 34% | Training loss: 0.6871976394683886
Epoch: 63 | Iteration number: [1570/4518] 34% | Training loss: 0.6871994859094073
Epoch: 63 | Iteration number: [1580/4518] 34% | Training loss: 0.6871941891274874
Epoch: 63 | Iteration number: [1590/4518] 35% | Training loss: 0.6871937492733482
Epoch: 63 | Iteration number: [1600/4518] 35% | Training loss: 0.6871971102058887
Epoch: 63 | Iteration number: [1610/4518] 35% | Training loss: 0.6871952597769151
Epoch: 63 | Iteration number: [1620/4518] 35% | Training loss: 0.6871878788795001
Epoch: 63 | Iteration number: [1630/4518] 36% | Training loss: 0.687173704355041
Epoch: 63 | Iteration number: [1640/4518] 36% | Training loss: 0.6871716633075621
Epoch: 63 | Iteration number: [1650/4518] 36% | Training loss: 0.6871701887159637
Epoch: 63 | Iteration number: [1660/4518] 36% | Training loss: 0.6871700291174004
Epoch: 63 | Iteration number: [1670/4518] 36% | Training loss: 0.6871620112193558
Epoch: 63 | Iteration number: [1680/4518] 37% | Training loss: 0.6871621642084349
Epoch: 63 | Iteration number: [1690/4518] 37% | Training loss: 0.6871580228650358
Epoch: 63 | Iteration number: [1700/4518] 37% | Training loss: 0.687163217979319
Epoch: 63 | Iteration number: [1710/4518] 37% | Training loss: 0.6871640223857255
Epoch: 63 | Iteration number: [1720/4518] 38% | Training loss: 0.6871643905376279
Epoch: 63 | Iteration number: [1730/4518] 38% | Training loss: 0.6871560796492362
Epoch: 63 | Iteration number: [1740/4518] 38% | Training loss: 0.6871576277003891
Epoch: 63 | Iteration number: [1750/4518] 38% | Training loss: 0.6871572100094386
Epoch: 63 | Iteration number: [1760/4518] 38% | Training loss: 0.6871628343043003
Epoch: 63 | Iteration number: [1770/4518] 39% | Training loss: 0.6871661891371517
Epoch: 63 | Iteration number: [1780/4518] 39% | Training loss: 0.6871605844979876
Epoch: 63 | Iteration number: [1790/4518] 39% | Training loss: 0.6871610646807281
Epoch: 63 | Iteration number: [1800/4518] 39% | Training loss: 0.6871587474809753
Epoch: 63 | Iteration number: [1810/4518] 40% | Training loss: 0.6871591217280751
Epoch: 63 | Iteration number: [1820/4518] 40% | Training loss: 0.6871601812787108
Epoch: 63 | Iteration number: [1830/4518] 40% | Training loss: 0.687161716411674
Epoch: 63 | Iteration number: [1840/4518] 40% | Training loss: 0.6871531706141389
Epoch: 63 | Iteration number: [1850/4518] 40% | Training loss: 0.6871497323061969
Epoch: 63 | Iteration number: [1860/4518] 41% | Training loss: 0.6871506944779426
Epoch: 63 | Iteration number: [1870/4518] 41% | Training loss: 0.6871530184133805
Epoch: 63 | Iteration number: [1880/4518] 41% | Training loss: 0.6871460117241169
Epoch: 63 | Iteration number: [1890/4518] 41% | Training loss: 0.6871434602787886
Epoch: 63 | Iteration number: [1900/4518] 42% | Training loss: 0.6871386389983328
Epoch: 63 | Iteration number: [1910/4518] 42% | Training loss: 0.6871395105466793
Epoch: 63 | Iteration number: [1920/4518] 42% | Training loss: 0.6871326750144362
Epoch: 63 | Iteration number: [1930/4518] 42% | Training loss: 0.687124569768115
Epoch: 63 | Iteration number: [1940/4518] 42% | Training loss: 0.6871211739545016
Epoch: 63 | Iteration number: [1950/4518] 43% | Training loss: 0.6871219461392134
Epoch: 63 | Iteration number: [1960/4518] 43% | Training loss: 0.6871198128376689
Epoch: 63 | Iteration number: [1970/4518] 43% | Training loss: 0.6871207994858021
Epoch: 63 | Iteration number: [1980/4518] 43% | Training loss: 0.6871189791144747
Epoch: 63 | Iteration number: [1990/4518] 44% | Training loss: 0.687117838080804
Epoch: 63 | Iteration number: [2000/4518] 44% | Training loss: 0.6871209765672683
Epoch: 63 | Iteration number: [2010/4518] 44% | Training loss: 0.6871184177956178
Epoch: 63 | Iteration number: [2020/4518] 44% | Training loss: 0.6871139580660527
Epoch: 63 | Iteration number: [2030/4518] 44% | Training loss: 0.6871049857198311
Epoch: 63 | Iteration number: [2040/4518] 45% | Training loss: 0.6870984117190043
Epoch: 63 | Iteration number: [2050/4518] 45% | Training loss: 0.6870896252771703
Epoch: 63 | Iteration number: [2060/4518] 45% | Training loss: 0.6870842845694533
Epoch: 63 | Iteration number: [2070/4518] 45% | Training loss: 0.68708398612801
Epoch: 63 | Iteration number: [2080/4518] 46% | Training loss: 0.6870889479151139
Epoch: 63 | Iteration number: [2090/4518] 46% | Training loss: 0.6870901288027969
Epoch: 63 | Iteration number: [2100/4518] 46% | Training loss: 0.6870872558582397
Epoch: 63 | Iteration number: [2110/4518] 46% | Training loss: 0.687090727729255
Epoch: 63 | Iteration number: [2120/4518] 46% | Training loss: 0.687087891658522
Epoch: 63 | Iteration number: [2130/4518] 47% | Training loss: 0.6870922085265039
Epoch: 63 | Iteration number: [2140/4518] 47% | Training loss: 0.6870899614886703
Epoch: 63 | Iteration number: [2150/4518] 47% | Training loss: 0.6870919432196506
Epoch: 63 | Iteration number: [2160/4518] 47% | Training loss: 0.6870935403638416
Epoch: 63 | Iteration number: [2170/4518] 48% | Training loss: 0.6870922670386354
Epoch: 63 | Iteration number: [2180/4518] 48% | Training loss: 0.6870951576517262
Epoch: 63 | Iteration number: [2190/4518] 48% | Training loss: 0.6870932402676099
Epoch: 63 | Iteration number: [2200/4518] 48% | Training loss: 0.6870912366834554
Epoch: 63 | Iteration number: [2210/4518] 48% | Training loss: 0.6870893822536209
Epoch: 63 | Iteration number: [2220/4518] 49% | Training loss: 0.6870797563780535
Epoch: 63 | Iteration number: [2230/4518] 49% | Training loss: 0.6870843230074296
Epoch: 63 | Iteration number: [2240/4518] 49% | Training loss: 0.6870828573192869
Epoch: 63 | Iteration number: [2250/4518] 49% | Training loss: 0.6870841339694129
Epoch: 63 | Iteration number: [2260/4518] 50% | Training loss: 0.6870831123759261
Epoch: 63 | Iteration number: [2270/4518] 50% | Training loss: 0.6870784735627111
Epoch: 63 | Iteration number: [2280/4518] 50% | Training loss: 0.6870779852072398
Epoch: 63 | Iteration number: [2290/4518] 50% | Training loss: 0.6870726752229133
Epoch: 63 | Iteration number: [2300/4518] 50% | Training loss: 0.6870771926900615
Epoch: 63 | Iteration number: [2310/4518] 51% | Training loss: 0.6870753656992149
Epoch: 63 | Iteration number: [2320/4518] 51% | Training loss: 0.6870772474027913
Epoch: 63 | Iteration number: [2330/4518] 51% | Training loss: 0.687076966675566
Epoch: 63 | Iteration number: [2340/4518] 51% | Training loss: 0.6870786520150992
Epoch: 63 | Iteration number: [2350/4518] 52% | Training loss: 0.6870813705566081
Epoch: 63 | Iteration number: [2360/4518] 52% | Training loss: 0.6870787562960285
Epoch: 63 | Iteration number: [2370/4518] 52% | Training loss: 0.6870737613756446
Epoch: 63 | Iteration number: [2380/4518] 52% | Training loss: 0.6870761968508488
Epoch: 63 | Iteration number: [2390/4518] 52% | Training loss: 0.6870770185811749
Epoch: 63 | Iteration number: [2400/4518] 53% | Training loss: 0.687073215469718
Epoch: 63 | Iteration number: [2410/4518] 53% | Training loss: 0.687073501388067
Epoch: 63 | Iteration number: [2420/4518] 53% | Training loss: 0.6870642440378173
Epoch: 63 | Iteration number: [2430/4518] 53% | Training loss: 0.6870691398043691
Epoch: 63 | Iteration number: [2440/4518] 54% | Training loss: 0.6870685853430483
Epoch: 63 | Iteration number: [2450/4518] 54% | Training loss: 0.6870648668250259
Epoch: 63 | Iteration number: [2460/4518] 54% | Training loss: 0.687065946474308
Epoch: 63 | Iteration number: [2470/4518] 54% | Training loss: 0.6870638504684695
Epoch: 63 | Iteration number: [2480/4518] 54% | Training loss: 0.6870637244514881
Epoch: 63 | Iteration number: [2490/4518] 55% | Training loss: 0.6870575182409172
Epoch: 63 | Iteration number: [2500/4518] 55% | Training loss: 0.6870526379108429
Epoch: 63 | Iteration number: [2510/4518] 55% | Training loss: 0.6870526864234194
Epoch: 63 | Iteration number: [2520/4518] 55% | Training loss: 0.6870547527831699
Epoch: 63 | Iteration number: [2530/4518] 55% | Training loss: 0.6870555422051622
Epoch: 63 | Iteration number: [2540/4518] 56% | Training loss: 0.6870576567537202
Epoch: 63 | Iteration number: [2550/4518] 56% | Training loss: 0.6870532970101225
Epoch: 63 | Iteration number: [2560/4518] 56% | Training loss: 0.6870516983559355
Epoch: 63 | Iteration number: [2570/4518] 56% | Training loss: 0.6870530517184781
Epoch: 63 | Iteration number: [2580/4518] 57% | Training loss: 0.6870517370543738
Epoch: 63 | Iteration number: [2590/4518] 57% | Training loss: 0.6870483713720756
Epoch: 63 | Iteration number: [2600/4518] 57% | Training loss: 0.6870434139783566
Epoch: 63 | Iteration number: [2610/4518] 57% | Training loss: 0.6870410760243734
Epoch: 63 | Iteration number: [2620/4518] 57% | Training loss: 0.6870409748936428
Epoch: 63 | Iteration number: [2630/4518] 58% | Training loss: 0.6870436624655706
Epoch: 63 | Iteration number: [2640/4518] 58% | Training loss: 0.6870455545909477
Epoch: 63 | Iteration number: [2650/4518] 58% | Training loss: 0.6870484795210496
Epoch: 63 | Iteration number: [2660/4518] 58% | Training loss: 0.6870481038676168
Epoch: 63 | Iteration number: [2670/4518] 59% | Training loss: 0.6870479198877285
Epoch: 63 | Iteration number: [2680/4518] 59% | Training loss: 0.6870447828031297
Epoch: 63 | Iteration number: [2690/4518] 59% | Training loss: 0.6870428029932497
Epoch: 63 | Iteration number: [2700/4518] 59% | Training loss: 0.6870381698122731
Epoch: 63 | Iteration number: [2710/4518] 59% | Training loss: 0.6870398974506617
Epoch: 63 | Iteration number: [2720/4518] 60% | Training loss: 0.6870357723577935
Epoch: 63 | Iteration number: [2730/4518] 60% | Training loss: 0.6870342150712625
Epoch: 63 | Iteration number: [2740/4518] 60% | Training loss: 0.6870311624377313
Epoch: 63 | Iteration number: [2750/4518] 60% | Training loss: 0.6870293186577884
Epoch: 63 | Iteration number: [2760/4518] 61% | Training loss: 0.6870303387875142
Epoch: 63 | Iteration number: [2770/4518] 61% | Training loss: 0.6870318804837307
Epoch: 63 | Iteration number: [2780/4518] 61% | Training loss: 0.6870298485318533
Epoch: 63 | Iteration number: [2790/4518] 61% | Training loss: 0.6870296646830856
Epoch: 63 | Iteration number: [2800/4518] 61% | Training loss: 0.6870328401667731
Epoch: 63 | Iteration number: [2810/4518] 62% | Training loss: 0.6870349104718382
Epoch: 63 | Iteration number: [2820/4518] 62% | Training loss: 0.6870387588198303
Epoch: 63 | Iteration number: [2830/4518] 62% | Training loss: 0.6870367045326705
Epoch: 63 | Iteration number: [2840/4518] 62% | Training loss: 0.6870379513628047
Epoch: 63 | Iteration number: [2850/4518] 63% | Training loss: 0.6870326805951302
Epoch: 63 | Iteration number: [2860/4518] 63% | Training loss: 0.6870341261992088
Epoch: 63 | Iteration number: [2870/4518] 63% | Training loss: 0.6870370769126906
Epoch: 63 | Iteration number: [2880/4518] 63% | Training loss: 0.6870348441518015
Epoch: 63 | Iteration number: [2890/4518] 63% | Training loss: 0.687030389028437
Epoch: 63 | Iteration number: [2900/4518] 64% | Training loss: 0.6870316241732959
Epoch: 63 | Iteration number: [2910/4518] 64% | Training loss: 0.6870302396746436
Epoch: 63 | Iteration number: [2920/4518] 64% | Training loss: 0.6870275638487241
Epoch: 63 | Iteration number: [2930/4518] 64% | Training loss: 0.687025040957708
Epoch: 63 | Iteration number: [2940/4518] 65% | Training loss: 0.6870251595568495
Epoch: 63 | Iteration number: [2950/4518] 65% | Training loss: 0.6870281024302466
Epoch: 63 | Iteration number: [2960/4518] 65% | Training loss: 0.6870309637406388
Epoch: 63 | Iteration number: [2970/4518] 65% | Training loss: 0.6870278076290683
Epoch: 63 | Iteration number: [2980/4518] 65% | Training loss: 0.6870290668218728
Epoch: 63 | Iteration number: [2990/4518] 66% | Training loss: 0.687029653249377
Epoch: 63 | Iteration number: [3000/4518] 66% | Training loss: 0.6870281892418861
Epoch: 63 | Iteration number: [3010/4518] 66% | Training loss: 0.687029576420388
Epoch: 63 | Iteration number: [3020/4518] 66% | Training loss: 0.68703153135366
Epoch: 63 | Iteration number: [3030/4518] 67% | Training loss: 0.6870310635653266
Epoch: 63 | Iteration number: [3040/4518] 67% | Training loss: 0.687028116615195
Epoch: 63 | Iteration number: [3050/4518] 67% | Training loss: 0.6870274143336249
Epoch: 63 | Iteration number: [3060/4518] 67% | Training loss: 0.6870254885916617
Epoch: 63 | Iteration number: [3070/4518] 67% | Training loss: 0.6870237618393541
Epoch: 63 | Iteration number: [3080/4518] 68% | Training loss: 0.6870239205948718
Epoch: 63 | Iteration number: [3090/4518] 68% | Training loss: 0.6870205295703172
Epoch: 63 | Iteration number: [3100/4518] 68% | Training loss: 0.687019353239767
Epoch: 63 | Iteration number: [3110/4518] 68% | Training loss: 0.687019960615796
Epoch: 63 | Iteration number: [3120/4518] 69% | Training loss: 0.6870170503663711
Epoch: 63 | Iteration number: [3130/4518] 69% | Training loss: 0.6870213390348818
Epoch: 63 | Iteration number: [3140/4518] 69% | Training loss: 0.6870168482042422
Epoch: 63 | Iteration number: [3150/4518] 69% | Training loss: 0.6870110296824622
Epoch: 63 | Iteration number: [3160/4518] 69% | Training loss: 0.6870075584966925
Epoch: 63 | Iteration number: [3170/4518] 70% | Training loss: 0.6870032315562576
Epoch: 63 | Iteration number: [3180/4518] 70% | Training loss: 0.6870066405279831
Epoch: 63 | Iteration number: [3190/4518] 70% | Training loss: 0.6870078312379065
Epoch: 63 | Iteration number: [3200/4518] 70% | Training loss: 0.6870066186785698
Epoch: 63 | Iteration number: [3210/4518] 71% | Training loss: 0.6870033725399838
Epoch: 63 | Iteration number: [3220/4518] 71% | Training loss: 0.6870062205917347
Epoch: 63 | Iteration number: [3230/4518] 71% | Training loss: 0.6870045330133231
Epoch: 63 | Iteration number: [3240/4518] 71% | Training loss: 0.687002520336781
Epoch: 63 | Iteration number: [3250/4518] 71% | Training loss: 0.6869953296551338
Epoch: 63 | Iteration number: [3260/4518] 72% | Training loss: 0.6869950968246519
Epoch: 63 | Iteration number: [3270/4518] 72% | Training loss: 0.6869939832512392
Epoch: 63 | Iteration number: [3280/4518] 72% | Training loss: 0.6869885587474195
Epoch: 63 | Iteration number: [3290/4518] 72% | Training loss: 0.6869898696619688
Epoch: 63 | Iteration number: [3300/4518] 73% | Training loss: 0.6869886799292131
Epoch: 63 | Iteration number: [3310/4518] 73% | Training loss: 0.6869874565442884
Epoch: 63 | Iteration number: [3320/4518] 73% | Training loss: 0.6869860557727067
Epoch: 63 | Iteration number: [3330/4518] 73% | Training loss: 0.6869863354407989
Epoch: 63 | Iteration number: [3340/4518] 73% | Training loss: 0.68698490031822
Epoch: 63 | Iteration number: [3350/4518] 74% | Training loss: 0.6869837144417549
Epoch: 63 | Iteration number: [3360/4518] 74% | Training loss: 0.6869813862123659
Epoch: 63 | Iteration number: [3370/4518] 74% | Training loss: 0.6869830544518434
Epoch: 63 | Iteration number: [3380/4518] 74% | Training loss: 0.686987964606144
Epoch: 63 | Iteration number: [3390/4518] 75% | Training loss: 0.6869880059651569
Epoch: 63 | Iteration number: [3400/4518] 75% | Training loss: 0.6869878746481503
Epoch: 63 | Iteration number: [3410/4518] 75% | Training loss: 0.6869869225535574
Epoch: 63 | Iteration number: [3420/4518] 75% | Training loss: 0.6869876926579671
Epoch: 63 | Iteration number: [3430/4518] 75% | Training loss: 0.686982922929369
Epoch: 63 | Iteration number: [3440/4518] 76% | Training loss: 0.6869839139629242
Epoch: 63 | Iteration number: [3450/4518] 76% | Training loss: 0.6869834456754768
Epoch: 63 | Iteration number: [3460/4518] 76% | Training loss: 0.6869846926775971
Epoch: 63 | Iteration number: [3470/4518] 76% | Training loss: 0.6869869326480184
Epoch: 63 | Iteration number: [3480/4518] 77% | Training loss: 0.6869883453880233
Epoch: 63 | Iteration number: [3490/4518] 77% | Training loss: 0.6869865020230028
Epoch: 63 | Iteration number: [3500/4518] 77% | Training loss: 0.6869914219890322
Epoch: 63 | Iteration number: [3510/4518] 77% | Training loss: 0.6869908436920568
Epoch: 63 | Iteration number: [3520/4518] 77% | Training loss: 0.6869891776449301
Epoch: 63 | Iteration number: [3530/4518] 78% | Training loss: 0.6869902743327381
Epoch: 63 | Iteration number: [3540/4518] 78% | Training loss: 0.6869878217662122
Epoch: 63 | Iteration number: [3550/4518] 78% | Training loss: 0.6869905576403712
Epoch: 63 | Iteration number: [3560/4518] 78% | Training loss: 0.6869941624362818
Epoch: 63 | Iteration number: [3570/4518] 79% | Training loss: 0.6869925519832376
Epoch: 63 | Iteration number: [3580/4518] 79% | Training loss: 0.6869952248627913
Epoch: 63 | Iteration number: [3590/4518] 79% | Training loss: 0.6869915925028597
Epoch: 63 | Iteration number: [3600/4518] 79% | Training loss: 0.6869882700840632
Epoch: 63 | Iteration number: [3610/4518] 79% | Training loss: 0.6869843564205222
Epoch: 63 | Iteration number: [3620/4518] 80% | Training loss: 0.6869857330513264
Epoch: 63 | Iteration number: [3630/4518] 80% | Training loss: 0.6869873248841152
Epoch: 63 | Iteration number: [3640/4518] 80% | Training loss: 0.6869854136155202
Epoch: 63 | Iteration number: [3650/4518] 80% | Training loss: 0.6869853108223171
Epoch: 63 | Iteration number: [3660/4518] 81% | Training loss: 0.6869835897710154
Epoch: 63 | Iteration number: [3670/4518] 81% | Training loss: 0.6869831130355191
Epoch: 63 | Iteration number: [3680/4518] 81% | Training loss: 0.6869836259309364
Epoch: 63 | Iteration number: [3690/4518] 81% | Training loss: 0.6869809905364908
Epoch: 63 | Iteration number: [3700/4518] 81% | Training loss: 0.6869821872260119
Epoch: 63 | Iteration number: [3710/4518] 82% | Training loss: 0.6869833111281022
Epoch: 63 | Iteration number: [3720/4518] 82% | Training loss: 0.6869848941282559
Epoch: 63 | Iteration number: [3730/4518] 82% | Training loss: 0.6869847416078757
Epoch: 63 | Iteration number: [3740/4518] 82% | Training loss: 0.6869852271468881
Epoch: 63 | Iteration number: [3750/4518] 83% | Training loss: 0.6869820426146189
Epoch: 63 | Iteration number: [3760/4518] 83% | Training loss: 0.6869834895939269
Epoch: 63 | Iteration number: [3770/4518] 83% | Training loss: 0.6869842105424057
Epoch: 63 | Iteration number: [3780/4518] 83% | Training loss: 0.6869829129132013
Epoch: 63 | Iteration number: [3790/4518] 83% | Training loss: 0.6869806222519333
Epoch: 63 | Iteration number: [3800/4518] 84% | Training loss: 0.6869805597474701
Epoch: 63 | Iteration number: [3810/4518] 84% | Training loss: 0.6869799767109979
Epoch: 63 | Iteration number: [3820/4518] 84% | Training loss: 0.6869793707787678
Epoch: 63 | Iteration number: [3830/4518] 84% | Training loss: 0.6869798368791376
Epoch: 63 | Iteration number: [3840/4518] 84% | Training loss: 0.6869782957558831
Epoch: 63 | Iteration number: [3850/4518] 85% | Training loss: 0.6869746935677219
Epoch: 63 | Iteration number: [3860/4518] 85% | Training loss: 0.6869734059034851
Epoch: 63 | Iteration number: [3870/4518] 85% | Training loss: 0.6869725591760582
Epoch: 63 | Iteration number: [3880/4518] 85% | Training loss: 0.6869736319811074
Epoch: 63 | Iteration number: [3890/4518] 86% | Training loss: 0.6869753643142533
Epoch: 63 | Iteration number: [3900/4518] 86% | Training loss: 0.6869771160376378
Epoch: 63 | Iteration number: [3910/4518] 86% | Training loss: 0.6869755133338596
Epoch: 63 | Iteration number: [3920/4518] 86% | Training loss: 0.6869728975302103
Epoch: 63 | Iteration number: [3930/4518] 86% | Training loss: 0.6869710759352182
Epoch: 63 | Iteration number: [3940/4518] 87% | Training loss: 0.6869716938377032
Epoch: 63 | Iteration number: [3950/4518] 87% | Training loss: 0.6869691705251042
Epoch: 63 | Iteration number: [3960/4518] 87% | Training loss: 0.6869705465857429
Epoch: 63 | Iteration number: [3970/4518] 87% | Training loss: 0.6869687056061002
Epoch: 63 | Iteration number: [3980/4518] 88% | Training loss: 0.6869691550432138
Epoch: 63 | Iteration number: [3990/4518] 88% | Training loss: 0.6869705958772722
Epoch: 63 | Iteration number: [4000/4518] 88% | Training loss: 0.6869746139645576
Epoch: 63 | Iteration number: [4010/4518] 88% | Training loss: 0.6869723039523622
Epoch: 63 | Iteration number: [4020/4518] 88% | Training loss: 0.6869738299900027
Epoch: 63 | Iteration number: [4030/4518] 89% | Training loss: 0.68697192050683
Epoch: 63 | Iteration number: [4040/4518] 89% | Training loss: 0.6869681969580084
Epoch: 63 | Iteration number: [4050/4518] 89% | Training loss: 0.6869713404149185
Epoch: 63 | Iteration number: [4060/4518] 89% | Training loss: 0.6869736290036751
Epoch: 63 | Iteration number: [4070/4518] 90% | Training loss: 0.6869745194765507
Epoch: 63 | Iteration number: [4080/4518] 90% | Training loss: 0.6869741315350814
Epoch: 63 | Iteration number: [4090/4518] 90% | Training loss: 0.686968277573294
Epoch: 63 | Iteration number: [4100/4518] 90% | Training loss: 0.6869653526311967
Epoch: 63 | Iteration number: [4110/4518] 90% | Training loss: 0.6869658062347821
Epoch: 63 | Iteration number: [4120/4518] 91% | Training loss: 0.6869615230311468
Epoch: 63 | Iteration number: [4130/4518] 91% | Training loss: 0.6869580876596326
Epoch: 63 | Iteration number: [4140/4518] 91% | Training loss: 0.6869577519703602
Epoch: 63 | Iteration number: [4150/4518] 91% | Training loss: 0.6869622748013002
Epoch: 63 | Iteration number: [4160/4518] 92% | Training loss: 0.6869610650751453
Epoch: 63 | Iteration number: [4170/4518] 92% | Training loss: 0.6869593394746025
Epoch: 63 | Iteration number: [4180/4518] 92% | Training loss: 0.686959230785735
Epoch: 63 | Iteration number: [4190/4518] 92% | Training loss: 0.6869601538471504
Epoch: 63 | Iteration number: [4200/4518] 92% | Training loss: 0.6869609563833191
Epoch: 63 | Iteration number: [4210/4518] 93% | Training loss: 0.6869647111292406
Epoch: 63 | Iteration number: [4220/4518] 93% | Training loss: 0.686962011301122
Epoch: 63 | Iteration number: [4230/4518] 93% | Training loss: 0.6869620924018517
Epoch: 63 | Iteration number: [4240/4518] 93% | Training loss: 0.6869615984412859
Epoch: 63 | Iteration number: [4250/4518] 94% | Training loss: 0.6869575336820939
Epoch: 63 | Iteration number: [4260/4518] 94% | Training loss: 0.686956020518088
Epoch: 63 | Iteration number: [4270/4518] 94% | Training loss: 0.6869570175992801
Epoch: 63 | Iteration number: [4280/4518] 94% | Training loss: 0.6869573705942831
Epoch: 63 | Iteration number: [4290/4518] 94% | Training loss: 0.6869568098258305
Epoch: 63 | Iteration number: [4300/4518] 95% | Training loss: 0.6869549775539443
Epoch: 63 | Iteration number: [4310/4518] 95% | Training loss: 0.6869501707033878
Epoch: 63 | Iteration number: [4320/4518] 95% | Training loss: 0.6869490962613511
Epoch: 63 | Iteration number: [4330/4518] 95% | Training loss: 0.6869456384666522
Epoch: 63 | Iteration number: [4340/4518] 96% | Training loss: 0.6869411747027103
Epoch: 63 | Iteration number: [4350/4518] 96% | Training loss: 0.6869387332872413
Epoch: 63 | Iteration number: [4360/4518] 96% | Training loss: 0.6869394404352258
Epoch: 63 | Iteration number: [4370/4518] 96% | Training loss: 0.6869382550159908
Epoch: 63 | Iteration number: [4380/4518] 96% | Training loss: 0.686940097182853
Epoch: 63 | Iteration number: [4390/4518] 97% | Training loss: 0.6869413454739
Epoch: 63 | Iteration number: [4400/4518] 97% | Training loss: 0.6869407977570187
Epoch: 63 | Iteration number: [4410/4518] 97% | Training loss: 0.6869424917800626
Epoch: 63 | Iteration number: [4420/4518] 97% | Training loss: 0.6869408778610273
Epoch: 63 | Iteration number: [4430/4518] 98% | Training loss: 0.6869408821144707
Epoch: 63 | Iteration number: [4440/4518] 98% | Training loss: 0.6869401639109259
Epoch: 63 | Iteration number: [4450/4518] 98% | Training loss: 0.6869348446572765
Epoch: 63 | Iteration number: [4460/4518] 98% | Training loss: 0.6869363051759823
Epoch: 63 | Iteration number: [4470/4518] 98% | Training loss: 0.6869339707980486
Epoch: 63 | Iteration number: [4480/4518] 99% | Training loss: 0.6869333067376698
Epoch: 63 | Iteration number: [4490/4518] 99% | Training loss: 0.6869343070649357
Epoch: 63 | Iteration number: [4500/4518] 99% | Training loss: 0.6869353370136685
Epoch: 63 | Iteration number: [4510/4518] 99% | Training loss: 0.6869370355838682

 End of epoch: 63 | Train Loss: 0.6867851146347178 | Training Time: 629 

 End of epoch: 63 | Eval Loss: 0.6896858227496244 | Evaluating Time: 17 
Epoch: 64 | Iteration number: [10/4518] 0% | Training loss: 0.7550201058387757
Epoch: 64 | Iteration number: [20/4518] 0% | Training loss: 0.7214129984378814
Epoch: 64 | Iteration number: [30/4518] 0% | Training loss: 0.7099067409833272
Epoch: 64 | Iteration number: [40/4518] 0% | Training loss: 0.7040135875344277
Epoch: 64 | Iteration number: [50/4518] 1% | Training loss: 0.7003029811382294
Epoch: 64 | Iteration number: [60/4518] 1% | Training loss: 0.6980012367169063
Epoch: 64 | Iteration number: [70/4518] 1% | Training loss: 0.696368910585131
Epoch: 64 | Iteration number: [80/4518] 1% | Training loss: 0.6952370636165142
Epoch: 64 | Iteration number: [90/4518] 1% | Training loss: 0.6941858483685388
Epoch: 64 | Iteration number: [100/4518] 2% | Training loss: 0.6933550769090653
Epoch: 64 | Iteration number: [110/4518] 2% | Training loss: 0.6928045256571336
Epoch: 64 | Iteration number: [120/4518] 2% | Training loss: 0.6923077454169592
Epoch: 64 | Iteration number: [130/4518] 2% | Training loss: 0.691942699597432
Epoch: 64 | Iteration number: [140/4518] 3% | Training loss: 0.6915997573307582
Epoch: 64 | Iteration number: [150/4518] 3% | Training loss: 0.6912164362271627
Epoch: 64 | Iteration number: [160/4518] 3% | Training loss: 0.6909157503396273
Epoch: 64 | Iteration number: [170/4518] 3% | Training loss: 0.6905916098286123
Epoch: 64 | Iteration number: [180/4518] 3% | Training loss: 0.6903900212711758
Epoch: 64 | Iteration number: [190/4518] 4% | Training loss: 0.6901035779400876
Epoch: 64 | Iteration number: [200/4518] 4% | Training loss: 0.6899907705187798
Epoch: 64 | Iteration number: [210/4518] 4% | Training loss: 0.6898500885282244
Epoch: 64 | Iteration number: [220/4518] 4% | Training loss: 0.6897975848479705
Epoch: 64 | Iteration number: [230/4518] 5% | Training loss: 0.6896936281867649
Epoch: 64 | Iteration number: [240/4518] 5% | Training loss: 0.6895738139748573
Epoch: 64 | Iteration number: [250/4518] 5% | Training loss: 0.6894670660495759
Epoch: 64 | Iteration number: [260/4518] 5% | Training loss: 0.6893290253785941
Epoch: 64 | Iteration number: [270/4518] 5% | Training loss: 0.6892817788653903
Epoch: 64 | Iteration number: [280/4518] 6% | Training loss: 0.6891918376088142
Epoch: 64 | Iteration number: [290/4518] 6% | Training loss: 0.6890654522797157
Epoch: 64 | Iteration number: [300/4518] 6% | Training loss: 0.6889347545305888
Epoch: 64 | Iteration number: [310/4518] 6% | Training loss: 0.6888273219908437
Epoch: 64 | Iteration number: [320/4518] 7% | Training loss: 0.6887827999889851
Epoch: 64 | Iteration number: [330/4518] 7% | Training loss: 0.6887058615684509
Epoch: 64 | Iteration number: [340/4518] 7% | Training loss: 0.6886431949980119
Epoch: 64 | Iteration number: [350/4518] 7% | Training loss: 0.6885496587412698
Epoch: 64 | Iteration number: [360/4518] 7% | Training loss: 0.6885075150264635
Epoch: 64 | Iteration number: [370/4518] 8% | Training loss: 0.6884713092365781
Epoch: 64 | Iteration number: [380/4518] 8% | Training loss: 0.6884720306647452
Epoch: 64 | Iteration number: [390/4518] 8% | Training loss: 0.6884457534704453
Epoch: 64 | Iteration number: [400/4518] 8% | Training loss: 0.6883781988918781
Epoch: 64 | Iteration number: [410/4518] 9% | Training loss: 0.6883323957280415
Epoch: 64 | Iteration number: [420/4518] 9% | Training loss: 0.6882827108814603
Epoch: 64 | Iteration number: [430/4518] 9% | Training loss: 0.6882488246573958
Epoch: 64 | Iteration number: [440/4518] 9% | Training loss: 0.6881856646050106
Epoch: 64 | Iteration number: [450/4518] 9% | Training loss: 0.6881496393680573
Epoch: 64 | Iteration number: [460/4518] 10% | Training loss: 0.688122549523478
Epoch: 64 | Iteration number: [470/4518] 10% | Training loss: 0.6881112967399841
Epoch: 64 | Iteration number: [480/4518] 10% | Training loss: 0.6880870173374812
Epoch: 64 | Iteration number: [490/4518] 10% | Training loss: 0.6880461967721277
Epoch: 64 | Iteration number: [500/4518] 11% | Training loss: 0.6880367215871811
Epoch: 64 | Iteration number: [510/4518] 11% | Training loss: 0.6879863086868735
Epoch: 64 | Iteration number: [520/4518] 11% | Training loss: 0.6879512932438117
Epoch: 64 | Iteration number: [530/4518] 11% | Training loss: 0.6879286960610803
Epoch: 64 | Iteration number: [540/4518] 11% | Training loss: 0.6879069586594899
Epoch: 64 | Iteration number: [550/4518] 12% | Training loss: 0.6878808975219727
Epoch: 64 | Iteration number: [560/4518] 12% | Training loss: 0.6878348784787315
Epoch: 64 | Iteration number: [570/4518] 12% | Training loss: 0.6878400808886478
Epoch: 64 | Iteration number: [580/4518] 12% | Training loss: 0.6878076746545989
Epoch: 64 | Iteration number: [590/4518] 13% | Training loss: 0.6877884587999118
Epoch: 64 | Iteration number: [600/4518] 13% | Training loss: 0.6877407640218735
Epoch: 64 | Iteration number: [610/4518] 13% | Training loss: 0.6877385343684524
Epoch: 64 | Iteration number: [620/4518] 13% | Training loss: 0.687717378716315
Epoch: 64 | Iteration number: [630/4518] 13% | Training loss: 0.6876949382206751
Epoch: 64 | Iteration number: [640/4518] 14% | Training loss: 0.6876792877912521
Epoch: 64 | Iteration number: [650/4518] 14% | Training loss: 0.6876582050323486
Epoch: 64 | Iteration number: [660/4518] 14% | Training loss: 0.6876516976139763
Epoch: 64 | Iteration number: [670/4518] 14% | Training loss: 0.6876439292929066
Epoch: 64 | Iteration number: [680/4518] 15% | Training loss: 0.687636610076708
Epoch: 64 | Iteration number: [690/4518] 15% | Training loss: 0.6876385174799656
Epoch: 64 | Iteration number: [700/4518] 15% | Training loss: 0.6876032889740807
Epoch: 64 | Iteration number: [710/4518] 15% | Training loss: 0.6875888406390875
Epoch: 64 | Iteration number: [720/4518] 15% | Training loss: 0.687587032549911
Epoch: 64 | Iteration number: [730/4518] 16% | Training loss: 0.6875779915345859
Epoch: 64 | Iteration number: [740/4518] 16% | Training loss: 0.6875571545716879
Epoch: 64 | Iteration number: [750/4518] 16% | Training loss: 0.6875383952458699
Epoch: 64 | Iteration number: [760/4518] 16% | Training loss: 0.6875327892209354
Epoch: 64 | Iteration number: [770/4518] 17% | Training loss: 0.687530779838562
Epoch: 64 | Iteration number: [780/4518] 17% | Training loss: 0.6875072964490988
Epoch: 64 | Iteration number: [790/4518] 17% | Training loss: 0.6874998518183262
Epoch: 64 | Iteration number: [800/4518] 17% | Training loss: 0.6874892423301935
Epoch: 64 | Iteration number: [810/4518] 17% | Training loss: 0.6874923566241323
Epoch: 64 | Iteration number: [820/4518] 18% | Training loss: 0.687485800647154
Epoch: 64 | Iteration number: [830/4518] 18% | Training loss: 0.687498849127666
Epoch: 64 | Iteration number: [840/4518] 18% | Training loss: 0.6874833168728011
Epoch: 64 | Iteration number: [850/4518] 18% | Training loss: 0.6874692339055678
Epoch: 64 | Iteration number: [860/4518] 19% | Training loss: 0.6874518324469411
Epoch: 64 | Iteration number: [870/4518] 19% | Training loss: 0.6874403811734299
Epoch: 64 | Iteration number: [880/4518] 19% | Training loss: 0.6874370663003488
Epoch: 64 | Iteration number: [890/4518] 19% | Training loss: 0.6874244843975882
Epoch: 64 | Iteration number: [900/4518] 19% | Training loss: 0.6874184421698253
Epoch: 64 | Iteration number: [910/4518] 20% | Training loss: 0.6873948837374593
Epoch: 64 | Iteration number: [920/4518] 20% | Training loss: 0.6873767259328262
Epoch: 64 | Iteration number: [930/4518] 20% | Training loss: 0.6873852985520517
Epoch: 64 | Iteration number: [940/4518] 20% | Training loss: 0.6873722671828372
Epoch: 64 | Iteration number: [950/4518] 21% | Training loss: 0.6873653861723448
Epoch: 64 | Iteration number: [960/4518] 21% | Training loss: 0.6873606874297062
Epoch: 64 | Iteration number: [970/4518] 21% | Training loss: 0.6873513963419138
Epoch: 64 | Iteration number: [980/4518] 21% | Training loss: 0.6873436691201463
Epoch: 64 | Iteration number: [990/4518] 21% | Training loss: 0.6873451656163341
Epoch: 64 | Iteration number: [1000/4518] 22% | Training loss: 0.6873351231217384
Epoch: 64 | Iteration number: [1010/4518] 22% | Training loss: 0.6873301962224564
Epoch: 64 | Iteration number: [1020/4518] 22% | Training loss: 0.6873317549041673
Epoch: 64 | Iteration number: [1030/4518] 22% | Training loss: 0.6873300046018026
Epoch: 64 | Iteration number: [1040/4518] 23% | Training loss: 0.6873302271732917
Epoch: 64 | Iteration number: [1050/4518] 23% | Training loss: 0.6873262098289672
Epoch: 64 | Iteration number: [1060/4518] 23% | Training loss: 0.6873227976965455
Epoch: 64 | Iteration number: [1070/4518] 23% | Training loss: 0.6873204264685372
Epoch: 64 | Iteration number: [1080/4518] 23% | Training loss: 0.6873189504499788
Epoch: 64 | Iteration number: [1090/4518] 24% | Training loss: 0.6873085413504084
Epoch: 64 | Iteration number: [1100/4518] 24% | Training loss: 0.6873072319680994
Epoch: 64 | Iteration number: [1110/4518] 24% | Training loss: 0.6872990912682301
Epoch: 64 | Iteration number: [1120/4518] 24% | Training loss: 0.6873029733342784
Epoch: 64 | Iteration number: [1130/4518] 25% | Training loss: 0.6872935271368618
Epoch: 64 | Iteration number: [1140/4518] 25% | Training loss: 0.6872943274284664
Epoch: 64 | Iteration number: [1150/4518] 25% | Training loss: 0.6872939997134001
Epoch: 64 | Iteration number: [1160/4518] 25% | Training loss: 0.6872862541470034
Epoch: 64 | Iteration number: [1170/4518] 25% | Training loss: 0.6872844066375341
Epoch: 64 | Iteration number: [1180/4518] 26% | Training loss: 0.6872901309344728
Epoch: 64 | Iteration number: [1190/4518] 26% | Training loss: 0.6873000599756962
Epoch: 64 | Iteration number: [1200/4518] 26% | Training loss: 0.6872908390561739
Epoch: 64 | Iteration number: [1210/4518] 26% | Training loss: 0.6872914415745696
Epoch: 64 | Iteration number: [1220/4518] 27% | Training loss: 0.6872932790244212
Epoch: 64 | Iteration number: [1230/4518] 27% | Training loss: 0.6872835474770244
Epoch: 64 | Iteration number: [1240/4518] 27% | Training loss: 0.687281693373957
Epoch: 64 | Iteration number: [1250/4518] 27% | Training loss: 0.687287432050705
Epoch: 64 | Iteration number: [1260/4518] 27% | Training loss: 0.6872742287223301
Epoch: 64 | Iteration number: [1270/4518] 28% | Training loss: 0.687271478514033
Epoch: 64 | Iteration number: [1280/4518] 28% | Training loss: 0.687269197544083
Epoch: 64 | Iteration number: [1290/4518] 28% | Training loss: 0.687259450762771
Epoch: 64 | Iteration number: [1300/4518] 28% | Training loss: 0.6872537214480914
Epoch: 64 | Iteration number: [1310/4518] 28% | Training loss: 0.6872532649804618
Epoch: 64 | Iteration number: [1320/4518] 29% | Training loss: 0.6872525361902786
Epoch: 64 | Iteration number: [1330/4518] 29% | Training loss: 0.6872416474765405
Epoch: 64 | Iteration number: [1340/4518] 29% | Training loss: 0.6872406252284549
Epoch: 64 | Iteration number: [1350/4518] 29% | Training loss: 0.6872297514367987
Epoch: 64 | Iteration number: [1360/4518] 30% | Training loss: 0.6872354215558838
Epoch: 64 | Iteration number: [1370/4518] 30% | Training loss: 0.6872284857461052
Epoch: 64 | Iteration number: [1380/4518] 30% | Training loss: 0.6872270442437435
Epoch: 64 | Iteration number: [1390/4518] 30% | Training loss: 0.68720983536981
Epoch: 64 | Iteration number: [1400/4518] 30% | Training loss: 0.6872123403634344
Epoch: 64 | Iteration number: [1410/4518] 31% | Training loss: 0.6872167626171247
Epoch: 64 | Iteration number: [1420/4518] 31% | Training loss: 0.6872020254672413
Epoch: 64 | Iteration number: [1430/4518] 31% | Training loss: 0.6871852787224563
Epoch: 64 | Iteration number: [1440/4518] 31% | Training loss: 0.6871794063183997
Epoch: 64 | Iteration number: [1450/4518] 32% | Training loss: 0.6871797033425036
Epoch: 64 | Iteration number: [1460/4518] 32% | Training loss: 0.6871660693459315
Epoch: 64 | Iteration number: [1470/4518] 32% | Training loss: 0.6871712442158031
Epoch: 64 | Iteration number: [1480/4518] 32% | Training loss: 0.6871682462660043
Epoch: 64 | Iteration number: [1490/4518] 32% | Training loss: 0.6871630650638734
Epoch: 64 | Iteration number: [1500/4518] 33% | Training loss: 0.687161835471789
Epoch: 64 | Iteration number: [1510/4518] 33% | Training loss: 0.6871710950570391
Epoch: 64 | Iteration number: [1520/4518] 33% | Training loss: 0.6871713585759464
Epoch: 64 | Iteration number: [1530/4518] 33% | Training loss: 0.6871631244428796
Epoch: 64 | Iteration number: [1540/4518] 34% | Training loss: 0.6871542639933623
Epoch: 64 | Iteration number: [1550/4518] 34% | Training loss: 0.6871454611132222
Epoch: 64 | Iteration number: [1560/4518] 34% | Training loss: 0.6871414540287776
Epoch: 64 | Iteration number: [1570/4518] 34% | Training loss: 0.6871427092962205
Epoch: 64 | Iteration number: [1580/4518] 34% | Training loss: 0.6871468309737458
Epoch: 64 | Iteration number: [1590/4518] 35% | Training loss: 0.6871317935064903
Epoch: 64 | Iteration number: [1600/4518] 35% | Training loss: 0.6871293133497238
Epoch: 64 | Iteration number: [1610/4518] 35% | Training loss: 0.6871299790669673
Epoch: 64 | Iteration number: [1620/4518] 35% | Training loss: 0.6871240222159727
Epoch: 64 | Iteration number: [1630/4518] 36% | Training loss: 0.6871207700185249
Epoch: 64 | Iteration number: [1640/4518] 36% | Training loss: 0.6871199568233839
Epoch: 64 | Iteration number: [1650/4518] 36% | Training loss: 0.6871218080231638
Epoch: 64 | Iteration number: [1660/4518] 36% | Training loss: 0.6871188654597983
Epoch: 64 | Iteration number: [1670/4518] 36% | Training loss: 0.68711642580118
Epoch: 64 | Iteration number: [1680/4518] 37% | Training loss: 0.6871167964878536
Epoch: 64 | Iteration number: [1690/4518] 37% | Training loss: 0.6871095871078897
Epoch: 64 | Iteration number: [1700/4518] 37% | Training loss: 0.6871089054907069
Epoch: 64 | Iteration number: [1710/4518] 37% | Training loss: 0.6871006373773542
Epoch: 64 | Iteration number: [1720/4518] 38% | Training loss: 0.6871054320141327
Epoch: 64 | Iteration number: [1730/4518] 38% | Training loss: 0.6870927235983699
Epoch: 64 | Iteration number: [1740/4518] 38% | Training loss: 0.6870906722271579
Epoch: 64 | Iteration number: [1750/4518] 38% | Training loss: 0.6870854996953691
Epoch: 64 | Iteration number: [1760/4518] 38% | Training loss: 0.6870878501033241
Epoch: 64 | Iteration number: [1770/4518] 39% | Training loss: 0.6870816349983215
Epoch: 64 | Iteration number: [1780/4518] 39% | Training loss: 0.6870857096789929
Epoch: 64 | Iteration number: [1790/4518] 39% | Training loss: 0.6870785052549906
Epoch: 64 | Iteration number: [1800/4518] 39% | Training loss: 0.6870765881405936
Epoch: 64 | Iteration number: [1810/4518] 40% | Training loss: 0.6870712788065494
Epoch: 64 | Iteration number: [1820/4518] 40% | Training loss: 0.6870670508552383
Epoch: 64 | Iteration number: [1830/4518] 40% | Training loss: 0.687070636996806
Epoch: 64 | Iteration number: [1840/4518] 40% | Training loss: 0.6870601512167764
Epoch: 64 | Iteration number: [1850/4518] 40% | Training loss: 0.6870531819639979
Epoch: 64 | Iteration number: [1860/4518] 41% | Training loss: 0.6870528212478084
Epoch: 64 | Iteration number: [1870/4518] 41% | Training loss: 0.6870473167156791
Epoch: 64 | Iteration number: [1880/4518] 41% | Training loss: 0.6870464109359904
Epoch: 64 | Iteration number: [1890/4518] 41% | Training loss: 0.6870406425819195
Epoch: 64 | Iteration number: [1900/4518] 42% | Training loss: 0.6870463750550622
Epoch: 64 | Iteration number: [1910/4518] 42% | Training loss: 0.6870478236550436
Epoch: 64 | Iteration number: [1920/4518] 42% | Training loss: 0.6870451224967837
Epoch: 64 | Iteration number: [1930/4518] 42% | Training loss: 0.6870461561210415
Epoch: 64 | Iteration number: [1940/4518] 42% | Training loss: 0.6870424234682752
Epoch: 64 | Iteration number: [1950/4518] 43% | Training loss: 0.6870373120369055
Epoch: 64 | Iteration number: [1960/4518] 43% | Training loss: 0.6870374198774902
Epoch: 64 | Iteration number: [1970/4518] 43% | Training loss: 0.6870341100668544
Epoch: 64 | Iteration number: [1980/4518] 43% | Training loss: 0.6870342548748459
Epoch: 64 | Iteration number: [1990/4518] 44% | Training loss: 0.687027575682156
Epoch: 64 | Iteration number: [2000/4518] 44% | Training loss: 0.6870273917615414
Epoch: 64 | Iteration number: [2010/4518] 44% | Training loss: 0.6870284280077142
Epoch: 64 | Iteration number: [2020/4518] 44% | Training loss: 0.6870248264015311
Epoch: 64 | Iteration number: [2030/4518] 44% | Training loss: 0.6870289316318305
Epoch: 64 | Iteration number: [2040/4518] 45% | Training loss: 0.687032173340227
Epoch: 64 | Iteration number: [2050/4518] 45% | Training loss: 0.6870355597937979
Epoch: 64 | Iteration number: [2060/4518] 45% | Training loss: 0.6870381343422585
Epoch: 64 | Iteration number: [2070/4518] 45% | Training loss: 0.6870336918727211
Epoch: 64 | Iteration number: [2080/4518] 46% | Training loss: 0.6870410010791742
Epoch: 64 | Iteration number: [2090/4518] 46% | Training loss: 0.6870399232401232
Epoch: 64 | Iteration number: [2100/4518] 46% | Training loss: 0.6870380703324364
Epoch: 64 | Iteration number: [2110/4518] 46% | Training loss: 0.6870426010746526
Epoch: 64 | Iteration number: [2120/4518] 46% | Training loss: 0.6870315841908725
Epoch: 64 | Iteration number: [2130/4518] 47% | Training loss: 0.687035477273341
Epoch: 64 | Iteration number: [2140/4518] 47% | Training loss: 0.6870387388445507
Epoch: 64 | Iteration number: [2150/4518] 47% | Training loss: 0.6870383107107739
Epoch: 64 | Iteration number: [2160/4518] 47% | Training loss: 0.6870316648924792
Epoch: 64 | Iteration number: [2170/4518] 48% | Training loss: 0.6870292496296667
Epoch: 64 | Iteration number: [2180/4518] 48% | Training loss: 0.6870304494002544
Epoch: 64 | Iteration number: [2190/4518] 48% | Training loss: 0.6870382321479658
Epoch: 64 | Iteration number: [2200/4518] 48% | Training loss: 0.6870402632789179
Epoch: 64 | Iteration number: [2210/4518] 48% | Training loss: 0.6870385728810168
Epoch: 64 | Iteration number: [2220/4518] 49% | Training loss: 0.6870420853833894
Epoch: 64 | Iteration number: [2230/4518] 49% | Training loss: 0.6870361251681375
Epoch: 64 | Iteration number: [2240/4518] 49% | Training loss: 0.6870345697073
Epoch: 64 | Iteration number: [2250/4518] 49% | Training loss: 0.6870297145843506
Epoch: 64 | Iteration number: [2260/4518] 50% | Training loss: 0.6870304244809446
Epoch: 64 | Iteration number: [2270/4518] 50% | Training loss: 0.6870324134301509
Epoch: 64 | Iteration number: [2280/4518] 50% | Training loss: 0.6870311628831061
Epoch: 64 | Iteration number: [2290/4518] 50% | Training loss: 0.6870289432429851
Epoch: 64 | Iteration number: [2300/4518] 50% | Training loss: 0.6870255854337112
Epoch: 64 | Iteration number: [2310/4518] 51% | Training loss: 0.6870237156942294
Epoch: 64 | Iteration number: [2320/4518] 51% | Training loss: 0.6870302088815591
Epoch: 64 | Iteration number: [2330/4518] 51% | Training loss: 0.687029470829493
Epoch: 64 | Iteration number: [2340/4518] 51% | Training loss: 0.687032966583203
Epoch: 64 | Iteration number: [2350/4518] 52% | Training loss: 0.6870345207731775
Epoch: 64 | Iteration number: [2360/4518] 52% | Training loss: 0.6870325788855552
Epoch: 64 | Iteration number: [2370/4518] 52% | Training loss: 0.6870357813965923
Epoch: 64 | Iteration number: [2380/4518] 52% | Training loss: 0.6870375355502136
Epoch: 64 | Iteration number: [2390/4518] 52% | Training loss: 0.6870399043649809
Epoch: 64 | Iteration number: [2400/4518] 53% | Training loss: 0.6870372158040603
Epoch: 64 | Iteration number: [2410/4518] 53% | Training loss: 0.6870400311788583
Epoch: 64 | Iteration number: [2420/4518] 53% | Training loss: 0.6870417816579835
Epoch: 64 | Iteration number: [2430/4518] 53% | Training loss: 0.6870368394341488
Epoch: 64 | Iteration number: [2440/4518] 54% | Training loss: 0.6870359139608555
Epoch: 64 | Iteration number: [2450/4518] 54% | Training loss: 0.6870436501746275
Epoch: 64 | Iteration number: [2460/4518] 54% | Training loss: 0.6870445668939652
Epoch: 64 | Iteration number: [2470/4518] 54% | Training loss: 0.687045072712879
Epoch: 64 | Iteration number: [2480/4518] 54% | Training loss: 0.6870427082863546
Epoch: 64 | Iteration number: [2490/4518] 55% | Training loss: 0.6870394045569331
Epoch: 64 | Iteration number: [2500/4518] 55% | Training loss: 0.687037603878975
Epoch: 64 | Iteration number: [2510/4518] 55% | Training loss: 0.6870359846082816
Epoch: 64 | Iteration number: [2520/4518] 55% | Training loss: 0.6870385342883685
Epoch: 64 | Iteration number: [2530/4518] 55% | Training loss: 0.6870378250425512
Epoch: 64 | Iteration number: [2540/4518] 56% | Training loss: 0.6870366929084297
Epoch: 64 | Iteration number: [2550/4518] 56% | Training loss: 0.6870352027462978
Epoch: 64 | Iteration number: [2560/4518] 56% | Training loss: 0.6870334153529256
Epoch: 64 | Iteration number: [2570/4518] 56% | Training loss: 0.6870344678483584
Epoch: 64 | Iteration number: [2580/4518] 57% | Training loss: 0.6870384578094926
Epoch: 64 | Iteration number: [2590/4518] 57% | Training loss: 0.6870369228847238
Epoch: 64 | Iteration number: [2600/4518] 57% | Training loss: 0.6870339118517362
Epoch: 64 | Iteration number: [2610/4518] 57% | Training loss: 0.6870312463506428
Epoch: 64 | Iteration number: [2620/4518] 57% | Training loss: 0.6870330528221058
Epoch: 64 | Iteration number: [2630/4518] 58% | Training loss: 0.6870335168258319
Epoch: 64 | Iteration number: [2640/4518] 58% | Training loss: 0.6870354456883488
Epoch: 64 | Iteration number: [2650/4518] 58% | Training loss: 0.6870412634453683
Epoch: 64 | Iteration number: [2660/4518] 58% | Training loss: 0.6870383422177537
Epoch: 64 | Iteration number: [2670/4518] 59% | Training loss: 0.6870377623409815
Epoch: 64 | Iteration number: [2680/4518] 59% | Training loss: 0.6870412265854096
Epoch: 64 | Iteration number: [2690/4518] 59% | Training loss: 0.6870367164505459
Epoch: 64 | Iteration number: [2700/4518] 59% | Training loss: 0.6870396783837566
Epoch: 64 | Iteration number: [2710/4518] 59% | Training loss: 0.6870381741946033
Epoch: 64 | Iteration number: [2720/4518] 60% | Training loss: 0.6870350953191519
Epoch: 64 | Iteration number: [2730/4518] 60% | Training loss: 0.687034556782726
Epoch: 64 | Iteration number: [2740/4518] 60% | Training loss: 0.687034571845166
Epoch: 64 | Iteration number: [2750/4518] 60% | Training loss: 0.6870359111048958
Epoch: 64 | Iteration number: [2760/4518] 61% | Training loss: 0.6870366749556168
Epoch: 64 | Iteration number: [2770/4518] 61% | Training loss: 0.6870339466561479
Epoch: 64 | Iteration number: [2780/4518] 61% | Training loss: 0.687030406371295
Epoch: 64 | Iteration number: [2790/4518] 61% | Training loss: 0.6870283850845897
Epoch: 64 | Iteration number: [2800/4518] 61% | Training loss: 0.6870260666310787
Epoch: 64 | Iteration number: [2810/4518] 62% | Training loss: 0.6870274640911415
Epoch: 64 | Iteration number: [2820/4518] 62% | Training loss: 0.6870270960719873
Epoch: 64 | Iteration number: [2830/4518] 62% | Training loss: 0.6870256094123787
Epoch: 64 | Iteration number: [2840/4518] 62% | Training loss: 0.6870235964655876
Epoch: 64 | Iteration number: [2850/4518] 63% | Training loss: 0.6870254952029178
Epoch: 64 | Iteration number: [2860/4518] 63% | Training loss: 0.6870252035506121
Epoch: 64 | Iteration number: [2870/4518] 63% | Training loss: 0.6870262707359699
Epoch: 64 | Iteration number: [2880/4518] 63% | Training loss: 0.6870287902860178
Epoch: 64 | Iteration number: [2890/4518] 63% | Training loss: 0.6870270271202272
Epoch: 64 | Iteration number: [2900/4518] 64% | Training loss: 0.6870292178104663
Epoch: 64 | Iteration number: [2910/4518] 64% | Training loss: 0.6870273772179056
Epoch: 64 | Iteration number: [2920/4518] 64% | Training loss: 0.6870254492106503
Epoch: 64 | Iteration number: [2930/4518] 64% | Training loss: 0.68702768482039
Epoch: 64 | Iteration number: [2940/4518] 65% | Training loss: 0.6870259609960374
Epoch: 64 | Iteration number: [2950/4518] 65% | Training loss: 0.6870234369221381
Epoch: 64 | Iteration number: [2960/4518] 65% | Training loss: 0.6870215081886665
Epoch: 64 | Iteration number: [2970/4518] 65% | Training loss: 0.6870182785923633
Epoch: 64 | Iteration number: [2980/4518] 65% | Training loss: 0.6870179566160944
Epoch: 64 | Iteration number: [2990/4518] 66% | Training loss: 0.6870177373240225
Epoch: 64 | Iteration number: [3000/4518] 66% | Training loss: 0.6870171159704527
Epoch: 64 | Iteration number: [3010/4518] 66% | Training loss: 0.6870145505448908
Epoch: 64 | Iteration number: [3020/4518] 66% | Training loss: 0.6870131395313124
Epoch: 64 | Iteration number: [3030/4518] 67% | Training loss: 0.6870121931675637
Epoch: 64 | Iteration number: [3040/4518] 67% | Training loss: 0.6870116217748115
Epoch: 64 | Iteration number: [3050/4518] 67% | Training loss: 0.6870086037526365
Epoch: 64 | Iteration number: [3060/4518] 67% | Training loss: 0.6870109470256793
Epoch: 64 | Iteration number: [3070/4518] 67% | Training loss: 0.687009869413966
Epoch: 64 | Iteration number: [3080/4518] 68% | Training loss: 0.6870048608292233
Epoch: 64 | Iteration number: [3090/4518] 68% | Training loss: 0.6870044633022789
Epoch: 64 | Iteration number: [3100/4518] 68% | Training loss: 0.6870024031592954
Epoch: 64 | Iteration number: [3110/4518] 68% | Training loss: 0.6869994932240612
Epoch: 64 | Iteration number: [3120/4518] 69% | Training loss: 0.6869966971759612
Epoch: 64 | Iteration number: [3130/4518] 69% | Training loss: 0.687000817517503
Epoch: 64 | Iteration number: [3140/4518] 69% | Training loss: 0.687004805579307
Epoch: 64 | Iteration number: [3150/4518] 69% | Training loss: 0.6870049317867036
Epoch: 64 | Iteration number: [3160/4518] 69% | Training loss: 0.6870024061844319
Epoch: 64 | Iteration number: [3170/4518] 70% | Training loss: 0.6870044255482286
Epoch: 64 | Iteration number: [3180/4518] 70% | Training loss: 0.6870016552367301
Epoch: 64 | Iteration number: [3190/4518] 70% | Training loss: 0.6869974416812011
Epoch: 64 | Iteration number: [3200/4518] 70% | Training loss: 0.686999231223017
Epoch: 64 | Iteration number: [3210/4518] 71% | Training loss: 0.6870021003614705
Epoch: 64 | Iteration number: [3220/4518] 71% | Training loss: 0.6870027421424107
Epoch: 64 | Iteration number: [3230/4518] 71% | Training loss: 0.6870027745102212
Epoch: 64 | Iteration number: [3240/4518] 71% | Training loss: 0.6869985285732482
Epoch: 64 | Iteration number: [3250/4518] 71% | Training loss: 0.6870025671445407
Epoch: 64 | Iteration number: [3260/4518] 72% | Training loss: 0.6869996438362848
Epoch: 64 | Iteration number: [3270/4518] 72% | Training loss: 0.6869964307236744
Epoch: 64 | Iteration number: [3280/4518] 72% | Training loss: 0.6869949632665006
Epoch: 64 | Iteration number: [3290/4518] 72% | Training loss: 0.6869923406277746
Epoch: 64 | Iteration number: [3300/4518] 73% | Training loss: 0.6869944417115413
Epoch: 64 | Iteration number: [3310/4518] 73% | Training loss: 0.686991275527326
Epoch: 64 | Iteration number: [3320/4518] 73% | Training loss: 0.6869901261954422
Epoch: 64 | Iteration number: [3330/4518] 73% | Training loss: 0.686985766654974
Epoch: 64 | Iteration number: [3340/4518] 73% | Training loss: 0.6869850115147893
Epoch: 64 | Iteration number: [3350/4518] 74% | Training loss: 0.686986151310935
Epoch: 64 | Iteration number: [3360/4518] 74% | Training loss: 0.686985708471565
Epoch: 64 | Iteration number: [3370/4518] 74% | Training loss: 0.6869825029231674
Epoch: 64 | Iteration number: [3380/4518] 74% | Training loss: 0.6869848803302946
Epoch: 64 | Iteration number: [3390/4518] 75% | Training loss: 0.6869870092664848
Epoch: 64 | Iteration number: [3400/4518] 75% | Training loss: 0.6869881166079465
Epoch: 64 | Iteration number: [3410/4518] 75% | Training loss: 0.6869898909347847
Epoch: 64 | Iteration number: [3420/4518] 75% | Training loss: 0.6869891089479826
Epoch: 64 | Iteration number: [3430/4518] 75% | Training loss: 0.686987620383588
Epoch: 64 | Iteration number: [3440/4518] 76% | Training loss: 0.6869887939892536
Epoch: 64 | Iteration number: [3450/4518] 76% | Training loss: 0.686991025554961
Epoch: 64 | Iteration number: [3460/4518] 76% | Training loss: 0.6869904212524436
Epoch: 64 | Iteration number: [3470/4518] 76% | Training loss: 0.6869870070937044
Epoch: 64 | Iteration number: [3480/4518] 77% | Training loss: 0.6869840111026819
Epoch: 64 | Iteration number: [3490/4518] 77% | Training loss: 0.6869831445053177
Epoch: 64 | Iteration number: [3500/4518] 77% | Training loss: 0.6869811331885202
Epoch: 64 | Iteration number: [3510/4518] 77% | Training loss: 0.6869827533379579
Epoch: 64 | Iteration number: [3520/4518] 77% | Training loss: 0.6869840863753449
Epoch: 64 | Iteration number: [3530/4518] 78% | Training loss: 0.6869812225484984
Epoch: 64 | Iteration number: [3540/4518] 78% | Training loss: 0.6869789320028434
Epoch: 64 | Iteration number: [3550/4518] 78% | Training loss: 0.6869806262808786
Epoch: 64 | Iteration number: [3560/4518] 78% | Training loss: 0.686980767313684
Epoch: 64 | Iteration number: [3570/4518] 79% | Training loss: 0.6869768869476158
Epoch: 64 | Iteration number: [3580/4518] 79% | Training loss: 0.6869757201252037
Epoch: 64 | Iteration number: [3590/4518] 79% | Training loss: 0.6869751703772372
Epoch: 64 | Iteration number: [3600/4518] 79% | Training loss: 0.6869764830503199
Epoch: 64 | Iteration number: [3610/4518] 79% | Training loss: 0.6869784385874
Epoch: 64 | Iteration number: [3620/4518] 80% | Training loss: 0.6869762370764221
Epoch: 64 | Iteration number: [3630/4518] 80% | Training loss: 0.6869783474722513
Epoch: 64 | Iteration number: [3640/4518] 80% | Training loss: 0.6869766430212901
Epoch: 64 | Iteration number: [3650/4518] 80% | Training loss: 0.686974306351518
Epoch: 64 | Iteration number: [3660/4518] 81% | Training loss: 0.6869743516862067
Epoch: 64 | Iteration number: [3670/4518] 81% | Training loss: 0.6869744692576354
Epoch: 64 | Iteration number: [3680/4518] 81% | Training loss: 0.6869754534214735
Epoch: 64 | Iteration number: [3690/4518] 81% | Training loss: 0.6869743406449553
Epoch: 64 | Iteration number: [3700/4518] 81% | Training loss: 0.686974808493176
Epoch: 64 | Iteration number: [3710/4518] 82% | Training loss: 0.6869741531234546
Epoch: 64 | Iteration number: [3720/4518] 82% | Training loss: 0.6869726707377741
Epoch: 64 | Iteration number: [3730/4518] 82% | Training loss: 0.6869707492816863
Epoch: 64 | Iteration number: [3740/4518] 82% | Training loss: 0.6869708001932359
Epoch: 64 | Iteration number: [3750/4518] 83% | Training loss: 0.6869666230042776
Epoch: 64 | Iteration number: [3760/4518] 83% | Training loss: 0.6869660980523901
Epoch: 64 | Iteration number: [3770/4518] 83% | Training loss: 0.6869634959362546
Epoch: 64 | Iteration number: [3780/4518] 83% | Training loss: 0.6869633076998292
Epoch: 64 | Iteration number: [3790/4518] 83% | Training loss: 0.6869650295510455
Epoch: 64 | Iteration number: [3800/4518] 84% | Training loss: 0.6869617285853938
Epoch: 64 | Iteration number: [3810/4518] 84% | Training loss: 0.6869632756616187
Epoch: 64 | Iteration number: [3820/4518] 84% | Training loss: 0.6869618548616689
Epoch: 64 | Iteration number: [3830/4518] 84% | Training loss: 0.6869635020161422
Epoch: 64 | Iteration number: [3840/4518] 84% | Training loss: 0.6869628213966886
Epoch: 64 | Iteration number: [3850/4518] 85% | Training loss: 0.6869651358313374
Epoch: 64 | Iteration number: [3860/4518] 85% | Training loss: 0.6869661827315938
Epoch: 64 | Iteration number: [3870/4518] 85% | Training loss: 0.6869664104101886
Epoch: 64 | Iteration number: [3880/4518] 85% | Training loss: 0.686965425281795
Epoch: 64 | Iteration number: [3890/4518] 86% | Training loss: 0.6869656098992168
Epoch: 64 | Iteration number: [3900/4518] 86% | Training loss: 0.6869685798730606
Epoch: 64 | Iteration number: [3910/4518] 86% | Training loss: 0.6869660091979425
Epoch: 64 | Iteration number: [3920/4518] 86% | Training loss: 0.686969096548095
Epoch: 64 | Iteration number: [3930/4518] 86% | Training loss: 0.6869695033735901
Epoch: 64 | Iteration number: [3940/4518] 87% | Training loss: 0.6869720540070897
Epoch: 64 | Iteration number: [3950/4518] 87% | Training loss: 0.6869735803936101
Epoch: 64 | Iteration number: [3960/4518] 87% | Training loss: 0.6869703015594771
Epoch: 64 | Iteration number: [3970/4518] 87% | Training loss: 0.6869650088869955
Epoch: 64 | Iteration number: [3980/4518] 88% | Training loss: 0.6869625344647834
Epoch: 64 | Iteration number: [3990/4518] 88% | Training loss: 0.6869625161614334
Epoch: 64 | Iteration number: [4000/4518] 88% | Training loss: 0.686962596476078
Epoch: 64 | Iteration number: [4010/4518] 88% | Training loss: 0.686962902456745
Epoch: 64 | Iteration number: [4020/4518] 88% | Training loss: 0.6869622723973212
Epoch: 64 | Iteration number: [4030/4518] 89% | Training loss: 0.6869597181640843
Epoch: 64 | Iteration number: [4040/4518] 89% | Training loss: 0.6869622604681713
Epoch: 64 | Iteration number: [4050/4518] 89% | Training loss: 0.6869631655569429
Epoch: 64 | Iteration number: [4060/4518] 89% | Training loss: 0.686963183084145
Epoch: 64 | Iteration number: [4070/4518] 90% | Training loss: 0.6869635426295184
Epoch: 64 | Iteration number: [4080/4518] 90% | Training loss: 0.6869637254844694
Epoch: 64 | Iteration number: [4090/4518] 90% | Training loss: 0.6869610832489499
Epoch: 64 | Iteration number: [4100/4518] 90% | Training loss: 0.6869578278064727
Epoch: 64 | Iteration number: [4110/4518] 90% | Training loss: 0.6869549646574795
Epoch: 64 | Iteration number: [4120/4518] 91% | Training loss: 0.6869503272389903
Epoch: 64 | Iteration number: [4130/4518] 91% | Training loss: 0.6869470016142358
Epoch: 64 | Iteration number: [4140/4518] 91% | Training loss: 0.6869472178140125
Epoch: 64 | Iteration number: [4150/4518] 91% | Training loss: 0.6869458275530712
Epoch: 64 | Iteration number: [4160/4518] 92% | Training loss: 0.6869463476567315
Epoch: 64 | Iteration number: [4170/4518] 92% | Training loss: 0.6869452061841814
Epoch: 64 | Iteration number: [4180/4518] 92% | Training loss: 0.686943584381108
Epoch: 64 | Iteration number: [4190/4518] 92% | Training loss: 0.6869428765517716
Epoch: 64 | Iteration number: [4200/4518] 92% | Training loss: 0.6869416763243221
Epoch: 64 | Iteration number: [4210/4518] 93% | Training loss: 0.6869446799477602
Epoch: 64 | Iteration number: [4220/4518] 93% | Training loss: 0.6869478449296047
Epoch: 64 | Iteration number: [4230/4518] 93% | Training loss: 0.6869476213381928
Epoch: 64 | Iteration number: [4240/4518] 93% | Training loss: 0.6869486256731007
Epoch: 64 | Iteration number: [4250/4518] 94% | Training loss: 0.6869466675169328
Epoch: 64 | Iteration number: [4260/4518] 94% | Training loss: 0.6869404104393972
Epoch: 64 | Iteration number: [4270/4518] 94% | Training loss: 0.6869404917438918
Epoch: 64 | Iteration number: [4280/4518] 94% | Training loss: 0.6869395481091793
Epoch: 64 | Iteration number: [4290/4518] 94% | Training loss: 0.6869404032791689
Epoch: 64 | Iteration number: [4300/4518] 95% | Training loss: 0.68693954975106
Epoch: 64 | Iteration number: [4310/4518] 95% | Training loss: 0.6869406801641955
Epoch: 64 | Iteration number: [4320/4518] 95% | Training loss: 0.686939894683935
Epoch: 64 | Iteration number: [4330/4518] 95% | Training loss: 0.6869413105912903
Epoch: 64 | Iteration number: [4340/4518] 96% | Training loss: 0.6869403935247852
Epoch: 64 | Iteration number: [4350/4518] 96% | Training loss: 0.6869378955062778
Epoch: 64 | Iteration number: [4360/4518] 96% | Training loss: 0.6869387418578524
Epoch: 64 | Iteration number: [4370/4518] 96% | Training loss: 0.6869392948919903
Epoch: 64 | Iteration number: [4380/4518] 96% | Training loss: 0.6869406950256052
Epoch: 64 | Iteration number: [4390/4518] 97% | Training loss: 0.6869404653481851
Epoch: 64 | Iteration number: [4400/4518] 97% | Training loss: 0.6869415591657162
Epoch: 64 | Iteration number: [4410/4518] 97% | Training loss: 0.6869385131767818
Epoch: 64 | Iteration number: [4420/4518] 97% | Training loss: 0.6869370994794423
Epoch: 64 | Iteration number: [4430/4518] 98% | Training loss: 0.6869369719152257
Epoch: 64 | Iteration number: [4440/4518] 98% | Training loss: 0.6869366833621318
Epoch: 64 | Iteration number: [4450/4518] 98% | Training loss: 0.6869364670287357
Epoch: 64 | Iteration number: [4460/4518] 98% | Training loss: 0.6869359339967437
Epoch: 64 | Iteration number: [4470/4518] 98% | Training loss: 0.6869347829146674
Epoch: 64 | Iteration number: [4480/4518] 99% | Training loss: 0.6869344075476485
Epoch: 64 | Iteration number: [4490/4518] 99% | Training loss: 0.6869337119610113
Epoch: 64 | Iteration number: [4500/4518] 99% | Training loss: 0.6869323357741038
Epoch: 64 | Iteration number: [4510/4518] 99% | Training loss: 0.6869315733534269

 End of epoch: 64 | Train Loss: 0.6867787858826653 | Training Time: 632 

 End of epoch: 64 | Eval Loss: 0.689709412808321 | Evaluating Time: 17 
Epoch: 65 | Iteration number: [10/4518] 0% | Training loss: 0.7557900905609131
Epoch: 65 | Iteration number: [20/4518] 0% | Training loss: 0.7218009293079376
Epoch: 65 | Iteration number: [30/4518] 0% | Training loss: 0.7099948783715566
Epoch: 65 | Iteration number: [40/4518] 0% | Training loss: 0.703972551226616
Epoch: 65 | Iteration number: [50/4518] 1% | Training loss: 0.7006419849395752
Epoch: 65 | Iteration number: [60/4518] 1% | Training loss: 0.6984531193971634
Epoch: 65 | Iteration number: [70/4518] 1% | Training loss: 0.6966320548738753
Epoch: 65 | Iteration number: [80/4518] 1% | Training loss: 0.6954343877732754
Epoch: 65 | Iteration number: [90/4518] 1% | Training loss: 0.6944951567384932
Epoch: 65 | Iteration number: [100/4518] 2% | Training loss: 0.6937198388576508
Epoch: 65 | Iteration number: [110/4518] 2% | Training loss: 0.693099381165071
Epoch: 65 | Iteration number: [120/4518] 2% | Training loss: 0.6925659467776616
Epoch: 65 | Iteration number: [130/4518] 2% | Training loss: 0.6921602473809169
Epoch: 65 | Iteration number: [140/4518] 3% | Training loss: 0.6917968026229313
Epoch: 65 | Iteration number: [150/4518] 3% | Training loss: 0.6914088825384775
Epoch: 65 | Iteration number: [160/4518] 3% | Training loss: 0.6911339089274406
Epoch: 65 | Iteration number: [170/4518] 3% | Training loss: 0.6908149877015282
Epoch: 65 | Iteration number: [180/4518] 3% | Training loss: 0.690639681617419
Epoch: 65 | Iteration number: [190/4518] 4% | Training loss: 0.6904587137071709
Epoch: 65 | Iteration number: [200/4518] 4% | Training loss: 0.6903297933936119
Epoch: 65 | Iteration number: [210/4518] 4% | Training loss: 0.6902029204936254
Epoch: 65 | Iteration number: [220/4518] 4% | Training loss: 0.6900717491453344
Epoch: 65 | Iteration number: [230/4518] 5% | Training loss: 0.6898962518443232
Epoch: 65 | Iteration number: [240/4518] 5% | Training loss: 0.6898305011292298
Epoch: 65 | Iteration number: [250/4518] 5% | Training loss: 0.6896655871868134
Epoch: 65 | Iteration number: [260/4518] 5% | Training loss: 0.6895591071018806
Epoch: 65 | Iteration number: [270/4518] 5% | Training loss: 0.6894521688973462
Epoch: 65 | Iteration number: [280/4518] 6% | Training loss: 0.689342796589647
Epoch: 65 | Iteration number: [290/4518] 6% | Training loss: 0.6892488087045735
Epoch: 65 | Iteration number: [300/4518] 6% | Training loss: 0.6892091755072276
Epoch: 65 | Iteration number: [310/4518] 6% | Training loss: 0.6891236699396565
Epoch: 65 | Iteration number: [320/4518] 7% | Training loss: 0.6890817262232304
Epoch: 65 | Iteration number: [330/4518] 7% | Training loss: 0.6890156810933893
Epoch: 65 | Iteration number: [340/4518] 7% | Training loss: 0.6889123609837364
Epoch: 65 | Iteration number: [350/4518] 7% | Training loss: 0.6888793005262103
Epoch: 65 | Iteration number: [360/4518] 7% | Training loss: 0.6888627933131324
Epoch: 65 | Iteration number: [370/4518] 8% | Training loss: 0.688833687595419
Epoch: 65 | Iteration number: [380/4518] 8% | Training loss: 0.6887960391609292
Epoch: 65 | Iteration number: [390/4518] 8% | Training loss: 0.6887805989155402
Epoch: 65 | Iteration number: [400/4518] 8% | Training loss: 0.6887426450848579
Epoch: 65 | Iteration number: [410/4518] 9% | Training loss: 0.6887002667275871
Epoch: 65 | Iteration number: [420/4518] 9% | Training loss: 0.6886798214344751
Epoch: 65 | Iteration number: [430/4518] 9% | Training loss: 0.6886309457379718
Epoch: 65 | Iteration number: [440/4518] 9% | Training loss: 0.6886172232302752
Epoch: 65 | Iteration number: [450/4518] 9% | Training loss: 0.6885726194911533
Epoch: 65 | Iteration number: [460/4518] 10% | Training loss: 0.6885656771452531
Epoch: 65 | Iteration number: [470/4518] 10% | Training loss: 0.68851914228277
Epoch: 65 | Iteration number: [480/4518] 10% | Training loss: 0.6885081325968107
Epoch: 65 | Iteration number: [490/4518] 10% | Training loss: 0.6884756922721863
Epoch: 65 | Iteration number: [500/4518] 11% | Training loss: 0.6884640561342239
Epoch: 65 | Iteration number: [510/4518] 11% | Training loss: 0.6884219649960013
Epoch: 65 | Iteration number: [520/4518] 11% | Training loss: 0.6883916185452388
Epoch: 65 | Iteration number: [530/4518] 11% | Training loss: 0.6883567323099892
Epoch: 65 | Iteration number: [540/4518] 11% | Training loss: 0.6883200888280515
Epoch: 65 | Iteration number: [550/4518] 12% | Training loss: 0.6882788905230436
Epoch: 65 | Iteration number: [560/4518] 12% | Training loss: 0.688247906097344
Epoch: 65 | Iteration number: [570/4518] 12% | Training loss: 0.6882246242280592
Epoch: 65 | Iteration number: [580/4518] 12% | Training loss: 0.6882322728633881
Epoch: 65 | Iteration number: [590/4518] 13% | Training loss: 0.6882175796112772
Epoch: 65 | Iteration number: [600/4518] 13% | Training loss: 0.6881898305813472
Epoch: 65 | Iteration number: [610/4518] 13% | Training loss: 0.6881680790518151
Epoch: 65 | Iteration number: [620/4518] 13% | Training loss: 0.6881390675421684
Epoch: 65 | Iteration number: [630/4518] 13% | Training loss: 0.6881274921553475
Epoch: 65 | Iteration number: [640/4518] 14% | Training loss: 0.6880883696489036
Epoch: 65 | Iteration number: [650/4518] 14% | Training loss: 0.6880766015786391
Epoch: 65 | Iteration number: [660/4518] 14% | Training loss: 0.6880444100408843
Epoch: 65 | Iteration number: [670/4518] 14% | Training loss: 0.6880318997511223
Epoch: 65 | Iteration number: [680/4518] 15% | Training loss: 0.6880180338726324
Epoch: 65 | Iteration number: [690/4518] 15% | Training loss: 0.6879931991514953
Epoch: 65 | Iteration number: [700/4518] 15% | Training loss: 0.6879731896093914
Epoch: 65 | Iteration number: [710/4518] 15% | Training loss: 0.6879636542058327
Epoch: 65 | Iteration number: [720/4518] 15% | Training loss: 0.6879625687168704
Epoch: 65 | Iteration number: [730/4518] 16% | Training loss: 0.6879530290218249
Epoch: 65 | Iteration number: [740/4518] 16% | Training loss: 0.687920392767803
Epoch: 65 | Iteration number: [750/4518] 16% | Training loss: 0.687912947177887
Epoch: 65 | Iteration number: [760/4518] 16% | Training loss: 0.6879039451479911
Epoch: 65 | Iteration number: [770/4518] 17% | Training loss: 0.6878675739486496
Epoch: 65 | Iteration number: [780/4518] 17% | Training loss: 0.6878687670597663
Epoch: 65 | Iteration number: [790/4518] 17% | Training loss: 0.6878639304185216
Epoch: 65 | Iteration number: [800/4518] 17% | Training loss: 0.6878702139109373
Epoch: 65 | Iteration number: [810/4518] 17% | Training loss: 0.687864202776073
Epoch: 65 | Iteration number: [820/4518] 18% | Training loss: 0.6878571691309533
Epoch: 65 | Iteration number: [830/4518] 18% | Training loss: 0.6878402338688632
Epoch: 65 | Iteration number: [840/4518] 18% | Training loss: 0.6878341866391046
Epoch: 65 | Iteration number: [850/4518] 18% | Training loss: 0.6878132430244894
Epoch: 65 | Iteration number: [860/4518] 19% | Training loss: 0.6878042587014132
Epoch: 65 | Iteration number: [870/4518] 19% | Training loss: 0.6877841291071355
Epoch: 65 | Iteration number: [880/4518] 19% | Training loss: 0.6877666035159068
Epoch: 65 | Iteration number: [890/4518] 19% | Training loss: 0.6877679250213538
Epoch: 65 | Iteration number: [900/4518] 19% | Training loss: 0.687754003405571
Epoch: 65 | Iteration number: [910/4518] 20% | Training loss: 0.6877453147710024
Epoch: 65 | Iteration number: [920/4518] 20% | Training loss: 0.6877409686212954
Epoch: 65 | Iteration number: [930/4518] 20% | Training loss: 0.687732026077086
Epoch: 65 | Iteration number: [940/4518] 20% | Training loss: 0.6877146219319485
Epoch: 65 | Iteration number: [950/4518] 21% | Training loss: 0.6877153579812301
Epoch: 65 | Iteration number: [960/4518] 21% | Training loss: 0.6877068599686027
Epoch: 65 | Iteration number: [970/4518] 21% | Training loss: 0.6876957174428959
Epoch: 65 | Iteration number: [980/4518] 21% | Training loss: 0.6876809092808743
Epoch: 65 | Iteration number: [990/4518] 21% | Training loss: 0.6876712061540045
Epoch: 65 | Iteration number: [1000/4518] 22% | Training loss: 0.6876596992611885
Epoch: 65 | Iteration number: [1010/4518] 22% | Training loss: 0.6876512095479682
Epoch: 65 | Iteration number: [1020/4518] 22% | Training loss: 0.6876411045298857
Epoch: 65 | Iteration number: [1030/4518] 22% | Training loss: 0.6876350891242907
Epoch: 65 | Iteration number: [1040/4518] 23% | Training loss: 0.687627754188501
Epoch: 65 | Iteration number: [1050/4518] 23% | Training loss: 0.6876078352474031
Epoch: 65 | Iteration number: [1060/4518] 23% | Training loss: 0.6875987298646064
Epoch: 65 | Iteration number: [1070/4518] 23% | Training loss: 0.6875909418146187
Epoch: 65 | Iteration number: [1080/4518] 23% | Training loss: 0.6875877595058194
Epoch: 65 | Iteration number: [1090/4518] 24% | Training loss: 0.6875793622721226
Epoch: 65 | Iteration number: [1100/4518] 24% | Training loss: 0.6875733643228358
Epoch: 65 | Iteration number: [1110/4518] 24% | Training loss: 0.687566326759957
Epoch: 65 | Iteration number: [1120/4518] 24% | Training loss: 0.6875696545732873
Epoch: 65 | Iteration number: [1130/4518] 25% | Training loss: 0.6875638499724126
Epoch: 65 | Iteration number: [1140/4518] 25% | Training loss: 0.6875538763769886
Epoch: 65 | Iteration number: [1150/4518] 25% | Training loss: 0.6875432006172512
Epoch: 65 | Iteration number: [1160/4518] 25% | Training loss: 0.6875305287796876
Epoch: 65 | Iteration number: [1170/4518] 25% | Training loss: 0.6875290636323456
Epoch: 65 | Iteration number: [1180/4518] 26% | Training loss: 0.687526622919713
Epoch: 65 | Iteration number: [1190/4518] 26% | Training loss: 0.6875300739492689
Epoch: 65 | Iteration number: [1200/4518] 26% | Training loss: 0.6875238956014316
Epoch: 65 | Iteration number: [1210/4518] 26% | Training loss: 0.6875142065454121
Epoch: 65 | Iteration number: [1220/4518] 27% | Training loss: 0.6875065361378623
Epoch: 65 | Iteration number: [1230/4518] 27% | Training loss: 0.6874926811795894
Epoch: 65 | Iteration number: [1240/4518] 27% | Training loss: 0.6874836769315504
Epoch: 65 | Iteration number: [1250/4518] 27% | Training loss: 0.6874770995140076
Epoch: 65 | Iteration number: [1260/4518] 27% | Training loss: 0.6874742423731183
Epoch: 65 | Iteration number: [1270/4518] 28% | Training loss: 0.6874700215857799
Epoch: 65 | Iteration number: [1280/4518] 28% | Training loss: 0.6874667894095182
Epoch: 65 | Iteration number: [1290/4518] 28% | Training loss: 0.6874539699203284
Epoch: 65 | Iteration number: [1300/4518] 28% | Training loss: 0.6874548921218285
Epoch: 65 | Iteration number: [1310/4518] 28% | Training loss: 0.6874557617511458
Epoch: 65 | Iteration number: [1320/4518] 29% | Training loss: 0.6874597954930681
Epoch: 65 | Iteration number: [1330/4518] 29% | Training loss: 0.6874505193161785
Epoch: 65 | Iteration number: [1340/4518] 29% | Training loss: 0.6874449330924163
Epoch: 65 | Iteration number: [1350/4518] 29% | Training loss: 0.6874382971834253
Epoch: 65 | Iteration number: [1360/4518] 30% | Training loss: 0.6874331824481488
Epoch: 65 | Iteration number: [1370/4518] 30% | Training loss: 0.6874304328086602
Epoch: 65 | Iteration number: [1380/4518] 30% | Training loss: 0.6874326184607934
Epoch: 65 | Iteration number: [1390/4518] 30% | Training loss: 0.6874322179838908
Epoch: 65 | Iteration number: [1400/4518] 30% | Training loss: 0.6874143543413708
Epoch: 65 | Iteration number: [1410/4518] 31% | Training loss: 0.6874105536345895
Epoch: 65 | Iteration number: [1420/4518] 31% | Training loss: 0.6874155791712478
Epoch: 65 | Iteration number: [1430/4518] 31% | Training loss: 0.687408590650225
Epoch: 65 | Iteration number: [1440/4518] 31% | Training loss: 0.6873997354673015
Epoch: 65 | Iteration number: [1450/4518] 32% | Training loss: 0.6873925108334114
Epoch: 65 | Iteration number: [1460/4518] 32% | Training loss: 0.6873901319422134
Epoch: 65 | Iteration number: [1470/4518] 32% | Training loss: 0.687373989252817
Epoch: 65 | Iteration number: [1480/4518] 32% | Training loss: 0.6873733868470063
Epoch: 65 | Iteration number: [1490/4518] 32% | Training loss: 0.6873792727521602
Epoch: 65 | Iteration number: [1500/4518] 33% | Training loss: 0.6873793897628784
Epoch: 65 | Iteration number: [1510/4518] 33% | Training loss: 0.6873817183324044
Epoch: 65 | Iteration number: [1520/4518] 33% | Training loss: 0.6873738759442379
Epoch: 65 | Iteration number: [1530/4518] 33% | Training loss: 0.6873677094387852
Epoch: 65 | Iteration number: [1540/4518] 34% | Training loss: 0.6873621921260635
Epoch: 65 | Iteration number: [1550/4518] 34% | Training loss: 0.6873616421222687
Epoch: 65 | Iteration number: [1560/4518] 34% | Training loss: 0.6873571044359452
Epoch: 65 | Iteration number: [1570/4518] 34% | Training loss: 0.6873513708448714
Epoch: 65 | Iteration number: [1580/4518] 34% | Training loss: 0.6873396739929537
Epoch: 65 | Iteration number: [1590/4518] 35% | Training loss: 0.6873371969603892
Epoch: 65 | Iteration number: [1600/4518] 35% | Training loss: 0.6873322224989533
Epoch: 65 | Iteration number: [1610/4518] 35% | Training loss: 0.6873227342315342
Epoch: 65 | Iteration number: [1620/4518] 35% | Training loss: 0.687310955259535
Epoch: 65 | Iteration number: [1630/4518] 36% | Training loss: 0.6873076767643537
Epoch: 65 | Iteration number: [1640/4518] 36% | Training loss: 0.6873064606654935
Epoch: 65 | Iteration number: [1650/4518] 36% | Training loss: 0.6873007115450772
Epoch: 65 | Iteration number: [1660/4518] 36% | Training loss: 0.6872932889734406
Epoch: 65 | Iteration number: [1670/4518] 36% | Training loss: 0.6872805696761537
Epoch: 65 | Iteration number: [1680/4518] 37% | Training loss: 0.687275998649143
Epoch: 65 | Iteration number: [1690/4518] 37% | Training loss: 0.6872742462087665
Epoch: 65 | Iteration number: [1700/4518] 37% | Training loss: 0.6872676970327601
Epoch: 65 | Iteration number: [1710/4518] 37% | Training loss: 0.6872686423753437
Epoch: 65 | Iteration number: [1720/4518] 38% | Training loss: 0.6872684060487636
Epoch: 65 | Iteration number: [1730/4518] 38% | Training loss: 0.6872634774343127
Epoch: 65 | Iteration number: [1740/4518] 38% | Training loss: 0.6872536398213486
Epoch: 65 | Iteration number: [1750/4518] 38% | Training loss: 0.6872464838368552
Epoch: 65 | Iteration number: [1760/4518] 38% | Training loss: 0.6872474507852034
Epoch: 65 | Iteration number: [1770/4518] 39% | Training loss: 0.6872476155138285
Epoch: 65 | Iteration number: [1780/4518] 39% | Training loss: 0.6872478825322698
Epoch: 65 | Iteration number: [1790/4518] 39% | Training loss: 0.6872476019672842
Epoch: 65 | Iteration number: [1800/4518] 39% | Training loss: 0.6872456049919129
Epoch: 65 | Iteration number: [1810/4518] 40% | Training loss: 0.6872478844711135
Epoch: 65 | Iteration number: [1820/4518] 40% | Training loss: 0.6872448565868231
Epoch: 65 | Iteration number: [1830/4518] 40% | Training loss: 0.687238818341917
Epoch: 65 | Iteration number: [1840/4518] 40% | Training loss: 0.6872309388349885
Epoch: 65 | Iteration number: [1850/4518] 40% | Training loss: 0.687235006190635
Epoch: 65 | Iteration number: [1860/4518] 41% | Training loss: 0.6872345848109133
Epoch: 65 | Iteration number: [1870/4518] 41% | Training loss: 0.6872346024780988
Epoch: 65 | Iteration number: [1880/4518] 41% | Training loss: 0.6872305063808218
Epoch: 65 | Iteration number: [1890/4518] 41% | Training loss: 0.6872336578747583
Epoch: 65 | Iteration number: [1900/4518] 42% | Training loss: 0.687230115564246
Epoch: 65 | Iteration number: [1910/4518] 42% | Training loss: 0.687225397937585
Epoch: 65 | Iteration number: [1920/4518] 42% | Training loss: 0.6872265593148768
Epoch: 65 | Iteration number: [1930/4518] 42% | Training loss: 0.6872168145031509
Epoch: 65 | Iteration number: [1940/4518] 42% | Training loss: 0.6872106297421701
Epoch: 65 | Iteration number: [1950/4518] 43% | Training loss: 0.687207673176741
Epoch: 65 | Iteration number: [1960/4518] 43% | Training loss: 0.6872040404957168
Epoch: 65 | Iteration number: [1970/4518] 43% | Training loss: 0.6871945620793376
Epoch: 65 | Iteration number: [1980/4518] 43% | Training loss: 0.6871888902452257
Epoch: 65 | Iteration number: [1990/4518] 44% | Training loss: 0.6871875665295664
Epoch: 65 | Iteration number: [2000/4518] 44% | Training loss: 0.6871876464486122
Epoch: 65 | Iteration number: [2010/4518] 44% | Training loss: 0.6871774800084717
Epoch: 65 | Iteration number: [2020/4518] 44% | Training loss: 0.6871769584936671
Epoch: 65 | Iteration number: [2030/4518] 44% | Training loss: 0.6871713478283342
Epoch: 65 | Iteration number: [2040/4518] 45% | Training loss: 0.6871585591166627
Epoch: 65 | Iteration number: [2050/4518] 45% | Training loss: 0.6871573147831893
Epoch: 65 | Iteration number: [2060/4518] 45% | Training loss: 0.6871543145295486
Epoch: 65 | Iteration number: [2070/4518] 45% | Training loss: 0.6871537282846976
Epoch: 65 | Iteration number: [2080/4518] 46% | Training loss: 0.6871535221831157
Epoch: 65 | Iteration number: [2090/4518] 46% | Training loss: 0.6871502177281813
Epoch: 65 | Iteration number: [2100/4518] 46% | Training loss: 0.6871516133773895
Epoch: 65 | Iteration number: [2110/4518] 46% | Training loss: 0.6871484787825725
Epoch: 65 | Iteration number: [2120/4518] 46% | Training loss: 0.6871493341225499
Epoch: 65 | Iteration number: [2130/4518] 47% | Training loss: 0.6871468786622437
Epoch: 65 | Iteration number: [2140/4518] 47% | Training loss: 0.6871449095902041
Epoch: 65 | Iteration number: [2150/4518] 47% | Training loss: 0.687140596744626
Epoch: 65 | Iteration number: [2160/4518] 47% | Training loss: 0.6871433627274302
Epoch: 65 | Iteration number: [2170/4518] 48% | Training loss: 0.6871467958672255
Epoch: 65 | Iteration number: [2180/4518] 48% | Training loss: 0.6871447284287269
Epoch: 65 | Iteration number: [2190/4518] 48% | Training loss: 0.6871412247555441
Epoch: 65 | Iteration number: [2200/4518] 48% | Training loss: 0.6871423058347269
Epoch: 65 | Iteration number: [2210/4518] 48% | Training loss: 0.6871338375822991
Epoch: 65 | Iteration number: [2220/4518] 49% | Training loss: 0.6871310226015143
Epoch: 65 | Iteration number: [2230/4518] 49% | Training loss: 0.6871238400316024
Epoch: 65 | Iteration number: [2240/4518] 49% | Training loss: 0.6871314944965499
Epoch: 65 | Iteration number: [2250/4518] 49% | Training loss: 0.6871326398319668
Epoch: 65 | Iteration number: [2260/4518] 50% | Training loss: 0.6871261426569086
Epoch: 65 | Iteration number: [2270/4518] 50% | Training loss: 0.6871272162981495
Epoch: 65 | Iteration number: [2280/4518] 50% | Training loss: 0.6871266035134332
Epoch: 65 | Iteration number: [2290/4518] 50% | Training loss: 0.6871256540956455
Epoch: 65 | Iteration number: [2300/4518] 50% | Training loss: 0.6871188011635905
Epoch: 65 | Iteration number: [2310/4518] 51% | Training loss: 0.6871162241929537
Epoch: 65 | Iteration number: [2320/4518] 51% | Training loss: 0.6871127792473497
Epoch: 65 | Iteration number: [2330/4518] 51% | Training loss: 0.6871113661276936
Epoch: 65 | Iteration number: [2340/4518] 51% | Training loss: 0.6871091118480406
Epoch: 65 | Iteration number: [2350/4518] 52% | Training loss: 0.6871068395452297
Epoch: 65 | Iteration number: [2360/4518] 52% | Training loss: 0.6871058336253894
Epoch: 65 | Iteration number: [2370/4518] 52% | Training loss: 0.6871072592614572
Epoch: 65 | Iteration number: [2380/4518] 52% | Training loss: 0.6871051183768682
Epoch: 65 | Iteration number: [2390/4518] 52% | Training loss: 0.6871047991838415
Epoch: 65 | Iteration number: [2400/4518] 53% | Training loss: 0.6871045229087274
Epoch: 65 | Iteration number: [2410/4518] 53% | Training loss: 0.6870959024211678
Epoch: 65 | Iteration number: [2420/4518] 53% | Training loss: 0.6870941878596614
Epoch: 65 | Iteration number: [2430/4518] 53% | Training loss: 0.687090290672004
Epoch: 65 | Iteration number: [2440/4518] 54% | Training loss: 0.6870884101654663
Epoch: 65 | Iteration number: [2450/4518] 54% | Training loss: 0.6870843472529431
Epoch: 65 | Iteration number: [2460/4518] 54% | Training loss: 0.6870832991793873
Epoch: 65 | Iteration number: [2470/4518] 54% | Training loss: 0.6870776350922913
Epoch: 65 | Iteration number: [2480/4518] 54% | Training loss: 0.6870735923128743
Epoch: 65 | Iteration number: [2490/4518] 55% | Training loss: 0.6870633006574638
Epoch: 65 | Iteration number: [2500/4518] 55% | Training loss: 0.6870643704652786
Epoch: 65 | Iteration number: [2510/4518] 55% | Training loss: 0.6870631694081295
Epoch: 65 | Iteration number: [2520/4518] 55% | Training loss: 0.6870643488471471
Epoch: 65 | Iteration number: [2530/4518] 55% | Training loss: 0.6870628966173165
Epoch: 65 | Iteration number: [2540/4518] 56% | Training loss: 0.6870615156616752
Epoch: 65 | Iteration number: [2550/4518] 56% | Training loss: 0.687061705308802
Epoch: 65 | Iteration number: [2560/4518] 56% | Training loss: 0.6870555626461282
Epoch: 65 | Iteration number: [2570/4518] 56% | Training loss: 0.6870517516878328
Epoch: 65 | Iteration number: [2580/4518] 57% | Training loss: 0.6870497647181962
Epoch: 65 | Iteration number: [2590/4518] 57% | Training loss: 0.6870451646421867
Epoch: 65 | Iteration number: [2600/4518] 57% | Training loss: 0.6870466374204709
Epoch: 65 | Iteration number: [2610/4518] 57% | Training loss: 0.687049169627186
Epoch: 65 | Iteration number: [2620/4518] 57% | Training loss: 0.6870422663124462
Epoch: 65 | Iteration number: [2630/4518] 58% | Training loss: 0.6870432832395169
Epoch: 65 | Iteration number: [2640/4518] 58% | Training loss: 0.6870455290783536
Epoch: 65 | Iteration number: [2650/4518] 58% | Training loss: 0.6870434562665112
Epoch: 65 | Iteration number: [2660/4518] 58% | Training loss: 0.6870428029531823
Epoch: 65 | Iteration number: [2670/4518] 59% | Training loss: 0.6870390030775178
Epoch: 65 | Iteration number: [2680/4518] 59% | Training loss: 0.6870449060601974
Epoch: 65 | Iteration number: [2690/4518] 59% | Training loss: 0.6870424665704535
Epoch: 65 | Iteration number: [2700/4518] 59% | Training loss: 0.6870374082415193
Epoch: 65 | Iteration number: [2710/4518] 59% | Training loss: 0.6870373644512078
Epoch: 65 | Iteration number: [2720/4518] 60% | Training loss: 0.6870367459076292
Epoch: 65 | Iteration number: [2730/4518] 60% | Training loss: 0.6870395467176542
Epoch: 65 | Iteration number: [2740/4518] 60% | Training loss: 0.6870388838061451
Epoch: 65 | Iteration number: [2750/4518] 60% | Training loss: 0.6870371821143411
Epoch: 65 | Iteration number: [2760/4518] 61% | Training loss: 0.6870351665045904
Epoch: 65 | Iteration number: [2770/4518] 61% | Training loss: 0.6870291340221997
Epoch: 65 | Iteration number: [2780/4518] 61% | Training loss: 0.6870285493006809
Epoch: 65 | Iteration number: [2790/4518] 61% | Training loss: 0.6870312771275907
Epoch: 65 | Iteration number: [2800/4518] 61% | Training loss: 0.6870302887686661
Epoch: 65 | Iteration number: [2810/4518] 62% | Training loss: 0.6870318694683156
Epoch: 65 | Iteration number: [2820/4518] 62% | Training loss: 0.6870342321429692
Epoch: 65 | Iteration number: [2830/4518] 62% | Training loss: 0.6870351318967637
Epoch: 65 | Iteration number: [2840/4518] 62% | Training loss: 0.6870336740999154
Epoch: 65 | Iteration number: [2850/4518] 63% | Training loss: 0.6870345216884948
Epoch: 65 | Iteration number: [2860/4518] 63% | Training loss: 0.6870329820401185
Epoch: 65 | Iteration number: [2870/4518] 63% | Training loss: 0.6870364323102639
Epoch: 65 | Iteration number: [2880/4518] 63% | Training loss: 0.6870360171629323
Epoch: 65 | Iteration number: [2890/4518] 63% | Training loss: 0.6870397891759047
Epoch: 65 | Iteration number: [2900/4518] 64% | Training loss: 0.6870406123070881
Epoch: 65 | Iteration number: [2910/4518] 64% | Training loss: 0.687040292704638
Epoch: 65 | Iteration number: [2920/4518] 64% | Training loss: 0.6870360393842606
Epoch: 65 | Iteration number: [2930/4518] 64% | Training loss: 0.6870379615562361
Epoch: 65 | Iteration number: [2940/4518] 65% | Training loss: 0.6870348710794838
Epoch: 65 | Iteration number: [2950/4518] 65% | Training loss: 0.6870347525305667
Epoch: 65 | Iteration number: [2960/4518] 65% | Training loss: 0.6870380552032509
Epoch: 65 | Iteration number: [2970/4518] 65% | Training loss: 0.6870347217076556
Epoch: 65 | Iteration number: [2980/4518] 65% | Training loss: 0.6870293908671244
Epoch: 65 | Iteration number: [2990/4518] 66% | Training loss: 0.6870287884836611
Epoch: 65 | Iteration number: [3000/4518] 66% | Training loss: 0.687028584142526
Epoch: 65 | Iteration number: [3010/4518] 66% | Training loss: 0.6870237971263075
Epoch: 65 | Iteration number: [3020/4518] 66% | Training loss: 0.68702395043231
Epoch: 65 | Iteration number: [3030/4518] 67% | Training loss: 0.687024974232853
Epoch: 65 | Iteration number: [3040/4518] 67% | Training loss: 0.6870256614724272
Epoch: 65 | Iteration number: [3050/4518] 67% | Training loss: 0.6870218213464393
Epoch: 65 | Iteration number: [3060/4518] 67% | Training loss: 0.6870214929767683
Epoch: 65 | Iteration number: [3070/4518] 67% | Training loss: 0.6870191527694367
Epoch: 65 | Iteration number: [3080/4518] 68% | Training loss: 0.6870149661581237
Epoch: 65 | Iteration number: [3090/4518] 68% | Training loss: 0.6870185010641524
Epoch: 65 | Iteration number: [3100/4518] 68% | Training loss: 0.6870193096130125
Epoch: 65 | Iteration number: [3110/4518] 68% | Training loss: 0.6870139443989352
Epoch: 65 | Iteration number: [3120/4518] 69% | Training loss: 0.6870164969601692
Epoch: 65 | Iteration number: [3130/4518] 69% | Training loss: 0.6870139817841137
Epoch: 65 | Iteration number: [3140/4518] 69% | Training loss: 0.6870136881140387
Epoch: 65 | Iteration number: [3150/4518] 69% | Training loss: 0.6870111055222768
Epoch: 65 | Iteration number: [3160/4518] 69% | Training loss: 0.6870140234314943
Epoch: 65 | Iteration number: [3170/4518] 70% | Training loss: 0.6870110200970707
Epoch: 65 | Iteration number: [3180/4518] 70% | Training loss: 0.6870071607378294
Epoch: 65 | Iteration number: [3190/4518] 70% | Training loss: 0.6870099494449771
Epoch: 65 | Iteration number: [3200/4518] 70% | Training loss: 0.687007171139121
Epoch: 65 | Iteration number: [3210/4518] 71% | Training loss: 0.6870041367606582
Epoch: 65 | Iteration number: [3220/4518] 71% | Training loss: 0.6870055879680266
Epoch: 65 | Iteration number: [3230/4518] 71% | Training loss: 0.6870101824448943
Epoch: 65 | Iteration number: [3240/4518] 71% | Training loss: 0.6870099103561154
Epoch: 65 | Iteration number: [3250/4518] 71% | Training loss: 0.6870104210743537
Epoch: 65 | Iteration number: [3260/4518] 72% | Training loss: 0.6870082414223373
Epoch: 65 | Iteration number: [3270/4518] 72% | Training loss: 0.6870072598304223
Epoch: 65 | Iteration number: [3280/4518] 72% | Training loss: 0.6870059046803452
Epoch: 65 | Iteration number: [3290/4518] 72% | Training loss: 0.6870040473242299
Epoch: 65 | Iteration number: [3300/4518] 73% | Training loss: 0.687003464066621
Epoch: 65 | Iteration number: [3310/4518] 73% | Training loss: 0.6870079990240022
Epoch: 65 | Iteration number: [3320/4518] 73% | Training loss: 0.6870055567607822
Epoch: 65 | Iteration number: [3330/4518] 73% | Training loss: 0.6870027422725975
Epoch: 65 | Iteration number: [3340/4518] 73% | Training loss: 0.6870007366834286
Epoch: 65 | Iteration number: [3350/4518] 74% | Training loss: 0.6870008299066059
Epoch: 65 | Iteration number: [3360/4518] 74% | Training loss: 0.6869982689973854
Epoch: 65 | Iteration number: [3370/4518] 74% | Training loss: 0.6870012262631595
Epoch: 65 | Iteration number: [3380/4518] 74% | Training loss: 0.6869977194882003
Epoch: 65 | Iteration number: [3390/4518] 75% | Training loss: 0.6869949430491017
Epoch: 65 | Iteration number: [3400/4518] 75% | Training loss: 0.6869973676870851
Epoch: 65 | Iteration number: [3410/4518] 75% | Training loss: 0.6869960902723049
Epoch: 65 | Iteration number: [3420/4518] 75% | Training loss: 0.6869949570176197
Epoch: 65 | Iteration number: [3430/4518] 75% | Training loss: 0.686991481044202
Epoch: 65 | Iteration number: [3440/4518] 76% | Training loss: 0.6869912053783273
Epoch: 65 | Iteration number: [3450/4518] 76% | Training loss: 0.6869952086780382
Epoch: 65 | Iteration number: [3460/4518] 76% | Training loss: 0.6869943590350234
Epoch: 65 | Iteration number: [3470/4518] 76% | Training loss: 0.6869977454458945
Epoch: 65 | Iteration number: [3480/4518] 77% | Training loss: 0.6869938570877602
Epoch: 65 | Iteration number: [3490/4518] 77% | Training loss: 0.6869904889247479
Epoch: 65 | Iteration number: [3500/4518] 77% | Training loss: 0.6869918458291463
Epoch: 65 | Iteration number: [3510/4518] 77% | Training loss: 0.6869899853512093
Epoch: 65 | Iteration number: [3520/4518] 77% | Training loss: 0.6869941861961376
Epoch: 65 | Iteration number: [3530/4518] 78% | Training loss: 0.6869944914711096
Epoch: 65 | Iteration number: [3540/4518] 78% | Training loss: 0.6869950656331865
Epoch: 65 | Iteration number: [3550/4518] 78% | Training loss: 0.6869937669727164
Epoch: 65 | Iteration number: [3560/4518] 78% | Training loss: 0.6869912128602521
Epoch: 65 | Iteration number: [3570/4518] 79% | Training loss: 0.6869906081705868
Epoch: 65 | Iteration number: [3580/4518] 79% | Training loss: 0.6869889184249846
Epoch: 65 | Iteration number: [3590/4518] 79% | Training loss: 0.6869919202121851
Epoch: 65 | Iteration number: [3600/4518] 79% | Training loss: 0.6869939445290301
Epoch: 65 | Iteration number: [3610/4518] 79% | Training loss: 0.6869940171776716
Epoch: 65 | Iteration number: [3620/4518] 80% | Training loss: 0.6869970211337284
Epoch: 65 | Iteration number: [3630/4518] 80% | Training loss: 0.6869951769668537
Epoch: 65 | Iteration number: [3640/4518] 80% | Training loss: 0.686996591942651
Epoch: 65 | Iteration number: [3650/4518] 80% | Training loss: 0.6869931716461705
Epoch: 65 | Iteration number: [3660/4518] 81% | Training loss: 0.68698926266751
Epoch: 65 | Iteration number: [3670/4518] 81% | Training loss: 0.6869834483319472
Epoch: 65 | Iteration number: [3680/4518] 81% | Training loss: 0.6869842057804698
Epoch: 65 | Iteration number: [3690/4518] 81% | Training loss: 0.6869843823961449
Epoch: 65 | Iteration number: [3700/4518] 81% | Training loss: 0.6869839365095706
Epoch: 65 | Iteration number: [3710/4518] 82% | Training loss: 0.6869856163819202
Epoch: 65 | Iteration number: [3720/4518] 82% | Training loss: 0.6869848080860671
Epoch: 65 | Iteration number: [3730/4518] 82% | Training loss: 0.6869849088044971
Epoch: 65 | Iteration number: [3740/4518] 82% | Training loss: 0.6869824351473925
Epoch: 65 | Iteration number: [3750/4518] 83% | Training loss: 0.6869829976558686
Epoch: 65 | Iteration number: [3760/4518] 83% | Training loss: 0.686979658505384
Epoch: 65 | Iteration number: [3770/4518] 83% | Training loss: 0.6869836823535534
Epoch: 65 | Iteration number: [3780/4518] 83% | Training loss: 0.6869825388546343
Epoch: 65 | Iteration number: [3790/4518] 83% | Training loss: 0.6869828364308088
Epoch: 65 | Iteration number: [3800/4518] 84% | Training loss: 0.6869814841684542
Epoch: 65 | Iteration number: [3810/4518] 84% | Training loss: 0.686978561374459
Epoch: 65 | Iteration number: [3820/4518] 84% | Training loss: 0.6869802685776306
Epoch: 65 | Iteration number: [3830/4518] 84% | Training loss: 0.6869771238562332
Epoch: 65 | Iteration number: [3840/4518] 84% | Training loss: 0.6869759967084974
Epoch: 65 | Iteration number: [3850/4518] 85% | Training loss: 0.6869742657921531
Epoch: 65 | Iteration number: [3860/4518] 85% | Training loss: 0.6869749746019976
Epoch: 65 | Iteration number: [3870/4518] 85% | Training loss: 0.6869719651934404
Epoch: 65 | Iteration number: [3880/4518] 85% | Training loss: 0.6869699304865807
Epoch: 65 | Iteration number: [3890/4518] 86% | Training loss: 0.6869697786542015
Epoch: 65 | Iteration number: [3900/4518] 86% | Training loss: 0.6869713162764525
Epoch: 65 | Iteration number: [3910/4518] 86% | Training loss: 0.6869677126255181
Epoch: 65 | Iteration number: [3920/4518] 86% | Training loss: 0.6869654049222567
Epoch: 65 | Iteration number: [3930/4518] 86% | Training loss: 0.6869665136319081
Epoch: 65 | Iteration number: [3940/4518] 87% | Training loss: 0.6869652372477624
Epoch: 65 | Iteration number: [3950/4518] 87% | Training loss: 0.6869644278061541
Epoch: 65 | Iteration number: [3960/4518] 87% | Training loss: 0.6869626263024831
Epoch: 65 | Iteration number: [3970/4518] 87% | Training loss: 0.6869648714509959
Epoch: 65 | Iteration number: [3980/4518] 88% | Training loss: 0.6869650164591008
Epoch: 65 | Iteration number: [3990/4518] 88% | Training loss: 0.6869640106545355
Epoch: 65 | Iteration number: [4000/4518] 88% | Training loss: 0.6869608227759599
Epoch: 65 | Iteration number: [4010/4518] 88% | Training loss: 0.6869578318256987
Epoch: 65 | Iteration number: [4020/4518] 88% | Training loss: 0.6869551435335358
Epoch: 65 | Iteration number: [4030/4518] 89% | Training loss: 0.6869553096241158
Epoch: 65 | Iteration number: [4040/4518] 89% | Training loss: 0.686955825984478
Epoch: 65 | Iteration number: [4050/4518] 89% | Training loss: 0.6869563545562603
Epoch: 65 | Iteration number: [4060/4518] 89% | Training loss: 0.6869565022990034
Epoch: 65 | Iteration number: [4070/4518] 90% | Training loss: 0.6869540791839581
Epoch: 65 | Iteration number: [4080/4518] 90% | Training loss: 0.6869556685142657
Epoch: 65 | Iteration number: [4090/4518] 90% | Training loss: 0.6869570368222327
Epoch: 65 | Iteration number: [4100/4518] 90% | Training loss: 0.68695918904572
Epoch: 65 | Iteration number: [4110/4518] 90% | Training loss: 0.6869592933759202
Epoch: 65 | Iteration number: [4120/4518] 91% | Training loss: 0.6869589552283287
Epoch: 65 | Iteration number: [4130/4518] 91% | Training loss: 0.6869581821900015
Epoch: 65 | Iteration number: [4140/4518] 91% | Training loss: 0.6869575565131966
Epoch: 65 | Iteration number: [4150/4518] 91% | Training loss: 0.6869546384121998
Epoch: 65 | Iteration number: [4160/4518] 92% | Training loss: 0.686955581806027
Epoch: 65 | Iteration number: [4170/4518] 92% | Training loss: 0.6869562671624785
Epoch: 65 | Iteration number: [4180/4518] 92% | Training loss: 0.6869541749999853
Epoch: 65 | Iteration number: [4190/4518] 92% | Training loss: 0.6869551311671591
Epoch: 65 | Iteration number: [4200/4518] 92% | Training loss: 0.6869590668451219
Epoch: 65 | Iteration number: [4210/4518] 93% | Training loss: 0.6869591171979338
Epoch: 65 | Iteration number: [4220/4518] 93% | Training loss: 0.6869581920416999
Epoch: 65 | Iteration number: [4230/4518] 93% | Training loss: 0.6869577768423879
Epoch: 65 | Iteration number: [4240/4518] 93% | Training loss: 0.6869564749862788
Epoch: 65 | Iteration number: [4250/4518] 94% | Training loss: 0.6869542740513297
Epoch: 65 | Iteration number: [4260/4518] 94% | Training loss: 0.6869551295125988
Epoch: 65 | Iteration number: [4270/4518] 94% | Training loss: 0.6869536225913001
Epoch: 65 | Iteration number: [4280/4518] 94% | Training loss: 0.6869497614764721
Epoch: 65 | Iteration number: [4290/4518] 94% | Training loss: 0.686950326577211
Epoch: 65 | Iteration number: [4300/4518] 95% | Training loss: 0.6869502498382746
Epoch: 65 | Iteration number: [4310/4518] 95% | Training loss: 0.6869558230491912
Epoch: 65 | Iteration number: [4320/4518] 95% | Training loss: 0.6869577958627984
Epoch: 65 | Iteration number: [4330/4518] 95% | Training loss: 0.6869570846645716
Epoch: 65 | Iteration number: [4340/4518] 96% | Training loss: 0.6869582561990633
Epoch: 65 | Iteration number: [4350/4518] 96% | Training loss: 0.6869574582576752
Epoch: 65 | Iteration number: [4360/4518] 96% | Training loss: 0.6869566181247387
Epoch: 65 | Iteration number: [4370/4518] 96% | Training loss: 0.6869531962636952
Epoch: 65 | Iteration number: [4380/4518] 96% | Training loss: 0.6869521472279884
Epoch: 65 | Iteration number: [4390/4518] 97% | Training loss: 0.68695052642214
Epoch: 65 | Iteration number: [4400/4518] 97% | Training loss: 0.6869501687721773
Epoch: 65 | Iteration number: [4410/4518] 97% | Training loss: 0.686948831673382
Epoch: 65 | Iteration number: [4420/4518] 97% | Training loss: 0.6869489327410228
Epoch: 65 | Iteration number: [4430/4518] 98% | Training loss: 0.6869465450670057
Epoch: 65 | Iteration number: [4440/4518] 98% | Training loss: 0.6869470957028974
Epoch: 65 | Iteration number: [4450/4518] 98% | Training loss: 0.6869468595204729
Epoch: 65 | Iteration number: [4460/4518] 98% | Training loss: 0.6869484564247688
Epoch: 65 | Iteration number: [4470/4518] 98% | Training loss: 0.6869454905624091
Epoch: 65 | Iteration number: [4480/4518] 99% | Training loss: 0.6869442260425006
Epoch: 65 | Iteration number: [4490/4518] 99% | Training loss: 0.6869421985340544
Epoch: 65 | Iteration number: [4500/4518] 99% | Training loss: 0.6869403771691852
Epoch: 65 | Iteration number: [4510/4518] 99% | Training loss: 0.6869385190126372

 End of epoch: 65 | Train Loss: 0.6867858530568465 | Training Time: 632 

 End of epoch: 65 | Eval Loss: 0.6897320431105944 | Evaluating Time: 17 
Epoch: 66 | Iteration number: [10/4518] 0% | Training loss: 0.7557497322559357
Epoch: 66 | Iteration number: [20/4518] 0% | Training loss: 0.7213670492172242
Epoch: 66 | Iteration number: [30/4518] 0% | Training loss: 0.7096576889355978
Epoch: 66 | Iteration number: [40/4518] 0% | Training loss: 0.7038571432232856
Epoch: 66 | Iteration number: [50/4518] 1% | Training loss: 0.7004732406139373
Epoch: 66 | Iteration number: [60/4518] 1% | Training loss: 0.6983662158250808
Epoch: 66 | Iteration number: [70/4518] 1% | Training loss: 0.6967999058110373
Epoch: 66 | Iteration number: [80/4518] 1% | Training loss: 0.6953747227787972
Epoch: 66 | Iteration number: [90/4518] 1% | Training loss: 0.6942828317483266
Epoch: 66 | Iteration number: [100/4518] 2% | Training loss: 0.6935878503322601
Epoch: 66 | Iteration number: [110/4518] 2% | Training loss: 0.6929398991844871
Epoch: 66 | Iteration number: [120/4518] 2% | Training loss: 0.6924838269750277
Epoch: 66 | Iteration number: [130/4518] 2% | Training loss: 0.6920717427363763
Epoch: 66 | Iteration number: [140/4518] 3% | Training loss: 0.6917341134377888
Epoch: 66 | Iteration number: [150/4518] 3% | Training loss: 0.6914231292406718
Epoch: 66 | Iteration number: [160/4518] 3% | Training loss: 0.6911819711327553
Epoch: 66 | Iteration number: [170/4518] 3% | Training loss: 0.6909637388061075
Epoch: 66 | Iteration number: [180/4518] 3% | Training loss: 0.690735536482599
Epoch: 66 | Iteration number: [190/4518] 4% | Training loss: 0.6904781523503756
Epoch: 66 | Iteration number: [200/4518] 4% | Training loss: 0.6903387260437012
Epoch: 66 | Iteration number: [210/4518] 4% | Training loss: 0.6901448292391641
Epoch: 66 | Iteration number: [220/4518] 4% | Training loss: 0.689985434033654
Epoch: 66 | Iteration number: [230/4518] 5% | Training loss: 0.6898177890673928
Epoch: 66 | Iteration number: [240/4518] 5% | Training loss: 0.6896769821643829
Epoch: 66 | Iteration number: [250/4518] 5% | Training loss: 0.6895458650588989
Epoch: 66 | Iteration number: [260/4518] 5% | Training loss: 0.6894137416894619
Epoch: 66 | Iteration number: [270/4518] 5% | Training loss: 0.6893208411004809
Epoch: 66 | Iteration number: [280/4518] 6% | Training loss: 0.6892391053693635
Epoch: 66 | Iteration number: [290/4518] 6% | Training loss: 0.6891084705961161
Epoch: 66 | Iteration number: [300/4518] 6% | Training loss: 0.6890047528346379
Epoch: 66 | Iteration number: [310/4518] 6% | Training loss: 0.6889578477028877
Epoch: 66 | Iteration number: [320/4518] 7% | Training loss: 0.6888632211834192
Epoch: 66 | Iteration number: [330/4518] 7% | Training loss: 0.6888058526949449
Epoch: 66 | Iteration number: [340/4518] 7% | Training loss: 0.6887768836582409
Epoch: 66 | Iteration number: [350/4518] 7% | Training loss: 0.6887105572223663
Epoch: 66 | Iteration number: [360/4518] 7% | Training loss: 0.6886947467923165
Epoch: 66 | Iteration number: [370/4518] 8% | Training loss: 0.6886275423539652
Epoch: 66 | Iteration number: [380/4518] 8% | Training loss: 0.68852631543812
Epoch: 66 | Iteration number: [390/4518] 8% | Training loss: 0.6884893814722697
Epoch: 66 | Iteration number: [400/4518] 8% | Training loss: 0.6884316097199917
Epoch: 66 | Iteration number: [410/4518] 9% | Training loss: 0.6884074004685007
Epoch: 66 | Iteration number: [420/4518] 9% | Training loss: 0.6883747327895392
Epoch: 66 | Iteration number: [430/4518] 9% | Training loss: 0.6883545093758162
Epoch: 66 | Iteration number: [440/4518] 9% | Training loss: 0.6883326874537902
Epoch: 66 | Iteration number: [450/4518] 9% | Training loss: 0.6883282089233398
Epoch: 66 | Iteration number: [460/4518] 10% | Training loss: 0.6883101752270823
Epoch: 66 | Iteration number: [470/4518] 10% | Training loss: 0.6882715543533894
Epoch: 66 | Iteration number: [480/4518] 10% | Training loss: 0.6882364162554343
Epoch: 66 | Iteration number: [490/4518] 10% | Training loss: 0.6882059041334658
Epoch: 66 | Iteration number: [500/4518] 11% | Training loss: 0.6881740998029708
Epoch: 66 | Iteration number: [510/4518] 11% | Training loss: 0.6881352934182859
Epoch: 66 | Iteration number: [520/4518] 11% | Training loss: 0.6881237333783736
Epoch: 66 | Iteration number: [530/4518] 11% | Training loss: 0.6880951070560599
Epoch: 66 | Iteration number: [540/4518] 11% | Training loss: 0.688080487759025
Epoch: 66 | Iteration number: [550/4518] 12% | Training loss: 0.6880664084174416
Epoch: 66 | Iteration number: [560/4518] 12% | Training loss: 0.6880552000233106
Epoch: 66 | Iteration number: [570/4518] 12% | Training loss: 0.6880373540677522
Epoch: 66 | Iteration number: [580/4518] 12% | Training loss: 0.6880226550431087
Epoch: 66 | Iteration number: [590/4518] 13% | Training loss: 0.6879906253289368
Epoch: 66 | Iteration number: [600/4518] 13% | Training loss: 0.6879673507809639
Epoch: 66 | Iteration number: [610/4518] 13% | Training loss: 0.6879375390342024
Epoch: 66 | Iteration number: [620/4518] 13% | Training loss: 0.6879137568896817
Epoch: 66 | Iteration number: [630/4518] 13% | Training loss: 0.6878856850994958
Epoch: 66 | Iteration number: [640/4518] 14% | Training loss: 0.6878461956046522
Epoch: 66 | Iteration number: [650/4518] 14% | Training loss: 0.6878262567520141
Epoch: 66 | Iteration number: [660/4518] 14% | Training loss: 0.687809358311422
Epoch: 66 | Iteration number: [670/4518] 14% | Training loss: 0.6877852081362881
Epoch: 66 | Iteration number: [680/4518] 15% | Training loss: 0.687769541933256
Epoch: 66 | Iteration number: [690/4518] 15% | Training loss: 0.6877671582975249
Epoch: 66 | Iteration number: [700/4518] 15% | Training loss: 0.6877635318892342
Epoch: 66 | Iteration number: [710/4518] 15% | Training loss: 0.6877540175343902
Epoch: 66 | Iteration number: [720/4518] 15% | Training loss: 0.6877562157809735
Epoch: 66 | Iteration number: [730/4518] 16% | Training loss: 0.6877401133922681
Epoch: 66 | Iteration number: [740/4518] 16% | Training loss: 0.6877352777365092
Epoch: 66 | Iteration number: [750/4518] 16% | Training loss: 0.6877118355433146
Epoch: 66 | Iteration number: [760/4518] 16% | Training loss: 0.6877013829977889
Epoch: 66 | Iteration number: [770/4518] 17% | Training loss: 0.687687791709776
Epoch: 66 | Iteration number: [780/4518] 17% | Training loss: 0.6876902149273799
Epoch: 66 | Iteration number: [790/4518] 17% | Training loss: 0.6876813259305833
Epoch: 66 | Iteration number: [800/4518] 17% | Training loss: 0.6876888209581375
Epoch: 66 | Iteration number: [810/4518] 17% | Training loss: 0.6876832180553012
Epoch: 66 | Iteration number: [820/4518] 18% | Training loss: 0.6876662582159042
Epoch: 66 | Iteration number: [830/4518] 18% | Training loss: 0.6876700633979705
Epoch: 66 | Iteration number: [840/4518] 18% | Training loss: 0.6876494342372531
Epoch: 66 | Iteration number: [850/4518] 18% | Training loss: 0.6876564161917743
Epoch: 66 | Iteration number: [860/4518] 19% | Training loss: 0.6876547775296278
Epoch: 66 | Iteration number: [870/4518] 19% | Training loss: 0.6876211112258078
Epoch: 66 | Iteration number: [880/4518] 19% | Training loss: 0.6876055537977002
Epoch: 66 | Iteration number: [890/4518] 19% | Training loss: 0.6875980580120944
Epoch: 66 | Iteration number: [900/4518] 19% | Training loss: 0.6875928401947021
Epoch: 66 | Iteration number: [910/4518] 20% | Training loss: 0.687604591348669
Epoch: 66 | Iteration number: [920/4518] 20% | Training loss: 0.687589026922765
Epoch: 66 | Iteration number: [930/4518] 20% | Training loss: 0.6875745065750615
Epoch: 66 | Iteration number: [940/4518] 20% | Training loss: 0.6875758881264544
Epoch: 66 | Iteration number: [950/4518] 21% | Training loss: 0.6875678278897938
Epoch: 66 | Iteration number: [960/4518] 21% | Training loss: 0.6875507960716883
Epoch: 66 | Iteration number: [970/4518] 21% | Training loss: 0.6875337549706095
Epoch: 66 | Iteration number: [980/4518] 21% | Training loss: 0.6875205102015515
Epoch: 66 | Iteration number: [990/4518] 21% | Training loss: 0.6875057438407282
Epoch: 66 | Iteration number: [1000/4518] 22% | Training loss: 0.6875016347765922
Epoch: 66 | Iteration number: [1010/4518] 22% | Training loss: 0.6874992861015962
Epoch: 66 | Iteration number: [1020/4518] 22% | Training loss: 0.6874946217910917
Epoch: 66 | Iteration number: [1030/4518] 22% | Training loss: 0.6874848621562847
Epoch: 66 | Iteration number: [1040/4518] 23% | Training loss: 0.6874694870641598
Epoch: 66 | Iteration number: [1050/4518] 23% | Training loss: 0.6874673370520273
Epoch: 66 | Iteration number: [1060/4518] 23% | Training loss: 0.6874719226135397
Epoch: 66 | Iteration number: [1070/4518] 23% | Training loss: 0.6874652667580364
Epoch: 66 | Iteration number: [1080/4518] 23% | Training loss: 0.6874686853753196
Epoch: 66 | Iteration number: [1090/4518] 24% | Training loss: 0.6874646215810688
Epoch: 66 | Iteration number: [1100/4518] 24% | Training loss: 0.6874508120255037
Epoch: 66 | Iteration number: [1110/4518] 24% | Training loss: 0.6874453010322812
Epoch: 66 | Iteration number: [1120/4518] 24% | Training loss: 0.6874331620122706
Epoch: 66 | Iteration number: [1130/4518] 25% | Training loss: 0.6874316234504227
Epoch: 66 | Iteration number: [1140/4518] 25% | Training loss: 0.6874162799956506
Epoch: 66 | Iteration number: [1150/4518] 25% | Training loss: 0.6874084939645684
Epoch: 66 | Iteration number: [1160/4518] 25% | Training loss: 0.687405999518674
Epoch: 66 | Iteration number: [1170/4518] 25% | Training loss: 0.687389447953966
Epoch: 66 | Iteration number: [1180/4518] 26% | Training loss: 0.6873930328983372
Epoch: 66 | Iteration number: [1190/4518] 26% | Training loss: 0.6873899639153681
Epoch: 66 | Iteration number: [1200/4518] 26% | Training loss: 0.6873861761391162
Epoch: 66 | Iteration number: [1210/4518] 26% | Training loss: 0.6873787038089815
Epoch: 66 | Iteration number: [1220/4518] 27% | Training loss: 0.6873820961498823
Epoch: 66 | Iteration number: [1230/4518] 27% | Training loss: 0.6873733306803355
Epoch: 66 | Iteration number: [1240/4518] 27% | Training loss: 0.6873628597105703
Epoch: 66 | Iteration number: [1250/4518] 27% | Training loss: 0.6873608734130859
Epoch: 66 | Iteration number: [1260/4518] 27% | Training loss: 0.687357160117891
Epoch: 66 | Iteration number: [1270/4518] 28% | Training loss: 0.6873465929913709
Epoch: 66 | Iteration number: [1280/4518] 28% | Training loss: 0.6873356763739139
Epoch: 66 | Iteration number: [1290/4518] 28% | Training loss: 0.6873379304889561
Epoch: 66 | Iteration number: [1300/4518] 28% | Training loss: 0.6873325183299872
Epoch: 66 | Iteration number: [1310/4518] 28% | Training loss: 0.6873206235070265
Epoch: 66 | Iteration number: [1320/4518] 29% | Training loss: 0.6873151077917128
Epoch: 66 | Iteration number: [1330/4518] 29% | Training loss: 0.6873180109755437
Epoch: 66 | Iteration number: [1340/4518] 29% | Training loss: 0.6873197765492681
Epoch: 66 | Iteration number: [1350/4518] 29% | Training loss: 0.6873214724770299
Epoch: 66 | Iteration number: [1360/4518] 30% | Training loss: 0.6873087219455662
Epoch: 66 | Iteration number: [1370/4518] 30% | Training loss: 0.6873004101053641
Epoch: 66 | Iteration number: [1380/4518] 30% | Training loss: 0.6872970226018326
Epoch: 66 | Iteration number: [1390/4518] 30% | Training loss: 0.6872908709289358
Epoch: 66 | Iteration number: [1400/4518] 30% | Training loss: 0.6872871240547725
Epoch: 66 | Iteration number: [1410/4518] 31% | Training loss: 0.6872968386673758
Epoch: 66 | Iteration number: [1420/4518] 31% | Training loss: 0.6872937927363624
Epoch: 66 | Iteration number: [1430/4518] 31% | Training loss: 0.6872992369678471
Epoch: 66 | Iteration number: [1440/4518] 31% | Training loss: 0.687286017007298
Epoch: 66 | Iteration number: [1450/4518] 32% | Training loss: 0.6872686797997047
Epoch: 66 | Iteration number: [1460/4518] 32% | Training loss: 0.6872629973578126
Epoch: 66 | Iteration number: [1470/4518] 32% | Training loss: 0.6872613559774801
Epoch: 66 | Iteration number: [1480/4518] 32% | Training loss: 0.6872463016091166
Epoch: 66 | Iteration number: [1490/4518] 32% | Training loss: 0.6872432705139954
Epoch: 66 | Iteration number: [1500/4518] 33% | Training loss: 0.6872455800374349
Epoch: 66 | Iteration number: [1510/4518] 33% | Training loss: 0.6872477317093224
Epoch: 66 | Iteration number: [1520/4518] 33% | Training loss: 0.6872400758689956
Epoch: 66 | Iteration number: [1530/4518] 33% | Training loss: 0.6872338559113297
Epoch: 66 | Iteration number: [1540/4518] 34% | Training loss: 0.6872284027663145
Epoch: 66 | Iteration number: [1550/4518] 34% | Training loss: 0.6872208231879818
Epoch: 66 | Iteration number: [1560/4518] 34% | Training loss: 0.687217826797412
Epoch: 66 | Iteration number: [1570/4518] 34% | Training loss: 0.6872169078155688
Epoch: 66 | Iteration number: [1580/4518] 34% | Training loss: 0.6872125315515301
Epoch: 66 | Iteration number: [1590/4518] 35% | Training loss: 0.6872105364904464
Epoch: 66 | Iteration number: [1600/4518] 35% | Training loss: 0.6872115525975824
Epoch: 66 | Iteration number: [1610/4518] 35% | Training loss: 0.6872046104499272
Epoch: 66 | Iteration number: [1620/4518] 35% | Training loss: 0.6871949906702395
Epoch: 66 | Iteration number: [1630/4518] 36% | Training loss: 0.6871912109705568
Epoch: 66 | Iteration number: [1640/4518] 36% | Training loss: 0.6871819173780883
Epoch: 66 | Iteration number: [1650/4518] 36% | Training loss: 0.6871809827920162
Epoch: 66 | Iteration number: [1660/4518] 36% | Training loss: 0.6871729524738818
Epoch: 66 | Iteration number: [1670/4518] 36% | Training loss: 0.6871761507973699
Epoch: 66 | Iteration number: [1680/4518] 37% | Training loss: 0.6871823347040585
Epoch: 66 | Iteration number: [1690/4518] 37% | Training loss: 0.6871788435433743
Epoch: 66 | Iteration number: [1700/4518] 37% | Training loss: 0.6871776196535896
Epoch: 66 | Iteration number: [1710/4518] 37% | Training loss: 0.6871701157581039
Epoch: 66 | Iteration number: [1720/4518] 38% | Training loss: 0.6871636938217074
Epoch: 66 | Iteration number: [1730/4518] 38% | Training loss: 0.6871589636527045
Epoch: 66 | Iteration number: [1740/4518] 38% | Training loss: 0.6871662409141146
Epoch: 66 | Iteration number: [1750/4518] 38% | Training loss: 0.6871679134368897
Epoch: 66 | Iteration number: [1760/4518] 38% | Training loss: 0.687158802761273
Epoch: 66 | Iteration number: [1770/4518] 39% | Training loss: 0.687156913879901
Epoch: 66 | Iteration number: [1780/4518] 39% | Training loss: 0.6871496812346276
Epoch: 66 | Iteration number: [1790/4518] 39% | Training loss: 0.6871483312305792
Epoch: 66 | Iteration number: [1800/4518] 39% | Training loss: 0.6871439263886876
Epoch: 66 | Iteration number: [1810/4518] 40% | Training loss: 0.6871354292769458
Epoch: 66 | Iteration number: [1820/4518] 40% | Training loss: 0.6871287798488533
Epoch: 66 | Iteration number: [1830/4518] 40% | Training loss: 0.6871329575939908
Epoch: 66 | Iteration number: [1840/4518] 40% | Training loss: 0.6871323747803335
Epoch: 66 | Iteration number: [1850/4518] 40% | Training loss: 0.6871302809586396
Epoch: 66 | Iteration number: [1860/4518] 41% | Training loss: 0.687127062486064
Epoch: 66 | Iteration number: [1870/4518] 41% | Training loss: 0.6871271973943965
Epoch: 66 | Iteration number: [1880/4518] 41% | Training loss: 0.6871268530475333
Epoch: 66 | Iteration number: [1890/4518] 41% | Training loss: 0.6871291406255551
Epoch: 66 | Iteration number: [1900/4518] 42% | Training loss: 0.6871314278401827
Epoch: 66 | Iteration number: [1910/4518] 42% | Training loss: 0.6871306696799413
Epoch: 66 | Iteration number: [1920/4518] 42% | Training loss: 0.6871286498382687
Epoch: 66 | Iteration number: [1930/4518] 42% | Training loss: 0.6871305848341531
Epoch: 66 | Iteration number: [1940/4518] 42% | Training loss: 0.6871314107757254
Epoch: 66 | Iteration number: [1950/4518] 43% | Training loss: 0.687132498514958
Epoch: 66 | Iteration number: [1960/4518] 43% | Training loss: 0.6871330330566484
Epoch: 66 | Iteration number: [1970/4518] 43% | Training loss: 0.6871294860609897
Epoch: 66 | Iteration number: [1980/4518] 43% | Training loss: 0.6871267104088657
Epoch: 66 | Iteration number: [1990/4518] 44% | Training loss: 0.6871183161160455
Epoch: 66 | Iteration number: [2000/4518] 44% | Training loss: 0.687118528008461
Epoch: 66 | Iteration number: [2010/4518] 44% | Training loss: 0.6871231230930309
Epoch: 66 | Iteration number: [2020/4518] 44% | Training loss: 0.6871208136329556
Epoch: 66 | Iteration number: [2030/4518] 44% | Training loss: 0.6871203020582058
Epoch: 66 | Iteration number: [2040/4518] 45% | Training loss: 0.6871177500661682
Epoch: 66 | Iteration number: [2050/4518] 45% | Training loss: 0.6871134977224397
Epoch: 66 | Iteration number: [2060/4518] 45% | Training loss: 0.6871137657211822
Epoch: 66 | Iteration number: [2070/4518] 45% | Training loss: 0.6871157018458786
Epoch: 66 | Iteration number: [2080/4518] 46% | Training loss: 0.6871185334829184
Epoch: 66 | Iteration number: [2090/4518] 46% | Training loss: 0.6871206189741929
Epoch: 66 | Iteration number: [2100/4518] 46% | Training loss: 0.6871194122518812
Epoch: 66 | Iteration number: [2110/4518] 46% | Training loss: 0.6871190810938017
Epoch: 66 | Iteration number: [2120/4518] 46% | Training loss: 0.6871185952481234
Epoch: 66 | Iteration number: [2130/4518] 47% | Training loss: 0.6871153290842621
Epoch: 66 | Iteration number: [2140/4518] 47% | Training loss: 0.687107892543356
Epoch: 66 | Iteration number: [2150/4518] 47% | Training loss: 0.6871081952161567
Epoch: 66 | Iteration number: [2160/4518] 47% | Training loss: 0.6871048853353218
Epoch: 66 | Iteration number: [2170/4518] 48% | Training loss: 0.6871064239657969
Epoch: 66 | Iteration number: [2180/4518] 48% | Training loss: 0.6871035940876794
Epoch: 66 | Iteration number: [2190/4518] 48% | Training loss: 0.6870988522762578
Epoch: 66 | Iteration number: [2200/4518] 48% | Training loss: 0.687092800357125
Epoch: 66 | Iteration number: [2210/4518] 48% | Training loss: 0.6870972944330845
Epoch: 66 | Iteration number: [2220/4518] 49% | Training loss: 0.6870985296932427
Epoch: 66 | Iteration number: [2230/4518] 49% | Training loss: 0.6870923807535471
Epoch: 66 | Iteration number: [2240/4518] 49% | Training loss: 0.6870958511584572
Epoch: 66 | Iteration number: [2250/4518] 49% | Training loss: 0.6870940189626482
Epoch: 66 | Iteration number: [2260/4518] 50% | Training loss: 0.6870888523823392
Epoch: 66 | Iteration number: [2270/4518] 50% | Training loss: 0.6870893022825014
Epoch: 66 | Iteration number: [2280/4518] 50% | Training loss: 0.6870931577002793
Epoch: 66 | Iteration number: [2290/4518] 50% | Training loss: 0.6870887175918146
Epoch: 66 | Iteration number: [2300/4518] 50% | Training loss: 0.6870889936063601
Epoch: 66 | Iteration number: [2310/4518] 51% | Training loss: 0.687089713646736
Epoch: 66 | Iteration number: [2320/4518] 51% | Training loss: 0.6870880028297162
Epoch: 66 | Iteration number: [2330/4518] 51% | Training loss: 0.6870916360949242
Epoch: 66 | Iteration number: [2340/4518] 51% | Training loss: 0.6870890294894194
Epoch: 66 | Iteration number: [2350/4518] 52% | Training loss: 0.6870927207013394
Epoch: 66 | Iteration number: [2360/4518] 52% | Training loss: 0.6870862278897883
Epoch: 66 | Iteration number: [2370/4518] 52% | Training loss: 0.6870841990794814
Epoch: 66 | Iteration number: [2380/4518] 52% | Training loss: 0.687083323913462
Epoch: 66 | Iteration number: [2390/4518] 52% | Training loss: 0.6870800812124708
Epoch: 66 | Iteration number: [2400/4518] 53% | Training loss: 0.6870759109407664
Epoch: 66 | Iteration number: [2410/4518] 53% | Training loss: 0.6870707737954326
Epoch: 66 | Iteration number: [2420/4518] 53% | Training loss: 0.687070003767644
Epoch: 66 | Iteration number: [2430/4518] 53% | Training loss: 0.6870646673465461
Epoch: 66 | Iteration number: [2440/4518] 54% | Training loss: 0.6870655137495917
Epoch: 66 | Iteration number: [2450/4518] 54% | Training loss: 0.6870627266046953
Epoch: 66 | Iteration number: [2460/4518] 54% | Training loss: 0.6870569715654947
Epoch: 66 | Iteration number: [2470/4518] 54% | Training loss: 0.6870604124146434
Epoch: 66 | Iteration number: [2480/4518] 54% | Training loss: 0.6870541152454192
Epoch: 66 | Iteration number: [2490/4518] 55% | Training loss: 0.6870583886602317
Epoch: 66 | Iteration number: [2500/4518] 55% | Training loss: 0.6870598089456558
Epoch: 66 | Iteration number: [2510/4518] 55% | Training loss: 0.6870566394936991
Epoch: 66 | Iteration number: [2520/4518] 55% | Training loss: 0.6870553279206866
Epoch: 66 | Iteration number: [2530/4518] 55% | Training loss: 0.6870499645768419
Epoch: 66 | Iteration number: [2540/4518] 56% | Training loss: 0.6870498067281378
Epoch: 66 | Iteration number: [2550/4518] 56% | Training loss: 0.6870516348352619
Epoch: 66 | Iteration number: [2560/4518] 56% | Training loss: 0.6870502473320812
Epoch: 66 | Iteration number: [2570/4518] 56% | Training loss: 0.687048716976485
Epoch: 66 | Iteration number: [2580/4518] 57% | Training loss: 0.6870484840731288
Epoch: 66 | Iteration number: [2590/4518] 57% | Training loss: 0.6870474599042915
Epoch: 66 | Iteration number: [2600/4518] 57% | Training loss: 0.6870474386902956
Epoch: 66 | Iteration number: [2610/4518] 57% | Training loss: 0.6870477572483121
Epoch: 66 | Iteration number: [2620/4518] 57% | Training loss: 0.687042926468012
Epoch: 66 | Iteration number: [2630/4518] 58% | Training loss: 0.6870386930926218
Epoch: 66 | Iteration number: [2640/4518] 58% | Training loss: 0.6870430460481932
Epoch: 66 | Iteration number: [2650/4518] 58% | Training loss: 0.6870412214297169
Epoch: 66 | Iteration number: [2660/4518] 58% | Training loss: 0.6870359365429197
Epoch: 66 | Iteration number: [2670/4518] 59% | Training loss: 0.6870375762271524
Epoch: 66 | Iteration number: [2680/4518] 59% | Training loss: 0.6870348576067099
Epoch: 66 | Iteration number: [2690/4518] 59% | Training loss: 0.6870341255540742
Epoch: 66 | Iteration number: [2700/4518] 59% | Training loss: 0.6870284275876151
Epoch: 66 | Iteration number: [2710/4518] 59% | Training loss: 0.6870266972872604
Epoch: 66 | Iteration number: [2720/4518] 60% | Training loss: 0.6870308098985868
Epoch: 66 | Iteration number: [2730/4518] 60% | Training loss: 0.6870286707913046
Epoch: 66 | Iteration number: [2740/4518] 60% | Training loss: 0.6870282910818601
Epoch: 66 | Iteration number: [2750/4518] 60% | Training loss: 0.6870212088714946
Epoch: 66 | Iteration number: [2760/4518] 61% | Training loss: 0.6870250392867171
Epoch: 66 | Iteration number: [2770/4518] 61% | Training loss: 0.6870243994983095
Epoch: 66 | Iteration number: [2780/4518] 61% | Training loss: 0.6870248138904571
Epoch: 66 | Iteration number: [2790/4518] 61% | Training loss: 0.687025577364002
Epoch: 66 | Iteration number: [2800/4518] 61% | Training loss: 0.6870238064229488
Epoch: 66 | Iteration number: [2810/4518] 62% | Training loss: 0.6870174063482318
Epoch: 66 | Iteration number: [2820/4518] 62% | Training loss: 0.6870205233283077
Epoch: 66 | Iteration number: [2830/4518] 62% | Training loss: 0.687018596325662
Epoch: 66 | Iteration number: [2840/4518] 62% | Training loss: 0.6870180439151509
Epoch: 66 | Iteration number: [2850/4518] 63% | Training loss: 0.6870141246235162
Epoch: 66 | Iteration number: [2860/4518] 63% | Training loss: 0.6870107100560114
Epoch: 66 | Iteration number: [2870/4518] 63% | Training loss: 0.6870103658491726
Epoch: 66 | Iteration number: [2880/4518] 63% | Training loss: 0.687006937381294
Epoch: 66 | Iteration number: [2890/4518] 63% | Training loss: 0.6870065182138066
Epoch: 66 | Iteration number: [2900/4518] 64% | Training loss: 0.68700662730069
Epoch: 66 | Iteration number: [2910/4518] 64% | Training loss: 0.6870072257887457
Epoch: 66 | Iteration number: [2920/4518] 64% | Training loss: 0.6870079532265663
Epoch: 66 | Iteration number: [2930/4518] 64% | Training loss: 0.6870070368966958
Epoch: 66 | Iteration number: [2940/4518] 65% | Training loss: 0.6870043483923892
Epoch: 66 | Iteration number: [2950/4518] 65% | Training loss: 0.6870014333927025
Epoch: 66 | Iteration number: [2960/4518] 65% | Training loss: 0.6870003736099681
Epoch: 66 | Iteration number: [2970/4518] 65% | Training loss: 0.6869972454979765
Epoch: 66 | Iteration number: [2980/4518] 65% | Training loss: 0.6870007859780485
Epoch: 66 | Iteration number: [2990/4518] 66% | Training loss: 0.687005468894008
Epoch: 66 | Iteration number: [3000/4518] 66% | Training loss: 0.6870047076940536
Epoch: 66 | Iteration number: [3010/4518] 66% | Training loss: 0.6870035571513382
Epoch: 66 | Iteration number: [3020/4518] 66% | Training loss: 0.6870031498520579
Epoch: 66 | Iteration number: [3030/4518] 67% | Training loss: 0.6870026232779223
Epoch: 66 | Iteration number: [3040/4518] 67% | Training loss: 0.6870068976753636
Epoch: 66 | Iteration number: [3050/4518] 67% | Training loss: 0.6870097743096899
Epoch: 66 | Iteration number: [3060/4518] 67% | Training loss: 0.6870103962670744
Epoch: 66 | Iteration number: [3070/4518] 67% | Training loss: 0.687008590787552
Epoch: 66 | Iteration number: [3080/4518] 68% | Training loss: 0.6870057358370198
Epoch: 66 | Iteration number: [3090/4518] 68% | Training loss: 0.6870068210807048
Epoch: 66 | Iteration number: [3100/4518] 68% | Training loss: 0.6870052433590735
Epoch: 66 | Iteration number: [3110/4518] 68% | Training loss: 0.6870014418551393
Epoch: 66 | Iteration number: [3120/4518] 69% | Training loss: 0.6870043047918724
Epoch: 66 | Iteration number: [3130/4518] 69% | Training loss: 0.6869979971513962
Epoch: 66 | Iteration number: [3140/4518] 69% | Training loss: 0.6870000830881156
Epoch: 66 | Iteration number: [3150/4518] 69% | Training loss: 0.6869991552072858
Epoch: 66 | Iteration number: [3160/4518] 69% | Training loss: 0.6869971670681917
Epoch: 66 | Iteration number: [3170/4518] 70% | Training loss: 0.686999640611444
Epoch: 66 | Iteration number: [3180/4518] 70% | Training loss: 0.6870000859851357
Epoch: 66 | Iteration number: [3190/4518] 70% | Training loss: 0.686998585959587
Epoch: 66 | Iteration number: [3200/4518] 70% | Training loss: 0.6869977275282144
Epoch: 66 | Iteration number: [3210/4518] 71% | Training loss: 0.6869968508262871
Epoch: 66 | Iteration number: [3220/4518] 71% | Training loss: 0.6869951282043635
Epoch: 66 | Iteration number: [3230/4518] 71% | Training loss: 0.6869931953241213
Epoch: 66 | Iteration number: [3240/4518] 71% | Training loss: 0.6869926342809641
Epoch: 66 | Iteration number: [3250/4518] 71% | Training loss: 0.6869888456968161
Epoch: 66 | Iteration number: [3260/4518] 72% | Training loss: 0.6869853807738954
Epoch: 66 | Iteration number: [3270/4518] 72% | Training loss: 0.6869838810841972
Epoch: 66 | Iteration number: [3280/4518] 72% | Training loss: 0.6869831862064396
Epoch: 66 | Iteration number: [3290/4518] 72% | Training loss: 0.6869832211533579
Epoch: 66 | Iteration number: [3300/4518] 73% | Training loss: 0.6869810509862322
Epoch: 66 | Iteration number: [3310/4518] 73% | Training loss: 0.6869814181976088
Epoch: 66 | Iteration number: [3320/4518] 73% | Training loss: 0.6869851417929294
Epoch: 66 | Iteration number: [3330/4518] 73% | Training loss: 0.686984612257989
Epoch: 66 | Iteration number: [3340/4518] 73% | Training loss: 0.6869855308782554
Epoch: 66 | Iteration number: [3350/4518] 74% | Training loss: 0.686983142770938
Epoch: 66 | Iteration number: [3360/4518] 74% | Training loss: 0.6869825796534618
Epoch: 66 | Iteration number: [3370/4518] 74% | Training loss: 0.6869819919680983
Epoch: 66 | Iteration number: [3380/4518] 74% | Training loss: 0.6869828085751223
Epoch: 66 | Iteration number: [3390/4518] 75% | Training loss: 0.6869837980882256
Epoch: 66 | Iteration number: [3400/4518] 75% | Training loss: 0.6869847125516219
Epoch: 66 | Iteration number: [3410/4518] 75% | Training loss: 0.6869834974888832
Epoch: 66 | Iteration number: [3420/4518] 75% | Training loss: 0.686986238130352
Epoch: 66 | Iteration number: [3430/4518] 75% | Training loss: 0.6869876539915714
Epoch: 66 | Iteration number: [3440/4518] 76% | Training loss: 0.6869867559609025
Epoch: 66 | Iteration number: [3450/4518] 76% | Training loss: 0.6869860846754433
Epoch: 66 | Iteration number: [3460/4518] 76% | Training loss: 0.6869875099617622
Epoch: 66 | Iteration number: [3470/4518] 76% | Training loss: 0.6869828898212752
Epoch: 66 | Iteration number: [3480/4518] 77% | Training loss: 0.6869844241046358
Epoch: 66 | Iteration number: [3490/4518] 77% | Training loss: 0.6869867999608332
Epoch: 66 | Iteration number: [3500/4518] 77% | Training loss: 0.6869858947822026
Epoch: 66 | Iteration number: [3510/4518] 77% | Training loss: 0.6869886622809277
Epoch: 66 | Iteration number: [3520/4518] 77% | Training loss: 0.6869905288754539
Epoch: 66 | Iteration number: [3530/4518] 78% | Training loss: 0.686984941540629
Epoch: 66 | Iteration number: [3540/4518] 78% | Training loss: 0.6869816003546203
Epoch: 66 | Iteration number: [3550/4518] 78% | Training loss: 0.6869839819048492
Epoch: 66 | Iteration number: [3560/4518] 78% | Training loss: 0.6869824011506659
Epoch: 66 | Iteration number: [3570/4518] 79% | Training loss: 0.6869835753233827
Epoch: 66 | Iteration number: [3580/4518] 79% | Training loss: 0.6869814150160252
Epoch: 66 | Iteration number: [3590/4518] 79% | Training loss: 0.6869798952158447
Epoch: 66 | Iteration number: [3600/4518] 79% | Training loss: 0.6869785032669703
Epoch: 66 | Iteration number: [3610/4518] 79% | Training loss: 0.6869782326129005
Epoch: 66 | Iteration number: [3620/4518] 80% | Training loss: 0.6869771232591808
Epoch: 66 | Iteration number: [3630/4518] 80% | Training loss: 0.6869773095961116
Epoch: 66 | Iteration number: [3640/4518] 80% | Training loss: 0.6869783205972924
Epoch: 66 | Iteration number: [3650/4518] 80% | Training loss: 0.6869761004839858
Epoch: 66 | Iteration number: [3660/4518] 81% | Training loss: 0.6869742282589928
Epoch: 66 | Iteration number: [3670/4518] 81% | Training loss: 0.6869765895751256
Epoch: 66 | Iteration number: [3680/4518] 81% | Training loss: 0.6869772667308216
Epoch: 66 | Iteration number: [3690/4518] 81% | Training loss: 0.6869769650423106
Epoch: 66 | Iteration number: [3700/4518] 81% | Training loss: 0.6869791773525444
Epoch: 66 | Iteration number: [3710/4518] 82% | Training loss: 0.6869797923976199
Epoch: 66 | Iteration number: [3720/4518] 82% | Training loss: 0.6869784202466729
Epoch: 66 | Iteration number: [3730/4518] 82% | Training loss: 0.6869796518985452
Epoch: 66 | Iteration number: [3740/4518] 82% | Training loss: 0.6869779360166846
Epoch: 66 | Iteration number: [3750/4518] 83% | Training loss: 0.6869768195152283
Epoch: 66 | Iteration number: [3760/4518] 83% | Training loss: 0.6869737241179386
Epoch: 66 | Iteration number: [3770/4518] 83% | Training loss: 0.6869752874741187
Epoch: 66 | Iteration number: [3780/4518] 83% | Training loss: 0.6869724424112411
Epoch: 66 | Iteration number: [3790/4518] 83% | Training loss: 0.6869723267479748
Epoch: 66 | Iteration number: [3800/4518] 84% | Training loss: 0.6869742605560705
Epoch: 66 | Iteration number: [3810/4518] 84% | Training loss: 0.68697178503034
Epoch: 66 | Iteration number: [3820/4518] 84% | Training loss: 0.686970416522775
Epoch: 66 | Iteration number: [3830/4518] 84% | Training loss: 0.6869678253760225
Epoch: 66 | Iteration number: [3840/4518] 84% | Training loss: 0.6869662819119792
Epoch: 66 | Iteration number: [3850/4518] 85% | Training loss: 0.6869651767340573
Epoch: 66 | Iteration number: [3860/4518] 85% | Training loss: 0.686965808751052
Epoch: 66 | Iteration number: [3870/4518] 85% | Training loss: 0.6869638543720393
Epoch: 66 | Iteration number: [3880/4518] 85% | Training loss: 0.6869615066911756
Epoch: 66 | Iteration number: [3890/4518] 86% | Training loss: 0.6869631244621424
Epoch: 66 | Iteration number: [3900/4518] 86% | Training loss: 0.6869627000582523
Epoch: 66 | Iteration number: [3910/4518] 86% | Training loss: 0.6869629722117158
Epoch: 66 | Iteration number: [3920/4518] 86% | Training loss: 0.6869621219379561
Epoch: 66 | Iteration number: [3930/4518] 86% | Training loss: 0.6869588723012813
Epoch: 66 | Iteration number: [3940/4518] 87% | Training loss: 0.6869580394574228
Epoch: 66 | Iteration number: [3950/4518] 87% | Training loss: 0.6869551702239846
Epoch: 66 | Iteration number: [3960/4518] 87% | Training loss: 0.6869529441751615
Epoch: 66 | Iteration number: [3970/4518] 87% | Training loss: 0.6869537573467274
Epoch: 66 | Iteration number: [3980/4518] 88% | Training loss: 0.6869560322869364
Epoch: 66 | Iteration number: [3990/4518] 88% | Training loss: 0.6869554106603589
Epoch: 66 | Iteration number: [4000/4518] 88% | Training loss: 0.6869536588788032
Epoch: 66 | Iteration number: [4010/4518] 88% | Training loss: 0.6869502224827051
Epoch: 66 | Iteration number: [4020/4518] 88% | Training loss: 0.6869516693982319
Epoch: 66 | Iteration number: [4030/4518] 89% | Training loss: 0.6869522079048914
Epoch: 66 | Iteration number: [4040/4518] 89% | Training loss: 0.6869489488035145
Epoch: 66 | Iteration number: [4050/4518] 89% | Training loss: 0.6869485960036148
Epoch: 66 | Iteration number: [4060/4518] 89% | Training loss: 0.6869478086973059
Epoch: 66 | Iteration number: [4070/4518] 90% | Training loss: 0.6869481848996746
Epoch: 66 | Iteration number: [4080/4518] 90% | Training loss: 0.686945231404959
Epoch: 66 | Iteration number: [4090/4518] 90% | Training loss: 0.6869461228474428
Epoch: 66 | Iteration number: [4100/4518] 90% | Training loss: 0.6869452432306802
Epoch: 66 | Iteration number: [4110/4518] 90% | Training loss: 0.6869464117535129
Epoch: 66 | Iteration number: [4120/4518] 91% | Training loss: 0.6869503837476656
Epoch: 66 | Iteration number: [4130/4518] 91% | Training loss: 0.6869483632700784
Epoch: 66 | Iteration number: [4140/4518] 91% | Training loss: 0.6869501735997084
Epoch: 66 | Iteration number: [4150/4518] 91% | Training loss: 0.6869524847743023
Epoch: 66 | Iteration number: [4160/4518] 92% | Training loss: 0.6869533758897047
Epoch: 66 | Iteration number: [4170/4518] 92% | Training loss: 0.686952044938108
Epoch: 66 | Iteration number: [4180/4518] 92% | Training loss: 0.6869511708118129
Epoch: 66 | Iteration number: [4190/4518] 92% | Training loss: 0.6869486529388974
Epoch: 66 | Iteration number: [4200/4518] 92% | Training loss: 0.6869470761645408
Epoch: 66 | Iteration number: [4210/4518] 93% | Training loss: 0.6869476597552628
Epoch: 66 | Iteration number: [4220/4518] 93% | Training loss: 0.6869454591336408
Epoch: 66 | Iteration number: [4230/4518] 93% | Training loss: 0.6869444179478549
Epoch: 66 | Iteration number: [4240/4518] 93% | Training loss: 0.6869455117943152
Epoch: 66 | Iteration number: [4250/4518] 94% | Training loss: 0.6869425142793094
Epoch: 66 | Iteration number: [4260/4518] 94% | Training loss: 0.6869425492527339
Epoch: 66 | Iteration number: [4270/4518] 94% | Training loss: 0.6869419722981419
Epoch: 66 | Iteration number: [4280/4518] 94% | Training loss: 0.6869388490915298
Epoch: 66 | Iteration number: [4290/4518] 94% | Training loss: 0.6869368403524786
Epoch: 66 | Iteration number: [4300/4518] 95% | Training loss: 0.6869365298470785
Epoch: 66 | Iteration number: [4310/4518] 95% | Training loss: 0.6869355407502424
Epoch: 66 | Iteration number: [4320/4518] 95% | Training loss: 0.6869351798185596
Epoch: 66 | Iteration number: [4330/4518] 95% | Training loss: 0.6869361766766731
Epoch: 66 | Iteration number: [4340/4518] 96% | Training loss: 0.686938534065875
Epoch: 66 | Iteration number: [4350/4518] 96% | Training loss: 0.6869370874454235
Epoch: 66 | Iteration number: [4360/4518] 96% | Training loss: 0.6869361366153857
Epoch: 66 | Iteration number: [4370/4518] 96% | Training loss: 0.6869362875444119
Epoch: 66 | Iteration number: [4380/4518] 96% | Training loss: 0.6869362338220693
Epoch: 66 | Iteration number: [4390/4518] 97% | Training loss: 0.6869355304094544
Epoch: 66 | Iteration number: [4400/4518] 97% | Training loss: 0.686934637400237
Epoch: 66 | Iteration number: [4410/4518] 97% | Training loss: 0.6869369796344212
Epoch: 66 | Iteration number: [4420/4518] 97% | Training loss: 0.6869330086993956
Epoch: 66 | Iteration number: [4430/4518] 98% | Training loss: 0.6869323134287755
Epoch: 66 | Iteration number: [4440/4518] 98% | Training loss: 0.6869316248743383
Epoch: 66 | Iteration number: [4450/4518] 98% | Training loss: 0.6869291828991322
Epoch: 66 | Iteration number: [4460/4518] 98% | Training loss: 0.6869285385972181
Epoch: 66 | Iteration number: [4470/4518] 98% | Training loss: 0.6869292973271952
Epoch: 66 | Iteration number: [4480/4518] 99% | Training loss: 0.6869291611947119
Epoch: 66 | Iteration number: [4490/4518] 99% | Training loss: 0.6869300821177944
Epoch: 66 | Iteration number: [4500/4518] 99% | Training loss: 0.6869301024278005
Epoch: 66 | Iteration number: [4510/4518] 99% | Training loss: 0.6869307998146557

 End of epoch: 66 | Train Loss: 0.6867783554046752 | Training Time: 633 

 End of epoch: 66 | Eval Loss: 0.6896673647724852 | Evaluating Time: 17 
Epoch: 67 | Iteration number: [10/4518] 0% | Training loss: 0.7552983522415161
Epoch: 67 | Iteration number: [20/4518] 0% | Training loss: 0.7209207117557526
Epoch: 67 | Iteration number: [30/4518] 0% | Training loss: 0.7096253514289856
Epoch: 67 | Iteration number: [40/4518] 0% | Training loss: 0.7035514891147614
Epoch: 67 | Iteration number: [50/4518] 1% | Training loss: 0.7003079783916474
Epoch: 67 | Iteration number: [60/4518] 1% | Training loss: 0.6981051494677861
Epoch: 67 | Iteration number: [70/4518] 1% | Training loss: 0.6961286059447698
Epoch: 67 | Iteration number: [80/4518] 1% | Training loss: 0.695154146105051
Epoch: 67 | Iteration number: [90/4518] 1% | Training loss: 0.6941711260212793
Epoch: 67 | Iteration number: [100/4518] 2% | Training loss: 0.6935067963600159
Epoch: 67 | Iteration number: [110/4518] 2% | Training loss: 0.6929219598119909
Epoch: 67 | Iteration number: [120/4518] 2% | Training loss: 0.6924630974729856
Epoch: 67 | Iteration number: [130/4518] 2% | Training loss: 0.6920353215474349
Epoch: 67 | Iteration number: [140/4518] 3% | Training loss: 0.6916359058448247
Epoch: 67 | Iteration number: [150/4518] 3% | Training loss: 0.6913234504063924
Epoch: 67 | Iteration number: [160/4518] 3% | Training loss: 0.6910326361656189
Epoch: 67 | Iteration number: [170/4518] 3% | Training loss: 0.6908445312696345
Epoch: 67 | Iteration number: [180/4518] 3% | Training loss: 0.6906950645976596
Epoch: 67 | Iteration number: [190/4518] 4% | Training loss: 0.6905463174769753
Epoch: 67 | Iteration number: [200/4518] 4% | Training loss: 0.6903565254807472
Epoch: 67 | Iteration number: [210/4518] 4% | Training loss: 0.6901961428778512
Epoch: 67 | Iteration number: [220/4518] 4% | Training loss: 0.6900305027311499
Epoch: 67 | Iteration number: [230/4518] 5% | Training loss: 0.689940962843273
Epoch: 67 | Iteration number: [240/4518] 5% | Training loss: 0.6898027303318183
Epoch: 67 | Iteration number: [250/4518] 5% | Training loss: 0.6896574931144714
Epoch: 67 | Iteration number: [260/4518] 5% | Training loss: 0.689515815102137
Epoch: 67 | Iteration number: [270/4518] 5% | Training loss: 0.6893866488227138
Epoch: 67 | Iteration number: [280/4518] 6% | Training loss: 0.6893010818532535
Epoch: 67 | Iteration number: [290/4518] 6% | Training loss: 0.6892143944214131
Epoch: 67 | Iteration number: [300/4518] 6% | Training loss: 0.6891017071406047
Epoch: 67 | Iteration number: [310/4518] 6% | Training loss: 0.6890482306480408
Epoch: 67 | Iteration number: [320/4518] 7% | Training loss: 0.68893031924963
Epoch: 67 | Iteration number: [330/4518] 7% | Training loss: 0.6888553621190967
Epoch: 67 | Iteration number: [340/4518] 7% | Training loss: 0.6887840034330592
Epoch: 67 | Iteration number: [350/4518] 7% | Training loss: 0.6887520851407732
Epoch: 67 | Iteration number: [360/4518] 7% | Training loss: 0.688660860227214
Epoch: 67 | Iteration number: [370/4518] 8% | Training loss: 0.6886232297162752
Epoch: 67 | Iteration number: [380/4518] 8% | Training loss: 0.6885871048036375
Epoch: 67 | Iteration number: [390/4518] 8% | Training loss: 0.6885201200460777
Epoch: 67 | Iteration number: [400/4518] 8% | Training loss: 0.6884423144161701
Epoch: 67 | Iteration number: [410/4518] 9% | Training loss: 0.6883920050248867
Epoch: 67 | Iteration number: [420/4518] 9% | Training loss: 0.6883591629209973
Epoch: 67 | Iteration number: [430/4518] 9% | Training loss: 0.6883322521697643
Epoch: 67 | Iteration number: [440/4518] 9% | Training loss: 0.6883091497150334
Epoch: 67 | Iteration number: [450/4518] 9% | Training loss: 0.6882456917232938
Epoch: 67 | Iteration number: [460/4518] 10% | Training loss: 0.6882455805073614
Epoch: 67 | Iteration number: [470/4518] 10% | Training loss: 0.6882160805641336
Epoch: 67 | Iteration number: [480/4518] 10% | Training loss: 0.6881641130894423
Epoch: 67 | Iteration number: [490/4518] 10% | Training loss: 0.688142998364507
Epoch: 67 | Iteration number: [500/4518] 11% | Training loss: 0.6881252266168595
Epoch: 67 | Iteration number: [510/4518] 11% | Training loss: 0.6881038221658445
Epoch: 67 | Iteration number: [520/4518] 11% | Training loss: 0.6880743769498971
Epoch: 67 | Iteration number: [530/4518] 11% | Training loss: 0.6880286292085108
Epoch: 67 | Iteration number: [540/4518] 11% | Training loss: 0.6880170866295143
Epoch: 67 | Iteration number: [550/4518] 12% | Training loss: 0.688012534271587
Epoch: 67 | Iteration number: [560/4518] 12% | Training loss: 0.6879967827882085
Epoch: 67 | Iteration number: [570/4518] 12% | Training loss: 0.6879802205060658
Epoch: 67 | Iteration number: [580/4518] 12% | Training loss: 0.6879243588653104
Epoch: 67 | Iteration number: [590/4518] 13% | Training loss: 0.687916629092168
Epoch: 67 | Iteration number: [600/4518] 13% | Training loss: 0.6878956797719001
Epoch: 67 | Iteration number: [610/4518] 13% | Training loss: 0.6878872156143189
Epoch: 67 | Iteration number: [620/4518] 13% | Training loss: 0.6878675594445198
Epoch: 67 | Iteration number: [630/4518] 13% | Training loss: 0.6878526942124442
Epoch: 67 | Iteration number: [640/4518] 14% | Training loss: 0.6878386131487787
Epoch: 67 | Iteration number: [650/4518] 14% | Training loss: 0.6878303487484272
Epoch: 67 | Iteration number: [660/4518] 14% | Training loss: 0.6878361798597105
Epoch: 67 | Iteration number: [670/4518] 14% | Training loss: 0.6878182193236565
Epoch: 67 | Iteration number: [680/4518] 15% | Training loss: 0.6878088643445688
Epoch: 67 | Iteration number: [690/4518] 15% | Training loss: 0.6877900920052459
Epoch: 67 | Iteration number: [700/4518] 15% | Training loss: 0.6877494890349252
Epoch: 67 | Iteration number: [710/4518] 15% | Training loss: 0.6877301797900401
Epoch: 67 | Iteration number: [720/4518] 15% | Training loss: 0.687719304776854
Epoch: 67 | Iteration number: [730/4518] 16% | Training loss: 0.6877167046070098
Epoch: 67 | Iteration number: [740/4518] 16% | Training loss: 0.68769379354812
Epoch: 67 | Iteration number: [750/4518] 16% | Training loss: 0.6876857566038768
Epoch: 67 | Iteration number: [760/4518] 16% | Training loss: 0.6876758216243041
Epoch: 67 | Iteration number: [770/4518] 17% | Training loss: 0.6876755782536098
Epoch: 67 | Iteration number: [780/4518] 17% | Training loss: 0.6876531321268815
Epoch: 67 | Iteration number: [790/4518] 17% | Training loss: 0.687637805636925
Epoch: 67 | Iteration number: [800/4518] 17% | Training loss: 0.6876330686360598
Epoch: 67 | Iteration number: [810/4518] 17% | Training loss: 0.6876330853244405
Epoch: 67 | Iteration number: [820/4518] 18% | Training loss: 0.6876368014550791
Epoch: 67 | Iteration number: [830/4518] 18% | Training loss: 0.6876260972884765
Epoch: 67 | Iteration number: [840/4518] 18% | Training loss: 0.687626499576228
Epoch: 67 | Iteration number: [850/4518] 18% | Training loss: 0.6876038281356587
Epoch: 67 | Iteration number: [860/4518] 19% | Training loss: 0.6875896848218386
Epoch: 67 | Iteration number: [870/4518] 19% | Training loss: 0.6875816091038714
Epoch: 67 | Iteration number: [880/4518] 19% | Training loss: 0.6875806816599586
Epoch: 67 | Iteration number: [890/4518] 19% | Training loss: 0.6875530893213293
Epoch: 67 | Iteration number: [900/4518] 19% | Training loss: 0.68754891594251
Epoch: 67 | Iteration number: [910/4518] 20% | Training loss: 0.6875298463381254
Epoch: 67 | Iteration number: [920/4518] 20% | Training loss: 0.6875136556832687
Epoch: 67 | Iteration number: [930/4518] 20% | Training loss: 0.6875180905224174
Epoch: 67 | Iteration number: [940/4518] 20% | Training loss: 0.6875097597533084
Epoch: 67 | Iteration number: [950/4518] 21% | Training loss: 0.6875023887031957
Epoch: 67 | Iteration number: [960/4518] 21% | Training loss: 0.6874910696099202
Epoch: 67 | Iteration number: [970/4518] 21% | Training loss: 0.6874868655327669
Epoch: 67 | Iteration number: [980/4518] 21% | Training loss: 0.6874866706984384
Epoch: 67 | Iteration number: [990/4518] 21% | Training loss: 0.6874749079497173
Epoch: 67 | Iteration number: [1000/4518] 22% | Training loss: 0.687458585202694
Epoch: 67 | Iteration number: [1010/4518] 22% | Training loss: 0.6874595557108965
Epoch: 67 | Iteration number: [1020/4518] 22% | Training loss: 0.6874553160340178
Epoch: 67 | Iteration number: [1030/4518] 22% | Training loss: 0.6874555337776258
Epoch: 67 | Iteration number: [1040/4518] 23% | Training loss: 0.6874518365241014
Epoch: 67 | Iteration number: [1050/4518] 23% | Training loss: 0.6874492175806136
Epoch: 67 | Iteration number: [1060/4518] 23% | Training loss: 0.6874559792145243
Epoch: 67 | Iteration number: [1070/4518] 23% | Training loss: 0.6874682487171387
Epoch: 67 | Iteration number: [1080/4518] 23% | Training loss: 0.6874734155005879
Epoch: 67 | Iteration number: [1090/4518] 24% | Training loss: 0.6874690047644694
Epoch: 67 | Iteration number: [1100/4518] 24% | Training loss: 0.6874641439589587
Epoch: 67 | Iteration number: [1110/4518] 24% | Training loss: 0.687458286092088
Epoch: 67 | Iteration number: [1120/4518] 24% | Training loss: 0.6874520861144576
Epoch: 67 | Iteration number: [1130/4518] 25% | Training loss: 0.6874398250495438
Epoch: 67 | Iteration number: [1140/4518] 25% | Training loss: 0.6874303758144379
Epoch: 67 | Iteration number: [1150/4518] 25% | Training loss: 0.6874210348336594
Epoch: 67 | Iteration number: [1160/4518] 25% | Training loss: 0.6874212914499743
Epoch: 67 | Iteration number: [1170/4518] 25% | Training loss: 0.6874109770497705
Epoch: 67 | Iteration number: [1180/4518] 26% | Training loss: 0.6873952400381282
Epoch: 67 | Iteration number: [1190/4518] 26% | Training loss: 0.6874027035817378
Epoch: 67 | Iteration number: [1200/4518] 26% | Training loss: 0.6873959273099899
Epoch: 67 | Iteration number: [1210/4518] 26% | Training loss: 0.6873887822155125
Epoch: 67 | Iteration number: [1220/4518] 27% | Training loss: 0.6873894785759879
Epoch: 67 | Iteration number: [1230/4518] 27% | Training loss: 0.6873842312068474
Epoch: 67 | Iteration number: [1240/4518] 27% | Training loss: 0.6873788296695679
Epoch: 67 | Iteration number: [1250/4518] 27% | Training loss: 0.6873724946022034
Epoch: 67 | Iteration number: [1260/4518] 27% | Training loss: 0.6873766356044345
Epoch: 67 | Iteration number: [1270/4518] 28% | Training loss: 0.687367923006298
Epoch: 67 | Iteration number: [1280/4518] 28% | Training loss: 0.6873571121133863
Epoch: 67 | Iteration number: [1290/4518] 28% | Training loss: 0.6873448174129161
Epoch: 67 | Iteration number: [1300/4518] 28% | Training loss: 0.6873371334259326
Epoch: 67 | Iteration number: [1310/4518] 28% | Training loss: 0.687343867453
Epoch: 67 | Iteration number: [1320/4518] 29% | Training loss: 0.6873402198607271
Epoch: 67 | Iteration number: [1330/4518] 29% | Training loss: 0.6873299782885645
Epoch: 67 | Iteration number: [1340/4518] 29% | Training loss: 0.6873347218801726
Epoch: 67 | Iteration number: [1350/4518] 29% | Training loss: 0.6873339435789321
Epoch: 67 | Iteration number: [1360/4518] 30% | Training loss: 0.6873314377139597
Epoch: 67 | Iteration number: [1370/4518] 30% | Training loss: 0.6873224346742143
Epoch: 67 | Iteration number: [1380/4518] 30% | Training loss: 0.6873226690551509
Epoch: 67 | Iteration number: [1390/4518] 30% | Training loss: 0.6873223284165636
Epoch: 67 | Iteration number: [1400/4518] 30% | Training loss: 0.6873234367796353
Epoch: 67 | Iteration number: [1410/4518] 31% | Training loss: 0.6873166436421956
Epoch: 67 | Iteration number: [1420/4518] 31% | Training loss: 0.6873117437664892
Epoch: 67 | Iteration number: [1430/4518] 31% | Training loss: 0.687301984075066
Epoch: 67 | Iteration number: [1440/4518] 31% | Training loss: 0.6872997454057137
Epoch: 67 | Iteration number: [1450/4518] 32% | Training loss: 0.6872981353052732
Epoch: 67 | Iteration number: [1460/4518] 32% | Training loss: 0.6872967400371212
Epoch: 67 | Iteration number: [1470/4518] 32% | Training loss: 0.6872929102304031
Epoch: 67 | Iteration number: [1480/4518] 32% | Training loss: 0.6872896097399093
Epoch: 67 | Iteration number: [1490/4518] 32% | Training loss: 0.687282868359713
Epoch: 67 | Iteration number: [1500/4518] 33% | Training loss: 0.6872747929493587
Epoch: 67 | Iteration number: [1510/4518] 33% | Training loss: 0.6872708517589317
Epoch: 67 | Iteration number: [1520/4518] 33% | Training loss: 0.6872719101999936
Epoch: 67 | Iteration number: [1530/4518] 33% | Training loss: 0.6872579493943383
Epoch: 67 | Iteration number: [1540/4518] 34% | Training loss: 0.6872522845283732
Epoch: 67 | Iteration number: [1550/4518] 34% | Training loss: 0.6872525500482128
Epoch: 67 | Iteration number: [1560/4518] 34% | Training loss: 0.6872446769705185
Epoch: 67 | Iteration number: [1570/4518] 34% | Training loss: 0.6872377380443986
Epoch: 67 | Iteration number: [1580/4518] 34% | Training loss: 0.687237133519559
Epoch: 67 | Iteration number: [1590/4518] 35% | Training loss: 0.6872361571159002
Epoch: 67 | Iteration number: [1600/4518] 35% | Training loss: 0.6872309397906065
Epoch: 67 | Iteration number: [1610/4518] 35% | Training loss: 0.6872284717811561
Epoch: 67 | Iteration number: [1620/4518] 35% | Training loss: 0.6872321340036981
Epoch: 67 | Iteration number: [1630/4518] 36% | Training loss: 0.687236383539036
Epoch: 67 | Iteration number: [1640/4518] 36% | Training loss: 0.6872341893068175
Epoch: 67 | Iteration number: [1650/4518] 36% | Training loss: 0.6872322873635726
Epoch: 67 | Iteration number: [1660/4518] 36% | Training loss: 0.6872251503438834
Epoch: 67 | Iteration number: [1670/4518] 36% | Training loss: 0.6872212432101815
Epoch: 67 | Iteration number: [1680/4518] 37% | Training loss: 0.6872180033297766
Epoch: 67 | Iteration number: [1690/4518] 37% | Training loss: 0.6872206114100281
Epoch: 67 | Iteration number: [1700/4518] 37% | Training loss: 0.6872185046181959
Epoch: 67 | Iteration number: [1710/4518] 37% | Training loss: 0.6872181026559127
Epoch: 67 | Iteration number: [1720/4518] 38% | Training loss: 0.6872084330334219
Epoch: 67 | Iteration number: [1730/4518] 38% | Training loss: 0.6871945188913732
Epoch: 67 | Iteration number: [1740/4518] 38% | Training loss: 0.6871919642577227
Epoch: 67 | Iteration number: [1750/4518] 38% | Training loss: 0.6871903357505799
Epoch: 67 | Iteration number: [1760/4518] 38% | Training loss: 0.6871837072074414
Epoch: 67 | Iteration number: [1770/4518] 39% | Training loss: 0.6871867971905207
Epoch: 67 | Iteration number: [1780/4518] 39% | Training loss: 0.6871813194805316
Epoch: 67 | Iteration number: [1790/4518] 39% | Training loss: 0.6871823301528419
Epoch: 67 | Iteration number: [1800/4518] 39% | Training loss: 0.6871808683872223
Epoch: 67 | Iteration number: [1810/4518] 40% | Training loss: 0.6871829965167283
Epoch: 67 | Iteration number: [1820/4518] 40% | Training loss: 0.6871844566130376
Epoch: 67 | Iteration number: [1830/4518] 40% | Training loss: 0.6871835945408201
Epoch: 67 | Iteration number: [1840/4518] 40% | Training loss: 0.6871805926056012
Epoch: 67 | Iteration number: [1850/4518] 40% | Training loss: 0.6871809013791986
Epoch: 67 | Iteration number: [1860/4518] 41% | Training loss: 0.6871755525309552
Epoch: 67 | Iteration number: [1870/4518] 41% | Training loss: 0.6871761791846331
Epoch: 67 | Iteration number: [1880/4518] 41% | Training loss: 0.6871693733207723
Epoch: 67 | Iteration number: [1890/4518] 41% | Training loss: 0.6871708827359336
Epoch: 67 | Iteration number: [1900/4518] 42% | Training loss: 0.6871729749754856
Epoch: 67 | Iteration number: [1910/4518] 42% | Training loss: 0.6871744092222284
Epoch: 67 | Iteration number: [1920/4518] 42% | Training loss: 0.6871759611492355
Epoch: 67 | Iteration number: [1930/4518] 42% | Training loss: 0.6871725958554856
Epoch: 67 | Iteration number: [1940/4518] 42% | Training loss: 0.6871731448419315
Epoch: 67 | Iteration number: [1950/4518] 43% | Training loss: 0.6871651177528577
Epoch: 67 | Iteration number: [1960/4518] 43% | Training loss: 0.6871543463395566
Epoch: 67 | Iteration number: [1970/4518] 43% | Training loss: 0.6871548290785194
Epoch: 67 | Iteration number: [1980/4518] 43% | Training loss: 0.6871560864376299
Epoch: 67 | Iteration number: [1990/4518] 44% | Training loss: 0.6871569737417614
Epoch: 67 | Iteration number: [2000/4518] 44% | Training loss: 0.6871501350402832
Epoch: 67 | Iteration number: [2010/4518] 44% | Training loss: 0.6871461119521317
Epoch: 67 | Iteration number: [2020/4518] 44% | Training loss: 0.6871347447138022
Epoch: 67 | Iteration number: [2030/4518] 44% | Training loss: 0.6871336203196953
Epoch: 67 | Iteration number: [2040/4518] 45% | Training loss: 0.6871300986876675
Epoch: 67 | Iteration number: [2050/4518] 45% | Training loss: 0.6871226720984389
Epoch: 67 | Iteration number: [2060/4518] 45% | Training loss: 0.6871160765006704
Epoch: 67 | Iteration number: [2070/4518] 45% | Training loss: 0.6871134983744598
Epoch: 67 | Iteration number: [2080/4518] 46% | Training loss: 0.6871201033775624
Epoch: 67 | Iteration number: [2090/4518] 46% | Training loss: 0.6871146379475388
Epoch: 67 | Iteration number: [2100/4518] 46% | Training loss: 0.6871077311038971
Epoch: 67 | Iteration number: [2110/4518] 46% | Training loss: 0.68710847672128
Epoch: 67 | Iteration number: [2120/4518] 46% | Training loss: 0.6871070799681376
Epoch: 67 | Iteration number: [2130/4518] 47% | Training loss: 0.6871067789238943
Epoch: 67 | Iteration number: [2140/4518] 47% | Training loss: 0.6871029730990669
Epoch: 67 | Iteration number: [2150/4518] 47% | Training loss: 0.6871032449256542
Epoch: 67 | Iteration number: [2160/4518] 47% | Training loss: 0.6871076121926307
Epoch: 67 | Iteration number: [2170/4518] 48% | Training loss: 0.6871066627689221
Epoch: 67 | Iteration number: [2180/4518] 48% | Training loss: 0.6871074327088277
Epoch: 67 | Iteration number: [2190/4518] 48% | Training loss: 0.6871109783377277
Epoch: 67 | Iteration number: [2200/4518] 48% | Training loss: 0.6871053850379857
Epoch: 67 | Iteration number: [2210/4518] 48% | Training loss: 0.6871087192949666
Epoch: 67 | Iteration number: [2220/4518] 49% | Training loss: 0.687106825478442
Epoch: 67 | Iteration number: [2230/4518] 49% | Training loss: 0.687097881968246
Epoch: 67 | Iteration number: [2240/4518] 49% | Training loss: 0.6870892371982336
Epoch: 67 | Iteration number: [2250/4518] 49% | Training loss: 0.6870875940852695
Epoch: 67 | Iteration number: [2260/4518] 50% | Training loss: 0.6870867240481672
Epoch: 67 | Iteration number: [2270/4518] 50% | Training loss: 0.6870902701096387
Epoch: 67 | Iteration number: [2280/4518] 50% | Training loss: 0.6870839930678668
Epoch: 67 | Iteration number: [2290/4518] 50% | Training loss: 0.6870814491827936
Epoch: 67 | Iteration number: [2300/4518] 50% | Training loss: 0.6870798736033232
Epoch: 67 | Iteration number: [2310/4518] 51% | Training loss: 0.6870784555420731
Epoch: 67 | Iteration number: [2320/4518] 51% | Training loss: 0.6870745639605769
Epoch: 67 | Iteration number: [2330/4518] 51% | Training loss: 0.687077977140574
Epoch: 67 | Iteration number: [2340/4518] 51% | Training loss: 0.6870766464461628
Epoch: 67 | Iteration number: [2350/4518] 52% | Training loss: 0.6870698782230945
Epoch: 67 | Iteration number: [2360/4518] 52% | Training loss: 0.6870687022047528
Epoch: 67 | Iteration number: [2370/4518] 52% | Training loss: 0.6870660486855085
Epoch: 67 | Iteration number: [2380/4518] 52% | Training loss: 0.6870636900432971
Epoch: 67 | Iteration number: [2390/4518] 52% | Training loss: 0.6870562482329093
Epoch: 67 | Iteration number: [2400/4518] 53% | Training loss: 0.6870503710707029
Epoch: 67 | Iteration number: [2410/4518] 53% | Training loss: 0.6870501428471562
Epoch: 67 | Iteration number: [2420/4518] 53% | Training loss: 0.6870433320437581
Epoch: 67 | Iteration number: [2430/4518] 53% | Training loss: 0.6870390949425874
Epoch: 67 | Iteration number: [2440/4518] 54% | Training loss: 0.6870379718112164
Epoch: 67 | Iteration number: [2450/4518] 54% | Training loss: 0.6870406575592197
Epoch: 67 | Iteration number: [2460/4518] 54% | Training loss: 0.687037997274864
Epoch: 67 | Iteration number: [2470/4518] 54% | Training loss: 0.6870377654006125
Epoch: 67 | Iteration number: [2480/4518] 54% | Training loss: 0.6870349874900233
Epoch: 67 | Iteration number: [2490/4518] 55% | Training loss: 0.6870315144579094
Epoch: 67 | Iteration number: [2500/4518] 55% | Training loss: 0.6870319813966751
Epoch: 67 | Iteration number: [2510/4518] 55% | Training loss: 0.6870270685845637
Epoch: 67 | Iteration number: [2520/4518] 55% | Training loss: 0.6870238694879743
Epoch: 67 | Iteration number: [2530/4518] 55% | Training loss: 0.687018300657687
Epoch: 67 | Iteration number: [2540/4518] 56% | Training loss: 0.6870198740264563
Epoch: 67 | Iteration number: [2550/4518] 56% | Training loss: 0.6870195957959867
Epoch: 67 | Iteration number: [2560/4518] 56% | Training loss: 0.6870181625243277
Epoch: 67 | Iteration number: [2570/4518] 56% | Training loss: 0.6870206190454357
Epoch: 67 | Iteration number: [2580/4518] 57% | Training loss: 0.68701881449814
Epoch: 67 | Iteration number: [2590/4518] 57% | Training loss: 0.6870233767511301
Epoch: 67 | Iteration number: [2600/4518] 57% | Training loss: 0.6870223985727016
Epoch: 67 | Iteration number: [2610/4518] 57% | Training loss: 0.6870204161181761
Epoch: 67 | Iteration number: [2620/4518] 57% | Training loss: 0.6870222306661024
Epoch: 67 | Iteration number: [2630/4518] 58% | Training loss: 0.6870178816662995
Epoch: 67 | Iteration number: [2640/4518] 58% | Training loss: 0.6870124667657144
Epoch: 67 | Iteration number: [2650/4518] 58% | Training loss: 0.6870063412864253
Epoch: 67 | Iteration number: [2660/4518] 58% | Training loss: 0.6870085084124615
Epoch: 67 | Iteration number: [2670/4518] 59% | Training loss: 0.6869997889808055
Epoch: 67 | Iteration number: [2680/4518] 59% | Training loss: 0.6869986072182656
Epoch: 67 | Iteration number: [2690/4518] 59% | Training loss: 0.686996070536539
Epoch: 67 | Iteration number: [2700/4518] 59% | Training loss: 0.6869948229083308
Epoch: 67 | Iteration number: [2710/4518] 59% | Training loss: 0.6869927813646098
Epoch: 67 | Iteration number: [2720/4518] 60% | Training loss: 0.6869964444023722
Epoch: 67 | Iteration number: [2730/4518] 60% | Training loss: 0.6869904698688032
Epoch: 67 | Iteration number: [2740/4518] 60% | Training loss: 0.686989109424779
Epoch: 67 | Iteration number: [2750/4518] 60% | Training loss: 0.686988715952093
Epoch: 67 | Iteration number: [2760/4518] 61% | Training loss: 0.686982339275056
Epoch: 67 | Iteration number: [2770/4518] 61% | Training loss: 0.686979862455857
Epoch: 67 | Iteration number: [2780/4518] 61% | Training loss: 0.6869806968908516
Epoch: 67 | Iteration number: [2790/4518] 61% | Training loss: 0.6869805456276008
Epoch: 67 | Iteration number: [2800/4518] 61% | Training loss: 0.6869799990952015
Epoch: 67 | Iteration number: [2810/4518] 62% | Training loss: 0.6869799526560774
Epoch: 67 | Iteration number: [2820/4518] 62% | Training loss: 0.686981811274028
Epoch: 67 | Iteration number: [2830/4518] 62% | Training loss: 0.6869782781432459
Epoch: 67 | Iteration number: [2840/4518] 62% | Training loss: 0.6869811780226063
Epoch: 67 | Iteration number: [2850/4518] 63% | Training loss: 0.6869817953778986
Epoch: 67 | Iteration number: [2860/4518] 63% | Training loss: 0.6869790473601202
Epoch: 67 | Iteration number: [2870/4518] 63% | Training loss: 0.6869748948135442
Epoch: 67 | Iteration number: [2880/4518] 63% | Training loss: 0.6869771659167276
Epoch: 67 | Iteration number: [2890/4518] 63% | Training loss: 0.6869778500708742
Epoch: 67 | Iteration number: [2900/4518] 64% | Training loss: 0.686972110538647
Epoch: 67 | Iteration number: [2910/4518] 64% | Training loss: 0.6869711942484289
Epoch: 67 | Iteration number: [2920/4518] 64% | Training loss: 0.6869693315600696
Epoch: 67 | Iteration number: [2930/4518] 64% | Training loss: 0.6869731078375728
Epoch: 67 | Iteration number: [2940/4518] 65% | Training loss: 0.6869741907533334
Epoch: 67 | Iteration number: [2950/4518] 65% | Training loss: 0.6869753111216982
Epoch: 67 | Iteration number: [2960/4518] 65% | Training loss: 0.6869756459585719
Epoch: 67 | Iteration number: [2970/4518] 65% | Training loss: 0.6869760051319495
Epoch: 67 | Iteration number: [2980/4518] 65% | Training loss: 0.686978804885141
Epoch: 67 | Iteration number: [2990/4518] 66% | Training loss: 0.6869805552090291
Epoch: 67 | Iteration number: [3000/4518] 66% | Training loss: 0.6869844096104304
Epoch: 67 | Iteration number: [3010/4518] 66% | Training loss: 0.6869854463889353
Epoch: 67 | Iteration number: [3020/4518] 66% | Training loss: 0.6869854667131474
Epoch: 67 | Iteration number: [3030/4518] 67% | Training loss: 0.6869852109120624
Epoch: 67 | Iteration number: [3040/4518] 67% | Training loss: 0.6869879054591844
Epoch: 67 | Iteration number: [3050/4518] 67% | Training loss: 0.6869914493599876
Epoch: 67 | Iteration number: [3060/4518] 67% | Training loss: 0.6869910820636874
Epoch: 67 | Iteration number: [3070/4518] 67% | Training loss: 0.6869943634694873
Epoch: 67 | Iteration number: [3080/4518] 68% | Training loss: 0.6869973948636612
Epoch: 67 | Iteration number: [3090/4518] 68% | Training loss: 0.6869964090172913
Epoch: 67 | Iteration number: [3100/4518] 68% | Training loss: 0.6869961703785005
Epoch: 67 | Iteration number: [3110/4518] 68% | Training loss: 0.6869957251372445
Epoch: 67 | Iteration number: [3120/4518] 69% | Training loss: 0.6869975899847655
Epoch: 67 | Iteration number: [3130/4518] 69% | Training loss: 0.6869979853256822
Epoch: 67 | Iteration number: [3140/4518] 69% | Training loss: 0.68699717333742
Epoch: 67 | Iteration number: [3150/4518] 69% | Training loss: 0.6869960557279132
Epoch: 67 | Iteration number: [3160/4518] 69% | Training loss: 0.686991283240952
Epoch: 67 | Iteration number: [3170/4518] 70% | Training loss: 0.686990536631846
Epoch: 67 | Iteration number: [3180/4518] 70% | Training loss: 0.6869886716956612
Epoch: 67 | Iteration number: [3190/4518] 70% | Training loss: 0.6869862961544886
Epoch: 67 | Iteration number: [3200/4518] 70% | Training loss: 0.6869891544990242
Epoch: 67 | Iteration number: [3210/4518] 71% | Training loss: 0.6869846497183648
Epoch: 67 | Iteration number: [3220/4518] 71% | Training loss: 0.6869819254793735
Epoch: 67 | Iteration number: [3230/4518] 71% | Training loss: 0.6869812702985002
Epoch: 67 | Iteration number: [3240/4518] 71% | Training loss: 0.6869832850348803
Epoch: 67 | Iteration number: [3250/4518] 71% | Training loss: 0.6869851629917438
Epoch: 67 | Iteration number: [3260/4518] 72% | Training loss: 0.686983303552025
Epoch: 67 | Iteration number: [3270/4518] 72% | Training loss: 0.686981350110576
Epoch: 67 | Iteration number: [3280/4518] 72% | Training loss: 0.6869804579128579
Epoch: 67 | Iteration number: [3290/4518] 72% | Training loss: 0.6869786635539452
Epoch: 67 | Iteration number: [3300/4518] 73% | Training loss: 0.6869781253554604
Epoch: 67 | Iteration number: [3310/4518] 73% | Training loss: 0.6869764056270576
Epoch: 67 | Iteration number: [3320/4518] 73% | Training loss: 0.6869737176112382
Epoch: 67 | Iteration number: [3330/4518] 73% | Training loss: 0.6869772806360915
Epoch: 67 | Iteration number: [3340/4518] 73% | Training loss: 0.686976677090108
Epoch: 67 | Iteration number: [3350/4518] 74% | Training loss: 0.6869773282221894
Epoch: 67 | Iteration number: [3360/4518] 74% | Training loss: 0.6869771065633922
Epoch: 67 | Iteration number: [3370/4518] 74% | Training loss: 0.6869756102031346
Epoch: 67 | Iteration number: [3380/4518] 74% | Training loss: 0.6869751213570319
Epoch: 67 | Iteration number: [3390/4518] 75% | Training loss: 0.6869777694915952
Epoch: 67 | Iteration number: [3400/4518] 75% | Training loss: 0.6869737508542397
Epoch: 67 | Iteration number: [3410/4518] 75% | Training loss: 0.6869708909491989
Epoch: 67 | Iteration number: [3420/4518] 75% | Training loss: 0.6869736620557239
Epoch: 67 | Iteration number: [3430/4518] 75% | Training loss: 0.686977370695887
Epoch: 67 | Iteration number: [3440/4518] 76% | Training loss: 0.6869767496752185
Epoch: 67 | Iteration number: [3450/4518] 76% | Training loss: 0.6869772333856942
Epoch: 67 | Iteration number: [3460/4518] 76% | Training loss: 0.6869764419821646
Epoch: 67 | Iteration number: [3470/4518] 76% | Training loss: 0.6869773771474272
Epoch: 67 | Iteration number: [3480/4518] 77% | Training loss: 0.6869753776610583
Epoch: 67 | Iteration number: [3490/4518] 77% | Training loss: 0.6869770051585911
Epoch: 67 | Iteration number: [3500/4518] 77% | Training loss: 0.6869763832262584
Epoch: 67 | Iteration number: [3510/4518] 77% | Training loss: 0.6869760049034728
Epoch: 67 | Iteration number: [3520/4518] 77% | Training loss: 0.6869766706092791
Epoch: 67 | Iteration number: [3530/4518] 78% | Training loss: 0.6869758900265518
Epoch: 67 | Iteration number: [3540/4518] 78% | Training loss: 0.6869749495201866
Epoch: 67 | Iteration number: [3550/4518] 78% | Training loss: 0.6869751887758013
Epoch: 67 | Iteration number: [3560/4518] 78% | Training loss: 0.6869722308737508
Epoch: 67 | Iteration number: [3570/4518] 79% | Training loss: 0.6869666948872788
Epoch: 67 | Iteration number: [3580/4518] 79% | Training loss: 0.6869668241153216
Epoch: 67 | Iteration number: [3590/4518] 79% | Training loss: 0.6869630908069504
Epoch: 67 | Iteration number: [3600/4518] 79% | Training loss: 0.6869607365131378
Epoch: 67 | Iteration number: [3610/4518] 79% | Training loss: 0.6869586178965846
Epoch: 67 | Iteration number: [3620/4518] 80% | Training loss: 0.6869552383436024
Epoch: 67 | Iteration number: [3630/4518] 80% | Training loss: 0.6869549685109089
Epoch: 67 | Iteration number: [3640/4518] 80% | Training loss: 0.6869554821115273
Epoch: 67 | Iteration number: [3650/4518] 80% | Training loss: 0.6869544990911876
Epoch: 67 | Iteration number: [3660/4518] 81% | Training loss: 0.6869512417440206
Epoch: 67 | Iteration number: [3670/4518] 81% | Training loss: 0.6869488736264387
Epoch: 67 | Iteration number: [3680/4518] 81% | Training loss: 0.6869499452574097
Epoch: 67 | Iteration number: [3690/4518] 81% | Training loss: 0.6869522470284284
Epoch: 67 | Iteration number: [3700/4518] 81% | Training loss: 0.6869472235763395
Epoch: 67 | Iteration number: [3710/4518] 82% | Training loss: 0.6869482197369526
Epoch: 67 | Iteration number: [3720/4518] 82% | Training loss: 0.686948395079823
Epoch: 67 | Iteration number: [3730/4518] 82% | Training loss: 0.6869480683720464
Epoch: 67 | Iteration number: [3740/4518] 82% | Training loss: 0.6869474922590715
Epoch: 67 | Iteration number: [3750/4518] 83% | Training loss: 0.6869461524804433
Epoch: 67 | Iteration number: [3760/4518] 83% | Training loss: 0.6869505052553847
Epoch: 67 | Iteration number: [3770/4518] 83% | Training loss: 0.6869508207792945
Epoch: 67 | Iteration number: [3780/4518] 83% | Training loss: 0.686948287818167
Epoch: 67 | Iteration number: [3790/4518] 83% | Training loss: 0.6869506429871028
Epoch: 67 | Iteration number: [3800/4518] 84% | Training loss: 0.686949707614748
Epoch: 67 | Iteration number: [3810/4518] 84% | Training loss: 0.6869500334963711
Epoch: 67 | Iteration number: [3820/4518] 84% | Training loss: 0.6869474124065869
Epoch: 67 | Iteration number: [3830/4518] 84% | Training loss: 0.686946016550064
Epoch: 67 | Iteration number: [3840/4518] 84% | Training loss: 0.686942891869694
Epoch: 67 | Iteration number: [3850/4518] 85% | Training loss: 0.6869412758752897
Epoch: 67 | Iteration number: [3860/4518] 85% | Training loss: 0.6869412421716927
Epoch: 67 | Iteration number: [3870/4518] 85% | Training loss: 0.686942667354293
Epoch: 67 | Iteration number: [3880/4518] 85% | Training loss: 0.6869427791114935
Epoch: 67 | Iteration number: [3890/4518] 86% | Training loss: 0.6869413094839277
Epoch: 67 | Iteration number: [3900/4518] 86% | Training loss: 0.6869439299901327
Epoch: 67 | Iteration number: [3910/4518] 86% | Training loss: 0.6869441747817847
Epoch: 67 | Iteration number: [3920/4518] 86% | Training loss: 0.6869413597547278
Epoch: 67 | Iteration number: [3930/4518] 86% | Training loss: 0.6869429174422005
Epoch: 67 | Iteration number: [3940/4518] 87% | Training loss: 0.6869428450686073
Epoch: 67 | Iteration number: [3950/4518] 87% | Training loss: 0.6869434359405614
Epoch: 67 | Iteration number: [3960/4518] 87% | Training loss: 0.6869422395723035
Epoch: 67 | Iteration number: [3970/4518] 87% | Training loss: 0.6869437946780803
Epoch: 67 | Iteration number: [3980/4518] 88% | Training loss: 0.6869439895278845
Epoch: 67 | Iteration number: [3990/4518] 88% | Training loss: 0.6869437553978205
Epoch: 67 | Iteration number: [4000/4518] 88% | Training loss: 0.6869443591237068
Epoch: 67 | Iteration number: [4010/4518] 88% | Training loss: 0.6869423204378
Epoch: 67 | Iteration number: [4020/4518] 88% | Training loss: 0.6869414032988287
Epoch: 67 | Iteration number: [4030/4518] 89% | Training loss: 0.6869413973232061
Epoch: 67 | Iteration number: [4040/4518] 89% | Training loss: 0.6869403235835604
Epoch: 67 | Iteration number: [4050/4518] 89% | Training loss: 0.6869369334939085
Epoch: 67 | Iteration number: [4060/4518] 89% | Training loss: 0.6869361374031734
Epoch: 67 | Iteration number: [4070/4518] 90% | Training loss: 0.6869327954197398
Epoch: 67 | Iteration number: [4080/4518] 90% | Training loss: 0.6869338376849305
Epoch: 67 | Iteration number: [4090/4518] 90% | Training loss: 0.6869323231625964
Epoch: 67 | Iteration number: [4100/4518] 90% | Training loss: 0.6869324019042456
Epoch: 67 | Iteration number: [4110/4518] 90% | Training loss: 0.6869309516573764
Epoch: 67 | Iteration number: [4120/4518] 91% | Training loss: 0.6869305271112803
Epoch: 67 | Iteration number: [4130/4518] 91% | Training loss: 0.6869291440193648
Epoch: 67 | Iteration number: [4140/4518] 91% | Training loss: 0.6869289662095084
Epoch: 67 | Iteration number: [4150/4518] 91% | Training loss: 0.6869285350678915
Epoch: 67 | Iteration number: [4160/4518] 92% | Training loss: 0.6869291464153391
Epoch: 67 | Iteration number: [4170/4518] 92% | Training loss: 0.6869262659006553
Epoch: 67 | Iteration number: [4180/4518] 92% | Training loss: 0.6869277293887435
Epoch: 67 | Iteration number: [4190/4518] 92% | Training loss: 0.6869273585891951
Epoch: 67 | Iteration number: [4200/4518] 92% | Training loss: 0.686926682023775
Epoch: 67 | Iteration number: [4210/4518] 93% | Training loss: 0.6869251063912045
Epoch: 67 | Iteration number: [4220/4518] 93% | Training loss: 0.6869257741488551
Epoch: 67 | Iteration number: [4230/4518] 93% | Training loss: 0.6869242801592987
Epoch: 67 | Iteration number: [4240/4518] 93% | Training loss: 0.686924251323601
Epoch: 67 | Iteration number: [4250/4518] 94% | Training loss: 0.6869217070972218
Epoch: 67 | Iteration number: [4260/4518] 94% | Training loss: 0.6869224894494518
Epoch: 67 | Iteration number: [4270/4518] 94% | Training loss: 0.6869241668831827
Epoch: 67 | Iteration number: [4280/4518] 94% | Training loss: 0.6869269478543897
Epoch: 67 | Iteration number: [4290/4518] 94% | Training loss: 0.686924261924548
Epoch: 67 | Iteration number: [4300/4518] 95% | Training loss: 0.6869262690876805
Epoch: 67 | Iteration number: [4310/4518] 95% | Training loss: 0.6869257761403192
Epoch: 67 | Iteration number: [4320/4518] 95% | Training loss: 0.6869277782186314
Epoch: 67 | Iteration number: [4330/4518] 95% | Training loss: 0.6869299003764058
Epoch: 67 | Iteration number: [4340/4518] 96% | Training loss: 0.6869308733857722
Epoch: 67 | Iteration number: [4350/4518] 96% | Training loss: 0.6869291851575348
Epoch: 67 | Iteration number: [4360/4518] 96% | Training loss: 0.6869280277452338
Epoch: 67 | Iteration number: [4370/4518] 96% | Training loss: 0.6869270250644509
Epoch: 67 | Iteration number: [4380/4518] 96% | Training loss: 0.6869253215588391
Epoch: 67 | Iteration number: [4390/4518] 97% | Training loss: 0.6869268375268558
Epoch: 67 | Iteration number: [4400/4518] 97% | Training loss: 0.6869244706088846
Epoch: 67 | Iteration number: [4410/4518] 97% | Training loss: 0.6869282938185193
Epoch: 67 | Iteration number: [4420/4518] 97% | Training loss: 0.686926640806155
Epoch: 67 | Iteration number: [4430/4518] 98% | Training loss: 0.6869260104192298
Epoch: 67 | Iteration number: [4440/4518] 98% | Training loss: 0.6869283933628787
Epoch: 67 | Iteration number: [4450/4518] 98% | Training loss: 0.686924545363094
Epoch: 67 | Iteration number: [4460/4518] 98% | Training loss: 0.6869253095222696
Epoch: 67 | Iteration number: [4470/4518] 98% | Training loss: 0.6869230580409901
Epoch: 67 | Iteration number: [4480/4518] 99% | Training loss: 0.6869246834489916
Epoch: 67 | Iteration number: [4490/4518] 99% | Training loss: 0.6869276542175055
Epoch: 67 | Iteration number: [4500/4518] 99% | Training loss: 0.6869286236498091
Epoch: 67 | Iteration number: [4510/4518] 99% | Training loss: 0.6869293020728422

 End of epoch: 67 | Train Loss: 0.6867775807949545 | Training Time: 633 

 End of epoch: 67 | Eval Loss: 0.6896722791146259 | Evaluating Time: 16 
Epoch: 68 | Iteration number: [10/4518] 0% | Training loss: 0.7545758962631226
Epoch: 68 | Iteration number: [20/4518] 0% | Training loss: 0.7211301654577256
Epoch: 68 | Iteration number: [30/4518] 0% | Training loss: 0.7094468156496684
Epoch: 68 | Iteration number: [40/4518] 0% | Training loss: 0.7039429828524589
Epoch: 68 | Iteration number: [50/4518] 1% | Training loss: 0.7005161499977112
Epoch: 68 | Iteration number: [60/4518] 1% | Training loss: 0.6982944041490555
Epoch: 68 | Iteration number: [70/4518] 1% | Training loss: 0.6965310088225773
Epoch: 68 | Iteration number: [80/4518] 1% | Training loss: 0.6952756106853485
Epoch: 68 | Iteration number: [90/4518] 1% | Training loss: 0.6943694174289703
Epoch: 68 | Iteration number: [100/4518] 2% | Training loss: 0.6935455441474915
Epoch: 68 | Iteration number: [110/4518] 2% | Training loss: 0.6929767207665877
Epoch: 68 | Iteration number: [120/4518] 2% | Training loss: 0.6924008091290792
Epoch: 68 | Iteration number: [130/4518] 2% | Training loss: 0.6919164799726927
Epoch: 68 | Iteration number: [140/4518] 3% | Training loss: 0.6914987806762968
Epoch: 68 | Iteration number: [150/4518] 3% | Training loss: 0.6911606081326802
Epoch: 68 | Iteration number: [160/4518] 3% | Training loss: 0.6909401897341013
Epoch: 68 | Iteration number: [170/4518] 3% | Training loss: 0.6907113464439616
Epoch: 68 | Iteration number: [180/4518] 3% | Training loss: 0.6904375384251277
Epoch: 68 | Iteration number: [190/4518] 4% | Training loss: 0.6902818124545248
Epoch: 68 | Iteration number: [200/4518] 4% | Training loss: 0.6901333403587341
Epoch: 68 | Iteration number: [210/4518] 4% | Training loss: 0.6899562463873908
Epoch: 68 | Iteration number: [220/4518] 4% | Training loss: 0.6897947276180441
Epoch: 68 | Iteration number: [230/4518] 5% | Training loss: 0.6896993375342825
Epoch: 68 | Iteration number: [240/4518] 5% | Training loss: 0.6895480091373126
Epoch: 68 | Iteration number: [250/4518] 5% | Training loss: 0.6894661102294922
Epoch: 68 | Iteration number: [260/4518] 5% | Training loss: 0.6893256201193882
Epoch: 68 | Iteration number: [270/4518] 5% | Training loss: 0.6892348048863588
Epoch: 68 | Iteration number: [280/4518] 6% | Training loss: 0.6891652532986232
Epoch: 68 | Iteration number: [290/4518] 6% | Training loss: 0.6891036027464373
Epoch: 68 | Iteration number: [300/4518] 6% | Training loss: 0.6890449102719625
Epoch: 68 | Iteration number: [310/4518] 6% | Training loss: 0.688985046071391
Epoch: 68 | Iteration number: [320/4518] 7% | Training loss: 0.6888889081776142
Epoch: 68 | Iteration number: [330/4518] 7% | Training loss: 0.6888841813260859
Epoch: 68 | Iteration number: [340/4518] 7% | Training loss: 0.688805096114383
Epoch: 68 | Iteration number: [350/4518] 7% | Training loss: 0.6887772853033883
Epoch: 68 | Iteration number: [360/4518] 7% | Training loss: 0.6887280121445656
Epoch: 68 | Iteration number: [370/4518] 8% | Training loss: 0.6886919326073414
Epoch: 68 | Iteration number: [380/4518] 8% | Training loss: 0.6886344650858327
Epoch: 68 | Iteration number: [390/4518] 8% | Training loss: 0.6885813758923457
Epoch: 68 | Iteration number: [400/4518] 8% | Training loss: 0.6885631729662418
Epoch: 68 | Iteration number: [410/4518] 9% | Training loss: 0.6885210695790082
Epoch: 68 | Iteration number: [420/4518] 9% | Training loss: 0.6884696099020186
Epoch: 68 | Iteration number: [430/4518] 9% | Training loss: 0.688426235526107
Epoch: 68 | Iteration number: [440/4518] 9% | Training loss: 0.6883768194101073
Epoch: 68 | Iteration number: [450/4518] 9% | Training loss: 0.6883456243409051
Epoch: 68 | Iteration number: [460/4518] 10% | Training loss: 0.6883173945157425
Epoch: 68 | Iteration number: [470/4518] 10% | Training loss: 0.6882795567208148
Epoch: 68 | Iteration number: [480/4518] 10% | Training loss: 0.6882476606716712
Epoch: 68 | Iteration number: [490/4518] 10% | Training loss: 0.6881998109574221
Epoch: 68 | Iteration number: [500/4518] 11% | Training loss: 0.6881697696447372
Epoch: 68 | Iteration number: [510/4518] 11% | Training loss: 0.6881234999965219
Epoch: 68 | Iteration number: [520/4518] 11% | Training loss: 0.6880838919144411
Epoch: 68 | Iteration number: [530/4518] 11% | Training loss: 0.6880743833083027
Epoch: 68 | Iteration number: [540/4518] 11% | Training loss: 0.6880733870797687
Epoch: 68 | Iteration number: [550/4518] 12% | Training loss: 0.6880343816497109
Epoch: 68 | Iteration number: [560/4518] 12% | Training loss: 0.6879951035337789
Epoch: 68 | Iteration number: [570/4518] 12% | Training loss: 0.6879716489398688
Epoch: 68 | Iteration number: [580/4518] 12% | Training loss: 0.6879642492738264
Epoch: 68 | Iteration number: [590/4518] 13% | Training loss: 0.6879018927024583
Epoch: 68 | Iteration number: [600/4518] 13% | Training loss: 0.6879044829805692
Epoch: 68 | Iteration number: [610/4518] 13% | Training loss: 0.6878965391487372
Epoch: 68 | Iteration number: [620/4518] 13% | Training loss: 0.6878908586117529
Epoch: 68 | Iteration number: [630/4518] 13% | Training loss: 0.6878717549263484
Epoch: 68 | Iteration number: [640/4518] 14% | Training loss: 0.6878511914983392
Epoch: 68 | Iteration number: [650/4518] 14% | Training loss: 0.6878356196330144
Epoch: 68 | Iteration number: [660/4518] 14% | Training loss: 0.6878223032662363
Epoch: 68 | Iteration number: [670/4518] 14% | Training loss: 0.6878002100026429
Epoch: 68 | Iteration number: [680/4518] 15% | Training loss: 0.687784442217911
Epoch: 68 | Iteration number: [690/4518] 15% | Training loss: 0.6877615366293036
Epoch: 68 | Iteration number: [700/4518] 15% | Training loss: 0.6877312682356154
Epoch: 68 | Iteration number: [710/4518] 15% | Training loss: 0.687714725984654
Epoch: 68 | Iteration number: [720/4518] 15% | Training loss: 0.6876941275265481
Epoch: 68 | Iteration number: [730/4518] 16% | Training loss: 0.68766923514131
Epoch: 68 | Iteration number: [740/4518] 16% | Training loss: 0.6876568072551006
Epoch: 68 | Iteration number: [750/4518] 16% | Training loss: 0.6876489752133688
Epoch: 68 | Iteration number: [760/4518] 16% | Training loss: 0.6876371059762804
Epoch: 68 | Iteration number: [770/4518] 17% | Training loss: 0.6876280276032237
Epoch: 68 | Iteration number: [780/4518] 17% | Training loss: 0.687599854133068
Epoch: 68 | Iteration number: [790/4518] 17% | Training loss: 0.6875880688806123
Epoch: 68 | Iteration number: [800/4518] 17% | Training loss: 0.6875766806304455
Epoch: 68 | Iteration number: [810/4518] 17% | Training loss: 0.6875367137385003
Epoch: 68 | Iteration number: [820/4518] 18% | Training loss: 0.6875451239870816
Epoch: 68 | Iteration number: [830/4518] 18% | Training loss: 0.687536229139351
Epoch: 68 | Iteration number: [840/4518] 18% | Training loss: 0.6875297380345208
Epoch: 68 | Iteration number: [850/4518] 18% | Training loss: 0.6875136011488298
Epoch: 68 | Iteration number: [860/4518] 19% | Training loss: 0.687511515755986
Epoch: 68 | Iteration number: [870/4518] 19% | Training loss: 0.6875182561490728
Epoch: 68 | Iteration number: [880/4518] 19% | Training loss: 0.6875134025107731
Epoch: 68 | Iteration number: [890/4518] 19% | Training loss: 0.6875135379560878
Epoch: 68 | Iteration number: [900/4518] 19% | Training loss: 0.6875157472160127
Epoch: 68 | Iteration number: [910/4518] 20% | Training loss: 0.6875179759093694
Epoch: 68 | Iteration number: [920/4518] 20% | Training loss: 0.6875193154682284
Epoch: 68 | Iteration number: [930/4518] 20% | Training loss: 0.6875191889783387
Epoch: 68 | Iteration number: [940/4518] 20% | Training loss: 0.6874983189587898
Epoch: 68 | Iteration number: [950/4518] 21% | Training loss: 0.6874890717079765
Epoch: 68 | Iteration number: [960/4518] 21% | Training loss: 0.6874763878062368
Epoch: 68 | Iteration number: [970/4518] 21% | Training loss: 0.6874865573706086
Epoch: 68 | Iteration number: [980/4518] 21% | Training loss: 0.6874671248757109
Epoch: 68 | Iteration number: [990/4518] 21% | Training loss: 0.687459961332456
Epoch: 68 | Iteration number: [1000/4518] 22% | Training loss: 0.6874434468746186
Epoch: 68 | Iteration number: [1010/4518] 22% | Training loss: 0.6874478920851603
Epoch: 68 | Iteration number: [1020/4518] 22% | Training loss: 0.6874494850051169
Epoch: 68 | Iteration number: [1030/4518] 22% | Training loss: 0.6874438115115304
Epoch: 68 | Iteration number: [1040/4518] 23% | Training loss: 0.6874416935329254
Epoch: 68 | Iteration number: [1050/4518] 23% | Training loss: 0.6874233018216632
Epoch: 68 | Iteration number: [1060/4518] 23% | Training loss: 0.6874128585716464
Epoch: 68 | Iteration number: [1070/4518] 23% | Training loss: 0.68741324354555
Epoch: 68 | Iteration number: [1080/4518] 23% | Training loss: 0.6874095401830144
Epoch: 68 | Iteration number: [1090/4518] 24% | Training loss: 0.6873970914324489
Epoch: 68 | Iteration number: [1100/4518] 24% | Training loss: 0.6873913772539659
Epoch: 68 | Iteration number: [1110/4518] 24% | Training loss: 0.6873865028222402
Epoch: 68 | Iteration number: [1120/4518] 24% | Training loss: 0.6873871013522148
Epoch: 68 | Iteration number: [1130/4518] 25% | Training loss: 0.6873809240560615
Epoch: 68 | Iteration number: [1140/4518] 25% | Training loss: 0.6873711638283311
Epoch: 68 | Iteration number: [1150/4518] 25% | Training loss: 0.6873624904259391
Epoch: 68 | Iteration number: [1160/4518] 25% | Training loss: 0.6873533212419214
Epoch: 68 | Iteration number: [1170/4518] 25% | Training loss: 0.6873520751794179
Epoch: 68 | Iteration number: [1180/4518] 26% | Training loss: 0.6873492089368529
Epoch: 68 | Iteration number: [1190/4518] 26% | Training loss: 0.6873478934544475
Epoch: 68 | Iteration number: [1200/4518] 26% | Training loss: 0.6873491170008977
Epoch: 68 | Iteration number: [1210/4518] 26% | Training loss: 0.6873469702468431
Epoch: 68 | Iteration number: [1220/4518] 27% | Training loss: 0.6873416293351376
Epoch: 68 | Iteration number: [1230/4518] 27% | Training loss: 0.6873395688165495
Epoch: 68 | Iteration number: [1240/4518] 27% | Training loss: 0.6873349695436416
Epoch: 68 | Iteration number: [1250/4518] 27% | Training loss: 0.687336613035202
Epoch: 68 | Iteration number: [1260/4518] 27% | Training loss: 0.6873364324607546
Epoch: 68 | Iteration number: [1270/4518] 28% | Training loss: 0.6873286955938565
Epoch: 68 | Iteration number: [1280/4518] 28% | Training loss: 0.6873191029764711
Epoch: 68 | Iteration number: [1290/4518] 28% | Training loss: 0.6873132631298183
Epoch: 68 | Iteration number: [1300/4518] 28% | Training loss: 0.6872998570020382
Epoch: 68 | Iteration number: [1310/4518] 28% | Training loss: 0.6872929988471607
Epoch: 68 | Iteration number: [1320/4518] 29% | Training loss: 0.6872868585767168
Epoch: 68 | Iteration number: [1330/4518] 29% | Training loss: 0.6872865056633053
Epoch: 68 | Iteration number: [1340/4518] 29% | Training loss: 0.6872847134497628
Epoch: 68 | Iteration number: [1350/4518] 29% | Training loss: 0.6872833652408035
Epoch: 68 | Iteration number: [1360/4518] 30% | Training loss: 0.6872847733690458
Epoch: 68 | Iteration number: [1370/4518] 30% | Training loss: 0.6872797222468104
Epoch: 68 | Iteration number: [1380/4518] 30% | Training loss: 0.6872816001159557
Epoch: 68 | Iteration number: [1390/4518] 30% | Training loss: 0.6872782627455623
Epoch: 68 | Iteration number: [1400/4518] 30% | Training loss: 0.6872742226294108
Epoch: 68 | Iteration number: [1410/4518] 31% | Training loss: 0.6872742270324247
Epoch: 68 | Iteration number: [1420/4518] 31% | Training loss: 0.6872707156648099
Epoch: 68 | Iteration number: [1430/4518] 31% | Training loss: 0.6872618284258809
Epoch: 68 | Iteration number: [1440/4518] 31% | Training loss: 0.6872481956664059
Epoch: 68 | Iteration number: [1450/4518] 32% | Training loss: 0.6872439684539006
Epoch: 68 | Iteration number: [1460/4518] 32% | Training loss: 0.6872362956608812
Epoch: 68 | Iteration number: [1470/4518] 32% | Training loss: 0.6872383568968091
Epoch: 68 | Iteration number: [1480/4518] 32% | Training loss: 0.6872415807198834
Epoch: 68 | Iteration number: [1490/4518] 32% | Training loss: 0.687233724450105
Epoch: 68 | Iteration number: [1500/4518] 33% | Training loss: 0.6872222846349081
Epoch: 68 | Iteration number: [1510/4518] 33% | Training loss: 0.6872253188629024
Epoch: 68 | Iteration number: [1520/4518] 33% | Training loss: 0.6872306613937804
Epoch: 68 | Iteration number: [1530/4518] 33% | Training loss: 0.6872314566490697
Epoch: 68 | Iteration number: [1540/4518] 34% | Training loss: 0.6872323084961284
Epoch: 68 | Iteration number: [1550/4518] 34% | Training loss: 0.6872347894407088
Epoch: 68 | Iteration number: [1560/4518] 34% | Training loss: 0.687235569419005
Epoch: 68 | Iteration number: [1570/4518] 34% | Training loss: 0.6872321662249838
Epoch: 68 | Iteration number: [1580/4518] 34% | Training loss: 0.6872316436299795
Epoch: 68 | Iteration number: [1590/4518] 35% | Training loss: 0.6872326837770594
Epoch: 68 | Iteration number: [1600/4518] 35% | Training loss: 0.6872324598208069
Epoch: 68 | Iteration number: [1610/4518] 35% | Training loss: 0.6872348779106733
Epoch: 68 | Iteration number: [1620/4518] 35% | Training loss: 0.6872351543770896
Epoch: 68 | Iteration number: [1630/4518] 36% | Training loss: 0.687233621942485
Epoch: 68 | Iteration number: [1640/4518] 36% | Training loss: 0.6872268674213712
Epoch: 68 | Iteration number: [1650/4518] 36% | Training loss: 0.6872234378439007
Epoch: 68 | Iteration number: [1660/4518] 36% | Training loss: 0.6872168268424919
Epoch: 68 | Iteration number: [1670/4518] 36% | Training loss: 0.6872156958380146
Epoch: 68 | Iteration number: [1680/4518] 37% | Training loss: 0.6872113451361657
Epoch: 68 | Iteration number: [1690/4518] 37% | Training loss: 0.6872101037459966
Epoch: 68 | Iteration number: [1700/4518] 37% | Training loss: 0.6872099540514105
Epoch: 68 | Iteration number: [1710/4518] 37% | Training loss: 0.687214513968306
Epoch: 68 | Iteration number: [1720/4518] 38% | Training loss: 0.6872139518344125
Epoch: 68 | Iteration number: [1730/4518] 38% | Training loss: 0.6872129998110622
Epoch: 68 | Iteration number: [1740/4518] 38% | Training loss: 0.6872153586012194
Epoch: 68 | Iteration number: [1750/4518] 38% | Training loss: 0.6872114586489542
Epoch: 68 | Iteration number: [1760/4518] 38% | Training loss: 0.687210879068483
Epoch: 68 | Iteration number: [1770/4518] 39% | Training loss: 0.6872152371931884
Epoch: 68 | Iteration number: [1780/4518] 39% | Training loss: 0.6872150419803148
Epoch: 68 | Iteration number: [1790/4518] 39% | Training loss: 0.6872129536873801
Epoch: 68 | Iteration number: [1800/4518] 39% | Training loss: 0.6872022162212266
Epoch: 68 | Iteration number: [1810/4518] 40% | Training loss: 0.6871971435639082
Epoch: 68 | Iteration number: [1820/4518] 40% | Training loss: 0.6871908724635512
Epoch: 68 | Iteration number: [1830/4518] 40% | Training loss: 0.6871911866743057
Epoch: 68 | Iteration number: [1840/4518] 40% | Training loss: 0.6871856250192808
Epoch: 68 | Iteration number: [1850/4518] 40% | Training loss: 0.6871810634716137
Epoch: 68 | Iteration number: [1860/4518] 41% | Training loss: 0.6871746119632516
Epoch: 68 | Iteration number: [1870/4518] 41% | Training loss: 0.6871691264251975
Epoch: 68 | Iteration number: [1880/4518] 41% | Training loss: 0.6871688042866423
Epoch: 68 | Iteration number: [1890/4518] 41% | Training loss: 0.6871680305117652
Epoch: 68 | Iteration number: [1900/4518] 42% | Training loss: 0.6871660885999077
Epoch: 68 | Iteration number: [1910/4518] 42% | Training loss: 0.6871616334191167
Epoch: 68 | Iteration number: [1920/4518] 42% | Training loss: 0.687165375209103
Epoch: 68 | Iteration number: [1930/4518] 42% | Training loss: 0.6871657952125826
Epoch: 68 | Iteration number: [1940/4518] 42% | Training loss: 0.6871580673554509
Epoch: 68 | Iteration number: [1950/4518] 43% | Training loss: 0.6871558391130888
Epoch: 68 | Iteration number: [1960/4518] 43% | Training loss: 0.6871548009162046
Epoch: 68 | Iteration number: [1970/4518] 43% | Training loss: 0.6871511297480104
Epoch: 68 | Iteration number: [1980/4518] 43% | Training loss: 0.687156336867448
Epoch: 68 | Iteration number: [1990/4518] 44% | Training loss: 0.6871617015582233
Epoch: 68 | Iteration number: [2000/4518] 44% | Training loss: 0.6871559205651283
Epoch: 68 | Iteration number: [2010/4518] 44% | Training loss: 0.6871577279781228
Epoch: 68 | Iteration number: [2020/4518] 44% | Training loss: 0.6871515567940061
Epoch: 68 | Iteration number: [2030/4518] 44% | Training loss: 0.6871464520252397
Epoch: 68 | Iteration number: [2040/4518] 45% | Training loss: 0.6871420751307525
Epoch: 68 | Iteration number: [2050/4518] 45% | Training loss: 0.6871382055049989
Epoch: 68 | Iteration number: [2060/4518] 45% | Training loss: 0.6871336188999194
Epoch: 68 | Iteration number: [2070/4518] 45% | Training loss: 0.6871417736661607
Epoch: 68 | Iteration number: [2080/4518] 46% | Training loss: 0.687147121045452
Epoch: 68 | Iteration number: [2090/4518] 46% | Training loss: 0.687148650724922
Epoch: 68 | Iteration number: [2100/4518] 46% | Training loss: 0.6871387613103503
Epoch: 68 | Iteration number: [2110/4518] 46% | Training loss: 0.687136248587432
Epoch: 68 | Iteration number: [2120/4518] 46% | Training loss: 0.6871304755222123
Epoch: 68 | Iteration number: [2130/4518] 47% | Training loss: 0.6871230638642826
Epoch: 68 | Iteration number: [2140/4518] 47% | Training loss: 0.6871181699717156
Epoch: 68 | Iteration number: [2150/4518] 47% | Training loss: 0.6871193234033363
Epoch: 68 | Iteration number: [2160/4518] 47% | Training loss: 0.6871233044399155
Epoch: 68 | Iteration number: [2170/4518] 48% | Training loss: 0.6871172620678827
Epoch: 68 | Iteration number: [2180/4518] 48% | Training loss: 0.6871186322575316
Epoch: 68 | Iteration number: [2190/4518] 48% | Training loss: 0.6871166558026178
Epoch: 68 | Iteration number: [2200/4518] 48% | Training loss: 0.6871101706678218
Epoch: 68 | Iteration number: [2210/4518] 48% | Training loss: 0.6871102000793181
Epoch: 68 | Iteration number: [2220/4518] 49% | Training loss: 0.6871111754898552
Epoch: 68 | Iteration number: [2230/4518] 49% | Training loss: 0.687105460150894
Epoch: 68 | Iteration number: [2240/4518] 49% | Training loss: 0.6871065922347562
Epoch: 68 | Iteration number: [2250/4518] 49% | Training loss: 0.6871050505108304
Epoch: 68 | Iteration number: [2260/4518] 50% | Training loss: 0.6871064816164759
Epoch: 68 | Iteration number: [2270/4518] 50% | Training loss: 0.6871043035112289
Epoch: 68 | Iteration number: [2280/4518] 50% | Training loss: 0.6870962472861273
Epoch: 68 | Iteration number: [2290/4518] 50% | Training loss: 0.6870961897237853
Epoch: 68 | Iteration number: [2300/4518] 50% | Training loss: 0.6870993781089783
Epoch: 68 | Iteration number: [2310/4518] 51% | Training loss: 0.6870956508370188
Epoch: 68 | Iteration number: [2320/4518] 51% | Training loss: 0.6870991379536432
Epoch: 68 | Iteration number: [2330/4518] 51% | Training loss: 0.6870977916431018
Epoch: 68 | Iteration number: [2340/4518] 51% | Training loss: 0.6870989001204825
Epoch: 68 | Iteration number: [2350/4518] 52% | Training loss: 0.6870912531081667
Epoch: 68 | Iteration number: [2360/4518] 52% | Training loss: 0.687085381933188
Epoch: 68 | Iteration number: [2370/4518] 52% | Training loss: 0.6870803063931847
Epoch: 68 | Iteration number: [2380/4518] 52% | Training loss: 0.6870724959283315
Epoch: 68 | Iteration number: [2390/4518] 52% | Training loss: 0.6870695722402389
Epoch: 68 | Iteration number: [2400/4518] 53% | Training loss: 0.687069509550929
Epoch: 68 | Iteration number: [2410/4518] 53% | Training loss: 0.6870670308215984
Epoch: 68 | Iteration number: [2420/4518] 53% | Training loss: 0.6870630006652233
Epoch: 68 | Iteration number: [2430/4518] 53% | Training loss: 0.6870652065600877
Epoch: 68 | Iteration number: [2440/4518] 54% | Training loss: 0.6870606719958977
Epoch: 68 | Iteration number: [2450/4518] 54% | Training loss: 0.6870631995736336
Epoch: 68 | Iteration number: [2460/4518] 54% | Training loss: 0.6870616097518099
Epoch: 68 | Iteration number: [2470/4518] 54% | Training loss: 0.687054317634598
Epoch: 68 | Iteration number: [2480/4518] 54% | Training loss: 0.6870508141815662
Epoch: 68 | Iteration number: [2490/4518] 55% | Training loss: 0.6870465017944933
Epoch: 68 | Iteration number: [2500/4518] 55% | Training loss: 0.6870441008090973
Epoch: 68 | Iteration number: [2510/4518] 55% | Training loss: 0.6870352121700803
Epoch: 68 | Iteration number: [2520/4518] 55% | Training loss: 0.6870349193612735
Epoch: 68 | Iteration number: [2530/4518] 55% | Training loss: 0.6870310405968677
Epoch: 68 | Iteration number: [2540/4518] 56% | Training loss: 0.6870271781063455
Epoch: 68 | Iteration number: [2550/4518] 56% | Training loss: 0.6870217747314303
Epoch: 68 | Iteration number: [2560/4518] 56% | Training loss: 0.6870286741526798
Epoch: 68 | Iteration number: [2570/4518] 56% | Training loss: 0.6870308661043412
Epoch: 68 | Iteration number: [2580/4518] 57% | Training loss: 0.6870346807463225
Epoch: 68 | Iteration number: [2590/4518] 57% | Training loss: 0.6870301443407434
Epoch: 68 | Iteration number: [2600/4518] 57% | Training loss: 0.6870248586627153
Epoch: 68 | Iteration number: [2610/4518] 57% | Training loss: 0.6870187647269603
Epoch: 68 | Iteration number: [2620/4518] 57% | Training loss: 0.6870136746923432
Epoch: 68 | Iteration number: [2630/4518] 58% | Training loss: 0.6870129984141302
Epoch: 68 | Iteration number: [2640/4518] 58% | Training loss: 0.687012745823824
Epoch: 68 | Iteration number: [2650/4518] 58% | Training loss: 0.68701257206359
Epoch: 68 | Iteration number: [2660/4518] 58% | Training loss: 0.6870103433392102
Epoch: 68 | Iteration number: [2670/4518] 59% | Training loss: 0.6870040635491131
Epoch: 68 | Iteration number: [2680/4518] 59% | Training loss: 0.6869992823298298
Epoch: 68 | Iteration number: [2690/4518] 59% | Training loss: 0.6870025232378878
Epoch: 68 | Iteration number: [2700/4518] 59% | Training loss: 0.6869977157645756
Epoch: 68 | Iteration number: [2710/4518] 59% | Training loss: 0.686998270446524
Epoch: 68 | Iteration number: [2720/4518] 60% | Training loss: 0.6869954300496508
Epoch: 68 | Iteration number: [2730/4518] 60% | Training loss: 0.686988311394667
Epoch: 68 | Iteration number: [2740/4518] 60% | Training loss: 0.6869889074215924
Epoch: 68 | Iteration number: [2750/4518] 60% | Training loss: 0.6869919968084855
Epoch: 68 | Iteration number: [2760/4518] 61% | Training loss: 0.686992042997609
Epoch: 68 | Iteration number: [2770/4518] 61% | Training loss: 0.686991616104484
Epoch: 68 | Iteration number: [2780/4518] 61% | Training loss: 0.6869877996633379
Epoch: 68 | Iteration number: [2790/4518] 61% | Training loss: 0.6869874238540622
Epoch: 68 | Iteration number: [2800/4518] 61% | Training loss: 0.6869890307102885
Epoch: 68 | Iteration number: [2810/4518] 62% | Training loss: 0.6869883699773469
Epoch: 68 | Iteration number: [2820/4518] 62% | Training loss: 0.6869869485603156
Epoch: 68 | Iteration number: [2830/4518] 62% | Training loss: 0.6869805767131778
Epoch: 68 | Iteration number: [2840/4518] 62% | Training loss: 0.6869839691360232
Epoch: 68 | Iteration number: [2850/4518] 63% | Training loss: 0.6869863001087255
Epoch: 68 | Iteration number: [2860/4518] 63% | Training loss: 0.6869836652195537
Epoch: 68 | Iteration number: [2870/4518] 63% | Training loss: 0.6869826383499318
Epoch: 68 | Iteration number: [2880/4518] 63% | Training loss: 0.6869870604119367
Epoch: 68 | Iteration number: [2890/4518] 63% | Training loss: 0.6869876987793866
Epoch: 68 | Iteration number: [2900/4518] 64% | Training loss: 0.6869887321159758
Epoch: 68 | Iteration number: [2910/4518] 64% | Training loss: 0.6869832303310998
Epoch: 68 | Iteration number: [2920/4518] 64% | Training loss: 0.6869801413931259
Epoch: 68 | Iteration number: [2930/4518] 64% | Training loss: 0.6869839419277048
Epoch: 68 | Iteration number: [2940/4518] 65% | Training loss: 0.6869862407040433
Epoch: 68 | Iteration number: [2950/4518] 65% | Training loss: 0.6869872831288031
Epoch: 68 | Iteration number: [2960/4518] 65% | Training loss: 0.6869896635010436
Epoch: 68 | Iteration number: [2970/4518] 65% | Training loss: 0.6869888263920743
Epoch: 68 | Iteration number: [2980/4518] 65% | Training loss: 0.6869849094208454
Epoch: 68 | Iteration number: [2990/4518] 66% | Training loss: 0.6869900435508294
Epoch: 68 | Iteration number: [3000/4518] 66% | Training loss: 0.6869914767543475
Epoch: 68 | Iteration number: [3010/4518] 66% | Training loss: 0.6869878856248633
Epoch: 68 | Iteration number: [3020/4518] 66% | Training loss: 0.6869874820606598
Epoch: 68 | Iteration number: [3030/4518] 67% | Training loss: 0.6869844492905998
Epoch: 68 | Iteration number: [3040/4518] 67% | Training loss: 0.6869824520263232
Epoch: 68 | Iteration number: [3050/4518] 67% | Training loss: 0.6869819727295735
Epoch: 68 | Iteration number: [3060/4518] 67% | Training loss: 0.6869828996315501
Epoch: 68 | Iteration number: [3070/4518] 67% | Training loss: 0.6869841429620301
Epoch: 68 | Iteration number: [3080/4518] 68% | Training loss: 0.6869809908332762
Epoch: 68 | Iteration number: [3090/4518] 68% | Training loss: 0.6869811993586593
Epoch: 68 | Iteration number: [3100/4518] 68% | Training loss: 0.6869786506314431
Epoch: 68 | Iteration number: [3110/4518] 68% | Training loss: 0.6869798172325183
Epoch: 68 | Iteration number: [3120/4518] 69% | Training loss: 0.6869784923509146
Epoch: 68 | Iteration number: [3130/4518] 69% | Training loss: 0.6869757116983493
Epoch: 68 | Iteration number: [3140/4518] 69% | Training loss: 0.6869751051922512
Epoch: 68 | Iteration number: [3150/4518] 69% | Training loss: 0.6869769964331672
Epoch: 68 | Iteration number: [3160/4518] 69% | Training loss: 0.6869770756816562
Epoch: 68 | Iteration number: [3170/4518] 70% | Training loss: 0.6869780371429792
Epoch: 68 | Iteration number: [3180/4518] 70% | Training loss: 0.6869774337272224
Epoch: 68 | Iteration number: [3190/4518] 70% | Training loss: 0.6869781368017944
Epoch: 68 | Iteration number: [3200/4518] 70% | Training loss: 0.6869744551181793
Epoch: 68 | Iteration number: [3210/4518] 71% | Training loss: 0.6869753817160181
Epoch: 68 | Iteration number: [3220/4518] 71% | Training loss: 0.6869766379550377
Epoch: 68 | Iteration number: [3230/4518] 71% | Training loss: 0.6869764092536903
Epoch: 68 | Iteration number: [3240/4518] 71% | Training loss: 0.686979032151493
Epoch: 68 | Iteration number: [3250/4518] 71% | Training loss: 0.6869795135167929
Epoch: 68 | Iteration number: [3260/4518] 72% | Training loss: 0.6869756974142753
Epoch: 68 | Iteration number: [3270/4518] 72% | Training loss: 0.6869761237492984
Epoch: 68 | Iteration number: [3280/4518] 72% | Training loss: 0.6869783596294682
Epoch: 68 | Iteration number: [3290/4518] 72% | Training loss: 0.6869745454346156
Epoch: 68 | Iteration number: [3300/4518] 73% | Training loss: 0.686973115548943
Epoch: 68 | Iteration number: [3310/4518] 73% | Training loss: 0.6869759636523141
Epoch: 68 | Iteration number: [3320/4518] 73% | Training loss: 0.6869761229818125
Epoch: 68 | Iteration number: [3330/4518] 73% | Training loss: 0.6869753386881259
Epoch: 68 | Iteration number: [3340/4518] 73% | Training loss: 0.6869718131191003
Epoch: 68 | Iteration number: [3350/4518] 74% | Training loss: 0.68697333325201
Epoch: 68 | Iteration number: [3360/4518] 74% | Training loss: 0.6869769672907534
Epoch: 68 | Iteration number: [3370/4518] 74% | Training loss: 0.6869761422762884
Epoch: 68 | Iteration number: [3380/4518] 74% | Training loss: 0.6869768575098387
Epoch: 68 | Iteration number: [3390/4518] 75% | Training loss: 0.6869741521226269
Epoch: 68 | Iteration number: [3400/4518] 75% | Training loss: 0.6869719558778931
Epoch: 68 | Iteration number: [3410/4518] 75% | Training loss: 0.6869718041238198
Epoch: 68 | Iteration number: [3420/4518] 75% | Training loss: 0.6869735600132691
Epoch: 68 | Iteration number: [3430/4518] 75% | Training loss: 0.6869693190293826
Epoch: 68 | Iteration number: [3440/4518] 76% | Training loss: 0.6869710968330849
Epoch: 68 | Iteration number: [3450/4518] 76% | Training loss: 0.6869684712092081
Epoch: 68 | Iteration number: [3460/4518] 76% | Training loss: 0.6869655485098073
Epoch: 68 | Iteration number: [3470/4518] 76% | Training loss: 0.6869654701491255
Epoch: 68 | Iteration number: [3480/4518] 77% | Training loss: 0.6869627226700727
Epoch: 68 | Iteration number: [3490/4518] 77% | Training loss: 0.6869592812307243
Epoch: 68 | Iteration number: [3500/4518] 77% | Training loss: 0.6869604226691383
Epoch: 68 | Iteration number: [3510/4518] 77% | Training loss: 0.6869584028197829
Epoch: 68 | Iteration number: [3520/4518] 77% | Training loss: 0.6869610724632036
Epoch: 68 | Iteration number: [3530/4518] 78% | Training loss: 0.6869551823091912
Epoch: 68 | Iteration number: [3540/4518] 78% | Training loss: 0.6869574213432054
Epoch: 68 | Iteration number: [3550/4518] 78% | Training loss: 0.6869572824827382
Epoch: 68 | Iteration number: [3560/4518] 78% | Training loss: 0.6869495117764794
Epoch: 68 | Iteration number: [3570/4518] 79% | Training loss: 0.6869508188311794
Epoch: 68 | Iteration number: [3580/4518] 79% | Training loss: 0.6869512353196491
Epoch: 68 | Iteration number: [3590/4518] 79% | Training loss: 0.6869517478106082
Epoch: 68 | Iteration number: [3600/4518] 79% | Training loss: 0.6869528877900707
Epoch: 68 | Iteration number: [3610/4518] 79% | Training loss: 0.6869519890015146
Epoch: 68 | Iteration number: [3620/4518] 80% | Training loss: 0.6869487120960299
Epoch: 68 | Iteration number: [3630/4518] 80% | Training loss: 0.6869477035913915
Epoch: 68 | Iteration number: [3640/4518] 80% | Training loss: 0.6869481301405927
Epoch: 68 | Iteration number: [3650/4518] 80% | Training loss: 0.686945247829777
Epoch: 68 | Iteration number: [3660/4518] 81% | Training loss: 0.6869453013268976
Epoch: 68 | Iteration number: [3670/4518] 81% | Training loss: 0.6869487602964084
Epoch: 68 | Iteration number: [3680/4518] 81% | Training loss: 0.6869494684526454
Epoch: 68 | Iteration number: [3690/4518] 81% | Training loss: 0.6869485032913808
Epoch: 68 | Iteration number: [3700/4518] 81% | Training loss: 0.6869494929345878
Epoch: 68 | Iteration number: [3710/4518] 82% | Training loss: 0.6869497103189843
Epoch: 68 | Iteration number: [3720/4518] 82% | Training loss: 0.6869478641979156
Epoch: 68 | Iteration number: [3730/4518] 82% | Training loss: 0.6869452711084892
Epoch: 68 | Iteration number: [3740/4518] 82% | Training loss: 0.686945489750189
Epoch: 68 | Iteration number: [3750/4518] 83% | Training loss: 0.6869436113039652
Epoch: 68 | Iteration number: [3760/4518] 83% | Training loss: 0.6869395469255903
Epoch: 68 | Iteration number: [3770/4518] 83% | Training loss: 0.6869370625253065
Epoch: 68 | Iteration number: [3780/4518] 83% | Training loss: 0.6869375588086547
Epoch: 68 | Iteration number: [3790/4518] 83% | Training loss: 0.686939808828535
Epoch: 68 | Iteration number: [3800/4518] 84% | Training loss: 0.6869401247093552
Epoch: 68 | Iteration number: [3810/4518] 84% | Training loss: 0.6869390217338022
Epoch: 68 | Iteration number: [3820/4518] 84% | Training loss: 0.686935648103659
Epoch: 68 | Iteration number: [3830/4518] 84% | Training loss: 0.6869368505540155
Epoch: 68 | Iteration number: [3840/4518] 84% | Training loss: 0.686935291532427
Epoch: 68 | Iteration number: [3850/4518] 85% | Training loss: 0.686933176889048
Epoch: 68 | Iteration number: [3860/4518] 85% | Training loss: 0.6869365747728496
Epoch: 68 | Iteration number: [3870/4518] 85% | Training loss: 0.6869353197187724
Epoch: 68 | Iteration number: [3880/4518] 85% | Training loss: 0.6869337538314849
Epoch: 68 | Iteration number: [3890/4518] 86% | Training loss: 0.6869311477653778
Epoch: 68 | Iteration number: [3900/4518] 86% | Training loss: 0.6869335066813689
Epoch: 68 | Iteration number: [3910/4518] 86% | Training loss: 0.6869317882506134
Epoch: 68 | Iteration number: [3920/4518] 86% | Training loss: 0.6869319756572344
Epoch: 68 | Iteration number: [3930/4518] 86% | Training loss: 0.6869283876801265
Epoch: 68 | Iteration number: [3940/4518] 87% | Training loss: 0.6869272167610033
Epoch: 68 | Iteration number: [3950/4518] 87% | Training loss: 0.6869279801996448
Epoch: 68 | Iteration number: [3960/4518] 87% | Training loss: 0.686926758018407
Epoch: 68 | Iteration number: [3970/4518] 87% | Training loss: 0.6869257320985386
Epoch: 68 | Iteration number: [3980/4518] 88% | Training loss: 0.6869255649085021
Epoch: 68 | Iteration number: [3990/4518] 88% | Training loss: 0.6869263407580536
Epoch: 68 | Iteration number: [4000/4518] 88% | Training loss: 0.6869239494800568
Epoch: 68 | Iteration number: [4010/4518] 88% | Training loss: 0.6869259943985879
Epoch: 68 | Iteration number: [4020/4518] 88% | Training loss: 0.6869258893811288
Epoch: 68 | Iteration number: [4030/4518] 89% | Training loss: 0.6869240796151883
Epoch: 68 | Iteration number: [4040/4518] 89% | Training loss: 0.6869234092902429
Epoch: 68 | Iteration number: [4050/4518] 89% | Training loss: 0.6869242179393769
Epoch: 68 | Iteration number: [4060/4518] 89% | Training loss: 0.6869249012229478
Epoch: 68 | Iteration number: [4070/4518] 90% | Training loss: 0.6869236127310947
Epoch: 68 | Iteration number: [4080/4518] 90% | Training loss: 0.6869301299254099
Epoch: 68 | Iteration number: [4090/4518] 90% | Training loss: 0.6869315875334379
Epoch: 68 | Iteration number: [4100/4518] 90% | Training loss: 0.6869299924373626
Epoch: 68 | Iteration number: [4110/4518] 90% | Training loss: 0.6869309739619857
Epoch: 68 | Iteration number: [4120/4518] 91% | Training loss: 0.6869324787583166
Epoch: 68 | Iteration number: [4130/4518] 91% | Training loss: 0.6869341712454041
Epoch: 68 | Iteration number: [4140/4518] 91% | Training loss: 0.6869350265909508
Epoch: 68 | Iteration number: [4150/4518] 91% | Training loss: 0.6869353483671166
Epoch: 68 | Iteration number: [4160/4518] 92% | Training loss: 0.6869369704992725
Epoch: 68 | Iteration number: [4170/4518] 92% | Training loss: 0.68693864557097
Epoch: 68 | Iteration number: [4180/4518] 92% | Training loss: 0.6869374760742963
Epoch: 68 | Iteration number: [4190/4518] 92% | Training loss: 0.686938482821699
Epoch: 68 | Iteration number: [4200/4518] 92% | Training loss: 0.6869409494314875
Epoch: 68 | Iteration number: [4210/4518] 93% | Training loss: 0.6869428707698179
Epoch: 68 | Iteration number: [4220/4518] 93% | Training loss: 0.6869413564979182
Epoch: 68 | Iteration number: [4230/4518] 93% | Training loss: 0.6869397992924313
Epoch: 68 | Iteration number: [4240/4518] 93% | Training loss: 0.6869426230917561
Epoch: 68 | Iteration number: [4250/4518] 94% | Training loss: 0.6869438847373514
Epoch: 68 | Iteration number: [4260/4518] 94% | Training loss: 0.6869381359905145
Epoch: 68 | Iteration number: [4270/4518] 94% | Training loss: 0.6869380858938364
Epoch: 68 | Iteration number: [4280/4518] 94% | Training loss: 0.6869378525520039
Epoch: 68 | Iteration number: [4290/4518] 94% | Training loss: 0.6869392406134617
Epoch: 68 | Iteration number: [4300/4518] 95% | Training loss: 0.6869378176400828
Epoch: 68 | Iteration number: [4310/4518] 95% | Training loss: 0.686935961592225
Epoch: 68 | Iteration number: [4320/4518] 95% | Training loss: 0.6869351105005653
Epoch: 68 | Iteration number: [4330/4518] 95% | Training loss: 0.6869332711773711
Epoch: 68 | Iteration number: [4340/4518] 96% | Training loss: 0.68693268767425
Epoch: 68 | Iteration number: [4350/4518] 96% | Training loss: 0.6869345443276154
Epoch: 68 | Iteration number: [4360/4518] 96% | Training loss: 0.6869342239624864
Epoch: 68 | Iteration number: [4370/4518] 96% | Training loss: 0.6869359436242477
Epoch: 68 | Iteration number: [4380/4518] 96% | Training loss: 0.6869381701565225
Epoch: 68 | Iteration number: [4390/4518] 97% | Training loss: 0.6869376353630987
Epoch: 68 | Iteration number: [4400/4518] 97% | Training loss: 0.6869370553032919
Epoch: 68 | Iteration number: [4410/4518] 97% | Training loss: 0.6869353672003801
Epoch: 68 | Iteration number: [4420/4518] 97% | Training loss: 0.6869353088588197
Epoch: 68 | Iteration number: [4430/4518] 98% | Training loss: 0.6869334418805942
Epoch: 68 | Iteration number: [4440/4518] 98% | Training loss: 0.6869341072064262
Epoch: 68 | Iteration number: [4450/4518] 98% | Training loss: 0.6869293017467756
Epoch: 68 | Iteration number: [4460/4518] 98% | Training loss: 0.68693107639193
Epoch: 68 | Iteration number: [4470/4518] 98% | Training loss: 0.6869301034166776
Epoch: 68 | Iteration number: [4480/4518] 99% | Training loss: 0.6869274671854717
Epoch: 68 | Iteration number: [4490/4518] 99% | Training loss: 0.6869268844414395
Epoch: 68 | Iteration number: [4500/4518] 99% | Training loss: 0.6869280341201358
Epoch: 68 | Iteration number: [4510/4518] 99% | Training loss: 0.6869292744115293

 End of epoch: 68 | Train Loss: 0.6867774665065443 | Training Time: 630 

 End of epoch: 68 | Eval Loss: 0.689655235835484 | Evaluating Time: 16 
Epoch: 69 | Iteration number: [10/4518] 0% | Training loss: 0.7550778031349182
Epoch: 69 | Iteration number: [20/4518] 0% | Training loss: 0.7208890914916992
Epoch: 69 | Iteration number: [30/4518] 0% | Training loss: 0.7090828478336334
Epoch: 69 | Iteration number: [40/4518] 0% | Training loss: 0.7038526087999344
Epoch: 69 | Iteration number: [50/4518] 1% | Training loss: 0.7006551826000214
Epoch: 69 | Iteration number: [60/4518] 1% | Training loss: 0.6982362061738968
Epoch: 69 | Iteration number: [70/4518] 1% | Training loss: 0.6966155213969094
Epoch: 69 | Iteration number: [80/4518] 1% | Training loss: 0.6953933596611023
Epoch: 69 | Iteration number: [90/4518] 1% | Training loss: 0.6944367733266619
Epoch: 69 | Iteration number: [100/4518] 2% | Training loss: 0.6934771561622619
Epoch: 69 | Iteration number: [110/4518] 2% | Training loss: 0.692961183461276
Epoch: 69 | Iteration number: [120/4518] 2% | Training loss: 0.6924067700902621
Epoch: 69 | Iteration number: [130/4518] 2% | Training loss: 0.6920120743604806
Epoch: 69 | Iteration number: [140/4518] 3% | Training loss: 0.6916824012994767
Epoch: 69 | Iteration number: [150/4518] 3% | Training loss: 0.6913357945283254
Epoch: 69 | Iteration number: [160/4518] 3% | Training loss: 0.6910579163581133
Epoch: 69 | Iteration number: [170/4518] 3% | Training loss: 0.690770332252278
Epoch: 69 | Iteration number: [180/4518] 3% | Training loss: 0.6906353394190471
Epoch: 69 | Iteration number: [190/4518] 4% | Training loss: 0.6904790228918979
Epoch: 69 | Iteration number: [200/4518] 4% | Training loss: 0.6902881279587746
Epoch: 69 | Iteration number: [210/4518] 4% | Training loss: 0.6900514333021073
Epoch: 69 | Iteration number: [220/4518] 4% | Training loss: 0.6899600893259048
Epoch: 69 | Iteration number: [230/4518] 5% | Training loss: 0.6897901960041212
Epoch: 69 | Iteration number: [240/4518] 5% | Training loss: 0.6897238319118818
Epoch: 69 | Iteration number: [250/4518] 5% | Training loss: 0.6896147391796112
Epoch: 69 | Iteration number: [260/4518] 5% | Training loss: 0.6895307777019647
Epoch: 69 | Iteration number: [270/4518] 5% | Training loss: 0.6894482462494461
Epoch: 69 | Iteration number: [280/4518] 6% | Training loss: 0.6893774524331093
Epoch: 69 | Iteration number: [290/4518] 6% | Training loss: 0.6892782813516156
Epoch: 69 | Iteration number: [300/4518] 6% | Training loss: 0.689216146270434
Epoch: 69 | Iteration number: [310/4518] 6% | Training loss: 0.689120727392935
Epoch: 69 | Iteration number: [320/4518] 7% | Training loss: 0.6890295129269361
Epoch: 69 | Iteration number: [330/4518] 7% | Training loss: 0.6889646934740471
Epoch: 69 | Iteration number: [340/4518] 7% | Training loss: 0.6888715770314722
Epoch: 69 | Iteration number: [350/4518] 7% | Training loss: 0.688783244235175
Epoch: 69 | Iteration number: [360/4518] 7% | Training loss: 0.6887282288736767
Epoch: 69 | Iteration number: [370/4518] 8% | Training loss: 0.6887235979776125
Epoch: 69 | Iteration number: [380/4518] 8% | Training loss: 0.6886712591899069
Epoch: 69 | Iteration number: [390/4518] 8% | Training loss: 0.688647689574804
Epoch: 69 | Iteration number: [400/4518] 8% | Training loss: 0.6886074671149254
Epoch: 69 | Iteration number: [410/4518] 9% | Training loss: 0.6885449977909647
Epoch: 69 | Iteration number: [420/4518] 9% | Training loss: 0.6885290754692895
Epoch: 69 | Iteration number: [430/4518] 9% | Training loss: 0.68848270732303
Epoch: 69 | Iteration number: [440/4518] 9% | Training loss: 0.6884545622901483
Epoch: 69 | Iteration number: [450/4518] 9% | Training loss: 0.6883933443493313
Epoch: 69 | Iteration number: [460/4518] 10% | Training loss: 0.6883627408224603
Epoch: 69 | Iteration number: [470/4518] 10% | Training loss: 0.6883407521755137
Epoch: 69 | Iteration number: [480/4518] 10% | Training loss: 0.688324794297417
Epoch: 69 | Iteration number: [490/4518] 10% | Training loss: 0.6883016538863279
Epoch: 69 | Iteration number: [500/4518] 11% | Training loss: 0.6882697024345398
Epoch: 69 | Iteration number: [510/4518] 11% | Training loss: 0.6882196605205536
Epoch: 69 | Iteration number: [520/4518] 11% | Training loss: 0.6881741171846023
Epoch: 69 | Iteration number: [530/4518] 11% | Training loss: 0.6881500590522335
Epoch: 69 | Iteration number: [540/4518] 11% | Training loss: 0.6881396013277549
Epoch: 69 | Iteration number: [550/4518] 12% | Training loss: 0.688117902170528
Epoch: 69 | Iteration number: [560/4518] 12% | Training loss: 0.6880808752562318
Epoch: 69 | Iteration number: [570/4518] 12% | Training loss: 0.6880723863317255
Epoch: 69 | Iteration number: [580/4518] 12% | Training loss: 0.6880612399043708
Epoch: 69 | Iteration number: [590/4518] 13% | Training loss: 0.6880277646800219
Epoch: 69 | Iteration number: [600/4518] 13% | Training loss: 0.6880183918277423
Epoch: 69 | Iteration number: [610/4518] 13% | Training loss: 0.6879969437591366
Epoch: 69 | Iteration number: [620/4518] 13% | Training loss: 0.6879896230274631
Epoch: 69 | Iteration number: [630/4518] 13% | Training loss: 0.68794566988945
Epoch: 69 | Iteration number: [640/4518] 14% | Training loss: 0.6879185300320387
Epoch: 69 | Iteration number: [650/4518] 14% | Training loss: 0.6878890822483943
Epoch: 69 | Iteration number: [660/4518] 14% | Training loss: 0.6878880629936854
Epoch: 69 | Iteration number: [670/4518] 14% | Training loss: 0.687867921501843
Epoch: 69 | Iteration number: [680/4518] 15% | Training loss: 0.6878703788799398
Epoch: 69 | Iteration number: [690/4518] 15% | Training loss: 0.6878573161968287
Epoch: 69 | Iteration number: [700/4518] 15% | Training loss: 0.6878568227802004
Epoch: 69 | Iteration number: [710/4518] 15% | Training loss: 0.687828755714524
Epoch: 69 | Iteration number: [720/4518] 15% | Training loss: 0.6877976242866781
Epoch: 69 | Iteration number: [730/4518] 16% | Training loss: 0.687782929776466
Epoch: 69 | Iteration number: [740/4518] 16% | Training loss: 0.6877575432126587
Epoch: 69 | Iteration number: [750/4518] 16% | Training loss: 0.6877517615954081
Epoch: 69 | Iteration number: [760/4518] 16% | Training loss: 0.6877480036333987
Epoch: 69 | Iteration number: [770/4518] 17% | Training loss: 0.6877555410583298
Epoch: 69 | Iteration number: [780/4518] 17% | Training loss: 0.6877549527547299
Epoch: 69 | Iteration number: [790/4518] 17% | Training loss: 0.6877447146403639
Epoch: 69 | Iteration number: [800/4518] 17% | Training loss: 0.6877228818833828
Epoch: 69 | Iteration number: [810/4518] 17% | Training loss: 0.6876975189020604
Epoch: 69 | Iteration number: [820/4518] 18% | Training loss: 0.687680911363625
Epoch: 69 | Iteration number: [830/4518] 18% | Training loss: 0.6876783868634557
Epoch: 69 | Iteration number: [840/4518] 18% | Training loss: 0.687656512430736
Epoch: 69 | Iteration number: [850/4518] 18% | Training loss: 0.6876458179950714
Epoch: 69 | Iteration number: [860/4518] 19% | Training loss: 0.6876525605140731
Epoch: 69 | Iteration number: [870/4518] 19% | Training loss: 0.6876364599014151
Epoch: 69 | Iteration number: [880/4518] 19% | Training loss: 0.6876109122552655
Epoch: 69 | Iteration number: [890/4518] 19% | Training loss: 0.6875979633143778
Epoch: 69 | Iteration number: [900/4518] 19% | Training loss: 0.6875931882196002
Epoch: 69 | Iteration number: [910/4518] 20% | Training loss: 0.6875904910512023
Epoch: 69 | Iteration number: [920/4518] 20% | Training loss: 0.687582357098227
Epoch: 69 | Iteration number: [930/4518] 20% | Training loss: 0.687584255010851
Epoch: 69 | Iteration number: [940/4518] 20% | Training loss: 0.6875980982121
Epoch: 69 | Iteration number: [950/4518] 21% | Training loss: 0.6875812143401095
Epoch: 69 | Iteration number: [960/4518] 21% | Training loss: 0.687564408344527
Epoch: 69 | Iteration number: [970/4518] 21% | Training loss: 0.6875584841389017
Epoch: 69 | Iteration number: [980/4518] 21% | Training loss: 0.6875518989806273
Epoch: 69 | Iteration number: [990/4518] 21% | Training loss: 0.6875269125808369
Epoch: 69 | Iteration number: [1000/4518] 22% | Training loss: 0.6875208941102028
Epoch: 69 | Iteration number: [1010/4518] 22% | Training loss: 0.6875301392361669
Epoch: 69 | Iteration number: [1020/4518] 22% | Training loss: 0.6875242663364785
Epoch: 69 | Iteration number: [1030/4518] 22% | Training loss: 0.6875101609716138
Epoch: 69 | Iteration number: [1040/4518] 23% | Training loss: 0.6874978021933482
Epoch: 69 | Iteration number: [1050/4518] 23% | Training loss: 0.6874923616363888
Epoch: 69 | Iteration number: [1060/4518] 23% | Training loss: 0.6874867213784523
Epoch: 69 | Iteration number: [1070/4518] 23% | Training loss: 0.6874837120559728
Epoch: 69 | Iteration number: [1080/4518] 23% | Training loss: 0.6874882038544725
Epoch: 69 | Iteration number: [1090/4518] 24% | Training loss: 0.6874932114684253
Epoch: 69 | Iteration number: [1100/4518] 24% | Training loss: 0.6874782300537283
Epoch: 69 | Iteration number: [1110/4518] 24% | Training loss: 0.6874731101431288
Epoch: 69 | Iteration number: [1120/4518] 24% | Training loss: 0.6874757803976536
Epoch: 69 | Iteration number: [1130/4518] 25% | Training loss: 0.6874688126872072
Epoch: 69 | Iteration number: [1140/4518] 25% | Training loss: 0.6874686916146362
Epoch: 69 | Iteration number: [1150/4518] 25% | Training loss: 0.6874637694462485
Epoch: 69 | Iteration number: [1160/4518] 25% | Training loss: 0.6874612241469581
Epoch: 69 | Iteration number: [1170/4518] 25% | Training loss: 0.6874519990040706
Epoch: 69 | Iteration number: [1180/4518] 26% | Training loss: 0.6874438551017794
Epoch: 69 | Iteration number: [1190/4518] 26% | Training loss: 0.6874402181441043
Epoch: 69 | Iteration number: [1200/4518] 26% | Training loss: 0.6874392822384834
Epoch: 69 | Iteration number: [1210/4518] 26% | Training loss: 0.6874279601514832
Epoch: 69 | Iteration number: [1220/4518] 27% | Training loss: 0.6874173108671532
Epoch: 69 | Iteration number: [1230/4518] 27% | Training loss: 0.6873959887318495
Epoch: 69 | Iteration number: [1240/4518] 27% | Training loss: 0.6873856777625699
Epoch: 69 | Iteration number: [1250/4518] 27% | Training loss: 0.6873770525932312
Epoch: 69 | Iteration number: [1260/4518] 27% | Training loss: 0.6873738306855398
Epoch: 69 | Iteration number: [1270/4518] 28% | Training loss: 0.687370674206516
Epoch: 69 | Iteration number: [1280/4518] 28% | Training loss: 0.6873675787355751
Epoch: 69 | Iteration number: [1290/4518] 28% | Training loss: 0.6873640931391901
Epoch: 69 | Iteration number: [1300/4518] 28% | Training loss: 0.6873584070113989
Epoch: 69 | Iteration number: [1310/4518] 28% | Training loss: 0.6873530009775671
Epoch: 69 | Iteration number: [1320/4518] 29% | Training loss: 0.687347976547299
Epoch: 69 | Iteration number: [1330/4518] 29% | Training loss: 0.6873375188587303
Epoch: 69 | Iteration number: [1340/4518] 29% | Training loss: 0.6873357459235547
Epoch: 69 | Iteration number: [1350/4518] 29% | Training loss: 0.6873393639811763
Epoch: 69 | Iteration number: [1360/4518] 30% | Training loss: 0.6873343251207296
Epoch: 69 | Iteration number: [1370/4518] 30% | Training loss: 0.6873362592537038
Epoch: 69 | Iteration number: [1380/4518] 30% | Training loss: 0.6873276167157768
Epoch: 69 | Iteration number: [1390/4518] 30% | Training loss: 0.6873351196162134
Epoch: 69 | Iteration number: [1400/4518] 30% | Training loss: 0.6873190743156842
Epoch: 69 | Iteration number: [1410/4518] 31% | Training loss: 0.6873157088638198
Epoch: 69 | Iteration number: [1420/4518] 31% | Training loss: 0.6873139561062128
Epoch: 69 | Iteration number: [1430/4518] 31% | Training loss: 0.6873062116282803
Epoch: 69 | Iteration number: [1440/4518] 31% | Training loss: 0.6873049859785372
Epoch: 69 | Iteration number: [1450/4518] 32% | Training loss: 0.6872970243980144
Epoch: 69 | Iteration number: [1460/4518] 32% | Training loss: 0.6872968254432287
Epoch: 69 | Iteration number: [1470/4518] 32% | Training loss: 0.6872959889522215
Epoch: 69 | Iteration number: [1480/4518] 32% | Training loss: 0.6872849076180845
Epoch: 69 | Iteration number: [1490/4518] 32% | Training loss: 0.6872849248399671
Epoch: 69 | Iteration number: [1500/4518] 33% | Training loss: 0.6872853811581929
Epoch: 69 | Iteration number: [1510/4518] 33% | Training loss: 0.6872877157681825
Epoch: 69 | Iteration number: [1520/4518] 33% | Training loss: 0.6872832620222318
Epoch: 69 | Iteration number: [1530/4518] 33% | Training loss: 0.6872866026716294
Epoch: 69 | Iteration number: [1540/4518] 34% | Training loss: 0.687285634062507
Epoch: 69 | Iteration number: [1550/4518] 34% | Training loss: 0.6872750451103333
Epoch: 69 | Iteration number: [1560/4518] 34% | Training loss: 0.6872706391872504
Epoch: 69 | Iteration number: [1570/4518] 34% | Training loss: 0.6872639446881167
Epoch: 69 | Iteration number: [1580/4518] 34% | Training loss: 0.6872647669496416
Epoch: 69 | Iteration number: [1590/4518] 35% | Training loss: 0.6872659114171874
Epoch: 69 | Iteration number: [1600/4518] 35% | Training loss: 0.6872571954131126
Epoch: 69 | Iteration number: [1610/4518] 35% | Training loss: 0.6872530235266834
Epoch: 69 | Iteration number: [1620/4518] 35% | Training loss: 0.6872463257224471
Epoch: 69 | Iteration number: [1630/4518] 36% | Training loss: 0.6872415166325364
Epoch: 69 | Iteration number: [1640/4518] 36% | Training loss: 0.6872448340058327
Epoch: 69 | Iteration number: [1650/4518] 36% | Training loss: 0.6872505301417726
Epoch: 69 | Iteration number: [1660/4518] 36% | Training loss: 0.6872502738093755
Epoch: 69 | Iteration number: [1670/4518] 36% | Training loss: 0.687250496348935
Epoch: 69 | Iteration number: [1680/4518] 37% | Training loss: 0.687249232828617
Epoch: 69 | Iteration number: [1690/4518] 37% | Training loss: 0.6872496313950014
Epoch: 69 | Iteration number: [1700/4518] 37% | Training loss: 0.6872461002013263
Epoch: 69 | Iteration number: [1710/4518] 37% | Training loss: 0.6872400704183077
Epoch: 69 | Iteration number: [1720/4518] 38% | Training loss: 0.6872397448434386
Epoch: 69 | Iteration number: [1730/4518] 38% | Training loss: 0.6872351518256127
Epoch: 69 | Iteration number: [1740/4518] 38% | Training loss: 0.6872301976228582
Epoch: 69 | Iteration number: [1750/4518] 38% | Training loss: 0.6872230238233293
Epoch: 69 | Iteration number: [1760/4518] 38% | Training loss: 0.6872095242820003
Epoch: 69 | Iteration number: [1770/4518] 39% | Training loss: 0.6872062929942783
Epoch: 69 | Iteration number: [1780/4518] 39% | Training loss: 0.6872039689441746
Epoch: 69 | Iteration number: [1790/4518] 39% | Training loss: 0.6872038734691769
Epoch: 69 | Iteration number: [1800/4518] 39% | Training loss: 0.6872048442562421
Epoch: 69 | Iteration number: [1810/4518] 40% | Training loss: 0.6871987010563276
Epoch: 69 | Iteration number: [1820/4518] 40% | Training loss: 0.6871963948011398
Epoch: 69 | Iteration number: [1830/4518] 40% | Training loss: 0.6871904403134121
Epoch: 69 | Iteration number: [1840/4518] 40% | Training loss: 0.6871856920745062
Epoch: 69 | Iteration number: [1850/4518] 40% | Training loss: 0.6871876938922985
Epoch: 69 | Iteration number: [1860/4518] 41% | Training loss: 0.687186959514054
Epoch: 69 | Iteration number: [1870/4518] 41% | Training loss: 0.6871805292081068
Epoch: 69 | Iteration number: [1880/4518] 41% | Training loss: 0.6871812039550315
Epoch: 69 | Iteration number: [1890/4518] 41% | Training loss: 0.6871789681217658
Epoch: 69 | Iteration number: [1900/4518] 42% | Training loss: 0.6871746321728355
Epoch: 69 | Iteration number: [1910/4518] 42% | Training loss: 0.6871742723499917
Epoch: 69 | Iteration number: [1920/4518] 42% | Training loss: 0.6871766237542033
Epoch: 69 | Iteration number: [1930/4518] 42% | Training loss: 0.6871750814309392
Epoch: 69 | Iteration number: [1940/4518] 42% | Training loss: 0.6871734985985707
Epoch: 69 | Iteration number: [1950/4518] 43% | Training loss: 0.6871735503734686
Epoch: 69 | Iteration number: [1960/4518] 43% | Training loss: 0.687176000676593
Epoch: 69 | Iteration number: [1970/4518] 43% | Training loss: 0.6871777469434108
Epoch: 69 | Iteration number: [1980/4518] 43% | Training loss: 0.6871719346805052
Epoch: 69 | Iteration number: [1990/4518] 44% | Training loss: 0.6871689646088298
Epoch: 69 | Iteration number: [2000/4518] 44% | Training loss: 0.6871666257679463
Epoch: 69 | Iteration number: [2010/4518] 44% | Training loss: 0.6871646105056971
Epoch: 69 | Iteration number: [2020/4518] 44% | Training loss: 0.6871572566504526
Epoch: 69 | Iteration number: [2030/4518] 44% | Training loss: 0.6871555356850177
Epoch: 69 | Iteration number: [2040/4518] 45% | Training loss: 0.6871513256839678
Epoch: 69 | Iteration number: [2050/4518] 45% | Training loss: 0.6871444012479084
Epoch: 69 | Iteration number: [2060/4518] 45% | Training loss: 0.6871411202891359
Epoch: 69 | Iteration number: [2070/4518] 45% | Training loss: 0.6871403989872494
Epoch: 69 | Iteration number: [2080/4518] 46% | Training loss: 0.6871370340195986
Epoch: 69 | Iteration number: [2090/4518] 46% | Training loss: 0.6871305140867188
Epoch: 69 | Iteration number: [2100/4518] 46% | Training loss: 0.6871314812558038
Epoch: 69 | Iteration number: [2110/4518] 46% | Training loss: 0.6871338394015887
Epoch: 69 | Iteration number: [2120/4518] 46% | Training loss: 0.6871322967814949
Epoch: 69 | Iteration number: [2130/4518] 47% | Training loss: 0.6871309006717843
Epoch: 69 | Iteration number: [2140/4518] 47% | Training loss: 0.687127236144565
Epoch: 69 | Iteration number: [2150/4518] 47% | Training loss: 0.687123841352241
Epoch: 69 | Iteration number: [2160/4518] 47% | Training loss: 0.6871238649443344
Epoch: 69 | Iteration number: [2170/4518] 48% | Training loss: 0.6871287473885145
Epoch: 69 | Iteration number: [2180/4518] 48% | Training loss: 0.687126202895007
Epoch: 69 | Iteration number: [2190/4518] 48% | Training loss: 0.6871242522921192
Epoch: 69 | Iteration number: [2200/4518] 48% | Training loss: 0.6871236500144005
Epoch: 69 | Iteration number: [2210/4518] 48% | Training loss: 0.6871188809159654
Epoch: 69 | Iteration number: [2220/4518] 49% | Training loss: 0.6871166989878491
Epoch: 69 | Iteration number: [2230/4518] 49% | Training loss: 0.687113769840232
Epoch: 69 | Iteration number: [2240/4518] 49% | Training loss: 0.6871147938072681
Epoch: 69 | Iteration number: [2250/4518] 49% | Training loss: 0.6871134577857123
Epoch: 69 | Iteration number: [2260/4518] 50% | Training loss: 0.6871105761918347
Epoch: 69 | Iteration number: [2270/4518] 50% | Training loss: 0.6871090464392423
Epoch: 69 | Iteration number: [2280/4518] 50% | Training loss: 0.6871071538119985
Epoch: 69 | Iteration number: [2290/4518] 50% | Training loss: 0.6871024486019102
Epoch: 69 | Iteration number: [2300/4518] 50% | Training loss: 0.687102358755858
Epoch: 69 | Iteration number: [2310/4518] 51% | Training loss: 0.6870986375973854
Epoch: 69 | Iteration number: [2320/4518] 51% | Training loss: 0.6871001151872093
Epoch: 69 | Iteration number: [2330/4518] 51% | Training loss: 0.6871003152474825
Epoch: 69 | Iteration number: [2340/4518] 51% | Training loss: 0.6870930486000502
Epoch: 69 | Iteration number: [2350/4518] 52% | Training loss: 0.6870919223541909
Epoch: 69 | Iteration number: [2360/4518] 52% | Training loss: 0.6870909482998363
Epoch: 69 | Iteration number: [2370/4518] 52% | Training loss: 0.6870921634420564
Epoch: 69 | Iteration number: [2380/4518] 52% | Training loss: 0.6870865895718086
Epoch: 69 | Iteration number: [2390/4518] 52% | Training loss: 0.6870868668895386
Epoch: 69 | Iteration number: [2400/4518] 53% | Training loss: 0.6870873428384463
Epoch: 69 | Iteration number: [2410/4518] 53% | Training loss: 0.6870886833835934
Epoch: 69 | Iteration number: [2420/4518] 53% | Training loss: 0.6870871365809244
Epoch: 69 | Iteration number: [2430/4518] 53% | Training loss: 0.6870845609976921
Epoch: 69 | Iteration number: [2440/4518] 54% | Training loss: 0.6870845045466892
Epoch: 69 | Iteration number: [2450/4518] 54% | Training loss: 0.6870853487569458
Epoch: 69 | Iteration number: [2460/4518] 54% | Training loss: 0.6870820615107451
Epoch: 69 | Iteration number: [2470/4518] 54% | Training loss: 0.6870804738419258
Epoch: 69 | Iteration number: [2480/4518] 54% | Training loss: 0.6870839770042128
Epoch: 69 | Iteration number: [2490/4518] 55% | Training loss: 0.6870826877264613
Epoch: 69 | Iteration number: [2500/4518] 55% | Training loss: 0.6870868624210358
Epoch: 69 | Iteration number: [2510/4518] 55% | Training loss: 0.6870890333120566
Epoch: 69 | Iteration number: [2520/4518] 55% | Training loss: 0.6870919054935849
Epoch: 69 | Iteration number: [2530/4518] 55% | Training loss: 0.6870897878771243
Epoch: 69 | Iteration number: [2540/4518] 56% | Training loss: 0.6870913778703044
Epoch: 69 | Iteration number: [2550/4518] 56% | Training loss: 0.6870911066672382
Epoch: 69 | Iteration number: [2560/4518] 56% | Training loss: 0.6870879494817927
Epoch: 69 | Iteration number: [2570/4518] 56% | Training loss: 0.6870854210760807
Epoch: 69 | Iteration number: [2580/4518] 57% | Training loss: 0.6870854030052821
Epoch: 69 | Iteration number: [2590/4518] 57% | Training loss: 0.6870877569246476
Epoch: 69 | Iteration number: [2600/4518] 57% | Training loss: 0.6870834626372044
Epoch: 69 | Iteration number: [2610/4518] 57% | Training loss: 0.6870878334246376
Epoch: 69 | Iteration number: [2620/4518] 57% | Training loss: 0.68708886718022
Epoch: 69 | Iteration number: [2630/4518] 58% | Training loss: 0.6870853774221225
Epoch: 69 | Iteration number: [2640/4518] 58% | Training loss: 0.6870828268202869
Epoch: 69 | Iteration number: [2650/4518] 58% | Training loss: 0.6870814304981592
Epoch: 69 | Iteration number: [2660/4518] 58% | Training loss: 0.6870847693959573
Epoch: 69 | Iteration number: [2670/4518] 59% | Training loss: 0.6870770893293373
Epoch: 69 | Iteration number: [2680/4518] 59% | Training loss: 0.6870771725008736
Epoch: 69 | Iteration number: [2690/4518] 59% | Training loss: 0.6870748315823566
Epoch: 69 | Iteration number: [2700/4518] 59% | Training loss: 0.6870717426582619
Epoch: 69 | Iteration number: [2710/4518] 59% | Training loss: 0.687072409562959
Epoch: 69 | Iteration number: [2720/4518] 60% | Training loss: 0.6870676312595606
Epoch: 69 | Iteration number: [2730/4518] 60% | Training loss: 0.6870648195018698
Epoch: 69 | Iteration number: [2740/4518] 60% | Training loss: 0.6870642018579218
Epoch: 69 | Iteration number: [2750/4518] 60% | Training loss: 0.687064104903828
Epoch: 69 | Iteration number: [2760/4518] 61% | Training loss: 0.6870592053817666
Epoch: 69 | Iteration number: [2770/4518] 61% | Training loss: 0.687054413449463
Epoch: 69 | Iteration number: [2780/4518] 61% | Training loss: 0.6870547777457203
Epoch: 69 | Iteration number: [2790/4518] 61% | Training loss: 0.6870566958167647
Epoch: 69 | Iteration number: [2800/4518] 61% | Training loss: 0.6870543468637126
Epoch: 69 | Iteration number: [2810/4518] 62% | Training loss: 0.6870528996414985
Epoch: 69 | Iteration number: [2820/4518] 62% | Training loss: 0.6870529087088633
Epoch: 69 | Iteration number: [2830/4518] 62% | Training loss: 0.6870497142678857
Epoch: 69 | Iteration number: [2840/4518] 62% | Training loss: 0.6870496617236608
Epoch: 69 | Iteration number: [2850/4518] 63% | Training loss: 0.6870492943546228
Epoch: 69 | Iteration number: [2860/4518] 63% | Training loss: 0.687048589120378
Epoch: 69 | Iteration number: [2870/4518] 63% | Training loss: 0.6870489211240297
Epoch: 69 | Iteration number: [2880/4518] 63% | Training loss: 0.6870486760305033
Epoch: 69 | Iteration number: [2890/4518] 63% | Training loss: 0.6870442104793337
Epoch: 69 | Iteration number: [2900/4518] 64% | Training loss: 0.6870489305874397
Epoch: 69 | Iteration number: [2910/4518] 64% | Training loss: 0.68704425766296
Epoch: 69 | Iteration number: [2920/4518] 64% | Training loss: 0.6870437649627255
Epoch: 69 | Iteration number: [2930/4518] 64% | Training loss: 0.6870446903510306
Epoch: 69 | Iteration number: [2940/4518] 65% | Training loss: 0.6870460293730911
Epoch: 69 | Iteration number: [2950/4518] 65% | Training loss: 0.6870421620950861
Epoch: 69 | Iteration number: [2960/4518] 65% | Training loss: 0.687040101938151
Epoch: 69 | Iteration number: [2970/4518] 65% | Training loss: 0.6870409162758978
Epoch: 69 | Iteration number: [2980/4518] 65% | Training loss: 0.6870408189576744
Epoch: 69 | Iteration number: [2990/4518] 66% | Training loss: 0.6870439644641302
Epoch: 69 | Iteration number: [3000/4518] 66% | Training loss: 0.687043743789196
Epoch: 69 | Iteration number: [3010/4518] 66% | Training loss: 0.6870435362242385
Epoch: 69 | Iteration number: [3020/4518] 66% | Training loss: 0.6870414296128102
Epoch: 69 | Iteration number: [3030/4518] 67% | Training loss: 0.687034792711239
Epoch: 69 | Iteration number: [3040/4518] 67% | Training loss: 0.6870330600362075
Epoch: 69 | Iteration number: [3050/4518] 67% | Training loss: 0.6870337980692504
Epoch: 69 | Iteration number: [3060/4518] 67% | Training loss: 0.6870346586688671
Epoch: 69 | Iteration number: [3070/4518] 67% | Training loss: 0.687029863743518
Epoch: 69 | Iteration number: [3080/4518] 68% | Training loss: 0.6870357910534004
Epoch: 69 | Iteration number: [3090/4518] 68% | Training loss: 0.6870326148846388
Epoch: 69 | Iteration number: [3100/4518] 68% | Training loss: 0.6870259158842025
Epoch: 69 | Iteration number: [3110/4518] 68% | Training loss: 0.6870252760660227
Epoch: 69 | Iteration number: [3120/4518] 69% | Training loss: 0.6870266909209581
Epoch: 69 | Iteration number: [3130/4518] 69% | Training loss: 0.687020900721748
Epoch: 69 | Iteration number: [3140/4518] 69% | Training loss: 0.6870176003047616
Epoch: 69 | Iteration number: [3150/4518] 69% | Training loss: 0.6870182096579718
Epoch: 69 | Iteration number: [3160/4518] 69% | Training loss: 0.6870147930293143
Epoch: 69 | Iteration number: [3170/4518] 70% | Training loss: 0.687013757322865
Epoch: 69 | Iteration number: [3180/4518] 70% | Training loss: 0.6870204295189876
Epoch: 69 | Iteration number: [3190/4518] 70% | Training loss: 0.6870144698687108
Epoch: 69 | Iteration number: [3200/4518] 70% | Training loss: 0.6870082716457546
Epoch: 69 | Iteration number: [3210/4518] 71% | Training loss: 0.6870034160272355
Epoch: 69 | Iteration number: [3220/4518] 71% | Training loss: 0.6870072138790758
Epoch: 69 | Iteration number: [3230/4518] 71% | Training loss: 0.6870047358905568
Epoch: 69 | Iteration number: [3240/4518] 71% | Training loss: 0.6870076026445554
Epoch: 69 | Iteration number: [3250/4518] 71% | Training loss: 0.6870025282272926
Epoch: 69 | Iteration number: [3260/4518] 72% | Training loss: 0.687002856179249
Epoch: 69 | Iteration number: [3270/4518] 72% | Training loss: 0.6870036711386585
Epoch: 69 | Iteration number: [3280/4518] 72% | Training loss: 0.6869986209382372
Epoch: 69 | Iteration number: [3290/4518] 72% | Training loss: 0.6869994273120509
Epoch: 69 | Iteration number: [3300/4518] 73% | Training loss: 0.6869956693866036
Epoch: 69 | Iteration number: [3310/4518] 73% | Training loss: 0.6869962223707009
Epoch: 69 | Iteration number: [3320/4518] 73% | Training loss: 0.6869977300784674
Epoch: 69 | Iteration number: [3330/4518] 73% | Training loss: 0.6869975489897054
Epoch: 69 | Iteration number: [3340/4518] 73% | Training loss: 0.6869995741073243
Epoch: 69 | Iteration number: [3350/4518] 74% | Training loss: 0.6869953999590518
Epoch: 69 | Iteration number: [3360/4518] 74% | Training loss: 0.686992960902197
Epoch: 69 | Iteration number: [3370/4518] 74% | Training loss: 0.6869907655241935
Epoch: 69 | Iteration number: [3380/4518] 74% | Training loss: 0.6869932957654874
Epoch: 69 | Iteration number: [3390/4518] 75% | Training loss: 0.6869936985428002
Epoch: 69 | Iteration number: [3400/4518] 75% | Training loss: 0.6869913253012826
Epoch: 69 | Iteration number: [3410/4518] 75% | Training loss: 0.6869943886383537
Epoch: 69 | Iteration number: [3420/4518] 75% | Training loss: 0.6869938779818384
Epoch: 69 | Iteration number: [3430/4518] 75% | Training loss: 0.6869941167337902
Epoch: 69 | Iteration number: [3440/4518] 76% | Training loss: 0.6869952961975752
Epoch: 69 | Iteration number: [3450/4518] 76% | Training loss: 0.6869915334038112
Epoch: 69 | Iteration number: [3460/4518] 76% | Training loss: 0.686992038846705
Epoch: 69 | Iteration number: [3470/4518] 76% | Training loss: 0.6869944925267002
Epoch: 69 | Iteration number: [3480/4518] 77% | Training loss: 0.6869911957574987
Epoch: 69 | Iteration number: [3490/4518] 77% | Training loss: 0.686990851112628
Epoch: 69 | Iteration number: [3500/4518] 77% | Training loss: 0.6869886827128274
Epoch: 69 | Iteration number: [3510/4518] 77% | Training loss: 0.6869864887831217
Epoch: 69 | Iteration number: [3520/4518] 77% | Training loss: 0.6869871486486359
Epoch: 69 | Iteration number: [3530/4518] 78% | Training loss: 0.6869831238184705
Epoch: 69 | Iteration number: [3540/4518] 78% | Training loss: 0.6869863288382353
Epoch: 69 | Iteration number: [3550/4518] 78% | Training loss: 0.6869838213752693
Epoch: 69 | Iteration number: [3560/4518] 78% | Training loss: 0.686983726282468
Epoch: 69 | Iteration number: [3570/4518] 79% | Training loss: 0.6869876705965742
Epoch: 69 | Iteration number: [3580/4518] 79% | Training loss: 0.6869880455499254
Epoch: 69 | Iteration number: [3590/4518] 79% | Training loss: 0.6869859626034176
Epoch: 69 | Iteration number: [3600/4518] 79% | Training loss: 0.6869844927887122
Epoch: 69 | Iteration number: [3610/4518] 79% | Training loss: 0.6869839074704125
Epoch: 69 | Iteration number: [3620/4518] 80% | Training loss: 0.6869873284634964
Epoch: 69 | Iteration number: [3630/4518] 80% | Training loss: 0.6869844843369214
Epoch: 69 | Iteration number: [3640/4518] 80% | Training loss: 0.6869845234758252
Epoch: 69 | Iteration number: [3650/4518] 80% | Training loss: 0.6869811422530919
Epoch: 69 | Iteration number: [3660/4518] 81% | Training loss: 0.6869801167744757
Epoch: 69 | Iteration number: [3670/4518] 81% | Training loss: 0.68698249883158
Epoch: 69 | Iteration number: [3680/4518] 81% | Training loss: 0.6869798752276793
Epoch: 69 | Iteration number: [3690/4518] 81% | Training loss: 0.6869766341638436
Epoch: 69 | Iteration number: [3700/4518] 81% | Training loss: 0.6869798601640237
Epoch: 69 | Iteration number: [3710/4518] 82% | Training loss: 0.6869787881637841
Epoch: 69 | Iteration number: [3720/4518] 82% | Training loss: 0.6869770409759655
Epoch: 69 | Iteration number: [3730/4518] 82% | Training loss: 0.6869746822294537
Epoch: 69 | Iteration number: [3740/4518] 82% | Training loss: 0.6869758380606851
Epoch: 69 | Iteration number: [3750/4518] 83% | Training loss: 0.6869701154232025
Epoch: 69 | Iteration number: [3760/4518] 83% | Training loss: 0.6869689687452418
Epoch: 69 | Iteration number: [3770/4518] 83% | Training loss: 0.6869684445446935
Epoch: 69 | Iteration number: [3780/4518] 83% | Training loss: 0.6869679737343359
Epoch: 69 | Iteration number: [3790/4518] 83% | Training loss: 0.6869713635903865
Epoch: 69 | Iteration number: [3800/4518] 84% | Training loss: 0.6869718261141526
Epoch: 69 | Iteration number: [3810/4518] 84% | Training loss: 0.686969398951593
Epoch: 69 | Iteration number: [3820/4518] 84% | Training loss: 0.6869696433319471
Epoch: 69 | Iteration number: [3830/4518] 84% | Training loss: 0.6869670549042853
Epoch: 69 | Iteration number: [3840/4518] 84% | Training loss: 0.6869659163833907
Epoch: 69 | Iteration number: [3850/4518] 85% | Training loss: 0.6869675184999193
Epoch: 69 | Iteration number: [3860/4518] 85% | Training loss: 0.6869661544271084
Epoch: 69 | Iteration number: [3870/4518] 85% | Training loss: 0.6869645367759143
Epoch: 69 | Iteration number: [3880/4518] 85% | Training loss: 0.6869643907571577
Epoch: 69 | Iteration number: [3890/4518] 86% | Training loss: 0.686963321846984
Epoch: 69 | Iteration number: [3900/4518] 86% | Training loss: 0.6869595875342687
Epoch: 69 | Iteration number: [3910/4518] 86% | Training loss: 0.6869620857946098
Epoch: 69 | Iteration number: [3920/4518] 86% | Training loss: 0.6869606823489374
Epoch: 69 | Iteration number: [3930/4518] 86% | Training loss: 0.6869604675217742
Epoch: 69 | Iteration number: [3940/4518] 87% | Training loss: 0.686959760231415
Epoch: 69 | Iteration number: [3950/4518] 87% | Training loss: 0.6869577368603477
Epoch: 69 | Iteration number: [3960/4518] 87% | Training loss: 0.6869572658881996
Epoch: 69 | Iteration number: [3970/4518] 87% | Training loss: 0.6869581196260092
Epoch: 69 | Iteration number: [3980/4518] 88% | Training loss: 0.686954563182203
Epoch: 69 | Iteration number: [3990/4518] 88% | Training loss: 0.6869514313556796
Epoch: 69 | Iteration number: [4000/4518] 88% | Training loss: 0.6869529597163201
Epoch: 69 | Iteration number: [4010/4518] 88% | Training loss: 0.6869486917432704
Epoch: 69 | Iteration number: [4020/4518] 88% | Training loss: 0.6869473421603293
Epoch: 69 | Iteration number: [4030/4518] 89% | Training loss: 0.6869476346165015
Epoch: 69 | Iteration number: [4040/4518] 89% | Training loss: 0.6869472948631438
Epoch: 69 | Iteration number: [4050/4518] 89% | Training loss: 0.6869450370470683
Epoch: 69 | Iteration number: [4060/4518] 89% | Training loss: 0.6869440313630504
Epoch: 69 | Iteration number: [4070/4518] 90% | Training loss: 0.6869428864128759
Epoch: 69 | Iteration number: [4080/4518] 90% | Training loss: 0.6869436838024972
Epoch: 69 | Iteration number: [4090/4518] 90% | Training loss: 0.6869438211754657
Epoch: 69 | Iteration number: [4100/4518] 90% | Training loss: 0.6869461621016991
Epoch: 69 | Iteration number: [4110/4518] 90% | Training loss: 0.6869473945775462
Epoch: 69 | Iteration number: [4120/4518] 91% | Training loss: 0.686944166925347
Epoch: 69 | Iteration number: [4130/4518] 91% | Training loss: 0.6869430876817311
Epoch: 69 | Iteration number: [4140/4518] 91% | Training loss: 0.6869413633997313
Epoch: 69 | Iteration number: [4150/4518] 91% | Training loss: 0.6869404648585492
Epoch: 69 | Iteration number: [4160/4518] 92% | Training loss: 0.6869377307450542
Epoch: 69 | Iteration number: [4170/4518] 92% | Training loss: 0.6869335627813133
Epoch: 69 | Iteration number: [4180/4518] 92% | Training loss: 0.6869337720021106
Epoch: 69 | Iteration number: [4190/4518] 92% | Training loss: 0.6869339860566761
Epoch: 69 | Iteration number: [4200/4518] 92% | Training loss: 0.6869342019586336
Epoch: 69 | Iteration number: [4210/4518] 93% | Training loss: 0.6869342773090915
Epoch: 69 | Iteration number: [4220/4518] 93% | Training loss: 0.6869315625225764
Epoch: 69 | Iteration number: [4230/4518] 93% | Training loss: 0.6869292348552821
Epoch: 69 | Iteration number: [4240/4518] 93% | Training loss: 0.6869284760698957
Epoch: 69 | Iteration number: [4250/4518] 94% | Training loss: 0.6869290509364184
Epoch: 69 | Iteration number: [4260/4518] 94% | Training loss: 0.6869262121093105
Epoch: 69 | Iteration number: [4270/4518] 94% | Training loss: 0.6869249106988974
Epoch: 69 | Iteration number: [4280/4518] 94% | Training loss: 0.6869219759218047
Epoch: 69 | Iteration number: [4290/4518] 94% | Training loss: 0.6869226081943735
Epoch: 69 | Iteration number: [4300/4518] 95% | Training loss: 0.6869211936135625
Epoch: 69 | Iteration number: [4310/4518] 95% | Training loss: 0.6869191042508437
Epoch: 69 | Iteration number: [4320/4518] 95% | Training loss: 0.6869204146994485
Epoch: 69 | Iteration number: [4330/4518] 95% | Training loss: 0.6869167463471102
Epoch: 69 | Iteration number: [4340/4518] 96% | Training loss: 0.6869165015660124
Epoch: 69 | Iteration number: [4350/4518] 96% | Training loss: 0.6869195223128659
Epoch: 69 | Iteration number: [4360/4518] 96% | Training loss: 0.6869239445263092
Epoch: 69 | Iteration number: [4370/4518] 96% | Training loss: 0.6869234495222978
Epoch: 69 | Iteration number: [4380/4518] 96% | Training loss: 0.6869222420943927
Epoch: 69 | Iteration number: [4390/4518] 97% | Training loss: 0.6869204765707594
Epoch: 69 | Iteration number: [4400/4518] 97% | Training loss: 0.6869214993850752
Epoch: 69 | Iteration number: [4410/4518] 97% | Training loss: 0.6869230999427588
Epoch: 69 | Iteration number: [4420/4518] 97% | Training loss: 0.686923359503034
Epoch: 69 | Iteration number: [4430/4518] 98% | Training loss: 0.6869242233024494
Epoch: 69 | Iteration number: [4440/4518] 98% | Training loss: 0.6869222340551583
Epoch: 69 | Iteration number: [4450/4518] 98% | Training loss: 0.6869223857059907
Epoch: 69 | Iteration number: [4460/4518] 98% | Training loss: 0.6869232216891686
Epoch: 69 | Iteration number: [4470/4518] 98% | Training loss: 0.6869230922969929
Epoch: 69 | Iteration number: [4480/4518] 99% | Training loss: 0.6869234023881811
Epoch: 69 | Iteration number: [4490/4518] 99% | Training loss: 0.6869237333602523
Epoch: 69 | Iteration number: [4500/4518] 99% | Training loss: 0.6869256250196033
Epoch: 69 | Iteration number: [4510/4518] 99% | Training loss: 0.686924683928754

 End of epoch: 69 | Train Loss: 0.686772944864946 | Training Time: 629 

 End of epoch: 69 | Eval Loss: 0.689718020205595 | Evaluating Time: 17 
Epoch: 70 | Iteration number: [10/4518] 0% | Training loss: 0.7556391179561615
Epoch: 70 | Iteration number: [20/4518] 0% | Training loss: 0.7216537594795227
Epoch: 70 | Iteration number: [30/4518] 0% | Training loss: 0.7102840383847554
Epoch: 70 | Iteration number: [40/4518] 0% | Training loss: 0.7042599394917488
Epoch: 70 | Iteration number: [50/4518] 1% | Training loss: 0.7009548544883728
Epoch: 70 | Iteration number: [60/4518] 1% | Training loss: 0.6987996240456898
Epoch: 70 | Iteration number: [70/4518] 1% | Training loss: 0.6968761094978877
Epoch: 70 | Iteration number: [80/4518] 1% | Training loss: 0.695762176811695
Epoch: 70 | Iteration number: [90/4518] 1% | Training loss: 0.6946589913633134
Epoch: 70 | Iteration number: [100/4518] 2% | Training loss: 0.6938815277814865
Epoch: 70 | Iteration number: [110/4518] 2% | Training loss: 0.6931840804490176
Epoch: 70 | Iteration number: [120/4518] 2% | Training loss: 0.6926275094350179
Epoch: 70 | Iteration number: [130/4518] 2% | Training loss: 0.692162405527555
Epoch: 70 | Iteration number: [140/4518] 3% | Training loss: 0.6918326105390277
Epoch: 70 | Iteration number: [150/4518] 3% | Training loss: 0.6915198981761932
Epoch: 70 | Iteration number: [160/4518] 3% | Training loss: 0.6911210913211108
Epoch: 70 | Iteration number: [170/4518] 3% | Training loss: 0.690844467457603
Epoch: 70 | Iteration number: [180/4518] 3% | Training loss: 0.6905696236424976
Epoch: 70 | Iteration number: [190/4518] 4% | Training loss: 0.6903785953396245
Epoch: 70 | Iteration number: [200/4518] 4% | Training loss: 0.6902125602960587
Epoch: 70 | Iteration number: [210/4518] 4% | Training loss: 0.6900418221950531
Epoch: 70 | Iteration number: [220/4518] 4% | Training loss: 0.6898949292573062
Epoch: 70 | Iteration number: [230/4518] 5% | Training loss: 0.6897652996622998
Epoch: 70 | Iteration number: [240/4518] 5% | Training loss: 0.6896298460662365
Epoch: 70 | Iteration number: [250/4518] 5% | Training loss: 0.6895235493183136
Epoch: 70 | Iteration number: [260/4518] 5% | Training loss: 0.6894304656065428
Epoch: 70 | Iteration number: [270/4518] 5% | Training loss: 0.6893401969362188
Epoch: 70 | Iteration number: [280/4518] 6% | Training loss: 0.6892400264739991
Epoch: 70 | Iteration number: [290/4518] 6% | Training loss: 0.6891660497106354
Epoch: 70 | Iteration number: [300/4518] 6% | Training loss: 0.6890953115622203
Epoch: 70 | Iteration number: [310/4518] 6% | Training loss: 0.6889959379549949
Epoch: 70 | Iteration number: [320/4518] 7% | Training loss: 0.6889527991414071
Epoch: 70 | Iteration number: [330/4518] 7% | Training loss: 0.68888626351501
Epoch: 70 | Iteration number: [340/4518] 7% | Training loss: 0.6887857098789776
Epoch: 70 | Iteration number: [350/4518] 7% | Training loss: 0.6887278917857579
Epoch: 70 | Iteration number: [360/4518] 7% | Training loss: 0.6886803294221561
Epoch: 70 | Iteration number: [370/4518] 8% | Training loss: 0.6886353665107006
Epoch: 70 | Iteration number: [380/4518] 8% | Training loss: 0.6885849350377133
Epoch: 70 | Iteration number: [390/4518] 8% | Training loss: 0.6885373904154851
Epoch: 70 | Iteration number: [400/4518] 8% | Training loss: 0.6884876488149166
Epoch: 70 | Iteration number: [410/4518] 9% | Training loss: 0.6884546749475525
Epoch: 70 | Iteration number: [420/4518] 9% | Training loss: 0.6884203196991058
Epoch: 70 | Iteration number: [430/4518] 9% | Training loss: 0.688363738808521
Epoch: 70 | Iteration number: [440/4518] 9% | Training loss: 0.6883393643931909
Epoch: 70 | Iteration number: [450/4518] 9% | Training loss: 0.6883101438151465
Epoch: 70 | Iteration number: [460/4518] 10% | Training loss: 0.688292888066043
Epoch: 70 | Iteration number: [470/4518] 10% | Training loss: 0.6882463311895411
Epoch: 70 | Iteration number: [480/4518] 10% | Training loss: 0.6882306383301814
Epoch: 70 | Iteration number: [490/4518] 10% | Training loss: 0.6882328698829728
Epoch: 70 | Iteration number: [500/4518] 11% | Training loss: 0.688191377401352
Epoch: 70 | Iteration number: [510/4518] 11% | Training loss: 0.688151695915297
Epoch: 70 | Iteration number: [520/4518] 11% | Training loss: 0.6881182440198385
Epoch: 70 | Iteration number: [530/4518] 11% | Training loss: 0.6880908646673526
Epoch: 70 | Iteration number: [540/4518] 11% | Training loss: 0.6880411705485097
Epoch: 70 | Iteration number: [550/4518] 12% | Training loss: 0.6880168429287997
Epoch: 70 | Iteration number: [560/4518] 12% | Training loss: 0.6880026351128306
Epoch: 70 | Iteration number: [570/4518] 12% | Training loss: 0.6879987500215832
Epoch: 70 | Iteration number: [580/4518] 12% | Training loss: 0.687974689232892
Epoch: 70 | Iteration number: [590/4518] 13% | Training loss: 0.6879552234027345
Epoch: 70 | Iteration number: [600/4518] 13% | Training loss: 0.6879327780008316
Epoch: 70 | Iteration number: [610/4518] 13% | Training loss: 0.6879077897697199
Epoch: 70 | Iteration number: [620/4518] 13% | Training loss: 0.6878891383447955
Epoch: 70 | Iteration number: [630/4518] 13% | Training loss: 0.6878675598000723
Epoch: 70 | Iteration number: [640/4518] 14% | Training loss: 0.6878445280715824
Epoch: 70 | Iteration number: [650/4518] 14% | Training loss: 0.6878338910983159
Epoch: 70 | Iteration number: [660/4518] 14% | Training loss: 0.6878014800223438
Epoch: 70 | Iteration number: [670/4518] 14% | Training loss: 0.6877994887864411
Epoch: 70 | Iteration number: [680/4518] 15% | Training loss: 0.6877900535569471
Epoch: 70 | Iteration number: [690/4518] 15% | Training loss: 0.6877840784148893
Epoch: 70 | Iteration number: [700/4518] 15% | Training loss: 0.6877776370729719
Epoch: 70 | Iteration number: [710/4518] 15% | Training loss: 0.6877523130094502
Epoch: 70 | Iteration number: [720/4518] 15% | Training loss: 0.6877383852170573
Epoch: 70 | Iteration number: [730/4518] 16% | Training loss: 0.6877322780759367
Epoch: 70 | Iteration number: [740/4518] 16% | Training loss: 0.6877370239109606
Epoch: 70 | Iteration number: [750/4518] 16% | Training loss: 0.6877190690835316
Epoch: 70 | Iteration number: [760/4518] 16% | Training loss: 0.6877049085341002
Epoch: 70 | Iteration number: [770/4518] 17% | Training loss: 0.6877027311882415
Epoch: 70 | Iteration number: [780/4518] 17% | Training loss: 0.6876888379836694
Epoch: 70 | Iteration number: [790/4518] 17% | Training loss: 0.6876672494260571
Epoch: 70 | Iteration number: [800/4518] 17% | Training loss: 0.6876565585285426
Epoch: 70 | Iteration number: [810/4518] 17% | Training loss: 0.6876300130361392
Epoch: 70 | Iteration number: [820/4518] 18% | Training loss: 0.6876037890591272
Epoch: 70 | Iteration number: [830/4518] 18% | Training loss: 0.6875911794513105
Epoch: 70 | Iteration number: [840/4518] 18% | Training loss: 0.6875846107800802
Epoch: 70 | Iteration number: [850/4518] 18% | Training loss: 0.6875768453934613
Epoch: 70 | Iteration number: [860/4518] 19% | Training loss: 0.6875671408897223
Epoch: 70 | Iteration number: [870/4518] 19% | Training loss: 0.6875733516682153
Epoch: 70 | Iteration number: [880/4518] 19% | Training loss: 0.6875556155361913
Epoch: 70 | Iteration number: [890/4518] 19% | Training loss: 0.6875473589709635
Epoch: 70 | Iteration number: [900/4518] 19% | Training loss: 0.6875617414712906
Epoch: 70 | Iteration number: [910/4518] 20% | Training loss: 0.6875490998828804
Epoch: 70 | Iteration number: [920/4518] 20% | Training loss: 0.6875309481568959
Epoch: 70 | Iteration number: [930/4518] 20% | Training loss: 0.6875233795694126
Epoch: 70 | Iteration number: [940/4518] 20% | Training loss: 0.6875166809305232
Epoch: 70 | Iteration number: [950/4518] 21% | Training loss: 0.6875071980451283
Epoch: 70 | Iteration number: [960/4518] 21% | Training loss: 0.6875051011020938
Epoch: 70 | Iteration number: [970/4518] 21% | Training loss: 0.6874869347847614
Epoch: 70 | Iteration number: [980/4518] 21% | Training loss: 0.6874729140072453
Epoch: 70 | Iteration number: [990/4518] 21% | Training loss: 0.6874722606003887
Epoch: 70 | Iteration number: [1000/4518] 22% | Training loss: 0.6874581306576729
Epoch: 70 | Iteration number: [1010/4518] 22% | Training loss: 0.6874532525492186
Epoch: 70 | Iteration number: [1020/4518] 22% | Training loss: 0.6874672830689187
Epoch: 70 | Iteration number: [1030/4518] 22% | Training loss: 0.6874609274771607
Epoch: 70 | Iteration number: [1040/4518] 23% | Training loss: 0.6874572960803143
Epoch: 70 | Iteration number: [1050/4518] 23% | Training loss: 0.6874409555253529
Epoch: 70 | Iteration number: [1060/4518] 23% | Training loss: 0.6874237043115328
Epoch: 70 | Iteration number: [1070/4518] 23% | Training loss: 0.6874136298059303
Epoch: 70 | Iteration number: [1080/4518] 23% | Training loss: 0.6874116750778976
Epoch: 70 | Iteration number: [1090/4518] 24% | Training loss: 0.6874203207295969
Epoch: 70 | Iteration number: [1100/4518] 24% | Training loss: 0.6874133686585859
Epoch: 70 | Iteration number: [1110/4518] 24% | Training loss: 0.6874078954662288
Epoch: 70 | Iteration number: [1120/4518] 24% | Training loss: 0.687395268785102
Epoch: 70 | Iteration number: [1130/4518] 25% | Training loss: 0.6873852333663839
Epoch: 70 | Iteration number: [1140/4518] 25% | Training loss: 0.6873831191083841
Epoch: 70 | Iteration number: [1150/4518] 25% | Training loss: 0.6873744386693705
Epoch: 70 | Iteration number: [1160/4518] 25% | Training loss: 0.6873739294964691
Epoch: 70 | Iteration number: [1170/4518] 25% | Training loss: 0.6873734390124296
Epoch: 70 | Iteration number: [1180/4518] 26% | Training loss: 0.6873537592463574
Epoch: 70 | Iteration number: [1190/4518] 26% | Training loss: 0.6873487914309783
Epoch: 70 | Iteration number: [1200/4518] 26% | Training loss: 0.6873366391162078
Epoch: 70 | Iteration number: [1210/4518] 26% | Training loss: 0.6873381907289678
Epoch: 70 | Iteration number: [1220/4518] 27% | Training loss: 0.6873400510334577
Epoch: 70 | Iteration number: [1230/4518] 27% | Training loss: 0.687324400985144
Epoch: 70 | Iteration number: [1240/4518] 27% | Training loss: 0.6873206545749019
Epoch: 70 | Iteration number: [1250/4518] 27% | Training loss: 0.6873178917407989
Epoch: 70 | Iteration number: [1260/4518] 27% | Training loss: 0.6873162259185125
Epoch: 70 | Iteration number: [1270/4518] 28% | Training loss: 0.6873074527331224
Epoch: 70 | Iteration number: [1280/4518] 28% | Training loss: 0.6873173730447888
Epoch: 70 | Iteration number: [1290/4518] 28% | Training loss: 0.6873231479363848
Epoch: 70 | Iteration number: [1300/4518] 28% | Training loss: 0.6873148339069807
Epoch: 70 | Iteration number: [1310/4518] 28% | Training loss: 0.6873110611930149
Epoch: 70 | Iteration number: [1320/4518] 29% | Training loss: 0.6873154147556334
Epoch: 70 | Iteration number: [1330/4518] 29% | Training loss: 0.6873177929928428
Epoch: 70 | Iteration number: [1340/4518] 29% | Training loss: 0.6873178796981698
Epoch: 70 | Iteration number: [1350/4518] 29% | Training loss: 0.6873169929009897
Epoch: 70 | Iteration number: [1360/4518] 30% | Training loss: 0.6873217666850371
Epoch: 70 | Iteration number: [1370/4518] 30% | Training loss: 0.6873179219064921
Epoch: 70 | Iteration number: [1380/4518] 30% | Training loss: 0.6873169857954633
Epoch: 70 | Iteration number: [1390/4518] 30% | Training loss: 0.6873199727037828
Epoch: 70 | Iteration number: [1400/4518] 30% | Training loss: 0.6873097638998713
Epoch: 70 | Iteration number: [1410/4518] 31% | Training loss: 0.6873038977173204
Epoch: 70 | Iteration number: [1420/4518] 31% | Training loss: 0.6873079464049406
Epoch: 70 | Iteration number: [1430/4518] 31% | Training loss: 0.68730392464391
Epoch: 70 | Iteration number: [1440/4518] 31% | Training loss: 0.6873028509318828
Epoch: 70 | Iteration number: [1450/4518] 32% | Training loss: 0.6872874332296437
Epoch: 70 | Iteration number: [1460/4518] 32% | Training loss: 0.6872887447272261
Epoch: 70 | Iteration number: [1470/4518] 32% | Training loss: 0.687286550901374
Epoch: 70 | Iteration number: [1480/4518] 32% | Training loss: 0.6872941747307777
Epoch: 70 | Iteration number: [1490/4518] 32% | Training loss: 0.6872770640274022
Epoch: 70 | Iteration number: [1500/4518] 33% | Training loss: 0.6872799782752991
Epoch: 70 | Iteration number: [1510/4518] 33% | Training loss: 0.6872839558203488
Epoch: 70 | Iteration number: [1520/4518] 33% | Training loss: 0.6872836652554963
Epoch: 70 | Iteration number: [1530/4518] 33% | Training loss: 0.6872736963960859
Epoch: 70 | Iteration number: [1540/4518] 34% | Training loss: 0.687265341893419
Epoch: 70 | Iteration number: [1550/4518] 34% | Training loss: 0.6872651999996554
Epoch: 70 | Iteration number: [1560/4518] 34% | Training loss: 0.6872681720898701
Epoch: 70 | Iteration number: [1570/4518] 34% | Training loss: 0.6872584783727196
Epoch: 70 | Iteration number: [1580/4518] 34% | Training loss: 0.6872556342354303
Epoch: 70 | Iteration number: [1590/4518] 35% | Training loss: 0.6872534997058365
Epoch: 70 | Iteration number: [1600/4518] 35% | Training loss: 0.6872500560432673
Epoch: 70 | Iteration number: [1610/4518] 35% | Training loss: 0.6872573620784357
Epoch: 70 | Iteration number: [1620/4518] 35% | Training loss: 0.6872535264786379
Epoch: 70 | Iteration number: [1630/4518] 36% | Training loss: 0.6872465214114979
Epoch: 70 | Iteration number: [1640/4518] 36% | Training loss: 0.6872422715149274
Epoch: 70 | Iteration number: [1650/4518] 36% | Training loss: 0.6872393214341366
Epoch: 70 | Iteration number: [1660/4518] 36% | Training loss: 0.6872293335127543
Epoch: 70 | Iteration number: [1670/4518] 36% | Training loss: 0.6872250627971694
Epoch: 70 | Iteration number: [1680/4518] 37% | Training loss: 0.6872150127731619
Epoch: 70 | Iteration number: [1690/4518] 37% | Training loss: 0.6872126684386349
Epoch: 70 | Iteration number: [1700/4518] 37% | Training loss: 0.6872095096111298
Epoch: 70 | Iteration number: [1710/4518] 37% | Training loss: 0.687209765534652
Epoch: 70 | Iteration number: [1720/4518] 38% | Training loss: 0.6872098837480989
Epoch: 70 | Iteration number: [1730/4518] 38% | Training loss: 0.6872067271284974
Epoch: 70 | Iteration number: [1740/4518] 38% | Training loss: 0.6872031878123338
Epoch: 70 | Iteration number: [1750/4518] 38% | Training loss: 0.6872087271894728
Epoch: 70 | Iteration number: [1760/4518] 38% | Training loss: 0.687200725722042
Epoch: 70 | Iteration number: [1770/4518] 39% | Training loss: 0.6871966760710808
Epoch: 70 | Iteration number: [1780/4518] 39% | Training loss: 0.6871933804469162
Epoch: 70 | Iteration number: [1790/4518] 39% | Training loss: 0.6871930949181818
Epoch: 70 | Iteration number: [1800/4518] 39% | Training loss: 0.6871832408176528
Epoch: 70 | Iteration number: [1810/4518] 40% | Training loss: 0.6871843510569788
Epoch: 70 | Iteration number: [1820/4518] 40% | Training loss: 0.6871835860904757
Epoch: 70 | Iteration number: [1830/4518] 40% | Training loss: 0.6871815196477651
Epoch: 70 | Iteration number: [1840/4518] 40% | Training loss: 0.6871758666699347
Epoch: 70 | Iteration number: [1850/4518] 40% | Training loss: 0.6871791680116911
Epoch: 70 | Iteration number: [1860/4518] 41% | Training loss: 0.687178076563343
Epoch: 70 | Iteration number: [1870/4518] 41% | Training loss: 0.6871683743867008
Epoch: 70 | Iteration number: [1880/4518] 41% | Training loss: 0.6871680042845137
Epoch: 70 | Iteration number: [1890/4518] 41% | Training loss: 0.6871578793361705
Epoch: 70 | Iteration number: [1900/4518] 42% | Training loss: 0.6871578459676944
Epoch: 70 | Iteration number: [1910/4518] 42% | Training loss: 0.6871546647935638
Epoch: 70 | Iteration number: [1920/4518] 42% | Training loss: 0.6871584278220931
Epoch: 70 | Iteration number: [1930/4518] 42% | Training loss: 0.6871635813478361
Epoch: 70 | Iteration number: [1940/4518] 42% | Training loss: 0.687162801992033
Epoch: 70 | Iteration number: [1950/4518] 43% | Training loss: 0.6871608716402299
Epoch: 70 | Iteration number: [1960/4518] 43% | Training loss: 0.6871597118827761
Epoch: 70 | Iteration number: [1970/4518] 43% | Training loss: 0.6871627282672728
Epoch: 70 | Iteration number: [1980/4518] 43% | Training loss: 0.6871656749284629
Epoch: 70 | Iteration number: [1990/4518] 44% | Training loss: 0.6871690555433532
Epoch: 70 | Iteration number: [2000/4518] 44% | Training loss: 0.6871632596254349
Epoch: 70 | Iteration number: [2010/4518] 44% | Training loss: 0.6871619491138269
Epoch: 70 | Iteration number: [2020/4518] 44% | Training loss: 0.6871572832364847
Epoch: 70 | Iteration number: [2030/4518] 44% | Training loss: 0.6871590475437089
Epoch: 70 | Iteration number: [2040/4518] 45% | Training loss: 0.6871554767384248
Epoch: 70 | Iteration number: [2050/4518] 45% | Training loss: 0.6871535512877673
Epoch: 70 | Iteration number: [2060/4518] 45% | Training loss: 0.6871540646819235
Epoch: 70 | Iteration number: [2070/4518] 45% | Training loss: 0.6871486461104979
Epoch: 70 | Iteration number: [2080/4518] 46% | Training loss: 0.6871465328507699
Epoch: 70 | Iteration number: [2090/4518] 46% | Training loss: 0.6871462576126939
Epoch: 70 | Iteration number: [2100/4518] 46% | Training loss: 0.6871443235306512
Epoch: 70 | Iteration number: [2110/4518] 46% | Training loss: 0.6871406380599144
Epoch: 70 | Iteration number: [2120/4518] 46% | Training loss: 0.6871411674989845
Epoch: 70 | Iteration number: [2130/4518] 47% | Training loss: 0.6871404559959269
Epoch: 70 | Iteration number: [2140/4518] 47% | Training loss: 0.6871367513019347
Epoch: 70 | Iteration number: [2150/4518] 47% | Training loss: 0.6871297463705374
Epoch: 70 | Iteration number: [2160/4518] 47% | Training loss: 0.6871305735574829
Epoch: 70 | Iteration number: [2170/4518] 48% | Training loss: 0.687126206994606
Epoch: 70 | Iteration number: [2180/4518] 48% | Training loss: 0.6871210355824287
Epoch: 70 | Iteration number: [2190/4518] 48% | Training loss: 0.6871208339249162
Epoch: 70 | Iteration number: [2200/4518] 48% | Training loss: 0.687121277234771
Epoch: 70 | Iteration number: [2210/4518] 48% | Training loss: 0.6871173759391405
Epoch: 70 | Iteration number: [2220/4518] 49% | Training loss: 0.6871115054633167
Epoch: 70 | Iteration number: [2230/4518] 49% | Training loss: 0.6871097211880535
Epoch: 70 | Iteration number: [2240/4518] 49% | Training loss: 0.6871083440259099
Epoch: 70 | Iteration number: [2250/4518] 49% | Training loss: 0.6871095406744215
Epoch: 70 | Iteration number: [2260/4518] 50% | Training loss: 0.6871032941921622
Epoch: 70 | Iteration number: [2270/4518] 50% | Training loss: 0.6871016450390417
Epoch: 70 | Iteration number: [2280/4518] 50% | Training loss: 0.687097188856518
Epoch: 70 | Iteration number: [2290/4518] 50% | Training loss: 0.6870945198567153
Epoch: 70 | Iteration number: [2300/4518] 50% | Training loss: 0.6870921655323194
Epoch: 70 | Iteration number: [2310/4518] 51% | Training loss: 0.6870906569999018
Epoch: 70 | Iteration number: [2320/4518] 51% | Training loss: 0.6870918584537917
Epoch: 70 | Iteration number: [2330/4518] 51% | Training loss: 0.6870925794599394
Epoch: 70 | Iteration number: [2340/4518] 51% | Training loss: 0.6870784082728574
Epoch: 70 | Iteration number: [2350/4518] 52% | Training loss: 0.6870798616206393
Epoch: 70 | Iteration number: [2360/4518] 52% | Training loss: 0.687077872202558
Epoch: 70 | Iteration number: [2370/4518] 52% | Training loss: 0.687075706800831
Epoch: 70 | Iteration number: [2380/4518] 52% | Training loss: 0.6870789227866325
Epoch: 70 | Iteration number: [2390/4518] 52% | Training loss: 0.6870782501527953
Epoch: 70 | Iteration number: [2400/4518] 53% | Training loss: 0.6870789537578821
Epoch: 70 | Iteration number: [2410/4518] 53% | Training loss: 0.6870775340009032
Epoch: 70 | Iteration number: [2420/4518] 53% | Training loss: 0.6870740774002942
Epoch: 70 | Iteration number: [2430/4518] 53% | Training loss: 0.6870678076282941
Epoch: 70 | Iteration number: [2440/4518] 54% | Training loss: 0.6870650857198434
Epoch: 70 | Iteration number: [2450/4518] 54% | Training loss: 0.6870629067323646
Epoch: 70 | Iteration number: [2460/4518] 54% | Training loss: 0.6870617387982888
Epoch: 70 | Iteration number: [2470/4518] 54% | Training loss: 0.6870587772927303
Epoch: 70 | Iteration number: [2480/4518] 54% | Training loss: 0.6870531066050453
Epoch: 70 | Iteration number: [2490/4518] 55% | Training loss: 0.6870502272762927
Epoch: 70 | Iteration number: [2500/4518] 55% | Training loss: 0.6870549880027771
Epoch: 70 | Iteration number: [2510/4518] 55% | Training loss: 0.6870454431292545
Epoch: 70 | Iteration number: [2520/4518] 55% | Training loss: 0.6870434122189643
Epoch: 70 | Iteration number: [2530/4518] 55% | Training loss: 0.6870423306118358
Epoch: 70 | Iteration number: [2540/4518] 56% | Training loss: 0.6870431143233157
Epoch: 70 | Iteration number: [2550/4518] 56% | Training loss: 0.6870441425781624
Epoch: 70 | Iteration number: [2560/4518] 56% | Training loss: 0.6870440364815295
Epoch: 70 | Iteration number: [2570/4518] 56% | Training loss: 0.6870437550637508
Epoch: 70 | Iteration number: [2580/4518] 57% | Training loss: 0.6870448223611181
Epoch: 70 | Iteration number: [2590/4518] 57% | Training loss: 0.687046317704396
Epoch: 70 | Iteration number: [2600/4518] 57% | Training loss: 0.6870422078095949
Epoch: 70 | Iteration number: [2610/4518] 57% | Training loss: 0.6870456947677437
Epoch: 70 | Iteration number: [2620/4518] 57% | Training loss: 0.6870453905285769
Epoch: 70 | Iteration number: [2630/4518] 58% | Training loss: 0.6870425168552327
Epoch: 70 | Iteration number: [2640/4518] 58% | Training loss: 0.6870415061260715
Epoch: 70 | Iteration number: [2650/4518] 58% | Training loss: 0.68704186738662
Epoch: 70 | Iteration number: [2660/4518] 58% | Training loss: 0.6870435612766366
Epoch: 70 | Iteration number: [2670/4518] 59% | Training loss: 0.6870378950785162
Epoch: 70 | Iteration number: [2680/4518] 59% | Training loss: 0.68703564269774
Epoch: 70 | Iteration number: [2690/4518] 59% | Training loss: 0.6870320864548027
Epoch: 70 | Iteration number: [2700/4518] 59% | Training loss: 0.6870334895010348
Epoch: 70 | Iteration number: [2710/4518] 59% | Training loss: 0.6870288315954244
Epoch: 70 | Iteration number: [2720/4518] 60% | Training loss: 0.6870288181173451
Epoch: 70 | Iteration number: [2730/4518] 60% | Training loss: 0.6870260107866574
Epoch: 70 | Iteration number: [2740/4518] 60% | Training loss: 0.6870273795006049
Epoch: 70 | Iteration number: [2750/4518] 60% | Training loss: 0.6870274813175201
Epoch: 70 | Iteration number: [2760/4518] 61% | Training loss: 0.6870332559165747
Epoch: 70 | Iteration number: [2770/4518] 61% | Training loss: 0.6870325542529138
Epoch: 70 | Iteration number: [2780/4518] 61% | Training loss: 0.6870345240874256
Epoch: 70 | Iteration number: [2790/4518] 61% | Training loss: 0.6870353307347998
Epoch: 70 | Iteration number: [2800/4518] 61% | Training loss: 0.6870331986674241
Epoch: 70 | Iteration number: [2810/4518] 62% | Training loss: 0.6870324631390623
Epoch: 70 | Iteration number: [2820/4518] 62% | Training loss: 0.68703334445649
Epoch: 70 | Iteration number: [2830/4518] 62% | Training loss: 0.6870357554919307
Epoch: 70 | Iteration number: [2840/4518] 62% | Training loss: 0.6870324041012307
Epoch: 70 | Iteration number: [2850/4518] 63% | Training loss: 0.687029895949782
Epoch: 70 | Iteration number: [2860/4518] 63% | Training loss: 0.6870277488148295
Epoch: 70 | Iteration number: [2870/4518] 63% | Training loss: 0.6870283984556431
Epoch: 70 | Iteration number: [2880/4518] 63% | Training loss: 0.6870272108457155
Epoch: 70 | Iteration number: [2890/4518] 63% | Training loss: 0.687026986283827
Epoch: 70 | Iteration number: [2900/4518] 64% | Training loss: 0.6870245612284233
Epoch: 70 | Iteration number: [2910/4518] 64% | Training loss: 0.6870203664417529
Epoch: 70 | Iteration number: [2920/4518] 64% | Training loss: 0.6870206140696186
Epoch: 70 | Iteration number: [2930/4518] 64% | Training loss: 0.6870174078607721
Epoch: 70 | Iteration number: [2940/4518] 65% | Training loss: 0.6870152075071724
Epoch: 70 | Iteration number: [2950/4518] 65% | Training loss: 0.6870108462390253
Epoch: 70 | Iteration number: [2960/4518] 65% | Training loss: 0.6870063253552527
Epoch: 70 | Iteration number: [2970/4518] 65% | Training loss: 0.687005983639245
Epoch: 70 | Iteration number: [2980/4518] 65% | Training loss: 0.6870023434394158
Epoch: 70 | Iteration number: [2990/4518] 66% | Training loss: 0.6870003541377077
Epoch: 70 | Iteration number: [3000/4518] 66% | Training loss: 0.6870027447342872
Epoch: 70 | Iteration number: [3010/4518] 66% | Training loss: 0.6869987678092183
Epoch: 70 | Iteration number: [3020/4518] 66% | Training loss: 0.6869972770774602
Epoch: 70 | Iteration number: [3030/4518] 67% | Training loss: 0.6869974693646131
Epoch: 70 | Iteration number: [3040/4518] 67% | Training loss: 0.6869979417441707
Epoch: 70 | Iteration number: [3050/4518] 67% | Training loss: 0.6869976325894965
Epoch: 70 | Iteration number: [3060/4518] 67% | Training loss: 0.686994935620844
Epoch: 70 | Iteration number: [3070/4518] 67% | Training loss: 0.6869958113769755
Epoch: 70 | Iteration number: [3080/4518] 68% | Training loss: 0.6869949427517977
Epoch: 70 | Iteration number: [3090/4518] 68% | Training loss: 0.686989988941205
Epoch: 70 | Iteration number: [3100/4518] 68% | Training loss: 0.6869845885999741
Epoch: 70 | Iteration number: [3110/4518] 68% | Training loss: 0.6869841461204639
Epoch: 70 | Iteration number: [3120/4518] 69% | Training loss: 0.6869804852665999
Epoch: 70 | Iteration number: [3130/4518] 69% | Training loss: 0.6869784270231716
Epoch: 70 | Iteration number: [3140/4518] 69% | Training loss: 0.6869820044868311
Epoch: 70 | Iteration number: [3150/4518] 69% | Training loss: 0.6869832442866431
Epoch: 70 | Iteration number: [3160/4518] 69% | Training loss: 0.6869772150358068
Epoch: 70 | Iteration number: [3170/4518] 70% | Training loss: 0.6869742324487644
Epoch: 70 | Iteration number: [3180/4518] 70% | Training loss: 0.6869704927101076
Epoch: 70 | Iteration number: [3190/4518] 70% | Training loss: 0.6869726151508224
Epoch: 70 | Iteration number: [3200/4518] 70% | Training loss: 0.6869752796553076
Epoch: 70 | Iteration number: [3210/4518] 71% | Training loss: 0.686971877427116
Epoch: 70 | Iteration number: [3220/4518] 71% | Training loss: 0.6869711790025604
Epoch: 70 | Iteration number: [3230/4518] 71% | Training loss: 0.6869713754292243
Epoch: 70 | Iteration number: [3240/4518] 71% | Training loss: 0.6869701013704876
Epoch: 70 | Iteration number: [3250/4518] 71% | Training loss: 0.68696927519945
Epoch: 70 | Iteration number: [3260/4518] 72% | Training loss: 0.686974079879515
Epoch: 70 | Iteration number: [3270/4518] 72% | Training loss: 0.6869723969460992
Epoch: 70 | Iteration number: [3280/4518] 72% | Training loss: 0.6869718119502067
Epoch: 70 | Iteration number: [3290/4518] 72% | Training loss: 0.6869685844266306
Epoch: 70 | Iteration number: [3300/4518] 73% | Training loss: 0.6869704539667476
Epoch: 70 | Iteration number: [3310/4518] 73% | Training loss: 0.6869696461542135
Epoch: 70 | Iteration number: [3320/4518] 73% | Training loss: 0.6869685338383698
Epoch: 70 | Iteration number: [3330/4518] 73% | Training loss: 0.6869708984642774
Epoch: 70 | Iteration number: [3340/4518] 73% | Training loss: 0.6869735894624345
Epoch: 70 | Iteration number: [3350/4518] 74% | Training loss: 0.6869706770199449
Epoch: 70 | Iteration number: [3360/4518] 74% | Training loss: 0.6869685278052375
Epoch: 70 | Iteration number: [3370/4518] 74% | Training loss: 0.6869670461653248
Epoch: 70 | Iteration number: [3380/4518] 74% | Training loss: 0.6869686868063797
Epoch: 70 | Iteration number: [3390/4518] 75% | Training loss: 0.6869706134880539
Epoch: 70 | Iteration number: [3400/4518] 75% | Training loss: 0.6869736164457658
Epoch: 70 | Iteration number: [3410/4518] 75% | Training loss: 0.6869716603909769
Epoch: 70 | Iteration number: [3420/4518] 75% | Training loss: 0.6869741848163438
Epoch: 70 | Iteration number: [3430/4518] 75% | Training loss: 0.6869765122847377
Epoch: 70 | Iteration number: [3440/4518] 76% | Training loss: 0.6869751318942668
Epoch: 70 | Iteration number: [3450/4518] 76% | Training loss: 0.686979827431665
Epoch: 70 | Iteration number: [3460/4518] 76% | Training loss: 0.6869816324614376
Epoch: 70 | Iteration number: [3470/4518] 76% | Training loss: 0.6869822540613004
Epoch: 70 | Iteration number: [3480/4518] 77% | Training loss: 0.6869809477664959
Epoch: 70 | Iteration number: [3490/4518] 77% | Training loss: 0.6869824718267665
Epoch: 70 | Iteration number: [3500/4518] 77% | Training loss: 0.6869849376337869
Epoch: 70 | Iteration number: [3510/4518] 77% | Training loss: 0.6869866297795222
Epoch: 70 | Iteration number: [3520/4518] 77% | Training loss: 0.6869890003888445
Epoch: 70 | Iteration number: [3530/4518] 78% | Training loss: 0.6869853123051587
Epoch: 70 | Iteration number: [3540/4518] 78% | Training loss: 0.6869850359562427
Epoch: 70 | Iteration number: [3550/4518] 78% | Training loss: 0.6869867655592905
Epoch: 70 | Iteration number: [3560/4518] 78% | Training loss: 0.6869871226756761
Epoch: 70 | Iteration number: [3570/4518] 79% | Training loss: 0.6869862370464315
Epoch: 70 | Iteration number: [3580/4518] 79% | Training loss: 0.6869839288835419
Epoch: 70 | Iteration number: [3590/4518] 79% | Training loss: 0.6869826004697752
Epoch: 70 | Iteration number: [3600/4518] 79% | Training loss: 0.6869820269942284
Epoch: 70 | Iteration number: [3610/4518] 79% | Training loss: 0.6869778562780893
Epoch: 70 | Iteration number: [3620/4518] 80% | Training loss: 0.686978992506944
Epoch: 70 | Iteration number: [3630/4518] 80% | Training loss: 0.6869788053771353
Epoch: 70 | Iteration number: [3640/4518] 80% | Training loss: 0.6869742185532391
Epoch: 70 | Iteration number: [3650/4518] 80% | Training loss: 0.6869700990964288
Epoch: 70 | Iteration number: [3660/4518] 81% | Training loss: 0.6869699318552278
Epoch: 70 | Iteration number: [3670/4518] 81% | Training loss: 0.686966722489053
Epoch: 70 | Iteration number: [3680/4518] 81% | Training loss: 0.6869673349773107
Epoch: 70 | Iteration number: [3690/4518] 81% | Training loss: 0.6869675959028849
Epoch: 70 | Iteration number: [3700/4518] 81% | Training loss: 0.6869606206062677
Epoch: 70 | Iteration number: [3710/4518] 82% | Training loss: 0.6869633538061075
Epoch: 70 | Iteration number: [3720/4518] 82% | Training loss: 0.6869609638728121
Epoch: 70 | Iteration number: [3730/4518] 82% | Training loss: 0.6869553491513147
Epoch: 70 | Iteration number: [3740/4518] 82% | Training loss: 0.6869552152042083
Epoch: 70 | Iteration number: [3750/4518] 83% | Training loss: 0.6869588716348012
Epoch: 70 | Iteration number: [3760/4518] 83% | Training loss: 0.6869569790965699
Epoch: 70 | Iteration number: [3770/4518] 83% | Training loss: 0.6869582604033877
Epoch: 70 | Iteration number: [3780/4518] 83% | Training loss: 0.68695624628395
Epoch: 70 | Iteration number: [3790/4518] 83% | Training loss: 0.6869540729120098
Epoch: 70 | Iteration number: [3800/4518] 84% | Training loss: 0.686954857722709
Epoch: 70 | Iteration number: [3810/4518] 84% | Training loss: 0.6869529042813409
Epoch: 70 | Iteration number: [3820/4518] 84% | Training loss: 0.6869535928621342
Epoch: 70 | Iteration number: [3830/4518] 84% | Training loss: 0.6869544342199131
Epoch: 70 | Iteration number: [3840/4518] 84% | Training loss: 0.68695291695185
Epoch: 70 | Iteration number: [3850/4518] 85% | Training loss: 0.6869533677224989
Epoch: 70 | Iteration number: [3860/4518] 85% | Training loss: 0.6869575502495692
Epoch: 70 | Iteration number: [3870/4518] 85% | Training loss: 0.6869585918209657
Epoch: 70 | Iteration number: [3880/4518] 85% | Training loss: 0.6869565358942317
Epoch: 70 | Iteration number: [3890/4518] 86% | Training loss: 0.6869584128758595
Epoch: 70 | Iteration number: [3900/4518] 86% | Training loss: 0.6869594170955511
Epoch: 70 | Iteration number: [3910/4518] 86% | Training loss: 0.6869596908312015
Epoch: 70 | Iteration number: [3920/4518] 86% | Training loss: 0.6869580342909511
Epoch: 70 | Iteration number: [3930/4518] 86% | Training loss: 0.6869583678761209
Epoch: 70 | Iteration number: [3940/4518] 87% | Training loss: 0.6869571316968366
Epoch: 70 | Iteration number: [3950/4518] 87% | Training loss: 0.6869549075561233
Epoch: 70 | Iteration number: [3960/4518] 87% | Training loss: 0.6869565711027444
Epoch: 70 | Iteration number: [3970/4518] 87% | Training loss: 0.6869575176491245
Epoch: 70 | Iteration number: [3980/4518] 88% | Training loss: 0.686955714555242
Epoch: 70 | Iteration number: [3990/4518] 88% | Training loss: 0.6869555319311624
Epoch: 70 | Iteration number: [4000/4518] 88% | Training loss: 0.6869561441093683
Epoch: 70 | Iteration number: [4010/4518] 88% | Training loss: 0.6869556957498155
Epoch: 70 | Iteration number: [4020/4518] 88% | Training loss: 0.6869569831078325
Epoch: 70 | Iteration number: [4030/4518] 89% | Training loss: 0.6869592926194591
Epoch: 70 | Iteration number: [4040/4518] 89% | Training loss: 0.6869603851496583
Epoch: 70 | Iteration number: [4050/4518] 89% | Training loss: 0.6869577820507097
Epoch: 70 | Iteration number: [4060/4518] 89% | Training loss: 0.6869584123489305
Epoch: 70 | Iteration number: [4070/4518] 90% | Training loss: 0.6869577722701745
Epoch: 70 | Iteration number: [4080/4518] 90% | Training loss: 0.686960130871511
Epoch: 70 | Iteration number: [4090/4518] 90% | Training loss: 0.6869623417959236
Epoch: 70 | Iteration number: [4100/4518] 90% | Training loss: 0.6869642310753101
Epoch: 70 | Iteration number: [4110/4518] 90% | Training loss: 0.6869634805369551
Epoch: 70 | Iteration number: [4120/4518] 91% | Training loss: 0.6869624657683002
Epoch: 70 | Iteration number: [4130/4518] 91% | Training loss: 0.6869624103818621
Epoch: 70 | Iteration number: [4140/4518] 91% | Training loss: 0.6869622318784971
Epoch: 70 | Iteration number: [4150/4518] 91% | Training loss: 0.6869622702770922
Epoch: 70 | Iteration number: [4160/4518] 92% | Training loss: 0.6869638258448014
Epoch: 70 | Iteration number: [4170/4518] 92% | Training loss: 0.6869596798214124
Epoch: 70 | Iteration number: [4180/4518] 92% | Training loss: 0.6869573725039879
Epoch: 70 | Iteration number: [4190/4518] 92% | Training loss: 0.6869561620003284
Epoch: 70 | Iteration number: [4200/4518] 92% | Training loss: 0.6869553423921267
Epoch: 70 | Iteration number: [4210/4518] 93% | Training loss: 0.6869563574037756
Epoch: 70 | Iteration number: [4220/4518] 93% | Training loss: 0.6869549752694171
Epoch: 70 | Iteration number: [4230/4518] 93% | Training loss: 0.6869551115988558
Epoch: 70 | Iteration number: [4240/4518] 93% | Training loss: 0.6869546364922569
Epoch: 70 | Iteration number: [4250/4518] 94% | Training loss: 0.6869549700652852
Epoch: 70 | Iteration number: [4260/4518] 94% | Training loss: 0.6869559115926984
Epoch: 70 | Iteration number: [4270/4518] 94% | Training loss: 0.6869571186898743
Epoch: 70 | Iteration number: [4280/4518] 94% | Training loss: 0.6869565304612445
Epoch: 70 | Iteration number: [4290/4518] 94% | Training loss: 0.6869562230465851
Epoch: 70 | Iteration number: [4300/4518] 95% | Training loss: 0.6869593225107636
Epoch: 70 | Iteration number: [4310/4518] 95% | Training loss: 0.686958960037497
Epoch: 70 | Iteration number: [4320/4518] 95% | Training loss: 0.6869561302993032
Epoch: 70 | Iteration number: [4330/4518] 95% | Training loss: 0.6869573844497804
Epoch: 70 | Iteration number: [4340/4518] 96% | Training loss: 0.6869568676580482
Epoch: 70 | Iteration number: [4350/4518] 96% | Training loss: 0.6869552134371352
Epoch: 70 | Iteration number: [4360/4518] 96% | Training loss: 0.6869531942480201
Epoch: 70 | Iteration number: [4370/4518] 96% | Training loss: 0.6869514741122859
Epoch: 70 | Iteration number: [4380/4518] 96% | Training loss: 0.6869510268647921
Epoch: 70 | Iteration number: [4390/4518] 97% | Training loss: 0.686951420098068
Epoch: 70 | Iteration number: [4400/4518] 97% | Training loss: 0.6869483788176016
Epoch: 70 | Iteration number: [4410/4518] 97% | Training loss: 0.6869485978366566
Epoch: 70 | Iteration number: [4420/4518] 97% | Training loss: 0.6869444977374098
Epoch: 70 | Iteration number: [4430/4518] 98% | Training loss: 0.686943976281728
Epoch: 70 | Iteration number: [4440/4518] 98% | Training loss: 0.6869409065525811
Epoch: 70 | Iteration number: [4450/4518] 98% | Training loss: 0.6869366564911403
Epoch: 70 | Iteration number: [4460/4518] 98% | Training loss: 0.6869376176943159
Epoch: 70 | Iteration number: [4470/4518] 98% | Training loss: 0.6869351310884659
Epoch: 70 | Iteration number: [4480/4518] 99% | Training loss: 0.6869328348631305
Epoch: 70 | Iteration number: [4490/4518] 99% | Training loss: 0.6869317560259642
Epoch: 70 | Iteration number: [4500/4518] 99% | Training loss: 0.6869322053856319
Epoch: 70 | Iteration number: [4510/4518] 99% | Training loss: 0.6869309231738029

 End of epoch: 70 | Train Loss: 0.6867775240135489 | Training Time: 630 

 End of epoch: 70 | Eval Loss: 0.6896684607680963 | Evaluating Time: 17 
Epoch: 71 | Iteration number: [10/4518] 0% | Training loss: 0.7549995183944702
Epoch: 71 | Iteration number: [20/4518] 0% | Training loss: 0.7209656983613968
Epoch: 71 | Iteration number: [30/4518] 0% | Training loss: 0.7101601878801982
Epoch: 71 | Iteration number: [40/4518] 0% | Training loss: 0.7044498860836029
Epoch: 71 | Iteration number: [50/4518] 1% | Training loss: 0.7007547354698181
Epoch: 71 | Iteration number: [60/4518] 1% | Training loss: 0.6984876235326131
Epoch: 71 | Iteration number: [70/4518] 1% | Training loss: 0.6966541843754904
Epoch: 71 | Iteration number: [80/4518] 1% | Training loss: 0.6954201243817806
Epoch: 71 | Iteration number: [90/4518] 1% | Training loss: 0.6944330890973409
Epoch: 71 | Iteration number: [100/4518] 2% | Training loss: 0.6936867344379425
Epoch: 71 | Iteration number: [110/4518] 2% | Training loss: 0.6928974129936912
Epoch: 71 | Iteration number: [120/4518] 2% | Training loss: 0.6923720608154933
Epoch: 71 | Iteration number: [130/4518] 2% | Training loss: 0.6918380884023813
Epoch: 71 | Iteration number: [140/4518] 3% | Training loss: 0.6914108429636274
Epoch: 71 | Iteration number: [150/4518] 3% | Training loss: 0.6911362580458323
Epoch: 71 | Iteration number: [160/4518] 3% | Training loss: 0.6908396393060684
Epoch: 71 | Iteration number: [170/4518] 3% | Training loss: 0.6905815531225765
Epoch: 71 | Iteration number: [180/4518] 3% | Training loss: 0.6903481390741136
Epoch: 71 | Iteration number: [190/4518] 4% | Training loss: 0.6902371629288322
Epoch: 71 | Iteration number: [200/4518] 4% | Training loss: 0.6900389638543128
Epoch: 71 | Iteration number: [210/4518] 4% | Training loss: 0.6899216404982975
Epoch: 71 | Iteration number: [220/4518] 4% | Training loss: 0.6897876804525201
Epoch: 71 | Iteration number: [230/4518] 5% | Training loss: 0.689672119980273
Epoch: 71 | Iteration number: [240/4518] 5% | Training loss: 0.6895918520788352
Epoch: 71 | Iteration number: [250/4518] 5% | Training loss: 0.6894957931041718
Epoch: 71 | Iteration number: [260/4518] 5% | Training loss: 0.689384087232443
Epoch: 71 | Iteration number: [270/4518] 5% | Training loss: 0.6892531825436486
Epoch: 71 | Iteration number: [280/4518] 6% | Training loss: 0.6891663851482528
Epoch: 71 | Iteration number: [290/4518] 6% | Training loss: 0.689107248495365
Epoch: 71 | Iteration number: [300/4518] 6% | Training loss: 0.6890232678254445
Epoch: 71 | Iteration number: [310/4518] 6% | Training loss: 0.6889540401197249
Epoch: 71 | Iteration number: [320/4518] 7% | Training loss: 0.6888906121253967
Epoch: 71 | Iteration number: [330/4518] 7% | Training loss: 0.6887872914473215
Epoch: 71 | Iteration number: [340/4518] 7% | Training loss: 0.6887309218154234
Epoch: 71 | Iteration number: [350/4518] 7% | Training loss: 0.6886800193786621
Epoch: 71 | Iteration number: [360/4518] 7% | Training loss: 0.6886007654998038
Epoch: 71 | Iteration number: [370/4518] 8% | Training loss: 0.6885270714759827
Epoch: 71 | Iteration number: [380/4518] 8% | Training loss: 0.6885064168980247
Epoch: 71 | Iteration number: [390/4518] 8% | Training loss: 0.688447651037803
Epoch: 71 | Iteration number: [400/4518] 8% | Training loss: 0.6884312979876995
Epoch: 71 | Iteration number: [410/4518] 9% | Training loss: 0.6884135256453259
Epoch: 71 | Iteration number: [420/4518] 9% | Training loss: 0.6883634476434617
Epoch: 71 | Iteration number: [430/4518] 9% | Training loss: 0.6883256743120593
Epoch: 71 | Iteration number: [440/4518] 9% | Training loss: 0.688313627243042
Epoch: 71 | Iteration number: [450/4518] 9% | Training loss: 0.6882873458332486
Epoch: 71 | Iteration number: [460/4518] 10% | Training loss: 0.6882645752118981
Epoch: 71 | Iteration number: [470/4518] 10% | Training loss: 0.6882331791076254
Epoch: 71 | Iteration number: [480/4518] 10% | Training loss: 0.6881865702569485
Epoch: 71 | Iteration number: [490/4518] 10% | Training loss: 0.6881704049451011
Epoch: 71 | Iteration number: [500/4518] 11% | Training loss: 0.6881418213844299
Epoch: 71 | Iteration number: [510/4518] 11% | Training loss: 0.6881248822399214
Epoch: 71 | Iteration number: [520/4518] 11% | Training loss: 0.6880952412119279
Epoch: 71 | Iteration number: [530/4518] 11% | Training loss: 0.6880428769678439
Epoch: 71 | Iteration number: [540/4518] 11% | Training loss: 0.6880116181241142
Epoch: 71 | Iteration number: [550/4518] 12% | Training loss: 0.6879900952902707
Epoch: 71 | Iteration number: [560/4518] 12% | Training loss: 0.6879584891455514
Epoch: 71 | Iteration number: [570/4518] 12% | Training loss: 0.6879153698159938
Epoch: 71 | Iteration number: [580/4518] 12% | Training loss: 0.6878860689442733
Epoch: 71 | Iteration number: [590/4518] 13% | Training loss: 0.6878842420497183
Epoch: 71 | Iteration number: [600/4518] 13% | Training loss: 0.6878823480010032
Epoch: 71 | Iteration number: [610/4518] 13% | Training loss: 0.6878747593183987
Epoch: 71 | Iteration number: [620/4518] 13% | Training loss: 0.687868990436677
Epoch: 71 | Iteration number: [630/4518] 13% | Training loss: 0.6878584336666834
Epoch: 71 | Iteration number: [640/4518] 14% | Training loss: 0.6878459411673248
Epoch: 71 | Iteration number: [650/4518] 14% | Training loss: 0.6878271833749918
Epoch: 71 | Iteration number: [660/4518] 14% | Training loss: 0.6878210266431173
Epoch: 71 | Iteration number: [670/4518] 14% | Training loss: 0.6878116282064524
Epoch: 71 | Iteration number: [680/4518] 15% | Training loss: 0.6878018597469611
Epoch: 71 | Iteration number: [690/4518] 15% | Training loss: 0.6877785128095876
Epoch: 71 | Iteration number: [700/4518] 15% | Training loss: 0.6877573815413883
Epoch: 71 | Iteration number: [710/4518] 15% | Training loss: 0.6877318931297517
Epoch: 71 | Iteration number: [720/4518] 15% | Training loss: 0.6877065448297395
Epoch: 71 | Iteration number: [730/4518] 16% | Training loss: 0.6877095120410397
Epoch: 71 | Iteration number: [740/4518] 16% | Training loss: 0.6876976095341347
Epoch: 71 | Iteration number: [750/4518] 16% | Training loss: 0.6876775240898132
Epoch: 71 | Iteration number: [760/4518] 16% | Training loss: 0.6876607363945559
Epoch: 71 | Iteration number: [770/4518] 17% | Training loss: 0.687635296505767
Epoch: 71 | Iteration number: [780/4518] 17% | Training loss: 0.687610084659014
Epoch: 71 | Iteration number: [790/4518] 17% | Training loss: 0.6875999942610536
Epoch: 71 | Iteration number: [800/4518] 17% | Training loss: 0.687586925253272
Epoch: 71 | Iteration number: [810/4518] 17% | Training loss: 0.687595405254835
Epoch: 71 | Iteration number: [820/4518] 18% | Training loss: 0.6875804475167903
Epoch: 71 | Iteration number: [830/4518] 18% | Training loss: 0.6875756642186498
Epoch: 71 | Iteration number: [840/4518] 18% | Training loss: 0.6875603184813545
Epoch: 71 | Iteration number: [850/4518] 18% | Training loss: 0.6875590701664195
Epoch: 71 | Iteration number: [860/4518] 19% | Training loss: 0.687535650854887
Epoch: 71 | Iteration number: [870/4518] 19% | Training loss: 0.6875211671851147
Epoch: 71 | Iteration number: [880/4518] 19% | Training loss: 0.6875163404779001
Epoch: 71 | Iteration number: [890/4518] 19% | Training loss: 0.6875058375717549
Epoch: 71 | Iteration number: [900/4518] 19% | Training loss: 0.6875067584382163
Epoch: 71 | Iteration number: [910/4518] 20% | Training loss: 0.6874899998470977
Epoch: 71 | Iteration number: [920/4518] 20% | Training loss: 0.6874843373894691
Epoch: 71 | Iteration number: [930/4518] 20% | Training loss: 0.6874796513588198
Epoch: 71 | Iteration number: [940/4518] 20% | Training loss: 0.6874710072862341
Epoch: 71 | Iteration number: [950/4518] 21% | Training loss: 0.6874522755020543
Epoch: 71 | Iteration number: [960/4518] 21% | Training loss: 0.6874477587019404
Epoch: 71 | Iteration number: [970/4518] 21% | Training loss: 0.6874478845252204
Epoch: 71 | Iteration number: [980/4518] 21% | Training loss: 0.6874396324765926
Epoch: 71 | Iteration number: [990/4518] 21% | Training loss: 0.6874267085634097
Epoch: 71 | Iteration number: [1000/4518] 22% | Training loss: 0.6874193490147591
Epoch: 71 | Iteration number: [1010/4518] 22% | Training loss: 0.6874136631441589
Epoch: 71 | Iteration number: [1020/4518] 22% | Training loss: 0.6873972367422253
Epoch: 71 | Iteration number: [1030/4518] 22% | Training loss: 0.6873772821958782
Epoch: 71 | Iteration number: [1040/4518] 23% | Training loss: 0.6873714710657414
Epoch: 71 | Iteration number: [1050/4518] 23% | Training loss: 0.6873612426008497
Epoch: 71 | Iteration number: [1060/4518] 23% | Training loss: 0.6873560497783265
Epoch: 71 | Iteration number: [1070/4518] 23% | Training loss: 0.6873476669610104
Epoch: 71 | Iteration number: [1080/4518] 23% | Training loss: 0.6873359297712643
Epoch: 71 | Iteration number: [1090/4518] 24% | Training loss: 0.6873357402622153
Epoch: 71 | Iteration number: [1100/4518] 24% | Training loss: 0.6873302495479584
Epoch: 71 | Iteration number: [1110/4518] 24% | Training loss: 0.6873215294099069
Epoch: 71 | Iteration number: [1120/4518] 24% | Training loss: 0.6873131813747543
Epoch: 71 | Iteration number: [1130/4518] 25% | Training loss: 0.6873074170234984
Epoch: 71 | Iteration number: [1140/4518] 25% | Training loss: 0.6873051392927504
Epoch: 71 | Iteration number: [1150/4518] 25% | Training loss: 0.6873009162363799
Epoch: 71 | Iteration number: [1160/4518] 25% | Training loss: 0.6872979655348022
Epoch: 71 | Iteration number: [1170/4518] 25% | Training loss: 0.6872945819655035
Epoch: 71 | Iteration number: [1180/4518] 26% | Training loss: 0.6873041388341936
Epoch: 71 | Iteration number: [1190/4518] 26% | Training loss: 0.6872936173146512
Epoch: 71 | Iteration number: [1200/4518] 26% | Training loss: 0.687291353046894
Epoch: 71 | Iteration number: [1210/4518] 26% | Training loss: 0.6872845746761511
Epoch: 71 | Iteration number: [1220/4518] 27% | Training loss: 0.6872811381934119
Epoch: 71 | Iteration number: [1230/4518] 27% | Training loss: 0.687270427477069
Epoch: 71 | Iteration number: [1240/4518] 27% | Training loss: 0.6872627443844272
Epoch: 71 | Iteration number: [1250/4518] 27% | Training loss: 0.6872677684307098
Epoch: 71 | Iteration number: [1260/4518] 27% | Training loss: 0.6872548167194639
Epoch: 71 | Iteration number: [1270/4518] 28% | Training loss: 0.6872473614891683
Epoch: 71 | Iteration number: [1280/4518] 28% | Training loss: 0.6872483802959323
Epoch: 71 | Iteration number: [1290/4518] 28% | Training loss: 0.6872367564559907
Epoch: 71 | Iteration number: [1300/4518] 28% | Training loss: 0.6872138552482312
Epoch: 71 | Iteration number: [1310/4518] 28% | Training loss: 0.6872097967235187
Epoch: 71 | Iteration number: [1320/4518] 29% | Training loss: 0.6872124493573651
Epoch: 71 | Iteration number: [1330/4518] 29% | Training loss: 0.6872180179097599
Epoch: 71 | Iteration number: [1340/4518] 29% | Training loss: 0.6872193651857661
Epoch: 71 | Iteration number: [1350/4518] 29% | Training loss: 0.6872163048938469
Epoch: 71 | Iteration number: [1360/4518] 30% | Training loss: 0.6872191277496955
Epoch: 71 | Iteration number: [1370/4518] 30% | Training loss: 0.6872155857782294
Epoch: 71 | Iteration number: [1380/4518] 30% | Training loss: 0.6872142913548843
Epoch: 71 | Iteration number: [1390/4518] 30% | Training loss: 0.6872119916428765
Epoch: 71 | Iteration number: [1400/4518] 30% | Training loss: 0.687203964974199
Epoch: 71 | Iteration number: [1410/4518] 31% | Training loss: 0.6872090919220701
Epoch: 71 | Iteration number: [1420/4518] 31% | Training loss: 0.6872044073024266
Epoch: 71 | Iteration number: [1430/4518] 31% | Training loss: 0.6872022938478243
Epoch: 71 | Iteration number: [1440/4518] 31% | Training loss: 0.6871987477772765
Epoch: 71 | Iteration number: [1450/4518] 32% | Training loss: 0.687194211688535
Epoch: 71 | Iteration number: [1460/4518] 32% | Training loss: 0.6871817792115146
Epoch: 71 | Iteration number: [1470/4518] 32% | Training loss: 0.6871847247996298
Epoch: 71 | Iteration number: [1480/4518] 32% | Training loss: 0.6871769627203812
Epoch: 71 | Iteration number: [1490/4518] 32% | Training loss: 0.687178608315103
Epoch: 71 | Iteration number: [1500/4518] 33% | Training loss: 0.6871770457029343
Epoch: 71 | Iteration number: [1510/4518] 33% | Training loss: 0.6871775071352523
Epoch: 71 | Iteration number: [1520/4518] 33% | Training loss: 0.6871749610493058
Epoch: 71 | Iteration number: [1530/4518] 33% | Training loss: 0.687171696759517
Epoch: 71 | Iteration number: [1540/4518] 34% | Training loss: 0.6871700840336936
Epoch: 71 | Iteration number: [1550/4518] 34% | Training loss: 0.6871630324471382
Epoch: 71 | Iteration number: [1560/4518] 34% | Training loss: 0.6871634618594096
Epoch: 71 | Iteration number: [1570/4518] 34% | Training loss: 0.6871614065519563
Epoch: 71 | Iteration number: [1580/4518] 34% | Training loss: 0.6871586940333813
Epoch: 71 | Iteration number: [1590/4518] 35% | Training loss: 0.6871600275144637
Epoch: 71 | Iteration number: [1600/4518] 35% | Training loss: 0.6871551088988781
Epoch: 71 | Iteration number: [1610/4518] 35% | Training loss: 0.6871520539618426
Epoch: 71 | Iteration number: [1620/4518] 35% | Training loss: 0.6871495607458515
Epoch: 71 | Iteration number: [1630/4518] 36% | Training loss: 0.6871538653329837
Epoch: 71 | Iteration number: [1640/4518] 36% | Training loss: 0.6871481396439599
Epoch: 71 | Iteration number: [1650/4518] 36% | Training loss: 0.6871477484341824
Epoch: 71 | Iteration number: [1660/4518] 36% | Training loss: 0.6871485176574753
Epoch: 71 | Iteration number: [1670/4518] 36% | Training loss: 0.6871466890066683
Epoch: 71 | Iteration number: [1680/4518] 37% | Training loss: 0.6871443965605327
Epoch: 71 | Iteration number: [1690/4518] 37% | Training loss: 0.6871426751627725
Epoch: 71 | Iteration number: [1700/4518] 37% | Training loss: 0.6871440473374198
Epoch: 71 | Iteration number: [1710/4518] 37% | Training loss: 0.6871408087816852
Epoch: 71 | Iteration number: [1720/4518] 38% | Training loss: 0.6871362684424533
Epoch: 71 | Iteration number: [1730/4518] 38% | Training loss: 0.6871296415783766
Epoch: 71 | Iteration number: [1740/4518] 38% | Training loss: 0.6871334802830357
Epoch: 71 | Iteration number: [1750/4518] 38% | Training loss: 0.687130289724895
Epoch: 71 | Iteration number: [1760/4518] 38% | Training loss: 0.6871269409629431
Epoch: 71 | Iteration number: [1770/4518] 39% | Training loss: 0.6871284046752305
Epoch: 71 | Iteration number: [1780/4518] 39% | Training loss: 0.687125792597117
Epoch: 71 | Iteration number: [1790/4518] 39% | Training loss: 0.6871193021036394
Epoch: 71 | Iteration number: [1800/4518] 39% | Training loss: 0.6871167233917448
Epoch: 71 | Iteration number: [1810/4518] 40% | Training loss: 0.6871115001525668
Epoch: 71 | Iteration number: [1820/4518] 40% | Training loss: 0.6871116522249284
Epoch: 71 | Iteration number: [1830/4518] 40% | Training loss: 0.6871060537510231
Epoch: 71 | Iteration number: [1840/4518] 40% | Training loss: 0.6870987347934557
Epoch: 71 | Iteration number: [1850/4518] 40% | Training loss: 0.6871012899360142
Epoch: 71 | Iteration number: [1860/4518] 41% | Training loss: 0.6871027444319059
Epoch: 71 | Iteration number: [1870/4518] 41% | Training loss: 0.6870924451134421
Epoch: 71 | Iteration number: [1880/4518] 41% | Training loss: 0.6870914999791916
Epoch: 71 | Iteration number: [1890/4518] 41% | Training loss: 0.6870886102239921
Epoch: 71 | Iteration number: [1900/4518] 42% | Training loss: 0.6870848550921992
Epoch: 71 | Iteration number: [1910/4518] 42% | Training loss: 0.6870813200299029
Epoch: 71 | Iteration number: [1920/4518] 42% | Training loss: 0.6870752975034217
Epoch: 71 | Iteration number: [1930/4518] 42% | Training loss: 0.687076242044182
Epoch: 71 | Iteration number: [1940/4518] 42% | Training loss: 0.6870752475003606
Epoch: 71 | Iteration number: [1950/4518] 43% | Training loss: 0.6870712810907609
Epoch: 71 | Iteration number: [1960/4518] 43% | Training loss: 0.687075387975391
Epoch: 71 | Iteration number: [1970/4518] 43% | Training loss: 0.6870773450069622
Epoch: 71 | Iteration number: [1980/4518] 43% | Training loss: 0.6870673273548935
Epoch: 71 | Iteration number: [1990/4518] 44% | Training loss: 0.6870678101951753
Epoch: 71 | Iteration number: [2000/4518] 44% | Training loss: 0.6870633310675621
Epoch: 71 | Iteration number: [2010/4518] 44% | Training loss: 0.6870632652619585
Epoch: 71 | Iteration number: [2020/4518] 44% | Training loss: 0.6870666867730642
Epoch: 71 | Iteration number: [2030/4518] 44% | Training loss: 0.6870583117595447
Epoch: 71 | Iteration number: [2040/4518] 45% | Training loss: 0.687061023069363
Epoch: 71 | Iteration number: [2050/4518] 45% | Training loss: 0.6870648195394655
Epoch: 71 | Iteration number: [2060/4518] 45% | Training loss: 0.6870669256425598
Epoch: 71 | Iteration number: [2070/4518] 45% | Training loss: 0.6870671039042265
Epoch: 71 | Iteration number: [2080/4518] 46% | Training loss: 0.6870670149532648
Epoch: 71 | Iteration number: [2090/4518] 46% | Training loss: 0.687058726537741
Epoch: 71 | Iteration number: [2100/4518] 46% | Training loss: 0.6870569350322088
Epoch: 71 | Iteration number: [2110/4518] 46% | Training loss: 0.6870534917754585
Epoch: 71 | Iteration number: [2120/4518] 46% | Training loss: 0.6870559227072968
Epoch: 71 | Iteration number: [2130/4518] 47% | Training loss: 0.6870580987191536
Epoch: 71 | Iteration number: [2140/4518] 47% | Training loss: 0.6870605754796589
Epoch: 71 | Iteration number: [2150/4518] 47% | Training loss: 0.6870632341573405
Epoch: 71 | Iteration number: [2160/4518] 47% | Training loss: 0.687070465253459
Epoch: 71 | Iteration number: [2170/4518] 48% | Training loss: 0.6870651431622044
Epoch: 71 | Iteration number: [2180/4518] 48% | Training loss: 0.6870578723489691
Epoch: 71 | Iteration number: [2190/4518] 48% | Training loss: 0.6870557256757397
Epoch: 71 | Iteration number: [2200/4518] 48% | Training loss: 0.6870526121421294
Epoch: 71 | Iteration number: [2210/4518] 48% | Training loss: 0.6870513061322777
Epoch: 71 | Iteration number: [2220/4518] 49% | Training loss: 0.6870513962732779
Epoch: 71 | Iteration number: [2230/4518] 49% | Training loss: 0.6870458786797631
Epoch: 71 | Iteration number: [2240/4518] 49% | Training loss: 0.6870438207473074
Epoch: 71 | Iteration number: [2250/4518] 49% | Training loss: 0.6870434337192112
Epoch: 71 | Iteration number: [2260/4518] 50% | Training loss: 0.6870450346343285
Epoch: 71 | Iteration number: [2270/4518] 50% | Training loss: 0.6870441977148014
Epoch: 71 | Iteration number: [2280/4518] 50% | Training loss: 0.6870400987434806
Epoch: 71 | Iteration number: [2290/4518] 50% | Training loss: 0.6870412795824775
Epoch: 71 | Iteration number: [2300/4518] 50% | Training loss: 0.6870428001103194
Epoch: 71 | Iteration number: [2310/4518] 51% | Training loss: 0.6870464824494862
Epoch: 71 | Iteration number: [2320/4518] 51% | Training loss: 0.6870470164151027
Epoch: 71 | Iteration number: [2330/4518] 51% | Training loss: 0.6870464851416231
Epoch: 71 | Iteration number: [2340/4518] 51% | Training loss: 0.6870414878313358
Epoch: 71 | Iteration number: [2350/4518] 52% | Training loss: 0.6870411369902022
Epoch: 71 | Iteration number: [2360/4518] 52% | Training loss: 0.6870436012492341
Epoch: 71 | Iteration number: [2370/4518] 52% | Training loss: 0.6870441674180172
Epoch: 71 | Iteration number: [2380/4518] 52% | Training loss: 0.6870445301803221
Epoch: 71 | Iteration number: [2390/4518] 52% | Training loss: 0.6870446663770715
Epoch: 71 | Iteration number: [2400/4518] 53% | Training loss: 0.6870416302233935
Epoch: 71 | Iteration number: [2410/4518] 53% | Training loss: 0.6870497930099361
Epoch: 71 | Iteration number: [2420/4518] 53% | Training loss: 0.6870464711642462
Epoch: 71 | Iteration number: [2430/4518] 53% | Training loss: 0.6870465829293915
Epoch: 71 | Iteration number: [2440/4518] 54% | Training loss: 0.6870440811407371
Epoch: 71 | Iteration number: [2450/4518] 54% | Training loss: 0.687046866976485
Epoch: 71 | Iteration number: [2460/4518] 54% | Training loss: 0.6870446197143415
Epoch: 71 | Iteration number: [2470/4518] 54% | Training loss: 0.6870415268639322
Epoch: 71 | Iteration number: [2480/4518] 54% | Training loss: 0.6870391139099675
Epoch: 71 | Iteration number: [2490/4518] 55% | Training loss: 0.6870382953121001
Epoch: 71 | Iteration number: [2500/4518] 55% | Training loss: 0.6870345206737518
Epoch: 71 | Iteration number: [2510/4518] 55% | Training loss: 0.6870394271683408
Epoch: 71 | Iteration number: [2520/4518] 55% | Training loss: 0.6870391315411007
Epoch: 71 | Iteration number: [2530/4518] 55% | Training loss: 0.687039625833157
Epoch: 71 | Iteration number: [2540/4518] 56% | Training loss: 0.6870386849003514
Epoch: 71 | Iteration number: [2550/4518] 56% | Training loss: 0.6870343244543262
Epoch: 71 | Iteration number: [2560/4518] 56% | Training loss: 0.6870372958481312
Epoch: 71 | Iteration number: [2570/4518] 56% | Training loss: 0.6870321824856769
Epoch: 71 | Iteration number: [2580/4518] 57% | Training loss: 0.6870296180479286
Epoch: 71 | Iteration number: [2590/4518] 57% | Training loss: 0.6870258087126905
Epoch: 71 | Iteration number: [2600/4518] 57% | Training loss: 0.6870249092808136
Epoch: 71 | Iteration number: [2610/4518] 57% | Training loss: 0.687026657500943
Epoch: 71 | Iteration number: [2620/4518] 57% | Training loss: 0.6870219790526019
Epoch: 71 | Iteration number: [2630/4518] 58% | Training loss: 0.6870222483297718
Epoch: 71 | Iteration number: [2640/4518] 58% | Training loss: 0.6870239944846341
Epoch: 71 | Iteration number: [2650/4518] 58% | Training loss: 0.6870209301417729
Epoch: 71 | Iteration number: [2660/4518] 58% | Training loss: 0.6870210501484405
Epoch: 71 | Iteration number: [2670/4518] 59% | Training loss: 0.6870220286122869
Epoch: 71 | Iteration number: [2680/4518] 59% | Training loss: 0.6870218433995745
Epoch: 71 | Iteration number: [2690/4518] 59% | Training loss: 0.687021705829521
Epoch: 71 | Iteration number: [2700/4518] 59% | Training loss: 0.6870227511282321
Epoch: 71 | Iteration number: [2710/4518] 59% | Training loss: 0.6870226908873808
Epoch: 71 | Iteration number: [2720/4518] 60% | Training loss: 0.6870179952724892
Epoch: 71 | Iteration number: [2730/4518] 60% | Training loss: 0.6870187581022144
Epoch: 71 | Iteration number: [2740/4518] 60% | Training loss: 0.6870214931286165
Epoch: 71 | Iteration number: [2750/4518] 60% | Training loss: 0.6870206551118331
Epoch: 71 | Iteration number: [2760/4518] 61% | Training loss: 0.6870197211486706
Epoch: 71 | Iteration number: [2770/4518] 61% | Training loss: 0.6870210402709052
Epoch: 71 | Iteration number: [2780/4518] 61% | Training loss: 0.6870213635748239
Epoch: 71 | Iteration number: [2790/4518] 61% | Training loss: 0.6870127140193857
Epoch: 71 | Iteration number: [2800/4518] 61% | Training loss: 0.6870082153592791
Epoch: 71 | Iteration number: [2810/4518] 62% | Training loss: 0.6870043077927043
Epoch: 71 | Iteration number: [2820/4518] 62% | Training loss: 0.6870008946944636
Epoch: 71 | Iteration number: [2830/4518] 62% | Training loss: 0.6870025216690643
Epoch: 71 | Iteration number: [2840/4518] 62% | Training loss: 0.6869970373914276
Epoch: 71 | Iteration number: [2850/4518] 63% | Training loss: 0.686998503291816
Epoch: 71 | Iteration number: [2860/4518] 63% | Training loss: 0.6869950388486569
Epoch: 71 | Iteration number: [2870/4518] 63% | Training loss: 0.6869944964967123
Epoch: 71 | Iteration number: [2880/4518] 63% | Training loss: 0.6869922811786334
Epoch: 71 | Iteration number: [2890/4518] 63% | Training loss: 0.686992526549369
Epoch: 71 | Iteration number: [2900/4518] 64% | Training loss: 0.6869938672616565
Epoch: 71 | Iteration number: [2910/4518] 64% | Training loss: 0.6869885890139746
Epoch: 71 | Iteration number: [2920/4518] 64% | Training loss: 0.6869799617626896
Epoch: 71 | Iteration number: [2930/4518] 64% | Training loss: 0.686982528361851
Epoch: 71 | Iteration number: [2940/4518] 65% | Training loss: 0.6869793188004266
Epoch: 71 | Iteration number: [2950/4518] 65% | Training loss: 0.686985759391623
Epoch: 71 | Iteration number: [2960/4518] 65% | Training loss: 0.6869812082398582
Epoch: 71 | Iteration number: [2970/4518] 65% | Training loss: 0.6869839046137903
Epoch: 71 | Iteration number: [2980/4518] 65% | Training loss: 0.6869843097741172
Epoch: 71 | Iteration number: [2990/4518] 66% | Training loss: 0.6869834504797308
Epoch: 71 | Iteration number: [3000/4518] 66% | Training loss: 0.686981874704361
Epoch: 71 | Iteration number: [3010/4518] 66% | Training loss: 0.6869735815200299
Epoch: 71 | Iteration number: [3020/4518] 66% | Training loss: 0.6869692725258947
Epoch: 71 | Iteration number: [3030/4518] 67% | Training loss: 0.6869734771377576
Epoch: 71 | Iteration number: [3040/4518] 67% | Training loss: 0.6869740343015445
Epoch: 71 | Iteration number: [3050/4518] 67% | Training loss: 0.6869777421091424
Epoch: 71 | Iteration number: [3060/4518] 67% | Training loss: 0.6869770853153241
Epoch: 71 | Iteration number: [3070/4518] 67% | Training loss: 0.6869781815267929
Epoch: 71 | Iteration number: [3080/4518] 68% | Training loss: 0.6869779213682398
Epoch: 71 | Iteration number: [3090/4518] 68% | Training loss: 0.6869787621073739
Epoch: 71 | Iteration number: [3100/4518] 68% | Training loss: 0.6869785911421622
Epoch: 71 | Iteration number: [3110/4518] 68% | Training loss: 0.6869781109872738
Epoch: 71 | Iteration number: [3120/4518] 69% | Training loss: 0.6869766159699513
Epoch: 71 | Iteration number: [3130/4518] 69% | Training loss: 0.6869776002515239
Epoch: 71 | Iteration number: [3140/4518] 69% | Training loss: 0.6869810060710664
Epoch: 71 | Iteration number: [3150/4518] 69% | Training loss: 0.6869812011907971
Epoch: 71 | Iteration number: [3160/4518] 69% | Training loss: 0.686983930027183
Epoch: 71 | Iteration number: [3170/4518] 70% | Training loss: 0.686982070553566
Epoch: 71 | Iteration number: [3180/4518] 70% | Training loss: 0.6869790375982441
Epoch: 71 | Iteration number: [3190/4518] 70% | Training loss: 0.6869776308723378
Epoch: 71 | Iteration number: [3200/4518] 70% | Training loss: 0.6869715000130237
Epoch: 71 | Iteration number: [3210/4518] 71% | Training loss: 0.686967151465817
Epoch: 71 | Iteration number: [3220/4518] 71% | Training loss: 0.6869658186198762
Epoch: 71 | Iteration number: [3230/4518] 71% | Training loss: 0.6869705627761759
Epoch: 71 | Iteration number: [3240/4518] 71% | Training loss: 0.6869745544997262
Epoch: 71 | Iteration number: [3250/4518] 71% | Training loss: 0.6869730293200567
Epoch: 71 | Iteration number: [3260/4518] 72% | Training loss: 0.686971939451124
Epoch: 71 | Iteration number: [3270/4518] 72% | Training loss: 0.6869741998681235
Epoch: 71 | Iteration number: [3280/4518] 72% | Training loss: 0.6869758906706077
Epoch: 71 | Iteration number: [3290/4518] 72% | Training loss: 0.6869757157147475
Epoch: 71 | Iteration number: [3300/4518] 73% | Training loss: 0.6869752452590249
Epoch: 71 | Iteration number: [3310/4518] 73% | Training loss: 0.6869711779755768
Epoch: 71 | Iteration number: [3320/4518] 73% | Training loss: 0.6869741880570549
Epoch: 71 | Iteration number: [3330/4518] 73% | Training loss: 0.6869735428878853
Epoch: 71 | Iteration number: [3340/4518] 73% | Training loss: 0.6869718413153094
Epoch: 71 | Iteration number: [3350/4518] 74% | Training loss: 0.6869733906326009
Epoch: 71 | Iteration number: [3360/4518] 74% | Training loss: 0.6869746468429054
Epoch: 71 | Iteration number: [3370/4518] 74% | Training loss: 0.6869690370488944
Epoch: 71 | Iteration number: [3380/4518] 74% | Training loss: 0.6869658579487773
Epoch: 71 | Iteration number: [3390/4518] 75% | Training loss: 0.6869700006503271
Epoch: 71 | Iteration number: [3400/4518] 75% | Training loss: 0.6869685739103486
Epoch: 71 | Iteration number: [3410/4518] 75% | Training loss: 0.6869714477369863
Epoch: 71 | Iteration number: [3420/4518] 75% | Training loss: 0.6869720720233973
Epoch: 71 | Iteration number: [3430/4518] 75% | Training loss: 0.6869693702407202
Epoch: 71 | Iteration number: [3440/4518] 76% | Training loss: 0.6869694237272407
Epoch: 71 | Iteration number: [3450/4518] 76% | Training loss: 0.6869665528553119
Epoch: 71 | Iteration number: [3460/4518] 76% | Training loss: 0.6869673641603117
Epoch: 71 | Iteration number: [3470/4518] 76% | Training loss: 0.686966378235336
Epoch: 71 | Iteration number: [3480/4518] 77% | Training loss: 0.686962727448721
Epoch: 71 | Iteration number: [3490/4518] 77% | Training loss: 0.6869609721752156
Epoch: 71 | Iteration number: [3500/4518] 77% | Training loss: 0.6869585885831287
Epoch: 71 | Iteration number: [3510/4518] 77% | Training loss: 0.6869587104035239
Epoch: 71 | Iteration number: [3520/4518] 77% | Training loss: 0.68696034044366
Epoch: 71 | Iteration number: [3530/4518] 78% | Training loss: 0.6869613032503101
Epoch: 71 | Iteration number: [3540/4518] 78% | Training loss: 0.6869663214952932
Epoch: 71 | Iteration number: [3550/4518] 78% | Training loss: 0.6869632321008494
Epoch: 71 | Iteration number: [3560/4518] 78% | Training loss: 0.6869669740287105
Epoch: 71 | Iteration number: [3570/4518] 79% | Training loss: 0.6869662428269533
Epoch: 71 | Iteration number: [3580/4518] 79% | Training loss: 0.6869652343029417
Epoch: 71 | Iteration number: [3590/4518] 79% | Training loss: 0.6869637788836338
Epoch: 71 | Iteration number: [3600/4518] 79% | Training loss: 0.6869632268283102
Epoch: 71 | Iteration number: [3610/4518] 79% | Training loss: 0.6869627186796342
Epoch: 71 | Iteration number: [3620/4518] 80% | Training loss: 0.6869615989001416
Epoch: 71 | Iteration number: [3630/4518] 80% | Training loss: 0.686960048485065
Epoch: 71 | Iteration number: [3640/4518] 80% | Training loss: 0.6869597855505053
Epoch: 71 | Iteration number: [3650/4518] 80% | Training loss: 0.686960197246238
Epoch: 71 | Iteration number: [3660/4518] 81% | Training loss: 0.6869554583166466
Epoch: 71 | Iteration number: [3670/4518] 81% | Training loss: 0.6869548636983461
Epoch: 71 | Iteration number: [3680/4518] 81% | Training loss: 0.6869542943070764
Epoch: 71 | Iteration number: [3690/4518] 81% | Training loss: 0.6869570157230708
Epoch: 71 | Iteration number: [3700/4518] 81% | Training loss: 0.6869592957399987
Epoch: 71 | Iteration number: [3710/4518] 82% | Training loss: 0.6869595521383208
Epoch: 71 | Iteration number: [3720/4518] 82% | Training loss: 0.6869632186107738
Epoch: 71 | Iteration number: [3730/4518] 82% | Training loss: 0.6869630417139856
Epoch: 71 | Iteration number: [3740/4518] 82% | Training loss: 0.6869645725915776
Epoch: 71 | Iteration number: [3750/4518] 83% | Training loss: 0.6869627448240916
Epoch: 71 | Iteration number: [3760/4518] 83% | Training loss: 0.686960237235465
Epoch: 71 | Iteration number: [3770/4518] 83% | Training loss: 0.6869650639494788
Epoch: 71 | Iteration number: [3780/4518] 83% | Training loss: 0.6869635326048684
Epoch: 71 | Iteration number: [3790/4518] 83% | Training loss: 0.6869672446106229
Epoch: 71 | Iteration number: [3800/4518] 84% | Training loss: 0.6869641001444113
Epoch: 71 | Iteration number: [3810/4518] 84% | Training loss: 0.686964108077247
Epoch: 71 | Iteration number: [3820/4518] 84% | Training loss: 0.6869654970955474
Epoch: 71 | Iteration number: [3830/4518] 84% | Training loss: 0.6869650109629718
Epoch: 71 | Iteration number: [3840/4518] 84% | Training loss: 0.6869672311159472
Epoch: 71 | Iteration number: [3850/4518] 85% | Training loss: 0.6869683460600965
Epoch: 71 | Iteration number: [3860/4518] 85% | Training loss: 0.6869680166398923
Epoch: 71 | Iteration number: [3870/4518] 85% | Training loss: 0.6869666631061594
Epoch: 71 | Iteration number: [3880/4518] 85% | Training loss: 0.6869673047329962
Epoch: 71 | Iteration number: [3890/4518] 86% | Training loss: 0.6869678995603155
Epoch: 71 | Iteration number: [3900/4518] 86% | Training loss: 0.6869704279685632
Epoch: 71 | Iteration number: [3910/4518] 86% | Training loss: 0.6869701034730048
Epoch: 71 | Iteration number: [3920/4518] 86% | Training loss: 0.6869674528435785
Epoch: 71 | Iteration number: [3930/4518] 86% | Training loss: 0.6869703904818033
Epoch: 71 | Iteration number: [3940/4518] 87% | Training loss: 0.686968719944131
Epoch: 71 | Iteration number: [3950/4518] 87% | Training loss: 0.6869693033755581
Epoch: 71 | Iteration number: [3960/4518] 87% | Training loss: 0.6869698762442127
Epoch: 71 | Iteration number: [3970/4518] 87% | Training loss: 0.6869674874342959
Epoch: 71 | Iteration number: [3980/4518] 88% | Training loss: 0.6869659791489942
Epoch: 71 | Iteration number: [3990/4518] 88% | Training loss: 0.6869642934106047
Epoch: 71 | Iteration number: [4000/4518] 88% | Training loss: 0.6869668956249952
Epoch: 71 | Iteration number: [4010/4518] 88% | Training loss: 0.6869677646647665
Epoch: 71 | Iteration number: [4020/4518] 88% | Training loss: 0.6869698822350051
Epoch: 71 | Iteration number: [4030/4518] 89% | Training loss: 0.6869656807139849
Epoch: 71 | Iteration number: [4040/4518] 89% | Training loss: 0.6869651415117897
Epoch: 71 | Iteration number: [4050/4518] 89% | Training loss: 0.6869653987884522
Epoch: 71 | Iteration number: [4060/4518] 89% | Training loss: 0.6869618247588867
Epoch: 71 | Iteration number: [4070/4518] 90% | Training loss: 0.6869597261602228
Epoch: 71 | Iteration number: [4080/4518] 90% | Training loss: 0.6869582397096298
Epoch: 71 | Iteration number: [4090/4518] 90% | Training loss: 0.6869569675700881
Epoch: 71 | Iteration number: [4100/4518] 90% | Training loss: 0.6869555167890177
Epoch: 71 | Iteration number: [4110/4518] 90% | Training loss: 0.6869566949324596
Epoch: 71 | Iteration number: [4120/4518] 91% | Training loss: 0.686954570568881
Epoch: 71 | Iteration number: [4130/4518] 91% | Training loss: 0.6869568599194071
Epoch: 71 | Iteration number: [4140/4518] 91% | Training loss: 0.6869557678987439
Epoch: 71 | Iteration number: [4150/4518] 91% | Training loss: 0.68695334813681
Epoch: 71 | Iteration number: [4160/4518] 92% | Training loss: 0.6869555002508255
Epoch: 71 | Iteration number: [4170/4518] 92% | Training loss: 0.6869521635327693
Epoch: 71 | Iteration number: [4180/4518] 92% | Training loss: 0.6869526386973961
Epoch: 71 | Iteration number: [4190/4518] 92% | Training loss: 0.6869445921839848
Epoch: 71 | Iteration number: [4200/4518] 92% | Training loss: 0.686943406235604
Epoch: 71 | Iteration number: [4210/4518] 93% | Training loss: 0.6869391219491346
Epoch: 71 | Iteration number: [4220/4518] 93% | Training loss: 0.6869377104168255
Epoch: 71 | Iteration number: [4230/4518] 93% | Training loss: 0.6869342100958452
Epoch: 71 | Iteration number: [4240/4518] 93% | Training loss: 0.686936016844691
Epoch: 71 | Iteration number: [4250/4518] 94% | Training loss: 0.6869328407820533
Epoch: 71 | Iteration number: [4260/4518] 94% | Training loss: 0.6869341664191143
Epoch: 71 | Iteration number: [4270/4518] 94% | Training loss: 0.6869355951874262
Epoch: 71 | Iteration number: [4280/4518] 94% | Training loss: 0.6869353740850341
Epoch: 71 | Iteration number: [4290/4518] 94% | Training loss: 0.6869336349841876
Epoch: 71 | Iteration number: [4300/4518] 95% | Training loss: 0.6869367629844089
Epoch: 71 | Iteration number: [4310/4518] 95% | Training loss: 0.6869351964262411
Epoch: 71 | Iteration number: [4320/4518] 95% | Training loss: 0.6869341991979767
Epoch: 71 | Iteration number: [4330/4518] 95% | Training loss: 0.6869326025867022
Epoch: 71 | Iteration number: [4340/4518] 96% | Training loss: 0.6869340985326723
Epoch: 71 | Iteration number: [4350/4518] 96% | Training loss: 0.6869329516504002
Epoch: 71 | Iteration number: [4360/4518] 96% | Training loss: 0.6869288882941281
Epoch: 71 | Iteration number: [4370/4518] 96% | Training loss: 0.6869262319544087
Epoch: 71 | Iteration number: [4380/4518] 96% | Training loss: 0.6869270257345618
Epoch: 71 | Iteration number: [4390/4518] 97% | Training loss: 0.6869269180678018
Epoch: 71 | Iteration number: [4400/4518] 97% | Training loss: 0.6869255803660913
Epoch: 71 | Iteration number: [4410/4518] 97% | Training loss: 0.6869266413912481
Epoch: 71 | Iteration number: [4420/4518] 97% | Training loss: 0.6869275053971493
Epoch: 71 | Iteration number: [4430/4518] 98% | Training loss: 0.6869300417921613
Epoch: 71 | Iteration number: [4440/4518] 98% | Training loss: 0.6869305477620246
Epoch: 71 | Iteration number: [4450/4518] 98% | Training loss: 0.686932984885205
Epoch: 71 | Iteration number: [4460/4518] 98% | Training loss: 0.6869323210197714
Epoch: 71 | Iteration number: [4470/4518] 98% | Training loss: 0.6869304053468726
Epoch: 71 | Iteration number: [4480/4518] 99% | Training loss: 0.6869320241867432
Epoch: 71 | Iteration number: [4490/4518] 99% | Training loss: 0.6869309477922911
Epoch: 71 | Iteration number: [4500/4518] 99% | Training loss: 0.686927542620235
Epoch: 71 | Iteration number: [4510/4518] 99% | Training loss: 0.6869250803987625

 End of epoch: 71 | Train Loss: 0.6867713145367494 | Training Time: 632 

 End of epoch: 71 | Eval Loss: 0.689633691797451 | Evaluating Time: 17 
Epoch: 72 | Iteration number: [10/4518] 0% | Training loss: 0.7538054347038269
Epoch: 72 | Iteration number: [20/4518] 0% | Training loss: 0.7198973774909974
Epoch: 72 | Iteration number: [30/4518] 0% | Training loss: 0.7085205455621083
Epoch: 72 | Iteration number: [40/4518] 0% | Training loss: 0.7030321404337883
Epoch: 72 | Iteration number: [50/4518] 1% | Training loss: 0.6997012543678284
Epoch: 72 | Iteration number: [60/4518] 1% | Training loss: 0.6975383003552754
Epoch: 72 | Iteration number: [70/4518] 1% | Training loss: 0.6959416278770991
Epoch: 72 | Iteration number: [80/4518] 1% | Training loss: 0.6948605820536613
Epoch: 72 | Iteration number: [90/4518] 1% | Training loss: 0.6939706524213155
Epoch: 72 | Iteration number: [100/4518] 2% | Training loss: 0.69319366812706
Epoch: 72 | Iteration number: [110/4518] 2% | Training loss: 0.6926114635034041
Epoch: 72 | Iteration number: [120/4518] 2% | Training loss: 0.6921762138605118
Epoch: 72 | Iteration number: [130/4518] 2% | Training loss: 0.6916857985349801
Epoch: 72 | Iteration number: [140/4518] 3% | Training loss: 0.6913811053548541
Epoch: 72 | Iteration number: [150/4518] 3% | Training loss: 0.6910008939107259
Epoch: 72 | Iteration number: [160/4518] 3% | Training loss: 0.6907639559358358
Epoch: 72 | Iteration number: [170/4518] 3% | Training loss: 0.6905508227208081
Epoch: 72 | Iteration number: [180/4518] 3% | Training loss: 0.6902732908725738
Epoch: 72 | Iteration number: [190/4518] 4% | Training loss: 0.6900873372429296
Epoch: 72 | Iteration number: [200/4518] 4% | Training loss: 0.6899566388130188
Epoch: 72 | Iteration number: [210/4518] 4% | Training loss: 0.6897921525296711
Epoch: 72 | Iteration number: [220/4518] 4% | Training loss: 0.6897135864604603
Epoch: 72 | Iteration number: [230/4518] 5% | Training loss: 0.6896180044049802
Epoch: 72 | Iteration number: [240/4518] 5% | Training loss: 0.6894958799084028
Epoch: 72 | Iteration number: [250/4518] 5% | Training loss: 0.6893338234424591
Epoch: 72 | Iteration number: [260/4518] 5% | Training loss: 0.689221851183818
Epoch: 72 | Iteration number: [270/4518] 5% | Training loss: 0.6890869109718888
Epoch: 72 | Iteration number: [280/4518] 6% | Training loss: 0.6890200314777238
Epoch: 72 | Iteration number: [290/4518] 6% | Training loss: 0.6889552841926443
Epoch: 72 | Iteration number: [300/4518] 6% | Training loss: 0.6888760008414586
Epoch: 72 | Iteration number: [310/4518] 6% | Training loss: 0.6888464381617885
Epoch: 72 | Iteration number: [320/4518] 7% | Training loss: 0.6887838060036302
Epoch: 72 | Iteration number: [330/4518] 7% | Training loss: 0.6886812461144997
Epoch: 72 | Iteration number: [340/4518] 7% | Training loss: 0.6886012434959412
Epoch: 72 | Iteration number: [350/4518] 7% | Training loss: 0.6885405319077628
Epoch: 72 | Iteration number: [360/4518] 7% | Training loss: 0.6884825370377965
Epoch: 72 | Iteration number: [370/4518] 8% | Training loss: 0.6884176428253587
Epoch: 72 | Iteration number: [380/4518] 8% | Training loss: 0.6883719787785881
Epoch: 72 | Iteration number: [390/4518] 8% | Training loss: 0.6883448397501921
Epoch: 72 | Iteration number: [400/4518] 8% | Training loss: 0.6883266185224056
Epoch: 72 | Iteration number: [410/4518] 9% | Training loss: 0.6882929592597775
Epoch: 72 | Iteration number: [420/4518] 9% | Training loss: 0.6882642345769064
Epoch: 72 | Iteration number: [430/4518] 9% | Training loss: 0.6882599062697832
Epoch: 72 | Iteration number: [440/4518] 9% | Training loss: 0.6881928748705171
Epoch: 72 | Iteration number: [450/4518] 9% | Training loss: 0.6881836472617255
Epoch: 72 | Iteration number: [460/4518] 10% | Training loss: 0.6881665736436844
Epoch: 72 | Iteration number: [470/4518] 10% | Training loss: 0.6881034329850623
Epoch: 72 | Iteration number: [480/4518] 10% | Training loss: 0.6880762594441573
Epoch: 72 | Iteration number: [490/4518] 10% | Training loss: 0.6880710144432224
Epoch: 72 | Iteration number: [500/4518] 11% | Training loss: 0.6880584132671356
Epoch: 72 | Iteration number: [510/4518] 11% | Training loss: 0.6880341598800584
Epoch: 72 | Iteration number: [520/4518] 11% | Training loss: 0.688038739676659
Epoch: 72 | Iteration number: [530/4518] 11% | Training loss: 0.6880361765060785
Epoch: 72 | Iteration number: [540/4518] 11% | Training loss: 0.6880248262926384
Epoch: 72 | Iteration number: [550/4518] 12% | Training loss: 0.6880071007121693
Epoch: 72 | Iteration number: [560/4518] 12% | Training loss: 0.6879766523838043
Epoch: 72 | Iteration number: [570/4518] 12% | Training loss: 0.6879362514144496
Epoch: 72 | Iteration number: [580/4518] 12% | Training loss: 0.6879410295650876
Epoch: 72 | Iteration number: [590/4518] 13% | Training loss: 0.6879124079720449
Epoch: 72 | Iteration number: [600/4518] 13% | Training loss: 0.6879070639610291
Epoch: 72 | Iteration number: [610/4518] 13% | Training loss: 0.6878901766949013
Epoch: 72 | Iteration number: [620/4518] 13% | Training loss: 0.6878504892510753
Epoch: 72 | Iteration number: [630/4518] 13% | Training loss: 0.6878132655507042
Epoch: 72 | Iteration number: [640/4518] 14% | Training loss: 0.6877907072193921
Epoch: 72 | Iteration number: [650/4518] 14% | Training loss: 0.6877608421215644
Epoch: 72 | Iteration number: [660/4518] 14% | Training loss: 0.687746442267389
Epoch: 72 | Iteration number: [670/4518] 14% | Training loss: 0.687743518245754
Epoch: 72 | Iteration number: [680/4518] 15% | Training loss: 0.6877116723972209
Epoch: 72 | Iteration number: [690/4518] 15% | Training loss: 0.6876826611981876
Epoch: 72 | Iteration number: [700/4518] 15% | Training loss: 0.6876725415672574
Epoch: 72 | Iteration number: [710/4518] 15% | Training loss: 0.687668596606859
Epoch: 72 | Iteration number: [720/4518] 15% | Training loss: 0.6876625903778606
Epoch: 72 | Iteration number: [730/4518] 16% | Training loss: 0.6876368556120624
Epoch: 72 | Iteration number: [740/4518] 16% | Training loss: 0.6876420101603946
Epoch: 72 | Iteration number: [750/4518] 16% | Training loss: 0.6876308580239614
Epoch: 72 | Iteration number: [760/4518] 16% | Training loss: 0.6876353290520216
Epoch: 72 | Iteration number: [770/4518] 17% | Training loss: 0.6876237418744471
Epoch: 72 | Iteration number: [780/4518] 17% | Training loss: 0.6876114055896416
Epoch: 72 | Iteration number: [790/4518] 17% | Training loss: 0.6875977776473081
Epoch: 72 | Iteration number: [800/4518] 17% | Training loss: 0.6875613762438297
Epoch: 72 | Iteration number: [810/4518] 17% | Training loss: 0.6875747193524867
Epoch: 72 | Iteration number: [820/4518] 18% | Training loss: 0.6875438789768917
Epoch: 72 | Iteration number: [830/4518] 18% | Training loss: 0.6875331625880965
Epoch: 72 | Iteration number: [840/4518] 18% | Training loss: 0.6875179343989917
Epoch: 72 | Iteration number: [850/4518] 18% | Training loss: 0.687508066261516
Epoch: 72 | Iteration number: [860/4518] 19% | Training loss: 0.6874985744786817
Epoch: 72 | Iteration number: [870/4518] 19% | Training loss: 0.6874933662085697
Epoch: 72 | Iteration number: [880/4518] 19% | Training loss: 0.6874858424744823
Epoch: 72 | Iteration number: [890/4518] 19% | Training loss: 0.687479957703794
Epoch: 72 | Iteration number: [900/4518] 19% | Training loss: 0.6874638423654769
Epoch: 72 | Iteration number: [910/4518] 20% | Training loss: 0.6874515147654565
Epoch: 72 | Iteration number: [920/4518] 20% | Training loss: 0.6874394027435261
Epoch: 72 | Iteration number: [930/4518] 20% | Training loss: 0.6874402772995734
Epoch: 72 | Iteration number: [940/4518] 20% | Training loss: 0.6874327483963459
Epoch: 72 | Iteration number: [950/4518] 21% | Training loss: 0.6874195583243119
Epoch: 72 | Iteration number: [960/4518] 21% | Training loss: 0.6874190193290511
Epoch: 72 | Iteration number: [970/4518] 21% | Training loss: 0.6874230966125567
Epoch: 72 | Iteration number: [980/4518] 21% | Training loss: 0.6874167044552005
Epoch: 72 | Iteration number: [990/4518] 21% | Training loss: 0.6874065416629869
Epoch: 72 | Iteration number: [1000/4518] 22% | Training loss: 0.6873923096656799
Epoch: 72 | Iteration number: [1010/4518] 22% | Training loss: 0.6873931513564422
Epoch: 72 | Iteration number: [1020/4518] 22% | Training loss: 0.6873908121211856
Epoch: 72 | Iteration number: [1030/4518] 22% | Training loss: 0.6873718014041197
Epoch: 72 | Iteration number: [1040/4518] 23% | Training loss: 0.6873783458310824
Epoch: 72 | Iteration number: [1050/4518] 23% | Training loss: 0.687358823560533
Epoch: 72 | Iteration number: [1060/4518] 23% | Training loss: 0.6873527497615455
Epoch: 72 | Iteration number: [1070/4518] 23% | Training loss: 0.6873503427082133
Epoch: 72 | Iteration number: [1080/4518] 23% | Training loss: 0.6873355763377966
Epoch: 72 | Iteration number: [1090/4518] 24% | Training loss: 0.6873313751789408
Epoch: 72 | Iteration number: [1100/4518] 24% | Training loss: 0.6873225778341293
Epoch: 72 | Iteration number: [1110/4518] 24% | Training loss: 0.68732048337524
Epoch: 72 | Iteration number: [1120/4518] 24% | Training loss: 0.6873024045356683
Epoch: 72 | Iteration number: [1130/4518] 25% | Training loss: 0.6872835936272039
Epoch: 72 | Iteration number: [1140/4518] 25% | Training loss: 0.6872777242409556
Epoch: 72 | Iteration number: [1150/4518] 25% | Training loss: 0.6872725215683813
Epoch: 72 | Iteration number: [1160/4518] 25% | Training loss: 0.6872603218103277
Epoch: 72 | Iteration number: [1170/4518] 25% | Training loss: 0.6872612753994445
Epoch: 72 | Iteration number: [1180/4518] 26% | Training loss: 0.6872661057165114
Epoch: 72 | Iteration number: [1190/4518] 26% | Training loss: 0.6872524354638172
Epoch: 72 | Iteration number: [1200/4518] 26% | Training loss: 0.6872574080526829
Epoch: 72 | Iteration number: [1210/4518] 26% | Training loss: 0.6872573389987315
Epoch: 72 | Iteration number: [1220/4518] 27% | Training loss: 0.6872609952922727
Epoch: 72 | Iteration number: [1230/4518] 27% | Training loss: 0.6872701656527636
Epoch: 72 | Iteration number: [1240/4518] 27% | Training loss: 0.6872626396436845
Epoch: 72 | Iteration number: [1250/4518] 27% | Training loss: 0.6872579261302948
Epoch: 72 | Iteration number: [1260/4518] 27% | Training loss: 0.6872581117209934
Epoch: 72 | Iteration number: [1270/4518] 28% | Training loss: 0.687252766597928
Epoch: 72 | Iteration number: [1280/4518] 28% | Training loss: 0.6872468455694616
Epoch: 72 | Iteration number: [1290/4518] 28% | Training loss: 0.6872350628523863
Epoch: 72 | Iteration number: [1300/4518] 28% | Training loss: 0.6872347176533479
Epoch: 72 | Iteration number: [1310/4518] 28% | Training loss: 0.6872355821478457
Epoch: 72 | Iteration number: [1320/4518] 29% | Training loss: 0.6872228621533423
Epoch: 72 | Iteration number: [1330/4518] 29% | Training loss: 0.6872276515440834
Epoch: 72 | Iteration number: [1340/4518] 29% | Training loss: 0.6872296659804102
Epoch: 72 | Iteration number: [1350/4518] 29% | Training loss: 0.6872224466888993
Epoch: 72 | Iteration number: [1360/4518] 30% | Training loss: 0.6872189716381185
Epoch: 72 | Iteration number: [1370/4518] 30% | Training loss: 0.687213685303709
Epoch: 72 | Iteration number: [1380/4518] 30% | Training loss: 0.6872128710798595
Epoch: 72 | Iteration number: [1390/4518] 30% | Training loss: 0.6872090994025306
Epoch: 72 | Iteration number: [1400/4518] 30% | Training loss: 0.6872121573346002
Epoch: 72 | Iteration number: [1410/4518] 31% | Training loss: 0.6872181570276301
Epoch: 72 | Iteration number: [1420/4518] 31% | Training loss: 0.6872135022156675
Epoch: 72 | Iteration number: [1430/4518] 31% | Training loss: 0.6872150952582593
Epoch: 72 | Iteration number: [1440/4518] 31% | Training loss: 0.6872082092695766
Epoch: 72 | Iteration number: [1450/4518] 32% | Training loss: 0.6871944842256349
Epoch: 72 | Iteration number: [1460/4518] 32% | Training loss: 0.6871903665669977
Epoch: 72 | Iteration number: [1470/4518] 32% | Training loss: 0.6871874045758021
Epoch: 72 | Iteration number: [1480/4518] 32% | Training loss: 0.6871800077122611
Epoch: 72 | Iteration number: [1490/4518] 32% | Training loss: 0.6871785671918984
Epoch: 72 | Iteration number: [1500/4518] 33% | Training loss: 0.6871776317755381
Epoch: 72 | Iteration number: [1510/4518] 33% | Training loss: 0.6871736064651944
Epoch: 72 | Iteration number: [1520/4518] 33% | Training loss: 0.6871706712794932
Epoch: 72 | Iteration number: [1530/4518] 33% | Training loss: 0.6871732767500909
Epoch: 72 | Iteration number: [1540/4518] 34% | Training loss: 0.6871775214548235
Epoch: 72 | Iteration number: [1550/4518] 34% | Training loss: 0.6871725015486441
Epoch: 72 | Iteration number: [1560/4518] 34% | Training loss: 0.687164512811563
Epoch: 72 | Iteration number: [1570/4518] 34% | Training loss: 0.6871550183007672
Epoch: 72 | Iteration number: [1580/4518] 34% | Training loss: 0.6871523882392087
Epoch: 72 | Iteration number: [1590/4518] 35% | Training loss: 0.6871487117413455
Epoch: 72 | Iteration number: [1600/4518] 35% | Training loss: 0.6871494572609663
Epoch: 72 | Iteration number: [1610/4518] 35% | Training loss: 0.6871508289938387
Epoch: 72 | Iteration number: [1620/4518] 35% | Training loss: 0.6871532226418271
Epoch: 72 | Iteration number: [1630/4518] 36% | Training loss: 0.6871575871493919
Epoch: 72 | Iteration number: [1640/4518] 36% | Training loss: 0.6871443960361364
Epoch: 72 | Iteration number: [1650/4518] 36% | Training loss: 0.6871435682340101
Epoch: 72 | Iteration number: [1660/4518] 36% | Training loss: 0.6871340057576996
Epoch: 72 | Iteration number: [1670/4518] 36% | Training loss: 0.6871238205604211
Epoch: 72 | Iteration number: [1680/4518] 37% | Training loss: 0.6871176619969663
Epoch: 72 | Iteration number: [1690/4518] 37% | Training loss: 0.6871086210894162
Epoch: 72 | Iteration number: [1700/4518] 37% | Training loss: 0.6871088503739413
Epoch: 72 | Iteration number: [1710/4518] 37% | Training loss: 0.6871062983197775
Epoch: 72 | Iteration number: [1720/4518] 38% | Training loss: 0.6871035146158795
Epoch: 72 | Iteration number: [1730/4518] 38% | Training loss: 0.6871004599022728
Epoch: 72 | Iteration number: [1740/4518] 38% | Training loss: 0.6871016920297995
Epoch: 72 | Iteration number: [1750/4518] 38% | Training loss: 0.687096070936748
Epoch: 72 | Iteration number: [1760/4518] 38% | Training loss: 0.6870918078517372
Epoch: 72 | Iteration number: [1770/4518] 39% | Training loss: 0.6870914371000172
Epoch: 72 | Iteration number: [1780/4518] 39% | Training loss: 0.6870862972535444
Epoch: 72 | Iteration number: [1790/4518] 39% | Training loss: 0.6870873390962292
Epoch: 72 | Iteration number: [1800/4518] 39% | Training loss: 0.6870804177721341
Epoch: 72 | Iteration number: [1810/4518] 40% | Training loss: 0.687083052074053
Epoch: 72 | Iteration number: [1820/4518] 40% | Training loss: 0.6870849405671214
Epoch: 72 | Iteration number: [1830/4518] 40% | Training loss: 0.6870778246004073
Epoch: 72 | Iteration number: [1840/4518] 40% | Training loss: 0.6870728761929533
Epoch: 72 | Iteration number: [1850/4518] 40% | Training loss: 0.6870690734322007
Epoch: 72 | Iteration number: [1860/4518] 41% | Training loss: 0.6870645515700822
Epoch: 72 | Iteration number: [1870/4518] 41% | Training loss: 0.6870743128386411
Epoch: 72 | Iteration number: [1880/4518] 41% | Training loss: 0.6870758493212943
Epoch: 72 | Iteration number: [1890/4518] 41% | Training loss: 0.6870689785038984
Epoch: 72 | Iteration number: [1900/4518] 42% | Training loss: 0.6870697766228726
Epoch: 72 | Iteration number: [1910/4518] 42% | Training loss: 0.687072930286068
Epoch: 72 | Iteration number: [1920/4518] 42% | Training loss: 0.6870697980125745
Epoch: 72 | Iteration number: [1930/4518] 42% | Training loss: 0.6870668222249481
Epoch: 72 | Iteration number: [1940/4518] 42% | Training loss: 0.6870711805586962
Epoch: 72 | Iteration number: [1950/4518] 43% | Training loss: 0.687075068125358
Epoch: 72 | Iteration number: [1960/4518] 43% | Training loss: 0.6870767735096873
Epoch: 72 | Iteration number: [1970/4518] 43% | Training loss: 0.6870827860941137
Epoch: 72 | Iteration number: [1980/4518] 43% | Training loss: 0.6870817001419838
Epoch: 72 | Iteration number: [1990/4518] 44% | Training loss: 0.6870771636315925
Epoch: 72 | Iteration number: [2000/4518] 44% | Training loss: 0.6870770706534386
Epoch: 72 | Iteration number: [2010/4518] 44% | Training loss: 0.6870711847917358
Epoch: 72 | Iteration number: [2020/4518] 44% | Training loss: 0.6870653805166188
Epoch: 72 | Iteration number: [2030/4518] 44% | Training loss: 0.687069412610801
Epoch: 72 | Iteration number: [2040/4518] 45% | Training loss: 0.6870617517361454
Epoch: 72 | Iteration number: [2050/4518] 45% | Training loss: 0.6870649575896379
Epoch: 72 | Iteration number: [2060/4518] 45% | Training loss: 0.6870658582854039
Epoch: 72 | Iteration number: [2070/4518] 45% | Training loss: 0.6870656380330883
Epoch: 72 | Iteration number: [2080/4518] 46% | Training loss: 0.6870613679289818
Epoch: 72 | Iteration number: [2090/4518] 46% | Training loss: 0.687059027156191
Epoch: 72 | Iteration number: [2100/4518] 46% | Training loss: 0.687059845158032
Epoch: 72 | Iteration number: [2110/4518] 46% | Training loss: 0.6870639577296108
Epoch: 72 | Iteration number: [2120/4518] 46% | Training loss: 0.6870651139403289
Epoch: 72 | Iteration number: [2130/4518] 47% | Training loss: 0.6870579132171863
Epoch: 72 | Iteration number: [2140/4518] 47% | Training loss: 0.68705634608447
Epoch: 72 | Iteration number: [2150/4518] 47% | Training loss: 0.6870562975905662
Epoch: 72 | Iteration number: [2160/4518] 47% | Training loss: 0.6870464257895946
Epoch: 72 | Iteration number: [2170/4518] 48% | Training loss: 0.68703825682539
Epoch: 72 | Iteration number: [2180/4518] 48% | Training loss: 0.6870342452865128
Epoch: 72 | Iteration number: [2190/4518] 48% | Training loss: 0.687029068655075
Epoch: 72 | Iteration number: [2200/4518] 48% | Training loss: 0.6870301039381461
Epoch: 72 | Iteration number: [2210/4518] 48% | Training loss: 0.6870262781419366
Epoch: 72 | Iteration number: [2220/4518] 49% | Training loss: 0.6870317943998285
Epoch: 72 | Iteration number: [2230/4518] 49% | Training loss: 0.6870313076694985
Epoch: 72 | Iteration number: [2240/4518] 49% | Training loss: 0.6870279325704489
Epoch: 72 | Iteration number: [2250/4518] 49% | Training loss: 0.6870261369546254
Epoch: 72 | Iteration number: [2260/4518] 50% | Training loss: 0.6870268016262392
Epoch: 72 | Iteration number: [2270/4518] 50% | Training loss: 0.687022016332013
Epoch: 72 | Iteration number: [2280/4518] 50% | Training loss: 0.6870228857847682
Epoch: 72 | Iteration number: [2290/4518] 50% | Training loss: 0.6870189567320212
Epoch: 72 | Iteration number: [2300/4518] 50% | Training loss: 0.6870144427340964
Epoch: 72 | Iteration number: [2310/4518] 51% | Training loss: 0.6870084850044994
Epoch: 72 | Iteration number: [2320/4518] 51% | Training loss: 0.6870055448906175
Epoch: 72 | Iteration number: [2330/4518] 51% | Training loss: 0.6869998013512771
Epoch: 72 | Iteration number: [2340/4518] 51% | Training loss: 0.6870014981326894
Epoch: 72 | Iteration number: [2350/4518] 52% | Training loss: 0.6870005569559463
Epoch: 72 | Iteration number: [2360/4518] 52% | Training loss: 0.6869980567087561
Epoch: 72 | Iteration number: [2370/4518] 52% | Training loss: 0.6869993926855079
Epoch: 72 | Iteration number: [2380/4518] 52% | Training loss: 0.686996455603287
Epoch: 72 | Iteration number: [2390/4518] 52% | Training loss: 0.686999174615828
Epoch: 72 | Iteration number: [2400/4518] 53% | Training loss: 0.686997996866703
Epoch: 72 | Iteration number: [2410/4518] 53% | Training loss: 0.6869942240695242
Epoch: 72 | Iteration number: [2420/4518] 53% | Training loss: 0.6869881488813842
Epoch: 72 | Iteration number: [2430/4518] 53% | Training loss: 0.6869928254266825
Epoch: 72 | Iteration number: [2440/4518] 54% | Training loss: 0.6869907009308456
Epoch: 72 | Iteration number: [2450/4518] 54% | Training loss: 0.6869858991613194
Epoch: 72 | Iteration number: [2460/4518] 54% | Training loss: 0.6869878017563161
Epoch: 72 | Iteration number: [2470/4518] 54% | Training loss: 0.6869889621309906
Epoch: 72 | Iteration number: [2480/4518] 54% | Training loss: 0.68698971877175
Epoch: 72 | Iteration number: [2490/4518] 55% | Training loss: 0.6869864295285389
Epoch: 72 | Iteration number: [2500/4518] 55% | Training loss: 0.6869820585489274
Epoch: 72 | Iteration number: [2510/4518] 55% | Training loss: 0.6869787869937867
Epoch: 72 | Iteration number: [2520/4518] 55% | Training loss: 0.6869722517473357
Epoch: 72 | Iteration number: [2530/4518] 55% | Training loss: 0.6869720721197694
Epoch: 72 | Iteration number: [2540/4518] 56% | Training loss: 0.6869710969877993
Epoch: 72 | Iteration number: [2550/4518] 56% | Training loss: 0.6869737013414794
Epoch: 72 | Iteration number: [2560/4518] 56% | Training loss: 0.6869771937839687
Epoch: 72 | Iteration number: [2570/4518] 56% | Training loss: 0.6869778219595958
Epoch: 72 | Iteration number: [2580/4518] 57% | Training loss: 0.6869769343341043
Epoch: 72 | Iteration number: [2590/4518] 57% | Training loss: 0.6869774597722131
Epoch: 72 | Iteration number: [2600/4518] 57% | Training loss: 0.6869778024004056
Epoch: 72 | Iteration number: [2610/4518] 57% | Training loss: 0.6869758881143226
Epoch: 72 | Iteration number: [2620/4518] 57% | Training loss: 0.686977123781925
Epoch: 72 | Iteration number: [2630/4518] 58% | Training loss: 0.6869767447161584
Epoch: 72 | Iteration number: [2640/4518] 58% | Training loss: 0.6869753951150359
Epoch: 72 | Iteration number: [2650/4518] 58% | Training loss: 0.6869732015087919
Epoch: 72 | Iteration number: [2660/4518] 58% | Training loss: 0.6869753945814936
Epoch: 72 | Iteration number: [2670/4518] 59% | Training loss: 0.6869779039411509
Epoch: 72 | Iteration number: [2680/4518] 59% | Training loss: 0.6869731712474751
Epoch: 72 | Iteration number: [2690/4518] 59% | Training loss: 0.6869742624600137
Epoch: 72 | Iteration number: [2700/4518] 59% | Training loss: 0.6869729590857471
Epoch: 72 | Iteration number: [2710/4518] 59% | Training loss: 0.6869734517982525
Epoch: 72 | Iteration number: [2720/4518] 60% | Training loss: 0.6869745563058293
Epoch: 72 | Iteration number: [2730/4518] 60% | Training loss: 0.6869754043035892
Epoch: 72 | Iteration number: [2740/4518] 60% | Training loss: 0.6869780814778196
Epoch: 72 | Iteration number: [2750/4518] 60% | Training loss: 0.6869758329174736
Epoch: 72 | Iteration number: [2760/4518] 61% | Training loss: 0.686978885056316
Epoch: 72 | Iteration number: [2770/4518] 61% | Training loss: 0.6869757493265269
Epoch: 72 | Iteration number: [2780/4518] 61% | Training loss: 0.6869796666524393
Epoch: 72 | Iteration number: [2790/4518] 61% | Training loss: 0.6869749185218605
Epoch: 72 | Iteration number: [2800/4518] 61% | Training loss: 0.6869743599636214
Epoch: 72 | Iteration number: [2810/4518] 62% | Training loss: 0.6869739651892108
Epoch: 72 | Iteration number: [2820/4518] 62% | Training loss: 0.6869760211689252
Epoch: 72 | Iteration number: [2830/4518] 62% | Training loss: 0.6869753807888436
Epoch: 72 | Iteration number: [2840/4518] 62% | Training loss: 0.6869756231215638
Epoch: 72 | Iteration number: [2850/4518] 63% | Training loss: 0.6869715208128879
Epoch: 72 | Iteration number: [2860/4518] 63% | Training loss: 0.6869705253339314
Epoch: 72 | Iteration number: [2870/4518] 63% | Training loss: 0.6869690511077123
Epoch: 72 | Iteration number: [2880/4518] 63% | Training loss: 0.6869680275312728
Epoch: 72 | Iteration number: [2890/4518] 63% | Training loss: 0.6869638020398295
Epoch: 72 | Iteration number: [2900/4518] 64% | Training loss: 0.6869610623244582
Epoch: 72 | Iteration number: [2910/4518] 64% | Training loss: 0.6869651640403721
Epoch: 72 | Iteration number: [2920/4518] 64% | Training loss: 0.6869627163834768
Epoch: 72 | Iteration number: [2930/4518] 64% | Training loss: 0.6869623150841775
Epoch: 72 | Iteration number: [2940/4518] 65% | Training loss: 0.6869599665306052
Epoch: 72 | Iteration number: [2950/4518] 65% | Training loss: 0.6869624021295774
Epoch: 72 | Iteration number: [2960/4518] 65% | Training loss: 0.6869600280112511
Epoch: 72 | Iteration number: [2970/4518] 65% | Training loss: 0.6869595845540365
Epoch: 72 | Iteration number: [2980/4518] 65% | Training loss: 0.686960170713047
Epoch: 72 | Iteration number: [2990/4518] 66% | Training loss: 0.6869572693288925
Epoch: 72 | Iteration number: [3000/4518] 66% | Training loss: 0.6869552384018898
Epoch: 72 | Iteration number: [3010/4518] 66% | Training loss: 0.6869517401009303
Epoch: 72 | Iteration number: [3020/4518] 66% | Training loss: 0.6869505747264584
Epoch: 72 | Iteration number: [3030/4518] 67% | Training loss: 0.6869516284158914
Epoch: 72 | Iteration number: [3040/4518] 67% | Training loss: 0.6869501011152016
Epoch: 72 | Iteration number: [3050/4518] 67% | Training loss: 0.6869509918963322
Epoch: 72 | Iteration number: [3060/4518] 67% | Training loss: 0.6869515591002757
Epoch: 72 | Iteration number: [3070/4518] 67% | Training loss: 0.6869541619421993
Epoch: 72 | Iteration number: [3080/4518] 68% | Training loss: 0.686956216975466
Epoch: 72 | Iteration number: [3090/4518] 68% | Training loss: 0.6869548841587548
Epoch: 72 | Iteration number: [3100/4518] 68% | Training loss: 0.6869542735622776
Epoch: 72 | Iteration number: [3110/4518] 68% | Training loss: 0.6869562725928818
Epoch: 72 | Iteration number: [3120/4518] 69% | Training loss: 0.6869572314696434
Epoch: 72 | Iteration number: [3130/4518] 69% | Training loss: 0.6869567118894558
Epoch: 72 | Iteration number: [3140/4518] 69% | Training loss: 0.6869595213870334
Epoch: 72 | Iteration number: [3150/4518] 69% | Training loss: 0.6869589073506612
Epoch: 72 | Iteration number: [3160/4518] 69% | Training loss: 0.6869617232039005
Epoch: 72 | Iteration number: [3170/4518] 70% | Training loss: 0.6869656831120091
Epoch: 72 | Iteration number: [3180/4518] 70% | Training loss: 0.6869668814746089
Epoch: 72 | Iteration number: [3190/4518] 70% | Training loss: 0.6869627839158695
Epoch: 72 | Iteration number: [3200/4518] 70% | Training loss: 0.6869601059705019
Epoch: 72 | Iteration number: [3210/4518] 71% | Training loss: 0.6869642225195686
Epoch: 72 | Iteration number: [3220/4518] 71% | Training loss: 0.6869618510422499
Epoch: 72 | Iteration number: [3230/4518] 71% | Training loss: 0.6869618332976527
Epoch: 72 | Iteration number: [3240/4518] 71% | Training loss: 0.6869626828181891
Epoch: 72 | Iteration number: [3250/4518] 71% | Training loss: 0.6869642584690681
Epoch: 72 | Iteration number: [3260/4518] 72% | Training loss: 0.6869647877347981
Epoch: 72 | Iteration number: [3270/4518] 72% | Training loss: 0.6869640276154976
Epoch: 72 | Iteration number: [3280/4518] 72% | Training loss: 0.6869616375645486
Epoch: 72 | Iteration number: [3290/4518] 72% | Training loss: 0.6869604156191226
Epoch: 72 | Iteration number: [3300/4518] 73% | Training loss: 0.6869582077228662
Epoch: 72 | Iteration number: [3310/4518] 73% | Training loss: 0.6869563360948937
Epoch: 72 | Iteration number: [3320/4518] 73% | Training loss: 0.6869539476302733
Epoch: 72 | Iteration number: [3330/4518] 73% | Training loss: 0.6869557166242742
Epoch: 72 | Iteration number: [3340/4518] 73% | Training loss: 0.6869577822927944
Epoch: 72 | Iteration number: [3350/4518] 74% | Training loss: 0.686959769868139
Epoch: 72 | Iteration number: [3360/4518] 74% | Training loss: 0.6869597271971759
Epoch: 72 | Iteration number: [3370/4518] 74% | Training loss: 0.6869619179903931
Epoch: 72 | Iteration number: [3380/4518] 74% | Training loss: 0.6869592357669356
Epoch: 72 | Iteration number: [3390/4518] 75% | Training loss: 0.6869571416778902
Epoch: 72 | Iteration number: [3400/4518] 75% | Training loss: 0.6869559026115081
Epoch: 72 | Iteration number: [3410/4518] 75% | Training loss: 0.6869540418522798
Epoch: 72 | Iteration number: [3420/4518] 75% | Training loss: 0.6869550213304877
Epoch: 72 | Iteration number: [3430/4518] 75% | Training loss: 0.686954848915773
Epoch: 72 | Iteration number: [3440/4518] 76% | Training loss: 0.686952568070833
Epoch: 72 | Iteration number: [3450/4518] 76% | Training loss: 0.6869499664721281
Epoch: 72 | Iteration number: [3460/4518] 76% | Training loss: 0.6869556194957281
Epoch: 72 | Iteration number: [3470/4518] 76% | Training loss: 0.6869552815166605
Epoch: 72 | Iteration number: [3480/4518] 77% | Training loss: 0.6869514990469505
Epoch: 72 | Iteration number: [3490/4518] 77% | Training loss: 0.6869481786274295
Epoch: 72 | Iteration number: [3500/4518] 77% | Training loss: 0.6869468257086617
Epoch: 72 | Iteration number: [3510/4518] 77% | Training loss: 0.6869455531791404
Epoch: 72 | Iteration number: [3520/4518] 77% | Training loss: 0.6869442465461113
Epoch: 72 | Iteration number: [3530/4518] 78% | Training loss: 0.6869434147144512
Epoch: 72 | Iteration number: [3540/4518] 78% | Training loss: 0.6869422050519178
Epoch: 72 | Iteration number: [3550/4518] 78% | Training loss: 0.6869436160275634
Epoch: 72 | Iteration number: [3560/4518] 78% | Training loss: 0.6869447491979331
Epoch: 72 | Iteration number: [3570/4518] 79% | Training loss: 0.6869475443990959
Epoch: 72 | Iteration number: [3580/4518] 79% | Training loss: 0.6869454393340223
Epoch: 72 | Iteration number: [3590/4518] 79% | Training loss: 0.6869411994487794
Epoch: 72 | Iteration number: [3600/4518] 79% | Training loss: 0.6869422424170706
Epoch: 72 | Iteration number: [3610/4518] 79% | Training loss: 0.6869418555349525
Epoch: 72 | Iteration number: [3620/4518] 80% | Training loss: 0.6869417156303785
Epoch: 72 | Iteration number: [3630/4518] 80% | Training loss: 0.6869393476113144
Epoch: 72 | Iteration number: [3640/4518] 80% | Training loss: 0.6869406873871992
Epoch: 72 | Iteration number: [3650/4518] 80% | Training loss: 0.6869406542549394
Epoch: 72 | Iteration number: [3660/4518] 81% | Training loss: 0.6869409227468929
Epoch: 72 | Iteration number: [3670/4518] 81% | Training loss: 0.6869424909759282
Epoch: 72 | Iteration number: [3680/4518] 81% | Training loss: 0.6869431710761527
Epoch: 72 | Iteration number: [3690/4518] 81% | Training loss: 0.6869442847363025
Epoch: 72 | Iteration number: [3700/4518] 81% | Training loss: 0.6869483948881562
Epoch: 72 | Iteration number: [3710/4518] 82% | Training loss: 0.6869515791896861
Epoch: 72 | Iteration number: [3720/4518] 82% | Training loss: 0.6869502783462565
Epoch: 72 | Iteration number: [3730/4518] 82% | Training loss: 0.6869496695477585
Epoch: 72 | Iteration number: [3740/4518] 82% | Training loss: 0.6869456012299991
Epoch: 72 | Iteration number: [3750/4518] 83% | Training loss: 0.6869444487889608
Epoch: 72 | Iteration number: [3760/4518] 83% | Training loss: 0.6869414932233222
Epoch: 72 | Iteration number: [3770/4518] 83% | Training loss: 0.6869392476916629
Epoch: 72 | Iteration number: [3780/4518] 83% | Training loss: 0.686944306527496
Epoch: 72 | Iteration number: [3790/4518] 83% | Training loss: 0.6869470485439401
Epoch: 72 | Iteration number: [3800/4518] 84% | Training loss: 0.6869436384659064
Epoch: 72 | Iteration number: [3810/4518] 84% | Training loss: 0.6869451940998318
Epoch: 72 | Iteration number: [3820/4518] 84% | Training loss: 0.6869432231830677
Epoch: 72 | Iteration number: [3830/4518] 84% | Training loss: 0.6869428803030567
Epoch: 72 | Iteration number: [3840/4518] 84% | Training loss: 0.6869452485504249
Epoch: 72 | Iteration number: [3850/4518] 85% | Training loss: 0.6869461317495866
Epoch: 72 | Iteration number: [3860/4518] 85% | Training loss: 0.686944225940062
Epoch: 72 | Iteration number: [3870/4518] 85% | Training loss: 0.686943128527905
Epoch: 72 | Iteration number: [3880/4518] 85% | Training loss: 0.6869440370613766
Epoch: 72 | Iteration number: [3890/4518] 86% | Training loss: 0.6869415999684665
Epoch: 72 | Iteration number: [3900/4518] 86% | Training loss: 0.6869402842949598
Epoch: 72 | Iteration number: [3910/4518] 86% | Training loss: 0.6869377627854457
Epoch: 72 | Iteration number: [3920/4518] 86% | Training loss: 0.6869359483676297
Epoch: 72 | Iteration number: [3930/4518] 86% | Training loss: 0.6869369119329913
Epoch: 72 | Iteration number: [3940/4518] 87% | Training loss: 0.6869332553620265
Epoch: 72 | Iteration number: [3950/4518] 87% | Training loss: 0.6869330406339863
Epoch: 72 | Iteration number: [3960/4518] 87% | Training loss: 0.6869363213428343
Epoch: 72 | Iteration number: [3970/4518] 87% | Training loss: 0.6869372906702892
Epoch: 72 | Iteration number: [3980/4518] 88% | Training loss: 0.6869355860667014
Epoch: 72 | Iteration number: [3990/4518] 88% | Training loss: 0.6869358235732057
Epoch: 72 | Iteration number: [4000/4518] 88% | Training loss: 0.6869359550327062
Epoch: 72 | Iteration number: [4010/4518] 88% | Training loss: 0.6869356671027709
Epoch: 72 | Iteration number: [4020/4518] 88% | Training loss: 0.6869369133936232
Epoch: 72 | Iteration number: [4030/4518] 89% | Training loss: 0.6869367641787375
Epoch: 72 | Iteration number: [4040/4518] 89% | Training loss: 0.6869364689924929
Epoch: 72 | Iteration number: [4050/4518] 89% | Training loss: 0.6869376858222632
Epoch: 72 | Iteration number: [4060/4518] 89% | Training loss: 0.6869352926761646
Epoch: 72 | Iteration number: [4070/4518] 90% | Training loss: 0.6869374874182942
Epoch: 72 | Iteration number: [4080/4518] 90% | Training loss: 0.6869377495757505
Epoch: 72 | Iteration number: [4090/4518] 90% | Training loss: 0.6869374991629118
Epoch: 72 | Iteration number: [4100/4518] 90% | Training loss: 0.6869351580520956
Epoch: 72 | Iteration number: [4110/4518] 90% | Training loss: 0.6869335011264124
Epoch: 72 | Iteration number: [4120/4518] 91% | Training loss: 0.6869324200217006
Epoch: 72 | Iteration number: [4130/4518] 91% | Training loss: 0.6869318660177273
Epoch: 72 | Iteration number: [4140/4518] 91% | Training loss: 0.6869315770081276
Epoch: 72 | Iteration number: [4150/4518] 91% | Training loss: 0.686931237528123
Epoch: 72 | Iteration number: [4160/4518] 92% | Training loss: 0.6869286230693643
Epoch: 72 | Iteration number: [4170/4518] 92% | Training loss: 0.6869289003258986
Epoch: 72 | Iteration number: [4180/4518] 92% | Training loss: 0.6869265507710608
Epoch: 72 | Iteration number: [4190/4518] 92% | Training loss: 0.6869247376776538
Epoch: 72 | Iteration number: [4200/4518] 92% | Training loss: 0.6869232079812458
Epoch: 72 | Iteration number: [4210/4518] 93% | Training loss: 0.6869230392568185
Epoch: 72 | Iteration number: [4220/4518] 93% | Training loss: 0.6869249215764457
Epoch: 72 | Iteration number: [4230/4518] 93% | Training loss: 0.6869218945503235
Epoch: 72 | Iteration number: [4240/4518] 93% | Training loss: 0.6869199111214224
Epoch: 72 | Iteration number: [4250/4518] 94% | Training loss: 0.6869201883989222
Epoch: 72 | Iteration number: [4260/4518] 94% | Training loss: 0.6869199315007304
Epoch: 72 | Iteration number: [4270/4518] 94% | Training loss: 0.6869183943757408
Epoch: 72 | Iteration number: [4280/4518] 94% | Training loss: 0.6869189408616485
Epoch: 72 | Iteration number: [4290/4518] 94% | Training loss: 0.6869189156241072
Epoch: 72 | Iteration number: [4300/4518] 95% | Training loss: 0.6869208373025406
Epoch: 72 | Iteration number: [4310/4518] 95% | Training loss: 0.6869201695974354
Epoch: 72 | Iteration number: [4320/4518] 95% | Training loss: 0.6869204331465342
Epoch: 72 | Iteration number: [4330/4518] 95% | Training loss: 0.6869178390943426
Epoch: 72 | Iteration number: [4340/4518] 96% | Training loss: 0.6869183418388191
Epoch: 72 | Iteration number: [4350/4518] 96% | Training loss: 0.6869167845413603
Epoch: 72 | Iteration number: [4360/4518] 96% | Training loss: 0.6869171746553631
Epoch: 72 | Iteration number: [4370/4518] 96% | Training loss: 0.6869185231506688
Epoch: 72 | Iteration number: [4380/4518] 96% | Training loss: 0.6869161840579281
Epoch: 72 | Iteration number: [4390/4518] 97% | Training loss: 0.6869159140999606
Epoch: 72 | Iteration number: [4400/4518] 97% | Training loss: 0.6869176555899057
Epoch: 72 | Iteration number: [4410/4518] 97% | Training loss: 0.6869174301894614
Epoch: 72 | Iteration number: [4420/4518] 97% | Training loss: 0.6869182256282185
Epoch: 72 | Iteration number: [4430/4518] 98% | Training loss: 0.6869172836264961
Epoch: 72 | Iteration number: [4440/4518] 98% | Training loss: 0.6869160541006036
Epoch: 72 | Iteration number: [4450/4518] 98% | Training loss: 0.6869195372067141
Epoch: 72 | Iteration number: [4460/4518] 98% | Training loss: 0.6869190566609259
Epoch: 72 | Iteration number: [4470/4518] 98% | Training loss: 0.6869183676621524
Epoch: 72 | Iteration number: [4480/4518] 99% | Training loss: 0.6869210736959108
Epoch: 72 | Iteration number: [4490/4518] 99% | Training loss: 0.6869218490437038
Epoch: 72 | Iteration number: [4500/4518] 99% | Training loss: 0.6869207416640387
Epoch: 72 | Iteration number: [4510/4518] 99% | Training loss: 0.6869222886414327

 End of epoch: 72 | Train Loss: 0.6867707355484702 | Training Time: 632 

 End of epoch: 72 | Eval Loss: 0.689630173906988 | Evaluating Time: 17 
Epoch: 73 | Iteration number: [10/4518] 0% | Training loss: 0.7569021224975586
Epoch: 73 | Iteration number: [20/4518] 0% | Training loss: 0.7218774646520615
Epoch: 73 | Iteration number: [30/4518] 0% | Training loss: 0.7098374485969543
Epoch: 73 | Iteration number: [40/4518] 0% | Training loss: 0.7043927207589149
Epoch: 73 | Iteration number: [50/4518] 1% | Training loss: 0.7009223294258118
Epoch: 73 | Iteration number: [60/4518] 1% | Training loss: 0.6983130385478338
Epoch: 73 | Iteration number: [70/4518] 1% | Training loss: 0.6968452649457114
Epoch: 73 | Iteration number: [80/4518] 1% | Training loss: 0.6956976287066936
Epoch: 73 | Iteration number: [90/4518] 1% | Training loss: 0.6946670982572768
Epoch: 73 | Iteration number: [100/4518] 2% | Training loss: 0.693852441906929
Epoch: 73 | Iteration number: [110/4518] 2% | Training loss: 0.6932629216801036
Epoch: 73 | Iteration number: [120/4518] 2% | Training loss: 0.6925958563884099
Epoch: 73 | Iteration number: [130/4518] 2% | Training loss: 0.6920513767462511
Epoch: 73 | Iteration number: [140/4518] 3% | Training loss: 0.691612161057336
Epoch: 73 | Iteration number: [150/4518] 3% | Training loss: 0.691325630346934
Epoch: 73 | Iteration number: [160/4518] 3% | Training loss: 0.6910614635795355
Epoch: 73 | Iteration number: [170/4518] 3% | Training loss: 0.6908595141242532
Epoch: 73 | Iteration number: [180/4518] 3% | Training loss: 0.6905742913484574
Epoch: 73 | Iteration number: [190/4518] 4% | Training loss: 0.6903862749275408
Epoch: 73 | Iteration number: [200/4518] 4% | Training loss: 0.6902196249365806
Epoch: 73 | Iteration number: [210/4518] 4% | Training loss: 0.6900390769754138
Epoch: 73 | Iteration number: [220/4518] 4% | Training loss: 0.6898916837843981
Epoch: 73 | Iteration number: [230/4518] 5% | Training loss: 0.68977043369542
Epoch: 73 | Iteration number: [240/4518] 5% | Training loss: 0.6895931077500185
Epoch: 73 | Iteration number: [250/4518] 5% | Training loss: 0.6894885766506195
Epoch: 73 | Iteration number: [260/4518] 5% | Training loss: 0.6894251552911905
Epoch: 73 | Iteration number: [270/4518] 5% | Training loss: 0.6893030645670715
Epoch: 73 | Iteration number: [280/4518] 6% | Training loss: 0.6892217678683145
Epoch: 73 | Iteration number: [290/4518] 6% | Training loss: 0.6890917103866051
Epoch: 73 | Iteration number: [300/4518] 6% | Training loss: 0.689018080830574
Epoch: 73 | Iteration number: [310/4518] 6% | Training loss: 0.6889701979775582
Epoch: 73 | Iteration number: [320/4518] 7% | Training loss: 0.688885910436511
Epoch: 73 | Iteration number: [330/4518] 7% | Training loss: 0.6887989817243634
Epoch: 73 | Iteration number: [340/4518] 7% | Training loss: 0.6887579372700523
Epoch: 73 | Iteration number: [350/4518] 7% | Training loss: 0.6887209660666329
Epoch: 73 | Iteration number: [360/4518] 7% | Training loss: 0.6886689278814527
Epoch: 73 | Iteration number: [370/4518] 8% | Training loss: 0.6886172030423139
Epoch: 73 | Iteration number: [380/4518] 8% | Training loss: 0.6885569864197781
Epoch: 73 | Iteration number: [390/4518] 8% | Training loss: 0.6885165021969721
Epoch: 73 | Iteration number: [400/4518] 8% | Training loss: 0.6884770973026753
Epoch: 73 | Iteration number: [410/4518] 9% | Training loss: 0.6884628364225713
Epoch: 73 | Iteration number: [420/4518] 9% | Training loss: 0.6884492668367568
Epoch: 73 | Iteration number: [430/4518] 9% | Training loss: 0.6884425726047781
Epoch: 73 | Iteration number: [440/4518] 9% | Training loss: 0.6884001225233078
Epoch: 73 | Iteration number: [450/4518] 9% | Training loss: 0.6883581777413686
Epoch: 73 | Iteration number: [460/4518] 10% | Training loss: 0.6883178777020911
Epoch: 73 | Iteration number: [470/4518] 10% | Training loss: 0.6882742773979268
Epoch: 73 | Iteration number: [480/4518] 10% | Training loss: 0.6882731681068738
Epoch: 73 | Iteration number: [490/4518] 10% | Training loss: 0.6882626796255307
Epoch: 73 | Iteration number: [500/4518] 11% | Training loss: 0.68823763692379
Epoch: 73 | Iteration number: [510/4518] 11% | Training loss: 0.6881853119999755
Epoch: 73 | Iteration number: [520/4518] 11% | Training loss: 0.6881441498031983
Epoch: 73 | Iteration number: [530/4518] 11% | Training loss: 0.688125513297207
Epoch: 73 | Iteration number: [540/4518] 11% | Training loss: 0.6881060670923304
Epoch: 73 | Iteration number: [550/4518] 12% | Training loss: 0.6880867791175842
Epoch: 73 | Iteration number: [560/4518] 12% | Training loss: 0.6880733538951193
Epoch: 73 | Iteration number: [570/4518] 12% | Training loss: 0.6880608093320277
Epoch: 73 | Iteration number: [580/4518] 12% | Training loss: 0.6880493048963876
Epoch: 73 | Iteration number: [590/4518] 13% | Training loss: 0.6880364644325385
Epoch: 73 | Iteration number: [600/4518] 13% | Training loss: 0.6879949866731961
Epoch: 73 | Iteration number: [610/4518] 13% | Training loss: 0.6879722469165677
Epoch: 73 | Iteration number: [620/4518] 13% | Training loss: 0.6879478994877107
Epoch: 73 | Iteration number: [630/4518] 13% | Training loss: 0.6879166150849964
Epoch: 73 | Iteration number: [640/4518] 14% | Training loss: 0.6878701227717101
Epoch: 73 | Iteration number: [650/4518] 14% | Training loss: 0.6878625914683709
Epoch: 73 | Iteration number: [660/4518] 14% | Training loss: 0.6878234595963449
Epoch: 73 | Iteration number: [670/4518] 14% | Training loss: 0.687811145052981
Epoch: 73 | Iteration number: [680/4518] 15% | Training loss: 0.6877924203872681
Epoch: 73 | Iteration number: [690/4518] 15% | Training loss: 0.6877784058667611
Epoch: 73 | Iteration number: [700/4518] 15% | Training loss: 0.6877573746442794
Epoch: 73 | Iteration number: [710/4518] 15% | Training loss: 0.6877413993989917
Epoch: 73 | Iteration number: [720/4518] 15% | Training loss: 0.687713532977634
Epoch: 73 | Iteration number: [730/4518] 16% | Training loss: 0.6876988392170161
Epoch: 73 | Iteration number: [740/4518] 16% | Training loss: 0.6876779581243927
Epoch: 73 | Iteration number: [750/4518] 16% | Training loss: 0.6876488961378733
Epoch: 73 | Iteration number: [760/4518] 16% | Training loss: 0.6876544569668017
Epoch: 73 | Iteration number: [770/4518] 17% | Training loss: 0.6876334288677612
Epoch: 73 | Iteration number: [780/4518] 17% | Training loss: 0.687626304381933
Epoch: 73 | Iteration number: [790/4518] 17% | Training loss: 0.6876299708704405
Epoch: 73 | Iteration number: [800/4518] 17% | Training loss: 0.6876186657696962
Epoch: 73 | Iteration number: [810/4518] 17% | Training loss: 0.68762706577042
Epoch: 73 | Iteration number: [820/4518] 18% | Training loss: 0.6876117202566892
Epoch: 73 | Iteration number: [830/4518] 18% | Training loss: 0.687580801923591
Epoch: 73 | Iteration number: [840/4518] 18% | Training loss: 0.687566546811944
Epoch: 73 | Iteration number: [850/4518] 18% | Training loss: 0.6875647774163415
Epoch: 73 | Iteration number: [860/4518] 19% | Training loss: 0.6875503400037455
Epoch: 73 | Iteration number: [870/4518] 19% | Training loss: 0.6875380830518131
Epoch: 73 | Iteration number: [880/4518] 19% | Training loss: 0.6875295899808407
Epoch: 73 | Iteration number: [890/4518] 19% | Training loss: 0.6875117802218105
Epoch: 73 | Iteration number: [900/4518] 19% | Training loss: 0.687511544558737
Epoch: 73 | Iteration number: [910/4518] 20% | Training loss: 0.6874951901671651
Epoch: 73 | Iteration number: [920/4518] 20% | Training loss: 0.6874880919637887
Epoch: 73 | Iteration number: [930/4518] 20% | Training loss: 0.687475384243073
Epoch: 73 | Iteration number: [940/4518] 20% | Training loss: 0.6874716250186271
Epoch: 73 | Iteration number: [950/4518] 21% | Training loss: 0.6874659470507973
Epoch: 73 | Iteration number: [960/4518] 21% | Training loss: 0.6874685608471434
Epoch: 73 | Iteration number: [970/4518] 21% | Training loss: 0.6874631726250207
Epoch: 73 | Iteration number: [980/4518] 21% | Training loss: 0.6874609713043486
Epoch: 73 | Iteration number: [990/4518] 21% | Training loss: 0.6874522502374167
Epoch: 73 | Iteration number: [1000/4518] 22% | Training loss: 0.6874414932727814
Epoch: 73 | Iteration number: [1010/4518] 22% | Training loss: 0.6874209752767393
Epoch: 73 | Iteration number: [1020/4518] 22% | Training loss: 0.6874163790660746
Epoch: 73 | Iteration number: [1030/4518] 22% | Training loss: 0.6874028547296246
Epoch: 73 | Iteration number: [1040/4518] 23% | Training loss: 0.6873925022780896
Epoch: 73 | Iteration number: [1050/4518] 23% | Training loss: 0.6873749528044746
Epoch: 73 | Iteration number: [1060/4518] 23% | Training loss: 0.6873713552389504
Epoch: 73 | Iteration number: [1070/4518] 23% | Training loss: 0.6873574043545767
Epoch: 73 | Iteration number: [1080/4518] 23% | Training loss: 0.6873527679730345
Epoch: 73 | Iteration number: [1090/4518] 24% | Training loss: 0.6873229203967873
Epoch: 73 | Iteration number: [1100/4518] 24% | Training loss: 0.6873213715986772
Epoch: 73 | Iteration number: [1110/4518] 24% | Training loss: 0.6873167339208964
Epoch: 73 | Iteration number: [1120/4518] 24% | Training loss: 0.6873113157493728
Epoch: 73 | Iteration number: [1130/4518] 25% | Training loss: 0.6873096302547286
Epoch: 73 | Iteration number: [1140/4518] 25% | Training loss: 0.6873154387139437
Epoch: 73 | Iteration number: [1150/4518] 25% | Training loss: 0.6873120829851731
Epoch: 73 | Iteration number: [1160/4518] 25% | Training loss: 0.6873063637264843
Epoch: 73 | Iteration number: [1170/4518] 25% | Training loss: 0.687296216813927
Epoch: 73 | Iteration number: [1180/4518] 26% | Training loss: 0.6872925607834832
Epoch: 73 | Iteration number: [1190/4518] 26% | Training loss: 0.6873106076937764
Epoch: 73 | Iteration number: [1200/4518] 26% | Training loss: 0.6873065026601156
Epoch: 73 | Iteration number: [1210/4518] 26% | Training loss: 0.6873056354601521
Epoch: 73 | Iteration number: [1220/4518] 27% | Training loss: 0.6872946852543315
Epoch: 73 | Iteration number: [1230/4518] 27% | Training loss: 0.6872861714867072
Epoch: 73 | Iteration number: [1240/4518] 27% | Training loss: 0.6872777125527781
Epoch: 73 | Iteration number: [1250/4518] 27% | Training loss: 0.6872767263889312
Epoch: 73 | Iteration number: [1260/4518] 27% | Training loss: 0.6872705124200337
Epoch: 73 | Iteration number: [1270/4518] 28% | Training loss: 0.6872669700093157
Epoch: 73 | Iteration number: [1280/4518] 28% | Training loss: 0.6872602606657893
Epoch: 73 | Iteration number: [1290/4518] 28% | Training loss: 0.6872599996337595
Epoch: 73 | Iteration number: [1300/4518] 28% | Training loss: 0.6872644025087357
Epoch: 73 | Iteration number: [1310/4518] 28% | Training loss: 0.6872589222347464
Epoch: 73 | Iteration number: [1320/4518] 29% | Training loss: 0.6872591697808468
Epoch: 73 | Iteration number: [1330/4518] 29% | Training loss: 0.6872543294626967
Epoch: 73 | Iteration number: [1340/4518] 29% | Training loss: 0.6872565485203445
Epoch: 73 | Iteration number: [1350/4518] 29% | Training loss: 0.6872557966355924
Epoch: 73 | Iteration number: [1360/4518] 30% | Training loss: 0.6872613449745318
Epoch: 73 | Iteration number: [1370/4518] 30% | Training loss: 0.6872580098844793
Epoch: 73 | Iteration number: [1380/4518] 30% | Training loss: 0.6872597033130949
Epoch: 73 | Iteration number: [1390/4518] 30% | Training loss: 0.6872507966250825
Epoch: 73 | Iteration number: [1400/4518] 30% | Training loss: 0.6872456952078002
Epoch: 73 | Iteration number: [1410/4518] 31% | Training loss: 0.6872351816359986
Epoch: 73 | Iteration number: [1420/4518] 31% | Training loss: 0.687244398745013
Epoch: 73 | Iteration number: [1430/4518] 31% | Training loss: 0.6872471188748633
Epoch: 73 | Iteration number: [1440/4518] 31% | Training loss: 0.6872470572590827
Epoch: 73 | Iteration number: [1450/4518] 32% | Training loss: 0.6872479709674573
Epoch: 73 | Iteration number: [1460/4518] 32% | Training loss: 0.6872452529325878
Epoch: 73 | Iteration number: [1470/4518] 32% | Training loss: 0.6872354723158337
Epoch: 73 | Iteration number: [1480/4518] 32% | Training loss: 0.6872305361403002
Epoch: 73 | Iteration number: [1490/4518] 32% | Training loss: 0.6872294474768158
Epoch: 73 | Iteration number: [1500/4518] 33% | Training loss: 0.6872304298082987
Epoch: 73 | Iteration number: [1510/4518] 33% | Training loss: 0.6872277079433795
Epoch: 73 | Iteration number: [1520/4518] 33% | Training loss: 0.687225757852981
Epoch: 73 | Iteration number: [1530/4518] 33% | Training loss: 0.6872248096403732
Epoch: 73 | Iteration number: [1540/4518] 34% | Training loss: 0.6872159207022035
Epoch: 73 | Iteration number: [1550/4518] 34% | Training loss: 0.6872177607397879
Epoch: 73 | Iteration number: [1560/4518] 34% | Training loss: 0.6872106521557539
Epoch: 73 | Iteration number: [1570/4518] 34% | Training loss: 0.6872156408562022
Epoch: 73 | Iteration number: [1580/4518] 34% | Training loss: 0.6872084137759631
Epoch: 73 | Iteration number: [1590/4518] 35% | Training loss: 0.687208391023132
Epoch: 73 | Iteration number: [1600/4518] 35% | Training loss: 0.6872045311331749
Epoch: 73 | Iteration number: [1610/4518] 35% | Training loss: 0.6872012968759359
Epoch: 73 | Iteration number: [1620/4518] 35% | Training loss: 0.6872005591789881
Epoch: 73 | Iteration number: [1630/4518] 36% | Training loss: 0.6871973554415205
Epoch: 73 | Iteration number: [1640/4518] 36% | Training loss: 0.6871990407385478
Epoch: 73 | Iteration number: [1650/4518] 36% | Training loss: 0.6871975594578368
Epoch: 73 | Iteration number: [1660/4518] 36% | Training loss: 0.6872008055807596
Epoch: 73 | Iteration number: [1670/4518] 36% | Training loss: 0.687196027304598
Epoch: 73 | Iteration number: [1680/4518] 37% | Training loss: 0.6871836787178403
Epoch: 73 | Iteration number: [1690/4518] 37% | Training loss: 0.6871767559347773
Epoch: 73 | Iteration number: [1700/4518] 37% | Training loss: 0.687177371558021
Epoch: 73 | Iteration number: [1710/4518] 37% | Training loss: 0.6871781148408589
Epoch: 73 | Iteration number: [1720/4518] 38% | Training loss: 0.6871818163020667
Epoch: 73 | Iteration number: [1730/4518] 38% | Training loss: 0.687187664116049
Epoch: 73 | Iteration number: [1740/4518] 38% | Training loss: 0.6871848978187846
Epoch: 73 | Iteration number: [1750/4518] 38% | Training loss: 0.6871813960756574
Epoch: 73 | Iteration number: [1760/4518] 38% | Training loss: 0.6871693525463343
Epoch: 73 | Iteration number: [1770/4518] 39% | Training loss: 0.6871713727881006
Epoch: 73 | Iteration number: [1780/4518] 39% | Training loss: 0.6871688661950358
Epoch: 73 | Iteration number: [1790/4518] 39% | Training loss: 0.6871716065446758
Epoch: 73 | Iteration number: [1800/4518] 39% | Training loss: 0.6871702845229043
Epoch: 73 | Iteration number: [1810/4518] 40% | Training loss: 0.6871684000966298
Epoch: 73 | Iteration number: [1820/4518] 40% | Training loss: 0.6871683068327852
Epoch: 73 | Iteration number: [1830/4518] 40% | Training loss: 0.6871697315427123
Epoch: 73 | Iteration number: [1840/4518] 40% | Training loss: 0.6871682206249755
Epoch: 73 | Iteration number: [1850/4518] 40% | Training loss: 0.6871682227302242
Epoch: 73 | Iteration number: [1860/4518] 41% | Training loss: 0.6871648222208023
Epoch: 73 | Iteration number: [1870/4518] 41% | Training loss: 0.6871601034931958
Epoch: 73 | Iteration number: [1880/4518] 41% | Training loss: 0.6871642360344846
Epoch: 73 | Iteration number: [1890/4518] 41% | Training loss: 0.6871617435462891
Epoch: 73 | Iteration number: [1900/4518] 42% | Training loss: 0.6871554155726182
Epoch: 73 | Iteration number: [1910/4518] 42% | Training loss: 0.6871524512767792
Epoch: 73 | Iteration number: [1920/4518] 42% | Training loss: 0.6871470705916484
Epoch: 73 | Iteration number: [1930/4518] 42% | Training loss: 0.6871347054916342
Epoch: 73 | Iteration number: [1940/4518] 42% | Training loss: 0.6871349818620485
Epoch: 73 | Iteration number: [1950/4518] 43% | Training loss: 0.6871383123520093
Epoch: 73 | Iteration number: [1960/4518] 43% | Training loss: 0.6871292711216577
Epoch: 73 | Iteration number: [1970/4518] 43% | Training loss: 0.6871269599435293
Epoch: 73 | Iteration number: [1980/4518] 43% | Training loss: 0.6871226170448341
Epoch: 73 | Iteration number: [1990/4518] 44% | Training loss: 0.6871263213493117
Epoch: 73 | Iteration number: [2000/4518] 44% | Training loss: 0.6871236374974251
Epoch: 73 | Iteration number: [2010/4518] 44% | Training loss: 0.6871190747218345
Epoch: 73 | Iteration number: [2020/4518] 44% | Training loss: 0.6871160782209718
Epoch: 73 | Iteration number: [2030/4518] 44% | Training loss: 0.6871160990792542
Epoch: 73 | Iteration number: [2040/4518] 45% | Training loss: 0.6871213612311027
Epoch: 73 | Iteration number: [2050/4518] 45% | Training loss: 0.6871211665723382
Epoch: 73 | Iteration number: [2060/4518] 45% | Training loss: 0.687118265003834
Epoch: 73 | Iteration number: [2070/4518] 45% | Training loss: 0.6871126644565287
Epoch: 73 | Iteration number: [2080/4518] 46% | Training loss: 0.6871118954741038
Epoch: 73 | Iteration number: [2090/4518] 46% | Training loss: 0.6871114372921903
Epoch: 73 | Iteration number: [2100/4518] 46% | Training loss: 0.6871080108483633
Epoch: 73 | Iteration number: [2110/4518] 46% | Training loss: 0.6871122797236059
Epoch: 73 | Iteration number: [2120/4518] 46% | Training loss: 0.6871139652605327
Epoch: 73 | Iteration number: [2130/4518] 47% | Training loss: 0.6871179951468543
Epoch: 73 | Iteration number: [2140/4518] 47% | Training loss: 0.6871177761632705
Epoch: 73 | Iteration number: [2150/4518] 47% | Training loss: 0.6871164249264917
Epoch: 73 | Iteration number: [2160/4518] 47% | Training loss: 0.6871115716519179
Epoch: 73 | Iteration number: [2170/4518] 48% | Training loss: 0.6871114425120816
Epoch: 73 | Iteration number: [2180/4518] 48% | Training loss: 0.6871056421634254
Epoch: 73 | Iteration number: [2190/4518] 48% | Training loss: 0.6871104941520517
Epoch: 73 | Iteration number: [2200/4518] 48% | Training loss: 0.6871092801744287
Epoch: 73 | Iteration number: [2210/4518] 48% | Training loss: 0.6871087162742787
Epoch: 73 | Iteration number: [2220/4518] 49% | Training loss: 0.6871073771167446
Epoch: 73 | Iteration number: [2230/4518] 49% | Training loss: 0.6871069750710987
Epoch: 73 | Iteration number: [2240/4518] 49% | Training loss: 0.6871022080736501
Epoch: 73 | Iteration number: [2250/4518] 49% | Training loss: 0.6870942154725392
Epoch: 73 | Iteration number: [2260/4518] 50% | Training loss: 0.687088984989487
Epoch: 73 | Iteration number: [2270/4518] 50% | Training loss: 0.6870913745285656
Epoch: 73 | Iteration number: [2280/4518] 50% | Training loss: 0.6870926966792659
Epoch: 73 | Iteration number: [2290/4518] 50% | Training loss: 0.6870948742310553
Epoch: 73 | Iteration number: [2300/4518] 50% | Training loss: 0.6870990640184154
Epoch: 73 | Iteration number: [2310/4518] 51% | Training loss: 0.6871006164199862
Epoch: 73 | Iteration number: [2320/4518] 51% | Training loss: 0.6871022771144736
Epoch: 73 | Iteration number: [2330/4518] 51% | Training loss: 0.6871010097567104
Epoch: 73 | Iteration number: [2340/4518] 51% | Training loss: 0.6870998673459403
Epoch: 73 | Iteration number: [2350/4518] 52% | Training loss: 0.6870969453771064
Epoch: 73 | Iteration number: [2360/4518] 52% | Training loss: 0.6871000793525728
Epoch: 73 | Iteration number: [2370/4518] 52% | Training loss: 0.687104571921916
Epoch: 73 | Iteration number: [2380/4518] 52% | Training loss: 0.6871020271247175
Epoch: 73 | Iteration number: [2390/4518] 52% | Training loss: 0.6871003669176141
Epoch: 73 | Iteration number: [2400/4518] 53% | Training loss: 0.6870973092814286
Epoch: 73 | Iteration number: [2410/4518] 53% | Training loss: 0.6871025879106086
Epoch: 73 | Iteration number: [2420/4518] 53% | Training loss: 0.6871035664534766
Epoch: 73 | Iteration number: [2430/4518] 53% | Training loss: 0.6871030410621392
Epoch: 73 | Iteration number: [2440/4518] 54% | Training loss: 0.6871039691030002
Epoch: 73 | Iteration number: [2450/4518] 54% | Training loss: 0.6871036187969909
Epoch: 73 | Iteration number: [2460/4518] 54% | Training loss: 0.6871007445624204
Epoch: 73 | Iteration number: [2470/4518] 54% | Training loss: 0.6870975380725706
Epoch: 73 | Iteration number: [2480/4518] 54% | Training loss: 0.6870992005592392
Epoch: 73 | Iteration number: [2490/4518] 55% | Training loss: 0.6870925114336741
Epoch: 73 | Iteration number: [2500/4518] 55% | Training loss: 0.6870913892507553
Epoch: 73 | Iteration number: [2510/4518] 55% | Training loss: 0.6870849229187604
Epoch: 73 | Iteration number: [2520/4518] 55% | Training loss: 0.6870866217783519
Epoch: 73 | Iteration number: [2530/4518] 55% | Training loss: 0.6870868824216217
Epoch: 73 | Iteration number: [2540/4518] 56% | Training loss: 0.687084274169967
Epoch: 73 | Iteration number: [2550/4518] 56% | Training loss: 0.6870859599113465
Epoch: 73 | Iteration number: [2560/4518] 56% | Training loss: 0.6870822774246335
Epoch: 73 | Iteration number: [2570/4518] 56% | Training loss: 0.687083541094561
Epoch: 73 | Iteration number: [2580/4518] 57% | Training loss: 0.687084214423978
Epoch: 73 | Iteration number: [2590/4518] 57% | Training loss: 0.6870748988910071
Epoch: 73 | Iteration number: [2600/4518] 57% | Training loss: 0.6870712060882495
Epoch: 73 | Iteration number: [2610/4518] 57% | Training loss: 0.6870722000854682
Epoch: 73 | Iteration number: [2620/4518] 57% | Training loss: 0.6870681569548963
Epoch: 73 | Iteration number: [2630/4518] 58% | Training loss: 0.68706115223609
Epoch: 73 | Iteration number: [2640/4518] 58% | Training loss: 0.6870675422477
Epoch: 73 | Iteration number: [2650/4518] 58% | Training loss: 0.6870683332659163
Epoch: 73 | Iteration number: [2660/4518] 58% | Training loss: 0.6870676011967479
Epoch: 73 | Iteration number: [2670/4518] 59% | Training loss: 0.6870633307914162
Epoch: 73 | Iteration number: [2680/4518] 59% | Training loss: 0.6870605521237673
Epoch: 73 | Iteration number: [2690/4518] 59% | Training loss: 0.687063299435222
Epoch: 73 | Iteration number: [2700/4518] 59% | Training loss: 0.687060293312426
Epoch: 73 | Iteration number: [2710/4518] 59% | Training loss: 0.6870616795392054
Epoch: 73 | Iteration number: [2720/4518] 60% | Training loss: 0.6870610151220771
Epoch: 73 | Iteration number: [2730/4518] 60% | Training loss: 0.6870612444458427
Epoch: 73 | Iteration number: [2740/4518] 60% | Training loss: 0.6870596953334599
Epoch: 73 | Iteration number: [2750/4518] 60% | Training loss: 0.6870546716993505
Epoch: 73 | Iteration number: [2760/4518] 61% | Training loss: 0.6870523876686027
Epoch: 73 | Iteration number: [2770/4518] 61% | Training loss: 0.6870519579747953
Epoch: 73 | Iteration number: [2780/4518] 61% | Training loss: 0.6870509702310288
Epoch: 73 | Iteration number: [2790/4518] 61% | Training loss: 0.6870504398927039
Epoch: 73 | Iteration number: [2800/4518] 61% | Training loss: 0.687053817404168
Epoch: 73 | Iteration number: [2810/4518] 62% | Training loss: 0.6870516956700973
Epoch: 73 | Iteration number: [2820/4518] 62% | Training loss: 0.6870497863132058
Epoch: 73 | Iteration number: [2830/4518] 62% | Training loss: 0.6870510164503495
Epoch: 73 | Iteration number: [2840/4518] 62% | Training loss: 0.6870440197662568
Epoch: 73 | Iteration number: [2850/4518] 63% | Training loss: 0.6870446018168801
Epoch: 73 | Iteration number: [2860/4518] 63% | Training loss: 0.6870412634386049
Epoch: 73 | Iteration number: [2870/4518] 63% | Training loss: 0.6870382634604849
Epoch: 73 | Iteration number: [2880/4518] 63% | Training loss: 0.6870376558560464
Epoch: 73 | Iteration number: [2890/4518] 63% | Training loss: 0.6870366989122543
Epoch: 73 | Iteration number: [2900/4518] 64% | Training loss: 0.6870406237347373
Epoch: 73 | Iteration number: [2910/4518] 64% | Training loss: 0.6870370345222172
Epoch: 73 | Iteration number: [2920/4518] 64% | Training loss: 0.6870332303520751
Epoch: 73 | Iteration number: [2930/4518] 64% | Training loss: 0.6870308345088373
Epoch: 73 | Iteration number: [2940/4518] 65% | Training loss: 0.6870316839339782
Epoch: 73 | Iteration number: [2950/4518] 65% | Training loss: 0.6870341078103599
Epoch: 73 | Iteration number: [2960/4518] 65% | Training loss: 0.6870355483043838
Epoch: 73 | Iteration number: [2970/4518] 65% | Training loss: 0.6870346968021457
Epoch: 73 | Iteration number: [2980/4518] 65% | Training loss: 0.6870354932626622
Epoch: 73 | Iteration number: [2990/4518] 66% | Training loss: 0.6870347303889667
Epoch: 73 | Iteration number: [3000/4518] 66% | Training loss: 0.6870303547183673
Epoch: 73 | Iteration number: [3010/4518] 66% | Training loss: 0.6870251052007327
Epoch: 73 | Iteration number: [3020/4518] 66% | Training loss: 0.6870236615866225
Epoch: 73 | Iteration number: [3030/4518] 67% | Training loss: 0.6870253890654435
Epoch: 73 | Iteration number: [3040/4518] 67% | Training loss: 0.6870203114261753
Epoch: 73 | Iteration number: [3050/4518] 67% | Training loss: 0.6870199133138187
Epoch: 73 | Iteration number: [3060/4518] 67% | Training loss: 0.6870192973637114
Epoch: 73 | Iteration number: [3070/4518] 67% | Training loss: 0.6870229873672759
Epoch: 73 | Iteration number: [3080/4518] 68% | Training loss: 0.687024087720103
Epoch: 73 | Iteration number: [3090/4518] 68% | Training loss: 0.6870217755581569
Epoch: 73 | Iteration number: [3100/4518] 68% | Training loss: 0.6870218978197344
Epoch: 73 | Iteration number: [3110/4518] 68% | Training loss: 0.6870220646214256
Epoch: 73 | Iteration number: [3120/4518] 69% | Training loss: 0.6870224096645148
Epoch: 73 | Iteration number: [3130/4518] 69% | Training loss: 0.6870241315981831
Epoch: 73 | Iteration number: [3140/4518] 69% | Training loss: 0.6870240506283037
Epoch: 73 | Iteration number: [3150/4518] 69% | Training loss: 0.6870286468097142
Epoch: 73 | Iteration number: [3160/4518] 69% | Training loss: 0.6870304982684836
Epoch: 73 | Iteration number: [3170/4518] 70% | Training loss: 0.6870296970526879
Epoch: 73 | Iteration number: [3180/4518] 70% | Training loss: 0.6870276046061666
Epoch: 73 | Iteration number: [3190/4518] 70% | Training loss: 0.6870244457430227
Epoch: 73 | Iteration number: [3200/4518] 70% | Training loss: 0.6870241697132587
Epoch: 73 | Iteration number: [3210/4518] 71% | Training loss: 0.6870226332703112
Epoch: 73 | Iteration number: [3220/4518] 71% | Training loss: 0.687019191154782
Epoch: 73 | Iteration number: [3230/4518] 71% | Training loss: 0.6870142860493793
Epoch: 73 | Iteration number: [3240/4518] 71% | Training loss: 0.687013292643759
Epoch: 73 | Iteration number: [3250/4518] 71% | Training loss: 0.6870097161623148
Epoch: 73 | Iteration number: [3260/4518] 72% | Training loss: 0.6870126604668202
Epoch: 73 | Iteration number: [3270/4518] 72% | Training loss: 0.6870075010742981
Epoch: 73 | Iteration number: [3280/4518] 72% | Training loss: 0.6870039486667004
Epoch: 73 | Iteration number: [3290/4518] 72% | Training loss: 0.6870022482785048
Epoch: 73 | Iteration number: [3300/4518] 73% | Training loss: 0.6870015366872152
Epoch: 73 | Iteration number: [3310/4518] 73% | Training loss: 0.6869979887930648
Epoch: 73 | Iteration number: [3320/4518] 73% | Training loss: 0.6869950862713607
Epoch: 73 | Iteration number: [3330/4518] 73% | Training loss: 0.6869946390121907
Epoch: 73 | Iteration number: [3340/4518] 73% | Training loss: 0.6869951381297883
Epoch: 73 | Iteration number: [3350/4518] 74% | Training loss: 0.6869966739505085
Epoch: 73 | Iteration number: [3360/4518] 74% | Training loss: 0.6869964286862384
Epoch: 73 | Iteration number: [3370/4518] 74% | Training loss: 0.6869939582284197
Epoch: 73 | Iteration number: [3380/4518] 74% | Training loss: 0.686990866259005
Epoch: 73 | Iteration number: [3390/4518] 75% | Training loss: 0.6869887861881988
Epoch: 73 | Iteration number: [3400/4518] 75% | Training loss: 0.6869859643718775
Epoch: 73 | Iteration number: [3410/4518] 75% | Training loss: 0.686986059509764
Epoch: 73 | Iteration number: [3420/4518] 75% | Training loss: 0.6869858246274859
Epoch: 73 | Iteration number: [3430/4518] 75% | Training loss: 0.6869859747740688
Epoch: 73 | Iteration number: [3440/4518] 76% | Training loss: 0.6869850183295649
Epoch: 73 | Iteration number: [3450/4518] 76% | Training loss: 0.6869855055774468
Epoch: 73 | Iteration number: [3460/4518] 76% | Training loss: 0.6869835322130622
Epoch: 73 | Iteration number: [3470/4518] 76% | Training loss: 0.6869793469349315
Epoch: 73 | Iteration number: [3480/4518] 77% | Training loss: 0.6869772869451293
Epoch: 73 | Iteration number: [3490/4518] 77% | Training loss: 0.6869776637984552
Epoch: 73 | Iteration number: [3500/4518] 77% | Training loss: 0.6869738117967333
Epoch: 73 | Iteration number: [3510/4518] 77% | Training loss: 0.6869752174089437
Epoch: 73 | Iteration number: [3520/4518] 77% | Training loss: 0.6869740141894329
Epoch: 73 | Iteration number: [3530/4518] 78% | Training loss: 0.6869709540021318
Epoch: 73 | Iteration number: [3540/4518] 78% | Training loss: 0.6869714163454239
Epoch: 73 | Iteration number: [3550/4518] 78% | Training loss: 0.6869701224313656
Epoch: 73 | Iteration number: [3560/4518] 78% | Training loss: 0.6869698755694239
Epoch: 73 | Iteration number: [3570/4518] 79% | Training loss: 0.6869677358147811
Epoch: 73 | Iteration number: [3580/4518] 79% | Training loss: 0.6869663988245266
Epoch: 73 | Iteration number: [3590/4518] 79% | Training loss: 0.6869648476164986
Epoch: 73 | Iteration number: [3600/4518] 79% | Training loss: 0.6869637842476368
Epoch: 73 | Iteration number: [3610/4518] 79% | Training loss: 0.6869629808079833
Epoch: 73 | Iteration number: [3620/4518] 80% | Training loss: 0.6869611581550777
Epoch: 73 | Iteration number: [3630/4518] 80% | Training loss: 0.6869584780258252
Epoch: 73 | Iteration number: [3640/4518] 80% | Training loss: 0.6869590236917957
Epoch: 73 | Iteration number: [3650/4518] 80% | Training loss: 0.6869598524374505
Epoch: 73 | Iteration number: [3660/4518] 81% | Training loss: 0.6869619292802498
Epoch: 73 | Iteration number: [3670/4518] 81% | Training loss: 0.686960272145856
Epoch: 73 | Iteration number: [3680/4518] 81% | Training loss: 0.6869622187284024
Epoch: 73 | Iteration number: [3690/4518] 81% | Training loss: 0.6869605423796791
Epoch: 73 | Iteration number: [3700/4518] 81% | Training loss: 0.6869602886889432
Epoch: 73 | Iteration number: [3710/4518] 82% | Training loss: 0.6869588810799899
Epoch: 73 | Iteration number: [3720/4518] 82% | Training loss: 0.6869560969292476
Epoch: 73 | Iteration number: [3730/4518] 82% | Training loss: 0.6869584116954905
Epoch: 73 | Iteration number: [3740/4518] 82% | Training loss: 0.6869555912393938
Epoch: 73 | Iteration number: [3750/4518] 83% | Training loss: 0.6869534166018169
Epoch: 73 | Iteration number: [3760/4518] 83% | Training loss: 0.6869486869015592
Epoch: 73 | Iteration number: [3770/4518] 83% | Training loss: 0.686944264189318
Epoch: 73 | Iteration number: [3780/4518] 83% | Training loss: 0.6869472613725712
Epoch: 73 | Iteration number: [3790/4518] 83% | Training loss: 0.6869464377614628
Epoch: 73 | Iteration number: [3800/4518] 84% | Training loss: 0.6869462932724701
Epoch: 73 | Iteration number: [3810/4518] 84% | Training loss: 0.686944249952872
Epoch: 73 | Iteration number: [3820/4518] 84% | Training loss: 0.6869424622252349
Epoch: 73 | Iteration number: [3830/4518] 84% | Training loss: 0.686943664936733
Epoch: 73 | Iteration number: [3840/4518] 84% | Training loss: 0.6869447551046809
Epoch: 73 | Iteration number: [3850/4518] 85% | Training loss: 0.6869458116649033
Epoch: 73 | Iteration number: [3860/4518] 85% | Training loss: 0.6869458612537137
Epoch: 73 | Iteration number: [3870/4518] 85% | Training loss: 0.6869479658375722
Epoch: 73 | Iteration number: [3880/4518] 85% | Training loss: 0.6869447130671481
Epoch: 73 | Iteration number: [3890/4518] 86% | Training loss: 0.6869444912227689
Epoch: 73 | Iteration number: [3900/4518] 86% | Training loss: 0.6869459438018309
Epoch: 73 | Iteration number: [3910/4518] 86% | Training loss: 0.6869468683324507
Epoch: 73 | Iteration number: [3920/4518] 86% | Training loss: 0.6869490019672987
Epoch: 73 | Iteration number: [3930/4518] 86% | Training loss: 0.6869486326934727
Epoch: 73 | Iteration number: [3940/4518] 87% | Training loss: 0.6869507257254596
Epoch: 73 | Iteration number: [3950/4518] 87% | Training loss: 0.686948542851436
Epoch: 73 | Iteration number: [3960/4518] 87% | Training loss: 0.686949759300309
Epoch: 73 | Iteration number: [3970/4518] 87% | Training loss: 0.6869539138502078
Epoch: 73 | Iteration number: [3980/4518] 88% | Training loss: 0.6869521054191206
Epoch: 73 | Iteration number: [3990/4518] 88% | Training loss: 0.6869536653795936
Epoch: 73 | Iteration number: [4000/4518] 88% | Training loss: 0.6869521714746952
Epoch: 73 | Iteration number: [4010/4518] 88% | Training loss: 0.6869520383582746
Epoch: 73 | Iteration number: [4020/4518] 88% | Training loss: 0.6869522924150401
Epoch: 73 | Iteration number: [4030/4518] 89% | Training loss: 0.6869523573602103
Epoch: 73 | Iteration number: [4040/4518] 89% | Training loss: 0.6869513710684115
Epoch: 73 | Iteration number: [4050/4518] 89% | Training loss: 0.6869528997238772
Epoch: 73 | Iteration number: [4060/4518] 89% | Training loss: 0.6869512428791065
Epoch: 73 | Iteration number: [4070/4518] 90% | Training loss: 0.6869497559873127
Epoch: 73 | Iteration number: [4080/4518] 90% | Training loss: 0.686948686896586
Epoch: 73 | Iteration number: [4090/4518] 90% | Training loss: 0.6869464228963502
Epoch: 73 | Iteration number: [4100/4518] 90% | Training loss: 0.6869407858645044
Epoch: 73 | Iteration number: [4110/4518] 90% | Training loss: 0.6869408533956013
Epoch: 73 | Iteration number: [4120/4518] 91% | Training loss: 0.6869414740974463
Epoch: 73 | Iteration number: [4130/4518] 91% | Training loss: 0.6869422788770089
Epoch: 73 | Iteration number: [4140/4518] 91% | Training loss: 0.6869415262471075
Epoch: 73 | Iteration number: [4150/4518] 91% | Training loss: 0.6869404702014233
Epoch: 73 | Iteration number: [4160/4518] 92% | Training loss: 0.6869407424989801
Epoch: 73 | Iteration number: [4170/4518] 92% | Training loss: 0.6869391027829058
Epoch: 73 | Iteration number: [4180/4518] 92% | Training loss: 0.6869379436285302
Epoch: 73 | Iteration number: [4190/4518] 92% | Training loss: 0.6869395371268643
Epoch: 73 | Iteration number: [4200/4518] 92% | Training loss: 0.6869385326050577
Epoch: 73 | Iteration number: [4210/4518] 93% | Training loss: 0.6869392878935626
Epoch: 73 | Iteration number: [4220/4518] 93% | Training loss: 0.6869388060547165
Epoch: 73 | Iteration number: [4230/4518] 93% | Training loss: 0.6869397314445911
Epoch: 73 | Iteration number: [4240/4518] 93% | Training loss: 0.6869405328524563
Epoch: 73 | Iteration number: [4250/4518] 94% | Training loss: 0.6869377209438997
Epoch: 73 | Iteration number: [4260/4518] 94% | Training loss: 0.686938687501379
Epoch: 73 | Iteration number: [4270/4518] 94% | Training loss: 0.686942475070998
Epoch: 73 | Iteration number: [4280/4518] 94% | Training loss: 0.6869405014771167
Epoch: 73 | Iteration number: [4290/4518] 94% | Training loss: 0.6869419448025577
Epoch: 73 | Iteration number: [4300/4518] 95% | Training loss: 0.6869402459333109
Epoch: 73 | Iteration number: [4310/4518] 95% | Training loss: 0.6869367699888632
Epoch: 73 | Iteration number: [4320/4518] 95% | Training loss: 0.6869354840919927
Epoch: 73 | Iteration number: [4330/4518] 95% | Training loss: 0.6869353258169275
Epoch: 73 | Iteration number: [4340/4518] 96% | Training loss: 0.6869322767180781
Epoch: 73 | Iteration number: [4350/4518] 96% | Training loss: 0.6869311779257895
Epoch: 73 | Iteration number: [4360/4518] 96% | Training loss: 0.6869322601124781
Epoch: 73 | Iteration number: [4370/4518] 96% | Training loss: 0.6869313387085153
Epoch: 73 | Iteration number: [4380/4518] 96% | Training loss: 0.6869276885164383
Epoch: 73 | Iteration number: [4390/4518] 97% | Training loss: 0.6869275152547485
Epoch: 73 | Iteration number: [4400/4518] 97% | Training loss: 0.6869282756881281
Epoch: 73 | Iteration number: [4410/4518] 97% | Training loss: 0.6869293824615392
Epoch: 73 | Iteration number: [4420/4518] 97% | Training loss: 0.6869278066568245
Epoch: 73 | Iteration number: [4430/4518] 98% | Training loss: 0.6869276471520116
Epoch: 73 | Iteration number: [4440/4518] 98% | Training loss: 0.6869258326318887
Epoch: 73 | Iteration number: [4450/4518] 98% | Training loss: 0.6869253022081396
Epoch: 73 | Iteration number: [4460/4518] 98% | Training loss: 0.6869251806907055
Epoch: 73 | Iteration number: [4470/4518] 98% | Training loss: 0.6869248509407043
Epoch: 73 | Iteration number: [4480/4518] 99% | Training loss: 0.6869253417477011
Epoch: 73 | Iteration number: [4490/4518] 99% | Training loss: 0.6869264824751491
Epoch: 73 | Iteration number: [4500/4518] 99% | Training loss: 0.6869249861240387
Epoch: 73 | Iteration number: [4510/4518] 99% | Training loss: 0.6869216464575537

 End of epoch: 73 | Train Loss: 0.6867697336416215 | Training Time: 632 

 End of epoch: 73 | Eval Loss: 0.6896815701406829 | Evaluating Time: 17 
Epoch: 74 | Iteration number: [10/4518] 0% | Training loss: 0.7541170537471771
Epoch: 74 | Iteration number: [20/4518] 0% | Training loss: 0.7204438507556915
Epoch: 74 | Iteration number: [30/4518] 0% | Training loss: 0.7091401318709055
Epoch: 74 | Iteration number: [40/4518] 0% | Training loss: 0.7032599911093712
Epoch: 74 | Iteration number: [50/4518] 1% | Training loss: 0.6999632203578949
Epoch: 74 | Iteration number: [60/4518] 1% | Training loss: 0.6978241175413131
Epoch: 74 | Iteration number: [70/4518] 1% | Training loss: 0.6960423733506884
Epoch: 74 | Iteration number: [80/4518] 1% | Training loss: 0.6948073357343674
Epoch: 74 | Iteration number: [90/4518] 1% | Training loss: 0.6938457952605354
Epoch: 74 | Iteration number: [100/4518] 2% | Training loss: 0.693128628730774
Epoch: 74 | Iteration number: [110/4518] 2% | Training loss: 0.6925834997133775
Epoch: 74 | Iteration number: [120/4518] 2% | Training loss: 0.6921505495905876
Epoch: 74 | Iteration number: [130/4518] 2% | Training loss: 0.691803444807346
Epoch: 74 | Iteration number: [140/4518] 3% | Training loss: 0.6915486199515206
Epoch: 74 | Iteration number: [150/4518] 3% | Training loss: 0.6912665383021037
Epoch: 74 | Iteration number: [160/4518] 3% | Training loss: 0.691030989587307
Epoch: 74 | Iteration number: [170/4518] 3% | Training loss: 0.6908234599758597
Epoch: 74 | Iteration number: [180/4518] 3% | Training loss: 0.6906167305178113
Epoch: 74 | Iteration number: [190/4518] 4% | Training loss: 0.6904524818847054
Epoch: 74 | Iteration number: [200/4518] 4% | Training loss: 0.6902115473151207
Epoch: 74 | Iteration number: [210/4518] 4% | Training loss: 0.690052897021884
Epoch: 74 | Iteration number: [220/4518] 4% | Training loss: 0.6899643264033578
Epoch: 74 | Iteration number: [230/4518] 5% | Training loss: 0.6898866622344307
Epoch: 74 | Iteration number: [240/4518] 5% | Training loss: 0.6897462256252765
Epoch: 74 | Iteration number: [250/4518] 5% | Training loss: 0.6896519238948822
Epoch: 74 | Iteration number: [260/4518] 5% | Training loss: 0.6895724564790726
Epoch: 74 | Iteration number: [270/4518] 5% | Training loss: 0.6894417168917479
Epoch: 74 | Iteration number: [280/4518] 6% | Training loss: 0.6893193975090981
Epoch: 74 | Iteration number: [290/4518] 6% | Training loss: 0.6892334105639623
Epoch: 74 | Iteration number: [300/4518] 6% | Training loss: 0.6891294920444488
Epoch: 74 | Iteration number: [310/4518] 6% | Training loss: 0.6890933273300048
Epoch: 74 | Iteration number: [320/4518] 7% | Training loss: 0.6890198601409793
Epoch: 74 | Iteration number: [330/4518] 7% | Training loss: 0.6889791042515726
Epoch: 74 | Iteration number: [340/4518] 7% | Training loss: 0.6889570872573292
Epoch: 74 | Iteration number: [350/4518] 7% | Training loss: 0.6889062309265137
Epoch: 74 | Iteration number: [360/4518] 7% | Training loss: 0.6888776602016555
Epoch: 74 | Iteration number: [370/4518] 8% | Training loss: 0.6888143433106912
Epoch: 74 | Iteration number: [380/4518] 8% | Training loss: 0.6887598884733099
Epoch: 74 | Iteration number: [390/4518] 8% | Training loss: 0.6886545334106836
Epoch: 74 | Iteration number: [400/4518] 8% | Training loss: 0.6885851220786572
Epoch: 74 | Iteration number: [410/4518] 9% | Training loss: 0.6885527878272825
Epoch: 74 | Iteration number: [420/4518] 9% | Training loss: 0.6885377452487037
Epoch: 74 | Iteration number: [430/4518] 9% | Training loss: 0.6885240166686302
Epoch: 74 | Iteration number: [440/4518] 9% | Training loss: 0.6884948660026897
Epoch: 74 | Iteration number: [450/4518] 9% | Training loss: 0.6884465559323629
Epoch: 74 | Iteration number: [460/4518] 10% | Training loss: 0.6883810757294945
Epoch: 74 | Iteration number: [470/4518] 10% | Training loss: 0.6883252142591679
Epoch: 74 | Iteration number: [480/4518] 10% | Training loss: 0.6883026783665022
Epoch: 74 | Iteration number: [490/4518] 10% | Training loss: 0.6882975238926556
Epoch: 74 | Iteration number: [500/4518] 11% | Training loss: 0.6882657464742661
Epoch: 74 | Iteration number: [510/4518] 11% | Training loss: 0.6882055761767368
Epoch: 74 | Iteration number: [520/4518] 11% | Training loss: 0.6881483585788654
Epoch: 74 | Iteration number: [530/4518] 11% | Training loss: 0.6881386255318264
Epoch: 74 | Iteration number: [540/4518] 11% | Training loss: 0.6880985110998153
Epoch: 74 | Iteration number: [550/4518] 12% | Training loss: 0.6880823370543393
Epoch: 74 | Iteration number: [560/4518] 12% | Training loss: 0.6880443489977291
Epoch: 74 | Iteration number: [570/4518] 12% | Training loss: 0.6880282373804795
Epoch: 74 | Iteration number: [580/4518] 12% | Training loss: 0.6880159952517213
Epoch: 74 | Iteration number: [590/4518] 13% | Training loss: 0.6880092882503898
Epoch: 74 | Iteration number: [600/4518] 13% | Training loss: 0.6880154512325922
Epoch: 74 | Iteration number: [610/4518] 13% | Training loss: 0.6879923163867387
Epoch: 74 | Iteration number: [620/4518] 13% | Training loss: 0.6879796537660783
Epoch: 74 | Iteration number: [630/4518] 13% | Training loss: 0.6879685137006971
Epoch: 74 | Iteration number: [640/4518] 14% | Training loss: 0.6879268900491298
Epoch: 74 | Iteration number: [650/4518] 14% | Training loss: 0.6879052138328552
Epoch: 74 | Iteration number: [660/4518] 14% | Training loss: 0.6878940465775403
Epoch: 74 | Iteration number: [670/4518] 14% | Training loss: 0.6878858626778446
Epoch: 74 | Iteration number: [680/4518] 15% | Training loss: 0.6878696956178721
Epoch: 74 | Iteration number: [690/4518] 15% | Training loss: 0.6878613018471261
Epoch: 74 | Iteration number: [700/4518] 15% | Training loss: 0.6878412295239312
Epoch: 74 | Iteration number: [710/4518] 15% | Training loss: 0.6878358133242164
Epoch: 74 | Iteration number: [720/4518] 15% | Training loss: 0.6878047276702192
Epoch: 74 | Iteration number: [730/4518] 16% | Training loss: 0.6877953589779057
Epoch: 74 | Iteration number: [740/4518] 16% | Training loss: 0.6877858017747467
Epoch: 74 | Iteration number: [750/4518] 16% | Training loss: 0.6877690728505452
Epoch: 74 | Iteration number: [760/4518] 16% | Training loss: 0.687763514487367
Epoch: 74 | Iteration number: [770/4518] 17% | Training loss: 0.6877519586643616
Epoch: 74 | Iteration number: [780/4518] 17% | Training loss: 0.6877233282113686
Epoch: 74 | Iteration number: [790/4518] 17% | Training loss: 0.687700546014158
Epoch: 74 | Iteration number: [800/4518] 17% | Training loss: 0.6876973804831504
Epoch: 74 | Iteration number: [810/4518] 17% | Training loss: 0.687684561735318
Epoch: 74 | Iteration number: [820/4518] 18% | Training loss: 0.6876643733280461
Epoch: 74 | Iteration number: [830/4518] 18% | Training loss: 0.6876426792288401
Epoch: 74 | Iteration number: [840/4518] 18% | Training loss: 0.6876307042581694
Epoch: 74 | Iteration number: [850/4518] 18% | Training loss: 0.687612199643079
Epoch: 74 | Iteration number: [860/4518] 19% | Training loss: 0.6875951141812081
Epoch: 74 | Iteration number: [870/4518] 19% | Training loss: 0.6875826293709635
Epoch: 74 | Iteration number: [880/4518] 19% | Training loss: 0.6875723305073651
Epoch: 74 | Iteration number: [890/4518] 19% | Training loss: 0.6875627559892247
Epoch: 74 | Iteration number: [900/4518] 19% | Training loss: 0.6875563110245598
Epoch: 74 | Iteration number: [910/4518] 20% | Training loss: 0.6875380926079803
Epoch: 74 | Iteration number: [920/4518] 20% | Training loss: 0.6875277627421462
Epoch: 74 | Iteration number: [930/4518] 20% | Training loss: 0.6875234892291407
Epoch: 74 | Iteration number: [940/4518] 20% | Training loss: 0.6874978568325651
Epoch: 74 | Iteration number: [950/4518] 21% | Training loss: 0.6874763737226788
Epoch: 74 | Iteration number: [960/4518] 21% | Training loss: 0.687465409686168
Epoch: 74 | Iteration number: [970/4518] 21% | Training loss: 0.6874643701253478
Epoch: 74 | Iteration number: [980/4518] 21% | Training loss: 0.6874563895926183
Epoch: 74 | Iteration number: [990/4518] 21% | Training loss: 0.6874487846186667
Epoch: 74 | Iteration number: [1000/4518] 22% | Training loss: 0.6874442111849784
Epoch: 74 | Iteration number: [1010/4518] 22% | Training loss: 0.6874469798390228
Epoch: 74 | Iteration number: [1020/4518] 22% | Training loss: 0.6874377594274633
Epoch: 74 | Iteration number: [1030/4518] 22% | Training loss: 0.6874302104260157
Epoch: 74 | Iteration number: [1040/4518] 23% | Training loss: 0.6874181808187412
Epoch: 74 | Iteration number: [1050/4518] 23% | Training loss: 0.6874107498214358
Epoch: 74 | Iteration number: [1060/4518] 23% | Training loss: 0.6874006255055374
Epoch: 74 | Iteration number: [1070/4518] 23% | Training loss: 0.6873775228161678
Epoch: 74 | Iteration number: [1080/4518] 23% | Training loss: 0.6873841959569189
Epoch: 74 | Iteration number: [1090/4518] 24% | Training loss: 0.6873817950213721
Epoch: 74 | Iteration number: [1100/4518] 24% | Training loss: 0.6873774190382524
Epoch: 74 | Iteration number: [1110/4518] 24% | Training loss: 0.6873620404316498
Epoch: 74 | Iteration number: [1120/4518] 24% | Training loss: 0.6873632268714053
Epoch: 74 | Iteration number: [1130/4518] 25% | Training loss: 0.6873642923557652
Epoch: 74 | Iteration number: [1140/4518] 25% | Training loss: 0.6873624957967223
Epoch: 74 | Iteration number: [1150/4518] 25% | Training loss: 0.6873568109325741
Epoch: 74 | Iteration number: [1160/4518] 25% | Training loss: 0.6873587736281855
Epoch: 74 | Iteration number: [1170/4518] 25% | Training loss: 0.6873493722361377
Epoch: 74 | Iteration number: [1180/4518] 26% | Training loss: 0.6873484344805701
Epoch: 74 | Iteration number: [1190/4518] 26% | Training loss: 0.6873492382153743
Epoch: 74 | Iteration number: [1200/4518] 26% | Training loss: 0.6873435639341672
Epoch: 74 | Iteration number: [1210/4518] 26% | Training loss: 0.6873390819415574
Epoch: 74 | Iteration number: [1220/4518] 27% | Training loss: 0.6873354648468925
Epoch: 74 | Iteration number: [1230/4518] 27% | Training loss: 0.6873272885151995
Epoch: 74 | Iteration number: [1240/4518] 27% | Training loss: 0.6873294382326065
Epoch: 74 | Iteration number: [1250/4518] 27% | Training loss: 0.687326576089859
Epoch: 74 | Iteration number: [1260/4518] 27% | Training loss: 0.687319436905876
Epoch: 74 | Iteration number: [1270/4518] 28% | Training loss: 0.6873232090567041
Epoch: 74 | Iteration number: [1280/4518] 28% | Training loss: 0.6873241612687707
Epoch: 74 | Iteration number: [1290/4518] 28% | Training loss: 0.687319434798041
Epoch: 74 | Iteration number: [1300/4518] 28% | Training loss: 0.6873083305358887
Epoch: 74 | Iteration number: [1310/4518] 28% | Training loss: 0.6873051606061804
Epoch: 74 | Iteration number: [1320/4518] 29% | Training loss: 0.6873016254468398
Epoch: 74 | Iteration number: [1330/4518] 29% | Training loss: 0.6873061244200943
Epoch: 74 | Iteration number: [1340/4518] 29% | Training loss: 0.6873064292455787
Epoch: 74 | Iteration number: [1350/4518] 29% | Training loss: 0.6872973331698665
Epoch: 74 | Iteration number: [1360/4518] 30% | Training loss: 0.6872926328550367
Epoch: 74 | Iteration number: [1370/4518] 30% | Training loss: 0.6872961438485305
Epoch: 74 | Iteration number: [1380/4518] 30% | Training loss: 0.6872914389423702
Epoch: 74 | Iteration number: [1390/4518] 30% | Training loss: 0.687288887337815
Epoch: 74 | Iteration number: [1400/4518] 30% | Training loss: 0.6872871594769614
Epoch: 74 | Iteration number: [1410/4518] 31% | Training loss: 0.6872738302176726
Epoch: 74 | Iteration number: [1420/4518] 31% | Training loss: 0.6872655804728118
Epoch: 74 | Iteration number: [1430/4518] 31% | Training loss: 0.6872560187236413
Epoch: 74 | Iteration number: [1440/4518] 31% | Training loss: 0.6872534220003419
Epoch: 74 | Iteration number: [1450/4518] 32% | Training loss: 0.6872534985788937
Epoch: 74 | Iteration number: [1460/4518] 32% | Training loss: 0.687249640161044
Epoch: 74 | Iteration number: [1470/4518] 32% | Training loss: 0.6872406552843496
Epoch: 74 | Iteration number: [1480/4518] 32% | Training loss: 0.6872441116217021
Epoch: 74 | Iteration number: [1490/4518] 32% | Training loss: 0.687236827851942
Epoch: 74 | Iteration number: [1500/4518] 33% | Training loss: 0.6872348773479462
Epoch: 74 | Iteration number: [1510/4518] 33% | Training loss: 0.6872291458363564
Epoch: 74 | Iteration number: [1520/4518] 33% | Training loss: 0.6872241846824947
Epoch: 74 | Iteration number: [1530/4518] 33% | Training loss: 0.6872149115683985
Epoch: 74 | Iteration number: [1540/4518] 34% | Training loss: 0.6872143751615054
Epoch: 74 | Iteration number: [1550/4518] 34% | Training loss: 0.6872009099683454
Epoch: 74 | Iteration number: [1560/4518] 34% | Training loss: 0.6872029354939094
Epoch: 74 | Iteration number: [1570/4518] 34% | Training loss: 0.6872030229705155
Epoch: 74 | Iteration number: [1580/4518] 34% | Training loss: 0.6872032830609551
Epoch: 74 | Iteration number: [1590/4518] 35% | Training loss: 0.6872025129930028
Epoch: 74 | Iteration number: [1600/4518] 35% | Training loss: 0.687194487825036
Epoch: 74 | Iteration number: [1610/4518] 35% | Training loss: 0.6871874840363212
Epoch: 74 | Iteration number: [1620/4518] 35% | Training loss: 0.6871984327648892
Epoch: 74 | Iteration number: [1630/4518] 36% | Training loss: 0.6871992173004735
Epoch: 74 | Iteration number: [1640/4518] 36% | Training loss: 0.6871947424077406
Epoch: 74 | Iteration number: [1650/4518] 36% | Training loss: 0.6871900154966296
Epoch: 74 | Iteration number: [1660/4518] 36% | Training loss: 0.6871928171580096
Epoch: 74 | Iteration number: [1670/4518] 36% | Training loss: 0.6871945071363164
Epoch: 74 | Iteration number: [1680/4518] 37% | Training loss: 0.6871940227136726
Epoch: 74 | Iteration number: [1690/4518] 37% | Training loss: 0.6871904665549126
Epoch: 74 | Iteration number: [1700/4518] 37% | Training loss: 0.6871855647423688
Epoch: 74 | Iteration number: [1710/4518] 37% | Training loss: 0.6871802705770348
Epoch: 74 | Iteration number: [1720/4518] 38% | Training loss: 0.6871816100422726
Epoch: 74 | Iteration number: [1730/4518] 38% | Training loss: 0.6871712370070419
Epoch: 74 | Iteration number: [1740/4518] 38% | Training loss: 0.6871666772954765
Epoch: 74 | Iteration number: [1750/4518] 38% | Training loss: 0.6871653747899191
Epoch: 74 | Iteration number: [1760/4518] 38% | Training loss: 0.6871709381314841
Epoch: 74 | Iteration number: [1770/4518] 39% | Training loss: 0.6871674410030667
Epoch: 74 | Iteration number: [1780/4518] 39% | Training loss: 0.6871656095713712
Epoch: 74 | Iteration number: [1790/4518] 39% | Training loss: 0.6871646464869963
Epoch: 74 | Iteration number: [1800/4518] 39% | Training loss: 0.687162967092461
Epoch: 74 | Iteration number: [1810/4518] 40% | Training loss: 0.6871684370778542
Epoch: 74 | Iteration number: [1820/4518] 40% | Training loss: 0.6871587302003588
Epoch: 74 | Iteration number: [1830/4518] 40% | Training loss: 0.6871563688653415
Epoch: 74 | Iteration number: [1840/4518] 40% | Training loss: 0.6871545328070288
Epoch: 74 | Iteration number: [1850/4518] 40% | Training loss: 0.6871504566476152
Epoch: 74 | Iteration number: [1860/4518] 41% | Training loss: 0.6871523009833469
Epoch: 74 | Iteration number: [1870/4518] 41% | Training loss: 0.6871583020623355
Epoch: 74 | Iteration number: [1880/4518] 41% | Training loss: 0.6871602489910227
Epoch: 74 | Iteration number: [1890/4518] 41% | Training loss: 0.6871564878042413
Epoch: 74 | Iteration number: [1900/4518] 42% | Training loss: 0.687151263073871
Epoch: 74 | Iteration number: [1910/4518] 42% | Training loss: 0.6871483908585853
Epoch: 74 | Iteration number: [1920/4518] 42% | Training loss: 0.687144587840885
Epoch: 74 | Iteration number: [1930/4518] 42% | Training loss: 0.6871481557275347
Epoch: 74 | Iteration number: [1940/4518] 42% | Training loss: 0.6871469096424654
Epoch: 74 | Iteration number: [1950/4518] 43% | Training loss: 0.6871490091849596
Epoch: 74 | Iteration number: [1960/4518] 43% | Training loss: 0.687147600857579
Epoch: 74 | Iteration number: [1970/4518] 43% | Training loss: 0.687145624638814
Epoch: 74 | Iteration number: [1980/4518] 43% | Training loss: 0.6871469473296946
Epoch: 74 | Iteration number: [1990/4518] 44% | Training loss: 0.6871479548102049
Epoch: 74 | Iteration number: [2000/4518] 44% | Training loss: 0.6871474738419056
Epoch: 74 | Iteration number: [2010/4518] 44% | Training loss: 0.6871490370278335
Epoch: 74 | Iteration number: [2020/4518] 44% | Training loss: 0.6871518714593189
Epoch: 74 | Iteration number: [2030/4518] 44% | Training loss: 0.6871536158575801
Epoch: 74 | Iteration number: [2040/4518] 45% | Training loss: 0.6871562717007655
Epoch: 74 | Iteration number: [2050/4518] 45% | Training loss: 0.6871508333741165
Epoch: 74 | Iteration number: [2060/4518] 45% | Training loss: 0.6871558041248507
Epoch: 74 | Iteration number: [2070/4518] 45% | Training loss: 0.6871523106443709
Epoch: 74 | Iteration number: [2080/4518] 46% | Training loss: 0.6871489949237842
Epoch: 74 | Iteration number: [2090/4518] 46% | Training loss: 0.687151303673475
Epoch: 74 | Iteration number: [2100/4518] 46% | Training loss: 0.6871518861963636
Epoch: 74 | Iteration number: [2110/4518] 46% | Training loss: 0.6871522885363249
Epoch: 74 | Iteration number: [2120/4518] 46% | Training loss: 0.6871545975219528
Epoch: 74 | Iteration number: [2130/4518] 47% | Training loss: 0.68715309662998
Epoch: 74 | Iteration number: [2140/4518] 47% | Training loss: 0.6871469835254633
Epoch: 74 | Iteration number: [2150/4518] 47% | Training loss: 0.687137944143872
Epoch: 74 | Iteration number: [2160/4518] 47% | Training loss: 0.6871333431314539
Epoch: 74 | Iteration number: [2170/4518] 48% | Training loss: 0.6871324869619536
Epoch: 74 | Iteration number: [2180/4518] 48% | Training loss: 0.6871267582298419
Epoch: 74 | Iteration number: [2190/4518] 48% | Training loss: 0.6871277905490301
Epoch: 74 | Iteration number: [2200/4518] 48% | Training loss: 0.6871241300485351
Epoch: 74 | Iteration number: [2210/4518] 48% | Training loss: 0.6871249518513141
Epoch: 74 | Iteration number: [2220/4518] 49% | Training loss: 0.6871245278699978
Epoch: 74 | Iteration number: [2230/4518] 49% | Training loss: 0.6871297440721316
Epoch: 74 | Iteration number: [2240/4518] 49% | Training loss: 0.6871302158970918
Epoch: 74 | Iteration number: [2250/4518] 49% | Training loss: 0.6871303655306498
Epoch: 74 | Iteration number: [2260/4518] 50% | Training loss: 0.6871313311884889
Epoch: 74 | Iteration number: [2270/4518] 50% | Training loss: 0.6871286059528721
Epoch: 74 | Iteration number: [2280/4518] 50% | Training loss: 0.6871264652202004
Epoch: 74 | Iteration number: [2290/4518] 50% | Training loss: 0.6871251023492438
Epoch: 74 | Iteration number: [2300/4518] 50% | Training loss: 0.6871236767717029
Epoch: 74 | Iteration number: [2310/4518] 51% | Training loss: 0.6871152213641576
Epoch: 74 | Iteration number: [2320/4518] 51% | Training loss: 0.6871121701752317
Epoch: 74 | Iteration number: [2330/4518] 51% | Training loss: 0.6871117954602057
Epoch: 74 | Iteration number: [2340/4518] 51% | Training loss: 0.6871085635362527
Epoch: 74 | Iteration number: [2350/4518] 52% | Training loss: 0.6871068281823016
Epoch: 74 | Iteration number: [2360/4518] 52% | Training loss: 0.6871039065769163
Epoch: 74 | Iteration number: [2370/4518] 52% | Training loss: 0.687095509098552
Epoch: 74 | Iteration number: [2380/4518] 52% | Training loss: 0.6870925067853527
Epoch: 74 | Iteration number: [2390/4518] 52% | Training loss: 0.6870935527101222
Epoch: 74 | Iteration number: [2400/4518] 53% | Training loss: 0.6870894199113051
Epoch: 74 | Iteration number: [2410/4518] 53% | Training loss: 0.6870887202345979
Epoch: 74 | Iteration number: [2420/4518] 53% | Training loss: 0.6870844258749781
Epoch: 74 | Iteration number: [2430/4518] 53% | Training loss: 0.6870874322245641
Epoch: 74 | Iteration number: [2440/4518] 54% | Training loss: 0.6870788552721993
Epoch: 74 | Iteration number: [2450/4518] 54% | Training loss: 0.6870750511665733
Epoch: 74 | Iteration number: [2460/4518] 54% | Training loss: 0.68707718752264
Epoch: 74 | Iteration number: [2470/4518] 54% | Training loss: 0.6870725221238155
Epoch: 74 | Iteration number: [2480/4518] 54% | Training loss: 0.6870664006519702
Epoch: 74 | Iteration number: [2490/4518] 55% | Training loss: 0.6870628370338654
Epoch: 74 | Iteration number: [2500/4518] 55% | Training loss: 0.6870656636476516
Epoch: 74 | Iteration number: [2510/4518] 55% | Training loss: 0.6870630326261559
Epoch: 74 | Iteration number: [2520/4518] 55% | Training loss: 0.6870577845308515
Epoch: 74 | Iteration number: [2530/4518] 55% | Training loss: 0.6870560012316044
Epoch: 74 | Iteration number: [2540/4518] 56% | Training loss: 0.6870532574850743
Epoch: 74 | Iteration number: [2550/4518] 56% | Training loss: 0.6870457206987867
Epoch: 74 | Iteration number: [2560/4518] 56% | Training loss: 0.6870453025447205
Epoch: 74 | Iteration number: [2570/4518] 56% | Training loss: 0.6870404229553757
Epoch: 74 | Iteration number: [2580/4518] 57% | Training loss: 0.6870409570461096
Epoch: 74 | Iteration number: [2590/4518] 57% | Training loss: 0.6870377437488453
Epoch: 74 | Iteration number: [2600/4518] 57% | Training loss: 0.6870381097380932
Epoch: 74 | Iteration number: [2610/4518] 57% | Training loss: 0.6870342578467739
Epoch: 74 | Iteration number: [2620/4518] 57% | Training loss: 0.687034507562186
Epoch: 74 | Iteration number: [2630/4518] 58% | Training loss: 0.687034421479294
Epoch: 74 | Iteration number: [2640/4518] 58% | Training loss: 0.6870289413540652
Epoch: 74 | Iteration number: [2650/4518] 58% | Training loss: 0.6870222515205168
Epoch: 74 | Iteration number: [2660/4518] 58% | Training loss: 0.6870202034039605
Epoch: 74 | Iteration number: [2670/4518] 59% | Training loss: 0.6870174960027473
Epoch: 74 | Iteration number: [2680/4518] 59% | Training loss: 0.6870148536207071
Epoch: 74 | Iteration number: [2690/4518] 59% | Training loss: 0.6870131873951526
Epoch: 74 | Iteration number: [2700/4518] 59% | Training loss: 0.6870120501959766
Epoch: 74 | Iteration number: [2710/4518] 59% | Training loss: 0.6870102286558749
Epoch: 74 | Iteration number: [2720/4518] 60% | Training loss: 0.6870091258602984
Epoch: 74 | Iteration number: [2730/4518] 60% | Training loss: 0.687008075596212
Epoch: 74 | Iteration number: [2740/4518] 60% | Training loss: 0.6870073662622131
Epoch: 74 | Iteration number: [2750/4518] 60% | Training loss: 0.6870071738199754
Epoch: 74 | Iteration number: [2760/4518] 61% | Training loss: 0.6870057715238005
Epoch: 74 | Iteration number: [2770/4518] 61% | Training loss: 0.6870045090410253
Epoch: 74 | Iteration number: [2780/4518] 61% | Training loss: 0.6870072583286024
Epoch: 74 | Iteration number: [2790/4518] 61% | Training loss: 0.6870016465904892
Epoch: 74 | Iteration number: [2800/4518] 61% | Training loss: 0.6869978096655437
Epoch: 74 | Iteration number: [2810/4518] 62% | Training loss: 0.6869982624393342
Epoch: 74 | Iteration number: [2820/4518] 62% | Training loss: 0.6869957101049152
Epoch: 74 | Iteration number: [2830/4518] 62% | Training loss: 0.6869966708307974
Epoch: 74 | Iteration number: [2840/4518] 62% | Training loss: 0.6869959375178311
Epoch: 74 | Iteration number: [2850/4518] 63% | Training loss: 0.6869942255187453
Epoch: 74 | Iteration number: [2860/4518] 63% | Training loss: 0.68699731422471
Epoch: 74 | Iteration number: [2870/4518] 63% | Training loss: 0.6869948516531689
Epoch: 74 | Iteration number: [2880/4518] 63% | Training loss: 0.686995958433383
Epoch: 74 | Iteration number: [2890/4518] 63% | Training loss: 0.6869936999771422
Epoch: 74 | Iteration number: [2900/4518] 64% | Training loss: 0.6869912185956691
Epoch: 74 | Iteration number: [2910/4518] 64% | Training loss: 0.6869894902730725
Epoch: 74 | Iteration number: [2920/4518] 64% | Training loss: 0.6869901647510593
Epoch: 74 | Iteration number: [2930/4518] 64% | Training loss: 0.6869893521172195
Epoch: 74 | Iteration number: [2940/4518] 65% | Training loss: 0.686984418119703
Epoch: 74 | Iteration number: [2950/4518] 65% | Training loss: 0.6869853044162362
Epoch: 74 | Iteration number: [2960/4518] 65% | Training loss: 0.6869865818402252
Epoch: 74 | Iteration number: [2970/4518] 65% | Training loss: 0.686988441711323
Epoch: 74 | Iteration number: [2980/4518] 65% | Training loss: 0.6869896991740937
Epoch: 74 | Iteration number: [2990/4518] 66% | Training loss: 0.6869880476524199
Epoch: 74 | Iteration number: [3000/4518] 66% | Training loss: 0.6869905196825663
Epoch: 74 | Iteration number: [3010/4518] 66% | Training loss: 0.6869912578021965
Epoch: 74 | Iteration number: [3020/4518] 66% | Training loss: 0.6869920712038381
Epoch: 74 | Iteration number: [3030/4518] 67% | Training loss: 0.6869943414584245
Epoch: 74 | Iteration number: [3040/4518] 67% | Training loss: 0.6869926120889814
Epoch: 74 | Iteration number: [3050/4518] 67% | Training loss: 0.6869905001999902
Epoch: 74 | Iteration number: [3060/4518] 67% | Training loss: 0.6869889913820753
Epoch: 74 | Iteration number: [3070/4518] 67% | Training loss: 0.6869880205062779
Epoch: 74 | Iteration number: [3080/4518] 68% | Training loss: 0.6869884141273312
Epoch: 74 | Iteration number: [3090/4518] 68% | Training loss: 0.6869872292847309
Epoch: 74 | Iteration number: [3100/4518] 68% | Training loss: 0.6869891339348209
Epoch: 74 | Iteration number: [3110/4518] 68% | Training loss: 0.6869869326855209
Epoch: 74 | Iteration number: [3120/4518] 69% | Training loss: 0.6869896656045547
Epoch: 74 | Iteration number: [3130/4518] 69% | Training loss: 0.6869864415817748
Epoch: 74 | Iteration number: [3140/4518] 69% | Training loss: 0.6869897348675759
Epoch: 74 | Iteration number: [3150/4518] 69% | Training loss: 0.6869862914842273
Epoch: 74 | Iteration number: [3160/4518] 69% | Training loss: 0.6869829301969914
Epoch: 74 | Iteration number: [3170/4518] 70% | Training loss: 0.6869823087465123
Epoch: 74 | Iteration number: [3180/4518] 70% | Training loss: 0.686979205072301
Epoch: 74 | Iteration number: [3190/4518] 70% | Training loss: 0.6869814383946242
Epoch: 74 | Iteration number: [3200/4518] 70% | Training loss: 0.6869829217717052
Epoch: 74 | Iteration number: [3210/4518] 71% | Training loss: 0.6869838872802592
Epoch: 74 | Iteration number: [3220/4518] 71% | Training loss: 0.6869856853107488
Epoch: 74 | Iteration number: [3230/4518] 71% | Training loss: 0.6869773326089876
Epoch: 74 | Iteration number: [3240/4518] 71% | Training loss: 0.6869746072056853
Epoch: 74 | Iteration number: [3250/4518] 71% | Training loss: 0.6869761365743784
Epoch: 74 | Iteration number: [3260/4518] 72% | Training loss: 0.6869758250888871
Epoch: 74 | Iteration number: [3270/4518] 72% | Training loss: 0.6869772658800131
Epoch: 74 | Iteration number: [3280/4518] 72% | Training loss: 0.6869769286273456
Epoch: 74 | Iteration number: [3290/4518] 72% | Training loss: 0.6869802602699825
Epoch: 74 | Iteration number: [3300/4518] 73% | Training loss: 0.6869818792379264
Epoch: 74 | Iteration number: [3310/4518] 73% | Training loss: 0.6869838875586173
Epoch: 74 | Iteration number: [3320/4518] 73% | Training loss: 0.6869811636496739
Epoch: 74 | Iteration number: [3330/4518] 73% | Training loss: 0.6869841584751198
Epoch: 74 | Iteration number: [3340/4518] 73% | Training loss: 0.686981550215961
Epoch: 74 | Iteration number: [3350/4518] 74% | Training loss: 0.6869818041217861
Epoch: 74 | Iteration number: [3360/4518] 74% | Training loss: 0.6869818346131416
Epoch: 74 | Iteration number: [3370/4518] 74% | Training loss: 0.6869834665905474
Epoch: 74 | Iteration number: [3380/4518] 74% | Training loss: 0.6869825480957709
Epoch: 74 | Iteration number: [3390/4518] 75% | Training loss: 0.6869808082735293
Epoch: 74 | Iteration number: [3400/4518] 75% | Training loss: 0.6869785635085667
Epoch: 74 | Iteration number: [3410/4518] 75% | Training loss: 0.6869781314627516
Epoch: 74 | Iteration number: [3420/4518] 75% | Training loss: 0.6869777843268992
Epoch: 74 | Iteration number: [3430/4518] 75% | Training loss: 0.6869809440204075
Epoch: 74 | Iteration number: [3440/4518] 76% | Training loss: 0.6869794221118439
Epoch: 74 | Iteration number: [3450/4518] 76% | Training loss: 0.6869830169021219
Epoch: 74 | Iteration number: [3460/4518] 76% | Training loss: 0.686983385458158
Epoch: 74 | Iteration number: [3470/4518] 76% | Training loss: 0.6869766349579484
Epoch: 74 | Iteration number: [3480/4518] 77% | Training loss: 0.6869779885157772
Epoch: 74 | Iteration number: [3490/4518] 77% | Training loss: 0.6869758835153115
Epoch: 74 | Iteration number: [3500/4518] 77% | Training loss: 0.6869740254878998
Epoch: 74 | Iteration number: [3510/4518] 77% | Training loss: 0.686974461856391
Epoch: 74 | Iteration number: [3520/4518] 77% | Training loss: 0.6869749447500164
Epoch: 74 | Iteration number: [3530/4518] 78% | Training loss: 0.6869733041811935
Epoch: 74 | Iteration number: [3540/4518] 78% | Training loss: 0.6869774938808323
Epoch: 74 | Iteration number: [3550/4518] 78% | Training loss: 0.6869769740608377
Epoch: 74 | Iteration number: [3560/4518] 78% | Training loss: 0.6869747045669663
Epoch: 74 | Iteration number: [3570/4518] 79% | Training loss: 0.6869749616675016
Epoch: 74 | Iteration number: [3580/4518] 79% | Training loss: 0.6869736969970458
Epoch: 74 | Iteration number: [3590/4518] 79% | Training loss: 0.6869704919439172
Epoch: 74 | Iteration number: [3600/4518] 79% | Training loss: 0.6869723103443781
Epoch: 74 | Iteration number: [3610/4518] 79% | Training loss: 0.6869700490767936
Epoch: 74 | Iteration number: [3620/4518] 80% | Training loss: 0.6869678822176233
Epoch: 74 | Iteration number: [3630/4518] 80% | Training loss: 0.6869699468954207
Epoch: 74 | Iteration number: [3640/4518] 80% | Training loss: 0.6869694244239356
Epoch: 74 | Iteration number: [3650/4518] 80% | Training loss: 0.686969792042693
Epoch: 74 | Iteration number: [3660/4518] 81% | Training loss: 0.6869704004682479
Epoch: 74 | Iteration number: [3670/4518] 81% | Training loss: 0.6869685153545411
Epoch: 74 | Iteration number: [3680/4518] 81% | Training loss: 0.6869677073281745
Epoch: 74 | Iteration number: [3690/4518] 81% | Training loss: 0.6869683808104455
Epoch: 74 | Iteration number: [3700/4518] 81% | Training loss: 0.686966669881666
Epoch: 74 | Iteration number: [3710/4518] 82% | Training loss: 0.686962720309949
Epoch: 74 | Iteration number: [3720/4518] 82% | Training loss: 0.6869645899822635
Epoch: 74 | Iteration number: [3730/4518] 82% | Training loss: 0.6869636189042723
Epoch: 74 | Iteration number: [3740/4518] 82% | Training loss: 0.6869657981363847
Epoch: 74 | Iteration number: [3750/4518] 83% | Training loss: 0.6869632777055105
Epoch: 74 | Iteration number: [3760/4518] 83% | Training loss: 0.6869608541593907
Epoch: 74 | Iteration number: [3770/4518] 83% | Training loss: 0.6869562382249048
Epoch: 74 | Iteration number: [3780/4518] 83% | Training loss: 0.6869542219020702
Epoch: 74 | Iteration number: [3790/4518] 83% | Training loss: 0.6869515804627955
Epoch: 74 | Iteration number: [3800/4518] 84% | Training loss: 0.686951186515783
Epoch: 74 | Iteration number: [3810/4518] 84% | Training loss: 0.6869512292500243
Epoch: 74 | Iteration number: [3820/4518] 84% | Training loss: 0.6869534429143237
Epoch: 74 | Iteration number: [3830/4518] 84% | Training loss: 0.6869506864417004
Epoch: 74 | Iteration number: [3840/4518] 84% | Training loss: 0.6869532028523584
Epoch: 74 | Iteration number: [3850/4518] 85% | Training loss: 0.6869507219884303
Epoch: 74 | Iteration number: [3860/4518] 85% | Training loss: 0.6869492807999794
Epoch: 74 | Iteration number: [3870/4518] 85% | Training loss: 0.6869482455635564
Epoch: 74 | Iteration number: [3880/4518] 85% | Training loss: 0.686948344403321
Epoch: 74 | Iteration number: [3890/4518] 86% | Training loss: 0.6869486809236531
Epoch: 74 | Iteration number: [3900/4518] 86% | Training loss: 0.6869476739259867
Epoch: 74 | Iteration number: [3910/4518] 86% | Training loss: 0.6869462551210848
Epoch: 74 | Iteration number: [3920/4518] 86% | Training loss: 0.6869472535137011
Epoch: 74 | Iteration number: [3930/4518] 86% | Training loss: 0.6869441212133597
Epoch: 74 | Iteration number: [3940/4518] 87% | Training loss: 0.6869398901910346
Epoch: 74 | Iteration number: [3950/4518] 87% | Training loss: 0.6869427149657962
Epoch: 74 | Iteration number: [3960/4518] 87% | Training loss: 0.6869428226743082
Epoch: 74 | Iteration number: [3970/4518] 87% | Training loss: 0.686940973306483
Epoch: 74 | Iteration number: [3980/4518] 88% | Training loss: 0.6869402764280836
Epoch: 74 | Iteration number: [3990/4518] 88% | Training loss: 0.6869425780342934
Epoch: 74 | Iteration number: [4000/4518] 88% | Training loss: 0.6869436872005462
Epoch: 74 | Iteration number: [4010/4518] 88% | Training loss: 0.6869432083389111
Epoch: 74 | Iteration number: [4020/4518] 88% | Training loss: 0.6869412787962909
Epoch: 74 | Iteration number: [4030/4518] 89% | Training loss: 0.6869413203548261
Epoch: 74 | Iteration number: [4040/4518] 89% | Training loss: 0.6869435821429337
Epoch: 74 | Iteration number: [4050/4518] 89% | Training loss: 0.6869435754234409
Epoch: 74 | Iteration number: [4060/4518] 89% | Training loss: 0.6869421188320433
Epoch: 74 | Iteration number: [4070/4518] 90% | Training loss: 0.6869381543166514
Epoch: 74 | Iteration number: [4080/4518] 90% | Training loss: 0.6869361177817279
Epoch: 74 | Iteration number: [4090/4518] 90% | Training loss: 0.6869352881949222
Epoch: 74 | Iteration number: [4100/4518] 90% | Training loss: 0.686932707283555
Epoch: 74 | Iteration number: [4110/4518] 90% | Training loss: 0.6869354460071183
Epoch: 74 | Iteration number: [4120/4518] 91% | Training loss: 0.6869378991497374
Epoch: 74 | Iteration number: [4130/4518] 91% | Training loss: 0.6869408124006978
Epoch: 74 | Iteration number: [4140/4518] 91% | Training loss: 0.6869369825159294
Epoch: 74 | Iteration number: [4150/4518] 91% | Training loss: 0.6869390501889838
Epoch: 74 | Iteration number: [4160/4518] 92% | Training loss: 0.6869363609128274
Epoch: 74 | Iteration number: [4170/4518] 92% | Training loss: 0.6869331210637264
Epoch: 74 | Iteration number: [4180/4518] 92% | Training loss: 0.6869317029651842
Epoch: 74 | Iteration number: [4190/4518] 92% | Training loss: 0.6869314998317163
Epoch: 74 | Iteration number: [4200/4518] 92% | Training loss: 0.6869349676512536
Epoch: 74 | Iteration number: [4210/4518] 93% | Training loss: 0.686935081518744
Epoch: 74 | Iteration number: [4220/4518] 93% | Training loss: 0.686935032727594
Epoch: 74 | Iteration number: [4230/4518] 93% | Training loss: 0.6869377254453393
Epoch: 74 | Iteration number: [4240/4518] 93% | Training loss: 0.6869367371471423
Epoch: 74 | Iteration number: [4250/4518] 94% | Training loss: 0.686934561771505
Epoch: 74 | Iteration number: [4260/4518] 94% | Training loss: 0.6869329510720124
Epoch: 74 | Iteration number: [4270/4518] 94% | Training loss: 0.6869311372066829
Epoch: 74 | Iteration number: [4280/4518] 94% | Training loss: 0.6869309368534623
Epoch: 74 | Iteration number: [4290/4518] 94% | Training loss: 0.6869299045253745
Epoch: 74 | Iteration number: [4300/4518] 95% | Training loss: 0.6869293572597726
Epoch: 74 | Iteration number: [4310/4518] 95% | Training loss: 0.6869290452960473
Epoch: 74 | Iteration number: [4320/4518] 95% | Training loss: 0.6869290879203214
Epoch: 74 | Iteration number: [4330/4518] 95% | Training loss: 0.6869265969988931
Epoch: 74 | Iteration number: [4340/4518] 96% | Training loss: 0.6869283402158368
Epoch: 74 | Iteration number: [4350/4518] 96% | Training loss: 0.6869293302092059
Epoch: 74 | Iteration number: [4360/4518] 96% | Training loss: 0.6869300368182156
Epoch: 74 | Iteration number: [4370/4518] 96% | Training loss: 0.6869272294251815
Epoch: 74 | Iteration number: [4380/4518] 96% | Training loss: 0.6869271100247831
Epoch: 74 | Iteration number: [4390/4518] 97% | Training loss: 0.6869259635245338
Epoch: 74 | Iteration number: [4400/4518] 97% | Training loss: 0.6869248089871623
Epoch: 74 | Iteration number: [4410/4518] 97% | Training loss: 0.6869221196423312
Epoch: 74 | Iteration number: [4420/4518] 97% | Training loss: 0.6869239990392961
Epoch: 74 | Iteration number: [4430/4518] 98% | Training loss: 0.6869244014705546
Epoch: 74 | Iteration number: [4440/4518] 98% | Training loss: 0.6869256182028367
Epoch: 74 | Iteration number: [4450/4518] 98% | Training loss: 0.6869254676143774
Epoch: 74 | Iteration number: [4460/4518] 98% | Training loss: 0.6869234825730859
Epoch: 74 | Iteration number: [4470/4518] 98% | Training loss: 0.6869240851876987
Epoch: 74 | Iteration number: [4480/4518] 99% | Training loss: 0.6869247778717961
Epoch: 74 | Iteration number: [4490/4518] 99% | Training loss: 0.6869232785330053
Epoch: 74 | Iteration number: [4500/4518] 99% | Training loss: 0.6869238595962525
Epoch: 74 | Iteration number: [4510/4518] 99% | Training loss: 0.6869215531121865

 End of epoch: 74 | Train Loss: 0.6867664143304584 | Training Time: 632 

 End of epoch: 74 | Eval Loss: 0.6896325507942511 | Evaluating Time: 17 
Epoch: 75 | Iteration number: [10/4518] 0% | Training loss: 0.7561413168907165
Epoch: 75 | Iteration number: [20/4518] 0% | Training loss: 0.7218028396368027
Epoch: 75 | Iteration number: [30/4518] 0% | Training loss: 0.7102432211240133
Epoch: 75 | Iteration number: [40/4518] 0% | Training loss: 0.7044608935713768
Epoch: 75 | Iteration number: [50/4518] 1% | Training loss: 0.7011475133895874
Epoch: 75 | Iteration number: [60/4518] 1% | Training loss: 0.6989394237597784
Epoch: 75 | Iteration number: [70/4518] 1% | Training loss: 0.6973388007708958
Epoch: 75 | Iteration number: [80/4518] 1% | Training loss: 0.6962146058678627
Epoch: 75 | Iteration number: [90/4518] 1% | Training loss: 0.6953229427337646
Epoch: 75 | Iteration number: [100/4518] 2% | Training loss: 0.6945502334833145
Epoch: 75 | Iteration number: [110/4518] 2% | Training loss: 0.6937540075995705
Epoch: 75 | Iteration number: [120/4518] 2% | Training loss: 0.6931391770641009
Epoch: 75 | Iteration number: [130/4518] 2% | Training loss: 0.6926685713804686
Epoch: 75 | Iteration number: [140/4518] 3% | Training loss: 0.692228986961501
Epoch: 75 | Iteration number: [150/4518] 3% | Training loss: 0.6918836041291555
Epoch: 75 | Iteration number: [160/4518] 3% | Training loss: 0.6915927968919278
Epoch: 75 | Iteration number: [170/4518] 3% | Training loss: 0.6913497556658352
Epoch: 75 | Iteration number: [180/4518] 3% | Training loss: 0.6911042243242264
Epoch: 75 | Iteration number: [190/4518] 4% | Training loss: 0.6908123675145601
Epoch: 75 | Iteration number: [200/4518] 4% | Training loss: 0.6906540378928184
Epoch: 75 | Iteration number: [210/4518] 4% | Training loss: 0.690499480565389
Epoch: 75 | Iteration number: [220/4518] 4% | Training loss: 0.6902866092595187
Epoch: 75 | Iteration number: [230/4518] 5% | Training loss: 0.6901610102342522
Epoch: 75 | Iteration number: [240/4518] 5% | Training loss: 0.6899898859361807
Epoch: 75 | Iteration number: [250/4518] 5% | Training loss: 0.6898313059806823
Epoch: 75 | Iteration number: [260/4518] 5% | Training loss: 0.6897465061682921
Epoch: 75 | Iteration number: [270/4518] 5% | Training loss: 0.6896793255099544
Epoch: 75 | Iteration number: [280/4518] 6% | Training loss: 0.6895357308643205
Epoch: 75 | Iteration number: [290/4518] 6% | Training loss: 0.6894407447042137
Epoch: 75 | Iteration number: [300/4518] 6% | Training loss: 0.6893138734499613
Epoch: 75 | Iteration number: [310/4518] 6% | Training loss: 0.6892334959199352
Epoch: 75 | Iteration number: [320/4518] 7% | Training loss: 0.6891238087788224
Epoch: 75 | Iteration number: [330/4518] 7% | Training loss: 0.6891140390526165
Epoch: 75 | Iteration number: [340/4518] 7% | Training loss: 0.6890213559655582
Epoch: 75 | Iteration number: [350/4518] 7% | Training loss: 0.6889420933382852
Epoch: 75 | Iteration number: [360/4518] 7% | Training loss: 0.6888795905643039
Epoch: 75 | Iteration number: [370/4518] 8% | Training loss: 0.6888106824578466
Epoch: 75 | Iteration number: [380/4518] 8% | Training loss: 0.6887430617683812
Epoch: 75 | Iteration number: [390/4518] 8% | Training loss: 0.6886359881132077
Epoch: 75 | Iteration number: [400/4518] 8% | Training loss: 0.6885972593724727
Epoch: 75 | Iteration number: [410/4518] 9% | Training loss: 0.6885741075364554
Epoch: 75 | Iteration number: [420/4518] 9% | Training loss: 0.6885304524784996
Epoch: 75 | Iteration number: [430/4518] 9% | Training loss: 0.6885015511235525
Epoch: 75 | Iteration number: [440/4518] 9% | Training loss: 0.6884725329550829
Epoch: 75 | Iteration number: [450/4518] 9% | Training loss: 0.6884190323617724
Epoch: 75 | Iteration number: [460/4518] 10% | Training loss: 0.6883890365776808
Epoch: 75 | Iteration number: [470/4518] 10% | Training loss: 0.6883428015607469
Epoch: 75 | Iteration number: [480/4518] 10% | Training loss: 0.6883115546156963
Epoch: 75 | Iteration number: [490/4518] 10% | Training loss: 0.6882784952922744
Epoch: 75 | Iteration number: [500/4518] 11% | Training loss: 0.6882465418577194
Epoch: 75 | Iteration number: [510/4518] 11% | Training loss: 0.6882268195058785
Epoch: 75 | Iteration number: [520/4518] 11% | Training loss: 0.6882079217296381
Epoch: 75 | Iteration number: [530/4518] 11% | Training loss: 0.6881846621351422
Epoch: 75 | Iteration number: [540/4518] 11% | Training loss: 0.6881407098637686
Epoch: 75 | Iteration number: [550/4518] 12% | Training loss: 0.6880859773809259
Epoch: 75 | Iteration number: [560/4518] 12% | Training loss: 0.6880833709878581
Epoch: 75 | Iteration number: [570/4518] 12% | Training loss: 0.6880753064364717
Epoch: 75 | Iteration number: [580/4518] 12% | Training loss: 0.688052105492559
Epoch: 75 | Iteration number: [590/4518] 13% | Training loss: 0.6879974063170158
Epoch: 75 | Iteration number: [600/4518] 13% | Training loss: 0.6879821808139484
Epoch: 75 | Iteration number: [610/4518] 13% | Training loss: 0.6879627906885304
Epoch: 75 | Iteration number: [620/4518] 13% | Training loss: 0.6879405295656573
Epoch: 75 | Iteration number: [630/4518] 13% | Training loss: 0.6879160478001549
Epoch: 75 | Iteration number: [640/4518] 14% | Training loss: 0.6878734108060598
Epoch: 75 | Iteration number: [650/4518] 14% | Training loss: 0.6878461192204403
Epoch: 75 | Iteration number: [660/4518] 14% | Training loss: 0.6878224742231946
Epoch: 75 | Iteration number: [670/4518] 14% | Training loss: 0.6878159990061575
Epoch: 75 | Iteration number: [680/4518] 15% | Training loss: 0.6878130979397717
Epoch: 75 | Iteration number: [690/4518] 15% | Training loss: 0.6878039271071337
Epoch: 75 | Iteration number: [700/4518] 15% | Training loss: 0.6877900310925075
Epoch: 75 | Iteration number: [710/4518] 15% | Training loss: 0.6877719458559869
Epoch: 75 | Iteration number: [720/4518] 15% | Training loss: 0.6877590202622943
Epoch: 75 | Iteration number: [730/4518] 16% | Training loss: 0.6877458291511013
Epoch: 75 | Iteration number: [740/4518] 16% | Training loss: 0.687728961416193
Epoch: 75 | Iteration number: [750/4518] 16% | Training loss: 0.6877207434972127
Epoch: 75 | Iteration number: [760/4518] 16% | Training loss: 0.6876986305964621
Epoch: 75 | Iteration number: [770/4518] 17% | Training loss: 0.6876897111341551
Epoch: 75 | Iteration number: [780/4518] 17% | Training loss: 0.6876909879537729
Epoch: 75 | Iteration number: [790/4518] 17% | Training loss: 0.6876718145382555
Epoch: 75 | Iteration number: [800/4518] 17% | Training loss: 0.6876661244034767
Epoch: 75 | Iteration number: [810/4518] 17% | Training loss: 0.6876612365245819
Epoch: 75 | Iteration number: [820/4518] 18% | Training loss: 0.6876519026552759
Epoch: 75 | Iteration number: [830/4518] 18% | Training loss: 0.6876466977309031
Epoch: 75 | Iteration number: [840/4518] 18% | Training loss: 0.687636209101904
Epoch: 75 | Iteration number: [850/4518] 18% | Training loss: 0.6876225693786846
Epoch: 75 | Iteration number: [860/4518] 19% | Training loss: 0.6876117085994676
Epoch: 75 | Iteration number: [870/4518] 19% | Training loss: 0.6875955561796824
Epoch: 75 | Iteration number: [880/4518] 19% | Training loss: 0.6875952793793245
Epoch: 75 | Iteration number: [890/4518] 19% | Training loss: 0.6875913193386592
Epoch: 75 | Iteration number: [900/4518] 19% | Training loss: 0.687577614320649
Epoch: 75 | Iteration number: [910/4518] 20% | Training loss: 0.6875644729032622
Epoch: 75 | Iteration number: [920/4518] 20% | Training loss: 0.6875556211108746
Epoch: 75 | Iteration number: [930/4518] 20% | Training loss: 0.6875356132625252
Epoch: 75 | Iteration number: [940/4518] 20% | Training loss: 0.6875377183264875
Epoch: 75 | Iteration number: [950/4518] 21% | Training loss: 0.6875224068290309
Epoch: 75 | Iteration number: [960/4518] 21% | Training loss: 0.687514389368395
Epoch: 75 | Iteration number: [970/4518] 21% | Training loss: 0.6875189867830768
Epoch: 75 | Iteration number: [980/4518] 21% | Training loss: 0.6875219138301149
Epoch: 75 | Iteration number: [990/4518] 21% | Training loss: 0.687510160544906
Epoch: 75 | Iteration number: [1000/4518] 22% | Training loss: 0.687508908689022
Epoch: 75 | Iteration number: [1010/4518] 22% | Training loss: 0.6875003838303065
Epoch: 75 | Iteration number: [1020/4518] 22% | Training loss: 0.6874933694507561
Epoch: 75 | Iteration number: [1030/4518] 22% | Training loss: 0.6874881777948546
Epoch: 75 | Iteration number: [1040/4518] 23% | Training loss: 0.6874930604146077
Epoch: 75 | Iteration number: [1050/4518] 23% | Training loss: 0.687475129876818
Epoch: 75 | Iteration number: [1060/4518] 23% | Training loss: 0.6874607708094255
Epoch: 75 | Iteration number: [1070/4518] 23% | Training loss: 0.6874517550535291
Epoch: 75 | Iteration number: [1080/4518] 23% | Training loss: 0.6874584359151346
Epoch: 75 | Iteration number: [1090/4518] 24% | Training loss: 0.687460677886228
Epoch: 75 | Iteration number: [1100/4518] 24% | Training loss: 0.6874492232907902
Epoch: 75 | Iteration number: [1110/4518] 24% | Training loss: 0.6874398414616112
Epoch: 75 | Iteration number: [1120/4518] 24% | Training loss: 0.6874272211321762
Epoch: 75 | Iteration number: [1130/4518] 25% | Training loss: 0.6874227580770982
Epoch: 75 | Iteration number: [1140/4518] 25% | Training loss: 0.6874298974610211
Epoch: 75 | Iteration number: [1150/4518] 25% | Training loss: 0.6874271736456
Epoch: 75 | Iteration number: [1160/4518] 25% | Training loss: 0.6874152019619941
Epoch: 75 | Iteration number: [1170/4518] 25% | Training loss: 0.6874018135233823
Epoch: 75 | Iteration number: [1180/4518] 26% | Training loss: 0.6873903106834929
Epoch: 75 | Iteration number: [1190/4518] 26% | Training loss: 0.6873835897746207
Epoch: 75 | Iteration number: [1200/4518] 26% | Training loss: 0.6873872547845046
Epoch: 75 | Iteration number: [1210/4518] 26% | Training loss: 0.6873874270226344
Epoch: 75 | Iteration number: [1220/4518] 27% | Training loss: 0.6873842611664631
Epoch: 75 | Iteration number: [1230/4518] 27% | Training loss: 0.6873676912571357
Epoch: 75 | Iteration number: [1240/4518] 27% | Training loss: 0.6873574272278816
Epoch: 75 | Iteration number: [1250/4518] 27% | Training loss: 0.6873593422412873
Epoch: 75 | Iteration number: [1260/4518] 27% | Training loss: 0.6873542702860302
Epoch: 75 | Iteration number: [1270/4518] 28% | Training loss: 0.6873541436326785
Epoch: 75 | Iteration number: [1280/4518] 28% | Training loss: 0.687340454151854
Epoch: 75 | Iteration number: [1290/4518] 28% | Training loss: 0.6873284954895345
Epoch: 75 | Iteration number: [1300/4518] 28% | Training loss: 0.6873303296015812
Epoch: 75 | Iteration number: [1310/4518] 28% | Training loss: 0.6873284776702182
Epoch: 75 | Iteration number: [1320/4518] 29% | Training loss: 0.6873186925595457
Epoch: 75 | Iteration number: [1330/4518] 29% | Training loss: 0.6873208098841789
Epoch: 75 | Iteration number: [1340/4518] 29% | Training loss: 0.687317374660008
Epoch: 75 | Iteration number: [1350/4518] 29% | Training loss: 0.6873253645720305
Epoch: 75 | Iteration number: [1360/4518] 30% | Training loss: 0.6873225118307507
Epoch: 75 | Iteration number: [1370/4518] 30% | Training loss: 0.687317557186976
Epoch: 75 | Iteration number: [1380/4518] 30% | Training loss: 0.6873217942922012
Epoch: 75 | Iteration number: [1390/4518] 30% | Training loss: 0.6873211428415861
Epoch: 75 | Iteration number: [1400/4518] 30% | Training loss: 0.6873143920302391
Epoch: 75 | Iteration number: [1410/4518] 31% | Training loss: 0.6873130363775484
Epoch: 75 | Iteration number: [1420/4518] 31% | Training loss: 0.6873061283373497
Epoch: 75 | Iteration number: [1430/4518] 31% | Training loss: 0.6873124667814562
Epoch: 75 | Iteration number: [1440/4518] 31% | Training loss: 0.6873089370628198
Epoch: 75 | Iteration number: [1450/4518] 32% | Training loss: 0.6873070009412436
Epoch: 75 | Iteration number: [1460/4518] 32% | Training loss: 0.6873051659293371
Epoch: 75 | Iteration number: [1470/4518] 32% | Training loss: 0.6872981160676398
Epoch: 75 | Iteration number: [1480/4518] 32% | Training loss: 0.6872922776921375
Epoch: 75 | Iteration number: [1490/4518] 32% | Training loss: 0.6872918701011863
Epoch: 75 | Iteration number: [1500/4518] 33% | Training loss: 0.6872942215998967
Epoch: 75 | Iteration number: [1510/4518] 33% | Training loss: 0.6872855878428907
Epoch: 75 | Iteration number: [1520/4518] 33% | Training loss: 0.6872882590482109
Epoch: 75 | Iteration number: [1530/4518] 33% | Training loss: 0.6872820159578635
Epoch: 75 | Iteration number: [1540/4518] 34% | Training loss: 0.6872810378477171
Epoch: 75 | Iteration number: [1550/4518] 34% | Training loss: 0.6872739878392988
Epoch: 75 | Iteration number: [1560/4518] 34% | Training loss: 0.6872642538868464
Epoch: 75 | Iteration number: [1570/4518] 34% | Training loss: 0.6872570424702517
Epoch: 75 | Iteration number: [1580/4518] 34% | Training loss: 0.6872599312399007
Epoch: 75 | Iteration number: [1590/4518] 35% | Training loss: 0.6872516099386995
Epoch: 75 | Iteration number: [1600/4518] 35% | Training loss: 0.6872387227416038
Epoch: 75 | Iteration number: [1610/4518] 35% | Training loss: 0.6872364750930241
Epoch: 75 | Iteration number: [1620/4518] 35% | Training loss: 0.6872342491223489
Epoch: 75 | Iteration number: [1630/4518] 36% | Training loss: 0.6872336408843293
Epoch: 75 | Iteration number: [1640/4518] 36% | Training loss: 0.6872235394832564
Epoch: 75 | Iteration number: [1650/4518] 36% | Training loss: 0.6872199580524907
Epoch: 75 | Iteration number: [1660/4518] 36% | Training loss: 0.6872167123728488
Epoch: 75 | Iteration number: [1670/4518] 36% | Training loss: 0.6872141820584943
Epoch: 75 | Iteration number: [1680/4518] 37% | Training loss: 0.6872050657868385
Epoch: 75 | Iteration number: [1690/4518] 37% | Training loss: 0.6871998357702289
Epoch: 75 | Iteration number: [1700/4518] 37% | Training loss: 0.6871958221407498
Epoch: 75 | Iteration number: [1710/4518] 37% | Training loss: 0.6871963231187118
Epoch: 75 | Iteration number: [1720/4518] 38% | Training loss: 0.6871965168520462
Epoch: 75 | Iteration number: [1730/4518] 38% | Training loss: 0.687190290889299
Epoch: 75 | Iteration number: [1740/4518] 38% | Training loss: 0.6871887927425319
Epoch: 75 | Iteration number: [1750/4518] 38% | Training loss: 0.6871904626573835
Epoch: 75 | Iteration number: [1760/4518] 38% | Training loss: 0.6871899030086669
Epoch: 75 | Iteration number: [1770/4518] 39% | Training loss: 0.6871878122542537
Epoch: 75 | Iteration number: [1780/4518] 39% | Training loss: 0.6871805216489213
Epoch: 75 | Iteration number: [1790/4518] 39% | Training loss: 0.6871713701906151
Epoch: 75 | Iteration number: [1800/4518] 39% | Training loss: 0.6871730516354243
Epoch: 75 | Iteration number: [1810/4518] 40% | Training loss: 0.6871645116345
Epoch: 75 | Iteration number: [1820/4518] 40% | Training loss: 0.6871601352979849
Epoch: 75 | Iteration number: [1830/4518] 40% | Training loss: 0.6871606229432945
Epoch: 75 | Iteration number: [1840/4518] 40% | Training loss: 0.6871568724836992
Epoch: 75 | Iteration number: [1850/4518] 40% | Training loss: 0.6871596094079919
Epoch: 75 | Iteration number: [1860/4518] 41% | Training loss: 0.6871611302898776
Epoch: 75 | Iteration number: [1870/4518] 41% | Training loss: 0.6871581628679592
Epoch: 75 | Iteration number: [1880/4518] 41% | Training loss: 0.6871532148186197
Epoch: 75 | Iteration number: [1890/4518] 41% | Training loss: 0.6871522129212738
Epoch: 75 | Iteration number: [1900/4518] 42% | Training loss: 0.6871494992469487
Epoch: 75 | Iteration number: [1910/4518] 42% | Training loss: 0.6871458616556297
Epoch: 75 | Iteration number: [1920/4518] 42% | Training loss: 0.6871402795736988
Epoch: 75 | Iteration number: [1930/4518] 42% | Training loss: 0.6871453469590202
Epoch: 75 | Iteration number: [1940/4518] 42% | Training loss: 0.6871340830608742
Epoch: 75 | Iteration number: [1950/4518] 43% | Training loss: 0.6871349795353718
Epoch: 75 | Iteration number: [1960/4518] 43% | Training loss: 0.6871327117997773
Epoch: 75 | Iteration number: [1970/4518] 43% | Training loss: 0.6871276624916773
Epoch: 75 | Iteration number: [1980/4518] 43% | Training loss: 0.6871233121915297
Epoch: 75 | Iteration number: [1990/4518] 44% | Training loss: 0.687117177577474
Epoch: 75 | Iteration number: [2000/4518] 44% | Training loss: 0.6871126670241355
Epoch: 75 | Iteration number: [2010/4518] 44% | Training loss: 0.6871113074359609
Epoch: 75 | Iteration number: [2020/4518] 44% | Training loss: 0.6871145790756339
Epoch: 75 | Iteration number: [2030/4518] 44% | Training loss: 0.687118522668707
Epoch: 75 | Iteration number: [2040/4518] 45% | Training loss: 0.6871168428191952
Epoch: 75 | Iteration number: [2050/4518] 45% | Training loss: 0.6871167672843468
Epoch: 75 | Iteration number: [2060/4518] 45% | Training loss: 0.6871164606034177
Epoch: 75 | Iteration number: [2070/4518] 45% | Training loss: 0.6871205601715236
Epoch: 75 | Iteration number: [2080/4518] 46% | Training loss: 0.6871153555523891
Epoch: 75 | Iteration number: [2090/4518] 46% | Training loss: 0.6871125132843638
Epoch: 75 | Iteration number: [2100/4518] 46% | Training loss: 0.6871096530982427
Epoch: 75 | Iteration number: [2110/4518] 46% | Training loss: 0.6871071564360253
Epoch: 75 | Iteration number: [2120/4518] 46% | Training loss: 0.6871085558016345
Epoch: 75 | Iteration number: [2130/4518] 47% | Training loss: 0.6870990971724192
Epoch: 75 | Iteration number: [2140/4518] 47% | Training loss: 0.6871011339336912
Epoch: 75 | Iteration number: [2150/4518] 47% | Training loss: 0.687099006203718
Epoch: 75 | Iteration number: [2160/4518] 47% | Training loss: 0.6870970066498827
Epoch: 75 | Iteration number: [2170/4518] 48% | Training loss: 0.6870949103535595
Epoch: 75 | Iteration number: [2180/4518] 48% | Training loss: 0.6871011613432421
Epoch: 75 | Iteration number: [2190/4518] 48% | Training loss: 0.6870990589056929
Epoch: 75 | Iteration number: [2200/4518] 48% | Training loss: 0.6871034883369099
Epoch: 75 | Iteration number: [2210/4518] 48% | Training loss: 0.6871032475885762
Epoch: 75 | Iteration number: [2220/4518] 49% | Training loss: 0.6870946456183185
Epoch: 75 | Iteration number: [2230/4518] 49% | Training loss: 0.687095041446087
Epoch: 75 | Iteration number: [2240/4518] 49% | Training loss: 0.6870944736259325
Epoch: 75 | Iteration number: [2250/4518] 49% | Training loss: 0.6870913256804149
Epoch: 75 | Iteration number: [2260/4518] 50% | Training loss: 0.6870857074197415
Epoch: 75 | Iteration number: [2270/4518] 50% | Training loss: 0.6870804630712265
Epoch: 75 | Iteration number: [2280/4518] 50% | Training loss: 0.6870781294086523
Epoch: 75 | Iteration number: [2290/4518] 50% | Training loss: 0.6870787186914136
Epoch: 75 | Iteration number: [2300/4518] 50% | Training loss: 0.6870828736865002
Epoch: 75 | Iteration number: [2310/4518] 51% | Training loss: 0.687078106171125
Epoch: 75 | Iteration number: [2320/4518] 51% | Training loss: 0.6870788068093102
Epoch: 75 | Iteration number: [2330/4518] 51% | Training loss: 0.6870732449410811
Epoch: 75 | Iteration number: [2340/4518] 51% | Training loss: 0.6870758410447683
Epoch: 75 | Iteration number: [2350/4518] 52% | Training loss: 0.6870748495801966
Epoch: 75 | Iteration number: [2360/4518] 52% | Training loss: 0.6870753347873688
Epoch: 75 | Iteration number: [2370/4518] 52% | Training loss: 0.6870725564061337
Epoch: 75 | Iteration number: [2380/4518] 52% | Training loss: 0.687068823856466
Epoch: 75 | Iteration number: [2390/4518] 52% | Training loss: 0.6870695868795387
Epoch: 75 | Iteration number: [2400/4518] 53% | Training loss: 0.6870630527287722
Epoch: 75 | Iteration number: [2410/4518] 53% | Training loss: 0.6870629292306069
Epoch: 75 | Iteration number: [2420/4518] 53% | Training loss: 0.6870645423812315
Epoch: 75 | Iteration number: [2430/4518] 53% | Training loss: 0.6870617752212556
Epoch: 75 | Iteration number: [2440/4518] 54% | Training loss: 0.687060344805483
Epoch: 75 | Iteration number: [2450/4518] 54% | Training loss: 0.6870588840513814
Epoch: 75 | Iteration number: [2460/4518] 54% | Training loss: 0.6870576199961872
Epoch: 75 | Iteration number: [2470/4518] 54% | Training loss: 0.6870541562194283
Epoch: 75 | Iteration number: [2480/4518] 54% | Training loss: 0.6870472838080699
Epoch: 75 | Iteration number: [2490/4518] 55% | Training loss: 0.6870475303935238
Epoch: 75 | Iteration number: [2500/4518] 55% | Training loss: 0.6870447598695755
Epoch: 75 | Iteration number: [2510/4518] 55% | Training loss: 0.6870456168613586
Epoch: 75 | Iteration number: [2520/4518] 55% | Training loss: 0.687043924842562
Epoch: 75 | Iteration number: [2530/4518] 55% | Training loss: 0.6870357535573334
Epoch: 75 | Iteration number: [2540/4518] 56% | Training loss: 0.6870375813696328
Epoch: 75 | Iteration number: [2550/4518] 56% | Training loss: 0.6870429932136162
Epoch: 75 | Iteration number: [2560/4518] 56% | Training loss: 0.6870370285352692
Epoch: 75 | Iteration number: [2570/4518] 56% | Training loss: 0.6870339516535807
Epoch: 75 | Iteration number: [2580/4518] 57% | Training loss: 0.6870345823062483
Epoch: 75 | Iteration number: [2590/4518] 57% | Training loss: 0.6870321722104282
Epoch: 75 | Iteration number: [2600/4518] 57% | Training loss: 0.6870319885703233
Epoch: 75 | Iteration number: [2610/4518] 57% | Training loss: 0.6870303438997817
Epoch: 75 | Iteration number: [2620/4518] 57% | Training loss: 0.6870317142428333
Epoch: 75 | Iteration number: [2630/4518] 58% | Training loss: 0.6870341834913188
Epoch: 75 | Iteration number: [2640/4518] 58% | Training loss: 0.6870358874400456
Epoch: 75 | Iteration number: [2650/4518] 58% | Training loss: 0.687030000371753
Epoch: 75 | Iteration number: [2660/4518] 58% | Training loss: 0.6870313897840958
Epoch: 75 | Iteration number: [2670/4518] 59% | Training loss: 0.6870263716031549
Epoch: 75 | Iteration number: [2680/4518] 59% | Training loss: 0.6870221566353272
Epoch: 75 | Iteration number: [2690/4518] 59% | Training loss: 0.6870187470460913
Epoch: 75 | Iteration number: [2700/4518] 59% | Training loss: 0.6870192752281825
Epoch: 75 | Iteration number: [2710/4518] 59% | Training loss: 0.6870189368284937
Epoch: 75 | Iteration number: [2720/4518] 60% | Training loss: 0.6870139648809153
Epoch: 75 | Iteration number: [2730/4518] 60% | Training loss: 0.6870140440516419
Epoch: 75 | Iteration number: [2740/4518] 60% | Training loss: 0.6870139858148394
Epoch: 75 | Iteration number: [2750/4518] 60% | Training loss: 0.6870095717906952
Epoch: 75 | Iteration number: [2760/4518] 61% | Training loss: 0.6870103965202967
Epoch: 75 | Iteration number: [2770/4518] 61% | Training loss: 0.6870080434243171
Epoch: 75 | Iteration number: [2780/4518] 61% | Training loss: 0.6870084675095922
Epoch: 75 | Iteration number: [2790/4518] 61% | Training loss: 0.6870098645969104
Epoch: 75 | Iteration number: [2800/4518] 61% | Training loss: 0.6870105131396226
Epoch: 75 | Iteration number: [2810/4518] 62% | Training loss: 0.6870124276634637
Epoch: 75 | Iteration number: [2820/4518] 62% | Training loss: 0.6870104894359061
Epoch: 75 | Iteration number: [2830/4518] 62% | Training loss: 0.6870112160490596
Epoch: 75 | Iteration number: [2840/4518] 62% | Training loss: 0.6870093976108121
Epoch: 75 | Iteration number: [2850/4518] 63% | Training loss: 0.6870095435987439
Epoch: 75 | Iteration number: [2860/4518] 63% | Training loss: 0.6870095201722392
Epoch: 75 | Iteration number: [2870/4518] 63% | Training loss: 0.6870075255320878
Epoch: 75 | Iteration number: [2880/4518] 63% | Training loss: 0.6870078621018264
Epoch: 75 | Iteration number: [2890/4518] 63% | Training loss: 0.6870104639381686
Epoch: 75 | Iteration number: [2900/4518] 64% | Training loss: 0.6870101965706924
Epoch: 75 | Iteration number: [2910/4518] 64% | Training loss: 0.6870100296035255
Epoch: 75 | Iteration number: [2920/4518] 64% | Training loss: 0.6870124974887665
Epoch: 75 | Iteration number: [2930/4518] 64% | Training loss: 0.6870096704862223
Epoch: 75 | Iteration number: [2940/4518] 65% | Training loss: 0.6870088082592504
Epoch: 75 | Iteration number: [2950/4518] 65% | Training loss: 0.6870040072222887
Epoch: 75 | Iteration number: [2960/4518] 65% | Training loss: 0.6870069660246372
Epoch: 75 | Iteration number: [2970/4518] 65% | Training loss: 0.6870078659619546
Epoch: 75 | Iteration number: [2980/4518] 65% | Training loss: 0.6870043200734478
Epoch: 75 | Iteration number: [2990/4518] 66% | Training loss: 0.687002190538872
Epoch: 75 | Iteration number: [3000/4518] 66% | Training loss: 0.6870036811232567
Epoch: 75 | Iteration number: [3010/4518] 66% | Training loss: 0.6870052653095651
Epoch: 75 | Iteration number: [3020/4518] 66% | Training loss: 0.6869990403289037
Epoch: 75 | Iteration number: [3030/4518] 67% | Training loss: 0.6869979688239963
Epoch: 75 | Iteration number: [3040/4518] 67% | Training loss: 0.6869983129399387
Epoch: 75 | Iteration number: [3050/4518] 67% | Training loss: 0.6870015224276996
Epoch: 75 | Iteration number: [3060/4518] 67% | Training loss: 0.6869972415024939
Epoch: 75 | Iteration number: [3070/4518] 67% | Training loss: 0.6869991205414265
Epoch: 75 | Iteration number: [3080/4518] 68% | Training loss: 0.6870006979866461
Epoch: 75 | Iteration number: [3090/4518] 68% | Training loss: 0.6869971122170729
Epoch: 75 | Iteration number: [3100/4518] 68% | Training loss: 0.6869939415685592
Epoch: 75 | Iteration number: [3110/4518] 68% | Training loss: 0.6869955896947928
Epoch: 75 | Iteration number: [3120/4518] 69% | Training loss: 0.6869948708285124
Epoch: 75 | Iteration number: [3130/4518] 69% | Training loss: 0.6869897195135062
Epoch: 75 | Iteration number: [3140/4518] 69% | Training loss: 0.6869902408047087
Epoch: 75 | Iteration number: [3150/4518] 69% | Training loss: 0.6869860244932628
Epoch: 75 | Iteration number: [3160/4518] 69% | Training loss: 0.6869833530881737
Epoch: 75 | Iteration number: [3170/4518] 70% | Training loss: 0.6869794475355359
Epoch: 75 | Iteration number: [3180/4518] 70% | Training loss: 0.6869780798565667
Epoch: 75 | Iteration number: [3190/4518] 70% | Training loss: 0.6869783402610349
Epoch: 75 | Iteration number: [3200/4518] 70% | Training loss: 0.6869785614125431
Epoch: 75 | Iteration number: [3210/4518] 71% | Training loss: 0.6869774430711693
Epoch: 75 | Iteration number: [3220/4518] 71% | Training loss: 0.6869746360719574
Epoch: 75 | Iteration number: [3230/4518] 71% | Training loss: 0.6869737187775296
Epoch: 75 | Iteration number: [3240/4518] 71% | Training loss: 0.6869737174223971
Epoch: 75 | Iteration number: [3250/4518] 71% | Training loss: 0.6869734124770531
Epoch: 75 | Iteration number: [3260/4518] 72% | Training loss: 0.686974194974987
Epoch: 75 | Iteration number: [3270/4518] 72% | Training loss: 0.6869738227001388
Epoch: 75 | Iteration number: [3280/4518] 72% | Training loss: 0.6869732356834702
Epoch: 75 | Iteration number: [3290/4518] 72% | Training loss: 0.6869690326571827
Epoch: 75 | Iteration number: [3300/4518] 73% | Training loss: 0.6869684011647196
Epoch: 75 | Iteration number: [3310/4518] 73% | Training loss: 0.6869662271525564
Epoch: 75 | Iteration number: [3320/4518] 73% | Training loss: 0.686969419254596
Epoch: 75 | Iteration number: [3330/4518] 73% | Training loss: 0.6869700212378401
Epoch: 75 | Iteration number: [3340/4518] 73% | Training loss: 0.6869701493286087
Epoch: 75 | Iteration number: [3350/4518] 74% | Training loss: 0.6869708854582772
Epoch: 75 | Iteration number: [3360/4518] 74% | Training loss: 0.6869704282177346
Epoch: 75 | Iteration number: [3370/4518] 74% | Training loss: 0.6869726384252044
Epoch: 75 | Iteration number: [3380/4518] 74% | Training loss: 0.686971825749211
Epoch: 75 | Iteration number: [3390/4518] 75% | Training loss: 0.6869711542024022
Epoch: 75 | Iteration number: [3400/4518] 75% | Training loss: 0.6869687579659854
Epoch: 75 | Iteration number: [3410/4518] 75% | Training loss: 0.6869681411299887
Epoch: 75 | Iteration number: [3420/4518] 75% | Training loss: 0.6869645294738792
Epoch: 75 | Iteration number: [3430/4518] 75% | Training loss: 0.6869634269451609
Epoch: 75 | Iteration number: [3440/4518] 76% | Training loss: 0.6869650585187036
Epoch: 75 | Iteration number: [3450/4518] 76% | Training loss: 0.6869648645926213
Epoch: 75 | Iteration number: [3460/4518] 76% | Training loss: 0.6869654417554767
Epoch: 75 | Iteration number: [3470/4518] 76% | Training loss: 0.6869592388184682
Epoch: 75 | Iteration number: [3480/4518] 77% | Training loss: 0.6869561094319684
Epoch: 75 | Iteration number: [3490/4518] 77% | Training loss: 0.6869550664821122
Epoch: 75 | Iteration number: [3500/4518] 77% | Training loss: 0.6869552449669156
Epoch: 75 | Iteration number: [3510/4518] 77% | Training loss: 0.6869541522614298
Epoch: 75 | Iteration number: [3520/4518] 77% | Training loss: 0.6869556425816633
Epoch: 75 | Iteration number: [3530/4518] 78% | Training loss: 0.6869580751606831
Epoch: 75 | Iteration number: [3540/4518] 78% | Training loss: 0.68695663984886
Epoch: 75 | Iteration number: [3550/4518] 78% | Training loss: 0.6869550008840963
Epoch: 75 | Iteration number: [3560/4518] 78% | Training loss: 0.6869547615057967
Epoch: 75 | Iteration number: [3570/4518] 79% | Training loss: 0.6869547373440419
Epoch: 75 | Iteration number: [3580/4518] 79% | Training loss: 0.686954713850048
Epoch: 75 | Iteration number: [3590/4518] 79% | Training loss: 0.6869537284281261
Epoch: 75 | Iteration number: [3600/4518] 79% | Training loss: 0.6869542556835545
Epoch: 75 | Iteration number: [3610/4518] 79% | Training loss: 0.6869511873768307
Epoch: 75 | Iteration number: [3620/4518] 80% | Training loss: 0.6869515578061837
Epoch: 75 | Iteration number: [3630/4518] 80% | Training loss: 0.6869514944467991
Epoch: 75 | Iteration number: [3640/4518] 80% | Training loss: 0.6869546801834316
Epoch: 75 | Iteration number: [3650/4518] 80% | Training loss: 0.6869538987662694
Epoch: 75 | Iteration number: [3660/4518] 81% | Training loss: 0.6869519591494336
Epoch: 75 | Iteration number: [3670/4518] 81% | Training loss: 0.6869527312325522
Epoch: 75 | Iteration number: [3680/4518] 81% | Training loss: 0.6869507807428422
Epoch: 75 | Iteration number: [3690/4518] 81% | Training loss: 0.6869527937758583
Epoch: 75 | Iteration number: [3700/4518] 81% | Training loss: 0.6869535670248238
Epoch: 75 | Iteration number: [3710/4518] 82% | Training loss: 0.6869493890001446
Epoch: 75 | Iteration number: [3720/4518] 82% | Training loss: 0.6869470363022179
Epoch: 75 | Iteration number: [3730/4518] 82% | Training loss: 0.6869454757457764
Epoch: 75 | Iteration number: [3740/4518] 82% | Training loss: 0.6869473072296796
Epoch: 75 | Iteration number: [3750/4518] 83% | Training loss: 0.6869471170743306
Epoch: 75 | Iteration number: [3760/4518] 83% | Training loss: 0.6869488803947226
Epoch: 75 | Iteration number: [3770/4518] 83% | Training loss: 0.6869487666799156
Epoch: 75 | Iteration number: [3780/4518] 83% | Training loss: 0.6869499223730552
Epoch: 75 | Iteration number: [3790/4518] 83% | Training loss: 0.6869515794405522
Epoch: 75 | Iteration number: [3800/4518] 84% | Training loss: 0.6869506385608724
Epoch: 75 | Iteration number: [3810/4518] 84% | Training loss: 0.6869523363163464
Epoch: 75 | Iteration number: [3820/4518] 84% | Training loss: 0.6869532106122421
Epoch: 75 | Iteration number: [3830/4518] 84% | Training loss: 0.6869511322004054
Epoch: 75 | Iteration number: [3840/4518] 84% | Training loss: 0.6869511417423685
Epoch: 75 | Iteration number: [3850/4518] 85% | Training loss: 0.6869516029915252
Epoch: 75 | Iteration number: [3860/4518] 85% | Training loss: 0.6869499996536136
Epoch: 75 | Iteration number: [3870/4518] 85% | Training loss: 0.6869524006849728
Epoch: 75 | Iteration number: [3880/4518] 85% | Training loss: 0.6869508223742554
Epoch: 75 | Iteration number: [3890/4518] 86% | Training loss: 0.686950421333313
Epoch: 75 | Iteration number: [3900/4518] 86% | Training loss: 0.6869499232371649
Epoch: 75 | Iteration number: [3910/4518] 86% | Training loss: 0.6869475514382658
Epoch: 75 | Iteration number: [3920/4518] 86% | Training loss: 0.6869479881409479
Epoch: 75 | Iteration number: [3930/4518] 86% | Training loss: 0.6869513591130575
Epoch: 75 | Iteration number: [3940/4518] 87% | Training loss: 0.6869499368413451
Epoch: 75 | Iteration number: [3950/4518] 87% | Training loss: 0.6869484915914414
Epoch: 75 | Iteration number: [3960/4518] 87% | Training loss: 0.6869468230189699
Epoch: 75 | Iteration number: [3970/4518] 87% | Training loss: 0.6869441989537151
Epoch: 75 | Iteration number: [3980/4518] 88% | Training loss: 0.6869479749969502
Epoch: 75 | Iteration number: [3990/4518] 88% | Training loss: 0.686947845889811
Epoch: 75 | Iteration number: [4000/4518] 88% | Training loss: 0.6869494542777538
Epoch: 75 | Iteration number: [4010/4518] 88% | Training loss: 0.686949722517161
Epoch: 75 | Iteration number: [4020/4518] 88% | Training loss: 0.6869480819844488
Epoch: 75 | Iteration number: [4030/4518] 89% | Training loss: 0.6869484372085732
Epoch: 75 | Iteration number: [4040/4518] 89% | Training loss: 0.6869512952347793
Epoch: 75 | Iteration number: [4050/4518] 89% | Training loss: 0.6869521709136021
Epoch: 75 | Iteration number: [4060/4518] 89% | Training loss: 0.6869516771121565
Epoch: 75 | Iteration number: [4070/4518] 90% | Training loss: 0.6869501537274962
Epoch: 75 | Iteration number: [4080/4518] 90% | Training loss: 0.6869478203502356
Epoch: 75 | Iteration number: [4090/4518] 90% | Training loss: 0.6869481483560903
Epoch: 75 | Iteration number: [4100/4518] 90% | Training loss: 0.6869511651120535
Epoch: 75 | Iteration number: [4110/4518] 90% | Training loss: 0.6869513981388723
Epoch: 75 | Iteration number: [4120/4518] 91% | Training loss: 0.6869482458216473
Epoch: 75 | Iteration number: [4130/4518] 91% | Training loss: 0.6869457652436042
Epoch: 75 | Iteration number: [4140/4518] 91% | Training loss: 0.6869451679325335
Epoch: 75 | Iteration number: [4150/4518] 91% | Training loss: 0.6869461759314479
Epoch: 75 | Iteration number: [4160/4518] 92% | Training loss: 0.6869456590368197
Epoch: 75 | Iteration number: [4170/4518] 92% | Training loss: 0.6869488853201877
Epoch: 75 | Iteration number: [4180/4518] 92% | Training loss: 0.6869448240721625
Epoch: 75 | Iteration number: [4190/4518] 92% | Training loss: 0.6869415239388732
Epoch: 75 | Iteration number: [4200/4518] 92% | Training loss: 0.6869420870003247
Epoch: 75 | Iteration number: [4210/4518] 93% | Training loss: 0.6869431271547376
Epoch: 75 | Iteration number: [4220/4518] 93% | Training loss: 0.6869413384752816
Epoch: 75 | Iteration number: [4230/4518] 93% | Training loss: 0.6869416125136346
Epoch: 75 | Iteration number: [4240/4518] 93% | Training loss: 0.6869423566280671
Epoch: 75 | Iteration number: [4250/4518] 94% | Training loss: 0.6869430850393632
Epoch: 75 | Iteration number: [4260/4518] 94% | Training loss: 0.686942421886283
Epoch: 75 | Iteration number: [4270/4518] 94% | Training loss: 0.686940725542064
Epoch: 75 | Iteration number: [4280/4518] 94% | Training loss: 0.6869410334207188
Epoch: 75 | Iteration number: [4290/4518] 94% | Training loss: 0.6869391935132878
Epoch: 75 | Iteration number: [4300/4518] 95% | Training loss: 0.6869364804445312
Epoch: 75 | Iteration number: [4310/4518] 95% | Training loss: 0.6869354525187729
Epoch: 75 | Iteration number: [4320/4518] 95% | Training loss: 0.6869344559946546
Epoch: 75 | Iteration number: [4330/4518] 95% | Training loss: 0.6869368567477748
Epoch: 75 | Iteration number: [4340/4518] 96% | Training loss: 0.6869366986822972
Epoch: 75 | Iteration number: [4350/4518] 96% | Training loss: 0.6869337632875333
Epoch: 75 | Iteration number: [4360/4518] 96% | Training loss: 0.6869356805714992
Epoch: 75 | Iteration number: [4370/4518] 96% | Training loss: 0.6869387865202924
Epoch: 75 | Iteration number: [4380/4518] 96% | Training loss: 0.686935162340125
Epoch: 75 | Iteration number: [4390/4518] 97% | Training loss: 0.6869309427933704
Epoch: 75 | Iteration number: [4400/4518] 97% | Training loss: 0.686931113709103
Epoch: 75 | Iteration number: [4410/4518] 97% | Training loss: 0.6869290432827273
Epoch: 75 | Iteration number: [4420/4518] 97% | Training loss: 0.686928146861797
Epoch: 75 | Iteration number: [4430/4518] 98% | Training loss: 0.6869273732531959
Epoch: 75 | Iteration number: [4440/4518] 98% | Training loss: 0.6869272643247166
Epoch: 75 | Iteration number: [4450/4518] 98% | Training loss: 0.6869262816798821
Epoch: 75 | Iteration number: [4460/4518] 98% | Training loss: 0.6869256412501827
Epoch: 75 | Iteration number: [4470/4518] 98% | Training loss: 0.6869251746325952
Epoch: 75 | Iteration number: [4480/4518] 99% | Training loss: 0.6869255328817027
Epoch: 75 | Iteration number: [4490/4518] 99% | Training loss: 0.68692338057775
Epoch: 75 | Iteration number: [4500/4518] 99% | Training loss: 0.6869223338365554
Epoch: 75 | Iteration number: [4510/4518] 99% | Training loss: 0.6869226697278922

 End of epoch: 75 | Train Loss: 0.6867671326732889 | Training Time: 633 

 End of epoch: 75 | Eval Loss: 0.6896340567238477 | Evaluating Time: 17 
Epoch: 76 | Iteration number: [10/4518] 0% | Training loss: 0.7549315452575683
Epoch: 76 | Iteration number: [20/4518] 0% | Training loss: 0.7205728024244309
Epoch: 76 | Iteration number: [30/4518] 0% | Training loss: 0.7093227982521058
Epoch: 76 | Iteration number: [40/4518] 0% | Training loss: 0.7038388729095459
Epoch: 76 | Iteration number: [50/4518] 1% | Training loss: 0.7005348229408264
Epoch: 76 | Iteration number: [60/4518] 1% | Training loss: 0.6982137868801753
Epoch: 76 | Iteration number: [70/4518] 1% | Training loss: 0.6966494483607156
Epoch: 76 | Iteration number: [80/4518] 1% | Training loss: 0.6953736394643784
Epoch: 76 | Iteration number: [90/4518] 1% | Training loss: 0.6944947633478377
Epoch: 76 | Iteration number: [100/4518] 2% | Training loss: 0.6936909395456314
Epoch: 76 | Iteration number: [110/4518] 2% | Training loss: 0.6930551810698076
Epoch: 76 | Iteration number: [120/4518] 2% | Training loss: 0.6925180584192276
Epoch: 76 | Iteration number: [130/4518] 2% | Training loss: 0.6921161592006684
Epoch: 76 | Iteration number: [140/4518] 3% | Training loss: 0.6916989109345845
Epoch: 76 | Iteration number: [150/4518] 3% | Training loss: 0.6913906141122182
Epoch: 76 | Iteration number: [160/4518] 3% | Training loss: 0.6910600736737251
Epoch: 76 | Iteration number: [170/4518] 3% | Training loss: 0.6908159014056711
Epoch: 76 | Iteration number: [180/4518] 3% | Training loss: 0.6906690001487732
Epoch: 76 | Iteration number: [190/4518] 4% | Training loss: 0.6903275747048228
Epoch: 76 | Iteration number: [200/4518] 4% | Training loss: 0.6901273015141487
Epoch: 76 | Iteration number: [210/4518] 4% | Training loss: 0.6899784749462491
Epoch: 76 | Iteration number: [220/4518] 4% | Training loss: 0.6897514909505844
Epoch: 76 | Iteration number: [230/4518] 5% | Training loss: 0.6896267901296201
Epoch: 76 | Iteration number: [240/4518] 5% | Training loss: 0.689537909378608
Epoch: 76 | Iteration number: [250/4518] 5% | Training loss: 0.6894178066253662
Epoch: 76 | Iteration number: [260/4518] 5% | Training loss: 0.6893355961029346
Epoch: 76 | Iteration number: [270/4518] 5% | Training loss: 0.6892053610748715
Epoch: 76 | Iteration number: [280/4518] 6% | Training loss: 0.6891535443919046
Epoch: 76 | Iteration number: [290/4518] 6% | Training loss: 0.6890936580197564
Epoch: 76 | Iteration number: [300/4518] 6% | Training loss: 0.6889966662724812
Epoch: 76 | Iteration number: [310/4518] 6% | Training loss: 0.6889551047355899
Epoch: 76 | Iteration number: [320/4518] 7% | Training loss: 0.6889201113954186
Epoch: 76 | Iteration number: [330/4518] 7% | Training loss: 0.6888663850047372
Epoch: 76 | Iteration number: [340/4518] 7% | Training loss: 0.6888094544410706
Epoch: 76 | Iteration number: [350/4518] 7% | Training loss: 0.6887685350009374
Epoch: 76 | Iteration number: [360/4518] 7% | Training loss: 0.6887142467829916
Epoch: 76 | Iteration number: [370/4518] 8% | Training loss: 0.6886815918458474
Epoch: 76 | Iteration number: [380/4518] 8% | Training loss: 0.6886397066869234
Epoch: 76 | Iteration number: [390/4518] 8% | Training loss: 0.6886056683002374
Epoch: 76 | Iteration number: [400/4518] 8% | Training loss: 0.6885579515993595
Epoch: 76 | Iteration number: [410/4518] 9% | Training loss: 0.6885534145483156
Epoch: 76 | Iteration number: [420/4518] 9% | Training loss: 0.6885246641579128
Epoch: 76 | Iteration number: [430/4518] 9% | Training loss: 0.6884858633196631
Epoch: 76 | Iteration number: [440/4518] 9% | Training loss: 0.6884390673854134
Epoch: 76 | Iteration number: [450/4518] 9% | Training loss: 0.6883901080820296
Epoch: 76 | Iteration number: [460/4518] 10% | Training loss: 0.6883485937895982
Epoch: 76 | Iteration number: [470/4518] 10% | Training loss: 0.6883008024793991
Epoch: 76 | Iteration number: [480/4518] 10% | Training loss: 0.6882653962820768
Epoch: 76 | Iteration number: [490/4518] 10% | Training loss: 0.6882295480796269
Epoch: 76 | Iteration number: [500/4518] 11% | Training loss: 0.688188425064087
Epoch: 76 | Iteration number: [510/4518] 11% | Training loss: 0.6881401231475904
Epoch: 76 | Iteration number: [520/4518] 11% | Training loss: 0.6880845263600349
Epoch: 76 | Iteration number: [530/4518] 11% | Training loss: 0.6880186069686458
Epoch: 76 | Iteration number: [540/4518] 11% | Training loss: 0.6879631833897697
Epoch: 76 | Iteration number: [550/4518] 12% | Training loss: 0.6879442010142587
Epoch: 76 | Iteration number: [560/4518] 12% | Training loss: 0.6879301548004151
Epoch: 76 | Iteration number: [570/4518] 12% | Training loss: 0.6879045151827629
Epoch: 76 | Iteration number: [580/4518] 12% | Training loss: 0.6878771942237328
Epoch: 76 | Iteration number: [590/4518] 13% | Training loss: 0.6878517127643198
Epoch: 76 | Iteration number: [600/4518] 13% | Training loss: 0.6878312439719836
Epoch: 76 | Iteration number: [610/4518] 13% | Training loss: 0.6878066780137234
Epoch: 76 | Iteration number: [620/4518] 13% | Training loss: 0.6877780299032888
Epoch: 76 | Iteration number: [630/4518] 13% | Training loss: 0.68776103787952
Epoch: 76 | Iteration number: [640/4518] 14% | Training loss: 0.6877537560649216
Epoch: 76 | Iteration number: [650/4518] 14% | Training loss: 0.6877370157608619
Epoch: 76 | Iteration number: [660/4518] 14% | Training loss: 0.6877161874012514
Epoch: 76 | Iteration number: [670/4518] 14% | Training loss: 0.6877145841940125
Epoch: 76 | Iteration number: [680/4518] 15% | Training loss: 0.6876920081236784
Epoch: 76 | Iteration number: [690/4518] 15% | Training loss: 0.6876910454985025
Epoch: 76 | Iteration number: [700/4518] 15% | Training loss: 0.6877011930942536
Epoch: 76 | Iteration number: [710/4518] 15% | Training loss: 0.687688088333103
Epoch: 76 | Iteration number: [720/4518] 15% | Training loss: 0.68766166990002
Epoch: 76 | Iteration number: [730/4518] 16% | Training loss: 0.6876548682173638
Epoch: 76 | Iteration number: [740/4518] 16% | Training loss: 0.6876635413717579
Epoch: 76 | Iteration number: [750/4518] 16% | Training loss: 0.6876666804949443
Epoch: 76 | Iteration number: [760/4518] 16% | Training loss: 0.6876447938774761
Epoch: 76 | Iteration number: [770/4518] 17% | Training loss: 0.6876255450310645
Epoch: 76 | Iteration number: [780/4518] 17% | Training loss: 0.6876115809648465
Epoch: 76 | Iteration number: [790/4518] 17% | Training loss: 0.6875988366483133
Epoch: 76 | Iteration number: [800/4518] 17% | Training loss: 0.6875870164483786
Epoch: 76 | Iteration number: [810/4518] 17% | Training loss: 0.6875819127500793
Epoch: 76 | Iteration number: [820/4518] 18% | Training loss: 0.6875636988296742
Epoch: 76 | Iteration number: [830/4518] 18% | Training loss: 0.6875452802841922
Epoch: 76 | Iteration number: [840/4518] 18% | Training loss: 0.6875189466845422
Epoch: 76 | Iteration number: [850/4518] 18% | Training loss: 0.6874995840297026
Epoch: 76 | Iteration number: [860/4518] 19% | Training loss: 0.6874858944221984
Epoch: 76 | Iteration number: [870/4518] 19% | Training loss: 0.6874801524754228
Epoch: 76 | Iteration number: [880/4518] 19% | Training loss: 0.6874744329940189
Epoch: 76 | Iteration number: [890/4518] 19% | Training loss: 0.6874718599774864
Epoch: 76 | Iteration number: [900/4518] 19% | Training loss: 0.6874713051981396
Epoch: 76 | Iteration number: [910/4518] 20% | Training loss: 0.6874674690948738
Epoch: 76 | Iteration number: [920/4518] 20% | Training loss: 0.6874517206912455
Epoch: 76 | Iteration number: [930/4518] 20% | Training loss: 0.6874294422647005
Epoch: 76 | Iteration number: [940/4518] 20% | Training loss: 0.6874181144415064
Epoch: 76 | Iteration number: [950/4518] 21% | Training loss: 0.6874215258422651
Epoch: 76 | Iteration number: [960/4518] 21% | Training loss: 0.6874173344423373
Epoch: 76 | Iteration number: [970/4518] 21% | Training loss: 0.687416515215156
Epoch: 76 | Iteration number: [980/4518] 21% | Training loss: 0.6874193066236924
Epoch: 76 | Iteration number: [990/4518] 21% | Training loss: 0.6874058480214591
Epoch: 76 | Iteration number: [1000/4518] 22% | Training loss: 0.6873864803314209
Epoch: 76 | Iteration number: [1010/4518] 22% | Training loss: 0.6873805305155197
Epoch: 76 | Iteration number: [1020/4518] 22% | Training loss: 0.6873704029648912
Epoch: 76 | Iteration number: [1030/4518] 22% | Training loss: 0.6873578340104483
Epoch: 76 | Iteration number: [1040/4518] 23% | Training loss: 0.6873537816680395
Epoch: 76 | Iteration number: [1050/4518] 23% | Training loss: 0.6873368908677783
Epoch: 76 | Iteration number: [1060/4518] 23% | Training loss: 0.6873156011666892
Epoch: 76 | Iteration number: [1070/4518] 23% | Training loss: 0.6873149244027718
Epoch: 76 | Iteration number: [1080/4518] 23% | Training loss: 0.6873103868078303
Epoch: 76 | Iteration number: [1090/4518] 24% | Training loss: 0.6873196067066367
Epoch: 76 | Iteration number: [1100/4518] 24% | Training loss: 0.6873191754384474
Epoch: 76 | Iteration number: [1110/4518] 24% | Training loss: 0.6873171680145436
Epoch: 76 | Iteration number: [1120/4518] 24% | Training loss: 0.687329289317131
Epoch: 76 | Iteration number: [1130/4518] 25% | Training loss: 0.6873284815686994
Epoch: 76 | Iteration number: [1140/4518] 25% | Training loss: 0.6873206732043049
Epoch: 76 | Iteration number: [1150/4518] 25% | Training loss: 0.6873169341812964
Epoch: 76 | Iteration number: [1160/4518] 25% | Training loss: 0.6873090404374846
Epoch: 76 | Iteration number: [1170/4518] 25% | Training loss: 0.6873134418939932
Epoch: 76 | Iteration number: [1180/4518] 26% | Training loss: 0.6873157678014141
Epoch: 76 | Iteration number: [1190/4518] 26% | Training loss: 0.6873095775852684
Epoch: 76 | Iteration number: [1200/4518] 26% | Training loss: 0.6873083161811034
Epoch: 76 | Iteration number: [1210/4518] 26% | Training loss: 0.6873108299803142
Epoch: 76 | Iteration number: [1220/4518] 27% | Training loss: 0.6873078263685352
Epoch: 76 | Iteration number: [1230/4518] 27% | Training loss: 0.6873058261910105
Epoch: 76 | Iteration number: [1240/4518] 27% | Training loss: 0.687299418112924
Epoch: 76 | Iteration number: [1250/4518] 27% | Training loss: 0.687298984670639
Epoch: 76 | Iteration number: [1260/4518] 27% | Training loss: 0.6872993773884244
Epoch: 76 | Iteration number: [1270/4518] 28% | Training loss: 0.6872966242118145
Epoch: 76 | Iteration number: [1280/4518] 28% | Training loss: 0.6872914653737098
Epoch: 76 | Iteration number: [1290/4518] 28% | Training loss: 0.6872730429320373
Epoch: 76 | Iteration number: [1300/4518] 28% | Training loss: 0.6872768904154117
Epoch: 76 | Iteration number: [1310/4518] 28% | Training loss: 0.6872716516028834
Epoch: 76 | Iteration number: [1320/4518] 29% | Training loss: 0.6872722580577388
Epoch: 76 | Iteration number: [1330/4518] 29% | Training loss: 0.6872677101676625
Epoch: 76 | Iteration number: [1340/4518] 29% | Training loss: 0.6872623169155263
Epoch: 76 | Iteration number: [1350/4518] 29% | Training loss: 0.6872527490721808
Epoch: 76 | Iteration number: [1360/4518] 30% | Training loss: 0.6872503987129996
Epoch: 76 | Iteration number: [1370/4518] 30% | Training loss: 0.6872444995998466
Epoch: 76 | Iteration number: [1380/4518] 30% | Training loss: 0.68723458868006
Epoch: 76 | Iteration number: [1390/4518] 30% | Training loss: 0.6872232489019847
Epoch: 76 | Iteration number: [1400/4518] 30% | Training loss: 0.687217327952385
Epoch: 76 | Iteration number: [1410/4518] 31% | Training loss: 0.6872099038556958
Epoch: 76 | Iteration number: [1420/4518] 31% | Training loss: 0.6872085559116283
Epoch: 76 | Iteration number: [1430/4518] 31% | Training loss: 0.6872053259319358
Epoch: 76 | Iteration number: [1440/4518] 31% | Training loss: 0.6872056862546339
Epoch: 76 | Iteration number: [1450/4518] 32% | Training loss: 0.6872060412374036
Epoch: 76 | Iteration number: [1460/4518] 32% | Training loss: 0.6871902300478661
Epoch: 76 | Iteration number: [1470/4518] 32% | Training loss: 0.6871938202251382
Epoch: 76 | Iteration number: [1480/4518] 32% | Training loss: 0.6871893797371839
Epoch: 76 | Iteration number: [1490/4518] 32% | Training loss: 0.6871856725055899
Epoch: 76 | Iteration number: [1500/4518] 33% | Training loss: 0.68717893298467
Epoch: 76 | Iteration number: [1510/4518] 33% | Training loss: 0.6871786565180645
Epoch: 76 | Iteration number: [1520/4518] 33% | Training loss: 0.687177182694799
Epoch: 76 | Iteration number: [1530/4518] 33% | Training loss: 0.6871767127046398
Epoch: 76 | Iteration number: [1540/4518] 34% | Training loss: 0.6871724713158298
Epoch: 76 | Iteration number: [1550/4518] 34% | Training loss: 0.6871771161402426
Epoch: 76 | Iteration number: [1560/4518] 34% | Training loss: 0.6871704891706124
Epoch: 76 | Iteration number: [1570/4518] 34% | Training loss: 0.6871666603407283
Epoch: 76 | Iteration number: [1580/4518] 34% | Training loss: 0.687168268651902
Epoch: 76 | Iteration number: [1590/4518] 35% | Training loss: 0.6871648531664842
Epoch: 76 | Iteration number: [1600/4518] 35% | Training loss: 0.6871635404601694
Epoch: 76 | Iteration number: [1610/4518] 35% | Training loss: 0.6871570280249815
Epoch: 76 | Iteration number: [1620/4518] 35% | Training loss: 0.6871506936020322
Epoch: 76 | Iteration number: [1630/4518] 36% | Training loss: 0.6871406957050042
Epoch: 76 | Iteration number: [1640/4518] 36% | Training loss: 0.6871435687309358
Epoch: 76 | Iteration number: [1650/4518] 36% | Training loss: 0.6871438152862318
Epoch: 76 | Iteration number: [1660/4518] 36% | Training loss: 0.6871309813605734
Epoch: 76 | Iteration number: [1670/4518] 36% | Training loss: 0.6871223233774036
Epoch: 76 | Iteration number: [1680/4518] 37% | Training loss: 0.687119631256376
Epoch: 76 | Iteration number: [1690/4518] 37% | Training loss: 0.6871196856512826
Epoch: 76 | Iteration number: [1700/4518] 37% | Training loss: 0.6871200353257796
Epoch: 76 | Iteration number: [1710/4518] 37% | Training loss: 0.6871126023649472
Epoch: 76 | Iteration number: [1720/4518] 38% | Training loss: 0.6871135330477426
Epoch: 76 | Iteration number: [1730/4518] 38% | Training loss: 0.6871136930292052
Epoch: 76 | Iteration number: [1740/4518] 38% | Training loss: 0.6871099048647388
Epoch: 76 | Iteration number: [1750/4518] 38% | Training loss: 0.6871107887199946
Epoch: 76 | Iteration number: [1760/4518] 38% | Training loss: 0.6871111605655064
Epoch: 76 | Iteration number: [1770/4518] 39% | Training loss: 0.6871106526272445
Epoch: 76 | Iteration number: [1780/4518] 39% | Training loss: 0.6871112985557385
Epoch: 76 | Iteration number: [1790/4518] 39% | Training loss: 0.6871081340579347
Epoch: 76 | Iteration number: [1800/4518] 39% | Training loss: 0.6871071391304334
Epoch: 76 | Iteration number: [1810/4518] 40% | Training loss: 0.6871048706341844
Epoch: 76 | Iteration number: [1820/4518] 40% | Training loss: 0.6871051257455741
Epoch: 76 | Iteration number: [1830/4518] 40% | Training loss: 0.6871020259427243
Epoch: 76 | Iteration number: [1840/4518] 40% | Training loss: 0.6871059821675654
Epoch: 76 | Iteration number: [1850/4518] 40% | Training loss: 0.6871041720944482
Epoch: 76 | Iteration number: [1860/4518] 41% | Training loss: 0.6870999752513824
Epoch: 76 | Iteration number: [1870/4518] 41% | Training loss: 0.6870949522059232
Epoch: 76 | Iteration number: [1880/4518] 41% | Training loss: 0.6871006317912264
Epoch: 76 | Iteration number: [1890/4518] 41% | Training loss: 0.6871016507426267
Epoch: 76 | Iteration number: [1900/4518] 42% | Training loss: 0.6870983853151924
Epoch: 76 | Iteration number: [1910/4518] 42% | Training loss: 0.6871029611033295
Epoch: 76 | Iteration number: [1920/4518] 42% | Training loss: 0.6871031723916531
Epoch: 76 | Iteration number: [1930/4518] 42% | Training loss: 0.687097878066987
Epoch: 76 | Iteration number: [1940/4518] 42% | Training loss: 0.6870929742289572
Epoch: 76 | Iteration number: [1950/4518] 43% | Training loss: 0.6870987660456926
Epoch: 76 | Iteration number: [1960/4518] 43% | Training loss: 0.6870972801836169
Epoch: 76 | Iteration number: [1970/4518] 43% | Training loss: 0.6870956407283163
Epoch: 76 | Iteration number: [1980/4518] 43% | Training loss: 0.6870876919741582
Epoch: 76 | Iteration number: [1990/4518] 44% | Training loss: 0.6870859954524879
Epoch: 76 | Iteration number: [2000/4518] 44% | Training loss: 0.6870793094635009
Epoch: 76 | Iteration number: [2010/4518] 44% | Training loss: 0.6870782900508956
Epoch: 76 | Iteration number: [2020/4518] 44% | Training loss: 0.6870737068133779
Epoch: 76 | Iteration number: [2030/4518] 44% | Training loss: 0.6870664621515227
Epoch: 76 | Iteration number: [2040/4518] 45% | Training loss: 0.6870662517699541
Epoch: 76 | Iteration number: [2050/4518] 45% | Training loss: 0.6870671049559989
Epoch: 76 | Iteration number: [2060/4518] 45% | Training loss: 0.6870622748599469
Epoch: 76 | Iteration number: [2070/4518] 45% | Training loss: 0.6870584380799446
Epoch: 76 | Iteration number: [2080/4518] 46% | Training loss: 0.6870586502437408
Epoch: 76 | Iteration number: [2090/4518] 46% | Training loss: 0.6870527793631029
Epoch: 76 | Iteration number: [2100/4518] 46% | Training loss: 0.6870525545733316
Epoch: 76 | Iteration number: [2110/4518] 46% | Training loss: 0.6870540199969052
Epoch: 76 | Iteration number: [2120/4518] 46% | Training loss: 0.687057256248762
Epoch: 76 | Iteration number: [2130/4518] 47% | Training loss: 0.6870525772862591
Epoch: 76 | Iteration number: [2140/4518] 47% | Training loss: 0.6870517405951134
Epoch: 76 | Iteration number: [2150/4518] 47% | Training loss: 0.6870501002045565
Epoch: 76 | Iteration number: [2160/4518] 47% | Training loss: 0.6870474269544636
Epoch: 76 | Iteration number: [2170/4518] 48% | Training loss: 0.6870478028525955
Epoch: 76 | Iteration number: [2180/4518] 48% | Training loss: 0.6870426056308484
Epoch: 76 | Iteration number: [2190/4518] 48% | Training loss: 0.6870430946894432
Epoch: 76 | Iteration number: [2200/4518] 48% | Training loss: 0.6870427163080736
Epoch: 76 | Iteration number: [2210/4518] 48% | Training loss: 0.6870453935133386
Epoch: 76 | Iteration number: [2220/4518] 49% | Training loss: 0.6870408301686382
Epoch: 76 | Iteration number: [2230/4518] 49% | Training loss: 0.6870358896362407
Epoch: 76 | Iteration number: [2240/4518] 49% | Training loss: 0.6870361569736685
Epoch: 76 | Iteration number: [2250/4518] 49% | Training loss: 0.6870362157821656
Epoch: 76 | Iteration number: [2260/4518] 50% | Training loss: 0.6870359190269909
Epoch: 76 | Iteration number: [2270/4518] 50% | Training loss: 0.6870316888792399
Epoch: 76 | Iteration number: [2280/4518] 50% | Training loss: 0.6870245415390583
Epoch: 76 | Iteration number: [2290/4518] 50% | Training loss: 0.6870232540447119
Epoch: 76 | Iteration number: [2300/4518] 50% | Training loss: 0.6870249127305073
Epoch: 76 | Iteration number: [2310/4518] 51% | Training loss: 0.6870200170841052
Epoch: 76 | Iteration number: [2320/4518] 51% | Training loss: 0.6870224344319311
Epoch: 76 | Iteration number: [2330/4518] 51% | Training loss: 0.6870207036513627
Epoch: 76 | Iteration number: [2340/4518] 51% | Training loss: 0.6870204024589979
Epoch: 76 | Iteration number: [2350/4518] 52% | Training loss: 0.6870210431230829
Epoch: 76 | Iteration number: [2360/4518] 52% | Training loss: 0.6870167820635489
Epoch: 76 | Iteration number: [2370/4518] 52% | Training loss: 0.6870202623339142
Epoch: 76 | Iteration number: [2380/4518] 52% | Training loss: 0.6870211206313943
Epoch: 76 | Iteration number: [2390/4518] 52% | Training loss: 0.6870200389349311
Epoch: 76 | Iteration number: [2400/4518] 53% | Training loss: 0.6870207239190738
Epoch: 76 | Iteration number: [2410/4518] 53% | Training loss: 0.6870190551666798
Epoch: 76 | Iteration number: [2420/4518] 53% | Training loss: 0.6870205749411228
Epoch: 76 | Iteration number: [2430/4518] 53% | Training loss: 0.6870193048759743
Epoch: 76 | Iteration number: [2440/4518] 54% | Training loss: 0.6870200221655799
Epoch: 76 | Iteration number: [2450/4518] 54% | Training loss: 0.6870112427400082
Epoch: 76 | Iteration number: [2460/4518] 54% | Training loss: 0.6870116704120869
Epoch: 76 | Iteration number: [2470/4518] 54% | Training loss: 0.687012930003255
Epoch: 76 | Iteration number: [2480/4518] 54% | Training loss: 0.6870098077241451
Epoch: 76 | Iteration number: [2490/4518] 55% | Training loss: 0.687012621724462
Epoch: 76 | Iteration number: [2500/4518] 55% | Training loss: 0.687012531709671
Epoch: 76 | Iteration number: [2510/4518] 55% | Training loss: 0.6870165802805547
Epoch: 76 | Iteration number: [2520/4518] 55% | Training loss: 0.6870080412380279
Epoch: 76 | Iteration number: [2530/4518] 55% | Training loss: 0.6870130608675508
Epoch: 76 | Iteration number: [2540/4518] 56% | Training loss: 0.6870164062798493
Epoch: 76 | Iteration number: [2550/4518] 56% | Training loss: 0.6870129829995772
Epoch: 76 | Iteration number: [2560/4518] 56% | Training loss: 0.6870148581918329
Epoch: 76 | Iteration number: [2570/4518] 56% | Training loss: 0.6870152414076987
Epoch: 76 | Iteration number: [2580/4518] 57% | Training loss: 0.687009998624639
Epoch: 76 | Iteration number: [2590/4518] 57% | Training loss: 0.6870136819520972
Epoch: 76 | Iteration number: [2600/4518] 57% | Training loss: 0.6870136866202721
Epoch: 76 | Iteration number: [2610/4518] 57% | Training loss: 0.6870120433783623
Epoch: 76 | Iteration number: [2620/4518] 57% | Training loss: 0.6870099684664311
Epoch: 76 | Iteration number: [2630/4518] 58% | Training loss: 0.6870032400006124
Epoch: 76 | Iteration number: [2640/4518] 58% | Training loss: 0.6870039793803836
Epoch: 76 | Iteration number: [2650/4518] 58% | Training loss: 0.6869950377491285
Epoch: 76 | Iteration number: [2660/4518] 58% | Training loss: 0.6869929393655375
Epoch: 76 | Iteration number: [2670/4518] 59% | Training loss: 0.6869925249605143
Epoch: 76 | Iteration number: [2680/4518] 59% | Training loss: 0.6869880807266306
Epoch: 76 | Iteration number: [2690/4518] 59% | Training loss: 0.6869840669144485
Epoch: 76 | Iteration number: [2700/4518] 59% | Training loss: 0.6869864829381307
Epoch: 76 | Iteration number: [2710/4518] 59% | Training loss: 0.6869917197201085
Epoch: 76 | Iteration number: [2720/4518] 60% | Training loss: 0.6869948656462571
Epoch: 76 | Iteration number: [2730/4518] 60% | Training loss: 0.6869967461505653
Epoch: 76 | Iteration number: [2740/4518] 60% | Training loss: 0.6869931068733661
Epoch: 76 | Iteration number: [2750/4518] 60% | Training loss: 0.6869908537214453
Epoch: 76 | Iteration number: [2760/4518] 61% | Training loss: 0.6869913769372995
Epoch: 76 | Iteration number: [2770/4518] 61% | Training loss: 0.6869875848938842
Epoch: 76 | Iteration number: [2780/4518] 61% | Training loss: 0.686985059200431
Epoch: 76 | Iteration number: [2790/4518] 61% | Training loss: 0.6869839354868859
Epoch: 76 | Iteration number: [2800/4518] 61% | Training loss: 0.686984447900738
Epoch: 76 | Iteration number: [2810/4518] 62% | Training loss: 0.6869822306565119
Epoch: 76 | Iteration number: [2820/4518] 62% | Training loss: 0.686984255656283
Epoch: 76 | Iteration number: [2830/4518] 62% | Training loss: 0.686987539378156
Epoch: 76 | Iteration number: [2840/4518] 62% | Training loss: 0.6869903328553052
Epoch: 76 | Iteration number: [2850/4518] 63% | Training loss: 0.6869908430701808
Epoch: 76 | Iteration number: [2860/4518] 63% | Training loss: 0.6869881605976945
Epoch: 76 | Iteration number: [2870/4518] 63% | Training loss: 0.6869870742231295
Epoch: 76 | Iteration number: [2880/4518] 63% | Training loss: 0.686985109684368
Epoch: 76 | Iteration number: [2890/4518] 63% | Training loss: 0.6869800688486198
Epoch: 76 | Iteration number: [2900/4518] 64% | Training loss: 0.6869747461738258
Epoch: 76 | Iteration number: [2910/4518] 64% | Training loss: 0.6869765869325789
Epoch: 76 | Iteration number: [2920/4518] 64% | Training loss: 0.6869723903397992
Epoch: 76 | Iteration number: [2930/4518] 64% | Training loss: 0.6869704174914051
Epoch: 76 | Iteration number: [2940/4518] 65% | Training loss: 0.686968460111391
Epoch: 76 | Iteration number: [2950/4518] 65% | Training loss: 0.6869662611363297
Epoch: 76 | Iteration number: [2960/4518] 65% | Training loss: 0.6869658982431567
Epoch: 76 | Iteration number: [2970/4518] 65% | Training loss: 0.6869672702217744
Epoch: 76 | Iteration number: [2980/4518] 65% | Training loss: 0.6869653122537088
Epoch: 76 | Iteration number: [2990/4518] 66% | Training loss: 0.6869615180436585
Epoch: 76 | Iteration number: [3000/4518] 66% | Training loss: 0.686966767569383
Epoch: 76 | Iteration number: [3010/4518] 66% | Training loss: 0.6869701216981261
Epoch: 76 | Iteration number: [3020/4518] 66% | Training loss: 0.6869714558519275
Epoch: 76 | Iteration number: [3030/4518] 67% | Training loss: 0.6869754420255277
Epoch: 76 | Iteration number: [3040/4518] 67% | Training loss: 0.6869808147808439
Epoch: 76 | Iteration number: [3050/4518] 67% | Training loss: 0.6869809840741705
Epoch: 76 | Iteration number: [3060/4518] 67% | Training loss: 0.6869793349816129
Epoch: 76 | Iteration number: [3070/4518] 67% | Training loss: 0.686979001178027
Epoch: 76 | Iteration number: [3080/4518] 68% | Training loss: 0.6869748435817755
Epoch: 76 | Iteration number: [3090/4518] 68% | Training loss: 0.6869768943601442
Epoch: 76 | Iteration number: [3100/4518] 68% | Training loss: 0.6869788108910284
Epoch: 76 | Iteration number: [3110/4518] 68% | Training loss: 0.68697774757143
Epoch: 76 | Iteration number: [3120/4518] 69% | Training loss: 0.6869773766169182
Epoch: 76 | Iteration number: [3130/4518] 69% | Training loss: 0.6869763511057478
Epoch: 76 | Iteration number: [3140/4518] 69% | Training loss: 0.6869732708118523
Epoch: 76 | Iteration number: [3150/4518] 69% | Training loss: 0.6869707339907449
Epoch: 76 | Iteration number: [3160/4518] 69% | Training loss: 0.6869684077327765
Epoch: 76 | Iteration number: [3170/4518] 70% | Training loss: 0.6869702583607815
Epoch: 76 | Iteration number: [3180/4518] 70% | Training loss: 0.686970121568104
Epoch: 76 | Iteration number: [3190/4518] 70% | Training loss: 0.6869698147041297
Epoch: 76 | Iteration number: [3200/4518] 70% | Training loss: 0.686967206299305
Epoch: 76 | Iteration number: [3210/4518] 71% | Training loss: 0.6869692733726026
Epoch: 76 | Iteration number: [3220/4518] 71% | Training loss: 0.6869693490289013
Epoch: 76 | Iteration number: [3230/4518] 71% | Training loss: 0.686969574667721
Epoch: 76 | Iteration number: [3240/4518] 71% | Training loss: 0.6869702388842901
Epoch: 76 | Iteration number: [3250/4518] 71% | Training loss: 0.6869728959890512
Epoch: 76 | Iteration number: [3260/4518] 72% | Training loss: 0.686971624131583
Epoch: 76 | Iteration number: [3270/4518] 72% | Training loss: 0.6869745369168961
Epoch: 76 | Iteration number: [3280/4518] 72% | Training loss: 0.686973755497758
Epoch: 76 | Iteration number: [3290/4518] 72% | Training loss: 0.6869747301365466
Epoch: 76 | Iteration number: [3300/4518] 73% | Training loss: 0.6869750200257156
Epoch: 76 | Iteration number: [3310/4518] 73% | Training loss: 0.6869746632446335
Epoch: 76 | Iteration number: [3320/4518] 73% | Training loss: 0.6869765555822706
Epoch: 76 | Iteration number: [3330/4518] 73% | Training loss: 0.6869770250162921
Epoch: 76 | Iteration number: [3340/4518] 73% | Training loss: 0.6869819325065898
Epoch: 76 | Iteration number: [3350/4518] 74% | Training loss: 0.6869803825065272
Epoch: 76 | Iteration number: [3360/4518] 74% | Training loss: 0.6869825597142889
Epoch: 76 | Iteration number: [3370/4518] 74% | Training loss: 0.6869837581757622
Epoch: 76 | Iteration number: [3380/4518] 74% | Training loss: 0.6869835948097636
Epoch: 76 | Iteration number: [3390/4518] 75% | Training loss: 0.6869800113822858
Epoch: 76 | Iteration number: [3400/4518] 75% | Training loss: 0.6869788503296235
Epoch: 76 | Iteration number: [3410/4518] 75% | Training loss: 0.686978645216335
Epoch: 76 | Iteration number: [3420/4518] 75% | Training loss: 0.6869761261500811
Epoch: 76 | Iteration number: [3430/4518] 75% | Training loss: 0.6869731500440714
Epoch: 76 | Iteration number: [3440/4518] 76% | Training loss: 0.6869733181110648
Epoch: 76 | Iteration number: [3450/4518] 76% | Training loss: 0.6869696261571802
Epoch: 76 | Iteration number: [3460/4518] 76% | Training loss: 0.6869653613236598
Epoch: 76 | Iteration number: [3470/4518] 76% | Training loss: 0.6869636859605223
Epoch: 76 | Iteration number: [3480/4518] 77% | Training loss: 0.68696522301641
Epoch: 76 | Iteration number: [3490/4518] 77% | Training loss: 0.68696702100486
Epoch: 76 | Iteration number: [3500/4518] 77% | Training loss: 0.6869664803402764
Epoch: 76 | Iteration number: [3510/4518] 77% | Training loss: 0.6869693700744216
Epoch: 76 | Iteration number: [3520/4518] 77% | Training loss: 0.6869720485061407
Epoch: 76 | Iteration number: [3530/4518] 78% | Training loss: 0.6869719186686929
Epoch: 76 | Iteration number: [3540/4518] 78% | Training loss: 0.686971869727986
Epoch: 76 | Iteration number: [3550/4518] 78% | Training loss: 0.6869738714292016
Epoch: 76 | Iteration number: [3560/4518] 78% | Training loss: 0.686970410621568
Epoch: 76 | Iteration number: [3570/4518] 79% | Training loss: 0.686969617735438
Epoch: 76 | Iteration number: [3580/4518] 79% | Training loss: 0.6869686932370649
Epoch: 76 | Iteration number: [3590/4518] 79% | Training loss: 0.6869693039187482
Epoch: 76 | Iteration number: [3600/4518] 79% | Training loss: 0.6869656728373633
Epoch: 76 | Iteration number: [3610/4518] 79% | Training loss: 0.6869645626591183
Epoch: 76 | Iteration number: [3620/4518] 80% | Training loss: 0.6869677086890732
Epoch: 76 | Iteration number: [3630/4518] 80% | Training loss: 0.6869679811736441
Epoch: 76 | Iteration number: [3640/4518] 80% | Training loss: 0.6869692043943719
Epoch: 76 | Iteration number: [3650/4518] 80% | Training loss: 0.6869674811624501
Epoch: 76 | Iteration number: [3660/4518] 81% | Training loss: 0.6869674647766384
Epoch: 76 | Iteration number: [3670/4518] 81% | Training loss: 0.6869667106818114
Epoch: 76 | Iteration number: [3680/4518] 81% | Training loss: 0.6869638395050298
Epoch: 76 | Iteration number: [3690/4518] 81% | Training loss: 0.6869616488777202
Epoch: 76 | Iteration number: [3700/4518] 81% | Training loss: 0.6869609196121628
Epoch: 76 | Iteration number: [3710/4518] 82% | Training loss: 0.686959822383531
Epoch: 76 | Iteration number: [3720/4518] 82% | Training loss: 0.6869589619899309
Epoch: 76 | Iteration number: [3730/4518] 82% | Training loss: 0.6869571401350619
Epoch: 76 | Iteration number: [3740/4518] 82% | Training loss: 0.6869563018893176
Epoch: 76 | Iteration number: [3750/4518] 83% | Training loss: 0.6869566961924235
Epoch: 76 | Iteration number: [3760/4518] 83% | Training loss: 0.6869590296707255
Epoch: 76 | Iteration number: [3770/4518] 83% | Training loss: 0.686953021850763
Epoch: 76 | Iteration number: [3780/4518] 83% | Training loss: 0.6869503400786213
Epoch: 76 | Iteration number: [3790/4518] 83% | Training loss: 0.6869479168845355
Epoch: 76 | Iteration number: [3800/4518] 84% | Training loss: 0.686950015566851
Epoch: 76 | Iteration number: [3810/4518] 84% | Training loss: 0.6869511469924857
Epoch: 76 | Iteration number: [3820/4518] 84% | Training loss: 0.6869501463561782
Epoch: 76 | Iteration number: [3830/4518] 84% | Training loss: 0.6869489507015318
Epoch: 76 | Iteration number: [3840/4518] 84% | Training loss: 0.6869467321007202
Epoch: 76 | Iteration number: [3850/4518] 85% | Training loss: 0.6869428353805047
Epoch: 76 | Iteration number: [3860/4518] 85% | Training loss: 0.6869454838760158
Epoch: 76 | Iteration number: [3870/4518] 85% | Training loss: 0.6869425230710081
Epoch: 76 | Iteration number: [3880/4518] 85% | Training loss: 0.6869433975250451
Epoch: 76 | Iteration number: [3890/4518] 86% | Training loss: 0.686940960053613
Epoch: 76 | Iteration number: [3900/4518] 86% | Training loss: 0.6869384190516594
Epoch: 76 | Iteration number: [3910/4518] 86% | Training loss: 0.686936954753783
Epoch: 76 | Iteration number: [3920/4518] 86% | Training loss: 0.6869365925539513
Epoch: 76 | Iteration number: [3930/4518] 86% | Training loss: 0.6869337847669617
Epoch: 76 | Iteration number: [3940/4518] 87% | Training loss: 0.6869353055197576
Epoch: 76 | Iteration number: [3950/4518] 87% | Training loss: 0.6869326520267921
Epoch: 76 | Iteration number: [3960/4518] 87% | Training loss: 0.6869318449286499
Epoch: 76 | Iteration number: [3970/4518] 87% | Training loss: 0.6869317497204173
Epoch: 76 | Iteration number: [3980/4518] 88% | Training loss: 0.6869312871640652
Epoch: 76 | Iteration number: [3990/4518] 88% | Training loss: 0.686930963718204
Epoch: 76 | Iteration number: [4000/4518] 88% | Training loss: 0.6869244184046984
Epoch: 76 | Iteration number: [4010/4518] 88% | Training loss: 0.6869230580448807
Epoch: 76 | Iteration number: [4020/4518] 88% | Training loss: 0.6869231809875859
Epoch: 76 | Iteration number: [4030/4518] 89% | Training loss: 0.6869207914650588
Epoch: 76 | Iteration number: [4040/4518] 89% | Training loss: 0.6869186523527202
Epoch: 76 | Iteration number: [4050/4518] 89% | Training loss: 0.6869148763609522
Epoch: 76 | Iteration number: [4060/4518] 89% | Training loss: 0.6869119398112368
Epoch: 76 | Iteration number: [4070/4518] 90% | Training loss: 0.6869114745454061
Epoch: 76 | Iteration number: [4080/4518] 90% | Training loss: 0.686912461194922
Epoch: 76 | Iteration number: [4090/4518] 90% | Training loss: 0.6869140662890483
Epoch: 76 | Iteration number: [4100/4518] 90% | Training loss: 0.6869130350031504
Epoch: 76 | Iteration number: [4110/4518] 90% | Training loss: 0.686912654815219
Epoch: 76 | Iteration number: [4120/4518] 91% | Training loss: 0.6869141776295542
Epoch: 76 | Iteration number: [4130/4518] 91% | Training loss: 0.6869167527044079
Epoch: 76 | Iteration number: [4140/4518] 91% | Training loss: 0.6869184946380376
Epoch: 76 | Iteration number: [4150/4518] 91% | Training loss: 0.6869169913286186
Epoch: 76 | Iteration number: [4160/4518] 92% | Training loss: 0.6869157911779789
Epoch: 76 | Iteration number: [4170/4518] 92% | Training loss: 0.6869181572104529
Epoch: 76 | Iteration number: [4180/4518] 92% | Training loss: 0.6869166449211431
Epoch: 76 | Iteration number: [4190/4518] 92% | Training loss: 0.6869182605305264
Epoch: 76 | Iteration number: [4200/4518] 92% | Training loss: 0.6869192531562986
Epoch: 76 | Iteration number: [4210/4518] 93% | Training loss: 0.6869196878476267
Epoch: 76 | Iteration number: [4220/4518] 93% | Training loss: 0.6869202434169173
Epoch: 76 | Iteration number: [4230/4518] 93% | Training loss: 0.6869231682719914
Epoch: 76 | Iteration number: [4240/4518] 93% | Training loss: 0.6869218550481886
Epoch: 76 | Iteration number: [4250/4518] 94% | Training loss: 0.6869196134174571
Epoch: 76 | Iteration number: [4260/4518] 94% | Training loss: 0.6869197577238083
Epoch: 76 | Iteration number: [4270/4518] 94% | Training loss: 0.6869176439993275
Epoch: 76 | Iteration number: [4280/4518] 94% | Training loss: 0.6869170615884745
Epoch: 76 | Iteration number: [4290/4518] 94% | Training loss: 0.686915606913311
Epoch: 76 | Iteration number: [4300/4518] 95% | Training loss: 0.6869171120538268
Epoch: 76 | Iteration number: [4310/4518] 95% | Training loss: 0.6869186784441123
Epoch: 76 | Iteration number: [4320/4518] 95% | Training loss: 0.6869169590373834
Epoch: 76 | Iteration number: [4330/4518] 95% | Training loss: 0.6869176703154628
Epoch: 76 | Iteration number: [4340/4518] 96% | Training loss: 0.6869220271363237
Epoch: 76 | Iteration number: [4350/4518] 96% | Training loss: 0.6869182666416825
Epoch: 76 | Iteration number: [4360/4518] 96% | Training loss: 0.6869147778787744
Epoch: 76 | Iteration number: [4370/4518] 96% | Training loss: 0.6869154998994256
Epoch: 76 | Iteration number: [4380/4518] 96% | Training loss: 0.6869149329727643
Epoch: 76 | Iteration number: [4390/4518] 97% | Training loss: 0.6869133261178784
Epoch: 76 | Iteration number: [4400/4518] 97% | Training loss: 0.6869140773334287
Epoch: 76 | Iteration number: [4410/4518] 97% | Training loss: 0.6869150681290227
Epoch: 76 | Iteration number: [4420/4518] 97% | Training loss: 0.6869155084115887
Epoch: 76 | Iteration number: [4430/4518] 98% | Training loss: 0.6869149425228885
Epoch: 76 | Iteration number: [4440/4518] 98% | Training loss: 0.6869120176713746
Epoch: 76 | Iteration number: [4450/4518] 98% | Training loss: 0.6869129147154561
Epoch: 76 | Iteration number: [4460/4518] 98% | Training loss: 0.6869152363239382
Epoch: 76 | Iteration number: [4470/4518] 98% | Training loss: 0.68691445505059
Epoch: 76 | Iteration number: [4480/4518] 99% | Training loss: 0.6869165111599224
Epoch: 76 | Iteration number: [4490/4518] 99% | Training loss: 0.6869160630655182
Epoch: 76 | Iteration number: [4500/4518] 99% | Training loss: 0.6869174570375018
Epoch: 76 | Iteration number: [4510/4518] 99% | Training loss: 0.6869189882357739

 End of epoch: 76 | Train Loss: 0.6867672023439682 | Training Time: 634 

 End of epoch: 76 | Eval Loss: 0.6896222221608065 | Evaluating Time: 17 
Epoch: 77 | Iteration number: [10/4518] 0% | Training loss: 0.7554180741310119
Epoch: 77 | Iteration number: [20/4518] 0% | Training loss: 0.7210319072008133
Epoch: 77 | Iteration number: [30/4518] 0% | Training loss: 0.7090189735094706
Epoch: 77 | Iteration number: [40/4518] 0% | Training loss: 0.7035755395889283
Epoch: 77 | Iteration number: [50/4518] 1% | Training loss: 0.7001358807086945
Epoch: 77 | Iteration number: [60/4518] 1% | Training loss: 0.6978591670592625
Epoch: 77 | Iteration number: [70/4518] 1% | Training loss: 0.69630931190082
Epoch: 77 | Iteration number: [80/4518] 1% | Training loss: 0.6951820023357869
Epoch: 77 | Iteration number: [90/4518] 1% | Training loss: 0.6941774838500553
Epoch: 77 | Iteration number: [100/4518] 2% | Training loss: 0.6932514065504074
Epoch: 77 | Iteration number: [110/4518] 2% | Training loss: 0.6927102917974646
Epoch: 77 | Iteration number: [120/4518] 2% | Training loss: 0.6922227640946707
Epoch: 77 | Iteration number: [130/4518] 2% | Training loss: 0.6917507543013646
Epoch: 77 | Iteration number: [140/4518] 3% | Training loss: 0.6913770343576159
Epoch: 77 | Iteration number: [150/4518] 3% | Training loss: 0.6910380474726359
Epoch: 77 | Iteration number: [160/4518] 3% | Training loss: 0.6908399559557438
Epoch: 77 | Iteration number: [170/4518] 3% | Training loss: 0.6904678071246427
Epoch: 77 | Iteration number: [180/4518] 3% | Training loss: 0.6903296828269958
Epoch: 77 | Iteration number: [190/4518] 4% | Training loss: 0.6900930025075611
Epoch: 77 | Iteration number: [200/4518] 4% | Training loss: 0.6898750349879265
Epoch: 77 | Iteration number: [210/4518] 4% | Training loss: 0.6897513744376954
Epoch: 77 | Iteration number: [220/4518] 4% | Training loss: 0.6896044278686697
Epoch: 77 | Iteration number: [230/4518] 5% | Training loss: 0.6894614312959754
Epoch: 77 | Iteration number: [240/4518] 5% | Training loss: 0.6893219721813997
Epoch: 77 | Iteration number: [250/4518] 5% | Training loss: 0.689199066400528
Epoch: 77 | Iteration number: [260/4518] 5% | Training loss: 0.6891359395705736
Epoch: 77 | Iteration number: [270/4518] 5% | Training loss: 0.6890170602886765
Epoch: 77 | Iteration number: [280/4518] 6% | Training loss: 0.6889547288417817
Epoch: 77 | Iteration number: [290/4518] 6% | Training loss: 0.6888669910102055
Epoch: 77 | Iteration number: [300/4518] 6% | Training loss: 0.6888170899947484
Epoch: 77 | Iteration number: [310/4518] 6% | Training loss: 0.6887342154979705
Epoch: 77 | Iteration number: [320/4518] 7% | Training loss: 0.6886825622990728
Epoch: 77 | Iteration number: [330/4518] 7% | Training loss: 0.688648897228819
Epoch: 77 | Iteration number: [340/4518] 7% | Training loss: 0.6886064732775968
Epoch: 77 | Iteration number: [350/4518] 7% | Training loss: 0.6885458595412118
Epoch: 77 | Iteration number: [360/4518] 7% | Training loss: 0.6884927115506596
Epoch: 77 | Iteration number: [370/4518] 8% | Training loss: 0.6884405931910953
Epoch: 77 | Iteration number: [380/4518] 8% | Training loss: 0.6884022552716105
Epoch: 77 | Iteration number: [390/4518] 8% | Training loss: 0.6883470171537155
Epoch: 77 | Iteration number: [400/4518] 8% | Training loss: 0.6883243595063686
Epoch: 77 | Iteration number: [410/4518] 9% | Training loss: 0.6882865238480451
Epoch: 77 | Iteration number: [420/4518] 9% | Training loss: 0.6882682722239267
Epoch: 77 | Iteration number: [430/4518] 9% | Training loss: 0.6882275629875272
Epoch: 77 | Iteration number: [440/4518] 9% | Training loss: 0.6882047901099378
Epoch: 77 | Iteration number: [450/4518] 9% | Training loss: 0.6882009862528907
Epoch: 77 | Iteration number: [460/4518] 10% | Training loss: 0.6881871917973394
Epoch: 77 | Iteration number: [470/4518] 10% | Training loss: 0.6881670466128816
Epoch: 77 | Iteration number: [480/4518] 10% | Training loss: 0.688115943223238
Epoch: 77 | Iteration number: [490/4518] 10% | Training loss: 0.6880806495948714
Epoch: 77 | Iteration number: [500/4518] 11% | Training loss: 0.6880184670686722
Epoch: 77 | Iteration number: [510/4518] 11% | Training loss: 0.687989716202605
Epoch: 77 | Iteration number: [520/4518] 11% | Training loss: 0.6879777398246986
Epoch: 77 | Iteration number: [530/4518] 11% | Training loss: 0.6879604584765884
Epoch: 77 | Iteration number: [540/4518] 11% | Training loss: 0.6879407157500584
Epoch: 77 | Iteration number: [550/4518] 12% | Training loss: 0.6879006532105533
Epoch: 77 | Iteration number: [560/4518] 12% | Training loss: 0.6878789063010897
Epoch: 77 | Iteration number: [570/4518] 12% | Training loss: 0.6878621840686129
Epoch: 77 | Iteration number: [580/4518] 12% | Training loss: 0.6878496523561148
Epoch: 77 | Iteration number: [590/4518] 13% | Training loss: 0.6878353855367434
Epoch: 77 | Iteration number: [600/4518] 13% | Training loss: 0.6878142035007477
Epoch: 77 | Iteration number: [610/4518] 13% | Training loss: 0.6877975254762368
Epoch: 77 | Iteration number: [620/4518] 13% | Training loss: 0.6877666199399579
Epoch: 77 | Iteration number: [630/4518] 13% | Training loss: 0.687749308347702
Epoch: 77 | Iteration number: [640/4518] 14% | Training loss: 0.6877409040927887
Epoch: 77 | Iteration number: [650/4518] 14% | Training loss: 0.6877399162145761
Epoch: 77 | Iteration number: [660/4518] 14% | Training loss: 0.6877338460900567
Epoch: 77 | Iteration number: [670/4518] 14% | Training loss: 0.6877216947612478
Epoch: 77 | Iteration number: [680/4518] 15% | Training loss: 0.6877023124519517
Epoch: 77 | Iteration number: [690/4518] 15% | Training loss: 0.6876930072687675
Epoch: 77 | Iteration number: [700/4518] 15% | Training loss: 0.6876626345089504
Epoch: 77 | Iteration number: [710/4518] 15% | Training loss: 0.6876413568644456
Epoch: 77 | Iteration number: [720/4518] 15% | Training loss: 0.6876321285963058
Epoch: 77 | Iteration number: [730/4518] 16% | Training loss: 0.687634933158143
Epoch: 77 | Iteration number: [740/4518] 16% | Training loss: 0.6876243720183501
Epoch: 77 | Iteration number: [750/4518] 16% | Training loss: 0.6876170755227407
Epoch: 77 | Iteration number: [760/4518] 16% | Training loss: 0.6875962922447606
Epoch: 77 | Iteration number: [770/4518] 17% | Training loss: 0.6875842144736996
Epoch: 77 | Iteration number: [780/4518] 17% | Training loss: 0.6875719952277648
Epoch: 77 | Iteration number: [790/4518] 17% | Training loss: 0.6875572503367556
Epoch: 77 | Iteration number: [800/4518] 17% | Training loss: 0.6875537673383951
Epoch: 77 | Iteration number: [810/4518] 17% | Training loss: 0.6875460817490096
Epoch: 77 | Iteration number: [820/4518] 18% | Training loss: 0.6875376164913177
Epoch: 77 | Iteration number: [830/4518] 18% | Training loss: 0.6875200759215527
Epoch: 77 | Iteration number: [840/4518] 18% | Training loss: 0.6875045252697808
Epoch: 77 | Iteration number: [850/4518] 18% | Training loss: 0.6874711324186886
Epoch: 77 | Iteration number: [860/4518] 19% | Training loss: 0.6874692841324695
Epoch: 77 | Iteration number: [870/4518] 19% | Training loss: 0.6874684459861667
Epoch: 77 | Iteration number: [880/4518] 19% | Training loss: 0.6874687215143984
Epoch: 77 | Iteration number: [890/4518] 19% | Training loss: 0.6874751697765308
Epoch: 77 | Iteration number: [900/4518] 19% | Training loss: 0.6874654503663381
Epoch: 77 | Iteration number: [910/4518] 20% | Training loss: 0.6874587057711004
Epoch: 77 | Iteration number: [920/4518] 20% | Training loss: 0.6874493582093197
Epoch: 77 | Iteration number: [930/4518] 20% | Training loss: 0.6874421037012531
Epoch: 77 | Iteration number: [940/4518] 20% | Training loss: 0.6874382941646778
Epoch: 77 | Iteration number: [950/4518] 21% | Training loss: 0.6874340982186167
Epoch: 77 | Iteration number: [960/4518] 21% | Training loss: 0.6874249548340837
Epoch: 77 | Iteration number: [970/4518] 21% | Training loss: 0.6874108819002958
Epoch: 77 | Iteration number: [980/4518] 21% | Training loss: 0.6874024232431334
Epoch: 77 | Iteration number: [990/4518] 21% | Training loss: 0.6873871001932356
Epoch: 77 | Iteration number: [1000/4518] 22% | Training loss: 0.6873941943049431
Epoch: 77 | Iteration number: [1010/4518] 22% | Training loss: 0.6873843268592759
Epoch: 77 | Iteration number: [1020/4518] 22% | Training loss: 0.6873791785801158
Epoch: 77 | Iteration number: [1030/4518] 22% | Training loss: 0.6873912575175462
Epoch: 77 | Iteration number: [1040/4518] 23% | Training loss: 0.6873881439750011
Epoch: 77 | Iteration number: [1050/4518] 23% | Training loss: 0.6873909601143429
Epoch: 77 | Iteration number: [1060/4518] 23% | Training loss: 0.6873942259909972
Epoch: 77 | Iteration number: [1070/4518] 23% | Training loss: 0.6873817267818986
Epoch: 77 | Iteration number: [1080/4518] 23% | Training loss: 0.6873757460051113
Epoch: 77 | Iteration number: [1090/4518] 24% | Training loss: 0.6873633167065611
Epoch: 77 | Iteration number: [1100/4518] 24% | Training loss: 0.6873552321303974
Epoch: 77 | Iteration number: [1110/4518] 24% | Training loss: 0.6873385088937777
Epoch: 77 | Iteration number: [1120/4518] 24% | Training loss: 0.687323648216469
Epoch: 77 | Iteration number: [1130/4518] 25% | Training loss: 0.6873203132004865
Epoch: 77 | Iteration number: [1140/4518] 25% | Training loss: 0.6873286555733598
Epoch: 77 | Iteration number: [1150/4518] 25% | Training loss: 0.6873298490565756
Epoch: 77 | Iteration number: [1160/4518] 25% | Training loss: 0.6873203472844486
Epoch: 77 | Iteration number: [1170/4518] 25% | Training loss: 0.6873118792334173
Epoch: 77 | Iteration number: [1180/4518] 26% | Training loss: 0.6873090044421665
Epoch: 77 | Iteration number: [1190/4518] 26% | Training loss: 0.6873036382078123
Epoch: 77 | Iteration number: [1200/4518] 26% | Training loss: 0.6872907025615375
Epoch: 77 | Iteration number: [1210/4518] 26% | Training loss: 0.6872764432233227
Epoch: 77 | Iteration number: [1220/4518] 27% | Training loss: 0.6872762694222028
Epoch: 77 | Iteration number: [1230/4518] 27% | Training loss: 0.6872716564473098
Epoch: 77 | Iteration number: [1240/4518] 27% | Training loss: 0.6872660344646823
Epoch: 77 | Iteration number: [1250/4518] 27% | Training loss: 0.6872655519485473
Epoch: 77 | Iteration number: [1260/4518] 27% | Training loss: 0.6872575268858955
Epoch: 77 | Iteration number: [1270/4518] 28% | Training loss: 0.6872616794165664
Epoch: 77 | Iteration number: [1280/4518] 28% | Training loss: 0.6872527346480638
Epoch: 77 | Iteration number: [1290/4518] 28% | Training loss: 0.6872408095256303
Epoch: 77 | Iteration number: [1300/4518] 28% | Training loss: 0.6872377411677287
Epoch: 77 | Iteration number: [1310/4518] 28% | Training loss: 0.6872333708155246
Epoch: 77 | Iteration number: [1320/4518] 29% | Training loss: 0.687236553204782
Epoch: 77 | Iteration number: [1330/4518] 29% | Training loss: 0.6872374413605024
Epoch: 77 | Iteration number: [1340/4518] 29% | Training loss: 0.687235761400479
Epoch: 77 | Iteration number: [1350/4518] 29% | Training loss: 0.6872305802062706
Epoch: 77 | Iteration number: [1360/4518] 30% | Training loss: 0.6872221554026884
Epoch: 77 | Iteration number: [1370/4518] 30% | Training loss: 0.6872243959103187
Epoch: 77 | Iteration number: [1380/4518] 30% | Training loss: 0.6872205559758172
Epoch: 77 | Iteration number: [1390/4518] 30% | Training loss: 0.6872117525382008
Epoch: 77 | Iteration number: [1400/4518] 30% | Training loss: 0.6872137051820755
Epoch: 77 | Iteration number: [1410/4518] 31% | Training loss: 0.6872119972469113
Epoch: 77 | Iteration number: [1420/4518] 31% | Training loss: 0.6872152365849051
Epoch: 77 | Iteration number: [1430/4518] 31% | Training loss: 0.687215060120696
Epoch: 77 | Iteration number: [1440/4518] 31% | Training loss: 0.6872093627850214
Epoch: 77 | Iteration number: [1450/4518] 32% | Training loss: 0.6872004715327559
Epoch: 77 | Iteration number: [1460/4518] 32% | Training loss: 0.6871925967605147
Epoch: 77 | Iteration number: [1470/4518] 32% | Training loss: 0.6872010411048423
Epoch: 77 | Iteration number: [1480/4518] 32% | Training loss: 0.6872020852726859
Epoch: 77 | Iteration number: [1490/4518] 32% | Training loss: 0.687199076270097
Epoch: 77 | Iteration number: [1500/4518] 33% | Training loss: 0.6872047321399053
Epoch: 77 | Iteration number: [1510/4518] 33% | Training loss: 0.6872054046352968
Epoch: 77 | Iteration number: [1520/4518] 33% | Training loss: 0.6872005284616821
Epoch: 77 | Iteration number: [1530/4518] 33% | Training loss: 0.6871929963429769
Epoch: 77 | Iteration number: [1540/4518] 34% | Training loss: 0.6871859168464487
Epoch: 77 | Iteration number: [1550/4518] 34% | Training loss: 0.6871879762218844
Epoch: 77 | Iteration number: [1560/4518] 34% | Training loss: 0.6871863127518922
Epoch: 77 | Iteration number: [1570/4518] 34% | Training loss: 0.6871743565152405
Epoch: 77 | Iteration number: [1580/4518] 34% | Training loss: 0.6871632512234435
Epoch: 77 | Iteration number: [1590/4518] 35% | Training loss: 0.6871636290595217
Epoch: 77 | Iteration number: [1600/4518] 35% | Training loss: 0.6871580531075597
Epoch: 77 | Iteration number: [1610/4518] 35% | Training loss: 0.6871554812659388
Epoch: 77 | Iteration number: [1620/4518] 35% | Training loss: 0.6871492910900233
Epoch: 77 | Iteration number: [1630/4518] 36% | Training loss: 0.6871487692455572
Epoch: 77 | Iteration number: [1640/4518] 36% | Training loss: 0.687146613074512
Epoch: 77 | Iteration number: [1650/4518] 36% | Training loss: 0.6871453235727368
Epoch: 77 | Iteration number: [1660/4518] 36% | Training loss: 0.6871442859431347
Epoch: 77 | Iteration number: [1670/4518] 36% | Training loss: 0.6871396008722797
Epoch: 77 | Iteration number: [1680/4518] 37% | Training loss: 0.687141364032314
Epoch: 77 | Iteration number: [1690/4518] 37% | Training loss: 0.6871326690242135
Epoch: 77 | Iteration number: [1700/4518] 37% | Training loss: 0.6871286014248343
Epoch: 77 | Iteration number: [1710/4518] 37% | Training loss: 0.6871158773787538
Epoch: 77 | Iteration number: [1720/4518] 38% | Training loss: 0.687113862883213
Epoch: 77 | Iteration number: [1730/4518] 38% | Training loss: 0.6871157301299144
Epoch: 77 | Iteration number: [1740/4518] 38% | Training loss: 0.687119706780061
Epoch: 77 | Iteration number: [1750/4518] 38% | Training loss: 0.687124329158238
Epoch: 77 | Iteration number: [1760/4518] 38% | Training loss: 0.687123023413799
Epoch: 77 | Iteration number: [1770/4518] 39% | Training loss: 0.6871197887733158
Epoch: 77 | Iteration number: [1780/4518] 39% | Training loss: 0.6871102591244023
Epoch: 77 | Iteration number: [1790/4518] 39% | Training loss: 0.6871170295017391
Epoch: 77 | Iteration number: [1800/4518] 39% | Training loss: 0.687118858926826
Epoch: 77 | Iteration number: [1810/4518] 40% | Training loss: 0.6871179444355201
Epoch: 77 | Iteration number: [1820/4518] 40% | Training loss: 0.6871051862999633
Epoch: 77 | Iteration number: [1830/4518] 40% | Training loss: 0.6870998195611714
Epoch: 77 | Iteration number: [1840/4518] 40% | Training loss: 0.6870907035534797
Epoch: 77 | Iteration number: [1850/4518] 40% | Training loss: 0.6870883586600021
Epoch: 77 | Iteration number: [1860/4518] 41% | Training loss: 0.6870818260215944
Epoch: 77 | Iteration number: [1870/4518] 41% | Training loss: 0.6870817668297712
Epoch: 77 | Iteration number: [1880/4518] 41% | Training loss: 0.6870804530826021
Epoch: 77 | Iteration number: [1890/4518] 41% | Training loss: 0.6870854118198314
Epoch: 77 | Iteration number: [1900/4518] 42% | Training loss: 0.6870927807845567
Epoch: 77 | Iteration number: [1910/4518] 42% | Training loss: 0.687091539417886
Epoch: 77 | Iteration number: [1920/4518] 42% | Training loss: 0.6870913616381585
Epoch: 77 | Iteration number: [1930/4518] 42% | Training loss: 0.6870838927481459
Epoch: 77 | Iteration number: [1940/4518] 42% | Training loss: 0.6870806123178029
Epoch: 77 | Iteration number: [1950/4518] 43% | Training loss: 0.6870757019825471
Epoch: 77 | Iteration number: [1960/4518] 43% | Training loss: 0.6870762170881641
Epoch: 77 | Iteration number: [1970/4518] 43% | Training loss: 0.6870702127817319
Epoch: 77 | Iteration number: [1980/4518] 43% | Training loss: 0.687068592087187
Epoch: 77 | Iteration number: [1990/4518] 44% | Training loss: 0.6870590983024195
Epoch: 77 | Iteration number: [2000/4518] 44% | Training loss: 0.6870557710528373
Epoch: 77 | Iteration number: [2010/4518] 44% | Training loss: 0.6870556945527964
Epoch: 77 | Iteration number: [2020/4518] 44% | Training loss: 0.6870599726934244
Epoch: 77 | Iteration number: [2030/4518] 44% | Training loss: 0.6870628708101846
Epoch: 77 | Iteration number: [2040/4518] 45% | Training loss: 0.6870637483748735
Epoch: 77 | Iteration number: [2050/4518] 45% | Training loss: 0.6870608370187806
Epoch: 77 | Iteration number: [2060/4518] 45% | Training loss: 0.6870605644670505
Epoch: 77 | Iteration number: [2070/4518] 45% | Training loss: 0.6870584394044922
Epoch: 77 | Iteration number: [2080/4518] 46% | Training loss: 0.687059843282287
Epoch: 77 | Iteration number: [2090/4518] 46% | Training loss: 0.6870566436548552
Epoch: 77 | Iteration number: [2100/4518] 46% | Training loss: 0.6870609582038153
Epoch: 77 | Iteration number: [2110/4518] 46% | Training loss: 0.6870634545647137
Epoch: 77 | Iteration number: [2120/4518] 46% | Training loss: 0.6870613811151036
Epoch: 77 | Iteration number: [2130/4518] 47% | Training loss: 0.6870550814648749
Epoch: 77 | Iteration number: [2140/4518] 47% | Training loss: 0.6870561720333367
Epoch: 77 | Iteration number: [2150/4518] 47% | Training loss: 0.6870558813560841
Epoch: 77 | Iteration number: [2160/4518] 47% | Training loss: 0.6870503645252298
Epoch: 77 | Iteration number: [2170/4518] 48% | Training loss: 0.6870470542786857
Epoch: 77 | Iteration number: [2180/4518] 48% | Training loss: 0.6870439066252577
Epoch: 77 | Iteration number: [2190/4518] 48% | Training loss: 0.6870445327671696
Epoch: 77 | Iteration number: [2200/4518] 48% | Training loss: 0.6870463358543136
Epoch: 77 | Iteration number: [2210/4518] 48% | Training loss: 0.6870487910050612
Epoch: 77 | Iteration number: [2220/4518] 49% | Training loss: 0.6870457609226038
Epoch: 77 | Iteration number: [2230/4518] 49% | Training loss: 0.6870472134496064
Epoch: 77 | Iteration number: [2240/4518] 49% | Training loss: 0.6870487043101873
Epoch: 77 | Iteration number: [2250/4518] 49% | Training loss: 0.6870443243715498
Epoch: 77 | Iteration number: [2260/4518] 50% | Training loss: 0.6870371999202577
Epoch: 77 | Iteration number: [2270/4518] 50% | Training loss: 0.6870355951891072
Epoch: 77 | Iteration number: [2280/4518] 50% | Training loss: 0.6870377699534098
Epoch: 77 | Iteration number: [2290/4518] 50% | Training loss: 0.687034066431387
Epoch: 77 | Iteration number: [2300/4518] 50% | Training loss: 0.6870359574711841
Epoch: 77 | Iteration number: [2310/4518] 51% | Training loss: 0.6870313235433587
Epoch: 77 | Iteration number: [2320/4518] 51% | Training loss: 0.6870257366320183
Epoch: 77 | Iteration number: [2330/4518] 51% | Training loss: 0.6870219962279684
Epoch: 77 | Iteration number: [2340/4518] 51% | Training loss: 0.6870253597569261
Epoch: 77 | Iteration number: [2350/4518] 52% | Training loss: 0.6870191211142439
Epoch: 77 | Iteration number: [2360/4518] 52% | Training loss: 0.6870241091160451
Epoch: 77 | Iteration number: [2370/4518] 52% | Training loss: 0.6870246965925402
Epoch: 77 | Iteration number: [2380/4518] 52% | Training loss: 0.6870259887781464
Epoch: 77 | Iteration number: [2390/4518] 52% | Training loss: 0.6870301507008125
Epoch: 77 | Iteration number: [2400/4518] 53% | Training loss: 0.6870241717249155
Epoch: 77 | Iteration number: [2410/4518] 53% | Training loss: 0.6870254658564492
Epoch: 77 | Iteration number: [2420/4518] 53% | Training loss: 0.687023186880695
Epoch: 77 | Iteration number: [2430/4518] 53% | Training loss: 0.6870270131301487
Epoch: 77 | Iteration number: [2440/4518] 54% | Training loss: 0.687026183160602
Epoch: 77 | Iteration number: [2450/4518] 54% | Training loss: 0.6870252178153213
Epoch: 77 | Iteration number: [2460/4518] 54% | Training loss: 0.6870261719556359
Epoch: 77 | Iteration number: [2470/4518] 54% | Training loss: 0.6870244394188468
Epoch: 77 | Iteration number: [2480/4518] 54% | Training loss: 0.6870218701660633
Epoch: 77 | Iteration number: [2490/4518] 55% | Training loss: 0.6870183583244263
Epoch: 77 | Iteration number: [2500/4518] 55% | Training loss: 0.6870217082500458
Epoch: 77 | Iteration number: [2510/4518] 55% | Training loss: 0.6870229977060599
Epoch: 77 | Iteration number: [2520/4518] 55% | Training loss: 0.687019598767871
Epoch: 77 | Iteration number: [2530/4518] 55% | Training loss: 0.6870155757830548
Epoch: 77 | Iteration number: [2540/4518] 56% | Training loss: 0.6870136218277488
Epoch: 77 | Iteration number: [2550/4518] 56% | Training loss: 0.6870165119217891
Epoch: 77 | Iteration number: [2560/4518] 56% | Training loss: 0.6870185277424753
Epoch: 77 | Iteration number: [2570/4518] 56% | Training loss: 0.6870135720137956
Epoch: 77 | Iteration number: [2580/4518] 57% | Training loss: 0.6870135928309241
Epoch: 77 | Iteration number: [2590/4518] 57% | Training loss: 0.6870119613570136
Epoch: 77 | Iteration number: [2600/4518] 57% | Training loss: 0.6870133071908584
Epoch: 77 | Iteration number: [2610/4518] 57% | Training loss: 0.6870092295595512
Epoch: 77 | Iteration number: [2620/4518] 57% | Training loss: 0.6870067750907126
Epoch: 77 | Iteration number: [2630/4518] 58% | Training loss: 0.6870077568995182
Epoch: 77 | Iteration number: [2640/4518] 58% | Training loss: 0.6870051662127177
Epoch: 77 | Iteration number: [2650/4518] 58% | Training loss: 0.6870035490000023
Epoch: 77 | Iteration number: [2660/4518] 58% | Training loss: 0.6869984203935566
Epoch: 77 | Iteration number: [2670/4518] 59% | Training loss: 0.686997070272317
Epoch: 77 | Iteration number: [2680/4518] 59% | Training loss: 0.687000327212597
Epoch: 77 | Iteration number: [2690/4518] 59% | Training loss: 0.6870017133237704
Epoch: 77 | Iteration number: [2700/4518] 59% | Training loss: 0.6869995045661926
Epoch: 77 | Iteration number: [2710/4518] 59% | Training loss: 0.6869995293362114
Epoch: 77 | Iteration number: [2720/4518] 60% | Training loss: 0.6870000532006516
Epoch: 77 | Iteration number: [2730/4518] 60% | Training loss: 0.6869985467130011
Epoch: 77 | Iteration number: [2740/4518] 60% | Training loss: 0.6870019457636088
Epoch: 77 | Iteration number: [2750/4518] 60% | Training loss: 0.6870001638152382
Epoch: 77 | Iteration number: [2760/4518] 61% | Training loss: 0.6870015741042469
Epoch: 77 | Iteration number: [2770/4518] 61% | Training loss: 0.6869966805626769
Epoch: 77 | Iteration number: [2780/4518] 61% | Training loss: 0.6869933506138891
Epoch: 77 | Iteration number: [2790/4518] 61% | Training loss: 0.6869911651671147
Epoch: 77 | Iteration number: [2800/4518] 61% | Training loss: 0.6869924557421888
Epoch: 77 | Iteration number: [2810/4518] 62% | Training loss: 0.68699212195186
Epoch: 77 | Iteration number: [2820/4518] 62% | Training loss: 0.686990542741532
Epoch: 77 | Iteration number: [2830/4518] 62% | Training loss: 0.6869894900507304
Epoch: 77 | Iteration number: [2840/4518] 62% | Training loss: 0.6869897801061751
Epoch: 77 | Iteration number: [2850/4518] 63% | Training loss: 0.6869921199898971
Epoch: 77 | Iteration number: [2860/4518] 63% | Training loss: 0.6869884747933674
Epoch: 77 | Iteration number: [2870/4518] 63% | Training loss: 0.686987168448312
Epoch: 77 | Iteration number: [2880/4518] 63% | Training loss: 0.6869867632579473
Epoch: 77 | Iteration number: [2890/4518] 63% | Training loss: 0.6869882707364832
Epoch: 77 | Iteration number: [2900/4518] 64% | Training loss: 0.6869851539463833
Epoch: 77 | Iteration number: [2910/4518] 64% | Training loss: 0.6869833073050705
Epoch: 77 | Iteration number: [2920/4518] 64% | Training loss: 0.6869816266510584
Epoch: 77 | Iteration number: [2930/4518] 64% | Training loss: 0.6869820612485905
Epoch: 77 | Iteration number: [2940/4518] 65% | Training loss: 0.6869831077501076
Epoch: 77 | Iteration number: [2950/4518] 65% | Training loss: 0.6869777599633751
Epoch: 77 | Iteration number: [2960/4518] 65% | Training loss: 0.6869772407050069
Epoch: 77 | Iteration number: [2970/4518] 65% | Training loss: 0.6869772218895279
Epoch: 77 | Iteration number: [2980/4518] 65% | Training loss: 0.6869788886716702
Epoch: 77 | Iteration number: [2990/4518] 66% | Training loss: 0.6869787421712907
Epoch: 77 | Iteration number: [3000/4518] 66% | Training loss: 0.686979963739713
Epoch: 77 | Iteration number: [3010/4518] 66% | Training loss: 0.6869777772315713
Epoch: 77 | Iteration number: [3020/4518] 66% | Training loss: 0.6869800350129209
Epoch: 77 | Iteration number: [3030/4518] 67% | Training loss: 0.6869795604900952
Epoch: 77 | Iteration number: [3040/4518] 67% | Training loss: 0.6869744681017963
Epoch: 77 | Iteration number: [3050/4518] 67% | Training loss: 0.6869750233556403
Epoch: 77 | Iteration number: [3060/4518] 67% | Training loss: 0.6869710019016577
Epoch: 77 | Iteration number: [3070/4518] 67% | Training loss: 0.68697042117678
Epoch: 77 | Iteration number: [3080/4518] 68% | Training loss: 0.6869726414030248
Epoch: 77 | Iteration number: [3090/4518] 68% | Training loss: 0.6869733101920402
Epoch: 77 | Iteration number: [3100/4518] 68% | Training loss: 0.6869758754584097
Epoch: 77 | Iteration number: [3110/4518] 68% | Training loss: 0.686979645356488
Epoch: 77 | Iteration number: [3120/4518] 69% | Training loss: 0.6869816570518873
Epoch: 77 | Iteration number: [3130/4518] 69% | Training loss: 0.6869794467958018
Epoch: 77 | Iteration number: [3140/4518] 69% | Training loss: 0.6869793305351476
Epoch: 77 | Iteration number: [3150/4518] 69% | Training loss: 0.6869796587550451
Epoch: 77 | Iteration number: [3160/4518] 69% | Training loss: 0.6869784681102897
Epoch: 77 | Iteration number: [3170/4518] 70% | Training loss: 0.6869813280526772
Epoch: 77 | Iteration number: [3180/4518] 70% | Training loss: 0.6869763650609262
Epoch: 77 | Iteration number: [3190/4518] 70% | Training loss: 0.6869758622399692
Epoch: 77 | Iteration number: [3200/4518] 70% | Training loss: 0.6869751900993287
Epoch: 77 | Iteration number: [3210/4518] 71% | Training loss: 0.6869758667418518
Epoch: 77 | Iteration number: [3220/4518] 71% | Training loss: 0.6869763269187501
Epoch: 77 | Iteration number: [3230/4518] 71% | Training loss: 0.6869739344983647
Epoch: 77 | Iteration number: [3240/4518] 71% | Training loss: 0.6869755417108536
Epoch: 77 | Iteration number: [3250/4518] 71% | Training loss: 0.6869756618096279
Epoch: 77 | Iteration number: [3260/4518] 72% | Training loss: 0.6869748946165014
Epoch: 77 | Iteration number: [3270/4518] 72% | Training loss: 0.6869739556531294
Epoch: 77 | Iteration number: [3280/4518] 72% | Training loss: 0.686972935515933
Epoch: 77 | Iteration number: [3290/4518] 72% | Training loss: 0.6869696167102338
Epoch: 77 | Iteration number: [3300/4518] 73% | Training loss: 0.6869715534195755
Epoch: 77 | Iteration number: [3310/4518] 73% | Training loss: 0.6869701771037456
Epoch: 77 | Iteration number: [3320/4518] 73% | Training loss: 0.686968975164086
Epoch: 77 | Iteration number: [3330/4518] 73% | Training loss: 0.6869654644895961
Epoch: 77 | Iteration number: [3340/4518] 73% | Training loss: 0.6869653585428249
Epoch: 77 | Iteration number: [3350/4518] 74% | Training loss: 0.6869648115136731
Epoch: 77 | Iteration number: [3360/4518] 74% | Training loss: 0.6869605916596594
Epoch: 77 | Iteration number: [3370/4518] 74% | Training loss: 0.6869584374505617
Epoch: 77 | Iteration number: [3380/4518] 74% | Training loss: 0.6869608899369042
Epoch: 77 | Iteration number: [3390/4518] 75% | Training loss: 0.6869584814988758
Epoch: 77 | Iteration number: [3400/4518] 75% | Training loss: 0.686960251524168
Epoch: 77 | Iteration number: [3410/4518] 75% | Training loss: 0.686964941252012
Epoch: 77 | Iteration number: [3420/4518] 75% | Training loss: 0.686963476719912
Epoch: 77 | Iteration number: [3430/4518] 75% | Training loss: 0.6869644851100688
Epoch: 77 | Iteration number: [3440/4518] 76% | Training loss: 0.6869621735326079
Epoch: 77 | Iteration number: [3450/4518] 76% | Training loss: 0.6869631032667298
Epoch: 77 | Iteration number: [3460/4518] 76% | Training loss: 0.6869641583606687
Epoch: 77 | Iteration number: [3470/4518] 76% | Training loss: 0.6869630251562905
Epoch: 77 | Iteration number: [3480/4518] 77% | Training loss: 0.6869628750044724
Epoch: 77 | Iteration number: [3490/4518] 77% | Training loss: 0.6869617135271985
Epoch: 77 | Iteration number: [3500/4518] 77% | Training loss: 0.6869584631238664
Epoch: 77 | Iteration number: [3510/4518] 77% | Training loss: 0.6869590804108188
Epoch: 77 | Iteration number: [3520/4518] 77% | Training loss: 0.6869592873718251
Epoch: 77 | Iteration number: [3530/4518] 78% | Training loss: 0.6869619784713129
Epoch: 77 | Iteration number: [3540/4518] 78% | Training loss: 0.6869615720658653
Epoch: 77 | Iteration number: [3550/4518] 78% | Training loss: 0.6869664141997485
Epoch: 77 | Iteration number: [3560/4518] 78% | Training loss: 0.6869669673650453
Epoch: 77 | Iteration number: [3570/4518] 79% | Training loss: 0.6869668718312635
Epoch: 77 | Iteration number: [3580/4518] 79% | Training loss: 0.6869685409122339
Epoch: 77 | Iteration number: [3590/4518] 79% | Training loss: 0.6869675589637172
Epoch: 77 | Iteration number: [3600/4518] 79% | Training loss: 0.6869631045560042
Epoch: 77 | Iteration number: [3610/4518] 79% | Training loss: 0.6869645770566946
Epoch: 77 | Iteration number: [3620/4518] 80% | Training loss: 0.6869627412017538
Epoch: 77 | Iteration number: [3630/4518] 80% | Training loss: 0.6869614201636354
Epoch: 77 | Iteration number: [3640/4518] 80% | Training loss: 0.686961150267622
Epoch: 77 | Iteration number: [3650/4518] 80% | Training loss: 0.6869623228295209
Epoch: 77 | Iteration number: [3660/4518] 81% | Training loss: 0.6869625025596775
Epoch: 77 | Iteration number: [3670/4518] 81% | Training loss: 0.6869656507260793
Epoch: 77 | Iteration number: [3680/4518] 81% | Training loss: 0.686960122782899
Epoch: 77 | Iteration number: [3690/4518] 81% | Training loss: 0.6869577520908056
Epoch: 77 | Iteration number: [3700/4518] 81% | Training loss: 0.6869576474460396
Epoch: 77 | Iteration number: [3710/4518] 82% | Training loss: 0.6869555191691674
Epoch: 77 | Iteration number: [3720/4518] 82% | Training loss: 0.6869511610077274
Epoch: 77 | Iteration number: [3730/4518] 82% | Training loss: 0.686951520887201
Epoch: 77 | Iteration number: [3740/4518] 82% | Training loss: 0.6869486973247426
Epoch: 77 | Iteration number: [3750/4518] 83% | Training loss: 0.6869507696946462
Epoch: 77 | Iteration number: [3760/4518] 83% | Training loss: 0.6869545525851402
Epoch: 77 | Iteration number: [3770/4518] 83% | Training loss: 0.6869514006992866
Epoch: 77 | Iteration number: [3780/4518] 83% | Training loss: 0.6869477743036533
Epoch: 77 | Iteration number: [3790/4518] 83% | Training loss: 0.6869467036862487
Epoch: 77 | Iteration number: [3800/4518] 84% | Training loss: 0.6869461212346428
Epoch: 77 | Iteration number: [3810/4518] 84% | Training loss: 0.6869437366332908
Epoch: 77 | Iteration number: [3820/4518] 84% | Training loss: 0.6869440038790877
Epoch: 77 | Iteration number: [3830/4518] 84% | Training loss: 0.6869448689194323
Epoch: 77 | Iteration number: [3840/4518] 84% | Training loss: 0.6869417014376571
Epoch: 77 | Iteration number: [3850/4518] 85% | Training loss: 0.6869421114859643
Epoch: 77 | Iteration number: [3860/4518] 85% | Training loss: 0.6869420377701675
Epoch: 77 | Iteration number: [3870/4518] 85% | Training loss: 0.6869390044101449
Epoch: 77 | Iteration number: [3880/4518] 85% | Training loss: 0.6869375211522751
Epoch: 77 | Iteration number: [3890/4518] 86% | Training loss: 0.6869343569315491
Epoch: 77 | Iteration number: [3900/4518] 86% | Training loss: 0.6869341525359032
Epoch: 77 | Iteration number: [3910/4518] 86% | Training loss: 0.686936239421825
Epoch: 77 | Iteration number: [3920/4518] 86% | Training loss: 0.6869378408759225
Epoch: 77 | Iteration number: [3930/4518] 86% | Training loss: 0.6869413285765029
Epoch: 77 | Iteration number: [3940/4518] 87% | Training loss: 0.6869382733167125
Epoch: 77 | Iteration number: [3950/4518] 87% | Training loss: 0.6869386380231833
Epoch: 77 | Iteration number: [3960/4518] 87% | Training loss: 0.6869359908681927
Epoch: 77 | Iteration number: [3970/4518] 87% | Training loss: 0.6869350020170812
Epoch: 77 | Iteration number: [3980/4518] 88% | Training loss: 0.6869339799910934
Epoch: 77 | Iteration number: [3990/4518] 88% | Training loss: 0.686931560272561
Epoch: 77 | Iteration number: [4000/4518] 88% | Training loss: 0.686930676445365
Epoch: 77 | Iteration number: [4010/4518] 88% | Training loss: 0.6869315042014134
Epoch: 77 | Iteration number: [4020/4518] 88% | Training loss: 0.6869319610779558
Epoch: 77 | Iteration number: [4030/4518] 89% | Training loss: 0.6869318044511024
Epoch: 77 | Iteration number: [4040/4518] 89% | Training loss: 0.6869316697710811
Epoch: 77 | Iteration number: [4050/4518] 89% | Training loss: 0.6869306668381632
Epoch: 77 | Iteration number: [4060/4518] 89% | Training loss: 0.6869312109324732
Epoch: 77 | Iteration number: [4070/4518] 90% | Training loss: 0.6869285639000173
Epoch: 77 | Iteration number: [4080/4518] 90% | Training loss: 0.6869276246895977
Epoch: 77 | Iteration number: [4090/4518] 90% | Training loss: 0.6869262731308459
Epoch: 77 | Iteration number: [4100/4518] 90% | Training loss: 0.686927268679549
Epoch: 77 | Iteration number: [4110/4518] 90% | Training loss: 0.6869311509196195
Epoch: 77 | Iteration number: [4120/4518] 91% | Training loss: 0.6869287216258281
Epoch: 77 | Iteration number: [4130/4518] 91% | Training loss: 0.6869287651041229
Epoch: 77 | Iteration number: [4140/4518] 91% | Training loss: 0.6869292324435884
Epoch: 77 | Iteration number: [4150/4518] 91% | Training loss: 0.6869273121529315
Epoch: 77 | Iteration number: [4160/4518] 92% | Training loss: 0.686929305929404
Epoch: 77 | Iteration number: [4170/4518] 92% | Training loss: 0.6869265766452542
Epoch: 77 | Iteration number: [4180/4518] 92% | Training loss: 0.6869264426556501
Epoch: 77 | Iteration number: [4190/4518] 92% | Training loss: 0.6869310893278417
Epoch: 77 | Iteration number: [4200/4518] 92% | Training loss: 0.6869305315471831
Epoch: 77 | Iteration number: [4210/4518] 93% | Training loss: 0.6869273889093105
Epoch: 77 | Iteration number: [4220/4518] 93% | Training loss: 0.6869271064680335
Epoch: 77 | Iteration number: [4230/4518] 93% | Training loss: 0.686929873709983
Epoch: 77 | Iteration number: [4240/4518] 93% | Training loss: 0.6869273222842307
Epoch: 77 | Iteration number: [4250/4518] 94% | Training loss: 0.6869269953475279
Epoch: 77 | Iteration number: [4260/4518] 94% | Training loss: 0.6869237946092802
Epoch: 77 | Iteration number: [4270/4518] 94% | Training loss: 0.6869235244093231
Epoch: 77 | Iteration number: [4280/4518] 94% | Training loss: 0.6869220235358889
Epoch: 77 | Iteration number: [4290/4518] 94% | Training loss: 0.6869230004596265
Epoch: 77 | Iteration number: [4300/4518] 95% | Training loss: 0.6869222420592641
Epoch: 77 | Iteration number: [4310/4518] 95% | Training loss: 0.6869227808755402
Epoch: 77 | Iteration number: [4320/4518] 95% | Training loss: 0.6869240695265708
Epoch: 77 | Iteration number: [4330/4518] 95% | Training loss: 0.686926542762796
Epoch: 77 | Iteration number: [4340/4518] 96% | Training loss: 0.6869268846539308
Epoch: 77 | Iteration number: [4350/4518] 96% | Training loss: 0.6869253296550663
Epoch: 77 | Iteration number: [4360/4518] 96% | Training loss: 0.6869235436714024
Epoch: 77 | Iteration number: [4370/4518] 96% | Training loss: 0.68692311675925
Epoch: 77 | Iteration number: [4380/4518] 96% | Training loss: 0.686921142334263
Epoch: 77 | Iteration number: [4390/4518] 97% | Training loss: 0.6869242144201231
Epoch: 77 | Iteration number: [4400/4518] 97% | Training loss: 0.6869249754602259
Epoch: 77 | Iteration number: [4410/4518] 97% | Training loss: 0.6869232733909235
Epoch: 77 | Iteration number: [4420/4518] 97% | Training loss: 0.6869234992503042
Epoch: 77 | Iteration number: [4430/4518] 98% | Training loss: 0.6869233614838688
Epoch: 77 | Iteration number: [4440/4518] 98% | Training loss: 0.6869246204157133
Epoch: 77 | Iteration number: [4450/4518] 98% | Training loss: 0.6869272127981936
Epoch: 77 | Iteration number: [4460/4518] 98% | Training loss: 0.6869257668743219
Epoch: 77 | Iteration number: [4470/4518] 98% | Training loss: 0.6869210639255959
Epoch: 77 | Iteration number: [4480/4518] 99% | Training loss: 0.6869213244877755
Epoch: 77 | Iteration number: [4490/4518] 99% | Training loss: 0.6869192493386683
Epoch: 77 | Iteration number: [4500/4518] 99% | Training loss: 0.6869193658034006
Epoch: 77 | Iteration number: [4510/4518] 99% | Training loss: 0.6869198061806664

 End of epoch: 77 | Train Loss: 0.6867680564793194 | Training Time: 633 

 End of epoch: 77 | Eval Loss: 0.689645317136025 | Evaluating Time: 17 
Epoch: 78 | Iteration number: [10/4518] 0% | Training loss: 0.7553759157657624
Epoch: 78 | Iteration number: [20/4518] 0% | Training loss: 0.7213445842266083
Epoch: 78 | Iteration number: [30/4518] 0% | Training loss: 0.7099497993787129
Epoch: 78 | Iteration number: [40/4518] 0% | Training loss: 0.7042100906372071
Epoch: 78 | Iteration number: [50/4518] 1% | Training loss: 0.7009872496128082
Epoch: 78 | Iteration number: [60/4518] 1% | Training loss: 0.6984308967987697
Epoch: 78 | Iteration number: [70/4518] 1% | Training loss: 0.6966711938381195
Epoch: 78 | Iteration number: [80/4518] 1% | Training loss: 0.6954289428889752
Epoch: 78 | Iteration number: [90/4518] 1% | Training loss: 0.6945427086618211
Epoch: 78 | Iteration number: [100/4518] 2% | Training loss: 0.6937655061483383
Epoch: 78 | Iteration number: [110/4518] 2% | Training loss: 0.6931180027398196
Epoch: 78 | Iteration number: [120/4518] 2% | Training loss: 0.6924795617659887
Epoch: 78 | Iteration number: [130/4518] 2% | Training loss: 0.6920753547778496
Epoch: 78 | Iteration number: [140/4518] 3% | Training loss: 0.6917050072125026
Epoch: 78 | Iteration number: [150/4518] 3% | Training loss: 0.6913783133029938
Epoch: 78 | Iteration number: [160/4518] 3% | Training loss: 0.6910464905202389
Epoch: 78 | Iteration number: [170/4518] 3% | Training loss: 0.6907972805640277
Epoch: 78 | Iteration number: [180/4518] 3% | Training loss: 0.6905156440205045
Epoch: 78 | Iteration number: [190/4518] 4% | Training loss: 0.6904103765362187
Epoch: 78 | Iteration number: [200/4518] 4% | Training loss: 0.6902446216344833
Epoch: 78 | Iteration number: [210/4518] 4% | Training loss: 0.6900137555031549
Epoch: 78 | Iteration number: [220/4518] 4% | Training loss: 0.6898469017310576
Epoch: 78 | Iteration number: [230/4518] 5% | Training loss: 0.6897154385628907
Epoch: 78 | Iteration number: [240/4518] 5% | Training loss: 0.6895489883919557
Epoch: 78 | Iteration number: [250/4518] 5% | Training loss: 0.6894775249958038
Epoch: 78 | Iteration number: [260/4518] 5% | Training loss: 0.6893878757953644
Epoch: 78 | Iteration number: [270/4518] 5% | Training loss: 0.6892788811966225
Epoch: 78 | Iteration number: [280/4518] 6% | Training loss: 0.6891514516302517
Epoch: 78 | Iteration number: [290/4518] 6% | Training loss: 0.6891212683299492
Epoch: 78 | Iteration number: [300/4518] 6% | Training loss: 0.6890358871221542
Epoch: 78 | Iteration number: [310/4518] 6% | Training loss: 0.6889562366470214
Epoch: 78 | Iteration number: [320/4518] 7% | Training loss: 0.6888800628483296
Epoch: 78 | Iteration number: [330/4518] 7% | Training loss: 0.6887944270264018
Epoch: 78 | Iteration number: [340/4518] 7% | Training loss: 0.6887497889644959
Epoch: 78 | Iteration number: [350/4518] 7% | Training loss: 0.6886921901362283
Epoch: 78 | Iteration number: [360/4518] 7% | Training loss: 0.6886653027600712
Epoch: 78 | Iteration number: [370/4518] 8% | Training loss: 0.6886004794288326
Epoch: 78 | Iteration number: [380/4518] 8% | Training loss: 0.6885296818457152
Epoch: 78 | Iteration number: [390/4518] 8% | Training loss: 0.6884999828460889
Epoch: 78 | Iteration number: [400/4518] 8% | Training loss: 0.6884521578252315
Epoch: 78 | Iteration number: [410/4518] 9% | Training loss: 0.6884049723788006
Epoch: 78 | Iteration number: [420/4518] 9% | Training loss: 0.6883310936746143
Epoch: 78 | Iteration number: [430/4518] 9% | Training loss: 0.68830072339191
Epoch: 78 | Iteration number: [440/4518] 9% | Training loss: 0.6882739445025271
Epoch: 78 | Iteration number: [450/4518] 9% | Training loss: 0.6882324494255914
Epoch: 78 | Iteration number: [460/4518] 10% | Training loss: 0.6882046450739322
Epoch: 78 | Iteration number: [470/4518] 10% | Training loss: 0.6882018744945526
Epoch: 78 | Iteration number: [480/4518] 10% | Training loss: 0.688203492636482
Epoch: 78 | Iteration number: [490/4518] 10% | Training loss: 0.6881903718928901
Epoch: 78 | Iteration number: [500/4518] 11% | Training loss: 0.6881614339351654
Epoch: 78 | Iteration number: [510/4518] 11% | Training loss: 0.6881405001761867
Epoch: 78 | Iteration number: [520/4518] 11% | Training loss: 0.6881127720841995
Epoch: 78 | Iteration number: [530/4518] 11% | Training loss: 0.6880858828436653
Epoch: 78 | Iteration number: [540/4518] 11% | Training loss: 0.6880514926380581
Epoch: 78 | Iteration number: [550/4518] 12% | Training loss: 0.6880157019875266
Epoch: 78 | Iteration number: [560/4518] 12% | Training loss: 0.6880254297384194
Epoch: 78 | Iteration number: [570/4518] 12% | Training loss: 0.6880136304780057
Epoch: 78 | Iteration number: [580/4518] 12% | Training loss: 0.6879957129215372
Epoch: 78 | Iteration number: [590/4518] 13% | Training loss: 0.6879511040146068
Epoch: 78 | Iteration number: [600/4518] 13% | Training loss: 0.6879224091768265
Epoch: 78 | Iteration number: [610/4518] 13% | Training loss: 0.6878871610907258
Epoch: 78 | Iteration number: [620/4518] 13% | Training loss: 0.6878785615967166
Epoch: 78 | Iteration number: [630/4518] 13% | Training loss: 0.687868660120737
Epoch: 78 | Iteration number: [640/4518] 14% | Training loss: 0.6878555295057595
Epoch: 78 | Iteration number: [650/4518] 14% | Training loss: 0.6878245118031135
Epoch: 78 | Iteration number: [660/4518] 14% | Training loss: 0.6878074888930176
Epoch: 78 | Iteration number: [670/4518] 14% | Training loss: 0.6877967691243585
Epoch: 78 | Iteration number: [680/4518] 15% | Training loss: 0.6877741033540052
Epoch: 78 | Iteration number: [690/4518] 15% | Training loss: 0.6877658824125926
Epoch: 78 | Iteration number: [700/4518] 15% | Training loss: 0.6877506996052606
Epoch: 78 | Iteration number: [710/4518] 15% | Training loss: 0.6877433008711104
Epoch: 78 | Iteration number: [720/4518] 15% | Training loss: 0.6877426011694803
Epoch: 78 | Iteration number: [730/4518] 16% | Training loss: 0.6877125070519643
Epoch: 78 | Iteration number: [740/4518] 16% | Training loss: 0.6876975976132058
Epoch: 78 | Iteration number: [750/4518] 16% | Training loss: 0.6876825830936432
Epoch: 78 | Iteration number: [760/4518] 16% | Training loss: 0.6876778862978282
Epoch: 78 | Iteration number: [770/4518] 17% | Training loss: 0.6876583430674169
Epoch: 78 | Iteration number: [780/4518] 17% | Training loss: 0.6876291538660343
Epoch: 78 | Iteration number: [790/4518] 17% | Training loss: 0.687623348718957
Epoch: 78 | Iteration number: [800/4518] 17% | Training loss: 0.6876048422604799
Epoch: 78 | Iteration number: [810/4518] 17% | Training loss: 0.6875919105094156
Epoch: 78 | Iteration number: [820/4518] 18% | Training loss: 0.687583855376011
Epoch: 78 | Iteration number: [830/4518] 18% | Training loss: 0.6875831181744495
Epoch: 78 | Iteration number: [840/4518] 18% | Training loss: 0.6875822209176563
Epoch: 78 | Iteration number: [850/4518] 18% | Training loss: 0.687563940006144
Epoch: 78 | Iteration number: [860/4518] 19% | Training loss: 0.6875435488168583
Epoch: 78 | Iteration number: [870/4518] 19% | Training loss: 0.68753032862455
Epoch: 78 | Iteration number: [880/4518] 19% | Training loss: 0.6875266383317384
Epoch: 78 | Iteration number: [890/4518] 19% | Training loss: 0.6875211504068267
Epoch: 78 | Iteration number: [900/4518] 19% | Training loss: 0.6875236022472382
Epoch: 78 | Iteration number: [910/4518] 20% | Training loss: 0.6875048567305554
Epoch: 78 | Iteration number: [920/4518] 20% | Training loss: 0.6874958150412726
Epoch: 78 | Iteration number: [930/4518] 20% | Training loss: 0.687493069517997
Epoch: 78 | Iteration number: [940/4518] 20% | Training loss: 0.6874660117195007
Epoch: 78 | Iteration number: [950/4518] 21% | Training loss: 0.6874537149855965
Epoch: 78 | Iteration number: [960/4518] 21% | Training loss: 0.6874498087912798
Epoch: 78 | Iteration number: [970/4518] 21% | Training loss: 0.6874418895269178
Epoch: 78 | Iteration number: [980/4518] 21% | Training loss: 0.687433374840386
Epoch: 78 | Iteration number: [990/4518] 21% | Training loss: 0.6874187313547038
Epoch: 78 | Iteration number: [1000/4518] 22% | Training loss: 0.6874076058268547
Epoch: 78 | Iteration number: [1010/4518] 22% | Training loss: 0.6873964801873311
Epoch: 78 | Iteration number: [1020/4518] 22% | Training loss: 0.6873916057395
Epoch: 78 | Iteration number: [1030/4518] 22% | Training loss: 0.6873849662183558
Epoch: 78 | Iteration number: [1040/4518] 23% | Training loss: 0.6873725229157851
Epoch: 78 | Iteration number: [1050/4518] 23% | Training loss: 0.6873533600852603
Epoch: 78 | Iteration number: [1060/4518] 23% | Training loss: 0.687358728501032
Epoch: 78 | Iteration number: [1070/4518] 23% | Training loss: 0.6873465128034075
Epoch: 78 | Iteration number: [1080/4518] 23% | Training loss: 0.6873412552255171
Epoch: 78 | Iteration number: [1090/4518] 24% | Training loss: 0.6873294486365187
Epoch: 78 | Iteration number: [1100/4518] 24% | Training loss: 0.6873280317674983
Epoch: 78 | Iteration number: [1110/4518] 24% | Training loss: 0.6873246733132783
Epoch: 78 | Iteration number: [1120/4518] 24% | Training loss: 0.6873033317072051
Epoch: 78 | Iteration number: [1130/4518] 25% | Training loss: 0.6872960739431128
Epoch: 78 | Iteration number: [1140/4518] 25% | Training loss: 0.6872889966295477
Epoch: 78 | Iteration number: [1150/4518] 25% | Training loss: 0.6872797541514687
Epoch: 78 | Iteration number: [1160/4518] 25% | Training loss: 0.6872768306012811
Epoch: 78 | Iteration number: [1170/4518] 25% | Training loss: 0.687277438192286
Epoch: 78 | Iteration number: [1180/4518] 26% | Training loss: 0.6872702760211492
Epoch: 78 | Iteration number: [1190/4518] 26% | Training loss: 0.6872685046756969
Epoch: 78 | Iteration number: [1200/4518] 26% | Training loss: 0.6872590773304303
Epoch: 78 | Iteration number: [1210/4518] 26% | Training loss: 0.6872501336838588
Epoch: 78 | Iteration number: [1220/4518] 27% | Training loss: 0.6872592229823598
Epoch: 78 | Iteration number: [1230/4518] 27% | Training loss: 0.6872572556743777
Epoch: 78 | Iteration number: [1240/4518] 27% | Training loss: 0.6872407417624228
Epoch: 78 | Iteration number: [1250/4518] 27% | Training loss: 0.6872350324630737
Epoch: 78 | Iteration number: [1260/4518] 27% | Training loss: 0.6872306690329597
Epoch: 78 | Iteration number: [1270/4518] 28% | Training loss: 0.6872277433477988
Epoch: 78 | Iteration number: [1280/4518] 28% | Training loss: 0.6872266003862023
Epoch: 78 | Iteration number: [1290/4518] 28% | Training loss: 0.6872285068497177
Epoch: 78 | Iteration number: [1300/4518] 28% | Training loss: 0.6872234530173815
Epoch: 78 | Iteration number: [1310/4518] 28% | Training loss: 0.6872193116723126
Epoch: 78 | Iteration number: [1320/4518] 29% | Training loss: 0.6872149842255043
Epoch: 78 | Iteration number: [1330/4518] 29% | Training loss: 0.6872062658905087
Epoch: 78 | Iteration number: [1340/4518] 29% | Training loss: 0.6872002454391166
Epoch: 78 | Iteration number: [1350/4518] 29% | Training loss: 0.6871952855587006
Epoch: 78 | Iteration number: [1360/4518] 30% | Training loss: 0.6872024425250642
Epoch: 78 | Iteration number: [1370/4518] 30% | Training loss: 0.687201089841606
Epoch: 78 | Iteration number: [1380/4518] 30% | Training loss: 0.6871995772572531
Epoch: 78 | Iteration number: [1390/4518] 30% | Training loss: 0.6871925594995347
Epoch: 78 | Iteration number: [1400/4518] 30% | Training loss: 0.6871984038608415
Epoch: 78 | Iteration number: [1410/4518] 31% | Training loss: 0.6871955683890809
Epoch: 78 | Iteration number: [1420/4518] 31% | Training loss: 0.6871852485226914
Epoch: 78 | Iteration number: [1430/4518] 31% | Training loss: 0.6871806382716119
Epoch: 78 | Iteration number: [1440/4518] 31% | Training loss: 0.6871789399120543
Epoch: 78 | Iteration number: [1450/4518] 32% | Training loss: 0.687172219917692
Epoch: 78 | Iteration number: [1460/4518] 32% | Training loss: 0.6871622308068079
Epoch: 78 | Iteration number: [1470/4518] 32% | Training loss: 0.6871553728369628
Epoch: 78 | Iteration number: [1480/4518] 32% | Training loss: 0.6871565832076846
Epoch: 78 | Iteration number: [1490/4518] 32% | Training loss: 0.6871612559628967
Epoch: 78 | Iteration number: [1500/4518] 33% | Training loss: 0.6871579008499781
Epoch: 78 | Iteration number: [1510/4518] 33% | Training loss: 0.6871515670754262
Epoch: 78 | Iteration number: [1520/4518] 33% | Training loss: 0.6871568951559694
Epoch: 78 | Iteration number: [1530/4518] 33% | Training loss: 0.6871463830954109
Epoch: 78 | Iteration number: [1540/4518] 34% | Training loss: 0.687144011259079
Epoch: 78 | Iteration number: [1550/4518] 34% | Training loss: 0.6871427154925561
Epoch: 78 | Iteration number: [1560/4518] 34% | Training loss: 0.6871482533522141
Epoch: 78 | Iteration number: [1570/4518] 34% | Training loss: 0.6871581966709939
Epoch: 78 | Iteration number: [1580/4518] 34% | Training loss: 0.6871492422079738
Epoch: 78 | Iteration number: [1590/4518] 35% | Training loss: 0.6871447683880164
Epoch: 78 | Iteration number: [1600/4518] 35% | Training loss: 0.6871393529698253
Epoch: 78 | Iteration number: [1610/4518] 35% | Training loss: 0.6871343989920172
Epoch: 78 | Iteration number: [1620/4518] 35% | Training loss: 0.6871368265446322
Epoch: 78 | Iteration number: [1630/4518] 36% | Training loss: 0.6871307408882796
Epoch: 78 | Iteration number: [1640/4518] 36% | Training loss: 0.6871284609887658
Epoch: 78 | Iteration number: [1650/4518] 36% | Training loss: 0.6871349250909053
Epoch: 78 | Iteration number: [1660/4518] 36% | Training loss: 0.6871325916913619
Epoch: 78 | Iteration number: [1670/4518] 36% | Training loss: 0.6871342153249387
Epoch: 78 | Iteration number: [1680/4518] 37% | Training loss: 0.687136746907518
Epoch: 78 | Iteration number: [1690/4518] 37% | Training loss: 0.6871329623566577
Epoch: 78 | Iteration number: [1700/4518] 37% | Training loss: 0.6871251593617832
Epoch: 78 | Iteration number: [1710/4518] 37% | Training loss: 0.6871293034818438
Epoch: 78 | Iteration number: [1720/4518] 38% | Training loss: 0.6871306955467823
Epoch: 78 | Iteration number: [1730/4518] 38% | Training loss: 0.6871357635611055
Epoch: 78 | Iteration number: [1740/4518] 38% | Training loss: 0.6871305673971944
Epoch: 78 | Iteration number: [1750/4518] 38% | Training loss: 0.6871262641974858
Epoch: 78 | Iteration number: [1760/4518] 38% | Training loss: 0.6871257534081285
Epoch: 78 | Iteration number: [1770/4518] 39% | Training loss: 0.6871302848481863
Epoch: 78 | Iteration number: [1780/4518] 39% | Training loss: 0.6871236225527324
Epoch: 78 | Iteration number: [1790/4518] 39% | Training loss: 0.6871271058500812
Epoch: 78 | Iteration number: [1800/4518] 39% | Training loss: 0.6871215587192111
Epoch: 78 | Iteration number: [1810/4518] 40% | Training loss: 0.6871145519762408
Epoch: 78 | Iteration number: [1820/4518] 40% | Training loss: 0.6871161320052304
Epoch: 78 | Iteration number: [1830/4518] 40% | Training loss: 0.6871207788993752
Epoch: 78 | Iteration number: [1840/4518] 40% | Training loss: 0.6871176319277805
Epoch: 78 | Iteration number: [1850/4518] 40% | Training loss: 0.6871198143830171
Epoch: 78 | Iteration number: [1860/4518] 41% | Training loss: 0.6871199768397116
Epoch: 78 | Iteration number: [1870/4518] 41% | Training loss: 0.6871110672937994
Epoch: 78 | Iteration number: [1880/4518] 41% | Training loss: 0.6871106035531835
Epoch: 78 | Iteration number: [1890/4518] 41% | Training loss: 0.6871134150280523
Epoch: 78 | Iteration number: [1900/4518] 42% | Training loss: 0.6871093399273722
Epoch: 78 | Iteration number: [1910/4518] 42% | Training loss: 0.6871095714144682
Epoch: 78 | Iteration number: [1920/4518] 42% | Training loss: 0.6871107047734161
Epoch: 78 | Iteration number: [1930/4518] 42% | Training loss: 0.6871135594313627
Epoch: 78 | Iteration number: [1940/4518] 42% | Training loss: 0.6871097179417758
Epoch: 78 | Iteration number: [1950/4518] 43% | Training loss: 0.6871102698032673
Epoch: 78 | Iteration number: [1960/4518] 43% | Training loss: 0.6871025340289486
Epoch: 78 | Iteration number: [1970/4518] 43% | Training loss: 0.6870985950310218
Epoch: 78 | Iteration number: [1980/4518] 43% | Training loss: 0.687099470032586
Epoch: 78 | Iteration number: [1990/4518] 44% | Training loss: 0.6871003698763536
Epoch: 78 | Iteration number: [2000/4518] 44% | Training loss: 0.6871040734350682
Epoch: 78 | Iteration number: [2010/4518] 44% | Training loss: 0.6871007317630806
Epoch: 78 | Iteration number: [2020/4518] 44% | Training loss: 0.6870983635730082
Epoch: 78 | Iteration number: [2030/4518] 44% | Training loss: 0.6870949546398201
Epoch: 78 | Iteration number: [2040/4518] 45% | Training loss: 0.6870967417955398
Epoch: 78 | Iteration number: [2050/4518] 45% | Training loss: 0.6870914410381782
Epoch: 78 | Iteration number: [2060/4518] 45% | Training loss: 0.687086706774906
Epoch: 78 | Iteration number: [2070/4518] 45% | Training loss: 0.6870876861079304
Epoch: 78 | Iteration number: [2080/4518] 46% | Training loss: 0.6870830957419597
Epoch: 78 | Iteration number: [2090/4518] 46% | Training loss: 0.6870741608610564
Epoch: 78 | Iteration number: [2100/4518] 46% | Training loss: 0.6870735940762929
Epoch: 78 | Iteration number: [2110/4518] 46% | Training loss: 0.6870742522427256
Epoch: 78 | Iteration number: [2120/4518] 46% | Training loss: 0.6870723929045335
Epoch: 78 | Iteration number: [2130/4518] 47% | Training loss: 0.6870761129218088
Epoch: 78 | Iteration number: [2140/4518] 47% | Training loss: 0.6870721576091285
Epoch: 78 | Iteration number: [2150/4518] 47% | Training loss: 0.6870686067259589
Epoch: 78 | Iteration number: [2160/4518] 47% | Training loss: 0.6870585248426154
Epoch: 78 | Iteration number: [2170/4518] 48% | Training loss: 0.687060651663811
Epoch: 78 | Iteration number: [2180/4518] 48% | Training loss: 0.6870565311350953
Epoch: 78 | Iteration number: [2190/4518] 48% | Training loss: 0.6870508675161562
Epoch: 78 | Iteration number: [2200/4518] 48% | Training loss: 0.6870493068207394
Epoch: 78 | Iteration number: [2210/4518] 48% | Training loss: 0.6870496289762437
Epoch: 78 | Iteration number: [2220/4518] 49% | Training loss: 0.6870490077111098
Epoch: 78 | Iteration number: [2230/4518] 49% | Training loss: 0.6870548255240436
Epoch: 78 | Iteration number: [2240/4518] 49% | Training loss: 0.687054326305432
Epoch: 78 | Iteration number: [2250/4518] 49% | Training loss: 0.6870584733751085
Epoch: 78 | Iteration number: [2260/4518] 50% | Training loss: 0.6870589462529242
Epoch: 78 | Iteration number: [2270/4518] 50% | Training loss: 0.6870584148404881
Epoch: 78 | Iteration number: [2280/4518] 50% | Training loss: 0.6870547172531747
Epoch: 78 | Iteration number: [2290/4518] 50% | Training loss: 0.6870458005297132
Epoch: 78 | Iteration number: [2300/4518] 50% | Training loss: 0.6870404889790909
Epoch: 78 | Iteration number: [2310/4518] 51% | Training loss: 0.6870379874716589
Epoch: 78 | Iteration number: [2320/4518] 51% | Training loss: 0.6870346746568022
Epoch: 78 | Iteration number: [2330/4518] 51% | Training loss: 0.6870359269334523
Epoch: 78 | Iteration number: [2340/4518] 51% | Training loss: 0.6870325038575719
Epoch: 78 | Iteration number: [2350/4518] 52% | Training loss: 0.6870280442339308
Epoch: 78 | Iteration number: [2360/4518] 52% | Training loss: 0.6870247079406755
Epoch: 78 | Iteration number: [2370/4518] 52% | Training loss: 0.6870184289503701
Epoch: 78 | Iteration number: [2380/4518] 52% | Training loss: 0.6870198343230897
Epoch: 78 | Iteration number: [2390/4518] 52% | Training loss: 0.6870184000565915
Epoch: 78 | Iteration number: [2400/4518] 53% | Training loss: 0.6870180261631806
Epoch: 78 | Iteration number: [2410/4518] 53% | Training loss: 0.6870191645325466
Epoch: 78 | Iteration number: [2420/4518] 53% | Training loss: 0.6870186957199711
Epoch: 78 | Iteration number: [2430/4518] 53% | Training loss: 0.6870181099622829
Epoch: 78 | Iteration number: [2440/4518] 54% | Training loss: 0.6870145648962162
Epoch: 78 | Iteration number: [2450/4518] 54% | Training loss: 0.6870160199671376
Epoch: 78 | Iteration number: [2460/4518] 54% | Training loss: 0.6870194522103643
Epoch: 78 | Iteration number: [2470/4518] 54% | Training loss: 0.6870232562063194
Epoch: 78 | Iteration number: [2480/4518] 54% | Training loss: 0.6870231649327663
Epoch: 78 | Iteration number: [2490/4518] 55% | Training loss: 0.687022527011044
Epoch: 78 | Iteration number: [2500/4518] 55% | Training loss: 0.6870200052976608
Epoch: 78 | Iteration number: [2510/4518] 55% | Training loss: 0.6870093033845681
Epoch: 78 | Iteration number: [2520/4518] 55% | Training loss: 0.6870055791167986
Epoch: 78 | Iteration number: [2530/4518] 55% | Training loss: 0.6870066436618685
Epoch: 78 | Iteration number: [2540/4518] 56% | Training loss: 0.6870041445484312
Epoch: 78 | Iteration number: [2550/4518] 56% | Training loss: 0.6869997398759804
Epoch: 78 | Iteration number: [2560/4518] 56% | Training loss: 0.6869997863424941
Epoch: 78 | Iteration number: [2570/4518] 56% | Training loss: 0.686997373813785
Epoch: 78 | Iteration number: [2580/4518] 57% | Training loss: 0.6869956224694732
Epoch: 78 | Iteration number: [2590/4518] 57% | Training loss: 0.6869968845807447
Epoch: 78 | Iteration number: [2600/4518] 57% | Training loss: 0.6869931782438204
Epoch: 78 | Iteration number: [2610/4518] 57% | Training loss: 0.6869941365216427
Epoch: 78 | Iteration number: [2620/4518] 57% | Training loss: 0.686986652471637
Epoch: 78 | Iteration number: [2630/4518] 58% | Training loss: 0.6869848891809412
Epoch: 78 | Iteration number: [2640/4518] 58% | Training loss: 0.686984892550743
Epoch: 78 | Iteration number: [2650/4518] 58% | Training loss: 0.6869824922984501
Epoch: 78 | Iteration number: [2660/4518] 58% | Training loss: 0.68698122604449
Epoch: 78 | Iteration number: [2670/4518] 59% | Training loss: 0.6869821185476325
Epoch: 78 | Iteration number: [2680/4518] 59% | Training loss: 0.6869827989322036
Epoch: 78 | Iteration number: [2690/4518] 59% | Training loss: 0.6869858584882601
Epoch: 78 | Iteration number: [2700/4518] 59% | Training loss: 0.6869839222563637
Epoch: 78 | Iteration number: [2710/4518] 59% | Training loss: 0.6869857824376588
Epoch: 78 | Iteration number: [2720/4518] 60% | Training loss: 0.6869819656014442
Epoch: 78 | Iteration number: [2730/4518] 60% | Training loss: 0.6869842310091515
Epoch: 78 | Iteration number: [2740/4518] 60% | Training loss: 0.6869828342738813
Epoch: 78 | Iteration number: [2750/4518] 60% | Training loss: 0.6869834140864286
Epoch: 78 | Iteration number: [2760/4518] 61% | Training loss: 0.6869855927384418
Epoch: 78 | Iteration number: [2770/4518] 61% | Training loss: 0.6869876906114365
Epoch: 78 | Iteration number: [2780/4518] 61% | Training loss: 0.6869875515536439
Epoch: 78 | Iteration number: [2790/4518] 61% | Training loss: 0.6869864413601523
Epoch: 78 | Iteration number: [2800/4518] 61% | Training loss: 0.6869833887687751
Epoch: 78 | Iteration number: [2810/4518] 62% | Training loss: 0.6869802713182049
Epoch: 78 | Iteration number: [2820/4518] 62% | Training loss: 0.6869791768966838
Epoch: 78 | Iteration number: [2830/4518] 62% | Training loss: 0.6869790808682729
Epoch: 78 | Iteration number: [2840/4518] 62% | Training loss: 0.6869780912995338
Epoch: 78 | Iteration number: [2850/4518] 63% | Training loss: 0.6869776651942939
Epoch: 78 | Iteration number: [2860/4518] 63% | Training loss: 0.6869781623561899
Epoch: 78 | Iteration number: [2870/4518] 63% | Training loss: 0.6869763815859884
Epoch: 78 | Iteration number: [2880/4518] 63% | Training loss: 0.6869770764062803
Epoch: 78 | Iteration number: [2890/4518] 63% | Training loss: 0.6869792209158306
Epoch: 78 | Iteration number: [2900/4518] 64% | Training loss: 0.686977841134729
Epoch: 78 | Iteration number: [2910/4518] 64% | Training loss: 0.6869756855301021
Epoch: 78 | Iteration number: [2920/4518] 64% | Training loss: 0.686977344118569
Epoch: 78 | Iteration number: [2930/4518] 64% | Training loss: 0.6869768028169768
Epoch: 78 | Iteration number: [2940/4518] 65% | Training loss: 0.6869763470020424
Epoch: 78 | Iteration number: [2950/4518] 65% | Training loss: 0.6869751845982115
Epoch: 78 | Iteration number: [2960/4518] 65% | Training loss: 0.6869754413897927
Epoch: 78 | Iteration number: [2970/4518] 65% | Training loss: 0.6869761914717228
Epoch: 78 | Iteration number: [2980/4518] 65% | Training loss: 0.6869751071969935
Epoch: 78 | Iteration number: [2990/4518] 66% | Training loss: 0.6869751119294693
Epoch: 78 | Iteration number: [3000/4518] 66% | Training loss: 0.6869712229768435
Epoch: 78 | Iteration number: [3010/4518] 66% | Training loss: 0.6869709257667643
Epoch: 78 | Iteration number: [3020/4518] 66% | Training loss: 0.6869687235908003
Epoch: 78 | Iteration number: [3030/4518] 67% | Training loss: 0.6869688533517
Epoch: 78 | Iteration number: [3040/4518] 67% | Training loss: 0.6869664220825622
Epoch: 78 | Iteration number: [3050/4518] 67% | Training loss: 0.6869673857337139
Epoch: 78 | Iteration number: [3060/4518] 67% | Training loss: 0.6869686529332516
Epoch: 78 | Iteration number: [3070/4518] 67% | Training loss: 0.6869658927964077
Epoch: 78 | Iteration number: [3080/4518] 68% | Training loss: 0.6869639271265501
Epoch: 78 | Iteration number: [3090/4518] 68% | Training loss: 0.6869690766419407
Epoch: 78 | Iteration number: [3100/4518] 68% | Training loss: 0.6869673830270767
Epoch: 78 | Iteration number: [3110/4518] 68% | Training loss: 0.6869674487129285
Epoch: 78 | Iteration number: [3120/4518] 69% | Training loss: 0.6869689834996676
Epoch: 78 | Iteration number: [3130/4518] 69% | Training loss: 0.6869664622191042
Epoch: 78 | Iteration number: [3140/4518] 69% | Training loss: 0.686965078817811
Epoch: 78 | Iteration number: [3150/4518] 69% | Training loss: 0.6869668078233325
Epoch: 78 | Iteration number: [3160/4518] 69% | Training loss: 0.6869696416809589
Epoch: 78 | Iteration number: [3170/4518] 70% | Training loss: 0.6869636332199025
Epoch: 78 | Iteration number: [3180/4518] 70% | Training loss: 0.6869623494785537
Epoch: 78 | Iteration number: [3190/4518] 70% | Training loss: 0.6869662652568758
Epoch: 78 | Iteration number: [3200/4518] 70% | Training loss: 0.6869621090777218
Epoch: 78 | Iteration number: [3210/4518] 71% | Training loss: 0.686963088861507
Epoch: 78 | Iteration number: [3220/4518] 71% | Training loss: 0.6869616550688418
Epoch: 78 | Iteration number: [3230/4518] 71% | Training loss: 0.6869611167870808
Epoch: 78 | Iteration number: [3240/4518] 71% | Training loss: 0.6869596254126525
Epoch: 78 | Iteration number: [3250/4518] 71% | Training loss: 0.6869624402523041
Epoch: 78 | Iteration number: [3260/4518] 72% | Training loss: 0.686963886260255
Epoch: 78 | Iteration number: [3270/4518] 72% | Training loss: 0.6869630546562533
Epoch: 78 | Iteration number: [3280/4518] 72% | Training loss: 0.686958438866749
Epoch: 78 | Iteration number: [3290/4518] 72% | Training loss: 0.6869610992064954
Epoch: 78 | Iteration number: [3300/4518] 73% | Training loss: 0.6869606719956254
Epoch: 78 | Iteration number: [3310/4518] 73% | Training loss: 0.6869602320417537
Epoch: 78 | Iteration number: [3320/4518] 73% | Training loss: 0.6869585668825241
Epoch: 78 | Iteration number: [3330/4518] 73% | Training loss: 0.6869607390942158
Epoch: 78 | Iteration number: [3340/4518] 73% | Training loss: 0.6869580696264427
Epoch: 78 | Iteration number: [3350/4518] 74% | Training loss: 0.6869553670954348
Epoch: 78 | Iteration number: [3360/4518] 74% | Training loss: 0.6869580956442015
Epoch: 78 | Iteration number: [3370/4518] 74% | Training loss: 0.6869547127439289
Epoch: 78 | Iteration number: [3380/4518] 74% | Training loss: 0.6869515196106137
Epoch: 78 | Iteration number: [3390/4518] 75% | Training loss: 0.6869545446384622
Epoch: 78 | Iteration number: [3400/4518] 75% | Training loss: 0.6869565120690009
Epoch: 78 | Iteration number: [3410/4518] 75% | Training loss: 0.6869593466831442
Epoch: 78 | Iteration number: [3420/4518] 75% | Training loss: 0.6869622284557387
Epoch: 78 | Iteration number: [3430/4518] 75% | Training loss: 0.6869648478816619
Epoch: 78 | Iteration number: [3440/4518] 76% | Training loss: 0.6869644247341987
Epoch: 78 | Iteration number: [3450/4518] 76% | Training loss: 0.6869635940807453
Epoch: 78 | Iteration number: [3460/4518] 76% | Training loss: 0.6869614394413942
Epoch: 78 | Iteration number: [3470/4518] 76% | Training loss: 0.6869622104964958
Epoch: 78 | Iteration number: [3480/4518] 77% | Training loss: 0.6869617880075828
Epoch: 78 | Iteration number: [3490/4518] 77% | Training loss: 0.6869623547126366
Epoch: 78 | Iteration number: [3500/4518] 77% | Training loss: 0.6869595075334821
Epoch: 78 | Iteration number: [3510/4518] 77% | Training loss: 0.6869609107658734
Epoch: 78 | Iteration number: [3520/4518] 77% | Training loss: 0.6869640225713903
Epoch: 78 | Iteration number: [3530/4518] 78% | Training loss: 0.6869648769286807
Epoch: 78 | Iteration number: [3540/4518] 78% | Training loss: 0.6869665655375874
Epoch: 78 | Iteration number: [3550/4518] 78% | Training loss: 0.6869621977671772
Epoch: 78 | Iteration number: [3560/4518] 78% | Training loss: 0.6869595686036549
Epoch: 78 | Iteration number: [3570/4518] 79% | Training loss: 0.686958607154734
Epoch: 78 | Iteration number: [3580/4518] 79% | Training loss: 0.6869597098181368
Epoch: 78 | Iteration number: [3590/4518] 79% | Training loss: 0.6869601975908518
Epoch: 78 | Iteration number: [3600/4518] 79% | Training loss: 0.6869623586866591
Epoch: 78 | Iteration number: [3610/4518] 79% | Training loss: 0.6869589626789093
Epoch: 78 | Iteration number: [3620/4518] 80% | Training loss: 0.6869582880597088
Epoch: 78 | Iteration number: [3630/4518] 80% | Training loss: 0.6869590542861581
Epoch: 78 | Iteration number: [3640/4518] 80% | Training loss: 0.6869551981215949
Epoch: 78 | Iteration number: [3650/4518] 80% | Training loss: 0.6869528014855842
Epoch: 78 | Iteration number: [3660/4518] 81% | Training loss: 0.6869490930780036
Epoch: 78 | Iteration number: [3670/4518] 81% | Training loss: 0.6869468651772844
Epoch: 78 | Iteration number: [3680/4518] 81% | Training loss: 0.6869436140617599
Epoch: 78 | Iteration number: [3690/4518] 81% | Training loss: 0.6869391340388838
Epoch: 78 | Iteration number: [3700/4518] 81% | Training loss: 0.6869359304776063
Epoch: 78 | Iteration number: [3710/4518] 82% | Training loss: 0.686935180682699
Epoch: 78 | Iteration number: [3720/4518] 82% | Training loss: 0.6869348966947166
Epoch: 78 | Iteration number: [3730/4518] 82% | Training loss: 0.6869349392425599
Epoch: 78 | Iteration number: [3740/4518] 82% | Training loss: 0.686930195533018
Epoch: 78 | Iteration number: [3750/4518] 83% | Training loss: 0.6869321138381957
Epoch: 78 | Iteration number: [3760/4518] 83% | Training loss: 0.6869334402395055
Epoch: 78 | Iteration number: [3770/4518] 83% | Training loss: 0.6869331930297123
Epoch: 78 | Iteration number: [3780/4518] 83% | Training loss: 0.6869317892997984
Epoch: 78 | Iteration number: [3790/4518] 83% | Training loss: 0.6869317807434102
Epoch: 78 | Iteration number: [3800/4518] 84% | Training loss: 0.6869316458388379
Epoch: 78 | Iteration number: [3810/4518] 84% | Training loss: 0.6869310592885406
Epoch: 78 | Iteration number: [3820/4518] 84% | Training loss: 0.6869319327682725
Epoch: 78 | Iteration number: [3830/4518] 84% | Training loss: 0.6869321317803455
Epoch: 78 | Iteration number: [3840/4518] 84% | Training loss: 0.6869319192133844
Epoch: 78 | Iteration number: [3850/4518] 85% | Training loss: 0.6869308611324855
Epoch: 78 | Iteration number: [3860/4518] 85% | Training loss: 0.6869295623481583
Epoch: 78 | Iteration number: [3870/4518] 85% | Training loss: 0.686929136006407
Epoch: 78 | Iteration number: [3880/4518] 85% | Training loss: 0.6869295839489121
Epoch: 78 | Iteration number: [3890/4518] 86% | Training loss: 0.6869286020341446
Epoch: 78 | Iteration number: [3900/4518] 86% | Training loss: 0.6869281541078519
Epoch: 78 | Iteration number: [3910/4518] 86% | Training loss: 0.6869255049454281
Epoch: 78 | Iteration number: [3920/4518] 86% | Training loss: 0.6869261045389029
Epoch: 78 | Iteration number: [3930/4518] 86% | Training loss: 0.6869292583629375
Epoch: 78 | Iteration number: [3940/4518] 87% | Training loss: 0.6869296963898663
Epoch: 78 | Iteration number: [3950/4518] 87% | Training loss: 0.6869290639026255
Epoch: 78 | Iteration number: [3960/4518] 87% | Training loss: 0.68693059153027
Epoch: 78 | Iteration number: [3970/4518] 87% | Training loss: 0.686930458821938
Epoch: 78 | Iteration number: [3980/4518] 88% | Training loss: 0.686930323455801
Epoch: 78 | Iteration number: [3990/4518] 88% | Training loss: 0.6869305863266899
Epoch: 78 | Iteration number: [4000/4518] 88% | Training loss: 0.6869325399249792
Epoch: 78 | Iteration number: [4010/4518] 88% | Training loss: 0.6869307303517834
Epoch: 78 | Iteration number: [4020/4518] 88% | Training loss: 0.6869306663375588
Epoch: 78 | Iteration number: [4030/4518] 89% | Training loss: 0.6869303387240796
Epoch: 78 | Iteration number: [4040/4518] 89% | Training loss: 0.6869283794471533
Epoch: 78 | Iteration number: [4050/4518] 89% | Training loss: 0.6869270177535068
Epoch: 78 | Iteration number: [4060/4518] 89% | Training loss: 0.6869257017603061
Epoch: 78 | Iteration number: [4070/4518] 90% | Training loss: 0.6869294960463662
Epoch: 78 | Iteration number: [4080/4518] 90% | Training loss: 0.686929879542075
Epoch: 78 | Iteration number: [4090/4518] 90% | Training loss: 0.6869284571382993
Epoch: 78 | Iteration number: [4100/4518] 90% | Training loss: 0.6869318831403081
Epoch: 78 | Iteration number: [4110/4518] 90% | Training loss: 0.6869332139944508
Epoch: 78 | Iteration number: [4120/4518] 91% | Training loss: 0.6869327433479643
Epoch: 78 | Iteration number: [4130/4518] 91% | Training loss: 0.6869328111482301
Epoch: 78 | Iteration number: [4140/4518] 91% | Training loss: 0.6869322179452233
Epoch: 78 | Iteration number: [4150/4518] 91% | Training loss: 0.6869324609601354
Epoch: 78 | Iteration number: [4160/4518] 92% | Training loss: 0.6869288991133754
Epoch: 78 | Iteration number: [4170/4518] 92% | Training loss: 0.6869308044298661
Epoch: 78 | Iteration number: [4180/4518] 92% | Training loss: 0.6869321501996528
Epoch: 78 | Iteration number: [4190/4518] 92% | Training loss: 0.6869322429551145
Epoch: 78 | Iteration number: [4200/4518] 92% | Training loss: 0.686930161302998
Epoch: 78 | Iteration number: [4210/4518] 93% | Training loss: 0.6869311512082886
Epoch: 78 | Iteration number: [4220/4518] 93% | Training loss: 0.6869312899655076
Epoch: 78 | Iteration number: [4230/4518] 93% | Training loss: 0.6869320958923223
Epoch: 78 | Iteration number: [4240/4518] 93% | Training loss: 0.6869305459958203
Epoch: 78 | Iteration number: [4250/4518] 94% | Training loss: 0.6869304774088018
Epoch: 78 | Iteration number: [4260/4518] 94% | Training loss: 0.6869314439979517
Epoch: 78 | Iteration number: [4270/4518] 94% | Training loss: 0.686932057700615
Epoch: 78 | Iteration number: [4280/4518] 94% | Training loss: 0.6869335668527077
Epoch: 78 | Iteration number: [4290/4518] 94% | Training loss: 0.6869304497897764
Epoch: 78 | Iteration number: [4300/4518] 95% | Training loss: 0.6869295961912288
Epoch: 78 | Iteration number: [4310/4518] 95% | Training loss: 0.6869309135628411
Epoch: 78 | Iteration number: [4320/4518] 95% | Training loss: 0.686927707300142
Epoch: 78 | Iteration number: [4330/4518] 95% | Training loss: 0.6869262722292894
Epoch: 78 | Iteration number: [4340/4518] 96% | Training loss: 0.6869257013643941
Epoch: 78 | Iteration number: [4350/4518] 96% | Training loss: 0.6869266666489086
Epoch: 78 | Iteration number: [4360/4518] 96% | Training loss: 0.6869243438227461
Epoch: 78 | Iteration number: [4370/4518] 96% | Training loss: 0.6869191900543544
Epoch: 78 | Iteration number: [4380/4518] 96% | Training loss: 0.6869192935424309
Epoch: 78 | Iteration number: [4390/4518] 97% | Training loss: 0.686919328115524
Epoch: 78 | Iteration number: [4400/4518] 97% | Training loss: 0.6869196728549221
Epoch: 78 | Iteration number: [4410/4518] 97% | Training loss: 0.6869217052481342
Epoch: 78 | Iteration number: [4420/4518] 97% | Training loss: 0.6869232828800494
Epoch: 78 | Iteration number: [4430/4518] 98% | Training loss: 0.6869205805302743
Epoch: 78 | Iteration number: [4440/4518] 98% | Training loss: 0.6869193448945209
Epoch: 78 | Iteration number: [4450/4518] 98% | Training loss: 0.6869195406356554
Epoch: 78 | Iteration number: [4460/4518] 98% | Training loss: 0.6869187222868872
Epoch: 78 | Iteration number: [4470/4518] 98% | Training loss: 0.686917483193229
Epoch: 78 | Iteration number: [4480/4518] 99% | Training loss: 0.6869158687602196
Epoch: 78 | Iteration number: [4490/4518] 99% | Training loss: 0.6869160632779179
Epoch: 78 | Iteration number: [4500/4518] 99% | Training loss: 0.6869164254797829
Epoch: 78 | Iteration number: [4510/4518] 99% | Training loss: 0.686917385188016

 End of epoch: 78 | Train Loss: 0.6867630395835456 | Training Time: 634 

 End of epoch: 78 | Eval Loss: 0.6896017303272169 | Evaluating Time: 17 
Epoch: 79 | Iteration number: [10/4518] 0% | Training loss: 0.7545524358749389
Epoch: 79 | Iteration number: [20/4518] 0% | Training loss: 0.7204936236143112
Epoch: 79 | Iteration number: [30/4518] 0% | Training loss: 0.7089905937512716
Epoch: 79 | Iteration number: [40/4518] 0% | Training loss: 0.703274430334568
Epoch: 79 | Iteration number: [50/4518] 1% | Training loss: 0.700075796842575
Epoch: 79 | Iteration number: [60/4518] 1% | Training loss: 0.6980123519897461
Epoch: 79 | Iteration number: [70/4518] 1% | Training loss: 0.6963632549558367
Epoch: 79 | Iteration number: [80/4518] 1% | Training loss: 0.6952083170413971
Epoch: 79 | Iteration number: [90/4518] 1% | Training loss: 0.694277247455385
Epoch: 79 | Iteration number: [100/4518] 2% | Training loss: 0.6936151522397995
Epoch: 79 | Iteration number: [110/4518] 2% | Training loss: 0.6929959492249922
Epoch: 79 | Iteration number: [120/4518] 2% | Training loss: 0.6923740550875663
Epoch: 79 | Iteration number: [130/4518] 2% | Training loss: 0.6919220309991103
Epoch: 79 | Iteration number: [140/4518] 3% | Training loss: 0.6914873221090861
Epoch: 79 | Iteration number: [150/4518] 3% | Training loss: 0.6912633407115937
Epoch: 79 | Iteration number: [160/4518] 3% | Training loss: 0.6909437838941812
Epoch: 79 | Iteration number: [170/4518] 3% | Training loss: 0.6906490890418782
Epoch: 79 | Iteration number: [180/4518] 3% | Training loss: 0.6905115213659074
Epoch: 79 | Iteration number: [190/4518] 4% | Training loss: 0.6902823877962012
Epoch: 79 | Iteration number: [200/4518] 4% | Training loss: 0.6900910052657128
Epoch: 79 | Iteration number: [210/4518] 4% | Training loss: 0.6899853010972341
Epoch: 79 | Iteration number: [220/4518] 4% | Training loss: 0.6898102754896337
Epoch: 79 | Iteration number: [230/4518] 5% | Training loss: 0.6895859663901122
Epoch: 79 | Iteration number: [240/4518] 5% | Training loss: 0.6895239604016145
Epoch: 79 | Iteration number: [250/4518] 5% | Training loss: 0.6894213931560517
Epoch: 79 | Iteration number: [260/4518] 5% | Training loss: 0.6892898357831515
Epoch: 79 | Iteration number: [270/4518] 5% | Training loss: 0.6892014344533285
Epoch: 79 | Iteration number: [280/4518] 6% | Training loss: 0.6891122977648463
Epoch: 79 | Iteration number: [290/4518] 6% | Training loss: 0.6890572323881347
Epoch: 79 | Iteration number: [300/4518] 6% | Training loss: 0.688977741797765
Epoch: 79 | Iteration number: [310/4518] 6% | Training loss: 0.6889331131212173
Epoch: 79 | Iteration number: [320/4518] 7% | Training loss: 0.6888419179245829
Epoch: 79 | Iteration number: [330/4518] 7% | Training loss: 0.6887744291262193
Epoch: 79 | Iteration number: [340/4518] 7% | Training loss: 0.6887006137300941
Epoch: 79 | Iteration number: [350/4518] 7% | Training loss: 0.6886413955688476
Epoch: 79 | Iteration number: [360/4518] 7% | Training loss: 0.6886110229624642
Epoch: 79 | Iteration number: [370/4518] 8% | Training loss: 0.68853408726486
Epoch: 79 | Iteration number: [380/4518] 8% | Training loss: 0.6885209790970149
Epoch: 79 | Iteration number: [390/4518] 8% | Training loss: 0.6884733866422604
Epoch: 79 | Iteration number: [400/4518] 8% | Training loss: 0.6884580437839031
Epoch: 79 | Iteration number: [410/4518] 9% | Training loss: 0.6884322131552347
Epoch: 79 | Iteration number: [420/4518] 9% | Training loss: 0.6884266735542388
Epoch: 79 | Iteration number: [430/4518] 9% | Training loss: 0.6883544955142709
Epoch: 79 | Iteration number: [440/4518] 9% | Training loss: 0.6883382760665634
Epoch: 79 | Iteration number: [450/4518] 9% | Training loss: 0.6882946091228062
Epoch: 79 | Iteration number: [460/4518] 10% | Training loss: 0.6882616527702498
Epoch: 79 | Iteration number: [470/4518] 10% | Training loss: 0.6882195572903815
Epoch: 79 | Iteration number: [480/4518] 10% | Training loss: 0.6881947374592224
Epoch: 79 | Iteration number: [490/4518] 10% | Training loss: 0.688153730363262
Epoch: 79 | Iteration number: [500/4518] 11% | Training loss: 0.6881139143705368
Epoch: 79 | Iteration number: [510/4518] 11% | Training loss: 0.6880903530354593
Epoch: 79 | Iteration number: [520/4518] 11% | Training loss: 0.688082557458144
Epoch: 79 | Iteration number: [530/4518] 11% | Training loss: 0.6880492287986684
Epoch: 79 | Iteration number: [540/4518] 11% | Training loss: 0.6880115341257166
Epoch: 79 | Iteration number: [550/4518] 12% | Training loss: 0.6880007670142434
Epoch: 79 | Iteration number: [560/4518] 12% | Training loss: 0.6879955141672066
Epoch: 79 | Iteration number: [570/4518] 12% | Training loss: 0.6879462395843706
Epoch: 79 | Iteration number: [580/4518] 12% | Training loss: 0.6879265132649192
Epoch: 79 | Iteration number: [590/4518] 13% | Training loss: 0.6878918796272601
Epoch: 79 | Iteration number: [600/4518] 13% | Training loss: 0.6878729203343391
Epoch: 79 | Iteration number: [610/4518] 13% | Training loss: 0.6878580525273182
Epoch: 79 | Iteration number: [620/4518] 13% | Training loss: 0.6878535773484937
Epoch: 79 | Iteration number: [630/4518] 13% | Training loss: 0.6878259248203702
Epoch: 79 | Iteration number: [640/4518] 14% | Training loss: 0.6877925305627286
Epoch: 79 | Iteration number: [650/4518] 14% | Training loss: 0.6877867747270144
Epoch: 79 | Iteration number: [660/4518] 14% | Training loss: 0.687777763876048
Epoch: 79 | Iteration number: [670/4518] 14% | Training loss: 0.6877618649112645
Epoch: 79 | Iteration number: [680/4518] 15% | Training loss: 0.6877523849992191
Epoch: 79 | Iteration number: [690/4518] 15% | Training loss: 0.6877218407997187
Epoch: 79 | Iteration number: [700/4518] 15% | Training loss: 0.6877154424360821
Epoch: 79 | Iteration number: [710/4518] 15% | Training loss: 0.6877099877511951
Epoch: 79 | Iteration number: [720/4518] 15% | Training loss: 0.6876847065157361
Epoch: 79 | Iteration number: [730/4518] 16% | Training loss: 0.6876761621808353
Epoch: 79 | Iteration number: [740/4518] 16% | Training loss: 0.6876718128049696
Epoch: 79 | Iteration number: [750/4518] 16% | Training loss: 0.6876661520004272
Epoch: 79 | Iteration number: [760/4518] 16% | Training loss: 0.6876444167996708
Epoch: 79 | Iteration number: [770/4518] 17% | Training loss: 0.6876237983827467
Epoch: 79 | Iteration number: [780/4518] 17% | Training loss: 0.6876035071336306
Epoch: 79 | Iteration number: [790/4518] 17% | Training loss: 0.687572933375081
Epoch: 79 | Iteration number: [800/4518] 17% | Training loss: 0.6875509300082921
Epoch: 79 | Iteration number: [810/4518] 17% | Training loss: 0.6875479202947499
Epoch: 79 | Iteration number: [820/4518] 18% | Training loss: 0.6875262921176306
Epoch: 79 | Iteration number: [830/4518] 18% | Training loss: 0.6875131391617189
Epoch: 79 | Iteration number: [840/4518] 18% | Training loss: 0.6874982324384508
Epoch: 79 | Iteration number: [850/4518] 18% | Training loss: 0.687474528761471
Epoch: 79 | Iteration number: [860/4518] 19% | Training loss: 0.687442525805429
Epoch: 79 | Iteration number: [870/4518] 19% | Training loss: 0.6874186841235763
Epoch: 79 | Iteration number: [880/4518] 19% | Training loss: 0.6874233255332166
Epoch: 79 | Iteration number: [890/4518] 19% | Training loss: 0.687419132771117
Epoch: 79 | Iteration number: [900/4518] 19% | Training loss: 0.6874134477641848
Epoch: 79 | Iteration number: [910/4518] 20% | Training loss: 0.6873925962290921
Epoch: 79 | Iteration number: [920/4518] 20% | Training loss: 0.687386359533538
Epoch: 79 | Iteration number: [930/4518] 20% | Training loss: 0.6873726294245771
Epoch: 79 | Iteration number: [940/4518] 20% | Training loss: 0.6873496106964476
Epoch: 79 | Iteration number: [950/4518] 21% | Training loss: 0.6873410797746557
Epoch: 79 | Iteration number: [960/4518] 21% | Training loss: 0.6873532576486469
Epoch: 79 | Iteration number: [970/4518] 21% | Training loss: 0.6873466807542388
Epoch: 79 | Iteration number: [980/4518] 21% | Training loss: 0.6873531098876681
Epoch: 79 | Iteration number: [990/4518] 21% | Training loss: 0.6873536494043139
Epoch: 79 | Iteration number: [1000/4518] 22% | Training loss: 0.6873571221828461
Epoch: 79 | Iteration number: [1010/4518] 22% | Training loss: 0.6873361391596274
Epoch: 79 | Iteration number: [1020/4518] 22% | Training loss: 0.687324039199773
Epoch: 79 | Iteration number: [1030/4518] 22% | Training loss: 0.6873192148301208
Epoch: 79 | Iteration number: [1040/4518] 23% | Training loss: 0.6873149049396698
Epoch: 79 | Iteration number: [1050/4518] 23% | Training loss: 0.6873125428812844
Epoch: 79 | Iteration number: [1060/4518] 23% | Training loss: 0.6872974689839021
Epoch: 79 | Iteration number: [1070/4518] 23% | Training loss: 0.687302099488606
Epoch: 79 | Iteration number: [1080/4518] 23% | Training loss: 0.6872909753410904
Epoch: 79 | Iteration number: [1090/4518] 24% | Training loss: 0.6872913577687849
Epoch: 79 | Iteration number: [1100/4518] 24% | Training loss: 0.6872695837237618
Epoch: 79 | Iteration number: [1110/4518] 24% | Training loss: 0.6872612494606155
Epoch: 79 | Iteration number: [1120/4518] 24% | Training loss: 0.6872581590499197
Epoch: 79 | Iteration number: [1130/4518] 25% | Training loss: 0.6872449043050276
Epoch: 79 | Iteration number: [1140/4518] 25% | Training loss: 0.687239073138488
Epoch: 79 | Iteration number: [1150/4518] 25% | Training loss: 0.6872281524409418
Epoch: 79 | Iteration number: [1160/4518] 25% | Training loss: 0.6872138834719
Epoch: 79 | Iteration number: [1170/4518] 25% | Training loss: 0.6872000452799675
Epoch: 79 | Iteration number: [1180/4518] 26% | Training loss: 0.6871987770674592
Epoch: 79 | Iteration number: [1190/4518] 26% | Training loss: 0.6872001524732895
Epoch: 79 | Iteration number: [1200/4518] 26% | Training loss: 0.6871998614569506
Epoch: 79 | Iteration number: [1210/4518] 26% | Training loss: 0.6871889398610296
Epoch: 79 | Iteration number: [1220/4518] 27% | Training loss: 0.6871799912609038
Epoch: 79 | Iteration number: [1230/4518] 27% | Training loss: 0.6871722452524232
Epoch: 79 | Iteration number: [1240/4518] 27% | Training loss: 0.687170379152221
Epoch: 79 | Iteration number: [1250/4518] 27% | Training loss: 0.6871570336818695
Epoch: 79 | Iteration number: [1260/4518] 27% | Training loss: 0.6871658532392411
Epoch: 79 | Iteration number: [1270/4518] 28% | Training loss: 0.6871718568126047
Epoch: 79 | Iteration number: [1280/4518] 28% | Training loss: 0.687170869577676
Epoch: 79 | Iteration number: [1290/4518] 28% | Training loss: 0.687158706206684
Epoch: 79 | Iteration number: [1300/4518] 28% | Training loss: 0.6871521046528449
Epoch: 79 | Iteration number: [1310/4518] 28% | Training loss: 0.6871490954442788
Epoch: 79 | Iteration number: [1320/4518] 29% | Training loss: 0.6871464394258731
Epoch: 79 | Iteration number: [1330/4518] 29% | Training loss: 0.6871475950219578
Epoch: 79 | Iteration number: [1340/4518] 29% | Training loss: 0.6871474918144852
Epoch: 79 | Iteration number: [1350/4518] 29% | Training loss: 0.6871357070075141
Epoch: 79 | Iteration number: [1360/4518] 30% | Training loss: 0.6871316558297943
Epoch: 79 | Iteration number: [1370/4518] 30% | Training loss: 0.6871356355447839
Epoch: 79 | Iteration number: [1380/4518] 30% | Training loss: 0.6871315778597541
Epoch: 79 | Iteration number: [1390/4518] 30% | Training loss: 0.6871208297691757
Epoch: 79 | Iteration number: [1400/4518] 30% | Training loss: 0.6871162030952317
Epoch: 79 | Iteration number: [1410/4518] 31% | Training loss: 0.687114278982717
Epoch: 79 | Iteration number: [1420/4518] 31% | Training loss: 0.6871140360412463
Epoch: 79 | Iteration number: [1430/4518] 31% | Training loss: 0.687119426385506
Epoch: 79 | Iteration number: [1440/4518] 31% | Training loss: 0.6871070536060466
Epoch: 79 | Iteration number: [1450/4518] 32% | Training loss: 0.687102167811887
Epoch: 79 | Iteration number: [1460/4518] 32% | Training loss: 0.6871040278101621
Epoch: 79 | Iteration number: [1470/4518] 32% | Training loss: 0.6871006029803737
Epoch: 79 | Iteration number: [1480/4518] 32% | Training loss: 0.6870953732245677
Epoch: 79 | Iteration number: [1490/4518] 32% | Training loss: 0.6870964410321024
Epoch: 79 | Iteration number: [1500/4518] 33% | Training loss: 0.6870880386829377
Epoch: 79 | Iteration number: [1510/4518] 33% | Training loss: 0.6870865635129789
Epoch: 79 | Iteration number: [1520/4518] 33% | Training loss: 0.6870805227442791
Epoch: 79 | Iteration number: [1530/4518] 33% | Training loss: 0.6870846771336848
Epoch: 79 | Iteration number: [1540/4518] 34% | Training loss: 0.6870761987063791
Epoch: 79 | Iteration number: [1550/4518] 34% | Training loss: 0.6870645328490965
Epoch: 79 | Iteration number: [1560/4518] 34% | Training loss: 0.6870625073328996
Epoch: 79 | Iteration number: [1570/4518] 34% | Training loss: 0.6870598230771958
Epoch: 79 | Iteration number: [1580/4518] 34% | Training loss: 0.687058625040175
Epoch: 79 | Iteration number: [1590/4518] 35% | Training loss: 0.6870620874114006
Epoch: 79 | Iteration number: [1600/4518] 35% | Training loss: 0.6870615810900926
Epoch: 79 | Iteration number: [1610/4518] 35% | Training loss: 0.6870675684502406
Epoch: 79 | Iteration number: [1620/4518] 35% | Training loss: 0.687070831509284
Epoch: 79 | Iteration number: [1630/4518] 36% | Training loss: 0.687075796961053
Epoch: 79 | Iteration number: [1640/4518] 36% | Training loss: 0.6870740161072917
Epoch: 79 | Iteration number: [1650/4518] 36% | Training loss: 0.6870677557497313
Epoch: 79 | Iteration number: [1660/4518] 36% | Training loss: 0.6870639927415962
Epoch: 79 | Iteration number: [1670/4518] 36% | Training loss: 0.6870587807929445
Epoch: 79 | Iteration number: [1680/4518] 37% | Training loss: 0.6870600873870509
Epoch: 79 | Iteration number: [1690/4518] 37% | Training loss: 0.6870626880572392
Epoch: 79 | Iteration number: [1700/4518] 37% | Training loss: 0.6870611531594221
Epoch: 79 | Iteration number: [1710/4518] 37% | Training loss: 0.6870595957800659
Epoch: 79 | Iteration number: [1720/4518] 38% | Training loss: 0.6870586437541385
Epoch: 79 | Iteration number: [1730/4518] 38% | Training loss: 0.687059766467596
Epoch: 79 | Iteration number: [1740/4518] 38% | Training loss: 0.6870632761511309
Epoch: 79 | Iteration number: [1750/4518] 38% | Training loss: 0.6870606800147465
Epoch: 79 | Iteration number: [1760/4518] 38% | Training loss: 0.6870622673495249
Epoch: 79 | Iteration number: [1770/4518] 39% | Training loss: 0.6870598349194069
Epoch: 79 | Iteration number: [1780/4518] 39% | Training loss: 0.6870563250579191
Epoch: 79 | Iteration number: [1790/4518] 39% | Training loss: 0.6870508622190806
Epoch: 79 | Iteration number: [1800/4518] 39% | Training loss: 0.6870420435733265
Epoch: 79 | Iteration number: [1810/4518] 40% | Training loss: 0.6870386619923523
Epoch: 79 | Iteration number: [1820/4518] 40% | Training loss: 0.6870444328247846
Epoch: 79 | Iteration number: [1830/4518] 40% | Training loss: 0.6870477952266651
Epoch: 79 | Iteration number: [1840/4518] 40% | Training loss: 0.6870546255098737
Epoch: 79 | Iteration number: [1850/4518] 40% | Training loss: 0.6870588386703181
Epoch: 79 | Iteration number: [1860/4518] 41% | Training loss: 0.6870533767887341
Epoch: 79 | Iteration number: [1870/4518] 41% | Training loss: 0.6870520038400741
Epoch: 79 | Iteration number: [1880/4518] 41% | Training loss: 0.6870430974884236
Epoch: 79 | Iteration number: [1890/4518] 41% | Training loss: 0.6870386408119605
Epoch: 79 | Iteration number: [1900/4518] 42% | Training loss: 0.6870398512325789
Epoch: 79 | Iteration number: [1910/4518] 42% | Training loss: 0.6870295220644687
Epoch: 79 | Iteration number: [1920/4518] 42% | Training loss: 0.6870313330243031
Epoch: 79 | Iteration number: [1930/4518] 42% | Training loss: 0.68703679769768
Epoch: 79 | Iteration number: [1940/4518] 42% | Training loss: 0.6870384186506271
Epoch: 79 | Iteration number: [1950/4518] 43% | Training loss: 0.6870390670727461
Epoch: 79 | Iteration number: [1960/4518] 43% | Training loss: 0.6870408593695991
Epoch: 79 | Iteration number: [1970/4518] 43% | Training loss: 0.6870417863886974
Epoch: 79 | Iteration number: [1980/4518] 43% | Training loss: 0.6870421398769725
Epoch: 79 | Iteration number: [1990/4518] 44% | Training loss: 0.6870429824944118
Epoch: 79 | Iteration number: [2000/4518] 44% | Training loss: 0.6870467877686024
Epoch: 79 | Iteration number: [2010/4518] 44% | Training loss: 0.6870466613947456
Epoch: 79 | Iteration number: [2020/4518] 44% | Training loss: 0.6870394385687195
Epoch: 79 | Iteration number: [2030/4518] 44% | Training loss: 0.6870373630171339
Epoch: 79 | Iteration number: [2040/4518] 45% | Training loss: 0.6870399040918724
Epoch: 79 | Iteration number: [2050/4518] 45% | Training loss: 0.6870406548860597
Epoch: 79 | Iteration number: [2060/4518] 45% | Training loss: 0.687039614128835
Epoch: 79 | Iteration number: [2070/4518] 45% | Training loss: 0.6870358670103377
Epoch: 79 | Iteration number: [2080/4518] 46% | Training loss: 0.6870351323141501
Epoch: 79 | Iteration number: [2090/4518] 46% | Training loss: 0.6870302794652693
Epoch: 79 | Iteration number: [2100/4518] 46% | Training loss: 0.6870251715750921
Epoch: 79 | Iteration number: [2110/4518] 46% | Training loss: 0.6870258794576636
Epoch: 79 | Iteration number: [2120/4518] 46% | Training loss: 0.6870240723187069
Epoch: 79 | Iteration number: [2130/4518] 47% | Training loss: 0.6870246578550114
Epoch: 79 | Iteration number: [2140/4518] 47% | Training loss: 0.6870268552659828
Epoch: 79 | Iteration number: [2150/4518] 47% | Training loss: 0.6870294288701789
Epoch: 79 | Iteration number: [2160/4518] 47% | Training loss: 0.6870318097924745
Epoch: 79 | Iteration number: [2170/4518] 48% | Training loss: 0.687028393080707
Epoch: 79 | Iteration number: [2180/4518] 48% | Training loss: 0.6870283890481389
Epoch: 79 | Iteration number: [2190/4518] 48% | Training loss: 0.6870268480146312
Epoch: 79 | Iteration number: [2200/4518] 48% | Training loss: 0.6870262572711164
Epoch: 79 | Iteration number: [2210/4518] 48% | Training loss: 0.6870278338231652
Epoch: 79 | Iteration number: [2220/4518] 49% | Training loss: 0.687026335097648
Epoch: 79 | Iteration number: [2230/4518] 49% | Training loss: 0.687024605995871
Epoch: 79 | Iteration number: [2240/4518] 49% | Training loss: 0.6870235567380275
Epoch: 79 | Iteration number: [2250/4518] 49% | Training loss: 0.6870231306817797
Epoch: 79 | Iteration number: [2260/4518] 50% | Training loss: 0.6870202319811931
Epoch: 79 | Iteration number: [2270/4518] 50% | Training loss: 0.6870205353010068
Epoch: 79 | Iteration number: [2280/4518] 50% | Training loss: 0.6870163032621668
Epoch: 79 | Iteration number: [2290/4518] 50% | Training loss: 0.6870163446951121
Epoch: 79 | Iteration number: [2300/4518] 50% | Training loss: 0.6870132273176442
Epoch: 79 | Iteration number: [2310/4518] 51% | Training loss: 0.6870091218710977
Epoch: 79 | Iteration number: [2320/4518] 51% | Training loss: 0.6870076389148317
Epoch: 79 | Iteration number: [2330/4518] 51% | Training loss: 0.6870040967229099
Epoch: 79 | Iteration number: [2340/4518] 51% | Training loss: 0.6869993681836332
Epoch: 79 | Iteration number: [2350/4518] 52% | Training loss: 0.6869991938357658
Epoch: 79 | Iteration number: [2360/4518] 52% | Training loss: 0.6869948490696438
Epoch: 79 | Iteration number: [2370/4518] 52% | Training loss: 0.6869897541366046
Epoch: 79 | Iteration number: [2380/4518] 52% | Training loss: 0.686982660734353
Epoch: 79 | Iteration number: [2390/4518] 52% | Training loss: 0.6869790323857982
Epoch: 79 | Iteration number: [2400/4518] 53% | Training loss: 0.6869773432115713
Epoch: 79 | Iteration number: [2410/4518] 53% | Training loss: 0.686974353587479
Epoch: 79 | Iteration number: [2420/4518] 53% | Training loss: 0.6869746735765915
Epoch: 79 | Iteration number: [2430/4518] 53% | Training loss: 0.6869707801459748
Epoch: 79 | Iteration number: [2440/4518] 54% | Training loss: 0.6869665872610984
Epoch: 79 | Iteration number: [2450/4518] 54% | Training loss: 0.6869659199763317
Epoch: 79 | Iteration number: [2460/4518] 54% | Training loss: 0.686964318228931
Epoch: 79 | Iteration number: [2470/4518] 54% | Training loss: 0.6869658775657778
Epoch: 79 | Iteration number: [2480/4518] 54% | Training loss: 0.6869684706051503
Epoch: 79 | Iteration number: [2490/4518] 55% | Training loss: 0.6869703086983248
Epoch: 79 | Iteration number: [2500/4518] 55% | Training loss: 0.686974682188034
Epoch: 79 | Iteration number: [2510/4518] 55% | Training loss: 0.686969654469851
Epoch: 79 | Iteration number: [2520/4518] 55% | Training loss: 0.686971628476703
Epoch: 79 | Iteration number: [2530/4518] 55% | Training loss: 0.6869699315591292
Epoch: 79 | Iteration number: [2540/4518] 56% | Training loss: 0.6869699659075325
Epoch: 79 | Iteration number: [2550/4518] 56% | Training loss: 0.6869728069913154
Epoch: 79 | Iteration number: [2560/4518] 56% | Training loss: 0.6869714408414438
Epoch: 79 | Iteration number: [2570/4518] 56% | Training loss: 0.686969141227262
Epoch: 79 | Iteration number: [2580/4518] 57% | Training loss: 0.6869687044112257
Epoch: 79 | Iteration number: [2590/4518] 57% | Training loss: 0.6869695733182679
Epoch: 79 | Iteration number: [2600/4518] 57% | Training loss: 0.6869716561986849
Epoch: 79 | Iteration number: [2610/4518] 57% | Training loss: 0.6869698602577735
Epoch: 79 | Iteration number: [2620/4518] 57% | Training loss: 0.68697269986604
Epoch: 79 | Iteration number: [2630/4518] 58% | Training loss: 0.6869706756941719
Epoch: 79 | Iteration number: [2640/4518] 58% | Training loss: 0.6869712084757559
Epoch: 79 | Iteration number: [2650/4518] 58% | Training loss: 0.6869686809125937
Epoch: 79 | Iteration number: [2660/4518] 58% | Training loss: 0.6869674635336811
Epoch: 79 | Iteration number: [2670/4518] 59% | Training loss: 0.686966741152024
Epoch: 79 | Iteration number: [2680/4518] 59% | Training loss: 0.6869671709501921
Epoch: 79 | Iteration number: [2690/4518] 59% | Training loss: 0.6869643241277857
Epoch: 79 | Iteration number: [2700/4518] 59% | Training loss: 0.6869631117803079
Epoch: 79 | Iteration number: [2710/4518] 59% | Training loss: 0.6869562271556291
Epoch: 79 | Iteration number: [2720/4518] 60% | Training loss: 0.6869585315751678
Epoch: 79 | Iteration number: [2730/4518] 60% | Training loss: 0.6869578791843666
Epoch: 79 | Iteration number: [2740/4518] 60% | Training loss: 0.6869563211272233
Epoch: 79 | Iteration number: [2750/4518] 60% | Training loss: 0.6869575549689206
Epoch: 79 | Iteration number: [2760/4518] 61% | Training loss: 0.6869562063960062
Epoch: 79 | Iteration number: [2770/4518] 61% | Training loss: 0.6869560915425366
Epoch: 79 | Iteration number: [2780/4518] 61% | Training loss: 0.6869479492628318
Epoch: 79 | Iteration number: [2790/4518] 61% | Training loss: 0.6869481800704874
Epoch: 79 | Iteration number: [2800/4518] 61% | Training loss: 0.6869512787248407
Epoch: 79 | Iteration number: [2810/4518] 62% | Training loss: 0.6869485061151701
Epoch: 79 | Iteration number: [2820/4518] 62% | Training loss: 0.6869497416924077
Epoch: 79 | Iteration number: [2830/4518] 62% | Training loss: 0.6869552306699247
Epoch: 79 | Iteration number: [2840/4518] 62% | Training loss: 0.6869604331926561
Epoch: 79 | Iteration number: [2850/4518] 63% | Training loss: 0.6869601287549002
Epoch: 79 | Iteration number: [2860/4518] 63% | Training loss: 0.6869611072165149
Epoch: 79 | Iteration number: [2870/4518] 63% | Training loss: 0.6869599584087678
Epoch: 79 | Iteration number: [2880/4518] 63% | Training loss: 0.6869533534472188
Epoch: 79 | Iteration number: [2890/4518] 63% | Training loss: 0.686954741783208
Epoch: 79 | Iteration number: [2900/4518] 64% | Training loss: 0.6869568188231567
Epoch: 79 | Iteration number: [2910/4518] 64% | Training loss: 0.6869537628803056
Epoch: 79 | Iteration number: [2920/4518] 64% | Training loss: 0.6869547898026361
Epoch: 79 | Iteration number: [2930/4518] 64% | Training loss: 0.6869566677780281
Epoch: 79 | Iteration number: [2940/4518] 65% | Training loss: 0.68695298214348
Epoch: 79 | Iteration number: [2950/4518] 65% | Training loss: 0.686949293492204
Epoch: 79 | Iteration number: [2960/4518] 65% | Training loss: 0.686949214218436
Epoch: 79 | Iteration number: [2970/4518] 65% | Training loss: 0.6869534128643446
Epoch: 79 | Iteration number: [2980/4518] 65% | Training loss: 0.6869546048793217
Epoch: 79 | Iteration number: [2990/4518] 66% | Training loss: 0.6869471464667432
Epoch: 79 | Iteration number: [3000/4518] 66% | Training loss: 0.6869498560031255
Epoch: 79 | Iteration number: [3010/4518] 66% | Training loss: 0.6869488125623658
Epoch: 79 | Iteration number: [3020/4518] 66% | Training loss: 0.6869474501996641
Epoch: 79 | Iteration number: [3030/4518] 67% | Training loss: 0.6869450201885928
Epoch: 79 | Iteration number: [3040/4518] 67% | Training loss: 0.6869445414723534
Epoch: 79 | Iteration number: [3050/4518] 67% | Training loss: 0.6869398517686812
Epoch: 79 | Iteration number: [3060/4518] 67% | Training loss: 0.686940962952726
Epoch: 79 | Iteration number: [3070/4518] 67% | Training loss: 0.6869418961411579
Epoch: 79 | Iteration number: [3080/4518] 68% | Training loss: 0.6869406090541319
Epoch: 79 | Iteration number: [3090/4518] 68% | Training loss: 0.686938102731427
Epoch: 79 | Iteration number: [3100/4518] 68% | Training loss: 0.686942508816719
Epoch: 79 | Iteration number: [3110/4518] 68% | Training loss: 0.6869490677329122
Epoch: 79 | Iteration number: [3120/4518] 69% | Training loss: 0.6869523496772998
Epoch: 79 | Iteration number: [3130/4518] 69% | Training loss: 0.686950170993805
Epoch: 79 | Iteration number: [3140/4518] 69% | Training loss: 0.6869515228613167
Epoch: 79 | Iteration number: [3150/4518] 69% | Training loss: 0.686953274011612
Epoch: 79 | Iteration number: [3160/4518] 69% | Training loss: 0.6869495288103442
Epoch: 79 | Iteration number: [3170/4518] 70% | Training loss: 0.6869466821289965
Epoch: 79 | Iteration number: [3180/4518] 70% | Training loss: 0.6869466378628832
Epoch: 79 | Iteration number: [3190/4518] 70% | Training loss: 0.6869440478590962
Epoch: 79 | Iteration number: [3200/4518] 70% | Training loss: 0.6869427080638707
Epoch: 79 | Iteration number: [3210/4518] 71% | Training loss: 0.6869419571580917
Epoch: 79 | Iteration number: [3220/4518] 71% | Training loss: 0.6869402201094242
Epoch: 79 | Iteration number: [3230/4518] 71% | Training loss: 0.6869421600188265
Epoch: 79 | Iteration number: [3240/4518] 71% | Training loss: 0.6869402705703253
Epoch: 79 | Iteration number: [3250/4518] 71% | Training loss: 0.6869383218288422
Epoch: 79 | Iteration number: [3260/4518] 72% | Training loss: 0.6869387738178113
Epoch: 79 | Iteration number: [3270/4518] 72% | Training loss: 0.6869416966715355
Epoch: 79 | Iteration number: [3280/4518] 72% | Training loss: 0.6869443574147981
Epoch: 79 | Iteration number: [3290/4518] 72% | Training loss: 0.686945858588697
Epoch: 79 | Iteration number: [3300/4518] 73% | Training loss: 0.6869479539177634
Epoch: 79 | Iteration number: [3310/4518] 73% | Training loss: 0.6869446173535373
Epoch: 79 | Iteration number: [3320/4518] 73% | Training loss: 0.6869420379400253
Epoch: 79 | Iteration number: [3330/4518] 73% | Training loss: 0.6869423038429684
Epoch: 79 | Iteration number: [3340/4518] 73% | Training loss: 0.6869437813937307
Epoch: 79 | Iteration number: [3350/4518] 74% | Training loss: 0.6869393427336394
Epoch: 79 | Iteration number: [3360/4518] 74% | Training loss: 0.6869408101198219
Epoch: 79 | Iteration number: [3370/4518] 74% | Training loss: 0.6869409675944806
Epoch: 79 | Iteration number: [3380/4518] 74% | Training loss: 0.6869432706628326
Epoch: 79 | Iteration number: [3390/4518] 75% | Training loss: 0.6869474783583728
Epoch: 79 | Iteration number: [3400/4518] 75% | Training loss: 0.6869468519091606
Epoch: 79 | Iteration number: [3410/4518] 75% | Training loss: 0.686947008154609
Epoch: 79 | Iteration number: [3420/4518] 75% | Training loss: 0.686949987421956
Epoch: 79 | Iteration number: [3430/4518] 75% | Training loss: 0.6869485770300595
Epoch: 79 | Iteration number: [3440/4518] 76% | Training loss: 0.6869494417725608
Epoch: 79 | Iteration number: [3450/4518] 76% | Training loss: 0.6869525161169577
Epoch: 79 | Iteration number: [3460/4518] 76% | Training loss: 0.6869530784429153
Epoch: 79 | Iteration number: [3470/4518] 76% | Training loss: 0.6869506928522237
Epoch: 79 | Iteration number: [3480/4518] 77% | Training loss: 0.6869509768211979
Epoch: 79 | Iteration number: [3490/4518] 77% | Training loss: 0.6869519248049717
Epoch: 79 | Iteration number: [3500/4518] 77% | Training loss: 0.6869473886319569
Epoch: 79 | Iteration number: [3510/4518] 77% | Training loss: 0.6869439856618897
Epoch: 79 | Iteration number: [3520/4518] 77% | Training loss: 0.6869417906654152
Epoch: 79 | Iteration number: [3530/4518] 78% | Training loss: 0.6869387258551276
Epoch: 79 | Iteration number: [3540/4518] 78% | Training loss: 0.6869397318800964
Epoch: 79 | Iteration number: [3550/4518] 78% | Training loss: 0.6869404067287982
Epoch: 79 | Iteration number: [3560/4518] 78% | Training loss: 0.6869394498092405
Epoch: 79 | Iteration number: [3570/4518] 79% | Training loss: 0.6869347727432304
Epoch: 79 | Iteration number: [3580/4518] 79% | Training loss: 0.6869320381453583
Epoch: 79 | Iteration number: [3590/4518] 79% | Training loss: 0.686930738551371
Epoch: 79 | Iteration number: [3600/4518] 79% | Training loss: 0.6869314722882377
Epoch: 79 | Iteration number: [3610/4518] 79% | Training loss: 0.6869300909484852
Epoch: 79 | Iteration number: [3620/4518] 80% | Training loss: 0.6869279775994918
Epoch: 79 | Iteration number: [3630/4518] 80% | Training loss: 0.6869287650775646
Epoch: 79 | Iteration number: [3640/4518] 80% | Training loss: 0.6869289499062758
Epoch: 79 | Iteration number: [3650/4518] 80% | Training loss: 0.6869272646512071
Epoch: 79 | Iteration number: [3660/4518] 81% | Training loss: 0.6869278591024419
Epoch: 79 | Iteration number: [3670/4518] 81% | Training loss: 0.6869304354249294
Epoch: 79 | Iteration number: [3680/4518] 81% | Training loss: 0.6869320225456487
Epoch: 79 | Iteration number: [3690/4518] 81% | Training loss: 0.6869323593975729
Epoch: 79 | Iteration number: [3700/4518] 81% | Training loss: 0.6869332458038587
Epoch: 79 | Iteration number: [3710/4518] 82% | Training loss: 0.6869352432274112
Epoch: 79 | Iteration number: [3720/4518] 82% | Training loss: 0.686935704882427
Epoch: 79 | Iteration number: [3730/4518] 82% | Training loss: 0.6869376793943206
Epoch: 79 | Iteration number: [3740/4518] 82% | Training loss: 0.686934477871752
Epoch: 79 | Iteration number: [3750/4518] 83% | Training loss: 0.6869334859530131
Epoch: 79 | Iteration number: [3760/4518] 83% | Training loss: 0.686933973685224
Epoch: 79 | Iteration number: [3770/4518] 83% | Training loss: 0.6869324023432694
Epoch: 79 | Iteration number: [3780/4518] 83% | Training loss: 0.6869336626674764
Epoch: 79 | Iteration number: [3790/4518] 83% | Training loss: 0.6869322449676594
Epoch: 79 | Iteration number: [3800/4518] 84% | Training loss: 0.6869326823949814
Epoch: 79 | Iteration number: [3810/4518] 84% | Training loss: 0.6869311931095724
Epoch: 79 | Iteration number: [3820/4518] 84% | Training loss: 0.6869283541178828
Epoch: 79 | Iteration number: [3830/4518] 84% | Training loss: 0.6869278395144809
Epoch: 79 | Iteration number: [3840/4518] 84% | Training loss: 0.6869275326064478
Epoch: 79 | Iteration number: [3850/4518] 85% | Training loss: 0.6869259729323449
Epoch: 79 | Iteration number: [3860/4518] 85% | Training loss: 0.6869243257095159
Epoch: 79 | Iteration number: [3870/4518] 85% | Training loss: 0.6869266403737918
Epoch: 79 | Iteration number: [3880/4518] 85% | Training loss: 0.6869253248590784
Epoch: 79 | Iteration number: [3890/4518] 86% | Training loss: 0.6869232522338092
Epoch: 79 | Iteration number: [3900/4518] 86% | Training loss: 0.6869245934486389
Epoch: 79 | Iteration number: [3910/4518] 86% | Training loss: 0.686923796837897
Epoch: 79 | Iteration number: [3920/4518] 86% | Training loss: 0.6869273098603803
Epoch: 79 | Iteration number: [3930/4518] 86% | Training loss: 0.6869230577053914
Epoch: 79 | Iteration number: [3940/4518] 87% | Training loss: 0.6869227434324129
Epoch: 79 | Iteration number: [3950/4518] 87% | Training loss: 0.6869231912154186
Epoch: 79 | Iteration number: [3960/4518] 87% | Training loss: 0.6869206557219679
Epoch: 79 | Iteration number: [3970/4518] 87% | Training loss: 0.6869194985937411
Epoch: 79 | Iteration number: [3980/4518] 88% | Training loss: 0.686917568765693
Epoch: 79 | Iteration number: [3990/4518] 88% | Training loss: 0.6869198412972883
Epoch: 79 | Iteration number: [4000/4518] 88% | Training loss: 0.6869201882481575
Epoch: 79 | Iteration number: [4010/4518] 88% | Training loss: 0.6869221825849385
Epoch: 79 | Iteration number: [4020/4518] 88% | Training loss: 0.6869234400602122
Epoch: 79 | Iteration number: [4030/4518] 89% | Training loss: 0.6869229875486482
Epoch: 79 | Iteration number: [4040/4518] 89% | Training loss: 0.6869237668148361
Epoch: 79 | Iteration number: [4050/4518] 89% | Training loss: 0.686924151579539
Epoch: 79 | Iteration number: [4060/4518] 89% | Training loss: 0.6869215655649824
Epoch: 79 | Iteration number: [4070/4518] 90% | Training loss: 0.6869214917576577
Epoch: 79 | Iteration number: [4080/4518] 90% | Training loss: 0.6869201003336439
Epoch: 79 | Iteration number: [4090/4518] 90% | Training loss: 0.6869158512368471
Epoch: 79 | Iteration number: [4100/4518] 90% | Training loss: 0.6869147574174694
Epoch: 79 | Iteration number: [4110/4518] 90% | Training loss: 0.686913647123787
Epoch: 79 | Iteration number: [4120/4518] 91% | Training loss: 0.6869167677696468
Epoch: 79 | Iteration number: [4130/4518] 91% | Training loss: 0.6869192186481439
Epoch: 79 | Iteration number: [4140/4518] 91% | Training loss: 0.6869224130387468
Epoch: 79 | Iteration number: [4150/4518] 91% | Training loss: 0.6869250395211829
Epoch: 79 | Iteration number: [4160/4518] 92% | Training loss: 0.6869239100469993
Epoch: 79 | Iteration number: [4170/4518] 92% | Training loss: 0.6869250316556981
Epoch: 79 | Iteration number: [4180/4518] 92% | Training loss: 0.6869247608635414
Epoch: 79 | Iteration number: [4190/4518] 92% | Training loss: 0.6869230496428178
Epoch: 79 | Iteration number: [4200/4518] 92% | Training loss: 0.686922667154244
Epoch: 79 | Iteration number: [4210/4518] 93% | Training loss: 0.6869166283737735
Epoch: 79 | Iteration number: [4220/4518] 93% | Training loss: 0.6869143531362027
Epoch: 79 | Iteration number: [4230/4518] 93% | Training loss: 0.6869156029489305
Epoch: 79 | Iteration number: [4240/4518] 93% | Training loss: 0.6869198813191
Epoch: 79 | Iteration number: [4250/4518] 94% | Training loss: 0.6869210245469037
Epoch: 79 | Iteration number: [4260/4518] 94% | Training loss: 0.686919502067454
Epoch: 79 | Iteration number: [4270/4518] 94% | Training loss: 0.6869221711465849
Epoch: 79 | Iteration number: [4280/4518] 94% | Training loss: 0.6869211664266676
Epoch: 79 | Iteration number: [4290/4518] 94% | Training loss: 0.6869227482861294
Epoch: 79 | Iteration number: [4300/4518] 95% | Training loss: 0.6869213609501373
Epoch: 79 | Iteration number: [4310/4518] 95% | Training loss: 0.6869223095009885
Epoch: 79 | Iteration number: [4320/4518] 95% | Training loss: 0.6869217524511947
Epoch: 79 | Iteration number: [4330/4518] 95% | Training loss: 0.6869205338437342
Epoch: 79 | Iteration number: [4340/4518] 96% | Training loss: 0.6869175241564826
Epoch: 79 | Iteration number: [4350/4518] 96% | Training loss: 0.6869203292090317
Epoch: 79 | Iteration number: [4360/4518] 96% | Training loss: 0.686915399790357
Epoch: 79 | Iteration number: [4370/4518] 96% | Training loss: 0.6869166941610026
Epoch: 79 | Iteration number: [4380/4518] 96% | Training loss: 0.6869168936389767
Epoch: 79 | Iteration number: [4390/4518] 97% | Training loss: 0.686915533186906
Epoch: 79 | Iteration number: [4400/4518] 97% | Training loss: 0.6869141182845289
Epoch: 79 | Iteration number: [4410/4518] 97% | Training loss: 0.6869114977702532
Epoch: 79 | Iteration number: [4420/4518] 97% | Training loss: 0.6869111637993636
Epoch: 79 | Iteration number: [4430/4518] 98% | Training loss: 0.686912613151843
Epoch: 79 | Iteration number: [4440/4518] 98% | Training loss: 0.6869121932365873
Epoch: 79 | Iteration number: [4450/4518] 98% | Training loss: 0.6869135251072016
Epoch: 79 | Iteration number: [4460/4518] 98% | Training loss: 0.6869136685079523
Epoch: 79 | Iteration number: [4470/4518] 98% | Training loss: 0.6869161269142057
Epoch: 79 | Iteration number: [4480/4518] 99% | Training loss: 0.6869162530372185
Epoch: 79 | Iteration number: [4490/4518] 99% | Training loss: 0.6869153414112422
Epoch: 79 | Iteration number: [4500/4518] 99% | Training loss: 0.6869157092703714
Epoch: 79 | Iteration number: [4510/4518] 99% | Training loss: 0.6869170751777827

 End of epoch: 79 | Train Loss: 0.6867636026746142 | Training Time: 633 

 End of epoch: 79 | Eval Loss: 0.6898451277187893 | Evaluating Time: 17 
Epoch: 80 | Iteration number: [10/4518] 0% | Training loss: 0.7547733366489411
Epoch: 80 | Iteration number: [20/4518] 0% | Training loss: 0.7204846650362015
Epoch: 80 | Iteration number: [30/4518] 0% | Training loss: 0.7096518417199452
Epoch: 80 | Iteration number: [40/4518] 0% | Training loss: 0.7040177717804909
Epoch: 80 | Iteration number: [50/4518] 1% | Training loss: 0.7005147337913513
Epoch: 80 | Iteration number: [60/4518] 1% | Training loss: 0.6982106387615203
Epoch: 80 | Iteration number: [70/4518] 1% | Training loss: 0.696662529025759
Epoch: 80 | Iteration number: [80/4518] 1% | Training loss: 0.6953731402754784
Epoch: 80 | Iteration number: [90/4518] 1% | Training loss: 0.6944390727414025
Epoch: 80 | Iteration number: [100/4518] 2% | Training loss: 0.6937494772672653
Epoch: 80 | Iteration number: [110/4518] 2% | Training loss: 0.6930548424070532
Epoch: 80 | Iteration number: [120/4518] 2% | Training loss: 0.6926223586002985
Epoch: 80 | Iteration number: [130/4518] 2% | Training loss: 0.692167840554164
Epoch: 80 | Iteration number: [140/4518] 3% | Training loss: 0.6917192105736051
Epoch: 80 | Iteration number: [150/4518] 3% | Training loss: 0.6914038940270741
Epoch: 80 | Iteration number: [160/4518] 3% | Training loss: 0.6911607254296541
Epoch: 80 | Iteration number: [170/4518] 3% | Training loss: 0.690880286693573
Epoch: 80 | Iteration number: [180/4518] 3% | Training loss: 0.6907040589385562
Epoch: 80 | Iteration number: [190/4518] 4% | Training loss: 0.6905032644146367
Epoch: 80 | Iteration number: [200/4518] 4% | Training loss: 0.6902984371781349
Epoch: 80 | Iteration number: [210/4518] 4% | Training loss: 0.6901591570604415
Epoch: 80 | Iteration number: [220/4518] 4% | Training loss: 0.6899976334788582
Epoch: 80 | Iteration number: [230/4518] 5% | Training loss: 0.6898337011751922
Epoch: 80 | Iteration number: [240/4518] 5% | Training loss: 0.6897021842499574
Epoch: 80 | Iteration number: [250/4518] 5% | Training loss: 0.6895454075336457
Epoch: 80 | Iteration number: [260/4518] 5% | Training loss: 0.6893532450382526
Epoch: 80 | Iteration number: [270/4518] 5% | Training loss: 0.6892557972007327
Epoch: 80 | Iteration number: [280/4518] 6% | Training loss: 0.6891548931598663
Epoch: 80 | Iteration number: [290/4518] 6% | Training loss: 0.6890400512465116
Epoch: 80 | Iteration number: [300/4518] 6% | Training loss: 0.6889673258860906
Epoch: 80 | Iteration number: [310/4518] 6% | Training loss: 0.6889090347674585
Epoch: 80 | Iteration number: [320/4518] 7% | Training loss: 0.6887976100668312
Epoch: 80 | Iteration number: [330/4518] 7% | Training loss: 0.6887403144980921
Epoch: 80 | Iteration number: [340/4518] 7% | Training loss: 0.6886985820882461
Epoch: 80 | Iteration number: [350/4518] 7% | Training loss: 0.6886490024839129
Epoch: 80 | Iteration number: [360/4518] 7% | Training loss: 0.6885749568541845
Epoch: 80 | Iteration number: [370/4518] 8% | Training loss: 0.6885224757967768
Epoch: 80 | Iteration number: [380/4518] 8% | Training loss: 0.6884468026851353
Epoch: 80 | Iteration number: [390/4518] 8% | Training loss: 0.6884071266039824
Epoch: 80 | Iteration number: [400/4518] 8% | Training loss: 0.6883806079626084
Epoch: 80 | Iteration number: [410/4518] 9% | Training loss: 0.6883502226050308
Epoch: 80 | Iteration number: [420/4518] 9% | Training loss: 0.6883358102469217
Epoch: 80 | Iteration number: [430/4518] 9% | Training loss: 0.6882912985114165
Epoch: 80 | Iteration number: [440/4518] 9% | Training loss: 0.6882828361608765
Epoch: 80 | Iteration number: [450/4518] 9% | Training loss: 0.688240829176373
Epoch: 80 | Iteration number: [460/4518] 10% | Training loss: 0.6881876793892487
Epoch: 80 | Iteration number: [470/4518] 10% | Training loss: 0.6881217162659827
Epoch: 80 | Iteration number: [480/4518] 10% | Training loss: 0.6881169642011324
Epoch: 80 | Iteration number: [490/4518] 10% | Training loss: 0.6880945382069569
Epoch: 80 | Iteration number: [500/4518] 11% | Training loss: 0.6880790348052979
Epoch: 80 | Iteration number: [510/4518] 11% | Training loss: 0.6880360456073985
Epoch: 80 | Iteration number: [520/4518] 11% | Training loss: 0.6879846854851797
Epoch: 80 | Iteration number: [530/4518] 11% | Training loss: 0.6879492086059642
Epoch: 80 | Iteration number: [540/4518] 11% | Training loss: 0.6879263978313517
Epoch: 80 | Iteration number: [550/4518] 12% | Training loss: 0.6878938298875635
Epoch: 80 | Iteration number: [560/4518] 12% | Training loss: 0.6878665997513703
Epoch: 80 | Iteration number: [570/4518] 12% | Training loss: 0.6878658180696923
Epoch: 80 | Iteration number: [580/4518] 12% | Training loss: 0.6878480903033553
Epoch: 80 | Iteration number: [590/4518] 13% | Training loss: 0.6878425753722757
Epoch: 80 | Iteration number: [600/4518] 13% | Training loss: 0.6878293419877688
Epoch: 80 | Iteration number: [610/4518] 13% | Training loss: 0.6878219893721284
Epoch: 80 | Iteration number: [620/4518] 13% | Training loss: 0.6878105682711447
Epoch: 80 | Iteration number: [630/4518] 13% | Training loss: 0.6877831843164232
Epoch: 80 | Iteration number: [640/4518] 14% | Training loss: 0.6877735804766416
Epoch: 80 | Iteration number: [650/4518] 14% | Training loss: 0.6877718462393834
Epoch: 80 | Iteration number: [660/4518] 14% | Training loss: 0.6877647565169768
Epoch: 80 | Iteration number: [670/4518] 14% | Training loss: 0.6877473302741549
Epoch: 80 | Iteration number: [680/4518] 15% | Training loss: 0.6877037028179449
Epoch: 80 | Iteration number: [690/4518] 15% | Training loss: 0.6876828793166341
Epoch: 80 | Iteration number: [700/4518] 15% | Training loss: 0.6876570557696479
Epoch: 80 | Iteration number: [710/4518] 15% | Training loss: 0.6876576583989908
Epoch: 80 | Iteration number: [720/4518] 15% | Training loss: 0.6876578614943557
Epoch: 80 | Iteration number: [730/4518] 16% | Training loss: 0.6876472344137218
Epoch: 80 | Iteration number: [740/4518] 16% | Training loss: 0.6876436852925533
Epoch: 80 | Iteration number: [750/4518] 16% | Training loss: 0.6876368217468262
Epoch: 80 | Iteration number: [760/4518] 16% | Training loss: 0.6876186490058899
Epoch: 80 | Iteration number: [770/4518] 17% | Training loss: 0.6876112146811052
Epoch: 80 | Iteration number: [780/4518] 17% | Training loss: 0.6875955150677607
Epoch: 80 | Iteration number: [790/4518] 17% | Training loss: 0.6875953630556034
Epoch: 80 | Iteration number: [800/4518] 17% | Training loss: 0.6875979765504598
Epoch: 80 | Iteration number: [810/4518] 17% | Training loss: 0.6875737246171928
Epoch: 80 | Iteration number: [820/4518] 18% | Training loss: 0.6875703624835828
Epoch: 80 | Iteration number: [830/4518] 18% | Training loss: 0.687558087886098
Epoch: 80 | Iteration number: [840/4518] 18% | Training loss: 0.6875397742504166
Epoch: 80 | Iteration number: [850/4518] 18% | Training loss: 0.6875358612397138
Epoch: 80 | Iteration number: [860/4518] 19% | Training loss: 0.6875236570142036
Epoch: 80 | Iteration number: [870/4518] 19% | Training loss: 0.6875058136452203
Epoch: 80 | Iteration number: [880/4518] 19% | Training loss: 0.6874857480553064
Epoch: 80 | Iteration number: [890/4518] 19% | Training loss: 0.687478061740318
Epoch: 80 | Iteration number: [900/4518] 19% | Training loss: 0.6874636093775431
Epoch: 80 | Iteration number: [910/4518] 20% | Training loss: 0.6874535461048503
Epoch: 80 | Iteration number: [920/4518] 20% | Training loss: 0.6874418703758198
Epoch: 80 | Iteration number: [930/4518] 20% | Training loss: 0.6874264296024076
Epoch: 80 | Iteration number: [940/4518] 20% | Training loss: 0.6874303787312609
Epoch: 80 | Iteration number: [950/4518] 21% | Training loss: 0.6874108859112388
Epoch: 80 | Iteration number: [960/4518] 21% | Training loss: 0.6874009734640519
Epoch: 80 | Iteration number: [970/4518] 21% | Training loss: 0.6873899474586408
Epoch: 80 | Iteration number: [980/4518] 21% | Training loss: 0.687397052803818
Epoch: 80 | Iteration number: [990/4518] 21% | Training loss: 0.6873852337851669
Epoch: 80 | Iteration number: [1000/4518] 22% | Training loss: 0.6873767886161805
Epoch: 80 | Iteration number: [1010/4518] 22% | Training loss: 0.6873677362899969
Epoch: 80 | Iteration number: [1020/4518] 22% | Training loss: 0.6873749588050094
Epoch: 80 | Iteration number: [1030/4518] 22% | Training loss: 0.6873691650270258
Epoch: 80 | Iteration number: [1040/4518] 23% | Training loss: 0.6873687985997934
Epoch: 80 | Iteration number: [1050/4518] 23% | Training loss: 0.687365307410558
Epoch: 80 | Iteration number: [1060/4518] 23% | Training loss: 0.6873649656772614
Epoch: 80 | Iteration number: [1070/4518] 23% | Training loss: 0.6873640708834211
Epoch: 80 | Iteration number: [1080/4518] 23% | Training loss: 0.6873610468374358
Epoch: 80 | Iteration number: [1090/4518] 24% | Training loss: 0.6873556733131408
Epoch: 80 | Iteration number: [1100/4518] 24% | Training loss: 0.6873496248505332
Epoch: 80 | Iteration number: [1110/4518] 24% | Training loss: 0.6873408557595433
Epoch: 80 | Iteration number: [1120/4518] 24% | Training loss: 0.6873237273522785
Epoch: 80 | Iteration number: [1130/4518] 25% | Training loss: 0.6873223753102058
Epoch: 80 | Iteration number: [1140/4518] 25% | Training loss: 0.6873134921517289
Epoch: 80 | Iteration number: [1150/4518] 25% | Training loss: 0.6873018518738124
Epoch: 80 | Iteration number: [1160/4518] 25% | Training loss: 0.6873003578905401
Epoch: 80 | Iteration number: [1170/4518] 25% | Training loss: 0.6873038200741141
Epoch: 80 | Iteration number: [1180/4518] 26% | Training loss: 0.6872987802756034
Epoch: 80 | Iteration number: [1190/4518] 26% | Training loss: 0.6872953379855437
Epoch: 80 | Iteration number: [1200/4518] 26% | Training loss: 0.6872899085779984
Epoch: 80 | Iteration number: [1210/4518] 26% | Training loss: 0.6872844984708739
Epoch: 80 | Iteration number: [1220/4518] 27% | Training loss: 0.6872888171281971
Epoch: 80 | Iteration number: [1230/4518] 27% | Training loss: 0.6872785256160954
Epoch: 80 | Iteration number: [1240/4518] 27% | Training loss: 0.6872721979694981
Epoch: 80 | Iteration number: [1250/4518] 27% | Training loss: 0.6872617332935334
Epoch: 80 | Iteration number: [1260/4518] 27% | Training loss: 0.6872481546704732
Epoch: 80 | Iteration number: [1270/4518] 28% | Training loss: 0.6872379173444012
Epoch: 80 | Iteration number: [1280/4518] 28% | Training loss: 0.6872354068793356
Epoch: 80 | Iteration number: [1290/4518] 28% | Training loss: 0.6872248875078305
Epoch: 80 | Iteration number: [1300/4518] 28% | Training loss: 0.6872168134267513
Epoch: 80 | Iteration number: [1310/4518] 28% | Training loss: 0.6872038425380037
Epoch: 80 | Iteration number: [1320/4518] 29% | Training loss: 0.6871990854993011
Epoch: 80 | Iteration number: [1330/4518] 29% | Training loss: 0.6871881731470725
Epoch: 80 | Iteration number: [1340/4518] 29% | Training loss: 0.6871774865620172
Epoch: 80 | Iteration number: [1350/4518] 29% | Training loss: 0.6871771976682874
Epoch: 80 | Iteration number: [1360/4518] 30% | Training loss: 0.687179035737234
Epoch: 80 | Iteration number: [1370/4518] 30% | Training loss: 0.6871787940063616
Epoch: 80 | Iteration number: [1380/4518] 30% | Training loss: 0.687177437932595
Epoch: 80 | Iteration number: [1390/4518] 30% | Training loss: 0.6871726440011169
Epoch: 80 | Iteration number: [1400/4518] 30% | Training loss: 0.6871738623721259
Epoch: 80 | Iteration number: [1410/4518] 31% | Training loss: 0.6871666558668124
Epoch: 80 | Iteration number: [1420/4518] 31% | Training loss: 0.6871662637717287
Epoch: 80 | Iteration number: [1430/4518] 31% | Training loss: 0.6871689588456721
Epoch: 80 | Iteration number: [1440/4518] 31% | Training loss: 0.6871617188470232
Epoch: 80 | Iteration number: [1450/4518] 32% | Training loss: 0.6871575901015051
Epoch: 80 | Iteration number: [1460/4518] 32% | Training loss: 0.6871520723790339
Epoch: 80 | Iteration number: [1470/4518] 32% | Training loss: 0.6871532052552619
Epoch: 80 | Iteration number: [1480/4518] 32% | Training loss: 0.6871491773305712
Epoch: 80 | Iteration number: [1490/4518] 32% | Training loss: 0.6871467647136458
Epoch: 80 | Iteration number: [1500/4518] 33% | Training loss: 0.6871456413666407
Epoch: 80 | Iteration number: [1510/4518] 33% | Training loss: 0.6871421338311884
Epoch: 80 | Iteration number: [1520/4518] 33% | Training loss: 0.6871466306087218
Epoch: 80 | Iteration number: [1530/4518] 33% | Training loss: 0.6871546971642114
Epoch: 80 | Iteration number: [1540/4518] 34% | Training loss: 0.6871497269187655
Epoch: 80 | Iteration number: [1550/4518] 34% | Training loss: 0.6871498040230043
Epoch: 80 | Iteration number: [1560/4518] 34% | Training loss: 0.6871498638238662
Epoch: 80 | Iteration number: [1570/4518] 34% | Training loss: 0.6871492106823405
Epoch: 80 | Iteration number: [1580/4518] 34% | Training loss: 0.6871470871605451
Epoch: 80 | Iteration number: [1590/4518] 35% | Training loss: 0.6871424236387577
Epoch: 80 | Iteration number: [1600/4518] 35% | Training loss: 0.687141431234777
Epoch: 80 | Iteration number: [1610/4518] 35% | Training loss: 0.687139711283749
Epoch: 80 | Iteration number: [1620/4518] 35% | Training loss: 0.6871470535610928
Epoch: 80 | Iteration number: [1630/4518] 36% | Training loss: 0.6871348699177701
Epoch: 80 | Iteration number: [1640/4518] 36% | Training loss: 0.687137893351113
Epoch: 80 | Iteration number: [1650/4518] 36% | Training loss: 0.6871397809187572
Epoch: 80 | Iteration number: [1660/4518] 36% | Training loss: 0.68714348038277
Epoch: 80 | Iteration number: [1670/4518] 36% | Training loss: 0.6871491723074884
Epoch: 80 | Iteration number: [1680/4518] 37% | Training loss: 0.6871463620591731
Epoch: 80 | Iteration number: [1690/4518] 37% | Training loss: 0.6871503583072911
Epoch: 80 | Iteration number: [1700/4518] 37% | Training loss: 0.6871497217697256
Epoch: 80 | Iteration number: [1710/4518] 37% | Training loss: 0.6871513812514076
Epoch: 80 | Iteration number: [1720/4518] 38% | Training loss: 0.6871583996817123
Epoch: 80 | Iteration number: [1730/4518] 38% | Training loss: 0.6871494666344857
Epoch: 80 | Iteration number: [1740/4518] 38% | Training loss: 0.687145654908542
Epoch: 80 | Iteration number: [1750/4518] 38% | Training loss: 0.6871434297561646
Epoch: 80 | Iteration number: [1760/4518] 38% | Training loss: 0.6871395561166785
Epoch: 80 | Iteration number: [1770/4518] 39% | Training loss: 0.6871423246833565
Epoch: 80 | Iteration number: [1780/4518] 39% | Training loss: 0.6871424194467202
Epoch: 80 | Iteration number: [1790/4518] 39% | Training loss: 0.6871411928251469
Epoch: 80 | Iteration number: [1800/4518] 39% | Training loss: 0.6871391140090095
Epoch: 80 | Iteration number: [1810/4518] 40% | Training loss: 0.6871392655438481
Epoch: 80 | Iteration number: [1820/4518] 40% | Training loss: 0.6871335131453944
Epoch: 80 | Iteration number: [1830/4518] 40% | Training loss: 0.6871266956863508
Epoch: 80 | Iteration number: [1840/4518] 40% | Training loss: 0.6871240708167138
Epoch: 80 | Iteration number: [1850/4518] 40% | Training loss: 0.68711752069963
Epoch: 80 | Iteration number: [1860/4518] 41% | Training loss: 0.687113935620554
Epoch: 80 | Iteration number: [1870/4518] 41% | Training loss: 0.6871150986714797
Epoch: 80 | Iteration number: [1880/4518] 41% | Training loss: 0.6871127219276225
Epoch: 80 | Iteration number: [1890/4518] 41% | Training loss: 0.6871093682195775
Epoch: 80 | Iteration number: [1900/4518] 42% | Training loss: 0.6871076340110679
Epoch: 80 | Iteration number: [1910/4518] 42% | Training loss: 0.6871098716533621
Epoch: 80 | Iteration number: [1920/4518] 42% | Training loss: 0.6871050766669213
Epoch: 80 | Iteration number: [1930/4518] 42% | Training loss: 0.6871063859969223
Epoch: 80 | Iteration number: [1940/4518] 42% | Training loss: 0.6871060146498926
Epoch: 80 | Iteration number: [1950/4518] 43% | Training loss: 0.6871007337325659
Epoch: 80 | Iteration number: [1960/4518] 43% | Training loss: 0.6871013710085226
Epoch: 80 | Iteration number: [1970/4518] 43% | Training loss: 0.6871009030317897
Epoch: 80 | Iteration number: [1980/4518] 43% | Training loss: 0.6870987817494556
Epoch: 80 | Iteration number: [1990/4518] 44% | Training loss: 0.6871017653738434
Epoch: 80 | Iteration number: [2000/4518] 44% | Training loss: 0.6871050605773926
Epoch: 80 | Iteration number: [2010/4518] 44% | Training loss: 0.687106699522455
Epoch: 80 | Iteration number: [2020/4518] 44% | Training loss: 0.6871081517179414
Epoch: 80 | Iteration number: [2030/4518] 44% | Training loss: 0.6871070020010905
Epoch: 80 | Iteration number: [2040/4518] 45% | Training loss: 0.6871052544783144
Epoch: 80 | Iteration number: [2050/4518] 45% | Training loss: 0.6871113025851366
Epoch: 80 | Iteration number: [2060/4518] 45% | Training loss: 0.6871201505360094
Epoch: 80 | Iteration number: [2070/4518] 45% | Training loss: 0.6871264282919934
Epoch: 80 | Iteration number: [2080/4518] 46% | Training loss: 0.6871256575561486
Epoch: 80 | Iteration number: [2090/4518] 46% | Training loss: 0.6871272313537781
Epoch: 80 | Iteration number: [2100/4518] 46% | Training loss: 0.6871293159893581
Epoch: 80 | Iteration number: [2110/4518] 46% | Training loss: 0.6871234627979061
Epoch: 80 | Iteration number: [2120/4518] 46% | Training loss: 0.6871210484291023
Epoch: 80 | Iteration number: [2130/4518] 47% | Training loss: 0.6871199130172461
Epoch: 80 | Iteration number: [2140/4518] 47% | Training loss: 0.687123760469606
Epoch: 80 | Iteration number: [2150/4518] 47% | Training loss: 0.6871215767915859
Epoch: 80 | Iteration number: [2160/4518] 47% | Training loss: 0.6871179302257521
Epoch: 80 | Iteration number: [2170/4518] 48% | Training loss: 0.6871168940847371
Epoch: 80 | Iteration number: [2180/4518] 48% | Training loss: 0.6871129589069874
Epoch: 80 | Iteration number: [2190/4518] 48% | Training loss: 0.6871093745645322
Epoch: 80 | Iteration number: [2200/4518] 48% | Training loss: 0.6871105476671999
Epoch: 80 | Iteration number: [2210/4518] 48% | Training loss: 0.6870984096872321
Epoch: 80 | Iteration number: [2220/4518] 49% | Training loss: 0.6870949034755295
Epoch: 80 | Iteration number: [2230/4518] 49% | Training loss: 0.6870926368931484
Epoch: 80 | Iteration number: [2240/4518] 49% | Training loss: 0.6870891564126526
Epoch: 80 | Iteration number: [2250/4518] 49% | Training loss: 0.6870841957198249
Epoch: 80 | Iteration number: [2260/4518] 50% | Training loss: 0.6870838985242674
Epoch: 80 | Iteration number: [2270/4518] 50% | Training loss: 0.6870814852514981
Epoch: 80 | Iteration number: [2280/4518] 50% | Training loss: 0.6870741379365587
Epoch: 80 | Iteration number: [2290/4518] 50% | Training loss: 0.6870701362212152
Epoch: 80 | Iteration number: [2300/4518] 50% | Training loss: 0.6870640785538632
Epoch: 80 | Iteration number: [2310/4518] 51% | Training loss: 0.6870568486777219
Epoch: 80 | Iteration number: [2320/4518] 51% | Training loss: 0.6870572113528334
Epoch: 80 | Iteration number: [2330/4518] 51% | Training loss: 0.6870599459169249
Epoch: 80 | Iteration number: [2340/4518] 51% | Training loss: 0.6870657870147983
Epoch: 80 | Iteration number: [2350/4518] 52% | Training loss: 0.6870627510040365
Epoch: 80 | Iteration number: [2360/4518] 52% | Training loss: 0.6870596887701649
Epoch: 80 | Iteration number: [2370/4518] 52% | Training loss: 0.6870595878438105
Epoch: 80 | Iteration number: [2380/4518] 52% | Training loss: 0.6870543341676728
Epoch: 80 | Iteration number: [2390/4518] 52% | Training loss: 0.6870554327715391
Epoch: 80 | Iteration number: [2400/4518] 53% | Training loss: 0.6870541484405597
Epoch: 80 | Iteration number: [2410/4518] 53% | Training loss: 0.6870570467468119
Epoch: 80 | Iteration number: [2420/4518] 53% | Training loss: 0.6870558834272968
Epoch: 80 | Iteration number: [2430/4518] 53% | Training loss: 0.6870578000574936
Epoch: 80 | Iteration number: [2440/4518] 54% | Training loss: 0.6870606816938666
Epoch: 80 | Iteration number: [2450/4518] 54% | Training loss: 0.6870608183315822
Epoch: 80 | Iteration number: [2460/4518] 54% | Training loss: 0.6870547087454214
Epoch: 80 | Iteration number: [2470/4518] 54% | Training loss: 0.6870574488572263
Epoch: 80 | Iteration number: [2480/4518] 54% | Training loss: 0.6870571051153445
Epoch: 80 | Iteration number: [2490/4518] 55% | Training loss: 0.6870554582660936
Epoch: 80 | Iteration number: [2500/4518] 55% | Training loss: 0.6870495558738708
Epoch: 80 | Iteration number: [2510/4518] 55% | Training loss: 0.6870499985626495
Epoch: 80 | Iteration number: [2520/4518] 55% | Training loss: 0.6870477050069779
Epoch: 80 | Iteration number: [2530/4518] 55% | Training loss: 0.6870384461794917
Epoch: 80 | Iteration number: [2540/4518] 56% | Training loss: 0.687034978477035
Epoch: 80 | Iteration number: [2550/4518] 56% | Training loss: 0.6870341411291384
Epoch: 80 | Iteration number: [2560/4518] 56% | Training loss: 0.6870307779870928
Epoch: 80 | Iteration number: [2570/4518] 56% | Training loss: 0.687031166794699
Epoch: 80 | Iteration number: [2580/4518] 57% | Training loss: 0.6870333864938382
Epoch: 80 | Iteration number: [2590/4518] 57% | Training loss: 0.6870356936482389
Epoch: 80 | Iteration number: [2600/4518] 57% | Training loss: 0.6870415474589054
Epoch: 80 | Iteration number: [2610/4518] 57% | Training loss: 0.6870391747503902
Epoch: 80 | Iteration number: [2620/4518] 57% | Training loss: 0.6870379194048525
Epoch: 80 | Iteration number: [2630/4518] 58% | Training loss: 0.687033072034669
Epoch: 80 | Iteration number: [2640/4518] 58% | Training loss: 0.6870326815003699
Epoch: 80 | Iteration number: [2650/4518] 58% | Training loss: 0.687036126042312
Epoch: 80 | Iteration number: [2660/4518] 58% | Training loss: 0.687036159455328
Epoch: 80 | Iteration number: [2670/4518] 59% | Training loss: 0.6870342535919018
Epoch: 80 | Iteration number: [2680/4518] 59% | Training loss: 0.6870336054421183
Epoch: 80 | Iteration number: [2690/4518] 59% | Training loss: 0.6870342098868912
Epoch: 80 | Iteration number: [2700/4518] 59% | Training loss: 0.6870304691791534
Epoch: 80 | Iteration number: [2710/4518] 59% | Training loss: 0.6870316609025442
Epoch: 80 | Iteration number: [2720/4518] 60% | Training loss: 0.6870276785729562
Epoch: 80 | Iteration number: [2730/4518] 60% | Training loss: 0.6870278789228572
Epoch: 80 | Iteration number: [2740/4518] 60% | Training loss: 0.687026592392991
Epoch: 80 | Iteration number: [2750/4518] 60% | Training loss: 0.68702565741539
Epoch: 80 | Iteration number: [2760/4518] 61% | Training loss: 0.6870248341905898
Epoch: 80 | Iteration number: [2770/4518] 61% | Training loss: 0.6870220899581909
Epoch: 80 | Iteration number: [2780/4518] 61% | Training loss: 0.6870227982243188
Epoch: 80 | Iteration number: [2790/4518] 61% | Training loss: 0.6870250848245449
Epoch: 80 | Iteration number: [2800/4518] 61% | Training loss: 0.6870281081753118
Epoch: 80 | Iteration number: [2810/4518] 62% | Training loss: 0.6870237128378234
Epoch: 80 | Iteration number: [2820/4518] 62% | Training loss: 0.6870239473615133
Epoch: 80 | Iteration number: [2830/4518] 62% | Training loss: 0.6870223474797428
Epoch: 80 | Iteration number: [2840/4518] 62% | Training loss: 0.6870201083556028
Epoch: 80 | Iteration number: [2850/4518] 63% | Training loss: 0.6870234130558215
Epoch: 80 | Iteration number: [2860/4518] 63% | Training loss: 0.6870227620318219
Epoch: 80 | Iteration number: [2870/4518] 63% | Training loss: 0.6870189355017832
Epoch: 80 | Iteration number: [2880/4518] 63% | Training loss: 0.6870170259020395
Epoch: 80 | Iteration number: [2890/4518] 63% | Training loss: 0.6870153085789465
Epoch: 80 | Iteration number: [2900/4518] 64% | Training loss: 0.6870167892349177
Epoch: 80 | Iteration number: [2910/4518] 64% | Training loss: 0.6870184501626647
Epoch: 80 | Iteration number: [2920/4518] 64% | Training loss: 0.6870204127202295
Epoch: 80 | Iteration number: [2930/4518] 64% | Training loss: 0.68701943657504
Epoch: 80 | Iteration number: [2940/4518] 65% | Training loss: 0.6870164002690996
Epoch: 80 | Iteration number: [2950/4518] 65% | Training loss: 0.6870199156009544
Epoch: 80 | Iteration number: [2960/4518] 65% | Training loss: 0.6870198863382275
Epoch: 80 | Iteration number: [2970/4518] 65% | Training loss: 0.6870197323636976
Epoch: 80 | Iteration number: [2980/4518] 65% | Training loss: 0.6870249020773292
Epoch: 80 | Iteration number: [2990/4518] 66% | Training loss: 0.6870254639797785
Epoch: 80 | Iteration number: [3000/4518] 66% | Training loss: 0.6870294525623322
Epoch: 80 | Iteration number: [3010/4518] 66% | Training loss: 0.6870247754345701
Epoch: 80 | Iteration number: [3020/4518] 66% | Training loss: 0.6870251858076513
Epoch: 80 | Iteration number: [3030/4518] 67% | Training loss: 0.6870266954300821
Epoch: 80 | Iteration number: [3040/4518] 67% | Training loss: 0.6870252582587694
Epoch: 80 | Iteration number: [3050/4518] 67% | Training loss: 0.687025125065788
Epoch: 80 | Iteration number: [3060/4518] 67% | Training loss: 0.6870243205354105
Epoch: 80 | Iteration number: [3070/4518] 67% | Training loss: 0.6870261053114838
Epoch: 80 | Iteration number: [3080/4518] 68% | Training loss: 0.6870232187308274
Epoch: 80 | Iteration number: [3090/4518] 68% | Training loss: 0.6870154985525075
Epoch: 80 | Iteration number: [3100/4518] 68% | Training loss: 0.6870163578179574
Epoch: 80 | Iteration number: [3110/4518] 68% | Training loss: 0.6870139075053849
Epoch: 80 | Iteration number: [3120/4518] 69% | Training loss: 0.687014809403664
Epoch: 80 | Iteration number: [3130/4518] 69% | Training loss: 0.6870119883229557
Epoch: 80 | Iteration number: [3140/4518] 69% | Training loss: 0.6870108092666432
Epoch: 80 | Iteration number: [3150/4518] 69% | Training loss: 0.6870037754187508
Epoch: 80 | Iteration number: [3160/4518] 69% | Training loss: 0.6870026989828182
Epoch: 80 | Iteration number: [3170/4518] 70% | Training loss: 0.6870033557858752
Epoch: 80 | Iteration number: [3180/4518] 70% | Training loss: 0.6870020930684587
Epoch: 80 | Iteration number: [3190/4518] 70% | Training loss: 0.6870007698438758
Epoch: 80 | Iteration number: [3200/4518] 70% | Training loss: 0.6870000048913062
Epoch: 80 | Iteration number: [3210/4518] 71% | Training loss: 0.6870005143951404
Epoch: 80 | Iteration number: [3220/4518] 71% | Training loss: 0.6870039860284106
Epoch: 80 | Iteration number: [3230/4518] 71% | Training loss: 0.6870049453925792
Epoch: 80 | Iteration number: [3240/4518] 71% | Training loss: 0.6870028596969299
Epoch: 80 | Iteration number: [3250/4518] 71% | Training loss: 0.6869996568423051
Epoch: 80 | Iteration number: [3260/4518] 72% | Training loss: 0.686993911277297
Epoch: 80 | Iteration number: [3270/4518] 72% | Training loss: 0.686992444995711
Epoch: 80 | Iteration number: [3280/4518] 72% | Training loss: 0.6869944773796128
Epoch: 80 | Iteration number: [3290/4518] 72% | Training loss: 0.6869934712137494
Epoch: 80 | Iteration number: [3300/4518] 73% | Training loss: 0.6869916703303655
Epoch: 80 | Iteration number: [3310/4518] 73% | Training loss: 0.6869924773262347
Epoch: 80 | Iteration number: [3320/4518] 73% | Training loss: 0.6869935954191598
Epoch: 80 | Iteration number: [3330/4518] 73% | Training loss: 0.6869941515607518
Epoch: 80 | Iteration number: [3340/4518] 73% | Training loss: 0.6869925867654606
Epoch: 80 | Iteration number: [3350/4518] 74% | Training loss: 0.6869891731952553
Epoch: 80 | Iteration number: [3360/4518] 74% | Training loss: 0.6869883072340772
Epoch: 80 | Iteration number: [3370/4518] 74% | Training loss: 0.6869898988691211
Epoch: 80 | Iteration number: [3380/4518] 74% | Training loss: 0.686989075985886
Epoch: 80 | Iteration number: [3390/4518] 75% | Training loss: 0.6869900643649706
Epoch: 80 | Iteration number: [3400/4518] 75% | Training loss: 0.6869901396947748
Epoch: 80 | Iteration number: [3410/4518] 75% | Training loss: 0.6869908565649888
Epoch: 80 | Iteration number: [3420/4518] 75% | Training loss: 0.6869903626149161
Epoch: 80 | Iteration number: [3430/4518] 75% | Training loss: 0.6869901888919642
Epoch: 80 | Iteration number: [3440/4518] 76% | Training loss: 0.6869904105226661
Epoch: 80 | Iteration number: [3450/4518] 76% | Training loss: 0.6869889325853707
Epoch: 80 | Iteration number: [3460/4518] 76% | Training loss: 0.6869859695262303
Epoch: 80 | Iteration number: [3470/4518] 76% | Training loss: 0.6869830055436071
Epoch: 80 | Iteration number: [3480/4518] 77% | Training loss: 0.686984119624242
Epoch: 80 | Iteration number: [3490/4518] 77% | Training loss: 0.6869808588465168
Epoch: 80 | Iteration number: [3500/4518] 77% | Training loss: 0.6869763623986925
Epoch: 80 | Iteration number: [3510/4518] 77% | Training loss: 0.6869740776526623
Epoch: 80 | Iteration number: [3520/4518] 77% | Training loss: 0.6869758266278289
Epoch: 80 | Iteration number: [3530/4518] 78% | Training loss: 0.6869727549404328
Epoch: 80 | Iteration number: [3540/4518] 78% | Training loss: 0.6869767977187863
Epoch: 80 | Iteration number: [3550/4518] 78% | Training loss: 0.6869745778365874
Epoch: 80 | Iteration number: [3560/4518] 78% | Training loss: 0.6869740554455961
Epoch: 80 | Iteration number: [3570/4518] 79% | Training loss: 0.686972425832134
Epoch: 80 | Iteration number: [3580/4518] 79% | Training loss: 0.6869725513558148
Epoch: 80 | Iteration number: [3590/4518] 79% | Training loss: 0.6869685610356769
Epoch: 80 | Iteration number: [3600/4518] 79% | Training loss: 0.6869684979485141
Epoch: 80 | Iteration number: [3610/4518] 79% | Training loss: 0.6869721725211579
Epoch: 80 | Iteration number: [3620/4518] 80% | Training loss: 0.6869724423187213
Epoch: 80 | Iteration number: [3630/4518] 80% | Training loss: 0.6869710748845881
Epoch: 80 | Iteration number: [3640/4518] 80% | Training loss: 0.6869646473245307
Epoch: 80 | Iteration number: [3650/4518] 80% | Training loss: 0.6869655298696805
Epoch: 80 | Iteration number: [3660/4518] 81% | Training loss: 0.6869640283734421
Epoch: 80 | Iteration number: [3670/4518] 81% | Training loss: 0.6869646708711942
Epoch: 80 | Iteration number: [3680/4518] 81% | Training loss: 0.6869618965555793
Epoch: 80 | Iteration number: [3690/4518] 81% | Training loss: 0.6869573717356374
Epoch: 80 | Iteration number: [3700/4518] 81% | Training loss: 0.6869562557742402
Epoch: 80 | Iteration number: [3710/4518] 82% | Training loss: 0.6869568826214001
Epoch: 80 | Iteration number: [3720/4518] 82% | Training loss: 0.6869514019418789
Epoch: 80 | Iteration number: [3730/4518] 82% | Training loss: 0.6869506505155691
Epoch: 80 | Iteration number: [3740/4518] 82% | Training loss: 0.6869471393326387
Epoch: 80 | Iteration number: [3750/4518] 83% | Training loss: 0.6869482821464539
Epoch: 80 | Iteration number: [3760/4518] 83% | Training loss: 0.6869475916662114
Epoch: 80 | Iteration number: [3770/4518] 83% | Training loss: 0.6869456785901472
Epoch: 80 | Iteration number: [3780/4518] 83% | Training loss: 0.6869458940294054
Epoch: 80 | Iteration number: [3790/4518] 83% | Training loss: 0.6869444312709617
Epoch: 80 | Iteration number: [3800/4518] 84% | Training loss: 0.6869435424396866
Epoch: 80 | Iteration number: [3810/4518] 84% | Training loss: 0.6869448423542063
Epoch: 80 | Iteration number: [3820/4518] 84% | Training loss: 0.6869472911064537
Epoch: 80 | Iteration number: [3830/4518] 84% | Training loss: 0.6869492371773284
Epoch: 80 | Iteration number: [3840/4518] 84% | Training loss: 0.6869476904937376
Epoch: 80 | Iteration number: [3850/4518] 85% | Training loss: 0.686948670628783
Epoch: 80 | Iteration number: [3860/4518] 85% | Training loss: 0.6869494237739188
Epoch: 80 | Iteration number: [3870/4518] 85% | Training loss: 0.6869490379510924
Epoch: 80 | Iteration number: [3880/4518] 85% | Training loss: 0.6869508922560927
Epoch: 80 | Iteration number: [3890/4518] 86% | Training loss: 0.686948031953184
Epoch: 80 | Iteration number: [3900/4518] 86% | Training loss: 0.6869492144003893
Epoch: 80 | Iteration number: [3910/4518] 86% | Training loss: 0.6869479706830076
Epoch: 80 | Iteration number: [3920/4518] 86% | Training loss: 0.6869465734581558
Epoch: 80 | Iteration number: [3930/4518] 86% | Training loss: 0.6869467989785677
Epoch: 80 | Iteration number: [3940/4518] 87% | Training loss: 0.6869489294169518
Epoch: 80 | Iteration number: [3950/4518] 87% | Training loss: 0.6869481057456777
Epoch: 80 | Iteration number: [3960/4518] 87% | Training loss: 0.6869458918168088
Epoch: 80 | Iteration number: [3970/4518] 87% | Training loss: 0.6869447727347501
Epoch: 80 | Iteration number: [3980/4518] 88% | Training loss: 0.6869412986327655
Epoch: 80 | Iteration number: [3990/4518] 88% | Training loss: 0.6869398359666791
Epoch: 80 | Iteration number: [4000/4518] 88% | Training loss: 0.6869373882710934
Epoch: 80 | Iteration number: [4010/4518] 88% | Training loss: 0.6869357704075791
Epoch: 80 | Iteration number: [4020/4518] 88% | Training loss: 0.6869345174055195
Epoch: 80 | Iteration number: [4030/4518] 89% | Training loss: 0.6869361037651895
Epoch: 80 | Iteration number: [4040/4518] 89% | Training loss: 0.6869348301008196
Epoch: 80 | Iteration number: [4050/4518] 89% | Training loss: 0.6869358886759959
Epoch: 80 | Iteration number: [4060/4518] 89% | Training loss: 0.686935842565715
Epoch: 80 | Iteration number: [4070/4518] 90% | Training loss: 0.6869340777250706
Epoch: 80 | Iteration number: [4080/4518] 90% | Training loss: 0.6869312354454807
Epoch: 80 | Iteration number: [4090/4518] 90% | Training loss: 0.6869294309091452
Epoch: 80 | Iteration number: [4100/4518] 90% | Training loss: 0.6869280352243563
Epoch: 80 | Iteration number: [4110/4518] 90% | Training loss: 0.6869287744200723
Epoch: 80 | Iteration number: [4120/4518] 91% | Training loss: 0.6869303524349499
Epoch: 80 | Iteration number: [4130/4518] 91% | Training loss: 0.6869274264242112
Epoch: 80 | Iteration number: [4140/4518] 91% | Training loss: 0.6869279814659109
Epoch: 80 | Iteration number: [4150/4518] 91% | Training loss: 0.6869242156700915
Epoch: 80 | Iteration number: [4160/4518] 92% | Training loss: 0.6869239622153915
Epoch: 80 | Iteration number: [4170/4518] 92% | Training loss: 0.6869239746237831
Epoch: 80 | Iteration number: [4180/4518] 92% | Training loss: 0.6869269581217515
Epoch: 80 | Iteration number: [4190/4518] 92% | Training loss: 0.6869288475815037
Epoch: 80 | Iteration number: [4200/4518] 92% | Training loss: 0.6869270269217945
Epoch: 80 | Iteration number: [4210/4518] 93% | Training loss: 0.6869251380198925
Epoch: 80 | Iteration number: [4220/4518] 93% | Training loss: 0.6869238097238315
Epoch: 80 | Iteration number: [4230/4518] 93% | Training loss: 0.6869257102480453
Epoch: 80 | Iteration number: [4240/4518] 93% | Training loss: 0.6869263889935782
Epoch: 80 | Iteration number: [4250/4518] 94% | Training loss: 0.6869282201879164
Epoch: 80 | Iteration number: [4260/4518] 94% | Training loss: 0.6869248899495658
Epoch: 80 | Iteration number: [4270/4518] 94% | Training loss: 0.6869238497920561
Epoch: 80 | Iteration number: [4280/4518] 94% | Training loss: 0.6869227503922498
Epoch: 80 | Iteration number: [4290/4518] 94% | Training loss: 0.6869234787139581
Epoch: 80 | Iteration number: [4300/4518] 95% | Training loss: 0.6869243510656579
Epoch: 80 | Iteration number: [4310/4518] 95% | Training loss: 0.6869252816845259
Epoch: 80 | Iteration number: [4320/4518] 95% | Training loss: 0.6869236471752326
Epoch: 80 | Iteration number: [4330/4518] 95% | Training loss: 0.6869233557864094
Epoch: 80 | Iteration number: [4340/4518] 96% | Training loss: 0.6869213621737221
Epoch: 80 | Iteration number: [4350/4518] 96% | Training loss: 0.686921302244581
Epoch: 80 | Iteration number: [4360/4518] 96% | Training loss: 0.6869214460253715
Epoch: 80 | Iteration number: [4370/4518] 96% | Training loss: 0.6869194123510365
Epoch: 80 | Iteration number: [4380/4518] 96% | Training loss: 0.6869174830037165
Epoch: 80 | Iteration number: [4390/4518] 97% | Training loss: 0.6869158545088931
Epoch: 80 | Iteration number: [4400/4518] 97% | Training loss: 0.6869180879132314
Epoch: 80 | Iteration number: [4410/4518] 97% | Training loss: 0.6869166951195723
Epoch: 80 | Iteration number: [4420/4518] 97% | Training loss: 0.6869185740726566
Epoch: 80 | Iteration number: [4430/4518] 98% | Training loss: 0.6869179535261933
Epoch: 80 | Iteration number: [4440/4518] 98% | Training loss: 0.6869173481523454
Epoch: 80 | Iteration number: [4450/4518] 98% | Training loss: 0.6869148382979833
Epoch: 80 | Iteration number: [4460/4518] 98% | Training loss: 0.6869155079393643
Epoch: 80 | Iteration number: [4470/4518] 98% | Training loss: 0.6869151154220504
Epoch: 80 | Iteration number: [4480/4518] 99% | Training loss: 0.6869126233937485
Epoch: 80 | Iteration number: [4490/4518] 99% | Training loss: 0.6869123649358219
Epoch: 80 | Iteration number: [4500/4518] 99% | Training loss: 0.6869133177465863
Epoch: 80 | Iteration number: [4510/4518] 99% | Training loss: 0.6869146441408905

 End of epoch: 80 | Train Loss: 0.6867614021312879 | Training Time: 633 

 End of epoch: 80 | Eval Loss: 0.6896106917030957 | Evaluating Time: 17 
Epoch: 81 | Iteration number: [10/4518] 0% | Training loss: 0.7558477818965912
Epoch: 81 | Iteration number: [20/4518] 0% | Training loss: 0.721391960978508
Epoch: 81 | Iteration number: [30/4518] 0% | Training loss: 0.709737354516983
Epoch: 81 | Iteration number: [40/4518] 0% | Training loss: 0.7039807513356209
Epoch: 81 | Iteration number: [50/4518] 1% | Training loss: 0.7004486525058746
Epoch: 81 | Iteration number: [60/4518] 1% | Training loss: 0.6979846636454264
Epoch: 81 | Iteration number: [70/4518] 1% | Training loss: 0.696412296806063
Epoch: 81 | Iteration number: [80/4518] 1% | Training loss: 0.6952263846993446
Epoch: 81 | Iteration number: [90/4518] 1% | Training loss: 0.6943011747466193
Epoch: 81 | Iteration number: [100/4518] 2% | Training loss: 0.6936706817150116
Epoch: 81 | Iteration number: [110/4518] 2% | Training loss: 0.692978928305886
Epoch: 81 | Iteration number: [120/4518] 2% | Training loss: 0.6924270366628965
Epoch: 81 | Iteration number: [130/4518] 2% | Training loss: 0.6920205886547383
Epoch: 81 | Iteration number: [140/4518] 3% | Training loss: 0.6916422273431505
Epoch: 81 | Iteration number: [150/4518] 3% | Training loss: 0.6912873438994089
Epoch: 81 | Iteration number: [160/4518] 3% | Training loss: 0.6910157013684511
Epoch: 81 | Iteration number: [170/4518] 3% | Training loss: 0.6908630167736727
Epoch: 81 | Iteration number: [180/4518] 3% | Training loss: 0.6906305872731738
Epoch: 81 | Iteration number: [190/4518] 4% | Training loss: 0.6904098240952743
Epoch: 81 | Iteration number: [200/4518] 4% | Training loss: 0.6902208137512207
Epoch: 81 | Iteration number: [210/4518] 4% | Training loss: 0.6900821748233977
Epoch: 81 | Iteration number: [220/4518] 4% | Training loss: 0.6899632554162632
Epoch: 81 | Iteration number: [230/4518] 5% | Training loss: 0.6898725144241167
Epoch: 81 | Iteration number: [240/4518] 5% | Training loss: 0.6897780065735181
Epoch: 81 | Iteration number: [250/4518] 5% | Training loss: 0.6896559147834778
Epoch: 81 | Iteration number: [260/4518] 5% | Training loss: 0.689557054409614
Epoch: 81 | Iteration number: [270/4518] 5% | Training loss: 0.6894515483467667
Epoch: 81 | Iteration number: [280/4518] 6% | Training loss: 0.6893370977469853
Epoch: 81 | Iteration number: [290/4518] 6% | Training loss: 0.6892521728729379
Epoch: 81 | Iteration number: [300/4518] 6% | Training loss: 0.6891608625650406
Epoch: 81 | Iteration number: [310/4518] 6% | Training loss: 0.6890738371879824
Epoch: 81 | Iteration number: [320/4518] 7% | Training loss: 0.6890034275129437
Epoch: 81 | Iteration number: [330/4518] 7% | Training loss: 0.6889338621587464
Epoch: 81 | Iteration number: [340/4518] 7% | Training loss: 0.6888607971808489
Epoch: 81 | Iteration number: [350/4518] 7% | Training loss: 0.6887921401432582
Epoch: 81 | Iteration number: [360/4518] 7% | Training loss: 0.6887371268537309
Epoch: 81 | Iteration number: [370/4518] 8% | Training loss: 0.6886621428502573
Epoch: 81 | Iteration number: [380/4518] 8% | Training loss: 0.688625140096012
Epoch: 81 | Iteration number: [390/4518] 8% | Training loss: 0.6885738138969127
Epoch: 81 | Iteration number: [400/4518] 8% | Training loss: 0.6885037812590599
Epoch: 81 | Iteration number: [410/4518] 9% | Training loss: 0.688463583806666
Epoch: 81 | Iteration number: [420/4518] 9% | Training loss: 0.6884216430641356
Epoch: 81 | Iteration number: [430/4518] 9% | Training loss: 0.6884144701236903
Epoch: 81 | Iteration number: [440/4518] 9% | Training loss: 0.6883707498962229
Epoch: 81 | Iteration number: [450/4518] 9% | Training loss: 0.6883401540915172
Epoch: 81 | Iteration number: [460/4518] 10% | Training loss: 0.6883122911919718
Epoch: 81 | Iteration number: [470/4518] 10% | Training loss: 0.6882573674333856
Epoch: 81 | Iteration number: [480/4518] 10% | Training loss: 0.6882370479404927
Epoch: 81 | Iteration number: [490/4518] 10% | Training loss: 0.6881784462198919
Epoch: 81 | Iteration number: [500/4518] 11% | Training loss: 0.6881274324655533
Epoch: 81 | Iteration number: [510/4518] 11% | Training loss: 0.6881030679917803
Epoch: 81 | Iteration number: [520/4518] 11% | Training loss: 0.6880710740502064
Epoch: 81 | Iteration number: [530/4518] 11% | Training loss: 0.6880386295183649
Epoch: 81 | Iteration number: [540/4518] 11% | Training loss: 0.6880058659447564
Epoch: 81 | Iteration number: [550/4518] 12% | Training loss: 0.6879825276678259
Epoch: 81 | Iteration number: [560/4518] 12% | Training loss: 0.6879809132644108
Epoch: 81 | Iteration number: [570/4518] 12% | Training loss: 0.6879756405688169
Epoch: 81 | Iteration number: [580/4518] 12% | Training loss: 0.6879528866759662
Epoch: 81 | Iteration number: [590/4518] 13% | Training loss: 0.6879182065947581
Epoch: 81 | Iteration number: [600/4518] 13% | Training loss: 0.6878982228040695
Epoch: 81 | Iteration number: [610/4518] 13% | Training loss: 0.6878754698839344
Epoch: 81 | Iteration number: [620/4518] 13% | Training loss: 0.6878734547284342
Epoch: 81 | Iteration number: [630/4518] 13% | Training loss: 0.6878446441794198
Epoch: 81 | Iteration number: [640/4518] 14% | Training loss: 0.6878210881724953
Epoch: 81 | Iteration number: [650/4518] 14% | Training loss: 0.687791178043072
Epoch: 81 | Iteration number: [660/4518] 14% | Training loss: 0.6877880315889012
Epoch: 81 | Iteration number: [670/4518] 14% | Training loss: 0.6878014732652635
Epoch: 81 | Iteration number: [680/4518] 15% | Training loss: 0.6877939999103546
Epoch: 81 | Iteration number: [690/4518] 15% | Training loss: 0.6877829758153445
Epoch: 81 | Iteration number: [700/4518] 15% | Training loss: 0.687772923878261
Epoch: 81 | Iteration number: [710/4518] 15% | Training loss: 0.6877754771373641
Epoch: 81 | Iteration number: [720/4518] 15% | Training loss: 0.6877728714711137
Epoch: 81 | Iteration number: [730/4518] 16% | Training loss: 0.6877811631927752
Epoch: 81 | Iteration number: [740/4518] 16% | Training loss: 0.6877660308335278
Epoch: 81 | Iteration number: [750/4518] 16% | Training loss: 0.6877620203495025
Epoch: 81 | Iteration number: [760/4518] 16% | Training loss: 0.6877652810592401
Epoch: 81 | Iteration number: [770/4518] 17% | Training loss: 0.6877467722861798
Epoch: 81 | Iteration number: [780/4518] 17% | Training loss: 0.6877348963266764
Epoch: 81 | Iteration number: [790/4518] 17% | Training loss: 0.6877357610418827
Epoch: 81 | Iteration number: [800/4518] 17% | Training loss: 0.6877197416126728
Epoch: 81 | Iteration number: [810/4518] 17% | Training loss: 0.6876918739006843
Epoch: 81 | Iteration number: [820/4518] 18% | Training loss: 0.6876778797405522
Epoch: 81 | Iteration number: [830/4518] 18% | Training loss: 0.6876694729529231
Epoch: 81 | Iteration number: [840/4518] 18% | Training loss: 0.6876559818784396
Epoch: 81 | Iteration number: [850/4518] 18% | Training loss: 0.6876464024010827
Epoch: 81 | Iteration number: [860/4518] 19% | Training loss: 0.6876341685306194
Epoch: 81 | Iteration number: [870/4518] 19% | Training loss: 0.6876139300308008
Epoch: 81 | Iteration number: [880/4518] 19% | Training loss: 0.6875959409231489
Epoch: 81 | Iteration number: [890/4518] 19% | Training loss: 0.6876044690608978
Epoch: 81 | Iteration number: [900/4518] 19% | Training loss: 0.6875869682762358
Epoch: 81 | Iteration number: [910/4518] 20% | Training loss: 0.6875679669144389
Epoch: 81 | Iteration number: [920/4518] 20% | Training loss: 0.6875600329559782
Epoch: 81 | Iteration number: [930/4518] 20% | Training loss: 0.6875590924934675
Epoch: 81 | Iteration number: [940/4518] 20% | Training loss: 0.6875499323327491
Epoch: 81 | Iteration number: [950/4518] 21% | Training loss: 0.6875542705937435
Epoch: 81 | Iteration number: [960/4518] 21% | Training loss: 0.6875435267264645
Epoch: 81 | Iteration number: [970/4518] 21% | Training loss: 0.6875387323271368
Epoch: 81 | Iteration number: [980/4518] 21% | Training loss: 0.6875231733735727
Epoch: 81 | Iteration number: [990/4518] 21% | Training loss: 0.687511065391579
Epoch: 81 | Iteration number: [1000/4518] 22% | Training loss: 0.687506405711174
Epoch: 81 | Iteration number: [1010/4518] 22% | Training loss: 0.6875010058431342
Epoch: 81 | Iteration number: [1020/4518] 22% | Training loss: 0.6874934111155716
Epoch: 81 | Iteration number: [1030/4518] 22% | Training loss: 0.6874938764039753
Epoch: 81 | Iteration number: [1040/4518] 23% | Training loss: 0.6874920857067292
Epoch: 81 | Iteration number: [1050/4518] 23% | Training loss: 0.6874825000195276
Epoch: 81 | Iteration number: [1060/4518] 23% | Training loss: 0.6874841342557151
Epoch: 81 | Iteration number: [1070/4518] 23% | Training loss: 0.6874843465947659
Epoch: 81 | Iteration number: [1080/4518] 23% | Training loss: 0.6874897227795036
Epoch: 81 | Iteration number: [1090/4518] 24% | Training loss: 0.6874803282252145
Epoch: 81 | Iteration number: [1100/4518] 24% | Training loss: 0.6874648508158597
Epoch: 81 | Iteration number: [1110/4518] 24% | Training loss: 0.6874537203226003
Epoch: 81 | Iteration number: [1120/4518] 24% | Training loss: 0.6874379150569438
Epoch: 81 | Iteration number: [1130/4518] 25% | Training loss: 0.6874409666103599
Epoch: 81 | Iteration number: [1140/4518] 25% | Training loss: 0.6874360760052999
Epoch: 81 | Iteration number: [1150/4518] 25% | Training loss: 0.6874327706254046
Epoch: 81 | Iteration number: [1160/4518] 25% | Training loss: 0.6874272263255613
Epoch: 81 | Iteration number: [1170/4518] 25% | Training loss: 0.6874156940696586
Epoch: 81 | Iteration number: [1180/4518] 26% | Training loss: 0.687422510880535
Epoch: 81 | Iteration number: [1190/4518] 26% | Training loss: 0.6874279680372286
Epoch: 81 | Iteration number: [1200/4518] 26% | Training loss: 0.6874225926895936
Epoch: 81 | Iteration number: [1210/4518] 26% | Training loss: 0.6874111299179803
Epoch: 81 | Iteration number: [1220/4518] 27% | Training loss: 0.6874086322354489
Epoch: 81 | Iteration number: [1230/4518] 27% | Training loss: 0.6874040988887229
Epoch: 81 | Iteration number: [1240/4518] 27% | Training loss: 0.6874026998396843
Epoch: 81 | Iteration number: [1250/4518] 27% | Training loss: 0.6873918725967407
Epoch: 81 | Iteration number: [1260/4518] 27% | Training loss: 0.6873951181532845
Epoch: 81 | Iteration number: [1270/4518] 28% | Training loss: 0.6873851048195456
Epoch: 81 | Iteration number: [1280/4518] 28% | Training loss: 0.6873664722312242
Epoch: 81 | Iteration number: [1290/4518] 28% | Training loss: 0.6873520468556604
Epoch: 81 | Iteration number: [1300/4518] 28% | Training loss: 0.6873432331360303
Epoch: 81 | Iteration number: [1310/4518] 28% | Training loss: 0.6873323408701948
Epoch: 81 | Iteration number: [1320/4518] 29% | Training loss: 0.6873282064542626
Epoch: 81 | Iteration number: [1330/4518] 29% | Training loss: 0.68732210711429
Epoch: 81 | Iteration number: [1340/4518] 29% | Training loss: 0.6873223487565766
Epoch: 81 | Iteration number: [1350/4518] 29% | Training loss: 0.6873150915569729
Epoch: 81 | Iteration number: [1360/4518] 30% | Training loss: 0.6873100761105032
Epoch: 81 | Iteration number: [1370/4518] 30% | Training loss: 0.6873112416180381
Epoch: 81 | Iteration number: [1380/4518] 30% | Training loss: 0.687310589828353
Epoch: 81 | Iteration number: [1390/4518] 30% | Training loss: 0.6873070269179858
Epoch: 81 | Iteration number: [1400/4518] 30% | Training loss: 0.6873132853848594
Epoch: 81 | Iteration number: [1410/4518] 31% | Training loss: 0.6873054126898448
Epoch: 81 | Iteration number: [1420/4518] 31% | Training loss: 0.6872901672208813
Epoch: 81 | Iteration number: [1430/4518] 31% | Training loss: 0.6872947638685053
Epoch: 81 | Iteration number: [1440/4518] 31% | Training loss: 0.6872828993946314
Epoch: 81 | Iteration number: [1450/4518] 32% | Training loss: 0.6872773889426528
Epoch: 81 | Iteration number: [1460/4518] 32% | Training loss: 0.6872683471196318
Epoch: 81 | Iteration number: [1470/4518] 32% | Training loss: 0.6872689841150427
Epoch: 81 | Iteration number: [1480/4518] 32% | Training loss: 0.6872674020158278
Epoch: 81 | Iteration number: [1490/4518] 32% | Training loss: 0.6872717276515576
Epoch: 81 | Iteration number: [1500/4518] 33% | Training loss: 0.6872702333132426
Epoch: 81 | Iteration number: [1510/4518] 33% | Training loss: 0.6872704764865092
Epoch: 81 | Iteration number: [1520/4518] 33% | Training loss: 0.6872619825366296
Epoch: 81 | Iteration number: [1530/4518] 33% | Training loss: 0.687250756087646
Epoch: 81 | Iteration number: [1540/4518] 34% | Training loss: 0.687243531354062
Epoch: 81 | Iteration number: [1550/4518] 34% | Training loss: 0.6872408587317312
Epoch: 81 | Iteration number: [1560/4518] 34% | Training loss: 0.6872408989912424
Epoch: 81 | Iteration number: [1570/4518] 34% | Training loss: 0.6872308634648657
Epoch: 81 | Iteration number: [1580/4518] 34% | Training loss: 0.6872297254921514
Epoch: 81 | Iteration number: [1590/4518] 35% | Training loss: 0.6872248754186451
Epoch: 81 | Iteration number: [1600/4518] 35% | Training loss: 0.6872204336896539
Epoch: 81 | Iteration number: [1610/4518] 35% | Training loss: 0.6872138209594703
Epoch: 81 | Iteration number: [1620/4518] 35% | Training loss: 0.6872089704981557
Epoch: 81 | Iteration number: [1630/4518] 36% | Training loss: 0.687211348454645
Epoch: 81 | Iteration number: [1640/4518] 36% | Training loss: 0.6872078764729384
Epoch: 81 | Iteration number: [1650/4518] 36% | Training loss: 0.6872005846283653
Epoch: 81 | Iteration number: [1660/4518] 36% | Training loss: 0.6872066693492682
Epoch: 81 | Iteration number: [1670/4518] 36% | Training loss: 0.6872041633386098
Epoch: 81 | Iteration number: [1680/4518] 37% | Training loss: 0.6872110707419259
Epoch: 81 | Iteration number: [1690/4518] 37% | Training loss: 0.6872122759649739
Epoch: 81 | Iteration number: [1700/4518] 37% | Training loss: 0.6872082434682285
Epoch: 81 | Iteration number: [1710/4518] 37% | Training loss: 0.6872034571324176
Epoch: 81 | Iteration number: [1720/4518] 38% | Training loss: 0.6872025588917178
Epoch: 81 | Iteration number: [1730/4518] 38% | Training loss: 0.6872011528883366
Epoch: 81 | Iteration number: [1740/4518] 38% | Training loss: 0.6871967006346275
Epoch: 81 | Iteration number: [1750/4518] 38% | Training loss: 0.6871942745958056
Epoch: 81 | Iteration number: [1760/4518] 38% | Training loss: 0.6871870717203076
Epoch: 81 | Iteration number: [1770/4518] 39% | Training loss: 0.6871839802817437
Epoch: 81 | Iteration number: [1780/4518] 39% | Training loss: 0.6871838727359022
Epoch: 81 | Iteration number: [1790/4518] 39% | Training loss: 0.6871780406829365
Epoch: 81 | Iteration number: [1800/4518] 39% | Training loss: 0.6871733233994908
Epoch: 81 | Iteration number: [1810/4518] 40% | Training loss: 0.6871631527144606
Epoch: 81 | Iteration number: [1820/4518] 40% | Training loss: 0.6871636554107561
Epoch: 81 | Iteration number: [1830/4518] 40% | Training loss: 0.6871621378783971
Epoch: 81 | Iteration number: [1840/4518] 40% | Training loss: 0.6871643287980038
Epoch: 81 | Iteration number: [1850/4518] 40% | Training loss: 0.6871627578542039
Epoch: 81 | Iteration number: [1860/4518] 41% | Training loss: 0.6871587459118136
Epoch: 81 | Iteration number: [1870/4518] 41% | Training loss: 0.6871586313540923
Epoch: 81 | Iteration number: [1880/4518] 41% | Training loss: 0.687156874924264
Epoch: 81 | Iteration number: [1890/4518] 41% | Training loss: 0.6871555863864838
Epoch: 81 | Iteration number: [1900/4518] 42% | Training loss: 0.6871530754001517
Epoch: 81 | Iteration number: [1910/4518] 42% | Training loss: 0.6871544245025875
Epoch: 81 | Iteration number: [1920/4518] 42% | Training loss: 0.6871563583302002
Epoch: 81 | Iteration number: [1930/4518] 42% | Training loss: 0.6871535430300421
Epoch: 81 | Iteration number: [1940/4518] 42% | Training loss: 0.6871556196323375
Epoch: 81 | Iteration number: [1950/4518] 43% | Training loss: 0.6871457713689559
Epoch: 81 | Iteration number: [1960/4518] 43% | Training loss: 0.6871491176133253
Epoch: 81 | Iteration number: [1970/4518] 43% | Training loss: 0.6871460367580355
Epoch: 81 | Iteration number: [1980/4518] 43% | Training loss: 0.6871456191696302
Epoch: 81 | Iteration number: [1990/4518] 44% | Training loss: 0.6871465831545729
Epoch: 81 | Iteration number: [2000/4518] 44% | Training loss: 0.6871425559222698
Epoch: 81 | Iteration number: [2010/4518] 44% | Training loss: 0.6871442020235963
Epoch: 81 | Iteration number: [2020/4518] 44% | Training loss: 0.6871525099666992
Epoch: 81 | Iteration number: [2030/4518] 44% | Training loss: 0.6871538702783914
Epoch: 81 | Iteration number: [2040/4518] 45% | Training loss: 0.6871498304839228
Epoch: 81 | Iteration number: [2050/4518] 45% | Training loss: 0.6871425645525863
Epoch: 81 | Iteration number: [2060/4518] 45% | Training loss: 0.6871411991929545
Epoch: 81 | Iteration number: [2070/4518] 45% | Training loss: 0.6871395966856952
Epoch: 81 | Iteration number: [2080/4518] 46% | Training loss: 0.6871379568599738
Epoch: 81 | Iteration number: [2090/4518] 46% | Training loss: 0.6871425258485895
Epoch: 81 | Iteration number: [2100/4518] 46% | Training loss: 0.6871407012996219
Epoch: 81 | Iteration number: [2110/4518] 46% | Training loss: 0.6871360746040164
Epoch: 81 | Iteration number: [2120/4518] 46% | Training loss: 0.6871327912751234
Epoch: 81 | Iteration number: [2130/4518] 47% | Training loss: 0.6871376229004121
Epoch: 81 | Iteration number: [2140/4518] 47% | Training loss: 0.6871328513198924
Epoch: 81 | Iteration number: [2150/4518] 47% | Training loss: 0.6871303398387376
Epoch: 81 | Iteration number: [2160/4518] 47% | Training loss: 0.6871280956875395
Epoch: 81 | Iteration number: [2170/4518] 48% | Training loss: 0.6871296110241094
Epoch: 81 | Iteration number: [2180/4518] 48% | Training loss: 0.6871262610505481
Epoch: 81 | Iteration number: [2190/4518] 48% | Training loss: 0.687120972267569
Epoch: 81 | Iteration number: [2200/4518] 48% | Training loss: 0.6871225460821933
Epoch: 81 | Iteration number: [2210/4518] 48% | Training loss: 0.6871189988306745
Epoch: 81 | Iteration number: [2220/4518] 49% | Training loss: 0.6871160843082377
Epoch: 81 | Iteration number: [2230/4518] 49% | Training loss: 0.6871142354514033
Epoch: 81 | Iteration number: [2240/4518] 49% | Training loss: 0.6871146094586168
Epoch: 81 | Iteration number: [2250/4518] 49% | Training loss: 0.6871144008901384
Epoch: 81 | Iteration number: [2260/4518] 50% | Training loss: 0.6871117403813168
Epoch: 81 | Iteration number: [2270/4518] 50% | Training loss: 0.6871063286512433
Epoch: 81 | Iteration number: [2280/4518] 50% | Training loss: 0.6871013739914225
Epoch: 81 | Iteration number: [2290/4518] 50% | Training loss: 0.6870965598452039
Epoch: 81 | Iteration number: [2300/4518] 50% | Training loss: 0.6870993251126746
Epoch: 81 | Iteration number: [2310/4518] 51% | Training loss: 0.6870993106396167
Epoch: 81 | Iteration number: [2320/4518] 51% | Training loss: 0.6870983086269478
Epoch: 81 | Iteration number: [2330/4518] 51% | Training loss: 0.6870928879971157
Epoch: 81 | Iteration number: [2340/4518] 51% | Training loss: 0.6870982812765317
Epoch: 81 | Iteration number: [2350/4518] 52% | Training loss: 0.6870949991205906
Epoch: 81 | Iteration number: [2360/4518] 52% | Training loss: 0.6870881414514477
Epoch: 81 | Iteration number: [2370/4518] 52% | Training loss: 0.6870841806196463
Epoch: 81 | Iteration number: [2380/4518] 52% | Training loss: 0.687090481279277
Epoch: 81 | Iteration number: [2390/4518] 52% | Training loss: 0.6870873286634309
Epoch: 81 | Iteration number: [2400/4518] 53% | Training loss: 0.6870842862377564
Epoch: 81 | Iteration number: [2410/4518] 53% | Training loss: 0.6870811844267786
Epoch: 81 | Iteration number: [2420/4518] 53% | Training loss: 0.6870794304885155
Epoch: 81 | Iteration number: [2430/4518] 53% | Training loss: 0.6870719925366311
Epoch: 81 | Iteration number: [2440/4518] 54% | Training loss: 0.6870720277555653
Epoch: 81 | Iteration number: [2450/4518] 54% | Training loss: 0.6870679057617577
Epoch: 81 | Iteration number: [2460/4518] 54% | Training loss: 0.6870689331031428
Epoch: 81 | Iteration number: [2470/4518] 54% | Training loss: 0.6870700277780232
Epoch: 81 | Iteration number: [2480/4518] 54% | Training loss: 0.6870728906844893
Epoch: 81 | Iteration number: [2490/4518] 55% | Training loss: 0.6870651839009251
Epoch: 81 | Iteration number: [2500/4518] 55% | Training loss: 0.6870639303684235
Epoch: 81 | Iteration number: [2510/4518] 55% | Training loss: 0.6870601359591542
Epoch: 81 | Iteration number: [2520/4518] 55% | Training loss: 0.6870589366980961
Epoch: 81 | Iteration number: [2530/4518] 55% | Training loss: 0.6870536507589544
Epoch: 81 | Iteration number: [2540/4518] 56% | Training loss: 0.6870512368876165
Epoch: 81 | Iteration number: [2550/4518] 56% | Training loss: 0.6870522865594602
Epoch: 81 | Iteration number: [2560/4518] 56% | Training loss: 0.6870486528379842
Epoch: 81 | Iteration number: [2570/4518] 56% | Training loss: 0.6870487689044225
Epoch: 81 | Iteration number: [2580/4518] 57% | Training loss: 0.6870475839043773
Epoch: 81 | Iteration number: [2590/4518] 57% | Training loss: 0.6870429221037272
Epoch: 81 | Iteration number: [2600/4518] 57% | Training loss: 0.6870438229349943
Epoch: 81 | Iteration number: [2610/4518] 57% | Training loss: 0.68704753230358
Epoch: 81 | Iteration number: [2620/4518] 57% | Training loss: 0.6870474591737485
Epoch: 81 | Iteration number: [2630/4518] 58% | Training loss: 0.6870489683894604
Epoch: 81 | Iteration number: [2640/4518] 58% | Training loss: 0.6870463366535577
Epoch: 81 | Iteration number: [2650/4518] 58% | Training loss: 0.6870436657149837
Epoch: 81 | Iteration number: [2660/4518] 58% | Training loss: 0.687041356464974
Epoch: 81 | Iteration number: [2670/4518] 59% | Training loss: 0.6870377907145783
Epoch: 81 | Iteration number: [2680/4518] 59% | Training loss: 0.6870381694676271
Epoch: 81 | Iteration number: [2690/4518] 59% | Training loss: 0.6870361731841218
Epoch: 81 | Iteration number: [2700/4518] 59% | Training loss: 0.6870310598611832
Epoch: 81 | Iteration number: [2710/4518] 59% | Training loss: 0.6870288874830267
Epoch: 81 | Iteration number: [2720/4518] 60% | Training loss: 0.6870319839786081
Epoch: 81 | Iteration number: [2730/4518] 60% | Training loss: 0.6870287210950048
Epoch: 81 | Iteration number: [2740/4518] 60% | Training loss: 0.6870271778889816
Epoch: 81 | Iteration number: [2750/4518] 60% | Training loss: 0.6870289316177368
Epoch: 81 | Iteration number: [2760/4518] 61% | Training loss: 0.6870288704832395
Epoch: 81 | Iteration number: [2770/4518] 61% | Training loss: 0.6870298097710317
Epoch: 81 | Iteration number: [2780/4518] 61% | Training loss: 0.6870287451812689
Epoch: 81 | Iteration number: [2790/4518] 61% | Training loss: 0.6870234168985838
Epoch: 81 | Iteration number: [2800/4518] 61% | Training loss: 0.6870214623425688
Epoch: 81 | Iteration number: [2810/4518] 62% | Training loss: 0.6870212032065273
Epoch: 81 | Iteration number: [2820/4518] 62% | Training loss: 0.6870207516436881
Epoch: 81 | Iteration number: [2830/4518] 62% | Training loss: 0.6870184252834994
Epoch: 81 | Iteration number: [2840/4518] 62% | Training loss: 0.6870198605765759
Epoch: 81 | Iteration number: [2850/4518] 63% | Training loss: 0.6870209909740247
Epoch: 81 | Iteration number: [2860/4518] 63% | Training loss: 0.6870204705458421
Epoch: 81 | Iteration number: [2870/4518] 63% | Training loss: 0.6870223299343827
Epoch: 81 | Iteration number: [2880/4518] 63% | Training loss: 0.6870214821770787
Epoch: 81 | Iteration number: [2890/4518] 63% | Training loss: 0.687019504292201
Epoch: 81 | Iteration number: [2900/4518] 64% | Training loss: 0.6870142686983635
Epoch: 81 | Iteration number: [2910/4518] 64% | Training loss: 0.6870149878292149
Epoch: 81 | Iteration number: [2920/4518] 64% | Training loss: 0.6870124723200929
Epoch: 81 | Iteration number: [2930/4518] 64% | Training loss: 0.6870121416785204
Epoch: 81 | Iteration number: [2940/4518] 65% | Training loss: 0.6870112451363583
Epoch: 81 | Iteration number: [2950/4518] 65% | Training loss: 0.6870104064375667
Epoch: 81 | Iteration number: [2960/4518] 65% | Training loss: 0.6870115268874812
Epoch: 81 | Iteration number: [2970/4518] 65% | Training loss: 0.6870095676243907
Epoch: 81 | Iteration number: [2980/4518] 65% | Training loss: 0.6870089814566925
Epoch: 81 | Iteration number: [2990/4518] 66% | Training loss: 0.6870059361625276
Epoch: 81 | Iteration number: [3000/4518] 66% | Training loss: 0.6870058795611064
Epoch: 81 | Iteration number: [3010/4518] 66% | Training loss: 0.6869984376074072
Epoch: 81 | Iteration number: [3020/4518] 66% | Training loss: 0.6869972119268203
Epoch: 81 | Iteration number: [3030/4518] 67% | Training loss: 0.6869972697972464
Epoch: 81 | Iteration number: [3040/4518] 67% | Training loss: 0.6869978201820662
Epoch: 81 | Iteration number: [3050/4518] 67% | Training loss: 0.6869964339107764
Epoch: 81 | Iteration number: [3060/4518] 67% | Training loss: 0.6869945019093994
Epoch: 81 | Iteration number: [3070/4518] 67% | Training loss: 0.6869915809227511
Epoch: 81 | Iteration number: [3080/4518] 68% | Training loss: 0.6869889989688799
Epoch: 81 | Iteration number: [3090/4518] 68% | Training loss: 0.686988817796738
Epoch: 81 | Iteration number: [3100/4518] 68% | Training loss: 0.6869863536665517
Epoch: 81 | Iteration number: [3110/4518] 68% | Training loss: 0.6869831829400691
Epoch: 81 | Iteration number: [3120/4518] 69% | Training loss: 0.6869858088401648
Epoch: 81 | Iteration number: [3130/4518] 69% | Training loss: 0.6869837706271833
Epoch: 81 | Iteration number: [3140/4518] 69% | Training loss: 0.6869809914926055
Epoch: 81 | Iteration number: [3150/4518] 69% | Training loss: 0.6869801105582525
Epoch: 81 | Iteration number: [3160/4518] 69% | Training loss: 0.6869816072379487
Epoch: 81 | Iteration number: [3170/4518] 70% | Training loss: 0.6869803510817819
Epoch: 81 | Iteration number: [3180/4518] 70% | Training loss: 0.686980538341984
Epoch: 81 | Iteration number: [3190/4518] 70% | Training loss: 0.686984741407502
Epoch: 81 | Iteration number: [3200/4518] 70% | Training loss: 0.6869835578836501
Epoch: 81 | Iteration number: [3210/4518] 71% | Training loss: 0.6869834763238735
Epoch: 81 | Iteration number: [3220/4518] 71% | Training loss: 0.6869803083794458
Epoch: 81 | Iteration number: [3230/4518] 71% | Training loss: 0.6869789495556716
Epoch: 81 | Iteration number: [3240/4518] 71% | Training loss: 0.6869755365966279
Epoch: 81 | Iteration number: [3250/4518] 71% | Training loss: 0.6869719094129709
Epoch: 81 | Iteration number: [3260/4518] 72% | Training loss: 0.6869749157889489
Epoch: 81 | Iteration number: [3270/4518] 72% | Training loss: 0.6869741818955915
Epoch: 81 | Iteration number: [3280/4518] 72% | Training loss: 0.6869751278765318
Epoch: 81 | Iteration number: [3290/4518] 72% | Training loss: 0.6869742117391894
Epoch: 81 | Iteration number: [3300/4518] 73% | Training loss: 0.6869744123653932
Epoch: 81 | Iteration number: [3310/4518] 73% | Training loss: 0.6869719568876341
Epoch: 81 | Iteration number: [3320/4518] 73% | Training loss: 0.6869662623807609
Epoch: 81 | Iteration number: [3330/4518] 73% | Training loss: 0.6869641164580623
Epoch: 81 | Iteration number: [3340/4518] 73% | Training loss: 0.6869615937421422
Epoch: 81 | Iteration number: [3350/4518] 74% | Training loss: 0.6869596020855121
Epoch: 81 | Iteration number: [3360/4518] 74% | Training loss: 0.6869592726230621
Epoch: 81 | Iteration number: [3370/4518] 74% | Training loss: 0.6869569217239007
Epoch: 81 | Iteration number: [3380/4518] 74% | Training loss: 0.6869558821592106
Epoch: 81 | Iteration number: [3390/4518] 75% | Training loss: 0.6869565257280625
Epoch: 81 | Iteration number: [3400/4518] 75% | Training loss: 0.6869534671131302
Epoch: 81 | Iteration number: [3410/4518] 75% | Training loss: 0.686952655843276
Epoch: 81 | Iteration number: [3420/4518] 75% | Training loss: 0.6869539372927961
Epoch: 81 | Iteration number: [3430/4518] 75% | Training loss: 0.6869554416083733
Epoch: 81 | Iteration number: [3440/4518] 76% | Training loss: 0.6869559015992076
Epoch: 81 | Iteration number: [3450/4518] 76% | Training loss: 0.6869549656259841
Epoch: 81 | Iteration number: [3460/4518] 76% | Training loss: 0.6869543998055375
Epoch: 81 | Iteration number: [3470/4518] 76% | Training loss: 0.6869470373869629
Epoch: 81 | Iteration number: [3480/4518] 77% | Training loss: 0.6869501442744814
Epoch: 81 | Iteration number: [3490/4518] 77% | Training loss: 0.6869479653657679
Epoch: 81 | Iteration number: [3500/4518] 77% | Training loss: 0.686950308067458
Epoch: 81 | Iteration number: [3510/4518] 77% | Training loss: 0.6869516316132668
Epoch: 81 | Iteration number: [3520/4518] 77% | Training loss: 0.6869535122913393
Epoch: 81 | Iteration number: [3530/4518] 78% | Training loss: 0.6869543093290951
Epoch: 81 | Iteration number: [3540/4518] 78% | Training loss: 0.6869537161400089
Epoch: 81 | Iteration number: [3550/4518] 78% | Training loss: 0.6869543571203527
Epoch: 81 | Iteration number: [3560/4518] 78% | Training loss: 0.6869530596759882
Epoch: 81 | Iteration number: [3570/4518] 79% | Training loss: 0.6869520451341357
Epoch: 81 | Iteration number: [3580/4518] 79% | Training loss: 0.686955454928915
Epoch: 81 | Iteration number: [3590/4518] 79% | Training loss: 0.6869560367217635
Epoch: 81 | Iteration number: [3600/4518] 79% | Training loss: 0.6869558454222149
Epoch: 81 | Iteration number: [3610/4518] 79% | Training loss: 0.6869576069952048
Epoch: 81 | Iteration number: [3620/4518] 80% | Training loss: 0.6869543352673726
Epoch: 81 | Iteration number: [3630/4518] 80% | Training loss: 0.6869536403453711
Epoch: 81 | Iteration number: [3640/4518] 80% | Training loss: 0.6869567033026245
Epoch: 81 | Iteration number: [3650/4518] 80% | Training loss: 0.6869606435952121
Epoch: 81 | Iteration number: [3660/4518] 81% | Training loss: 0.6869633382135402
Epoch: 81 | Iteration number: [3670/4518] 81% | Training loss: 0.6869608968902349
Epoch: 81 | Iteration number: [3680/4518] 81% | Training loss: 0.6869587567837342
Epoch: 81 | Iteration number: [3690/4518] 81% | Training loss: 0.6869583581682789
Epoch: 81 | Iteration number: [3700/4518] 81% | Training loss: 0.6869584631597674
Epoch: 81 | Iteration number: [3710/4518] 82% | Training loss: 0.6869601154263129
Epoch: 81 | Iteration number: [3720/4518] 82% | Training loss: 0.686957058486759
Epoch: 81 | Iteration number: [3730/4518] 82% | Training loss: 0.6869585472840726
Epoch: 81 | Iteration number: [3740/4518] 82% | Training loss: 0.6869557278041534
Epoch: 81 | Iteration number: [3750/4518] 83% | Training loss: 0.6869574428399404
Epoch: 81 | Iteration number: [3760/4518] 83% | Training loss: 0.6869578958350293
Epoch: 81 | Iteration number: [3770/4518] 83% | Training loss: 0.6869556997593897
Epoch: 81 | Iteration number: [3780/4518] 83% | Training loss: 0.6869577609830433
Epoch: 81 | Iteration number: [3790/4518] 83% | Training loss: 0.6869578977216202
Epoch: 81 | Iteration number: [3800/4518] 84% | Training loss: 0.686957434007996
Epoch: 81 | Iteration number: [3810/4518] 84% | Training loss: 0.6869587972408204
Epoch: 81 | Iteration number: [3820/4518] 84% | Training loss: 0.6869569622097215
Epoch: 81 | Iteration number: [3830/4518] 84% | Training loss: 0.6869502964281227
Epoch: 81 | Iteration number: [3840/4518] 84% | Training loss: 0.6869471860428651
Epoch: 81 | Iteration number: [3850/4518] 85% | Training loss: 0.6869509375869454
Epoch: 81 | Iteration number: [3860/4518] 85% | Training loss: 0.6869503786063564
Epoch: 81 | Iteration number: [3870/4518] 85% | Training loss: 0.6869475755580636
Epoch: 81 | Iteration number: [3880/4518] 85% | Training loss: 0.6869463488305967
Epoch: 81 | Iteration number: [3890/4518] 86% | Training loss: 0.6869451132255838
Epoch: 81 | Iteration number: [3900/4518] 86% | Training loss: 0.6869431819212742
Epoch: 81 | Iteration number: [3910/4518] 86% | Training loss: 0.6869436934323567
Epoch: 81 | Iteration number: [3920/4518] 86% | Training loss: 0.6869447544369163
Epoch: 81 | Iteration number: [3930/4518] 86% | Training loss: 0.6869424515401438
Epoch: 81 | Iteration number: [3940/4518] 87% | Training loss: 0.6869431109143997
Epoch: 81 | Iteration number: [3950/4518] 87% | Training loss: 0.6869403242461289
Epoch: 81 | Iteration number: [3960/4518] 87% | Training loss: 0.6869392459741747
Epoch: 81 | Iteration number: [3970/4518] 87% | Training loss: 0.6869403958320618
Epoch: 81 | Iteration number: [3980/4518] 88% | Training loss: 0.6869377421074776
Epoch: 81 | Iteration number: [3990/4518] 88% | Training loss: 0.6869389000542481
Epoch: 81 | Iteration number: [4000/4518] 88% | Training loss: 0.6869403169304132
Epoch: 81 | Iteration number: [4010/4518] 88% | Training loss: 0.6869371378362328
Epoch: 81 | Iteration number: [4020/4518] 88% | Training loss: 0.686937925352979
Epoch: 81 | Iteration number: [4030/4518] 89% | Training loss: 0.6869381043958309
Epoch: 81 | Iteration number: [4040/4518] 89% | Training loss: 0.6869402106888224
Epoch: 81 | Iteration number: [4050/4518] 89% | Training loss: 0.686938466216311
Epoch: 81 | Iteration number: [4060/4518] 89% | Training loss: 0.686939948767864
Epoch: 81 | Iteration number: [4070/4518] 90% | Training loss: 0.6869381851880497
Epoch: 81 | Iteration number: [4080/4518] 90% | Training loss: 0.686935985409746
Epoch: 81 | Iteration number: [4090/4518] 90% | Training loss: 0.6869347052206911
Epoch: 81 | Iteration number: [4100/4518] 90% | Training loss: 0.6869335310197459
Epoch: 81 | Iteration number: [4110/4518] 90% | Training loss: 0.6869326156711346
Epoch: 81 | Iteration number: [4120/4518] 91% | Training loss: 0.6869341647162021
Epoch: 81 | Iteration number: [4130/4518] 91% | Training loss: 0.6869340563801819
Epoch: 81 | Iteration number: [4140/4518] 91% | Training loss: 0.6869329854486069
Epoch: 81 | Iteration number: [4150/4518] 91% | Training loss: 0.6869321633247008
Epoch: 81 | Iteration number: [4160/4518] 92% | Training loss: 0.6869285982388716
Epoch: 81 | Iteration number: [4170/4518] 92% | Training loss: 0.686931613580786
Epoch: 81 | Iteration number: [4180/4518] 92% | Training loss: 0.6869305959586322
Epoch: 81 | Iteration number: [4190/4518] 92% | Training loss: 0.6869292194063737
Epoch: 81 | Iteration number: [4200/4518] 92% | Training loss: 0.686930261240119
Epoch: 81 | Iteration number: [4210/4518] 93% | Training loss: 0.6869264017374669
Epoch: 81 | Iteration number: [4220/4518] 93% | Training loss: 0.6869266985010761
Epoch: 81 | Iteration number: [4230/4518] 93% | Training loss: 0.6869257560153943
Epoch: 81 | Iteration number: [4240/4518] 93% | Training loss: 0.6869256653453943
Epoch: 81 | Iteration number: [4250/4518] 94% | Training loss: 0.6869265794193044
Epoch: 81 | Iteration number: [4260/4518] 94% | Training loss: 0.6869233959997204
Epoch: 81 | Iteration number: [4270/4518] 94% | Training loss: 0.6869219512654691
Epoch: 81 | Iteration number: [4280/4518] 94% | Training loss: 0.686919081517469
Epoch: 81 | Iteration number: [4290/4518] 94% | Training loss: 0.6869173832845576
Epoch: 81 | Iteration number: [4300/4518] 95% | Training loss: 0.6869150459073311
Epoch: 81 | Iteration number: [4310/4518] 95% | Training loss: 0.686916229232558
Epoch: 81 | Iteration number: [4320/4518] 95% | Training loss: 0.68691358719435
Epoch: 81 | Iteration number: [4330/4518] 95% | Training loss: 0.686916275511713
Epoch: 81 | Iteration number: [4340/4518] 96% | Training loss: 0.6869167263744064
Epoch: 81 | Iteration number: [4350/4518] 96% | Training loss: 0.6869180099032391
Epoch: 81 | Iteration number: [4360/4518] 96% | Training loss: 0.6869159032718851
Epoch: 81 | Iteration number: [4370/4518] 96% | Training loss: 0.6869169443913946
Epoch: 81 | Iteration number: [4380/4518] 96% | Training loss: 0.6869161304409646
Epoch: 81 | Iteration number: [4390/4518] 97% | Training loss: 0.6869168511827334
Epoch: 81 | Iteration number: [4400/4518] 97% | Training loss: 0.6869154167039828
Epoch: 81 | Iteration number: [4410/4518] 97% | Training loss: 0.6869172469288314
Epoch: 81 | Iteration number: [4420/4518] 97% | Training loss: 0.686917043878482
Epoch: 81 | Iteration number: [4430/4518] 98% | Training loss: 0.6869164754117315
Epoch: 81 | Iteration number: [4440/4518] 98% | Training loss: 0.6869126914857744
Epoch: 81 | Iteration number: [4450/4518] 98% | Training loss: 0.6869139507915197
Epoch: 81 | Iteration number: [4460/4518] 98% | Training loss: 0.6869130601530118
Epoch: 81 | Iteration number: [4470/4518] 98% | Training loss: 0.6869118810100043
Epoch: 81 | Iteration number: [4480/4518] 99% | Training loss: 0.6869131106750241
Epoch: 81 | Iteration number: [4490/4518] 99% | Training loss: 0.6869148754330149
Epoch: 81 | Iteration number: [4500/4518] 99% | Training loss: 0.6869103202952279
Epoch: 81 | Iteration number: [4510/4518] 99% | Training loss: 0.6869123525207165

 End of epoch: 81 | Train Loss: 0.6867591020885745 | Training Time: 633 

 End of epoch: 81 | Eval Loss: 0.6895934379830653 | Evaluating Time: 17 
Epoch: 82 | Iteration number: [10/4518] 0% | Training loss: 0.7560921669006347
Epoch: 82 | Iteration number: [20/4518] 0% | Training loss: 0.7206869721412659
Epoch: 82 | Iteration number: [30/4518] 0% | Training loss: 0.709204351902008
Epoch: 82 | Iteration number: [40/4518] 0% | Training loss: 0.703480975329876
Epoch: 82 | Iteration number: [50/4518] 1% | Training loss: 0.70007328748703
Epoch: 82 | Iteration number: [60/4518] 1% | Training loss: 0.6980956514676412
Epoch: 82 | Iteration number: [70/4518] 1% | Training loss: 0.6964151706014361
Epoch: 82 | Iteration number: [80/4518] 1% | Training loss: 0.6951865151524543
Epoch: 82 | Iteration number: [90/4518] 1% | Training loss: 0.6942735718356239
Epoch: 82 | Iteration number: [100/4518] 2% | Training loss: 0.6934216994047165
Epoch: 82 | Iteration number: [110/4518] 2% | Training loss: 0.6928331104191867
Epoch: 82 | Iteration number: [120/4518] 2% | Training loss: 0.6923409049709638
Epoch: 82 | Iteration number: [130/4518] 2% | Training loss: 0.69193170941793
Epoch: 82 | Iteration number: [140/4518] 3% | Training loss: 0.69152016384261
Epoch: 82 | Iteration number: [150/4518] 3% | Training loss: 0.6911836214860281
Epoch: 82 | Iteration number: [160/4518] 3% | Training loss: 0.6909010615199804
Epoch: 82 | Iteration number: [170/4518] 3% | Training loss: 0.6906627272858339
Epoch: 82 | Iteration number: [180/4518] 3% | Training loss: 0.6903901454475191
Epoch: 82 | Iteration number: [190/4518] 4% | Training loss: 0.6902138176717256
Epoch: 82 | Iteration number: [200/4518] 4% | Training loss: 0.6900223535299301
Epoch: 82 | Iteration number: [210/4518] 4% | Training loss: 0.6898700912793477
Epoch: 82 | Iteration number: [220/4518] 4% | Training loss: 0.6896958497437564
Epoch: 82 | Iteration number: [230/4518] 5% | Training loss: 0.6894938295302184
Epoch: 82 | Iteration number: [240/4518] 5% | Training loss: 0.6894215700527032
Epoch: 82 | Iteration number: [250/4518] 5% | Training loss: 0.6892862234115601
Epoch: 82 | Iteration number: [260/4518] 5% | Training loss: 0.6891922808610476
Epoch: 82 | Iteration number: [270/4518] 5% | Training loss: 0.6890960995797758
Epoch: 82 | Iteration number: [280/4518] 6% | Training loss: 0.6889826323304857
Epoch: 82 | Iteration number: [290/4518] 6% | Training loss: 0.6888632751744369
Epoch: 82 | Iteration number: [300/4518] 6% | Training loss: 0.6887942238648732
Epoch: 82 | Iteration number: [310/4518] 6% | Training loss: 0.688780709620445
Epoch: 82 | Iteration number: [320/4518] 7% | Training loss: 0.688739986717701
Epoch: 82 | Iteration number: [330/4518] 7% | Training loss: 0.6886934325550542
Epoch: 82 | Iteration number: [340/4518] 7% | Training loss: 0.6886339757372352
Epoch: 82 | Iteration number: [350/4518] 7% | Training loss: 0.688573681967599
Epoch: 82 | Iteration number: [360/4518] 7% | Training loss: 0.6885152580009566
Epoch: 82 | Iteration number: [370/4518] 8% | Training loss: 0.6885131193173898
Epoch: 82 | Iteration number: [380/4518] 8% | Training loss: 0.6884971582575848
Epoch: 82 | Iteration number: [390/4518] 8% | Training loss: 0.6884478330612183
Epoch: 82 | Iteration number: [400/4518] 8% | Training loss: 0.6883845825493335
Epoch: 82 | Iteration number: [410/4518] 9% | Training loss: 0.6883474307816203
Epoch: 82 | Iteration number: [420/4518] 9% | Training loss: 0.6883038886955806
Epoch: 82 | Iteration number: [430/4518] 9% | Training loss: 0.6882379096607829
Epoch: 82 | Iteration number: [440/4518] 9% | Training loss: 0.6882253699681976
Epoch: 82 | Iteration number: [450/4518] 9% | Training loss: 0.6881598406367831
Epoch: 82 | Iteration number: [460/4518] 10% | Training loss: 0.6881162884442703
Epoch: 82 | Iteration number: [470/4518] 10% | Training loss: 0.6880851404463991
Epoch: 82 | Iteration number: [480/4518] 10% | Training loss: 0.6880323754002651
Epoch: 82 | Iteration number: [490/4518] 10% | Training loss: 0.6880069128104619
Epoch: 82 | Iteration number: [500/4518] 11% | Training loss: 0.6879853463172912
Epoch: 82 | Iteration number: [510/4518] 11% | Training loss: 0.6879546537118799
Epoch: 82 | Iteration number: [520/4518] 11% | Training loss: 0.6879177477497321
Epoch: 82 | Iteration number: [530/4518] 11% | Training loss: 0.687900455605309
Epoch: 82 | Iteration number: [540/4518] 11% | Training loss: 0.6878586657621243
Epoch: 82 | Iteration number: [550/4518] 12% | Training loss: 0.6878488449616865
Epoch: 82 | Iteration number: [560/4518] 12% | Training loss: 0.6878016945506845
Epoch: 82 | Iteration number: [570/4518] 12% | Training loss: 0.6878003588893957
Epoch: 82 | Iteration number: [580/4518] 12% | Training loss: 0.6877699184006658
Epoch: 82 | Iteration number: [590/4518] 13% | Training loss: 0.6877180382356806
Epoch: 82 | Iteration number: [600/4518] 13% | Training loss: 0.6877035142978033
Epoch: 82 | Iteration number: [610/4518] 13% | Training loss: 0.6876877673336717
Epoch: 82 | Iteration number: [620/4518] 13% | Training loss: 0.6876497871452762
Epoch: 82 | Iteration number: [630/4518] 13% | Training loss: 0.687642261622444
Epoch: 82 | Iteration number: [640/4518] 14% | Training loss: 0.6876303857192397
Epoch: 82 | Iteration number: [650/4518] 14% | Training loss: 0.6876037047459529
Epoch: 82 | Iteration number: [660/4518] 14% | Training loss: 0.687598072940653
Epoch: 82 | Iteration number: [670/4518] 14% | Training loss: 0.6875858267741417
Epoch: 82 | Iteration number: [680/4518] 15% | Training loss: 0.6875766347436344
Epoch: 82 | Iteration number: [690/4518] 15% | Training loss: 0.6875620808290399
Epoch: 82 | Iteration number: [700/4518] 15% | Training loss: 0.6875476287943977
Epoch: 82 | Iteration number: [710/4518] 15% | Training loss: 0.6875224994941497
Epoch: 82 | Iteration number: [720/4518] 15% | Training loss: 0.6874992945128017
Epoch: 82 | Iteration number: [730/4518] 16% | Training loss: 0.6874854016793918
Epoch: 82 | Iteration number: [740/4518] 16% | Training loss: 0.6874842366656742
Epoch: 82 | Iteration number: [750/4518] 16% | Training loss: 0.68746874888738
Epoch: 82 | Iteration number: [760/4518] 16% | Training loss: 0.6874631946024142
Epoch: 82 | Iteration number: [770/4518] 17% | Training loss: 0.6874626237076599
Epoch: 82 | Iteration number: [780/4518] 17% | Training loss: 0.6874693745221847
Epoch: 82 | Iteration number: [790/4518] 17% | Training loss: 0.6874530723577813
Epoch: 82 | Iteration number: [800/4518] 17% | Training loss: 0.6874271839112044
Epoch: 82 | Iteration number: [810/4518] 17% | Training loss: 0.6874082171622617
Epoch: 82 | Iteration number: [820/4518] 18% | Training loss: 0.6873966704054577
Epoch: 82 | Iteration number: [830/4518] 18% | Training loss: 0.687386618105762
Epoch: 82 | Iteration number: [840/4518] 18% | Training loss: 0.6873872515701113
Epoch: 82 | Iteration number: [850/4518] 18% | Training loss: 0.6873722183003145
Epoch: 82 | Iteration number: [860/4518] 19% | Training loss: 0.6873583241257557
Epoch: 82 | Iteration number: [870/4518] 19% | Training loss: 0.6873161230964222
Epoch: 82 | Iteration number: [880/4518] 19% | Training loss: 0.6873165864836086
Epoch: 82 | Iteration number: [890/4518] 19% | Training loss: 0.6873149409053031
Epoch: 82 | Iteration number: [900/4518] 19% | Training loss: 0.6873199509912067
Epoch: 82 | Iteration number: [910/4518] 20% | Training loss: 0.6873198265557761
Epoch: 82 | Iteration number: [920/4518] 20% | Training loss: 0.6873158605850261
Epoch: 82 | Iteration number: [930/4518] 20% | Training loss: 0.6873088460455659
Epoch: 82 | Iteration number: [940/4518] 20% | Training loss: 0.6873064660011454
Epoch: 82 | Iteration number: [950/4518] 21% | Training loss: 0.6873094006588585
Epoch: 82 | Iteration number: [960/4518] 21% | Training loss: 0.6872949839259187
Epoch: 82 | Iteration number: [970/4518] 21% | Training loss: 0.687285652725967
Epoch: 82 | Iteration number: [980/4518] 21% | Training loss: 0.6872733145952225
Epoch: 82 | Iteration number: [990/4518] 21% | Training loss: 0.6872720407717156
Epoch: 82 | Iteration number: [1000/4518] 22% | Training loss: 0.6872609279155731
Epoch: 82 | Iteration number: [1010/4518] 22% | Training loss: 0.6872541909760768
Epoch: 82 | Iteration number: [1020/4518] 22% | Training loss: 0.6872494110874101
Epoch: 82 | Iteration number: [1030/4518] 22% | Training loss: 0.6872451351684274
Epoch: 82 | Iteration number: [1040/4518] 23% | Training loss: 0.6872388674089542
Epoch: 82 | Iteration number: [1050/4518] 23% | Training loss: 0.6872337868100121
Epoch: 82 | Iteration number: [1060/4518] 23% | Training loss: 0.6872364892712179
Epoch: 82 | Iteration number: [1070/4518] 23% | Training loss: 0.6872229352732685
Epoch: 82 | Iteration number: [1080/4518] 23% | Training loss: 0.6872241455095786
Epoch: 82 | Iteration number: [1090/4518] 24% | Training loss: 0.6872095706812832
Epoch: 82 | Iteration number: [1100/4518] 24% | Training loss: 0.6872052005204288
Epoch: 82 | Iteration number: [1110/4518] 24% | Training loss: 0.6872026940186818
Epoch: 82 | Iteration number: [1120/4518] 24% | Training loss: 0.6872070580188717
Epoch: 82 | Iteration number: [1130/4518] 25% | Training loss: 0.6872053021350794
Epoch: 82 | Iteration number: [1140/4518] 25% | Training loss: 0.6872156984450525
Epoch: 82 | Iteration number: [1150/4518] 25% | Training loss: 0.6872103071212768
Epoch: 82 | Iteration number: [1160/4518] 25% | Training loss: 0.6872113318278872
Epoch: 82 | Iteration number: [1170/4518] 25% | Training loss: 0.6872085858104575
Epoch: 82 | Iteration number: [1180/4518] 26% | Training loss: 0.6871971976453976
Epoch: 82 | Iteration number: [1190/4518] 26% | Training loss: 0.6871982729234616
Epoch: 82 | Iteration number: [1200/4518] 26% | Training loss: 0.6871997155745824
Epoch: 82 | Iteration number: [1210/4518] 26% | Training loss: 0.6872017006243556
Epoch: 82 | Iteration number: [1220/4518] 27% | Training loss: 0.6871995140783123
Epoch: 82 | Iteration number: [1230/4518] 27% | Training loss: 0.6871998837323693
Epoch: 82 | Iteration number: [1240/4518] 27% | Training loss: 0.6871940096539836
Epoch: 82 | Iteration number: [1250/4518] 27% | Training loss: 0.6872027977466584
Epoch: 82 | Iteration number: [1260/4518] 27% | Training loss: 0.6872039245234596
Epoch: 82 | Iteration number: [1270/4518] 28% | Training loss: 0.6872011744131253
Epoch: 82 | Iteration number: [1280/4518] 28% | Training loss: 0.687202556245029
Epoch: 82 | Iteration number: [1290/4518] 28% | Training loss: 0.6872025176536205
Epoch: 82 | Iteration number: [1300/4518] 28% | Training loss: 0.6871934611063737
Epoch: 82 | Iteration number: [1310/4518] 28% | Training loss: 0.6871962833040544
Epoch: 82 | Iteration number: [1320/4518] 29% | Training loss: 0.6871980423728625
Epoch: 82 | Iteration number: [1330/4518] 29% | Training loss: 0.6871827851560779
Epoch: 82 | Iteration number: [1340/4518] 29% | Training loss: 0.6871799242140642
Epoch: 82 | Iteration number: [1350/4518] 29% | Training loss: 0.6871792124377356
Epoch: 82 | Iteration number: [1360/4518] 30% | Training loss: 0.6871756176299909
Epoch: 82 | Iteration number: [1370/4518] 30% | Training loss: 0.6871639090732936
Epoch: 82 | Iteration number: [1380/4518] 30% | Training loss: 0.6871620368266451
Epoch: 82 | Iteration number: [1390/4518] 30% | Training loss: 0.6871592431188487
Epoch: 82 | Iteration number: [1400/4518] 30% | Training loss: 0.6871517205238342
Epoch: 82 | Iteration number: [1410/4518] 31% | Training loss: 0.6871353477873701
Epoch: 82 | Iteration number: [1420/4518] 31% | Training loss: 0.6871244315949964
Epoch: 82 | Iteration number: [1430/4518] 31% | Training loss: 0.6871083806444716
Epoch: 82 | Iteration number: [1440/4518] 31% | Training loss: 0.6871055118325684
Epoch: 82 | Iteration number: [1450/4518] 32% | Training loss: 0.6871009254455567
Epoch: 82 | Iteration number: [1460/4518] 32% | Training loss: 0.6870948349368082
Epoch: 82 | Iteration number: [1470/4518] 32% | Training loss: 0.6870890556955013
Epoch: 82 | Iteration number: [1480/4518] 32% | Training loss: 0.687089569947204
Epoch: 82 | Iteration number: [1490/4518] 32% | Training loss: 0.6870896646240413
Epoch: 82 | Iteration number: [1500/4518] 33% | Training loss: 0.6870958616336187
Epoch: 82 | Iteration number: [1510/4518] 33% | Training loss: 0.6870933998499485
Epoch: 82 | Iteration number: [1520/4518] 33% | Training loss: 0.6870948297412772
Epoch: 82 | Iteration number: [1530/4518] 33% | Training loss: 0.6870894235333586
Epoch: 82 | Iteration number: [1540/4518] 34% | Training loss: 0.6870845385186084
Epoch: 82 | Iteration number: [1550/4518] 34% | Training loss: 0.6870863690683918
Epoch: 82 | Iteration number: [1560/4518] 34% | Training loss: 0.6870916730318314
Epoch: 82 | Iteration number: [1570/4518] 34% | Training loss: 0.687093605585159
Epoch: 82 | Iteration number: [1580/4518] 34% | Training loss: 0.6870879997180988
Epoch: 82 | Iteration number: [1590/4518] 35% | Training loss: 0.6870857211403877
Epoch: 82 | Iteration number: [1600/4518] 35% | Training loss: 0.687084414511919
Epoch: 82 | Iteration number: [1610/4518] 35% | Training loss: 0.6870835083612004
Epoch: 82 | Iteration number: [1620/4518] 35% | Training loss: 0.6870762037274278
Epoch: 82 | Iteration number: [1630/4518] 36% | Training loss: 0.6870727189845103
Epoch: 82 | Iteration number: [1640/4518] 36% | Training loss: 0.6870692490441043
Epoch: 82 | Iteration number: [1650/4518] 36% | Training loss: 0.6870629664623376
Epoch: 82 | Iteration number: [1660/4518] 36% | Training loss: 0.6870673136897834
Epoch: 82 | Iteration number: [1670/4518] 36% | Training loss: 0.6870715775889551
Epoch: 82 | Iteration number: [1680/4518] 37% | Training loss: 0.6870713483010019
Epoch: 82 | Iteration number: [1690/4518] 37% | Training loss: 0.6870716081921165
Epoch: 82 | Iteration number: [1700/4518] 37% | Training loss: 0.6870698491264792
Epoch: 82 | Iteration number: [1710/4518] 37% | Training loss: 0.6870682512807568
Epoch: 82 | Iteration number: [1720/4518] 38% | Training loss: 0.6870579429144084
Epoch: 82 | Iteration number: [1730/4518] 38% | Training loss: 0.6870546159372164
Epoch: 82 | Iteration number: [1740/4518] 38% | Training loss: 0.6870626934986005
Epoch: 82 | Iteration number: [1750/4518] 38% | Training loss: 0.6870571180411748
Epoch: 82 | Iteration number: [1760/4518] 38% | Training loss: 0.687056535787203
Epoch: 82 | Iteration number: [1770/4518] 39% | Training loss: 0.6870510746193471
Epoch: 82 | Iteration number: [1780/4518] 39% | Training loss: 0.6870513461613923
Epoch: 82 | Iteration number: [1790/4518] 39% | Training loss: 0.6870467527285634
Epoch: 82 | Iteration number: [1800/4518] 39% | Training loss: 0.6870451217558649
Epoch: 82 | Iteration number: [1810/4518] 40% | Training loss: 0.6870436384532992
Epoch: 82 | Iteration number: [1820/4518] 40% | Training loss: 0.6870393639409935
Epoch: 82 | Iteration number: [1830/4518] 40% | Training loss: 0.6870362174641239
Epoch: 82 | Iteration number: [1840/4518] 40% | Training loss: 0.6870317578639673
Epoch: 82 | Iteration number: [1850/4518] 40% | Training loss: 0.6870322893116925
Epoch: 82 | Iteration number: [1860/4518] 41% | Training loss: 0.687035063582082
Epoch: 82 | Iteration number: [1870/4518] 41% | Training loss: 0.6870298342271285
Epoch: 82 | Iteration number: [1880/4518] 41% | Training loss: 0.6870290282241842
Epoch: 82 | Iteration number: [1890/4518] 41% | Training loss: 0.6870261420963933
Epoch: 82 | Iteration number: [1900/4518] 42% | Training loss: 0.6870261472463608
Epoch: 82 | Iteration number: [1910/4518] 42% | Training loss: 0.6870294622725841
Epoch: 82 | Iteration number: [1920/4518] 42% | Training loss: 0.6870317709632218
Epoch: 82 | Iteration number: [1930/4518] 42% | Training loss: 0.6870333809617888
Epoch: 82 | Iteration number: [1940/4518] 42% | Training loss: 0.6870265420257431
Epoch: 82 | Iteration number: [1950/4518] 43% | Training loss: 0.6870319922765096
Epoch: 82 | Iteration number: [1960/4518] 43% | Training loss: 0.6870320111513137
Epoch: 82 | Iteration number: [1970/4518] 43% | Training loss: 0.68703320852391
Epoch: 82 | Iteration number: [1980/4518] 43% | Training loss: 0.6870401981503073
Epoch: 82 | Iteration number: [1990/4518] 44% | Training loss: 0.6870444058173865
Epoch: 82 | Iteration number: [2000/4518] 44% | Training loss: 0.6870398323535919
Epoch: 82 | Iteration number: [2010/4518] 44% | Training loss: 0.6870393185769741
Epoch: 82 | Iteration number: [2020/4518] 44% | Training loss: 0.6870388694328837
Epoch: 82 | Iteration number: [2030/4518] 44% | Training loss: 0.687035532126873
Epoch: 82 | Iteration number: [2040/4518] 45% | Training loss: 0.6870350189653097
Epoch: 82 | Iteration number: [2050/4518] 45% | Training loss: 0.6870349765405422
Epoch: 82 | Iteration number: [2060/4518] 45% | Training loss: 0.687034287238584
Epoch: 82 | Iteration number: [2070/4518] 45% | Training loss: 0.6870333219783894
Epoch: 82 | Iteration number: [2080/4518] 46% | Training loss: 0.6870340022903222
Epoch: 82 | Iteration number: [2090/4518] 46% | Training loss: 0.687034554658324
Epoch: 82 | Iteration number: [2100/4518] 46% | Training loss: 0.6870379168079013
Epoch: 82 | Iteration number: [2110/4518] 46% | Training loss: 0.6870354078957255
Epoch: 82 | Iteration number: [2120/4518] 46% | Training loss: 0.6870303828198955
Epoch: 82 | Iteration number: [2130/4518] 47% | Training loss: 0.6870250039537188
Epoch: 82 | Iteration number: [2140/4518] 47% | Training loss: 0.6870283405078905
Epoch: 82 | Iteration number: [2150/4518] 47% | Training loss: 0.6870278077901796
Epoch: 82 | Iteration number: [2160/4518] 47% | Training loss: 0.6870257786302655
Epoch: 82 | Iteration number: [2170/4518] 48% | Training loss: 0.6870178821449455
Epoch: 82 | Iteration number: [2180/4518] 48% | Training loss: 0.6870179730817813
Epoch: 82 | Iteration number: [2190/4518] 48% | Training loss: 0.6870204479454859
Epoch: 82 | Iteration number: [2200/4518] 48% | Training loss: 0.6870141149921851
Epoch: 82 | Iteration number: [2210/4518] 48% | Training loss: 0.6870176096038042
Epoch: 82 | Iteration number: [2220/4518] 49% | Training loss: 0.6870204961246198
Epoch: 82 | Iteration number: [2230/4518] 49% | Training loss: 0.6870208735957809
Epoch: 82 | Iteration number: [2240/4518] 49% | Training loss: 0.6870248617072191
Epoch: 82 | Iteration number: [2250/4518] 49% | Training loss: 0.6870245380136701
Epoch: 82 | Iteration number: [2260/4518] 50% | Training loss: 0.6870262613602444
Epoch: 82 | Iteration number: [2270/4518] 50% | Training loss: 0.6870247860311937
Epoch: 82 | Iteration number: [2280/4518] 50% | Training loss: 0.6870202754934629
Epoch: 82 | Iteration number: [2290/4518] 50% | Training loss: 0.6870171491495907
Epoch: 82 | Iteration number: [2300/4518] 50% | Training loss: 0.687013497326685
Epoch: 82 | Iteration number: [2310/4518] 51% | Training loss: 0.6870127794804511
Epoch: 82 | Iteration number: [2320/4518] 51% | Training loss: 0.6870104864496609
Epoch: 82 | Iteration number: [2330/4518] 51% | Training loss: 0.687011419805846
Epoch: 82 | Iteration number: [2340/4518] 51% | Training loss: 0.6870095958567073
Epoch: 82 | Iteration number: [2350/4518] 52% | Training loss: 0.6870082604124191
Epoch: 82 | Iteration number: [2360/4518] 52% | Training loss: 0.6870084583759308
Epoch: 82 | Iteration number: [2370/4518] 52% | Training loss: 0.6870108013917625
Epoch: 82 | Iteration number: [2380/4518] 52% | Training loss: 0.6870073083318582
Epoch: 82 | Iteration number: [2390/4518] 52% | Training loss: 0.6870090446711584
Epoch: 82 | Iteration number: [2400/4518] 53% | Training loss: 0.6870054788887501
Epoch: 82 | Iteration number: [2410/4518] 53% | Training loss: 0.6870052225362215
Epoch: 82 | Iteration number: [2420/4518] 53% | Training loss: 0.6869996293270884
Epoch: 82 | Iteration number: [2430/4518] 53% | Training loss: 0.6869964011412099
Epoch: 82 | Iteration number: [2440/4518] 54% | Training loss: 0.6869969243153197
Epoch: 82 | Iteration number: [2450/4518] 54% | Training loss: 0.6869996626279792
Epoch: 82 | Iteration number: [2460/4518] 54% | Training loss: 0.6870000461979611
Epoch: 82 | Iteration number: [2470/4518] 54% | Training loss: 0.6869963922963934
Epoch: 82 | Iteration number: [2480/4518] 54% | Training loss: 0.6869984982475158
Epoch: 82 | Iteration number: [2490/4518] 55% | Training loss: 0.6869969176480091
Epoch: 82 | Iteration number: [2500/4518] 55% | Training loss: 0.6869951184272766
Epoch: 82 | Iteration number: [2510/4518] 55% | Training loss: 0.6869935062776998
Epoch: 82 | Iteration number: [2520/4518] 55% | Training loss: 0.6869976729627639
Epoch: 82 | Iteration number: [2530/4518] 55% | Training loss: 0.6869934301366919
Epoch: 82 | Iteration number: [2540/4518] 56% | Training loss: 0.6869942048637886
Epoch: 82 | Iteration number: [2550/4518] 56% | Training loss: 0.6869933668538636
Epoch: 82 | Iteration number: [2560/4518] 56% | Training loss: 0.6869921812787652
Epoch: 82 | Iteration number: [2570/4518] 56% | Training loss: 0.6869935990307582
Epoch: 82 | Iteration number: [2580/4518] 57% | Training loss: 0.6869970987240474
Epoch: 82 | Iteration number: [2590/4518] 57% | Training loss: 0.6870010098205109
Epoch: 82 | Iteration number: [2600/4518] 57% | Training loss: 0.6869923023535656
Epoch: 82 | Iteration number: [2610/4518] 57% | Training loss: 0.6869902243787758
Epoch: 82 | Iteration number: [2620/4518] 57% | Training loss: 0.6869894189688995
Epoch: 82 | Iteration number: [2630/4518] 58% | Training loss: 0.6869910695027036
Epoch: 82 | Iteration number: [2640/4518] 58% | Training loss: 0.6869910169957262
Epoch: 82 | Iteration number: [2650/4518] 58% | Training loss: 0.6869910875806269
Epoch: 82 | Iteration number: [2660/4518] 58% | Training loss: 0.6869961174134921
Epoch: 82 | Iteration number: [2670/4518] 59% | Training loss: 0.6869946782062116
Epoch: 82 | Iteration number: [2680/4518] 59% | Training loss: 0.6869913247983848
Epoch: 82 | Iteration number: [2690/4518] 59% | Training loss: 0.6869930141920494
Epoch: 82 | Iteration number: [2700/4518] 59% | Training loss: 0.686991438291691
Epoch: 82 | Iteration number: [2710/4518] 59% | Training loss: 0.6869900084949507
Epoch: 82 | Iteration number: [2720/4518] 60% | Training loss: 0.6869924987721092
Epoch: 82 | Iteration number: [2730/4518] 60% | Training loss: 0.6869913657506307
Epoch: 82 | Iteration number: [2740/4518] 60% | Training loss: 0.6869895096025328
Epoch: 82 | Iteration number: [2750/4518] 60% | Training loss: 0.686989003723318
Epoch: 82 | Iteration number: [2760/4518] 61% | Training loss: 0.6869923627462939
Epoch: 82 | Iteration number: [2770/4518] 61% | Training loss: 0.6869935364069061
Epoch: 82 | Iteration number: [2780/4518] 61% | Training loss: 0.6869935807135465
Epoch: 82 | Iteration number: [2790/4518] 61% | Training loss: 0.6869951814092615
Epoch: 82 | Iteration number: [2800/4518] 61% | Training loss: 0.6869962142407894
Epoch: 82 | Iteration number: [2810/4518] 62% | Training loss: 0.6869991887930873
Epoch: 82 | Iteration number: [2820/4518] 62% | Training loss: 0.6870010346596969
Epoch: 82 | Iteration number: [2830/4518] 62% | Training loss: 0.6869979355444756
Epoch: 82 | Iteration number: [2840/4518] 62% | Training loss: 0.6869966684092939
Epoch: 82 | Iteration number: [2850/4518] 63% | Training loss: 0.6869959853615677
Epoch: 82 | Iteration number: [2860/4518] 63% | Training loss: 0.6869965034556555
Epoch: 82 | Iteration number: [2870/4518] 63% | Training loss: 0.6869937975647558
Epoch: 82 | Iteration number: [2880/4518] 63% | Training loss: 0.686996261196004
Epoch: 82 | Iteration number: [2890/4518] 63% | Training loss: 0.6869959198892323
Epoch: 82 | Iteration number: [2900/4518] 64% | Training loss: 0.6869973097587454
Epoch: 82 | Iteration number: [2910/4518] 64% | Training loss: 0.6869971724924763
Epoch: 82 | Iteration number: [2920/4518] 64% | Training loss: 0.6869955579916092
Epoch: 82 | Iteration number: [2930/4518] 64% | Training loss: 0.6869943830747246
Epoch: 82 | Iteration number: [2940/4518] 65% | Training loss: 0.6869939587351416
Epoch: 82 | Iteration number: [2950/4518] 65% | Training loss: 0.686995123948081
Epoch: 82 | Iteration number: [2960/4518] 65% | Training loss: 0.6869889011455549
Epoch: 82 | Iteration number: [2970/4518] 65% | Training loss: 0.6869868456915974
Epoch: 82 | Iteration number: [2980/4518] 65% | Training loss: 0.6869834431265824
Epoch: 82 | Iteration number: [2990/4518] 66% | Training loss: 0.6869854686650942
Epoch: 82 | Iteration number: [3000/4518] 66% | Training loss: 0.6869861092964809
Epoch: 82 | Iteration number: [3010/4518] 66% | Training loss: 0.6869892179371907
Epoch: 82 | Iteration number: [3020/4518] 66% | Training loss: 0.6869895411248239
Epoch: 82 | Iteration number: [3030/4518] 67% | Training loss: 0.6869849514646499
Epoch: 82 | Iteration number: [3040/4518] 67% | Training loss: 0.686985913526855
Epoch: 82 | Iteration number: [3050/4518] 67% | Training loss: 0.6869836841841213
Epoch: 82 | Iteration number: [3060/4518] 67% | Training loss: 0.6869839701777191
Epoch: 82 | Iteration number: [3070/4518] 67% | Training loss: 0.6869823921386893
Epoch: 82 | Iteration number: [3080/4518] 68% | Training loss: 0.68697997643189
Epoch: 82 | Iteration number: [3090/4518] 68% | Training loss: 0.6869800591353074
Epoch: 82 | Iteration number: [3100/4518] 68% | Training loss: 0.6869793461791931
Epoch: 82 | Iteration number: [3110/4518] 68% | Training loss: 0.6869792537673877
Epoch: 82 | Iteration number: [3120/4518] 69% | Training loss: 0.6869772764543692
Epoch: 82 | Iteration number: [3130/4518] 69% | Training loss: 0.6869729357405593
Epoch: 82 | Iteration number: [3140/4518] 69% | Training loss: 0.686969880503454
Epoch: 82 | Iteration number: [3150/4518] 69% | Training loss: 0.6869645929904211
Epoch: 82 | Iteration number: [3160/4518] 69% | Training loss: 0.6869649125994006
Epoch: 82 | Iteration number: [3170/4518] 70% | Training loss: 0.686966919748565
Epoch: 82 | Iteration number: [3180/4518] 70% | Training loss: 0.686967730840797
Epoch: 82 | Iteration number: [3190/4518] 70% | Training loss: 0.68696988073636
Epoch: 82 | Iteration number: [3200/4518] 70% | Training loss: 0.6869691496156156
Epoch: 82 | Iteration number: [3210/4518] 71% | Training loss: 0.6869687567433093
Epoch: 82 | Iteration number: [3220/4518] 71% | Training loss: 0.6869675222576035
Epoch: 82 | Iteration number: [3230/4518] 71% | Training loss: 0.6869670129228302
Epoch: 82 | Iteration number: [3240/4518] 71% | Training loss: 0.6869664895681687
Epoch: 82 | Iteration number: [3250/4518] 71% | Training loss: 0.6869649676176218
Epoch: 82 | Iteration number: [3260/4518] 72% | Training loss: 0.6869618471780438
Epoch: 82 | Iteration number: [3270/4518] 72% | Training loss: 0.6869610898173912
Epoch: 82 | Iteration number: [3280/4518] 72% | Training loss: 0.6869613907140929
Epoch: 82 | Iteration number: [3290/4518] 72% | Training loss: 0.686958288784085
Epoch: 82 | Iteration number: [3300/4518] 73% | Training loss: 0.6869606121200503
Epoch: 82 | Iteration number: [3310/4518] 73% | Training loss: 0.6869574298491291
Epoch: 82 | Iteration number: [3320/4518] 73% | Training loss: 0.6869574271950377
Epoch: 82 | Iteration number: [3330/4518] 73% | Training loss: 0.6869565342281674
Epoch: 82 | Iteration number: [3340/4518] 73% | Training loss: 0.6869583728427658
Epoch: 82 | Iteration number: [3350/4518] 74% | Training loss: 0.6869555360523623
Epoch: 82 | Iteration number: [3360/4518] 74% | Training loss: 0.6869533316897495
Epoch: 82 | Iteration number: [3370/4518] 74% | Training loss: 0.6869501484784599
Epoch: 82 | Iteration number: [3380/4518] 74% | Training loss: 0.6869469490806026
Epoch: 82 | Iteration number: [3390/4518] 75% | Training loss: 0.6869479260789257
Epoch: 82 | Iteration number: [3400/4518] 75% | Training loss: 0.686949072147117
Epoch: 82 | Iteration number: [3410/4518] 75% | Training loss: 0.6869485771201573
Epoch: 82 | Iteration number: [3420/4518] 75% | Training loss: 0.6869484349998117
Epoch: 82 | Iteration number: [3430/4518] 75% | Training loss: 0.6869483807517905
Epoch: 82 | Iteration number: [3440/4518] 76% | Training loss: 0.6869480178453201
Epoch: 82 | Iteration number: [3450/4518] 76% | Training loss: 0.6869474680700164
Epoch: 82 | Iteration number: [3460/4518] 76% | Training loss: 0.6869478741133144
Epoch: 82 | Iteration number: [3470/4518] 76% | Training loss: 0.6869435959659324
Epoch: 82 | Iteration number: [3480/4518] 77% | Training loss: 0.6869461642770932
Epoch: 82 | Iteration number: [3490/4518] 77% | Training loss: 0.6869445030361329
Epoch: 82 | Iteration number: [3500/4518] 77% | Training loss: 0.6869455029283251
Epoch: 82 | Iteration number: [3510/4518] 77% | Training loss: 0.6869487909679739
Epoch: 82 | Iteration number: [3520/4518] 77% | Training loss: 0.6869429462165995
Epoch: 82 | Iteration number: [3530/4518] 78% | Training loss: 0.6869388957199226
Epoch: 82 | Iteration number: [3540/4518] 78% | Training loss: 0.6869404320831353
Epoch: 82 | Iteration number: [3550/4518] 78% | Training loss: 0.6869389926379835
Epoch: 82 | Iteration number: [3560/4518] 78% | Training loss: 0.686939442894432
Epoch: 82 | Iteration number: [3570/4518] 79% | Training loss: 0.6869382354224763
Epoch: 82 | Iteration number: [3580/4518] 79% | Training loss: 0.6869375058226079
Epoch: 82 | Iteration number: [3590/4518] 79% | Training loss: 0.6869345027922256
Epoch: 82 | Iteration number: [3600/4518] 79% | Training loss: 0.6869342644347085
Epoch: 82 | Iteration number: [3610/4518] 79% | Training loss: 0.6869361612109927
Epoch: 82 | Iteration number: [3620/4518] 80% | Training loss: 0.6869314072375798
Epoch: 82 | Iteration number: [3630/4518] 80% | Training loss: 0.6869301184149813
Epoch: 82 | Iteration number: [3640/4518] 80% | Training loss: 0.6869319425179408
Epoch: 82 | Iteration number: [3650/4518] 80% | Training loss: 0.6869308186720495
Epoch: 82 | Iteration number: [3660/4518] 81% | Training loss: 0.6869288942690104
Epoch: 82 | Iteration number: [3670/4518] 81% | Training loss: 0.686928551057379
Epoch: 82 | Iteration number: [3680/4518] 81% | Training loss: 0.6869309783953688
Epoch: 82 | Iteration number: [3690/4518] 81% | Training loss: 0.6869316768517016
Epoch: 82 | Iteration number: [3700/4518] 81% | Training loss: 0.6869310102269456
Epoch: 82 | Iteration number: [3710/4518] 82% | Training loss: 0.6869290149436806
Epoch: 82 | Iteration number: [3720/4518] 82% | Training loss: 0.6869265112825619
Epoch: 82 | Iteration number: [3730/4518] 82% | Training loss: 0.6869252156955626
Epoch: 82 | Iteration number: [3740/4518] 82% | Training loss: 0.6869266036519392
Epoch: 82 | Iteration number: [3750/4518] 83% | Training loss: 0.6869265711784363
Epoch: 82 | Iteration number: [3760/4518] 83% | Training loss: 0.6869272940970482
Epoch: 82 | Iteration number: [3770/4518] 83% | Training loss: 0.6869252052642306
Epoch: 82 | Iteration number: [3780/4518] 83% | Training loss: 0.6869234689329037
Epoch: 82 | Iteration number: [3790/4518] 83% | Training loss: 0.6869235356910877
Epoch: 82 | Iteration number: [3800/4518] 84% | Training loss: 0.6869258053208652
Epoch: 82 | Iteration number: [3810/4518] 84% | Training loss: 0.6869253750861161
Epoch: 82 | Iteration number: [3820/4518] 84% | Training loss: 0.6869276211835951
Epoch: 82 | Iteration number: [3830/4518] 84% | Training loss: 0.6869285303992329
Epoch: 82 | Iteration number: [3840/4518] 84% | Training loss: 0.6869277280134459
Epoch: 82 | Iteration number: [3850/4518] 85% | Training loss: 0.6869228392916841
Epoch: 82 | Iteration number: [3860/4518] 85% | Training loss: 0.6869230459854393
Epoch: 82 | Iteration number: [3870/4518] 85% | Training loss: 0.6869231023991755
Epoch: 82 | Iteration number: [3880/4518] 85% | Training loss: 0.6869208821623596
Epoch: 82 | Iteration number: [3890/4518] 86% | Training loss: 0.6869210026564512
Epoch: 82 | Iteration number: [3900/4518] 86% | Training loss: 0.6869217857030722
Epoch: 82 | Iteration number: [3910/4518] 86% | Training loss: 0.6869220392325955
Epoch: 82 | Iteration number: [3920/4518] 86% | Training loss: 0.6869215936533042
Epoch: 82 | Iteration number: [3930/4518] 86% | Training loss: 0.6869217666354192
Epoch: 82 | Iteration number: [3940/4518] 87% | Training loss: 0.6869230886855101
Epoch: 82 | Iteration number: [3950/4518] 87% | Training loss: 0.6869243317767034
Epoch: 82 | Iteration number: [3960/4518] 87% | Training loss: 0.6869252487264498
Epoch: 82 | Iteration number: [3970/4518] 87% | Training loss: 0.686927949916806
Epoch: 82 | Iteration number: [3980/4518] 88% | Training loss: 0.6869267289063439
Epoch: 82 | Iteration number: [3990/4518] 88% | Training loss: 0.6869245679605575
Epoch: 82 | Iteration number: [4000/4518] 88% | Training loss: 0.686920902788639
Epoch: 82 | Iteration number: [4010/4518] 88% | Training loss: 0.6869217938318514
Epoch: 82 | Iteration number: [4020/4518] 88% | Training loss: 0.6869198137699668
Epoch: 82 | Iteration number: [4030/4518] 89% | Training loss: 0.6869189306465036
Epoch: 82 | Iteration number: [4040/4518] 89% | Training loss: 0.6869150544894804
Epoch: 82 | Iteration number: [4050/4518] 89% | Training loss: 0.6869155054475055
Epoch: 82 | Iteration number: [4060/4518] 89% | Training loss: 0.6869147918494464
Epoch: 82 | Iteration number: [4070/4518] 90% | Training loss: 0.6869160402319062
Epoch: 82 | Iteration number: [4080/4518] 90% | Training loss: 0.6869172212978204
Epoch: 82 | Iteration number: [4090/4518] 90% | Training loss: 0.6869192499548998
Epoch: 82 | Iteration number: [4100/4518] 90% | Training loss: 0.6869194318463163
Epoch: 82 | Iteration number: [4110/4518] 90% | Training loss: 0.6869195092333494
Epoch: 82 | Iteration number: [4120/4518] 91% | Training loss: 0.686921181840804
Epoch: 82 | Iteration number: [4130/4518] 91% | Training loss: 0.6869234469987578
Epoch: 82 | Iteration number: [4140/4518] 91% | Training loss: 0.6869245691719839
Epoch: 82 | Iteration number: [4150/4518] 91% | Training loss: 0.6869232583189585
Epoch: 82 | Iteration number: [4160/4518] 92% | Training loss: 0.6869223023406588
Epoch: 82 | Iteration number: [4170/4518] 92% | Training loss: 0.6869194815913551
Epoch: 82 | Iteration number: [4180/4518] 92% | Training loss: 0.6869226489340859
Epoch: 82 | Iteration number: [4190/4518] 92% | Training loss: 0.6869205806022043
Epoch: 82 | Iteration number: [4200/4518] 92% | Training loss: 0.6869182659046991
Epoch: 82 | Iteration number: [4210/4518] 93% | Training loss: 0.6869157935547998
Epoch: 82 | Iteration number: [4220/4518] 93% | Training loss: 0.6869167463333121
Epoch: 82 | Iteration number: [4230/4518] 93% | Training loss: 0.6869202298475495
Epoch: 82 | Iteration number: [4240/4518] 93% | Training loss: 0.6869192452222671
Epoch: 82 | Iteration number: [4250/4518] 94% | Training loss: 0.6869182223572451
Epoch: 82 | Iteration number: [4260/4518] 94% | Training loss: 0.6869172316201976
Epoch: 82 | Iteration number: [4270/4518] 94% | Training loss: 0.6869175549692516
Epoch: 82 | Iteration number: [4280/4518] 94% | Training loss: 0.6869180771234994
Epoch: 82 | Iteration number: [4290/4518] 94% | Training loss: 0.6869189719914834
Epoch: 82 | Iteration number: [4300/4518] 95% | Training loss: 0.6869188798444216
Epoch: 82 | Iteration number: [4310/4518] 95% | Training loss: 0.6869158720472296
Epoch: 82 | Iteration number: [4320/4518] 95% | Training loss: 0.6869140233430597
Epoch: 82 | Iteration number: [4330/4518] 95% | Training loss: 0.6869139471037559
Epoch: 82 | Iteration number: [4340/4518] 96% | Training loss: 0.6869127092960243
Epoch: 82 | Iteration number: [4350/4518] 96% | Training loss: 0.6869124772493866
Epoch: 82 | Iteration number: [4360/4518] 96% | Training loss: 0.6869113331404301
Epoch: 82 | Iteration number: [4370/4518] 96% | Training loss: 0.6869107426167625
Epoch: 82 | Iteration number: [4380/4518] 96% | Training loss: 0.6869127260359454
Epoch: 82 | Iteration number: [4390/4518] 97% | Training loss: 0.6869126026342561
Epoch: 82 | Iteration number: [4400/4518] 97% | Training loss: 0.6869122409549626
Epoch: 82 | Iteration number: [4410/4518] 97% | Training loss: 0.6869123976787472
Epoch: 82 | Iteration number: [4420/4518] 97% | Training loss: 0.6869115169905969
Epoch: 82 | Iteration number: [4430/4518] 98% | Training loss: 0.6869119827015405
Epoch: 82 | Iteration number: [4440/4518] 98% | Training loss: 0.686911556205234
Epoch: 82 | Iteration number: [4450/4518] 98% | Training loss: 0.6869088380792168
Epoch: 82 | Iteration number: [4460/4518] 98% | Training loss: 0.6869093303322258
Epoch: 82 | Iteration number: [4470/4518] 98% | Training loss: 0.6869095209994306
Epoch: 82 | Iteration number: [4480/4518] 99% | Training loss: 0.6869097756487983
Epoch: 82 | Iteration number: [4490/4518] 99% | Training loss: 0.6869086206224819
Epoch: 82 | Iteration number: [4500/4518] 99% | Training loss: 0.6869100216362212
Epoch: 82 | Iteration number: [4510/4518] 99% | Training loss: 0.6869094218488807

 End of epoch: 82 | Train Loss: 0.6867578580164181 | Training Time: 633 

 End of epoch: 82 | Eval Loss: 0.6895951932790328 | Evaluating Time: 17 
Epoch: 83 | Iteration number: [10/4518] 0% | Training loss: 0.7551701903343201
Epoch: 83 | Iteration number: [20/4518] 0% | Training loss: 0.7210764855146408
Epoch: 83 | Iteration number: [30/4518] 0% | Training loss: 0.7094136198361715
Epoch: 83 | Iteration number: [40/4518] 0% | Training loss: 0.7037940844893456
Epoch: 83 | Iteration number: [50/4518] 1% | Training loss: 0.7005142021179199
Epoch: 83 | Iteration number: [60/4518] 1% | Training loss: 0.6983807822068532
Epoch: 83 | Iteration number: [70/4518] 1% | Training loss: 0.6967316048485892
Epoch: 83 | Iteration number: [80/4518] 1% | Training loss: 0.6952924698591232
Epoch: 83 | Iteration number: [90/4518] 1% | Training loss: 0.6942756467395359
Epoch: 83 | Iteration number: [100/4518] 2% | Training loss: 0.6935645121335984
Epoch: 83 | Iteration number: [110/4518] 2% | Training loss: 0.6929334217851812
Epoch: 83 | Iteration number: [120/4518] 2% | Training loss: 0.6924873908360799
Epoch: 83 | Iteration number: [130/4518] 2% | Training loss: 0.691994827068769
Epoch: 83 | Iteration number: [140/4518] 3% | Training loss: 0.6916148338999067
Epoch: 83 | Iteration number: [150/4518] 3% | Training loss: 0.6912951421737671
Epoch: 83 | Iteration number: [160/4518] 3% | Training loss: 0.691009359434247
Epoch: 83 | Iteration number: [170/4518] 3% | Training loss: 0.6908221255330479
Epoch: 83 | Iteration number: [180/4518] 3% | Training loss: 0.6906318472491371
Epoch: 83 | Iteration number: [190/4518] 4% | Training loss: 0.6904490618329299
Epoch: 83 | Iteration number: [200/4518] 4% | Training loss: 0.6902632650732994
Epoch: 83 | Iteration number: [210/4518] 4% | Training loss: 0.690103352637518
Epoch: 83 | Iteration number: [220/4518] 4% | Training loss: 0.6899170287630775
Epoch: 83 | Iteration number: [230/4518] 5% | Training loss: 0.6897474371868632
Epoch: 83 | Iteration number: [240/4518] 5% | Training loss: 0.6896691689888637
Epoch: 83 | Iteration number: [250/4518] 5% | Training loss: 0.6896063106060029
Epoch: 83 | Iteration number: [260/4518] 5% | Training loss: 0.6894732090143058
Epoch: 83 | Iteration number: [270/4518] 5% | Training loss: 0.6893984063907906
Epoch: 83 | Iteration number: [280/4518] 6% | Training loss: 0.6893353193998337
Epoch: 83 | Iteration number: [290/4518] 6% | Training loss: 0.6892872497953217
Epoch: 83 | Iteration number: [300/4518] 6% | Training loss: 0.6891779228051503
Epoch: 83 | Iteration number: [310/4518] 6% | Training loss: 0.68908869316501
Epoch: 83 | Iteration number: [320/4518] 7% | Training loss: 0.688970353640616
Epoch: 83 | Iteration number: [330/4518] 7% | Training loss: 0.688935212655501
Epoch: 83 | Iteration number: [340/4518] 7% | Training loss: 0.6888782673022327
Epoch: 83 | Iteration number: [350/4518] 7% | Training loss: 0.6888209567751203
Epoch: 83 | Iteration number: [360/4518] 7% | Training loss: 0.6887685941325293
Epoch: 83 | Iteration number: [370/4518] 8% | Training loss: 0.6886887806492883
Epoch: 83 | Iteration number: [380/4518] 8% | Training loss: 0.6886549237527345
Epoch: 83 | Iteration number: [390/4518] 8% | Training loss: 0.6886052674207932
Epoch: 83 | Iteration number: [400/4518] 8% | Training loss: 0.6885476122796536
Epoch: 83 | Iteration number: [410/4518] 9% | Training loss: 0.6885023442710319
Epoch: 83 | Iteration number: [420/4518] 9% | Training loss: 0.6884804247390657
Epoch: 83 | Iteration number: [430/4518] 9% | Training loss: 0.6884259092253308
Epoch: 83 | Iteration number: [440/4518] 9% | Training loss: 0.688365750150247
Epoch: 83 | Iteration number: [450/4518] 9% | Training loss: 0.6883169906669193
Epoch: 83 | Iteration number: [460/4518] 10% | Training loss: 0.6882913785136264
Epoch: 83 | Iteration number: [470/4518] 10% | Training loss: 0.6882126820848343
Epoch: 83 | Iteration number: [480/4518] 10% | Training loss: 0.688177028670907
Epoch: 83 | Iteration number: [490/4518] 10% | Training loss: 0.6881242837224688
Epoch: 83 | Iteration number: [500/4518] 11% | Training loss: 0.6880659363269805
Epoch: 83 | Iteration number: [510/4518] 11% | Training loss: 0.6880386318646226
Epoch: 83 | Iteration number: [520/4518] 11% | Training loss: 0.6880167687168488
Epoch: 83 | Iteration number: [530/4518] 11% | Training loss: 0.6880050400518022
Epoch: 83 | Iteration number: [540/4518] 11% | Training loss: 0.6879683742920558
Epoch: 83 | Iteration number: [550/4518] 12% | Training loss: 0.6879508998177268
Epoch: 83 | Iteration number: [560/4518] 12% | Training loss: 0.6879163988998958
Epoch: 83 | Iteration number: [570/4518] 12% | Training loss: 0.6878982788638065
Epoch: 83 | Iteration number: [580/4518] 12% | Training loss: 0.6878491053293492
Epoch: 83 | Iteration number: [590/4518] 13% | Training loss: 0.6878287664914535
Epoch: 83 | Iteration number: [600/4518] 13% | Training loss: 0.6878103625774383
Epoch: 83 | Iteration number: [610/4518] 13% | Training loss: 0.6877940950823612
Epoch: 83 | Iteration number: [620/4518] 13% | Training loss: 0.6877622824522757
Epoch: 83 | Iteration number: [630/4518] 13% | Training loss: 0.6877416910633208
Epoch: 83 | Iteration number: [640/4518] 14% | Training loss: 0.6877215076237917
Epoch: 83 | Iteration number: [650/4518] 14% | Training loss: 0.6876923779340891
Epoch: 83 | Iteration number: [660/4518] 14% | Training loss: 0.6876915761918733
Epoch: 83 | Iteration number: [670/4518] 14% | Training loss: 0.6876722631169789
Epoch: 83 | Iteration number: [680/4518] 15% | Training loss: 0.6876475831165033
Epoch: 83 | Iteration number: [690/4518] 15% | Training loss: 0.6876418040282485
Epoch: 83 | Iteration number: [700/4518] 15% | Training loss: 0.6876224935906274
Epoch: 83 | Iteration number: [710/4518] 15% | Training loss: 0.6876228104174976
Epoch: 83 | Iteration number: [720/4518] 15% | Training loss: 0.6876190842853652
Epoch: 83 | Iteration number: [730/4518] 16% | Training loss: 0.6876135955118153
Epoch: 83 | Iteration number: [740/4518] 16% | Training loss: 0.6875689523445593
Epoch: 83 | Iteration number: [750/4518] 16% | Training loss: 0.6875641603469849
Epoch: 83 | Iteration number: [760/4518] 16% | Training loss: 0.6875679596474297
Epoch: 83 | Iteration number: [770/4518] 17% | Training loss: 0.6875577251632492
Epoch: 83 | Iteration number: [780/4518] 17% | Training loss: 0.6875356753667196
Epoch: 83 | Iteration number: [790/4518] 17% | Training loss: 0.6875231195099746
Epoch: 83 | Iteration number: [800/4518] 17% | Training loss: 0.6875050687044859
Epoch: 83 | Iteration number: [810/4518] 17% | Training loss: 0.6875089211228453
Epoch: 83 | Iteration number: [820/4518] 18% | Training loss: 0.687503298099448
Epoch: 83 | Iteration number: [830/4518] 18% | Training loss: 0.6874946127454918
Epoch: 83 | Iteration number: [840/4518] 18% | Training loss: 0.6874904912852106
Epoch: 83 | Iteration number: [850/4518] 18% | Training loss: 0.6874842596054077
Epoch: 83 | Iteration number: [860/4518] 19% | Training loss: 0.6874709260325099
Epoch: 83 | Iteration number: [870/4518] 19% | Training loss: 0.6874679516101706
Epoch: 83 | Iteration number: [880/4518] 19% | Training loss: 0.687448664619164
Epoch: 83 | Iteration number: [890/4518] 19% | Training loss: 0.6874510752351096
Epoch: 83 | Iteration number: [900/4518] 19% | Training loss: 0.6874554750654432
Epoch: 83 | Iteration number: [910/4518] 20% | Training loss: 0.6874444161797618
Epoch: 83 | Iteration number: [920/4518] 20% | Training loss: 0.6874436190594797
Epoch: 83 | Iteration number: [930/4518] 20% | Training loss: 0.6874369659731465
Epoch: 83 | Iteration number: [940/4518] 20% | Training loss: 0.6874318339723222
Epoch: 83 | Iteration number: [950/4518] 21% | Training loss: 0.6874234743494737
Epoch: 83 | Iteration number: [960/4518] 21% | Training loss: 0.6874200914055109
Epoch: 83 | Iteration number: [970/4518] 21% | Training loss: 0.6874135663828899
Epoch: 83 | Iteration number: [980/4518] 21% | Training loss: 0.6874077501953865
Epoch: 83 | Iteration number: [990/4518] 21% | Training loss: 0.6873993079469661
Epoch: 83 | Iteration number: [1000/4518] 22% | Training loss: 0.6873843212723731
Epoch: 83 | Iteration number: [1010/4518] 22% | Training loss: 0.6873852011590901
Epoch: 83 | Iteration number: [1020/4518] 22% | Training loss: 0.6873779561005386
Epoch: 83 | Iteration number: [1030/4518] 22% | Training loss: 0.6873702361167056
Epoch: 83 | Iteration number: [1040/4518] 23% | Training loss: 0.6873625978827477
Epoch: 83 | Iteration number: [1050/4518] 23% | Training loss: 0.6873569293816885
Epoch: 83 | Iteration number: [1060/4518] 23% | Training loss: 0.687349343243635
Epoch: 83 | Iteration number: [1070/4518] 23% | Training loss: 0.6873414981588025
Epoch: 83 | Iteration number: [1080/4518] 23% | Training loss: 0.6873341573057351
Epoch: 83 | Iteration number: [1090/4518] 24% | Training loss: 0.6873286836737886
Epoch: 83 | Iteration number: [1100/4518] 24% | Training loss: 0.6873210706494072
Epoch: 83 | Iteration number: [1110/4518] 24% | Training loss: 0.6873164723585318
Epoch: 83 | Iteration number: [1120/4518] 24% | Training loss: 0.6873070961662702
Epoch: 83 | Iteration number: [1130/4518] 25% | Training loss: 0.6873094837749953
Epoch: 83 | Iteration number: [1140/4518] 25% | Training loss: 0.68729725516679
Epoch: 83 | Iteration number: [1150/4518] 25% | Training loss: 0.6872969864762347
Epoch: 83 | Iteration number: [1160/4518] 25% | Training loss: 0.687302641878868
Epoch: 83 | Iteration number: [1170/4518] 25% | Training loss: 0.6872978944554288
Epoch: 83 | Iteration number: [1180/4518] 26% | Training loss: 0.6872872440996817
Epoch: 83 | Iteration number: [1190/4518] 26% | Training loss: 0.6872756004333496
Epoch: 83 | Iteration number: [1200/4518] 26% | Training loss: 0.6872824666400751
Epoch: 83 | Iteration number: [1210/4518] 26% | Training loss: 0.6872636173382278
Epoch: 83 | Iteration number: [1220/4518] 27% | Training loss: 0.6872615879676381
Epoch: 83 | Iteration number: [1230/4518] 27% | Training loss: 0.6872654503438531
Epoch: 83 | Iteration number: [1240/4518] 27% | Training loss: 0.6872635556324835
Epoch: 83 | Iteration number: [1250/4518] 27% | Training loss: 0.6872568887710572
Epoch: 83 | Iteration number: [1260/4518] 27% | Training loss: 0.6872546397977405
Epoch: 83 | Iteration number: [1270/4518] 28% | Training loss: 0.6872409889078516
Epoch: 83 | Iteration number: [1280/4518] 28% | Training loss: 0.6872360828332603
Epoch: 83 | Iteration number: [1290/4518] 28% | Training loss: 0.6872254677983217
Epoch: 83 | Iteration number: [1300/4518] 28% | Training loss: 0.6872285774120918
Epoch: 83 | Iteration number: [1310/4518] 28% | Training loss: 0.6872158428639856
Epoch: 83 | Iteration number: [1320/4518] 29% | Training loss: 0.6872174946647702
Epoch: 83 | Iteration number: [1330/4518] 29% | Training loss: 0.6872189817571999
Epoch: 83 | Iteration number: [1340/4518] 29% | Training loss: 0.687214283311545
Epoch: 83 | Iteration number: [1350/4518] 29% | Training loss: 0.6872042333638226
Epoch: 83 | Iteration number: [1360/4518] 30% | Training loss: 0.6872039435102659
Epoch: 83 | Iteration number: [1370/4518] 30% | Training loss: 0.687202599187837
Epoch: 83 | Iteration number: [1380/4518] 30% | Training loss: 0.6871967377006144
Epoch: 83 | Iteration number: [1390/4518] 30% | Training loss: 0.6871971620072563
Epoch: 83 | Iteration number: [1400/4518] 30% | Training loss: 0.6871954281841005
Epoch: 83 | Iteration number: [1410/4518] 31% | Training loss: 0.687195132049263
Epoch: 83 | Iteration number: [1420/4518] 31% | Training loss: 0.6872004564799054
Epoch: 83 | Iteration number: [1430/4518] 31% | Training loss: 0.6871938445768156
Epoch: 83 | Iteration number: [1440/4518] 31% | Training loss: 0.6871953633510404
Epoch: 83 | Iteration number: [1450/4518] 32% | Training loss: 0.6871970800284681
Epoch: 83 | Iteration number: [1460/4518] 32% | Training loss: 0.687184270563191
Epoch: 83 | Iteration number: [1470/4518] 32% | Training loss: 0.6871808613644165
Epoch: 83 | Iteration number: [1480/4518] 32% | Training loss: 0.6871777846201046
Epoch: 83 | Iteration number: [1490/4518] 32% | Training loss: 0.6871766612833778
Epoch: 83 | Iteration number: [1500/4518] 33% | Training loss: 0.6871786437431971
Epoch: 83 | Iteration number: [1510/4518] 33% | Training loss: 0.687180312185098
Epoch: 83 | Iteration number: [1520/4518] 33% | Training loss: 0.6871758295517219
Epoch: 83 | Iteration number: [1530/4518] 33% | Training loss: 0.687174687315436
Epoch: 83 | Iteration number: [1540/4518] 34% | Training loss: 0.6871818390759554
Epoch: 83 | Iteration number: [1550/4518] 34% | Training loss: 0.6871718633174896
Epoch: 83 | Iteration number: [1560/4518] 34% | Training loss: 0.6871668227972129
Epoch: 83 | Iteration number: [1570/4518] 34% | Training loss: 0.687162871345593
Epoch: 83 | Iteration number: [1580/4518] 34% | Training loss: 0.6871609379596348
Epoch: 83 | Iteration number: [1590/4518] 35% | Training loss: 0.6871621895136323
Epoch: 83 | Iteration number: [1600/4518] 35% | Training loss: 0.6871631408855319
Epoch: 83 | Iteration number: [1610/4518] 35% | Training loss: 0.6871540977717927
Epoch: 83 | Iteration number: [1620/4518] 35% | Training loss: 0.6871515137545856
Epoch: 83 | Iteration number: [1630/4518] 36% | Training loss: 0.6871534357407342
Epoch: 83 | Iteration number: [1640/4518] 36% | Training loss: 0.6871511582557748
Epoch: 83 | Iteration number: [1650/4518] 36% | Training loss: 0.6871407863226804
Epoch: 83 | Iteration number: [1660/4518] 36% | Training loss: 0.6871365483984889
Epoch: 83 | Iteration number: [1670/4518] 36% | Training loss: 0.6871353989589714
Epoch: 83 | Iteration number: [1680/4518] 37% | Training loss: 0.6871281595811958
Epoch: 83 | Iteration number: [1690/4518] 37% | Training loss: 0.6871323054711495
Epoch: 83 | Iteration number: [1700/4518] 37% | Training loss: 0.6871411383853239
Epoch: 83 | Iteration number: [1710/4518] 37% | Training loss: 0.6871377615900764
Epoch: 83 | Iteration number: [1720/4518] 38% | Training loss: 0.6871396657685901
Epoch: 83 | Iteration number: [1730/4518] 38% | Training loss: 0.6871453070916193
Epoch: 83 | Iteration number: [1740/4518] 38% | Training loss: 0.6871426994088052
Epoch: 83 | Iteration number: [1750/4518] 38% | Training loss: 0.6871399349144527
Epoch: 83 | Iteration number: [1760/4518] 38% | Training loss: 0.6871453009545803
Epoch: 83 | Iteration number: [1770/4518] 39% | Training loss: 0.6871383681135662
Epoch: 83 | Iteration number: [1780/4518] 39% | Training loss: 0.6871320302231928
Epoch: 83 | Iteration number: [1790/4518] 39% | Training loss: 0.6871299094993975
Epoch: 83 | Iteration number: [1800/4518] 39% | Training loss: 0.6871249523758888
Epoch: 83 | Iteration number: [1810/4518] 40% | Training loss: 0.6871220373975638
Epoch: 83 | Iteration number: [1820/4518] 40% | Training loss: 0.68712605038187
Epoch: 83 | Iteration number: [1830/4518] 40% | Training loss: 0.687128879203171
Epoch: 83 | Iteration number: [1840/4518] 40% | Training loss: 0.687126194977242
Epoch: 83 | Iteration number: [1850/4518] 40% | Training loss: 0.6871220055464152
Epoch: 83 | Iteration number: [1860/4518] 41% | Training loss: 0.6871232972670627
Epoch: 83 | Iteration number: [1870/4518] 41% | Training loss: 0.6871216273881535
Epoch: 83 | Iteration number: [1880/4518] 41% | Training loss: 0.6871199746398216
Epoch: 83 | Iteration number: [1890/4518] 41% | Training loss: 0.6871245943680011
Epoch: 83 | Iteration number: [1900/4518] 42% | Training loss: 0.687123536059731
Epoch: 83 | Iteration number: [1910/4518] 42% | Training loss: 0.6871217343819703
Epoch: 83 | Iteration number: [1920/4518] 42% | Training loss: 0.6871170031217237
Epoch: 83 | Iteration number: [1930/4518] 42% | Training loss: 0.6871208914203347
Epoch: 83 | Iteration number: [1940/4518] 42% | Training loss: 0.6871183401837792
Epoch: 83 | Iteration number: [1950/4518] 43% | Training loss: 0.687119385340275
Epoch: 83 | Iteration number: [1960/4518] 43% | Training loss: 0.6871199946926565
Epoch: 83 | Iteration number: [1970/4518] 43% | Training loss: 0.6871206568279847
Epoch: 83 | Iteration number: [1980/4518] 43% | Training loss: 0.6871179194161386
Epoch: 83 | Iteration number: [1990/4518] 44% | Training loss: 0.6871190127715393
Epoch: 83 | Iteration number: [2000/4518] 44% | Training loss: 0.6871165155768394
Epoch: 83 | Iteration number: [2010/4518] 44% | Training loss: 0.6871207580637576
Epoch: 83 | Iteration number: [2020/4518] 44% | Training loss: 0.6871205431990104
Epoch: 83 | Iteration number: [2030/4518] 44% | Training loss: 0.6871241411845672
Epoch: 83 | Iteration number: [2040/4518] 45% | Training loss: 0.6871238526760363
Epoch: 83 | Iteration number: [2050/4518] 45% | Training loss: 0.6871123053969407
Epoch: 83 | Iteration number: [2060/4518] 45% | Training loss: 0.6871172133290652
Epoch: 83 | Iteration number: [2070/4518] 45% | Training loss: 0.6871124810354721
Epoch: 83 | Iteration number: [2080/4518] 46% | Training loss: 0.6871150948393804
Epoch: 83 | Iteration number: [2090/4518] 46% | Training loss: 0.6871107577136829
Epoch: 83 | Iteration number: [2100/4518] 46% | Training loss: 0.6871076596350897
Epoch: 83 | Iteration number: [2110/4518] 46% | Training loss: 0.6871053846808971
Epoch: 83 | Iteration number: [2120/4518] 46% | Training loss: 0.6870999891521796
Epoch: 83 | Iteration number: [2130/4518] 47% | Training loss: 0.6871042387866079
Epoch: 83 | Iteration number: [2140/4518] 47% | Training loss: 0.6871023412898322
Epoch: 83 | Iteration number: [2150/4518] 47% | Training loss: 0.6870972404091857
Epoch: 83 | Iteration number: [2160/4518] 47% | Training loss: 0.6870978044966857
Epoch: 83 | Iteration number: [2170/4518] 48% | Training loss: 0.6870927049267677
Epoch: 83 | Iteration number: [2180/4518] 48% | Training loss: 0.6870911182066716
Epoch: 83 | Iteration number: [2190/4518] 48% | Training loss: 0.6870935909279949
Epoch: 83 | Iteration number: [2200/4518] 48% | Training loss: 0.6870928483117711
Epoch: 83 | Iteration number: [2210/4518] 48% | Training loss: 0.6870918759123772
Epoch: 83 | Iteration number: [2220/4518] 49% | Training loss: 0.6870928728902662
Epoch: 83 | Iteration number: [2230/4518] 49% | Training loss: 0.687090001860007
Epoch: 83 | Iteration number: [2240/4518] 49% | Training loss: 0.6870874785685114
Epoch: 83 | Iteration number: [2250/4518] 49% | Training loss: 0.6870869705941942
Epoch: 83 | Iteration number: [2260/4518] 50% | Training loss: 0.6870847368398599
Epoch: 83 | Iteration number: [2270/4518] 50% | Training loss: 0.6870850616089573
Epoch: 83 | Iteration number: [2280/4518] 50% | Training loss: 0.6870851613711892
Epoch: 83 | Iteration number: [2290/4518] 50% | Training loss: 0.6870853235107321
Epoch: 83 | Iteration number: [2300/4518] 50% | Training loss: 0.6870831023351006
Epoch: 83 | Iteration number: [2310/4518] 51% | Training loss: 0.6870862111642764
Epoch: 83 | Iteration number: [2320/4518] 51% | Training loss: 0.6870868064976972
Epoch: 83 | Iteration number: [2330/4518] 51% | Training loss: 0.6870881572557621
Epoch: 83 | Iteration number: [2340/4518] 51% | Training loss: 0.6870859309903576
Epoch: 83 | Iteration number: [2350/4518] 52% | Training loss: 0.6870855411570123
Epoch: 83 | Iteration number: [2360/4518] 52% | Training loss: 0.6870800979561725
Epoch: 83 | Iteration number: [2370/4518] 52% | Training loss: 0.6870820308033424
Epoch: 83 | Iteration number: [2380/4518] 52% | Training loss: 0.6870841880555915
Epoch: 83 | Iteration number: [2390/4518] 52% | Training loss: 0.6870859325430883
Epoch: 83 | Iteration number: [2400/4518] 53% | Training loss: 0.6870865466694037
Epoch: 83 | Iteration number: [2410/4518] 53% | Training loss: 0.6870791104324626
Epoch: 83 | Iteration number: [2420/4518] 53% | Training loss: 0.6870709946086584
Epoch: 83 | Iteration number: [2430/4518] 53% | Training loss: 0.6870625455928928
Epoch: 83 | Iteration number: [2440/4518] 54% | Training loss: 0.6870616612131478
Epoch: 83 | Iteration number: [2450/4518] 54% | Training loss: 0.6870586198689986
Epoch: 83 | Iteration number: [2460/4518] 54% | Training loss: 0.6870579342531964
Epoch: 83 | Iteration number: [2470/4518] 54% | Training loss: 0.6870600096368596
Epoch: 83 | Iteration number: [2480/4518] 54% | Training loss: 0.6870614367627328
Epoch: 83 | Iteration number: [2490/4518] 55% | Training loss: 0.6870586266479339
Epoch: 83 | Iteration number: [2500/4518] 55% | Training loss: 0.6870590366125107
Epoch: 83 | Iteration number: [2510/4518] 55% | Training loss: 0.6870529087178736
Epoch: 83 | Iteration number: [2520/4518] 55% | Training loss: 0.6870529198930377
Epoch: 83 | Iteration number: [2530/4518] 55% | Training loss: 0.6870465229858052
Epoch: 83 | Iteration number: [2540/4518] 56% | Training loss: 0.6870479052930366
Epoch: 83 | Iteration number: [2550/4518] 56% | Training loss: 0.6870418688596464
Epoch: 83 | Iteration number: [2560/4518] 56% | Training loss: 0.6870340409688651
Epoch: 83 | Iteration number: [2570/4518] 56% | Training loss: 0.6870405170936065
Epoch: 83 | Iteration number: [2580/4518] 57% | Training loss: 0.6870353455691375
Epoch: 83 | Iteration number: [2590/4518] 57% | Training loss: 0.6870334603151299
Epoch: 83 | Iteration number: [2600/4518] 57% | Training loss: 0.6870366029326732
Epoch: 83 | Iteration number: [2610/4518] 57% | Training loss: 0.6870402184254365
Epoch: 83 | Iteration number: [2620/4518] 57% | Training loss: 0.6870356919883772
Epoch: 83 | Iteration number: [2630/4518] 58% | Training loss: 0.6870345794882611
Epoch: 83 | Iteration number: [2640/4518] 58% | Training loss: 0.6870305678158095
Epoch: 83 | Iteration number: [2650/4518] 58% | Training loss: 0.6870306346551427
Epoch: 83 | Iteration number: [2660/4518] 58% | Training loss: 0.6870362674383292
Epoch: 83 | Iteration number: [2670/4518] 59% | Training loss: 0.6870332893360866
Epoch: 83 | Iteration number: [2680/4518] 59% | Training loss: 0.6870360663577691
Epoch: 83 | Iteration number: [2690/4518] 59% | Training loss: 0.6870320612613153
Epoch: 83 | Iteration number: [2700/4518] 59% | Training loss: 0.6870269299878015
Epoch: 83 | Iteration number: [2710/4518] 59% | Training loss: 0.6870242805058666
Epoch: 83 | Iteration number: [2720/4518] 60% | Training loss: 0.6870233481202055
Epoch: 83 | Iteration number: [2730/4518] 60% | Training loss: 0.6870226851313106
Epoch: 83 | Iteration number: [2740/4518] 60% | Training loss: 0.6870205512664614
Epoch: 83 | Iteration number: [2750/4518] 60% | Training loss: 0.6870213526162234
Epoch: 83 | Iteration number: [2760/4518] 61% | Training loss: 0.6870243069486341
Epoch: 83 | Iteration number: [2770/4518] 61% | Training loss: 0.6870221891773306
Epoch: 83 | Iteration number: [2780/4518] 61% | Training loss: 0.6870211185311242
Epoch: 83 | Iteration number: [2790/4518] 61% | Training loss: 0.6870201650486197
Epoch: 83 | Iteration number: [2800/4518] 61% | Training loss: 0.6870156404588904
Epoch: 83 | Iteration number: [2810/4518] 62% | Training loss: 0.6870065118918639
Epoch: 83 | Iteration number: [2820/4518] 62% | Training loss: 0.687004280407378
Epoch: 83 | Iteration number: [2830/4518] 62% | Training loss: 0.6870014502597782
Epoch: 83 | Iteration number: [2840/4518] 62% | Training loss: 0.6869978091876272
Epoch: 83 | Iteration number: [2850/4518] 63% | Training loss: 0.6869980029265086
Epoch: 83 | Iteration number: [2860/4518] 63% | Training loss: 0.6870016577360514
Epoch: 83 | Iteration number: [2870/4518] 63% | Training loss: 0.6870055520991415
Epoch: 83 | Iteration number: [2880/4518] 63% | Training loss: 0.6870005002038346
Epoch: 83 | Iteration number: [2890/4518] 63% | Training loss: 0.6870009940182049
Epoch: 83 | Iteration number: [2900/4518] 64% | Training loss: 0.6869992392022034
Epoch: 83 | Iteration number: [2910/4518] 64% | Training loss: 0.6869963442337063
Epoch: 83 | Iteration number: [2920/4518] 64% | Training loss: 0.686995382117082
Epoch: 83 | Iteration number: [2930/4518] 64% | Training loss: 0.6869934953520322
Epoch: 83 | Iteration number: [2940/4518] 65% | Training loss: 0.6869913765767804
Epoch: 83 | Iteration number: [2950/4518] 65% | Training loss: 0.6869945185871448
Epoch: 83 | Iteration number: [2960/4518] 65% | Training loss: 0.6869916161773978
Epoch: 83 | Iteration number: [2970/4518] 65% | Training loss: 0.6869877135512805
Epoch: 83 | Iteration number: [2980/4518] 65% | Training loss: 0.6869830903790941
Epoch: 83 | Iteration number: [2990/4518] 66% | Training loss: 0.6869855446759674
Epoch: 83 | Iteration number: [3000/4518] 66% | Training loss: 0.6869879028598468
Epoch: 83 | Iteration number: [3010/4518] 66% | Training loss: 0.6869862346950163
Epoch: 83 | Iteration number: [3020/4518] 66% | Training loss: 0.6869855833369375
Epoch: 83 | Iteration number: [3030/4518] 67% | Training loss: 0.6869847136755588
Epoch: 83 | Iteration number: [3040/4518] 67% | Training loss: 0.686983348527237
Epoch: 83 | Iteration number: [3050/4518] 67% | Training loss: 0.6869852343934482
Epoch: 83 | Iteration number: [3060/4518] 67% | Training loss: 0.686985639906397
Epoch: 83 | Iteration number: [3070/4518] 67% | Training loss: 0.6869878727760688
Epoch: 83 | Iteration number: [3080/4518] 68% | Training loss: 0.686986792822937
Epoch: 83 | Iteration number: [3090/4518] 68% | Training loss: 0.6869835016989785
Epoch: 83 | Iteration number: [3100/4518] 68% | Training loss: 0.6869786781457162
Epoch: 83 | Iteration number: [3110/4518] 68% | Training loss: 0.6869761565490551
Epoch: 83 | Iteration number: [3120/4518] 69% | Training loss: 0.6869725737625207
Epoch: 83 | Iteration number: [3130/4518] 69% | Training loss: 0.686972628671902
Epoch: 83 | Iteration number: [3140/4518] 69% | Training loss: 0.6869727913930918
Epoch: 83 | Iteration number: [3150/4518] 69% | Training loss: 0.6869682575218261
Epoch: 83 | Iteration number: [3160/4518] 69% | Training loss: 0.6869710931483703
Epoch: 83 | Iteration number: [3170/4518] 70% | Training loss: 0.6869663760677122
Epoch: 83 | Iteration number: [3180/4518] 70% | Training loss: 0.6869646885485019
Epoch: 83 | Iteration number: [3190/4518] 70% | Training loss: 0.6869606838144106
Epoch: 83 | Iteration number: [3200/4518] 70% | Training loss: 0.6869589535333216
Epoch: 83 | Iteration number: [3210/4518] 71% | Training loss: 0.6869577544129155
Epoch: 83 | Iteration number: [3220/4518] 71% | Training loss: 0.6869593567914845
Epoch: 83 | Iteration number: [3230/4518] 71% | Training loss: 0.6869592697812308
Epoch: 83 | Iteration number: [3240/4518] 71% | Training loss: 0.6869577405629335
Epoch: 83 | Iteration number: [3250/4518] 71% | Training loss: 0.6869570756692153
Epoch: 83 | Iteration number: [3260/4518] 72% | Training loss: 0.6869562147219488
Epoch: 83 | Iteration number: [3270/4518] 72% | Training loss: 0.6869559242273325
Epoch: 83 | Iteration number: [3280/4518] 72% | Training loss: 0.6869551046410712
Epoch: 83 | Iteration number: [3290/4518] 72% | Training loss: 0.6869558147746379
Epoch: 83 | Iteration number: [3300/4518] 73% | Training loss: 0.6869542945515026
Epoch: 83 | Iteration number: [3310/4518] 73% | Training loss: 0.686953748587035
Epoch: 83 | Iteration number: [3320/4518] 73% | Training loss: 0.6869544374655528
Epoch: 83 | Iteration number: [3330/4518] 73% | Training loss: 0.6869529705684823
Epoch: 83 | Iteration number: [3340/4518] 73% | Training loss: 0.6869569581782746
Epoch: 83 | Iteration number: [3350/4518] 74% | Training loss: 0.6869575824844304
Epoch: 83 | Iteration number: [3360/4518] 74% | Training loss: 0.6869542709241311
Epoch: 83 | Iteration number: [3370/4518] 74% | Training loss: 0.686954044464434
Epoch: 83 | Iteration number: [3380/4518] 74% | Training loss: 0.6869535446519682
Epoch: 83 | Iteration number: [3390/4518] 75% | Training loss: 0.6869516839847453
Epoch: 83 | Iteration number: [3400/4518] 75% | Training loss: 0.6869525058304562
Epoch: 83 | Iteration number: [3410/4518] 75% | Training loss: 0.6869520153817543
Epoch: 83 | Iteration number: [3420/4518] 75% | Training loss: 0.6869488870365578
Epoch: 83 | Iteration number: [3430/4518] 75% | Training loss: 0.6869503220733331
Epoch: 83 | Iteration number: [3440/4518] 76% | Training loss: 0.6869528682599234
Epoch: 83 | Iteration number: [3450/4518] 76% | Training loss: 0.6869518288667651
Epoch: 83 | Iteration number: [3460/4518] 76% | Training loss: 0.6869511758316459
Epoch: 83 | Iteration number: [3470/4518] 76% | Training loss: 0.6869480702134992
Epoch: 83 | Iteration number: [3480/4518] 77% | Training loss: 0.6869503868722368
Epoch: 83 | Iteration number: [3490/4518] 77% | Training loss: 0.6869500630222966
Epoch: 83 | Iteration number: [3500/4518] 77% | Training loss: 0.6869487381322044
Epoch: 83 | Iteration number: [3510/4518] 77% | Training loss: 0.6869456534881537
Epoch: 83 | Iteration number: [3520/4518] 77% | Training loss: 0.6869439241391692
Epoch: 83 | Iteration number: [3530/4518] 78% | Training loss: 0.6869449180178872
Epoch: 83 | Iteration number: [3540/4518] 78% | Training loss: 0.6869437379520492
Epoch: 83 | Iteration number: [3550/4518] 78% | Training loss: 0.6869462207673301
Epoch: 83 | Iteration number: [3560/4518] 78% | Training loss: 0.686945308108678
Epoch: 83 | Iteration number: [3570/4518] 79% | Training loss: 0.6869432522803127
Epoch: 83 | Iteration number: [3580/4518] 79% | Training loss: 0.6869440528434082
Epoch: 83 | Iteration number: [3590/4518] 79% | Training loss: 0.6869391637260204
Epoch: 83 | Iteration number: [3600/4518] 79% | Training loss: 0.6869381799962786
Epoch: 83 | Iteration number: [3610/4518] 79% | Training loss: 0.6869430462904584
Epoch: 83 | Iteration number: [3620/4518] 80% | Training loss: 0.6869417826773712
Epoch: 83 | Iteration number: [3630/4518] 80% | Training loss: 0.6869379904808749
Epoch: 83 | Iteration number: [3640/4518] 80% | Training loss: 0.6869358479321658
Epoch: 83 | Iteration number: [3650/4518] 80% | Training loss: 0.6869366319865396
Epoch: 83 | Iteration number: [3660/4518] 81% | Training loss: 0.6869368826105295
Epoch: 83 | Iteration number: [3670/4518] 81% | Training loss: 0.686937734103008
Epoch: 83 | Iteration number: [3680/4518] 81% | Training loss: 0.6869358847160703
Epoch: 83 | Iteration number: [3690/4518] 81% | Training loss: 0.6869329592399804
Epoch: 83 | Iteration number: [3700/4518] 81% | Training loss: 0.6869323526685303
Epoch: 83 | Iteration number: [3710/4518] 82% | Training loss: 0.6869343189377026
Epoch: 83 | Iteration number: [3720/4518] 82% | Training loss: 0.6869309218019568
Epoch: 83 | Iteration number: [3730/4518] 82% | Training loss: 0.6869308461612416
Epoch: 83 | Iteration number: [3740/4518] 82% | Training loss: 0.6869290826154902
Epoch: 83 | Iteration number: [3750/4518] 83% | Training loss: 0.686930294195811
Epoch: 83 | Iteration number: [3760/4518] 83% | Training loss: 0.6869325318552079
Epoch: 83 | Iteration number: [3770/4518] 83% | Training loss: 0.686931908968589
Epoch: 83 | Iteration number: [3780/4518] 83% | Training loss: 0.686931460133936
Epoch: 83 | Iteration number: [3790/4518] 83% | Training loss: 0.6869327576147849
Epoch: 83 | Iteration number: [3800/4518] 84% | Training loss: 0.6869307715171262
Epoch: 83 | Iteration number: [3810/4518] 84% | Training loss: 0.68693241012378
Epoch: 83 | Iteration number: [3820/4518] 84% | Training loss: 0.6869330446601538
Epoch: 83 | Iteration number: [3830/4518] 84% | Training loss: 0.686934324079643
Epoch: 83 | Iteration number: [3840/4518] 84% | Training loss: 0.6869329950772226
Epoch: 83 | Iteration number: [3850/4518] 85% | Training loss: 0.6869333071677716
Epoch: 83 | Iteration number: [3860/4518] 85% | Training loss: 0.6869318964413411
Epoch: 83 | Iteration number: [3870/4518] 85% | Training loss: 0.6869313724743303
Epoch: 83 | Iteration number: [3880/4518] 85% | Training loss: 0.6869328620507545
Epoch: 83 | Iteration number: [3890/4518] 86% | Training loss: 0.6869334721779762
Epoch: 83 | Iteration number: [3900/4518] 86% | Training loss: 0.6869379835709547
Epoch: 83 | Iteration number: [3910/4518] 86% | Training loss: 0.6869367170974117
Epoch: 83 | Iteration number: [3920/4518] 86% | Training loss: 0.6869362901972265
Epoch: 83 | Iteration number: [3930/4518] 86% | Training loss: 0.686934387592869
Epoch: 83 | Iteration number: [3940/4518] 87% | Training loss: 0.6869331174695552
Epoch: 83 | Iteration number: [3950/4518] 87% | Training loss: 0.6869324215001698
Epoch: 83 | Iteration number: [3960/4518] 87% | Training loss: 0.6869313367840015
Epoch: 83 | Iteration number: [3970/4518] 87% | Training loss: 0.6869317214494989
Epoch: 83 | Iteration number: [3980/4518] 88% | Training loss: 0.6869285534224917
Epoch: 83 | Iteration number: [3990/4518] 88% | Training loss: 0.6869314934376786
Epoch: 83 | Iteration number: [4000/4518] 88% | Training loss: 0.6869330228418111
Epoch: 83 | Iteration number: [4010/4518] 88% | Training loss: 0.6869344479871212
Epoch: 83 | Iteration number: [4020/4518] 88% | Training loss: 0.6869313901336632
Epoch: 83 | Iteration number: [4030/4518] 89% | Training loss: 0.6869295124084719
Epoch: 83 | Iteration number: [4040/4518] 89% | Training loss: 0.6869309760113754
Epoch: 83 | Iteration number: [4050/4518] 89% | Training loss: 0.6869339481106511
Epoch: 83 | Iteration number: [4060/4518] 89% | Training loss: 0.6869309957538332
Epoch: 83 | Iteration number: [4070/4518] 90% | Training loss: 0.6869311559405316
Epoch: 83 | Iteration number: [4080/4518] 90% | Training loss: 0.686928585551533
Epoch: 83 | Iteration number: [4090/4518] 90% | Training loss: 0.6869260784612017
Epoch: 83 | Iteration number: [4100/4518] 90% | Training loss: 0.6869253560682622
Epoch: 83 | Iteration number: [4110/4518] 90% | Training loss: 0.6869242032804048
Epoch: 83 | Iteration number: [4120/4518] 91% | Training loss: 0.6869204541577876
Epoch: 83 | Iteration number: [4130/4518] 91% | Training loss: 0.6869204162829725
Epoch: 83 | Iteration number: [4140/4518] 91% | Training loss: 0.6869210863170992
Epoch: 83 | Iteration number: [4150/4518] 91% | Training loss: 0.6869201367303549
Epoch: 83 | Iteration number: [4160/4518] 92% | Training loss: 0.6869237881010541
Epoch: 83 | Iteration number: [4170/4518] 92% | Training loss: 0.6869257354336105
Epoch: 83 | Iteration number: [4180/4518] 92% | Training loss: 0.686924274187339
Epoch: 83 | Iteration number: [4190/4518] 92% | Training loss: 0.6869219708556492
Epoch: 83 | Iteration number: [4200/4518] 92% | Training loss: 0.686921388890062
Epoch: 83 | Iteration number: [4210/4518] 93% | Training loss: 0.6869175311080633
Epoch: 83 | Iteration number: [4220/4518] 93% | Training loss: 0.686917406235826
Epoch: 83 | Iteration number: [4230/4518] 93% | Training loss: 0.6869143918755488
Epoch: 83 | Iteration number: [4240/4518] 93% | Training loss: 0.6869144228550623
Epoch: 83 | Iteration number: [4250/4518] 94% | Training loss: 0.6869130984334385
Epoch: 83 | Iteration number: [4260/4518] 94% | Training loss: 0.6869154074522251
Epoch: 83 | Iteration number: [4270/4518] 94% | Training loss: 0.6869134699293266
Epoch: 83 | Iteration number: [4280/4518] 94% | Training loss: 0.6869131793207097
Epoch: 83 | Iteration number: [4290/4518] 94% | Training loss: 0.6869128521644707
Epoch: 83 | Iteration number: [4300/4518] 95% | Training loss: 0.6869117991175763
Epoch: 83 | Iteration number: [4310/4518] 95% | Training loss: 0.6869084118966989
Epoch: 83 | Iteration number: [4320/4518] 95% | Training loss: 0.6869076295997257
Epoch: 83 | Iteration number: [4330/4518] 95% | Training loss: 0.6869111384310292
Epoch: 83 | Iteration number: [4340/4518] 96% | Training loss: 0.686914478716213
Epoch: 83 | Iteration number: [4350/4518] 96% | Training loss: 0.686917276999046
Epoch: 83 | Iteration number: [4360/4518] 96% | Training loss: 0.6869152742378208
Epoch: 83 | Iteration number: [4370/4518] 96% | Training loss: 0.6869130854475689
Epoch: 83 | Iteration number: [4380/4518] 96% | Training loss: 0.6869141089861796
Epoch: 83 | Iteration number: [4390/4518] 97% | Training loss: 0.6869124108539355
Epoch: 83 | Iteration number: [4400/4518] 97% | Training loss: 0.6869120001657443
Epoch: 83 | Iteration number: [4410/4518] 97% | Training loss: 0.6869101339186671
Epoch: 83 | Iteration number: [4420/4518] 97% | Training loss: 0.686911394733649
Epoch: 83 | Iteration number: [4430/4518] 98% | Training loss: 0.6869112235294239
Epoch: 83 | Iteration number: [4440/4518] 98% | Training loss: 0.68690818928115
Epoch: 83 | Iteration number: [4450/4518] 98% | Training loss: 0.6869084545467676
Epoch: 83 | Iteration number: [4460/4518] 98% | Training loss: 0.6869082059961797
Epoch: 83 | Iteration number: [4470/4518] 98% | Training loss: 0.6869069417317708
Epoch: 83 | Iteration number: [4480/4518] 99% | Training loss: 0.68690713243559
Epoch: 83 | Iteration number: [4490/4518] 99% | Training loss: 0.686907367066445
Epoch: 83 | Iteration number: [4500/4518] 99% | Training loss: 0.686907704618242
Epoch: 83 | Iteration number: [4510/4518] 99% | Training loss: 0.6869104667672032

 End of epoch: 83 | Train Loss: 0.6867581557494025 | Training Time: 632 

 End of epoch: 83 | Eval Loss: 0.6895905222211566 | Evaluating Time: 17 
Epoch: 84 | Iteration number: [10/4518] 0% | Training loss: 0.7545177459716796
Epoch: 84 | Iteration number: [20/4518] 0% | Training loss: 0.7214152783155441
Epoch: 84 | Iteration number: [30/4518] 0% | Training loss: 0.7098109622796377
Epoch: 84 | Iteration number: [40/4518] 0% | Training loss: 0.7038449227809906
Epoch: 84 | Iteration number: [50/4518] 1% | Training loss: 0.7003809332847595
Epoch: 84 | Iteration number: [60/4518] 1% | Training loss: 0.6982158978780111
Epoch: 84 | Iteration number: [70/4518] 1% | Training loss: 0.6964975544384547
Epoch: 84 | Iteration number: [80/4518] 1% | Training loss: 0.6953433707356453
Epoch: 84 | Iteration number: [90/4518] 1% | Training loss: 0.6944539527098338
Epoch: 84 | Iteration number: [100/4518] 2% | Training loss: 0.693514643907547
Epoch: 84 | Iteration number: [110/4518] 2% | Training loss: 0.6927741841836409
Epoch: 84 | Iteration number: [120/4518] 2% | Training loss: 0.6922675301631291
Epoch: 84 | Iteration number: [130/4518] 2% | Training loss: 0.6918542192532466
Epoch: 84 | Iteration number: [140/4518] 3% | Training loss: 0.691585641673633
Epoch: 84 | Iteration number: [150/4518] 3% | Training loss: 0.6912524894873301
Epoch: 84 | Iteration number: [160/4518] 3% | Training loss: 0.6908945184201002
Epoch: 84 | Iteration number: [170/4518] 3% | Training loss: 0.690677419830771
Epoch: 84 | Iteration number: [180/4518] 3% | Training loss: 0.6904147038857142
Epoch: 84 | Iteration number: [190/4518] 4% | Training loss: 0.6902356913215235
Epoch: 84 | Iteration number: [200/4518] 4% | Training loss: 0.6900575262308121
Epoch: 84 | Iteration number: [210/4518] 4% | Training loss: 0.689949510494868
Epoch: 84 | Iteration number: [220/4518] 4% | Training loss: 0.6897850372574547
Epoch: 84 | Iteration number: [230/4518] 5% | Training loss: 0.6896319505961045
Epoch: 84 | Iteration number: [240/4518] 5% | Training loss: 0.689521133651336
Epoch: 84 | Iteration number: [250/4518] 5% | Training loss: 0.6893988304138183
Epoch: 84 | Iteration number: [260/4518] 5% | Training loss: 0.6893627194257883
Epoch: 84 | Iteration number: [270/4518] 5% | Training loss: 0.6892313102881114
Epoch: 84 | Iteration number: [280/4518] 6% | Training loss: 0.6890929611665862
Epoch: 84 | Iteration number: [290/4518] 6% | Training loss: 0.68901705721329
Epoch: 84 | Iteration number: [300/4518] 6% | Training loss: 0.6889140460888544
Epoch: 84 | Iteration number: [310/4518] 6% | Training loss: 0.6888067918439065
Epoch: 84 | Iteration number: [320/4518] 7% | Training loss: 0.6887588692829013
Epoch: 84 | Iteration number: [330/4518] 7% | Training loss: 0.6886660783579855
Epoch: 84 | Iteration number: [340/4518] 7% | Training loss: 0.6886156150523354
Epoch: 84 | Iteration number: [350/4518] 7% | Training loss: 0.6885568080629622
Epoch: 84 | Iteration number: [360/4518] 7% | Training loss: 0.688495074874825
Epoch: 84 | Iteration number: [370/4518] 8% | Training loss: 0.6884593452956226
Epoch: 84 | Iteration number: [380/4518] 8% | Training loss: 0.6884201895249518
Epoch: 84 | Iteration number: [390/4518] 8% | Training loss: 0.6884014740968362
Epoch: 84 | Iteration number: [400/4518] 8% | Training loss: 0.6883731466531754
Epoch: 84 | Iteration number: [410/4518] 9% | Training loss: 0.6883243758503984
Epoch: 84 | Iteration number: [420/4518] 9% | Training loss: 0.6882913871890023
Epoch: 84 | Iteration number: [430/4518] 9% | Training loss: 0.6882518644942793
Epoch: 84 | Iteration number: [440/4518] 9% | Training loss: 0.6882208110256629
Epoch: 84 | Iteration number: [450/4518] 9% | Training loss: 0.6882142003377278
Epoch: 84 | Iteration number: [460/4518] 10% | Training loss: 0.6881470658209012
Epoch: 84 | Iteration number: [470/4518] 10% | Training loss: 0.6881337707347058
Epoch: 84 | Iteration number: [480/4518] 10% | Training loss: 0.6881224982440471
Epoch: 84 | Iteration number: [490/4518] 10% | Training loss: 0.6880978507655008
Epoch: 84 | Iteration number: [500/4518] 11% | Training loss: 0.6880849764347077
Epoch: 84 | Iteration number: [510/4518] 11% | Training loss: 0.6880500393755296
Epoch: 84 | Iteration number: [520/4518] 11% | Training loss: 0.6880251691891597
Epoch: 84 | Iteration number: [530/4518] 11% | Training loss: 0.6879933205415618
Epoch: 84 | Iteration number: [540/4518] 11% | Training loss: 0.6879612392849392
Epoch: 84 | Iteration number: [550/4518] 12% | Training loss: 0.6879632789438421
Epoch: 84 | Iteration number: [560/4518] 12% | Training loss: 0.6879528130803789
Epoch: 84 | Iteration number: [570/4518] 12% | Training loss: 0.6879145644213024
Epoch: 84 | Iteration number: [580/4518] 12% | Training loss: 0.6878755580762337
Epoch: 84 | Iteration number: [590/4518] 13% | Training loss: 0.6878631019996384
Epoch: 84 | Iteration number: [600/4518] 13% | Training loss: 0.6878518428405126
Epoch: 84 | Iteration number: [610/4518] 13% | Training loss: 0.6878610210340531
Epoch: 84 | Iteration number: [620/4518] 13% | Training loss: 0.6878348288036162
Epoch: 84 | Iteration number: [630/4518] 13% | Training loss: 0.6878278883676681
Epoch: 84 | Iteration number: [640/4518] 14% | Training loss: 0.6878100357018411
Epoch: 84 | Iteration number: [650/4518] 14% | Training loss: 0.6878035576526935
Epoch: 84 | Iteration number: [660/4518] 14% | Training loss: 0.6877943324320244
Epoch: 84 | Iteration number: [670/4518] 14% | Training loss: 0.6877689249479949
Epoch: 84 | Iteration number: [680/4518] 15% | Training loss: 0.6877567067742347
Epoch: 84 | Iteration number: [690/4518] 15% | Training loss: 0.6877195264118305
Epoch: 84 | Iteration number: [700/4518] 15% | Training loss: 0.6877004258121763
Epoch: 84 | Iteration number: [710/4518] 15% | Training loss: 0.6876915385185832
Epoch: 84 | Iteration number: [720/4518] 15% | Training loss: 0.6876715988748603
Epoch: 84 | Iteration number: [730/4518] 16% | Training loss: 0.6876677909942522
Epoch: 84 | Iteration number: [740/4518] 16% | Training loss: 0.6876516844775226
Epoch: 84 | Iteration number: [750/4518] 16% | Training loss: 0.6876344301700592
Epoch: 84 | Iteration number: [760/4518] 16% | Training loss: 0.687612493022492
Epoch: 84 | Iteration number: [770/4518] 17% | Training loss: 0.6875915627200883
Epoch: 84 | Iteration number: [780/4518] 17% | Training loss: 0.6875918073531909
Epoch: 84 | Iteration number: [790/4518] 17% | Training loss: 0.6875893515876577
Epoch: 84 | Iteration number: [800/4518] 17% | Training loss: 0.6875893867760897
Epoch: 84 | Iteration number: [810/4518] 17% | Training loss: 0.6875810778435366
Epoch: 84 | Iteration number: [820/4518] 18% | Training loss: 0.6875827062420728
Epoch: 84 | Iteration number: [830/4518] 18% | Training loss: 0.6875791918800538
Epoch: 84 | Iteration number: [840/4518] 18% | Training loss: 0.687561642839795
Epoch: 84 | Iteration number: [850/4518] 18% | Training loss: 0.6875313308659722
Epoch: 84 | Iteration number: [860/4518] 19% | Training loss: 0.6875158065973326
Epoch: 84 | Iteration number: [870/4518] 19% | Training loss: 0.6875132301072965
Epoch: 84 | Iteration number: [880/4518] 19% | Training loss: 0.6875062015246262
Epoch: 84 | Iteration number: [890/4518] 19% | Training loss: 0.6875010809871588
Epoch: 84 | Iteration number: [900/4518] 19% | Training loss: 0.6875003175603018
Epoch: 84 | Iteration number: [910/4518] 20% | Training loss: 0.68749524302535
Epoch: 84 | Iteration number: [920/4518] 20% | Training loss: 0.6874871897308723
Epoch: 84 | Iteration number: [930/4518] 20% | Training loss: 0.6874900492929643
Epoch: 84 | Iteration number: [940/4518] 20% | Training loss: 0.6874886130398893
Epoch: 84 | Iteration number: [950/4518] 21% | Training loss: 0.6874933173781947
Epoch: 84 | Iteration number: [960/4518] 21% | Training loss: 0.6874790410821636
Epoch: 84 | Iteration number: [970/4518] 21% | Training loss: 0.6874787932204217
Epoch: 84 | Iteration number: [980/4518] 21% | Training loss: 0.6874742748785992
Epoch: 84 | Iteration number: [990/4518] 21% | Training loss: 0.6874740193588565
Epoch: 84 | Iteration number: [1000/4518] 22% | Training loss: 0.687467013835907
Epoch: 84 | Iteration number: [1010/4518] 22% | Training loss: 0.6874680884403758
Epoch: 84 | Iteration number: [1020/4518] 22% | Training loss: 0.6874598836781932
Epoch: 84 | Iteration number: [1030/4518] 22% | Training loss: 0.6874428736353384
Epoch: 84 | Iteration number: [1040/4518] 23% | Training loss: 0.6874462985648558
Epoch: 84 | Iteration number: [1050/4518] 23% | Training loss: 0.6874414195900872
Epoch: 84 | Iteration number: [1060/4518] 23% | Training loss: 0.6874387673611911
Epoch: 84 | Iteration number: [1070/4518] 23% | Training loss: 0.687426710908658
Epoch: 84 | Iteration number: [1080/4518] 23% | Training loss: 0.6874106583219988
Epoch: 84 | Iteration number: [1090/4518] 24% | Training loss: 0.6874161667233213
Epoch: 84 | Iteration number: [1100/4518] 24% | Training loss: 0.6874172574281693
Epoch: 84 | Iteration number: [1110/4518] 24% | Training loss: 0.6874057722521257
Epoch: 84 | Iteration number: [1120/4518] 24% | Training loss: 0.6873871099203825
Epoch: 84 | Iteration number: [1130/4518] 25% | Training loss: 0.6873950528887521
Epoch: 84 | Iteration number: [1140/4518] 25% | Training loss: 0.6873939159146526
Epoch: 84 | Iteration number: [1150/4518] 25% | Training loss: 0.6873963972796564
Epoch: 84 | Iteration number: [1160/4518] 25% | Training loss: 0.6873922860314106
Epoch: 84 | Iteration number: [1170/4518] 25% | Training loss: 0.6873849946209508
Epoch: 84 | Iteration number: [1180/4518] 26% | Training loss: 0.6873748492891506
Epoch: 84 | Iteration number: [1190/4518] 26% | Training loss: 0.687351984837476
Epoch: 84 | Iteration number: [1200/4518] 26% | Training loss: 0.6873348374664784
Epoch: 84 | Iteration number: [1210/4518] 26% | Training loss: 0.68731118371664
Epoch: 84 | Iteration number: [1220/4518] 27% | Training loss: 0.68729219783525
Epoch: 84 | Iteration number: [1230/4518] 27% | Training loss: 0.6872848615898349
Epoch: 84 | Iteration number: [1240/4518] 27% | Training loss: 0.6872737295204593
Epoch: 84 | Iteration number: [1250/4518] 27% | Training loss: 0.6872750864505768
Epoch: 84 | Iteration number: [1260/4518] 27% | Training loss: 0.6872663821965929
Epoch: 84 | Iteration number: [1270/4518] 28% | Training loss: 0.687264935003491
Epoch: 84 | Iteration number: [1280/4518] 28% | Training loss: 0.6872683030087501
Epoch: 84 | Iteration number: [1290/4518] 28% | Training loss: 0.6872571261354196
Epoch: 84 | Iteration number: [1300/4518] 28% | Training loss: 0.6872611740002266
Epoch: 84 | Iteration number: [1310/4518] 28% | Training loss: 0.6872563198322558
Epoch: 84 | Iteration number: [1320/4518] 29% | Training loss: 0.687255241699291
Epoch: 84 | Iteration number: [1330/4518] 29% | Training loss: 0.6872486879054766
Epoch: 84 | Iteration number: [1340/4518] 29% | Training loss: 0.6872461049859203
Epoch: 84 | Iteration number: [1350/4518] 29% | Training loss: 0.6872464745574527
Epoch: 84 | Iteration number: [1360/4518] 30% | Training loss: 0.6872423918369939
Epoch: 84 | Iteration number: [1370/4518] 30% | Training loss: 0.6872440632242356
Epoch: 84 | Iteration number: [1380/4518] 30% | Training loss: 0.6872347755276639
Epoch: 84 | Iteration number: [1390/4518] 30% | Training loss: 0.6872279714766166
Epoch: 84 | Iteration number: [1400/4518] 30% | Training loss: 0.6872214041437421
Epoch: 84 | Iteration number: [1410/4518] 31% | Training loss: 0.6872179820182476
Epoch: 84 | Iteration number: [1420/4518] 31% | Training loss: 0.6872075940101919
Epoch: 84 | Iteration number: [1430/4518] 31% | Training loss: 0.6871999624309006
Epoch: 84 | Iteration number: [1440/4518] 31% | Training loss: 0.6871992392672432
Epoch: 84 | Iteration number: [1450/4518] 32% | Training loss: 0.6871996396163415
Epoch: 84 | Iteration number: [1460/4518] 32% | Training loss: 0.6871916947299487
Epoch: 84 | Iteration number: [1470/4518] 32% | Training loss: 0.6871883482349163
Epoch: 84 | Iteration number: [1480/4518] 32% | Training loss: 0.6871874331622511
Epoch: 84 | Iteration number: [1490/4518] 32% | Training loss: 0.6871882492263846
Epoch: 84 | Iteration number: [1500/4518] 33% | Training loss: 0.6871850805282593
Epoch: 84 | Iteration number: [1510/4518] 33% | Training loss: 0.6871861353220529
Epoch: 84 | Iteration number: [1520/4518] 33% | Training loss: 0.6871845686121991
Epoch: 84 | Iteration number: [1530/4518] 33% | Training loss: 0.6871784135407093
Epoch: 84 | Iteration number: [1540/4518] 34% | Training loss: 0.6871756574550232
Epoch: 84 | Iteration number: [1550/4518] 34% | Training loss: 0.6871793852698418
Epoch: 84 | Iteration number: [1560/4518] 34% | Training loss: 0.6871813748127374
Epoch: 84 | Iteration number: [1570/4518] 34% | Training loss: 0.6871783132386056
Epoch: 84 | Iteration number: [1580/4518] 34% | Training loss: 0.6871682932105245
Epoch: 84 | Iteration number: [1590/4518] 35% | Training loss: 0.6871636850279083
Epoch: 84 | Iteration number: [1600/4518] 35% | Training loss: 0.6871615067869424
Epoch: 84 | Iteration number: [1610/4518] 35% | Training loss: 0.6871595156488952
Epoch: 84 | Iteration number: [1620/4518] 35% | Training loss: 0.687157913049062
Epoch: 84 | Iteration number: [1630/4518] 36% | Training loss: 0.6871522406493228
Epoch: 84 | Iteration number: [1640/4518] 36% | Training loss: 0.6871567812998121
Epoch: 84 | Iteration number: [1650/4518] 36% | Training loss: 0.6871531292525205
Epoch: 84 | Iteration number: [1660/4518] 36% | Training loss: 0.6871450616652707
Epoch: 84 | Iteration number: [1670/4518] 36% | Training loss: 0.6871426931398358
Epoch: 84 | Iteration number: [1680/4518] 37% | Training loss: 0.687146537254254
Epoch: 84 | Iteration number: [1690/4518] 37% | Training loss: 0.687144930158141
Epoch: 84 | Iteration number: [1700/4518] 37% | Training loss: 0.6871367882630405
Epoch: 84 | Iteration number: [1710/4518] 37% | Training loss: 0.6871390569628331
Epoch: 84 | Iteration number: [1720/4518] 38% | Training loss: 0.6871397629033688
Epoch: 84 | Iteration number: [1730/4518] 38% | Training loss: 0.6871344540505051
Epoch: 84 | Iteration number: [1740/4518] 38% | Training loss: 0.6871353591310567
Epoch: 84 | Iteration number: [1750/4518] 38% | Training loss: 0.6871401974473681
Epoch: 84 | Iteration number: [1760/4518] 38% | Training loss: 0.6871342052451589
Epoch: 84 | Iteration number: [1770/4518] 39% | Training loss: 0.6871317845279887
Epoch: 84 | Iteration number: [1780/4518] 39% | Training loss: 0.6871382814779711
Epoch: 84 | Iteration number: [1790/4518] 39% | Training loss: 0.6871400314336382
Epoch: 84 | Iteration number: [1800/4518] 39% | Training loss: 0.6871436408162117
Epoch: 84 | Iteration number: [1810/4518] 40% | Training loss: 0.6871424200126479
Epoch: 84 | Iteration number: [1820/4518] 40% | Training loss: 0.6871459689441618
Epoch: 84 | Iteration number: [1830/4518] 40% | Training loss: 0.6871464497078963
Epoch: 84 | Iteration number: [1840/4518] 40% | Training loss: 0.6871437843079152
Epoch: 84 | Iteration number: [1850/4518] 40% | Training loss: 0.687144196838946
Epoch: 84 | Iteration number: [1860/4518] 41% | Training loss: 0.687147831275899
Epoch: 84 | Iteration number: [1870/4518] 41% | Training loss: 0.6871463539766118
Epoch: 84 | Iteration number: [1880/4518] 41% | Training loss: 0.6871442732658792
Epoch: 84 | Iteration number: [1890/4518] 41% | Training loss: 0.6871374216344621
Epoch: 84 | Iteration number: [1900/4518] 42% | Training loss: 0.6871347885382803
Epoch: 84 | Iteration number: [1910/4518] 42% | Training loss: 0.6871371546340862
Epoch: 84 | Iteration number: [1920/4518] 42% | Training loss: 0.687128886859864
Epoch: 84 | Iteration number: [1930/4518] 42% | Training loss: 0.687131021523105
Epoch: 84 | Iteration number: [1940/4518] 42% | Training loss: 0.6871318449679109
Epoch: 84 | Iteration number: [1950/4518] 43% | Training loss: 0.687125830925428
Epoch: 84 | Iteration number: [1960/4518] 43% | Training loss: 0.687129357457161
Epoch: 84 | Iteration number: [1970/4518] 43% | Training loss: 0.6871301690333991
Epoch: 84 | Iteration number: [1980/4518] 43% | Training loss: 0.6871251834462387
Epoch: 84 | Iteration number: [1990/4518] 44% | Training loss: 0.6871245810434446
Epoch: 84 | Iteration number: [2000/4518] 44% | Training loss: 0.6871213647425175
Epoch: 84 | Iteration number: [2010/4518] 44% | Training loss: 0.6871201069793891
Epoch: 84 | Iteration number: [2020/4518] 44% | Training loss: 0.6871165531106515
Epoch: 84 | Iteration number: [2030/4518] 44% | Training loss: 0.6871172788695161
Epoch: 84 | Iteration number: [2040/4518] 45% | Training loss: 0.6871139863250302
Epoch: 84 | Iteration number: [2050/4518] 45% | Training loss: 0.687107562030234
Epoch: 84 | Iteration number: [2060/4518] 45% | Training loss: 0.6871076810707166
Epoch: 84 | Iteration number: [2070/4518] 45% | Training loss: 0.6871057022021012
Epoch: 84 | Iteration number: [2080/4518] 46% | Training loss: 0.6871055340824219
Epoch: 84 | Iteration number: [2090/4518] 46% | Training loss: 0.6870996717060582
Epoch: 84 | Iteration number: [2100/4518] 46% | Training loss: 0.6870957418282827
Epoch: 84 | Iteration number: [2110/4518] 46% | Training loss: 0.6870973399182632
Epoch: 84 | Iteration number: [2120/4518] 46% | Training loss: 0.687092509668953
Epoch: 84 | Iteration number: [2130/4518] 47% | Training loss: 0.6870876918936
Epoch: 84 | Iteration number: [2140/4518] 47% | Training loss: 0.6870830401360432
Epoch: 84 | Iteration number: [2150/4518] 47% | Training loss: 0.6870855982359065
Epoch: 84 | Iteration number: [2160/4518] 47% | Training loss: 0.6870875408528028
Epoch: 84 | Iteration number: [2170/4518] 48% | Training loss: 0.6870889447251772
Epoch: 84 | Iteration number: [2180/4518] 48% | Training loss: 0.6870875955448238
Epoch: 84 | Iteration number: [2190/4518] 48% | Training loss: 0.6870864615320615
Epoch: 84 | Iteration number: [2200/4518] 48% | Training loss: 0.6870888796448708
Epoch: 84 | Iteration number: [2210/4518] 48% | Training loss: 0.6870883280335508
Epoch: 84 | Iteration number: [2220/4518] 49% | Training loss: 0.6870899107005145
Epoch: 84 | Iteration number: [2230/4518] 49% | Training loss: 0.6870897598598036
Epoch: 84 | Iteration number: [2240/4518] 49% | Training loss: 0.6870867694328938
Epoch: 84 | Iteration number: [2250/4518] 49% | Training loss: 0.687084636873669
Epoch: 84 | Iteration number: [2260/4518] 50% | Training loss: 0.6870787072498187
Epoch: 84 | Iteration number: [2270/4518] 50% | Training loss: 0.6870803326762195
Epoch: 84 | Iteration number: [2280/4518] 50% | Training loss: 0.6870876039067905
Epoch: 84 | Iteration number: [2290/4518] 50% | Training loss: 0.6870897696788655
Epoch: 84 | Iteration number: [2300/4518] 50% | Training loss: 0.6870921665430069
Epoch: 84 | Iteration number: [2310/4518] 51% | Training loss: 0.6870919747528059
Epoch: 84 | Iteration number: [2320/4518] 51% | Training loss: 0.6870887165182623
Epoch: 84 | Iteration number: [2330/4518] 51% | Training loss: 0.6870874324581654
Epoch: 84 | Iteration number: [2340/4518] 51% | Training loss: 0.687087253958751
Epoch: 84 | Iteration number: [2350/4518] 52% | Training loss: 0.6870834677777392
Epoch: 84 | Iteration number: [2360/4518] 52% | Training loss: 0.6870826764126955
Epoch: 84 | Iteration number: [2370/4518] 52% | Training loss: 0.6870856236807907
Epoch: 84 | Iteration number: [2380/4518] 52% | Training loss: 0.6870822131884198
Epoch: 84 | Iteration number: [2390/4518] 52% | Training loss: 0.6870811514525234
Epoch: 84 | Iteration number: [2400/4518] 53% | Training loss: 0.6870826818545659
Epoch: 84 | Iteration number: [2410/4518] 53% | Training loss: 0.6870868452357058
Epoch: 84 | Iteration number: [2420/4518] 53% | Training loss: 0.6870859907185736
Epoch: 84 | Iteration number: [2430/4518] 53% | Training loss: 0.6870845301161087
Epoch: 84 | Iteration number: [2440/4518] 54% | Training loss: 0.6870794925044794
Epoch: 84 | Iteration number: [2450/4518] 54% | Training loss: 0.6870757206362121
Epoch: 84 | Iteration number: [2460/4518] 54% | Training loss: 0.687070655822754
Epoch: 84 | Iteration number: [2470/4518] 54% | Training loss: 0.6870656586851668
Epoch: 84 | Iteration number: [2480/4518] 54% | Training loss: 0.6870728786914579
Epoch: 84 | Iteration number: [2490/4518] 55% | Training loss: 0.6870692731386208
Epoch: 84 | Iteration number: [2500/4518] 55% | Training loss: 0.6870718348503113
Epoch: 84 | Iteration number: [2510/4518] 55% | Training loss: 0.6870752878160591
Epoch: 84 | Iteration number: [2520/4518] 55% | Training loss: 0.6870716063512696
Epoch: 84 | Iteration number: [2530/4518] 55% | Training loss: 0.6870702720677899
Epoch: 84 | Iteration number: [2540/4518] 56% | Training loss: 0.6870688681762049
Epoch: 84 | Iteration number: [2550/4518] 56% | Training loss: 0.6870637265841166
Epoch: 84 | Iteration number: [2560/4518] 56% | Training loss: 0.6870651959441603
Epoch: 84 | Iteration number: [2570/4518] 56% | Training loss: 0.6870573857646972
Epoch: 84 | Iteration number: [2580/4518] 57% | Training loss: 0.6870553714129352
Epoch: 84 | Iteration number: [2590/4518] 57% | Training loss: 0.6870584595387507
Epoch: 84 | Iteration number: [2600/4518] 57% | Training loss: 0.6870538760836308
Epoch: 84 | Iteration number: [2610/4518] 57% | Training loss: 0.6870548129310097
Epoch: 84 | Iteration number: [2620/4518] 57% | Training loss: 0.6870514069349711
Epoch: 84 | Iteration number: [2630/4518] 58% | Training loss: 0.6870513537310828
Epoch: 84 | Iteration number: [2640/4518] 58% | Training loss: 0.687049314989285
Epoch: 84 | Iteration number: [2650/4518] 58% | Training loss: 0.6870440282236855
Epoch: 84 | Iteration number: [2660/4518] 58% | Training loss: 0.6870422860957626
Epoch: 84 | Iteration number: [2670/4518] 59% | Training loss: 0.6870447221766697
Epoch: 84 | Iteration number: [2680/4518] 59% | Training loss: 0.6870441759255395
Epoch: 84 | Iteration number: [2690/4518] 59% | Training loss: 0.6870387683127449
Epoch: 84 | Iteration number: [2700/4518] 59% | Training loss: 0.6870363971259859
Epoch: 84 | Iteration number: [2710/4518] 59% | Training loss: 0.6870381420608817
Epoch: 84 | Iteration number: [2720/4518] 60% | Training loss: 0.687030982489095
Epoch: 84 | Iteration number: [2730/4518] 60% | Training loss: 0.6870274862963638
Epoch: 84 | Iteration number: [2740/4518] 60% | Training loss: 0.6870232317351946
Epoch: 84 | Iteration number: [2750/4518] 60% | Training loss: 0.6870190103704279
Epoch: 84 | Iteration number: [2760/4518] 61% | Training loss: 0.6870199536931687
Epoch: 84 | Iteration number: [2770/4518] 61% | Training loss: 0.6870170653942259
Epoch: 84 | Iteration number: [2780/4518] 61% | Training loss: 0.687015368977039
Epoch: 84 | Iteration number: [2790/4518] 61% | Training loss: 0.6870130822009083
Epoch: 84 | Iteration number: [2800/4518] 61% | Training loss: 0.6870122880807945
Epoch: 84 | Iteration number: [2810/4518] 62% | Training loss: 0.6870162991866522
Epoch: 84 | Iteration number: [2820/4518] 62% | Training loss: 0.6870193229288074
Epoch: 84 | Iteration number: [2830/4518] 62% | Training loss: 0.687019696694802
Epoch: 84 | Iteration number: [2840/4518] 62% | Training loss: 0.6870202161476646
Epoch: 84 | Iteration number: [2850/4518] 63% | Training loss: 0.6870188703035054
Epoch: 84 | Iteration number: [2860/4518] 63% | Training loss: 0.6870170114340483
Epoch: 84 | Iteration number: [2870/4518] 63% | Training loss: 0.6870115611195979
Epoch: 84 | Iteration number: [2880/4518] 63% | Training loss: 0.6870051784233915
Epoch: 84 | Iteration number: [2890/4518] 63% | Training loss: 0.6870024582712708
Epoch: 84 | Iteration number: [2900/4518] 64% | Training loss: 0.6870024724458826
Epoch: 84 | Iteration number: [2910/4518] 64% | Training loss: 0.6870009929658621
Epoch: 84 | Iteration number: [2920/4518] 64% | Training loss: 0.6869995447258427
Epoch: 84 | Iteration number: [2930/4518] 64% | Training loss: 0.6870007143696013
Epoch: 84 | Iteration number: [2940/4518] 65% | Training loss: 0.6870016657373532
Epoch: 84 | Iteration number: [2950/4518] 65% | Training loss: 0.6870021579831334
Epoch: 84 | Iteration number: [2960/4518] 65% | Training loss: 0.6870029259775136
Epoch: 84 | Iteration number: [2970/4518] 65% | Training loss: 0.6870033556162709
Epoch: 84 | Iteration number: [2980/4518] 65% | Training loss: 0.6870010088354149
Epoch: 84 | Iteration number: [2990/4518] 66% | Training loss: 0.687000205405181
Epoch: 84 | Iteration number: [3000/4518] 66% | Training loss: 0.6870006716450056
Epoch: 84 | Iteration number: [3010/4518] 66% | Training loss: 0.6869975367851827
Epoch: 84 | Iteration number: [3020/4518] 66% | Training loss: 0.6869970422312124
Epoch: 84 | Iteration number: [3030/4518] 67% | Training loss: 0.6869935256223081
Epoch: 84 | Iteration number: [3040/4518] 67% | Training loss: 0.6869928382337094
Epoch: 84 | Iteration number: [3050/4518] 67% | Training loss: 0.6869963604895795
Epoch: 84 | Iteration number: [3060/4518] 67% | Training loss: 0.6869910249523088
Epoch: 84 | Iteration number: [3070/4518] 67% | Training loss: 0.6869879104997902
Epoch: 84 | Iteration number: [3080/4518] 68% | Training loss: 0.6869886859283819
Epoch: 84 | Iteration number: [3090/4518] 68% | Training loss: 0.6869892248443801
Epoch: 84 | Iteration number: [3100/4518] 68% | Training loss: 0.6869886246419722
Epoch: 84 | Iteration number: [3110/4518] 68% | Training loss: 0.6869903067492212
Epoch: 84 | Iteration number: [3120/4518] 69% | Training loss: 0.6869913974633584
Epoch: 84 | Iteration number: [3130/4518] 69% | Training loss: 0.6869919307886982
Epoch: 84 | Iteration number: [3140/4518] 69% | Training loss: 0.686989418887029
Epoch: 84 | Iteration number: [3150/4518] 69% | Training loss: 0.6869862494771443
Epoch: 84 | Iteration number: [3160/4518] 69% | Training loss: 0.6869920311849329
Epoch: 84 | Iteration number: [3170/4518] 70% | Training loss: 0.6869906160921705
Epoch: 84 | Iteration number: [3180/4518] 70% | Training loss: 0.68698850133509
Epoch: 84 | Iteration number: [3190/4518] 70% | Training loss: 0.6869904934238864
Epoch: 84 | Iteration number: [3200/4518] 70% | Training loss: 0.6869865474291146
Epoch: 84 | Iteration number: [3210/4518] 71% | Training loss: 0.6869901921518866
Epoch: 84 | Iteration number: [3220/4518] 71% | Training loss: 0.6869909253549872
Epoch: 84 | Iteration number: [3230/4518] 71% | Training loss: 0.6869858218235866
Epoch: 84 | Iteration number: [3240/4518] 71% | Training loss: 0.6869866333258005
Epoch: 84 | Iteration number: [3250/4518] 71% | Training loss: 0.6869867740227626
Epoch: 84 | Iteration number: [3260/4518] 72% | Training loss: 0.6869856865128126
Epoch: 84 | Iteration number: [3270/4518] 72% | Training loss: 0.6869842573407958
Epoch: 84 | Iteration number: [3280/4518] 72% | Training loss: 0.6869877811248709
Epoch: 84 | Iteration number: [3290/4518] 72% | Training loss: 0.6869865847032484
Epoch: 84 | Iteration number: [3300/4518] 73% | Training loss: 0.6869840844291629
Epoch: 84 | Iteration number: [3310/4518] 73% | Training loss: 0.686978746342875
Epoch: 84 | Iteration number: [3320/4518] 73% | Training loss: 0.6869795027626566
Epoch: 84 | Iteration number: [3330/4518] 73% | Training loss: 0.6869799991627713
Epoch: 84 | Iteration number: [3340/4518] 73% | Training loss: 0.6869823024658386
Epoch: 84 | Iteration number: [3350/4518] 74% | Training loss: 0.6869841758528752
Epoch: 84 | Iteration number: [3360/4518] 74% | Training loss: 0.6869846003041381
Epoch: 84 | Iteration number: [3370/4518] 74% | Training loss: 0.6869824994211735
Epoch: 84 | Iteration number: [3380/4518] 74% | Training loss: 0.6869837751226312
Epoch: 84 | Iteration number: [3390/4518] 75% | Training loss: 0.6869862661424991
Epoch: 84 | Iteration number: [3400/4518] 75% | Training loss: 0.6869851846905316
Epoch: 84 | Iteration number: [3410/4518] 75% | Training loss: 0.6869815219707154
Epoch: 84 | Iteration number: [3420/4518] 75% | Training loss: 0.6869789422778358
Epoch: 84 | Iteration number: [3430/4518] 75% | Training loss: 0.6869768518921933
Epoch: 84 | Iteration number: [3440/4518] 76% | Training loss: 0.6869785340199637
Epoch: 84 | Iteration number: [3450/4518] 76% | Training loss: 0.6869801828308382
Epoch: 84 | Iteration number: [3460/4518] 76% | Training loss: 0.6869770713968774
Epoch: 84 | Iteration number: [3470/4518] 76% | Training loss: 0.6869774521599585
Epoch: 84 | Iteration number: [3480/4518] 77% | Training loss: 0.6869765857855479
Epoch: 84 | Iteration number: [3490/4518] 77% | Training loss: 0.6869721007210478
Epoch: 84 | Iteration number: [3500/4518] 77% | Training loss: 0.686973197902952
Epoch: 84 | Iteration number: [3510/4518] 77% | Training loss: 0.6869730079615558
Epoch: 84 | Iteration number: [3520/4518] 77% | Training loss: 0.6869720544327389
Epoch: 84 | Iteration number: [3530/4518] 78% | Training loss: 0.686972335563503
Epoch: 84 | Iteration number: [3540/4518] 78% | Training loss: 0.6869697457821355
Epoch: 84 | Iteration number: [3550/4518] 78% | Training loss: 0.686968586965346
Epoch: 84 | Iteration number: [3560/4518] 78% | Training loss: 0.6869667802466435
Epoch: 84 | Iteration number: [3570/4518] 79% | Training loss: 0.6869666426789527
Epoch: 84 | Iteration number: [3580/4518] 79% | Training loss: 0.6869655424489656
Epoch: 84 | Iteration number: [3590/4518] 79% | Training loss: 0.6869660462343593
Epoch: 84 | Iteration number: [3600/4518] 79% | Training loss: 0.6869655191898346
Epoch: 84 | Iteration number: [3610/4518] 79% | Training loss: 0.68696385562585
Epoch: 84 | Iteration number: [3620/4518] 80% | Training loss: 0.6869658404456976
Epoch: 84 | Iteration number: [3630/4518] 80% | Training loss: 0.6869670717348408
Epoch: 84 | Iteration number: [3640/4518] 80% | Training loss: 0.6869630961136504
Epoch: 84 | Iteration number: [3650/4518] 80% | Training loss: 0.6869623732240233
Epoch: 84 | Iteration number: [3660/4518] 81% | Training loss: 0.6869578129118258
Epoch: 84 | Iteration number: [3670/4518] 81% | Training loss: 0.6869544819200396
Epoch: 84 | Iteration number: [3680/4518] 81% | Training loss: 0.6869536759412807
Epoch: 84 | Iteration number: [3690/4518] 81% | Training loss: 0.6869498211678451
Epoch: 84 | Iteration number: [3700/4518] 81% | Training loss: 0.6869492765536179
Epoch: 84 | Iteration number: [3710/4518] 82% | Training loss: 0.6869498484700195
Epoch: 84 | Iteration number: [3720/4518] 82% | Training loss: 0.6869525608997191
Epoch: 84 | Iteration number: [3730/4518] 82% | Training loss: 0.6869513413861355
Epoch: 84 | Iteration number: [3740/4518] 82% | Training loss: 0.6869521833836714
Epoch: 84 | Iteration number: [3750/4518] 83% | Training loss: 0.6869492406050364
Epoch: 84 | Iteration number: [3760/4518] 83% | Training loss: 0.6869487249629295
Epoch: 84 | Iteration number: [3770/4518] 83% | Training loss: 0.6869485844509671
Epoch: 84 | Iteration number: [3780/4518] 83% | Training loss: 0.6869502480540957
Epoch: 84 | Iteration number: [3790/4518] 83% | Training loss: 0.6869481440741657
Epoch: 84 | Iteration number: [3800/4518] 84% | Training loss: 0.6869506427018266
Epoch: 84 | Iteration number: [3810/4518] 84% | Training loss: 0.6869491168050941
Epoch: 84 | Iteration number: [3820/4518] 84% | Training loss: 0.6869486810805285
Epoch: 84 | Iteration number: [3830/4518] 84% | Training loss: 0.6869509621793234
Epoch: 84 | Iteration number: [3840/4518] 84% | Training loss: 0.6869529309061666
Epoch: 84 | Iteration number: [3850/4518] 85% | Training loss: 0.6869519953603869
Epoch: 84 | Iteration number: [3860/4518] 85% | Training loss: 0.6869502612037363
Epoch: 84 | Iteration number: [3870/4518] 85% | Training loss: 0.6869490113523271
Epoch: 84 | Iteration number: [3880/4518] 85% | Training loss: 0.6869471129375635
Epoch: 84 | Iteration number: [3890/4518] 86% | Training loss: 0.6869485869658943
Epoch: 84 | Iteration number: [3900/4518] 86% | Training loss: 0.6869454148946664
Epoch: 84 | Iteration number: [3910/4518] 86% | Training loss: 0.6869434213546841
Epoch: 84 | Iteration number: [3920/4518] 86% | Training loss: 0.6869413516807313
Epoch: 84 | Iteration number: [3930/4518] 86% | Training loss: 0.6869406650387907
Epoch: 84 | Iteration number: [3940/4518] 87% | Training loss: 0.6869396980341316
Epoch: 84 | Iteration number: [3950/4518] 87% | Training loss: 0.6869380512871319
Epoch: 84 | Iteration number: [3960/4518] 87% | Training loss: 0.6869382598032855
Epoch: 84 | Iteration number: [3970/4518] 87% | Training loss: 0.6869332801034529
Epoch: 84 | Iteration number: [3980/4518] 88% | Training loss: 0.6869372754989557
Epoch: 84 | Iteration number: [3990/4518] 88% | Training loss: 0.6869391831987185
Epoch: 84 | Iteration number: [4000/4518] 88% | Training loss: 0.686936159580946
Epoch: 84 | Iteration number: [4010/4518] 88% | Training loss: 0.6869378847225646
Epoch: 84 | Iteration number: [4020/4518] 88% | Training loss: 0.6869391420290838
Epoch: 84 | Iteration number: [4030/4518] 89% | Training loss: 0.6869412317761121
Epoch: 84 | Iteration number: [4040/4518] 89% | Training loss: 0.686938021427924
Epoch: 84 | Iteration number: [4050/4518] 89% | Training loss: 0.6869332090719247
Epoch: 84 | Iteration number: [4060/4518] 89% | Training loss: 0.68692939147867
Epoch: 84 | Iteration number: [4070/4518] 90% | Training loss: 0.686928791042042
Epoch: 84 | Iteration number: [4080/4518] 90% | Training loss: 0.6869278261182354
Epoch: 84 | Iteration number: [4090/4518] 90% | Training loss: 0.686928656209069
Epoch: 84 | Iteration number: [4100/4518] 90% | Training loss: 0.6869288353512927
Epoch: 84 | Iteration number: [4110/4518] 90% | Training loss: 0.6869315837711604
Epoch: 84 | Iteration number: [4120/4518] 91% | Training loss: 0.6869320632184593
Epoch: 84 | Iteration number: [4130/4518] 91% | Training loss: 0.6869336063434657
Epoch: 84 | Iteration number: [4140/4518] 91% | Training loss: 0.6869334371913458
Epoch: 84 | Iteration number: [4150/4518] 91% | Training loss: 0.6869305177050901
Epoch: 84 | Iteration number: [4160/4518] 92% | Training loss: 0.6869264043151186
Epoch: 84 | Iteration number: [4170/4518] 92% | Training loss: 0.6869264337656309
Epoch: 84 | Iteration number: [4180/4518] 92% | Training loss: 0.6869275863233365
Epoch: 84 | Iteration number: [4190/4518] 92% | Training loss: 0.6869274908574498
Epoch: 84 | Iteration number: [4200/4518] 92% | Training loss: 0.6869259624254136
Epoch: 84 | Iteration number: [4210/4518] 93% | Training loss: 0.6869274832432174
Epoch: 84 | Iteration number: [4220/4518] 93% | Training loss: 0.6869266006901366
Epoch: 84 | Iteration number: [4230/4518] 93% | Training loss: 0.6869209830501682
Epoch: 84 | Iteration number: [4240/4518] 93% | Training loss: 0.6869174427018976
Epoch: 84 | Iteration number: [4250/4518] 94% | Training loss: 0.6869161074301776
Epoch: 84 | Iteration number: [4260/4518] 94% | Training loss: 0.6869177942124891
Epoch: 84 | Iteration number: [4270/4518] 94% | Training loss: 0.6869132025459611
Epoch: 84 | Iteration number: [4280/4518] 94% | Training loss: 0.6869107209215655
Epoch: 84 | Iteration number: [4290/4518] 94% | Training loss: 0.6869106872654184
Epoch: 84 | Iteration number: [4300/4518] 95% | Training loss: 0.6869103061737016
Epoch: 84 | Iteration number: [4310/4518] 95% | Training loss: 0.6869070600605897
Epoch: 84 | Iteration number: [4320/4518] 95% | Training loss: 0.6869055709077252
Epoch: 84 | Iteration number: [4330/4518] 95% | Training loss: 0.6869071889832169
Epoch: 84 | Iteration number: [4340/4518] 96% | Training loss: 0.6869072767996018
Epoch: 84 | Iteration number: [4350/4518] 96% | Training loss: 0.686905260620446
Epoch: 84 | Iteration number: [4360/4518] 96% | Training loss: 0.6869052877393338
Epoch: 84 | Iteration number: [4370/4518] 96% | Training loss: 0.6869048590518244
Epoch: 84 | Iteration number: [4380/4518] 96% | Training loss: 0.6869047260583808
Epoch: 84 | Iteration number: [4390/4518] 97% | Training loss: 0.6869066133314493
Epoch: 84 | Iteration number: [4400/4518] 97% | Training loss: 0.6869081710008058
Epoch: 84 | Iteration number: [4410/4518] 97% | Training loss: 0.6869095401834198
Epoch: 84 | Iteration number: [4420/4518] 97% | Training loss: 0.6869088295762895
Epoch: 84 | Iteration number: [4430/4518] 98% | Training loss: 0.6869082807821829
Epoch: 84 | Iteration number: [4440/4518] 98% | Training loss: 0.6869086693267564
Epoch: 84 | Iteration number: [4450/4518] 98% | Training loss: 0.6869065176235156
Epoch: 84 | Iteration number: [4460/4518] 98% | Training loss: 0.6869066865588518
Epoch: 84 | Iteration number: [4470/4518] 98% | Training loss: 0.6869086728266688
Epoch: 84 | Iteration number: [4480/4518] 99% | Training loss: 0.6869114918368203
Epoch: 84 | Iteration number: [4490/4518] 99% | Training loss: 0.6869144880691987
Epoch: 84 | Iteration number: [4500/4518] 99% | Training loss: 0.6869094424115287
Epoch: 84 | Iteration number: [4510/4518] 99% | Training loss: 0.6869088298069136

 End of epoch: 84 | Train Loss: 0.6867575871042046 | Training Time: 633 

 End of epoch: 84 | Eval Loss: 0.6895860421414278 | Evaluating Time: 17 
Epoch: 85 | Iteration number: [10/4518] 0% | Training loss: 0.7549092948436738
Epoch: 85 | Iteration number: [20/4518] 0% | Training loss: 0.7199160665273666
Epoch: 85 | Iteration number: [30/4518] 0% | Training loss: 0.7089151998360952
Epoch: 85 | Iteration number: [40/4518] 0% | Training loss: 0.7033130556344986
Epoch: 85 | Iteration number: [50/4518] 1% | Training loss: 0.7000556814670563
Epoch: 85 | Iteration number: [60/4518] 1% | Training loss: 0.6978959461053212
Epoch: 85 | Iteration number: [70/4518] 1% | Training loss: 0.6963645824364253
Epoch: 85 | Iteration number: [80/4518] 1% | Training loss: 0.6950904510915279
Epoch: 85 | Iteration number: [90/4518] 1% | Training loss: 0.6941403766473134
Epoch: 85 | Iteration number: [100/4518] 2% | Training loss: 0.6935092878341674
Epoch: 85 | Iteration number: [110/4518] 2% | Training loss: 0.6930074881423604
Epoch: 85 | Iteration number: [120/4518] 2% | Training loss: 0.6925431549549103
Epoch: 85 | Iteration number: [130/4518] 2% | Training loss: 0.6920708417892456
Epoch: 85 | Iteration number: [140/4518] 3% | Training loss: 0.6916620360953467
Epoch: 85 | Iteration number: [150/4518] 3% | Training loss: 0.6914175947507223
Epoch: 85 | Iteration number: [160/4518] 3% | Training loss: 0.6911177717149257
Epoch: 85 | Iteration number: [170/4518] 3% | Training loss: 0.6908832451876472
Epoch: 85 | Iteration number: [180/4518] 3% | Training loss: 0.6906584481398265
Epoch: 85 | Iteration number: [190/4518] 4% | Training loss: 0.6903920007379432
Epoch: 85 | Iteration number: [200/4518] 4% | Training loss: 0.6902266451716423
Epoch: 85 | Iteration number: [210/4518] 4% | Training loss: 0.6900808447883242
Epoch: 85 | Iteration number: [220/4518] 4% | Training loss: 0.6899662692438472
Epoch: 85 | Iteration number: [230/4518] 5% | Training loss: 0.6898520239021467
Epoch: 85 | Iteration number: [240/4518] 5% | Training loss: 0.6897429938117663
Epoch: 85 | Iteration number: [250/4518] 5% | Training loss: 0.6896347725391387
Epoch: 85 | Iteration number: [260/4518] 5% | Training loss: 0.6895388506926023
Epoch: 85 | Iteration number: [270/4518] 5% | Training loss: 0.6894323110580445
Epoch: 85 | Iteration number: [280/4518] 6% | Training loss: 0.6893320973430361
Epoch: 85 | Iteration number: [290/4518] 6% | Training loss: 0.689274150955266
Epoch: 85 | Iteration number: [300/4518] 6% | Training loss: 0.6892125004529953
Epoch: 85 | Iteration number: [310/4518] 6% | Training loss: 0.6891469928526109
Epoch: 85 | Iteration number: [320/4518] 7% | Training loss: 0.6890981681644917
Epoch: 85 | Iteration number: [330/4518] 7% | Training loss: 0.6890745634382421
Epoch: 85 | Iteration number: [340/4518] 7% | Training loss: 0.6890315646634383
Epoch: 85 | Iteration number: [350/4518] 7% | Training loss: 0.6890104373863765
Epoch: 85 | Iteration number: [360/4518] 7% | Training loss: 0.688936861190531
Epoch: 85 | Iteration number: [370/4518] 8% | Training loss: 0.6888650444713799
Epoch: 85 | Iteration number: [380/4518] 8% | Training loss: 0.6888558543042133
Epoch: 85 | Iteration number: [390/4518] 8% | Training loss: 0.688782717478581
Epoch: 85 | Iteration number: [400/4518] 8% | Training loss: 0.688738539069891
Epoch: 85 | Iteration number: [410/4518] 9% | Training loss: 0.6886900259227288
Epoch: 85 | Iteration number: [420/4518] 9% | Training loss: 0.6886457071417854
Epoch: 85 | Iteration number: [430/4518] 9% | Training loss: 0.688607544954433
Epoch: 85 | Iteration number: [440/4518] 9% | Training loss: 0.6885498974810947
Epoch: 85 | Iteration number: [450/4518] 9% | Training loss: 0.6884951298766666
Epoch: 85 | Iteration number: [460/4518] 10% | Training loss: 0.6884558570125828
Epoch: 85 | Iteration number: [470/4518] 10% | Training loss: 0.6883884925791558
Epoch: 85 | Iteration number: [480/4518] 10% | Training loss: 0.6883294485509396
Epoch: 85 | Iteration number: [490/4518] 10% | Training loss: 0.6882718203019123
Epoch: 85 | Iteration number: [500/4518] 11% | Training loss: 0.6882362110614777
Epoch: 85 | Iteration number: [510/4518] 11% | Training loss: 0.6881790316572376
Epoch: 85 | Iteration number: [520/4518] 11% | Training loss: 0.6881579229464898
Epoch: 85 | Iteration number: [530/4518] 11% | Training loss: 0.6881717254530709
Epoch: 85 | Iteration number: [540/4518] 11% | Training loss: 0.6881106995873981
Epoch: 85 | Iteration number: [550/4518] 12% | Training loss: 0.6880997879938646
Epoch: 85 | Iteration number: [560/4518] 12% | Training loss: 0.6880707873829773
Epoch: 85 | Iteration number: [570/4518] 12% | Training loss: 0.6880785331391451
Epoch: 85 | Iteration number: [580/4518] 12% | Training loss: 0.6880379675791182
Epoch: 85 | Iteration number: [590/4518] 13% | Training loss: 0.6880126943022518
Epoch: 85 | Iteration number: [600/4518] 13% | Training loss: 0.6879916247725487
Epoch: 85 | Iteration number: [610/4518] 13% | Training loss: 0.6879896765849629
Epoch: 85 | Iteration number: [620/4518] 13% | Training loss: 0.6879760092304599
Epoch: 85 | Iteration number: [630/4518] 13% | Training loss: 0.6879393706246028
Epoch: 85 | Iteration number: [640/4518] 14% | Training loss: 0.6879080944694579
Epoch: 85 | Iteration number: [650/4518] 14% | Training loss: 0.6879088237652412
Epoch: 85 | Iteration number: [660/4518] 14% | Training loss: 0.6878826330105464
Epoch: 85 | Iteration number: [670/4518] 14% | Training loss: 0.6878817245141784
Epoch: 85 | Iteration number: [680/4518] 15% | Training loss: 0.6878540379159591
Epoch: 85 | Iteration number: [690/4518] 15% | Training loss: 0.6878212367278942
Epoch: 85 | Iteration number: [700/4518] 15% | Training loss: 0.6878069872515542
Epoch: 85 | Iteration number: [710/4518] 15% | Training loss: 0.6877969830808505
Epoch: 85 | Iteration number: [720/4518] 15% | Training loss: 0.6877822621001137
Epoch: 85 | Iteration number: [730/4518] 16% | Training loss: 0.6877841043145689
Epoch: 85 | Iteration number: [740/4518] 16% | Training loss: 0.687756359577179
Epoch: 85 | Iteration number: [750/4518] 16% | Training loss: 0.6877381239732107
Epoch: 85 | Iteration number: [760/4518] 16% | Training loss: 0.6877355232834816
Epoch: 85 | Iteration number: [770/4518] 17% | Training loss: 0.6877393370324915
Epoch: 85 | Iteration number: [780/4518] 17% | Training loss: 0.6877323612952844
Epoch: 85 | Iteration number: [790/4518] 17% | Training loss: 0.6877240949793707
Epoch: 85 | Iteration number: [800/4518] 17% | Training loss: 0.6877060352265835
Epoch: 85 | Iteration number: [810/4518] 17% | Training loss: 0.6876935405495727
Epoch: 85 | Iteration number: [820/4518] 18% | Training loss: 0.68768077747124
Epoch: 85 | Iteration number: [830/4518] 18% | Training loss: 0.6876556026648326
Epoch: 85 | Iteration number: [840/4518] 18% | Training loss: 0.6876538046059154
Epoch: 85 | Iteration number: [850/4518] 18% | Training loss: 0.6876538600641139
Epoch: 85 | Iteration number: [860/4518] 19% | Training loss: 0.6876306314801061
Epoch: 85 | Iteration number: [870/4518] 19% | Training loss: 0.6876249265396732
Epoch: 85 | Iteration number: [880/4518] 19% | Training loss: 0.6876213465224613
Epoch: 85 | Iteration number: [890/4518] 19% | Training loss: 0.6876144335511025
Epoch: 85 | Iteration number: [900/4518] 19% | Training loss: 0.6876069193416171
Epoch: 85 | Iteration number: [910/4518] 20% | Training loss: 0.6875870906389676
Epoch: 85 | Iteration number: [920/4518] 20% | Training loss: 0.6875695012185885
Epoch: 85 | Iteration number: [930/4518] 20% | Training loss: 0.6875661559643284
Epoch: 85 | Iteration number: [940/4518] 20% | Training loss: 0.6875464563040024
Epoch: 85 | Iteration number: [950/4518] 21% | Training loss: 0.6875347201447738
Epoch: 85 | Iteration number: [960/4518] 21% | Training loss: 0.6875314607595404
Epoch: 85 | Iteration number: [970/4518] 21% | Training loss: 0.6875379159278476
Epoch: 85 | Iteration number: [980/4518] 21% | Training loss: 0.687523869288211
Epoch: 85 | Iteration number: [990/4518] 21% | Training loss: 0.6875108738740285
Epoch: 85 | Iteration number: [1000/4518] 22% | Training loss: 0.6875001345276832
Epoch: 85 | Iteration number: [1010/4518] 22% | Training loss: 0.6874905433985267
Epoch: 85 | Iteration number: [1020/4518] 22% | Training loss: 0.6874730657128727
Epoch: 85 | Iteration number: [1030/4518] 22% | Training loss: 0.6874687526411223
Epoch: 85 | Iteration number: [1040/4518] 23% | Training loss: 0.6874614725319239
Epoch: 85 | Iteration number: [1050/4518] 23% | Training loss: 0.6874534251008715
Epoch: 85 | Iteration number: [1060/4518] 23% | Training loss: 0.6874455382239144
Epoch: 85 | Iteration number: [1070/4518] 23% | Training loss: 0.687447669517214
Epoch: 85 | Iteration number: [1080/4518] 23% | Training loss: 0.6874421785275141
Epoch: 85 | Iteration number: [1090/4518] 24% | Training loss: 0.6874317715474225
Epoch: 85 | Iteration number: [1100/4518] 24% | Training loss: 0.6874270204522392
Epoch: 85 | Iteration number: [1110/4518] 24% | Training loss: 0.6874224937713898
Epoch: 85 | Iteration number: [1120/4518] 24% | Training loss: 0.6874226969799825
Epoch: 85 | Iteration number: [1130/4518] 25% | Training loss: 0.6874174008854722
Epoch: 85 | Iteration number: [1140/4518] 25% | Training loss: 0.6874145726885712
Epoch: 85 | Iteration number: [1150/4518] 25% | Training loss: 0.6874059749167899
Epoch: 85 | Iteration number: [1160/4518] 25% | Training loss: 0.6874075883421404
Epoch: 85 | Iteration number: [1170/4518] 25% | Training loss: 0.6874023026890225
Epoch: 85 | Iteration number: [1180/4518] 26% | Training loss: 0.6874019943556543
Epoch: 85 | Iteration number: [1190/4518] 26% | Training loss: 0.6873800244651923
Epoch: 85 | Iteration number: [1200/4518] 26% | Training loss: 0.6873768199483553
Epoch: 85 | Iteration number: [1210/4518] 26% | Training loss: 0.6873648537584572
Epoch: 85 | Iteration number: [1220/4518] 27% | Training loss: 0.6873540760552297
Epoch: 85 | Iteration number: [1230/4518] 27% | Training loss: 0.687352044940964
Epoch: 85 | Iteration number: [1240/4518] 27% | Training loss: 0.6873627383382089
Epoch: 85 | Iteration number: [1250/4518] 27% | Training loss: 0.6873574917793274
Epoch: 85 | Iteration number: [1260/4518] 27% | Training loss: 0.687348132663303
Epoch: 85 | Iteration number: [1270/4518] 28% | Training loss: 0.6873506290706124
Epoch: 85 | Iteration number: [1280/4518] 28% | Training loss: 0.687353517441079
Epoch: 85 | Iteration number: [1290/4518] 28% | Training loss: 0.6873419090758922
Epoch: 85 | Iteration number: [1300/4518] 28% | Training loss: 0.6873374402981538
Epoch: 85 | Iteration number: [1310/4518] 28% | Training loss: 0.6873328314482711
Epoch: 85 | Iteration number: [1320/4518] 29% | Training loss: 0.6873257055427089
Epoch: 85 | Iteration number: [1330/4518] 29% | Training loss: 0.6873200051766589
Epoch: 85 | Iteration number: [1340/4518] 29% | Training loss: 0.68731377480635
Epoch: 85 | Iteration number: [1350/4518] 29% | Training loss: 0.6873087828247636
Epoch: 85 | Iteration number: [1360/4518] 30% | Training loss: 0.6872975580394268
Epoch: 85 | Iteration number: [1370/4518] 30% | Training loss: 0.6872961937946125
Epoch: 85 | Iteration number: [1380/4518] 30% | Training loss: 0.687294436364934
Epoch: 85 | Iteration number: [1390/4518] 30% | Training loss: 0.6872865248927109
Epoch: 85 | Iteration number: [1400/4518] 30% | Training loss: 0.6872846551026617
Epoch: 85 | Iteration number: [1410/4518] 31% | Training loss: 0.6872828912227712
Epoch: 85 | Iteration number: [1420/4518] 31% | Training loss: 0.6872853078472783
Epoch: 85 | Iteration number: [1430/4518] 31% | Training loss: 0.687279069757128
Epoch: 85 | Iteration number: [1440/4518] 31% | Training loss: 0.6872810474286477
Epoch: 85 | Iteration number: [1450/4518] 32% | Training loss: 0.6872747721343205
Epoch: 85 | Iteration number: [1460/4518] 32% | Training loss: 0.6872666853747956
Epoch: 85 | Iteration number: [1470/4518] 32% | Training loss: 0.6872604885474354
Epoch: 85 | Iteration number: [1480/4518] 32% | Training loss: 0.6872573755480148
Epoch: 85 | Iteration number: [1490/4518] 32% | Training loss: 0.6872497932222865
Epoch: 85 | Iteration number: [1500/4518] 33% | Training loss: 0.6872467046578725
Epoch: 85 | Iteration number: [1510/4518] 33% | Training loss: 0.6872397415685337
Epoch: 85 | Iteration number: [1520/4518] 33% | Training loss: 0.6872396952227542
Epoch: 85 | Iteration number: [1530/4518] 33% | Training loss: 0.6872227653179294
Epoch: 85 | Iteration number: [1540/4518] 34% | Training loss: 0.6872189121586936
Epoch: 85 | Iteration number: [1550/4518] 34% | Training loss: 0.6872147889291087
Epoch: 85 | Iteration number: [1560/4518] 34% | Training loss: 0.6872086270879476
Epoch: 85 | Iteration number: [1570/4518] 34% | Training loss: 0.6872068909702786
Epoch: 85 | Iteration number: [1580/4518] 34% | Training loss: 0.6872099639871453
Epoch: 85 | Iteration number: [1590/4518] 35% | Training loss: 0.6872063091715926
Epoch: 85 | Iteration number: [1600/4518] 35% | Training loss: 0.6872043069452047
Epoch: 85 | Iteration number: [1610/4518] 35% | Training loss: 0.6871996781100398
Epoch: 85 | Iteration number: [1620/4518] 35% | Training loss: 0.6872000249079716
Epoch: 85 | Iteration number: [1630/4518] 36% | Training loss: 0.6871966627112196
Epoch: 85 | Iteration number: [1640/4518] 36% | Training loss: 0.687193422928089
Epoch: 85 | Iteration number: [1650/4518] 36% | Training loss: 0.6871820809624412
Epoch: 85 | Iteration number: [1660/4518] 36% | Training loss: 0.6871824304382486
Epoch: 85 | Iteration number: [1670/4518] 36% | Training loss: 0.6871762371705677
Epoch: 85 | Iteration number: [1680/4518] 37% | Training loss: 0.6871636385718981
Epoch: 85 | Iteration number: [1690/4518] 37% | Training loss: 0.687161154612987
Epoch: 85 | Iteration number: [1700/4518] 37% | Training loss: 0.6871638740160886
Epoch: 85 | Iteration number: [1710/4518] 37% | Training loss: 0.6871614282939866
Epoch: 85 | Iteration number: [1720/4518] 38% | Training loss: 0.6871602611832841
Epoch: 85 | Iteration number: [1730/4518] 38% | Training loss: 0.6871536462293195
Epoch: 85 | Iteration number: [1740/4518] 38% | Training loss: 0.6871534291355089
Epoch: 85 | Iteration number: [1750/4518] 38% | Training loss: 0.6871517056056431
Epoch: 85 | Iteration number: [1760/4518] 38% | Training loss: 0.6871492976492102
Epoch: 85 | Iteration number: [1770/4518] 39% | Training loss: 0.6871483773161462
Epoch: 85 | Iteration number: [1780/4518] 39% | Training loss: 0.6871418597323171
Epoch: 85 | Iteration number: [1790/4518] 39% | Training loss: 0.6871461526308645
Epoch: 85 | Iteration number: [1800/4518] 39% | Training loss: 0.6871451924906836
Epoch: 85 | Iteration number: [1810/4518] 40% | Training loss: 0.687136919425996
Epoch: 85 | Iteration number: [1820/4518] 40% | Training loss: 0.68713848227328
Epoch: 85 | Iteration number: [1830/4518] 40% | Training loss: 0.6871392466982857
Epoch: 85 | Iteration number: [1840/4518] 40% | Training loss: 0.6871341910375202
Epoch: 85 | Iteration number: [1850/4518] 40% | Training loss: 0.687133150100708
Epoch: 85 | Iteration number: [1860/4518] 41% | Training loss: 0.6871263731230972
Epoch: 85 | Iteration number: [1870/4518] 41% | Training loss: 0.687122379617895
Epoch: 85 | Iteration number: [1880/4518] 41% | Training loss: 0.6871142327785492
Epoch: 85 | Iteration number: [1890/4518] 41% | Training loss: 0.6871236019033603
Epoch: 85 | Iteration number: [1900/4518] 42% | Training loss: 0.6871149220592098
Epoch: 85 | Iteration number: [1910/4518] 42% | Training loss: 0.6871122369279412
Epoch: 85 | Iteration number: [1920/4518] 42% | Training loss: 0.6871092006874581
Epoch: 85 | Iteration number: [1930/4518] 42% | Training loss: 0.6871065867379539
Epoch: 85 | Iteration number: [1940/4518] 42% | Training loss: 0.6871023087464657
Epoch: 85 | Iteration number: [1950/4518] 43% | Training loss: 0.6871030970108815
Epoch: 85 | Iteration number: [1960/4518] 43% | Training loss: 0.6871019189150966
Epoch: 85 | Iteration number: [1970/4518] 43% | Training loss: 0.6870976107677227
Epoch: 85 | Iteration number: [1980/4518] 43% | Training loss: 0.6870879233786554
Epoch: 85 | Iteration number: [1990/4518] 44% | Training loss: 0.6870894111880106
Epoch: 85 | Iteration number: [2000/4518] 44% | Training loss: 0.6870851014852524
Epoch: 85 | Iteration number: [2010/4518] 44% | Training loss: 0.6870790987168972
Epoch: 85 | Iteration number: [2020/4518] 44% | Training loss: 0.687080940014065
Epoch: 85 | Iteration number: [2030/4518] 44% | Training loss: 0.6870741710580629
Epoch: 85 | Iteration number: [2040/4518] 45% | Training loss: 0.6870690168118945
Epoch: 85 | Iteration number: [2050/4518] 45% | Training loss: 0.6870716545349214
Epoch: 85 | Iteration number: [2060/4518] 45% | Training loss: 0.6870670298638853
Epoch: 85 | Iteration number: [2070/4518] 45% | Training loss: 0.6870673721539226
Epoch: 85 | Iteration number: [2080/4518] 46% | Training loss: 0.6870647075084539
Epoch: 85 | Iteration number: [2090/4518] 46% | Training loss: 0.6870645341120268
Epoch: 85 | Iteration number: [2100/4518] 46% | Training loss: 0.6870643430664426
Epoch: 85 | Iteration number: [2110/4518] 46% | Training loss: 0.687067492680527
Epoch: 85 | Iteration number: [2120/4518] 46% | Training loss: 0.6870692567724102
Epoch: 85 | Iteration number: [2130/4518] 47% | Training loss: 0.6870679239991685
Epoch: 85 | Iteration number: [2140/4518] 47% | Training loss: 0.6870700417835022
Epoch: 85 | Iteration number: [2150/4518] 47% | Training loss: 0.687065067679383
Epoch: 85 | Iteration number: [2160/4518] 47% | Training loss: 0.6870583236769393
Epoch: 85 | Iteration number: [2170/4518] 48% | Training loss: 0.6870577674307582
Epoch: 85 | Iteration number: [2180/4518] 48% | Training loss: 0.687049368379313
Epoch: 85 | Iteration number: [2190/4518] 48% | Training loss: 0.6870526567986023
Epoch: 85 | Iteration number: [2200/4518] 48% | Training loss: 0.6870542893084612
Epoch: 85 | Iteration number: [2210/4518] 48% | Training loss: 0.6870515909399921
Epoch: 85 | Iteration number: [2220/4518] 49% | Training loss: 0.6870421914635478
Epoch: 85 | Iteration number: [2230/4518] 49% | Training loss: 0.6870376083348364
Epoch: 85 | Iteration number: [2240/4518] 49% | Training loss: 0.6870367153148565
Epoch: 85 | Iteration number: [2250/4518] 49% | Training loss: 0.6870392181608412
Epoch: 85 | Iteration number: [2260/4518] 50% | Training loss: 0.6870368789782566
Epoch: 85 | Iteration number: [2270/4518] 50% | Training loss: 0.6870334618942328
Epoch: 85 | Iteration number: [2280/4518] 50% | Training loss: 0.6870278358198049
Epoch: 85 | Iteration number: [2290/4518] 50% | Training loss: 0.6870229365003161
Epoch: 85 | Iteration number: [2300/4518] 50% | Training loss: 0.687028798720111
Epoch: 85 | Iteration number: [2310/4518] 51% | Training loss: 0.6870322311337376
Epoch: 85 | Iteration number: [2320/4518] 51% | Training loss: 0.6870303019110499
Epoch: 85 | Iteration number: [2330/4518] 51% | Training loss: 0.6870275188413301
Epoch: 85 | Iteration number: [2340/4518] 51% | Training loss: 0.6870278371195507
Epoch: 85 | Iteration number: [2350/4518] 52% | Training loss: 0.687028096635291
Epoch: 85 | Iteration number: [2360/4518] 52% | Training loss: 0.6870329526773954
Epoch: 85 | Iteration number: [2370/4518] 52% | Training loss: 0.6870336078641787
Epoch: 85 | Iteration number: [2380/4518] 52% | Training loss: 0.687029558670621
Epoch: 85 | Iteration number: [2390/4518] 52% | Training loss: 0.6870253804338528
Epoch: 85 | Iteration number: [2400/4518] 53% | Training loss: 0.6870249156653881
Epoch: 85 | Iteration number: [2410/4518] 53% | Training loss: 0.6870281385682925
Epoch: 85 | Iteration number: [2420/4518] 53% | Training loss: 0.6870246062594012
Epoch: 85 | Iteration number: [2430/4518] 53% | Training loss: 0.6870231811647062
Epoch: 85 | Iteration number: [2440/4518] 54% | Training loss: 0.6870207003394111
Epoch: 85 | Iteration number: [2450/4518] 54% | Training loss: 0.6870215113552249
Epoch: 85 | Iteration number: [2460/4518] 54% | Training loss: 0.6870223109799672
Epoch: 85 | Iteration number: [2470/4518] 54% | Training loss: 0.6870171489985848
Epoch: 85 | Iteration number: [2480/4518] 54% | Training loss: 0.6870154600229955
Epoch: 85 | Iteration number: [2490/4518] 55% | Training loss: 0.6870127432317619
Epoch: 85 | Iteration number: [2500/4518] 55% | Training loss: 0.687013778424263
Epoch: 85 | Iteration number: [2510/4518] 55% | Training loss: 0.6870107437747408
Epoch: 85 | Iteration number: [2520/4518] 55% | Training loss: 0.6870111683294886
Epoch: 85 | Iteration number: [2530/4518] 55% | Training loss: 0.6870086124763187
Epoch: 85 | Iteration number: [2540/4518] 56% | Training loss: 0.6870031809712959
Epoch: 85 | Iteration number: [2550/4518] 56% | Training loss: 0.6870027790583816
Epoch: 85 | Iteration number: [2560/4518] 56% | Training loss: 0.6870089023839683
Epoch: 85 | Iteration number: [2570/4518] 56% | Training loss: 0.6870053948595366
Epoch: 85 | Iteration number: [2580/4518] 57% | Training loss: 0.6870011223841083
Epoch: 85 | Iteration number: [2590/4518] 57% | Training loss: 0.6869966886448584
Epoch: 85 | Iteration number: [2600/4518] 57% | Training loss: 0.6869928614680584
Epoch: 85 | Iteration number: [2610/4518] 57% | Training loss: 0.6869935657329487
Epoch: 85 | Iteration number: [2620/4518] 57% | Training loss: 0.6869948240181872
Epoch: 85 | Iteration number: [2630/4518] 58% | Training loss: 0.6869910941831059
Epoch: 85 | Iteration number: [2640/4518] 58% | Training loss: 0.6869919576428153
Epoch: 85 | Iteration number: [2650/4518] 58% | Training loss: 0.6869945008349868
Epoch: 85 | Iteration number: [2660/4518] 58% | Training loss: 0.686993282002614
Epoch: 85 | Iteration number: [2670/4518] 59% | Training loss: 0.6869954546069384
Epoch: 85 | Iteration number: [2680/4518] 59% | Training loss: 0.686994609637047
Epoch: 85 | Iteration number: [2690/4518] 59% | Training loss: 0.686991636371967
Epoch: 85 | Iteration number: [2700/4518] 59% | Training loss: 0.6869907025496165
Epoch: 85 | Iteration number: [2710/4518] 59% | Training loss: 0.686989676160566
Epoch: 85 | Iteration number: [2720/4518] 60% | Training loss: 0.6869856707532617
Epoch: 85 | Iteration number: [2730/4518] 60% | Training loss: 0.6869852185685993
Epoch: 85 | Iteration number: [2740/4518] 60% | Training loss: 0.6869841151646454
Epoch: 85 | Iteration number: [2750/4518] 60% | Training loss: 0.6869830950390209
Epoch: 85 | Iteration number: [2760/4518] 61% | Training loss: 0.6869791876578677
Epoch: 85 | Iteration number: [2770/4518] 61% | Training loss: 0.6869831747526727
Epoch: 85 | Iteration number: [2780/4518] 61% | Training loss: 0.6869811074982444
Epoch: 85 | Iteration number: [2790/4518] 61% | Training loss: 0.6869835054148056
Epoch: 85 | Iteration number: [2800/4518] 61% | Training loss: 0.6869806914883001
Epoch: 85 | Iteration number: [2810/4518] 62% | Training loss: 0.6869762935884483
Epoch: 85 | Iteration number: [2820/4518] 62% | Training loss: 0.6869736983843729
Epoch: 85 | Iteration number: [2830/4518] 62% | Training loss: 0.6869745951659266
Epoch: 85 | Iteration number: [2840/4518] 62% | Training loss: 0.6869698319426725
Epoch: 85 | Iteration number: [2850/4518] 63% | Training loss: 0.6869696635321567
Epoch: 85 | Iteration number: [2860/4518] 63% | Training loss: 0.6869660825162501
Epoch: 85 | Iteration number: [2870/4518] 63% | Training loss: 0.6869649444722963
Epoch: 85 | Iteration number: [2880/4518] 63% | Training loss: 0.6869635082781315
Epoch: 85 | Iteration number: [2890/4518] 63% | Training loss: 0.6869634173320651
Epoch: 85 | Iteration number: [2900/4518] 64% | Training loss: 0.686963003997145
Epoch: 85 | Iteration number: [2910/4518] 64% | Training loss: 0.6869653447387145
Epoch: 85 | Iteration number: [2920/4518] 64% | Training loss: 0.6869658580993953
Epoch: 85 | Iteration number: [2930/4518] 64% | Training loss: 0.6869662925651863
Epoch: 85 | Iteration number: [2940/4518] 65% | Training loss: 0.6869639350037996
Epoch: 85 | Iteration number: [2950/4518] 65% | Training loss: 0.6869614593457367
Epoch: 85 | Iteration number: [2960/4518] 65% | Training loss: 0.6869652462368075
Epoch: 85 | Iteration number: [2970/4518] 65% | Training loss: 0.6869653064594525
Epoch: 85 | Iteration number: [2980/4518] 65% | Training loss: 0.6869683542907637
Epoch: 85 | Iteration number: [2990/4518] 66% | Training loss: 0.6869658114918099
Epoch: 85 | Iteration number: [3000/4518] 66% | Training loss: 0.6869633796215058
Epoch: 85 | Iteration number: [3010/4518] 66% | Training loss: 0.6869629491801278
Epoch: 85 | Iteration number: [3020/4518] 66% | Training loss: 0.6869633563899047
Epoch: 85 | Iteration number: [3030/4518] 67% | Training loss: 0.6869650787449513
Epoch: 85 | Iteration number: [3040/4518] 67% | Training loss: 0.6869653282785102
Epoch: 85 | Iteration number: [3050/4518] 67% | Training loss: 0.6869666852911965
Epoch: 85 | Iteration number: [3060/4518] 67% | Training loss: 0.6869639640150507
Epoch: 85 | Iteration number: [3070/4518] 67% | Training loss: 0.6869655517296993
Epoch: 85 | Iteration number: [3080/4518] 68% | Training loss: 0.6869653474200855
Epoch: 85 | Iteration number: [3090/4518] 68% | Training loss: 0.6869720199540209
Epoch: 85 | Iteration number: [3100/4518] 68% | Training loss: 0.6869675397488378
Epoch: 85 | Iteration number: [3110/4518] 68% | Training loss: 0.6869669867098523
Epoch: 85 | Iteration number: [3120/4518] 69% | Training loss: 0.6869692773582079
Epoch: 85 | Iteration number: [3130/4518] 69% | Training loss: 0.6869700001832395
Epoch: 85 | Iteration number: [3140/4518] 69% | Training loss: 0.6869709546588788
Epoch: 85 | Iteration number: [3150/4518] 69% | Training loss: 0.686973824557804
Epoch: 85 | Iteration number: [3160/4518] 69% | Training loss: 0.6869767745650267
Epoch: 85 | Iteration number: [3170/4518] 70% | Training loss: 0.6869746871175074
Epoch: 85 | Iteration number: [3180/4518] 70% | Training loss: 0.6869720574632381
Epoch: 85 | Iteration number: [3190/4518] 70% | Training loss: 0.6869725847692699
Epoch: 85 | Iteration number: [3200/4518] 70% | Training loss: 0.6869740576297044
Epoch: 85 | Iteration number: [3210/4518] 71% | Training loss: 0.6869743955840946
Epoch: 85 | Iteration number: [3220/4518] 71% | Training loss: 0.6869749194531707
Epoch: 85 | Iteration number: [3230/4518] 71% | Training loss: 0.6869743972370869
Epoch: 85 | Iteration number: [3240/4518] 71% | Training loss: 0.6869755212723473
Epoch: 85 | Iteration number: [3250/4518] 71% | Training loss: 0.6869779249154604
Epoch: 85 | Iteration number: [3260/4518] 72% | Training loss: 0.6869764573917798
Epoch: 85 | Iteration number: [3270/4518] 72% | Training loss: 0.6869765191996863
Epoch: 85 | Iteration number: [3280/4518] 72% | Training loss: 0.6869762317618219
Epoch: 85 | Iteration number: [3290/4518] 72% | Training loss: 0.6869774151355662
Epoch: 85 | Iteration number: [3300/4518] 73% | Training loss: 0.6869760631250613
Epoch: 85 | Iteration number: [3310/4518] 73% | Training loss: 0.6869710138737255
Epoch: 85 | Iteration number: [3320/4518] 73% | Training loss: 0.6869648684220142
Epoch: 85 | Iteration number: [3330/4518] 73% | Training loss: 0.6869655179189849
Epoch: 85 | Iteration number: [3340/4518] 73% | Training loss: 0.6869649566219238
Epoch: 85 | Iteration number: [3350/4518] 74% | Training loss: 0.6869643717203567
Epoch: 85 | Iteration number: [3360/4518] 74% | Training loss: 0.6869606991254148
Epoch: 85 | Iteration number: [3370/4518] 74% | Training loss: 0.6869608731581125
Epoch: 85 | Iteration number: [3380/4518] 74% | Training loss: 0.6869602658163161
Epoch: 85 | Iteration number: [3390/4518] 75% | Training loss: 0.6869613538097843
Epoch: 85 | Iteration number: [3400/4518] 75% | Training loss: 0.686959893756053
Epoch: 85 | Iteration number: [3410/4518] 75% | Training loss: 0.6869635535824683
Epoch: 85 | Iteration number: [3420/4518] 75% | Training loss: 0.6869644056112446
Epoch: 85 | Iteration number: [3430/4518] 75% | Training loss: 0.6869664664518729
Epoch: 85 | Iteration number: [3440/4518] 76% | Training loss: 0.68696426960618
Epoch: 85 | Iteration number: [3450/4518] 76% | Training loss: 0.6869597865187603
Epoch: 85 | Iteration number: [3460/4518] 76% | Training loss: 0.6869634116143849
Epoch: 85 | Iteration number: [3470/4518] 76% | Training loss: 0.6869591176509857
Epoch: 85 | Iteration number: [3480/4518] 77% | Training loss: 0.6869596589228203
Epoch: 85 | Iteration number: [3490/4518] 77% | Training loss: 0.6869596469197369
Epoch: 85 | Iteration number: [3500/4518] 77% | Training loss: 0.6869612034218652
Epoch: 85 | Iteration number: [3510/4518] 77% | Training loss: 0.6869580159669588
Epoch: 85 | Iteration number: [3520/4518] 77% | Training loss: 0.6869598516178402
Epoch: 85 | Iteration number: [3530/4518] 78% | Training loss: 0.6869558491720357
Epoch: 85 | Iteration number: [3540/4518] 78% | Training loss: 0.6869508089655537
Epoch: 85 | Iteration number: [3550/4518] 78% | Training loss: 0.6869491645148103
Epoch: 85 | Iteration number: [3560/4518] 78% | Training loss: 0.6869516408342994
Epoch: 85 | Iteration number: [3570/4518] 79% | Training loss: 0.6869531600081287
Epoch: 85 | Iteration number: [3580/4518] 79% | Training loss: 0.6869547142496322
Epoch: 85 | Iteration number: [3590/4518] 79% | Training loss: 0.6869550256011878
Epoch: 85 | Iteration number: [3600/4518] 79% | Training loss: 0.6869556010762851
Epoch: 85 | Iteration number: [3610/4518] 79% | Training loss: 0.6869559928320782
Epoch: 85 | Iteration number: [3620/4518] 80% | Training loss: 0.6869581522862556
Epoch: 85 | Iteration number: [3630/4518] 80% | Training loss: 0.6869552322327269
Epoch: 85 | Iteration number: [3640/4518] 80% | Training loss: 0.6869519301659458
Epoch: 85 | Iteration number: [3650/4518] 80% | Training loss: 0.6869551181303312
Epoch: 85 | Iteration number: [3660/4518] 81% | Training loss: 0.686953302452473
Epoch: 85 | Iteration number: [3670/4518] 81% | Training loss: 0.6869537253470772
Epoch: 85 | Iteration number: [3680/4518] 81% | Training loss: 0.6869538766696401
Epoch: 85 | Iteration number: [3690/4518] 81% | Training loss: 0.6869518603089703
Epoch: 85 | Iteration number: [3700/4518] 81% | Training loss: 0.6869517114839039
Epoch: 85 | Iteration number: [3710/4518] 82% | Training loss: 0.6869529909682723
Epoch: 85 | Iteration number: [3720/4518] 82% | Training loss: 0.6869513464871273
Epoch: 85 | Iteration number: [3730/4518] 82% | Training loss: 0.6869545197039443
Epoch: 85 | Iteration number: [3740/4518] 82% | Training loss: 0.6869522893492551
Epoch: 85 | Iteration number: [3750/4518] 83% | Training loss: 0.6869469194889068
Epoch: 85 | Iteration number: [3760/4518] 83% | Training loss: 0.6869448315431463
Epoch: 85 | Iteration number: [3770/4518] 83% | Training loss: 0.6869456634439272
Epoch: 85 | Iteration number: [3780/4518] 83% | Training loss: 0.6869467528408797
Epoch: 85 | Iteration number: [3790/4518] 83% | Training loss: 0.686942278175052
Epoch: 85 | Iteration number: [3800/4518] 84% | Training loss: 0.6869411478544536
Epoch: 85 | Iteration number: [3810/4518] 84% | Training loss: 0.6869398081865836
Epoch: 85 | Iteration number: [3820/4518] 84% | Training loss: 0.6869401719557677
Epoch: 85 | Iteration number: [3830/4518] 84% | Training loss: 0.6869428771438549
Epoch: 85 | Iteration number: [3840/4518] 84% | Training loss: 0.6869408615864814
Epoch: 85 | Iteration number: [3850/4518] 85% | Training loss: 0.6869369511325638
Epoch: 85 | Iteration number: [3860/4518] 85% | Training loss: 0.6869395949216704
Epoch: 85 | Iteration number: [3870/4518] 85% | Training loss: 0.686937598402802
Epoch: 85 | Iteration number: [3880/4518] 85% | Training loss: 0.6869400687592546
Epoch: 85 | Iteration number: [3890/4518] 86% | Training loss: 0.6869403688644076
Epoch: 85 | Iteration number: [3900/4518] 86% | Training loss: 0.686939837825604
Epoch: 85 | Iteration number: [3910/4518] 86% | Training loss: 0.6869402919583918
Epoch: 85 | Iteration number: [3920/4518] 86% | Training loss: 0.6869377897254059
Epoch: 85 | Iteration number: [3930/4518] 86% | Training loss: 0.6869391495793223
Epoch: 85 | Iteration number: [3940/4518] 87% | Training loss: 0.68694316124553
Epoch: 85 | Iteration number: [3950/4518] 87% | Training loss: 0.6869448182703574
Epoch: 85 | Iteration number: [3960/4518] 87% | Training loss: 0.68694609545096
Epoch: 85 | Iteration number: [3970/4518] 87% | Training loss: 0.686948642292311
Epoch: 85 | Iteration number: [3980/4518] 88% | Training loss: 0.6869473923091314
Epoch: 85 | Iteration number: [3990/4518] 88% | Training loss: 0.6869445647661548
Epoch: 85 | Iteration number: [4000/4518] 88% | Training loss: 0.6869467382282018
Epoch: 85 | Iteration number: [4010/4518] 88% | Training loss: 0.6869524522761157
Epoch: 85 | Iteration number: [4020/4518] 88% | Training loss: 0.6869516219517485
Epoch: 85 | Iteration number: [4030/4518] 89% | Training loss: 0.6869520761091124
Epoch: 85 | Iteration number: [4040/4518] 89% | Training loss: 0.6869527071861937
Epoch: 85 | Iteration number: [4050/4518] 89% | Training loss: 0.6869530651010113
Epoch: 85 | Iteration number: [4060/4518] 89% | Training loss: 0.6869523687022073
Epoch: 85 | Iteration number: [4070/4518] 90% | Training loss: 0.6869514427841149
Epoch: 85 | Iteration number: [4080/4518] 90% | Training loss: 0.6869507674639131
Epoch: 85 | Iteration number: [4090/4518] 90% | Training loss: 0.6869499107590514
Epoch: 85 | Iteration number: [4100/4518] 90% | Training loss: 0.6869485072391789
Epoch: 85 | Iteration number: [4110/4518] 90% | Training loss: 0.6869485289365996
Epoch: 85 | Iteration number: [4120/4518] 91% | Training loss: 0.6869507717854768
Epoch: 85 | Iteration number: [4130/4518] 91% | Training loss: 0.6869510058629311
Epoch: 85 | Iteration number: [4140/4518] 91% | Training loss: 0.6869477226682331
Epoch: 85 | Iteration number: [4150/4518] 91% | Training loss: 0.6869490509866232
Epoch: 85 | Iteration number: [4160/4518] 92% | Training loss: 0.6869481230584474
Epoch: 85 | Iteration number: [4170/4518] 92% | Training loss: 0.6869437797035245
Epoch: 85 | Iteration number: [4180/4518] 92% | Training loss: 0.6869403285272954
Epoch: 85 | Iteration number: [4190/4518] 92% | Training loss: 0.6869436065450774
Epoch: 85 | Iteration number: [4200/4518] 92% | Training loss: 0.6869420194909686
Epoch: 85 | Iteration number: [4210/4518] 93% | Training loss: 0.6869387177418643
Epoch: 85 | Iteration number: [4220/4518] 93% | Training loss: 0.6869373440036276
Epoch: 85 | Iteration number: [4230/4518] 93% | Training loss: 0.6869370993288414
Epoch: 85 | Iteration number: [4240/4518] 93% | Training loss: 0.6869375537870065
Epoch: 85 | Iteration number: [4250/4518] 94% | Training loss: 0.6869357779867509
Epoch: 85 | Iteration number: [4260/4518] 94% | Training loss: 0.6869375703900074
Epoch: 85 | Iteration number: [4270/4518] 94% | Training loss: 0.6869332335034355
Epoch: 85 | Iteration number: [4280/4518] 94% | Training loss: 0.6869309633552471
Epoch: 85 | Iteration number: [4290/4518] 94% | Training loss: 0.6869289694966136
Epoch: 85 | Iteration number: [4300/4518] 95% | Training loss: 0.6869286282117977
Epoch: 85 | Iteration number: [4310/4518] 95% | Training loss: 0.6869253313043554
Epoch: 85 | Iteration number: [4320/4518] 95% | Training loss: 0.6869258649095341
Epoch: 85 | Iteration number: [4330/4518] 95% | Training loss: 0.6869256905953273
Epoch: 85 | Iteration number: [4340/4518] 96% | Training loss: 0.6869261555408003
Epoch: 85 | Iteration number: [4350/4518] 96% | Training loss: 0.6869295842620148
Epoch: 85 | Iteration number: [4360/4518] 96% | Training loss: 0.6869271142903818
Epoch: 85 | Iteration number: [4370/4518] 96% | Training loss: 0.6869263595383555
Epoch: 85 | Iteration number: [4380/4518] 96% | Training loss: 0.6869254577241531
Epoch: 85 | Iteration number: [4390/4518] 97% | Training loss: 0.6869266035888081
Epoch: 85 | Iteration number: [4400/4518] 97% | Training loss: 0.6869211004132574
Epoch: 85 | Iteration number: [4410/4518] 97% | Training loss: 0.6869171873512182
Epoch: 85 | Iteration number: [4420/4518] 97% | Training loss: 0.6869191811904648
Epoch: 85 | Iteration number: [4430/4518] 98% | Training loss: 0.6869202814306685
Epoch: 85 | Iteration number: [4440/4518] 98% | Training loss: 0.686920218908035
Epoch: 85 | Iteration number: [4450/4518] 98% | Training loss: 0.6869204449117854
Epoch: 85 | Iteration number: [4460/4518] 98% | Training loss: 0.6869210079379146
Epoch: 85 | Iteration number: [4470/4518] 98% | Training loss: 0.6869151673194279
Epoch: 85 | Iteration number: [4480/4518] 99% | Training loss: 0.686915285273322
Epoch: 85 | Iteration number: [4490/4518] 99% | Training loss: 0.6869123065790249
Epoch: 85 | Iteration number: [4500/4518] 99% | Training loss: 0.6869117684761683
Epoch: 85 | Iteration number: [4510/4518] 99% | Training loss: 0.6869109563446891

 End of epoch: 85 | Train Loss: 0.6867568264655594 | Training Time: 632 

 End of epoch: 85 | Eval Loss: 0.6896508482037759 | Evaluating Time: 17 
Epoch: 86 | Iteration number: [10/4518] 0% | Training loss: 0.7548879086971283
Epoch: 86 | Iteration number: [20/4518] 0% | Training loss: 0.7203643590211868
Epoch: 86 | Iteration number: [30/4518] 0% | Training loss: 0.7087053000926972
Epoch: 86 | Iteration number: [40/4518] 0% | Training loss: 0.7034566104412079
Epoch: 86 | Iteration number: [50/4518] 1% | Training loss: 0.7000100541114808
Epoch: 86 | Iteration number: [60/4518] 1% | Training loss: 0.6978670875231425
Epoch: 86 | Iteration number: [70/4518] 1% | Training loss: 0.6961523541382381
Epoch: 86 | Iteration number: [80/4518] 1% | Training loss: 0.695100761204958
Epoch: 86 | Iteration number: [90/4518] 1% | Training loss: 0.694135578473409
Epoch: 86 | Iteration number: [100/4518] 2% | Training loss: 0.6933588916063309
Epoch: 86 | Iteration number: [110/4518] 2% | Training loss: 0.6926742483269085
Epoch: 86 | Iteration number: [120/4518] 2% | Training loss: 0.6920678074161212
Epoch: 86 | Iteration number: [130/4518] 2% | Training loss: 0.6917183220386505
Epoch: 86 | Iteration number: [140/4518] 3% | Training loss: 0.6914272904396057
Epoch: 86 | Iteration number: [150/4518] 3% | Training loss: 0.6910959366957347
Epoch: 86 | Iteration number: [160/4518] 3% | Training loss: 0.6908450923860073
Epoch: 86 | Iteration number: [170/4518] 3% | Training loss: 0.6906601166023928
Epoch: 86 | Iteration number: [180/4518] 3% | Training loss: 0.6904953469832739
Epoch: 86 | Iteration number: [190/4518] 4% | Training loss: 0.6903040167532469
Epoch: 86 | Iteration number: [200/4518] 4% | Training loss: 0.6901157185435295
Epoch: 86 | Iteration number: [210/4518] 4% | Training loss: 0.6899341109253111
Epoch: 86 | Iteration number: [220/4518] 4% | Training loss: 0.6897517754272982
Epoch: 86 | Iteration number: [230/4518] 5% | Training loss: 0.6896253331847813
Epoch: 86 | Iteration number: [240/4518] 5% | Training loss: 0.6895431940754254
Epoch: 86 | Iteration number: [250/4518] 5% | Training loss: 0.6894922561645508
Epoch: 86 | Iteration number: [260/4518] 5% | Training loss: 0.6894160747528076
Epoch: 86 | Iteration number: [270/4518] 5% | Training loss: 0.6893085802042925
Epoch: 86 | Iteration number: [280/4518] 6% | Training loss: 0.6891878698553358
Epoch: 86 | Iteration number: [290/4518] 6% | Training loss: 0.6890878611597522
Epoch: 86 | Iteration number: [300/4518] 6% | Training loss: 0.6889835874239604
Epoch: 86 | Iteration number: [310/4518] 6% | Training loss: 0.6889435510481557
Epoch: 86 | Iteration number: [320/4518] 7% | Training loss: 0.6889026880264282
Epoch: 86 | Iteration number: [330/4518] 7% | Training loss: 0.6887833306283662
Epoch: 86 | Iteration number: [340/4518] 7% | Training loss: 0.6887521380887313
Epoch: 86 | Iteration number: [350/4518] 7% | Training loss: 0.6887236789294652
Epoch: 86 | Iteration number: [360/4518] 7% | Training loss: 0.6886969808075163
Epoch: 86 | Iteration number: [370/4518] 8% | Training loss: 0.6886354530179822
Epoch: 86 | Iteration number: [380/4518] 8% | Training loss: 0.6885772761545683
Epoch: 86 | Iteration number: [390/4518] 8% | Training loss: 0.6885201935584728
Epoch: 86 | Iteration number: [400/4518] 8% | Training loss: 0.6884527878463268
Epoch: 86 | Iteration number: [410/4518] 9% | Training loss: 0.6884235470760159
Epoch: 86 | Iteration number: [420/4518] 9% | Training loss: 0.6884196742659523
Epoch: 86 | Iteration number: [430/4518] 9% | Training loss: 0.68835737178492
Epoch: 86 | Iteration number: [440/4518] 9% | Training loss: 0.6883022684942592
Epoch: 86 | Iteration number: [450/4518] 9% | Training loss: 0.6882399562994639
Epoch: 86 | Iteration number: [460/4518] 10% | Training loss: 0.6882368780996488
Epoch: 86 | Iteration number: [470/4518] 10% | Training loss: 0.688182069266096
Epoch: 86 | Iteration number: [480/4518] 10% | Training loss: 0.6881678142895301
Epoch: 86 | Iteration number: [490/4518] 10% | Training loss: 0.6881527015141078
Epoch: 86 | Iteration number: [500/4518] 11% | Training loss: 0.6881228377819061
Epoch: 86 | Iteration number: [510/4518] 11% | Training loss: 0.6880871122958614
Epoch: 86 | Iteration number: [520/4518] 11% | Training loss: 0.6880549809107414
Epoch: 86 | Iteration number: [530/4518] 11% | Training loss: 0.6880172053598008
Epoch: 86 | Iteration number: [540/4518] 11% | Training loss: 0.6879840907123353
Epoch: 86 | Iteration number: [550/4518] 12% | Training loss: 0.6879780873385343
Epoch: 86 | Iteration number: [560/4518] 12% | Training loss: 0.6879439875483513
Epoch: 86 | Iteration number: [570/4518] 12% | Training loss: 0.6879334758248246
Epoch: 86 | Iteration number: [580/4518] 12% | Training loss: 0.687936947366287
Epoch: 86 | Iteration number: [590/4518] 13% | Training loss: 0.6879285585072081
Epoch: 86 | Iteration number: [600/4518] 13% | Training loss: 0.6879018395145734
Epoch: 86 | Iteration number: [610/4518] 13% | Training loss: 0.6878747866779077
Epoch: 86 | Iteration number: [620/4518] 13% | Training loss: 0.687873778612383
Epoch: 86 | Iteration number: [630/4518] 13% | Training loss: 0.6878441680045355
Epoch: 86 | Iteration number: [640/4518] 14% | Training loss: 0.6878309024497866
Epoch: 86 | Iteration number: [650/4518] 14% | Training loss: 0.6878123814326066
Epoch: 86 | Iteration number: [660/4518] 14% | Training loss: 0.6877978773731174
Epoch: 86 | Iteration number: [670/4518] 14% | Training loss: 0.6877786783140097
Epoch: 86 | Iteration number: [680/4518] 15% | Training loss: 0.6877741861869308
Epoch: 86 | Iteration number: [690/4518] 15% | Training loss: 0.687759240295576
Epoch: 86 | Iteration number: [700/4518] 15% | Training loss: 0.6877300159420285
Epoch: 86 | Iteration number: [710/4518] 15% | Training loss: 0.6876862547766994
Epoch: 86 | Iteration number: [720/4518] 15% | Training loss: 0.6876599174406793
Epoch: 86 | Iteration number: [730/4518] 16% | Training loss: 0.6876291333812556
Epoch: 86 | Iteration number: [740/4518] 16% | Training loss: 0.6875922655737078
Epoch: 86 | Iteration number: [750/4518] 16% | Training loss: 0.6875765961011251
Epoch: 86 | Iteration number: [760/4518] 16% | Training loss: 0.6875690788814895
Epoch: 86 | Iteration number: [770/4518] 17% | Training loss: 0.6875674913455914
Epoch: 86 | Iteration number: [780/4518] 17% | Training loss: 0.6875379706040406
Epoch: 86 | Iteration number: [790/4518] 17% | Training loss: 0.6875350654125214
Epoch: 86 | Iteration number: [800/4518] 17% | Training loss: 0.6875370244681835
Epoch: 86 | Iteration number: [810/4518] 17% | Training loss: 0.6875259982215034
Epoch: 86 | Iteration number: [820/4518] 18% | Training loss: 0.6875227308854824
Epoch: 86 | Iteration number: [830/4518] 18% | Training loss: 0.6875129886420376
Epoch: 86 | Iteration number: [840/4518] 18% | Training loss: 0.6875068570886339
Epoch: 86 | Iteration number: [850/4518] 18% | Training loss: 0.6875119637040531
Epoch: 86 | Iteration number: [860/4518] 19% | Training loss: 0.6874987175991368
Epoch: 86 | Iteration number: [870/4518] 19% | Training loss: 0.6874907231878961
Epoch: 86 | Iteration number: [880/4518] 19% | Training loss: 0.6874837895008651
Epoch: 86 | Iteration number: [890/4518] 19% | Training loss: 0.6874737221203493
Epoch: 86 | Iteration number: [900/4518] 19% | Training loss: 0.6874657256073422
Epoch: 86 | Iteration number: [910/4518] 20% | Training loss: 0.6874444856748476
Epoch: 86 | Iteration number: [920/4518] 20% | Training loss: 0.6874493859384371
Epoch: 86 | Iteration number: [930/4518] 20% | Training loss: 0.6874460962510878
Epoch: 86 | Iteration number: [940/4518] 20% | Training loss: 0.6874274793457478
Epoch: 86 | Iteration number: [950/4518] 21% | Training loss: 0.6874096539146022
Epoch: 86 | Iteration number: [960/4518] 21% | Training loss: 0.6873999806741874
Epoch: 86 | Iteration number: [970/4518] 21% | Training loss: 0.6874069793322651
Epoch: 86 | Iteration number: [980/4518] 21% | Training loss: 0.6873870885493804
Epoch: 86 | Iteration number: [990/4518] 21% | Training loss: 0.687381502112957
Epoch: 86 | Iteration number: [1000/4518] 22% | Training loss: 0.6873757937550544
Epoch: 86 | Iteration number: [1010/4518] 22% | Training loss: 0.6873622684785635
Epoch: 86 | Iteration number: [1020/4518] 22% | Training loss: 0.6873601291109533
Epoch: 86 | Iteration number: [1030/4518] 22% | Training loss: 0.6873575872587926
Epoch: 86 | Iteration number: [1040/4518] 23% | Training loss: 0.6873506768391683
Epoch: 86 | Iteration number: [1050/4518] 23% | Training loss: 0.6873549049808866
Epoch: 86 | Iteration number: [1060/4518] 23% | Training loss: 0.6873504769127324
Epoch: 86 | Iteration number: [1070/4518] 23% | Training loss: 0.6873398973563007
Epoch: 86 | Iteration number: [1080/4518] 23% | Training loss: 0.6873336920583689
Epoch: 86 | Iteration number: [1090/4518] 24% | Training loss: 0.6873347048365742
Epoch: 86 | Iteration number: [1100/4518] 24% | Training loss: 0.6873246201601896
Epoch: 86 | Iteration number: [1110/4518] 24% | Training loss: 0.6873099665921014
Epoch: 86 | Iteration number: [1120/4518] 24% | Training loss: 0.6873012973793915
Epoch: 86 | Iteration number: [1130/4518] 25% | Training loss: 0.6873065159911603
Epoch: 86 | Iteration number: [1140/4518] 25% | Training loss: 0.6873083357748232
Epoch: 86 | Iteration number: [1150/4518] 25% | Training loss: 0.6873050733752872
Epoch: 86 | Iteration number: [1160/4518] 25% | Training loss: 0.6873015622126645
Epoch: 86 | Iteration number: [1170/4518] 25% | Training loss: 0.6872837825718089
Epoch: 86 | Iteration number: [1180/4518] 26% | Training loss: 0.6872759501812822
Epoch: 86 | Iteration number: [1190/4518] 26% | Training loss: 0.6872770309949121
Epoch: 86 | Iteration number: [1200/4518] 26% | Training loss: 0.687267997165521
Epoch: 86 | Iteration number: [1210/4518] 26% | Training loss: 0.6872709011735995
Epoch: 86 | Iteration number: [1220/4518] 27% | Training loss: 0.6872692320190492
Epoch: 86 | Iteration number: [1230/4518] 27% | Training loss: 0.6872708838645035
Epoch: 86 | Iteration number: [1240/4518] 27% | Training loss: 0.6872553312490063
Epoch: 86 | Iteration number: [1250/4518] 27% | Training loss: 0.6872509266376495
Epoch: 86 | Iteration number: [1260/4518] 27% | Training loss: 0.6872597831582267
Epoch: 86 | Iteration number: [1270/4518] 28% | Training loss: 0.6872525045252221
Epoch: 86 | Iteration number: [1280/4518] 28% | Training loss: 0.6872502458281815
Epoch: 86 | Iteration number: [1290/4518] 28% | Training loss: 0.6872458764286928
Epoch: 86 | Iteration number: [1300/4518] 28% | Training loss: 0.6872438263893127
Epoch: 86 | Iteration number: [1310/4518] 28% | Training loss: 0.6872433221067181
Epoch: 86 | Iteration number: [1320/4518] 29% | Training loss: 0.6872320398688316
Epoch: 86 | Iteration number: [1330/4518] 29% | Training loss: 0.6872271697324022
Epoch: 86 | Iteration number: [1340/4518] 29% | Training loss: 0.687221264082994
Epoch: 86 | Iteration number: [1350/4518] 29% | Training loss: 0.6872096342069132
Epoch: 86 | Iteration number: [1360/4518] 30% | Training loss: 0.6872067592599813
Epoch: 86 | Iteration number: [1370/4518] 30% | Training loss: 0.6871951696211405
Epoch: 86 | Iteration number: [1380/4518] 30% | Training loss: 0.6871835909459902
Epoch: 86 | Iteration number: [1390/4518] 30% | Training loss: 0.6871789365363635
Epoch: 86 | Iteration number: [1400/4518] 30% | Training loss: 0.6871716377990587
Epoch: 86 | Iteration number: [1410/4518] 31% | Training loss: 0.687167252758716
Epoch: 86 | Iteration number: [1420/4518] 31% | Training loss: 0.6871620566492349
Epoch: 86 | Iteration number: [1430/4518] 31% | Training loss: 0.687168475214418
Epoch: 86 | Iteration number: [1440/4518] 31% | Training loss: 0.6871619677791992
Epoch: 86 | Iteration number: [1450/4518] 32% | Training loss: 0.6871662791433005
Epoch: 86 | Iteration number: [1460/4518] 32% | Training loss: 0.6871537757246462
Epoch: 86 | Iteration number: [1470/4518] 32% | Training loss: 0.687157711488049
Epoch: 86 | Iteration number: [1480/4518] 32% | Training loss: 0.6871522407676722
Epoch: 86 | Iteration number: [1490/4518] 32% | Training loss: 0.6871400459900798
Epoch: 86 | Iteration number: [1500/4518] 33% | Training loss: 0.6871309793790181
Epoch: 86 | Iteration number: [1510/4518] 33% | Training loss: 0.6871188015337811
Epoch: 86 | Iteration number: [1520/4518] 33% | Training loss: 0.687115516043023
Epoch: 86 | Iteration number: [1530/4518] 33% | Training loss: 0.6871077225099202
Epoch: 86 | Iteration number: [1540/4518] 34% | Training loss: 0.6871123760164558
Epoch: 86 | Iteration number: [1550/4518] 34% | Training loss: 0.6871102008511943
Epoch: 86 | Iteration number: [1560/4518] 34% | Training loss: 0.6871068337788948
Epoch: 86 | Iteration number: [1570/4518] 34% | Training loss: 0.6871111549769238
Epoch: 86 | Iteration number: [1580/4518] 34% | Training loss: 0.6871126191148275
Epoch: 86 | Iteration number: [1590/4518] 35% | Training loss: 0.6871067835474914
Epoch: 86 | Iteration number: [1600/4518] 35% | Training loss: 0.687108577825129
Epoch: 86 | Iteration number: [1610/4518] 35% | Training loss: 0.6871082823469031
Epoch: 86 | Iteration number: [1620/4518] 35% | Training loss: 0.6871046126256755
Epoch: 86 | Iteration number: [1630/4518] 36% | Training loss: 0.687103948856424
Epoch: 86 | Iteration number: [1640/4518] 36% | Training loss: 0.6870976701378823
Epoch: 86 | Iteration number: [1650/4518] 36% | Training loss: 0.6870934795610832
Epoch: 86 | Iteration number: [1660/4518] 36% | Training loss: 0.6870894417705307
Epoch: 86 | Iteration number: [1670/4518] 36% | Training loss: 0.6870918264289102
Epoch: 86 | Iteration number: [1680/4518] 37% | Training loss: 0.6870884341853005
Epoch: 86 | Iteration number: [1690/4518] 37% | Training loss: 0.6870859443788698
Epoch: 86 | Iteration number: [1700/4518] 37% | Training loss: 0.6870858431213043
Epoch: 86 | Iteration number: [1710/4518] 37% | Training loss: 0.6870790308330491
Epoch: 86 | Iteration number: [1720/4518] 38% | Training loss: 0.6870824244826339
Epoch: 86 | Iteration number: [1730/4518] 38% | Training loss: 0.6870803048844971
Epoch: 86 | Iteration number: [1740/4518] 38% | Training loss: 0.6870726451791566
Epoch: 86 | Iteration number: [1750/4518] 38% | Training loss: 0.6870722917488643
Epoch: 86 | Iteration number: [1760/4518] 38% | Training loss: 0.6870731333778664
Epoch: 86 | Iteration number: [1770/4518] 39% | Training loss: 0.6870611351425365
Epoch: 86 | Iteration number: [1780/4518] 39% | Training loss: 0.68705999660358
Epoch: 86 | Iteration number: [1790/4518] 39% | Training loss: 0.6870640168975851
Epoch: 86 | Iteration number: [1800/4518] 39% | Training loss: 0.6870636634363069
Epoch: 86 | Iteration number: [1810/4518] 40% | Training loss: 0.687058919371821
Epoch: 86 | Iteration number: [1820/4518] 40% | Training loss: 0.6870616523774116
Epoch: 86 | Iteration number: [1830/4518] 40% | Training loss: 0.6870588247893287
Epoch: 86 | Iteration number: [1840/4518] 40% | Training loss: 0.6870534806471804
Epoch: 86 | Iteration number: [1850/4518] 40% | Training loss: 0.6870513146954613
Epoch: 86 | Iteration number: [1860/4518] 41% | Training loss: 0.6870467266728801
Epoch: 86 | Iteration number: [1870/4518] 41% | Training loss: 0.687046783620661
Epoch: 86 | Iteration number: [1880/4518] 41% | Training loss: 0.687037375696162
Epoch: 86 | Iteration number: [1890/4518] 41% | Training loss: 0.6870362495934522
Epoch: 86 | Iteration number: [1900/4518] 42% | Training loss: 0.6870392358930487
Epoch: 86 | Iteration number: [1910/4518] 42% | Training loss: 0.6870333625384026
Epoch: 86 | Iteration number: [1920/4518] 42% | Training loss: 0.6870346162157754
Epoch: 86 | Iteration number: [1930/4518] 42% | Training loss: 0.6870346025172911
Epoch: 86 | Iteration number: [1940/4518] 42% | Training loss: 0.6870293771483235
Epoch: 86 | Iteration number: [1950/4518] 43% | Training loss: 0.6870289514003656
Epoch: 86 | Iteration number: [1960/4518] 43% | Training loss: 0.6870330504008701
Epoch: 86 | Iteration number: [1970/4518] 43% | Training loss: 0.6870307806784731
Epoch: 86 | Iteration number: [1980/4518] 43% | Training loss: 0.687037853700946
Epoch: 86 | Iteration number: [1990/4518] 44% | Training loss: 0.687036206614432
Epoch: 86 | Iteration number: [2000/4518] 44% | Training loss: 0.6870359868705272
Epoch: 86 | Iteration number: [2010/4518] 44% | Training loss: 0.6870350773951307
Epoch: 86 | Iteration number: [2020/4518] 44% | Training loss: 0.6870315897582782
Epoch: 86 | Iteration number: [2030/4518] 44% | Training loss: 0.6870277907167163
Epoch: 86 | Iteration number: [2040/4518] 45% | Training loss: 0.6870305833278918
Epoch: 86 | Iteration number: [2050/4518] 45% | Training loss: 0.6870238273608975
Epoch: 86 | Iteration number: [2060/4518] 45% | Training loss: 0.6870273028762596
Epoch: 86 | Iteration number: [2070/4518] 45% | Training loss: 0.687029433567167
Epoch: 86 | Iteration number: [2080/4518] 46% | Training loss: 0.687029912809913
Epoch: 86 | Iteration number: [2090/4518] 46% | Training loss: 0.6870279821767762
Epoch: 86 | Iteration number: [2100/4518] 46% | Training loss: 0.687027091383934
Epoch: 86 | Iteration number: [2110/4518] 46% | Training loss: 0.6870288345486066
Epoch: 86 | Iteration number: [2120/4518] 46% | Training loss: 0.6870290298506899
Epoch: 86 | Iteration number: [2130/4518] 47% | Training loss: 0.6870213105365144
Epoch: 86 | Iteration number: [2140/4518] 47% | Training loss: 0.6870233782262446
Epoch: 86 | Iteration number: [2150/4518] 47% | Training loss: 0.6870246336626452
Epoch: 86 | Iteration number: [2160/4518] 47% | Training loss: 0.6870224471445436
Epoch: 86 | Iteration number: [2170/4518] 48% | Training loss: 0.6870216755548381
Epoch: 86 | Iteration number: [2180/4518] 48% | Training loss: 0.68701932165054
Epoch: 86 | Iteration number: [2190/4518] 48% | Training loss: 0.6870175688234094
Epoch: 86 | Iteration number: [2200/4518] 48% | Training loss: 0.68701564444737
Epoch: 86 | Iteration number: [2210/4518] 48% | Training loss: 0.687013030429771
Epoch: 86 | Iteration number: [2220/4518] 49% | Training loss: 0.6870151173961055
Epoch: 86 | Iteration number: [2230/4518] 49% | Training loss: 0.6870139408004658
Epoch: 86 | Iteration number: [2240/4518] 49% | Training loss: 0.6870142558057394
Epoch: 86 | Iteration number: [2250/4518] 49% | Training loss: 0.6870178963608212
Epoch: 86 | Iteration number: [2260/4518] 50% | Training loss: 0.6870188458039698
Epoch: 86 | Iteration number: [2270/4518] 50% | Training loss: 0.6870198627925654
Epoch: 86 | Iteration number: [2280/4518] 50% | Training loss: 0.6870149498445945
Epoch: 86 | Iteration number: [2290/4518] 50% | Training loss: 0.6870146045257951
Epoch: 86 | Iteration number: [2300/4518] 50% | Training loss: 0.6870123695031456
Epoch: 86 | Iteration number: [2310/4518] 51% | Training loss: 0.6870041154937827
Epoch: 86 | Iteration number: [2320/4518] 51% | Training loss: 0.6870077569936884
Epoch: 86 | Iteration number: [2330/4518] 51% | Training loss: 0.6870085434084798
Epoch: 86 | Iteration number: [2340/4518] 51% | Training loss: 0.6870038370036672
Epoch: 86 | Iteration number: [2350/4518] 52% | Training loss: 0.6870013157864835
Epoch: 86 | Iteration number: [2360/4518] 52% | Training loss: 0.6870034122366017
Epoch: 86 | Iteration number: [2370/4518] 52% | Training loss: 0.6870051483564739
Epoch: 86 | Iteration number: [2380/4518] 52% | Training loss: 0.6870049196631969
Epoch: 86 | Iteration number: [2390/4518] 52% | Training loss: 0.6870051481234978
Epoch: 86 | Iteration number: [2400/4518] 53% | Training loss: 0.6869994699458282
Epoch: 86 | Iteration number: [2410/4518] 53% | Training loss: 0.6869974055230865
Epoch: 86 | Iteration number: [2420/4518] 53% | Training loss: 0.6869930150095096
Epoch: 86 | Iteration number: [2430/4518] 53% | Training loss: 0.686993523119899
Epoch: 86 | Iteration number: [2440/4518] 54% | Training loss: 0.686991672413271
Epoch: 86 | Iteration number: [2450/4518] 54% | Training loss: 0.6869870444949793
Epoch: 86 | Iteration number: [2460/4518] 54% | Training loss: 0.6869810410631382
Epoch: 86 | Iteration number: [2470/4518] 54% | Training loss: 0.6869833104040941
Epoch: 86 | Iteration number: [2480/4518] 54% | Training loss: 0.6869845007456118
Epoch: 86 | Iteration number: [2490/4518] 55% | Training loss: 0.6869859231523721
Epoch: 86 | Iteration number: [2500/4518] 55% | Training loss: 0.686987138390541
Epoch: 86 | Iteration number: [2510/4518] 55% | Training loss: 0.6869861611807014
Epoch: 86 | Iteration number: [2520/4518] 55% | Training loss: 0.6869885241938016
Epoch: 86 | Iteration number: [2530/4518] 55% | Training loss: 0.686987883441533
Epoch: 86 | Iteration number: [2540/4518] 56% | Training loss: 0.6869843145759087
Epoch: 86 | Iteration number: [2550/4518] 56% | Training loss: 0.6869864333844652
Epoch: 86 | Iteration number: [2560/4518] 56% | Training loss: 0.6869855741271749
Epoch: 86 | Iteration number: [2570/4518] 56% | Training loss: 0.686982224678715
Epoch: 86 | Iteration number: [2580/4518] 57% | Training loss: 0.686985853245092
Epoch: 86 | Iteration number: [2590/4518] 57% | Training loss: 0.6869898458015045
Epoch: 86 | Iteration number: [2600/4518] 57% | Training loss: 0.686990989102767
Epoch: 86 | Iteration number: [2610/4518] 57% | Training loss: 0.6869878562245789
Epoch: 86 | Iteration number: [2620/4518] 57% | Training loss: 0.6869852708951207
Epoch: 86 | Iteration number: [2630/4518] 58% | Training loss: 0.6869890026946485
Epoch: 86 | Iteration number: [2640/4518] 58% | Training loss: 0.6869897463556492
Epoch: 86 | Iteration number: [2650/4518] 58% | Training loss: 0.6869894290420244
Epoch: 86 | Iteration number: [2660/4518] 58% | Training loss: 0.6869863002596045
Epoch: 86 | Iteration number: [2670/4518] 59% | Training loss: 0.6869886640082584
Epoch: 86 | Iteration number: [2680/4518] 59% | Training loss: 0.6869905143308995
Epoch: 86 | Iteration number: [2690/4518] 59% | Training loss: 0.6869871602847231
Epoch: 86 | Iteration number: [2700/4518] 59% | Training loss: 0.6869849406789851
Epoch: 86 | Iteration number: [2710/4518] 59% | Training loss: 0.6869809699674374
Epoch: 86 | Iteration number: [2720/4518] 60% | Training loss: 0.6869822852313519
Epoch: 86 | Iteration number: [2730/4518] 60% | Training loss: 0.6869842712259118
Epoch: 86 | Iteration number: [2740/4518] 60% | Training loss: 0.6869820332440146
Epoch: 86 | Iteration number: [2750/4518] 60% | Training loss: 0.68698123923215
Epoch: 86 | Iteration number: [2760/4518] 61% | Training loss: 0.6869811640701432
Epoch: 86 | Iteration number: [2770/4518] 61% | Training loss: 0.6869806946184661
Epoch: 86 | Iteration number: [2780/4518] 61% | Training loss: 0.6869817445389659
Epoch: 86 | Iteration number: [2790/4518] 61% | Training loss: 0.6869821247447776
Epoch: 86 | Iteration number: [2800/4518] 61% | Training loss: 0.6869821679166385
Epoch: 86 | Iteration number: [2810/4518] 62% | Training loss: 0.6869817353016117
Epoch: 86 | Iteration number: [2820/4518] 62% | Training loss: 0.6869805495155619
Epoch: 86 | Iteration number: [2830/4518] 62% | Training loss: 0.6869823732982676
Epoch: 86 | Iteration number: [2840/4518] 62% | Training loss: 0.6869743184724324
Epoch: 86 | Iteration number: [2850/4518] 63% | Training loss: 0.6869731736392306
Epoch: 86 | Iteration number: [2860/4518] 63% | Training loss: 0.6869741455033109
Epoch: 86 | Iteration number: [2870/4518] 63% | Training loss: 0.6869743565856787
Epoch: 86 | Iteration number: [2880/4518] 63% | Training loss: 0.6869757356743018
Epoch: 86 | Iteration number: [2890/4518] 63% | Training loss: 0.6869746649554032
Epoch: 86 | Iteration number: [2900/4518] 64% | Training loss: 0.686975650561267
Epoch: 86 | Iteration number: [2910/4518] 64% | Training loss: 0.6869753177837817
Epoch: 86 | Iteration number: [2920/4518] 64% | Training loss: 0.6869756634308867
Epoch: 86 | Iteration number: [2930/4518] 64% | Training loss: 0.6869751753050313
Epoch: 86 | Iteration number: [2940/4518] 65% | Training loss: 0.6869744070533181
Epoch: 86 | Iteration number: [2950/4518] 65% | Training loss: 0.686976701869803
Epoch: 86 | Iteration number: [2960/4518] 65% | Training loss: 0.6869754575595662
Epoch: 86 | Iteration number: [2970/4518] 65% | Training loss: 0.6869744437912899
Epoch: 86 | Iteration number: [2980/4518] 65% | Training loss: 0.6869722447139305
Epoch: 86 | Iteration number: [2990/4518] 66% | Training loss: 0.6869741720499403
Epoch: 86 | Iteration number: [3000/4518] 66% | Training loss: 0.6869744588534037
Epoch: 86 | Iteration number: [3010/4518] 66% | Training loss: 0.6869724126353216
Epoch: 86 | Iteration number: [3020/4518] 66% | Training loss: 0.6869774003889387
Epoch: 86 | Iteration number: [3030/4518] 67% | Training loss: 0.6869756536318524
Epoch: 86 | Iteration number: [3040/4518] 67% | Training loss: 0.6869723739984789
Epoch: 86 | Iteration number: [3050/4518] 67% | Training loss: 0.6869706418866017
Epoch: 86 | Iteration number: [3060/4518] 67% | Training loss: 0.6869682602438272
Epoch: 86 | Iteration number: [3070/4518] 67% | Training loss: 0.6869672801284914
Epoch: 86 | Iteration number: [3080/4518] 68% | Training loss: 0.6869662577455694
Epoch: 86 | Iteration number: [3090/4518] 68% | Training loss: 0.6869696309651372
Epoch: 86 | Iteration number: [3100/4518] 68% | Training loss: 0.686970979417524
Epoch: 86 | Iteration number: [3110/4518] 68% | Training loss: 0.6869674298157646
Epoch: 86 | Iteration number: [3120/4518] 69% | Training loss: 0.6869671636475967
Epoch: 86 | Iteration number: [3130/4518] 69% | Training loss: 0.6869666517923434
Epoch: 86 | Iteration number: [3140/4518] 69% | Training loss: 0.6869633629253715
Epoch: 86 | Iteration number: [3150/4518] 69% | Training loss: 0.6869598729648287
Epoch: 86 | Iteration number: [3160/4518] 69% | Training loss: 0.6869590546888641
Epoch: 86 | Iteration number: [3170/4518] 70% | Training loss: 0.6869549447617697
Epoch: 86 | Iteration number: [3180/4518] 70% | Training loss: 0.6869564074577775
Epoch: 86 | Iteration number: [3190/4518] 70% | Training loss: 0.6869532385216237
Epoch: 86 | Iteration number: [3200/4518] 70% | Training loss: 0.6869501643627882
Epoch: 86 | Iteration number: [3210/4518] 71% | Training loss: 0.6869452372518284
Epoch: 86 | Iteration number: [3220/4518] 71% | Training loss: 0.6869455340856351
Epoch: 86 | Iteration number: [3230/4518] 71% | Training loss: 0.6869493494092864
Epoch: 86 | Iteration number: [3240/4518] 71% | Training loss: 0.6869505690019808
Epoch: 86 | Iteration number: [3250/4518] 71% | Training loss: 0.6869510010939378
Epoch: 86 | Iteration number: [3260/4518] 72% | Training loss: 0.6869526282775621
Epoch: 86 | Iteration number: [3270/4518] 72% | Training loss: 0.686950828431214
Epoch: 86 | Iteration number: [3280/4518] 72% | Training loss: 0.6869504670907811
Epoch: 86 | Iteration number: [3290/4518] 72% | Training loss: 0.6869494551039756
Epoch: 86 | Iteration number: [3300/4518] 73% | Training loss: 0.6869482975114476
Epoch: 86 | Iteration number: [3310/4518] 73% | Training loss: 0.6869490606547122
Epoch: 86 | Iteration number: [3320/4518] 73% | Training loss: 0.6869523498846823
Epoch: 86 | Iteration number: [3330/4518] 73% | Training loss: 0.6869521334901586
Epoch: 86 | Iteration number: [3340/4518] 73% | Training loss: 0.6869499534546972
Epoch: 86 | Iteration number: [3350/4518] 74% | Training loss: 0.6869505959126486
Epoch: 86 | Iteration number: [3360/4518] 74% | Training loss: 0.6869541202982267
Epoch: 86 | Iteration number: [3370/4518] 74% | Training loss: 0.6869497361805743
Epoch: 86 | Iteration number: [3380/4518] 74% | Training loss: 0.6869478716829119
Epoch: 86 | Iteration number: [3390/4518] 75% | Training loss: 0.6869444577567345
Epoch: 86 | Iteration number: [3400/4518] 75% | Training loss: 0.6869409360780435
Epoch: 86 | Iteration number: [3410/4518] 75% | Training loss: 0.686938501260847
Epoch: 86 | Iteration number: [3420/4518] 75% | Training loss: 0.6869353276072887
Epoch: 86 | Iteration number: [3430/4518] 75% | Training loss: 0.686934818401281
Epoch: 86 | Iteration number: [3440/4518] 76% | Training loss: 0.6869358278637708
Epoch: 86 | Iteration number: [3450/4518] 76% | Training loss: 0.6869313034458436
Epoch: 86 | Iteration number: [3460/4518] 76% | Training loss: 0.6869325317571618
Epoch: 86 | Iteration number: [3470/4518] 76% | Training loss: 0.6869363207981978
Epoch: 86 | Iteration number: [3480/4518] 77% | Training loss: 0.6869348136344176
Epoch: 86 | Iteration number: [3490/4518] 77% | Training loss: 0.6869361064837108
Epoch: 86 | Iteration number: [3500/4518] 77% | Training loss: 0.6869387475763048
Epoch: 86 | Iteration number: [3510/4518] 77% | Training loss: 0.6869423706477185
Epoch: 86 | Iteration number: [3520/4518] 77% | Training loss: 0.6869418380443345
Epoch: 86 | Iteration number: [3530/4518] 78% | Training loss: 0.6869425010579842
Epoch: 86 | Iteration number: [3540/4518] 78% | Training loss: 0.6869441578617204
Epoch: 86 | Iteration number: [3550/4518] 78% | Training loss: 0.6869414823827609
Epoch: 86 | Iteration number: [3560/4518] 78% | Training loss: 0.6869422370463275
Epoch: 86 | Iteration number: [3570/4518] 79% | Training loss: 0.6869401929592218
Epoch: 86 | Iteration number: [3580/4518] 79% | Training loss: 0.6869406688146751
Epoch: 86 | Iteration number: [3590/4518] 79% | Training loss: 0.6869437582313517
Epoch: 86 | Iteration number: [3600/4518] 79% | Training loss: 0.6869397123654684
Epoch: 86 | Iteration number: [3610/4518] 79% | Training loss: 0.6869321823450337
Epoch: 86 | Iteration number: [3620/4518] 80% | Training loss: 0.6869344869371277
Epoch: 86 | Iteration number: [3630/4518] 80% | Training loss: 0.6869325858830749
Epoch: 86 | Iteration number: [3640/4518] 80% | Training loss: 0.686930686382802
Epoch: 86 | Iteration number: [3650/4518] 80% | Training loss: 0.6869296701313699
Epoch: 86 | Iteration number: [3660/4518] 81% | Training loss: 0.6869327055463375
Epoch: 86 | Iteration number: [3670/4518] 81% | Training loss: 0.6869282106287797
Epoch: 86 | Iteration number: [3680/4518] 81% | Training loss: 0.6869294483052648
Epoch: 86 | Iteration number: [3690/4518] 81% | Training loss: 0.6869280947417747
Epoch: 86 | Iteration number: [3700/4518] 81% | Training loss: 0.68693039463984
Epoch: 86 | Iteration number: [3710/4518] 82% | Training loss: 0.6869282037742697
Epoch: 86 | Iteration number: [3720/4518] 82% | Training loss: 0.6869266247717283
Epoch: 86 | Iteration number: [3730/4518] 82% | Training loss: 0.6869303008027116
Epoch: 86 | Iteration number: [3740/4518] 82% | Training loss: 0.6869301702090126
Epoch: 86 | Iteration number: [3750/4518] 83% | Training loss: 0.6869302722771963
Epoch: 86 | Iteration number: [3760/4518] 83% | Training loss: 0.6869316584727866
Epoch: 86 | Iteration number: [3770/4518] 83% | Training loss: 0.6869335144995379
Epoch: 86 | Iteration number: [3780/4518] 83% | Training loss: 0.686932572501677
Epoch: 86 | Iteration number: [3790/4518] 83% | Training loss: 0.6869294439267987
Epoch: 86 | Iteration number: [3800/4518] 84% | Training loss: 0.6869289459680256
Epoch: 86 | Iteration number: [3810/4518] 84% | Training loss: 0.6869287006498321
Epoch: 86 | Iteration number: [3820/4518] 84% | Training loss: 0.6869282330205927
Epoch: 86 | Iteration number: [3830/4518] 84% | Training loss: 0.686927958194643
Epoch: 86 | Iteration number: [3840/4518] 84% | Training loss: 0.6869254252252479
Epoch: 86 | Iteration number: [3850/4518] 85% | Training loss: 0.6869254514923343
Epoch: 86 | Iteration number: [3860/4518] 85% | Training loss: 0.6869278057869235
Epoch: 86 | Iteration number: [3870/4518] 85% | Training loss: 0.6869307386474708
Epoch: 86 | Iteration number: [3880/4518] 85% | Training loss: 0.6869340605956992
Epoch: 86 | Iteration number: [3890/4518] 86% | Training loss: 0.6869340899517726
Epoch: 86 | Iteration number: [3900/4518] 86% | Training loss: 0.686936736886318
Epoch: 86 | Iteration number: [3910/4518] 86% | Training loss: 0.6869354678389361
Epoch: 86 | Iteration number: [3920/4518] 86% | Training loss: 0.6869372305669347
Epoch: 86 | Iteration number: [3930/4518] 86% | Training loss: 0.6869350004590498
Epoch: 86 | Iteration number: [3940/4518] 87% | Training loss: 0.68693602538956
Epoch: 86 | Iteration number: [3950/4518] 87% | Training loss: 0.6869341051125828
Epoch: 86 | Iteration number: [3960/4518] 87% | Training loss: 0.6869353769252998
Epoch: 86 | Iteration number: [3970/4518] 87% | Training loss: 0.686937116946021
Epoch: 86 | Iteration number: [3980/4518] 88% | Training loss: 0.6869371854030907
Epoch: 86 | Iteration number: [3990/4518] 88% | Training loss: 0.6869331792930613
Epoch: 86 | Iteration number: [4000/4518] 88% | Training loss: 0.6869323772192001
Epoch: 86 | Iteration number: [4010/4518] 88% | Training loss: 0.6869305308768874
Epoch: 86 | Iteration number: [4020/4518] 88% | Training loss: 0.6869317414748728
Epoch: 86 | Iteration number: [4030/4518] 89% | Training loss: 0.686929209593212
Epoch: 86 | Iteration number: [4040/4518] 89% | Training loss: 0.6869318935688179
Epoch: 86 | Iteration number: [4050/4518] 89% | Training loss: 0.6869308317149126
Epoch: 86 | Iteration number: [4060/4518] 89% | Training loss: 0.6869291068297889
Epoch: 86 | Iteration number: [4070/4518] 90% | Training loss: 0.6869294045891164
Epoch: 86 | Iteration number: [4080/4518] 90% | Training loss: 0.6869302448980948
Epoch: 86 | Iteration number: [4090/4518] 90% | Training loss: 0.6869308407120134
Epoch: 86 | Iteration number: [4100/4518] 90% | Training loss: 0.6869327638643544
Epoch: 86 | Iteration number: [4110/4518] 90% | Training loss: 0.6869309885948534
Epoch: 86 | Iteration number: [4120/4518] 91% | Training loss: 0.6869295333195659
Epoch: 86 | Iteration number: [4130/4518] 91% | Training loss: 0.6869298691178061
Epoch: 86 | Iteration number: [4140/4518] 91% | Training loss: 0.6869283496181746
Epoch: 86 | Iteration number: [4150/4518] 91% | Training loss: 0.6869285617822624
Epoch: 86 | Iteration number: [4160/4518] 92% | Training loss: 0.6869298954565938
Epoch: 86 | Iteration number: [4170/4518] 92% | Training loss: 0.6869308008421525
Epoch: 86 | Iteration number: [4180/4518] 92% | Training loss: 0.686928019540732
Epoch: 86 | Iteration number: [4190/4518] 92% | Training loss: 0.6869267988603269
Epoch: 86 | Iteration number: [4200/4518] 92% | Training loss: 0.6869259086818922
Epoch: 86 | Iteration number: [4210/4518] 93% | Training loss: 0.6869267568735499
Epoch: 86 | Iteration number: [4220/4518] 93% | Training loss: 0.6869231997790495
Epoch: 86 | Iteration number: [4230/4518] 93% | Training loss: 0.6869225431982225
Epoch: 86 | Iteration number: [4240/4518] 93% | Training loss: 0.6869200952913401
Epoch: 86 | Iteration number: [4250/4518] 94% | Training loss: 0.6869176720170413
Epoch: 86 | Iteration number: [4260/4518] 94% | Training loss: 0.6869175994620077
Epoch: 86 | Iteration number: [4270/4518] 94% | Training loss: 0.6869151241606236
Epoch: 86 | Iteration number: [4280/4518] 94% | Training loss: 0.686914825258411
Epoch: 86 | Iteration number: [4290/4518] 94% | Training loss: 0.6869146146974363
Epoch: 86 | Iteration number: [4300/4518] 95% | Training loss: 0.6869137073256248
Epoch: 86 | Iteration number: [4310/4518] 95% | Training loss: 0.6869158405577224
Epoch: 86 | Iteration number: [4320/4518] 95% | Training loss: 0.6869116446624199
Epoch: 86 | Iteration number: [4330/4518] 95% | Training loss: 0.686913510145271
Epoch: 86 | Iteration number: [4340/4518] 96% | Training loss: 0.6869138854714583
Epoch: 86 | Iteration number: [4350/4518] 96% | Training loss: 0.6869135727690554
Epoch: 86 | Iteration number: [4360/4518] 96% | Training loss: 0.6869153433436648
Epoch: 86 | Iteration number: [4370/4518] 96% | Training loss: 0.6869177290176636
Epoch: 86 | Iteration number: [4380/4518] 96% | Training loss: 0.6869174871678766
Epoch: 86 | Iteration number: [4390/4518] 97% | Training loss: 0.686921059026262
Epoch: 86 | Iteration number: [4400/4518] 97% | Training loss: 0.6869167921353471
Epoch: 86 | Iteration number: [4410/4518] 97% | Training loss: 0.6869172201270148
Epoch: 86 | Iteration number: [4420/4518] 97% | Training loss: 0.6869110800022453
Epoch: 86 | Iteration number: [4430/4518] 98% | Training loss: 0.6869084783655257
Epoch: 86 | Iteration number: [4440/4518] 98% | Training loss: 0.6869107454075469
Epoch: 86 | Iteration number: [4450/4518] 98% | Training loss: 0.6869110230247626
Epoch: 86 | Iteration number: [4460/4518] 98% | Training loss: 0.6869104776414521
Epoch: 86 | Iteration number: [4470/4518] 98% | Training loss: 0.6869037560435216
Epoch: 86 | Iteration number: [4480/4518] 99% | Training loss: 0.6869045905236687
Epoch: 86 | Iteration number: [4490/4518] 99% | Training loss: 0.6869039407551687
Epoch: 86 | Iteration number: [4500/4518] 99% | Training loss: 0.6869050299194124
Epoch: 86 | Iteration number: [4510/4518] 99% | Training loss: 0.6869064061181772

 End of epoch: 86 | Train Loss: 0.6867550414792728 | Training Time: 632 

 End of epoch: 86 | Eval Loss: 0.6895824330193656 | Evaluating Time: 17 
Epoch: 87 | Iteration number: [10/4518] 0% | Training loss: 0.7558380603790283
Epoch: 87 | Iteration number: [20/4518] 0% | Training loss: 0.7208141058683395
Epoch: 87 | Iteration number: [30/4518] 0% | Training loss: 0.7094094256560007
Epoch: 87 | Iteration number: [40/4518] 0% | Training loss: 0.7038242474198342
Epoch: 87 | Iteration number: [50/4518] 1% | Training loss: 0.7005316936969757
Epoch: 87 | Iteration number: [60/4518] 1% | Training loss: 0.6982542475064596
Epoch: 87 | Iteration number: [70/4518] 1% | Training loss: 0.6965934574604035
Epoch: 87 | Iteration number: [80/4518] 1% | Training loss: 0.6952912449836731
Epoch: 87 | Iteration number: [90/4518] 1% | Training loss: 0.6943700697686938
Epoch: 87 | Iteration number: [100/4518] 2% | Training loss: 0.6935805690288543
Epoch: 87 | Iteration number: [110/4518] 2% | Training loss: 0.6930281346494501
Epoch: 87 | Iteration number: [120/4518] 2% | Training loss: 0.6924931079149246
Epoch: 87 | Iteration number: [130/4518] 2% | Training loss: 0.6921004166969886
Epoch: 87 | Iteration number: [140/4518] 3% | Training loss: 0.6917308092117309
Epoch: 87 | Iteration number: [150/4518] 3% | Training loss: 0.6914175816377004
Epoch: 87 | Iteration number: [160/4518] 3% | Training loss: 0.6911795333027839
Epoch: 87 | Iteration number: [170/4518] 3% | Training loss: 0.6908858541180106
Epoch: 87 | Iteration number: [180/4518] 3% | Training loss: 0.6906282977925406
Epoch: 87 | Iteration number: [190/4518] 4% | Training loss: 0.6904323555921253
Epoch: 87 | Iteration number: [200/4518] 4% | Training loss: 0.6902302026748657
Epoch: 87 | Iteration number: [210/4518] 4% | Training loss: 0.690100748198373
Epoch: 87 | Iteration number: [220/4518] 4% | Training loss: 0.6899747723882849
Epoch: 87 | Iteration number: [230/4518] 5% | Training loss: 0.689869552332422
Epoch: 87 | Iteration number: [240/4518] 5% | Training loss: 0.6896913779278596
Epoch: 87 | Iteration number: [250/4518] 5% | Training loss: 0.6895847008228302
Epoch: 87 | Iteration number: [260/4518] 5% | Training loss: 0.6894796832249714
Epoch: 87 | Iteration number: [270/4518] 5% | Training loss: 0.6893506652779049
Epoch: 87 | Iteration number: [280/4518] 6% | Training loss: 0.6892549110310419
Epoch: 87 | Iteration number: [290/4518] 6% | Training loss: 0.6891895033162215
Epoch: 87 | Iteration number: [300/4518] 6% | Training loss: 0.689128453930219
Epoch: 87 | Iteration number: [310/4518] 6% | Training loss: 0.6890124588243423
Epoch: 87 | Iteration number: [320/4518] 7% | Training loss: 0.6889432245865464
Epoch: 87 | Iteration number: [330/4518] 7% | Training loss: 0.6888339434609269
Epoch: 87 | Iteration number: [340/4518] 7% | Training loss: 0.6887722169651704
Epoch: 87 | Iteration number: [350/4518] 7% | Training loss: 0.6887013838972365
Epoch: 87 | Iteration number: [360/4518] 7% | Training loss: 0.6886551772554715
Epoch: 87 | Iteration number: [370/4518] 8% | Training loss: 0.6885835958493722
Epoch: 87 | Iteration number: [380/4518] 8% | Training loss: 0.688560990910781
Epoch: 87 | Iteration number: [390/4518] 8% | Training loss: 0.6885089186521677
Epoch: 87 | Iteration number: [400/4518] 8% | Training loss: 0.6884503646194935
Epoch: 87 | Iteration number: [410/4518] 9% | Training loss: 0.6883917538131156
Epoch: 87 | Iteration number: [420/4518] 9% | Training loss: 0.6883764969451087
Epoch: 87 | Iteration number: [430/4518] 9% | Training loss: 0.6883217638315157
Epoch: 87 | Iteration number: [440/4518] 9% | Training loss: 0.6882606962865049
Epoch: 87 | Iteration number: [450/4518] 9% | Training loss: 0.6882271428902944
Epoch: 87 | Iteration number: [460/4518] 10% | Training loss: 0.6881927162408829
Epoch: 87 | Iteration number: [470/4518] 10% | Training loss: 0.6881776439382675
Epoch: 87 | Iteration number: [480/4518] 10% | Training loss: 0.6881455149501562
Epoch: 87 | Iteration number: [490/4518] 10% | Training loss: 0.6881323127114043
Epoch: 87 | Iteration number: [500/4518] 11% | Training loss: 0.6880841273069381
Epoch: 87 | Iteration number: [510/4518] 11% | Training loss: 0.6880478049025817
Epoch: 87 | Iteration number: [520/4518] 11% | Training loss: 0.6880036331140078
Epoch: 87 | Iteration number: [530/4518] 11% | Training loss: 0.6879721803485223
Epoch: 87 | Iteration number: [540/4518] 11% | Training loss: 0.6879416522052553
Epoch: 87 | Iteration number: [550/4518] 12% | Training loss: 0.6879097254709764
Epoch: 87 | Iteration number: [560/4518] 12% | Training loss: 0.6878937989473343
Epoch: 87 | Iteration number: [570/4518] 12% | Training loss: 0.6878476369799229
Epoch: 87 | Iteration number: [580/4518] 12% | Training loss: 0.6878483476309941
Epoch: 87 | Iteration number: [590/4518] 13% | Training loss: 0.6878206332861367
Epoch: 87 | Iteration number: [600/4518] 13% | Training loss: 0.6878041942914327
Epoch: 87 | Iteration number: [610/4518] 13% | Training loss: 0.6877896403680083
Epoch: 87 | Iteration number: [620/4518] 13% | Training loss: 0.6877948845586469
Epoch: 87 | Iteration number: [630/4518] 13% | Training loss: 0.6877707080235557
Epoch: 87 | Iteration number: [640/4518] 14% | Training loss: 0.6877330644987524
Epoch: 87 | Iteration number: [650/4518] 14% | Training loss: 0.6877304144089038
Epoch: 87 | Iteration number: [660/4518] 14% | Training loss: 0.6877199961380525
Epoch: 87 | Iteration number: [670/4518] 14% | Training loss: 0.687702212404849
Epoch: 87 | Iteration number: [680/4518] 15% | Training loss: 0.6876959967262605
Epoch: 87 | Iteration number: [690/4518] 15% | Training loss: 0.6876693751501001
Epoch: 87 | Iteration number: [700/4518] 15% | Training loss: 0.6876641075100217
Epoch: 87 | Iteration number: [710/4518] 15% | Training loss: 0.6876383556446559
Epoch: 87 | Iteration number: [720/4518] 15% | Training loss: 0.6876074399385187
Epoch: 87 | Iteration number: [730/4518] 16% | Training loss: 0.6875733446584988
Epoch: 87 | Iteration number: [740/4518] 16% | Training loss: 0.6875663552735303
Epoch: 87 | Iteration number: [750/4518] 16% | Training loss: 0.6875413715044657
Epoch: 87 | Iteration number: [760/4518] 16% | Training loss: 0.6875362224484745
Epoch: 87 | Iteration number: [770/4518] 17% | Training loss: 0.6875127119677408
Epoch: 87 | Iteration number: [780/4518] 17% | Training loss: 0.6875009581828728
Epoch: 87 | Iteration number: [790/4518] 17% | Training loss: 0.6874933352198782
Epoch: 87 | Iteration number: [800/4518] 17% | Training loss: 0.6874827110767364
Epoch: 87 | Iteration number: [810/4518] 17% | Training loss: 0.6874696092105206
Epoch: 87 | Iteration number: [820/4518] 18% | Training loss: 0.6874611137116827
Epoch: 87 | Iteration number: [830/4518] 18% | Training loss: 0.6874584527618913
Epoch: 87 | Iteration number: [840/4518] 18% | Training loss: 0.687451411925611
Epoch: 87 | Iteration number: [850/4518] 18% | Training loss: 0.6874432390577653
Epoch: 87 | Iteration number: [860/4518] 19% | Training loss: 0.6874378751876742
Epoch: 87 | Iteration number: [870/4518] 19% | Training loss: 0.6874269994511002
Epoch: 87 | Iteration number: [880/4518] 19% | Training loss: 0.6874122146178375
Epoch: 87 | Iteration number: [890/4518] 19% | Training loss: 0.6874093469609035
Epoch: 87 | Iteration number: [900/4518] 19% | Training loss: 0.6874091378185484
Epoch: 87 | Iteration number: [910/4518] 20% | Training loss: 0.6873990645120432
Epoch: 87 | Iteration number: [920/4518] 20% | Training loss: 0.6873884878080824
Epoch: 87 | Iteration number: [930/4518] 20% | Training loss: 0.6873720726659222
Epoch: 87 | Iteration number: [940/4518] 20% | Training loss: 0.68735701429083
Epoch: 87 | Iteration number: [950/4518] 21% | Training loss: 0.6873349418138203
Epoch: 87 | Iteration number: [960/4518] 21% | Training loss: 0.687321690407892
Epoch: 87 | Iteration number: [970/4518] 21% | Training loss: 0.6873202421616034
Epoch: 87 | Iteration number: [980/4518] 21% | Training loss: 0.6873076556288467
Epoch: 87 | Iteration number: [990/4518] 21% | Training loss: 0.6873023870015386
Epoch: 87 | Iteration number: [1000/4518] 22% | Training loss: 0.6873095269799232
Epoch: 87 | Iteration number: [1010/4518] 22% | Training loss: 0.6873053525934125
Epoch: 87 | Iteration number: [1020/4518] 22% | Training loss: 0.6873057475277021
Epoch: 87 | Iteration number: [1030/4518] 22% | Training loss: 0.6872994211113569
Epoch: 87 | Iteration number: [1040/4518] 23% | Training loss: 0.6872935057259523
Epoch: 87 | Iteration number: [1050/4518] 23% | Training loss: 0.6872863009430114
Epoch: 87 | Iteration number: [1060/4518] 23% | Training loss: 0.6872906550483884
Epoch: 87 | Iteration number: [1070/4518] 23% | Training loss: 0.6872897597116845
Epoch: 87 | Iteration number: [1080/4518] 23% | Training loss: 0.6872916301643407
Epoch: 87 | Iteration number: [1090/4518] 24% | Training loss: 0.6872940314472269
Epoch: 87 | Iteration number: [1100/4518] 24% | Training loss: 0.6872731196880341
Epoch: 87 | Iteration number: [1110/4518] 24% | Training loss: 0.6872708127842293
Epoch: 87 | Iteration number: [1120/4518] 24% | Training loss: 0.6872593956334251
Epoch: 87 | Iteration number: [1130/4518] 25% | Training loss: 0.6872473499943724
Epoch: 87 | Iteration number: [1140/4518] 25% | Training loss: 0.6872392050529781
Epoch: 87 | Iteration number: [1150/4518] 25% | Training loss: 0.6872316156781239
Epoch: 87 | Iteration number: [1160/4518] 25% | Training loss: 0.687235699439871
Epoch: 87 | Iteration number: [1170/4518] 25% | Training loss: 0.687222742728698
Epoch: 87 | Iteration number: [1180/4518] 26% | Training loss: 0.6872184396800348
Epoch: 87 | Iteration number: [1190/4518] 26% | Training loss: 0.6872149311694778
Epoch: 87 | Iteration number: [1200/4518] 26% | Training loss: 0.6872075758377711
Epoch: 87 | Iteration number: [1210/4518] 26% | Training loss: 0.6872033306882401
Epoch: 87 | Iteration number: [1220/4518] 27% | Training loss: 0.6872026952563739
Epoch: 87 | Iteration number: [1230/4518] 27% | Training loss: 0.6871853054054384
Epoch: 87 | Iteration number: [1240/4518] 27% | Training loss: 0.6871832839904293
Epoch: 87 | Iteration number: [1250/4518] 27% | Training loss: 0.687165997171402
Epoch: 87 | Iteration number: [1260/4518] 27% | Training loss: 0.687166683730625
Epoch: 87 | Iteration number: [1270/4518] 28% | Training loss: 0.6871568967976908
Epoch: 87 | Iteration number: [1280/4518] 28% | Training loss: 0.68714770055376
Epoch: 87 | Iteration number: [1290/4518] 28% | Training loss: 0.6871378824230312
Epoch: 87 | Iteration number: [1300/4518] 28% | Training loss: 0.6871403533678788
Epoch: 87 | Iteration number: [1310/4518] 28% | Training loss: 0.6871380153958124
Epoch: 87 | Iteration number: [1320/4518] 29% | Training loss: 0.687136279633551
Epoch: 87 | Iteration number: [1330/4518] 29% | Training loss: 0.6871286103151795
Epoch: 87 | Iteration number: [1340/4518] 29% | Training loss: 0.687131729143769
Epoch: 87 | Iteration number: [1350/4518] 29% | Training loss: 0.687115093337165
Epoch: 87 | Iteration number: [1360/4518] 30% | Training loss: 0.6871023503734784
Epoch: 87 | Iteration number: [1370/4518] 30% | Training loss: 0.6871085076871579
Epoch: 87 | Iteration number: [1380/4518] 30% | Training loss: 0.6870962336011555
Epoch: 87 | Iteration number: [1390/4518] 30% | Training loss: 0.6870904788696509
Epoch: 87 | Iteration number: [1400/4518] 30% | Training loss: 0.6870971933432988
Epoch: 87 | Iteration number: [1410/4518] 31% | Training loss: 0.6870922480069154
Epoch: 87 | Iteration number: [1420/4518] 31% | Training loss: 0.6870957372473999
Epoch: 87 | Iteration number: [1430/4518] 31% | Training loss: 0.6871045070511478
Epoch: 87 | Iteration number: [1440/4518] 31% | Training loss: 0.687109254921476
Epoch: 87 | Iteration number: [1450/4518] 32% | Training loss: 0.687103056167734
Epoch: 87 | Iteration number: [1460/4518] 32% | Training loss: 0.687102357083804
Epoch: 87 | Iteration number: [1470/4518] 32% | Training loss: 0.6870977950744889
Epoch: 87 | Iteration number: [1480/4518] 32% | Training loss: 0.6870944371900043
Epoch: 87 | Iteration number: [1490/4518] 32% | Training loss: 0.6870944787191865
Epoch: 87 | Iteration number: [1500/4518] 33% | Training loss: 0.687088595310847
Epoch: 87 | Iteration number: [1510/4518] 33% | Training loss: 0.6870882881792966
Epoch: 87 | Iteration number: [1520/4518] 33% | Training loss: 0.68708648740461
Epoch: 87 | Iteration number: [1530/4518] 33% | Training loss: 0.6870883623369379
Epoch: 87 | Iteration number: [1540/4518] 34% | Training loss: 0.6870813768792462
Epoch: 87 | Iteration number: [1550/4518] 34% | Training loss: 0.6870775510034254
Epoch: 87 | Iteration number: [1560/4518] 34% | Training loss: 0.6870725738314482
Epoch: 87 | Iteration number: [1570/4518] 34% | Training loss: 0.6870656616748518
Epoch: 87 | Iteration number: [1580/4518] 34% | Training loss: 0.6870614899487435
Epoch: 87 | Iteration number: [1590/4518] 35% | Training loss: 0.6870555549672565
Epoch: 87 | Iteration number: [1600/4518] 35% | Training loss: 0.6870508547127246
Epoch: 87 | Iteration number: [1610/4518] 35% | Training loss: 0.687044994801468
Epoch: 87 | Iteration number: [1620/4518] 35% | Training loss: 0.6870339659996975
Epoch: 87 | Iteration number: [1630/4518] 36% | Training loss: 0.6870364637462639
Epoch: 87 | Iteration number: [1640/4518] 36% | Training loss: 0.6870284871720687
Epoch: 87 | Iteration number: [1650/4518] 36% | Training loss: 0.6870339610721126
Epoch: 87 | Iteration number: [1660/4518] 36% | Training loss: 0.6870287372046207
Epoch: 87 | Iteration number: [1670/4518] 36% | Training loss: 0.6870269070485395
Epoch: 87 | Iteration number: [1680/4518] 37% | Training loss: 0.6870149643293448
Epoch: 87 | Iteration number: [1690/4518] 37% | Training loss: 0.6870043354626943
Epoch: 87 | Iteration number: [1700/4518] 37% | Training loss: 0.6869995866803562
Epoch: 87 | Iteration number: [1710/4518] 37% | Training loss: 0.6869977135058732
Epoch: 87 | Iteration number: [1720/4518] 38% | Training loss: 0.6869946760147116
Epoch: 87 | Iteration number: [1730/4518] 38% | Training loss: 0.6869820786693882
Epoch: 87 | Iteration number: [1740/4518] 38% | Training loss: 0.6869707295264321
Epoch: 87 | Iteration number: [1750/4518] 38% | Training loss: 0.6869677656378065
Epoch: 87 | Iteration number: [1760/4518] 38% | Training loss: 0.6869710547341542
Epoch: 87 | Iteration number: [1770/4518] 39% | Training loss: 0.6869721869964384
Epoch: 87 | Iteration number: [1780/4518] 39% | Training loss: 0.686970705765017
Epoch: 87 | Iteration number: [1790/4518] 39% | Training loss: 0.6869682824145482
Epoch: 87 | Iteration number: [1800/4518] 39% | Training loss: 0.6869719780484835
Epoch: 87 | Iteration number: [1810/4518] 40% | Training loss: 0.6869712877998035
Epoch: 87 | Iteration number: [1820/4518] 40% | Training loss: 0.6869724623449556
Epoch: 87 | Iteration number: [1830/4518] 40% | Training loss: 0.686977451551156
Epoch: 87 | Iteration number: [1840/4518] 40% | Training loss: 0.6869762836267119
Epoch: 87 | Iteration number: [1850/4518] 40% | Training loss: 0.6869773007727958
Epoch: 87 | Iteration number: [1860/4518] 41% | Training loss: 0.6869777995732522
Epoch: 87 | Iteration number: [1870/4518] 41% | Training loss: 0.686977931841172
Epoch: 87 | Iteration number: [1880/4518] 41% | Training loss: 0.6869801113897182
Epoch: 87 | Iteration number: [1890/4518] 41% | Training loss: 0.6869795996360678
Epoch: 87 | Iteration number: [1900/4518] 42% | Training loss: 0.6869776537543849
Epoch: 87 | Iteration number: [1910/4518] 42% | Training loss: 0.6869747311657012
Epoch: 87 | Iteration number: [1920/4518] 42% | Training loss: 0.6869727705605329
Epoch: 87 | Iteration number: [1930/4518] 42% | Training loss: 0.6869705018910719
Epoch: 87 | Iteration number: [1940/4518] 42% | Training loss: 0.686966994558413
Epoch: 87 | Iteration number: [1950/4518] 43% | Training loss: 0.6869678462162996
Epoch: 87 | Iteration number: [1960/4518] 43% | Training loss: 0.6869663111409362
Epoch: 87 | Iteration number: [1970/4518] 43% | Training loss: 0.6869661652194667
Epoch: 87 | Iteration number: [1980/4518] 43% | Training loss: 0.6869590361913045
Epoch: 87 | Iteration number: [1990/4518] 44% | Training loss: 0.6869590962052944
Epoch: 87 | Iteration number: [2000/4518] 44% | Training loss: 0.6869601309895516
Epoch: 87 | Iteration number: [2010/4518] 44% | Training loss: 0.6869604541887692
Epoch: 87 | Iteration number: [2020/4518] 44% | Training loss: 0.686960173685952
Epoch: 87 | Iteration number: [2030/4518] 44% | Training loss: 0.6869633063306949
Epoch: 87 | Iteration number: [2040/4518] 45% | Training loss: 0.6869589577118556
Epoch: 87 | Iteration number: [2050/4518] 45% | Training loss: 0.6869571515408958
Epoch: 87 | Iteration number: [2060/4518] 45% | Training loss: 0.6869547788379262
Epoch: 87 | Iteration number: [2070/4518] 45% | Training loss: 0.6869586995258423
Epoch: 87 | Iteration number: [2080/4518] 46% | Training loss: 0.6869673256690686
Epoch: 87 | Iteration number: [2090/4518] 46% | Training loss: 0.6869665970927791
Epoch: 87 | Iteration number: [2100/4518] 46% | Training loss: 0.6869697407597587
Epoch: 87 | Iteration number: [2110/4518] 46% | Training loss: 0.6869665550677132
Epoch: 87 | Iteration number: [2120/4518] 46% | Training loss: 0.6869627899156426
Epoch: 87 | Iteration number: [2130/4518] 47% | Training loss: 0.6869651446320082
Epoch: 87 | Iteration number: [2140/4518] 47% | Training loss: 0.6869624980977762
Epoch: 87 | Iteration number: [2150/4518] 47% | Training loss: 0.6869646044664605
Epoch: 87 | Iteration number: [2160/4518] 47% | Training loss: 0.6869673473967446
Epoch: 87 | Iteration number: [2170/4518] 48% | Training loss: 0.6869657668649876
Epoch: 87 | Iteration number: [2180/4518] 48% | Training loss: 0.686967295271541
Epoch: 87 | Iteration number: [2190/4518] 48% | Training loss: 0.6869713713044989
Epoch: 87 | Iteration number: [2200/4518] 48% | Training loss: 0.6869667767665603
Epoch: 87 | Iteration number: [2210/4518] 48% | Training loss: 0.6869687054761394
Epoch: 87 | Iteration number: [2220/4518] 49% | Training loss: 0.6869616037016516
Epoch: 87 | Iteration number: [2230/4518] 49% | Training loss: 0.6869673843341023
Epoch: 87 | Iteration number: [2240/4518] 49% | Training loss: 0.6869696870446205
Epoch: 87 | Iteration number: [2250/4518] 49% | Training loss: 0.6869688207043542
Epoch: 87 | Iteration number: [2260/4518] 50% | Training loss: 0.686966885534008
Epoch: 87 | Iteration number: [2270/4518] 50% | Training loss: 0.6869686715928468
Epoch: 87 | Iteration number: [2280/4518] 50% | Training loss: 0.686967615809357
Epoch: 87 | Iteration number: [2290/4518] 50% | Training loss: 0.6869643855563418
Epoch: 87 | Iteration number: [2300/4518] 50% | Training loss: 0.6869657766819001
Epoch: 87 | Iteration number: [2310/4518] 51% | Training loss: 0.6869718890427511
Epoch: 87 | Iteration number: [2320/4518] 51% | Training loss: 0.6869731696772164
Epoch: 87 | Iteration number: [2330/4518] 51% | Training loss: 0.6869726545820932
Epoch: 87 | Iteration number: [2340/4518] 51% | Training loss: 0.686971706381211
Epoch: 87 | Iteration number: [2350/4518] 52% | Training loss: 0.6869702447982544
Epoch: 87 | Iteration number: [2360/4518] 52% | Training loss: 0.6869646612365367
Epoch: 87 | Iteration number: [2370/4518] 52% | Training loss: 0.6869685035466142
Epoch: 87 | Iteration number: [2380/4518] 52% | Training loss: 0.6869665562856098
Epoch: 87 | Iteration number: [2390/4518] 52% | Training loss: 0.6869684159755707
Epoch: 87 | Iteration number: [2400/4518] 53% | Training loss: 0.68697545448939
Epoch: 87 | Iteration number: [2410/4518] 53% | Training loss: 0.6869790546379644
Epoch: 87 | Iteration number: [2420/4518] 53% | Training loss: 0.6869805794116879
Epoch: 87 | Iteration number: [2430/4518] 53% | Training loss: 0.686980838515631
Epoch: 87 | Iteration number: [2440/4518] 54% | Training loss: 0.6869808047277028
Epoch: 87 | Iteration number: [2450/4518] 54% | Training loss: 0.6869822063008133
Epoch: 87 | Iteration number: [2460/4518] 54% | Training loss: 0.6869808717714092
Epoch: 87 | Iteration number: [2470/4518] 54% | Training loss: 0.6869811765819426
Epoch: 87 | Iteration number: [2480/4518] 54% | Training loss: 0.6869802476657975
Epoch: 87 | Iteration number: [2490/4518] 55% | Training loss: 0.6869754288330614
Epoch: 87 | Iteration number: [2500/4518] 55% | Training loss: 0.6869683127880096
Epoch: 87 | Iteration number: [2510/4518] 55% | Training loss: 0.6869668636901445
Epoch: 87 | Iteration number: [2520/4518] 55% | Training loss: 0.6869637503746956
Epoch: 87 | Iteration number: [2530/4518] 55% | Training loss: 0.6869574854025257
Epoch: 87 | Iteration number: [2540/4518] 56% | Training loss: 0.6869546282948471
Epoch: 87 | Iteration number: [2550/4518] 56% | Training loss: 0.6869551821549733
Epoch: 87 | Iteration number: [2560/4518] 56% | Training loss: 0.6869485083036124
Epoch: 87 | Iteration number: [2570/4518] 56% | Training loss: 0.6869455851469523
Epoch: 87 | Iteration number: [2580/4518] 57% | Training loss: 0.6869471383418224
Epoch: 87 | Iteration number: [2590/4518] 57% | Training loss: 0.6869457939646879
Epoch: 87 | Iteration number: [2600/4518] 57% | Training loss: 0.6869458065583156
Epoch: 87 | Iteration number: [2610/4518] 57% | Training loss: 0.6869503200054169
Epoch: 87 | Iteration number: [2620/4518] 57% | Training loss: 0.6869563731073424
Epoch: 87 | Iteration number: [2630/4518] 58% | Training loss: 0.6869600143496074
Epoch: 87 | Iteration number: [2640/4518] 58% | Training loss: 0.6869623443393996
Epoch: 87 | Iteration number: [2650/4518] 58% | Training loss: 0.6869587844722675
Epoch: 87 | Iteration number: [2660/4518] 58% | Training loss: 0.6869562005862258
Epoch: 87 | Iteration number: [2670/4518] 59% | Training loss: 0.6869567010063357
Epoch: 87 | Iteration number: [2680/4518] 59% | Training loss: 0.6869554798327275
Epoch: 87 | Iteration number: [2690/4518] 59% | Training loss: 0.6869583441200753
Epoch: 87 | Iteration number: [2700/4518] 59% | Training loss: 0.6869565194182926
Epoch: 87 | Iteration number: [2710/4518] 59% | Training loss: 0.6869573433680728
Epoch: 87 | Iteration number: [2720/4518] 60% | Training loss: 0.6869620339616257
Epoch: 87 | Iteration number: [2730/4518] 60% | Training loss: 0.6869560658495069
Epoch: 87 | Iteration number: [2740/4518] 60% | Training loss: 0.6869530648645693
Epoch: 87 | Iteration number: [2750/4518] 60% | Training loss: 0.6869557465856726
Epoch: 87 | Iteration number: [2760/4518] 61% | Training loss: 0.6869567562488542
Epoch: 87 | Iteration number: [2770/4518] 61% | Training loss: 0.6869585694603971
Epoch: 87 | Iteration number: [2780/4518] 61% | Training loss: 0.6869625165093717
Epoch: 87 | Iteration number: [2790/4518] 61% | Training loss: 0.6869606706403917
Epoch: 87 | Iteration number: [2800/4518] 61% | Training loss: 0.6869514403385776
Epoch: 87 | Iteration number: [2810/4518] 62% | Training loss: 0.6869547273552715
Epoch: 87 | Iteration number: [2820/4518] 62% | Training loss: 0.6869557482130983
Epoch: 87 | Iteration number: [2830/4518] 62% | Training loss: 0.6869580542662118
Epoch: 87 | Iteration number: [2840/4518] 62% | Training loss: 0.6869528154881908
Epoch: 87 | Iteration number: [2850/4518] 63% | Training loss: 0.6869522646017242
Epoch: 87 | Iteration number: [2860/4518] 63% | Training loss: 0.6869523800336398
Epoch: 87 | Iteration number: [2870/4518] 63% | Training loss: 0.6869561310013828
Epoch: 87 | Iteration number: [2880/4518] 63% | Training loss: 0.6869562542272939
Epoch: 87 | Iteration number: [2890/4518] 63% | Training loss: 0.6869587654679704
Epoch: 87 | Iteration number: [2900/4518] 64% | Training loss: 0.6869567281418834
Epoch: 87 | Iteration number: [2910/4518] 64% | Training loss: 0.6869559082993117
Epoch: 87 | Iteration number: [2920/4518] 64% | Training loss: 0.6869552620469708
Epoch: 87 | Iteration number: [2930/4518] 64% | Training loss: 0.686956176599138
Epoch: 87 | Iteration number: [2940/4518] 65% | Training loss: 0.6869522972982757
Epoch: 87 | Iteration number: [2950/4518] 65% | Training loss: 0.6869524026927302
Epoch: 87 | Iteration number: [2960/4518] 65% | Training loss: 0.6869545513310948
Epoch: 87 | Iteration number: [2970/4518] 65% | Training loss: 0.686956031053556
Epoch: 87 | Iteration number: [2980/4518] 65% | Training loss: 0.6869577563449041
Epoch: 87 | Iteration number: [2990/4518] 66% | Training loss: 0.6869567447282797
Epoch: 87 | Iteration number: [3000/4518] 66% | Training loss: 0.6869548549056053
Epoch: 87 | Iteration number: [3010/4518] 66% | Training loss: 0.6869551628729038
Epoch: 87 | Iteration number: [3020/4518] 66% | Training loss: 0.6869552538884397
Epoch: 87 | Iteration number: [3030/4518] 67% | Training loss: 0.6869526432685726
Epoch: 87 | Iteration number: [3040/4518] 67% | Training loss: 0.6869532011057201
Epoch: 87 | Iteration number: [3050/4518] 67% | Training loss: 0.6869508063011482
Epoch: 87 | Iteration number: [3060/4518] 67% | Training loss: 0.6869492609516468
Epoch: 87 | Iteration number: [3070/4518] 67% | Training loss: 0.6869472187388603
Epoch: 87 | Iteration number: [3080/4518] 68% | Training loss: 0.6869483124319609
Epoch: 87 | Iteration number: [3090/4518] 68% | Training loss: 0.6869473104723834
Epoch: 87 | Iteration number: [3100/4518] 68% | Training loss: 0.6869455210816475
Epoch: 87 | Iteration number: [3110/4518] 68% | Training loss: 0.6869431070192834
Epoch: 87 | Iteration number: [3120/4518] 69% | Training loss: 0.6869420263438653
Epoch: 87 | Iteration number: [3130/4518] 69% | Training loss: 0.6869409599433691
Epoch: 87 | Iteration number: [3140/4518] 69% | Training loss: 0.6869406037269884
Epoch: 87 | Iteration number: [3150/4518] 69% | Training loss: 0.6869361244307624
Epoch: 87 | Iteration number: [3160/4518] 69% | Training loss: 0.6869356565083129
Epoch: 87 | Iteration number: [3170/4518] 70% | Training loss: 0.6869344930167454
Epoch: 87 | Iteration number: [3180/4518] 70% | Training loss: 0.6869368055144196
Epoch: 87 | Iteration number: [3190/4518] 70% | Training loss: 0.686935444106129
Epoch: 87 | Iteration number: [3200/4518] 70% | Training loss: 0.6869379037246108
Epoch: 87 | Iteration number: [3210/4518] 71% | Training loss: 0.6869410487721642
Epoch: 87 | Iteration number: [3220/4518] 71% | Training loss: 0.686940331377598
Epoch: 87 | Iteration number: [3230/4518] 71% | Training loss: 0.6869443364925798
Epoch: 87 | Iteration number: [3240/4518] 71% | Training loss: 0.6869453508544852
Epoch: 87 | Iteration number: [3250/4518] 71% | Training loss: 0.6869447409739862
Epoch: 87 | Iteration number: [3260/4518] 72% | Training loss: 0.6869427507274721
Epoch: 87 | Iteration number: [3270/4518] 72% | Training loss: 0.6869421772453763
Epoch: 87 | Iteration number: [3280/4518] 72% | Training loss: 0.6869453839230828
Epoch: 87 | Iteration number: [3290/4518] 72% | Training loss: 0.6869421552017467
Epoch: 87 | Iteration number: [3300/4518] 73% | Training loss: 0.6869434847976222
Epoch: 87 | Iteration number: [3310/4518] 73% | Training loss: 0.6869448683413134
Epoch: 87 | Iteration number: [3320/4518] 73% | Training loss: 0.6869439925774035
Epoch: 87 | Iteration number: [3330/4518] 73% | Training loss: 0.6869466340935624
Epoch: 87 | Iteration number: [3340/4518] 73% | Training loss: 0.6869472503840567
Epoch: 87 | Iteration number: [3350/4518] 74% | Training loss: 0.6869490630946942
Epoch: 87 | Iteration number: [3360/4518] 74% | Training loss: 0.6869465416563408
Epoch: 87 | Iteration number: [3370/4518] 74% | Training loss: 0.6869468757766645
Epoch: 87 | Iteration number: [3380/4518] 74% | Training loss: 0.686945012705566
Epoch: 87 | Iteration number: [3390/4518] 75% | Training loss: 0.6869468722547402
Epoch: 87 | Iteration number: [3400/4518] 75% | Training loss: 0.6869454719915109
Epoch: 87 | Iteration number: [3410/4518] 75% | Training loss: 0.686943022858712
Epoch: 87 | Iteration number: [3420/4518] 75% | Training loss: 0.6869371762575461
Epoch: 87 | Iteration number: [3430/4518] 75% | Training loss: 0.6869339809820881
Epoch: 87 | Iteration number: [3440/4518] 76% | Training loss: 0.686935214854257
Epoch: 87 | Iteration number: [3450/4518] 76% | Training loss: 0.6869331264841384
Epoch: 87 | Iteration number: [3460/4518] 76% | Training loss: 0.6869332590027352
Epoch: 87 | Iteration number: [3470/4518] 76% | Training loss: 0.6869348413318996
Epoch: 87 | Iteration number: [3480/4518] 77% | Training loss: 0.6869354217559441
Epoch: 87 | Iteration number: [3490/4518] 77% | Training loss: 0.6869376028164752
Epoch: 87 | Iteration number: [3500/4518] 77% | Training loss: 0.6869396445580891
Epoch: 87 | Iteration number: [3510/4518] 77% | Training loss: 0.6869402064387276
Epoch: 87 | Iteration number: [3520/4518] 77% | Training loss: 0.6869429609484293
Epoch: 87 | Iteration number: [3530/4518] 78% | Training loss: 0.6869414449075801
Epoch: 87 | Iteration number: [3540/4518] 78% | Training loss: 0.6869374881188075
Epoch: 87 | Iteration number: [3550/4518] 78% | Training loss: 0.6869349057405767
Epoch: 87 | Iteration number: [3560/4518] 78% | Training loss: 0.686935307504086
Epoch: 87 | Iteration number: [3570/4518] 79% | Training loss: 0.6869324944266418
Epoch: 87 | Iteration number: [3580/4518] 79% | Training loss: 0.686929798775545
Epoch: 87 | Iteration number: [3590/4518] 79% | Training loss: 0.6869250555224405
Epoch: 87 | Iteration number: [3600/4518] 79% | Training loss: 0.6869263256920709
Epoch: 87 | Iteration number: [3610/4518] 79% | Training loss: 0.6869230518380691
Epoch: 87 | Iteration number: [3620/4518] 80% | Training loss: 0.686921805703179
Epoch: 87 | Iteration number: [3630/4518] 80% | Training loss: 0.6869229807669794
Epoch: 87 | Iteration number: [3640/4518] 80% | Training loss: 0.6869231077995929
Epoch: 87 | Iteration number: [3650/4518] 80% | Training loss: 0.6869206311931348
Epoch: 87 | Iteration number: [3660/4518] 81% | Training loss: 0.6869171903758753
Epoch: 87 | Iteration number: [3670/4518] 81% | Training loss: 0.6869182335420915
Epoch: 87 | Iteration number: [3680/4518] 81% | Training loss: 0.686918198754606
Epoch: 87 | Iteration number: [3690/4518] 81% | Training loss: 0.6869190618597718
Epoch: 87 | Iteration number: [3700/4518] 81% | Training loss: 0.6869171471531327
Epoch: 87 | Iteration number: [3710/4518] 82% | Training loss: 0.6869133069830121
Epoch: 87 | Iteration number: [3720/4518] 82% | Training loss: 0.6869143058375645
Epoch: 87 | Iteration number: [3730/4518] 82% | Training loss: 0.6869138680897833
Epoch: 87 | Iteration number: [3740/4518] 82% | Training loss: 0.6869154845329529
Epoch: 87 | Iteration number: [3750/4518] 83% | Training loss: 0.6869136987368266
Epoch: 87 | Iteration number: [3760/4518] 83% | Training loss: 0.6869094562023244
Epoch: 87 | Iteration number: [3770/4518] 83% | Training loss: 0.6869075768348076
Epoch: 87 | Iteration number: [3780/4518] 83% | Training loss: 0.686906473157267
Epoch: 87 | Iteration number: [3790/4518] 83% | Training loss: 0.686901927057231
Epoch: 87 | Iteration number: [3800/4518] 84% | Training loss: 0.6869027085053293
Epoch: 87 | Iteration number: [3810/4518] 84% | Training loss: 0.6869032307403294
Epoch: 87 | Iteration number: [3820/4518] 84% | Training loss: 0.6869019639429622
Epoch: 87 | Iteration number: [3830/4518] 84% | Training loss: 0.6869035070776628
Epoch: 87 | Iteration number: [3840/4518] 84% | Training loss: 0.6869022977848848
Epoch: 87 | Iteration number: [3850/4518] 85% | Training loss: 0.6869000465993758
Epoch: 87 | Iteration number: [3860/4518] 85% | Training loss: 0.6869011273810283
Epoch: 87 | Iteration number: [3870/4518] 85% | Training loss: 0.6869022581774443
Epoch: 87 | Iteration number: [3880/4518] 85% | Training loss: 0.6868982563928231
Epoch: 87 | Iteration number: [3890/4518] 86% | Training loss: 0.6868992424562842
Epoch: 87 | Iteration number: [3900/4518] 86% | Training loss: 0.6869014448080307
Epoch: 87 | Iteration number: [3910/4518] 86% | Training loss: 0.6869009497525442
Epoch: 87 | Iteration number: [3920/4518] 86% | Training loss: 0.686901283370597
Epoch: 87 | Iteration number: [3930/4518] 86% | Training loss: 0.6868995772214943
Epoch: 87 | Iteration number: [3940/4518] 87% | Training loss: 0.6868995590863494
Epoch: 87 | Iteration number: [3950/4518] 87% | Training loss: 0.6869009313251399
Epoch: 87 | Iteration number: [3960/4518] 87% | Training loss: 0.6869032197227382
Epoch: 87 | Iteration number: [3970/4518] 87% | Training loss: 0.6869022758091127
Epoch: 87 | Iteration number: [3980/4518] 88% | Training loss: 0.6869019127371323
Epoch: 87 | Iteration number: [3990/4518] 88% | Training loss: 0.6869056972495297
Epoch: 87 | Iteration number: [4000/4518] 88% | Training loss: 0.6869041703492403
Epoch: 87 | Iteration number: [4010/4518] 88% | Training loss: 0.6869052813088805
Epoch: 87 | Iteration number: [4020/4518] 88% | Training loss: 0.6869044740698231
Epoch: 87 | Iteration number: [4030/4518] 89% | Training loss: 0.6869059441698988
Epoch: 87 | Iteration number: [4040/4518] 89% | Training loss: 0.6869094854386726
Epoch: 87 | Iteration number: [4050/4518] 89% | Training loss: 0.6869101516552913
Epoch: 87 | Iteration number: [4060/4518] 89% | Training loss: 0.6869091777672321
Epoch: 87 | Iteration number: [4070/4518] 90% | Training loss: 0.6869108622431462
Epoch: 87 | Iteration number: [4080/4518] 90% | Training loss: 0.686911160878691
Epoch: 87 | Iteration number: [4090/4518] 90% | Training loss: 0.6869112990450451
Epoch: 87 | Iteration number: [4100/4518] 90% | Training loss: 0.6869133702720084
Epoch: 87 | Iteration number: [4110/4518] 90% | Training loss: 0.6869127564476645
Epoch: 87 | Iteration number: [4120/4518] 91% | Training loss: 0.6869100121763146
Epoch: 87 | Iteration number: [4130/4518] 91% | Training loss: 0.6869101875919407
Epoch: 87 | Iteration number: [4140/4518] 91% | Training loss: 0.6869116519528311
Epoch: 87 | Iteration number: [4150/4518] 91% | Training loss: 0.6869127485838281
Epoch: 87 | Iteration number: [4160/4518] 92% | Training loss: 0.6869108823056405
Epoch: 87 | Iteration number: [4170/4518] 92% | Training loss: 0.6869095350912721
Epoch: 87 | Iteration number: [4180/4518] 92% | Training loss: 0.6869090839293585
Epoch: 87 | Iteration number: [4190/4518] 92% | Training loss: 0.6869073699653007
Epoch: 87 | Iteration number: [4200/4518] 92% | Training loss: 0.6869065765823636
Epoch: 87 | Iteration number: [4210/4518] 93% | Training loss: 0.6869059768538577
Epoch: 87 | Iteration number: [4220/4518] 93% | Training loss: 0.6869055222419765
Epoch: 87 | Iteration number: [4230/4518] 93% | Training loss: 0.6869081705456366
Epoch: 87 | Iteration number: [4240/4518] 93% | Training loss: 0.6869072832870033
Epoch: 87 | Iteration number: [4250/4518] 94% | Training loss: 0.6869079482274897
Epoch: 87 | Iteration number: [4260/4518] 94% | Training loss: 0.6869093491577767
Epoch: 87 | Iteration number: [4270/4518] 94% | Training loss: 0.6869107043575626
Epoch: 87 | Iteration number: [4280/4518] 94% | Training loss: 0.6869134892927152
Epoch: 87 | Iteration number: [4290/4518] 94% | Training loss: 0.6869159234153641
Epoch: 87 | Iteration number: [4300/4518] 95% | Training loss: 0.6869172549247742
Epoch: 87 | Iteration number: [4310/4518] 95% | Training loss: 0.6869164622300186
Epoch: 87 | Iteration number: [4320/4518] 95% | Training loss: 0.6869155912211647
Epoch: 87 | Iteration number: [4330/4518] 95% | Training loss: 0.6869146414909847
Epoch: 87 | Iteration number: [4340/4518] 96% | Training loss: 0.6869143028413096
Epoch: 87 | Iteration number: [4350/4518] 96% | Training loss: 0.6869139658034533
Epoch: 87 | Iteration number: [4360/4518] 96% | Training loss: 0.6869140361290459
Epoch: 87 | Iteration number: [4370/4518] 96% | Training loss: 0.68690810099892
Epoch: 87 | Iteration number: [4380/4518] 96% | Training loss: 0.6869076660778969
Epoch: 87 | Iteration number: [4390/4518] 97% | Training loss: 0.6869058607107957
Epoch: 87 | Iteration number: [4400/4518] 97% | Training loss: 0.6869074003398419
Epoch: 87 | Iteration number: [4410/4518] 97% | Training loss: 0.6869058403839059
Epoch: 87 | Iteration number: [4420/4518] 97% | Training loss: 0.6869070911434441
Epoch: 87 | Iteration number: [4430/4518] 98% | Training loss: 0.6869068882669875
Epoch: 87 | Iteration number: [4440/4518] 98% | Training loss: 0.6869069798841133
Epoch: 87 | Iteration number: [4450/4518] 98% | Training loss: 0.686907970731178
Epoch: 87 | Iteration number: [4460/4518] 98% | Training loss: 0.6869079556299432
Epoch: 87 | Iteration number: [4470/4518] 98% | Training loss: 0.6869074070747
Epoch: 87 | Iteration number: [4480/4518] 99% | Training loss: 0.6869057987018355
Epoch: 87 | Iteration number: [4490/4518] 99% | Training loss: 0.6869022155657643
Epoch: 87 | Iteration number: [4500/4518] 99% | Training loss: 0.6869032930003273
Epoch: 87 | Iteration number: [4510/4518] 99% | Training loss: 0.6869050834633559

 End of epoch: 87 | Train Loss: 0.6867524947593464 | Training Time: 633 

 End of epoch: 87 | Eval Loss: 0.6895928735635719 | Evaluating Time: 17 
Epoch: 88 | Iteration number: [10/4518] 0% | Training loss: 0.7563333809375763
Epoch: 88 | Iteration number: [20/4518] 0% | Training loss: 0.7214484184980392
Epoch: 88 | Iteration number: [30/4518] 0% | Training loss: 0.7091412901878357
Epoch: 88 | Iteration number: [40/4518] 0% | Training loss: 0.7035730496048928
Epoch: 88 | Iteration number: [50/4518] 1% | Training loss: 0.7001711392402649
Epoch: 88 | Iteration number: [60/4518] 1% | Training loss: 0.6980528861284256
Epoch: 88 | Iteration number: [70/4518] 1% | Training loss: 0.696431964635849
Epoch: 88 | Iteration number: [80/4518] 1% | Training loss: 0.6950858354568481
Epoch: 88 | Iteration number: [90/4518] 1% | Training loss: 0.6942541539669037
Epoch: 88 | Iteration number: [100/4518] 2% | Training loss: 0.6935039591789246
Epoch: 88 | Iteration number: [110/4518] 2% | Training loss: 0.6928179513324391
Epoch: 88 | Iteration number: [120/4518] 2% | Training loss: 0.6922185103098552
Epoch: 88 | Iteration number: [130/4518] 2% | Training loss: 0.6918035053289854
Epoch: 88 | Iteration number: [140/4518] 3% | Training loss: 0.6914486054863248
Epoch: 88 | Iteration number: [150/4518] 3% | Training loss: 0.6911609570185343
Epoch: 88 | Iteration number: [160/4518] 3% | Training loss: 0.690944080427289
Epoch: 88 | Iteration number: [170/4518] 3% | Training loss: 0.6906702557030846
Epoch: 88 | Iteration number: [180/4518] 3% | Training loss: 0.69052152203189
Epoch: 88 | Iteration number: [190/4518] 4% | Training loss: 0.6903405958100369
Epoch: 88 | Iteration number: [200/4518] 4% | Training loss: 0.6901522040367126
Epoch: 88 | Iteration number: [210/4518] 4% | Training loss: 0.6900107554027013
Epoch: 88 | Iteration number: [220/4518] 4% | Training loss: 0.6899208654056895
Epoch: 88 | Iteration number: [230/4518] 5% | Training loss: 0.6897883389307105
Epoch: 88 | Iteration number: [240/4518] 5% | Training loss: 0.689632382740577
Epoch: 88 | Iteration number: [250/4518] 5% | Training loss: 0.6895867750644684
Epoch: 88 | Iteration number: [260/4518] 5% | Training loss: 0.6895167825313715
Epoch: 88 | Iteration number: [270/4518] 5% | Training loss: 0.6894329576580612
Epoch: 88 | Iteration number: [280/4518] 6% | Training loss: 0.689326882149492
Epoch: 88 | Iteration number: [290/4518] 6% | Training loss: 0.6892943160287265
Epoch: 88 | Iteration number: [300/4518] 6% | Training loss: 0.6891957302888234
Epoch: 88 | Iteration number: [310/4518] 6% | Training loss: 0.6891316169692624
Epoch: 88 | Iteration number: [320/4518] 7% | Training loss: 0.6890876265242696
Epoch: 88 | Iteration number: [330/4518] 7% | Training loss: 0.6890013371453141
Epoch: 88 | Iteration number: [340/4518] 7% | Training loss: 0.6889676314942977
Epoch: 88 | Iteration number: [350/4518] 7% | Training loss: 0.6888916119507381
Epoch: 88 | Iteration number: [360/4518] 7% | Training loss: 0.6888250543011559
Epoch: 88 | Iteration number: [370/4518] 8% | Training loss: 0.6887706398963929
Epoch: 88 | Iteration number: [380/4518] 8% | Training loss: 0.6887595570401142
Epoch: 88 | Iteration number: [390/4518] 8% | Training loss: 0.6887398482897342
Epoch: 88 | Iteration number: [400/4518] 8% | Training loss: 0.6887005932629109
Epoch: 88 | Iteration number: [410/4518] 9% | Training loss: 0.6886619623114423
Epoch: 88 | Iteration number: [420/4518] 9% | Training loss: 0.6885837220010304
Epoch: 88 | Iteration number: [430/4518] 9% | Training loss: 0.6885695809541746
Epoch: 88 | Iteration number: [440/4518] 9% | Training loss: 0.6885185924443331
Epoch: 88 | Iteration number: [450/4518] 9% | Training loss: 0.6884874229960971
Epoch: 88 | Iteration number: [460/4518] 10% | Training loss: 0.6884484174458877
Epoch: 88 | Iteration number: [470/4518] 10% | Training loss: 0.6884098780916093
Epoch: 88 | Iteration number: [480/4518] 10% | Training loss: 0.6883988128354152
Epoch: 88 | Iteration number: [490/4518] 10% | Training loss: 0.6883698739567582
Epoch: 88 | Iteration number: [500/4518] 11% | Training loss: 0.6883433153629303
Epoch: 88 | Iteration number: [510/4518] 11% | Training loss: 0.6883108700022978
Epoch: 88 | Iteration number: [520/4518] 11% | Training loss: 0.688294220658449
Epoch: 88 | Iteration number: [530/4518] 11% | Training loss: 0.6882598416985206
Epoch: 88 | Iteration number: [540/4518] 11% | Training loss: 0.688220493219517
Epoch: 88 | Iteration number: [550/4518] 12% | Training loss: 0.688190816749226
Epoch: 88 | Iteration number: [560/4518] 12% | Training loss: 0.6881809202688081
Epoch: 88 | Iteration number: [570/4518] 12% | Training loss: 0.6881682425214534
Epoch: 88 | Iteration number: [580/4518] 12% | Training loss: 0.6881608080247353
Epoch: 88 | Iteration number: [590/4518] 13% | Training loss: 0.6881425349389092
Epoch: 88 | Iteration number: [600/4518] 13% | Training loss: 0.6881349626183509
Epoch: 88 | Iteration number: [610/4518] 13% | Training loss: 0.6880770392105228
Epoch: 88 | Iteration number: [620/4518] 13% | Training loss: 0.6880519516045047
Epoch: 88 | Iteration number: [630/4518] 13% | Training loss: 0.6880160484049055
Epoch: 88 | Iteration number: [640/4518] 14% | Training loss: 0.6880074906162917
Epoch: 88 | Iteration number: [650/4518] 14% | Training loss: 0.6879843809054448
Epoch: 88 | Iteration number: [660/4518] 14% | Training loss: 0.6879692195942908
Epoch: 88 | Iteration number: [670/4518] 14% | Training loss: 0.6879500211174808
Epoch: 88 | Iteration number: [680/4518] 15% | Training loss: 0.6879423428984249
Epoch: 88 | Iteration number: [690/4518] 15% | Training loss: 0.6879396978495778
Epoch: 88 | Iteration number: [700/4518] 15% | Training loss: 0.6879277206318719
Epoch: 88 | Iteration number: [710/4518] 15% | Training loss: 0.6879304889222266
Epoch: 88 | Iteration number: [720/4518] 15% | Training loss: 0.6879076538814439
Epoch: 88 | Iteration number: [730/4518] 16% | Training loss: 0.6878954583651399
Epoch: 88 | Iteration number: [740/4518] 16% | Training loss: 0.6878836384496173
Epoch: 88 | Iteration number: [750/4518] 16% | Training loss: 0.687864442507426
Epoch: 88 | Iteration number: [760/4518] 16% | Training loss: 0.6878398194124824
Epoch: 88 | Iteration number: [770/4518] 17% | Training loss: 0.6878208537380417
Epoch: 88 | Iteration number: [780/4518] 17% | Training loss: 0.6878192560030864
Epoch: 88 | Iteration number: [790/4518] 17% | Training loss: 0.6877895390685601
Epoch: 88 | Iteration number: [800/4518] 17% | Training loss: 0.6877660368382931
Epoch: 88 | Iteration number: [810/4518] 17% | Training loss: 0.6877473891517263
Epoch: 88 | Iteration number: [820/4518] 18% | Training loss: 0.687745275366597
Epoch: 88 | Iteration number: [830/4518] 18% | Training loss: 0.6877305488988578
Epoch: 88 | Iteration number: [840/4518] 18% | Training loss: 0.6877181399436224
Epoch: 88 | Iteration number: [850/4518] 18% | Training loss: 0.687717741727829
Epoch: 88 | Iteration number: [860/4518] 19% | Training loss: 0.6876976392296857
Epoch: 88 | Iteration number: [870/4518] 19% | Training loss: 0.6876834084932831
Epoch: 88 | Iteration number: [880/4518] 19% | Training loss: 0.6876717190850865
Epoch: 88 | Iteration number: [890/4518] 19% | Training loss: 0.6876632114474693
Epoch: 88 | Iteration number: [900/4518] 19% | Training loss: 0.6876547292868296
Epoch: 88 | Iteration number: [910/4518] 20% | Training loss: 0.6876443800035413
Epoch: 88 | Iteration number: [920/4518] 20% | Training loss: 0.6876274823494579
Epoch: 88 | Iteration number: [930/4518] 20% | Training loss: 0.6876222608550903
Epoch: 88 | Iteration number: [940/4518] 20% | Training loss: 0.6876159099188257
Epoch: 88 | Iteration number: [950/4518] 21% | Training loss: 0.6876069334933632
Epoch: 88 | Iteration number: [960/4518] 21% | Training loss: 0.6875888849919041
Epoch: 88 | Iteration number: [970/4518] 21% | Training loss: 0.6875815287078779
Epoch: 88 | Iteration number: [980/4518] 21% | Training loss: 0.687563594202606
Epoch: 88 | Iteration number: [990/4518] 21% | Training loss: 0.6875550160504351
Epoch: 88 | Iteration number: [1000/4518] 22% | Training loss: 0.6875240783691406
Epoch: 88 | Iteration number: [1010/4518] 22% | Training loss: 0.6875257538686884
Epoch: 88 | Iteration number: [1020/4518] 22% | Training loss: 0.6875123817546694
Epoch: 88 | Iteration number: [1030/4518] 22% | Training loss: 0.6875108439366794
Epoch: 88 | Iteration number: [1040/4518] 23% | Training loss: 0.6875117013087639
Epoch: 88 | Iteration number: [1050/4518] 23% | Training loss: 0.6874970493997846
Epoch: 88 | Iteration number: [1060/4518] 23% | Training loss: 0.6874759874253903
Epoch: 88 | Iteration number: [1070/4518] 23% | Training loss: 0.6874778563174132
Epoch: 88 | Iteration number: [1080/4518] 23% | Training loss: 0.687482372202255
Epoch: 88 | Iteration number: [1090/4518] 24% | Training loss: 0.687483480928141
Epoch: 88 | Iteration number: [1100/4518] 24% | Training loss: 0.6874802864681591
Epoch: 88 | Iteration number: [1110/4518] 24% | Training loss: 0.6874655955546611
Epoch: 88 | Iteration number: [1120/4518] 24% | Training loss: 0.6874610894492694
Epoch: 88 | Iteration number: [1130/4518] 25% | Training loss: 0.6874460462975291
Epoch: 88 | Iteration number: [1140/4518] 25% | Training loss: 0.6874465928788771
Epoch: 88 | Iteration number: [1150/4518] 25% | Training loss: 0.6874377473540928
Epoch: 88 | Iteration number: [1160/4518] 25% | Training loss: 0.6874387649112734
Epoch: 88 | Iteration number: [1170/4518] 25% | Training loss: 0.6874329317838718
Epoch: 88 | Iteration number: [1180/4518] 26% | Training loss: 0.687422277513197
Epoch: 88 | Iteration number: [1190/4518] 26% | Training loss: 0.6874238685399544
Epoch: 88 | Iteration number: [1200/4518] 26% | Training loss: 0.6874223359922568
Epoch: 88 | Iteration number: [1210/4518] 26% | Training loss: 0.6874159956273954
Epoch: 88 | Iteration number: [1220/4518] 27% | Training loss: 0.6874082593644252
Epoch: 88 | Iteration number: [1230/4518] 27% | Training loss: 0.6874058612963049
Epoch: 88 | Iteration number: [1240/4518] 27% | Training loss: 0.6873968740624766
Epoch: 88 | Iteration number: [1250/4518] 27% | Training loss: 0.68738810338974
Epoch: 88 | Iteration number: [1260/4518] 27% | Training loss: 0.6873757532191656
Epoch: 88 | Iteration number: [1270/4518] 28% | Training loss: 0.6873807786956547
Epoch: 88 | Iteration number: [1280/4518] 28% | Training loss: 0.6873656430281698
Epoch: 88 | Iteration number: [1290/4518] 28% | Training loss: 0.6873618716879408
Epoch: 88 | Iteration number: [1300/4518] 28% | Training loss: 0.6873585914189999
Epoch: 88 | Iteration number: [1310/4518] 28% | Training loss: 0.6873559896272557
Epoch: 88 | Iteration number: [1320/4518] 29% | Training loss: 0.6873570369951653
Epoch: 88 | Iteration number: [1330/4518] 29% | Training loss: 0.6873460968186085
Epoch: 88 | Iteration number: [1340/4518] 29% | Training loss: 0.6873407360777926
Epoch: 88 | Iteration number: [1350/4518] 29% | Training loss: 0.6873371267760241
Epoch: 88 | Iteration number: [1360/4518] 30% | Training loss: 0.6873317717191051
Epoch: 88 | Iteration number: [1370/4518] 30% | Training loss: 0.6873312232268117
Epoch: 88 | Iteration number: [1380/4518] 30% | Training loss: 0.687330705013828
Epoch: 88 | Iteration number: [1390/4518] 30% | Training loss: 0.6873165400765783
Epoch: 88 | Iteration number: [1400/4518] 30% | Training loss: 0.6873089049969401
Epoch: 88 | Iteration number: [1410/4518] 31% | Training loss: 0.6873033641923404
Epoch: 88 | Iteration number: [1420/4518] 31% | Training loss: 0.6872984723725789
Epoch: 88 | Iteration number: [1430/4518] 31% | Training loss: 0.6872967285709781
Epoch: 88 | Iteration number: [1440/4518] 31% | Training loss: 0.6872982751992014
Epoch: 88 | Iteration number: [1450/4518] 32% | Training loss: 0.6872869702865337
Epoch: 88 | Iteration number: [1460/4518] 32% | Training loss: 0.6872763650058067
Epoch: 88 | Iteration number: [1470/4518] 32% | Training loss: 0.687272777930409
Epoch: 88 | Iteration number: [1480/4518] 32% | Training loss: 0.6872629164441212
Epoch: 88 | Iteration number: [1490/4518] 32% | Training loss: 0.687255679640994
Epoch: 88 | Iteration number: [1500/4518] 33% | Training loss: 0.6872512043317159
Epoch: 88 | Iteration number: [1510/4518] 33% | Training loss: 0.6872511624500451
Epoch: 88 | Iteration number: [1520/4518] 33% | Training loss: 0.6872518461001547
Epoch: 88 | Iteration number: [1530/4518] 33% | Training loss: 0.6872490636273927
Epoch: 88 | Iteration number: [1540/4518] 34% | Training loss: 0.6872456408940353
Epoch: 88 | Iteration number: [1550/4518] 34% | Training loss: 0.6872434274996481
Epoch: 88 | Iteration number: [1560/4518] 34% | Training loss: 0.6872524214478639
Epoch: 88 | Iteration number: [1570/4518] 34% | Training loss: 0.6872538883215303
Epoch: 88 | Iteration number: [1580/4518] 34% | Training loss: 0.687251076781297
Epoch: 88 | Iteration number: [1590/4518] 35% | Training loss: 0.687245133500429
Epoch: 88 | Iteration number: [1600/4518] 35% | Training loss: 0.6872412525862456
Epoch: 88 | Iteration number: [1610/4518] 35% | Training loss: 0.687248741877005
Epoch: 88 | Iteration number: [1620/4518] 35% | Training loss: 0.687249184427438
Epoch: 88 | Iteration number: [1630/4518] 36% | Training loss: 0.6872471351199355
Epoch: 88 | Iteration number: [1640/4518] 36% | Training loss: 0.6872436044056242
Epoch: 88 | Iteration number: [1650/4518] 36% | Training loss: 0.6872423313242016
Epoch: 88 | Iteration number: [1660/4518] 36% | Training loss: 0.6872310262846659
Epoch: 88 | Iteration number: [1670/4518] 36% | Training loss: 0.6872217717284927
Epoch: 88 | Iteration number: [1680/4518] 37% | Training loss: 0.6872220100746268
Epoch: 88 | Iteration number: [1690/4518] 37% | Training loss: 0.6872297884797204
Epoch: 88 | Iteration number: [1700/4518] 37% | Training loss: 0.6872263939941631
Epoch: 88 | Iteration number: [1710/4518] 37% | Training loss: 0.6872277743983687
Epoch: 88 | Iteration number: [1720/4518] 38% | Training loss: 0.6872247659189756
Epoch: 88 | Iteration number: [1730/4518] 38% | Training loss: 0.6872166910267978
Epoch: 88 | Iteration number: [1740/4518] 38% | Training loss: 0.6872112997304434
Epoch: 88 | Iteration number: [1750/4518] 38% | Training loss: 0.6872199555465154
Epoch: 88 | Iteration number: [1760/4518] 38% | Training loss: 0.6872168213129044
Epoch: 88 | Iteration number: [1770/4518] 39% | Training loss: 0.6872060579095183
Epoch: 88 | Iteration number: [1780/4518] 39% | Training loss: 0.6872036779194736
Epoch: 88 | Iteration number: [1790/4518] 39% | Training loss: 0.6872064155240298
Epoch: 88 | Iteration number: [1800/4518] 39% | Training loss: 0.6872004796730148
Epoch: 88 | Iteration number: [1810/4518] 40% | Training loss: 0.6871993233156468
Epoch: 88 | Iteration number: [1820/4518] 40% | Training loss: 0.6871965295993365
Epoch: 88 | Iteration number: [1830/4518] 40% | Training loss: 0.6872032632267541
Epoch: 88 | Iteration number: [1840/4518] 40% | Training loss: 0.687203546775424
Epoch: 88 | Iteration number: [1850/4518] 40% | Training loss: 0.6871997497855006
Epoch: 88 | Iteration number: [1860/4518] 41% | Training loss: 0.6872010604348234
Epoch: 88 | Iteration number: [1870/4518] 41% | Training loss: 0.6871961390270906
Epoch: 88 | Iteration number: [1880/4518] 41% | Training loss: 0.6871904974605175
Epoch: 88 | Iteration number: [1890/4518] 41% | Training loss: 0.6871870471686913
Epoch: 88 | Iteration number: [1900/4518] 42% | Training loss: 0.6871933502272556
Epoch: 88 | Iteration number: [1910/4518] 42% | Training loss: 0.6871889040420193
Epoch: 88 | Iteration number: [1920/4518] 42% | Training loss: 0.6871844165337583
Epoch: 88 | Iteration number: [1930/4518] 42% | Training loss: 0.687186567585703
Epoch: 88 | Iteration number: [1940/4518] 42% | Training loss: 0.6871916508244486
Epoch: 88 | Iteration number: [1950/4518] 43% | Training loss: 0.6871903114135449
Epoch: 88 | Iteration number: [1960/4518] 43% | Training loss: 0.6871768303671661
Epoch: 88 | Iteration number: [1970/4518] 43% | Training loss: 0.6871701808145203
Epoch: 88 | Iteration number: [1980/4518] 43% | Training loss: 0.6871690005064011
Epoch: 88 | Iteration number: [1990/4518] 44% | Training loss: 0.6871628744518338
Epoch: 88 | Iteration number: [2000/4518] 44% | Training loss: 0.6871607339084148
Epoch: 88 | Iteration number: [2010/4518] 44% | Training loss: 0.6871564407846821
Epoch: 88 | Iteration number: [2020/4518] 44% | Training loss: 0.687150295683653
Epoch: 88 | Iteration number: [2030/4518] 44% | Training loss: 0.6871452787533182
Epoch: 88 | Iteration number: [2040/4518] 45% | Training loss: 0.6871420578629363
Epoch: 88 | Iteration number: [2050/4518] 45% | Training loss: 0.6871436949474056
Epoch: 88 | Iteration number: [2060/4518] 45% | Training loss: 0.6871445320184948
Epoch: 88 | Iteration number: [2070/4518] 45% | Training loss: 0.6871323640219831
Epoch: 88 | Iteration number: [2080/4518] 46% | Training loss: 0.6871334949078468
Epoch: 88 | Iteration number: [2090/4518] 46% | Training loss: 0.6871343200856989
Epoch: 88 | Iteration number: [2100/4518] 46% | Training loss: 0.6871302570615496
Epoch: 88 | Iteration number: [2110/4518] 46% | Training loss: 0.687129158177082
Epoch: 88 | Iteration number: [2120/4518] 46% | Training loss: 0.6871355652809144
Epoch: 88 | Iteration number: [2130/4518] 47% | Training loss: 0.6871355344152227
Epoch: 88 | Iteration number: [2140/4518] 47% | Training loss: 0.6871276405370124
Epoch: 88 | Iteration number: [2150/4518] 47% | Training loss: 0.6871267364468685
Epoch: 88 | Iteration number: [2160/4518] 47% | Training loss: 0.6871267299961161
Epoch: 88 | Iteration number: [2170/4518] 48% | Training loss: 0.6871264881527369
Epoch: 88 | Iteration number: [2180/4518] 48% | Training loss: 0.6871247515219068
Epoch: 88 | Iteration number: [2190/4518] 48% | Training loss: 0.6871153362537628
Epoch: 88 | Iteration number: [2200/4518] 48% | Training loss: 0.6871114013682712
Epoch: 88 | Iteration number: [2210/4518] 48% | Training loss: 0.6871148834940535
Epoch: 88 | Iteration number: [2220/4518] 49% | Training loss: 0.6871137020824192
Epoch: 88 | Iteration number: [2230/4518] 49% | Training loss: 0.6871092356373911
Epoch: 88 | Iteration number: [2240/4518] 49% | Training loss: 0.6871062550427658
Epoch: 88 | Iteration number: [2250/4518] 49% | Training loss: 0.6871058778497908
Epoch: 88 | Iteration number: [2260/4518] 50% | Training loss: 0.6871049494078729
Epoch: 88 | Iteration number: [2270/4518] 50% | Training loss: 0.6871097423694207
Epoch: 88 | Iteration number: [2280/4518] 50% | Training loss: 0.687104993718758
Epoch: 88 | Iteration number: [2290/4518] 50% | Training loss: 0.6871036545678517
Epoch: 88 | Iteration number: [2300/4518] 50% | Training loss: 0.6870970033562702
Epoch: 88 | Iteration number: [2310/4518] 51% | Training loss: 0.6870966558332567
Epoch: 88 | Iteration number: [2320/4518] 51% | Training loss: 0.6870930439439313
Epoch: 88 | Iteration number: [2330/4518] 51% | Training loss: 0.6870912283531074
Epoch: 88 | Iteration number: [2340/4518] 51% | Training loss: 0.6870888306034936
Epoch: 88 | Iteration number: [2350/4518] 52% | Training loss: 0.6870920220588116
Epoch: 88 | Iteration number: [2360/4518] 52% | Training loss: 0.6870864320104405
Epoch: 88 | Iteration number: [2370/4518] 52% | Training loss: 0.6870827774961287
Epoch: 88 | Iteration number: [2380/4518] 52% | Training loss: 0.6870807525991391
Epoch: 88 | Iteration number: [2390/4518] 52% | Training loss: 0.6870792602146021
Epoch: 88 | Iteration number: [2400/4518] 53% | Training loss: 0.6870704898486535
Epoch: 88 | Iteration number: [2410/4518] 53% | Training loss: 0.6870711988185946
Epoch: 88 | Iteration number: [2420/4518] 53% | Training loss: 0.687075485424562
Epoch: 88 | Iteration number: [2430/4518] 53% | Training loss: 0.6870721966150857
Epoch: 88 | Iteration number: [2440/4518] 54% | Training loss: 0.6870732509699025
Epoch: 88 | Iteration number: [2450/4518] 54% | Training loss: 0.6870748681438212
Epoch: 88 | Iteration number: [2460/4518] 54% | Training loss: 0.6870771783881071
Epoch: 88 | Iteration number: [2470/4518] 54% | Training loss: 0.6870777236063953
Epoch: 88 | Iteration number: [2480/4518] 54% | Training loss: 0.6870782816121656
Epoch: 88 | Iteration number: [2490/4518] 55% | Training loss: 0.6870730354603993
Epoch: 88 | Iteration number: [2500/4518] 55% | Training loss: 0.6870660740852356
Epoch: 88 | Iteration number: [2510/4518] 55% | Training loss: 0.6870639645958326
Epoch: 88 | Iteration number: [2520/4518] 55% | Training loss: 0.6870599027663943
Epoch: 88 | Iteration number: [2530/4518] 55% | Training loss: 0.6870540451862124
Epoch: 88 | Iteration number: [2540/4518] 56% | Training loss: 0.687051229683433
Epoch: 88 | Iteration number: [2550/4518] 56% | Training loss: 0.6870521432745691
Epoch: 88 | Iteration number: [2560/4518] 56% | Training loss: 0.6870556128676981
Epoch: 88 | Iteration number: [2570/4518] 56% | Training loss: 0.6870565520882143
Epoch: 88 | Iteration number: [2580/4518] 57% | Training loss: 0.6870554550904636
Epoch: 88 | Iteration number: [2590/4518] 57% | Training loss: 0.6870607676653329
Epoch: 88 | Iteration number: [2600/4518] 57% | Training loss: 0.687059848835835
Epoch: 88 | Iteration number: [2610/4518] 57% | Training loss: 0.687058393137665
Epoch: 88 | Iteration number: [2620/4518] 57% | Training loss: 0.6870552382851375
Epoch: 88 | Iteration number: [2630/4518] 58% | Training loss: 0.6870471613262089
Epoch: 88 | Iteration number: [2640/4518] 58% | Training loss: 0.6870462683791464
Epoch: 88 | Iteration number: [2650/4518] 58% | Training loss: 0.6870458996745775
Epoch: 88 | Iteration number: [2660/4518] 58% | Training loss: 0.6870410500612474
Epoch: 88 | Iteration number: [2670/4518] 59% | Training loss: 0.687040063459775
Epoch: 88 | Iteration number: [2680/4518] 59% | Training loss: 0.6870434908279732
Epoch: 88 | Iteration number: [2690/4518] 59% | Training loss: 0.6870475617261624
Epoch: 88 | Iteration number: [2700/4518] 59% | Training loss: 0.687045882432549
Epoch: 88 | Iteration number: [2710/4518] 59% | Training loss: 0.6870444052553705
Epoch: 88 | Iteration number: [2720/4518] 60% | Training loss: 0.6870447935426937
Epoch: 88 | Iteration number: [2730/4518] 60% | Training loss: 0.6870455029246572
Epoch: 88 | Iteration number: [2740/4518] 60% | Training loss: 0.6870446859920112
Epoch: 88 | Iteration number: [2750/4518] 60% | Training loss: 0.6870400321266867
Epoch: 88 | Iteration number: [2760/4518] 61% | Training loss: 0.6870390997416731
Epoch: 88 | Iteration number: [2770/4518] 61% | Training loss: 0.6870397842102532
Epoch: 88 | Iteration number: [2780/4518] 61% | Training loss: 0.687041546415082
Epoch: 88 | Iteration number: [2790/4518] 61% | Training loss: 0.6870433188681107
Epoch: 88 | Iteration number: [2800/4518] 61% | Training loss: 0.6870404274761677
Epoch: 88 | Iteration number: [2810/4518] 62% | Training loss: 0.6870397944255232
Epoch: 88 | Iteration number: [2820/4518] 62% | Training loss: 0.6870318736801756
Epoch: 88 | Iteration number: [2830/4518] 62% | Training loss: 0.687026584295839
Epoch: 88 | Iteration number: [2840/4518] 62% | Training loss: 0.6870257614993713
Epoch: 88 | Iteration number: [2850/4518] 63% | Training loss: 0.6870294246757239
Epoch: 88 | Iteration number: [2860/4518] 63% | Training loss: 0.687029644867757
Epoch: 88 | Iteration number: [2870/4518] 63% | Training loss: 0.6870249555501373
Epoch: 88 | Iteration number: [2880/4518] 63% | Training loss: 0.6870223810689317
Epoch: 88 | Iteration number: [2890/4518] 63% | Training loss: 0.6870193731207336
Epoch: 88 | Iteration number: [2900/4518] 64% | Training loss: 0.6870164201382933
Epoch: 88 | Iteration number: [2910/4518] 64% | Training loss: 0.6870201962510335
Epoch: 88 | Iteration number: [2920/4518] 64% | Training loss: 0.6870230246692488
Epoch: 88 | Iteration number: [2930/4518] 64% | Training loss: 0.68701628580842
Epoch: 88 | Iteration number: [2940/4518] 65% | Training loss: 0.687011078689374
Epoch: 88 | Iteration number: [2950/4518] 65% | Training loss: 0.687007412041648
Epoch: 88 | Iteration number: [2960/4518] 65% | Training loss: 0.6870074982981424
Epoch: 88 | Iteration number: [2970/4518] 65% | Training loss: 0.6870035660186601
Epoch: 88 | Iteration number: [2980/4518] 65% | Training loss: 0.6870047353058053
Epoch: 88 | Iteration number: [2990/4518] 66% | Training loss: 0.6870019389235456
Epoch: 88 | Iteration number: [3000/4518] 66% | Training loss: 0.6869994066754976
Epoch: 88 | Iteration number: [3010/4518] 66% | Training loss: 0.6869960190845882
Epoch: 88 | Iteration number: [3020/4518] 66% | Training loss: 0.686994782149397
Epoch: 88 | Iteration number: [3030/4518] 67% | Training loss: 0.6869926647384568
Epoch: 88 | Iteration number: [3040/4518] 67% | Training loss: 0.6869941009306594
Epoch: 88 | Iteration number: [3050/4518] 67% | Training loss: 0.6869940029402248
Epoch: 88 | Iteration number: [3060/4518] 67% | Training loss: 0.6869953679298264
Epoch: 88 | Iteration number: [3070/4518] 67% | Training loss: 0.6869964683288861
Epoch: 88 | Iteration number: [3080/4518] 68% | Training loss: 0.6869940714596154
Epoch: 88 | Iteration number: [3090/4518] 68% | Training loss: 0.6869932509741736
Epoch: 88 | Iteration number: [3100/4518] 68% | Training loss: 0.6869918465998865
Epoch: 88 | Iteration number: [3110/4518] 68% | Training loss: 0.6869937083345518
Epoch: 88 | Iteration number: [3120/4518] 69% | Training loss: 0.6869951394123909
Epoch: 88 | Iteration number: [3130/4518] 69% | Training loss: 0.6869886592363778
Epoch: 88 | Iteration number: [3140/4518] 69% | Training loss: 0.6869850480822242
Epoch: 88 | Iteration number: [3150/4518] 69% | Training loss: 0.6869851073764619
Epoch: 88 | Iteration number: [3160/4518] 69% | Training loss: 0.6869836187249497
Epoch: 88 | Iteration number: [3170/4518] 70% | Training loss: 0.686980979280893
Epoch: 88 | Iteration number: [3180/4518] 70% | Training loss: 0.6869838924153046
Epoch: 88 | Iteration number: [3190/4518] 70% | Training loss: 0.6869806033316824
Epoch: 88 | Iteration number: [3200/4518] 70% | Training loss: 0.6869764090888202
Epoch: 88 | Iteration number: [3210/4518] 71% | Training loss: 0.6869781931798407
Epoch: 88 | Iteration number: [3220/4518] 71% | Training loss: 0.6869798509045417
Epoch: 88 | Iteration number: [3230/4518] 71% | Training loss: 0.686976885906314
Epoch: 88 | Iteration number: [3240/4518] 71% | Training loss: 0.6869734224529914
Epoch: 88 | Iteration number: [3250/4518] 71% | Training loss: 0.68697222333688
Epoch: 88 | Iteration number: [3260/4518] 72% | Training loss: 0.6869711979583728
Epoch: 88 | Iteration number: [3270/4518] 72% | Training loss: 0.6869714884218455
Epoch: 88 | Iteration number: [3280/4518] 72% | Training loss: 0.6869692718292155
Epoch: 88 | Iteration number: [3290/4518] 72% | Training loss: 0.686966265969001
Epoch: 88 | Iteration number: [3300/4518] 73% | Training loss: 0.6869677605954083
Epoch: 88 | Iteration number: [3310/4518] 73% | Training loss: 0.6869694738589744
Epoch: 88 | Iteration number: [3320/4518] 73% | Training loss: 0.6869705136281898
Epoch: 88 | Iteration number: [3330/4518] 73% | Training loss: 0.6869716111067179
Epoch: 88 | Iteration number: [3340/4518] 73% | Training loss: 0.6869652400652092
Epoch: 88 | Iteration number: [3350/4518] 74% | Training loss: 0.686965435707747
Epoch: 88 | Iteration number: [3360/4518] 74% | Training loss: 0.686963079940705
Epoch: 88 | Iteration number: [3370/4518] 74% | Training loss: 0.6869611828723364
Epoch: 88 | Iteration number: [3380/4518] 74% | Training loss: 0.6869630643601954
Epoch: 88 | Iteration number: [3390/4518] 75% | Training loss: 0.6869665388688225
Epoch: 88 | Iteration number: [3400/4518] 75% | Training loss: 0.686966988391736
Epoch: 88 | Iteration number: [3410/4518] 75% | Training loss: 0.686967173000235
Epoch: 88 | Iteration number: [3420/4518] 75% | Training loss: 0.6869689398690274
Epoch: 88 | Iteration number: [3430/4518] 75% | Training loss: 0.6869697808524262
Epoch: 88 | Iteration number: [3440/4518] 76% | Training loss: 0.6869663409195667
Epoch: 88 | Iteration number: [3450/4518] 76% | Training loss: 0.6869694151740143
Epoch: 88 | Iteration number: [3460/4518] 76% | Training loss: 0.6869688563264175
Epoch: 88 | Iteration number: [3470/4518] 76% | Training loss: 0.686962125349457
Epoch: 88 | Iteration number: [3480/4518] 77% | Training loss: 0.6869591118275434
Epoch: 88 | Iteration number: [3490/4518] 77% | Training loss: 0.6869615651816556
Epoch: 88 | Iteration number: [3500/4518] 77% | Training loss: 0.6869612244027001
Epoch: 88 | Iteration number: [3510/4518] 77% | Training loss: 0.686961322513401
Epoch: 88 | Iteration number: [3520/4518] 77% | Training loss: 0.6869604161009193
Epoch: 88 | Iteration number: [3530/4518] 78% | Training loss: 0.6869567831075901
Epoch: 88 | Iteration number: [3540/4518] 78% | Training loss: 0.6869551816734217
Epoch: 88 | Iteration number: [3550/4518] 78% | Training loss: 0.6869562124702292
Epoch: 88 | Iteration number: [3560/4518] 78% | Training loss: 0.686956275329831
Epoch: 88 | Iteration number: [3570/4518] 79% | Training loss: 0.6869551488832265
Epoch: 88 | Iteration number: [3580/4518] 79% | Training loss: 0.68695640484048
Epoch: 88 | Iteration number: [3590/4518] 79% | Training loss: 0.6869545670771001
Epoch: 88 | Iteration number: [3600/4518] 79% | Training loss: 0.6869575630128384
Epoch: 88 | Iteration number: [3610/4518] 79% | Training loss: 0.6869558963584107
Epoch: 88 | Iteration number: [3620/4518] 80% | Training loss: 0.6869557003289956
Epoch: 88 | Iteration number: [3630/4518] 80% | Training loss: 0.6869534360311577
Epoch: 88 | Iteration number: [3640/4518] 80% | Training loss: 0.6869544008112216
Epoch: 88 | Iteration number: [3650/4518] 80% | Training loss: 0.6869568678940812
Epoch: 88 | Iteration number: [3660/4518] 81% | Training loss: 0.6869570745796454
Epoch: 88 | Iteration number: [3670/4518] 81% | Training loss: 0.6869541372200448
Epoch: 88 | Iteration number: [3680/4518] 81% | Training loss: 0.6869544799399117
Epoch: 88 | Iteration number: [3690/4518] 81% | Training loss: 0.6869577801970609
Epoch: 88 | Iteration number: [3700/4518] 81% | Training loss: 0.6869580846863824
Epoch: 88 | Iteration number: [3710/4518] 82% | Training loss: 0.6869593626084032
Epoch: 88 | Iteration number: [3720/4518] 82% | Training loss: 0.6869626242146697
Epoch: 88 | Iteration number: [3730/4518] 82% | Training loss: 0.6869595029558637
Epoch: 88 | Iteration number: [3740/4518] 82% | Training loss: 0.6869586508701192
Epoch: 88 | Iteration number: [3750/4518] 83% | Training loss: 0.6869551674048106
Epoch: 88 | Iteration number: [3760/4518] 83% | Training loss: 0.686956527179226
Epoch: 88 | Iteration number: [3770/4518] 83% | Training loss: 0.6869574466023585
Epoch: 88 | Iteration number: [3780/4518] 83% | Training loss: 0.6869587896362184
Epoch: 88 | Iteration number: [3790/4518] 83% | Training loss: 0.6869585989018543
Epoch: 88 | Iteration number: [3800/4518] 84% | Training loss: 0.6869602354263005
Epoch: 88 | Iteration number: [3810/4518] 84% | Training loss: 0.6869620561599732
Epoch: 88 | Iteration number: [3820/4518] 84% | Training loss: 0.6869640081184697
Epoch: 88 | Iteration number: [3830/4518] 84% | Training loss: 0.6869629048958771
Epoch: 88 | Iteration number: [3840/4518] 84% | Training loss: 0.686963467594857
Epoch: 88 | Iteration number: [3850/4518] 85% | Training loss: 0.6869644808614409
Epoch: 88 | Iteration number: [3860/4518] 85% | Training loss: 0.6869620191618568
Epoch: 88 | Iteration number: [3870/4518] 85% | Training loss: 0.6869616816826261
Epoch: 88 | Iteration number: [3880/4518] 85% | Training loss: 0.6869625226124045
Epoch: 88 | Iteration number: [3890/4518] 86% | Training loss: 0.6869638686468178
Epoch: 88 | Iteration number: [3900/4518] 86% | Training loss: 0.6869583471157612
Epoch: 88 | Iteration number: [3910/4518] 86% | Training loss: 0.686958478539801
Epoch: 88 | Iteration number: [3920/4518] 86% | Training loss: 0.6869588698507572
Epoch: 88 | Iteration number: [3930/4518] 86% | Training loss: 0.6869583673604572
Epoch: 88 | Iteration number: [3940/4518] 87% | Training loss: 0.6869565811102766
Epoch: 88 | Iteration number: [3950/4518] 87% | Training loss: 0.6869549390032321
Epoch: 88 | Iteration number: [3960/4518] 87% | Training loss: 0.6869540040992728
Epoch: 88 | Iteration number: [3970/4518] 87% | Training loss: 0.6869540598140256
Epoch: 88 | Iteration number: [3980/4518] 88% | Training loss: 0.6869530240345241
Epoch: 88 | Iteration number: [3990/4518] 88% | Training loss: 0.6869534078098479
Epoch: 88 | Iteration number: [4000/4518] 88% | Training loss: 0.6869529534131289
Epoch: 88 | Iteration number: [4010/4518] 88% | Training loss: 0.6869518511015875
Epoch: 88 | Iteration number: [4020/4518] 88% | Training loss: 0.6869539216234909
Epoch: 88 | Iteration number: [4030/4518] 89% | Training loss: 0.6869516884570678
Epoch: 88 | Iteration number: [4040/4518] 89% | Training loss: 0.6869493628197377
Epoch: 88 | Iteration number: [4050/4518] 89% | Training loss: 0.6869481765193703
Epoch: 88 | Iteration number: [4060/4518] 89% | Training loss: 0.6869481984911294
Epoch: 88 | Iteration number: [4070/4518] 90% | Training loss: 0.6869469905075336
Epoch: 88 | Iteration number: [4080/4518] 90% | Training loss: 0.6869438712795576
Epoch: 88 | Iteration number: [4090/4518] 90% | Training loss: 0.6869442478077336
Epoch: 88 | Iteration number: [4100/4518] 90% | Training loss: 0.686941538511253
Epoch: 88 | Iteration number: [4110/4518] 90% | Training loss: 0.6869411427464218
Epoch: 88 | Iteration number: [4120/4518] 91% | Training loss: 0.6869397104220483
Epoch: 88 | Iteration number: [4130/4518] 91% | Training loss: 0.6869364216598991
Epoch: 88 | Iteration number: [4140/4518] 91% | Training loss: 0.6869342271976425
Epoch: 88 | Iteration number: [4150/4518] 91% | Training loss: 0.6869334258372525
Epoch: 88 | Iteration number: [4160/4518] 92% | Training loss: 0.6869311890206657
Epoch: 88 | Iteration number: [4170/4518] 92% | Training loss: 0.6869298382485799
Epoch: 88 | Iteration number: [4180/4518] 92% | Training loss: 0.6869278570681667
Epoch: 88 | Iteration number: [4190/4518] 92% | Training loss: 0.6869253310070402
Epoch: 88 | Iteration number: [4200/4518] 92% | Training loss: 0.686926056203388
Epoch: 88 | Iteration number: [4210/4518] 93% | Training loss: 0.6869242226284643
Epoch: 88 | Iteration number: [4220/4518] 93% | Training loss: 0.6869249808279824
Epoch: 88 | Iteration number: [4230/4518] 93% | Training loss: 0.6869251361129978
Epoch: 88 | Iteration number: [4240/4518] 93% | Training loss: 0.6869221437792733
Epoch: 88 | Iteration number: [4250/4518] 94% | Training loss: 0.6869192579493804
Epoch: 88 | Iteration number: [4260/4518] 94% | Training loss: 0.686919443596137
Epoch: 88 | Iteration number: [4270/4518] 94% | Training loss: 0.6869222635128459
Epoch: 88 | Iteration number: [4280/4518] 94% | Training loss: 0.6869232428686641
Epoch: 88 | Iteration number: [4290/4518] 94% | Training loss: 0.6869229405493169
Epoch: 88 | Iteration number: [4300/4518] 95% | Training loss: 0.6869234937568044
Epoch: 88 | Iteration number: [4310/4518] 95% | Training loss: 0.6869226118113214
Epoch: 88 | Iteration number: [4320/4518] 95% | Training loss: 0.6869224457553139
Epoch: 88 | Iteration number: [4330/4518] 95% | Training loss: 0.6869224045072913
Epoch: 88 | Iteration number: [4340/4518] 96% | Training loss: 0.6869211500278816
Epoch: 88 | Iteration number: [4350/4518] 96% | Training loss: 0.6869197425760072
Epoch: 88 | Iteration number: [4360/4518] 96% | Training loss: 0.6869161756213652
Epoch: 88 | Iteration number: [4370/4518] 96% | Training loss: 0.6869126343072416
Epoch: 88 | Iteration number: [4380/4518] 96% | Training loss: 0.6869115262951481
Epoch: 88 | Iteration number: [4390/4518] 97% | Training loss: 0.6869098492934111
Epoch: 88 | Iteration number: [4400/4518] 97% | Training loss: 0.6869104346903888
Epoch: 88 | Iteration number: [4410/4518] 97% | Training loss: 0.6869086249345014
Epoch: 88 | Iteration number: [4420/4518] 97% | Training loss: 0.6869084304544182
Epoch: 88 | Iteration number: [4430/4518] 98% | Training loss: 0.6869088055856072
Epoch: 88 | Iteration number: [4440/4518] 98% | Training loss: 0.6869088581150716
Epoch: 88 | Iteration number: [4450/4518] 98% | Training loss: 0.6869081957822435
Epoch: 88 | Iteration number: [4460/4518] 98% | Training loss: 0.6869071642780518
Epoch: 88 | Iteration number: [4470/4518] 98% | Training loss: 0.6869049562303812
Epoch: 88 | Iteration number: [4480/4518] 99% | Training loss: 0.6869027527049184
Epoch: 88 | Iteration number: [4490/4518] 99% | Training loss: 0.6869013432405042
Epoch: 88 | Iteration number: [4500/4518] 99% | Training loss: 0.6869011378685633
Epoch: 88 | Iteration number: [4510/4518] 99% | Training loss: 0.6869016907828346

 End of epoch: 88 | Train Loss: 0.6867521183714501 | Training Time: 632 

 End of epoch: 88 | Eval Loss: 0.6895622525896344 | Evaluating Time: 17 
Epoch: 89 | Iteration number: [10/4518] 0% | Training loss: 0.7562071502208709
Epoch: 89 | Iteration number: [20/4518] 0% | Training loss: 0.7212233990430832
Epoch: 89 | Iteration number: [30/4518] 0% | Training loss: 0.7096265812714895
Epoch: 89 | Iteration number: [40/4518] 0% | Training loss: 0.7040820866823196
Epoch: 89 | Iteration number: [50/4518] 1% | Training loss: 0.7007178628444671
Epoch: 89 | Iteration number: [60/4518] 1% | Training loss: 0.6984834094842275
Epoch: 89 | Iteration number: [70/4518] 1% | Training loss: 0.6967173150607517
Epoch: 89 | Iteration number: [80/4518] 1% | Training loss: 0.6956153638660908
Epoch: 89 | Iteration number: [90/4518] 1% | Training loss: 0.6945793079005347
Epoch: 89 | Iteration number: [100/4518] 2% | Training loss: 0.6937081849575043
Epoch: 89 | Iteration number: [110/4518] 2% | Training loss: 0.6930717495354739
Epoch: 89 | Iteration number: [120/4518] 2% | Training loss: 0.69258331010739
Epoch: 89 | Iteration number: [130/4518] 2% | Training loss: 0.692123451599708
Epoch: 89 | Iteration number: [140/4518] 3% | Training loss: 0.6918258803231375
Epoch: 89 | Iteration number: [150/4518] 3% | Training loss: 0.6915083885192871
Epoch: 89 | Iteration number: [160/4518] 3% | Training loss: 0.6912432041019201
Epoch: 89 | Iteration number: [170/4518] 3% | Training loss: 0.6908920063691981
Epoch: 89 | Iteration number: [180/4518] 3% | Training loss: 0.6907080772850248
Epoch: 89 | Iteration number: [190/4518] 4% | Training loss: 0.6905110628981339
Epoch: 89 | Iteration number: [200/4518] 4% | Training loss: 0.69032246530056
Epoch: 89 | Iteration number: [210/4518] 4% | Training loss: 0.6901420374711354
Epoch: 89 | Iteration number: [220/4518] 4% | Training loss: 0.6899880761449987
Epoch: 89 | Iteration number: [230/4518] 5% | Training loss: 0.6898093762605086
Epoch: 89 | Iteration number: [240/4518] 5% | Training loss: 0.6897075429558754
Epoch: 89 | Iteration number: [250/4518] 5% | Training loss: 0.6895765631198884
Epoch: 89 | Iteration number: [260/4518] 5% | Training loss: 0.6894644145782177
Epoch: 89 | Iteration number: [270/4518] 5% | Training loss: 0.6893707118652485
Epoch: 89 | Iteration number: [280/4518] 6% | Training loss: 0.6892615822809083
Epoch: 89 | Iteration number: [290/4518] 6% | Training loss: 0.6891820272495006
Epoch: 89 | Iteration number: [300/4518] 6% | Training loss: 0.6891101457675298
Epoch: 89 | Iteration number: [310/4518] 6% | Training loss: 0.6890164990578929
Epoch: 89 | Iteration number: [320/4518] 7% | Training loss: 0.6889093834906816
Epoch: 89 | Iteration number: [330/4518] 7% | Training loss: 0.6888345738252004
Epoch: 89 | Iteration number: [340/4518] 7% | Training loss: 0.6887788460535161
Epoch: 89 | Iteration number: [350/4518] 7% | Training loss: 0.688743782213756
Epoch: 89 | Iteration number: [360/4518] 7% | Training loss: 0.6887178391218185
Epoch: 89 | Iteration number: [370/4518] 8% | Training loss: 0.6886430513214421
Epoch: 89 | Iteration number: [380/4518] 8% | Training loss: 0.6885673788033033
Epoch: 89 | Iteration number: [390/4518] 8% | Training loss: 0.6885002224873273
Epoch: 89 | Iteration number: [400/4518] 8% | Training loss: 0.6884739470481872
Epoch: 89 | Iteration number: [410/4518] 9% | Training loss: 0.688406374105593
Epoch: 89 | Iteration number: [420/4518] 9% | Training loss: 0.6883338203032812
Epoch: 89 | Iteration number: [430/4518] 9% | Training loss: 0.6883143517860146
Epoch: 89 | Iteration number: [440/4518] 9% | Training loss: 0.6883120967583223
Epoch: 89 | Iteration number: [450/4518] 9% | Training loss: 0.6882641161812676
Epoch: 89 | Iteration number: [460/4518] 10% | Training loss: 0.6882366197264713
Epoch: 89 | Iteration number: [470/4518] 10% | Training loss: 0.6882084453359564
Epoch: 89 | Iteration number: [480/4518] 10% | Training loss: 0.6881446237365405
Epoch: 89 | Iteration number: [490/4518] 10% | Training loss: 0.6881104247910635
Epoch: 89 | Iteration number: [500/4518] 11% | Training loss: 0.6880756055116654
Epoch: 89 | Iteration number: [510/4518] 11% | Training loss: 0.6880320145803339
Epoch: 89 | Iteration number: [520/4518] 11% | Training loss: 0.6880188439901058
Epoch: 89 | Iteration number: [530/4518] 11% | Training loss: 0.6880144174368876
Epoch: 89 | Iteration number: [540/4518] 11% | Training loss: 0.6879834595653745
Epoch: 89 | Iteration number: [550/4518] 12% | Training loss: 0.6879772840846669
Epoch: 89 | Iteration number: [560/4518] 12% | Training loss: 0.6879593330834594
Epoch: 89 | Iteration number: [570/4518] 12% | Training loss: 0.6879466079829032
Epoch: 89 | Iteration number: [580/4518] 12% | Training loss: 0.6879312745456038
Epoch: 89 | Iteration number: [590/4518] 13% | Training loss: 0.6879389760857921
Epoch: 89 | Iteration number: [600/4518] 13% | Training loss: 0.6878938750425975
Epoch: 89 | Iteration number: [610/4518] 13% | Training loss: 0.6878664444704525
Epoch: 89 | Iteration number: [620/4518] 13% | Training loss: 0.6878381340734421
Epoch: 89 | Iteration number: [630/4518] 13% | Training loss: 0.687831114114277
Epoch: 89 | Iteration number: [640/4518] 14% | Training loss: 0.6878248497843742
Epoch: 89 | Iteration number: [650/4518] 14% | Training loss: 0.6878113676034487
Epoch: 89 | Iteration number: [660/4518] 14% | Training loss: 0.6877787054488154
Epoch: 89 | Iteration number: [670/4518] 14% | Training loss: 0.6877424176059552
Epoch: 89 | Iteration number: [680/4518] 15% | Training loss: 0.6876928673947559
Epoch: 89 | Iteration number: [690/4518] 15% | Training loss: 0.6876946579718936
Epoch: 89 | Iteration number: [700/4518] 15% | Training loss: 0.6876637082440512
Epoch: 89 | Iteration number: [710/4518] 15% | Training loss: 0.6876411528654501
Epoch: 89 | Iteration number: [720/4518] 15% | Training loss: 0.687629758566618
Epoch: 89 | Iteration number: [730/4518] 16% | Training loss: 0.6876180643088197
Epoch: 89 | Iteration number: [740/4518] 16% | Training loss: 0.6875927350005588
Epoch: 89 | Iteration number: [750/4518] 16% | Training loss: 0.6875803973674774
Epoch: 89 | Iteration number: [760/4518] 16% | Training loss: 0.6875690902534284
Epoch: 89 | Iteration number: [770/4518] 17% | Training loss: 0.6875564646411252
Epoch: 89 | Iteration number: [780/4518] 17% | Training loss: 0.687537619089469
Epoch: 89 | Iteration number: [790/4518] 17% | Training loss: 0.687540175944944
Epoch: 89 | Iteration number: [800/4518] 17% | Training loss: 0.6875426598638296
Epoch: 89 | Iteration number: [810/4518] 17% | Training loss: 0.6875289786009141
Epoch: 89 | Iteration number: [820/4518] 18% | Training loss: 0.6875331739100015
Epoch: 89 | Iteration number: [830/4518] 18% | Training loss: 0.6875127643705851
Epoch: 89 | Iteration number: [840/4518] 18% | Training loss: 0.6875035667703265
Epoch: 89 | Iteration number: [850/4518] 18% | Training loss: 0.6875122433550218
Epoch: 89 | Iteration number: [860/4518] 19% | Training loss: 0.6875077172767284
Epoch: 89 | Iteration number: [870/4518] 19% | Training loss: 0.687488200335667
Epoch: 89 | Iteration number: [880/4518] 19% | Training loss: 0.6874749109148979
Epoch: 89 | Iteration number: [890/4518] 19% | Training loss: 0.6874633113319955
Epoch: 89 | Iteration number: [900/4518] 19% | Training loss: 0.687452557153172
Epoch: 89 | Iteration number: [910/4518] 20% | Training loss: 0.6874309053132822
Epoch: 89 | Iteration number: [920/4518] 20% | Training loss: 0.6874252667245657
Epoch: 89 | Iteration number: [930/4518] 20% | Training loss: 0.6874278737011776
Epoch: 89 | Iteration number: [940/4518] 20% | Training loss: 0.6874162728482104
Epoch: 89 | Iteration number: [950/4518] 21% | Training loss: 0.6874189676109114
Epoch: 89 | Iteration number: [960/4518] 21% | Training loss: 0.687410153200229
Epoch: 89 | Iteration number: [970/4518] 21% | Training loss: 0.6874047763568839
Epoch: 89 | Iteration number: [980/4518] 21% | Training loss: 0.6873941394139309
Epoch: 89 | Iteration number: [990/4518] 21% | Training loss: 0.6873761192114666
Epoch: 89 | Iteration number: [1000/4518] 22% | Training loss: 0.6873618511557579
Epoch: 89 | Iteration number: [1010/4518] 22% | Training loss: 0.687363352043794
Epoch: 89 | Iteration number: [1020/4518] 22% | Training loss: 0.6873685959507437
Epoch: 89 | Iteration number: [1030/4518] 22% | Training loss: 0.6873538786925159
Epoch: 89 | Iteration number: [1040/4518] 23% | Training loss: 0.6873506971276724
Epoch: 89 | Iteration number: [1050/4518] 23% | Training loss: 0.6873493422780718
Epoch: 89 | Iteration number: [1060/4518] 23% | Training loss: 0.6873494446277618
Epoch: 89 | Iteration number: [1070/4518] 23% | Training loss: 0.6873327567198566
Epoch: 89 | Iteration number: [1080/4518] 23% | Training loss: 0.6873177756865819
Epoch: 89 | Iteration number: [1090/4518] 24% | Training loss: 0.6873080332891657
Epoch: 89 | Iteration number: [1100/4518] 24% | Training loss: 0.6873197948390787
Epoch: 89 | Iteration number: [1110/4518] 24% | Training loss: 0.6873115057343835
Epoch: 89 | Iteration number: [1120/4518] 24% | Training loss: 0.6873057371271508
Epoch: 89 | Iteration number: [1130/4518] 25% | Training loss: 0.6872846716800622
Epoch: 89 | Iteration number: [1140/4518] 25% | Training loss: 0.6872782872957096
Epoch: 89 | Iteration number: [1150/4518] 25% | Training loss: 0.6872715369514797
Epoch: 89 | Iteration number: [1160/4518] 25% | Training loss: 0.687265925520453
Epoch: 89 | Iteration number: [1170/4518] 25% | Training loss: 0.6872710342081184
Epoch: 89 | Iteration number: [1180/4518] 26% | Training loss: 0.6872648724054886
Epoch: 89 | Iteration number: [1190/4518] 26% | Training loss: 0.6872506879457907
Epoch: 89 | Iteration number: [1200/4518] 26% | Training loss: 0.6872423238058885
Epoch: 89 | Iteration number: [1210/4518] 26% | Training loss: 0.687233358276777
Epoch: 89 | Iteration number: [1220/4518] 27% | Training loss: 0.6872303675432674
Epoch: 89 | Iteration number: [1230/4518] 27% | Training loss: 0.6872295546337841
Epoch: 89 | Iteration number: [1240/4518] 27% | Training loss: 0.687229579783255
Epoch: 89 | Iteration number: [1250/4518] 27% | Training loss: 0.6872263409137725
Epoch: 89 | Iteration number: [1260/4518] 27% | Training loss: 0.687217109449326
Epoch: 89 | Iteration number: [1270/4518] 28% | Training loss: 0.6872081151628119
Epoch: 89 | Iteration number: [1280/4518] 28% | Training loss: 0.6871998654678464
Epoch: 89 | Iteration number: [1290/4518] 28% | Training loss: 0.6872051810109339
Epoch: 89 | Iteration number: [1300/4518] 28% | Training loss: 0.6872086577232067
Epoch: 89 | Iteration number: [1310/4518] 28% | Training loss: 0.6872112786041872
Epoch: 89 | Iteration number: [1320/4518] 29% | Training loss: 0.687212023184155
Epoch: 89 | Iteration number: [1330/4518] 29% | Training loss: 0.6872134282624811
Epoch: 89 | Iteration number: [1340/4518] 29% | Training loss: 0.6872064424094869
Epoch: 89 | Iteration number: [1350/4518] 29% | Training loss: 0.6872012905279795
Epoch: 89 | Iteration number: [1360/4518] 30% | Training loss: 0.687188437055139
Epoch: 89 | Iteration number: [1370/4518] 30% | Training loss: 0.6871808147343406
Epoch: 89 | Iteration number: [1380/4518] 30% | Training loss: 0.6871828116368557
Epoch: 89 | Iteration number: [1390/4518] 30% | Training loss: 0.6871808213724507
Epoch: 89 | Iteration number: [1400/4518] 30% | Training loss: 0.6871758996588844
Epoch: 89 | Iteration number: [1410/4518] 31% | Training loss: 0.6871676470371003
Epoch: 89 | Iteration number: [1420/4518] 31% | Training loss: 0.6871672034683362
Epoch: 89 | Iteration number: [1430/4518] 31% | Training loss: 0.6871526839849832
Epoch: 89 | Iteration number: [1440/4518] 31% | Training loss: 0.6871546147598161
Epoch: 89 | Iteration number: [1450/4518] 32% | Training loss: 0.6871499800682068
Epoch: 89 | Iteration number: [1460/4518] 32% | Training loss: 0.6871489914312755
Epoch: 89 | Iteration number: [1470/4518] 32% | Training loss: 0.6871442285930218
Epoch: 89 | Iteration number: [1480/4518] 32% | Training loss: 0.6871364769097921
Epoch: 89 | Iteration number: [1490/4518] 32% | Training loss: 0.6871383392570802
Epoch: 89 | Iteration number: [1500/4518] 33% | Training loss: 0.6871411184072495
Epoch: 89 | Iteration number: [1510/4518] 33% | Training loss: 0.6871360823808127
Epoch: 89 | Iteration number: [1520/4518] 33% | Training loss: 0.687136433351981
Epoch: 89 | Iteration number: [1530/4518] 33% | Training loss: 0.6871365743135315
Epoch: 89 | Iteration number: [1540/4518] 34% | Training loss: 0.687142236317907
Epoch: 89 | Iteration number: [1550/4518] 34% | Training loss: 0.687143394562506
Epoch: 89 | Iteration number: [1560/4518] 34% | Training loss: 0.6871469932870987
Epoch: 89 | Iteration number: [1570/4518] 34% | Training loss: 0.6871415401340291
Epoch: 89 | Iteration number: [1580/4518] 34% | Training loss: 0.6871414006888112
Epoch: 89 | Iteration number: [1590/4518] 35% | Training loss: 0.6871392713777674
Epoch: 89 | Iteration number: [1600/4518] 35% | Training loss: 0.6871411322802305
Epoch: 89 | Iteration number: [1610/4518] 35% | Training loss: 0.6871431021956924
Epoch: 89 | Iteration number: [1620/4518] 35% | Training loss: 0.6871433263575589
Epoch: 89 | Iteration number: [1630/4518] 36% | Training loss: 0.6871361251989025
Epoch: 89 | Iteration number: [1640/4518] 36% | Training loss: 0.6871303278498533
Epoch: 89 | Iteration number: [1650/4518] 36% | Training loss: 0.6871230390938845
Epoch: 89 | Iteration number: [1660/4518] 36% | Training loss: 0.6871217073805361
Epoch: 89 | Iteration number: [1670/4518] 36% | Training loss: 0.6871219973007362
Epoch: 89 | Iteration number: [1680/4518] 37% | Training loss: 0.6871169343590736
Epoch: 89 | Iteration number: [1690/4518] 37% | Training loss: 0.687113550181925
Epoch: 89 | Iteration number: [1700/4518] 37% | Training loss: 0.6871159295124166
Epoch: 89 | Iteration number: [1710/4518] 37% | Training loss: 0.687107268028092
Epoch: 89 | Iteration number: [1720/4518] 38% | Training loss: 0.6871071061076119
Epoch: 89 | Iteration number: [1730/4518] 38% | Training loss: 0.6871037179335004
Epoch: 89 | Iteration number: [1740/4518] 38% | Training loss: 0.6871025009744469
Epoch: 89 | Iteration number: [1750/4518] 38% | Training loss: 0.687100729056767
Epoch: 89 | Iteration number: [1760/4518] 38% | Training loss: 0.6870958135886626
Epoch: 89 | Iteration number: [1770/4518] 39% | Training loss: 0.6870894021233597
Epoch: 89 | Iteration number: [1780/4518] 39% | Training loss: 0.6870918810032727
Epoch: 89 | Iteration number: [1790/4518] 39% | Training loss: 0.687098025409869
Epoch: 89 | Iteration number: [1800/4518] 39% | Training loss: 0.6870901506808069
Epoch: 89 | Iteration number: [1810/4518] 40% | Training loss: 0.6870863222944144
Epoch: 89 | Iteration number: [1820/4518] 40% | Training loss: 0.6870873474157774
Epoch: 89 | Iteration number: [1830/4518] 40% | Training loss: 0.6870773773375756
Epoch: 89 | Iteration number: [1840/4518] 40% | Training loss: 0.6870829243374907
Epoch: 89 | Iteration number: [1850/4518] 40% | Training loss: 0.6870860754154824
Epoch: 89 | Iteration number: [1860/4518] 41% | Training loss: 0.6870800176294901
Epoch: 89 | Iteration number: [1870/4518] 41% | Training loss: 0.6870807324182541
Epoch: 89 | Iteration number: [1880/4518] 41% | Training loss: 0.687081319030295
Epoch: 89 | Iteration number: [1890/4518] 41% | Training loss: 0.6870811213576604
Epoch: 89 | Iteration number: [1900/4518] 42% | Training loss: 0.6870777751270093
Epoch: 89 | Iteration number: [1910/4518] 42% | Training loss: 0.6870760734792779
Epoch: 89 | Iteration number: [1920/4518] 42% | Training loss: 0.6870738792233169
Epoch: 89 | Iteration number: [1930/4518] 42% | Training loss: 0.6870734590014028
Epoch: 89 | Iteration number: [1940/4518] 42% | Training loss: 0.6870803299331173
Epoch: 89 | Iteration number: [1950/4518] 43% | Training loss: 0.6870739658367939
Epoch: 89 | Iteration number: [1960/4518] 43% | Training loss: 0.6870677249468102
Epoch: 89 | Iteration number: [1970/4518] 43% | Training loss: 0.6870623230026458
Epoch: 89 | Iteration number: [1980/4518] 43% | Training loss: 0.6870598975757156
Epoch: 89 | Iteration number: [1990/4518] 44% | Training loss: 0.6870575712254299
Epoch: 89 | Iteration number: [2000/4518] 44% | Training loss: 0.6870580544173718
Epoch: 89 | Iteration number: [2010/4518] 44% | Training loss: 0.6870600504958214
Epoch: 89 | Iteration number: [2020/4518] 44% | Training loss: 0.6870585722203302
Epoch: 89 | Iteration number: [2030/4518] 44% | Training loss: 0.687060019564746
Epoch: 89 | Iteration number: [2040/4518] 45% | Training loss: 0.6870514850990445
Epoch: 89 | Iteration number: [2050/4518] 45% | Training loss: 0.6870414411730883
Epoch: 89 | Iteration number: [2060/4518] 45% | Training loss: 0.6870387716200745
Epoch: 89 | Iteration number: [2070/4518] 45% | Training loss: 0.6870375727397808
Epoch: 89 | Iteration number: [2080/4518] 46% | Training loss: 0.6870338228459542
Epoch: 89 | Iteration number: [2090/4518] 46% | Training loss: 0.6870375032345074
Epoch: 89 | Iteration number: [2100/4518] 46% | Training loss: 0.687029423515002
Epoch: 89 | Iteration number: [2110/4518] 46% | Training loss: 0.6870226932927895
Epoch: 89 | Iteration number: [2120/4518] 46% | Training loss: 0.6870222908708284
Epoch: 89 | Iteration number: [2130/4518] 47% | Training loss: 0.6870289554898168
Epoch: 89 | Iteration number: [2140/4518] 47% | Training loss: 0.687032372734257
Epoch: 89 | Iteration number: [2150/4518] 47% | Training loss: 0.6870326618815578
Epoch: 89 | Iteration number: [2160/4518] 47% | Training loss: 0.6870320595248982
Epoch: 89 | Iteration number: [2170/4518] 48% | Training loss: 0.6870300899727553
Epoch: 89 | Iteration number: [2180/4518] 48% | Training loss: 0.6870279410290062
Epoch: 89 | Iteration number: [2190/4518] 48% | Training loss: 0.6870247045608416
Epoch: 89 | Iteration number: [2200/4518] 48% | Training loss: 0.6870245372707193
Epoch: 89 | Iteration number: [2210/4518] 48% | Training loss: 0.6870303336311789
Epoch: 89 | Iteration number: [2220/4518] 49% | Training loss: 0.6870323229748924
Epoch: 89 | Iteration number: [2230/4518] 49% | Training loss: 0.687034831560246
Epoch: 89 | Iteration number: [2240/4518] 49% | Training loss: 0.6870364237842815
Epoch: 89 | Iteration number: [2250/4518] 49% | Training loss: 0.6870345001750522
Epoch: 89 | Iteration number: [2260/4518] 50% | Training loss: 0.687034797668457
Epoch: 89 | Iteration number: [2270/4518] 50% | Training loss: 0.6870351140982254
Epoch: 89 | Iteration number: [2280/4518] 50% | Training loss: 0.6870342672394033
Epoch: 89 | Iteration number: [2290/4518] 50% | Training loss: 0.6870334838415337
Epoch: 89 | Iteration number: [2300/4518] 50% | Training loss: 0.687031839178956
Epoch: 89 | Iteration number: [2310/4518] 51% | Training loss: 0.6870306830901605
Epoch: 89 | Iteration number: [2320/4518] 51% | Training loss: 0.6870297936786866
Epoch: 89 | Iteration number: [2330/4518] 51% | Training loss: 0.6870247946020871
Epoch: 89 | Iteration number: [2340/4518] 51% | Training loss: 0.6870227412026153
Epoch: 89 | Iteration number: [2350/4518] 52% | Training loss: 0.6870214813059949
Epoch: 89 | Iteration number: [2360/4518] 52% | Training loss: 0.6870224736757198
Epoch: 89 | Iteration number: [2370/4518] 52% | Training loss: 0.6870200480086894
Epoch: 89 | Iteration number: [2380/4518] 52% | Training loss: 0.6870203925030572
Epoch: 89 | Iteration number: [2390/4518] 52% | Training loss: 0.6870155873408378
Epoch: 89 | Iteration number: [2400/4518] 53% | Training loss: 0.6870170765618483
Epoch: 89 | Iteration number: [2410/4518] 53% | Training loss: 0.6870180911542964
Epoch: 89 | Iteration number: [2420/4518] 53% | Training loss: 0.6870143101727667
Epoch: 89 | Iteration number: [2430/4518] 53% | Training loss: 0.6870098636964712
Epoch: 89 | Iteration number: [2440/4518] 54% | Training loss: 0.6870114863163135
Epoch: 89 | Iteration number: [2450/4518] 54% | Training loss: 0.6870083795275007
Epoch: 89 | Iteration number: [2460/4518] 54% | Training loss: 0.687011890149698
Epoch: 89 | Iteration number: [2470/4518] 54% | Training loss: 0.6870098025209991
Epoch: 89 | Iteration number: [2480/4518] 54% | Training loss: 0.6870070990054838
Epoch: 89 | Iteration number: [2490/4518] 55% | Training loss: 0.6870075748148692
Epoch: 89 | Iteration number: [2500/4518] 55% | Training loss: 0.6870109393835068
Epoch: 89 | Iteration number: [2510/4518] 55% | Training loss: 0.6870102973573237
Epoch: 89 | Iteration number: [2520/4518] 55% | Training loss: 0.6870073370044194
Epoch: 89 | Iteration number: [2530/4518] 55% | Training loss: 0.687006910610576
Epoch: 89 | Iteration number: [2540/4518] 56% | Training loss: 0.687008433712749
Epoch: 89 | Iteration number: [2550/4518] 56% | Training loss: 0.6870107129975861
Epoch: 89 | Iteration number: [2560/4518] 56% | Training loss: 0.687010183907114
Epoch: 89 | Iteration number: [2570/4518] 56% | Training loss: 0.6870076841185528
Epoch: 89 | Iteration number: [2580/4518] 57% | Training loss: 0.6870021949211756
Epoch: 89 | Iteration number: [2590/4518] 57% | Training loss: 0.6870026960336103
Epoch: 89 | Iteration number: [2600/4518] 57% | Training loss: 0.687001377252432
Epoch: 89 | Iteration number: [2610/4518] 57% | Training loss: 0.6869999327650472
Epoch: 89 | Iteration number: [2620/4518] 57% | Training loss: 0.6869976220012621
Epoch: 89 | Iteration number: [2630/4518] 58% | Training loss: 0.6870017686950843
Epoch: 89 | Iteration number: [2640/4518] 58% | Training loss: 0.6870049838541132
Epoch: 89 | Iteration number: [2650/4518] 58% | Training loss: 0.6870065874423621
Epoch: 89 | Iteration number: [2660/4518] 58% | Training loss: 0.6870080138059487
Epoch: 89 | Iteration number: [2670/4518] 59% | Training loss: 0.6870023396577728
Epoch: 89 | Iteration number: [2680/4518] 59% | Training loss: 0.6869979519230216
Epoch: 89 | Iteration number: [2690/4518] 59% | Training loss: 0.6869962248881953
Epoch: 89 | Iteration number: [2700/4518] 59% | Training loss: 0.6869927328824997
Epoch: 89 | Iteration number: [2710/4518] 59% | Training loss: 0.6869939774164855
Epoch: 89 | Iteration number: [2720/4518] 60% | Training loss: 0.6869894492932979
Epoch: 89 | Iteration number: [2730/4518] 60% | Training loss: 0.6869868756213904
Epoch: 89 | Iteration number: [2740/4518] 60% | Training loss: 0.6869866874748773
Epoch: 89 | Iteration number: [2750/4518] 60% | Training loss: 0.6869799792333082
Epoch: 89 | Iteration number: [2760/4518] 61% | Training loss: 0.6869764118954755
Epoch: 89 | Iteration number: [2770/4518] 61% | Training loss: 0.6869777439733705
Epoch: 89 | Iteration number: [2780/4518] 61% | Training loss: 0.6869736078188574
Epoch: 89 | Iteration number: [2790/4518] 61% | Training loss: 0.6869727963615062
Epoch: 89 | Iteration number: [2800/4518] 61% | Training loss: 0.6869689057554518
Epoch: 89 | Iteration number: [2810/4518] 62% | Training loss: 0.6869659862272256
Epoch: 89 | Iteration number: [2820/4518] 62% | Training loss: 0.6869659294684728
Epoch: 89 | Iteration number: [2830/4518] 62% | Training loss: 0.6869650906050584
Epoch: 89 | Iteration number: [2840/4518] 62% | Training loss: 0.6869689921887827
Epoch: 89 | Iteration number: [2850/4518] 63% | Training loss: 0.6869694106620655
Epoch: 89 | Iteration number: [2860/4518] 63% | Training loss: 0.6869644888839521
Epoch: 89 | Iteration number: [2870/4518] 63% | Training loss: 0.6869651120298831
Epoch: 89 | Iteration number: [2880/4518] 63% | Training loss: 0.6869627736922768
Epoch: 89 | Iteration number: [2890/4518] 63% | Training loss: 0.6869577295227447
Epoch: 89 | Iteration number: [2900/4518] 64% | Training loss: 0.6869585364029325
Epoch: 89 | Iteration number: [2910/4518] 64% | Training loss: 0.6869560643160056
Epoch: 89 | Iteration number: [2920/4518] 64% | Training loss: 0.6869564805537054
Epoch: 89 | Iteration number: [2930/4518] 64% | Training loss: 0.686961171509056
Epoch: 89 | Iteration number: [2940/4518] 65% | Training loss: 0.6869583782492852
Epoch: 89 | Iteration number: [2950/4518] 65% | Training loss: 0.686954435776856
Epoch: 89 | Iteration number: [2960/4518] 65% | Training loss: 0.6869549978021029
Epoch: 89 | Iteration number: [2970/4518] 65% | Training loss: 0.6869557619295538
Epoch: 89 | Iteration number: [2980/4518] 65% | Training loss: 0.6869575174862906
Epoch: 89 | Iteration number: [2990/4518] 66% | Training loss: 0.6869585532408494
Epoch: 89 | Iteration number: [3000/4518] 66% | Training loss: 0.6869566520452499
Epoch: 89 | Iteration number: [3010/4518] 66% | Training loss: 0.6869588043008532
Epoch: 89 | Iteration number: [3020/4518] 66% | Training loss: 0.6869616947624068
Epoch: 89 | Iteration number: [3030/4518] 67% | Training loss: 0.6869610716407448
Epoch: 89 | Iteration number: [3040/4518] 67% | Training loss: 0.6869596317214401
Epoch: 89 | Iteration number: [3050/4518] 67% | Training loss: 0.6869623337808203
Epoch: 89 | Iteration number: [3060/4518] 67% | Training loss: 0.6869664702929702
Epoch: 89 | Iteration number: [3070/4518] 67% | Training loss: 0.686963226643758
Epoch: 89 | Iteration number: [3080/4518] 68% | Training loss: 0.6869615397670052
Epoch: 89 | Iteration number: [3090/4518] 68% | Training loss: 0.6869666394099448
Epoch: 89 | Iteration number: [3100/4518] 68% | Training loss: 0.6869624871784641
Epoch: 89 | Iteration number: [3110/4518] 68% | Training loss: 0.6869615045774404
Epoch: 89 | Iteration number: [3120/4518] 69% | Training loss: 0.6869599766265123
Epoch: 89 | Iteration number: [3130/4518] 69% | Training loss: 0.6869567354456685
Epoch: 89 | Iteration number: [3140/4518] 69% | Training loss: 0.6869541151128756
Epoch: 89 | Iteration number: [3150/4518] 69% | Training loss: 0.686950302748453
Epoch: 89 | Iteration number: [3160/4518] 69% | Training loss: 0.6869489294818685
Epoch: 89 | Iteration number: [3170/4518] 70% | Training loss: 0.6869431199899607
Epoch: 89 | Iteration number: [3180/4518] 70% | Training loss: 0.6869449055044906
Epoch: 89 | Iteration number: [3190/4518] 70% | Training loss: 0.6869431311247117
Epoch: 89 | Iteration number: [3200/4518] 70% | Training loss: 0.6869407289102674
Epoch: 89 | Iteration number: [3210/4518] 71% | Training loss: 0.6869374449565032
Epoch: 89 | Iteration number: [3220/4518] 71% | Training loss: 0.6869389912171393
Epoch: 89 | Iteration number: [3230/4518] 71% | Training loss: 0.6869414930373153
Epoch: 89 | Iteration number: [3240/4518] 71% | Training loss: 0.6869376708511953
Epoch: 89 | Iteration number: [3250/4518] 71% | Training loss: 0.6869368906938113
Epoch: 89 | Iteration number: [3260/4518] 72% | Training loss: 0.6869334808705043
Epoch: 89 | Iteration number: [3270/4518] 72% | Training loss: 0.6869373858157284
Epoch: 89 | Iteration number: [3280/4518] 72% | Training loss: 0.6869393015053215
Epoch: 89 | Iteration number: [3290/4518] 72% | Training loss: 0.6869371476687921
Epoch: 89 | Iteration number: [3300/4518] 73% | Training loss: 0.6869389380650087
Epoch: 89 | Iteration number: [3310/4518] 73% | Training loss: 0.6869393917729127
Epoch: 89 | Iteration number: [3320/4518] 73% | Training loss: 0.6869409775338977
Epoch: 89 | Iteration number: [3330/4518] 73% | Training loss: 0.6869395314215182
Epoch: 89 | Iteration number: [3340/4518] 73% | Training loss: 0.6869394833634713
Epoch: 89 | Iteration number: [3350/4518] 74% | Training loss: 0.6869395764372243
Epoch: 89 | Iteration number: [3360/4518] 74% | Training loss: 0.686939015416872
Epoch: 89 | Iteration number: [3370/4518] 74% | Training loss: 0.6869398729560637
Epoch: 89 | Iteration number: [3380/4518] 74% | Training loss: 0.6869409049932773
Epoch: 89 | Iteration number: [3390/4518] 75% | Training loss: 0.6869423867678572
Epoch: 89 | Iteration number: [3400/4518] 75% | Training loss: 0.6869438094777219
Epoch: 89 | Iteration number: [3410/4518] 75% | Training loss: 0.6869416667044688
Epoch: 89 | Iteration number: [3420/4518] 75% | Training loss: 0.6869407537562108
Epoch: 89 | Iteration number: [3430/4518] 75% | Training loss: 0.6869438427704069
Epoch: 89 | Iteration number: [3440/4518] 76% | Training loss: 0.6869423447480035
Epoch: 89 | Iteration number: [3450/4518] 76% | Training loss: 0.6869403330657793
Epoch: 89 | Iteration number: [3460/4518] 76% | Training loss: 0.6869378794135386
Epoch: 89 | Iteration number: [3470/4518] 76% | Training loss: 0.6869394627703026
Epoch: 89 | Iteration number: [3480/4518] 77% | Training loss: 0.6869385227047163
Epoch: 89 | Iteration number: [3490/4518] 77% | Training loss: 0.6869345063978758
Epoch: 89 | Iteration number: [3500/4518] 77% | Training loss: 0.6869319139719009
Epoch: 89 | Iteration number: [3510/4518] 77% | Training loss: 0.6869301707826109
Epoch: 89 | Iteration number: [3520/4518] 77% | Training loss: 0.6869237351315942
Epoch: 89 | Iteration number: [3530/4518] 78% | Training loss: 0.6869219297390147
Epoch: 89 | Iteration number: [3540/4518] 78% | Training loss: 0.6869205055432132
Epoch: 89 | Iteration number: [3550/4518] 78% | Training loss: 0.6869220201566186
Epoch: 89 | Iteration number: [3560/4518] 78% | Training loss: 0.6869204411345922
Epoch: 89 | Iteration number: [3570/4518] 79% | Training loss: 0.6869214388836665
Epoch: 89 | Iteration number: [3580/4518] 79% | Training loss: 0.6869214816799377
Epoch: 89 | Iteration number: [3590/4518] 79% | Training loss: 0.6869217522463095
Epoch: 89 | Iteration number: [3600/4518] 79% | Training loss: 0.6869212277730306
Epoch: 89 | Iteration number: [3610/4518] 79% | Training loss: 0.6869196656503176
Epoch: 89 | Iteration number: [3620/4518] 80% | Training loss: 0.6869232124221918
Epoch: 89 | Iteration number: [3630/4518] 80% | Training loss: 0.6869229919982679
Epoch: 89 | Iteration number: [3640/4518] 80% | Training loss: 0.6869245311061104
Epoch: 89 | Iteration number: [3650/4518] 80% | Training loss: 0.6869202259468705
Epoch: 89 | Iteration number: [3660/4518] 81% | Training loss: 0.686919470334965
Epoch: 89 | Iteration number: [3670/4518] 81% | Training loss: 0.6869153902543663
Epoch: 89 | Iteration number: [3680/4518] 81% | Training loss: 0.686916785541436
Epoch: 89 | Iteration number: [3690/4518] 81% | Training loss: 0.6869177888240917
Epoch: 89 | Iteration number: [3700/4518] 81% | Training loss: 0.6869186416832176
Epoch: 89 | Iteration number: [3710/4518] 82% | Training loss: 0.6869198764109548
Epoch: 89 | Iteration number: [3720/4518] 82% | Training loss: 0.6869174321812969
Epoch: 89 | Iteration number: [3730/4518] 82% | Training loss: 0.686917468897459
Epoch: 89 | Iteration number: [3740/4518] 82% | Training loss: 0.6869207379174105
Epoch: 89 | Iteration number: [3750/4518] 83% | Training loss: 0.6869221626758576
Epoch: 89 | Iteration number: [3760/4518] 83% | Training loss: 0.6869181112089056
Epoch: 89 | Iteration number: [3770/4518] 83% | Training loss: 0.6869176816877066
Epoch: 89 | Iteration number: [3780/4518] 83% | Training loss: 0.6869176840813702
Epoch: 89 | Iteration number: [3790/4518] 83% | Training loss: 0.686916140751977
Epoch: 89 | Iteration number: [3800/4518] 84% | Training loss: 0.6869141002548368
Epoch: 89 | Iteration number: [3810/4518] 84% | Training loss: 0.6869114957143628
Epoch: 89 | Iteration number: [3820/4518] 84% | Training loss: 0.6869128787548754
Epoch: 89 | Iteration number: [3830/4518] 84% | Training loss: 0.6869131979058368
Epoch: 89 | Iteration number: [3840/4518] 84% | Training loss: 0.6869159385096282
Epoch: 89 | Iteration number: [3850/4518] 85% | Training loss: 0.6869184382085677
Epoch: 89 | Iteration number: [3860/4518] 85% | Training loss: 0.6869186822923354
Epoch: 89 | Iteration number: [3870/4518] 85% | Training loss: 0.6869200879135181
Epoch: 89 | Iteration number: [3880/4518] 85% | Training loss: 0.6869220386460885
Epoch: 89 | Iteration number: [3890/4518] 86% | Training loss: 0.686923977173386
Epoch: 89 | Iteration number: [3900/4518] 86% | Training loss: 0.6869202775221604
Epoch: 89 | Iteration number: [3910/4518] 86% | Training loss: 0.6869193515509291
Epoch: 89 | Iteration number: [3920/4518] 86% | Training loss: 0.6869162303148484
Epoch: 89 | Iteration number: [3930/4518] 86% | Training loss: 0.6869110871513988
Epoch: 89 | Iteration number: [3940/4518] 87% | Training loss: 0.6869145415458583
Epoch: 89 | Iteration number: [3950/4518] 87% | Training loss: 0.6869144668156587
Epoch: 89 | Iteration number: [3960/4518] 87% | Training loss: 0.6869129162846189
Epoch: 89 | Iteration number: [3970/4518] 87% | Training loss: 0.686915023471006
Epoch: 89 | Iteration number: [3980/4518] 88% | Training loss: 0.6869157885786277
Epoch: 89 | Iteration number: [3990/4518] 88% | Training loss: 0.6869141528929087
Epoch: 89 | Iteration number: [4000/4518] 88% | Training loss: 0.686914731040597
Epoch: 89 | Iteration number: [4010/4518] 88% | Training loss: 0.6869164695020329
Epoch: 89 | Iteration number: [4020/4518] 88% | Training loss: 0.6869185108747056
Epoch: 89 | Iteration number: [4030/4518] 89% | Training loss: 0.6869203474770113
Epoch: 89 | Iteration number: [4040/4518] 89% | Training loss: 0.6869189847371365
Epoch: 89 | Iteration number: [4050/4518] 89% | Training loss: 0.6869169219776436
Epoch: 89 | Iteration number: [4060/4518] 89% | Training loss: 0.6869156823222861
Epoch: 89 | Iteration number: [4070/4518] 90% | Training loss: 0.6869133658286102
Epoch: 89 | Iteration number: [4080/4518] 90% | Training loss: 0.6869141826734824
Epoch: 89 | Iteration number: [4090/4518] 90% | Training loss: 0.6869156396913645
Epoch: 89 | Iteration number: [4100/4518] 90% | Training loss: 0.686915082495387
Epoch: 89 | Iteration number: [4110/4518] 90% | Training loss: 0.6869150900347679
Epoch: 89 | Iteration number: [4120/4518] 91% | Training loss: 0.6869159026632031
Epoch: 89 | Iteration number: [4130/4518] 91% | Training loss: 0.6869151227410711
Epoch: 89 | Iteration number: [4140/4518] 91% | Training loss: 0.6869156976828829
Epoch: 89 | Iteration number: [4150/4518] 91% | Training loss: 0.6869142872166921
Epoch: 89 | Iteration number: [4160/4518] 92% | Training loss: 0.6869146373552771
Epoch: 89 | Iteration number: [4170/4518] 92% | Training loss: 0.6869135548456682
Epoch: 89 | Iteration number: [4180/4518] 92% | Training loss: 0.686910419971749
Epoch: 89 | Iteration number: [4190/4518] 92% | Training loss: 0.6869088613759362
Epoch: 89 | Iteration number: [4200/4518] 92% | Training loss: 0.6869107272795268
Epoch: 89 | Iteration number: [4210/4518] 93% | Training loss: 0.6869101117880497
Epoch: 89 | Iteration number: [4220/4518] 93% | Training loss: 0.6869105838910098
Epoch: 89 | Iteration number: [4230/4518] 93% | Training loss: 0.6869097296932347
Epoch: 89 | Iteration number: [4240/4518] 93% | Training loss: 0.6869080779265683
Epoch: 89 | Iteration number: [4250/4518] 94% | Training loss: 0.686909592740676
Epoch: 89 | Iteration number: [4260/4518] 94% | Training loss: 0.6869086376658068
Epoch: 89 | Iteration number: [4270/4518] 94% | Training loss: 0.6869056638426189
Epoch: 89 | Iteration number: [4280/4518] 94% | Training loss: 0.6869027125361924
Epoch: 89 | Iteration number: [4290/4518] 94% | Training loss: 0.686901730396253
Epoch: 89 | Iteration number: [4300/4518] 95% | Training loss: 0.6869018873503042
Epoch: 89 | Iteration number: [4310/4518] 95% | Training loss: 0.6869031662315891
Epoch: 89 | Iteration number: [4320/4518] 95% | Training loss: 0.6869042954235165
Epoch: 89 | Iteration number: [4330/4518] 95% | Training loss: 0.6869043364398199
Epoch: 89 | Iteration number: [4340/4518] 96% | Training loss: 0.6869045221448494
Epoch: 89 | Iteration number: [4350/4518] 96% | Training loss: 0.68690419403986
Epoch: 89 | Iteration number: [4360/4518] 96% | Training loss: 0.6869075846097885
Epoch: 89 | Iteration number: [4370/4518] 96% | Training loss: 0.6869083337298247
Epoch: 89 | Iteration number: [4380/4518] 96% | Training loss: 0.6869068026134413
Epoch: 89 | Iteration number: [4390/4518] 97% | Training loss: 0.6869087344828934
Epoch: 89 | Iteration number: [4400/4518] 97% | Training loss: 0.6869091879237782
Epoch: 89 | Iteration number: [4410/4518] 97% | Training loss: 0.6869071388866356
Epoch: 89 | Iteration number: [4420/4518] 97% | Training loss: 0.6869063074097914
Epoch: 89 | Iteration number: [4430/4518] 98% | Training loss: 0.6869048196898088
Epoch: 89 | Iteration number: [4440/4518] 98% | Training loss: 0.6869043060922407
Epoch: 89 | Iteration number: [4450/4518] 98% | Training loss: 0.6869069244620505
Epoch: 89 | Iteration number: [4460/4518] 98% | Training loss: 0.686905410792261
Epoch: 89 | Iteration number: [4470/4518] 98% | Training loss: 0.6869046806355718
Epoch: 89 | Iteration number: [4480/4518] 99% | Training loss: 0.686904160159507
Epoch: 89 | Iteration number: [4490/4518] 99% | Training loss: 0.6869034125040262
Epoch: 89 | Iteration number: [4500/4518] 99% | Training loss: 0.6869019646247227
Epoch: 89 | Iteration number: [4510/4518] 99% | Training loss: 0.6869013428820211

 End of epoch: 89 | Train Loss: 0.6867507959610069 | Training Time: 633 

 End of epoch: 89 | Eval Loss: 0.6895737161441725 | Evaluating Time: 17 
Epoch: 90 | Iteration number: [10/4518] 0% | Training loss: 0.754750543832779
Epoch: 90 | Iteration number: [20/4518] 0% | Training loss: 0.7208004862070083
Epoch: 90 | Iteration number: [30/4518] 0% | Training loss: 0.7091520150502523
Epoch: 90 | Iteration number: [40/4518] 0% | Training loss: 0.7035463854670525
Epoch: 90 | Iteration number: [50/4518] 1% | Training loss: 0.7002928304672241
Epoch: 90 | Iteration number: [60/4518] 1% | Training loss: 0.6979234953721364
Epoch: 90 | Iteration number: [70/4518] 1% | Training loss: 0.6963997432163783
Epoch: 90 | Iteration number: [80/4518] 1% | Training loss: 0.6953123793005943
Epoch: 90 | Iteration number: [90/4518] 1% | Training loss: 0.694461030430264
Epoch: 90 | Iteration number: [100/4518] 2% | Training loss: 0.693529788851738
Epoch: 90 | Iteration number: [110/4518] 2% | Training loss: 0.6929061580788005
Epoch: 90 | Iteration number: [120/4518] 2% | Training loss: 0.6924702197313308
Epoch: 90 | Iteration number: [130/4518] 2% | Training loss: 0.6919164020281572
Epoch: 90 | Iteration number: [140/4518] 3% | Training loss: 0.6915890744754246
Epoch: 90 | Iteration number: [150/4518] 3% | Training loss: 0.6912794192632039
Epoch: 90 | Iteration number: [160/4518] 3% | Training loss: 0.6909813333302737
Epoch: 90 | Iteration number: [170/4518] 3% | Training loss: 0.6907860387774075
Epoch: 90 | Iteration number: [180/4518] 3% | Training loss: 0.6905827081865734
Epoch: 90 | Iteration number: [190/4518] 4% | Training loss: 0.6904089773956098
Epoch: 90 | Iteration number: [200/4518] 4% | Training loss: 0.6901826280355453
Epoch: 90 | Iteration number: [210/4518] 4% | Training loss: 0.6900041812942141
Epoch: 90 | Iteration number: [220/4518] 4% | Training loss: 0.6898348431695591
Epoch: 90 | Iteration number: [230/4518] 5% | Training loss: 0.6897040732528852
Epoch: 90 | Iteration number: [240/4518] 5% | Training loss: 0.689591218282779
Epoch: 90 | Iteration number: [250/4518] 5% | Training loss: 0.6894578120708466
Epoch: 90 | Iteration number: [260/4518] 5% | Training loss: 0.6893116607115819
Epoch: 90 | Iteration number: [270/4518] 5% | Training loss: 0.6891854908731249
Epoch: 90 | Iteration number: [280/4518] 6% | Training loss: 0.6889903343149594
Epoch: 90 | Iteration number: [290/4518] 6% | Training loss: 0.6889212482962115
Epoch: 90 | Iteration number: [300/4518] 6% | Training loss: 0.688852725426356
Epoch: 90 | Iteration number: [310/4518] 6% | Training loss: 0.6888092160224915
Epoch: 90 | Iteration number: [320/4518] 7% | Training loss: 0.6887493655085564
Epoch: 90 | Iteration number: [330/4518] 7% | Training loss: 0.6887185356833718
Epoch: 90 | Iteration number: [340/4518] 7% | Training loss: 0.6886626187492819
Epoch: 90 | Iteration number: [350/4518] 7% | Training loss: 0.6886364684786115
Epoch: 90 | Iteration number: [360/4518] 7% | Training loss: 0.6885961062378354
Epoch: 90 | Iteration number: [370/4518] 8% | Training loss: 0.688566151986251
Epoch: 90 | Iteration number: [380/4518] 8% | Training loss: 0.688518877719578
Epoch: 90 | Iteration number: [390/4518] 8% | Training loss: 0.6884960007973207
Epoch: 90 | Iteration number: [400/4518] 8% | Training loss: 0.688455808609724
Epoch: 90 | Iteration number: [410/4518] 9% | Training loss: 0.6884234184172096
Epoch: 90 | Iteration number: [420/4518] 9% | Training loss: 0.6883673524572735
Epoch: 90 | Iteration number: [430/4518] 9% | Training loss: 0.6883528641490049
Epoch: 90 | Iteration number: [440/4518] 9% | Training loss: 0.6883239609273997
Epoch: 90 | Iteration number: [450/4518] 9% | Training loss: 0.6882804560661316
Epoch: 90 | Iteration number: [460/4518] 10% | Training loss: 0.6882686639609544
Epoch: 90 | Iteration number: [470/4518] 10% | Training loss: 0.6882597982883454
Epoch: 90 | Iteration number: [480/4518] 10% | Training loss: 0.6882280165950457
Epoch: 90 | Iteration number: [490/4518] 10% | Training loss: 0.6881634504211193
Epoch: 90 | Iteration number: [500/4518] 11% | Training loss: 0.6881282601356506
Epoch: 90 | Iteration number: [510/4518] 11% | Training loss: 0.6880982278608808
Epoch: 90 | Iteration number: [520/4518] 11% | Training loss: 0.688075260244883
Epoch: 90 | Iteration number: [530/4518] 11% | Training loss: 0.6880544127158399
Epoch: 90 | Iteration number: [540/4518] 11% | Training loss: 0.6880150672462252
Epoch: 90 | Iteration number: [550/4518] 12% | Training loss: 0.687990648096258
Epoch: 90 | Iteration number: [560/4518] 12% | Training loss: 0.687977182652269
Epoch: 90 | Iteration number: [570/4518] 12% | Training loss: 0.6879604957605663
Epoch: 90 | Iteration number: [580/4518] 12% | Training loss: 0.6879397148716039
Epoch: 90 | Iteration number: [590/4518] 13% | Training loss: 0.6879288095538899
Epoch: 90 | Iteration number: [600/4518] 13% | Training loss: 0.687916547258695
Epoch: 90 | Iteration number: [610/4518] 13% | Training loss: 0.6878984068260818
Epoch: 90 | Iteration number: [620/4518] 13% | Training loss: 0.6878826367278252
Epoch: 90 | Iteration number: [630/4518] 13% | Training loss: 0.6878849684246002
Epoch: 90 | Iteration number: [640/4518] 14% | Training loss: 0.6878724336624146
Epoch: 90 | Iteration number: [650/4518] 14% | Training loss: 0.6878657072324019
Epoch: 90 | Iteration number: [660/4518] 14% | Training loss: 0.6878399069562103
Epoch: 90 | Iteration number: [670/4518] 14% | Training loss: 0.6878321996375696
Epoch: 90 | Iteration number: [680/4518] 15% | Training loss: 0.687826202546849
Epoch: 90 | Iteration number: [690/4518] 15% | Training loss: 0.6878244987432508
Epoch: 90 | Iteration number: [700/4518] 15% | Training loss: 0.6878074105296816
Epoch: 90 | Iteration number: [710/4518] 15% | Training loss: 0.687809746114301
Epoch: 90 | Iteration number: [720/4518] 15% | Training loss: 0.6877908036112785
Epoch: 90 | Iteration number: [730/4518] 16% | Training loss: 0.687786580765084
Epoch: 90 | Iteration number: [740/4518] 16% | Training loss: 0.6877610330646102
Epoch: 90 | Iteration number: [750/4518] 16% | Training loss: 0.6877431750297547
Epoch: 90 | Iteration number: [760/4518] 16% | Training loss: 0.6877428358322696
Epoch: 90 | Iteration number: [770/4518] 17% | Training loss: 0.6877211343158375
Epoch: 90 | Iteration number: [780/4518] 17% | Training loss: 0.6877003535246238
Epoch: 90 | Iteration number: [790/4518] 17% | Training loss: 0.6876872166802611
Epoch: 90 | Iteration number: [800/4518] 17% | Training loss: 0.6876688390225172
Epoch: 90 | Iteration number: [810/4518] 17% | Training loss: 0.6876542866230011
Epoch: 90 | Iteration number: [820/4518] 18% | Training loss: 0.687639545013265
Epoch: 90 | Iteration number: [830/4518] 18% | Training loss: 0.6876377178961972
Epoch: 90 | Iteration number: [840/4518] 18% | Training loss: 0.6876268795558385
Epoch: 90 | Iteration number: [850/4518] 18% | Training loss: 0.6876250529289245
Epoch: 90 | Iteration number: [860/4518] 19% | Training loss: 0.6876071945179341
Epoch: 90 | Iteration number: [870/4518] 19% | Training loss: 0.687599407461868
Epoch: 90 | Iteration number: [880/4518] 19% | Training loss: 0.6875891437584704
Epoch: 90 | Iteration number: [890/4518] 19% | Training loss: 0.687580598673124
Epoch: 90 | Iteration number: [900/4518] 19% | Training loss: 0.6875777891609404
Epoch: 90 | Iteration number: [910/4518] 20% | Training loss: 0.6875703169749333
Epoch: 90 | Iteration number: [920/4518] 20% | Training loss: 0.6875342177956001
Epoch: 90 | Iteration number: [930/4518] 20% | Training loss: 0.6875255715462469
Epoch: 90 | Iteration number: [940/4518] 20% | Training loss: 0.6875182123260295
Epoch: 90 | Iteration number: [950/4518] 21% | Training loss: 0.6875051128864288
Epoch: 90 | Iteration number: [960/4518] 21% | Training loss: 0.6875038322682182
Epoch: 90 | Iteration number: [970/4518] 21% | Training loss: 0.6874910155522455
Epoch: 90 | Iteration number: [980/4518] 21% | Training loss: 0.6874690395836928
Epoch: 90 | Iteration number: [990/4518] 21% | Training loss: 0.6874588093974373
Epoch: 90 | Iteration number: [1000/4518] 22% | Training loss: 0.6874549906849862
Epoch: 90 | Iteration number: [1010/4518] 22% | Training loss: 0.6874461702781148
Epoch: 90 | Iteration number: [1020/4518] 22% | Training loss: 0.687441340322588
Epoch: 90 | Iteration number: [1030/4518] 22% | Training loss: 0.6874366783980027
Epoch: 90 | Iteration number: [1040/4518] 23% | Training loss: 0.6874448971106456
Epoch: 90 | Iteration number: [1050/4518] 23% | Training loss: 0.6874350617045448
Epoch: 90 | Iteration number: [1060/4518] 23% | Training loss: 0.6874216042599588
Epoch: 90 | Iteration number: [1070/4518] 23% | Training loss: 0.687422737395652
Epoch: 90 | Iteration number: [1080/4518] 23% | Training loss: 0.6874170474984028
Epoch: 90 | Iteration number: [1090/4518] 24% | Training loss: 0.6874298067814714
Epoch: 90 | Iteration number: [1100/4518] 24% | Training loss: 0.6874224766276099
Epoch: 90 | Iteration number: [1110/4518] 24% | Training loss: 0.6874139827650947
Epoch: 90 | Iteration number: [1120/4518] 24% | Training loss: 0.6874190978705883
Epoch: 90 | Iteration number: [1130/4518] 25% | Training loss: 0.6874144566270103
Epoch: 90 | Iteration number: [1140/4518] 25% | Training loss: 0.6874194221015562
Epoch: 90 | Iteration number: [1150/4518] 25% | Training loss: 0.6874077929102856
Epoch: 90 | Iteration number: [1160/4518] 25% | Training loss: 0.6874027089312159
Epoch: 90 | Iteration number: [1170/4518] 25% | Training loss: 0.6873948674426119
Epoch: 90 | Iteration number: [1180/4518] 26% | Training loss: 0.6873830786195853
Epoch: 90 | Iteration number: [1190/4518] 26% | Training loss: 0.6873730286329734
Epoch: 90 | Iteration number: [1200/4518] 26% | Training loss: 0.6873750578860441
Epoch: 90 | Iteration number: [1210/4518] 26% | Training loss: 0.6873758202249354
Epoch: 90 | Iteration number: [1220/4518] 27% | Training loss: 0.6873696315972532
Epoch: 90 | Iteration number: [1230/4518] 27% | Training loss: 0.687372447950084
Epoch: 90 | Iteration number: [1240/4518] 27% | Training loss: 0.6873709531561021
Epoch: 90 | Iteration number: [1250/4518] 27% | Training loss: 0.6873677168369293
Epoch: 90 | Iteration number: [1260/4518] 27% | Training loss: 0.6873626311620077
Epoch: 90 | Iteration number: [1270/4518] 28% | Training loss: 0.6873450916583144
Epoch: 90 | Iteration number: [1280/4518] 28% | Training loss: 0.6873419452924281
Epoch: 90 | Iteration number: [1290/4518] 28% | Training loss: 0.6873327415118846
Epoch: 90 | Iteration number: [1300/4518] 28% | Training loss: 0.6873337117525248
Epoch: 90 | Iteration number: [1310/4518] 28% | Training loss: 0.6873235354896721
Epoch: 90 | Iteration number: [1320/4518] 29% | Training loss: 0.687317804992199
Epoch: 90 | Iteration number: [1330/4518] 29% | Training loss: 0.6873180224483174
Epoch: 90 | Iteration number: [1340/4518] 29% | Training loss: 0.6873164908209843
Epoch: 90 | Iteration number: [1350/4518] 29% | Training loss: 0.6873159709683171
Epoch: 90 | Iteration number: [1360/4518] 30% | Training loss: 0.6873113703640068
Epoch: 90 | Iteration number: [1370/4518] 30% | Training loss: 0.687311009769022
Epoch: 90 | Iteration number: [1380/4518] 30% | Training loss: 0.6873184203237727
Epoch: 90 | Iteration number: [1390/4518] 30% | Training loss: 0.6873088815658213
Epoch: 90 | Iteration number: [1400/4518] 30% | Training loss: 0.6873122254014015
Epoch: 90 | Iteration number: [1410/4518] 31% | Training loss: 0.6873097458207016
Epoch: 90 | Iteration number: [1420/4518] 31% | Training loss: 0.6872928359978635
Epoch: 90 | Iteration number: [1430/4518] 31% | Training loss: 0.687294518405741
Epoch: 90 | Iteration number: [1440/4518] 31% | Training loss: 0.6872800364262528
Epoch: 90 | Iteration number: [1450/4518] 32% | Training loss: 0.6872654741796954
Epoch: 90 | Iteration number: [1460/4518] 32% | Training loss: 0.6872657444379101
Epoch: 90 | Iteration number: [1470/4518] 32% | Training loss: 0.6872775198245535
Epoch: 90 | Iteration number: [1480/4518] 32% | Training loss: 0.6872720358339516
Epoch: 90 | Iteration number: [1490/4518] 32% | Training loss: 0.687268056845505
Epoch: 90 | Iteration number: [1500/4518] 33% | Training loss: 0.6872593780755997
Epoch: 90 | Iteration number: [1510/4518] 33% | Training loss: 0.6872527013551321
Epoch: 90 | Iteration number: [1520/4518] 33% | Training loss: 0.6872521982773354
Epoch: 90 | Iteration number: [1530/4518] 33% | Training loss: 0.6872501042933246
Epoch: 90 | Iteration number: [1540/4518] 34% | Training loss: 0.687248091689952
Epoch: 90 | Iteration number: [1550/4518] 34% | Training loss: 0.6872477570656808
Epoch: 90 | Iteration number: [1560/4518] 34% | Training loss: 0.6872456228885895
Epoch: 90 | Iteration number: [1570/4518] 34% | Training loss: 0.6872403828961074
Epoch: 90 | Iteration number: [1580/4518] 34% | Training loss: 0.687230429656898
Epoch: 90 | Iteration number: [1590/4518] 35% | Training loss: 0.6872238778093326
Epoch: 90 | Iteration number: [1600/4518] 35% | Training loss: 0.687220597192645
Epoch: 90 | Iteration number: [1610/4518] 35% | Training loss: 0.6872129341089948
Epoch: 90 | Iteration number: [1620/4518] 35% | Training loss: 0.6872021118799846
Epoch: 90 | Iteration number: [1630/4518] 36% | Training loss: 0.687205253971135
Epoch: 90 | Iteration number: [1640/4518] 36% | Training loss: 0.6871982035113544
Epoch: 90 | Iteration number: [1650/4518] 36% | Training loss: 0.6871950947515892
Epoch: 90 | Iteration number: [1660/4518] 36% | Training loss: 0.6871932082147484
Epoch: 90 | Iteration number: [1670/4518] 36% | Training loss: 0.6871877615323324
Epoch: 90 | Iteration number: [1680/4518] 37% | Training loss: 0.68718258628533
Epoch: 90 | Iteration number: [1690/4518] 37% | Training loss: 0.6871745085927862
Epoch: 90 | Iteration number: [1700/4518] 37% | Training loss: 0.6871715001849568
Epoch: 90 | Iteration number: [1710/4518] 37% | Training loss: 0.6871683590244828
Epoch: 90 | Iteration number: [1720/4518] 38% | Training loss: 0.6871722114987151
Epoch: 90 | Iteration number: [1730/4518] 38% | Training loss: 0.6871680716558688
Epoch: 90 | Iteration number: [1740/4518] 38% | Training loss: 0.6871661084821854
Epoch: 90 | Iteration number: [1750/4518] 38% | Training loss: 0.6871677275385175
Epoch: 90 | Iteration number: [1760/4518] 38% | Training loss: 0.687167780304497
Epoch: 90 | Iteration number: [1770/4518] 39% | Training loss: 0.6871673585331373
Epoch: 90 | Iteration number: [1780/4518] 39% | Training loss: 0.6871703664908249
Epoch: 90 | Iteration number: [1790/4518] 39% | Training loss: 0.6871701610154946
Epoch: 90 | Iteration number: [1800/4518] 39% | Training loss: 0.687169795135657
Epoch: 90 | Iteration number: [1810/4518] 40% | Training loss: 0.6871676444678017
Epoch: 90 | Iteration number: [1820/4518] 40% | Training loss: 0.6871704789963398
Epoch: 90 | Iteration number: [1830/4518] 40% | Training loss: 0.6871722751627855
Epoch: 90 | Iteration number: [1840/4518] 40% | Training loss: 0.6871655638127223
Epoch: 90 | Iteration number: [1850/4518] 40% | Training loss: 0.6871669092693844
Epoch: 90 | Iteration number: [1860/4518] 41% | Training loss: 0.6871643013210706
Epoch: 90 | Iteration number: [1870/4518] 41% | Training loss: 0.6871602734142446
Epoch: 90 | Iteration number: [1880/4518] 41% | Training loss: 0.6871597364861914
Epoch: 90 | Iteration number: [1890/4518] 41% | Training loss: 0.6871542445566289
Epoch: 90 | Iteration number: [1900/4518] 42% | Training loss: 0.6871509337111523
Epoch: 90 | Iteration number: [1910/4518] 42% | Training loss: 0.6871501869556167
Epoch: 90 | Iteration number: [1920/4518] 42% | Training loss: 0.6871446950050691
Epoch: 90 | Iteration number: [1930/4518] 42% | Training loss: 0.6871321170441227
Epoch: 90 | Iteration number: [1940/4518] 42% | Training loss: 0.6871327281919951
Epoch: 90 | Iteration number: [1950/4518] 43% | Training loss: 0.6871343696423066
Epoch: 90 | Iteration number: [1960/4518] 43% | Training loss: 0.687125151437156
Epoch: 90 | Iteration number: [1970/4518] 43% | Training loss: 0.6871185315139403
Epoch: 90 | Iteration number: [1980/4518] 43% | Training loss: 0.6871225472351518
Epoch: 90 | Iteration number: [1990/4518] 44% | Training loss: 0.687125604865539
Epoch: 90 | Iteration number: [2000/4518] 44% | Training loss: 0.6871250931918621
Epoch: 90 | Iteration number: [2010/4518] 44% | Training loss: 0.6871172328493489
Epoch: 90 | Iteration number: [2020/4518] 44% | Training loss: 0.6871142983141512
Epoch: 90 | Iteration number: [2030/4518] 44% | Training loss: 0.6871097000948901
Epoch: 90 | Iteration number: [2040/4518] 45% | Training loss: 0.6871101536294993
Epoch: 90 | Iteration number: [2050/4518] 45% | Training loss: 0.6871068347663414
Epoch: 90 | Iteration number: [2060/4518] 45% | Training loss: 0.687106874122203
Epoch: 90 | Iteration number: [2070/4518] 45% | Training loss: 0.6871022608545091
Epoch: 90 | Iteration number: [2080/4518] 46% | Training loss: 0.6871041744660873
Epoch: 90 | Iteration number: [2090/4518] 46% | Training loss: 0.687108886070799
Epoch: 90 | Iteration number: [2100/4518] 46% | Training loss: 0.6871067931254705
Epoch: 90 | Iteration number: [2110/4518] 46% | Training loss: 0.6871055754157605
Epoch: 90 | Iteration number: [2120/4518] 46% | Training loss: 0.687105099322661
Epoch: 90 | Iteration number: [2130/4518] 47% | Training loss: 0.687098597668706
Epoch: 90 | Iteration number: [2140/4518] 47% | Training loss: 0.6870957252856726
Epoch: 90 | Iteration number: [2150/4518] 47% | Training loss: 0.6870975792962452
Epoch: 90 | Iteration number: [2160/4518] 47% | Training loss: 0.687095233163348
Epoch: 90 | Iteration number: [2170/4518] 48% | Training loss: 0.6870939209713914
Epoch: 90 | Iteration number: [2180/4518] 48% | Training loss: 0.6870930347420754
Epoch: 90 | Iteration number: [2190/4518] 48% | Training loss: 0.6870919619793217
Epoch: 90 | Iteration number: [2200/4518] 48% | Training loss: 0.6870892828431996
Epoch: 90 | Iteration number: [2210/4518] 48% | Training loss: 0.6870850416330191
Epoch: 90 | Iteration number: [2220/4518] 49% | Training loss: 0.6870839422082042
Epoch: 90 | Iteration number: [2230/4518] 49% | Training loss: 0.6870835177566973
Epoch: 90 | Iteration number: [2240/4518] 49% | Training loss: 0.687079183491213
Epoch: 90 | Iteration number: [2250/4518] 49% | Training loss: 0.6870856189197964
Epoch: 90 | Iteration number: [2260/4518] 50% | Training loss: 0.6870863834313586
Epoch: 90 | Iteration number: [2270/4518] 50% | Training loss: 0.687082311497911
Epoch: 90 | Iteration number: [2280/4518] 50% | Training loss: 0.6870811362015573
Epoch: 90 | Iteration number: [2290/4518] 50% | Training loss: 0.6870820630846065
Epoch: 90 | Iteration number: [2300/4518] 50% | Training loss: 0.6870734791652016
Epoch: 90 | Iteration number: [2310/4518] 51% | Training loss: 0.6870764555353107
Epoch: 90 | Iteration number: [2320/4518] 51% | Training loss: 0.6870703792006805
Epoch: 90 | Iteration number: [2330/4518] 51% | Training loss: 0.6870701980693146
Epoch: 90 | Iteration number: [2340/4518] 51% | Training loss: 0.6870680765209035
Epoch: 90 | Iteration number: [2350/4518] 52% | Training loss: 0.6870681095884201
Epoch: 90 | Iteration number: [2360/4518] 52% | Training loss: 0.687062894666599
Epoch: 90 | Iteration number: [2370/4518] 52% | Training loss: 0.6870665972494375
Epoch: 90 | Iteration number: [2380/4518] 52% | Training loss: 0.6870637491971505
Epoch: 90 | Iteration number: [2390/4518] 52% | Training loss: 0.6870639894297931
Epoch: 90 | Iteration number: [2400/4518] 53% | Training loss: 0.6870612676690022
Epoch: 90 | Iteration number: [2410/4518] 53% | Training loss: 0.6870625193435621
Epoch: 90 | Iteration number: [2420/4518] 53% | Training loss: 0.687063226497863
Epoch: 90 | Iteration number: [2430/4518] 53% | Training loss: 0.6870616965823704
Epoch: 90 | Iteration number: [2440/4518] 54% | Training loss: 0.6870607893486492
Epoch: 90 | Iteration number: [2450/4518] 54% | Training loss: 0.6870521080007358
Epoch: 90 | Iteration number: [2460/4518] 54% | Training loss: 0.6870523259164841
Epoch: 90 | Iteration number: [2470/4518] 54% | Training loss: 0.6870503475308901
Epoch: 90 | Iteration number: [2480/4518] 54% | Training loss: 0.6870550830998728
Epoch: 90 | Iteration number: [2490/4518] 55% | Training loss: 0.6870490718558131
Epoch: 90 | Iteration number: [2500/4518] 55% | Training loss: 0.6870469194889068
Epoch: 90 | Iteration number: [2510/4518] 55% | Training loss: 0.6870477511350852
Epoch: 90 | Iteration number: [2520/4518] 55% | Training loss: 0.6870472674095441
Epoch: 90 | Iteration number: [2530/4518] 55% | Training loss: 0.6870499674981762
Epoch: 90 | Iteration number: [2540/4518] 56% | Training loss: 0.687052055677091
Epoch: 90 | Iteration number: [2550/4518] 56% | Training loss: 0.6870522636759515
Epoch: 90 | Iteration number: [2560/4518] 56% | Training loss: 0.6870490171015262
Epoch: 90 | Iteration number: [2570/4518] 56% | Training loss: 0.687050056874984
Epoch: 90 | Iteration number: [2580/4518] 57% | Training loss: 0.6870502778495005
Epoch: 90 | Iteration number: [2590/4518] 57% | Training loss: 0.6870498708086125
Epoch: 90 | Iteration number: [2600/4518] 57% | Training loss: 0.6870514888946827
Epoch: 90 | Iteration number: [2610/4518] 57% | Training loss: 0.6870533861876448
Epoch: 90 | Iteration number: [2620/4518] 57% | Training loss: 0.6870488979661737
Epoch: 90 | Iteration number: [2630/4518] 58% | Training loss: 0.6870492862657902
Epoch: 90 | Iteration number: [2640/4518] 58% | Training loss: 0.6870542247187007
Epoch: 90 | Iteration number: [2650/4518] 58% | Training loss: 0.6870549226931806
Epoch: 90 | Iteration number: [2660/4518] 58% | Training loss: 0.6870488003008348
Epoch: 90 | Iteration number: [2670/4518] 59% | Training loss: 0.6870471850316623
Epoch: 90 | Iteration number: [2680/4518] 59% | Training loss: 0.6870503527459814
Epoch: 90 | Iteration number: [2690/4518] 59% | Training loss: 0.6870430738509367
Epoch: 90 | Iteration number: [2700/4518] 59% | Training loss: 0.6870449156672866
Epoch: 90 | Iteration number: [2710/4518] 59% | Training loss: 0.6870453081007813
Epoch: 90 | Iteration number: [2720/4518] 60% | Training loss: 0.6870450362124864
Epoch: 90 | Iteration number: [2730/4518] 60% | Training loss: 0.6870455893404754
Epoch: 90 | Iteration number: [2740/4518] 60% | Training loss: 0.6870429516708764
Epoch: 90 | Iteration number: [2750/4518] 60% | Training loss: 0.6870385860096324
Epoch: 90 | Iteration number: [2760/4518] 61% | Training loss: 0.6870369111498197
Epoch: 90 | Iteration number: [2770/4518] 61% | Training loss: 0.6870316397196979
Epoch: 90 | Iteration number: [2780/4518] 61% | Training loss: 0.6870265163534837
Epoch: 90 | Iteration number: [2790/4518] 61% | Training loss: 0.6870245639782225
Epoch: 90 | Iteration number: [2800/4518] 61% | Training loss: 0.687025041452476
Epoch: 90 | Iteration number: [2810/4518] 62% | Training loss: 0.6870242488766056
Epoch: 90 | Iteration number: [2820/4518] 62% | Training loss: 0.6870241058633683
Epoch: 90 | Iteration number: [2830/4518] 62% | Training loss: 0.6870286073996406
Epoch: 90 | Iteration number: [2840/4518] 62% | Training loss: 0.6870266928009584
Epoch: 90 | Iteration number: [2850/4518] 63% | Training loss: 0.6870227743449964
Epoch: 90 | Iteration number: [2860/4518] 63% | Training loss: 0.6870212246071209
Epoch: 90 | Iteration number: [2870/4518] 63% | Training loss: 0.6870238001338281
Epoch: 90 | Iteration number: [2880/4518] 63% | Training loss: 0.6870200883804096
Epoch: 90 | Iteration number: [2890/4518] 63% | Training loss: 0.6870221892442671
Epoch: 90 | Iteration number: [2900/4518] 64% | Training loss: 0.6870202660971675
Epoch: 90 | Iteration number: [2910/4518] 64% | Training loss: 0.6870169327635945
Epoch: 90 | Iteration number: [2920/4518] 64% | Training loss: 0.6870170828618415
Epoch: 90 | Iteration number: [2930/4518] 64% | Training loss: 0.6870111887975764
Epoch: 90 | Iteration number: [2940/4518] 65% | Training loss: 0.68700707125015
Epoch: 90 | Iteration number: [2950/4518] 65% | Training loss: 0.687007276122853
Epoch: 90 | Iteration number: [2960/4518] 65% | Training loss: 0.6870123387591259
Epoch: 90 | Iteration number: [2970/4518] 65% | Training loss: 0.6870142409697125
Epoch: 90 | Iteration number: [2980/4518] 65% | Training loss: 0.6870118632612613
Epoch: 90 | Iteration number: [2990/4518] 66% | Training loss: 0.6870066133231224
Epoch: 90 | Iteration number: [3000/4518] 66% | Training loss: 0.6870064490437507
Epoch: 90 | Iteration number: [3010/4518] 66% | Training loss: 0.6870030921360979
Epoch: 90 | Iteration number: [3020/4518] 66% | Training loss: 0.6870013019304402
Epoch: 90 | Iteration number: [3030/4518] 67% | Training loss: 0.6870003766352587
Epoch: 90 | Iteration number: [3040/4518] 67% | Training loss: 0.6869987520928446
Epoch: 90 | Iteration number: [3050/4518] 67% | Training loss: 0.6869997875807715
Epoch: 90 | Iteration number: [3060/4518] 67% | Training loss: 0.687001907338504
Epoch: 90 | Iteration number: [3070/4518] 67% | Training loss: 0.68699944106686
Epoch: 90 | Iteration number: [3080/4518] 68% | Training loss: 0.6870008845607956
Epoch: 90 | Iteration number: [3090/4518] 68% | Training loss: 0.686999841396091
Epoch: 90 | Iteration number: [3100/4518] 68% | Training loss: 0.687003263984957
Epoch: 90 | Iteration number: [3110/4518] 68% | Training loss: 0.6870047003509914
Epoch: 90 | Iteration number: [3120/4518] 69% | Training loss: 0.687001279168404
Epoch: 90 | Iteration number: [3130/4518] 69% | Training loss: 0.6870001851941069
Epoch: 90 | Iteration number: [3140/4518] 69% | Training loss: 0.6869981865214694
Epoch: 90 | Iteration number: [3150/4518] 69% | Training loss: 0.6869985891145373
Epoch: 90 | Iteration number: [3160/4518] 69% | Training loss: 0.6869968735907651
Epoch: 90 | Iteration number: [3170/4518] 70% | Training loss: 0.6869937311399622
Epoch: 90 | Iteration number: [3180/4518] 70% | Training loss: 0.6869924633195565
Epoch: 90 | Iteration number: [3190/4518] 70% | Training loss: 0.686992007232385
Epoch: 90 | Iteration number: [3200/4518] 70% | Training loss: 0.6869895523414016
Epoch: 90 | Iteration number: [3210/4518] 71% | Training loss: 0.6869869518874219
Epoch: 90 | Iteration number: [3220/4518] 71% | Training loss: 0.686982214006578
Epoch: 90 | Iteration number: [3230/4518] 71% | Training loss: 0.6869791642246601
Epoch: 90 | Iteration number: [3240/4518] 71% | Training loss: 0.6869792967298884
Epoch: 90 | Iteration number: [3250/4518] 71% | Training loss: 0.6869760929437784
Epoch: 90 | Iteration number: [3260/4518] 72% | Training loss: 0.6869780163823461
Epoch: 90 | Iteration number: [3270/4518] 72% | Training loss: 0.6869767447677227
Epoch: 90 | Iteration number: [3280/4518] 72% | Training loss: 0.6869752981132123
Epoch: 90 | Iteration number: [3290/4518] 72% | Training loss: 0.686976081930033
Epoch: 90 | Iteration number: [3300/4518] 73% | Training loss: 0.6869750107057166
Epoch: 90 | Iteration number: [3310/4518] 73% | Training loss: 0.6869714616468666
Epoch: 90 | Iteration number: [3320/4518] 73% | Training loss: 0.6869704452982868
Epoch: 90 | Iteration number: [3330/4518] 73% | Training loss: 0.6869676083236843
Epoch: 90 | Iteration number: [3340/4518] 73% | Training loss: 0.6869653232975634
Epoch: 90 | Iteration number: [3350/4518] 74% | Training loss: 0.6869619080201903
Epoch: 90 | Iteration number: [3360/4518] 74% | Training loss: 0.6869620889247883
Epoch: 90 | Iteration number: [3370/4518] 74% | Training loss: 0.6869590238399959
Epoch: 90 | Iteration number: [3380/4518] 74% | Training loss: 0.6869593263377805
Epoch: 90 | Iteration number: [3390/4518] 75% | Training loss: 0.6869604805753646
Epoch: 90 | Iteration number: [3400/4518] 75% | Training loss: 0.6869599133379319
Epoch: 90 | Iteration number: [3410/4518] 75% | Training loss: 0.6869570267340305
Epoch: 90 | Iteration number: [3420/4518] 75% | Training loss: 0.6869587652515947
Epoch: 90 | Iteration number: [3430/4518] 75% | Training loss: 0.686954189910833
Epoch: 90 | Iteration number: [3440/4518] 76% | Training loss: 0.6869546448941841
Epoch: 90 | Iteration number: [3450/4518] 76% | Training loss: 0.686953258825385
Epoch: 90 | Iteration number: [3460/4518] 76% | Training loss: 0.6869505300170424
Epoch: 90 | Iteration number: [3470/4518] 76% | Training loss: 0.6869532635129494
Epoch: 90 | Iteration number: [3480/4518] 77% | Training loss: 0.6869550906892481
Epoch: 90 | Iteration number: [3490/4518] 77% | Training loss: 0.6869569803889638
Epoch: 90 | Iteration number: [3500/4518] 77% | Training loss: 0.686955121074404
Epoch: 90 | Iteration number: [3510/4518] 77% | Training loss: 0.6869527764809438
Epoch: 90 | Iteration number: [3520/4518] 77% | Training loss: 0.6869495546953245
Epoch: 90 | Iteration number: [3530/4518] 78% | Training loss: 0.6869506486414512
Epoch: 90 | Iteration number: [3540/4518] 78% | Training loss: 0.6869491869446922
Epoch: 90 | Iteration number: [3550/4518] 78% | Training loss: 0.6869455141752538
Epoch: 90 | Iteration number: [3560/4518] 78% | Training loss: 0.6869442001654861
Epoch: 90 | Iteration number: [3570/4518] 79% | Training loss: 0.686943066737899
Epoch: 90 | Iteration number: [3580/4518] 79% | Training loss: 0.6869413675209664
Epoch: 90 | Iteration number: [3590/4518] 79% | Training loss: 0.686938935900133
Epoch: 90 | Iteration number: [3600/4518] 79% | Training loss: 0.6869407817886936
Epoch: 90 | Iteration number: [3610/4518] 79% | Training loss: 0.6869411770821938
Epoch: 90 | Iteration number: [3620/4518] 80% | Training loss: 0.6869385239333737
Epoch: 90 | Iteration number: [3630/4518] 80% | Training loss: 0.6869371411393168
Epoch: 90 | Iteration number: [3640/4518] 80% | Training loss: 0.6869374482841282
Epoch: 90 | Iteration number: [3650/4518] 80% | Training loss: 0.6869378409320361
Epoch: 90 | Iteration number: [3660/4518] 81% | Training loss: 0.6869343081132961
Epoch: 90 | Iteration number: [3670/4518] 81% | Training loss: 0.6869340221303685
Epoch: 90 | Iteration number: [3680/4518] 81% | Training loss: 0.6869340552583985
Epoch: 90 | Iteration number: [3690/4518] 81% | Training loss: 0.6869262323954564
Epoch: 90 | Iteration number: [3700/4518] 81% | Training loss: 0.6869261752270364
Epoch: 90 | Iteration number: [3710/4518] 82% | Training loss: 0.6869282282266334
Epoch: 90 | Iteration number: [3720/4518] 82% | Training loss: 0.6869261037438147
Epoch: 90 | Iteration number: [3730/4518] 82% | Training loss: 0.686928993719193
Epoch: 90 | Iteration number: [3740/4518] 82% | Training loss: 0.6869266233501587
Epoch: 90 | Iteration number: [3750/4518] 83% | Training loss: 0.6869260246594747
Epoch: 90 | Iteration number: [3760/4518] 83% | Training loss: 0.6869242663396166
Epoch: 90 | Iteration number: [3770/4518] 83% | Training loss: 0.6869224615217204
Epoch: 90 | Iteration number: [3780/4518] 83% | Training loss: 0.6869205141982073
Epoch: 90 | Iteration number: [3790/4518] 83% | Training loss: 0.6869198938158383
Epoch: 90 | Iteration number: [3800/4518] 84% | Training loss: 0.6869210651516915
Epoch: 90 | Iteration number: [3810/4518] 84% | Training loss: 0.6869186294360423
Epoch: 90 | Iteration number: [3820/4518] 84% | Training loss: 0.6869178256595322
Epoch: 90 | Iteration number: [3830/4518] 84% | Training loss: 0.6869198632613797
Epoch: 90 | Iteration number: [3840/4518] 84% | Training loss: 0.6869212160197397
Epoch: 90 | Iteration number: [3850/4518] 85% | Training loss: 0.6869199779591003
Epoch: 90 | Iteration number: [3860/4518] 85% | Training loss: 0.6869165045146497
Epoch: 90 | Iteration number: [3870/4518] 85% | Training loss: 0.6869155545105305
Epoch: 90 | Iteration number: [3880/4518] 85% | Training loss: 0.6869187277309673
Epoch: 90 | Iteration number: [3890/4518] 86% | Training loss: 0.6869167021123793
Epoch: 90 | Iteration number: [3900/4518] 86% | Training loss: 0.686919980721596
Epoch: 90 | Iteration number: [3910/4518] 86% | Training loss: 0.686917408302312
Epoch: 90 | Iteration number: [3920/4518] 86% | Training loss: 0.686921331894641
Epoch: 90 | Iteration number: [3930/4518] 86% | Training loss: 0.6869222893818038
Epoch: 90 | Iteration number: [3940/4518] 87% | Training loss: 0.686924483464454
Epoch: 90 | Iteration number: [3950/4518] 87% | Training loss: 0.6869269384915315
Epoch: 90 | Iteration number: [3960/4518] 87% | Training loss: 0.6869276824774164
Epoch: 90 | Iteration number: [3970/4518] 87% | Training loss: 0.6869294280369276
Epoch: 90 | Iteration number: [3980/4518] 88% | Training loss: 0.6869315610459102
Epoch: 90 | Iteration number: [3990/4518] 88% | Training loss: 0.6869328844517395
Epoch: 90 | Iteration number: [4000/4518] 88% | Training loss: 0.6869337261170149
Epoch: 90 | Iteration number: [4010/4518] 88% | Training loss: 0.686935593436781
Epoch: 90 | Iteration number: [4020/4518] 88% | Training loss: 0.6869322157617825
Epoch: 90 | Iteration number: [4030/4518] 89% | Training loss: 0.6869323639360906
Epoch: 90 | Iteration number: [4040/4518] 89% | Training loss: 0.6869356984696766
Epoch: 90 | Iteration number: [4050/4518] 89% | Training loss: 0.6869375413435477
Epoch: 90 | Iteration number: [4060/4518] 89% | Training loss: 0.6869387688601546
Epoch: 90 | Iteration number: [4070/4518] 90% | Training loss: 0.6869426967910233
Epoch: 90 | Iteration number: [4080/4518] 90% | Training loss: 0.6869403300332088
Epoch: 90 | Iteration number: [4090/4518] 90% | Training loss: 0.6869372656409489
Epoch: 90 | Iteration number: [4100/4518] 90% | Training loss: 0.6869384652812306
Epoch: 90 | Iteration number: [4110/4518] 90% | Training loss: 0.6869394402289333
Epoch: 90 | Iteration number: [4120/4518] 91% | Training loss: 0.6869418990843504
Epoch: 90 | Iteration number: [4130/4518] 91% | Training loss: 0.6869404513235531
Epoch: 90 | Iteration number: [4140/4518] 91% | Training loss: 0.6869362037970824
Epoch: 90 | Iteration number: [4150/4518] 91% | Training loss: 0.6869344986203205
Epoch: 90 | Iteration number: [4160/4518] 92% | Training loss: 0.6869355871413763
Epoch: 90 | Iteration number: [4170/4518] 92% | Training loss: 0.6869335753883389
Epoch: 90 | Iteration number: [4180/4518] 92% | Training loss: 0.686932590061968
Epoch: 90 | Iteration number: [4190/4518] 92% | Training loss: 0.6869312599336902
Epoch: 90 | Iteration number: [4200/4518] 92% | Training loss: 0.6869277389702343
Epoch: 90 | Iteration number: [4210/4518] 93% | Training loss: 0.6869281046747312
Epoch: 90 | Iteration number: [4220/4518] 93% | Training loss: 0.6869278836589289
Epoch: 90 | Iteration number: [4230/4518] 93% | Training loss: 0.6869274168854346
Epoch: 90 | Iteration number: [4240/4518] 93% | Training loss: 0.6869261294181617
Epoch: 90 | Iteration number: [4250/4518] 94% | Training loss: 0.6869247189970578
Epoch: 90 | Iteration number: [4260/4518] 94% | Training loss: 0.6869245642647497
Epoch: 90 | Iteration number: [4270/4518] 94% | Training loss: 0.6869243604796273
Epoch: 90 | Iteration number: [4280/4518] 94% | Training loss: 0.6869250310497863
Epoch: 90 | Iteration number: [4290/4518] 94% | Training loss: 0.6869247290499004
Epoch: 90 | Iteration number: [4300/4518] 95% | Training loss: 0.6869252739950668
Epoch: 90 | Iteration number: [4310/4518] 95% | Training loss: 0.6869259605413247
Epoch: 90 | Iteration number: [4320/4518] 95% | Training loss: 0.6869243331115555
Epoch: 90 | Iteration number: [4330/4518] 95% | Training loss: 0.6869200939807275
Epoch: 90 | Iteration number: [4340/4518] 96% | Training loss: 0.6869193666541631
Epoch: 90 | Iteration number: [4350/4518] 96% | Training loss: 0.6869214549283872
Epoch: 90 | Iteration number: [4360/4518] 96% | Training loss: 0.6869223964323691
Epoch: 90 | Iteration number: [4370/4518] 96% | Training loss: 0.6869248218203573
Epoch: 90 | Iteration number: [4380/4518] 96% | Training loss: 0.6869254404007028
Epoch: 90 | Iteration number: [4390/4518] 97% | Training loss: 0.6869287377337931
Epoch: 90 | Iteration number: [4400/4518] 97% | Training loss: 0.6869259233501824
Epoch: 90 | Iteration number: [4410/4518] 97% | Training loss: 0.6869237723669498
Epoch: 90 | Iteration number: [4420/4518] 97% | Training loss: 0.6869238882582651
Epoch: 90 | Iteration number: [4430/4518] 98% | Training loss: 0.6869244150195111
Epoch: 90 | Iteration number: [4440/4518] 98% | Training loss: 0.6869238001537753
Epoch: 90 | Iteration number: [4450/4518] 98% | Training loss: 0.6869199297535286
Epoch: 90 | Iteration number: [4460/4518] 98% | Training loss: 0.6869153252631559
Epoch: 90 | Iteration number: [4470/4518] 98% | Training loss: 0.6869141718018509
Epoch: 90 | Iteration number: [4480/4518] 99% | Training loss: 0.6869111534474152
Epoch: 90 | Iteration number: [4490/4518] 99% | Training loss: 0.6869075889709532
Epoch: 90 | Iteration number: [4500/4518] 99% | Training loss: 0.6869032956096861
Epoch: 90 | Iteration number: [4510/4518] 99% | Training loss: 0.68690300507186

 End of epoch: 90 | Train Loss: 0.6867500391218608 | Training Time: 633 

 End of epoch: 90 | Eval Loss: 0.6895625700755995 | Evaluating Time: 17 
Epoch: 91 | Iteration number: [10/4518] 0% | Training loss: 0.7555489718914032
Epoch: 91 | Iteration number: [20/4518] 0% | Training loss: 0.7214576482772828
Epoch: 91 | Iteration number: [30/4518] 0% | Training loss: 0.7102022588253021
Epoch: 91 | Iteration number: [40/4518] 0% | Training loss: 0.7043429210782051
Epoch: 91 | Iteration number: [50/4518] 1% | Training loss: 0.7007421159744263
Epoch: 91 | Iteration number: [60/4518] 1% | Training loss: 0.6982154856125514
Epoch: 91 | Iteration number: [70/4518] 1% | Training loss: 0.6966447310788291
Epoch: 91 | Iteration number: [80/4518] 1% | Training loss: 0.6955717235803605
Epoch: 91 | Iteration number: [90/4518] 1% | Training loss: 0.694478405184216
Epoch: 91 | Iteration number: [100/4518] 2% | Training loss: 0.6935844928026199
Epoch: 91 | Iteration number: [110/4518] 2% | Training loss: 0.692928299036893
Epoch: 91 | Iteration number: [120/4518] 2% | Training loss: 0.6923520897825559
Epoch: 91 | Iteration number: [130/4518] 2% | Training loss: 0.691831519970527
Epoch: 91 | Iteration number: [140/4518] 3% | Training loss: 0.6914331210511071
Epoch: 91 | Iteration number: [150/4518] 3% | Training loss: 0.6911866978804271
Epoch: 91 | Iteration number: [160/4518] 3% | Training loss: 0.6909883569926023
Epoch: 91 | Iteration number: [170/4518] 3% | Training loss: 0.6906541095060461
Epoch: 91 | Iteration number: [180/4518] 3% | Training loss: 0.6904676089684169
Epoch: 91 | Iteration number: [190/4518] 4% | Training loss: 0.6902573155729395
Epoch: 91 | Iteration number: [200/4518] 4% | Training loss: 0.6901300784945488
Epoch: 91 | Iteration number: [210/4518] 4% | Training loss: 0.6900068952923729
Epoch: 91 | Iteration number: [220/4518] 4% | Training loss: 0.6898582323030992
Epoch: 91 | Iteration number: [230/4518] 5% | Training loss: 0.6897697054821512
Epoch: 91 | Iteration number: [240/4518] 5% | Training loss: 0.6896560788154602
Epoch: 91 | Iteration number: [250/4518] 5% | Training loss: 0.6895345902442932
Epoch: 91 | Iteration number: [260/4518] 5% | Training loss: 0.6894219405375994
Epoch: 91 | Iteration number: [270/4518] 5% | Training loss: 0.689248220788108
Epoch: 91 | Iteration number: [280/4518] 6% | Training loss: 0.6891690897090095
Epoch: 91 | Iteration number: [290/4518] 6% | Training loss: 0.6891088962554932
Epoch: 91 | Iteration number: [300/4518] 6% | Training loss: 0.6890224951505661
Epoch: 91 | Iteration number: [310/4518] 6% | Training loss: 0.6889402149185058
Epoch: 91 | Iteration number: [320/4518] 7% | Training loss: 0.6888955205678939
Epoch: 91 | Iteration number: [330/4518] 7% | Training loss: 0.6888305709217534
Epoch: 91 | Iteration number: [340/4518] 7% | Training loss: 0.6887734362307717
Epoch: 91 | Iteration number: [350/4518] 7% | Training loss: 0.6887058520317078
Epoch: 91 | Iteration number: [360/4518] 7% | Training loss: 0.6886658032735189
Epoch: 91 | Iteration number: [370/4518] 8% | Training loss: 0.6886149722176629
Epoch: 91 | Iteration number: [380/4518] 8% | Training loss: 0.688603244016045
Epoch: 91 | Iteration number: [390/4518] 8% | Training loss: 0.6885461688041687
Epoch: 91 | Iteration number: [400/4518] 8% | Training loss: 0.6885350751876831
Epoch: 91 | Iteration number: [410/4518] 9% | Training loss: 0.6884833548127152
Epoch: 91 | Iteration number: [420/4518] 9% | Training loss: 0.6884446761437825
Epoch: 91 | Iteration number: [430/4518] 9% | Training loss: 0.6884040709151779
Epoch: 91 | Iteration number: [440/4518] 9% | Training loss: 0.6883575344627554
Epoch: 91 | Iteration number: [450/4518] 9% | Training loss: 0.6883328615294563
Epoch: 91 | Iteration number: [460/4518] 10% | Training loss: 0.688312684841778
Epoch: 91 | Iteration number: [470/4518] 10% | Training loss: 0.6882524279837913
Epoch: 91 | Iteration number: [480/4518] 10% | Training loss: 0.688223147019744
Epoch: 91 | Iteration number: [490/4518] 10% | Training loss: 0.6882123534776726
Epoch: 91 | Iteration number: [500/4518] 11% | Training loss: 0.6881667159795761
Epoch: 91 | Iteration number: [510/4518] 11% | Training loss: 0.6881186209472956
Epoch: 91 | Iteration number: [520/4518] 11% | Training loss: 0.688080330307667
Epoch: 91 | Iteration number: [530/4518] 11% | Training loss: 0.6880356707662906
Epoch: 91 | Iteration number: [540/4518] 11% | Training loss: 0.6880022716742975
Epoch: 91 | Iteration number: [550/4518] 12% | Training loss: 0.6879717057401483
Epoch: 91 | Iteration number: [560/4518] 12% | Training loss: 0.6879425921610424
Epoch: 91 | Iteration number: [570/4518] 12% | Training loss: 0.6879324356714884
Epoch: 91 | Iteration number: [580/4518] 12% | Training loss: 0.6879203702869087
Epoch: 91 | Iteration number: [590/4518] 13% | Training loss: 0.6879011601714765
Epoch: 91 | Iteration number: [600/4518] 13% | Training loss: 0.6878878087798754
Epoch: 91 | Iteration number: [610/4518] 13% | Training loss: 0.6878378821201012
Epoch: 91 | Iteration number: [620/4518] 13% | Training loss: 0.6878374423711531
Epoch: 91 | Iteration number: [630/4518] 13% | Training loss: 0.6878268544636076
Epoch: 91 | Iteration number: [640/4518] 14% | Training loss: 0.6877927113324404
Epoch: 91 | Iteration number: [650/4518] 14% | Training loss: 0.6877962343509381
Epoch: 91 | Iteration number: [660/4518] 14% | Training loss: 0.6877922226082195
Epoch: 91 | Iteration number: [670/4518] 14% | Training loss: 0.6877909584721522
Epoch: 91 | Iteration number: [680/4518] 15% | Training loss: 0.6877451138461337
Epoch: 91 | Iteration number: [690/4518] 15% | Training loss: 0.687731378233951
Epoch: 91 | Iteration number: [700/4518] 15% | Training loss: 0.6877167848178318
Epoch: 91 | Iteration number: [710/4518] 15% | Training loss: 0.6876811717597532
Epoch: 91 | Iteration number: [720/4518] 15% | Training loss: 0.6876566855443849
Epoch: 91 | Iteration number: [730/4518] 16% | Training loss: 0.6876438351526653
Epoch: 91 | Iteration number: [740/4518] 16% | Training loss: 0.6876329508182165
Epoch: 91 | Iteration number: [750/4518] 16% | Training loss: 0.6876232625643413
Epoch: 91 | Iteration number: [760/4518] 16% | Training loss: 0.6875882085216672
Epoch: 91 | Iteration number: [770/4518] 17% | Training loss: 0.6875843590730196
Epoch: 91 | Iteration number: [780/4518] 17% | Training loss: 0.6875798622002969
Epoch: 91 | Iteration number: [790/4518] 17% | Training loss: 0.6875742039348506
Epoch: 91 | Iteration number: [800/4518] 17% | Training loss: 0.6875644681602716
Epoch: 91 | Iteration number: [810/4518] 17% | Training loss: 0.6875712778097317
Epoch: 91 | Iteration number: [820/4518] 18% | Training loss: 0.6875680397196514
Epoch: 91 | Iteration number: [830/4518] 18% | Training loss: 0.6875604491635977
Epoch: 91 | Iteration number: [840/4518] 18% | Training loss: 0.6875776153944787
Epoch: 91 | Iteration number: [850/4518] 18% | Training loss: 0.6875686291386099
Epoch: 91 | Iteration number: [860/4518] 19% | Training loss: 0.6875555432813112
Epoch: 91 | Iteration number: [870/4518] 19% | Training loss: 0.6875584712658805
Epoch: 91 | Iteration number: [880/4518] 19% | Training loss: 0.6875381553714925
Epoch: 91 | Iteration number: [890/4518] 19% | Training loss: 0.6875100704391351
Epoch: 91 | Iteration number: [900/4518] 19% | Training loss: 0.6874954849481583
Epoch: 91 | Iteration number: [910/4518] 20% | Training loss: 0.6874763346635379
Epoch: 91 | Iteration number: [920/4518] 20% | Training loss: 0.6874692088883856
Epoch: 91 | Iteration number: [930/4518] 20% | Training loss: 0.6874677581812746
Epoch: 91 | Iteration number: [940/4518] 20% | Training loss: 0.6874755698315641
Epoch: 91 | Iteration number: [950/4518] 21% | Training loss: 0.6874504622660185
Epoch: 91 | Iteration number: [960/4518] 21% | Training loss: 0.6874516282230616
Epoch: 91 | Iteration number: [970/4518] 21% | Training loss: 0.6874346612040529
Epoch: 91 | Iteration number: [980/4518] 21% | Training loss: 0.6874267841480216
Epoch: 91 | Iteration number: [990/4518] 21% | Training loss: 0.6874253932875817
Epoch: 91 | Iteration number: [1000/4518] 22% | Training loss: 0.6874259114861488
Epoch: 91 | Iteration number: [1010/4518] 22% | Training loss: 0.6874176277382539
Epoch: 91 | Iteration number: [1020/4518] 22% | Training loss: 0.6874119000107635
Epoch: 91 | Iteration number: [1030/4518] 22% | Training loss: 0.6874164980592079
Epoch: 91 | Iteration number: [1040/4518] 23% | Training loss: 0.6874142706967317
Epoch: 91 | Iteration number: [1050/4518] 23% | Training loss: 0.6874091430505117
Epoch: 91 | Iteration number: [1060/4518] 23% | Training loss: 0.687414684273162
Epoch: 91 | Iteration number: [1070/4518] 23% | Training loss: 0.6874132186452919
Epoch: 91 | Iteration number: [1080/4518] 23% | Training loss: 0.6874190628528595
Epoch: 91 | Iteration number: [1090/4518] 24% | Training loss: 0.6874085688809736
Epoch: 91 | Iteration number: [1100/4518] 24% | Training loss: 0.6873891873793169
Epoch: 91 | Iteration number: [1110/4518] 24% | Training loss: 0.6873642690546877
Epoch: 91 | Iteration number: [1120/4518] 24% | Training loss: 0.687361577046769
Epoch: 91 | Iteration number: [1130/4518] 25% | Training loss: 0.6873523466882453
Epoch: 91 | Iteration number: [1140/4518] 25% | Training loss: 0.6873383946063226
Epoch: 91 | Iteration number: [1150/4518] 25% | Training loss: 0.6873322959049888
Epoch: 91 | Iteration number: [1160/4518] 25% | Training loss: 0.6873221008428212
Epoch: 91 | Iteration number: [1170/4518] 25% | Training loss: 0.6873151837760567
Epoch: 91 | Iteration number: [1180/4518] 26% | Training loss: 0.6872981119964082
Epoch: 91 | Iteration number: [1190/4518] 26% | Training loss: 0.6872922391951585
Epoch: 91 | Iteration number: [1200/4518] 26% | Training loss: 0.6872878620525201
Epoch: 91 | Iteration number: [1210/4518] 26% | Training loss: 0.6872901702715346
Epoch: 91 | Iteration number: [1220/4518] 27% | Training loss: 0.6872853036298127
Epoch: 91 | Iteration number: [1230/4518] 27% | Training loss: 0.6872815038130535
Epoch: 91 | Iteration number: [1240/4518] 27% | Training loss: 0.6872673345669623
Epoch: 91 | Iteration number: [1250/4518] 27% | Training loss: 0.6872646375656128
Epoch: 91 | Iteration number: [1260/4518] 27% | Training loss: 0.6872673218212431
Epoch: 91 | Iteration number: [1270/4518] 28% | Training loss: 0.6872580885887146
Epoch: 91 | Iteration number: [1280/4518] 28% | Training loss: 0.6872427608352154
Epoch: 91 | Iteration number: [1290/4518] 28% | Training loss: 0.6872457197470259
Epoch: 91 | Iteration number: [1300/4518] 28% | Training loss: 0.6872432640882639
Epoch: 91 | Iteration number: [1310/4518] 28% | Training loss: 0.6872331859956261
Epoch: 91 | Iteration number: [1320/4518] 29% | Training loss: 0.6872240325266664
Epoch: 91 | Iteration number: [1330/4518] 29% | Training loss: 0.6872151582760918
Epoch: 91 | Iteration number: [1340/4518] 29% | Training loss: 0.6872172360544774
Epoch: 91 | Iteration number: [1350/4518] 29% | Training loss: 0.6872125884780177
Epoch: 91 | Iteration number: [1360/4518] 30% | Training loss: 0.6872093571459545
Epoch: 91 | Iteration number: [1370/4518] 30% | Training loss: 0.6872052648641768
Epoch: 91 | Iteration number: [1380/4518] 30% | Training loss: 0.6871869973946308
Epoch: 91 | Iteration number: [1390/4518] 30% | Training loss: 0.6871944579717925
Epoch: 91 | Iteration number: [1400/4518] 30% | Training loss: 0.6872040860993521
Epoch: 91 | Iteration number: [1410/4518] 31% | Training loss: 0.6871877845720197
Epoch: 91 | Iteration number: [1420/4518] 31% | Training loss: 0.687186349277765
Epoch: 91 | Iteration number: [1430/4518] 31% | Training loss: 0.6871882337373454
Epoch: 91 | Iteration number: [1440/4518] 31% | Training loss: 0.6871885134528081
Epoch: 91 | Iteration number: [1450/4518] 32% | Training loss: 0.6871940558121122
Epoch: 91 | Iteration number: [1460/4518] 32% | Training loss: 0.6871894829485514
Epoch: 91 | Iteration number: [1470/4518] 32% | Training loss: 0.6871875772670824
Epoch: 91 | Iteration number: [1480/4518] 32% | Training loss: 0.6871799374754365
Epoch: 91 | Iteration number: [1490/4518] 32% | Training loss: 0.6871774977085574
Epoch: 91 | Iteration number: [1500/4518] 33% | Training loss: 0.6871774267355601
Epoch: 91 | Iteration number: [1510/4518] 33% | Training loss: 0.6871694761001511
Epoch: 91 | Iteration number: [1520/4518] 33% | Training loss: 0.6871670031625974
Epoch: 91 | Iteration number: [1530/4518] 33% | Training loss: 0.6871637402406705
Epoch: 91 | Iteration number: [1540/4518] 34% | Training loss: 0.6871553010367728
Epoch: 91 | Iteration number: [1550/4518] 34% | Training loss: 0.687149308689179
Epoch: 91 | Iteration number: [1560/4518] 34% | Training loss: 0.6871466358120625
Epoch: 91 | Iteration number: [1570/4518] 34% | Training loss: 0.6871567859391498
Epoch: 91 | Iteration number: [1580/4518] 34% | Training loss: 0.6871577656344522
Epoch: 91 | Iteration number: [1590/4518] 35% | Training loss: 0.6871535706070234
Epoch: 91 | Iteration number: [1600/4518] 35% | Training loss: 0.6871515424549579
Epoch: 91 | Iteration number: [1610/4518] 35% | Training loss: 0.6871486079618797
Epoch: 91 | Iteration number: [1620/4518] 35% | Training loss: 0.6871376124061184
Epoch: 91 | Iteration number: [1630/4518] 36% | Training loss: 0.6871370580298769
Epoch: 91 | Iteration number: [1640/4518] 36% | Training loss: 0.6871322503177131
Epoch: 91 | Iteration number: [1650/4518] 36% | Training loss: 0.6871325454206177
Epoch: 91 | Iteration number: [1660/4518] 36% | Training loss: 0.6871366299778582
Epoch: 91 | Iteration number: [1670/4518] 36% | Training loss: 0.6871302081082395
Epoch: 91 | Iteration number: [1680/4518] 37% | Training loss: 0.6871221517877919
Epoch: 91 | Iteration number: [1690/4518] 37% | Training loss: 0.6871163584424194
Epoch: 91 | Iteration number: [1700/4518] 37% | Training loss: 0.6871175221134634
Epoch: 91 | Iteration number: [1710/4518] 37% | Training loss: 0.6871166047994156
Epoch: 91 | Iteration number: [1720/4518] 38% | Training loss: 0.6871112498779629
Epoch: 91 | Iteration number: [1730/4518] 38% | Training loss: 0.6870984050235307
Epoch: 91 | Iteration number: [1740/4518] 38% | Training loss: 0.6870934089367418
Epoch: 91 | Iteration number: [1750/4518] 38% | Training loss: 0.687095769575664
Epoch: 91 | Iteration number: [1760/4518] 38% | Training loss: 0.6871000593020158
Epoch: 91 | Iteration number: [1770/4518] 39% | Training loss: 0.6870963676164379
Epoch: 91 | Iteration number: [1780/4518] 39% | Training loss: 0.6870984735783566
Epoch: 91 | Iteration number: [1790/4518] 39% | Training loss: 0.6870997188810529
Epoch: 91 | Iteration number: [1800/4518] 39% | Training loss: 0.687095207174619
Epoch: 91 | Iteration number: [1810/4518] 40% | Training loss: 0.6870947502594626
Epoch: 91 | Iteration number: [1820/4518] 40% | Training loss: 0.6870909529072898
Epoch: 91 | Iteration number: [1830/4518] 40% | Training loss: 0.6870943711429346
Epoch: 91 | Iteration number: [1840/4518] 40% | Training loss: 0.6870870795586835
Epoch: 91 | Iteration number: [1850/4518] 40% | Training loss: 0.6870874999020551
Epoch: 91 | Iteration number: [1860/4518] 41% | Training loss: 0.6870816438108363
Epoch: 91 | Iteration number: [1870/4518] 41% | Training loss: 0.687075865428078
Epoch: 91 | Iteration number: [1880/4518] 41% | Training loss: 0.6870808656862442
Epoch: 91 | Iteration number: [1890/4518] 41% | Training loss: 0.6870787901853127
Epoch: 91 | Iteration number: [1900/4518] 42% | Training loss: 0.687072669361767
Epoch: 91 | Iteration number: [1910/4518] 42% | Training loss: 0.6870759327374204
Epoch: 91 | Iteration number: [1920/4518] 42% | Training loss: 0.6870822788526615
Epoch: 91 | Iteration number: [1930/4518] 42% | Training loss: 0.6870781649579656
Epoch: 91 | Iteration number: [1940/4518] 42% | Training loss: 0.6870745581142681
Epoch: 91 | Iteration number: [1950/4518] 43% | Training loss: 0.6870665329847581
Epoch: 91 | Iteration number: [1960/4518] 43% | Training loss: 0.6870628532098264
Epoch: 91 | Iteration number: [1970/4518] 43% | Training loss: 0.6870532485736808
Epoch: 91 | Iteration number: [1980/4518] 43% | Training loss: 0.6870502162762363
Epoch: 91 | Iteration number: [1990/4518] 44% | Training loss: 0.6870428215618709
Epoch: 91 | Iteration number: [2000/4518] 44% | Training loss: 0.6870370685458184
Epoch: 91 | Iteration number: [2010/4518] 44% | Training loss: 0.6870298360117633
Epoch: 91 | Iteration number: [2020/4518] 44% | Training loss: 0.6870313236618987
Epoch: 91 | Iteration number: [2030/4518] 44% | Training loss: 0.6870271263157793
Epoch: 91 | Iteration number: [2040/4518] 45% | Training loss: 0.6870266842199307
Epoch: 91 | Iteration number: [2050/4518] 45% | Training loss: 0.6870189565856283
Epoch: 91 | Iteration number: [2060/4518] 45% | Training loss: 0.687018465648577
Epoch: 91 | Iteration number: [2070/4518] 45% | Training loss: 0.6870120134042657
Epoch: 91 | Iteration number: [2080/4518] 46% | Training loss: 0.6870111262855622
Epoch: 91 | Iteration number: [2090/4518] 46% | Training loss: 0.6870030762191024
Epoch: 91 | Iteration number: [2100/4518] 46% | Training loss: 0.6869947367622738
Epoch: 91 | Iteration number: [2110/4518] 46% | Training loss: 0.686990849977421
Epoch: 91 | Iteration number: [2120/4518] 46% | Training loss: 0.6869871166235996
Epoch: 91 | Iteration number: [2130/4518] 47% | Training loss: 0.6869809584998189
Epoch: 91 | Iteration number: [2140/4518] 47% | Training loss: 0.6869851744063546
Epoch: 91 | Iteration number: [2150/4518] 47% | Training loss: 0.6869879170905712
Epoch: 91 | Iteration number: [2160/4518] 47% | Training loss: 0.6869886667088226
Epoch: 91 | Iteration number: [2170/4518] 48% | Training loss: 0.6869942173430447
Epoch: 91 | Iteration number: [2180/4518] 48% | Training loss: 0.6869840845602369
Epoch: 91 | Iteration number: [2190/4518] 48% | Training loss: 0.6869761303679583
Epoch: 91 | Iteration number: [2200/4518] 48% | Training loss: 0.6869794119217179
Epoch: 91 | Iteration number: [2210/4518] 48% | Training loss: 0.6869812496377332
Epoch: 91 | Iteration number: [2220/4518] 49% | Training loss: 0.6869779744932244
Epoch: 91 | Iteration number: [2230/4518] 49% | Training loss: 0.6869864852171842
Epoch: 91 | Iteration number: [2240/4518] 49% | Training loss: 0.6869877344795636
Epoch: 91 | Iteration number: [2250/4518] 49% | Training loss: 0.6869866054322985
Epoch: 91 | Iteration number: [2260/4518] 50% | Training loss: 0.6869847575120166
Epoch: 91 | Iteration number: [2270/4518] 50% | Training loss: 0.6869848063863847
Epoch: 91 | Iteration number: [2280/4518] 50% | Training loss: 0.6869843133186039
Epoch: 91 | Iteration number: [2290/4518] 50% | Training loss: 0.6869855339870703
Epoch: 91 | Iteration number: [2300/4518] 50% | Training loss: 0.6869855870889581
Epoch: 91 | Iteration number: [2310/4518] 51% | Training loss: 0.6869877200106006
Epoch: 91 | Iteration number: [2320/4518] 51% | Training loss: 0.6869893144430785
Epoch: 91 | Iteration number: [2330/4518] 51% | Training loss: 0.6869901495174277
Epoch: 91 | Iteration number: [2340/4518] 51% | Training loss: 0.6869931646901318
Epoch: 91 | Iteration number: [2350/4518] 52% | Training loss: 0.6869905776673175
Epoch: 91 | Iteration number: [2360/4518] 52% | Training loss: 0.6869944532038802
Epoch: 91 | Iteration number: [2370/4518] 52% | Training loss: 0.6869907321054725
Epoch: 91 | Iteration number: [2380/4518] 52% | Training loss: 0.6869928365244585
Epoch: 91 | Iteration number: [2390/4518] 52% | Training loss: 0.6869860581773095
Epoch: 91 | Iteration number: [2400/4518] 53% | Training loss: 0.6869846733907858
Epoch: 91 | Iteration number: [2410/4518] 53% | Training loss: 0.6869848673027086
Epoch: 91 | Iteration number: [2420/4518] 53% | Training loss: 0.6869790704782344
Epoch: 91 | Iteration number: [2430/4518] 53% | Training loss: 0.6869829235744084
Epoch: 91 | Iteration number: [2440/4518] 54% | Training loss: 0.6869788084118092
Epoch: 91 | Iteration number: [2450/4518] 54% | Training loss: 0.6869737529024786
Epoch: 91 | Iteration number: [2460/4518] 54% | Training loss: 0.6869773725910885
Epoch: 91 | Iteration number: [2470/4518] 54% | Training loss: 0.6869815177280411
Epoch: 91 | Iteration number: [2480/4518] 54% | Training loss: 0.6869754845576902
Epoch: 91 | Iteration number: [2490/4518] 55% | Training loss: 0.6869724570507985
Epoch: 91 | Iteration number: [2500/4518] 55% | Training loss: 0.6869767315387726
Epoch: 91 | Iteration number: [2510/4518] 55% | Training loss: 0.6869798915319709
Epoch: 91 | Iteration number: [2520/4518] 55% | Training loss: 0.686978402520929
Epoch: 91 | Iteration number: [2530/4518] 55% | Training loss: 0.6869773878645992
Epoch: 91 | Iteration number: [2540/4518] 56% | Training loss: 0.6869726158502534
Epoch: 91 | Iteration number: [2550/4518] 56% | Training loss: 0.6869763374796101
Epoch: 91 | Iteration number: [2560/4518] 56% | Training loss: 0.6869736122433097
Epoch: 91 | Iteration number: [2570/4518] 56% | Training loss: 0.6869742116575575
Epoch: 91 | Iteration number: [2580/4518] 57% | Training loss: 0.6869734438814858
Epoch: 91 | Iteration number: [2590/4518] 57% | Training loss: 0.6869783672126564
Epoch: 91 | Iteration number: [2600/4518] 57% | Training loss: 0.6869799986481666
Epoch: 91 | Iteration number: [2610/4518] 57% | Training loss: 0.6869772815841367
Epoch: 91 | Iteration number: [2620/4518] 57% | Training loss: 0.6869744902576199
Epoch: 91 | Iteration number: [2630/4518] 58% | Training loss: 0.6869744388322866
Epoch: 91 | Iteration number: [2640/4518] 58% | Training loss: 0.6869733840452902
Epoch: 91 | Iteration number: [2650/4518] 58% | Training loss: 0.6869717897559112
Epoch: 91 | Iteration number: [2660/4518] 58% | Training loss: 0.6869655782566931
Epoch: 91 | Iteration number: [2670/4518] 59% | Training loss: 0.6869634075111217
Epoch: 91 | Iteration number: [2680/4518] 59% | Training loss: 0.6869636448239212
Epoch: 91 | Iteration number: [2690/4518] 59% | Training loss: 0.686960407327099
Epoch: 91 | Iteration number: [2700/4518] 59% | Training loss: 0.6869562191433377
Epoch: 91 | Iteration number: [2710/4518] 59% | Training loss: 0.686953892369112
Epoch: 91 | Iteration number: [2720/4518] 60% | Training loss: 0.6869514192509301
Epoch: 91 | Iteration number: [2730/4518] 60% | Training loss: 0.6869508796122484
Epoch: 91 | Iteration number: [2740/4518] 60% | Training loss: 0.6869501815660156
Epoch: 91 | Iteration number: [2750/4518] 60% | Training loss: 0.6869509985663674
Epoch: 91 | Iteration number: [2760/4518] 61% | Training loss: 0.6869562429578407
Epoch: 91 | Iteration number: [2770/4518] 61% | Training loss: 0.6869544325322451
Epoch: 91 | Iteration number: [2780/4518] 61% | Training loss: 0.6869536962869356
Epoch: 91 | Iteration number: [2790/4518] 61% | Training loss: 0.686950430776056
Epoch: 91 | Iteration number: [2800/4518] 61% | Training loss: 0.6869500697297709
Epoch: 91 | Iteration number: [2810/4518] 62% | Training loss: 0.6869517466351654
Epoch: 91 | Iteration number: [2820/4518] 62% | Training loss: 0.686947374690509
Epoch: 91 | Iteration number: [2830/4518] 62% | Training loss: 0.6869475027276434
Epoch: 91 | Iteration number: [2840/4518] 62% | Training loss: 0.6869520459796341
Epoch: 91 | Iteration number: [2850/4518] 63% | Training loss: 0.6869523301668334
Epoch: 91 | Iteration number: [2860/4518] 63% | Training loss: 0.6869517319269114
Epoch: 91 | Iteration number: [2870/4518] 63% | Training loss: 0.6869507030535242
Epoch: 91 | Iteration number: [2880/4518] 63% | Training loss: 0.6869514317769143
Epoch: 91 | Iteration number: [2890/4518] 63% | Training loss: 0.6869518595170809
Epoch: 91 | Iteration number: [2900/4518] 64% | Training loss: 0.6869472385891553
Epoch: 91 | Iteration number: [2910/4518] 64% | Training loss: 0.686945601181476
Epoch: 91 | Iteration number: [2920/4518] 64% | Training loss: 0.6869439757850072
Epoch: 91 | Iteration number: [2930/4518] 64% | Training loss: 0.6869453122794832
Epoch: 91 | Iteration number: [2940/4518] 65% | Training loss: 0.6869491283990898
Epoch: 91 | Iteration number: [2950/4518] 65% | Training loss: 0.6869489299644859
Epoch: 91 | Iteration number: [2960/4518] 65% | Training loss: 0.6869476667529828
Epoch: 91 | Iteration number: [2970/4518] 65% | Training loss: 0.6869457639026321
Epoch: 91 | Iteration number: [2980/4518] 65% | Training loss: 0.6869461940038925
Epoch: 91 | Iteration number: [2990/4518] 66% | Training loss: 0.6869433567476113
Epoch: 91 | Iteration number: [3000/4518] 66% | Training loss: 0.6869386365016301
Epoch: 91 | Iteration number: [3010/4518] 66% | Training loss: 0.6869398845390624
Epoch: 91 | Iteration number: [3020/4518] 66% | Training loss: 0.6869385626339755
Epoch: 91 | Iteration number: [3030/4518] 67% | Training loss: 0.6869390610814488
Epoch: 91 | Iteration number: [3040/4518] 67% | Training loss: 0.6869399679922744
Epoch: 91 | Iteration number: [3050/4518] 67% | Training loss: 0.6869396143663125
Epoch: 91 | Iteration number: [3060/4518] 67% | Training loss: 0.6869402285105263
Epoch: 91 | Iteration number: [3070/4518] 67% | Training loss: 0.6869418063070565
Epoch: 91 | Iteration number: [3080/4518] 68% | Training loss: 0.6869433171563334
Epoch: 91 | Iteration number: [3090/4518] 68% | Training loss: 0.6869473092957222
Epoch: 91 | Iteration number: [3100/4518] 68% | Training loss: 0.6869452869699847
Epoch: 91 | Iteration number: [3110/4518] 68% | Training loss: 0.686944927394965
Epoch: 91 | Iteration number: [3120/4518] 69% | Training loss: 0.6869439798860978
Epoch: 91 | Iteration number: [3130/4518] 69% | Training loss: 0.6869482203413503
Epoch: 91 | Iteration number: [3140/4518] 69% | Training loss: 0.6869472790865382
Epoch: 91 | Iteration number: [3150/4518] 69% | Training loss: 0.6869481155228994
Epoch: 91 | Iteration number: [3160/4518] 69% | Training loss: 0.6869452282786369
Epoch: 91 | Iteration number: [3170/4518] 70% | Training loss: 0.6869442973791237
Epoch: 91 | Iteration number: [3180/4518] 70% | Training loss: 0.686945818748864
Epoch: 91 | Iteration number: [3190/4518] 70% | Training loss: 0.6869488523858468
Epoch: 91 | Iteration number: [3200/4518] 70% | Training loss: 0.686947474181652
Epoch: 91 | Iteration number: [3210/4518] 71% | Training loss: 0.6869451993351042
Epoch: 91 | Iteration number: [3220/4518] 71% | Training loss: 0.6869431672444255
Epoch: 91 | Iteration number: [3230/4518] 71% | Training loss: 0.6869444546684761
Epoch: 91 | Iteration number: [3240/4518] 71% | Training loss: 0.6869424586494763
Epoch: 91 | Iteration number: [3250/4518] 71% | Training loss: 0.6869416042657999
Epoch: 91 | Iteration number: [3260/4518] 72% | Training loss: 0.6869397850672891
Epoch: 91 | Iteration number: [3270/4518] 72% | Training loss: 0.6869377397069144
Epoch: 91 | Iteration number: [3280/4518] 72% | Training loss: 0.6869383847568094
Epoch: 91 | Iteration number: [3290/4518] 72% | Training loss: 0.6869381344970599
Epoch: 91 | Iteration number: [3300/4518] 73% | Training loss: 0.6869382561878724
Epoch: 91 | Iteration number: [3310/4518] 73% | Training loss: 0.6869354304410179
Epoch: 91 | Iteration number: [3320/4518] 73% | Training loss: 0.6869367319237755
Epoch: 91 | Iteration number: [3330/4518] 73% | Training loss: 0.686934426185247
Epoch: 91 | Iteration number: [3340/4518] 73% | Training loss: 0.686930043540315
Epoch: 91 | Iteration number: [3350/4518] 74% | Training loss: 0.6869286185947817
Epoch: 91 | Iteration number: [3360/4518] 74% | Training loss: 0.686929066142156
Epoch: 91 | Iteration number: [3370/4518] 74% | Training loss: 0.6869286099244296
Epoch: 91 | Iteration number: [3380/4518] 74% | Training loss: 0.6869288689462391
Epoch: 91 | Iteration number: [3390/4518] 75% | Training loss: 0.6869263339007499
Epoch: 91 | Iteration number: [3400/4518] 75% | Training loss: 0.6869300278495339
Epoch: 91 | Iteration number: [3410/4518] 75% | Training loss: 0.6869315505726946
Epoch: 91 | Iteration number: [3420/4518] 75% | Training loss: 0.6869321044251235
Epoch: 91 | Iteration number: [3430/4518] 75% | Training loss: 0.6869355826092879
Epoch: 91 | Iteration number: [3440/4518] 76% | Training loss: 0.6869362680024879
Epoch: 91 | Iteration number: [3450/4518] 76% | Training loss: 0.6869363207575204
Epoch: 91 | Iteration number: [3460/4518] 76% | Training loss: 0.6869347448982944
Epoch: 91 | Iteration number: [3470/4518] 76% | Training loss: 0.6869356568161967
Epoch: 91 | Iteration number: [3480/4518] 77% | Training loss: 0.6869318187750619
Epoch: 91 | Iteration number: [3490/4518] 77% | Training loss: 0.6869303910814247
Epoch: 91 | Iteration number: [3500/4518] 77% | Training loss: 0.6869317000082561
Epoch: 91 | Iteration number: [3510/4518] 77% | Training loss: 0.6869310039570529
Epoch: 91 | Iteration number: [3520/4518] 77% | Training loss: 0.6869287233122371
Epoch: 91 | Iteration number: [3530/4518] 78% | Training loss: 0.6869278480412264
Epoch: 91 | Iteration number: [3540/4518] 78% | Training loss: 0.6869242247888597
Epoch: 91 | Iteration number: [3550/4518] 78% | Training loss: 0.6869246214376369
Epoch: 91 | Iteration number: [3560/4518] 78% | Training loss: 0.6869241053301297
Epoch: 91 | Iteration number: [3570/4518] 79% | Training loss: 0.6869246723104258
Epoch: 91 | Iteration number: [3580/4518] 79% | Training loss: 0.6869231743519533
Epoch: 91 | Iteration number: [3590/4518] 79% | Training loss: 0.6869237252596693
Epoch: 91 | Iteration number: [3600/4518] 79% | Training loss: 0.6869252858393722
Epoch: 91 | Iteration number: [3610/4518] 79% | Training loss: 0.6869246510587571
Epoch: 91 | Iteration number: [3620/4518] 80% | Training loss: 0.6869239940827723
Epoch: 91 | Iteration number: [3630/4518] 80% | Training loss: 0.6869209290371782
Epoch: 91 | Iteration number: [3640/4518] 80% | Training loss: 0.686920894747907
Epoch: 91 | Iteration number: [3650/4518] 80% | Training loss: 0.6869217128949623
Epoch: 91 | Iteration number: [3660/4518] 81% | Training loss: 0.68692090838659
Epoch: 91 | Iteration number: [3670/4518] 81% | Training loss: 0.6869214890763286
Epoch: 91 | Iteration number: [3680/4518] 81% | Training loss: 0.6869212380893852
Epoch: 91 | Iteration number: [3690/4518] 81% | Training loss: 0.6869228627462051
Epoch: 91 | Iteration number: [3700/4518] 81% | Training loss: 0.6869202003930066
Epoch: 91 | Iteration number: [3710/4518] 82% | Training loss: 0.6869157997263731
Epoch: 91 | Iteration number: [3720/4518] 82% | Training loss: 0.6869161116500054
Epoch: 91 | Iteration number: [3730/4518] 82% | Training loss: 0.6869176056046269
Epoch: 91 | Iteration number: [3740/4518] 82% | Training loss: 0.6869206039822675
Epoch: 91 | Iteration number: [3750/4518] 83% | Training loss: 0.6869217700481415
Epoch: 91 | Iteration number: [3760/4518] 83% | Training loss: 0.6869206707211251
Epoch: 91 | Iteration number: [3770/4518] 83% | Training loss: 0.6869189906657849
Epoch: 91 | Iteration number: [3780/4518] 83% | Training loss: 0.6869193773421031
Epoch: 91 | Iteration number: [3790/4518] 83% | Training loss: 0.6869163646232485
Epoch: 91 | Iteration number: [3800/4518] 84% | Training loss: 0.6869162688286681
Epoch: 91 | Iteration number: [3810/4518] 84% | Training loss: 0.6869174317894332
Epoch: 91 | Iteration number: [3820/4518] 84% | Training loss: 0.6869179049711577
Epoch: 91 | Iteration number: [3830/4518] 84% | Training loss: 0.686917716653789
Epoch: 91 | Iteration number: [3840/4518] 84% | Training loss: 0.6869196061510593
Epoch: 91 | Iteration number: [3850/4518] 85% | Training loss: 0.6869208020668525
Epoch: 91 | Iteration number: [3860/4518] 85% | Training loss: 0.6869264905934507
Epoch: 91 | Iteration number: [3870/4518] 85% | Training loss: 0.6869289135902119
Epoch: 91 | Iteration number: [3880/4518] 85% | Training loss: 0.6869283034936668
Epoch: 91 | Iteration number: [3890/4518] 86% | Training loss: 0.6869263943485858
Epoch: 91 | Iteration number: [3900/4518] 86% | Training loss: 0.6869246836503347
Epoch: 91 | Iteration number: [3910/4518] 86% | Training loss: 0.6869258644483278
Epoch: 91 | Iteration number: [3920/4518] 86% | Training loss: 0.6869238602567692
Epoch: 91 | Iteration number: [3930/4518] 86% | Training loss: 0.6869235226064542
Epoch: 91 | Iteration number: [3940/4518] 87% | Training loss: 0.6869243790958134
Epoch: 91 | Iteration number: [3950/4518] 87% | Training loss: 0.6869231620619569
Epoch: 91 | Iteration number: [3960/4518] 87% | Training loss: 0.6869176291456126
Epoch: 91 | Iteration number: [3970/4518] 87% | Training loss: 0.6869155695816732
Epoch: 91 | Iteration number: [3980/4518] 88% | Training loss: 0.6869152665737286
Epoch: 91 | Iteration number: [3990/4518] 88% | Training loss: 0.6869161925369636
Epoch: 91 | Iteration number: [4000/4518] 88% | Training loss: 0.6869155509471894
Epoch: 91 | Iteration number: [4010/4518] 88% | Training loss: 0.6869155996458192
Epoch: 91 | Iteration number: [4020/4518] 88% | Training loss: 0.6869140273451212
Epoch: 91 | Iteration number: [4030/4518] 89% | Training loss: 0.6869120369921843
Epoch: 91 | Iteration number: [4040/4518] 89% | Training loss: 0.68691354576904
Epoch: 91 | Iteration number: [4050/4518] 89% | Training loss: 0.6869099029199577
Epoch: 91 | Iteration number: [4060/4518] 89% | Training loss: 0.6869133287609505
Epoch: 91 | Iteration number: [4070/4518] 90% | Training loss: 0.6869100735287116
Epoch: 91 | Iteration number: [4080/4518] 90% | Training loss: 0.6869095318895929
Epoch: 91 | Iteration number: [4090/4518] 90% | Training loss: 0.6869083991843505
Epoch: 91 | Iteration number: [4100/4518] 90% | Training loss: 0.6869097062291168
Epoch: 91 | Iteration number: [4110/4518] 90% | Training loss: 0.6869097341586203
Epoch: 91 | Iteration number: [4120/4518] 91% | Training loss: 0.6869096229811317
Epoch: 91 | Iteration number: [4130/4518] 91% | Training loss: 0.6869095388249681
Epoch: 91 | Iteration number: [4140/4518] 91% | Training loss: 0.6869080276880863
Epoch: 91 | Iteration number: [4150/4518] 91% | Training loss: 0.6869065221964595
Epoch: 91 | Iteration number: [4160/4518] 92% | Training loss: 0.6869033685097328
Epoch: 91 | Iteration number: [4170/4518] 92% | Training loss: 0.6869049829258908
Epoch: 91 | Iteration number: [4180/4518] 92% | Training loss: 0.686902879485103
Epoch: 91 | Iteration number: [4190/4518] 92% | Training loss: 0.6869008825616222
Epoch: 91 | Iteration number: [4200/4518] 92% | Training loss: 0.6869019193592526
Epoch: 91 | Iteration number: [4210/4518] 93% | Training loss: 0.6869020272745373
Epoch: 91 | Iteration number: [4220/4518] 93% | Training loss: 0.6869037474783676
Epoch: 91 | Iteration number: [4230/4518] 93% | Training loss: 0.6869034753905402
Epoch: 91 | Iteration number: [4240/4518] 93% | Training loss: 0.6869039235390583
Epoch: 91 | Iteration number: [4250/4518] 94% | Training loss: 0.6869017267227173
Epoch: 91 | Iteration number: [4260/4518] 94% | Training loss: 0.6868998565724198
Epoch: 91 | Iteration number: [4270/4518] 94% | Training loss: 0.6869012376463665
Epoch: 91 | Iteration number: [4280/4518] 94% | Training loss: 0.6868995561917252
Epoch: 91 | Iteration number: [4290/4518] 94% | Training loss: 0.6869011883274381
Epoch: 91 | Iteration number: [4300/4518] 95% | Training loss: 0.6869011855402658
Epoch: 91 | Iteration number: [4310/4518] 95% | Training loss: 0.6869001832749617
Epoch: 91 | Iteration number: [4320/4518] 95% | Training loss: 0.6869026969428416
Epoch: 91 | Iteration number: [4330/4518] 95% | Training loss: 0.6869048485442066
Epoch: 91 | Iteration number: [4340/4518] 96% | Training loss: 0.6869044851048202
Epoch: 91 | Iteration number: [4350/4518] 96% | Training loss: 0.686902198353033
Epoch: 91 | Iteration number: [4360/4518] 96% | Training loss: 0.6869047806350463
Epoch: 91 | Iteration number: [4370/4518] 96% | Training loss: 0.6869068722703091
Epoch: 91 | Iteration number: [4380/4518] 96% | Training loss: 0.6869065308815813
Epoch: 91 | Iteration number: [4390/4518] 97% | Training loss: 0.6869060690690825
Epoch: 91 | Iteration number: [4400/4518] 97% | Training loss: 0.6869066806273026
Epoch: 91 | Iteration number: [4410/4518] 97% | Training loss: 0.6869100960879639
Epoch: 91 | Iteration number: [4420/4518] 97% | Training loss: 0.6869097152581581
Epoch: 91 | Iteration number: [4430/4518] 98% | Training loss: 0.686907445012043
Epoch: 91 | Iteration number: [4440/4518] 98% | Training loss: 0.6869061169189375
Epoch: 91 | Iteration number: [4450/4518] 98% | Training loss: 0.6869054460123684
Epoch: 91 | Iteration number: [4460/4518] 98% | Training loss: 0.686905676714508
Epoch: 91 | Iteration number: [4470/4518] 98% | Training loss: 0.6869059986182774
Epoch: 91 | Iteration number: [4480/4518] 99% | Training loss: 0.686907300326441
Epoch: 91 | Iteration number: [4490/4518] 99% | Training loss: 0.6869072457198842
Epoch: 91 | Iteration number: [4500/4518] 99% | Training loss: 0.6869097909927369
Epoch: 91 | Iteration number: [4510/4518] 99% | Training loss: 0.6869105171073567

 End of epoch: 91 | Train Loss: 0.686757010648925 | Training Time: 633 

 End of epoch: 91 | Eval Loss: 0.6895735543601367 | Evaluating Time: 17 
Epoch: 92 | Iteration number: [10/4518] 0% | Training loss: 0.7563486516475677
Epoch: 92 | Iteration number: [20/4518] 0% | Training loss: 0.7212980568408967
Epoch: 92 | Iteration number: [30/4518] 0% | Training loss: 0.7092444638411204
Epoch: 92 | Iteration number: [40/4518] 0% | Training loss: 0.7035015150904655
Epoch: 92 | Iteration number: [50/4518] 1% | Training loss: 0.7003262162208557
Epoch: 92 | Iteration number: [60/4518] 1% | Training loss: 0.6979381660620372
Epoch: 92 | Iteration number: [70/4518] 1% | Training loss: 0.6964976225580488
Epoch: 92 | Iteration number: [80/4518] 1% | Training loss: 0.6952716715633869
Epoch: 92 | Iteration number: [90/4518] 1% | Training loss: 0.6944874034987556
Epoch: 92 | Iteration number: [100/4518] 2% | Training loss: 0.69384889960289
Epoch: 92 | Iteration number: [110/4518] 2% | Training loss: 0.6931937737898393
Epoch: 92 | Iteration number: [120/4518] 2% | Training loss: 0.6926621754964193
Epoch: 92 | Iteration number: [130/4518] 2% | Training loss: 0.6921670400179349
Epoch: 92 | Iteration number: [140/4518] 3% | Training loss: 0.6918829679489136
Epoch: 92 | Iteration number: [150/4518] 3% | Training loss: 0.6915374636650086
Epoch: 92 | Iteration number: [160/4518] 3% | Training loss: 0.6912224512547255
Epoch: 92 | Iteration number: [170/4518] 3% | Training loss: 0.690910923130372
Epoch: 92 | Iteration number: [180/4518] 3% | Training loss: 0.6906954093111886
Epoch: 92 | Iteration number: [190/4518] 4% | Training loss: 0.690434824165545
Epoch: 92 | Iteration number: [200/4518] 4% | Training loss: 0.6902823376655579
Epoch: 92 | Iteration number: [210/4518] 4% | Training loss: 0.6901369052273887
Epoch: 92 | Iteration number: [220/4518] 4% | Training loss: 0.6900330714204095
Epoch: 92 | Iteration number: [230/4518] 5% | Training loss: 0.6899085980394613
Epoch: 92 | Iteration number: [240/4518] 5% | Training loss: 0.6897398131589095
Epoch: 92 | Iteration number: [250/4518] 5% | Training loss: 0.6896354901790619
Epoch: 92 | Iteration number: [260/4518] 5% | Training loss: 0.6895377528208952
Epoch: 92 | Iteration number: [270/4518] 5% | Training loss: 0.6894263914337865
Epoch: 92 | Iteration number: [280/4518] 6% | Training loss: 0.6892771163157054
Epoch: 92 | Iteration number: [290/4518] 6% | Training loss: 0.6891642720534884
Epoch: 92 | Iteration number: [300/4518] 6% | Training loss: 0.6890727637211481
Epoch: 92 | Iteration number: [310/4518] 6% | Training loss: 0.6889696972985422
Epoch: 92 | Iteration number: [320/4518] 7% | Training loss: 0.6889402495697141
Epoch: 92 | Iteration number: [330/4518] 7% | Training loss: 0.68886085116502
Epoch: 92 | Iteration number: [340/4518] 7% | Training loss: 0.6887841186102699
Epoch: 92 | Iteration number: [350/4518] 7% | Training loss: 0.6887123904909407
Epoch: 92 | Iteration number: [360/4518] 7% | Training loss: 0.6886579568187395
Epoch: 92 | Iteration number: [370/4518] 8% | Training loss: 0.6885849400146588
Epoch: 92 | Iteration number: [380/4518] 8% | Training loss: 0.688531504649865
Epoch: 92 | Iteration number: [390/4518] 8% | Training loss: 0.6884896816351475
Epoch: 92 | Iteration number: [400/4518] 8% | Training loss: 0.6884487833082676
Epoch: 92 | Iteration number: [410/4518] 9% | Training loss: 0.6884120561727664
Epoch: 92 | Iteration number: [420/4518] 9% | Training loss: 0.6883718274888538
Epoch: 92 | Iteration number: [430/4518] 9% | Training loss: 0.688346950397935
Epoch: 92 | Iteration number: [440/4518] 9% | Training loss: 0.6882994768294421
Epoch: 92 | Iteration number: [450/4518] 9% | Training loss: 0.6882674120532142
Epoch: 92 | Iteration number: [460/4518] 10% | Training loss: 0.6882253655920858
Epoch: 92 | Iteration number: [470/4518] 10% | Training loss: 0.6882024454309585
Epoch: 92 | Iteration number: [480/4518] 10% | Training loss: 0.6881722589333852
Epoch: 92 | Iteration number: [490/4518] 10% | Training loss: 0.6881643646833848
Epoch: 92 | Iteration number: [500/4518] 11% | Training loss: 0.6881497803926467
Epoch: 92 | Iteration number: [510/4518] 11% | Training loss: 0.6881408444806641
Epoch: 92 | Iteration number: [520/4518] 11% | Training loss: 0.688105701827086
Epoch: 92 | Iteration number: [530/4518] 11% | Training loss: 0.6880635399863405
Epoch: 92 | Iteration number: [540/4518] 11% | Training loss: 0.6880092489498633
Epoch: 92 | Iteration number: [550/4518] 12% | Training loss: 0.6879874244603243
Epoch: 92 | Iteration number: [560/4518] 12% | Training loss: 0.6879686152296407
Epoch: 92 | Iteration number: [570/4518] 12% | Training loss: 0.6879376011982299
Epoch: 92 | Iteration number: [580/4518] 12% | Training loss: 0.6879000815851936
Epoch: 92 | Iteration number: [590/4518] 13% | Training loss: 0.687869060140545
Epoch: 92 | Iteration number: [600/4518] 13% | Training loss: 0.6878350087006887
Epoch: 92 | Iteration number: [610/4518] 13% | Training loss: 0.6878233894950053
Epoch: 92 | Iteration number: [620/4518] 13% | Training loss: 0.6877827018499374
Epoch: 92 | Iteration number: [630/4518] 13% | Training loss: 0.6877355169682275
Epoch: 92 | Iteration number: [640/4518] 14% | Training loss: 0.6877092096023262
Epoch: 92 | Iteration number: [650/4518] 14% | Training loss: 0.6876875647214743
Epoch: 92 | Iteration number: [660/4518] 14% | Training loss: 0.6876823369300726
Epoch: 92 | Iteration number: [670/4518] 14% | Training loss: 0.6876817752176256
Epoch: 92 | Iteration number: [680/4518] 15% | Training loss: 0.687651748867596
Epoch: 92 | Iteration number: [690/4518] 15% | Training loss: 0.6876339084860207
Epoch: 92 | Iteration number: [700/4518] 15% | Training loss: 0.6876124951669148
Epoch: 92 | Iteration number: [710/4518] 15% | Training loss: 0.6875874360682259
Epoch: 92 | Iteration number: [720/4518] 15% | Training loss: 0.6875813527239694
Epoch: 92 | Iteration number: [730/4518] 16% | Training loss: 0.6875768801120863
Epoch: 92 | Iteration number: [740/4518] 16% | Training loss: 0.6875733920851269
Epoch: 92 | Iteration number: [750/4518] 16% | Training loss: 0.6875704119205475
Epoch: 92 | Iteration number: [760/4518] 16% | Training loss: 0.6875620880409291
Epoch: 92 | Iteration number: [770/4518] 17% | Training loss: 0.6875465038534883
Epoch: 92 | Iteration number: [780/4518] 17% | Training loss: 0.6875325326736157
Epoch: 92 | Iteration number: [790/4518] 17% | Training loss: 0.6875191208682483
Epoch: 92 | Iteration number: [800/4518] 17% | Training loss: 0.6875017370283604
Epoch: 92 | Iteration number: [810/4518] 17% | Training loss: 0.6874772571487191
Epoch: 92 | Iteration number: [820/4518] 18% | Training loss: 0.6874706600497409
Epoch: 92 | Iteration number: [830/4518] 18% | Training loss: 0.6874674500471138
Epoch: 92 | Iteration number: [840/4518] 18% | Training loss: 0.6874570510217122
Epoch: 92 | Iteration number: [850/4518] 18% | Training loss: 0.6874558281197267
Epoch: 92 | Iteration number: [860/4518] 19% | Training loss: 0.6874634066986484
Epoch: 92 | Iteration number: [870/4518] 19% | Training loss: 0.6874516240481673
Epoch: 92 | Iteration number: [880/4518] 19% | Training loss: 0.6874409387734803
Epoch: 92 | Iteration number: [890/4518] 19% | Training loss: 0.6874263281232855
Epoch: 92 | Iteration number: [900/4518] 19% | Training loss: 0.6874086486630969
Epoch: 92 | Iteration number: [910/4518] 20% | Training loss: 0.6873975318866772
Epoch: 92 | Iteration number: [920/4518] 20% | Training loss: 0.6873907465649688
Epoch: 92 | Iteration number: [930/4518] 20% | Training loss: 0.6873883801762776
Epoch: 92 | Iteration number: [940/4518] 20% | Training loss: 0.6873913865774236
Epoch: 92 | Iteration number: [950/4518] 21% | Training loss: 0.6873752682459982
Epoch: 92 | Iteration number: [960/4518] 21% | Training loss: 0.6873738277703524
Epoch: 92 | Iteration number: [970/4518] 21% | Training loss: 0.6873690592873957
Epoch: 92 | Iteration number: [980/4518] 21% | Training loss: 0.687367899807132
Epoch: 92 | Iteration number: [990/4518] 21% | Training loss: 0.6873623935863226
Epoch: 92 | Iteration number: [1000/4518] 22% | Training loss: 0.6873523765802383
Epoch: 92 | Iteration number: [1010/4518] 22% | Training loss: 0.6873548288746636
Epoch: 92 | Iteration number: [1020/4518] 22% | Training loss: 0.6873454057118472
Epoch: 92 | Iteration number: [1030/4518] 22% | Training loss: 0.6873382728076676
Epoch: 92 | Iteration number: [1040/4518] 23% | Training loss: 0.6873207215506297
Epoch: 92 | Iteration number: [1050/4518] 23% | Training loss: 0.6873171746730804
Epoch: 92 | Iteration number: [1060/4518] 23% | Training loss: 0.687310627327775
Epoch: 92 | Iteration number: [1070/4518] 23% | Training loss: 0.687302541732788
Epoch: 92 | Iteration number: [1080/4518] 23% | Training loss: 0.6872978095655088
Epoch: 92 | Iteration number: [1090/4518] 24% | Training loss: 0.6872877513596771
Epoch: 92 | Iteration number: [1100/4518] 24% | Training loss: 0.6872746486555447
Epoch: 92 | Iteration number: [1110/4518] 24% | Training loss: 0.6872736188205513
Epoch: 92 | Iteration number: [1120/4518] 24% | Training loss: 0.687261201441288
Epoch: 92 | Iteration number: [1130/4518] 25% | Training loss: 0.6872681922089737
Epoch: 92 | Iteration number: [1140/4518] 25% | Training loss: 0.6872643438870447
Epoch: 92 | Iteration number: [1150/4518] 25% | Training loss: 0.6872728659277377
Epoch: 92 | Iteration number: [1160/4518] 25% | Training loss: 0.6872629957980123
Epoch: 92 | Iteration number: [1170/4518] 25% | Training loss: 0.6872571524901268
Epoch: 92 | Iteration number: [1180/4518] 26% | Training loss: 0.6872668658272695
Epoch: 92 | Iteration number: [1190/4518] 26% | Training loss: 0.6872546432398948
Epoch: 92 | Iteration number: [1200/4518] 26% | Training loss: 0.6872500916818778
Epoch: 92 | Iteration number: [1210/4518] 26% | Training loss: 0.6872516689714322
Epoch: 92 | Iteration number: [1220/4518] 27% | Training loss: 0.6872408107167385
Epoch: 92 | Iteration number: [1230/4518] 27% | Training loss: 0.6872325395180927
Epoch: 92 | Iteration number: [1240/4518] 27% | Training loss: 0.6872203588005035
Epoch: 92 | Iteration number: [1250/4518] 27% | Training loss: 0.6872214510440826
Epoch: 92 | Iteration number: [1260/4518] 27% | Training loss: 0.6872220621695594
Epoch: 92 | Iteration number: [1270/4518] 28% | Training loss: 0.6872216448539824
Epoch: 92 | Iteration number: [1280/4518] 28% | Training loss: 0.6872131711337716
Epoch: 92 | Iteration number: [1290/4518] 28% | Training loss: 0.6872116357319115
Epoch: 92 | Iteration number: [1300/4518] 28% | Training loss: 0.6872045690279741
Epoch: 92 | Iteration number: [1310/4518] 28% | Training loss: 0.6872061550162221
Epoch: 92 | Iteration number: [1320/4518] 29% | Training loss: 0.687209898549499
Epoch: 92 | Iteration number: [1330/4518] 29% | Training loss: 0.6872069344484717
Epoch: 92 | Iteration number: [1340/4518] 29% | Training loss: 0.6872030052231319
Epoch: 92 | Iteration number: [1350/4518] 29% | Training loss: 0.6872041449281905
Epoch: 92 | Iteration number: [1360/4518] 30% | Training loss: 0.6871980600935571
Epoch: 92 | Iteration number: [1370/4518] 30% | Training loss: 0.6871849344594635
Epoch: 92 | Iteration number: [1380/4518] 30% | Training loss: 0.6871890025726263
Epoch: 92 | Iteration number: [1390/4518] 30% | Training loss: 0.6871861216833266
Epoch: 92 | Iteration number: [1400/4518] 30% | Training loss: 0.6871823879224913
Epoch: 92 | Iteration number: [1410/4518] 31% | Training loss: 0.6871770240313618
Epoch: 92 | Iteration number: [1420/4518] 31% | Training loss: 0.6871761290959909
Epoch: 92 | Iteration number: [1430/4518] 31% | Training loss: 0.687165072497788
Epoch: 92 | Iteration number: [1440/4518] 31% | Training loss: 0.6871597111225128
Epoch: 92 | Iteration number: [1450/4518] 32% | Training loss: 0.6871569133627004
Epoch: 92 | Iteration number: [1460/4518] 32% | Training loss: 0.6871555356130208
Epoch: 92 | Iteration number: [1470/4518] 32% | Training loss: 0.68714220929308
Epoch: 92 | Iteration number: [1480/4518] 32% | Training loss: 0.6871472946292645
Epoch: 92 | Iteration number: [1490/4518] 32% | Training loss: 0.6871415079040015
Epoch: 92 | Iteration number: [1500/4518] 33% | Training loss: 0.6871385837395986
Epoch: 92 | Iteration number: [1510/4518] 33% | Training loss: 0.6871434816066793
Epoch: 92 | Iteration number: [1520/4518] 33% | Training loss: 0.6871474453101033
Epoch: 92 | Iteration number: [1530/4518] 33% | Training loss: 0.6871502766032624
Epoch: 92 | Iteration number: [1540/4518] 34% | Training loss: 0.6871430818136637
Epoch: 92 | Iteration number: [1550/4518] 34% | Training loss: 0.6871398442791354
Epoch: 92 | Iteration number: [1560/4518] 34% | Training loss: 0.6871392997029501
Epoch: 92 | Iteration number: [1570/4518] 34% | Training loss: 0.6871296032978471
Epoch: 92 | Iteration number: [1580/4518] 34% | Training loss: 0.6871226247730134
Epoch: 92 | Iteration number: [1590/4518] 35% | Training loss: 0.6871198248938195
Epoch: 92 | Iteration number: [1600/4518] 35% | Training loss: 0.687120941132307
Epoch: 92 | Iteration number: [1610/4518] 35% | Training loss: 0.6871261340120565
Epoch: 92 | Iteration number: [1620/4518] 35% | Training loss: 0.6871301131483949
Epoch: 92 | Iteration number: [1630/4518] 36% | Training loss: 0.687119843696524
Epoch: 92 | Iteration number: [1640/4518] 36% | Training loss: 0.6871162023849604
Epoch: 92 | Iteration number: [1650/4518] 36% | Training loss: 0.6871121214736592
Epoch: 92 | Iteration number: [1660/4518] 36% | Training loss: 0.6871046940605324
Epoch: 92 | Iteration number: [1670/4518] 36% | Training loss: 0.6871052303357039
Epoch: 92 | Iteration number: [1680/4518] 37% | Training loss: 0.6871036473839056
Epoch: 92 | Iteration number: [1690/4518] 37% | Training loss: 0.6871051341824278
Epoch: 92 | Iteration number: [1700/4518] 37% | Training loss: 0.6871009782833212
Epoch: 92 | Iteration number: [1710/4518] 37% | Training loss: 0.6870984439961394
Epoch: 92 | Iteration number: [1720/4518] 38% | Training loss: 0.687089838780636
Epoch: 92 | Iteration number: [1730/4518] 38% | Training loss: 0.6870949305206365
Epoch: 92 | Iteration number: [1740/4518] 38% | Training loss: 0.6870921183591602
Epoch: 92 | Iteration number: [1750/4518] 38% | Training loss: 0.6870930083819798
Epoch: 92 | Iteration number: [1760/4518] 38% | Training loss: 0.6870898089625619
Epoch: 92 | Iteration number: [1770/4518] 39% | Training loss: 0.6870903327976916
Epoch: 92 | Iteration number: [1780/4518] 39% | Training loss: 0.6870916319362234
Epoch: 92 | Iteration number: [1790/4518] 39% | Training loss: 0.687095902219165
Epoch: 92 | Iteration number: [1800/4518] 39% | Training loss: 0.6870929894844691
Epoch: 92 | Iteration number: [1810/4518] 40% | Training loss: 0.6870816262058131
Epoch: 92 | Iteration number: [1820/4518] 40% | Training loss: 0.6870808319076077
Epoch: 92 | Iteration number: [1830/4518] 40% | Training loss: 0.6870802431810098
Epoch: 92 | Iteration number: [1840/4518] 40% | Training loss: 0.6870783915662247
Epoch: 92 | Iteration number: [1850/4518] 40% | Training loss: 0.6870745819968146
Epoch: 92 | Iteration number: [1860/4518] 41% | Training loss: 0.6870694451434638
Epoch: 92 | Iteration number: [1870/4518] 41% | Training loss: 0.6870713611975073
Epoch: 92 | Iteration number: [1880/4518] 41% | Training loss: 0.687070243282521
Epoch: 92 | Iteration number: [1890/4518] 41% | Training loss: 0.6870715310333898
Epoch: 92 | Iteration number: [1900/4518] 42% | Training loss: 0.6870674339721078
Epoch: 92 | Iteration number: [1910/4518] 42% | Training loss: 0.6870710552674938
Epoch: 92 | Iteration number: [1920/4518] 42% | Training loss: 0.6870786428141097
Epoch: 92 | Iteration number: [1930/4518] 42% | Training loss: 0.6870703303752168
Epoch: 92 | Iteration number: [1940/4518] 42% | Training loss: 0.6870751428849918
Epoch: 92 | Iteration number: [1950/4518] 43% | Training loss: 0.6870728707619203
Epoch: 92 | Iteration number: [1960/4518] 43% | Training loss: 0.6870766634539682
Epoch: 92 | Iteration number: [1970/4518] 43% | Training loss: 0.6870709545721257
Epoch: 92 | Iteration number: [1980/4518] 43% | Training loss: 0.6870678441994118
Epoch: 92 | Iteration number: [1990/4518] 44% | Training loss: 0.6870682878709917
Epoch: 92 | Iteration number: [2000/4518] 44% | Training loss: 0.6870678218305111
Epoch: 92 | Iteration number: [2010/4518] 44% | Training loss: 0.6870710360766643
Epoch: 92 | Iteration number: [2020/4518] 44% | Training loss: 0.6870696480911557
Epoch: 92 | Iteration number: [2030/4518] 44% | Training loss: 0.6870691524644204
Epoch: 92 | Iteration number: [2040/4518] 45% | Training loss: 0.6870754590513659
Epoch: 92 | Iteration number: [2050/4518] 45% | Training loss: 0.6870715141296386
Epoch: 92 | Iteration number: [2060/4518] 45% | Training loss: 0.6870715653722727
Epoch: 92 | Iteration number: [2070/4518] 45% | Training loss: 0.6870760944442472
Epoch: 92 | Iteration number: [2080/4518] 46% | Training loss: 0.6870729908920251
Epoch: 92 | Iteration number: [2090/4518] 46% | Training loss: 0.6870729751278909
Epoch: 92 | Iteration number: [2100/4518] 46% | Training loss: 0.6870778543892361
Epoch: 92 | Iteration number: [2110/4518] 46% | Training loss: 0.6870853250625574
Epoch: 92 | Iteration number: [2120/4518] 46% | Training loss: 0.6870842005003174
Epoch: 92 | Iteration number: [2130/4518] 47% | Training loss: 0.6870818254533508
Epoch: 92 | Iteration number: [2140/4518] 47% | Training loss: 0.687077403179953
Epoch: 92 | Iteration number: [2150/4518] 47% | Training loss: 0.6870801768746487
Epoch: 92 | Iteration number: [2160/4518] 47% | Training loss: 0.6870758112657953
Epoch: 92 | Iteration number: [2170/4518] 48% | Training loss: 0.6870747668402536
Epoch: 92 | Iteration number: [2180/4518] 48% | Training loss: 0.6870733456053865
Epoch: 92 | Iteration number: [2190/4518] 48% | Training loss: 0.6870663904163935
Epoch: 92 | Iteration number: [2200/4518] 48% | Training loss: 0.6870676750757477
Epoch: 92 | Iteration number: [2210/4518] 48% | Training loss: 0.6870658653354214
Epoch: 92 | Iteration number: [2220/4518] 49% | Training loss: 0.6870622303571787
Epoch: 92 | Iteration number: [2230/4518] 49% | Training loss: 0.6870579189783789
Epoch: 92 | Iteration number: [2240/4518] 49% | Training loss: 0.6870628732655729
Epoch: 92 | Iteration number: [2250/4518] 49% | Training loss: 0.6870606811841329
Epoch: 92 | Iteration number: [2260/4518] 50% | Training loss: 0.6870630471843534
Epoch: 92 | Iteration number: [2270/4518] 50% | Training loss: 0.6870645195377031
Epoch: 92 | Iteration number: [2280/4518] 50% | Training loss: 0.6870607232315499
Epoch: 92 | Iteration number: [2290/4518] 50% | Training loss: 0.6870574840812184
Epoch: 92 | Iteration number: [2300/4518] 50% | Training loss: 0.6870605807200723
Epoch: 92 | Iteration number: [2310/4518] 51% | Training loss: 0.6870623834205396
Epoch: 92 | Iteration number: [2320/4518] 51% | Training loss: 0.6870561230542331
Epoch: 92 | Iteration number: [2330/4518] 51% | Training loss: 0.687048576036748
Epoch: 92 | Iteration number: [2340/4518] 51% | Training loss: 0.6870479881254017
Epoch: 92 | Iteration number: [2350/4518] 52% | Training loss: 0.6870494237351925
Epoch: 92 | Iteration number: [2360/4518] 52% | Training loss: 0.6870511078228385
Epoch: 92 | Iteration number: [2370/4518] 52% | Training loss: 0.6870494606122689
Epoch: 92 | Iteration number: [2380/4518] 52% | Training loss: 0.6870478120421161
Epoch: 92 | Iteration number: [2390/4518] 52% | Training loss: 0.6870452099764197
Epoch: 92 | Iteration number: [2400/4518] 53% | Training loss: 0.6870367806156477
Epoch: 92 | Iteration number: [2410/4518] 53% | Training loss: 0.6870388886493272
Epoch: 92 | Iteration number: [2420/4518] 53% | Training loss: 0.6870365305626688
Epoch: 92 | Iteration number: [2430/4518] 53% | Training loss: 0.6870346151261664
Epoch: 92 | Iteration number: [2440/4518] 54% | Training loss: 0.6870246326092814
Epoch: 92 | Iteration number: [2450/4518] 54% | Training loss: 0.687025619088387
Epoch: 92 | Iteration number: [2460/4518] 54% | Training loss: 0.6870239413366085
Epoch: 92 | Iteration number: [2470/4518] 54% | Training loss: 0.6870217638218451
Epoch: 92 | Iteration number: [2480/4518] 54% | Training loss: 0.6870243625054436
Epoch: 92 | Iteration number: [2490/4518] 55% | Training loss: 0.6870246342865818
Epoch: 92 | Iteration number: [2500/4518] 55% | Training loss: 0.6870225165128708
Epoch: 92 | Iteration number: [2510/4518] 55% | Training loss: 0.6870237574634324
Epoch: 92 | Iteration number: [2520/4518] 55% | Training loss: 0.6870226208416242
Epoch: 92 | Iteration number: [2530/4518] 55% | Training loss: 0.6870170405024125
Epoch: 92 | Iteration number: [2540/4518] 56% | Training loss: 0.6870174804306406
Epoch: 92 | Iteration number: [2550/4518] 56% | Training loss: 0.6870147458478516
Epoch: 92 | Iteration number: [2560/4518] 56% | Training loss: 0.6870139884529636
Epoch: 92 | Iteration number: [2570/4518] 56% | Training loss: 0.6870096342572907
Epoch: 92 | Iteration number: [2580/4518] 57% | Training loss: 0.6870067594818366
Epoch: 92 | Iteration number: [2590/4518] 57% | Training loss: 0.6870046275462883
Epoch: 92 | Iteration number: [2600/4518] 57% | Training loss: 0.6870047998428345
Epoch: 92 | Iteration number: [2610/4518] 57% | Training loss: 0.6869990766048432
Epoch: 92 | Iteration number: [2620/4518] 57% | Training loss: 0.6869978286610305
Epoch: 92 | Iteration number: [2630/4518] 58% | Training loss: 0.6869989013717201
Epoch: 92 | Iteration number: [2640/4518] 58% | Training loss: 0.6869932776147669
Epoch: 92 | Iteration number: [2650/4518] 58% | Training loss: 0.68699360399876
Epoch: 92 | Iteration number: [2660/4518] 58% | Training loss: 0.6869933092504515
Epoch: 92 | Iteration number: [2670/4518] 59% | Training loss: 0.6869850255130382
Epoch: 92 | Iteration number: [2680/4518] 59% | Training loss: 0.686984471354022
Epoch: 92 | Iteration number: [2690/4518] 59% | Training loss: 0.6869861712021456
Epoch: 92 | Iteration number: [2700/4518] 59% | Training loss: 0.6869861326394258
Epoch: 92 | Iteration number: [2710/4518] 59% | Training loss: 0.6869853344570667
Epoch: 92 | Iteration number: [2720/4518] 60% | Training loss: 0.686980825991315
Epoch: 92 | Iteration number: [2730/4518] 60% | Training loss: 0.6869827033835889
Epoch: 92 | Iteration number: [2740/4518] 60% | Training loss: 0.6869827800641095
Epoch: 92 | Iteration number: [2750/4518] 60% | Training loss: 0.6869832018722187
Epoch: 92 | Iteration number: [2760/4518] 61% | Training loss: 0.6869806825250819
Epoch: 92 | Iteration number: [2770/4518] 61% | Training loss: 0.6869800450999815
Epoch: 92 | Iteration number: [2780/4518] 61% | Training loss: 0.6869863296798665
Epoch: 92 | Iteration number: [2790/4518] 61% | Training loss: 0.6869861516901242
Epoch: 92 | Iteration number: [2800/4518] 61% | Training loss: 0.6869863344090326
Epoch: 92 | Iteration number: [2810/4518] 62% | Training loss: 0.6869851048094522
Epoch: 92 | Iteration number: [2820/4518] 62% | Training loss: 0.6869819309483183
Epoch: 92 | Iteration number: [2830/4518] 62% | Training loss: 0.6869787281688448
Epoch: 92 | Iteration number: [2840/4518] 62% | Training loss: 0.6869801964768222
Epoch: 92 | Iteration number: [2850/4518] 63% | Training loss: 0.6869844288156743
Epoch: 92 | Iteration number: [2860/4518] 63% | Training loss: 0.6869812844724922
Epoch: 92 | Iteration number: [2870/4518] 63% | Training loss: 0.6869764021049393
Epoch: 92 | Iteration number: [2880/4518] 63% | Training loss: 0.6869767809286713
Epoch: 92 | Iteration number: [2890/4518] 63% | Training loss: 0.6869776923969955
Epoch: 92 | Iteration number: [2900/4518] 64% | Training loss: 0.686977716972088
Epoch: 92 | Iteration number: [2910/4518] 64% | Training loss: 0.6869750926379895
Epoch: 92 | Iteration number: [2920/4518] 64% | Training loss: 0.686976920925591
Epoch: 92 | Iteration number: [2930/4518] 64% | Training loss: 0.6869764619109574
Epoch: 92 | Iteration number: [2940/4518] 65% | Training loss: 0.686969304530799
Epoch: 92 | Iteration number: [2950/4518] 65% | Training loss: 0.6869687554997913
Epoch: 92 | Iteration number: [2960/4518] 65% | Training loss: 0.686968113240358
Epoch: 92 | Iteration number: [2970/4518] 65% | Training loss: 0.6869653730480759
Epoch: 92 | Iteration number: [2980/4518] 65% | Training loss: 0.6869626358451459
Epoch: 92 | Iteration number: [2990/4518] 66% | Training loss: 0.6869627256855917
Epoch: 92 | Iteration number: [3000/4518] 66% | Training loss: 0.6869608450333278
Epoch: 92 | Iteration number: [3010/4518] 66% | Training loss: 0.6869636980204091
Epoch: 92 | Iteration number: [3020/4518] 66% | Training loss: 0.6869591630057783
Epoch: 92 | Iteration number: [3030/4518] 67% | Training loss: 0.6869587967498074
Epoch: 92 | Iteration number: [3040/4518] 67% | Training loss: 0.6869577510184364
Epoch: 92 | Iteration number: [3050/4518] 67% | Training loss: 0.6869603088253834
Epoch: 92 | Iteration number: [3060/4518] 67% | Training loss: 0.6869571482823565
Epoch: 92 | Iteration number: [3070/4518] 67% | Training loss: 0.6869582171548849
Epoch: 92 | Iteration number: [3080/4518] 68% | Training loss: 0.6869576622526367
Epoch: 92 | Iteration number: [3090/4518] 68% | Training loss: 0.6869582582445978
Epoch: 92 | Iteration number: [3100/4518] 68% | Training loss: 0.6869577131925091
Epoch: 92 | Iteration number: [3110/4518] 68% | Training loss: 0.6869549339607214
Epoch: 92 | Iteration number: [3120/4518] 69% | Training loss: 0.6869538274904092
Epoch: 92 | Iteration number: [3130/4518] 69% | Training loss: 0.6869574412370262
Epoch: 92 | Iteration number: [3140/4518] 69% | Training loss: 0.68695959029304
Epoch: 92 | Iteration number: [3150/4518] 69% | Training loss: 0.6869610796655927
Epoch: 92 | Iteration number: [3160/4518] 69% | Training loss: 0.6869616435864304
Epoch: 92 | Iteration number: [3170/4518] 70% | Training loss: 0.6869590824334779
Epoch: 92 | Iteration number: [3180/4518] 70% | Training loss: 0.6869573542157059
Epoch: 92 | Iteration number: [3190/4518] 70% | Training loss: 0.6869570841983568
Epoch: 92 | Iteration number: [3200/4518] 70% | Training loss: 0.6869553596153856
Epoch: 92 | Iteration number: [3210/4518] 71% | Training loss: 0.6869599645568575
Epoch: 92 | Iteration number: [3220/4518] 71% | Training loss: 0.6869567901451396
Epoch: 92 | Iteration number: [3230/4518] 71% | Training loss: 0.686952349423624
Epoch: 92 | Iteration number: [3240/4518] 71% | Training loss: 0.6869521879487568
Epoch: 92 | Iteration number: [3250/4518] 71% | Training loss: 0.6869549674070798
Epoch: 92 | Iteration number: [3260/4518] 72% | Training loss: 0.6869536116627828
Epoch: 92 | Iteration number: [3270/4518] 72% | Training loss: 0.6869551864239054
Epoch: 92 | Iteration number: [3280/4518] 72% | Training loss: 0.6869528607442612
Epoch: 92 | Iteration number: [3290/4518] 72% | Training loss: 0.6869525051225644
Epoch: 92 | Iteration number: [3300/4518] 73% | Training loss: 0.6869544158379237
Epoch: 92 | Iteration number: [3310/4518] 73% | Training loss: 0.6869561954027216
Epoch: 92 | Iteration number: [3320/4518] 73% | Training loss: 0.6869594408805112
Epoch: 92 | Iteration number: [3330/4518] 73% | Training loss: 0.6869575301806132
Epoch: 92 | Iteration number: [3340/4518] 73% | Training loss: 0.6869581072451826
Epoch: 92 | Iteration number: [3350/4518] 74% | Training loss: 0.6869588167275955
Epoch: 92 | Iteration number: [3360/4518] 74% | Training loss: 0.6869595191485826
Epoch: 92 | Iteration number: [3370/4518] 74% | Training loss: 0.6869561325371796
Epoch: 92 | Iteration number: [3380/4518] 74% | Training loss: 0.6869550288781612
Epoch: 92 | Iteration number: [3390/4518] 75% | Training loss: 0.6869551586893807
Epoch: 92 | Iteration number: [3400/4518] 75% | Training loss: 0.6869505981487386
Epoch: 92 | Iteration number: [3410/4518] 75% | Training loss: 0.6869488308681421
Epoch: 92 | Iteration number: [3420/4518] 75% | Training loss: 0.6869476026610324
Epoch: 92 | Iteration number: [3430/4518] 75% | Training loss: 0.6869471665547818
Epoch: 92 | Iteration number: [3440/4518] 76% | Training loss: 0.6869453169232191
Epoch: 92 | Iteration number: [3450/4518] 76% | Training loss: 0.6869416216663692
Epoch: 92 | Iteration number: [3460/4518] 76% | Training loss: 0.6869409804227035
Epoch: 92 | Iteration number: [3470/4518] 76% | Training loss: 0.6869441420269288
Epoch: 92 | Iteration number: [3480/4518] 77% | Training loss: 0.6869406942492244
Epoch: 92 | Iteration number: [3490/4518] 77% | Training loss: 0.6869401846369222
Epoch: 92 | Iteration number: [3500/4518] 77% | Training loss: 0.6869372366326196
Epoch: 92 | Iteration number: [3510/4518] 77% | Training loss: 0.6869358648771574
Epoch: 92 | Iteration number: [3520/4518] 77% | Training loss: 0.6869328994981267
Epoch: 92 | Iteration number: [3530/4518] 78% | Training loss: 0.6869300515725998
Epoch: 92 | Iteration number: [3540/4518] 78% | Training loss: 0.6869287740712785
Epoch: 92 | Iteration number: [3550/4518] 78% | Training loss: 0.6869291144861301
Epoch: 92 | Iteration number: [3560/4518] 78% | Training loss: 0.6869292577665843
Epoch: 92 | Iteration number: [3570/4518] 79% | Training loss: 0.6869277142343067
Epoch: 92 | Iteration number: [3580/4518] 79% | Training loss: 0.6869299146383169
Epoch: 92 | Iteration number: [3590/4518] 79% | Training loss: 0.6869269919760712
Epoch: 92 | Iteration number: [3600/4518] 79% | Training loss: 0.6869267095128695
Epoch: 92 | Iteration number: [3610/4518] 79% | Training loss: 0.6869298235531329
Epoch: 92 | Iteration number: [3620/4518] 80% | Training loss: 0.6869318682844467
Epoch: 92 | Iteration number: [3630/4518] 80% | Training loss: 0.6869330707660392
Epoch: 92 | Iteration number: [3640/4518] 80% | Training loss: 0.6869326914404775
Epoch: 92 | Iteration number: [3650/4518] 80% | Training loss: 0.6869344905631183
Epoch: 92 | Iteration number: [3660/4518] 81% | Training loss: 0.6869349259984949
Epoch: 92 | Iteration number: [3670/4518] 81% | Training loss: 0.6869344405809605
Epoch: 92 | Iteration number: [3680/4518] 81% | Training loss: 0.6869367514939412
Epoch: 92 | Iteration number: [3690/4518] 81% | Training loss: 0.6869357800742152
Epoch: 92 | Iteration number: [3700/4518] 81% | Training loss: 0.6869376597855542
Epoch: 92 | Iteration number: [3710/4518] 82% | Training loss: 0.6869344908914797
Epoch: 92 | Iteration number: [3720/4518] 82% | Training loss: 0.6869321613382268
Epoch: 92 | Iteration number: [3730/4518] 82% | Training loss: 0.6869330124944528
Epoch: 92 | Iteration number: [3740/4518] 82% | Training loss: 0.6869317024627472
Epoch: 92 | Iteration number: [3750/4518] 83% | Training loss: 0.686931229464213
Epoch: 92 | Iteration number: [3760/4518] 83% | Training loss: 0.6869299308733737
Epoch: 92 | Iteration number: [3770/4518] 83% | Training loss: 0.6869291866489684
Epoch: 92 | Iteration number: [3780/4518] 83% | Training loss: 0.6869289879603361
Epoch: 92 | Iteration number: [3790/4518] 83% | Training loss: 0.6869315673933809
Epoch: 92 | Iteration number: [3800/4518] 84% | Training loss: 0.6869339563815218
Epoch: 92 | Iteration number: [3810/4518] 84% | Training loss: 0.68693536918933
Epoch: 92 | Iteration number: [3820/4518] 84% | Training loss: 0.6869289171945362
Epoch: 92 | Iteration number: [3830/4518] 84% | Training loss: 0.6869297485594339
Epoch: 92 | Iteration number: [3840/4518] 84% | Training loss: 0.6869330476193378
Epoch: 92 | Iteration number: [3850/4518] 85% | Training loss: 0.6869342582876032
Epoch: 92 | Iteration number: [3860/4518] 85% | Training loss: 0.6869372569526415
Epoch: 92 | Iteration number: [3870/4518] 85% | Training loss: 0.6869348724067057
Epoch: 92 | Iteration number: [3880/4518] 85% | Training loss: 0.6869330131976875
Epoch: 92 | Iteration number: [3890/4518] 86% | Training loss: 0.6869366081024504
Epoch: 92 | Iteration number: [3900/4518] 86% | Training loss: 0.6869368729377404
Epoch: 92 | Iteration number: [3910/4518] 86% | Training loss: 0.6869337682986199
Epoch: 92 | Iteration number: [3920/4518] 86% | Training loss: 0.6869368703237602
Epoch: 92 | Iteration number: [3930/4518] 86% | Training loss: 0.6869362957453303
Epoch: 92 | Iteration number: [3940/4518] 87% | Training loss: 0.686937594534782
Epoch: 92 | Iteration number: [3950/4518] 87% | Training loss: 0.6869343535205986
Epoch: 92 | Iteration number: [3960/4518] 87% | Training loss: 0.6869345254970319
Epoch: 92 | Iteration number: [3970/4518] 87% | Training loss: 0.6869360717177692
Epoch: 92 | Iteration number: [3980/4518] 88% | Training loss: 0.6869352655943913
Epoch: 92 | Iteration number: [3990/4518] 88% | Training loss: 0.6869367771728295
Epoch: 92 | Iteration number: [4000/4518] 88% | Training loss: 0.6869362279623746
Epoch: 92 | Iteration number: [4010/4518] 88% | Training loss: 0.6869332518066255
Epoch: 92 | Iteration number: [4020/4518] 88% | Training loss: 0.6869309366045899
Epoch: 92 | Iteration number: [4030/4518] 89% | Training loss: 0.6869332208526934
Epoch: 92 | Iteration number: [4040/4518] 89% | Training loss: 0.6869325482019103
Epoch: 92 | Iteration number: [4050/4518] 89% | Training loss: 0.6869332890598863
Epoch: 92 | Iteration number: [4060/4518] 89% | Training loss: 0.6869342042307548
Epoch: 92 | Iteration number: [4070/4518] 90% | Training loss: 0.686931441852443
Epoch: 92 | Iteration number: [4080/4518] 90% | Training loss: 0.6869287169008863
Epoch: 92 | Iteration number: [4090/4518] 90% | Training loss: 0.6869265531852368
Epoch: 92 | Iteration number: [4100/4518] 90% | Training loss: 0.6869263496195398
Epoch: 92 | Iteration number: [4110/4518] 90% | Training loss: 0.6869262215574873
Epoch: 92 | Iteration number: [4120/4518] 91% | Training loss: 0.6869250773226173
Epoch: 92 | Iteration number: [4130/4518] 91% | Training loss: 0.6869233898764372
Epoch: 92 | Iteration number: [4140/4518] 91% | Training loss: 0.6869219669973217
Epoch: 92 | Iteration number: [4150/4518] 91% | Training loss: 0.6869219696378134
Epoch: 92 | Iteration number: [4160/4518] 92% | Training loss: 0.6869211106202924
Epoch: 92 | Iteration number: [4170/4518] 92% | Training loss: 0.6869197929362885
Epoch: 92 | Iteration number: [4180/4518] 92% | Training loss: 0.6869192708337136
Epoch: 92 | Iteration number: [4190/4518] 92% | Training loss: 0.6869185668045126
Epoch: 92 | Iteration number: [4200/4518] 92% | Training loss: 0.6869210760508265
Epoch: 92 | Iteration number: [4210/4518] 93% | Training loss: 0.6869205163380313
Epoch: 92 | Iteration number: [4220/4518] 93% | Training loss: 0.6869153903276435
Epoch: 92 | Iteration number: [4230/4518] 93% | Training loss: 0.6869169080511053
Epoch: 92 | Iteration number: [4240/4518] 93% | Training loss: 0.6869147856842797
Epoch: 92 | Iteration number: [4250/4518] 94% | Training loss: 0.6869119067051831
Epoch: 92 | Iteration number: [4260/4518] 94% | Training loss: 0.6869113762473836
Epoch: 92 | Iteration number: [4270/4518] 94% | Training loss: 0.6869107789401427
Epoch: 92 | Iteration number: [4280/4518] 94% | Training loss: 0.6869116576893307
Epoch: 92 | Iteration number: [4290/4518] 94% | Training loss: 0.6869112739474068
Epoch: 92 | Iteration number: [4300/4518] 95% | Training loss: 0.6869102611791256
Epoch: 92 | Iteration number: [4310/4518] 95% | Training loss: 0.6869085572435242
Epoch: 92 | Iteration number: [4320/4518] 95% | Training loss: 0.6869083180609676
Epoch: 92 | Iteration number: [4330/4518] 95% | Training loss: 0.6869067528231315
Epoch: 92 | Iteration number: [4340/4518] 96% | Training loss: 0.6869036913330104
Epoch: 92 | Iteration number: [4350/4518] 96% | Training loss: 0.6869033495996191
Epoch: 92 | Iteration number: [4360/4518] 96% | Training loss: 0.6869014419546915
Epoch: 92 | Iteration number: [4370/4518] 96% | Training loss: 0.6868992134962802
Epoch: 92 | Iteration number: [4380/4518] 96% | Training loss: 0.6869001356161892
Epoch: 92 | Iteration number: [4390/4518] 97% | Training loss: 0.6869001978350663
Epoch: 92 | Iteration number: [4400/4518] 97% | Training loss: 0.6869021798534827
Epoch: 92 | Iteration number: [4410/4518] 97% | Training loss: 0.6869000039673716
Epoch: 92 | Iteration number: [4420/4518] 97% | Training loss: 0.686900051255032
Epoch: 92 | Iteration number: [4430/4518] 98% | Training loss: 0.6869002128293229
Epoch: 92 | Iteration number: [4440/4518] 98% | Training loss: 0.6869009003445908
Epoch: 92 | Iteration number: [4450/4518] 98% | Training loss: 0.6869019972876217
Epoch: 92 | Iteration number: [4460/4518] 98% | Training loss: 0.6869010037905432
Epoch: 92 | Iteration number: [4470/4518] 98% | Training loss: 0.6868983976259594
Epoch: 92 | Iteration number: [4480/4518] 99% | Training loss: 0.6869004985450634
Epoch: 92 | Iteration number: [4490/4518] 99% | Training loss: 0.6869003709546707
Epoch: 92 | Iteration number: [4500/4518] 99% | Training loss: 0.6868994515736898
Epoch: 92 | Iteration number: [4510/4518] 99% | Training loss: 0.686899108950156

 End of epoch: 92 | Train Loss: 0.686747319062973 | Training Time: 632 

 End of epoch: 92 | Eval Loss: 0.6895537412896449 | Evaluating Time: 17 
Epoch: 93 | Iteration number: [10/4518] 0% | Training loss: 0.753943943977356
Epoch: 93 | Iteration number: [20/4518] 0% | Training loss: 0.7203308314085006
Epoch: 93 | Iteration number: [30/4518] 0% | Training loss: 0.7091475268205006
Epoch: 93 | Iteration number: [40/4518] 0% | Training loss: 0.7033202975988389
Epoch: 93 | Iteration number: [50/4518] 1% | Training loss: 0.6999696230888367
Epoch: 93 | Iteration number: [60/4518] 1% | Training loss: 0.6975579510132471
Epoch: 93 | Iteration number: [70/4518] 1% | Training loss: 0.6959558955260685
Epoch: 93 | Iteration number: [80/4518] 1% | Training loss: 0.6947827979922294
Epoch: 93 | Iteration number: [90/4518] 1% | Training loss: 0.6938580347432031
Epoch: 93 | Iteration number: [100/4518] 2% | Training loss: 0.6932868123054504
Epoch: 93 | Iteration number: [110/4518] 2% | Training loss: 0.6926974600011652
Epoch: 93 | Iteration number: [120/4518] 2% | Training loss: 0.6922529394427935
Epoch: 93 | Iteration number: [130/4518] 2% | Training loss: 0.691829226567195
Epoch: 93 | Iteration number: [140/4518] 3% | Training loss: 0.691520157456398
Epoch: 93 | Iteration number: [150/4518] 3% | Training loss: 0.6911659733454386
Epoch: 93 | Iteration number: [160/4518] 3% | Training loss: 0.6909784514456987
Epoch: 93 | Iteration number: [170/4518] 3% | Training loss: 0.6907020947512459
Epoch: 93 | Iteration number: [180/4518] 3% | Training loss: 0.6904539661275015
Epoch: 93 | Iteration number: [190/4518] 4% | Training loss: 0.6902564685595663
Epoch: 93 | Iteration number: [200/4518] 4% | Training loss: 0.690037933588028
Epoch: 93 | Iteration number: [210/4518] 4% | Training loss: 0.6898102663812183
Epoch: 93 | Iteration number: [220/4518] 4% | Training loss: 0.6897197159853848
Epoch: 93 | Iteration number: [230/4518] 5% | Training loss: 0.6895851275195246
Epoch: 93 | Iteration number: [240/4518] 5% | Training loss: 0.6894119046628475
Epoch: 93 | Iteration number: [250/4518] 5% | Training loss: 0.6892834451198578
Epoch: 93 | Iteration number: [260/4518] 5% | Training loss: 0.6891896733870873
Epoch: 93 | Iteration number: [270/4518] 5% | Training loss: 0.6891278112376178
Epoch: 93 | Iteration number: [280/4518] 6% | Training loss: 0.6890755566103118
Epoch: 93 | Iteration number: [290/4518] 6% | Training loss: 0.6889535692231409
Epoch: 93 | Iteration number: [300/4518] 6% | Training loss: 0.6889127631982167
Epoch: 93 | Iteration number: [310/4518] 6% | Training loss: 0.6888417774631131
Epoch: 93 | Iteration number: [320/4518] 7% | Training loss: 0.6887945234775543
Epoch: 93 | Iteration number: [330/4518] 7% | Training loss: 0.6887442408186016
Epoch: 93 | Iteration number: [340/4518] 7% | Training loss: 0.6886666639762766
Epoch: 93 | Iteration number: [350/4518] 7% | Training loss: 0.6886075011321476
Epoch: 93 | Iteration number: [360/4518] 7% | Training loss: 0.6885757151577208
Epoch: 93 | Iteration number: [370/4518] 8% | Training loss: 0.6885197140075064
Epoch: 93 | Iteration number: [380/4518] 8% | Training loss: 0.6884639834102831
Epoch: 93 | Iteration number: [390/4518] 8% | Training loss: 0.6884178201357524
Epoch: 93 | Iteration number: [400/4518] 8% | Training loss: 0.688401134610176
Epoch: 93 | Iteration number: [410/4518] 9% | Training loss: 0.6883672869786983
Epoch: 93 | Iteration number: [420/4518] 9% | Training loss: 0.6883679046517327
Epoch: 93 | Iteration number: [430/4518] 9% | Training loss: 0.6883265485597211
Epoch: 93 | Iteration number: [440/4518] 9% | Training loss: 0.6882926625284281
Epoch: 93 | Iteration number: [450/4518] 9% | Training loss: 0.6882916348510318
Epoch: 93 | Iteration number: [460/4518] 10% | Training loss: 0.6882388932549435
Epoch: 93 | Iteration number: [470/4518] 10% | Training loss: 0.6882110758030668
Epoch: 93 | Iteration number: [480/4518] 10% | Training loss: 0.6882083810865879
Epoch: 93 | Iteration number: [490/4518] 10% | Training loss: 0.6881555103525824
Epoch: 93 | Iteration number: [500/4518] 11% | Training loss: 0.6881209355592728
Epoch: 93 | Iteration number: [510/4518] 11% | Training loss: 0.6880945580847123
Epoch: 93 | Iteration number: [520/4518] 11% | Training loss: 0.6880490470391053
Epoch: 93 | Iteration number: [530/4518] 11% | Training loss: 0.6880317829689889
Epoch: 93 | Iteration number: [540/4518] 11% | Training loss: 0.6880184207801465
Epoch: 93 | Iteration number: [550/4518] 12% | Training loss: 0.6879914755170996
Epoch: 93 | Iteration number: [560/4518] 12% | Training loss: 0.687964693563325
Epoch: 93 | Iteration number: [570/4518] 12% | Training loss: 0.6879442164772436
Epoch: 93 | Iteration number: [580/4518] 12% | Training loss: 0.6879185161713897
Epoch: 93 | Iteration number: [590/4518] 13% | Training loss: 0.6879376874131672
Epoch: 93 | Iteration number: [600/4518] 13% | Training loss: 0.687916892170906
Epoch: 93 | Iteration number: [610/4518] 13% | Training loss: 0.6879018039976964
Epoch: 93 | Iteration number: [620/4518] 13% | Training loss: 0.6878886232453008
Epoch: 93 | Iteration number: [630/4518] 13% | Training loss: 0.6878805498282115
Epoch: 93 | Iteration number: [640/4518] 14% | Training loss: 0.6878785630688071
Epoch: 93 | Iteration number: [650/4518] 14% | Training loss: 0.6878598800072303
Epoch: 93 | Iteration number: [660/4518] 14% | Training loss: 0.6878327096953537
Epoch: 93 | Iteration number: [670/4518] 14% | Training loss: 0.6878168856919702
Epoch: 93 | Iteration number: [680/4518] 15% | Training loss: 0.6878241600359187
Epoch: 93 | Iteration number: [690/4518] 15% | Training loss: 0.6877894931945248
Epoch: 93 | Iteration number: [700/4518] 15% | Training loss: 0.6877651965618133
Epoch: 93 | Iteration number: [710/4518] 15% | Training loss: 0.6877666313883285
Epoch: 93 | Iteration number: [720/4518] 15% | Training loss: 0.6877559382054541
Epoch: 93 | Iteration number: [730/4518] 16% | Training loss: 0.6877392489616185
Epoch: 93 | Iteration number: [740/4518] 16% | Training loss: 0.6877167390005009
Epoch: 93 | Iteration number: [750/4518] 16% | Training loss: 0.687701187133789
Epoch: 93 | Iteration number: [760/4518] 16% | Training loss: 0.687703134276365
Epoch: 93 | Iteration number: [770/4518] 17% | Training loss: 0.6876883710359598
Epoch: 93 | Iteration number: [780/4518] 17% | Training loss: 0.6876691384957387
Epoch: 93 | Iteration number: [790/4518] 17% | Training loss: 0.687654034548168
Epoch: 93 | Iteration number: [800/4518] 17% | Training loss: 0.687656938880682
Epoch: 93 | Iteration number: [810/4518] 17% | Training loss: 0.6876541616740051
Epoch: 93 | Iteration number: [820/4518] 18% | Training loss: 0.6876459570192709
Epoch: 93 | Iteration number: [830/4518] 18% | Training loss: 0.687639117959034
Epoch: 93 | Iteration number: [840/4518] 18% | Training loss: 0.6876177343584242
Epoch: 93 | Iteration number: [850/4518] 18% | Training loss: 0.6876135433421415
Epoch: 93 | Iteration number: [860/4518] 19% | Training loss: 0.6876122166944104
Epoch: 93 | Iteration number: [870/4518] 19% | Training loss: 0.6876044496037494
Epoch: 93 | Iteration number: [880/4518] 19% | Training loss: 0.6875938792120326
Epoch: 93 | Iteration number: [890/4518] 19% | Training loss: 0.6875770568177941
Epoch: 93 | Iteration number: [900/4518] 19% | Training loss: 0.6875591714514626
Epoch: 93 | Iteration number: [910/4518] 20% | Training loss: 0.6875504687592223
Epoch: 93 | Iteration number: [920/4518] 20% | Training loss: 0.687538878036582
Epoch: 93 | Iteration number: [930/4518] 20% | Training loss: 0.6875411180398797
Epoch: 93 | Iteration number: [940/4518] 20% | Training loss: 0.6875301939375857
Epoch: 93 | Iteration number: [950/4518] 21% | Training loss: 0.6875285054508008
Epoch: 93 | Iteration number: [960/4518] 21% | Training loss: 0.6875105790173014
Epoch: 93 | Iteration number: [970/4518] 21% | Training loss: 0.6875017267527039
Epoch: 93 | Iteration number: [980/4518] 21% | Training loss: 0.6874991210139527
Epoch: 93 | Iteration number: [990/4518] 21% | Training loss: 0.6874857100573453
Epoch: 93 | Iteration number: [1000/4518] 22% | Training loss: 0.6874752399325371
Epoch: 93 | Iteration number: [1010/4518] 22% | Training loss: 0.6874597300987433
Epoch: 93 | Iteration number: [1020/4518] 22% | Training loss: 0.687456535299619
Epoch: 93 | Iteration number: [1030/4518] 22% | Training loss: 0.6874588807809701
Epoch: 93 | Iteration number: [1040/4518] 23% | Training loss: 0.6874493376566814
Epoch: 93 | Iteration number: [1050/4518] 23% | Training loss: 0.6874445053509304
Epoch: 93 | Iteration number: [1060/4518] 23% | Training loss: 0.6874419539042239
Epoch: 93 | Iteration number: [1070/4518] 23% | Training loss: 0.6874242209385488
Epoch: 93 | Iteration number: [1080/4518] 23% | Training loss: 0.687424631913503
Epoch: 93 | Iteration number: [1090/4518] 24% | Training loss: 0.6874232017118996
Epoch: 93 | Iteration number: [1100/4518] 24% | Training loss: 0.6874192581393502
Epoch: 93 | Iteration number: [1110/4518] 24% | Training loss: 0.6874140867778847
Epoch: 93 | Iteration number: [1120/4518] 24% | Training loss: 0.6874039377485003
Epoch: 93 | Iteration number: [1130/4518] 25% | Training loss: 0.6873985929826719
Epoch: 93 | Iteration number: [1140/4518] 25% | Training loss: 0.6874005301479708
Epoch: 93 | Iteration number: [1150/4518] 25% | Training loss: 0.6873877376058827
Epoch: 93 | Iteration number: [1160/4518] 25% | Training loss: 0.6873810514807701
Epoch: 93 | Iteration number: [1170/4518] 25% | Training loss: 0.6873831762207879
Epoch: 93 | Iteration number: [1180/4518] 26% | Training loss: 0.6873482231871556
Epoch: 93 | Iteration number: [1190/4518] 26% | Training loss: 0.6873481476006388
Epoch: 93 | Iteration number: [1200/4518] 26% | Training loss: 0.6873572938640913
Epoch: 93 | Iteration number: [1210/4518] 26% | Training loss: 0.6873609575358304
Epoch: 93 | Iteration number: [1220/4518] 27% | Training loss: 0.6873587289794547
Epoch: 93 | Iteration number: [1230/4518] 27% | Training loss: 0.6873489074106139
Epoch: 93 | Iteration number: [1240/4518] 27% | Training loss: 0.6873536521869321
Epoch: 93 | Iteration number: [1250/4518] 27% | Training loss: 0.6873542741298676
Epoch: 93 | Iteration number: [1260/4518] 27% | Training loss: 0.6873542057143317
Epoch: 93 | Iteration number: [1270/4518] 28% | Training loss: 0.6873568240582474
Epoch: 93 | Iteration number: [1280/4518] 28% | Training loss: 0.6873548614792526
Epoch: 93 | Iteration number: [1290/4518] 28% | Training loss: 0.687348821643711
Epoch: 93 | Iteration number: [1300/4518] 28% | Training loss: 0.6873285014812763
Epoch: 93 | Iteration number: [1310/4518] 28% | Training loss: 0.6873242631213355
Epoch: 93 | Iteration number: [1320/4518] 29% | Training loss: 0.6873179099324978
Epoch: 93 | Iteration number: [1330/4518] 29% | Training loss: 0.6873167915451796
Epoch: 93 | Iteration number: [1340/4518] 29% | Training loss: 0.6873194569972024
Epoch: 93 | Iteration number: [1350/4518] 29% | Training loss: 0.6873277304349122
Epoch: 93 | Iteration number: [1360/4518] 30% | Training loss: 0.6873237026526647
Epoch: 93 | Iteration number: [1370/4518] 30% | Training loss: 0.6873155390694193
Epoch: 93 | Iteration number: [1380/4518] 30% | Training loss: 0.6873078979443813
Epoch: 93 | Iteration number: [1390/4518] 30% | Training loss: 0.6873079719732134
Epoch: 93 | Iteration number: [1400/4518] 30% | Training loss: 0.6873090864079339
Epoch: 93 | Iteration number: [1410/4518] 31% | Training loss: 0.6873013752994808
Epoch: 93 | Iteration number: [1420/4518] 31% | Training loss: 0.6872938788692716
Epoch: 93 | Iteration number: [1430/4518] 31% | Training loss: 0.6872860329968112
Epoch: 93 | Iteration number: [1440/4518] 31% | Training loss: 0.6872802579982413
Epoch: 93 | Iteration number: [1450/4518] 32% | Training loss: 0.6872728695540593
Epoch: 93 | Iteration number: [1460/4518] 32% | Training loss: 0.6872735982480115
Epoch: 93 | Iteration number: [1470/4518] 32% | Training loss: 0.6872675727013828
Epoch: 93 | Iteration number: [1480/4518] 32% | Training loss: 0.6872625591384398
Epoch: 93 | Iteration number: [1490/4518] 32% | Training loss: 0.6872649274016387
Epoch: 93 | Iteration number: [1500/4518] 33% | Training loss: 0.6872530169487
Epoch: 93 | Iteration number: [1510/4518] 33% | Training loss: 0.687243773921436
Epoch: 93 | Iteration number: [1520/4518] 33% | Training loss: 0.6872389992208857
Epoch: 93 | Iteration number: [1530/4518] 33% | Training loss: 0.6872345480653975
Epoch: 93 | Iteration number: [1540/4518] 34% | Training loss: 0.6872346935721186
Epoch: 93 | Iteration number: [1550/4518] 34% | Training loss: 0.6872280532313931
Epoch: 93 | Iteration number: [1560/4518] 34% | Training loss: 0.6872337428805155
Epoch: 93 | Iteration number: [1570/4518] 34% | Training loss: 0.6872277940534482
Epoch: 93 | Iteration number: [1580/4518] 34% | Training loss: 0.6872147769867619
Epoch: 93 | Iteration number: [1590/4518] 35% | Training loss: 0.6872089218793426
Epoch: 93 | Iteration number: [1600/4518] 35% | Training loss: 0.6872067878767848
Epoch: 93 | Iteration number: [1610/4518] 35% | Training loss: 0.6872033757082424
Epoch: 93 | Iteration number: [1620/4518] 35% | Training loss: 0.6871910513551147
Epoch: 93 | Iteration number: [1630/4518] 36% | Training loss: 0.6871827288639326
Epoch: 93 | Iteration number: [1640/4518] 36% | Training loss: 0.6871809445139838
Epoch: 93 | Iteration number: [1650/4518] 36% | Training loss: 0.6871790776469491
Epoch: 93 | Iteration number: [1660/4518] 36% | Training loss: 0.6871848192918731
Epoch: 93 | Iteration number: [1670/4518] 36% | Training loss: 0.6871890150858256
Epoch: 93 | Iteration number: [1680/4518] 37% | Training loss: 0.6871862332380954
Epoch: 93 | Iteration number: [1690/4518] 37% | Training loss: 0.6871838513563371
Epoch: 93 | Iteration number: [1700/4518] 37% | Training loss: 0.6871869741818484
Epoch: 93 | Iteration number: [1710/4518] 37% | Training loss: 0.687184787005709
Epoch: 93 | Iteration number: [1720/4518] 38% | Training loss: 0.6871807718692824
Epoch: 93 | Iteration number: [1730/4518] 38% | Training loss: 0.6871771744565468
Epoch: 93 | Iteration number: [1740/4518] 38% | Training loss: 0.687180948874046
Epoch: 93 | Iteration number: [1750/4518] 38% | Training loss: 0.6871849468094962
Epoch: 93 | Iteration number: [1760/4518] 38% | Training loss: 0.6871776741336693
Epoch: 93 | Iteration number: [1770/4518] 39% | Training loss: 0.6871813547476536
Epoch: 93 | Iteration number: [1780/4518] 39% | Training loss: 0.6871766686774372
Epoch: 93 | Iteration number: [1790/4518] 39% | Training loss: 0.6871720349988458
Epoch: 93 | Iteration number: [1800/4518] 39% | Training loss: 0.6871739697456359
Epoch: 93 | Iteration number: [1810/4518] 40% | Training loss: 0.6871682983735649
Epoch: 93 | Iteration number: [1820/4518] 40% | Training loss: 0.6871673395672997
Epoch: 93 | Iteration number: [1830/4518] 40% | Training loss: 0.6871601918030307
Epoch: 93 | Iteration number: [1840/4518] 40% | Training loss: 0.6871594012431477
Epoch: 93 | Iteration number: [1850/4518] 40% | Training loss: 0.6871598127403775
Epoch: 93 | Iteration number: [1860/4518] 41% | Training loss: 0.6871519433234328
Epoch: 93 | Iteration number: [1870/4518] 41% | Training loss: 0.6871496894461586
Epoch: 93 | Iteration number: [1880/4518] 41% | Training loss: 0.6871485651807582
Epoch: 93 | Iteration number: [1890/4518] 41% | Training loss: 0.6871487500806334
Epoch: 93 | Iteration number: [1900/4518] 42% | Training loss: 0.687141580832632
Epoch: 93 | Iteration number: [1910/4518] 42% | Training loss: 0.687134419280197
Epoch: 93 | Iteration number: [1920/4518] 42% | Training loss: 0.6871326370164752
Epoch: 93 | Iteration number: [1930/4518] 42% | Training loss: 0.6871292114566645
Epoch: 93 | Iteration number: [1940/4518] 42% | Training loss: 0.6871319107788125
Epoch: 93 | Iteration number: [1950/4518] 43% | Training loss: 0.6871251705976633
Epoch: 93 | Iteration number: [1960/4518] 43% | Training loss: 0.6871352909779062
Epoch: 93 | Iteration number: [1970/4518] 43% | Training loss: 0.6871348437016386
Epoch: 93 | Iteration number: [1980/4518] 43% | Training loss: 0.6871314291099105
Epoch: 93 | Iteration number: [1990/4518] 44% | Training loss: 0.6871305485466617
Epoch: 93 | Iteration number: [2000/4518] 44% | Training loss: 0.6871303512454033
Epoch: 93 | Iteration number: [2010/4518] 44% | Training loss: 0.6871296056170961
Epoch: 93 | Iteration number: [2020/4518] 44% | Training loss: 0.6871189614038656
Epoch: 93 | Iteration number: [2030/4518] 44% | Training loss: 0.6871137957854812
Epoch: 93 | Iteration number: [2040/4518] 45% | Training loss: 0.6871128409808758
Epoch: 93 | Iteration number: [2050/4518] 45% | Training loss: 0.6871099559562962
Epoch: 93 | Iteration number: [2060/4518] 45% | Training loss: 0.6871128075909846
Epoch: 93 | Iteration number: [2070/4518] 45% | Training loss: 0.6871074053112436
Epoch: 93 | Iteration number: [2080/4518] 46% | Training loss: 0.6871024009413444
Epoch: 93 | Iteration number: [2090/4518] 46% | Training loss: 0.6870938510700847
Epoch: 93 | Iteration number: [2100/4518] 46% | Training loss: 0.6870953306981495
Epoch: 93 | Iteration number: [2110/4518] 46% | Training loss: 0.6870981952025427
Epoch: 93 | Iteration number: [2120/4518] 46% | Training loss: 0.6870979350130513
Epoch: 93 | Iteration number: [2130/4518] 47% | Training loss: 0.6870956561654946
Epoch: 93 | Iteration number: [2140/4518] 47% | Training loss: 0.6870906749896915
Epoch: 93 | Iteration number: [2150/4518] 47% | Training loss: 0.6870908929580866
Epoch: 93 | Iteration number: [2160/4518] 47% | Training loss: 0.6870927462147342
Epoch: 93 | Iteration number: [2170/4518] 48% | Training loss: 0.6870926623245538
Epoch: 93 | Iteration number: [2180/4518] 48% | Training loss: 0.6870896315355913
Epoch: 93 | Iteration number: [2190/4518] 48% | Training loss: 0.687090529644326
Epoch: 93 | Iteration number: [2200/4518] 48% | Training loss: 0.6870864428444342
Epoch: 93 | Iteration number: [2210/4518] 48% | Training loss: 0.6870866701074315
Epoch: 93 | Iteration number: [2220/4518] 49% | Training loss: 0.6870889814587327
Epoch: 93 | Iteration number: [2230/4518] 49% | Training loss: 0.6870906818875283
Epoch: 93 | Iteration number: [2240/4518] 49% | Training loss: 0.6870916935482195
Epoch: 93 | Iteration number: [2250/4518] 49% | Training loss: 0.6870913880666097
Epoch: 93 | Iteration number: [2260/4518] 50% | Training loss: 0.6870877300479771
Epoch: 93 | Iteration number: [2270/4518] 50% | Training loss: 0.6870798716198505
Epoch: 93 | Iteration number: [2280/4518] 50% | Training loss: 0.6870734114395944
Epoch: 93 | Iteration number: [2290/4518] 50% | Training loss: 0.6870746586260317
Epoch: 93 | Iteration number: [2300/4518] 50% | Training loss: 0.6870713171492452
Epoch: 93 | Iteration number: [2310/4518] 51% | Training loss: 0.6870690512450742
Epoch: 93 | Iteration number: [2320/4518] 51% | Training loss: 0.6870680548250675
Epoch: 93 | Iteration number: [2330/4518] 51% | Training loss: 0.6870655224046993
Epoch: 93 | Iteration number: [2340/4518] 51% | Training loss: 0.6870606407141074
Epoch: 93 | Iteration number: [2350/4518] 52% | Training loss: 0.6870564608624641
Epoch: 93 | Iteration number: [2360/4518] 52% | Training loss: 0.6870509020100206
Epoch: 93 | Iteration number: [2370/4518] 52% | Training loss: 0.6870457620811865
Epoch: 93 | Iteration number: [2380/4518] 52% | Training loss: 0.6870397320064177
Epoch: 93 | Iteration number: [2390/4518] 52% | Training loss: 0.6870299798424773
Epoch: 93 | Iteration number: [2400/4518] 53% | Training loss: 0.6870305606971184
Epoch: 93 | Iteration number: [2410/4518] 53% | Training loss: 0.6870271750505534
Epoch: 93 | Iteration number: [2420/4518] 53% | Training loss: 0.6870192648458087
Epoch: 93 | Iteration number: [2430/4518] 53% | Training loss: 0.6870123101360023
Epoch: 93 | Iteration number: [2440/4518] 54% | Training loss: 0.6870108306407928
Epoch: 93 | Iteration number: [2450/4518] 54% | Training loss: 0.6870137811680229
Epoch: 93 | Iteration number: [2460/4518] 54% | Training loss: 0.6870112725147387
Epoch: 93 | Iteration number: [2470/4518] 54% | Training loss: 0.6870133261448941
Epoch: 93 | Iteration number: [2480/4518] 54% | Training loss: 0.6870145738365189
Epoch: 93 | Iteration number: [2490/4518] 55% | Training loss: 0.6870124114325726
Epoch: 93 | Iteration number: [2500/4518] 55% | Training loss: 0.6870107155561447
Epoch: 93 | Iteration number: [2510/4518] 55% | Training loss: 0.6870063160045213
Epoch: 93 | Iteration number: [2520/4518] 55% | Training loss: 0.6870064019210755
Epoch: 93 | Iteration number: [2530/4518] 55% | Training loss: 0.687006151676178
Epoch: 93 | Iteration number: [2540/4518] 56% | Training loss: 0.6870115610088889
Epoch: 93 | Iteration number: [2550/4518] 56% | Training loss: 0.6870111735661825
Epoch: 93 | Iteration number: [2560/4518] 56% | Training loss: 0.6870084788184613
Epoch: 93 | Iteration number: [2570/4518] 56% | Training loss: 0.6870054635788216
Epoch: 93 | Iteration number: [2580/4518] 57% | Training loss: 0.6869989570028098
Epoch: 93 | Iteration number: [2590/4518] 57% | Training loss: 0.6869992659589038
Epoch: 93 | Iteration number: [2600/4518] 57% | Training loss: 0.6870003544138028
Epoch: 93 | Iteration number: [2610/4518] 57% | Training loss: 0.6870029673722512
Epoch: 93 | Iteration number: [2620/4518] 57% | Training loss: 0.6870031703519457
Epoch: 93 | Iteration number: [2630/4518] 58% | Training loss: 0.6870033297022032
Epoch: 93 | Iteration number: [2640/4518] 58% | Training loss: 0.6870062625769413
Epoch: 93 | Iteration number: [2650/4518] 58% | Training loss: 0.687003030529562
Epoch: 93 | Iteration number: [2660/4518] 58% | Training loss: 0.6870029270873034
Epoch: 93 | Iteration number: [2670/4518] 59% | Training loss: 0.6869972325442882
Epoch: 93 | Iteration number: [2680/4518] 59% | Training loss: 0.6870000143549335
Epoch: 93 | Iteration number: [2690/4518] 59% | Training loss: 0.6869961275487141
Epoch: 93 | Iteration number: [2700/4518] 59% | Training loss: 0.6869988990713048
Epoch: 93 | Iteration number: [2710/4518] 59% | Training loss: 0.6869993189384137
Epoch: 93 | Iteration number: [2720/4518] 60% | Training loss: 0.6870002714150092
Epoch: 93 | Iteration number: [2730/4518] 60% | Training loss: 0.687002580069797
Epoch: 93 | Iteration number: [2740/4518] 60% | Training loss: 0.6870010548481976
Epoch: 93 | Iteration number: [2750/4518] 60% | Training loss: 0.6870066026340831
Epoch: 93 | Iteration number: [2760/4518] 61% | Training loss: 0.6870055488702179
Epoch: 93 | Iteration number: [2770/4518] 61% | Training loss: 0.6870011265742649
Epoch: 93 | Iteration number: [2780/4518] 61% | Training loss: 0.6869993970548506
Epoch: 93 | Iteration number: [2790/4518] 61% | Training loss: 0.6869987752275227
Epoch: 93 | Iteration number: [2800/4518] 61% | Training loss: 0.6869964117450373
Epoch: 93 | Iteration number: [2810/4518] 62% | Training loss: 0.686995943839864
Epoch: 93 | Iteration number: [2820/4518] 62% | Training loss: 0.6869963962135586
Epoch: 93 | Iteration number: [2830/4518] 62% | Training loss: 0.6869990399364027
Epoch: 93 | Iteration number: [2840/4518] 62% | Training loss: 0.6869974829151597
Epoch: 93 | Iteration number: [2850/4518] 63% | Training loss: 0.6869966537492317
Epoch: 93 | Iteration number: [2860/4518] 63% | Training loss: 0.6869962886913673
Epoch: 93 | Iteration number: [2870/4518] 63% | Training loss: 0.6869953764647972
Epoch: 93 | Iteration number: [2880/4518] 63% | Training loss: 0.6869946079742577
Epoch: 93 | Iteration number: [2890/4518] 63% | Training loss: 0.6869957485413469
Epoch: 93 | Iteration number: [2900/4518] 64% | Training loss: 0.6869922086082656
Epoch: 93 | Iteration number: [2910/4518] 64% | Training loss: 0.6869938250055018
Epoch: 93 | Iteration number: [2920/4518] 64% | Training loss: 0.6869916982438466
Epoch: 93 | Iteration number: [2930/4518] 64% | Training loss: 0.6869891961279989
Epoch: 93 | Iteration number: [2940/4518] 65% | Training loss: 0.6869887074848422
Epoch: 93 | Iteration number: [2950/4518] 65% | Training loss: 0.6869940042495728
Epoch: 93 | Iteration number: [2960/4518] 65% | Training loss: 0.6869925951031415
Epoch: 93 | Iteration number: [2970/4518] 65% | Training loss: 0.6869848093199811
Epoch: 93 | Iteration number: [2980/4518] 65% | Training loss: 0.6869842979331945
Epoch: 93 | Iteration number: [2990/4518] 66% | Training loss: 0.686983055972734
Epoch: 93 | Iteration number: [3000/4518] 66% | Training loss: 0.6869853898088137
Epoch: 93 | Iteration number: [3010/4518] 66% | Training loss: 0.6869804476186683
Epoch: 93 | Iteration number: [3020/4518] 66% | Training loss: 0.6869777511681942
Epoch: 93 | Iteration number: [3030/4518] 67% | Training loss: 0.6869756418682954
Epoch: 93 | Iteration number: [3040/4518] 67% | Training loss: 0.686975120360914
Epoch: 93 | Iteration number: [3050/4518] 67% | Training loss: 0.6869711865362574
Epoch: 93 | Iteration number: [3060/4518] 67% | Training loss: 0.686968689377791
Epoch: 93 | Iteration number: [3070/4518] 67% | Training loss: 0.6869672748475587
Epoch: 93 | Iteration number: [3080/4518] 68% | Training loss: 0.6869685420355239
Epoch: 93 | Iteration number: [3090/4518] 68% | Training loss: 0.6869681106994838
Epoch: 93 | Iteration number: [3100/4518] 68% | Training loss: 0.6869633046657808
Epoch: 93 | Iteration number: [3110/4518] 68% | Training loss: 0.6869628426346365
Epoch: 93 | Iteration number: [3120/4518] 69% | Training loss: 0.6869628316889971
Epoch: 93 | Iteration number: [3130/4518] 69% | Training loss: 0.6869590263016307
Epoch: 93 | Iteration number: [3140/4518] 69% | Training loss: 0.6869517827299749
Epoch: 93 | Iteration number: [3150/4518] 69% | Training loss: 0.6869490902575236
Epoch: 93 | Iteration number: [3160/4518] 69% | Training loss: 0.6869509478913077
Epoch: 93 | Iteration number: [3170/4518] 70% | Training loss: 0.6869500606594026
Epoch: 93 | Iteration number: [3180/4518] 70% | Training loss: 0.6869510214283782
Epoch: 93 | Iteration number: [3190/4518] 70% | Training loss: 0.6869529537646374
Epoch: 93 | Iteration number: [3200/4518] 70% | Training loss: 0.6869528204202652
Epoch: 93 | Iteration number: [3210/4518] 71% | Training loss: 0.686947959847168
Epoch: 93 | Iteration number: [3220/4518] 71% | Training loss: 0.6869461582129046
Epoch: 93 | Iteration number: [3230/4518] 71% | Training loss: 0.6869471927545389
Epoch: 93 | Iteration number: [3240/4518] 71% | Training loss: 0.6869486750276
Epoch: 93 | Iteration number: [3250/4518] 71% | Training loss: 0.686946664590102
Epoch: 93 | Iteration number: [3260/4518] 72% | Training loss: 0.686944494401019
Epoch: 93 | Iteration number: [3270/4518] 72% | Training loss: 0.6869434189723537
Epoch: 93 | Iteration number: [3280/4518] 72% | Training loss: 0.686938341434409
Epoch: 93 | Iteration number: [3290/4518] 72% | Training loss: 0.686938161853599
Epoch: 93 | Iteration number: [3300/4518] 73% | Training loss: 0.6869361395546885
Epoch: 93 | Iteration number: [3310/4518] 73% | Training loss: 0.6869378581327974
Epoch: 93 | Iteration number: [3320/4518] 73% | Training loss: 0.6869365455156349
Epoch: 93 | Iteration number: [3330/4518] 73% | Training loss: 0.6869382906067478
Epoch: 93 | Iteration number: [3340/4518] 73% | Training loss: 0.6869332808577372
Epoch: 93 | Iteration number: [3350/4518] 74% | Training loss: 0.6869291232948873
Epoch: 93 | Iteration number: [3360/4518] 74% | Training loss: 0.6869340310848895
Epoch: 93 | Iteration number: [3370/4518] 74% | Training loss: 0.6869335212940986
Epoch: 93 | Iteration number: [3380/4518] 74% | Training loss: 0.6869370685879296
Epoch: 93 | Iteration number: [3390/4518] 75% | Training loss: 0.686937127633784
Epoch: 93 | Iteration number: [3400/4518] 75% | Training loss: 0.6869362112879753
Epoch: 93 | Iteration number: [3410/4518] 75% | Training loss: 0.6869350219227351
Epoch: 93 | Iteration number: [3420/4518] 75% | Training loss: 0.6869340662022083
Epoch: 93 | Iteration number: [3430/4518] 75% | Training loss: 0.6869332644751747
Epoch: 93 | Iteration number: [3440/4518] 76% | Training loss: 0.6869356912928958
Epoch: 93 | Iteration number: [3450/4518] 76% | Training loss: 0.6869349072981572
Epoch: 93 | Iteration number: [3460/4518] 76% | Training loss: 0.6869328318992791
Epoch: 93 | Iteration number: [3470/4518] 76% | Training loss: 0.6869287057122168
Epoch: 93 | Iteration number: [3480/4518] 77% | Training loss: 0.6869314288784718
Epoch: 93 | Iteration number: [3490/4518] 77% | Training loss: 0.686933709249797
Epoch: 93 | Iteration number: [3500/4518] 77% | Training loss: 0.6869310935395104
Epoch: 93 | Iteration number: [3510/4518] 77% | Training loss: 0.6869304571226451
Epoch: 93 | Iteration number: [3520/4518] 77% | Training loss: 0.6869308033958077
Epoch: 93 | Iteration number: [3530/4518] 78% | Training loss: 0.6869296940798124
Epoch: 93 | Iteration number: [3540/4518] 78% | Training loss: 0.6869271959288645
Epoch: 93 | Iteration number: [3550/4518] 78% | Training loss: 0.6869276901701806
Epoch: 93 | Iteration number: [3560/4518] 78% | Training loss: 0.6869275564390622
Epoch: 93 | Iteration number: [3570/4518] 79% | Training loss: 0.6869233021382191
Epoch: 93 | Iteration number: [3580/4518] 79% | Training loss: 0.6869243354937218
Epoch: 93 | Iteration number: [3590/4518] 79% | Training loss: 0.6869256158725133
Epoch: 93 | Iteration number: [3600/4518] 79% | Training loss: 0.686928773307138
Epoch: 93 | Iteration number: [3610/4518] 79% | Training loss: 0.6869260805300398
Epoch: 93 | Iteration number: [3620/4518] 80% | Training loss: 0.686924425689555
Epoch: 93 | Iteration number: [3630/4518] 80% | Training loss: 0.6869267196858881
Epoch: 93 | Iteration number: [3640/4518] 80% | Training loss: 0.6869278376410296
Epoch: 93 | Iteration number: [3650/4518] 80% | Training loss: 0.6869268198535867
Epoch: 93 | Iteration number: [3660/4518] 81% | Training loss: 0.6869234592536759
Epoch: 93 | Iteration number: [3670/4518] 81% | Training loss: 0.6869203026353176
Epoch: 93 | Iteration number: [3680/4518] 81% | Training loss: 0.686920556847168
Epoch: 93 | Iteration number: [3690/4518] 81% | Training loss: 0.686920455429289
Epoch: 93 | Iteration number: [3700/4518] 81% | Training loss: 0.6869158973564973
Epoch: 93 | Iteration number: [3710/4518] 82% | Training loss: 0.6869194955838659
Epoch: 93 | Iteration number: [3720/4518] 82% | Training loss: 0.6869158872032678
Epoch: 93 | Iteration number: [3730/4518] 82% | Training loss: 0.6869182897317185
Epoch: 93 | Iteration number: [3740/4518] 82% | Training loss: 0.6869183086934574
Epoch: 93 | Iteration number: [3750/4518] 83% | Training loss: 0.6869186664740244
Epoch: 93 | Iteration number: [3760/4518] 83% | Training loss: 0.6869165117119221
Epoch: 93 | Iteration number: [3770/4518] 83% | Training loss: 0.6869157723469823
Epoch: 93 | Iteration number: [3780/4518] 83% | Training loss: 0.686915246030641
Epoch: 93 | Iteration number: [3790/4518] 83% | Training loss: 0.6869173088300197
Epoch: 93 | Iteration number: [3800/4518] 84% | Training loss: 0.6869160432094021
Epoch: 93 | Iteration number: [3810/4518] 84% | Training loss: 0.6869152659036982
Epoch: 93 | Iteration number: [3820/4518] 84% | Training loss: 0.6869152662017582
Epoch: 93 | Iteration number: [3830/4518] 84% | Training loss: 0.6869154322240745
Epoch: 93 | Iteration number: [3840/4518] 84% | Training loss: 0.6869155153787384
Epoch: 93 | Iteration number: [3850/4518] 85% | Training loss: 0.686913991330506
Epoch: 93 | Iteration number: [3860/4518] 85% | Training loss: 0.6869128607252101
Epoch: 93 | Iteration number: [3870/4518] 85% | Training loss: 0.6869130286289432
Epoch: 93 | Iteration number: [3880/4518] 85% | Training loss: 0.6869152941961878
Epoch: 93 | Iteration number: [3890/4518] 86% | Training loss: 0.6869110648766887
Epoch: 93 | Iteration number: [3900/4518] 86% | Training loss: 0.6869100841803428
Epoch: 93 | Iteration number: [3910/4518] 86% | Training loss: 0.6869094374692044
Epoch: 93 | Iteration number: [3920/4518] 86% | Training loss: 0.6869071571498501
Epoch: 93 | Iteration number: [3930/4518] 86% | Training loss: 0.6869075543552865
Epoch: 93 | Iteration number: [3940/4518] 87% | Training loss: 0.6869080418862668
Epoch: 93 | Iteration number: [3950/4518] 87% | Training loss: 0.6869093661368648
Epoch: 93 | Iteration number: [3960/4518] 87% | Training loss: 0.6869082163229133
Epoch: 93 | Iteration number: [3970/4518] 87% | Training loss: 0.6869099307870985
Epoch: 93 | Iteration number: [3980/4518] 88% | Training loss: 0.6869097396656496
Epoch: 93 | Iteration number: [3990/4518] 88% | Training loss: 0.6869121906601994
Epoch: 93 | Iteration number: [4000/4518] 88% | Training loss: 0.6869148414134979
Epoch: 93 | Iteration number: [4010/4518] 88% | Training loss: 0.6869121494881827
Epoch: 93 | Iteration number: [4020/4518] 88% | Training loss: 0.6869112645067386
Epoch: 93 | Iteration number: [4030/4518] 89% | Training loss: 0.6869135977020926
Epoch: 93 | Iteration number: [4040/4518] 89% | Training loss: 0.6869114520231095
Epoch: 93 | Iteration number: [4050/4518] 89% | Training loss: 0.6869099680582682
Epoch: 93 | Iteration number: [4060/4518] 89% | Training loss: 0.6869112032828073
Epoch: 93 | Iteration number: [4070/4518] 90% | Training loss: 0.6869103330798465
Epoch: 93 | Iteration number: [4080/4518] 90% | Training loss: 0.6869122983193865
Epoch: 93 | Iteration number: [4090/4518] 90% | Training loss: 0.6869135720076945
Epoch: 93 | Iteration number: [4100/4518] 90% | Training loss: 0.6869145488302882
Epoch: 93 | Iteration number: [4110/4518] 90% | Training loss: 0.6869155927586149
Epoch: 93 | Iteration number: [4120/4518] 91% | Training loss: 0.6869180338764653
Epoch: 93 | Iteration number: [4130/4518] 91% | Training loss: 0.6869149533657416
Epoch: 93 | Iteration number: [4140/4518] 91% | Training loss: 0.6869114957281933
Epoch: 93 | Iteration number: [4150/4518] 91% | Training loss: 0.6869124537490937
Epoch: 93 | Iteration number: [4160/4518] 92% | Training loss: 0.6869139310688926
Epoch: 93 | Iteration number: [4170/4518] 92% | Training loss: 0.6869096613902268
Epoch: 93 | Iteration number: [4180/4518] 92% | Training loss: 0.6869083204052665
Epoch: 93 | Iteration number: [4190/4518] 92% | Training loss: 0.6869091002781806
Epoch: 93 | Iteration number: [4200/4518] 92% | Training loss: 0.686907876091344
Epoch: 93 | Iteration number: [4210/4518] 93% | Training loss: 0.6869093674661995
Epoch: 93 | Iteration number: [4220/4518] 93% | Training loss: 0.686909270978652
Epoch: 93 | Iteration number: [4230/4518] 93% | Training loss: 0.6869094895414709
Epoch: 93 | Iteration number: [4240/4518] 93% | Training loss: 0.6869083784661203
Epoch: 93 | Iteration number: [4250/4518] 94% | Training loss: 0.686908526616938
Epoch: 93 | Iteration number: [4260/4518] 94% | Training loss: 0.6869085902059582
Epoch: 93 | Iteration number: [4270/4518] 94% | Training loss: 0.6869088122939617
Epoch: 93 | Iteration number: [4280/4518] 94% | Training loss: 0.686907896970477
Epoch: 93 | Iteration number: [4290/4518] 94% | Training loss: 0.6869085792339209
Epoch: 93 | Iteration number: [4300/4518] 95% | Training loss: 0.6869082910515542
Epoch: 93 | Iteration number: [4310/4518] 95% | Training loss: 0.6869061680514962
Epoch: 93 | Iteration number: [4320/4518] 95% | Training loss: 0.6869029173834457
Epoch: 93 | Iteration number: [4330/4518] 95% | Training loss: 0.6869035277713529
Epoch: 93 | Iteration number: [4340/4518] 96% | Training loss: 0.6869034447702944
Epoch: 93 | Iteration number: [4350/4518] 96% | Training loss: 0.6869046106420714
Epoch: 93 | Iteration number: [4360/4518] 96% | Training loss: 0.6869061779128303
Epoch: 93 | Iteration number: [4370/4518] 96% | Training loss: 0.6869094696961496
Epoch: 93 | Iteration number: [4380/4518] 96% | Training loss: 0.6869108134344832
Epoch: 93 | Iteration number: [4390/4518] 97% | Training loss: 0.686908567440537
Epoch: 93 | Iteration number: [4400/4518] 97% | Training loss: 0.6869051728736271
Epoch: 93 | Iteration number: [4410/4518] 97% | Training loss: 0.6868998824468816
Epoch: 93 | Iteration number: [4420/4518] 97% | Training loss: 0.6869005772862499
Epoch: 93 | Iteration number: [4430/4518] 98% | Training loss: 0.6869017393136939
Epoch: 93 | Iteration number: [4440/4518] 98% | Training loss: 0.6869001007026381
Epoch: 93 | Iteration number: [4450/4518] 98% | Training loss: 0.6868990690654583
Epoch: 93 | Iteration number: [4460/4518] 98% | Training loss: 0.6868982893335445
Epoch: 93 | Iteration number: [4470/4518] 98% | Training loss: 0.68690086256471
Epoch: 93 | Iteration number: [4480/4518] 99% | Training loss: 0.6869002018922141
Epoch: 93 | Iteration number: [4490/4518] 99% | Training loss: 0.6868986284414219
Epoch: 93 | Iteration number: [4500/4518] 99% | Training loss: 0.6868992966016133
Epoch: 93 | Iteration number: [4510/4518] 99% | Training loss: 0.6868992120490106

 End of epoch: 93 | Train Loss: 0.6867490299062531 | Training Time: 632 

 End of epoch: 93 | Eval Loss: 0.6895482284682137 | Evaluating Time: 17 
Epoch: 94 | Iteration number: [10/4518] 0% | Training loss: 0.7549787282943725
Epoch: 94 | Iteration number: [20/4518] 0% | Training loss: 0.7211929470300674
Epoch: 94 | Iteration number: [30/4518] 0% | Training loss: 0.709691212574641
Epoch: 94 | Iteration number: [40/4518] 0% | Training loss: 0.7037268936634063
Epoch: 94 | Iteration number: [50/4518] 1% | Training loss: 0.7002909088134766
Epoch: 94 | Iteration number: [60/4518] 1% | Training loss: 0.6976748396952946
Epoch: 94 | Iteration number: [70/4518] 1% | Training loss: 0.6962146435465132
Epoch: 94 | Iteration number: [80/4518] 1% | Training loss: 0.6950107954442502
Epoch: 94 | Iteration number: [90/4518] 1% | Training loss: 0.6941321445835962
Epoch: 94 | Iteration number: [100/4518] 2% | Training loss: 0.6935315054655075
Epoch: 94 | Iteration number: [110/4518] 2% | Training loss: 0.6929761957038533
Epoch: 94 | Iteration number: [120/4518] 2% | Training loss: 0.6925280943512917
Epoch: 94 | Iteration number: [130/4518] 2% | Training loss: 0.692098514850323
Epoch: 94 | Iteration number: [140/4518] 3% | Training loss: 0.6917432103838239
Epoch: 94 | Iteration number: [150/4518] 3% | Training loss: 0.691500518321991
Epoch: 94 | Iteration number: [160/4518] 3% | Training loss: 0.6912203591316939
Epoch: 94 | Iteration number: [170/4518] 3% | Training loss: 0.6908672830637763
Epoch: 94 | Iteration number: [180/4518] 3% | Training loss: 0.6906884382168452
Epoch: 94 | Iteration number: [190/4518] 4% | Training loss: 0.6905003277879013
Epoch: 94 | Iteration number: [200/4518] 4% | Training loss: 0.6902717652916909
Epoch: 94 | Iteration number: [210/4518] 4% | Training loss: 0.6900783550171625
Epoch: 94 | Iteration number: [220/4518] 4% | Training loss: 0.6899155367504467
Epoch: 94 | Iteration number: [230/4518] 5% | Training loss: 0.6897455935892851
Epoch: 94 | Iteration number: [240/4518] 5% | Training loss: 0.6896006427705288
Epoch: 94 | Iteration number: [250/4518] 5% | Training loss: 0.68945094871521
Epoch: 94 | Iteration number: [260/4518] 5% | Training loss: 0.6893683795745557
Epoch: 94 | Iteration number: [270/4518] 5% | Training loss: 0.6892875580875962
Epoch: 94 | Iteration number: [280/4518] 6% | Training loss: 0.6891668487872397
Epoch: 94 | Iteration number: [290/4518] 6% | Training loss: 0.6890797347858034
Epoch: 94 | Iteration number: [300/4518] 6% | Training loss: 0.6890422636270523
Epoch: 94 | Iteration number: [310/4518] 6% | Training loss: 0.6889856753810759
Epoch: 94 | Iteration number: [320/4518] 7% | Training loss: 0.68888531755656
Epoch: 94 | Iteration number: [330/4518] 7% | Training loss: 0.6887979973446239
Epoch: 94 | Iteration number: [340/4518] 7% | Training loss: 0.6887519429711735
Epoch: 94 | Iteration number: [350/4518] 7% | Training loss: 0.688705860716956
Epoch: 94 | Iteration number: [360/4518] 7% | Training loss: 0.6885969998108016
Epoch: 94 | Iteration number: [370/4518] 8% | Training loss: 0.6885286548653164
Epoch: 94 | Iteration number: [380/4518] 8% | Training loss: 0.688447315128226
Epoch: 94 | Iteration number: [390/4518] 8% | Training loss: 0.6883857219647138
Epoch: 94 | Iteration number: [400/4518] 8% | Training loss: 0.6883144740760326
Epoch: 94 | Iteration number: [410/4518] 9% | Training loss: 0.6882893118916489
Epoch: 94 | Iteration number: [420/4518] 9% | Training loss: 0.6882559170325597
Epoch: 94 | Iteration number: [430/4518] 9% | Training loss: 0.6882184711999672
Epoch: 94 | Iteration number: [440/4518] 9% | Training loss: 0.6882118720899929
Epoch: 94 | Iteration number: [450/4518] 9% | Training loss: 0.6881980782084994
Epoch: 94 | Iteration number: [460/4518] 10% | Training loss: 0.6881500981424166
Epoch: 94 | Iteration number: [470/4518] 10% | Training loss: 0.688119012497841
Epoch: 94 | Iteration number: [480/4518] 10% | Training loss: 0.6881313459326823
Epoch: 94 | Iteration number: [490/4518] 10% | Training loss: 0.6881282401328184
Epoch: 94 | Iteration number: [500/4518] 11% | Training loss: 0.6881100884675979
Epoch: 94 | Iteration number: [510/4518] 11% | Training loss: 0.688073846989987
Epoch: 94 | Iteration number: [520/4518] 11% | Training loss: 0.6880262519304569
Epoch: 94 | Iteration number: [530/4518] 11% | Training loss: 0.6880187897187359
Epoch: 94 | Iteration number: [540/4518] 11% | Training loss: 0.6879938294490179
Epoch: 94 | Iteration number: [550/4518] 12% | Training loss: 0.6879757220094854
Epoch: 94 | Iteration number: [560/4518] 12% | Training loss: 0.6879549869469234
Epoch: 94 | Iteration number: [570/4518] 12% | Training loss: 0.6879056028106756
Epoch: 94 | Iteration number: [580/4518] 12% | Training loss: 0.687881639085967
Epoch: 94 | Iteration number: [590/4518] 13% | Training loss: 0.6878493336297697
Epoch: 94 | Iteration number: [600/4518] 13% | Training loss: 0.6878288006782531
Epoch: 94 | Iteration number: [610/4518] 13% | Training loss: 0.6877951271221286
Epoch: 94 | Iteration number: [620/4518] 13% | Training loss: 0.6877816953005329
Epoch: 94 | Iteration number: [630/4518] 13% | Training loss: 0.6877938918651096
Epoch: 94 | Iteration number: [640/4518] 14% | Training loss: 0.6877885900437832
Epoch: 94 | Iteration number: [650/4518] 14% | Training loss: 0.6877827802988199
Epoch: 94 | Iteration number: [660/4518] 14% | Training loss: 0.6877439464583541
Epoch: 94 | Iteration number: [670/4518] 14% | Training loss: 0.6877180568317869
Epoch: 94 | Iteration number: [680/4518] 15% | Training loss: 0.687698531063164
Epoch: 94 | Iteration number: [690/4518] 15% | Training loss: 0.6876853791699893
Epoch: 94 | Iteration number: [700/4518] 15% | Training loss: 0.6876753394944327
Epoch: 94 | Iteration number: [710/4518] 15% | Training loss: 0.6876580920017941
Epoch: 94 | Iteration number: [720/4518] 15% | Training loss: 0.6876397199928761
Epoch: 94 | Iteration number: [730/4518] 16% | Training loss: 0.6876269176398238
Epoch: 94 | Iteration number: [740/4518] 16% | Training loss: 0.6876150604035404
Epoch: 94 | Iteration number: [750/4518] 16% | Training loss: 0.6876097917556763
Epoch: 94 | Iteration number: [760/4518] 16% | Training loss: 0.6875930012840974
Epoch: 94 | Iteration number: [770/4518] 17% | Training loss: 0.6875667362244098
Epoch: 94 | Iteration number: [780/4518] 17% | Training loss: 0.6875664458825038
Epoch: 94 | Iteration number: [790/4518] 17% | Training loss: 0.6875568293317964
Epoch: 94 | Iteration number: [800/4518] 17% | Training loss: 0.6875370659679174
Epoch: 94 | Iteration number: [810/4518] 17% | Training loss: 0.6875266136210642
Epoch: 94 | Iteration number: [820/4518] 18% | Training loss: 0.6875177895150534
Epoch: 94 | Iteration number: [830/4518] 18% | Training loss: 0.6875040400459106
Epoch: 94 | Iteration number: [840/4518] 18% | Training loss: 0.6874936342948959
Epoch: 94 | Iteration number: [850/4518] 18% | Training loss: 0.6874817922536065
Epoch: 94 | Iteration number: [860/4518] 19% | Training loss: 0.6874799930772116
Epoch: 94 | Iteration number: [870/4518] 19% | Training loss: 0.6874664813622661
Epoch: 94 | Iteration number: [880/4518] 19% | Training loss: 0.6874788907441226
Epoch: 94 | Iteration number: [890/4518] 19% | Training loss: 0.6874665192673716
Epoch: 94 | Iteration number: [900/4518] 19% | Training loss: 0.6874636464648777
Epoch: 94 | Iteration number: [910/4518] 20% | Training loss: 0.6874533086687654
Epoch: 94 | Iteration number: [920/4518] 20% | Training loss: 0.6874538605627807
Epoch: 94 | Iteration number: [930/4518] 20% | Training loss: 0.6874469070024388
Epoch: 94 | Iteration number: [940/4518] 20% | Training loss: 0.687437368073362
Epoch: 94 | Iteration number: [950/4518] 21% | Training loss: 0.6874226417039571
Epoch: 94 | Iteration number: [960/4518] 21% | Training loss: 0.6874274887144566
Epoch: 94 | Iteration number: [970/4518] 21% | Training loss: 0.6874336695548185
Epoch: 94 | Iteration number: [980/4518] 21% | Training loss: 0.6874338825138248
Epoch: 94 | Iteration number: [990/4518] 21% | Training loss: 0.6874212059709761
Epoch: 94 | Iteration number: [1000/4518] 22% | Training loss: 0.6874207465648651
Epoch: 94 | Iteration number: [1010/4518] 22% | Training loss: 0.6874204038393379
Epoch: 94 | Iteration number: [1020/4518] 22% | Training loss: 0.6874093635409486
Epoch: 94 | Iteration number: [1030/4518] 22% | Training loss: 0.6874013220800936
Epoch: 94 | Iteration number: [1040/4518] 23% | Training loss: 0.6873956333559293
Epoch: 94 | Iteration number: [1050/4518] 23% | Training loss: 0.6873977125826336
Epoch: 94 | Iteration number: [1060/4518] 23% | Training loss: 0.6873889283751542
Epoch: 94 | Iteration number: [1070/4518] 23% | Training loss: 0.6873692042916735
Epoch: 94 | Iteration number: [1080/4518] 23% | Training loss: 0.6873564550722087
Epoch: 94 | Iteration number: [1090/4518] 24% | Training loss: 0.6873494579157698
Epoch: 94 | Iteration number: [1100/4518] 24% | Training loss: 0.6873337786306034
Epoch: 94 | Iteration number: [1110/4518] 24% | Training loss: 0.6873290080207962
Epoch: 94 | Iteration number: [1120/4518] 24% | Training loss: 0.6873126279030527
Epoch: 94 | Iteration number: [1130/4518] 25% | Training loss: 0.6873067317810734
Epoch: 94 | Iteration number: [1140/4518] 25% | Training loss: 0.6873085409402847
Epoch: 94 | Iteration number: [1150/4518] 25% | Training loss: 0.6873020223949267
Epoch: 94 | Iteration number: [1160/4518] 25% | Training loss: 0.6872921932360222
Epoch: 94 | Iteration number: [1170/4518] 25% | Training loss: 0.6872716104372953
Epoch: 94 | Iteration number: [1180/4518] 26% | Training loss: 0.6872672895253715
Epoch: 94 | Iteration number: [1190/4518] 26% | Training loss: 0.6872654861261864
Epoch: 94 | Iteration number: [1200/4518] 26% | Training loss: 0.6872623245914777
Epoch: 94 | Iteration number: [1210/4518] 26% | Training loss: 0.6872591488124911
Epoch: 94 | Iteration number: [1220/4518] 27% | Training loss: 0.6872429986957644
Epoch: 94 | Iteration number: [1230/4518] 27% | Training loss: 0.6872394056824165
Epoch: 94 | Iteration number: [1240/4518] 27% | Training loss: 0.6872341683314692
Epoch: 94 | Iteration number: [1250/4518] 27% | Training loss: 0.6872362147331238
Epoch: 94 | Iteration number: [1260/4518] 27% | Training loss: 0.6872332511913208
Epoch: 94 | Iteration number: [1270/4518] 28% | Training loss: 0.6872383541948214
Epoch: 94 | Iteration number: [1280/4518] 28% | Training loss: 0.6872369242366403
Epoch: 94 | Iteration number: [1290/4518] 28% | Training loss: 0.6872153434180475
Epoch: 94 | Iteration number: [1300/4518] 28% | Training loss: 0.6872158586978913
Epoch: 94 | Iteration number: [1310/4518] 28% | Training loss: 0.6872105890557966
Epoch: 94 | Iteration number: [1320/4518] 29% | Training loss: 0.6872007855863282
Epoch: 94 | Iteration number: [1330/4518] 29% | Training loss: 0.6871919069971357
Epoch: 94 | Iteration number: [1340/4518] 29% | Training loss: 0.68719496077566
Epoch: 94 | Iteration number: [1350/4518] 29% | Training loss: 0.6871857991483477
Epoch: 94 | Iteration number: [1360/4518] 30% | Training loss: 0.6871751149787623
Epoch: 94 | Iteration number: [1370/4518] 30% | Training loss: 0.6871801395485871
Epoch: 94 | Iteration number: [1380/4518] 30% | Training loss: 0.6871758650178494
Epoch: 94 | Iteration number: [1390/4518] 30% | Training loss: 0.6871826017074448
Epoch: 94 | Iteration number: [1400/4518] 30% | Training loss: 0.6871757207172258
Epoch: 94 | Iteration number: [1410/4518] 31% | Training loss: 0.6871794738668077
Epoch: 94 | Iteration number: [1420/4518] 31% | Training loss: 0.6871835214990966
Epoch: 94 | Iteration number: [1430/4518] 31% | Training loss: 0.6871778391874753
Epoch: 94 | Iteration number: [1440/4518] 31% | Training loss: 0.6871762496315771
Epoch: 94 | Iteration number: [1450/4518] 32% | Training loss: 0.6871789657247478
Epoch: 94 | Iteration number: [1460/4518] 32% | Training loss: 0.687178815513441
Epoch: 94 | Iteration number: [1470/4518] 32% | Training loss: 0.6871732863439184
Epoch: 94 | Iteration number: [1480/4518] 32% | Training loss: 0.6871709112782736
Epoch: 94 | Iteration number: [1490/4518] 32% | Training loss: 0.6871765955182529
Epoch: 94 | Iteration number: [1500/4518] 33% | Training loss: 0.6871610481739044
Epoch: 94 | Iteration number: [1510/4518] 33% | Training loss: 0.6871561005020773
Epoch: 94 | Iteration number: [1520/4518] 33% | Training loss: 0.6871628473855947
Epoch: 94 | Iteration number: [1530/4518] 33% | Training loss: 0.6871542031858482
Epoch: 94 | Iteration number: [1540/4518] 34% | Training loss: 0.6871559832777295
Epoch: 94 | Iteration number: [1550/4518] 34% | Training loss: 0.687151751172158
Epoch: 94 | Iteration number: [1560/4518] 34% | Training loss: 0.6871476351832733
Epoch: 94 | Iteration number: [1570/4518] 34% | Training loss: 0.6871495520233348
Epoch: 94 | Iteration number: [1580/4518] 34% | Training loss: 0.6871419018205208
Epoch: 94 | Iteration number: [1590/4518] 35% | Training loss: 0.6871466381744769
Epoch: 94 | Iteration number: [1600/4518] 35% | Training loss: 0.6871569458395242
Epoch: 94 | Iteration number: [1610/4518] 35% | Training loss: 0.6871521012383218
Epoch: 94 | Iteration number: [1620/4518] 35% | Training loss: 0.6871419824935772
Epoch: 94 | Iteration number: [1630/4518] 36% | Training loss: 0.687141018520835
Epoch: 94 | Iteration number: [1640/4518] 36% | Training loss: 0.6871339013663734
Epoch: 94 | Iteration number: [1650/4518] 36% | Training loss: 0.6871249988223567
Epoch: 94 | Iteration number: [1660/4518] 36% | Training loss: 0.6871195245220001
Epoch: 94 | Iteration number: [1670/4518] 36% | Training loss: 0.6871192235432699
Epoch: 94 | Iteration number: [1680/4518] 37% | Training loss: 0.6871226042509079
Epoch: 94 | Iteration number: [1690/4518] 37% | Training loss: 0.6871176643837134
Epoch: 94 | Iteration number: [1700/4518] 37% | Training loss: 0.6871239620447159
Epoch: 94 | Iteration number: [1710/4518] 37% | Training loss: 0.6871223254510533
Epoch: 94 | Iteration number: [1720/4518] 38% | Training loss: 0.6871168421797974
Epoch: 94 | Iteration number: [1730/4518] 38% | Training loss: 0.6871155070087124
Epoch: 94 | Iteration number: [1740/4518] 38% | Training loss: 0.6871196453256169
Epoch: 94 | Iteration number: [1750/4518] 38% | Training loss: 0.6871241881847382
Epoch: 94 | Iteration number: [1760/4518] 38% | Training loss: 0.6871296808123588
Epoch: 94 | Iteration number: [1770/4518] 39% | Training loss: 0.6871290709339293
Epoch: 94 | Iteration number: [1780/4518] 39% | Training loss: 0.6871318295765458
Epoch: 94 | Iteration number: [1790/4518] 39% | Training loss: 0.6871287882994007
Epoch: 94 | Iteration number: [1800/4518] 39% | Training loss: 0.6871255285541217
Epoch: 94 | Iteration number: [1810/4518] 40% | Training loss: 0.6871307095111404
Epoch: 94 | Iteration number: [1820/4518] 40% | Training loss: 0.687131205692396
Epoch: 94 | Iteration number: [1830/4518] 40% | Training loss: 0.6871362909918926
Epoch: 94 | Iteration number: [1840/4518] 40% | Training loss: 0.6871379339500614
Epoch: 94 | Iteration number: [1850/4518] 40% | Training loss: 0.6871346269104932
Epoch: 94 | Iteration number: [1860/4518] 41% | Training loss: 0.6871400183246982
Epoch: 94 | Iteration number: [1870/4518] 41% | Training loss: 0.6871357778814388
Epoch: 94 | Iteration number: [1880/4518] 41% | Training loss: 0.6871359402829028
Epoch: 94 | Iteration number: [1890/4518] 41% | Training loss: 0.6871254629243618
Epoch: 94 | Iteration number: [1900/4518] 42% | Training loss: 0.6871263876400496
Epoch: 94 | Iteration number: [1910/4518] 42% | Training loss: 0.6871260167728543
Epoch: 94 | Iteration number: [1920/4518] 42% | Training loss: 0.687126592049996
Epoch: 94 | Iteration number: [1930/4518] 42% | Training loss: 0.6871289395297747
Epoch: 94 | Iteration number: [1940/4518] 42% | Training loss: 0.6871281289255496
Epoch: 94 | Iteration number: [1950/4518] 43% | Training loss: 0.6871198984292838
Epoch: 94 | Iteration number: [1960/4518] 43% | Training loss: 0.6871121299814205
Epoch: 94 | Iteration number: [1970/4518] 43% | Training loss: 0.6871117198527767
Epoch: 94 | Iteration number: [1980/4518] 43% | Training loss: 0.6871108646946724
Epoch: 94 | Iteration number: [1990/4518] 44% | Training loss: 0.6871016414620769
Epoch: 94 | Iteration number: [2000/4518] 44% | Training loss: 0.687097032904625
Epoch: 94 | Iteration number: [2010/4518] 44% | Training loss: 0.687098667544512
Epoch: 94 | Iteration number: [2020/4518] 44% | Training loss: 0.6870956592630632
Epoch: 94 | Iteration number: [2030/4518] 44% | Training loss: 0.6870843592242067
Epoch: 94 | Iteration number: [2040/4518] 45% | Training loss: 0.6870859606593263
Epoch: 94 | Iteration number: [2050/4518] 45% | Training loss: 0.6870808441173739
Epoch: 94 | Iteration number: [2060/4518] 45% | Training loss: 0.6870798310319197
Epoch: 94 | Iteration number: [2070/4518] 45% | Training loss: 0.6870774578069143
Epoch: 94 | Iteration number: [2080/4518] 46% | Training loss: 0.6870792919340042
Epoch: 94 | Iteration number: [2090/4518] 46% | Training loss: 0.687083199919696
Epoch: 94 | Iteration number: [2100/4518] 46% | Training loss: 0.6870820939540863
Epoch: 94 | Iteration number: [2110/4518] 46% | Training loss: 0.6870776883516266
Epoch: 94 | Iteration number: [2120/4518] 46% | Training loss: 0.6870820457080625
Epoch: 94 | Iteration number: [2130/4518] 47% | Training loss: 0.6870804936673159
Epoch: 94 | Iteration number: [2140/4518] 47% | Training loss: 0.6870763341121584
Epoch: 94 | Iteration number: [2150/4518] 47% | Training loss: 0.6870772062068762
Epoch: 94 | Iteration number: [2160/4518] 47% | Training loss: 0.6870725913456193
Epoch: 94 | Iteration number: [2170/4518] 48% | Training loss: 0.6870752376345446
Epoch: 94 | Iteration number: [2180/4518] 48% | Training loss: 0.6870688056727068
Epoch: 94 | Iteration number: [2190/4518] 48% | Training loss: 0.6870707530953568
Epoch: 94 | Iteration number: [2200/4518] 48% | Training loss: 0.6870685064521703
Epoch: 94 | Iteration number: [2210/4518] 48% | Training loss: 0.6870658152783079
Epoch: 94 | Iteration number: [2220/4518] 49% | Training loss: 0.6870652141066285
Epoch: 94 | Iteration number: [2230/4518] 49% | Training loss: 0.6870657908007703
Epoch: 94 | Iteration number: [2240/4518] 49% | Training loss: 0.6870665700041823
Epoch: 94 | Iteration number: [2250/4518] 49% | Training loss: 0.6870674237145318
Epoch: 94 | Iteration number: [2260/4518] 50% | Training loss: 0.687064127610848
Epoch: 94 | Iteration number: [2270/4518] 50% | Training loss: 0.6870686766071992
Epoch: 94 | Iteration number: [2280/4518] 50% | Training loss: 0.6870730517726196
Epoch: 94 | Iteration number: [2290/4518] 50% | Training loss: 0.6870683279620508
Epoch: 94 | Iteration number: [2300/4518] 50% | Training loss: 0.6870682501015456
Epoch: 94 | Iteration number: [2310/4518] 51% | Training loss: 0.6870697638173124
Epoch: 94 | Iteration number: [2320/4518] 51% | Training loss: 0.6870706355263447
Epoch: 94 | Iteration number: [2330/4518] 51% | Training loss: 0.6870634058514378
Epoch: 94 | Iteration number: [2340/4518] 51% | Training loss: 0.6870637968055203
Epoch: 94 | Iteration number: [2350/4518] 52% | Training loss: 0.687063619431029
Epoch: 94 | Iteration number: [2360/4518] 52% | Training loss: 0.6870656600695545
Epoch: 94 | Iteration number: [2370/4518] 52% | Training loss: 0.6870684844280597
Epoch: 94 | Iteration number: [2380/4518] 52% | Training loss: 0.6870702752045222
Epoch: 94 | Iteration number: [2390/4518] 52% | Training loss: 0.6870655888044684
Epoch: 94 | Iteration number: [2400/4518] 53% | Training loss: 0.6870648692548275
Epoch: 94 | Iteration number: [2410/4518] 53% | Training loss: 0.6870641217192179
Epoch: 94 | Iteration number: [2420/4518] 53% | Training loss: 0.6870641473157346
Epoch: 94 | Iteration number: [2430/4518] 53% | Training loss: 0.6870618752981901
Epoch: 94 | Iteration number: [2440/4518] 54% | Training loss: 0.687059058102428
Epoch: 94 | Iteration number: [2450/4518] 54% | Training loss: 0.6870595321606616
Epoch: 94 | Iteration number: [2460/4518] 54% | Training loss: 0.6870577085551207
Epoch: 94 | Iteration number: [2470/4518] 54% | Training loss: 0.68705696818317
Epoch: 94 | Iteration number: [2480/4518] 54% | Training loss: 0.6870544876302442
Epoch: 94 | Iteration number: [2490/4518] 55% | Training loss: 0.6870494817155433
Epoch: 94 | Iteration number: [2500/4518] 55% | Training loss: 0.6870478130340576
Epoch: 94 | Iteration number: [2510/4518] 55% | Training loss: 0.6870404838328342
Epoch: 94 | Iteration number: [2520/4518] 55% | Training loss: 0.6870376342109271
Epoch: 94 | Iteration number: [2530/4518] 55% | Training loss: 0.6870418615491966
Epoch: 94 | Iteration number: [2540/4518] 56% | Training loss: 0.6870414885010306
Epoch: 94 | Iteration number: [2550/4518] 56% | Training loss: 0.6870430608122956
Epoch: 94 | Iteration number: [2560/4518] 56% | Training loss: 0.6870407394366339
Epoch: 94 | Iteration number: [2570/4518] 56% | Training loss: 0.6870412386808877
Epoch: 94 | Iteration number: [2580/4518] 57% | Training loss: 0.6870420762503794
Epoch: 94 | Iteration number: [2590/4518] 57% | Training loss: 0.6870387637477123
Epoch: 94 | Iteration number: [2600/4518] 57% | Training loss: 0.6870381921071272
Epoch: 94 | Iteration number: [2610/4518] 57% | Training loss: 0.6870358631300286
Epoch: 94 | Iteration number: [2620/4518] 57% | Training loss: 0.6870345566336435
Epoch: 94 | Iteration number: [2630/4518] 58% | Training loss: 0.6870357106620368
Epoch: 94 | Iteration number: [2640/4518] 58% | Training loss: 0.6870320196630377
Epoch: 94 | Iteration number: [2650/4518] 58% | Training loss: 0.6870281688672192
Epoch: 94 | Iteration number: [2660/4518] 58% | Training loss: 0.6870286536620076
Epoch: 94 | Iteration number: [2670/4518] 59% | Training loss: 0.6870247572772066
Epoch: 94 | Iteration number: [2680/4518] 59% | Training loss: 0.6870231641984698
Epoch: 94 | Iteration number: [2690/4518] 59% | Training loss: 0.6870208799395863
Epoch: 94 | Iteration number: [2700/4518] 59% | Training loss: 0.6870208578198045
Epoch: 94 | Iteration number: [2710/4518] 59% | Training loss: 0.6870217385547187
Epoch: 94 | Iteration number: [2720/4518] 60% | Training loss: 0.6870257613194339
Epoch: 94 | Iteration number: [2730/4518] 60% | Training loss: 0.687026810842556
Epoch: 94 | Iteration number: [2740/4518] 60% | Training loss: 0.6870243756005364
Epoch: 94 | Iteration number: [2750/4518] 60% | Training loss: 0.6870227286598899
Epoch: 94 | Iteration number: [2760/4518] 61% | Training loss: 0.6870192989275076
Epoch: 94 | Iteration number: [2770/4518] 61% | Training loss: 0.6870180614803673
Epoch: 94 | Iteration number: [2780/4518] 61% | Training loss: 0.6870168991869302
Epoch: 94 | Iteration number: [2790/4518] 61% | Training loss: 0.6870188409923226
Epoch: 94 | Iteration number: [2800/4518] 61% | Training loss: 0.6870210040679999
Epoch: 94 | Iteration number: [2810/4518] 62% | Training loss: 0.6870180381574664
Epoch: 94 | Iteration number: [2820/4518] 62% | Training loss: 0.6870148284426818
Epoch: 94 | Iteration number: [2830/4518] 62% | Training loss: 0.6870138852629982
Epoch: 94 | Iteration number: [2840/4518] 62% | Training loss: 0.6870107829360895
Epoch: 94 | Iteration number: [2850/4518] 63% | Training loss: 0.6870087230205536
Epoch: 94 | Iteration number: [2860/4518] 63% | Training loss: 0.6870046736060322
Epoch: 94 | Iteration number: [2870/4518] 63% | Training loss: 0.6870094241165533
Epoch: 94 | Iteration number: [2880/4518] 63% | Training loss: 0.6870065156163441
Epoch: 94 | Iteration number: [2890/4518] 63% | Training loss: 0.6870055261367745
Epoch: 94 | Iteration number: [2900/4518] 64% | Training loss: 0.687001410496646
Epoch: 94 | Iteration number: [2910/4518] 64% | Training loss: 0.6869996466997154
Epoch: 94 | Iteration number: [2920/4518] 64% | Training loss: 0.6870011680134355
Epoch: 94 | Iteration number: [2930/4518] 64% | Training loss: 0.6870010553569924
Epoch: 94 | Iteration number: [2940/4518] 65% | Training loss: 0.6869950310105369
Epoch: 94 | Iteration number: [2950/4518] 65% | Training loss: 0.686995815058886
Epoch: 94 | Iteration number: [2960/4518] 65% | Training loss: 0.686991907777013
Epoch: 94 | Iteration number: [2970/4518] 65% | Training loss: 0.6869953731294433
Epoch: 94 | Iteration number: [2980/4518] 65% | Training loss: 0.6869911753691282
Epoch: 94 | Iteration number: [2990/4518] 66% | Training loss: 0.6869919208778585
Epoch: 94 | Iteration number: [3000/4518] 66% | Training loss: 0.6869911864797275
Epoch: 94 | Iteration number: [3010/4518] 66% | Training loss: 0.6869886639506317
Epoch: 94 | Iteration number: [3020/4518] 66% | Training loss: 0.6869896021505065
Epoch: 94 | Iteration number: [3030/4518] 67% | Training loss: 0.6869876166971604
Epoch: 94 | Iteration number: [3040/4518] 67% | Training loss: 0.6869883294560407
Epoch: 94 | Iteration number: [3050/4518] 67% | Training loss: 0.6869884229683485
Epoch: 94 | Iteration number: [3060/4518] 67% | Training loss: 0.6869897858379713
Epoch: 94 | Iteration number: [3070/4518] 67% | Training loss: 0.6869882158425421
Epoch: 94 | Iteration number: [3080/4518] 68% | Training loss: 0.6869874116081696
Epoch: 94 | Iteration number: [3090/4518] 68% | Training loss: 0.6869856623191278
Epoch: 94 | Iteration number: [3100/4518] 68% | Training loss: 0.686986358992515
Epoch: 94 | Iteration number: [3110/4518] 68% | Training loss: 0.6869875608916451
Epoch: 94 | Iteration number: [3120/4518] 69% | Training loss: 0.6869853412493682
Epoch: 94 | Iteration number: [3130/4518] 69% | Training loss: 0.6869862575500537
Epoch: 94 | Iteration number: [3140/4518] 69% | Training loss: 0.6869840583983501
Epoch: 94 | Iteration number: [3150/4518] 69% | Training loss: 0.686982542030395
Epoch: 94 | Iteration number: [3160/4518] 69% | Training loss: 0.6869808400922184
Epoch: 94 | Iteration number: [3170/4518] 70% | Training loss: 0.6869832798133513
Epoch: 94 | Iteration number: [3180/4518] 70% | Training loss: 0.6869853612761827
Epoch: 94 | Iteration number: [3190/4518] 70% | Training loss: 0.6869903832020057
Epoch: 94 | Iteration number: [3200/4518] 70% | Training loss: 0.6869897763617336
Epoch: 94 | Iteration number: [3210/4518] 71% | Training loss: 0.686991294095078
Epoch: 94 | Iteration number: [3220/4518] 71% | Training loss: 0.6869915366172791
Epoch: 94 | Iteration number: [3230/4518] 71% | Training loss: 0.6869880973001014
Epoch: 94 | Iteration number: [3240/4518] 71% | Training loss: 0.6869880261980457
Epoch: 94 | Iteration number: [3250/4518] 71% | Training loss: 0.686985916192715
Epoch: 94 | Iteration number: [3260/4518] 72% | Training loss: 0.6869853651413889
Epoch: 94 | Iteration number: [3270/4518] 72% | Training loss: 0.6869866876609464
Epoch: 94 | Iteration number: [3280/4518] 72% | Training loss: 0.6869881166008914
Epoch: 94 | Iteration number: [3290/4518] 72% | Training loss: 0.6869916094110368
Epoch: 94 | Iteration number: [3300/4518] 73% | Training loss: 0.6869847491835103
Epoch: 94 | Iteration number: [3310/4518] 73% | Training loss: 0.6869846063258065
Epoch: 94 | Iteration number: [3320/4518] 73% | Training loss: 0.6869833747486034
Epoch: 94 | Iteration number: [3330/4518] 73% | Training loss: 0.6869800845423977
Epoch: 94 | Iteration number: [3340/4518] 73% | Training loss: 0.686978380141144
Epoch: 94 | Iteration number: [3350/4518] 74% | Training loss: 0.68697567952213
Epoch: 94 | Iteration number: [3360/4518] 74% | Training loss: 0.6869755717970076
Epoch: 94 | Iteration number: [3370/4518] 74% | Training loss: 0.6869707293255747
Epoch: 94 | Iteration number: [3380/4518] 74% | Training loss: 0.6869715216420811
Epoch: 94 | Iteration number: [3390/4518] 75% | Training loss: 0.6869695218790949
Epoch: 94 | Iteration number: [3400/4518] 75% | Training loss: 0.6869703059512026
Epoch: 94 | Iteration number: [3410/4518] 75% | Training loss: 0.6869727738791547
Epoch: 94 | Iteration number: [3420/4518] 75% | Training loss: 0.6869733637536478
Epoch: 94 | Iteration number: [3430/4518] 75% | Training loss: 0.6869754354043187
Epoch: 94 | Iteration number: [3440/4518] 76% | Training loss: 0.6869735322892666
Epoch: 94 | Iteration number: [3450/4518] 76% | Training loss: 0.6869737417456032
Epoch: 94 | Iteration number: [3460/4518] 76% | Training loss: 0.6869719773875496
Epoch: 94 | Iteration number: [3470/4518] 76% | Training loss: 0.6869742798873946
Epoch: 94 | Iteration number: [3480/4518] 77% | Training loss: 0.6869721712394693
Epoch: 94 | Iteration number: [3490/4518] 77% | Training loss: 0.686972079560545
Epoch: 94 | Iteration number: [3500/4518] 77% | Training loss: 0.6869725391864777
Epoch: 94 | Iteration number: [3510/4518] 77% | Training loss: 0.6869723903827178
Epoch: 94 | Iteration number: [3520/4518] 77% | Training loss: 0.6869707249612971
Epoch: 94 | Iteration number: [3530/4518] 78% | Training loss: 0.6869686469646756
Epoch: 94 | Iteration number: [3540/4518] 78% | Training loss: 0.6869677939152313
Epoch: 94 | Iteration number: [3550/4518] 78% | Training loss: 0.6869701467937147
Epoch: 94 | Iteration number: [3560/4518] 78% | Training loss: 0.6869700869649984
Epoch: 94 | Iteration number: [3570/4518] 79% | Training loss: 0.68696386840831
Epoch: 94 | Iteration number: [3580/4518] 79% | Training loss: 0.6869604889740492
Epoch: 94 | Iteration number: [3590/4518] 79% | Training loss: 0.6869578525880585
Epoch: 94 | Iteration number: [3600/4518] 79% | Training loss: 0.6869606098863814
Epoch: 94 | Iteration number: [3610/4518] 79% | Training loss: 0.6869581942082772
Epoch: 94 | Iteration number: [3620/4518] 80% | Training loss: 0.6869580294051881
Epoch: 94 | Iteration number: [3630/4518] 80% | Training loss: 0.6869542661284612
Epoch: 94 | Iteration number: [3640/4518] 80% | Training loss: 0.6869513917919043
Epoch: 94 | Iteration number: [3650/4518] 80% | Training loss: 0.6869515484653107
Epoch: 94 | Iteration number: [3660/4518] 81% | Training loss: 0.6869480449156683
Epoch: 94 | Iteration number: [3670/4518] 81% | Training loss: 0.6869463989455303
Epoch: 94 | Iteration number: [3680/4518] 81% | Training loss: 0.6869475127886171
Epoch: 94 | Iteration number: [3690/4518] 81% | Training loss: 0.6869482968234757
Epoch: 94 | Iteration number: [3700/4518] 81% | Training loss: 0.6869481290514404
Epoch: 94 | Iteration number: [3710/4518] 82% | Training loss: 0.6869462834696243
Epoch: 94 | Iteration number: [3720/4518] 82% | Training loss: 0.6869436642495534
Epoch: 94 | Iteration number: [3730/4518] 82% | Training loss: 0.6869375790731517
Epoch: 94 | Iteration number: [3740/4518] 82% | Training loss: 0.6869366240533278
Epoch: 94 | Iteration number: [3750/4518] 83% | Training loss: 0.6869363068898519
Epoch: 94 | Iteration number: [3760/4518] 83% | Training loss: 0.6869347900310729
Epoch: 94 | Iteration number: [3770/4518] 83% | Training loss: 0.686938124657942
Epoch: 94 | Iteration number: [3780/4518] 83% | Training loss: 0.6869373116701368
Epoch: 94 | Iteration number: [3790/4518] 83% | Training loss: 0.6869354400911558
Epoch: 94 | Iteration number: [3800/4518] 84% | Training loss: 0.6869371818555029
Epoch: 94 | Iteration number: [3810/4518] 84% | Training loss: 0.6869392538477429
Epoch: 94 | Iteration number: [3820/4518] 84% | Training loss: 0.6869373974687766
Epoch: 94 | Iteration number: [3830/4518] 84% | Training loss: 0.6869408331558536
Epoch: 94 | Iteration number: [3840/4518] 84% | Training loss: 0.6869380799587816
Epoch: 94 | Iteration number: [3850/4518] 85% | Training loss: 0.6869407857238472
Epoch: 94 | Iteration number: [3860/4518] 85% | Training loss: 0.6869417672175817
Epoch: 94 | Iteration number: [3870/4518] 85% | Training loss: 0.6869448616677168
Epoch: 94 | Iteration number: [3880/4518] 85% | Training loss: 0.6869411631343291
Epoch: 94 | Iteration number: [3890/4518] 86% | Training loss: 0.686940607466857
Epoch: 94 | Iteration number: [3900/4518] 86% | Training loss: 0.686939410276902
Epoch: 94 | Iteration number: [3910/4518] 86% | Training loss: 0.686942130555887
Epoch: 94 | Iteration number: [3920/4518] 86% | Training loss: 0.6869438480205682
Epoch: 94 | Iteration number: [3930/4518] 86% | Training loss: 0.6869466121870142
Epoch: 94 | Iteration number: [3940/4518] 87% | Training loss: 0.6869440656628101
Epoch: 94 | Iteration number: [3950/4518] 87% | Training loss: 0.6869392331642441
Epoch: 94 | Iteration number: [3960/4518] 87% | Training loss: 0.6869362283385161
Epoch: 94 | Iteration number: [3970/4518] 87% | Training loss: 0.6869309535104622
Epoch: 94 | Iteration number: [3980/4518] 88% | Training loss: 0.6869250014499204
Epoch: 94 | Iteration number: [3990/4518] 88% | Training loss: 0.6869271837529682
Epoch: 94 | Iteration number: [4000/4518] 88% | Training loss: 0.6869246896207333
Epoch: 94 | Iteration number: [4010/4518] 88% | Training loss: 0.6869252589426731
Epoch: 94 | Iteration number: [4020/4518] 88% | Training loss: 0.6869234407719095
Epoch: 94 | Iteration number: [4030/4518] 89% | Training loss: 0.6869217413530752
Epoch: 94 | Iteration number: [4040/4518] 89% | Training loss: 0.686921806456429
Epoch: 94 | Iteration number: [4050/4518] 89% | Training loss: 0.6869223160949754
Epoch: 94 | Iteration number: [4060/4518] 89% | Training loss: 0.6869205628416221
Epoch: 94 | Iteration number: [4070/4518] 90% | Training loss: 0.6869181606195482
Epoch: 94 | Iteration number: [4080/4518] 90% | Training loss: 0.6869172395444384
Epoch: 94 | Iteration number: [4090/4518] 90% | Training loss: 0.6869167819728478
Epoch: 94 | Iteration number: [4100/4518] 90% | Training loss: 0.6869185347091861
Epoch: 94 | Iteration number: [4110/4518] 90% | Training loss: 0.6869165273768478
Epoch: 94 | Iteration number: [4120/4518] 91% | Training loss: 0.6869143554741897
Epoch: 94 | Iteration number: [4130/4518] 91% | Training loss: 0.6869157809610805
Epoch: 94 | Iteration number: [4140/4518] 91% | Training loss: 0.6869175621276893
Epoch: 94 | Iteration number: [4150/4518] 91% | Training loss: 0.6869167347844825
Epoch: 94 | Iteration number: [4160/4518] 92% | Training loss: 0.6869156056012099
Epoch: 94 | Iteration number: [4170/4518] 92% | Training loss: 0.6869163640254408
Epoch: 94 | Iteration number: [4180/4518] 92% | Training loss: 0.6869186957059294
Epoch: 94 | Iteration number: [4190/4518] 92% | Training loss: 0.6869130288501912
Epoch: 94 | Iteration number: [4200/4518] 92% | Training loss: 0.686913745701313
Epoch: 94 | Iteration number: [4210/4518] 93% | Training loss: 0.6869127188895491
Epoch: 94 | Iteration number: [4220/4518] 93% | Training loss: 0.6869119402780351
Epoch: 94 | Iteration number: [4230/4518] 93% | Training loss: 0.6869124368150183
Epoch: 94 | Iteration number: [4240/4518] 93% | Training loss: 0.6869084315620503
Epoch: 94 | Iteration number: [4250/4518] 94% | Training loss: 0.6869070417881012
Epoch: 94 | Iteration number: [4260/4518] 94% | Training loss: 0.6869087544265488
Epoch: 94 | Iteration number: [4270/4518] 94% | Training loss: 0.6869089508642916
Epoch: 94 | Iteration number: [4280/4518] 94% | Training loss: 0.6869102154101167
Epoch: 94 | Iteration number: [4290/4518] 94% | Training loss: 0.6869123955567678
Epoch: 94 | Iteration number: [4300/4518] 95% | Training loss: 0.6869133913101152
Epoch: 94 | Iteration number: [4310/4518] 95% | Training loss: 0.686913742861449
Epoch: 94 | Iteration number: [4320/4518] 95% | Training loss: 0.6869140533937348
Epoch: 94 | Iteration number: [4330/4518] 95% | Training loss: 0.6869144224129428
Epoch: 94 | Iteration number: [4340/4518] 96% | Training loss: 0.6869119309884612
Epoch: 94 | Iteration number: [4350/4518] 96% | Training loss: 0.6869109838447351
Epoch: 94 | Iteration number: [4360/4518] 96% | Training loss: 0.6869091303250111
Epoch: 94 | Iteration number: [4370/4518] 96% | Training loss: 0.686905789102515
Epoch: 94 | Iteration number: [4380/4518] 96% | Training loss: 0.6869055101316269
Epoch: 94 | Iteration number: [4390/4518] 97% | Training loss: 0.6869027864688622
Epoch: 94 | Iteration number: [4400/4518] 97% | Training loss: 0.6869063644923947
Epoch: 94 | Iteration number: [4410/4518] 97% | Training loss: 0.6869022779859383
Epoch: 94 | Iteration number: [4420/4518] 97% | Training loss: 0.6869021938667038
Epoch: 94 | Iteration number: [4430/4518] 98% | Training loss: 0.6869036428815355
Epoch: 94 | Iteration number: [4440/4518] 98% | Training loss: 0.6869020169651187
Epoch: 94 | Iteration number: [4450/4518] 98% | Training loss: 0.6869015736794204
Epoch: 94 | Iteration number: [4460/4518] 98% | Training loss: 0.6869031022215103
Epoch: 94 | Iteration number: [4470/4518] 98% | Training loss: 0.6869007468623602
Epoch: 94 | Iteration number: [4480/4518] 99% | Training loss: 0.6869023524889989
Epoch: 94 | Iteration number: [4490/4518] 99% | Training loss: 0.6869015632599659
Epoch: 94 | Iteration number: [4500/4518] 99% | Training loss: 0.6869017163647546
Epoch: 94 | Iteration number: [4510/4518] 99% | Training loss: 0.6869023656237152

 End of epoch: 94 | Train Loss: 0.6867480424981879 | Training Time: 632 

 End of epoch: 94 | Eval Loss: 0.6895418386070096 | Evaluating Time: 17 
Epoch: 95 | Iteration number: [10/4518] 0% | Training loss: 0.7550797045230866
Epoch: 95 | Iteration number: [20/4518] 0% | Training loss: 0.7213663130998611
Epoch: 95 | Iteration number: [30/4518] 0% | Training loss: 0.7100600898265839
Epoch: 95 | Iteration number: [40/4518] 0% | Training loss: 0.7040997624397278
Epoch: 95 | Iteration number: [50/4518] 1% | Training loss: 0.7007092344760895
Epoch: 95 | Iteration number: [60/4518] 1% | Training loss: 0.6985046863555908
Epoch: 95 | Iteration number: [70/4518] 1% | Training loss: 0.6968992940017156
Epoch: 95 | Iteration number: [80/4518] 1% | Training loss: 0.6955668412148952
Epoch: 95 | Iteration number: [90/4518] 1% | Training loss: 0.6945372237099542
Epoch: 95 | Iteration number: [100/4518] 2% | Training loss: 0.6937179040908813
Epoch: 95 | Iteration number: [110/4518] 2% | Training loss: 0.6930827552622015
Epoch: 95 | Iteration number: [120/4518] 2% | Training loss: 0.6924688597520192
Epoch: 95 | Iteration number: [130/4518] 2% | Training loss: 0.6920255679350633
Epoch: 95 | Iteration number: [140/4518] 3% | Training loss: 0.6916701474360057
Epoch: 95 | Iteration number: [150/4518] 3% | Training loss: 0.6913790186246236
Epoch: 95 | Iteration number: [160/4518] 3% | Training loss: 0.691110673174262
Epoch: 95 | Iteration number: [170/4518] 3% | Training loss: 0.6909486072904923
Epoch: 95 | Iteration number: [180/4518] 3% | Training loss: 0.6907730493280623
Epoch: 95 | Iteration number: [190/4518] 4% | Training loss: 0.6905456292001825
Epoch: 95 | Iteration number: [200/4518] 4% | Training loss: 0.6903868880867958
Epoch: 95 | Iteration number: [210/4518] 4% | Training loss: 0.6901628184886206
Epoch: 95 | Iteration number: [220/4518] 4% | Training loss: 0.6900193252346732
Epoch: 95 | Iteration number: [230/4518] 5% | Training loss: 0.6898718149765678
Epoch: 95 | Iteration number: [240/4518] 5% | Training loss: 0.6897451410690943
Epoch: 95 | Iteration number: [250/4518] 5% | Training loss: 0.689692625284195
Epoch: 95 | Iteration number: [260/4518] 5% | Training loss: 0.689556647493289
Epoch: 95 | Iteration number: [270/4518] 5% | Training loss: 0.6894385766100001
Epoch: 95 | Iteration number: [280/4518] 6% | Training loss: 0.6893271195037024
Epoch: 95 | Iteration number: [290/4518] 6% | Training loss: 0.68921940347244
Epoch: 95 | Iteration number: [300/4518] 6% | Training loss: 0.6891177692015966
Epoch: 95 | Iteration number: [310/4518] 6% | Training loss: 0.689078180636129
Epoch: 95 | Iteration number: [320/4518] 7% | Training loss: 0.6890577865764499
Epoch: 95 | Iteration number: [330/4518] 7% | Training loss: 0.6890071332454681
Epoch: 95 | Iteration number: [340/4518] 7% | Training loss: 0.6889083406504463
Epoch: 95 | Iteration number: [350/4518] 7% | Training loss: 0.6888296750613622
Epoch: 95 | Iteration number: [360/4518] 7% | Training loss: 0.688809102276961
Epoch: 95 | Iteration number: [370/4518] 8% | Training loss: 0.6887562215328217
Epoch: 95 | Iteration number: [380/4518] 8% | Training loss: 0.6886760325808274
Epoch: 95 | Iteration number: [390/4518] 8% | Training loss: 0.6886028601573064
Epoch: 95 | Iteration number: [400/4518] 8% | Training loss: 0.6885233433544635
Epoch: 95 | Iteration number: [410/4518] 9% | Training loss: 0.6884793765661193
Epoch: 95 | Iteration number: [420/4518] 9% | Training loss: 0.6884588634683972
Epoch: 95 | Iteration number: [430/4518] 9% | Training loss: 0.6884133605069892
Epoch: 95 | Iteration number: [440/4518] 9% | Training loss: 0.688380811295726
Epoch: 95 | Iteration number: [450/4518] 9% | Training loss: 0.688331525988049
Epoch: 95 | Iteration number: [460/4518] 10% | Training loss: 0.6882941016684407
Epoch: 95 | Iteration number: [470/4518] 10% | Training loss: 0.6882781524607475
Epoch: 95 | Iteration number: [480/4518] 10% | Training loss: 0.6882268191625674
Epoch: 95 | Iteration number: [490/4518] 10% | Training loss: 0.6882195559083198
Epoch: 95 | Iteration number: [500/4518] 11% | Training loss: 0.6881975736618042
Epoch: 95 | Iteration number: [510/4518] 11% | Training loss: 0.6881811626985961
Epoch: 95 | Iteration number: [520/4518] 11% | Training loss: 0.6881407721684529
Epoch: 95 | Iteration number: [530/4518] 11% | Training loss: 0.688129323720932
Epoch: 95 | Iteration number: [540/4518] 11% | Training loss: 0.6880916401191994
Epoch: 95 | Iteration number: [550/4518] 12% | Training loss: 0.6880536453290419
Epoch: 95 | Iteration number: [560/4518] 12% | Training loss: 0.688010724740369
Epoch: 95 | Iteration number: [570/4518] 12% | Training loss: 0.687997765708388
Epoch: 95 | Iteration number: [580/4518] 12% | Training loss: 0.6879700049244124
Epoch: 95 | Iteration number: [590/4518] 13% | Training loss: 0.6879359950453549
Epoch: 95 | Iteration number: [600/4518] 13% | Training loss: 0.6879304851094882
Epoch: 95 | Iteration number: [610/4518] 13% | Training loss: 0.6879047119226612
Epoch: 95 | Iteration number: [620/4518] 13% | Training loss: 0.6878913991874264
Epoch: 95 | Iteration number: [630/4518] 13% | Training loss: 0.6878741002272046
Epoch: 95 | Iteration number: [640/4518] 14% | Training loss: 0.6878629296086729
Epoch: 95 | Iteration number: [650/4518] 14% | Training loss: 0.6878493076104384
Epoch: 95 | Iteration number: [660/4518] 14% | Training loss: 0.687845661333113
Epoch: 95 | Iteration number: [670/4518] 14% | Training loss: 0.6878338664325315
Epoch: 95 | Iteration number: [680/4518] 15% | Training loss: 0.6878089921439395
Epoch: 95 | Iteration number: [690/4518] 15% | Training loss: 0.6877784678901451
Epoch: 95 | Iteration number: [700/4518] 15% | Training loss: 0.6877611872128078
Epoch: 95 | Iteration number: [710/4518] 15% | Training loss: 0.6877552296913846
Epoch: 95 | Iteration number: [720/4518] 15% | Training loss: 0.6877344669567214
Epoch: 95 | Iteration number: [730/4518] 16% | Training loss: 0.6877494995724664
Epoch: 95 | Iteration number: [740/4518] 16% | Training loss: 0.6877369800129453
Epoch: 95 | Iteration number: [750/4518] 16% | Training loss: 0.6877349215348562
Epoch: 95 | Iteration number: [760/4518] 16% | Training loss: 0.687707434045641
Epoch: 95 | Iteration number: [770/4518] 17% | Training loss: 0.6876987063265466
Epoch: 95 | Iteration number: [780/4518] 17% | Training loss: 0.6876884273229501
Epoch: 95 | Iteration number: [790/4518] 17% | Training loss: 0.6876653334007987
Epoch: 95 | Iteration number: [800/4518] 17% | Training loss: 0.6876463782042265
Epoch: 95 | Iteration number: [810/4518] 17% | Training loss: 0.6876182401621783
Epoch: 95 | Iteration number: [820/4518] 18% | Training loss: 0.6875952105696609
Epoch: 95 | Iteration number: [830/4518] 18% | Training loss: 0.687600452497781
Epoch: 95 | Iteration number: [840/4518] 18% | Training loss: 0.6875913289331255
Epoch: 95 | Iteration number: [850/4518] 18% | Training loss: 0.6875810993418974
Epoch: 95 | Iteration number: [860/4518] 19% | Training loss: 0.6875568082166272
Epoch: 95 | Iteration number: [870/4518] 19% | Training loss: 0.6875379989201995
Epoch: 95 | Iteration number: [880/4518] 19% | Training loss: 0.6875211129134352
Epoch: 95 | Iteration number: [890/4518] 19% | Training loss: 0.6875154368663102
Epoch: 95 | Iteration number: [900/4518] 19% | Training loss: 0.6875008133384917
Epoch: 95 | Iteration number: [910/4518] 20% | Training loss: 0.6875023231401548
Epoch: 95 | Iteration number: [920/4518] 20% | Training loss: 0.6874839913585912
Epoch: 95 | Iteration number: [930/4518] 20% | Training loss: 0.6874779400005135
Epoch: 95 | Iteration number: [940/4518] 20% | Training loss: 0.6874721366674342
Epoch: 95 | Iteration number: [950/4518] 21% | Training loss: 0.6874550956173947
Epoch: 95 | Iteration number: [960/4518] 21% | Training loss: 0.6874544651558002
Epoch: 95 | Iteration number: [970/4518] 21% | Training loss: 0.6874539331677034
Epoch: 95 | Iteration number: [980/4518] 21% | Training loss: 0.6874451946239082
Epoch: 95 | Iteration number: [990/4518] 21% | Training loss: 0.6874476276864909
Epoch: 95 | Iteration number: [1000/4518] 22% | Training loss: 0.6874365226626397
Epoch: 95 | Iteration number: [1010/4518] 22% | Training loss: 0.6874304073871953
Epoch: 95 | Iteration number: [1020/4518] 22% | Training loss: 0.6874167021583109
Epoch: 95 | Iteration number: [1030/4518] 22% | Training loss: 0.6874033029797008
Epoch: 95 | Iteration number: [1040/4518] 23% | Training loss: 0.6873797099750776
Epoch: 95 | Iteration number: [1050/4518] 23% | Training loss: 0.6873737316472189
Epoch: 95 | Iteration number: [1060/4518] 23% | Training loss: 0.687383021836011
Epoch: 95 | Iteration number: [1070/4518] 23% | Training loss: 0.6873694113481824
Epoch: 95 | Iteration number: [1080/4518] 23% | Training loss: 0.6873695098691517
Epoch: 95 | Iteration number: [1090/4518] 24% | Training loss: 0.6873751442366783
Epoch: 95 | Iteration number: [1100/4518] 24% | Training loss: 0.687362531802871
Epoch: 95 | Iteration number: [1110/4518] 24% | Training loss: 0.6873453940894153
Epoch: 95 | Iteration number: [1120/4518] 24% | Training loss: 0.6873321685407843
Epoch: 95 | Iteration number: [1130/4518] 25% | Training loss: 0.6873292321652438
Epoch: 95 | Iteration number: [1140/4518] 25% | Training loss: 0.6873214800629699
Epoch: 95 | Iteration number: [1150/4518] 25% | Training loss: 0.6873186238952305
Epoch: 95 | Iteration number: [1160/4518] 25% | Training loss: 0.6873064860701561
Epoch: 95 | Iteration number: [1170/4518] 25% | Training loss: 0.6873076819456541
Epoch: 95 | Iteration number: [1180/4518] 26% | Training loss: 0.687301415103977
Epoch: 95 | Iteration number: [1190/4518] 26% | Training loss: 0.6873034814325701
Epoch: 95 | Iteration number: [1200/4518] 26% | Training loss: 0.6872916554907957
Epoch: 95 | Iteration number: [1210/4518] 26% | Training loss: 0.6872912475885439
Epoch: 95 | Iteration number: [1220/4518] 27% | Training loss: 0.6872821262136835
Epoch: 95 | Iteration number: [1230/4518] 27% | Training loss: 0.6872682525375025
Epoch: 95 | Iteration number: [1240/4518] 27% | Training loss: 0.6872750036658779
Epoch: 95 | Iteration number: [1250/4518] 27% | Training loss: 0.6872778403282166
Epoch: 95 | Iteration number: [1260/4518] 27% | Training loss: 0.68727801995618
Epoch: 95 | Iteration number: [1270/4518] 28% | Training loss: 0.6872726382702354
Epoch: 95 | Iteration number: [1280/4518] 28% | Training loss: 0.6872653040569275
Epoch: 95 | Iteration number: [1290/4518] 28% | Training loss: 0.6872647934181746
Epoch: 95 | Iteration number: [1300/4518] 28% | Training loss: 0.6872742216862165
Epoch: 95 | Iteration number: [1310/4518] 28% | Training loss: 0.6872787673964755
Epoch: 95 | Iteration number: [1320/4518] 29% | Training loss: 0.6872774694002036
Epoch: 95 | Iteration number: [1330/4518] 29% | Training loss: 0.6872764907833329
Epoch: 95 | Iteration number: [1340/4518] 29% | Training loss: 0.6872737149249262
Epoch: 95 | Iteration number: [1350/4518] 29% | Training loss: 0.6872622137158005
Epoch: 95 | Iteration number: [1360/4518] 30% | Training loss: 0.6872635514858891
Epoch: 95 | Iteration number: [1370/4518] 30% | Training loss: 0.6872695828006216
Epoch: 95 | Iteration number: [1380/4518] 30% | Training loss: 0.6872610434673835
Epoch: 95 | Iteration number: [1390/4518] 30% | Training loss: 0.6872521309543856
Epoch: 95 | Iteration number: [1400/4518] 30% | Training loss: 0.6872480600646564
Epoch: 95 | Iteration number: [1410/4518] 31% | Training loss: 0.6872515392641649
Epoch: 95 | Iteration number: [1420/4518] 31% | Training loss: 0.6872385148850965
Epoch: 95 | Iteration number: [1430/4518] 31% | Training loss: 0.6872267335028082
Epoch: 95 | Iteration number: [1440/4518] 31% | Training loss: 0.6872272050629059
Epoch: 95 | Iteration number: [1450/4518] 32% | Training loss: 0.6872212322827044
Epoch: 95 | Iteration number: [1460/4518] 32% | Training loss: 0.6872180684380336
Epoch: 95 | Iteration number: [1470/4518] 32% | Training loss: 0.6872148455405722
Epoch: 95 | Iteration number: [1480/4518] 32% | Training loss: 0.6872155103329066
Epoch: 95 | Iteration number: [1490/4518] 32% | Training loss: 0.6872129671925666
Epoch: 95 | Iteration number: [1500/4518] 33% | Training loss: 0.6872042003472646
Epoch: 95 | Iteration number: [1510/4518] 33% | Training loss: 0.687203403892896
Epoch: 95 | Iteration number: [1520/4518] 33% | Training loss: 0.6872025427457533
Epoch: 95 | Iteration number: [1530/4518] 33% | Training loss: 0.6871980904364119
Epoch: 95 | Iteration number: [1540/4518] 34% | Training loss: 0.687197391979106
Epoch: 95 | Iteration number: [1550/4518] 34% | Training loss: 0.6872008741286493
Epoch: 95 | Iteration number: [1560/4518] 34% | Training loss: 0.6871897225196545
Epoch: 95 | Iteration number: [1570/4518] 34% | Training loss: 0.68718624737612
Epoch: 95 | Iteration number: [1580/4518] 34% | Training loss: 0.6871869416553763
Epoch: 95 | Iteration number: [1590/4518] 35% | Training loss: 0.687178517250145
Epoch: 95 | Iteration number: [1600/4518] 35% | Training loss: 0.6871768048778176
Epoch: 95 | Iteration number: [1610/4518] 35% | Training loss: 0.6871789321025706
Epoch: 95 | Iteration number: [1620/4518] 35% | Training loss: 0.6871697326869141
Epoch: 95 | Iteration number: [1630/4518] 36% | Training loss: 0.6871704022942876
Epoch: 95 | Iteration number: [1640/4518] 36% | Training loss: 0.6871633239635607
Epoch: 95 | Iteration number: [1650/4518] 36% | Training loss: 0.6871622520865817
Epoch: 95 | Iteration number: [1660/4518] 36% | Training loss: 0.6871499587613416
Epoch: 95 | Iteration number: [1670/4518] 36% | Training loss: 0.6871437449298219
Epoch: 95 | Iteration number: [1680/4518] 37% | Training loss: 0.687144056352831
Epoch: 95 | Iteration number: [1690/4518] 37% | Training loss: 0.6871340441985948
Epoch: 95 | Iteration number: [1700/4518] 37% | Training loss: 0.6871297421525506
Epoch: 95 | Iteration number: [1710/4518] 37% | Training loss: 0.6871286679429618
Epoch: 95 | Iteration number: [1720/4518] 38% | Training loss: 0.6871227722874907
Epoch: 95 | Iteration number: [1730/4518] 38% | Training loss: 0.6871319800443043
Epoch: 95 | Iteration number: [1740/4518] 38% | Training loss: 0.6871301092293071
Epoch: 95 | Iteration number: [1750/4518] 38% | Training loss: 0.6871298245702471
Epoch: 95 | Iteration number: [1760/4518] 38% | Training loss: 0.6871239128437909
Epoch: 95 | Iteration number: [1770/4518] 39% | Training loss: 0.6871194605099953
Epoch: 95 | Iteration number: [1780/4518] 39% | Training loss: 0.6871131159951178
Epoch: 95 | Iteration number: [1790/4518] 39% | Training loss: 0.6871164027539045
Epoch: 95 | Iteration number: [1800/4518] 39% | Training loss: 0.6871102950970331
Epoch: 95 | Iteration number: [1810/4518] 40% | Training loss: 0.6871093391384209
Epoch: 95 | Iteration number: [1820/4518] 40% | Training loss: 0.6871082134299226
Epoch: 95 | Iteration number: [1830/4518] 40% | Training loss: 0.6871083295736157
Epoch: 95 | Iteration number: [1840/4518] 40% | Training loss: 0.687101285872252
Epoch: 95 | Iteration number: [1850/4518] 40% | Training loss: 0.6871002763348657
Epoch: 95 | Iteration number: [1860/4518] 41% | Training loss: 0.6870943795288763
Epoch: 95 | Iteration number: [1870/4518] 41% | Training loss: 0.6870948874695416
Epoch: 95 | Iteration number: [1880/4518] 41% | Training loss: 0.6870909711147877
Epoch: 95 | Iteration number: [1890/4518] 41% | Training loss: 0.6870859479778028
Epoch: 95 | Iteration number: [1900/4518] 42% | Training loss: 0.6870816298848704
Epoch: 95 | Iteration number: [1910/4518] 42% | Training loss: 0.6870786860663229
Epoch: 95 | Iteration number: [1920/4518] 42% | Training loss: 0.6870801152351002
Epoch: 95 | Iteration number: [1930/4518] 42% | Training loss: 0.6870796813557185
Epoch: 95 | Iteration number: [1940/4518] 42% | Training loss: 0.687081851203417
Epoch: 95 | Iteration number: [1950/4518] 43% | Training loss: 0.6870844817467225
Epoch: 95 | Iteration number: [1960/4518] 43% | Training loss: 0.6870893981383771
Epoch: 95 | Iteration number: [1970/4518] 43% | Training loss: 0.6870878302808946
Epoch: 95 | Iteration number: [1980/4518] 43% | Training loss: 0.6870779119657747
Epoch: 95 | Iteration number: [1990/4518] 44% | Training loss: 0.6870738910969777
Epoch: 95 | Iteration number: [2000/4518] 44% | Training loss: 0.6870679574608802
Epoch: 95 | Iteration number: [2010/4518] 44% | Training loss: 0.6870758966130404
Epoch: 95 | Iteration number: [2020/4518] 44% | Training loss: 0.6870699771560065
Epoch: 95 | Iteration number: [2030/4518] 44% | Training loss: 0.6870590730547318
Epoch: 95 | Iteration number: [2040/4518] 45% | Training loss: 0.6870638040350933
Epoch: 95 | Iteration number: [2050/4518] 45% | Training loss: 0.6870600662580351
Epoch: 95 | Iteration number: [2060/4518] 45% | Training loss: 0.6870589262362823
Epoch: 95 | Iteration number: [2070/4518] 45% | Training loss: 0.6870512495870176
Epoch: 95 | Iteration number: [2080/4518] 46% | Training loss: 0.687046359708676
Epoch: 95 | Iteration number: [2090/4518] 46% | Training loss: 0.6870410397862704
Epoch: 95 | Iteration number: [2100/4518] 46% | Training loss: 0.6870402512096223
Epoch: 95 | Iteration number: [2110/4518] 46% | Training loss: 0.6870405831890649
Epoch: 95 | Iteration number: [2120/4518] 46% | Training loss: 0.6870454766559151
Epoch: 95 | Iteration number: [2130/4518] 47% | Training loss: 0.6870405192386376
Epoch: 95 | Iteration number: [2140/4518] 47% | Training loss: 0.6870388947357641
Epoch: 95 | Iteration number: [2150/4518] 47% | Training loss: 0.6870336765743965
Epoch: 95 | Iteration number: [2160/4518] 47% | Training loss: 0.6870325098711031
Epoch: 95 | Iteration number: [2170/4518] 48% | Training loss: 0.6870352198451345
Epoch: 95 | Iteration number: [2180/4518] 48% | Training loss: 0.6870349064606045
Epoch: 95 | Iteration number: [2190/4518] 48% | Training loss: 0.6870399729574108
Epoch: 95 | Iteration number: [2200/4518] 48% | Training loss: 0.6870373074845835
Epoch: 95 | Iteration number: [2210/4518] 48% | Training loss: 0.6870377836184264
Epoch: 95 | Iteration number: [2220/4518] 49% | Training loss: 0.6870372985665862
Epoch: 95 | Iteration number: [2230/4518] 49% | Training loss: 0.6870376089763214
Epoch: 95 | Iteration number: [2240/4518] 49% | Training loss: 0.6870355621512447
Epoch: 95 | Iteration number: [2250/4518] 49% | Training loss: 0.687030562294854
Epoch: 95 | Iteration number: [2260/4518] 50% | Training loss: 0.6870302289988087
Epoch: 95 | Iteration number: [2270/4518] 50% | Training loss: 0.6870302900868891
Epoch: 95 | Iteration number: [2280/4518] 50% | Training loss: 0.6870355341779558
Epoch: 95 | Iteration number: [2290/4518] 50% | Training loss: 0.6870354145635164
Epoch: 95 | Iteration number: [2300/4518] 50% | Training loss: 0.6870390647649764
Epoch: 95 | Iteration number: [2310/4518] 51% | Training loss: 0.6870325537471028
Epoch: 95 | Iteration number: [2320/4518] 51% | Training loss: 0.6870298809532461
Epoch: 95 | Iteration number: [2330/4518] 51% | Training loss: 0.6870292776132346
Epoch: 95 | Iteration number: [2340/4518] 51% | Training loss: 0.6870248871226596
Epoch: 95 | Iteration number: [2350/4518] 52% | Training loss: 0.6870242244132022
Epoch: 95 | Iteration number: [2360/4518] 52% | Training loss: 0.6870235266321797
Epoch: 95 | Iteration number: [2370/4518] 52% | Training loss: 0.6870213963311432
Epoch: 95 | Iteration number: [2380/4518] 52% | Training loss: 0.687020609759483
Epoch: 95 | Iteration number: [2390/4518] 52% | Training loss: 0.68701938690002
Epoch: 95 | Iteration number: [2400/4518] 53% | Training loss: 0.6870197908828656
Epoch: 95 | Iteration number: [2410/4518] 53% | Training loss: 0.6870174114634882
Epoch: 95 | Iteration number: [2420/4518] 53% | Training loss: 0.6870134062264577
Epoch: 95 | Iteration number: [2430/4518] 53% | Training loss: 0.687008458719332
Epoch: 95 | Iteration number: [2440/4518] 54% | Training loss: 0.6870141676214875
Epoch: 95 | Iteration number: [2450/4518] 54% | Training loss: 0.6870158479165058
Epoch: 95 | Iteration number: [2460/4518] 54% | Training loss: 0.6870099808627028
Epoch: 95 | Iteration number: [2470/4518] 54% | Training loss: 0.6870064328556601
Epoch: 95 | Iteration number: [2480/4518] 54% | Training loss: 0.6870073061796926
Epoch: 95 | Iteration number: [2490/4518] 55% | Training loss: 0.687002908034497
Epoch: 95 | Iteration number: [2500/4518] 55% | Training loss: 0.6870046073913574
Epoch: 95 | Iteration number: [2510/4518] 55% | Training loss: 0.6870036681334811
Epoch: 95 | Iteration number: [2520/4518] 55% | Training loss: 0.6870012876769853
Epoch: 95 | Iteration number: [2530/4518] 55% | Training loss: 0.6870003633112776
Epoch: 95 | Iteration number: [2540/4518] 56% | Training loss: 0.6870002267398233
Epoch: 95 | Iteration number: [2550/4518] 56% | Training loss: 0.686997124377419
Epoch: 95 | Iteration number: [2560/4518] 56% | Training loss: 0.6869946516584605
Epoch: 95 | Iteration number: [2570/4518] 56% | Training loss: 0.6869953874252186
Epoch: 95 | Iteration number: [2580/4518] 57% | Training loss: 0.6869965866554615
Epoch: 95 | Iteration number: [2590/4518] 57% | Training loss: 0.6869953523501466
Epoch: 95 | Iteration number: [2600/4518] 57% | Training loss: 0.6869985859210674
Epoch: 95 | Iteration number: [2610/4518] 57% | Training loss: 0.6869972468107596
Epoch: 95 | Iteration number: [2620/4518] 57% | Training loss: 0.6869968903201227
Epoch: 95 | Iteration number: [2630/4518] 58% | Training loss: 0.6869965369937084
Epoch: 95 | Iteration number: [2640/4518] 58% | Training loss: 0.6869995533065363
Epoch: 95 | Iteration number: [2650/4518] 58% | Training loss: 0.6870017130644817
Epoch: 95 | Iteration number: [2660/4518] 58% | Training loss: 0.6870029440723864
Epoch: 95 | Iteration number: [2670/4518] 59% | Training loss: 0.6869986745971866
Epoch: 95 | Iteration number: [2680/4518] 59% | Training loss: 0.6869968034883044
Epoch: 95 | Iteration number: [2690/4518] 59% | Training loss: 0.6869971978841661
Epoch: 95 | Iteration number: [2700/4518] 59% | Training loss: 0.6869901319344839
Epoch: 95 | Iteration number: [2710/4518] 59% | Training loss: 0.6869840409702921
Epoch: 95 | Iteration number: [2720/4518] 60% | Training loss: 0.686986639876576
Epoch: 95 | Iteration number: [2730/4518] 60% | Training loss: 0.6869868732852377
Epoch: 95 | Iteration number: [2740/4518] 60% | Training loss: 0.686987389526228
Epoch: 95 | Iteration number: [2750/4518] 60% | Training loss: 0.6869866627779874
Epoch: 95 | Iteration number: [2760/4518] 61% | Training loss: 0.6869856621044269
Epoch: 95 | Iteration number: [2770/4518] 61% | Training loss: 0.6869847729748337
Epoch: 95 | Iteration number: [2780/4518] 61% | Training loss: 0.6869867472339877
Epoch: 95 | Iteration number: [2790/4518] 61% | Training loss: 0.6869829058006246
Epoch: 95 | Iteration number: [2800/4518] 61% | Training loss: 0.6869840189814568
Epoch: 95 | Iteration number: [2810/4518] 62% | Training loss: 0.6869830251800633
Epoch: 95 | Iteration number: [2820/4518] 62% | Training loss: 0.6869834938581953
Epoch: 95 | Iteration number: [2830/4518] 62% | Training loss: 0.6869865009515108
Epoch: 95 | Iteration number: [2840/4518] 62% | Training loss: 0.6869840510084595
Epoch: 95 | Iteration number: [2850/4518] 63% | Training loss: 0.6869775201144971
Epoch: 95 | Iteration number: [2860/4518] 63% | Training loss: 0.686973705158367
Epoch: 95 | Iteration number: [2870/4518] 63% | Training loss: 0.6869751866270856
Epoch: 95 | Iteration number: [2880/4518] 63% | Training loss: 0.686980045441952
Epoch: 95 | Iteration number: [2890/4518] 63% | Training loss: 0.6869793870457316
Epoch: 95 | Iteration number: [2900/4518] 64% | Training loss: 0.6869803894799331
Epoch: 95 | Iteration number: [2910/4518] 64% | Training loss: 0.6869790755596358
Epoch: 95 | Iteration number: [2920/4518] 64% | Training loss: 0.6869780766229107
Epoch: 95 | Iteration number: [2930/4518] 64% | Training loss: 0.6869792177408629
Epoch: 95 | Iteration number: [2940/4518] 65% | Training loss: 0.6869756625825856
Epoch: 95 | Iteration number: [2950/4518] 65% | Training loss: 0.6869716516793785
Epoch: 95 | Iteration number: [2960/4518] 65% | Training loss: 0.6869671410000002
Epoch: 95 | Iteration number: [2970/4518] 65% | Training loss: 0.6869652634116535
Epoch: 95 | Iteration number: [2980/4518] 65% | Training loss: 0.6869667502857695
Epoch: 95 | Iteration number: [2990/4518] 66% | Training loss: 0.6869671136240497
Epoch: 95 | Iteration number: [3000/4518] 66% | Training loss: 0.6869710400501887
Epoch: 95 | Iteration number: [3010/4518] 66% | Training loss: 0.6869675650549093
Epoch: 95 | Iteration number: [3020/4518] 66% | Training loss: 0.6869677667783586
Epoch: 95 | Iteration number: [3030/4518] 67% | Training loss: 0.6869684840586319
Epoch: 95 | Iteration number: [3040/4518] 67% | Training loss: 0.6869670501665065
Epoch: 95 | Iteration number: [3050/4518] 67% | Training loss: 0.6869700002474863
Epoch: 95 | Iteration number: [3060/4518] 67% | Training loss: 0.6869702360988442
Epoch: 95 | Iteration number: [3070/4518] 67% | Training loss: 0.686969860796043
Epoch: 95 | Iteration number: [3080/4518] 68% | Training loss: 0.6869705065697819
Epoch: 95 | Iteration number: [3090/4518] 68% | Training loss: 0.686970958374079
Epoch: 95 | Iteration number: [3100/4518] 68% | Training loss: 0.6869678284468189
Epoch: 95 | Iteration number: [3110/4518] 68% | Training loss: 0.6869705160714422
Epoch: 95 | Iteration number: [3120/4518] 69% | Training loss: 0.6869675930111836
Epoch: 95 | Iteration number: [3130/4518] 69% | Training loss: 0.6869681222560687
Epoch: 95 | Iteration number: [3140/4518] 69% | Training loss: 0.6869707786923002
Epoch: 95 | Iteration number: [3150/4518] 69% | Training loss: 0.6869728751788063
Epoch: 95 | Iteration number: [3160/4518] 69% | Training loss: 0.6869720918468282
Epoch: 95 | Iteration number: [3170/4518] 70% | Training loss: 0.6869734205658128
Epoch: 95 | Iteration number: [3180/4518] 70% | Training loss: 0.6869711952576847
Epoch: 95 | Iteration number: [3190/4518] 70% | Training loss: 0.6869722797579152
Epoch: 95 | Iteration number: [3200/4518] 70% | Training loss: 0.6869711093604565
Epoch: 95 | Iteration number: [3210/4518] 71% | Training loss: 0.6869688322239575
Epoch: 95 | Iteration number: [3220/4518] 71% | Training loss: 0.6869681429418718
Epoch: 95 | Iteration number: [3230/4518] 71% | Training loss: 0.6869643387226129
Epoch: 95 | Iteration number: [3240/4518] 71% | Training loss: 0.6869653324470107
Epoch: 95 | Iteration number: [3250/4518] 71% | Training loss: 0.6869693795901078
Epoch: 95 | Iteration number: [3260/4518] 72% | Training loss: 0.6869714922151683
Epoch: 95 | Iteration number: [3270/4518] 72% | Training loss: 0.6869724382318853
Epoch: 95 | Iteration number: [3280/4518] 72% | Training loss: 0.6869703689181224
Epoch: 95 | Iteration number: [3290/4518] 72% | Training loss: 0.6869678599312675
Epoch: 95 | Iteration number: [3300/4518] 73% | Training loss: 0.6869679568933719
Epoch: 95 | Iteration number: [3310/4518] 73% | Training loss: 0.6869666578006168
Epoch: 95 | Iteration number: [3320/4518] 73% | Training loss: 0.686962909601539
Epoch: 95 | Iteration number: [3330/4518] 73% | Training loss: 0.6869597040139162
Epoch: 95 | Iteration number: [3340/4518] 73% | Training loss: 0.686958457520622
Epoch: 95 | Iteration number: [3350/4518] 74% | Training loss: 0.6869564212436107
Epoch: 95 | Iteration number: [3360/4518] 74% | Training loss: 0.6869521636515856
Epoch: 95 | Iteration number: [3370/4518] 74% | Training loss: 0.6869557667379917
Epoch: 95 | Iteration number: [3380/4518] 74% | Training loss: 0.6869547023928377
Epoch: 95 | Iteration number: [3390/4518] 75% | Training loss: 0.6869504600675408
Epoch: 95 | Iteration number: [3400/4518] 75% | Training loss: 0.6869478552657016
Epoch: 95 | Iteration number: [3410/4518] 75% | Training loss: 0.6869487509000336
Epoch: 95 | Iteration number: [3420/4518] 75% | Training loss: 0.6869450336311296
Epoch: 95 | Iteration number: [3430/4518] 75% | Training loss: 0.6869401957655092
Epoch: 95 | Iteration number: [3440/4518] 76% | Training loss: 0.6869388256655183
Epoch: 95 | Iteration number: [3450/4518] 76% | Training loss: 0.6869374146150506
Epoch: 95 | Iteration number: [3460/4518] 76% | Training loss: 0.6869401118658871
Epoch: 95 | Iteration number: [3470/4518] 76% | Training loss: 0.6869420231934583
Epoch: 95 | Iteration number: [3480/4518] 77% | Training loss: 0.6869436953088333
Epoch: 95 | Iteration number: [3490/4518] 77% | Training loss: 0.6869408315778803
Epoch: 95 | Iteration number: [3500/4518] 77% | Training loss: 0.686941907780511
Epoch: 95 | Iteration number: [3510/4518] 77% | Training loss: 0.6869424847795753
Epoch: 95 | Iteration number: [3520/4518] 77% | Training loss: 0.6869407937438651
Epoch: 95 | Iteration number: [3530/4518] 78% | Training loss: 0.6869427968523658
Epoch: 95 | Iteration number: [3540/4518] 78% | Training loss: 0.6869396705580296
Epoch: 95 | Iteration number: [3550/4518] 78% | Training loss: 0.6869418287109321
Epoch: 95 | Iteration number: [3560/4518] 78% | Training loss: 0.6869406394576758
Epoch: 95 | Iteration number: [3570/4518] 79% | Training loss: 0.6869370799939506
Epoch: 95 | Iteration number: [3580/4518] 79% | Training loss: 0.6869394002347019
Epoch: 95 | Iteration number: [3590/4518] 79% | Training loss: 0.6869376024163865
Epoch: 95 | Iteration number: [3600/4518] 79% | Training loss: 0.6869366191327572
Epoch: 95 | Iteration number: [3610/4518] 79% | Training loss: 0.6869384110634347
Epoch: 95 | Iteration number: [3620/4518] 80% | Training loss: 0.6869373263904403
Epoch: 95 | Iteration number: [3630/4518] 80% | Training loss: 0.6869395887063554
Epoch: 95 | Iteration number: [3640/4518] 80% | Training loss: 0.6869417929551104
Epoch: 95 | Iteration number: [3650/4518] 80% | Training loss: 0.6869426426332291
Epoch: 95 | Iteration number: [3660/4518] 81% | Training loss: 0.6869430359921169
Epoch: 95 | Iteration number: [3670/4518] 81% | Training loss: 0.6869462535231899
Epoch: 95 | Iteration number: [3680/4518] 81% | Training loss: 0.6869459043378415
Epoch: 95 | Iteration number: [3690/4518] 81% | Training loss: 0.686947849853252
Epoch: 95 | Iteration number: [3700/4518] 81% | Training loss: 0.6869476450617249
Epoch: 95 | Iteration number: [3710/4518] 82% | Training loss: 0.6869479729801496
Epoch: 95 | Iteration number: [3720/4518] 82% | Training loss: 0.686947772019012
Epoch: 95 | Iteration number: [3730/4518] 82% | Training loss: 0.6869458212929181
Epoch: 95 | Iteration number: [3740/4518] 82% | Training loss: 0.6869471926102664
Epoch: 95 | Iteration number: [3750/4518] 83% | Training loss: 0.6869447554588318
Epoch: 95 | Iteration number: [3760/4518] 83% | Training loss: 0.6869431281501942
Epoch: 95 | Iteration number: [3770/4518] 83% | Training loss: 0.6869425553700019
Epoch: 95 | Iteration number: [3780/4518] 83% | Training loss: 0.686945806246586
Epoch: 95 | Iteration number: [3790/4518] 83% | Training loss: 0.6869436234628934
Epoch: 95 | Iteration number: [3800/4518] 84% | Training loss: 0.686941388202341
Epoch: 95 | Iteration number: [3810/4518] 84% | Training loss: 0.6869415004891674
Epoch: 95 | Iteration number: [3820/4518] 84% | Training loss: 0.6869451539834757
Epoch: 95 | Iteration number: [3830/4518] 84% | Training loss: 0.6869449623571052
Epoch: 95 | Iteration number: [3840/4518] 84% | Training loss: 0.6869439899766197
Epoch: 95 | Iteration number: [3850/4518] 85% | Training loss: 0.6869457748958042
Epoch: 95 | Iteration number: [3860/4518] 85% | Training loss: 0.6869438266352669
Epoch: 95 | Iteration number: [3870/4518] 85% | Training loss: 0.6869427893204898
Epoch: 95 | Iteration number: [3880/4518] 85% | Training loss: 0.6869446395752357
Epoch: 95 | Iteration number: [3890/4518] 86% | Training loss: 0.686942929673011
Epoch: 95 | Iteration number: [3900/4518] 86% | Training loss: 0.6869427137955642
Epoch: 95 | Iteration number: [3910/4518] 86% | Training loss: 0.6869401208427556
Epoch: 95 | Iteration number: [3920/4518] 86% | Training loss: 0.6869392151887319
Epoch: 95 | Iteration number: [3930/4518] 86% | Training loss: 0.6869422043097838
Epoch: 95 | Iteration number: [3940/4518] 87% | Training loss: 0.6869389124025548
Epoch: 95 | Iteration number: [3950/4518] 87% | Training loss: 0.6869404679159575
Epoch: 95 | Iteration number: [3960/4518] 87% | Training loss: 0.6869393000699053
Epoch: 95 | Iteration number: [3970/4518] 87% | Training loss: 0.6869363054970951
Epoch: 95 | Iteration number: [3980/4518] 88% | Training loss: 0.6869307817226679
Epoch: 95 | Iteration number: [3990/4518] 88% | Training loss: 0.6869362982741574
Epoch: 95 | Iteration number: [4000/4518] 88% | Training loss: 0.6869350164681673
Epoch: 95 | Iteration number: [4010/4518] 88% | Training loss: 0.6869352005069095
Epoch: 95 | Iteration number: [4020/4518] 88% | Training loss: 0.6869345764022562
Epoch: 95 | Iteration number: [4030/4518] 89% | Training loss: 0.6869346404193944
Epoch: 95 | Iteration number: [4040/4518] 89% | Training loss: 0.6869298564325464
Epoch: 95 | Iteration number: [4050/4518] 89% | Training loss: 0.6869293075137668
Epoch: 95 | Iteration number: [4060/4518] 89% | Training loss: 0.6869277742989545
Epoch: 95 | Iteration number: [4070/4518] 90% | Training loss: 0.6869281252420505
Epoch: 95 | Iteration number: [4080/4518] 90% | Training loss: 0.6869241451369781
Epoch: 95 | Iteration number: [4090/4518] 90% | Training loss: 0.6869260257497102
Epoch: 95 | Iteration number: [4100/4518] 90% | Training loss: 0.6869241668683727
Epoch: 95 | Iteration number: [4110/4518] 90% | Training loss: 0.6869231211007947
Epoch: 95 | Iteration number: [4120/4518] 91% | Training loss: 0.6869211117474778
Epoch: 95 | Iteration number: [4130/4518] 91% | Training loss: 0.6869241616916426
Epoch: 95 | Iteration number: [4140/4518] 91% | Training loss: 0.6869278538342259
Epoch: 95 | Iteration number: [4150/4518] 91% | Training loss: 0.6869253855010113
Epoch: 95 | Iteration number: [4160/4518] 92% | Training loss: 0.6869244794862774
Epoch: 95 | Iteration number: [4170/4518] 92% | Training loss: 0.6869234344656233
Epoch: 95 | Iteration number: [4180/4518] 92% | Training loss: 0.6869216995661338
Epoch: 95 | Iteration number: [4190/4518] 92% | Training loss: 0.6869232083419626
Epoch: 95 | Iteration number: [4200/4518] 92% | Training loss: 0.6869214738834472
Epoch: 95 | Iteration number: [4210/4518] 93% | Training loss: 0.6869210584429833
Epoch: 95 | Iteration number: [4220/4518] 93% | Training loss: 0.6869220037595921
Epoch: 95 | Iteration number: [4230/4518] 93% | Training loss: 0.6869243420044018
Epoch: 95 | Iteration number: [4240/4518] 93% | Training loss: 0.6869223090978164
Epoch: 95 | Iteration number: [4250/4518] 94% | Training loss: 0.6869217915114234
Epoch: 95 | Iteration number: [4260/4518] 94% | Training loss: 0.6869196379548507
Epoch: 95 | Iteration number: [4270/4518] 94% | Training loss: 0.686919371068338
Epoch: 95 | Iteration number: [4280/4518] 94% | Training loss: 0.6869180291891098
Epoch: 95 | Iteration number: [4290/4518] 94% | Training loss: 0.6869180315302247
Epoch: 95 | Iteration number: [4300/4518] 95% | Training loss: 0.6869142993660861
Epoch: 95 | Iteration number: [4310/4518] 95% | Training loss: 0.6869136952745389
Epoch: 95 | Iteration number: [4320/4518] 95% | Training loss: 0.6869150759169349
Epoch: 95 | Iteration number: [4330/4518] 95% | Training loss: 0.6869127486649617
Epoch: 95 | Iteration number: [4340/4518] 96% | Training loss: 0.6869122983398526
Epoch: 95 | Iteration number: [4350/4518] 96% | Training loss: 0.6869114417454292
Epoch: 95 | Iteration number: [4360/4518] 96% | Training loss: 0.6869105108560772
Epoch: 95 | Iteration number: [4370/4518] 96% | Training loss: 0.6869098350303396
Epoch: 95 | Iteration number: [4380/4518] 96% | Training loss: 0.6869075062612421
Epoch: 95 | Iteration number: [4390/4518] 97% | Training loss: 0.6869077280197708
Epoch: 95 | Iteration number: [4400/4518] 97% | Training loss: 0.686907521716573
Epoch: 95 | Iteration number: [4410/4518] 97% | Training loss: 0.6869043055575451
Epoch: 95 | Iteration number: [4420/4518] 97% | Training loss: 0.6869044015310469
Epoch: 95 | Iteration number: [4430/4518] 98% | Training loss: 0.6869055776240863
Epoch: 95 | Iteration number: [4440/4518] 98% | Training loss: 0.6869059997635919
Epoch: 95 | Iteration number: [4450/4518] 98% | Training loss: 0.6869045761863837
Epoch: 95 | Iteration number: [4460/4518] 98% | Training loss: 0.686902312459967
Epoch: 95 | Iteration number: [4470/4518] 98% | Training loss: 0.6869021287033755
Epoch: 95 | Iteration number: [4480/4518] 99% | Training loss: 0.6869009659226452
Epoch: 95 | Iteration number: [4490/4518] 99% | Training loss: 0.6869008918647511
Epoch: 95 | Iteration number: [4500/4518] 99% | Training loss: 0.6869008281893201
Epoch: 95 | Iteration number: [4510/4518] 99% | Training loss: 0.6868995851661572

 End of epoch: 95 | Train Loss: 0.6867459460057321 | Training Time: 633 

 End of epoch: 95 | Eval Loss: 0.6895414931433541 | Evaluating Time: 17 
Epoch: 96 | Iteration number: [10/4518] 0% | Training loss: 0.7541246712207794
Epoch: 96 | Iteration number: [20/4518] 0% | Training loss: 0.7208581268787384
Epoch: 96 | Iteration number: [30/4518] 0% | Training loss: 0.7094032863775889
Epoch: 96 | Iteration number: [40/4518] 0% | Training loss: 0.7035598739981651
Epoch: 96 | Iteration number: [50/4518] 1% | Training loss: 0.699950430393219
Epoch: 96 | Iteration number: [60/4518] 1% | Training loss: 0.6977295696735382
Epoch: 96 | Iteration number: [70/4518] 1% | Training loss: 0.6962082377501897
Epoch: 96 | Iteration number: [80/4518] 1% | Training loss: 0.6948696337640285
Epoch: 96 | Iteration number: [90/4518] 1% | Training loss: 0.6938092271486919
Epoch: 96 | Iteration number: [100/4518] 2% | Training loss: 0.6931312066316605
Epoch: 96 | Iteration number: [110/4518] 2% | Training loss: 0.6925606922669845
Epoch: 96 | Iteration number: [120/4518] 2% | Training loss: 0.6919806465506554
Epoch: 96 | Iteration number: [130/4518] 2% | Training loss: 0.6914416881707999
Epoch: 96 | Iteration number: [140/4518] 3% | Training loss: 0.6910941864762987
Epoch: 96 | Iteration number: [150/4518] 3% | Training loss: 0.6908928632736206
Epoch: 96 | Iteration number: [160/4518] 3% | Training loss: 0.690614002943039
Epoch: 96 | Iteration number: [170/4518] 3% | Training loss: 0.6904157386106603
Epoch: 96 | Iteration number: [180/4518] 3% | Training loss: 0.6902158465650347
Epoch: 96 | Iteration number: [190/4518] 4% | Training loss: 0.6899979892529939
Epoch: 96 | Iteration number: [200/4518] 4% | Training loss: 0.689872495830059
Epoch: 96 | Iteration number: [210/4518] 4% | Training loss: 0.6897008972508567
Epoch: 96 | Iteration number: [220/4518] 4% | Training loss: 0.6895718560977415
Epoch: 96 | Iteration number: [230/4518] 5% | Training loss: 0.6894413769245148
Epoch: 96 | Iteration number: [240/4518] 5% | Training loss: 0.6893088849882285
Epoch: 96 | Iteration number: [250/4518] 5% | Training loss: 0.6891772511005402
Epoch: 96 | Iteration number: [260/4518] 5% | Training loss: 0.6890674127982213
Epoch: 96 | Iteration number: [270/4518] 5% | Training loss: 0.6889301010855922
Epoch: 96 | Iteration number: [280/4518] 6% | Training loss: 0.6888090693524905
Epoch: 96 | Iteration number: [290/4518] 6% | Training loss: 0.6887536416793691
Epoch: 96 | Iteration number: [300/4518] 6% | Training loss: 0.6887093522151311
Epoch: 96 | Iteration number: [310/4518] 6% | Training loss: 0.6886656340091459
Epoch: 96 | Iteration number: [320/4518] 7% | Training loss: 0.6885921079665422
Epoch: 96 | Iteration number: [330/4518] 7% | Training loss: 0.6885855960123467
Epoch: 96 | Iteration number: [340/4518] 7% | Training loss: 0.688505865370526
Epoch: 96 | Iteration number: [350/4518] 7% | Training loss: 0.6884287527629307
Epoch: 96 | Iteration number: [360/4518] 7% | Training loss: 0.6884001106023788
Epoch: 96 | Iteration number: [370/4518] 8% | Training loss: 0.6883889124200151
Epoch: 96 | Iteration number: [380/4518] 8% | Training loss: 0.6883426040410996
Epoch: 96 | Iteration number: [390/4518] 8% | Training loss: 0.6882818280122219
Epoch: 96 | Iteration number: [400/4518] 8% | Training loss: 0.688236078619957
Epoch: 96 | Iteration number: [410/4518] 9% | Training loss: 0.6882066014336377
Epoch: 96 | Iteration number: [420/4518] 9% | Training loss: 0.6881861428419749
Epoch: 96 | Iteration number: [430/4518] 9% | Training loss: 0.6881494113179141
Epoch: 96 | Iteration number: [440/4518] 9% | Training loss: 0.6881112402135675
Epoch: 96 | Iteration number: [450/4518] 9% | Training loss: 0.6880979511472914
Epoch: 96 | Iteration number: [460/4518] 10% | Training loss: 0.688105917106504
Epoch: 96 | Iteration number: [470/4518] 10% | Training loss: 0.688063408592914
Epoch: 96 | Iteration number: [480/4518] 10% | Training loss: 0.6880438450723887
Epoch: 96 | Iteration number: [490/4518] 10% | Training loss: 0.6880206021727348
Epoch: 96 | Iteration number: [500/4518] 11% | Training loss: 0.6879998446702957
Epoch: 96 | Iteration number: [510/4518] 11% | Training loss: 0.6879410952913995
Epoch: 96 | Iteration number: [520/4518] 11% | Training loss: 0.6878866471923315
Epoch: 96 | Iteration number: [530/4518] 11% | Training loss: 0.687857195116439
Epoch: 96 | Iteration number: [540/4518] 11% | Training loss: 0.6878168144711742
Epoch: 96 | Iteration number: [550/4518] 12% | Training loss: 0.6878013408184052
Epoch: 96 | Iteration number: [560/4518] 12% | Training loss: 0.6877897701093129
Epoch: 96 | Iteration number: [570/4518] 12% | Training loss: 0.6877714935101961
Epoch: 96 | Iteration number: [580/4518] 12% | Training loss: 0.6877496122286237
Epoch: 96 | Iteration number: [590/4518] 13% | Training loss: 0.6877151826680716
Epoch: 96 | Iteration number: [600/4518] 13% | Training loss: 0.6877060640851657
Epoch: 96 | Iteration number: [610/4518] 13% | Training loss: 0.6876840032514978
Epoch: 96 | Iteration number: [620/4518] 13% | Training loss: 0.6876801633065747
Epoch: 96 | Iteration number: [630/4518] 13% | Training loss: 0.687678397269476
Epoch: 96 | Iteration number: [640/4518] 14% | Training loss: 0.6876708269119263
Epoch: 96 | Iteration number: [650/4518] 14% | Training loss: 0.6876405417919159
Epoch: 96 | Iteration number: [660/4518] 14% | Training loss: 0.687641419244535
Epoch: 96 | Iteration number: [670/4518] 14% | Training loss: 0.6876247299251271
Epoch: 96 | Iteration number: [680/4518] 15% | Training loss: 0.687614386835519
Epoch: 96 | Iteration number: [690/4518] 15% | Training loss: 0.6875872916069583
Epoch: 96 | Iteration number: [700/4518] 15% | Training loss: 0.6875514371906009
Epoch: 96 | Iteration number: [710/4518] 15% | Training loss: 0.6875649573097766
Epoch: 96 | Iteration number: [720/4518] 15% | Training loss: 0.6875595221916835
Epoch: 96 | Iteration number: [730/4518] 16% | Training loss: 0.6875462124608968
Epoch: 96 | Iteration number: [740/4518] 16% | Training loss: 0.6875324051122408
Epoch: 96 | Iteration number: [750/4518] 16% | Training loss: 0.6875025889873505
Epoch: 96 | Iteration number: [760/4518] 16% | Training loss: 0.6875103878347497
Epoch: 96 | Iteration number: [770/4518] 17% | Training loss: 0.6874856896988757
Epoch: 96 | Iteration number: [780/4518] 17% | Training loss: 0.6874725602376155
Epoch: 96 | Iteration number: [790/4518] 17% | Training loss: 0.6874387585664097
Epoch: 96 | Iteration number: [800/4518] 17% | Training loss: 0.6874198108166456
Epoch: 96 | Iteration number: [810/4518] 17% | Training loss: 0.6874141524603338
Epoch: 96 | Iteration number: [820/4518] 18% | Training loss: 0.6874323517811007
Epoch: 96 | Iteration number: [830/4518] 18% | Training loss: 0.6874314675848168
Epoch: 96 | Iteration number: [840/4518] 18% | Training loss: 0.6874437234940983
Epoch: 96 | Iteration number: [850/4518] 18% | Training loss: 0.6874336513350991
Epoch: 96 | Iteration number: [860/4518] 19% | Training loss: 0.6874148640521737
Epoch: 96 | Iteration number: [870/4518] 19% | Training loss: 0.6874092288400935
Epoch: 96 | Iteration number: [880/4518] 19% | Training loss: 0.6874025958505544
Epoch: 96 | Iteration number: [890/4518] 19% | Training loss: 0.6873979234963321
Epoch: 96 | Iteration number: [900/4518] 19% | Training loss: 0.6873848795890808
Epoch: 96 | Iteration number: [910/4518] 20% | Training loss: 0.6873848579087101
Epoch: 96 | Iteration number: [920/4518] 20% | Training loss: 0.6873722623223844
Epoch: 96 | Iteration number: [930/4518] 20% | Training loss: 0.6873603543286683
Epoch: 96 | Iteration number: [940/4518] 20% | Training loss: 0.6873494163472602
Epoch: 96 | Iteration number: [950/4518] 21% | Training loss: 0.6873389636215411
Epoch: 96 | Iteration number: [960/4518] 21% | Training loss: 0.6873393898829818
Epoch: 96 | Iteration number: [970/4518] 21% | Training loss: 0.6873334730408855
Epoch: 96 | Iteration number: [980/4518] 21% | Training loss: 0.6873129528395984
Epoch: 96 | Iteration number: [990/4518] 21% | Training loss: 0.687294419967767
Epoch: 96 | Iteration number: [1000/4518] 22% | Training loss: 0.6872912703752517
Epoch: 96 | Iteration number: [1010/4518] 22% | Training loss: 0.6872905011224275
Epoch: 96 | Iteration number: [1020/4518] 22% | Training loss: 0.6872747052533954
Epoch: 96 | Iteration number: [1030/4518] 22% | Training loss: 0.6872826426931955
Epoch: 96 | Iteration number: [1040/4518] 23% | Training loss: 0.6872838125205957
Epoch: 96 | Iteration number: [1050/4518] 23% | Training loss: 0.6872781792141143
Epoch: 96 | Iteration number: [1060/4518] 23% | Training loss: 0.6872775471997711
Epoch: 96 | Iteration number: [1070/4518] 23% | Training loss: 0.6872714465466615
Epoch: 96 | Iteration number: [1080/4518] 23% | Training loss: 0.6872761566329886
Epoch: 96 | Iteration number: [1090/4518] 24% | Training loss: 0.6872858179271768
Epoch: 96 | Iteration number: [1100/4518] 24% | Training loss: 0.6872741082581607
Epoch: 96 | Iteration number: [1110/4518] 24% | Training loss: 0.687267132385357
Epoch: 96 | Iteration number: [1120/4518] 24% | Training loss: 0.6872565640402691
Epoch: 96 | Iteration number: [1130/4518] 25% | Training loss: 0.6872374239748558
Epoch: 96 | Iteration number: [1140/4518] 25% | Training loss: 0.6872379242328175
Epoch: 96 | Iteration number: [1150/4518] 25% | Training loss: 0.687238878219024
Epoch: 96 | Iteration number: [1160/4518] 25% | Training loss: 0.6872348235598926
Epoch: 96 | Iteration number: [1170/4518] 25% | Training loss: 0.6872345470974588
Epoch: 96 | Iteration number: [1180/4518] 26% | Training loss: 0.6872285899469408
Epoch: 96 | Iteration number: [1190/4518] 26% | Training loss: 0.6872251767571232
Epoch: 96 | Iteration number: [1200/4518] 26% | Training loss: 0.6872230688730876
Epoch: 96 | Iteration number: [1210/4518] 26% | Training loss: 0.6872189179924894
Epoch: 96 | Iteration number: [1220/4518] 27% | Training loss: 0.6872181111183323
Epoch: 96 | Iteration number: [1230/4518] 27% | Training loss: 0.687222596494163
Epoch: 96 | Iteration number: [1240/4518] 27% | Training loss: 0.6872203836037266
Epoch: 96 | Iteration number: [1250/4518] 27% | Training loss: 0.6872118900299072
Epoch: 96 | Iteration number: [1260/4518] 27% | Training loss: 0.6871938043170505
Epoch: 96 | Iteration number: [1270/4518] 28% | Training loss: 0.6871931236090623
Epoch: 96 | Iteration number: [1280/4518] 28% | Training loss: 0.6871866184752434
Epoch: 96 | Iteration number: [1290/4518] 28% | Training loss: 0.687180661739305
Epoch: 96 | Iteration number: [1300/4518] 28% | Training loss: 0.6871740916600594
Epoch: 96 | Iteration number: [1310/4518] 28% | Training loss: 0.6871619888389383
Epoch: 96 | Iteration number: [1320/4518] 29% | Training loss: 0.6871596671866648
Epoch: 96 | Iteration number: [1330/4518] 29% | Training loss: 0.6871678220150166
Epoch: 96 | Iteration number: [1340/4518] 29% | Training loss: 0.6871606996699945
Epoch: 96 | Iteration number: [1350/4518] 29% | Training loss: 0.6871524060655523
Epoch: 96 | Iteration number: [1360/4518] 30% | Training loss: 0.687140414688517
Epoch: 96 | Iteration number: [1370/4518] 30% | Training loss: 0.6871318178890395
Epoch: 96 | Iteration number: [1380/4518] 30% | Training loss: 0.6871338151071382
Epoch: 96 | Iteration number: [1390/4518] 30% | Training loss: 0.6871326855618319
Epoch: 96 | Iteration number: [1400/4518] 30% | Training loss: 0.6871244319847651
Epoch: 96 | Iteration number: [1410/4518] 31% | Training loss: 0.6871288075091991
Epoch: 96 | Iteration number: [1420/4518] 31% | Training loss: 0.6871302336454391
Epoch: 96 | Iteration number: [1430/4518] 31% | Training loss: 0.6871266024512844
Epoch: 96 | Iteration number: [1440/4518] 31% | Training loss: 0.687129704364472
Epoch: 96 | Iteration number: [1450/4518] 32% | Training loss: 0.6871255725005577
Epoch: 96 | Iteration number: [1460/4518] 32% | Training loss: 0.6871133297273557
Epoch: 96 | Iteration number: [1470/4518] 32% | Training loss: 0.6871099088467708
Epoch: 96 | Iteration number: [1480/4518] 32% | Training loss: 0.687106403708458
Epoch: 96 | Iteration number: [1490/4518] 32% | Training loss: 0.6871056267879153
Epoch: 96 | Iteration number: [1500/4518] 33% | Training loss: 0.687092181245486
Epoch: 96 | Iteration number: [1510/4518] 33% | Training loss: 0.6870903619077822
Epoch: 96 | Iteration number: [1520/4518] 33% | Training loss: 0.6870906624354814
Epoch: 96 | Iteration number: [1530/4518] 33% | Training loss: 0.68709546541856
Epoch: 96 | Iteration number: [1540/4518] 34% | Training loss: 0.6870908042440167
Epoch: 96 | Iteration number: [1550/4518] 34% | Training loss: 0.6870896389407496
Epoch: 96 | Iteration number: [1560/4518] 34% | Training loss: 0.6870851276394648
Epoch: 96 | Iteration number: [1570/4518] 34% | Training loss: 0.6870813952130117
Epoch: 96 | Iteration number: [1580/4518] 34% | Training loss: 0.6870828050224087
Epoch: 96 | Iteration number: [1590/4518] 35% | Training loss: 0.6870888579191652
Epoch: 96 | Iteration number: [1600/4518] 35% | Training loss: 0.6870886178314686
Epoch: 96 | Iteration number: [1610/4518] 35% | Training loss: 0.687085948005226
Epoch: 96 | Iteration number: [1620/4518] 35% | Training loss: 0.6870856810131191
Epoch: 96 | Iteration number: [1630/4518] 36% | Training loss: 0.6870879720325119
Epoch: 96 | Iteration number: [1640/4518] 36% | Training loss: 0.6870742601592367
Epoch: 96 | Iteration number: [1650/4518] 36% | Training loss: 0.6870754444237911
Epoch: 96 | Iteration number: [1660/4518] 36% | Training loss: 0.6870604640389063
Epoch: 96 | Iteration number: [1670/4518] 36% | Training loss: 0.6870552201114015
Epoch: 96 | Iteration number: [1680/4518] 37% | Training loss: 0.687059632475887
Epoch: 96 | Iteration number: [1690/4518] 37% | Training loss: 0.6870575793396086
Epoch: 96 | Iteration number: [1700/4518] 37% | Training loss: 0.6870509333820904
Epoch: 96 | Iteration number: [1710/4518] 37% | Training loss: 0.6870547870794932
Epoch: 96 | Iteration number: [1720/4518] 38% | Training loss: 0.6870588395831196
Epoch: 96 | Iteration number: [1730/4518] 38% | Training loss: 0.6870565704527618
Epoch: 96 | Iteration number: [1740/4518] 38% | Training loss: 0.6870633621325438
Epoch: 96 | Iteration number: [1750/4518] 38% | Training loss: 0.6870513479369027
Epoch: 96 | Iteration number: [1760/4518] 38% | Training loss: 0.6870500009506941
Epoch: 96 | Iteration number: [1770/4518] 39% | Training loss: 0.6870478286581524
Epoch: 96 | Iteration number: [1780/4518] 39% | Training loss: 0.6870523647311029
Epoch: 96 | Iteration number: [1790/4518] 39% | Training loss: 0.6870506731491515
Epoch: 96 | Iteration number: [1800/4518] 39% | Training loss: 0.6870512827237447
Epoch: 96 | Iteration number: [1810/4518] 40% | Training loss: 0.6870512840168252
Epoch: 96 | Iteration number: [1820/4518] 40% | Training loss: 0.6870494079786342
Epoch: 96 | Iteration number: [1830/4518] 40% | Training loss: 0.6870500220627082
Epoch: 96 | Iteration number: [1840/4518] 40% | Training loss: 0.6870515079278013
Epoch: 96 | Iteration number: [1850/4518] 40% | Training loss: 0.6870528563937626
Epoch: 96 | Iteration number: [1860/4518] 41% | Training loss: 0.6870534102121989
Epoch: 96 | Iteration number: [1870/4518] 41% | Training loss: 0.6870473602557565
Epoch: 96 | Iteration number: [1880/4518] 41% | Training loss: 0.6870460104118002
Epoch: 96 | Iteration number: [1890/4518] 41% | Training loss: 0.6870390892659546
Epoch: 96 | Iteration number: [1900/4518] 42% | Training loss: 0.687036645192849
Epoch: 96 | Iteration number: [1910/4518] 42% | Training loss: 0.6870416788218533
Epoch: 96 | Iteration number: [1920/4518] 42% | Training loss: 0.6870396227265397
Epoch: 96 | Iteration number: [1930/4518] 42% | Training loss: 0.6870306250036071
Epoch: 96 | Iteration number: [1940/4518] 42% | Training loss: 0.6870224782793792
Epoch: 96 | Iteration number: [1950/4518] 43% | Training loss: 0.6870132020803599
Epoch: 96 | Iteration number: [1960/4518] 43% | Training loss: 0.6870141195399421
Epoch: 96 | Iteration number: [1970/4518] 43% | Training loss: 0.6870080187841116
Epoch: 96 | Iteration number: [1980/4518] 43% | Training loss: 0.6870043358718506
Epoch: 96 | Iteration number: [1990/4518] 44% | Training loss: 0.687006120226491
Epoch: 96 | Iteration number: [2000/4518] 44% | Training loss: 0.6870063706338405
Epoch: 96 | Iteration number: [2010/4518] 44% | Training loss: 0.6870059991653878
Epoch: 96 | Iteration number: [2020/4518] 44% | Training loss: 0.6870085734837126
Epoch: 96 | Iteration number: [2030/4518] 44% | Training loss: 0.6870058020053826
Epoch: 96 | Iteration number: [2040/4518] 45% | Training loss: 0.6870019978460143
Epoch: 96 | Iteration number: [2050/4518] 45% | Training loss: 0.6870028585631673
Epoch: 96 | Iteration number: [2060/4518] 45% | Training loss: 0.6870087383152211
Epoch: 96 | Iteration number: [2070/4518] 45% | Training loss: 0.6870074866762483
Epoch: 96 | Iteration number: [2080/4518] 46% | Training loss: 0.6870145526356422
Epoch: 96 | Iteration number: [2090/4518] 46% | Training loss: 0.6870174052612633
Epoch: 96 | Iteration number: [2100/4518] 46% | Training loss: 0.6870150855041686
Epoch: 96 | Iteration number: [2110/4518] 46% | Training loss: 0.6870139552801141
Epoch: 96 | Iteration number: [2120/4518] 46% | Training loss: 0.6870146390120938
Epoch: 96 | Iteration number: [2130/4518] 47% | Training loss: 0.6870165004136977
Epoch: 96 | Iteration number: [2140/4518] 47% | Training loss: 0.6870127361232989
Epoch: 96 | Iteration number: [2150/4518] 47% | Training loss: 0.6870132110562436
Epoch: 96 | Iteration number: [2160/4518] 47% | Training loss: 0.6870090231851295
Epoch: 96 | Iteration number: [2170/4518] 48% | Training loss: 0.6870064672786519
Epoch: 96 | Iteration number: [2180/4518] 48% | Training loss: 0.6870073809536226
Epoch: 96 | Iteration number: [2190/4518] 48% | Training loss: 0.6870088726418203
Epoch: 96 | Iteration number: [2200/4518] 48% | Training loss: 0.687007442875342
Epoch: 96 | Iteration number: [2210/4518] 48% | Training loss: 0.6870117353368129
Epoch: 96 | Iteration number: [2220/4518] 49% | Training loss: 0.6870071288164672
Epoch: 96 | Iteration number: [2230/4518] 49% | Training loss: 0.6870076509869152
Epoch: 96 | Iteration number: [2240/4518] 49% | Training loss: 0.6870018890393632
Epoch: 96 | Iteration number: [2250/4518] 49% | Training loss: 0.6870014670424991
Epoch: 96 | Iteration number: [2260/4518] 50% | Training loss: 0.6870027397058707
Epoch: 96 | Iteration number: [2270/4518] 50% | Training loss: 0.6870018883686234
Epoch: 96 | Iteration number: [2280/4518] 50% | Training loss: 0.6870040133334043
Epoch: 96 | Iteration number: [2290/4518] 50% | Training loss: 0.6870068440531019
Epoch: 96 | Iteration number: [2300/4518] 50% | Training loss: 0.6870019938375639
Epoch: 96 | Iteration number: [2310/4518] 51% | Training loss: 0.6869999777961087
Epoch: 96 | Iteration number: [2320/4518] 51% | Training loss: 0.6870014600969594
Epoch: 96 | Iteration number: [2330/4518] 51% | Training loss: 0.6870052160623248
Epoch: 96 | Iteration number: [2340/4518] 51% | Training loss: 0.6870080102457959
Epoch: 96 | Iteration number: [2350/4518] 52% | Training loss: 0.6870093461807738
Epoch: 96 | Iteration number: [2360/4518] 52% | Training loss: 0.6870033548545029
Epoch: 96 | Iteration number: [2370/4518] 52% | Training loss: 0.6869973646186072
Epoch: 96 | Iteration number: [2380/4518] 52% | Training loss: 0.6869936051989803
Epoch: 96 | Iteration number: [2390/4518] 52% | Training loss: 0.6869954707233477
Epoch: 96 | Iteration number: [2400/4518] 53% | Training loss: 0.6869887348761161
Epoch: 96 | Iteration number: [2410/4518] 53% | Training loss: 0.6869870989649127
Epoch: 96 | Iteration number: [2420/4518] 53% | Training loss: 0.6869803123976573
Epoch: 96 | Iteration number: [2430/4518] 53% | Training loss: 0.6869812007303591
Epoch: 96 | Iteration number: [2440/4518] 54% | Training loss: 0.6869859525414764
Epoch: 96 | Iteration number: [2450/4518] 54% | Training loss: 0.6869874473737211
Epoch: 96 | Iteration number: [2460/4518] 54% | Training loss: 0.6869857482309264
Epoch: 96 | Iteration number: [2470/4518] 54% | Training loss: 0.6869814894701305
Epoch: 96 | Iteration number: [2480/4518] 54% | Training loss: 0.6869815155142738
Epoch: 96 | Iteration number: [2490/4518] 55% | Training loss: 0.6869804919005398
Epoch: 96 | Iteration number: [2500/4518] 55% | Training loss: 0.6869783781528472
Epoch: 96 | Iteration number: [2510/4518] 55% | Training loss: 0.6869754333657573
Epoch: 96 | Iteration number: [2520/4518] 55% | Training loss: 0.6869738867358556
Epoch: 96 | Iteration number: [2530/4518] 55% | Training loss: 0.6869717770649981
Epoch: 96 | Iteration number: [2540/4518] 56% | Training loss: 0.6869745858776288
Epoch: 96 | Iteration number: [2550/4518] 56% | Training loss: 0.686973098563213
Epoch: 96 | Iteration number: [2560/4518] 56% | Training loss: 0.6869683412835002
Epoch: 96 | Iteration number: [2570/4518] 56% | Training loss: 0.6869723014330585
Epoch: 96 | Iteration number: [2580/4518] 57% | Training loss: 0.6869733552831088
Epoch: 96 | Iteration number: [2590/4518] 57% | Training loss: 0.6869755796253911
Epoch: 96 | Iteration number: [2600/4518] 57% | Training loss: 0.686977152136656
Epoch: 96 | Iteration number: [2610/4518] 57% | Training loss: 0.6869727324937038
Epoch: 96 | Iteration number: [2620/4518] 57% | Training loss: 0.6869664187422235
Epoch: 96 | Iteration number: [2630/4518] 58% | Training loss: 0.6869641222428007
Epoch: 96 | Iteration number: [2640/4518] 58% | Training loss: 0.6869629867826448
Epoch: 96 | Iteration number: [2650/4518] 58% | Training loss: 0.6869588448416512
Epoch: 96 | Iteration number: [2660/4518] 58% | Training loss: 0.6869608904186048
Epoch: 96 | Iteration number: [2670/4518] 59% | Training loss: 0.6869578373342864
Epoch: 96 | Iteration number: [2680/4518] 59% | Training loss: 0.6869602144431712
Epoch: 96 | Iteration number: [2690/4518] 59% | Training loss: 0.6869581126590644
Epoch: 96 | Iteration number: [2700/4518] 59% | Training loss: 0.686960852433134
Epoch: 96 | Iteration number: [2710/4518] 59% | Training loss: 0.6869608746463522
Epoch: 96 | Iteration number: [2720/4518] 60% | Training loss: 0.6869613643516512
Epoch: 96 | Iteration number: [2730/4518] 60% | Training loss: 0.6869593847583938
Epoch: 96 | Iteration number: [2740/4518] 60% | Training loss: 0.6869588346594442
Epoch: 96 | Iteration number: [2750/4518] 60% | Training loss: 0.6869549541906877
Epoch: 96 | Iteration number: [2760/4518] 61% | Training loss: 0.6869533666450044
Epoch: 96 | Iteration number: [2770/4518] 61% | Training loss: 0.6869541073964391
Epoch: 96 | Iteration number: [2780/4518] 61% | Training loss: 0.6869556417568125
Epoch: 96 | Iteration number: [2790/4518] 61% | Training loss: 0.6869519685545276
Epoch: 96 | Iteration number: [2800/4518] 61% | Training loss: 0.6869479452073574
Epoch: 96 | Iteration number: [2810/4518] 62% | Training loss: 0.686947187388919
Epoch: 96 | Iteration number: [2820/4518] 62% | Training loss: 0.6869469922485081
Epoch: 96 | Iteration number: [2830/4518] 62% | Training loss: 0.6869409091059816
Epoch: 96 | Iteration number: [2840/4518] 62% | Training loss: 0.6869351564368732
Epoch: 96 | Iteration number: [2850/4518] 63% | Training loss: 0.6869334940115611
Epoch: 96 | Iteration number: [2860/4518] 63% | Training loss: 0.6869334182747594
Epoch: 96 | Iteration number: [2870/4518] 63% | Training loss: 0.6869336702267052
Epoch: 96 | Iteration number: [2880/4518] 63% | Training loss: 0.6869342754284541
Epoch: 96 | Iteration number: [2890/4518] 63% | Training loss: 0.6869375568772682
Epoch: 96 | Iteration number: [2900/4518] 64% | Training loss: 0.6869388677333963
Epoch: 96 | Iteration number: [2910/4518] 64% | Training loss: 0.6869422636695743
Epoch: 96 | Iteration number: [2920/4518] 64% | Training loss: 0.6869452407711173
Epoch: 96 | Iteration number: [2930/4518] 64% | Training loss: 0.6869456500526988
Epoch: 96 | Iteration number: [2940/4518] 65% | Training loss: 0.6869451944925347
Epoch: 96 | Iteration number: [2950/4518] 65% | Training loss: 0.6869417910454637
Epoch: 96 | Iteration number: [2960/4518] 65% | Training loss: 0.6869409896030619
Epoch: 96 | Iteration number: [2970/4518] 65% | Training loss: 0.6869404741409251
Epoch: 96 | Iteration number: [2980/4518] 65% | Training loss: 0.6869408518075943
Epoch: 96 | Iteration number: [2990/4518] 66% | Training loss: 0.6869420850954726
Epoch: 96 | Iteration number: [3000/4518] 66% | Training loss: 0.6869399215976397
Epoch: 96 | Iteration number: [3010/4518] 66% | Training loss: 0.6869424285682729
Epoch: 96 | Iteration number: [3020/4518] 66% | Training loss: 0.6869430123970208
Epoch: 96 | Iteration number: [3030/4518] 67% | Training loss: 0.6869444352958856
Epoch: 96 | Iteration number: [3040/4518] 67% | Training loss: 0.6869471645668933
Epoch: 96 | Iteration number: [3050/4518] 67% | Training loss: 0.6869368346401903
Epoch: 96 | Iteration number: [3060/4518] 67% | Training loss: 0.6869365032397065
Epoch: 96 | Iteration number: [3070/4518] 67% | Training loss: 0.6869343844415311
Epoch: 96 | Iteration number: [3080/4518] 68% | Training loss: 0.686933345860475
Epoch: 96 | Iteration number: [3090/4518] 68% | Training loss: 0.6869320604600567
Epoch: 96 | Iteration number: [3100/4518] 68% | Training loss: 0.6869351214939549
Epoch: 96 | Iteration number: [3110/4518] 68% | Training loss: 0.68693714891216
Epoch: 96 | Iteration number: [3120/4518] 69% | Training loss: 0.6869378765615133
Epoch: 96 | Iteration number: [3130/4518] 69% | Training loss: 0.6869367516269318
Epoch: 96 | Iteration number: [3140/4518] 69% | Training loss: 0.6869383128205682
Epoch: 96 | Iteration number: [3150/4518] 69% | Training loss: 0.686932759266051
Epoch: 96 | Iteration number: [3160/4518] 69% | Training loss: 0.6869330929049963
Epoch: 96 | Iteration number: [3170/4518] 70% | Training loss: 0.6869333791807999
Epoch: 96 | Iteration number: [3180/4518] 70% | Training loss: 0.6869366862301557
Epoch: 96 | Iteration number: [3190/4518] 70% | Training loss: 0.6869368065300406
Epoch: 96 | Iteration number: [3200/4518] 70% | Training loss: 0.6869339475221932
Epoch: 96 | Iteration number: [3210/4518] 71% | Training loss: 0.6869359994231726
Epoch: 96 | Iteration number: [3220/4518] 71% | Training loss: 0.6869345387501746
Epoch: 96 | Iteration number: [3230/4518] 71% | Training loss: 0.6869341410535039
Epoch: 96 | Iteration number: [3240/4518] 71% | Training loss: 0.6869346058111132
Epoch: 96 | Iteration number: [3250/4518] 71% | Training loss: 0.6869316890789913
Epoch: 96 | Iteration number: [3260/4518] 72% | Training loss: 0.6869288791542404
Epoch: 96 | Iteration number: [3270/4518] 72% | Training loss: 0.6869321237281193
Epoch: 96 | Iteration number: [3280/4518] 72% | Training loss: 0.6869289372388909
Epoch: 96 | Iteration number: [3290/4518] 72% | Training loss: 0.6869265163560768
Epoch: 96 | Iteration number: [3300/4518] 73% | Training loss: 0.6869296283613552
Epoch: 96 | Iteration number: [3310/4518] 73% | Training loss: 0.6869307426347473
Epoch: 96 | Iteration number: [3320/4518] 73% | Training loss: 0.6869281720863767
Epoch: 96 | Iteration number: [3330/4518] 73% | Training loss: 0.6869281724587575
Epoch: 96 | Iteration number: [3340/4518] 73% | Training loss: 0.6869252956199075
Epoch: 96 | Iteration number: [3350/4518] 74% | Training loss: 0.6869278262800245
Epoch: 96 | Iteration number: [3360/4518] 74% | Training loss: 0.6869283556938172
Epoch: 96 | Iteration number: [3370/4518] 74% | Training loss: 0.6869298127886095
Epoch: 96 | Iteration number: [3380/4518] 74% | Training loss: 0.6869278557554505
Epoch: 96 | Iteration number: [3390/4518] 75% | Training loss: 0.6869257149267337
Epoch: 96 | Iteration number: [3400/4518] 75% | Training loss: 0.6869237015878453
Epoch: 96 | Iteration number: [3410/4518] 75% | Training loss: 0.6869216114544798
Epoch: 96 | Iteration number: [3420/4518] 75% | Training loss: 0.6869249688951593
Epoch: 96 | Iteration number: [3430/4518] 75% | Training loss: 0.6869247384912418
Epoch: 96 | Iteration number: [3440/4518] 76% | Training loss: 0.6869229768424533
Epoch: 96 | Iteration number: [3450/4518] 76% | Training loss: 0.6869260950710463
Epoch: 96 | Iteration number: [3460/4518] 76% | Training loss: 0.6869220762239027
Epoch: 96 | Iteration number: [3470/4518] 76% | Training loss: 0.6869195844494987
Epoch: 96 | Iteration number: [3480/4518] 77% | Training loss: 0.6869197232113488
Epoch: 96 | Iteration number: [3490/4518] 77% | Training loss: 0.6869157041895355
Epoch: 96 | Iteration number: [3500/4518] 77% | Training loss: 0.6869161230666296
Epoch: 96 | Iteration number: [3510/4518] 77% | Training loss: 0.6869151056661905
Epoch: 96 | Iteration number: [3520/4518] 77% | Training loss: 0.686920153112574
Epoch: 96 | Iteration number: [3530/4518] 78% | Training loss: 0.6869208654499595
Epoch: 96 | Iteration number: [3540/4518] 78% | Training loss: 0.6869209555414437
Epoch: 96 | Iteration number: [3550/4518] 78% | Training loss: 0.6869231707445332
Epoch: 96 | Iteration number: [3560/4518] 78% | Training loss: 0.6869251293245326
Epoch: 96 | Iteration number: [3570/4518] 79% | Training loss: 0.6869233082823393
Epoch: 96 | Iteration number: [3580/4518] 79% | Training loss: 0.6869215343418068
Epoch: 96 | Iteration number: [3590/4518] 79% | Training loss: 0.6869167220459675
Epoch: 96 | Iteration number: [3600/4518] 79% | Training loss: 0.686911654803488
Epoch: 96 | Iteration number: [3610/4518] 79% | Training loss: 0.6869082820877804
Epoch: 96 | Iteration number: [3620/4518] 80% | Training loss: 0.6869070969563162
Epoch: 96 | Iteration number: [3630/4518] 80% | Training loss: 0.68690811208457
Epoch: 96 | Iteration number: [3640/4518] 80% | Training loss: 0.686905049950212
Epoch: 96 | Iteration number: [3650/4518] 80% | Training loss: 0.6869088620355684
Epoch: 96 | Iteration number: [3660/4518] 81% | Training loss: 0.6869074726691011
Epoch: 96 | Iteration number: [3670/4518] 81% | Training loss: 0.6869077020834837
Epoch: 96 | Iteration number: [3680/4518] 81% | Training loss: 0.6869037185998067
Epoch: 96 | Iteration number: [3690/4518] 81% | Training loss: 0.6869055576925355
Epoch: 96 | Iteration number: [3700/4518] 81% | Training loss: 0.6869026540582245
Epoch: 96 | Iteration number: [3710/4518] 82% | Training loss: 0.686903149066267
Epoch: 96 | Iteration number: [3720/4518] 82% | Training loss: 0.686905578836318
Epoch: 96 | Iteration number: [3730/4518] 82% | Training loss: 0.6869048387051907
Epoch: 96 | Iteration number: [3740/4518] 82% | Training loss: 0.6869025767805742
Epoch: 96 | Iteration number: [3750/4518] 83% | Training loss: 0.6868980576992035
Epoch: 96 | Iteration number: [3760/4518] 83% | Training loss: 0.6868965181105948
Epoch: 96 | Iteration number: [3770/4518] 83% | Training loss: 0.6868977958548923
Epoch: 96 | Iteration number: [3780/4518] 83% | Training loss: 0.6868993539343435
Epoch: 96 | Iteration number: [3790/4518] 83% | Training loss: 0.6869031806734432
Epoch: 96 | Iteration number: [3800/4518] 84% | Training loss: 0.6869039751667726
Epoch: 96 | Iteration number: [3810/4518] 84% | Training loss: 0.6869022911614946
Epoch: 96 | Iteration number: [3820/4518] 84% | Training loss: 0.6869021683151185
Epoch: 96 | Iteration number: [3830/4518] 84% | Training loss: 0.6869020815462108
Epoch: 96 | Iteration number: [3840/4518] 84% | Training loss: 0.6869002977696558
Epoch: 96 | Iteration number: [3850/4518] 85% | Training loss: 0.6869009750384789
Epoch: 96 | Iteration number: [3860/4518] 85% | Training loss: 0.6869005344846706
Epoch: 96 | Iteration number: [3870/4518] 85% | Training loss: 0.6868985573604741
Epoch: 96 | Iteration number: [3880/4518] 85% | Training loss: 0.6869005533223299
Epoch: 96 | Iteration number: [3890/4518] 86% | Training loss: 0.6869020438899112
Epoch: 96 | Iteration number: [3900/4518] 86% | Training loss: 0.6869006102513044
Epoch: 96 | Iteration number: [3910/4518] 86% | Training loss: 0.6869017650404244
Epoch: 96 | Iteration number: [3920/4518] 86% | Training loss: 0.6869047708049112
Epoch: 96 | Iteration number: [3930/4518] 86% | Training loss: 0.6869081073438241
Epoch: 96 | Iteration number: [3940/4518] 87% | Training loss: 0.6869068512607952
Epoch: 96 | Iteration number: [3950/4518] 87% | Training loss: 0.6869029301027708
Epoch: 96 | Iteration number: [3960/4518] 87% | Training loss: 0.6869046702679962
Epoch: 96 | Iteration number: [3970/4518] 87% | Training loss: 0.6869054277387614
Epoch: 96 | Iteration number: [3980/4518] 88% | Training loss: 0.6869059635616427
Epoch: 96 | Iteration number: [3990/4518] 88% | Training loss: 0.6869077087494365
Epoch: 96 | Iteration number: [4000/4518] 88% | Training loss: 0.686906469553709
Epoch: 96 | Iteration number: [4010/4518] 88% | Training loss: 0.6869066087385068
Epoch: 96 | Iteration number: [4020/4518] 88% | Training loss: 0.6869010680943579
Epoch: 96 | Iteration number: [4030/4518] 89% | Training loss: 0.6868990222070708
Epoch: 96 | Iteration number: [4040/4518] 89% | Training loss: 0.6868986952275333
Epoch: 96 | Iteration number: [4050/4518] 89% | Training loss: 0.6868992472136463
Epoch: 96 | Iteration number: [4060/4518] 89% | Training loss: 0.6868988472399453
Epoch: 96 | Iteration number: [4070/4518] 90% | Training loss: 0.6868980002198231
Epoch: 96 | Iteration number: [4080/4518] 90% | Training loss: 0.6868949482546133
Epoch: 96 | Iteration number: [4090/4518] 90% | Training loss: 0.686892971797211
Epoch: 96 | Iteration number: [4100/4518] 90% | Training loss: 0.6868958678623525
Epoch: 96 | Iteration number: [4110/4518] 90% | Training loss: 0.686893898770757
Epoch: 96 | Iteration number: [4120/4518] 91% | Training loss: 0.6868927759163588
Epoch: 96 | Iteration number: [4130/4518] 91% | Training loss: 0.6868926052031159
Epoch: 96 | Iteration number: [4140/4518] 91% | Training loss: 0.6868951021617161
Epoch: 96 | Iteration number: [4150/4518] 91% | Training loss: 0.6868918703550316
Epoch: 96 | Iteration number: [4160/4518] 92% | Training loss: 0.6868925349357037
Epoch: 96 | Iteration number: [4170/4518] 92% | Training loss: 0.6868936813277878
Epoch: 96 | Iteration number: [4180/4518] 92% | Training loss: 0.6868953814917204
Epoch: 96 | Iteration number: [4190/4518] 92% | Training loss: 0.686896731972979
Epoch: 96 | Iteration number: [4200/4518] 92% | Training loss: 0.6868954316633088
Epoch: 96 | Iteration number: [4210/4518] 93% | Training loss: 0.6868935689365495
Epoch: 96 | Iteration number: [4220/4518] 93% | Training loss: 0.6868921558438884
Epoch: 96 | Iteration number: [4230/4518] 93% | Training loss: 0.686892551944611
Epoch: 96 | Iteration number: [4240/4518] 93% | Training loss: 0.686892246975089
Epoch: 96 | Iteration number: [4250/4518] 94% | Training loss: 0.6868921683956595
Epoch: 96 | Iteration number: [4260/4518] 94% | Training loss: 0.6868892953429424
Epoch: 96 | Iteration number: [4270/4518] 94% | Training loss: 0.6868921989579391
Epoch: 96 | Iteration number: [4280/4518] 94% | Training loss: 0.6868914712812298
Epoch: 96 | Iteration number: [4290/4518] 94% | Training loss: 0.6868938457715762
Epoch: 96 | Iteration number: [4300/4518] 95% | Training loss: 0.6868911764510842
Epoch: 96 | Iteration number: [4310/4518] 95% | Training loss: 0.6868948491571121
Epoch: 96 | Iteration number: [4320/4518] 95% | Training loss: 0.6868957152107248
Epoch: 96 | Iteration number: [4330/4518] 95% | Training loss: 0.6868963352251823
Epoch: 96 | Iteration number: [4340/4518] 96% | Training loss: 0.6868951044324356
Epoch: 96 | Iteration number: [4350/4518] 96% | Training loss: 0.6868949670490178
Epoch: 96 | Iteration number: [4360/4518] 96% | Training loss: 0.6868988946080208
Epoch: 96 | Iteration number: [4370/4518] 96% | Training loss: 0.6868984165671761
Epoch: 96 | Iteration number: [4380/4518] 96% | Training loss: 0.6868963934242998
Epoch: 96 | Iteration number: [4390/4518] 97% | Training loss: 0.6868954740379829
Epoch: 96 | Iteration number: [4400/4518] 97% | Training loss: 0.6868951583044095
Epoch: 96 | Iteration number: [4410/4518] 97% | Training loss: 0.6868958139770966
Epoch: 96 | Iteration number: [4420/4518] 97% | Training loss: 0.6868962055417747
Epoch: 96 | Iteration number: [4430/4518] 98% | Training loss: 0.6868978388826142
Epoch: 96 | Iteration number: [4440/4518] 98% | Training loss: 0.6868970109401522
Epoch: 96 | Iteration number: [4450/4518] 98% | Training loss: 0.6868999754846766
Epoch: 96 | Iteration number: [4460/4518] 98% | Training loss: 0.6869010823858158
Epoch: 96 | Iteration number: [4470/4518] 98% | Training loss: 0.6869017516873294
Epoch: 96 | Iteration number: [4480/4518] 99% | Training loss: 0.686898795847914
Epoch: 96 | Iteration number: [4490/4518] 99% | Training loss: 0.6868977019144326
Epoch: 96 | Iteration number: [4500/4518] 99% | Training loss: 0.6868982393874062
Epoch: 96 | Iteration number: [4510/4518] 99% | Training loss: 0.6869009404779802

 End of epoch: 96 | Train Loss: 0.6867473917547819 | Training Time: 633 

 End of epoch: 96 | Eval Loss: 0.6895455365278282 | Evaluating Time: 17 
Epoch: 97 | Iteration number: [10/4518] 0% | Training loss: 0.7540295660495758
Epoch: 97 | Iteration number: [20/4518] 0% | Training loss: 0.7201587408781052
Epoch: 97 | Iteration number: [30/4518] 0% | Training loss: 0.7091993788878123
Epoch: 97 | Iteration number: [40/4518] 0% | Training loss: 0.7036984637379646
Epoch: 97 | Iteration number: [50/4518] 1% | Training loss: 0.7002577054500579
Epoch: 97 | Iteration number: [60/4518] 1% | Training loss: 0.6982515126466751
Epoch: 97 | Iteration number: [70/4518] 1% | Training loss: 0.696616348198482
Epoch: 97 | Iteration number: [80/4518] 1% | Training loss: 0.6952946692705154
Epoch: 97 | Iteration number: [90/4518] 1% | Training loss: 0.6943703691164652
Epoch: 97 | Iteration number: [100/4518] 2% | Training loss: 0.693530330657959
Epoch: 97 | Iteration number: [110/4518] 2% | Training loss: 0.6929810995405371
Epoch: 97 | Iteration number: [120/4518] 2% | Training loss: 0.6925690829753876
Epoch: 97 | Iteration number: [130/4518] 2% | Training loss: 0.69219699547841
Epoch: 97 | Iteration number: [140/4518] 3% | Training loss: 0.6918032271521432
Epoch: 97 | Iteration number: [150/4518] 3% | Training loss: 0.6916296056906382
Epoch: 97 | Iteration number: [160/4518] 3% | Training loss: 0.6913076773285866
Epoch: 97 | Iteration number: [170/4518] 3% | Training loss: 0.6910926349022809
Epoch: 97 | Iteration number: [180/4518] 3% | Training loss: 0.6908707072337469
Epoch: 97 | Iteration number: [190/4518] 4% | Training loss: 0.6906230597119583
Epoch: 97 | Iteration number: [200/4518] 4% | Training loss: 0.6904501056671143
Epoch: 97 | Iteration number: [210/4518] 4% | Training loss: 0.6902729057130359
Epoch: 97 | Iteration number: [220/4518] 4% | Training loss: 0.6901291050694206
Epoch: 97 | Iteration number: [230/4518] 5% | Training loss: 0.689913230875264
Epoch: 97 | Iteration number: [240/4518] 5% | Training loss: 0.6897800162434577
Epoch: 97 | Iteration number: [250/4518] 5% | Training loss: 0.6896749777793885
Epoch: 97 | Iteration number: [260/4518] 5% | Training loss: 0.6894984304904938
Epoch: 97 | Iteration number: [270/4518] 5% | Training loss: 0.6894555608431499
Epoch: 97 | Iteration number: [280/4518] 6% | Training loss: 0.689358152449131
Epoch: 97 | Iteration number: [290/4518] 6% | Training loss: 0.6892411007963378
Epoch: 97 | Iteration number: [300/4518] 6% | Training loss: 0.6892008074124654
Epoch: 97 | Iteration number: [310/4518] 6% | Training loss: 0.6891207420056866
Epoch: 97 | Iteration number: [320/4518] 7% | Training loss: 0.6890345886349678
Epoch: 97 | Iteration number: [330/4518] 7% | Training loss: 0.6889813648931908
Epoch: 97 | Iteration number: [340/4518] 7% | Training loss: 0.688893291704795
Epoch: 97 | Iteration number: [350/4518] 7% | Training loss: 0.6887939347539629
Epoch: 97 | Iteration number: [360/4518] 7% | Training loss: 0.6887266043159697
Epoch: 97 | Iteration number: [370/4518] 8% | Training loss: 0.6886525676057146
Epoch: 97 | Iteration number: [380/4518] 8% | Training loss: 0.6886061589968832
Epoch: 97 | Iteration number: [390/4518] 8% | Training loss: 0.6885691142999208
Epoch: 97 | Iteration number: [400/4518] 8% | Training loss: 0.6885377685725689
Epoch: 97 | Iteration number: [410/4518] 9% | Training loss: 0.6885137991207402
Epoch: 97 | Iteration number: [420/4518] 9% | Training loss: 0.6884622907354718
Epoch: 97 | Iteration number: [430/4518] 9% | Training loss: 0.6883901013884434
Epoch: 97 | Iteration number: [440/4518] 9% | Training loss: 0.6883491455153985
Epoch: 97 | Iteration number: [450/4518] 9% | Training loss: 0.6883132225937314
Epoch: 97 | Iteration number: [460/4518] 10% | Training loss: 0.68826669830343
Epoch: 97 | Iteration number: [470/4518] 10% | Training loss: 0.6882475312719953
Epoch: 97 | Iteration number: [480/4518] 10% | Training loss: 0.6882240939885378
Epoch: 97 | Iteration number: [490/4518] 10% | Training loss: 0.6882109398744545
Epoch: 97 | Iteration number: [500/4518] 11% | Training loss: 0.6881803886890412
Epoch: 97 | Iteration number: [510/4518] 11% | Training loss: 0.6881561300333808
Epoch: 97 | Iteration number: [520/4518] 11% | Training loss: 0.688118813931942
Epoch: 97 | Iteration number: [530/4518] 11% | Training loss: 0.688078059902731
Epoch: 97 | Iteration number: [540/4518] 11% | Training loss: 0.6880576825804181
Epoch: 97 | Iteration number: [550/4518] 12% | Training loss: 0.6880532636425712
Epoch: 97 | Iteration number: [560/4518] 12% | Training loss: 0.6880144673798766
Epoch: 97 | Iteration number: [570/4518] 12% | Training loss: 0.6879988299127211
Epoch: 97 | Iteration number: [580/4518] 12% | Training loss: 0.6879344470542053
Epoch: 97 | Iteration number: [590/4518] 13% | Training loss: 0.6879122304714332
Epoch: 97 | Iteration number: [600/4518] 13% | Training loss: 0.6879054319858551
Epoch: 97 | Iteration number: [610/4518] 13% | Training loss: 0.6878800203565691
Epoch: 97 | Iteration number: [620/4518] 13% | Training loss: 0.6878696132090784
Epoch: 97 | Iteration number: [630/4518] 13% | Training loss: 0.687859479870115
Epoch: 97 | Iteration number: [640/4518] 14% | Training loss: 0.6878464340232313
Epoch: 97 | Iteration number: [650/4518] 14% | Training loss: 0.6878336015114418
Epoch: 97 | Iteration number: [660/4518] 14% | Training loss: 0.687801137024706
Epoch: 97 | Iteration number: [670/4518] 14% | Training loss: 0.6877890862635712
Epoch: 97 | Iteration number: [680/4518] 15% | Training loss: 0.687783018280478
Epoch: 97 | Iteration number: [690/4518] 15% | Training loss: 0.68776597328808
Epoch: 97 | Iteration number: [700/4518] 15% | Training loss: 0.6877703035729272
Epoch: 97 | Iteration number: [710/4518] 15% | Training loss: 0.6877560541663371
Epoch: 97 | Iteration number: [720/4518] 15% | Training loss: 0.6877486383749379
Epoch: 97 | Iteration number: [730/4518] 16% | Training loss: 0.6877277489394358
Epoch: 97 | Iteration number: [740/4518] 16% | Training loss: 0.6877139813191182
Epoch: 97 | Iteration number: [750/4518] 16% | Training loss: 0.6877183609803518
Epoch: 97 | Iteration number: [760/4518] 16% | Training loss: 0.687695725262165
Epoch: 97 | Iteration number: [770/4518] 17% | Training loss: 0.6876782375496703
Epoch: 97 | Iteration number: [780/4518] 17% | Training loss: 0.6876784005990395
Epoch: 97 | Iteration number: [790/4518] 17% | Training loss: 0.6876758978336672
Epoch: 97 | Iteration number: [800/4518] 17% | Training loss: 0.687668189778924
Epoch: 97 | Iteration number: [810/4518] 17% | Training loss: 0.6876553467026463
Epoch: 97 | Iteration number: [820/4518] 18% | Training loss: 0.6876389081885175
Epoch: 97 | Iteration number: [830/4518] 18% | Training loss: 0.6876264213797558
Epoch: 97 | Iteration number: [840/4518] 18% | Training loss: 0.6876164708109129
Epoch: 97 | Iteration number: [850/4518] 18% | Training loss: 0.6876147689538844
Epoch: 97 | Iteration number: [860/4518] 19% | Training loss: 0.6876172930002212
Epoch: 97 | Iteration number: [870/4518] 19% | Training loss: 0.6875846368828039
Epoch: 97 | Iteration number: [880/4518] 19% | Training loss: 0.6875698885457082
Epoch: 97 | Iteration number: [890/4518] 19% | Training loss: 0.687546120734697
Epoch: 97 | Iteration number: [900/4518] 19% | Training loss: 0.6875284465816286
Epoch: 97 | Iteration number: [910/4518] 20% | Training loss: 0.6875206749517839
Epoch: 97 | Iteration number: [920/4518] 20% | Training loss: 0.687512926692548
Epoch: 97 | Iteration number: [930/4518] 20% | Training loss: 0.6874860136098759
Epoch: 97 | Iteration number: [940/4518] 20% | Training loss: 0.6874805971663049
Epoch: 97 | Iteration number: [950/4518] 21% | Training loss: 0.6874804581466474
Epoch: 97 | Iteration number: [960/4518] 21% | Training loss: 0.6874699046835303
Epoch: 97 | Iteration number: [970/4518] 21% | Training loss: 0.6874590678927824
Epoch: 97 | Iteration number: [980/4518] 21% | Training loss: 0.6874502632082725
Epoch: 97 | Iteration number: [990/4518] 21% | Training loss: 0.6874362236923641
Epoch: 97 | Iteration number: [1000/4518] 22% | Training loss: 0.6874331786632538
Epoch: 97 | Iteration number: [1010/4518] 22% | Training loss: 0.6874337400540267
Epoch: 97 | Iteration number: [1020/4518] 22% | Training loss: 0.6874239959553177
Epoch: 97 | Iteration number: [1030/4518] 22% | Training loss: 0.6874196997545298
Epoch: 97 | Iteration number: [1040/4518] 23% | Training loss: 0.6874142579161204
Epoch: 97 | Iteration number: [1050/4518] 23% | Training loss: 0.6874211844376156
Epoch: 97 | Iteration number: [1060/4518] 23% | Training loss: 0.6874160135129712
Epoch: 97 | Iteration number: [1070/4518] 23% | Training loss: 0.6874162730769576
Epoch: 97 | Iteration number: [1080/4518] 23% | Training loss: 0.6874202834787192
Epoch: 97 | Iteration number: [1090/4518] 24% | Training loss: 0.6874186974052989
Epoch: 97 | Iteration number: [1100/4518] 24% | Training loss: 0.6874239881472154
Epoch: 97 | Iteration number: [1110/4518] 24% | Training loss: 0.6874246085012281
Epoch: 97 | Iteration number: [1120/4518] 24% | Training loss: 0.6874252451317651
Epoch: 97 | Iteration number: [1130/4518] 25% | Training loss: 0.6874119006426989
Epoch: 97 | Iteration number: [1140/4518] 25% | Training loss: 0.6873978755976025
Epoch: 97 | Iteration number: [1150/4518] 25% | Training loss: 0.6873928883801336
Epoch: 97 | Iteration number: [1160/4518] 25% | Training loss: 0.6873834593542691
Epoch: 97 | Iteration number: [1170/4518] 25% | Training loss: 0.6873880468882048
Epoch: 97 | Iteration number: [1180/4518] 26% | Training loss: 0.6873799601853904
Epoch: 97 | Iteration number: [1190/4518] 26% | Training loss: 0.6873840776812129
Epoch: 97 | Iteration number: [1200/4518] 26% | Training loss: 0.6873725504676501
Epoch: 97 | Iteration number: [1210/4518] 26% | Training loss: 0.6873667933724144
Epoch: 97 | Iteration number: [1220/4518] 27% | Training loss: 0.6873672657814183
Epoch: 97 | Iteration number: [1230/4518] 27% | Training loss: 0.6873645526122272
Epoch: 97 | Iteration number: [1240/4518] 27% | Training loss: 0.687362540489243
Epoch: 97 | Iteration number: [1250/4518] 27% | Training loss: 0.6873604629039765
Epoch: 97 | Iteration number: [1260/4518] 27% | Training loss: 0.6873520912159057
Epoch: 97 | Iteration number: [1270/4518] 28% | Training loss: 0.6873447579661692
Epoch: 97 | Iteration number: [1280/4518] 28% | Training loss: 0.687337998719886
Epoch: 97 | Iteration number: [1290/4518] 28% | Training loss: 0.687338574034299
Epoch: 97 | Iteration number: [1300/4518] 28% | Training loss: 0.6873362840138949
Epoch: 97 | Iteration number: [1310/4518] 28% | Training loss: 0.687322294985065
Epoch: 97 | Iteration number: [1320/4518] 29% | Training loss: 0.687314655564048
Epoch: 97 | Iteration number: [1330/4518] 29% | Training loss: 0.6873129915922208
Epoch: 97 | Iteration number: [1340/4518] 29% | Training loss: 0.687306774151859
Epoch: 97 | Iteration number: [1350/4518] 29% | Training loss: 0.6873087578349644
Epoch: 97 | Iteration number: [1360/4518] 30% | Training loss: 0.6872993487207328
Epoch: 97 | Iteration number: [1370/4518] 30% | Training loss: 0.6873021754905255
Epoch: 97 | Iteration number: [1380/4518] 30% | Training loss: 0.6872973039530326
Epoch: 97 | Iteration number: [1390/4518] 30% | Training loss: 0.6872964423337429
Epoch: 97 | Iteration number: [1400/4518] 30% | Training loss: 0.6872928512522153
Epoch: 97 | Iteration number: [1410/4518] 31% | Training loss: 0.6872949688147146
Epoch: 97 | Iteration number: [1420/4518] 31% | Training loss: 0.6872848881382337
Epoch: 97 | Iteration number: [1430/4518] 31% | Training loss: 0.6872822949519524
Epoch: 97 | Iteration number: [1440/4518] 31% | Training loss: 0.687275082576606
Epoch: 97 | Iteration number: [1450/4518] 32% | Training loss: 0.6872643931569724
Epoch: 97 | Iteration number: [1460/4518] 32% | Training loss: 0.6872684461613224
Epoch: 97 | Iteration number: [1470/4518] 32% | Training loss: 0.6872656197369504
Epoch: 97 | Iteration number: [1480/4518] 32% | Training loss: 0.6872599130949458
Epoch: 97 | Iteration number: [1490/4518] 32% | Training loss: 0.6872555777930573
Epoch: 97 | Iteration number: [1500/4518] 33% | Training loss: 0.6872455680767695
Epoch: 97 | Iteration number: [1510/4518] 33% | Training loss: 0.6872388425647028
Epoch: 97 | Iteration number: [1520/4518] 33% | Training loss: 0.6872392775196778
Epoch: 97 | Iteration number: [1530/4518] 33% | Training loss: 0.6872386714991401
Epoch: 97 | Iteration number: [1540/4518] 34% | Training loss: 0.6872399566235481
Epoch: 97 | Iteration number: [1550/4518] 34% | Training loss: 0.6872411248760839
Epoch: 97 | Iteration number: [1560/4518] 34% | Training loss: 0.6872380104584571
Epoch: 97 | Iteration number: [1570/4518] 34% | Training loss: 0.6872382764603682
Epoch: 97 | Iteration number: [1580/4518] 34% | Training loss: 0.6872375777627848
Epoch: 97 | Iteration number: [1590/4518] 35% | Training loss: 0.687234073390001
Epoch: 97 | Iteration number: [1600/4518] 35% | Training loss: 0.6872329906001687
Epoch: 97 | Iteration number: [1610/4518] 35% | Training loss: 0.6872280184526621
Epoch: 97 | Iteration number: [1620/4518] 35% | Training loss: 0.6872254919122767
Epoch: 97 | Iteration number: [1630/4518] 36% | Training loss: 0.6872290430259119
Epoch: 97 | Iteration number: [1640/4518] 36% | Training loss: 0.6872256601729044
Epoch: 97 | Iteration number: [1650/4518] 36% | Training loss: 0.6872192222060579
Epoch: 97 | Iteration number: [1660/4518] 36% | Training loss: 0.687215097051069
Epoch: 97 | Iteration number: [1670/4518] 36% | Training loss: 0.6872161981588352
Epoch: 97 | Iteration number: [1680/4518] 37% | Training loss: 0.6872069881430694
Epoch: 97 | Iteration number: [1690/4518] 37% | Training loss: 0.6872008938408463
Epoch: 97 | Iteration number: [1700/4518] 37% | Training loss: 0.6871879998726004
Epoch: 97 | Iteration number: [1710/4518] 37% | Training loss: 0.6871842913111748
Epoch: 97 | Iteration number: [1720/4518] 38% | Training loss: 0.6871775001633998
Epoch: 97 | Iteration number: [1730/4518] 38% | Training loss: 0.6871648469412258
Epoch: 97 | Iteration number: [1740/4518] 38% | Training loss: 0.6871660611067695
Epoch: 97 | Iteration number: [1750/4518] 38% | Training loss: 0.6871683198724474
Epoch: 97 | Iteration number: [1760/4518] 38% | Training loss: 0.6871685029769485
Epoch: 97 | Iteration number: [1770/4518] 39% | Training loss: 0.6871668510517832
Epoch: 97 | Iteration number: [1780/4518] 39% | Training loss: 0.6871574521734474
Epoch: 97 | Iteration number: [1790/4518] 39% | Training loss: 0.6871532916689719
Epoch: 97 | Iteration number: [1800/4518] 39% | Training loss: 0.6871508208579488
Epoch: 97 | Iteration number: [1810/4518] 40% | Training loss: 0.6871485777981373
Epoch: 97 | Iteration number: [1820/4518] 40% | Training loss: 0.6871515294025232
Epoch: 97 | Iteration number: [1830/4518] 40% | Training loss: 0.6871457224660884
Epoch: 97 | Iteration number: [1840/4518] 40% | Training loss: 0.6871418137913164
Epoch: 97 | Iteration number: [1850/4518] 40% | Training loss: 0.6871336748471131
Epoch: 97 | Iteration number: [1860/4518] 41% | Training loss: 0.687139569815769
Epoch: 97 | Iteration number: [1870/4518] 41% | Training loss: 0.6871364477483984
Epoch: 97 | Iteration number: [1880/4518] 41% | Training loss: 0.6871310136102615
Epoch: 97 | Iteration number: [1890/4518] 41% | Training loss: 0.6871298061792181
Epoch: 97 | Iteration number: [1900/4518] 42% | Training loss: 0.687128616885135
Epoch: 97 | Iteration number: [1910/4518] 42% | Training loss: 0.6871255536354025
Epoch: 97 | Iteration number: [1920/4518] 42% | Training loss: 0.6871246854153772
Epoch: 97 | Iteration number: [1930/4518] 42% | Training loss: 0.6871307915047661
Epoch: 97 | Iteration number: [1940/4518] 42% | Training loss: 0.6871225605920418
Epoch: 97 | Iteration number: [1950/4518] 43% | Training loss: 0.6871236773026295
Epoch: 97 | Iteration number: [1960/4518] 43% | Training loss: 0.6871275907268329
Epoch: 97 | Iteration number: [1970/4518] 43% | Training loss: 0.6871190213915055
Epoch: 97 | Iteration number: [1980/4518] 43% | Training loss: 0.6871187252227706
Epoch: 97 | Iteration number: [1990/4518] 44% | Training loss: 0.6871136638387364
Epoch: 97 | Iteration number: [2000/4518] 44% | Training loss: 0.6871088052690029
Epoch: 97 | Iteration number: [2010/4518] 44% | Training loss: 0.6870998483688677
Epoch: 97 | Iteration number: [2020/4518] 44% | Training loss: 0.687097349349815
Epoch: 97 | Iteration number: [2030/4518] 44% | Training loss: 0.6870928360910838
Epoch: 97 | Iteration number: [2040/4518] 45% | Training loss: 0.6870942216001305
Epoch: 97 | Iteration number: [2050/4518] 45% | Training loss: 0.6870889051076843
Epoch: 97 | Iteration number: [2060/4518] 45% | Training loss: 0.6870865812000719
Epoch: 97 | Iteration number: [2070/4518] 45% | Training loss: 0.6870917937605854
Epoch: 97 | Iteration number: [2080/4518] 46% | Training loss: 0.6870875157129306
Epoch: 97 | Iteration number: [2090/4518] 46% | Training loss: 0.6870864612348913
Epoch: 97 | Iteration number: [2100/4518] 46% | Training loss: 0.6870850689070566
Epoch: 97 | Iteration number: [2110/4518] 46% | Training loss: 0.6870844325183127
Epoch: 97 | Iteration number: [2120/4518] 46% | Training loss: 0.6870807826800166
Epoch: 97 | Iteration number: [2130/4518] 47% | Training loss: 0.6870815279338282
Epoch: 97 | Iteration number: [2140/4518] 47% | Training loss: 0.6870796724457607
Epoch: 97 | Iteration number: [2150/4518] 47% | Training loss: 0.6870809142534123
Epoch: 97 | Iteration number: [2160/4518] 47% | Training loss: 0.6870790947642591
Epoch: 97 | Iteration number: [2170/4518] 48% | Training loss: 0.6870790812277024
Epoch: 97 | Iteration number: [2180/4518] 48% | Training loss: 0.6870790017580767
Epoch: 97 | Iteration number: [2190/4518] 48% | Training loss: 0.6870778240841817
Epoch: 97 | Iteration number: [2200/4518] 48% | Training loss: 0.6870761976458809
Epoch: 97 | Iteration number: [2210/4518] 48% | Training loss: 0.6870706770754508
Epoch: 97 | Iteration number: [2220/4518] 49% | Training loss: 0.6870766498215564
Epoch: 97 | Iteration number: [2230/4518] 49% | Training loss: 0.6870722493515955
Epoch: 97 | Iteration number: [2240/4518] 49% | Training loss: 0.6870720927470497
Epoch: 97 | Iteration number: [2250/4518] 49% | Training loss: 0.6870659889115227
Epoch: 97 | Iteration number: [2260/4518] 50% | Training loss: 0.6870649885551064
Epoch: 97 | Iteration number: [2270/4518] 50% | Training loss: 0.6870635067051203
Epoch: 97 | Iteration number: [2280/4518] 50% | Training loss: 0.6870586993662935
Epoch: 97 | Iteration number: [2290/4518] 50% | Training loss: 0.6870571884786197
Epoch: 97 | Iteration number: [2300/4518] 50% | Training loss: 0.6870487357222516
Epoch: 97 | Iteration number: [2310/4518] 51% | Training loss: 0.6870477269738268
Epoch: 97 | Iteration number: [2320/4518] 51% | Training loss: 0.6870460813672378
Epoch: 97 | Iteration number: [2330/4518] 51% | Training loss: 0.6870468484997238
Epoch: 97 | Iteration number: [2340/4518] 51% | Training loss: 0.687046822370627
Epoch: 97 | Iteration number: [2350/4518] 52% | Training loss: 0.6870426020470072
Epoch: 97 | Iteration number: [2360/4518] 52% | Training loss: 0.6870383085335715
Epoch: 97 | Iteration number: [2370/4518] 52% | Training loss: 0.6870393411771155
Epoch: 97 | Iteration number: [2380/4518] 52% | Training loss: 0.6870346886270187
Epoch: 97 | Iteration number: [2390/4518] 52% | Training loss: 0.6870298037967921
Epoch: 97 | Iteration number: [2400/4518] 53% | Training loss: 0.6870212218910455
Epoch: 97 | Iteration number: [2410/4518] 53% | Training loss: 0.687023786761454
Epoch: 97 | Iteration number: [2420/4518] 53% | Training loss: 0.6870174624703147
Epoch: 97 | Iteration number: [2430/4518] 53% | Training loss: 0.6870172818011218
Epoch: 97 | Iteration number: [2440/4518] 54% | Training loss: 0.6870204752830208
Epoch: 97 | Iteration number: [2450/4518] 54% | Training loss: 0.6870193343746419
Epoch: 97 | Iteration number: [2460/4518] 54% | Training loss: 0.6870200058793634
Epoch: 97 | Iteration number: [2470/4518] 54% | Training loss: 0.6870111906335421
Epoch: 97 | Iteration number: [2480/4518] 54% | Training loss: 0.687011200093454
Epoch: 97 | Iteration number: [2490/4518] 55% | Training loss: 0.6870154748001251
Epoch: 97 | Iteration number: [2500/4518] 55% | Training loss: 0.687014594745636
Epoch: 97 | Iteration number: [2510/4518] 55% | Training loss: 0.6870140593840306
Epoch: 97 | Iteration number: [2520/4518] 55% | Training loss: 0.6870033813847436
Epoch: 97 | Iteration number: [2530/4518] 55% | Training loss: 0.6870042262576785
Epoch: 97 | Iteration number: [2540/4518] 56% | Training loss: 0.6870024204723478
Epoch: 97 | Iteration number: [2550/4518] 56% | Training loss: 0.6870026628643858
Epoch: 97 | Iteration number: [2560/4518] 56% | Training loss: 0.6869993204483762
Epoch: 97 | Iteration number: [2570/4518] 56% | Training loss: 0.6869962933230492
Epoch: 97 | Iteration number: [2580/4518] 57% | Training loss: 0.6869907306146252
Epoch: 97 | Iteration number: [2590/4518] 57% | Training loss: 0.6869897821465054
Epoch: 97 | Iteration number: [2600/4518] 57% | Training loss: 0.6869963819705524
Epoch: 97 | Iteration number: [2610/4518] 57% | Training loss: 0.6869990529228445
Epoch: 97 | Iteration number: [2620/4518] 57% | Training loss: 0.6869978910411587
Epoch: 97 | Iteration number: [2630/4518] 58% | Training loss: 0.6869994492811848
Epoch: 97 | Iteration number: [2640/4518] 58% | Training loss: 0.6869950154739799
Epoch: 97 | Iteration number: [2650/4518] 58% | Training loss: 0.6869913542495584
Epoch: 97 | Iteration number: [2660/4518] 58% | Training loss: 0.6869899732950039
Epoch: 97 | Iteration number: [2670/4518] 59% | Training loss: 0.6869918065124683
Epoch: 97 | Iteration number: [2680/4518] 59% | Training loss: 0.6869914009499906
Epoch: 97 | Iteration number: [2690/4518] 59% | Training loss: 0.6869908392429351
Epoch: 97 | Iteration number: [2700/4518] 59% | Training loss: 0.6869896782989855
Epoch: 97 | Iteration number: [2710/4518] 59% | Training loss: 0.6869875954965824
Epoch: 97 | Iteration number: [2720/4518] 60% | Training loss: 0.6869851275401957
Epoch: 97 | Iteration number: [2730/4518] 60% | Training loss: 0.6869889707792373
Epoch: 97 | Iteration number: [2740/4518] 60% | Training loss: 0.6869867574994581
Epoch: 97 | Iteration number: [2750/4518] 60% | Training loss: 0.6869893139492381
Epoch: 97 | Iteration number: [2760/4518] 61% | Training loss: 0.6869928966397825
Epoch: 97 | Iteration number: [2770/4518] 61% | Training loss: 0.6869878842297014
Epoch: 97 | Iteration number: [2780/4518] 61% | Training loss: 0.6869900037702039
Epoch: 97 | Iteration number: [2790/4518] 61% | Training loss: 0.6869877077558989
Epoch: 97 | Iteration number: [2800/4518] 61% | Training loss: 0.6869822602186885
Epoch: 97 | Iteration number: [2810/4518] 62% | Training loss: 0.6869817673311539
Epoch: 97 | Iteration number: [2820/4518] 62% | Training loss: 0.6869846813644923
Epoch: 97 | Iteration number: [2830/4518] 62% | Training loss: 0.6869847580948483
Epoch: 97 | Iteration number: [2840/4518] 62% | Training loss: 0.6869834510793149
Epoch: 97 | Iteration number: [2850/4518] 63% | Training loss: 0.6869821971550323
Epoch: 97 | Iteration number: [2860/4518] 63% | Training loss: 0.6869855249678338
Epoch: 97 | Iteration number: [2870/4518] 63% | Training loss: 0.6869877241214394
Epoch: 97 | Iteration number: [2880/4518] 63% | Training loss: 0.6869871928046147
Epoch: 97 | Iteration number: [2890/4518] 63% | Training loss: 0.6869876864253444
Epoch: 97 | Iteration number: [2900/4518] 64% | Training loss: 0.6869808456815523
Epoch: 97 | Iteration number: [2910/4518] 64% | Training loss: 0.6869812595065926
Epoch: 97 | Iteration number: [2920/4518] 64% | Training loss: 0.6869769545042351
Epoch: 97 | Iteration number: [2930/4518] 64% | Training loss: 0.6869700756699558
Epoch: 97 | Iteration number: [2940/4518] 65% | Training loss: 0.6869713367450805
Epoch: 97 | Iteration number: [2950/4518] 65% | Training loss: 0.6869725317268048
Epoch: 97 | Iteration number: [2960/4518] 65% | Training loss: 0.6869668631336173
Epoch: 97 | Iteration number: [2970/4518] 65% | Training loss: 0.6869640035661383
Epoch: 97 | Iteration number: [2980/4518] 65% | Training loss: 0.6869639334862664
Epoch: 97 | Iteration number: [2990/4518] 66% | Training loss: 0.6869625137402461
Epoch: 97 | Iteration number: [3000/4518] 66% | Training loss: 0.6869619046250979
Epoch: 97 | Iteration number: [3010/4518] 66% | Training loss: 0.6869572880260176
Epoch: 97 | Iteration number: [3020/4518] 66% | Training loss: 0.6869630015843752
Epoch: 97 | Iteration number: [3030/4518] 67% | Training loss: 0.6869653957118296
Epoch: 97 | Iteration number: [3040/4518] 67% | Training loss: 0.6869676264689157
Epoch: 97 | Iteration number: [3050/4518] 67% | Training loss: 0.6869639498093089
Epoch: 97 | Iteration number: [3060/4518] 67% | Training loss: 0.6869653099892186
Epoch: 97 | Iteration number: [3070/4518] 67% | Training loss: 0.6869641958308143
Epoch: 97 | Iteration number: [3080/4518] 68% | Training loss: 0.6869610354497835
Epoch: 97 | Iteration number: [3090/4518] 68% | Training loss: 0.6869555742995253
Epoch: 97 | Iteration number: [3100/4518] 68% | Training loss: 0.6869579184247602
Epoch: 97 | Iteration number: [3110/4518] 68% | Training loss: 0.6869579711527687
Epoch: 97 | Iteration number: [3120/4518] 69% | Training loss: 0.6869542147677679
Epoch: 97 | Iteration number: [3130/4518] 69% | Training loss: 0.6869507089019202
Epoch: 97 | Iteration number: [3140/4518] 69% | Training loss: 0.6869476713951985
Epoch: 97 | Iteration number: [3150/4518] 69% | Training loss: 0.6869502888217804
Epoch: 97 | Iteration number: [3160/4518] 69% | Training loss: 0.6869513201374042
Epoch: 97 | Iteration number: [3170/4518] 70% | Training loss: 0.6869501857915511
Epoch: 97 | Iteration number: [3180/4518] 70% | Training loss: 0.6869500855229935
Epoch: 97 | Iteration number: [3190/4518] 70% | Training loss: 0.6869441047170692
Epoch: 97 | Iteration number: [3200/4518] 70% | Training loss: 0.6869441496767104
Epoch: 97 | Iteration number: [3210/4518] 71% | Training loss: 0.6869387738986922
Epoch: 97 | Iteration number: [3220/4518] 71% | Training loss: 0.6869368919674654
Epoch: 97 | Iteration number: [3230/4518] 71% | Training loss: 0.6869400728228661
Epoch: 97 | Iteration number: [3240/4518] 71% | Training loss: 0.686936810704661
Epoch: 97 | Iteration number: [3250/4518] 71% | Training loss: 0.6869381987314958
Epoch: 97 | Iteration number: [3260/4518] 72% | Training loss: 0.6869343726912891
Epoch: 97 | Iteration number: [3270/4518] 72% | Training loss: 0.6869323607067085
Epoch: 97 | Iteration number: [3280/4518] 72% | Training loss: 0.6869379330699037
Epoch: 97 | Iteration number: [3290/4518] 72% | Training loss: 0.6869387686614932
Epoch: 97 | Iteration number: [3300/4518] 73% | Training loss: 0.6869383946151444
Epoch: 97 | Iteration number: [3310/4518] 73% | Training loss: 0.6869376873501838
Epoch: 97 | Iteration number: [3320/4518] 73% | Training loss: 0.686938761623509
Epoch: 97 | Iteration number: [3330/4518] 73% | Training loss: 0.6869373351783008
Epoch: 97 | Iteration number: [3340/4518] 73% | Training loss: 0.6869356335994012
Epoch: 97 | Iteration number: [3350/4518] 74% | Training loss: 0.686933710130293
Epoch: 97 | Iteration number: [3360/4518] 74% | Training loss: 0.6869368413197142
Epoch: 97 | Iteration number: [3370/4518] 74% | Training loss: 0.6869384032682424
Epoch: 97 | Iteration number: [3380/4518] 74% | Training loss: 0.686939198995483
Epoch: 97 | Iteration number: [3390/4518] 75% | Training loss: 0.6869360244907109
Epoch: 97 | Iteration number: [3400/4518] 75% | Training loss: 0.6869325969149085
Epoch: 97 | Iteration number: [3410/4518] 75% | Training loss: 0.6869318970836852
Epoch: 97 | Iteration number: [3420/4518] 75% | Training loss: 0.6869327646772764
Epoch: 97 | Iteration number: [3430/4518] 75% | Training loss: 0.6869290547016411
Epoch: 97 | Iteration number: [3440/4518] 76% | Training loss: 0.6869301266448442
Epoch: 97 | Iteration number: [3450/4518] 76% | Training loss: 0.6869286190599635
Epoch: 97 | Iteration number: [3460/4518] 76% | Training loss: 0.6869282319538855
Epoch: 97 | Iteration number: [3470/4518] 76% | Training loss: 0.6869311103216166
Epoch: 97 | Iteration number: [3480/4518] 77% | Training loss: 0.6869315943156166
Epoch: 97 | Iteration number: [3490/4518] 77% | Training loss: 0.6869310744000028
Epoch: 97 | Iteration number: [3500/4518] 77% | Training loss: 0.6869271167346409
Epoch: 97 | Iteration number: [3510/4518] 77% | Training loss: 0.6869240136058242
Epoch: 97 | Iteration number: [3520/4518] 77% | Training loss: 0.6869244507429275
Epoch: 97 | Iteration number: [3530/4518] 78% | Training loss: 0.6869265852501305
Epoch: 97 | Iteration number: [3540/4518] 78% | Training loss: 0.686928770973184
Epoch: 97 | Iteration number: [3550/4518] 78% | Training loss: 0.6869310056659538
Epoch: 97 | Iteration number: [3560/4518] 78% | Training loss: 0.6869310874115215
Epoch: 97 | Iteration number: [3570/4518] 79% | Training loss: 0.6869321205368897
Epoch: 97 | Iteration number: [3580/4518] 79% | Training loss: 0.6869334610480836
Epoch: 97 | Iteration number: [3590/4518] 79% | Training loss: 0.6869324802024118
Epoch: 97 | Iteration number: [3600/4518] 79% | Training loss: 0.686929395082924
Epoch: 97 | Iteration number: [3610/4518] 79% | Training loss: 0.686927419075345
Epoch: 97 | Iteration number: [3620/4518] 80% | Training loss: 0.6869245553378901
Epoch: 97 | Iteration number: [3630/4518] 80% | Training loss: 0.6869243253853695
Epoch: 97 | Iteration number: [3640/4518] 80% | Training loss: 0.6869228958919809
Epoch: 97 | Iteration number: [3650/4518] 80% | Training loss: 0.6869237162642283
Epoch: 97 | Iteration number: [3660/4518] 81% | Training loss: 0.6869231971235223
Epoch: 97 | Iteration number: [3670/4518] 81% | Training loss: 0.6869227685460603
Epoch: 97 | Iteration number: [3680/4518] 81% | Training loss: 0.6869202338321053
Epoch: 97 | Iteration number: [3690/4518] 81% | Training loss: 0.686921083539482
Epoch: 97 | Iteration number: [3700/4518] 81% | Training loss: 0.6869190247155524
Epoch: 97 | Iteration number: [3710/4518] 82% | Training loss: 0.6869189520730484
Epoch: 97 | Iteration number: [3720/4518] 82% | Training loss: 0.6869176596403122
Epoch: 97 | Iteration number: [3730/4518] 82% | Training loss: 0.6869173230818065
Epoch: 97 | Iteration number: [3740/4518] 82% | Training loss: 0.6869141829683182
Epoch: 97 | Iteration number: [3750/4518] 83% | Training loss: 0.6869170222918193
Epoch: 97 | Iteration number: [3760/4518] 83% | Training loss: 0.6869188685842017
Epoch: 97 | Iteration number: [3770/4518] 83% | Training loss: 0.6869183856865455
Epoch: 97 | Iteration number: [3780/4518] 83% | Training loss: 0.6869147947067937
Epoch: 97 | Iteration number: [3790/4518] 83% | Training loss: 0.6869178937576063
Epoch: 97 | Iteration number: [3800/4518] 84% | Training loss: 0.6869170946823924
Epoch: 97 | Iteration number: [3810/4518] 84% | Training loss: 0.6869218297048504
Epoch: 97 | Iteration number: [3820/4518] 84% | Training loss: 0.6869234895831003
Epoch: 97 | Iteration number: [3830/4518] 84% | Training loss: 0.6869192602429004
Epoch: 97 | Iteration number: [3840/4518] 84% | Training loss: 0.6869226027590533
Epoch: 97 | Iteration number: [3850/4518] 85% | Training loss: 0.6869183459374811
Epoch: 97 | Iteration number: [3860/4518] 85% | Training loss: 0.686917710072636
Epoch: 97 | Iteration number: [3870/4518] 85% | Training loss: 0.6869185807014928
Epoch: 97 | Iteration number: [3880/4518] 85% | Training loss: 0.6869179908915893
Epoch: 97 | Iteration number: [3890/4518] 86% | Training loss: 0.6869197804547827
Epoch: 97 | Iteration number: [3900/4518] 86% | Training loss: 0.6869222384385574
Epoch: 97 | Iteration number: [3910/4518] 86% | Training loss: 0.6869235988163277
Epoch: 97 | Iteration number: [3920/4518] 86% | Training loss: 0.6869266634845004
Epoch: 97 | Iteration number: [3930/4518] 86% | Training loss: 0.6869258284568787
Epoch: 97 | Iteration number: [3940/4518] 87% | Training loss: 0.6869297754189689
Epoch: 97 | Iteration number: [3950/4518] 87% | Training loss: 0.686931056372727
Epoch: 97 | Iteration number: [3960/4518] 87% | Training loss: 0.6869304145827438
Epoch: 97 | Iteration number: [3970/4518] 87% | Training loss: 0.6869322675901937
Epoch: 97 | Iteration number: [3980/4518] 88% | Training loss: 0.6869288173602454
Epoch: 97 | Iteration number: [3990/4518] 88% | Training loss: 0.6869254696787449
Epoch: 97 | Iteration number: [4000/4518] 88% | Training loss: 0.6869237899780274
Epoch: 97 | Iteration number: [4010/4518] 88% | Training loss: 0.6869229517821361
Epoch: 97 | Iteration number: [4020/4518] 88% | Training loss: 0.6869237316929879
Epoch: 97 | Iteration number: [4030/4518] 89% | Training loss: 0.6869232626470088
Epoch: 97 | Iteration number: [4040/4518] 89% | Training loss: 0.6869234185112585
Epoch: 97 | Iteration number: [4050/4518] 89% | Training loss: 0.6869210290320126
Epoch: 97 | Iteration number: [4060/4518] 89% | Training loss: 0.686919942512888
Epoch: 97 | Iteration number: [4070/4518] 90% | Training loss: 0.6869182888354365
Epoch: 97 | Iteration number: [4080/4518] 90% | Training loss: 0.6869192509820649
Epoch: 97 | Iteration number: [4090/4518] 90% | Training loss: 0.6869212689784453
Epoch: 97 | Iteration number: [4100/4518] 90% | Training loss: 0.6869234044958905
Epoch: 97 | Iteration number: [4110/4518] 90% | Training loss: 0.6869255679947326
Epoch: 97 | Iteration number: [4120/4518] 91% | Training loss: 0.6869257651920457
Epoch: 97 | Iteration number: [4130/4518] 91% | Training loss: 0.6869273627641415
Epoch: 97 | Iteration number: [4140/4518] 91% | Training loss: 0.6869282111885467
Epoch: 97 | Iteration number: [4150/4518] 91% | Training loss: 0.6869257212403309
Epoch: 97 | Iteration number: [4160/4518] 92% | Training loss: 0.6869241417457278
Epoch: 97 | Iteration number: [4170/4518] 92% | Training loss: 0.6869233395984704
Epoch: 97 | Iteration number: [4180/4518] 92% | Training loss: 0.6869226089077133
Epoch: 97 | Iteration number: [4190/4518] 92% | Training loss: 0.686920598554725
Epoch: 97 | Iteration number: [4200/4518] 92% | Training loss: 0.6869215657313664
Epoch: 97 | Iteration number: [4210/4518] 93% | Training loss: 0.6869242517795245
Epoch: 97 | Iteration number: [4220/4518] 93% | Training loss: 0.6869237225202588
Epoch: 97 | Iteration number: [4230/4518] 93% | Training loss: 0.6869228389105335
Epoch: 97 | Iteration number: [4240/4518] 93% | Training loss: 0.6869219535504872
Epoch: 97 | Iteration number: [4250/4518] 94% | Training loss: 0.6869206369484172
Epoch: 97 | Iteration number: [4260/4518] 94% | Training loss: 0.6869225187620647
Epoch: 97 | Iteration number: [4270/4518] 94% | Training loss: 0.6869201323885549
Epoch: 97 | Iteration number: [4280/4518] 94% | Training loss: 0.6869166828622327
Epoch: 97 | Iteration number: [4290/4518] 94% | Training loss: 0.6869158939603881
Epoch: 97 | Iteration number: [4300/4518] 95% | Training loss: 0.686914408900017
Epoch: 97 | Iteration number: [4310/4518] 95% | Training loss: 0.6869111349438847
Epoch: 97 | Iteration number: [4320/4518] 95% | Training loss: 0.6869083084993892
Epoch: 97 | Iteration number: [4330/4518] 95% | Training loss: 0.6869093256238977
Epoch: 97 | Iteration number: [4340/4518] 96% | Training loss: 0.6869096082888441
Epoch: 97 | Iteration number: [4350/4518] 96% | Training loss: 0.6869097270499701
Epoch: 97 | Iteration number: [4360/4518] 96% | Training loss: 0.6869107052820538
Epoch: 97 | Iteration number: [4370/4518] 96% | Training loss: 0.6869097216451195
Epoch: 97 | Iteration number: [4380/4518] 96% | Training loss: 0.6869072147972508
Epoch: 97 | Iteration number: [4390/4518] 97% | Training loss: 0.6869045723543623
Epoch: 97 | Iteration number: [4400/4518] 97% | Training loss: 0.6869060127030719
Epoch: 97 | Iteration number: [4410/4518] 97% | Training loss: 0.6869069621000701
Epoch: 97 | Iteration number: [4420/4518] 97% | Training loss: 0.6869061757401643
Epoch: 97 | Iteration number: [4430/4518] 98% | Training loss: 0.6869049815910934
Epoch: 97 | Iteration number: [4440/4518] 98% | Training loss: 0.6869026571646467
Epoch: 97 | Iteration number: [4450/4518] 98% | Training loss: 0.6869028778022594
Epoch: 97 | Iteration number: [4460/4518] 98% | Training loss: 0.6869020076476939
Epoch: 97 | Iteration number: [4470/4518] 98% | Training loss: 0.6869029148046336
Epoch: 97 | Iteration number: [4480/4518] 99% | Training loss: 0.6869029869591551
Epoch: 97 | Iteration number: [4490/4518] 99% | Training loss: 0.6869020363934056
Epoch: 97 | Iteration number: [4500/4518] 99% | Training loss: 0.6868995122379726
Epoch: 97 | Iteration number: [4510/4518] 99% | Training loss: 0.6868988730690696

 End of epoch: 97 | Train Loss: 0.6867454682186991 | Training Time: 632 

 End of epoch: 97 | Eval Loss: 0.689544175352369 | Evaluating Time: 17 
Epoch: 98 | Iteration number: [10/4518] 0% | Training loss: 0.7560199797153473
Epoch: 98 | Iteration number: [20/4518] 0% | Training loss: 0.7207965165376663
Epoch: 98 | Iteration number: [30/4518] 0% | Training loss: 0.7091666301091512
Epoch: 98 | Iteration number: [40/4518] 0% | Training loss: 0.7034021481871605
Epoch: 98 | Iteration number: [50/4518] 1% | Training loss: 0.6999705696105957
Epoch: 98 | Iteration number: [60/4518] 1% | Training loss: 0.6978377789258957
Epoch: 98 | Iteration number: [70/4518] 1% | Training loss: 0.6962119477135794
Epoch: 98 | Iteration number: [80/4518] 1% | Training loss: 0.6951093882322311
Epoch: 98 | Iteration number: [90/4518] 1% | Training loss: 0.6942280683252546
Epoch: 98 | Iteration number: [100/4518] 2% | Training loss: 0.6935725533962249
Epoch: 98 | Iteration number: [110/4518] 2% | Training loss: 0.6929622173309327
Epoch: 98 | Iteration number: [120/4518] 2% | Training loss: 0.6924251566330591
Epoch: 98 | Iteration number: [130/4518] 2% | Training loss: 0.6920158895162436
Epoch: 98 | Iteration number: [140/4518] 3% | Training loss: 0.6916404400553022
Epoch: 98 | Iteration number: [150/4518] 3% | Training loss: 0.6912393041451772
Epoch: 98 | Iteration number: [160/4518] 3% | Training loss: 0.6909258119761944
Epoch: 98 | Iteration number: [170/4518] 3% | Training loss: 0.69068644397399
Epoch: 98 | Iteration number: [180/4518] 3% | Training loss: 0.6905193133486642
Epoch: 98 | Iteration number: [190/4518] 4% | Training loss: 0.690371750216735
Epoch: 98 | Iteration number: [200/4518] 4% | Training loss: 0.6902436247467995
Epoch: 98 | Iteration number: [210/4518] 4% | Training loss: 0.6901124505769639
Epoch: 98 | Iteration number: [220/4518] 4% | Training loss: 0.6899593903259797
Epoch: 98 | Iteration number: [230/4518] 5% | Training loss: 0.689837836700937
Epoch: 98 | Iteration number: [240/4518] 5% | Training loss: 0.689712285498778
Epoch: 98 | Iteration number: [250/4518] 5% | Training loss: 0.6896091060638427
Epoch: 98 | Iteration number: [260/4518] 5% | Training loss: 0.6894892254701027
Epoch: 98 | Iteration number: [270/4518] 5% | Training loss: 0.6894050664371915
Epoch: 98 | Iteration number: [280/4518] 6% | Training loss: 0.6893486910632678
Epoch: 98 | Iteration number: [290/4518] 6% | Training loss: 0.689217208993846
Epoch: 98 | Iteration number: [300/4518] 6% | Training loss: 0.6890879768133163
Epoch: 98 | Iteration number: [310/4518] 6% | Training loss: 0.6890603886496636
Epoch: 98 | Iteration number: [320/4518] 7% | Training loss: 0.6890435703098774
Epoch: 98 | Iteration number: [330/4518] 7% | Training loss: 0.6889454763947112
Epoch: 98 | Iteration number: [340/4518] 7% | Training loss: 0.6888671959147734
Epoch: 98 | Iteration number: [350/4518] 7% | Training loss: 0.6888287399496351
Epoch: 98 | Iteration number: [360/4518] 7% | Training loss: 0.6887361190385288
Epoch: 98 | Iteration number: [370/4518] 8% | Training loss: 0.6886811432000753
Epoch: 98 | Iteration number: [380/4518] 8% | Training loss: 0.6885816751342071
Epoch: 98 | Iteration number: [390/4518] 8% | Training loss: 0.6885275889665653
Epoch: 98 | Iteration number: [400/4518] 8% | Training loss: 0.6884792874753475
Epoch: 98 | Iteration number: [410/4518] 9% | Training loss: 0.6884359569084354
Epoch: 98 | Iteration number: [420/4518] 9% | Training loss: 0.68839272970245
Epoch: 98 | Iteration number: [430/4518] 9% | Training loss: 0.6883565424486648
Epoch: 98 | Iteration number: [440/4518] 9% | Training loss: 0.6883109634572809
Epoch: 98 | Iteration number: [450/4518] 9% | Training loss: 0.6882804493109386
Epoch: 98 | Iteration number: [460/4518] 10% | Training loss: 0.688251174144123
Epoch: 98 | Iteration number: [470/4518] 10% | Training loss: 0.6882312556530567
Epoch: 98 | Iteration number: [480/4518] 10% | Training loss: 0.6881721804539362
Epoch: 98 | Iteration number: [490/4518] 10% | Training loss: 0.6881369104190749
Epoch: 98 | Iteration number: [500/4518] 11% | Training loss: 0.68809663438797
Epoch: 98 | Iteration number: [510/4518] 11% | Training loss: 0.6880865987609415
Epoch: 98 | Iteration number: [520/4518] 11% | Training loss: 0.6880480875189487
Epoch: 98 | Iteration number: [530/4518] 11% | Training loss: 0.6880237812141202
Epoch: 98 | Iteration number: [540/4518] 11% | Training loss: 0.6879958773100817
Epoch: 98 | Iteration number: [550/4518] 12% | Training loss: 0.6879723797061227
Epoch: 98 | Iteration number: [560/4518] 12% | Training loss: 0.6879429414868354
Epoch: 98 | Iteration number: [570/4518] 12% | Training loss: 0.6879138281470851
Epoch: 98 | Iteration number: [580/4518] 12% | Training loss: 0.6878932163633149
Epoch: 98 | Iteration number: [590/4518] 13% | Training loss: 0.6878452072709293
Epoch: 98 | Iteration number: [600/4518] 13% | Training loss: 0.6878265618284544
Epoch: 98 | Iteration number: [610/4518] 13% | Training loss: 0.6878150215891541
Epoch: 98 | Iteration number: [620/4518] 13% | Training loss: 0.6878031954649956
Epoch: 98 | Iteration number: [630/4518] 13% | Training loss: 0.6877780989995078
Epoch: 98 | Iteration number: [640/4518] 14% | Training loss: 0.6877646987326443
Epoch: 98 | Iteration number: [650/4518] 14% | Training loss: 0.6877505454650292
Epoch: 98 | Iteration number: [660/4518] 14% | Training loss: 0.6877522844256777
Epoch: 98 | Iteration number: [670/4518] 14% | Training loss: 0.687743343613041
Epoch: 98 | Iteration number: [680/4518] 15% | Training loss: 0.6877447440343745
Epoch: 98 | Iteration number: [690/4518] 15% | Training loss: 0.6877546990263289
Epoch: 98 | Iteration number: [700/4518] 15% | Training loss: 0.6877482844250543
Epoch: 98 | Iteration number: [710/4518] 15% | Training loss: 0.6877516607163657
Epoch: 98 | Iteration number: [720/4518] 15% | Training loss: 0.6877365570101474
Epoch: 98 | Iteration number: [730/4518] 16% | Training loss: 0.6877319749904005
Epoch: 98 | Iteration number: [740/4518] 16% | Training loss: 0.6877214357659623
Epoch: 98 | Iteration number: [750/4518] 16% | Training loss: 0.6876944666703542
Epoch: 98 | Iteration number: [760/4518] 16% | Training loss: 0.6876915127823228
Epoch: 98 | Iteration number: [770/4518] 17% | Training loss: 0.6876765849528375
Epoch: 98 | Iteration number: [780/4518] 17% | Training loss: 0.687667111097238
Epoch: 98 | Iteration number: [790/4518] 17% | Training loss: 0.6876617387125764
Epoch: 98 | Iteration number: [800/4518] 17% | Training loss: 0.6876471523195505
Epoch: 98 | Iteration number: [810/4518] 17% | Training loss: 0.6876235180430942
Epoch: 98 | Iteration number: [820/4518] 18% | Training loss: 0.6876090765726276
Epoch: 98 | Iteration number: [830/4518] 18% | Training loss: 0.6876041333359408
Epoch: 98 | Iteration number: [840/4518] 18% | Training loss: 0.6875817614651861
Epoch: 98 | Iteration number: [850/4518] 18% | Training loss: 0.6875704829131856
Epoch: 98 | Iteration number: [860/4518] 19% | Training loss: 0.687576809733413
Epoch: 98 | Iteration number: [870/4518] 19% | Training loss: 0.6875627253247404
Epoch: 98 | Iteration number: [880/4518] 19% | Training loss: 0.6875580988824368
Epoch: 98 | Iteration number: [890/4518] 19% | Training loss: 0.6875448117765148
Epoch: 98 | Iteration number: [900/4518] 19% | Training loss: 0.6875210574600432
Epoch: 98 | Iteration number: [910/4518] 20% | Training loss: 0.6874895836625781
Epoch: 98 | Iteration number: [920/4518] 20% | Training loss: 0.68747912146475
Epoch: 98 | Iteration number: [930/4518] 20% | Training loss: 0.6874792091308102
Epoch: 98 | Iteration number: [940/4518] 20% | Training loss: 0.6874633116925016
Epoch: 98 | Iteration number: [950/4518] 21% | Training loss: 0.6874440185647261
Epoch: 98 | Iteration number: [960/4518] 21% | Training loss: 0.687436340811352
Epoch: 98 | Iteration number: [970/4518] 21% | Training loss: 0.6874217399616831
Epoch: 98 | Iteration number: [980/4518] 21% | Training loss: 0.6874136873653957
Epoch: 98 | Iteration number: [990/4518] 21% | Training loss: 0.6874023902897883
Epoch: 98 | Iteration number: [1000/4518] 22% | Training loss: 0.6873913824558258
Epoch: 98 | Iteration number: [1010/4518] 22% | Training loss: 0.6873898240599302
Epoch: 98 | Iteration number: [1020/4518] 22% | Training loss: 0.6873899950116289
Epoch: 98 | Iteration number: [1030/4518] 22% | Training loss: 0.6873744904994965
Epoch: 98 | Iteration number: [1040/4518] 23% | Training loss: 0.6873699906353767
Epoch: 98 | Iteration number: [1050/4518] 23% | Training loss: 0.6873638053167433
Epoch: 98 | Iteration number: [1060/4518] 23% | Training loss: 0.6873605671918617
Epoch: 98 | Iteration number: [1070/4518] 23% | Training loss: 0.6873547692722249
Epoch: 98 | Iteration number: [1080/4518] 23% | Training loss: 0.6873376876667694
Epoch: 98 | Iteration number: [1090/4518] 24% | Training loss: 0.6873210889483811
Epoch: 98 | Iteration number: [1100/4518] 24% | Training loss: 0.6873142842812971
Epoch: 98 | Iteration number: [1110/4518] 24% | Training loss: 0.6873089779067684
Epoch: 98 | Iteration number: [1120/4518] 24% | Training loss: 0.6873019709650959
Epoch: 98 | Iteration number: [1130/4518] 25% | Training loss: 0.6872936918672207
Epoch: 98 | Iteration number: [1140/4518] 25% | Training loss: 0.6872839916693537
Epoch: 98 | Iteration number: [1150/4518] 25% | Training loss: 0.6872799380965855
Epoch: 98 | Iteration number: [1160/4518] 25% | Training loss: 0.6872821519087101
Epoch: 98 | Iteration number: [1170/4518] 25% | Training loss: 0.6872788809812986
Epoch: 98 | Iteration number: [1180/4518] 26% | Training loss: 0.6872809386354382
Epoch: 98 | Iteration number: [1190/4518] 26% | Training loss: 0.6872890246014635
Epoch: 98 | Iteration number: [1200/4518] 26% | Training loss: 0.687299425949653
Epoch: 98 | Iteration number: [1210/4518] 26% | Training loss: 0.6872999938066341
Epoch: 98 | Iteration number: [1220/4518] 27% | Training loss: 0.6873071156075743
Epoch: 98 | Iteration number: [1230/4518] 27% | Training loss: 0.6873057781196222
Epoch: 98 | Iteration number: [1240/4518] 27% | Training loss: 0.6873023131201345
Epoch: 98 | Iteration number: [1250/4518] 27% | Training loss: 0.6873090489387512
Epoch: 98 | Iteration number: [1260/4518] 27% | Training loss: 0.6873035023136744
Epoch: 98 | Iteration number: [1270/4518] 28% | Training loss: 0.6873033984439579
Epoch: 98 | Iteration number: [1280/4518] 28% | Training loss: 0.687301150849089
Epoch: 98 | Iteration number: [1290/4518] 28% | Training loss: 0.6872941905213881
Epoch: 98 | Iteration number: [1300/4518] 28% | Training loss: 0.6872979656091103
Epoch: 98 | Iteration number: [1310/4518] 28% | Training loss: 0.6872932816279753
Epoch: 98 | Iteration number: [1320/4518] 29% | Training loss: 0.6872827985973069
Epoch: 98 | Iteration number: [1330/4518] 29% | Training loss: 0.687288198524848
Epoch: 98 | Iteration number: [1340/4518] 29% | Training loss: 0.6872864063995988
Epoch: 98 | Iteration number: [1350/4518] 29% | Training loss: 0.6872741992826815
Epoch: 98 | Iteration number: [1360/4518] 30% | Training loss: 0.6872718772467445
Epoch: 98 | Iteration number: [1370/4518] 30% | Training loss: 0.6872791375121932
Epoch: 98 | Iteration number: [1380/4518] 30% | Training loss: 0.6872726334609847
Epoch: 98 | Iteration number: [1390/4518] 30% | Training loss: 0.6872689842320174
Epoch: 98 | Iteration number: [1400/4518] 30% | Training loss: 0.687270233971732
Epoch: 98 | Iteration number: [1410/4518] 31% | Training loss: 0.6872733902001212
Epoch: 98 | Iteration number: [1420/4518] 31% | Training loss: 0.6872746620799454
Epoch: 98 | Iteration number: [1430/4518] 31% | Training loss: 0.6872692174427992
Epoch: 98 | Iteration number: [1440/4518] 31% | Training loss: 0.6872583948075771
Epoch: 98 | Iteration number: [1450/4518] 32% | Training loss: 0.687252418583837
Epoch: 98 | Iteration number: [1460/4518] 32% | Training loss: 0.6872448221461414
Epoch: 98 | Iteration number: [1470/4518] 32% | Training loss: 0.687241845106592
Epoch: 98 | Iteration number: [1480/4518] 32% | Training loss: 0.6872417474115217
Epoch: 98 | Iteration number: [1490/4518] 32% | Training loss: 0.6872455352904813
Epoch: 98 | Iteration number: [1500/4518] 33% | Training loss: 0.6872474761406581
Epoch: 98 | Iteration number: [1510/4518] 33% | Training loss: 0.6872417717974707
Epoch: 98 | Iteration number: [1520/4518] 33% | Training loss: 0.6872335247303311
Epoch: 98 | Iteration number: [1530/4518] 33% | Training loss: 0.687235755234762
Epoch: 98 | Iteration number: [1540/4518] 34% | Training loss: 0.6872287169292376
Epoch: 98 | Iteration number: [1550/4518] 34% | Training loss: 0.6872146441475038
Epoch: 98 | Iteration number: [1560/4518] 34% | Training loss: 0.6872153002100113
Epoch: 98 | Iteration number: [1570/4518] 34% | Training loss: 0.687215249933255
Epoch: 98 | Iteration number: [1580/4518] 34% | Training loss: 0.6872116240142266
Epoch: 98 | Iteration number: [1590/4518] 35% | Training loss: 0.6871981442349512
Epoch: 98 | Iteration number: [1600/4518] 35% | Training loss: 0.6871910434961319
Epoch: 98 | Iteration number: [1610/4518] 35% | Training loss: 0.6871840505866531
Epoch: 98 | Iteration number: [1620/4518] 35% | Training loss: 0.6871913961422296
Epoch: 98 | Iteration number: [1630/4518] 36% | Training loss: 0.687196388858959
Epoch: 98 | Iteration number: [1640/4518] 36% | Training loss: 0.6871903464198112
Epoch: 98 | Iteration number: [1650/4518] 36% | Training loss: 0.6871896687782172
Epoch: 98 | Iteration number: [1660/4518] 36% | Training loss: 0.6871815739984972
Epoch: 98 | Iteration number: [1670/4518] 36% | Training loss: 0.6871784562122322
Epoch: 98 | Iteration number: [1680/4518] 37% | Training loss: 0.6871702243174825
Epoch: 98 | Iteration number: [1690/4518] 37% | Training loss: 0.6871666961167691
Epoch: 98 | Iteration number: [1700/4518] 37% | Training loss: 0.6871608679434832
Epoch: 98 | Iteration number: [1710/4518] 37% | Training loss: 0.6871539405911986
Epoch: 98 | Iteration number: [1720/4518] 38% | Training loss: 0.6871490163165469
Epoch: 98 | Iteration number: [1730/4518] 38% | Training loss: 0.6871459660502528
Epoch: 98 | Iteration number: [1740/4518] 38% | Training loss: 0.6871375955726908
Epoch: 98 | Iteration number: [1750/4518] 38% | Training loss: 0.6871331991468157
Epoch: 98 | Iteration number: [1760/4518] 38% | Training loss: 0.6871289689771154
Epoch: 98 | Iteration number: [1770/4518] 39% | Training loss: 0.6871271353993712
Epoch: 98 | Iteration number: [1780/4518] 39% | Training loss: 0.6871261824047967
Epoch: 98 | Iteration number: [1790/4518] 39% | Training loss: 0.6871251888115313
Epoch: 98 | Iteration number: [1800/4518] 39% | Training loss: 0.6871220972471767
Epoch: 98 | Iteration number: [1810/4518] 40% | Training loss: 0.6871278216167049
Epoch: 98 | Iteration number: [1820/4518] 40% | Training loss: 0.68712778035756
Epoch: 98 | Iteration number: [1830/4518] 40% | Training loss: 0.687119214554302
Epoch: 98 | Iteration number: [1840/4518] 40% | Training loss: 0.6871179131710011
Epoch: 98 | Iteration number: [1850/4518] 40% | Training loss: 0.6871177425255647
Epoch: 98 | Iteration number: [1860/4518] 41% | Training loss: 0.6871183292519661
Epoch: 98 | Iteration number: [1870/4518] 41% | Training loss: 0.687113085118207
Epoch: 98 | Iteration number: [1880/4518] 41% | Training loss: 0.68710599471914
Epoch: 98 | Iteration number: [1890/4518] 41% | Training loss: 0.6871107031743994
Epoch: 98 | Iteration number: [1900/4518] 42% | Training loss: 0.6871105387963746
Epoch: 98 | Iteration number: [1910/4518] 42% | Training loss: 0.6871055464782015
Epoch: 98 | Iteration number: [1920/4518] 42% | Training loss: 0.6871016910610099
Epoch: 98 | Iteration number: [1930/4518] 42% | Training loss: 0.6870949851725385
Epoch: 98 | Iteration number: [1940/4518] 42% | Training loss: 0.6870921185336162
Epoch: 98 | Iteration number: [1950/4518] 43% | Training loss: 0.6870910403667352
Epoch: 98 | Iteration number: [1960/4518] 43% | Training loss: 0.6870893129280635
Epoch: 98 | Iteration number: [1970/4518] 43% | Training loss: 0.6870882006466086
Epoch: 98 | Iteration number: [1980/4518] 43% | Training loss: 0.6870831749053916
Epoch: 98 | Iteration number: [1990/4518] 44% | Training loss: 0.6870869711415851
Epoch: 98 | Iteration number: [2000/4518] 44% | Training loss: 0.6870824398696422
Epoch: 98 | Iteration number: [2010/4518] 44% | Training loss: 0.6870807410176121
Epoch: 98 | Iteration number: [2020/4518] 44% | Training loss: 0.6870844237580158
Epoch: 98 | Iteration number: [2030/4518] 44% | Training loss: 0.68708247289869
Epoch: 98 | Iteration number: [2040/4518] 45% | Training loss: 0.6870801760869868
Epoch: 98 | Iteration number: [2050/4518] 45% | Training loss: 0.6870770576523572
Epoch: 98 | Iteration number: [2060/4518] 45% | Training loss: 0.6870742202673144
Epoch: 98 | Iteration number: [2070/4518] 45% | Training loss: 0.6870748040756741
Epoch: 98 | Iteration number: [2080/4518] 46% | Training loss: 0.6870676514620965
Epoch: 98 | Iteration number: [2090/4518] 46% | Training loss: 0.6870705006225257
Epoch: 98 | Iteration number: [2100/4518] 46% | Training loss: 0.687064705320767
Epoch: 98 | Iteration number: [2110/4518] 46% | Training loss: 0.6870684078801864
Epoch: 98 | Iteration number: [2120/4518] 46% | Training loss: 0.6870707777873525
Epoch: 98 | Iteration number: [2130/4518] 47% | Training loss: 0.6870593119675005
Epoch: 98 | Iteration number: [2140/4518] 47% | Training loss: 0.6870542044394484
Epoch: 98 | Iteration number: [2150/4518] 47% | Training loss: 0.6870508892314379
Epoch: 98 | Iteration number: [2160/4518] 47% | Training loss: 0.6870444966963044
Epoch: 98 | Iteration number: [2170/4518] 48% | Training loss: 0.687041696562745
Epoch: 98 | Iteration number: [2180/4518] 48% | Training loss: 0.6870407240379841
Epoch: 98 | Iteration number: [2190/4518] 48% | Training loss: 0.6870394156948072
Epoch: 98 | Iteration number: [2200/4518] 48% | Training loss: 0.6870404943011024
Epoch: 98 | Iteration number: [2210/4518] 48% | Training loss: 0.687030821121656
Epoch: 98 | Iteration number: [2220/4518] 49% | Training loss: 0.6870355186698673
Epoch: 98 | Iteration number: [2230/4518] 49% | Training loss: 0.6870246410637159
Epoch: 98 | Iteration number: [2240/4518] 49% | Training loss: 0.687021273188293
Epoch: 98 | Iteration number: [2250/4518] 49% | Training loss: 0.6870142095088959
Epoch: 98 | Iteration number: [2260/4518] 50% | Training loss: 0.6870107603811585
Epoch: 98 | Iteration number: [2270/4518] 50% | Training loss: 0.6870109677052183
Epoch: 98 | Iteration number: [2280/4518] 50% | Training loss: 0.6870068929697338
Epoch: 98 | Iteration number: [2290/4518] 50% | Training loss: 0.6870020748486165
Epoch: 98 | Iteration number: [2300/4518] 50% | Training loss: 0.687003098518952
Epoch: 98 | Iteration number: [2310/4518] 51% | Training loss: 0.6870080811120731
Epoch: 98 | Iteration number: [2320/4518] 51% | Training loss: 0.687009835397375
Epoch: 98 | Iteration number: [2330/4518] 51% | Training loss: 0.6870072637248961
Epoch: 98 | Iteration number: [2340/4518] 51% | Training loss: 0.687008614698027
Epoch: 98 | Iteration number: [2350/4518] 52% | Training loss: 0.6870040224714482
Epoch: 98 | Iteration number: [2360/4518] 52% | Training loss: 0.6870006434240583
Epoch: 98 | Iteration number: [2370/4518] 52% | Training loss: 0.6870020292227781
Epoch: 98 | Iteration number: [2380/4518] 52% | Training loss: 0.6869959680222664
Epoch: 98 | Iteration number: [2390/4518] 52% | Training loss: 0.6869994734121666
Epoch: 98 | Iteration number: [2400/4518] 53% | Training loss: 0.6870008668551842
Epoch: 98 | Iteration number: [2410/4518] 53% | Training loss: 0.6869979263835923
Epoch: 98 | Iteration number: [2420/4518] 53% | Training loss: 0.686994585025409
Epoch: 98 | Iteration number: [2430/4518] 53% | Training loss: 0.6869907419377393
Epoch: 98 | Iteration number: [2440/4518] 54% | Training loss: 0.6869948374687648
Epoch: 98 | Iteration number: [2450/4518] 54% | Training loss: 0.6869948695630443
Epoch: 98 | Iteration number: [2460/4518] 54% | Training loss: 0.6869976694748654
Epoch: 98 | Iteration number: [2470/4518] 54% | Training loss: 0.6869917696545481
Epoch: 98 | Iteration number: [2480/4518] 54% | Training loss: 0.6869944118443997
Epoch: 98 | Iteration number: [2490/4518] 55% | Training loss: 0.6869955092548845
Epoch: 98 | Iteration number: [2500/4518] 55% | Training loss: 0.6869965755939483
Epoch: 98 | Iteration number: [2510/4518] 55% | Training loss: 0.6869995169668084
Epoch: 98 | Iteration number: [2520/4518] 55% | Training loss: 0.6869992453900594
Epoch: 98 | Iteration number: [2530/4518] 55% | Training loss: 0.6869996667143856
Epoch: 98 | Iteration number: [2540/4518] 56% | Training loss: 0.6870008760080563
Epoch: 98 | Iteration number: [2550/4518] 56% | Training loss: 0.6869977749095244
Epoch: 98 | Iteration number: [2560/4518] 56% | Training loss: 0.6870013484032824
Epoch: 98 | Iteration number: [2570/4518] 56% | Training loss: 0.6869993960579082
Epoch: 98 | Iteration number: [2580/4518] 57% | Training loss: 0.6869979648165
Epoch: 98 | Iteration number: [2590/4518] 57% | Training loss: 0.6869958577929316
Epoch: 98 | Iteration number: [2600/4518] 57% | Training loss: 0.6869940702731793
Epoch: 98 | Iteration number: [2610/4518] 57% | Training loss: 0.6869883736203
Epoch: 98 | Iteration number: [2620/4518] 57% | Training loss: 0.6869836576112354
Epoch: 98 | Iteration number: [2630/4518] 58% | Training loss: 0.6869836810650481
Epoch: 98 | Iteration number: [2640/4518] 58% | Training loss: 0.6869805791612827
Epoch: 98 | Iteration number: [2650/4518] 58% | Training loss: 0.6869803508947481
Epoch: 98 | Iteration number: [2660/4518] 58% | Training loss: 0.6869811677843108
Epoch: 98 | Iteration number: [2670/4518] 59% | Training loss: 0.6869820749491788
Epoch: 98 | Iteration number: [2680/4518] 59% | Training loss: 0.6869809871956484
Epoch: 98 | Iteration number: [2690/4518] 59% | Training loss: 0.6869853029020657
Epoch: 98 | Iteration number: [2700/4518] 59% | Training loss: 0.686985681520568
Epoch: 98 | Iteration number: [2710/4518] 59% | Training loss: 0.6869846808954359
Epoch: 98 | Iteration number: [2720/4518] 60% | Training loss: 0.6869826810544029
Epoch: 98 | Iteration number: [2730/4518] 60% | Training loss: 0.6869775123211928
Epoch: 98 | Iteration number: [2740/4518] 60% | Training loss: 0.6869745635855807
Epoch: 98 | Iteration number: [2750/4518] 60% | Training loss: 0.6869728285182606
Epoch: 98 | Iteration number: [2760/4518] 61% | Training loss: 0.6869734223338141
Epoch: 98 | Iteration number: [2770/4518] 61% | Training loss: 0.6869711104498013
Epoch: 98 | Iteration number: [2780/4518] 61% | Training loss: 0.6869712471104354
Epoch: 98 | Iteration number: [2790/4518] 61% | Training loss: 0.6869727245368411
Epoch: 98 | Iteration number: [2800/4518] 61% | Training loss: 0.6869711772671767
Epoch: 98 | Iteration number: [2810/4518] 62% | Training loss: 0.6869741635602564
Epoch: 98 | Iteration number: [2820/4518] 62% | Training loss: 0.6869766334481273
Epoch: 98 | Iteration number: [2830/4518] 62% | Training loss: 0.6869780188314485
Epoch: 98 | Iteration number: [2840/4518] 62% | Training loss: 0.6869774603298012
Epoch: 98 | Iteration number: [2850/4518] 63% | Training loss: 0.6869790113390538
Epoch: 98 | Iteration number: [2860/4518] 63% | Training loss: 0.6869779107870756
Epoch: 98 | Iteration number: [2870/4518] 63% | Training loss: 0.6869758007833766
Epoch: 98 | Iteration number: [2880/4518] 63% | Training loss: 0.6869754930958152
Epoch: 98 | Iteration number: [2890/4518] 63% | Training loss: 0.6869738187344429
Epoch: 98 | Iteration number: [2900/4518] 64% | Training loss: 0.6869762732037182
Epoch: 98 | Iteration number: [2910/4518] 64% | Training loss: 0.6869730232507503
Epoch: 98 | Iteration number: [2920/4518] 64% | Training loss: 0.6869703079943787
Epoch: 98 | Iteration number: [2930/4518] 64% | Training loss: 0.6869699696021682
Epoch: 98 | Iteration number: [2940/4518] 65% | Training loss: 0.6869683411048383
Epoch: 98 | Iteration number: [2950/4518] 65% | Training loss: 0.6869675686197766
Epoch: 98 | Iteration number: [2960/4518] 65% | Training loss: 0.6869664289459989
Epoch: 98 | Iteration number: [2970/4518] 65% | Training loss: 0.6869638091787345
Epoch: 98 | Iteration number: [2980/4518] 65% | Training loss: 0.6869633490607242
Epoch: 98 | Iteration number: [2990/4518] 66% | Training loss: 0.6869647184741936
Epoch: 98 | Iteration number: [3000/4518] 66% | Training loss: 0.6869601770043373
Epoch: 98 | Iteration number: [3010/4518] 66% | Training loss: 0.6869598806894499
Epoch: 98 | Iteration number: [3020/4518] 66% | Training loss: 0.6869621705732598
Epoch: 98 | Iteration number: [3030/4518] 67% | Training loss: 0.6869632325156687
Epoch: 98 | Iteration number: [3040/4518] 67% | Training loss: 0.6869617282363929
Epoch: 98 | Iteration number: [3050/4518] 67% | Training loss: 0.6869611273632675
Epoch: 98 | Iteration number: [3060/4518] 67% | Training loss: 0.6869545158607507
Epoch: 98 | Iteration number: [3070/4518] 67% | Training loss: 0.6869528974888768
Epoch: 98 | Iteration number: [3080/4518] 68% | Training loss: 0.6869552811631908
Epoch: 98 | Iteration number: [3090/4518] 68% | Training loss: 0.6869534044396916
Epoch: 98 | Iteration number: [3100/4518] 68% | Training loss: 0.6869549916059741
Epoch: 98 | Iteration number: [3110/4518] 68% | Training loss: 0.6869572885933413
Epoch: 98 | Iteration number: [3120/4518] 69% | Training loss: 0.6869584002555945
Epoch: 98 | Iteration number: [3130/4518] 69% | Training loss: 0.6869605655106493
Epoch: 98 | Iteration number: [3140/4518] 69% | Training loss: 0.6869542794242786
Epoch: 98 | Iteration number: [3150/4518] 69% | Training loss: 0.6869460161148556
Epoch: 98 | Iteration number: [3160/4518] 69% | Training loss: 0.6869457938059976
Epoch: 98 | Iteration number: [3170/4518] 70% | Training loss: 0.6869432903614706
Epoch: 98 | Iteration number: [3180/4518] 70% | Training loss: 0.6869445733116858
Epoch: 98 | Iteration number: [3190/4518] 70% | Training loss: 0.6869444075796671
Epoch: 98 | Iteration number: [3200/4518] 70% | Training loss: 0.686945257820189
Epoch: 98 | Iteration number: [3210/4518] 71% | Training loss: 0.6869450495621868
Epoch: 98 | Iteration number: [3220/4518] 71% | Training loss: 0.6869454957683634
Epoch: 98 | Iteration number: [3230/4518] 71% | Training loss: 0.6869435710434574
Epoch: 98 | Iteration number: [3240/4518] 71% | Training loss: 0.6869436494730137
Epoch: 98 | Iteration number: [3250/4518] 71% | Training loss: 0.6869432471715486
Epoch: 98 | Iteration number: [3260/4518] 72% | Training loss: 0.6869428564434402
Epoch: 98 | Iteration number: [3270/4518] 72% | Training loss: 0.6869457569144187
Epoch: 98 | Iteration number: [3280/4518] 72% | Training loss: 0.6869443978296548
Epoch: 98 | Iteration number: [3290/4518] 72% | Training loss: 0.6869501367890726
Epoch: 98 | Iteration number: [3300/4518] 73% | Training loss: 0.6869487309275252
Epoch: 98 | Iteration number: [3310/4518] 73% | Training loss: 0.6869524306941248
Epoch: 98 | Iteration number: [3320/4518] 73% | Training loss: 0.6869547105697265
Epoch: 98 | Iteration number: [3330/4518] 73% | Training loss: 0.6869556973109374
Epoch: 98 | Iteration number: [3340/4518] 73% | Training loss: 0.6869593896016389
Epoch: 98 | Iteration number: [3350/4518] 74% | Training loss: 0.6869598332981565
Epoch: 98 | Iteration number: [3360/4518] 74% | Training loss: 0.6869579048029014
Epoch: 98 | Iteration number: [3370/4518] 74% | Training loss: 0.6869573212342022
Epoch: 98 | Iteration number: [3380/4518] 74% | Training loss: 0.6869594987327531
Epoch: 98 | Iteration number: [3390/4518] 75% | Training loss: 0.6869533584181187
Epoch: 98 | Iteration number: [3400/4518] 75% | Training loss: 0.6869513254656511
Epoch: 98 | Iteration number: [3410/4518] 75% | Training loss: 0.6869486492749882
Epoch: 98 | Iteration number: [3420/4518] 75% | Training loss: 0.6869485068565223
Epoch: 98 | Iteration number: [3430/4518] 75% | Training loss: 0.6869525069571792
Epoch: 98 | Iteration number: [3440/4518] 76% | Training loss: 0.6869497299714143
Epoch: 98 | Iteration number: [3450/4518] 76% | Training loss: 0.6869525204361349
Epoch: 98 | Iteration number: [3460/4518] 76% | Training loss: 0.6869515171457578
Epoch: 98 | Iteration number: [3470/4518] 76% | Training loss: 0.6869533759029179
Epoch: 98 | Iteration number: [3480/4518] 77% | Training loss: 0.6869510181333827
Epoch: 98 | Iteration number: [3490/4518] 77% | Training loss: 0.6869466306657709
Epoch: 98 | Iteration number: [3500/4518] 77% | Training loss: 0.6869484043121338
Epoch: 98 | Iteration number: [3510/4518] 77% | Training loss: 0.686946002387593
Epoch: 98 | Iteration number: [3520/4518] 77% | Training loss: 0.6869436958804727
Epoch: 98 | Iteration number: [3530/4518] 78% | Training loss: 0.6869431296928071
Epoch: 98 | Iteration number: [3540/4518] 78% | Training loss: 0.6869436993437298
Epoch: 98 | Iteration number: [3550/4518] 78% | Training loss: 0.6869426176581584
Epoch: 98 | Iteration number: [3560/4518] 78% | Training loss: 0.6869421017471324
Epoch: 98 | Iteration number: [3570/4518] 79% | Training loss: 0.6869426385862153
Epoch: 98 | Iteration number: [3580/4518] 79% | Training loss: 0.6869439824999378
Epoch: 98 | Iteration number: [3590/4518] 79% | Training loss: 0.6869451885435907
Epoch: 98 | Iteration number: [3600/4518] 79% | Training loss: 0.6869429237147172
Epoch: 98 | Iteration number: [3610/4518] 79% | Training loss: 0.6869411090569483
Epoch: 98 | Iteration number: [3620/4518] 80% | Training loss: 0.6869393645564495
Epoch: 98 | Iteration number: [3630/4518] 80% | Training loss: 0.6869421794559016
Epoch: 98 | Iteration number: [3640/4518] 80% | Training loss: 0.686945606981005
Epoch: 98 | Iteration number: [3650/4518] 80% | Training loss: 0.6869427107294945
Epoch: 98 | Iteration number: [3660/4518] 81% | Training loss: 0.6869394527269843
Epoch: 98 | Iteration number: [3670/4518] 81% | Training loss: 0.6869403559278078
Epoch: 98 | Iteration number: [3680/4518] 81% | Training loss: 0.6869397404563168
Epoch: 98 | Iteration number: [3690/4518] 81% | Training loss: 0.6869369821012181
Epoch: 98 | Iteration number: [3700/4518] 81% | Training loss: 0.6869339019221229
Epoch: 98 | Iteration number: [3710/4518] 82% | Training loss: 0.6869334787050027
Epoch: 98 | Iteration number: [3720/4518] 82% | Training loss: 0.6869367771571683
Epoch: 98 | Iteration number: [3730/4518] 82% | Training loss: 0.6869358414619282
Epoch: 98 | Iteration number: [3740/4518] 82% | Training loss: 0.6869316469698666
Epoch: 98 | Iteration number: [3750/4518] 83% | Training loss: 0.6869270117123921
Epoch: 98 | Iteration number: [3760/4518] 83% | Training loss: 0.68692914193615
Epoch: 98 | Iteration number: [3770/4518] 83% | Training loss: 0.6869266402500062
Epoch: 98 | Iteration number: [3780/4518] 83% | Training loss: 0.6869282267554097
Epoch: 98 | Iteration number: [3790/4518] 83% | Training loss: 0.6869276148348181
Epoch: 98 | Iteration number: [3800/4518] 84% | Training loss: 0.6869252897720588
Epoch: 98 | Iteration number: [3810/4518] 84% | Training loss: 0.6869263994881487
Epoch: 98 | Iteration number: [3820/4518] 84% | Training loss: 0.6869264863236413
Epoch: 98 | Iteration number: [3830/4518] 84% | Training loss: 0.6869236817092248
Epoch: 98 | Iteration number: [3840/4518] 84% | Training loss: 0.68692383505404
Epoch: 98 | Iteration number: [3850/4518] 85% | Training loss: 0.6869244580145006
Epoch: 98 | Iteration number: [3860/4518] 85% | Training loss: 0.6869247073027754
Epoch: 98 | Iteration number: [3870/4518] 85% | Training loss: 0.6869236584319625
Epoch: 98 | Iteration number: [3880/4518] 85% | Training loss: 0.6869237192666408
Epoch: 98 | Iteration number: [3890/4518] 86% | Training loss: 0.6869229922870744
Epoch: 98 | Iteration number: [3900/4518] 86% | Training loss: 0.686919528505741
Epoch: 98 | Iteration number: [3910/4518] 86% | Training loss: 0.686917586293062
Epoch: 98 | Iteration number: [3920/4518] 86% | Training loss: 0.6869182153623932
Epoch: 98 | Iteration number: [3930/4518] 86% | Training loss: 0.6869156505467024
Epoch: 98 | Iteration number: [3940/4518] 87% | Training loss: 0.6869158541339303
Epoch: 98 | Iteration number: [3950/4518] 87% | Training loss: 0.6869151350667205
Epoch: 98 | Iteration number: [3960/4518] 87% | Training loss: 0.6869159126522565
Epoch: 98 | Iteration number: [3970/4518] 87% | Training loss: 0.686916130826215
Epoch: 98 | Iteration number: [3980/4518] 88% | Training loss: 0.686916505646466
Epoch: 98 | Iteration number: [3990/4518] 88% | Training loss: 0.6869137601296704
Epoch: 98 | Iteration number: [4000/4518] 88% | Training loss: 0.6869129874408245
Epoch: 98 | Iteration number: [4010/4518] 88% | Training loss: 0.6869121365119097
Epoch: 98 | Iteration number: [4020/4518] 88% | Training loss: 0.6869100193182628
Epoch: 98 | Iteration number: [4030/4518] 89% | Training loss: 0.6869112303919591
Epoch: 98 | Iteration number: [4040/4518] 89% | Training loss: 0.6869097156099754
Epoch: 98 | Iteration number: [4050/4518] 89% | Training loss: 0.6869104059831596
Epoch: 98 | Iteration number: [4060/4518] 89% | Training loss: 0.6869095817428504
Epoch: 98 | Iteration number: [4070/4518] 90% | Training loss: 0.6869051934167266
Epoch: 98 | Iteration number: [4080/4518] 90% | Training loss: 0.6869043650288208
Epoch: 98 | Iteration number: [4090/4518] 90% | Training loss: 0.6869033466195711
Epoch: 98 | Iteration number: [4100/4518] 90% | Training loss: 0.6869056959123147
Epoch: 98 | Iteration number: [4110/4518] 90% | Training loss: 0.6869047595636688
Epoch: 98 | Iteration number: [4120/4518] 91% | Training loss: 0.6869070400890794
Epoch: 98 | Iteration number: [4130/4518] 91% | Training loss: 0.6869034341547737
Epoch: 98 | Iteration number: [4140/4518] 91% | Training loss: 0.6869013405940383
Epoch: 98 | Iteration number: [4150/4518] 91% | Training loss: 0.6869002541145647
Epoch: 98 | Iteration number: [4160/4518] 92% | Training loss: 0.6869003726456028
Epoch: 98 | Iteration number: [4170/4518] 92% | Training loss: 0.6868952843639776
Epoch: 98 | Iteration number: [4180/4518] 92% | Training loss: 0.6868915126084141
Epoch: 98 | Iteration number: [4190/4518] 92% | Training loss: 0.6868920832659009
Epoch: 98 | Iteration number: [4200/4518] 92% | Training loss: 0.6868888638416926
Epoch: 98 | Iteration number: [4210/4518] 93% | Training loss: 0.6868907063137607
Epoch: 98 | Iteration number: [4220/4518] 93% | Training loss: 0.6868914079044668
Epoch: 98 | Iteration number: [4230/4518] 93% | Training loss: 0.6868924843363164
Epoch: 98 | Iteration number: [4240/4518] 93% | Training loss: 0.6868960022082868
Epoch: 98 | Iteration number: [4250/4518] 94% | Training loss: 0.6868964254435371
Epoch: 98 | Iteration number: [4260/4518] 94% | Training loss: 0.6868953479567604
Epoch: 98 | Iteration number: [4270/4518] 94% | Training loss: 0.686894229159143
Epoch: 98 | Iteration number: [4280/4518] 94% | Training loss: 0.6868932087148462
Epoch: 98 | Iteration number: [4290/4518] 94% | Training loss: 0.6868899681351401
Epoch: 98 | Iteration number: [4300/4518] 95% | Training loss: 0.686890328859174
Epoch: 98 | Iteration number: [4310/4518] 95% | Training loss: 0.686888418037211
Epoch: 98 | Iteration number: [4320/4518] 95% | Training loss: 0.6868892619179354
Epoch: 98 | Iteration number: [4330/4518] 95% | Training loss: 0.6868894900102813
Epoch: 98 | Iteration number: [4340/4518] 96% | Training loss: 0.686888389296246
Epoch: 98 | Iteration number: [4350/4518] 96% | Training loss: 0.6868905351079744
Epoch: 98 | Iteration number: [4360/4518] 96% | Training loss: 0.6868901590004973
Epoch: 98 | Iteration number: [4370/4518] 96% | Training loss: 0.6868890262986758
Epoch: 98 | Iteration number: [4380/4518] 96% | Training loss: 0.6868921558470487
Epoch: 98 | Iteration number: [4390/4518] 97% | Training loss: 0.6868921093218419
Epoch: 98 | Iteration number: [4400/4518] 97% | Training loss: 0.6868904287706722
Epoch: 98 | Iteration number: [4410/4518] 97% | Training loss: 0.6868909618616644
Epoch: 98 | Iteration number: [4420/4518] 97% | Training loss: 0.6868911649441827
Epoch: 98 | Iteration number: [4430/4518] 98% | Training loss: 0.6868926399986577
Epoch: 98 | Iteration number: [4440/4518] 98% | Training loss: 0.6868931625206192
Epoch: 98 | Iteration number: [4450/4518] 98% | Training loss: 0.6868924508068
Epoch: 98 | Iteration number: [4460/4518] 98% | Training loss: 0.6868918086915807
Epoch: 98 | Iteration number: [4470/4518] 98% | Training loss: 0.6868912786712049
Epoch: 98 | Iteration number: [4480/4518] 99% | Training loss: 0.6868909979505199
Epoch: 98 | Iteration number: [4490/4518] 99% | Training loss: 0.6868936320057425
Epoch: 98 | Iteration number: [4500/4518] 99% | Training loss: 0.6868946430550681
Epoch: 98 | Iteration number: [4510/4518] 99% | Training loss: 0.6868958537039366

 End of epoch: 98 | Train Loss: 0.6867449359589839 | Training Time: 632 

 End of epoch: 98 | Eval Loss: 0.6895334720611572 | Evaluating Time: 17 
Epoch: 99 | Iteration number: [10/4518] 0% | Training loss: 0.7568387448787689
Epoch: 99 | Iteration number: [20/4518] 0% | Training loss: 0.7219608783721924
Epoch: 99 | Iteration number: [30/4518] 0% | Training loss: 0.7103731175263722
Epoch: 99 | Iteration number: [40/4518] 0% | Training loss: 0.7044219523668289
Epoch: 99 | Iteration number: [50/4518] 1% | Training loss: 0.701062124967575
Epoch: 99 | Iteration number: [60/4518] 1% | Training loss: 0.6986024290323257
Epoch: 99 | Iteration number: [70/4518] 1% | Training loss: 0.696803719656808
Epoch: 99 | Iteration number: [80/4518] 1% | Training loss: 0.6955320298671722
Epoch: 99 | Iteration number: [90/4518] 1% | Training loss: 0.6945634265740712
Epoch: 99 | Iteration number: [100/4518] 2% | Training loss: 0.6939049279689788
Epoch: 99 | Iteration number: [110/4518] 2% | Training loss: 0.6933082699775696
Epoch: 99 | Iteration number: [120/4518] 2% | Training loss: 0.6927912880976995
Epoch: 99 | Iteration number: [130/4518] 2% | Training loss: 0.6923380416173202
Epoch: 99 | Iteration number: [140/4518] 3% | Training loss: 0.6919893967253822
Epoch: 99 | Iteration number: [150/4518] 3% | Training loss: 0.6917087578773499
Epoch: 99 | Iteration number: [160/4518] 3% | Training loss: 0.6914233509451151
Epoch: 99 | Iteration number: [170/4518] 3% | Training loss: 0.6910872820545645
Epoch: 99 | Iteration number: [180/4518] 3% | Training loss: 0.6908343242274391
Epoch: 99 | Iteration number: [190/4518] 4% | Training loss: 0.6906130812670055
Epoch: 99 | Iteration number: [200/4518] 4% | Training loss: 0.6904485160112381
Epoch: 99 | Iteration number: [210/4518] 4% | Training loss: 0.6903140666938964
Epoch: 99 | Iteration number: [220/4518] 4% | Training loss: 0.690172738107768
Epoch: 99 | Iteration number: [230/4518] 5% | Training loss: 0.6900531488916148
Epoch: 99 | Iteration number: [240/4518] 5% | Training loss: 0.6898954262336096
Epoch: 99 | Iteration number: [250/4518] 5% | Training loss: 0.6897938141822815
Epoch: 99 | Iteration number: [260/4518] 5% | Training loss: 0.6896721805517491
Epoch: 99 | Iteration number: [270/4518] 5% | Training loss: 0.689585558352647
Epoch: 99 | Iteration number: [280/4518] 6% | Training loss: 0.6894848800131252
Epoch: 99 | Iteration number: [290/4518] 6% | Training loss: 0.6894049480043608
Epoch: 99 | Iteration number: [300/4518] 6% | Training loss: 0.6893054658174514
Epoch: 99 | Iteration number: [310/4518] 6% | Training loss: 0.6892431541796653
Epoch: 99 | Iteration number: [320/4518] 7% | Training loss: 0.6891389559954405
Epoch: 99 | Iteration number: [330/4518] 7% | Training loss: 0.689071470860279
Epoch: 99 | Iteration number: [340/4518] 7% | Training loss: 0.6890062391757965
Epoch: 99 | Iteration number: [350/4518] 7% | Training loss: 0.6889350189481462
Epoch: 99 | Iteration number: [360/4518] 7% | Training loss: 0.6888582635256979
Epoch: 99 | Iteration number: [370/4518] 8% | Training loss: 0.6888340376518868
Epoch: 99 | Iteration number: [380/4518] 8% | Training loss: 0.68876346161491
Epoch: 99 | Iteration number: [390/4518] 8% | Training loss: 0.6886824684265332
Epoch: 99 | Iteration number: [400/4518] 8% | Training loss: 0.6886690093576908
Epoch: 99 | Iteration number: [410/4518] 9% | Training loss: 0.6886169608046369
Epoch: 99 | Iteration number: [420/4518] 9% | Training loss: 0.6885620655048461
Epoch: 99 | Iteration number: [430/4518] 9% | Training loss: 0.6885132043860679
Epoch: 99 | Iteration number: [440/4518] 9% | Training loss: 0.6884922116994858
Epoch: 99 | Iteration number: [450/4518] 9% | Training loss: 0.688439412381914
Epoch: 99 | Iteration number: [460/4518] 10% | Training loss: 0.6883839776982432
Epoch: 99 | Iteration number: [470/4518] 10% | Training loss: 0.6883703201375109
Epoch: 99 | Iteration number: [480/4518] 10% | Training loss: 0.6883180846770605
Epoch: 99 | Iteration number: [490/4518] 10% | Training loss: 0.6883055706413425
Epoch: 99 | Iteration number: [500/4518] 11% | Training loss: 0.6882689442634583
Epoch: 99 | Iteration number: [510/4518] 11% | Training loss: 0.6882274334337197
Epoch: 99 | Iteration number: [520/4518] 11% | Training loss: 0.6881960507768851
Epoch: 99 | Iteration number: [530/4518] 11% | Training loss: 0.6881534189548133
Epoch: 99 | Iteration number: [540/4518] 11% | Training loss: 0.6880872856687617
Epoch: 99 | Iteration number: [550/4518] 12% | Training loss: 0.6880678738247265
Epoch: 99 | Iteration number: [560/4518] 12% | Training loss: 0.6880542592278549
Epoch: 99 | Iteration number: [570/4518] 12% | Training loss: 0.6880284060511672
Epoch: 99 | Iteration number: [580/4518] 12% | Training loss: 0.6879833615031735
Epoch: 99 | Iteration number: [590/4518] 13% | Training loss: 0.6879537132837005
Epoch: 99 | Iteration number: [600/4518] 13% | Training loss: 0.6879312108953793
Epoch: 99 | Iteration number: [610/4518] 13% | Training loss: 0.6879318869504772
Epoch: 99 | Iteration number: [620/4518] 13% | Training loss: 0.6879251325322736
Epoch: 99 | Iteration number: [630/4518] 13% | Training loss: 0.6879159842218672
Epoch: 99 | Iteration number: [640/4518] 14% | Training loss: 0.6878934724256396
Epoch: 99 | Iteration number: [650/4518] 14% | Training loss: 0.6878929658119495
Epoch: 99 | Iteration number: [660/4518] 14% | Training loss: 0.687871517015226
Epoch: 99 | Iteration number: [670/4518] 14% | Training loss: 0.6878713462779771
Epoch: 99 | Iteration number: [680/4518] 15% | Training loss: 0.6878681751735071
Epoch: 99 | Iteration number: [690/4518] 15% | Training loss: 0.6878533318422843
Epoch: 99 | Iteration number: [700/4518] 15% | Training loss: 0.6878090915509633
Epoch: 99 | Iteration number: [710/4518] 15% | Training loss: 0.6878161624283857
Epoch: 99 | Iteration number: [720/4518] 15% | Training loss: 0.6878179782794581
Epoch: 99 | Iteration number: [730/4518] 16% | Training loss: 0.6877970909419125
Epoch: 99 | Iteration number: [740/4518] 16% | Training loss: 0.687783218638317
Epoch: 99 | Iteration number: [750/4518] 16% | Training loss: 0.687786128838857
Epoch: 99 | Iteration number: [760/4518] 16% | Training loss: 0.687775810925584
Epoch: 99 | Iteration number: [770/4518] 17% | Training loss: 0.6877658022688581
Epoch: 99 | Iteration number: [780/4518] 17% | Training loss: 0.6877293161856822
Epoch: 99 | Iteration number: [790/4518] 17% | Training loss: 0.6877155467679229
Epoch: 99 | Iteration number: [800/4518] 17% | Training loss: 0.6876879134774208
Epoch: 99 | Iteration number: [810/4518] 17% | Training loss: 0.6876717207608399
Epoch: 99 | Iteration number: [820/4518] 18% | Training loss: 0.6876542132802126
Epoch: 99 | Iteration number: [830/4518] 18% | Training loss: 0.6876399298748338
Epoch: 99 | Iteration number: [840/4518] 18% | Training loss: 0.6876443755768594
Epoch: 99 | Iteration number: [850/4518] 18% | Training loss: 0.6876531277684604
Epoch: 99 | Iteration number: [860/4518] 19% | Training loss: 0.687640477405038
Epoch: 99 | Iteration number: [870/4518] 19% | Training loss: 0.6876200701313457
Epoch: 99 | Iteration number: [880/4518] 19% | Training loss: 0.6876156731085343
Epoch: 99 | Iteration number: [890/4518] 19% | Training loss: 0.6876055052441158
Epoch: 99 | Iteration number: [900/4518] 19% | Training loss: 0.6876008529133267
Epoch: 99 | Iteration number: [910/4518] 20% | Training loss: 0.6876033306776822
Epoch: 99 | Iteration number: [920/4518] 20% | Training loss: 0.687590883737025
Epoch: 99 | Iteration number: [930/4518] 20% | Training loss: 0.6875905059358125
Epoch: 99 | Iteration number: [940/4518] 20% | Training loss: 0.6875954313481107
Epoch: 99 | Iteration number: [950/4518] 21% | Training loss: 0.6875800015424427
Epoch: 99 | Iteration number: [960/4518] 21% | Training loss: 0.6875746466219426
Epoch: 99 | Iteration number: [970/4518] 21% | Training loss: 0.6875757449066516
Epoch: 99 | Iteration number: [980/4518] 21% | Training loss: 0.6875640868532414
Epoch: 99 | Iteration number: [990/4518] 21% | Training loss: 0.6875536083573043
Epoch: 99 | Iteration number: [1000/4518] 22% | Training loss: 0.6875451192855835
Epoch: 99 | Iteration number: [1010/4518] 22% | Training loss: 0.6875261129129051
Epoch: 99 | Iteration number: [1020/4518] 22% | Training loss: 0.6875149369239807
Epoch: 99 | Iteration number: [1030/4518] 22% | Training loss: 0.6875140520554145
Epoch: 99 | Iteration number: [1040/4518] 23% | Training loss: 0.687505945792565
Epoch: 99 | Iteration number: [1050/4518] 23% | Training loss: 0.6875026026793889
Epoch: 99 | Iteration number: [1060/4518] 23% | Training loss: 0.6874870516219229
Epoch: 99 | Iteration number: [1070/4518] 23% | Training loss: 0.6874676903274571
Epoch: 99 | Iteration number: [1080/4518] 23% | Training loss: 0.6874567447989075
Epoch: 99 | Iteration number: [1090/4518] 24% | Training loss: 0.6874444055994716
Epoch: 99 | Iteration number: [1100/4518] 24% | Training loss: 0.6874184913526882
Epoch: 99 | Iteration number: [1110/4518] 24% | Training loss: 0.6874084163356472
Epoch: 99 | Iteration number: [1120/4518] 24% | Training loss: 0.6874106816947461
Epoch: 99 | Iteration number: [1130/4518] 25% | Training loss: 0.6874163801691173
Epoch: 99 | Iteration number: [1140/4518] 25% | Training loss: 0.6874207140583741
Epoch: 99 | Iteration number: [1150/4518] 25% | Training loss: 0.6874115233835967
Epoch: 99 | Iteration number: [1160/4518] 25% | Training loss: 0.6873939744357405
Epoch: 99 | Iteration number: [1170/4518] 25% | Training loss: 0.6873917883277958
Epoch: 99 | Iteration number: [1180/4518] 26% | Training loss: 0.6873774679535526
Epoch: 99 | Iteration number: [1190/4518] 26% | Training loss: 0.6873742882944957
Epoch: 99 | Iteration number: [1200/4518] 26% | Training loss: 0.6873652610182762
Epoch: 99 | Iteration number: [1210/4518] 26% | Training loss: 0.6873637613186167
Epoch: 99 | Iteration number: [1220/4518] 27% | Training loss: 0.687359820281873
Epoch: 99 | Iteration number: [1230/4518] 27% | Training loss: 0.6873621534041273
Epoch: 99 | Iteration number: [1240/4518] 27% | Training loss: 0.68736408487443
Epoch: 99 | Iteration number: [1250/4518] 27% | Training loss: 0.6873544474124909
Epoch: 99 | Iteration number: [1260/4518] 27% | Training loss: 0.6873482876353794
Epoch: 99 | Iteration number: [1270/4518] 28% | Training loss: 0.6873453779952733
Epoch: 99 | Iteration number: [1280/4518] 28% | Training loss: 0.6873353554867208
Epoch: 99 | Iteration number: [1290/4518] 28% | Training loss: 0.6873180419899697
Epoch: 99 | Iteration number: [1300/4518] 28% | Training loss: 0.6873108073381278
Epoch: 99 | Iteration number: [1310/4518] 28% | Training loss: 0.6873132271166066
Epoch: 99 | Iteration number: [1320/4518] 29% | Training loss: 0.6873172555909012
Epoch: 99 | Iteration number: [1330/4518] 29% | Training loss: 0.6873078942298889
Epoch: 99 | Iteration number: [1340/4518] 29% | Training loss: 0.6873072049066202
Epoch: 99 | Iteration number: [1350/4518] 29% | Training loss: 0.6873139883412255
Epoch: 99 | Iteration number: [1360/4518] 30% | Training loss: 0.6873038289301535
Epoch: 99 | Iteration number: [1370/4518] 30% | Training loss: 0.6873129525758924
Epoch: 99 | Iteration number: [1380/4518] 30% | Training loss: 0.6873126136651938
Epoch: 99 | Iteration number: [1390/4518] 30% | Training loss: 0.6872993025848334
Epoch: 99 | Iteration number: [1400/4518] 30% | Training loss: 0.6873018268176487
Epoch: 99 | Iteration number: [1410/4518] 31% | Training loss: 0.6872914050487762
Epoch: 99 | Iteration number: [1420/4518] 31% | Training loss: 0.6872804485156503
Epoch: 99 | Iteration number: [1430/4518] 31% | Training loss: 0.6872645754080552
Epoch: 99 | Iteration number: [1440/4518] 31% | Training loss: 0.687259626802471
Epoch: 99 | Iteration number: [1450/4518] 32% | Training loss: 0.6872407255501582
Epoch: 99 | Iteration number: [1460/4518] 32% | Training loss: 0.6872384717203166
Epoch: 99 | Iteration number: [1470/4518] 32% | Training loss: 0.6872404814577427
Epoch: 99 | Iteration number: [1480/4518] 32% | Training loss: 0.687232472566334
Epoch: 99 | Iteration number: [1490/4518] 32% | Training loss: 0.6872277862673638
Epoch: 99 | Iteration number: [1500/4518] 33% | Training loss: 0.6872202568451563
Epoch: 99 | Iteration number: [1510/4518] 33% | Training loss: 0.6872228013363895
Epoch: 99 | Iteration number: [1520/4518] 33% | Training loss: 0.6872282096822011
Epoch: 99 | Iteration number: [1530/4518] 33% | Training loss: 0.6872207004649966
Epoch: 99 | Iteration number: [1540/4518] 34% | Training loss: 0.6872206716181396
Epoch: 99 | Iteration number: [1550/4518] 34% | Training loss: 0.6872167356937162
Epoch: 99 | Iteration number: [1560/4518] 34% | Training loss: 0.6872146703875982
Epoch: 99 | Iteration number: [1570/4518] 34% | Training loss: 0.6872079105513871
Epoch: 99 | Iteration number: [1580/4518] 34% | Training loss: 0.687203956593441
Epoch: 99 | Iteration number: [1590/4518] 35% | Training loss: 0.6872035767297325
Epoch: 99 | Iteration number: [1600/4518] 35% | Training loss: 0.6871969361230731
Epoch: 99 | Iteration number: [1610/4518] 35% | Training loss: 0.6871944677015269
Epoch: 99 | Iteration number: [1620/4518] 35% | Training loss: 0.6871942407922981
Epoch: 99 | Iteration number: [1630/4518] 36% | Training loss: 0.6871950413186126
Epoch: 99 | Iteration number: [1640/4518] 36% | Training loss: 0.6871819742932552
Epoch: 99 | Iteration number: [1650/4518] 36% | Training loss: 0.6871748249819785
Epoch: 99 | Iteration number: [1660/4518] 36% | Training loss: 0.68716805078179
Epoch: 99 | Iteration number: [1670/4518] 36% | Training loss: 0.6871691958633012
Epoch: 99 | Iteration number: [1680/4518] 37% | Training loss: 0.6871639872235912
Epoch: 99 | Iteration number: [1690/4518] 37% | Training loss: 0.6871556078541208
Epoch: 99 | Iteration number: [1700/4518] 37% | Training loss: 0.6871579561514013
Epoch: 99 | Iteration number: [1710/4518] 37% | Training loss: 0.6871537988297424
Epoch: 99 | Iteration number: [1720/4518] 38% | Training loss: 0.6871491709767386
Epoch: 99 | Iteration number: [1730/4518] 38% | Training loss: 0.6871484264473006
Epoch: 99 | Iteration number: [1740/4518] 38% | Training loss: 0.687141527903491
Epoch: 99 | Iteration number: [1750/4518] 38% | Training loss: 0.6871373142174312
Epoch: 99 | Iteration number: [1760/4518] 38% | Training loss: 0.6871417749334465
Epoch: 99 | Iteration number: [1770/4518] 39% | Training loss: 0.6871414141803138
Epoch: 99 | Iteration number: [1780/4518] 39% | Training loss: 0.6871359131309424
Epoch: 99 | Iteration number: [1790/4518] 39% | Training loss: 0.6871390504544008
Epoch: 99 | Iteration number: [1800/4518] 39% | Training loss: 0.6871262689100371
Epoch: 99 | Iteration number: [1810/4518] 40% | Training loss: 0.687123347777688
Epoch: 99 | Iteration number: [1820/4518] 40% | Training loss: 0.6871254438554848
Epoch: 99 | Iteration number: [1830/4518] 40% | Training loss: 0.6871240715185801
Epoch: 99 | Iteration number: [1840/4518] 40% | Training loss: 0.6871220526487931
Epoch: 99 | Iteration number: [1850/4518] 40% | Training loss: 0.6871156966364061
Epoch: 99 | Iteration number: [1860/4518] 41% | Training loss: 0.687110064683422
Epoch: 99 | Iteration number: [1870/4518] 41% | Training loss: 0.6871074813253739
Epoch: 99 | Iteration number: [1880/4518] 41% | Training loss: 0.6870977056153277
Epoch: 99 | Iteration number: [1890/4518] 41% | Training loss: 0.687098468422259
Epoch: 99 | Iteration number: [1900/4518] 42% | Training loss: 0.687093096469578
Epoch: 99 | Iteration number: [1910/4518] 42% | Training loss: 0.6870998738635897
Epoch: 99 | Iteration number: [1920/4518] 42% | Training loss: 0.6870955836027861
Epoch: 99 | Iteration number: [1930/4518] 42% | Training loss: 0.6870934722028248
Epoch: 99 | Iteration number: [1940/4518] 42% | Training loss: 0.6870964727450892
Epoch: 99 | Iteration number: [1950/4518] 43% | Training loss: 0.6870992250014574
Epoch: 99 | Iteration number: [1960/4518] 43% | Training loss: 0.6871019950326608
Epoch: 99 | Iteration number: [1970/4518] 43% | Training loss: 0.6870988732667139
Epoch: 99 | Iteration number: [1980/4518] 43% | Training loss: 0.6870920906163225
Epoch: 99 | Iteration number: [1990/4518] 44% | Training loss: 0.68708980017571
Epoch: 99 | Iteration number: [2000/4518] 44% | Training loss: 0.6870918806791305
Epoch: 99 | Iteration number: [2010/4518] 44% | Training loss: 0.6870887087945321
Epoch: 99 | Iteration number: [2020/4518] 44% | Training loss: 0.6870913860526415
Epoch: 99 | Iteration number: [2030/4518] 44% | Training loss: 0.6870863973507153
Epoch: 99 | Iteration number: [2040/4518] 45% | Training loss: 0.6870835401263892
Epoch: 99 | Iteration number: [2050/4518] 45% | Training loss: 0.6870850450818131
Epoch: 99 | Iteration number: [2060/4518] 45% | Training loss: 0.6870799798699259
Epoch: 99 | Iteration number: [2070/4518] 45% | Training loss: 0.6870781924413598
Epoch: 99 | Iteration number: [2080/4518] 46% | Training loss: 0.6870758511985724
Epoch: 99 | Iteration number: [2090/4518] 46% | Training loss: 0.687078341998552
Epoch: 99 | Iteration number: [2100/4518] 46% | Training loss: 0.6870770737386885
Epoch: 99 | Iteration number: [2110/4518] 46% | Training loss: 0.6870778927305863
Epoch: 99 | Iteration number: [2120/4518] 46% | Training loss: 0.6870812907814979
Epoch: 99 | Iteration number: [2130/4518] 47% | Training loss: 0.6870766481883089
Epoch: 99 | Iteration number: [2140/4518] 47% | Training loss: 0.6870703181930792
Epoch: 99 | Iteration number: [2150/4518] 47% | Training loss: 0.6870720896332763
Epoch: 99 | Iteration number: [2160/4518] 47% | Training loss: 0.6870715916984611
Epoch: 99 | Iteration number: [2170/4518] 48% | Training loss: 0.6870722341647346
Epoch: 99 | Iteration number: [2180/4518] 48% | Training loss: 0.6870739961709451
Epoch: 99 | Iteration number: [2190/4518] 48% | Training loss: 0.6870786056398801
Epoch: 99 | Iteration number: [2200/4518] 48% | Training loss: 0.6870730539614504
Epoch: 99 | Iteration number: [2210/4518] 48% | Training loss: 0.6870741389725543
Epoch: 99 | Iteration number: [2220/4518] 49% | Training loss: 0.6870742069708334
Epoch: 99 | Iteration number: [2230/4518] 49% | Training loss: 0.6870772452899694
Epoch: 99 | Iteration number: [2240/4518] 49% | Training loss: 0.6870732236653566
Epoch: 99 | Iteration number: [2250/4518] 49% | Training loss: 0.6870719941722022
Epoch: 99 | Iteration number: [2260/4518] 50% | Training loss: 0.6870673975585836
Epoch: 99 | Iteration number: [2270/4518] 50% | Training loss: 0.6870648033030757
Epoch: 99 | Iteration number: [2280/4518] 50% | Training loss: 0.6870650637568089
Epoch: 99 | Iteration number: [2290/4518] 50% | Training loss: 0.6870645580593675
Epoch: 99 | Iteration number: [2300/4518] 50% | Training loss: 0.6870602520393289
Epoch: 99 | Iteration number: [2310/4518] 51% | Training loss: 0.6870586938156193
Epoch: 99 | Iteration number: [2320/4518] 51% | Training loss: 0.6870554694327815
Epoch: 99 | Iteration number: [2330/4518] 51% | Training loss: 0.6870526201223611
Epoch: 99 | Iteration number: [2340/4518] 51% | Training loss: 0.6870521531909959
Epoch: 99 | Iteration number: [2350/4518] 52% | Training loss: 0.6870481198645653
Epoch: 99 | Iteration number: [2360/4518] 52% | Training loss: 0.6870453804478807
Epoch: 99 | Iteration number: [2370/4518] 52% | Training loss: 0.6870356212185404
Epoch: 99 | Iteration number: [2380/4518] 52% | Training loss: 0.6870353387183502
Epoch: 99 | Iteration number: [2390/4518] 52% | Training loss: 0.687028826031226
Epoch: 99 | Iteration number: [2400/4518] 53% | Training loss: 0.6870268552501997
Epoch: 99 | Iteration number: [2410/4518] 53% | Training loss: 0.6870281365155184
Epoch: 99 | Iteration number: [2420/4518] 53% | Training loss: 0.6870283569186187
Epoch: 99 | Iteration number: [2430/4518] 53% | Training loss: 0.6870319716479062
Epoch: 99 | Iteration number: [2440/4518] 54% | Training loss: 0.6870287890072728
Epoch: 99 | Iteration number: [2450/4518] 54% | Training loss: 0.6870237361898227
Epoch: 99 | Iteration number: [2460/4518] 54% | Training loss: 0.6870172460147036
Epoch: 99 | Iteration number: [2470/4518] 54% | Training loss: 0.687018383997172
Epoch: 99 | Iteration number: [2480/4518] 54% | Training loss: 0.6870198945845327
Epoch: 99 | Iteration number: [2490/4518] 55% | Training loss: 0.6870171439934926
Epoch: 99 | Iteration number: [2500/4518] 55% | Training loss: 0.6870187849283218
Epoch: 99 | Iteration number: [2510/4518] 55% | Training loss: 0.6870172719319029
Epoch: 99 | Iteration number: [2520/4518] 55% | Training loss: 0.6870126047304699
Epoch: 99 | Iteration number: [2530/4518] 55% | Training loss: 0.6870103815091928
Epoch: 99 | Iteration number: [2540/4518] 56% | Training loss: 0.6870035625818207
Epoch: 99 | Iteration number: [2550/4518] 56% | Training loss: 0.6870025058821135
Epoch: 99 | Iteration number: [2560/4518] 56% | Training loss: 0.6869978926377371
Epoch: 99 | Iteration number: [2570/4518] 56% | Training loss: 0.6869975109972378
Epoch: 99 | Iteration number: [2580/4518] 57% | Training loss: 0.686998289014942
Epoch: 99 | Iteration number: [2590/4518] 57% | Training loss: 0.6869931916242401
Epoch: 99 | Iteration number: [2600/4518] 57% | Training loss: 0.6869914667881453
Epoch: 99 | Iteration number: [2610/4518] 57% | Training loss: 0.6869892370198422
Epoch: 99 | Iteration number: [2620/4518] 57% | Training loss: 0.6869893847758534
Epoch: 99 | Iteration number: [2630/4518] 58% | Training loss: 0.6869845387600221
Epoch: 99 | Iteration number: [2640/4518] 58% | Training loss: 0.686983982089794
Epoch: 99 | Iteration number: [2650/4518] 58% | Training loss: 0.6869808101878976
Epoch: 99 | Iteration number: [2660/4518] 58% | Training loss: 0.686978561761684
Epoch: 99 | Iteration number: [2670/4518] 59% | Training loss: 0.6869798489277729
Epoch: 99 | Iteration number: [2680/4518] 59% | Training loss: 0.6869787357858758
Epoch: 99 | Iteration number: [2690/4518] 59% | Training loss: 0.6869771484770296
Epoch: 99 | Iteration number: [2700/4518] 59% | Training loss: 0.6869808587100771
Epoch: 99 | Iteration number: [2710/4518] 59% | Training loss: 0.6869768267408068
Epoch: 99 | Iteration number: [2720/4518] 60% | Training loss: 0.6869774507906508
Epoch: 99 | Iteration number: [2730/4518] 60% | Training loss: 0.6869771608502874
Epoch: 99 | Iteration number: [2740/4518] 60% | Training loss: 0.6869788403493644
Epoch: 99 | Iteration number: [2750/4518] 60% | Training loss: 0.6869753243706443
Epoch: 99 | Iteration number: [2760/4518] 61% | Training loss: 0.6869756797085638
Epoch: 99 | Iteration number: [2770/4518] 61% | Training loss: 0.686978245642211
Epoch: 99 | Iteration number: [2780/4518] 61% | Training loss: 0.6869754755454097
Epoch: 99 | Iteration number: [2790/4518] 61% | Training loss: 0.6869758577543348
Epoch: 99 | Iteration number: [2800/4518] 61% | Training loss: 0.686974203394992
Epoch: 99 | Iteration number: [2810/4518] 62% | Training loss: 0.6869743345258923
Epoch: 99 | Iteration number: [2820/4518] 62% | Training loss: 0.6869704012752424
Epoch: 99 | Iteration number: [2830/4518] 62% | Training loss: 0.6869646604406539
Epoch: 99 | Iteration number: [2840/4518] 62% | Training loss: 0.6869632705626353
Epoch: 99 | Iteration number: [2850/4518] 63% | Training loss: 0.6869677590278157
Epoch: 99 | Iteration number: [2860/4518] 63% | Training loss: 0.6869670799562148
Epoch: 99 | Iteration number: [2870/4518] 63% | Training loss: 0.6869638083911523
Epoch: 99 | Iteration number: [2880/4518] 63% | Training loss: 0.68695730186171
Epoch: 99 | Iteration number: [2890/4518] 63% | Training loss: 0.6869567116445323
Epoch: 99 | Iteration number: [2900/4518] 64% | Training loss: 0.6869574259272937
Epoch: 99 | Iteration number: [2910/4518] 64% | Training loss: 0.686958750867352
Epoch: 99 | Iteration number: [2920/4518] 64% | Training loss: 0.6869583178872931
Epoch: 99 | Iteration number: [2930/4518] 64% | Training loss: 0.6869621198738801
Epoch: 99 | Iteration number: [2940/4518] 65% | Training loss: 0.6869631306249269
Epoch: 99 | Iteration number: [2950/4518] 65% | Training loss: 0.6869636699708842
Epoch: 99 | Iteration number: [2960/4518] 65% | Training loss: 0.6869625574229536
Epoch: 99 | Iteration number: [2970/4518] 65% | Training loss: 0.6869599333315185
Epoch: 99 | Iteration number: [2980/4518] 65% | Training loss: 0.6869589759399427
Epoch: 99 | Iteration number: [2990/4518] 66% | Training loss: 0.6869614323046693
Epoch: 99 | Iteration number: [3000/4518] 66% | Training loss: 0.6869584544102351
Epoch: 99 | Iteration number: [3010/4518] 66% | Training loss: 0.6869537719658443
Epoch: 99 | Iteration number: [3020/4518] 66% | Training loss: 0.6869529221034207
Epoch: 99 | Iteration number: [3030/4518] 67% | Training loss: 0.6869531723532346
Epoch: 99 | Iteration number: [3040/4518] 67% | Training loss: 0.6869512503868656
Epoch: 99 | Iteration number: [3050/4518] 67% | Training loss: 0.6869531733286185
Epoch: 99 | Iteration number: [3060/4518] 67% | Training loss: 0.6869558683992212
Epoch: 99 | Iteration number: [3070/4518] 67% | Training loss: 0.6869524607052632
Epoch: 99 | Iteration number: [3080/4518] 68% | Training loss: 0.6869514662917559
Epoch: 99 | Iteration number: [3090/4518] 68% | Training loss: 0.6869565016822136
Epoch: 99 | Iteration number: [3100/4518] 68% | Training loss: 0.6869503997218225
Epoch: 99 | Iteration number: [3110/4518] 68% | Training loss: 0.6869471157670405
Epoch: 99 | Iteration number: [3120/4518] 69% | Training loss: 0.6869495276266183
Epoch: 99 | Iteration number: [3130/4518] 69% | Training loss: 0.6869447071331377
Epoch: 99 | Iteration number: [3140/4518] 69% | Training loss: 0.6869451593441568
Epoch: 99 | Iteration number: [3150/4518] 69% | Training loss: 0.6869446539878845
Epoch: 99 | Iteration number: [3160/4518] 69% | Training loss: 0.6869488575790502
Epoch: 99 | Iteration number: [3170/4518] 70% | Training loss: 0.6869516213233539
Epoch: 99 | Iteration number: [3180/4518] 70% | Training loss: 0.6869504694481315
Epoch: 99 | Iteration number: [3190/4518] 70% | Training loss: 0.686943198801208
Epoch: 99 | Iteration number: [3200/4518] 70% | Training loss: 0.6869371756352485
Epoch: 99 | Iteration number: [3210/4518] 71% | Training loss: 0.686937572038805
Epoch: 99 | Iteration number: [3220/4518] 71% | Training loss: 0.6869366790382018
Epoch: 99 | Iteration number: [3230/4518] 71% | Training loss: 0.6869398753894003
Epoch: 99 | Iteration number: [3240/4518] 71% | Training loss: 0.6869391763099918
Epoch: 99 | Iteration number: [3250/4518] 71% | Training loss: 0.6869376436563639
Epoch: 99 | Iteration number: [3260/4518] 72% | Training loss: 0.6869373833474938
Epoch: 99 | Iteration number: [3270/4518] 72% | Training loss: 0.6869369765122731
Epoch: 99 | Iteration number: [3280/4518] 72% | Training loss: 0.6869399414556783
Epoch: 99 | Iteration number: [3290/4518] 72% | Training loss: 0.6869442895190694
Epoch: 99 | Iteration number: [3300/4518] 73% | Training loss: 0.6869425182450901
Epoch: 99 | Iteration number: [3310/4518] 73% | Training loss: 0.6869410058162724
Epoch: 99 | Iteration number: [3320/4518] 73% | Training loss: 0.6869390942605145
Epoch: 99 | Iteration number: [3330/4518] 73% | Training loss: 0.6869423994251915
Epoch: 99 | Iteration number: [3340/4518] 73% | Training loss: 0.6869429660057593
Epoch: 99 | Iteration number: [3350/4518] 74% | Training loss: 0.6869402520336322
Epoch: 99 | Iteration number: [3360/4518] 74% | Training loss: 0.6869407333965812
Epoch: 99 | Iteration number: [3370/4518] 74% | Training loss: 0.6869370847144537
Epoch: 99 | Iteration number: [3380/4518] 74% | Training loss: 0.686934806168432
Epoch: 99 | Iteration number: [3390/4518] 75% | Training loss: 0.6869359020989905
Epoch: 99 | Iteration number: [3400/4518] 75% | Training loss: 0.6869362109899521
Epoch: 99 | Iteration number: [3410/4518] 75% | Training loss: 0.6869320069764716
Epoch: 99 | Iteration number: [3420/4518] 75% | Training loss: 0.6869297231847082
Epoch: 99 | Iteration number: [3430/4518] 75% | Training loss: 0.6869282569030284
Epoch: 99 | Iteration number: [3440/4518] 76% | Training loss: 0.6869281607831633
Epoch: 99 | Iteration number: [3450/4518] 76% | Training loss: 0.6869296939476677
Epoch: 99 | Iteration number: [3460/4518] 76% | Training loss: 0.6869303106055783
Epoch: 99 | Iteration number: [3470/4518] 76% | Training loss: 0.6869283612935618
Epoch: 99 | Iteration number: [3480/4518] 77% | Training loss: 0.6869287920409235
Epoch: 99 | Iteration number: [3490/4518] 77% | Training loss: 0.6869251171633985
Epoch: 99 | Iteration number: [3500/4518] 77% | Training loss: 0.6869256600652422
Epoch: 99 | Iteration number: [3510/4518] 77% | Training loss: 0.6869233851419215
Epoch: 99 | Iteration number: [3520/4518] 77% | Training loss: 0.686922839013013
Epoch: 99 | Iteration number: [3530/4518] 78% | Training loss: 0.6869190202725171
Epoch: 99 | Iteration number: [3540/4518] 78% | Training loss: 0.6869192250199238
Epoch: 99 | Iteration number: [3550/4518] 78% | Training loss: 0.6869162208261624
Epoch: 99 | Iteration number: [3560/4518] 78% | Training loss: 0.6869139148278183
Epoch: 99 | Iteration number: [3570/4518] 79% | Training loss: 0.686914498315138
Epoch: 99 | Iteration number: [3580/4518] 79% | Training loss: 0.6869143901257542
Epoch: 99 | Iteration number: [3590/4518] 79% | Training loss: 0.686912649322021
Epoch: 99 | Iteration number: [3600/4518] 79% | Training loss: 0.6869120485915078
Epoch: 99 | Iteration number: [3610/4518] 79% | Training loss: 0.6869113804891169
Epoch: 99 | Iteration number: [3620/4518] 80% | Training loss: 0.6869094102257524
Epoch: 99 | Iteration number: [3630/4518] 80% | Training loss: 0.6869119282924767
Epoch: 99 | Iteration number: [3640/4518] 80% | Training loss: 0.6869105697660656
Epoch: 99 | Iteration number: [3650/4518] 80% | Training loss: 0.6869103234761382
Epoch: 99 | Iteration number: [3660/4518] 81% | Training loss: 0.6869087976673262
Epoch: 99 | Iteration number: [3670/4518] 81% | Training loss: 0.6869081986047916
Epoch: 99 | Iteration number: [3680/4518] 81% | Training loss: 0.6869108073251403
Epoch: 99 | Iteration number: [3690/4518] 81% | Training loss: 0.6869127246099436
Epoch: 99 | Iteration number: [3700/4518] 81% | Training loss: 0.6869108037851952
Epoch: 99 | Iteration number: [3710/4518] 82% | Training loss: 0.6869108323459676
Epoch: 99 | Iteration number: [3720/4518] 82% | Training loss: 0.6869107386277568
Epoch: 99 | Iteration number: [3730/4518] 82% | Training loss: 0.68691515952908
Epoch: 99 | Iteration number: [3740/4518] 82% | Training loss: 0.6869130699073567
Epoch: 99 | Iteration number: [3750/4518] 83% | Training loss: 0.6869128510475159
Epoch: 99 | Iteration number: [3760/4518] 83% | Training loss: 0.6869141884465166
Epoch: 99 | Iteration number: [3770/4518] 83% | Training loss: 0.6869165953179569
Epoch: 99 | Iteration number: [3780/4518] 83% | Training loss: 0.6869162030951687
Epoch: 99 | Iteration number: [3790/4518] 83% | Training loss: 0.6869136733398589
Epoch: 99 | Iteration number: [3800/4518] 84% | Training loss: 0.6869110559319195
Epoch: 99 | Iteration number: [3810/4518] 84% | Training loss: 0.6869100488233442
Epoch: 99 | Iteration number: [3820/4518] 84% | Training loss: 0.6869124076441321
Epoch: 99 | Iteration number: [3830/4518] 84% | Training loss: 0.6869114590687166
Epoch: 99 | Iteration number: [3840/4518] 84% | Training loss: 0.6869112285940597
Epoch: 99 | Iteration number: [3850/4518] 85% | Training loss: 0.6869125787933151
Epoch: 99 | Iteration number: [3860/4518] 85% | Training loss: 0.6869132371764108
Epoch: 99 | Iteration number: [3870/4518] 85% | Training loss: 0.686913642957229
Epoch: 99 | Iteration number: [3880/4518] 85% | Training loss: 0.6869151089148423
Epoch: 99 | Iteration number: [3890/4518] 86% | Training loss: 0.686917841005448
Epoch: 99 | Iteration number: [3900/4518] 86% | Training loss: 0.6869208853214215
Epoch: 99 | Iteration number: [3910/4518] 86% | Training loss: 0.6869208639844909
Epoch: 99 | Iteration number: [3920/4518] 86% | Training loss: 0.6869190650478918
Epoch: 99 | Iteration number: [3930/4518] 86% | Training loss: 0.6869187453775916
Epoch: 99 | Iteration number: [3940/4518] 87% | Training loss: 0.6869171337881669
Epoch: 99 | Iteration number: [3950/4518] 87% | Training loss: 0.6869113594972635
Epoch: 99 | Iteration number: [3960/4518] 87% | Training loss: 0.6869130678550162
Epoch: 99 | Iteration number: [3970/4518] 87% | Training loss: 0.6869112102150616
Epoch: 99 | Iteration number: [3980/4518] 88% | Training loss: 0.6869100529195076
Epoch: 99 | Iteration number: [3990/4518] 88% | Training loss: 0.6869055190480742
Epoch: 99 | Iteration number: [4000/4518] 88% | Training loss: 0.686905714944005
Epoch: 99 | Iteration number: [4010/4518] 88% | Training loss: 0.6869057792975124
Epoch: 99 | Iteration number: [4020/4518] 88% | Training loss: 0.6869063620395328
Epoch: 99 | Iteration number: [4030/4518] 89% | Training loss: 0.6869046146461449
Epoch: 99 | Iteration number: [4040/4518] 89% | Training loss: 0.6869016032702852
Epoch: 99 | Iteration number: [4050/4518] 89% | Training loss: 0.6869008910067288
Epoch: 99 | Iteration number: [4060/4518] 89% | Training loss: 0.6869005254777194
Epoch: 99 | Iteration number: [4070/4518] 90% | Training loss: 0.6869009391828017
Epoch: 99 | Iteration number: [4080/4518] 90% | Training loss: 0.6869004100122873
Epoch: 99 | Iteration number: [4090/4518] 90% | Training loss: 0.6869022615235709
Epoch: 99 | Iteration number: [4100/4518] 90% | Training loss: 0.6869028886353097
Epoch: 99 | Iteration number: [4110/4518] 90% | Training loss: 0.686899722246068
Epoch: 99 | Iteration number: [4120/4518] 91% | Training loss: 0.6869005764427695
Epoch: 99 | Iteration number: [4130/4518] 91% | Training loss: 0.6869010031078976
Epoch: 99 | Iteration number: [4140/4518] 91% | Training loss: 0.6869036254819465
Epoch: 99 | Iteration number: [4150/4518] 91% | Training loss: 0.686903239215713
Epoch: 99 | Iteration number: [4160/4518] 92% | Training loss: 0.6869024967058347
Epoch: 99 | Iteration number: [4170/4518] 92% | Training loss: 0.6869028194345158
Epoch: 99 | Iteration number: [4180/4518] 92% | Training loss: 0.6869020524492675
Epoch: 99 | Iteration number: [4190/4518] 92% | Training loss: 0.6868981129514289
Epoch: 99 | Iteration number: [4200/4518] 92% | Training loss: 0.6868981645930381
Epoch: 99 | Iteration number: [4210/4518] 93% | Training loss: 0.6868993195388776
Epoch: 99 | Iteration number: [4220/4518] 93% | Training loss: 0.6868987154056676
Epoch: 99 | Iteration number: [4230/4518] 93% | Training loss: 0.6868967509156987
Epoch: 99 | Iteration number: [4240/4518] 93% | Training loss: 0.6868965293298352
Epoch: 99 | Iteration number: [4250/4518] 94% | Training loss: 0.686898495351567
Epoch: 99 | Iteration number: [4260/4518] 94% | Training loss: 0.6869002855719535
Epoch: 99 | Iteration number: [4270/4518] 94% | Training loss: 0.6869001011798197
Epoch: 99 | Iteration number: [4280/4518] 94% | Training loss: 0.6869016399450392
Epoch: 99 | Iteration number: [4290/4518] 94% | Training loss: 0.6869029945426888
Epoch: 99 | Iteration number: [4300/4518] 95% | Training loss: 0.6869001761009527
Epoch: 99 | Iteration number: [4310/4518] 95% | Training loss: 0.6868991774223797
Epoch: 99 | Iteration number: [4320/4518] 95% | Training loss: 0.6868993442505598
Epoch: 99 | Iteration number: [4330/4518] 95% | Training loss: 0.686899510500888
Epoch: 99 | Iteration number: [4340/4518] 96% | Training loss: 0.6868993886192822
Epoch: 99 | Iteration number: [4350/4518] 96% | Training loss: 0.6868978587238268
Epoch: 99 | Iteration number: [4360/4518] 96% | Training loss: 0.6868985441299753
Epoch: 99 | Iteration number: [4370/4518] 96% | Training loss: 0.6869009244769334
Epoch: 99 | Iteration number: [4380/4518] 96% | Training loss: 0.6869000515437017
Epoch: 99 | Iteration number: [4390/4518] 97% | Training loss: 0.6869003142202633
Epoch: 99 | Iteration number: [4400/4518] 97% | Training loss: 0.6869015336307612
Epoch: 99 | Iteration number: [4410/4518] 97% | Training loss: 0.6868981689687759
Epoch: 99 | Iteration number: [4420/4518] 97% | Training loss: 0.6868979781191813
Epoch: 99 | Iteration number: [4430/4518] 98% | Training loss: 0.6868982987667583
Epoch: 99 | Iteration number: [4440/4518] 98% | Training loss: 0.6868973362553227
Epoch: 99 | Iteration number: [4450/4518] 98% | Training loss: 0.6868987718726812
Epoch: 99 | Iteration number: [4460/4518] 98% | Training loss: 0.6868992827532002
Epoch: 99 | Iteration number: [4470/4518] 98% | Training loss: 0.6868965760706789
Epoch: 99 | Iteration number: [4480/4518] 99% | Training loss: 0.6868968799444182
Epoch: 99 | Iteration number: [4490/4518] 99% | Training loss: 0.6868959140936888
Epoch: 99 | Iteration number: [4500/4518] 99% | Training loss: 0.6868948939376407
Epoch: 99 | Iteration number: [4510/4518] 99% | Training loss: 0.6868949127567316

 End of epoch: 99 | Train Loss: 0.6867416395899362 | Training Time: 632 

 End of epoch: 99 | Eval Loss: 0.6895558919225421 | Evaluating Time: 17 
Epoch: 100 | Iteration number: [10/4518] 0% | Training loss: 0.7554395377635956
Epoch: 100 | Iteration number: [20/4518] 0% | Training loss: 0.7208362698554993
Epoch: 100 | Iteration number: [30/4518] 0% | Training loss: 0.709991584221522
Epoch: 100 | Iteration number: [40/4518] 0% | Training loss: 0.704589618742466
Epoch: 100 | Iteration number: [50/4518] 1% | Training loss: 0.7009345531463623
Epoch: 100 | Iteration number: [60/4518] 1% | Training loss: 0.6985939611991246
Epoch: 100 | Iteration number: [70/4518] 1% | Training loss: 0.696815494128636
Epoch: 100 | Iteration number: [80/4518] 1% | Training loss: 0.6954920679330826
Epoch: 100 | Iteration number: [90/4518] 1% | Training loss: 0.6945621020264096
Epoch: 100 | Iteration number: [100/4518] 2% | Training loss: 0.6938727027177811
Epoch: 100 | Iteration number: [110/4518] 2% | Training loss: 0.6933473988012834
Epoch: 100 | Iteration number: [120/4518] 2% | Training loss: 0.6926973914106687
Epoch: 100 | Iteration number: [130/4518] 2% | Training loss: 0.6922268505279835
Epoch: 100 | Iteration number: [140/4518] 3% | Training loss: 0.6918501202549253
Epoch: 100 | Iteration number: [150/4518] 3% | Training loss: 0.6915043743451437
Epoch: 100 | Iteration number: [160/4518] 3% | Training loss: 0.6912867039442062
Epoch: 100 | Iteration number: [170/4518] 3% | Training loss: 0.6910558118539698
Epoch: 100 | Iteration number: [180/4518] 3% | Training loss: 0.6908236112859514
Epoch: 100 | Iteration number: [190/4518] 4% | Training loss: 0.6906126191741542
Epoch: 100 | Iteration number: [200/4518] 4% | Training loss: 0.6903993600606918
Epoch: 100 | Iteration number: [210/4518] 4% | Training loss: 0.6902125341551645
Epoch: 100 | Iteration number: [220/4518] 4% | Training loss: 0.6900055213408036
Epoch: 100 | Iteration number: [230/4518] 5% | Training loss: 0.6898410372112108
Epoch: 100 | Iteration number: [240/4518] 5% | Training loss: 0.6897075397272905
Epoch: 100 | Iteration number: [250/4518] 5% | Training loss: 0.6895815260410308
Epoch: 100 | Iteration number: [260/4518] 5% | Training loss: 0.6895237881403703
Epoch: 100 | Iteration number: [270/4518] 5% | Training loss: 0.6894502988568059
Epoch: 100 | Iteration number: [280/4518] 6% | Training loss: 0.6893590401325908
Epoch: 100 | Iteration number: [290/4518] 6% | Training loss: 0.6892814930143027
Epoch: 100 | Iteration number: [300/4518] 6% | Training loss: 0.6891790127754212
Epoch: 100 | Iteration number: [310/4518] 6% | Training loss: 0.6891017809990914
Epoch: 100 | Iteration number: [320/4518] 7% | Training loss: 0.6889944266527891
Epoch: 100 | Iteration number: [330/4518] 7% | Training loss: 0.6889261043432987
Epoch: 100 | Iteration number: [340/4518] 7% | Training loss: 0.6888272830668618
Epoch: 100 | Iteration number: [350/4518] 7% | Training loss: 0.6887592959403992
Epoch: 100 | Iteration number: [360/4518] 7% | Training loss: 0.6887075732151667
Epoch: 100 | Iteration number: [370/4518] 8% | Training loss: 0.6886908355596904
Epoch: 100 | Iteration number: [380/4518] 8% | Training loss: 0.688643897834577
Epoch: 100 | Iteration number: [390/4518] 8% | Training loss: 0.6886090617913466
Epoch: 100 | Iteration number: [400/4518] 8% | Training loss: 0.6885974662005901
Epoch: 100 | Iteration number: [410/4518] 9% | Training loss: 0.6885186782697352
Epoch: 100 | Iteration number: [420/4518] 9% | Training loss: 0.6884979991685777
Epoch: 100 | Iteration number: [430/4518] 9% | Training loss: 0.6884652018547058
Epoch: 100 | Iteration number: [440/4518] 9% | Training loss: 0.688450895791704
Epoch: 100 | Iteration number: [450/4518] 9% | Training loss: 0.6884322876400418
Epoch: 100 | Iteration number: [460/4518] 10% | Training loss: 0.6883819963621056
Epoch: 100 | Iteration number: [470/4518] 10% | Training loss: 0.6883314902478076
Epoch: 100 | Iteration number: [480/4518] 10% | Training loss: 0.6883206746230522
Epoch: 100 | Iteration number: [490/4518] 10% | Training loss: 0.6882850667651819
Epoch: 100 | Iteration number: [500/4518] 11% | Training loss: 0.6882359925508499
Epoch: 100 | Iteration number: [510/4518] 11% | Training loss: 0.6881823353907641
Epoch: 100 | Iteration number: [520/4518] 11% | Training loss: 0.6881761690744987
Epoch: 100 | Iteration number: [530/4518] 11% | Training loss: 0.6881629343302744
Epoch: 100 | Iteration number: [540/4518] 11% | Training loss: 0.688124453579938
Epoch: 100 | Iteration number: [550/4518] 12% | Training loss: 0.6881045098738237
Epoch: 100 | Iteration number: [560/4518] 12% | Training loss: 0.6880694090255669
Epoch: 100 | Iteration number: [570/4518] 12% | Training loss: 0.6880202474301321
Epoch: 100 | Iteration number: [580/4518] 12% | Training loss: 0.6879951706220364
Epoch: 100 | Iteration number: [590/4518] 13% | Training loss: 0.687967392751726
Epoch: 100 | Iteration number: [600/4518] 13% | Training loss: 0.6879557419816653
Epoch: 100 | Iteration number: [610/4518] 13% | Training loss: 0.6879432140803728
Epoch: 100 | Iteration number: [620/4518] 13% | Training loss: 0.6879117447522378
Epoch: 100 | Iteration number: [630/4518] 13% | Training loss: 0.6879048963387807
Epoch: 100 | Iteration number: [640/4518] 14% | Training loss: 0.6878734615631401
Epoch: 100 | Iteration number: [650/4518] 14% | Training loss: 0.6878600398393778
Epoch: 100 | Iteration number: [660/4518] 14% | Training loss: 0.6878394550446308
Epoch: 100 | Iteration number: [670/4518] 14% | Training loss: 0.6878267157433638
Epoch: 100 | Iteration number: [680/4518] 15% | Training loss: 0.6877833897576613
Epoch: 100 | Iteration number: [690/4518] 15% | Training loss: 0.6877481095168901
Epoch: 100 | Iteration number: [700/4518] 15% | Training loss: 0.6877454517568861
Epoch: 100 | Iteration number: [710/4518] 15% | Training loss: 0.6877207309427396
Epoch: 100 | Iteration number: [720/4518] 15% | Training loss: 0.6877268726627032
Epoch: 100 | Iteration number: [730/4518] 16% | Training loss: 0.6877138108423312
Epoch: 100 | Iteration number: [740/4518] 16% | Training loss: 0.6876975861755578
Epoch: 100 | Iteration number: [750/4518] 16% | Training loss: 0.6876874873638154
Epoch: 100 | Iteration number: [760/4518] 16% | Training loss: 0.6876753102791937
Epoch: 100 | Iteration number: [770/4518] 17% | Training loss: 0.6876514543186535
Epoch: 100 | Iteration number: [780/4518] 17% | Training loss: 0.6876388817261427
Epoch: 100 | Iteration number: [790/4518] 17% | Training loss: 0.6876189171513425
Epoch: 100 | Iteration number: [800/4518] 17% | Training loss: 0.6876278299838304
Epoch: 100 | Iteration number: [810/4518] 17% | Training loss: 0.687626083103227
Epoch: 100 | Iteration number: [820/4518] 18% | Training loss: 0.687613792244981
Epoch: 100 | Iteration number: [830/4518] 18% | Training loss: 0.687598430320441
Epoch: 100 | Iteration number: [840/4518] 18% | Training loss: 0.6875955042384919
Epoch: 100 | Iteration number: [850/4518] 18% | Training loss: 0.6875871930402868
Epoch: 100 | Iteration number: [860/4518] 19% | Training loss: 0.6875756172939789
Epoch: 100 | Iteration number: [870/4518] 19% | Training loss: 0.6875540328436884
Epoch: 100 | Iteration number: [880/4518] 19% | Training loss: 0.6875477142632007
Epoch: 100 | Iteration number: [890/4518] 19% | Training loss: 0.6875256418512109
Epoch: 100 | Iteration number: [900/4518] 19% | Training loss: 0.6875160832537545
Epoch: 100 | Iteration number: [910/4518] 20% | Training loss: 0.6875185904922066
Epoch: 100 | Iteration number: [920/4518] 20% | Training loss: 0.6874985941078352
Epoch: 100 | Iteration number: [930/4518] 20% | Training loss: 0.6874911821016702
Epoch: 100 | Iteration number: [940/4518] 20% | Training loss: 0.6874871757436306
Epoch: 100 | Iteration number: [950/4518] 21% | Training loss: 0.6874787515088131
Epoch: 100 | Iteration number: [960/4518] 21% | Training loss: 0.687473465440174
Epoch: 100 | Iteration number: [970/4518] 21% | Training loss: 0.6874722260789773
Epoch: 100 | Iteration number: [980/4518] 21% | Training loss: 0.6874683811956522
Epoch: 100 | Iteration number: [990/4518] 21% | Training loss: 0.6874547175084702
Epoch: 100 | Iteration number: [1000/4518] 22% | Training loss: 0.6874367671012879
Epoch: 100 | Iteration number: [1010/4518] 22% | Training loss: 0.6874201713222088
Epoch: 100 | Iteration number: [1020/4518] 22% | Training loss: 0.6874143262119854
Epoch: 100 | Iteration number: [1030/4518] 22% | Training loss: 0.6874133930044267
Epoch: 100 | Iteration number: [1040/4518] 23% | Training loss: 0.6874143376946449
Epoch: 100 | Iteration number: [1050/4518] 23% | Training loss: 0.6874048026402791
Epoch: 100 | Iteration number: [1060/4518] 23% | Training loss: 0.6874059573659357
Epoch: 100 | Iteration number: [1070/4518] 23% | Training loss: 0.6873937834089048
Epoch: 100 | Iteration number: [1080/4518] 23% | Training loss: 0.6873922783467504
Epoch: 100 | Iteration number: [1090/4518] 24% | Training loss: 0.687389230236001
Epoch: 100 | Iteration number: [1100/4518] 24% | Training loss: 0.687387093522332
Epoch: 100 | Iteration number: [1110/4518] 24% | Training loss: 0.6873805870880951
Epoch: 100 | Iteration number: [1120/4518] 24% | Training loss: 0.6873865486255714
Epoch: 100 | Iteration number: [1130/4518] 25% | Training loss: 0.687379249007301
Epoch: 100 | Iteration number: [1140/4518] 25% | Training loss: 0.6873614843477283
Epoch: 100 | Iteration number: [1150/4518] 25% | Training loss: 0.687349745657133
Epoch: 100 | Iteration number: [1160/4518] 25% | Training loss: 0.6873342169769879
Epoch: 100 | Iteration number: [1170/4518] 25% | Training loss: 0.6873295162478064
Epoch: 100 | Iteration number: [1180/4518] 26% | Training loss: 0.6873385146512824
Epoch: 100 | Iteration number: [1190/4518] 26% | Training loss: 0.6873260265638849
Epoch: 100 | Iteration number: [1200/4518] 26% | Training loss: 0.6873231257001559
Epoch: 100 | Iteration number: [1210/4518] 26% | Training loss: 0.6873271816032978
Epoch: 100 | Iteration number: [1220/4518] 27% | Training loss: 0.6873145520687103
Epoch: 100 | Iteration number: [1230/4518] 27% | Training loss: 0.687309661531836
Epoch: 100 | Iteration number: [1240/4518] 27% | Training loss: 0.6873009734096066
Epoch: 100 | Iteration number: [1250/4518] 27% | Training loss: 0.6872938853263855
Epoch: 100 | Iteration number: [1260/4518] 27% | Training loss: 0.687298068451503
Epoch: 100 | Iteration number: [1270/4518] 28% | Training loss: 0.6872907347097171
Epoch: 100 | Iteration number: [1280/4518] 28% | Training loss: 0.6872867245227099
Epoch: 100 | Iteration number: [1290/4518] 28% | Training loss: 0.6872938714286153
Epoch: 100 | Iteration number: [1300/4518] 28% | Training loss: 0.6872745345647518
Epoch: 100 | Iteration number: [1310/4518] 28% | Training loss: 0.6872739464727067
Epoch: 100 | Iteration number: [1320/4518] 29% | Training loss: 0.6872637888698867
Epoch: 100 | Iteration number: [1330/4518] 29% | Training loss: 0.6872678401326775
Epoch: 100 | Iteration number: [1340/4518] 29% | Training loss: 0.6872614740880567
Epoch: 100 | Iteration number: [1350/4518] 29% | Training loss: 0.687252456744512
Epoch: 100 | Iteration number: [1360/4518] 30% | Training loss: 0.6872477096669815
Epoch: 100 | Iteration number: [1370/4518] 30% | Training loss: 0.6872425885096084
Epoch: 100 | Iteration number: [1380/4518] 30% | Training loss: 0.6872433465460073
Epoch: 100 | Iteration number: [1390/4518] 30% | Training loss: 0.687238070004278
Epoch: 100 | Iteration number: [1400/4518] 30% | Training loss: 0.6872318035364151
Epoch: 100 | Iteration number: [1410/4518] 31% | Training loss: 0.6872244691595119
Epoch: 100 | Iteration number: [1420/4518] 31% | Training loss: 0.6872176040646056
Epoch: 100 | Iteration number: [1430/4518] 31% | Training loss: 0.6872085697584219
Epoch: 100 | Iteration number: [1440/4518] 31% | Training loss: 0.6872102156281471
Epoch: 100 | Iteration number: [1450/4518] 32% | Training loss: 0.6871954443948022
Epoch: 100 | Iteration number: [1460/4518] 32% | Training loss: 0.6871965180929392
Epoch: 100 | Iteration number: [1470/4518] 32% | Training loss: 0.6872011545158568
Epoch: 100 | Iteration number: [1480/4518] 32% | Training loss: 0.6871910684414813
Epoch: 100 | Iteration number: [1490/4518] 32% | Training loss: 0.6871957558513487
Epoch: 100 | Iteration number: [1500/4518] 33% | Training loss: 0.687195416132609
Epoch: 100 | Iteration number: [1510/4518] 33% | Training loss: 0.6871966707785397
Epoch: 100 | Iteration number: [1520/4518] 33% | Training loss: 0.6871928668335865
Epoch: 100 | Iteration number: [1530/4518] 33% | Training loss: 0.6871897229571747
Epoch: 100 | Iteration number: [1540/4518] 34% | Training loss: 0.6871931958508182
Epoch: 100 | Iteration number: [1550/4518] 34% | Training loss: 0.6871859064794356
Epoch: 100 | Iteration number: [1560/4518] 34% | Training loss: 0.6871753846223537
Epoch: 100 | Iteration number: [1570/4518] 34% | Training loss: 0.6871737424355404
Epoch: 100 | Iteration number: [1580/4518] 34% | Training loss: 0.6871734187950062
Epoch: 100 | Iteration number: [1590/4518] 35% | Training loss: 0.6871693235148424
Epoch: 100 | Iteration number: [1600/4518] 35% | Training loss: 0.6871705529466271
Epoch: 100 | Iteration number: [1610/4518] 35% | Training loss: 0.6871702256410018
Epoch: 100 | Iteration number: [1620/4518] 35% | Training loss: 0.6871718015199826
Epoch: 100 | Iteration number: [1630/4518] 36% | Training loss: 0.6871594760681222
Epoch: 100 | Iteration number: [1640/4518] 36% | Training loss: 0.6871587162337652
Epoch: 100 | Iteration number: [1650/4518] 36% | Training loss: 0.6871639454364776
Epoch: 100 | Iteration number: [1660/4518] 36% | Training loss: 0.6871628107076668
Epoch: 100 | Iteration number: [1670/4518] 36% | Training loss: 0.687162452008196
Epoch: 100 | Iteration number: [1680/4518] 37% | Training loss: 0.6871539094973178
Epoch: 100 | Iteration number: [1690/4518] 37% | Training loss: 0.6871563797166361
Epoch: 100 | Iteration number: [1700/4518] 37% | Training loss: 0.6871556075530894
Epoch: 100 | Iteration number: [1710/4518] 37% | Training loss: 0.6871547379340345
Epoch: 100 | Iteration number: [1720/4518] 38% | Training loss: 0.6871524004395618
Epoch: 100 | Iteration number: [1730/4518] 38% | Training loss: 0.6871441162735051
Epoch: 100 | Iteration number: [1740/4518] 38% | Training loss: 0.6871404719421234
Epoch: 100 | Iteration number: [1750/4518] 38% | Training loss: 0.6871335854189736
Epoch: 100 | Iteration number: [1760/4518] 38% | Training loss: 0.6871351299299435
Epoch: 100 | Iteration number: [1770/4518] 39% | Training loss: 0.6871340624693424
Epoch: 100 | Iteration number: [1780/4518] 39% | Training loss: 0.6871373604522663
Epoch: 100 | Iteration number: [1790/4518] 39% | Training loss: 0.6871305492670177
Epoch: 100 | Iteration number: [1800/4518] 39% | Training loss: 0.6871161420808898
Epoch: 100 | Iteration number: [1810/4518] 40% | Training loss: 0.6871189256399376
Epoch: 100 | Iteration number: [1820/4518] 40% | Training loss: 0.6871146231562226
Epoch: 100 | Iteration number: [1830/4518] 40% | Training loss: 0.687108585515309
Epoch: 100 | Iteration number: [1840/4518] 40% | Training loss: 0.687107975197875
Epoch: 100 | Iteration number: [1850/4518] 40% | Training loss: 0.6871032213198172
Epoch: 100 | Iteration number: [1860/4518] 41% | Training loss: 0.6871015762129138
Epoch: 100 | Iteration number: [1870/4518] 41% | Training loss: 0.6870933935922735
Epoch: 100 | Iteration number: [1880/4518] 41% | Training loss: 0.6870932767048795
Epoch: 100 | Iteration number: [1890/4518] 41% | Training loss: 0.6870925813440293
Epoch: 100 | Iteration number: [1900/4518] 42% | Training loss: 0.6870846731411784
Epoch: 100 | Iteration number: [1910/4518] 42% | Training loss: 0.6870824224349716
Epoch: 100 | Iteration number: [1920/4518] 42% | Training loss: 0.6870780939857165
Epoch: 100 | Iteration number: [1930/4518] 42% | Training loss: 0.6870723426650843
Epoch: 100 | Iteration number: [1940/4518] 42% | Training loss: 0.6870724633796927
Epoch: 100 | Iteration number: [1950/4518] 43% | Training loss: 0.6870742515722911
Epoch: 100 | Iteration number: [1960/4518] 43% | Training loss: 0.6870695241555875
Epoch: 100 | Iteration number: [1970/4518] 43% | Training loss: 0.6870705358873164
Epoch: 100 | Iteration number: [1980/4518] 43% | Training loss: 0.6870787512774419
Epoch: 100 | Iteration number: [1990/4518] 44% | Training loss: 0.687072799463368
Epoch: 100 | Iteration number: [2000/4518] 44% | Training loss: 0.6870776961147785
Epoch: 100 | Iteration number: [2010/4518] 44% | Training loss: 0.6870748666685019
Epoch: 100 | Iteration number: [2020/4518] 44% | Training loss: 0.6870741858340726
Epoch: 100 | Iteration number: [2030/4518] 44% | Training loss: 0.6870803356464273
Epoch: 100 | Iteration number: [2040/4518] 45% | Training loss: 0.6870795813845653
Epoch: 100 | Iteration number: [2050/4518] 45% | Training loss: 0.6870750009722826
Epoch: 100 | Iteration number: [2060/4518] 45% | Training loss: 0.6870747845439078
Epoch: 100 | Iteration number: [2070/4518] 45% | Training loss: 0.6870740278331554
Epoch: 100 | Iteration number: [2080/4518] 46% | Training loss: 0.6870771927042649
Epoch: 100 | Iteration number: [2090/4518] 46% | Training loss: 0.6870761402771234
Epoch: 100 | Iteration number: [2100/4518] 46% | Training loss: 0.6870723135414578
Epoch: 100 | Iteration number: [2110/4518] 46% | Training loss: 0.6870713839316255
Epoch: 100 | Iteration number: [2120/4518] 46% | Training loss: 0.6870676394059972
Epoch: 100 | Iteration number: [2130/4518] 47% | Training loss: 0.6870658579007001
Epoch: 100 | Iteration number: [2140/4518] 47% | Training loss: 0.687067220589825
Epoch: 100 | Iteration number: [2150/4518] 47% | Training loss: 0.6870661604127218
Epoch: 100 | Iteration number: [2160/4518] 47% | Training loss: 0.687061107682961
Epoch: 100 | Iteration number: [2170/4518] 48% | Training loss: 0.6870580113153854
Epoch: 100 | Iteration number: [2180/4518] 48% | Training loss: 0.687048829722842
Epoch: 100 | Iteration number: [2190/4518] 48% | Training loss: 0.6870433597532037
Epoch: 100 | Iteration number: [2200/4518] 48% | Training loss: 0.6870410108566284
Epoch: 100 | Iteration number: [2210/4518] 48% | Training loss: 0.6870386052725003
Epoch: 100 | Iteration number: [2220/4518] 49% | Training loss: 0.6870419081266936
Epoch: 100 | Iteration number: [2230/4518] 49% | Training loss: 0.687037646556649
Epoch: 100 | Iteration number: [2240/4518] 49% | Training loss: 0.6870326547750405
Epoch: 100 | Iteration number: [2250/4518] 49% | Training loss: 0.6870367340511746
Epoch: 100 | Iteration number: [2260/4518] 50% | Training loss: 0.6870323151350022
Epoch: 100 | Iteration number: [2270/4518] 50% | Training loss: 0.6870261983724417
Epoch: 100 | Iteration number: [2280/4518] 50% | Training loss: 0.6870294853522066
Epoch: 100 | Iteration number: [2290/4518] 50% | Training loss: 0.6870280430046232
Epoch: 100 | Iteration number: [2300/4518] 50% | Training loss: 0.6870256518281025
Epoch: 100 | Iteration number: [2310/4518] 51% | Training loss: 0.687022584779954
Epoch: 100 | Iteration number: [2320/4518] 51% | Training loss: 0.6870180812118383
Epoch: 100 | Iteration number: [2330/4518] 51% | Training loss: 0.6870178507377149
Epoch: 100 | Iteration number: [2340/4518] 51% | Training loss: 0.6870177116913673
Epoch: 100 | Iteration number: [2350/4518] 52% | Training loss: 0.6870207100979825
Epoch: 100 | Iteration number: [2360/4518] 52% | Training loss: 0.6870216436305289
Epoch: 100 | Iteration number: [2370/4518] 52% | Training loss: 0.6870203339600864
Epoch: 100 | Iteration number: [2380/4518] 52% | Training loss: 0.6870191137079431
Epoch: 100 | Iteration number: [2390/4518] 52% | Training loss: 0.6870201471959198
Epoch: 100 | Iteration number: [2400/4518] 53% | Training loss: 0.687023491859436
Epoch: 100 | Iteration number: [2410/4518] 53% | Training loss: 0.6870223778659378
Epoch: 100 | Iteration number: [2420/4518] 53% | Training loss: 0.6870216110274812
Epoch: 100 | Iteration number: [2430/4518] 53% | Training loss: 0.6870213270187377
Epoch: 100 | Iteration number: [2440/4518] 54% | Training loss: 0.6870222282458525
Epoch: 100 | Iteration number: [2450/4518] 54% | Training loss: 0.6870252105411219
Epoch: 100 | Iteration number: [2460/4518] 54% | Training loss: 0.6870284318197064
Epoch: 100 | Iteration number: [2470/4518] 54% | Training loss: 0.6870270050006356
Epoch: 100 | Iteration number: [2480/4518] 54% | Training loss: 0.6870278183971682
Epoch: 100 | Iteration number: [2490/4518] 55% | Training loss: 0.6870230615857136
Epoch: 100 | Iteration number: [2500/4518] 55% | Training loss: 0.6870217533111572
Epoch: 100 | Iteration number: [2510/4518] 55% | Training loss: 0.6870171083872062
Epoch: 100 | Iteration number: [2520/4518] 55% | Training loss: 0.6870142500788446
Epoch: 100 | Iteration number: [2530/4518] 55% | Training loss: 0.6870122122670351
Epoch: 100 | Iteration number: [2540/4518] 56% | Training loss: 0.6870096608409731
Epoch: 100 | Iteration number: [2550/4518] 56% | Training loss: 0.6870113035043081
Epoch: 100 | Iteration number: [2560/4518] 56% | Training loss: 0.6870118619175628
Epoch: 100 | Iteration number: [2570/4518] 56% | Training loss: 0.6870101055282563
Epoch: 100 | Iteration number: [2580/4518] 57% | Training loss: 0.6870094536579856
Epoch: 100 | Iteration number: [2590/4518] 57% | Training loss: 0.6870080432836614
Epoch: 100 | Iteration number: [2600/4518] 57% | Training loss: 0.6870027818129613
Epoch: 100 | Iteration number: [2610/4518] 57% | Training loss: 0.687004523966961
Epoch: 100 | Iteration number: [2620/4518] 57% | Training loss: 0.6870031103150536
Epoch: 100 | Iteration number: [2630/4518] 58% | Training loss: 0.6870022574078447
Epoch: 100 | Iteration number: [2640/4518] 58% | Training loss: 0.6870003719673012
Epoch: 100 | Iteration number: [2650/4518] 58% | Training loss: 0.6869928712889833
Epoch: 100 | Iteration number: [2660/4518] 58% | Training loss: 0.6869995455096539
Epoch: 100 | Iteration number: [2670/4518] 59% | Training loss: 0.6869972552029827
Epoch: 100 | Iteration number: [2680/4518] 59% | Training loss: 0.6869943904342936
Epoch: 100 | Iteration number: [2690/4518] 59% | Training loss: 0.6869917079196987
Epoch: 100 | Iteration number: [2700/4518] 59% | Training loss: 0.686991253539368
Epoch: 100 | Iteration number: [2710/4518] 59% | Training loss: 0.6869938181115253
Epoch: 100 | Iteration number: [2720/4518] 60% | Training loss: 0.6869926374186488
Epoch: 100 | Iteration number: [2730/4518] 60% | Training loss: 0.6869902981506599
Epoch: 100 | Iteration number: [2740/4518] 60% | Training loss: 0.6869880197474556
Epoch: 100 | Iteration number: [2750/4518] 60% | Training loss: 0.6869897781502117
Epoch: 100 | Iteration number: [2760/4518] 61% | Training loss: 0.6869894872541012
Epoch: 100 | Iteration number: [2770/4518] 61% | Training loss: 0.686991422249522
Epoch: 100 | Iteration number: [2780/4518] 61% | Training loss: 0.686990655154633
Epoch: 100 | Iteration number: [2790/4518] 61% | Training loss: 0.6869940105518559
Epoch: 100 | Iteration number: [2800/4518] 61% | Training loss: 0.6869987067793096
Epoch: 100 | Iteration number: [2810/4518] 62% | Training loss: 0.6870006605611577
Epoch: 100 | Iteration number: [2820/4518] 62% | Training loss: 0.6869982222504649
Epoch: 100 | Iteration number: [2830/4518] 62% | Training loss: 0.6869933291374584
Epoch: 100 | Iteration number: [2840/4518] 62% | Training loss: 0.6869906575117313
Epoch: 100 | Iteration number: [2850/4518] 63% | Training loss: 0.6869926771364714
Epoch: 100 | Iteration number: [2860/4518] 63% | Training loss: 0.6869929815714176
Epoch: 100 | Iteration number: [2870/4518] 63% | Training loss: 0.6869882553088956
Epoch: 100 | Iteration number: [2880/4518] 63% | Training loss: 0.6869884838660558
Epoch: 100 | Iteration number: [2890/4518] 63% | Training loss: 0.6869893790735093
Epoch: 100 | Iteration number: [2900/4518] 64% | Training loss: 0.6869897873237215
Epoch: 100 | Iteration number: [2910/4518] 64% | Training loss: 0.6869828208410453
Epoch: 100 | Iteration number: [2920/4518] 64% | Training loss: 0.6869851082563401
Epoch: 100 | Iteration number: [2930/4518] 64% | Training loss: 0.6869848439514433
Epoch: 100 | Iteration number: [2940/4518] 65% | Training loss: 0.6869874395278035
Epoch: 100 | Iteration number: [2950/4518] 65% | Training loss: 0.6869858343520407
Epoch: 100 | Iteration number: [2960/4518] 65% | Training loss: 0.6869871092003745
Epoch: 100 | Iteration number: [2970/4518] 65% | Training loss: 0.6869866510633668
Epoch: 100 | Iteration number: [2980/4518] 65% | Training loss: 0.6869827984163425
Epoch: 100 | Iteration number: [2990/4518] 66% | Training loss: 0.6869856529211918
Epoch: 100 | Iteration number: [3000/4518] 66% | Training loss: 0.6869878214995067
Epoch: 100 | Iteration number: [3010/4518] 66% | Training loss: 0.6869868232760319
Epoch: 100 | Iteration number: [3020/4518] 66% | Training loss: 0.6869832258745534
Epoch: 100 | Iteration number: [3030/4518] 67% | Training loss: 0.6869797372188505
Epoch: 100 | Iteration number: [3040/4518] 67% | Training loss: 0.6869805431679675
Epoch: 100 | Iteration number: [3050/4518] 67% | Training loss: 0.6869810050823649
Epoch: 100 | Iteration number: [3060/4518] 67% | Training loss: 0.6869807866468928
Epoch: 100 | Iteration number: [3070/4518] 67% | Training loss: 0.6869828957688149
Epoch: 100 | Iteration number: [3080/4518] 68% | Training loss: 0.6869818431603444
Epoch: 100 | Iteration number: [3090/4518] 68% | Training loss: 0.6869849072883816
Epoch: 100 | Iteration number: [3100/4518] 68% | Training loss: 0.6869860876183356
Epoch: 100 | Iteration number: [3110/4518] 68% | Training loss: 0.6869837462710414
Epoch: 100 | Iteration number: [3120/4518] 69% | Training loss: 0.6869843748326485
Epoch: 100 | Iteration number: [3130/4518] 69% | Training loss: 0.6869848302949351
Epoch: 100 | Iteration number: [3140/4518] 69% | Training loss: 0.6869848325374021
Epoch: 100 | Iteration number: [3150/4518] 69% | Training loss: 0.6869838358296289
Epoch: 100 | Iteration number: [3160/4518] 69% | Training loss: 0.6869828158164326
Epoch: 100 | Iteration number: [3170/4518] 70% | Training loss: 0.6869796692008852
Epoch: 100 | Iteration number: [3180/4518] 70% | Training loss: 0.6869748727330621
Epoch: 100 | Iteration number: [3190/4518] 70% | Training loss: 0.6869787576803966
Epoch: 100 | Iteration number: [3200/4518] 70% | Training loss: 0.6869775166921318
Epoch: 100 | Iteration number: [3210/4518] 71% | Training loss: 0.6869704438889881
Epoch: 100 | Iteration number: [3220/4518] 71% | Training loss: 0.6869691445220332
Epoch: 100 | Iteration number: [3230/4518] 71% | Training loss: 0.6869673818073037
Epoch: 100 | Iteration number: [3240/4518] 71% | Training loss: 0.6869668265551696
Epoch: 100 | Iteration number: [3250/4518] 71% | Training loss: 0.6869655034358685
Epoch: 100 | Iteration number: [3260/4518] 72% | Training loss: 0.6869682141242583
Epoch: 100 | Iteration number: [3270/4518] 72% | Training loss: 0.6869676677276599
Epoch: 100 | Iteration number: [3280/4518] 72% | Training loss: 0.6869704335382799
Epoch: 100 | Iteration number: [3290/4518] 72% | Training loss: 0.6869706029406435
Epoch: 100 | Iteration number: [3300/4518] 73% | Training loss: 0.6869730453599583
Epoch: 100 | Iteration number: [3310/4518] 73% | Training loss: 0.6869728834787524
Epoch: 100 | Iteration number: [3320/4518] 73% | Training loss: 0.6869743238371538
Epoch: 100 | Iteration number: [3330/4518] 73% | Training loss: 0.6869752416918585
Epoch: 100 | Iteration number: [3340/4518] 73% | Training loss: 0.6869725552504647
Epoch: 100 | Iteration number: [3350/4518] 74% | Training loss: 0.6869739370381654
Epoch: 100 | Iteration number: [3360/4518] 74% | Training loss: 0.6869690001010895
Epoch: 100 | Iteration number: [3370/4518] 74% | Training loss: 0.6869664298497604
Epoch: 100 | Iteration number: [3380/4518] 74% | Training loss: 0.6869648911543852
Epoch: 100 | Iteration number: [3390/4518] 75% | Training loss: 0.6869654626093783
Epoch: 100 | Iteration number: [3400/4518] 75% | Training loss: 0.6869636939728961
Epoch: 100 | Iteration number: [3410/4518] 75% | Training loss: 0.6869633381842168
Epoch: 100 | Iteration number: [3420/4518] 75% | Training loss: 0.6869610829137223
Epoch: 100 | Iteration number: [3430/4518] 75% | Training loss: 0.6869601244307816
Epoch: 100 | Iteration number: [3440/4518] 76% | Training loss: 0.6869590472689895
Epoch: 100 | Iteration number: [3450/4518] 76% | Training loss: 0.6869565672805343
Epoch: 100 | Iteration number: [3460/4518] 76% | Training loss: 0.6869578444716559
Epoch: 100 | Iteration number: [3470/4518] 76% | Training loss: 0.6869611973034202
Epoch: 100 | Iteration number: [3480/4518] 77% | Training loss: 0.6869586777755584
Epoch: 100 | Iteration number: [3490/4518] 77% | Training loss: 0.6869574717942486
Epoch: 100 | Iteration number: [3500/4518] 77% | Training loss: 0.6869554589135306
Epoch: 100 | Iteration number: [3510/4518] 77% | Training loss: 0.6869564190379575
Epoch: 100 | Iteration number: [3520/4518] 77% | Training loss: 0.6869521369818937
Epoch: 100 | Iteration number: [3530/4518] 78% | Training loss: 0.6869529268221545
Epoch: 100 | Iteration number: [3540/4518] 78% | Training loss: 0.6869491694168856
Epoch: 100 | Iteration number: [3550/4518] 78% | Training loss: 0.6869492654901155
Epoch: 100 | Iteration number: [3560/4518] 78% | Training loss: 0.6869495576352216
Epoch: 100 | Iteration number: [3570/4518] 79% | Training loss: 0.6869502828234718
Epoch: 100 | Iteration number: [3580/4518] 79% | Training loss: 0.6869509537792738
Epoch: 100 | Iteration number: [3590/4518] 79% | Training loss: 0.6869534995894578
Epoch: 100 | Iteration number: [3600/4518] 79% | Training loss: 0.6869521267546548
Epoch: 100 | Iteration number: [3610/4518] 79% | Training loss: 0.6869462901865676
Epoch: 100 | Iteration number: [3620/4518] 80% | Training loss: 0.6869450001756131
Epoch: 100 | Iteration number: [3630/4518] 80% | Training loss: 0.6869451935133658
Epoch: 100 | Iteration number: [3640/4518] 80% | Training loss: 0.6869446570892911
Epoch: 100 | Iteration number: [3650/4518] 80% | Training loss: 0.6869425000556528
Epoch: 100 | Iteration number: [3660/4518] 81% | Training loss: 0.6869392721216535
Epoch: 100 | Iteration number: [3670/4518] 81% | Training loss: 0.686938445152314
Epoch: 100 | Iteration number: [3680/4518] 81% | Training loss: 0.6869351422657137
Epoch: 100 | Iteration number: [3690/4518] 81% | Training loss: 0.6869341413987684
Epoch: 100 | Iteration number: [3700/4518] 81% | Training loss: 0.6869329649693257
Epoch: 100 | Iteration number: [3710/4518] 82% | Training loss: 0.6869346981099995
Epoch: 100 | Iteration number: [3720/4518] 82% | Training loss: 0.6869301667937668
Epoch: 100 | Iteration number: [3730/4518] 82% | Training loss: 0.6869264096101552
Epoch: 100 | Iteration number: [3740/4518] 82% | Training loss: 0.6869281928328906
Epoch: 100 | Iteration number: [3750/4518] 83% | Training loss: 0.6869300659497579
Epoch: 100 | Iteration number: [3760/4518] 83% | Training loss: 0.6869290750870045
Epoch: 100 | Iteration number: [3770/4518] 83% | Training loss: 0.6869277417185452
Epoch: 100 | Iteration number: [3780/4518] 83% | Training loss: 0.6869292788404636
Epoch: 100 | Iteration number: [3790/4518] 83% | Training loss: 0.6869315563846075
Epoch: 100 | Iteration number: [3800/4518] 84% | Training loss: 0.6869317949759333
Epoch: 100 | Iteration number: [3810/4518] 84% | Training loss: 0.686931309236942
Epoch: 100 | Iteration number: [3820/4518] 84% | Training loss: 0.6869298879232706
Epoch: 100 | Iteration number: [3830/4518] 84% | Training loss: 0.6869284685691405
Epoch: 100 | Iteration number: [3840/4518] 84% | Training loss: 0.6869269129199286
Epoch: 100 | Iteration number: [3850/4518] 85% | Training loss: 0.6869266110581237
Epoch: 100 | Iteration number: [3860/4518] 85% | Training loss: 0.6869270264021473
Epoch: 100 | Iteration number: [3870/4518] 85% | Training loss: 0.6869293625194589
Epoch: 100 | Iteration number: [3880/4518] 85% | Training loss: 0.6869302351142942
Epoch: 100 | Iteration number: [3890/4518] 86% | Training loss: 0.6869257214290011
Epoch: 100 | Iteration number: [3900/4518] 86% | Training loss: 0.6869260289883002
Epoch: 100 | Iteration number: [3910/4518] 86% | Training loss: 0.6869252076234355
Epoch: 100 | Iteration number: [3920/4518] 86% | Training loss: 0.6869246680669638
Epoch: 100 | Iteration number: [3930/4518] 86% | Training loss: 0.6869249645383607
Epoch: 100 | Iteration number: [3940/4518] 87% | Training loss: 0.6869241183784407
Epoch: 100 | Iteration number: [3950/4518] 87% | Training loss: 0.6869228593458103
Epoch: 100 | Iteration number: [3960/4518] 87% | Training loss: 0.6869202307378403
Epoch: 100 | Iteration number: [3970/4518] 87% | Training loss: 0.6869166147648837
Epoch: 100 | Iteration number: [3980/4518] 88% | Training loss: 0.6869135752844451
Epoch: 100 | Iteration number: [3990/4518] 88% | Training loss: 0.6869081798651463
Epoch: 100 | Iteration number: [4000/4518] 88% | Training loss: 0.686905087530613
Epoch: 100 | Iteration number: [4010/4518] 88% | Training loss: 0.686909082256945
Epoch: 100 | Iteration number: [4020/4518] 88% | Training loss: 0.6869091526192812
Epoch: 100 | Iteration number: [4030/4518] 89% | Training loss: 0.6869072913679828
Epoch: 100 | Iteration number: [4040/4518] 89% | Training loss: 0.6869065814236603
Epoch: 100 | Iteration number: [4050/4518] 89% | Training loss: 0.6869093483465689
Epoch: 100 | Iteration number: [4060/4518] 89% | Training loss: 0.6869060558785358
Epoch: 100 | Iteration number: [4070/4518] 90% | Training loss: 0.6869051846737357
Epoch: 100 | Iteration number: [4080/4518] 90% | Training loss: 0.6869070268144795
Epoch: 100 | Iteration number: [4090/4518] 90% | Training loss: 0.6869051705945675
Epoch: 100 | Iteration number: [4100/4518] 90% | Training loss: 0.686904636839541
Epoch: 100 | Iteration number: [4110/4518] 90% | Training loss: 0.6869036837940958
Epoch: 100 | Iteration number: [4120/4518] 91% | Training loss: 0.6869044498621839
Epoch: 100 | Iteration number: [4130/4518] 91% | Training loss: 0.6869025892408939
Epoch: 100 | Iteration number: [4140/4518] 91% | Training loss: 0.6869068862735361
Epoch: 100 | Iteration number: [4150/4518] 91% | Training loss: 0.6869068667543939
Epoch: 100 | Iteration number: [4160/4518] 92% | Training loss: 0.6869065633760049
Epoch: 100 | Iteration number: [4170/4518] 92% | Training loss: 0.6869046885189678
Epoch: 100 | Iteration number: [4180/4518] 92% | Training loss: 0.6869067493950921
Epoch: 100 | Iteration number: [4190/4518] 92% | Training loss: 0.6869027970372066
Epoch: 100 | Iteration number: [4200/4518] 92% | Training loss: 0.6869020348787308
Epoch: 100 | Iteration number: [4210/4518] 93% | Training loss: 0.686901644771286
Epoch: 100 | Iteration number: [4220/4518] 93% | Training loss: 0.6869014175441028
Epoch: 100 | Iteration number: [4230/4518] 93% | Training loss: 0.6869019978435327
Epoch: 100 | Iteration number: [4240/4518] 93% | Training loss: 0.6869047234362027
Epoch: 100 | Iteration number: [4250/4518] 94% | Training loss: 0.6869033244217143
Epoch: 100 | Iteration number: [4260/4518] 94% | Training loss: 0.6869011736531773
Epoch: 100 | Iteration number: [4270/4518] 94% | Training loss: 0.6869013010338821
Epoch: 100 | Iteration number: [4280/4518] 94% | Training loss: 0.6869025697774976
Epoch: 100 | Iteration number: [4290/4518] 94% | Training loss: 0.6869008352567544
Epoch: 100 | Iteration number: [4300/4518] 95% | Training loss: 0.6868980857521989
Epoch: 100 | Iteration number: [4310/4518] 95% | Training loss: 0.6868983463455519
Epoch: 100 | Iteration number: [4320/4518] 95% | Training loss: 0.6868982137491305
Epoch: 100 | Iteration number: [4330/4518] 95% | Training loss: 0.6868992405317672
Epoch: 100 | Iteration number: [4340/4518] 96% | Training loss: 0.6868977971890006
Epoch: 100 | Iteration number: [4350/4518] 96% | Training loss: 0.6868981278627768
Epoch: 100 | Iteration number: [4360/4518] 96% | Training loss: 0.686895804900095
Epoch: 100 | Iteration number: [4370/4518] 96% | Training loss: 0.6868954240730207
Epoch: 100 | Iteration number: [4380/4518] 96% | Training loss: 0.6868963986499125
Epoch: 100 | Iteration number: [4390/4518] 97% | Training loss: 0.6868965463920715
Epoch: 100 | Iteration number: [4400/4518] 97% | Training loss: 0.6868962127376687
Epoch: 100 | Iteration number: [4410/4518] 97% | Training loss: 0.6868989113101613
Epoch: 100 | Iteration number: [4420/4518] 97% | Training loss: 0.6869008835354542
Epoch: 100 | Iteration number: [4430/4518] 98% | Training loss: 0.6869005435880097
Epoch: 100 | Iteration number: [4440/4518] 98% | Training loss: 0.6868983958755528
Epoch: 100 | Iteration number: [4450/4518] 98% | Training loss: 0.6868963331586859
Epoch: 100 | Iteration number: [4460/4518] 98% | Training loss: 0.6868976676009696
Epoch: 100 | Iteration number: [4470/4518] 98% | Training loss: 0.686897999261583
Epoch: 100 | Iteration number: [4480/4518] 99% | Training loss: 0.6868940513714084
Epoch: 100 | Iteration number: [4490/4518] 99% | Training loss: 0.6868931616467728
Epoch: 100 | Iteration number: [4500/4518] 99% | Training loss: 0.6868931706481509
Epoch: 100 | Iteration number: [4510/4518] 99% | Training loss: 0.6868923846739623

 End of epoch: 100 | Train Loss: 0.6867422734862568 | Training Time: 634 

 End of epoch: 100 | Eval Loss: 0.6895420612121115 | Evaluating Time: 17 

 End of Test | Dice Loss: 0.9433226877450943 | Binary Cross Entropy With Logits Loss: 0.6899126887321472 
