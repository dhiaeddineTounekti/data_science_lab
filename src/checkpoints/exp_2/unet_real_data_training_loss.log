Epoch: 1 | Iteration number: [10/393] 2% | Training loss: 1.0519344329833984
Epoch: 1 | Iteration number: [20/393] 5% | Training loss: 0.9946383088827133
Epoch: 1 | Iteration number: [30/393] 7% | Training loss: 0.9714068293571472
Epoch: 1 | Iteration number: [40/393] 10% | Training loss: 0.9564869552850723
Epoch: 1 | Iteration number: [50/393] 12% | Training loss: 0.9440420293807983
Epoch: 1 | Iteration number: [60/393] 15% | Training loss: 0.9338538040717442
Epoch: 1 | Iteration number: [70/393] 17% | Training loss: 0.9248896130493709
Epoch: 1 | Iteration number: [80/393] 20% | Training loss: 0.9170789040625096
Epoch: 1 | Iteration number: [90/393] 22% | Training loss: 0.9104547593328688
Epoch: 1 | Iteration number: [100/393] 25% | Training loss: 0.9047264844179154
Epoch: 1 | Iteration number: [110/393] 27% | Training loss: 0.8999368131160737
Epoch: 1 | Iteration number: [120/393] 30% | Training loss: 0.89564019292593
Epoch: 1 | Iteration number: [130/393] 33% | Training loss: 0.8919433359916393
Epoch: 1 | Iteration number: [140/393] 35% | Training loss: 0.8889320139374052
Epoch: 1 | Iteration number: [150/393] 38% | Training loss: 0.8859736307462056
Epoch: 1 | Iteration number: [160/393] 40% | Training loss: 0.8832217387855053
Epoch: 1 | Iteration number: [170/393] 43% | Training loss: 0.8809021420338574
Epoch: 1 | Iteration number: [180/393] 45% | Training loss: 0.878634320696195
Epoch: 1 | Iteration number: [190/393] 48% | Training loss: 0.8765024069108461
Epoch: 1 | Iteration number: [200/393] 50% | Training loss: 0.8744658985733986
Epoch: 1 | Iteration number: [210/393] 53% | Training loss: 0.8725824671132224
Epoch: 1 | Iteration number: [220/393] 55% | Training loss: 0.8708420710130171
Epoch: 1 | Iteration number: [230/393] 58% | Training loss: 0.8691798461520154
Epoch: 1 | Iteration number: [240/393] 61% | Training loss: 0.8676562957465649
Epoch: 1 | Iteration number: [250/393] 63% | Training loss: 0.8661296701431275
Epoch: 1 | Iteration number: [260/393] 66% | Training loss: 0.8646911820540062
Epoch: 1 | Iteration number: [270/393] 68% | Training loss: 0.8633177843358781
Epoch: 1 | Iteration number: [280/393] 71% | Training loss: 0.8619408933179719
Epoch: 1 | Iteration number: [290/393] 73% | Training loss: 0.8605693552000769
Epoch: 1 | Iteration number: [300/393] 76% | Training loss: 0.8592011086146036
Epoch: 1 | Iteration number: [310/393] 78% | Training loss: 0.8580231872297103
Epoch: 1 | Iteration number: [320/393] 81% | Training loss: 0.8568435190245509
Epoch: 1 | Iteration number: [330/393] 83% | Training loss: 0.8557027984749187
Epoch: 1 | Iteration number: [340/393] 86% | Training loss: 0.8546061365043416
Epoch: 1 | Iteration number: [350/393] 89% | Training loss: 0.8535178063596998
Epoch: 1 | Iteration number: [360/393] 91% | Training loss: 0.8524122955070601
Epoch: 1 | Iteration number: [370/393] 94% | Training loss: 0.8513850980513805
Epoch: 1 | Iteration number: [380/393] 96% | Training loss: 0.850358226738478
Epoch: 1 | Iteration number: [390/393] 99% | Training loss: 0.8493535949633672

 End of epoch: 1 | Train Loss: 0.8469762328926843 | Training Time: 70 

 End of epoch: 1 | Eval Loss: 0.809404443721382 | Evaluating Time: 18 
Epoch: 2 | Iteration number: [10/393] 2% | Training loss: 0.892307311296463
Epoch: 2 | Iteration number: [20/393] 5% | Training loss: 0.850909760594368
Epoch: 2 | Iteration number: [30/393] 7% | Training loss: 0.8362642149130504
Epoch: 2 | Iteration number: [40/393] 10% | Training loss: 0.8290404424071312
Epoch: 2 | Iteration number: [50/393] 12% | Training loss: 0.8240762889385224
Epoch: 2 | Iteration number: [60/393] 15% | Training loss: 0.8207580099503199
Epoch: 2 | Iteration number: [70/393] 17% | Training loss: 0.818114480801991
Epoch: 2 | Iteration number: [80/393] 20% | Training loss: 0.8158091768622399
Epoch: 2 | Iteration number: [90/393] 22% | Training loss: 0.8141455160246955
Epoch: 2 | Iteration number: [100/393] 25% | Training loss: 0.8126667386293411
Epoch: 2 | Iteration number: [110/393] 27% | Training loss: 0.8113047020001845
Epoch: 2 | Iteration number: [120/393] 30% | Training loss: 0.810147832830747
Epoch: 2 | Iteration number: [130/393] 33% | Training loss: 0.8089838032539074
Epoch: 2 | Iteration number: [140/393] 35% | Training loss: 0.8079955424581255
Epoch: 2 | Iteration number: [150/393] 38% | Training loss: 0.8070441512266795
Epoch: 2 | Iteration number: [160/393] 40% | Training loss: 0.8061750259250402
Epoch: 2 | Iteration number: [170/393] 43% | Training loss: 0.8054451146546532
Epoch: 2 | Iteration number: [180/393] 45% | Training loss: 0.8046274254719417
Epoch: 2 | Iteration number: [190/393] 48% | Training loss: 0.8037468144768163
Epoch: 2 | Iteration number: [200/393] 50% | Training loss: 0.8030052345991134
Epoch: 2 | Iteration number: [210/393] 53% | Training loss: 0.802269123565583
Epoch: 2 | Iteration number: [220/393] 55% | Training loss: 0.8015782017599452
Epoch: 2 | Iteration number: [230/393] 58% | Training loss: 0.8009307814681011
Epoch: 2 | Iteration number: [240/393] 61% | Training loss: 0.8003212280571461
Epoch: 2 | Iteration number: [250/393] 63% | Training loss: 0.7996766803264618
Epoch: 2 | Iteration number: [260/393] 66% | Training loss: 0.7989896547335845
Epoch: 2 | Iteration number: [270/393] 68% | Training loss: 0.7983931826220618
Epoch: 2 | Iteration number: [280/393] 71% | Training loss: 0.7977811789938382
Epoch: 2 | Iteration number: [290/393] 73% | Training loss: 0.797154768582048
Epoch: 2 | Iteration number: [300/393] 76% | Training loss: 0.7965450624624888
Epoch: 2 | Iteration number: [310/393] 78% | Training loss: 0.7959332527652864
Epoch: 2 | Iteration number: [320/393] 81% | Training loss: 0.7954188754782081
Epoch: 2 | Iteration number: [330/393] 83% | Training loss: 0.7948935436479974
Epoch: 2 | Iteration number: [340/393] 86% | Training loss: 0.7942955141558367
Epoch: 2 | Iteration number: [350/393] 89% | Training loss: 0.7937441498892648
Epoch: 2 | Iteration number: [360/393] 91% | Training loss: 0.7932109594345093
Epoch: 2 | Iteration number: [370/393] 94% | Training loss: 0.7927050455196484
Epoch: 2 | Iteration number: [380/393] 96% | Training loss: 0.7922428584412524
Epoch: 2 | Iteration number: [390/393] 99% | Training loss: 0.7917229901521634

 End of epoch: 2 | Train Loss: 0.7895908815260152 | Training Time: 67 

 End of epoch: 2 | Eval Loss: 0.773376601082938 | Evaluating Time: 17 
Epoch: 3 | Iteration number: [10/393] 2% | Training loss: 0.8479364812374115
Epoch: 3 | Iteration number: [20/393] 5% | Training loss: 0.808938005566597
Epoch: 3 | Iteration number: [30/393] 7% | Training loss: 0.7960866570472718
Epoch: 3 | Iteration number: [40/393] 10% | Training loss: 0.7888411790132522
Epoch: 3 | Iteration number: [50/393] 12% | Training loss: 0.7848136377334595
Epoch: 3 | Iteration number: [60/393] 15% | Training loss: 0.7819175849358241
Epoch: 3 | Iteration number: [70/393] 17% | Training loss: 0.7798413157463073
Epoch: 3 | Iteration number: [80/393] 20% | Training loss: 0.7780048027634621
Epoch: 3 | Iteration number: [90/393] 22% | Training loss: 0.7763696743382348
Epoch: 3 | Iteration number: [100/393] 25% | Training loss: 0.7751460111141205
Epoch: 3 | Iteration number: [110/393] 27% | Training loss: 0.7740632403980602
Epoch: 3 | Iteration number: [120/393] 30% | Training loss: 0.7730328013499578
Epoch: 3 | Iteration number: [130/393] 33% | Training loss: 0.772124522465926
Epoch: 3 | Iteration number: [140/393] 35% | Training loss: 0.7713500039918082
Epoch: 3 | Iteration number: [150/393] 38% | Training loss: 0.7706645683447519
Epoch: 3 | Iteration number: [160/393] 40% | Training loss: 0.7699442069977522
Epoch: 3 | Iteration number: [170/393] 43% | Training loss: 0.769268811450285
Epoch: 3 | Iteration number: [180/393] 45% | Training loss: 0.76869542102019
Epoch: 3 | Iteration number: [190/393] 48% | Training loss: 0.7681388246385674
Epoch: 3 | Iteration number: [200/393] 50% | Training loss: 0.7676707279682159
Epoch: 3 | Iteration number: [210/393] 53% | Training loss: 0.7671565887473878
Epoch: 3 | Iteration number: [220/393] 55% | Training loss: 0.766673386909745
Epoch: 3 | Iteration number: [230/393] 58% | Training loss: 0.7662314427935559
Epoch: 3 | Iteration number: [240/393] 61% | Training loss: 0.7657776204248269
Epoch: 3 | Iteration number: [250/393] 63% | Training loss: 0.7652747128009796
Epoch: 3 | Iteration number: [260/393] 66% | Training loss: 0.7647809033210461
Epoch: 3 | Iteration number: [270/393] 68% | Training loss: 0.7643197602695889
Epoch: 3 | Iteration number: [280/393] 71% | Training loss: 0.7638679910983358
Epoch: 3 | Iteration number: [290/393] 73% | Training loss: 0.7634326309993349
Epoch: 3 | Iteration number: [300/393] 76% | Training loss: 0.7630185333887736
Epoch: 3 | Iteration number: [310/393] 78% | Training loss: 0.7626013398170471
Epoch: 3 | Iteration number: [320/393] 81% | Training loss: 0.7621666984632611
Epoch: 3 | Iteration number: [330/393] 83% | Training loss: 0.7617773646658117
Epoch: 3 | Iteration number: [340/393] 86% | Training loss: 0.7613560397835338
Epoch: 3 | Iteration number: [350/393] 89% | Training loss: 0.7609688651561737
Epoch: 3 | Iteration number: [360/393] 91% | Training loss: 0.7605554834008217
Epoch: 3 | Iteration number: [370/393] 94% | Training loss: 0.7601830139353468
Epoch: 3 | Iteration number: [380/393] 96% | Training loss: 0.75981964468956
Epoch: 3 | Iteration number: [390/393] 99% | Training loss: 0.7594002651862609

 End of epoch: 3 | Train Loss: 0.7573942507192986 | Training Time: 68 

 End of epoch: 3 | Eval Loss: 0.7496098340774069 | Evaluating Time: 17 
Epoch: 4 | Iteration number: [10/393] 2% | Training loss: 0.8185414612293244
Epoch: 4 | Iteration number: [20/393] 5% | Training loss: 0.7811914384365082
Epoch: 4 | Iteration number: [30/393] 7% | Training loss: 0.7691797852516175
Epoch: 4 | Iteration number: [40/393] 10% | Training loss: 0.7629826247692109
Epoch: 4 | Iteration number: [50/393] 12% | Training loss: 0.7589883697032929
Epoch: 4 | Iteration number: [60/393] 15% | Training loss: 0.7562930951515834
Epoch: 4 | Iteration number: [70/393] 17% | Training loss: 0.7541544786521367
Epoch: 4 | Iteration number: [80/393] 20% | Training loss: 0.7525156378746033
Epoch: 4 | Iteration number: [90/393] 22% | Training loss: 0.751077514886856
Epoch: 4 | Iteration number: [100/393] 25% | Training loss: 0.7499999922513961
Epoch: 4 | Iteration number: [110/393] 27% | Training loss: 0.74901817928661
Epoch: 4 | Iteration number: [120/393] 30% | Training loss: 0.7482194915413857
Epoch: 4 | Iteration number: [130/393] 33% | Training loss: 0.7474461138248444
Epoch: 4 | Iteration number: [140/393] 35% | Training loss: 0.746791946036475
Epoch: 4 | Iteration number: [150/393] 38% | Training loss: 0.7461371064186096
Epoch: 4 | Iteration number: [160/393] 40% | Training loss: 0.7455541275441646
Epoch: 4 | Iteration number: [170/393] 43% | Training loss: 0.7450352146345026
Epoch: 4 | Iteration number: [180/393] 45% | Training loss: 0.7445762213733461
Epoch: 4 | Iteration number: [190/393] 48% | Training loss: 0.7442819861989273
Epoch: 4 | Iteration number: [200/393] 50% | Training loss: 0.7439189940690994
Epoch: 4 | Iteration number: [210/393] 53% | Training loss: 0.7435626892816453
Epoch: 4 | Iteration number: [220/393] 55% | Training loss: 0.7431465793739666
Epoch: 4 | Iteration number: [230/393] 58% | Training loss: 0.7427482314731764
Epoch: 4 | Iteration number: [240/393] 61% | Training loss: 0.7423902268211047
Epoch: 4 | Iteration number: [250/393] 63% | Training loss: 0.7420344204902649
Epoch: 4 | Iteration number: [260/393] 66% | Training loss: 0.7417108120826574
Epoch: 4 | Iteration number: [270/393] 68% | Training loss: 0.7413851378140626
Epoch: 4 | Iteration number: [280/393] 71% | Training loss: 0.7410296120813915
Epoch: 4 | Iteration number: [290/393] 73% | Training loss: 0.74071785519863
Epoch: 4 | Iteration number: [300/393] 76% | Training loss: 0.7404175595442454
Epoch: 4 | Iteration number: [310/393] 78% | Training loss: 0.7401433638988003
Epoch: 4 | Iteration number: [320/393] 81% | Training loss: 0.7398847164586186
Epoch: 4 | Iteration number: [330/393] 83% | Training loss: 0.7395965066823093
Epoch: 4 | Iteration number: [340/393] 86% | Training loss: 0.73932845732745
Epoch: 4 | Iteration number: [350/393] 89% | Training loss: 0.7390608436720711
Epoch: 4 | Iteration number: [360/393] 91% | Training loss: 0.7387912049889565
Epoch: 4 | Iteration number: [370/393] 94% | Training loss: 0.7385207530614492
Epoch: 4 | Iteration number: [380/393] 96% | Training loss: 0.7382983783358021
Epoch: 4 | Iteration number: [390/393] 99% | Training loss: 0.7380387827371939

 End of epoch: 4 | Train Loss: 0.7361079939752438 | Training Time: 68 

 End of epoch: 4 | Eval Loss: 0.7291641563785319 | Evaluating Time: 18 
Epoch: 5 | Iteration number: [10/393] 2% | Training loss: 0.7997729301452636
Epoch: 5 | Iteration number: [20/393] 5% | Training loss: 0.7639493733644486
Epoch: 5 | Iteration number: [30/393] 7% | Training loss: 0.7519393662611643
Epoch: 5 | Iteration number: [40/393] 10% | Training loss: 0.7454980552196503
Epoch: 5 | Iteration number: [50/393] 12% | Training loss: 0.7416713404655456
Epoch: 5 | Iteration number: [60/393] 15% | Training loss: 0.7391030748685201
Epoch: 5 | Iteration number: [70/393] 17% | Training loss: 0.7372428042548044
Epoch: 5 | Iteration number: [80/393] 20% | Training loss: 0.7357130937278271
Epoch: 5 | Iteration number: [90/393] 22% | Training loss: 0.7344972762796614
Epoch: 5 | Iteration number: [100/393] 25% | Training loss: 0.7335301041603088
Epoch: 5 | Iteration number: [110/393] 27% | Training loss: 0.7329879202625968
Epoch: 5 | Iteration number: [120/393] 30% | Training loss: 0.7329720745484034
Epoch: 5 | Iteration number: [130/393] 33% | Training loss: 0.7325262152231656
Epoch: 5 | Iteration number: [140/393] 35% | Training loss: 0.7320458676133837
Epoch: 5 | Iteration number: [150/393] 38% | Training loss: 0.7315595165888469
Epoch: 5 | Iteration number: [160/393] 40% | Training loss: 0.7311117392033338
Epoch: 5 | Iteration number: [170/393] 43% | Training loss: 0.7307905768646913
Epoch: 5 | Iteration number: [180/393] 45% | Training loss: 0.7304376463095347
Epoch: 5 | Iteration number: [190/393] 48% | Training loss: 0.7301472218413102
Epoch: 5 | Iteration number: [200/393] 50% | Training loss: 0.729826717376709
Epoch: 5 | Iteration number: [210/393] 53% | Training loss: 0.7294577828475407
Epoch: 5 | Iteration number: [220/393] 55% | Training loss: 0.7291770146651702
Epoch: 5 | Iteration number: [230/393] 58% | Training loss: 0.7288597474927487
Epoch: 5 | Iteration number: [240/393] 61% | Training loss: 0.7285716481506824
Epoch: 5 | Iteration number: [250/393] 63% | Training loss: 0.7282086043357849
Epoch: 5 | Iteration number: [260/393] 66% | Training loss: 0.7279332754703668
Epoch: 5 | Iteration number: [270/393] 68% | Training loss: 0.727631844414605
Epoch: 5 | Iteration number: [280/393] 71% | Training loss: 0.7273872045533998
Epoch: 5 | Iteration number: [290/393] 73% | Training loss: 0.7271484054368118
Epoch: 5 | Iteration number: [300/393] 76% | Training loss: 0.7269221379359563
Epoch: 5 | Iteration number: [310/393] 78% | Training loss: 0.7267136927573912
Epoch: 5 | Iteration number: [320/393] 81% | Training loss: 0.7264791432768106
Epoch: 5 | Iteration number: [330/393] 83% | Training loss: 0.7262458530339327
Epoch: 5 | Iteration number: [340/393] 86% | Training loss: 0.7260349263163174
Epoch: 5 | Iteration number: [350/393] 89% | Training loss: 0.7258276607309069
Epoch: 5 | Iteration number: [360/393] 91% | Training loss: 0.7256190665894084
Epoch: 5 | Iteration number: [370/393] 94% | Training loss: 0.7254042802630244
Epoch: 5 | Iteration number: [380/393] 96% | Training loss: 0.7251906951791361
Epoch: 5 | Iteration number: [390/393] 99% | Training loss: 0.7250037491321564

 End of epoch: 5 | Train Loss: 0.7231208131513522 | Training Time: 67 

 End of epoch: 5 | Eval Loss: 0.7166374629857589 | Evaluating Time: 18 
Epoch: 6 | Iteration number: [10/393] 2% | Training loss: 0.7887796044349671
Epoch: 6 | Iteration number: [20/393] 5% | Training loss: 0.7536489993333817
Epoch: 6 | Iteration number: [30/393] 7% | Training loss: 0.7408140301704407
Epoch: 6 | Iteration number: [40/393] 10% | Training loss: 0.7349723890423775
Epoch: 6 | Iteration number: [50/393] 12% | Training loss: 0.7314881014823914
Epoch: 6 | Iteration number: [60/393] 15% | Training loss: 0.7288577993710835
Epoch: 6 | Iteration number: [70/393] 17% | Training loss: 0.7270872209753309
Epoch: 6 | Iteration number: [80/393] 20% | Training loss: 0.7255167409777641
Epoch: 6 | Iteration number: [90/393] 22% | Training loss: 0.7245140916771359
Epoch: 6 | Iteration number: [100/393] 25% | Training loss: 0.7237174588441849
Epoch: 6 | Iteration number: [110/393] 27% | Training loss: 0.7230023394931446
Epoch: 6 | Iteration number: [120/393] 30% | Training loss: 0.7223604083061218
Epoch: 6 | Iteration number: [130/393] 33% | Training loss: 0.7218114266028771
Epoch: 6 | Iteration number: [140/393] 35% | Training loss: 0.7213924275977271
Epoch: 6 | Iteration number: [150/393] 38% | Training loss: 0.7209564594427744
Epoch: 6 | Iteration number: [160/393] 40% | Training loss: 0.7204600151628255
Epoch: 6 | Iteration number: [170/393] 43% | Training loss: 0.7200365171712988
Epoch: 6 | Iteration number: [180/393] 45% | Training loss: 0.7196223153008355
Epoch: 6 | Iteration number: [190/393] 48% | Training loss: 0.7193953093729522
Epoch: 6 | Iteration number: [200/393] 50% | Training loss: 0.7191086223721505
Epoch: 6 | Iteration number: [210/393] 53% | Training loss: 0.7188118383997962
Epoch: 6 | Iteration number: [220/393] 55% | Training loss: 0.7184895106337287
Epoch: 6 | Iteration number: [230/393] 58% | Training loss: 0.718244213902432
Epoch: 6 | Iteration number: [240/393] 61% | Training loss: 0.7179489053785801
Epoch: 6 | Iteration number: [250/393] 63% | Training loss: 0.7177534821033478
Epoch: 6 | Iteration number: [260/393] 66% | Training loss: 0.717520047380374
Epoch: 6 | Iteration number: [270/393] 68% | Training loss: 0.7173467777393482
Epoch: 6 | Iteration number: [280/393] 71% | Training loss: 0.7170992263725826
Epoch: 6 | Iteration number: [290/393] 73% | Training loss: 0.7169201121248048
Epoch: 6 | Iteration number: [300/393] 76% | Training loss: 0.7167052302757899
Epoch: 6 | Iteration number: [310/393] 78% | Training loss: 0.7165400960753041
Epoch: 6 | Iteration number: [320/393] 81% | Training loss: 0.7163855211809278
Epoch: 6 | Iteration number: [330/393] 83% | Training loss: 0.7162483954068386
Epoch: 6 | Iteration number: [340/393] 86% | Training loss: 0.7160578440217411
Epoch: 6 | Iteration number: [350/393] 89% | Training loss: 0.7159176986558097
Epoch: 6 | Iteration number: [360/393] 91% | Training loss: 0.7157659144865142
Epoch: 6 | Iteration number: [370/393] 94% | Training loss: 0.7156155235058552
Epoch: 6 | Iteration number: [380/393] 96% | Training loss: 0.7154977953747699
Epoch: 6 | Iteration number: [390/393] 99% | Training loss: 0.7153385863854335

 End of epoch: 6 | Train Loss: 0.7135024568203449 | Training Time: 68 

 End of epoch: 6 | Eval Loss: 0.7096613511747244 | Evaluating Time: 17 
Epoch: 7 | Iteration number: [10/393] 2% | Training loss: 0.7809293866157532
Epoch: 7 | Iteration number: [20/393] 5% | Training loss: 0.7456102669239044
Epoch: 7 | Iteration number: [30/393] 7% | Training loss: 0.7336372971534729
Epoch: 7 | Iteration number: [40/393] 10% | Training loss: 0.7276396930217743
Epoch: 7 | Iteration number: [50/393] 12% | Training loss: 0.7240735840797424
Epoch: 7 | Iteration number: [60/393] 15% | Training loss: 0.7214745610952378
Epoch: 7 | Iteration number: [70/393] 17% | Training loss: 0.7197971905980791
Epoch: 7 | Iteration number: [80/393] 20% | Training loss: 0.7184735670685768
Epoch: 7 | Iteration number: [90/393] 22% | Training loss: 0.7174252019988165
Epoch: 7 | Iteration number: [100/393] 25% | Training loss: 0.7165577286481857
Epoch: 7 | Iteration number: [110/393] 27% | Training loss: 0.7159209370613098
Epoch: 7 | Iteration number: [120/393] 30% | Training loss: 0.7153045763572057
Epoch: 7 | Iteration number: [130/393] 33% | Training loss: 0.7146899961508237
Epoch: 7 | Iteration number: [140/393] 35% | Training loss: 0.7141949419464384
Epoch: 7 | Iteration number: [150/393] 38% | Training loss: 0.7138316098848979
Epoch: 7 | Iteration number: [160/393] 40% | Training loss: 0.7135026782751084
Epoch: 7 | Iteration number: [170/393] 43% | Training loss: 0.7131767195813796
Epoch: 7 | Iteration number: [180/393] 45% | Training loss: 0.7129465414418115
Epoch: 7 | Iteration number: [190/393] 48% | Training loss: 0.7126270585938503
Epoch: 7 | Iteration number: [200/393] 50% | Training loss: 0.7123337778449058
Epoch: 7 | Iteration number: [210/393] 53% | Training loss: 0.7120794117450714
Epoch: 7 | Iteration number: [220/393] 55% | Training loss: 0.7118810726837679
Epoch: 7 | Iteration number: [230/393] 58% | Training loss: 0.71165229678154
Epoch: 7 | Iteration number: [240/393] 61% | Training loss: 0.7115018342932066
Epoch: 7 | Iteration number: [250/393] 63% | Training loss: 0.711288314819336
Epoch: 7 | Iteration number: [260/393] 66% | Training loss: 0.7110801662390048
Epoch: 7 | Iteration number: [270/393] 68% | Training loss: 0.7109023992662077
Epoch: 7 | Iteration number: [280/393] 71% | Training loss: 0.7107224871005331
Epoch: 7 | Iteration number: [290/393] 73% | Training loss: 0.7105611328420968
Epoch: 7 | Iteration number: [300/393] 76% | Training loss: 0.7104405748844147
Epoch: 7 | Iteration number: [310/393] 78% | Training loss: 0.7102642130467199
Epoch: 7 | Iteration number: [320/393] 81% | Training loss: 0.7101617027074099
Epoch: 7 | Iteration number: [330/393] 83% | Training loss: 0.710019294240258
Epoch: 7 | Iteration number: [340/393] 86% | Training loss: 0.709881738354178
Epoch: 7 | Iteration number: [350/393] 89% | Training loss: 0.7097651817117419
Epoch: 7 | Iteration number: [360/393] 91% | Training loss: 0.7096548471185896
Epoch: 7 | Iteration number: [370/393] 94% | Training loss: 0.7095027731882559
Epoch: 7 | Iteration number: [380/393] 96% | Training loss: 0.7093914118252302
Epoch: 7 | Iteration number: [390/393] 99% | Training loss: 0.7092756385986622

 End of epoch: 7 | Train Loss: 0.7074488772994083 | Training Time: 69 

 End of epoch: 7 | Eval Loss: 0.7045707070097631 | Evaluating Time: 22 
Epoch: 8 | Iteration number: [10/393] 2% | Training loss: 0.7758357703685761
Epoch: 8 | Iteration number: [20/393] 5% | Training loss: 0.7410125523805619
Epoch: 8 | Iteration number: [30/393] 7% | Training loss: 0.7293591638406117
Epoch: 8 | Iteration number: [40/393] 10% | Training loss: 0.7235852211713791
Epoch: 8 | Iteration number: [50/393] 12% | Training loss: 0.7199533033370972
Epoch: 8 | Iteration number: [60/393] 15% | Training loss: 0.717409873008728
Epoch: 8 | Iteration number: [70/393] 17% | Training loss: 0.7154585676533836
Epoch: 8 | Iteration number: [80/393] 20% | Training loss: 0.7141566693782806
Epoch: 8 | Iteration number: [90/393] 22% | Training loss: 0.71316240562333
Epoch: 8 | Iteration number: [100/393] 25% | Training loss: 0.7122095227241516
Epoch: 8 | Iteration number: [110/393] 27% | Training loss: 0.711435489762913
Epoch: 8 | Iteration number: [120/393] 30% | Training loss: 0.7108306750655174
Epoch: 8 | Iteration number: [130/393] 33% | Training loss: 0.7103151160937089
Epoch: 8 | Iteration number: [140/393] 35% | Training loss: 0.7097872516938618
Epoch: 8 | Iteration number: [150/393] 38% | Training loss: 0.7092897562185924
Epoch: 8 | Iteration number: [160/393] 40% | Training loss: 0.7088782984763384
Epoch: 8 | Iteration number: [170/393] 43% | Training loss: 0.7085605684448691
Epoch: 8 | Iteration number: [180/393] 45% | Training loss: 0.7082468026214176
Epoch: 8 | Iteration number: [190/393] 48% | Training loss: 0.7079344310258564
Epoch: 8 | Iteration number: [200/393] 50% | Training loss: 0.7076590144634247
Epoch: 8 | Iteration number: [210/393] 53% | Training loss: 0.7074295693919772
Epoch: 8 | Iteration number: [220/393] 55% | Training loss: 0.7071921670978719
Epoch: 8 | Iteration number: [230/393] 58% | Training loss: 0.707025267507719
Epoch: 8 | Iteration number: [240/393] 61% | Training loss: 0.7069317234059175
Epoch: 8 | Iteration number: [250/393] 63% | Training loss: 0.7068418505191802
Epoch: 8 | Iteration number: [260/393] 66% | Training loss: 0.7067484832726992
Epoch: 8 | Iteration number: [270/393] 68% | Training loss: 0.7066097526638596
Epoch: 8 | Iteration number: [280/393] 71% | Training loss: 0.7064818701573781
Epoch: 8 | Iteration number: [290/393] 73% | Training loss: 0.7063591404207822
Epoch: 8 | Iteration number: [300/393] 76% | Training loss: 0.7062461870908737
Epoch: 8 | Iteration number: [310/393] 78% | Training loss: 0.7061096762457202
Epoch: 8 | Iteration number: [320/393] 81% | Training loss: 0.7060091806575656
Epoch: 8 | Iteration number: [330/393] 83% | Training loss: 0.705895297274445
Epoch: 8 | Iteration number: [340/393] 86% | Training loss: 0.7057916367755217
Epoch: 8 | Iteration number: [350/393] 89% | Training loss: 0.7056772538593837
Epoch: 8 | Iteration number: [360/393] 91% | Training loss: 0.7055932114521662
Epoch: 8 | Iteration number: [370/393] 94% | Training loss: 0.7054598113975009
Epoch: 8 | Iteration number: [380/393] 96% | Training loss: 0.7053610738955046
Epoch: 8 | Iteration number: [390/393] 99% | Training loss: 0.7052643418312072

 End of epoch: 8 | Train Loss: 0.7034472704843711 | Training Time: 67 

 End of epoch: 8 | Eval Loss: 0.7010923770009255 | Evaluating Time: 17 
Epoch: 9 | Iteration number: [10/393] 2% | Training loss: 0.7718665301799774
Epoch: 9 | Iteration number: [20/393] 5% | Training loss: 0.7367824971675873
Epoch: 9 | Iteration number: [30/393] 7% | Training loss: 0.7247820516427358
Epoch: 9 | Iteration number: [40/393] 10% | Training loss: 0.7185834959149361
Epoch: 9 | Iteration number: [50/393] 12% | Training loss: 0.7152845847606659
Epoch: 9 | Iteration number: [60/393] 15% | Training loss: 0.7127126187086106
Epoch: 9 | Iteration number: [70/393] 17% | Training loss: 0.7110182694026402
Epoch: 9 | Iteration number: [80/393] 20% | Training loss: 0.7098166510462761
Epoch: 9 | Iteration number: [90/393] 22% | Training loss: 0.7088002893659804
Epoch: 9 | Iteration number: [100/393] 25% | Training loss: 0.7079910802841186
Epoch: 9 | Iteration number: [110/393] 27% | Training loss: 0.7072085662321611
Epoch: 9 | Iteration number: [120/393] 30% | Training loss: 0.7067181870341301
Epoch: 9 | Iteration number: [130/393] 33% | Training loss: 0.7064624080291161
Epoch: 9 | Iteration number: [140/393] 35% | Training loss: 0.7061915831906455
Epoch: 9 | Iteration number: [150/393] 38% | Training loss: 0.7058964864412943
Epoch: 9 | Iteration number: [160/393] 40% | Training loss: 0.7055638395249844
Epoch: 9 | Iteration number: [170/393] 43% | Training loss: 0.7052567180465249
Epoch: 9 | Iteration number: [180/393] 45% | Training loss: 0.7049898289971881
Epoch: 9 | Iteration number: [190/393] 48% | Training loss: 0.7047662474607167
Epoch: 9 | Iteration number: [200/393] 50% | Training loss: 0.7045213761925697
Epoch: 9 | Iteration number: [210/393] 53% | Training loss: 0.7043150893279484
Epoch: 9 | Iteration number: [220/393] 55% | Training loss: 0.7041173577308655
Epoch: 9 | Iteration number: [230/393] 58% | Training loss: 0.7039343717305556
Epoch: 9 | Iteration number: [240/393] 61% | Training loss: 0.7037828676402569
Epoch: 9 | Iteration number: [250/393] 63% | Training loss: 0.7036270802021026
Epoch: 9 | Iteration number: [260/393] 66% | Training loss: 0.7035200900756395
Epoch: 9 | Iteration number: [270/393] 68% | Training loss: 0.7034246029677215
Epoch: 9 | Iteration number: [280/393] 71% | Training loss: 0.7032941022089549
Epoch: 9 | Iteration number: [290/393] 73% | Training loss: 0.7031802387073123
Epoch: 9 | Iteration number: [300/393] 76% | Training loss: 0.7030936801433563
Epoch: 9 | Iteration number: [310/393] 78% | Training loss: 0.7029678573531489
Epoch: 9 | Iteration number: [320/393] 81% | Training loss: 0.702862293459475
Epoch: 9 | Iteration number: [330/393] 83% | Training loss: 0.7027295885664044
Epoch: 9 | Iteration number: [340/393] 86% | Training loss: 0.7026595131439322
Epoch: 9 | Iteration number: [350/393] 89% | Training loss: 0.7025459665911539
Epoch: 9 | Iteration number: [360/393] 91% | Training loss: 0.7024297083417574
Epoch: 9 | Iteration number: [370/393] 94% | Training loss: 0.7023566075273462
Epoch: 9 | Iteration number: [380/393] 96% | Training loss: 0.7022766444243883
Epoch: 9 | Iteration number: [390/393] 99% | Training loss: 0.7022099554538727

 End of epoch: 9 | Train Loss: 0.7004191961907248 | Training Time: 68 

 End of epoch: 9 | Eval Loss: 0.6988963934839988 | Evaluating Time: 17 
Epoch: 10 | Iteration number: [10/393] 2% | Training loss: 0.7686510801315307
Epoch: 10 | Iteration number: [20/393] 5% | Training loss: 0.734438705444336
Epoch: 10 | Iteration number: [30/393] 7% | Training loss: 0.72286350329717
Epoch: 10 | Iteration number: [40/393] 10% | Training loss: 0.7171202331781388
Epoch: 10 | Iteration number: [50/393] 12% | Training loss: 0.7135638856887817
Epoch: 10 | Iteration number: [60/393] 15% | Training loss: 0.71126702328523
Epoch: 10 | Iteration number: [70/393] 17% | Training loss: 0.7095544397830963
Epoch: 10 | Iteration number: [80/393] 20% | Training loss: 0.7082269705832005
Epoch: 10 | Iteration number: [90/393] 22% | Training loss: 0.7072115202744802
Epoch: 10 | Iteration number: [100/393] 25% | Training loss: 0.7063629567623139
Epoch: 10 | Iteration number: [110/393] 27% | Training loss: 0.7056903600692749
Epoch: 10 | Iteration number: [120/393] 30% | Training loss: 0.7051457484563192
Epoch: 10 | Iteration number: [130/393] 33% | Training loss: 0.7046712072995993
Epoch: 10 | Iteration number: [140/393] 35% | Training loss: 0.7043013070310865
Epoch: 10 | Iteration number: [150/393] 38% | Training loss: 0.7039319992065429
Epoch: 10 | Iteration number: [160/393] 40% | Training loss: 0.7035298869013786
Epoch: 10 | Iteration number: [170/393] 43% | Training loss: 0.7032166523091933
Epoch: 10 | Iteration number: [180/393] 45% | Training loss: 0.7029505021042294
Epoch: 10 | Iteration number: [190/393] 48% | Training loss: 0.7026713835565668
Epoch: 10 | Iteration number: [200/393] 50% | Training loss: 0.7023865148425102
Epoch: 10 | Iteration number: [210/393] 53% | Training loss: 0.7021915467012496
Epoch: 10 | Iteration number: [220/393] 55% | Training loss: 0.7020087177103216
Epoch: 10 | Iteration number: [230/393] 58% | Training loss: 0.7018173412136409
Epoch: 10 | Iteration number: [240/393] 61% | Training loss: 0.7016690500080586
Epoch: 10 | Iteration number: [250/393] 63% | Training loss: 0.7015431363582612
Epoch: 10 | Iteration number: [260/393] 66% | Training loss: 0.7014014484790655
Epoch: 10 | Iteration number: [270/393] 68% | Training loss: 0.7012300241876531
Epoch: 10 | Iteration number: [280/393] 71% | Training loss: 0.7010641300252506
Epoch: 10 | Iteration number: [290/393] 73% | Training loss: 0.7009660328256673
Epoch: 10 | Iteration number: [300/393] 76% | Training loss: 0.7008123594522476
Epoch: 10 | Iteration number: [310/393] 78% | Training loss: 0.7007081708600444
Epoch: 10 | Iteration number: [320/393] 81% | Training loss: 0.7006305830553174
Epoch: 10 | Iteration number: [330/393] 83% | Training loss: 0.7005895788019354
Epoch: 10 | Iteration number: [340/393] 86% | Training loss: 0.700507504624479
Epoch: 10 | Iteration number: [350/393] 89% | Training loss: 0.700438175201416
Epoch: 10 | Iteration number: [360/393] 91% | Training loss: 0.7003593709733751
Epoch: 10 | Iteration number: [370/393] 94% | Training loss: 0.7002940983385653
Epoch: 10 | Iteration number: [380/393] 96% | Training loss: 0.7002527428300758
Epoch: 10 | Iteration number: [390/393] 99% | Training loss: 0.7001929614788447

 End of epoch: 10 | Train Loss: 0.6984138396253416 | Training Time: 68 

 End of epoch: 10 | Eval Loss: 0.6985653711825001 | Evaluating Time: 17 
Epoch: 11 | Iteration number: [10/393] 2% | Training loss: 0.7668340384960175
Epoch: 11 | Iteration number: [20/393] 5% | Training loss: 0.7327968209981919
Epoch: 11 | Iteration number: [30/393] 7% | Training loss: 0.7211312333742778
Epoch: 11 | Iteration number: [40/393] 10% | Training loss: 0.7153101935982704
Epoch: 11 | Iteration number: [50/393] 12% | Training loss: 0.7116500806808471
Epoch: 11 | Iteration number: [60/393] 15% | Training loss: 0.709211481610934
Epoch: 11 | Iteration number: [70/393] 17% | Training loss: 0.707539325101035
Epoch: 11 | Iteration number: [80/393] 20% | Training loss: 0.7062409512698651
Epoch: 11 | Iteration number: [90/393] 22% | Training loss: 0.7052316943804423
Epoch: 11 | Iteration number: [100/393] 25% | Training loss: 0.7043279951810837
Epoch: 11 | Iteration number: [110/393] 27% | Training loss: 0.7036328673362732
Epoch: 11 | Iteration number: [120/393] 30% | Training loss: 0.7031489620606105
Epoch: 11 | Iteration number: [130/393] 33% | Training loss: 0.7027141561874977
Epoch: 11 | Iteration number: [140/393] 35% | Training loss: 0.7023096420935222
Epoch: 11 | Iteration number: [150/393] 38% | Training loss: 0.7019398772716522
Epoch: 11 | Iteration number: [160/393] 40% | Training loss: 0.7016015775501728
Epoch: 11 | Iteration number: [170/393] 43% | Training loss: 0.7012775105588577
Epoch: 11 | Iteration number: [180/393] 45% | Training loss: 0.7009919010930591
Epoch: 11 | Iteration number: [190/393] 48% | Training loss: 0.7007094860076905
Epoch: 11 | Iteration number: [200/393] 50% | Training loss: 0.7005069038271904
Epoch: 11 | Iteration number: [210/393] 53% | Training loss: 0.7003378240835099
Epoch: 11 | Iteration number: [220/393] 55% | Training loss: 0.700158280134201
Epoch: 11 | Iteration number: [230/393] 58% | Training loss: 0.6999847606472347
Epoch: 11 | Iteration number: [240/393] 61% | Training loss: 0.6997959916790326
Epoch: 11 | Iteration number: [250/393] 63% | Training loss: 0.6996647469997406
Epoch: 11 | Iteration number: [260/393] 66% | Training loss: 0.6995022500936802
Epoch: 11 | Iteration number: [270/393] 68% | Training loss: 0.6994064247166669
Epoch: 11 | Iteration number: [280/393] 71% | Training loss: 0.6992813350898879
Epoch: 11 | Iteration number: [290/393] 73% | Training loss: 0.6991890175589199
Epoch: 11 | Iteration number: [300/393] 76% | Training loss: 0.6990829308827718
Epoch: 11 | Iteration number: [310/393] 78% | Training loss: 0.6989551821062642
Epoch: 11 | Iteration number: [320/393] 81% | Training loss: 0.6988404877483845
Epoch: 11 | Iteration number: [330/393] 83% | Training loss: 0.6987511721524325
Epoch: 11 | Iteration number: [340/393] 86% | Training loss: 0.698682528032976
Epoch: 11 | Iteration number: [350/393] 89% | Training loss: 0.6986060673849923
Epoch: 11 | Iteration number: [360/393] 91% | Training loss: 0.6985181076659097
Epoch: 11 | Iteration number: [370/393] 94% | Training loss: 0.6984458510940139
Epoch: 11 | Iteration number: [380/393] 96% | Training loss: 0.6983754379184622
Epoch: 11 | Iteration number: [390/393] 99% | Training loss: 0.6983193203424796

 End of epoch: 11 | Train Loss: 0.6965214852765013 | Training Time: 68 

 End of epoch: 11 | Eval Loss: 0.6957795863248863 | Evaluating Time: 18 
Epoch: 12 | Iteration number: [10/393] 2% | Training loss: 0.7647826373577118
Epoch: 12 | Iteration number: [20/393] 5% | Training loss: 0.7302703052759171
Epoch: 12 | Iteration number: [30/393] 7% | Training loss: 0.7187831302483877
Epoch: 12 | Iteration number: [40/393] 10% | Training loss: 0.7129749447107315
Epoch: 12 | Iteration number: [50/393] 12% | Training loss: 0.7099834191799164
Epoch: 12 | Iteration number: [60/393] 15% | Training loss: 0.7077834069728851
Epoch: 12 | Iteration number: [70/393] 17% | Training loss: 0.7061093330383301
Epoch: 12 | Iteration number: [80/393] 20% | Training loss: 0.7046726956963539
Epoch: 12 | Iteration number: [90/393] 22% | Training loss: 0.7038855738110013
Epoch: 12 | Iteration number: [100/393] 25% | Training loss: 0.7031290221214295
Epoch: 12 | Iteration number: [110/393] 27% | Training loss: 0.7025673232295296
Epoch: 12 | Iteration number: [120/393] 30% | Training loss: 0.7020451376835505
Epoch: 12 | Iteration number: [130/393] 33% | Training loss: 0.7015913569010221
Epoch: 12 | Iteration number: [140/393] 35% | Training loss: 0.7012194092784609
Epoch: 12 | Iteration number: [150/393] 38% | Training loss: 0.70082332889239
Epoch: 12 | Iteration number: [160/393] 40% | Training loss: 0.7004457611590624
Epoch: 12 | Iteration number: [170/393] 43% | Training loss: 0.7001391666776994
Epoch: 12 | Iteration number: [180/393] 45% | Training loss: 0.6999290251069599
Epoch: 12 | Iteration number: [190/393] 48% | Training loss: 0.6996904768441853
Epoch: 12 | Iteration number: [200/393] 50% | Training loss: 0.6994431525468826
Epoch: 12 | Iteration number: [210/393] 53% | Training loss: 0.6993073999881745
Epoch: 12 | Iteration number: [220/393] 55% | Training loss: 0.6991385319016197
Epoch: 12 | Iteration number: [230/393] 58% | Training loss: 0.6990115093148273
Epoch: 12 | Iteration number: [240/393] 61% | Training loss: 0.6988563413421313
Epoch: 12 | Iteration number: [250/393] 63% | Training loss: 0.6987036647796631
Epoch: 12 | Iteration number: [260/393] 66% | Training loss: 0.6985597461462021
Epoch: 12 | Iteration number: [270/393] 68% | Training loss: 0.6984280043178135
Epoch: 12 | Iteration number: [280/393] 71% | Training loss: 0.6983281141945294
Epoch: 12 | Iteration number: [290/393] 73% | Training loss: 0.6982002778299924
Epoch: 12 | Iteration number: [300/393] 76% | Training loss: 0.6981157412131628
Epoch: 12 | Iteration number: [310/393] 78% | Training loss: 0.6979970558997124
Epoch: 12 | Iteration number: [320/393] 81% | Training loss: 0.697910932265222
Epoch: 12 | Iteration number: [330/393] 83% | Training loss: 0.6978069025458712
Epoch: 12 | Iteration number: [340/393] 86% | Training loss: 0.6977418543661342
Epoch: 12 | Iteration number: [350/393] 89% | Training loss: 0.6976525631972722
Epoch: 12 | Iteration number: [360/393] 91% | Training loss: 0.6975750780767864
Epoch: 12 | Iteration number: [370/393] 94% | Training loss: 0.6975030647741781
Epoch: 12 | Iteration number: [380/393] 96% | Training loss: 0.6974457830190659
Epoch: 12 | Iteration number: [390/393] 99% | Training loss: 0.6973729501932096

 End of epoch: 12 | Train Loss: 0.6955924237350775 | Training Time: 67 

 End of epoch: 12 | Eval Loss: 0.6949489676222509 | Evaluating Time: 17 
Epoch: 13 | Iteration number: [10/393] 2% | Training loss: 0.7655128836631775
Epoch: 13 | Iteration number: [20/393] 5% | Training loss: 0.7307187438011169
Epoch: 13 | Iteration number: [30/393] 7% | Training loss: 0.7190675457318624
Epoch: 13 | Iteration number: [40/393] 10% | Training loss: 0.7130502805113792
Epoch: 13 | Iteration number: [50/393] 12% | Training loss: 0.7091233897209167
Epoch: 13 | Iteration number: [60/393] 15% | Training loss: 0.7069161415100098
Epoch: 13 | Iteration number: [70/393] 17% | Training loss: 0.7051790101187569
Epoch: 13 | Iteration number: [80/393] 20% | Training loss: 0.7039158284664154
Epoch: 13 | Iteration number: [90/393] 22% | Training loss: 0.7028533438841502
Epoch: 13 | Iteration number: [100/393] 25% | Training loss: 0.7020060956478119
Epoch: 13 | Iteration number: [110/393] 27% | Training loss: 0.701383093812249
Epoch: 13 | Iteration number: [120/393] 30% | Training loss: 0.7008444791038831
Epoch: 13 | Iteration number: [130/393] 33% | Training loss: 0.7003539287126981
Epoch: 13 | Iteration number: [140/393] 35% | Training loss: 0.6999757783753532
Epoch: 13 | Iteration number: [150/393] 38% | Training loss: 0.6995952645937602
Epoch: 13 | Iteration number: [160/393] 40% | Training loss: 0.6992526754736901
Epoch: 13 | Iteration number: [170/393] 43% | Training loss: 0.6989854570697336
Epoch: 13 | Iteration number: [180/393] 45% | Training loss: 0.6987184299363031
Epoch: 13 | Iteration number: [190/393] 48% | Training loss: 0.6984560681016821
Epoch: 13 | Iteration number: [200/393] 50% | Training loss: 0.6982063978910447
Epoch: 13 | Iteration number: [210/393] 53% | Training loss: 0.6980083283923921
Epoch: 13 | Iteration number: [220/393] 55% | Training loss: 0.6978166469118812
Epoch: 13 | Iteration number: [230/393] 58% | Training loss: 0.6976531754369321
Epoch: 13 | Iteration number: [240/393] 61% | Training loss: 0.6975045231481393
Epoch: 13 | Iteration number: [250/393] 63% | Training loss: 0.6973521921634674
Epoch: 13 | Iteration number: [260/393] 66% | Training loss: 0.69721240401268
Epoch: 13 | Iteration number: [270/393] 68% | Training loss: 0.6971017786750087
Epoch: 13 | Iteration number: [280/393] 71% | Training loss: 0.696999662050179
Epoch: 13 | Iteration number: [290/393] 73% | Training loss: 0.6969047147652199
Epoch: 13 | Iteration number: [300/393] 76% | Training loss: 0.6967889668544134
Epoch: 13 | Iteration number: [310/393] 78% | Training loss: 0.6966972493356274
Epoch: 13 | Iteration number: [320/393] 81% | Training loss: 0.6966252891346812
Epoch: 13 | Iteration number: [330/393] 83% | Training loss: 0.6965432676402006
Epoch: 13 | Iteration number: [340/393] 86% | Training loss: 0.6965027141220429
Epoch: 13 | Iteration number: [350/393] 89% | Training loss: 0.6964688132490431
Epoch: 13 | Iteration number: [360/393] 91% | Training loss: 0.6964218831724591
Epoch: 13 | Iteration number: [370/393] 94% | Training loss: 0.6963563537275469
Epoch: 13 | Iteration number: [380/393] 96% | Training loss: 0.696303612621207
Epoch: 13 | Iteration number: [390/393] 99% | Training loss: 0.6962595688991058

 End of epoch: 13 | Train Loss: 0.6944819831362814 | Training Time: 68 

 End of epoch: 13 | Eval Loss: 0.69401501757758 | Evaluating Time: 17 
Epoch: 14 | Iteration number: [10/393] 2% | Training loss: 0.7627437055110932
Epoch: 14 | Iteration number: [20/393] 5% | Training loss: 0.7280400156974792
Epoch: 14 | Iteration number: [30/393] 7% | Training loss: 0.7163470407327016
Epoch: 14 | Iteration number: [40/393] 10% | Training loss: 0.7106777027249336
Epoch: 14 | Iteration number: [50/393] 12% | Training loss: 0.7072891938686371
Epoch: 14 | Iteration number: [60/393] 15% | Training loss: 0.7049556901057561
Epoch: 14 | Iteration number: [70/393] 17% | Training loss: 0.7033533820084164
Epoch: 14 | Iteration number: [80/393] 20% | Training loss: 0.7021259754896164
Epoch: 14 | Iteration number: [90/393] 22% | Training loss: 0.7012753241591984
Epoch: 14 | Iteration number: [100/393] 25% | Training loss: 0.7005145609378814
Epoch: 14 | Iteration number: [110/393] 27% | Training loss: 0.6998731846159155
Epoch: 14 | Iteration number: [120/393] 30% | Training loss: 0.6993314544359843
Epoch: 14 | Iteration number: [130/393] 33% | Training loss: 0.6988630601992973
Epoch: 14 | Iteration number: [140/393] 35% | Training loss: 0.6984913800443922
Epoch: 14 | Iteration number: [150/393] 38% | Training loss: 0.6981970040003459
Epoch: 14 | Iteration number: [160/393] 40% | Training loss: 0.697928511723876
Epoch: 14 | Iteration number: [170/393] 43% | Training loss: 0.6976838448468377
Epoch: 14 | Iteration number: [180/393] 45% | Training loss: 0.6974656485848957
Epoch: 14 | Iteration number: [190/393] 48% | Training loss: 0.6972188224917963
Epoch: 14 | Iteration number: [200/393] 50% | Training loss: 0.696988362967968
Epoch: 14 | Iteration number: [210/393] 53% | Training loss: 0.6968294365065438
Epoch: 14 | Iteration number: [220/393] 55% | Training loss: 0.6967018569057638
Epoch: 14 | Iteration number: [230/393] 58% | Training loss: 0.6965795949749325
Epoch: 14 | Iteration number: [240/393] 61% | Training loss: 0.6964707784354687
Epoch: 14 | Iteration number: [250/393] 63% | Training loss: 0.6963448419570922
Epoch: 14 | Iteration number: [260/393] 66% | Training loss: 0.6962821550094165
Epoch: 14 | Iteration number: [270/393] 68% | Training loss: 0.6962024185392591
Epoch: 14 | Iteration number: [280/393] 71% | Training loss: 0.6961185312696866
Epoch: 14 | Iteration number: [290/393] 73% | Training loss: 0.6960453800086317
Epoch: 14 | Iteration number: [300/393] 76% | Training loss: 0.6959755845864614
Epoch: 14 | Iteration number: [310/393] 78% | Training loss: 0.6958976632164371
Epoch: 14 | Iteration number: [320/393] 81% | Training loss: 0.6958059290423989
Epoch: 14 | Iteration number: [330/393] 83% | Training loss: 0.6957242962085839
Epoch: 14 | Iteration number: [340/393] 86% | Training loss: 0.6956864267587661
Epoch: 14 | Iteration number: [350/393] 89% | Training loss: 0.6956563224111284
Epoch: 14 | Iteration number: [360/393] 91% | Training loss: 0.6956082850694656
Epoch: 14 | Iteration number: [370/393] 94% | Training loss: 0.6955549955368042
Epoch: 14 | Iteration number: [380/393] 96% | Training loss: 0.695495827103916
Epoch: 14 | Iteration number: [390/393] 99% | Training loss: 0.6954162388275831

 End of epoch: 14 | Train Loss: 0.6936580628232495 | Training Time: 67 

 End of epoch: 14 | Eval Loss: 0.6934288569859096 | Evaluating Time: 17 
Epoch: 15 | Iteration number: [10/393] 2% | Training loss: 0.7631897270679474
Epoch: 15 | Iteration number: [20/393] 5% | Training loss: 0.7281884104013443
Epoch: 15 | Iteration number: [30/393] 7% | Training loss: 0.7167101999123892
Epoch: 15 | Iteration number: [40/393] 10% | Training loss: 0.7107600107789039
Epoch: 15 | Iteration number: [50/393] 12% | Training loss: 0.707355991601944
Epoch: 15 | Iteration number: [60/393] 15% | Training loss: 0.7049612412850063
Epoch: 15 | Iteration number: [70/393] 17% | Training loss: 0.7033320256641933
Epoch: 15 | Iteration number: [80/393] 20% | Training loss: 0.7019869454205037
Epoch: 15 | Iteration number: [90/393] 22% | Training loss: 0.7009281105465359
Epoch: 15 | Iteration number: [100/393] 25% | Training loss: 0.7001714390516282
Epoch: 15 | Iteration number: [110/393] 27% | Training loss: 0.6995590388774872
Epoch: 15 | Iteration number: [120/393] 30% | Training loss: 0.6990569685896237
Epoch: 15 | Iteration number: [130/393] 33% | Training loss: 0.69866105730717
Epoch: 15 | Iteration number: [140/393] 35% | Training loss: 0.6982148259878158
Epoch: 15 | Iteration number: [150/393] 38% | Training loss: 0.6978797705968222
Epoch: 15 | Iteration number: [160/393] 40% | Training loss: 0.6976363591849803
Epoch: 15 | Iteration number: [170/393] 43% | Training loss: 0.6973830812117633
Epoch: 15 | Iteration number: [180/393] 45% | Training loss: 0.6971405595541
Epoch: 15 | Iteration number: [190/393] 48% | Training loss: 0.696914825000261
Epoch: 15 | Iteration number: [200/393] 50% | Training loss: 0.6967240026593209
Epoch: 15 | Iteration number: [210/393] 53% | Training loss: 0.6965405739489056
Epoch: 15 | Iteration number: [220/393] 55% | Training loss: 0.6963825597004457
Epoch: 15 | Iteration number: [230/393] 58% | Training loss: 0.6962344566117162
Epoch: 15 | Iteration number: [240/393] 61% | Training loss: 0.6960987652341525
Epoch: 15 | Iteration number: [250/393] 63% | Training loss: 0.6959393057823181
Epoch: 15 | Iteration number: [260/393] 66% | Training loss: 0.6957964012256035
Epoch: 15 | Iteration number: [270/393] 68% | Training loss: 0.6956991643817336
Epoch: 15 | Iteration number: [280/393] 71% | Training loss: 0.6955714789884431
Epoch: 15 | Iteration number: [290/393] 73% | Training loss: 0.695505233057614
Epoch: 15 | Iteration number: [300/393] 76% | Training loss: 0.6954408097267151
Epoch: 15 | Iteration number: [310/393] 78% | Training loss: 0.6953704359069948
Epoch: 15 | Iteration number: [320/393] 81% | Training loss: 0.6952862914651632
Epoch: 15 | Iteration number: [330/393] 83% | Training loss: 0.6952136397361756
Epoch: 15 | Iteration number: [340/393] 86% | Training loss: 0.6951577896580977
Epoch: 15 | Iteration number: [350/393] 89% | Training loss: 0.6950992388384682
Epoch: 15 | Iteration number: [360/393] 91% | Training loss: 0.6950306567880843
Epoch: 15 | Iteration number: [370/393] 94% | Training loss: 0.6949740566111899
Epoch: 15 | Iteration number: [380/393] 96% | Training loss: 0.6949089751431816
Epoch: 15 | Iteration number: [390/393] 99% | Training loss: 0.6948546935350467

 End of epoch: 15 | Train Loss: 0.6930861204635096 | Training Time: 67 

 End of epoch: 15 | Eval Loss: 0.6929618959524193 | Evaluating Time: 17 
Epoch: 16 | Iteration number: [10/393] 2% | Training loss: 0.7632580518722534
Epoch: 16 | Iteration number: [20/393] 5% | Training loss: 0.7283031344413757
Epoch: 16 | Iteration number: [30/393] 7% | Training loss: 0.7169291337331136
Epoch: 16 | Iteration number: [40/393] 10% | Training loss: 0.7109252616763115
Epoch: 16 | Iteration number: [50/393] 12% | Training loss: 0.7074252831935882
Epoch: 16 | Iteration number: [60/393] 15% | Training loss: 0.7049016386270524
Epoch: 16 | Iteration number: [70/393] 17% | Training loss: 0.703203911440713
Epoch: 16 | Iteration number: [80/393] 20% | Training loss: 0.7018605925142765
Epoch: 16 | Iteration number: [90/393] 22% | Training loss: 0.7010485423935784
Epoch: 16 | Iteration number: [100/393] 25% | Training loss: 0.7001997315883637
Epoch: 16 | Iteration number: [110/393] 27% | Training loss: 0.6995770248499784
Epoch: 16 | Iteration number: [120/393] 30% | Training loss: 0.6989698683222135
Epoch: 16 | Iteration number: [130/393] 33% | Training loss: 0.6984431821566361
Epoch: 16 | Iteration number: [140/393] 35% | Training loss: 0.6979841564382826
Epoch: 16 | Iteration number: [150/393] 38% | Training loss: 0.6977367913722992
Epoch: 16 | Iteration number: [160/393] 40% | Training loss: 0.6974097155034542
Epoch: 16 | Iteration number: [170/393] 43% | Training loss: 0.6971007417230045
Epoch: 16 | Iteration number: [180/393] 45% | Training loss: 0.696824261546135
Epoch: 16 | Iteration number: [190/393] 48% | Training loss: 0.6966264821981129
Epoch: 16 | Iteration number: [200/393] 50% | Training loss: 0.6964720007777214
Epoch: 16 | Iteration number: [210/393] 53% | Training loss: 0.6962253141970861
Epoch: 16 | Iteration number: [220/393] 55% | Training loss: 0.6960325276309793
Epoch: 16 | Iteration number: [230/393] 58% | Training loss: 0.695863815235055
Epoch: 16 | Iteration number: [240/393] 61% | Training loss: 0.6957422740757465
Epoch: 16 | Iteration number: [250/393] 63% | Training loss: 0.6956087203025818
Epoch: 16 | Iteration number: [260/393] 66% | Training loss: 0.6954971024623284
Epoch: 16 | Iteration number: [270/393] 68% | Training loss: 0.6954006245842687
Epoch: 16 | Iteration number: [280/393] 71% | Training loss: 0.6953130413378988
Epoch: 16 | Iteration number: [290/393] 73% | Training loss: 0.6952294694966283
Epoch: 16 | Iteration number: [300/393] 76% | Training loss: 0.6951628897587458
Epoch: 16 | Iteration number: [310/393] 78% | Training loss: 0.6950611877825952
Epoch: 16 | Iteration number: [320/393] 81% | Training loss: 0.6949521655216813
Epoch: 16 | Iteration number: [330/393] 83% | Training loss: 0.6948928139426491
Epoch: 16 | Iteration number: [340/393] 86% | Training loss: 0.6948154614252202
Epoch: 16 | Iteration number: [350/393] 89% | Training loss: 0.6947501732621875
Epoch: 16 | Iteration number: [360/393] 91% | Training loss: 0.6946887304385503
Epoch: 16 | Iteration number: [370/393] 94% | Training loss: 0.6946275298659866
Epoch: 16 | Iteration number: [380/393] 96% | Training loss: 0.6945753000284496
Epoch: 16 | Iteration number: [390/393] 99% | Training loss: 0.6945225877639575

 End of epoch: 16 | Train Loss: 0.6927383884825475 | Training Time: 67 

 End of epoch: 16 | Eval Loss: 0.6928511614702186 | Evaluating Time: 17 
Epoch: 17 | Iteration number: [10/393] 2% | Training loss: 0.7618047416210174
Epoch: 17 | Iteration number: [20/393] 5% | Training loss: 0.7270953536033631
Epoch: 17 | Iteration number: [30/393] 7% | Training loss: 0.7155479411284129
Epoch: 17 | Iteration number: [40/393] 10% | Training loss: 0.7099520444869996
Epoch: 17 | Iteration number: [50/393] 12% | Training loss: 0.7065452063083648
Epoch: 17 | Iteration number: [60/393] 15% | Training loss: 0.704068140188853
Epoch: 17 | Iteration number: [70/393] 17% | Training loss: 0.7024699798652104
Epoch: 17 | Iteration number: [80/393] 20% | Training loss: 0.7012059807777404
Epoch: 17 | Iteration number: [90/393] 22% | Training loss: 0.7003438936339484
Epoch: 17 | Iteration number: [100/393] 25% | Training loss: 0.6995868694782257
Epoch: 17 | Iteration number: [110/393] 27% | Training loss: 0.6989321258935062
Epoch: 17 | Iteration number: [120/393] 30% | Training loss: 0.698367191851139
Epoch: 17 | Iteration number: [130/393] 33% | Training loss: 0.6979133771016047
Epoch: 17 | Iteration number: [140/393] 35% | Training loss: 0.6975656334842955
Epoch: 17 | Iteration number: [150/393] 38% | Training loss: 0.6971898504098256
Epoch: 17 | Iteration number: [160/393] 40% | Training loss: 0.6968990463763476
Epoch: 17 | Iteration number: [170/393] 43% | Training loss: 0.6966623113435857
Epoch: 17 | Iteration number: [180/393] 45% | Training loss: 0.6964855972263548
Epoch: 17 | Iteration number: [190/393] 48% | Training loss: 0.6963174474866767
Epoch: 17 | Iteration number: [200/393] 50% | Training loss: 0.6960735139250755
Epoch: 17 | Iteration number: [210/393] 53% | Training loss: 0.6958799932684218
Epoch: 17 | Iteration number: [220/393] 55% | Training loss: 0.6957115460525859
Epoch: 17 | Iteration number: [230/393] 58% | Training loss: 0.6955561215462892
Epoch: 17 | Iteration number: [240/393] 61% | Training loss: 0.6953875951468944
Epoch: 17 | Iteration number: [250/393] 63% | Training loss: 0.6952673740386963
Epoch: 17 | Iteration number: [260/393] 66% | Training loss: 0.695105732862766
Epoch: 17 | Iteration number: [270/393] 68% | Training loss: 0.695049109061559
Epoch: 17 | Iteration number: [280/393] 71% | Training loss: 0.6949545581425939
Epoch: 17 | Iteration number: [290/393] 73% | Training loss: 0.6948436021804809
Epoch: 17 | Iteration number: [300/393] 76% | Training loss: 0.6947492412726084
Epoch: 17 | Iteration number: [310/393] 78% | Training loss: 0.6946767549360952
Epoch: 17 | Iteration number: [320/393] 81% | Training loss: 0.6945941988378763
Epoch: 17 | Iteration number: [330/393] 83% | Training loss: 0.6945414980252583
Epoch: 17 | Iteration number: [340/393] 86% | Training loss: 0.6944464999086717
Epoch: 17 | Iteration number: [350/393] 89% | Training loss: 0.6943516644409725
Epoch: 17 | Iteration number: [360/393] 91% | Training loss: 0.6943008674515618
Epoch: 17 | Iteration number: [370/393] 94% | Training loss: 0.6942694072787826
Epoch: 17 | Iteration number: [380/393] 96% | Training loss: 0.6942218683267894
Epoch: 17 | Iteration number: [390/393] 99% | Training loss: 0.6941671593066974

 End of epoch: 17 | Train Loss: 0.6923907418894101 | Training Time: 67 

 End of epoch: 17 | Eval Loss: 0.6924193610950392 | Evaluating Time: 17 
Epoch: 18 | Iteration number: [10/393] 2% | Training loss: 0.7624884486198426
Epoch: 18 | Iteration number: [20/393] 5% | Training loss: 0.7276160895824433
Epoch: 18 | Iteration number: [30/393] 7% | Training loss: 0.7156508564949036
Epoch: 18 | Iteration number: [40/393] 10% | Training loss: 0.7099221691489219
Epoch: 18 | Iteration number: [50/393] 12% | Training loss: 0.7063906919956208
Epoch: 18 | Iteration number: [60/393] 15% | Training loss: 0.7041301717360814
Epoch: 18 | Iteration number: [70/393] 17% | Training loss: 0.7024569698742458
Epoch: 18 | Iteration number: [80/393] 20% | Training loss: 0.7011421024799347
Epoch: 18 | Iteration number: [90/393] 22% | Training loss: 0.7001379311084748
Epoch: 18 | Iteration number: [100/393] 25% | Training loss: 0.6992416149377823
Epoch: 18 | Iteration number: [110/393] 27% | Training loss: 0.69859677715735
Epoch: 18 | Iteration number: [120/393] 30% | Training loss: 0.6981489469607671
Epoch: 18 | Iteration number: [130/393] 33% | Training loss: 0.6975781358205355
Epoch: 18 | Iteration number: [140/393] 35% | Training loss: 0.6972083078963416
Epoch: 18 | Iteration number: [150/393] 38% | Training loss: 0.6968168409665426
Epoch: 18 | Iteration number: [160/393] 40% | Training loss: 0.6964875310659409
Epoch: 18 | Iteration number: [170/393] 43% | Training loss: 0.6963072527857388
Epoch: 18 | Iteration number: [180/393] 45% | Training loss: 0.696058432923423
Epoch: 18 | Iteration number: [190/393] 48% | Training loss: 0.6958621777986226
Epoch: 18 | Iteration number: [200/393] 50% | Training loss: 0.6956718254089356
Epoch: 18 | Iteration number: [210/393] 53% | Training loss: 0.6954796697412219
Epoch: 18 | Iteration number: [220/393] 55% | Training loss: 0.6953018714081157
Epoch: 18 | Iteration number: [230/393] 58% | Training loss: 0.6951583823432093
Epoch: 18 | Iteration number: [240/393] 61% | Training loss: 0.6950295843183995
Epoch: 18 | Iteration number: [250/393] 63% | Training loss: 0.6949200747013092
Epoch: 18 | Iteration number: [260/393] 66% | Training loss: 0.6948008202589475
Epoch: 18 | Iteration number: [270/393] 68% | Training loss: 0.6947155164347755
Epoch: 18 | Iteration number: [280/393] 71% | Training loss: 0.6945784209030015
Epoch: 18 | Iteration number: [290/393] 73% | Training loss: 0.6945233254597105
Epoch: 18 | Iteration number: [300/393] 76% | Training loss: 0.6944735886653265
Epoch: 18 | Iteration number: [310/393] 78% | Training loss: 0.6943948268890381
Epoch: 18 | Iteration number: [320/393] 81% | Training loss: 0.694316954165697
Epoch: 18 | Iteration number: [330/393] 83% | Training loss: 0.694239234382456
Epoch: 18 | Iteration number: [340/393] 86% | Training loss: 0.6941873290959526
Epoch: 18 | Iteration number: [350/393] 89% | Training loss: 0.6941510941301073
Epoch: 18 | Iteration number: [360/393] 91% | Training loss: 0.6940901728139983
Epoch: 18 | Iteration number: [370/393] 94% | Training loss: 0.6940140712905575
Epoch: 18 | Iteration number: [380/393] 96% | Training loss: 0.6939984737258208
Epoch: 18 | Iteration number: [390/393] 99% | Training loss: 0.6939528161134475

 End of epoch: 18 | Train Loss: 0.6921811416252273 | Training Time: 67 

 End of epoch: 18 | Eval Loss: 0.6922365451345638 | Evaluating Time: 17 
Epoch: 19 | Iteration number: [10/393] 2% | Training loss: 0.7613387942314148
Epoch: 19 | Iteration number: [20/393] 5% | Training loss: 0.7261273920536041
Epoch: 19 | Iteration number: [30/393] 7% | Training loss: 0.7145377635955811
Epoch: 19 | Iteration number: [40/393] 10% | Training loss: 0.7086347594857216
Epoch: 19 | Iteration number: [50/393] 12% | Training loss: 0.7054733550548553
Epoch: 19 | Iteration number: [60/393] 15% | Training loss: 0.7032647748788198
Epoch: 19 | Iteration number: [70/393] 17% | Training loss: 0.7016601852008275
Epoch: 19 | Iteration number: [80/393] 20% | Training loss: 0.7003650203347206
Epoch: 19 | Iteration number: [90/393] 22% | Training loss: 0.6994925306902992
Epoch: 19 | Iteration number: [100/393] 25% | Training loss: 0.6987022405862808
Epoch: 19 | Iteration number: [110/393] 27% | Training loss: 0.6980888437141072
Epoch: 19 | Iteration number: [120/393] 30% | Training loss: 0.6975287700692813
Epoch: 19 | Iteration number: [130/393] 33% | Training loss: 0.6970875969299903
Epoch: 19 | Iteration number: [140/393] 35% | Training loss: 0.6966318100690841
Epoch: 19 | Iteration number: [150/393] 38% | Training loss: 0.6963163542747498
Epoch: 19 | Iteration number: [160/393] 40% | Training loss: 0.6960413802415133
Epoch: 19 | Iteration number: [170/393] 43% | Training loss: 0.6957526038674747
Epoch: 19 | Iteration number: [180/393] 45% | Training loss: 0.6955737935172187
Epoch: 19 | Iteration number: [190/393] 48% | Training loss: 0.6953728763680709
Epoch: 19 | Iteration number: [200/393] 50% | Training loss: 0.6952021029591561
Epoch: 19 | Iteration number: [210/393] 53% | Training loss: 0.6950428119727543
Epoch: 19 | Iteration number: [220/393] 55% | Training loss: 0.6948782357302579
Epoch: 19 | Iteration number: [230/393] 58% | Training loss: 0.6947509750075962
Epoch: 19 | Iteration number: [240/393] 61% | Training loss: 0.6946244987348715
Epoch: 19 | Iteration number: [250/393] 63% | Training loss: 0.6945302848815917
Epoch: 19 | Iteration number: [260/393] 66% | Training loss: 0.69444607427487
Epoch: 19 | Iteration number: [270/393] 68% | Training loss: 0.6943399890705392
Epoch: 19 | Iteration number: [280/393] 71% | Training loss: 0.6942413462059839
Epoch: 19 | Iteration number: [290/393] 73% | Training loss: 0.694164968153526
Epoch: 19 | Iteration number: [300/393] 76% | Training loss: 0.6940637262662251
Epoch: 19 | Iteration number: [310/393] 78% | Training loss: 0.6939856073548717
Epoch: 19 | Iteration number: [320/393] 81% | Training loss: 0.6938943332061172
Epoch: 19 | Iteration number: [330/393] 83% | Training loss: 0.6938218087861032
Epoch: 19 | Iteration number: [340/393] 86% | Training loss: 0.6937827643226174
Epoch: 19 | Iteration number: [350/393] 89% | Training loss: 0.6937283195768084
Epoch: 19 | Iteration number: [360/393] 91% | Training loss: 0.6937090347210566
Epoch: 19 | Iteration number: [370/393] 94% | Training loss: 0.693663829242861
Epoch: 19 | Iteration number: [380/393] 96% | Training loss: 0.693622048277604
Epoch: 19 | Iteration number: [390/393] 99% | Training loss: 0.6935950244084382

 End of epoch: 19 | Train Loss: 0.6918178804351477 | Training Time: 68 

 End of epoch: 19 | Eval Loss: 0.6919836523581524 | Evaluating Time: 17 
Epoch: 20 | Iteration number: [10/393] 2% | Training loss: 0.762342894077301
Epoch: 20 | Iteration number: [20/393] 5% | Training loss: 0.7271992921829223
Epoch: 20 | Iteration number: [30/393] 7% | Training loss: 0.715270733833313
Epoch: 20 | Iteration number: [40/393] 10% | Training loss: 0.7093338251113892
Epoch: 20 | Iteration number: [50/393] 12% | Training loss: 0.7057224106788635
Epoch: 20 | Iteration number: [60/393] 15% | Training loss: 0.7033507545789083
Epoch: 20 | Iteration number: [70/393] 17% | Training loss: 0.7016742212431771
Epoch: 20 | Iteration number: [80/393] 20% | Training loss: 0.7003464475274086
Epoch: 20 | Iteration number: [90/393] 22% | Training loss: 0.6993304755952623
Epoch: 20 | Iteration number: [100/393] 25% | Training loss: 0.6986757600307465
Epoch: 20 | Iteration number: [110/393] 27% | Training loss: 0.6981055823239413
Epoch: 20 | Iteration number: [120/393] 30% | Training loss: 0.6976053198178609
Epoch: 20 | Iteration number: [130/393] 33% | Training loss: 0.6971356584475591
Epoch: 20 | Iteration number: [140/393] 35% | Training loss: 0.6967208474874497
Epoch: 20 | Iteration number: [150/393] 38% | Training loss: 0.6963661964734396
Epoch: 20 | Iteration number: [160/393] 40% | Training loss: 0.6960494671016931
Epoch: 20 | Iteration number: [170/393] 43% | Training loss: 0.695738093993243
Epoch: 20 | Iteration number: [180/393] 45% | Training loss: 0.6954686029089822
Epoch: 20 | Iteration number: [190/393] 48% | Training loss: 0.6952950154480181
Epoch: 20 | Iteration number: [200/393] 50% | Training loss: 0.6950502267479897
Epoch: 20 | Iteration number: [210/393] 53% | Training loss: 0.6948546886444091
Epoch: 20 | Iteration number: [220/393] 55% | Training loss: 0.6947429678656838
Epoch: 20 | Iteration number: [230/393] 58% | Training loss: 0.6946156548417133
Epoch: 20 | Iteration number: [240/393] 61% | Training loss: 0.6944812181095282
Epoch: 20 | Iteration number: [250/393] 63% | Training loss: 0.6943796081542969
Epoch: 20 | Iteration number: [260/393] 66% | Training loss: 0.6943203121423721
Epoch: 20 | Iteration number: [270/393] 68% | Training loss: 0.6942548608338391
Epoch: 20 | Iteration number: [280/393] 71% | Training loss: 0.6941420823335648
Epoch: 20 | Iteration number: [290/393] 73% | Training loss: 0.6940117527698648
Epoch: 20 | Iteration number: [300/393] 76% | Training loss: 0.6939617578188578
Epoch: 20 | Iteration number: [310/393] 78% | Training loss: 0.6939182177666695
Epoch: 20 | Iteration number: [320/393] 81% | Training loss: 0.6938549675047397
Epoch: 20 | Iteration number: [330/393] 83% | Training loss: 0.6937927610946424
Epoch: 20 | Iteration number: [340/393] 86% | Training loss: 0.693710291911574
Epoch: 20 | Iteration number: [350/393] 89% | Training loss: 0.6936726568426405
Epoch: 20 | Iteration number: [360/393] 91% | Training loss: 0.6936185432804955
Epoch: 20 | Iteration number: [370/393] 94% | Training loss: 0.6935581614842286
Epoch: 20 | Iteration number: [380/393] 96% | Training loss: 0.69348718916115
Epoch: 20 | Iteration number: [390/393] 99% | Training loss: 0.6934217051053658

 End of epoch: 20 | Train Loss: 0.6916542972317179 | Training Time: 68 

 End of epoch: 20 | Eval Loss: 0.6918383216371342 | Evaluating Time: 17 
Epoch: 21 | Iteration number: [10/393] 2% | Training loss: 0.7600774645805359
Epoch: 21 | Iteration number: [20/393] 5% | Training loss: 0.725750207901001
Epoch: 21 | Iteration number: [30/393] 7% | Training loss: 0.714220913251241
Epoch: 21 | Iteration number: [40/393] 10% | Training loss: 0.7086281433701516
Epoch: 21 | Iteration number: [50/393] 12% | Training loss: 0.7052553474903107
Epoch: 21 | Iteration number: [60/393] 15% | Training loss: 0.7029708921909332
Epoch: 21 | Iteration number: [70/393] 17% | Training loss: 0.7014190537588937
Epoch: 21 | Iteration number: [80/393] 20% | Training loss: 0.7000397779047489
Epoch: 21 | Iteration number: [90/393] 22% | Training loss: 0.6991113616360558
Epoch: 21 | Iteration number: [100/393] 25% | Training loss: 0.6983691024780273
Epoch: 21 | Iteration number: [110/393] 27% | Training loss: 0.6976680972359397
Epoch: 21 | Iteration number: [120/393] 30% | Training loss: 0.6972325543562571
Epoch: 21 | Iteration number: [130/393] 33% | Training loss: 0.6968493030621455
Epoch: 21 | Iteration number: [140/393] 35% | Training loss: 0.6964606204203196
Epoch: 21 | Iteration number: [150/393] 38% | Training loss: 0.6960566254456838
Epoch: 21 | Iteration number: [160/393] 40% | Training loss: 0.6957504484802485
Epoch: 21 | Iteration number: [170/393] 43% | Training loss: 0.6954786006142112
Epoch: 21 | Iteration number: [180/393] 45% | Training loss: 0.6952237943808238
Epoch: 21 | Iteration number: [190/393] 48% | Training loss: 0.6949932095251585
Epoch: 21 | Iteration number: [200/393] 50% | Training loss: 0.6948053050041199
Epoch: 21 | Iteration number: [210/393] 53% | Training loss: 0.6946852669829414
Epoch: 21 | Iteration number: [220/393] 55% | Training loss: 0.6945600886236537
Epoch: 21 | Iteration number: [230/393] 58% | Training loss: 0.6944449953410936
Epoch: 21 | Iteration number: [240/393] 61% | Training loss: 0.6943400941789151
Epoch: 21 | Iteration number: [250/393] 63% | Training loss: 0.6942012488842011
Epoch: 21 | Iteration number: [260/393] 66% | Training loss: 0.6941070719407155
Epoch: 21 | Iteration number: [270/393] 68% | Training loss: 0.6940105795860291
Epoch: 21 | Iteration number: [280/393] 71% | Training loss: 0.6939186943428857
Epoch: 21 | Iteration number: [290/393] 73% | Training loss: 0.6938762566138958
Epoch: 21 | Iteration number: [300/393] 76% | Training loss: 0.6937895498673121
Epoch: 21 | Iteration number: [310/393] 78% | Training loss: 0.6937158209662284
Epoch: 21 | Iteration number: [320/393] 81% | Training loss: 0.6936493573710323
Epoch: 21 | Iteration number: [330/393] 83% | Training loss: 0.6935583992437883
Epoch: 21 | Iteration number: [340/393] 86% | Training loss: 0.6935124358710121
Epoch: 21 | Iteration number: [350/393] 89% | Training loss: 0.6934336265495845
Epoch: 21 | Iteration number: [360/393] 91% | Training loss: 0.6933737071024046
Epoch: 21 | Iteration number: [370/393] 94% | Training loss: 0.6933146576623659
Epoch: 21 | Iteration number: [380/393] 96% | Training loss: 0.6932249273124494
Epoch: 21 | Iteration number: [390/393] 99% | Training loss: 0.6931880056858063

 End of epoch: 21 | Train Loss: 0.6914106645353575 | Training Time: 67 

 End of epoch: 21 | Eval Loss: 0.6919549399492692 | Evaluating Time: 17 
Epoch: 22 | Iteration number: [10/393] 2% | Training loss: 0.7600247800350189
Epoch: 22 | Iteration number: [20/393] 5% | Training loss: 0.7254866361618042
Epoch: 22 | Iteration number: [30/393] 7% | Training loss: 0.7142502665519714
Epoch: 22 | Iteration number: [40/393] 10% | Training loss: 0.7087507337331772
Epoch: 22 | Iteration number: [50/393] 12% | Training loss: 0.7051982140541077
Epoch: 22 | Iteration number: [60/393] 15% | Training loss: 0.7029256363709767
Epoch: 22 | Iteration number: [70/393] 17% | Training loss: 0.7013136046273368
Epoch: 22 | Iteration number: [80/393] 20% | Training loss: 0.7000572212040425
Epoch: 22 | Iteration number: [90/393] 22% | Training loss: 0.6990541557470957
Epoch: 22 | Iteration number: [100/393] 25% | Training loss: 0.6983625096082687
Epoch: 22 | Iteration number: [110/393] 27% | Training loss: 0.697662461345846
Epoch: 22 | Iteration number: [120/393] 30% | Training loss: 0.6971523046493531
Epoch: 22 | Iteration number: [130/393] 33% | Training loss: 0.6967345315676469
Epoch: 22 | Iteration number: [140/393] 35% | Training loss: 0.6963503611939293
Epoch: 22 | Iteration number: [150/393] 38% | Training loss: 0.6959775865077973
Epoch: 22 | Iteration number: [160/393] 40% | Training loss: 0.6956946771591902
Epoch: 22 | Iteration number: [170/393] 43% | Training loss: 0.695476822642719
Epoch: 22 | Iteration number: [180/393] 45% | Training loss: 0.695267837577396
Epoch: 22 | Iteration number: [190/393] 48% | Training loss: 0.6950365163778004
Epoch: 22 | Iteration number: [200/393] 50% | Training loss: 0.6948273295164108
Epoch: 22 | Iteration number: [210/393] 53% | Training loss: 0.69468703184809
Epoch: 22 | Iteration number: [220/393] 55% | Training loss: 0.6945472378622402
Epoch: 22 | Iteration number: [230/393] 58% | Training loss: 0.6944205027559529
Epoch: 22 | Iteration number: [240/393] 61% | Training loss: 0.6942612797021865
Epoch: 22 | Iteration number: [250/393] 63% | Training loss: 0.6941236319541931
Epoch: 22 | Iteration number: [260/393] 66% | Training loss: 0.6940371735737874
Epoch: 22 | Iteration number: [270/393] 68% | Training loss: 0.6938777738147311
Epoch: 22 | Iteration number: [280/393] 71% | Training loss: 0.6937998935580254
Epoch: 22 | Iteration number: [290/393] 73% | Training loss: 0.6937350414950272
Epoch: 22 | Iteration number: [300/393] 76% | Training loss: 0.6936786750952403
Epoch: 22 | Iteration number: [310/393] 78% | Training loss: 0.6936073951182827
Epoch: 22 | Iteration number: [320/393] 81% | Training loss: 0.6935145849362016
Epoch: 22 | Iteration number: [330/393] 83% | Training loss: 0.6934414968346104
Epoch: 22 | Iteration number: [340/393] 86% | Training loss: 0.6934133093146717
Epoch: 22 | Iteration number: [350/393] 89% | Training loss: 0.6933659773213523
Epoch: 22 | Iteration number: [360/393] 91% | Training loss: 0.6933048847648833
Epoch: 22 | Iteration number: [370/393] 94% | Training loss: 0.6932573529514107
Epoch: 22 | Iteration number: [380/393] 96% | Training loss: 0.6932021078310515
Epoch: 22 | Iteration number: [390/393] 99% | Training loss: 0.6931444194072333

 End of epoch: 22 | Train Loss: 0.6913771090920038 | Training Time: 68 

 End of epoch: 22 | Eval Loss: 0.6914745435422781 | Evaluating Time: 17 
Epoch: 23 | Iteration number: [10/393] 2% | Training loss: 0.7609543919563293
Epoch: 23 | Iteration number: [20/393] 5% | Training loss: 0.7265014767646789
Epoch: 23 | Iteration number: [30/393] 7% | Training loss: 0.7149538477261861
Epoch: 23 | Iteration number: [40/393] 10% | Training loss: 0.7092028349637985
Epoch: 23 | Iteration number: [50/393] 12% | Training loss: 0.7057766640186309
Epoch: 23 | Iteration number: [60/393] 15% | Training loss: 0.7034581949313482
Epoch: 23 | Iteration number: [70/393] 17% | Training loss: 0.7017656709466662
Epoch: 23 | Iteration number: [80/393] 20% | Training loss: 0.7003469511866569
Epoch: 23 | Iteration number: [90/393] 22% | Training loss: 0.6992463767528534
Epoch: 23 | Iteration number: [100/393] 25% | Training loss: 0.6983700561523437
Epoch: 23 | Iteration number: [110/393] 27% | Training loss: 0.6976743969050321
Epoch: 23 | Iteration number: [120/393] 30% | Training loss: 0.6970712100466092
Epoch: 23 | Iteration number: [130/393] 33% | Training loss: 0.6966882256361154
Epoch: 23 | Iteration number: [140/393] 35% | Training loss: 0.6962438259805952
Epoch: 23 | Iteration number: [150/393] 38% | Training loss: 0.6959730879465739
Epoch: 23 | Iteration number: [160/393] 40% | Training loss: 0.6956517700105905
Epoch: 23 | Iteration number: [170/393] 43% | Training loss: 0.6954111092230852
Epoch: 23 | Iteration number: [180/393] 45% | Training loss: 0.6951688607533772
Epoch: 23 | Iteration number: [190/393] 48% | Training loss: 0.6949640396394228
Epoch: 23 | Iteration number: [200/393] 50% | Training loss: 0.6947438561916351
Epoch: 23 | Iteration number: [210/393] 53% | Training loss: 0.6946007975510189
Epoch: 23 | Iteration number: [220/393] 55% | Training loss: 0.6944676420905374
Epoch: 23 | Iteration number: [230/393] 58% | Training loss: 0.6942857055560402
Epoch: 23 | Iteration number: [240/393] 61% | Training loss: 0.694158353159825
Epoch: 23 | Iteration number: [250/393] 63% | Training loss: 0.6940287759304047
Epoch: 23 | Iteration number: [260/393] 66% | Training loss: 0.6939152607550988
Epoch: 23 | Iteration number: [270/393] 68% | Training loss: 0.6938449190722571
Epoch: 23 | Iteration number: [280/393] 71% | Training loss: 0.6937809569495065
Epoch: 23 | Iteration number: [290/393] 73% | Training loss: 0.6936812234335932
Epoch: 23 | Iteration number: [300/393] 76% | Training loss: 0.6935741555690765
Epoch: 23 | Iteration number: [310/393] 78% | Training loss: 0.6934798350257259
Epoch: 23 | Iteration number: [320/393] 81% | Training loss: 0.6934055246412754
Epoch: 23 | Iteration number: [330/393] 83% | Training loss: 0.6933346423235807
Epoch: 23 | Iteration number: [340/393] 86% | Training loss: 0.693252757191658
Epoch: 23 | Iteration number: [350/393] 89% | Training loss: 0.6931944125039237
Epoch: 23 | Iteration number: [360/393] 91% | Training loss: 0.6931337538692687
Epoch: 23 | Iteration number: [370/393] 94% | Training loss: 0.693044062562891
Epoch: 23 | Iteration number: [380/393] 96% | Training loss: 0.6929796129465103
Epoch: 23 | Iteration number: [390/393] 99% | Training loss: 0.6929627254987374

 End of epoch: 23 | Train Loss: 0.6911872049021054 | Training Time: 68 

 End of epoch: 23 | Eval Loss: 0.6914268318487673 | Evaluating Time: 17 
Epoch: 24 | Iteration number: [10/393] 2% | Training loss: 0.7608280837535858
Epoch: 24 | Iteration number: [20/393] 5% | Training loss: 0.7262152791023254
Epoch: 24 | Iteration number: [30/393] 7% | Training loss: 0.7146857142448425
Epoch: 24 | Iteration number: [40/393] 10% | Training loss: 0.7089730188250541
Epoch: 24 | Iteration number: [50/393] 12% | Training loss: 0.7053294229507446
Epoch: 24 | Iteration number: [60/393] 15% | Training loss: 0.703069473306338
Epoch: 24 | Iteration number: [70/393] 17% | Training loss: 0.7013471816267286
Epoch: 24 | Iteration number: [80/393] 20% | Training loss: 0.700071568787098
Epoch: 24 | Iteration number: [90/393] 22% | Training loss: 0.6991311656104193
Epoch: 24 | Iteration number: [100/393] 25% | Training loss: 0.6983743542432785
Epoch: 24 | Iteration number: [110/393] 27% | Training loss: 0.6975562090223486
Epoch: 24 | Iteration number: [120/393] 30% | Training loss: 0.6970212072134018
Epoch: 24 | Iteration number: [130/393] 33% | Training loss: 0.6966148958756373
Epoch: 24 | Iteration number: [140/393] 35% | Training loss: 0.6962680267436164
Epoch: 24 | Iteration number: [150/393] 38% | Training loss: 0.6959095168113708
Epoch: 24 | Iteration number: [160/393] 40% | Training loss: 0.6956635016947985
Epoch: 24 | Iteration number: [170/393] 43% | Training loss: 0.6954090234111338
Epoch: 24 | Iteration number: [180/393] 45% | Training loss: 0.6952324433459176
Epoch: 24 | Iteration number: [190/393] 48% | Training loss: 0.6949513557710145
Epoch: 24 | Iteration number: [200/393] 50% | Training loss: 0.6947643598914146
Epoch: 24 | Iteration number: [210/393] 53% | Training loss: 0.6946163872877756
Epoch: 24 | Iteration number: [220/393] 55% | Training loss: 0.6944389226761731
Epoch: 24 | Iteration number: [230/393] 58% | Training loss: 0.6942944490391275
Epoch: 24 | Iteration number: [240/393] 61% | Training loss: 0.6942268398900827
Epoch: 24 | Iteration number: [250/393] 63% | Training loss: 0.6940901968479156
Epoch: 24 | Iteration number: [260/393] 66% | Training loss: 0.6939814457526574
Epoch: 24 | Iteration number: [270/393] 68% | Training loss: 0.693870723468286
Epoch: 24 | Iteration number: [280/393] 71% | Training loss: 0.6937219306826592
Epoch: 24 | Iteration number: [290/393] 73% | Training loss: 0.6936087043120943
Epoch: 24 | Iteration number: [300/393] 76% | Training loss: 0.6935102337598801
Epoch: 24 | Iteration number: [310/393] 78% | Training loss: 0.6934467025341526
Epoch: 24 | Iteration number: [320/393] 81% | Training loss: 0.6933628808706999
Epoch: 24 | Iteration number: [330/393] 83% | Training loss: 0.6933094320875226
Epoch: 24 | Iteration number: [340/393] 86% | Training loss: 0.6932461927918827
Epoch: 24 | Iteration number: [350/393] 89% | Training loss: 0.6932050953592573
Epoch: 24 | Iteration number: [360/393] 91% | Training loss: 0.6931541918052567
Epoch: 24 | Iteration number: [370/393] 94% | Training loss: 0.6931008498410921
Epoch: 24 | Iteration number: [380/393] 96% | Training loss: 0.6930452389152426
Epoch: 24 | Iteration number: [390/393] 99% | Training loss: 0.6929741124312083

 End of epoch: 24 | Train Loss: 0.6911954987443434 | Training Time: 68 

 End of epoch: 24 | Eval Loss: 0.6912501734130236 | Evaluating Time: 17 
Epoch: 25 | Iteration number: [10/393] 2% | Training loss: 0.7606189906597137
Epoch: 25 | Iteration number: [20/393] 5% | Training loss: 0.7254304498434067
Epoch: 25 | Iteration number: [30/393] 7% | Training loss: 0.7136887947718302
Epoch: 25 | Iteration number: [40/393] 10% | Training loss: 0.7082199528813362
Epoch: 25 | Iteration number: [50/393] 12% | Training loss: 0.7050398004055023
Epoch: 25 | Iteration number: [60/393] 15% | Training loss: 0.7027398377656937
Epoch: 25 | Iteration number: [70/393] 17% | Training loss: 0.7008962248052869
Epoch: 25 | Iteration number: [80/393] 20% | Training loss: 0.699648067355156
Epoch: 25 | Iteration number: [90/393] 22% | Training loss: 0.6986600657304128
Epoch: 25 | Iteration number: [100/393] 25% | Training loss: 0.6979566442966462
Epoch: 25 | Iteration number: [110/393] 27% | Training loss: 0.6972711958668448
Epoch: 25 | Iteration number: [120/393] 30% | Training loss: 0.6967491994301478
Epoch: 25 | Iteration number: [130/393] 33% | Training loss: 0.6962923325025119
Epoch: 25 | Iteration number: [140/393] 35% | Training loss: 0.695835594194276
Epoch: 25 | Iteration number: [150/393] 38% | Training loss: 0.6955762994289398
Epoch: 25 | Iteration number: [160/393] 40% | Training loss: 0.6953632585704327
Epoch: 25 | Iteration number: [170/393] 43% | Training loss: 0.6951017832054811
Epoch: 25 | Iteration number: [180/393] 45% | Training loss: 0.6949297567208608
Epoch: 25 | Iteration number: [190/393] 48% | Training loss: 0.6947007389445053
Epoch: 25 | Iteration number: [200/393] 50% | Training loss: 0.6944470447301865
Epoch: 25 | Iteration number: [210/393] 53% | Training loss: 0.6942295145420802
Epoch: 25 | Iteration number: [220/393] 55% | Training loss: 0.6941134165633809
Epoch: 25 | Iteration number: [230/393] 58% | Training loss: 0.6939817565938701
Epoch: 25 | Iteration number: [240/393] 61% | Training loss: 0.6938867909212907
Epoch: 25 | Iteration number: [250/393] 63% | Training loss: 0.6937465348243713
Epoch: 25 | Iteration number: [260/393] 66% | Training loss: 0.6936623295912376
Epoch: 25 | Iteration number: [270/393] 68% | Training loss: 0.6935660861156605
Epoch: 25 | Iteration number: [280/393] 71% | Training loss: 0.6934698792440551
Epoch: 25 | Iteration number: [290/393] 73% | Training loss: 0.6934203135556188
Epoch: 25 | Iteration number: [300/393] 76% | Training loss: 0.6933494873841604
Epoch: 25 | Iteration number: [310/393] 78% | Training loss: 0.6932455003261566
Epoch: 25 | Iteration number: [320/393] 81% | Training loss: 0.6931770749390125
Epoch: 25 | Iteration number: [330/393] 83% | Training loss: 0.6931507421262336
Epoch: 25 | Iteration number: [340/393] 86% | Training loss: 0.6931198006167131
Epoch: 25 | Iteration number: [350/393] 89% | Training loss: 0.6930546574933188
Epoch: 25 | Iteration number: [360/393] 91% | Training loss: 0.6929974524511231
Epoch: 25 | Iteration number: [370/393] 94% | Training loss: 0.6929338592129785
Epoch: 25 | Iteration number: [380/393] 96% | Training loss: 0.6928690733093964
Epoch: 25 | Iteration number: [390/393] 99% | Training loss: 0.6928139272408608

 End of epoch: 25 | Train Loss: 0.6910383191727499 | Training Time: 67 

 End of epoch: 25 | Eval Loss: 0.6912287339872244 | Evaluating Time: 17 
Epoch: 26 | Iteration number: [10/393] 2% | Training loss: 0.7594127178192138
Epoch: 26 | Iteration number: [20/393] 5% | Training loss: 0.7244246959686279
Epoch: 26 | Iteration number: [30/393] 7% | Training loss: 0.7130842685699463
Epoch: 26 | Iteration number: [40/393] 10% | Training loss: 0.7076900407671929
Epoch: 26 | Iteration number: [50/393] 12% | Training loss: 0.7041717100143433
Epoch: 26 | Iteration number: [60/393] 15% | Training loss: 0.7018944581349691
Epoch: 26 | Iteration number: [70/393] 17% | Training loss: 0.7004425082887922
Epoch: 26 | Iteration number: [80/393] 20% | Training loss: 0.699452867358923
Epoch: 26 | Iteration number: [90/393] 22% | Training loss: 0.6985163377390967
Epoch: 26 | Iteration number: [100/393] 25% | Training loss: 0.6977570199966431
Epoch: 26 | Iteration number: [110/393] 27% | Training loss: 0.69716510664333
Epoch: 26 | Iteration number: [120/393] 30% | Training loss: 0.6966008236010869
Epoch: 26 | Iteration number: [130/393] 33% | Training loss: 0.6961140871047974
Epoch: 26 | Iteration number: [140/393] 35% | Training loss: 0.6958307266235352
Epoch: 26 | Iteration number: [150/393] 38% | Training loss: 0.6955749134222666
Epoch: 26 | Iteration number: [160/393] 40% | Training loss: 0.6952627804130316
Epoch: 26 | Iteration number: [170/393] 43% | Training loss: 0.6949491045054268
Epoch: 26 | Iteration number: [180/393] 45% | Training loss: 0.6946810699171491
Epoch: 26 | Iteration number: [190/393] 48% | Training loss: 0.6944671448908354
Epoch: 26 | Iteration number: [200/393] 50% | Training loss: 0.6942979922890663
Epoch: 26 | Iteration number: [210/393] 53% | Training loss: 0.6941417481218065
Epoch: 26 | Iteration number: [220/393] 55% | Training loss: 0.6939910214055668
Epoch: 26 | Iteration number: [230/393] 58% | Training loss: 0.6938806458659794
Epoch: 26 | Iteration number: [240/393] 61% | Training loss: 0.6937483817338943
Epoch: 26 | Iteration number: [250/393] 63% | Training loss: 0.6936663410663605
Epoch: 26 | Iteration number: [260/393] 66% | Training loss: 0.6935647274439152
Epoch: 26 | Iteration number: [270/393] 68% | Training loss: 0.6934544682502747
Epoch: 26 | Iteration number: [280/393] 71% | Training loss: 0.693367167030062
Epoch: 26 | Iteration number: [290/393] 73% | Training loss: 0.6933375385300866
Epoch: 26 | Iteration number: [300/393] 76% | Training loss: 0.6932535700003306
Epoch: 26 | Iteration number: [310/393] 78% | Training loss: 0.6931674299701568
Epoch: 26 | Iteration number: [320/393] 81% | Training loss: 0.6931011861190199
Epoch: 26 | Iteration number: [330/393] 83% | Training loss: 0.6930377929499655
Epoch: 26 | Iteration number: [340/393] 86% | Training loss: 0.6929933651405222
Epoch: 26 | Iteration number: [350/393] 89% | Training loss: 0.6928904708794185
Epoch: 26 | Iteration number: [360/393] 91% | Training loss: 0.6928466897871759
Epoch: 26 | Iteration number: [370/393] 94% | Training loss: 0.6928045424255165
Epoch: 26 | Iteration number: [380/393] 96% | Training loss: 0.6927441063680146
Epoch: 26 | Iteration number: [390/393] 99% | Training loss: 0.6927167045764434

 End of epoch: 26 | Train Loss: 0.6909258925277768 | Training Time: 68 

 End of epoch: 26 | Eval Loss: 0.6910941053409966 | Evaluating Time: 17 
Epoch: 27 | Iteration number: [10/393] 2% | Training loss: 0.7605464816093445
Epoch: 27 | Iteration number: [20/393] 5% | Training loss: 0.7255666762590408
Epoch: 27 | Iteration number: [30/393] 7% | Training loss: 0.7140634059906006
Epoch: 27 | Iteration number: [40/393] 10% | Training loss: 0.7082975700497627
Epoch: 27 | Iteration number: [50/393] 12% | Training loss: 0.7047806906700135
Epoch: 27 | Iteration number: [60/393] 15% | Training loss: 0.7024785826603571
Epoch: 27 | Iteration number: [70/393] 17% | Training loss: 0.7008158266544342
Epoch: 27 | Iteration number: [80/393] 20% | Training loss: 0.6995570488274098
Epoch: 27 | Iteration number: [90/393] 22% | Training loss: 0.6986622009012434
Epoch: 27 | Iteration number: [100/393] 25% | Training loss: 0.6978437095880509
Epoch: 27 | Iteration number: [110/393] 27% | Training loss: 0.6972880926999179
Epoch: 27 | Iteration number: [120/393] 30% | Training loss: 0.6967427467306455
Epoch: 27 | Iteration number: [130/393] 33% | Training loss: 0.6963470280170441
Epoch: 27 | Iteration number: [140/393] 35% | Training loss: 0.6959690596376147
Epoch: 27 | Iteration number: [150/393] 38% | Training loss: 0.6955939054489135
Epoch: 27 | Iteration number: [160/393] 40% | Training loss: 0.6953210208564997
Epoch: 27 | Iteration number: [170/393] 43% | Training loss: 0.6950699469622443
Epoch: 27 | Iteration number: [180/393] 45% | Training loss: 0.6948835213979085
Epoch: 27 | Iteration number: [190/393] 48% | Training loss: 0.6946299556054567
Epoch: 27 | Iteration number: [200/393] 50% | Training loss: 0.6944376665353775
Epoch: 27 | Iteration number: [210/393] 53% | Training loss: 0.6942734244323913
Epoch: 27 | Iteration number: [220/393] 55% | Training loss: 0.6941003718159415
Epoch: 27 | Iteration number: [230/393] 58% | Training loss: 0.6939243267411771
Epoch: 27 | Iteration number: [240/393] 61% | Training loss: 0.6937823101878167
Epoch: 27 | Iteration number: [250/393] 63% | Training loss: 0.693657781124115
Epoch: 27 | Iteration number: [260/393] 66% | Training loss: 0.6935755443114501
Epoch: 27 | Iteration number: [270/393] 68% | Training loss: 0.6934746241128004
Epoch: 27 | Iteration number: [280/393] 71% | Training loss: 0.6933343120983668
Epoch: 27 | Iteration number: [290/393] 73% | Training loss: 0.693226948483237
Epoch: 27 | Iteration number: [300/393] 76% | Training loss: 0.6931402373313904
Epoch: 27 | Iteration number: [310/393] 78% | Training loss: 0.6930736903221376
Epoch: 27 | Iteration number: [320/393] 81% | Training loss: 0.6929910190403461
Epoch: 27 | Iteration number: [330/393] 83% | Training loss: 0.6928926106655237
Epoch: 27 | Iteration number: [340/393] 86% | Training loss: 0.6928546149941052
Epoch: 27 | Iteration number: [350/393] 89% | Training loss: 0.6927751052379608
Epoch: 27 | Iteration number: [360/393] 91% | Training loss: 0.6927330687642097
Epoch: 27 | Iteration number: [370/393] 94% | Training loss: 0.692678524674596
Epoch: 27 | Iteration number: [380/393] 96% | Training loss: 0.692621312015935
Epoch: 27 | Iteration number: [390/393] 99% | Training loss: 0.6925884399658594

 End of epoch: 27 | Train Loss: 0.6908147495818199 | Training Time: 67 

 End of epoch: 27 | Eval Loss: 0.691065501193611 | Evaluating Time: 18 
Epoch: 28 | Iteration number: [10/393] 2% | Training loss: 0.7599048733711242
Epoch: 28 | Iteration number: [20/393] 5% | Training loss: 0.7249962747097015
Epoch: 28 | Iteration number: [30/393] 7% | Training loss: 0.713643592596054
Epoch: 28 | Iteration number: [40/393] 10% | Training loss: 0.7081795513629914
Epoch: 28 | Iteration number: [50/393] 12% | Training loss: 0.7044983279705047
Epoch: 28 | Iteration number: [60/393] 15% | Training loss: 0.7022496928771337
Epoch: 28 | Iteration number: [70/393] 17% | Training loss: 0.7006613458905901
Epoch: 28 | Iteration number: [80/393] 20% | Training loss: 0.6994350381195545
Epoch: 28 | Iteration number: [90/393] 22% | Training loss: 0.6984655949804518
Epoch: 28 | Iteration number: [100/393] 25% | Training loss: 0.6976773357391357
Epoch: 28 | Iteration number: [110/393] 27% | Training loss: 0.6971298786726865
Epoch: 28 | Iteration number: [120/393] 30% | Training loss: 0.6966764936844508
Epoch: 28 | Iteration number: [130/393] 33% | Training loss: 0.6962373064114498
Epoch: 28 | Iteration number: [140/393] 35% | Training loss: 0.6958160809108189
Epoch: 28 | Iteration number: [150/393] 38% | Training loss: 0.6955217186609904
Epoch: 28 | Iteration number: [160/393] 40% | Training loss: 0.6952056385576725
Epoch: 28 | Iteration number: [170/393] 43% | Training loss: 0.6949541877297795
Epoch: 28 | Iteration number: [180/393] 45% | Training loss: 0.6947231153647105
Epoch: 28 | Iteration number: [190/393] 48% | Training loss: 0.6944495436392333
Epoch: 28 | Iteration number: [200/393] 50% | Training loss: 0.694216277897358
Epoch: 28 | Iteration number: [210/393] 53% | Training loss: 0.694067599092211
Epoch: 28 | Iteration number: [220/393] 55% | Training loss: 0.6939663391221653
Epoch: 28 | Iteration number: [230/393] 58% | Training loss: 0.6937930534715238
Epoch: 28 | Iteration number: [240/393] 61% | Training loss: 0.6936579155425231
Epoch: 28 | Iteration number: [250/393] 63% | Training loss: 0.693552696943283
Epoch: 28 | Iteration number: [260/393] 66% | Training loss: 0.6934736934991983
Epoch: 28 | Iteration number: [270/393] 68% | Training loss: 0.6933641054012157
Epoch: 28 | Iteration number: [280/393] 71% | Training loss: 0.6932604640722275
Epoch: 28 | Iteration number: [290/393] 73% | Training loss: 0.6931776831889974
Epoch: 28 | Iteration number: [300/393] 76% | Training loss: 0.6930878553787867
Epoch: 28 | Iteration number: [310/393] 78% | Training loss: 0.6930302571865821
Epoch: 28 | Iteration number: [320/393] 81% | Training loss: 0.6929957455024123
Epoch: 28 | Iteration number: [330/393] 83% | Training loss: 0.6929381569226583
Epoch: 28 | Iteration number: [340/393] 86% | Training loss: 0.692854574673316
Epoch: 28 | Iteration number: [350/393] 89% | Training loss: 0.6927906688622066
Epoch: 28 | Iteration number: [360/393] 91% | Training loss: 0.6926998042398029
Epoch: 28 | Iteration number: [370/393] 94% | Training loss: 0.6926319191584716
Epoch: 28 | Iteration number: [380/393] 96% | Training loss: 0.6925712814456538
Epoch: 28 | Iteration number: [390/393] 99% | Training loss: 0.692536257322018

 End of epoch: 28 | Train Loss: 0.6907562989618335 | Training Time: 68 

 End of epoch: 28 | Eval Loss: 0.6915649881168288 | Evaluating Time: 17 
Epoch: 29 | Iteration number: [10/393] 2% | Training loss: 0.7605152189731598
Epoch: 29 | Iteration number: [20/393] 5% | Training loss: 0.7255530387163163
Epoch: 29 | Iteration number: [30/393] 7% | Training loss: 0.7141383508841197
Epoch: 29 | Iteration number: [40/393] 10% | Training loss: 0.7084084659814834
Epoch: 29 | Iteration number: [50/393] 12% | Training loss: 0.7048435509204865
Epoch: 29 | Iteration number: [60/393] 15% | Training loss: 0.7025440732638041
Epoch: 29 | Iteration number: [70/393] 17% | Training loss: 0.700895174912044
Epoch: 29 | Iteration number: [80/393] 20% | Training loss: 0.6996827676892281
Epoch: 29 | Iteration number: [90/393] 22% | Training loss: 0.6986721840169695
Epoch: 29 | Iteration number: [100/393] 25% | Training loss: 0.6978201299905777
Epoch: 29 | Iteration number: [110/393] 27% | Training loss: 0.6972243081439625
Epoch: 29 | Iteration number: [120/393] 30% | Training loss: 0.6967485447724661
Epoch: 29 | Iteration number: [130/393] 33% | Training loss: 0.696237915295821
Epoch: 29 | Iteration number: [140/393] 35% | Training loss: 0.6958918741771153
Epoch: 29 | Iteration number: [150/393] 38% | Training loss: 0.6955753131707509
Epoch: 29 | Iteration number: [160/393] 40% | Training loss: 0.6952788207679987
Epoch: 29 | Iteration number: [170/393] 43% | Training loss: 0.6949378739385044
Epoch: 29 | Iteration number: [180/393] 45% | Training loss: 0.6946994354327519
Epoch: 29 | Iteration number: [190/393] 48% | Training loss: 0.6944431565309825
Epoch: 29 | Iteration number: [200/393] 50% | Training loss: 0.6942387163639069
Epoch: 29 | Iteration number: [210/393] 53% | Training loss: 0.6940944050039564
Epoch: 29 | Iteration number: [220/393] 55% | Training loss: 0.6939391694285653
Epoch: 29 | Iteration number: [230/393] 58% | Training loss: 0.6938189781230429
Epoch: 29 | Iteration number: [240/393] 61% | Training loss: 0.6936802943547566
Epoch: 29 | Iteration number: [250/393] 63% | Training loss: 0.6935481181144715
Epoch: 29 | Iteration number: [260/393] 66% | Training loss: 0.6934175456945713
Epoch: 29 | Iteration number: [270/393] 68% | Training loss: 0.6933293583216491
Epoch: 29 | Iteration number: [280/393] 71% | Training loss: 0.6932671872632844
Epoch: 29 | Iteration number: [290/393] 73% | Training loss: 0.6932391337279615
Epoch: 29 | Iteration number: [300/393] 76% | Training loss: 0.6931290966272354
Epoch: 29 | Iteration number: [310/393] 78% | Training loss: 0.6930621310587852
Epoch: 29 | Iteration number: [320/393] 81% | Training loss: 0.6929598128423095
Epoch: 29 | Iteration number: [330/393] 83% | Training loss: 0.6928801919474746
Epoch: 29 | Iteration number: [340/393] 86% | Training loss: 0.6928115008508458
Epoch: 29 | Iteration number: [350/393] 89% | Training loss: 0.6927173164912632
Epoch: 29 | Iteration number: [360/393] 91% | Training loss: 0.6926474024852117
Epoch: 29 | Iteration number: [370/393] 94% | Training loss: 0.6925905839816944
Epoch: 29 | Iteration number: [380/393] 96% | Training loss: 0.6925557687094337
Epoch: 29 | Iteration number: [390/393] 99% | Training loss: 0.6925220744732099

 End of epoch: 29 | Train Loss: 0.690746338009531 | Training Time: 68 

 End of epoch: 29 | Eval Loss: 0.6910519076853382 | Evaluating Time: 17 
Epoch: 30 | Iteration number: [10/393] 2% | Training loss: 0.7582833945751191
Epoch: 30 | Iteration number: [20/393] 5% | Training loss: 0.7246240079402924
Epoch: 30 | Iteration number: [30/393] 7% | Training loss: 0.7134896914164225
Epoch: 30 | Iteration number: [40/393] 10% | Training loss: 0.7076820626854896
Epoch: 30 | Iteration number: [50/393] 12% | Training loss: 0.7042750072479248
Epoch: 30 | Iteration number: [60/393] 15% | Training loss: 0.7021236250797908
Epoch: 30 | Iteration number: [70/393] 17% | Training loss: 0.700444175515856
Epoch: 30 | Iteration number: [80/393] 20% | Training loss: 0.699185474216938
Epoch: 30 | Iteration number: [90/393] 22% | Training loss: 0.698167993625005
Epoch: 30 | Iteration number: [100/393] 25% | Training loss: 0.6974458295106888
Epoch: 30 | Iteration number: [110/393] 27% | Training loss: 0.6968374572016977
Epoch: 30 | Iteration number: [120/393] 30% | Training loss: 0.6963353564341863
Epoch: 30 | Iteration number: [130/393] 33% | Training loss: 0.6959476956954369
Epoch: 30 | Iteration number: [140/393] 35% | Training loss: 0.6954756549426487
Epoch: 30 | Iteration number: [150/393] 38% | Training loss: 0.6951937186717987
Epoch: 30 | Iteration number: [160/393] 40% | Training loss: 0.6949603714048862
Epoch: 30 | Iteration number: [170/393] 43% | Training loss: 0.6947683706003077
Epoch: 30 | Iteration number: [180/393] 45% | Training loss: 0.6944807489713033
Epoch: 30 | Iteration number: [190/393] 48% | Training loss: 0.6943031157317915
Epoch: 30 | Iteration number: [200/393] 50% | Training loss: 0.6941460952162742
Epoch: 30 | Iteration number: [210/393] 53% | Training loss: 0.6939918347767421
Epoch: 30 | Iteration number: [220/393] 55% | Training loss: 0.6938183491880243
Epoch: 30 | Iteration number: [230/393] 58% | Training loss: 0.6936918279399042
Epoch: 30 | Iteration number: [240/393] 61% | Training loss: 0.6935746843616167
Epoch: 30 | Iteration number: [250/393] 63% | Training loss: 0.6934838869571686
Epoch: 30 | Iteration number: [260/393] 66% | Training loss: 0.6933898464991496
Epoch: 30 | Iteration number: [270/393] 68% | Training loss: 0.6932825706623219
Epoch: 30 | Iteration number: [280/393] 71% | Training loss: 0.6931871573839868
Epoch: 30 | Iteration number: [290/393] 73% | Training loss: 0.6931547822623417
Epoch: 30 | Iteration number: [300/393] 76% | Training loss: 0.6930942328770956
Epoch: 30 | Iteration number: [310/393] 78% | Training loss: 0.6929611352182203
Epoch: 30 | Iteration number: [320/393] 81% | Training loss: 0.6929024387151003
Epoch: 30 | Iteration number: [330/393] 83% | Training loss: 0.6928315115697457
Epoch: 30 | Iteration number: [340/393] 86% | Training loss: 0.6927554659983691
Epoch: 30 | Iteration number: [350/393] 89% | Training loss: 0.6926989790371486
Epoch: 30 | Iteration number: [360/393] 91% | Training loss: 0.6926596209406852
Epoch: 30 | Iteration number: [370/393] 94% | Training loss: 0.6926146769845808
Epoch: 30 | Iteration number: [380/393] 96% | Training loss: 0.692552335638749
Epoch: 30 | Iteration number: [390/393] 99% | Training loss: 0.6925300408632328

 End of epoch: 30 | Train Loss: 0.6907561165079209 | Training Time: 67 

 End of epoch: 30 | Eval Loss: 0.6909779760302329 | Evaluating Time: 17 
Epoch: 31 | Iteration number: [10/393] 2% | Training loss: 0.7593413829803467
Epoch: 31 | Iteration number: [20/393] 5% | Training loss: 0.7253684014081955
Epoch: 31 | Iteration number: [30/393] 7% | Training loss: 0.7136180063088735
Epoch: 31 | Iteration number: [40/393] 10% | Training loss: 0.7076955914497376
Epoch: 31 | Iteration number: [50/393] 12% | Training loss: 0.704412704706192
Epoch: 31 | Iteration number: [60/393] 15% | Training loss: 0.7022433271010716
Epoch: 31 | Iteration number: [70/393] 17% | Training loss: 0.7006670194012778
Epoch: 31 | Iteration number: [80/393] 20% | Training loss: 0.6994875013828278
Epoch: 31 | Iteration number: [90/393] 22% | Training loss: 0.6985761463642121
Epoch: 31 | Iteration number: [100/393] 25% | Training loss: 0.6978665971755982
Epoch: 31 | Iteration number: [110/393] 27% | Training loss: 0.6972298367456956
Epoch: 31 | Iteration number: [120/393] 30% | Training loss: 0.696698700884978
Epoch: 31 | Iteration number: [130/393] 33% | Training loss: 0.6962453975127294
Epoch: 31 | Iteration number: [140/393] 35% | Training loss: 0.6958582861082895
Epoch: 31 | Iteration number: [150/393] 38% | Training loss: 0.6954940116405487
Epoch: 31 | Iteration number: [160/393] 40% | Training loss: 0.6951715249568224
Epoch: 31 | Iteration number: [170/393] 43% | Training loss: 0.6949045104138991
Epoch: 31 | Iteration number: [180/393] 45% | Training loss: 0.6946613871388965
Epoch: 31 | Iteration number: [190/393] 48% | Training loss: 0.6944333409008226
Epoch: 31 | Iteration number: [200/393] 50% | Training loss: 0.6941955184936524
Epoch: 31 | Iteration number: [210/393] 53% | Training loss: 0.6940333695638747
Epoch: 31 | Iteration number: [220/393] 55% | Training loss: 0.6938159658150239
Epoch: 31 | Iteration number: [230/393] 58% | Training loss: 0.6936741424643476
Epoch: 31 | Iteration number: [240/393] 61% | Training loss: 0.693516072879235
Epoch: 31 | Iteration number: [250/393] 63% | Training loss: 0.6934512434005737
Epoch: 31 | Iteration number: [260/393] 66% | Training loss: 0.6933674557850911
Epoch: 31 | Iteration number: [270/393] 68% | Training loss: 0.6932528235294201
Epoch: 31 | Iteration number: [280/393] 71% | Training loss: 0.6931898996233941
Epoch: 31 | Iteration number: [290/393] 73% | Training loss: 0.6931177743550004
Epoch: 31 | Iteration number: [300/393] 76% | Training loss: 0.6930198655525843
Epoch: 31 | Iteration number: [310/393] 78% | Training loss: 0.6929312957871345
Epoch: 31 | Iteration number: [320/393] 81% | Training loss: 0.6928315233439207
Epoch: 31 | Iteration number: [330/393] 83% | Training loss: 0.6927826102935907
Epoch: 31 | Iteration number: [340/393] 86% | Training loss: 0.6927280967726427
Epoch: 31 | Iteration number: [350/393] 89% | Training loss: 0.6926658831323896
Epoch: 31 | Iteration number: [360/393] 91% | Training loss: 0.6926057078772121
Epoch: 31 | Iteration number: [370/393] 94% | Training loss: 0.6925099303593507
Epoch: 31 | Iteration number: [380/393] 96% | Training loss: 0.6924824357032776
Epoch: 31 | Iteration number: [390/393] 99% | Training loss: 0.6924424646756588

 End of epoch: 31 | Train Loss: 0.6906792016429756 | Training Time: 67 

 End of epoch: 31 | Eval Loss: 0.6911455307688031 | Evaluating Time: 17 
Epoch: 32 | Iteration number: [10/393] 2% | Training loss: 0.7598835527896881
Epoch: 32 | Iteration number: [20/393] 5% | Training loss: 0.7253936916589737
Epoch: 32 | Iteration number: [30/393] 7% | Training loss: 0.7136607348918915
Epoch: 32 | Iteration number: [40/393] 10% | Training loss: 0.7079525008797646
Epoch: 32 | Iteration number: [50/393] 12% | Training loss: 0.7046125888824463
Epoch: 32 | Iteration number: [60/393] 15% | Training loss: 0.7021938304106394
Epoch: 32 | Iteration number: [70/393] 17% | Training loss: 0.7006576580660684
Epoch: 32 | Iteration number: [80/393] 20% | Training loss: 0.6994607843458652
Epoch: 32 | Iteration number: [90/393] 22% | Training loss: 0.6984283056524064
Epoch: 32 | Iteration number: [100/393] 25% | Training loss: 0.697650848031044
Epoch: 32 | Iteration number: [110/393] 27% | Training loss: 0.697069117155942
Epoch: 32 | Iteration number: [120/393] 30% | Training loss: 0.6965848555167516
Epoch: 32 | Iteration number: [130/393] 33% | Training loss: 0.6961634218692779
Epoch: 32 | Iteration number: [140/393] 35% | Training loss: 0.6957687761102404
Epoch: 32 | Iteration number: [150/393] 38% | Training loss: 0.6954665009180705
Epoch: 32 | Iteration number: [160/393] 40% | Training loss: 0.6952077500522137
Epoch: 32 | Iteration number: [170/393] 43% | Training loss: 0.6950294859269086
Epoch: 32 | Iteration number: [180/393] 45% | Training loss: 0.6947698258691364
Epoch: 32 | Iteration number: [190/393] 48% | Training loss: 0.6945433525662673
Epoch: 32 | Iteration number: [200/393] 50% | Training loss: 0.6943022775650024
Epoch: 32 | Iteration number: [210/393] 53% | Training loss: 0.6940539501962207
Epoch: 32 | Iteration number: [220/393] 55% | Training loss: 0.6938745113936338
Epoch: 32 | Iteration number: [230/393] 58% | Training loss: 0.693712478098662
Epoch: 32 | Iteration number: [240/393] 61% | Training loss: 0.6936002078155676
Epoch: 32 | Iteration number: [250/393] 63% | Training loss: 0.693456702709198
Epoch: 32 | Iteration number: [260/393] 66% | Training loss: 0.6932872898303546
Epoch: 32 | Iteration number: [270/393] 68% | Training loss: 0.6931658992060908
Epoch: 32 | Iteration number: [280/393] 71% | Training loss: 0.693038552573749
Epoch: 32 | Iteration number: [290/393] 73% | Training loss: 0.6929103343651213
Epoch: 32 | Iteration number: [300/393] 76% | Training loss: 0.6927961595853169
Epoch: 32 | Iteration number: [310/393] 78% | Training loss: 0.692751766789344
Epoch: 32 | Iteration number: [320/393] 81% | Training loss: 0.6926652858033776
Epoch: 32 | Iteration number: [330/393] 83% | Training loss: 0.6926031643694097
Epoch: 32 | Iteration number: [340/393] 86% | Training loss: 0.6925742526264752
Epoch: 32 | Iteration number: [350/393] 89% | Training loss: 0.6925253776141576
Epoch: 32 | Iteration number: [360/393] 91% | Training loss: 0.6924795061349869
Epoch: 32 | Iteration number: [370/393] 94% | Training loss: 0.692427487147821
Epoch: 32 | Iteration number: [380/393] 96% | Training loss: 0.6923934776532022
Epoch: 32 | Iteration number: [390/393] 99% | Training loss: 0.6923714420734308

 End of epoch: 32 | Train Loss: 0.6905828644604477 | Training Time: 66 

 End of epoch: 32 | Eval Loss: 0.6908920565429999 | Evaluating Time: 17 
Epoch: 33 | Iteration number: [10/393] 2% | Training loss: 0.7599863648414612
Epoch: 33 | Iteration number: [20/393] 5% | Training loss: 0.7248763501644134
Epoch: 33 | Iteration number: [30/393] 7% | Training loss: 0.7130519270896911
Epoch: 33 | Iteration number: [40/393] 10% | Training loss: 0.7074880927801133
Epoch: 33 | Iteration number: [50/393] 12% | Training loss: 0.7041867184638977
Epoch: 33 | Iteration number: [60/393] 15% | Training loss: 0.7019981135924657
Epoch: 33 | Iteration number: [70/393] 17% | Training loss: 0.7003783668790545
Epoch: 33 | Iteration number: [80/393] 20% | Training loss: 0.6990875847637653
Epoch: 33 | Iteration number: [90/393] 22% | Training loss: 0.6981125632921855
Epoch: 33 | Iteration number: [100/393] 25% | Training loss: 0.6974766385555268
Epoch: 33 | Iteration number: [110/393] 27% | Training loss: 0.6969467157667334
Epoch: 33 | Iteration number: [120/393] 30% | Training loss: 0.6965262706081072
Epoch: 33 | Iteration number: [130/393] 33% | Training loss: 0.6960743890358851
Epoch: 33 | Iteration number: [140/393] 35% | Training loss: 0.695693085023335
Epoch: 33 | Iteration number: [150/393] 38% | Training loss: 0.6952742246786753
Epoch: 33 | Iteration number: [160/393] 40% | Training loss: 0.6950482726097107
Epoch: 33 | Iteration number: [170/393] 43% | Training loss: 0.6947050364578471
Epoch: 33 | Iteration number: [180/393] 45% | Training loss: 0.6944855736361609
Epoch: 33 | Iteration number: [190/393] 48% | Training loss: 0.6942355701797887
Epoch: 33 | Iteration number: [200/393] 50% | Training loss: 0.6940652886033059
Epoch: 33 | Iteration number: [210/393] 53% | Training loss: 0.6938798546791076
Epoch: 33 | Iteration number: [220/393] 55% | Training loss: 0.6936952021988956
Epoch: 33 | Iteration number: [230/393] 58% | Training loss: 0.6935732794844586
Epoch: 33 | Iteration number: [240/393] 61% | Training loss: 0.6934820388754209
Epoch: 33 | Iteration number: [250/393] 63% | Training loss: 0.6933447070121765
Epoch: 33 | Iteration number: [260/393] 66% | Training loss: 0.693204558812655
Epoch: 33 | Iteration number: [270/393] 68% | Training loss: 0.6930964441211135
Epoch: 33 | Iteration number: [280/393] 71% | Training loss: 0.6929941613759313
Epoch: 33 | Iteration number: [290/393] 73% | Training loss: 0.6929402608295967
Epoch: 33 | Iteration number: [300/393] 76% | Training loss: 0.6928810596466064
Epoch: 33 | Iteration number: [310/393] 78% | Training loss: 0.6927864895712945
Epoch: 33 | Iteration number: [320/393] 81% | Training loss: 0.6927198074758053
Epoch: 33 | Iteration number: [330/393] 83% | Training loss: 0.6926817493005233
Epoch: 33 | Iteration number: [340/393] 86% | Training loss: 0.6925932914018631
Epoch: 33 | Iteration number: [350/393] 89% | Training loss: 0.6925612900938306
Epoch: 33 | Iteration number: [360/393] 91% | Training loss: 0.6925222466389338
Epoch: 33 | Iteration number: [370/393] 94% | Training loss: 0.6924849271774292
Epoch: 33 | Iteration number: [380/393] 96% | Training loss: 0.6924574695135418
Epoch: 33 | Iteration number: [390/393] 99% | Training loss: 0.6924112685215779

 End of epoch: 33 | Train Loss: 0.6906196672194483 | Training Time: 67 

 End of epoch: 33 | Eval Loss: 0.6908558521951947 | Evaluating Time: 17 
Epoch: 34 | Iteration number: [10/393] 2% | Training loss: 0.7599765300750733
Epoch: 34 | Iteration number: [20/393] 5% | Training loss: 0.7249248415231705
Epoch: 34 | Iteration number: [30/393] 7% | Training loss: 0.7135344445705414
Epoch: 34 | Iteration number: [40/393] 10% | Training loss: 0.7077695548534393
Epoch: 34 | Iteration number: [50/393] 12% | Training loss: 0.7043747484683991
Epoch: 34 | Iteration number: [60/393] 15% | Training loss: 0.7020846496025721
Epoch: 34 | Iteration number: [70/393] 17% | Training loss: 0.7004435530730656
Epoch: 34 | Iteration number: [80/393] 20% | Training loss: 0.6992232851684094
Epoch: 34 | Iteration number: [90/393] 22% | Training loss: 0.6981749984953138
Epoch: 34 | Iteration number: [100/393] 25% | Training loss: 0.6974159270524979
Epoch: 34 | Iteration number: [110/393] 27% | Training loss: 0.6967249778184024
Epoch: 34 | Iteration number: [120/393] 30% | Training loss: 0.6961516017715136
Epoch: 34 | Iteration number: [130/393] 33% | Training loss: 0.6958454994054941
Epoch: 34 | Iteration number: [140/393] 35% | Training loss: 0.6955958932638169
Epoch: 34 | Iteration number: [150/393] 38% | Training loss: 0.6953410136699677
Epoch: 34 | Iteration number: [160/393] 40% | Training loss: 0.6949956268072128
Epoch: 34 | Iteration number: [170/393] 43% | Training loss: 0.6948214723783381
Epoch: 34 | Iteration number: [180/393] 45% | Training loss: 0.6946366611454222
Epoch: 34 | Iteration number: [190/393] 48% | Training loss: 0.6944919658334632
Epoch: 34 | Iteration number: [200/393] 50% | Training loss: 0.6942725914716721
Epoch: 34 | Iteration number: [210/393] 53% | Training loss: 0.6940986491384961
Epoch: 34 | Iteration number: [220/393] 55% | Training loss: 0.6939899216998707
Epoch: 34 | Iteration number: [230/393] 58% | Training loss: 0.6938764647297238
Epoch: 34 | Iteration number: [240/393] 61% | Training loss: 0.6937757370372614
Epoch: 34 | Iteration number: [250/393] 63% | Training loss: 0.6936481881141663
Epoch: 34 | Iteration number: [260/393] 66% | Training loss: 0.6935619445947501
Epoch: 34 | Iteration number: [270/393] 68% | Training loss: 0.6934794428171935
Epoch: 34 | Iteration number: [280/393] 71% | Training loss: 0.6933907389640808
Epoch: 34 | Iteration number: [290/393] 73% | Training loss: 0.6932768957368258
Epoch: 34 | Iteration number: [300/393] 76% | Training loss: 0.6931663791338603
Epoch: 34 | Iteration number: [310/393] 78% | Training loss: 0.6930565126480595
Epoch: 34 | Iteration number: [320/393] 81% | Training loss: 0.6929666250944138
Epoch: 34 | Iteration number: [330/393] 83% | Training loss: 0.6928942617141839
Epoch: 34 | Iteration number: [340/393] 86% | Training loss: 0.6928360295646331
Epoch: 34 | Iteration number: [350/393] 89% | Training loss: 0.6927833490712302
Epoch: 34 | Iteration number: [360/393] 91% | Training loss: 0.6927325064937274
Epoch: 34 | Iteration number: [370/393] 94% | Training loss: 0.6926780467097824
Epoch: 34 | Iteration number: [380/393] 96% | Training loss: 0.6926143177245793
Epoch: 34 | Iteration number: [390/393] 99% | Training loss: 0.6925820298683949

 End of epoch: 34 | Train Loss: 0.6907948900118432 | Training Time: 67 

 End of epoch: 34 | Eval Loss: 0.6909969400386421 | Evaluating Time: 17 
Epoch: 35 | Iteration number: [10/393] 2% | Training loss: 0.7592722177505493
Epoch: 35 | Iteration number: [20/393] 5% | Training loss: 0.7249584078788758
Epoch: 35 | Iteration number: [30/393] 7% | Training loss: 0.7134399811426798
Epoch: 35 | Iteration number: [40/393] 10% | Training loss: 0.707664392888546
Epoch: 35 | Iteration number: [50/393] 12% | Training loss: 0.7041788852214813
Epoch: 35 | Iteration number: [60/393] 15% | Training loss: 0.7020007073879242
Epoch: 35 | Iteration number: [70/393] 17% | Training loss: 0.7003944686480931
Epoch: 35 | Iteration number: [80/393] 20% | Training loss: 0.6993419416248798
Epoch: 35 | Iteration number: [90/393] 22% | Training loss: 0.698393647538291
Epoch: 35 | Iteration number: [100/393] 25% | Training loss: 0.6977119445800781
Epoch: 35 | Iteration number: [110/393] 27% | Training loss: 0.6970731160857461
Epoch: 35 | Iteration number: [120/393] 30% | Training loss: 0.6964188272754351
Epoch: 35 | Iteration number: [130/393] 33% | Training loss: 0.6959471445817214
Epoch: 35 | Iteration number: [140/393] 35% | Training loss: 0.6955332704952785
Epoch: 35 | Iteration number: [150/393] 38% | Training loss: 0.6952583901087444
Epoch: 35 | Iteration number: [160/393] 40% | Training loss: 0.6948564395308494
Epoch: 35 | Iteration number: [170/393] 43% | Training loss: 0.6946262980208677
Epoch: 35 | Iteration number: [180/393] 45% | Training loss: 0.6944155759281583
Epoch: 35 | Iteration number: [190/393] 48% | Training loss: 0.6941643815291555
Epoch: 35 | Iteration number: [200/393] 50% | Training loss: 0.6939426109194755
Epoch: 35 | Iteration number: [210/393] 53% | Training loss: 0.6938102058001927
Epoch: 35 | Iteration number: [220/393] 55% | Training loss: 0.6936746632510965
Epoch: 35 | Iteration number: [230/393] 58% | Training loss: 0.6935509764629861
Epoch: 35 | Iteration number: [240/393] 61% | Training loss: 0.6934008662899335
Epoch: 35 | Iteration number: [250/393] 63% | Training loss: 0.6932655656337738
Epoch: 35 | Iteration number: [260/393] 66% | Training loss: 0.6930891073667086
Epoch: 35 | Iteration number: [270/393] 68% | Training loss: 0.6929791017814919
Epoch: 35 | Iteration number: [280/393] 71% | Training loss: 0.6928766486900193
Epoch: 35 | Iteration number: [290/393] 73% | Training loss: 0.6928417004387954
Epoch: 35 | Iteration number: [300/393] 76% | Training loss: 0.6927925056219101
Epoch: 35 | Iteration number: [310/393] 78% | Training loss: 0.6926894314827458
Epoch: 35 | Iteration number: [320/393] 81% | Training loss: 0.6926208065822721
Epoch: 35 | Iteration number: [330/393] 83% | Training loss: 0.6925762189157081
Epoch: 35 | Iteration number: [340/393] 86% | Training loss: 0.6925270676612854
Epoch: 35 | Iteration number: [350/393] 89% | Training loss: 0.6924828675815037
Epoch: 35 | Iteration number: [360/393] 91% | Training loss: 0.6924452260136604
Epoch: 35 | Iteration number: [370/393] 94% | Training loss: 0.6923907284801071
Epoch: 35 | Iteration number: [380/393] 96% | Training loss: 0.692330077761098
Epoch: 35 | Iteration number: [390/393] 99% | Training loss: 0.6922978080235995

 End of epoch: 35 | Train Loss: 0.6905218741972634 | Training Time: 67 

 End of epoch: 35 | Eval Loss: 0.6909402621035673 | Evaluating Time: 17 
Epoch: 36 | Iteration number: [10/393] 2% | Training loss: 0.7593738257884979
Epoch: 36 | Iteration number: [20/393] 5% | Training loss: 0.7249077498912812
Epoch: 36 | Iteration number: [30/393] 7% | Training loss: 0.7133559346199035
Epoch: 36 | Iteration number: [40/393] 10% | Training loss: 0.7078167244791984
Epoch: 36 | Iteration number: [50/393] 12% | Training loss: 0.704063013792038
Epoch: 36 | Iteration number: [60/393] 15% | Training loss: 0.7017476101716359
Epoch: 36 | Iteration number: [70/393] 17% | Training loss: 0.7002000374453409
Epoch: 36 | Iteration number: [80/393] 20% | Training loss: 0.6989242374897003
Epoch: 36 | Iteration number: [90/393] 22% | Training loss: 0.6978952679369185
Epoch: 36 | Iteration number: [100/393] 25% | Training loss: 0.6971788305044174
Epoch: 36 | Iteration number: [110/393] 27% | Training loss: 0.6965002054517919
Epoch: 36 | Iteration number: [120/393] 30% | Training loss: 0.6959787329037984
Epoch: 36 | Iteration number: [130/393] 33% | Training loss: 0.6955682818706219
Epoch: 36 | Iteration number: [140/393] 35% | Training loss: 0.6952270235334124
Epoch: 36 | Iteration number: [150/393] 38% | Training loss: 0.6949170196056366
Epoch: 36 | Iteration number: [160/393] 40% | Training loss: 0.6946299109607935
Epoch: 36 | Iteration number: [170/393] 43% | Training loss: 0.6943744848756229
Epoch: 36 | Iteration number: [180/393] 45% | Training loss: 0.6941600776380963
Epoch: 36 | Iteration number: [190/393] 48% | Training loss: 0.6939647229094255
Epoch: 36 | Iteration number: [200/393] 50% | Training loss: 0.6938243708014489
Epoch: 36 | Iteration number: [210/393] 53% | Training loss: 0.6936399658521016
Epoch: 36 | Iteration number: [220/393] 55% | Training loss: 0.6935492829843001
Epoch: 36 | Iteration number: [230/393] 58% | Training loss: 0.6933941548285277
Epoch: 36 | Iteration number: [240/393] 61% | Training loss: 0.6933112184206645
Epoch: 36 | Iteration number: [250/393] 63% | Training loss: 0.6931213932037353
Epoch: 36 | Iteration number: [260/393] 66% | Training loss: 0.6930118961976125
Epoch: 36 | Iteration number: [270/393] 68% | Training loss: 0.6929273589893624
Epoch: 36 | Iteration number: [280/393] 71% | Training loss: 0.692821413065706
Epoch: 36 | Iteration number: [290/393] 73% | Training loss: 0.6927437410272401
Epoch: 36 | Iteration number: [300/393] 76% | Training loss: 0.6926617650190989
Epoch: 36 | Iteration number: [310/393] 78% | Training loss: 0.6925754447137156
Epoch: 36 | Iteration number: [320/393] 81% | Training loss: 0.6925378475338221
Epoch: 36 | Iteration number: [330/393] 83% | Training loss: 0.6924898340846553
Epoch: 36 | Iteration number: [340/393] 86% | Training loss: 0.6923997212858761
Epoch: 36 | Iteration number: [350/393] 89% | Training loss: 0.6923585740157536
Epoch: 36 | Iteration number: [360/393] 91% | Training loss: 0.6923241164949205
Epoch: 36 | Iteration number: [370/393] 94% | Training loss: 0.6922901646510975
Epoch: 36 | Iteration number: [380/393] 96% | Training loss: 0.6922662738122438
Epoch: 36 | Iteration number: [390/393] 99% | Training loss: 0.6922498061106755

 End of epoch: 36 | Train Loss: 0.6904709017610429 | Training Time: 67 

 End of epoch: 36 | Eval Loss: 0.6910589677946908 | Evaluating Time: 17 
Epoch: 37 | Iteration number: [10/393] 2% | Training loss: 0.759663724899292
Epoch: 37 | Iteration number: [20/393] 5% | Training loss: 0.7243857502937316
Epoch: 37 | Iteration number: [30/393] 7% | Training loss: 0.713329037030538
Epoch: 37 | Iteration number: [40/393] 10% | Training loss: 0.7073994159698487
Epoch: 37 | Iteration number: [50/393] 12% | Training loss: 0.7042275869846344
Epoch: 37 | Iteration number: [60/393] 15% | Training loss: 0.702033190925916
Epoch: 37 | Iteration number: [70/393] 17% | Training loss: 0.700242714371
Epoch: 37 | Iteration number: [80/393] 20% | Training loss: 0.6989717870950699
Epoch: 37 | Iteration number: [90/393] 22% | Training loss: 0.6979675869146983
Epoch: 37 | Iteration number: [100/393] 25% | Training loss: 0.6972699224948883
Epoch: 37 | Iteration number: [110/393] 27% | Training loss: 0.6966958788308231
Epoch: 37 | Iteration number: [120/393] 30% | Training loss: 0.6960566009084383
Epoch: 37 | Iteration number: [130/393] 33% | Training loss: 0.6956682131840632
Epoch: 37 | Iteration number: [140/393] 35% | Training loss: 0.695335014803069
Epoch: 37 | Iteration number: [150/393] 38% | Training loss: 0.6949403675397238
Epoch: 37 | Iteration number: [160/393] 40% | Training loss: 0.6946530275046825
Epoch: 37 | Iteration number: [170/393] 43% | Training loss: 0.6944253704127143
Epoch: 37 | Iteration number: [180/393] 45% | Training loss: 0.6942138953341378
Epoch: 37 | Iteration number: [190/393] 48% | Training loss: 0.6939499920920322
Epoch: 37 | Iteration number: [200/393] 50% | Training loss: 0.6937761837244034
Epoch: 37 | Iteration number: [210/393] 53% | Training loss: 0.693617362067813
Epoch: 37 | Iteration number: [220/393] 55% | Training loss: 0.6934804902835325
Epoch: 37 | Iteration number: [230/393] 58% | Training loss: 0.6933633983135223
Epoch: 37 | Iteration number: [240/393] 61% | Training loss: 0.6932447363932928
Epoch: 37 | Iteration number: [250/393] 63% | Training loss: 0.6931293432712555
Epoch: 37 | Iteration number: [260/393] 66% | Training loss: 0.6930193282090701
Epoch: 37 | Iteration number: [270/393] 68% | Training loss: 0.6929486700782069
Epoch: 37 | Iteration number: [280/393] 71% | Training loss: 0.6928530957017626
Epoch: 37 | Iteration number: [290/393] 73% | Training loss: 0.6927461634422171
Epoch: 37 | Iteration number: [300/393] 76% | Training loss: 0.6926531771818797
Epoch: 37 | Iteration number: [310/393] 78% | Training loss: 0.6925964924596971
Epoch: 37 | Iteration number: [320/393] 81% | Training loss: 0.6925386352464556
Epoch: 37 | Iteration number: [330/393] 83% | Training loss: 0.6925018884918906
Epoch: 37 | Iteration number: [340/393] 86% | Training loss: 0.6924262542934979
Epoch: 37 | Iteration number: [350/393] 89% | Training loss: 0.6924108632973263
Epoch: 37 | Iteration number: [360/393] 91% | Training loss: 0.6923337693015734
Epoch: 37 | Iteration number: [370/393] 94% | Training loss: 0.6923155264274494
Epoch: 37 | Iteration number: [380/393] 96% | Training loss: 0.6922954967147426
Epoch: 37 | Iteration number: [390/393] 99% | Training loss: 0.6922466213886554

 End of epoch: 37 | Train Loss: 0.6904836958297943 | Training Time: 66 

 End of epoch: 37 | Eval Loss: 0.6910473302919038 | Evaluating Time: 17 
Epoch: 38 | Iteration number: [10/393] 2% | Training loss: 0.7600255191326142
Epoch: 38 | Iteration number: [20/393] 5% | Training loss: 0.7256382077932357
Epoch: 38 | Iteration number: [30/393] 7% | Training loss: 0.7139369626839955
Epoch: 38 | Iteration number: [40/393] 10% | Training loss: 0.7082336112856865
Epoch: 38 | Iteration number: [50/393] 12% | Training loss: 0.7047189676761627
Epoch: 38 | Iteration number: [60/393] 15% | Training loss: 0.7022857805093129
Epoch: 38 | Iteration number: [70/393] 17% | Training loss: 0.70056671329907
Epoch: 38 | Iteration number: [80/393] 20% | Training loss: 0.6992017216980457
Epoch: 38 | Iteration number: [90/393] 22% | Training loss: 0.6982804106341468
Epoch: 38 | Iteration number: [100/393] 25% | Training loss: 0.6973637765645981
Epoch: 38 | Iteration number: [110/393] 27% | Training loss: 0.6967438551512631
Epoch: 38 | Iteration number: [120/393] 30% | Training loss: 0.6962586502234142
Epoch: 38 | Iteration number: [130/393] 33% | Training loss: 0.6958202352890601
Epoch: 38 | Iteration number: [140/393] 35% | Training loss: 0.6954036508287702
Epoch: 38 | Iteration number: [150/393] 38% | Training loss: 0.6950508439540863
Epoch: 38 | Iteration number: [160/393] 40% | Training loss: 0.6947838060557843
Epoch: 38 | Iteration number: [170/393] 43% | Training loss: 0.6945394386263455
Epoch: 38 | Iteration number: [180/393] 45% | Training loss: 0.6943607654836442
Epoch: 38 | Iteration number: [190/393] 48% | Training loss: 0.6941617253579592
Epoch: 38 | Iteration number: [200/393] 50% | Training loss: 0.693994228541851
Epoch: 38 | Iteration number: [210/393] 53% | Training loss: 0.6938322714396885
Epoch: 38 | Iteration number: [220/393] 55% | Training loss: 0.6936944631013003
Epoch: 38 | Iteration number: [230/393] 58% | Training loss: 0.6934881337310956
Epoch: 38 | Iteration number: [240/393] 61% | Training loss: 0.693381984035174
Epoch: 38 | Iteration number: [250/393] 63% | Training loss: 0.6932416937351227
Epoch: 38 | Iteration number: [260/393] 66% | Training loss: 0.6930963133390133
Epoch: 38 | Iteration number: [270/393] 68% | Training loss: 0.6930024729834663
Epoch: 38 | Iteration number: [280/393] 71% | Training loss: 0.6928968289068766
Epoch: 38 | Iteration number: [290/393] 73% | Training loss: 0.6928374163035689
Epoch: 38 | Iteration number: [300/393] 76% | Training loss: 0.6927721164623897
Epoch: 38 | Iteration number: [310/393] 78% | Training loss: 0.692696548277332
Epoch: 38 | Iteration number: [320/393] 81% | Training loss: 0.6926163708791137
Epoch: 38 | Iteration number: [330/393] 83% | Training loss: 0.6925391558444861
Epoch: 38 | Iteration number: [340/393] 86% | Training loss: 0.6924282678786446
Epoch: 38 | Iteration number: [350/393] 89% | Training loss: 0.6923857980115073
Epoch: 38 | Iteration number: [360/393] 91% | Training loss: 0.6923540479607052
Epoch: 38 | Iteration number: [370/393] 94% | Training loss: 0.6923019096658036
Epoch: 38 | Iteration number: [380/393] 96% | Training loss: 0.6922536250792052
Epoch: 38 | Iteration number: [390/393] 99% | Training loss: 0.6922085769665547

 End of epoch: 38 | Train Loss: 0.6904388456854201 | Training Time: 67 

 End of epoch: 38 | Eval Loss: 0.6908251083627039 | Evaluating Time: 17 
Epoch: 39 | Iteration number: [10/393] 2% | Training loss: 0.7603927075862884
Epoch: 39 | Iteration number: [20/393] 5% | Training loss: 0.7248507380485535
Epoch: 39 | Iteration number: [30/393] 7% | Training loss: 0.7134847184022267
Epoch: 39 | Iteration number: [40/393] 10% | Training loss: 0.7078531563282013
Epoch: 39 | Iteration number: [50/393] 12% | Training loss: 0.7045460939407349
Epoch: 39 | Iteration number: [60/393] 15% | Training loss: 0.7021211604277293
Epoch: 39 | Iteration number: [70/393] 17% | Training loss: 0.7003682613372803
Epoch: 39 | Iteration number: [80/393] 20% | Training loss: 0.6990830138325691
Epoch: 39 | Iteration number: [90/393] 22% | Training loss: 0.6981485671467251
Epoch: 39 | Iteration number: [100/393] 25% | Training loss: 0.6973372328281403
Epoch: 39 | Iteration number: [110/393] 27% | Training loss: 0.6967597305774689
Epoch: 39 | Iteration number: [120/393] 30% | Training loss: 0.6962000514070193
Epoch: 39 | Iteration number: [130/393] 33% | Training loss: 0.6958226190163539
Epoch: 39 | Iteration number: [140/393] 35% | Training loss: 0.6954812918390546
Epoch: 39 | Iteration number: [150/393] 38% | Training loss: 0.695146427154541
Epoch: 39 | Iteration number: [160/393] 40% | Training loss: 0.6948496025055647
Epoch: 39 | Iteration number: [170/393] 43% | Training loss: 0.6946305583505069
Epoch: 39 | Iteration number: [180/393] 45% | Training loss: 0.6943841348091762
Epoch: 39 | Iteration number: [190/393] 48% | Training loss: 0.6941858435931959
Epoch: 39 | Iteration number: [200/393] 50% | Training loss: 0.6940247040987014
Epoch: 39 | Iteration number: [210/393] 53% | Training loss: 0.6938698921884809
Epoch: 39 | Iteration number: [220/393] 55% | Training loss: 0.693716022643176
Epoch: 39 | Iteration number: [230/393] 58% | Training loss: 0.693608806444251
Epoch: 39 | Iteration number: [240/393] 61% | Training loss: 0.6935118794441223
Epoch: 39 | Iteration number: [250/393] 63% | Training loss: 0.6934062960147858
Epoch: 39 | Iteration number: [260/393] 66% | Training loss: 0.6932818575547292
Epoch: 39 | Iteration number: [270/393] 68% | Training loss: 0.6931579678146927
Epoch: 39 | Iteration number: [280/393] 71% | Training loss: 0.693025072983333
Epoch: 39 | Iteration number: [290/393] 73% | Training loss: 0.692893575594343
Epoch: 39 | Iteration number: [300/393] 76% | Training loss: 0.6928184868892034
Epoch: 39 | Iteration number: [310/393] 78% | Training loss: 0.6927345843084397
Epoch: 39 | Iteration number: [320/393] 81% | Training loss: 0.6926400495693088
Epoch: 39 | Iteration number: [330/393] 83% | Training loss: 0.6925485520651846
Epoch: 39 | Iteration number: [340/393] 86% | Training loss: 0.692467467048589
Epoch: 39 | Iteration number: [350/393] 89% | Training loss: 0.6923936714444842
Epoch: 39 | Iteration number: [360/393] 91% | Training loss: 0.6923432972696092
Epoch: 39 | Iteration number: [370/393] 94% | Training loss: 0.6922981634333327
Epoch: 39 | Iteration number: [380/393] 96% | Training loss: 0.6922348158924203
Epoch: 39 | Iteration number: [390/393] 99% | Training loss: 0.6922117977570265

 End of epoch: 39 | Train Loss: 0.6904385952852458 | Training Time: 66 

 End of epoch: 39 | Eval Loss: 0.6907655633225733 | Evaluating Time: 17 
Epoch: 40 | Iteration number: [10/393] 2% | Training loss: 0.7582285523414611
Epoch: 40 | Iteration number: [20/393] 5% | Training loss: 0.7244637966156006
Epoch: 40 | Iteration number: [30/393] 7% | Training loss: 0.7133446196715038
Epoch: 40 | Iteration number: [40/393] 10% | Training loss: 0.7074338078498841
Epoch: 40 | Iteration number: [50/393] 12% | Training loss: 0.7039743256568909
Epoch: 40 | Iteration number: [60/393] 15% | Training loss: 0.7016471316417058
Epoch: 40 | Iteration number: [70/393] 17% | Training loss: 0.6999904743262699
Epoch: 40 | Iteration number: [80/393] 20% | Training loss: 0.6987929657101631
Epoch: 40 | Iteration number: [90/393] 22% | Training loss: 0.6978863908184899
Epoch: 40 | Iteration number: [100/393] 25% | Training loss: 0.6971860527992249
Epoch: 40 | Iteration number: [110/393] 27% | Training loss: 0.696704270622947
Epoch: 40 | Iteration number: [120/393] 30% | Training loss: 0.6962562491496403
Epoch: 40 | Iteration number: [130/393] 33% | Training loss: 0.6956687872226421
Epoch: 40 | Iteration number: [140/393] 35% | Training loss: 0.695314034819603
Epoch: 40 | Iteration number: [150/393] 38% | Training loss: 0.6948944358030955
Epoch: 40 | Iteration number: [160/393] 40% | Training loss: 0.6945420823991298
Epoch: 40 | Iteration number: [170/393] 43% | Training loss: 0.6942743876401116
Epoch: 40 | Iteration number: [180/393] 45% | Training loss: 0.6940225604507658
Epoch: 40 | Iteration number: [190/393] 48% | Training loss: 0.6938052403299432
Epoch: 40 | Iteration number: [200/393] 50% | Training loss: 0.6936422455310821
Epoch: 40 | Iteration number: [210/393] 53% | Training loss: 0.6935184070042202
Epoch: 40 | Iteration number: [220/393] 55% | Training loss: 0.6934025539593263
Epoch: 40 | Iteration number: [230/393] 58% | Training loss: 0.6932468038538228
Epoch: 40 | Iteration number: [240/393] 61% | Training loss: 0.6931270450353623
Epoch: 40 | Iteration number: [250/393] 63% | Training loss: 0.6930818266868591
Epoch: 40 | Iteration number: [260/393] 66% | Training loss: 0.6929716396790284
Epoch: 40 | Iteration number: [270/393] 68% | Training loss: 0.692863627495589
Epoch: 40 | Iteration number: [280/393] 71% | Training loss: 0.6928341678210668
Epoch: 40 | Iteration number: [290/393] 73% | Training loss: 0.6927583174458866
Epoch: 40 | Iteration number: [300/393] 76% | Training loss: 0.6926972657442093
Epoch: 40 | Iteration number: [310/393] 78% | Training loss: 0.692633984550353
Epoch: 40 | Iteration number: [320/393] 81% | Training loss: 0.6925530590116977
Epoch: 40 | Iteration number: [330/393] 83% | Training loss: 0.6925040579203403
Epoch: 40 | Iteration number: [340/393] 86% | Training loss: 0.6924387712689007
Epoch: 40 | Iteration number: [350/393] 89% | Training loss: 0.6924015016215188
Epoch: 40 | Iteration number: [360/393] 91% | Training loss: 0.6923778977659013
Epoch: 40 | Iteration number: [370/393] 94% | Training loss: 0.6923322268434473
Epoch: 40 | Iteration number: [380/393] 96% | Training loss: 0.6922956684702322
Epoch: 40 | Iteration number: [390/393] 99% | Training loss: 0.6922750829122005

 End of epoch: 40 | Train Loss: 0.6904835250541455 | Training Time: 66 

 End of epoch: 40 | Eval Loss: 0.6907843777111599 | Evaluating Time: 17 
Epoch: 41 | Iteration number: [10/393] 2% | Training loss: 0.75849769115448
Epoch: 41 | Iteration number: [20/393] 5% | Training loss: 0.7241358011960983
Epoch: 41 | Iteration number: [30/393] 7% | Training loss: 0.7133083005746206
Epoch: 41 | Iteration number: [40/393] 10% | Training loss: 0.7077423527836799
Epoch: 41 | Iteration number: [50/393] 12% | Training loss: 0.704308090209961
Epoch: 41 | Iteration number: [60/393] 15% | Training loss: 0.7021272987127304
Epoch: 41 | Iteration number: [70/393] 17% | Training loss: 0.7004161425999232
Epoch: 41 | Iteration number: [80/393] 20% | Training loss: 0.6992511928081513
Epoch: 41 | Iteration number: [90/393] 22% | Training loss: 0.6983646757072872
Epoch: 41 | Iteration number: [100/393] 25% | Training loss: 0.6975886172056198
Epoch: 41 | Iteration number: [110/393] 27% | Training loss: 0.6969595741141926
Epoch: 41 | Iteration number: [120/393] 30% | Training loss: 0.6963799516359965
Epoch: 41 | Iteration number: [130/393] 33% | Training loss: 0.6959469116651095
Epoch: 41 | Iteration number: [140/393] 35% | Training loss: 0.6955764945064272
Epoch: 41 | Iteration number: [150/393] 38% | Training loss: 0.6952698401610057
Epoch: 41 | Iteration number: [160/393] 40% | Training loss: 0.6949577756226063
Epoch: 41 | Iteration number: [170/393] 43% | Training loss: 0.6946324955014621
Epoch: 41 | Iteration number: [180/393] 45% | Training loss: 0.694394929210345
Epoch: 41 | Iteration number: [190/393] 48% | Training loss: 0.6941807335928867
Epoch: 41 | Iteration number: [200/393] 50% | Training loss: 0.6939687138795853
Epoch: 41 | Iteration number: [210/393] 53% | Training loss: 0.6937766072295961
Epoch: 41 | Iteration number: [220/393] 55% | Training loss: 0.6935714071447199
Epoch: 41 | Iteration number: [230/393] 58% | Training loss: 0.6935174384842748
Epoch: 41 | Iteration number: [240/393] 61% | Training loss: 0.6933745125929515
Epoch: 41 | Iteration number: [250/393] 63% | Training loss: 0.6932440967559814
Epoch: 41 | Iteration number: [260/393] 66% | Training loss: 0.6931544113617677
Epoch: 41 | Iteration number: [270/393] 68% | Training loss: 0.6930452357839655
Epoch: 41 | Iteration number: [280/393] 71% | Training loss: 0.6929772579244204
Epoch: 41 | Iteration number: [290/393] 73% | Training loss: 0.6929119938406451
Epoch: 41 | Iteration number: [300/393] 76% | Training loss: 0.6928249222040176
Epoch: 41 | Iteration number: [310/393] 78% | Training loss: 0.6927340765153208
Epoch: 41 | Iteration number: [320/393] 81% | Training loss: 0.6926613170653582
Epoch: 41 | Iteration number: [330/393] 83% | Training loss: 0.6926084626804698
Epoch: 41 | Iteration number: [340/393] 86% | Training loss: 0.6925429019857855
Epoch: 41 | Iteration number: [350/393] 89% | Training loss: 0.6924789791447775
Epoch: 41 | Iteration number: [360/393] 91% | Training loss: 0.6924109583099683
Epoch: 41 | Iteration number: [370/393] 94% | Training loss: 0.6923656346024694
Epoch: 41 | Iteration number: [380/393] 96% | Training loss: 0.6923349647145522
Epoch: 41 | Iteration number: [390/393] 99% | Training loss: 0.6922574619452159

 End of epoch: 41 | Train Loss: 0.690478266498818 | Training Time: 67 

 End of epoch: 41 | Eval Loss: 0.6907415815762111 | Evaluating Time: 17 
Epoch: 42 | Iteration number: [10/393] 2% | Training loss: 0.7596397519111633
Epoch: 42 | Iteration number: [20/393] 5% | Training loss: 0.7251810163259507
Epoch: 42 | Iteration number: [30/393] 7% | Training loss: 0.7135779857635498
Epoch: 42 | Iteration number: [40/393] 10% | Training loss: 0.7076756596565247
Epoch: 42 | Iteration number: [50/393] 12% | Training loss: 0.7041928327083588
Epoch: 42 | Iteration number: [60/393] 15% | Training loss: 0.7019455830256144
Epoch: 42 | Iteration number: [70/393] 17% | Training loss: 0.7004320383071899
Epoch: 42 | Iteration number: [80/393] 20% | Training loss: 0.6991441354155541
Epoch: 42 | Iteration number: [90/393] 22% | Training loss: 0.6980851027700636
Epoch: 42 | Iteration number: [100/393] 25% | Training loss: 0.6972560209035873
Epoch: 42 | Iteration number: [110/393] 27% | Training loss: 0.6965456637469205
Epoch: 42 | Iteration number: [120/393] 30% | Training loss: 0.6959919144709905
Epoch: 42 | Iteration number: [130/393] 33% | Training loss: 0.695687375160364
Epoch: 42 | Iteration number: [140/393] 35% | Training loss: 0.6952491534607751
Epoch: 42 | Iteration number: [150/393] 38% | Training loss: 0.6948566941420237
Epoch: 42 | Iteration number: [160/393] 40% | Training loss: 0.6945593625307083
Epoch: 42 | Iteration number: [170/393] 43% | Training loss: 0.6943370878696442
Epoch: 42 | Iteration number: [180/393] 45% | Training loss: 0.6940870026747386
Epoch: 42 | Iteration number: [190/393] 48% | Training loss: 0.693907988698859
Epoch: 42 | Iteration number: [200/393] 50% | Training loss: 0.6937104469537735
Epoch: 42 | Iteration number: [210/393] 53% | Training loss: 0.6935353798525674
Epoch: 42 | Iteration number: [220/393] 55% | Training loss: 0.6934308707714081
Epoch: 42 | Iteration number: [230/393] 58% | Training loss: 0.6933034272297569
Epoch: 42 | Iteration number: [240/393] 61% | Training loss: 0.6931292568643888
Epoch: 42 | Iteration number: [250/393] 63% | Training loss: 0.6930311932563782
Epoch: 42 | Iteration number: [260/393] 66% | Training loss: 0.69291733113619
Epoch: 42 | Iteration number: [270/393] 68% | Training loss: 0.6928043546500029
Epoch: 42 | Iteration number: [280/393] 71% | Training loss: 0.692742629136358
Epoch: 42 | Iteration number: [290/393] 73% | Training loss: 0.6927076648021566
Epoch: 42 | Iteration number: [300/393] 76% | Training loss: 0.6926709785064061
Epoch: 42 | Iteration number: [310/393] 78% | Training loss: 0.6926148203111464
Epoch: 42 | Iteration number: [320/393] 81% | Training loss: 0.6925281886011362
Epoch: 42 | Iteration number: [330/393] 83% | Training loss: 0.692481376727422
Epoch: 42 | Iteration number: [340/393] 86% | Training loss: 0.6924214044037987
Epoch: 42 | Iteration number: [350/393] 89% | Training loss: 0.6923547826494489
Epoch: 42 | Iteration number: [360/393] 91% | Training loss: 0.6923038431339794
Epoch: 42 | Iteration number: [370/393] 94% | Training loss: 0.6922631726071641
Epoch: 42 | Iteration number: [380/393] 96% | Training loss: 0.692217681282445
Epoch: 42 | Iteration number: [390/393] 99% | Training loss: 0.692163216150724

 End of epoch: 42 | Train Loss: 0.6903953441530087 | Training Time: 67 

 End of epoch: 42 | Eval Loss: 0.6907386086425003 | Evaluating Time: 17 
Epoch: 43 | Iteration number: [10/393] 2% | Training loss: 0.7585920751094818
Epoch: 43 | Iteration number: [20/393] 5% | Training loss: 0.7244916051626206
Epoch: 43 | Iteration number: [30/393] 7% | Training loss: 0.713265186548233
Epoch: 43 | Iteration number: [40/393] 10% | Training loss: 0.707311075925827
Epoch: 43 | Iteration number: [50/393] 12% | Training loss: 0.703935307264328
Epoch: 43 | Iteration number: [60/393] 15% | Training loss: 0.7017674724260966
Epoch: 43 | Iteration number: [70/393] 17% | Training loss: 0.7001844184739249
Epoch: 43 | Iteration number: [80/393] 20% | Training loss: 0.6990347556769848
Epoch: 43 | Iteration number: [90/393] 22% | Training loss: 0.6980076471964518
Epoch: 43 | Iteration number: [100/393] 25% | Training loss: 0.6972952741384506
Epoch: 43 | Iteration number: [110/393] 27% | Training loss: 0.696727944504131
Epoch: 43 | Iteration number: [120/393] 30% | Training loss: 0.6961845402916272
Epoch: 43 | Iteration number: [130/393] 33% | Training loss: 0.6956741360517649
Epoch: 43 | Iteration number: [140/393] 35% | Training loss: 0.6953045206410544
Epoch: 43 | Iteration number: [150/393] 38% | Training loss: 0.6950326240062714
Epoch: 43 | Iteration number: [160/393] 40% | Training loss: 0.6947590120136737
Epoch: 43 | Iteration number: [170/393] 43% | Training loss: 0.694528509238187
Epoch: 43 | Iteration number: [180/393] 45% | Training loss: 0.6943503687779109
Epoch: 43 | Iteration number: [190/393] 48% | Training loss: 0.6940912278074968
Epoch: 43 | Iteration number: [200/393] 50% | Training loss: 0.6939623954892159
Epoch: 43 | Iteration number: [210/393] 53% | Training loss: 0.693755571047465
Epoch: 43 | Iteration number: [220/393] 55% | Training loss: 0.6935581358996304
Epoch: 43 | Iteration number: [230/393] 58% | Training loss: 0.6934301708055579
Epoch: 43 | Iteration number: [240/393] 61% | Training loss: 0.6933261958261331
Epoch: 43 | Iteration number: [250/393] 63% | Training loss: 0.6932155215740203
Epoch: 43 | Iteration number: [260/393] 66% | Training loss: 0.6931372913030478
Epoch: 43 | Iteration number: [270/393] 68% | Training loss: 0.693027733873438
Epoch: 43 | Iteration number: [280/393] 71% | Training loss: 0.6929361405117171
Epoch: 43 | Iteration number: [290/393] 73% | Training loss: 0.6928315228429334
Epoch: 43 | Iteration number: [300/393] 76% | Training loss: 0.6927673437198003
Epoch: 43 | Iteration number: [310/393] 78% | Training loss: 0.6926580423308957
Epoch: 43 | Iteration number: [320/393] 81% | Training loss: 0.6925583116710186
Epoch: 43 | Iteration number: [330/393] 83% | Training loss: 0.6924778891332222
Epoch: 43 | Iteration number: [340/393] 86% | Training loss: 0.6924153533051995
Epoch: 43 | Iteration number: [350/393] 89% | Training loss: 0.6923532266276223
Epoch: 43 | Iteration number: [360/393] 91% | Training loss: 0.6922953810956743
Epoch: 43 | Iteration number: [370/393] 94% | Training loss: 0.6922669531525792
Epoch: 43 | Iteration number: [380/393] 96% | Training loss: 0.6922348071085779
Epoch: 43 | Iteration number: [390/393] 99% | Training loss: 0.6921938116733845

 End of epoch: 43 | Train Loss: 0.6904281089627409 | Training Time: 67 

 End of epoch: 43 | Eval Loss: 0.6908435006530917 | Evaluating Time: 17 
Epoch: 44 | Iteration number: [10/393] 2% | Training loss: 0.7604372143745423
Epoch: 44 | Iteration number: [20/393] 5% | Training loss: 0.7250539302825928
Epoch: 44 | Iteration number: [30/393] 7% | Training loss: 0.7133808175722758
Epoch: 44 | Iteration number: [40/393] 10% | Training loss: 0.707359068095684
Epoch: 44 | Iteration number: [50/393] 12% | Training loss: 0.7038841164112091
Epoch: 44 | Iteration number: [60/393] 15% | Training loss: 0.7016361276308696
Epoch: 44 | Iteration number: [70/393] 17% | Training loss: 0.7001945759568896
Epoch: 44 | Iteration number: [80/393] 20% | Training loss: 0.6989351995289326
Epoch: 44 | Iteration number: [90/393] 22% | Training loss: 0.6979285385873583
Epoch: 44 | Iteration number: [100/393] 25% | Training loss: 0.6971883499622344
Epoch: 44 | Iteration number: [110/393] 27% | Training loss: 0.6966200508854606
Epoch: 44 | Iteration number: [120/393] 30% | Training loss: 0.6961707611878712
Epoch: 44 | Iteration number: [130/393] 33% | Training loss: 0.6957669010529152
Epoch: 44 | Iteration number: [140/393] 35% | Training loss: 0.6953254329306738
Epoch: 44 | Iteration number: [150/393] 38% | Training loss: 0.6950201682249705
Epoch: 44 | Iteration number: [160/393] 40% | Training loss: 0.6947325669229031
Epoch: 44 | Iteration number: [170/393] 43% | Training loss: 0.6945064264185289
Epoch: 44 | Iteration number: [180/393] 45% | Training loss: 0.6942776931656731
Epoch: 44 | Iteration number: [190/393] 48% | Training loss: 0.6940501605209551
Epoch: 44 | Iteration number: [200/393] 50% | Training loss: 0.6939055508375168
Epoch: 44 | Iteration number: [210/393] 53% | Training loss: 0.6937524605365026
Epoch: 44 | Iteration number: [220/393] 55% | Training loss: 0.6936412998221138
Epoch: 44 | Iteration number: [230/393] 58% | Training loss: 0.6935215594975844
Epoch: 44 | Iteration number: [240/393] 61% | Training loss: 0.6933614537119865
Epoch: 44 | Iteration number: [250/393] 63% | Training loss: 0.6932184417247772
Epoch: 44 | Iteration number: [260/393] 66% | Training loss: 0.6931216987279746
Epoch: 44 | Iteration number: [270/393] 68% | Training loss: 0.6930247185406861
Epoch: 44 | Iteration number: [280/393] 71% | Training loss: 0.6928864253418786
Epoch: 44 | Iteration number: [290/393] 73% | Training loss: 0.6928353381567988
Epoch: 44 | Iteration number: [300/393] 76% | Training loss: 0.6927273138364156
Epoch: 44 | Iteration number: [310/393] 78% | Training loss: 0.692651302776029
Epoch: 44 | Iteration number: [320/393] 81% | Training loss: 0.6925845421850682
Epoch: 44 | Iteration number: [330/393] 83% | Training loss: 0.6925233862616799
Epoch: 44 | Iteration number: [340/393] 86% | Training loss: 0.6924296529854045
Epoch: 44 | Iteration number: [350/393] 89% | Training loss: 0.6923542044843947
Epoch: 44 | Iteration number: [360/393] 91% | Training loss: 0.6923002665241559
Epoch: 44 | Iteration number: [370/393] 94% | Training loss: 0.692244581757365
Epoch: 44 | Iteration number: [380/393] 96% | Training loss: 0.6922062161721682
Epoch: 44 | Iteration number: [390/393] 99% | Training loss: 0.6921625672242581

 End of epoch: 44 | Train Loss: 0.6903900272063627 | Training Time: 67 

 End of epoch: 44 | Eval Loss: 0.6907880890126131 | Evaluating Time: 17 
Epoch: 45 | Iteration number: [10/393] 2% | Training loss: 0.7599090516567231
Epoch: 45 | Iteration number: [20/393] 5% | Training loss: 0.724954491853714
Epoch: 45 | Iteration number: [30/393] 7% | Training loss: 0.7134681582450867
Epoch: 45 | Iteration number: [40/393] 10% | Training loss: 0.7077944830060006
Epoch: 45 | Iteration number: [50/393] 12% | Training loss: 0.70434929728508
Epoch: 45 | Iteration number: [60/393] 15% | Training loss: 0.7021836926539738
Epoch: 45 | Iteration number: [70/393] 17% | Training loss: 0.7004257134028844
Epoch: 45 | Iteration number: [80/393] 20% | Training loss: 0.6989449292421341
Epoch: 45 | Iteration number: [90/393] 22% | Training loss: 0.6979831364419725
Epoch: 45 | Iteration number: [100/393] 25% | Training loss: 0.6973724609613419
Epoch: 45 | Iteration number: [110/393] 27% | Training loss: 0.6967548841779883
Epoch: 45 | Iteration number: [120/393] 30% | Training loss: 0.6961672628919283
Epoch: 45 | Iteration number: [130/393] 33% | Training loss: 0.695740753870744
Epoch: 45 | Iteration number: [140/393] 35% | Training loss: 0.6953653774091175
Epoch: 45 | Iteration number: [150/393] 38% | Training loss: 0.6949744315942129
Epoch: 45 | Iteration number: [160/393] 40% | Training loss: 0.6946823474019765
Epoch: 45 | Iteration number: [170/393] 43% | Training loss: 0.694426843699287
Epoch: 45 | Iteration number: [180/393] 45% | Training loss: 0.6942160874605179
Epoch: 45 | Iteration number: [190/393] 48% | Training loss: 0.6940019751849927
Epoch: 45 | Iteration number: [200/393] 50% | Training loss: 0.6938307642936706
Epoch: 45 | Iteration number: [210/393] 53% | Training loss: 0.693656230256671
Epoch: 45 | Iteration number: [220/393] 55% | Training loss: 0.6935069758783687
Epoch: 45 | Iteration number: [230/393] 58% | Training loss: 0.6933669274267943
Epoch: 45 | Iteration number: [240/393] 61% | Training loss: 0.6932947042087714
Epoch: 45 | Iteration number: [250/393] 63% | Training loss: 0.693133944272995
Epoch: 45 | Iteration number: [260/393] 66% | Training loss: 0.6930372499502622
Epoch: 45 | Iteration number: [270/393] 68% | Training loss: 0.6929263399706946
Epoch: 45 | Iteration number: [280/393] 71% | Training loss: 0.692866509939943
Epoch: 45 | Iteration number: [290/393] 73% | Training loss: 0.6927998505789658
Epoch: 45 | Iteration number: [300/393] 76% | Training loss: 0.692689563035965
Epoch: 45 | Iteration number: [310/393] 78% | Training loss: 0.6926120758056641
Epoch: 45 | Iteration number: [320/393] 81% | Training loss: 0.6925277085974813
Epoch: 45 | Iteration number: [330/393] 83% | Training loss: 0.6924697456937847
Epoch: 45 | Iteration number: [340/393] 86% | Training loss: 0.6924090436276268
Epoch: 45 | Iteration number: [350/393] 89% | Training loss: 0.6923669317790441
Epoch: 45 | Iteration number: [360/393] 91% | Training loss: 0.6923023210631476
Epoch: 45 | Iteration number: [370/393] 94% | Training loss: 0.6922034725949571
Epoch: 45 | Iteration number: [380/393] 96% | Training loss: 0.692156415864041
Epoch: 45 | Iteration number: [390/393] 99% | Training loss: 0.6921117574740678

 End of epoch: 45 | Train Loss: 0.6903404455451868 | Training Time: 66 

 End of epoch: 45 | Eval Loss: 0.6907280355083699 | Evaluating Time: 17 
Epoch: 46 | Iteration number: [10/393] 2% | Training loss: 0.7600100755691528
Epoch: 46 | Iteration number: [20/393] 5% | Training loss: 0.7244865238666535
Epoch: 46 | Iteration number: [30/393] 7% | Training loss: 0.7132298092047373
Epoch: 46 | Iteration number: [40/393] 10% | Training loss: 0.707696832716465
Epoch: 46 | Iteration number: [50/393] 12% | Training loss: 0.7043691945075988
Epoch: 46 | Iteration number: [60/393] 15% | Training loss: 0.7017719844977061
Epoch: 46 | Iteration number: [70/393] 17% | Training loss: 0.700008339541299
Epoch: 46 | Iteration number: [80/393] 20% | Training loss: 0.6987446658313274
Epoch: 46 | Iteration number: [90/393] 22% | Training loss: 0.6978436589241028
Epoch: 46 | Iteration number: [100/393] 25% | Training loss: 0.6971848845481873
Epoch: 46 | Iteration number: [110/393] 27% | Training loss: 0.6965449333190918
Epoch: 46 | Iteration number: [120/393] 30% | Training loss: 0.6960549344619115
Epoch: 46 | Iteration number: [130/393] 33% | Training loss: 0.6956076681613922
Epoch: 46 | Iteration number: [140/393] 35% | Training loss: 0.6952261507511139
Epoch: 46 | Iteration number: [150/393] 38% | Training loss: 0.6948755570252736
Epoch: 46 | Iteration number: [160/393] 40% | Training loss: 0.694637230783701
Epoch: 46 | Iteration number: [170/393] 43% | Training loss: 0.6943718643749461
Epoch: 46 | Iteration number: [180/393] 45% | Training loss: 0.6941526227527195
Epoch: 46 | Iteration number: [190/393] 48% | Training loss: 0.6939444830543117
Epoch: 46 | Iteration number: [200/393] 50% | Training loss: 0.6937551054358483
Epoch: 46 | Iteration number: [210/393] 53% | Training loss: 0.6936344362440563
Epoch: 46 | Iteration number: [220/393] 55% | Training loss: 0.6934854865074158
Epoch: 46 | Iteration number: [230/393] 58% | Training loss: 0.6933882347915483
Epoch: 46 | Iteration number: [240/393] 61% | Training loss: 0.693298198779424
Epoch: 46 | Iteration number: [250/393] 63% | Training loss: 0.6932314758300782
Epoch: 46 | Iteration number: [260/393] 66% | Training loss: 0.6931215226650238
Epoch: 46 | Iteration number: [270/393] 68% | Training loss: 0.6930264901231836
Epoch: 46 | Iteration number: [280/393] 71% | Training loss: 0.6929589103375162
Epoch: 46 | Iteration number: [290/393] 73% | Training loss: 0.6928816550764544
Epoch: 46 | Iteration number: [300/393] 76% | Training loss: 0.6927672984202703
Epoch: 46 | Iteration number: [310/393] 78% | Training loss: 0.6927037094869921
Epoch: 46 | Iteration number: [320/393] 81% | Training loss: 0.6925973713397979
Epoch: 46 | Iteration number: [330/393] 83% | Training loss: 0.6925630876512239
Epoch: 46 | Iteration number: [340/393] 86% | Training loss: 0.6925165923202738
Epoch: 46 | Iteration number: [350/393] 89% | Training loss: 0.6924443517412459
Epoch: 46 | Iteration number: [360/393] 91% | Training loss: 0.6923692686690225
Epoch: 46 | Iteration number: [370/393] 94% | Training loss: 0.6923447159496514
Epoch: 46 | Iteration number: [380/393] 96% | Training loss: 0.6922825273714568
Epoch: 46 | Iteration number: [390/393] 99% | Training loss: 0.6922551971215468

 End of epoch: 46 | Train Loss: 0.6904905963186696 | Training Time: 67 

 End of epoch: 46 | Eval Loss: 0.6909565487686469 | Evaluating Time: 17 
Epoch: 47 | Iteration number: [10/393] 2% | Training loss: 0.7604787945747375
Epoch: 47 | Iteration number: [20/393] 5% | Training loss: 0.7255696952342987
Epoch: 47 | Iteration number: [30/393] 7% | Training loss: 0.713786784807841
Epoch: 47 | Iteration number: [40/393] 10% | Training loss: 0.7077650159597397
Epoch: 47 | Iteration number: [50/393] 12% | Training loss: 0.7044237768650055
Epoch: 47 | Iteration number: [60/393] 15% | Training loss: 0.7020731796820958
Epoch: 47 | Iteration number: [70/393] 17% | Training loss: 0.7005203000136784
Epoch: 47 | Iteration number: [80/393] 20% | Training loss: 0.6993305362761021
Epoch: 47 | Iteration number: [90/393] 22% | Training loss: 0.6982935256428189
Epoch: 47 | Iteration number: [100/393] 25% | Training loss: 0.6975304341316223
Epoch: 47 | Iteration number: [110/393] 27% | Training loss: 0.6969194661487232
Epoch: 47 | Iteration number: [120/393] 30% | Training loss: 0.6963256195187568
Epoch: 47 | Iteration number: [130/393] 33% | Training loss: 0.6958399011538579
Epoch: 47 | Iteration number: [140/393] 35% | Training loss: 0.6953915421451841
Epoch: 47 | Iteration number: [150/393] 38% | Training loss: 0.6950392238299052
Epoch: 47 | Iteration number: [160/393] 40% | Training loss: 0.6947769977152347
Epoch: 47 | Iteration number: [170/393] 43% | Training loss: 0.6945095416377572
Epoch: 47 | Iteration number: [180/393] 45% | Training loss: 0.6942535721593432
Epoch: 47 | Iteration number: [190/393] 48% | Training loss: 0.6940325981692264
Epoch: 47 | Iteration number: [200/393] 50% | Training loss: 0.6938329339027405
Epoch: 47 | Iteration number: [210/393] 53% | Training loss: 0.6937295042333149
Epoch: 47 | Iteration number: [220/393] 55% | Training loss: 0.6935464441776276
Epoch: 47 | Iteration number: [230/393] 58% | Training loss: 0.6933325666448344
Epoch: 47 | Iteration number: [240/393] 61% | Training loss: 0.6932063887516657
Epoch: 47 | Iteration number: [250/393] 63% | Training loss: 0.6930974931716919
Epoch: 47 | Iteration number: [260/393] 66% | Training loss: 0.6930073779362899
Epoch: 47 | Iteration number: [270/393] 68% | Training loss: 0.6928805375540698
Epoch: 47 | Iteration number: [280/393] 71% | Training loss: 0.6927926665970258
Epoch: 47 | Iteration number: [290/393] 73% | Training loss: 0.6927454054355622
Epoch: 47 | Iteration number: [300/393] 76% | Training loss: 0.6926831970612208
Epoch: 47 | Iteration number: [310/393] 78% | Training loss: 0.6926283949805844
Epoch: 47 | Iteration number: [320/393] 81% | Training loss: 0.6925439447164535
Epoch: 47 | Iteration number: [330/393] 83% | Training loss: 0.6924801504973209
Epoch: 47 | Iteration number: [340/393] 86% | Training loss: 0.6923810848418404
Epoch: 47 | Iteration number: [350/393] 89% | Training loss: 0.6923311603069305
Epoch: 47 | Iteration number: [360/393] 91% | Training loss: 0.692286665406492
Epoch: 47 | Iteration number: [370/393] 94% | Training loss: 0.6922900858763102
Epoch: 47 | Iteration number: [380/393] 96% | Training loss: 0.6922395163460782
Epoch: 47 | Iteration number: [390/393] 99% | Training loss: 0.6921660398825621

 End of epoch: 47 | Train Loss: 0.6904016050673624 | Training Time: 67 

 End of epoch: 47 | Eval Loss: 0.6908420713580384 | Evaluating Time: 17 
Epoch: 48 | Iteration number: [10/393] 2% | Training loss: 0.7588957846164703
Epoch: 48 | Iteration number: [20/393] 5% | Training loss: 0.724974611401558
Epoch: 48 | Iteration number: [30/393] 7% | Training loss: 0.7132639030615489
Epoch: 48 | Iteration number: [40/393] 10% | Training loss: 0.7072111815214157
Epoch: 48 | Iteration number: [50/393] 12% | Training loss: 0.7039295423030854
Epoch: 48 | Iteration number: [60/393] 15% | Training loss: 0.7017143338918685
Epoch: 48 | Iteration number: [70/393] 17% | Training loss: 0.6999795981815883
Epoch: 48 | Iteration number: [80/393] 20% | Training loss: 0.6988585367798805
Epoch: 48 | Iteration number: [90/393] 22% | Training loss: 0.6979844099945492
Epoch: 48 | Iteration number: [100/393] 25% | Training loss: 0.6971537160873413
Epoch: 48 | Iteration number: [110/393] 27% | Training loss: 0.6964582134376872
Epoch: 48 | Iteration number: [120/393] 30% | Training loss: 0.6959540779391925
Epoch: 48 | Iteration number: [130/393] 33% | Training loss: 0.6955598083826212
Epoch: 48 | Iteration number: [140/393] 35% | Training loss: 0.6952044929776873
Epoch: 48 | Iteration number: [150/393] 38% | Training loss: 0.6948982274532318
Epoch: 48 | Iteration number: [160/393] 40% | Training loss: 0.69454635232687
Epoch: 48 | Iteration number: [170/393] 43% | Training loss: 0.6943017815842348
Epoch: 48 | Iteration number: [180/393] 45% | Training loss: 0.6940973930888705
Epoch: 48 | Iteration number: [190/393] 48% | Training loss: 0.693902936107234
Epoch: 48 | Iteration number: [200/393] 50% | Training loss: 0.6937199351191521
Epoch: 48 | Iteration number: [210/393] 53% | Training loss: 0.6935655715919676
Epoch: 48 | Iteration number: [220/393] 55% | Training loss: 0.6934474652463739
Epoch: 48 | Iteration number: [230/393] 58% | Training loss: 0.6932656117107557
Epoch: 48 | Iteration number: [240/393] 61% | Training loss: 0.6931073519090811
Epoch: 48 | Iteration number: [250/393] 63% | Training loss: 0.693033100605011
Epoch: 48 | Iteration number: [260/393] 66% | Training loss: 0.692934979383762
Epoch: 48 | Iteration number: [270/393] 68% | Training loss: 0.6928745962955334
Epoch: 48 | Iteration number: [280/393] 71% | Training loss: 0.6927679370556559
Epoch: 48 | Iteration number: [290/393] 73% | Training loss: 0.6926954170753216
Epoch: 48 | Iteration number: [300/393] 76% | Training loss: 0.6926304123799006
Epoch: 48 | Iteration number: [310/393] 78% | Training loss: 0.6925376707507718
Epoch: 48 | Iteration number: [320/393] 81% | Training loss: 0.6924606792628765
Epoch: 48 | Iteration number: [330/393] 83% | Training loss: 0.6923872572002989
Epoch: 48 | Iteration number: [340/393] 86% | Training loss: 0.6923151375616298
Epoch: 48 | Iteration number: [350/393] 89% | Training loss: 0.6922827882426126
Epoch: 48 | Iteration number: [360/393] 91% | Training loss: 0.6922548550698492
Epoch: 48 | Iteration number: [370/393] 94% | Training loss: 0.6922199083341135
Epoch: 48 | Iteration number: [380/393] 96% | Training loss: 0.6921831130981445
Epoch: 48 | Iteration number: [390/393] 99% | Training loss: 0.6921267825823564

 End of epoch: 48 | Train Loss: 0.6903492318461566 | Training Time: 67 

 End of epoch: 48 | Eval Loss: 0.6907657713306193 | Evaluating Time: 17 
Epoch: 49 | Iteration number: [10/393] 2% | Training loss: 0.7596682548522949
Epoch: 49 | Iteration number: [20/393] 5% | Training loss: 0.7249681204557419
Epoch: 49 | Iteration number: [30/393] 7% | Training loss: 0.7134253323078156
Epoch: 49 | Iteration number: [40/393] 10% | Training loss: 0.7077497258782387
Epoch: 49 | Iteration number: [50/393] 12% | Training loss: 0.704205174446106
Epoch: 49 | Iteration number: [60/393] 15% | Training loss: 0.7020677377780279
Epoch: 49 | Iteration number: [70/393] 17% | Training loss: 0.7003085655825478
Epoch: 49 | Iteration number: [80/393] 20% | Training loss: 0.6990747965872288
Epoch: 49 | Iteration number: [90/393] 22% | Training loss: 0.6982206298245324
Epoch: 49 | Iteration number: [100/393] 25% | Training loss: 0.6975630551576615
Epoch: 49 | Iteration number: [110/393] 27% | Training loss: 0.6968948245048523
Epoch: 49 | Iteration number: [120/393] 30% | Training loss: 0.6963439057270686
Epoch: 49 | Iteration number: [130/393] 33% | Training loss: 0.6958284478921156
Epoch: 49 | Iteration number: [140/393] 35% | Training loss: 0.6954568437167576
Epoch: 49 | Iteration number: [150/393] 38% | Training loss: 0.6950519716739655
Epoch: 49 | Iteration number: [160/393] 40% | Training loss: 0.6947503581643104
Epoch: 49 | Iteration number: [170/393] 43% | Training loss: 0.6944648921489716
Epoch: 49 | Iteration number: [180/393] 45% | Training loss: 0.6941904293166267
Epoch: 49 | Iteration number: [190/393] 48% | Training loss: 0.6939722895622253
Epoch: 49 | Iteration number: [200/393] 50% | Training loss: 0.6938056057691574
Epoch: 49 | Iteration number: [210/393] 53% | Training loss: 0.6936055541038513
Epoch: 49 | Iteration number: [220/393] 55% | Training loss: 0.6934496102007952
Epoch: 49 | Iteration number: [230/393] 58% | Training loss: 0.6932840217714724
Epoch: 49 | Iteration number: [240/393] 61% | Training loss: 0.6931751223901907
Epoch: 49 | Iteration number: [250/393] 63% | Training loss: 0.6930681946277618
Epoch: 49 | Iteration number: [260/393] 66% | Training loss: 0.6929706617043568
Epoch: 49 | Iteration number: [270/393] 68% | Training loss: 0.6928681678242153
Epoch: 49 | Iteration number: [280/393] 71% | Training loss: 0.692746373798166
Epoch: 49 | Iteration number: [290/393] 73% | Training loss: 0.6926501769444038
Epoch: 49 | Iteration number: [300/393] 76% | Training loss: 0.6925899881124497
Epoch: 49 | Iteration number: [310/393] 78% | Training loss: 0.6924902775595265
Epoch: 49 | Iteration number: [320/393] 81% | Training loss: 0.6924113061279058
Epoch: 49 | Iteration number: [330/393] 83% | Training loss: 0.6923584107196692
Epoch: 49 | Iteration number: [340/393] 86% | Training loss: 0.6923072425758138
Epoch: 49 | Iteration number: [350/393] 89% | Training loss: 0.6922619129930224
Epoch: 49 | Iteration number: [360/393] 91% | Training loss: 0.6922070710195436
Epoch: 49 | Iteration number: [370/393] 94% | Training loss: 0.692141159643998
Epoch: 49 | Iteration number: [380/393] 96% | Training loss: 0.692082868438018
Epoch: 49 | Iteration number: [390/393] 99% | Training loss: 0.692055574288735

 End of epoch: 49 | Train Loss: 0.69029421994401 | Training Time: 67 

 End of epoch: 49 | Eval Loss: 0.690789955002921 | Evaluating Time: 17 
Epoch: 50 | Iteration number: [10/393] 2% | Training loss: 0.7596700429916382
Epoch: 50 | Iteration number: [20/393] 5% | Training loss: 0.7248391777276992
Epoch: 50 | Iteration number: [30/393] 7% | Training loss: 0.7129919807116191
Epoch: 50 | Iteration number: [40/393] 10% | Training loss: 0.7075266778469086
Epoch: 50 | Iteration number: [50/393] 12% | Training loss: 0.7042801249027252
Epoch: 50 | Iteration number: [60/393] 15% | Training loss: 0.701987565557162
Epoch: 50 | Iteration number: [70/393] 17% | Training loss: 0.7002041757106781
Epoch: 50 | Iteration number: [80/393] 20% | Training loss: 0.6987928710877895
Epoch: 50 | Iteration number: [90/393] 22% | Training loss: 0.6978533493147956
Epoch: 50 | Iteration number: [100/393] 25% | Training loss: 0.697155357003212
Epoch: 50 | Iteration number: [110/393] 27% | Training loss: 0.6963471521030773
Epoch: 50 | Iteration number: [120/393] 30% | Training loss: 0.6959158539772033
Epoch: 50 | Iteration number: [130/393] 33% | Training loss: 0.6954981432511256
Epoch: 50 | Iteration number: [140/393] 35% | Training loss: 0.6951202890702657
Epoch: 50 | Iteration number: [150/393] 38% | Training loss: 0.6948074797789255
Epoch: 50 | Iteration number: [160/393] 40% | Training loss: 0.6945186510682106
Epoch: 50 | Iteration number: [170/393] 43% | Training loss: 0.6942058503627777
Epoch: 50 | Iteration number: [180/393] 45% | Training loss: 0.6940391113360723
Epoch: 50 | Iteration number: [190/393] 48% | Training loss: 0.6938622220566398
Epoch: 50 | Iteration number: [200/393] 50% | Training loss: 0.6937094217538834
Epoch: 50 | Iteration number: [210/393] 53% | Training loss: 0.6935132165749868
Epoch: 50 | Iteration number: [220/393] 55% | Training loss: 0.6933543080633336
Epoch: 50 | Iteration number: [230/393] 58% | Training loss: 0.6932704391686813
Epoch: 50 | Iteration number: [240/393] 61% | Training loss: 0.693168486158053
Epoch: 50 | Iteration number: [250/393] 63% | Training loss: 0.6930531959533691
Epoch: 50 | Iteration number: [260/393] 66% | Training loss: 0.6929485155985906
Epoch: 50 | Iteration number: [270/393] 68% | Training loss: 0.6928681216858051
Epoch: 50 | Iteration number: [280/393] 71% | Training loss: 0.692743672643389
Epoch: 50 | Iteration number: [290/393] 73% | Training loss: 0.6926371991634369
Epoch: 50 | Iteration number: [300/393] 76% | Training loss: 0.6925999506314595
Epoch: 50 | Iteration number: [310/393] 78% | Training loss: 0.6925493897930268
Epoch: 50 | Iteration number: [320/393] 81% | Training loss: 0.6924866979941726
Epoch: 50 | Iteration number: [330/393] 83% | Training loss: 0.6923970576488611
Epoch: 50 | Iteration number: [340/393] 86% | Training loss: 0.6923536323449191
Epoch: 50 | Iteration number: [350/393] 89% | Training loss: 0.6922998394284929
Epoch: 50 | Iteration number: [360/393] 91% | Training loss: 0.6922277770108647
Epoch: 50 | Iteration number: [370/393] 94% | Training loss: 0.692198315021154
Epoch: 50 | Iteration number: [380/393] 96% | Training loss: 0.6921279331571177
Epoch: 50 | Iteration number: [390/393] 99% | Training loss: 0.6920944965802707

 End of epoch: 50 | Train Loss: 0.6903344831090543 | Training Time: 67 

 End of epoch: 50 | Eval Loss: 0.6906632890506667 | Evaluating Time: 17 
Epoch: 51 | Iteration number: [10/393] 2% | Training loss: 0.7600717365741729
Epoch: 51 | Iteration number: [20/393] 5% | Training loss: 0.72551009953022
Epoch: 51 | Iteration number: [30/393] 7% | Training loss: 0.7133811076482137
Epoch: 51 | Iteration number: [40/393] 10% | Training loss: 0.7074833601713181
Epoch: 51 | Iteration number: [50/393] 12% | Training loss: 0.7036937713623047
Epoch: 51 | Iteration number: [60/393] 15% | Training loss: 0.7016449292500814
Epoch: 51 | Iteration number: [70/393] 17% | Training loss: 0.7000331018652235
Epoch: 51 | Iteration number: [80/393] 20% | Training loss: 0.6989102743566036
Epoch: 51 | Iteration number: [90/393] 22% | Training loss: 0.698041401969062
Epoch: 51 | Iteration number: [100/393] 25% | Training loss: 0.6972422283887864
Epoch: 51 | Iteration number: [110/393] 27% | Training loss: 0.6966349352489818
Epoch: 51 | Iteration number: [120/393] 30% | Training loss: 0.6960610911250115
Epoch: 51 | Iteration number: [130/393] 33% | Training loss: 0.695680837906324
Epoch: 51 | Iteration number: [140/393] 35% | Training loss: 0.6953023829630443
Epoch: 51 | Iteration number: [150/393] 38% | Training loss: 0.6948895215988159
Epoch: 51 | Iteration number: [160/393] 40% | Training loss: 0.6945742584764958
Epoch: 51 | Iteration number: [170/393] 43% | Training loss: 0.6943151884219225
Epoch: 51 | Iteration number: [180/393] 45% | Training loss: 0.6941351473331452
Epoch: 51 | Iteration number: [190/393] 48% | Training loss: 0.6940214047306462
Epoch: 51 | Iteration number: [200/393] 50% | Training loss: 0.6937691080570221
Epoch: 51 | Iteration number: [210/393] 53% | Training loss: 0.6936048252241952
Epoch: 51 | Iteration number: [220/393] 55% | Training loss: 0.6935118339278481
Epoch: 51 | Iteration number: [230/393] 58% | Training loss: 0.6933481050574262
Epoch: 51 | Iteration number: [240/393] 61% | Training loss: 0.6931994055708249
Epoch: 51 | Iteration number: [250/393] 63% | Training loss: 0.6930983152389526
Epoch: 51 | Iteration number: [260/393] 66% | Training loss: 0.6929934013348359
Epoch: 51 | Iteration number: [270/393] 68% | Training loss: 0.6928981184959412
Epoch: 51 | Iteration number: [280/393] 71% | Training loss: 0.6928193324378559
Epoch: 51 | Iteration number: [290/393] 73% | Training loss: 0.6926969630964871
Epoch: 51 | Iteration number: [300/393] 76% | Training loss: 0.6926392583052318
Epoch: 51 | Iteration number: [310/393] 78% | Training loss: 0.6925941880672208
Epoch: 51 | Iteration number: [320/393] 81% | Training loss: 0.6924937061965466
Epoch: 51 | Iteration number: [330/393] 83% | Training loss: 0.6924332125620408
Epoch: 51 | Iteration number: [340/393] 86% | Training loss: 0.6923646804164437
Epoch: 51 | Iteration number: [350/393] 89% | Training loss: 0.692324891941888
Epoch: 51 | Iteration number: [360/393] 91% | Training loss: 0.6922839774025811
Epoch: 51 | Iteration number: [370/393] 94% | Training loss: 0.6922133270147685
Epoch: 51 | Iteration number: [380/393] 96% | Training loss: 0.6921612176455949
Epoch: 51 | Iteration number: [390/393] 99% | Training loss: 0.69206835826238

 End of epoch: 51 | Train Loss: 0.6903078516627693 | Training Time: 67 

 End of epoch: 51 | Eval Loss: 0.6908245183983628 | Evaluating Time: 18 
Epoch: 52 | Iteration number: [10/393] 2% | Training loss: 0.759341698884964
Epoch: 52 | Iteration number: [20/393] 5% | Training loss: 0.7256036847829819
Epoch: 52 | Iteration number: [30/393] 7% | Training loss: 0.7140361487865448
Epoch: 52 | Iteration number: [40/393] 10% | Training loss: 0.7082087934017182
Epoch: 52 | Iteration number: [50/393] 12% | Training loss: 0.7047059667110444
Epoch: 52 | Iteration number: [60/393] 15% | Training loss: 0.7024556547403336
Epoch: 52 | Iteration number: [70/393] 17% | Training loss: 0.7009826804910387
Epoch: 52 | Iteration number: [80/393] 20% | Training loss: 0.6995626918971538
Epoch: 52 | Iteration number: [90/393] 22% | Training loss: 0.6985899998082055
Epoch: 52 | Iteration number: [100/393] 25% | Training loss: 0.6978755211830139
Epoch: 52 | Iteration number: [110/393] 27% | Training loss: 0.6972229464487596
Epoch: 52 | Iteration number: [120/393] 30% | Training loss: 0.6967047835389774
Epoch: 52 | Iteration number: [130/393] 33% | Training loss: 0.6962706845540266
Epoch: 52 | Iteration number: [140/393] 35% | Training loss: 0.6958797901868821
Epoch: 52 | Iteration number: [150/393] 38% | Training loss: 0.6954977206389109
Epoch: 52 | Iteration number: [160/393] 40% | Training loss: 0.6951578758656979
Epoch: 52 | Iteration number: [170/393] 43% | Training loss: 0.6948872660889345
Epoch: 52 | Iteration number: [180/393] 45% | Training loss: 0.6946313040124046
Epoch: 52 | Iteration number: [190/393] 48% | Training loss: 0.6944273396542198
Epoch: 52 | Iteration number: [200/393] 50% | Training loss: 0.6942559316754341
Epoch: 52 | Iteration number: [210/393] 53% | Training loss: 0.6940654104664212
Epoch: 52 | Iteration number: [220/393] 55% | Training loss: 0.6939051181077958
Epoch: 52 | Iteration number: [230/393] 58% | Training loss: 0.6937411818815314
Epoch: 52 | Iteration number: [240/393] 61% | Training loss: 0.6935763520499071
Epoch: 52 | Iteration number: [250/393] 63% | Training loss: 0.6934765281677246
Epoch: 52 | Iteration number: [260/393] 66% | Training loss: 0.6933541020521751
Epoch: 52 | Iteration number: [270/393] 68% | Training loss: 0.6932045285348539
Epoch: 52 | Iteration number: [280/393] 71% | Training loss: 0.6931223092334611
Epoch: 52 | Iteration number: [290/393] 73% | Training loss: 0.6930617102261247
Epoch: 52 | Iteration number: [300/393] 76% | Training loss: 0.6929327569405238
Epoch: 52 | Iteration number: [310/393] 78% | Training loss: 0.6928673980697508
Epoch: 52 | Iteration number: [320/393] 81% | Training loss: 0.6927337266504765
Epoch: 52 | Iteration number: [330/393] 83% | Training loss: 0.6926975672895258
Epoch: 52 | Iteration number: [340/393] 86% | Training loss: 0.6926203711944467
Epoch: 52 | Iteration number: [350/393] 89% | Training loss: 0.6925721071447645
Epoch: 52 | Iteration number: [360/393] 91% | Training loss: 0.6925140505035718
Epoch: 52 | Iteration number: [370/393] 94% | Training loss: 0.6924509079069705
Epoch: 52 | Iteration number: [380/393] 96% | Training loss: 0.6923545747995377
Epoch: 52 | Iteration number: [390/393] 99% | Training loss: 0.692325180157637

 End of epoch: 52 | Train Loss: 0.6905550974925966 | Training Time: 67 

 End of epoch: 52 | Eval Loss: 0.6907412093512866 | Evaluating Time: 17 
Epoch: 53 | Iteration number: [10/393] 2% | Training loss: 0.7596813380718231
Epoch: 53 | Iteration number: [20/393] 5% | Training loss: 0.7242706060409546
Epoch: 53 | Iteration number: [30/393] 7% | Training loss: 0.7128049770991007
Epoch: 53 | Iteration number: [40/393] 10% | Training loss: 0.7072326421737671
Epoch: 53 | Iteration number: [50/393] 12% | Training loss: 0.703695924282074
Epoch: 53 | Iteration number: [60/393] 15% | Training loss: 0.7015394389629364
Epoch: 53 | Iteration number: [70/393] 17% | Training loss: 0.7000677798475538
Epoch: 53 | Iteration number: [80/393] 20% | Training loss: 0.6988620974123478
Epoch: 53 | Iteration number: [90/393] 22% | Training loss: 0.6979449285401238
Epoch: 53 | Iteration number: [100/393] 25% | Training loss: 0.6971820378303528
Epoch: 53 | Iteration number: [110/393] 27% | Training loss: 0.6966116813096133
Epoch: 53 | Iteration number: [120/393] 30% | Training loss: 0.6960754945874215
Epoch: 53 | Iteration number: [130/393] 33% | Training loss: 0.6956153044333825
Epoch: 53 | Iteration number: [140/393] 35% | Training loss: 0.6952151324067797
Epoch: 53 | Iteration number: [150/393] 38% | Training loss: 0.6949603847662608
Epoch: 53 | Iteration number: [160/393] 40% | Training loss: 0.6946838326752186
Epoch: 53 | Iteration number: [170/393] 43% | Training loss: 0.6943929237477919
Epoch: 53 | Iteration number: [180/393] 45% | Training loss: 0.6941936092244254
Epoch: 53 | Iteration number: [190/393] 48% | Training loss: 0.6940178366083848
Epoch: 53 | Iteration number: [200/393] 50% | Training loss: 0.6938234433531761
Epoch: 53 | Iteration number: [210/393] 53% | Training loss: 0.6936993000053224
Epoch: 53 | Iteration number: [220/393] 55% | Training loss: 0.6935286844318563
Epoch: 53 | Iteration number: [230/393] 58% | Training loss: 0.6933983603249425
Epoch: 53 | Iteration number: [240/393] 61% | Training loss: 0.6932973804573218
Epoch: 53 | Iteration number: [250/393] 63% | Training loss: 0.693175017118454
Epoch: 53 | Iteration number: [260/393] 66% | Training loss: 0.6930456241736045
Epoch: 53 | Iteration number: [270/393] 68% | Training loss: 0.6929505089918773
Epoch: 53 | Iteration number: [280/393] 71% | Training loss: 0.6928691035934857
Epoch: 53 | Iteration number: [290/393] 73% | Training loss: 0.6927942676790829
Epoch: 53 | Iteration number: [300/393] 76% | Training loss: 0.69265966852506
Epoch: 53 | Iteration number: [310/393] 78% | Training loss: 0.6925593599196403
Epoch: 53 | Iteration number: [320/393] 81% | Training loss: 0.6925036326050759
Epoch: 53 | Iteration number: [330/393] 83% | Training loss: 0.6924653369368929
Epoch: 53 | Iteration number: [340/393] 86% | Training loss: 0.6924105602152207
Epoch: 53 | Iteration number: [350/393] 89% | Training loss: 0.6923501532418387
Epoch: 53 | Iteration number: [360/393] 91% | Training loss: 0.6922518913944562
Epoch: 53 | Iteration number: [370/393] 94% | Training loss: 0.6922126813514813
Epoch: 53 | Iteration number: [380/393] 96% | Training loss: 0.6921635169731943
Epoch: 53 | Iteration number: [390/393] 99% | Training loss: 0.6921236591461377

 End of epoch: 53 | Train Loss: 0.6903529541789727 | Training Time: 67 

 End of epoch: 53 | Eval Loss: 0.6907178637932758 | Evaluating Time: 17 
Epoch: 54 | Iteration number: [10/393] 2% | Training loss: 0.7585853636264801
Epoch: 54 | Iteration number: [20/393] 5% | Training loss: 0.7248374462127686
Epoch: 54 | Iteration number: [30/393] 7% | Training loss: 0.7132745226224263
Epoch: 54 | Iteration number: [40/393] 10% | Training loss: 0.7076683312654495
Epoch: 54 | Iteration number: [50/393] 12% | Training loss: 0.704185471534729
Epoch: 54 | Iteration number: [60/393] 15% | Training loss: 0.7018271247545879
Epoch: 54 | Iteration number: [70/393] 17% | Training loss: 0.7001934792314257
Epoch: 54 | Iteration number: [80/393] 20% | Training loss: 0.6989295609295368
Epoch: 54 | Iteration number: [90/393] 22% | Training loss: 0.6979213145044115
Epoch: 54 | Iteration number: [100/393] 25% | Training loss: 0.6971995776891708
Epoch: 54 | Iteration number: [110/393] 27% | Training loss: 0.6965773051435297
Epoch: 54 | Iteration number: [120/393] 30% | Training loss: 0.6959612995386124
Epoch: 54 | Iteration number: [130/393] 33% | Training loss: 0.6954806061891409
Epoch: 54 | Iteration number: [140/393] 35% | Training loss: 0.6951299424682345
Epoch: 54 | Iteration number: [150/393] 38% | Training loss: 0.6948541299502055
Epoch: 54 | Iteration number: [160/393] 40% | Training loss: 0.6946313984692096
Epoch: 54 | Iteration number: [170/393] 43% | Training loss: 0.6944028111065135
Epoch: 54 | Iteration number: [180/393] 45% | Training loss: 0.6941693931818008
Epoch: 54 | Iteration number: [190/393] 48% | Training loss: 0.6940035402774811
Epoch: 54 | Iteration number: [200/393] 50% | Training loss: 0.6937704119086265
Epoch: 54 | Iteration number: [210/393] 53% | Training loss: 0.693634283542633
Epoch: 54 | Iteration number: [220/393] 55% | Training loss: 0.6934627516703172
Epoch: 54 | Iteration number: [230/393] 58% | Training loss: 0.6933328633723052
Epoch: 54 | Iteration number: [240/393] 61% | Training loss: 0.6931977008779844
Epoch: 54 | Iteration number: [250/393] 63% | Training loss: 0.6931150536537171
Epoch: 54 | Iteration number: [260/393] 66% | Training loss: 0.6930010855197907
Epoch: 54 | Iteration number: [270/393] 68% | Training loss: 0.6928422018333718
Epoch: 54 | Iteration number: [280/393] 71% | Training loss: 0.6927076601556369
Epoch: 54 | Iteration number: [290/393] 73% | Training loss: 0.6926236236917561
Epoch: 54 | Iteration number: [300/393] 76% | Training loss: 0.6925138084093729
Epoch: 54 | Iteration number: [310/393] 78% | Training loss: 0.6924221454128142
Epoch: 54 | Iteration number: [320/393] 81% | Training loss: 0.6923670912161469
Epoch: 54 | Iteration number: [330/393] 83% | Training loss: 0.6923117193308743
Epoch: 54 | Iteration number: [340/393] 86% | Training loss: 0.6922592103481293
Epoch: 54 | Iteration number: [350/393] 89% | Training loss: 0.6921896011488778
Epoch: 54 | Iteration number: [360/393] 91% | Training loss: 0.6921491732199987
Epoch: 54 | Iteration number: [370/393] 94% | Training loss: 0.6921189077802606
Epoch: 54 | Iteration number: [380/393] 96% | Training loss: 0.6920845932082126
Epoch: 54 | Iteration number: [390/393] 99% | Training loss: 0.6920245427351731

 End of epoch: 54 | Train Loss: 0.6902682441488174 | Training Time: 67 

 End of epoch: 54 | Eval Loss: 0.6907075667867855 | Evaluating Time: 17 
Epoch: 55 | Iteration number: [10/393] 2% | Training loss: 0.7595601916313172
Epoch: 55 | Iteration number: [20/393] 5% | Training loss: 0.7255130469799042
Epoch: 55 | Iteration number: [30/393] 7% | Training loss: 0.713957013686498
Epoch: 55 | Iteration number: [40/393] 10% | Training loss: 0.7077149093151093
Epoch: 55 | Iteration number: [50/393] 12% | Training loss: 0.7040463995933532
Epoch: 55 | Iteration number: [60/393] 15% | Training loss: 0.701563087105751
Epoch: 55 | Iteration number: [70/393] 17% | Training loss: 0.7000125476292202
Epoch: 55 | Iteration number: [80/393] 20% | Training loss: 0.6988990113139153
Epoch: 55 | Iteration number: [90/393] 22% | Training loss: 0.6979662795861562
Epoch: 55 | Iteration number: [100/393] 25% | Training loss: 0.6971407276391983
Epoch: 55 | Iteration number: [110/393] 27% | Training loss: 0.696509622443806
Epoch: 55 | Iteration number: [120/393] 30% | Training loss: 0.6959957192341487
Epoch: 55 | Iteration number: [130/393] 33% | Training loss: 0.6955927926760453
Epoch: 55 | Iteration number: [140/393] 35% | Training loss: 0.6952089990888323
Epoch: 55 | Iteration number: [150/393] 38% | Training loss: 0.6948493580023448
Epoch: 55 | Iteration number: [160/393] 40% | Training loss: 0.6945775575935841
Epoch: 55 | Iteration number: [170/393] 43% | Training loss: 0.6943201524369856
Epoch: 55 | Iteration number: [180/393] 45% | Training loss: 0.6941050499677658
Epoch: 55 | Iteration number: [190/393] 48% | Training loss: 0.6939142490688123
Epoch: 55 | Iteration number: [200/393] 50% | Training loss: 0.6937500050663948
Epoch: 55 | Iteration number: [210/393] 53% | Training loss: 0.6935646278517587
Epoch: 55 | Iteration number: [220/393] 55% | Training loss: 0.6933792599222877
Epoch: 55 | Iteration number: [230/393] 58% | Training loss: 0.6932643032592276
Epoch: 55 | Iteration number: [240/393] 61% | Training loss: 0.6931412244836489
Epoch: 55 | Iteration number: [250/393] 63% | Training loss: 0.6930442950725555
Epoch: 55 | Iteration number: [260/393] 66% | Training loss: 0.6929702275074445
Epoch: 55 | Iteration number: [270/393] 68% | Training loss: 0.6928473468180056
Epoch: 55 | Iteration number: [280/393] 71% | Training loss: 0.6926852158137731
Epoch: 55 | Iteration number: [290/393] 73% | Training loss: 0.6926123952043468
Epoch: 55 | Iteration number: [300/393] 76% | Training loss: 0.6925025566418965
Epoch: 55 | Iteration number: [310/393] 78% | Training loss: 0.6924576470928807
Epoch: 55 | Iteration number: [320/393] 81% | Training loss: 0.6923964759334922
Epoch: 55 | Iteration number: [330/393] 83% | Training loss: 0.692354677662705
Epoch: 55 | Iteration number: [340/393] 86% | Training loss: 0.692313812585438
Epoch: 55 | Iteration number: [350/393] 89% | Training loss: 0.6922559966359819
Epoch: 55 | Iteration number: [360/393] 91% | Training loss: 0.6921807358662287
Epoch: 55 | Iteration number: [370/393] 94% | Training loss: 0.6921515429342115
Epoch: 55 | Iteration number: [380/393] 96% | Training loss: 0.6921020892105605
Epoch: 55 | Iteration number: [390/393] 99% | Training loss: 0.6920440410956358

 End of epoch: 55 | Train Loss: 0.6902628736641571 | Training Time: 67 

 End of epoch: 55 | Eval Loss: 0.69067104008733 | Evaluating Time: 17 
Epoch: 56 | Iteration number: [10/393] 2% | Training loss: 0.7581581354141236
Epoch: 56 | Iteration number: [20/393] 5% | Training loss: 0.7245933532714843
Epoch: 56 | Iteration number: [30/393] 7% | Training loss: 0.7131494740645091
Epoch: 56 | Iteration number: [40/393] 10% | Training loss: 0.7073265880346298
Epoch: 56 | Iteration number: [50/393] 12% | Training loss: 0.70364910364151
Epoch: 56 | Iteration number: [60/393] 15% | Training loss: 0.7014351854721705
Epoch: 56 | Iteration number: [70/393] 17% | Training loss: 0.6997360595635005
Epoch: 56 | Iteration number: [80/393] 20% | Training loss: 0.6984203226864338
Epoch: 56 | Iteration number: [90/393] 22% | Training loss: 0.6974692344665527
Epoch: 56 | Iteration number: [100/393] 25% | Training loss: 0.6968025267124176
Epoch: 56 | Iteration number: [110/393] 27% | Training loss: 0.6962612975727428
Epoch: 56 | Iteration number: [120/393] 30% | Training loss: 0.6957859968145689
Epoch: 56 | Iteration number: [130/393] 33% | Training loss: 0.6953414687743553
Epoch: 56 | Iteration number: [140/393] 35% | Training loss: 0.6949149250984192
Epoch: 56 | Iteration number: [150/393] 38% | Training loss: 0.6945990280310312
Epoch: 56 | Iteration number: [160/393] 40% | Training loss: 0.6943654526025057
Epoch: 56 | Iteration number: [170/393] 43% | Training loss: 0.6941219740054186
Epoch: 56 | Iteration number: [180/393] 45% | Training loss: 0.6939049031999376
Epoch: 56 | Iteration number: [190/393] 48% | Training loss: 0.6937182620952004
Epoch: 56 | Iteration number: [200/393] 50% | Training loss: 0.6935223689675332
Epoch: 56 | Iteration number: [210/393] 53% | Training loss: 0.6933357218901316
Epoch: 56 | Iteration number: [220/393] 55% | Training loss: 0.6931680866263129
Epoch: 56 | Iteration number: [230/393] 58% | Training loss: 0.6930328763049581
Epoch: 56 | Iteration number: [240/393] 61% | Training loss: 0.692933912575245
Epoch: 56 | Iteration number: [250/393] 63% | Training loss: 0.6928140089511872
Epoch: 56 | Iteration number: [260/393] 66% | Training loss: 0.6927386370988993
Epoch: 56 | Iteration number: [270/393] 68% | Training loss: 0.6926248133182525
Epoch: 56 | Iteration number: [280/393] 71% | Training loss: 0.6925320710454669
Epoch: 56 | Iteration number: [290/393] 73% | Training loss: 0.6924524607329533
Epoch: 56 | Iteration number: [300/393] 76% | Training loss: 0.6923849711815516
Epoch: 56 | Iteration number: [310/393] 78% | Training loss: 0.6923484642659464
Epoch: 56 | Iteration number: [320/393] 81% | Training loss: 0.6923073943704366
Epoch: 56 | Iteration number: [330/393] 83% | Training loss: 0.6922546045346694
Epoch: 56 | Iteration number: [340/393] 86% | Training loss: 0.6922191833748537
Epoch: 56 | Iteration number: [350/393] 89% | Training loss: 0.6921729518686022
Epoch: 56 | Iteration number: [360/393] 91% | Training loss: 0.6921084943744872
Epoch: 56 | Iteration number: [370/393] 94% | Training loss: 0.69204995825484
Epoch: 56 | Iteration number: [380/393] 96% | Training loss: 0.6920270232777846
Epoch: 56 | Iteration number: [390/393] 99% | Training loss: 0.6919849227636289

 End of epoch: 56 | Train Loss: 0.6902134265305129 | Training Time: 67 

 End of epoch: 56 | Eval Loss: 0.6906747319260422 | Evaluating Time: 17 
Epoch: 57 | Iteration number: [10/393] 2% | Training loss: 0.7593691945075989
Epoch: 57 | Iteration number: [20/393] 5% | Training loss: 0.7248520582914353
Epoch: 57 | Iteration number: [30/393] 7% | Training loss: 0.7134157240390777
Epoch: 57 | Iteration number: [40/393] 10% | Training loss: 0.707619009912014
Epoch: 57 | Iteration number: [50/393] 12% | Training loss: 0.7041352987289429
Epoch: 57 | Iteration number: [60/393] 15% | Training loss: 0.7019532740116119
Epoch: 57 | Iteration number: [70/393] 17% | Training loss: 0.7001174816063472
Epoch: 57 | Iteration number: [80/393] 20% | Training loss: 0.6989607803523541
Epoch: 57 | Iteration number: [90/393] 22% | Training loss: 0.6979600754049089
Epoch: 57 | Iteration number: [100/393] 25% | Training loss: 0.6971452641487121
Epoch: 57 | Iteration number: [110/393] 27% | Training loss: 0.6965345035899769
Epoch: 57 | Iteration number: [120/393] 30% | Training loss: 0.6960291624069214
Epoch: 57 | Iteration number: [130/393] 33% | Training loss: 0.6956052312484154
Epoch: 57 | Iteration number: [140/393] 35% | Training loss: 0.6952132655041559
Epoch: 57 | Iteration number: [150/393] 38% | Training loss: 0.6948740474383036
Epoch: 57 | Iteration number: [160/393] 40% | Training loss: 0.6945932108908892
Epoch: 57 | Iteration number: [170/393] 43% | Training loss: 0.6942293966517729
Epoch: 57 | Iteration number: [180/393] 45% | Training loss: 0.6940513326062097
Epoch: 57 | Iteration number: [190/393] 48% | Training loss: 0.6938412553385684
Epoch: 57 | Iteration number: [200/393] 50% | Training loss: 0.6937091460824013
Epoch: 57 | Iteration number: [210/393] 53% | Training loss: 0.6935806186426253
Epoch: 57 | Iteration number: [220/393] 55% | Training loss: 0.6934008853002028
Epoch: 57 | Iteration number: [230/393] 58% | Training loss: 0.6932379258715589
Epoch: 57 | Iteration number: [240/393] 61% | Training loss: 0.693084799995025
Epoch: 57 | Iteration number: [250/393] 63% | Training loss: 0.6929798741340637
Epoch: 57 | Iteration number: [260/393] 66% | Training loss: 0.6929334642795416
Epoch: 57 | Iteration number: [270/393] 68% | Training loss: 0.6928657059316282
Epoch: 57 | Iteration number: [280/393] 71% | Training loss: 0.6927730683769499
Epoch: 57 | Iteration number: [290/393] 73% | Training loss: 0.6926880891980796
Epoch: 57 | Iteration number: [300/393] 76% | Training loss: 0.6926129774252574
Epoch: 57 | Iteration number: [310/393] 78% | Training loss: 0.6925233342955189
Epoch: 57 | Iteration number: [320/393] 81% | Training loss: 0.6924265392124653
Epoch: 57 | Iteration number: [330/393] 83% | Training loss: 0.6923862040042877
Epoch: 57 | Iteration number: [340/393] 86% | Training loss: 0.6923204846241895
Epoch: 57 | Iteration number: [350/393] 89% | Training loss: 0.692259008032935
Epoch: 57 | Iteration number: [360/393] 91% | Training loss: 0.6921953901648521
Epoch: 57 | Iteration number: [370/393] 94% | Training loss: 0.6921160994349299
Epoch: 57 | Iteration number: [380/393] 96% | Training loss: 0.6920734000833411
Epoch: 57 | Iteration number: [390/393] 99% | Training loss: 0.6919840031709427

 End of epoch: 57 | Train Loss: 0.6902086486039878 | Training Time: 67 

 End of epoch: 57 | Eval Loss: 0.6906932105823439 | Evaluating Time: 18 
Epoch: 58 | Iteration number: [10/393] 2% | Training loss: 0.7592792928218841
Epoch: 58 | Iteration number: [20/393] 5% | Training loss: 0.7250345200300217
Epoch: 58 | Iteration number: [30/393] 7% | Training loss: 0.7132562359174093
Epoch: 58 | Iteration number: [40/393] 10% | Training loss: 0.7075886622071266
Epoch: 58 | Iteration number: [50/393] 12% | Training loss: 0.7043709361553192
Epoch: 58 | Iteration number: [60/393] 15% | Training loss: 0.7020631392796834
Epoch: 58 | Iteration number: [70/393] 17% | Training loss: 0.7004516022545951
Epoch: 58 | Iteration number: [80/393] 20% | Training loss: 0.6991002053022385
Epoch: 58 | Iteration number: [90/393] 22% | Training loss: 0.6980301631821526
Epoch: 58 | Iteration number: [100/393] 25% | Training loss: 0.6971637916564941
Epoch: 58 | Iteration number: [110/393] 27% | Training loss: 0.6965450590307062
Epoch: 58 | Iteration number: [120/393] 30% | Training loss: 0.6960264891386032
Epoch: 58 | Iteration number: [130/393] 33% | Training loss: 0.6956171801457038
Epoch: 58 | Iteration number: [140/393] 35% | Training loss: 0.6951212133680071
Epoch: 58 | Iteration number: [150/393] 38% | Training loss: 0.6947950681050619
Epoch: 58 | Iteration number: [160/393] 40% | Training loss: 0.6944761268794537
Epoch: 58 | Iteration number: [170/393] 43% | Training loss: 0.6942125429125393
Epoch: 58 | Iteration number: [180/393] 45% | Training loss: 0.6939713272783491
Epoch: 58 | Iteration number: [190/393] 48% | Training loss: 0.6937273320398832
Epoch: 58 | Iteration number: [200/393] 50% | Training loss: 0.6935299387574196
Epoch: 58 | Iteration number: [210/393] 53% | Training loss: 0.6933795772847675
Epoch: 58 | Iteration number: [220/393] 55% | Training loss: 0.6932831642302599
Epoch: 58 | Iteration number: [230/393] 58% | Training loss: 0.693168067154677
Epoch: 58 | Iteration number: [240/393] 61% | Training loss: 0.6930488909284274
Epoch: 58 | Iteration number: [250/393] 63% | Training loss: 0.6929435935020447
Epoch: 58 | Iteration number: [260/393] 66% | Training loss: 0.6928226044544807
Epoch: 58 | Iteration number: [270/393] 68% | Training loss: 0.6927249917277584
Epoch: 58 | Iteration number: [280/393] 71% | Training loss: 0.6925978811723845
Epoch: 58 | Iteration number: [290/393] 73% | Training loss: 0.6925361505870161
Epoch: 58 | Iteration number: [300/393] 76% | Training loss: 0.6924569449822108
Epoch: 58 | Iteration number: [310/393] 78% | Training loss: 0.692381372374873
Epoch: 58 | Iteration number: [320/393] 81% | Training loss: 0.6923374330624938
Epoch: 58 | Iteration number: [330/393] 83% | Training loss: 0.6923233680652849
Epoch: 58 | Iteration number: [340/393] 86% | Training loss: 0.6922483540633145
Epoch: 58 | Iteration number: [350/393] 89% | Training loss: 0.692209688595363
Epoch: 58 | Iteration number: [360/393] 91% | Training loss: 0.692164828379949
Epoch: 58 | Iteration number: [370/393] 94% | Training loss: 0.6921340929495322
Epoch: 58 | Iteration number: [380/393] 96% | Training loss: 0.6920874357223511
Epoch: 58 | Iteration number: [390/393] 99% | Training loss: 0.6920632269137945

 End of epoch: 58 | Train Loss: 0.6902853079121228 | Training Time: 67 

 End of epoch: 58 | Eval Loss: 0.6907985976764134 | Evaluating Time: 17 
Epoch: 59 | Iteration number: [10/393] 2% | Training loss: 0.7598868668079376
Epoch: 59 | Iteration number: [20/393] 5% | Training loss: 0.7247951060533524
Epoch: 59 | Iteration number: [30/393] 7% | Training loss: 0.7138259987036387
Epoch: 59 | Iteration number: [40/393] 10% | Training loss: 0.707973127067089
Epoch: 59 | Iteration number: [50/393] 12% | Training loss: 0.7045146787166595
Epoch: 59 | Iteration number: [60/393] 15% | Training loss: 0.7020789394776027
Epoch: 59 | Iteration number: [70/393] 17% | Training loss: 0.7003276058605739
Epoch: 59 | Iteration number: [80/393] 20% | Training loss: 0.6991083271801471
Epoch: 59 | Iteration number: [90/393] 22% | Training loss: 0.6981578065289391
Epoch: 59 | Iteration number: [100/393] 25% | Training loss: 0.6972965055704117
Epoch: 59 | Iteration number: [110/393] 27% | Training loss: 0.6965597185221586
Epoch: 59 | Iteration number: [120/393] 30% | Training loss: 0.6959996039668719
Epoch: 59 | Iteration number: [130/393] 33% | Training loss: 0.6955219076229976
Epoch: 59 | Iteration number: [140/393] 35% | Training loss: 0.6950735735041754
Epoch: 59 | Iteration number: [150/393] 38% | Training loss: 0.6947702058156331
Epoch: 59 | Iteration number: [160/393] 40% | Training loss: 0.6945104006677866
Epoch: 59 | Iteration number: [170/393] 43% | Training loss: 0.6942668925313389
Epoch: 59 | Iteration number: [180/393] 45% | Training loss: 0.6940387576818466
Epoch: 59 | Iteration number: [190/393] 48% | Training loss: 0.6938819072748486
Epoch: 59 | Iteration number: [200/393] 50% | Training loss: 0.6937394398450851
Epoch: 59 | Iteration number: [210/393] 53% | Training loss: 0.6936171693461282
Epoch: 59 | Iteration number: [220/393] 55% | Training loss: 0.6934575874697079
Epoch: 59 | Iteration number: [230/393] 58% | Training loss: 0.6933025655539139
Epoch: 59 | Iteration number: [240/393] 61% | Training loss: 0.6931781927744548
Epoch: 59 | Iteration number: [250/393] 63% | Training loss: 0.6930251672267914
Epoch: 59 | Iteration number: [260/393] 66% | Training loss: 0.692921869800641
Epoch: 59 | Iteration number: [270/393] 68% | Training loss: 0.6927906669952252
Epoch: 59 | Iteration number: [280/393] 71% | Training loss: 0.6927297704986164
Epoch: 59 | Iteration number: [290/393] 73% | Training loss: 0.6926502842327644
Epoch: 59 | Iteration number: [300/393] 76% | Training loss: 0.6925556554396948
Epoch: 59 | Iteration number: [310/393] 78% | Training loss: 0.6924721191006322
Epoch: 59 | Iteration number: [320/393] 81% | Training loss: 0.6923879351466894
Epoch: 59 | Iteration number: [330/393] 83% | Training loss: 0.6922986539927396
Epoch: 59 | Iteration number: [340/393] 86% | Training loss: 0.6922336674788419
Epoch: 59 | Iteration number: [350/393] 89% | Training loss: 0.6921889693396432
Epoch: 59 | Iteration number: [360/393] 91% | Training loss: 0.6921009568704499
Epoch: 59 | Iteration number: [370/393] 94% | Training loss: 0.6920651682325312
Epoch: 59 | Iteration number: [380/393] 96% | Training loss: 0.6920295814150258
Epoch: 59 | Iteration number: [390/393] 99% | Training loss: 0.6919852163547124

 End of epoch: 59 | Train Loss: 0.690207787900784 | Training Time: 67 

 End of epoch: 59 | Eval Loss: 0.6905251936036714 | Evaluating Time: 17 
Epoch: 60 | Iteration number: [10/393] 2% | Training loss: 0.7592793822288513
Epoch: 60 | Iteration number: [20/393] 5% | Training loss: 0.7253774583339692
Epoch: 60 | Iteration number: [30/393] 7% | Training loss: 0.7136881609757741
Epoch: 60 | Iteration number: [40/393] 10% | Training loss: 0.7079396203160286
Epoch: 60 | Iteration number: [50/393] 12% | Training loss: 0.7044162261486053
Epoch: 60 | Iteration number: [60/393] 15% | Training loss: 0.7018910338481267
Epoch: 60 | Iteration number: [70/393] 17% | Training loss: 0.7002906424658639
Epoch: 60 | Iteration number: [80/393] 20% | Training loss: 0.6989820696413517
Epoch: 60 | Iteration number: [90/393] 22% | Training loss: 0.698067863782247
Epoch: 60 | Iteration number: [100/393] 25% | Training loss: 0.6973193448781967
Epoch: 60 | Iteration number: [110/393] 27% | Training loss: 0.6966844287785616
Epoch: 60 | Iteration number: [120/393] 30% | Training loss: 0.6961250722408294
Epoch: 60 | Iteration number: [130/393] 33% | Training loss: 0.6956691352220682
Epoch: 60 | Iteration number: [140/393] 35% | Training loss: 0.695362183025905
Epoch: 60 | Iteration number: [150/393] 38% | Training loss: 0.6949948680400848
Epoch: 60 | Iteration number: [160/393] 40% | Training loss: 0.6946587353944779
Epoch: 60 | Iteration number: [170/393] 43% | Training loss: 0.6944500071160934
Epoch: 60 | Iteration number: [180/393] 45% | Training loss: 0.694140628973643
Epoch: 60 | Iteration number: [190/393] 48% | Training loss: 0.6939831432543303
Epoch: 60 | Iteration number: [200/393] 50% | Training loss: 0.693780190050602
Epoch: 60 | Iteration number: [210/393] 53% | Training loss: 0.6936150553680601
Epoch: 60 | Iteration number: [220/393] 55% | Training loss: 0.6933566949584268
Epoch: 60 | Iteration number: [230/393] 58% | Training loss: 0.6932127377261286
Epoch: 60 | Iteration number: [240/393] 61% | Training loss: 0.6931067270537218
Epoch: 60 | Iteration number: [250/393] 63% | Training loss: 0.6930074326992035
Epoch: 60 | Iteration number: [260/393] 66% | Training loss: 0.6928907146820655
Epoch: 60 | Iteration number: [270/393] 68% | Training loss: 0.692759018253397
Epoch: 60 | Iteration number: [280/393] 71% | Training loss: 0.6926396250724792
Epoch: 60 | Iteration number: [290/393] 73% | Training loss: 0.6925367525939283
Epoch: 60 | Iteration number: [300/393] 76% | Training loss: 0.6924644114573797
Epoch: 60 | Iteration number: [310/393] 78% | Training loss: 0.6924098093663492
Epoch: 60 | Iteration number: [320/393] 81% | Training loss: 0.6923488615080714
Epoch: 60 | Iteration number: [330/393] 83% | Training loss: 0.6923117955525716
Epoch: 60 | Iteration number: [340/393] 86% | Training loss: 0.6922328242484261
Epoch: 60 | Iteration number: [350/393] 89% | Training loss: 0.6921576431819371
Epoch: 60 | Iteration number: [360/393] 91% | Training loss: 0.6921171908577283
Epoch: 60 | Iteration number: [370/393] 94% | Training loss: 0.6920799290811693
Epoch: 60 | Iteration number: [380/393] 96% | Training loss: 0.6920043833945927
Epoch: 60 | Iteration number: [390/393] 99% | Training loss: 0.6919717557919332

 End of epoch: 60 | Train Loss: 0.6901934541212087 | Training Time: 67 

 End of epoch: 60 | Eval Loss: 0.6905673194904717 | Evaluating Time: 18 
Epoch: 61 | Iteration number: [10/393] 2% | Training loss: 0.7593363702297211
Epoch: 61 | Iteration number: [20/393] 5% | Training loss: 0.724631866812706
Epoch: 61 | Iteration number: [30/393] 7% | Training loss: 0.71333127617836
Epoch: 61 | Iteration number: [40/393] 10% | Training loss: 0.7075357407331466
Epoch: 61 | Iteration number: [50/393] 12% | Training loss: 0.7042428517341613
Epoch: 61 | Iteration number: [60/393] 15% | Training loss: 0.701823478937149
Epoch: 61 | Iteration number: [70/393] 17% | Training loss: 0.7001150131225586
Epoch: 61 | Iteration number: [80/393] 20% | Training loss: 0.6988756082952022
Epoch: 61 | Iteration number: [90/393] 22% | Training loss: 0.6979445377985637
Epoch: 61 | Iteration number: [100/393] 25% | Training loss: 0.6971766078472137
Epoch: 61 | Iteration number: [110/393] 27% | Training loss: 0.6965110421180725
Epoch: 61 | Iteration number: [120/393] 30% | Training loss: 0.6959064548214277
Epoch: 61 | Iteration number: [130/393] 33% | Training loss: 0.695445670072849
Epoch: 61 | Iteration number: [140/393] 35% | Training loss: 0.6950079326118742
Epoch: 61 | Iteration number: [150/393] 38% | Training loss: 0.6946887950102488
Epoch: 61 | Iteration number: [160/393] 40% | Training loss: 0.6944091491401195
Epoch: 61 | Iteration number: [170/393] 43% | Training loss: 0.69413662517772
Epoch: 61 | Iteration number: [180/393] 45% | Training loss: 0.6939075857400894
Epoch: 61 | Iteration number: [190/393] 48% | Training loss: 0.6936972320079804
Epoch: 61 | Iteration number: [200/393] 50% | Training loss: 0.6934920820593834
Epoch: 61 | Iteration number: [210/393] 53% | Training loss: 0.693379176798321
Epoch: 61 | Iteration number: [220/393] 55% | Training loss: 0.69324633018537
Epoch: 61 | Iteration number: [230/393] 58% | Training loss: 0.6931533388469531
Epoch: 61 | Iteration number: [240/393] 61% | Training loss: 0.6930122944215934
Epoch: 61 | Iteration number: [250/393] 63% | Training loss: 0.6929072377681732
Epoch: 61 | Iteration number: [260/393] 66% | Training loss: 0.6928585272568922
Epoch: 61 | Iteration number: [270/393] 68% | Training loss: 0.6928236424922943
Epoch: 61 | Iteration number: [280/393] 71% | Training loss: 0.6927803401436124
Epoch: 61 | Iteration number: [290/393] 73% | Training loss: 0.6926858075733843
Epoch: 61 | Iteration number: [300/393] 76% | Training loss: 0.6926159665981928
Epoch: 61 | Iteration number: [310/393] 78% | Training loss: 0.6925769644398843
Epoch: 61 | Iteration number: [320/393] 81% | Training loss: 0.6924775278195738
Epoch: 61 | Iteration number: [330/393] 83% | Training loss: 0.6924039407209917
Epoch: 61 | Iteration number: [340/393] 86% | Training loss: 0.6923337690970477
Epoch: 61 | Iteration number: [350/393] 89% | Training loss: 0.692290746484484
Epoch: 61 | Iteration number: [360/393] 91% | Training loss: 0.6922085255384445
Epoch: 61 | Iteration number: [370/393] 94% | Training loss: 0.6921273698677888
Epoch: 61 | Iteration number: [380/393] 96% | Training loss: 0.6920815839579231
Epoch: 61 | Iteration number: [390/393] 99% | Training loss: 0.6920561521481245

 End of epoch: 61 | Train Loss: 0.6902933783506923 | Training Time: 67 

 End of epoch: 61 | Eval Loss: 0.690899341690297 | Evaluating Time: 17 
Epoch: 62 | Iteration number: [10/393] 2% | Training loss: 0.7596539735794068
Epoch: 62 | Iteration number: [20/393] 5% | Training loss: 0.7244039416313172
Epoch: 62 | Iteration number: [30/393] 7% | Training loss: 0.7132463117440542
Epoch: 62 | Iteration number: [40/393] 10% | Training loss: 0.707668599486351
Epoch: 62 | Iteration number: [50/393] 12% | Training loss: 0.7040038585662842
Epoch: 62 | Iteration number: [60/393] 15% | Training loss: 0.7017295897006989
Epoch: 62 | Iteration number: [70/393] 17% | Training loss: 0.7000613672392709
Epoch: 62 | Iteration number: [80/393] 20% | Training loss: 0.6986179672181606
Epoch: 62 | Iteration number: [90/393] 22% | Training loss: 0.6976348718007406
Epoch: 62 | Iteration number: [100/393] 25% | Training loss: 0.696834961771965
Epoch: 62 | Iteration number: [110/393] 27% | Training loss: 0.6962952077388763
Epoch: 62 | Iteration number: [120/393] 30% | Training loss: 0.6958826536933581
Epoch: 62 | Iteration number: [130/393] 33% | Training loss: 0.695453129364894
Epoch: 62 | Iteration number: [140/393] 35% | Training loss: 0.6950970113277435
Epoch: 62 | Iteration number: [150/393] 38% | Training loss: 0.6946769789854685
Epoch: 62 | Iteration number: [160/393] 40% | Training loss: 0.6944163415580988
Epoch: 62 | Iteration number: [170/393] 43% | Training loss: 0.694165706283906
Epoch: 62 | Iteration number: [180/393] 45% | Training loss: 0.6939372976620992
Epoch: 62 | Iteration number: [190/393] 48% | Training loss: 0.6937779570880689
Epoch: 62 | Iteration number: [200/393] 50% | Training loss: 0.6935420781373978
Epoch: 62 | Iteration number: [210/393] 53% | Training loss: 0.6934017856915792
Epoch: 62 | Iteration number: [220/393] 55% | Training loss: 0.6932326812635768
Epoch: 62 | Iteration number: [230/393] 58% | Training loss: 0.6931015245292498
Epoch: 62 | Iteration number: [240/393] 61% | Training loss: 0.6929759432872137
Epoch: 62 | Iteration number: [250/393] 63% | Training loss: 0.6928675532341003
Epoch: 62 | Iteration number: [260/393] 66% | Training loss: 0.6927674843714787
Epoch: 62 | Iteration number: [270/393] 68% | Training loss: 0.6926566867916673
Epoch: 62 | Iteration number: [280/393] 71% | Training loss: 0.6925924411841802
Epoch: 62 | Iteration number: [290/393] 73% | Training loss: 0.6925229364428027
Epoch: 62 | Iteration number: [300/393] 76% | Training loss: 0.692462124824524
Epoch: 62 | Iteration number: [310/393] 78% | Training loss: 0.6924112577592173
Epoch: 62 | Iteration number: [320/393] 81% | Training loss: 0.6923385659232736
Epoch: 62 | Iteration number: [330/393] 83% | Training loss: 0.692279623855244
Epoch: 62 | Iteration number: [340/393] 86% | Training loss: 0.6922080667579875
Epoch: 62 | Iteration number: [350/393] 89% | Training loss: 0.6921701073646546
Epoch: 62 | Iteration number: [360/393] 91% | Training loss: 0.6921153366565704
Epoch: 62 | Iteration number: [370/393] 94% | Training loss: 0.6921103640182599
Epoch: 62 | Iteration number: [380/393] 96% | Training loss: 0.6920815918006396
Epoch: 62 | Iteration number: [390/393] 99% | Training loss: 0.6920205533504487

 End of epoch: 62 | Train Loss: 0.6902461748086769 | Training Time: 67 

 End of epoch: 62 | Eval Loss: 0.6905986253096132 | Evaluating Time: 17 
Epoch: 63 | Iteration number: [10/393] 2% | Training loss: 0.7590897142887115
Epoch: 63 | Iteration number: [20/393] 5% | Training loss: 0.7244030773639679
Epoch: 63 | Iteration number: [30/393] 7% | Training loss: 0.7128608842690786
Epoch: 63 | Iteration number: [40/393] 10% | Training loss: 0.70687994658947
Epoch: 63 | Iteration number: [50/393] 12% | Training loss: 0.703559809923172
Epoch: 63 | Iteration number: [60/393] 15% | Training loss: 0.7011520902315775
Epoch: 63 | Iteration number: [70/393] 17% | Training loss: 0.6997219596590315
Epoch: 63 | Iteration number: [80/393] 20% | Training loss: 0.6983417093753814
Epoch: 63 | Iteration number: [90/393] 22% | Training loss: 0.6974534147315555
Epoch: 63 | Iteration number: [100/393] 25% | Training loss: 0.6967295771837234
Epoch: 63 | Iteration number: [110/393] 27% | Training loss: 0.6960929399186915
Epoch: 63 | Iteration number: [120/393] 30% | Training loss: 0.6955736160278321
Epoch: 63 | Iteration number: [130/393] 33% | Training loss: 0.6952675764377301
Epoch: 63 | Iteration number: [140/393] 35% | Training loss: 0.6949230108942305
Epoch: 63 | Iteration number: [150/393] 38% | Training loss: 0.694584420522054
Epoch: 63 | Iteration number: [160/393] 40% | Training loss: 0.6943018116056919
Epoch: 63 | Iteration number: [170/393] 43% | Training loss: 0.6940856835421394
Epoch: 63 | Iteration number: [180/393] 45% | Training loss: 0.693884195221795
Epoch: 63 | Iteration number: [190/393] 48% | Training loss: 0.6936860297855578
Epoch: 63 | Iteration number: [200/393] 50% | Training loss: 0.6935308569669724
Epoch: 63 | Iteration number: [210/393] 53% | Training loss: 0.6933177130562919
Epoch: 63 | Iteration number: [220/393] 55% | Training loss: 0.6931431745940989
Epoch: 63 | Iteration number: [230/393] 58% | Training loss: 0.693056212041689
Epoch: 63 | Iteration number: [240/393] 61% | Training loss: 0.692945770919323
Epoch: 63 | Iteration number: [250/393] 63% | Training loss: 0.6928260846138
Epoch: 63 | Iteration number: [260/393] 66% | Training loss: 0.692781240435747
Epoch: 63 | Iteration number: [270/393] 68% | Training loss: 0.6927097706883042
Epoch: 63 | Iteration number: [280/393] 71% | Training loss: 0.6926208704710006
Epoch: 63 | Iteration number: [290/393] 73% | Training loss: 0.6925181199764383
Epoch: 63 | Iteration number: [300/393] 76% | Training loss: 0.692498193581899
Epoch: 63 | Iteration number: [310/393] 78% | Training loss: 0.6924145502428855
Epoch: 63 | Iteration number: [320/393] 81% | Training loss: 0.6923326771706343
Epoch: 63 | Iteration number: [330/393] 83% | Training loss: 0.6922412816322211
Epoch: 63 | Iteration number: [340/393] 86% | Training loss: 0.6922088842181598
Epoch: 63 | Iteration number: [350/393] 89% | Training loss: 0.6921248524529593
Epoch: 63 | Iteration number: [360/393] 91% | Training loss: 0.6920873641967773
Epoch: 63 | Iteration number: [370/393] 94% | Training loss: 0.6920147435085193
Epoch: 63 | Iteration number: [380/393] 96% | Training loss: 0.6919436964549517
Epoch: 63 | Iteration number: [390/393] 99% | Training loss: 0.6919105280668307

 End of epoch: 63 | Train Loss: 0.6901424231420037 | Training Time: 67 

 End of epoch: 63 | Eval Loss: 0.6905152712549482 | Evaluating Time: 18 
Epoch: 64 | Iteration number: [10/393] 2% | Training loss: 0.7592277348041534
Epoch: 64 | Iteration number: [20/393] 5% | Training loss: 0.7250032931566238
Epoch: 64 | Iteration number: [30/393] 7% | Training loss: 0.7129059195518493
Epoch: 64 | Iteration number: [40/393] 10% | Training loss: 0.7072477236390113
Epoch: 64 | Iteration number: [50/393] 12% | Training loss: 0.703836909532547
Epoch: 64 | Iteration number: [60/393] 15% | Training loss: 0.701637809475263
Epoch: 64 | Iteration number: [70/393] 17% | Training loss: 0.6999942822115762
Epoch: 64 | Iteration number: [80/393] 20% | Training loss: 0.698790892213583
Epoch: 64 | Iteration number: [90/393] 22% | Training loss: 0.6979066769282023
Epoch: 64 | Iteration number: [100/393] 25% | Training loss: 0.6970907783508301
Epoch: 64 | Iteration number: [110/393] 27% | Training loss: 0.6964089745824987
Epoch: 64 | Iteration number: [120/393] 30% | Training loss: 0.6958590671420097
Epoch: 64 | Iteration number: [130/393] 33% | Training loss: 0.695492028273069
Epoch: 64 | Iteration number: [140/393] 35% | Training loss: 0.6951241297381264
Epoch: 64 | Iteration number: [150/393] 38% | Training loss: 0.694688735405604
Epoch: 64 | Iteration number: [160/393] 40% | Training loss: 0.6944316308945417
Epoch: 64 | Iteration number: [170/393] 43% | Training loss: 0.6940973930499132
Epoch: 64 | Iteration number: [180/393] 45% | Training loss: 0.6939002335071563
Epoch: 64 | Iteration number: [190/393] 48% | Training loss: 0.6936589950009396
Epoch: 64 | Iteration number: [200/393] 50% | Training loss: 0.6934861722588539
Epoch: 64 | Iteration number: [210/393] 53% | Training loss: 0.6932438708487011
Epoch: 64 | Iteration number: [220/393] 55% | Training loss: 0.6931616268374703
Epoch: 64 | Iteration number: [230/393] 58% | Training loss: 0.6930538522160572
Epoch: 64 | Iteration number: [240/393] 61% | Training loss: 0.6929013572633267
Epoch: 64 | Iteration number: [250/393] 63% | Training loss: 0.6928398985862732
Epoch: 64 | Iteration number: [260/393] 66% | Training loss: 0.692797426535533
Epoch: 64 | Iteration number: [270/393] 68% | Training loss: 0.6926773367104707
Epoch: 64 | Iteration number: [280/393] 71% | Training loss: 0.6925305954047611
Epoch: 64 | Iteration number: [290/393] 73% | Training loss: 0.6925066791731735
Epoch: 64 | Iteration number: [300/393] 76% | Training loss: 0.6924255424737931
Epoch: 64 | Iteration number: [310/393] 78% | Training loss: 0.6923660409065985
Epoch: 64 | Iteration number: [320/393] 81% | Training loss: 0.6923173749819398
Epoch: 64 | Iteration number: [330/393] 83% | Training loss: 0.6922540419029467
Epoch: 64 | Iteration number: [340/393] 86% | Training loss: 0.6922308055793538
Epoch: 64 | Iteration number: [350/393] 89% | Training loss: 0.6921371528080531
Epoch: 64 | Iteration number: [360/393] 91% | Training loss: 0.6921086099412707
Epoch: 64 | Iteration number: [370/393] 94% | Training loss: 0.6920611202716828
Epoch: 64 | Iteration number: [380/393] 96% | Training loss: 0.6920380286480251
Epoch: 64 | Iteration number: [390/393] 99% | Training loss: 0.6919608434041341

 End of epoch: 64 | Train Loss: 0.6901967052284997 | Training Time: 67 

 End of epoch: 64 | Eval Loss: 0.6905878745779699 | Evaluating Time: 17 
Epoch: 65 | Iteration number: [10/393] 2% | Training loss: 0.7596686840057373
Epoch: 65 | Iteration number: [20/393] 5% | Training loss: 0.7242215543985366
Epoch: 65 | Iteration number: [30/393] 7% | Training loss: 0.7129556914170583
Epoch: 65 | Iteration number: [40/393] 10% | Training loss: 0.7073306366801262
Epoch: 65 | Iteration number: [50/393] 12% | Training loss: 0.7040938615798951
Epoch: 65 | Iteration number: [60/393] 15% | Training loss: 0.701816388964653
Epoch: 65 | Iteration number: [70/393] 17% | Training loss: 0.7001111669199808
Epoch: 65 | Iteration number: [80/393] 20% | Training loss: 0.6988342270255089
Epoch: 65 | Iteration number: [90/393] 22% | Training loss: 0.6979174183474647
Epoch: 65 | Iteration number: [100/393] 25% | Training loss: 0.697262510061264
Epoch: 65 | Iteration number: [110/393] 27% | Training loss: 0.6965400153940374
Epoch: 65 | Iteration number: [120/393] 30% | Training loss: 0.6959880058964093
Epoch: 65 | Iteration number: [130/393] 33% | Training loss: 0.695540496477714
Epoch: 65 | Iteration number: [140/393] 35% | Training loss: 0.6951861585889544
Epoch: 65 | Iteration number: [150/393] 38% | Training loss: 0.6948907995223998
Epoch: 65 | Iteration number: [160/393] 40% | Training loss: 0.6945949696004391
Epoch: 65 | Iteration number: [170/393] 43% | Training loss: 0.6943651963682735
Epoch: 65 | Iteration number: [180/393] 45% | Training loss: 0.6940784040424559
Epoch: 65 | Iteration number: [190/393] 48% | Training loss: 0.6938176318218834
Epoch: 65 | Iteration number: [200/393] 50% | Training loss: 0.6936178967356682
Epoch: 65 | Iteration number: [210/393] 53% | Training loss: 0.6934840574150993
Epoch: 65 | Iteration number: [220/393] 55% | Training loss: 0.6933691065419804
Epoch: 65 | Iteration number: [230/393] 58% | Training loss: 0.6932562175004379
Epoch: 65 | Iteration number: [240/393] 61% | Training loss: 0.693134364237388
Epoch: 65 | Iteration number: [250/393] 63% | Training loss: 0.6930465993881225
Epoch: 65 | Iteration number: [260/393] 66% | Training loss: 0.6929286835285333
Epoch: 65 | Iteration number: [270/393] 68% | Training loss: 0.6928423912436874
Epoch: 65 | Iteration number: [280/393] 71% | Training loss: 0.6927508224334036
Epoch: 65 | Iteration number: [290/393] 73% | Training loss: 0.6926250866774855
Epoch: 65 | Iteration number: [300/393] 76% | Training loss: 0.6925265163183212
Epoch: 65 | Iteration number: [310/393] 78% | Training loss: 0.6923988644153841
Epoch: 65 | Iteration number: [320/393] 81% | Training loss: 0.6923103945329785
Epoch: 65 | Iteration number: [330/393] 83% | Training loss: 0.6922714518778252
Epoch: 65 | Iteration number: [340/393] 86% | Training loss: 0.6922111116787967
Epoch: 65 | Iteration number: [350/393] 89% | Training loss: 0.6921487993853432
Epoch: 65 | Iteration number: [360/393] 91% | Training loss: 0.6920996295081244
Epoch: 65 | Iteration number: [370/393] 94% | Training loss: 0.6920133611640414
Epoch: 65 | Iteration number: [380/393] 96% | Training loss: 0.6919852623814031
Epoch: 65 | Iteration number: [390/393] 99% | Training loss: 0.6919554913655306

 End of epoch: 65 | Train Loss: 0.6901749522631405 | Training Time: 67 

 End of epoch: 65 | Eval Loss: 0.6905174936567035 | Evaluating Time: 17 
Epoch: 66 | Iteration number: [10/393] 2% | Training loss: 0.7581922113895416
Epoch: 66 | Iteration number: [20/393] 5% | Training loss: 0.7235567986965179
Epoch: 66 | Iteration number: [30/393] 7% | Training loss: 0.7125779370466868
Epoch: 66 | Iteration number: [40/393] 10% | Training loss: 0.7071071341633797
Epoch: 66 | Iteration number: [50/393] 12% | Training loss: 0.7037997245788574
Epoch: 66 | Iteration number: [60/393] 15% | Training loss: 0.7014422436555227
Epoch: 66 | Iteration number: [70/393] 17% | Training loss: 0.6997829616069794
Epoch: 66 | Iteration number: [80/393] 20% | Training loss: 0.6985291950404644
Epoch: 66 | Iteration number: [90/393] 22% | Training loss: 0.6974738730324639
Epoch: 66 | Iteration number: [100/393] 25% | Training loss: 0.6968054616451264
Epoch: 66 | Iteration number: [110/393] 27% | Training loss: 0.6961506112055345
Epoch: 66 | Iteration number: [120/393] 30% | Training loss: 0.695674558977286
Epoch: 66 | Iteration number: [130/393] 33% | Training loss: 0.6953153344301077
Epoch: 66 | Iteration number: [140/393] 35% | Training loss: 0.6949781937258585
Epoch: 66 | Iteration number: [150/393] 38% | Training loss: 0.6946293330192566
Epoch: 66 | Iteration number: [160/393] 40% | Training loss: 0.6942678987979889
Epoch: 66 | Iteration number: [170/393] 43% | Training loss: 0.694054170215831
Epoch: 66 | Iteration number: [180/393] 45% | Training loss: 0.6938443435562982
Epoch: 66 | Iteration number: [190/393] 48% | Training loss: 0.6936678475455234
Epoch: 66 | Iteration number: [200/393] 50% | Training loss: 0.6934917417168617
Epoch: 66 | Iteration number: [210/393] 53% | Training loss: 0.6933434361503238
Epoch: 66 | Iteration number: [220/393] 55% | Training loss: 0.6932307695800608
Epoch: 66 | Iteration number: [230/393] 58% | Training loss: 0.6931093773116236
Epoch: 66 | Iteration number: [240/393] 61% | Training loss: 0.6929187322656314
Epoch: 66 | Iteration number: [250/393] 63% | Training loss: 0.6928125321865082
Epoch: 66 | Iteration number: [260/393] 66% | Training loss: 0.6927142597161806
Epoch: 66 | Iteration number: [270/393] 68% | Training loss: 0.692614119582706
Epoch: 66 | Iteration number: [280/393] 71% | Training loss: 0.6925403654575348
Epoch: 66 | Iteration number: [290/393] 73% | Training loss: 0.6924342297274491
Epoch: 66 | Iteration number: [300/393] 76% | Training loss: 0.6923943018913269
Epoch: 66 | Iteration number: [310/393] 78% | Training loss: 0.6923232316970825
Epoch: 66 | Iteration number: [320/393] 81% | Training loss: 0.6922381455078721
Epoch: 66 | Iteration number: [330/393] 83% | Training loss: 0.6921639740467072
Epoch: 66 | Iteration number: [340/393] 86% | Training loss: 0.692088470564169
Epoch: 66 | Iteration number: [350/393] 89% | Training loss: 0.6920467220033918
Epoch: 66 | Iteration number: [360/393] 91% | Training loss: 0.6920073716176881
Epoch: 66 | Iteration number: [370/393] 94% | Training loss: 0.6919755784240929
Epoch: 66 | Iteration number: [380/393] 96% | Training loss: 0.691916089622598
Epoch: 66 | Iteration number: [390/393] 99% | Training loss: 0.6918852034287575

 End of epoch: 66 | Train Loss: 0.6901106831378306 | Training Time: 67 

 End of epoch: 66 | Eval Loss: 0.6905475076364012 | Evaluating Time: 17 
Epoch: 67 | Iteration number: [10/393] 2% | Training loss: 0.7591185867786407
Epoch: 67 | Iteration number: [20/393] 5% | Training loss: 0.7252095669507981
Epoch: 67 | Iteration number: [30/393] 7% | Training loss: 0.7136784493923187
Epoch: 67 | Iteration number: [40/393] 10% | Training loss: 0.7078022480010986
Epoch: 67 | Iteration number: [50/393] 12% | Training loss: 0.7045289778709412
Epoch: 67 | Iteration number: [60/393] 15% | Training loss: 0.7020456731319428
Epoch: 67 | Iteration number: [70/393] 17% | Training loss: 0.7003149117742266
Epoch: 67 | Iteration number: [80/393] 20% | Training loss: 0.698977456241846
Epoch: 67 | Iteration number: [90/393] 22% | Training loss: 0.6980165521303813
Epoch: 67 | Iteration number: [100/393] 25% | Training loss: 0.6971305876970291
Epoch: 67 | Iteration number: [110/393] 27% | Training loss: 0.6965317699042234
Epoch: 67 | Iteration number: [120/393] 30% | Training loss: 0.6960643207033476
Epoch: 67 | Iteration number: [130/393] 33% | Training loss: 0.6956189462771782
Epoch: 67 | Iteration number: [140/393] 35% | Training loss: 0.6952647830758776
Epoch: 67 | Iteration number: [150/393] 38% | Training loss: 0.6949861884117127
Epoch: 67 | Iteration number: [160/393] 40% | Training loss: 0.6946835003793239
Epoch: 67 | Iteration number: [170/393] 43% | Training loss: 0.6944439043016994
Epoch: 67 | Iteration number: [180/393] 45% | Training loss: 0.6942086458206177
Epoch: 67 | Iteration number: [190/393] 48% | Training loss: 0.6939767297945525
Epoch: 67 | Iteration number: [200/393] 50% | Training loss: 0.6938065722584724
Epoch: 67 | Iteration number: [210/393] 53% | Training loss: 0.6936300081866128
Epoch: 67 | Iteration number: [220/393] 55% | Training loss: 0.693422866138545
Epoch: 67 | Iteration number: [230/393] 58% | Training loss: 0.6933192076890365
Epoch: 67 | Iteration number: [240/393] 61% | Training loss: 0.6931980977455775
Epoch: 67 | Iteration number: [250/393] 63% | Training loss: 0.6930665454864502
Epoch: 67 | Iteration number: [260/393] 66% | Training loss: 0.6929329789601839
Epoch: 67 | Iteration number: [270/393] 68% | Training loss: 0.6928363287890399
Epoch: 67 | Iteration number: [280/393] 71% | Training loss: 0.6927312878625733
Epoch: 67 | Iteration number: [290/393] 73% | Training loss: 0.692646240982516
Epoch: 67 | Iteration number: [300/393] 76% | Training loss: 0.6925562951962153
Epoch: 67 | Iteration number: [310/393] 78% | Training loss: 0.6924939855452507
Epoch: 67 | Iteration number: [320/393] 81% | Training loss: 0.6923936350271106
Epoch: 67 | Iteration number: [330/393] 83% | Training loss: 0.6923445587808436
Epoch: 67 | Iteration number: [340/393] 86% | Training loss: 0.6922641875112758
Epoch: 67 | Iteration number: [350/393] 89% | Training loss: 0.6922079537596021
Epoch: 67 | Iteration number: [360/393] 91% | Training loss: 0.692148475183381
Epoch: 67 | Iteration number: [370/393] 94% | Training loss: 0.6920877508215002
Epoch: 67 | Iteration number: [380/393] 96% | Training loss: 0.6919925369714436
Epoch: 67 | Iteration number: [390/393] 99% | Training loss: 0.6919107252206558

 End of epoch: 67 | Train Loss: 0.690138789381993 | Training Time: 67 

 End of epoch: 67 | Eval Loss: 0.6904818598104983 | Evaluating Time: 17 
Epoch: 68 | Iteration number: [10/393] 2% | Training loss: 0.7597728431224823
Epoch: 68 | Iteration number: [20/393] 5% | Training loss: 0.7249187409877778
Epoch: 68 | Iteration number: [30/393] 7% | Training loss: 0.7131240646044413
Epoch: 68 | Iteration number: [40/393] 10% | Training loss: 0.7074094697833061
Epoch: 68 | Iteration number: [50/393] 12% | Training loss: 0.7038806235790253
Epoch: 68 | Iteration number: [60/393] 15% | Training loss: 0.7014714936415355
Epoch: 68 | Iteration number: [70/393] 17% | Training loss: 0.6997548767498561
Epoch: 68 | Iteration number: [80/393] 20% | Training loss: 0.6986107923090458
Epoch: 68 | Iteration number: [90/393] 22% | Training loss: 0.6976670967208014
Epoch: 68 | Iteration number: [100/393] 25% | Training loss: 0.6969570636749267
Epoch: 68 | Iteration number: [110/393] 27% | Training loss: 0.6963746580210599
Epoch: 68 | Iteration number: [120/393] 30% | Training loss: 0.6958720271786054
Epoch: 68 | Iteration number: [130/393] 33% | Training loss: 0.6954718195475065
Epoch: 68 | Iteration number: [140/393] 35% | Training loss: 0.6951652250119618
Epoch: 68 | Iteration number: [150/393] 38% | Training loss: 0.6948958615461985
Epoch: 68 | Iteration number: [160/393] 40% | Training loss: 0.6945853356271983
Epoch: 68 | Iteration number: [170/393] 43% | Training loss: 0.6943525458083434
Epoch: 68 | Iteration number: [180/393] 45% | Training loss: 0.6940793332126406
Epoch: 68 | Iteration number: [190/393] 48% | Training loss: 0.69384189718648
Epoch: 68 | Iteration number: [200/393] 50% | Training loss: 0.6936474445462227
Epoch: 68 | Iteration number: [210/393] 53% | Training loss: 0.6935048256601606
Epoch: 68 | Iteration number: [220/393] 55% | Training loss: 0.693334368684075
Epoch: 68 | Iteration number: [230/393] 58% | Training loss: 0.6931547211564105
Epoch: 68 | Iteration number: [240/393] 61% | Training loss: 0.692966300000747
Epoch: 68 | Iteration number: [250/393] 63% | Training loss: 0.6928358702659607
Epoch: 68 | Iteration number: [260/393] 66% | Training loss: 0.6927467050460668
Epoch: 68 | Iteration number: [270/393] 68% | Training loss: 0.692639594607883
Epoch: 68 | Iteration number: [280/393] 71% | Training loss: 0.6925505297524589
Epoch: 68 | Iteration number: [290/393] 73% | Training loss: 0.6924983606256288
Epoch: 68 | Iteration number: [300/393] 76% | Training loss: 0.6924027341604233
Epoch: 68 | Iteration number: [310/393] 78% | Training loss: 0.6923271273413012
Epoch: 68 | Iteration number: [320/393] 81% | Training loss: 0.6922785637900233
Epoch: 68 | Iteration number: [330/393] 83% | Training loss: 0.6922459941921812
Epoch: 68 | Iteration number: [340/393] 86% | Training loss: 0.6921850653255687
Epoch: 68 | Iteration number: [350/393] 89% | Training loss: 0.6921027902194432
Epoch: 68 | Iteration number: [360/393] 91% | Training loss: 0.6920572186509768
Epoch: 68 | Iteration number: [370/393] 94% | Training loss: 0.692020510016261
Epoch: 68 | Iteration number: [380/393] 96% | Training loss: 0.6919277975433751
Epoch: 68 | Iteration number: [390/393] 99% | Training loss: 0.6918936581183702

 End of epoch: 68 | Train Loss: 0.6901244390708496 | Training Time: 67 

 End of epoch: 68 | Eval Loss: 0.690556987207763 | Evaluating Time: 17 
Epoch: 69 | Iteration number: [10/393] 2% | Training loss: 0.7584347605705262
Epoch: 69 | Iteration number: [20/393] 5% | Training loss: 0.7240053385496139
Epoch: 69 | Iteration number: [30/393] 7% | Training loss: 0.7125825643539428
Epoch: 69 | Iteration number: [40/393] 10% | Training loss: 0.7067130848765373
Epoch: 69 | Iteration number: [50/393] 12% | Training loss: 0.7034725511074066
Epoch: 69 | Iteration number: [60/393] 15% | Training loss: 0.7013916134834289
Epoch: 69 | Iteration number: [70/393] 17% | Training loss: 0.6998638101986476
Epoch: 69 | Iteration number: [80/393] 20% | Training loss: 0.6986679591238498
Epoch: 69 | Iteration number: [90/393] 22% | Training loss: 0.6976943294207255
Epoch: 69 | Iteration number: [100/393] 25% | Training loss: 0.6967988222837448
Epoch: 69 | Iteration number: [110/393] 27% | Training loss: 0.6962170080705122
Epoch: 69 | Iteration number: [120/393] 30% | Training loss: 0.6957164208094279
Epoch: 69 | Iteration number: [130/393] 33% | Training loss: 0.6952503332724937
Epoch: 69 | Iteration number: [140/393] 35% | Training loss: 0.6949005833693913
Epoch: 69 | Iteration number: [150/393] 38% | Training loss: 0.6945571637153626
Epoch: 69 | Iteration number: [160/393] 40% | Training loss: 0.6942907061427832
Epoch: 69 | Iteration number: [170/393] 43% | Training loss: 0.6940649663700776
Epoch: 69 | Iteration number: [180/393] 45% | Training loss: 0.6938557558589511
Epoch: 69 | Iteration number: [190/393] 48% | Training loss: 0.6936756912030672
Epoch: 69 | Iteration number: [200/393] 50% | Training loss: 0.6934684190154076
Epoch: 69 | Iteration number: [210/393] 53% | Training loss: 0.6933412222635178
Epoch: 69 | Iteration number: [220/393] 55% | Training loss: 0.6931870365684683
Epoch: 69 | Iteration number: [230/393] 58% | Training loss: 0.6930800948453986
Epoch: 69 | Iteration number: [240/393] 61% | Training loss: 0.6930240509410699
Epoch: 69 | Iteration number: [250/393] 63% | Training loss: 0.6929101147651673
Epoch: 69 | Iteration number: [260/393] 66% | Training loss: 0.6928355033581074
Epoch: 69 | Iteration number: [270/393] 68% | Training loss: 0.6927470825336598
Epoch: 69 | Iteration number: [280/393] 71% | Training loss: 0.692633726980005
Epoch: 69 | Iteration number: [290/393] 73% | Training loss: 0.6925831868730742
Epoch: 69 | Iteration number: [300/393] 76% | Training loss: 0.6925089814265569
Epoch: 69 | Iteration number: [310/393] 78% | Training loss: 0.6923894132337263
Epoch: 69 | Iteration number: [320/393] 81% | Training loss: 0.692351788468659
Epoch: 69 | Iteration number: [330/393] 83% | Training loss: 0.6922838653578903
Epoch: 69 | Iteration number: [340/393] 86% | Training loss: 0.6922074310919818
Epoch: 69 | Iteration number: [350/393] 89% | Training loss: 0.6921514008726393
Epoch: 69 | Iteration number: [360/393] 91% | Training loss: 0.6920825918515523
Epoch: 69 | Iteration number: [370/393] 94% | Training loss: 0.6920308085712227
Epoch: 69 | Iteration number: [380/393] 96% | Training loss: 0.6919607024443777
Epoch: 69 | Iteration number: [390/393] 99% | Training loss: 0.6919259539017311

 End of epoch: 69 | Train Loss: 0.6901566293706725 | Training Time: 66 

 End of epoch: 69 | Eval Loss: 0.6904883700974134 | Evaluating Time: 17 
Epoch: 70 | Iteration number: [10/393] 2% | Training loss: 0.7595844805240631
Epoch: 70 | Iteration number: [20/393] 5% | Training loss: 0.7242727696895599
Epoch: 70 | Iteration number: [30/393] 7% | Training loss: 0.7130686899026235
Epoch: 70 | Iteration number: [40/393] 10% | Training loss: 0.7074305444955826
Epoch: 70 | Iteration number: [50/393] 12% | Training loss: 0.703884938955307
Epoch: 70 | Iteration number: [60/393] 15% | Training loss: 0.7014961580435435
Epoch: 70 | Iteration number: [70/393] 17% | Training loss: 0.6998738884925843
Epoch: 70 | Iteration number: [80/393] 20% | Training loss: 0.6986949913203716
Epoch: 70 | Iteration number: [90/393] 22% | Training loss: 0.6978118220965067
Epoch: 70 | Iteration number: [100/393] 25% | Training loss: 0.69699059009552
Epoch: 70 | Iteration number: [110/393] 27% | Training loss: 0.696471803296696
Epoch: 70 | Iteration number: [120/393] 30% | Training loss: 0.6959278027216593
Epoch: 70 | Iteration number: [130/393] 33% | Training loss: 0.695458062336995
Epoch: 70 | Iteration number: [140/393] 35% | Training loss: 0.69505466903959
Epoch: 70 | Iteration number: [150/393] 38% | Training loss: 0.6947112294038137
Epoch: 70 | Iteration number: [160/393] 40% | Training loss: 0.6943928427994251
Epoch: 70 | Iteration number: [170/393] 43% | Training loss: 0.6940990248147179
Epoch: 70 | Iteration number: [180/393] 45% | Training loss: 0.6938461068603727
Epoch: 70 | Iteration number: [190/393] 48% | Training loss: 0.6936619306865491
Epoch: 70 | Iteration number: [200/393] 50% | Training loss: 0.6935289898514747
Epoch: 70 | Iteration number: [210/393] 53% | Training loss: 0.6933919197037106
Epoch: 70 | Iteration number: [220/393] 55% | Training loss: 0.6932565881447359
Epoch: 70 | Iteration number: [230/393] 58% | Training loss: 0.6931140005588532
Epoch: 70 | Iteration number: [240/393] 61% | Training loss: 0.6929732747375965
Epoch: 70 | Iteration number: [250/393] 63% | Training loss: 0.6928784890174866
Epoch: 70 | Iteration number: [260/393] 66% | Training loss: 0.6927099067431229
Epoch: 70 | Iteration number: [270/393] 68% | Training loss: 0.6926128480169508
Epoch: 70 | Iteration number: [280/393] 71% | Training loss: 0.6925165412681443
Epoch: 70 | Iteration number: [290/393] 73% | Training loss: 0.6924233541406434
Epoch: 70 | Iteration number: [300/393] 76% | Training loss: 0.6923260468244553
Epoch: 70 | Iteration number: [310/393] 78% | Training loss: 0.6922906014227098
Epoch: 70 | Iteration number: [320/393] 81% | Training loss: 0.6922283746302128
Epoch: 70 | Iteration number: [330/393] 83% | Training loss: 0.6921935341574929
Epoch: 70 | Iteration number: [340/393] 86% | Training loss: 0.6921382791855756
Epoch: 70 | Iteration number: [350/393] 89% | Training loss: 0.6920737593514579
Epoch: 70 | Iteration number: [360/393] 91% | Training loss: 0.6920106301705042
Epoch: 70 | Iteration number: [370/393] 94% | Training loss: 0.6919517943987975
Epoch: 70 | Iteration number: [380/393] 96% | Training loss: 0.6919104458470093
Epoch: 70 | Iteration number: [390/393] 99% | Training loss: 0.6918665101894965

 End of epoch: 70 | Train Loss: 0.6900893436133406 | Training Time: 66 

 End of epoch: 70 | Eval Loss: 0.6906522390793781 | Evaluating Time: 17 
Epoch: 71 | Iteration number: [10/393] 2% | Training loss: 0.759270179271698
Epoch: 71 | Iteration number: [20/393] 5% | Training loss: 0.7244185388088227
Epoch: 71 | Iteration number: [30/393] 7% | Training loss: 0.7128552635510762
Epoch: 71 | Iteration number: [40/393] 10% | Training loss: 0.7069996282458305
Epoch: 71 | Iteration number: [50/393] 12% | Training loss: 0.7036537444591522
Epoch: 71 | Iteration number: [60/393] 15% | Training loss: 0.7015172948439916
Epoch: 71 | Iteration number: [70/393] 17% | Training loss: 0.700061445576804
Epoch: 71 | Iteration number: [80/393] 20% | Training loss: 0.6988375179469586
Epoch: 71 | Iteration number: [90/393] 22% | Training loss: 0.69785286254353
Epoch: 71 | Iteration number: [100/393] 25% | Training loss: 0.6971406489610672
Epoch: 71 | Iteration number: [110/393] 27% | Training loss: 0.6964855708859183
Epoch: 71 | Iteration number: [120/393] 30% | Training loss: 0.6959032267332077
Epoch: 71 | Iteration number: [130/393] 33% | Training loss: 0.6954234402913314
Epoch: 71 | Iteration number: [140/393] 35% | Training loss: 0.6950312674045562
Epoch: 71 | Iteration number: [150/393] 38% | Training loss: 0.6946878397464752
Epoch: 71 | Iteration number: [160/393] 40% | Training loss: 0.6943843562155962
Epoch: 71 | Iteration number: [170/393] 43% | Training loss: 0.6941335043486427
Epoch: 71 | Iteration number: [180/393] 45% | Training loss: 0.6939435326390796
Epoch: 71 | Iteration number: [190/393] 48% | Training loss: 0.6937295954478414
Epoch: 71 | Iteration number: [200/393] 50% | Training loss: 0.6935669699311257
Epoch: 71 | Iteration number: [210/393] 53% | Training loss: 0.6934783555212475
Epoch: 71 | Iteration number: [220/393] 55% | Training loss: 0.6933463034304705
Epoch: 71 | Iteration number: [230/393] 58% | Training loss: 0.6932204575642296
Epoch: 71 | Iteration number: [240/393] 61% | Training loss: 0.6930962291856607
Epoch: 71 | Iteration number: [250/393] 63% | Training loss: 0.6929636247158051
Epoch: 71 | Iteration number: [260/393] 66% | Training loss: 0.6928641037299083
Epoch: 71 | Iteration number: [270/393] 68% | Training loss: 0.6927804576026069
Epoch: 71 | Iteration number: [280/393] 71% | Training loss: 0.692673881990569
Epoch: 71 | Iteration number: [290/393] 73% | Training loss: 0.6925694514965189
Epoch: 71 | Iteration number: [300/393] 76% | Training loss: 0.6925042603413264
Epoch: 71 | Iteration number: [310/393] 78% | Training loss: 0.6923895230216365
Epoch: 71 | Iteration number: [320/393] 81% | Training loss: 0.6923425057902932
Epoch: 71 | Iteration number: [330/393] 83% | Training loss: 0.6922797643777095
Epoch: 71 | Iteration number: [340/393] 86% | Training loss: 0.6922031367526335
Epoch: 71 | Iteration number: [350/393] 89% | Training loss: 0.692126933165959
Epoch: 71 | Iteration number: [360/393] 91% | Training loss: 0.6920930936932563
Epoch: 71 | Iteration number: [370/393] 94% | Training loss: 0.6920570918031641
Epoch: 71 | Iteration number: [380/393] 96% | Training loss: 0.6919851874050341
Epoch: 71 | Iteration number: [390/393] 99% | Training loss: 0.6919524098053956

 End of epoch: 71 | Train Loss: 0.690183654996275 | Training Time: 66 

 End of epoch: 71 | Eval Loss: 0.6905245951243809 | Evaluating Time: 17 
Epoch: 72 | Iteration number: [10/393] 2% | Training loss: 0.7595961272716523
Epoch: 72 | Iteration number: [20/393] 5% | Training loss: 0.7254012852907181
Epoch: 72 | Iteration number: [30/393] 7% | Training loss: 0.713641357421875
Epoch: 72 | Iteration number: [40/393] 10% | Training loss: 0.7075200378894806
Epoch: 72 | Iteration number: [50/393] 12% | Training loss: 0.7041685831546783
Epoch: 72 | Iteration number: [60/393] 15% | Training loss: 0.7019046594699224
Epoch: 72 | Iteration number: [70/393] 17% | Training loss: 0.7004269318921226
Epoch: 72 | Iteration number: [80/393] 20% | Training loss: 0.699276789277792
Epoch: 72 | Iteration number: [90/393] 22% | Training loss: 0.6982410331567128
Epoch: 72 | Iteration number: [100/393] 25% | Training loss: 0.6974952727556228
Epoch: 72 | Iteration number: [110/393] 27% | Training loss: 0.6968251943588257
Epoch: 72 | Iteration number: [120/393] 30% | Training loss: 0.6961724092562993
Epoch: 72 | Iteration number: [130/393] 33% | Training loss: 0.6956229429978591
Epoch: 72 | Iteration number: [140/393] 35% | Training loss: 0.6952420268739973
Epoch: 72 | Iteration number: [150/393] 38% | Training loss: 0.6949504339694976
Epoch: 72 | Iteration number: [160/393] 40% | Training loss: 0.6947212293744087
Epoch: 72 | Iteration number: [170/393] 43% | Training loss: 0.6944284018348245
Epoch: 72 | Iteration number: [180/393] 45% | Training loss: 0.6941692355606291
Epoch: 72 | Iteration number: [190/393] 48% | Training loss: 0.6939562841465599
Epoch: 72 | Iteration number: [200/393] 50% | Training loss: 0.6937662872672081
Epoch: 72 | Iteration number: [210/393] 53% | Training loss: 0.6935753138292403
Epoch: 72 | Iteration number: [220/393] 55% | Training loss: 0.693372065370733
Epoch: 72 | Iteration number: [230/393] 58% | Training loss: 0.6931509043859398
Epoch: 72 | Iteration number: [240/393] 61% | Training loss: 0.6930391572415828
Epoch: 72 | Iteration number: [250/393] 63% | Training loss: 0.6928826377391816
Epoch: 72 | Iteration number: [260/393] 66% | Training loss: 0.6927114995626303
Epoch: 72 | Iteration number: [270/393] 68% | Training loss: 0.6926351452315295
Epoch: 72 | Iteration number: [280/393] 71% | Training loss: 0.6925361522606441
Epoch: 72 | Iteration number: [290/393] 73% | Training loss: 0.6924183068604305
Epoch: 72 | Iteration number: [300/393] 76% | Training loss: 0.6923154576619466
Epoch: 72 | Iteration number: [310/393] 78% | Training loss: 0.6922673550344283
Epoch: 72 | Iteration number: [320/393] 81% | Training loss: 0.6922075105831027
Epoch: 72 | Iteration number: [330/393] 83% | Training loss: 0.6921946173364466
Epoch: 72 | Iteration number: [340/393] 86% | Training loss: 0.6921593427658081
Epoch: 72 | Iteration number: [350/393] 89% | Training loss: 0.6920761045387813
Epoch: 72 | Iteration number: [360/393] 91% | Training loss: 0.6920219489269787
Epoch: 72 | Iteration number: [370/393] 94% | Training loss: 0.6920071785514419
Epoch: 72 | Iteration number: [380/393] 96% | Training loss: 0.6919478126262364
Epoch: 72 | Iteration number: [390/393] 99% | Training loss: 0.691909480553407

 End of epoch: 72 | Train Loss: 0.6901305243562499 | Training Time: 66 

 End of epoch: 72 | Eval Loss: 0.6905558997271012 | Evaluating Time: 17 
Epoch: 73 | Iteration number: [10/393] 2% | Training loss: 0.7592118322849274
Epoch: 73 | Iteration number: [20/393] 5% | Training loss: 0.7239472419023514
Epoch: 73 | Iteration number: [30/393] 7% | Training loss: 0.7125767568747202
Epoch: 73 | Iteration number: [40/393] 10% | Training loss: 0.7071440815925598
Epoch: 73 | Iteration number: [50/393] 12% | Training loss: 0.7037585139274597
Epoch: 73 | Iteration number: [60/393] 15% | Training loss: 0.7014636546373367
Epoch: 73 | Iteration number: [70/393] 17% | Training loss: 0.6999558891568866
Epoch: 73 | Iteration number: [80/393] 20% | Training loss: 0.698760075867176
Epoch: 73 | Iteration number: [90/393] 22% | Training loss: 0.697813155916002
Epoch: 73 | Iteration number: [100/393] 25% | Training loss: 0.6970841145515442
Epoch: 73 | Iteration number: [110/393] 27% | Training loss: 0.6964106944474306
Epoch: 73 | Iteration number: [120/393] 30% | Training loss: 0.6959522237380346
Epoch: 73 | Iteration number: [130/393] 33% | Training loss: 0.6953672555776743
Epoch: 73 | Iteration number: [140/393] 35% | Training loss: 0.6950443220990045
Epoch: 73 | Iteration number: [150/393] 38% | Training loss: 0.6946908517678578
Epoch: 73 | Iteration number: [160/393] 40% | Training loss: 0.6944746773689985
Epoch: 73 | Iteration number: [170/393] 43% | Training loss: 0.6941499857341542
Epoch: 73 | Iteration number: [180/393] 45% | Training loss: 0.6939493056800631
Epoch: 73 | Iteration number: [190/393] 48% | Training loss: 0.6937432502445422
Epoch: 73 | Iteration number: [200/393] 50% | Training loss: 0.6935441711544991
Epoch: 73 | Iteration number: [210/393] 53% | Training loss: 0.6933684655598231
Epoch: 73 | Iteration number: [220/393] 55% | Training loss: 0.6932610403407704
Epoch: 73 | Iteration number: [230/393] 58% | Training loss: 0.6930849938288979
Epoch: 73 | Iteration number: [240/393] 61% | Training loss: 0.6929441682994366
Epoch: 73 | Iteration number: [250/393] 63% | Training loss: 0.6928473708629608
Epoch: 73 | Iteration number: [260/393] 66% | Training loss: 0.6927439568134455
Epoch: 73 | Iteration number: [270/393] 68% | Training loss: 0.6926616485472079
Epoch: 73 | Iteration number: [280/393] 71% | Training loss: 0.6925658519778933
Epoch: 73 | Iteration number: [290/393] 73% | Training loss: 0.6924953107176156
Epoch: 73 | Iteration number: [300/393] 76% | Training loss: 0.6924246031045914
Epoch: 73 | Iteration number: [310/393] 78% | Training loss: 0.6923723668821397
Epoch: 73 | Iteration number: [320/393] 81% | Training loss: 0.6923042697831988
Epoch: 73 | Iteration number: [330/393] 83% | Training loss: 0.6922486158934507
Epoch: 73 | Iteration number: [340/393] 86% | Training loss: 0.6921894353978774
Epoch: 73 | Iteration number: [350/393] 89% | Training loss: 0.6921229943207332
Epoch: 73 | Iteration number: [360/393] 91% | Training loss: 0.6920443755057123
Epoch: 73 | Iteration number: [370/393] 94% | Training loss: 0.6919461899512523
Epoch: 73 | Iteration number: [380/393] 96% | Training loss: 0.691892377326363
Epoch: 73 | Iteration number: [390/393] 99% | Training loss: 0.691850479443868

 End of epoch: 73 | Train Loss: 0.6900673087013284 | Training Time: 66 

 End of epoch: 73 | Eval Loss: 0.6904871792209392 | Evaluating Time: 17 
Epoch: 74 | Iteration number: [10/393] 2% | Training loss: 0.7576402127742767
Epoch: 74 | Iteration number: [20/393] 5% | Training loss: 0.7238122045993804
Epoch: 74 | Iteration number: [30/393] 7% | Training loss: 0.7125448524951935
Epoch: 74 | Iteration number: [40/393] 10% | Training loss: 0.7066614836454391
Epoch: 74 | Iteration number: [50/393] 12% | Training loss: 0.7032254087924957
Epoch: 74 | Iteration number: [60/393] 15% | Training loss: 0.7012137164672215
Epoch: 74 | Iteration number: [70/393] 17% | Training loss: 0.6996192608560835
Epoch: 74 | Iteration number: [80/393] 20% | Training loss: 0.6983492821455002
Epoch: 74 | Iteration number: [90/393] 22% | Training loss: 0.6973905993832482
Epoch: 74 | Iteration number: [100/393] 25% | Training loss: 0.6965612185001373
Epoch: 74 | Iteration number: [110/393] 27% | Training loss: 0.6959946052594619
Epoch: 74 | Iteration number: [120/393] 30% | Training loss: 0.6955720946192742
Epoch: 74 | Iteration number: [130/393] 33% | Training loss: 0.6951348373523125
Epoch: 74 | Iteration number: [140/393] 35% | Training loss: 0.6948180432830539
Epoch: 74 | Iteration number: [150/393] 38% | Training loss: 0.6945013276735942
Epoch: 74 | Iteration number: [160/393] 40% | Training loss: 0.6942614741623402
Epoch: 74 | Iteration number: [170/393] 43% | Training loss: 0.6939719729563769
Epoch: 74 | Iteration number: [180/393] 45% | Training loss: 0.6937822212775548
Epoch: 74 | Iteration number: [190/393] 48% | Training loss: 0.6936074225526107
Epoch: 74 | Iteration number: [200/393] 50% | Training loss: 0.6934665191173554
Epoch: 74 | Iteration number: [210/393] 53% | Training loss: 0.69328563837778
Epoch: 74 | Iteration number: [220/393] 55% | Training loss: 0.693201448971575
Epoch: 74 | Iteration number: [230/393] 58% | Training loss: 0.6930673163870107
Epoch: 74 | Iteration number: [240/393] 61% | Training loss: 0.6929225752751033
Epoch: 74 | Iteration number: [250/393] 63% | Training loss: 0.6927470090389252
Epoch: 74 | Iteration number: [260/393] 66% | Training loss: 0.6926424528543765
Epoch: 74 | Iteration number: [270/393] 68% | Training loss: 0.6925731312345575
Epoch: 74 | Iteration number: [280/393] 71% | Training loss: 0.6925134396978787
Epoch: 74 | Iteration number: [290/393] 73% | Training loss: 0.6924156969991223
Epoch: 74 | Iteration number: [300/393] 76% | Training loss: 0.6923254332939783
Epoch: 74 | Iteration number: [310/393] 78% | Training loss: 0.692264235981049
Epoch: 74 | Iteration number: [320/393] 81% | Training loss: 0.6922241332009434
Epoch: 74 | Iteration number: [330/393] 83% | Training loss: 0.6921794185132691
Epoch: 74 | Iteration number: [340/393] 86% | Training loss: 0.6921551203026491
Epoch: 74 | Iteration number: [350/393] 89% | Training loss: 0.6920859578677586
Epoch: 74 | Iteration number: [360/393] 91% | Training loss: 0.692004733118746
Epoch: 74 | Iteration number: [370/393] 94% | Training loss: 0.6919563027652534
Epoch: 74 | Iteration number: [380/393] 96% | Training loss: 0.6918864236066216
Epoch: 74 | Iteration number: [390/393] 99% | Training loss: 0.6918300819702637

 End of epoch: 74 | Train Loss: 0.6900606417777277 | Training Time: 66 

 End of epoch: 74 | Eval Loss: 0.6905067319772682 | Evaluating Time: 17 
Epoch: 75 | Iteration number: [10/393] 2% | Training loss: 0.7585837721824646
Epoch: 75 | Iteration number: [20/393] 5% | Training loss: 0.7244887709617615
Epoch: 75 | Iteration number: [30/393] 7% | Training loss: 0.7126151978969574
Epoch: 75 | Iteration number: [40/393] 10% | Training loss: 0.707161383330822
Epoch: 75 | Iteration number: [50/393] 12% | Training loss: 0.703691508769989
Epoch: 75 | Iteration number: [60/393] 15% | Training loss: 0.701426213979721
Epoch: 75 | Iteration number: [70/393] 17% | Training loss: 0.6998305669852666
Epoch: 75 | Iteration number: [80/393] 20% | Training loss: 0.698731680214405
Epoch: 75 | Iteration number: [90/393] 22% | Training loss: 0.697862340344323
Epoch: 75 | Iteration number: [100/393] 25% | Training loss: 0.6970979392528533
Epoch: 75 | Iteration number: [110/393] 27% | Training loss: 0.6963817683133212
Epoch: 75 | Iteration number: [120/393] 30% | Training loss: 0.6957890744010607
Epoch: 75 | Iteration number: [130/393] 33% | Training loss: 0.6953775603037614
Epoch: 75 | Iteration number: [140/393] 35% | Training loss: 0.6950734777109964
Epoch: 75 | Iteration number: [150/393] 38% | Training loss: 0.6946569927533468
Epoch: 75 | Iteration number: [160/393] 40% | Training loss: 0.6944160558283329
Epoch: 75 | Iteration number: [170/393] 43% | Training loss: 0.6941496649209191
Epoch: 75 | Iteration number: [180/393] 45% | Training loss: 0.6939335637622409
Epoch: 75 | Iteration number: [190/393] 48% | Training loss: 0.6937428050919583
Epoch: 75 | Iteration number: [200/393] 50% | Training loss: 0.6935135212540626
Epoch: 75 | Iteration number: [210/393] 53% | Training loss: 0.6933384001255035
Epoch: 75 | Iteration number: [220/393] 55% | Training loss: 0.6932146023620259
Epoch: 75 | Iteration number: [230/393] 58% | Training loss: 0.6931107896825541
Epoch: 75 | Iteration number: [240/393] 61% | Training loss: 0.6930158006648223
Epoch: 75 | Iteration number: [250/393] 63% | Training loss: 0.6928952579498291
Epoch: 75 | Iteration number: [260/393] 66% | Training loss: 0.6927988497110513
Epoch: 75 | Iteration number: [270/393] 68% | Training loss: 0.6926786601543427
Epoch: 75 | Iteration number: [280/393] 71% | Training loss: 0.6926359710948807
Epoch: 75 | Iteration number: [290/393] 73% | Training loss: 0.692523703492921
Epoch: 75 | Iteration number: [300/393] 76% | Training loss: 0.6924538107713064
Epoch: 75 | Iteration number: [310/393] 78% | Training loss: 0.6923758633675113
Epoch: 75 | Iteration number: [320/393] 81% | Training loss: 0.6923097968101501
Epoch: 75 | Iteration number: [330/393] 83% | Training loss: 0.692215937014782
Epoch: 75 | Iteration number: [340/393] 86% | Training loss: 0.6921586928998723
Epoch: 75 | Iteration number: [350/393] 89% | Training loss: 0.6920874748911177
Epoch: 75 | Iteration number: [360/393] 91% | Training loss: 0.6920494500133726
Epoch: 75 | Iteration number: [370/393] 94% | Training loss: 0.6919921027647482
Epoch: 75 | Iteration number: [380/393] 96% | Training loss: 0.6919373887149911
Epoch: 75 | Iteration number: [390/393] 99% | Training loss: 0.6919106462062934

 End of epoch: 75 | Train Loss: 0.6901335144467633 | Training Time: 67 

 End of epoch: 75 | Eval Loss: 0.69048964612338 | Evaluating Time: 17 
Epoch: 76 | Iteration number: [10/393] 2% | Training loss: 0.758423388004303
Epoch: 76 | Iteration number: [20/393] 5% | Training loss: 0.72408886551857
Epoch: 76 | Iteration number: [30/393] 7% | Training loss: 0.7127789616584778
Epoch: 76 | Iteration number: [40/393] 10% | Training loss: 0.7072133973240853
Epoch: 76 | Iteration number: [50/393] 12% | Training loss: 0.7040027618408203
Epoch: 76 | Iteration number: [60/393] 15% | Training loss: 0.7018489688634872
Epoch: 76 | Iteration number: [70/393] 17% | Training loss: 0.6999579421111516
Epoch: 76 | Iteration number: [80/393] 20% | Training loss: 0.698651646822691
Epoch: 76 | Iteration number: [90/393] 22% | Training loss: 0.6977926790714264
Epoch: 76 | Iteration number: [100/393] 25% | Training loss: 0.6970873773097992
Epoch: 76 | Iteration number: [110/393] 27% | Training loss: 0.6964564269239252
Epoch: 76 | Iteration number: [120/393] 30% | Training loss: 0.6959720065196355
Epoch: 76 | Iteration number: [130/393] 33% | Training loss: 0.6956136070764982
Epoch: 76 | Iteration number: [140/393] 35% | Training loss: 0.6951412034886224
Epoch: 76 | Iteration number: [150/393] 38% | Training loss: 0.6947442471981049
Epoch: 76 | Iteration number: [160/393] 40% | Training loss: 0.6944626200944185
Epoch: 76 | Iteration number: [170/393] 43% | Training loss: 0.6941739587222828
Epoch: 76 | Iteration number: [180/393] 45% | Training loss: 0.693964104851087
Epoch: 76 | Iteration number: [190/393] 48% | Training loss: 0.693763256072998
Epoch: 76 | Iteration number: [200/393] 50% | Training loss: 0.6936175286769867
Epoch: 76 | Iteration number: [210/393] 53% | Training loss: 0.6934418334847405
Epoch: 76 | Iteration number: [220/393] 55% | Training loss: 0.6933266620744358
Epoch: 76 | Iteration number: [230/393] 58% | Training loss: 0.6932536824889804
Epoch: 76 | Iteration number: [240/393] 61% | Training loss: 0.6930752575397492
Epoch: 76 | Iteration number: [250/393] 63% | Training loss: 0.6929709844589234
Epoch: 76 | Iteration number: [260/393] 66% | Training loss: 0.6928469061851501
Epoch: 76 | Iteration number: [270/393] 68% | Training loss: 0.6927737569367444
Epoch: 76 | Iteration number: [280/393] 71% | Training loss: 0.69269462036235
Epoch: 76 | Iteration number: [290/393] 73% | Training loss: 0.6925247377362744
Epoch: 76 | Iteration number: [300/393] 76% | Training loss: 0.6924044726292292
Epoch: 76 | Iteration number: [310/393] 78% | Training loss: 0.6923288022318194
Epoch: 76 | Iteration number: [320/393] 81% | Training loss: 0.6923151180148125
Epoch: 76 | Iteration number: [330/393] 83% | Training loss: 0.6922049287593726
Epoch: 76 | Iteration number: [340/393] 86% | Training loss: 0.6921181568328072
Epoch: 76 | Iteration number: [350/393] 89% | Training loss: 0.6920712755407605
Epoch: 76 | Iteration number: [360/393] 91% | Training loss: 0.6920243442058563
Epoch: 76 | Iteration number: [370/393] 94% | Training loss: 0.6920030709859487
Epoch: 76 | Iteration number: [380/393] 96% | Training loss: 0.6919587850570679
Epoch: 76 | Iteration number: [390/393] 99% | Training loss: 0.6919093689857385

 End of epoch: 76 | Train Loss: 0.690129255217147 | Training Time: 66 

 End of epoch: 76 | Eval Loss: 0.6905611425029988 | Evaluating Time: 17 
Epoch: 77 | Iteration number: [10/393] 2% | Training loss: 0.7598251700401306
Epoch: 77 | Iteration number: [20/393] 5% | Training loss: 0.7251807898283005
Epoch: 77 | Iteration number: [30/393] 7% | Training loss: 0.7136372009913127
Epoch: 77 | Iteration number: [40/393] 10% | Training loss: 0.708070658147335
Epoch: 77 | Iteration number: [50/393] 12% | Training loss: 0.7043860256671906
Epoch: 77 | Iteration number: [60/393] 15% | Training loss: 0.7020137657721838
Epoch: 77 | Iteration number: [70/393] 17% | Training loss: 0.7001882723399571
Epoch: 77 | Iteration number: [80/393] 20% | Training loss: 0.6990462861955166
Epoch: 77 | Iteration number: [90/393] 22% | Training loss: 0.6980452299118042
Epoch: 77 | Iteration number: [100/393] 25% | Training loss: 0.6972023677825928
Epoch: 77 | Iteration number: [110/393] 27% | Training loss: 0.6965263643048026
Epoch: 77 | Iteration number: [120/393] 30% | Training loss: 0.6960257748762767
Epoch: 77 | Iteration number: [130/393] 33% | Training loss: 0.69553342461586
Epoch: 77 | Iteration number: [140/393] 35% | Training loss: 0.6951220124959946
Epoch: 77 | Iteration number: [150/393] 38% | Training loss: 0.6947678303718567
Epoch: 77 | Iteration number: [160/393] 40% | Training loss: 0.694497038051486
Epoch: 77 | Iteration number: [170/393] 43% | Training loss: 0.6942814525435953
Epoch: 77 | Iteration number: [180/393] 45% | Training loss: 0.6939976202117072
Epoch: 77 | Iteration number: [190/393] 48% | Training loss: 0.693827633167568
Epoch: 77 | Iteration number: [200/393] 50% | Training loss: 0.6936485353112221
Epoch: 77 | Iteration number: [210/393] 53% | Training loss: 0.6934235445090703
Epoch: 77 | Iteration number: [220/393] 55% | Training loss: 0.693228529529138
Epoch: 77 | Iteration number: [230/393] 58% | Training loss: 0.6930777811485788
Epoch: 77 | Iteration number: [240/393] 61% | Training loss: 0.6929873769481977
Epoch: 77 | Iteration number: [250/393] 63% | Training loss: 0.6928779590129852
Epoch: 77 | Iteration number: [260/393] 66% | Training loss: 0.6927972626227599
Epoch: 77 | Iteration number: [270/393] 68% | Training loss: 0.6926936765511831
Epoch: 77 | Iteration number: [280/393] 71% | Training loss: 0.692568037552493
Epoch: 77 | Iteration number: [290/393] 73% | Training loss: 0.6924729900113468
Epoch: 77 | Iteration number: [300/393] 76% | Training loss: 0.6923930686712265
Epoch: 77 | Iteration number: [310/393] 78% | Training loss: 0.6923084933911601
Epoch: 77 | Iteration number: [320/393] 81% | Training loss: 0.6922566296532751
Epoch: 77 | Iteration number: [330/393] 83% | Training loss: 0.6921549394275203
Epoch: 77 | Iteration number: [340/393] 86% | Training loss: 0.6921054044190575
Epoch: 77 | Iteration number: [350/393] 89% | Training loss: 0.69207394020898
Epoch: 77 | Iteration number: [360/393] 91% | Training loss: 0.692023545006911
Epoch: 77 | Iteration number: [370/393] 94% | Training loss: 0.6919631630987735
Epoch: 77 | Iteration number: [380/393] 96% | Training loss: 0.6918875571928527
Epoch: 77 | Iteration number: [390/393] 99% | Training loss: 0.6918370039035112

 End of epoch: 77 | Train Loss: 0.6900773551931212 | Training Time: 66 

 End of epoch: 77 | Eval Loss: 0.6904782421734869 | Evaluating Time: 17 
Epoch: 78 | Iteration number: [10/393] 2% | Training loss: 0.7606162548065185
Epoch: 78 | Iteration number: [20/393] 5% | Training loss: 0.7257499456405639
Epoch: 78 | Iteration number: [30/393] 7% | Training loss: 0.7139113028844197
Epoch: 78 | Iteration number: [40/393] 10% | Training loss: 0.7077894046902656
Epoch: 78 | Iteration number: [50/393] 12% | Training loss: 0.7043781578540802
Epoch: 78 | Iteration number: [60/393] 15% | Training loss: 0.7020082861185074
Epoch: 78 | Iteration number: [70/393] 17% | Training loss: 0.7002730863434928
Epoch: 78 | Iteration number: [80/393] 20% | Training loss: 0.6990127548575401
Epoch: 78 | Iteration number: [90/393] 22% | Training loss: 0.6979365454779731
Epoch: 78 | Iteration number: [100/393] 25% | Training loss: 0.6971114957332611
Epoch: 78 | Iteration number: [110/393] 27% | Training loss: 0.6964289128780365
Epoch: 78 | Iteration number: [120/393] 30% | Training loss: 0.6958652342359225
Epoch: 78 | Iteration number: [130/393] 33% | Training loss: 0.6954658618340126
Epoch: 78 | Iteration number: [140/393] 35% | Training loss: 0.6950614431074688
Epoch: 78 | Iteration number: [150/393] 38% | Training loss: 0.6947236879666646
Epoch: 78 | Iteration number: [160/393] 40% | Training loss: 0.6944479219615459
Epoch: 78 | Iteration number: [170/393] 43% | Training loss: 0.6941466194741867
Epoch: 78 | Iteration number: [180/393] 45% | Training loss: 0.6939083814620972
Epoch: 78 | Iteration number: [190/393] 48% | Training loss: 0.6936861254666981
Epoch: 78 | Iteration number: [200/393] 50% | Training loss: 0.6934188303351402
Epoch: 78 | Iteration number: [210/393] 53% | Training loss: 0.6932108379545666
Epoch: 78 | Iteration number: [220/393] 55% | Training loss: 0.6930683948776939
Epoch: 78 | Iteration number: [230/393] 58% | Training loss: 0.6929804957431296
Epoch: 78 | Iteration number: [240/393] 61% | Training loss: 0.6928641031185786
Epoch: 78 | Iteration number: [250/393] 63% | Training loss: 0.6926915726661682
Epoch: 78 | Iteration number: [260/393] 66% | Training loss: 0.6925598103266496
Epoch: 78 | Iteration number: [270/393] 68% | Training loss: 0.6925129945631381
Epoch: 78 | Iteration number: [280/393] 71% | Training loss: 0.6924175075122289
Epoch: 78 | Iteration number: [290/393] 73% | Training loss: 0.6923360919130259
Epoch: 78 | Iteration number: [300/393] 76% | Training loss: 0.6922711481650671
Epoch: 78 | Iteration number: [310/393] 78% | Training loss: 0.6922326478265947
Epoch: 78 | Iteration number: [320/393] 81% | Training loss: 0.6921952724456787
Epoch: 78 | Iteration number: [330/393] 83% | Training loss: 0.6921404708515514
Epoch: 78 | Iteration number: [340/393] 86% | Training loss: 0.6920863482881995
Epoch: 78 | Iteration number: [350/393] 89% | Training loss: 0.6919990646839141
Epoch: 78 | Iteration number: [360/393] 91% | Training loss: 0.6919415667653084
Epoch: 78 | Iteration number: [370/393] 94% | Training loss: 0.6919000922022639
Epoch: 78 | Iteration number: [380/393] 96% | Training loss: 0.6918701982811878
Epoch: 78 | Iteration number: [390/393] 99% | Training loss: 0.6918216835229825

 End of epoch: 78 | Train Loss: 0.6900569217198981 | Training Time: 66 

 End of epoch: 78 | Eval Loss: 0.690510592898544 | Evaluating Time: 17 
Epoch: 79 | Iteration number: [10/393] 2% | Training loss: 0.7591623604297638
Epoch: 79 | Iteration number: [20/393] 5% | Training loss: 0.7250238507986069
Epoch: 79 | Iteration number: [30/393] 7% | Training loss: 0.7133655766646068
Epoch: 79 | Iteration number: [40/393] 10% | Training loss: 0.7077725872397422
Epoch: 79 | Iteration number: [50/393] 12% | Training loss: 0.7041265511512756
Epoch: 79 | Iteration number: [60/393] 15% | Training loss: 0.7017952551444372
Epoch: 79 | Iteration number: [70/393] 17% | Training loss: 0.700155976840428
Epoch: 79 | Iteration number: [80/393] 20% | Training loss: 0.6988597400486469
Epoch: 79 | Iteration number: [90/393] 22% | Training loss: 0.6978666709529029
Epoch: 79 | Iteration number: [100/393] 25% | Training loss: 0.6970423167943954
Epoch: 79 | Iteration number: [110/393] 27% | Training loss: 0.6963366551832719
Epoch: 79 | Iteration number: [120/393] 30% | Training loss: 0.6958405236403148
Epoch: 79 | Iteration number: [130/393] 33% | Training loss: 0.695386948952308
Epoch: 79 | Iteration number: [140/393] 35% | Training loss: 0.6950116800410407
Epoch: 79 | Iteration number: [150/393] 38% | Training loss: 0.6947450836499532
Epoch: 79 | Iteration number: [160/393] 40% | Training loss: 0.6944269124418497
Epoch: 79 | Iteration number: [170/393] 43% | Training loss: 0.6942030440358554
Epoch: 79 | Iteration number: [180/393] 45% | Training loss: 0.6939868923690584
Epoch: 79 | Iteration number: [190/393] 48% | Training loss: 0.6938022309227994
Epoch: 79 | Iteration number: [200/393] 50% | Training loss: 0.6936528819799423
Epoch: 79 | Iteration number: [210/393] 53% | Training loss: 0.6934424139204479
Epoch: 79 | Iteration number: [220/393] 55% | Training loss: 0.6932704706083644
Epoch: 79 | Iteration number: [230/393] 58% | Training loss: 0.6931401592233907
Epoch: 79 | Iteration number: [240/393] 61% | Training loss: 0.6930015044907729
Epoch: 79 | Iteration number: [250/393] 63% | Training loss: 0.692854430437088
Epoch: 79 | Iteration number: [260/393] 66% | Training loss: 0.692711394566756
Epoch: 79 | Iteration number: [270/393] 68% | Training loss: 0.69256717077008
Epoch: 79 | Iteration number: [280/393] 71% | Training loss: 0.6924380700503077
Epoch: 79 | Iteration number: [290/393] 73% | Training loss: 0.6923830373533841
Epoch: 79 | Iteration number: [300/393] 76% | Training loss: 0.6923332599798838
Epoch: 79 | Iteration number: [310/393] 78% | Training loss: 0.6922839956898843
Epoch: 79 | Iteration number: [320/393] 81% | Training loss: 0.6922194786369801
Epoch: 79 | Iteration number: [330/393] 83% | Training loss: 0.6921253236857328
Epoch: 79 | Iteration number: [340/393] 86% | Training loss: 0.6921024446978289
Epoch: 79 | Iteration number: [350/393] 89% | Training loss: 0.6920557606220246
Epoch: 79 | Iteration number: [360/393] 91% | Training loss: 0.6919900824626287
Epoch: 79 | Iteration number: [370/393] 94% | Training loss: 0.6919416066762564
Epoch: 79 | Iteration number: [380/393] 96% | Training loss: 0.6918708631866857
Epoch: 79 | Iteration number: [390/393] 99% | Training loss: 0.6918243399033179

 End of epoch: 79 | Train Loss: 0.6900577649815391 | Training Time: 66 

 End of epoch: 79 | Eval Loss: 0.6905472229938118 | Evaluating Time: 17 
Epoch: 80 | Iteration number: [10/393] 2% | Training loss: 0.7586712777614594
Epoch: 80 | Iteration number: [20/393] 5% | Training loss: 0.7243577629327774
Epoch: 80 | Iteration number: [30/393] 7% | Training loss: 0.713001960515976
Epoch: 80 | Iteration number: [40/393] 10% | Training loss: 0.7075244262814522
Epoch: 80 | Iteration number: [50/393] 12% | Training loss: 0.7041665196418763
Epoch: 80 | Iteration number: [60/393] 15% | Training loss: 0.7019264469544093
Epoch: 80 | Iteration number: [70/393] 17% | Training loss: 0.7003157019615174
Epoch: 80 | Iteration number: [80/393] 20% | Training loss: 0.6988946840167045
Epoch: 80 | Iteration number: [90/393] 22% | Training loss: 0.69792261256112
Epoch: 80 | Iteration number: [100/393] 25% | Training loss: 0.6971376240253448
Epoch: 80 | Iteration number: [110/393] 27% | Training loss: 0.6963145548647101
Epoch: 80 | Iteration number: [120/393] 30% | Training loss: 0.695769177377224
Epoch: 80 | Iteration number: [130/393] 33% | Training loss: 0.695378231543761
Epoch: 80 | Iteration number: [140/393] 35% | Training loss: 0.6949084447962898
Epoch: 80 | Iteration number: [150/393] 38% | Training loss: 0.6945606482028961
Epoch: 80 | Iteration number: [160/393] 40% | Training loss: 0.6942666482180357
Epoch: 80 | Iteration number: [170/393] 43% | Training loss: 0.6940171154106365
Epoch: 80 | Iteration number: [180/393] 45% | Training loss: 0.6937542067633735
Epoch: 80 | Iteration number: [190/393] 48% | Training loss: 0.6935358063170785
Epoch: 80 | Iteration number: [200/393] 50% | Training loss: 0.6933831629157067
Epoch: 80 | Iteration number: [210/393] 53% | Training loss: 0.6932004079932258
Epoch: 80 | Iteration number: [220/393] 55% | Training loss: 0.6930723439563404
Epoch: 80 | Iteration number: [230/393] 58% | Training loss: 0.692875400574311
Epoch: 80 | Iteration number: [240/393] 61% | Training loss: 0.6927734620869159
Epoch: 80 | Iteration number: [250/393] 63% | Training loss: 0.6927006051540375
Epoch: 80 | Iteration number: [260/393] 66% | Training loss: 0.6925873563839839
Epoch: 80 | Iteration number: [270/393] 68% | Training loss: 0.6925012566425183
Epoch: 80 | Iteration number: [280/393] 71% | Training loss: 0.6924761518836021
Epoch: 80 | Iteration number: [290/393] 73% | Training loss: 0.692411660120405
Epoch: 80 | Iteration number: [300/393] 76% | Training loss: 0.6923257011175156
Epoch: 80 | Iteration number: [310/393] 78% | Training loss: 0.6922385756046542
Epoch: 80 | Iteration number: [320/393] 81% | Training loss: 0.6921574003994465
Epoch: 80 | Iteration number: [330/393] 83% | Training loss: 0.692085307114052
Epoch: 80 | Iteration number: [340/393] 86% | Training loss: 0.6920488329494701
Epoch: 80 | Iteration number: [350/393] 89% | Training loss: 0.6919949679715293
Epoch: 80 | Iteration number: [360/393] 91% | Training loss: 0.6919919550418854
Epoch: 80 | Iteration number: [370/393] 94% | Training loss: 0.6919554177168253
Epoch: 80 | Iteration number: [380/393] 96% | Training loss: 0.6919322296192771
Epoch: 80 | Iteration number: [390/393] 99% | Training loss: 0.6918787782008832

 End of epoch: 80 | Train Loss: 0.6901114417699761 | Training Time: 67 

 End of epoch: 80 | Eval Loss: 0.6904768749159209 | Evaluating Time: 17 
Epoch: 81 | Iteration number: [10/393] 2% | Training loss: 0.7578627586364746
Epoch: 81 | Iteration number: [20/393] 5% | Training loss: 0.7239156126976013
Epoch: 81 | Iteration number: [30/393] 7% | Training loss: 0.7127412776152293
Epoch: 81 | Iteration number: [40/393] 10% | Training loss: 0.7072185203433037
Epoch: 81 | Iteration number: [50/393] 12% | Training loss: 0.7037203645706177
Epoch: 81 | Iteration number: [60/393] 15% | Training loss: 0.701371165116628
Epoch: 81 | Iteration number: [70/393] 17% | Training loss: 0.6996160898889814
Epoch: 81 | Iteration number: [80/393] 20% | Training loss: 0.6984088435769081
Epoch: 81 | Iteration number: [90/393] 22% | Training loss: 0.6974201613002353
Epoch: 81 | Iteration number: [100/393] 25% | Training loss: 0.6967731362581253
Epoch: 81 | Iteration number: [110/393] 27% | Training loss: 0.6962071391669187
Epoch: 81 | Iteration number: [120/393] 30% | Training loss: 0.6956520209709803
Epoch: 81 | Iteration number: [130/393] 33% | Training loss: 0.6951201163805448
Epoch: 81 | Iteration number: [140/393] 35% | Training loss: 0.6947304951293128
Epoch: 81 | Iteration number: [150/393] 38% | Training loss: 0.6943537708123525
Epoch: 81 | Iteration number: [160/393] 40% | Training loss: 0.694106824696064
Epoch: 81 | Iteration number: [170/393] 43% | Training loss: 0.69384805560112
Epoch: 81 | Iteration number: [180/393] 45% | Training loss: 0.6936451620525784
Epoch: 81 | Iteration number: [190/393] 48% | Training loss: 0.6934113684453462
Epoch: 81 | Iteration number: [200/393] 50% | Training loss: 0.6932982593774796
Epoch: 81 | Iteration number: [210/393] 53% | Training loss: 0.6931379394871848
Epoch: 81 | Iteration number: [220/393] 55% | Training loss: 0.6930272216146642
Epoch: 81 | Iteration number: [230/393] 58% | Training loss: 0.6928705464238706
Epoch: 81 | Iteration number: [240/393] 61% | Training loss: 0.6927611688772838
Epoch: 81 | Iteration number: [250/393] 63% | Training loss: 0.6926274824142457
Epoch: 81 | Iteration number: [260/393] 66% | Training loss: 0.6925647540734364
Epoch: 81 | Iteration number: [270/393] 68% | Training loss: 0.6924482138068587
Epoch: 81 | Iteration number: [280/393] 71% | Training loss: 0.6923669996006149
Epoch: 81 | Iteration number: [290/393] 73% | Training loss: 0.6922864494652584
Epoch: 81 | Iteration number: [300/393] 76% | Training loss: 0.6922378289699554
Epoch: 81 | Iteration number: [310/393] 78% | Training loss: 0.6921797979262567
Epoch: 81 | Iteration number: [320/393] 81% | Training loss: 0.6921258803457022
Epoch: 81 | Iteration number: [330/393] 83% | Training loss: 0.6920757515863939
Epoch: 81 | Iteration number: [340/393] 86% | Training loss: 0.6920152657172259
Epoch: 81 | Iteration number: [350/393] 89% | Training loss: 0.6919743093422481
Epoch: 81 | Iteration number: [360/393] 91% | Training loss: 0.6919282709558805
Epoch: 81 | Iteration number: [370/393] 94% | Training loss: 0.6918591786075283
Epoch: 81 | Iteration number: [380/393] 96% | Training loss: 0.6918068277208429
Epoch: 81 | Iteration number: [390/393] 99% | Training loss: 0.6917946150669685

 End of epoch: 81 | Train Loss: 0.6900208330033086 | Training Time: 66 

 End of epoch: 81 | Eval Loss: 0.6904468536376953 | Evaluating Time: 17 
Epoch: 82 | Iteration number: [10/393] 2% | Training loss: 0.7579870760440827
Epoch: 82 | Iteration number: [20/393] 5% | Training loss: 0.7240933001041412
Epoch: 82 | Iteration number: [30/393] 7% | Training loss: 0.7126322865486145
Epoch: 82 | Iteration number: [40/393] 10% | Training loss: 0.7067071482539177
Epoch: 82 | Iteration number: [50/393] 12% | Training loss: 0.7034025168418885
Epoch: 82 | Iteration number: [60/393] 15% | Training loss: 0.7012977023919423
Epoch: 82 | Iteration number: [70/393] 17% | Training loss: 0.6995410093239376
Epoch: 82 | Iteration number: [80/393] 20% | Training loss: 0.6981678135693073
Epoch: 82 | Iteration number: [90/393] 22% | Training loss: 0.6970838321579828
Epoch: 82 | Iteration number: [100/393] 25% | Training loss: 0.6963785809278488
Epoch: 82 | Iteration number: [110/393] 27% | Training loss: 0.695816526629708
Epoch: 82 | Iteration number: [120/393] 30% | Training loss: 0.6953921327988307
Epoch: 82 | Iteration number: [130/393] 33% | Training loss: 0.6950927367577187
Epoch: 82 | Iteration number: [140/393] 35% | Training loss: 0.6947740857090269
Epoch: 82 | Iteration number: [150/393] 38% | Training loss: 0.6944509788354238
Epoch: 82 | Iteration number: [160/393] 40% | Training loss: 0.6941581401973963
Epoch: 82 | Iteration number: [170/393] 43% | Training loss: 0.6938577771186829
Epoch: 82 | Iteration number: [180/393] 45% | Training loss: 0.6937109794881609
Epoch: 82 | Iteration number: [190/393] 48% | Training loss: 0.6935909660238969
Epoch: 82 | Iteration number: [200/393] 50% | Training loss: 0.6934479248523712
Epoch: 82 | Iteration number: [210/393] 53% | Training loss: 0.6932625526473636
Epoch: 82 | Iteration number: [220/393] 55% | Training loss: 0.6931055648760363
Epoch: 82 | Iteration number: [230/393] 58% | Training loss: 0.6930102923642034
Epoch: 82 | Iteration number: [240/393] 61% | Training loss: 0.6929273334642251
Epoch: 82 | Iteration number: [250/393] 63% | Training loss: 0.6928425605297088
Epoch: 82 | Iteration number: [260/393] 66% | Training loss: 0.6927503881546168
Epoch: 82 | Iteration number: [270/393] 68% | Training loss: 0.6926811948970512
Epoch: 82 | Iteration number: [280/393] 71% | Training loss: 0.692598120868206
Epoch: 82 | Iteration number: [290/393] 73% | Training loss: 0.6925129933603879
Epoch: 82 | Iteration number: [300/393] 76% | Training loss: 0.692453160683314
Epoch: 82 | Iteration number: [310/393] 78% | Training loss: 0.692353178416529
Epoch: 82 | Iteration number: [320/393] 81% | Training loss: 0.6922297824174166
Epoch: 82 | Iteration number: [330/393] 83% | Training loss: 0.6921674471912962
Epoch: 82 | Iteration number: [340/393] 86% | Training loss: 0.6920787993599387
Epoch: 82 | Iteration number: [350/393] 89% | Training loss: 0.6920183944702148
Epoch: 82 | Iteration number: [360/393] 91% | Training loss: 0.6919483953052097
Epoch: 82 | Iteration number: [370/393] 94% | Training loss: 0.6918976247310639
Epoch: 82 | Iteration number: [380/393] 96% | Training loss: 0.6918341828019996
Epoch: 82 | Iteration number: [390/393] 99% | Training loss: 0.6918130529232515

 End of epoch: 82 | Train Loss: 0.6900469539426362 | Training Time: 66 

 End of epoch: 82 | Eval Loss: 0.6905828702206515 | Evaluating Time: 16 
Epoch: 83 | Iteration number: [10/393] 2% | Training loss: 0.7587947845458984
Epoch: 83 | Iteration number: [20/393] 5% | Training loss: 0.7250352948904037
Epoch: 83 | Iteration number: [30/393] 7% | Training loss: 0.7135235071182251
Epoch: 83 | Iteration number: [40/393] 10% | Training loss: 0.7076681047677994
Epoch: 83 | Iteration number: [50/393] 12% | Training loss: 0.703882167339325
Epoch: 83 | Iteration number: [60/393] 15% | Training loss: 0.7015309582153956
Epoch: 83 | Iteration number: [70/393] 17% | Training loss: 0.6997635245323182
Epoch: 83 | Iteration number: [80/393] 20% | Training loss: 0.6985801495611668
Epoch: 83 | Iteration number: [90/393] 22% | Training loss: 0.6975937339994642
Epoch: 83 | Iteration number: [100/393] 25% | Training loss: 0.6967991977930069
Epoch: 83 | Iteration number: [110/393] 27% | Training loss: 0.6961463175036691
Epoch: 83 | Iteration number: [120/393] 30% | Training loss: 0.6956289594372114
Epoch: 83 | Iteration number: [130/393] 33% | Training loss: 0.695202427643996
Epoch: 83 | Iteration number: [140/393] 35% | Training loss: 0.6948309123516083
Epoch: 83 | Iteration number: [150/393] 38% | Training loss: 0.6944729419549306
Epoch: 83 | Iteration number: [160/393] 40% | Training loss: 0.6941744886338711
Epoch: 83 | Iteration number: [170/393] 43% | Training loss: 0.6939294327707851
Epoch: 83 | Iteration number: [180/393] 45% | Training loss: 0.693714451458719
Epoch: 83 | Iteration number: [190/393] 48% | Training loss: 0.693496520895707
Epoch: 83 | Iteration number: [200/393] 50% | Training loss: 0.6933467572927475
Epoch: 83 | Iteration number: [210/393] 53% | Training loss: 0.6931854091939472
Epoch: 83 | Iteration number: [220/393] 55% | Training loss: 0.6929599379951303
Epoch: 83 | Iteration number: [230/393] 58% | Training loss: 0.6928856787474259
Epoch: 83 | Iteration number: [240/393] 61% | Training loss: 0.6927431022127469
Epoch: 83 | Iteration number: [250/393] 63% | Training loss: 0.6926981985569001
Epoch: 83 | Iteration number: [260/393] 66% | Training loss: 0.6925690020506199
Epoch: 83 | Iteration number: [270/393] 68% | Training loss: 0.6924630516105228
Epoch: 83 | Iteration number: [280/393] 71% | Training loss: 0.6924085021018982
Epoch: 83 | Iteration number: [290/393] 73% | Training loss: 0.6923544657641444
Epoch: 83 | Iteration number: [300/393] 76% | Training loss: 0.6923189860582352
Epoch: 83 | Iteration number: [310/393] 78% | Training loss: 0.6922764616627847
Epoch: 83 | Iteration number: [320/393] 81% | Training loss: 0.6922157617285848
Epoch: 83 | Iteration number: [330/393] 83% | Training loss: 0.6921022745695982
Epoch: 83 | Iteration number: [340/393] 86% | Training loss: 0.6920610419091057
Epoch: 83 | Iteration number: [350/393] 89% | Training loss: 0.6920110315935952
Epoch: 83 | Iteration number: [360/393] 91% | Training loss: 0.6919669119848145
Epoch: 83 | Iteration number: [370/393] 94% | Training loss: 0.6919112464866123
Epoch: 83 | Iteration number: [380/393] 96% | Training loss: 0.6918861594639326
Epoch: 83 | Iteration number: [390/393] 99% | Training loss: 0.691815770436556

 End of epoch: 83 | Train Loss: 0.690055280544679 | Training Time: 66 

 End of epoch: 83 | Eval Loss: 0.6904878628497221 | Evaluating Time: 16 
Epoch: 84 | Iteration number: [10/393] 2% | Training loss: 0.7583239912986756
Epoch: 84 | Iteration number: [20/393] 5% | Training loss: 0.7238732665777207
Epoch: 84 | Iteration number: [30/393] 7% | Training loss: 0.7125418543815613
Epoch: 84 | Iteration number: [40/393] 10% | Training loss: 0.706728720664978
Epoch: 84 | Iteration number: [50/393] 12% | Training loss: 0.7033745408058166
Epoch: 84 | Iteration number: [60/393] 15% | Training loss: 0.701020402709643
Epoch: 84 | Iteration number: [70/393] 17% | Training loss: 0.6994868304048266
Epoch: 84 | Iteration number: [80/393] 20% | Training loss: 0.6983771815896034
Epoch: 84 | Iteration number: [90/393] 22% | Training loss: 0.6974103305074904
Epoch: 84 | Iteration number: [100/393] 25% | Training loss: 0.6966879850625992
Epoch: 84 | Iteration number: [110/393] 27% | Training loss: 0.6961479279127988
Epoch: 84 | Iteration number: [120/393] 30% | Training loss: 0.6956634153922399
Epoch: 84 | Iteration number: [130/393] 33% | Training loss: 0.6953096912457393
Epoch: 84 | Iteration number: [140/393] 35% | Training loss: 0.6949242493935994
Epoch: 84 | Iteration number: [150/393] 38% | Training loss: 0.6945943176746369
Epoch: 84 | Iteration number: [160/393] 40% | Training loss: 0.6943494409322739
Epoch: 84 | Iteration number: [170/393] 43% | Training loss: 0.6941576291533077
Epoch: 84 | Iteration number: [180/393] 45% | Training loss: 0.6939088298214806
Epoch: 84 | Iteration number: [190/393] 48% | Training loss: 0.6937190156233938
Epoch: 84 | Iteration number: [200/393] 50% | Training loss: 0.6935004281997681
Epoch: 84 | Iteration number: [210/393] 53% | Training loss: 0.6933711909112477
Epoch: 84 | Iteration number: [220/393] 55% | Training loss: 0.6932631823149594
Epoch: 84 | Iteration number: [230/393] 58% | Training loss: 0.6931554110153861
Epoch: 84 | Iteration number: [240/393] 61% | Training loss: 0.6930369260410468
Epoch: 84 | Iteration number: [250/393] 63% | Training loss: 0.6928815009593964
Epoch: 84 | Iteration number: [260/393] 66% | Training loss: 0.6927823444971671
Epoch: 84 | Iteration number: [270/393] 68% | Training loss: 0.6926794531168761
Epoch: 84 | Iteration number: [280/393] 71% | Training loss: 0.6925822115370206
Epoch: 84 | Iteration number: [290/393] 73% | Training loss: 0.6924799764978474
Epoch: 84 | Iteration number: [300/393] 76% | Training loss: 0.6923684493700664
Epoch: 84 | Iteration number: [310/393] 78% | Training loss: 0.6922795113055936
Epoch: 84 | Iteration number: [320/393] 81% | Training loss: 0.6922217043116689
Epoch: 84 | Iteration number: [330/393] 83% | Training loss: 0.6921412937568896
Epoch: 84 | Iteration number: [340/393] 86% | Training loss: 0.6920824473395067
Epoch: 84 | Iteration number: [350/393] 89% | Training loss: 0.692001997913633
Epoch: 84 | Iteration number: [360/393] 91% | Training loss: 0.6919579767518573
Epoch: 84 | Iteration number: [370/393] 94% | Training loss: 0.6919008833331031
Epoch: 84 | Iteration number: [380/393] 96% | Training loss: 0.691878005391673
Epoch: 84 | Iteration number: [390/393] 99% | Training loss: 0.6918396662443113

 End of epoch: 84 | Train Loss: 0.6900655536251213 | Training Time: 66 

 End of epoch: 84 | Eval Loss: 0.6904503788266864 | Evaluating Time: 17 
Epoch: 85 | Iteration number: [10/393] 2% | Training loss: 0.7584877908229828
Epoch: 85 | Iteration number: [20/393] 5% | Training loss: 0.7251166611909866
Epoch: 85 | Iteration number: [30/393] 7% | Training loss: 0.7132815837860107
Epoch: 85 | Iteration number: [40/393] 10% | Training loss: 0.7076409846544266
Epoch: 85 | Iteration number: [50/393] 12% | Training loss: 0.704134521484375
Epoch: 85 | Iteration number: [60/393] 15% | Training loss: 0.7018982003132502
Epoch: 85 | Iteration number: [70/393] 17% | Training loss: 0.7000163086823055
Epoch: 85 | Iteration number: [80/393] 20% | Training loss: 0.6987334609031677
Epoch: 85 | Iteration number: [90/393] 22% | Training loss: 0.6978569865226746
Epoch: 85 | Iteration number: [100/393] 25% | Training loss: 0.6971258109807968
Epoch: 85 | Iteration number: [110/393] 27% | Training loss: 0.6964663814414631
Epoch: 85 | Iteration number: [120/393] 30% | Training loss: 0.6959895441929499
Epoch: 85 | Iteration number: [130/393] 33% | Training loss: 0.6955427587032318
Epoch: 85 | Iteration number: [140/393] 35% | Training loss: 0.6951733167682376
Epoch: 85 | Iteration number: [150/393] 38% | Training loss: 0.6948749792575836
Epoch: 85 | Iteration number: [160/393] 40% | Training loss: 0.6945827282965183
Epoch: 85 | Iteration number: [170/393] 43% | Training loss: 0.694338708414751
Epoch: 85 | Iteration number: [180/393] 45% | Training loss: 0.6940782487392425
Epoch: 85 | Iteration number: [190/393] 48% | Training loss: 0.6938870295097953
Epoch: 85 | Iteration number: [200/393] 50% | Training loss: 0.6936942437291145
Epoch: 85 | Iteration number: [210/393] 53% | Training loss: 0.6935424892675309
Epoch: 85 | Iteration number: [220/393] 55% | Training loss: 0.6934317951852625
Epoch: 85 | Iteration number: [230/393] 58% | Training loss: 0.693295714388723
Epoch: 85 | Iteration number: [240/393] 61% | Training loss: 0.6931402722994486
Epoch: 85 | Iteration number: [250/393] 63% | Training loss: 0.6930190579891204
Epoch: 85 | Iteration number: [260/393] 66% | Training loss: 0.6928747422420062
Epoch: 85 | Iteration number: [270/393] 68% | Training loss: 0.6927433031576651
Epoch: 85 | Iteration number: [280/393] 71% | Training loss: 0.6926749127251761
Epoch: 85 | Iteration number: [290/393] 73% | Training loss: 0.6925812114929331
Epoch: 85 | Iteration number: [300/393] 76% | Training loss: 0.6924797125657399
Epoch: 85 | Iteration number: [310/393] 78% | Training loss: 0.6923873032293012
Epoch: 85 | Iteration number: [320/393] 81% | Training loss: 0.6922871863469482
Epoch: 85 | Iteration number: [330/393] 83% | Training loss: 0.6922061656460617
Epoch: 85 | Iteration number: [340/393] 86% | Training loss: 0.6921702993266723
Epoch: 85 | Iteration number: [350/393] 89% | Training loss: 0.692124480349677
Epoch: 85 | Iteration number: [360/393] 91% | Training loss: 0.6920632782909605
Epoch: 85 | Iteration number: [370/393] 94% | Training loss: 0.6920175521760373
Epoch: 85 | Iteration number: [380/393] 96% | Training loss: 0.6919443662229338
Epoch: 85 | Iteration number: [390/393] 99% | Training loss: 0.6918999384611081

 End of epoch: 85 | Train Loss: 0.6901148683545547 | Training Time: 66 

 End of epoch: 85 | Eval Loss: 0.6905334798657164 | Evaluating Time: 16 
Epoch: 86 | Iteration number: [10/393] 2% | Training loss: 0.7594443917274475
Epoch: 86 | Iteration number: [20/393] 5% | Training loss: 0.7244580924510956
Epoch: 86 | Iteration number: [30/393] 7% | Training loss: 0.7127485156059266
Epoch: 86 | Iteration number: [40/393] 10% | Training loss: 0.7071798384189606
Epoch: 86 | Iteration number: [50/393] 12% | Training loss: 0.7037508463859559
Epoch: 86 | Iteration number: [60/393] 15% | Training loss: 0.7013963172833125
Epoch: 86 | Iteration number: [70/393] 17% | Training loss: 0.6998321882316044
Epoch: 86 | Iteration number: [80/393] 20% | Training loss: 0.6984377555549145
Epoch: 86 | Iteration number: [90/393] 22% | Training loss: 0.6974285781383515
Epoch: 86 | Iteration number: [100/393] 25% | Training loss: 0.6967493742704391
Epoch: 86 | Iteration number: [110/393] 27% | Training loss: 0.6962659218094566
Epoch: 86 | Iteration number: [120/393] 30% | Training loss: 0.695701623459657
Epoch: 86 | Iteration number: [130/393] 33% | Training loss: 0.6952965030303369
Epoch: 86 | Iteration number: [140/393] 35% | Training loss: 0.6949407104934965
Epoch: 86 | Iteration number: [150/393] 38% | Training loss: 0.6946413270632426
Epoch: 86 | Iteration number: [160/393] 40% | Training loss: 0.6942769404500723
Epoch: 86 | Iteration number: [170/393] 43% | Training loss: 0.6940071943928213
Epoch: 86 | Iteration number: [180/393] 45% | Training loss: 0.6938141736719343
Epoch: 86 | Iteration number: [190/393] 48% | Training loss: 0.693636966692774
Epoch: 86 | Iteration number: [200/393] 50% | Training loss: 0.6934980553388596
Epoch: 86 | Iteration number: [210/393] 53% | Training loss: 0.6933759203978948
Epoch: 86 | Iteration number: [220/393] 55% | Training loss: 0.6932147185910832
Epoch: 86 | Iteration number: [230/393] 58% | Training loss: 0.6931331460890563
Epoch: 86 | Iteration number: [240/393] 61% | Training loss: 0.692995335906744
Epoch: 86 | Iteration number: [250/393] 63% | Training loss: 0.6928172709941864
Epoch: 86 | Iteration number: [260/393] 66% | Training loss: 0.6927170627392255
Epoch: 86 | Iteration number: [270/393] 68% | Training loss: 0.6926335630593476
Epoch: 86 | Iteration number: [280/393] 71% | Training loss: 0.692555511210646
Epoch: 86 | Iteration number: [290/393] 73% | Training loss: 0.6924407272503293
Epoch: 86 | Iteration number: [300/393] 76% | Training loss: 0.6923689182599385
Epoch: 86 | Iteration number: [310/393] 78% | Training loss: 0.692302672132369
Epoch: 86 | Iteration number: [320/393] 81% | Training loss: 0.6922318860888481
Epoch: 86 | Iteration number: [330/393] 83% | Training loss: 0.6921578605969747
Epoch: 86 | Iteration number: [340/393] 86% | Training loss: 0.692104530860396
Epoch: 86 | Iteration number: [350/393] 89% | Training loss: 0.6919887508664813
Epoch: 86 | Iteration number: [360/393] 91% | Training loss: 0.6919586734639274
Epoch: 86 | Iteration number: [370/393] 94% | Training loss: 0.6919134354269182
Epoch: 86 | Iteration number: [380/393] 96% | Training loss: 0.6918610146171168
Epoch: 86 | Iteration number: [390/393] 99% | Training loss: 0.6918522741550054

 End of epoch: 86 | Train Loss: 0.6900749773772922 | Training Time: 66 

 End of epoch: 86 | Eval Loss: 0.6905666455930594 | Evaluating Time: 16 
Epoch: 87 | Iteration number: [10/393] 2% | Training loss: 0.7600214421749115
Epoch: 87 | Iteration number: [20/393] 5% | Training loss: 0.7245263189077378
Epoch: 87 | Iteration number: [30/393] 7% | Training loss: 0.7134302298227946
Epoch: 87 | Iteration number: [40/393] 10% | Training loss: 0.7076043754816055
Epoch: 87 | Iteration number: [50/393] 12% | Training loss: 0.7040503108501435
Epoch: 87 | Iteration number: [60/393] 15% | Training loss: 0.7016256749629974
Epoch: 87 | Iteration number: [70/393] 17% | Training loss: 0.70003667814391
Epoch: 87 | Iteration number: [80/393] 20% | Training loss: 0.698611169308424
Epoch: 87 | Iteration number: [90/393] 22% | Training loss: 0.6976362380716535
Epoch: 87 | Iteration number: [100/393] 25% | Training loss: 0.6970064449310303
Epoch: 87 | Iteration number: [110/393] 27% | Training loss: 0.6962922123345462
Epoch: 87 | Iteration number: [120/393] 30% | Training loss: 0.6957427258292834
Epoch: 87 | Iteration number: [130/393] 33% | Training loss: 0.6953893363475799
Epoch: 87 | Iteration number: [140/393] 35% | Training loss: 0.6950473776885442
Epoch: 87 | Iteration number: [150/393] 38% | Training loss: 0.6946782819430033
Epoch: 87 | Iteration number: [160/393] 40% | Training loss: 0.694402477517724
Epoch: 87 | Iteration number: [170/393] 43% | Training loss: 0.6940869566272286
Epoch: 87 | Iteration number: [180/393] 45% | Training loss: 0.6938426729705599
Epoch: 87 | Iteration number: [190/393] 48% | Training loss: 0.6935951292514801
Epoch: 87 | Iteration number: [200/393] 50% | Training loss: 0.6933972379565239
Epoch: 87 | Iteration number: [210/393] 53% | Training loss: 0.6932765974884941
Epoch: 87 | Iteration number: [220/393] 55% | Training loss: 0.6931974960999056
Epoch: 87 | Iteration number: [230/393] 58% | Training loss: 0.6930940063103386
Epoch: 87 | Iteration number: [240/393] 61% | Training loss: 0.6929719453056653
Epoch: 87 | Iteration number: [250/393] 63% | Training loss: 0.6928823363780975
Epoch: 87 | Iteration number: [260/393] 66% | Training loss: 0.6927289660160358
Epoch: 87 | Iteration number: [270/393] 68% | Training loss: 0.6926087145452147
Epoch: 87 | Iteration number: [280/393] 71% | Training loss: 0.6925345925348145
Epoch: 87 | Iteration number: [290/393] 73% | Training loss: 0.6924534181068683
Epoch: 87 | Iteration number: [300/393] 76% | Training loss: 0.6923499802748362
Epoch: 87 | Iteration number: [310/393] 78% | Training loss: 0.6922579007764016
Epoch: 87 | Iteration number: [320/393] 81% | Training loss: 0.6921839104965329
Epoch: 87 | Iteration number: [330/393] 83% | Training loss: 0.6921339853243395
Epoch: 87 | Iteration number: [340/393] 86% | Training loss: 0.6920881867408752
Epoch: 87 | Iteration number: [350/393] 89% | Training loss: 0.6920429272311074
Epoch: 87 | Iteration number: [360/393] 91% | Training loss: 0.6919849453700914
Epoch: 87 | Iteration number: [370/393] 94% | Training loss: 0.6919496272061322
Epoch: 87 | Iteration number: [380/393] 96% | Training loss: 0.691905056332287
Epoch: 87 | Iteration number: [390/393] 99% | Training loss: 0.6918289908995995

 End of epoch: 87 | Train Loss: 0.6900458208477224 | Training Time: 66 

 End of epoch: 87 | Eval Loss: 0.6904793187063567 | Evaluating Time: 17 
Epoch: 88 | Iteration number: [10/393] 2% | Training loss: 0.7594415783882141
Epoch: 88 | Iteration number: [20/393] 5% | Training loss: 0.7244548082351685
Epoch: 88 | Iteration number: [30/393] 7% | Training loss: 0.7128996968269348
Epoch: 88 | Iteration number: [40/393] 10% | Training loss: 0.7071895778179169
Epoch: 88 | Iteration number: [50/393] 12% | Training loss: 0.7041384148597717
Epoch: 88 | Iteration number: [60/393] 15% | Training loss: 0.7020057956377665
Epoch: 88 | Iteration number: [70/393] 17% | Training loss: 0.7003478458949498
Epoch: 88 | Iteration number: [80/393] 20% | Training loss: 0.6991211786866188
Epoch: 88 | Iteration number: [90/393] 22% | Training loss: 0.6980179005199009
Epoch: 88 | Iteration number: [100/393] 25% | Training loss: 0.6971340894699096
Epoch: 88 | Iteration number: [110/393] 27% | Training loss: 0.6965292383324017
Epoch: 88 | Iteration number: [120/393] 30% | Training loss: 0.6960072159767151
Epoch: 88 | Iteration number: [130/393] 33% | Training loss: 0.6955104699501624
Epoch: 88 | Iteration number: [140/393] 35% | Training loss: 0.6951254695653916
Epoch: 88 | Iteration number: [150/393] 38% | Training loss: 0.6947517045338949
Epoch: 88 | Iteration number: [160/393] 40% | Training loss: 0.6944607492536307
Epoch: 88 | Iteration number: [170/393] 43% | Training loss: 0.6942201281295103
Epoch: 88 | Iteration number: [180/393] 45% | Training loss: 0.6939193367958069
Epoch: 88 | Iteration number: [190/393] 48% | Training loss: 0.6937145766459013
Epoch: 88 | Iteration number: [200/393] 50% | Training loss: 0.6935261926054954
Epoch: 88 | Iteration number: [210/393] 53% | Training loss: 0.6933667304969969
Epoch: 88 | Iteration number: [220/393] 55% | Training loss: 0.6931818758899515
Epoch: 88 | Iteration number: [230/393] 58% | Training loss: 0.6930613559225332
Epoch: 88 | Iteration number: [240/393] 61% | Training loss: 0.6929059604803721
Epoch: 88 | Iteration number: [250/393] 63% | Training loss: 0.6927973570823669
Epoch: 88 | Iteration number: [260/393] 66% | Training loss: 0.6927104335564833
Epoch: 88 | Iteration number: [270/393] 68% | Training loss: 0.6925954615628278
Epoch: 88 | Iteration number: [280/393] 71% | Training loss: 0.692497204031263
Epoch: 88 | Iteration number: [290/393] 73% | Training loss: 0.692382045655415
Epoch: 88 | Iteration number: [300/393] 76% | Training loss: 0.6923116074005763
Epoch: 88 | Iteration number: [310/393] 78% | Training loss: 0.6922594499203467
Epoch: 88 | Iteration number: [320/393] 81% | Training loss: 0.6922063771635294
Epoch: 88 | Iteration number: [330/393] 83% | Training loss: 0.692150781732617
Epoch: 88 | Iteration number: [340/393] 86% | Training loss: 0.6920523988849977
Epoch: 88 | Iteration number: [350/393] 89% | Training loss: 0.6920200102669852
Epoch: 88 | Iteration number: [360/393] 91% | Training loss: 0.691967563993401
Epoch: 88 | Iteration number: [370/393] 94% | Training loss: 0.6919298661721719
Epoch: 88 | Iteration number: [380/393] 96% | Training loss: 0.6919017529801319
Epoch: 88 | Iteration number: [390/393] 99% | Training loss: 0.6918407097840921

 End of epoch: 88 | Train Loss: 0.6900589584394266 | Training Time: 66 

 End of epoch: 88 | Eval Loss: 0.6904490419796535 | Evaluating Time: 16 
Epoch: 89 | Iteration number: [10/393] 2% | Training loss: 0.7597948253154755
Epoch: 89 | Iteration number: [20/393] 5% | Training loss: 0.7247490376234055
Epoch: 89 | Iteration number: [30/393] 7% | Training loss: 0.7129426797231039
Epoch: 89 | Iteration number: [40/393] 10% | Training loss: 0.7072220697999001
Epoch: 89 | Iteration number: [50/393] 12% | Training loss: 0.703732568025589
Epoch: 89 | Iteration number: [60/393] 15% | Training loss: 0.7015055000782013
Epoch: 89 | Iteration number: [70/393] 17% | Training loss: 0.6997107114110674
Epoch: 89 | Iteration number: [80/393] 20% | Training loss: 0.6985798746347427
Epoch: 89 | Iteration number: [90/393] 22% | Training loss: 0.697573866446813
Epoch: 89 | Iteration number: [100/393] 25% | Training loss: 0.6967690622806549
Epoch: 89 | Iteration number: [110/393] 27% | Training loss: 0.6961534657261589
Epoch: 89 | Iteration number: [120/393] 30% | Training loss: 0.695606708029906
Epoch: 89 | Iteration number: [130/393] 33% | Training loss: 0.6952013304600348
Epoch: 89 | Iteration number: [140/393] 35% | Training loss: 0.6948014450924737
Epoch: 89 | Iteration number: [150/393] 38% | Training loss: 0.6944290773073832
Epoch: 89 | Iteration number: [160/393] 40% | Training loss: 0.6940899223089219
Epoch: 89 | Iteration number: [170/393] 43% | Training loss: 0.693850888224209
Epoch: 89 | Iteration number: [180/393] 45% | Training loss: 0.6936147832208209
Epoch: 89 | Iteration number: [190/393] 48% | Training loss: 0.6934726275895772
Epoch: 89 | Iteration number: [200/393] 50% | Training loss: 0.6933005222678185
Epoch: 89 | Iteration number: [210/393] 53% | Training loss: 0.6931361927872612
Epoch: 89 | Iteration number: [220/393] 55% | Training loss: 0.6929913959719918
Epoch: 89 | Iteration number: [230/393] 58% | Training loss: 0.6929182617560677
Epoch: 89 | Iteration number: [240/393] 61% | Training loss: 0.6927524919311205
Epoch: 89 | Iteration number: [250/393] 63% | Training loss: 0.69263764834404
Epoch: 89 | Iteration number: [260/393] 66% | Training loss: 0.6925837237101334
Epoch: 89 | Iteration number: [270/393] 68% | Training loss: 0.692461821768019
Epoch: 89 | Iteration number: [280/393] 71% | Training loss: 0.6923671556370599
Epoch: 89 | Iteration number: [290/393] 73% | Training loss: 0.6922967374324799
Epoch: 89 | Iteration number: [300/393] 76% | Training loss: 0.6922130413850148
Epoch: 89 | Iteration number: [310/393] 78% | Training loss: 0.6921674812993696
Epoch: 89 | Iteration number: [320/393] 81% | Training loss: 0.6921468503773213
Epoch: 89 | Iteration number: [330/393] 83% | Training loss: 0.6920340971513228
Epoch: 89 | Iteration number: [340/393] 86% | Training loss: 0.6919829584219876
Epoch: 89 | Iteration number: [350/393] 89% | Training loss: 0.6919608931882041
Epoch: 89 | Iteration number: [360/393] 91% | Training loss: 0.6919139318996006
Epoch: 89 | Iteration number: [370/393] 94% | Training loss: 0.6918641663886406
Epoch: 89 | Iteration number: [380/393] 96% | Training loss: 0.6917770633572027
Epoch: 89 | Iteration number: [390/393] 99% | Training loss: 0.6917530278364817

 End of epoch: 89 | Train Loss: 0.6899867139699805 | Training Time: 66 

 End of epoch: 89 | Eval Loss: 0.6904181363631268 | Evaluating Time: 16 
Epoch: 90 | Iteration number: [10/393] 2% | Training loss: 0.7581699013710022
Epoch: 90 | Iteration number: [20/393] 5% | Training loss: 0.7242724776268006
Epoch: 90 | Iteration number: [30/393] 7% | Training loss: 0.7124698658784231
Epoch: 90 | Iteration number: [40/393] 10% | Training loss: 0.7069109708070755
Epoch: 90 | Iteration number: [50/393] 12% | Training loss: 0.7034145426750184
Epoch: 90 | Iteration number: [60/393] 15% | Training loss: 0.701327312986056
Epoch: 90 | Iteration number: [70/393] 17% | Training loss: 0.6998032280376979
Epoch: 90 | Iteration number: [80/393] 20% | Training loss: 0.6985903844237328
Epoch: 90 | Iteration number: [90/393] 22% | Training loss: 0.6976701147026486
Epoch: 90 | Iteration number: [100/393] 25% | Training loss: 0.6969146728515625
Epoch: 90 | Iteration number: [110/393] 27% | Training loss: 0.6963061034679413
Epoch: 90 | Iteration number: [120/393] 30% | Training loss: 0.6957796429594357
Epoch: 90 | Iteration number: [130/393] 33% | Training loss: 0.6954021568481739
Epoch: 90 | Iteration number: [140/393] 35% | Training loss: 0.6951012053659984
Epoch: 90 | Iteration number: [150/393] 38% | Training loss: 0.6947157780329386
Epoch: 90 | Iteration number: [160/393] 40% | Training loss: 0.694397148117423
Epoch: 90 | Iteration number: [170/393] 43% | Training loss: 0.6941746522398556
Epoch: 90 | Iteration number: [180/393] 45% | Training loss: 0.693920965327157
Epoch: 90 | Iteration number: [190/393] 48% | Training loss: 0.6937625994807796
Epoch: 90 | Iteration number: [200/393] 50% | Training loss: 0.6936101251840592
Epoch: 90 | Iteration number: [210/393] 53% | Training loss: 0.6933426944982438
Epoch: 90 | Iteration number: [220/393] 55% | Training loss: 0.6931430345231836
Epoch: 90 | Iteration number: [230/393] 58% | Training loss: 0.6929954108984574
Epoch: 90 | Iteration number: [240/393] 61% | Training loss: 0.6928699883321922
Epoch: 90 | Iteration number: [250/393] 63% | Training loss: 0.6927218430042267
Epoch: 90 | Iteration number: [260/393] 66% | Training loss: 0.6926314459397243
Epoch: 90 | Iteration number: [270/393] 68% | Training loss: 0.6925442764052638
Epoch: 90 | Iteration number: [280/393] 71% | Training loss: 0.692479587665626
Epoch: 90 | Iteration number: [290/393] 73% | Training loss: 0.6923697132488776
Epoch: 90 | Iteration number: [300/393] 76% | Training loss: 0.6923011714220046
Epoch: 90 | Iteration number: [310/393] 78% | Training loss: 0.6922158225890129
Epoch: 90 | Iteration number: [320/393] 81% | Training loss: 0.6921760689467191
Epoch: 90 | Iteration number: [330/393] 83% | Training loss: 0.6921376194014693
Epoch: 90 | Iteration number: [340/393] 86% | Training loss: 0.6921027555185206
Epoch: 90 | Iteration number: [350/393] 89% | Training loss: 0.6920152258872986
Epoch: 90 | Iteration number: [360/393] 91% | Training loss: 0.6919608626100752
Epoch: 90 | Iteration number: [370/393] 94% | Training loss: 0.691879611240851
Epoch: 90 | Iteration number: [380/393] 96% | Training loss: 0.6918204767139334
Epoch: 90 | Iteration number: [390/393] 99% | Training loss: 0.6917668003302354

 End of epoch: 90 | Train Loss: 0.6900005006911494 | Training Time: 65 

 End of epoch: 90 | Eval Loss: 0.6904729057331475 | Evaluating Time: 16 
Epoch: 91 | Iteration number: [10/393] 2% | Training loss: 0.7588408708572387
Epoch: 91 | Iteration number: [20/393] 5% | Training loss: 0.7247513622045517
Epoch: 91 | Iteration number: [30/393] 7% | Training loss: 0.7134059548377991
Epoch: 91 | Iteration number: [40/393] 10% | Training loss: 0.7073138773441314
Epoch: 91 | Iteration number: [50/393] 12% | Training loss: 0.7039066565036773
Epoch: 91 | Iteration number: [60/393] 15% | Training loss: 0.701568873723348
Epoch: 91 | Iteration number: [70/393] 17% | Training loss: 0.6998140352112906
Epoch: 91 | Iteration number: [80/393] 20% | Training loss: 0.698497400432825
Epoch: 91 | Iteration number: [90/393] 22% | Training loss: 0.6974771002928416
Epoch: 91 | Iteration number: [100/393] 25% | Training loss: 0.6967347103357315
Epoch: 91 | Iteration number: [110/393] 27% | Training loss: 0.6959996288472956
Epoch: 91 | Iteration number: [120/393] 30% | Training loss: 0.6955254688858986
Epoch: 91 | Iteration number: [130/393] 33% | Training loss: 0.6950971970191369
Epoch: 91 | Iteration number: [140/393] 35% | Training loss: 0.6947063995259148
Epoch: 91 | Iteration number: [150/393] 38% | Training loss: 0.6943563294410705
Epoch: 91 | Iteration number: [160/393] 40% | Training loss: 0.6941025964915752
Epoch: 91 | Iteration number: [170/393] 43% | Training loss: 0.6938270758180057
Epoch: 91 | Iteration number: [180/393] 45% | Training loss: 0.6936403989791871
Epoch: 91 | Iteration number: [190/393] 48% | Training loss: 0.6934110434431778
Epoch: 91 | Iteration number: [200/393] 50% | Training loss: 0.6932097968459129
Epoch: 91 | Iteration number: [210/393] 53% | Training loss: 0.6930100758870442
Epoch: 91 | Iteration number: [220/393] 55% | Training loss: 0.6929350479082628
Epoch: 91 | Iteration number: [230/393] 58% | Training loss: 0.6927864600782809
Epoch: 91 | Iteration number: [240/393] 61% | Training loss: 0.6927314105133215
Epoch: 91 | Iteration number: [250/393] 63% | Training loss: 0.6926261136531829
Epoch: 91 | Iteration number: [260/393] 66% | Training loss: 0.6925795965469801
Epoch: 91 | Iteration number: [270/393] 68% | Training loss: 0.692516812130257
Epoch: 91 | Iteration number: [280/393] 71% | Training loss: 0.6924135529569218
Epoch: 91 | Iteration number: [290/393] 73% | Training loss: 0.6923034869391342
Epoch: 91 | Iteration number: [300/393] 76% | Training loss: 0.6922562172015508
Epoch: 91 | Iteration number: [310/393] 78% | Training loss: 0.692168382675417
Epoch: 91 | Iteration number: [320/393] 81% | Training loss: 0.6921454781666398
Epoch: 91 | Iteration number: [330/393] 83% | Training loss: 0.6920928458372752
Epoch: 91 | Iteration number: [340/393] 86% | Training loss: 0.6920683757347219
Epoch: 91 | Iteration number: [350/393] 89% | Training loss: 0.691989974124091
Epoch: 91 | Iteration number: [360/393] 91% | Training loss: 0.6919616881344054
Epoch: 91 | Iteration number: [370/393] 94% | Training loss: 0.6918799799841804
Epoch: 91 | Iteration number: [380/393] 96% | Training loss: 0.6918132731789037
Epoch: 91 | Iteration number: [390/393] 99% | Training loss: 0.6917798785062936

 End of epoch: 91 | Train Loss: 0.6900158403180634 | Training Time: 66 

 End of epoch: 91 | Eval Loss: 0.6905364929413309 | Evaluating Time: 16 
Epoch: 92 | Iteration number: [10/393] 2% | Training loss: 0.7580447912216186
Epoch: 92 | Iteration number: [20/393] 5% | Training loss: 0.7247615963220596
Epoch: 92 | Iteration number: [30/393] 7% | Training loss: 0.7126111805438995
Epoch: 92 | Iteration number: [40/393] 10% | Training loss: 0.7070868030190468
Epoch: 92 | Iteration number: [50/393] 12% | Training loss: 0.70354936003685
Epoch: 92 | Iteration number: [60/393] 15% | Training loss: 0.7012813011805217
Epoch: 92 | Iteration number: [70/393] 17% | Training loss: 0.6997680945055825
Epoch: 92 | Iteration number: [80/393] 20% | Training loss: 0.6985367514193058
Epoch: 92 | Iteration number: [90/393] 22% | Training loss: 0.697692792945438
Epoch: 92 | Iteration number: [100/393] 25% | Training loss: 0.6969064426422119
Epoch: 92 | Iteration number: [110/393] 27% | Training loss: 0.6963875689289787
Epoch: 92 | Iteration number: [120/393] 30% | Training loss: 0.6959349125623703
Epoch: 92 | Iteration number: [130/393] 33% | Training loss: 0.6955324672735654
Epoch: 92 | Iteration number: [140/393] 35% | Training loss: 0.6951383416141782
Epoch: 92 | Iteration number: [150/393] 38% | Training loss: 0.6948120212554931
Epoch: 92 | Iteration number: [160/393] 40% | Training loss: 0.6944812871515751
Epoch: 92 | Iteration number: [170/393] 43% | Training loss: 0.69421908084084
Epoch: 92 | Iteration number: [180/393] 45% | Training loss: 0.6939405169751909
Epoch: 92 | Iteration number: [190/393] 48% | Training loss: 0.693805203939739
Epoch: 92 | Iteration number: [200/393] 50% | Training loss: 0.6936263281106949
Epoch: 92 | Iteration number: [210/393] 53% | Training loss: 0.6934073209762573
Epoch: 92 | Iteration number: [220/393] 55% | Training loss: 0.6932644491845911
Epoch: 92 | Iteration number: [230/393] 58% | Training loss: 0.6931347909181015
Epoch: 92 | Iteration number: [240/393] 61% | Training loss: 0.6929752518733342
Epoch: 92 | Iteration number: [250/393] 63% | Training loss: 0.6928452377319336
Epoch: 92 | Iteration number: [260/393] 66% | Training loss: 0.6927412679562202
Epoch: 92 | Iteration number: [270/393] 68% | Training loss: 0.6926109150603965
Epoch: 92 | Iteration number: [280/393] 71% | Training loss: 0.6925422628011022
Epoch: 92 | Iteration number: [290/393] 73% | Training loss: 0.6924775045493553
Epoch: 92 | Iteration number: [300/393] 76% | Training loss: 0.6923716499408086
Epoch: 92 | Iteration number: [310/393] 78% | Training loss: 0.6922928310209705
Epoch: 92 | Iteration number: [320/393] 81% | Training loss: 0.6922359490767122
Epoch: 92 | Iteration number: [330/393] 83% | Training loss: 0.6921634534994762
Epoch: 92 | Iteration number: [340/393] 86% | Training loss: 0.692091155928724
Epoch: 92 | Iteration number: [350/393] 89% | Training loss: 0.6920715030602046
Epoch: 92 | Iteration number: [360/393] 91% | Training loss: 0.6919905905922253
Epoch: 92 | Iteration number: [370/393] 94% | Training loss: 0.6919053931494017
Epoch: 92 | Iteration number: [380/393] 96% | Training loss: 0.6918682675612601
Epoch: 92 | Iteration number: [390/393] 99% | Training loss: 0.691790912548701

 End of epoch: 92 | Train Loss: 0.6900119899793435 | Training Time: 66 

 End of epoch: 92 | Eval Loss: 0.6905213107868117 | Evaluating Time: 17 
Epoch: 93 | Iteration number: [10/393] 2% | Training loss: 0.7587954521179199
Epoch: 93 | Iteration number: [20/393] 5% | Training loss: 0.7245629817247391
Epoch: 93 | Iteration number: [30/393] 7% | Training loss: 0.713158384958903
Epoch: 93 | Iteration number: [40/393] 10% | Training loss: 0.7074124872684479
Epoch: 93 | Iteration number: [50/393] 12% | Training loss: 0.7041060483455658
Epoch: 93 | Iteration number: [60/393] 15% | Training loss: 0.7018446256717046
Epoch: 93 | Iteration number: [70/393] 17% | Training loss: 0.7002300432750157
Epoch: 93 | Iteration number: [80/393] 20% | Training loss: 0.6988856710493565
Epoch: 93 | Iteration number: [90/393] 22% | Training loss: 0.697924843761656
Epoch: 93 | Iteration number: [100/393] 25% | Training loss: 0.6971550524234772
Epoch: 93 | Iteration number: [110/393] 27% | Training loss: 0.6965055324814536
Epoch: 93 | Iteration number: [120/393] 30% | Training loss: 0.6959015121062596
Epoch: 93 | Iteration number: [130/393] 33% | Training loss: 0.6954571361725147
Epoch: 93 | Iteration number: [140/393] 35% | Training loss: 0.6950847732169287
Epoch: 93 | Iteration number: [150/393] 38% | Training loss: 0.6947288616498312
Epoch: 93 | Iteration number: [160/393] 40% | Training loss: 0.6944450553506613
Epoch: 93 | Iteration number: [170/393] 43% | Training loss: 0.6942265261622036
Epoch: 93 | Iteration number: [180/393] 45% | Training loss: 0.6939494616455502
Epoch: 93 | Iteration number: [190/393] 48% | Training loss: 0.693735952440061
Epoch: 93 | Iteration number: [200/393] 50% | Training loss: 0.6935733941197395
Epoch: 93 | Iteration number: [210/393] 53% | Training loss: 0.6933838375977107
Epoch: 93 | Iteration number: [220/393] 55% | Training loss: 0.693220499699766
Epoch: 93 | Iteration number: [230/393] 58% | Training loss: 0.6930867534616719
Epoch: 93 | Iteration number: [240/393] 61% | Training loss: 0.6929636158049106
Epoch: 93 | Iteration number: [250/393] 63% | Training loss: 0.6928190863132477
Epoch: 93 | Iteration number: [260/393] 66% | Training loss: 0.6927160455630376
Epoch: 93 | Iteration number: [270/393] 68% | Training loss: 0.6926363735287278
Epoch: 93 | Iteration number: [280/393] 71% | Training loss: 0.6925052355442728
Epoch: 93 | Iteration number: [290/393] 73% | Training loss: 0.692396602548402
Epoch: 93 | Iteration number: [300/393] 76% | Training loss: 0.6923330169916153
Epoch: 93 | Iteration number: [310/393] 78% | Training loss: 0.6922398609499778
Epoch: 93 | Iteration number: [320/393] 81% | Training loss: 0.6922019414603711
Epoch: 93 | Iteration number: [330/393] 83% | Training loss: 0.6921530196160981
Epoch: 93 | Iteration number: [340/393] 86% | Training loss: 0.6920977049014148
Epoch: 93 | Iteration number: [350/393] 89% | Training loss: 0.6919963300228119
Epoch: 93 | Iteration number: [360/393] 91% | Training loss: 0.6919338929984304
Epoch: 93 | Iteration number: [370/393] 94% | Training loss: 0.6918903366939442
Epoch: 93 | Iteration number: [380/393] 96% | Training loss: 0.6918266241487704
Epoch: 93 | Iteration number: [390/393] 99% | Training loss: 0.6918162014239874

 End of epoch: 93 | Train Loss: 0.6900433383825171 | Training Time: 66 

 End of epoch: 93 | Eval Loss: 0.6904581104006086 | Evaluating Time: 16 
Epoch: 94 | Iteration number: [10/393] 2% | Training loss: 0.7591927230358124
Epoch: 94 | Iteration number: [20/393] 5% | Training loss: 0.7247468441724777
Epoch: 94 | Iteration number: [30/393] 7% | Training loss: 0.7135698159535726
Epoch: 94 | Iteration number: [40/393] 10% | Training loss: 0.7079578191041946
Epoch: 94 | Iteration number: [50/393] 12% | Training loss: 0.7043693923950195
Epoch: 94 | Iteration number: [60/393] 15% | Training loss: 0.7018400986989339
Epoch: 94 | Iteration number: [70/393] 17% | Training loss: 0.7002295068332127
Epoch: 94 | Iteration number: [80/393] 20% | Training loss: 0.698838634043932
Epoch: 94 | Iteration number: [90/393] 22% | Training loss: 0.6979057980908288
Epoch: 94 | Iteration number: [100/393] 25% | Training loss: 0.6970898348093033
Epoch: 94 | Iteration number: [110/393] 27% | Training loss: 0.6964941669594158
Epoch: 94 | Iteration number: [120/393] 30% | Training loss: 0.6960839693744977
Epoch: 94 | Iteration number: [130/393] 33% | Training loss: 0.6957349978960478
Epoch: 94 | Iteration number: [140/393] 35% | Training loss: 0.6953154827867235
Epoch: 94 | Iteration number: [150/393] 38% | Training loss: 0.6948760426044465
Epoch: 94 | Iteration number: [160/393] 40% | Training loss: 0.6944623280316591
Epoch: 94 | Iteration number: [170/393] 43% | Training loss: 0.6942092920050902
Epoch: 94 | Iteration number: [180/393] 45% | Training loss: 0.6939603447914123
Epoch: 94 | Iteration number: [190/393] 48% | Training loss: 0.6937325581123954
Epoch: 94 | Iteration number: [200/393] 50% | Training loss: 0.6935441747307778
Epoch: 94 | Iteration number: [210/393] 53% | Training loss: 0.693367957785016
Epoch: 94 | Iteration number: [220/393] 55% | Training loss: 0.6931476362726905
Epoch: 94 | Iteration number: [230/393] 58% | Training loss: 0.6929846317871757
Epoch: 94 | Iteration number: [240/393] 61% | Training loss: 0.692868493994077
Epoch: 94 | Iteration number: [250/393] 63% | Training loss: 0.6927855269908905
Epoch: 94 | Iteration number: [260/393] 66% | Training loss: 0.6926885852446922
Epoch: 94 | Iteration number: [270/393] 68% | Training loss: 0.6926120009687212
Epoch: 94 | Iteration number: [280/393] 71% | Training loss: 0.6924798912235669
Epoch: 94 | Iteration number: [290/393] 73% | Training loss: 0.6924118596931984
Epoch: 94 | Iteration number: [300/393] 76% | Training loss: 0.6923046729962031
Epoch: 94 | Iteration number: [310/393] 78% | Training loss: 0.6922492619483701
Epoch: 94 | Iteration number: [320/393] 81% | Training loss: 0.6921710960566998
Epoch: 94 | Iteration number: [330/393] 83% | Training loss: 0.6920975376259196
Epoch: 94 | Iteration number: [340/393] 86% | Training loss: 0.6920497669893153
Epoch: 94 | Iteration number: [350/393] 89% | Training loss: 0.691990088054112
Epoch: 94 | Iteration number: [360/393] 91% | Training loss: 0.6919034128387769
Epoch: 94 | Iteration number: [370/393] 94% | Training loss: 0.6918606381158571
Epoch: 94 | Iteration number: [380/393] 96% | Training loss: 0.6917910182162335
Epoch: 94 | Iteration number: [390/393] 99% | Training loss: 0.6917516517333495

 End of epoch: 94 | Train Loss: 0.6899869331270078 | Training Time: 66 

 End of epoch: 94 | Eval Loss: 0.6904791520566357 | Evaluating Time: 16 
Epoch: 95 | Iteration number: [10/393] 2% | Training loss: 0.7592293798923493
Epoch: 95 | Iteration number: [20/393] 5% | Training loss: 0.7246395081281662
Epoch: 95 | Iteration number: [30/393] 7% | Training loss: 0.7129823724428813
Epoch: 95 | Iteration number: [40/393] 10% | Training loss: 0.7072795465588569
Epoch: 95 | Iteration number: [50/393] 12% | Training loss: 0.7039197719097138
Epoch: 95 | Iteration number: [60/393] 15% | Training loss: 0.7015590757131577
Epoch: 95 | Iteration number: [70/393] 17% | Training loss: 0.6999543930803026
Epoch: 95 | Iteration number: [80/393] 20% | Training loss: 0.6986803852021695
Epoch: 95 | Iteration number: [90/393] 22% | Training loss: 0.6977243264516194
Epoch: 95 | Iteration number: [100/393] 25% | Training loss: 0.6969569313526154
Epoch: 95 | Iteration number: [110/393] 27% | Training loss: 0.6963752724907615
Epoch: 95 | Iteration number: [120/393] 30% | Training loss: 0.695888773103555
Epoch: 95 | Iteration number: [130/393] 33% | Training loss: 0.6954290321240059
Epoch: 95 | Iteration number: [140/393] 35% | Training loss: 0.6949845688683646
Epoch: 95 | Iteration number: [150/393] 38% | Training loss: 0.6946356741587321
Epoch: 95 | Iteration number: [160/393] 40% | Training loss: 0.6943326130509376
Epoch: 95 | Iteration number: [170/393] 43% | Training loss: 0.6940383083680097
Epoch: 95 | Iteration number: [180/393] 45% | Training loss: 0.6938321361939113
Epoch: 95 | Iteration number: [190/393] 48% | Training loss: 0.6936711647008594
Epoch: 95 | Iteration number: [200/393] 50% | Training loss: 0.6934958323836327
Epoch: 95 | Iteration number: [210/393] 53% | Training loss: 0.6933761321362995
Epoch: 95 | Iteration number: [220/393] 55% | Training loss: 0.6932535101066936
Epoch: 95 | Iteration number: [230/393] 58% | Training loss: 0.6930989522001018
Epoch: 95 | Iteration number: [240/393] 61% | Training loss: 0.6929683983325958
Epoch: 95 | Iteration number: [250/393] 63% | Training loss: 0.6928927199840546
Epoch: 95 | Iteration number: [260/393] 66% | Training loss: 0.6927467254491952
Epoch: 95 | Iteration number: [270/393] 68% | Training loss: 0.6926746500862969
Epoch: 95 | Iteration number: [280/393] 71% | Training loss: 0.6925951570272446
Epoch: 95 | Iteration number: [290/393] 73% | Training loss: 0.692512570989543
Epoch: 95 | Iteration number: [300/393] 76% | Training loss: 0.6923962863286336
Epoch: 95 | Iteration number: [310/393] 78% | Training loss: 0.6923226048869472
Epoch: 95 | Iteration number: [320/393] 81% | Training loss: 0.6921980151906609
Epoch: 95 | Iteration number: [330/393] 83% | Training loss: 0.6921036662477436
Epoch: 95 | Iteration number: [340/393] 86% | Training loss: 0.6920080684563693
Epoch: 95 | Iteration number: [350/393] 89% | Training loss: 0.691983905008861
Epoch: 95 | Iteration number: [360/393] 91% | Training loss: 0.6919263917538855
Epoch: 95 | Iteration number: [370/393] 94% | Training loss: 0.6918649130576365
Epoch: 95 | Iteration number: [380/393] 96% | Training loss: 0.6917762477146951
Epoch: 95 | Iteration number: [390/393] 99% | Training loss: 0.691731041822678

 End of epoch: 95 | Train Loss: 0.6899655396095062 | Training Time: 65 

 End of epoch: 95 | Eval Loss: 0.6904529406099903 | Evaluating Time: 17 
Epoch: 96 | Iteration number: [10/393] 2% | Training loss: 0.7588396608829499
Epoch: 96 | Iteration number: [20/393] 5% | Training loss: 0.7246901214122772
Epoch: 96 | Iteration number: [30/393] 7% | Training loss: 0.7132324020067851
Epoch: 96 | Iteration number: [40/393] 10% | Training loss: 0.7073850944638252
Epoch: 96 | Iteration number: [50/393] 12% | Training loss: 0.7041581428050995
Epoch: 96 | Iteration number: [60/393] 15% | Training loss: 0.7017526964346568
Epoch: 96 | Iteration number: [70/393] 17% | Training loss: 0.7000467266355243
Epoch: 96 | Iteration number: [80/393] 20% | Training loss: 0.6988325901329517
Epoch: 96 | Iteration number: [90/393] 22% | Training loss: 0.6978357434272766
Epoch: 96 | Iteration number: [100/393] 25% | Training loss: 0.6971073257923126
Epoch: 96 | Iteration number: [110/393] 27% | Training loss: 0.6965048638257113
Epoch: 96 | Iteration number: [120/393] 30% | Training loss: 0.6960230986277263
Epoch: 96 | Iteration number: [130/393] 33% | Training loss: 0.6955865681171417
Epoch: 96 | Iteration number: [140/393] 35% | Training loss: 0.6950916196618762
Epoch: 96 | Iteration number: [150/393] 38% | Training loss: 0.6947663235664367
Epoch: 96 | Iteration number: [160/393] 40% | Training loss: 0.6945238739252091
Epoch: 96 | Iteration number: [170/393] 43% | Training loss: 0.6942941556958592
Epoch: 96 | Iteration number: [180/393] 45% | Training loss: 0.694052043888304
Epoch: 96 | Iteration number: [190/393] 48% | Training loss: 0.6938590206597981
Epoch: 96 | Iteration number: [200/393] 50% | Training loss: 0.6936629348993302
Epoch: 96 | Iteration number: [210/393] 53% | Training loss: 0.6934840327217465
Epoch: 96 | Iteration number: [220/393] 55% | Training loss: 0.6933580853722312
Epoch: 96 | Iteration number: [230/393] 58% | Training loss: 0.6931988283343937
Epoch: 96 | Iteration number: [240/393] 61% | Training loss: 0.6930614237984022
Epoch: 96 | Iteration number: [250/393] 63% | Training loss: 0.6928826420307159
Epoch: 96 | Iteration number: [260/393] 66% | Training loss: 0.6927966500704105
Epoch: 96 | Iteration number: [270/393] 68% | Training loss: 0.6927070483013436
Epoch: 96 | Iteration number: [280/393] 71% | Training loss: 0.6926522727523531
Epoch: 96 | Iteration number: [290/393] 73% | Training loss: 0.692551097993193
Epoch: 96 | Iteration number: [300/393] 76% | Training loss: 0.6924564915895463
Epoch: 96 | Iteration number: [310/393] 78% | Training loss: 0.6923882369072206
Epoch: 96 | Iteration number: [320/393] 81% | Training loss: 0.692250027321279
Epoch: 96 | Iteration number: [330/393] 83% | Training loss: 0.6921712391304248
Epoch: 96 | Iteration number: [340/393] 86% | Training loss: 0.6920900493860245
Epoch: 96 | Iteration number: [350/393] 89% | Training loss: 0.6920099585396903
Epoch: 96 | Iteration number: [360/393] 91% | Training loss: 0.6919534769323137
Epoch: 96 | Iteration number: [370/393] 94% | Training loss: 0.6918814293436102
Epoch: 96 | Iteration number: [380/393] 96% | Training loss: 0.6918126928178887
Epoch: 96 | Iteration number: [390/393] 99% | Training loss: 0.6917813612864567

 End of epoch: 96 | Train Loss: 0.6900057163250659 | Training Time: 66 

 End of epoch: 96 | Eval Loss: 0.6904848084157827 | Evaluating Time: 16 
Epoch: 97 | Iteration number: [10/393] 2% | Training loss: 0.7587012410163879
Epoch: 97 | Iteration number: [20/393] 5% | Training loss: 0.7241136312484742
Epoch: 97 | Iteration number: [30/393] 7% | Training loss: 0.7128564874331157
Epoch: 97 | Iteration number: [40/393] 10% | Training loss: 0.707089152932167
Epoch: 97 | Iteration number: [50/393] 12% | Training loss: 0.7035426151752472
Epoch: 97 | Iteration number: [60/393] 15% | Training loss: 0.7011959532896678
Epoch: 97 | Iteration number: [70/393] 17% | Training loss: 0.6994795799255371
Epoch: 97 | Iteration number: [80/393] 20% | Training loss: 0.6982714869081974
Epoch: 97 | Iteration number: [90/393] 22% | Training loss: 0.6973432580629985
Epoch: 97 | Iteration number: [100/393] 25% | Training loss: 0.6964752507209778
Epoch: 97 | Iteration number: [110/393] 27% | Training loss: 0.6958823030645197
Epoch: 97 | Iteration number: [120/393] 30% | Training loss: 0.6954179858167966
Epoch: 97 | Iteration number: [130/393] 33% | Training loss: 0.694921167080219
Epoch: 97 | Iteration number: [140/393] 35% | Training loss: 0.6945273356778281
Epoch: 97 | Iteration number: [150/393] 38% | Training loss: 0.6942565051714579
Epoch: 97 | Iteration number: [160/393] 40% | Training loss: 0.6939349506050349
Epoch: 97 | Iteration number: [170/393] 43% | Training loss: 0.6938041809727163
Epoch: 97 | Iteration number: [180/393] 45% | Training loss: 0.693582703338729
Epoch: 97 | Iteration number: [190/393] 48% | Training loss: 0.693394336574956
Epoch: 97 | Iteration number: [200/393] 50% | Training loss: 0.6931855174899101
Epoch: 97 | Iteration number: [210/393] 53% | Training loss: 0.693029282774244
Epoch: 97 | Iteration number: [220/393] 55% | Training loss: 0.6929251429709521
Epoch: 97 | Iteration number: [230/393] 58% | Training loss: 0.6927935532901598
Epoch: 97 | Iteration number: [240/393] 61% | Training loss: 0.692687863856554
Epoch: 97 | Iteration number: [250/393] 63% | Training loss: 0.6926308488845825
Epoch: 97 | Iteration number: [260/393] 66% | Training loss: 0.6925499464456851
Epoch: 97 | Iteration number: [270/393] 68% | Training loss: 0.6924321870009105
Epoch: 97 | Iteration number: [280/393] 71% | Training loss: 0.6923730079616819
Epoch: 97 | Iteration number: [290/393] 73% | Training loss: 0.6922982427580603
Epoch: 97 | Iteration number: [300/393] 76% | Training loss: 0.6922411626577377
Epoch: 97 | Iteration number: [310/393] 78% | Training loss: 0.6921902639250601
Epoch: 97 | Iteration number: [320/393] 81% | Training loss: 0.692128374427557
Epoch: 97 | Iteration number: [330/393] 83% | Training loss: 0.692049342213255
Epoch: 97 | Iteration number: [340/393] 86% | Training loss: 0.691942212862127
Epoch: 97 | Iteration number: [350/393] 89% | Training loss: 0.6918888720444271
Epoch: 97 | Iteration number: [360/393] 91% | Training loss: 0.6918439093563292
Epoch: 97 | Iteration number: [370/393] 94% | Training loss: 0.6918103132698987
Epoch: 97 | Iteration number: [380/393] 96% | Training loss: 0.691760476011979
Epoch: 97 | Iteration number: [390/393] 99% | Training loss: 0.6917382649886302

 End of epoch: 97 | Train Loss: 0.6899783617364238 | Training Time: 66 

 End of epoch: 97 | Eval Loss: 0.690458360983401 | Evaluating Time: 16 
Epoch: 98 | Iteration number: [10/393] 2% | Training loss: 0.7588445365428924
Epoch: 98 | Iteration number: [20/393] 5% | Training loss: 0.7238624900579452
Epoch: 98 | Iteration number: [30/393] 7% | Training loss: 0.7127558588981628
Epoch: 98 | Iteration number: [40/393] 10% | Training loss: 0.7073732823133468
Epoch: 98 | Iteration number: [50/393] 12% | Training loss: 0.7038229990005493
Epoch: 98 | Iteration number: [60/393] 15% | Training loss: 0.7017015159130097
Epoch: 98 | Iteration number: [70/393] 17% | Training loss: 0.7001026664461408
Epoch: 98 | Iteration number: [80/393] 20% | Training loss: 0.6989928774535656
Epoch: 98 | Iteration number: [90/393] 22% | Training loss: 0.6981255802843306
Epoch: 98 | Iteration number: [100/393] 25% | Training loss: 0.6972488278150558
Epoch: 98 | Iteration number: [110/393] 27% | Training loss: 0.6965471386909485
Epoch: 98 | Iteration number: [120/393] 30% | Training loss: 0.6959862714012464
Epoch: 98 | Iteration number: [130/393] 33% | Training loss: 0.6954797070759994
Epoch: 98 | Iteration number: [140/393] 35% | Training loss: 0.6951422780752182
Epoch: 98 | Iteration number: [150/393] 38% | Training loss: 0.6946993446350098
Epoch: 98 | Iteration number: [160/393] 40% | Training loss: 0.6944763220846653
Epoch: 98 | Iteration number: [170/393] 43% | Training loss: 0.6941671574816984
Epoch: 98 | Iteration number: [180/393] 45% | Training loss: 0.6939362939861086
Epoch: 98 | Iteration number: [190/393] 48% | Training loss: 0.6937570135844381
Epoch: 98 | Iteration number: [200/393] 50% | Training loss: 0.6935405707359314
Epoch: 98 | Iteration number: [210/393] 53% | Training loss: 0.6933907162575494
Epoch: 98 | Iteration number: [220/393] 55% | Training loss: 0.6931919374249198
Epoch: 98 | Iteration number: [230/393] 58% | Training loss: 0.693052174474882
Epoch: 98 | Iteration number: [240/393] 61% | Training loss: 0.6928551740944385
Epoch: 98 | Iteration number: [250/393] 63% | Training loss: 0.6927486219406128
Epoch: 98 | Iteration number: [260/393] 66% | Training loss: 0.692615491610307
Epoch: 98 | Iteration number: [270/393] 68% | Training loss: 0.692513397887901
Epoch: 98 | Iteration number: [280/393] 71% | Training loss: 0.6924160704016685
Epoch: 98 | Iteration number: [290/393] 73% | Training loss: 0.6923704607733365
Epoch: 98 | Iteration number: [300/393] 76% | Training loss: 0.6922876723607381
Epoch: 98 | Iteration number: [310/393] 78% | Training loss: 0.6922109384690561
Epoch: 98 | Iteration number: [320/393] 81% | Training loss: 0.6921627523377538
Epoch: 98 | Iteration number: [330/393] 83% | Training loss: 0.6921211401621501
Epoch: 98 | Iteration number: [340/393] 86% | Training loss: 0.6920490955605226
Epoch: 98 | Iteration number: [350/393] 89% | Training loss: 0.6919900144849505
Epoch: 98 | Iteration number: [360/393] 91% | Training loss: 0.6919516767064731
Epoch: 98 | Iteration number: [370/393] 94% | Training loss: 0.6918758701633763
Epoch: 98 | Iteration number: [380/393] 96% | Training loss: 0.6918123187203157
Epoch: 98 | Iteration number: [390/393] 99% | Training loss: 0.6917915338124985

 End of epoch: 98 | Train Loss: 0.6900228219481218 | Training Time: 66 

 End of epoch: 98 | Eval Loss: 0.6905294559439834 | Evaluating Time: 17 
Epoch: 99 | Iteration number: [10/393] 2% | Training loss: 0.7602004468441009
Epoch: 99 | Iteration number: [20/393] 5% | Training loss: 0.7256629943847657
Epoch: 99 | Iteration number: [30/393] 7% | Training loss: 0.7139118373394012
Epoch: 99 | Iteration number: [40/393] 10% | Training loss: 0.708218888938427
Epoch: 99 | Iteration number: [50/393] 12% | Training loss: 0.7045517158508301
Epoch: 99 | Iteration number: [60/393] 15% | Training loss: 0.702221683661143
Epoch: 99 | Iteration number: [70/393] 17% | Training loss: 0.700177127122879
Epoch: 99 | Iteration number: [80/393] 20% | Training loss: 0.6989841654896736
Epoch: 99 | Iteration number: [90/393] 22% | Training loss: 0.6979365964730581
Epoch: 99 | Iteration number: [100/393] 25% | Training loss: 0.6970095658302307
Epoch: 99 | Iteration number: [110/393] 27% | Training loss: 0.696281253749674
Epoch: 99 | Iteration number: [120/393] 30% | Training loss: 0.6957555780808131
Epoch: 99 | Iteration number: [130/393] 33% | Training loss: 0.6953176388373742
Epoch: 99 | Iteration number: [140/393] 35% | Training loss: 0.6950398798499788
Epoch: 99 | Iteration number: [150/393] 38% | Training loss: 0.6946378000577291
Epoch: 99 | Iteration number: [160/393] 40% | Training loss: 0.6943319447338581
Epoch: 99 | Iteration number: [170/393] 43% | Training loss: 0.6940999188843895
Epoch: 99 | Iteration number: [180/393] 45% | Training loss: 0.6938695132732391
Epoch: 99 | Iteration number: [190/393] 48% | Training loss: 0.6936002759557022
Epoch: 99 | Iteration number: [200/393] 50% | Training loss: 0.6933449894189835
Epoch: 99 | Iteration number: [210/393] 53% | Training loss: 0.6931902570383889
Epoch: 99 | Iteration number: [220/393] 55% | Training loss: 0.6930387364192443
Epoch: 99 | Iteration number: [230/393] 58% | Training loss: 0.692880236065906
Epoch: 99 | Iteration number: [240/393] 61% | Training loss: 0.6927254242201646
Epoch: 99 | Iteration number: [250/393] 63% | Training loss: 0.6926393470764161
Epoch: 99 | Iteration number: [260/393] 66% | Training loss: 0.6925529120060113
Epoch: 99 | Iteration number: [270/393] 68% | Training loss: 0.6925066769123077
Epoch: 99 | Iteration number: [280/393] 71% | Training loss: 0.6924065342971257
Epoch: 99 | Iteration number: [290/393] 73% | Training loss: 0.6923239130398323
Epoch: 99 | Iteration number: [300/393] 76% | Training loss: 0.692261426448822
Epoch: 99 | Iteration number: [310/393] 78% | Training loss: 0.6922364475265625
Epoch: 99 | Iteration number: [320/393] 81% | Training loss: 0.6921963902190328
Epoch: 99 | Iteration number: [330/393] 83% | Training loss: 0.692149037845207
Epoch: 99 | Iteration number: [340/393] 86% | Training loss: 0.6920707190738005
Epoch: 99 | Iteration number: [350/393] 89% | Training loss: 0.6920029015200478
Epoch: 99 | Iteration number: [360/393] 91% | Training loss: 0.6919106149011188
Epoch: 99 | Iteration number: [370/393] 94% | Training loss: 0.6918365646053005
Epoch: 99 | Iteration number: [380/393] 96% | Training loss: 0.6917900584245983
Epoch: 99 | Iteration number: [390/393] 99% | Training loss: 0.6917583633691836

 End of epoch: 99 | Train Loss: 0.6899845010148357 | Training Time: 66 

 End of epoch: 99 | Eval Loss: 0.6904303005763462 | Evaluating Time: 16 
Epoch: 100 | Iteration number: [10/393] 2% | Training loss: 0.7581392526626587
Epoch: 100 | Iteration number: [20/393] 5% | Training loss: 0.7242512762546539
Epoch: 100 | Iteration number: [30/393] 7% | Training loss: 0.7125872671604156
Epoch: 100 | Iteration number: [40/393] 10% | Training loss: 0.7069666415452958
Epoch: 100 | Iteration number: [50/393] 12% | Training loss: 0.7033599984645843
Epoch: 100 | Iteration number: [60/393] 15% | Training loss: 0.7012337446212769
Epoch: 100 | Iteration number: [70/393] 17% | Training loss: 0.6997247057301658
Epoch: 100 | Iteration number: [80/393] 20% | Training loss: 0.6984633840620518
Epoch: 100 | Iteration number: [90/393] 22% | Training loss: 0.6974734776549869
Epoch: 100 | Iteration number: [100/393] 25% | Training loss: 0.6967197442054749
Epoch: 100 | Iteration number: [110/393] 27% | Training loss: 0.6961249129338698
Epoch: 100 | Iteration number: [120/393] 30% | Training loss: 0.6955769295493762
Epoch: 100 | Iteration number: [130/393] 33% | Training loss: 0.6952433278927437
Epoch: 100 | Iteration number: [140/393] 35% | Training loss: 0.6948539286851882
Epoch: 100 | Iteration number: [150/393] 38% | Training loss: 0.6945036478837331
Epoch: 100 | Iteration number: [160/393] 40% | Training loss: 0.6942728262394666
Epoch: 100 | Iteration number: [170/393] 43% | Training loss: 0.6939811408519745
Epoch: 100 | Iteration number: [180/393] 45% | Training loss: 0.6938320563899146
Epoch: 100 | Iteration number: [190/393] 48% | Training loss: 0.6936413084205828
Epoch: 100 | Iteration number: [200/393] 50% | Training loss: 0.6934307888150215
Epoch: 100 | Iteration number: [210/393] 53% | Training loss: 0.693267381758917
Epoch: 100 | Iteration number: [220/393] 55% | Training loss: 0.6930486735972491
Epoch: 100 | Iteration number: [230/393] 58% | Training loss: 0.6929320545300194
Epoch: 100 | Iteration number: [240/393] 61% | Training loss: 0.6928348571062088
Epoch: 100 | Iteration number: [250/393] 63% | Training loss: 0.6926728634834289
Epoch: 100 | Iteration number: [260/393] 66% | Training loss: 0.692558825474519
Epoch: 100 | Iteration number: [270/393] 68% | Training loss: 0.6924486597379048
Epoch: 100 | Iteration number: [280/393] 71% | Training loss: 0.6923589861818722
Epoch: 100 | Iteration number: [290/393] 73% | Training loss: 0.6923298636387134
Epoch: 100 | Iteration number: [300/393] 76% | Training loss: 0.69223379890124
Epoch: 100 | Iteration number: [310/393] 78% | Training loss: 0.6921589701406418
Epoch: 100 | Iteration number: [320/393] 81% | Training loss: 0.6921042382717133
Epoch: 100 | Iteration number: [330/393] 83% | Training loss: 0.6920424362023672
Epoch: 100 | Iteration number: [340/393] 86% | Training loss: 0.6919746831935994
Epoch: 100 | Iteration number: [350/393] 89% | Training loss: 0.6919371778624398
Epoch: 100 | Iteration number: [360/393] 91% | Training loss: 0.6918847310874198
Epoch: 100 | Iteration number: [370/393] 94% | Training loss: 0.6918535247042372
Epoch: 100 | Iteration number: [380/393] 96% | Training loss: 0.691807518036742
Epoch: 100 | Iteration number: [390/393] 99% | Training loss: 0.6917398703403962

 End of epoch: 100 | Train Loss: 0.6899675537308361 | Training Time: 65 

 End of epoch: 100 | Eval Loss: 0.690406722681863 | Evaluating Time: 16 

 End of Test | Dice Loss: 0.8785761804878711 | Binary Cross Entropy With Logits Loss: 0.6900006854534149 
