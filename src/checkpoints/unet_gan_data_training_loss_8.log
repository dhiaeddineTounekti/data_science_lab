Epoch: 1 | Iteration number: [10/565] 1% | Training loss: 0.7655538201332093
Epoch: 1 | Iteration number: [20/565] 3% | Training loss: 0.7305442422628403
Epoch: 1 | Iteration number: [30/565] 5% | Training loss: 0.7188283105691274
Epoch: 1 | Iteration number: [40/565] 7% | Training loss: 0.7129154786467552
Epoch: 1 | Iteration number: [50/565] 8% | Training loss: 0.7093598532676697
Epoch: 1 | Iteration number: [60/565] 10% | Training loss: 0.7069136291742325
Epoch: 1 | Iteration number: [70/565] 12% | Training loss: 0.7052267815385546
Epoch: 1 | Iteration number: [80/565] 14% | Training loss: 0.7039119556546212
Epoch: 1 | Iteration number: [90/565] 15% | Training loss: 0.7029271980126699
Epoch: 1 | Iteration number: [100/565] 17% | Training loss: 0.7021205168962479
Epoch: 1 | Iteration number: [110/565] 19% | Training loss: 0.7014585717157884
Epoch: 1 | Iteration number: [120/565] 21% | Training loss: 0.7008584101994833
Epoch: 1 | Iteration number: [130/565] 23% | Training loss: 0.700344318151474
Epoch: 1 | Iteration number: [140/565] 24% | Training loss: 0.6999343063150133
Epoch: 1 | Iteration number: [150/565] 26% | Training loss: 0.6995540157953898
Epoch: 1 | Iteration number: [160/565] 28% | Training loss: 0.6992326378822327
Epoch: 1 | Iteration number: [170/565] 30% | Training loss: 0.6989424554740682
Epoch: 1 | Iteration number: [180/565] 31% | Training loss: 0.6986805650922987
Epoch: 1 | Iteration number: [190/565] 33% | Training loss: 0.6984353504682842
Epoch: 1 | Iteration number: [200/565] 35% | Training loss: 0.6981987285614014
Epoch: 1 | Iteration number: [210/565] 37% | Training loss: 0.6980034223624638
Epoch: 1 | Iteration number: [220/565] 38% | Training loss: 0.6978015796704726
Epoch: 1 | Iteration number: [230/565] 40% | Training loss: 0.6976207707239234
Epoch: 1 | Iteration number: [240/565] 42% | Training loss: 0.6974301651120186
Epoch: 1 | Iteration number: [250/565] 44% | Training loss: 0.6972769346237183
Epoch: 1 | Iteration number: [260/565] 46% | Training loss: 0.6971288172098307
Epoch: 1 | Iteration number: [270/565] 47% | Training loss: 0.6969963329809683
Epoch: 1 | Iteration number: [280/565] 49% | Training loss: 0.6968654432467052
Epoch: 1 | Iteration number: [290/565] 51% | Training loss: 0.6967490687452513
Epoch: 1 | Iteration number: [300/565] 53% | Training loss: 0.6966304894288381
Epoch: 1 | Iteration number: [310/565] 54% | Training loss: 0.6965257225498076
Epoch: 1 | Iteration number: [320/565] 56% | Training loss: 0.6964148271828889
Epoch: 1 | Iteration number: [330/565] 58% | Training loss: 0.6963107295108564
Epoch: 1 | Iteration number: [340/565] 60% | Training loss: 0.6962132476708468
Epoch: 1 | Iteration number: [350/565] 61% | Training loss: 0.6961172160080501
Epoch: 1 | Iteration number: [360/565] 63% | Training loss: 0.6960250301493539
Epoch: 1 | Iteration number: [370/565] 65% | Training loss: 0.6959211686173001
Epoch: 1 | Iteration number: [380/565] 67% | Training loss: 0.6958240349041788
Epoch: 1 | Iteration number: [390/565] 69% | Training loss: 0.695731727587871
Epoch: 1 | Iteration number: [400/565] 70% | Training loss: 0.6956466580927372
Epoch: 1 | Iteration number: [410/565] 72% | Training loss: 0.6955662004831361
Epoch: 1 | Iteration number: [420/565] 74% | Training loss: 0.6954944352308909
Epoch: 1 | Iteration number: [430/565] 76% | Training loss: 0.6954273125459981
Epoch: 1 | Iteration number: [440/565] 77% | Training loss: 0.6953627861358903
Epoch: 1 | Iteration number: [450/565] 79% | Training loss: 0.6952957692411211
Epoch: 1 | Iteration number: [460/565] 81% | Training loss: 0.6952288781819136
Epoch: 1 | Iteration number: [470/565] 83% | Training loss: 0.6951709766337212
Epoch: 1 | Iteration number: [480/565] 84% | Training loss: 0.6951069404681524
Epoch: 1 | Iteration number: [490/565] 86% | Training loss: 0.695052236926799
Epoch: 1 | Iteration number: [500/565] 88% | Training loss: 0.6949861491918564
Epoch: 1 | Iteration number: [510/565] 90% | Training loss: 0.6949308846511093
Epoch: 1 | Iteration number: [520/565] 92% | Training loss: 0.6948707683728291
Epoch: 1 | Iteration number: [530/565] 93% | Training loss: 0.6948177297160311
Epoch: 1 | Iteration number: [540/565] 95% | Training loss: 0.6947521239519119
Epoch: 1 | Iteration number: [550/565] 97% | Training loss: 0.6946995584531264
Epoch: 1 | Iteration number: [560/565] 99% | Training loss: 0.6946456052362919

 End of epoch: 1 | Train Loss: 0.6933946006065976 | Training Time: 88 

 End of epoch: 1 | Eval Loss: 0.6934668592044285 | Evaluating Time: 6 
Epoch: 2 | Iteration number: [10/565] 1% | Training loss: 0.7604645371437073
Epoch: 2 | Iteration number: [20/565] 3% | Training loss: 0.7259396851062775
Epoch: 2 | Iteration number: [30/565] 5% | Training loss: 0.714491049448649
Epoch: 2 | Iteration number: [40/565] 7% | Training loss: 0.7086847588419914
Epoch: 2 | Iteration number: [50/565] 8% | Training loss: 0.7052676367759705
Epoch: 2 | Iteration number: [60/565] 10% | Training loss: 0.7029579778512319
Epoch: 2 | Iteration number: [70/565] 12% | Training loss: 0.7013187459536961
Epoch: 2 | Iteration number: [80/565] 14% | Training loss: 0.7000620767474175
Epoch: 2 | Iteration number: [90/565] 15% | Training loss: 0.699143236875534
Epoch: 2 | Iteration number: [100/565] 17% | Training loss: 0.698377230167389
Epoch: 2 | Iteration number: [110/565] 19% | Training loss: 0.6977514266967774
Epoch: 2 | Iteration number: [120/565] 21% | Training loss: 0.69717359294494
Epoch: 2 | Iteration number: [130/565] 23% | Training loss: 0.6967245835524339
Epoch: 2 | Iteration number: [140/565] 24% | Training loss: 0.6963116283927645
Epoch: 2 | Iteration number: [150/565] 26% | Training loss: 0.6959612913926443
Epoch: 2 | Iteration number: [160/565] 28% | Training loss: 0.6956326968967914
Epoch: 2 | Iteration number: [170/565] 30% | Training loss: 0.6953608916086309
Epoch: 2 | Iteration number: [180/565] 31% | Training loss: 0.6951240277952618
Epoch: 2 | Iteration number: [190/565] 33% | Training loss: 0.6949280465904035
Epoch: 2 | Iteration number: [200/565] 35% | Training loss: 0.6947247898578643
Epoch: 2 | Iteration number: [210/565] 37% | Training loss: 0.6945333265122913
Epoch: 2 | Iteration number: [220/565] 38% | Training loss: 0.6943812966346741
Epoch: 2 | Iteration number: [230/565] 40% | Training loss: 0.6942394575347071
Epoch: 2 | Iteration number: [240/565] 42% | Training loss: 0.6941051431000232
Epoch: 2 | Iteration number: [250/565] 44% | Training loss: 0.6939599516391755
Epoch: 2 | Iteration number: [260/565] 46% | Training loss: 0.6938488373389611
Epoch: 2 | Iteration number: [270/565] 47% | Training loss: 0.6937337338924408
Epoch: 2 | Iteration number: [280/565] 49% | Training loss: 0.6936381024973733
Epoch: 2 | Iteration number: [290/565] 51% | Training loss: 0.6935416605965844
Epoch: 2 | Iteration number: [300/565] 53% | Training loss: 0.6934555747111638
Epoch: 2 | Iteration number: [310/565] 54% | Training loss: 0.6933662391478016
Epoch: 2 | Iteration number: [320/565] 56% | Training loss: 0.6932985534891486
Epoch: 2 | Iteration number: [330/565] 58% | Training loss: 0.6932209684993281
Epoch: 2 | Iteration number: [340/565] 60% | Training loss: 0.6931522786617279
Epoch: 2 | Iteration number: [350/565] 61% | Training loss: 0.693084602526256
Epoch: 2 | Iteration number: [360/565] 63% | Training loss: 0.6930195879605081
Epoch: 2 | Iteration number: [370/565] 65% | Training loss: 0.6929459243207364
Epoch: 2 | Iteration number: [380/565] 67% | Training loss: 0.6928893377906398
Epoch: 2 | Iteration number: [390/565] 69% | Training loss: 0.6928334080255949
Epoch: 2 | Iteration number: [400/565] 70% | Training loss: 0.6927795311808587
Epoch: 2 | Iteration number: [410/565] 72% | Training loss: 0.6927269265419099
Epoch: 2 | Iteration number: [420/565] 74% | Training loss: 0.6926789769104549
Epoch: 2 | Iteration number: [430/565] 76% | Training loss: 0.6926224334295406
Epoch: 2 | Iteration number: [440/565] 77% | Training loss: 0.6925723677331751
Epoch: 2 | Iteration number: [450/565] 79% | Training loss: 0.6925282434622446
Epoch: 2 | Iteration number: [460/565] 81% | Training loss: 0.6924810506727385
Epoch: 2 | Iteration number: [470/565] 83% | Training loss: 0.6924400532499273
Epoch: 2 | Iteration number: [480/565] 84% | Training loss: 0.6923984675357739
Epoch: 2 | Iteration number: [490/565] 86% | Training loss: 0.6923601767238305
Epoch: 2 | Iteration number: [500/565] 88% | Training loss: 0.6923246558904648
Epoch: 2 | Iteration number: [510/565] 90% | Training loss: 0.6922929465770722
Epoch: 2 | Iteration number: [520/565] 92% | Training loss: 0.6922651804410495
Epoch: 2 | Iteration number: [530/565] 93% | Training loss: 0.6922310390562382
Epoch: 2 | Iteration number: [540/565] 95% | Training loss: 0.6921940411682482
Epoch: 2 | Iteration number: [550/565] 97% | Training loss: 0.6921564513986761
Epoch: 2 | Iteration number: [560/565] 99% | Training loss: 0.6921208253928594

 End of epoch: 2 | Train Loss: 0.6908825194941158 | Training Time: 89 

 End of epoch: 2 | Eval Loss: 0.6923263072967529 | Evaluating Time: 6 
Epoch: 3 | Iteration number: [10/565] 1% | Training loss: 0.7591884434223175
Epoch: 3 | Iteration number: [20/565] 3% | Training loss: 0.7244325548410415
Epoch: 3 | Iteration number: [30/565] 5% | Training loss: 0.7130184590816497
Epoch: 3 | Iteration number: [40/565] 7% | Training loss: 0.7072901785373688
Epoch: 3 | Iteration number: [50/565] 8% | Training loss: 0.7038755607604981
Epoch: 3 | Iteration number: [60/565] 10% | Training loss: 0.7016395022471745
Epoch: 3 | Iteration number: [70/565] 12% | Training loss: 0.6999466563974108
Epoch: 3 | Iteration number: [80/565] 14% | Training loss: 0.6986924573779106
Epoch: 3 | Iteration number: [90/565] 15% | Training loss: 0.6977650847699907
Epoch: 3 | Iteration number: [100/565] 17% | Training loss: 0.6969729930162429
Epoch: 3 | Iteration number: [110/565] 19% | Training loss: 0.6963231406428597
Epoch: 3 | Iteration number: [120/565] 21% | Training loss: 0.6958006312449773
Epoch: 3 | Iteration number: [130/565] 23% | Training loss: 0.6953154829832223
Epoch: 3 | Iteration number: [140/565] 24% | Training loss: 0.6949343983616147
Epoch: 3 | Iteration number: [150/565] 26% | Training loss: 0.694596805969874
Epoch: 3 | Iteration number: [160/565] 28% | Training loss: 0.6943162448704243
Epoch: 3 | Iteration number: [170/565] 30% | Training loss: 0.6940682323539958
Epoch: 3 | Iteration number: [180/565] 31% | Training loss: 0.6938431888818741
Epoch: 3 | Iteration number: [190/565] 33% | Training loss: 0.6936278735336504
Epoch: 3 | Iteration number: [200/565] 35% | Training loss: 0.6934477734565735
Epoch: 3 | Iteration number: [210/565] 37% | Training loss: 0.6932820073195867
Epoch: 3 | Iteration number: [220/565] 38% | Training loss: 0.6931324319405989
Epoch: 3 | Iteration number: [230/565] 40% | Training loss: 0.6929758696452432
Epoch: 3 | Iteration number: [240/565] 42% | Training loss: 0.6928340477248033
Epoch: 3 | Iteration number: [250/565] 44% | Training loss: 0.6927029194831849
Epoch: 3 | Iteration number: [260/565] 46% | Training loss: 0.6925869492384104
Epoch: 3 | Iteration number: [270/565] 47% | Training loss: 0.6924953072159379
Epoch: 3 | Iteration number: [280/565] 49% | Training loss: 0.6923841650996889
Epoch: 3 | Iteration number: [290/565] 51% | Training loss: 0.6922845069704384
Epoch: 3 | Iteration number: [300/565] 53% | Training loss: 0.6922041777769724
Epoch: 3 | Iteration number: [310/565] 54% | Training loss: 0.6921259164810181
Epoch: 3 | Iteration number: [320/565] 56% | Training loss: 0.6920642172917724
Epoch: 3 | Iteration number: [330/565] 58% | Training loss: 0.6919903408397328
Epoch: 3 | Iteration number: [340/565] 60% | Training loss: 0.691933458868195
Epoch: 3 | Iteration number: [350/565] 61% | Training loss: 0.6918682175023215
Epoch: 3 | Iteration number: [360/565] 63% | Training loss: 0.6918124662505256
Epoch: 3 | Iteration number: [370/565] 65% | Training loss: 0.6917519324534648
Epoch: 3 | Iteration number: [380/565] 67% | Training loss: 0.691698313073108
Epoch: 3 | Iteration number: [390/565] 69% | Training loss: 0.6916335665262663
Epoch: 3 | Iteration number: [400/565] 70% | Training loss: 0.6915872158110141
Epoch: 3 | Iteration number: [410/565] 72% | Training loss: 0.6915488815889126
Epoch: 3 | Iteration number: [420/565] 74% | Training loss: 0.6914990058967045
Epoch: 3 | Iteration number: [430/565] 76% | Training loss: 0.6914529776850412
Epoch: 3 | Iteration number: [440/565] 77% | Training loss: 0.6914073910225521
Epoch: 3 | Iteration number: [450/565] 79% | Training loss: 0.6913684356212616
Epoch: 3 | Iteration number: [460/565] 81% | Training loss: 0.6913286884193836
Epoch: 3 | Iteration number: [470/565] 83% | Training loss: 0.6912909079105296
Epoch: 3 | Iteration number: [480/565] 84% | Training loss: 0.6912489823997021
Epoch: 3 | Iteration number: [490/565] 86% | Training loss: 0.6912100802878944
Epoch: 3 | Iteration number: [500/565] 88% | Training loss: 0.6911785128116608
Epoch: 3 | Iteration number: [510/565] 90% | Training loss: 0.6911471801645616
Epoch: 3 | Iteration number: [520/565] 92% | Training loss: 0.691114204778121
Epoch: 3 | Iteration number: [530/565] 93% | Training loss: 0.6910766089862248
Epoch: 3 | Iteration number: [540/565] 95% | Training loss: 0.6910461041662428
Epoch: 3 | Iteration number: [550/565] 97% | Training loss: 0.6910230857675725
Epoch: 3 | Iteration number: [560/565] 99% | Training loss: 0.6909851888460773

 End of epoch: 3 | Train Loss: 0.6897515049022911 | Training Time: 90 

 End of epoch: 3 | Eval Loss: 0.6919576014791217 | Evaluating Time: 6 
Epoch: 4 | Iteration number: [10/565] 1% | Training loss: 0.7578626155853272
Epoch: 4 | Iteration number: [20/565] 3% | Training loss: 0.7236161917448044
Epoch: 4 | Iteration number: [30/565] 5% | Training loss: 0.7121205449104309
Epoch: 4 | Iteration number: [40/565] 7% | Training loss: 0.7063602551817894
Epoch: 4 | Iteration number: [50/565] 8% | Training loss: 0.7029458439350128
Epoch: 4 | Iteration number: [60/565] 10% | Training loss: 0.7006929218769073
Epoch: 4 | Iteration number: [70/565] 12% | Training loss: 0.6990749674183981
Epoch: 4 | Iteration number: [80/565] 14% | Training loss: 0.6978258810937404
Epoch: 4 | Iteration number: [90/565] 15% | Training loss: 0.6968051724963717
Epoch: 4 | Iteration number: [100/565] 17% | Training loss: 0.6960132116079331
Epoch: 4 | Iteration number: [110/565] 19% | Training loss: 0.6953982494094155
Epoch: 4 | Iteration number: [120/565] 21% | Training loss: 0.694863676528136
Epoch: 4 | Iteration number: [130/565] 23% | Training loss: 0.6944041082492242
Epoch: 4 | Iteration number: [140/565] 24% | Training loss: 0.6940371389899935
Epoch: 4 | Iteration number: [150/565] 26% | Training loss: 0.6937050346533458
Epoch: 4 | Iteration number: [160/565] 28% | Training loss: 0.6934093490242959
Epoch: 4 | Iteration number: [170/565] 30% | Training loss: 0.6931811595664304
Epoch: 4 | Iteration number: [180/565] 31% | Training loss: 0.6929522040817473
Epoch: 4 | Iteration number: [190/565] 33% | Training loss: 0.6927622064163811
Epoch: 4 | Iteration number: [200/565] 35% | Training loss: 0.692578125
Epoch: 4 | Iteration number: [210/565] 37% | Training loss: 0.6924190910089584
Epoch: 4 | Iteration number: [220/565] 38% | Training loss: 0.69226767772978
Epoch: 4 | Iteration number: [230/565] 40% | Training loss: 0.6921480515728826
Epoch: 4 | Iteration number: [240/565] 42% | Training loss: 0.692013368755579
Epoch: 4 | Iteration number: [250/565] 44% | Training loss: 0.6919157297611237
Epoch: 4 | Iteration number: [260/565] 46% | Training loss: 0.6918033971236303
Epoch: 4 | Iteration number: [270/565] 47% | Training loss: 0.6917099742977707
Epoch: 4 | Iteration number: [280/565] 49% | Training loss: 0.6916143553597587
Epoch: 4 | Iteration number: [290/565] 51% | Training loss: 0.6915394928948633
Epoch: 4 | Iteration number: [300/565] 53% | Training loss: 0.6914580806096395
Epoch: 4 | Iteration number: [310/565] 54% | Training loss: 0.6913779712492419
Epoch: 4 | Iteration number: [320/565] 56% | Training loss: 0.6913029115647078
Epoch: 4 | Iteration number: [330/565] 58% | Training loss: 0.6912330809867744
Epoch: 4 | Iteration number: [340/565] 60% | Training loss: 0.6911557865493437
Epoch: 4 | Iteration number: [350/565] 61% | Training loss: 0.6910906904084342
Epoch: 4 | Iteration number: [360/565] 63% | Training loss: 0.6910334491067462
Epoch: 4 | Iteration number: [370/565] 65% | Training loss: 0.690977226237993
Epoch: 4 | Iteration number: [380/565] 67% | Training loss: 0.6909196376800537
Epoch: 4 | Iteration number: [390/565] 69% | Training loss: 0.690866919205739
Epoch: 4 | Iteration number: [400/565] 70% | Training loss: 0.6908103181421756
Epoch: 4 | Iteration number: [410/565] 72% | Training loss: 0.6907588399038083
Epoch: 4 | Iteration number: [420/565] 74% | Training loss: 0.6907169584717069
Epoch: 4 | Iteration number: [430/565] 76% | Training loss: 0.6906754568565724
Epoch: 4 | Iteration number: [440/565] 77% | Training loss: 0.6906349098140543
Epoch: 4 | Iteration number: [450/565] 79% | Training loss: 0.6905930871433682
Epoch: 4 | Iteration number: [460/565] 81% | Training loss: 0.690559795110122
Epoch: 4 | Iteration number: [470/565] 83% | Training loss: 0.6905199525204111
Epoch: 4 | Iteration number: [480/565] 84% | Training loss: 0.6904899639387926
Epoch: 4 | Iteration number: [490/565] 86% | Training loss: 0.6904604927617677
Epoch: 4 | Iteration number: [500/565] 88% | Training loss: 0.6904282690286636
Epoch: 4 | Iteration number: [510/565] 90% | Training loss: 0.6903941730658213
Epoch: 4 | Iteration number: [520/565] 92% | Training loss: 0.6903622983739927
Epoch: 4 | Iteration number: [530/565] 93% | Training loss: 0.6903386644597324
Epoch: 4 | Iteration number: [540/565] 95% | Training loss: 0.6903124823614403
Epoch: 4 | Iteration number: [550/565] 97% | Training loss: 0.6902809433503584
Epoch: 4 | Iteration number: [560/565] 99% | Training loss: 0.6902595334819385

 End of epoch: 4 | Train Loss: 0.6890231649432562 | Training Time: 89 

 End of epoch: 4 | Eval Loss: 0.6913981693131583 | Evaluating Time: 6 
Epoch: 5 | Iteration number: [10/565] 1% | Training loss: 0.7573212087154388
Epoch: 5 | Iteration number: [20/565] 3% | Training loss: 0.7231180250644684
Epoch: 5 | Iteration number: [30/565] 5% | Training loss: 0.711807930469513
Epoch: 5 | Iteration number: [40/565] 7% | Training loss: 0.7058703169226647
Epoch: 5 | Iteration number: [50/565] 8% | Training loss: 0.7024722707271576
Epoch: 5 | Iteration number: [60/565] 10% | Training loss: 0.7001469711462657
Epoch: 5 | Iteration number: [70/565] 12% | Training loss: 0.698482664993831
Epoch: 5 | Iteration number: [80/565] 14% | Training loss: 0.6972289629280567
Epoch: 5 | Iteration number: [90/565] 15% | Training loss: 0.6962935586770376
Epoch: 5 | Iteration number: [100/565] 17% | Training loss: 0.6955136936903
Epoch: 5 | Iteration number: [110/565] 19% | Training loss: 0.6948646090247415
Epoch: 5 | Iteration number: [120/565] 21% | Training loss: 0.694344092408816
Epoch: 5 | Iteration number: [130/565] 23% | Training loss: 0.693912259890483
Epoch: 5 | Iteration number: [140/565] 24% | Training loss: 0.6935419559478759
Epoch: 5 | Iteration number: [150/565] 26% | Training loss: 0.6932156606515248
Epoch: 5 | Iteration number: [160/565] 28% | Training loss: 0.6929128624498844
Epoch: 5 | Iteration number: [170/565] 30% | Training loss: 0.6926534242489759
Epoch: 5 | Iteration number: [180/565] 31% | Training loss: 0.6924350079562929
Epoch: 5 | Iteration number: [190/565] 33% | Training loss: 0.6922077793824045
Epoch: 5 | Iteration number: [200/565] 35% | Training loss: 0.6920395216345787
Epoch: 5 | Iteration number: [210/565] 37% | Training loss: 0.6919042905171712
Epoch: 5 | Iteration number: [220/565] 38% | Training loss: 0.6917587559331547
Epoch: 5 | Iteration number: [230/565] 40% | Training loss: 0.691630707875542
Epoch: 5 | Iteration number: [240/565] 42% | Training loss: 0.6914962184925874
Epoch: 5 | Iteration number: [250/565] 44% | Training loss: 0.6913651270866394
Epoch: 5 | Iteration number: [260/565] 46% | Training loss: 0.6912479684903071
Epoch: 5 | Iteration number: [270/565] 47% | Training loss: 0.6911451498667399
Epoch: 5 | Iteration number: [280/565] 49% | Training loss: 0.6910478700484548
Epoch: 5 | Iteration number: [290/565] 51% | Training loss: 0.6909517021014773
Epoch: 5 | Iteration number: [300/565] 53% | Training loss: 0.6908650710185369
Epoch: 5 | Iteration number: [310/565] 54% | Training loss: 0.6907793585331209
Epoch: 5 | Iteration number: [320/565] 56% | Training loss: 0.6907110527157784
Epoch: 5 | Iteration number: [330/565] 58% | Training loss: 0.690635331291141
Epoch: 5 | Iteration number: [340/565] 60% | Training loss: 0.6905670758555917
Epoch: 5 | Iteration number: [350/565] 61% | Training loss: 0.6904975146906717
Epoch: 5 | Iteration number: [360/565] 63% | Training loss: 0.690452263255914
Epoch: 5 | Iteration number: [370/565] 65% | Training loss: 0.6903878970726116
Epoch: 5 | Iteration number: [380/565] 67% | Training loss: 0.6903415007026572
Epoch: 5 | Iteration number: [390/565] 69% | Training loss: 0.690293835523801
Epoch: 5 | Iteration number: [400/565] 70% | Training loss: 0.6902443584799767
Epoch: 5 | Iteration number: [410/565] 72% | Training loss: 0.6901984565141724
Epoch: 5 | Iteration number: [420/565] 74% | Training loss: 0.6901595732995442
Epoch: 5 | Iteration number: [430/565] 76% | Training loss: 0.6901196501975836
Epoch: 5 | Iteration number: [440/565] 77% | Training loss: 0.6900876755064184
Epoch: 5 | Iteration number: [450/565] 79% | Training loss: 0.690036790503396
Epoch: 5 | Iteration number: [460/565] 81% | Training loss: 0.690001417502113
Epoch: 5 | Iteration number: [470/565] 83% | Training loss: 0.6899732403298642
Epoch: 5 | Iteration number: [480/565] 84% | Training loss: 0.689946116010348
Epoch: 5 | Iteration number: [490/565] 86% | Training loss: 0.6899144435415463
Epoch: 5 | Iteration number: [500/565] 88% | Training loss: 0.6898770859241485
Epoch: 5 | Iteration number: [510/565] 90% | Training loss: 0.6898606536435146
Epoch: 5 | Iteration number: [520/565] 92% | Training loss: 0.6898284093691752
Epoch: 5 | Iteration number: [530/565] 93% | Training loss: 0.6898012268093398
Epoch: 5 | Iteration number: [540/565] 95% | Training loss: 0.68977371443201
Epoch: 5 | Iteration number: [550/565] 97% | Training loss: 0.6897517989982258
Epoch: 5 | Iteration number: [560/565] 99% | Training loss: 0.6897223381059511

 End of epoch: 5 | Train Loss: 0.6884927324489155 | Training Time: 89 

 End of epoch: 5 | Eval Loss: 0.6909764323915754 | Evaluating Time: 6 
Epoch: 6 | Iteration number: [10/565] 1% | Training loss: 0.757213580608368
Epoch: 6 | Iteration number: [20/565] 3% | Training loss: 0.7225287795066834
Epoch: 6 | Iteration number: [30/565] 5% | Training loss: 0.7110743959744771
Epoch: 6 | Iteration number: [40/565] 7% | Training loss: 0.7051509886980056
Epoch: 6 | Iteration number: [50/565] 8% | Training loss: 0.7017701649665833
Epoch: 6 | Iteration number: [60/565] 10% | Training loss: 0.6995462308327357
Epoch: 6 | Iteration number: [70/565] 12% | Training loss: 0.6979265434401376
Epoch: 6 | Iteration number: [80/565] 14% | Training loss: 0.6967254988849163
Epoch: 6 | Iteration number: [90/565] 15% | Training loss: 0.6958091570271386
Epoch: 6 | Iteration number: [100/565] 17% | Training loss: 0.695044887661934
Epoch: 6 | Iteration number: [110/565] 19% | Training loss: 0.694396176663312
Epoch: 6 | Iteration number: [120/565] 21% | Training loss: 0.6938719456394513
Epoch: 6 | Iteration number: [130/565] 23% | Training loss: 0.6934516434486095
Epoch: 6 | Iteration number: [140/565] 24% | Training loss: 0.6930518427065441
Epoch: 6 | Iteration number: [150/565] 26% | Training loss: 0.692721985578537
Epoch: 6 | Iteration number: [160/565] 28% | Training loss: 0.692418397590518
Epoch: 6 | Iteration number: [170/565] 30% | Training loss: 0.6921810939031489
Epoch: 6 | Iteration number: [180/565] 31% | Training loss: 0.6919752369324367
Epoch: 6 | Iteration number: [190/565] 33% | Training loss: 0.6917542783837569
Epoch: 6 | Iteration number: [200/565] 35% | Training loss: 0.6915822985768318
Epoch: 6 | Iteration number: [210/565] 37% | Training loss: 0.6914285055228642
Epoch: 6 | Iteration number: [220/565] 38% | Training loss: 0.6912888234311884
Epoch: 6 | Iteration number: [230/565] 40% | Training loss: 0.6911354220431783
Epoch: 6 | Iteration number: [240/565] 42% | Training loss: 0.6910251056154569
Epoch: 6 | Iteration number: [250/565] 44% | Training loss: 0.6909133217334748
Epoch: 6 | Iteration number: [260/565] 46% | Training loss: 0.6908092079254297
Epoch: 6 | Iteration number: [270/565] 47% | Training loss: 0.6906860689322154
Epoch: 6 | Iteration number: [280/565] 49% | Training loss: 0.6905800842813083
Epoch: 6 | Iteration number: [290/565] 51% | Training loss: 0.6905053138732911
Epoch: 6 | Iteration number: [300/565] 53% | Training loss: 0.6904203673203786
Epoch: 6 | Iteration number: [310/565] 54% | Training loss: 0.6903495475169151
Epoch: 6 | Iteration number: [320/565] 56% | Training loss: 0.6902794569730759
Epoch: 6 | Iteration number: [330/565] 58% | Training loss: 0.690211397409439
Epoch: 6 | Iteration number: [340/565] 60% | Training loss: 0.6901389292057822
Epoch: 6 | Iteration number: [350/565] 61% | Training loss: 0.6900752181666238
Epoch: 6 | Iteration number: [360/565] 63% | Training loss: 0.6900192560421096
Epoch: 6 | Iteration number: [370/565] 65% | Training loss: 0.6899673486078107
Epoch: 6 | Iteration number: [380/565] 67% | Training loss: 0.689925722071999
Epoch: 6 | Iteration number: [390/565] 69% | Training loss: 0.6898733901671874
Epoch: 6 | Iteration number: [400/565] 70% | Training loss: 0.6898221008479595
Epoch: 6 | Iteration number: [410/565] 72% | Training loss: 0.6897902083106158
Epoch: 6 | Iteration number: [420/565] 74% | Training loss: 0.6897538187957946
Epoch: 6 | Iteration number: [430/565] 76% | Training loss: 0.6897255261277043
Epoch: 6 | Iteration number: [440/565] 77% | Training loss: 0.689695252749053
Epoch: 6 | Iteration number: [450/565] 79% | Training loss: 0.6896633744239807
Epoch: 6 | Iteration number: [460/565] 81% | Training loss: 0.6896235278119212
Epoch: 6 | Iteration number: [470/565] 83% | Training loss: 0.6895960996759699
Epoch: 6 | Iteration number: [480/565] 84% | Training loss: 0.6895591824005047
Epoch: 6 | Iteration number: [490/565] 86% | Training loss: 0.6895276253320732
Epoch: 6 | Iteration number: [500/565] 88% | Training loss: 0.6895051686763763
Epoch: 6 | Iteration number: [510/565] 90% | Training loss: 0.6894708514213562
Epoch: 6 | Iteration number: [520/565] 92% | Training loss: 0.6894416023905461
Epoch: 6 | Iteration number: [530/565] 93% | Training loss: 0.6894027386071547
Epoch: 6 | Iteration number: [540/565] 95% | Training loss: 0.6893774303021254
Epoch: 6 | Iteration number: [550/565] 97% | Training loss: 0.6893484643372623
Epoch: 6 | Iteration number: [560/565] 99% | Training loss: 0.6893268992858274

 End of epoch: 6 | Train Loss: 0.6880955890216659 | Training Time: 88 

 End of epoch: 6 | Eval Loss: 0.6907722439084735 | Evaluating Time: 6 
Epoch: 7 | Iteration number: [10/565] 1% | Training loss: 0.7561885833740234
Epoch: 7 | Iteration number: [20/565] 3% | Training loss: 0.7218868881464005
Epoch: 7 | Iteration number: [30/565] 5% | Training loss: 0.7106221954027812
Epoch: 7 | Iteration number: [40/565] 7% | Training loss: 0.7050038412213325
Epoch: 7 | Iteration number: [50/565] 8% | Training loss: 0.7016128599643707
Epoch: 7 | Iteration number: [60/565] 10% | Training loss: 0.699382949868838
Epoch: 7 | Iteration number: [70/565] 12% | Training loss: 0.6977281425680433
Epoch: 7 | Iteration number: [80/565] 14% | Training loss: 0.6965099968016147
Epoch: 7 | Iteration number: [90/565] 15% | Training loss: 0.6955848038196564
Epoch: 7 | Iteration number: [100/565] 17% | Training loss: 0.6947722500562667
Epoch: 7 | Iteration number: [110/565] 19% | Training loss: 0.6941376333886927
Epoch: 7 | Iteration number: [120/565] 21% | Training loss: 0.6935851454734803
Epoch: 7 | Iteration number: [130/565] 23% | Training loss: 0.6931386424944951
Epoch: 7 | Iteration number: [140/565] 24% | Training loss: 0.6927838410649981
Epoch: 7 | Iteration number: [150/565] 26% | Training loss: 0.6924450095494589
Epoch: 7 | Iteration number: [160/565] 28% | Training loss: 0.6921575721353292
Epoch: 7 | Iteration number: [170/565] 30% | Training loss: 0.6918901229605955
Epoch: 7 | Iteration number: [180/565] 31% | Training loss: 0.6916687736908594
Epoch: 7 | Iteration number: [190/565] 33% | Training loss: 0.6914521355378
Epoch: 7 | Iteration number: [200/565] 35% | Training loss: 0.6912485668063164
Epoch: 7 | Iteration number: [210/565] 37% | Training loss: 0.6910806204591479
Epoch: 7 | Iteration number: [220/565] 38% | Training loss: 0.6909284903244539
Epoch: 7 | Iteration number: [230/565] 40% | Training loss: 0.6907902450665183
Epoch: 7 | Iteration number: [240/565] 42% | Training loss: 0.6906792027254899
Epoch: 7 | Iteration number: [250/565] 44% | Training loss: 0.6905992746353149
Epoch: 7 | Iteration number: [260/565] 46% | Training loss: 0.6904981303673524
Epoch: 7 | Iteration number: [270/565] 47% | Training loss: 0.6904190498369711
Epoch: 7 | Iteration number: [280/565] 49% | Training loss: 0.6903338183249746
Epoch: 7 | Iteration number: [290/565] 51% | Training loss: 0.6902640297495085
Epoch: 7 | Iteration number: [300/565] 53% | Training loss: 0.6901856935024262
Epoch: 7 | Iteration number: [310/565] 54% | Training loss: 0.6901093619485055
Epoch: 7 | Iteration number: [320/565] 56% | Training loss: 0.6900370914489031
Epoch: 7 | Iteration number: [330/565] 58% | Training loss: 0.6899854790080677
Epoch: 7 | Iteration number: [340/565] 60% | Training loss: 0.6899211583768621
Epoch: 7 | Iteration number: [350/565] 61% | Training loss: 0.6898770880699158
Epoch: 7 | Iteration number: [360/565] 63% | Training loss: 0.6898239922192362
Epoch: 7 | Iteration number: [370/565] 65% | Training loss: 0.6897695629983335
Epoch: 7 | Iteration number: [380/565] 67% | Training loss: 0.6897139641799425
Epoch: 7 | Iteration number: [390/565] 69% | Training loss: 0.6896651786107283
Epoch: 7 | Iteration number: [400/565] 70% | Training loss: 0.6896052032709121
Epoch: 7 | Iteration number: [410/565] 72% | Training loss: 0.6895645474515311
Epoch: 7 | Iteration number: [420/565] 74% | Training loss: 0.6895143987167449
Epoch: 7 | Iteration number: [430/565] 76% | Training loss: 0.6894738381685213
Epoch: 7 | Iteration number: [440/565] 77% | Training loss: 0.6894311020320112
Epoch: 7 | Iteration number: [450/565] 79% | Training loss: 0.6894025496641795
Epoch: 7 | Iteration number: [460/565] 81% | Training loss: 0.689361137540444
Epoch: 7 | Iteration number: [470/565] 83% | Training loss: 0.689318075078599
Epoch: 7 | Iteration number: [480/565] 84% | Training loss: 0.6892937298864126
Epoch: 7 | Iteration number: [490/565] 86% | Training loss: 0.6892655150014527
Epoch: 7 | Iteration number: [500/565] 88% | Training loss: 0.689236741065979
Epoch: 7 | Iteration number: [510/565] 90% | Training loss: 0.6892019389891157
Epoch: 7 | Iteration number: [520/565] 92% | Training loss: 0.6891765968157695
Epoch: 7 | Iteration number: [530/565] 93% | Training loss: 0.6891464815949494
Epoch: 7 | Iteration number: [540/565] 95% | Training loss: 0.689119905895657
Epoch: 7 | Iteration number: [550/565] 97% | Training loss: 0.6891000313108617
Epoch: 7 | Iteration number: [560/565] 99% | Training loss: 0.689072148501873

 End of epoch: 7 | Train Loss: 0.6878444161035319 | Training Time: 89 

 End of epoch: 7 | Eval Loss: 0.6903542535645621 | Evaluating Time: 5 
Epoch: 8 | Iteration number: [10/565] 1% | Training loss: 0.7565786838531494
Epoch: 8 | Iteration number: [20/565] 3% | Training loss: 0.7221733510494233
Epoch: 8 | Iteration number: [30/565] 5% | Training loss: 0.7107201675573985
Epoch: 8 | Iteration number: [40/565] 7% | Training loss: 0.7049345061182976
Epoch: 8 | Iteration number: [50/565] 8% | Training loss: 0.7015447092056274
Epoch: 8 | Iteration number: [60/565] 10% | Training loss: 0.6991627116998037
Epoch: 8 | Iteration number: [70/565] 12% | Training loss: 0.6975484720298222
Epoch: 8 | Iteration number: [80/565] 14% | Training loss: 0.6963769376277924
Epoch: 8 | Iteration number: [90/565] 15% | Training loss: 0.6954057627254062
Epoch: 8 | Iteration number: [100/565] 17% | Training loss: 0.6946828579902649
Epoch: 8 | Iteration number: [110/565] 19% | Training loss: 0.6940555155277253
Epoch: 8 | Iteration number: [120/565] 21% | Training loss: 0.6935636887947718
Epoch: 8 | Iteration number: [130/565] 23% | Training loss: 0.6931229174137116
Epoch: 8 | Iteration number: [140/565] 24% | Training loss: 0.6927501171827316
Epoch: 8 | Iteration number: [150/565] 26% | Training loss: 0.6923924744129181
Epoch: 8 | Iteration number: [160/565] 28% | Training loss: 0.6920996461063623
Epoch: 8 | Iteration number: [170/565] 30% | Training loss: 0.6918570711332209
Epoch: 8 | Iteration number: [180/565] 31% | Training loss: 0.6916062987513012
Epoch: 8 | Iteration number: [190/565] 33% | Training loss: 0.6913923978805542
Epoch: 8 | Iteration number: [200/565] 35% | Training loss: 0.6911742514371872
Epoch: 8 | Iteration number: [210/565] 37% | Training loss: 0.6909889377298809
Epoch: 8 | Iteration number: [220/565] 38% | Training loss: 0.6908284306526185
Epoch: 8 | Iteration number: [230/565] 40% | Training loss: 0.690682257776675
Epoch: 8 | Iteration number: [240/565] 42% | Training loss: 0.6905787934859594
Epoch: 8 | Iteration number: [250/565] 44% | Training loss: 0.6904758086204529
Epoch: 8 | Iteration number: [260/565] 46% | Training loss: 0.6903851078106806
Epoch: 8 | Iteration number: [270/565] 47% | Training loss: 0.6902794570834548
Epoch: 8 | Iteration number: [280/565] 49% | Training loss: 0.6901722942079817
Epoch: 8 | Iteration number: [290/565] 51% | Training loss: 0.6900827169418335
Epoch: 8 | Iteration number: [300/565] 53% | Training loss: 0.6900045502185822
Epoch: 8 | Iteration number: [310/565] 54% | Training loss: 0.6899267861920019
Epoch: 8 | Iteration number: [320/565] 56% | Training loss: 0.6898654134944081
Epoch: 8 | Iteration number: [330/565] 58% | Training loss: 0.6898083905378978
Epoch: 8 | Iteration number: [340/565] 60% | Training loss: 0.6897380274884841
Epoch: 8 | Iteration number: [350/565] 61% | Training loss: 0.6896832348619188
Epoch: 8 | Iteration number: [360/565] 63% | Training loss: 0.6896275101436509
Epoch: 8 | Iteration number: [370/565] 65% | Training loss: 0.6895765449549701
Epoch: 8 | Iteration number: [380/565] 67% | Training loss: 0.6895211188416732
Epoch: 8 | Iteration number: [390/565] 69% | Training loss: 0.689474559135926
Epoch: 8 | Iteration number: [400/565] 70% | Training loss: 0.6894297574460506
Epoch: 8 | Iteration number: [410/565] 72% | Training loss: 0.6893813285885788
Epoch: 8 | Iteration number: [420/565] 74% | Training loss: 0.6893356795821871
Epoch: 8 | Iteration number: [430/565] 76% | Training loss: 0.6892830552056778
Epoch: 8 | Iteration number: [440/565] 77% | Training loss: 0.6892557282339443
Epoch: 8 | Iteration number: [450/565] 79% | Training loss: 0.6892193218072256
Epoch: 8 | Iteration number: [460/565] 81% | Training loss: 0.6891797556825306
Epoch: 8 | Iteration number: [470/565] 83% | Training loss: 0.6891456221012359
Epoch: 8 | Iteration number: [480/565] 84% | Training loss: 0.6891129293789466
Epoch: 8 | Iteration number: [490/565] 86% | Training loss: 0.6890792372275372
Epoch: 8 | Iteration number: [500/565] 88% | Training loss: 0.6890400168895722
Epoch: 8 | Iteration number: [510/565] 90% | Training loss: 0.6890164194153804
Epoch: 8 | Iteration number: [520/565] 92% | Training loss: 0.6889909306397805
Epoch: 8 | Iteration number: [530/565] 93% | Training loss: 0.6889668887516238
Epoch: 8 | Iteration number: [540/565] 95% | Training loss: 0.6889347445081782
Epoch: 8 | Iteration number: [550/565] 97% | Training loss: 0.6889105326479131
Epoch: 8 | Iteration number: [560/565] 99% | Training loss: 0.6888848152543817

 End of epoch: 8 | Train Loss: 0.6876570283839133 | Training Time: 88 

 End of epoch: 8 | Eval Loss: 0.6897797669683184 | Evaluating Time: 6 
Epoch: 9 | Iteration number: [10/565] 1% | Training loss: 0.7561809778213501
Epoch: 9 | Iteration number: [20/565] 3% | Training loss: 0.721738588809967
Epoch: 9 | Iteration number: [30/565] 5% | Training loss: 0.7104960819085439
Epoch: 9 | Iteration number: [40/565] 7% | Training loss: 0.7047621637582779
Epoch: 9 | Iteration number: [50/565] 8% | Training loss: 0.7013205015659332
Epoch: 9 | Iteration number: [60/565] 10% | Training loss: 0.6989891797304153
Epoch: 9 | Iteration number: [70/565] 12% | Training loss: 0.6973452065672193
Epoch: 9 | Iteration number: [80/565] 14% | Training loss: 0.696125028282404
Epoch: 9 | Iteration number: [90/565] 15% | Training loss: 0.6951619002554151
Epoch: 9 | Iteration number: [100/565] 17% | Training loss: 0.694382900595665
Epoch: 9 | Iteration number: [110/565] 19% | Training loss: 0.6936671376228333
Epoch: 9 | Iteration number: [120/565] 21% | Training loss: 0.6931758716702461
Epoch: 9 | Iteration number: [130/565] 23% | Training loss: 0.6927934848345243
Epoch: 9 | Iteration number: [140/565] 24% | Training loss: 0.6924494304827281
Epoch: 9 | Iteration number: [150/565] 26% | Training loss: 0.6921296962102255
Epoch: 9 | Iteration number: [160/565] 28% | Training loss: 0.691850395128131
Epoch: 9 | Iteration number: [170/565] 30% | Training loss: 0.6915669584975523
Epoch: 9 | Iteration number: [180/565] 31% | Training loss: 0.6913372264968024
Epoch: 9 | Iteration number: [190/565] 33% | Training loss: 0.6911146650188847
Epoch: 9 | Iteration number: [200/565] 35% | Training loss: 0.6909406369924546
Epoch: 9 | Iteration number: [210/565] 37% | Training loss: 0.6907836766470046
Epoch: 9 | Iteration number: [220/565] 38% | Training loss: 0.6906283598054539
Epoch: 9 | Iteration number: [230/565] 40% | Training loss: 0.6904937891856484
Epoch: 9 | Iteration number: [240/565] 42% | Training loss: 0.6903903660674889
Epoch: 9 | Iteration number: [250/565] 44% | Training loss: 0.690270620584488
Epoch: 9 | Iteration number: [260/565] 46% | Training loss: 0.6901755383381477
Epoch: 9 | Iteration number: [270/565] 47% | Training loss: 0.6900853953979633
Epoch: 9 | Iteration number: [280/565] 49% | Training loss: 0.6899938632334982
Epoch: 9 | Iteration number: [290/565] 51% | Training loss: 0.6898957014083862
Epoch: 9 | Iteration number: [300/565] 53% | Training loss: 0.6898310414950053
Epoch: 9 | Iteration number: [310/565] 54% | Training loss: 0.6897706458645482
Epoch: 9 | Iteration number: [320/565] 56% | Training loss: 0.6897016650065779
Epoch: 9 | Iteration number: [330/565] 58% | Training loss: 0.6896327645489664
Epoch: 9 | Iteration number: [340/565] 60% | Training loss: 0.6895664085360135
Epoch: 9 | Iteration number: [350/565] 61% | Training loss: 0.6895079576969146
Epoch: 9 | Iteration number: [360/565] 63% | Training loss: 0.6894444488816791
Epoch: 9 | Iteration number: [370/565] 65% | Training loss: 0.6893953658439017
Epoch: 9 | Iteration number: [380/565] 67% | Training loss: 0.6893407922042044
Epoch: 9 | Iteration number: [390/565] 69% | Training loss: 0.6892995339173537
Epoch: 9 | Iteration number: [400/565] 70% | Training loss: 0.6892586779594422
Epoch: 9 | Iteration number: [410/565] 72% | Training loss: 0.689219931131456
Epoch: 9 | Iteration number: [420/565] 74% | Training loss: 0.6891795902025132
Epoch: 9 | Iteration number: [430/565] 76% | Training loss: 0.6891503691673279
Epoch: 9 | Iteration number: [440/565] 77% | Training loss: 0.6891085589473898
Epoch: 9 | Iteration number: [450/565] 79% | Training loss: 0.689063938193851
Epoch: 9 | Iteration number: [460/565] 81% | Training loss: 0.6890377333630686
Epoch: 9 | Iteration number: [470/565] 83% | Training loss: 0.6889942129875751
Epoch: 9 | Iteration number: [480/565] 84% | Training loss: 0.6889587345222632
Epoch: 9 | Iteration number: [490/565] 86% | Training loss: 0.6889240823229965
Epoch: 9 | Iteration number: [500/565] 88% | Training loss: 0.688888505935669
Epoch: 9 | Iteration number: [510/565] 90% | Training loss: 0.6888507019071018
Epoch: 9 | Iteration number: [520/565] 92% | Training loss: 0.6888333084491584
Epoch: 9 | Iteration number: [530/565] 93% | Training loss: 0.6888076475206412
Epoch: 9 | Iteration number: [540/565] 95% | Training loss: 0.688789192725111
Epoch: 9 | Iteration number: [550/565] 97% | Training loss: 0.6887598646770824
Epoch: 9 | Iteration number: [560/565] 99% | Training loss: 0.6887284298028264

 End of epoch: 9 | Train Loss: 0.6875025348325746 | Training Time: 90 

 End of epoch: 9 | Eval Loss: 0.690287070614951 | Evaluating Time: 6 
Epoch: 10 | Iteration number: [10/565] 1% | Training loss: 0.7564557909965515
Epoch: 10 | Iteration number: [20/565] 3% | Training loss: 0.7221563994884491
Epoch: 10 | Iteration number: [30/565] 5% | Training loss: 0.7105348070462545
Epoch: 10 | Iteration number: [40/565] 7% | Training loss: 0.7048491910099983
Epoch: 10 | Iteration number: [50/565] 8% | Training loss: 0.7013749516010285
Epoch: 10 | Iteration number: [60/565] 10% | Training loss: 0.699030273159345
Epoch: 10 | Iteration number: [70/565] 12% | Training loss: 0.6974330391202654
Epoch: 10 | Iteration number: [80/565] 14% | Training loss: 0.6961505077779293
Epoch: 10 | Iteration number: [90/565] 15% | Training loss: 0.6951908270517985
Epoch: 10 | Iteration number: [100/565] 17% | Training loss: 0.6944184690713883
Epoch: 10 | Iteration number: [110/565] 19% | Training loss: 0.6938051283359528
Epoch: 10 | Iteration number: [120/565] 21% | Training loss: 0.6932643229762713
Epoch: 10 | Iteration number: [130/565] 23% | Training loss: 0.692803948200666
Epoch: 10 | Iteration number: [140/565] 24% | Training loss: 0.6924361241715294
Epoch: 10 | Iteration number: [150/565] 26% | Training loss: 0.6921080537637074
Epoch: 10 | Iteration number: [160/565] 28% | Training loss: 0.6918325122445822
Epoch: 10 | Iteration number: [170/565] 30% | Training loss: 0.6915724473841051
Epoch: 10 | Iteration number: [180/565] 31% | Training loss: 0.6913426886002223
Epoch: 10 | Iteration number: [190/565] 33% | Training loss: 0.691130687061109
Epoch: 10 | Iteration number: [200/565] 35% | Training loss: 0.6909564808011055
Epoch: 10 | Iteration number: [210/565] 37% | Training loss: 0.6907743377344949
Epoch: 10 | Iteration number: [220/565] 38% | Training loss: 0.6906352216547186
Epoch: 10 | Iteration number: [230/565] 40% | Training loss: 0.6905042078184045
Epoch: 10 | Iteration number: [240/565] 42% | Training loss: 0.6903871019681295
Epoch: 10 | Iteration number: [250/565] 44% | Training loss: 0.6902623369693756
Epoch: 10 | Iteration number: [260/565] 46% | Training loss: 0.6901358012969677
Epoch: 10 | Iteration number: [270/565] 47% | Training loss: 0.6900109021751969
Epoch: 10 | Iteration number: [280/565] 49% | Training loss: 0.6899136006832123
Epoch: 10 | Iteration number: [290/565] 51% | Training loss: 0.689823382065214
Epoch: 10 | Iteration number: [300/565] 53% | Training loss: 0.6897402087847392
Epoch: 10 | Iteration number: [310/565] 54% | Training loss: 0.6896570234529433
Epoch: 10 | Iteration number: [320/565] 56% | Training loss: 0.689589797705412
Epoch: 10 | Iteration number: [330/565] 58% | Training loss: 0.6895246213132685
Epoch: 10 | Iteration number: [340/565] 60% | Training loss: 0.6894626797998653
Epoch: 10 | Iteration number: [350/565] 61% | Training loss: 0.6893931337765284
Epoch: 10 | Iteration number: [360/565] 63% | Training loss: 0.6893396880891588
Epoch: 10 | Iteration number: [370/565] 65% | Training loss: 0.6892904122133513
Epoch: 10 | Iteration number: [380/565] 67% | Training loss: 0.6892397977803882
Epoch: 10 | Iteration number: [390/565] 69% | Training loss: 0.6891904913462126
Epoch: 10 | Iteration number: [400/565] 70% | Training loss: 0.6891398239135742
Epoch: 10 | Iteration number: [410/565] 72% | Training loss: 0.6890933653203453
Epoch: 10 | Iteration number: [420/565] 74% | Training loss: 0.6890564079795565
Epoch: 10 | Iteration number: [430/565] 76% | Training loss: 0.6890147171741308
Epoch: 10 | Iteration number: [440/565] 77% | Training loss: 0.6889799971472134
Epoch: 10 | Iteration number: [450/565] 79% | Training loss: 0.6889351289802127
Epoch: 10 | Iteration number: [460/565] 81% | Training loss: 0.6888983064371607
Epoch: 10 | Iteration number: [470/565] 83% | Training loss: 0.6888688886419255
Epoch: 10 | Iteration number: [480/565] 84% | Training loss: 0.6888373726358016
Epoch: 10 | Iteration number: [490/565] 86% | Training loss: 0.6888077509646513
Epoch: 10 | Iteration number: [500/565] 88% | Training loss: 0.6887803038358689
Epoch: 10 | Iteration number: [510/565] 90% | Training loss: 0.6887506986365599
Epoch: 10 | Iteration number: [520/565] 92% | Training loss: 0.6887215033173562
Epoch: 10 | Iteration number: [530/565] 93% | Training loss: 0.6886980723659947
Epoch: 10 | Iteration number: [540/565] 95% | Training loss: 0.6886667180944372
Epoch: 10 | Iteration number: [550/565] 97% | Training loss: 0.6886462092399597
Epoch: 10 | Iteration number: [560/565] 99% | Training loss: 0.6886292321341378

 End of epoch: 10 | Train Loss: 0.6873948009668198 | Training Time: 89 

 End of epoch: 10 | Eval Loss: 0.6903618318693978 | Evaluating Time: 6 
Epoch: 11 | Iteration number: [10/565] 1% | Training loss: 0.7561705887317658
Epoch: 11 | Iteration number: [20/565] 3% | Training loss: 0.7217149376869202
Epoch: 11 | Iteration number: [30/565] 5% | Training loss: 0.7102141718069712
Epoch: 11 | Iteration number: [40/565] 7% | Training loss: 0.7044593244791031
Epoch: 11 | Iteration number: [50/565] 8% | Training loss: 0.7009975647926331
Epoch: 11 | Iteration number: [60/565] 10% | Training loss: 0.6986872573693593
Epoch: 11 | Iteration number: [70/565] 12% | Training loss: 0.6970699114458901
Epoch: 11 | Iteration number: [80/565] 14% | Training loss: 0.6958621352910995
Epoch: 11 | Iteration number: [90/565] 15% | Training loss: 0.6948325369093153
Epoch: 11 | Iteration number: [100/565] 17% | Training loss: 0.6941039913892746
Epoch: 11 | Iteration number: [110/565] 19% | Training loss: 0.6934967891736464
Epoch: 11 | Iteration number: [120/565] 21% | Training loss: 0.6930126960078875
Epoch: 11 | Iteration number: [130/565] 23% | Training loss: 0.6925625090415661
Epoch: 11 | Iteration number: [140/565] 24% | Training loss: 0.6921937299626214
Epoch: 11 | Iteration number: [150/565] 26% | Training loss: 0.6918778530756633
Epoch: 11 | Iteration number: [160/565] 28% | Training loss: 0.6915772397071123
Epoch: 11 | Iteration number: [170/565] 30% | Training loss: 0.6913335694986231
Epoch: 11 | Iteration number: [180/565] 31% | Training loss: 0.6911333266231748
Epoch: 11 | Iteration number: [190/565] 33% | Training loss: 0.690944242477417
Epoch: 11 | Iteration number: [200/565] 35% | Training loss: 0.6907614421844482
Epoch: 11 | Iteration number: [210/565] 37% | Training loss: 0.6905889116582417
Epoch: 11 | Iteration number: [220/565] 38% | Training loss: 0.6904488918456164
Epoch: 11 | Iteration number: [230/565] 40% | Training loss: 0.6903176496858182
Epoch: 11 | Iteration number: [240/565] 42% | Training loss: 0.6902026484409968
Epoch: 11 | Iteration number: [250/565] 44% | Training loss: 0.6900875463485717
Epoch: 11 | Iteration number: [260/565] 46% | Training loss: 0.6899662102644261
Epoch: 11 | Iteration number: [270/565] 47% | Training loss: 0.6898758188441948
Epoch: 11 | Iteration number: [280/565] 49% | Training loss: 0.689792402940137
Epoch: 11 | Iteration number: [290/565] 51% | Training loss: 0.6896959115718974
Epoch: 11 | Iteration number: [300/565] 53% | Training loss: 0.6896005582809448
Epoch: 11 | Iteration number: [310/565] 54% | Training loss: 0.6895323655297679
Epoch: 11 | Iteration number: [320/565] 56% | Training loss: 0.689462105743587
Epoch: 11 | Iteration number: [330/565] 58% | Training loss: 0.6894093670628287
Epoch: 11 | Iteration number: [340/565] 60% | Training loss: 0.6893487739212373
Epoch: 11 | Iteration number: [350/565] 61% | Training loss: 0.6892724556582315
Epoch: 11 | Iteration number: [360/565] 63% | Training loss: 0.6892360361085997
Epoch: 11 | Iteration number: [370/565] 65% | Training loss: 0.6891809083319999
Epoch: 11 | Iteration number: [380/565] 67% | Training loss: 0.6891239483105509
Epoch: 11 | Iteration number: [390/565] 69% | Training loss: 0.6890654079425029
Epoch: 11 | Iteration number: [400/565] 70% | Training loss: 0.6890153031051159
Epoch: 11 | Iteration number: [410/565] 72% | Training loss: 0.6889649692105084
Epoch: 11 | Iteration number: [420/565] 74% | Training loss: 0.6889297591788428
Epoch: 11 | Iteration number: [430/565] 76% | Training loss: 0.6888977979504785
Epoch: 11 | Iteration number: [440/565] 77% | Training loss: 0.6888628329743038
Epoch: 11 | Iteration number: [450/565] 79% | Training loss: 0.6888284807735019
Epoch: 11 | Iteration number: [460/565] 81% | Training loss: 0.6888053984745689
Epoch: 11 | Iteration number: [470/565] 83% | Training loss: 0.6887712380987533
Epoch: 11 | Iteration number: [480/565] 84% | Training loss: 0.6887324202805758
Epoch: 11 | Iteration number: [490/565] 86% | Training loss: 0.6887124178360919
Epoch: 11 | Iteration number: [500/565] 88% | Training loss: 0.6886936599016189
Epoch: 11 | Iteration number: [510/565] 90% | Training loss: 0.6886648457424314
Epoch: 11 | Iteration number: [520/565] 92% | Training loss: 0.6886343323267423
Epoch: 11 | Iteration number: [530/565] 93% | Training loss: 0.6886012871310396
Epoch: 11 | Iteration number: [540/565] 95% | Training loss: 0.6885820192319375
Epoch: 11 | Iteration number: [550/565] 97% | Training loss: 0.688567819703709
Epoch: 11 | Iteration number: [560/565] 99% | Training loss: 0.6885378940829209

 End of epoch: 11 | Train Loss: 0.6873104434097763 | Training Time: 89 

 End of epoch: 11 | Eval Loss: 0.6897023916244507 | Evaluating Time: 6 
Epoch: 12 | Iteration number: [10/565] 1% | Training loss: 0.7560566008090973
Epoch: 12 | Iteration number: [20/565] 3% | Training loss: 0.7217100888490677
Epoch: 12 | Iteration number: [30/565] 5% | Training loss: 0.7101718584696451
Epoch: 12 | Iteration number: [40/565] 7% | Training loss: 0.7044647037982941
Epoch: 12 | Iteration number: [50/565] 8% | Training loss: 0.7010310578346253
Epoch: 12 | Iteration number: [60/565] 10% | Training loss: 0.6987094183762869
Epoch: 12 | Iteration number: [70/565] 12% | Training loss: 0.697114588533129
Epoch: 12 | Iteration number: [80/565] 14% | Training loss: 0.695916186273098
Epoch: 12 | Iteration number: [90/565] 15% | Training loss: 0.6949857122368283
Epoch: 12 | Iteration number: [100/565] 17% | Training loss: 0.6941996520757675
Epoch: 12 | Iteration number: [110/565] 19% | Training loss: 0.6935769780115648
Epoch: 12 | Iteration number: [120/565] 21% | Training loss: 0.6930712635318438
Epoch: 12 | Iteration number: [130/565] 23% | Training loss: 0.6926331377946413
Epoch: 12 | Iteration number: [140/565] 24% | Training loss: 0.6922374759401594
Epoch: 12 | Iteration number: [150/565] 26% | Training loss: 0.6919020954767863
Epoch: 12 | Iteration number: [160/565] 28% | Training loss: 0.6916160527616739
Epoch: 12 | Iteration number: [170/565] 30% | Training loss: 0.6913635878001942
Epoch: 12 | Iteration number: [180/565] 31% | Training loss: 0.6911261757214864
Epoch: 12 | Iteration number: [190/565] 33% | Training loss: 0.690918252970043
Epoch: 12 | Iteration number: [200/565] 35% | Training loss: 0.6907191768288612
Epoch: 12 | Iteration number: [210/565] 37% | Training loss: 0.6905538496517
Epoch: 12 | Iteration number: [220/565] 38% | Training loss: 0.6903993387113918
Epoch: 12 | Iteration number: [230/565] 40% | Training loss: 0.6902541997640029
Epoch: 12 | Iteration number: [240/565] 42% | Training loss: 0.6901348973313968
Epoch: 12 | Iteration number: [250/565] 44% | Training loss: 0.6900184879302979
Epoch: 12 | Iteration number: [260/565] 46% | Training loss: 0.6899034800437781
Epoch: 12 | Iteration number: [270/565] 47% | Training loss: 0.6897882942800169
Epoch: 12 | Iteration number: [280/565] 49% | Training loss: 0.6896899864077568
Epoch: 12 | Iteration number: [290/565] 51% | Training loss: 0.6896072506904602
Epoch: 12 | Iteration number: [300/565] 53% | Training loss: 0.6895191830396652
Epoch: 12 | Iteration number: [310/565] 54% | Training loss: 0.6894578666456284
Epoch: 12 | Iteration number: [320/565] 56% | Training loss: 0.6893802667036653
Epoch: 12 | Iteration number: [330/565] 58% | Training loss: 0.6893335828275392
Epoch: 12 | Iteration number: [340/565] 60% | Training loss: 0.6892815258573083
Epoch: 12 | Iteration number: [350/565] 61% | Training loss: 0.6892263465268271
Epoch: 12 | Iteration number: [360/565] 63% | Training loss: 0.6891615064607726
Epoch: 12 | Iteration number: [370/565] 65% | Training loss: 0.6890999847167247
Epoch: 12 | Iteration number: [380/565] 67% | Training loss: 0.6890421654048718
Epoch: 12 | Iteration number: [390/565] 69% | Training loss: 0.6889914796902583
Epoch: 12 | Iteration number: [400/565] 70% | Training loss: 0.6889482721686363
Epoch: 12 | Iteration number: [410/565] 72% | Training loss: 0.6888994264893415
Epoch: 12 | Iteration number: [420/565] 74% | Training loss: 0.6888638233854657
Epoch: 12 | Iteration number: [430/565] 76% | Training loss: 0.6888331532478332
Epoch: 12 | Iteration number: [440/565] 77% | Training loss: 0.6887983309951695
Epoch: 12 | Iteration number: [450/565] 79% | Training loss: 0.6887581961684757
Epoch: 12 | Iteration number: [460/565] 81% | Training loss: 0.6887286238048388
Epoch: 12 | Iteration number: [470/565] 83% | Training loss: 0.6886949719266688
Epoch: 12 | Iteration number: [480/565] 84% | Training loss: 0.6886646421005328
Epoch: 12 | Iteration number: [490/565] 86% | Training loss: 0.6886302864064976
Epoch: 12 | Iteration number: [500/565] 88% | Training loss: 0.6886023242473602
Epoch: 12 | Iteration number: [510/565] 90% | Training loss: 0.6885808312425427
Epoch: 12 | Iteration number: [520/565] 92% | Training loss: 0.6885595712524194
Epoch: 12 | Iteration number: [530/565] 93% | Training loss: 0.6885329174545576
Epoch: 12 | Iteration number: [540/565] 95% | Training loss: 0.688506172100703
Epoch: 12 | Iteration number: [550/565] 97% | Training loss: 0.6884844398498535
Epoch: 12 | Iteration number: [560/565] 99% | Training loss: 0.6884692595473357

 End of epoch: 12 | Train Loss: 0.6872463865617735 | Training Time: 89 

 End of epoch: 12 | Eval Loss: 0.689938851765224 | Evaluating Time: 6 
Epoch: 13 | Iteration number: [10/565] 1% | Training loss: 0.7557439088821412
Epoch: 13 | Iteration number: [20/565] 3% | Training loss: 0.7213559806346893
Epoch: 13 | Iteration number: [30/565] 5% | Training loss: 0.7099929591019948
Epoch: 13 | Iteration number: [40/565] 7% | Training loss: 0.7042549237608909
Epoch: 13 | Iteration number: [50/565] 8% | Training loss: 0.700893725156784
Epoch: 13 | Iteration number: [60/565] 10% | Training loss: 0.6985375215609868
Epoch: 13 | Iteration number: [70/565] 12% | Training loss: 0.6968864015170506
Epoch: 13 | Iteration number: [80/565] 14% | Training loss: 0.6956537909805774
Epoch: 13 | Iteration number: [90/565] 15% | Training loss: 0.6947396920786963
Epoch: 13 | Iteration number: [100/565] 17% | Training loss: 0.6939543110132217
Epoch: 13 | Iteration number: [110/565] 19% | Training loss: 0.6933948256752708
Epoch: 13 | Iteration number: [120/565] 21% | Training loss: 0.6928854137659073
Epoch: 13 | Iteration number: [130/565] 23% | Training loss: 0.6924567685677455
Epoch: 13 | Iteration number: [140/565] 24% | Training loss: 0.6920970682586942
Epoch: 13 | Iteration number: [150/565] 26% | Training loss: 0.6917716248830159
Epoch: 13 | Iteration number: [160/565] 28% | Training loss: 0.6914923533797264
Epoch: 13 | Iteration number: [170/565] 30% | Training loss: 0.691234330219381
Epoch: 13 | Iteration number: [180/565] 31% | Training loss: 0.6910355134142769
Epoch: 13 | Iteration number: [190/565] 33% | Training loss: 0.6908428192138671
Epoch: 13 | Iteration number: [200/565] 35% | Training loss: 0.6906501740217209
Epoch: 13 | Iteration number: [210/565] 37% | Training loss: 0.6904901107152303
Epoch: 13 | Iteration number: [220/565] 38% | Training loss: 0.6903113229708238
Epoch: 13 | Iteration number: [230/565] 40% | Training loss: 0.6901758069577424
Epoch: 13 | Iteration number: [240/565] 42% | Training loss: 0.6900506280362606
Epoch: 13 | Iteration number: [250/565] 44% | Training loss: 0.6899373843669891
Epoch: 13 | Iteration number: [260/565] 46% | Training loss: 0.6898287399457051
Epoch: 13 | Iteration number: [270/565] 47% | Training loss: 0.6897357545517109
Epoch: 13 | Iteration number: [280/565] 49% | Training loss: 0.6896479764154979
Epoch: 13 | Iteration number: [290/565] 51% | Training loss: 0.689563075221818
Epoch: 13 | Iteration number: [300/565] 53% | Training loss: 0.6894765867789586
Epoch: 13 | Iteration number: [310/565] 54% | Training loss: 0.6894131520102101
Epoch: 13 | Iteration number: [320/565] 56% | Training loss: 0.6893393846228719
Epoch: 13 | Iteration number: [330/565] 58% | Training loss: 0.6892807778083917
Epoch: 13 | Iteration number: [340/565] 60% | Training loss: 0.6892186876605538
Epoch: 13 | Iteration number: [350/565] 61% | Training loss: 0.6891669060502733
Epoch: 13 | Iteration number: [360/565] 63% | Training loss: 0.6891113816036119
Epoch: 13 | Iteration number: [370/565] 65% | Training loss: 0.6890482014900929
Epoch: 13 | Iteration number: [380/565] 67% | Training loss: 0.689007652433295
Epoch: 13 | Iteration number: [390/565] 69% | Training loss: 0.6889443337917328
Epoch: 13 | Iteration number: [400/565] 70% | Training loss: 0.6889058250188828
Epoch: 13 | Iteration number: [410/565] 72% | Training loss: 0.6888613053938237
Epoch: 13 | Iteration number: [420/565] 74% | Training loss: 0.6888244687091737
Epoch: 13 | Iteration number: [430/565] 76% | Training loss: 0.6887896663920824
Epoch: 13 | Iteration number: [440/565] 77% | Training loss: 0.6887608570131388
Epoch: 13 | Iteration number: [450/565] 79% | Training loss: 0.6887103490034739
Epoch: 13 | Iteration number: [460/565] 81% | Training loss: 0.688669019419214
Epoch: 13 | Iteration number: [470/565] 83% | Training loss: 0.6886267057124604
Epoch: 13 | Iteration number: [480/565] 84% | Training loss: 0.6886118212093909
Epoch: 13 | Iteration number: [490/565] 86% | Training loss: 0.6885774443344194
Epoch: 13 | Iteration number: [500/565] 88% | Training loss: 0.6885470077991486
Epoch: 13 | Iteration number: [510/565] 90% | Training loss: 0.6885180319056792
Epoch: 13 | Iteration number: [520/565] 92% | Training loss: 0.6884937177483852
Epoch: 13 | Iteration number: [530/565] 93% | Training loss: 0.6884685887480682
Epoch: 13 | Iteration number: [540/565] 95% | Training loss: 0.6884468248596898
Epoch: 13 | Iteration number: [550/565] 97% | Training loss: 0.6884248306534507
Epoch: 13 | Iteration number: [560/565] 99% | Training loss: 0.6883933474974973

 End of epoch: 13 | Train Loss: 0.6871661569164917 | Training Time: 90 

 End of epoch: 13 | Eval Loss: 0.689880541392735 | Evaluating Time: 6 
Epoch: 14 | Iteration number: [10/565] 1% | Training loss: 0.755630886554718
Epoch: 14 | Iteration number: [20/565] 3% | Training loss: 0.721366360783577
Epoch: 14 | Iteration number: [30/565] 5% | Training loss: 0.7098280429840088
Epoch: 14 | Iteration number: [40/565] 7% | Training loss: 0.7042233273386955
Epoch: 14 | Iteration number: [50/565] 8% | Training loss: 0.7006991350650787
Epoch: 14 | Iteration number: [60/565] 10% | Training loss: 0.6983750472466151
Epoch: 14 | Iteration number: [70/565] 12% | Training loss: 0.6967802124364035
Epoch: 14 | Iteration number: [80/565] 14% | Training loss: 0.695511594414711
Epoch: 14 | Iteration number: [90/565] 15% | Training loss: 0.6946226583586799
Epoch: 14 | Iteration number: [100/565] 17% | Training loss: 0.6939237117767334
Epoch: 14 | Iteration number: [110/565] 19% | Training loss: 0.6933029006827961
Epoch: 14 | Iteration number: [120/565] 21% | Training loss: 0.6928179368376732
Epoch: 14 | Iteration number: [130/565] 23% | Training loss: 0.6924043907569005
Epoch: 14 | Iteration number: [140/565] 24% | Training loss: 0.6920240270239967
Epoch: 14 | Iteration number: [150/565] 26% | Training loss: 0.691710631052653
Epoch: 14 | Iteration number: [160/565] 28% | Training loss: 0.6914212472736836
Epoch: 14 | Iteration number: [170/565] 30% | Training loss: 0.6911793137297911
Epoch: 14 | Iteration number: [180/565] 31% | Training loss: 0.6909424202309714
Epoch: 14 | Iteration number: [190/565] 33% | Training loss: 0.6907531964151483
Epoch: 14 | Iteration number: [200/565] 35% | Training loss: 0.6905683526396751
Epoch: 14 | Iteration number: [210/565] 37% | Training loss: 0.6903946493353162
Epoch: 14 | Iteration number: [220/565] 38% | Training loss: 0.6902409133586016
Epoch: 14 | Iteration number: [230/565] 40% | Training loss: 0.6900941833205845
Epoch: 14 | Iteration number: [240/565] 42% | Training loss: 0.6899683726330598
Epoch: 14 | Iteration number: [250/565] 44% | Training loss: 0.6898685591220856
Epoch: 14 | Iteration number: [260/565] 46% | Training loss: 0.6897639201237605
Epoch: 14 | Iteration number: [270/565] 47% | Training loss: 0.6896684249242147
Epoch: 14 | Iteration number: [280/565] 49% | Training loss: 0.6895865832056318
Epoch: 14 | Iteration number: [290/565] 51% | Training loss: 0.6894979129577505
Epoch: 14 | Iteration number: [300/565] 53% | Training loss: 0.6894141346216202
Epoch: 14 | Iteration number: [310/565] 54% | Training loss: 0.68933740392808
Epoch: 14 | Iteration number: [320/565] 56% | Training loss: 0.6892806928604841
Epoch: 14 | Iteration number: [330/565] 58% | Training loss: 0.6892366530317249
Epoch: 14 | Iteration number: [340/565] 60% | Training loss: 0.6891756282133215
Epoch: 14 | Iteration number: [350/565] 61% | Training loss: 0.6891302817208427
Epoch: 14 | Iteration number: [360/565] 63% | Training loss: 0.6890705847077899
Epoch: 14 | Iteration number: [370/565] 65% | Training loss: 0.6890239966882242
Epoch: 14 | Iteration number: [380/565] 67% | Training loss: 0.6889813327475598
Epoch: 14 | Iteration number: [390/565] 69% | Training loss: 0.6889338361911285
Epoch: 14 | Iteration number: [400/565] 70% | Training loss: 0.6888940340280533
Epoch: 14 | Iteration number: [410/565] 72% | Training loss: 0.6888481257892236
Epoch: 14 | Iteration number: [420/565] 74% | Training loss: 0.6888171547935122
Epoch: 14 | Iteration number: [430/565] 76% | Training loss: 0.6887804836727852
Epoch: 14 | Iteration number: [440/565] 77% | Training loss: 0.6887463197112084
Epoch: 14 | Iteration number: [450/565] 79% | Training loss: 0.6887088170316484
Epoch: 14 | Iteration number: [460/565] 81% | Training loss: 0.6886667074068733
Epoch: 14 | Iteration number: [470/565] 83% | Training loss: 0.6886327796793998
Epoch: 14 | Iteration number: [480/565] 84% | Training loss: 0.688598348821203
Epoch: 14 | Iteration number: [490/565] 86% | Training loss: 0.6885655785093502
Epoch: 14 | Iteration number: [500/565] 88% | Training loss: 0.6885409277677536
Epoch: 14 | Iteration number: [510/565] 90% | Training loss: 0.6885046908668443
Epoch: 14 | Iteration number: [520/565] 92% | Training loss: 0.6884846278108083
Epoch: 14 | Iteration number: [530/565] 93% | Training loss: 0.6884539613183939
Epoch: 14 | Iteration number: [540/565] 95% | Training loss: 0.6884274042314953
Epoch: 14 | Iteration number: [550/565] 97% | Training loss: 0.6884034216403961
Epoch: 14 | Iteration number: [560/565] 99% | Training loss: 0.6883816967053072

 End of epoch: 14 | Train Loss: 0.6871507070760812 | Training Time: 89 

 End of epoch: 14 | Eval Loss: 0.6892851931708199 | Evaluating Time: 6 
Epoch: 15 | Iteration number: [10/565] 1% | Training loss: 0.7551453232765197
Epoch: 15 | Iteration number: [20/565] 3% | Training loss: 0.7209047764539719
Epoch: 15 | Iteration number: [30/565] 5% | Training loss: 0.709636531273524
Epoch: 15 | Iteration number: [40/565] 7% | Training loss: 0.7040626615285873
Epoch: 15 | Iteration number: [50/565] 8% | Training loss: 0.7006932604312897
Epoch: 15 | Iteration number: [60/565] 10% | Training loss: 0.6984622657299042
Epoch: 15 | Iteration number: [70/565] 12% | Training loss: 0.6968117279665811
Epoch: 15 | Iteration number: [80/565] 14% | Training loss: 0.695585610717535
Epoch: 15 | Iteration number: [90/565] 15% | Training loss: 0.6946067505412632
Epoch: 15 | Iteration number: [100/565] 17% | Training loss: 0.6938525795936584
Epoch: 15 | Iteration number: [110/565] 19% | Training loss: 0.6932222182100469
Epoch: 15 | Iteration number: [120/565] 21% | Training loss: 0.6927306686838468
Epoch: 15 | Iteration number: [130/565] 23% | Training loss: 0.6923005658846635
Epoch: 15 | Iteration number: [140/565] 24% | Training loss: 0.6919672186885562
Epoch: 15 | Iteration number: [150/565] 26% | Training loss: 0.6916635044415792
Epoch: 15 | Iteration number: [160/565] 28% | Training loss: 0.6913764476776123
Epoch: 15 | Iteration number: [170/565] 30% | Training loss: 0.6911347876576817
Epoch: 15 | Iteration number: [180/565] 31% | Training loss: 0.6909051971303092
Epoch: 15 | Iteration number: [190/565] 33% | Training loss: 0.690697990906866
Epoch: 15 | Iteration number: [200/565] 35% | Training loss: 0.6905397748947144
Epoch: 15 | Iteration number: [210/565] 37% | Training loss: 0.6903682898907434
Epoch: 15 | Iteration number: [220/565] 38% | Training loss: 0.6902201137759468
Epoch: 15 | Iteration number: [230/565] 40% | Training loss: 0.6900801995526189
Epoch: 15 | Iteration number: [240/565] 42% | Training loss: 0.68997295871377
Epoch: 15 | Iteration number: [250/565] 44% | Training loss: 0.6898757591247558
Epoch: 15 | Iteration number: [260/565] 46% | Training loss: 0.6897856810918221
Epoch: 15 | Iteration number: [270/565] 47% | Training loss: 0.6896811759030378
Epoch: 15 | Iteration number: [280/565] 49% | Training loss: 0.6895607920629637
Epoch: 15 | Iteration number: [290/565] 51% | Training loss: 0.6894822211101137
Epoch: 15 | Iteration number: [300/565] 53% | Training loss: 0.6894129955768585
Epoch: 15 | Iteration number: [310/565] 54% | Training loss: 0.6893267902635759
Epoch: 15 | Iteration number: [320/565] 56% | Training loss: 0.6892628233879805
Epoch: 15 | Iteration number: [330/565] 58% | Training loss: 0.6891889135042827
Epoch: 15 | Iteration number: [340/565] 60% | Training loss: 0.6891330953906564
Epoch: 15 | Iteration number: [350/565] 61% | Training loss: 0.6890579898016793
Epoch: 15 | Iteration number: [360/565] 63% | Training loss: 0.6890177893969748
Epoch: 15 | Iteration number: [370/565] 65% | Training loss: 0.6889559053085946
Epoch: 15 | Iteration number: [380/565] 67% | Training loss: 0.6888889463324296
Epoch: 15 | Iteration number: [390/565] 69% | Training loss: 0.6888426423072815
Epoch: 15 | Iteration number: [400/565] 70% | Training loss: 0.6888000018894672
Epoch: 15 | Iteration number: [410/565] 72% | Training loss: 0.6887613101703365
Epoch: 15 | Iteration number: [420/565] 74% | Training loss: 0.6887157028629667
Epoch: 15 | Iteration number: [430/565] 76% | Training loss: 0.6886848686739456
Epoch: 15 | Iteration number: [440/565] 77% | Training loss: 0.68864375366406
Epoch: 15 | Iteration number: [450/565] 79% | Training loss: 0.6885976004600525
Epoch: 15 | Iteration number: [460/565] 81% | Training loss: 0.6885680473369101
Epoch: 15 | Iteration number: [470/565] 83% | Training loss: 0.6885394971421425
Epoch: 15 | Iteration number: [480/565] 84% | Training loss: 0.6885215828816096
Epoch: 15 | Iteration number: [490/565] 86% | Training loss: 0.6884976255650423
Epoch: 15 | Iteration number: [500/565] 88% | Training loss: 0.6884692186117172
Epoch: 15 | Iteration number: [510/565] 90% | Training loss: 0.688443639348535
Epoch: 15 | Iteration number: [520/565] 92% | Training loss: 0.6884208164536036
Epoch: 15 | Iteration number: [530/565] 93% | Training loss: 0.6883963151922766
Epoch: 15 | Iteration number: [540/565] 95% | Training loss: 0.6883759940112079
Epoch: 15 | Iteration number: [550/565] 97% | Training loss: 0.6883566206151789
Epoch: 15 | Iteration number: [560/565] 99% | Training loss: 0.6883300524737154

 End of epoch: 15 | Train Loss: 0.6870939745312243 | Training Time: 89 

 End of epoch: 15 | Eval Loss: 0.6898085645266941 | Evaluating Time: 6 
Epoch: 16 | Iteration number: [10/565] 1% | Training loss: 0.7554616034030914
Epoch: 16 | Iteration number: [20/565] 3% | Training loss: 0.7212530970573425
Epoch: 16 | Iteration number: [30/565] 5% | Training loss: 0.7097487449645996
Epoch: 16 | Iteration number: [40/565] 7% | Training loss: 0.704025861620903
Epoch: 16 | Iteration number: [50/565] 8% | Training loss: 0.7006009590625762
Epoch: 16 | Iteration number: [60/565] 10% | Training loss: 0.6982747008403142
Epoch: 16 | Iteration number: [70/565] 12% | Training loss: 0.6966558345726558
Epoch: 16 | Iteration number: [80/565] 14% | Training loss: 0.6954600073397159
Epoch: 16 | Iteration number: [90/565] 15% | Training loss: 0.6945428272088369
Epoch: 16 | Iteration number: [100/565] 17% | Training loss: 0.6937841683626175
Epoch: 16 | Iteration number: [110/565] 19% | Training loss: 0.6931380564516241
Epoch: 16 | Iteration number: [120/565] 21% | Training loss: 0.6926291366418202
Epoch: 16 | Iteration number: [130/565] 23% | Training loss: 0.6921946479724004
Epoch: 16 | Iteration number: [140/565] 24% | Training loss: 0.691821225626128
Epoch: 16 | Iteration number: [150/565] 26% | Training loss: 0.6914859131971995
Epoch: 16 | Iteration number: [160/565] 28% | Training loss: 0.6911971237510443
Epoch: 16 | Iteration number: [170/565] 30% | Training loss: 0.6909482072381412
Epoch: 16 | Iteration number: [180/565] 31% | Training loss: 0.6907368848721186
Epoch: 16 | Iteration number: [190/565] 33% | Training loss: 0.6905190383133135
Epoch: 16 | Iteration number: [200/565] 35% | Training loss: 0.6903485110402108
Epoch: 16 | Iteration number: [210/565] 37% | Training loss: 0.6901892886275337
Epoch: 16 | Iteration number: [220/565] 38% | Training loss: 0.6900441763075915
Epoch: 16 | Iteration number: [230/565] 40% | Training loss: 0.6899209431979967
Epoch: 16 | Iteration number: [240/565] 42% | Training loss: 0.6897851077218851
Epoch: 16 | Iteration number: [250/565] 44% | Training loss: 0.6896681790351867
Epoch: 16 | Iteration number: [260/565] 46% | Training loss: 0.6895846029886833
Epoch: 16 | Iteration number: [270/565] 47% | Training loss: 0.6894968937944483
Epoch: 16 | Iteration number: [280/565] 49% | Training loss: 0.6894145942160061
Epoch: 16 | Iteration number: [290/565] 51% | Training loss: 0.6893340275205415
Epoch: 16 | Iteration number: [300/565] 53% | Training loss: 0.6892709561189015
Epoch: 16 | Iteration number: [310/565] 54% | Training loss: 0.6891789230608171
Epoch: 16 | Iteration number: [320/565] 56% | Training loss: 0.6891068505123258
Epoch: 16 | Iteration number: [330/565] 58% | Training loss: 0.6890631708231839
Epoch: 16 | Iteration number: [340/565] 60% | Training loss: 0.6890100659692988
Epoch: 16 | Iteration number: [350/565] 61% | Training loss: 0.6889623161724635
Epoch: 16 | Iteration number: [360/565] 63% | Training loss: 0.6889156502154138
Epoch: 16 | Iteration number: [370/565] 65% | Training loss: 0.6888616215538335
Epoch: 16 | Iteration number: [380/565] 67% | Training loss: 0.6888108120152825
Epoch: 16 | Iteration number: [390/565] 69% | Training loss: 0.6887727994185228
Epoch: 16 | Iteration number: [400/565] 70% | Training loss: 0.6887276102602482
Epoch: 16 | Iteration number: [410/565] 72% | Training loss: 0.6886880740886782
Epoch: 16 | Iteration number: [420/565] 74% | Training loss: 0.688659346245584
Epoch: 16 | Iteration number: [430/565] 76% | Training loss: 0.6886311704336211
Epoch: 16 | Iteration number: [440/565] 77% | Training loss: 0.6886052273891189
Epoch: 16 | Iteration number: [450/565] 79% | Training loss: 0.6885706108146243
Epoch: 16 | Iteration number: [460/565] 81% | Training loss: 0.6885486335858054
Epoch: 16 | Iteration number: [470/565] 83% | Training loss: 0.6885088792506685
Epoch: 16 | Iteration number: [480/565] 84% | Training loss: 0.6884876824915409
Epoch: 16 | Iteration number: [490/565] 86% | Training loss: 0.6884649405674058
Epoch: 16 | Iteration number: [500/565] 88% | Training loss: 0.6884347239732742
Epoch: 16 | Iteration number: [510/565] 90% | Training loss: 0.6884063519683539
Epoch: 16 | Iteration number: [520/565] 92% | Training loss: 0.6883892031816335
Epoch: 16 | Iteration number: [530/565] 93% | Training loss: 0.6883677532088082
Epoch: 16 | Iteration number: [540/565] 95% | Training loss: 0.6883374664518568
Epoch: 16 | Iteration number: [550/565] 97% | Training loss: 0.6883149553428997
Epoch: 16 | Iteration number: [560/565] 99% | Training loss: 0.6882931177105223

 End of epoch: 16 | Train Loss: 0.6870645983029255 | Training Time: 89 

 End of epoch: 16 | Eval Loss: 0.6896770511354718 | Evaluating Time: 6 
Epoch: 17 | Iteration number: [10/565] 1% | Training loss: 0.7559790968894958
Epoch: 17 | Iteration number: [20/565] 3% | Training loss: 0.7215884506702424
Epoch: 17 | Iteration number: [30/565] 5% | Training loss: 0.7099826037883759
Epoch: 17 | Iteration number: [40/565] 7% | Training loss: 0.7042265325784683
Epoch: 17 | Iteration number: [50/565] 8% | Training loss: 0.7007367873191833
Epoch: 17 | Iteration number: [60/565] 10% | Training loss: 0.6985842694838842
Epoch: 17 | Iteration number: [70/565] 12% | Training loss: 0.6968782646315438
Epoch: 17 | Iteration number: [80/565] 14% | Training loss: 0.695666478574276
Epoch: 17 | Iteration number: [90/565] 15% | Training loss: 0.6946559482150607
Epoch: 17 | Iteration number: [100/565] 17% | Training loss: 0.6939078551530838
Epoch: 17 | Iteration number: [110/565] 19% | Training loss: 0.6933341356841001
Epoch: 17 | Iteration number: [120/565] 21% | Training loss: 0.6928248797853788
Epoch: 17 | Iteration number: [130/565] 23% | Training loss: 0.6923488814097184
Epoch: 17 | Iteration number: [140/565] 24% | Training loss: 0.6919697493314743
Epoch: 17 | Iteration number: [150/565] 26% | Training loss: 0.6916571354866028
Epoch: 17 | Iteration number: [160/565] 28% | Training loss: 0.6913712281733752
Epoch: 17 | Iteration number: [170/565] 30% | Training loss: 0.6911112851956311
Epoch: 17 | Iteration number: [180/565] 31% | Training loss: 0.6908853219615089
Epoch: 17 | Iteration number: [190/565] 33% | Training loss: 0.6906925392778296
Epoch: 17 | Iteration number: [200/565] 35% | Training loss: 0.6905055397748947
Epoch: 17 | Iteration number: [210/565] 37% | Training loss: 0.6903280178705852
Epoch: 17 | Iteration number: [220/565] 38% | Training loss: 0.6901780965653332
Epoch: 17 | Iteration number: [230/565] 40% | Training loss: 0.6900238438792851
Epoch: 17 | Iteration number: [240/565] 42% | Training loss: 0.6898998436828454
Epoch: 17 | Iteration number: [250/565] 44% | Training loss: 0.6897904872894287
Epoch: 17 | Iteration number: [260/565] 46% | Training loss: 0.6896994987359414
Epoch: 17 | Iteration number: [270/565] 47% | Training loss: 0.6896222048335605
Epoch: 17 | Iteration number: [280/565] 49% | Training loss: 0.6895448316420828
Epoch: 17 | Iteration number: [290/565] 51% | Training loss: 0.6894606308690433
Epoch: 17 | Iteration number: [300/565] 53% | Training loss: 0.6893715622027715
Epoch: 17 | Iteration number: [310/565] 54% | Training loss: 0.6892878947719451
Epoch: 17 | Iteration number: [320/565] 56% | Training loss: 0.6892157275229692
Epoch: 17 | Iteration number: [330/565] 58% | Training loss: 0.6891662510958585
Epoch: 17 | Iteration number: [340/565] 60% | Training loss: 0.6891009311465656
Epoch: 17 | Iteration number: [350/565] 61% | Training loss: 0.6890441426209041
Epoch: 17 | Iteration number: [360/565] 63% | Training loss: 0.6889999061822891
Epoch: 17 | Iteration number: [370/565] 65% | Training loss: 0.6889422956350687
Epoch: 17 | Iteration number: [380/565] 67% | Training loss: 0.6888961083010623
Epoch: 17 | Iteration number: [390/565] 69% | Training loss: 0.6888479611812494
Epoch: 17 | Iteration number: [400/565] 70% | Training loss: 0.6888039809465408
Epoch: 17 | Iteration number: [410/565] 72% | Training loss: 0.6887617054508953
Epoch: 17 | Iteration number: [420/565] 74% | Training loss: 0.6887119738828569
Epoch: 17 | Iteration number: [430/565] 76% | Training loss: 0.6886563208214073
Epoch: 17 | Iteration number: [440/565] 77% | Training loss: 0.6886247656562111
Epoch: 17 | Iteration number: [450/565] 79% | Training loss: 0.6885879545741611
Epoch: 17 | Iteration number: [460/565] 81% | Training loss: 0.6885536429674729
Epoch: 17 | Iteration number: [470/565] 83% | Training loss: 0.6885199111826876
Epoch: 17 | Iteration number: [480/565] 84% | Training loss: 0.6884965137888988
Epoch: 17 | Iteration number: [490/565] 86% | Training loss: 0.6884645519207935
Epoch: 17 | Iteration number: [500/565] 88% | Training loss: 0.6884402394294739
Epoch: 17 | Iteration number: [510/565] 90% | Training loss: 0.6884070997144661
Epoch: 17 | Iteration number: [520/565] 92% | Training loss: 0.6883817178698687
Epoch: 17 | Iteration number: [530/565] 93% | Training loss: 0.6883562841505374
Epoch: 17 | Iteration number: [540/565] 95% | Training loss: 0.688332247182175
Epoch: 17 | Iteration number: [550/565] 97% | Training loss: 0.6883120390501889
Epoch: 17 | Iteration number: [560/565] 99% | Training loss: 0.688287683150598

 End of epoch: 17 | Train Loss: 0.68706172029529 | Training Time: 89 

 End of epoch: 17 | Eval Loss: 0.6899315799985614 | Evaluating Time: 6 
Epoch: 18 | Iteration number: [10/565] 1% | Training loss: 0.7557957112789154
Epoch: 18 | Iteration number: [20/565] 3% | Training loss: 0.7212460309267044
Epoch: 18 | Iteration number: [30/565] 5% | Training loss: 0.7097711980342865
Epoch: 18 | Iteration number: [40/565] 7% | Training loss: 0.7040730193257332
Epoch: 18 | Iteration number: [50/565] 8% | Training loss: 0.7006930422782898
Epoch: 18 | Iteration number: [60/565] 10% | Training loss: 0.6984195987383525
Epoch: 18 | Iteration number: [70/565] 12% | Training loss: 0.6968066487993513
Epoch: 18 | Iteration number: [80/565] 14% | Training loss: 0.6956400148570537
Epoch: 18 | Iteration number: [90/565] 15% | Training loss: 0.6946869942877028
Epoch: 18 | Iteration number: [100/565] 17% | Training loss: 0.6939275223016739
Epoch: 18 | Iteration number: [110/565] 19% | Training loss: 0.693279524824836
Epoch: 18 | Iteration number: [120/565] 21% | Training loss: 0.6927776351571083
Epoch: 18 | Iteration number: [130/565] 23% | Training loss: 0.6923261261903323
Epoch: 18 | Iteration number: [140/565] 24% | Training loss: 0.6919428186757224
Epoch: 18 | Iteration number: [150/565] 26% | Training loss: 0.6916245079040527
Epoch: 18 | Iteration number: [160/565] 28% | Training loss: 0.6913200046867132
Epoch: 18 | Iteration number: [170/565] 30% | Training loss: 0.6910537242889404
Epoch: 18 | Iteration number: [180/565] 31% | Training loss: 0.6908122059371736
Epoch: 18 | Iteration number: [190/565] 33% | Training loss: 0.690615229230178
Epoch: 18 | Iteration number: [200/565] 35% | Training loss: 0.6904254001379013
Epoch: 18 | Iteration number: [210/565] 37% | Training loss: 0.6902582801523662
Epoch: 18 | Iteration number: [220/565] 38% | Training loss: 0.6901373386383056
Epoch: 18 | Iteration number: [230/565] 40% | Training loss: 0.6900090987267702
Epoch: 18 | Iteration number: [240/565] 42% | Training loss: 0.6898902696867784
Epoch: 18 | Iteration number: [250/565] 44% | Training loss: 0.6897797081470489
Epoch: 18 | Iteration number: [260/565] 46% | Training loss: 0.6896840102397479
Epoch: 18 | Iteration number: [270/565] 47% | Training loss: 0.689586497898455
Epoch: 18 | Iteration number: [280/565] 49% | Training loss: 0.689496325807912
Epoch: 18 | Iteration number: [290/565] 51% | Training loss: 0.6893972670209819
Epoch: 18 | Iteration number: [300/565] 53% | Training loss: 0.6893229470650355
Epoch: 18 | Iteration number: [310/565] 54% | Training loss: 0.6892578863328503
Epoch: 18 | Iteration number: [320/565] 56% | Training loss: 0.6891936445608735
Epoch: 18 | Iteration number: [330/565] 58% | Training loss: 0.6891313263864228
Epoch: 18 | Iteration number: [340/565] 60% | Training loss: 0.6890623788623249
Epoch: 18 | Iteration number: [350/565] 61% | Training loss: 0.6890132711614881
Epoch: 18 | Iteration number: [360/565] 63% | Training loss: 0.6889432402120697
Epoch: 18 | Iteration number: [370/565] 65% | Training loss: 0.6888837685456147
Epoch: 18 | Iteration number: [380/565] 67% | Training loss: 0.6888372377345436
Epoch: 18 | Iteration number: [390/565] 69% | Training loss: 0.688784588758762
Epoch: 18 | Iteration number: [400/565] 70% | Training loss: 0.6887317162752151
Epoch: 18 | Iteration number: [410/565] 72% | Training loss: 0.688676120449857
Epoch: 18 | Iteration number: [420/565] 74% | Training loss: 0.6886405553136553
Epoch: 18 | Iteration number: [430/565] 76% | Training loss: 0.6885994078114975
Epoch: 18 | Iteration number: [440/565] 77% | Training loss: 0.6885580136017366
Epoch: 18 | Iteration number: [450/565] 79% | Training loss: 0.6885241968101925
Epoch: 18 | Iteration number: [460/565] 81% | Training loss: 0.6884923798882443
Epoch: 18 | Iteration number: [470/565] 83% | Training loss: 0.6884700643255356
Epoch: 18 | Iteration number: [480/565] 84% | Training loss: 0.6884499444315831
Epoch: 18 | Iteration number: [490/565] 86% | Training loss: 0.6884213440272273
Epoch: 18 | Iteration number: [500/565] 88% | Training loss: 0.6884016673564911
Epoch: 18 | Iteration number: [510/565] 90% | Training loss: 0.6883816371945773
Epoch: 18 | Iteration number: [520/565] 92% | Training loss: 0.6883470832155301
Epoch: 18 | Iteration number: [530/565] 93% | Training loss: 0.688326045027319
Epoch: 18 | Iteration number: [540/565] 95% | Training loss: 0.6883059980692687
Epoch: 18 | Iteration number: [550/565] 97% | Training loss: 0.6882852037386461
Epoch: 18 | Iteration number: [560/565] 99% | Training loss: 0.6882527601506029

 End of epoch: 18 | Train Loss: 0.6870232819455915 | Training Time: 89 

 End of epoch: 18 | Eval Loss: 0.6896048358508519 | Evaluating Time: 6 
Epoch: 19 | Iteration number: [10/565] 1% | Training loss: 0.7554760158061982
Epoch: 19 | Iteration number: [20/565] 3% | Training loss: 0.7211891621351242
Epoch: 19 | Iteration number: [30/565] 5% | Training loss: 0.7097800493240356
Epoch: 19 | Iteration number: [40/565] 7% | Training loss: 0.7039429605007171
Epoch: 19 | Iteration number: [50/565] 8% | Training loss: 0.7005412518978119
Epoch: 19 | Iteration number: [60/565] 10% | Training loss: 0.6982874353726705
Epoch: 19 | Iteration number: [70/565] 12% | Training loss: 0.6967336978231158
Epoch: 19 | Iteration number: [80/565] 14% | Training loss: 0.6955605626106263
Epoch: 19 | Iteration number: [90/565] 15% | Training loss: 0.6946265644497341
Epoch: 19 | Iteration number: [100/565] 17% | Training loss: 0.6938681203126907
Epoch: 19 | Iteration number: [110/565] 19% | Training loss: 0.6932613015174866
Epoch: 19 | Iteration number: [120/565] 21% | Training loss: 0.692713682850202
Epoch: 19 | Iteration number: [130/565] 23% | Training loss: 0.6922707718152267
Epoch: 19 | Iteration number: [140/565] 24% | Training loss: 0.6919254256146294
Epoch: 19 | Iteration number: [150/565] 26% | Training loss: 0.6915867408116658
Epoch: 19 | Iteration number: [160/565] 28% | Training loss: 0.6913073226809502
Epoch: 19 | Iteration number: [170/565] 30% | Training loss: 0.6910488170735977
Epoch: 19 | Iteration number: [180/565] 31% | Training loss: 0.6908385876152251
Epoch: 19 | Iteration number: [190/565] 33% | Training loss: 0.6906428970788655
Epoch: 19 | Iteration number: [200/565] 35% | Training loss: 0.6904539602994919
Epoch: 19 | Iteration number: [210/565] 37% | Training loss: 0.6903054927076612
Epoch: 19 | Iteration number: [220/565] 38% | Training loss: 0.6901385291056199
Epoch: 19 | Iteration number: [230/565] 40% | Training loss: 0.6899969720322153
Epoch: 19 | Iteration number: [240/565] 42% | Training loss: 0.6898674500485261
Epoch: 19 | Iteration number: [250/565] 44% | Training loss: 0.689752099275589
Epoch: 19 | Iteration number: [260/565] 46% | Training loss: 0.6896510883019521
Epoch: 19 | Iteration number: [270/565] 47% | Training loss: 0.6895396605685905
Epoch: 19 | Iteration number: [280/565] 49% | Training loss: 0.6894483919654574
Epoch: 19 | Iteration number: [290/565] 51% | Training loss: 0.6893840072483852
Epoch: 19 | Iteration number: [300/565] 53% | Training loss: 0.6892957429091136
Epoch: 19 | Iteration number: [310/565] 54% | Training loss: 0.6892346924351108
Epoch: 19 | Iteration number: [320/565] 56% | Training loss: 0.6891593189910055
Epoch: 19 | Iteration number: [330/565] 58% | Training loss: 0.6890893157684441
Epoch: 19 | Iteration number: [340/565] 60% | Training loss: 0.6890265219351824
Epoch: 19 | Iteration number: [350/565] 61% | Training loss: 0.688956492458071
Epoch: 19 | Iteration number: [360/565] 63% | Training loss: 0.6889102917578486
Epoch: 19 | Iteration number: [370/565] 65% | Training loss: 0.6888579191388311
Epoch: 19 | Iteration number: [380/565] 67% | Training loss: 0.6888016568986993
Epoch: 19 | Iteration number: [390/565] 69% | Training loss: 0.6887586546249879
Epoch: 19 | Iteration number: [400/565] 70% | Training loss: 0.6887133745849132
Epoch: 19 | Iteration number: [410/565] 72% | Training loss: 0.6886670047190131
Epoch: 19 | Iteration number: [420/565] 74% | Training loss: 0.6886244524092902
Epoch: 19 | Iteration number: [430/565] 76% | Training loss: 0.688587967185087
Epoch: 19 | Iteration number: [440/565] 77% | Training loss: 0.6885495368729938
Epoch: 19 | Iteration number: [450/565] 79% | Training loss: 0.688527704609765
Epoch: 19 | Iteration number: [460/565] 81% | Training loss: 0.6884936558163685
Epoch: 19 | Iteration number: [470/565] 83% | Training loss: 0.6884628459494164
Epoch: 19 | Iteration number: [480/565] 84% | Training loss: 0.6884386584162712
Epoch: 19 | Iteration number: [490/565] 86% | Training loss: 0.6884109298793637
Epoch: 19 | Iteration number: [500/565] 88% | Training loss: 0.6883823416233062
Epoch: 19 | Iteration number: [510/565] 90% | Training loss: 0.6883507449252932
Epoch: 19 | Iteration number: [520/565] 92% | Training loss: 0.6883194143955524
Epoch: 19 | Iteration number: [530/565] 93% | Training loss: 0.6882986872825982
Epoch: 19 | Iteration number: [540/565] 95% | Training loss: 0.6882748916193291
Epoch: 19 | Iteration number: [550/565] 97% | Training loss: 0.6882569551467895
Epoch: 19 | Iteration number: [560/565] 99% | Training loss: 0.68824237542493

 End of epoch: 19 | Train Loss: 0.6870134307219918 | Training Time: 89 

 End of epoch: 19 | Eval Loss: 0.6891855256898063 | Evaluating Time: 6 
Epoch: 20 | Iteration number: [10/565] 1% | Training loss: 0.7557535350322724
Epoch: 20 | Iteration number: [20/565] 3% | Training loss: 0.7212487816810608
Epoch: 20 | Iteration number: [30/565] 5% | Training loss: 0.7099317650000254
Epoch: 20 | Iteration number: [40/565] 7% | Training loss: 0.7041886448860168
Epoch: 20 | Iteration number: [50/565] 8% | Training loss: 0.7007640516757965
Epoch: 20 | Iteration number: [60/565] 10% | Training loss: 0.6984675904115041
Epoch: 20 | Iteration number: [70/565] 12% | Training loss: 0.696854316336768
Epoch: 20 | Iteration number: [80/565] 14% | Training loss: 0.695635174959898
Epoch: 20 | Iteration number: [90/565] 15% | Training loss: 0.694656083981196
Epoch: 20 | Iteration number: [100/565] 17% | Training loss: 0.693916871547699
Epoch: 20 | Iteration number: [110/565] 19% | Training loss: 0.6933154810558666
Epoch: 20 | Iteration number: [120/565] 21% | Training loss: 0.6927773361404737
Epoch: 20 | Iteration number: [130/565] 23% | Training loss: 0.6923428608820988
Epoch: 20 | Iteration number: [140/565] 24% | Training loss: 0.6920070920671736
Epoch: 20 | Iteration number: [150/565] 26% | Training loss: 0.6916609716415405
Epoch: 20 | Iteration number: [160/565] 28% | Training loss: 0.6913767345249653
Epoch: 20 | Iteration number: [170/565] 30% | Training loss: 0.6911334188545452
Epoch: 20 | Iteration number: [180/565] 31% | Training loss: 0.690924252404107
Epoch: 20 | Iteration number: [190/565] 33% | Training loss: 0.6906916677951813
Epoch: 20 | Iteration number: [200/565] 35% | Training loss: 0.6905057251453399
Epoch: 20 | Iteration number: [210/565] 37% | Training loss: 0.6903321836675916
Epoch: 20 | Iteration number: [220/565] 38% | Training loss: 0.690183365074071
Epoch: 20 | Iteration number: [230/565] 40% | Training loss: 0.6900441695814548
Epoch: 20 | Iteration number: [240/565] 42% | Training loss: 0.6899227062861125
Epoch: 20 | Iteration number: [250/565] 44% | Training loss: 0.6898000392913818
Epoch: 20 | Iteration number: [260/565] 46% | Training loss: 0.6896950256365996
Epoch: 20 | Iteration number: [270/565] 47% | Training loss: 0.689589575043431
Epoch: 20 | Iteration number: [280/565] 49% | Training loss: 0.6895121678709983
Epoch: 20 | Iteration number: [290/565] 51% | Training loss: 0.689426314008647
Epoch: 20 | Iteration number: [300/565] 53% | Training loss: 0.6893321335315704
Epoch: 20 | Iteration number: [310/565] 54% | Training loss: 0.6892685305687689
Epoch: 20 | Iteration number: [320/565] 56% | Training loss: 0.6891938040032983
Epoch: 20 | Iteration number: [330/565] 58% | Training loss: 0.6891234847632322
Epoch: 20 | Iteration number: [340/565] 60% | Training loss: 0.6890620966168011
Epoch: 20 | Iteration number: [350/565] 61% | Training loss: 0.6890044675554547
Epoch: 20 | Iteration number: [360/565] 63% | Training loss: 0.6889559510681365
Epoch: 20 | Iteration number: [370/565] 65% | Training loss: 0.6889018965734018
Epoch: 20 | Iteration number: [380/565] 67% | Training loss: 0.688843085891322
Epoch: 20 | Iteration number: [390/565] 69% | Training loss: 0.6887850845471407
Epoch: 20 | Iteration number: [400/565] 70% | Training loss: 0.6887465693056584
Epoch: 20 | Iteration number: [410/565] 72% | Training loss: 0.6886966436374479
Epoch: 20 | Iteration number: [420/565] 74% | Training loss: 0.6886482220320475
Epoch: 20 | Iteration number: [430/565] 76% | Training loss: 0.6886124204757602
Epoch: 20 | Iteration number: [440/565] 77% | Training loss: 0.6885648227550767
Epoch: 20 | Iteration number: [450/565] 79% | Training loss: 0.688518598344591
Epoch: 20 | Iteration number: [460/565] 81% | Training loss: 0.6884815148685289
Epoch: 20 | Iteration number: [470/565] 83% | Training loss: 0.688453987811474
Epoch: 20 | Iteration number: [480/565] 84% | Training loss: 0.6884298066298167
Epoch: 20 | Iteration number: [490/565] 86% | Training loss: 0.6883982505117144
Epoch: 20 | Iteration number: [500/565] 88% | Training loss: 0.6883730289936065
Epoch: 20 | Iteration number: [510/565] 90% | Training loss: 0.6883437828690397
Epoch: 20 | Iteration number: [520/565] 92% | Training loss: 0.6883116349577904
Epoch: 20 | Iteration number: [530/565] 93% | Training loss: 0.688289952615522
Epoch: 20 | Iteration number: [540/565] 95% | Training loss: 0.6882633401287926
Epoch: 20 | Iteration number: [550/565] 97% | Training loss: 0.6882478927482258
Epoch: 20 | Iteration number: [560/565] 99% | Training loss: 0.6882270286125797

 End of epoch: 20 | Train Loss: 0.6870016128615996 | Training Time: 89 

 End of epoch: 20 | Eval Loss: 0.6895665100642613 | Evaluating Time: 6 
Epoch: 21 | Iteration number: [10/565] 1% | Training loss: 0.7557685673236847
Epoch: 21 | Iteration number: [20/565] 3% | Training loss: 0.7213189661502838
Epoch: 21 | Iteration number: [30/565] 5% | Training loss: 0.70988583167394
Epoch: 21 | Iteration number: [40/565] 7% | Training loss: 0.7042554691433907
Epoch: 21 | Iteration number: [50/565] 8% | Training loss: 0.7008627557754517
Epoch: 21 | Iteration number: [60/565] 10% | Training loss: 0.6985281338294347
Epoch: 21 | Iteration number: [70/565] 12% | Training loss: 0.6968424337250846
Epoch: 21 | Iteration number: [80/565] 14% | Training loss: 0.6956929363310337
Epoch: 21 | Iteration number: [90/565] 15% | Training loss: 0.6947252796755896
Epoch: 21 | Iteration number: [100/565] 17% | Training loss: 0.6939524865150452
Epoch: 21 | Iteration number: [110/565] 19% | Training loss: 0.6933430509133772
Epoch: 21 | Iteration number: [120/565] 21% | Training loss: 0.692848361035188
Epoch: 21 | Iteration number: [130/565] 23% | Training loss: 0.6924030115971198
Epoch: 21 | Iteration number: [140/565] 24% | Training loss: 0.6920158799205508
Epoch: 21 | Iteration number: [150/565] 26% | Training loss: 0.6916829081376393
Epoch: 21 | Iteration number: [160/565] 28% | Training loss: 0.6913717620074749
Epoch: 21 | Iteration number: [170/565] 30% | Training loss: 0.6910976462504443
Epoch: 21 | Iteration number: [180/565] 31% | Training loss: 0.690844420923127
Epoch: 21 | Iteration number: [190/565] 33% | Training loss: 0.6906491775261728
Epoch: 21 | Iteration number: [200/565] 35% | Training loss: 0.6904615762829781
Epoch: 21 | Iteration number: [210/565] 37% | Training loss: 0.6902965358325414
Epoch: 21 | Iteration number: [220/565] 38% | Training loss: 0.6901690298860723
Epoch: 21 | Iteration number: [230/565] 40% | Training loss: 0.6900409369365029
Epoch: 21 | Iteration number: [240/565] 42% | Training loss: 0.6898925878107548
Epoch: 21 | Iteration number: [250/565] 44% | Training loss: 0.6897602231502533
Epoch: 21 | Iteration number: [260/565] 46% | Training loss: 0.6896722763776779
Epoch: 21 | Iteration number: [270/565] 47% | Training loss: 0.6895848347081078
Epoch: 21 | Iteration number: [280/565] 49% | Training loss: 0.689505814228739
Epoch: 21 | Iteration number: [290/565] 51% | Training loss: 0.6894154918604883
Epoch: 21 | Iteration number: [300/565] 53% | Training loss: 0.6893360211451849
Epoch: 21 | Iteration number: [310/565] 54% | Training loss: 0.68924438722672
Epoch: 21 | Iteration number: [320/565] 56% | Training loss: 0.6891656367108225
Epoch: 21 | Iteration number: [330/565] 58% | Training loss: 0.6891067454309174
Epoch: 21 | Iteration number: [340/565] 60% | Training loss: 0.6890355257426991
Epoch: 21 | Iteration number: [350/565] 61% | Training loss: 0.6889902033124651
Epoch: 21 | Iteration number: [360/565] 63% | Training loss: 0.6889535465174251
Epoch: 21 | Iteration number: [370/565] 65% | Training loss: 0.6889078522050703
Epoch: 21 | Iteration number: [380/565] 67% | Training loss: 0.6888614262405195
Epoch: 21 | Iteration number: [390/565] 69% | Training loss: 0.6888028875375405
Epoch: 21 | Iteration number: [400/565] 70% | Training loss: 0.6887395107746124
Epoch: 21 | Iteration number: [410/565] 72% | Training loss: 0.6886972251461774
Epoch: 21 | Iteration number: [420/565] 74% | Training loss: 0.688655072308722
Epoch: 21 | Iteration number: [430/565] 76% | Training loss: 0.6886124265748401
Epoch: 21 | Iteration number: [440/565] 77% | Training loss: 0.6885750509121201
Epoch: 21 | Iteration number: [450/565] 79% | Training loss: 0.6885421967506409
Epoch: 21 | Iteration number: [460/565] 81% | Training loss: 0.6884902412476747
Epoch: 21 | Iteration number: [470/565] 83% | Training loss: 0.6884564176518866
Epoch: 21 | Iteration number: [480/565] 84% | Training loss: 0.6884240542848905
Epoch: 21 | Iteration number: [490/565] 86% | Training loss: 0.688399081084193
Epoch: 21 | Iteration number: [500/565] 88% | Training loss: 0.6883595385551453
Epoch: 21 | Iteration number: [510/565] 90% | Training loss: 0.6883328899448993
Epoch: 21 | Iteration number: [520/565] 92% | Training loss: 0.6883059821449793
Epoch: 21 | Iteration number: [530/565] 93% | Training loss: 0.6882746810058378
Epoch: 21 | Iteration number: [540/565] 95% | Training loss: 0.6882466912269593
Epoch: 21 | Iteration number: [550/565] 97% | Training loss: 0.6882246724042026
Epoch: 21 | Iteration number: [560/565] 99% | Training loss: 0.6882100475685937

 End of epoch: 21 | Train Loss: 0.6869830314037019 | Training Time: 90 

 End of epoch: 21 | Eval Loss: 0.6899835893086025 | Evaluating Time: 6 
Epoch: 22 | Iteration number: [10/565] 1% | Training loss: 0.7556747972965241
Epoch: 22 | Iteration number: [20/565] 3% | Training loss: 0.7215695738792419
Epoch: 22 | Iteration number: [30/565] 5% | Training loss: 0.710011734565099
Epoch: 22 | Iteration number: [40/565] 7% | Training loss: 0.704282745718956
Epoch: 22 | Iteration number: [50/565] 8% | Training loss: 0.7008402943611145
Epoch: 22 | Iteration number: [60/565] 10% | Training loss: 0.6984578331311544
Epoch: 22 | Iteration number: [70/565] 12% | Training loss: 0.6967839709350041
Epoch: 22 | Iteration number: [80/565] 14% | Training loss: 0.6955372668802738
Epoch: 22 | Iteration number: [90/565] 15% | Training loss: 0.6946102135711246
Epoch: 22 | Iteration number: [100/565] 17% | Training loss: 0.6938503688573837
Epoch: 22 | Iteration number: [110/565] 19% | Training loss: 0.6932331784205004
Epoch: 22 | Iteration number: [120/565] 21% | Training loss: 0.6927024533351263
Epoch: 22 | Iteration number: [130/565] 23% | Training loss: 0.6922835753514216
Epoch: 22 | Iteration number: [140/565] 24% | Training loss: 0.6918937061514173
Epoch: 22 | Iteration number: [150/565] 26% | Training loss: 0.6915716036160787
Epoch: 22 | Iteration number: [160/565] 28% | Training loss: 0.6912711810320615
Epoch: 22 | Iteration number: [170/565] 30% | Training loss: 0.6910286296816434
Epoch: 22 | Iteration number: [180/565] 31% | Training loss: 0.6908052388164733
Epoch: 22 | Iteration number: [190/565] 33% | Training loss: 0.6906178110524228
Epoch: 22 | Iteration number: [200/565] 35% | Training loss: 0.6904426938295365
Epoch: 22 | Iteration number: [210/565] 37% | Training loss: 0.6902729326770419
Epoch: 22 | Iteration number: [220/565] 38% | Training loss: 0.6901229712096127
Epoch: 22 | Iteration number: [230/565] 40% | Training loss: 0.6899813996708911
Epoch: 22 | Iteration number: [240/565] 42% | Training loss: 0.6898516391714414
Epoch: 22 | Iteration number: [250/565] 44% | Training loss: 0.6897425594329833
Epoch: 22 | Iteration number: [260/565] 46% | Training loss: 0.6896309504142174
Epoch: 22 | Iteration number: [270/565] 47% | Training loss: 0.6895317271903709
Epoch: 22 | Iteration number: [280/565] 49% | Training loss: 0.6894251648868833
Epoch: 22 | Iteration number: [290/565] 51% | Training loss: 0.6893474056802947
Epoch: 22 | Iteration number: [300/565] 53% | Training loss: 0.6892852479219437
Epoch: 22 | Iteration number: [310/565] 54% | Training loss: 0.6891996429812524
Epoch: 22 | Iteration number: [320/565] 56% | Training loss: 0.6891362477093935
Epoch: 22 | Iteration number: [330/565] 58% | Training loss: 0.6890763681946379
Epoch: 22 | Iteration number: [340/565] 60% | Training loss: 0.6890078760245267
Epoch: 22 | Iteration number: [350/565] 61% | Training loss: 0.6889508506229945
Epoch: 22 | Iteration number: [360/565] 63% | Training loss: 0.6888903833097881
Epoch: 22 | Iteration number: [370/565] 65% | Training loss: 0.6888401136205003
Epoch: 22 | Iteration number: [380/565] 67% | Training loss: 0.6887830575830058
Epoch: 22 | Iteration number: [390/565] 69% | Training loss: 0.6887314374630268
Epoch: 22 | Iteration number: [400/565] 70% | Training loss: 0.6886783707141876
Epoch: 22 | Iteration number: [410/565] 72% | Training loss: 0.6886404951898063
Epoch: 22 | Iteration number: [420/565] 74% | Training loss: 0.6885968494982947
Epoch: 22 | Iteration number: [430/565] 76% | Training loss: 0.6885621858197589
Epoch: 22 | Iteration number: [440/565] 77% | Training loss: 0.6885348249565472
Epoch: 22 | Iteration number: [450/565] 79% | Training loss: 0.6884886075390709
Epoch: 22 | Iteration number: [460/565] 81% | Training loss: 0.6884614993696627
Epoch: 22 | Iteration number: [470/565] 83% | Training loss: 0.6884341106769887
Epoch: 22 | Iteration number: [480/565] 84% | Training loss: 0.6883950499196847
Epoch: 22 | Iteration number: [490/565] 86% | Training loss: 0.688364896603993
Epoch: 22 | Iteration number: [500/565] 88% | Training loss: 0.6883340475559234
Epoch: 22 | Iteration number: [510/565] 90% | Training loss: 0.6883148714607837
Epoch: 22 | Iteration number: [520/565] 92% | Training loss: 0.6882989350419778
Epoch: 22 | Iteration number: [530/565] 93% | Training loss: 0.6882663113890953
Epoch: 22 | Iteration number: [540/565] 95% | Training loss: 0.6882397175938995
Epoch: 22 | Iteration number: [550/565] 97% | Training loss: 0.6882130882956765
Epoch: 22 | Iteration number: [560/565] 99% | Training loss: 0.6881915958864349

 End of epoch: 22 | Train Loss: 0.6869681981812537 | Training Time: 90 

 End of epoch: 22 | Eval Loss: 0.689385746206556 | Evaluating Time: 6 
Epoch: 23 | Iteration number: [10/565] 1% | Training loss: 0.7554275751113891
Epoch: 23 | Iteration number: [20/565] 3% | Training loss: 0.721148532629013
Epoch: 23 | Iteration number: [30/565] 5% | Training loss: 0.7097541451454162
Epoch: 23 | Iteration number: [40/565] 7% | Training loss: 0.7040375530719757
Epoch: 23 | Iteration number: [50/565] 8% | Training loss: 0.7006339001655578
Epoch: 23 | Iteration number: [60/565] 10% | Training loss: 0.6983261346817017
Epoch: 23 | Iteration number: [70/565] 12% | Training loss: 0.6966977264199938
Epoch: 23 | Iteration number: [80/565] 14% | Training loss: 0.6954852938652039
Epoch: 23 | Iteration number: [90/565] 15% | Training loss: 0.6945441451337603
Epoch: 23 | Iteration number: [100/565] 17% | Training loss: 0.6937515527009964
Epoch: 23 | Iteration number: [110/565] 19% | Training loss: 0.6931603366678412
Epoch: 23 | Iteration number: [120/565] 21% | Training loss: 0.6926230976978938
Epoch: 23 | Iteration number: [130/565] 23% | Training loss: 0.6921944925418266
Epoch: 23 | Iteration number: [140/565] 24% | Training loss: 0.6918069102934429
Epoch: 23 | Iteration number: [150/565] 26% | Training loss: 0.6914878352483114
Epoch: 23 | Iteration number: [160/565] 28% | Training loss: 0.6912183746695518
Epoch: 23 | Iteration number: [170/565] 30% | Training loss: 0.6909653733758365
Epoch: 23 | Iteration number: [180/565] 31% | Training loss: 0.6907534466849433
Epoch: 23 | Iteration number: [190/565] 33% | Training loss: 0.6905408602011831
Epoch: 23 | Iteration number: [200/565] 35% | Training loss: 0.6903594645857811
Epoch: 23 | Iteration number: [210/565] 37% | Training loss: 0.690203903402601
Epoch: 23 | Iteration number: [220/565] 38% | Training loss: 0.6900564264167439
Epoch: 23 | Iteration number: [230/565] 40% | Training loss: 0.6899224255395973
Epoch: 23 | Iteration number: [240/565] 42% | Training loss: 0.6897974272569021
Epoch: 23 | Iteration number: [250/565] 44% | Training loss: 0.6896967549324036
Epoch: 23 | Iteration number: [260/565] 46% | Training loss: 0.6895898358179973
Epoch: 23 | Iteration number: [270/565] 47% | Training loss: 0.6894906838734944
Epoch: 23 | Iteration number: [280/565] 49% | Training loss: 0.6893878981471062
Epoch: 23 | Iteration number: [290/565] 51% | Training loss: 0.6893103874962906
Epoch: 23 | Iteration number: [300/565] 53% | Training loss: 0.6892295491695404
Epoch: 23 | Iteration number: [310/565] 54% | Training loss: 0.6891551806080726
Epoch: 23 | Iteration number: [320/565] 56% | Training loss: 0.689094109646976
Epoch: 23 | Iteration number: [330/565] 58% | Training loss: 0.6890246658614188
Epoch: 23 | Iteration number: [340/565] 60% | Training loss: 0.6889581366496927
Epoch: 23 | Iteration number: [350/565] 61% | Training loss: 0.6889142761911665
Epoch: 23 | Iteration number: [360/565] 63% | Training loss: 0.6888673098550903
Epoch: 23 | Iteration number: [370/565] 65% | Training loss: 0.6888238526679374
Epoch: 23 | Iteration number: [380/565] 67% | Training loss: 0.6887802931823228
Epoch: 23 | Iteration number: [390/565] 69% | Training loss: 0.6887424467465817
Epoch: 23 | Iteration number: [400/565] 70% | Training loss: 0.6886909285187721
Epoch: 23 | Iteration number: [410/565] 72% | Training loss: 0.6886386945480254
Epoch: 23 | Iteration number: [420/565] 74% | Training loss: 0.6886089835848127
Epoch: 23 | Iteration number: [430/565] 76% | Training loss: 0.6885777472063552
Epoch: 23 | Iteration number: [440/565] 77% | Training loss: 0.6885360081087459
Epoch: 23 | Iteration number: [450/565] 79% | Training loss: 0.6884999015596178
Epoch: 23 | Iteration number: [460/565] 81% | Training loss: 0.6884622400221617
Epoch: 23 | Iteration number: [470/565] 83% | Training loss: 0.6884178363262339
Epoch: 23 | Iteration number: [480/565] 84% | Training loss: 0.6883955876032511
Epoch: 23 | Iteration number: [490/565] 86% | Training loss: 0.6883633187838963
Epoch: 23 | Iteration number: [500/565] 88% | Training loss: 0.6883427813053131
Epoch: 23 | Iteration number: [510/565] 90% | Training loss: 0.6883134561426499
Epoch: 23 | Iteration number: [520/565] 92% | Training loss: 0.6882929928027667
Epoch: 23 | Iteration number: [530/565] 93% | Training loss: 0.6882640468624402
Epoch: 23 | Iteration number: [540/565] 95% | Training loss: 0.6882304519414901
Epoch: 23 | Iteration number: [550/565] 97% | Training loss: 0.6882052872397683
Epoch: 23 | Iteration number: [560/565] 99% | Training loss: 0.6881782092154026

 End of epoch: 23 | Train Loss: 0.686951340299792 | Training Time: 90 

 End of epoch: 23 | Eval Loss: 0.689582816192082 | Evaluating Time: 5 
Epoch: 24 | Iteration number: [10/565] 1% | Training loss: 0.7553032636642456
Epoch: 24 | Iteration number: [20/565] 3% | Training loss: 0.7211046367883682
Epoch: 24 | Iteration number: [30/565] 5% | Training loss: 0.7096887826919556
Epoch: 24 | Iteration number: [40/565] 7% | Training loss: 0.7040315553545952
Epoch: 24 | Iteration number: [50/565] 8% | Training loss: 0.7005004286766052
Epoch: 24 | Iteration number: [60/565] 10% | Training loss: 0.6982619325319926
Epoch: 24 | Iteration number: [70/565] 12% | Training loss: 0.6967011519840786
Epoch: 24 | Iteration number: [80/565] 14% | Training loss: 0.6955267362296581
Epoch: 24 | Iteration number: [90/565] 15% | Training loss: 0.6945637557241652
Epoch: 24 | Iteration number: [100/565] 17% | Training loss: 0.6937349206209182
Epoch: 24 | Iteration number: [110/565] 19% | Training loss: 0.6931626471606168
Epoch: 24 | Iteration number: [120/565] 21% | Training loss: 0.6926071132222812
Epoch: 24 | Iteration number: [130/565] 23% | Training loss: 0.6921543877858382
Epoch: 24 | Iteration number: [140/565] 24% | Training loss: 0.6917650903974261
Epoch: 24 | Iteration number: [150/565] 26% | Training loss: 0.6914366233348846
Epoch: 24 | Iteration number: [160/565] 28% | Training loss: 0.691128883510828
Epoch: 24 | Iteration number: [170/565] 30% | Training loss: 0.6908907147014842
Epoch: 24 | Iteration number: [180/565] 31% | Training loss: 0.6906620055437088
Epoch: 24 | Iteration number: [190/565] 33% | Training loss: 0.6904764140907087
Epoch: 24 | Iteration number: [200/565] 35% | Training loss: 0.6903266322612762
Epoch: 24 | Iteration number: [210/565] 37% | Training loss: 0.6901933312416076
Epoch: 24 | Iteration number: [220/565] 38% | Training loss: 0.6900242271748456
Epoch: 24 | Iteration number: [230/565] 40% | Training loss: 0.6898933322533317
Epoch: 24 | Iteration number: [240/565] 42% | Training loss: 0.6897726498544217
Epoch: 24 | Iteration number: [250/565] 44% | Training loss: 0.689675710439682
Epoch: 24 | Iteration number: [260/565] 46% | Training loss: 0.6895769901000537
Epoch: 24 | Iteration number: [270/565] 47% | Training loss: 0.6894793188130414
Epoch: 24 | Iteration number: [280/565] 49% | Training loss: 0.6894089524235044
Epoch: 24 | Iteration number: [290/565] 51% | Training loss: 0.6893315226867281
Epoch: 24 | Iteration number: [300/565] 53% | Training loss: 0.6892564501365026
Epoch: 24 | Iteration number: [310/565] 54% | Training loss: 0.6891853047955421
Epoch: 24 | Iteration number: [320/565] 56% | Training loss: 0.6891138561069965
Epoch: 24 | Iteration number: [330/565] 58% | Training loss: 0.6890444638151111
Epoch: 24 | Iteration number: [340/565] 60% | Training loss: 0.6889658053131664
Epoch: 24 | Iteration number: [350/565] 61% | Training loss: 0.6888974939073835
Epoch: 24 | Iteration number: [360/565] 63% | Training loss: 0.6888472984234492
Epoch: 24 | Iteration number: [370/565] 65% | Training loss: 0.6887945115566254
Epoch: 24 | Iteration number: [380/565] 67% | Training loss: 0.6887432172110206
Epoch: 24 | Iteration number: [390/565] 69% | Training loss: 0.6887034014249459
Epoch: 24 | Iteration number: [400/565] 70% | Training loss: 0.6886722558736801
Epoch: 24 | Iteration number: [410/565] 72% | Training loss: 0.688624958439571
Epoch: 24 | Iteration number: [420/565] 74% | Training loss: 0.6885762013140179
Epoch: 24 | Iteration number: [430/565] 76% | Training loss: 0.6885424353355585
Epoch: 24 | Iteration number: [440/565] 77% | Training loss: 0.6885034983808344
Epoch: 24 | Iteration number: [450/565] 79% | Training loss: 0.6884829058912065
Epoch: 24 | Iteration number: [460/565] 81% | Training loss: 0.6884486040343409
Epoch: 24 | Iteration number: [470/565] 83% | Training loss: 0.6884188673597701
Epoch: 24 | Iteration number: [480/565] 84% | Training loss: 0.6883904203772545
Epoch: 24 | Iteration number: [490/565] 86% | Training loss: 0.6883609200010494
Epoch: 24 | Iteration number: [500/565] 88% | Training loss: 0.6883236919641494
Epoch: 24 | Iteration number: [510/565] 90% | Training loss: 0.6883028792399987
Epoch: 24 | Iteration number: [520/565] 92% | Training loss: 0.6882690214193784
Epoch: 24 | Iteration number: [530/565] 93% | Training loss: 0.6882446230582471
Epoch: 24 | Iteration number: [540/565] 95% | Training loss: 0.6882211849645332
Epoch: 24 | Iteration number: [550/565] 97% | Training loss: 0.6881958817351949
Epoch: 24 | Iteration number: [560/565] 99% | Training loss: 0.6881739104432719

 End of epoch: 24 | Train Loss: 0.6869475418487482 | Training Time: 88 

 End of epoch: 24 | Eval Loss: 0.6898771354130336 | Evaluating Time: 5 
Epoch: 25 | Iteration number: [10/565] 1% | Training loss: 0.7559377670288085
Epoch: 25 | Iteration number: [20/565] 3% | Training loss: 0.7211328744888306
Epoch: 25 | Iteration number: [30/565] 5% | Training loss: 0.7098347504933675
Epoch: 25 | Iteration number: [40/565] 7% | Training loss: 0.7040861040353775
Epoch: 25 | Iteration number: [50/565] 8% | Training loss: 0.7006891644001008
Epoch: 25 | Iteration number: [60/565] 10% | Training loss: 0.6983720928430557
Epoch: 25 | Iteration number: [70/565] 12% | Training loss: 0.6967837120805468
Epoch: 25 | Iteration number: [80/565] 14% | Training loss: 0.6955349057912826
Epoch: 25 | Iteration number: [90/565] 15% | Training loss: 0.6945531924565633
Epoch: 25 | Iteration number: [100/565] 17% | Training loss: 0.6937900871038437
Epoch: 25 | Iteration number: [110/565] 19% | Training loss: 0.6931574144146659
Epoch: 25 | Iteration number: [120/565] 21% | Training loss: 0.6926296566923459
Epoch: 25 | Iteration number: [130/565] 23% | Training loss: 0.6921667772990007
Epoch: 25 | Iteration number: [140/565] 24% | Training loss: 0.6917941732066019
Epoch: 25 | Iteration number: [150/565] 26% | Training loss: 0.6914781435330709
Epoch: 25 | Iteration number: [160/565] 28% | Training loss: 0.6912113532423974
Epoch: 25 | Iteration number: [170/565] 30% | Training loss: 0.6909480824190027
Epoch: 25 | Iteration number: [180/565] 31% | Training loss: 0.6907499896155463
Epoch: 25 | Iteration number: [190/565] 33% | Training loss: 0.6905303700974114
Epoch: 25 | Iteration number: [200/565] 35% | Training loss: 0.6903643792867661
Epoch: 25 | Iteration number: [210/565] 37% | Training loss: 0.6902221963519142
Epoch: 25 | Iteration number: [220/565] 38% | Training loss: 0.6900887727737427
Epoch: 25 | Iteration number: [230/565] 40% | Training loss: 0.6899648332077524
Epoch: 25 | Iteration number: [240/565] 42% | Training loss: 0.6898334446052711
Epoch: 25 | Iteration number: [250/565] 44% | Training loss: 0.6897229859828949
Epoch: 25 | Iteration number: [260/565] 46% | Training loss: 0.689609636251743
Epoch: 25 | Iteration number: [270/565] 47% | Training loss: 0.6895128656316687
Epoch: 25 | Iteration number: [280/565] 49% | Training loss: 0.6894220537372998
Epoch: 25 | Iteration number: [290/565] 51% | Training loss: 0.6893502866399699
Epoch: 25 | Iteration number: [300/565] 53% | Training loss: 0.6892612981796264
Epoch: 25 | Iteration number: [310/565] 54% | Training loss: 0.6891809942260865
Epoch: 25 | Iteration number: [320/565] 56% | Training loss: 0.6891062302514911
Epoch: 25 | Iteration number: [330/565] 58% | Training loss: 0.6890418529510498
Epoch: 25 | Iteration number: [340/565] 60% | Training loss: 0.6889926053145352
Epoch: 25 | Iteration number: [350/565] 61% | Training loss: 0.688923922777176
Epoch: 25 | Iteration number: [360/565] 63% | Training loss: 0.6888800935612784
Epoch: 25 | Iteration number: [370/565] 65% | Training loss: 0.6888276435233451
Epoch: 25 | Iteration number: [380/565] 67% | Training loss: 0.6887714762436716
Epoch: 25 | Iteration number: [390/565] 69% | Training loss: 0.6887280399982746
Epoch: 25 | Iteration number: [400/565] 70% | Training loss: 0.6886783137917518
Epoch: 25 | Iteration number: [410/565] 72% | Training loss: 0.6886311804375997
Epoch: 25 | Iteration number: [420/565] 74% | Training loss: 0.6885899340822583
Epoch: 25 | Iteration number: [430/565] 76% | Training loss: 0.688555638318838
Epoch: 25 | Iteration number: [440/565] 77% | Training loss: 0.6885310190645131
Epoch: 25 | Iteration number: [450/565] 79% | Training loss: 0.6884866052203709
Epoch: 25 | Iteration number: [460/565] 81% | Training loss: 0.6884441874597383
Epoch: 25 | Iteration number: [470/565] 83% | Training loss: 0.688406503200531
Epoch: 25 | Iteration number: [480/565] 84% | Training loss: 0.6883749450246494
Epoch: 25 | Iteration number: [490/565] 86% | Training loss: 0.6883435293119781
Epoch: 25 | Iteration number: [500/565] 88% | Training loss: 0.688319363951683
Epoch: 25 | Iteration number: [510/565] 90% | Training loss: 0.6882922762749242
Epoch: 25 | Iteration number: [520/565] 92% | Training loss: 0.6882640325106107
Epoch: 25 | Iteration number: [530/565] 93% | Training loss: 0.688243841000323
Epoch: 25 | Iteration number: [540/565] 95% | Training loss: 0.6882212585873074
Epoch: 25 | Iteration number: [550/565] 97% | Training loss: 0.6882046021114696
Epoch: 25 | Iteration number: [560/565] 99% | Training loss: 0.6881844054375376

 End of epoch: 25 | Train Loss: 0.6869641761864181 | Training Time: 88 

 End of epoch: 25 | Eval Loss: 0.6899300643375942 | Evaluating Time: 6 
Epoch: 26 | Iteration number: [10/565] 1% | Training loss: 0.7558749258518219
Epoch: 26 | Iteration number: [20/565] 3% | Training loss: 0.7213330328464508
Epoch: 26 | Iteration number: [30/565] 5% | Training loss: 0.709920879205068
Epoch: 26 | Iteration number: [40/565] 7% | Training loss: 0.7042118817567825
Epoch: 26 | Iteration number: [50/565] 8% | Training loss: 0.7007349646091461
Epoch: 26 | Iteration number: [60/565] 10% | Training loss: 0.6984442671140035
Epoch: 26 | Iteration number: [70/565] 12% | Training loss: 0.6968226058142526
Epoch: 26 | Iteration number: [80/565] 14% | Training loss: 0.6956129685044289
Epoch: 26 | Iteration number: [90/565] 15% | Training loss: 0.6946344216664632
Epoch: 26 | Iteration number: [100/565] 17% | Training loss: 0.6938683032989502
Epoch: 26 | Iteration number: [110/565] 19% | Training loss: 0.6932351822202856
Epoch: 26 | Iteration number: [120/565] 21% | Training loss: 0.6927293539047241
Epoch: 26 | Iteration number: [130/565] 23% | Training loss: 0.6923036598242246
Epoch: 26 | Iteration number: [140/565] 24% | Training loss: 0.6919110941035407
Epoch: 26 | Iteration number: [150/565] 26% | Training loss: 0.6915728604793548
Epoch: 26 | Iteration number: [160/565] 28% | Training loss: 0.6912677634507418
Epoch: 26 | Iteration number: [170/565] 30% | Training loss: 0.6910258952309104
Epoch: 26 | Iteration number: [180/565] 31% | Training loss: 0.6908089614576763
Epoch: 26 | Iteration number: [190/565] 33% | Training loss: 0.6906068230930128
Epoch: 26 | Iteration number: [200/565] 35% | Training loss: 0.6904364287853241
Epoch: 26 | Iteration number: [210/565] 37% | Training loss: 0.6902661601702372
Epoch: 26 | Iteration number: [220/565] 38% | Training loss: 0.6901091591878371
Epoch: 26 | Iteration number: [230/565] 40% | Training loss: 0.6899676387724669
Epoch: 26 | Iteration number: [240/565] 42% | Training loss: 0.689821190883716
Epoch: 26 | Iteration number: [250/565] 44% | Training loss: 0.6897064957618714
Epoch: 26 | Iteration number: [260/565] 46% | Training loss: 0.6896076106108152
Epoch: 26 | Iteration number: [270/565] 47% | Training loss: 0.6895130108903955
Epoch: 26 | Iteration number: [280/565] 49% | Training loss: 0.6894325203129223
Epoch: 26 | Iteration number: [290/565] 51% | Training loss: 0.6893537617962936
Epoch: 26 | Iteration number: [300/565] 53% | Training loss: 0.6892626841862997
Epoch: 26 | Iteration number: [310/565] 54% | Training loss: 0.6891849198649006
Epoch: 26 | Iteration number: [320/565] 56% | Training loss: 0.6891420243307949
Epoch: 26 | Iteration number: [330/565] 58% | Training loss: 0.6890799482663472
Epoch: 26 | Iteration number: [340/565] 60% | Training loss: 0.6890186341369853
Epoch: 26 | Iteration number: [350/565] 61% | Training loss: 0.6889511901991708
Epoch: 26 | Iteration number: [360/565] 63% | Training loss: 0.6889081784420543
Epoch: 26 | Iteration number: [370/565] 65% | Training loss: 0.6888503865615742
Epoch: 26 | Iteration number: [380/565] 67% | Training loss: 0.6888061581473601
Epoch: 26 | Iteration number: [390/565] 69% | Training loss: 0.6887574648245787
Epoch: 26 | Iteration number: [400/565] 70% | Training loss: 0.6887180617451668
Epoch: 26 | Iteration number: [410/565] 72% | Training loss: 0.6886738214550949
Epoch: 26 | Iteration number: [420/565] 74% | Training loss: 0.6886393148274649
Epoch: 26 | Iteration number: [430/565] 76% | Training loss: 0.6886030780714611
Epoch: 26 | Iteration number: [440/565] 77% | Training loss: 0.688563405383717
Epoch: 26 | Iteration number: [450/565] 79% | Training loss: 0.6885261442926195
Epoch: 26 | Iteration number: [460/565] 81% | Training loss: 0.6884876442992169
Epoch: 26 | Iteration number: [470/565] 83% | Training loss: 0.6884406014959863
Epoch: 26 | Iteration number: [480/565] 84% | Training loss: 0.688411237920324
Epoch: 26 | Iteration number: [490/565] 86% | Training loss: 0.6883867213920671
Epoch: 26 | Iteration number: [500/565] 88% | Training loss: 0.6883460958003997
Epoch: 26 | Iteration number: [510/565] 90% | Training loss: 0.6883178089179245
Epoch: 26 | Iteration number: [520/565] 92% | Training loss: 0.6882887380627486
Epoch: 26 | Iteration number: [530/565] 93% | Training loss: 0.6882597743340259
Epoch: 26 | Iteration number: [540/565] 95% | Training loss: 0.6882272433351587
Epoch: 26 | Iteration number: [550/565] 97% | Training loss: 0.6882002532482148
Epoch: 26 | Iteration number: [560/565] 99% | Training loss: 0.6881808666246277

 End of epoch: 26 | Train Loss: 0.686951851106323 | Training Time: 89 

 End of epoch: 26 | Eval Loss: 0.6894933496202741 | Evaluating Time: 6 
Epoch: 27 | Iteration number: [10/565] 1% | Training loss: 0.7554225444793701
Epoch: 27 | Iteration number: [20/565] 3% | Training loss: 0.7210824131965637
Epoch: 27 | Iteration number: [30/565] 5% | Training loss: 0.7097023844718933
Epoch: 27 | Iteration number: [40/565] 7% | Training loss: 0.7041111722588539
Epoch: 27 | Iteration number: [50/565] 8% | Training loss: 0.7006822466850281
Epoch: 27 | Iteration number: [60/565] 10% | Training loss: 0.6983156482378642
Epoch: 27 | Iteration number: [70/565] 12% | Training loss: 0.6966149994305202
Epoch: 27 | Iteration number: [80/565] 14% | Training loss: 0.6954281069338322
Epoch: 27 | Iteration number: [90/565] 15% | Training loss: 0.6945135613282521
Epoch: 27 | Iteration number: [100/565] 17% | Training loss: 0.6937653970718384
Epoch: 27 | Iteration number: [110/565] 19% | Training loss: 0.6931532735174353
Epoch: 27 | Iteration number: [120/565] 21% | Training loss: 0.6926258141795795
Epoch: 27 | Iteration number: [130/565] 23% | Training loss: 0.6922050985006186
Epoch: 27 | Iteration number: [140/565] 24% | Training loss: 0.6918074088437217
Epoch: 27 | Iteration number: [150/565] 26% | Training loss: 0.6915075500806173
Epoch: 27 | Iteration number: [160/565] 28% | Training loss: 0.6912163149565458
Epoch: 27 | Iteration number: [170/565] 30% | Training loss: 0.690957672105116
Epoch: 27 | Iteration number: [180/565] 31% | Training loss: 0.6907514108551873
Epoch: 27 | Iteration number: [190/565] 33% | Training loss: 0.690557030627602
Epoch: 27 | Iteration number: [200/565] 35% | Training loss: 0.690358681678772
Epoch: 27 | Iteration number: [210/565] 37% | Training loss: 0.6901721057437715
Epoch: 27 | Iteration number: [220/565] 38% | Training loss: 0.6900137484073638
Epoch: 27 | Iteration number: [230/565] 40% | Training loss: 0.6898956783439802
Epoch: 27 | Iteration number: [240/565] 42% | Training loss: 0.6897641296188036
Epoch: 27 | Iteration number: [250/565] 44% | Training loss: 0.6896456189155579
Epoch: 27 | Iteration number: [260/565] 46% | Training loss: 0.6895366441745024
Epoch: 27 | Iteration number: [270/565] 47% | Training loss: 0.6894276219385641
Epoch: 27 | Iteration number: [280/565] 49% | Training loss: 0.6893543520144054
Epoch: 27 | Iteration number: [290/565] 51% | Training loss: 0.689274538385457
Epoch: 27 | Iteration number: [300/565] 53% | Training loss: 0.6892180995146433
Epoch: 27 | Iteration number: [310/565] 54% | Training loss: 0.6891411233332849
Epoch: 27 | Iteration number: [320/565] 56% | Training loss: 0.6890819307416678
Epoch: 27 | Iteration number: [330/565] 58% | Training loss: 0.6889976064364115
Epoch: 27 | Iteration number: [340/565] 60% | Training loss: 0.688949106721317
Epoch: 27 | Iteration number: [350/565] 61% | Training loss: 0.688891624893461
Epoch: 27 | Iteration number: [360/565] 63% | Training loss: 0.6888308942317962
Epoch: 27 | Iteration number: [370/565] 65% | Training loss: 0.6887732112729872
Epoch: 27 | Iteration number: [380/565] 67% | Training loss: 0.6887354712737234
Epoch: 27 | Iteration number: [390/565] 69% | Training loss: 0.688679406276116
Epoch: 27 | Iteration number: [400/565] 70% | Training loss: 0.6886392968893051
Epoch: 27 | Iteration number: [410/565] 72% | Training loss: 0.6885869056713291
Epoch: 27 | Iteration number: [420/565] 74% | Training loss: 0.6885504729691005
Epoch: 27 | Iteration number: [430/565] 76% | Training loss: 0.688512060808581
Epoch: 27 | Iteration number: [440/565] 77% | Training loss: 0.6884774167429317
Epoch: 27 | Iteration number: [450/565] 79% | Training loss: 0.6884499773714278
Epoch: 27 | Iteration number: [460/565] 81% | Training loss: 0.6884228466645531
Epoch: 27 | Iteration number: [470/565] 83% | Training loss: 0.6883894395320973
Epoch: 27 | Iteration number: [480/565] 84% | Training loss: 0.6883556154867013
Epoch: 27 | Iteration number: [490/565] 86% | Training loss: 0.6883223768399687
Epoch: 27 | Iteration number: [500/565] 88% | Training loss: 0.6882907018661499
Epoch: 27 | Iteration number: [510/565] 90% | Training loss: 0.6882725035443026
Epoch: 27 | Iteration number: [520/565] 92% | Training loss: 0.688242132617877
Epoch: 27 | Iteration number: [530/565] 93% | Training loss: 0.6882150860327595
Epoch: 27 | Iteration number: [540/565] 95% | Training loss: 0.688196274307039
Epoch: 27 | Iteration number: [550/565] 97% | Training loss: 0.6881687338785691
Epoch: 27 | Iteration number: [560/565] 99% | Training loss: 0.6881483875215053

 End of epoch: 27 | Train Loss: 0.6869207040398522 | Training Time: 89 

 End of epoch: 27 | Eval Loss: 0.6899575505937848 | Evaluating Time: 6 
Epoch: 28 | Iteration number: [10/565] 1% | Training loss: 0.7559634327888489
Epoch: 28 | Iteration number: [20/565] 3% | Training loss: 0.7213546633720398
Epoch: 28 | Iteration number: [30/565] 5% | Training loss: 0.7099105656147003
Epoch: 28 | Iteration number: [40/565] 7% | Training loss: 0.7041486710309982
Epoch: 28 | Iteration number: [50/565] 8% | Training loss: 0.700753024816513
Epoch: 28 | Iteration number: [60/565] 10% | Training loss: 0.6984605858723323
Epoch: 28 | Iteration number: [70/565] 12% | Training loss: 0.6968138694763184
Epoch: 28 | Iteration number: [80/565] 14% | Training loss: 0.6956165358424187
Epoch: 28 | Iteration number: [90/565] 15% | Training loss: 0.6946723255846236
Epoch: 28 | Iteration number: [100/565] 17% | Training loss: 0.693834325671196
Epoch: 28 | Iteration number: [110/565] 19% | Training loss: 0.6932225720448928
Epoch: 28 | Iteration number: [120/565] 21% | Training loss: 0.692657208442688
Epoch: 28 | Iteration number: [130/565] 23% | Training loss: 0.6922774071876819
Epoch: 28 | Iteration number: [140/565] 24% | Training loss: 0.691872273172651
Epoch: 28 | Iteration number: [150/565] 26% | Training loss: 0.6915550541877746
Epoch: 28 | Iteration number: [160/565] 28% | Training loss: 0.6912673819810152
Epoch: 28 | Iteration number: [170/565] 30% | Training loss: 0.6910268569693846
Epoch: 28 | Iteration number: [180/565] 31% | Training loss: 0.6908004939556122
Epoch: 28 | Iteration number: [190/565] 33% | Training loss: 0.6906048984904039
Epoch: 28 | Iteration number: [200/565] 35% | Training loss: 0.6904273739457131
Epoch: 28 | Iteration number: [210/565] 37% | Training loss: 0.6902613387221381
Epoch: 28 | Iteration number: [220/565] 38% | Training loss: 0.6901140264489434
Epoch: 28 | Iteration number: [230/565] 40% | Training loss: 0.6899567928003228
Epoch: 28 | Iteration number: [240/565] 42% | Training loss: 0.6898138600091139
Epoch: 28 | Iteration number: [250/565] 44% | Training loss: 0.6897021279335022
Epoch: 28 | Iteration number: [260/565] 46% | Training loss: 0.6895833540421266
Epoch: 28 | Iteration number: [270/565] 47% | Training loss: 0.6895083003573947
Epoch: 28 | Iteration number: [280/565] 49% | Training loss: 0.689397017444883
Epoch: 28 | Iteration number: [290/565] 51% | Training loss: 0.6893010260729954
Epoch: 28 | Iteration number: [300/565] 53% | Training loss: 0.6892260118325552
Epoch: 28 | Iteration number: [310/565] 54% | Training loss: 0.6891549268076497
Epoch: 28 | Iteration number: [320/565] 56% | Training loss: 0.6890778513625264
Epoch: 28 | Iteration number: [330/565] 58% | Training loss: 0.6890177311319293
Epoch: 28 | Iteration number: [340/565] 60% | Training loss: 0.6889461953850353
Epoch: 28 | Iteration number: [350/565] 61% | Training loss: 0.6888863236563546
Epoch: 28 | Iteration number: [360/565] 63% | Training loss: 0.6888322487473488
Epoch: 28 | Iteration number: [370/565] 65% | Training loss: 0.688780740789465
Epoch: 28 | Iteration number: [380/565] 67% | Training loss: 0.6887312986348805
Epoch: 28 | Iteration number: [390/565] 69% | Training loss: 0.6886758414598612
Epoch: 28 | Iteration number: [400/565] 70% | Training loss: 0.6886283205449582
Epoch: 28 | Iteration number: [410/565] 72% | Training loss: 0.68857894801512
Epoch: 28 | Iteration number: [420/565] 74% | Training loss: 0.6885402323234648
Epoch: 28 | Iteration number: [430/565] 76% | Training loss: 0.6884977732979974
Epoch: 28 | Iteration number: [440/565] 77% | Training loss: 0.6884747409007766
Epoch: 28 | Iteration number: [450/565] 79% | Training loss: 0.6884431772761874
Epoch: 28 | Iteration number: [460/565] 81% | Training loss: 0.6884158396202585
Epoch: 28 | Iteration number: [470/565] 83% | Training loss: 0.6883798358288217
Epoch: 28 | Iteration number: [480/565] 84% | Training loss: 0.6883486197640498
Epoch: 28 | Iteration number: [490/565] 86% | Training loss: 0.6883215006516904
Epoch: 28 | Iteration number: [500/565] 88% | Training loss: 0.688297738790512
Epoch: 28 | Iteration number: [510/565] 90% | Training loss: 0.6882647293455461
Epoch: 28 | Iteration number: [520/565] 92% | Training loss: 0.6882449984550476
Epoch: 28 | Iteration number: [530/565] 93% | Training loss: 0.6882213882680209
Epoch: 28 | Iteration number: [540/565] 95% | Training loss: 0.6882013818732015
Epoch: 28 | Iteration number: [550/565] 97% | Training loss: 0.6881671884926883
Epoch: 28 | Iteration number: [560/565] 99% | Training loss: 0.6881456607154437

 End of epoch: 28 | Train Loss: 0.686917608290647 | Training Time: 90 

 End of epoch: 28 | Eval Loss: 0.6891744988305228 | Evaluating Time: 5 
Epoch: 29 | Iteration number: [10/565] 1% | Training loss: 0.7559270083904266
Epoch: 29 | Iteration number: [20/565] 3% | Training loss: 0.7213814646005631
Epoch: 29 | Iteration number: [30/565] 5% | Training loss: 0.7098453362782796
Epoch: 29 | Iteration number: [40/565] 7% | Training loss: 0.7042154535651207
Epoch: 29 | Iteration number: [50/565] 8% | Training loss: 0.7007923626899719
Epoch: 29 | Iteration number: [60/565] 10% | Training loss: 0.6984729359547297
Epoch: 29 | Iteration number: [70/565] 12% | Training loss: 0.6968202037470681
Epoch: 29 | Iteration number: [80/565] 14% | Training loss: 0.6955972969532013
Epoch: 29 | Iteration number: [90/565] 15% | Training loss: 0.6946560422579448
Epoch: 29 | Iteration number: [100/565] 17% | Training loss: 0.6939020413160324
Epoch: 29 | Iteration number: [110/565] 19% | Training loss: 0.6932684475725347
Epoch: 29 | Iteration number: [120/565] 21% | Training loss: 0.6927619059880574
Epoch: 29 | Iteration number: [130/565] 23% | Training loss: 0.6923295209041008
Epoch: 29 | Iteration number: [140/565] 24% | Training loss: 0.6919472481523241
Epoch: 29 | Iteration number: [150/565] 26% | Training loss: 0.691609023809433
Epoch: 29 | Iteration number: [160/565] 28% | Training loss: 0.6913266237825155
Epoch: 29 | Iteration number: [170/565] 30% | Training loss: 0.6910642778172212
Epoch: 29 | Iteration number: [180/565] 31% | Training loss: 0.6908271186881595
Epoch: 29 | Iteration number: [190/565] 33% | Training loss: 0.6906331445041456
Epoch: 29 | Iteration number: [200/565] 35% | Training loss: 0.6904649069905281
Epoch: 29 | Iteration number: [210/565] 37% | Training loss: 0.6903000547772362
Epoch: 29 | Iteration number: [220/565] 38% | Training loss: 0.6901250955733386
Epoch: 29 | Iteration number: [230/565] 40% | Training loss: 0.6899834609549979
Epoch: 29 | Iteration number: [240/565] 42% | Training loss: 0.6898590572178364
Epoch: 29 | Iteration number: [250/565] 44% | Training loss: 0.6897269351482391
Epoch: 29 | Iteration number: [260/565] 46% | Training loss: 0.6896263468724031
Epoch: 29 | Iteration number: [270/565] 47% | Training loss: 0.6895220054520501
Epoch: 29 | Iteration number: [280/565] 49% | Training loss: 0.689436001437051
Epoch: 29 | Iteration number: [290/565] 51% | Training loss: 0.6893297033063297
Epoch: 29 | Iteration number: [300/565] 53% | Training loss: 0.6892534255981445
Epoch: 29 | Iteration number: [310/565] 54% | Training loss: 0.6891894627001978
Epoch: 29 | Iteration number: [320/565] 56% | Training loss: 0.6891203120350837
Epoch: 29 | Iteration number: [330/565] 58% | Training loss: 0.689041873180505
Epoch: 29 | Iteration number: [340/565] 60% | Training loss: 0.688978282143088
Epoch: 29 | Iteration number: [350/565] 61% | Training loss: 0.688929408277784
Epoch: 29 | Iteration number: [360/565] 63% | Training loss: 0.6888769043816461
Epoch: 29 | Iteration number: [370/565] 65% | Training loss: 0.6888219420974319
Epoch: 29 | Iteration number: [380/565] 67% | Training loss: 0.6887730675308328
Epoch: 29 | Iteration number: [390/565] 69% | Training loss: 0.6887221541160192
Epoch: 29 | Iteration number: [400/565] 70% | Training loss: 0.6886786364018918
Epoch: 29 | Iteration number: [410/565] 72% | Training loss: 0.6886317551136016
Epoch: 29 | Iteration number: [420/565] 74% | Training loss: 0.6885992653313138
Epoch: 29 | Iteration number: [430/565] 76% | Training loss: 0.6885602618372717
Epoch: 29 | Iteration number: [440/565] 77% | Training loss: 0.6885199484500018
Epoch: 29 | Iteration number: [450/565] 79% | Training loss: 0.688484214676751
Epoch: 29 | Iteration number: [460/565] 81% | Training loss: 0.6884406131246815
Epoch: 29 | Iteration number: [470/565] 83% | Training loss: 0.6884025297266372
Epoch: 29 | Iteration number: [480/565] 84% | Training loss: 0.6883753139525652
Epoch: 29 | Iteration number: [490/565] 86% | Training loss: 0.6883454696256287
Epoch: 29 | Iteration number: [500/565] 88% | Training loss: 0.6883107748031616
Epoch: 29 | Iteration number: [510/565] 90% | Training loss: 0.6882760404371748
Epoch: 29 | Iteration number: [520/565] 92% | Training loss: 0.688242588364161
Epoch: 29 | Iteration number: [530/565] 93% | Training loss: 0.6882210019624458
Epoch: 29 | Iteration number: [540/565] 95% | Training loss: 0.6881931351290809
Epoch: 29 | Iteration number: [550/565] 97% | Training loss: 0.6881710497899489
Epoch: 29 | Iteration number: [560/565] 99% | Training loss: 0.6881505805466857

 End of epoch: 29 | Train Loss: 0.686924469048998 | Training Time: 89 

 End of epoch: 29 | Eval Loss: 0.689998916217259 | Evaluating Time: 6 
Epoch: 30 | Iteration number: [10/565] 1% | Training loss: 0.7560571908950806
Epoch: 30 | Iteration number: [20/565] 3% | Training loss: 0.7211766928434372
Epoch: 30 | Iteration number: [30/565] 5% | Training loss: 0.7097705364227295
Epoch: 30 | Iteration number: [40/565] 7% | Training loss: 0.7038897261023521
Epoch: 30 | Iteration number: [50/565] 8% | Training loss: 0.7004613995552063
Epoch: 30 | Iteration number: [60/565] 10% | Training loss: 0.6981602946917216
Epoch: 30 | Iteration number: [70/565] 12% | Training loss: 0.6965429816927229
Epoch: 30 | Iteration number: [80/565] 14% | Training loss: 0.6953361712396144
Epoch: 30 | Iteration number: [90/565] 15% | Training loss: 0.6944475650787354
Epoch: 30 | Iteration number: [100/565] 17% | Training loss: 0.6937123686075211
Epoch: 30 | Iteration number: [110/565] 19% | Training loss: 0.6931225700811906
Epoch: 30 | Iteration number: [120/565] 21% | Training loss: 0.6925987258553505
Epoch: 30 | Iteration number: [130/565] 23% | Training loss: 0.6921763965716728
Epoch: 30 | Iteration number: [140/565] 24% | Training loss: 0.6917714434010642
Epoch: 30 | Iteration number: [150/565] 26% | Training loss: 0.6914466925462087
Epoch: 30 | Iteration number: [160/565] 28% | Training loss: 0.6911320801824331
Epoch: 30 | Iteration number: [170/565] 30% | Training loss: 0.6908858460538527
Epoch: 30 | Iteration number: [180/565] 31% | Training loss: 0.6906712641318639
Epoch: 30 | Iteration number: [190/565] 33% | Training loss: 0.6904603572268235
Epoch: 30 | Iteration number: [200/565] 35% | Training loss: 0.6902502501010894
Epoch: 30 | Iteration number: [210/565] 37% | Training loss: 0.6900884852522895
Epoch: 30 | Iteration number: [220/565] 38% | Training loss: 0.6899357042529366
Epoch: 30 | Iteration number: [230/565] 40% | Training loss: 0.6898126558117245
Epoch: 30 | Iteration number: [240/565] 42% | Training loss: 0.6897022850811482
Epoch: 30 | Iteration number: [250/565] 44% | Training loss: 0.6896049942970276
Epoch: 30 | Iteration number: [260/565] 46% | Training loss: 0.6894846290349961
Epoch: 30 | Iteration number: [270/565] 47% | Training loss: 0.6893953182079174
Epoch: 30 | Iteration number: [280/565] 49% | Training loss: 0.6892975956201554
Epoch: 30 | Iteration number: [290/565] 51% | Training loss: 0.6892164939436419
Epoch: 30 | Iteration number: [300/565] 53% | Training loss: 0.6891420874993006
Epoch: 30 | Iteration number: [310/565] 54% | Training loss: 0.6890652418136597
Epoch: 30 | Iteration number: [320/565] 56% | Training loss: 0.6889977702870965
Epoch: 30 | Iteration number: [330/565] 58% | Training loss: 0.6889287036476713
Epoch: 30 | Iteration number: [340/565] 60% | Training loss: 0.6888640999794007
Epoch: 30 | Iteration number: [350/565] 61% | Training loss: 0.6888071646009173
Epoch: 30 | Iteration number: [360/565] 63% | Training loss: 0.6887690891822179
Epoch: 30 | Iteration number: [370/565] 65% | Training loss: 0.6887244814151042
Epoch: 30 | Iteration number: [380/565] 67% | Training loss: 0.6886670288286711
Epoch: 30 | Iteration number: [390/565] 69% | Training loss: 0.688621406066112
Epoch: 30 | Iteration number: [400/565] 70% | Training loss: 0.6885906870663167
Epoch: 30 | Iteration number: [410/565] 72% | Training loss: 0.6885462788546958
Epoch: 30 | Iteration number: [420/565] 74% | Training loss: 0.6885065185172218
Epoch: 30 | Iteration number: [430/565] 76% | Training loss: 0.6884621336016544
Epoch: 30 | Iteration number: [440/565] 77% | Training loss: 0.6884300649166107
Epoch: 30 | Iteration number: [450/565] 79% | Training loss: 0.6883950340747833
Epoch: 30 | Iteration number: [460/565] 81% | Training loss: 0.6883778324593668
Epoch: 30 | Iteration number: [470/565] 83% | Training loss: 0.6883480504472205
Epoch: 30 | Iteration number: [480/565] 84% | Training loss: 0.6883217564473549
Epoch: 30 | Iteration number: [490/565] 86% | Training loss: 0.688294600832219
Epoch: 30 | Iteration number: [500/565] 88% | Training loss: 0.6882668813467026
Epoch: 30 | Iteration number: [510/565] 90% | Training loss: 0.6882431733841989
Epoch: 30 | Iteration number: [520/565] 92% | Training loss: 0.6882248376424496
Epoch: 30 | Iteration number: [530/565] 93% | Training loss: 0.6881918701360811
Epoch: 30 | Iteration number: [540/565] 95% | Training loss: 0.6881586694055133
Epoch: 30 | Iteration number: [550/565] 97% | Training loss: 0.6881373261321675
Epoch: 30 | Iteration number: [560/565] 99% | Training loss: 0.6881163450224059

 End of epoch: 30 | Train Loss: 0.6868933208220828 | Training Time: 89 

 End of epoch: 30 | Eval Loss: 0.6896910156522479 | Evaluating Time: 6 
Epoch: 31 | Iteration number: [10/565] 1% | Training loss: 0.7558196246623993
Epoch: 31 | Iteration number: [20/565] 3% | Training loss: 0.7213510036468506
Epoch: 31 | Iteration number: [30/565] 5% | Training loss: 0.7100689669450124
Epoch: 31 | Iteration number: [40/565] 7% | Training loss: 0.70430578738451
Epoch: 31 | Iteration number: [50/565] 8% | Training loss: 0.7008008575439453
Epoch: 31 | Iteration number: [60/565] 10% | Training loss: 0.6984745462735494
Epoch: 31 | Iteration number: [70/565] 12% | Training loss: 0.6968489706516265
Epoch: 31 | Iteration number: [80/565] 14% | Training loss: 0.6955948516726493
Epoch: 31 | Iteration number: [90/565] 15% | Training loss: 0.6946287579006619
Epoch: 31 | Iteration number: [100/565] 17% | Training loss: 0.6938473546504974
Epoch: 31 | Iteration number: [110/565] 19% | Training loss: 0.6932363380085338
Epoch: 31 | Iteration number: [120/565] 21% | Training loss: 0.6927199617028237
Epoch: 31 | Iteration number: [130/565] 23% | Training loss: 0.6922725163973295
Epoch: 31 | Iteration number: [140/565] 24% | Training loss: 0.6918852435691016
Epoch: 31 | Iteration number: [150/565] 26% | Training loss: 0.6915569786230723
Epoch: 31 | Iteration number: [160/565] 28% | Training loss: 0.6912949703633785
Epoch: 31 | Iteration number: [170/565] 30% | Training loss: 0.6910317901302786
Epoch: 31 | Iteration number: [180/565] 31% | Training loss: 0.6907964107063082
Epoch: 31 | Iteration number: [190/565] 33% | Training loss: 0.6905857312051873
Epoch: 31 | Iteration number: [200/565] 35% | Training loss: 0.6903827100992203
Epoch: 31 | Iteration number: [210/565] 37% | Training loss: 0.6902334755375272
Epoch: 31 | Iteration number: [220/565] 38% | Training loss: 0.6900803706862709
Epoch: 31 | Iteration number: [230/565] 40% | Training loss: 0.6899425970471423
Epoch: 31 | Iteration number: [240/565] 42% | Training loss: 0.689810860157013
Epoch: 31 | Iteration number: [250/565] 44% | Training loss: 0.6897013654708862
Epoch: 31 | Iteration number: [260/565] 46% | Training loss: 0.6895843764910331
Epoch: 31 | Iteration number: [270/565] 47% | Training loss: 0.6894898043738471
Epoch: 31 | Iteration number: [280/565] 49% | Training loss: 0.6893885118620736
Epoch: 31 | Iteration number: [290/565] 51% | Training loss: 0.689297045715924
Epoch: 31 | Iteration number: [300/565] 53% | Training loss: 0.6892239473263423
Epoch: 31 | Iteration number: [310/565] 54% | Training loss: 0.6891418747363552
Epoch: 31 | Iteration number: [320/565] 56% | Training loss: 0.6890736984089016
Epoch: 31 | Iteration number: [330/565] 58% | Training loss: 0.689020728523081
Epoch: 31 | Iteration number: [340/565] 60% | Training loss: 0.6889593466239817
Epoch: 31 | Iteration number: [350/565] 61% | Training loss: 0.6888973769119807
Epoch: 31 | Iteration number: [360/565] 63% | Training loss: 0.6888426936335034
Epoch: 31 | Iteration number: [370/565] 65% | Training loss: 0.6888011560246751
Epoch: 31 | Iteration number: [380/565] 67% | Training loss: 0.6887517212252868
Epoch: 31 | Iteration number: [390/565] 69% | Training loss: 0.6886999257099934
Epoch: 31 | Iteration number: [400/565] 70% | Training loss: 0.6886619573831558
Epoch: 31 | Iteration number: [410/565] 72% | Training loss: 0.6886173521600119
Epoch: 31 | Iteration number: [420/565] 74% | Training loss: 0.6885801308211826
Epoch: 31 | Iteration number: [430/565] 76% | Training loss: 0.6885339481886044
Epoch: 31 | Iteration number: [440/565] 77% | Training loss: 0.6884875271808018
Epoch: 31 | Iteration number: [450/565] 79% | Training loss: 0.6884495764308506
Epoch: 31 | Iteration number: [460/565] 81% | Training loss: 0.688413003216619
Epoch: 31 | Iteration number: [470/565] 83% | Training loss: 0.6883758387667067
Epoch: 31 | Iteration number: [480/565] 84% | Training loss: 0.6883375914146502
Epoch: 31 | Iteration number: [490/565] 86% | Training loss: 0.6883167359293724
Epoch: 31 | Iteration number: [500/565] 88% | Training loss: 0.6882786750793457
Epoch: 31 | Iteration number: [510/565] 90% | Training loss: 0.6882527003101274
Epoch: 31 | Iteration number: [520/565] 92% | Training loss: 0.688223030590094
Epoch: 31 | Iteration number: [530/565] 93% | Training loss: 0.6881965477511568
Epoch: 31 | Iteration number: [540/565] 95% | Training loss: 0.6881731606192059
Epoch: 31 | Iteration number: [550/565] 97% | Training loss: 0.6881426714767109
Epoch: 31 | Iteration number: [560/565] 99% | Training loss: 0.6881131982164723

 End of epoch: 31 | Train Loss: 0.6868892827920154 | Training Time: 88 

 End of epoch: 31 | Eval Loss: 0.689725433077131 | Evaluating Time: 6 
Epoch: 32 | Iteration number: [10/565] 1% | Training loss: 0.7554751634597778
Epoch: 32 | Iteration number: [20/565] 3% | Training loss: 0.7212968945503235
Epoch: 32 | Iteration number: [30/565] 5% | Training loss: 0.7099712272485097
Epoch: 32 | Iteration number: [40/565] 7% | Training loss: 0.7041722714900971
Epoch: 32 | Iteration number: [50/565] 8% | Training loss: 0.7005677723884582
Epoch: 32 | Iteration number: [60/565] 10% | Training loss: 0.6983152399460475
Epoch: 32 | Iteration number: [70/565] 12% | Training loss: 0.6966365694999694
Epoch: 32 | Iteration number: [80/565] 14% | Training loss: 0.6953762352466584
Epoch: 32 | Iteration number: [90/565] 15% | Training loss: 0.6944899340470632
Epoch: 32 | Iteration number: [100/565] 17% | Training loss: 0.6937435507774353
Epoch: 32 | Iteration number: [110/565] 19% | Training loss: 0.6931303186850114
Epoch: 32 | Iteration number: [120/565] 21% | Training loss: 0.6926425814628601
Epoch: 32 | Iteration number: [130/565] 23% | Training loss: 0.6922151285868424
Epoch: 32 | Iteration number: [140/565] 24% | Training loss: 0.6918491159166609
Epoch: 32 | Iteration number: [150/565] 26% | Training loss: 0.6914855285485586
Epoch: 32 | Iteration number: [160/565] 28% | Training loss: 0.6912223234772682
Epoch: 32 | Iteration number: [170/565] 30% | Training loss: 0.6909505002638873
Epoch: 32 | Iteration number: [180/565] 31% | Training loss: 0.6907096667422189
Epoch: 32 | Iteration number: [190/565] 33% | Training loss: 0.6905145588674043
Epoch: 32 | Iteration number: [200/565] 35% | Training loss: 0.690349867939949
Epoch: 32 | Iteration number: [210/565] 37% | Training loss: 0.6901819271700723
Epoch: 32 | Iteration number: [220/565] 38% | Training loss: 0.6900377403606068
Epoch: 32 | Iteration number: [230/565] 40% | Training loss: 0.6898980285810388
Epoch: 32 | Iteration number: [240/565] 42% | Training loss: 0.689774414896965
Epoch: 32 | Iteration number: [250/565] 44% | Training loss: 0.6896662690639496
Epoch: 32 | Iteration number: [260/565] 46% | Training loss: 0.6895535113719794
Epoch: 32 | Iteration number: [270/565] 47% | Training loss: 0.6894522587458293
Epoch: 32 | Iteration number: [280/565] 49% | Training loss: 0.6893511574183192
Epoch: 32 | Iteration number: [290/565] 51% | Training loss: 0.689253889075641
Epoch: 32 | Iteration number: [300/565] 53% | Training loss: 0.6891718612114588
Epoch: 32 | Iteration number: [310/565] 54% | Training loss: 0.6890937610980004
Epoch: 32 | Iteration number: [320/565] 56% | Training loss: 0.6890106419101357
Epoch: 32 | Iteration number: [330/565] 58% | Training loss: 0.6889460281892257
Epoch: 32 | Iteration number: [340/565] 60% | Training loss: 0.6888923893956577
Epoch: 32 | Iteration number: [350/565] 61% | Training loss: 0.6888305839470454
Epoch: 32 | Iteration number: [360/565] 63% | Training loss: 0.6887887482841809
Epoch: 32 | Iteration number: [370/565] 65% | Training loss: 0.6887364816021275
Epoch: 32 | Iteration number: [380/565] 67% | Training loss: 0.6886899177965365
Epoch: 32 | Iteration number: [390/565] 69% | Training loss: 0.6886532214971689
Epoch: 32 | Iteration number: [400/565] 70% | Training loss: 0.6885933615267277
Epoch: 32 | Iteration number: [410/565] 72% | Training loss: 0.6885569017107894
Epoch: 32 | Iteration number: [420/565] 74% | Training loss: 0.6885151403290884
Epoch: 32 | Iteration number: [430/565] 76% | Training loss: 0.6884721366472022
Epoch: 32 | Iteration number: [440/565] 77% | Training loss: 0.6884389737790281
Epoch: 32 | Iteration number: [450/565] 79% | Training loss: 0.6884076382054223
Epoch: 32 | Iteration number: [460/565] 81% | Training loss: 0.6883737250514652
Epoch: 32 | Iteration number: [470/565] 83% | Training loss: 0.6883530449359975
Epoch: 32 | Iteration number: [480/565] 84% | Training loss: 0.6883221251269181
Epoch: 32 | Iteration number: [490/565] 86% | Training loss: 0.6882821390823443
Epoch: 32 | Iteration number: [500/565] 88% | Training loss: 0.6882577967643738
Epoch: 32 | Iteration number: [510/565] 90% | Training loss: 0.6882331283653483
Epoch: 32 | Iteration number: [520/565] 92% | Training loss: 0.6882074309083132
Epoch: 32 | Iteration number: [530/565] 93% | Training loss: 0.6881830458371144
Epoch: 32 | Iteration number: [540/565] 95% | Training loss: 0.68816069121714
Epoch: 32 | Iteration number: [550/565] 97% | Training loss: 0.6881376958977092
Epoch: 32 | Iteration number: [560/565] 99% | Training loss: 0.6881118746740478

 End of epoch: 32 | Train Loss: 0.6868848918813519 | Training Time: 87 

 End of epoch: 32 | Eval Loss: 0.6898146442004612 | Evaluating Time: 6 
Epoch: 33 | Iteration number: [10/565] 1% | Training loss: 0.7556561350822448
Epoch: 33 | Iteration number: [20/565] 3% | Training loss: 0.7211641818284988
Epoch: 33 | Iteration number: [30/565] 5% | Training loss: 0.7097482820351918
Epoch: 33 | Iteration number: [40/565] 7% | Training loss: 0.704061222076416
Epoch: 33 | Iteration number: [50/565] 8% | Training loss: 0.700583484172821
Epoch: 33 | Iteration number: [60/565] 10% | Training loss: 0.698349517583847
Epoch: 33 | Iteration number: [70/565] 12% | Training loss: 0.6967205975736891
Epoch: 33 | Iteration number: [80/565] 14% | Training loss: 0.6954763829708099
Epoch: 33 | Iteration number: [90/565] 15% | Training loss: 0.694472402996487
Epoch: 33 | Iteration number: [100/565] 17% | Training loss: 0.6937515580654144
Epoch: 33 | Iteration number: [110/565] 19% | Training loss: 0.6931216239929199
Epoch: 33 | Iteration number: [120/565] 21% | Training loss: 0.6926192387938499
Epoch: 33 | Iteration number: [130/565] 23% | Training loss: 0.6921788321091579
Epoch: 33 | Iteration number: [140/565] 24% | Training loss: 0.6917965028967176
Epoch: 33 | Iteration number: [150/565] 26% | Training loss: 0.69147585272789
Epoch: 33 | Iteration number: [160/565] 28% | Training loss: 0.6911949519068002
Epoch: 33 | Iteration number: [170/565] 30% | Training loss: 0.690967681127436
Epoch: 33 | Iteration number: [180/565] 31% | Training loss: 0.6907322350475523
Epoch: 33 | Iteration number: [190/565] 33% | Training loss: 0.6905536504168259
Epoch: 33 | Iteration number: [200/565] 35% | Training loss: 0.6903838858008384
Epoch: 33 | Iteration number: [210/565] 37% | Training loss: 0.6902147707485017
Epoch: 33 | Iteration number: [220/565] 38% | Training loss: 0.6900808564641259
Epoch: 33 | Iteration number: [230/565] 40% | Training loss: 0.6899500178254169
Epoch: 33 | Iteration number: [240/565] 42% | Training loss: 0.6898273468017578
Epoch: 33 | Iteration number: [250/565] 44% | Training loss: 0.6896919770240784
Epoch: 33 | Iteration number: [260/565] 46% | Training loss: 0.689578570998632
Epoch: 33 | Iteration number: [270/565] 47% | Training loss: 0.689476587595763
Epoch: 33 | Iteration number: [280/565] 49% | Training loss: 0.6893636448042734
Epoch: 33 | Iteration number: [290/565] 51% | Training loss: 0.6892678147759931
Epoch: 33 | Iteration number: [300/565] 53% | Training loss: 0.6891855196158091
Epoch: 33 | Iteration number: [310/565] 54% | Training loss: 0.6891095730566209
Epoch: 33 | Iteration number: [320/565] 56% | Training loss: 0.6890316205099225
Epoch: 33 | Iteration number: [330/565] 58% | Training loss: 0.6889583260724039
Epoch: 33 | Iteration number: [340/565] 60% | Training loss: 0.6888903474106508
Epoch: 33 | Iteration number: [350/565] 61% | Training loss: 0.6888450576577868
Epoch: 33 | Iteration number: [360/565] 63% | Training loss: 0.6887783376706971
Epoch: 33 | Iteration number: [370/565] 65% | Training loss: 0.6887223285597723
Epoch: 33 | Iteration number: [380/565] 67% | Training loss: 0.6886835120226208
Epoch: 33 | Iteration number: [390/565] 69% | Training loss: 0.6886348709081992
Epoch: 33 | Iteration number: [400/565] 70% | Training loss: 0.6885935327410698
Epoch: 33 | Iteration number: [410/565] 72% | Training loss: 0.6885629709173994
Epoch: 33 | Iteration number: [420/565] 74% | Training loss: 0.6885245988766352
Epoch: 33 | Iteration number: [430/565] 76% | Training loss: 0.6884838399498961
Epoch: 33 | Iteration number: [440/565] 77% | Training loss: 0.6884449044411832
Epoch: 33 | Iteration number: [450/565] 79% | Training loss: 0.688401266336441
Epoch: 33 | Iteration number: [460/565] 81% | Training loss: 0.6883722445239191
Epoch: 33 | Iteration number: [470/565] 83% | Training loss: 0.6883389584561612
Epoch: 33 | Iteration number: [480/565] 84% | Training loss: 0.6883171405643225
Epoch: 33 | Iteration number: [490/565] 86% | Training loss: 0.6882868499171977
Epoch: 33 | Iteration number: [500/565] 88% | Training loss: 0.6882617700099946
Epoch: 33 | Iteration number: [510/565] 90% | Training loss: 0.6882219905946769
Epoch: 33 | Iteration number: [520/565] 92% | Training loss: 0.6881930938133827
Epoch: 33 | Iteration number: [530/565] 93% | Training loss: 0.6881720589016969
Epoch: 33 | Iteration number: [540/565] 95% | Training loss: 0.6881508964079398
Epoch: 33 | Iteration number: [550/565] 97% | Training loss: 0.6881243710084395
Epoch: 33 | Iteration number: [560/565] 99% | Training loss: 0.6881109836910452

 End of epoch: 33 | Train Loss: 0.6868846322582887 | Training Time: 89 

 End of epoch: 33 | Eval Loss: 0.6894300409725734 | Evaluating Time: 6 
Epoch: 34 | Iteration number: [10/565] 1% | Training loss: 0.7552606403827667
Epoch: 34 | Iteration number: [20/565] 3% | Training loss: 0.7210595905780792
Epoch: 34 | Iteration number: [30/565] 5% | Training loss: 0.7098255912462871
Epoch: 34 | Iteration number: [40/565] 7% | Training loss: 0.7040819272398948
Epoch: 34 | Iteration number: [50/565] 8% | Training loss: 0.700532556772232
Epoch: 34 | Iteration number: [60/565] 10% | Training loss: 0.6982685834169388
Epoch: 34 | Iteration number: [70/565] 12% | Training loss: 0.6966673127242498
Epoch: 34 | Iteration number: [80/565] 14% | Training loss: 0.6953870348632336
Epoch: 34 | Iteration number: [90/565] 15% | Training loss: 0.694472936126921
Epoch: 34 | Iteration number: [100/565] 17% | Training loss: 0.6936718428134918
Epoch: 34 | Iteration number: [110/565] 19% | Training loss: 0.6929855996912176
Epoch: 34 | Iteration number: [120/565] 21% | Training loss: 0.6924617449442546
Epoch: 34 | Iteration number: [130/565] 23% | Training loss: 0.6920391238652743
Epoch: 34 | Iteration number: [140/565] 24% | Training loss: 0.6916778960398265
Epoch: 34 | Iteration number: [150/565] 26% | Training loss: 0.6913580290476481
Epoch: 34 | Iteration number: [160/565] 28% | Training loss: 0.6911061804741621
Epoch: 34 | Iteration number: [170/565] 30% | Training loss: 0.6908678650856018
Epoch: 34 | Iteration number: [180/565] 31% | Training loss: 0.6906451645824644
Epoch: 34 | Iteration number: [190/565] 33% | Training loss: 0.6904537480128439
Epoch: 34 | Iteration number: [200/565] 35% | Training loss: 0.6902629122138023
Epoch: 34 | Iteration number: [210/565] 37% | Training loss: 0.6901120884077889
Epoch: 34 | Iteration number: [220/565] 38% | Training loss: 0.6899754860184409
Epoch: 34 | Iteration number: [230/565] 40% | Training loss: 0.6898468201575072
Epoch: 34 | Iteration number: [240/565] 42% | Training loss: 0.6897137090563774
Epoch: 34 | Iteration number: [250/565] 44% | Training loss: 0.6896119029521942
Epoch: 34 | Iteration number: [260/565] 46% | Training loss: 0.6895131927270156
Epoch: 34 | Iteration number: [270/565] 47% | Training loss: 0.6894116324407084
Epoch: 34 | Iteration number: [280/565] 49% | Training loss: 0.6893043096576418
Epoch: 34 | Iteration number: [290/565] 51% | Training loss: 0.6892278761699282
Epoch: 34 | Iteration number: [300/565] 53% | Training loss: 0.6891529268026352
Epoch: 34 | Iteration number: [310/565] 54% | Training loss: 0.6890803302488019
Epoch: 34 | Iteration number: [320/565] 56% | Training loss: 0.6890148598700762
Epoch: 34 | Iteration number: [330/565] 58% | Training loss: 0.6889387421535723
Epoch: 34 | Iteration number: [340/565] 60% | Training loss: 0.6888687004061306
Epoch: 34 | Iteration number: [350/565] 61% | Training loss: 0.6888084992340633
Epoch: 34 | Iteration number: [360/565] 63% | Training loss: 0.6887576611505615
Epoch: 34 | Iteration number: [370/565] 65% | Training loss: 0.6887098956752468
Epoch: 34 | Iteration number: [380/565] 67% | Training loss: 0.6886570872444856
Epoch: 34 | Iteration number: [390/565] 69% | Training loss: 0.6886125275721917
Epoch: 34 | Iteration number: [400/565] 70% | Training loss: 0.6885695138573646
Epoch: 34 | Iteration number: [410/565] 72% | Training loss: 0.6885376927329273
Epoch: 34 | Iteration number: [420/565] 74% | Training loss: 0.6885106289670581
Epoch: 34 | Iteration number: [430/565] 76% | Training loss: 0.6884763128535693
Epoch: 34 | Iteration number: [440/565] 77% | Training loss: 0.6884335265918211
Epoch: 34 | Iteration number: [450/565] 79% | Training loss: 0.6883929158581628
Epoch: 34 | Iteration number: [460/565] 81% | Training loss: 0.6883610109920087
Epoch: 34 | Iteration number: [470/565] 83% | Training loss: 0.6883359233115581
Epoch: 34 | Iteration number: [480/565] 84% | Training loss: 0.6883124311765035
Epoch: 34 | Iteration number: [490/565] 86% | Training loss: 0.6882801818604372
Epoch: 34 | Iteration number: [500/565] 88% | Training loss: 0.6882593791484832
Epoch: 34 | Iteration number: [510/565] 90% | Training loss: 0.6882395315404032
Epoch: 34 | Iteration number: [520/565] 92% | Training loss: 0.6882152964289372
Epoch: 34 | Iteration number: [530/565] 93% | Training loss: 0.6881945382873967
Epoch: 34 | Iteration number: [540/565] 95% | Training loss: 0.688166602783733
Epoch: 34 | Iteration number: [550/565] 97% | Training loss: 0.688143054897135
Epoch: 34 | Iteration number: [560/565] 99% | Training loss: 0.6881176086408751

 End of epoch: 34 | Train Loss: 0.6868901875166766 | Training Time: 88 

 End of epoch: 34 | Eval Loss: 0.6890678320612226 | Evaluating Time: 6 
Epoch: 35 | Iteration number: [10/565] 1% | Training loss: 0.7551240563392639
Epoch: 35 | Iteration number: [20/565] 3% | Training loss: 0.7210291862487793
Epoch: 35 | Iteration number: [30/565] 5% | Training loss: 0.7097287019093831
Epoch: 35 | Iteration number: [40/565] 7% | Training loss: 0.7040358319878578
Epoch: 35 | Iteration number: [50/565] 8% | Training loss: 0.7006271934509277
Epoch: 35 | Iteration number: [60/565] 10% | Training loss: 0.6982448726892472
Epoch: 35 | Iteration number: [70/565] 12% | Training loss: 0.6966799437999726
Epoch: 35 | Iteration number: [80/565] 14% | Training loss: 0.6954344362020493
Epoch: 35 | Iteration number: [90/565] 15% | Training loss: 0.6944508426719241
Epoch: 35 | Iteration number: [100/565] 17% | Training loss: 0.69369777739048
Epoch: 35 | Iteration number: [110/565] 19% | Training loss: 0.6930889346382835
Epoch: 35 | Iteration number: [120/565] 21% | Training loss: 0.6926188627878825
Epoch: 35 | Iteration number: [130/565] 23% | Training loss: 0.6921607251350697
Epoch: 35 | Iteration number: [140/565] 24% | Training loss: 0.691782381279128
Epoch: 35 | Iteration number: [150/565] 26% | Training loss: 0.6914531020323436
Epoch: 35 | Iteration number: [160/565] 28% | Training loss: 0.6911728926002979
Epoch: 35 | Iteration number: [170/565] 30% | Training loss: 0.6909215934136335
Epoch: 35 | Iteration number: [180/565] 31% | Training loss: 0.6906934824254778
Epoch: 35 | Iteration number: [190/565] 33% | Training loss: 0.6905123459665399
Epoch: 35 | Iteration number: [200/565] 35% | Training loss: 0.6903319031000137
Epoch: 35 | Iteration number: [210/565] 37% | Training loss: 0.6901702872344426
Epoch: 35 | Iteration number: [220/565] 38% | Training loss: 0.6900448492982171
Epoch: 35 | Iteration number: [230/565] 40% | Training loss: 0.689891544373139
Epoch: 35 | Iteration number: [240/565] 42% | Training loss: 0.6897657886147499
Epoch: 35 | Iteration number: [250/565] 44% | Training loss: 0.6896642270088196
Epoch: 35 | Iteration number: [260/565] 46% | Training loss: 0.689564625116495
Epoch: 35 | Iteration number: [270/565] 47% | Training loss: 0.6894672654293201
Epoch: 35 | Iteration number: [280/565] 49% | Training loss: 0.6893523388675281
Epoch: 35 | Iteration number: [290/565] 51% | Training loss: 0.6892562783997634
Epoch: 35 | Iteration number: [300/565] 53% | Training loss: 0.6891818956534068
Epoch: 35 | Iteration number: [310/565] 54% | Training loss: 0.6891145477371831
Epoch: 35 | Iteration number: [320/565] 56% | Training loss: 0.6890420554205775
Epoch: 35 | Iteration number: [330/565] 58% | Training loss: 0.688973765481602
Epoch: 35 | Iteration number: [340/565] 60% | Training loss: 0.6889122149523567
Epoch: 35 | Iteration number: [350/565] 61% | Training loss: 0.6888492006914956
Epoch: 35 | Iteration number: [360/565] 63% | Training loss: 0.6887868112987943
Epoch: 35 | Iteration number: [370/565] 65% | Training loss: 0.6887266859814928
Epoch: 35 | Iteration number: [380/565] 67% | Training loss: 0.6886822888725682
Epoch: 35 | Iteration number: [390/565] 69% | Training loss: 0.6886287233768366
Epoch: 35 | Iteration number: [400/565] 70% | Training loss: 0.6885940262675285
Epoch: 35 | Iteration number: [410/565] 72% | Training loss: 0.6885471637656049
Epoch: 35 | Iteration number: [420/565] 74% | Training loss: 0.6885147486414228
Epoch: 35 | Iteration number: [430/565] 76% | Training loss: 0.688471804247346
Epoch: 35 | Iteration number: [440/565] 77% | Training loss: 0.6884352536364036
Epoch: 35 | Iteration number: [450/565] 79% | Training loss: 0.6883949098322126
Epoch: 35 | Iteration number: [460/565] 81% | Training loss: 0.6883660159681154
Epoch: 35 | Iteration number: [470/565] 83% | Training loss: 0.68833178522739
Epoch: 35 | Iteration number: [480/565] 84% | Training loss: 0.6883093118667603
Epoch: 35 | Iteration number: [490/565] 86% | Training loss: 0.6882832518645695
Epoch: 35 | Iteration number: [500/565] 88% | Training loss: 0.6882535923719406
Epoch: 35 | Iteration number: [510/565] 90% | Training loss: 0.6882247051771949
Epoch: 35 | Iteration number: [520/565] 92% | Training loss: 0.6882019873995048
Epoch: 35 | Iteration number: [530/565] 93% | Training loss: 0.688187309481063
Epoch: 35 | Iteration number: [540/565] 95% | Training loss: 0.6881699577525809
Epoch: 35 | Iteration number: [550/565] 97% | Training loss: 0.6881401872634888
Epoch: 35 | Iteration number: [560/565] 99% | Training loss: 0.6881206286805016

 End of epoch: 35 | Train Loss: 0.6868964355603784 | Training Time: 90 

 End of epoch: 35 | Eval Loss: 0.6897306442260742 | Evaluating Time: 6 
Epoch: 36 | Iteration number: [10/565] 1% | Training loss: 0.7554990708827972
Epoch: 36 | Iteration number: [20/565] 3% | Training loss: 0.7212429881095886
Epoch: 36 | Iteration number: [30/565] 5% | Training loss: 0.7097468892733256
Epoch: 36 | Iteration number: [40/565] 7% | Training loss: 0.7040488168597221
Epoch: 36 | Iteration number: [50/565] 8% | Training loss: 0.7006564712524415
Epoch: 36 | Iteration number: [60/565] 10% | Training loss: 0.698339095711708
Epoch: 36 | Iteration number: [70/565] 12% | Training loss: 0.6967549673148564
Epoch: 36 | Iteration number: [80/565] 14% | Training loss: 0.6954836539924145
Epoch: 36 | Iteration number: [90/565] 15% | Training loss: 0.6945268955495623
Epoch: 36 | Iteration number: [100/565] 17% | Training loss: 0.6938172852993012
Epoch: 36 | Iteration number: [110/565] 19% | Training loss: 0.69317258217118
Epoch: 36 | Iteration number: [120/565] 21% | Training loss: 0.6926687826712926
Epoch: 36 | Iteration number: [130/565] 23% | Training loss: 0.6921842465033898
Epoch: 36 | Iteration number: [140/565] 24% | Training loss: 0.6918094975607736
Epoch: 36 | Iteration number: [150/565] 26% | Training loss: 0.6915078858534495
Epoch: 36 | Iteration number: [160/565] 28% | Training loss: 0.6912170767784118
Epoch: 36 | Iteration number: [170/565] 30% | Training loss: 0.6910036146640778
Epoch: 36 | Iteration number: [180/565] 31% | Training loss: 0.6907664494382011
Epoch: 36 | Iteration number: [190/565] 33% | Training loss: 0.6905474493378088
Epoch: 36 | Iteration number: [200/565] 35% | Training loss: 0.6903615951538086
Epoch: 36 | Iteration number: [210/565] 37% | Training loss: 0.6901973309971038
Epoch: 36 | Iteration number: [220/565] 38% | Training loss: 0.6900314127857035
Epoch: 36 | Iteration number: [230/565] 40% | Training loss: 0.6899039654628091
Epoch: 36 | Iteration number: [240/565] 42% | Training loss: 0.6897848650813103
Epoch: 36 | Iteration number: [250/565] 44% | Training loss: 0.6896801257133484
Epoch: 36 | Iteration number: [260/565] 46% | Training loss: 0.689578823859875
Epoch: 36 | Iteration number: [270/565] 47% | Training loss: 0.6894730035905485
Epoch: 36 | Iteration number: [280/565] 49% | Training loss: 0.689378117450646
Epoch: 36 | Iteration number: [290/565] 51% | Training loss: 0.6892924158737577
Epoch: 36 | Iteration number: [300/565] 53% | Training loss: 0.6892010209957758
Epoch: 36 | Iteration number: [310/565] 54% | Training loss: 0.6891296998147042
Epoch: 36 | Iteration number: [320/565] 56% | Training loss: 0.6890644732862711
Epoch: 36 | Iteration number: [330/565] 58% | Training loss: 0.6889989663254131
Epoch: 36 | Iteration number: [340/565] 60% | Training loss: 0.6889359453145195
Epoch: 36 | Iteration number: [350/565] 61% | Training loss: 0.6888765903881618
Epoch: 36 | Iteration number: [360/565] 63% | Training loss: 0.6888161710566945
Epoch: 36 | Iteration number: [370/565] 65% | Training loss: 0.6887652814388275
Epoch: 36 | Iteration number: [380/565] 67% | Training loss: 0.6886978990153263
Epoch: 36 | Iteration number: [390/565] 69% | Training loss: 0.6886489513592843
Epoch: 36 | Iteration number: [400/565] 70% | Training loss: 0.6885915705561638
Epoch: 36 | Iteration number: [410/565] 72% | Training loss: 0.6885531751120962
Epoch: 36 | Iteration number: [420/565] 74% | Training loss: 0.6885145339227858
Epoch: 36 | Iteration number: [430/565] 76% | Training loss: 0.6884858008040938
Epoch: 36 | Iteration number: [440/565] 77% | Training loss: 0.688454694910483
Epoch: 36 | Iteration number: [450/565] 79% | Training loss: 0.6884172576003604
Epoch: 36 | Iteration number: [460/565] 81% | Training loss: 0.688378715644712
Epoch: 36 | Iteration number: [470/565] 83% | Training loss: 0.6883442065817245
Epoch: 36 | Iteration number: [480/565] 84% | Training loss: 0.68831282419463
Epoch: 36 | Iteration number: [490/565] 86% | Training loss: 0.6882765537622023
Epoch: 36 | Iteration number: [500/565] 88% | Training loss: 0.6882536435127258
Epoch: 36 | Iteration number: [510/565] 90% | Training loss: 0.6882369671382156
Epoch: 36 | Iteration number: [520/565] 92% | Training loss: 0.6882049171970441
Epoch: 36 | Iteration number: [530/565] 93% | Training loss: 0.6881799261524992
Epoch: 36 | Iteration number: [540/565] 95% | Training loss: 0.6881562163432439
Epoch: 36 | Iteration number: [550/565] 97% | Training loss: 0.6881267488002777
Epoch: 36 | Iteration number: [560/565] 99% | Training loss: 0.6880987983729158

 End of epoch: 36 | Train Loss: 0.686870251292676 | Training Time: 89 

 End of epoch: 36 | Eval Loss: 0.6896615283829826 | Evaluating Time: 6 
Epoch: 37 | Iteration number: [10/565] 1% | Training loss: 0.7556506335735321
Epoch: 37 | Iteration number: [20/565] 3% | Training loss: 0.7211659997701645
Epoch: 37 | Iteration number: [30/565] 5% | Training loss: 0.7097614467144012
Epoch: 37 | Iteration number: [40/565] 7% | Training loss: 0.7040302738547325
Epoch: 37 | Iteration number: [50/565] 8% | Training loss: 0.7006510055065155
Epoch: 37 | Iteration number: [60/565] 10% | Training loss: 0.6983321160078049
Epoch: 37 | Iteration number: [70/565] 12% | Training loss: 0.6966927145208631
Epoch: 37 | Iteration number: [80/565] 14% | Training loss: 0.6954437628388405
Epoch: 37 | Iteration number: [90/565] 15% | Training loss: 0.6945145534144508
Epoch: 37 | Iteration number: [100/565] 17% | Training loss: 0.6937930089235306
Epoch: 37 | Iteration number: [110/565] 19% | Training loss: 0.6931860224767165
Epoch: 37 | Iteration number: [120/565] 21% | Training loss: 0.6926422546307246
Epoch: 37 | Iteration number: [130/565] 23% | Training loss: 0.6922035130170675
Epoch: 37 | Iteration number: [140/565] 24% | Training loss: 0.6918032599346978
Epoch: 37 | Iteration number: [150/565] 26% | Training loss: 0.6914622644583385
Epoch: 37 | Iteration number: [160/565] 28% | Training loss: 0.6911775555461646
Epoch: 37 | Iteration number: [170/565] 30% | Training loss: 0.6909267474623287
Epoch: 37 | Iteration number: [180/565] 31% | Training loss: 0.6907224982976914
Epoch: 37 | Iteration number: [190/565] 33% | Training loss: 0.6905139967014915
Epoch: 37 | Iteration number: [200/565] 35% | Training loss: 0.6903340357542038
Epoch: 37 | Iteration number: [210/565] 37% | Training loss: 0.6901761758895147
Epoch: 37 | Iteration number: [220/565] 38% | Training loss: 0.6900294479998675
Epoch: 37 | Iteration number: [230/565] 40% | Training loss: 0.6898797587208126
Epoch: 37 | Iteration number: [240/565] 42% | Training loss: 0.6897667825222016
Epoch: 37 | Iteration number: [250/565] 44% | Training loss: 0.6896458270549775
Epoch: 37 | Iteration number: [260/565] 46% | Training loss: 0.689544422351397
Epoch: 37 | Iteration number: [270/565] 47% | Training loss: 0.6894489526748657
Epoch: 37 | Iteration number: [280/565] 49% | Training loss: 0.6893645542008536
Epoch: 37 | Iteration number: [290/565] 51% | Training loss: 0.6892777155185568
Epoch: 37 | Iteration number: [300/565] 53% | Training loss: 0.6891868803898493
Epoch: 37 | Iteration number: [310/565] 54% | Training loss: 0.6891238354867505
Epoch: 37 | Iteration number: [320/565] 56% | Training loss: 0.6890432849526406
Epoch: 37 | Iteration number: [330/565] 58% | Training loss: 0.6889798193266897
Epoch: 37 | Iteration number: [340/565] 60% | Training loss: 0.6889353822259342
Epoch: 37 | Iteration number: [350/565] 61% | Training loss: 0.6888649625437601
Epoch: 37 | Iteration number: [360/565] 63% | Training loss: 0.6888102938731512
Epoch: 37 | Iteration number: [370/565] 65% | Training loss: 0.6887589409544661
Epoch: 37 | Iteration number: [380/565] 67% | Training loss: 0.6887152141646335
Epoch: 37 | Iteration number: [390/565] 69% | Training loss: 0.6886554780678872
Epoch: 37 | Iteration number: [400/565] 70% | Training loss: 0.6886188621819019
Epoch: 37 | Iteration number: [410/565] 72% | Training loss: 0.6885793142202424
Epoch: 37 | Iteration number: [420/565] 74% | Training loss: 0.688544567993709
Epoch: 37 | Iteration number: [430/565] 76% | Training loss: 0.6885025578875874
Epoch: 37 | Iteration number: [440/565] 77% | Training loss: 0.6884719401597976
Epoch: 37 | Iteration number: [450/565] 79% | Training loss: 0.688435955842336
Epoch: 37 | Iteration number: [460/565] 81% | Training loss: 0.6883945759223855
Epoch: 37 | Iteration number: [470/565] 83% | Training loss: 0.6883653694010795
Epoch: 37 | Iteration number: [480/565] 84% | Training loss: 0.6883344775686662
Epoch: 37 | Iteration number: [490/565] 86% | Training loss: 0.6882974752358028
Epoch: 37 | Iteration number: [500/565] 88% | Training loss: 0.6882706513404846
Epoch: 37 | Iteration number: [510/565] 90% | Training loss: 0.6882412488554038
Epoch: 37 | Iteration number: [520/565] 92% | Training loss: 0.6882171559792298
Epoch: 37 | Iteration number: [530/565] 93% | Training loss: 0.6881901987318723
Epoch: 37 | Iteration number: [540/565] 95% | Training loss: 0.6881623562839296
Epoch: 37 | Iteration number: [550/565] 97% | Training loss: 0.6881318410960111
Epoch: 37 | Iteration number: [560/565] 99% | Training loss: 0.6881176786763328

 End of epoch: 37 | Train Loss: 0.6868879926943146 | Training Time: 89 

 End of epoch: 37 | Eval Loss: 0.6891651153564453 | Evaluating Time: 6 
Epoch: 38 | Iteration number: [10/565] 1% | Training loss: 0.7556087851524353
Epoch: 38 | Iteration number: [20/565] 3% | Training loss: 0.7212572306394577
Epoch: 38 | Iteration number: [30/565] 5% | Training loss: 0.7096838037172953
Epoch: 38 | Iteration number: [40/565] 7% | Training loss: 0.7038634315133094
Epoch: 38 | Iteration number: [50/565] 8% | Training loss: 0.7004269003868103
Epoch: 38 | Iteration number: [60/565] 10% | Training loss: 0.6981736073891321
Epoch: 38 | Iteration number: [70/565] 12% | Training loss: 0.696496262720653
Epoch: 38 | Iteration number: [80/565] 14% | Training loss: 0.6953567333519459
Epoch: 38 | Iteration number: [90/565] 15% | Training loss: 0.6944435954093933
Epoch: 38 | Iteration number: [100/565] 17% | Training loss: 0.6936703902482987
Epoch: 38 | Iteration number: [110/565] 19% | Training loss: 0.6930491897192869
Epoch: 38 | Iteration number: [120/565] 21% | Training loss: 0.6924973989526431
Epoch: 38 | Iteration number: [130/565] 23% | Training loss: 0.6920416093789614
Epoch: 38 | Iteration number: [140/565] 24% | Training loss: 0.6916846105030605
Epoch: 38 | Iteration number: [150/565] 26% | Training loss: 0.691344705025355
Epoch: 38 | Iteration number: [160/565] 28% | Training loss: 0.6910583488643169
Epoch: 38 | Iteration number: [170/565] 30% | Training loss: 0.6908224736942964
Epoch: 38 | Iteration number: [180/565] 31% | Training loss: 0.6905789170000288
Epoch: 38 | Iteration number: [190/565] 33% | Training loss: 0.6903734423612293
Epoch: 38 | Iteration number: [200/565] 35% | Training loss: 0.6901935878396034
Epoch: 38 | Iteration number: [210/565] 37% | Training loss: 0.6900353877317338
Epoch: 38 | Iteration number: [220/565] 38% | Training loss: 0.6898925537412817
Epoch: 38 | Iteration number: [230/565] 40% | Training loss: 0.689777217740598
Epoch: 38 | Iteration number: [240/565] 42% | Training loss: 0.6896581391493479
Epoch: 38 | Iteration number: [250/565] 44% | Training loss: 0.6895531101226806
Epoch: 38 | Iteration number: [260/565] 46% | Training loss: 0.6894458906008647
Epoch: 38 | Iteration number: [270/565] 47% | Training loss: 0.6893510162830353
Epoch: 38 | Iteration number: [280/565] 49% | Training loss: 0.6892714255622455
Epoch: 38 | Iteration number: [290/565] 51% | Training loss: 0.6891991722172705
Epoch: 38 | Iteration number: [300/565] 53% | Training loss: 0.6891330101092656
Epoch: 38 | Iteration number: [310/565] 54% | Training loss: 0.6890553161021202
Epoch: 38 | Iteration number: [320/565] 56% | Training loss: 0.6889954032376409
Epoch: 38 | Iteration number: [330/565] 58% | Training loss: 0.6889185011386871
Epoch: 38 | Iteration number: [340/565] 60% | Training loss: 0.6888594210147858
Epoch: 38 | Iteration number: [350/565] 61% | Training loss: 0.6887992358207703
Epoch: 38 | Iteration number: [360/565] 63% | Training loss: 0.6887514746851391
Epoch: 38 | Iteration number: [370/565] 65% | Training loss: 0.6886967915135461
Epoch: 38 | Iteration number: [380/565] 67% | Training loss: 0.6886395176774577
Epoch: 38 | Iteration number: [390/565] 69% | Training loss: 0.6885958882478568
Epoch: 38 | Iteration number: [400/565] 70% | Training loss: 0.6885545445978641
Epoch: 38 | Iteration number: [410/565] 72% | Training loss: 0.6885023602625219
Epoch: 38 | Iteration number: [420/565] 74% | Training loss: 0.6884666765020007
Epoch: 38 | Iteration number: [430/565] 76% | Training loss: 0.6884304249009421
Epoch: 38 | Iteration number: [440/565] 77% | Training loss: 0.6884002602913163
Epoch: 38 | Iteration number: [450/565] 79% | Training loss: 0.6883570963806577
Epoch: 38 | Iteration number: [460/565] 81% | Training loss: 0.6883307034554689
Epoch: 38 | Iteration number: [470/565] 83% | Training loss: 0.6883037061133284
Epoch: 38 | Iteration number: [480/565] 84% | Training loss: 0.6882693149149418
Epoch: 38 | Iteration number: [490/565] 86% | Training loss: 0.6882314403446353
Epoch: 38 | Iteration number: [500/565] 88% | Training loss: 0.6882017314434051
Epoch: 38 | Iteration number: [510/565] 90% | Training loss: 0.6881922578110414
Epoch: 38 | Iteration number: [520/565] 92% | Training loss: 0.6881659391980904
Epoch: 38 | Iteration number: [530/565] 93% | Training loss: 0.6881333508581485
Epoch: 38 | Iteration number: [540/565] 95% | Training loss: 0.6881263347687545
Epoch: 38 | Iteration number: [550/565] 97% | Training loss: 0.6881057351285761
Epoch: 38 | Iteration number: [560/565] 99% | Training loss: 0.6880916762564864

 End of epoch: 38 | Train Loss: 0.6868642303795941 | Training Time: 88 

 End of epoch: 38 | Eval Loss: 0.6895478367805481 | Evaluating Time: 6 
Epoch: 39 | Iteration number: [10/565] 1% | Training loss: 0.7554081082344055
Epoch: 39 | Iteration number: [20/565] 3% | Training loss: 0.7210921108722687
Epoch: 39 | Iteration number: [30/565] 5% | Training loss: 0.709826648235321
Epoch: 39 | Iteration number: [40/565] 7% | Training loss: 0.7041047260165214
Epoch: 39 | Iteration number: [50/565] 8% | Training loss: 0.7006767582893372
Epoch: 39 | Iteration number: [60/565] 10% | Training loss: 0.6983660697937012
Epoch: 39 | Iteration number: [70/565] 12% | Training loss: 0.6967292410986764
Epoch: 39 | Iteration number: [80/565] 14% | Training loss: 0.6955289520323277
Epoch: 39 | Iteration number: [90/565] 15% | Training loss: 0.6946086870299445
Epoch: 39 | Iteration number: [100/565] 17% | Training loss: 0.6938762682676315
Epoch: 39 | Iteration number: [110/565] 19% | Training loss: 0.6932259277863936
Epoch: 39 | Iteration number: [120/565] 21% | Training loss: 0.6926976904273033
Epoch: 39 | Iteration number: [130/565] 23% | Training loss: 0.6922567285024203
Epoch: 39 | Iteration number: [140/565] 24% | Training loss: 0.6918671007667269
Epoch: 39 | Iteration number: [150/565] 26% | Training loss: 0.6915299558639526
Epoch: 39 | Iteration number: [160/565] 28% | Training loss: 0.6912380505353213
Epoch: 39 | Iteration number: [170/565] 30% | Training loss: 0.6909703068873462
Epoch: 39 | Iteration number: [180/565] 31% | Training loss: 0.6907496598031786
Epoch: 39 | Iteration number: [190/565] 33% | Training loss: 0.6905703321883553
Epoch: 39 | Iteration number: [200/565] 35% | Training loss: 0.6903674200177192
Epoch: 39 | Iteration number: [210/565] 37% | Training loss: 0.6901971459388733
Epoch: 39 | Iteration number: [220/565] 38% | Training loss: 0.6900204506787386
Epoch: 39 | Iteration number: [230/565] 40% | Training loss: 0.6898973299109418
Epoch: 39 | Iteration number: [240/565] 42% | Training loss: 0.6897774701317151
Epoch: 39 | Iteration number: [250/565] 44% | Training loss: 0.6896553463935852
Epoch: 39 | Iteration number: [260/565] 46% | Training loss: 0.6895544464771565
Epoch: 39 | Iteration number: [270/565] 47% | Training loss: 0.6894532689341792
Epoch: 39 | Iteration number: [280/565] 49% | Training loss: 0.6893600340400423
Epoch: 39 | Iteration number: [290/565] 51% | Training loss: 0.6892819856775219
Epoch: 39 | Iteration number: [300/565] 53% | Training loss: 0.6891854425271352
Epoch: 39 | Iteration number: [310/565] 54% | Training loss: 0.68912547134584
Epoch: 39 | Iteration number: [320/565] 56% | Training loss: 0.689047934859991
Epoch: 39 | Iteration number: [330/565] 58% | Training loss: 0.6889823454799074
Epoch: 39 | Iteration number: [340/565] 60% | Training loss: 0.688914758142303
Epoch: 39 | Iteration number: [350/565] 61% | Training loss: 0.6888603407996041
Epoch: 39 | Iteration number: [360/565] 63% | Training loss: 0.688802470266819
Epoch: 39 | Iteration number: [370/565] 65% | Training loss: 0.6887496904746906
Epoch: 39 | Iteration number: [380/565] 67% | Training loss: 0.6887057905134402
Epoch: 39 | Iteration number: [390/565] 69% | Training loss: 0.6886545895001828
Epoch: 39 | Iteration number: [400/565] 70% | Training loss: 0.6886081206798553
Epoch: 39 | Iteration number: [410/565] 72% | Training loss: 0.6885624850668558
Epoch: 39 | Iteration number: [420/565] 74% | Training loss: 0.6885245084762573
Epoch: 39 | Iteration number: [430/565] 76% | Training loss: 0.6884886183017909
Epoch: 39 | Iteration number: [440/565] 77% | Training loss: 0.6884505480527878
Epoch: 39 | Iteration number: [450/565] 79% | Training loss: 0.688408649497562
Epoch: 39 | Iteration number: [460/565] 81% | Training loss: 0.6883725093758625
Epoch: 39 | Iteration number: [470/565] 83% | Training loss: 0.6883429821501387
Epoch: 39 | Iteration number: [480/565] 84% | Training loss: 0.6883155105014642
Epoch: 39 | Iteration number: [490/565] 86% | Training loss: 0.6882868532015353
Epoch: 39 | Iteration number: [500/565] 88% | Training loss: 0.6882573740482331
Epoch: 39 | Iteration number: [510/565] 90% | Training loss: 0.6882282703530554
Epoch: 39 | Iteration number: [520/565] 92% | Training loss: 0.6881976994184348
Epoch: 39 | Iteration number: [530/565] 93% | Training loss: 0.6881656172140589
Epoch: 39 | Iteration number: [540/565] 95% | Training loss: 0.6881429346623245
Epoch: 39 | Iteration number: [550/565] 97% | Training loss: 0.688115675015883
Epoch: 39 | Iteration number: [560/565] 99% | Training loss: 0.6880927463727338

 End of epoch: 39 | Train Loss: 0.6868631490563925 | Training Time: 90 

 End of epoch: 39 | Eval Loss: 0.6896526983806065 | Evaluating Time: 5 
Epoch: 40 | Iteration number: [10/565] 1% | Training loss: 0.7557015419006348
Epoch: 40 | Iteration number: [20/565] 3% | Training loss: 0.7213244497776031
Epoch: 40 | Iteration number: [30/565] 5% | Training loss: 0.7097941180070241
Epoch: 40 | Iteration number: [40/565] 7% | Training loss: 0.7039641231298447
Epoch: 40 | Iteration number: [50/565] 8% | Training loss: 0.7005528616905212
Epoch: 40 | Iteration number: [60/565] 10% | Training loss: 0.6982611298561097
Epoch: 40 | Iteration number: [70/565] 12% | Training loss: 0.6965912452765873
Epoch: 40 | Iteration number: [80/565] 14% | Training loss: 0.6954028211534024
Epoch: 40 | Iteration number: [90/565] 15% | Training loss: 0.6944878101348877
Epoch: 40 | Iteration number: [100/565] 17% | Training loss: 0.6937018311023713
Epoch: 40 | Iteration number: [110/565] 19% | Training loss: 0.6930613479831002
Epoch: 40 | Iteration number: [120/565] 21% | Training loss: 0.6925446858008703
Epoch: 40 | Iteration number: [130/565] 23% | Training loss: 0.6921017633034633
Epoch: 40 | Iteration number: [140/565] 24% | Training loss: 0.6917379217488425
Epoch: 40 | Iteration number: [150/565] 26% | Training loss: 0.6914204065004984
Epoch: 40 | Iteration number: [160/565] 28% | Training loss: 0.6911194134503603
Epoch: 40 | Iteration number: [170/565] 30% | Training loss: 0.6908542510341196
Epoch: 40 | Iteration number: [180/565] 31% | Training loss: 0.6906343834267722
Epoch: 40 | Iteration number: [190/565] 33% | Training loss: 0.6904504979911603
Epoch: 40 | Iteration number: [200/565] 35% | Training loss: 0.6902603355050086
Epoch: 40 | Iteration number: [210/565] 37% | Training loss: 0.6900890750544412
Epoch: 40 | Iteration number: [220/565] 38% | Training loss: 0.689972679994323
Epoch: 40 | Iteration number: [230/565] 40% | Training loss: 0.6898546104845793
Epoch: 40 | Iteration number: [240/565] 42% | Training loss: 0.6897381318112215
Epoch: 40 | Iteration number: [250/565] 44% | Training loss: 0.6896273465156555
Epoch: 40 | Iteration number: [260/565] 46% | Training loss: 0.6895071107607621
Epoch: 40 | Iteration number: [270/565] 47% | Training loss: 0.6894087950388591
Epoch: 40 | Iteration number: [280/565] 49% | Training loss: 0.6893209842698914
Epoch: 40 | Iteration number: [290/565] 51% | Training loss: 0.6892141650462973
Epoch: 40 | Iteration number: [300/565] 53% | Training loss: 0.6891418542464575
Epoch: 40 | Iteration number: [310/565] 54% | Training loss: 0.6890651170284517
Epoch: 40 | Iteration number: [320/565] 56% | Training loss: 0.6890052415430545
Epoch: 40 | Iteration number: [330/565] 58% | Training loss: 0.6889441076553229
Epoch: 40 | Iteration number: [340/565] 60% | Training loss: 0.6888793440426098
Epoch: 40 | Iteration number: [350/565] 61% | Training loss: 0.688831946679524
Epoch: 40 | Iteration number: [360/565] 63% | Training loss: 0.688788562019666
Epoch: 40 | Iteration number: [370/565] 65% | Training loss: 0.6887366944068187
Epoch: 40 | Iteration number: [380/565] 67% | Training loss: 0.6886798366119987
Epoch: 40 | Iteration number: [390/565] 69% | Training loss: 0.6886303658668812
Epoch: 40 | Iteration number: [400/565] 70% | Training loss: 0.6885788272321224
Epoch: 40 | Iteration number: [410/565] 72% | Training loss: 0.688539901303082
Epoch: 40 | Iteration number: [420/565] 74% | Training loss: 0.6884996275107066
Epoch: 40 | Iteration number: [430/565] 76% | Training loss: 0.6884654404119004
Epoch: 40 | Iteration number: [440/565] 77% | Training loss: 0.6884262162176046
Epoch: 40 | Iteration number: [450/565] 79% | Training loss: 0.6883924600813124
Epoch: 40 | Iteration number: [460/565] 81% | Training loss: 0.688361275843952
Epoch: 40 | Iteration number: [470/565] 83% | Training loss: 0.6883409591431313
Epoch: 40 | Iteration number: [480/565] 84% | Training loss: 0.6883113373070955
Epoch: 40 | Iteration number: [490/565] 86% | Training loss: 0.6882884678791981
Epoch: 40 | Iteration number: [500/565] 88% | Training loss: 0.6882516896724701
Epoch: 40 | Iteration number: [510/565] 90% | Training loss: 0.6882231822200849
Epoch: 40 | Iteration number: [520/565] 92% | Training loss: 0.6881837768050341
Epoch: 40 | Iteration number: [530/565] 93% | Training loss: 0.6881598510832156
Epoch: 40 | Iteration number: [540/565] 95% | Training loss: 0.6881368810379946
Epoch: 40 | Iteration number: [550/565] 97% | Training loss: 0.68811426802115
Epoch: 40 | Iteration number: [560/565] 99% | Training loss: 0.6880782505231244

 End of epoch: 40 | Train Loss: 0.6868455166310335 | Training Time: 87 

 End of epoch: 40 | Eval Loss: 0.6893753664834159 | Evaluating Time: 6 
Epoch: 41 | Iteration number: [10/565] 1% | Training loss: 0.7554116368293762
Epoch: 41 | Iteration number: [20/565] 3% | Training loss: 0.7211885839700699
Epoch: 41 | Iteration number: [30/565] 5% | Training loss: 0.7097576320171356
Epoch: 41 | Iteration number: [40/565] 7% | Training loss: 0.7041671499609947
Epoch: 41 | Iteration number: [50/565] 8% | Training loss: 0.7006549334526062
Epoch: 41 | Iteration number: [60/565] 10% | Training loss: 0.6983621219793955
Epoch: 41 | Iteration number: [70/565] 12% | Training loss: 0.6967351913452149
Epoch: 41 | Iteration number: [80/565] 14% | Training loss: 0.6955075576901436
Epoch: 41 | Iteration number: [90/565] 15% | Training loss: 0.6945785370137957
Epoch: 41 | Iteration number: [100/565] 17% | Training loss: 0.6937929677963257
Epoch: 41 | Iteration number: [110/565] 19% | Training loss: 0.6931158575144681
Epoch: 41 | Iteration number: [120/565] 21% | Training loss: 0.6925844505429268
Epoch: 41 | Iteration number: [130/565] 23% | Training loss: 0.6921299677628737
Epoch: 41 | Iteration number: [140/565] 24% | Training loss: 0.6917790544884546
Epoch: 41 | Iteration number: [150/565] 26% | Training loss: 0.6914516858259837
Epoch: 41 | Iteration number: [160/565] 28% | Training loss: 0.6911541666835547
Epoch: 41 | Iteration number: [170/565] 30% | Training loss: 0.6909029399647432
Epoch: 41 | Iteration number: [180/565] 31% | Training loss: 0.690663347641627
Epoch: 41 | Iteration number: [190/565] 33% | Training loss: 0.6904690943266216
Epoch: 41 | Iteration number: [200/565] 35% | Training loss: 0.6902808636426926
Epoch: 41 | Iteration number: [210/565] 37% | Training loss: 0.6901308718181792
Epoch: 41 | Iteration number: [220/565] 38% | Training loss: 0.6899776111949574
Epoch: 41 | Iteration number: [230/565] 40% | Training loss: 0.6898650555506997
Epoch: 41 | Iteration number: [240/565] 42% | Training loss: 0.6897439981500307
Epoch: 41 | Iteration number: [250/565] 44% | Training loss: 0.6896330013275146
Epoch: 41 | Iteration number: [260/565] 46% | Training loss: 0.6895406615275603
Epoch: 41 | Iteration number: [270/565] 47% | Training loss: 0.6894521287194004
Epoch: 41 | Iteration number: [280/565] 49% | Training loss: 0.6893748021551541
Epoch: 41 | Iteration number: [290/565] 51% | Training loss: 0.6892924756839358
Epoch: 41 | Iteration number: [300/565] 53% | Training loss: 0.6891994102795919
Epoch: 41 | Iteration number: [310/565] 54% | Training loss: 0.6891224322780486
Epoch: 41 | Iteration number: [320/565] 56% | Training loss: 0.6890633409842849
Epoch: 41 | Iteration number: [330/565] 58% | Training loss: 0.6889936523004012
Epoch: 41 | Iteration number: [340/565] 60% | Training loss: 0.6889418803593692
Epoch: 41 | Iteration number: [350/565] 61% | Training loss: 0.688901355266571
Epoch: 41 | Iteration number: [360/565] 63% | Training loss: 0.6888418876462512
Epoch: 41 | Iteration number: [370/565] 65% | Training loss: 0.6887854653435784
Epoch: 41 | Iteration number: [380/565] 67% | Training loss: 0.688734024606253
Epoch: 41 | Iteration number: [390/565] 69% | Training loss: 0.6886862666178972
Epoch: 41 | Iteration number: [400/565] 70% | Training loss: 0.6886336001753807
Epoch: 41 | Iteration number: [410/565] 72% | Training loss: 0.6885935496993181
Epoch: 41 | Iteration number: [420/565] 74% | Training loss: 0.6885485982611066
Epoch: 41 | Iteration number: [430/565] 76% | Training loss: 0.6884956831155822
Epoch: 41 | Iteration number: [440/565] 77% | Training loss: 0.688452153720639
Epoch: 41 | Iteration number: [450/565] 79% | Training loss: 0.6884143706162771
Epoch: 41 | Iteration number: [460/565] 81% | Training loss: 0.6883827669465024
Epoch: 41 | Iteration number: [470/565] 83% | Training loss: 0.688350223480387
Epoch: 41 | Iteration number: [480/565] 84% | Training loss: 0.6883189503103495
Epoch: 41 | Iteration number: [490/565] 86% | Training loss: 0.6882914949436577
Epoch: 41 | Iteration number: [500/565] 88% | Training loss: 0.6882525213956833
Epoch: 41 | Iteration number: [510/565] 90% | Training loss: 0.688239413616704
Epoch: 41 | Iteration number: [520/565] 92% | Training loss: 0.6882082709899315
Epoch: 41 | Iteration number: [530/565] 93% | Training loss: 0.6881826892214001
Epoch: 41 | Iteration number: [540/565] 95% | Training loss: 0.6881587236015885
Epoch: 41 | Iteration number: [550/565] 97% | Training loss: 0.6881282365322113
Epoch: 41 | Iteration number: [560/565] 99% | Training loss: 0.6880998469889164

 End of epoch: 41 | Train Loss: 0.6868750369654293 | Training Time: 89 

 End of epoch: 41 | Eval Loss: 0.6896162543978009 | Evaluating Time: 6 
Epoch: 42 | Iteration number: [10/565] 1% | Training loss: 0.7559160888195038
Epoch: 42 | Iteration number: [20/565] 3% | Training loss: 0.721227166056633
Epoch: 42 | Iteration number: [30/565] 5% | Training loss: 0.7097810447216034
Epoch: 42 | Iteration number: [40/565] 7% | Training loss: 0.7040519624948501
Epoch: 42 | Iteration number: [50/565] 8% | Training loss: 0.7006239080429078
Epoch: 42 | Iteration number: [60/565] 10% | Training loss: 0.6982981274525325
Epoch: 42 | Iteration number: [70/565] 12% | Training loss: 0.6966981334345681
Epoch: 42 | Iteration number: [80/565] 14% | Training loss: 0.6955309838056565
Epoch: 42 | Iteration number: [90/565] 15% | Training loss: 0.6945410086048974
Epoch: 42 | Iteration number: [100/565] 17% | Training loss: 0.6937508261203766
Epoch: 42 | Iteration number: [110/565] 19% | Training loss: 0.6931275329806588
Epoch: 42 | Iteration number: [120/565] 21% | Training loss: 0.6926106095314026
Epoch: 42 | Iteration number: [130/565] 23% | Training loss: 0.6921612968811622
Epoch: 42 | Iteration number: [140/565] 24% | Training loss: 0.6917838948113578
Epoch: 42 | Iteration number: [150/565] 26% | Training loss: 0.691431036790212
Epoch: 42 | Iteration number: [160/565] 28% | Training loss: 0.6911347191780806
Epoch: 42 | Iteration number: [170/565] 30% | Training loss: 0.6908763867967269
Epoch: 42 | Iteration number: [180/565] 31% | Training loss: 0.6906525598631965
Epoch: 42 | Iteration number: [190/565] 33% | Training loss: 0.6904747545719147
Epoch: 42 | Iteration number: [200/565] 35% | Training loss: 0.6902965486049653
Epoch: 42 | Iteration number: [210/565] 37% | Training loss: 0.6901484739212763
Epoch: 42 | Iteration number: [220/565] 38% | Training loss: 0.6899821972305125
Epoch: 42 | Iteration number: [230/565] 40% | Training loss: 0.689838693452918
Epoch: 42 | Iteration number: [240/565] 42% | Training loss: 0.6897303879261016
Epoch: 42 | Iteration number: [250/565] 44% | Training loss: 0.6896134314537048
Epoch: 42 | Iteration number: [260/565] 46% | Training loss: 0.68951787008689
Epoch: 42 | Iteration number: [270/565] 47% | Training loss: 0.6894093312599041
Epoch: 42 | Iteration number: [280/565] 49% | Training loss: 0.6893181532621384
Epoch: 42 | Iteration number: [290/565] 51% | Training loss: 0.6892179959806902
Epoch: 42 | Iteration number: [300/565] 53% | Training loss: 0.6891322024663289
Epoch: 42 | Iteration number: [310/565] 54% | Training loss: 0.6890635782672513
Epoch: 42 | Iteration number: [320/565] 56% | Training loss: 0.6890098620206118
Epoch: 42 | Iteration number: [330/565] 58% | Training loss: 0.6889400673635078
Epoch: 42 | Iteration number: [340/565] 60% | Training loss: 0.6888833762968287
Epoch: 42 | Iteration number: [350/565] 61% | Training loss: 0.6888152645315443
Epoch: 42 | Iteration number: [360/565] 63% | Training loss: 0.6887717179126209
Epoch: 42 | Iteration number: [370/565] 65% | Training loss: 0.6887115069337794
Epoch: 42 | Iteration number: [380/565] 67% | Training loss: 0.6886691978103237
Epoch: 42 | Iteration number: [390/565] 69% | Training loss: 0.6886174579461416
Epoch: 42 | Iteration number: [400/565] 70% | Training loss: 0.6885794724524021
Epoch: 42 | Iteration number: [410/565] 72% | Training loss: 0.6885356561439794
Epoch: 42 | Iteration number: [420/565] 74% | Training loss: 0.6885079044671286
Epoch: 42 | Iteration number: [430/565] 76% | Training loss: 0.6884636920551921
Epoch: 42 | Iteration number: [440/565] 77% | Training loss: 0.6884255248037252
Epoch: 42 | Iteration number: [450/565] 79% | Training loss: 0.6883831486437055
Epoch: 42 | Iteration number: [460/565] 81% | Training loss: 0.6883436324803726
Epoch: 42 | Iteration number: [470/565] 83% | Training loss: 0.6883087785954171
Epoch: 42 | Iteration number: [480/565] 84% | Training loss: 0.6882721686114868
Epoch: 42 | Iteration number: [490/565] 86% | Training loss: 0.6882475606032781
Epoch: 42 | Iteration number: [500/565] 88% | Training loss: 0.6882179183959961
Epoch: 42 | Iteration number: [510/565] 90% | Training loss: 0.6881917068771287
Epoch: 42 | Iteration number: [520/565] 92% | Training loss: 0.6881675294958628
Epoch: 42 | Iteration number: [530/565] 93% | Training loss: 0.6881399650618715
Epoch: 42 | Iteration number: [540/565] 95% | Training loss: 0.6881273754217007
Epoch: 42 | Iteration number: [550/565] 97% | Training loss: 0.68809986168688
Epoch: 42 | Iteration number: [560/565] 99% | Training loss: 0.6880784994789533

 End of epoch: 42 | Train Loss: 0.6868530765043951 | Training Time: 88 

 End of epoch: 42 | Eval Loss: 0.6893660085541862 | Evaluating Time: 5 
Epoch: 43 | Iteration number: [10/565] 1% | Training loss: 0.755617368221283
Epoch: 43 | Iteration number: [20/565] 3% | Training loss: 0.7212377488613129
Epoch: 43 | Iteration number: [30/565] 5% | Training loss: 0.7098796347777049
Epoch: 43 | Iteration number: [40/565] 7% | Training loss: 0.7042551457881927
Epoch: 43 | Iteration number: [50/565] 8% | Training loss: 0.7007636272907257
Epoch: 43 | Iteration number: [60/565] 10% | Training loss: 0.6985554913679759
Epoch: 43 | Iteration number: [70/565] 12% | Training loss: 0.6968802400997707
Epoch: 43 | Iteration number: [80/565] 14% | Training loss: 0.6955346681177617
Epoch: 43 | Iteration number: [90/565] 15% | Training loss: 0.6945966283480326
Epoch: 43 | Iteration number: [100/565] 17% | Training loss: 0.6937920701503754
Epoch: 43 | Iteration number: [110/565] 19% | Training loss: 0.6931920143690976
Epoch: 43 | Iteration number: [120/565] 21% | Training loss: 0.6927168453733127
Epoch: 43 | Iteration number: [130/565] 23% | Training loss: 0.6922404247980851
Epoch: 43 | Iteration number: [140/565] 24% | Training loss: 0.69185400222029
Epoch: 43 | Iteration number: [150/565] 26% | Training loss: 0.6915074920654297
Epoch: 43 | Iteration number: [160/565] 28% | Training loss: 0.691212659701705
Epoch: 43 | Iteration number: [170/565] 30% | Training loss: 0.6909707132507773
Epoch: 43 | Iteration number: [180/565] 31% | Training loss: 0.6907443645927641
Epoch: 43 | Iteration number: [190/565] 33% | Training loss: 0.6905301511287689
Epoch: 43 | Iteration number: [200/565] 35% | Training loss: 0.6903270140290261
Epoch: 43 | Iteration number: [210/565] 37% | Training loss: 0.6901686974934169
Epoch: 43 | Iteration number: [220/565] 38% | Training loss: 0.6900145782665773
Epoch: 43 | Iteration number: [230/565] 40% | Training loss: 0.6898792067299718
Epoch: 43 | Iteration number: [240/565] 42% | Training loss: 0.6897579602897167
Epoch: 43 | Iteration number: [250/565] 44% | Training loss: 0.6896359429359437
Epoch: 43 | Iteration number: [260/565] 46% | Training loss: 0.6895452783657954
Epoch: 43 | Iteration number: [270/565] 47% | Training loss: 0.6894436767807713
Epoch: 43 | Iteration number: [280/565] 49% | Training loss: 0.689354630453246
Epoch: 43 | Iteration number: [290/565] 51% | Training loss: 0.6892572690700662
Epoch: 43 | Iteration number: [300/565] 53% | Training loss: 0.6891513125101725
Epoch: 43 | Iteration number: [310/565] 54% | Training loss: 0.6890897279785525
Epoch: 43 | Iteration number: [320/565] 56% | Training loss: 0.6890255462378263
Epoch: 43 | Iteration number: [330/565] 58% | Training loss: 0.6889621465495138
Epoch: 43 | Iteration number: [340/565] 60% | Training loss: 0.6889072602286058
Epoch: 43 | Iteration number: [350/565] 61% | Training loss: 0.6888650722163064
Epoch: 43 | Iteration number: [360/565] 63% | Training loss: 0.6887996981541316
Epoch: 43 | Iteration number: [370/565] 65% | Training loss: 0.6887375377319954
Epoch: 43 | Iteration number: [380/565] 67% | Training loss: 0.6886756424841128
Epoch: 43 | Iteration number: [390/565] 69% | Training loss: 0.6886151984716073
Epoch: 43 | Iteration number: [400/565] 70% | Training loss: 0.688574031740427
Epoch: 43 | Iteration number: [410/565] 72% | Training loss: 0.6885355112029286
Epoch: 43 | Iteration number: [420/565] 74% | Training loss: 0.6884915624346052
Epoch: 43 | Iteration number: [430/565] 76% | Training loss: 0.6884651595769926
Epoch: 43 | Iteration number: [440/565] 77% | Training loss: 0.6884309237653559
Epoch: 43 | Iteration number: [450/565] 79% | Training loss: 0.6883883145120409
Epoch: 43 | Iteration number: [460/565] 81% | Training loss: 0.6883534978265348
Epoch: 43 | Iteration number: [470/565] 83% | Training loss: 0.6883198148392616
Epoch: 43 | Iteration number: [480/565] 84% | Training loss: 0.6882888602713744
Epoch: 43 | Iteration number: [490/565] 86% | Training loss: 0.6882556821618762
Epoch: 43 | Iteration number: [500/565] 88% | Training loss: 0.6882236605882645
Epoch: 43 | Iteration number: [510/565] 90% | Training loss: 0.6881890238500109
Epoch: 43 | Iteration number: [520/565] 92% | Training loss: 0.6881726890802383
Epoch: 43 | Iteration number: [530/565] 93% | Training loss: 0.6881438211450037
Epoch: 43 | Iteration number: [540/565] 95% | Training loss: 0.6881207714478175
Epoch: 43 | Iteration number: [550/565] 97% | Training loss: 0.688082882491025
Epoch: 43 | Iteration number: [560/565] 99% | Training loss: 0.6880707155380931

 End of epoch: 43 | Train Loss: 0.6868437675248205 | Training Time: 90 

 End of epoch: 43 | Eval Loss: 0.6892275725092206 | Evaluating Time: 6 
Epoch: 44 | Iteration number: [10/565] 1% | Training loss: 0.7554376780986786
Epoch: 44 | Iteration number: [20/565] 3% | Training loss: 0.7212179243564606
Epoch: 44 | Iteration number: [30/565] 5% | Training loss: 0.7097602764765422
Epoch: 44 | Iteration number: [40/565] 7% | Training loss: 0.7039605602622032
Epoch: 44 | Iteration number: [50/565] 8% | Training loss: 0.700552544593811
Epoch: 44 | Iteration number: [60/565] 10% | Training loss: 0.6982110222180684
Epoch: 44 | Iteration number: [70/565] 12% | Training loss: 0.6965918438775199
Epoch: 44 | Iteration number: [80/565] 14% | Training loss: 0.6953484274446964
Epoch: 44 | Iteration number: [90/565] 15% | Training loss: 0.69440821674135
Epoch: 44 | Iteration number: [100/565] 17% | Training loss: 0.6936683219671249
Epoch: 44 | Iteration number: [110/565] 19% | Training loss: 0.693031350590966
Epoch: 44 | Iteration number: [120/565] 21% | Training loss: 0.6924924234549205
Epoch: 44 | Iteration number: [130/565] 23% | Training loss: 0.6920223034345186
Epoch: 44 | Iteration number: [140/565] 24% | Training loss: 0.6916396996804646
Epoch: 44 | Iteration number: [150/565] 26% | Training loss: 0.6913442893822987
Epoch: 44 | Iteration number: [160/565] 28% | Training loss: 0.6910414583981037
Epoch: 44 | Iteration number: [170/565] 30% | Training loss: 0.6907966974903555
Epoch: 44 | Iteration number: [180/565] 31% | Training loss: 0.6905626459254159
Epoch: 44 | Iteration number: [190/565] 33% | Training loss: 0.6903831321942179
Epoch: 44 | Iteration number: [200/565] 35% | Training loss: 0.6902214226126671
Epoch: 44 | Iteration number: [210/565] 37% | Training loss: 0.6900625924269358
Epoch: 44 | Iteration number: [220/565] 38% | Training loss: 0.6899051194841211
Epoch: 44 | Iteration number: [230/565] 40% | Training loss: 0.6897776458574378
Epoch: 44 | Iteration number: [240/565] 42% | Training loss: 0.6896686953802903
Epoch: 44 | Iteration number: [250/565] 44% | Training loss: 0.6895567634105683
Epoch: 44 | Iteration number: [260/565] 46% | Training loss: 0.6894553228066518
Epoch: 44 | Iteration number: [270/565] 47% | Training loss: 0.6893459849887424
Epoch: 44 | Iteration number: [280/565] 49% | Training loss: 0.6892591242279326
Epoch: 44 | Iteration number: [290/565] 51% | Training loss: 0.6891786042986245
Epoch: 44 | Iteration number: [300/565] 53% | Training loss: 0.6891048455238342
Epoch: 44 | Iteration number: [310/565] 54% | Training loss: 0.6890337224929564
Epoch: 44 | Iteration number: [320/565] 56% | Training loss: 0.6889664174988865
Epoch: 44 | Iteration number: [330/565] 58% | Training loss: 0.6889047066370646
Epoch: 44 | Iteration number: [340/565] 60% | Training loss: 0.6888344855869517
Epoch: 44 | Iteration number: [350/565] 61% | Training loss: 0.6887849353040968
Epoch: 44 | Iteration number: [360/565] 63% | Training loss: 0.6887332942750719
Epoch: 44 | Iteration number: [370/565] 65% | Training loss: 0.688675548901429
Epoch: 44 | Iteration number: [380/565] 67% | Training loss: 0.6886330750427748
Epoch: 44 | Iteration number: [390/565] 69% | Training loss: 0.6885953897084945
Epoch: 44 | Iteration number: [400/565] 70% | Training loss: 0.6885589933395386
Epoch: 44 | Iteration number: [410/565] 72% | Training loss: 0.6885182111728482
Epoch: 44 | Iteration number: [420/565] 74% | Training loss: 0.6884877414930435
Epoch: 44 | Iteration number: [430/565] 76% | Training loss: 0.6884453280027523
Epoch: 44 | Iteration number: [440/565] 77% | Training loss: 0.6884051169861447
Epoch: 44 | Iteration number: [450/565] 79% | Training loss: 0.6883631671799554
Epoch: 44 | Iteration number: [460/565] 81% | Training loss: 0.6883280741131824
Epoch: 44 | Iteration number: [470/565] 83% | Training loss: 0.6882829914701746
Epoch: 44 | Iteration number: [480/565] 84% | Training loss: 0.6882590095202128
Epoch: 44 | Iteration number: [490/565] 86% | Training loss: 0.6882368582852033
Epoch: 44 | Iteration number: [500/565] 88% | Training loss: 0.6882000753879547
Epoch: 44 | Iteration number: [510/565] 90% | Training loss: 0.6881798864579668
Epoch: 44 | Iteration number: [520/565] 92% | Training loss: 0.688158265558573
Epoch: 44 | Iteration number: [530/565] 93% | Training loss: 0.6881338306193082
Epoch: 44 | Iteration number: [540/565] 95% | Training loss: 0.6881083360424748
Epoch: 44 | Iteration number: [550/565] 97% | Training loss: 0.6880859842083671
Epoch: 44 | Iteration number: [560/565] 99% | Training loss: 0.6880633953426566

 End of epoch: 44 | Train Loss: 0.6868392443234942 | Training Time: 89 

 End of epoch: 44 | Eval Loss: 0.6894588044711522 | Evaluating Time: 6 
Epoch: 45 | Iteration number: [10/565] 1% | Training loss: 0.7553250312805175
Epoch: 45 | Iteration number: [20/565] 3% | Training loss: 0.7211485654115677
Epoch: 45 | Iteration number: [30/565] 5% | Training loss: 0.7096554338932037
Epoch: 45 | Iteration number: [40/565] 7% | Training loss: 0.7039740324020386
Epoch: 45 | Iteration number: [50/565] 8% | Training loss: 0.7005360209941864
Epoch: 45 | Iteration number: [60/565] 10% | Training loss: 0.6982305626074473
Epoch: 45 | Iteration number: [70/565] 12% | Training loss: 0.6965727320739201
Epoch: 45 | Iteration number: [80/565] 14% | Training loss: 0.6953576594591141
Epoch: 45 | Iteration number: [90/565] 15% | Training loss: 0.6944087107976278
Epoch: 45 | Iteration number: [100/565] 17% | Training loss: 0.6936471545696259
Epoch: 45 | Iteration number: [110/565] 19% | Training loss: 0.6930416329340501
Epoch: 45 | Iteration number: [120/565] 21% | Training loss: 0.6925101478894552
Epoch: 45 | Iteration number: [130/565] 23% | Training loss: 0.6921025698001568
Epoch: 45 | Iteration number: [140/565] 24% | Training loss: 0.6917324547256742
Epoch: 45 | Iteration number: [150/565] 26% | Training loss: 0.6913953320185343
Epoch: 45 | Iteration number: [160/565] 28% | Training loss: 0.6910988550633193
Epoch: 45 | Iteration number: [170/565] 30% | Training loss: 0.6908196943647721
Epoch: 45 | Iteration number: [180/565] 31% | Training loss: 0.6906017813417646
Epoch: 45 | Iteration number: [190/565] 33% | Training loss: 0.6903994475540361
Epoch: 45 | Iteration number: [200/565] 35% | Training loss: 0.6902086731791496
Epoch: 45 | Iteration number: [210/565] 37% | Training loss: 0.6900606325694493
Epoch: 45 | Iteration number: [220/565] 38% | Training loss: 0.6899210900068283
Epoch: 45 | Iteration number: [230/565] 40% | Training loss: 0.689796862654064
Epoch: 45 | Iteration number: [240/565] 42% | Training loss: 0.6896739915013314
Epoch: 45 | Iteration number: [250/565] 44% | Training loss: 0.689560408115387
Epoch: 45 | Iteration number: [260/565] 46% | Training loss: 0.6894597933842586
Epoch: 45 | Iteration number: [270/565] 47% | Training loss: 0.6893501215510898
Epoch: 45 | Iteration number: [280/565] 49% | Training loss: 0.689281208387443
Epoch: 45 | Iteration number: [290/565] 51% | Training loss: 0.6891820963086753
Epoch: 45 | Iteration number: [300/565] 53% | Training loss: 0.6890977191925048
Epoch: 45 | Iteration number: [310/565] 54% | Training loss: 0.689007923103148
Epoch: 45 | Iteration number: [320/565] 56% | Training loss: 0.6889538204297423
Epoch: 45 | Iteration number: [330/565] 58% | Training loss: 0.6888799931063797
Epoch: 45 | Iteration number: [340/565] 60% | Training loss: 0.6888208506738438
Epoch: 45 | Iteration number: [350/565] 61% | Training loss: 0.6887675213813782
Epoch: 45 | Iteration number: [360/565] 63% | Training loss: 0.6887259567777316
Epoch: 45 | Iteration number: [370/565] 65% | Training loss: 0.6886769510604239
Epoch: 45 | Iteration number: [380/565] 67% | Training loss: 0.6886065861112193
Epoch: 45 | Iteration number: [390/565] 69% | Training loss: 0.688566112671143
Epoch: 45 | Iteration number: [400/565] 70% | Training loss: 0.6885276629030704
Epoch: 45 | Iteration number: [410/565] 72% | Training loss: 0.6884904864357739
Epoch: 45 | Iteration number: [420/565] 74% | Training loss: 0.6884673744440079
Epoch: 45 | Iteration number: [430/565] 76% | Training loss: 0.6884443222090255
Epoch: 45 | Iteration number: [440/565] 77% | Training loss: 0.6884134800596671
Epoch: 45 | Iteration number: [450/565] 79% | Training loss: 0.6883793017599318
Epoch: 45 | Iteration number: [460/565] 81% | Training loss: 0.6883524675732073
Epoch: 45 | Iteration number: [470/565] 83% | Training loss: 0.6883225784656849
Epoch: 45 | Iteration number: [480/565] 84% | Training loss: 0.6882965009659529
Epoch: 45 | Iteration number: [490/565] 86% | Training loss: 0.6882723376459005
Epoch: 45 | Iteration number: [500/565] 88% | Training loss: 0.6882305215597153
Epoch: 45 | Iteration number: [510/565] 90% | Training loss: 0.6882051635022257
Epoch: 45 | Iteration number: [520/565] 92% | Training loss: 0.6881763476591843
Epoch: 45 | Iteration number: [530/565] 93% | Training loss: 0.6881515284754195
Epoch: 45 | Iteration number: [540/565] 95% | Training loss: 0.688124566939142
Epoch: 45 | Iteration number: [550/565] 97% | Training loss: 0.6881096690351313
Epoch: 45 | Iteration number: [560/565] 99% | Training loss: 0.6880857899785042

 End of epoch: 45 | Train Loss: 0.6868608520094273 | Training Time: 90 

 End of epoch: 45 | Eval Loss: 0.6897394827433995 | Evaluating Time: 6 
Epoch: 46 | Iteration number: [10/565] 1% | Training loss: 0.7556641578674317
Epoch: 46 | Iteration number: [20/565] 3% | Training loss: 0.7212760090827942
Epoch: 46 | Iteration number: [30/565] 5% | Training loss: 0.7097804725170136
Epoch: 46 | Iteration number: [40/565] 7% | Training loss: 0.7040826052427291
Epoch: 46 | Iteration number: [50/565] 8% | Training loss: 0.700700511932373
Epoch: 46 | Iteration number: [60/565] 10% | Training loss: 0.6983518709739049
Epoch: 46 | Iteration number: [70/565] 12% | Training loss: 0.6967079750129155
Epoch: 46 | Iteration number: [80/565] 14% | Training loss: 0.695523326843977
Epoch: 46 | Iteration number: [90/565] 15% | Training loss: 0.6945920745531718
Epoch: 46 | Iteration number: [100/565] 17% | Training loss: 0.6938019454479217
Epoch: 46 | Iteration number: [110/565] 19% | Training loss: 0.6931281366131522
Epoch: 46 | Iteration number: [120/565] 21% | Training loss: 0.6926288545131684
Epoch: 46 | Iteration number: [130/565] 23% | Training loss: 0.6921902262247526
Epoch: 46 | Iteration number: [140/565] 24% | Training loss: 0.6918299049139023
Epoch: 46 | Iteration number: [150/565] 26% | Training loss: 0.691504541238149
Epoch: 46 | Iteration number: [160/565] 28% | Training loss: 0.6912081122398377
Epoch: 46 | Iteration number: [170/565] 30% | Training loss: 0.6909535348415374
Epoch: 46 | Iteration number: [180/565] 31% | Training loss: 0.6907118065489664
Epoch: 46 | Iteration number: [190/565] 33% | Training loss: 0.6904725055945548
Epoch: 46 | Iteration number: [200/565] 35% | Training loss: 0.6902775478363037
Epoch: 46 | Iteration number: [210/565] 37% | Training loss: 0.6901102426506224
Epoch: 46 | Iteration number: [220/565] 38% | Training loss: 0.6899795364249837
Epoch: 46 | Iteration number: [230/565] 40% | Training loss: 0.6898481096910394
Epoch: 46 | Iteration number: [240/565] 42% | Training loss: 0.6897091858088971
Epoch: 46 | Iteration number: [250/565] 44% | Training loss: 0.6895873084068298
Epoch: 46 | Iteration number: [260/565] 46% | Training loss: 0.6894746104112038
Epoch: 46 | Iteration number: [270/565] 47% | Training loss: 0.6893619751488721
Epoch: 46 | Iteration number: [280/565] 49% | Training loss: 0.6892738255006926
Epoch: 46 | Iteration number: [290/565] 51% | Training loss: 0.6891909683572834
Epoch: 46 | Iteration number: [300/565] 53% | Training loss: 0.6891118027766545
Epoch: 46 | Iteration number: [310/565] 54% | Training loss: 0.6890473742638865
Epoch: 46 | Iteration number: [320/565] 56% | Training loss: 0.6889802565798163
Epoch: 46 | Iteration number: [330/565] 58% | Training loss: 0.688917167078365
Epoch: 46 | Iteration number: [340/565] 60% | Training loss: 0.6888591859270544
Epoch: 46 | Iteration number: [350/565] 61% | Training loss: 0.6888078715120043
Epoch: 46 | Iteration number: [360/565] 63% | Training loss: 0.6887468525105053
Epoch: 46 | Iteration number: [370/565] 65% | Training loss: 0.6886987853694606
Epoch: 46 | Iteration number: [380/565] 67% | Training loss: 0.6886496118809048
Epoch: 46 | Iteration number: [390/565] 69% | Training loss: 0.6886110056669285
Epoch: 46 | Iteration number: [400/565] 70% | Training loss: 0.6885560154914856
Epoch: 46 | Iteration number: [410/565] 72% | Training loss: 0.6885215647336913
Epoch: 46 | Iteration number: [420/565] 74% | Training loss: 0.6884819974501928
Epoch: 46 | Iteration number: [430/565] 76% | Training loss: 0.6884432652661967
Epoch: 46 | Iteration number: [440/565] 77% | Training loss: 0.6884135953404686
Epoch: 46 | Iteration number: [450/565] 79% | Training loss: 0.68837800277604
Epoch: 46 | Iteration number: [460/565] 81% | Training loss: 0.6883448679809985
Epoch: 46 | Iteration number: [470/565] 83% | Training loss: 0.6883136703612956
Epoch: 46 | Iteration number: [480/565] 84% | Training loss: 0.6882876465717952
Epoch: 46 | Iteration number: [490/565] 86% | Training loss: 0.6882478226204307
Epoch: 46 | Iteration number: [500/565] 88% | Training loss: 0.6882131321430206
Epoch: 46 | Iteration number: [510/565] 90% | Training loss: 0.6881860604473189
Epoch: 46 | Iteration number: [520/565] 92% | Training loss: 0.6881578752627739
Epoch: 46 | Iteration number: [530/565] 93% | Training loss: 0.6881355909806377
Epoch: 46 | Iteration number: [540/565] 95% | Training loss: 0.6881068033200723
Epoch: 46 | Iteration number: [550/565] 97% | Training loss: 0.6880820329622789
Epoch: 46 | Iteration number: [560/565] 99% | Training loss: 0.6880633389311177

 End of epoch: 46 | Train Loss: 0.6868361399237034 | Training Time: 90 

 End of epoch: 46 | Eval Loss: 0.6890869736671448 | Evaluating Time: 6 
Epoch: 47 | Iteration number: [10/565] 1% | Training loss: 0.7555439352989197
Epoch: 47 | Iteration number: [20/565] 3% | Training loss: 0.7210523128509522
Epoch: 47 | Iteration number: [30/565] 5% | Training loss: 0.7097114980220794
Epoch: 47 | Iteration number: [40/565] 7% | Training loss: 0.7039957895874978
Epoch: 47 | Iteration number: [50/565] 8% | Training loss: 0.7005170583724976
Epoch: 47 | Iteration number: [60/565] 10% | Training loss: 0.6982458800077438
Epoch: 47 | Iteration number: [70/565] 12% | Training loss: 0.6965957641601562
Epoch: 47 | Iteration number: [80/565] 14% | Training loss: 0.6953985393047333
Epoch: 47 | Iteration number: [90/565] 15% | Training loss: 0.6944624940554301
Epoch: 47 | Iteration number: [100/565] 17% | Training loss: 0.693720315694809
Epoch: 47 | Iteration number: [110/565] 19% | Training loss: 0.6930948149074208
Epoch: 47 | Iteration number: [120/565] 21% | Training loss: 0.6926035409172376
Epoch: 47 | Iteration number: [130/565] 23% | Training loss: 0.6921631858899043
Epoch: 47 | Iteration number: [140/565] 24% | Training loss: 0.6917973428964614
Epoch: 47 | Iteration number: [150/565] 26% | Training loss: 0.6914709063371023
Epoch: 47 | Iteration number: [160/565] 28% | Training loss: 0.6911554519087076
Epoch: 47 | Iteration number: [170/565] 30% | Training loss: 0.6909145502483144
Epoch: 47 | Iteration number: [180/565] 31% | Training loss: 0.6907071961296929
Epoch: 47 | Iteration number: [190/565] 33% | Training loss: 0.6905104910072527
Epoch: 47 | Iteration number: [200/565] 35% | Training loss: 0.6903198313713074
Epoch: 47 | Iteration number: [210/565] 37% | Training loss: 0.690159003791355
Epoch: 47 | Iteration number: [220/565] 38% | Training loss: 0.6900169608267871
Epoch: 47 | Iteration number: [230/565] 40% | Training loss: 0.6898972218451292
Epoch: 47 | Iteration number: [240/565] 42% | Training loss: 0.6897639331718286
Epoch: 47 | Iteration number: [250/565] 44% | Training loss: 0.6896452610492706
Epoch: 47 | Iteration number: [260/565] 46% | Training loss: 0.6895296924389326
Epoch: 47 | Iteration number: [270/565] 47% | Training loss: 0.6894393682479858
Epoch: 47 | Iteration number: [280/565] 49% | Training loss: 0.6893375439303262
Epoch: 47 | Iteration number: [290/565] 51% | Training loss: 0.689260770534647
Epoch: 47 | Iteration number: [300/565] 53% | Training loss: 0.6891701207558314
Epoch: 47 | Iteration number: [310/565] 54% | Training loss: 0.689105829692656
Epoch: 47 | Iteration number: [320/565] 56% | Training loss: 0.6890249699354172
Epoch: 47 | Iteration number: [330/565] 58% | Training loss: 0.6889652544801885
Epoch: 47 | Iteration number: [340/565] 60% | Training loss: 0.6889118217370089
Epoch: 47 | Iteration number: [350/565] 61% | Training loss: 0.6888612886837551
Epoch: 47 | Iteration number: [360/565] 63% | Training loss: 0.6888072681095865
Epoch: 47 | Iteration number: [370/565] 65% | Training loss: 0.6887448302797369
Epoch: 47 | Iteration number: [380/565] 67% | Training loss: 0.6887050936096593
Epoch: 47 | Iteration number: [390/565] 69% | Training loss: 0.688646305218721
Epoch: 47 | Iteration number: [400/565] 70% | Training loss: 0.6885821668803692
Epoch: 47 | Iteration number: [410/565] 72% | Training loss: 0.6885429990000841
Epoch: 47 | Iteration number: [420/565] 74% | Training loss: 0.6885009087267376
Epoch: 47 | Iteration number: [430/565] 76% | Training loss: 0.6884593269159628
Epoch: 47 | Iteration number: [440/565] 77% | Training loss: 0.6884185040538962
Epoch: 47 | Iteration number: [450/565] 79% | Training loss: 0.6883773880534702
Epoch: 47 | Iteration number: [460/565] 81% | Training loss: 0.6883431892032209
Epoch: 47 | Iteration number: [470/565] 83% | Training loss: 0.6883163822458146
Epoch: 47 | Iteration number: [480/565] 84% | Training loss: 0.6882814519107342
Epoch: 47 | Iteration number: [490/565] 86% | Training loss: 0.6882506413119179
Epoch: 47 | Iteration number: [500/565] 88% | Training loss: 0.6882226762771606
Epoch: 47 | Iteration number: [510/565] 90% | Training loss: 0.6881968654838263
Epoch: 47 | Iteration number: [520/565] 92% | Training loss: 0.6881655088984049
Epoch: 47 | Iteration number: [530/565] 93% | Training loss: 0.6881441978913433
Epoch: 47 | Iteration number: [540/565] 95% | Training loss: 0.6881124333099082
Epoch: 47 | Iteration number: [550/565] 97% | Training loss: 0.6880893763628873
Epoch: 47 | Iteration number: [560/565] 99% | Training loss: 0.6880708566733769

 End of epoch: 47 | Train Loss: 0.6868461919041862 | Training Time: 89 

 End of epoch: 47 | Eval Loss: 0.6890790036746434 | Evaluating Time: 6 
Epoch: 48 | Iteration number: [10/565] 1% | Training loss: 0.7560993611812592
Epoch: 48 | Iteration number: [20/565] 3% | Training loss: 0.7215575218200684
Epoch: 48 | Iteration number: [30/565] 5% | Training loss: 0.7101505696773529
Epoch: 48 | Iteration number: [40/565] 7% | Training loss: 0.7043598726391792
Epoch: 48 | Iteration number: [50/565] 8% | Training loss: 0.7008951556682587
Epoch: 48 | Iteration number: [60/565] 10% | Training loss: 0.6985885183016459
Epoch: 48 | Iteration number: [70/565] 12% | Training loss: 0.6968764160360609
Epoch: 48 | Iteration number: [80/565] 14% | Training loss: 0.6955926537513732
Epoch: 48 | Iteration number: [90/565] 15% | Training loss: 0.6946078949504428
Epoch: 48 | Iteration number: [100/565] 17% | Training loss: 0.6938517588376999
Epoch: 48 | Iteration number: [110/565] 19% | Training loss: 0.6931758539243178
Epoch: 48 | Iteration number: [120/565] 21% | Training loss: 0.6926657542586326
Epoch: 48 | Iteration number: [130/565] 23% | Training loss: 0.6922044529364659
Epoch: 48 | Iteration number: [140/565] 24% | Training loss: 0.6918428186859403
Epoch: 48 | Iteration number: [150/565] 26% | Training loss: 0.6915158013502757
Epoch: 48 | Iteration number: [160/565] 28% | Training loss: 0.6912184212356806
Epoch: 48 | Iteration number: [170/565] 30% | Training loss: 0.6909766025402967
Epoch: 48 | Iteration number: [180/565] 31% | Training loss: 0.6907649719052844
Epoch: 48 | Iteration number: [190/565] 33% | Training loss: 0.6905342600847545
Epoch: 48 | Iteration number: [200/565] 35% | Training loss: 0.6903280124068261
Epoch: 48 | Iteration number: [210/565] 37% | Training loss: 0.6901579692250206
Epoch: 48 | Iteration number: [220/565] 38% | Training loss: 0.6899925288828936
Epoch: 48 | Iteration number: [230/565] 40% | Training loss: 0.6898605649885924
Epoch: 48 | Iteration number: [240/565] 42% | Training loss: 0.6897374364236991
Epoch: 48 | Iteration number: [250/565] 44% | Training loss: 0.6896145887374878
Epoch: 48 | Iteration number: [260/565] 46% | Training loss: 0.6895046733892881
Epoch: 48 | Iteration number: [270/565] 47% | Training loss: 0.6894160392107787
Epoch: 48 | Iteration number: [280/565] 49% | Training loss: 0.6893119548048292
Epoch: 48 | Iteration number: [290/565] 51% | Training loss: 0.6892182146680766
Epoch: 48 | Iteration number: [300/565] 53% | Training loss: 0.6891567748785019
Epoch: 48 | Iteration number: [310/565] 54% | Training loss: 0.689078015089035
Epoch: 48 | Iteration number: [320/565] 56% | Training loss: 0.6890111830085516
Epoch: 48 | Iteration number: [330/565] 58% | Training loss: 0.6889382181745587
Epoch: 48 | Iteration number: [340/565] 60% | Training loss: 0.6888730494415058
Epoch: 48 | Iteration number: [350/565] 61% | Training loss: 0.6888178774288722
Epoch: 48 | Iteration number: [360/565] 63% | Training loss: 0.6887788666619195
Epoch: 48 | Iteration number: [370/565] 65% | Training loss: 0.6887301101877883
Epoch: 48 | Iteration number: [380/565] 67% | Training loss: 0.6886867978070912
Epoch: 48 | Iteration number: [390/565] 69% | Training loss: 0.688646882161116
Epoch: 48 | Iteration number: [400/565] 70% | Training loss: 0.68859015583992
Epoch: 48 | Iteration number: [410/565] 72% | Training loss: 0.6885483151528894
Epoch: 48 | Iteration number: [420/565] 74% | Training loss: 0.6885155287526903
Epoch: 48 | Iteration number: [430/565] 76% | Training loss: 0.6884705111037853
Epoch: 48 | Iteration number: [440/565] 77% | Training loss: 0.6884344373237002
Epoch: 48 | Iteration number: [450/565] 79% | Training loss: 0.6883915954165989
Epoch: 48 | Iteration number: [460/565] 81% | Training loss: 0.688353087461513
Epoch: 48 | Iteration number: [470/565] 83% | Training loss: 0.6883154583738206
Epoch: 48 | Iteration number: [480/565] 84% | Training loss: 0.6882779565950234
Epoch: 48 | Iteration number: [490/565] 86% | Training loss: 0.6882441425810055
Epoch: 48 | Iteration number: [500/565] 88% | Training loss: 0.6882231653928756
Epoch: 48 | Iteration number: [510/565] 90% | Training loss: 0.6881863686383939
Epoch: 48 | Iteration number: [520/565] 92% | Training loss: 0.6881591883989481
Epoch: 48 | Iteration number: [530/565] 93% | Training loss: 0.6881286251095106
Epoch: 48 | Iteration number: [540/565] 95% | Training loss: 0.6881041883318513
Epoch: 48 | Iteration number: [550/565] 97% | Training loss: 0.6880834062532946
Epoch: 48 | Iteration number: [560/565] 99% | Training loss: 0.6880555671240602

 End of epoch: 48 | Train Loss: 0.686830508603459 | Training Time: 89 

 End of epoch: 48 | Eval Loss: 0.6896687660898481 | Evaluating Time: 6 
Epoch: 49 | Iteration number: [10/565] 1% | Training loss: 0.755418860912323
Epoch: 49 | Iteration number: [20/565] 3% | Training loss: 0.7212487578392028
Epoch: 49 | Iteration number: [30/565] 5% | Training loss: 0.7096950451533
Epoch: 49 | Iteration number: [40/565] 7% | Training loss: 0.7039004176855087
Epoch: 49 | Iteration number: [50/565] 8% | Training loss: 0.700420206785202
Epoch: 49 | Iteration number: [60/565] 10% | Training loss: 0.6982208182414372
Epoch: 49 | Iteration number: [70/565] 12% | Training loss: 0.6966084028993335
Epoch: 49 | Iteration number: [80/565] 14% | Training loss: 0.6954359106719494
Epoch: 49 | Iteration number: [90/565] 15% | Training loss: 0.6944521420531803
Epoch: 49 | Iteration number: [100/565] 17% | Training loss: 0.6936661720275878
Epoch: 49 | Iteration number: [110/565] 19% | Training loss: 0.6931111005219546
Epoch: 49 | Iteration number: [120/565] 21% | Training loss: 0.6925445690751075
Epoch: 49 | Iteration number: [130/565] 23% | Training loss: 0.6921044514729426
Epoch: 49 | Iteration number: [140/565] 24% | Training loss: 0.6917448350361415
Epoch: 49 | Iteration number: [150/565] 26% | Training loss: 0.6914074297746022
Epoch: 49 | Iteration number: [160/565] 28% | Training loss: 0.6911011081188917
Epoch: 49 | Iteration number: [170/565] 30% | Training loss: 0.690843784458497
Epoch: 49 | Iteration number: [180/565] 31% | Training loss: 0.690638851457172
Epoch: 49 | Iteration number: [190/565] 33% | Training loss: 0.6904602314296522
Epoch: 49 | Iteration number: [200/565] 35% | Training loss: 0.6902735903859138
Epoch: 49 | Iteration number: [210/565] 37% | Training loss: 0.6900903446333749
Epoch: 49 | Iteration number: [220/565] 38% | Training loss: 0.6899304755709388
Epoch: 49 | Iteration number: [230/565] 40% | Training loss: 0.6897935590018397
Epoch: 49 | Iteration number: [240/565] 42% | Training loss: 0.6896843614677588
Epoch: 49 | Iteration number: [250/565] 44% | Training loss: 0.6895710213184356
Epoch: 49 | Iteration number: [260/565] 46% | Training loss: 0.6894555903398074
Epoch: 49 | Iteration number: [270/565] 47% | Training loss: 0.6893469788410046
Epoch: 49 | Iteration number: [280/565] 49% | Training loss: 0.689269308745861
Epoch: 49 | Iteration number: [290/565] 51% | Training loss: 0.6891755848095334
Epoch: 49 | Iteration number: [300/565] 53% | Training loss: 0.6891097897291183
Epoch: 49 | Iteration number: [310/565] 54% | Training loss: 0.6890276855038059
Epoch: 49 | Iteration number: [320/565] 56% | Training loss: 0.6889628536999226
Epoch: 49 | Iteration number: [330/565] 58% | Training loss: 0.6889102218729077
Epoch: 49 | Iteration number: [340/565] 60% | Training loss: 0.688861282082165
Epoch: 49 | Iteration number: [350/565] 61% | Training loss: 0.6888106456824712
Epoch: 49 | Iteration number: [360/565] 63% | Training loss: 0.6887518422471153
Epoch: 49 | Iteration number: [370/565] 65% | Training loss: 0.6886987077223288
Epoch: 49 | Iteration number: [380/565] 67% | Training loss: 0.6886415610187933
Epoch: 49 | Iteration number: [390/565] 69% | Training loss: 0.688594592993076
Epoch: 49 | Iteration number: [400/565] 70% | Training loss: 0.6885521690547466
Epoch: 49 | Iteration number: [410/565] 72% | Training loss: 0.6885173345484384
Epoch: 49 | Iteration number: [420/565] 74% | Training loss: 0.6884769381511779
Epoch: 49 | Iteration number: [430/565] 76% | Training loss: 0.6884375649829243
Epoch: 49 | Iteration number: [440/565] 77% | Training loss: 0.6883889339186928
Epoch: 49 | Iteration number: [450/565] 79% | Training loss: 0.6883589757813348
Epoch: 49 | Iteration number: [460/565] 81% | Training loss: 0.6883279320986374
Epoch: 49 | Iteration number: [470/565] 83% | Training loss: 0.6882882988199275
Epoch: 49 | Iteration number: [480/565] 84% | Training loss: 0.6882643733173609
Epoch: 49 | Iteration number: [490/565] 86% | Training loss: 0.6882406554660019
Epoch: 49 | Iteration number: [500/565] 88% | Training loss: 0.6882140952348709
Epoch: 49 | Iteration number: [510/565] 90% | Training loss: 0.688180059077693
Epoch: 49 | Iteration number: [520/565] 92% | Training loss: 0.6881509874875729
Epoch: 49 | Iteration number: [530/565] 93% | Training loss: 0.6881202694380059
Epoch: 49 | Iteration number: [540/565] 95% | Training loss: 0.6880970762835609
Epoch: 49 | Iteration number: [550/565] 97% | Training loss: 0.6880767655372619
Epoch: 49 | Iteration number: [560/565] 99% | Training loss: 0.6880507771457944

 End of epoch: 49 | Train Loss: 0.686825787177128 | Training Time: 89 

 End of epoch: 49 | Eval Loss: 0.6888988103185382 | Evaluating Time: 6 
Epoch: 50 | Iteration number: [10/565] 1% | Training loss: 0.7556041538715362
Epoch: 50 | Iteration number: [20/565] 3% | Training loss: 0.7216194778680801
Epoch: 50 | Iteration number: [30/565] 5% | Training loss: 0.709936253229777
Epoch: 50 | Iteration number: [40/565] 7% | Training loss: 0.7041657239198684
Epoch: 50 | Iteration number: [50/565] 8% | Training loss: 0.7007000935077667
Epoch: 50 | Iteration number: [60/565] 10% | Training loss: 0.6984060515960058
Epoch: 50 | Iteration number: [70/565] 12% | Training loss: 0.696761384180614
Epoch: 50 | Iteration number: [80/565] 14% | Training loss: 0.6954601868987084
Epoch: 50 | Iteration number: [90/565] 15% | Training loss: 0.694459515147739
Epoch: 50 | Iteration number: [100/565] 17% | Training loss: 0.6937152171134948
Epoch: 50 | Iteration number: [110/565] 19% | Training loss: 0.6930465524846857
Epoch: 50 | Iteration number: [120/565] 21% | Training loss: 0.6925496419270833
Epoch: 50 | Iteration number: [130/565] 23% | Training loss: 0.6921224511586703
Epoch: 50 | Iteration number: [140/565] 24% | Training loss: 0.6917511680296489
Epoch: 50 | Iteration number: [150/565] 26% | Training loss: 0.6914035165309906
Epoch: 50 | Iteration number: [160/565] 28% | Training loss: 0.6911204446107149
Epoch: 50 | Iteration number: [170/565] 30% | Training loss: 0.690833626424565
Epoch: 50 | Iteration number: [180/565] 31% | Training loss: 0.690606595410241
Epoch: 50 | Iteration number: [190/565] 33% | Training loss: 0.6904188372586902
Epoch: 50 | Iteration number: [200/565] 35% | Training loss: 0.6902479675412178
Epoch: 50 | Iteration number: [210/565] 37% | Training loss: 0.6900556578522636
Epoch: 50 | Iteration number: [220/565] 38% | Training loss: 0.6899026285518299
Epoch: 50 | Iteration number: [230/565] 40% | Training loss: 0.6897621916688007
Epoch: 50 | Iteration number: [240/565] 42% | Training loss: 0.6896445746223132
Epoch: 50 | Iteration number: [250/565] 44% | Training loss: 0.6895313246250152
Epoch: 50 | Iteration number: [260/565] 46% | Training loss: 0.6894231509703856
Epoch: 50 | Iteration number: [270/565] 47% | Training loss: 0.6893380688296424
Epoch: 50 | Iteration number: [280/565] 49% | Training loss: 0.689218000641891
Epoch: 50 | Iteration number: [290/565] 51% | Training loss: 0.6891194557321483
Epoch: 50 | Iteration number: [300/565] 53% | Training loss: 0.6890449563662211
Epoch: 50 | Iteration number: [310/565] 54% | Training loss: 0.6889755102895921
Epoch: 50 | Iteration number: [320/565] 56% | Training loss: 0.6889101315289736
Epoch: 50 | Iteration number: [330/565] 58% | Training loss: 0.6888424848065232
Epoch: 50 | Iteration number: [340/565] 60% | Training loss: 0.6887888245722826
Epoch: 50 | Iteration number: [350/565] 61% | Training loss: 0.6887541629586901
Epoch: 50 | Iteration number: [360/565] 63% | Training loss: 0.6886992568771044
Epoch: 50 | Iteration number: [370/565] 65% | Training loss: 0.6886456496006733
Epoch: 50 | Iteration number: [380/565] 67% | Training loss: 0.6886019414977024
Epoch: 50 | Iteration number: [390/565] 69% | Training loss: 0.6885525616315695
Epoch: 50 | Iteration number: [400/565] 70% | Training loss: 0.6885027781128883
Epoch: 50 | Iteration number: [410/565] 72% | Training loss: 0.6884701102245144
Epoch: 50 | Iteration number: [420/565] 74% | Training loss: 0.6884452479226248
Epoch: 50 | Iteration number: [430/565] 76% | Training loss: 0.6884019711682963
Epoch: 50 | Iteration number: [440/565] 77% | Training loss: 0.6883629992604255
Epoch: 50 | Iteration number: [450/565] 79% | Training loss: 0.6883291288216908
Epoch: 50 | Iteration number: [460/565] 81% | Training loss: 0.6882885866838953
Epoch: 50 | Iteration number: [470/565] 83% | Training loss: 0.688257798489104
Epoch: 50 | Iteration number: [480/565] 84% | Training loss: 0.6882244646549225
Epoch: 50 | Iteration number: [490/565] 86% | Training loss: 0.6882015959340699
Epoch: 50 | Iteration number: [500/565] 88% | Training loss: 0.6881805320978165
Epoch: 50 | Iteration number: [510/565] 90% | Training loss: 0.6881525701167537
Epoch: 50 | Iteration number: [520/565] 92% | Training loss: 0.6881206741699806
Epoch: 50 | Iteration number: [530/565] 93% | Training loss: 0.6881080809629189
Epoch: 50 | Iteration number: [540/565] 95% | Training loss: 0.6880907079687825
Epoch: 50 | Iteration number: [550/565] 97% | Training loss: 0.6880729387023232
Epoch: 50 | Iteration number: [560/565] 99% | Training loss: 0.6880485948707377

 End of epoch: 50 | Train Loss: 0.6868236154581593 | Training Time: 89 

 End of epoch: 50 | Eval Loss: 0.6896698134286063 | Evaluating Time: 6 
Epoch: 51 | Iteration number: [10/565] 1% | Training loss: 0.7557486832141876
Epoch: 51 | Iteration number: [20/565] 3% | Training loss: 0.7211261242628098
Epoch: 51 | Iteration number: [30/565] 5% | Training loss: 0.7094747642676036
Epoch: 51 | Iteration number: [40/565] 7% | Training loss: 0.7038479268550872
Epoch: 51 | Iteration number: [50/565] 8% | Training loss: 0.700466160774231
Epoch: 51 | Iteration number: [60/565] 10% | Training loss: 0.6981574575106303
Epoch: 51 | Iteration number: [70/565] 12% | Training loss: 0.6965012746197837
Epoch: 51 | Iteration number: [80/565] 14% | Training loss: 0.6953242167830467
Epoch: 51 | Iteration number: [90/565] 15% | Training loss: 0.694433374537362
Epoch: 51 | Iteration number: [100/565] 17% | Training loss: 0.6936865550279617
Epoch: 51 | Iteration number: [110/565] 19% | Training loss: 0.6930579456416044
Epoch: 51 | Iteration number: [120/565] 21% | Training loss: 0.6925221294164657
Epoch: 51 | Iteration number: [130/565] 23% | Training loss: 0.6920728385448456
Epoch: 51 | Iteration number: [140/565] 24% | Training loss: 0.6916867094380516
Epoch: 51 | Iteration number: [150/565] 26% | Training loss: 0.6913448317845663
Epoch: 51 | Iteration number: [160/565] 28% | Training loss: 0.6910760037600994
Epoch: 51 | Iteration number: [170/565] 30% | Training loss: 0.6908642435775084
Epoch: 51 | Iteration number: [180/565] 31% | Training loss: 0.6906514939334657
Epoch: 51 | Iteration number: [190/565] 33% | Training loss: 0.6904438439168428
Epoch: 51 | Iteration number: [200/565] 35% | Training loss: 0.6902631053328514
Epoch: 51 | Iteration number: [210/565] 37% | Training loss: 0.6900951155594417
Epoch: 51 | Iteration number: [220/565] 38% | Training loss: 0.6899358838796615
Epoch: 51 | Iteration number: [230/565] 40% | Training loss: 0.6897880735604659
Epoch: 51 | Iteration number: [240/565] 42% | Training loss: 0.6896517336368561
Epoch: 51 | Iteration number: [250/565] 44% | Training loss: 0.6895344183444977
Epoch: 51 | Iteration number: [260/565] 46% | Training loss: 0.6894212502699631
Epoch: 51 | Iteration number: [270/565] 47% | Training loss: 0.6893314509480087
Epoch: 51 | Iteration number: [280/565] 49% | Training loss: 0.689246936568192
Epoch: 51 | Iteration number: [290/565] 51% | Training loss: 0.6891600333411118
Epoch: 51 | Iteration number: [300/565] 53% | Training loss: 0.6890954391161601
Epoch: 51 | Iteration number: [310/565] 54% | Training loss: 0.6890198984453755
Epoch: 51 | Iteration number: [320/565] 56% | Training loss: 0.6889617705717683
Epoch: 51 | Iteration number: [330/565] 58% | Training loss: 0.6889040049278374
Epoch: 51 | Iteration number: [340/565] 60% | Training loss: 0.6888360803618151
Epoch: 51 | Iteration number: [350/565] 61% | Training loss: 0.6887831447805677
Epoch: 51 | Iteration number: [360/565] 63% | Training loss: 0.6887266707089212
Epoch: 51 | Iteration number: [370/565] 65% | Training loss: 0.6886746614365964
Epoch: 51 | Iteration number: [380/565] 67% | Training loss: 0.6886240350572687
Epoch: 51 | Iteration number: [390/565] 69% | Training loss: 0.6885660885236202
Epoch: 51 | Iteration number: [400/565] 70% | Training loss: 0.6885102300345898
Epoch: 51 | Iteration number: [410/565] 72% | Training loss: 0.6884765549403865
Epoch: 51 | Iteration number: [420/565] 74% | Training loss: 0.6884392501342864
Epoch: 51 | Iteration number: [430/565] 76% | Training loss: 0.6884060240069101
Epoch: 51 | Iteration number: [440/565] 77% | Training loss: 0.6883741251446984
Epoch: 51 | Iteration number: [450/565] 79% | Training loss: 0.6883475981818306
Epoch: 51 | Iteration number: [460/565] 81% | Training loss: 0.6883086952178374
Epoch: 51 | Iteration number: [470/565] 83% | Training loss: 0.6882724824103903
Epoch: 51 | Iteration number: [480/565] 84% | Training loss: 0.688247752437989
Epoch: 51 | Iteration number: [490/565] 86% | Training loss: 0.6882171337701837
Epoch: 51 | Iteration number: [500/565] 88% | Training loss: 0.6881973470449447
Epoch: 51 | Iteration number: [510/565] 90% | Training loss: 0.6881702620609134
Epoch: 51 | Iteration number: [520/565] 92% | Training loss: 0.6881400526716159
Epoch: 51 | Iteration number: [530/565] 93% | Training loss: 0.6881135354626854
Epoch: 51 | Iteration number: [540/565] 95% | Training loss: 0.6880987983059
Epoch: 51 | Iteration number: [550/565] 97% | Training loss: 0.6880713495341214
Epoch: 51 | Iteration number: [560/565] 99% | Training loss: 0.6880498455039092

 End of epoch: 51 | Train Loss: 0.6868189437199483 | Training Time: 90 

 End of epoch: 51 | Eval Loss: 0.6896165779658726 | Evaluating Time: 6 
Epoch: 52 | Iteration number: [10/565] 1% | Training loss: 0.7558139979839325
Epoch: 52 | Iteration number: [20/565] 3% | Training loss: 0.7211688339710236
Epoch: 52 | Iteration number: [30/565] 5% | Training loss: 0.7096816162268321
Epoch: 52 | Iteration number: [40/565] 7% | Training loss: 0.7039156302809715
Epoch: 52 | Iteration number: [50/565] 8% | Training loss: 0.7005278205871582
Epoch: 52 | Iteration number: [60/565] 10% | Training loss: 0.6982179194688797
Epoch: 52 | Iteration number: [70/565] 12% | Training loss: 0.6966364962714059
Epoch: 52 | Iteration number: [80/565] 14% | Training loss: 0.6953820079565048
Epoch: 52 | Iteration number: [90/565] 15% | Training loss: 0.6944191310140821
Epoch: 52 | Iteration number: [100/565] 17% | Training loss: 0.6936556124687194
Epoch: 52 | Iteration number: [110/565] 19% | Training loss: 0.6930157569321719
Epoch: 52 | Iteration number: [120/565] 21% | Training loss: 0.6925235892335574
Epoch: 52 | Iteration number: [130/565] 23% | Training loss: 0.6920513533628904
Epoch: 52 | Iteration number: [140/565] 24% | Training loss: 0.6916364009891237
Epoch: 52 | Iteration number: [150/565] 26% | Training loss: 0.6913329954942068
Epoch: 52 | Iteration number: [160/565] 28% | Training loss: 0.6910600800067186
Epoch: 52 | Iteration number: [170/565] 30% | Training loss: 0.690800651031382
Epoch: 52 | Iteration number: [180/565] 31% | Training loss: 0.6905865103006363
Epoch: 52 | Iteration number: [190/565] 33% | Training loss: 0.6903913965350703
Epoch: 52 | Iteration number: [200/565] 35% | Training loss: 0.6902071914076805
Epoch: 52 | Iteration number: [210/565] 37% | Training loss: 0.6900479089646112
Epoch: 52 | Iteration number: [220/565] 38% | Training loss: 0.6899025394157929
Epoch: 52 | Iteration number: [230/565] 40% | Training loss: 0.6897338760935742
Epoch: 52 | Iteration number: [240/565] 42% | Training loss: 0.6896060312787692
Epoch: 52 | Iteration number: [250/565] 44% | Training loss: 0.6894938516616821
Epoch: 52 | Iteration number: [260/565] 46% | Training loss: 0.6894217096842252
Epoch: 52 | Iteration number: [270/565] 47% | Training loss: 0.689302424369035
Epoch: 52 | Iteration number: [280/565] 49% | Training loss: 0.6892092568533761
Epoch: 52 | Iteration number: [290/565] 51% | Training loss: 0.6891259139981764
Epoch: 52 | Iteration number: [300/565] 53% | Training loss: 0.6890482417742412
Epoch: 52 | Iteration number: [310/565] 54% | Training loss: 0.6889658051152383
Epoch: 52 | Iteration number: [320/565] 56% | Training loss: 0.6889072742313147
Epoch: 52 | Iteration number: [330/565] 58% | Training loss: 0.6888670952031106
Epoch: 52 | Iteration number: [340/565] 60% | Training loss: 0.6888096095884547
Epoch: 52 | Iteration number: [350/565] 61% | Training loss: 0.6887543630599976
Epoch: 52 | Iteration number: [360/565] 63% | Training loss: 0.6887090282307731
Epoch: 52 | Iteration number: [370/565] 65% | Training loss: 0.6886623337462142
Epoch: 52 | Iteration number: [380/565] 67% | Training loss: 0.688614979543184
Epoch: 52 | Iteration number: [390/565] 69% | Training loss: 0.6885701867250296
Epoch: 52 | Iteration number: [400/565] 70% | Training loss: 0.6885189637541771
Epoch: 52 | Iteration number: [410/565] 72% | Training loss: 0.6884816543358129
Epoch: 52 | Iteration number: [420/565] 74% | Training loss: 0.6884430057945705
Epoch: 52 | Iteration number: [430/565] 76% | Training loss: 0.6884016146493512
Epoch: 52 | Iteration number: [440/565] 77% | Training loss: 0.6883687855167823
Epoch: 52 | Iteration number: [450/565] 79% | Training loss: 0.6883418207698399
Epoch: 52 | Iteration number: [460/565] 81% | Training loss: 0.6883112481106882
Epoch: 52 | Iteration number: [470/565] 83% | Training loss: 0.6882925870570731
Epoch: 52 | Iteration number: [480/565] 84% | Training loss: 0.6882699284702539
Epoch: 52 | Iteration number: [490/565] 86% | Training loss: 0.6882399630789854
Epoch: 52 | Iteration number: [500/565] 88% | Training loss: 0.6882150284051896
Epoch: 52 | Iteration number: [510/565] 90% | Training loss: 0.6881898394986695
Epoch: 52 | Iteration number: [520/565] 92% | Training loss: 0.6881655177244773
Epoch: 52 | Iteration number: [530/565] 93% | Training loss: 0.6881399176030789
Epoch: 52 | Iteration number: [540/565] 95% | Training loss: 0.6881090813212924
Epoch: 52 | Iteration number: [550/565] 97% | Training loss: 0.6880790902267803
Epoch: 52 | Iteration number: [560/565] 99% | Training loss: 0.6880680539778301

 End of epoch: 52 | Train Loss: 0.6868446768912594 | Training Time: 90 

 End of epoch: 52 | Eval Loss: 0.6898177521569389 | Evaluating Time: 5 
Epoch: 53 | Iteration number: [10/565] 1% | Training loss: 0.7558290958404541
Epoch: 53 | Iteration number: [20/565] 3% | Training loss: 0.721010822057724
Epoch: 53 | Iteration number: [30/565] 5% | Training loss: 0.7095497210820516
Epoch: 53 | Iteration number: [40/565] 7% | Training loss: 0.7038893893361091
Epoch: 53 | Iteration number: [50/565] 8% | Training loss: 0.7006296229362488
Epoch: 53 | Iteration number: [60/565] 10% | Training loss: 0.6983389665683111
Epoch: 53 | Iteration number: [70/565] 12% | Training loss: 0.6967423507145473
Epoch: 53 | Iteration number: [80/565] 14% | Training loss: 0.695567361265421
Epoch: 53 | Iteration number: [90/565] 15% | Training loss: 0.6946150051222907
Epoch: 53 | Iteration number: [100/565] 17% | Training loss: 0.6938407158851624
Epoch: 53 | Iteration number: [110/565] 19% | Training loss: 0.6932269957932559
Epoch: 53 | Iteration number: [120/565] 21% | Training loss: 0.6926952759424846
Epoch: 53 | Iteration number: [130/565] 23% | Training loss: 0.6922079283457536
Epoch: 53 | Iteration number: [140/565] 24% | Training loss: 0.6918313452175685
Epoch: 53 | Iteration number: [150/565] 26% | Training loss: 0.6914928487936656
Epoch: 53 | Iteration number: [160/565] 28% | Training loss: 0.6912060111761094
Epoch: 53 | Iteration number: [170/565] 30% | Training loss: 0.6909440356142381
Epoch: 53 | Iteration number: [180/565] 31% | Training loss: 0.6906972318887711
Epoch: 53 | Iteration number: [190/565] 33% | Training loss: 0.6905010151235681
Epoch: 53 | Iteration number: [200/565] 35% | Training loss: 0.6903083848953248
Epoch: 53 | Iteration number: [210/565] 37% | Training loss: 0.6901166779654366
Epoch: 53 | Iteration number: [220/565] 38% | Training loss: 0.6899599140340632
Epoch: 53 | Iteration number: [230/565] 40% | Training loss: 0.6898284225360207
Epoch: 53 | Iteration number: [240/565] 42% | Training loss: 0.6896938388546308
Epoch: 53 | Iteration number: [250/565] 44% | Training loss: 0.6895914204120636
Epoch: 53 | Iteration number: [260/565] 46% | Training loss: 0.6894883451553492
Epoch: 53 | Iteration number: [270/565] 47% | Training loss: 0.6893931024604374
Epoch: 53 | Iteration number: [280/565] 49% | Training loss: 0.6892973793404443
Epoch: 53 | Iteration number: [290/565] 51% | Training loss: 0.6892124488435942
Epoch: 53 | Iteration number: [300/565] 53% | Training loss: 0.6891391352812449
Epoch: 53 | Iteration number: [310/565] 54% | Training loss: 0.6890629228084318
Epoch: 53 | Iteration number: [320/565] 56% | Training loss: 0.6889931043609977
Epoch: 53 | Iteration number: [330/565] 58% | Training loss: 0.6889499622764009
Epoch: 53 | Iteration number: [340/565] 60% | Training loss: 0.6888857094680562
Epoch: 53 | Iteration number: [350/565] 61% | Training loss: 0.6888270843029022
Epoch: 53 | Iteration number: [360/565] 63% | Training loss: 0.6887757551338938
Epoch: 53 | Iteration number: [370/565] 65% | Training loss: 0.6887288190223075
Epoch: 53 | Iteration number: [380/565] 67% | Training loss: 0.6886769653935182
Epoch: 53 | Iteration number: [390/565] 69% | Training loss: 0.6886227861428872
Epoch: 53 | Iteration number: [400/565] 70% | Training loss: 0.6885668808221816
Epoch: 53 | Iteration number: [410/565] 72% | Training loss: 0.688524222810094
Epoch: 53 | Iteration number: [420/565] 74% | Training loss: 0.6884905544065294
Epoch: 53 | Iteration number: [430/565] 76% | Training loss: 0.688452209012453
Epoch: 53 | Iteration number: [440/565] 77% | Training loss: 0.6884106623855504
Epoch: 53 | Iteration number: [450/565] 79% | Training loss: 0.6883697348170811
Epoch: 53 | Iteration number: [460/565] 81% | Training loss: 0.6883327362330064
Epoch: 53 | Iteration number: [470/565] 83% | Training loss: 0.6883108376188481
Epoch: 53 | Iteration number: [480/565] 84% | Training loss: 0.6882845845073462
Epoch: 53 | Iteration number: [490/565] 86% | Training loss: 0.6882473251041101
Epoch: 53 | Iteration number: [500/565] 88% | Training loss: 0.6882183225154876
Epoch: 53 | Iteration number: [510/565] 90% | Training loss: 0.6881773984899708
Epoch: 53 | Iteration number: [520/565] 92% | Training loss: 0.6881564512848855
Epoch: 53 | Iteration number: [530/565] 93% | Training loss: 0.6881376035933224
Epoch: 53 | Iteration number: [540/565] 95% | Training loss: 0.6881114011561429
Epoch: 53 | Iteration number: [550/565] 97% | Training loss: 0.6880910320715471
Epoch: 53 | Iteration number: [560/565] 99% | Training loss: 0.6880741347159658

 End of epoch: 53 | Train Loss: 0.6868448723733953 | Training Time: 90 

 End of epoch: 53 | Eval Loss: 0.688980051449367 | Evaluating Time: 6 
Epoch: 54 | Iteration number: [10/565] 1% | Training loss: 0.7557632803916932
Epoch: 54 | Iteration number: [20/565] 3% | Training loss: 0.7212500751018525
Epoch: 54 | Iteration number: [30/565] 5% | Training loss: 0.7098006784915925
Epoch: 54 | Iteration number: [40/565] 7% | Training loss: 0.7040289744734765
Epoch: 54 | Iteration number: [50/565] 8% | Training loss: 0.7005433106422424
Epoch: 54 | Iteration number: [60/565] 10% | Training loss: 0.6982555816570918
Epoch: 54 | Iteration number: [70/565] 12% | Training loss: 0.6966363114970071
Epoch: 54 | Iteration number: [80/565] 14% | Training loss: 0.6954493582248688
Epoch: 54 | Iteration number: [90/565] 15% | Training loss: 0.6944648835394117
Epoch: 54 | Iteration number: [100/565] 17% | Training loss: 0.693745955824852
Epoch: 54 | Iteration number: [110/565] 19% | Training loss: 0.6930858644572171
Epoch: 54 | Iteration number: [120/565] 21% | Training loss: 0.692574480175972
Epoch: 54 | Iteration number: [130/565] 23% | Training loss: 0.6921486927912786
Epoch: 54 | Iteration number: [140/565] 24% | Training loss: 0.6917407218899045
Epoch: 54 | Iteration number: [150/565] 26% | Training loss: 0.6914032157262167
Epoch: 54 | Iteration number: [160/565] 28% | Training loss: 0.6911065500229597
Epoch: 54 | Iteration number: [170/565] 30% | Training loss: 0.6908471948960249
Epoch: 54 | Iteration number: [180/565] 31% | Training loss: 0.6905938492880928
Epoch: 54 | Iteration number: [190/565] 33% | Training loss: 0.6903897169389223
Epoch: 54 | Iteration number: [200/565] 35% | Training loss: 0.6902281653881073
Epoch: 54 | Iteration number: [210/565] 37% | Training loss: 0.6900404220535642
Epoch: 54 | Iteration number: [220/565] 38% | Training loss: 0.6898965724489906
Epoch: 54 | Iteration number: [230/565] 40% | Training loss: 0.6897672979728036
Epoch: 54 | Iteration number: [240/565] 42% | Training loss: 0.6896565395096937
Epoch: 54 | Iteration number: [250/565] 44% | Training loss: 0.6895502920150757
Epoch: 54 | Iteration number: [260/565] 46% | Training loss: 0.6894433131584754
Epoch: 54 | Iteration number: [270/565] 47% | Training loss: 0.6893376875806738
Epoch: 54 | Iteration number: [280/565] 49% | Training loss: 0.6892425156065396
Epoch: 54 | Iteration number: [290/565] 51% | Training loss: 0.6891642607491592
Epoch: 54 | Iteration number: [300/565] 53% | Training loss: 0.6890938361485799
Epoch: 54 | Iteration number: [310/565] 54% | Training loss: 0.6890109738995952
Epoch: 54 | Iteration number: [320/565] 56% | Training loss: 0.688935699686408
Epoch: 54 | Iteration number: [330/565] 58% | Training loss: 0.688872799728856
Epoch: 54 | Iteration number: [340/565] 60% | Training loss: 0.6888245217940386
Epoch: 54 | Iteration number: [350/565] 61% | Training loss: 0.6887695636068072
Epoch: 54 | Iteration number: [360/565] 63% | Training loss: 0.6887209397223261
Epoch: 54 | Iteration number: [370/565] 65% | Training loss: 0.6886647989621033
Epoch: 54 | Iteration number: [380/565] 67% | Training loss: 0.6886143340876228
Epoch: 54 | Iteration number: [390/565] 69% | Training loss: 0.6885734550463848
Epoch: 54 | Iteration number: [400/565] 70% | Training loss: 0.6885251180827617
Epoch: 54 | Iteration number: [410/565] 72% | Training loss: 0.6884957790374756
Epoch: 54 | Iteration number: [420/565] 74% | Training loss: 0.6884503096342087
Epoch: 54 | Iteration number: [430/565] 76% | Training loss: 0.6884075620839762
Epoch: 54 | Iteration number: [440/565] 77% | Training loss: 0.6883709688078273
Epoch: 54 | Iteration number: [450/565] 79% | Training loss: 0.6883329027228885
Epoch: 54 | Iteration number: [460/565] 81% | Training loss: 0.688299755298573
Epoch: 54 | Iteration number: [470/565] 83% | Training loss: 0.6882674804393282
Epoch: 54 | Iteration number: [480/565] 84% | Training loss: 0.6882388999064764
Epoch: 54 | Iteration number: [490/565] 86% | Training loss: 0.6882106273758168
Epoch: 54 | Iteration number: [500/565] 88% | Training loss: 0.6881942991018295
Epoch: 54 | Iteration number: [510/565] 90% | Training loss: 0.6881644570359997
Epoch: 54 | Iteration number: [520/565] 92% | Training loss: 0.6881411757606727
Epoch: 54 | Iteration number: [530/565] 93% | Training loss: 0.6881140779774144
Epoch: 54 | Iteration number: [540/565] 95% | Training loss: 0.688089793810138
Epoch: 54 | Iteration number: [550/565] 97% | Training loss: 0.6880650595101443
Epoch: 54 | Iteration number: [560/565] 99% | Training loss: 0.6880404969411237

 End of epoch: 54 | Train Loss: 0.6868145704269409 | Training Time: 88 

 End of epoch: 54 | Eval Loss: 0.6891581756728036 | Evaluating Time: 6 
Epoch: 55 | Iteration number: [10/565] 1% | Training loss: 0.7559525549411774
Epoch: 55 | Iteration number: [20/565] 3% | Training loss: 0.7215937465429306
Epoch: 55 | Iteration number: [30/565] 5% | Training loss: 0.7098980406920116
Epoch: 55 | Iteration number: [40/565] 7% | Training loss: 0.7042106583714485
Epoch: 55 | Iteration number: [50/565] 8% | Training loss: 0.7007195913791656
Epoch: 55 | Iteration number: [60/565] 10% | Training loss: 0.6984627842903137
Epoch: 55 | Iteration number: [70/565] 12% | Training loss: 0.6967519411018916
Epoch: 55 | Iteration number: [80/565] 14% | Training loss: 0.6955400057137012
Epoch: 55 | Iteration number: [90/565] 15% | Training loss: 0.6945549991395739
Epoch: 55 | Iteration number: [100/565] 17% | Training loss: 0.6937980216741562
Epoch: 55 | Iteration number: [110/565] 19% | Training loss: 0.6931590968912298
Epoch: 55 | Iteration number: [120/565] 21% | Training loss: 0.6926171660423279
Epoch: 55 | Iteration number: [130/565] 23% | Training loss: 0.6921512090242826
Epoch: 55 | Iteration number: [140/565] 24% | Training loss: 0.6917581341096333
Epoch: 55 | Iteration number: [150/565] 26% | Training loss: 0.6914537199338278
Epoch: 55 | Iteration number: [160/565] 28% | Training loss: 0.6911599412560463
Epoch: 55 | Iteration number: [170/565] 30% | Training loss: 0.6909269974512212
Epoch: 55 | Iteration number: [180/565] 31% | Training loss: 0.6907037552860048
Epoch: 55 | Iteration number: [190/565] 33% | Training loss: 0.6905079060479214
Epoch: 55 | Iteration number: [200/565] 35% | Training loss: 0.6903307074308396
Epoch: 55 | Iteration number: [210/565] 37% | Training loss: 0.6901696247713907
Epoch: 55 | Iteration number: [220/565] 38% | Training loss: 0.690033866871487
Epoch: 55 | Iteration number: [230/565] 40% | Training loss: 0.6898880787517714
Epoch: 55 | Iteration number: [240/565] 42% | Training loss: 0.689761771261692
Epoch: 55 | Iteration number: [250/565] 44% | Training loss: 0.6896428563594819
Epoch: 55 | Iteration number: [260/565] 46% | Training loss: 0.6895235027258213
Epoch: 55 | Iteration number: [270/565] 47% | Training loss: 0.6894074495191927
Epoch: 55 | Iteration number: [280/565] 49% | Training loss: 0.689326474070549
Epoch: 55 | Iteration number: [290/565] 51% | Training loss: 0.6892506607647599
Epoch: 55 | Iteration number: [300/565] 53% | Training loss: 0.6891578837235769
Epoch: 55 | Iteration number: [310/565] 54% | Training loss: 0.6890880138643326
Epoch: 55 | Iteration number: [320/565] 56% | Training loss: 0.6890196813270449
Epoch: 55 | Iteration number: [330/565] 58% | Training loss: 0.6889526744683584
Epoch: 55 | Iteration number: [340/565] 60% | Training loss: 0.6888843318995308
Epoch: 55 | Iteration number: [350/565] 61% | Training loss: 0.6888211454663958
Epoch: 55 | Iteration number: [360/565] 63% | Training loss: 0.6887680631544855
Epoch: 55 | Iteration number: [370/565] 65% | Training loss: 0.688719301449286
Epoch: 55 | Iteration number: [380/565] 67% | Training loss: 0.6886682759774359
Epoch: 55 | Iteration number: [390/565] 69% | Training loss: 0.6886420499055813
Epoch: 55 | Iteration number: [400/565] 70% | Training loss: 0.6885888721048832
Epoch: 55 | Iteration number: [410/565] 72% | Training loss: 0.6885388769754549
Epoch: 55 | Iteration number: [420/565] 74% | Training loss: 0.6884962506237484
Epoch: 55 | Iteration number: [430/565] 76% | Training loss: 0.6884530947651974
Epoch: 55 | Iteration number: [440/565] 77% | Training loss: 0.6884164638139985
Epoch: 55 | Iteration number: [450/565] 79% | Training loss: 0.6883737173345353
Epoch: 55 | Iteration number: [460/565] 81% | Training loss: 0.6883335259945497
Epoch: 55 | Iteration number: [470/565] 83% | Training loss: 0.6882911697347114
Epoch: 55 | Iteration number: [480/565] 84% | Training loss: 0.6882608162860075
Epoch: 55 | Iteration number: [490/565] 86% | Training loss: 0.6882353834959926
Epoch: 55 | Iteration number: [500/565] 88% | Training loss: 0.6882002885341645
Epoch: 55 | Iteration number: [510/565] 90% | Training loss: 0.688175381749284
Epoch: 55 | Iteration number: [520/565] 92% | Training loss: 0.6881532005392588
Epoch: 55 | Iteration number: [530/565] 93% | Training loss: 0.6881327769666348
Epoch: 55 | Iteration number: [540/565] 95% | Training loss: 0.6881083033702992
Epoch: 55 | Iteration number: [550/565] 97% | Training loss: 0.6880804131247781
Epoch: 55 | Iteration number: [560/565] 99% | Training loss: 0.6880683114486081

 End of epoch: 55 | Train Loss: 0.6868407358110479 | Training Time: 89 

 End of epoch: 55 | Eval Loss: 0.6892906682831901 | Evaluating Time: 6 
Epoch: 56 | Iteration number: [10/565] 1% | Training loss: 0.7550544798374176
Epoch: 56 | Iteration number: [20/565] 3% | Training loss: 0.7209747731685638
Epoch: 56 | Iteration number: [30/565] 5% | Training loss: 0.7097559789816539
Epoch: 56 | Iteration number: [40/565] 7% | Training loss: 0.7040759488940239
Epoch: 56 | Iteration number: [50/565] 8% | Training loss: 0.7005963695049285
Epoch: 56 | Iteration number: [60/565] 10% | Training loss: 0.6982283800840378
Epoch: 56 | Iteration number: [70/565] 12% | Training loss: 0.6965855053492955
Epoch: 56 | Iteration number: [80/565] 14% | Training loss: 0.6953726038336754
Epoch: 56 | Iteration number: [90/565] 15% | Training loss: 0.6944191343254513
Epoch: 56 | Iteration number: [100/565] 17% | Training loss: 0.6935870385169983
Epoch: 56 | Iteration number: [110/565] 19% | Training loss: 0.6929506502368233
Epoch: 56 | Iteration number: [120/565] 21% | Training loss: 0.6924298748373985
Epoch: 56 | Iteration number: [130/565] 23% | Training loss: 0.692002483514639
Epoch: 56 | Iteration number: [140/565] 24% | Training loss: 0.6916259688990457
Epoch: 56 | Iteration number: [150/565] 26% | Training loss: 0.6912983818848928
Epoch: 56 | Iteration number: [160/565] 28% | Training loss: 0.6910271592438221
Epoch: 56 | Iteration number: [170/565] 30% | Training loss: 0.6907757089418524
Epoch: 56 | Iteration number: [180/565] 31% | Training loss: 0.6905648579200109
Epoch: 56 | Iteration number: [190/565] 33% | Training loss: 0.690381016543037
Epoch: 56 | Iteration number: [200/565] 35% | Training loss: 0.6901883682608605
Epoch: 56 | Iteration number: [210/565] 37% | Training loss: 0.6900084935483478
Epoch: 56 | Iteration number: [220/565] 38% | Training loss: 0.6898773534731432
Epoch: 56 | Iteration number: [230/565] 40% | Training loss: 0.6897435797297436
Epoch: 56 | Iteration number: [240/565] 42% | Training loss: 0.6896378067632516
Epoch: 56 | Iteration number: [250/565] 44% | Training loss: 0.6895362451076508
Epoch: 56 | Iteration number: [260/565] 46% | Training loss: 0.6894300889510375
Epoch: 56 | Iteration number: [270/565] 47% | Training loss: 0.6893193790206202
Epoch: 56 | Iteration number: [280/565] 49% | Training loss: 0.6892459152000291
Epoch: 56 | Iteration number: [290/565] 51% | Training loss: 0.689164516432532
Epoch: 56 | Iteration number: [300/565] 53% | Training loss: 0.6890971302986145
Epoch: 56 | Iteration number: [310/565] 54% | Training loss: 0.6890311208463484
Epoch: 56 | Iteration number: [320/565] 56% | Training loss: 0.6889645347371698
Epoch: 56 | Iteration number: [330/565] 58% | Training loss: 0.6889000659639185
Epoch: 56 | Iteration number: [340/565] 60% | Training loss: 0.6888396717169706
Epoch: 56 | Iteration number: [350/565] 61% | Training loss: 0.6887759397711073
Epoch: 56 | Iteration number: [360/565] 63% | Training loss: 0.6887095964617199
Epoch: 56 | Iteration number: [370/565] 65% | Training loss: 0.6886602896290857
Epoch: 56 | Iteration number: [380/565] 67% | Training loss: 0.688590596537841
Epoch: 56 | Iteration number: [390/565] 69% | Training loss: 0.6885576983292897
Epoch: 56 | Iteration number: [400/565] 70% | Training loss: 0.6885063771903515
Epoch: 56 | Iteration number: [410/565] 72% | Training loss: 0.6884794954846545
Epoch: 56 | Iteration number: [420/565] 74% | Training loss: 0.6884400363479342
Epoch: 56 | Iteration number: [430/565] 76% | Training loss: 0.6884031904298206
Epoch: 56 | Iteration number: [440/565] 77% | Training loss: 0.6883623759854923
Epoch: 56 | Iteration number: [450/565] 79% | Training loss: 0.6883247535758549
Epoch: 56 | Iteration number: [460/565] 81% | Training loss: 0.6882864006187605
Epoch: 56 | Iteration number: [470/565] 83% | Training loss: 0.6882612138352495
Epoch: 56 | Iteration number: [480/565] 84% | Training loss: 0.6882366755356392
Epoch: 56 | Iteration number: [490/565] 86% | Training loss: 0.6882082971991325
Epoch: 56 | Iteration number: [500/565] 88% | Training loss: 0.6881820514202118
Epoch: 56 | Iteration number: [510/565] 90% | Training loss: 0.6881604801206028
Epoch: 56 | Iteration number: [520/565] 92% | Training loss: 0.6881341022940782
Epoch: 56 | Iteration number: [530/565] 93% | Training loss: 0.6881109639158789
Epoch: 56 | Iteration number: [540/565] 95% | Training loss: 0.6880795454537427
Epoch: 56 | Iteration number: [550/565] 97% | Training loss: 0.6880567605928941
Epoch: 56 | Iteration number: [560/565] 99% | Training loss: 0.6880446116839136

 End of epoch: 56 | Train Loss: 0.6868176981411149 | Training Time: 89 

 End of epoch: 56 | Eval Loss: 0.6896678124155317 | Evaluating Time: 6 
Epoch: 57 | Iteration number: [10/565] 1% | Training loss: 0.7558022737503052
Epoch: 57 | Iteration number: [20/565] 3% | Training loss: 0.7211570829153061
Epoch: 57 | Iteration number: [30/565] 5% | Training loss: 0.7098629613717397
Epoch: 57 | Iteration number: [40/565] 7% | Training loss: 0.7040352240204811
Epoch: 57 | Iteration number: [50/565] 8% | Training loss: 0.7006391084194183
Epoch: 57 | Iteration number: [60/565] 10% | Training loss: 0.6982611159483592
Epoch: 57 | Iteration number: [70/565] 12% | Training loss: 0.6966364273003169
Epoch: 57 | Iteration number: [80/565] 14% | Training loss: 0.6954791985452176
Epoch: 57 | Iteration number: [90/565] 15% | Training loss: 0.6945267260074616
Epoch: 57 | Iteration number: [100/565] 17% | Training loss: 0.6937576937675476
Epoch: 57 | Iteration number: [110/565] 19% | Training loss: 0.6931167640469291
Epoch: 57 | Iteration number: [120/565] 21% | Training loss: 0.692611250281334
Epoch: 57 | Iteration number: [130/565] 23% | Training loss: 0.6921445365135487
Epoch: 57 | Iteration number: [140/565] 24% | Training loss: 0.6917726584843227
Epoch: 57 | Iteration number: [150/565] 26% | Training loss: 0.6914220118522644
Epoch: 57 | Iteration number: [160/565] 28% | Training loss: 0.6911161735653877
Epoch: 57 | Iteration number: [170/565] 30% | Training loss: 0.6908525365240433
Epoch: 57 | Iteration number: [180/565] 31% | Training loss: 0.6906147615777122
Epoch: 57 | Iteration number: [190/565] 33% | Training loss: 0.6904228379851893
Epoch: 57 | Iteration number: [200/565] 35% | Training loss: 0.6902467766404152
Epoch: 57 | Iteration number: [210/565] 37% | Training loss: 0.6900738406748999
Epoch: 57 | Iteration number: [220/565] 38% | Training loss: 0.6899156732992693
Epoch: 57 | Iteration number: [230/565] 40% | Training loss: 0.6897886776405832
Epoch: 57 | Iteration number: [240/565] 42% | Training loss: 0.6896481797099113
Epoch: 57 | Iteration number: [250/565] 44% | Training loss: 0.6895290033817292
Epoch: 57 | Iteration number: [260/565] 46% | Training loss: 0.6894224586395117
Epoch: 57 | Iteration number: [270/565] 47% | Training loss: 0.6893154897071697
Epoch: 57 | Iteration number: [280/565] 49% | Training loss: 0.6892360101853098
Epoch: 57 | Iteration number: [290/565] 51% | Training loss: 0.6891607364703869
Epoch: 57 | Iteration number: [300/565] 53% | Training loss: 0.689096232453982
Epoch: 57 | Iteration number: [310/565] 54% | Training loss: 0.6890282698215977
Epoch: 57 | Iteration number: [320/565] 56% | Training loss: 0.6889590198174119
Epoch: 57 | Iteration number: [330/565] 58% | Training loss: 0.6888883664752498
Epoch: 57 | Iteration number: [340/565] 60% | Training loss: 0.6888111957732369
Epoch: 57 | Iteration number: [350/565] 61% | Training loss: 0.6887536379269191
Epoch: 57 | Iteration number: [360/565] 63% | Training loss: 0.6887097456389003
Epoch: 57 | Iteration number: [370/565] 65% | Training loss: 0.6886584207818315
Epoch: 57 | Iteration number: [380/565] 67% | Training loss: 0.6886047447982587
Epoch: 57 | Iteration number: [390/565] 69% | Training loss: 0.6885624772463089
Epoch: 57 | Iteration number: [400/565] 70% | Training loss: 0.6885190765559673
Epoch: 57 | Iteration number: [410/565] 72% | Training loss: 0.6884711570856048
Epoch: 57 | Iteration number: [420/565] 74% | Training loss: 0.6884286925906227
Epoch: 57 | Iteration number: [430/565] 76% | Training loss: 0.6883940551170084
Epoch: 57 | Iteration number: [440/565] 77% | Training loss: 0.688347286392342
Epoch: 57 | Iteration number: [450/565] 79% | Training loss: 0.6883167465527852
Epoch: 57 | Iteration number: [460/565] 81% | Training loss: 0.6882859897354375
Epoch: 57 | Iteration number: [470/565] 83% | Training loss: 0.68825464109157
Epoch: 57 | Iteration number: [480/565] 84% | Training loss: 0.6882208542277416
Epoch: 57 | Iteration number: [490/565] 86% | Training loss: 0.6881916100881538
Epoch: 57 | Iteration number: [500/565] 88% | Training loss: 0.6881613383293151
Epoch: 57 | Iteration number: [510/565] 90% | Training loss: 0.6881372337247811
Epoch: 57 | Iteration number: [520/565] 92% | Training loss: 0.688115946490031
Epoch: 57 | Iteration number: [530/565] 93% | Training loss: 0.6880971923189343
Epoch: 57 | Iteration number: [540/565] 95% | Training loss: 0.6880717851497509
Epoch: 57 | Iteration number: [550/565] 97% | Training loss: 0.6880500329624523
Epoch: 57 | Iteration number: [560/565] 99% | Training loss: 0.688030783193452

 End of epoch: 57 | Train Loss: 0.6868064292764242 | Training Time: 89 

 End of epoch: 57 | Eval Loss: 0.6890813112258911 | Evaluating Time: 6 
Epoch: 58 | Iteration number: [10/565] 1% | Training loss: 0.7552135705947876
Epoch: 58 | Iteration number: [20/565] 3% | Training loss: 0.7209177494049073
Epoch: 58 | Iteration number: [30/565] 5% | Training loss: 0.7094773153463999
Epoch: 58 | Iteration number: [40/565] 7% | Training loss: 0.7038240477442741
Epoch: 58 | Iteration number: [50/565] 8% | Training loss: 0.7004588103294372
Epoch: 58 | Iteration number: [60/565] 10% | Training loss: 0.6982366700967153
Epoch: 58 | Iteration number: [70/565] 12% | Training loss: 0.6966084054538182
Epoch: 58 | Iteration number: [80/565] 14% | Training loss: 0.6953506149351597
Epoch: 58 | Iteration number: [90/565] 15% | Training loss: 0.6943972726662954
Epoch: 58 | Iteration number: [100/565] 17% | Training loss: 0.6935960626602173
Epoch: 58 | Iteration number: [110/565] 19% | Training loss: 0.692945597930388
Epoch: 58 | Iteration number: [120/565] 21% | Training loss: 0.6924578006068866
Epoch: 58 | Iteration number: [130/565] 23% | Training loss: 0.6920482511703785
Epoch: 58 | Iteration number: [140/565] 24% | Training loss: 0.6916782276971
Epoch: 58 | Iteration number: [150/565] 26% | Training loss: 0.6913367184003194
Epoch: 58 | Iteration number: [160/565] 28% | Training loss: 0.6910620965063572
Epoch: 58 | Iteration number: [170/565] 30% | Training loss: 0.6907850240959841
Epoch: 58 | Iteration number: [180/565] 31% | Training loss: 0.6905890388621224
Epoch: 58 | Iteration number: [190/565] 33% | Training loss: 0.6903798740161092
Epoch: 58 | Iteration number: [200/565] 35% | Training loss: 0.6901976722478866
Epoch: 58 | Iteration number: [210/565] 37% | Training loss: 0.6900323087260837
Epoch: 58 | Iteration number: [220/565] 38% | Training loss: 0.6898810210553082
Epoch: 58 | Iteration number: [230/565] 40% | Training loss: 0.6897269300792528
Epoch: 58 | Iteration number: [240/565] 42% | Training loss: 0.6895970602830251
Epoch: 58 | Iteration number: [250/565] 44% | Training loss: 0.6894756407737732
Epoch: 58 | Iteration number: [260/565] 46% | Training loss: 0.6893602710503798
Epoch: 58 | Iteration number: [270/565] 47% | Training loss: 0.6892723935621756
Epoch: 58 | Iteration number: [280/565] 49% | Training loss: 0.6891869417258671
Epoch: 58 | Iteration number: [290/565] 51% | Training loss: 0.6891164290493932
Epoch: 58 | Iteration number: [300/565] 53% | Training loss: 0.6890403890609741
Epoch: 58 | Iteration number: [310/565] 54% | Training loss: 0.6889720782156914
Epoch: 58 | Iteration number: [320/565] 56% | Training loss: 0.688911521807313
Epoch: 58 | Iteration number: [330/565] 58% | Training loss: 0.6888437648614247
Epoch: 58 | Iteration number: [340/565] 60% | Training loss: 0.6887939312878777
Epoch: 58 | Iteration number: [350/565] 61% | Training loss: 0.6887438007763453
Epoch: 58 | Iteration number: [360/565] 63% | Training loss: 0.6887064379122522
Epoch: 58 | Iteration number: [370/565] 65% | Training loss: 0.6886547275491663
Epoch: 58 | Iteration number: [380/565] 67% | Training loss: 0.6886109556022443
Epoch: 58 | Iteration number: [390/565] 69% | Training loss: 0.6885698757110498
Epoch: 58 | Iteration number: [400/565] 70% | Training loss: 0.6885255201160908
Epoch: 58 | Iteration number: [410/565] 72% | Training loss: 0.6884762003654387
Epoch: 58 | Iteration number: [420/565] 74% | Training loss: 0.6884401412237258
Epoch: 58 | Iteration number: [430/565] 76% | Training loss: 0.6884008478286654
Epoch: 58 | Iteration number: [440/565] 77% | Training loss: 0.6883651939305392
Epoch: 58 | Iteration number: [450/565] 79% | Training loss: 0.6883245154221853
Epoch: 58 | Iteration number: [460/565] 81% | Training loss: 0.6882930291735607
Epoch: 58 | Iteration number: [470/565] 83% | Training loss: 0.6882687610514621
Epoch: 58 | Iteration number: [480/565] 84% | Training loss: 0.6882307411481937
Epoch: 58 | Iteration number: [490/565] 86% | Training loss: 0.6882046337030372
Epoch: 58 | Iteration number: [500/565] 88% | Training loss: 0.6881778230667114
Epoch: 58 | Iteration number: [510/565] 90% | Training loss: 0.688148893328274
Epoch: 58 | Iteration number: [520/565] 92% | Training loss: 0.6881284412283164
Epoch: 58 | Iteration number: [530/565] 93% | Training loss: 0.6881022059692526
Epoch: 58 | Iteration number: [540/565] 95% | Training loss: 0.6880827025130943
Epoch: 58 | Iteration number: [550/565] 97% | Training loss: 0.6880539811741222
Epoch: 58 | Iteration number: [560/565] 99% | Training loss: 0.6880348483366626

 End of epoch: 58 | Train Loss: 0.6868091277316608 | Training Time: 89 

 End of epoch: 58 | Eval Loss: 0.6892435380390712 | Evaluating Time: 6 
Epoch: 59 | Iteration number: [10/565] 1% | Training loss: 0.7557114064693451
Epoch: 59 | Iteration number: [20/565] 3% | Training loss: 0.7213257610797882
Epoch: 59 | Iteration number: [30/565] 5% | Training loss: 0.7097830653190613
Epoch: 59 | Iteration number: [40/565] 7% | Training loss: 0.7040042772889137
Epoch: 59 | Iteration number: [50/565] 8% | Training loss: 0.7006041145324707
Epoch: 59 | Iteration number: [60/565] 10% | Training loss: 0.6982676267623902
Epoch: 59 | Iteration number: [70/565] 12% | Training loss: 0.6966237000056675
Epoch: 59 | Iteration number: [80/565] 14% | Training loss: 0.6954251229763031
Epoch: 59 | Iteration number: [90/565] 15% | Training loss: 0.6944871683915456
Epoch: 59 | Iteration number: [100/565] 17% | Training loss: 0.6937192970514298
Epoch: 59 | Iteration number: [110/565] 19% | Training loss: 0.6931057290597396
Epoch: 59 | Iteration number: [120/565] 21% | Training loss: 0.6925985862811407
Epoch: 59 | Iteration number: [130/565] 23% | Training loss: 0.6921408501955179
Epoch: 59 | Iteration number: [140/565] 24% | Training loss: 0.6917237498930522
Epoch: 59 | Iteration number: [150/565] 26% | Training loss: 0.691400473912557
Epoch: 59 | Iteration number: [160/565] 28% | Training loss: 0.6911182202398777
Epoch: 59 | Iteration number: [170/565] 30% | Training loss: 0.6908300778445076
Epoch: 59 | Iteration number: [180/565] 31% | Training loss: 0.6906087577342988
Epoch: 59 | Iteration number: [190/565] 33% | Training loss: 0.6904240190982819
Epoch: 59 | Iteration number: [200/565] 35% | Training loss: 0.690253686606884
Epoch: 59 | Iteration number: [210/565] 37% | Training loss: 0.6901017299720219
Epoch: 59 | Iteration number: [220/565] 38% | Training loss: 0.6899907802993601
Epoch: 59 | Iteration number: [230/565] 40% | Training loss: 0.6898545431054157
Epoch: 59 | Iteration number: [240/565] 42% | Training loss: 0.6897537519534429
Epoch: 59 | Iteration number: [250/565] 44% | Training loss: 0.6896254253387452
Epoch: 59 | Iteration number: [260/565] 46% | Training loss: 0.6895127468384229
Epoch: 59 | Iteration number: [270/565] 47% | Training loss: 0.6894165032439762
Epoch: 59 | Iteration number: [280/565] 49% | Training loss: 0.6893306031823159
Epoch: 59 | Iteration number: [290/565] 51% | Training loss: 0.689244447288842
Epoch: 59 | Iteration number: [300/565] 53% | Training loss: 0.6891766210397084
Epoch: 59 | Iteration number: [310/565] 54% | Training loss: 0.6890912978879867
Epoch: 59 | Iteration number: [320/565] 56% | Training loss: 0.6890231519937515
Epoch: 59 | Iteration number: [330/565] 58% | Training loss: 0.6889375034606818
Epoch: 59 | Iteration number: [340/565] 60% | Training loss: 0.6888891137698118
Epoch: 59 | Iteration number: [350/565] 61% | Training loss: 0.6888294383457729
Epoch: 59 | Iteration number: [360/565] 63% | Training loss: 0.6887661245134141
Epoch: 59 | Iteration number: [370/565] 65% | Training loss: 0.6887069363851805
Epoch: 59 | Iteration number: [380/565] 67% | Training loss: 0.6886538660839985
Epoch: 59 | Iteration number: [390/565] 69% | Training loss: 0.6885946223369012
Epoch: 59 | Iteration number: [400/565] 70% | Training loss: 0.6885391886532307
Epoch: 59 | Iteration number: [410/565] 72% | Training loss: 0.6884927895010972
Epoch: 59 | Iteration number: [420/565] 74% | Training loss: 0.6884526746613638
Epoch: 59 | Iteration number: [430/565] 76% | Training loss: 0.6884095068587813
Epoch: 59 | Iteration number: [440/565] 77% | Training loss: 0.6883679036389697
Epoch: 59 | Iteration number: [450/565] 79% | Training loss: 0.6883397302362654
Epoch: 59 | Iteration number: [460/565] 81% | Training loss: 0.688305996293607
Epoch: 59 | Iteration number: [470/565] 83% | Training loss: 0.68827884679145
Epoch: 59 | Iteration number: [480/565] 84% | Training loss: 0.6882480240116516
Epoch: 59 | Iteration number: [490/565] 86% | Training loss: 0.6882193722287003
Epoch: 59 | Iteration number: [500/565] 88% | Training loss: 0.6881969388723373
Epoch: 59 | Iteration number: [510/565] 90% | Training loss: 0.6881736747190064
Epoch: 59 | Iteration number: [520/565] 92% | Training loss: 0.6881516325932283
Epoch: 59 | Iteration number: [530/565] 93% | Training loss: 0.6881238550510047
Epoch: 59 | Iteration number: [540/565] 95% | Training loss: 0.6880990206091492
Epoch: 59 | Iteration number: [550/565] 97% | Training loss: 0.688076171875
Epoch: 59 | Iteration number: [560/565] 99% | Training loss: 0.6880484474556786

 End of epoch: 59 | Train Loss: 0.6868187811522357 | Training Time: 88 

 End of epoch: 59 | Eval Loss: 0.6893438441412789 | Evaluating Time: 6 
Epoch: 60 | Iteration number: [10/565] 1% | Training loss: 0.7560100197792053
Epoch: 60 | Iteration number: [20/565] 3% | Training loss: 0.7214450031518936
Epoch: 60 | Iteration number: [30/565] 5% | Training loss: 0.7097973565260569
Epoch: 60 | Iteration number: [40/565] 7% | Training loss: 0.7040129274129867
Epoch: 60 | Iteration number: [50/565] 8% | Training loss: 0.7005443286895752
Epoch: 60 | Iteration number: [60/565] 10% | Training loss: 0.6982003182172776
Epoch: 60 | Iteration number: [70/565] 12% | Training loss: 0.6965131555284773
Epoch: 60 | Iteration number: [80/565] 14% | Training loss: 0.6953278601169586
Epoch: 60 | Iteration number: [90/565] 15% | Training loss: 0.6943661603662703
Epoch: 60 | Iteration number: [100/565] 17% | Training loss: 0.6935716700553894
Epoch: 60 | Iteration number: [110/565] 19% | Training loss: 0.6929674278606068
Epoch: 60 | Iteration number: [120/565] 21% | Training loss: 0.6924805760383606
Epoch: 60 | Iteration number: [130/565] 23% | Training loss: 0.6920527985462775
Epoch: 60 | Iteration number: [140/565] 24% | Training loss: 0.691656738945416
Epoch: 60 | Iteration number: [150/565] 26% | Training loss: 0.6913536139329275
Epoch: 60 | Iteration number: [160/565] 28% | Training loss: 0.6910613421350718
Epoch: 60 | Iteration number: [170/565] 30% | Training loss: 0.6907848831485299
Epoch: 60 | Iteration number: [180/565] 31% | Training loss: 0.6905765665902032
Epoch: 60 | Iteration number: [190/565] 33% | Training loss: 0.6903701161083422
Epoch: 60 | Iteration number: [200/565] 35% | Training loss: 0.6901960840821266
Epoch: 60 | Iteration number: [210/565] 37% | Training loss: 0.6900438921792167
Epoch: 60 | Iteration number: [220/565] 38% | Training loss: 0.6898926314982501
Epoch: 60 | Iteration number: [230/565] 40% | Training loss: 0.6897576484991157
Epoch: 60 | Iteration number: [240/565] 42% | Training loss: 0.6896361961960793
Epoch: 60 | Iteration number: [250/565] 44% | Training loss: 0.6895395975112915
Epoch: 60 | Iteration number: [260/565] 46% | Training loss: 0.6894368809003096
Epoch: 60 | Iteration number: [270/565] 47% | Training loss: 0.6893423283541644
Epoch: 60 | Iteration number: [280/565] 49% | Training loss: 0.6892567557947976
Epoch: 60 | Iteration number: [290/565] 51% | Training loss: 0.6891716174010573
Epoch: 60 | Iteration number: [300/565] 53% | Training loss: 0.6890933565298716
Epoch: 60 | Iteration number: [310/565] 54% | Training loss: 0.6890333762091975
Epoch: 60 | Iteration number: [320/565] 56% | Training loss: 0.6889538824558258
Epoch: 60 | Iteration number: [330/565] 58% | Training loss: 0.6888829157207952
Epoch: 60 | Iteration number: [340/565] 60% | Training loss: 0.6888221639044144
Epoch: 60 | Iteration number: [350/565] 61% | Training loss: 0.6887621145589011
Epoch: 60 | Iteration number: [360/565] 63% | Training loss: 0.6887151579062144
Epoch: 60 | Iteration number: [370/565] 65% | Training loss: 0.6886603374738951
Epoch: 60 | Iteration number: [380/565] 67% | Training loss: 0.6886032178213722
Epoch: 60 | Iteration number: [390/565] 69% | Training loss: 0.6885589211415022
Epoch: 60 | Iteration number: [400/565] 70% | Training loss: 0.6885200491547585
Epoch: 60 | Iteration number: [410/565] 72% | Training loss: 0.6884657252125623
Epoch: 60 | Iteration number: [420/565] 74% | Training loss: 0.6884266897326424
Epoch: 60 | Iteration number: [430/565] 76% | Training loss: 0.688395476479863
Epoch: 60 | Iteration number: [440/565] 77% | Training loss: 0.6883638736876574
Epoch: 60 | Iteration number: [450/565] 79% | Training loss: 0.688330835501353
Epoch: 60 | Iteration number: [460/565] 81% | Training loss: 0.6882983385220818
Epoch: 60 | Iteration number: [470/565] 83% | Training loss: 0.6882649393791848
Epoch: 60 | Iteration number: [480/565] 84% | Training loss: 0.6882334320495526
Epoch: 60 | Iteration number: [490/565] 86% | Training loss: 0.6882068030688228
Epoch: 60 | Iteration number: [500/565] 88% | Training loss: 0.6881885093450546
Epoch: 60 | Iteration number: [510/565] 90% | Training loss: 0.6881573201394549
Epoch: 60 | Iteration number: [520/565] 92% | Training loss: 0.6881320406611149
Epoch: 60 | Iteration number: [530/565] 93% | Training loss: 0.6881107776794794
Epoch: 60 | Iteration number: [540/565] 95% | Training loss: 0.6880874855650796
Epoch: 60 | Iteration number: [550/565] 97% | Training loss: 0.6880688538334586
Epoch: 60 | Iteration number: [560/565] 99% | Training loss: 0.6880451471677849

 End of epoch: 60 | Train Loss: 0.6868173950541336 | Training Time: 90 

 End of epoch: 60 | Eval Loss: 0.6889409167425973 | Evaluating Time: 5 
Epoch: 61 | Iteration number: [10/565] 1% | Training loss: 0.7555706560611725
Epoch: 61 | Iteration number: [20/565] 3% | Training loss: 0.7212172299623489
Epoch: 61 | Iteration number: [30/565] 5% | Training loss: 0.7097861270109812
Epoch: 61 | Iteration number: [40/565] 7% | Training loss: 0.7039986088871956
Epoch: 61 | Iteration number: [50/565] 8% | Training loss: 0.7005730652809143
Epoch: 61 | Iteration number: [60/565] 10% | Training loss: 0.6983168522516886
Epoch: 61 | Iteration number: [70/565] 12% | Training loss: 0.6966430417128971
Epoch: 61 | Iteration number: [80/565] 14% | Training loss: 0.6954007357358932
Epoch: 61 | Iteration number: [90/565] 15% | Training loss: 0.6944358090559641
Epoch: 61 | Iteration number: [100/565] 17% | Training loss: 0.6937076193094254
Epoch: 61 | Iteration number: [110/565] 19% | Training loss: 0.6930247664451599
Epoch: 61 | Iteration number: [120/565] 21% | Training loss: 0.6925054570039113
Epoch: 61 | Iteration number: [130/565] 23% | Training loss: 0.6920569584919856
Epoch: 61 | Iteration number: [140/565] 24% | Training loss: 0.691675769005503
Epoch: 61 | Iteration number: [150/565] 26% | Training loss: 0.691393940448761
Epoch: 61 | Iteration number: [160/565] 28% | Training loss: 0.6910962451249361
Epoch: 61 | Iteration number: [170/565] 30% | Training loss: 0.6908690378946416
Epoch: 61 | Iteration number: [180/565] 31% | Training loss: 0.6906510714027617
Epoch: 61 | Iteration number: [190/565] 33% | Training loss: 0.6904351767740752
Epoch: 61 | Iteration number: [200/565] 35% | Training loss: 0.6902635958790779
Epoch: 61 | Iteration number: [210/565] 37% | Training loss: 0.6900919868832542
Epoch: 61 | Iteration number: [220/565] 38% | Training loss: 0.6899505444548347
Epoch: 61 | Iteration number: [230/565] 40% | Training loss: 0.6898311145927595
Epoch: 61 | Iteration number: [240/565] 42% | Training loss: 0.6897207088768482
Epoch: 61 | Iteration number: [250/565] 44% | Training loss: 0.6896007559299469
Epoch: 61 | Iteration number: [260/565] 46% | Training loss: 0.6894998135475012
Epoch: 61 | Iteration number: [270/565] 47% | Training loss: 0.6894062602961505
Epoch: 61 | Iteration number: [280/565] 49% | Training loss: 0.689306594644274
Epoch: 61 | Iteration number: [290/565] 51% | Training loss: 0.6892098328162883
Epoch: 61 | Iteration number: [300/565] 53% | Training loss: 0.6891182772318523
Epoch: 61 | Iteration number: [310/565] 54% | Training loss: 0.6890515954263748
Epoch: 61 | Iteration number: [320/565] 56% | Training loss: 0.6889927159994841
Epoch: 61 | Iteration number: [330/565] 58% | Training loss: 0.688921046257019
Epoch: 61 | Iteration number: [340/565] 60% | Training loss: 0.6888554786934572
Epoch: 61 | Iteration number: [350/565] 61% | Training loss: 0.6888111821242742
Epoch: 61 | Iteration number: [360/565] 63% | Training loss: 0.6887563712067074
Epoch: 61 | Iteration number: [370/565] 65% | Training loss: 0.6887039759674588
Epoch: 61 | Iteration number: [380/565] 67% | Training loss: 0.6886604296533685
Epoch: 61 | Iteration number: [390/565] 69% | Training loss: 0.6886086289699261
Epoch: 61 | Iteration number: [400/565] 70% | Training loss: 0.6885575750470161
Epoch: 61 | Iteration number: [410/565] 72% | Training loss: 0.6885120463080523
Epoch: 61 | Iteration number: [420/565] 74% | Training loss: 0.6884716353246144
Epoch: 61 | Iteration number: [430/565] 76% | Training loss: 0.6884219223676726
Epoch: 61 | Iteration number: [440/565] 77% | Training loss: 0.6883876720612699
Epoch: 61 | Iteration number: [450/565] 79% | Training loss: 0.6883478792508443
Epoch: 61 | Iteration number: [460/565] 81% | Training loss: 0.6883116023695988
Epoch: 61 | Iteration number: [470/565] 83% | Training loss: 0.688284673842978
Epoch: 61 | Iteration number: [480/565] 84% | Training loss: 0.6882510680705309
Epoch: 61 | Iteration number: [490/565] 86% | Training loss: 0.6882177254375146
Epoch: 61 | Iteration number: [500/565] 88% | Training loss: 0.6881840230226517
Epoch: 61 | Iteration number: [510/565] 90% | Training loss: 0.6881506229148192
Epoch: 61 | Iteration number: [520/565] 92% | Training loss: 0.6881264621248612
Epoch: 61 | Iteration number: [530/565] 93% | Training loss: 0.6881022340846512
Epoch: 61 | Iteration number: [540/565] 95% | Training loss: 0.688083490398195
Epoch: 61 | Iteration number: [550/565] 97% | Training loss: 0.6880532629923387
Epoch: 61 | Iteration number: [560/565] 99% | Training loss: 0.6880322010389396

 End of epoch: 61 | Train Loss: 0.686802814808567 | Training Time: 87 

 End of epoch: 61 | Eval Loss: 0.6888473970549447 | Evaluating Time: 5 
Epoch: 62 | Iteration number: [10/565] 1% | Training loss: 0.7554709672927856
Epoch: 62 | Iteration number: [20/565] 3% | Training loss: 0.7212910205125809
Epoch: 62 | Iteration number: [30/565] 5% | Training loss: 0.7099307517210642
Epoch: 62 | Iteration number: [40/565] 7% | Training loss: 0.7041125923395157
Epoch: 62 | Iteration number: [50/565] 8% | Training loss: 0.7005933129787445
Epoch: 62 | Iteration number: [60/565] 10% | Training loss: 0.6983202030261357
Epoch: 62 | Iteration number: [70/565] 12% | Training loss: 0.6966848501137325
Epoch: 62 | Iteration number: [80/565] 14% | Training loss: 0.6954594172537327
Epoch: 62 | Iteration number: [90/565] 15% | Training loss: 0.6945564779970381
Epoch: 62 | Iteration number: [100/565] 17% | Training loss: 0.6937776148319245
Epoch: 62 | Iteration number: [110/565] 19% | Training loss: 0.6931085375222292
Epoch: 62 | Iteration number: [120/565] 21% | Training loss: 0.6926019564270973
Epoch: 62 | Iteration number: [130/565] 23% | Training loss: 0.6921555578708649
Epoch: 62 | Iteration number: [140/565] 24% | Training loss: 0.6917829637016569
Epoch: 62 | Iteration number: [150/565] 26% | Training loss: 0.691438798904419
Epoch: 62 | Iteration number: [160/565] 28% | Training loss: 0.6911673419177532
Epoch: 62 | Iteration number: [170/565] 30% | Training loss: 0.6909024824114407
Epoch: 62 | Iteration number: [180/565] 31% | Training loss: 0.6906771404875649
Epoch: 62 | Iteration number: [190/565] 33% | Training loss: 0.6904763773867958
Epoch: 62 | Iteration number: [200/565] 35% | Training loss: 0.6902932250499725
Epoch: 62 | Iteration number: [210/565] 37% | Training loss: 0.6901098614647275
Epoch: 62 | Iteration number: [220/565] 38% | Training loss: 0.6899693543260748
Epoch: 62 | Iteration number: [230/565] 40% | Training loss: 0.6898337465265523
Epoch: 62 | Iteration number: [240/565] 42% | Training loss: 0.6897028254965941
Epoch: 62 | Iteration number: [250/565] 44% | Training loss: 0.6896010732650757
Epoch: 62 | Iteration number: [260/565] 46% | Training loss: 0.6894976377487183
Epoch: 62 | Iteration number: [270/565] 47% | Training loss: 0.6894035105352049
Epoch: 62 | Iteration number: [280/565] 49% | Training loss: 0.6893130706889289
Epoch: 62 | Iteration number: [290/565] 51% | Training loss: 0.6892226967318305
Epoch: 62 | Iteration number: [300/565] 53% | Training loss: 0.6891432732343674
Epoch: 62 | Iteration number: [310/565] 54% | Training loss: 0.6890703974231597
Epoch: 62 | Iteration number: [320/565] 56% | Training loss: 0.6889954401180148
Epoch: 62 | Iteration number: [330/565] 58% | Training loss: 0.6889262970649834
Epoch: 62 | Iteration number: [340/565] 60% | Training loss: 0.6888499864760567
Epoch: 62 | Iteration number: [350/565] 61% | Training loss: 0.6887876793316432
Epoch: 62 | Iteration number: [360/565] 63% | Training loss: 0.6887412695421113
Epoch: 62 | Iteration number: [370/565] 65% | Training loss: 0.6886885340149338
Epoch: 62 | Iteration number: [380/565] 67% | Training loss: 0.68863309951205
Epoch: 62 | Iteration number: [390/565] 69% | Training loss: 0.6885789845234308
Epoch: 62 | Iteration number: [400/565] 70% | Training loss: 0.6885241417586804
Epoch: 62 | Iteration number: [410/565] 72% | Training loss: 0.6884777028386185
Epoch: 62 | Iteration number: [420/565] 74% | Training loss: 0.6884348328624453
Epoch: 62 | Iteration number: [430/565] 76% | Training loss: 0.6883893134982086
Epoch: 62 | Iteration number: [440/565] 77% | Training loss: 0.6883504700931635
Epoch: 62 | Iteration number: [450/565] 79% | Training loss: 0.688311320675744
Epoch: 62 | Iteration number: [460/565] 81% | Training loss: 0.6882779333902442
Epoch: 62 | Iteration number: [470/565] 83% | Training loss: 0.6882518611055739
Epoch: 62 | Iteration number: [480/565] 84% | Training loss: 0.688215435296297
Epoch: 62 | Iteration number: [490/565] 86% | Training loss: 0.6881936114661548
Epoch: 62 | Iteration number: [500/565] 88% | Training loss: 0.6881693977117539
Epoch: 62 | Iteration number: [510/565] 90% | Training loss: 0.6881446529837215
Epoch: 62 | Iteration number: [520/565] 92% | Training loss: 0.6881229115220217
Epoch: 62 | Iteration number: [530/565] 93% | Training loss: 0.6880982261783671
Epoch: 62 | Iteration number: [540/565] 95% | Training loss: 0.6880705570733106
Epoch: 62 | Iteration number: [550/565] 97% | Training loss: 0.6880465922572396
Epoch: 62 | Iteration number: [560/565] 99% | Training loss: 0.6880277532551969

 End of epoch: 62 | Train Loss: 0.6868061999304105 | Training Time: 90 

 End of epoch: 62 | Eval Loss: 0.6890039954866681 | Evaluating Time: 6 
Epoch: 63 | Iteration number: [10/565] 1% | Training loss: 0.7557461380958557
Epoch: 63 | Iteration number: [20/565] 3% | Training loss: 0.7211608469486237
Epoch: 63 | Iteration number: [30/565] 5% | Training loss: 0.7098133246103923
Epoch: 63 | Iteration number: [40/565] 7% | Training loss: 0.7040977373719215
Epoch: 63 | Iteration number: [50/565] 8% | Training loss: 0.7006524622440338
Epoch: 63 | Iteration number: [60/565] 10% | Training loss: 0.6983169873555501
Epoch: 63 | Iteration number: [70/565] 12% | Training loss: 0.6966719465596335
Epoch: 63 | Iteration number: [80/565] 14% | Training loss: 0.6954504452645779
Epoch: 63 | Iteration number: [90/565] 15% | Training loss: 0.6945027477211423
Epoch: 63 | Iteration number: [100/565] 17% | Training loss: 0.6937363809347152
Epoch: 63 | Iteration number: [110/565] 19% | Training loss: 0.6931137198751623
Epoch: 63 | Iteration number: [120/565] 21% | Training loss: 0.6925628860791524
Epoch: 63 | Iteration number: [130/565] 23% | Training loss: 0.6921135645646316
Epoch: 63 | Iteration number: [140/565] 24% | Training loss: 0.6917502667222705
Epoch: 63 | Iteration number: [150/565] 26% | Training loss: 0.6914150043328603
Epoch: 63 | Iteration number: [160/565] 28% | Training loss: 0.6911419842392206
Epoch: 63 | Iteration number: [170/565] 30% | Training loss: 0.6908940329271205
Epoch: 63 | Iteration number: [180/565] 31% | Training loss: 0.6906581736273236
Epoch: 63 | Iteration number: [190/565] 33% | Training loss: 0.6904797597935325
Epoch: 63 | Iteration number: [200/565] 35% | Training loss: 0.6902917516231537
Epoch: 63 | Iteration number: [210/565] 37% | Training loss: 0.690122199626196
Epoch: 63 | Iteration number: [220/565] 38% | Training loss: 0.6899596891619942
Epoch: 63 | Iteration number: [230/565] 40% | Training loss: 0.6898246068021525
Epoch: 63 | Iteration number: [240/565] 42% | Training loss: 0.6896993127961953
Epoch: 63 | Iteration number: [250/565] 44% | Training loss: 0.6895850422382355
Epoch: 63 | Iteration number: [260/565] 46% | Training loss: 0.6894737789264092
Epoch: 63 | Iteration number: [270/565] 47% | Training loss: 0.6893878250210373
Epoch: 63 | Iteration number: [280/565] 49% | Training loss: 0.6892909592815808
Epoch: 63 | Iteration number: [290/565] 51% | Training loss: 0.6892125941556075
Epoch: 63 | Iteration number: [300/565] 53% | Training loss: 0.6891237235069275
Epoch: 63 | Iteration number: [310/565] 54% | Training loss: 0.6890344031395451
Epoch: 63 | Iteration number: [320/565] 56% | Training loss: 0.6889765189960599
Epoch: 63 | Iteration number: [330/565] 58% | Training loss: 0.688918663335569
Epoch: 63 | Iteration number: [340/565] 60% | Training loss: 0.6888580283697914
Epoch: 63 | Iteration number: [350/565] 61% | Training loss: 0.6887971557889666
Epoch: 63 | Iteration number: [360/565] 63% | Training loss: 0.6887439979447258
Epoch: 63 | Iteration number: [370/565] 65% | Training loss: 0.6886887440810332
Epoch: 63 | Iteration number: [380/565] 67% | Training loss: 0.688640107292878
Epoch: 63 | Iteration number: [390/565] 69% | Training loss: 0.6885851678175804
Epoch: 63 | Iteration number: [400/565] 70% | Training loss: 0.6885303372144699
Epoch: 63 | Iteration number: [410/565] 72% | Training loss: 0.6884774852089766
Epoch: 63 | Iteration number: [420/565] 74% | Training loss: 0.6884473350786028
Epoch: 63 | Iteration number: [430/565] 76% | Training loss: 0.6883985735649286
Epoch: 63 | Iteration number: [440/565] 77% | Training loss: 0.6883631496266885
Epoch: 63 | Iteration number: [450/565] 79% | Training loss: 0.6883223492569394
Epoch: 63 | Iteration number: [460/565] 81% | Training loss: 0.6882804191630819
Epoch: 63 | Iteration number: [470/565] 83% | Training loss: 0.688247366661721
Epoch: 63 | Iteration number: [480/565] 84% | Training loss: 0.6882224019616843
Epoch: 63 | Iteration number: [490/565] 86% | Training loss: 0.6881919390084792
Epoch: 63 | Iteration number: [500/565] 88% | Training loss: 0.6881602910757065
Epoch: 63 | Iteration number: [510/565] 90% | Training loss: 0.6881369472718706
Epoch: 63 | Iteration number: [520/565] 92% | Training loss: 0.6881125220885643
Epoch: 63 | Iteration number: [530/565] 93% | Training loss: 0.6880960688276111
Epoch: 63 | Iteration number: [540/565] 95% | Training loss: 0.6880698369608985
Epoch: 63 | Iteration number: [550/565] 97% | Training loss: 0.6880437615784731
Epoch: 63 | Iteration number: [560/565] 99% | Training loss: 0.6880283283335822

 End of epoch: 63 | Train Loss: 0.6868027257708321 | Training Time: 89 

 End of epoch: 63 | Eval Loss: 0.6894591961588178 | Evaluating Time: 6 
Epoch: 64 | Iteration number: [10/565] 1% | Training loss: 0.7561862647533417
Epoch: 64 | Iteration number: [20/565] 3% | Training loss: 0.7217344254255295
Epoch: 64 | Iteration number: [30/565] 5% | Training loss: 0.7100745101769765
Epoch: 64 | Iteration number: [40/565] 7% | Training loss: 0.7042136326432228
Epoch: 64 | Iteration number: [50/565] 8% | Training loss: 0.7006966924667358
Epoch: 64 | Iteration number: [60/565] 10% | Training loss: 0.6984552174806595
Epoch: 64 | Iteration number: [70/565] 12% | Training loss: 0.6967920924936022
Epoch: 64 | Iteration number: [80/565] 14% | Training loss: 0.6955408483743668
Epoch: 64 | Iteration number: [90/565] 15% | Training loss: 0.6945427616437276
Epoch: 64 | Iteration number: [100/565] 17% | Training loss: 0.6937559014558792
Epoch: 64 | Iteration number: [110/565] 19% | Training loss: 0.6931129824031483
Epoch: 64 | Iteration number: [120/565] 21% | Training loss: 0.6925791566570599
Epoch: 64 | Iteration number: [130/565] 23% | Training loss: 0.6920874306788811
Epoch: 64 | Iteration number: [140/565] 24% | Training loss: 0.6917196788958141
Epoch: 64 | Iteration number: [150/565] 26% | Training loss: 0.6914158197244008
Epoch: 64 | Iteration number: [160/565] 28% | Training loss: 0.6911519512534141
Epoch: 64 | Iteration number: [170/565] 30% | Training loss: 0.6908972305410048
Epoch: 64 | Iteration number: [180/565] 31% | Training loss: 0.6906651712126202
Epoch: 64 | Iteration number: [190/565] 33% | Training loss: 0.6904420347590196
Epoch: 64 | Iteration number: [200/565] 35% | Training loss: 0.6902556091547012
Epoch: 64 | Iteration number: [210/565] 37% | Training loss: 0.6900994641440256
Epoch: 64 | Iteration number: [220/565] 38% | Training loss: 0.6899378161538731
Epoch: 64 | Iteration number: [230/565] 40% | Training loss: 0.6897934773693915
Epoch: 64 | Iteration number: [240/565] 42% | Training loss: 0.6896750003099441
Epoch: 64 | Iteration number: [250/565] 44% | Training loss: 0.6895670652389526
Epoch: 64 | Iteration number: [260/565] 46% | Training loss: 0.6894840928224417
Epoch: 64 | Iteration number: [270/565] 47% | Training loss: 0.6894094511314675
Epoch: 64 | Iteration number: [280/565] 49% | Training loss: 0.6893039880054338
Epoch: 64 | Iteration number: [290/565] 51% | Training loss: 0.689229004753047
Epoch: 64 | Iteration number: [300/565] 53% | Training loss: 0.689140165845553
Epoch: 64 | Iteration number: [310/565] 54% | Training loss: 0.6890544524115901
Epoch: 64 | Iteration number: [320/565] 56% | Training loss: 0.6889815555885435
Epoch: 64 | Iteration number: [330/565] 58% | Training loss: 0.6889228492072135
Epoch: 64 | Iteration number: [340/565] 60% | Training loss: 0.6888711412163342
Epoch: 64 | Iteration number: [350/565] 61% | Training loss: 0.6888136570794242
Epoch: 64 | Iteration number: [360/565] 63% | Training loss: 0.6887486312124464
Epoch: 64 | Iteration number: [370/565] 65% | Training loss: 0.6886899724199965
Epoch: 64 | Iteration number: [380/565] 67% | Training loss: 0.6886425273983102
Epoch: 64 | Iteration number: [390/565] 69% | Training loss: 0.6885917521440066
Epoch: 64 | Iteration number: [400/565] 70% | Training loss: 0.6885462227463722
Epoch: 64 | Iteration number: [410/565] 72% | Training loss: 0.6885006554243042
Epoch: 64 | Iteration number: [420/565] 74% | Training loss: 0.6884525941950934
Epoch: 64 | Iteration number: [430/565] 76% | Training loss: 0.688412745331609
Epoch: 64 | Iteration number: [440/565] 77% | Training loss: 0.6883746293458072
Epoch: 64 | Iteration number: [450/565] 79% | Training loss: 0.6883478417661455
Epoch: 64 | Iteration number: [460/565] 81% | Training loss: 0.6883115510577741
Epoch: 64 | Iteration number: [470/565] 83% | Training loss: 0.6882758565405582
Epoch: 64 | Iteration number: [480/565] 84% | Training loss: 0.6882484757651885
Epoch: 64 | Iteration number: [490/565] 86% | Training loss: 0.6882110061694164
Epoch: 64 | Iteration number: [500/565] 88% | Training loss: 0.6881810278892517
Epoch: 64 | Iteration number: [510/565] 90% | Training loss: 0.688155674233156
Epoch: 64 | Iteration number: [520/565] 92% | Training loss: 0.6881288911287601
Epoch: 64 | Iteration number: [530/565] 93% | Training loss: 0.6881088235468235
Epoch: 64 | Iteration number: [540/565] 95% | Training loss: 0.6880760234815103
Epoch: 64 | Iteration number: [550/565] 97% | Training loss: 0.6880562227422541
Epoch: 64 | Iteration number: [560/565] 99% | Training loss: 0.688035049183028

 End of epoch: 64 | Train Loss: 0.6868103514730403 | Training Time: 90 

 End of epoch: 64 | Eval Loss: 0.6882850527763367 | Evaluating Time: 6 
Epoch: 65 | Iteration number: [10/565] 1% | Training loss: 0.7550741910934449
Epoch: 65 | Iteration number: [20/565] 3% | Training loss: 0.721016812324524
Epoch: 65 | Iteration number: [30/565] 5% | Training loss: 0.7093810081481934
Epoch: 65 | Iteration number: [40/565] 7% | Training loss: 0.7035934671759605
Epoch: 65 | Iteration number: [50/565] 8% | Training loss: 0.7002403354644775
Epoch: 65 | Iteration number: [60/565] 10% | Training loss: 0.6980454246203105
Epoch: 65 | Iteration number: [70/565] 12% | Training loss: 0.6965229724134717
Epoch: 65 | Iteration number: [80/565] 14% | Training loss: 0.6953564703464508
Epoch: 65 | Iteration number: [90/565] 15% | Training loss: 0.6944050663047366
Epoch: 65 | Iteration number: [100/565] 17% | Training loss: 0.6935692805051804
Epoch: 65 | Iteration number: [110/565] 19% | Training loss: 0.6929776619781147
Epoch: 65 | Iteration number: [120/565] 21% | Training loss: 0.6924768095215161
Epoch: 65 | Iteration number: [130/565] 23% | Training loss: 0.6920227371729337
Epoch: 65 | Iteration number: [140/565] 24% | Training loss: 0.6916273372513907
Epoch: 65 | Iteration number: [150/565] 26% | Training loss: 0.6913276831309001
Epoch: 65 | Iteration number: [160/565] 28% | Training loss: 0.6910648193210364
Epoch: 65 | Iteration number: [170/565] 30% | Training loss: 0.6908328038804671
Epoch: 65 | Iteration number: [180/565] 31% | Training loss: 0.6906024903059006
Epoch: 65 | Iteration number: [190/565] 33% | Training loss: 0.6904053791573174
Epoch: 65 | Iteration number: [200/565] 35% | Training loss: 0.69021978110075
Epoch: 65 | Iteration number: [210/565] 37% | Training loss: 0.6900675047011603
Epoch: 65 | Iteration number: [220/565] 38% | Training loss: 0.6899273940108039
Epoch: 65 | Iteration number: [230/565] 40% | Training loss: 0.6898044176723646
Epoch: 65 | Iteration number: [240/565] 42% | Training loss: 0.6896804402271907
Epoch: 65 | Iteration number: [250/565] 44% | Training loss: 0.6895487420558929
Epoch: 65 | Iteration number: [260/565] 46% | Training loss: 0.6894409026090915
Epoch: 65 | Iteration number: [270/565] 47% | Training loss: 0.6893448209321057
Epoch: 65 | Iteration number: [280/565] 49% | Training loss: 0.6892596006393432
Epoch: 65 | Iteration number: [290/565] 51% | Training loss: 0.6891780945761451
Epoch: 65 | Iteration number: [300/565] 53% | Training loss: 0.6890990167856217
Epoch: 65 | Iteration number: [310/565] 54% | Training loss: 0.6890259196681361
Epoch: 65 | Iteration number: [320/565] 56% | Training loss: 0.6889682944864035
Epoch: 65 | Iteration number: [330/565] 58% | Training loss: 0.6888950521295721
Epoch: 65 | Iteration number: [340/565] 60% | Training loss: 0.688845453192206
Epoch: 65 | Iteration number: [350/565] 61% | Training loss: 0.6887858719485147
Epoch: 65 | Iteration number: [360/565] 63% | Training loss: 0.6887356443537607
Epoch: 65 | Iteration number: [370/565] 65% | Training loss: 0.688669968617929
Epoch: 65 | Iteration number: [380/565] 67% | Training loss: 0.688626974977945
Epoch: 65 | Iteration number: [390/565] 69% | Training loss: 0.6885727750949371
Epoch: 65 | Iteration number: [400/565] 70% | Training loss: 0.6885298788547516
Epoch: 65 | Iteration number: [410/565] 72% | Training loss: 0.6884937309637302
Epoch: 65 | Iteration number: [420/565] 74% | Training loss: 0.6884546407631466
Epoch: 65 | Iteration number: [430/565] 76% | Training loss: 0.6884181615918181
Epoch: 65 | Iteration number: [440/565] 77% | Training loss: 0.6883830772204833
Epoch: 65 | Iteration number: [450/565] 79% | Training loss: 0.6883548063702053
Epoch: 65 | Iteration number: [460/565] 81% | Training loss: 0.6883218236591505
Epoch: 65 | Iteration number: [470/565] 83% | Training loss: 0.6882921620886376
Epoch: 65 | Iteration number: [480/565] 84% | Training loss: 0.6882628055910269
Epoch: 65 | Iteration number: [490/565] 86% | Training loss: 0.6882252201742055
Epoch: 65 | Iteration number: [500/565] 88% | Training loss: 0.6881931235790253
Epoch: 65 | Iteration number: [510/565] 90% | Training loss: 0.6881657644814136
Epoch: 65 | Iteration number: [520/565] 92% | Training loss: 0.6881429410897768
Epoch: 65 | Iteration number: [530/565] 93% | Training loss: 0.6881127431707562
Epoch: 65 | Iteration number: [540/565] 95% | Training loss: 0.688087883370894
Epoch: 65 | Iteration number: [550/565] 97% | Training loss: 0.6880698545412584
Epoch: 65 | Iteration number: [560/565] 99% | Training loss: 0.6880415268242359

 End of epoch: 65 | Train Loss: 0.6868108437124607 | Training Time: 89 

 End of epoch: 65 | Eval Loss: 0.6895475217274257 | Evaluating Time: 6 
Epoch: 66 | Iteration number: [10/565] 1% | Training loss: 0.7556168615818024
Epoch: 66 | Iteration number: [20/565] 3% | Training loss: 0.7212148159742355
Epoch: 66 | Iteration number: [30/565] 5% | Training loss: 0.7095882753531139
Epoch: 66 | Iteration number: [40/565] 7% | Training loss: 0.7039432287216186
Epoch: 66 | Iteration number: [50/565] 8% | Training loss: 0.7004701805114746
Epoch: 66 | Iteration number: [60/565] 10% | Training loss: 0.6982705732186635
Epoch: 66 | Iteration number: [70/565] 12% | Training loss: 0.6965928256511689
Epoch: 66 | Iteration number: [80/565] 14% | Training loss: 0.6953333206474781
Epoch: 66 | Iteration number: [90/565] 15% | Training loss: 0.6943705558776856
Epoch: 66 | Iteration number: [100/565] 17% | Training loss: 0.6936173385381699
Epoch: 66 | Iteration number: [110/565] 19% | Training loss: 0.6930172589692203
Epoch: 66 | Iteration number: [120/565] 21% | Training loss: 0.692505135635535
Epoch: 66 | Iteration number: [130/565] 23% | Training loss: 0.6920563032993904
Epoch: 66 | Iteration number: [140/565] 24% | Training loss: 0.6916596961872918
Epoch: 66 | Iteration number: [150/565] 26% | Training loss: 0.691347062587738
Epoch: 66 | Iteration number: [160/565] 28% | Training loss: 0.691067174449563
Epoch: 66 | Iteration number: [170/565] 30% | Training loss: 0.6908029103980345
Epoch: 66 | Iteration number: [180/565] 31% | Training loss: 0.6905882954597473
Epoch: 66 | Iteration number: [190/565] 33% | Training loss: 0.6904001195179789
Epoch: 66 | Iteration number: [200/565] 35% | Training loss: 0.6902084657549858
Epoch: 66 | Iteration number: [210/565] 37% | Training loss: 0.6900142212708791
Epoch: 66 | Iteration number: [220/565] 38% | Training loss: 0.6898622293363917
Epoch: 66 | Iteration number: [230/565] 40% | Training loss: 0.6897418302038442
Epoch: 66 | Iteration number: [240/565] 42% | Training loss: 0.6896187134087086
Epoch: 66 | Iteration number: [250/565] 44% | Training loss: 0.6895013942718505
Epoch: 66 | Iteration number: [260/565] 46% | Training loss: 0.6894106729672506
Epoch: 66 | Iteration number: [270/565] 47% | Training loss: 0.6893133357719139
Epoch: 66 | Iteration number: [280/565] 49% | Training loss: 0.6892191580363682
Epoch: 66 | Iteration number: [290/565] 51% | Training loss: 0.6891404819899591
Epoch: 66 | Iteration number: [300/565] 53% | Training loss: 0.6890553629398346
Epoch: 66 | Iteration number: [310/565] 54% | Training loss: 0.688992630089483
Epoch: 66 | Iteration number: [320/565] 56% | Training loss: 0.6889228409156203
Epoch: 66 | Iteration number: [330/565] 58% | Training loss: 0.6888623640392766
Epoch: 66 | Iteration number: [340/565] 60% | Training loss: 0.6887946113067515
Epoch: 66 | Iteration number: [350/565] 61% | Training loss: 0.6887397658824921
Epoch: 66 | Iteration number: [360/565] 63% | Training loss: 0.6886825439002778
Epoch: 66 | Iteration number: [370/565] 65% | Training loss: 0.6886408195302293
Epoch: 66 | Iteration number: [380/565] 67% | Training loss: 0.6885880567525563
Epoch: 66 | Iteration number: [390/565] 69% | Training loss: 0.6885402653461847
Epoch: 66 | Iteration number: [400/565] 70% | Training loss: 0.6885005389153958
Epoch: 66 | Iteration number: [410/565] 72% | Training loss: 0.6884588926303677
Epoch: 66 | Iteration number: [420/565] 74% | Training loss: 0.6884223769108454
Epoch: 66 | Iteration number: [430/565] 76% | Training loss: 0.6883907241876736
Epoch: 66 | Iteration number: [440/565] 77% | Training loss: 0.6883547613566572
Epoch: 66 | Iteration number: [450/565] 79% | Training loss: 0.6883139359951019
Epoch: 66 | Iteration number: [460/565] 81% | Training loss: 0.6882783651351929
Epoch: 66 | Iteration number: [470/565] 83% | Training loss: 0.6882523775100708
Epoch: 66 | Iteration number: [480/565] 84% | Training loss: 0.6882244278987248
Epoch: 66 | Iteration number: [490/565] 86% | Training loss: 0.6882005713423904
Epoch: 66 | Iteration number: [500/565] 88% | Training loss: 0.6881719409227371
Epoch: 66 | Iteration number: [510/565] 90% | Training loss: 0.6881521102260141
Epoch: 66 | Iteration number: [520/565] 92% | Training loss: 0.6881333934573027
Epoch: 66 | Iteration number: [530/565] 93% | Training loss: 0.6881084013659999
Epoch: 66 | Iteration number: [540/565] 95% | Training loss: 0.6880839991348761
Epoch: 66 | Iteration number: [550/565] 97% | Training loss: 0.6880556181344119
Epoch: 66 | Iteration number: [560/565] 99% | Training loss: 0.6880324747945581

 End of epoch: 66 | Train Loss: 0.6868090706588947 | Training Time: 88 

 End of epoch: 66 | Eval Loss: 0.6889895626476833 | Evaluating Time: 6 
Epoch: 67 | Iteration number: [10/565] 1% | Training loss: 0.7555648744106293
Epoch: 67 | Iteration number: [20/565] 3% | Training loss: 0.7211033314466476
Epoch: 67 | Iteration number: [30/565] 5% | Training loss: 0.709727942943573
Epoch: 67 | Iteration number: [40/565] 7% | Training loss: 0.7040103301405907
Epoch: 67 | Iteration number: [50/565] 8% | Training loss: 0.7005510997772216
Epoch: 67 | Iteration number: [60/565] 10% | Training loss: 0.6981672366460164
Epoch: 67 | Iteration number: [70/565] 12% | Training loss: 0.6965520935399192
Epoch: 67 | Iteration number: [80/565] 14% | Training loss: 0.6953562684357166
Epoch: 67 | Iteration number: [90/565] 15% | Training loss: 0.6943835298220317
Epoch: 67 | Iteration number: [100/565] 17% | Training loss: 0.6936190527677536
Epoch: 67 | Iteration number: [110/565] 19% | Training loss: 0.6930399818853898
Epoch: 67 | Iteration number: [120/565] 21% | Training loss: 0.6925463169813156
Epoch: 67 | Iteration number: [130/565] 23% | Training loss: 0.6920838731985826
Epoch: 67 | Iteration number: [140/565] 24% | Training loss: 0.6916955901043755
Epoch: 67 | Iteration number: [150/565] 26% | Training loss: 0.6913371968269348
Epoch: 67 | Iteration number: [160/565] 28% | Training loss: 0.6910495191812516
Epoch: 67 | Iteration number: [170/565] 30% | Training loss: 0.6907910413601819
Epoch: 67 | Iteration number: [180/565] 31% | Training loss: 0.6905942976474762
Epoch: 67 | Iteration number: [190/565] 33% | Training loss: 0.6904057088651155
Epoch: 67 | Iteration number: [200/565] 35% | Training loss: 0.6902188056707382
Epoch: 67 | Iteration number: [210/565] 37% | Training loss: 0.6900552823430016
Epoch: 67 | Iteration number: [220/565] 38% | Training loss: 0.6899267643690109
Epoch: 67 | Iteration number: [230/565] 40% | Training loss: 0.6897773447244063
Epoch: 67 | Iteration number: [240/565] 42% | Training loss: 0.6896798603236676
Epoch: 67 | Iteration number: [250/565] 44% | Training loss: 0.6895534901618957
Epoch: 67 | Iteration number: [260/565] 46% | Training loss: 0.6894403207760591
Epoch: 67 | Iteration number: [270/565] 47% | Training loss: 0.6893491583841819
Epoch: 67 | Iteration number: [280/565] 49% | Training loss: 0.6892632382256644
Epoch: 67 | Iteration number: [290/565] 51% | Training loss: 0.6891790741476519
Epoch: 67 | Iteration number: [300/565] 53% | Training loss: 0.6891020921866099
Epoch: 67 | Iteration number: [310/565] 54% | Training loss: 0.6890289681573067
Epoch: 67 | Iteration number: [320/565] 56% | Training loss: 0.6889615043997764
Epoch: 67 | Iteration number: [330/565] 58% | Training loss: 0.6889041237758867
Epoch: 67 | Iteration number: [340/565] 60% | Training loss: 0.6888478400076137
Epoch: 67 | Iteration number: [350/565] 61% | Training loss: 0.6887854797499521
Epoch: 67 | Iteration number: [360/565] 63% | Training loss: 0.68873782902956
Epoch: 67 | Iteration number: [370/565] 65% | Training loss: 0.6886864069345835
Epoch: 67 | Iteration number: [380/565] 67% | Training loss: 0.6886341827480417
Epoch: 67 | Iteration number: [390/565] 69% | Training loss: 0.6885804350559528
Epoch: 67 | Iteration number: [400/565] 70% | Training loss: 0.6885281537473201
Epoch: 67 | Iteration number: [410/565] 72% | Training loss: 0.6884826806987204
Epoch: 67 | Iteration number: [420/565] 74% | Training loss: 0.6884480168422064
Epoch: 67 | Iteration number: [430/565] 76% | Training loss: 0.6884070576623429
Epoch: 67 | Iteration number: [440/565] 77% | Training loss: 0.68838585506786
Epoch: 67 | Iteration number: [450/565] 79% | Training loss: 0.6883404246966044
Epoch: 67 | Iteration number: [460/565] 81% | Training loss: 0.6883068623750106
Epoch: 67 | Iteration number: [470/565] 83% | Training loss: 0.6882723507728983
Epoch: 67 | Iteration number: [480/565] 84% | Training loss: 0.6882418675969044
Epoch: 67 | Iteration number: [490/565] 86% | Training loss: 0.6882146886416844
Epoch: 67 | Iteration number: [500/565] 88% | Training loss: 0.6881838408708573
Epoch: 67 | Iteration number: [510/565] 90% | Training loss: 0.6881504924858317
Epoch: 67 | Iteration number: [520/565] 92% | Training loss: 0.6881215288088872
Epoch: 67 | Iteration number: [530/565] 93% | Training loss: 0.6881021483889166
Epoch: 67 | Iteration number: [540/565] 95% | Training loss: 0.6880680531263351
Epoch: 67 | Iteration number: [550/565] 97% | Training loss: 0.6880418200926347
Epoch: 67 | Iteration number: [560/565] 99% | Training loss: 0.688023598172835

 End of epoch: 67 | Train Loss: 0.6867944286987845 | Training Time: 89 

 End of epoch: 67 | Eval Loss: 0.6892159836632865 | Evaluating Time: 5 
Epoch: 68 | Iteration number: [10/565] 1% | Training loss: 0.7549866378307343
Epoch: 68 | Iteration number: [20/565] 3% | Training loss: 0.720876207947731
Epoch: 68 | Iteration number: [30/565] 5% | Training loss: 0.709408438205719
Epoch: 68 | Iteration number: [40/565] 7% | Training loss: 0.7037666320800782
Epoch: 68 | Iteration number: [50/565] 8% | Training loss: 0.7003024780750274
Epoch: 68 | Iteration number: [60/565] 10% | Training loss: 0.6980578611294429
Epoch: 68 | Iteration number: [70/565] 12% | Training loss: 0.6964746900967189
Epoch: 68 | Iteration number: [80/565] 14% | Training loss: 0.6952785357832909
Epoch: 68 | Iteration number: [90/565] 15% | Training loss: 0.6943846656216516
Epoch: 68 | Iteration number: [100/565] 17% | Training loss: 0.6936245810985565
Epoch: 68 | Iteration number: [110/565] 19% | Training loss: 0.6930115921930833
Epoch: 68 | Iteration number: [120/565] 21% | Training loss: 0.6924997766812643
Epoch: 68 | Iteration number: [130/565] 23% | Training loss: 0.692038807960657
Epoch: 68 | Iteration number: [140/565] 24% | Training loss: 0.6916545020682471
Epoch: 68 | Iteration number: [150/565] 26% | Training loss: 0.6913160530726115
Epoch: 68 | Iteration number: [160/565] 28% | Training loss: 0.6910371519625187
Epoch: 68 | Iteration number: [170/565] 30% | Training loss: 0.6907926135203417
Epoch: 68 | Iteration number: [180/565] 31% | Training loss: 0.6905661596192254
Epoch: 68 | Iteration number: [190/565] 33% | Training loss: 0.6903859678067659
Epoch: 68 | Iteration number: [200/565] 35% | Training loss: 0.6902127221226693
Epoch: 68 | Iteration number: [210/565] 37% | Training loss: 0.6900342802206675
Epoch: 68 | Iteration number: [220/565] 38% | Training loss: 0.6899003616788171
Epoch: 68 | Iteration number: [230/565] 40% | Training loss: 0.6897756724253945
Epoch: 68 | Iteration number: [240/565] 42% | Training loss: 0.6896459067861239
Epoch: 68 | Iteration number: [250/565] 44% | Training loss: 0.6895394506454467
Epoch: 68 | Iteration number: [260/565] 46% | Training loss: 0.6894298104139475
Epoch: 68 | Iteration number: [270/565] 47% | Training loss: 0.6893243125191442
Epoch: 68 | Iteration number: [280/565] 49% | Training loss: 0.6892148124320167
Epoch: 68 | Iteration number: [290/565] 51% | Training loss: 0.689128208571467
Epoch: 68 | Iteration number: [300/565] 53% | Training loss: 0.689033334851265
Epoch: 68 | Iteration number: [310/565] 54% | Training loss: 0.6889652017624147
Epoch: 68 | Iteration number: [320/565] 56% | Training loss: 0.68888418097049
Epoch: 68 | Iteration number: [330/565] 58% | Training loss: 0.6888114929199218
Epoch: 68 | Iteration number: [340/565] 60% | Training loss: 0.6887480947901221
Epoch: 68 | Iteration number: [350/565] 61% | Training loss: 0.6886907725674766
Epoch: 68 | Iteration number: [360/565] 63% | Training loss: 0.6886451949675878
Epoch: 68 | Iteration number: [370/565] 65% | Training loss: 0.6885973411637384
Epoch: 68 | Iteration number: [380/565] 67% | Training loss: 0.688551558789454
Epoch: 68 | Iteration number: [390/565] 69% | Training loss: 0.6885136408683581
Epoch: 68 | Iteration number: [400/565] 70% | Training loss: 0.6884812372922897
Epoch: 68 | Iteration number: [410/565] 72% | Training loss: 0.6884438020427053
Epoch: 68 | Iteration number: [420/565] 74% | Training loss: 0.6884077239604224
Epoch: 68 | Iteration number: [430/565] 76% | Training loss: 0.6883710563182831
Epoch: 68 | Iteration number: [440/565] 77% | Training loss: 0.6883439555764198
Epoch: 68 | Iteration number: [450/565] 79% | Training loss: 0.6883095475037893
Epoch: 68 | Iteration number: [460/565] 81% | Training loss: 0.6882786575866782
Epoch: 68 | Iteration number: [470/565] 83% | Training loss: 0.6882440785144238
Epoch: 68 | Iteration number: [480/565] 84% | Training loss: 0.6882117585589488
Epoch: 68 | Iteration number: [490/565] 86% | Training loss: 0.688187403216654
Epoch: 68 | Iteration number: [500/565] 88% | Training loss: 0.6881607192754745
Epoch: 68 | Iteration number: [510/565] 90% | Training loss: 0.6881350135101991
Epoch: 68 | Iteration number: [520/565] 92% | Training loss: 0.6881128817796707
Epoch: 68 | Iteration number: [530/565] 93% | Training loss: 0.6880888775834497
Epoch: 68 | Iteration number: [540/565] 95% | Training loss: 0.6880670482361758
Epoch: 68 | Iteration number: [550/565] 97% | Training loss: 0.6880333751981909
Epoch: 68 | Iteration number: [560/565] 99% | Training loss: 0.6880146495997905

 End of epoch: 68 | Train Loss: 0.6867940340421896 | Training Time: 88 

 End of epoch: 68 | Eval Loss: 0.6891429168837411 | Evaluating Time: 6 
Epoch: 69 | Iteration number: [10/565] 1% | Training loss: 0.7555870592594147
Epoch: 69 | Iteration number: [20/565] 3% | Training loss: 0.7211593300104141
Epoch: 69 | Iteration number: [30/565] 5% | Training loss: 0.7097331464290619
Epoch: 69 | Iteration number: [40/565] 7% | Training loss: 0.7038837462663651
Epoch: 69 | Iteration number: [50/565] 8% | Training loss: 0.700555624961853
Epoch: 69 | Iteration number: [60/565] 10% | Training loss: 0.6982594758272171
Epoch: 69 | Iteration number: [70/565] 12% | Training loss: 0.6966513437884194
Epoch: 69 | Iteration number: [80/565] 14% | Training loss: 0.6954335257411003
Epoch: 69 | Iteration number: [90/565] 15% | Training loss: 0.6944800615310669
Epoch: 69 | Iteration number: [100/565] 17% | Training loss: 0.693750468492508
Epoch: 69 | Iteration number: [110/565] 19% | Training loss: 0.6931129152124579
Epoch: 69 | Iteration number: [120/565] 21% | Training loss: 0.6926240767041842
Epoch: 69 | Iteration number: [130/565] 23% | Training loss: 0.6921955681764163
Epoch: 69 | Iteration number: [140/565] 24% | Training loss: 0.6917861001832145
Epoch: 69 | Iteration number: [150/565] 26% | Training loss: 0.6914430709679922
Epoch: 69 | Iteration number: [160/565] 28% | Training loss: 0.6911541979759932
Epoch: 69 | Iteration number: [170/565] 30% | Training loss: 0.6908637516638811
Epoch: 69 | Iteration number: [180/565] 31% | Training loss: 0.6906505435705185
Epoch: 69 | Iteration number: [190/565] 33% | Training loss: 0.690415844791814
Epoch: 69 | Iteration number: [200/565] 35% | Training loss: 0.690231776535511
Epoch: 69 | Iteration number: [210/565] 37% | Training loss: 0.6900736317748115
Epoch: 69 | Iteration number: [220/565] 38% | Training loss: 0.6899159455841238
Epoch: 69 | Iteration number: [230/565] 40% | Training loss: 0.6897771752398947
Epoch: 69 | Iteration number: [240/565] 42% | Training loss: 0.6896638227005799
Epoch: 69 | Iteration number: [250/565] 44% | Training loss: 0.6895742943286896
Epoch: 69 | Iteration number: [260/565] 46% | Training loss: 0.6894748077942775
Epoch: 69 | Iteration number: [270/565] 47% | Training loss: 0.6893659158989235
Epoch: 69 | Iteration number: [280/565] 49% | Training loss: 0.6892554983496666
Epoch: 69 | Iteration number: [290/565] 51% | Training loss: 0.6891815391080133
Epoch: 69 | Iteration number: [300/565] 53% | Training loss: 0.6890909806887309
Epoch: 69 | Iteration number: [310/565] 54% | Training loss: 0.6890100794453775
Epoch: 69 | Iteration number: [320/565] 56% | Training loss: 0.6889232208952307
Epoch: 69 | Iteration number: [330/565] 58% | Training loss: 0.688873060724952
Epoch: 69 | Iteration number: [340/565] 60% | Training loss: 0.6888232674668817
Epoch: 69 | Iteration number: [350/565] 61% | Training loss: 0.6887819319111961
Epoch: 69 | Iteration number: [360/565] 63% | Training loss: 0.6887226606408755
Epoch: 69 | Iteration number: [370/565] 65% | Training loss: 0.6886804224671544
Epoch: 69 | Iteration number: [380/565] 67% | Training loss: 0.6886285941851766
Epoch: 69 | Iteration number: [390/565] 69% | Training loss: 0.6885839373637468
Epoch: 69 | Iteration number: [400/565] 70% | Training loss: 0.6885304619371891
Epoch: 69 | Iteration number: [410/565] 72% | Training loss: 0.6884807810550783
Epoch: 69 | Iteration number: [420/565] 74% | Training loss: 0.6884362348488399
Epoch: 69 | Iteration number: [430/565] 76% | Training loss: 0.6883913271648939
Epoch: 69 | Iteration number: [440/565] 77% | Training loss: 0.6883596343072977
Epoch: 69 | Iteration number: [450/565] 79% | Training loss: 0.6883270707395341
Epoch: 69 | Iteration number: [460/565] 81% | Training loss: 0.6883025682490805
Epoch: 69 | Iteration number: [470/565] 83% | Training loss: 0.688277149707713
Epoch: 69 | Iteration number: [480/565] 84% | Training loss: 0.6882493857294321
Epoch: 69 | Iteration number: [490/565] 86% | Training loss: 0.6882252129973198
Epoch: 69 | Iteration number: [500/565] 88% | Training loss: 0.6881993339061737
Epoch: 69 | Iteration number: [510/565] 90% | Training loss: 0.6881735634570029
Epoch: 69 | Iteration number: [520/565] 92% | Training loss: 0.6881343699418582
Epoch: 69 | Iteration number: [530/565] 93% | Training loss: 0.6881134288490943
Epoch: 69 | Iteration number: [540/565] 95% | Training loss: 0.6880872556456813
Epoch: 69 | Iteration number: [550/565] 97% | Training loss: 0.688053955598311
Epoch: 69 | Iteration number: [560/565] 99% | Training loss: 0.6880218901804516

 End of epoch: 69 | Train Loss: 0.6867928409998396 | Training Time: 89 

 End of epoch: 69 | Eval Loss: 0.6894857798303876 | Evaluating Time: 6 
Epoch: 70 | Iteration number: [10/565] 1% | Training loss: 0.7552024364471436
Epoch: 70 | Iteration number: [20/565] 3% | Training loss: 0.7210132360458374
Epoch: 70 | Iteration number: [30/565] 5% | Training loss: 0.709600176413854
Epoch: 70 | Iteration number: [40/565] 7% | Training loss: 0.7039001539349556
Epoch: 70 | Iteration number: [50/565] 8% | Training loss: 0.7004960405826569
Epoch: 70 | Iteration number: [60/565] 10% | Training loss: 0.6981553256511688
Epoch: 70 | Iteration number: [70/565] 12% | Training loss: 0.6965197588716234
Epoch: 70 | Iteration number: [80/565] 14% | Training loss: 0.6952713005244732
Epoch: 70 | Iteration number: [90/565] 15% | Training loss: 0.6943793488873375
Epoch: 70 | Iteration number: [100/565] 17% | Training loss: 0.6936383682489395
Epoch: 70 | Iteration number: [110/565] 19% | Training loss: 0.6930257683450526
Epoch: 70 | Iteration number: [120/565] 21% | Training loss: 0.6924683585762977
Epoch: 70 | Iteration number: [130/565] 23% | Training loss: 0.6920245574070857
Epoch: 70 | Iteration number: [140/565] 24% | Training loss: 0.6916421413421631
Epoch: 70 | Iteration number: [150/565] 26% | Training loss: 0.6913111555576325
Epoch: 70 | Iteration number: [160/565] 28% | Training loss: 0.6910246726125479
Epoch: 70 | Iteration number: [170/565] 30% | Training loss: 0.6907773000352523
Epoch: 70 | Iteration number: [180/565] 31% | Training loss: 0.6905403554439544
Epoch: 70 | Iteration number: [190/565] 33% | Training loss: 0.690350719188389
Epoch: 70 | Iteration number: [200/565] 35% | Training loss: 0.6901494699716568
Epoch: 70 | Iteration number: [210/565] 37% | Training loss: 0.6899974771908352
Epoch: 70 | Iteration number: [220/565] 38% | Training loss: 0.6898736533793536
Epoch: 70 | Iteration number: [230/565] 40% | Training loss: 0.6897397373033607
Epoch: 70 | Iteration number: [240/565] 42% | Training loss: 0.6895963748296102
Epoch: 70 | Iteration number: [250/565] 44% | Training loss: 0.6894987788200378
Epoch: 70 | Iteration number: [260/565] 46% | Training loss: 0.6893951899730242
Epoch: 70 | Iteration number: [270/565] 47% | Training loss: 0.6892779816080022
Epoch: 70 | Iteration number: [280/565] 49% | Training loss: 0.6892053614769663
Epoch: 70 | Iteration number: [290/565] 51% | Training loss: 0.6891104578971863
Epoch: 70 | Iteration number: [300/565] 53% | Training loss: 0.6890414977073669
Epoch: 70 | Iteration number: [310/565] 54% | Training loss: 0.6889630210015082
Epoch: 70 | Iteration number: [320/565] 56% | Training loss: 0.6888967690989375
Epoch: 70 | Iteration number: [330/565] 58% | Training loss: 0.6888296432567366
Epoch: 70 | Iteration number: [340/565] 60% | Training loss: 0.6887773063252954
Epoch: 70 | Iteration number: [350/565] 61% | Training loss: 0.6887173339298793
Epoch: 70 | Iteration number: [360/565] 63% | Training loss: 0.6886680515276061
Epoch: 70 | Iteration number: [370/565] 65% | Training loss: 0.6886295724559475
Epoch: 70 | Iteration number: [380/565] 67% | Training loss: 0.6885917978851419
Epoch: 70 | Iteration number: [390/565] 69% | Training loss: 0.6885364558452215
Epoch: 70 | Iteration number: [400/565] 70% | Training loss: 0.6884962923824787
Epoch: 70 | Iteration number: [410/565] 72% | Training loss: 0.6884514240230002
Epoch: 70 | Iteration number: [420/565] 74% | Training loss: 0.6884188274542491
Epoch: 70 | Iteration number: [430/565] 76% | Training loss: 0.6883777769499047
Epoch: 70 | Iteration number: [440/565] 77% | Training loss: 0.6883404216983101
Epoch: 70 | Iteration number: [450/565] 79% | Training loss: 0.6883068022463057
Epoch: 70 | Iteration number: [460/565] 81% | Training loss: 0.6882707209690757
Epoch: 70 | Iteration number: [470/565] 83% | Training loss: 0.6882412593415443
Epoch: 70 | Iteration number: [480/565] 84% | Training loss: 0.6882135593642791
Epoch: 70 | Iteration number: [490/565] 86% | Training loss: 0.6881869676161786
Epoch: 70 | Iteration number: [500/565] 88% | Training loss: 0.6881558231115341
Epoch: 70 | Iteration number: [510/565] 90% | Training loss: 0.688128110591103
Epoch: 70 | Iteration number: [520/565] 92% | Training loss: 0.6881048035163145
Epoch: 70 | Iteration number: [530/565] 93% | Training loss: 0.6880815612819959
Epoch: 70 | Iteration number: [540/565] 95% | Training loss: 0.6880674742990069
Epoch: 70 | Iteration number: [550/565] 97% | Training loss: 0.688038018508391
Epoch: 70 | Iteration number: [560/565] 99% | Training loss: 0.6880129766251359

 End of epoch: 70 | Train Loss: 0.6867881383516092 | Training Time: 90 

 End of epoch: 70 | Eval Loss: 0.6886765445981707 | Evaluating Time: 6 
Epoch: 71 | Iteration number: [10/565] 1% | Training loss: 0.7554576098918915
Epoch: 71 | Iteration number: [20/565] 3% | Training loss: 0.7210250824689866
Epoch: 71 | Iteration number: [30/565] 5% | Training loss: 0.709716010093689
Epoch: 71 | Iteration number: [40/565] 7% | Training loss: 0.7039938852190971
Epoch: 71 | Iteration number: [50/565] 8% | Training loss: 0.7005267894268036
Epoch: 71 | Iteration number: [60/565] 10% | Training loss: 0.6982234011093775
Epoch: 71 | Iteration number: [70/565] 12% | Training loss: 0.6966024628707341
Epoch: 71 | Iteration number: [80/565] 14% | Training loss: 0.6954026810824872
Epoch: 71 | Iteration number: [90/565] 15% | Training loss: 0.6944855074087779
Epoch: 71 | Iteration number: [100/565] 17% | Training loss: 0.6937398207187653
Epoch: 71 | Iteration number: [110/565] 19% | Training loss: 0.693121874332428
Epoch: 71 | Iteration number: [120/565] 21% | Training loss: 0.6925836155811945
Epoch: 71 | Iteration number: [130/565] 23% | Training loss: 0.69214290197079
Epoch: 71 | Iteration number: [140/565] 24% | Training loss: 0.6917504612888609
Epoch: 71 | Iteration number: [150/565] 26% | Training loss: 0.6914597829182942
Epoch: 71 | Iteration number: [160/565] 28% | Training loss: 0.6911690596491098
Epoch: 71 | Iteration number: [170/565] 30% | Training loss: 0.6909182169858147
Epoch: 71 | Iteration number: [180/565] 31% | Training loss: 0.6906831254561742
Epoch: 71 | Iteration number: [190/565] 33% | Training loss: 0.6904586120655662
Epoch: 71 | Iteration number: [200/565] 35% | Training loss: 0.6902927699685096
Epoch: 71 | Iteration number: [210/565] 37% | Training loss: 0.6901048702853066
Epoch: 71 | Iteration number: [220/565] 38% | Training loss: 0.6899488281119953
Epoch: 71 | Iteration number: [230/565] 40% | Training loss: 0.6898233032744864
Epoch: 71 | Iteration number: [240/565] 42% | Training loss: 0.6896898080905278
Epoch: 71 | Iteration number: [250/565] 44% | Training loss: 0.6895757555961609
Epoch: 71 | Iteration number: [260/565] 46% | Training loss: 0.6894740659456987
Epoch: 71 | Iteration number: [270/565] 47% | Training loss: 0.6893864519066281
Epoch: 71 | Iteration number: [280/565] 49% | Training loss: 0.6892974989754813
Epoch: 71 | Iteration number: [290/565] 51% | Training loss: 0.6892109028224287
Epoch: 71 | Iteration number: [300/565] 53% | Training loss: 0.6891099979480108
Epoch: 71 | Iteration number: [310/565] 54% | Training loss: 0.6890321177821006
Epoch: 71 | Iteration number: [320/565] 56% | Training loss: 0.688966334797442
Epoch: 71 | Iteration number: [330/565] 58% | Training loss: 0.688897996599024
Epoch: 71 | Iteration number: [340/565] 60% | Training loss: 0.6888441588948755
Epoch: 71 | Iteration number: [350/565] 61% | Training loss: 0.6887736087185996
Epoch: 71 | Iteration number: [360/565] 63% | Training loss: 0.6887116432189941
Epoch: 71 | Iteration number: [370/565] 65% | Training loss: 0.688656259388537
Epoch: 71 | Iteration number: [380/565] 67% | Training loss: 0.6886060479440187
Epoch: 71 | Iteration number: [390/565] 69% | Training loss: 0.6885605621032226
Epoch: 71 | Iteration number: [400/565] 70% | Training loss: 0.688524043560028
Epoch: 71 | Iteration number: [410/565] 72% | Training loss: 0.6884718429751513
Epoch: 71 | Iteration number: [420/565] 74% | Training loss: 0.6884405496574584
Epoch: 71 | Iteration number: [430/565] 76% | Training loss: 0.6884024247180583
Epoch: 71 | Iteration number: [440/565] 77% | Training loss: 0.6883718799461018
Epoch: 71 | Iteration number: [450/565] 79% | Training loss: 0.6883407273557451
Epoch: 71 | Iteration number: [460/565] 81% | Training loss: 0.6883041133051333
Epoch: 71 | Iteration number: [470/565] 83% | Training loss: 0.6882728023731962
Epoch: 71 | Iteration number: [480/565] 84% | Training loss: 0.6882326933244864
Epoch: 71 | Iteration number: [490/565] 86% | Training loss: 0.6882059932971487
Epoch: 71 | Iteration number: [500/565] 88% | Training loss: 0.6881706362962723
Epoch: 71 | Iteration number: [510/565] 90% | Training loss: 0.6881455960226994
Epoch: 71 | Iteration number: [520/565] 92% | Training loss: 0.6881319468984237
Epoch: 71 | Iteration number: [530/565] 93% | Training loss: 0.6881044617239035
Epoch: 71 | Iteration number: [540/565] 95% | Training loss: 0.688076964462245
Epoch: 71 | Iteration number: [550/565] 97% | Training loss: 0.6880474315990102
Epoch: 71 | Iteration number: [560/565] 99% | Training loss: 0.6880248820143087

 End of epoch: 71 | Train Loss: 0.6867968111966564 | Training Time: 88 

 End of epoch: 71 | Eval Loss: 0.6889574698039463 | Evaluating Time: 6 
Epoch: 72 | Iteration number: [10/565] 1% | Training loss: 0.7558264136314392
Epoch: 72 | Iteration number: [20/565] 3% | Training loss: 0.721155098080635
Epoch: 72 | Iteration number: [30/565] 5% | Training loss: 0.7095218400160471
Epoch: 72 | Iteration number: [40/565] 7% | Training loss: 0.7038336262106896
Epoch: 72 | Iteration number: [50/565] 8% | Training loss: 0.7003549885749817
Epoch: 72 | Iteration number: [60/565] 10% | Training loss: 0.6980841517448425
Epoch: 72 | Iteration number: [70/565] 12% | Training loss: 0.6964591230664935
Epoch: 72 | Iteration number: [80/565] 14% | Training loss: 0.6952404454350471
Epoch: 72 | Iteration number: [90/565] 15% | Training loss: 0.6943261729346382
Epoch: 72 | Iteration number: [100/565] 17% | Training loss: 0.6935473597049713
Epoch: 72 | Iteration number: [110/565] 19% | Training loss: 0.6929506822065874
Epoch: 72 | Iteration number: [120/565] 21% | Training loss: 0.6924174929658572
Epoch: 72 | Iteration number: [130/565] 23% | Training loss: 0.6920051904825064
Epoch: 72 | Iteration number: [140/565] 24% | Training loss: 0.6916263661214284
Epoch: 72 | Iteration number: [150/565] 26% | Training loss: 0.6913273052374522
Epoch: 72 | Iteration number: [160/565] 28% | Training loss: 0.6910492952913045
Epoch: 72 | Iteration number: [170/565] 30% | Training loss: 0.6907684312147253
Epoch: 72 | Iteration number: [180/565] 31% | Training loss: 0.6905176526970334
Epoch: 72 | Iteration number: [190/565] 33% | Training loss: 0.6903319107858759
Epoch: 72 | Iteration number: [200/565] 35% | Training loss: 0.6901716470718384
Epoch: 72 | Iteration number: [210/565] 37% | Training loss: 0.6900003677322751
Epoch: 72 | Iteration number: [220/565] 38% | Training loss: 0.6898675634102388
Epoch: 72 | Iteration number: [230/565] 40% | Training loss: 0.6897394247677016
Epoch: 72 | Iteration number: [240/565] 42% | Training loss: 0.6896154108146827
Epoch: 72 | Iteration number: [250/565] 44% | Training loss: 0.6895005826950074
Epoch: 72 | Iteration number: [260/565] 46% | Training loss: 0.6893998146057129
Epoch: 72 | Iteration number: [270/565] 47% | Training loss: 0.6893048734576613
Epoch: 72 | Iteration number: [280/565] 49% | Training loss: 0.6892169369118554
Epoch: 72 | Iteration number: [290/565] 51% | Training loss: 0.6891305397296774
Epoch: 72 | Iteration number: [300/565] 53% | Training loss: 0.6890621993939082
Epoch: 72 | Iteration number: [310/565] 54% | Training loss: 0.6889900603602009
Epoch: 72 | Iteration number: [320/565] 56% | Training loss: 0.6889200845733285
Epoch: 72 | Iteration number: [330/565] 58% | Training loss: 0.6888631641864776
Epoch: 72 | Iteration number: [340/565] 60% | Training loss: 0.6888070565812728
Epoch: 72 | Iteration number: [350/565] 61% | Training loss: 0.688731107371194
Epoch: 72 | Iteration number: [360/565] 63% | Training loss: 0.6886758499675327
Epoch: 72 | Iteration number: [370/565] 65% | Training loss: 0.6886277925323796
Epoch: 72 | Iteration number: [380/565] 67% | Training loss: 0.6885798807206907
Epoch: 72 | Iteration number: [390/565] 69% | Training loss: 0.6885465206244052
Epoch: 72 | Iteration number: [400/565] 70% | Training loss: 0.6885009232163429
Epoch: 72 | Iteration number: [410/565] 72% | Training loss: 0.688458611470897
Epoch: 72 | Iteration number: [420/565] 74% | Training loss: 0.6884152305977685
Epoch: 72 | Iteration number: [430/565] 76% | Training loss: 0.6883833154689434
Epoch: 72 | Iteration number: [440/565] 77% | Training loss: 0.6883487674322996
Epoch: 72 | Iteration number: [450/565] 79% | Training loss: 0.6883248019218445
Epoch: 72 | Iteration number: [460/565] 81% | Training loss: 0.6882905389951623
Epoch: 72 | Iteration number: [470/565] 83% | Training loss: 0.6882589500001136
Epoch: 72 | Iteration number: [480/565] 84% | Training loss: 0.6882271837443114
Epoch: 72 | Iteration number: [490/565] 86% | Training loss: 0.6882006650068322
Epoch: 72 | Iteration number: [500/565] 88% | Training loss: 0.6881806489229202
Epoch: 72 | Iteration number: [510/565] 90% | Training loss: 0.6881596992997562
Epoch: 72 | Iteration number: [520/565] 92% | Training loss: 0.6881291666856179
Epoch: 72 | Iteration number: [530/565] 93% | Training loss: 0.6881060869063971
Epoch: 72 | Iteration number: [540/565] 95% | Training loss: 0.6880754263312728
Epoch: 72 | Iteration number: [550/565] 97% | Training loss: 0.6880550473386591
Epoch: 72 | Iteration number: [560/565] 99% | Training loss: 0.6880287408828736

 End of epoch: 72 | Train Loss: 0.686805701888768 | Training Time: 89 

 End of epoch: 72 | Eval Loss: 0.6893035684313092 | Evaluating Time: 5 
Epoch: 73 | Iteration number: [10/565] 1% | Training loss: 0.7551515817642211
Epoch: 73 | Iteration number: [20/565] 3% | Training loss: 0.7208781182765961
Epoch: 73 | Iteration number: [30/565] 5% | Training loss: 0.7095609565575918
Epoch: 73 | Iteration number: [40/565] 7% | Training loss: 0.7038231700658798
Epoch: 73 | Iteration number: [50/565] 8% | Training loss: 0.7004649698734283
Epoch: 73 | Iteration number: [60/565] 10% | Training loss: 0.6981370468934377
Epoch: 73 | Iteration number: [70/565] 12% | Training loss: 0.6964648944990975
Epoch: 73 | Iteration number: [80/565] 14% | Training loss: 0.6952794387936592
Epoch: 73 | Iteration number: [90/565] 15% | Training loss: 0.6943890511989593
Epoch: 73 | Iteration number: [100/565] 17% | Training loss: 0.6936055147647857
Epoch: 73 | Iteration number: [110/565] 19% | Training loss: 0.693034107576717
Epoch: 73 | Iteration number: [120/565] 21% | Training loss: 0.6925657530625661
Epoch: 73 | Iteration number: [130/565] 23% | Training loss: 0.692143027140544
Epoch: 73 | Iteration number: [140/565] 24% | Training loss: 0.6917152685778482
Epoch: 73 | Iteration number: [150/565] 26% | Training loss: 0.6913737865289052
Epoch: 73 | Iteration number: [160/565] 28% | Training loss: 0.6911044407635927
Epoch: 73 | Iteration number: [170/565] 30% | Training loss: 0.6908737845280591
Epoch: 73 | Iteration number: [180/565] 31% | Training loss: 0.6906416058540344
Epoch: 73 | Iteration number: [190/565] 33% | Training loss: 0.6904569867410157
Epoch: 73 | Iteration number: [200/565] 35% | Training loss: 0.6902737182378769
Epoch: 73 | Iteration number: [210/565] 37% | Training loss: 0.6900955350626082
Epoch: 73 | Iteration number: [220/565] 38% | Training loss: 0.689947523041205
Epoch: 73 | Iteration number: [230/565] 40% | Training loss: 0.689813761866611
Epoch: 73 | Iteration number: [240/565] 42% | Training loss: 0.6896899119019508
Epoch: 73 | Iteration number: [250/565] 44% | Training loss: 0.689565809249878
Epoch: 73 | Iteration number: [260/565] 46% | Training loss: 0.6894419152003068
Epoch: 73 | Iteration number: [270/565] 47% | Training loss: 0.6893320328659481
Epoch: 73 | Iteration number: [280/565] 49% | Training loss: 0.689234302512237
Epoch: 73 | Iteration number: [290/565] 51% | Training loss: 0.6891547603853818
Epoch: 73 | Iteration number: [300/565] 53% | Training loss: 0.6890690884987514
Epoch: 73 | Iteration number: [310/565] 54% | Training loss: 0.6890152777394941
Epoch: 73 | Iteration number: [320/565] 56% | Training loss: 0.6889542488381266
Epoch: 73 | Iteration number: [330/565] 58% | Training loss: 0.6888809910326293
Epoch: 73 | Iteration number: [340/565] 60% | Training loss: 0.6888202975778018
Epoch: 73 | Iteration number: [350/565] 61% | Training loss: 0.688766987323761
Epoch: 73 | Iteration number: [360/565] 63% | Training loss: 0.6887150986327065
Epoch: 73 | Iteration number: [370/565] 65% | Training loss: 0.6886587948412508
Epoch: 73 | Iteration number: [380/565] 67% | Training loss: 0.688605514482448
Epoch: 73 | Iteration number: [390/565] 69% | Training loss: 0.6885631214349698
Epoch: 73 | Iteration number: [400/565] 70% | Training loss: 0.6885216242074966
Epoch: 73 | Iteration number: [410/565] 72% | Training loss: 0.6884730619628255
Epoch: 73 | Iteration number: [420/565] 74% | Training loss: 0.6884328444798787
Epoch: 73 | Iteration number: [430/565] 76% | Training loss: 0.688387942036917
Epoch: 73 | Iteration number: [440/565] 77% | Training loss: 0.6883553015914831
Epoch: 73 | Iteration number: [450/565] 79% | Training loss: 0.6883155079682668
Epoch: 73 | Iteration number: [460/565] 81% | Training loss: 0.6882854939802833
Epoch: 73 | Iteration number: [470/565] 83% | Training loss: 0.6882536109457624
Epoch: 73 | Iteration number: [480/565] 84% | Training loss: 0.6882246643304825
Epoch: 73 | Iteration number: [490/565] 86% | Training loss: 0.6881894094603402
Epoch: 73 | Iteration number: [500/565] 88% | Training loss: 0.688164021730423
Epoch: 73 | Iteration number: [510/565] 90% | Training loss: 0.6881312072277069
Epoch: 73 | Iteration number: [520/565] 92% | Training loss: 0.6881081405740518
Epoch: 73 | Iteration number: [530/565] 93% | Training loss: 0.6880817084942223
Epoch: 73 | Iteration number: [540/565] 95% | Training loss: 0.6880543506807751
Epoch: 73 | Iteration number: [550/565] 97% | Training loss: 0.6880371813340621
Epoch: 73 | Iteration number: [560/565] 99% | Training loss: 0.6880129724740982

 End of epoch: 73 | Train Loss: 0.6867880016301585 | Training Time: 89 

 End of epoch: 73 | Eval Loss: 0.689634987286159 | Evaluating Time: 5 
Epoch: 74 | Iteration number: [10/565] 1% | Training loss: 0.7557567775249481
Epoch: 74 | Iteration number: [20/565] 3% | Training loss: 0.7211974412202835
Epoch: 74 | Iteration number: [30/565] 5% | Training loss: 0.7097688217957815
Epoch: 74 | Iteration number: [40/565] 7% | Training loss: 0.7041211932897568
Epoch: 74 | Iteration number: [50/565] 8% | Training loss: 0.7006424152851105
Epoch: 74 | Iteration number: [60/565] 10% | Training loss: 0.6982620418071747
Epoch: 74 | Iteration number: [70/565] 12% | Training loss: 0.6966440166745868
Epoch: 74 | Iteration number: [80/565] 14% | Training loss: 0.6953846581280232
Epoch: 74 | Iteration number: [90/565] 15% | Training loss: 0.6944814562797547
Epoch: 74 | Iteration number: [100/565] 17% | Training loss: 0.6937864583730697
Epoch: 74 | Iteration number: [110/565] 19% | Training loss: 0.6931522862477736
Epoch: 74 | Iteration number: [120/565] 21% | Training loss: 0.6925635601083437
Epoch: 74 | Iteration number: [130/565] 23% | Training loss: 0.692087438931832
Epoch: 74 | Iteration number: [140/565] 24% | Training loss: 0.6917141271489007
Epoch: 74 | Iteration number: [150/565] 26% | Training loss: 0.6914110179742178
Epoch: 74 | Iteration number: [160/565] 28% | Training loss: 0.6911248669028283
Epoch: 74 | Iteration number: [170/565] 30% | Training loss: 0.6908587967648225
Epoch: 74 | Iteration number: [180/565] 31% | Training loss: 0.6906286117103365
Epoch: 74 | Iteration number: [190/565] 33% | Training loss: 0.6904335843889337
Epoch: 74 | Iteration number: [200/565] 35% | Training loss: 0.6902687484025956
Epoch: 74 | Iteration number: [210/565] 37% | Training loss: 0.690110304809752
Epoch: 74 | Iteration number: [220/565] 38% | Training loss: 0.6899585983969948
Epoch: 74 | Iteration number: [230/565] 40% | Training loss: 0.6898035894269529
Epoch: 74 | Iteration number: [240/565] 42% | Training loss: 0.6896799633900325
Epoch: 74 | Iteration number: [250/565] 44% | Training loss: 0.6895705897808075
Epoch: 74 | Iteration number: [260/565] 46% | Training loss: 0.6894679812284616
Epoch: 74 | Iteration number: [270/565] 47% | Training loss: 0.6893548166310346
Epoch: 74 | Iteration number: [280/565] 49% | Training loss: 0.6892604136041233
Epoch: 74 | Iteration number: [290/565] 51% | Training loss: 0.6891774290594561
Epoch: 74 | Iteration number: [300/565] 53% | Training loss: 0.6890930956602097
Epoch: 74 | Iteration number: [310/565] 54% | Training loss: 0.6890105218656601
Epoch: 74 | Iteration number: [320/565] 56% | Training loss: 0.6889457833021879
Epoch: 74 | Iteration number: [330/565] 58% | Training loss: 0.6888665889248703
Epoch: 74 | Iteration number: [340/565] 60% | Training loss: 0.688793425524936
Epoch: 74 | Iteration number: [350/565] 61% | Training loss: 0.6887466105393001
Epoch: 74 | Iteration number: [360/565] 63% | Training loss: 0.6886805317468113
Epoch: 74 | Iteration number: [370/565] 65% | Training loss: 0.6886355063399753
Epoch: 74 | Iteration number: [380/565] 67% | Training loss: 0.6885991810183776
Epoch: 74 | Iteration number: [390/565] 69% | Training loss: 0.6885457399563911
Epoch: 74 | Iteration number: [400/565] 70% | Training loss: 0.6884941771626473
Epoch: 74 | Iteration number: [410/565] 72% | Training loss: 0.6884511816792371
Epoch: 74 | Iteration number: [420/565] 74% | Training loss: 0.6884268427178973
Epoch: 74 | Iteration number: [430/565] 76% | Training loss: 0.6883863741575286
Epoch: 74 | Iteration number: [440/565] 77% | Training loss: 0.688355545157736
Epoch: 74 | Iteration number: [450/565] 79% | Training loss: 0.6883257593048944
Epoch: 74 | Iteration number: [460/565] 81% | Training loss: 0.688289001584053
Epoch: 74 | Iteration number: [470/565] 83% | Training loss: 0.6882545526991499
Epoch: 74 | Iteration number: [480/565] 84% | Training loss: 0.6882224937280019
Epoch: 74 | Iteration number: [490/565] 86% | Training loss: 0.6881869816050238
Epoch: 74 | Iteration number: [500/565] 88% | Training loss: 0.6881568564176559
Epoch: 74 | Iteration number: [510/565] 90% | Training loss: 0.6881351946615706
Epoch: 74 | Iteration number: [520/565] 92% | Training loss: 0.6881146096266233
Epoch: 74 | Iteration number: [530/565] 93% | Training loss: 0.6880902135147239
Epoch: 74 | Iteration number: [540/565] 95% | Training loss: 0.6880683733357323
Epoch: 74 | Iteration number: [550/565] 97% | Training loss: 0.6880406893383373
Epoch: 74 | Iteration number: [560/565] 99% | Training loss: 0.6880093373358249

 End of epoch: 74 | Train Loss: 0.6867798088926129 | Training Time: 90 

 End of epoch: 74 | Eval Loss: 0.6890255893979754 | Evaluating Time: 6 
Epoch: 75 | Iteration number: [10/565] 1% | Training loss: 0.7549069702625275
Epoch: 75 | Iteration number: [20/565] 3% | Training loss: 0.72111274600029
Epoch: 75 | Iteration number: [30/565] 5% | Training loss: 0.7095765570799509
Epoch: 75 | Iteration number: [40/565] 7% | Training loss: 0.7038317799568177
Epoch: 75 | Iteration number: [50/565] 8% | Training loss: 0.7004158198833466
Epoch: 75 | Iteration number: [60/565] 10% | Training loss: 0.6980662077665329
Epoch: 75 | Iteration number: [70/565] 12% | Training loss: 0.6965630982603346
Epoch: 75 | Iteration number: [80/565] 14% | Training loss: 0.6953824542462825
Epoch: 75 | Iteration number: [90/565] 15% | Training loss: 0.6943941606415642
Epoch: 75 | Iteration number: [100/565] 17% | Training loss: 0.6936236536502838
Epoch: 75 | Iteration number: [110/565] 19% | Training loss: 0.6930503194982355
Epoch: 75 | Iteration number: [120/565] 21% | Training loss: 0.6925332084298134
Epoch: 75 | Iteration number: [130/565] 23% | Training loss: 0.6921455933497502
Epoch: 75 | Iteration number: [140/565] 24% | Training loss: 0.6917704258646283
Epoch: 75 | Iteration number: [150/565] 26% | Training loss: 0.6914476505915323
Epoch: 75 | Iteration number: [160/565] 28% | Training loss: 0.6911419723182917
Epoch: 75 | Iteration number: [170/565] 30% | Training loss: 0.6908587392638711
Epoch: 75 | Iteration number: [180/565] 31% | Training loss: 0.6906209829780791
Epoch: 75 | Iteration number: [190/565] 33% | Training loss: 0.6903895873772471
Epoch: 75 | Iteration number: [200/565] 35% | Training loss: 0.690201997756958
Epoch: 75 | Iteration number: [210/565] 37% | Training loss: 0.6900644018536523
Epoch: 75 | Iteration number: [220/565] 38% | Training loss: 0.6899055578491905
Epoch: 75 | Iteration number: [230/565] 40% | Training loss: 0.6897661958051764
Epoch: 75 | Iteration number: [240/565] 42% | Training loss: 0.6896407601734003
Epoch: 75 | Iteration number: [250/565] 44% | Training loss: 0.6895144464969635
Epoch: 75 | Iteration number: [260/565] 46% | Training loss: 0.6894051636640842
Epoch: 75 | Iteration number: [270/565] 47% | Training loss: 0.6893166168972298
Epoch: 75 | Iteration number: [280/565] 49% | Training loss: 0.6892134785652161
Epoch: 75 | Iteration number: [290/565] 51% | Training loss: 0.6891123999809396
Epoch: 75 | Iteration number: [300/565] 53% | Training loss: 0.6890563390652339
Epoch: 75 | Iteration number: [310/565] 54% | Training loss: 0.6889657055177997
Epoch: 75 | Iteration number: [320/565] 56% | Training loss: 0.6889040822163224
Epoch: 75 | Iteration number: [330/565] 58% | Training loss: 0.6888353730693008
Epoch: 75 | Iteration number: [340/565] 60% | Training loss: 0.6887567004736732
Epoch: 75 | Iteration number: [350/565] 61% | Training loss: 0.688690185206277
Epoch: 75 | Iteration number: [360/565] 63% | Training loss: 0.6886504103740057
Epoch: 75 | Iteration number: [370/565] 65% | Training loss: 0.6886096015169814
Epoch: 75 | Iteration number: [380/565] 67% | Training loss: 0.6885640197678616
Epoch: 75 | Iteration number: [390/565] 69% | Training loss: 0.6885180699519622
Epoch: 75 | Iteration number: [400/565] 70% | Training loss: 0.6884676927328109
Epoch: 75 | Iteration number: [410/565] 72% | Training loss: 0.6884302944671817
Epoch: 75 | Iteration number: [420/565] 74% | Training loss: 0.6884039518379029
Epoch: 75 | Iteration number: [430/565] 76% | Training loss: 0.688364679175754
Epoch: 75 | Iteration number: [440/565] 77% | Training loss: 0.68834351639856
Epoch: 75 | Iteration number: [450/565] 79% | Training loss: 0.6883129590087467
Epoch: 75 | Iteration number: [460/565] 81% | Training loss: 0.6882811822321104
Epoch: 75 | Iteration number: [470/565] 83% | Training loss: 0.6882437574102523
Epoch: 75 | Iteration number: [480/565] 84% | Training loss: 0.6882131384064754
Epoch: 75 | Iteration number: [490/565] 86% | Training loss: 0.6881854414939881
Epoch: 75 | Iteration number: [500/565] 88% | Training loss: 0.688150544166565
Epoch: 75 | Iteration number: [510/565] 90% | Training loss: 0.6881173006459779
Epoch: 75 | Iteration number: [520/565] 92% | Training loss: 0.6880864738271787
Epoch: 75 | Iteration number: [530/565] 93% | Training loss: 0.6880599316560997
Epoch: 75 | Iteration number: [540/565] 95% | Training loss: 0.6880396323071586
Epoch: 75 | Iteration number: [550/565] 97% | Training loss: 0.6880274694616144
Epoch: 75 | Iteration number: [560/565] 99% | Training loss: 0.6880110701279981

 End of epoch: 75 | Train Loss: 0.6867890848522693 | Training Time: 88 

 End of epoch: 75 | Eval Loss: 0.6891898172242301 | Evaluating Time: 6 
Epoch: 76 | Iteration number: [10/565] 1% | Training loss: 0.7557196140289306
Epoch: 76 | Iteration number: [20/565] 3% | Training loss: 0.7212601095438004
Epoch: 76 | Iteration number: [30/565] 5% | Training loss: 0.7097360094388326
Epoch: 76 | Iteration number: [40/565] 7% | Training loss: 0.703953830897808
Epoch: 76 | Iteration number: [50/565] 8% | Training loss: 0.7003790962696076
Epoch: 76 | Iteration number: [60/565] 10% | Training loss: 0.6980639676253001
Epoch: 76 | Iteration number: [70/565] 12% | Training loss: 0.6964343905448913
Epoch: 76 | Iteration number: [80/565] 14% | Training loss: 0.6952551037073136
Epoch: 76 | Iteration number: [90/565] 15% | Training loss: 0.6942962997489506
Epoch: 76 | Iteration number: [100/565] 17% | Training loss: 0.6935612940788269
Epoch: 76 | Iteration number: [110/565] 19% | Training loss: 0.6929182832891291
Epoch: 76 | Iteration number: [120/565] 21% | Training loss: 0.6924219806989034
Epoch: 76 | Iteration number: [130/565] 23% | Training loss: 0.6919878074756035
Epoch: 76 | Iteration number: [140/565] 24% | Training loss: 0.691637031521116
Epoch: 76 | Iteration number: [150/565] 26% | Training loss: 0.6913616442680359
Epoch: 76 | Iteration number: [160/565] 28% | Training loss: 0.6910742290318013
Epoch: 76 | Iteration number: [170/565] 30% | Training loss: 0.6908218173419728
Epoch: 76 | Iteration number: [180/565] 31% | Training loss: 0.6905965215630001
Epoch: 76 | Iteration number: [190/565] 33% | Training loss: 0.6904054105281829
Epoch: 76 | Iteration number: [200/565] 35% | Training loss: 0.6902184036374092
Epoch: 76 | Iteration number: [210/565] 37% | Training loss: 0.6900611522651854
Epoch: 76 | Iteration number: [220/565] 38% | Training loss: 0.6899284861304543
Epoch: 76 | Iteration number: [230/565] 40% | Training loss: 0.6897945660611857
Epoch: 76 | Iteration number: [240/565] 42% | Training loss: 0.6896453378101189
Epoch: 76 | Iteration number: [250/565] 44% | Training loss: 0.6895453238487244
Epoch: 76 | Iteration number: [260/565] 46% | Training loss: 0.689457606123044
Epoch: 76 | Iteration number: [270/565] 47% | Training loss: 0.6893515162997775
Epoch: 76 | Iteration number: [280/565] 49% | Training loss: 0.6892585196665355
Epoch: 76 | Iteration number: [290/565] 51% | Training loss: 0.6891686153822931
Epoch: 76 | Iteration number: [300/565] 53% | Training loss: 0.6890854638814926
Epoch: 76 | Iteration number: [310/565] 54% | Training loss: 0.6890090561682178
Epoch: 76 | Iteration number: [320/565] 56% | Training loss: 0.6889345243573188
Epoch: 76 | Iteration number: [330/565] 58% | Training loss: 0.6888818459077315
Epoch: 76 | Iteration number: [340/565] 60% | Training loss: 0.6888122011633481
Epoch: 76 | Iteration number: [350/565] 61% | Training loss: 0.6887509976114545
Epoch: 76 | Iteration number: [360/565] 63% | Training loss: 0.688703539967537
Epoch: 76 | Iteration number: [370/565] 65% | Training loss: 0.6886467537364445
Epoch: 76 | Iteration number: [380/565] 67% | Training loss: 0.6886035762335124
Epoch: 76 | Iteration number: [390/565] 69% | Training loss: 0.6885539250496107
Epoch: 76 | Iteration number: [400/565] 70% | Training loss: 0.6885079805552959
Epoch: 76 | Iteration number: [410/565] 72% | Training loss: 0.6884621435549201
Epoch: 76 | Iteration number: [420/565] 74% | Training loss: 0.6884308762493587
Epoch: 76 | Iteration number: [430/565] 76% | Training loss: 0.6883861015009326
Epoch: 76 | Iteration number: [440/565] 77% | Training loss: 0.6883501096205278
Epoch: 76 | Iteration number: [450/565] 79% | Training loss: 0.6883211807409922
Epoch: 76 | Iteration number: [460/565] 81% | Training loss: 0.6882850783026737
Epoch: 76 | Iteration number: [470/565] 83% | Training loss: 0.6882554163324072
Epoch: 76 | Iteration number: [480/565] 84% | Training loss: 0.6882343745479981
Epoch: 76 | Iteration number: [490/565] 86% | Training loss: 0.6882031433436335
Epoch: 76 | Iteration number: [500/565] 88% | Training loss: 0.688172168970108
Epoch: 76 | Iteration number: [510/565] 90% | Training loss: 0.6881408561678494
Epoch: 76 | Iteration number: [520/565] 92% | Training loss: 0.6881078480527951
Epoch: 76 | Iteration number: [530/565] 93% | Training loss: 0.688079228041307
Epoch: 76 | Iteration number: [540/565] 95% | Training loss: 0.6880519100913295
Epoch: 76 | Iteration number: [550/565] 97% | Training loss: 0.6880261520905928
Epoch: 76 | Iteration number: [560/565] 99% | Training loss: 0.6880049522433962

 End of epoch: 76 | Train Loss: 0.6867791882658427 | Training Time: 89 

 End of epoch: 76 | Eval Loss: 0.6892289434160505 | Evaluating Time: 6 
Epoch: 77 | Iteration number: [10/565] 1% | Training loss: 0.7556783199310303
Epoch: 77 | Iteration number: [20/565] 3% | Training loss: 0.7211469084024429
Epoch: 77 | Iteration number: [30/565] 5% | Training loss: 0.7095881601174673
Epoch: 77 | Iteration number: [40/565] 7% | Training loss: 0.7037960216403008
Epoch: 77 | Iteration number: [50/565] 8% | Training loss: 0.7004049456119538
Epoch: 77 | Iteration number: [60/565] 10% | Training loss: 0.69818716943264
Epoch: 77 | Iteration number: [70/565] 12% | Training loss: 0.6966530297483716
Epoch: 77 | Iteration number: [80/565] 14% | Training loss: 0.6954373471438885
Epoch: 77 | Iteration number: [90/565] 15% | Training loss: 0.6944322877460056
Epoch: 77 | Iteration number: [100/565] 17% | Training loss: 0.6937191915512085
Epoch: 77 | Iteration number: [110/565] 19% | Training loss: 0.6931015160950748
Epoch: 77 | Iteration number: [120/565] 21% | Training loss: 0.6925935531655948
Epoch: 77 | Iteration number: [130/565] 23% | Training loss: 0.692141155554698
Epoch: 77 | Iteration number: [140/565] 24% | Training loss: 0.6917716494628361
Epoch: 77 | Iteration number: [150/565] 26% | Training loss: 0.6914330104986827
Epoch: 77 | Iteration number: [160/565] 28% | Training loss: 0.6911446653306484
Epoch: 77 | Iteration number: [170/565] 30% | Training loss: 0.6908997013288386
Epoch: 77 | Iteration number: [180/565] 31% | Training loss: 0.690672207209799
Epoch: 77 | Iteration number: [190/565] 33% | Training loss: 0.6904643802266371
Epoch: 77 | Iteration number: [200/565] 35% | Training loss: 0.6902689298987389
Epoch: 77 | Iteration number: [210/565] 37% | Training loss: 0.690102163382939
Epoch: 77 | Iteration number: [220/565] 38% | Training loss: 0.6899367503144525
Epoch: 77 | Iteration number: [230/565] 40% | Training loss: 0.6897944795048755
Epoch: 77 | Iteration number: [240/565] 42% | Training loss: 0.6896826749046644
Epoch: 77 | Iteration number: [250/565] 44% | Training loss: 0.6895665965080261
Epoch: 77 | Iteration number: [260/565] 46% | Training loss: 0.6894862812298995
Epoch: 77 | Iteration number: [270/565] 47% | Training loss: 0.6893872967472783
Epoch: 77 | Iteration number: [280/565] 49% | Training loss: 0.6893061933772905
Epoch: 77 | Iteration number: [290/565] 51% | Training loss: 0.6892095781605819
Epoch: 77 | Iteration number: [300/565] 53% | Training loss: 0.6891220339139302
Epoch: 77 | Iteration number: [310/565] 54% | Training loss: 0.6890449539307625
Epoch: 77 | Iteration number: [320/565] 56% | Training loss: 0.6889650385826827
Epoch: 77 | Iteration number: [330/565] 58% | Training loss: 0.6888857440514998
Epoch: 77 | Iteration number: [340/565] 60% | Training loss: 0.6888271522872588
Epoch: 77 | Iteration number: [350/565] 61% | Training loss: 0.6887695956230163
Epoch: 77 | Iteration number: [360/565] 63% | Training loss: 0.6887205748094453
Epoch: 77 | Iteration number: [370/565] 65% | Training loss: 0.6886629462242126
Epoch: 77 | Iteration number: [380/565] 67% | Training loss: 0.6886250699821271
Epoch: 77 | Iteration number: [390/565] 69% | Training loss: 0.6885729205914033
Epoch: 77 | Iteration number: [400/565] 70% | Training loss: 0.6885288760066033
Epoch: 77 | Iteration number: [410/565] 72% | Training loss: 0.6884856176085589
Epoch: 77 | Iteration number: [420/565] 74% | Training loss: 0.6884467892703556
Epoch: 77 | Iteration number: [430/565] 76% | Training loss: 0.6884174188902211
Epoch: 77 | Iteration number: [440/565] 77% | Training loss: 0.6883867914026434
Epoch: 77 | Iteration number: [450/565] 79% | Training loss: 0.6883528251118131
Epoch: 77 | Iteration number: [460/565] 81% | Training loss: 0.6883065341607384
Epoch: 77 | Iteration number: [470/565] 83% | Training loss: 0.6882670950382314
Epoch: 77 | Iteration number: [480/565] 84% | Training loss: 0.6882336835066477
Epoch: 77 | Iteration number: [490/565] 86% | Training loss: 0.6882115023476737
Epoch: 77 | Iteration number: [500/565] 88% | Training loss: 0.6881822913885116
Epoch: 77 | Iteration number: [510/565] 90% | Training loss: 0.6881508121303483
Epoch: 77 | Iteration number: [520/565] 92% | Training loss: 0.688116696362312
Epoch: 77 | Iteration number: [530/565] 93% | Training loss: 0.6880841376646509
Epoch: 77 | Iteration number: [540/565] 95% | Training loss: 0.6880575794864584
Epoch: 77 | Iteration number: [550/565] 97% | Training loss: 0.6880361489816146
Epoch: 77 | Iteration number: [560/565] 99% | Training loss: 0.688009162140744

 End of epoch: 77 | Train Loss: 0.686776472087455 | Training Time: 90 

 End of epoch: 77 | Eval Loss: 0.6889023440224784 | Evaluating Time: 6 
Epoch: 78 | Iteration number: [10/565] 1% | Training loss: 0.7554987490177154
Epoch: 78 | Iteration number: [20/565] 3% | Training loss: 0.7211751848459244
Epoch: 78 | Iteration number: [30/565] 5% | Training loss: 0.7097975055376688
Epoch: 78 | Iteration number: [40/565] 7% | Training loss: 0.7040842980146408
Epoch: 78 | Iteration number: [50/565] 8% | Training loss: 0.7007009422779084
Epoch: 78 | Iteration number: [60/565] 10% | Training loss: 0.6984119494756063
Epoch: 78 | Iteration number: [70/565] 12% | Training loss: 0.6967267453670501
Epoch: 78 | Iteration number: [80/565] 14% | Training loss: 0.6954812854528427
Epoch: 78 | Iteration number: [90/565] 15% | Training loss: 0.6945354786184099
Epoch: 78 | Iteration number: [100/565] 17% | Training loss: 0.693739406466484
Epoch: 78 | Iteration number: [110/565] 19% | Training loss: 0.693082641471516
Epoch: 78 | Iteration number: [120/565] 21% | Training loss: 0.6925351182619731
Epoch: 78 | Iteration number: [130/565] 23% | Training loss: 0.6920881968278151
Epoch: 78 | Iteration number: [140/565] 24% | Training loss: 0.6917350598743983
Epoch: 78 | Iteration number: [150/565] 26% | Training loss: 0.6914100627104441
Epoch: 78 | Iteration number: [160/565] 28% | Training loss: 0.6911012545228005
Epoch: 78 | Iteration number: [170/565] 30% | Training loss: 0.6908858478069305
Epoch: 78 | Iteration number: [180/565] 31% | Training loss: 0.6906806959046258
Epoch: 78 | Iteration number: [190/565] 33% | Training loss: 0.6904959010450463
Epoch: 78 | Iteration number: [200/565] 35% | Training loss: 0.6902879425883293
Epoch: 78 | Iteration number: [210/565] 37% | Training loss: 0.6900939509982155
Epoch: 78 | Iteration number: [220/565] 38% | Training loss: 0.6899688983505422
Epoch: 78 | Iteration number: [230/565] 40% | Training loss: 0.6898387807866802
Epoch: 78 | Iteration number: [240/565] 42% | Training loss: 0.6897013885279496
Epoch: 78 | Iteration number: [250/565] 44% | Training loss: 0.6895819807052612
Epoch: 78 | Iteration number: [260/565] 46% | Training loss: 0.6894571813253256
Epoch: 78 | Iteration number: [270/565] 47% | Training loss: 0.6893524512096688
Epoch: 78 | Iteration number: [280/565] 49% | Training loss: 0.6892643513424056
Epoch: 78 | Iteration number: [290/565] 51% | Training loss: 0.6891849316399673
Epoch: 78 | Iteration number: [300/565] 53% | Training loss: 0.6891001472870509
Epoch: 78 | Iteration number: [310/565] 54% | Training loss: 0.689031728044633
Epoch: 78 | Iteration number: [320/565] 56% | Training loss: 0.688948136754334
Epoch: 78 | Iteration number: [330/565] 58% | Training loss: 0.6888631939888
Epoch: 78 | Iteration number: [340/565] 60% | Training loss: 0.6888010834946352
Epoch: 78 | Iteration number: [350/565] 61% | Training loss: 0.6887394721167428
Epoch: 78 | Iteration number: [360/565] 63% | Training loss: 0.6886899557378557
Epoch: 78 | Iteration number: [370/565] 65% | Training loss: 0.6886321449601972
Epoch: 78 | Iteration number: [380/565] 67% | Training loss: 0.6885844608670787
Epoch: 78 | Iteration number: [390/565] 69% | Training loss: 0.6885470474377656
Epoch: 78 | Iteration number: [400/565] 70% | Training loss: 0.6884982889890671
Epoch: 78 | Iteration number: [410/565] 72% | Training loss: 0.6884528305472397
Epoch: 78 | Iteration number: [420/565] 74% | Training loss: 0.6884148521082741
Epoch: 78 | Iteration number: [430/565] 76% | Training loss: 0.6883784611557805
Epoch: 78 | Iteration number: [440/565] 77% | Training loss: 0.688330497524955
Epoch: 78 | Iteration number: [450/565] 79% | Training loss: 0.6882889329062568
Epoch: 78 | Iteration number: [460/565] 81% | Training loss: 0.68825374401134
Epoch: 78 | Iteration number: [470/565] 83% | Training loss: 0.6882367255839895
Epoch: 78 | Iteration number: [480/565] 84% | Training loss: 0.6882048570861419
Epoch: 78 | Iteration number: [490/565] 86% | Training loss: 0.6881799579883109
Epoch: 78 | Iteration number: [500/565] 88% | Training loss: 0.6881561195850372
Epoch: 78 | Iteration number: [510/565] 90% | Training loss: 0.6881286386181327
Epoch: 78 | Iteration number: [520/565] 92% | Training loss: 0.6881075462469688
Epoch: 78 | Iteration number: [530/565] 93% | Training loss: 0.6880786070283854
Epoch: 78 | Iteration number: [540/565] 95% | Training loss: 0.6880609786068952
Epoch: 78 | Iteration number: [550/565] 97% | Training loss: 0.6880375629121607
Epoch: 78 | Iteration number: [560/565] 99% | Training loss: 0.6880214908293315

 End of epoch: 78 | Train Loss: 0.6867921850322622 | Training Time: 89 

 End of epoch: 78 | Eval Loss: 0.6885409866060529 | Evaluating Time: 6 
Epoch: 79 | Iteration number: [10/565] 1% | Training loss: 0.7558310210704804
Epoch: 79 | Iteration number: [20/565] 3% | Training loss: 0.7212647557258606
Epoch: 79 | Iteration number: [30/565] 5% | Training loss: 0.7097386300563813
Epoch: 79 | Iteration number: [40/565] 7% | Training loss: 0.7040185987949371
Epoch: 79 | Iteration number: [50/565] 8% | Training loss: 0.7005806255340576
Epoch: 79 | Iteration number: [60/565] 10% | Training loss: 0.6982483416795731
Epoch: 79 | Iteration number: [70/565] 12% | Training loss: 0.6965568636144911
Epoch: 79 | Iteration number: [80/565] 14% | Training loss: 0.6953569017350674
Epoch: 79 | Iteration number: [90/565] 15% | Training loss: 0.6943843013710446
Epoch: 79 | Iteration number: [100/565] 17% | Training loss: 0.6936628103256226
Epoch: 79 | Iteration number: [110/565] 19% | Training loss: 0.6930459049614993
Epoch: 79 | Iteration number: [120/565] 21% | Training loss: 0.6925372049212456
Epoch: 79 | Iteration number: [130/565] 23% | Training loss: 0.692120690529163
Epoch: 79 | Iteration number: [140/565] 24% | Training loss: 0.6917160493986947
Epoch: 79 | Iteration number: [150/565] 26% | Training loss: 0.6913690765698751
Epoch: 79 | Iteration number: [160/565] 28% | Training loss: 0.6910740930587054
Epoch: 79 | Iteration number: [170/565] 30% | Training loss: 0.6908141560414258
Epoch: 79 | Iteration number: [180/565] 31% | Training loss: 0.6905981679757436
Epoch: 79 | Iteration number: [190/565] 33% | Training loss: 0.6903826512788471
Epoch: 79 | Iteration number: [200/565] 35% | Training loss: 0.6902210721373558
Epoch: 79 | Iteration number: [210/565] 37% | Training loss: 0.6900796484379541
Epoch: 79 | Iteration number: [220/565] 38% | Training loss: 0.6899387486956337
Epoch: 79 | Iteration number: [230/565] 40% | Training loss: 0.6898094791433086
Epoch: 79 | Iteration number: [240/565] 42% | Training loss: 0.6896650326748689
Epoch: 79 | Iteration number: [250/565] 44% | Training loss: 0.6895418567657471
Epoch: 79 | Iteration number: [260/565] 46% | Training loss: 0.68943569453863
Epoch: 79 | Iteration number: [270/565] 47% | Training loss: 0.689355589725353
Epoch: 79 | Iteration number: [280/565] 49% | Training loss: 0.6892549244420869
Epoch: 79 | Iteration number: [290/565] 51% | Training loss: 0.6891673112737722
Epoch: 79 | Iteration number: [300/565] 53% | Training loss: 0.6890914036830267
Epoch: 79 | Iteration number: [310/565] 54% | Training loss: 0.6890192991302859
Epoch: 79 | Iteration number: [320/565] 56% | Training loss: 0.6889559427276254
Epoch: 79 | Iteration number: [330/565] 58% | Training loss: 0.6889089905854427
Epoch: 79 | Iteration number: [340/565] 60% | Training loss: 0.6888448347063626
Epoch: 79 | Iteration number: [350/565] 61% | Training loss: 0.6887761383397238
Epoch: 79 | Iteration number: [360/565] 63% | Training loss: 0.6887184545397759
Epoch: 79 | Iteration number: [370/565] 65% | Training loss: 0.6886837255310367
Epoch: 79 | Iteration number: [380/565] 67% | Training loss: 0.6886224484757373
Epoch: 79 | Iteration number: [390/565] 69% | Training loss: 0.688568783723391
Epoch: 79 | Iteration number: [400/565] 70% | Training loss: 0.6885252085328102
Epoch: 79 | Iteration number: [410/565] 72% | Training loss: 0.6884673955963879
Epoch: 79 | Iteration number: [420/565] 74% | Training loss: 0.6884311186415809
Epoch: 79 | Iteration number: [430/565] 76% | Training loss: 0.6883892369824787
Epoch: 79 | Iteration number: [440/565] 77% | Training loss: 0.6883505762978034
Epoch: 79 | Iteration number: [450/565] 79% | Training loss: 0.6883063790533278
Epoch: 79 | Iteration number: [460/565] 81% | Training loss: 0.6882812655490378
Epoch: 79 | Iteration number: [470/565] 83% | Training loss: 0.6882469457514743
Epoch: 79 | Iteration number: [480/565] 84% | Training loss: 0.6882124818861485
Epoch: 79 | Iteration number: [490/565] 86% | Training loss: 0.6881860688024638
Epoch: 79 | Iteration number: [500/565] 88% | Training loss: 0.6881581236124039
Epoch: 79 | Iteration number: [510/565] 90% | Training loss: 0.6881337227774601
Epoch: 79 | Iteration number: [520/565] 92% | Training loss: 0.6881028620096353
Epoch: 79 | Iteration number: [530/565] 93% | Training loss: 0.6880782662697558
Epoch: 79 | Iteration number: [540/565] 95% | Training loss: 0.6880581884472459
Epoch: 79 | Iteration number: [550/565] 97% | Training loss: 0.6880389878966592
Epoch: 79 | Iteration number: [560/565] 99% | Training loss: 0.6880098654755524

 End of epoch: 79 | Train Loss: 0.6867825004906781 | Training Time: 90 

 End of epoch: 79 | Eval Loss: 0.6896052445684161 | Evaluating Time: 6 
Epoch: 80 | Iteration number: [10/565] 1% | Training loss: 0.7551649808883667
Epoch: 80 | Iteration number: [20/565] 3% | Training loss: 0.7209646046161652
Epoch: 80 | Iteration number: [30/565] 5% | Training loss: 0.7097722172737122
Epoch: 80 | Iteration number: [40/565] 7% | Training loss: 0.7039425313472748
Epoch: 80 | Iteration number: [50/565] 8% | Training loss: 0.7003604280948639
Epoch: 80 | Iteration number: [60/565] 10% | Training loss: 0.6981250842412313
Epoch: 80 | Iteration number: [70/565] 12% | Training loss: 0.6964729411261422
Epoch: 80 | Iteration number: [80/565] 14% | Training loss: 0.6952864520251751
Epoch: 80 | Iteration number: [90/565] 15% | Training loss: 0.6943621695041656
Epoch: 80 | Iteration number: [100/565] 17% | Training loss: 0.6936160099506378
Epoch: 80 | Iteration number: [110/565] 19% | Training loss: 0.6929863756353205
Epoch: 80 | Iteration number: [120/565] 21% | Training loss: 0.6924982572595278
Epoch: 80 | Iteration number: [130/565] 23% | Training loss: 0.6920680963076078
Epoch: 80 | Iteration number: [140/565] 24% | Training loss: 0.6916689574718475
Epoch: 80 | Iteration number: [150/565] 26% | Training loss: 0.6913735552628835
Epoch: 80 | Iteration number: [160/565] 28% | Training loss: 0.6910817891359329
Epoch: 80 | Iteration number: [170/565] 30% | Training loss: 0.6908001987373128
Epoch: 80 | Iteration number: [180/565] 31% | Training loss: 0.6905729658073849
Epoch: 80 | Iteration number: [190/565] 33% | Training loss: 0.6903760916308352
Epoch: 80 | Iteration number: [200/565] 35% | Training loss: 0.6901880437135697
Epoch: 80 | Iteration number: [210/565] 37% | Training loss: 0.6900050092311133
Epoch: 80 | Iteration number: [220/565] 38% | Training loss: 0.6898709015412764
Epoch: 80 | Iteration number: [230/565] 40% | Training loss: 0.6897234667902408
Epoch: 80 | Iteration number: [240/565] 42% | Training loss: 0.6895943989356359
Epoch: 80 | Iteration number: [250/565] 44% | Training loss: 0.6894948925971985
Epoch: 80 | Iteration number: [260/565] 46% | Training loss: 0.6893969600017255
Epoch: 80 | Iteration number: [270/565] 47% | Training loss: 0.689297494844154
Epoch: 80 | Iteration number: [280/565] 49% | Training loss: 0.6891956107957022
Epoch: 80 | Iteration number: [290/565] 51% | Training loss: 0.6891222626998507
Epoch: 80 | Iteration number: [300/565] 53% | Training loss: 0.6890325808525085
Epoch: 80 | Iteration number: [310/565] 54% | Training loss: 0.6889569645927799
Epoch: 80 | Iteration number: [320/565] 56% | Training loss: 0.6888896441087127
Epoch: 80 | Iteration number: [330/565] 58% | Training loss: 0.6888252372091467
Epoch: 80 | Iteration number: [340/565] 60% | Training loss: 0.6887799121001188
Epoch: 80 | Iteration number: [350/565] 61% | Training loss: 0.6887240314483642
Epoch: 80 | Iteration number: [360/565] 63% | Training loss: 0.6886648861898317
Epoch: 80 | Iteration number: [370/565] 65% | Training loss: 0.688610057895248
Epoch: 80 | Iteration number: [380/565] 67% | Training loss: 0.6885670774861385
Epoch: 80 | Iteration number: [390/565] 69% | Training loss: 0.688517574316416
Epoch: 80 | Iteration number: [400/565] 70% | Training loss: 0.6884792703390121
Epoch: 80 | Iteration number: [410/565] 72% | Training loss: 0.6884357801297816
Epoch: 80 | Iteration number: [420/565] 74% | Training loss: 0.6883869068963188
Epoch: 80 | Iteration number: [430/565] 76% | Training loss: 0.6883424538512563
Epoch: 80 | Iteration number: [440/565] 77% | Training loss: 0.6882946061817082
Epoch: 80 | Iteration number: [450/565] 79% | Training loss: 0.6882594354947408
Epoch: 80 | Iteration number: [460/565] 81% | Training loss: 0.6882297677838284
Epoch: 80 | Iteration number: [470/565] 83% | Training loss: 0.6882095681860092
Epoch: 80 | Iteration number: [480/565] 84% | Training loss: 0.688182566066583
Epoch: 80 | Iteration number: [490/565] 86% | Training loss: 0.6881498749158821
Epoch: 80 | Iteration number: [500/565] 88% | Training loss: 0.6881279915571212
Epoch: 80 | Iteration number: [510/565] 90% | Training loss: 0.6881066191430185
Epoch: 80 | Iteration number: [520/565] 92% | Training loss: 0.6880879523662421
Epoch: 80 | Iteration number: [530/565] 93% | Training loss: 0.6880593232388766
Epoch: 80 | Iteration number: [540/565] 95% | Training loss: 0.6880344610523295
Epoch: 80 | Iteration number: [550/565] 97% | Training loss: 0.6880184613574635
Epoch: 80 | Iteration number: [560/565] 99% | Training loss: 0.687999257764646

 End of epoch: 80 | Train Loss: 0.6867767181016703 | Training Time: 90 

 End of epoch: 80 | Eval Loss: 0.6888443657330104 | Evaluating Time: 6 
Epoch: 81 | Iteration number: [10/565] 1% | Training loss: 0.7550320625305176
Epoch: 81 | Iteration number: [20/565] 3% | Training loss: 0.7208684474229813
Epoch: 81 | Iteration number: [30/565] 5% | Training loss: 0.7095553874969482
Epoch: 81 | Iteration number: [40/565] 7% | Training loss: 0.7036732524633408
Epoch: 81 | Iteration number: [50/565] 8% | Training loss: 0.7003281402587891
Epoch: 81 | Iteration number: [60/565] 10% | Training loss: 0.6979868511358897
Epoch: 81 | Iteration number: [70/565] 12% | Training loss: 0.6964536905288696
Epoch: 81 | Iteration number: [80/565] 14% | Training loss: 0.695221035182476
Epoch: 81 | Iteration number: [90/565] 15% | Training loss: 0.6942926393614874
Epoch: 81 | Iteration number: [100/565] 17% | Training loss: 0.6935472851991653
Epoch: 81 | Iteration number: [110/565] 19% | Training loss: 0.6929199928587133
Epoch: 81 | Iteration number: [120/565] 21% | Training loss: 0.6924042368928591
Epoch: 81 | Iteration number: [130/565] 23% | Training loss: 0.6919912283237164
Epoch: 81 | Iteration number: [140/565] 24% | Training loss: 0.6916259761367526
Epoch: 81 | Iteration number: [150/565] 26% | Training loss: 0.6913130605220794
Epoch: 81 | Iteration number: [160/565] 28% | Training loss: 0.6910047367215156
Epoch: 81 | Iteration number: [170/565] 30% | Training loss: 0.6907464223749498
Epoch: 81 | Iteration number: [180/565] 31% | Training loss: 0.6905168755186929
Epoch: 81 | Iteration number: [190/565] 33% | Training loss: 0.6903136548243071
Epoch: 81 | Iteration number: [200/565] 35% | Training loss: 0.6901452389359474
Epoch: 81 | Iteration number: [210/565] 37% | Training loss: 0.6899921349116734
Epoch: 81 | Iteration number: [220/565] 38% | Training loss: 0.6898532908071171
Epoch: 81 | Iteration number: [230/565] 40% | Training loss: 0.6897395774074223
Epoch: 81 | Iteration number: [240/565] 42% | Training loss: 0.689608580370744
Epoch: 81 | Iteration number: [250/565] 44% | Training loss: 0.6895044186115264
Epoch: 81 | Iteration number: [260/565] 46% | Training loss: 0.6894061581446574
Epoch: 81 | Iteration number: [270/565] 47% | Training loss: 0.6893087384877381
Epoch: 81 | Iteration number: [280/565] 49% | Training loss: 0.6892344711082322
Epoch: 81 | Iteration number: [290/565] 51% | Training loss: 0.6891438566405198
Epoch: 81 | Iteration number: [300/565] 53% | Training loss: 0.6890801427761714
Epoch: 81 | Iteration number: [310/565] 54% | Training loss: 0.6890130089175317
Epoch: 81 | Iteration number: [320/565] 56% | Training loss: 0.688959288969636
Epoch: 81 | Iteration number: [330/565] 58% | Training loss: 0.6888945180358309
Epoch: 81 | Iteration number: [340/565] 60% | Training loss: 0.6888319825424868
Epoch: 81 | Iteration number: [350/565] 61% | Training loss: 0.6887764147349766
Epoch: 81 | Iteration number: [360/565] 63% | Training loss: 0.6887308895587921
Epoch: 81 | Iteration number: [370/565] 65% | Training loss: 0.688683689284969
Epoch: 81 | Iteration number: [380/565] 67% | Training loss: 0.6886357232144005
Epoch: 81 | Iteration number: [390/565] 69% | Training loss: 0.6885828542403686
Epoch: 81 | Iteration number: [400/565] 70% | Training loss: 0.6885361766815186
Epoch: 81 | Iteration number: [410/565] 72% | Training loss: 0.6884937353250457
Epoch: 81 | Iteration number: [420/565] 74% | Training loss: 0.6884567154305322
Epoch: 81 | Iteration number: [430/565] 76% | Training loss: 0.6884232141250788
Epoch: 81 | Iteration number: [440/565] 77% | Training loss: 0.6883807267655025
Epoch: 81 | Iteration number: [450/565] 79% | Training loss: 0.6883500740263198
Epoch: 81 | Iteration number: [460/565] 81% | Training loss: 0.6883145226084668
Epoch: 81 | Iteration number: [470/565] 83% | Training loss: 0.6882774098122374
Epoch: 81 | Iteration number: [480/565] 84% | Training loss: 0.6882393083224694
Epoch: 81 | Iteration number: [490/565] 86% | Training loss: 0.6882143224988665
Epoch: 81 | Iteration number: [500/565] 88% | Training loss: 0.6881845364570618
Epoch: 81 | Iteration number: [510/565] 90% | Training loss: 0.6881621781517477
Epoch: 81 | Iteration number: [520/565] 92% | Training loss: 0.6881347047594878
Epoch: 81 | Iteration number: [530/565] 93% | Training loss: 0.6880959099193789
Epoch: 81 | Iteration number: [540/565] 95% | Training loss: 0.6880737059646183
Epoch: 81 | Iteration number: [550/565] 97% | Training loss: 0.6880523121356964
Epoch: 81 | Iteration number: [560/565] 99% | Training loss: 0.6880334533751011

 End of epoch: 81 | Train Loss: 0.6868087108156322 | Training Time: 90 

 End of epoch: 81 | Eval Loss: 0.6894509792327881 | Evaluating Time: 6 
Epoch: 82 | Iteration number: [10/565] 1% | Training loss: 0.755798852443695
Epoch: 82 | Iteration number: [20/565] 3% | Training loss: 0.7214042901992798
Epoch: 82 | Iteration number: [30/565] 5% | Training loss: 0.7098240753014883
Epoch: 82 | Iteration number: [40/565] 7% | Training loss: 0.7040875896811485
Epoch: 82 | Iteration number: [50/565] 8% | Training loss: 0.7007134091854096
Epoch: 82 | Iteration number: [60/565] 10% | Training loss: 0.6983803252379099
Epoch: 82 | Iteration number: [70/565] 12% | Training loss: 0.6967859991959163
Epoch: 82 | Iteration number: [80/565] 14% | Training loss: 0.6955021910369397
Epoch: 82 | Iteration number: [90/565] 15% | Training loss: 0.6945163660579258
Epoch: 82 | Iteration number: [100/565] 17% | Training loss: 0.6936936891078949
Epoch: 82 | Iteration number: [110/565] 19% | Training loss: 0.6930728110400113
Epoch: 82 | Iteration number: [120/565] 21% | Training loss: 0.6925507848461468
Epoch: 82 | Iteration number: [130/565] 23% | Training loss: 0.6921214232077966
Epoch: 82 | Iteration number: [140/565] 24% | Training loss: 0.6917303200278964
Epoch: 82 | Iteration number: [150/565] 26% | Training loss: 0.6914175168673198
Epoch: 82 | Iteration number: [160/565] 28% | Training loss: 0.6911422692239284
Epoch: 82 | Iteration number: [170/565] 30% | Training loss: 0.6908852366840138
Epoch: 82 | Iteration number: [180/565] 31% | Training loss: 0.6906511432594723
Epoch: 82 | Iteration number: [190/565] 33% | Training loss: 0.6904420711492237
Epoch: 82 | Iteration number: [200/565] 35% | Training loss: 0.6902694833278656
Epoch: 82 | Iteration number: [210/565] 37% | Training loss: 0.6901232148919787
Epoch: 82 | Iteration number: [220/565] 38% | Training loss: 0.6899801606481726
Epoch: 82 | Iteration number: [230/565] 40% | Training loss: 0.6898405329040859
Epoch: 82 | Iteration number: [240/565] 42% | Training loss: 0.6897140249609948
Epoch: 82 | Iteration number: [250/565] 44% | Training loss: 0.6895973932743072
Epoch: 82 | Iteration number: [260/565] 46% | Training loss: 0.68950267800918
Epoch: 82 | Iteration number: [270/565] 47% | Training loss: 0.6894212433585414
Epoch: 82 | Iteration number: [280/565] 49% | Training loss: 0.6893148811800139
Epoch: 82 | Iteration number: [290/565] 51% | Training loss: 0.6892199413529758
Epoch: 82 | Iteration number: [300/565] 53% | Training loss: 0.6891389699776967
Epoch: 82 | Iteration number: [310/565] 54% | Training loss: 0.6890619947064307
Epoch: 82 | Iteration number: [320/565] 56% | Training loss: 0.6889980655163527
Epoch: 82 | Iteration number: [330/565] 58% | Training loss: 0.6889220329848202
Epoch: 82 | Iteration number: [340/565] 60% | Training loss: 0.6888504636638305
Epoch: 82 | Iteration number: [350/565] 61% | Training loss: 0.6887848653112139
Epoch: 82 | Iteration number: [360/565] 63% | Training loss: 0.68872835305002
Epoch: 82 | Iteration number: [370/565] 65% | Training loss: 0.6886768880728129
Epoch: 82 | Iteration number: [380/565] 67% | Training loss: 0.6886231359682585
Epoch: 82 | Iteration number: [390/565] 69% | Training loss: 0.6885754707532051
Epoch: 82 | Iteration number: [400/565] 70% | Training loss: 0.6885299804806709
Epoch: 82 | Iteration number: [410/565] 72% | Training loss: 0.6884948625797178
Epoch: 82 | Iteration number: [420/565] 74% | Training loss: 0.6884551929576056
Epoch: 82 | Iteration number: [430/565] 76% | Training loss: 0.6884069427501324
Epoch: 82 | Iteration number: [440/565] 77% | Training loss: 0.6883682208982381
Epoch: 82 | Iteration number: [450/565] 79% | Training loss: 0.6883406665590074
Epoch: 82 | Iteration number: [460/565] 81% | Training loss: 0.6883197232432987
Epoch: 82 | Iteration number: [470/565] 83% | Training loss: 0.6882815030026943
Epoch: 82 | Iteration number: [480/565] 84% | Training loss: 0.6882470307250818
Epoch: 82 | Iteration number: [490/565] 86% | Training loss: 0.6882042915237193
Epoch: 82 | Iteration number: [500/565] 88% | Training loss: 0.6881789162158966
Epoch: 82 | Iteration number: [510/565] 90% | Training loss: 0.6881501678158255
Epoch: 82 | Iteration number: [520/565] 92% | Training loss: 0.6881211530703765
Epoch: 82 | Iteration number: [530/565] 93% | Training loss: 0.6880844176940198
Epoch: 82 | Iteration number: [540/565] 95% | Training loss: 0.6880561624412184
Epoch: 82 | Iteration number: [550/565] 97% | Training loss: 0.6880342558297244
Epoch: 82 | Iteration number: [560/565] 99% | Training loss: 0.6880118685109274

 End of epoch: 82 | Train Loss: 0.686782325158077 | Training Time: 90 

 End of epoch: 82 | Eval Loss: 0.6894354139055524 | Evaluating Time: 5 
Epoch: 83 | Iteration number: [10/565] 1% | Training loss: 0.7555516302585602
Epoch: 83 | Iteration number: [20/565] 3% | Training loss: 0.7209256440401077
Epoch: 83 | Iteration number: [30/565] 5% | Training loss: 0.7096114019552867
Epoch: 83 | Iteration number: [40/565] 7% | Training loss: 0.7038291096687317
Epoch: 83 | Iteration number: [50/565] 8% | Training loss: 0.7004005789756775
Epoch: 83 | Iteration number: [60/565] 10% | Training loss: 0.6981752624114355
Epoch: 83 | Iteration number: [70/565] 12% | Training loss: 0.6965472885540553
Epoch: 83 | Iteration number: [80/565] 14% | Training loss: 0.6953591585159302
Epoch: 83 | Iteration number: [90/565] 15% | Training loss: 0.694419589969847
Epoch: 83 | Iteration number: [100/565] 17% | Training loss: 0.6936466646194458
Epoch: 83 | Iteration number: [110/565] 19% | Training loss: 0.6930069923400879
Epoch: 83 | Iteration number: [120/565] 21% | Training loss: 0.6924924607078234
Epoch: 83 | Iteration number: [130/565] 23% | Training loss: 0.6920813033213982
Epoch: 83 | Iteration number: [140/565] 24% | Training loss: 0.6917064883879253
Epoch: 83 | Iteration number: [150/565] 26% | Training loss: 0.69135848681132
Epoch: 83 | Iteration number: [160/565] 28% | Training loss: 0.6910691570490599
Epoch: 83 | Iteration number: [170/565] 30% | Training loss: 0.6908019146498512
Epoch: 83 | Iteration number: [180/565] 31% | Training loss: 0.6905824194351832
Epoch: 83 | Iteration number: [190/565] 33% | Training loss: 0.690379462116643
Epoch: 83 | Iteration number: [200/565] 35% | Training loss: 0.69020109385252
Epoch: 83 | Iteration number: [210/565] 37% | Training loss: 0.690037705217089
Epoch: 83 | Iteration number: [220/565] 38% | Training loss: 0.68990956409411
Epoch: 83 | Iteration number: [230/565] 40% | Training loss: 0.6897822152013364
Epoch: 83 | Iteration number: [240/565] 42% | Training loss: 0.6896581503252188
Epoch: 83 | Iteration number: [250/565] 44% | Training loss: 0.6895431954860687
Epoch: 83 | Iteration number: [260/565] 46% | Training loss: 0.6894346475601196
Epoch: 83 | Iteration number: [270/565] 47% | Training loss: 0.6893329388565488
Epoch: 83 | Iteration number: [280/565] 49% | Training loss: 0.6892558953591755
Epoch: 83 | Iteration number: [290/565] 51% | Training loss: 0.6891697014200276
Epoch: 83 | Iteration number: [300/565] 53% | Training loss: 0.6890927763779958
Epoch: 83 | Iteration number: [310/565] 54% | Training loss: 0.6890104922556108
Epoch: 83 | Iteration number: [320/565] 56% | Training loss: 0.6889549847692251
Epoch: 83 | Iteration number: [330/565] 58% | Training loss: 0.6888681122750947
Epoch: 83 | Iteration number: [340/565] 60% | Training loss: 0.6888154124512392
Epoch: 83 | Iteration number: [350/565] 61% | Training loss: 0.6887452159609113
Epoch: 83 | Iteration number: [360/565] 63% | Training loss: 0.6886941828661495
Epoch: 83 | Iteration number: [370/565] 65% | Training loss: 0.688641715371931
Epoch: 83 | Iteration number: [380/565] 67% | Training loss: 0.6885864044490614
Epoch: 83 | Iteration number: [390/565] 69% | Training loss: 0.6885481485953697
Epoch: 83 | Iteration number: [400/565] 70% | Training loss: 0.6885016775131225
Epoch: 83 | Iteration number: [410/565] 72% | Training loss: 0.688467972743802
Epoch: 83 | Iteration number: [420/565] 74% | Training loss: 0.6884214198305494
Epoch: 83 | Iteration number: [430/565] 76% | Training loss: 0.6883704031622687
Epoch: 83 | Iteration number: [440/565] 77% | Training loss: 0.6883410539139401
Epoch: 83 | Iteration number: [450/565] 79% | Training loss: 0.6883012427224053
Epoch: 83 | Iteration number: [460/565] 81% | Training loss: 0.6882811381765034
Epoch: 83 | Iteration number: [470/565] 83% | Training loss: 0.6882334238671242
Epoch: 83 | Iteration number: [480/565] 84% | Training loss: 0.6882017406324545
Epoch: 83 | Iteration number: [490/565] 86% | Training loss: 0.6881760509646668
Epoch: 83 | Iteration number: [500/565] 88% | Training loss: 0.6881532189846039
Epoch: 83 | Iteration number: [510/565] 90% | Training loss: 0.688132896493463
Epoch: 83 | Iteration number: [520/565] 92% | Training loss: 0.6881085596405543
Epoch: 83 | Iteration number: [530/565] 93% | Training loss: 0.6880839081305378
Epoch: 83 | Iteration number: [540/565] 95% | Training loss: 0.6880589029303303
Epoch: 83 | Iteration number: [550/565] 97% | Training loss: 0.6880296788432382
Epoch: 83 | Iteration number: [560/565] 99% | Training loss: 0.688008108415774

 End of epoch: 83 | Train Loss: 0.6867778165150533 | Training Time: 89 

 End of epoch: 83 | Eval Loss: 0.6888540812901088 | Evaluating Time: 6 
Epoch: 84 | Iteration number: [10/565] 1% | Training loss: 0.7552871525287628
Epoch: 84 | Iteration number: [20/565] 3% | Training loss: 0.7210138291120529
Epoch: 84 | Iteration number: [30/565] 5% | Training loss: 0.709590740998586
Epoch: 84 | Iteration number: [40/565] 7% | Training loss: 0.703763110935688
Epoch: 84 | Iteration number: [50/565] 8% | Training loss: 0.7003778457641602
Epoch: 84 | Iteration number: [60/565] 10% | Training loss: 0.6981215208768845
Epoch: 84 | Iteration number: [70/565] 12% | Training loss: 0.6965308274541583
Epoch: 84 | Iteration number: [80/565] 14% | Training loss: 0.695318876951933
Epoch: 84 | Iteration number: [90/565] 15% | Training loss: 0.6944348600175646
Epoch: 84 | Iteration number: [100/565] 17% | Training loss: 0.6936500805616379
Epoch: 84 | Iteration number: [110/565] 19% | Training loss: 0.6929785999384793
Epoch: 84 | Iteration number: [120/565] 21% | Training loss: 0.6924650525053342
Epoch: 84 | Iteration number: [130/565] 23% | Training loss: 0.6920215235306666
Epoch: 84 | Iteration number: [140/565] 24% | Training loss: 0.6916719943284988
Epoch: 84 | Iteration number: [150/565] 26% | Training loss: 0.6913540788491567
Epoch: 84 | Iteration number: [160/565] 28% | Training loss: 0.69105119779706
Epoch: 84 | Iteration number: [170/565] 30% | Training loss: 0.6907696552136365
Epoch: 84 | Iteration number: [180/565] 31% | Training loss: 0.6905578129821354
Epoch: 84 | Iteration number: [190/565] 33% | Training loss: 0.6903541536707627
Epoch: 84 | Iteration number: [200/565] 35% | Training loss: 0.6901801565289497
Epoch: 84 | Iteration number: [210/565] 37% | Training loss: 0.6900011596225557
Epoch: 84 | Iteration number: [220/565] 38% | Training loss: 0.6898634330792861
Epoch: 84 | Iteration number: [230/565] 40% | Training loss: 0.6897576702677686
Epoch: 84 | Iteration number: [240/565] 42% | Training loss: 0.68965362260739
Epoch: 84 | Iteration number: [250/565] 44% | Training loss: 0.6895261752605438
Epoch: 84 | Iteration number: [260/565] 46% | Training loss: 0.6894348573226196
Epoch: 84 | Iteration number: [270/565] 47% | Training loss: 0.6893429957054279
Epoch: 84 | Iteration number: [280/565] 49% | Training loss: 0.6892663346869605
Epoch: 84 | Iteration number: [290/565] 51% | Training loss: 0.6891763553537171
Epoch: 84 | Iteration number: [300/565] 53% | Training loss: 0.6891006082296371
Epoch: 84 | Iteration number: [310/565] 54% | Training loss: 0.6890154827025629
Epoch: 84 | Iteration number: [320/565] 56% | Training loss: 0.688951369933784
Epoch: 84 | Iteration number: [330/565] 58% | Training loss: 0.6888890551798271
Epoch: 84 | Iteration number: [340/565] 60% | Training loss: 0.6888141188551398
Epoch: 84 | Iteration number: [350/565] 61% | Training loss: 0.6887429615429469
Epoch: 84 | Iteration number: [360/565] 63% | Training loss: 0.6886893666452831
Epoch: 84 | Iteration number: [370/565] 65% | Training loss: 0.6886256921935726
Epoch: 84 | Iteration number: [380/565] 67% | Training loss: 0.6885758062726572
Epoch: 84 | Iteration number: [390/565] 69% | Training loss: 0.6885261142865206
Epoch: 84 | Iteration number: [400/565] 70% | Training loss: 0.6884862822294235
Epoch: 84 | Iteration number: [410/565] 72% | Training loss: 0.6884502266965261
Epoch: 84 | Iteration number: [420/565] 74% | Training loss: 0.6884153699591047
Epoch: 84 | Iteration number: [430/565] 76% | Training loss: 0.6883838555147481
Epoch: 84 | Iteration number: [440/565] 77% | Training loss: 0.6883449917489832
Epoch: 84 | Iteration number: [450/565] 79% | Training loss: 0.6883043593830532
Epoch: 84 | Iteration number: [460/565] 81% | Training loss: 0.6882741123437881
Epoch: 84 | Iteration number: [470/565] 83% | Training loss: 0.6882400016835395
Epoch: 84 | Iteration number: [480/565] 84% | Training loss: 0.6882143160949151
Epoch: 84 | Iteration number: [490/565] 86% | Training loss: 0.6881842362637423
Epoch: 84 | Iteration number: [500/565] 88% | Training loss: 0.688156813621521
Epoch: 84 | Iteration number: [510/565] 90% | Training loss: 0.6881313708483004
Epoch: 84 | Iteration number: [520/565] 92% | Training loss: 0.688099938401809
Epoch: 84 | Iteration number: [530/565] 93% | Training loss: 0.6880709184790558
Epoch: 84 | Iteration number: [540/565] 95% | Training loss: 0.688047194480896
Epoch: 84 | Iteration number: [550/565] 97% | Training loss: 0.6880241260745309
Epoch: 84 | Iteration number: [560/565] 99% | Training loss: 0.68800214273589

 End of epoch: 84 | Train Loss: 0.6867791787712975 | Training Time: 90 

 End of epoch: 84 | Eval Loss: 0.6891787137304034 | Evaluating Time: 6 
Epoch: 85 | Iteration number: [10/565] 1% | Training loss: 0.7554656207561493
Epoch: 85 | Iteration number: [20/565] 3% | Training loss: 0.721330001950264
Epoch: 85 | Iteration number: [30/565] 5% | Training loss: 0.7097337404886882
Epoch: 85 | Iteration number: [40/565] 7% | Training loss: 0.7039311692118645
Epoch: 85 | Iteration number: [50/565] 8% | Training loss: 0.7005695223808288
Epoch: 85 | Iteration number: [60/565] 10% | Training loss: 0.6982995619376501
Epoch: 85 | Iteration number: [70/565] 12% | Training loss: 0.6966295225279672
Epoch: 85 | Iteration number: [80/565] 14% | Training loss: 0.6954442486166954
Epoch: 85 | Iteration number: [90/565] 15% | Training loss: 0.6944544229242536
Epoch: 85 | Iteration number: [100/565] 17% | Training loss: 0.6936652415990829
Epoch: 85 | Iteration number: [110/565] 19% | Training loss: 0.6929889917373657
Epoch: 85 | Iteration number: [120/565] 21% | Training loss: 0.6924805512030919
Epoch: 85 | Iteration number: [130/565] 23% | Training loss: 0.6920440485844246
Epoch: 85 | Iteration number: [140/565] 24% | Training loss: 0.6916795994554247
Epoch: 85 | Iteration number: [150/565] 26% | Training loss: 0.6913282978534698
Epoch: 85 | Iteration number: [160/565] 28% | Training loss: 0.6910672158002853
Epoch: 85 | Iteration number: [170/565] 30% | Training loss: 0.6908250577309553
Epoch: 85 | Iteration number: [180/565] 31% | Training loss: 0.6905894329150518
Epoch: 85 | Iteration number: [190/565] 33% | Training loss: 0.690380651072452
Epoch: 85 | Iteration number: [200/565] 35% | Training loss: 0.6902007204294205
Epoch: 85 | Iteration number: [210/565] 37% | Training loss: 0.6900439869789851
Epoch: 85 | Iteration number: [220/565] 38% | Training loss: 0.6898768996650523
Epoch: 85 | Iteration number: [230/565] 40% | Training loss: 0.6897416239199431
Epoch: 85 | Iteration number: [240/565] 42% | Training loss: 0.6896237815419833
Epoch: 85 | Iteration number: [250/565] 44% | Training loss: 0.68951042842865
Epoch: 85 | Iteration number: [260/565] 46% | Training loss: 0.6894181783382709
Epoch: 85 | Iteration number: [270/565] 47% | Training loss: 0.6893243184796086
Epoch: 85 | Iteration number: [280/565] 49% | Training loss: 0.6892328958426203
Epoch: 85 | Iteration number: [290/565] 51% | Training loss: 0.6891639255244156
Epoch: 85 | Iteration number: [300/565] 53% | Training loss: 0.6890706485509872
Epoch: 85 | Iteration number: [310/565] 54% | Training loss: 0.6890020089764749
Epoch: 85 | Iteration number: [320/565] 56% | Training loss: 0.688941414654255
Epoch: 85 | Iteration number: [330/565] 58% | Training loss: 0.6888766548850319
Epoch: 85 | Iteration number: [340/565] 60% | Training loss: 0.6888040926526574
Epoch: 85 | Iteration number: [350/565] 61% | Training loss: 0.6887514838150569
Epoch: 85 | Iteration number: [360/565] 63% | Training loss: 0.6886992697914441
Epoch: 85 | Iteration number: [370/565] 65% | Training loss: 0.6886390761749165
Epoch: 85 | Iteration number: [380/565] 67% | Training loss: 0.6885841253556704
Epoch: 85 | Iteration number: [390/565] 69% | Training loss: 0.6885397506065858
Epoch: 85 | Iteration number: [400/565] 70% | Training loss: 0.6884909814596176
Epoch: 85 | Iteration number: [410/565] 72% | Training loss: 0.6884457345415906
Epoch: 85 | Iteration number: [420/565] 74% | Training loss: 0.6884046656744821
Epoch: 85 | Iteration number: [430/565] 76% | Training loss: 0.6883716774541279
Epoch: 85 | Iteration number: [440/565] 77% | Training loss: 0.6883370175957679
Epoch: 85 | Iteration number: [450/565] 79% | Training loss: 0.6883109908633762
Epoch: 85 | Iteration number: [460/565] 81% | Training loss: 0.6882767656575078
Epoch: 85 | Iteration number: [470/565] 83% | Training loss: 0.6882476672213128
Epoch: 85 | Iteration number: [480/565] 84% | Training loss: 0.6882172821710507
Epoch: 85 | Iteration number: [490/565] 86% | Training loss: 0.6881870538604503
Epoch: 85 | Iteration number: [500/565] 88% | Training loss: 0.6881629642248154
Epoch: 85 | Iteration number: [510/565] 90% | Training loss: 0.688137339961295
Epoch: 85 | Iteration number: [520/565] 92% | Training loss: 0.6881141612162957
Epoch: 85 | Iteration number: [530/565] 93% | Training loss: 0.6880835104663418
Epoch: 85 | Iteration number: [540/565] 95% | Training loss: 0.6880542587350916
Epoch: 85 | Iteration number: [550/565] 97% | Training loss: 0.6880250694534995
Epoch: 85 | Iteration number: [560/565] 99% | Training loss: 0.6880000975515161

 End of epoch: 85 | Train Loss: 0.6867741048863504 | Training Time: 89 

 End of epoch: 85 | Eval Loss: 0.6890978983470372 | Evaluating Time: 6 
Epoch: 86 | Iteration number: [10/565] 1% | Training loss: 0.7557486176490784
Epoch: 86 | Iteration number: [20/565] 3% | Training loss: 0.721114182472229
Epoch: 86 | Iteration number: [30/565] 5% | Training loss: 0.7096216162045796
Epoch: 86 | Iteration number: [40/565] 7% | Training loss: 0.703939002752304
Epoch: 86 | Iteration number: [50/565] 8% | Training loss: 0.7005095636844635
Epoch: 86 | Iteration number: [60/565] 10% | Training loss: 0.6982289284467698
Epoch: 86 | Iteration number: [70/565] 12% | Training loss: 0.6966017067432404
Epoch: 86 | Iteration number: [80/565] 14% | Training loss: 0.6953261315822601
Epoch: 86 | Iteration number: [90/565] 15% | Training loss: 0.6943659173117743
Epoch: 86 | Iteration number: [100/565] 17% | Training loss: 0.693606088757515
Epoch: 86 | Iteration number: [110/565] 19% | Training loss: 0.6929990611293099
Epoch: 86 | Iteration number: [120/565] 21% | Training loss: 0.6925155604879062
Epoch: 86 | Iteration number: [130/565] 23% | Training loss: 0.692070827117333
Epoch: 86 | Iteration number: [140/565] 24% | Training loss: 0.6917042012725557
Epoch: 86 | Iteration number: [150/565] 26% | Training loss: 0.6913854897022247
Epoch: 86 | Iteration number: [160/565] 28% | Training loss: 0.6911163359880448
Epoch: 86 | Iteration number: [170/565] 30% | Training loss: 0.6908586680889129
Epoch: 86 | Iteration number: [180/565] 31% | Training loss: 0.6905918823348152
Epoch: 86 | Iteration number: [190/565] 33% | Training loss: 0.6903916220915945
Epoch: 86 | Iteration number: [200/565] 35% | Training loss: 0.6902178904414177
Epoch: 86 | Iteration number: [210/565] 37% | Training loss: 0.6900519064494541
Epoch: 86 | Iteration number: [220/565] 38% | Training loss: 0.6898869823325764
Epoch: 86 | Iteration number: [230/565] 40% | Training loss: 0.6897596162298452
Epoch: 86 | Iteration number: [240/565] 42% | Training loss: 0.6896209915479025
Epoch: 86 | Iteration number: [250/565] 44% | Training loss: 0.689513943195343
Epoch: 86 | Iteration number: [260/565] 46% | Training loss: 0.6893962108171903
Epoch: 86 | Iteration number: [270/565] 47% | Training loss: 0.6893097956975301
Epoch: 86 | Iteration number: [280/565] 49% | Training loss: 0.6892020553350449
Epoch: 86 | Iteration number: [290/565] 51% | Training loss: 0.6891336560249328
Epoch: 86 | Iteration number: [300/565] 53% | Training loss: 0.6890511548519135
Epoch: 86 | Iteration number: [310/565] 54% | Training loss: 0.6889698463101541
Epoch: 86 | Iteration number: [320/565] 56% | Training loss: 0.688891987502575
Epoch: 86 | Iteration number: [330/565] 58% | Training loss: 0.6888360644831802
Epoch: 86 | Iteration number: [340/565] 60% | Training loss: 0.688791164931129
Epoch: 86 | Iteration number: [350/565] 61% | Training loss: 0.6887327941826412
Epoch: 86 | Iteration number: [360/565] 63% | Training loss: 0.6886814403865072
Epoch: 86 | Iteration number: [370/565] 65% | Training loss: 0.6886380100572431
Epoch: 86 | Iteration number: [380/565] 67% | Training loss: 0.6886032250366713
Epoch: 86 | Iteration number: [390/565] 69% | Training loss: 0.6885546986873333
Epoch: 86 | Iteration number: [400/565] 70% | Training loss: 0.6885099855065345
Epoch: 86 | Iteration number: [410/565] 72% | Training loss: 0.6884666801952735
Epoch: 86 | Iteration number: [420/565] 74% | Training loss: 0.6884248449688866
Epoch: 86 | Iteration number: [430/565] 76% | Training loss: 0.6883908457534258
Epoch: 86 | Iteration number: [440/565] 77% | Training loss: 0.68835462521423
Epoch: 86 | Iteration number: [450/565] 79% | Training loss: 0.6883211686876085
Epoch: 86 | Iteration number: [460/565] 81% | Training loss: 0.6882908848316773
Epoch: 86 | Iteration number: [470/565] 83% | Training loss: 0.6882695186645427
Epoch: 86 | Iteration number: [480/565] 84% | Training loss: 0.6882297532012065
Epoch: 86 | Iteration number: [490/565] 86% | Training loss: 0.6881977771009717
Epoch: 86 | Iteration number: [500/565] 88% | Training loss: 0.6881629149913788
Epoch: 86 | Iteration number: [510/565] 90% | Training loss: 0.6881412874249851
Epoch: 86 | Iteration number: [520/565] 92% | Training loss: 0.688112860918045
Epoch: 86 | Iteration number: [530/565] 93% | Training loss: 0.688089496459601
Epoch: 86 | Iteration number: [540/565] 95% | Training loss: 0.6880687519356057
Epoch: 86 | Iteration number: [550/565] 97% | Training loss: 0.688037294474515
Epoch: 86 | Iteration number: [560/565] 99% | Training loss: 0.6880175829998084

 End of epoch: 86 | Train Loss: 0.6867963884784057 | Training Time: 90 

 End of epoch: 86 | Eval Loss: 0.6887326070240566 | Evaluating Time: 6 
Epoch: 87 | Iteration number: [10/565] 1% | Training loss: 0.7551492273807525
Epoch: 87 | Iteration number: [20/565] 3% | Training loss: 0.720929530262947
Epoch: 87 | Iteration number: [30/565] 5% | Training loss: 0.7095228850841522
Epoch: 87 | Iteration number: [40/565] 7% | Training loss: 0.7037154451012612
Epoch: 87 | Iteration number: [50/565] 8% | Training loss: 0.7003358113765716
Epoch: 87 | Iteration number: [60/565] 10% | Training loss: 0.6980967183907827
Epoch: 87 | Iteration number: [70/565] 12% | Training loss: 0.6965448158127922
Epoch: 87 | Iteration number: [80/565] 14% | Training loss: 0.6952756717801094
Epoch: 87 | Iteration number: [90/565] 15% | Training loss: 0.694329027334849
Epoch: 87 | Iteration number: [100/565] 17% | Training loss: 0.693622876405716
Epoch: 87 | Iteration number: [110/565] 19% | Training loss: 0.6930173971436241
Epoch: 87 | Iteration number: [120/565] 21% | Training loss: 0.6924945811430613
Epoch: 87 | Iteration number: [130/565] 23% | Training loss: 0.6920914251070757
Epoch: 87 | Iteration number: [140/565] 24% | Training loss: 0.6917165773255485
Epoch: 87 | Iteration number: [150/565] 26% | Training loss: 0.6913829251130422
Epoch: 87 | Iteration number: [160/565] 28% | Training loss: 0.6910919830203056
Epoch: 87 | Iteration number: [170/565] 30% | Training loss: 0.6908339205910178
Epoch: 87 | Iteration number: [180/565] 31% | Training loss: 0.690586233470175
Epoch: 87 | Iteration number: [190/565] 33% | Training loss: 0.6903874146310907
Epoch: 87 | Iteration number: [200/565] 35% | Training loss: 0.6902204728126526
Epoch: 87 | Iteration number: [210/565] 37% | Training loss: 0.6900473611695426
Epoch: 87 | Iteration number: [220/565] 38% | Training loss: 0.6899037090214816
Epoch: 87 | Iteration number: [230/565] 40% | Training loss: 0.6897534720275713
Epoch: 87 | Iteration number: [240/565] 42% | Training loss: 0.6896351111431916
Epoch: 87 | Iteration number: [250/565] 44% | Training loss: 0.6895231876373291
Epoch: 87 | Iteration number: [260/565] 46% | Training loss: 0.6894157599944335
Epoch: 87 | Iteration number: [270/565] 47% | Training loss: 0.6893153089064139
Epoch: 87 | Iteration number: [280/565] 49% | Training loss: 0.6892105249421937
Epoch: 87 | Iteration number: [290/565] 51% | Training loss: 0.6891150493046333
Epoch: 87 | Iteration number: [300/565] 53% | Training loss: 0.689038742184639
Epoch: 87 | Iteration number: [310/565] 54% | Training loss: 0.6889744158714048
Epoch: 87 | Iteration number: [320/565] 56% | Training loss: 0.6888852650299668
Epoch: 87 | Iteration number: [330/565] 58% | Training loss: 0.6888344724973042
Epoch: 87 | Iteration number: [340/565] 60% | Training loss: 0.6887666206149494
Epoch: 87 | Iteration number: [350/565] 61% | Training loss: 0.6887095938410078
Epoch: 87 | Iteration number: [360/565] 63% | Training loss: 0.6886636123061181
Epoch: 87 | Iteration number: [370/565] 65% | Training loss: 0.6886121476018751
Epoch: 87 | Iteration number: [380/565] 67% | Training loss: 0.6885717434318442
Epoch: 87 | Iteration number: [390/565] 69% | Training loss: 0.6885294206631489
Epoch: 87 | Iteration number: [400/565] 70% | Training loss: 0.6884904783964158
Epoch: 87 | Iteration number: [410/565] 72% | Training loss: 0.6884427906536474
Epoch: 87 | Iteration number: [420/565] 74% | Training loss: 0.6883973541713896
Epoch: 87 | Iteration number: [430/565] 76% | Training loss: 0.688360511563545
Epoch: 87 | Iteration number: [440/565] 77% | Training loss: 0.6883154779672622
Epoch: 87 | Iteration number: [450/565] 79% | Training loss: 0.6882793513933817
Epoch: 87 | Iteration number: [460/565] 81% | Training loss: 0.6882514641336773
Epoch: 87 | Iteration number: [470/565] 83% | Training loss: 0.6882258117198944
Epoch: 87 | Iteration number: [480/565] 84% | Training loss: 0.6881936363875866
Epoch: 87 | Iteration number: [490/565] 86% | Training loss: 0.6881759357695677
Epoch: 87 | Iteration number: [500/565] 88% | Training loss: 0.6881506553888321
Epoch: 87 | Iteration number: [510/565] 90% | Training loss: 0.688113460704392
Epoch: 87 | Iteration number: [520/565] 92% | Training loss: 0.6880891688741171
Epoch: 87 | Iteration number: [530/565] 93% | Training loss: 0.6880681039027448
Epoch: 87 | Iteration number: [540/565] 95% | Training loss: 0.6880441238482793
Epoch: 87 | Iteration number: [550/565] 97% | Training loss: 0.6880173121799122
Epoch: 87 | Iteration number: [560/565] 99% | Training loss: 0.6880030652242047

 End of epoch: 87 | Train Loss: 0.6867800558562828 | Training Time: 89 

 End of epoch: 87 | Eval Loss: 0.6895924806594849 | Evaluating Time: 6 
Epoch: 88 | Iteration number: [10/565] 1% | Training loss: 0.7553113877773285
Epoch: 88 | Iteration number: [20/565] 3% | Training loss: 0.7211639106273651
Epoch: 88 | Iteration number: [30/565] 5% | Training loss: 0.7097203393777212
Epoch: 88 | Iteration number: [40/565] 7% | Training loss: 0.7040231615304947
Epoch: 88 | Iteration number: [50/565] 8% | Training loss: 0.7005959928035737
Epoch: 88 | Iteration number: [60/565] 10% | Training loss: 0.698380379875501
Epoch: 88 | Iteration number: [70/565] 12% | Training loss: 0.696757219518934
Epoch: 88 | Iteration number: [80/565] 14% | Training loss: 0.6954861097037792
Epoch: 88 | Iteration number: [90/565] 15% | Training loss: 0.6945531765619913
Epoch: 88 | Iteration number: [100/565] 17% | Training loss: 0.6937737292051316
Epoch: 88 | Iteration number: [110/565] 19% | Training loss: 0.6931652795184743
Epoch: 88 | Iteration number: [120/565] 21% | Training loss: 0.6926199654738109
Epoch: 88 | Iteration number: [130/565] 23% | Training loss: 0.6921654705817882
Epoch: 88 | Iteration number: [140/565] 24% | Training loss: 0.6917748996189662
Epoch: 88 | Iteration number: [150/565] 26% | Training loss: 0.6914329787095388
Epoch: 88 | Iteration number: [160/565] 28% | Training loss: 0.6911473549902439
Epoch: 88 | Iteration number: [170/565] 30% | Training loss: 0.6909017980098724
Epoch: 88 | Iteration number: [180/565] 31% | Training loss: 0.690652279721366
Epoch: 88 | Iteration number: [190/565] 33% | Training loss: 0.6904525650174994
Epoch: 88 | Iteration number: [200/565] 35% | Training loss: 0.690257722735405
Epoch: 88 | Iteration number: [210/565] 37% | Training loss: 0.6900703608989716
Epoch: 88 | Iteration number: [220/565] 38% | Training loss: 0.6899118672717701
Epoch: 88 | Iteration number: [230/565] 40% | Training loss: 0.6897806056167768
Epoch: 88 | Iteration number: [240/565] 42% | Training loss: 0.6896470787624518
Epoch: 88 | Iteration number: [250/565] 44% | Training loss: 0.6895052416324615
Epoch: 88 | Iteration number: [260/565] 46% | Training loss: 0.6893983756120389
Epoch: 88 | Iteration number: [270/565] 47% | Training loss: 0.6892915977372064
Epoch: 88 | Iteration number: [280/565] 49% | Training loss: 0.6892016029783657
Epoch: 88 | Iteration number: [290/565] 51% | Training loss: 0.6891027497834172
Epoch: 88 | Iteration number: [300/565] 53% | Training loss: 0.6890307740370433
Epoch: 88 | Iteration number: [310/565] 54% | Training loss: 0.6889557161638814
Epoch: 88 | Iteration number: [320/565] 56% | Training loss: 0.6888890625908971
Epoch: 88 | Iteration number: [330/565] 58% | Training loss: 0.6888199871236628
Epoch: 88 | Iteration number: [340/565] 60% | Training loss: 0.6887539425316979
Epoch: 88 | Iteration number: [350/565] 61% | Training loss: 0.6886965111323765
Epoch: 88 | Iteration number: [360/565] 63% | Training loss: 0.6886487604843246
Epoch: 88 | Iteration number: [370/565] 65% | Training loss: 0.6886123905310759
Epoch: 88 | Iteration number: [380/565] 67% | Training loss: 0.6885563462972641
Epoch: 88 | Iteration number: [390/565] 69% | Training loss: 0.6885110566249261
Epoch: 88 | Iteration number: [400/565] 70% | Training loss: 0.6884662318229675
Epoch: 88 | Iteration number: [410/565] 72% | Training loss: 0.6884251917280801
Epoch: 88 | Iteration number: [420/565] 74% | Training loss: 0.6883893797794978
Epoch: 88 | Iteration number: [430/565] 76% | Training loss: 0.6883534736411516
Epoch: 88 | Iteration number: [440/565] 77% | Training loss: 0.6883176118135452
Epoch: 88 | Iteration number: [450/565] 79% | Training loss: 0.6882771031061808
Epoch: 88 | Iteration number: [460/565] 81% | Training loss: 0.6882490726916687
Epoch: 88 | Iteration number: [470/565] 83% | Training loss: 0.6882242975082803
Epoch: 88 | Iteration number: [480/565] 84% | Training loss: 0.6881974319616954
Epoch: 88 | Iteration number: [490/565] 86% | Training loss: 0.6881764190537589
Epoch: 88 | Iteration number: [500/565] 88% | Training loss: 0.6881512874364852
Epoch: 88 | Iteration number: [510/565] 90% | Training loss: 0.6881240713830088
Epoch: 88 | Iteration number: [520/565] 92% | Training loss: 0.6880991925413792
Epoch: 88 | Iteration number: [530/565] 93% | Training loss: 0.6880762624290754
Epoch: 88 | Iteration number: [540/565] 95% | Training loss: 0.688064358079875
Epoch: 88 | Iteration number: [550/565] 97% | Training loss: 0.6880322391336614
Epoch: 88 | Iteration number: [560/565] 99% | Training loss: 0.6880013333899634

 End of epoch: 88 | Train Loss: 0.6867712256127754 | Training Time: 90 

 End of epoch: 88 | Eval Loss: 0.6893934181758335 | Evaluating Time: 6 
Epoch: 89 | Iteration number: [10/565] 1% | Training loss: 0.7557047545909882
Epoch: 89 | Iteration number: [20/565] 3% | Training loss: 0.7213460117578506
Epoch: 89 | Iteration number: [30/565] 5% | Training loss: 0.7097326080004375
Epoch: 89 | Iteration number: [40/565] 7% | Training loss: 0.7040321633219719
Epoch: 89 | Iteration number: [50/565] 8% | Training loss: 0.7005347263813019
Epoch: 89 | Iteration number: [60/565] 10% | Training loss: 0.698200582464536
Epoch: 89 | Iteration number: [70/565] 12% | Training loss: 0.6965887333665576
Epoch: 89 | Iteration number: [80/565] 14% | Training loss: 0.6953147724270821
Epoch: 89 | Iteration number: [90/565] 15% | Training loss: 0.6943109307024214
Epoch: 89 | Iteration number: [100/565] 17% | Training loss: 0.6935553193092346
Epoch: 89 | Iteration number: [110/565] 19% | Training loss: 0.6929215106097135
Epoch: 89 | Iteration number: [120/565] 21% | Training loss: 0.692434410750866
Epoch: 89 | Iteration number: [130/565] 23% | Training loss: 0.6920368964855488
Epoch: 89 | Iteration number: [140/565] 24% | Training loss: 0.6916528931685857
Epoch: 89 | Iteration number: [150/565] 26% | Training loss: 0.6913158675034841
Epoch: 89 | Iteration number: [160/565] 28% | Training loss: 0.6910232815891504
Epoch: 89 | Iteration number: [170/565] 30% | Training loss: 0.6907675949966207
Epoch: 89 | Iteration number: [180/565] 31% | Training loss: 0.6905344519350264
Epoch: 89 | Iteration number: [190/565] 33% | Training loss: 0.6903395486505408
Epoch: 89 | Iteration number: [200/565] 35% | Training loss: 0.6901561090350151
Epoch: 89 | Iteration number: [210/565] 37% | Training loss: 0.69001637895902
Epoch: 89 | Iteration number: [220/565] 38% | Training loss: 0.6898697259751233
Epoch: 89 | Iteration number: [230/565] 40% | Training loss: 0.6897439002990723
Epoch: 89 | Iteration number: [240/565] 42% | Training loss: 0.6896225805083911
Epoch: 89 | Iteration number: [250/565] 44% | Training loss: 0.6894936480522156
Epoch: 89 | Iteration number: [260/565] 46% | Training loss: 0.6893827493374164
Epoch: 89 | Iteration number: [270/565] 47% | Training loss: 0.6892949459729372
Epoch: 89 | Iteration number: [280/565] 49% | Training loss: 0.6892063796520234
Epoch: 89 | Iteration number: [290/565] 51% | Training loss: 0.6891078523520766
Epoch: 89 | Iteration number: [300/565] 53% | Training loss: 0.6890331971645355
Epoch: 89 | Iteration number: [310/565] 54% | Training loss: 0.6889571480212673
Epoch: 89 | Iteration number: [320/565] 56% | Training loss: 0.6888870736584067
Epoch: 89 | Iteration number: [330/565] 58% | Training loss: 0.6888328830401103
Epoch: 89 | Iteration number: [340/565] 60% | Training loss: 0.688781085435082
Epoch: 89 | Iteration number: [350/565] 61% | Training loss: 0.6887294975348881
Epoch: 89 | Iteration number: [360/565] 63% | Training loss: 0.6886827369530996
Epoch: 89 | Iteration number: [370/565] 65% | Training loss: 0.6886373938740911
Epoch: 89 | Iteration number: [380/565] 67% | Training loss: 0.6885920926144249
Epoch: 89 | Iteration number: [390/565] 69% | Training loss: 0.6885588305118756
Epoch: 89 | Iteration number: [400/565] 70% | Training loss: 0.6885167303681373
Epoch: 89 | Iteration number: [410/565] 72% | Training loss: 0.6884711656628586
Epoch: 89 | Iteration number: [420/565] 74% | Training loss: 0.6884215442907242
Epoch: 89 | Iteration number: [430/565] 76% | Training loss: 0.6883836650571158
Epoch: 89 | Iteration number: [440/565] 77% | Training loss: 0.6883376943794164
Epoch: 89 | Iteration number: [450/565] 79% | Training loss: 0.6883120804362827
Epoch: 89 | Iteration number: [460/565] 81% | Training loss: 0.6882800273273302
Epoch: 89 | Iteration number: [470/565] 83% | Training loss: 0.6882517132353275
Epoch: 89 | Iteration number: [480/565] 84% | Training loss: 0.6882229739179214
Epoch: 89 | Iteration number: [490/565] 86% | Training loss: 0.6881958796053517
Epoch: 89 | Iteration number: [500/565] 88% | Training loss: 0.6881542048454284
Epoch: 89 | Iteration number: [510/565] 90% | Training loss: 0.6881288291192522
Epoch: 89 | Iteration number: [520/565] 92% | Training loss: 0.6880953063185399
Epoch: 89 | Iteration number: [530/565] 93% | Training loss: 0.6880595597456086
Epoch: 89 | Iteration number: [540/565] 95% | Training loss: 0.6880317206735964
Epoch: 89 | Iteration number: [550/565] 97% | Training loss: 0.6880136256868189
Epoch: 89 | Iteration number: [560/565] 99% | Training loss: 0.687990157519068

 End of epoch: 89 | Train Loss: 0.6867649322062467 | Training Time: 89 

 End of epoch: 89 | Eval Loss: 0.6888500281742641 | Evaluating Time: 6 
Epoch: 90 | Iteration number: [10/565] 1% | Training loss: 0.755139684677124
Epoch: 90 | Iteration number: [20/565] 3% | Training loss: 0.7207459211349487
Epoch: 90 | Iteration number: [30/565] 5% | Training loss: 0.709229028224945
Epoch: 90 | Iteration number: [40/565] 7% | Training loss: 0.7036060154438019
Epoch: 90 | Iteration number: [50/565] 8% | Training loss: 0.7003202176094055
Epoch: 90 | Iteration number: [60/565] 10% | Training loss: 0.6980969895919164
Epoch: 90 | Iteration number: [70/565] 12% | Training loss: 0.696478602715901
Epoch: 90 | Iteration number: [80/565] 14% | Training loss: 0.6953164719045162
Epoch: 90 | Iteration number: [90/565] 15% | Training loss: 0.6943511691358354
Epoch: 90 | Iteration number: [100/565] 17% | Training loss: 0.6935981160402298
Epoch: 90 | Iteration number: [110/565] 19% | Training loss: 0.6929928188974207
Epoch: 90 | Iteration number: [120/565] 21% | Training loss: 0.6925004079937935
Epoch: 90 | Iteration number: [130/565] 23% | Training loss: 0.6920671357558323
Epoch: 90 | Iteration number: [140/565] 24% | Training loss: 0.6916887189660753
Epoch: 90 | Iteration number: [150/565] 26% | Training loss: 0.6913558411598205
Epoch: 90 | Iteration number: [160/565] 28% | Training loss: 0.6910765398293733
Epoch: 90 | Iteration number: [170/565] 30% | Training loss: 0.6908191456514247
Epoch: 90 | Iteration number: [180/565] 31% | Training loss: 0.6905789650148816
Epoch: 90 | Iteration number: [190/565] 33% | Training loss: 0.6903661028334969
Epoch: 90 | Iteration number: [200/565] 35% | Training loss: 0.690202632844448
Epoch: 90 | Iteration number: [210/565] 37% | Training loss: 0.6900533128352392
Epoch: 90 | Iteration number: [220/565] 38% | Training loss: 0.6899024657227776
Epoch: 90 | Iteration number: [230/565] 40% | Training loss: 0.6897633130135743
Epoch: 90 | Iteration number: [240/565] 42% | Training loss: 0.6896261548002561
Epoch: 90 | Iteration number: [250/565] 44% | Training loss: 0.6894893298149108
Epoch: 90 | Iteration number: [260/565] 46% | Training loss: 0.6893869241842857
Epoch: 90 | Iteration number: [270/565] 47% | Training loss: 0.6892872309243238
Epoch: 90 | Iteration number: [280/565] 49% | Training loss: 0.689196218763079
Epoch: 90 | Iteration number: [290/565] 51% | Training loss: 0.6891078685892039
Epoch: 90 | Iteration number: [300/565] 53% | Training loss: 0.6890241998434067
Epoch: 90 | Iteration number: [310/565] 54% | Training loss: 0.6889691258630445
Epoch: 90 | Iteration number: [320/565] 56% | Training loss: 0.6889086212962866
Epoch: 90 | Iteration number: [330/565] 58% | Training loss: 0.688850962935072
Epoch: 90 | Iteration number: [340/565] 60% | Training loss: 0.6887817056740031
Epoch: 90 | Iteration number: [350/565] 61% | Training loss: 0.6887266174384525
Epoch: 90 | Iteration number: [360/565] 63% | Training loss: 0.6886659267875883
Epoch: 90 | Iteration number: [370/565] 65% | Training loss: 0.6886095515779547
Epoch: 90 | Iteration number: [380/565] 67% | Training loss: 0.6885549835468593
Epoch: 90 | Iteration number: [390/565] 69% | Training loss: 0.6885014732678731
Epoch: 90 | Iteration number: [400/565] 70% | Training loss: 0.6884639179706573
Epoch: 90 | Iteration number: [410/565] 72% | Training loss: 0.6884385222341957
Epoch: 90 | Iteration number: [420/565] 74% | Training loss: 0.6883872384116763
Epoch: 90 | Iteration number: [430/565] 76% | Training loss: 0.6883475004240523
Epoch: 90 | Iteration number: [440/565] 77% | Training loss: 0.6883124795826998
Epoch: 90 | Iteration number: [450/565] 79% | Training loss: 0.6882745370599959
Epoch: 90 | Iteration number: [460/565] 81% | Training loss: 0.6882406094799871
Epoch: 90 | Iteration number: [470/565] 83% | Training loss: 0.6882260659907726
Epoch: 90 | Iteration number: [480/565] 84% | Training loss: 0.6881843185673158
Epoch: 90 | Iteration number: [490/565] 86% | Training loss: 0.688163235844398
Epoch: 90 | Iteration number: [500/565] 88% | Training loss: 0.688134864449501
Epoch: 90 | Iteration number: [510/565] 90% | Training loss: 0.6881095163962421
Epoch: 90 | Iteration number: [520/565] 92% | Training loss: 0.6880883779663306
Epoch: 90 | Iteration number: [530/565] 93% | Training loss: 0.6880586951408746
Epoch: 90 | Iteration number: [540/565] 95% | Training loss: 0.6880319980559526
Epoch: 90 | Iteration number: [550/565] 97% | Training loss: 0.6880118971521204
Epoch: 90 | Iteration number: [560/565] 99% | Training loss: 0.6879931936306612

 End of epoch: 90 | Train Loss: 0.6867662344358664 | Training Time: 91 

 End of epoch: 90 | Eval Loss: 0.6894554580960955 | Evaluating Time: 5 
Epoch: 91 | Iteration number: [10/565] 1% | Training loss: 0.7553209841251374
Epoch: 91 | Iteration number: [20/565] 3% | Training loss: 0.7209924995899201
Epoch: 91 | Iteration number: [30/565] 5% | Training loss: 0.7094646692276001
Epoch: 91 | Iteration number: [40/565] 7% | Training loss: 0.7037459507584571
Epoch: 91 | Iteration number: [50/565] 8% | Training loss: 0.7002732169628143
Epoch: 91 | Iteration number: [60/565] 10% | Training loss: 0.6979747941096623
Epoch: 91 | Iteration number: [70/565] 12% | Training loss: 0.6963670415537698
Epoch: 91 | Iteration number: [80/565] 14% | Training loss: 0.6951610907912255
Epoch: 91 | Iteration number: [90/565] 15% | Training loss: 0.6942507227261862
Epoch: 91 | Iteration number: [100/565] 17% | Training loss: 0.693483789563179
Epoch: 91 | Iteration number: [110/565] 19% | Training loss: 0.6928417698903517
Epoch: 91 | Iteration number: [120/565] 21% | Training loss: 0.6923481191198031
Epoch: 91 | Iteration number: [130/565] 23% | Training loss: 0.6919417683894817
Epoch: 91 | Iteration number: [140/565] 24% | Training loss: 0.6915638663939068
Epoch: 91 | Iteration number: [150/565] 26% | Training loss: 0.6912881497542064
Epoch: 91 | Iteration number: [160/565] 28% | Training loss: 0.6910088729113341
Epoch: 91 | Iteration number: [170/565] 30% | Training loss: 0.690769856116351
Epoch: 91 | Iteration number: [180/565] 31% | Training loss: 0.6905637615256839
Epoch: 91 | Iteration number: [190/565] 33% | Training loss: 0.6903721564694455
Epoch: 91 | Iteration number: [200/565] 35% | Training loss: 0.6901980194449425
Epoch: 91 | Iteration number: [210/565] 37% | Training loss: 0.6900385621048155
Epoch: 91 | Iteration number: [220/565] 38% | Training loss: 0.6898977566849102
Epoch: 91 | Iteration number: [230/565] 40% | Training loss: 0.6897713624912759
Epoch: 91 | Iteration number: [240/565] 42% | Training loss: 0.6896472975611687
Epoch: 91 | Iteration number: [250/565] 44% | Training loss: 0.6895112054347992
Epoch: 91 | Iteration number: [260/565] 46% | Training loss: 0.6894185348198965
Epoch: 91 | Iteration number: [270/565] 47% | Training loss: 0.6893211870281785
Epoch: 91 | Iteration number: [280/565] 49% | Training loss: 0.6892212188669613
Epoch: 91 | Iteration number: [290/565] 51% | Training loss: 0.6891240078827431
Epoch: 91 | Iteration number: [300/565] 53% | Training loss: 0.6890354760487875
Epoch: 91 | Iteration number: [310/565] 54% | Training loss: 0.6889592741766284
Epoch: 91 | Iteration number: [320/565] 56% | Training loss: 0.6888834798708559
Epoch: 91 | Iteration number: [330/565] 58% | Training loss: 0.6888288416645744
Epoch: 91 | Iteration number: [340/565] 60% | Training loss: 0.6887781530618667
Epoch: 91 | Iteration number: [350/565] 61% | Training loss: 0.6887142954553876
Epoch: 91 | Iteration number: [360/565] 63% | Training loss: 0.6886657625436783
Epoch: 91 | Iteration number: [370/565] 65% | Training loss: 0.688619834023553
Epoch: 91 | Iteration number: [380/565] 67% | Training loss: 0.6885722706192419
Epoch: 91 | Iteration number: [390/565] 69% | Training loss: 0.6885264130739065
Epoch: 91 | Iteration number: [400/565] 70% | Training loss: 0.6884776209294796
Epoch: 91 | Iteration number: [410/565] 72% | Training loss: 0.688439243159643
Epoch: 91 | Iteration number: [420/565] 74% | Training loss: 0.6883964495999473
Epoch: 91 | Iteration number: [430/565] 76% | Training loss: 0.688358335162318
Epoch: 91 | Iteration number: [440/565] 77% | Training loss: 0.6883213352073323
Epoch: 91 | Iteration number: [450/565] 79% | Training loss: 0.6882880832089319
Epoch: 91 | Iteration number: [460/565] 81% | Training loss: 0.6882587051909903
Epoch: 91 | Iteration number: [470/565] 83% | Training loss: 0.688230059628791
Epoch: 91 | Iteration number: [480/565] 84% | Training loss: 0.6881988837073246
Epoch: 91 | Iteration number: [490/565] 86% | Training loss: 0.688171052689455
Epoch: 91 | Iteration number: [500/565] 88% | Training loss: 0.6881433626413346
Epoch: 91 | Iteration number: [510/565] 90% | Training loss: 0.6881197154521942
Epoch: 91 | Iteration number: [520/565] 92% | Training loss: 0.6880993072803204
Epoch: 91 | Iteration number: [530/565] 93% | Training loss: 0.6880783708590381
Epoch: 91 | Iteration number: [540/565] 95% | Training loss: 0.6880449331469006
Epoch: 91 | Iteration number: [550/565] 97% | Training loss: 0.6880211735855449
Epoch: 91 | Iteration number: [560/565] 99% | Training loss: 0.6879867072616305

 End of epoch: 91 | Train Loss: 0.6867625143675677 | Training Time: 89 

 End of epoch: 91 | Eval Loss: 0.6893300414085388 | Evaluating Time: 6 
Epoch: 92 | Iteration number: [10/565] 1% | Training loss: 0.7556277394294739
Epoch: 92 | Iteration number: [20/565] 3% | Training loss: 0.7211749434471131
Epoch: 92 | Iteration number: [30/565] 5% | Training loss: 0.709725425640742
Epoch: 92 | Iteration number: [40/565] 7% | Training loss: 0.7039520353078842
Epoch: 92 | Iteration number: [50/565] 8% | Training loss: 0.7004826545715332
Epoch: 92 | Iteration number: [60/565] 10% | Training loss: 0.6981839170058568
Epoch: 92 | Iteration number: [70/565] 12% | Training loss: 0.6965239856924329
Epoch: 92 | Iteration number: [80/565] 14% | Training loss: 0.6953362613916397
Epoch: 92 | Iteration number: [90/565] 15% | Training loss: 0.6943734632598029
Epoch: 92 | Iteration number: [100/565] 17% | Training loss: 0.6936211746931076
Epoch: 92 | Iteration number: [110/565] 19% | Training loss: 0.6929527754133398
Epoch: 92 | Iteration number: [120/565] 21% | Training loss: 0.6924766133228938
Epoch: 92 | Iteration number: [130/565] 23% | Training loss: 0.6920406038944538
Epoch: 92 | Iteration number: [140/565] 24% | Training loss: 0.6916535594633647
Epoch: 92 | Iteration number: [150/565] 26% | Training loss: 0.6913128105799357
Epoch: 92 | Iteration number: [160/565] 28% | Training loss: 0.6910150986164808
Epoch: 92 | Iteration number: [170/565] 30% | Training loss: 0.6907468241803786
Epoch: 92 | Iteration number: [180/565] 31% | Training loss: 0.6905185441176097
Epoch: 92 | Iteration number: [190/565] 33% | Training loss: 0.6903232750139738
Epoch: 92 | Iteration number: [200/565] 35% | Training loss: 0.6901505830883979
Epoch: 92 | Iteration number: [210/565] 37% | Training loss: 0.6899948639529092
Epoch: 92 | Iteration number: [220/565] 38% | Training loss: 0.6898460393602198
Epoch: 92 | Iteration number: [230/565] 40% | Training loss: 0.689711213371028
Epoch: 92 | Iteration number: [240/565] 42% | Training loss: 0.689582567413648
Epoch: 92 | Iteration number: [250/565] 44% | Training loss: 0.6894802677631379
Epoch: 92 | Iteration number: [260/565] 46% | Training loss: 0.6893737024985827
Epoch: 92 | Iteration number: [270/565] 47% | Training loss: 0.6892738671214492
Epoch: 92 | Iteration number: [280/565] 49% | Training loss: 0.6891769477299281
Epoch: 92 | Iteration number: [290/565] 51% | Training loss: 0.6890825438088384
Epoch: 92 | Iteration number: [300/565] 53% | Training loss: 0.6890044426918029
Epoch: 92 | Iteration number: [310/565] 54% | Training loss: 0.688922203933039
Epoch: 92 | Iteration number: [320/565] 56% | Training loss: 0.6888563817366957
Epoch: 92 | Iteration number: [330/565] 58% | Training loss: 0.688791068575599
Epoch: 92 | Iteration number: [340/565] 60% | Training loss: 0.6887304881039787
Epoch: 92 | Iteration number: [350/565] 61% | Training loss: 0.6886799543244498
Epoch: 92 | Iteration number: [360/565] 63% | Training loss: 0.6886261812514729
Epoch: 92 | Iteration number: [370/565] 65% | Training loss: 0.6885703637793258
Epoch: 92 | Iteration number: [380/565] 67% | Training loss: 0.6885252103993768
Epoch: 92 | Iteration number: [390/565] 69% | Training loss: 0.6884821090942774
Epoch: 92 | Iteration number: [400/565] 70% | Training loss: 0.688446953445673
Epoch: 92 | Iteration number: [410/565] 72% | Training loss: 0.6883990274696815
Epoch: 92 | Iteration number: [420/565] 74% | Training loss: 0.6883728829168138
Epoch: 92 | Iteration number: [430/565] 76% | Training loss: 0.6883331962796144
Epoch: 92 | Iteration number: [440/565] 77% | Training loss: 0.6882914358919318
Epoch: 92 | Iteration number: [450/565] 79% | Training loss: 0.6882496636443668
Epoch: 92 | Iteration number: [460/565] 81% | Training loss: 0.6882272411947665
Epoch: 92 | Iteration number: [470/565] 83% | Training loss: 0.6881978674137846
Epoch: 92 | Iteration number: [480/565] 84% | Training loss: 0.6881672605872154
Epoch: 92 | Iteration number: [490/565] 86% | Training loss: 0.6881316666700402
Epoch: 92 | Iteration number: [500/565] 88% | Training loss: 0.6881060638427734
Epoch: 92 | Iteration number: [510/565] 90% | Training loss: 0.688078778514675
Epoch: 92 | Iteration number: [520/565] 92% | Training loss: 0.6880556719807478
Epoch: 92 | Iteration number: [530/565] 93% | Training loss: 0.6880398622098959
Epoch: 92 | Iteration number: [540/565] 95% | Training loss: 0.6880281846832346
Epoch: 92 | Iteration number: [550/565] 97% | Training loss: 0.6880026743628762
Epoch: 92 | Iteration number: [560/565] 99% | Training loss: 0.6879832121942725

 End of epoch: 92 | Train Loss: 0.6867606717928321 | Training Time: 89 

 End of epoch: 92 | Eval Loss: 0.6894279037203107 | Evaluating Time: 6 
Epoch: 93 | Iteration number: [10/565] 1% | Training loss: 0.7552993476390839
Epoch: 93 | Iteration number: [20/565] 3% | Training loss: 0.7208437770605087
Epoch: 93 | Iteration number: [30/565] 5% | Training loss: 0.709473168849945
Epoch: 93 | Iteration number: [40/565] 7% | Training loss: 0.7037378624081612
Epoch: 93 | Iteration number: [50/565] 8% | Training loss: 0.7003026747703552
Epoch: 93 | Iteration number: [60/565] 10% | Training loss: 0.6980161776145299
Epoch: 93 | Iteration number: [70/565] 12% | Training loss: 0.696411258833749
Epoch: 93 | Iteration number: [80/565] 14% | Training loss: 0.6952148973941803
Epoch: 93 | Iteration number: [90/565] 15% | Training loss: 0.6942867418130239
Epoch: 93 | Iteration number: [100/565] 17% | Training loss: 0.6935576742887497
Epoch: 93 | Iteration number: [110/565] 19% | Training loss: 0.6929623311216181
Epoch: 93 | Iteration number: [120/565] 21% | Training loss: 0.6924420709411303
Epoch: 93 | Iteration number: [130/565] 23% | Training loss: 0.6919740044153654
Epoch: 93 | Iteration number: [140/565] 24% | Training loss: 0.6916076294013432
Epoch: 93 | Iteration number: [150/565] 26% | Training loss: 0.6912676131725312
Epoch: 93 | Iteration number: [160/565] 28% | Training loss: 0.6909770540893078
Epoch: 93 | Iteration number: [170/565] 30% | Training loss: 0.6907426588675555
Epoch: 93 | Iteration number: [180/565] 31% | Training loss: 0.6905387341976166
Epoch: 93 | Iteration number: [190/565] 33% | Training loss: 0.6903491409201371
Epoch: 93 | Iteration number: [200/565] 35% | Training loss: 0.6901537963747978
Epoch: 93 | Iteration number: [210/565] 37% | Training loss: 0.6899749710446312
Epoch: 93 | Iteration number: [220/565] 38% | Training loss: 0.6898473742333325
Epoch: 93 | Iteration number: [230/565] 40% | Training loss: 0.689740881194239
Epoch: 93 | Iteration number: [240/565] 42% | Training loss: 0.6896235180397828
Epoch: 93 | Iteration number: [250/565] 44% | Training loss: 0.6894980156421662
Epoch: 93 | Iteration number: [260/565] 46% | Training loss: 0.6894019805468046
Epoch: 93 | Iteration number: [270/565] 47% | Training loss: 0.6892976014702409
Epoch: 93 | Iteration number: [280/565] 49% | Training loss: 0.6892101211207253
Epoch: 93 | Iteration number: [290/565] 51% | Training loss: 0.6891203837148074
Epoch: 93 | Iteration number: [300/565] 53% | Training loss: 0.6890524945656459
Epoch: 93 | Iteration number: [310/565] 54% | Training loss: 0.6889843258165544
Epoch: 93 | Iteration number: [320/565] 56% | Training loss: 0.6889078922569751
Epoch: 93 | Iteration number: [330/565] 58% | Training loss: 0.68883742202412
Epoch: 93 | Iteration number: [340/565] 60% | Training loss: 0.6887821215040544
Epoch: 93 | Iteration number: [350/565] 61% | Training loss: 0.6887252983025142
Epoch: 93 | Iteration number: [360/565] 63% | Training loss: 0.6886685378021664
Epoch: 93 | Iteration number: [370/565] 65% | Training loss: 0.688609715410181
Epoch: 93 | Iteration number: [380/565] 67% | Training loss: 0.6885717009243212
Epoch: 93 | Iteration number: [390/565] 69% | Training loss: 0.6885247328342535
Epoch: 93 | Iteration number: [400/565] 70% | Training loss: 0.6884808851778508
Epoch: 93 | Iteration number: [410/565] 72% | Training loss: 0.6884345047357606
Epoch: 93 | Iteration number: [420/565] 74% | Training loss: 0.6883908670573008
Epoch: 93 | Iteration number: [430/565] 76% | Training loss: 0.6883623386538306
Epoch: 93 | Iteration number: [440/565] 77% | Training loss: 0.6883171334862709
Epoch: 93 | Iteration number: [450/565] 79% | Training loss: 0.6882899665832519
Epoch: 93 | Iteration number: [460/565] 81% | Training loss: 0.6882569046124168
Epoch: 93 | Iteration number: [470/565] 83% | Training loss: 0.6882214238034918
Epoch: 93 | Iteration number: [480/565] 84% | Training loss: 0.6881898333628972
Epoch: 93 | Iteration number: [490/565] 86% | Training loss: 0.6881564645134672
Epoch: 93 | Iteration number: [500/565] 88% | Training loss: 0.6881251721382141
Epoch: 93 | Iteration number: [510/565] 90% | Training loss: 0.6881006522505891
Epoch: 93 | Iteration number: [520/565] 92% | Training loss: 0.688068246612182
Epoch: 93 | Iteration number: [530/565] 93% | Training loss: 0.6880424270090068
Epoch: 93 | Iteration number: [540/565] 95% | Training loss: 0.6880277324605871
Epoch: 93 | Iteration number: [550/565] 97% | Training loss: 0.6880087167566473
Epoch: 93 | Iteration number: [560/565] 99% | Training loss: 0.6879823462239334

 End of epoch: 93 | Train Loss: 0.6867619926950573 | Training Time: 89 

 End of epoch: 93 | Eval Loss: 0.6892832773072379 | Evaluating Time: 6 
Epoch: 94 | Iteration number: [10/565] 1% | Training loss: 0.7552044510841369
Epoch: 94 | Iteration number: [20/565] 3% | Training loss: 0.7209286034107208
Epoch: 94 | Iteration number: [30/565] 5% | Training loss: 0.7095909118652344
Epoch: 94 | Iteration number: [40/565] 7% | Training loss: 0.7038019195199012
Epoch: 94 | Iteration number: [50/565] 8% | Training loss: 0.7003567516803741
Epoch: 94 | Iteration number: [60/565] 10% | Training loss: 0.6980087657769521
Epoch: 94 | Iteration number: [70/565] 12% | Training loss: 0.6963732387338366
Epoch: 94 | Iteration number: [80/565] 14% | Training loss: 0.695192028582096
Epoch: 94 | Iteration number: [90/565] 15% | Training loss: 0.6942789130740695
Epoch: 94 | Iteration number: [100/565] 17% | Training loss: 0.6935324054956437
Epoch: 94 | Iteration number: [110/565] 19% | Training loss: 0.6929319506341761
Epoch: 94 | Iteration number: [120/565] 21% | Training loss: 0.6923911834756533
Epoch: 94 | Iteration number: [130/565] 23% | Training loss: 0.6919638665822836
Epoch: 94 | Iteration number: [140/565] 24% | Training loss: 0.6915959107024329
Epoch: 94 | Iteration number: [150/565] 26% | Training loss: 0.691287655433019
Epoch: 94 | Iteration number: [160/565] 28% | Training loss: 0.6910118401050568
Epoch: 94 | Iteration number: [170/565] 30% | Training loss: 0.6907665277228636
Epoch: 94 | Iteration number: [180/565] 31% | Training loss: 0.6905306071043015
Epoch: 94 | Iteration number: [190/565] 33% | Training loss: 0.690318298967261
Epoch: 94 | Iteration number: [200/565] 35% | Training loss: 0.6901477992534637
Epoch: 94 | Iteration number: [210/565] 37% | Training loss: 0.6899948318799337
Epoch: 94 | Iteration number: [220/565] 38% | Training loss: 0.6898569892753255
Epoch: 94 | Iteration number: [230/565] 40% | Training loss: 0.6897171142308608
Epoch: 94 | Iteration number: [240/565] 42% | Training loss: 0.6895876469711463
Epoch: 94 | Iteration number: [250/565] 44% | Training loss: 0.6894764716625214
Epoch: 94 | Iteration number: [260/565] 46% | Training loss: 0.6893616825342178
Epoch: 94 | Iteration number: [270/565] 47% | Training loss: 0.6892591604480037
Epoch: 94 | Iteration number: [280/565] 49% | Training loss: 0.6891515003783363
Epoch: 94 | Iteration number: [290/565] 51% | Training loss: 0.68907241060816
Epoch: 94 | Iteration number: [300/565] 53% | Training loss: 0.689011491338412
Epoch: 94 | Iteration number: [310/565] 54% | Training loss: 0.6889461521179445
Epoch: 94 | Iteration number: [320/565] 56% | Training loss: 0.6888789087533951
Epoch: 94 | Iteration number: [330/565] 58% | Training loss: 0.6888161102930704
Epoch: 94 | Iteration number: [340/565] 60% | Training loss: 0.6887670611633974
Epoch: 94 | Iteration number: [350/565] 61% | Training loss: 0.6887067583629063
Epoch: 94 | Iteration number: [360/565] 63% | Training loss: 0.6886718435419931
Epoch: 94 | Iteration number: [370/565] 65% | Training loss: 0.6886198034157625
Epoch: 94 | Iteration number: [380/565] 67% | Training loss: 0.6885719544009159
Epoch: 94 | Iteration number: [390/565] 69% | Training loss: 0.6885319384244772
Epoch: 94 | Iteration number: [400/565] 70% | Training loss: 0.6884911566972732
Epoch: 94 | Iteration number: [410/565] 72% | Training loss: 0.6884486502263604
Epoch: 94 | Iteration number: [420/565] 74% | Training loss: 0.6884069266773406
Epoch: 94 | Iteration number: [430/565] 76% | Training loss: 0.6883793696414593
Epoch: 94 | Iteration number: [440/565] 77% | Training loss: 0.6883313770998608
Epoch: 94 | Iteration number: [450/565] 79% | Training loss: 0.6883135069741143
Epoch: 94 | Iteration number: [460/565] 81% | Training loss: 0.6882744282484055
Epoch: 94 | Iteration number: [470/565] 83% | Training loss: 0.6882342186379939
Epoch: 94 | Iteration number: [480/565] 84% | Training loss: 0.6882075446347395
Epoch: 94 | Iteration number: [490/565] 86% | Training loss: 0.6881771559617957
Epoch: 94 | Iteration number: [500/565] 88% | Training loss: 0.6881521852016449
Epoch: 94 | Iteration number: [510/565] 90% | Training loss: 0.6881169831051546
Epoch: 94 | Iteration number: [520/565] 92% | Training loss: 0.6880860061599658
Epoch: 94 | Iteration number: [530/565] 93% | Training loss: 0.6880594562809422
Epoch: 94 | Iteration number: [540/565] 95% | Training loss: 0.6880324543626221
Epoch: 94 | Iteration number: [550/565] 97% | Training loss: 0.6880093241821635
Epoch: 94 | Iteration number: [560/565] 99% | Training loss: 0.6879852156553949

 End of epoch: 94 | Train Loss: 0.6867660145843979 | Training Time: 90 

 End of epoch: 94 | Eval Loss: 0.6888872555324009 | Evaluating Time: 6 
Epoch: 95 | Iteration number: [10/565] 1% | Training loss: 0.7556528151035309
Epoch: 95 | Iteration number: [20/565] 3% | Training loss: 0.7213315099477768
Epoch: 95 | Iteration number: [30/565] 5% | Training loss: 0.7097342848777771
Epoch: 95 | Iteration number: [40/565] 7% | Training loss: 0.7040101334452629
Epoch: 95 | Iteration number: [50/565] 8% | Training loss: 0.7006044006347656
Epoch: 95 | Iteration number: [60/565] 10% | Training loss: 0.6982881913582484
Epoch: 95 | Iteration number: [70/565] 12% | Training loss: 0.6967083641460964
Epoch: 95 | Iteration number: [80/565] 14% | Training loss: 0.6954609714448452
Epoch: 95 | Iteration number: [90/565] 15% | Training loss: 0.6944595621691809
Epoch: 95 | Iteration number: [100/565] 17% | Training loss: 0.6936527818441391
Epoch: 95 | Iteration number: [110/565] 19% | Training loss: 0.6930195206945593
Epoch: 95 | Iteration number: [120/565] 21% | Training loss: 0.6924991652369499
Epoch: 95 | Iteration number: [130/565] 23% | Training loss: 0.692065561734713
Epoch: 95 | Iteration number: [140/565] 24% | Training loss: 0.691744721361569
Epoch: 95 | Iteration number: [150/565] 26% | Training loss: 0.6913915737469991
Epoch: 95 | Iteration number: [160/565] 28% | Training loss: 0.6911221720278263
Epoch: 95 | Iteration number: [170/565] 30% | Training loss: 0.6908597953179303
Epoch: 95 | Iteration number: [180/565] 31% | Training loss: 0.6906181782484054
Epoch: 95 | Iteration number: [190/565] 33% | Training loss: 0.6904144676108109
Epoch: 95 | Iteration number: [200/565] 35% | Training loss: 0.6902390259504319
Epoch: 95 | Iteration number: [210/565] 37% | Training loss: 0.6901165607429686
Epoch: 95 | Iteration number: [220/565] 38% | Training loss: 0.6899521854790774
Epoch: 95 | Iteration number: [230/565] 40% | Training loss: 0.6898216403048971
Epoch: 95 | Iteration number: [240/565] 42% | Training loss: 0.6897021050254504
Epoch: 95 | Iteration number: [250/565] 44% | Training loss: 0.6895787880420685
Epoch: 95 | Iteration number: [260/565] 46% | Training loss: 0.689484132711704
Epoch: 95 | Iteration number: [270/565] 47% | Training loss: 0.6893827848964267
Epoch: 95 | Iteration number: [280/565] 49% | Training loss: 0.6892904613699232
Epoch: 95 | Iteration number: [290/565] 51% | Training loss: 0.6891941796089041
Epoch: 95 | Iteration number: [300/565] 53% | Training loss: 0.6891127723455429
Epoch: 95 | Iteration number: [310/565] 54% | Training loss: 0.6890390046181217
Epoch: 95 | Iteration number: [320/565] 56% | Training loss: 0.6889512354508043
Epoch: 95 | Iteration number: [330/565] 58% | Training loss: 0.6888802595210798
Epoch: 95 | Iteration number: [340/565] 60% | Training loss: 0.6888161443612155
Epoch: 95 | Iteration number: [350/565] 61% | Training loss: 0.6887560491902488
Epoch: 95 | Iteration number: [360/565] 63% | Training loss: 0.6886935700972875
Epoch: 95 | Iteration number: [370/565] 65% | Training loss: 0.688638503809233
Epoch: 95 | Iteration number: [380/565] 67% | Training loss: 0.6885982842821824
Epoch: 95 | Iteration number: [390/565] 69% | Training loss: 0.6885525552126077
Epoch: 95 | Iteration number: [400/565] 70% | Training loss: 0.6884957566857338
Epoch: 95 | Iteration number: [410/565] 72% | Training loss: 0.6884597077602294
Epoch: 95 | Iteration number: [420/565] 74% | Training loss: 0.6884101581005823
Epoch: 95 | Iteration number: [430/565] 76% | Training loss: 0.6883746252503506
Epoch: 95 | Iteration number: [440/565] 77% | Training loss: 0.6883405973965472
Epoch: 95 | Iteration number: [450/565] 79% | Training loss: 0.6882981937461429
Epoch: 95 | Iteration number: [460/565] 81% | Training loss: 0.6882583607798037
Epoch: 95 | Iteration number: [470/565] 83% | Training loss: 0.6882279938839851
Epoch: 95 | Iteration number: [480/565] 84% | Training loss: 0.6881972779830297
Epoch: 95 | Iteration number: [490/565] 86% | Training loss: 0.6881664906229291
Epoch: 95 | Iteration number: [500/565] 88% | Training loss: 0.6881314734220505
Epoch: 95 | Iteration number: [510/565] 90% | Training loss: 0.6881127962879107
Epoch: 95 | Iteration number: [520/565] 92% | Training loss: 0.6880832441724264
Epoch: 95 | Iteration number: [530/565] 93% | Training loss: 0.6880608024462214
Epoch: 95 | Iteration number: [540/565] 95% | Training loss: 0.6880431206138046
Epoch: 95 | Iteration number: [550/565] 97% | Training loss: 0.6880147748643701
Epoch: 95 | Iteration number: [560/565] 99% | Training loss: 0.6879956997931004

 End of epoch: 95 | Train Loss: 0.686766008360196 | Training Time: 89 

 End of epoch: 95 | Eval Loss: 0.6889475243432182 | Evaluating Time: 6 
Epoch: 96 | Iteration number: [10/565] 1% | Training loss: 0.7551384568214417
Epoch: 96 | Iteration number: [20/565] 3% | Training loss: 0.7209601074457168
Epoch: 96 | Iteration number: [30/565] 5% | Training loss: 0.7094564219315846
Epoch: 96 | Iteration number: [40/565] 7% | Training loss: 0.7037323892116547
Epoch: 96 | Iteration number: [50/565] 8% | Training loss: 0.7003675901889801
Epoch: 96 | Iteration number: [60/565] 10% | Training loss: 0.6980888942877451
Epoch: 96 | Iteration number: [70/565] 12% | Training loss: 0.6964662458215441
Epoch: 96 | Iteration number: [80/565] 14% | Training loss: 0.6952285788953304
Epoch: 96 | Iteration number: [90/565] 15% | Training loss: 0.6942902565002441
Epoch: 96 | Iteration number: [100/565] 17% | Training loss: 0.6935405176877976
Epoch: 96 | Iteration number: [110/565] 19% | Training loss: 0.6929171508008783
Epoch: 96 | Iteration number: [120/565] 21% | Training loss: 0.6924639582633972
Epoch: 96 | Iteration number: [130/565] 23% | Training loss: 0.6919928280206827
Epoch: 96 | Iteration number: [140/565] 24% | Training loss: 0.6916458968605314
Epoch: 96 | Iteration number: [150/565] 26% | Training loss: 0.691335813999176
Epoch: 96 | Iteration number: [160/565] 28% | Training loss: 0.6910441033542156
Epoch: 96 | Iteration number: [170/565] 30% | Training loss: 0.6907896196140962
Epoch: 96 | Iteration number: [180/565] 31% | Training loss: 0.6905553357468711
Epoch: 96 | Iteration number: [190/565] 33% | Training loss: 0.6903753117511147
Epoch: 96 | Iteration number: [200/565] 35% | Training loss: 0.69017259567976
Epoch: 96 | Iteration number: [210/565] 37% | Training loss: 0.6900068010602679
Epoch: 96 | Iteration number: [220/565] 38% | Training loss: 0.6898586844856088
Epoch: 96 | Iteration number: [230/565] 40% | Training loss: 0.6897192278633947
Epoch: 96 | Iteration number: [240/565] 42% | Training loss: 0.6896004383762677
Epoch: 96 | Iteration number: [250/565] 44% | Training loss: 0.6894876682758331
Epoch: 96 | Iteration number: [260/565] 46% | Training loss: 0.6893746770345248
Epoch: 96 | Iteration number: [270/565] 47% | Training loss: 0.6892741006833536
Epoch: 96 | Iteration number: [280/565] 49% | Training loss: 0.6891839204089982
Epoch: 96 | Iteration number: [290/565] 51% | Training loss: 0.6891050256531814
Epoch: 96 | Iteration number: [300/565] 53% | Training loss: 0.6890297736724218
Epoch: 96 | Iteration number: [310/565] 54% | Training loss: 0.6889704629298179
Epoch: 96 | Iteration number: [320/565] 56% | Training loss: 0.6888942299410701
Epoch: 96 | Iteration number: [330/565] 58% | Training loss: 0.6888252063231035
Epoch: 96 | Iteration number: [340/565] 60% | Training loss: 0.6887647127403932
Epoch: 96 | Iteration number: [350/565] 61% | Training loss: 0.6887189487048558
Epoch: 96 | Iteration number: [360/565] 63% | Training loss: 0.6886686558524767
Epoch: 96 | Iteration number: [370/565] 65% | Training loss: 0.6886164697440895
Epoch: 96 | Iteration number: [380/565] 67% | Training loss: 0.6885599699459578
Epoch: 96 | Iteration number: [390/565] 69% | Training loss: 0.6885119508474301
Epoch: 96 | Iteration number: [400/565] 70% | Training loss: 0.6884780913591385
Epoch: 96 | Iteration number: [410/565] 72% | Training loss: 0.6884315862888243
Epoch: 96 | Iteration number: [420/565] 74% | Training loss: 0.6883832490160352
Epoch: 96 | Iteration number: [430/565] 76% | Training loss: 0.688346473006315
Epoch: 96 | Iteration number: [440/565] 77% | Training loss: 0.6883114920421081
Epoch: 96 | Iteration number: [450/565] 79% | Training loss: 0.6882746907075247
Epoch: 96 | Iteration number: [460/565] 81% | Training loss: 0.6882354852945908
Epoch: 96 | Iteration number: [470/565] 83% | Training loss: 0.6882086932659149
Epoch: 96 | Iteration number: [480/565] 84% | Training loss: 0.68818652232488
Epoch: 96 | Iteration number: [490/565] 86% | Training loss: 0.6881526236631432
Epoch: 96 | Iteration number: [500/565] 88% | Training loss: 0.6881276882886886
Epoch: 96 | Iteration number: [510/565] 90% | Training loss: 0.6881004966941534
Epoch: 96 | Iteration number: [520/565] 92% | Training loss: 0.6880795479967043
Epoch: 96 | Iteration number: [530/565] 93% | Training loss: 0.6880534679259894
Epoch: 96 | Iteration number: [540/565] 95% | Training loss: 0.6880374281494706
Epoch: 96 | Iteration number: [550/565] 97% | Training loss: 0.6880092360756614
Epoch: 96 | Iteration number: [560/565] 99% | Training loss: 0.6879933793629919

 End of epoch: 96 | Train Loss: 0.6867686435184648 | Training Time: 89 

 End of epoch: 96 | Eval Loss: 0.6885157142366681 | Evaluating Time: 6 
Epoch: 97 | Iteration number: [10/565] 1% | Training loss: 0.7550109148025512
Epoch: 97 | Iteration number: [20/565] 3% | Training loss: 0.72094566822052
Epoch: 97 | Iteration number: [30/565] 5% | Training loss: 0.70942475994428
Epoch: 97 | Iteration number: [40/565] 7% | Training loss: 0.7038167312741279
Epoch: 97 | Iteration number: [50/565] 8% | Training loss: 0.7003730750083923
Epoch: 97 | Iteration number: [60/565] 10% | Training loss: 0.6981234600146612
Epoch: 97 | Iteration number: [70/565] 12% | Training loss: 0.6964914287839618
Epoch: 97 | Iteration number: [80/565] 14% | Training loss: 0.6953028492629528
Epoch: 97 | Iteration number: [90/565] 15% | Training loss: 0.6943874597549439
Epoch: 97 | Iteration number: [100/565] 17% | Training loss: 0.693621707558632
Epoch: 97 | Iteration number: [110/565] 19% | Training loss: 0.6929911201650446
Epoch: 97 | Iteration number: [120/565] 21% | Training loss: 0.6925002947449684
Epoch: 97 | Iteration number: [130/565] 23% | Training loss: 0.6920424864842342
Epoch: 97 | Iteration number: [140/565] 24% | Training loss: 0.6916404225996562
Epoch: 97 | Iteration number: [150/565] 26% | Training loss: 0.6913179500897726
Epoch: 97 | Iteration number: [160/565] 28% | Training loss: 0.6910413946956396
Epoch: 97 | Iteration number: [170/565] 30% | Training loss: 0.6908102459767286
Epoch: 97 | Iteration number: [180/565] 31% | Training loss: 0.6905734552277459
Epoch: 97 | Iteration number: [190/565] 33% | Training loss: 0.6903914740211086
Epoch: 97 | Iteration number: [200/565] 35% | Training loss: 0.6902160027623176
Epoch: 97 | Iteration number: [210/565] 37% | Training loss: 0.6900547214916775
Epoch: 97 | Iteration number: [220/565] 38% | Training loss: 0.6899027637460015
Epoch: 97 | Iteration number: [230/565] 40% | Training loss: 0.6897431321766065
Epoch: 97 | Iteration number: [240/565] 42% | Training loss: 0.6896318480372429
Epoch: 97 | Iteration number: [250/565] 44% | Training loss: 0.6895171830654144
Epoch: 97 | Iteration number: [260/565] 46% | Training loss: 0.6894189866689535
Epoch: 97 | Iteration number: [270/565] 47% | Training loss: 0.6893248176133191
Epoch: 97 | Iteration number: [280/565] 49% | Training loss: 0.6892382340771811
Epoch: 97 | Iteration number: [290/565] 51% | Training loss: 0.689148343842605
Epoch: 97 | Iteration number: [300/565] 53% | Training loss: 0.6890735125541687
Epoch: 97 | Iteration number: [310/565] 54% | Training loss: 0.6889941734652365
Epoch: 97 | Iteration number: [320/565] 56% | Training loss: 0.6889263387769461
Epoch: 97 | Iteration number: [330/565] 58% | Training loss: 0.6888618136897232
Epoch: 97 | Iteration number: [340/565] 60% | Training loss: 0.6887924431001439
Epoch: 97 | Iteration number: [350/565] 61% | Training loss: 0.68873816881861
Epoch: 97 | Iteration number: [360/565] 63% | Training loss: 0.6886778626177046
Epoch: 97 | Iteration number: [370/565] 65% | Training loss: 0.6886384775509705
Epoch: 97 | Iteration number: [380/565] 67% | Training loss: 0.6886012789450193
Epoch: 97 | Iteration number: [390/565] 69% | Training loss: 0.6885615756878486
Epoch: 97 | Iteration number: [400/565] 70% | Training loss: 0.6885236839950085
Epoch: 97 | Iteration number: [410/565] 72% | Training loss: 0.6884790320221971
Epoch: 97 | Iteration number: [420/565] 74% | Training loss: 0.6884450158902577
Epoch: 97 | Iteration number: [430/565] 76% | Training loss: 0.6884055290111276
Epoch: 97 | Iteration number: [440/565] 77% | Training loss: 0.6883601777932861
Epoch: 97 | Iteration number: [450/565] 79% | Training loss: 0.6883301341533661
Epoch: 97 | Iteration number: [460/565] 81% | Training loss: 0.6882977921029796
Epoch: 97 | Iteration number: [470/565] 83% | Training loss: 0.6882655884357209
Epoch: 97 | Iteration number: [480/565] 84% | Training loss: 0.688232085108757
Epoch: 97 | Iteration number: [490/565] 86% | Training loss: 0.6881994484638682
Epoch: 97 | Iteration number: [500/565] 88% | Training loss: 0.6881734702587128
Epoch: 97 | Iteration number: [510/565] 90% | Training loss: 0.6881420065374936
Epoch: 97 | Iteration number: [520/565] 92% | Training loss: 0.6881079928233074
Epoch: 97 | Iteration number: [530/565] 93% | Training loss: 0.6880750296250829
Epoch: 97 | Iteration number: [540/565] 95% | Training loss: 0.68805576827791
Epoch: 97 | Iteration number: [550/565] 97% | Training loss: 0.6880284049294212
Epoch: 97 | Iteration number: [560/565] 99% | Training loss: 0.6880017912813595

 End of epoch: 97 | Train Loss: 0.6867729765124025 | Training Time: 90 

 End of epoch: 97 | Eval Loss: 0.6893716284206935 | Evaluating Time: 6 
Epoch: 98 | Iteration number: [10/565] 1% | Training loss: 0.7553587675094604
Epoch: 98 | Iteration number: [20/565] 3% | Training loss: 0.7208745121955872
Epoch: 98 | Iteration number: [30/565] 5% | Training loss: 0.7094803750514984
Epoch: 98 | Iteration number: [40/565] 7% | Training loss: 0.703906475007534
Epoch: 98 | Iteration number: [50/565] 8% | Training loss: 0.7004657161235809
Epoch: 98 | Iteration number: [60/565] 10% | Training loss: 0.6982167015473048
Epoch: 98 | Iteration number: [70/565] 12% | Training loss: 0.6965509661606379
Epoch: 98 | Iteration number: [80/565] 14% | Training loss: 0.695310814678669
Epoch: 98 | Iteration number: [90/565] 15% | Training loss: 0.6943735851181878
Epoch: 98 | Iteration number: [100/565] 17% | Training loss: 0.693630103468895
Epoch: 98 | Iteration number: [110/565] 19% | Training loss: 0.693060471794822
Epoch: 98 | Iteration number: [120/565] 21% | Training loss: 0.6925443132718404
Epoch: 98 | Iteration number: [130/565] 23% | Training loss: 0.6920926415003263
Epoch: 98 | Iteration number: [140/565] 24% | Training loss: 0.6917372941970825
Epoch: 98 | Iteration number: [150/565] 26% | Training loss: 0.6913795367876688
Epoch: 98 | Iteration number: [160/565] 28% | Training loss: 0.6910881396383047
Epoch: 98 | Iteration number: [170/565] 30% | Training loss: 0.6908072752111099
Epoch: 98 | Iteration number: [180/565] 31% | Training loss: 0.6905713803238339
Epoch: 98 | Iteration number: [190/565] 33% | Training loss: 0.6903821223660519
Epoch: 98 | Iteration number: [200/565] 35% | Training loss: 0.6902137476205826
Epoch: 98 | Iteration number: [210/565] 37% | Training loss: 0.6900613685448964
Epoch: 98 | Iteration number: [220/565] 38% | Training loss: 0.6899204115975986
Epoch: 98 | Iteration number: [230/565] 40% | Training loss: 0.6897947772689488
Epoch: 98 | Iteration number: [240/565] 42% | Training loss: 0.6896804178754489
Epoch: 98 | Iteration number: [250/565] 44% | Training loss: 0.689568564414978
Epoch: 98 | Iteration number: [260/565] 46% | Training loss: 0.6894549787044525
Epoch: 98 | Iteration number: [270/565] 47% | Training loss: 0.6893600040011936
Epoch: 98 | Iteration number: [280/565] 49% | Training loss: 0.6892744779586792
Epoch: 98 | Iteration number: [290/565] 51% | Training loss: 0.6891840554516891
Epoch: 98 | Iteration number: [300/565] 53% | Training loss: 0.6891041433811188
Epoch: 98 | Iteration number: [310/565] 54% | Training loss: 0.6890267070262662
Epoch: 98 | Iteration number: [320/565] 56% | Training loss: 0.688947344198823
Epoch: 98 | Iteration number: [330/565] 58% | Training loss: 0.6888796721443985
Epoch: 98 | Iteration number: [340/565] 60% | Training loss: 0.6888079341720132
Epoch: 98 | Iteration number: [350/565] 61% | Training loss: 0.6887443222318377
Epoch: 98 | Iteration number: [360/565] 63% | Training loss: 0.6886853441596031
Epoch: 98 | Iteration number: [370/565] 65% | Training loss: 0.6886384904384613
Epoch: 98 | Iteration number: [380/565] 67% | Training loss: 0.6886040569920289
Epoch: 98 | Iteration number: [390/565] 69% | Training loss: 0.688561054223623
Epoch: 98 | Iteration number: [400/565] 70% | Training loss: 0.6885152299702167
Epoch: 98 | Iteration number: [410/565] 72% | Training loss: 0.6884778184134785
Epoch: 98 | Iteration number: [420/565] 74% | Training loss: 0.6884362944534846
Epoch: 98 | Iteration number: [430/565] 76% | Training loss: 0.6884157890497252
Epoch: 98 | Iteration number: [440/565] 77% | Training loss: 0.6883685476400635
Epoch: 98 | Iteration number: [450/565] 79% | Training loss: 0.6883327141073015
Epoch: 98 | Iteration number: [460/565] 81% | Training loss: 0.6882909237042717
Epoch: 98 | Iteration number: [470/565] 83% | Training loss: 0.6882651587750049
Epoch: 98 | Iteration number: [480/565] 84% | Training loss: 0.6882360018789768
Epoch: 98 | Iteration number: [490/565] 86% | Training loss: 0.6882079087958044
Epoch: 98 | Iteration number: [500/565] 88% | Training loss: 0.688165265917778
Epoch: 98 | Iteration number: [510/565] 90% | Training loss: 0.6881390743395861
Epoch: 98 | Iteration number: [520/565] 92% | Training loss: 0.6881109098975475
Epoch: 98 | Iteration number: [530/565] 93% | Training loss: 0.6880812124261316
Epoch: 98 | Iteration number: [540/565] 95% | Training loss: 0.6880456454224056
Epoch: 98 | Iteration number: [550/565] 97% | Training loss: 0.688018581867218
Epoch: 98 | Iteration number: [560/565] 99% | Training loss: 0.6879945985972882

 End of epoch: 98 | Train Loss: 0.6867702198239555 | Training Time: 89 

 End of epoch: 98 | Eval Loss: 0.68943704026086 | Evaluating Time: 6 
Epoch: 99 | Iteration number: [10/565] 1% | Training loss: 0.755844634771347
Epoch: 99 | Iteration number: [20/565] 3% | Training loss: 0.7212943881750107
Epoch: 99 | Iteration number: [30/565] 5% | Training loss: 0.7098577519257864
Epoch: 99 | Iteration number: [40/565] 7% | Training loss: 0.7041817739605903
Epoch: 99 | Iteration number: [50/565] 8% | Training loss: 0.7007382571697235
Epoch: 99 | Iteration number: [60/565] 10% | Training loss: 0.6983640919129054
Epoch: 99 | Iteration number: [70/565] 12% | Training loss: 0.6966878277914864
Epoch: 99 | Iteration number: [80/565] 14% | Training loss: 0.6954067774116993
Epoch: 99 | Iteration number: [90/565] 15% | Training loss: 0.6944102492597368
Epoch: 99 | Iteration number: [100/565] 17% | Training loss: 0.6936379337310791
Epoch: 99 | Iteration number: [110/565] 19% | Training loss: 0.6930174410343171
Epoch: 99 | Iteration number: [120/565] 21% | Training loss: 0.6924799983700116
Epoch: 99 | Iteration number: [130/565] 23% | Training loss: 0.6920174956321716
Epoch: 99 | Iteration number: [140/565] 24% | Training loss: 0.691657787987164
Epoch: 99 | Iteration number: [150/565] 26% | Training loss: 0.6913597679138184
Epoch: 99 | Iteration number: [160/565] 28% | Training loss: 0.6910765685141087
Epoch: 99 | Iteration number: [170/565] 30% | Training loss: 0.6908058510107152
Epoch: 99 | Iteration number: [180/565] 31% | Training loss: 0.6905527210897869
Epoch: 99 | Iteration number: [190/565] 33% | Training loss: 0.6903248934369338
Epoch: 99 | Iteration number: [200/565] 35% | Training loss: 0.690149929523468
Epoch: 99 | Iteration number: [210/565] 37% | Training loss: 0.6899844396682012
Epoch: 99 | Iteration number: [220/565] 38% | Training loss: 0.689813763445074
Epoch: 99 | Iteration number: [230/565] 40% | Training loss: 0.6896775984245798
Epoch: 99 | Iteration number: [240/565] 42% | Training loss: 0.689572116235892
Epoch: 99 | Iteration number: [250/565] 44% | Training loss: 0.6894560475349426
Epoch: 99 | Iteration number: [260/565] 46% | Training loss: 0.689336986037401
Epoch: 99 | Iteration number: [270/565] 47% | Training loss: 0.6892314630526083
Epoch: 99 | Iteration number: [280/565] 49% | Training loss: 0.6891405693122319
Epoch: 99 | Iteration number: [290/565] 51% | Training loss: 0.6890772137148627
Epoch: 99 | Iteration number: [300/565] 53% | Training loss: 0.6890156126022339
Epoch: 99 | Iteration number: [310/565] 54% | Training loss: 0.6889508189693574
Epoch: 99 | Iteration number: [320/565] 56% | Training loss: 0.688890234194696
Epoch: 99 | Iteration number: [330/565] 58% | Training loss: 0.6888240584821412
Epoch: 99 | Iteration number: [340/565] 60% | Training loss: 0.6887609473046135
Epoch: 99 | Iteration number: [350/565] 61% | Training loss: 0.6887075899328504
Epoch: 99 | Iteration number: [360/565] 63% | Training loss: 0.6886544252435366
Epoch: 99 | Iteration number: [370/565] 65% | Training loss: 0.6886099564062582
Epoch: 99 | Iteration number: [380/565] 67% | Training loss: 0.6885560953303387
Epoch: 99 | Iteration number: [390/565] 69% | Training loss: 0.6885201750657497
Epoch: 99 | Iteration number: [400/565] 70% | Training loss: 0.688480181992054
Epoch: 99 | Iteration number: [410/565] 72% | Training loss: 0.6884464431099775
Epoch: 99 | Iteration number: [420/565] 74% | Training loss: 0.688409559357734
Epoch: 99 | Iteration number: [430/565] 76% | Training loss: 0.688379321819128
Epoch: 99 | Iteration number: [440/565] 77% | Training loss: 0.6883427312428301
Epoch: 99 | Iteration number: [450/565] 79% | Training loss: 0.6883003205723233
Epoch: 99 | Iteration number: [460/565] 81% | Training loss: 0.6882671306962552
Epoch: 99 | Iteration number: [470/565] 83% | Training loss: 0.6882418972380617
Epoch: 99 | Iteration number: [480/565] 84% | Training loss: 0.6882039780418078
Epoch: 99 | Iteration number: [490/565] 86% | Training loss: 0.6881676858785201
Epoch: 99 | Iteration number: [500/565] 88% | Training loss: 0.6881379222869873
Epoch: 99 | Iteration number: [510/565] 90% | Training loss: 0.6881142154628155
Epoch: 99 | Iteration number: [520/565] 92% | Training loss: 0.6880898978847724
Epoch: 99 | Iteration number: [530/565] 93% | Training loss: 0.688061790983632
Epoch: 99 | Iteration number: [540/565] 95% | Training loss: 0.6880280144788601
Epoch: 99 | Iteration number: [550/565] 97% | Training loss: 0.687999834689227
Epoch: 99 | Iteration number: [560/565] 99% | Training loss: 0.6879839223410402

 End of epoch: 99 | Train Loss: 0.6867575302588201 | Training Time: 89 

 End of epoch: 99 | Eval Loss: 0.688662052154541 | Evaluating Time: 6 
Epoch: 100 | Iteration number: [10/565] 1% | Training loss: 0.7555930078029632
Epoch: 100 | Iteration number: [20/565] 3% | Training loss: 0.7211965560913086
Epoch: 100 | Iteration number: [30/565] 5% | Training loss: 0.7097669680913289
Epoch: 100 | Iteration number: [40/565] 7% | Training loss: 0.7041039764881134
Epoch: 100 | Iteration number: [50/565] 8% | Training loss: 0.7006432008743286
Epoch: 100 | Iteration number: [60/565] 10% | Training loss: 0.6983604808648427
Epoch: 100 | Iteration number: [70/565] 12% | Training loss: 0.696687366281237
Epoch: 100 | Iteration number: [80/565] 14% | Training loss: 0.6953800708055496
Epoch: 100 | Iteration number: [90/565] 15% | Training loss: 0.6943755520714654
Epoch: 100 | Iteration number: [100/565] 17% | Training loss: 0.6936164927482605
Epoch: 100 | Iteration number: [110/565] 19% | Training loss: 0.6929810789498416
Epoch: 100 | Iteration number: [120/565] 21% | Training loss: 0.6924238175153732
Epoch: 100 | Iteration number: [130/565] 23% | Training loss: 0.6919934726678408
Epoch: 100 | Iteration number: [140/565] 24% | Training loss: 0.6916058740445545
Epoch: 100 | Iteration number: [150/565] 26% | Training loss: 0.6912878839174906
Epoch: 100 | Iteration number: [160/565] 28% | Training loss: 0.691002544388175
Epoch: 100 | Iteration number: [170/565] 30% | Training loss: 0.69074466473916
Epoch: 100 | Iteration number: [180/565] 31% | Training loss: 0.6905112769868639
Epoch: 100 | Iteration number: [190/565] 33% | Training loss: 0.6903223037719727
Epoch: 100 | Iteration number: [200/565] 35% | Training loss: 0.6901424837112426
Epoch: 100 | Iteration number: [210/565] 37% | Training loss: 0.6899925160975683
Epoch: 100 | Iteration number: [220/565] 38% | Training loss: 0.6898432972756299
Epoch: 100 | Iteration number: [230/565] 40% | Training loss: 0.6897274527860724
Epoch: 100 | Iteration number: [240/565] 42% | Training loss: 0.6896026072402796
Epoch: 100 | Iteration number: [250/565] 44% | Training loss: 0.689498776435852
Epoch: 100 | Iteration number: [260/565] 46% | Training loss: 0.6893900692462921
Epoch: 100 | Iteration number: [270/565] 47% | Training loss: 0.689286012340475
Epoch: 100 | Iteration number: [280/565] 49% | Training loss: 0.6892005039112908
Epoch: 100 | Iteration number: [290/565] 51% | Training loss: 0.6891036740664778
Epoch: 100 | Iteration number: [300/565] 53% | Training loss: 0.6890317777792613
Epoch: 100 | Iteration number: [310/565] 54% | Training loss: 0.6889508183925382
Epoch: 100 | Iteration number: [320/565] 56% | Training loss: 0.688858650997281
Epoch: 100 | Iteration number: [330/565] 58% | Training loss: 0.6888039650339068
Epoch: 100 | Iteration number: [340/565] 60% | Training loss: 0.6887508616727941
Epoch: 100 | Iteration number: [350/565] 61% | Training loss: 0.6886916422843933
Epoch: 100 | Iteration number: [360/565] 63% | Training loss: 0.6886330392625597
Epoch: 100 | Iteration number: [370/565] 65% | Training loss: 0.6885991837527301
Epoch: 100 | Iteration number: [380/565] 67% | Training loss: 0.6885487211377997
Epoch: 100 | Iteration number: [390/565] 69% | Training loss: 0.6885018943211971
Epoch: 100 | Iteration number: [400/565] 70% | Training loss: 0.6884640035033226
Epoch: 100 | Iteration number: [410/565] 72% | Training loss: 0.6884308604205527
Epoch: 100 | Iteration number: [420/565] 74% | Training loss: 0.6883939582677114
Epoch: 100 | Iteration number: [430/565] 76% | Training loss: 0.6883570350879846
Epoch: 100 | Iteration number: [440/565] 77% | Training loss: 0.6883274310014464
Epoch: 100 | Iteration number: [450/565] 79% | Training loss: 0.6882970448335012
Epoch: 100 | Iteration number: [460/565] 81% | Training loss: 0.6882688594901043
Epoch: 100 | Iteration number: [470/565] 83% | Training loss: 0.6882319879024587
Epoch: 100 | Iteration number: [480/565] 84% | Training loss: 0.6882045995444059
Epoch: 100 | Iteration number: [490/565] 86% | Training loss: 0.6881739520296759
Epoch: 100 | Iteration number: [500/565] 88% | Training loss: 0.6881453754901886
Epoch: 100 | Iteration number: [510/565] 90% | Training loss: 0.6881215684554156
Epoch: 100 | Iteration number: [520/565] 92% | Training loss: 0.6880927374729744
Epoch: 100 | Iteration number: [530/565] 93% | Training loss: 0.6880691482211059
Epoch: 100 | Iteration number: [540/565] 95% | Training loss: 0.6880487788606573
Epoch: 100 | Iteration number: [550/565] 97% | Training loss: 0.6880169257250699
Epoch: 100 | Iteration number: [560/565] 99% | Training loss: 0.6879829959145614

 End of epoch: 100 | Train Loss: 0.6867593819061212 | Training Time: 90 

 End of epoch: 100 | Eval Loss: 0.6884803857122149 | Evaluating Time: 6 

 End of Test | Dice Loss: 0.9617135780198234 | Binary Cross Entropy With Logits Loss: 0.6896704946245465 
